{
    "title": "Privacy Loss of Noisy Stochastic Gradient Descent Might Converge Even for Non-Convex Losses. (arXiv:2305.09903v1 [cs.LG])",
    "abstract": "The Noisy-SGD algorithm is widely used for privately training machine learning models. Traditional privacy analyses of this algorithm assume that the internal state is publicly revealed, resulting in privacy loss bounds that increase indefinitely with the number of iterations. However, recent findings have shown that if the internal state remains hidden, then the privacy loss might remain bounded. Nevertheless, this remarkable result heavily relies on the assumption of (strong) convexity of the loss function. It remains an important open problem to further relax this condition while proving similar convergent upper bounds on the privacy loss. In this work, we address this problem for DP-SGD, a popular variant of Noisy-SGD that incorporates gradient clipping to limit the impact of individual samples on the training process. Our findings demonstrate that the privacy loss of projected DP-SGD converges exponentially fast, without requiring convexity or smoothness assumptions on the loss fu",
    "link": "http://arxiv.org/abs/2305.09903",
    "context": "Title: Privacy Loss of Noisy Stochastic Gradient Descent Might Converge Even for Non-Convex Losses. (arXiv:2305.09903v1 [cs.LG])\nAbstract: The Noisy-SGD algorithm is widely used for privately training machine learning models. Traditional privacy analyses of this algorithm assume that the internal state is publicly revealed, resulting in privacy loss bounds that increase indefinitely with the number of iterations. However, recent findings have shown that if the internal state remains hidden, then the privacy loss might remain bounded. Nevertheless, this remarkable result heavily relies on the assumption of (strong) convexity of the loss function. It remains an important open problem to further relax this condition while proving similar convergent upper bounds on the privacy loss. In this work, we address this problem for DP-SGD, a popular variant of Noisy-SGD that incorporates gradient clipping to limit the impact of individual samples on the training process. Our findings demonstrate that the privacy loss of projected DP-SGD converges exponentially fast, without requiring convexity or smoothness assumptions on the loss fu",
    "path": "papers/23/05/2305.09903.json",
    "total_tokens": 824,
    "translated_title": "噪声随机梯度下降的隐私损失可能会收敛，即使是对于非凸损失",
    "translated_abstract": "噪声随机梯度下降算法被广泛用于私密训练机器学习模型。但传统的隐私分析假定内部状态公开，导致随着迭代次数的增加隐私损失边界会无限增加。然而，最近的研究表明，如果内部状态保持隐藏，则隐私损失可能保持有限。本文解决了DP-SGD的问题，这是一种常用的包括梯度剪裁的噪声性SGD变体，以限制个体样本对训练过程的影响，在不需要损失函数强凸或平滑假设的情况下，我们发现经过投影的DP-SGD的隐私损失呈指数收敛。",
    "tldr": "本文研究了DP-SGD，一种常用的噪声性SGD变体，发现其隐私损失呈指数收敛，不需要损失函数强凸或平滑假设。",
    "en_tdlr": "This paper studies DP-SGD, a popular variant of noisy SGD with gradient clipping, and finds that its privacy loss converges exponentially fast without requiring strong convexity or smoothness assumptions on the loss function."
}