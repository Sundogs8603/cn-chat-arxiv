{
    "title": "Conditional Mutual Information for Disentangled Representations in Reinforcement Learning. (arXiv:2305.14133v2 [cs.LG] UPDATED)",
    "abstract": "Reinforcement Learning (RL) environments can produce training data with spurious correlations between features due to the amount of training data or its limited feature coverage. This can lead to RL agents encoding these misleading correlations in their latent representation, preventing the agent from generalising if the correlation changes within the environment or when deployed in the real world. Disentangled representations can improve robustness, but existing disentanglement techniques that minimise mutual information between features require independent features, thus they cannot disentangle correlated features. We propose an auxiliary task for RL algorithms that learns a disentangled representation of high-dimensional observations with correlated features by minimising the conditional mutual information between features in the representation. We demonstrate experimentally, using continuous control tasks, that our approach improves generalisation under correlation shifts, as well ",
    "link": "http://arxiv.org/abs/2305.14133",
    "context": "Title: Conditional Mutual Information for Disentangled Representations in Reinforcement Learning. (arXiv:2305.14133v2 [cs.LG] UPDATED)\nAbstract: Reinforcement Learning (RL) environments can produce training data with spurious correlations between features due to the amount of training data or its limited feature coverage. This can lead to RL agents encoding these misleading correlations in their latent representation, preventing the agent from generalising if the correlation changes within the environment or when deployed in the real world. Disentangled representations can improve robustness, but existing disentanglement techniques that minimise mutual information between features require independent features, thus they cannot disentangle correlated features. We propose an auxiliary task for RL algorithms that learns a disentangled representation of high-dimensional observations with correlated features by minimising the conditional mutual information between features in the representation. We demonstrate experimentally, using continuous control tasks, that our approach improves generalisation under correlation shifts, as well ",
    "path": "papers/23/05/2305.14133.json",
    "total_tokens": 885,
    "translated_title": "强化学习中用于解耦表示的条件互信息",
    "translated_abstract": "强化学习环境可以产生具有假相关性的训练数据，这是由于训练数据量或特征覆盖的有限性所导致的。这可能导致强化学习代理将这些误导性相关性编码到其潜在表示中，如果环境内的相关性发生变化或在真实世界中部署时，则会阻止代理进行泛化。解耦表示可以提高鲁棒性，但现有的最小化特征之间互信息的解耦技术要求特征之间是独立的，因此无法解耦相关特征。我们提出了一种用于强化学习算法的辅助任务，通过最小化表示中特征之间的条件互信息，学习具有相关特征的高维观测的解耦表示。我们在连续控制任务中进行了实验证明，我们的方法可以改善在相关性变化下的泛化性能，同时能够处理密集观测的相关特征。",
    "tldr": "本论文提出了一种用于解决强化学习中训练数据相关性问题的方法，通过最小化表示中特征之间的条件互信息，学习具有相关特征的解耦表示。实验证明该方法可以提高泛化性能并处理密集观测的相关特征。",
    "en_tdlr": "This paper proposes a method for addressing the issue of correlated training data in reinforcement learning by learning a disentangled representation with correlated features through minimizing the conditional mutual information between features. Experimental results demonstrate that this approach improves generalization performance and handles correlated features in dense observations."
}