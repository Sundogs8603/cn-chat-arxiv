{
    "title": "Cross-Domain Policy Adaptation via Value-Guided Data Filtering. (arXiv:2305.17625v2 [cs.LG] UPDATED)",
    "abstract": "Generalizing policies across different domains with dynamics mismatch poses a significant challenge in reinforcement learning. For example, a robot learns the policy in a simulator, but when it is deployed in the real world, the dynamics of the environment may be different. Given the source and target domain with dynamics mismatch, we consider the online dynamics adaptation problem, in which case the agent can access sufficient source domain data while online interactions with the target domain are limited. Existing research has attempted to solve the problem from the dynamics discrepancy perspective. In this work, we reveal the limitations of these methods and explore the problem from the value difference perspective via a novel insight on the value consistency across domains. Specifically, we present the Value-Guided Data Filtering (VGDF) algorithm, which selectively shares transitions from the source domain based on the proximity of paired value targets across the two domains. Empir",
    "link": "http://arxiv.org/abs/2305.17625",
    "context": "Title: Cross-Domain Policy Adaptation via Value-Guided Data Filtering. (arXiv:2305.17625v2 [cs.LG] UPDATED)\nAbstract: Generalizing policies across different domains with dynamics mismatch poses a significant challenge in reinforcement learning. For example, a robot learns the policy in a simulator, but when it is deployed in the real world, the dynamics of the environment may be different. Given the source and target domain with dynamics mismatch, we consider the online dynamics adaptation problem, in which case the agent can access sufficient source domain data while online interactions with the target domain are limited. Existing research has attempted to solve the problem from the dynamics discrepancy perspective. In this work, we reveal the limitations of these methods and explore the problem from the value difference perspective via a novel insight on the value consistency across domains. Specifically, we present the Value-Guided Data Filtering (VGDF) algorithm, which selectively shares transitions from the source domain based on the proximity of paired value targets across the two domains. Empir",
    "path": "papers/23/05/2305.17625.json",
    "total_tokens": 863,
    "translated_title": "跨领域策略适应性通过价值导向数据过滤",
    "translated_abstract": "在强化学习中，不同领域之间的策略泛化存在着动力学不匹配的重大挑战。例如，一个机器人在模拟器中学习策略，但当它在真实世界中部署时，环境的动力学可能会有所不同。针对动力学不匹配的源域和目标域，我们考虑在线动力学适应问题，在这种情况下，智能体可以访问足够的源域数据，而与目标域的在线交互是有限的。现有的研究试图从动力学差异的角度解决这个问题。在本文中，我们揭示了这些方法的局限性，并通过对领域之间价值的一种新的洞察，从价值差异的角度探索问题。具体而言，我们提出了基于价值目标对两个领域之间的配对值的距离的Value-Guided Data Filtering (VGDF)算法，该算法有选择性地共享来自源域的转换。Empir。",
    "tldr": "通过价值目标的一致性，我们提出了一种价值导向的数据过滤算法(VGDF)，用于解决在不同领域之间进行策略适应的问题。"
}