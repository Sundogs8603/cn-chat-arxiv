{
    "title": "Algorithmic Censoring in Dynamic Learning Systems. (arXiv:2305.09035v1 [cs.LG])",
    "abstract": "Dynamic learning systems subject to selective labeling exhibit censoring, i.e. persistent negative predictions assigned to one or more subgroups of points. In applications like consumer finance, this results in groups of applicants that are persistently denied and thus never enter into the training data. In this work, we formalize censoring, demonstrate how it can arise, and highlight difficulties in detection. We consider safeguards against censoring recourse and randomized-exploration - both of which ensure we collect labels for points that would otherwise go unobserved. The resulting techniques allow examples from censored groups to enter into the training data and correct the model. Our results highlight the otherwise unmeasured harms of censoring and demonstrate the effectiveness of mitigation strategies across a range of data generating processes.",
    "link": "http://arxiv.org/abs/2305.09035",
    "context": "Title: Algorithmic Censoring in Dynamic Learning Systems. (arXiv:2305.09035v1 [cs.LG])\nAbstract: Dynamic learning systems subject to selective labeling exhibit censoring, i.e. persistent negative predictions assigned to one or more subgroups of points. In applications like consumer finance, this results in groups of applicants that are persistently denied and thus never enter into the training data. In this work, we formalize censoring, demonstrate how it can arise, and highlight difficulties in detection. We consider safeguards against censoring recourse and randomized-exploration - both of which ensure we collect labels for points that would otherwise go unobserved. The resulting techniques allow examples from censored groups to enter into the training data and correct the model. Our results highlight the otherwise unmeasured harms of censoring and demonstrate the effectiveness of mitigation strategies across a range of data generating processes.",
    "path": "papers/23/05/2305.09035.json",
    "total_tokens": 807,
    "translated_title": "动态学习系统的算法审查",
    "translated_abstract": "受选择标记影响的动态学习系统可能会出现审查现象，即针对一组或多组数据点分配持续的负面预测。在消费金融等应用中，这会导致一些申请人组被持续拒绝，并且从未进入训练数据。本文规范化审查现象，展示其可能的出现方式，并强调检测的难度。我们考虑采取防范审查的措施，并进行随机探索，这两种方法都能确保我们对原本未观察到的数据点进行标注。由此产生的技术能够让来自被审查组的样本进入训练数据并纠正模型。我们的结果突显了审查的不可测量的危害，并展示了在各种数据生成过程中缓解策略的有效性。",
    "tldr": "本文介绍了动态学习系统中可能出现的审查现象，并且提出了防范审查的措施以及随机探索，从而确保来自被审查组的样本进入训练数据，并纠正模型。",
    "en_tdlr": "This paper formalizes the concept of censoring in dynamic learning systems subject to selective labeling and proposes measures like recourse and randomized-exploration to prevent censoring, allowing previously unobserved data to enter training data and improve model accuracy."
}