{
    "title": "AdvFunMatch: When Consistent Teaching Meets Adversarial Robustness. (arXiv:2305.14700v1 [cs.LG])",
    "abstract": "\\emph{Consistent teaching} is an effective paradigm for implementing knowledge distillation (KD), where both student and teacher models receive identical inputs, and KD is treated as a function matching task (FunMatch). However, one limitation of FunMatch is that it does not account for the transfer of adversarial robustness, a model's resistance to adversarial attacks. To tackle this problem, we propose a simple but effective strategy called Adversarial Function Matching (AdvFunMatch), which aims to match distributions for all data points within the $\\ell_p$-norm ball of the training data, in accordance with consistent teaching. Formulated as a min-max optimization problem, AdvFunMatch identifies the worst-case instances that maximizes the KL-divergence between teacher and student model outputs, which we refer to as \"mismatched examples,\" and then matches the outputs on these mismatched examples. Our experimental results show that AdvFunMatch effectively produces student models with b",
    "link": "http://arxiv.org/abs/2305.14700",
    "context": "Title: AdvFunMatch: When Consistent Teaching Meets Adversarial Robustness. (arXiv:2305.14700v1 [cs.LG])\nAbstract: \\emph{Consistent teaching} is an effective paradigm for implementing knowledge distillation (KD), where both student and teacher models receive identical inputs, and KD is treated as a function matching task (FunMatch). However, one limitation of FunMatch is that it does not account for the transfer of adversarial robustness, a model's resistance to adversarial attacks. To tackle this problem, we propose a simple but effective strategy called Adversarial Function Matching (AdvFunMatch), which aims to match distributions for all data points within the $\\ell_p$-norm ball of the training data, in accordance with consistent teaching. Formulated as a min-max optimization problem, AdvFunMatch identifies the worst-case instances that maximizes the KL-divergence between teacher and student model outputs, which we refer to as \"mismatched examples,\" and then matches the outputs on these mismatched examples. Our experimental results show that AdvFunMatch effectively produces student models with b",
    "path": "papers/23/05/2305.14700.json",
    "total_tokens": 942,
    "translated_title": "AdvFunMatch: 当一致的教学遇见对抗鲁棒性",
    "translated_abstract": "“一致的教学”是一种有效的知识蒸馏实现范例，在这种范例下，学生和教师模型接收相同的输入，并将知识蒸馏视为函数匹配任务（FunMatch）。然而，FunMatch 的一个限制是它没有考虑到模型的对抗鲁棒性，即模型抵抗对抗性攻击的能力。为解决这个问题，我们提出了一种简单而有效的策略，称为对抗函数匹配（AdvFunMatch），该策略旨在在一致教学的前提下，匹配训练数据 $\\ell_p$-范数球内的所有数据点的分布。AdvFunMatch 被制定为极小化-极大化优化问题，它确定了最大化教师模型和学生模型输出之间 KL 散度的最坏实例（我们称之为“不匹配实例”），然后匹配这些不匹配实例上的输出。我们的实验结果表明，AdvFunMatch 可以有效地生成具有强对抗性的学生模型。",
    "tldr": "AdvFunMatch是一种可以提高模型对抗鲁棒性的方法，它通过一致教学的方式，在匹配成功数据点的前提下，在训练数据的球形空间内匹配所有数据点的分布",
    "en_tdlr": "AdvFunMatch is a method that improves the adversarial robustness of models, which matches the distributions of all data points within the $\\ell_p$-norm ball of training data, under the principle of consistent teaching. It identifies the mismatched examples that maximize the KL-divergence between teacher and student model outputs and matches the outputs on these instances."
}