{
    "title": "Explaining V1 Properties with a Biologically Constrained Deep Learning Architecture. (arXiv:2305.11275v1 [q-bio.NC])",
    "abstract": "Convolutional neural networks (CNNs) have recently emerged as promising models of the ventral visual stream, despite their lack of biological specificity. While current state-of-the-art models of the primary visual cortex (V1) have surfaced from training with adversarial examples and extensively augmented data, these models are still unable to explain key neural properties observed in V1 that arise from biological circuitry. To address this gap, we systematically incorporated neuroscience-derived architectural components into CNNs to identify a set of mechanisms and architectures that comprehensively explain neural activity in V1. We show drastic improvements in model-V1 alignment driven by the integration of architectural components that simulate center-surround antagonism, local receptive fields, tuned normalization, and cortical magnification. Upon enhancing task-driven CNNs with a collection of these specialized components, we uncover models with latent representations that yield s",
    "link": "http://arxiv.org/abs/2305.11275",
    "context": "Title: Explaining V1 Properties with a Biologically Constrained Deep Learning Architecture. (arXiv:2305.11275v1 [q-bio.NC])\nAbstract: Convolutional neural networks (CNNs) have recently emerged as promising models of the ventral visual stream, despite their lack of biological specificity. While current state-of-the-art models of the primary visual cortex (V1) have surfaced from training with adversarial examples and extensively augmented data, these models are still unable to explain key neural properties observed in V1 that arise from biological circuitry. To address this gap, we systematically incorporated neuroscience-derived architectural components into CNNs to identify a set of mechanisms and architectures that comprehensively explain neural activity in V1. We show drastic improvements in model-V1 alignment driven by the integration of architectural components that simulate center-surround antagonism, local receptive fields, tuned normalization, and cortical magnification. Upon enhancing task-driven CNNs with a collection of these specialized components, we uncover models with latent representations that yield s",
    "path": "papers/23/05/2305.11275.json",
    "total_tokens": 809,
    "translated_title": "用生物约束深度学习架构解释V1特性",
    "translated_abstract": "尽管缺乏生物学的特异性，卷积神经网络(CNNs)最近被认为是腹侧视觉通路的有前途的模型。虽然当前的最先进的V1模型是通过对抗性例子的训练和广泛增强的数据浮现出来的，但这些模型仍无法解释V1中观察到的关键神经特性，这些特性来自于生物电路。为了弥补这个差距，我们系统地将神经科学的架构组件纳入CNNs中，以识别一组全面解释V1神经活动的机制和架构。我们展示了通过集成模拟中心-周围拮抗、局部感受野、调谐归一化和皮层放大的架构组件来推动模型-V1对齐的巨大改进。通过使用这些专门的组件增强任务驱动的CNNs，我们发现了潜在表示产生了优秀的模型。",
    "tldr": "该论文使用生物特性构建CNNs架构，成功解释V1神经活动特性。"
}