{
    "title": "An Exploration of Encoder-Decoder Approaches to Multi-Label Classification for Legal and Biomedical Text. (arXiv:2305.05627v1 [cs.CL])",
    "abstract": "Standard methods for multi-label text classification largely rely on encoder-only pre-trained language models, whereas encoder-decoder models have proven more effective in other classification tasks. In this study, we compare four methods for multi-label classification, two based on an encoder only, and two based on an encoder-decoder. We carry out experiments on four datasets -two in the legal domain and two in the biomedical domain, each with two levels of label granularity- and always depart from the same pre-trained model, T5. Our results show that encoder-decoder methods outperform encoder-only methods, with a growing advantage on more complex datasets and labeling schemes of finer granularity. Using encoder-decoder models in a non-autoregressive fashion, in particular, yields the best performance overall, so we further study this approach through ablations to better understand its strengths.",
    "link": "http://arxiv.org/abs/2305.05627",
    "context": "Title: An Exploration of Encoder-Decoder Approaches to Multi-Label Classification for Legal and Biomedical Text. (arXiv:2305.05627v1 [cs.CL])\nAbstract: Standard methods for multi-label text classification largely rely on encoder-only pre-trained language models, whereas encoder-decoder models have proven more effective in other classification tasks. In this study, we compare four methods for multi-label classification, two based on an encoder only, and two based on an encoder-decoder. We carry out experiments on four datasets -two in the legal domain and two in the biomedical domain, each with two levels of label granularity- and always depart from the same pre-trained model, T5. Our results show that encoder-decoder methods outperform encoder-only methods, with a growing advantage on more complex datasets and labeling schemes of finer granularity. Using encoder-decoder models in a non-autoregressive fashion, in particular, yields the best performance overall, so we further study this approach through ablations to better understand its strengths.",
    "path": "papers/23/05/2305.05627.json",
    "total_tokens": 902,
    "translated_title": "编码器-解码器方法在法律和生物医学文本的多标签分类中的探索",
    "translated_abstract": "多标签文本分类的标准方法主要依赖于仅具有编码器的预训练语言模型，而编码器-解码器模型在其他分类任务中已被证明更有效。本研究比较了四种多标签分类方法，其中两种基于仅具有编码器，两种基于编码器-解码器。我们在四个数据集上进行了实验，其中两个是法律领域的，两个是生物医学领域的，每个数据集都有两个标签粒度级别，并始终从同一预训练模型T5出发。结果表明，编码器-解码器方法优于仅具有编码器的方法，在更复杂的数据集和标签粒度更细的标签方案上优势越来越明显。特别是在非自回归的情况下使用编码器-解码器模型，整体上表现最佳，因此我们通过消融研究来进一步研究这种方法以更好地理解其优点。",
    "tldr": "本研究探索了编码器-解码器方法在多标签分类中的应用，结果表明该方法在更复杂的数据集和标签粒度更细的标签方案上表现更佳，尤其是在非自回归的情况下使用最佳。",
    "en_tdlr": "This study explores the application of encoder-decoder approaches to multi-label classification and finds that they outperform encoder-only methods, particularly in more complex datasets and finer label granularity, with non-autoregressive encoder-decoder models yielding the best performance."
}