{
    "title": "Constrained Optimization via Exact Augmented Lagrangian and Randomized Iterative Sketching. (arXiv:2305.18379v1 [math.OC])",
    "abstract": "We consider solving equality-constrained nonlinear, nonconvex optimization problems. This class of problems appears widely in a variety of applications in machine learning and engineering, ranging from constrained deep neural networks, to optimal control, to PDE-constrained optimization. We develop an adaptive inexact Newton method for this problem class. In each iteration, we solve the Lagrangian Newton system inexactly via a randomized iterative sketching solver, and select a suitable stepsize by performing line search on an exact augmented Lagrangian merit function. The randomized solvers have advantages over deterministic linear system solvers by significantly reducing per-iteration flops complexity and storage cost, when equipped with suitable sketching matrices. Our method adaptively controls the accuracy of the randomized solver and the penalty parameters of the exact augmented Lagrangian, to ensure that the inexact Newton direction is a descent direction of the exact augmented ",
    "link": "http://arxiv.org/abs/2305.18379",
    "context": "Title: Constrained Optimization via Exact Augmented Lagrangian and Randomized Iterative Sketching. (arXiv:2305.18379v1 [math.OC])\nAbstract: We consider solving equality-constrained nonlinear, nonconvex optimization problems. This class of problems appears widely in a variety of applications in machine learning and engineering, ranging from constrained deep neural networks, to optimal control, to PDE-constrained optimization. We develop an adaptive inexact Newton method for this problem class. In each iteration, we solve the Lagrangian Newton system inexactly via a randomized iterative sketching solver, and select a suitable stepsize by performing line search on an exact augmented Lagrangian merit function. The randomized solvers have advantages over deterministic linear system solvers by significantly reducing per-iteration flops complexity and storage cost, when equipped with suitable sketching matrices. Our method adaptively controls the accuracy of the randomized solver and the penalty parameters of the exact augmented Lagrangian, to ensure that the inexact Newton direction is a descent direction of the exact augmented ",
    "path": "papers/23/05/2305.18379.json",
    "total_tokens": 1021,
    "translated_title": "精确增广拉格朗日和随机迭代草图算法求解约束优化问题",
    "translated_abstract": "本文考虑解决等式约束的非线性、非凸优化问题。这类问题在机器学习和工程领域的各种应用中广泛出现，包括受约束的深度神经网络、最优控制和PDE约束优化。我们针对这类问题开发了一种自适应的不精确牛顿法。在每次迭代中，我们通过随机迭代草图求解增广拉格朗日牛顿系统，并通过在精确增广拉格朗日优势函数上执行线搜索来选择合适的步长。当配备适当的草图矩阵时，随机求解器相对于确定性线性系统求解器具有明显优势，可以显著减少每次迭代的浮点运算复杂度和存储成本。我们的方法自适应地控制随机求解器的精度和增广拉格朗日的惩罚参数，以确保不精确的牛顿方向是精确增广拉格朗日函数的下降方向。理论分析和数值实验均证明了所提出方法的效率和鲁棒性。",
    "tldr": "本文提出了一种自适应的不精确牛顿法来求解等式约束的非线性、非凸优化问题，通过随机迭代草图求解增广拉格朗日牛顿系统，并通过在精确增广拉格朗日优势函数上执行线搜索来选择合适的步长。该方法具有高效、鲁棒性好的特点。",
    "en_tdlr": "The paper proposes an adaptive inexact Newton method for solving equality-constrained nonlinear, nonconvex optimization problems, using randomized iterative sketching solver for the Lagrangian Newton system and line search on an exact augmented Lagrangian merit function for selecting suitable stepsize. The method has advantages such as efficiency and robustness."
}