{
    "title": "Alteration-free and Model-agnostic Origin Attribution of Generated Images. (arXiv:2305.18439v1 [cs.CV])",
    "abstract": "Recently, there has been a growing attention in image generation models. However, concerns have emerged regarding potential misuse and intellectual property (IP) infringement associated with these models. Therefore, it is necessary to analyze the origin of images by inferring if a specific image was generated by a particular model, i.e., origin attribution. Existing methods are limited in their applicability to specific types of generative models and require additional steps during training or generation. This restricts their use with pre-trained models that lack these specific operations and may compromise the quality of image generation. To overcome this problem, we first develop an alteration-free and model-agnostic origin attribution method via input reverse-engineering on image generation models, i.e., inverting the input of a particular model for a specific image. Given a particular model, we first analyze the differences in the hardness of reverse-engineering tasks for the gener",
    "link": "http://arxiv.org/abs/2305.18439",
    "context": "Title: Alteration-free and Model-agnostic Origin Attribution of Generated Images. (arXiv:2305.18439v1 [cs.CV])\nAbstract: Recently, there has been a growing attention in image generation models. However, concerns have emerged regarding potential misuse and intellectual property (IP) infringement associated with these models. Therefore, it is necessary to analyze the origin of images by inferring if a specific image was generated by a particular model, i.e., origin attribution. Existing methods are limited in their applicability to specific types of generative models and require additional steps during training or generation. This restricts their use with pre-trained models that lack these specific operations and may compromise the quality of image generation. To overcome this problem, we first develop an alteration-free and model-agnostic origin attribution method via input reverse-engineering on image generation models, i.e., inverting the input of a particular model for a specific image. Given a particular model, we first analyze the differences in the hardness of reverse-engineering tasks for the gener",
    "path": "papers/23/05/2305.18439.json",
    "total_tokens": 1040,
    "translated_title": "无改动且模型无关的生成图像源头归属方法",
    "translated_abstract": "近年来，生成图像模型受到了越来越多的关注。然而，这些模型存在潜在的滥用和知识产权侵权问题，因此有必要分析图像的来源，推断某个特定的模型是否生成了一张特定的图像，即原始归属。现有的方法在适用于特定类型的生成模型时存在限制，并且需要在训练或生成过程中进行额外的处理步骤。这限制了它们与缺少这些特定操作的预训练模型的使用，并可能影响图像生成的质量。为了解决这个问题，我们首先通过对生成图像模型的输入反向工程来开发一种无改动且模型无关的源头归属方法，即对于特定图像反转某特定模型的输入。给定一个特定的模型，我们首先分析反向工程任务在生成的图像和真实图像之间的难度差异，然后提出了一种度量方法来衡量这些任务之间的差异。基于这个度量标准，我们设计了一个模型无关的源头归属方法，不依赖于改动或额外的训练要求。我们的结果表明，我们的方法在准确性和灵活性方面优于现有技术。",
    "tldr": "该论文提出了一种无需改动且适用于多种生成模型的源头归属方法，通过反向工程分析生成图片的来源，解决了现有方法对特定型号的依赖限制问题，并取得了准确性和灵活性的提高。",
    "en_tdlr": "This paper proposes an alteration-free and model-agnostic origin attribution method for generated images, which uses input reverse-engineering to analyze the origin of images and overcomes the limitations of existing methods. The method outperforms state-of-the-art methods in both accuracy and flexibility."
}