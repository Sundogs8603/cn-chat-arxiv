{
    "title": "Masked Audio Text Encoders are Effective Multi-Modal Rescorers. (arXiv:2305.07677v1 [cs.SD])",
    "abstract": "Masked Language Models (MLMs) have proven to be effective for second-pass rescoring in Automatic Speech Recognition (ASR) systems. In this work, we propose Masked Audio Text Encoder (MATE), a multi-modal masked language model rescorer which incorporates acoustic representations into the input space of MLM. We adopt contrastive learning for effectively aligning the modalities by learning shared representations. We show that using a multi-modal rescorer is beneficial for domain generalization of the ASR system when target domain data is unavailable. MATE reduces word error rate (WER) by 4%-16% on in-domain, and 3%-7% on out-of-domain datasets, over the text-only baseline. Additionally, with very limited amount of training data (0.8 hours), MATE achieves a WER reduction of 8%-23% over the first-pass baseline.",
    "link": "http://arxiv.org/abs/2305.07677",
    "context": "Title: Masked Audio Text Encoders are Effective Multi-Modal Rescorers. (arXiv:2305.07677v1 [cs.SD])\nAbstract: Masked Language Models (MLMs) have proven to be effective for second-pass rescoring in Automatic Speech Recognition (ASR) systems. In this work, we propose Masked Audio Text Encoder (MATE), a multi-modal masked language model rescorer which incorporates acoustic representations into the input space of MLM. We adopt contrastive learning for effectively aligning the modalities by learning shared representations. We show that using a multi-modal rescorer is beneficial for domain generalization of the ASR system when target domain data is unavailable. MATE reduces word error rate (WER) by 4%-16% on in-domain, and 3%-7% on out-of-domain datasets, over the text-only baseline. Additionally, with very limited amount of training data (0.8 hours), MATE achieves a WER reduction of 8%-23% over the first-pass baseline.",
    "path": "papers/23/05/2305.07677.json",
    "total_tokens": 957,
    "translated_title": "Masked Audio Text Encoders 在多模态重打分中是有效的。",
    "translated_abstract": "掩码语言模型（MLM）已被证明对于自动语音识别（ASR）系统的二次打分非常有效。在这项工作中，我们提出 Masked Audio Text Encoder（MATE），它是一个多模态掩码语言模型重新打分器，将声学表示形式并入到MLM的输入空间中。我们采用对比学习来通过学习共享表示来有效地对齐各种模态。我们发现，当目标域数据不可用时，使用多模态重新打分器对ASR系统的领域泛化很有好处。与仅文本的基线相比，在域内数据组上，MATE 可以将单词错误率（WER）降低4％-16％，在域外数据组上可将WER降低3％-7％。此外，仅使用非常有限的训练数据（0.8小时），MATE就可以将WER比一次打分的基线降低8％-23％。",
    "tldr": "本文提出了Masked Audio Text Encoders（MATE），一个多模态掩码语言模型重新打分器，将声学表示形式并入到MLM的输入空间中。使用MATE对自动语音识别（ASR）系统进行多模态打分，即使在目标域数据不足的情况下，也可以提高系统的领域泛化能力，并且可以在非常有限的训练数据量下就将单词错误率（WER）降低。"
}