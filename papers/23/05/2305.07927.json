{
    "title": "RC3: Regularized Contrastive Cross-lingual Cross-modal Pre-training. (arXiv:2305.07927v1 [cs.CL])",
    "abstract": "Multilingual vision-language (V&L) pre-training has achieved remarkable progress in learning universal representations across different modalities and languages. In spite of recent success, there still remain challenges limiting further improvements of V&L pre-trained models in multilingual settings. Particularly, current V&L pre-training methods rely heavily on strictly-aligned multilingual image-text pairs generated from English-centric datasets through machine translation. However, the cost of collecting and translating such strictly-aligned datasets is usually unbearable. In this paper, we propose Regularized Contrastive Cross-lingual Cross-modal (RC^3) pre-training, which further exploits more abundant weakly-aligned multilingual image-text pairs. Specifically, we design a regularized cross-lingual visio-textual contrastive learning objective that constrains the representation proximity of weakly-aligned visio-textual inputs according to textual relevance. Besides, existing V&L pr",
    "link": "http://arxiv.org/abs/2305.07927",
    "context": "Title: RC3: Regularized Contrastive Cross-lingual Cross-modal Pre-training. (arXiv:2305.07927v1 [cs.CL])\nAbstract: Multilingual vision-language (V&L) pre-training has achieved remarkable progress in learning universal representations across different modalities and languages. In spite of recent success, there still remain challenges limiting further improvements of V&L pre-trained models in multilingual settings. Particularly, current V&L pre-training methods rely heavily on strictly-aligned multilingual image-text pairs generated from English-centric datasets through machine translation. However, the cost of collecting and translating such strictly-aligned datasets is usually unbearable. In this paper, we propose Regularized Contrastive Cross-lingual Cross-modal (RC^3) pre-training, which further exploits more abundant weakly-aligned multilingual image-text pairs. Specifically, we design a regularized cross-lingual visio-textual contrastive learning objective that constrains the representation proximity of weakly-aligned visio-textual inputs according to textual relevance. Besides, existing V&L pr",
    "path": "papers/23/05/2305.07927.json",
    "total_tokens": 940,
    "translated_title": "RC3: 规则化对比跨语言跨模态预训练",
    "translated_abstract": "多语种视觉-语言（V&L）预训练已经在跨不同语言和模态中实现了显著进展。尽管最近取得了成功，但仍存在挑战限制了V&L预训练模型在多语种环境中的进一步改进。本文提出规则化对比跨语言跨模态（RC^3）预训练，进一步利用更丰富的弱对准多语种图像-文本对。具体来说，设计一种规则化的跨语言视觉-文本对比学习目标，根据文本相关性约束弱对准视觉-文本输入的表示接近度。此外，现有的V&L预训练方法大多依赖于英语为中心的数据集，但收集和翻译严格对齐的多语种图像-文本对的成本通常是难以承受的。",
    "tldr": "本文提出了RC3预训练方法，通过规则化对比跨语言跨模态学习，有效利用弱对准的多语种图像-文本对，从而在多语种V&L任务中取得了更好的性能。"
}