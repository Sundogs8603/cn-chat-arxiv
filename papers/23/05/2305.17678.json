{
    "title": "Decoding the Underlying Meaning of Multimodal Hateful Memes. (arXiv:2305.17678v2 [cs.CL] UPDATED)",
    "abstract": "Recent studies have proposed models that yielded promising performance for the hateful meme classification task. Nevertheless, these proposed models do not generate interpretable explanations that uncover the underlying meaning and support the classification output. A major reason for the lack of explainable hateful meme methods is the absence of a hateful meme dataset that contains ground truth explanations for benchmarking or training. Intuitively, having such explanations can educate and assist content moderators in interpreting and removing flagged hateful memes. This paper address this research gap by introducing Hateful meme with Reasons Dataset (HatReD), which is a new multimodal hateful meme dataset annotated with the underlying hateful contextual reasons. We also define a new conditional generation task that aims to automatically generate underlying reasons to explain hateful memes and establish the baseline performance of state-of-the-art pre-trained language models on this t",
    "link": "http://arxiv.org/abs/2305.17678",
    "context": "Title: Decoding the Underlying Meaning of Multimodal Hateful Memes. (arXiv:2305.17678v2 [cs.CL] UPDATED)\nAbstract: Recent studies have proposed models that yielded promising performance for the hateful meme classification task. Nevertheless, these proposed models do not generate interpretable explanations that uncover the underlying meaning and support the classification output. A major reason for the lack of explainable hateful meme methods is the absence of a hateful meme dataset that contains ground truth explanations for benchmarking or training. Intuitively, having such explanations can educate and assist content moderators in interpreting and removing flagged hateful memes. This paper address this research gap by introducing Hateful meme with Reasons Dataset (HatReD), which is a new multimodal hateful meme dataset annotated with the underlying hateful contextual reasons. We also define a new conditional generation task that aims to automatically generate underlying reasons to explain hateful memes and establish the baseline performance of state-of-the-art pre-trained language models on this t",
    "path": "papers/23/05/2305.17678.json",
    "total_tokens": 817,
    "translated_abstract": "最近的研究提出了一些模型，为恶意表情包分类任务带来了良好的性能。然而，这些模型并没有生成可解释的说明来揭示潜在意义并支持分类输出。缺少可解释的恶意表情包方法的主要原因是缺乏恶意表情包数据集，该数据集包含基准测试或训练的真实解释。可以直观地看出，拥有这样的解释可以帮助内容管理员解释和删除标记的恶意表情包。本文通过引入包含基于多模态的恶意表情包数据集（HatReD）注释的潜在恶意上下文原因来解决这一研究差距。我们还定义了一个新的条件生成任务，旨在自动生成解释恶意表情包的潜在原因，并建立了状态最先进的预训练语言模型在此任务上的基线性能。",
    "tldr": "本文介绍了一个新的多模态恶意表情包数据集，其中包含潜在的恶意上下文原因，并定义了一个条件生成任务来自动生成解释这些表情包的潜在原因。",
    "en_tdlr": "This paper introduces a new multimodal dataset for hateful memes with underlying contextual reasons annotated, and defines a conditional generation task to automatically generate underlying reasons to explain these memes."
}