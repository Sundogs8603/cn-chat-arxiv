{
    "title": "An Empirical Comparison of Optimizers for Quantum Machine Learning with SPSA-based Gradients. (arXiv:2305.00224v1 [quant-ph])",
    "abstract": "VQA have attracted a lot of attention from the quantum computing community for the last few years. Their hybrid quantum-classical nature with relatively shallow quantum circuits makes them a promising platform for demonstrating the capabilities of NISQ devices. Although the classical machine learning community focuses on gradient-based parameter optimization, finding near-exact gradients for VQC with the parameter-shift rule introduces a large sampling overhead. Therefore, gradient-free optimizers have gained popularity in quantum machine learning circles. Among the most promising candidates is the SPSA algorithm, due to its low computational cost and inherent noise resilience. We introduce a novel approach that uses the approximated gradient from SPSA in combination with state-of-the-art gradient-based classical optimizers. We demonstrate numerically that this outperforms both standard SPSA and the parameter-shift rule in terms of convergence rate and absolute error in simple regressi",
    "link": "http://arxiv.org/abs/2305.00224",
    "context": "Title: An Empirical Comparison of Optimizers for Quantum Machine Learning with SPSA-based Gradients. (arXiv:2305.00224v1 [quant-ph])\nAbstract: VQA have attracted a lot of attention from the quantum computing community for the last few years. Their hybrid quantum-classical nature with relatively shallow quantum circuits makes them a promising platform for demonstrating the capabilities of NISQ devices. Although the classical machine learning community focuses on gradient-based parameter optimization, finding near-exact gradients for VQC with the parameter-shift rule introduces a large sampling overhead. Therefore, gradient-free optimizers have gained popularity in quantum machine learning circles. Among the most promising candidates is the SPSA algorithm, due to its low computational cost and inherent noise resilience. We introduce a novel approach that uses the approximated gradient from SPSA in combination with state-of-the-art gradient-based classical optimizers. We demonstrate numerically that this outperforms both standard SPSA and the parameter-shift rule in terms of convergence rate and absolute error in simple regressi",
    "path": "papers/23/05/2305.00224.json",
    "total_tokens": 944,
    "translated_title": "一种基于SPSA梯度的优化器在量子机器学习中的实证比较",
    "translated_abstract": "在过去几年中，VQA已经引起了量子计算社区的很多关注。它们的混合量子-经典特性与相对浅的量子电路使其成为展示NISQ设备能力的有前途平台。虽然经典机器学习社区专注于基于梯度的参数优化，但使用参数移动规则寻找接近精确梯度的VQC会引入大量采样开销。因此，无梯度优化器在量子机器学习圈中变得越来越受欢迎。最有前途的候选者之一是SPSA算法，由于其低计算成本和固有的噪声鲁棒性。我们介绍了一种新方法，该方法结合了来自SPSA的近似梯度和最先进的基于梯度的经典优化器。我们通过数值实验证明，这种方法在简单回归的收敛速度和绝对误差方面优于标准的SPSA和参数移动规则。",
    "tldr": "本文对比了基于梯度和基于SPSA算法的量子机器学习优化器的性能，提出了一种新方法，该方法结合了来自SPSA的近似梯度和最先进的基于梯度的经典优化器，在简单回归中达到更好的收敛效果和更小的误差。",
    "en_tdlr": "This paper empirically compares optimizers based on gradient and SPSA algorithm for quantum machine learning, proposes a novel approach that combines the approximated gradient from SPSA and state-of-the-art gradient-based classical optimizers, and demonstrates its superior performance in terms of convergence rate and absolute error in simple regression."
}