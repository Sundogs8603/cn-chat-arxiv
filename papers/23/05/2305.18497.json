{
    "title": "Collaborative Learning via Prediction Consensus. (arXiv:2305.18497v1 [cs.LG])",
    "abstract": "We consider a collaborative learning setting where each agent's goal is to improve their own model by leveraging the expertise of collaborators, in addition to their own training data. To facilitate the exchange of expertise among agents, we propose a distillation-based method leveraging unlabeled auxiliary data, which is pseudo-labeled by the collective. Central to our method is a trust weighting scheme which serves to adaptively weigh the influence of each collaborator on the pseudo-labels until a consensus on how to label the auxiliary data is reached. We demonstrate that our collaboration scheme is able to significantly boost individual model's performance with respect to the global distribution, compared to local training. At the same time, the adaptive trust weights can effectively identify and mitigate the negative impact of bad models on the collective. We find that our method is particularly effective in the presence of heterogeneity among individual agents, both in terms of t",
    "link": "http://arxiv.org/abs/2305.18497",
    "context": "Title: Collaborative Learning via Prediction Consensus. (arXiv:2305.18497v1 [cs.LG])\nAbstract: We consider a collaborative learning setting where each agent's goal is to improve their own model by leveraging the expertise of collaborators, in addition to their own training data. To facilitate the exchange of expertise among agents, we propose a distillation-based method leveraging unlabeled auxiliary data, which is pseudo-labeled by the collective. Central to our method is a trust weighting scheme which serves to adaptively weigh the influence of each collaborator on the pseudo-labels until a consensus on how to label the auxiliary data is reached. We demonstrate that our collaboration scheme is able to significantly boost individual model's performance with respect to the global distribution, compared to local training. At the same time, the adaptive trust weights can effectively identify and mitigate the negative impact of bad models on the collective. We find that our method is particularly effective in the presence of heterogeneity among individual agents, both in terms of t",
    "path": "papers/23/05/2305.18497.json",
    "total_tokens": 940,
    "translated_abstract": "本文考虑了一种协作学习环境，其中每个代理的目标是通过利用协作者的经验来改进自己的模型，除了他们自己的训练数据之外。为了促进代理之间的专业知识交流，我们提出了一种基于无标签辅助数据的蒸馏方法，这些无标签数据由集体伪标记。我们方法的核心是一种信任加权方案，该方案可以自适应地加权每个协作者对伪标签的影响，直到达成关于如何标记辅助数据的共识。我们证明了我们的协作方案能够显著提高各个模型相对于全局分布的性能，与本地训练相比。同时，自适应的信任权重可以有效地识别和缓解坏模型对集体的负面影响。我们发现，我们的方法在个体代理之间存在异质性的情况下特别有效，无论是在模型结构还是在标签分布上。",
    "tldr": "本文提出了一种基于预测共识的协作学习方法，其中利用无标签辅助数据和自适应信任权重进行知识交流和模型升级。该方法能够显著提高个体模型性能并有效识别和缓解坏模型对集体的负面影响，在个体异质性情况下尤其有效。",
    "en_tdlr": "This paper proposes a collaborative learning method via prediction consensus, which leverages unlabeled auxiliary data and adaptive trust weights for knowledge exchange and model improvement. The method significantly improves individual model's performance and effectively identifies and mitigates the negative impact of bad models on the collective, especially in the presence of heterogeneity among individual agents."
}