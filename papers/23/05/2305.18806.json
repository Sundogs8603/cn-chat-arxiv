{
    "title": "Prediction Error-based Classification for Class-Incremental Learning. (arXiv:2305.18806v1 [cs.LG])",
    "abstract": "Class-incremental learning (CIL) is a particularly challenging variant of continual learning, where the goal is to learn to discriminate between all classes presented in an incremental fashion. Existing approaches often suffer from excessive forgetting and imbalance of the scores assigned to classes that have not been seen together during training. In this study, we introduce a novel approach, Prediction Error-based Classification (PEC), which differs from traditional discriminative and generative classification paradigms. PEC computes a class score by measuring the prediction error of a model trained to replicate the outputs of a frozen random neural network on data from that class. The method can be interpreted as approximating a classification rule based on Gaussian Process posterior variance. PEC offers several practical advantages, including sample efficiency, ease of tuning, and effectiveness even when data are presented one class at a time. Our empirical results show that PEC pe",
    "link": "http://arxiv.org/abs/2305.18806",
    "context": "Title: Prediction Error-based Classification for Class-Incremental Learning. (arXiv:2305.18806v1 [cs.LG])\nAbstract: Class-incremental learning (CIL) is a particularly challenging variant of continual learning, where the goal is to learn to discriminate between all classes presented in an incremental fashion. Existing approaches often suffer from excessive forgetting and imbalance of the scores assigned to classes that have not been seen together during training. In this study, we introduce a novel approach, Prediction Error-based Classification (PEC), which differs from traditional discriminative and generative classification paradigms. PEC computes a class score by measuring the prediction error of a model trained to replicate the outputs of a frozen random neural network on data from that class. The method can be interpreted as approximating a classification rule based on Gaussian Process posterior variance. PEC offers several practical advantages, including sample efficiency, ease of tuning, and effectiveness even when data are presented one class at a time. Our empirical results show that PEC pe",
    "path": "papers/23/05/2305.18806.json",
    "total_tokens": 915,
    "translated_title": "基于预测误差的增量学习分类方法",
    "translated_abstract": "增量学习分类是连续学习中的一个挑战性问题，目标是学习来区分所有类别。现有的方法在处理大量分类时容易出现过度遗忘和分数不均衡。本研究提出了一种新方法，名为预测误差分类（PEC），它与传统的判别和生成分类范式有所不同。PEC通过测量模型在从该类别中学习的数据上复制随机神经网络输出的预测误差来计算类别得分。该方法可以解释为基于高斯过程后验方差的分类规则的近似。PEC具有几个实际优势，包括样本效率高、易于调整以及即使在逐个呈现数据时也很有效。本文的实证结果表明PEC在广泛的基准测试中表现出色，可以与最先进的增量学习方法相竞争。",
    "tldr": "本论文提出了一种新的增量学习分类方法——基于预测误差的分类方法（PEC）。对PEC的评估表明，在各种基准测试中，PEC可以与最先进的增量学习方法相竞争，并具有许多实际优势，例如样本效率高、易于调整。",
    "en_tdlr": "This paper proposes a novel class-incremental learning classification approach called Prediction Error-based Classification (PEC) which measures the prediction error of a model to replicate the outputs of a frozen random neural network on data from that class. PEC performed competitively against state-of-the-art CIL methods on a wide range of benchmarks and offers practical advantages such as high sample efficiency and ease of tuning."
}