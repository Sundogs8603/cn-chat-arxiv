{
    "title": "The Vault: A Comprehensive Multilingual Dataset for Advancing Code Understanding and Generation. (arXiv:2305.06156v1 [cs.CL])",
    "abstract": "We present The Vault, an open-source, large-scale code-text dataset designed to enhance the training of code-focused large language models (LLMs). Existing open-source datasets for training code-based LLMs often face challenges in terms of size, quality (due to noisy signals), and format (only containing code function and text explanation pairings). The Vault overcomes these limitations by providing 40 million code-text pairs across 10 popular programming languages, thorough cleaning for 10+ prevalent issues, and various levels of code-text pairings, including class, function, and line levels. Researchers and practitioners can utilize The Vault for training diverse code-focused LLMs or incorporate the provided data cleaning methods and scripts to improve their datasets. By employing The Vault as the training dataset for code-centric LLMs, we anticipate significant advancements in code understanding and generation tasks, fostering progress in both artificial intelligence research and so",
    "link": "http://arxiv.org/abs/2305.06156",
    "context": "Title: The Vault: A Comprehensive Multilingual Dataset for Advancing Code Understanding and Generation. (arXiv:2305.06156v1 [cs.CL])\nAbstract: We present The Vault, an open-source, large-scale code-text dataset designed to enhance the training of code-focused large language models (LLMs). Existing open-source datasets for training code-based LLMs often face challenges in terms of size, quality (due to noisy signals), and format (only containing code function and text explanation pairings). The Vault overcomes these limitations by providing 40 million code-text pairs across 10 popular programming languages, thorough cleaning for 10+ prevalent issues, and various levels of code-text pairings, including class, function, and line levels. Researchers and practitioners can utilize The Vault for training diverse code-focused LLMs or incorporate the provided data cleaning methods and scripts to improve their datasets. By employing The Vault as the training dataset for code-centric LLMs, we anticipate significant advancements in code understanding and generation tasks, fostering progress in both artificial intelligence research and so",
    "path": "papers/23/05/2305.06156.json",
    "total_tokens": 919,
    "translated_title": "The Vault：一个全面的多语言数据集，为促进代码理解和生成而设计",
    "translated_abstract": "我们介绍了 The Vault，这是一个开源的大规模代码文本数据集，旨在增强面向代码的大型语言模型（LLM）的训练。现有的用于训练基于代码的LLM的开源数据集在大小、质量(由于噪声信号)和格式（仅包含代码函数和文本说明配对）方面经常面临挑战。The Vault通过提供10种流行编程语言的40百万行代码-文本对，彻底清除10种多样的问题，以及各种级别的代码-文本对，包括类、函数和代码行等级别，来克服这些限制。研究人员和从业人员可以利用The Vault来训练不同的面向代码的LLM，或者将提供的数据清洗方法和脚本合并到自己的数据集中来改进数据集。通过将The Vault作为面向代码的LLMs的训练数据集，我们预计在代码理解和生成任务上取得显著进展，促进人工智能研究和实践的发展。",
    "tldr": "The Vault是一个提供了10种流行编程语言的40百万行代码-文本对的开源数据集，旨在增强面向代码的大型语言模型（LLM）的训练，有望在代码理解和生成任务上取得显著进展。",
    "en_tdlr": "The Vault is an open-source, large-scale code-text dataset that provides 40 million code-text pairs across 10 popular programming languages, designed to enhance the training of code-focused large language models (LLMs), and expected to make significant progress in code understanding and generation tasks."
}