{
    "title": "Fisher Information Embedding for Node and Graph Learning. (arXiv:2305.07580v1 [stat.ML])",
    "abstract": "Attention-based graph neural networks (GNNs), such as graph attention networks (GATs), have become popular neural architectures for processing graph-structured data and learning node embeddings. Despite their empirical success, these models rely on labeled data and the theoretical properties of these models have yet to be fully understood. In this work, we propose a novel attention-based node embedding framework for graphs. Our framework builds upon a hierarchical kernel for multisets of subgraphs around nodes (e.g. neighborhoods) and each kernel leverages the geometry of a smooth statistical manifold to compare pairs of multisets, by \"projecting\" the multisets onto the manifold. By explicitly computing node embeddings with a manifold of Gaussian mixtures, our method leads to a new attention mechanism for neighborhood aggregation. We provide theoretical insights into genralizability and expressivity of our embeddings, contributing to a deeper understanding of attention-based GNNs. We p",
    "link": "http://arxiv.org/abs/2305.07580",
    "context": "Title: Fisher Information Embedding for Node and Graph Learning. (arXiv:2305.07580v1 [stat.ML])\nAbstract: Attention-based graph neural networks (GNNs), such as graph attention networks (GATs), have become popular neural architectures for processing graph-structured data and learning node embeddings. Despite their empirical success, these models rely on labeled data and the theoretical properties of these models have yet to be fully understood. In this work, we propose a novel attention-based node embedding framework for graphs. Our framework builds upon a hierarchical kernel for multisets of subgraphs around nodes (e.g. neighborhoods) and each kernel leverages the geometry of a smooth statistical manifold to compare pairs of multisets, by \"projecting\" the multisets onto the manifold. By explicitly computing node embeddings with a manifold of Gaussian mixtures, our method leads to a new attention mechanism for neighborhood aggregation. We provide theoretical insights into genralizability and expressivity of our embeddings, contributing to a deeper understanding of attention-based GNNs. We p",
    "path": "papers/23/05/2305.07580.json",
    "total_tokens": 857,
    "translated_title": "基于Fisher信息嵌入的节点和图学习",
    "translated_abstract": "基于注意力机制的图神经网络（GNN），例如图注意力网络（GAT），已成为处理图结构数据和学习节点嵌入的流行神经网络结构。尽管这些模型在经验上取得了成功，但它们依赖于标注数据，且这些模型的理论属性尚未完全理解。本文提出了一种新颖的基于注意力机制的图节点嵌入框架。我们的框架建立在一种多重集合内节点周围子图的分层核之上（例如，邻域），并且每个核利用平滑统计流形的几何来比较多重集合的成对差异，通过将多重集合“映射”到流形上。通过显式计算高斯混合物流形中的节点嵌入，我们的方法引导出了一种新的关注机制进行邻域聚合。我们提供了有关嵌入的泛化和表达能力的理论见解，为更深入理解基于注意力机制的GNN做出了贡献。",
    "tldr": "本文提出了一种新的基于注意力机制的图节点嵌入框架，可以更好地理解基于注意力机制的GNN。",
    "en_tdlr": "This paper proposes a novel attention-based node embedding framework for graphs, contributing to a deeper understanding of attention-based GNNs."
}