{
    "title": "Do Large Language Models Know What They Don't Know?. (arXiv:2305.18153v2 [cs.CL] UPDATED)",
    "abstract": "Large language models (LLMs) have a wealth of knowledge that allows them to excel in various Natural Language Processing (NLP) tasks. Current research focuses on enhancing their performance within their existing knowledge. Despite their vast knowledge, LLMs are still limited by the amount of information they can accommodate and comprehend. Therefore, the ability to understand their own limitations on the unknows, referred to as self-knowledge, is of paramount importance. This study aims to evaluate LLMs' self-knowledge by assessing their ability to identify unanswerable or unknowable questions. We introduce an automated methodology to detect uncertainty in the responses of these models, providing a novel measure of their self-knowledge. We further introduce a unique dataset, SelfAware, consisting of unanswerable questions from five diverse categories and their answerable counterparts. Our extensive analysis, involving 20 LLMs including GPT-3, InstructGPT, and LLaMA, discovering an intr",
    "link": "http://arxiv.org/abs/2305.18153",
    "context": "Title: Do Large Language Models Know What They Don't Know?. (arXiv:2305.18153v2 [cs.CL] UPDATED)\nAbstract: Large language models (LLMs) have a wealth of knowledge that allows them to excel in various Natural Language Processing (NLP) tasks. Current research focuses on enhancing their performance within their existing knowledge. Despite their vast knowledge, LLMs are still limited by the amount of information they can accommodate and comprehend. Therefore, the ability to understand their own limitations on the unknows, referred to as self-knowledge, is of paramount importance. This study aims to evaluate LLMs' self-knowledge by assessing their ability to identify unanswerable or unknowable questions. We introduce an automated methodology to detect uncertainty in the responses of these models, providing a novel measure of their self-knowledge. We further introduce a unique dataset, SelfAware, consisting of unanswerable questions from five diverse categories and their answerable counterparts. Our extensive analysis, involving 20 LLMs including GPT-3, InstructGPT, and LLaMA, discovering an intr",
    "path": "papers/23/05/2305.18153.json",
    "total_tokens": 981,
    "translated_title": "大型语言模型是否知道自己所不知道的内容？",
    "translated_abstract": "大型语言模型（LLM）具有丰富的知识，使它们能够在各种自然语言处理（NLP）任务中表现出色。当前的研究集中在增强它们在现有知识范畴内的性能。尽管它们拥有庞大的知识储备，但LLM仍然受到它们能够容纳和理解的信息总量限制。因此，理解它们在未知领域的限制，即所谓的自我认知能力，至关重要。本研究旨在评估LLM的自我认知能力，通过评估它们识别无法回答或不可知问题的能力。我们引入一种自动化方法来检测这些模型响应中的不确定性，提供它们自我认知的一种新度量。我们进一步引入一个独特的数据集SelfAware，包括来自五个不同类别的无法回答问题及其可回答对应问题。我们进行了广泛的分析，涉及20个LLM（包括GPT-3、InstructGPT和LLaMA），发现它们在识别无法回答问题并认识到自身限制方面存在显著差异。",
    "tldr": "本文研究大型语言模型（LLM）的自我认知能力，基于无法回答或不可知问题对它们进行评估，发现LLM在认识自身限制方面存在显著差异。",
    "en_tdlr": "This paper examines the self-knowledge of large language models (LLMs) by evaluating their ability to recognize unanswerable or unknowable questions and finds that there is a significant discrepancy in LLMs' ability to acknowledge their own limitations."
}