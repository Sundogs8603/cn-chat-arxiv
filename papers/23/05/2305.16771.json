{
    "title": "Robust Nonparametric Regression under Poisoning Attack. (arXiv:2305.16771v1 [math.ST])",
    "abstract": "This paper studies robust nonparametric regression, in which an adversarial attacker can modify the values of up to $q$ samples from a training dataset of size $N$. Our initial solution is an M-estimator based on Huber loss minimization. Compared with simple kernel regression, i.e. the Nadaraya-Watson estimator, this method can significantly weaken the impact of malicious samples on the regression performance. We provide the convergence rate as well as the corresponding minimax lower bound. The result shows that, with proper bandwidth selection, $\\ell_\\infty$ error is minimax optimal. The $\\ell_2$ error is optimal if $q\\lesssim \\sqrt{N/\\ln^2 N}$, but is suboptimal with larger $q$. The reason is that this estimator is vulnerable if there are many attacked samples concentrating in a small region. To address this issue, we propose a correction method by projecting the initial estimate to the space of Lipschitz functions. The final estimate is nearly minimax optimal for arbitrary $q$, up t",
    "link": "http://arxiv.org/abs/2305.16771",
    "context": "Title: Robust Nonparametric Regression under Poisoning Attack. (arXiv:2305.16771v1 [math.ST])\nAbstract: This paper studies robust nonparametric regression, in which an adversarial attacker can modify the values of up to $q$ samples from a training dataset of size $N$. Our initial solution is an M-estimator based on Huber loss minimization. Compared with simple kernel regression, i.e. the Nadaraya-Watson estimator, this method can significantly weaken the impact of malicious samples on the regression performance. We provide the convergence rate as well as the corresponding minimax lower bound. The result shows that, with proper bandwidth selection, $\\ell_\\infty$ error is minimax optimal. The $\\ell_2$ error is optimal if $q\\lesssim \\sqrt{N/\\ln^2 N}$, but is suboptimal with larger $q$. The reason is that this estimator is vulnerable if there are many attacked samples concentrating in a small region. To address this issue, we propose a correction method by projecting the initial estimate to the space of Lipschitz functions. The final estimate is nearly minimax optimal for arbitrary $q$, up t",
    "path": "papers/23/05/2305.16771.json",
    "total_tokens": 1061,
    "translated_title": "毒化攻击下的鲁棒非参数回归",
    "translated_abstract": "本文研究了鲁棒非参数回归，在这种回归中，对抗性攻击者可以修改来自大小为N的训练数据集中最多q个样本的值。我们的初始解决方案是基于Huber损失最小化的M-评估器。与简单的核回归（即Nadaraya-Watson估计）相比，这种方法可以显着减弱恶意样本对回归性能的影响。我们提供了收敛速率以及相应的极小化下界。结果表明，通过正确选择带宽，$\\ell_\\infty $误差是极小化最优的。如果$q\\lesssim \\sqrt{N/\\ln^2 N}$，则$\\ell_2 $误差是最优的，但是如果$q$更大，则是次优的。原因是如果有许多被攻击的样本集中在一个小区域中，这个估计量就会很容易受到攻击。为了解决这个问题，我们提出了一种校正方法，将初始估计投影到Lipschitz函数空间中。最终的估计值几乎是任意$q$的极小化最优的。",
    "tldr": "本文提出了一种针对毒化攻击的鲁棒非参数回归方法，包括基于Huber损失的M-评估器和通过将初始估计投影到Lipschitz函数空间中的校正方法。结果表明，正确选择带宽时$\\ell_\\infty $误差是极小化最优的，而$\\ell_2 $误差在$q\\lesssim \\sqrt{N/\\ln^2 N}$时最优。",
    "en_tdlr": "This paper proposes a robust nonparametric regression method against poisoning attack, including an M-estimator based on Huber loss minimization and a correction method by projecting the initial estimate to the space of Lipschitz functions. The result shows that $\\ell_\\infty $ error is minimax optimal with proper bandwidth selection and $\\ell_2 $ error is optimal when $q\\lesssim \\sqrt{N/\\ln^2 N}$."
}