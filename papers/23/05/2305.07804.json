{
    "title": "Dr. LLaMA: Improving Small Language Models in Domain-Specific QA via Generative Data Augmentation. (arXiv:2305.07804v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) have made significant strides in natural language processing but face challenges in terms of computational expense and inefficiency as they grow in size, especially in domain-specific tasks. Small Language Models (SLMs), on the other hand, often struggle in these tasks due to limited capacity and training data. In this paper, we introduce Dr. LLaMA, a method for improving SLMs through generative data augmentation using LLMs, focusing on medical question-answering tasks and the PubMedQA dataset. Our findings indicate that LLMs effectively refine and diversify existing question-answer pairs, resulting in improved performance of a much smaller model on domain-specific QA datasets after fine-tuning. This study highlights the challenges of using LLMs for domain-specific question answering and suggests potential research directions to address these limitations, ultimately aiming to create more efficient and capable models for specialized applications. We have als",
    "link": "http://arxiv.org/abs/2305.07804",
    "context": "Title: Dr. LLaMA: Improving Small Language Models in Domain-Specific QA via Generative Data Augmentation. (arXiv:2305.07804v1 [cs.CL])\nAbstract: Large Language Models (LLMs) have made significant strides in natural language processing but face challenges in terms of computational expense and inefficiency as they grow in size, especially in domain-specific tasks. Small Language Models (SLMs), on the other hand, often struggle in these tasks due to limited capacity and training data. In this paper, we introduce Dr. LLaMA, a method for improving SLMs through generative data augmentation using LLMs, focusing on medical question-answering tasks and the PubMedQA dataset. Our findings indicate that LLMs effectively refine and diversify existing question-answer pairs, resulting in improved performance of a much smaller model on domain-specific QA datasets after fine-tuning. This study highlights the challenges of using LLMs for domain-specific question answering and suggests potential research directions to address these limitations, ultimately aiming to create more efficient and capable models for specialized applications. We have als",
    "path": "papers/23/05/2305.07804.json",
    "total_tokens": 1000,
    "translated_title": "Dr. LLaMA：通过生成式数据增强改善特定领域QA中的小语言模型",
    "translated_abstract": "大型语言模型在自然语言处理方面取得了重大进展，但随着其规模的增长，也面临着计算开销和效率的挑战，特别是在特定领域的任务中。另一方面，小型语言模型由于容量和训练数据的限制，在这些任务中往往表现不佳。本文介绍了一种名为Dr. LLaMA的方法，通过使用大型语言模型进行生成式数据增强，聚焦医学问答任务和PubMedQA数据集，以改善小语言模型的性能。我们的发现表明，LLM有效地细化和扩展现有的问题-答案对，在微调后，使得小型模型在特定领域QA数据集上性能提高。本研究强调了在特定领域问答任务中使用LLM面临的挑战，并提出了潜在的研究方向，最终旨在为专业应用创建更高效和能力更强的模型。",
    "tldr": "本论文介绍了一种名为Dr. LLaMA的方法，通过使用大型语言模型进行生成式数据增强，以改善小语言模型的性能，特别是在医学问答任务中。这种方法在微调后使模型性能提高，并提出了在特定领域问答任务中使用LLM所面临的挑战和潜在的研究方向。",
    "en_tdlr": "This paper introduces a method called Dr. LLaMA, which improves the performance of small language models, especially in medical question-answering tasks, through generative data augmentation using large language models. The method effectively refines and diversifies existing question-answer pairs, resulting in better performance of a much smaller model on domain-specific QA datasets after fine-tuning. The paper also highlights the challenges and potential research directions for using LLMs in domain-specific question answering."
}