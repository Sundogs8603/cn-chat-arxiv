{
    "title": "An Adversarial Non-Autoregressive Model for Text Generation with Incomplete Information. (arXiv:2305.03977v1 [cs.CL])",
    "abstract": "Non-autoregressive models have been widely studied in the Complete Information Scenario (CIS), in which the models have complete input information to obtain corresponding output. However, their explorations in the Incomplete Information Scenario (IIS) are extremely limited. Our analyses reveal that the IIS's incomplete input information will augment the inherent limitations of existing non-autoregressive models trained under Maximum Likelihood Estimation. In this paper, we propose for the IIS an Adversarial Non-autoregressive Transformer (ANT) which has two novel features: 1) Position Aware Self-Modulation to provide more reasonable hidden representations, and 2) Dependency Feed Forward Network to strengthen its capacity in dependency modeling. We compare ANT with other mainstream models in the IIS and demonstrate that ANT can achieve comparable performance with much fewer decoding iterations. Furthermore, we show its great potential in various applications like latent interpolation an",
    "link": "http://arxiv.org/abs/2305.03977",
    "context": "Title: An Adversarial Non-Autoregressive Model for Text Generation with Incomplete Information. (arXiv:2305.03977v1 [cs.CL])\nAbstract: Non-autoregressive models have been widely studied in the Complete Information Scenario (CIS), in which the models have complete input information to obtain corresponding output. However, their explorations in the Incomplete Information Scenario (IIS) are extremely limited. Our analyses reveal that the IIS's incomplete input information will augment the inherent limitations of existing non-autoregressive models trained under Maximum Likelihood Estimation. In this paper, we propose for the IIS an Adversarial Non-autoregressive Transformer (ANT) which has two novel features: 1) Position Aware Self-Modulation to provide more reasonable hidden representations, and 2) Dependency Feed Forward Network to strengthen its capacity in dependency modeling. We compare ANT with other mainstream models in the IIS and demonstrate that ANT can achieve comparable performance with much fewer decoding iterations. Furthermore, we show its great potential in various applications like latent interpolation an",
    "path": "papers/23/05/2305.03977.json",
    "total_tokens": 932,
    "translated_title": "一种带有不完整信息的文本生成对抗非自回归模型",
    "translated_abstract": "非自回归模型在完整信息情况（CIS）下已广泛研究，其中模型具有完整的输入信息来获取相应的输出。然而，它们在不完整信息情况（IIS）下的探索极为有限。我们的分析表明，IIS中不完整的输入信息将增加在最大似然估计下训练的现有非自回归模型的固有限制。在本文中，我们针对IIS提出了一种对抗非自回归Transformer （ANT）模型，具有两个新特性：1）位置感知自调节，可以提供更合理的隐藏表示；2）依赖性前馈网络，可以增强其依赖性建模能力。我们将ANT与IIS中的其他主流模型进行比较，并证明ANT可以实现可比较性能，同时也可以比其他模型更快地进行解码。此外，我们展示了ANT在潜在插值等各种应用方面的巨大潜力。",
    "tldr": "提出了一种新的对抗非自回归Transformer模型用于对不完整信息的文本生成，其具有位置感知自调节和依赖接口网络，能够在与其他主流模型相比更快的解码时间内获得可比较性能，具有在潜在插值等应用中的巨大潜力。",
    "en_tdlr": "An Adversarial Non-autoregressive Transformer (ANT) is proposed for text generation with incomplete information, featuring Position Aware Self-Modulation and Dependency Feed Forward Network to improve its performance in dependency modeling. Comparison with mainstream models shows that ANT can achieve comparable performance with less decoding iterations, and has great potential in various applications like latent interpolation."
}