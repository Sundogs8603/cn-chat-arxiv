{
    "title": "Active Learning for Natural Language Generation. (arXiv:2305.15040v2 [cs.CL] UPDATED)",
    "abstract": "The field of Natural Language Generation (NLG) suffers from a severe shortage of labeled data due to the extremely expensive and time-consuming process involved in manual annotation. A natural approach for coping with this problem is active learning (AL), a well-known machine learning technique for improving annotation efficiency by selectively choosing the most informative examples to label. However, while AL has been well-researched in the context of text classification, its application to NLG remains largely unexplored. In this paper, we present a first systematic study of active learning for NLG, considering a diverse set of tasks and multiple leading selection strategies, and harnessing a strong instruction-tuned model. Our results indicate that the performance of existing AL strategies is inconsistent, surpassing the baseline of random example selection in some cases but not in others. We highlight some notable differences between the classification and generation scenarios, and ",
    "link": "http://arxiv.org/abs/2305.15040",
    "context": "Title: Active Learning for Natural Language Generation. (arXiv:2305.15040v2 [cs.CL] UPDATED)\nAbstract: The field of Natural Language Generation (NLG) suffers from a severe shortage of labeled data due to the extremely expensive and time-consuming process involved in manual annotation. A natural approach for coping with this problem is active learning (AL), a well-known machine learning technique for improving annotation efficiency by selectively choosing the most informative examples to label. However, while AL has been well-researched in the context of text classification, its application to NLG remains largely unexplored. In this paper, we present a first systematic study of active learning for NLG, considering a diverse set of tasks and multiple leading selection strategies, and harnessing a strong instruction-tuned model. Our results indicate that the performance of existing AL strategies is inconsistent, surpassing the baseline of random example selection in some cases but not in others. We highlight some notable differences between the classification and generation scenarios, and ",
    "path": "papers/23/05/2305.15040.json",
    "total_tokens": 845,
    "translated_title": "自然语言生成的主动学习",
    "translated_abstract": "自然语言生成（NLG）领域由于手动标注涉及的过程极其昂贵且耗时，导致标记数据严重匮乏。应对这一问题的一种自然方法是主动学习（AL），一种通过选择最具信息量的示例进行标记来提高注释效率的机器学习技术。然而，虽然在文本分类的背景下，AL已经得到了广泛研究，但其在NLG中的应用还没有被充分探索。本文首次对NLG进行了主动学习的系统研究，考虑了多种任务和多种主要选择策略，并利用一个强大的指导调优模型。我们的结果表明，现有的AL策略的性能不一致，在某些情况下超过了随机示例选择的基准线，但在其他情况下没有达到该基准线。我们强调了分类和生成场景之间的一些显著差异。",
    "tldr": "本文首次对自然语言生成进行了主动学习的系统研究，发现现有的主动学习策略在不同情况下性能不一致，强调了分类和生成场景之间的差异。"
}