{
    "title": "Certification Labels for Trustworthy AI: Insights From an Empirical Mixed-Method Study. (arXiv:2305.18307v1 [cs.CY])",
    "abstract": "Auditing plays a pivotal role in the development of trustworthy AI. However, current research primarily focuses on creating auditable AI documentation, which is intended for regulators and experts rather than end-users affected by AI decisions. How to communicate to members of the public that an AI has been audited and considered trustworthy remains an open challenge. This study empirically investigated certification labels as a promising solution. Through interviews (N = 12) and a census-representative survey (N = 302), we investigated end-users' attitudes toward certification labels and their effectiveness in communicating trustworthiness in low- and high-stakes AI scenarios. Based on the survey results, we demonstrate that labels can significantly increase end-users' trust and willingness to use AI in both lowand high-stakes scenarios. However, end-users' preferences for certification labels and their effect on trust and willingness to use AI were more pronounced in high-stake sce",
    "link": "http://arxiv.org/abs/2305.18307",
    "context": "Title: Certification Labels for Trustworthy AI: Insights From an Empirical Mixed-Method Study. (arXiv:2305.18307v1 [cs.CY])\nAbstract: Auditing plays a pivotal role in the development of trustworthy AI. However, current research primarily focuses on creating auditable AI documentation, which is intended for regulators and experts rather than end-users affected by AI decisions. How to communicate to members of the public that an AI has been audited and considered trustworthy remains an open challenge. This study empirically investigated certification labels as a promising solution. Through interviews (N = 12) and a census-representative survey (N = 302), we investigated end-users' attitudes toward certification labels and their effectiveness in communicating trustworthiness in low- and high-stakes AI scenarios. Based on the survey results, we demonstrate that labels can significantly increase end-users' trust and willingness to use AI in both lowand high-stakes scenarios. However, end-users' preferences for certification labels and their effect on trust and willingness to use AI were more pronounced in high-stake sce",
    "path": "papers/23/05/2305.18307.json",
    "total_tokens": 924,
    "translated_title": "可信AI认证标签：基于经验杂交方法研究的深刻洞见",
    "translated_abstract": "审计在可信AI的发展中发挥着关键作用。然而，当前研究主要集中在创建可审计的AI文件方面，这些文件是针对监管机构和专家而不是受AI决策影响的终端用户而设计的。如何向公众传达一个经过审计并被视为可信的AI的信息仍然是一个开放性问题。本研究实证调查了认证标签作为一种有前途的解决方案。通过访谈（N = 12）和普查代表性调查（N = 302），我们调查了终端用户对认证标签的态度以及在低风险和高风险AI场景中有效传达可信性的能力。根据调查结果，我们证明标签可以显著增加终端用户在低风险和高风险场景下使用AI的信任和使用意愿。然而，在高风险场景中，终端用户对认证标签的偏好及其对信任和使用AI的影响更为明显。",
    "tldr": "本文研究了认证标签在传达可信AI上的作用。调查结果表明，认证标签可以显著增加终端用户在低风险和高风险场景下使用AI的信任和使用意愿，尤其是在高风险场景中，其效果更为明显。",
    "en_tdlr": "This paper examines the role of certification labels in communicating trustworthy AI to end-users. Results show that certification labels significantly increase trust and willingness to use AI, especially in high-stakes scenarios."
}