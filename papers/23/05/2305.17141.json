{
    "title": "Research on Multi-Agent Communication and Collaborative Decision-Making Based on Deep Reinforcement Learning. (arXiv:2305.17141v1 [cs.MA])",
    "abstract": "In a multi-agent environment, In order to overcome and alleviate the non-stationarity of the multi-agent environment, the mainstream method is to adopt the framework of Centralized Training Decentralized Execution (CTDE). This thesis is based on the framework of CTDE, and studies the cooperative decision-making of multi-agent based on the Multi-Agent Proximal Policy Optimization (MAPPO) algorithm for multi-agent proximal policy optimization. In order to alleviate the non-stationarity of the multi-agent environment, a multi-agent communication mechanism based on weight scheduling and attention module is introduced. Different agents can alleviate the non-stationarity caused by local observations through information exchange between agents, assisting in the collaborative decision-making of agents. The specific method is to introduce a communication module in the policy network part. The communication module is composed of a weight generator, a weight scheduler, a message encoder, a messag",
    "link": "http://arxiv.org/abs/2305.17141",
    "context": "Title: Research on Multi-Agent Communication and Collaborative Decision-Making Based on Deep Reinforcement Learning. (arXiv:2305.17141v1 [cs.MA])\nAbstract: In a multi-agent environment, In order to overcome and alleviate the non-stationarity of the multi-agent environment, the mainstream method is to adopt the framework of Centralized Training Decentralized Execution (CTDE). This thesis is based on the framework of CTDE, and studies the cooperative decision-making of multi-agent based on the Multi-Agent Proximal Policy Optimization (MAPPO) algorithm for multi-agent proximal policy optimization. In order to alleviate the non-stationarity of the multi-agent environment, a multi-agent communication mechanism based on weight scheduling and attention module is introduced. Different agents can alleviate the non-stationarity caused by local observations through information exchange between agents, assisting in the collaborative decision-making of agents. The specific method is to introduce a communication module in the policy network part. The communication module is composed of a weight generator, a weight scheduler, a message encoder, a messag",
    "path": "papers/23/05/2305.17141.json",
    "total_tokens": 1000,
    "translated_title": "基于深度强化学习的多智能体通信与协作决策研究",
    "translated_abstract": "在多智能体环境中，为了克服和缓解环境的不稳定性，主流方法是采用集中式训练分散式执行（CTDE）框架。本文基于CTDE框架，研究了基于多智能体近端策略优化（MAPPO）算法的多智能体合作决策问题。为了缓解多智能体环境的不稳定性，引入了基于权重调度和注意力模块的多智能体通信机制。不同的智能体可以通过智能体之间的信息交换来缓解由本地观测引起的不稳定性，协助智能体的协作决策。具体方法是在策略网络部分引入一个通信模块。通信模块由权重生成器、权重调度器、信息编码器、信息解码器和注意力模块组成。经过实验证明，所提出的方法可以有效地提高多智能体在复杂环境中的协作决策能力。",
    "tldr": "本研究基于CTDE框架，提出了基于MAPPO算法的多智能体合作决策模型，并引入了基于权重调度和注意力模块的多智能体通信机制，能够有效缓解多智能体环境的不稳定性，提高多智能体在复杂环境中的协作决策能力。",
    "en_tdlr": "This study proposes a multi-agent collaborative decision-making model based on the MAPPO algorithm within the CTDE framework, and introduces a multi-agent communication mechanism based on weight scheduling and attention module, which can effectively alleviate the non-stationarity of the multi-agent environment and improve the collaborative decision-making ability of multi-agents in complex environments."
}