{
    "title": "WikiSQE: A Large-Scale Dataset for Sentence Quality Estimation in Wikipedia. (arXiv:2305.05928v1 [cs.CL])",
    "abstract": "Wikipedia can be edited by anyone and thus contains various quality sentences. Therefore, Wikipedia includes some poor-quality edits, which are often marked up by other editors. While editors' reviews enhance the credibility of Wikipedia, it is hard to check all edited text. Assisting in this process is very important, but a large and comprehensive dataset for studying it does not currently exist. Here, we propose WikiSQE, the first large-scale dataset for sentence quality estimation in Wikipedia. Each sentence is extracted from the entire revision history of Wikipedia, and the target quality labels were carefully investigated and selected. WikiSQE has about 3.4 M sentences with 153 quality labels. In the experiment with automatic classification using competitive machine learning models, sentences that had problems with citation, syntax/semantics, or propositions were found to be more difficult to detect. In addition, we conducted automated essay scoring experiments to evaluate the gen",
    "link": "http://arxiv.org/abs/2305.05928",
    "context": "Title: WikiSQE: A Large-Scale Dataset for Sentence Quality Estimation in Wikipedia. (arXiv:2305.05928v1 [cs.CL])\nAbstract: Wikipedia can be edited by anyone and thus contains various quality sentences. Therefore, Wikipedia includes some poor-quality edits, which are often marked up by other editors. While editors' reviews enhance the credibility of Wikipedia, it is hard to check all edited text. Assisting in this process is very important, but a large and comprehensive dataset for studying it does not currently exist. Here, we propose WikiSQE, the first large-scale dataset for sentence quality estimation in Wikipedia. Each sentence is extracted from the entire revision history of Wikipedia, and the target quality labels were carefully investigated and selected. WikiSQE has about 3.4 M sentences with 153 quality labels. In the experiment with automatic classification using competitive machine learning models, sentences that had problems with citation, syntax/semantics, or propositions were found to be more difficult to detect. In addition, we conducted automated essay scoring experiments to evaluate the gen",
    "path": "papers/23/05/2305.05928.json",
    "total_tokens": 946,
    "translated_title": "WikiSQE：维基百科中句子质量估计的大规模数据集",
    "translated_abstract": "维基百科可以被任何人编辑，因此包含各种质量的句子。因此，维基百科包含一些质量较差的编辑，这些编辑通常会被其他编辑标记。虽然编辑的评论增强了维基百科的可信度，但很难检查所有编辑的文本。协助这个过程非常重要，但目前还没有一个大而全面的数据集来研究它。在这里，我们提出了 WikiSQE，这是第一个用于维基百科中句子质量估计的大规模数据集。每个句子都是从维基百科的整个修订历史中提取的，并且目标质量标签经过了仔细的调查和选择。WikiSQE具有约3.4 million个句子和153个质量标签。在使用竞争机器学习模型进行自动分类的实验中，发现具有引文，语法/语义或命题问题的句子更难以检测。此外，我们进行了自动作文评分实验，以评估生成摘要的有效性。",
    "tldr": "WikiSQE是第一个用于维基百科中句子质量估计的大规模数据集，其中包含约3.4M个句子和153个质量标签。在这个数据集上进行的实验表明，具有引文、语法/语义或命题问题的句子更难以检测。",
    "en_tdlr": "WikiSQE is the first large-scale dataset for sentence quality estimation in Wikipedia, with about 3.4M sentences and 153 quality labels. Experiments on this dataset indicate that sentences with problems in citation, syntax/semantics, or propositions are more difficult to detect."
}