{
    "title": "Enhancing the Ranking Context of Dense Retrieval Methods through Reciprocal Nearest Neighbors. (arXiv:2305.15720v1 [cs.IR])",
    "abstract": "Sparse annotation poses persistent challenges to training dense retrieval models, such as the problem of false negatives, i.e. unlabeled relevant documents that are spuriously used as negatives in contrastive learning, distorting the training signal. To alleviate this problem, we introduce evidence-based label smoothing, a computationally efficient method that prevents penalizing the model for assigning high relevance to false negatives. To compute the target relevance distribution over candidate documents within the ranking context of a given query, candidates most similar to the ground truth are assigned a non-zero relevance probability based on the degree of their similarity to the ground-truth document(s). As a relevance estimate we leverage an improved similarity metric based on reciprocal nearest neighbors, which can also be used independently to rerank candidates in post-processing. Through extensive experiments on two large-scale ad hoc text retrieval datasets we demonstrate th",
    "link": "http://arxiv.org/abs/2305.15720",
    "context": "Title: Enhancing the Ranking Context of Dense Retrieval Methods through Reciprocal Nearest Neighbors. (arXiv:2305.15720v1 [cs.IR])\nAbstract: Sparse annotation poses persistent challenges to training dense retrieval models, such as the problem of false negatives, i.e. unlabeled relevant documents that are spuriously used as negatives in contrastive learning, distorting the training signal. To alleviate this problem, we introduce evidence-based label smoothing, a computationally efficient method that prevents penalizing the model for assigning high relevance to false negatives. To compute the target relevance distribution over candidate documents within the ranking context of a given query, candidates most similar to the ground truth are assigned a non-zero relevance probability based on the degree of their similarity to the ground-truth document(s). As a relevance estimate we leverage an improved similarity metric based on reciprocal nearest neighbors, which can also be used independently to rerank candidates in post-processing. Through extensive experiments on two large-scale ad hoc text retrieval datasets we demonstrate th",
    "path": "papers/23/05/2305.15720.json",
    "total_tokens": 900,
    "translated_title": "通过逆向最近邻提升稠密检索方法的排名上下文质量",
    "translated_abstract": "稀疏标注给稠密检索模型训练带来了持久的挑战，例如虚假负样本问题，即未标记的相关文档被错误地用作负样本，扭曲了训练信号。为了缓解这个问题，我们介绍了一种称为基于证据的标签平滑的计算方法，这是一种计算效率高的方法，可以避免惩罚模型将高相关性赋予虚假负样本。为了在给定查询的排名上下文中计算候选文档的目标相关性分布，与基本事实最相似的候选者被赋予非零相关概率，该概率基于它们与基本事实文档的相似度程度。作为相关性估计，我们利用了一种基于逆向最近邻的改进相似度度量，该度量还可单独用于后处理中重新排名候选者。通过在两个大规模的自适应文本检索数据集上进行广泛的实验，我们展示了本方法的优越性。",
    "tldr": "为了解决稀疏标注在稠密检索模型训练中的问题，我们提出了基于证据的标签平滑方法，并且引入了逆向最近邻相似度度量方法来提高相关性估计的准确性。",
    "en_tdlr": "To address the challenges of sparse annotation in training dense retrieval models, the paper proposes evidence-based label smoothing and introduces a reciprocal nearest neighbor similarity metric to improve relevance estimation."
}