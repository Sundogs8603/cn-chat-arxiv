{
    "title": "ZipIt! Merging Models from Different Tasks without Training. (arXiv:2305.03053v1 [cs.CV])",
    "abstract": "Typical deep visual recognition models are capable of performing the one task they were trained on. In this paper, we tackle the extremely difficult problem of combining completely distinct models with different initializations, each solving a separate task, into one multi-task model without any additional training. Prior work in model merging permutes one model to the space of the other then adds them together. While this works for models trained on the same task, we find that this fails to account for the differences in models trained on disjoint tasks. Thus, we introduce \"ZipIt!\", a general method for merging two arbitrary models of the same architecture that incorporates two simple strategies. First, in order to account for features that aren't shared between models, we expand the model merging problem to additionally allow for merging features within each model by defining a general \"zip\" operation. Second, we add support for partially zipping the models up until a specified layer",
    "link": "http://arxiv.org/abs/2305.03053",
    "context": "Title: ZipIt! Merging Models from Different Tasks without Training. (arXiv:2305.03053v1 [cs.CV])\nAbstract: Typical deep visual recognition models are capable of performing the one task they were trained on. In this paper, we tackle the extremely difficult problem of combining completely distinct models with different initializations, each solving a separate task, into one multi-task model without any additional training. Prior work in model merging permutes one model to the space of the other then adds them together. While this works for models trained on the same task, we find that this fails to account for the differences in models trained on disjoint tasks. Thus, we introduce \"ZipIt!\", a general method for merging two arbitrary models of the same architecture that incorporates two simple strategies. First, in order to account for features that aren't shared between models, we expand the model merging problem to additionally allow for merging features within each model by defining a general \"zip\" operation. Second, we add support for partially zipping the models up until a specified layer",
    "path": "papers/23/05/2305.03053.json",
    "total_tokens": 844,
    "translated_title": "ZipIt！无需训练即可合并不同任务的模型",
    "translated_abstract": "典型的深度视觉识别模型能够执行它们经过训练的单一任务。本文解决将完全不同的、每个解决一个独立任务的模型合并成一个多任务模型的极其困难的问题，而且不需要任何额外的训练。以前的模型合并工作将一个模型置换到另一个模型的空间中，再将它们相加。虽然这对于在同一个任务上经过训练的模型起作用，但我们发现，这未能考虑到在不同任务上经过训练的模型之间的差异。因此，我们引入了“ZipIt！”，这是一种通用的方法，用于合并相同结构的两个任意模型，其中包括两种简单的策略。首先，为了考虑到在模型之间没有共享的特征，我们将模型合并问题扩展到还允许合并每个模型中的特征，定义一个通用的“zip”操作。其次，我们添加支持部分压缩模型的功能，直到特定层。",
    "tldr": "本文介绍了一种无需额外训练即可合并不同任务上训练的模型的方法“ZipIt！”。",
    "en_tdlr": "This paper introduces a method called \"ZipIt!\", which can merge models trained on different tasks without additional training."
}