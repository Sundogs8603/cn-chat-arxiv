{
    "title": "Accessible Instruction-Following Agent. (arXiv:2305.06358v1 [cs.AI])",
    "abstract": "Humans can collaborate and complete tasks based on visual signals and instruction from the environment. Training such a robot is difficult especially due to the understanding of the instruction and the complicated environment. Previous instruction-following agents are biased to English-centric corpus, making it unrealizable to be applied to users that use multiple languages or even low-resource languages. Nevertheless, the instruction-following agents are pre-trained in a mode that assumes the user can observe the environment, which limits its accessibility. In this work, we're trying to generalize the success of instruction-following agents to non-English languages with little corpus resources, and improve its intractability and accessibility. We introduce UVLN (Universal Vision-Language Navigation), a novel machine-translation instructional augmented framework for cross-lingual vision-language navigation, with a novel composition of state-of-the-art large language model (GPT3) with t",
    "link": "http://arxiv.org/abs/2305.06358",
    "context": "Title: Accessible Instruction-Following Agent. (arXiv:2305.06358v1 [cs.AI])\nAbstract: Humans can collaborate and complete tasks based on visual signals and instruction from the environment. Training such a robot is difficult especially due to the understanding of the instruction and the complicated environment. Previous instruction-following agents are biased to English-centric corpus, making it unrealizable to be applied to users that use multiple languages or even low-resource languages. Nevertheless, the instruction-following agents are pre-trained in a mode that assumes the user can observe the environment, which limits its accessibility. In this work, we're trying to generalize the success of instruction-following agents to non-English languages with little corpus resources, and improve its intractability and accessibility. We introduce UVLN (Universal Vision-Language Navigation), a novel machine-translation instructional augmented framework for cross-lingual vision-language navigation, with a novel composition of state-of-the-art large language model (GPT3) with t",
    "path": "papers/23/05/2305.06358.json",
    "total_tokens": 931,
    "translated_title": "“可访问的指令跟随机器人”",
    "translated_abstract": "人类可以根据环境中的视觉信号和指令合作并完成任务。训练这样的机器人很难，特别是由于对指令的理解和复杂的环境。以英语为中心的语料库使得先前的指令跟随代理程序偏向英语，使其无法应用于使用多种语言甚至是低资源语言的用户。然而，指令跟随代理程序是在假设用户可以观察到环境的模式下进行预训练的，这限制了它的可访问性。在这项工作中，我们试图将指令跟随代理程序的成功推广到非英语语言，并改善其不可操作性和可访问性。我们引入了UVLN (通用视觉-语言导航), 该框架是一种新颖的机器翻译增强框架，用于跨语言视觉-语言导航，其结合了最新的大型语言模型 (如 GPT3) 与图形嵌入技术。",
    "tldr": "该研究介绍了UVLN，一种新颖的机器翻译增强框架，用于跨语言视觉-语言导航，其结合了最新的语言模型与图形嵌入技术，旨在将指令跟随代理程序的成功推广到非英语语言，提高其易操作性和可访问性。"
}