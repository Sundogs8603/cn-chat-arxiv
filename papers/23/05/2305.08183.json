{
    "title": "Manipulating Visually-aware Federated Recommender Systems and Its Countermeasures. (arXiv:2305.08183v1 [cs.IR])",
    "abstract": "Federated recommender systems (FedRecs) have been widely explored recently due to their ability to protect user data privacy. In FedRecs, a central server collaboratively learns recommendation models by sharing model public parameters with clients, thereby offering a privacy-preserving solution. Unfortunately, the exposure of model parameters leaves a backdoor for adversaries to manipulate FedRecs. Existing works about FedRec security already reveal that items can easily be promoted by malicious users via model poisoning attacks, but all of them mainly focus on FedRecs with only collaborative information (i.e., user-item interactions). We argue that these attacks are effective because of the data sparsity of collaborative signals. In practice, auxiliary information, such as products' visual descriptions, is used to alleviate collaborative filtering data's sparsity. Therefore, when incorporating visual information in FedRecs, all existing model poisoning attacks' effectiveness becomes q",
    "link": "http://arxiv.org/abs/2305.08183",
    "context": "Title: Manipulating Visually-aware Federated Recommender Systems and Its Countermeasures. (arXiv:2305.08183v1 [cs.IR])\nAbstract: Federated recommender systems (FedRecs) have been widely explored recently due to their ability to protect user data privacy. In FedRecs, a central server collaboratively learns recommendation models by sharing model public parameters with clients, thereby offering a privacy-preserving solution. Unfortunately, the exposure of model parameters leaves a backdoor for adversaries to manipulate FedRecs. Existing works about FedRec security already reveal that items can easily be promoted by malicious users via model poisoning attacks, but all of them mainly focus on FedRecs with only collaborative information (i.e., user-item interactions). We argue that these attacks are effective because of the data sparsity of collaborative signals. In practice, auxiliary information, such as products' visual descriptions, is used to alleviate collaborative filtering data's sparsity. Therefore, when incorporating visual information in FedRecs, all existing model poisoning attacks' effectiveness becomes q",
    "path": "papers/23/05/2305.08183.json",
    "total_tokens": 852,
    "translated_title": "可视化信息对联邦推荐系统的影响及其对策",
    "translated_abstract": "近年来，联邦推荐系统（FedRec）因其保护用户数据隐私的能力而受到广泛关注。在FedRec中，中央服务器通过与客户端共享模型公共参数来协同学习推荐模型，从而提供一种保护隐私的解决方案。然而，模型参数的公开性为攻击者操纵FedRec留下了后门。现有的与FedRec安全相关的研究已经表明，通过模型污染攻击，恶意用户可以轻易地推广项目，但是它们主要集中于只具有协作信息（即用户-项目交互）的FedRec。我们认为这些攻击之所以有效，是因为协作信号的数据稀疏性。在实践中，辅助信息（如产品的视觉描述）用于缓解协作过滤数据的稀疏性。因此，当在FedRec中加入视觉信息时，所有现有的模型污染攻击的有效性都将降低。",
    "tldr": "本文研究了可视化信息对联邦推荐系统的影响，发现当加入视觉信息时，现有的恶意推广攻击将变得无效。",
    "en_tdlr": "This paper investigates the impact of visual information on federated recommender systems and finds that existing malicious promotion attacks become ineffective when incorporating visual information."
}