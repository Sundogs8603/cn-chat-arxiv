{
    "title": "LayoutGPT: Compositional Visual Planning and Generation with Large Language Models. (arXiv:2305.15393v2 [cs.CV] UPDATED)",
    "abstract": "Attaining a high degree of user controllability in visual generation often requires intricate, fine-grained inputs like layouts. However, such inputs impose a substantial burden on users when compared to simple text inputs. To address the issue, we study how Large Language Models (LLMs) can serve as visual planners by generating layouts from text conditions, and thus collaborate with visual generative models. We propose LayoutGPT, a method to compose in-context visual demonstrations in style sheet language to enhance the visual planning skills of LLMs. LayoutGPT can generate plausible layouts in multiple domains, ranging from 2D images to 3D indoor scenes. LayoutGPT also shows superior performance in converting challenging language concepts like numerical and spatial relations to layout arrangements for faithful text-to-image generation. When combined with a downstream image generation model, LayoutGPT outperforms text-to-image models/systems by 20-40% and achieves comparable performan",
    "link": "http://arxiv.org/abs/2305.15393",
    "context": "Title: LayoutGPT: Compositional Visual Planning and Generation with Large Language Models. (arXiv:2305.15393v2 [cs.CV] UPDATED)\nAbstract: Attaining a high degree of user controllability in visual generation often requires intricate, fine-grained inputs like layouts. However, such inputs impose a substantial burden on users when compared to simple text inputs. To address the issue, we study how Large Language Models (LLMs) can serve as visual planners by generating layouts from text conditions, and thus collaborate with visual generative models. We propose LayoutGPT, a method to compose in-context visual demonstrations in style sheet language to enhance the visual planning skills of LLMs. LayoutGPT can generate plausible layouts in multiple domains, ranging from 2D images to 3D indoor scenes. LayoutGPT also shows superior performance in converting challenging language concepts like numerical and spatial relations to layout arrangements for faithful text-to-image generation. When combined with a downstream image generation model, LayoutGPT outperforms text-to-image models/systems by 20-40% and achieves comparable performan",
    "path": "papers/23/05/2305.15393.json",
    "total_tokens": 915,
    "translated_title": "LayoutGPT: 使用大型语言模型进行组合式视觉规划和生成",
    "translated_abstract": "在视觉生成中，实现高度的用户可控性通常需要精细的输入，如布局。然而，与简单的文本输入相比，这样的输入给用户带来了很大的负担。为了解决这个问题，我们研究了大型语言模型（LLMs）如何通过从文本条件中生成布局来充当视觉规划者，并与视觉生成模型进行协作。我们提出了LayoutGPT，一种使用样式表语言来组成上下文中的视觉示例，以增强LLMs的视觉规划能力的方法。LayoutGPT可以在多个领域生成合理的布局，从2D图像到3D室内场景。LayoutGPT还在将具有挑战性的语言概念（如数字和空间关系）转化为布局安排以进行忠实的文本到图像生成方面表现出优越的性能。当与下游图像生成模型结合时，LayoutGPT的性能优于文本到图像模型/系统20-40%，并达到可比较的性能水平。",
    "tldr": "LayoutGPT是一种使用大型语言模型的视觉规划和生成方法，通过从文本条件生成布局来提高用户对生成结果的控制能力。LayoutGPT在多个领域生成合理的布局，并优于其他文本到图像模型/系统的性能。",
    "en_tdlr": "LayoutGPT is a visual planning and generation method that utilizes large language models to enhance user controllability by generating layouts from text conditions. It outperforms other text-to-image models/systems and generates plausible layouts in multiple domains."
}