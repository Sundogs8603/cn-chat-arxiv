{
    "title": "Trustworthy Federated Learning: A Survey. (arXiv:2305.11537v1 [cs.AI])",
    "abstract": "Federated Learning (FL) has emerged as a significant advancement in the field of Artificial Intelligence (AI), enabling collaborative model training across distributed devices while maintaining data privacy. As the importance of FL increases, addressing trustworthiness issues in its various aspects becomes crucial. In this survey, we provide an extensive overview of the current state of Trustworthy FL, exploring existing solutions and well-defined pillars relevant to Trustworthy . Despite the growth in literature on trustworthy centralized Machine Learning (ML)/Deep Learning (DL), further efforts are necessary to identify trustworthiness pillars and evaluation metrics specific to FL models, as well as to develop solutions for computing trustworthiness levels. We propose a taxonomy that encompasses three main pillars: Interpretability, Fairness, and Security & Privacy. Each pillar represents a dimension of trust, further broken down into different notions. Our survey covers trustworthin",
    "link": "http://arxiv.org/abs/2305.11537",
    "context": "Title: Trustworthy Federated Learning: A Survey. (arXiv:2305.11537v1 [cs.AI])\nAbstract: Federated Learning (FL) has emerged as a significant advancement in the field of Artificial Intelligence (AI), enabling collaborative model training across distributed devices while maintaining data privacy. As the importance of FL increases, addressing trustworthiness issues in its various aspects becomes crucial. In this survey, we provide an extensive overview of the current state of Trustworthy FL, exploring existing solutions and well-defined pillars relevant to Trustworthy . Despite the growth in literature on trustworthy centralized Machine Learning (ML)/Deep Learning (DL), further efforts are necessary to identify trustworthiness pillars and evaluation metrics specific to FL models, as well as to develop solutions for computing trustworthiness levels. We propose a taxonomy that encompasses three main pillars: Interpretability, Fairness, and Security & Privacy. Each pillar represents a dimension of trust, further broken down into different notions. Our survey covers trustworthin",
    "path": "papers/23/05/2305.11537.json",
    "total_tokens": 943,
    "translated_title": "可信联邦学习：综述",
    "translated_abstract": "联邦学习已经成为人工智能领域的一个重要进展，可以在保持数据隐私的同时，实现分布式设备上的协作模型训练。随着联邦学习的重要性不断增加，解决其各个方面的可信问题变得至关重要。在本综述中，我们提供了有关可信联邦学习的当前状态的广泛概述，探讨了与可信性相关的现有解决方案和明确定义的支柱。尽管在有关可信集中式机器学习（ML）/深度学习（DL）的文献增长迅速，但仍需要进一步努力，以确定针对FL模型的可信支柱和评估指标，以及开发计算可信度水平的解决方案。我们提出了一个涵盖三个主要支柱的分类法：可解释性，公平性和安全与隐私。每个支柱代表一维信任，进一步细分为不同的概念。我们的综述涵盖了与这三个支柱相关的FL的可信问题，并强调了挑战和开放的研究方向。",
    "tldr": "本文综述了联邦学习的可信性问题，提出了三个支柱：可解释性，公平性和安全与隐私，并探讨了相关的挑战和研究方向。",
    "en_tdlr": "This survey provides a comprehensive overview of the current state of trustworthy federated learning, proposing a taxonomy that encompasses interpretability, fairness, and security & privacy as the three main pillars of trust. The article explores existing solutions and challenges related to the trustworthiness of federated learning and identifies open research directions."
}