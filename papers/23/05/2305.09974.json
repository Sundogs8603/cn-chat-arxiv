{
    "title": "River of No Return: Graph Percolation Embeddings for Efficient Knowledge Graph Reasoning. (arXiv:2305.09974v1 [cs.AI])",
    "abstract": "We study Graph Neural Networks (GNNs)-based embedding techniques for knowledge graph (KG) reasoning. For the first time, we link the path redundancy issue in the state-of-the-art KG reasoning models based on path encoding and message passing to the transformation error in model training, which brings us new theoretical insights into KG reasoning, as well as high efficacy in practice. On the theoretical side, we analyze the entropy of transformation error in KG paths and point out query-specific redundant paths causing entropy increases. These findings guide us to maintain the shortest paths and remove redundant paths for minimized-entropy message passing. To achieve this goal, on the practical side, we propose an efficient Graph Percolation Process motivated by the percolation model in Fluid Mechanics, and design a lightweight GNN-based KG reasoning framework called Graph Percolation Embeddings (GraPE). GraPE outperforms previous state-of-the-art methods in both transductive and induct",
    "link": "http://arxiv.org/abs/2305.09974",
    "context": "Title: River of No Return: Graph Percolation Embeddings for Efficient Knowledge Graph Reasoning. (arXiv:2305.09974v1 [cs.AI])\nAbstract: We study Graph Neural Networks (GNNs)-based embedding techniques for knowledge graph (KG) reasoning. For the first time, we link the path redundancy issue in the state-of-the-art KG reasoning models based on path encoding and message passing to the transformation error in model training, which brings us new theoretical insights into KG reasoning, as well as high efficacy in practice. On the theoretical side, we analyze the entropy of transformation error in KG paths and point out query-specific redundant paths causing entropy increases. These findings guide us to maintain the shortest paths and remove redundant paths for minimized-entropy message passing. To achieve this goal, on the practical side, we propose an efficient Graph Percolation Process motivated by the percolation model in Fluid Mechanics, and design a lightweight GNN-based KG reasoning framework called Graph Percolation Embeddings (GraPE). GraPE outperforms previous state-of-the-art methods in both transductive and induct",
    "path": "papers/23/05/2305.09974.json",
    "total_tokens": 960,
    "translated_title": "无归河流：基于图渗透嵌入的高效知识图谱推理",
    "translated_abstract": "本文研究了基于图神经网络（GNN）的知识图谱（KG）推理嵌入技术。我们首次将路径编码和消息传递的最先进KG推理模型中的路径冗余问题与模型训练中的变换误差联系起来，这为我们带来了对KG推理的新的理论洞见，以及在实践中具有高效性。在理论方面，我们分析了KG路径变换误差的熵，并指出了查询特定冗余路径会引起熵的增加。这些发现指导我们维护最短路径，并消除冗余路径以最小化熵的消息传递。为了实现这一目标，在实践方面，我们提出了一种高效的图渗透过程，该过程受流体力学中渗透模型的启发，并设计了一个轻量级的基于GNN的KG推理框架，称为图渗透嵌入（GraPE）。GraPE在基准数据集WN18RR和FB15K237上的归纳式和传递式KG推理任务中均优于之前的最先进方法。",
    "tldr": "本文提出了一种基于图渗透的嵌入技术，通过维护最短路径和消除冗余路径来最小化熵的消息传递，从而显著提高了知识图谱推理的效率。",
    "en_tdlr": "The paper proposes a Graph Percolation Embedding (GraPE) approach for knowledge graph (KG) reasoning by maintaining shortest paths and removing redundant paths to minimize entropy in message passing, which outperforms previous state-of-the-art methods on benchmark datasets."
}