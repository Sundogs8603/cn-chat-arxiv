{
    "title": "Evaluating statistical language models as pragmatic reasoners. (arXiv:2305.01020v1 [cs.CL])",
    "abstract": "The relationship between communicated language and intended meaning is often probabilistic and sensitive to context. Numerous strategies attempt to estimate such a mapping, often leveraging recursive Bayesian models of communication. In parallel, large language models (LLMs) have been increasingly applied to semantic parsing applications, tasked with inferring logical representations from natural language. While existing LLM explorations have been largely restricted to literal language use, in this work, we evaluate the capacity of LLMs to infer the meanings of pragmatic utterances. Specifically, we explore the case of threshold estimation on the gradable adjective ``strong'', contextually conditioned on a strength prior, then extended to composition with qualification, negation, polarity inversion, and class comparison. We find that LLMs can derive context-grounded, human-like distributions over the interpretations of several complex pragmatic utterances, yet struggle composing with n",
    "link": "http://arxiv.org/abs/2305.01020",
    "context": "Title: Evaluating statistical language models as pragmatic reasoners. (arXiv:2305.01020v1 [cs.CL])\nAbstract: The relationship between communicated language and intended meaning is often probabilistic and sensitive to context. Numerous strategies attempt to estimate such a mapping, often leveraging recursive Bayesian models of communication. In parallel, large language models (LLMs) have been increasingly applied to semantic parsing applications, tasked with inferring logical representations from natural language. While existing LLM explorations have been largely restricted to literal language use, in this work, we evaluate the capacity of LLMs to infer the meanings of pragmatic utterances. Specifically, we explore the case of threshold estimation on the gradable adjective ``strong'', contextually conditioned on a strength prior, then extended to composition with qualification, negation, polarity inversion, and class comparison. We find that LLMs can derive context-grounded, human-like distributions over the interpretations of several complex pragmatic utterances, yet struggle composing with n",
    "path": "papers/23/05/2305.01020.json",
    "total_tokens": 910,
    "translated_title": "将统计语言模型作为语用推理的评估器",
    "translated_abstract": "沟通语言和预期意义之间的关系通常是概率性的，而且对语境非常敏感。许多策略试图估计这种映射，通常利用基于贝叶斯递归模型的通信方式。与此同时，大型语言模型 (LLMs) 被越来越多地应用于语义分析应用程序，任务是从自然语言推断逻辑表示。虽然现有的 LLM 探索主要局限于字面上的语言使用，但在这项工作中，我们评估了 LLM 推断语用话语的能力。具体而言，我们探讨了基于“强”这个等级形容词的门槛估计的情况，从具有强度先验条件的语境出发，然后扩展到限定、否定、极性反转和类比组合。我们发现，LLMs 可以推导出与语境相关的类人分布，涉及到几个复杂语用话语的解释，但在组合上还有困难。",
    "tldr": "本文评估了大型语言模型推断语用话语的能力。作者通过表述有关等级形容词“强”的门槛估计来测试 LLM 的性能，并发现 LLM 可以生成具有上下文依赖性、类人的分布，但在组合方面存在困难。",
    "en_tdlr": "This paper evaluates the capacity of large language models (LLMs) to infer the meanings of pragmatic utterances and finds that LLMs can derive context-grounded, human-like distributions over the interpretations of several complex pragmatic utterances, but struggle composing with negation, polarity inversion, and class comparison."
}