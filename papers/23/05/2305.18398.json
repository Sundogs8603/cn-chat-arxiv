{
    "title": "Mitigating Inappropriateness in Image Generation: Can there be Value in Reflecting the World's Ugliness?. (arXiv:2305.18398v1 [cs.CV])",
    "abstract": "Text-conditioned image generation models have recently achieved astonishing results in image quality and text alignment and are consequently employed in a fast-growing number of applications. Since they are highly data-driven, relying on billion-sized datasets randomly scraped from the web, they also reproduce inappropriate human behavior. Specifically, we demonstrate inappropriate degeneration on a large-scale for various generative text-to-image models, thus motivating the need for monitoring and moderating them at deployment. To this end, we evaluate mitigation strategies at inference to suppress the generation of inappropriate content. Our findings show that we can use models' representations of the world's ugliness to align them with human preferences.",
    "link": "http://arxiv.org/abs/2305.18398",
    "context": "Title: Mitigating Inappropriateness in Image Generation: Can there be Value in Reflecting the World's Ugliness?. (arXiv:2305.18398v1 [cs.CV])\nAbstract: Text-conditioned image generation models have recently achieved astonishing results in image quality and text alignment and are consequently employed in a fast-growing number of applications. Since they are highly data-driven, relying on billion-sized datasets randomly scraped from the web, they also reproduce inappropriate human behavior. Specifically, we demonstrate inappropriate degeneration on a large-scale for various generative text-to-image models, thus motivating the need for monitoring and moderating them at deployment. To this end, we evaluate mitigation strategies at inference to suppress the generation of inappropriate content. Our findings show that we can use models' representations of the world's ugliness to align them with human preferences.",
    "path": "papers/23/05/2305.18398.json",
    "total_tokens": 787,
    "translated_title": "图像生成中的不当行为缓解：反映世界丑陋是否有价值？",
    "translated_abstract": "近期，文本驱动的图像生成模型在图像质量和文本对齐方面取得了惊人的成果，并因此在越来越多的应用程序中得到应用。由于它们高度依赖于从网络上随机抓取的数十亿大小的数据集，因此它们还会复制不适当的人类行为。具体而言，我们证明了各种文本到图像生成模型的大规模不当退化，因此需要在部署时对其进行监视和调节。为此，我们评估了推理时的缓解策略，以抑制不合适内容的生成。我们的研究结果表明，我们可以使用模型对世界丑陋的表现来将其与人类偏好进行对齐。",
    "tldr": "该论文研究了文本驱动的图像生成模型复制不适当人类行为的问题，并提出了抑制生成不适当内容的策略，该策略利用模型对世界丑陋的表现与人类偏好对齐。",
    "en_tdlr": "This paper investigates the problem of text-driven image generation models reproducing inappropriate human behavior and proposes mitigation strategies to suppress the generation of inappropriate content. The strategy aligns the models' representations of the world's ugliness with human preferences."
}