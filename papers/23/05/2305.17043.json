{
    "title": "Explaining Deep Learning for ECG Analysis: Building Blocks for Auditing and Knowledge Discovery. (arXiv:2305.17043v1 [eess.SP])",
    "abstract": "Deep neural networks have become increasingly popular for analyzing ECG data because of their ability to accurately identify cardiac conditions and hidden clinical factors. However, the lack of transparency due to the black box nature of these models is a common concern. To address this issue, explainable AI (XAI) methods can be employed. In this study, we present a comprehensive analysis of post-hoc XAI methods, investigating the local (attributions per sample) and global (based on domain expert concepts) perspectives. We have established a set of sanity checks to identify sensible attribution methods, and we provide quantitative evidence in accordance with expert rules. This dataset-wide analysis goes beyond anecdotal evidence by aggregating data across patient subgroups. Furthermore, we demonstrate how these XAI techniques can be utilized for knowledge discovery, such as identifying subtypes of myocardial infarction. We believe that these proposed methods can serve as building block",
    "link": "http://arxiv.org/abs/2305.17043",
    "context": "Title: Explaining Deep Learning for ECG Analysis: Building Blocks for Auditing and Knowledge Discovery. (arXiv:2305.17043v1 [eess.SP])\nAbstract: Deep neural networks have become increasingly popular for analyzing ECG data because of their ability to accurately identify cardiac conditions and hidden clinical factors. However, the lack of transparency due to the black box nature of these models is a common concern. To address this issue, explainable AI (XAI) methods can be employed. In this study, we present a comprehensive analysis of post-hoc XAI methods, investigating the local (attributions per sample) and global (based on domain expert concepts) perspectives. We have established a set of sanity checks to identify sensible attribution methods, and we provide quantitative evidence in accordance with expert rules. This dataset-wide analysis goes beyond anecdotal evidence by aggregating data across patient subgroups. Furthermore, we demonstrate how these XAI techniques can be utilized for knowledge discovery, such as identifying subtypes of myocardial infarction. We believe that these proposed methods can serve as building block",
    "path": "papers/23/05/2305.17043.json",
    "total_tokens": 986,
    "translated_title": "解析心电图分析的深度学习：审计和知识发现的基石",
    "translated_abstract": "由于深度神经网络能够准确识别心脏疾病和隐藏的临床因素，因此它们已经越来越受欢迎地用于分析心电图数据。然而，这些模型的黑匣子特性缺乏透明度，是一个常见的问题。为了解决这个问题，可以使用可解释的人工智能（XAI）方法。在本研究中，我们展示了一种后事解释(XAI)方法的全面分析，研究了局部(每个样本的贡献值)和全局(基于领域专家概念)的视角。我们建立了一套检查措施，以确定合理的归因方法，并提供符合专家规则的定量证据。这种数据集范围的分析超出了个案经验证据，通过汇总患者亚组的数据来实现。此外，我们展示了这些XAI技术如何被用于知识发现，如识别心肌梗死的亚型。我们相信，这些提出的方法可以作为审计和知识发现的基础。",
    "tldr": "本文介绍了可解释人工智能(XAI)方法在心电图(ECG)分析中的应用，提出了一套检查措施以确定合理的归因方法，并通过对患者亚组的数据分析，展示了这些XAI技术如何被用于知识发现，如识别心肌梗死亚型。"
}