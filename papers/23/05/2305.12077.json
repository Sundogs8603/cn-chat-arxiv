{
    "title": "Few-Shot Dialogue Summarization via Skeleton-Assisted Prompt Transfer. (arXiv:2305.12077v1 [cs.CL])",
    "abstract": "In real-world scenarios, labeled samples for dialogue summarization are usually limited (i.e., few-shot) due to high annotation costs for high-quality dialogue summaries. To efficiently learn from few-shot samples, previous works have utilized massive annotated data from other downstream tasks and then performed prompt transfer in prompt tuning so as to enable cross-task knowledge transfer. However, existing general-purpose prompt transfer techniques lack consideration for dialogue-specific information. In this paper, we focus on improving the prompt transfer from dialogue state tracking to dialogue summarization and propose Skeleton-Assisted Prompt Transfer (SAPT), which leverages skeleton generation as extra supervision that functions as a medium connecting the distinct source and target task and resulting in the model's better consumption of dialogue state information. To automatically extract dialogue skeletons as supervised training data for skeleton generation, we design a novel ",
    "link": "http://arxiv.org/abs/2305.12077",
    "context": "Title: Few-Shot Dialogue Summarization via Skeleton-Assisted Prompt Transfer. (arXiv:2305.12077v1 [cs.CL])\nAbstract: In real-world scenarios, labeled samples for dialogue summarization are usually limited (i.e., few-shot) due to high annotation costs for high-quality dialogue summaries. To efficiently learn from few-shot samples, previous works have utilized massive annotated data from other downstream tasks and then performed prompt transfer in prompt tuning so as to enable cross-task knowledge transfer. However, existing general-purpose prompt transfer techniques lack consideration for dialogue-specific information. In this paper, we focus on improving the prompt transfer from dialogue state tracking to dialogue summarization and propose Skeleton-Assisted Prompt Transfer (SAPT), which leverages skeleton generation as extra supervision that functions as a medium connecting the distinct source and target task and resulting in the model's better consumption of dialogue state information. To automatically extract dialogue skeletons as supervised training data for skeleton generation, we design a novel ",
    "path": "papers/23/05/2305.12077.json",
    "total_tokens": 1001,
    "translated_title": "利用骨架辅助的提示传递进行少样本对话摘要",
    "translated_abstract": "在现实场景中，对话摘要的标记样本通常是有限的（即少样本），因为为高质量的对话摘要付出高昂的注释成本。为了有效地从少样本样本中学习，先前的工作利用了其他下游任务的海量注释数据，并在提示调整中执行提示传递，以实现跨任务知识传输。然而，现有的通用提示传递技术缺乏对对话特定信息的考虑。本文专注于改善从对话状态跟踪到对话摘要的提示传递，并提出了骨架辅助的提示传递（SAPT），它利用骨架生成作为额外的监督，作为连接不同源和目标任务的媒介，使模型更好地消耗对话状态信息。为了自动提取对话骨架作为骨架生成的受监督训练数据，我们设计了一种名为SkeletonNet的新型少样本对话摘要模型，其中涉及一个专门设计的骨架生成模块。实验结果表明，我们提出的SAPT在两个少样本对话摘要基准数据集上实现了最先进的性能。",
    "tldr": "该论文提出了一种利用骨架辅助的提示传递进行少样本对话摘要的方法，利用骨架生成作为额外的监督来更好地消耗对话状态信息，并提出了一种新型模型SkeletonNet进行骨架生成，实现了最先进的性能。",
    "en_tdlr": "This paper proposes a method for few-shot dialogue summarization via skeleton-assisted prompt transfer, which leverages skeleton generation as extra supervision to better consume dialogue state information, and introduces a novel model called SkeletonNet for skeleton generation, achieving state-of-the-art performance on two benchmark datasets."
}