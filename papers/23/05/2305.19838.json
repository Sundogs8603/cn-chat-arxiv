{
    "title": "Relaxing the Additivity Constraints in Decentralized No-Regret High-Dimensional Bayesian Optimization. (arXiv:2305.19838v2 [cs.LG] UPDATED)",
    "abstract": "Bayesian Optimization (BO) is typically used to optimize an unknown function $f$ that is noisy and costly to evaluate, by exploiting an acquisition function that must be maximized at each optimization step. Even if provably asymptotically optimal BO algorithms are efficient at optimizing low-dimensional functions, scaling them to high-dimensional spaces remains an open problem, often tackled by assuming an additive structure for $f$. By doing so, BO algorithms typically introduce additional restrictive assumptions on the additive structure that reduce their applicability domain. This paper contains two main contributions: (i) we relax the restrictive assumptions on the additive structure of $f$, at the expense of weakening the maximization guarantees of the acquisition function, and (ii) we address the over-exploration problem for decentralized BO algorithms. To these ends, we propose DumBO, an asymptotically optimal decentralized BO algorithm that achieves very competitive performance",
    "link": "http://arxiv.org/abs/2305.19838",
    "context": "Title: Relaxing the Additivity Constraints in Decentralized No-Regret High-Dimensional Bayesian Optimization. (arXiv:2305.19838v2 [cs.LG] UPDATED)\nAbstract: Bayesian Optimization (BO) is typically used to optimize an unknown function $f$ that is noisy and costly to evaluate, by exploiting an acquisition function that must be maximized at each optimization step. Even if provably asymptotically optimal BO algorithms are efficient at optimizing low-dimensional functions, scaling them to high-dimensional spaces remains an open problem, often tackled by assuming an additive structure for $f$. By doing so, BO algorithms typically introduce additional restrictive assumptions on the additive structure that reduce their applicability domain. This paper contains two main contributions: (i) we relax the restrictive assumptions on the additive structure of $f$, at the expense of weakening the maximization guarantees of the acquisition function, and (ii) we address the over-exploration problem for decentralized BO algorithms. To these ends, we propose DumBO, an asymptotically optimal decentralized BO algorithm that achieves very competitive performance",
    "path": "papers/23/05/2305.19838.json",
    "total_tokens": 898,
    "translated_title": "放松去中心化无遗憾高维贝叶斯优化中的加法约束",
    "translated_abstract": "贝叶斯优化常用于优化一个未知函数$f$，该函数存在噪声且评估成本高昂，通过利用必须在每个优化步骤中最大化的收获函数来实现。尽管可证明渐进最优的BO算法在优化低维函数方面效率很高，但将其扩展到高维空间仍然是一个待解决的问题，通常通过假设$f$具有加法结构来解决。通过这样做，BO算法通常引入了对加法结构的额外限制性假设，降低了它们的适用范围。本文包含两个主要贡献：（i）放松对$f$加法结构的限制性假设，以减弱收获函数的最大化保证；（ii）解决去中心化BO算法中的过度探索问题。为此，我们提出了DumBO，一种渐进最优的去中心化BO算法，具有非常竞争的性能。",
    "tldr": "本文提出了一种放松去中心化无遗憾高维贝叶斯优化中加法约束的方法，并且解决了过度探索问题。该方法称为DumBO，并且在实验中展示了竞争性能。"
}