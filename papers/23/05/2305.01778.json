{
    "title": "SLTUNET: A Simple Unified Model for Sign Language Translation. (arXiv:2305.01778v1 [cs.CL])",
    "abstract": "Despite recent successes with neural models for sign language translation (SLT), translation quality still lags behind spoken languages because of the data scarcity and modality gap between sign video and text. To address both problems, we investigate strategies for cross-modality representation sharing for SLT. We propose SLTUNET, a simple unified neural model designed to support multiple SLTrelated tasks jointly, such as sign-to-gloss, gloss-to-text and sign-to-text translation. Jointly modeling different tasks endows SLTUNET with the capability to explore the cross-task relatedness that could help narrow the modality gap. In addition, this allows us to leverage the knowledge from external resources, such as abundant parallel data used for spoken-language machine translation (MT). We show in experiments that SLTUNET achieves competitive and even state-of-the-art performance on PHOENIX-2014T and CSL-Daily when augmented with MT data and equipped with a set of optimization techniques. ",
    "link": "http://arxiv.org/abs/2305.01778",
    "context": "Title: SLTUNET: A Simple Unified Model for Sign Language Translation. (arXiv:2305.01778v1 [cs.CL])\nAbstract: Despite recent successes with neural models for sign language translation (SLT), translation quality still lags behind spoken languages because of the data scarcity and modality gap between sign video and text. To address both problems, we investigate strategies for cross-modality representation sharing for SLT. We propose SLTUNET, a simple unified neural model designed to support multiple SLTrelated tasks jointly, such as sign-to-gloss, gloss-to-text and sign-to-text translation. Jointly modeling different tasks endows SLTUNET with the capability to explore the cross-task relatedness that could help narrow the modality gap. In addition, this allows us to leverage the knowledge from external resources, such as abundant parallel data used for spoken-language machine translation (MT). We show in experiments that SLTUNET achieves competitive and even state-of-the-art performance on PHOENIX-2014T and CSL-Daily when augmented with MT data and equipped with a set of optimization techniques. ",
    "path": "papers/23/05/2305.01778.json",
    "total_tokens": 934,
    "translated_title": "SLTUNET：一种简单的统一模型进行手语翻译",
    "translated_abstract": "尽管最近神经模型在手语翻译（SLT）方面取得了成功，但由于数据稀缺性和手语视频与文本之间的模态差距，翻译质量仍然落后于口语语言。为了解决这两个问题，我们研究了跨模态表示共享的策略，提出了SLTUNET，这是一个设计用于支持多个SLT相关任务的简单统一神经模型，例如手语到手语编码、手语编码到文本、手语到文本翻译。联合建模不同任务赋予SLTUNET探索有助于缩小模态差距的跨任务相关性的能力。此外，这使我们能够利用外部资源的知识，例如用于口语机器翻译（MT）的丰富平行数据。我们通过实验证明，SLTUNET在增加MT数据并配备一组优化技术的情况下，可以在PHOENIX-2014T和CSL-Daily上实现竞争甚至领先的性能。",
    "tldr": "SLTUNET是一种简单的统一模型，为多个手语翻译任务提供支持。通过联合建模不同的任务，SLTUNET可以探索跨任务相关性以缩小模态差距，并借助外部数据进行优化，实现了竞争甚至领先的性能。",
    "en_tdlr": "SLTUNET is a simple unified model designed to support multiple sign language translation tasks. By jointly modeling different tasks, SLTUNET can explore cross-task relatedness to narrow the modality gap and leverage external resources for optimization, achieving competitive and even state-of-the-art performance."
}