{
    "title": "ParaLS: Lexical Substitution via Pretrained Paraphraser. (arXiv:2305.08146v1 [cs.CL])",
    "abstract": "Lexical substitution (LS) aims at finding appropriate substitutes for a target word in a sentence. Recently, LS methods based on pretrained language models have made remarkable progress, generating potential substitutes for a target word through analysis of its contextual surroundings. However, these methods tend to overlook the preservation of the sentence's meaning when generating the substitutes. This study explores how to generate the substitute candidates from a paraphraser, as the generated paraphrases from a paraphraser contain variations in word choice and preserve the sentence's meaning. Since we cannot directly generate the substitutes via commonly used decoding strategies, we propose two simple decoding strategies that focus on the variations of the target word during decoding. Experimental results show that our methods outperform state-of-the-art LS methods based on pre-trained language models on three benchmarks.",
    "link": "http://arxiv.org/abs/2305.08146",
    "context": "Title: ParaLS: Lexical Substitution via Pretrained Paraphraser. (arXiv:2305.08146v1 [cs.CL])\nAbstract: Lexical substitution (LS) aims at finding appropriate substitutes for a target word in a sentence. Recently, LS methods based on pretrained language models have made remarkable progress, generating potential substitutes for a target word through analysis of its contextual surroundings. However, these methods tend to overlook the preservation of the sentence's meaning when generating the substitutes. This study explores how to generate the substitute candidates from a paraphraser, as the generated paraphrases from a paraphraser contain variations in word choice and preserve the sentence's meaning. Since we cannot directly generate the substitutes via commonly used decoding strategies, we propose two simple decoding strategies that focus on the variations of the target word during decoding. Experimental results show that our methods outperform state-of-the-art LS methods based on pre-trained language models on three benchmarks.",
    "path": "papers/23/05/2305.08146.json",
    "total_tokens": 846,
    "translated_title": "ParaLS：基于预训练释义生成器的词汇替换",
    "translated_abstract": "词汇替换 (LS) 旨在找到句子中目标词的适当替代词。最近，基于预训练语言模型的 LS 方法取得了显著进展，通过分析目标词周围的语境生成潜在的替代词。然而，这些方法在生成替代词时往往忽视了句子含义的保留。本研究探讨了如何从释义生成器中生成替代词候选项，因为释义生成器生成的释义包含了词汇选择的变化并保留了句子的含义。由于我们无法直接通过常用的解码策略生成替代词，因此提出了两种简单的解码策略，专注于解码过程中目标词的变化。实验结果表明，我们的方法在三个基准测试中优于基于预训练语言模型的 LS 最新方法。",
    "tldr": "本研究提出了一种词汇替换方法，使用释义生成器生成替代词候选项，并提出两种解码策略，实验结果表明优于基于预训练语言模型的最新方法。",
    "en_tdlr": "This study proposes a lexical substitution method that uses a paraphraser to generate substitute candidates and proposes two decoding strategies that focus on the variations of the target word. Experimental results show that it outperforms state-of-the-art LS methods based on pre-trained language models."
}