{
    "title": "Mem-Rec: Memory Efficient Recommendation System using Alternative Representation. (arXiv:2305.07205v1 [cs.IR])",
    "abstract": "Deep learning-based recommendation systems (e.g., DLRMs) are widely used AI models to provide high-quality personalized recommendations. Training data used for modern recommendation systems commonly includes categorical features taking on tens-of-millions of possible distinct values. These categorical tokens are typically assigned learned vector representations, that are stored in large embedding tables, on the order of 100s of GB. Storing and accessing these tables represent a substantial burden in commercial deployments. Our work proposes MEM-REC, a novel alternative representation approach for embedding tables. MEM-REC leverages bloom filters and hashing methods to encode categorical features using two cache-friendly embedding tables. The first table (token embedding) contains raw embeddings (i.e. learned vector representation), and the second table (weight embedding), which is much smaller, contains weights to scale these raw embeddings to provide better discriminative capability t",
    "link": "http://arxiv.org/abs/2305.07205",
    "context": "Title: Mem-Rec: Memory Efficient Recommendation System using Alternative Representation. (arXiv:2305.07205v1 [cs.IR])\nAbstract: Deep learning-based recommendation systems (e.g., DLRMs) are widely used AI models to provide high-quality personalized recommendations. Training data used for modern recommendation systems commonly includes categorical features taking on tens-of-millions of possible distinct values. These categorical tokens are typically assigned learned vector representations, that are stored in large embedding tables, on the order of 100s of GB. Storing and accessing these tables represent a substantial burden in commercial deployments. Our work proposes MEM-REC, a novel alternative representation approach for embedding tables. MEM-REC leverages bloom filters and hashing methods to encode categorical features using two cache-friendly embedding tables. The first table (token embedding) contains raw embeddings (i.e. learned vector representation), and the second table (weight embedding), which is much smaller, contains weights to scale these raw embeddings to provide better discriminative capability t",
    "path": "papers/23/05/2305.07205.json",
    "total_tokens": 887,
    "translated_abstract": "基于深度学习的推荐系统 (例如DLRMs) 是提供高质量个性化推荐的广泛使用的AI模型。现代推荐系统所使用的训练数据通常包括具有数千万种可能值的分类特征。这些分类标识符通常被分配学习到的向量表示，这些向量存储在大型嵌入表中，其大小大约为100GB。在商业部署中，存储和访问这些表是一个实质性的负担。我们的工作提出了MEM-REC，一种新颖的嵌入表替代表示方法。MEM-REC利用Bloom过滤器和哈希方法，使用两个缓存友好的嵌入表对分类特征进行编码。第一个表 (标识符嵌入) 包含原始嵌入 (即学习到的向量表示)，第二个表 (权重嵌入) 的大小要小得多，包含权重以扩展这些原始嵌入以提供更好的判别能力。",
    "tldr": "Mem-Rec提出了一种新颖的嵌入表替代表示方法，它使用Bloom过滤器和哈希方法对分类特征进行编码，可以大大减小存储和访问嵌入表的负担，并提高推荐系统的判别能力。",
    "en_tdlr": "Mem-Rec proposes a novel alternative representation approach for embedding tables, which uses Bloom filters and hashing methods to encode categorical features, significantly reducing the burden of storing and accessing embedding tables while improving the discriminative capability of recommendation systems."
}