{
    "title": "Improving Multimodal Joint Variational Autoencoders through Normalizing Flows and Correlation Analysis. (arXiv:2305.11832v1 [stat.ML])",
    "abstract": "We propose a new multimodal variational autoencoder that enables to generate from the joint distribution and conditionally to any number of complex modalities. The unimodal posteriors are conditioned on the Deep Canonical Correlation Analysis embeddings which preserve the shared information across modalities leading to more coherent cross-modal generations. Furthermore, we use Normalizing Flows to enrich the unimodal posteriors and achieve more diverse data generation. Finally, we propose to use a Product of Experts for inferring one modality from several others which makes the model scalable to any number of modalities. We demonstrate that our method improves likelihood estimates, diversity of the generations and in particular coherence metrics in the conditional generations on several datasets.",
    "link": "http://arxiv.org/abs/2305.11832",
    "context": "Title: Improving Multimodal Joint Variational Autoencoders through Normalizing Flows and Correlation Analysis. (arXiv:2305.11832v1 [stat.ML])\nAbstract: We propose a new multimodal variational autoencoder that enables to generate from the joint distribution and conditionally to any number of complex modalities. The unimodal posteriors are conditioned on the Deep Canonical Correlation Analysis embeddings which preserve the shared information across modalities leading to more coherent cross-modal generations. Furthermore, we use Normalizing Flows to enrich the unimodal posteriors and achieve more diverse data generation. Finally, we propose to use a Product of Experts for inferring one modality from several others which makes the model scalable to any number of modalities. We demonstrate that our method improves likelihood estimates, diversity of the generations and in particular coherence metrics in the conditional generations on several datasets.",
    "path": "papers/23/05/2305.11832.json",
    "total_tokens": 804,
    "translated_title": "通过正则化流和相关性分析改进多模态联合变分自编码器",
    "translated_abstract": "我们提出了一种新的多模态变分自编码器，能够从联合分布生成并针对任意数量的复杂模态进行条件生成。单模后验分布是基于保留跨模态共享信息的深度典型相关分析嵌入进行条件生成的，从而实现了更连贯的跨模态生成。此外，我们使用正则化流来丰富单模后验分布，实现了更多样化的数据生成。最后，我们提出使用专家乘积来从多个模态中推断一个模态，从而使得模型可扩展到任意数量的模态。我们在几个数据集上证明了我们的方法改善了似然度估计、代表性的生成和在条件生成中特别是连贯性指标的性能。",
    "tldr": "本文提出了一种改进的多模态联合变分自编码器，利用正则化流和相关性分析技术，实现了更加连贯的跨模态生成，更多样化的数据生成，同时可扩展到任意数量的模态。",
    "en_tdlr": "This paper proposes an improved multimodal joint variational autoencoder, which utilizes normalizing flows and correlation analysis to achieve more coherent cross-modal generations and diverse data generation, and can be scaled to any number of modalities. The improvement is demonstrated through better likelihood estimates, representative generations, and in particular coherence metrics in conditional generations on several datasets."
}