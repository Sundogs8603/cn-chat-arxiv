{
    "title": "Embeddings between Barron spaces with higher order activation functions. (arXiv:2305.15839v1 [stat.ML])",
    "abstract": "The approximation properties of infinitely wide shallow neural networks heavily depend on the choice of the activation function. To understand this influence, we study embeddings between Barron spaces with different activation functions. These embeddings are proven by providing push-forward maps on the measures $\\mu$ used to represent functions $f$. An activation function of particular interest is the rectified power unit ($\\operatorname{RePU}$) given by $\\operatorname{RePU}_s(x)=\\max(0,x)^s$. For many commonly used activation functions, the well-known Taylor remainder theorem can be used to construct a push-forward map, which allows us to prove the embedding of the associated Barron space into a Barron space with a $\\operatorname{RePU}$ as activation function. Moreover, the Barron spaces associated with the $\\operatorname{RePU}_s$ have a hierarchical structure similar to the Sobolev spaces $H^m$.",
    "link": "http://arxiv.org/abs/2305.15839",
    "context": "Title: Embeddings between Barron spaces with higher order activation functions. (arXiv:2305.15839v1 [stat.ML])\nAbstract: The approximation properties of infinitely wide shallow neural networks heavily depend on the choice of the activation function. To understand this influence, we study embeddings between Barron spaces with different activation functions. These embeddings are proven by providing push-forward maps on the measures $\\mu$ used to represent functions $f$. An activation function of particular interest is the rectified power unit ($\\operatorname{RePU}$) given by $\\operatorname{RePU}_s(x)=\\max(0,x)^s$. For many commonly used activation functions, the well-known Taylor remainder theorem can be used to construct a push-forward map, which allows us to prove the embedding of the associated Barron space into a Barron space with a $\\operatorname{RePU}$ as activation function. Moreover, the Barron spaces associated with the $\\operatorname{RePU}_s$ have a hierarchical structure similar to the Sobolev spaces $H^m$.",
    "path": "papers/23/05/2305.15839.json",
    "total_tokens": 907,
    "translated_title": "具有高阶激活函数的Barron空间之间的嵌入",
    "translated_abstract": "无限宽浅层神经网络的逼近性质很大程度上取决于激活函数的选择。为了了解这种影响，我们研究了具有不同激活函数的Barron空间之间的嵌入。通过提供用于表示函数$f$的测量$\\mu$上的推进映射来证明这些嵌入。一种特别感兴趣的激活函数是给定为$\\operatorname{RePU}_s(x)=\\max(0,x)^s$的修正功率单位($\\operatorname{RePU}$)。对于许多常用的激活函数，可以使用众所周知的泰勒余项定理构造推进映射，这使我们能够证明相关Barron空间嵌入到具有$\\operatorname{RePU}$作为激活函数的Barron空间中。此外，与$\\operatorname{RePU}_s$相关的Barron空间具有类似于Sobolev空间$H^m$的分层结构。",
    "tldr": "本文研究了不同激活函数的Barron空间之间的嵌入，并证明了Barron空间的层次结构类似于Sobolev空间$H^m$。其中，修正功率单位激活函数在这个研究中特别重要。",
    "en_tdlr": "This paper studies the embeddings between Barron spaces with different activation functions, and proves that the Barron spaces associated with the rectified power unit activation function have a hierarchical structure similar to Sobolev spaces. The rectified power unit activation function is of particular interest in this study."
}