{
    "title": "Learning Directed Graphical Models with Optimal Transport. (arXiv:2305.15927v1 [cs.LG])",
    "abstract": "Estimating the parameters of a probabilistic directed graphical model from incomplete data remains a long-standing challenge. This is because, in the presence of latent variables, both the likelihood function and posterior distribution are intractable without further assumptions about structural dependencies or model classes. While existing learning methods are fundamentally based on likelihood maximization, here we offer a new view of the parameter learning problem through the lens of optimal transport. This perspective licenses a framework that operates on many directed graphs without making unrealistic assumptions on the posterior over the latent variables or resorting to black-box variational approximations. We develop a theoretical framework and support it with extensive empirical evidence demonstrating the flexibility and versatility of our approach. Across experiments, we show that not only can our method recover the ground-truth parameters but it also performs competitively on ",
    "link": "http://arxiv.org/abs/2305.15927",
    "context": "Title: Learning Directed Graphical Models with Optimal Transport. (arXiv:2305.15927v1 [cs.LG])\nAbstract: Estimating the parameters of a probabilistic directed graphical model from incomplete data remains a long-standing challenge. This is because, in the presence of latent variables, both the likelihood function and posterior distribution are intractable without further assumptions about structural dependencies or model classes. While existing learning methods are fundamentally based on likelihood maximization, here we offer a new view of the parameter learning problem through the lens of optimal transport. This perspective licenses a framework that operates on many directed graphs without making unrealistic assumptions on the posterior over the latent variables or resorting to black-box variational approximations. We develop a theoretical framework and support it with extensive empirical evidence demonstrating the flexibility and versatility of our approach. Across experiments, we show that not only can our method recover the ground-truth parameters but it also performs competitively on ",
    "path": "papers/23/05/2305.15927.json",
    "total_tokens": 833,
    "translated_title": "用最优传输学习有向图模型",
    "translated_abstract": "从不完整的数据中估计概率有向图模型的参数仍然是一个长期存在的挑战。这是因为在存在潜在变量的情况下，如果没有关于结构依赖性或模型类的进一步假设，似然函数和后验分布都是不可计算的。虽然现有的学习方法基本上是基于最大似然估计，但我们在这里通过最优传输的视角提供了参数学习问题的一个新视图。这个观点授权了一个框架，可以在许多有向图上运作，而不会对潜在变量的后验做出不切实际的假设或诉诸于黑箱变分近似。我们开发了一个理论框架，并支持它通过广泛的经验证据，展示了我们方法的灵活性和多功能性。通过实验，我们展示了我们的方法不仅可以恢复基准参数，而且在性能方面也表现得有竞争力。",
    "tldr": "通过最优传输的视角提供了参数学习问题的新视图，可以在许多有向图上进行操作并表现出灵活性和多功能性。",
    "en_tdlr": "This paper offers a new view of the parameter learning problem through the lens of optimal transport, which allows for a framework that operates on many directed graphs without making unrealistic assumptions on latent variables. The approach demonstrates flexibility and versatility in recovering ground-truth parameters and performing competitively on various experiments."
}