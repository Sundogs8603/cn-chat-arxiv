{
    "title": "Emulation Learning for Neuromimetic Systems. (arXiv:2305.03196v1 [eess.SY])",
    "abstract": "Building on our recent research on neural heuristic quantization systems, results on learning quantized motions and resilience to channel dropouts are reported. We propose a general emulation problem consistent with the neuromimetic paradigm. This optimal quantization problem can be solved by model predictive control (MPC), but because the optimization step involves integer programming, the approach suffers from combinatorial complexity when the number of input channels becomes large. Even if we collect data points to train a neural network simultaneously, collection of training data and the training itself are still time-consuming. Therefore, we propose a general Deep Q Network (DQN) algorithm that can not only learn the trajectory but also exhibit the advantages of resilience to channel dropout. Furthermore, to transfer the model to other emulation problems, a mapping-based transfer learning approach can be used directly on the current model to obtain the optimal direction for the ne",
    "link": "http://arxiv.org/abs/2305.03196",
    "context": "Title: Emulation Learning for Neuromimetic Systems. (arXiv:2305.03196v1 [eess.SY])\nAbstract: Building on our recent research on neural heuristic quantization systems, results on learning quantized motions and resilience to channel dropouts are reported. We propose a general emulation problem consistent with the neuromimetic paradigm. This optimal quantization problem can be solved by model predictive control (MPC), but because the optimization step involves integer programming, the approach suffers from combinatorial complexity when the number of input channels becomes large. Even if we collect data points to train a neural network simultaneously, collection of training data and the training itself are still time-consuming. Therefore, we propose a general Deep Q Network (DQN) algorithm that can not only learn the trajectory but also exhibit the advantages of resilience to channel dropout. Furthermore, to transfer the model to other emulation problems, a mapping-based transfer learning approach can be used directly on the current model to obtain the optimal direction for the ne",
    "path": "papers/23/05/2305.03196.json",
    "total_tokens": 914,
    "translated_title": "模仿神经系统的仿真学习",
    "translated_abstract": "基于我们最近在神经启发式量化系统上的研究，我们报告了学习量化运动和对信道中断的弹性的结果。我们提出了一种符合神经模仿模式的通用仿真问题。这个最优量化问题可以通过模型预测控制（MPC）来解决，但由于优化步骤涉及整数规划，当输入通道数量变大时，方法会受到组合复杂性的影响。即使我们同时收集数据点来训练神经网络，数据收集和训练本身仍然耗时。因此，我们提出了一个通用的深度Q网络（DQN）算法，不仅可以学习轨迹，还可以展示对信道中断的优势。此外，为了将模型转移到其他仿真问题，可以直接在当前模型上使用基于映射的迁移学习方法来获取最优方向。",
    "tldr": "本文提出了一种符合神经模仿模式的通用仿真问题，为了解决优化步骤的整数规划组合复杂性影响，提出了一种深度Q网络算法来学习轨迹和对信道中断具有优势；并且可以使用基于映射的迁移学习法来将模型应用于其他仿真问题。",
    "en_tdlr": "This paper proposes a general emulation problem consistent with the neuromimetic paradigm, and addresses the combinatorial complexity of integer programming in solving the optimal quantization problem. A Deep Q Network algorithm is proposed to learn trajectories and exhibit advantages in resilience to channel dropout. Moreover, a mapping-based transfer learning approach can be used to transfer the model to other emulation problems."
}