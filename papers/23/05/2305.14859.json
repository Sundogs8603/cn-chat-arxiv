{
    "title": "Utility-Probability Duality of Neural Networks. (arXiv:2305.14859v2 [cs.LG] UPDATED)",
    "abstract": "It is typically understood that the training of modern neural networks is a process of fitting the probability distribution of desired output. However, recent paradoxical observations in a number of language generation tasks let one wonder if this canonical probability-based explanation can really account for the empirical success of deep learning.  To resolve this issue, we propose an alternative utility-based explanation to the standard supervised learning procedure in deep learning. The basic idea is to interpret the learned neural network not as a probability model but as an ordinal utility function that encodes the preference revealed in training data. In this perspective, training of the neural network corresponds to a utility learning process. Specifically, we show that for all neural networks with softmax outputs, the SGD learning dynamic of maximum likelihood estimation (MLE) can be seen as an iteration process that optimizes the neural network toward an optimal utility functi",
    "link": "http://arxiv.org/abs/2305.14859",
    "context": "Title: Utility-Probability Duality of Neural Networks. (arXiv:2305.14859v2 [cs.LG] UPDATED)\nAbstract: It is typically understood that the training of modern neural networks is a process of fitting the probability distribution of desired output. However, recent paradoxical observations in a number of language generation tasks let one wonder if this canonical probability-based explanation can really account for the empirical success of deep learning.  To resolve this issue, we propose an alternative utility-based explanation to the standard supervised learning procedure in deep learning. The basic idea is to interpret the learned neural network not as a probability model but as an ordinal utility function that encodes the preference revealed in training data. In this perspective, training of the neural network corresponds to a utility learning process. Specifically, we show that for all neural networks with softmax outputs, the SGD learning dynamic of maximum likelihood estimation (MLE) can be seen as an iteration process that optimizes the neural network toward an optimal utility functi",
    "path": "papers/23/05/2305.14859.json",
    "total_tokens": 1035,
    "translated_title": "神经网络的效用-概率对偶",
    "translated_abstract": "现代神经网络的训练通常被认为是拟合所需输出的概率分布的过程。然而，最近在许多语言生成任务中观察到的悖论现象让人们怀疑这种基于概率的解释是否能真正解释深度学习的经验成功。为了解决这个问题，我们提出了一种替代方法，将深度学习中的标准监督学习过程解释为基于效用的解释。基本思想是将学习的神经网络不解释为概率模型，而解释为编码在训练数据中显示的偏好的序数效用函数。在这个视角下，神经网络的训练对应于一个效用学习过程。具体而言，我们证明了对于所有具有softmax输出的神经网络，最大似然估计（MLE）的SGD学习动态可以被视为一个迭代过程，该过程将神经网络优化到最优效用函数。这个框架不仅提供了对神经网络训练过程的新解释，而且提供了一个设计更好的神经网络体系结构的新视角。",
    "tldr": "提出了一种将深度学习中的标准监督学习过程解释为基于效用的解释方法，将学习的神经网络解释为编码在训练数据中显示的偏好的序数效用函数，可以将SGD最大似然估计的学习动态视为将神经网络优化到最优效用函数的迭代过程，从而提供了一个设计更好的神经网络体系结构的新视角。",
    "en_tdlr": "Proposed a utility-based interpretation to the standard supervised learning procedure in deep learning, interpreting the learned neural network as an ordinal utility function encoding the preference revealed in training data. The SGD learning dynamic of maximum likelihood estimation (MLE) can be seen as an iteration process that optimizes the neural network toward an optimal utility function, providing a new perspective on designing better neural network architectures."
}