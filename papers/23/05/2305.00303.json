{
    "title": "A Coupled Flow Approach to Imitation Learning. (arXiv:2305.00303v1 [cs.LG])",
    "abstract": "In reinforcement learning and imitation learning, an object of central importance is the state distribution induced by the policy. It plays a crucial role in the policy gradient theorem, and references to it--along with the related state-action distribution--can be found all across the literature. Despite its importance, the state distribution is mostly discussed indirectly and theoretically, rather than being modeled explicitly. The reason being an absence of appropriate density estimation tools. In this work, we investigate applications of a normalizing flow-based model for the aforementioned distributions. In particular, we use a pair of flows coupled through the optimality point of the Donsker-Varadhan representation of the Kullback-Leibler (KL) divergence, for distribution matching based imitation learning. Our algorithm, Coupled Flow Imitation Learning (CFIL), achieves state-of-the-art performance on benchmark tasks with a single expert trajectory and extends naturally to a varie",
    "link": "http://arxiv.org/abs/2305.00303",
    "context": "Title: A Coupled Flow Approach to Imitation Learning. (arXiv:2305.00303v1 [cs.LG])\nAbstract: In reinforcement learning and imitation learning, an object of central importance is the state distribution induced by the policy. It plays a crucial role in the policy gradient theorem, and references to it--along with the related state-action distribution--can be found all across the literature. Despite its importance, the state distribution is mostly discussed indirectly and theoretically, rather than being modeled explicitly. The reason being an absence of appropriate density estimation tools. In this work, we investigate applications of a normalizing flow-based model for the aforementioned distributions. In particular, we use a pair of flows coupled through the optimality point of the Donsker-Varadhan representation of the Kullback-Leibler (KL) divergence, for distribution matching based imitation learning. Our algorithm, Coupled Flow Imitation Learning (CFIL), achieves state-of-the-art performance on benchmark tasks with a single expert trajectory and extends naturally to a varie",
    "path": "papers/23/05/2305.00303.json",
    "total_tokens": 888,
    "translated_title": "一种耦合流方法用于模仿学习",
    "translated_abstract": "在强化学习和模仿学习中，策略引起的状态分布是一个非常重要的对象。它在策略梯度定理中起着至关重要的作用，并且与相关的状态行为分布一起被广泛引用。尽管状态分布非常重要，但它大多是间接地和理论上讨论，而不是明确地建模。原因是缺乏适当的密度估计工具。在这项工作中，我们研究了基于正则流模型的上述分布应用。特别是，我们使用通过Donsker-Varadhan表示的Kullback-Leibler（KL）散度的最优点耦合的一对流进行分布匹配的模仿学习。我们的算法Coupled Flow Imitation Learning（CFIL）在具有单个专家轨迹的基准任务上实现了最先进的性能，并且自然地扩展到各种形式的专家演示。",
    "tldr": "本文提出了一种新的模仿学习算法Coupled Flow Imitation Learning（CFIL），使用正则流模型的分布匹配来建模状态分布和状态行为分布。在基准任务中具有单个专家轨迹表现出最先进的性能。",
    "en_tdlr": "This paper proposes a new imitation learning algorithm, Coupled Flow Imitation Learning (CFIL), which uses a normalizing flow-based model for distribution matching to model the state distribution and state-action distribution. It achieves state-of-the-art performance on benchmark tasks with a single expert trajectory and extends naturally to various forms of expert demonstrations."
}