{
    "title": "All models are local: time to replace external validation with recurrent local validation. (arXiv:2305.03219v1 [cs.LG])",
    "abstract": "External validation is often recommended to ensure the generalizability of ML models. However, it neither guarantees generalizability nor equates to a model's clinical usefulness (the ultimate goal of any clinical decision-support tool). External validation is misaligned with current healthcare ML needs. First, patient data changes across time, geography, and facilities. These changes create significant volatility in the performance of a single fixed model (especially for deep learning models, which dominate clinical ML). Second, newer ML techniques, current market forces, and updated regulatory frameworks are enabling frequent updating and monitoring of individual deployed model instances. We submit that external validation is insufficient to establish ML models' safety or utility. Proposals to fix the external validation paradigm do not go far enough. Continued reliance on it as the ultimate test is likely to lead us astray. We propose the MLOps-inspired paradigm of recurring local v",
    "link": "http://arxiv.org/abs/2305.03219",
    "context": "Title: All models are local: time to replace external validation with recurrent local validation. (arXiv:2305.03219v1 [cs.LG])\nAbstract: External validation is often recommended to ensure the generalizability of ML models. However, it neither guarantees generalizability nor equates to a model's clinical usefulness (the ultimate goal of any clinical decision-support tool). External validation is misaligned with current healthcare ML needs. First, patient data changes across time, geography, and facilities. These changes create significant volatility in the performance of a single fixed model (especially for deep learning models, which dominate clinical ML). Second, newer ML techniques, current market forces, and updated regulatory frameworks are enabling frequent updating and monitoring of individual deployed model instances. We submit that external validation is insufficient to establish ML models' safety or utility. Proposals to fix the external validation paradigm do not go far enough. Continued reliance on it as the ultimate test is likely to lead us astray. We propose the MLOps-inspired paradigm of recurring local v",
    "path": "papers/23/05/2305.03219.json",
    "total_tokens": 1061,
    "translated_title": "所有的模型都是局部的: 用循环本地验证取代外部验证",
    "translated_abstract": "外部验证经常被推荐用于确保机器学习模型的泛化能力。然而，它既不能保证泛化能力，也不能等价于模型的临床实用性（任何临床决策支持工具的最终目标）。外部验证与当前医疗保健机器学习的需要不一致。其次，新的机器学习技术、当前的市场力量和更新的监管框架正在促进对个体部署的模型实例的频繁更新和监控。我们认为，外部验证不足以确保机器学习模型的安全性或实用性。修复外部验证范式的建议不够彻底。继续依赖它作为最终测试很可能会使我们走上错误道路。我们提出了 MLOps 启发式范式的循环本地验证作为新的黄金标准，强调监测和更新各个本地部署的模型。采用这种范式将更好地对齐临床和医疗特定需求与机器学习模型验证策略，提高临床决策支持工具的安全性和实用性。",
    "tldr": "本文认为外部验证无法确保机器学习模型的安全性或实用性，提出了循环本地验证的MLOps启发式范式作为新的黄金标准，强调对各个本地部署的模型进行监测和更新，从而更好地对齐临床和医疗特定需求与机器学习模型验证策略，提高临床决策支持工具的安全性和实用性。",
    "en_tdlr": "This paper proposes the MLOps-inspired paradigm of recurring local validation as a new gold-standard to better align clinical and healthcare-specific needs with machine learning model validation strategies, improving both the safety and utility of clinical decision-support tools."
}