{
    "title": "Causalainer: Causal Explainer for Automatic Video Summarization. (arXiv:2305.00455v1 [cs.CV])",
    "abstract": "The goal of video summarization is to automatically shorten videos such that it conveys the overall story without losing relevant information. In many application scenarios, improper video summarization can have a large impact. For example in forensics, the quality of the generated video summary will affect an investigator's judgment while in journalism it might yield undesired bias. Because of this, modeling explainability is a key concern. One of the best ways to address the explainability challenge is to uncover the causal relations that steer the process and lead to the result. Current machine learning-based video summarization algorithms learn optimal parameters but do not uncover causal relationships. Hence, they suffer from a relative lack of explainability. In this work, a Causal Explainer, dubbed Causalainer, is proposed to address this issue. Multiple meaningful random variables and their joint distributions are introduced to characterize the behaviors of key components in th",
    "link": "http://arxiv.org/abs/2305.00455",
    "context": "Title: Causalainer: Causal Explainer for Automatic Video Summarization. (arXiv:2305.00455v1 [cs.CV])\nAbstract: The goal of video summarization is to automatically shorten videos such that it conveys the overall story without losing relevant information. In many application scenarios, improper video summarization can have a large impact. For example in forensics, the quality of the generated video summary will affect an investigator's judgment while in journalism it might yield undesired bias. Because of this, modeling explainability is a key concern. One of the best ways to address the explainability challenge is to uncover the causal relations that steer the process and lead to the result. Current machine learning-based video summarization algorithms learn optimal parameters but do not uncover causal relationships. Hence, they suffer from a relative lack of explainability. In this work, a Causal Explainer, dubbed Causalainer, is proposed to address this issue. Multiple meaningful random variables and their joint distributions are introduced to characterize the behaviors of key components in th",
    "path": "papers/23/05/2305.00455.json",
    "total_tokens": 1039,
    "translated_title": "Causalainer: 自动视频摘要的因果解释器",
    "translated_abstract": "视频摘要的目标是自动缩短视频，以传达整个故事而不失去相关信息。在许多应用场景中，不适当的视频摘要可能会产生重大影响。例如，在法医学中，生成的视频摘要的质量将影响调查人员的判断，而在新闻学中可能会产生不希望的偏见。因此，对建模的可解释性是一个关键问题。揭示引导过程并导致结果的因果关系是解决可解释性挑战的最佳方法之一。当前基于机器学习的视频摘要算法学习最佳参数，但不揭示因果关系。因此，它们缺乏相对解释能力。在这项工作中，提出了一种称为Causalainer的因果解释器来解决这个问题。引入多个有意义的随机变量及其联合分布来描述视频摘要管道中关键组件的行为。Causalainer使人们能够分析用户指定的干预的因果效应，并了解视频摘要过程的基本逻辑。实验表明，Causalainer不仅实现了高质量的视频摘要，还提供了有意义的见解，以提高模型的透明度和可解释性。",
    "tldr": "Causalainer是一个自动视频摘要的因果解释器，其引入多个有意义的随机变量及其联合分布来描述视频摘要管道中关键组件的行为，可以分析用户指定的干预的因果效应，提高了模型的透明度和可解释性。",
    "en_tdlr": "Causalainer is a causal explainer for automatic video summarization that introduces multiple meaningful random variables and their joint distributions to characterize the behaviors of key components in the video summarization pipeline, enabling analysis of causal effects of user-specified interventions and improving model transparency and interpretability."
}