{
    "title": "Learning Achievement Structure for Structured Exploration in Domains with Sparse Reward. (arXiv:2305.00508v1 [cs.LG])",
    "abstract": "We propose Structured Exploration with Achievements (SEA), a multi-stage reinforcement learning algorithm designed for achievement-based environments, a particular type of environment with an internal achievement set. SEA first uses offline data to learn a representation of the known achievements with a determinant loss function, then recovers the dependency graph of the learned achievements with a heuristic algorithm, and finally interacts with the environment online to learn policies that master known achievements and explore new ones with a controller built with the recovered dependency graph. We empirically demonstrate that SEA can recover the achievement structure accurately and improve exploration in hard domains such as Crafter that are procedurally generated with high-dimensional observations like images.",
    "link": "http://arxiv.org/abs/2305.00508",
    "context": "Title: Learning Achievement Structure for Structured Exploration in Domains with Sparse Reward. (arXiv:2305.00508v1 [cs.LG])\nAbstract: We propose Structured Exploration with Achievements (SEA), a multi-stage reinforcement learning algorithm designed for achievement-based environments, a particular type of environment with an internal achievement set. SEA first uses offline data to learn a representation of the known achievements with a determinant loss function, then recovers the dependency graph of the learned achievements with a heuristic algorithm, and finally interacts with the environment online to learn policies that master known achievements and explore new ones with a controller built with the recovered dependency graph. We empirically demonstrate that SEA can recover the achievement structure accurately and improve exploration in hard domains such as Crafter that are procedurally generated with high-dimensional observations like images.",
    "path": "papers/23/05/2305.00508.json",
    "total_tokens": 818,
    "translated_title": "学习成就结构来在有稀疏奖励的领域进行结构化探索",
    "translated_abstract": "本文提出了一种名为SEA的多阶段强化学习算法，旨在为基于成就的环境设计，即具有内部成就集的特定类型环境。SEA首先使用离线数据，使用确定性损失函数学习已知成就的表示，然后使用启发式算法恢复学习成就的依赖关系图，最后通过使用恢复的依赖关系图构建控制器，在线与环境交互学习掌握已知成就并探索新成就的策略。我们通过实验证明，SEA可以准确地恢复成就结构，并改善在像图像这样具有高维观察值的大型生成领域（如Crafter）中的探索能力。",
    "tldr": "本文提出了SEA算法，可在成就型环境中进行探索任务。SEA首先学习已知成就的表示和依赖关系图，然后通过构建控制器在线探索新成就。实验证明SEA能够准确地恢复成就结构并改善在一些复杂领域中的探索性能。",
    "en_tdlr": "This paper proposes a multi-stage reinforcement learning algorithm called SEA, which is designed for achievement-based environments. It first learns a representation of known achievements and their dependency graph using offline data, and then interacts with the environment online to explore new achievements. Empirical results show that SEA accurately recovers the achievement structure and improves exploration in complex domains."
}