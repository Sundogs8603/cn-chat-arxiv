{
    "title": "Few-shot Action Recognition via Intra- and Inter-Video Information Maximization. (arXiv:2305.06114v1 [cs.CV])",
    "abstract": "Current few-shot action recognition involves two primary sources of information for classification:(1) intra-video information, determined by frame content within a single video clip, and (2) inter-video information, measured by relationships (e.g., feature similarity) among videos. However, existing methods inadequately exploit these two information sources. In terms of intra-video information, current sampling operations for input videos may omit critical action information, reducing the utilization efficiency of video data. For the inter-video information, the action misalignment among videos makes it challenging to calculate precise relationships. Moreover, how to jointly consider both inter- and intra-video information remains under-explored for few-shot action recognition. To this end, we propose a novel framework, Video Information Maximization (VIM), for few-shot video action recognition. VIM is equipped with an adaptive spatial-temporal video sampler and a spatiotemporal actio",
    "link": "http://arxiv.org/abs/2305.06114",
    "context": "Title: Few-shot Action Recognition via Intra- and Inter-Video Information Maximization. (arXiv:2305.06114v1 [cs.CV])\nAbstract: Current few-shot action recognition involves two primary sources of information for classification:(1) intra-video information, determined by frame content within a single video clip, and (2) inter-video information, measured by relationships (e.g., feature similarity) among videos. However, existing methods inadequately exploit these two information sources. In terms of intra-video information, current sampling operations for input videos may omit critical action information, reducing the utilization efficiency of video data. For the inter-video information, the action misalignment among videos makes it challenging to calculate precise relationships. Moreover, how to jointly consider both inter- and intra-video information remains under-explored for few-shot action recognition. To this end, we propose a novel framework, Video Information Maximization (VIM), for few-shot video action recognition. VIM is equipped with an adaptive spatial-temporal video sampler and a spatiotemporal actio",
    "path": "papers/23/05/2305.06114.json",
    "total_tokens": 880,
    "translated_title": "基于视频内部和视频间信息最大化的小样本动作识别",
    "translated_abstract": "当前的小样本动作识别涉及两个主要的信息源用于分类: (1) 来自视频片段内部的视频内部信息，由单个视频剪辑中的帧内容确定，以及 (2) 通过视频之间的关系(例如，特征相似性)测量的视频间信息。然而，现有方法未充分利用这两个信息源。关于视频内部信息，当前的输入视频采样操作可能会遗漏关键的动作信息，降低视频数据的利用效率。对于视频间信息，视频之间的动作不对齐使得计算精确关系变得困难。此外，如何共同考虑视频内外信息在小样本动作识别中仍未被充分探索。为此，我们提出了一个新的框架，称为视频信息最大化 (VIM)，用于小样本视频动作识别。VIM配备了一个自适应的时空视频采样器和一个时空动作增强器。",
    "tldr": "本论文提出了一种称为VIM的框架，采用自适应空间-时间视频采样器和时空动作增强器，用于小样本动作识别，充分利用视频内部和视频间信息以提高识别精度。"
}