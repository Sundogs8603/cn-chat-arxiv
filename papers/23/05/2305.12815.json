{
    "title": "Investigating Agency of LLMs in Human-AI Collaboration Tasks",
    "abstract": "Agency, the capacity to proactively shape events, is central to how humans interact and collaborate. While LLMs are being developed to simulate human behavior and serve as human-like agents, little attention has been given to the Agency that these models should possess in order to proactively manage the direction of interaction and collaboration. In this paper, we investigate Agency as a desirable function of LLMs, and how it can be measured and managed. We build on social-cognitive theory to develop a framework of features through which Agency is expressed in dialogue - indicating what you intend to do (Intentionality), motivating your intentions (Motivation), having self-belief in intentions (Self-Efficacy), and being able to self-adjust (Self-Regulation). We collect a new dataset of 83 human-human collaborative interior design conversations containing 908 conversational snippets annotated for Agency features. Using this dataset, we develop methods for measuring Agency of LLMs. Autom",
    "link": "https://arxiv.org/abs/2305.12815",
    "context": "Title: Investigating Agency of LLMs in Human-AI Collaboration Tasks\nAbstract: Agency, the capacity to proactively shape events, is central to how humans interact and collaborate. While LLMs are being developed to simulate human behavior and serve as human-like agents, little attention has been given to the Agency that these models should possess in order to proactively manage the direction of interaction and collaboration. In this paper, we investigate Agency as a desirable function of LLMs, and how it can be measured and managed. We build on social-cognitive theory to develop a framework of features through which Agency is expressed in dialogue - indicating what you intend to do (Intentionality), motivating your intentions (Motivation), having self-belief in intentions (Self-Efficacy), and being able to self-adjust (Self-Regulation). We collect a new dataset of 83 human-human collaborative interior design conversations containing 908 conversational snippets annotated for Agency features. Using this dataset, we develop methods for measuring Agency of LLMs. Autom",
    "path": "papers/23/05/2305.12815.json",
    "total_tokens": 832,
    "translated_title": "探究LLMs在人工智能协作任务中的代理力",
    "translated_abstract": "代理力是人类互动和协作的核心能力。虽然LLMs被开发成模拟人类行为并作为类人代理使用，但对这些模型应具有的代理力的关注却不足，以便主动管理互动和协作的方向。在本文中，我们研究了代理力作为LLMs的一种理想功能的性质，以及如何衡量和管理代理力。我们借鉴社会认知理论，开发了一种特征框架，通过对话表达代理力，表示您打算做什么（意向性），激发您的意图（动机），对意向有自信（自我效能），并能够自我调整（自我调节）。我们收集了一个新的数据集，包含908个对人对话片段的注释，用于标记代理力特征。利用这个数据集，我们开发了衡量LLMs代理力的方法。",
    "tldr": "本论文探讨了LLMs在人工智能协作任务中的代理力，开发了一种用于衡量和管理LLMs代理力的特征框架，并通过新的数据集验证了该方法的有效性。",
    "en_tdlr": "This paper investigates the agency of LLMs in human-AI collaboration tasks, develops a framework for measuring and managing agency, and validates the method using a new dataset."
}