{
    "title": "Improved Visual Story Generation with Adaptive Context Modeling. (arXiv:2305.16811v1 [cs.CV])",
    "abstract": "Diffusion models developed on top of powerful text-to-image generation models like Stable Diffusion achieve remarkable success in visual story generation. However, the best-performing approach considers historically generated results as flattened memory cells, ignoring the fact that not all preceding images contribute equally to the generation of the characters and scenes at the current stage. To address this, we present a simple method that improves the leading system with adaptive context modeling, which is not only incorporated in the encoder but also adopted as additional guidance in the sampling stage to boost the global consistency of the generated story. We evaluate our model on PororoSV and FlintstonesSV datasets and show that our approach achieves state-of-the-art FID scores on both story visualization and continuation scenarios. We conduct detailed model analysis and show that our model excels at generating semantically consistent images for stories.",
    "link": "http://arxiv.org/abs/2305.16811",
    "context": "Title: Improved Visual Story Generation with Adaptive Context Modeling. (arXiv:2305.16811v1 [cs.CV])\nAbstract: Diffusion models developed on top of powerful text-to-image generation models like Stable Diffusion achieve remarkable success in visual story generation. However, the best-performing approach considers historically generated results as flattened memory cells, ignoring the fact that not all preceding images contribute equally to the generation of the characters and scenes at the current stage. To address this, we present a simple method that improves the leading system with adaptive context modeling, which is not only incorporated in the encoder but also adopted as additional guidance in the sampling stage to boost the global consistency of the generated story. We evaluate our model on PororoSV and FlintstonesSV datasets and show that our approach achieves state-of-the-art FID scores on both story visualization and continuation scenarios. We conduct detailed model analysis and show that our model excels at generating semantically consistent images for stories.",
    "path": "papers/23/05/2305.16811.json",
    "total_tokens": 894,
    "translated_title": "基于自适应上下文建模的视觉故事生成的改进",
    "translated_abstract": "在像稳定扩散这样的强大的文本到图像生成模型上开发的扩散模型在视觉故事生成方面取得了显著的成功。然而，最佳表现的方法将历史生成的结果视为扁平化的记忆单元，忽略了并非所有先前的图像对当前阶段的角色和场景的生成都有同等的贡献。为了解决这个问题，我们提出了一种使用自适应上下文建模改进主要系统的简单方法，该方法不仅将其纳入编码器，而且还在采样阶段采用其作为额外的指导，以提高生成故事的全局一致性。我们评估了在PororoSV和FlintstonesSV数据集上的模型，并展示了我们的方法在故事可视化和延续场景方面都实现了最先进的FID分数。我们进行了详细的模型分析，并展示了我们的模型在生成语义一致的故事图像方面表现出色。",
    "tldr": "这篇论文提出了一种简单的方法，使用自适应上下文建模改进了视觉故事生成，以提高生成故事的全局一致性和生成语义一致的故事图像，并在PororoSV和FlintstonesSV数据集上实现了最佳结果。",
    "en_tdlr": "This paper proposes a simple method to improve visual story generation with adaptive context modeling, which boosts global consistency and generates semantically consistent images for stories. The approach achieves state-of-the-art FID scores on both story visualization and continuation scenarios in PororoSV and FlintstonesSV datasets."
}