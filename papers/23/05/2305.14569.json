{
    "title": "Few-shot Unified Question Answering: Tuning Models or Prompts?. (arXiv:2305.14569v1 [cs.CL])",
    "abstract": "Question-answering (QA) tasks often investigate specific question types, knowledge domains, or reasoning skills, leading to specialized models catering to specific categories of QA tasks. While recent research has explored the idea of unified QA models, such models are usually explored for high-resource scenarios and require re-training to extend their capabilities. To overcome these drawbacks, the paper explores the potential of two paradigms of tuning, model, and prompts, for unified QA under a low-resource setting. The paper provides an exhaustive analysis of their applicability using 16 QA datasets, revealing that prompt tuning can perform as well as model tuning in a few-shot setting with a good initialization. The study also shows that parameter-sharing results in superior few-shot performance, simple knowledge transfer techniques for prompt initialization can be effective, and prompt tuning achieves a significant performance boost from pre-training in a low-resource regime. The ",
    "link": "http://arxiv.org/abs/2305.14569",
    "context": "Title: Few-shot Unified Question Answering: Tuning Models or Prompts?. (arXiv:2305.14569v1 [cs.CL])\nAbstract: Question-answering (QA) tasks often investigate specific question types, knowledge domains, or reasoning skills, leading to specialized models catering to specific categories of QA tasks. While recent research has explored the idea of unified QA models, such models are usually explored for high-resource scenarios and require re-training to extend their capabilities. To overcome these drawbacks, the paper explores the potential of two paradigms of tuning, model, and prompts, for unified QA under a low-resource setting. The paper provides an exhaustive analysis of their applicability using 16 QA datasets, revealing that prompt tuning can perform as well as model tuning in a few-shot setting with a good initialization. The study also shows that parameter-sharing results in superior few-shot performance, simple knowledge transfer techniques for prompt initialization can be effective, and prompt tuning achieves a significant performance boost from pre-training in a low-resource regime. The ",
    "path": "papers/23/05/2305.14569.json",
    "total_tokens": 918,
    "translated_title": "少样本统一问答：调整模型还是提示？",
    "translated_abstract": "问答（QA）任务通常研究特定的问题类型、知识领域或推理技能，导致专门针对特定类别的QA任务的模型。虽然最近的研究探讨了统一QA模型的想法，但这些模型通常只在高资源情况下进行探索，并需要重新训练以扩展其能力。本文探讨了调整模型和提示两种范式在低资源情况下用于统一QA的潜力，采用16个QA数据集进行了详尽的应用分析，发现在良好的初始化条件下，提示调整可以在少样本情况下的表现与模型调整相当。研究还显示参数共享导致优秀的少样本性能，简单的提示初始化知识转移技术可以有效，提示调整在低资源范围内通过预训练实现了显著的性能提升。",
    "tldr": "本文探讨了调整模型和提示两种范式在低资源情况下用于统一QA的潜力，研究发现在良好的初始化条件下，提示调整可以在少样本情况下的表现与模型调整相当，通过参数共享和简单的提示初始化知识转移技术，提示调整在低资源情况下可以实现显著的性能提升。"
}