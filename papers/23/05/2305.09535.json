{
    "title": "What's the Problem, Linda? The Conjunction Fallacy as a Fairness Problem. (arXiv:2305.09535v1 [cs.AI])",
    "abstract": "The field of Artificial Intelligence (AI) is focusing on creating automated decision-making (ADM) systems that operate as close as possible to human-like intelligence. This effort has pushed AI researchers into exploring cognitive fields like psychology. The work of Daniel Kahneman and the late Amos Tversky on biased human decision-making, including the study of the conjunction fallacy, has experienced a second revival because of this. Under the conjunction fallacy a human decision-maker will go against basic probability laws and rank as more likely a conjunction over one of its parts. It has been proven overtime through a set of experiments with the Linda Problem being the most famous one. Although this interdisciplinary effort is welcomed, we fear that AI researchers ignore the driving force behind the conjunction fallacy as captured by the Linda Problem: the fact that Linda must be stereotypically described as a woman. In this paper we revisit the Linda Problem and formulate it as a",
    "link": "http://arxiv.org/abs/2305.09535",
    "context": "Title: What's the Problem, Linda? The Conjunction Fallacy as a Fairness Problem. (arXiv:2305.09535v1 [cs.AI])\nAbstract: The field of Artificial Intelligence (AI) is focusing on creating automated decision-making (ADM) systems that operate as close as possible to human-like intelligence. This effort has pushed AI researchers into exploring cognitive fields like psychology. The work of Daniel Kahneman and the late Amos Tversky on biased human decision-making, including the study of the conjunction fallacy, has experienced a second revival because of this. Under the conjunction fallacy a human decision-maker will go against basic probability laws and rank as more likely a conjunction over one of its parts. It has been proven overtime through a set of experiments with the Linda Problem being the most famous one. Although this interdisciplinary effort is welcomed, we fear that AI researchers ignore the driving force behind the conjunction fallacy as captured by the Linda Problem: the fact that Linda must be stereotypically described as a woman. In this paper we revisit the Linda Problem and formulate it as a",
    "path": "papers/23/05/2305.09535.json",
    "total_tokens": 1058,
    "translated_title": "《琳达，出了什么问题？》“连接谬误”作为公平性问题的探讨",
    "translated_abstract": "人工智能领域正在专注于创建尽可能接近人类智能的自动决策系统。这一努力推动人工智能研究人员探索心理学等认知领域。 Daniel Kahneman和已故的Amos Tversky在有偏见的人类决策制定方面的工作，包括对连接谬误的研究，因此进行了第二次复兴。 在连接谬误下，决策制定者会违反基本概率法则，认为连词比其中一个部分更有可能。通过一系列与琳达问题最为著名的实验，它已被证明是经得起时间考验的。虽然这种跨学科的努力受到欢迎，但我们担心，人工智能研究人员忽略了琳达问题所捕捉到的驱动力：琳达必须被刻板地描述为一个女性。 在本文中，我们重新审视琳达问题，并将其形式化为AI中的公平性问题。我们认为连接谬误是偏见数据集如何导致偏见结果的明显例子，从而延续和放大现有的系统性偏见。我们提出了一组问题供AI研究人员和从业人员使用，以避免类似情况在未来发生。",
    "tldr": "这篇论文探讨了“连接谬误”作为公平性问题在人工智能领域中的重要性，并提出了一些问题，以帮助AI研究人员和从业者避免类似情况在未来中复现。",
    "en_tdlr": "This paper discusses the importance of the conjunction fallacy as a fairness problem in the field of artificial intelligence and proposes a set of questions to help AI researchers and practitioners avoid similar occurrences in the future."
}