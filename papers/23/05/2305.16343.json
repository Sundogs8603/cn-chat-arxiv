{
    "title": "A Distributed Automatic Domain-Specific Multi-Word Term Recognition Architecture using Spark Ecosystem. (arXiv:2305.16343v1 [cs.CL])",
    "abstract": "Automatic Term Recognition is used to extract domain-specific terms that belong to a given domain. In order to be accurate, these corpus and language-dependent methods require large volumes of textual data that need to be processed to extract candidate terms that are afterward scored according to a given metric. To improve text preprocessing and candidate terms extraction and scoring, we propose a distributed Spark-based architecture to automatically extract domain-specific terms. The main contributions are as follows: (1) propose a novel distributed automatic domain-specific multi-word term recognition architecture built on top of the Spark ecosystem; (2) perform an in-depth analysis of our architecture in terms of accuracy and scalability; (3) design an easy-to-integrate Python implementation that enables the use of Big Data processing in fields such as Computational Linguistics and Natural Language Processing. We prove empirically the feasibility of our architecture by performing ex",
    "link": "http://arxiv.org/abs/2305.16343",
    "context": "Title: A Distributed Automatic Domain-Specific Multi-Word Term Recognition Architecture using Spark Ecosystem. (arXiv:2305.16343v1 [cs.CL])\nAbstract: Automatic Term Recognition is used to extract domain-specific terms that belong to a given domain. In order to be accurate, these corpus and language-dependent methods require large volumes of textual data that need to be processed to extract candidate terms that are afterward scored according to a given metric. To improve text preprocessing and candidate terms extraction and scoring, we propose a distributed Spark-based architecture to automatically extract domain-specific terms. The main contributions are as follows: (1) propose a novel distributed automatic domain-specific multi-word term recognition architecture built on top of the Spark ecosystem; (2) perform an in-depth analysis of our architecture in terms of accuracy and scalability; (3) design an easy-to-integrate Python implementation that enables the use of Big Data processing in fields such as Computational Linguistics and Natural Language Processing. We prove empirically the feasibility of our architecture by performing ex",
    "path": "papers/23/05/2305.16343.json",
    "total_tokens": 906,
    "translated_title": "基于Spark生态系统的分布式自动领域特定多词术语识别架构",
    "translated_abstract": "自动术语识别用于提取属于给定领域的特定术语。为了准确，这些基于语料库和语言依赖的方法需要处理大量文本数据以提取候选术语，然后根据给定的度量标准进行评分。为了改进文本预处理和候选术语的提取和评分，我们提出了一种使用Spark生态系统自动提取领域特定术语的分布式架构。主要贡献如下：（1）提出了一种新颖的分布式自动领域特定多词术语识别架构，构建在Spark生态系统之上；（2）从准确性和可扩展性方面对我们的架构进行了深入分析；（3）设计了一个易于集成的Python实现，使其能够在计算语言学和自然语言处理等领域使用大数据处理。我们通过在多个数据集和领域上进行实验来经验性地证明了我们架构的可行性，在术语提取准确性方面取得了最先进的结果。",
    "tldr": "本论文提出了一种基于Spark生态系统的分布式架构，可自动提取领域特定术语，经实验证明在术语提取准确性方面取得最先进的结果。",
    "en_tdlr": "This paper proposes a distributed architecture based on the Spark ecosystem for automatically extracting domain-specific terms, achieving state-of-the-art results in term extraction accuracy as demonstrated through experiments on multiple datasets and domains."
}