{
    "title": "ComedicSpeech: Text To Speech For Stand-up Comedies in Low-Resource Scenarios. (arXiv:2305.12200v1 [cs.SD])",
    "abstract": "Text to Speech (TTS) models can generate natural and high-quality speech, but it is not expressive enough when synthesizing speech with dramatic expressiveness, such as stand-up comedies. Considering comedians have diverse personal speech styles, including personal prosody, rhythm, and fillers, it requires real-world datasets and strong speech style modeling capabilities, which brings challenges. In this paper, we construct a new dataset and develop ComedicSpeech, a TTS system tailored for the stand-up comedy synthesis in low-resource scenarios. First, we extract prosody representation by the prosody encoder and condition it to the TTS model in a flexible way. Second, we enhance the personal rhythm modeling by a conditional duration predictor. Third, we model the personal fillers by introducing comedian-related special tokens. Experiments show that ComedicSpeech achieves better expressiveness than baselines with only ten-minute training data for each comedian. The audio samples are ava",
    "link": "http://arxiv.org/abs/2305.12200",
    "context": "Title: ComedicSpeech: Text To Speech For Stand-up Comedies in Low-Resource Scenarios. (arXiv:2305.12200v1 [cs.SD])\nAbstract: Text to Speech (TTS) models can generate natural and high-quality speech, but it is not expressive enough when synthesizing speech with dramatic expressiveness, such as stand-up comedies. Considering comedians have diverse personal speech styles, including personal prosody, rhythm, and fillers, it requires real-world datasets and strong speech style modeling capabilities, which brings challenges. In this paper, we construct a new dataset and develop ComedicSpeech, a TTS system tailored for the stand-up comedy synthesis in low-resource scenarios. First, we extract prosody representation by the prosody encoder and condition it to the TTS model in a flexible way. Second, we enhance the personal rhythm modeling by a conditional duration predictor. Third, we model the personal fillers by introducing comedian-related special tokens. Experiments show that ComedicSpeech achieves better expressiveness than baselines with only ten-minute training data for each comedian. The audio samples are ava",
    "path": "papers/23/05/2305.12200.json",
    "total_tokens": 1079,
    "translated_title": "ComedicSpeech: 用于低资源情境下的单口喜剧文本生成语音系统",
    "translated_abstract": "文本语音合成（TTS）模型可生成自然且高质量的语音，但在合成具有戏剧性表现力的语音时（如单口喜剧），其表现力不够。考虑到喜剧演员有着多样的个人演讲风格，包括个人语调、韵律和填充语，这需要真实世界的数据集和强大的语音风格建模能力，这带来了挑战。本文构建了一个新的数据集，并开发了ComedicSpeech，这是一个专门用于低资源场景中的单口喜剧合成的TTS系统。首先，我们使用语调编码器提取语调表示，并以灵活的方式将其定向到TTS模型。其次，我们通过有条件的持续时间预测器增强了个人韵律建模。第三，我们通过引入与喜剧演员相关的特殊标记来模拟个人填充语。实验表明，ComedicSpeech在每个喜剧演员仅有十分钟训练数据情况下，比基线模型表现出更好的表现力。音频样本可在https://bit.ly/3dxm5Ol获得。",
    "tldr": "本文构建了一个用于低资源情境中的单口喜剧文本生成语音系统ComedicSpeech，该系统使用语调编码器提取语调表示并以灵活的方式将其定向到TTS模型，同时通过有条件的持续时间预测器来增强个人韵律建模，并通过引入与喜剧演员相关的特殊标记来模拟个人填充语。实验表明，ComedicSpeech在仅有十分钟训练数据情况下比基线模型表现出更好的表现力。",
    "en_tdlr": "The paper presents ComedicSpeech, a TTS system tailored for stand-up comedy synthesis in low-resource scenarios, which achieves better expressiveness than baselines with only ten-minute training data for each comedian by extracting prosody representation by the prosody encoder, enhancing personal rhythm modeling by a conditional duration predictor, and modeling personal fillers by introducing comedian-related special tokens."
}