{
    "title": "X-IQE: eXplainable Image Quality Evaluation for Text-to-Image Generation with Visual Large Language Models. (arXiv:2305.10843v1 [cs.CV])",
    "abstract": "This paper introduces a novel explainable image quality evaluation approach called X-IQE, which leverages visual large language models (LLMs) to evaluate text-to-image generation methods by generating textual explanations. X-IQE utilizes a hierarchical Chain of Thought (CoT) to enable MiniGPT-4 to produce self-consistent, unbiased texts that are highly correlated with human evaluation. It offers several advantages, including the ability to distinguish between real and generated images, evaluate text-image alignment, and assess image aesthetics without requiring model training or fine-tuning. X-IQE is more cost-effective and efficient compared to human evaluation, while significantly enhancing the transparency and explainability of deep image quality evaluation models. We validate the effectiveness of our method as a benchmark using images generated by prevalent diffusion models. X-IQE demonstrates similar performance to state-of-the-art (SOTA) evaluation methods on COCO Caption, while ",
    "link": "http://arxiv.org/abs/2305.10843",
    "context": "Title: X-IQE: eXplainable Image Quality Evaluation for Text-to-Image Generation with Visual Large Language Models. (arXiv:2305.10843v1 [cs.CV])\nAbstract: This paper introduces a novel explainable image quality evaluation approach called X-IQE, which leverages visual large language models (LLMs) to evaluate text-to-image generation methods by generating textual explanations. X-IQE utilizes a hierarchical Chain of Thought (CoT) to enable MiniGPT-4 to produce self-consistent, unbiased texts that are highly correlated with human evaluation. It offers several advantages, including the ability to distinguish between real and generated images, evaluate text-image alignment, and assess image aesthetics without requiring model training or fine-tuning. X-IQE is more cost-effective and efficient compared to human evaluation, while significantly enhancing the transparency and explainability of deep image quality evaluation models. We validate the effectiveness of our method as a benchmark using images generated by prevalent diffusion models. X-IQE demonstrates similar performance to state-of-the-art (SOTA) evaluation methods on COCO Caption, while ",
    "path": "papers/23/05/2305.10843.json",
    "total_tokens": 963,
    "translated_title": "X-IQE：利用视觉大语言模型对文本到图像生成进行可解释的图像质量评估",
    "translated_abstract": "本文介绍了一种新颖的可解释的图像质量评估方法，称为X-IQE，它利用视觉大语言模型来评估文本到图像生成方法，通过生成文本解释。X-IQE利用分层思维链（CoT）使MiniGPT-4能够产生自洽、无偏的文本，与人类评估高度相关。它具有多种优点，包括能够区分真实图像和生成图像、评估文本-图像对齐和评估图像美学，而不需要模型训练或微调。与人类评估相比，X-IQE更具成本效益和效率，同时显著增强了深度图像质量评估模型的透明度和可解释性。我们使用主流扩散模型生成的图像验证了我们的方法作为基准的有效性。X-IQE在COCO Caption上表现出与最先进评估方法类似的性能，",
    "tldr": "本文提出了一种名为X-IQE的图像质量评估方法，使用视觉大语言模型对文本到图像生成进行评估，并生成文本解释。它具有区分真实和生成图像、评估文本-图像对齐和评估图像美学等优点，显著增强了深度图像质量评估模型的透明度和可解释性。"
}