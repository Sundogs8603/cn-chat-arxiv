{
    "title": "Model-Contrastive Federated Domain Adaptation. (arXiv:2305.10432v1 [cs.LG])",
    "abstract": "Federated domain adaptation (FDA) aims to collaboratively transfer knowledge from source clients (domains) to the related but different target client, without communicating the local data of any client. Moreover, the source clients have different data distributions, leading to extremely challenging in knowledge transfer. Despite the recent progress in FDA, we empirically find that existing methods can not leverage models of heterogeneous domains and thus they fail to achieve excellent performance. In this paper, we propose a model-based method named FDAC, aiming to address {\\bf F}ederated {\\bf D}omain {\\bf A}daptation based on {\\bf C}ontrastive learning and Vision Transformer (ViT). In particular, contrastive learning can leverage the unlabeled data to train excellent models and the ViT architecture performs better than convolutional neural networks (CNNs) in extracting adaptable features. To the best of our knowledge, FDAC is the first attempt to learn transferable representations by ",
    "link": "http://arxiv.org/abs/2305.10432",
    "context": "Title: Model-Contrastive Federated Domain Adaptation. (arXiv:2305.10432v1 [cs.LG])\nAbstract: Federated domain adaptation (FDA) aims to collaboratively transfer knowledge from source clients (domains) to the related but different target client, without communicating the local data of any client. Moreover, the source clients have different data distributions, leading to extremely challenging in knowledge transfer. Despite the recent progress in FDA, we empirically find that existing methods can not leverage models of heterogeneous domains and thus they fail to achieve excellent performance. In this paper, we propose a model-based method named FDAC, aiming to address {\\bf F}ederated {\\bf D}omain {\\bf A}daptation based on {\\bf C}ontrastive learning and Vision Transformer (ViT). In particular, contrastive learning can leverage the unlabeled data to train excellent models and the ViT architecture performs better than convolutional neural networks (CNNs) in extracting adaptable features. To the best of our knowledge, FDAC is the first attempt to learn transferable representations by ",
    "path": "papers/23/05/2305.10432.json",
    "total_tokens": 1004,
    "translated_title": "模型对比联邦领域自适应",
    "translated_abstract": "联邦领域自适应（FDA）旨在将知识从源客户端（领域）合作地转移到相关但不同的目标客户端，而不需要传递任何客户端的本地数据。此外，源客户端具有不同的数据分布，这导致知识传递极具挑战性。尽管FDA取得了最近的进展，但我们经验性地发现，现有方法无法利用异构领域的模型，因此无法实现出色的性能。在本文中，我们提出了一种名为FDAC的基于模型的方法，旨在通过对比学习和Vision Transformer（ViT）解决基于联邦的领域自适应。特别地，对比学习可以利用未标记的数据训练出优秀的模型，而ViT架构在提取适应特征方面比卷积神经网络（CNN）表现更好。据我们所知，FDAC是第一次尝试在联邦设置中通过比较不同模型来学习可转移的表示。在各种基准测试上进行的广泛实验表明，FDAC优于最先进的FDA方法。",
    "tldr": "本文提出了一种名为FDAC的联邦领域自适应方法，通过对比学习和采用Vision Transformer（ViT）框架提取可适应特征，成功实现了在联邦设置中学习可转移的表示。实验表明，FDAC优于最先进的联邦领域自适应方法。",
    "en_tdlr": "This paper proposes a model-based FDAC method for federated domain adaptation, which successfully learns transferable representations in a federated setting by using contrastive learning and the Vision Transformer (ViT) framework to extract adaptable features. Experiments show that FDAC outperforms state-of-the-art FDA approaches."
}