{
    "title": "Interpretable Sentence Representation with Variational Autoencoders and Attention. (arXiv:2305.02810v1 [cs.CL])",
    "abstract": "In this thesis, we develop methods to enhance the interpretability of recent representation learning techniques in natural language processing (NLP) while accounting for the unavailability of annotated data. We choose to leverage Variational Autoencoders (VAEs) due to their efficiency in relating observations to latent generative factors and their effectiveness in data-efficient learning and interpretable representation learning. As a first contribution, we identify and remove unnecessary components in the functioning scheme of semi-supervised VAEs making them faster, smaller and easier to design. Our second and main contribution is to use VAEs and Transformers to build two models with inductive bias to separate information in latent representations into understandable concepts without annotated data. The first model, Attention-Driven VAE (ADVAE), is able to separately represent and control information about syntactic roles in sentences. The second model, QKVAE, uses separate latent va",
    "link": "http://arxiv.org/abs/2305.02810",
    "context": "Title: Interpretable Sentence Representation with Variational Autoencoders and Attention. (arXiv:2305.02810v1 [cs.CL])\nAbstract: In this thesis, we develop methods to enhance the interpretability of recent representation learning techniques in natural language processing (NLP) while accounting for the unavailability of annotated data. We choose to leverage Variational Autoencoders (VAEs) due to their efficiency in relating observations to latent generative factors and their effectiveness in data-efficient learning and interpretable representation learning. As a first contribution, we identify and remove unnecessary components in the functioning scheme of semi-supervised VAEs making them faster, smaller and easier to design. Our second and main contribution is to use VAEs and Transformers to build two models with inductive bias to separate information in latent representations into understandable concepts without annotated data. The first model, Attention-Driven VAE (ADVAE), is able to separately represent and control information about syntactic roles in sentences. The second model, QKVAE, uses separate latent va",
    "path": "papers/23/05/2305.02810.json",
    "total_tokens": 951,
    "translated_title": "用变分自编码器和注意力机制实现可解释的句子表示",
    "translated_abstract": "本论文旨在增强自然语言处理中最近一些表示学习技术的解释性，同时考虑到缺乏注释数据的情况下进行研究的方法。我们选择利用变分自编码器（VAEs），因为它们在将观察结果与隐藏的生成因素联系起来方面很有效，并且在数据效率学习和可解释表示学习方面也很有效。我们首先删除半监督VAEs运行方案中的不必要组件，使得它们更快速、更小、更易于设计。其次，我们使用VAEs和Transformer构建了两个具有归纳偏差的模型，将潜在表示中的信息分离成可理解的概念，而不需要注释数据。我们的实验证明，这些模型提供了直观且可解释的表示形式，对自然语言处理中的下游任务非常有用。",
    "tldr": "本论文提出了使用VAEs和Transformers构建两种具有归纳偏差的模型，用于提高自然语言处理中表示学习技术的解释性和数据效率，能够将潜在表示中的信息分离为可理解的概念。实验结果表明这些模型提供了直观且可解释的表示形式，具有实用性。",
    "en_tdlr": "This paper proposes using VAEs and Transformers to build two models with inductive bias for enhancing the interpretability and efficiency of representation learning techniques in natural language processing, which can separate information in latent representations into understandable concepts. The experimental results demonstrate that the proposed models provide intuitive and interpretable representations with practical utility."
}