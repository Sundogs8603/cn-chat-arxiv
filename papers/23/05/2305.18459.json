{
    "title": "Diffusion Model is an Effective Planner and Data Synthesizer for Multi-Task Reinforcement Learning. (arXiv:2305.18459v1 [cs.LG])",
    "abstract": "Diffusion models have demonstrated highly-expressive generative capabilities in vision and NLP. Recent studies in reinforcement learning (RL) have shown that diffusion models are also powerful in modeling complex policies or trajectories in offline datasets. However, these works have been limited to single-task settings where a generalist agent capable of addressing multi-task predicaments is absent. In this paper, we aim to investigate the effectiveness of a single diffusion model in modeling large-scale multi-task offline data, which can be challenging due to diverse and multimodal data distribution. Specifically, we propose Multi-Task Diffusion Model (\\textsc{MTDiff}), a diffusion-based method that incorporates Transformer backbones and prompt learning for generative planning and data synthesis in multi-task offline settings. \\textsc{MTDiff} leverages vast amounts of knowledge available in multi-task data and performs implicit knowledge sharing among tasks. For generative planning, ",
    "link": "http://arxiv.org/abs/2305.18459",
    "context": "Title: Diffusion Model is an Effective Planner and Data Synthesizer for Multi-Task Reinforcement Learning. (arXiv:2305.18459v1 [cs.LG])\nAbstract: Diffusion models have demonstrated highly-expressive generative capabilities in vision and NLP. Recent studies in reinforcement learning (RL) have shown that diffusion models are also powerful in modeling complex policies or trajectories in offline datasets. However, these works have been limited to single-task settings where a generalist agent capable of addressing multi-task predicaments is absent. In this paper, we aim to investigate the effectiveness of a single diffusion model in modeling large-scale multi-task offline data, which can be challenging due to diverse and multimodal data distribution. Specifically, we propose Multi-Task Diffusion Model (\\textsc{MTDiff}), a diffusion-based method that incorporates Transformer backbones and prompt learning for generative planning and data synthesis in multi-task offline settings. \\textsc{MTDiff} leverages vast amounts of knowledge available in multi-task data and performs implicit knowledge sharing among tasks. For generative planning, ",
    "path": "papers/23/05/2305.18459.json",
    "total_tokens": 1023,
    "translated_title": "扩散模型是多任务强化学习的有效规划器和数据合成器",
    "translated_abstract": "扩散模型在视觉和NLP领域中展现出了高度表现力的生成能力。最近的研究表明，在强化学习领域中，扩散模型也能够有效地建模离线数据集中的复杂策略或轨迹。然而，这些研究仅限于单任务设置，没有考虑多任务的情况。本文旨在研究单一扩散模型在建模用于多个任务策略训练的大规模离线数据时的有效性，具有多样化和多模态的数据分布。具体而言，我们提出了Multi-Task Diffusion Model（MTDiff），这是一种基于扩散的方法，结合Transformer骨干和提示学习，用于多任务离线设置中的生成规划和数据合成。MTDiff利用大量可用于多任务数据中的知识，并在任务之间执行隐式知识共享以进行虚拟规划。",
    "tldr": "本文研究了单一扩散模型在建模多个任务的策略训练的大规模离线数据时的有效性。该方法名为Multi-Task Diffusion Model (MTDiff)，结合了Transformer骨干和提示学习，能够在如此复杂的多任务环境下取得相当不错的性能。",
    "en_tdlr": "This paper investigates the effectiveness of a single diffusion model in modeling large-scale multi-task offline data for policy training. The proposed method, Multi-Task Diffusion Model (MTDiff), combines Transformer backbones and prompt learning, and achieves considerable performance in such a complex multi-task environment by leveraging knowledge available in multi-task data and performing implicit knowledge sharing among tasks."
}