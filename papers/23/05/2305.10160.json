{
    "title": "Stop Uploading Test Data in Plain Text: Practical Strategies for Mitigating Data Contamination by Evaluation Benchmarks. (arXiv:2305.10160v1 [cs.CL])",
    "abstract": "Data contamination has become especially prevalent and challenging with the rise of models pretrained on very large, automatically-crawled corpora. For closed models, the training data becomes a trade secret, and even for open models, it is not trivial to ascertain whether a particular test instance has been compromised. Strategies such as live leaderboards with hidden answers, or using test data which is guaranteed to be unseen, are expensive and become fragile with time. Assuming that all relevant actors value clean test data and will cooperate to mitigate data contamination, what can be done? We propose three strategies that can make a difference: (1) Test data made public should be encrypted with a public key and licensed to disallow derivative distribution; (2) demand training exclusion controls from closed API holders, and protect your test data by refusing to evaluate until demands are met; (3) in case of test data based on internet text, avoid data which appears with its soluti",
    "link": "http://arxiv.org/abs/2305.10160",
    "context": "Title: Stop Uploading Test Data in Plain Text: Practical Strategies for Mitigating Data Contamination by Evaluation Benchmarks. (arXiv:2305.10160v1 [cs.CL])\nAbstract: Data contamination has become especially prevalent and challenging with the rise of models pretrained on very large, automatically-crawled corpora. For closed models, the training data becomes a trade secret, and even for open models, it is not trivial to ascertain whether a particular test instance has been compromised. Strategies such as live leaderboards with hidden answers, or using test data which is guaranteed to be unseen, are expensive and become fragile with time. Assuming that all relevant actors value clean test data and will cooperate to mitigate data contamination, what can be done? We propose three strategies that can make a difference: (1) Test data made public should be encrypted with a public key and licensed to disallow derivative distribution; (2) demand training exclusion controls from closed API holders, and protect your test data by refusing to evaluate until demands are met; (3) in case of test data based on internet text, avoid data which appears with its soluti",
    "path": "papers/23/05/2305.10160.json",
    "total_tokens": 913,
    "translated_title": "不要用明文上传测试数据：减轻数据外泄对于评估基准的持续影响的实用策略",
    "translated_abstract": "随着预训练模型在自动爬网资料库的大规模应用，数据外泄变得常见且部分难以应对。对于那些不会公开训练数据的模型，其数据成为了商业机密，即使在公开模型中，确定特定测试实例是否被泄露也不是一件容易的事情。本文提出三个可行的策略：（1）使用公钥加密发布的测试数据并限制派生发布的许可；（2）要求持有API训练数据的公司采用训练排除控制，并拒绝评估，直到训练排除控制无误为止；（3）如果测试数据来自互联网文本，那么需避免在网络搜索中出现包含正确提取部分的数据。",
    "tldr": "提出了三个适用策略：（1）公钥加密发布测试数据，仅允许特定派生发布；（2）对于API持有方，要求训练排除控制，保护测试数据，不停止评估直到达到要求；（3）如果测试数据来自互联网文本，需避免某些结果的使用。",
    "en_tdlr": "Three strategies proposed to mitigate data contamination: (1) encrypt test data with public key and license it to disallow derivative distribution; (2) demand training exclusion controls from closed API holders and refuse to evaluate until demands are met; (3) avoid using internet text with solution snippets in web searches for test data."
}