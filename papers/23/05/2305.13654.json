{
    "title": "Understanding and Mitigating Spurious Correlations in Text Classification. (arXiv:2305.13654v1 [cs.CL])",
    "abstract": "Recent work has shown that deep learning models are prone to exploit spurious correlations that are present in the training set, yet may not hold true in general. A sentiment classifier may erroneously learn that the token spielberg is always tied to positive movie reviews. Relying on spurious correlations may lead to significant degradation in generalizability and should be avoided. In this paper, we propose a neighborhood analysis framework to explain how exactly language models exploit spurious correlations. Driven by the analysis, we propose a family of regularization methods, NFL (do Not Forget your Language) to prevent the situation. Experiments on two text classification tasks show that NFL brings a significant improvement over standard fine-tuning in terms of robustness without sacrificing in-distribution accuracy.",
    "link": "http://arxiv.org/abs/2305.13654",
    "context": "Title: Understanding and Mitigating Spurious Correlations in Text Classification. (arXiv:2305.13654v1 [cs.CL])\nAbstract: Recent work has shown that deep learning models are prone to exploit spurious correlations that are present in the training set, yet may not hold true in general. A sentiment classifier may erroneously learn that the token spielberg is always tied to positive movie reviews. Relying on spurious correlations may lead to significant degradation in generalizability and should be avoided. In this paper, we propose a neighborhood analysis framework to explain how exactly language models exploit spurious correlations. Driven by the analysis, we propose a family of regularization methods, NFL (do Not Forget your Language) to prevent the situation. Experiments on two text classification tasks show that NFL brings a significant improvement over standard fine-tuning in terms of robustness without sacrificing in-distribution accuracy.",
    "path": "papers/23/05/2305.13654.json",
    "total_tokens": 892,
    "translated_title": "理解和减少文本分类中的伪相关性",
    "translated_abstract": "最近的研究表明，深度学习模型容易利用训练集中存在但通常不成立的伪相关性。例如情感分类器可能会错误地学习到令人愉悦的电影评论总是与“Spielberg”这个词相关联。依赖于伪相关性可能会导致泛化性能显著降低，因此应该避免。本文提出了一种邻域分析框架来解释语言模型如何利用伪相关性。在此基础上，我们提出了一系列正则化方法NFL（不要忘记你的语言），以避免这种情况。在两个文本分类任务上的实验表明，NFL相对于标准的微调算法在鲁棒性方面带来了显著的改进，而没有牺牲在数据内部的准确性。",
    "tldr": "本文研究了深度学习模型容易利用训练集中存在但通常不成立的伪相关性的问题，并提出了一种邻域分析框架以解释语言模型如何利用伪相关性。通过一系列正则化方法NFL（不要忘记你的语言）避免了这种情况，并在实验中证明了其鲁棒性方面的显著改进。",
    "en_tdlr": "This paper investigates the issue of deep learning models exploiting spurious correlations in the training set, and proposes a neighborhood analysis framework to explain how language models do this. It then introduces a family of regularization methods called NFL (do Not Forget your Language) to avoid relying on spurious correlations and shows significant improvement in robustness without sacrificing accuracy in experiments on two text classification tasks."
}