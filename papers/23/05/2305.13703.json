{
    "title": "MemeCap: A Dataset for Captioning and Interpreting Memes. (arXiv:2305.13703v1 [cs.CL])",
    "abstract": "Memes are a widely popular tool for web users to express their thoughts using visual metaphors. Understanding memes requires recognizing and interpreting visual metaphors with respect to the text inside or around the meme, often while employing background knowledge and reasoning abilities. We present the task of meme captioning and release a new dataset, MemeCap. Our dataset contains 6.3K memes along with the title of the post containing the meme, the meme captions, the literal image caption, and the visual metaphors. Despite the recent success of vision and language (VL) models on tasks such as image captioning and visual question answering, our extensive experiments using state-of-the-art VL models show that they still struggle with visual metaphors, and perform substantially worse than humans.",
    "link": "http://arxiv.org/abs/2305.13703",
    "context": "Title: MemeCap: A Dataset for Captioning and Interpreting Memes. (arXiv:2305.13703v1 [cs.CL])\nAbstract: Memes are a widely popular tool for web users to express their thoughts using visual metaphors. Understanding memes requires recognizing and interpreting visual metaphors with respect to the text inside or around the meme, often while employing background knowledge and reasoning abilities. We present the task of meme captioning and release a new dataset, MemeCap. Our dataset contains 6.3K memes along with the title of the post containing the meme, the meme captions, the literal image caption, and the visual metaphors. Despite the recent success of vision and language (VL) models on tasks such as image captioning and visual question answering, our extensive experiments using state-of-the-art VL models show that they still struggle with visual metaphors, and perform substantially worse than humans.",
    "path": "papers/23/05/2305.13703.json",
    "total_tokens": 769,
    "translated_title": "MemeCap：一个用于说明和解释Memes的数据集",
    "translated_abstract": "Memes是网民们使用视觉隐喻表达他们的思想的广泛工具。理解Memes需要识别和解释视觉隐喻，同时考虑Memes内外的文本，并常常使用背景知识和推理能力。我们提出了MemeCaption任务，并发布了一个新的数据集MemeCap。此数据集包含6.3K个Memes，以及包含Memes的帖子的标题、Memes的说明、字面图像说明和视觉隐喻。尽管近年来视觉和语言（VL）模型在图像说明和视觉问答等任务上取得了成功，但我们使用最先进的VL模型进行的广泛实验表明，它们仍然难以应对视觉隐喻，且表现远不如人类。",
    "tldr": "MemeCap是一个新的数据集，用于说明和解释Memes。 然而，即使是最先进的视觉和语言模型也难以应对Memes中的视觉隐喻，表现远远不如人类。",
    "en_tdlr": "MemeCap is a new dataset for captioning and interpreting Memes. However, even state-of-the-art vision and language models struggle with visual metaphors in Memes and perform substantially worse than humans."
}