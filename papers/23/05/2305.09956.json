{
    "title": "The Adversarial Consistency of Surrogate Risks for Binary Classification. (arXiv:2305.09956v1 [cs.LG])",
    "abstract": "We study the consistency of surrogate risks for robust binary classification. It is common to learn robust classifiers by adversarial training, which seeks to minimize the expected $0$-$1$ loss when each example can be maliciously corrupted within a small ball. We give a simple and complete characterization of the set of surrogate loss functions that are \\emph{consistent}, i.e., that can replace the $0$-$1$ loss without affecting the minimizing sequences of the original adversarial risk, for any data distribution. We also prove a quantitative version of adversarial consistency for the $\\rho$-margin loss. Our results reveal that the class of adversarially consistent surrogates is substantially smaller than in the standard setting, where many common surrogates are known to be consistent.",
    "link": "http://arxiv.org/abs/2305.09956",
    "context": "Title: The Adversarial Consistency of Surrogate Risks for Binary Classification. (arXiv:2305.09956v1 [cs.LG])\nAbstract: We study the consistency of surrogate risks for robust binary classification. It is common to learn robust classifiers by adversarial training, which seeks to minimize the expected $0$-$1$ loss when each example can be maliciously corrupted within a small ball. We give a simple and complete characterization of the set of surrogate loss functions that are \\emph{consistent}, i.e., that can replace the $0$-$1$ loss without affecting the minimizing sequences of the original adversarial risk, for any data distribution. We also prove a quantitative version of adversarial consistency for the $\\rho$-margin loss. Our results reveal that the class of adversarially consistent surrogates is substantially smaller than in the standard setting, where many common surrogates are known to be consistent.",
    "path": "papers/23/05/2305.09956.json",
    "total_tokens": 817,
    "translated_title": "二分类中代理风险的对抗一致性",
    "translated_abstract": "我们研究用于鲁棒二分类的代理风险的一致性。常见的做法是通过对抗性训练来学习鲁棒分类器，该方法试图在每个示例可以在小球内被恶意损坏的情况下最小化期望的$0$-$1$损失。我们给出了一种简单而完整的代理损失函数集的特征化，这些集是“一致”的，即可以替换$0$-$1$损失而不影响原始对抗风险的最小化序列的任何数据分布。我们还证明了用于$\\rho$-margin损失的对抗一致性的量化版本。我们的结果显示，与标准设置相比，敌对一致代理的类明显较小，在标准设置中，许多常见的代理都被认为是一致的。",
    "tldr": "本文研究了二分类中代理风险的对抗一致性，并给出了代理损失函数集合的特征化，结果表明敌对一致代理的类与标准设置相比小得多。",
    "en_tdlr": "This paper studies the adversarial consistency of surrogate risks for robust binary classification and characterizes the set of consistent surrogate loss functions, revealing that the class of adversarially consistent surrogates is much smaller than in the standard setting."
}