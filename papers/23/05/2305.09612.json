{
    "title": "Large Language Models are Built-in Autoregressive Search Engines. (arXiv:2305.09612v1 [cs.CL])",
    "abstract": "Document retrieval is a key stage of standard Web search engines. Existing dual-encoder dense retrievers obtain representations for questions and documents independently, allowing for only shallow interactions between them. To overcome this limitation, recent autoregressive search engines replace the dual-encoder architecture by directly generating identifiers for relevant documents in the candidate pool. However, the training cost of such autoregressive search engines rises sharply as the number of candidate documents increases. In this paper, we find that large language models (LLMs) can follow human instructions to directly generate URLs for document retrieval.  Surprisingly, when providing a few {Query-URL} pairs as in-context demonstrations, LLMs can generate Web URLs where nearly 90\\% of the corresponding documents contain correct answers to open-domain questions. In this way, LLMs can be thought of as built-in search engines, since they have not been explicitly trained to map qu",
    "link": "http://arxiv.org/abs/2305.09612",
    "context": "Title: Large Language Models are Built-in Autoregressive Search Engines. (arXiv:2305.09612v1 [cs.CL])\nAbstract: Document retrieval is a key stage of standard Web search engines. Existing dual-encoder dense retrievers obtain representations for questions and documents independently, allowing for only shallow interactions between them. To overcome this limitation, recent autoregressive search engines replace the dual-encoder architecture by directly generating identifiers for relevant documents in the candidate pool. However, the training cost of such autoregressive search engines rises sharply as the number of candidate documents increases. In this paper, we find that large language models (LLMs) can follow human instructions to directly generate URLs for document retrieval.  Surprisingly, when providing a few {Query-URL} pairs as in-context demonstrations, LLMs can generate Web URLs where nearly 90\\% of the corresponding documents contain correct answers to open-domain questions. In this way, LLMs can be thought of as built-in search engines, since they have not been explicitly trained to map qu",
    "path": "papers/23/05/2305.09612.json",
    "total_tokens": 864,
    "translated_title": "大型语言模型是内置的自回归搜索引擎",
    "translated_abstract": "文档检索是标准网络搜索引擎的关键阶段。现有的双编码器密集检索器独立地获取问题和文档的表示，只允许它们之间的浅层交互。为了克服这个限制，最近的自回归搜索引擎通过直接生成候选池中相关文档的标识符来替换双编码器架构。然而，这种自回归搜索引擎的训练成本随着候选文档数量的增加而急剧上升。在本文中，我们发现大型语言模型（LLM）可以遵循人类指示直接生成文档检索的URL。令人惊讶的是，当提供一些{Query-URL}对作为上下文演示时，LLMs可以生成Web URL，其中近90％的相应文档包含开放域问题的正确答案。这样，LLMs可以被认为是内置搜索引擎，因为它们没有明确训练以映射问题和文档之间的相关性。",
    "tldr": "本篇论文指出大型语言模型可以作为内置搜索引擎，通过提供一些上下文演示直接生成Web URLs，在文档检索中表现出色。",
    "en_tdlr": "This paper shows that large language models can be used as built-in search engines, performing well in document retrieval by directly generating Web URLs through providing some in-context demonstrations."
}