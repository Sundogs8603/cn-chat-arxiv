{
    "title": "Online learning of long range dependencies. (arXiv:2305.15947v1 [cs.LG])",
    "abstract": "Online learning holds the promise of enabling efficient long-term credit assignment in recurrent neural networks. However, current algorithms fall short of offline backpropagation by either not being scalable or failing to learn long-range dependencies. Here we present a high-performance online learning algorithm that merely doubles the memory and computational requirements of a single inference pass. We achieve this by leveraging independent recurrent modules in multi-layer networks, an architectural motif that has recently been shown to be particularly powerful. Experiments on synthetic memory problems and on the challenging long-range arena benchmark suite reveal that our algorithm performs competitively, establishing a new standard for what can be achieved through online learning. This ability to learn long-range dependencies offers a new perspective on learning in the brain and opens a promising avenue in neuromorphic computing.",
    "link": "http://arxiv.org/abs/2305.15947",
    "context": "Title: Online learning of long range dependencies. (arXiv:2305.15947v1 [cs.LG])\nAbstract: Online learning holds the promise of enabling efficient long-term credit assignment in recurrent neural networks. However, current algorithms fall short of offline backpropagation by either not being scalable or failing to learn long-range dependencies. Here we present a high-performance online learning algorithm that merely doubles the memory and computational requirements of a single inference pass. We achieve this by leveraging independent recurrent modules in multi-layer networks, an architectural motif that has recently been shown to be particularly powerful. Experiments on synthetic memory problems and on the challenging long-range arena benchmark suite reveal that our algorithm performs competitively, establishing a new standard for what can be achieved through online learning. This ability to learn long-range dependencies offers a new perspective on learning in the brain and opens a promising avenue in neuromorphic computing.",
    "path": "papers/23/05/2305.15947.json",
    "total_tokens": 799,
    "translated_title": "长依赖的在线学习",
    "translated_abstract": "在线学习有望在循环神经网络中实现长期信用分配，而当前算法要么不具备可扩展性，要么无法学习长程依赖关系。本文提出了一种高性能的在线学习算法，仅将单次推断所需的内存和计算资源翻倍。我们利用多层网络中的独立循环模块取得了这个成果，这种结构已经被证明非常有效。针对合成记忆问题和具有挑战性的长程竞技场基准套件的实验表明，我们的算法具有很强的竞争力，树立了在线学习的新标准。这种学习长程依赖的能力为了解大脑学习提供了新的视角，并在神经形态计算中开辟了一个有前途的发展方向。",
    "tldr": "本文提出了一种高性能的在线学习算法，通过利用多层网络中的独立循环模块学习长程依赖，从而提高竞争力，为神经形态计算提供了新的发展方向。",
    "en_tdlr": "This paper proposes a high-performance online learning algorithm that can learn long-range dependencies by leveraging independent recurrent modules in multi-layer networks, establishing a new standard for online learning and promising in neuromorphic computing."
}