{
    "title": "Scalable and Safe Remediation of Defective Actions in Self-Learning Conversational Systems. (arXiv:2305.10528v1 [cs.AI])",
    "abstract": "Off-Policy reinforcement learning has been a driving force for the state-of-the-art conversational AIs leading to more natural humanagent interactions and improving the user satisfaction for goal-oriented agents. However, in large-scale commercial settings, it is often challenging to balance between policy improvements and experience continuity on the broad spectrum of applications handled by such system. In the literature, off-policy evaluation and guard-railing on aggregate statistics has been commonly used to address this problem. In this paper, we propose a method for curating and leveraging high-precision samples sourced from historical regression incident reports to validate, safe-guard, and improve policies prior to the online deployment. We conducted extensive experiments using data from a real-world conversational system and actual regression incidents. The proposed method is currently deployed in our production system to protect customers against broken experiences and enable",
    "link": "http://arxiv.org/abs/2305.10528",
    "context": "Title: Scalable and Safe Remediation of Defective Actions in Self-Learning Conversational Systems. (arXiv:2305.10528v1 [cs.AI])\nAbstract: Off-Policy reinforcement learning has been a driving force for the state-of-the-art conversational AIs leading to more natural humanagent interactions and improving the user satisfaction for goal-oriented agents. However, in large-scale commercial settings, it is often challenging to balance between policy improvements and experience continuity on the broad spectrum of applications handled by such system. In the literature, off-policy evaluation and guard-railing on aggregate statistics has been commonly used to address this problem. In this paper, we propose a method for curating and leveraging high-precision samples sourced from historical regression incident reports to validate, safe-guard, and improve policies prior to the online deployment. We conducted extensive experiments using data from a real-world conversational system and actual regression incidents. The proposed method is currently deployed in our production system to protect customers against broken experiences and enable",
    "path": "papers/23/05/2305.10528.json",
    "total_tokens": 778,
    "translated_title": "自学习对话系统中缺陷行为的可扩展和安全修复",
    "translated_abstract": "强化学习已成为最新自然语言对话人工智能的驱动力，改善了目标为导向的代理人与人之间更自然的互动，提高了用户的满意度，但在大型商业环境中，平衡政策改进和经验连贯性经常具有挑战性。本文提出了一种方法，即使用历史回归事件报告中的高精度样本对政策进行验证、安全保护和改进，以便在在线部署前进行修正。作者对真实的对话系统和实际的回归事件数据进行了大量实验，并将所提出的方法应用于他们的生产系统中。",
    "tldr": "本文提出了一种在自学习对话系统中利用历史回归事件报告来验证、保护和改进政策的方法，以解决在大规模商业环境中的经验连贯性和政策改进之间的平衡问题。"
}