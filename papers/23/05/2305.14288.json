{
    "title": "LLM-powered Data Augmentation for Enhanced Cross-lingual Performance. (arXiv:2305.14288v2 [cs.CL] UPDATED)",
    "abstract": "This paper explores the potential of leveraging Large Language Models (LLMs) for data augmentation in multilingual commonsense reasoning datasets where the available training data is extremely limited. To achieve this, we utilise several LLMs, namely Dolly-v2, StableVicuna, ChatGPT, and GPT-4, to augment three datasets: XCOPA, XWinograd, and XStoryCloze. Subsequently, we evaluate the effectiveness of fine-tuning smaller multilingual models, mBERT and XLMR, using the synthesised data. We compare the performance of training with data generated in English and target languages, as well as translated English-generated data, revealing the overall advantages of incorporating data generated by LLMs, e.g. a notable 13.4 accuracy score improvement for the best case. Furthermore, we conduct a human evaluation by asking native speakers to assess the naturalness and logical coherence of the generated examples across different languages. The results of the evaluation indicate that LLMs such as ChatG",
    "link": "http://arxiv.org/abs/2305.14288",
    "context": "Title: LLM-powered Data Augmentation for Enhanced Cross-lingual Performance. (arXiv:2305.14288v2 [cs.CL] UPDATED)\nAbstract: This paper explores the potential of leveraging Large Language Models (LLMs) for data augmentation in multilingual commonsense reasoning datasets where the available training data is extremely limited. To achieve this, we utilise several LLMs, namely Dolly-v2, StableVicuna, ChatGPT, and GPT-4, to augment three datasets: XCOPA, XWinograd, and XStoryCloze. Subsequently, we evaluate the effectiveness of fine-tuning smaller multilingual models, mBERT and XLMR, using the synthesised data. We compare the performance of training with data generated in English and target languages, as well as translated English-generated data, revealing the overall advantages of incorporating data generated by LLMs, e.g. a notable 13.4 accuracy score improvement for the best case. Furthermore, we conduct a human evaluation by asking native speakers to assess the naturalness and logical coherence of the generated examples across different languages. The results of the evaluation indicate that LLMs such as ChatG",
    "path": "papers/23/05/2305.14288.json",
    "total_tokens": 952,
    "translated_title": "基于LLM的数据增强提升跨语言性能",
    "translated_abstract": "本文研究了利用大型语言模型（LLMs）对跨语言常识推理数据集进行数据增强的潜力，其中可用的训练数据非常有限。为了实现这一目标，我们利用了几个LLMs，包括Dolly-v2，StableVicuna，ChatGPT和GPT-4，来增强XCOPA，XWinograd和XStoryCloze三个数据集。随后，我们使用合成数据评估了小型多语言模型mBERT和XLMR的微调效果。我们比较了以英语和目标语言生成的数据进行训练的性能，以及翻译成英语的生成数据，揭示了利用LLMs生成数据的总体优势，例如在最佳情况下显著提高了13.4个准确率分数。此外，我们进行了人工评估，询问母语者评估不同语言之间生成的示例的自然性和逻辑连贯性。评估结果表明，像ChatG这样的LLMs可以产生较自然和逻辑连贯的示例。",
    "tldr": "本文研究了利用LLMs进行数据增强以提升跨语言常识推理数据集性能的潜力，并通过评估展示了利用LLMs生成数据的总体优势，同时进行了人工评估，证明了生成的示例具有较高的自然性和逻辑连贯性。"
}