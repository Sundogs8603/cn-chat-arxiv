{
    "title": "Symbolic Regression on FPGAs for Fast Machine Learning Inference. (arXiv:2305.04099v1 [cs.LG])",
    "abstract": "The high-energy physics community is investigating the feasibility of deploying machine-learning-based solutions on Field-Programmable Gate Arrays (FPGAs) to improve physics sensitivity while meeting data processing latency limitations. In this contribution, we introduce a novel end-to-end procedure that utilizes a machine learning technique called symbolic regression (SR). It searches equation space to discover algebraic relations approximating a dataset. We use PySR (software for uncovering these expressions based on evolutionary algorithm) and extend the functionality of hls4ml (a package for machine learning inference in FPGAs) to support PySR-generated expressions for resource-constrained production environments. Deep learning models often optimise the top metric by pinning the network size because vast hyperparameter space prevents extensive neural architecture search. Conversely, SR selects a set of models on the Pareto front, which allows for optimising the performance-resource",
    "link": "http://arxiv.org/abs/2305.04099",
    "context": "Title: Symbolic Regression on FPGAs for Fast Machine Learning Inference. (arXiv:2305.04099v1 [cs.LG])\nAbstract: The high-energy physics community is investigating the feasibility of deploying machine-learning-based solutions on Field-Programmable Gate Arrays (FPGAs) to improve physics sensitivity while meeting data processing latency limitations. In this contribution, we introduce a novel end-to-end procedure that utilizes a machine learning technique called symbolic regression (SR). It searches equation space to discover algebraic relations approximating a dataset. We use PySR (software for uncovering these expressions based on evolutionary algorithm) and extend the functionality of hls4ml (a package for machine learning inference in FPGAs) to support PySR-generated expressions for resource-constrained production environments. Deep learning models often optimise the top metric by pinning the network size because vast hyperparameter space prevents extensive neural architecture search. Conversely, SR selects a set of models on the Pareto front, which allows for optimising the performance-resource",
    "path": "papers/23/05/2305.04099.json",
    "total_tokens": 841,
    "translated_title": "FPGAs 上的符号回归用于快速机器学习推断",
    "translated_abstract": "高能物理界正在研究在可编程门阵列（FPGAs）上部署基于机器学习的解决方案的可行性，以改善物理灵敏度并满足数据处理时延限制。本文引入了一种利用符号回归（SR）机器学习技术的全新端到端流程。它在方程空间中搜索近似表示数据集的代数关系。我们使用 PySR（基于进化算法发现这些表达式的软件）并扩展了 hls4ml 的功能（一种用于支持FPGAs中的机器学习推断的软件包），以支持在资源受限制的生产环境中使用 PySR 生成的表达式。深度学习模型通常通过固定网络大小来优化顶级指标，因为巨大的超参数空间会防止广泛的神经结构搜索。相反，SR 选择位于帕累托前沿的一组模型，这允许优化性能-资源的平衡。",
    "tldr": "本论文提出了一种全新的利用符号回归的全流程，可在FPGA上进行机器学习推断，具有优化性能-资源平衡的特点。",
    "en_tdlr": "This paper presents a novel end-to-end approach that utilizes symbolic regression for machine learning inference on FPGAs, optimizing the performance-resource balance."
}