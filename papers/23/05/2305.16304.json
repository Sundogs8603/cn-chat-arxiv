{
    "title": "Candidate Set Re-ranking for Composed Image Retrieval with Dual Multi-modal Encoder. (arXiv:2305.16304v2 [cs.CV] UPDATED)",
    "abstract": "Composed image retrieval aims to find an image that best matches a given multi-modal user query consisting of a reference image and text pair. Existing methods commonly pre-compute image embeddings over the entire corpus and compare these to a reference image embedding modified by the query text at test time. Such a pipeline is very efficient at test time since fast vector distances can be used to evaluate candidates, but modifying the reference image embedding guided only by a short textual description can be difficult, especially independent of potential candidates. An alternative approach is to allow interactions between the query and every possible candidate, i.e., reference-text-candidate triplets, and pick the best from the entire set. Though this approach is more discriminative, for large-scale datasets the computational cost is prohibitive since pre-computation of candidate embeddings is no longer possible. We propose to combine the merits of both schemes using a two-stage mode",
    "link": "http://arxiv.org/abs/2305.16304",
    "context": "Title: Candidate Set Re-ranking for Composed Image Retrieval with Dual Multi-modal Encoder. (arXiv:2305.16304v2 [cs.CV] UPDATED)\nAbstract: Composed image retrieval aims to find an image that best matches a given multi-modal user query consisting of a reference image and text pair. Existing methods commonly pre-compute image embeddings over the entire corpus and compare these to a reference image embedding modified by the query text at test time. Such a pipeline is very efficient at test time since fast vector distances can be used to evaluate candidates, but modifying the reference image embedding guided only by a short textual description can be difficult, especially independent of potential candidates. An alternative approach is to allow interactions between the query and every possible candidate, i.e., reference-text-candidate triplets, and pick the best from the entire set. Though this approach is more discriminative, for large-scale datasets the computational cost is prohibitive since pre-computation of candidate embeddings is no longer possible. We propose to combine the merits of both schemes using a two-stage mode",
    "path": "papers/23/05/2305.16304.json",
    "total_tokens": 838,
    "translated_title": "具有双多模态编码器的组合图像检索候选集重排序",
    "translated_abstract": "组合图像检索旨在找到最匹配给定多模态用户查询(包括参考图像和文本对)的图像。现有方法通常预先计算整个语料库的图像嵌入，并在测试时将这些嵌入与经过查询文本修改的参考图像嵌入进行比较。然而，仅通过短文本描述引导修改参考图像嵌入可能很困难，特别是独立于潜在的候选项。一种替代方法是允许查询和每个可能的候选项之间的交互，即参考文本-候选项三元组，并从整个集合中选择最佳匹配。虽然这种方法更具有判别性，但对于大规模数据集，由于不能预先计算候选嵌入，因此计算成本是禁止性的。我们提出使用两阶段模式结合这两个方案的优点",
    "tldr": "本论文提出了一种使用两阶段模式结合预先计算图像嵌入和参考文本-候选项三元组交互选择的方式进行组合图像检索候选集重排序的方法。",
    "en_tdlr": "This paper proposes a method for re-ranking candidate sets in composed image retrieval using a two-stage mode that combines pre-computed image embeddings and interactions between reference-text-candidate triplets."
}