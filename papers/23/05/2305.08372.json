{
    "title": "Hierarchical Aligned Multimodal Learning for NER on Tweet Posts. (arXiv:2305.08372v2 [cs.CL] UPDATED)",
    "abstract": "Mining structured knowledge from tweets using named entity recognition (NER) can be beneficial for many down stream applications such as recommendation and intention understanding. With tweet posts tending to be multimodal, multimodal named entity recognition (MNER) has attracted more attention. In this paper, we propose a novel approach, which can dynamically align the image and text sequence and achieve the multi-level cross-modal learning to augment textual word representation for MNER improvement. To be specific, our framework can be split into three main stages: the first stage focuses on intra-modality representation learning to derive the implicit global and local knowledge of each modality, the second evaluates the relevance between the text and its accompanying image and integrates different grained visual information based on the relevance, the third enforces semantic refinement via iterative cross-modal interactions and co-attention. We conduct experiments on two open datase",
    "link": "http://arxiv.org/abs/2305.08372",
    "context": "Title: Hierarchical Aligned Multimodal Learning for NER on Tweet Posts. (arXiv:2305.08372v2 [cs.CL] UPDATED)\nAbstract: Mining structured knowledge from tweets using named entity recognition (NER) can be beneficial for many down stream applications such as recommendation and intention understanding. With tweet posts tending to be multimodal, multimodal named entity recognition (MNER) has attracted more attention. In this paper, we propose a novel approach, which can dynamically align the image and text sequence and achieve the multi-level cross-modal learning to augment textual word representation for MNER improvement. To be specific, our framework can be split into three main stages: the first stage focuses on intra-modality representation learning to derive the implicit global and local knowledge of each modality, the second evaluates the relevance between the text and its accompanying image and integrates different grained visual information based on the relevance, the third enforces semantic refinement via iterative cross-modal interactions and co-attention. We conduct experiments on two open datase",
    "path": "papers/23/05/2305.08372.json",
    "total_tokens": 879,
    "translated_title": "Tweet帖子上的层次对齐多模态学习用于NER",
    "translated_abstract": "使用命名实体识别（NER）从推文中挖掘结构化知识可以对推荐和意图理解等许多下游应用有益。由于推文倾向于是多模态的，多模态命名实体识别（MNER）引起了更多的关注。本文提出了一种新颖的方法，可以动态地对齐图像和文本序列，并实现多级跨模态学习，以增强MNER的文本词表示。具体而言，我们的框架可以分为三个主要阶段：第一阶段专注于内部模态表示学习，以推导出每个模态的隐含全局和局部知识。第二阶段评估文本与其伴随图像之间的相关性，并根据相关性整合不同粒度的视觉信息。第三阶段通过迭代跨模态交互和共同关注强化语义细化。我们在两个公开数据集上进行了实验证明了我们方法的有效性。",
    "tldr": "本文提出了一种新颖的方法用于多模态命名实体识别（MNER）的改进，该方法通过动态对齐图像和文本序列，并实现多级跨模态学习来增强文本词表示。实验证明了该方法的有效性。",
    "en_tdlr": "This paper proposes a novel approach for improving multimodal named entity recognition (MNER) by dynamically aligning image and text sequences and achieving multi-level cross-modal learning to enhance textual word representation. Experimental results demonstrate the effectiveness of this approach."
}