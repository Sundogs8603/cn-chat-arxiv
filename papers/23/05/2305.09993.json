{
    "title": "Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling. (arXiv:2305.09993v1 [cs.LG])",
    "abstract": "We introduce Reprompting, an iterative sampling algorithm that searches for the Chain-of-Thought (CoT) recipes for a given task without human intervention. Through Gibbs sampling, we infer CoT recipes that work consistently well for a set of training samples. Our method iteratively samples new recipes using previously sampled solutions as parent prompts to solve other training problems. On five Big-Bench Hard tasks that require multi-step reasoning, Reprompting achieves consistently better performance than the zero-shot, few-shot, and human-written CoT baselines. Reprompting can also facilitate transfer of knowledge from a stronger model to a weaker model leading to substantially improved performance of the weaker model. Overall, Reprompting brings up to +17 point improvements over the previous state-of-the-art method that uses human-written CoT prompts.",
    "link": "http://arxiv.org/abs/2305.09993",
    "context": "Title: Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling. (arXiv:2305.09993v1 [cs.LG])\nAbstract: We introduce Reprompting, an iterative sampling algorithm that searches for the Chain-of-Thought (CoT) recipes for a given task without human intervention. Through Gibbs sampling, we infer CoT recipes that work consistently well for a set of training samples. Our method iteratively samples new recipes using previously sampled solutions as parent prompts to solve other training problems. On five Big-Bench Hard tasks that require multi-step reasoning, Reprompting achieves consistently better performance than the zero-shot, few-shot, and human-written CoT baselines. Reprompting can also facilitate transfer of knowledge from a stronger model to a weaker model leading to substantially improved performance of the weaker model. Overall, Reprompting brings up to +17 point improvements over the previous state-of-the-art method that uses human-written CoT prompts.",
    "path": "papers/23/05/2305.09993.json",
    "total_tokens": 828,
    "translated_title": "Reprompting: 通过吉布斯采样自动推断思维链的提示",
    "translated_abstract": "我们引入了Reprompting，这是一种迭代采样算法，可以在没有人类干预的情况下搜索给定任务的思维链配方。通过吉布斯采样，我们推断适用于一组训练样例的思维链配方。我们的方法使用先前采样的解作为父提示，迭代地采样新的配方来解决其他训练问题。在需要多步推理的五个Big-Bench Hard任务中，Reprompting的表现始终优于零样本、少样本和人类编写的思维链基线。Reprompting还可以促进知识从一个更强的模型到一个较弱的模型的转移，从而大大提高了较弱模型的性能。总体而言，Reprompting相对于使用人类编写的思维链提示的先前最先进方法，带来了高达+17个性能改进。",
    "tldr": "Reprompting是一种无需人类干预的算法，通过迭代采样新配方解决多步推理任务，比人类编写的思维链提示表现更好，还可以提高较弱模型的性能。",
    "en_tdlr": "Reprompting is an automated algorithm that utilizes iterative sampling to infer Chain-of-Thought (CoT) recipes for multi-step reasoning tasks without human intervention, leading to better performance than human-written CoT prompts and improved performance of weaker models."
}