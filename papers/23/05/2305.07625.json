{
    "title": "Meta Omnium: A Benchmark for General-Purpose Learning-to-Learn. (arXiv:2305.07625v1 [cs.CV])",
    "abstract": "Meta-learning and other approaches to few-shot learning are widely studied for image recognition, and are increasingly applied to other vision tasks such as pose estimation and dense prediction. This naturally raises the question of whether there is any few-shot meta-learning algorithm capable of generalizing across these diverse task types? To support the community in answering this question, we introduce Meta Omnium, a dataset-of-datasets spanning multiple vision tasks including recognition, keypoint localization, semantic segmentation and regression. We experiment with popular few-shot meta-learning baselines and analyze their ability to generalize across tasks and to transfer knowledge between them. Meta Omnium enables meta-learning researchers to evaluate model generalization to a much wider array of tasks than previously possible, and provides a single framework for evaluating meta-learners across a wide suite of vision applications in a consistent manner.",
    "link": "http://arxiv.org/abs/2305.07625",
    "context": "Title: Meta Omnium: A Benchmark for General-Purpose Learning-to-Learn. (arXiv:2305.07625v1 [cs.CV])\nAbstract: Meta-learning and other approaches to few-shot learning are widely studied for image recognition, and are increasingly applied to other vision tasks such as pose estimation and dense prediction. This naturally raises the question of whether there is any few-shot meta-learning algorithm capable of generalizing across these diverse task types? To support the community in answering this question, we introduce Meta Omnium, a dataset-of-datasets spanning multiple vision tasks including recognition, keypoint localization, semantic segmentation and regression. We experiment with popular few-shot meta-learning baselines and analyze their ability to generalize across tasks and to transfer knowledge between them. Meta Omnium enables meta-learning researchers to evaluate model generalization to a much wider array of tasks than previously possible, and provides a single framework for evaluating meta-learners across a wide suite of vision applications in a consistent manner.",
    "path": "papers/23/05/2305.07625.json",
    "total_tokens": 851,
    "translated_title": "Meta Omnium: 一项通用学习-学习基准测试",
    "translated_abstract": "元学习以及其他少样本学习方法已广泛应用于图像识别，同时也越来越应用于其他视觉任务，如姿态估计和密集预测。这自然引出了一个问题：是否存在一种少样本元学习算法，能够泛化到这些多样化的任务类型之间？为了帮助学术界回答这个问题，我们引入了Meta Omnium这个数据集，它涵盖了多个视觉任务，包括识别、关键点定位、语义分割和回归。我们试验了受欢迎的少样本元学习基线，并分析了它们泛化到不同任务类型的能力以及在它们之间传递知识的能力。Meta Omnium使得学术界能够评估模型对于多项任务的泛化能力，这比以前更加广泛，同时它提供了一个在不同视觉应用中以一致的方式评估元学习者的框架。",
    "tldr": "Meta Omnium提供了一个数据集，包含多个视觉任务，使得学术界可以评估模型对于多项任务的泛化能力。它同时提供了一个一致的框架，来评估元学习者。",
    "en_tdlr": "Meta Omnium is a benchmark dataset that enables researchers to evaluate the generalization ability of models across a wide array of vision tasks and provides a consistent framework for evaluating meta-learners."
}