{
    "title": "ZARA: Improving Few-Shot Self-Rationalization for Small Language Models. (arXiv:2305.07355v1 [cs.CL])",
    "abstract": "Language models (LMs) that jointly generate end-task answers as well as free-text rationales are known as self-rationalization models. Recent works demonstrate great performance gain for self-rationalization by few-shot prompting LMs with rationale-augmented exemplars. However, the ability to benefit from explanations only emerges with large-scale LMs, which have poor accessibility. In this work, we explore the less-studied setting of leveraging explanations for small LMs to improve few-shot self-rationalization. We first revisit the relationship between rationales and answers. Inspired by the implicit mental process of how human beings assess explanations, we present a novel approach, Zero-shot Augmentation of Rationale-Answer pairs (ZARA), to automatically construct pseudo-parallel data for self-training by reducing the problem of plausibility judgement to natural language inference. Experimental results show ZARA achieves SOTA performance on the FEB benchmark, for both the task accu",
    "link": "http://arxiv.org/abs/2305.07355",
    "context": "Title: ZARA: Improving Few-Shot Self-Rationalization for Small Language Models. (arXiv:2305.07355v1 [cs.CL])\nAbstract: Language models (LMs) that jointly generate end-task answers as well as free-text rationales are known as self-rationalization models. Recent works demonstrate great performance gain for self-rationalization by few-shot prompting LMs with rationale-augmented exemplars. However, the ability to benefit from explanations only emerges with large-scale LMs, which have poor accessibility. In this work, we explore the less-studied setting of leveraging explanations for small LMs to improve few-shot self-rationalization. We first revisit the relationship between rationales and answers. Inspired by the implicit mental process of how human beings assess explanations, we present a novel approach, Zero-shot Augmentation of Rationale-Answer pairs (ZARA), to automatically construct pseudo-parallel data for self-training by reducing the problem of plausibility judgement to natural language inference. Experimental results show ZARA achieves SOTA performance on the FEB benchmark, for both the task accu",
    "path": "papers/23/05/2305.07355.json",
    "total_tokens": 944,
    "translated_title": "ZARA：改进小型语言模型的少样本自理性",
    "translated_abstract": "同时生成终端任务答案和自由文本解释的语言模型被称为自我解释模型。最近的研究通过使用有理据的例子来提示语言模型，展现了少样本自我解释性能显著提高的成果。然而，只有大规模语言模型才能受益于解释，而这些模型很难被获得。本文研究利用解释来提高少样本自我解释对小型语言模型的影响。我们首先重新探讨了解释和答案之间的关系。受到人类如何评估解释的隐含思考过程的启发，我们提出了一种新的方法ZARA，即理性答案对的零样本增强，通过将合理性判断问题转化为自然语言推理来自动构建伪平行数据进行自我训练。实验结果表明，在FEB基准测试中，ZARA在任务准确性和解释质量上都取得了SOTA的表现。",
    "tldr": "本文提出了一种名为ZARA的方法，其可以通过将合理性判断问题转化为自然语言推理来自动构建伪平行数据进行自我训练，从而提高小型语言模型的少样本自我解释性能，实验结果表明ZARA在任务准确性和解释质量上都表现出SOTA水平。",
    "en_tdlr": "This paper proposes a method called ZARA which improves few-shot self-rationalization for small language models by automatically constructing pseudo-parallel data for self-training through reducing the problem of plausibility judgement to natural language inference. Experimental results show that ZARA achieves state-of-the-art performance in task accuracy and explanation quality on the FEB benchmark."
}