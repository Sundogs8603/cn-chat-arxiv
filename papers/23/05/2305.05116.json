{
    "title": "Communication-Robust Multi-Agent Learning by Adaptable Auxiliary Multi-Agent Adversary Generation. (arXiv:2305.05116v1 [cs.LG])",
    "abstract": "Communication can promote coordination in cooperative Multi-Agent Reinforcement Learning (MARL). Nowadays, existing works mainly focus on improving the communication efficiency of agents, neglecting that real-world communication is much more challenging as there may exist noise or potential attackers. Thus the robustness of the communication-based policies becomes an emergent and severe issue that needs more exploration. In this paper, we posit that the ego system trained with auxiliary adversaries may handle this limitation and propose an adaptable method of Multi-Agent Auxiliary Adversaries Generation for robust Communication, dubbed MA3C, to obtain a robust communication-based policy. In specific, we introduce a novel message-attacking approach that models the learning of the auxiliary attacker as a cooperative problem under a shared goal to minimize the coordination ability of the ego system, with which every information channel may suffer from distinct message attacks. Furthermore",
    "link": "http://arxiv.org/abs/2305.05116",
    "context": "Title: Communication-Robust Multi-Agent Learning by Adaptable Auxiliary Multi-Agent Adversary Generation. (arXiv:2305.05116v1 [cs.LG])\nAbstract: Communication can promote coordination in cooperative Multi-Agent Reinforcement Learning (MARL). Nowadays, existing works mainly focus on improving the communication efficiency of agents, neglecting that real-world communication is much more challenging as there may exist noise or potential attackers. Thus the robustness of the communication-based policies becomes an emergent and severe issue that needs more exploration. In this paper, we posit that the ego system trained with auxiliary adversaries may handle this limitation and propose an adaptable method of Multi-Agent Auxiliary Adversaries Generation for robust Communication, dubbed MA3C, to obtain a robust communication-based policy. In specific, we introduce a novel message-attacking approach that models the learning of the auxiliary attacker as a cooperative problem under a shared goal to minimize the coordination ability of the ego system, with which every information channel may suffer from distinct message attacks. Furthermore",
    "path": "papers/23/05/2305.05116.json",
    "total_tokens": 1072,
    "translated_title": "通过可调节的辅助多代理对抗生成实现通信鲁棒的多代理学习",
    "translated_abstract": "在合作多代理强化学习环境下，通信可以促进代理的协作，然而现有研究主要集中在提高代理的通信效率，忽略了真实通信中的噪声或潜在攻击者可能导致的困难。因此，通信策略的稳健性成为一个急需探究的问题。本文提出使用辅助对抗方法训练的自我系统可以应对这种局限，并提出了一种适应性多代理辅助对抗生成的方法，命名为MA3C，以获得稳健的通信策略。具体而言，我们引入了一种新颖的信息攻击方法，将辅助对手的学习建模为一个协作问题，旨在通过一个共同的目标最小化自我系统的协同能力，从而使每个信息通道都可能受到不同的信息攻击。此外，我们将适应性MA3C框架集成到现有的MARL算法中，并将其应用于基准任务。实验结果表明，MA3C可以有效提高通信策略的鲁棒性，在通信攻击下取得更好的性能，验证了我们方法的有效性和泛化性。",
    "tldr": "本文提出了一种适应性的辅助对抗生成的方法，命名为MA3C，以在合作多代理强化学习环境下实现通信鲁棒性，能够通过共同的目标最小化协同能力，有效提高通信策略的鲁棒性，在通信攻击下取得更好的性能。",
    "en_tdlr": "This paper proposes an adaptive Multi-Agent Auxiliary Adversaries Generation method, dubbed MA3C, to achieve communication robustness in cooperative Multi-Agent Reinforcement Learning environment. MA3C can effectively improve the robustness of communication-based policies and achieve better performance under communication attacks, by minimizing the coordination ability of the ego system through a shared goal."
}