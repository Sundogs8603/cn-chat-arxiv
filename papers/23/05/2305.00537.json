{
    "title": "Interpretability of Machine Learning: Recent Advances and Future Prospects. (arXiv:2305.00537v1 [cs.MM])",
    "abstract": "The proliferation of machine learning (ML) has drawn unprecedented interest in the study of various multimedia contents such as text, image, audio and video, among others. Consequently, understanding and learning ML-based representations have taken center stage in knowledge discovery in intelligent multimedia research and applications. Nevertheless, the black-box nature of contemporary ML, especially in deep neural networks (DNNs), has posed a primary challenge for ML-based representation learning. To address this black-box problem, the studies on interpretability of ML have attracted tremendous interests in recent years. This paper presents a survey on recent advances and future prospects on interpretability of ML, with several application examples pertinent to multimedia computing, including text-image cross-modal representation learning, face recognition, and the recognition of objects. It is evidently shown that the study of interpretability of ML promises an important research dir",
    "link": "http://arxiv.org/abs/2305.00537",
    "context": "Title: Interpretability of Machine Learning: Recent Advances and Future Prospects. (arXiv:2305.00537v1 [cs.MM])\nAbstract: The proliferation of machine learning (ML) has drawn unprecedented interest in the study of various multimedia contents such as text, image, audio and video, among others. Consequently, understanding and learning ML-based representations have taken center stage in knowledge discovery in intelligent multimedia research and applications. Nevertheless, the black-box nature of contemporary ML, especially in deep neural networks (DNNs), has posed a primary challenge for ML-based representation learning. To address this black-box problem, the studies on interpretability of ML have attracted tremendous interests in recent years. This paper presents a survey on recent advances and future prospects on interpretability of ML, with several application examples pertinent to multimedia computing, including text-image cross-modal representation learning, face recognition, and the recognition of objects. It is evidently shown that the study of interpretability of ML promises an important research dir",
    "path": "papers/23/05/2305.00537.json",
    "total_tokens": 908,
    "translated_title": "机器学习的可解释性：最新进展和未来前景研究综述",
    "translated_abstract": "机器学习的广泛应用已经吸引了人们对各种多媒体内容（如文本、图像、音频和视频等）的研究和探索。特别是在深度神经网络等领域，现代机器学习的黑盒特性已成为面向多媒体研究和应用中表示学习的主要挑战。为了解决这个黑盒问题，近年来，机器学习的可解释性研究吸引了巨大的关注。本文对机器学习的可解释性最新进展和未来前景进行了综述，并提供了多个相关的多媒体计算应用示例，包括文本-图像跨模态表示学习、人脸识别和物体识别等。这个研究表明机器学习的可解释性研究有着重要的研究方向和前景。",
    "tldr": "本文综述了最新的机器学习可解释性进展和未来的前景，并提供了相关的多媒体计算应用示例，包括跨模态表示学习、人脸识别和物体识别等。研究显示，机器学习的可解释性研究有着重要的研究方向和前景。",
    "en_tdlr": "This paper presents a survey on recent advances and future prospects on interpretability of machine learning, and provides several application examples pertaining to multimedia computing, including cross-modal representation learning, face recognition, and object recognition. Research shows that the study of interpretability of machine learning promises an important research direction and prospect."
}