{
    "title": "Learning to Act through Evolution of Neural Diversity in Random Neural Networks. (arXiv:2305.15945v1 [cs.NE])",
    "abstract": "Biological nervous systems consist of networks of diverse, sophisticated information processors in the form of neurons of different classes. In most artificial neural networks (ANNs), neural computation is abstracted to an activation function that is usually shared between all neurons within a layer or even the whole network; training of ANNs focuses on synaptic optimization. In this paper, we propose the optimization of neuro-centric parameters to attain a set of diverse neurons that can perform complex computations. Demonstrating the promise of the approach, we show that evolving neural parameters alone allows agents to solve various reinforcement learning tasks without optimizing any synaptic weights. While not aiming to be an accurate biological model, parameterizing neurons to a larger degree than the current common practice, allows us to ask questions about the computational abilities afforded by neural diversity in random neural networks. The presented results open up interestin",
    "link": "http://arxiv.org/abs/2305.15945",
    "context": "Title: Learning to Act through Evolution of Neural Diversity in Random Neural Networks. (arXiv:2305.15945v1 [cs.NE])\nAbstract: Biological nervous systems consist of networks of diverse, sophisticated information processors in the form of neurons of different classes. In most artificial neural networks (ANNs), neural computation is abstracted to an activation function that is usually shared between all neurons within a layer or even the whole network; training of ANNs focuses on synaptic optimization. In this paper, we propose the optimization of neuro-centric parameters to attain a set of diverse neurons that can perform complex computations. Demonstrating the promise of the approach, we show that evolving neural parameters alone allows agents to solve various reinforcement learning tasks without optimizing any synaptic weights. While not aiming to be an accurate biological model, parameterizing neurons to a larger degree than the current common practice, allows us to ask questions about the computational abilities afforded by neural diversity in random neural networks. The presented results open up interestin",
    "path": "papers/23/05/2305.15945.json",
    "total_tokens": 895,
    "translated_title": "随机神经网络中通过神经元多样性的演化学习行为",
    "translated_abstract": "生物神经系统由不同类别神经元组成的网络构成，它们是多样化、复杂的信息处理器。在大多数人工神经网络中，神经计算被抽象为一个激活函数，通常是在整个网络或同一层中的所有神经元之间共享的；神经网络的训练主要关注突触权重的优化。本文推荐通过优化神经元中心参数来获得一组多样化的神经元，从而执行复杂计算。我们展示了这种方法的潜力，证明仅通过演化神经参数即可使代理在不优化任何突触权重的情况下解决各种强化学习任务。虽然不致力于精确的生物模型，但通过比当前常见的做法更大程度地对神经元参数化，我们能够探讨随机神经网络中神经多样性提供的计算能力。这些结果引起了人们的极大兴趣。",
    "tldr": "本文提出一种通过演化神经元中心参数来获得一组多样化的神经元，从而执行复杂计算的方法。研究显示，演化神经参数就足以使代理在不优化任何突触权重的情况下解决强化学习任务。",
    "en_tdlr": "This paper proposes a method of learning complex computations through the evolution of diverse neural parameters in random neural networks. The results demonstrate that evolving neural parameters alone is sufficient for agents to solve reinforcement learning tasks without optimizing synaptic weights."
}