{
    "title": "Regularization Through Simultaneous Learning: A Case Study for Hop Classification. (arXiv:2305.13447v1 [cs.LG])",
    "abstract": "Overfitting remains a prevalent challenge in deep neural networks, leading to suboptimal real-world performance. Employing regularization techniques is a common strategy to counter this challenge, improving model generalization. This paper proposes Simultaneous Learning, a novel regularization approach drawing on Transfer Learning and Multi-task Learning principles, applied specifically to the classification of hop varieties - an integral component of beer production. Our approach harnesses the power of auxiliary datasets in synergy with the target dataset to amplify the acquisition of highly relevant features. Through a strategic modification of the model's final layer, we enable the simultaneous classification of both datasets without the necessity to treat them as disparate tasks. To realize this, we formulate a loss function that includes an inter-group penalty. We conducted experimental evaluations using the InceptionV3 and ResNet50 models, designating the UFOP-HVD hop leaf datase",
    "link": "http://arxiv.org/abs/2305.13447",
    "context": "Title: Regularization Through Simultaneous Learning: A Case Study for Hop Classification. (arXiv:2305.13447v1 [cs.LG])\nAbstract: Overfitting remains a prevalent challenge in deep neural networks, leading to suboptimal real-world performance. Employing regularization techniques is a common strategy to counter this challenge, improving model generalization. This paper proposes Simultaneous Learning, a novel regularization approach drawing on Transfer Learning and Multi-task Learning principles, applied specifically to the classification of hop varieties - an integral component of beer production. Our approach harnesses the power of auxiliary datasets in synergy with the target dataset to amplify the acquisition of highly relevant features. Through a strategic modification of the model's final layer, we enable the simultaneous classification of both datasets without the necessity to treat them as disparate tasks. To realize this, we formulate a loss function that includes an inter-group penalty. We conducted experimental evaluations using the InceptionV3 and ResNet50 models, designating the UFOP-HVD hop leaf datase",
    "path": "papers/23/05/2305.13447.json",
    "total_tokens": 952,
    "translated_title": "同时学习正则化方法：以啤酒花分类为例的案例研究",
    "translated_abstract": "过度拟合仍然是深度神经网络面临的一个普遍挑战，导致现实世界中的表现不佳。采用正则化技术是抵制这一挑战的常见策略，可以提高模型的泛化能力。本文提出了一种新颖的正则化方法：Simultaneous Learning，它利用迁移学习和多任务学习原理，专门应用于啤酒生产中的啤酒花品种分类。我们的方法利用辅助数据集的强大能力，与目标数据集协同工作，从而增强获取高度相关特征的能力。通过对模型的最终层进行战略性修改，我们实现了两个数据集的同时分类，无需将它们视为不同的任务。为了实现这一点，我们制定了一个包括组间惩罚的损失函数。我们使用InceptionV3和ResNet50模型进行实验评估，并指定了UFOP-HVD啤酒花叶数据集。",
    "tldr": "本文提出了一种新颖的同时学习正则化方法，将迁移学习和多任务学习原理应用于啤酒生产中的啤酒花品种分类，利用辅助数据集的协同作用增强获取高度相关特征的能力，成功实现了两个数据集的同时分类。"
}