{
    "title": "Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models. (arXiv:2305.14763v1 [cs.CL])",
    "abstract": "The escalating debate on AI's capabilities warrants developing reliable metrics to assess machine \"intelligence\". Recently, many anecdotal examples were used to suggest that newer large language models (LLMs) like ChatGPT and GPT-4 exhibit Neural Theory-of-Mind (N-ToM); however, prior work reached conflicting conclusions regarding those abilities. We investigate the extent of LLMs' N-ToM through an extensive evaluation on 6 tasks and find that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust. We further examine the factors impacting performance on N-ToM tasks and discover that LLMs struggle with adversarial examples, indicating reliance on shallow heuristics rather than robust ToM abilities. We caution against drawing conclusions from anecdotal examples, limited benchmark testing, and using human-designed psychological tests to evaluate models.",
    "link": "http://arxiv.org/abs/2305.14763",
    "context": "Title: Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models. (arXiv:2305.14763v1 [cs.CL])\nAbstract: The escalating debate on AI's capabilities warrants developing reliable metrics to assess machine \"intelligence\". Recently, many anecdotal examples were used to suggest that newer large language models (LLMs) like ChatGPT and GPT-4 exhibit Neural Theory-of-Mind (N-ToM); however, prior work reached conflicting conclusions regarding those abilities. We investigate the extent of LLMs' N-ToM through an extensive evaluation on 6 tasks and find that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust. We further examine the factors impacting performance on N-ToM tasks and discover that LLMs struggle with adversarial examples, indicating reliance on shallow heuristics rather than robust ToM abilities. We caution against drawing conclusions from anecdotal examples, limited benchmark testing, and using human-designed psychological tests to evaluate models.",
    "path": "papers/23/05/2305.14763.json",
    "total_tokens": 906,
    "translated_title": "Clever Hans还是神经心智理论？在大语言模型中对社交推理进行压力测试。",
    "translated_abstract": "关于人工智能的能力的争论日益升级，需要开发可靠的度量标准来评估机器的“智能”。最近，许多轶事性的例子被用来暗示像ChatGPT和GPT-4这样的新型大型语言模型（LLMs）展示了神经心智理论（N-ToM）;然而，先前的研究对这些能力得出了相互矛盾的结论。我们通过对6项任务进行广泛评估来调查LLMs的N-ToM程度，并发现LLMs表现出某些N-ToM能力，但这种行为还远非稳健。我们进一步检查影响N-ToM任务表现的因素，并发现LLMs在对抗性例子上存在困难，表明依赖于浅层启发式而不是稳健的ToM能力。我们警告不要从轶事性的例子、有限的基准测试和使用人类设计的心理测试来评估模型中得出结论。",
    "tldr": "本文研究了大型语言模型的神经心智理论能力，并发现虽然模型表现出一定程度的N-ToM能力，但远非稳健，存在对抗性例子困难等问题。",
    "en_tdlr": "This paper investigates the Neural Theory-of-Mind (N-ToM) abilities of large language models (LLMs) and finds that although the models exhibit some level of N-ToM abilities, they are not robust and struggle with adversarial examples. The study cautions against drawing conclusions from anecdotal examples and limited benchmark testing."
}