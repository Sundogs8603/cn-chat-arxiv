{
    "title": "MALM: Mask Augmentation based Local Matching for Food-Recipe Retrieval. (arXiv:2305.11327v1 [cs.CV])",
    "abstract": "Image-to-recipe retrieval is a challenging vision-to-language task of significant practical value. The main challenge of the task lies in the ultra-high redundancy in the long recipe and the large variation reflected in both food item combination and food item appearance. A de-facto idea to address this task is to learn a shared feature embedding space in which a food image is aligned better to its paired recipe than other recipes. However, such supervised global matching is prone to supervision collapse, i.e., only partial information that is necessary for distinguishing training pairs can be identified, while other information that is potentially useful in generalization could be lost. To mitigate such a problem, we propose a mask-augmentation-based local matching network (MALM), where an image-text matching module and a masked self-distillation module benefit each other mutually to learn generalizable cross-modality representations. On one hand, we perform local matching between the",
    "link": "http://arxiv.org/abs/2305.11327",
    "context": "Title: MALM: Mask Augmentation based Local Matching for Food-Recipe Retrieval. (arXiv:2305.11327v1 [cs.CV])\nAbstract: Image-to-recipe retrieval is a challenging vision-to-language task of significant practical value. The main challenge of the task lies in the ultra-high redundancy in the long recipe and the large variation reflected in both food item combination and food item appearance. A de-facto idea to address this task is to learn a shared feature embedding space in which a food image is aligned better to its paired recipe than other recipes. However, such supervised global matching is prone to supervision collapse, i.e., only partial information that is necessary for distinguishing training pairs can be identified, while other information that is potentially useful in generalization could be lost. To mitigate such a problem, we propose a mask-augmentation-based local matching network (MALM), where an image-text matching module and a masked self-distillation module benefit each other mutually to learn generalizable cross-modality representations. On one hand, we perform local matching between the",
    "path": "papers/23/05/2305.11327.json",
    "total_tokens": 715,
    "translated_title": "基于口罩增强的局部匹配的食谱图像检索方法",
    "translated_abstract": "图像到食谱的检索是一项具有重要实用价值的视觉到语言的挑战性任务。该任务的主要挑战在于食谱长度超高冗余和反映在食品组合和外观上的大变化。为了解决这个问题，我们提出了一种基于口罩增强的局部匹配网络(MALM)，其中图像-文本匹配模块和掩码自蒸馏模块相互受益，以学习可泛化的跨模态表示。",
    "tldr": "提出了一种基于口罩增强的局部匹配网络(MALM)，用于图像到食谱的检索，学习可泛化的跨模态表示。",
    "en_tdlr": "MALM, a mask-augmentation-based local matching network, is proposed for image-to-recipe retrieval, which learns generalizable cross-modality representations."
}