{
    "title": "WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia. (arXiv:2305.14292v2 [cs.CL] UPDATED)",
    "abstract": "This paper presents the first few-shot LLM-based chatbot that almost never hallucinates and has high conversationality and low latency. WikiChat is grounded on the English Wikipedia, the largest curated free-text corpus.  WikiChat generates a response from an LLM, retains only the grounded facts, and combines them with additional information it retrieves from the corpus to form factual and engaging responses. We distill WikiChat based on GPT-4 into a 7B-parameter LLaMA model with minimal loss of quality, to significantly improve its latency, cost and privacy, and facilitate research and deployment.  Using a novel hybrid human-and-LLM evaluation methodology, we show that our best system achieves 97.3% factual accuracy in simulated conversations. It significantly outperforms all retrieval-based and LLM-based baselines, and by 3.9%, 38.6% and 51.0% on head, tail and recent knowledge compared to GPT-4. Compared to previous state-of-the-art retrieval-based chatbots, WikiChat is also signifi",
    "link": "http://arxiv.org/abs/2305.14292",
    "context": "Title: WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia. (arXiv:2305.14292v2 [cs.CL] UPDATED)\nAbstract: This paper presents the first few-shot LLM-based chatbot that almost never hallucinates and has high conversationality and low latency. WikiChat is grounded on the English Wikipedia, the largest curated free-text corpus.  WikiChat generates a response from an LLM, retains only the grounded facts, and combines them with additional information it retrieves from the corpus to form factual and engaging responses. We distill WikiChat based on GPT-4 into a 7B-parameter LLaMA model with minimal loss of quality, to significantly improve its latency, cost and privacy, and facilitate research and deployment.  Using a novel hybrid human-and-LLM evaluation methodology, we show that our best system achieves 97.3% factual accuracy in simulated conversations. It significantly outperforms all retrieval-based and LLM-based baselines, and by 3.9%, 38.6% and 51.0% on head, tail and recent knowledge compared to GPT-4. Compared to previous state-of-the-art retrieval-based chatbots, WikiChat is also signifi",
    "path": "papers/23/05/2305.14292.json",
    "total_tokens": 1116,
    "translated_title": "WikiChat: 通过对维基百科的少样本引入，阻止大型语言模型聊天机器人的幻觉",
    "translated_abstract": "本文提出了第一个几乎不会产生幻觉、具有高对话能力和低延迟的基于少样本的LLM聊天机器人——WikiChat。WikiChat基于英文维基百科进行 grounding，这是最大的精选文本语料库。WikiChat从LLM中生成响应，仅保留基于事实的内容，并与从语料库中检索到的附加信息结合，形成真实和引人入胜的回复。我们将 WikiChat 根据 GPT-4 进行了蒸馏，生成了一个参数为7B的 LLaMA 模型，以极少质量损失显著提高了其延迟、成本和隐私性，并促进了研究和部署。通过一种新颖的混合人工和LLM评估方法，我们展示了我们的最佳系统在模拟对话中达到了97.3%的事实准确性。与所有基于检索和LLM的基准相比，它在头部、尾部和最新知识方面分别提高了3.9%、38.6%和51.0%，与GPT-4相比。与之前最先进的基于检索的聊天机器人相比，WikiChat也取得了显著的...",
    "tldr": "WikiChat是一种以少样本为基础的语言模型聊天机器人，通过对维基百科进行 grounding，它几乎不会产生幻觉，具有高对话能力和低延迟。WikiChat从LLM中生成响应，保留基于事实的内容，并从语料库中检索到的信息结合，形成真实和引人入胜的回复。经过评估，它比其他模型表现更好，并且能在模拟对话中达到97.3%的事实准确性。"
}