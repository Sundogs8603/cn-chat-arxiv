{
    "title": "How Does Generative Retrieval Scale to Millions of Passages?. (arXiv:2305.11841v1 [cs.IR])",
    "abstract": "Popularized by the Differentiable Search Index, the emerging paradigm of generative retrieval re-frames the classic information retrieval problem into a sequence-to-sequence modeling task, forgoing external indices and encoding an entire document corpus within a single Transformer. Although many different approaches have been proposed to improve the effectiveness of generative retrieval, they have only been evaluated on document corpora on the order of 100k in size. We conduct the first empirical study of generative retrieval techniques across various corpus scales, ultimately scaling up to the entire MS MARCO passage ranking task with a corpus of 8.8M passages and evaluating model sizes up to 11B parameters. We uncover several findings about scaling generative retrieval to millions of passages; notably, the central importance of using synthetic queries as document representations during indexing, the ineffectiveness of existing proposed architecture modifications when accounting for c",
    "link": "http://arxiv.org/abs/2305.11841",
    "context": "Title: How Does Generative Retrieval Scale to Millions of Passages?. (arXiv:2305.11841v1 [cs.IR])\nAbstract: Popularized by the Differentiable Search Index, the emerging paradigm of generative retrieval re-frames the classic information retrieval problem into a sequence-to-sequence modeling task, forgoing external indices and encoding an entire document corpus within a single Transformer. Although many different approaches have been proposed to improve the effectiveness of generative retrieval, they have only been evaluated on document corpora on the order of 100k in size. We conduct the first empirical study of generative retrieval techniques across various corpus scales, ultimately scaling up to the entire MS MARCO passage ranking task with a corpus of 8.8M passages and evaluating model sizes up to 11B parameters. We uncover several findings about scaling generative retrieval to millions of passages; notably, the central importance of using synthetic queries as document representations during indexing, the ineffectiveness of existing proposed architecture modifications when accounting for c",
    "path": "papers/23/05/2305.11841.json",
    "total_tokens": 884,
    "translated_title": "生成式检索如何扩展到数百万篇文章？",
    "translated_abstract": "由可微搜索索引(Differentiable Search Index)推广而来的生成式检索的新兴范式,将经典的信息检索问题重新构造为序列到序列的建模任务，放弃了外部索引，并将整个文档语料库编码在单个Transformer中。虽然已经提出了许多不同的方法来提高生成式检索的有效性，但它们仅在约100k的文档语料库上进行了评估。我们进行了第一次根据不同的语料规模进行生成式检索技术的实证研究，最终扩展到整个8.8M篇章的MS MARCO检索任务，并评估了高达11B个参数的模型大小。我们揭示了关于将生成式检索扩展到数百万篇文章的几个发现，特别是索引期间使用合成查询作为文档表示的核心重要性，以及考虑并非现有的建议架构修改时的无效性。",
    "tldr": "本研究对不同语料规模下的生成式检索技术进行了实证研究，扩展到包含8.8M篇章的MS MARCO检索任务，并评估了高达11B个参数的模型大小，揭示出了在索引期间使用合成查询作为文档表示的重要性。",
    "en_tdlr": "This paper conducts the first empirical study of generative retrieval techniques across various corpus scales, and ultimately scales up to the entire MS MARCO passage ranking task with a corpus of 8.8M passages. The study uncovers the importance of using synthetic queries as document representations during indexing."
}