{
    "title": "HalOmi: A Manually Annotated Benchmark for Multilingual Hallucination and Omission Detection in Machine Translation. (arXiv:2305.11746v1 [cs.CL])",
    "abstract": "Hallucinations in machine translation are translations that contain information completely unrelated to the input. Omissions are translations that do not include some of the input information. While both cases tend to be catastrophic errors undermining user trust, annotated data with these types of pathologies is extremely scarce and is limited to a few high-resource languages. In this work, we release an annotated dataset for the hallucination and omission phenomena covering 18 translation directions with varying resource levels and scripts. Our annotation covers different levels of partial and full hallucinations as well as omissions both at the sentence and at the word level. Additionally, we revisit previous methods for hallucination and omission detection, show that conclusions made based on a single language pair largely do not hold for a large-scale evaluation, and establish new solid baselines.",
    "link": "http://arxiv.org/abs/2305.11746",
    "context": "Title: HalOmi: A Manually Annotated Benchmark for Multilingual Hallucination and Omission Detection in Machine Translation. (arXiv:2305.11746v1 [cs.CL])\nAbstract: Hallucinations in machine translation are translations that contain information completely unrelated to the input. Omissions are translations that do not include some of the input information. While both cases tend to be catastrophic errors undermining user trust, annotated data with these types of pathologies is extremely scarce and is limited to a few high-resource languages. In this work, we release an annotated dataset for the hallucination and omission phenomena covering 18 translation directions with varying resource levels and scripts. Our annotation covers different levels of partial and full hallucinations as well as omissions both at the sentence and at the word level. Additionally, we revisit previous methods for hallucination and omission detection, show that conclusions made based on a single language pair largely do not hold for a large-scale evaluation, and establish new solid baselines.",
    "path": "papers/23/05/2305.11746.json",
    "total_tokens": 891,
    "translated_title": "HalOmi：机器翻译中多语言“幻觉”和遗漏检测的手动注释基准",
    "translated_abstract": "机器翻译中的“幻觉”指的是完全与输入信息无关的信息，而“遗漏”是指未包括某些输入信息的翻译。尽管这两种情况往往是破坏用户信任的灾难性错误，但这些类型的带注释数据非常稀缺，并且仅限于少数高资源语言。在本研究中，我们发布了一个标注的数据集，用于涵盖18种翻译方向的幻觉和遗漏现象，其资源水平和脚本各不相同。我们的注释涵盖了不同级别的完全幻觉、部分幻觉以及句子和单词一级的遗漏。此外，我们重访了以前的研究，展示了基于单个语言对得出的结论在大规模评估中很难成立，并建立了新的可靠基线。",
    "tldr": "本文提供了一个涵盖18个翻译方向，包括多种资源水平和脚本的机器翻译中“幻觉”和遗漏现象的手动注释数据集。同时，通过评估不同语言对的表现，为该领域研究提供可靠的基线。",
    "en_tdlr": "This paper provides a manually annotated dataset for hallucination and omission phenomena in machine translation, covering 18 translation directions with varying resource levels and scripts. It also establishes new solid baselines by evaluating the performance in different language pairs."
}