{
    "title": "Interpretability at Scale: Identifying Causal Mechanisms in Alpaca. (arXiv:2305.08809v2 [cs.CL] UPDATED)",
    "abstract": "Obtaining human-interpretable explanations of large, general-purpose language models is an urgent goal for AI safety. However, it is just as important that our interpretability methods are faithful to the causal dynamics underlying model behavior and able to robustly generalize to unseen inputs. Distributed Alignment Search (DAS) is a powerful gradient descent method grounded in a theory of causal abstraction that has uncovered perfect alignments between interpretable symbolic algorithms and small deep learning models fine-tuned for specific tasks. In the present paper, we scale DAS significantly by replacing the remaining brute-force search steps with learned parameters -- an approach we call Boundless DAS. This enables us to efficiently search for interpretable causal structure in large language models while they follow instructions. We apply Boundless DAS to the Alpaca model (7B parameters), which, off the shelf, solves a simple numerical reasoning problem. With Boundless DAS, we di",
    "link": "http://arxiv.org/abs/2305.08809",
    "context": "Title: Interpretability at Scale: Identifying Causal Mechanisms in Alpaca. (arXiv:2305.08809v2 [cs.CL] UPDATED)\nAbstract: Obtaining human-interpretable explanations of large, general-purpose language models is an urgent goal for AI safety. However, it is just as important that our interpretability methods are faithful to the causal dynamics underlying model behavior and able to robustly generalize to unseen inputs. Distributed Alignment Search (DAS) is a powerful gradient descent method grounded in a theory of causal abstraction that has uncovered perfect alignments between interpretable symbolic algorithms and small deep learning models fine-tuned for specific tasks. In the present paper, we scale DAS significantly by replacing the remaining brute-force search steps with learned parameters -- an approach we call Boundless DAS. This enables us to efficiently search for interpretable causal structure in large language models while they follow instructions. We apply Boundless DAS to the Alpaca model (7B parameters), which, off the shelf, solves a simple numerical reasoning problem. With Boundless DAS, we di",
    "path": "papers/23/05/2305.08809.json",
    "total_tokens": 913,
    "translated_title": "规模上的解释性：在Alpaca中识别因果机制",
    "translated_abstract": "对于AI安全而言，获得大型通用语言模型的人类可解释性解释是一个紧急目标。然而，同样重要的是我们的解释性方法能够忠实于模型行为底层的因果动力学，且能够在未见输入上具有鲁棒泛化性。分布式对齐搜索（DAS）是一种强大的渐变下降方法，它基于一种因果抽象理论，已经发现了可解释的符号算法和针对特定任务进行细调的小型深度学习模型之间的完美对齐。在本文中，我们通过用学习得到的参数来替换剩余的蛮力搜索步骤，显著扩展了DAS，这种方法我们称之为无边界DAS。这使得我们能够在大型语言模型中高效地搜索可解释的因果结构，同时它们遵循指令。我们将无边界DAS应用于Alpaca模型（7B参数），它可以快速解决一个简单的数值推理问题。通过无边界DAS，我们发现...",
    "tldr": "通过使用分布式对齐搜索（DAS）方法，我们在大型语言模型中实现了规模上的解释性，这使得我们能够高效地搜索到解释性因果结构，并应用于Alpaca模型中。"
}