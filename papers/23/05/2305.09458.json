{
    "title": "An Empirical Study on Google Research Football Multi-agent Scenarios. (arXiv:2305.09458v1 [cs.LG])",
    "abstract": "Few multi-agent reinforcement learning (MARL) research on Google Research Football (GRF) focus on the 11v11 multi-agent full-game scenario and to the best of our knowledge, no open benchmark on this scenario has been released to the public. In this work, we fill the gap by providing a population-based MARL training pipeline and hyperparameter settings on multi-agent football scenario that outperforms the bot with difficulty 1.0 from scratch within 2 million steps. Our experiments serve as a reference for the expected performance of Independent Proximal Policy Optimization (IPPO), a state-of-the-art multi-agent reinforcement learning algorithm where each agent tries to maximize its own policy independently across various training configurations. Meanwhile, we open-source our training framework Light-MALib which extends the MALib codebase by distributed and asynchronized implementation with additional analytical tools for football games. Finally, we provide guidance for building strong f",
    "link": "http://arxiv.org/abs/2305.09458",
    "context": "Title: An Empirical Study on Google Research Football Multi-agent Scenarios. (arXiv:2305.09458v1 [cs.LG])\nAbstract: Few multi-agent reinforcement learning (MARL) research on Google Research Football (GRF) focus on the 11v11 multi-agent full-game scenario and to the best of our knowledge, no open benchmark on this scenario has been released to the public. In this work, we fill the gap by providing a population-based MARL training pipeline and hyperparameter settings on multi-agent football scenario that outperforms the bot with difficulty 1.0 from scratch within 2 million steps. Our experiments serve as a reference for the expected performance of Independent Proximal Policy Optimization (IPPO), a state-of-the-art multi-agent reinforcement learning algorithm where each agent tries to maximize its own policy independently across various training configurations. Meanwhile, we open-source our training framework Light-MALib which extends the MALib codebase by distributed and asynchronized implementation with additional analytical tools for football games. Finally, we provide guidance for building strong f",
    "path": "papers/23/05/2305.09458.json",
    "total_tokens": 856,
    "translated_title": "谷歌研究足球多智能体场景的实证研究",
    "translated_abstract": "目前，研究谷歌研究足球（GRF）上的11v11多智能体（MARL）场景仍然是一个较少被关注的课题。本研究提供了一种基于人口的MARL训练管线以及超参数设置的方法，用于训练多智能体足球场景，从零开始在200万步内就能优于难度为1.0的机器人。此外，本研究还开源了训练框架Light-MALib，扩展了MALib代码库，通过分布式和异步实现以及足球游戏的附加分析工具，提供了指导机器人较好表现的方法。",
    "tldr": "本研究提供了一种基于人口的MARL训练管线以及超参数，用于训练多智能体足球场景，从零开始在200万步内打败了难度为1.0的机器人，并提供了开源训练框架Light-MALib。"
}