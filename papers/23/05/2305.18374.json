{
    "title": "Pure Spectral Graph Embeddings: Reinterpreting Graph Convolution for Top-N Recommendation. (arXiv:2305.18374v1 [cs.IR])",
    "abstract": "The use of graph convolution in the development of recommender system algorithms has recently achieved state-of-the-art results in the collaborative filtering task (CF). While it has been demonstrated that the graph convolution operation is connected to a filtering operation on the graph spectral domain, the theoretical rationale for why this leads to higher performance on the collaborative filtering problem remains unknown. The presented work makes two contributions. First, we investigate the effect of using graph convolution throughout the user and item representation learning processes, demonstrating how the latent features learned are pushed from the filtering operation into the subspace spanned by the eigenvectors associated with the highest eigenvalues of the normalised adjacency matrix, and how vectors lying on this subspace are the optimal solutions for an objective function related to the sum of the prediction function over the training data. Then, we present an approach that ",
    "link": "http://arxiv.org/abs/2305.18374",
    "context": "Title: Pure Spectral Graph Embeddings: Reinterpreting Graph Convolution for Top-N Recommendation. (arXiv:2305.18374v1 [cs.IR])\nAbstract: The use of graph convolution in the development of recommender system algorithms has recently achieved state-of-the-art results in the collaborative filtering task (CF). While it has been demonstrated that the graph convolution operation is connected to a filtering operation on the graph spectral domain, the theoretical rationale for why this leads to higher performance on the collaborative filtering problem remains unknown. The presented work makes two contributions. First, we investigate the effect of using graph convolution throughout the user and item representation learning processes, demonstrating how the latent features learned are pushed from the filtering operation into the subspace spanned by the eigenvectors associated with the highest eigenvalues of the normalised adjacency matrix, and how vectors lying on this subspace are the optimal solutions for an objective function related to the sum of the prediction function over the training data. Then, we present an approach that ",
    "path": "papers/23/05/2305.18374.json",
    "total_tokens": 1031,
    "translated_title": "纯谱图嵌入：将图卷积重新解释为Top-N推荐中的方法",
    "translated_abstract": "最近在协同过滤任务（CF）的推荐系统算法的开发中，使用图卷积已经取得了最先进的结果。虽然已经证明，图卷积操作与图谱域上的过滤操作有关，但为什么这会导致协同过滤问题的更高性能的理论基础仍不为人知。本文提出了两个贡献。首先，我们研究了在用户和项目表示学习过程中使用图卷积的效果，并展示了学习到的潜在特征如何从过滤操作推进到由归一化邻接矩阵的最高特征值对应的特征向量张成的子空间中，并且该子空间上的向量是与训练数据上的预测函数的求和相关的目标函数的最优解。然后，我们提出了一种方法，将图卷积操作重新解释为纯谱嵌入，将其与谱方法文献对齐，并突出其与Laplacian Eigenmaps和Common Neighbour Ranking Mechanism的联系。通过利用图Laplacian的谱特性，该方法能够在Top-N推荐任务中取得优于现有基于图卷积的模型的性能。",
    "tldr": "本文提出了一种新的纯谱图嵌入方法，在Top-N推荐任务中比现有基于图卷积的模型具有更优的性能。"
}