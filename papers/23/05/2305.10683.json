{
    "title": "Paxion: Patching Action Knowledge in Video-Language Foundation Models. (arXiv:2305.10683v1 [cs.CV])",
    "abstract": "Action knowledge involves the understanding of textual, visual, and temporal aspects of actions. We introduce the Action Dynamics Benchmark (ActionBench) containing two carefully designed probing tasks: Action Antonym and Video Reversal, which targets multimodal alignment capabilities and temporal understanding skills of the model, respectively. Despite recent video-language models' (VidLM) impressive performance on various benchmark tasks, our diagnostic tasks reveal their surprising deficiency (near-random performance) in action knowledge, suggesting that current models rely on object recognition abilities as a shortcut for action understanding. To remedy this, we propose a novel framework, Paxion, along with a new Discriminative Video Dynamics Modeling (DVDM) objective. The Paxion framework utilizes a Knowledge Patcher network to encode new action knowledge and a Knowledge Fuser component to integrate the Patcher into frozen VidLMs without compromising their existing capabilities. D",
    "link": "http://arxiv.org/abs/2305.10683",
    "context": "Title: Paxion: Patching Action Knowledge in Video-Language Foundation Models. (arXiv:2305.10683v1 [cs.CV])\nAbstract: Action knowledge involves the understanding of textual, visual, and temporal aspects of actions. We introduce the Action Dynamics Benchmark (ActionBench) containing two carefully designed probing tasks: Action Antonym and Video Reversal, which targets multimodal alignment capabilities and temporal understanding skills of the model, respectively. Despite recent video-language models' (VidLM) impressive performance on various benchmark tasks, our diagnostic tasks reveal their surprising deficiency (near-random performance) in action knowledge, suggesting that current models rely on object recognition abilities as a shortcut for action understanding. To remedy this, we propose a novel framework, Paxion, along with a new Discriminative Video Dynamics Modeling (DVDM) objective. The Paxion framework utilizes a Knowledge Patcher network to encode new action knowledge and a Knowledge Fuser component to integrate the Patcher into frozen VidLMs without compromising their existing capabilities. D",
    "path": "papers/23/05/2305.10683.json",
    "total_tokens": 877,
    "translated_abstract": "行动知识涉及对行动的文本、视觉和时间方面的理解。我们介绍了Action Dynamics Benchmark(ActionBench)，其中包含两个精心设计的探测任务：Action Antonym和Video Reversal，分别针对模型的多模态对齐能力和时间理解技能。尽管最近的视频语言模型(VidLM)在各种基准任务上表现出色，我们的诊断任务揭示了它们在行动知识方面的惊人缺陷(近似随机性能)，提示当前模型依赖于物体识别能力作为行动理解的捷径。为了解决这个问题，我们提出了一个新的框架Paxion，并提出了一个新的区分性视频动力学建模(DVDM)目标。Paxion框架利用一个知识补丁网络来编码新的行动知识，和一个知识融合器组件将补丁器集成到冻结的VidLM中，而不影响它们现有的能力。",
    "tldr": "介绍了一个新的视频语言基础模型的框架Paxion，它通过利用知识补丁器和知识融合器集成新的行动知识，从而提高模型在行动知识上的表现。"
}