{
    "title": "Efficient Open Domain Multi-Hop Question Answering with Few-Shot Data Synthesis. (arXiv:2305.13691v1 [cs.CL])",
    "abstract": "Few-shot learning for open domain multi-hop question answering typically relies on large language models (LLMs). While powerful, LLMs are inefficient at the inference time. We propose a data synthesis framework for multi-hop question answering that allows for improving smaller language models with less than 10 human-annotated question answer pairs. The framework is built upon the data generation functions parameterized by LLMs and prompts, which requires minimal hand-crafted features. Empirically, we synthesize millions of multi-hop questions and claims. After finetuning language models on the synthetic data, we evaluate the models on popular benchmarks on multi-hop question answering and fact verification. Our experimental results show that finetuning on the synthetic data improves model performance significantly, allowing our finetuned models to be competitive with prior models while being almost one-third the size in terms of parameter counts.",
    "link": "http://arxiv.org/abs/2305.13691",
    "context": "Title: Efficient Open Domain Multi-Hop Question Answering with Few-Shot Data Synthesis. (arXiv:2305.13691v1 [cs.CL])\nAbstract: Few-shot learning for open domain multi-hop question answering typically relies on large language models (LLMs). While powerful, LLMs are inefficient at the inference time. We propose a data synthesis framework for multi-hop question answering that allows for improving smaller language models with less than 10 human-annotated question answer pairs. The framework is built upon the data generation functions parameterized by LLMs and prompts, which requires minimal hand-crafted features. Empirically, we synthesize millions of multi-hop questions and claims. After finetuning language models on the synthetic data, we evaluate the models on popular benchmarks on multi-hop question answering and fact verification. Our experimental results show that finetuning on the synthetic data improves model performance significantly, allowing our finetuned models to be competitive with prior models while being almost one-third the size in terms of parameter counts.",
    "path": "papers/23/05/2305.13691.json",
    "total_tokens": 903,
    "translated_title": "使用少量合成数据进行高效的开放领域“多跳问题回答”",
    "translated_abstract": "对于开放领域“多跳问题回答”，少量数据的学习通常依赖于大型语言模型（LLMs）。虽然强大，但是LLMs在推断时效率低下。我们提出了一种数据合成框架，用于“多跳问题回答”，可使小型语言模型在少于10个人类注释的问题-答案对方面得到改善。该框架建立在由LLMs和提示参数化的数据生成函数之上，这仅需要少量的手工特征。实证上，我们合成了数百万个多跳问题和声称。在合成数据上微调语言模型后，我们在流行的多跳问题回答和事实验证基准上评估模型。我们的实验结果表明，在合成数据上进行微调可以显著改善模型性能，使我们的微调模型在参数量上仅为之前模型的三分之一，同时保持竞争力。",
    "tldr": "提出了一种使用少量合成数据进行高效的开放领域多跳问题回答的方法，可用于改善小型语言模型的性能。通过语言模型和提示参数化的数据生成函数合成数据，微调后的模型参数量只有之前模型的三分之一，达到了与之前模型类似的性能。",
    "en_tdlr": "The paper proposes a method for efficient open domain multi-hop question answering with few-shot data synthesis, which improves smaller language models by synthesizing data using language models and prompts. After finetuning on synthetic data, the models achieve similar performance with prior models while having only one-third the size in terms of parameter counts."
}