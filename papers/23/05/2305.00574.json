{
    "title": "The Dark Side of Explanations: Poisoning Recommender Systems with Counterfactual Examples. (arXiv:2305.00574v1 [cs.IR])",
    "abstract": "Deep learning-based recommender systems have become an integral part of several online platforms. However, their black-box nature emphasizes the need for explainable artificial intelligence (XAI) approaches to provide human-understandable reasons why a specific item gets recommended to a given user. One such method is counterfactual explanation (CF). While CFs can be highly beneficial for users and system designers, malicious actors may also exploit these explanations to undermine the system's security. In this work, we propose H-CARS, a novel strategy to poison recommender systems via CFs. Specifically, we first train a logical-reasoning-based surrogate model on training data derived from counterfactual explanations. By reversing the learning process of the recommendation model, we thus develop a proficient greedy algorithm to generate fabricated user profiles and their associated interaction records for the aforementioned surrogate model. Our experiments, which employ a well-known CF",
    "link": "http://arxiv.org/abs/2305.00574",
    "context": "Title: The Dark Side of Explanations: Poisoning Recommender Systems with Counterfactual Examples. (arXiv:2305.00574v1 [cs.IR])\nAbstract: Deep learning-based recommender systems have become an integral part of several online platforms. However, their black-box nature emphasizes the need for explainable artificial intelligence (XAI) approaches to provide human-understandable reasons why a specific item gets recommended to a given user. One such method is counterfactual explanation (CF). While CFs can be highly beneficial for users and system designers, malicious actors may also exploit these explanations to undermine the system's security. In this work, we propose H-CARS, a novel strategy to poison recommender systems via CFs. Specifically, we first train a logical-reasoning-based surrogate model on training data derived from counterfactual explanations. By reversing the learning process of the recommendation model, we thus develop a proficient greedy algorithm to generate fabricated user profiles and their associated interaction records for the aforementioned surrogate model. Our experiments, which employ a well-known CF",
    "path": "papers/23/05/2305.00574.json",
    "total_tokens": 920,
    "translated_title": "解释的黑暗面：用反事实例子污染推荐系统",
    "translated_abstract": "基于深度学习的推荐系统已经成为几个在线平台的重要组成部分。然而，它们的黑匣子本质强调了对可解释人工智能（XAI）方法的需求，以提供人类可以理解的原因，说明为什么向特定用户推荐特定的项目。其中一种方法是反事实说明（CF）。虽然CF对用户和系统设计人员可能会非常有益，但恶意行为者也可能利用这些说明来破坏系统的安全性。在这项工作中，我们提出了一种新的策略H-CARS，通过CF污染推荐系统。具体而言，我们首先在从反事实说明派生的训练数据上训练了一种基于逻辑推理的代理模型。通过颠倒推荐模型的学习过程，我们因此开发出了一个有效的贪婪算法，为上述代理模型生成虚假用户资料及其相关交互记录。我们的实验使用了一个众所周知的CF模型测试了我们的腐败技术，结果显示能够成功干扰推荐系统的性能。",
    "tldr": "这篇论文讨论了解释能力的反面，研究使用反事实例子污染推荐系统。实验显示，他们的策略能够成功干扰推荐系统的性能。"
}