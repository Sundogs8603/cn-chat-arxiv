{
    "title": "Evaluating Open-Domain Dialogues in Latent Space with Next Sentence Prediction and Mutual Information. (arXiv:2305.16967v2 [cs.CL] UPDATED)",
    "abstract": "The long-standing one-to-many issue of the open-domain dialogues poses significant challenges for automatic evaluation methods, i.e., there may be multiple suitable responses which differ in semantics for a given conversational context. To tackle this challenge, we propose a novel learning-based automatic evaluation metric (CMN), which can robustly evaluate open-domain dialogues by augmenting Conditional Variational Autoencoders (CVAEs) with a Next Sentence Prediction (NSP) objective and employing Mutual Information (MI) to model the semantic similarity of text in the latent space. Experimental results on two open-domain dialogue datasets demonstrate the superiority of our method compared with a wide range of baselines, especially in handling responses which are distant to the golden reference responses in semantics.",
    "link": "http://arxiv.org/abs/2305.16967",
    "context": "Title: Evaluating Open-Domain Dialogues in Latent Space with Next Sentence Prediction and Mutual Information. (arXiv:2305.16967v2 [cs.CL] UPDATED)\nAbstract: The long-standing one-to-many issue of the open-domain dialogues poses significant challenges for automatic evaluation methods, i.e., there may be multiple suitable responses which differ in semantics for a given conversational context. To tackle this challenge, we propose a novel learning-based automatic evaluation metric (CMN), which can robustly evaluate open-domain dialogues by augmenting Conditional Variational Autoencoders (CVAEs) with a Next Sentence Prediction (NSP) objective and employing Mutual Information (MI) to model the semantic similarity of text in the latent space. Experimental results on two open-domain dialogue datasets demonstrate the superiority of our method compared with a wide range of baselines, especially in handling responses which are distant to the golden reference responses in semantics.",
    "path": "papers/23/05/2305.16967.json",
    "total_tokens": 895,
    "translated_title": "用下一句预测和互信息在潜空间中评估开放域对话",
    "translated_abstract": "开放域对话中的一对多问题使得自动评估方法面临重大挑战，本文提出了一种新的基于学习的自动评估度量方法（CMN），通过将条件变分自编码器（CVAEs）与下一句预测（NSP）目标相结合，并利用互信息（MI）在潜空间中建模文本的语义相似度，实现了对开放域对话的鲁棒评估。在两个开放域对话数据集上的实验结果表明，与广泛的基线方法相比，我们的方法具有明显的优越性，特别是在处理语义上远离黄金参考回答的响应时更为有效。",
    "tldr": "本文提出了一种新的基于学习的自动评估度量方法（CMN），能够通过将条件变分自编码器（CVAEs）与下一句预测（NSP）目标相结合，并利用互信息（MI）在潜空间中建模文本的语义相似度，来鲁棒地评估开放域对话，并在实验中取得了优异的结果。",
    "en_tdlr": "A novel learning-based automatic evaluation metric (CMN) is proposed in this paper to address the one-to-many issue of open-domain dialogues, which can robustly evaluate such dialogues by augmenting Conditional Variational Autoencoders (CVAEs) with a Next Sentence Prediction (NSP) objective and employing Mutual Information (MI) to model the semantic similarity of text in the latent space. The experimental results on two open-domain dialogue datasets show that our method outperforms a wide range of baselines, especially in handling responses that are distant to the golden reference responses in semantics."
}