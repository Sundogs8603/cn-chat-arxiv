{
    "title": "Physical Adversarial Attacks for Surveillance: A Survey. (arXiv:2305.01074v1 [cs.CV])",
    "abstract": "Modern automated surveillance techniques are heavily reliant on deep learning methods. Despite the superior performance, these learning systems are inherently vulnerable to adversarial attacks - maliciously crafted inputs that are designed to mislead, or trick, models into making incorrect predictions. An adversary can physically change their appearance by wearing adversarial t-shirts, glasses, or hats or by specific behavior, to potentially avoid various forms of detection, tracking and recognition of surveillance systems; and obtain unauthorized access to secure properties and assets. This poses a severe threat to the security and safety of modern surveillance systems. This paper reviews recent attempts and findings in learning and designing physical adversarial attacks for surveillance applications. In particular, we propose a framework to analyze physical adversarial attacks and provide a comprehensive survey of physical adversarial attacks on four key surveillance tasks: detection",
    "link": "http://arxiv.org/abs/2305.01074",
    "context": "Title: Physical Adversarial Attacks for Surveillance: A Survey. (arXiv:2305.01074v1 [cs.CV])\nAbstract: Modern automated surveillance techniques are heavily reliant on deep learning methods. Despite the superior performance, these learning systems are inherently vulnerable to adversarial attacks - maliciously crafted inputs that are designed to mislead, or trick, models into making incorrect predictions. An adversary can physically change their appearance by wearing adversarial t-shirts, glasses, or hats or by specific behavior, to potentially avoid various forms of detection, tracking and recognition of surveillance systems; and obtain unauthorized access to secure properties and assets. This poses a severe threat to the security and safety of modern surveillance systems. This paper reviews recent attempts and findings in learning and designing physical adversarial attacks for surveillance applications. In particular, we propose a framework to analyze physical adversarial attacks and provide a comprehensive survey of physical adversarial attacks on four key surveillance tasks: detection",
    "path": "papers/23/05/2305.01074.json",
    "total_tokens": 876,
    "tldr": "现代自动化监控技术存在对抗攻击风险，攻击者可以通过佩戴对抗性服装或采取特定行为来避免检测和识别，并获取对资产的未经授权访问。本文综述了关于物理对抗攻击在监控任务中的最近研究进展。",
    "en_tdlr": "Modern automated surveillance techniques are vulnerable to adversarial attacks, where attackers can physically alter their appearance or behavior to avoid detection and recognition by surveillance systems. This paper surveys recent research on physical adversarial attacks in surveillance applications."
}