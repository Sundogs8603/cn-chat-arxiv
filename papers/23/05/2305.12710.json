{
    "title": "Beyond Labels: Empowering Human Annotators with Natural Language Explanations through a Novel Active-Learning Architecture. (arXiv:2305.12710v2 [cs.CL] UPDATED)",
    "abstract": "Real-world domain experts (e.g., doctors) rarely annotate only a decision label in their day-to-day workflow without providing explanations. Yet, existing low-resource learning techniques, such as Active Learning (AL), that aim to support human annotators mostly focus on the label while neglecting the natural language explanation of a data point. This work proposes a novel AL architecture to support experts' real-world need for label and explanation annotations in low-resource scenarios. Our AL architecture leverages an explanation-generation model to produce explanations guided by human explanations, a prediction model that utilizes generated explanations toward prediction faithfully, and a novel data diversity-based AL sampling strategy that benefits from the explanation annotations. Automated and human evaluations demonstrate the effectiveness of incorporating explanations into AL sampling and the improved human annotation efficiency and trustworthiness with our AL architecture. Add",
    "link": "http://arxiv.org/abs/2305.12710",
    "context": "Title: Beyond Labels: Empowering Human Annotators with Natural Language Explanations through a Novel Active-Learning Architecture. (arXiv:2305.12710v2 [cs.CL] UPDATED)\nAbstract: Real-world domain experts (e.g., doctors) rarely annotate only a decision label in their day-to-day workflow without providing explanations. Yet, existing low-resource learning techniques, such as Active Learning (AL), that aim to support human annotators mostly focus on the label while neglecting the natural language explanation of a data point. This work proposes a novel AL architecture to support experts' real-world need for label and explanation annotations in low-resource scenarios. Our AL architecture leverages an explanation-generation model to produce explanations guided by human explanations, a prediction model that utilizes generated explanations toward prediction faithfully, and a novel data diversity-based AL sampling strategy that benefits from the explanation annotations. Automated and human evaluations demonstrate the effectiveness of incorporating explanations into AL sampling and the improved human annotation efficiency and trustworthiness with our AL architecture. Add",
    "path": "papers/23/05/2305.12710.json",
    "total_tokens": 862,
    "translated_title": "超越标签：通过一种新的主动学习架构赋予人类标注者自然语言解释的能力",
    "translated_abstract": "在现实世界中，领域专家（如医生）很少仅注释决策标签而不提供解释。然而，现有的低资源学习技术，如主动学习（AL），旨在支持人类标注者，却大多只关注标签而忽视数据点的自然语言解释。本研究提出了一种新颖的AL架构，以支持专家在低资源场景中对标签和解释注释的实际需求。我们的AL架构利用一个解释生成模型，根据人类解释生成解释，一个利用生成解释进行预测的预测模型，以及一个基于数据多样性的AL采样策略，从解释注释中受益。自动化和人工评估证明了将解释纳入AL采样的有效性，以及我们的AL架构改善了人工注释的效率和可信度。",
    "tldr": "本研究提出了一种新颖的主动学习架构，通过整合解释生成模型和预测模型，并采用数据多样性的采样策略，支持低资源场景下专家对标签和解释的注释需求。",
    "en_tdlr": "This study proposes a novel active learning architecture that supports experts' need for label and explanation annotations in low-resource scenarios by integrating an explanation-generation model, a prediction model, and a data diversity-based sampling strategy."
}