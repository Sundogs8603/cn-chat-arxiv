{
    "title": "A Curriculum View of Robust Loss Functions. (arXiv:2305.02139v1 [cs.LG])",
    "abstract": "Robust loss functions are designed to combat the adverse impacts of label noise, whose robustness is typically supported by theoretical bounds agnostic to the training dynamics. However, these bounds may fail to characterize the empirical performance as it remains unclear why robust loss functions can underfit. We show that most loss functions can be rewritten into a form with the same class-score margin and different sample-weighting functions. The resulting curriculum view provides a straightforward analysis of the training dynamics, which helps attribute underfitting to diminished average sample weights and noise robustness to larger weights for clean samples. We show that simple fixes to the curriculums can make underfitting robust loss functions competitive with the state-of-the-art, and training schedules can substantially affect the noise robustness even with robust loss functions. Code is available at \\url{github}.",
    "link": "http://arxiv.org/abs/2305.02139",
    "context": "Title: A Curriculum View of Robust Loss Functions. (arXiv:2305.02139v1 [cs.LG])\nAbstract: Robust loss functions are designed to combat the adverse impacts of label noise, whose robustness is typically supported by theoretical bounds agnostic to the training dynamics. However, these bounds may fail to characterize the empirical performance as it remains unclear why robust loss functions can underfit. We show that most loss functions can be rewritten into a form with the same class-score margin and different sample-weighting functions. The resulting curriculum view provides a straightforward analysis of the training dynamics, which helps attribute underfitting to diminished average sample weights and noise robustness to larger weights for clean samples. We show that simple fixes to the curriculums can make underfitting robust loss functions competitive with the state-of-the-art, and training schedules can substantially affect the noise robustness even with robust loss functions. Code is available at \\url{github}.",
    "path": "papers/23/05/2305.02139.json",
    "total_tokens": 1030,
    "translated_title": "鲁棒损失函数的课程视角",
    "translated_abstract": "鲁棒损失函数旨在应对标签噪声的负面影响，其鲁棒性通常由与训练动态无关的理论界限支持。然而，这些界限可能无法表征实证性能，因为目前尚不清楚为什么鲁棒损失函数会欠拟合。我们表明，大多数损失函数可以重写成具有相同类-分数间隔和不同样本加权函数形式的形式。所得到的课程视角提供了对训练动态的直观分析，有助于将欠拟合归因于平均样本权重的降低和将噪声鲁棒性归因于对干净样本赋予较大的样本权重。我们表明，对课程视角进行简单的修正可以使欠拟合的鲁棒损失函数与最先进的方法竞争，而训练进度可以极大地影响噪声鲁棒性，即使采用鲁棒损失函数。代码可在\\url{github}中找到。",
    "tldr": "本文提出了鲁棒损失函数的课程视角，以更直观的方式分析训练动态，指出欠拟合的原因是由于平均样本权重的降低而引起的，对噪声鲁棒性的优化则是通过对干净样本赋予更大的样本权重来实现的。进一步的研究表明，通过简单的课程修正可以提高鲁棒损失函数的性能，而训练进度对于鲁棒性也有着非常重要的影响。",
    "en_tdlr": "This paper proposes a curriculum view of robust loss functions, which provides a more intuitive way to analyze the training dynamics and points out that the reason for underfitting is due to the decrease in average sample weights, while the optimization of noise robustness is achieved by assigning larger weights to clean samples. Further research shows that simple curriculum modifications can improve the performance of robust loss functions, and the training schedule also has a significant impact on robustness."
}