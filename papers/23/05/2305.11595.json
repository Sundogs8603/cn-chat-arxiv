{
    "title": "Diving into the Inter-Consistency of Large Language Models: An Insightful Analysis through Debate. (arXiv:2305.11595v1 [cs.CL])",
    "abstract": "Large language models (LLMs) have demonstrated impressive zero-shot or few-shot commonsense reasoning performance on various natural language processing (NLP) tasks. However, despite their strong commonsense reasoning abilities, LLMs still exhibit various kinds of inconsistency problems. While previous researches mainly focused on the self-consistency within a single LLM, we propose to explore the inter-consistency issue between two or more LLMs, which is critical for diverse and precise decision-making processes. Since the LLMs possess human-like intelligence after instruction tuning and reinforcement learning with human feedback (RLHF), we design a formal debate framework to delve into the inter-consistency problem among LLMs with three-stage debate: fair debate, mismatched debate, and roundtable debate. Through extensive experiments on 7 commonsense reasoning datasets, LLMs not only become more inter-consistent by compromising and refuting but also achieve higher performance and str",
    "link": "http://arxiv.org/abs/2305.11595",
    "context": "Title: Diving into the Inter-Consistency of Large Language Models: An Insightful Analysis through Debate. (arXiv:2305.11595v1 [cs.CL])\nAbstract: Large language models (LLMs) have demonstrated impressive zero-shot or few-shot commonsense reasoning performance on various natural language processing (NLP) tasks. However, despite their strong commonsense reasoning abilities, LLMs still exhibit various kinds of inconsistency problems. While previous researches mainly focused on the self-consistency within a single LLM, we propose to explore the inter-consistency issue between two or more LLMs, which is critical for diverse and precise decision-making processes. Since the LLMs possess human-like intelligence after instruction tuning and reinforcement learning with human feedback (RLHF), we design a formal debate framework to delve into the inter-consistency problem among LLMs with three-stage debate: fair debate, mismatched debate, and roundtable debate. Through extensive experiments on 7 commonsense reasoning datasets, LLMs not only become more inter-consistent by compromising and refuting but also achieve higher performance and str",
    "path": "papers/23/05/2305.11595.json",
    "total_tokens": 845,
    "translated_title": "大型语言模型中的内部一致性问题研究：通过辩论进行深入分析",
    "translated_abstract": "大型语言模型LLMs在各种自然语言处理NLP任务中展现出了惊人的零样本或少量样本通识推理性能。然而，尽管它们拥有强大的常识推理能力，但它们仍然存在各种不一致问题。本研究提出探索两个或多个LLMs之间的内部一致性问题，这对于不同和精确的决策过程至关重要。通过严格的辩论框架，在7个常识推理数据集上进行了广泛的实验。LLMs不仅通过妥协和反驳变得更具内部一致性，而且还实现了更高的性能和常识知识的结构化学习。",
    "tldr": "本文提出了通过辩论探究大型语言模型之间的内部一致性问题，实验证明通过严格的辩论框架可以提高模型性能和常识知识的结构化学习。",
    "en_tdlr": "This paper proposes to explore the inter-consistency issue between two or more large language models (LLMs) through formal debate, and the experiments on 7 commonsense reasoning datasets show that LLMs become more inter-consistent and achieve higher performance and structured learning of commonsense knowledge."
}