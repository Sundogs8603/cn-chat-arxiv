{
    "title": "ContrastNet: A Contrastive Learning Framework for Few-Shot Text Classification. (arXiv:2305.09269v1 [cs.CL])",
    "abstract": "Few-shot text classification has recently been promoted by the meta-learning paradigm which aims to identify target classes with knowledge transferred from source classes with sets of small tasks named episodes. Despite their success, existing works building their meta-learner based on Prototypical Networks are unsatisfactory in learning discriminative text representations between similar classes, which may lead to contradictions during label prediction. In addition, the tasklevel and instance-level overfitting problems in few-shot text classification caused by a few training examples are not sufficiently tackled. In this work, we propose a contrastive learning framework named ContrastNet to tackle both discriminative representation and overfitting problems in few-shot text classification. ContrastNet learns to pull closer text representations belonging to the same class and push away text representations belonging to different classes, while simultaneously introducing unsupervised con",
    "link": "http://arxiv.org/abs/2305.09269",
    "context": "Title: ContrastNet: A Contrastive Learning Framework for Few-Shot Text Classification. (arXiv:2305.09269v1 [cs.CL])\nAbstract: Few-shot text classification has recently been promoted by the meta-learning paradigm which aims to identify target classes with knowledge transferred from source classes with sets of small tasks named episodes. Despite their success, existing works building their meta-learner based on Prototypical Networks are unsatisfactory in learning discriminative text representations between similar classes, which may lead to contradictions during label prediction. In addition, the tasklevel and instance-level overfitting problems in few-shot text classification caused by a few training examples are not sufficiently tackled. In this work, we propose a contrastive learning framework named ContrastNet to tackle both discriminative representation and overfitting problems in few-shot text classification. ContrastNet learns to pull closer text representations belonging to the same class and push away text representations belonging to different classes, while simultaneously introducing unsupervised con",
    "path": "papers/23/05/2305.09269.json",
    "total_tokens": 839,
    "translated_title": "ContrastNet：一种用于少样本文本分类的对比学习框架",
    "translated_abstract": "近年来，元学习范式推动了少样本文本分类，旨在通过名为episodes的小任务，将知识从源类别转移到目标类别。然而，现有基于原型网络构建元学习器的方法，不能很好地学习相似类别之间的区分性文本表示，可能导致标签预测时的矛盾问题。此外，由于少量训练示例，少样本文本分类中的任务层和实例层过拟合问题也没有得到足够解决。因此，我们提出了一种名为ContrastNet的对比学习框架，以解决少样本文本分类中的区分性表示和过拟合问题。ContrastNet学习将属于同一类别的文本表示拉近，并将属于不同类别的文本表示推远，同时引入无监督的对比学习以促进表示学习。",
    "tldr": "ContrastNet是一种对比学习框架，旨在解决少样本文本分类中的区分性表示和过拟合问题，通过拉近相同类别的文本表示，并推远不同类别的文本表示来学习区分特征。",
    "en_tdlr": "ContrastNet is a contrastive learning framework that aims to address the discriminative representation and overfitting problems in few-shot text classification, by pulling closer similar text representations and pushing away different ones to learn distinguishing features, while introducing unsupervised contrastive learning."
}