{
    "title": "On the Tool Manipulation Capability of Open-source Large Language Models. (arXiv:2305.16504v1 [cs.CL])",
    "abstract": "Recent studies on software tool manipulation with large language models (LLMs) mostly rely on closed model APIs. The industrial adoption of these models is substantially constrained due to the security and robustness risks in exposing information to closed LLM API services. In this paper, we ask can we enhance open-source LLMs to be competitive to leading closed LLM APIs in tool manipulation, with practical amount of human supervision. By analyzing common tool manipulation failures, we first demonstrate that open-source LLMs may require training with usage examples, in-context demonstration and generation style regulation to resolve failures. These insights motivate us to revisit classical methods in LLM literature, and demonstrate that we can adapt them as model alignment with programmatic data generation, system prompts and in-context demonstration retrievers to enhance open-source LLMs for tool manipulation. To evaluate these techniques, we create the ToolBench, a tool manipulation ",
    "link": "http://arxiv.org/abs/2305.16504",
    "context": "Title: On the Tool Manipulation Capability of Open-source Large Language Models. (arXiv:2305.16504v1 [cs.CL])\nAbstract: Recent studies on software tool manipulation with large language models (LLMs) mostly rely on closed model APIs. The industrial adoption of these models is substantially constrained due to the security and robustness risks in exposing information to closed LLM API services. In this paper, we ask can we enhance open-source LLMs to be competitive to leading closed LLM APIs in tool manipulation, with practical amount of human supervision. By analyzing common tool manipulation failures, we first demonstrate that open-source LLMs may require training with usage examples, in-context demonstration and generation style regulation to resolve failures. These insights motivate us to revisit classical methods in LLM literature, and demonstrate that we can adapt them as model alignment with programmatic data generation, system prompts and in-context demonstration retrievers to enhance open-source LLMs for tool manipulation. To evaluate these techniques, we create the ToolBench, a tool manipulation ",
    "path": "papers/23/05/2305.16504.json",
    "total_tokens": 1170,
    "translated_title": "开源大语言模型对工具操作能力的研究",
    "translated_abstract": "近期对使用大型语言模型( LLMs)进行软件工具操作的研究大多依赖于封闭模型API。由于向封闭LLMAPI服务公开信息存在安全和鲁棒性风险，这些模型的工业采用受到了实质性限制。本文提出了一个问题，那就是我们能否在实践中加强开源LLMs的功能，使其在工具操作方面与领先的封闭LLM APIs竞争。通过分析常见的工具操作失败，我们首先展示了开源LLMs可能需要训练使用示例、上下文演示和生成样式规则来解决失败。这些见解激发我们重新审视LLM文献中的经典方法，并证明我们可以将它们作为程序数据生成的模型对齐、系统提示和上下文演示检索器来适应开源LLMs以实现工具操作的增强。为了评估这些技术，我们创建了ToolBench，一个工具操作能力测试套件，包括现有API和我们改进的开源LLMs。在三个不同的编程任务上，我们发现改进的开源LLMs能够达到或超越现有API的性能，其中包括对已编写的程序进行轻微修改等实际操作。此外，我们通过反向工程测试和黑盒测试进一步证明了模型的鲁棒性。",
    "tldr": "本研究探讨了如何通过训练使用示例、上下文演示和生成样式规则来加强开源LLMs以达到与封闭型API的工具操作性能同等甚至更优的效果，并通过ToolBench测试得出了实验结果，同时本文还证明了改进的开源LLMs的鲁棒性。",
    "en_tdlr": "This paper explores how to enhance open-source LLMs to be competitive to leading closed LLM APIs in software tool manipulation by training with usage examples, in-context demonstration, and generation style regulation. The authors use ToolBench to test and demonstrate that improved open-source LLMs can achieve comparable or better performance than existing APIs with practical operations, and further prove the robustness of the model through reverse engineering tests and black-box testing."
}