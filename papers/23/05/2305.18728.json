{
    "title": "Plug-in Performative Optimization. (arXiv:2305.18728v1 [cs.LG])",
    "abstract": "When predictions are performative, the choice of which predictor to deploy influences the distribution of future observations. The overarching goal in learning under performativity is to find a predictor that has low \\emph{performative risk}, that is, good performance on its induced distribution. One family of solutions for optimizing the performative risk, including bandits and other derivative-free methods, is agnostic to any structure in the performative feedback, leading to exceedingly slow convergence rates. A complementary family of solutions makes use of explicit \\emph{models} for the feedback, such as best-response models in strategic classification, enabling significantly faster rates. However, these rates critically rely on the feedback model being well-specified. In this work we initiate a study of the use of possibly \\emph{misspecified} models in performative prediction. We study a general protocol for making use of models, called \\emph{plug-in performative optimization}, a",
    "link": "http://arxiv.org/abs/2305.18728",
    "context": "Title: Plug-in Performative Optimization. (arXiv:2305.18728v1 [cs.LG])\nAbstract: When predictions are performative, the choice of which predictor to deploy influences the distribution of future observations. The overarching goal in learning under performativity is to find a predictor that has low \\emph{performative risk}, that is, good performance on its induced distribution. One family of solutions for optimizing the performative risk, including bandits and other derivative-free methods, is agnostic to any structure in the performative feedback, leading to exceedingly slow convergence rates. A complementary family of solutions makes use of explicit \\emph{models} for the feedback, such as best-response models in strategic classification, enabling significantly faster rates. However, these rates critically rely on the feedback model being well-specified. In this work we initiate a study of the use of possibly \\emph{misspecified} models in performative prediction. We study a general protocol for making use of models, called \\emph{plug-in performative optimization}, a",
    "path": "papers/23/05/2305.18728.json",
    "total_tokens": 813,
    "translated_title": "插件化表现优化",
    "translated_abstract": "当预测具有表现性时，选择哪个预测器部署将影响未来观测的分布。在表现性学习中，总体目标是找到具有低“表现性风险”的预测器，即在其引导的分布上表现良好。最优化表现性风险的一系列解决方案，包括赌徒算法和其他无导数方法，在表现性反馈中不知道任何结构，导致收敛速度极慢。补充的一系列解决方案利用反馈中的显式“模型”，例如战略分类中的最佳响应模型，可以实现更快的速率。然而，这些速率关键依赖于反馈模型的规范。在本研究中，我们启动了对在表现性预测中使用可能的“规范不正确”模型的研究。我们研究了一种使用模型的通用协议，称为“插件式表现优化”。",
    "tldr": "研究了一种可能“规范不正确”模型的通用协议，“插件式表现优化”。"
}