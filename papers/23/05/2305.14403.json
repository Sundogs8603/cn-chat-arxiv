{
    "title": "Layer-adaptive Structured Pruning Guided by Latency. (arXiv:2305.14403v1 [cs.CV])",
    "abstract": "Structured pruning can simplify network architecture and improve inference speed. Combined with the underlying hardware and inference engine in which the final model is deployed, better results can be obtained by using latency collaborative loss function to guide network pruning together. Existing pruning methods that optimize latency have demonstrated leading performance, however, they often overlook the hardware features and connection in the network. To address this problem, we propose a global importance score SP-LAMP(Structured Pruning Layer-Adaptive Magnitude-based Pruning) by deriving a global importance score LAMP from unstructured pruning to structured pruning. In SP-LAMP, each layer includes a filter with an SP-LAMP score of 1, and the remaining filters are grouped. We utilize a group knapsack solver to maximize the SP-LAMP score under latency constraints. In addition, we improve the strategy of collect the latency to make it more accurate. In particular, for ResNet50/ResNet1",
    "link": "http://arxiv.org/abs/2305.14403",
    "context": "Title: Layer-adaptive Structured Pruning Guided by Latency. (arXiv:2305.14403v1 [cs.CV])\nAbstract: Structured pruning can simplify network architecture and improve inference speed. Combined with the underlying hardware and inference engine in which the final model is deployed, better results can be obtained by using latency collaborative loss function to guide network pruning together. Existing pruning methods that optimize latency have demonstrated leading performance, however, they often overlook the hardware features and connection in the network. To address this problem, we propose a global importance score SP-LAMP(Structured Pruning Layer-Adaptive Magnitude-based Pruning) by deriving a global importance score LAMP from unstructured pruning to structured pruning. In SP-LAMP, each layer includes a filter with an SP-LAMP score of 1, and the remaining filters are grouped. We utilize a group knapsack solver to maximize the SP-LAMP score under latency constraints. In addition, we improve the strategy of collect the latency to make it more accurate. In particular, for ResNet50/ResNet1",
    "path": "papers/23/05/2305.14403.json",
    "total_tokens": 922,
    "translated_title": "考虑延迟的分层自适应结构裁剪",
    "translated_abstract": "结构裁剪可以简化网络结构并提高推理速度。通过结合部署最终模型的底层硬件和推理引擎，使用延迟协同损失函数来指导网络裁剪可以获得更好的结果。现有的优化延迟的裁剪方法已经展现出领先的性能，然而，它们经常忽略网络中的硬件特征和连接。为了解决这个问题，我们提出了一个全局重要性分数SP-LAMP(结构裁剪层自适应基于幅度的裁剪)，通过从非结构化裁剪到结构化裁剪中导出全局重要性分数LAMP来计算SP-LAMP。在SP-LAMP中，每个层都包括一个SP-LAMP分数为1的过滤器，其余的过滤器分组。我们利用分组背包求解器，在延迟约束下最大化SP-LAMP分数。此外，我们改进了收集延迟的策略，使其更加准确。特别是对于ResNet50/ResNet1。",
    "tldr": "提出了一种全局重要性分数SP-LAMP的分层自适应结构裁剪方法，利用分组背包求解器在延迟约束下最大化SP-LAMP分数来指导网络裁剪，以获得更好的优化结果和推理速度。",
    "en_tdlr": "A layer-adaptive structured pruning method with global importance score SP-LAMP is introduced, where a group knapsack solver is utilized to maximize the SP-LAMP score under latency constraints, guiding network pruning for better optimization results and inference speed."
}