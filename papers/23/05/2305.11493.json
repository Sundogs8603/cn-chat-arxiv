{
    "title": "Accelerating Convergence in Global Non-Convex Optimization with Reversible Diffusion. (arXiv:2305.11493v1 [math.OC])",
    "abstract": "Langevin Dynamics has been extensively employed in global non-convex optimization due to the concentration of its stationary distribution around the global minimum of the potential function at low temperatures. In this paper, we propose to utilize a more comprehensive class of stochastic processes, known as reversible diffusion, and apply the Euler-Maruyama discretization for global non-convex optimization. We design the diffusion coefficient to be larger when distant from the optimum and smaller when near, thus enabling accelerated convergence while regulating discretization error, a strategy inspired by landscape modifications. Our proposed method can also be seen as a time change of Langevin Dynamics, and we prove convergence with respect to KL divergence, investigating the trade-off between convergence speed and discretization error. The efficacy of our proposed method is demonstrated through numerical experiments.",
    "link": "http://arxiv.org/abs/2305.11493",
    "context": "Title: Accelerating Convergence in Global Non-Convex Optimization with Reversible Diffusion. (arXiv:2305.11493v1 [math.OC])\nAbstract: Langevin Dynamics has been extensively employed in global non-convex optimization due to the concentration of its stationary distribution around the global minimum of the potential function at low temperatures. In this paper, we propose to utilize a more comprehensive class of stochastic processes, known as reversible diffusion, and apply the Euler-Maruyama discretization for global non-convex optimization. We design the diffusion coefficient to be larger when distant from the optimum and smaller when near, thus enabling accelerated convergence while regulating discretization error, a strategy inspired by landscape modifications. Our proposed method can also be seen as a time change of Langevin Dynamics, and we prove convergence with respect to KL divergence, investigating the trade-off between convergence speed and discretization error. The efficacy of our proposed method is demonstrated through numerical experiments.",
    "path": "papers/23/05/2305.11493.json",
    "total_tokens": 864,
    "translated_title": "可逆扩散加速全局非凸优化的收敛",
    "translated_abstract": "在全局非凸优化中，由于在低温下其稳定分布集中在潜在函数的全局最小值点附近，Langevin动力学已被广泛地应用。在本文中，我们提出利用一类更为全面的随机过程——可逆扩散，以及应用欧拉-马鲁雅马分解进行全局非凸优化。我们设计的扩散系数在远离最优点时较大，在附近时较小，从而在调节离散误差的同时加速收敛，这种策略受到了景观修改的启发。我们提出的方法也可以看作是Langevin动力学的时间变换，并证明了收敛性就KL散度而言，研究了收敛速度和离散误差之间的权衡。我们通过数值实验证明了我们提出的方法的有效性。",
    "tldr": "本论文提出了一种基于可逆扩散的全局非凸优化方法，其通过在远离最优点时设置较大的扩散系数以及在附近时设置较小的扩散系数来加速收敛并调节离散误差，同时证明了其收敛性能。",
    "en_tdlr": "This paper proposes a global non-convex optimization method based on reversible diffusion, which uses a larger diffusion coefficient when far away from the optimum and a smaller diffusion coefficient when near to accelerate convergence and regulate discretization error. Convergence performance is proved, and numerical experiments demonstrate its effectiveness."
}