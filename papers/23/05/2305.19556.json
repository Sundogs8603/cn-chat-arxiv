{
    "title": "Exploring Phonetic Context in Lip Movement for Authentic Talking Face Generation. (arXiv:2305.19556v1 [cs.CV])",
    "abstract": "Talking face generation is the task of synthesizing a natural face synchronous to driving audio. Although much progress has been made in terms of visual quality, lip synchronization, and facial motion of the talking face, current works still struggle to overcome issues of crude and asynchronous lip movement, which can result in puppetry-like animation. We identify that the prior works commonly correlate lip movement with audio at the phone level. However, due to co-articulation, where an isolated phone is influenced by the preceding or following phones, the articulation of a phone varies upon the phonetic context. Therefore, modeling lip motion with the phonetic context can generate more spatio-temporally aligned and stable lip movement. In this respect, we investigate the phonetic context in lip motion for authentic talking face generation. We propose a Context-Aware Lip-Sync framework (CALS), which leverages phonetic context to generate more spatio-temporally aligned and stable lip m",
    "link": "http://arxiv.org/abs/2305.19556",
    "context": "Title: Exploring Phonetic Context in Lip Movement for Authentic Talking Face Generation. (arXiv:2305.19556v1 [cs.CV])\nAbstract: Talking face generation is the task of synthesizing a natural face synchronous to driving audio. Although much progress has been made in terms of visual quality, lip synchronization, and facial motion of the talking face, current works still struggle to overcome issues of crude and asynchronous lip movement, which can result in puppetry-like animation. We identify that the prior works commonly correlate lip movement with audio at the phone level. However, due to co-articulation, where an isolated phone is influenced by the preceding or following phones, the articulation of a phone varies upon the phonetic context. Therefore, modeling lip motion with the phonetic context can generate more spatio-temporally aligned and stable lip movement. In this respect, we investigate the phonetic context in lip motion for authentic talking face generation. We propose a Context-Aware Lip-Sync framework (CALS), which leverages phonetic context to generate more spatio-temporally aligned and stable lip m",
    "path": "papers/23/05/2305.19556.json",
    "total_tokens": 932,
    "translated_title": "探索唇部运动的语音上下文对真实说话人脸生成的影响",
    "translated_abstract": "说话人脸生成是将自然面部与驱动音频同步合成的任务。尽管在视觉质量、唇形同步和面部动作方面取得了很大进展，但当前的研究仍然难以解决粗糙和异步的唇部运动问题，这可能导致类似木偶动画的效果。本文发现，以往的作品通常将唇部运动与音频在不同的音素级别上进行相关联，然而，由于音素之间的协同发音（co-articulation）现象，即隔离的音素受前一个或下一个音素的影响，因此同一个音素的发音因音素上下文而异。因此，使用音素上下文模型可以生成更加空间和时间上对齐、稳定的唇部运动。基于此，我们研究了唇部运动中的语音上下文对于真实说话人脸生成的影响。我们提出了一种Context-Aware Lip-Sync框架（CALS），利用语音上下文生成更加空间和时间上对齐、稳定的唇部运动。",
    "tldr": "本研究探讨了语音上下文对真实说话人脸生成的影响，提出了一种Context-Aware Lip-Sync框架（CALS），可利用语音上下文生成更加准确、稳定的唇部运动。",
    "en_tdlr": "This paper explores the impact of phonetic context on authentic talking face generation and proposes a Context-Aware Lip-Sync framework (CALS) to generate more accurate and stable lip movement by leveraging phonetic context."
}