{
    "title": "Predicting Rare Events by Shrinking Towards Proportional Odds. (arXiv:2305.18700v1 [stat.ME])",
    "abstract": "Training classifiers is difficult with severe class imbalance, but many rare events are the culmination of a sequence with much more common intermediate outcomes. For example, in online marketing a user first sees an ad, then may click on it, and finally may make a purchase; estimating the probability of purchases is difficult because of their rarity. We show both theoretically and through data experiments that the more abundant data in earlier steps may be leveraged to improve estimation of probabilities of rare events. We present PRESTO, a relaxation of the proportional odds model for ordinal regression. Instead of estimating weights for one separating hyperplane that is shifted by separate intercepts for each of the estimated Bayes decision boundaries between adjacent pairs of categorical responses, we estimate separate weights for each of these transitions. We impose an L1 penalty on the differences between weights for the same feature in adjacent weight vectors in order to shrink ",
    "link": "http://arxiv.org/abs/2305.18700",
    "context": "Title: Predicting Rare Events by Shrinking Towards Proportional Odds. (arXiv:2305.18700v1 [stat.ME])\nAbstract: Training classifiers is difficult with severe class imbalance, but many rare events are the culmination of a sequence with much more common intermediate outcomes. For example, in online marketing a user first sees an ad, then may click on it, and finally may make a purchase; estimating the probability of purchases is difficult because of their rarity. We show both theoretically and through data experiments that the more abundant data in earlier steps may be leveraged to improve estimation of probabilities of rare events. We present PRESTO, a relaxation of the proportional odds model for ordinal regression. Instead of estimating weights for one separating hyperplane that is shifted by separate intercepts for each of the estimated Bayes decision boundaries between adjacent pairs of categorical responses, we estimate separate weights for each of these transitions. We impose an L1 penalty on the differences between weights for the same feature in adjacent weight vectors in order to shrink ",
    "path": "papers/23/05/2305.18700.json",
    "total_tokens": 892,
    "translated_title": "通过向比例减少预测罕见事件",
    "translated_abstract": "训练分类器在严重的类别不平衡下是困难的，但许多罕见事件是由许多常见的中间结果序列组成的。例如，在在线营销中，用户先看到广告，然后可能点击它，最后可能购买；由于它们的罕见性，估计购买的概率是困难的。我们通过理论和数据实验展示了早期步骤中更丰富的数据可能被利用来改善罕见事件的概率估计。我们提出了PRESTO，一种序数回归比例减少模型的松弛方法。我们不是为一个分离超平面估计权重，并通过每个估计Bayes决策边界之间的分类反应对应的单独拦截进行平移。我们估计每次这些转换的单独权重。我们对相邻权向量中相同特征之间的差异施加L1惩罚，以缩小这些权重的差距。",
    "tldr": "本文提出了一种序数回归比例减少模型的松弛方法PRESTO，通过对相邻权向量中相同特征之间的差异施加L1惩罚，利用先前更丰富的数据来改善罕见事件的概率估计。"
}