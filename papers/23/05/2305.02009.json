{
    "title": "fairml: A Statistician's Take on Fair Machine Learning Modelling. (arXiv:2305.02009v1 [stat.ML])",
    "abstract": "The adoption of machine learning in applications where it is crucial to ensure fairness and accountability has led to a large number of model proposals in the literature, largely formulated as optimisation problems with constraints reducing or eliminating the effect of sensitive attributes on the response. While this approach is very flexible from a theoretical perspective, the resulting models are somewhat black-box in nature: very little can be said about their statistical properties, what are the best practices in their applied use, and how they can be extended to problems other than those they were originally designed for. Furthermore, the estimation of each model requires a bespoke implementation involving an appropriate solver which is less than desirable from a software engineering perspective.  In this paper, we describe the fairml R package which implements our previous work (Scutari, Panero, and Proissl 2022) and related models in the literature. fairml is designed around cla",
    "link": "http://arxiv.org/abs/2305.02009",
    "context": "Title: fairml: A Statistician's Take on Fair Machine Learning Modelling. (arXiv:2305.02009v1 [stat.ML])\nAbstract: The adoption of machine learning in applications where it is crucial to ensure fairness and accountability has led to a large number of model proposals in the literature, largely formulated as optimisation problems with constraints reducing or eliminating the effect of sensitive attributes on the response. While this approach is very flexible from a theoretical perspective, the resulting models are somewhat black-box in nature: very little can be said about their statistical properties, what are the best practices in their applied use, and how they can be extended to problems other than those they were originally designed for. Furthermore, the estimation of each model requires a bespoke implementation involving an appropriate solver which is less than desirable from a software engineering perspective.  In this paper, we describe the fairml R package which implements our previous work (Scutari, Panero, and Proissl 2022) and related models in the literature. fairml is designed around cla",
    "path": "papers/23/05/2305.02009.json",
    "total_tokens": 867,
    "translated_title": "公平机器学习建模的统计学观点",
    "translated_abstract": "机器学习在关键保障公平和问责的应用中的采用，导致文献中出现了大量模型建议，主要以约束条件的优化问题形式减少或消除敏感属性对响应的影响。虽然这种方法从理论上来看非常灵活，但所得的模型有些黑盒性质：很少有关于其统计属性的表述，关于其应用最佳实践的讨论，以及如何将其扩展到其他问题而不是其最初设计用途的研究。此外，估计每个模型需要特定的实现，涉及适当的求解器，从软件工程角度来看是不太理想的。在本文中，我们介绍了fairml R软件包，该软件包实现了我们之前的工作（Scutari，Panero和Proissl 2022）以及文献中的相关模型。fairml是围绕分类、回归和核估计的统计方法设计的。",
    "tldr": "这篇论文介绍了一个基于统计方法的公平机器学习建模包fairml，该包实现了分类、回归和核估计等方法，可以在保障公平和问责方面提供帮助。",
    "en_tdlr": "This paper introduces fairml, a statistical approach to fair machine learning modeling. The fairml R package implements various statistical methods including classification, regression, and kernel estimation, which can provide assistance in ensuring fairness and accountability."
}