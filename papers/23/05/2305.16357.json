{
    "title": "EDM3: Event Detection as Multi-task Text Generation. (arXiv:2305.16357v1 [cs.CL])",
    "abstract": "Event detection refers to identifying event occurrences in a text and comprises of two subtasks; event identification and classification. We present EDM3, a novel approach for Event Detection that formulates three generative tasks: identification, classification, and combined detection. We show that EDM3 helps to learn transferable knowledge that can be leveraged to perform Event Detection and its subtasks concurrently, mitigating the error propagation inherent in pipelined approaches. Unlike previous dataset- or domain-specific approaches, EDM3 utilizes the existing knowledge of language models, allowing it to be trained over any classification schema. We evaluate EDM3 on multiple event detection datasets: RAMS, WikiEvents, MAVEN, and MLEE, showing that EDM3 outperforms 1) single-task performance by 8.4% on average and 2) multi-task performance without instructional prompts by 2.4% on average. We obtain SOTA results on RAMS (71.3% vs. 65.1% F-1) and competitive performance on other da",
    "link": "http://arxiv.org/abs/2305.16357",
    "context": "Title: EDM3: Event Detection as Multi-task Text Generation. (arXiv:2305.16357v1 [cs.CL])\nAbstract: Event detection refers to identifying event occurrences in a text and comprises of two subtasks; event identification and classification. We present EDM3, a novel approach for Event Detection that formulates three generative tasks: identification, classification, and combined detection. We show that EDM3 helps to learn transferable knowledge that can be leveraged to perform Event Detection and its subtasks concurrently, mitigating the error propagation inherent in pipelined approaches. Unlike previous dataset- or domain-specific approaches, EDM3 utilizes the existing knowledge of language models, allowing it to be trained over any classification schema. We evaluate EDM3 on multiple event detection datasets: RAMS, WikiEvents, MAVEN, and MLEE, showing that EDM3 outperforms 1) single-task performance by 8.4% on average and 2) multi-task performance without instructional prompts by 2.4% on average. We obtain SOTA results on RAMS (71.3% vs. 65.1% F-1) and competitive performance on other da",
    "path": "papers/23/05/2305.16357.json",
    "total_tokens": 942,
    "translated_title": "EDM3：事件检测作为多任务文本生成",
    "translated_abstract": "事件检测指的是在文本中识别事件出现并包括两个子任务；事件识别和事件分类。我们提出了EDM3，一种新颖的事件检测方法，其构建了三个生成式任务：识别、分类和联合检测。我们展示EDM3能够帮助学习可转移的知识，使其能够同时执行事件检测及其子任务，减少了流水线方法中存在的误差传播。与先前基于数据集或特定领域的方法不同，EDM3利用了语言模型的现有知识，使其能够在任何分类模式上进行训练。我们在多个事件检测数据集上对EDM3进行了评估：RAMS、WikiEvents、MAVEN和MLEE，表明EDM3的平均单任务性能优于8.4％，平均无需指示性提示的多任务性能优于2.4％。我们在RAMS上获得了SOTA的结果（71.3％与65.1％的F-1），在其他数据集上也表现出了有竞争力的性能.",
    "tldr": "EDM3是一种新颖的事件检测方法，可以同时执行事件检测及其子任务，减少了误差传播。与先前基于数据集或特定领域的方法不同，EDM3利用现有语言模型的知识进行训练，在多个事件检测数据集上性能表现优异。",
    "en_tdlr": "EDM3 is a novel approach for event detection that mitigates error propagation by performing event detection and its subtasks concurrently. It utilizes existing language model knowledge for training, showing superior performance on multiple event detection datasets compared to previous dataset- or domain-specific methods."
}