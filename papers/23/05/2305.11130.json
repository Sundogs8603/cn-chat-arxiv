{
    "title": "SimOAP: Improve Coherence and Consistency in Persona-based Dialogue Generation via Over-sampling and Post-evaluation. (arXiv:2305.11130v2 [cs.AI] UPDATED)",
    "abstract": "Language models trained on large-scale corpora can generate remarkably fluent results in open-domain dialogue. However, for the persona-based dialogue generation task, consistency and coherence are also key factors, which are great challenges for language models. Existing works mainly focus on valuable data filtering, model structure modifying, or objective function designing, while their improvements are limited and hard to generalize to all types of pre-trained language models. However, we find that language models can produce consistent and coherent responses if we consider enough generations. Thus, the problems lay in large-scale response generation and target response selection. In this work, a simple but effective two-stage SimOAP strategy is proposed, i.e., over-sampling and post-evaluation. The over-sampling stage takes large-scale responses from existing trained models efficiently via off-the-shelf distilling and compressing methods, and the post-evaluation stage selects a goo",
    "link": "http://arxiv.org/abs/2305.11130",
    "context": "Title: SimOAP: Improve Coherence and Consistency in Persona-based Dialogue Generation via Over-sampling and Post-evaluation. (arXiv:2305.11130v2 [cs.AI] UPDATED)\nAbstract: Language models trained on large-scale corpora can generate remarkably fluent results in open-domain dialogue. However, for the persona-based dialogue generation task, consistency and coherence are also key factors, which are great challenges for language models. Existing works mainly focus on valuable data filtering, model structure modifying, or objective function designing, while their improvements are limited and hard to generalize to all types of pre-trained language models. However, we find that language models can produce consistent and coherent responses if we consider enough generations. Thus, the problems lay in large-scale response generation and target response selection. In this work, a simple but effective two-stage SimOAP strategy is proposed, i.e., over-sampling and post-evaluation. The over-sampling stage takes large-scale responses from existing trained models efficiently via off-the-shelf distilling and compressing methods, and the post-evaluation stage selects a goo",
    "path": "papers/23/05/2305.11130.json",
    "total_tokens": 1016,
    "translated_title": "SimOAP：通过过采样和后评估提高角色扮演对话生成中的连贯性和一致性",
    "translated_abstract": "在大规模语料库上训练的语言模型在开放域对话中可以生成非常流畅的结果。然而，在以角色为基础的对话生成任务中，连贯性和一致性也是关键因素，这对语言模型来说是巨大的挑战。现有的工作主要集中在有价值数据过滤、模型结构修改或目标函数设计上，但它们的改进有限，并且很难推广到所有类型的预训练语言模型。然而，我们发现，如果我们考虑足够多的生成，语言模型可以产生连贯和一致的响应。因此，问题在于大规模响应生成和目标响应选择。本文提出了一种简单但有效的两阶段SimOAP策略，即过采样和后评估。过采样阶段通过现有训练模型的现成蒸馏和压缩方法高效地获取大规模响应，后评估阶段在过采样生成的候选响应中选择一个好的响应，并提高最终响应的连贯性和一致性。该方法在三个公共角色扮演对话基准上取得了最先进的结果。",
    "tldr": "本文提出了一种简单而有效的两阶段SimOAP策略，通过过采样和后评估来提高角色扮演对话生成中的连贯性和一致性，并在三个公共角色扮演对话基准上取得了最先进的结果。",
    "en_tdlr": "A simple yet effective two-stage SimOAP strategy is proposed to improve coherence and consistency in persona-based dialogue generation via over-sampling and post-evaluation, achieving state-of-the-art results on three public benchmarks."
}