{
    "title": "Beyond Classification: Financial Reasoning in State-of-the-Art Language Models. (arXiv:2305.01505v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs), consisting of 100 billion or more parameters, have demonstrated remarkable ability in complex multi-step reasoning tasks. However, the application of such generic advancements has been limited to a few fields, such as clinical or legal, with the field of financial reasoning remaining largely unexplored. To the best of our knowledge, the ability of LLMs to solve financial reasoning problems has never been dealt with, and whether it can be performed at any scale remains unknown. To address this knowledge gap, this research presents a comprehensive investigation into the potential application of LLMs in the financial domain. The investigation includes a detailed exploration of a range of subjects, including task formulation, synthetic data generation, prompting methods, and evaluation capability. Furthermore, the study benchmarks various GPT variants with parameter scales ranging from 2.8B to 13B, with and without instruction tuning, on diverse dataset sizes.",
    "link": "http://arxiv.org/abs/2305.01505",
    "context": "Title: Beyond Classification: Financial Reasoning in State-of-the-Art Language Models. (arXiv:2305.01505v1 [cs.CL])\nAbstract: Large Language Models (LLMs), consisting of 100 billion or more parameters, have demonstrated remarkable ability in complex multi-step reasoning tasks. However, the application of such generic advancements has been limited to a few fields, such as clinical or legal, with the field of financial reasoning remaining largely unexplored. To the best of our knowledge, the ability of LLMs to solve financial reasoning problems has never been dealt with, and whether it can be performed at any scale remains unknown. To address this knowledge gap, this research presents a comprehensive investigation into the potential application of LLMs in the financial domain. The investigation includes a detailed exploration of a range of subjects, including task formulation, synthetic data generation, prompting methods, and evaluation capability. Furthermore, the study benchmarks various GPT variants with parameter scales ranging from 2.8B to 13B, with and without instruction tuning, on diverse dataset sizes.",
    "path": "papers/23/05/2305.01505.json",
    "total_tokens": 920,
    "translated_title": "超越分类：最先进的语言模型中的财务推理",
    "translated_abstract": "大语言模型(LLMs)由1000亿及以上的参数组成，在复杂的多步推理任务中表现出了非凡的能力。然而，这种通用的进展应用在很少领域中，例如临床或法律领域，而财务推理领域基本上未被探索。据我们所知，LLMs解决财务推理问题的能力从未被研究过，并且它是否可以在任何规模上完成仍未知。为了填补这一知识空白，本研究对LLMs在财务领域的潜在应用进行了全面调查。调查包括对一系列主题的详细探讨，包括任务制定，合成数据生成，提示方法和评估能力。此外，本研究在不同的数据集大小上对参数规模为2.8B至13B的各种GPT变体进行基准测试，包括有无指导调整。",
    "tldr": "本研究探讨了大语言模型在财务推理领域的潜在应用，对任务制定、数据生成、提示方法和评估能力等方面进行了详细研究，最终在各种数据集大小上对参数规模为2.8B至13B的各种GPT变体进行基准测试。"
}