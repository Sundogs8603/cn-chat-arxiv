{
    "title": "SAIL: Search-Augmented Instruction Learning. (arXiv:2305.15225v2 [cs.CL] UPDATED)",
    "abstract": "Large language models (LLMs) have been significantly improved by instruction fine-tuning, but still lack transparency and the ability to utilize up-to-date knowledge and information. In this work, we propose search-augmented instruction learning (SAIL), which grounds the language generation and instruction following abilities on complex search results generated by in-house and external search engines. With an instruction tuning corpus, we collect search results for each training case from different search APIs and domains, and construct a new search-grounded training set containing \\textit{(instruction, grounding information, response)} triplets. We then fine-tune the LLaMA-7B model on the constructed training set. Since the collected results contain unrelated and disputing languages, the model needs to learn to ground on trustworthy search results, filter out distracting passages, and generate the target response. The search result-denoising process entails explicit trustworthy inform",
    "link": "http://arxiv.org/abs/2305.15225",
    "context": "Title: SAIL: Search-Augmented Instruction Learning. (arXiv:2305.15225v2 [cs.CL] UPDATED)\nAbstract: Large language models (LLMs) have been significantly improved by instruction fine-tuning, but still lack transparency and the ability to utilize up-to-date knowledge and information. In this work, we propose search-augmented instruction learning (SAIL), which grounds the language generation and instruction following abilities on complex search results generated by in-house and external search engines. With an instruction tuning corpus, we collect search results for each training case from different search APIs and domains, and construct a new search-grounded training set containing \\textit{(instruction, grounding information, response)} triplets. We then fine-tune the LLaMA-7B model on the constructed training set. Since the collected results contain unrelated and disputing languages, the model needs to learn to ground on trustworthy search results, filter out distracting passages, and generate the target response. The search result-denoising process entails explicit trustworthy inform",
    "path": "papers/23/05/2305.15225.json",
    "total_tokens": 985,
    "translated_title": "SAIL: Search-Augmented Instruction Learning （SAIL：搜索增强的指令学习）",
    "translated_abstract": "大型语言模型通过指令微调得到了显著改进，但仍缺乏透明性和利用最新知识和信息的能力。在本文中，我们提出了搜索增强的指令学习（SAIL），它以内部和外部搜索引擎生成的搜索结果为基础，实现了语言生成和指令跟踪能力。通过指令微调语料库，我们从不同的搜索API和领域收集每个训练用例的搜索结果，并构建了一个包含（指令，接地信息，响应）三元组的新的搜索基础训练集。然后在构建的训练集上对LLaMA-7B模型进行微调。由于收集的结果包含不相关和争议的语言，模型需要学习在 可信赖 的搜索结果上进行接地，过滤出干扰的段落，并生成目标响应。搜索结果去噪过程需要显式的、可信任的信息。",
    "tldr": "这篇论文提出了一种称为SAIL的搜索增强指令学习方法，该方法以内部和外部搜索引擎生成的搜索结果为基础，实现了语言生成和指令跟踪能力。通过构建一个包含指令、接地信息和响应三元组的新的搜索基础训练集来实现这一目标。在训练过程中，模型需要学习过滤干扰段落并生成目标响应。",
    "en_tdlr": "This paper proposes a search-augmented instruction learning method called SAIL, which utilizes complex search results generated by internal and external engines to enhance the language generation and instruction following abilities of large language models. It involves constructing a new search-grounded training set containing (instruction, grounding information, response) triplets and training the LLaMA-7B model on it. The model learns to filter out distracting passages and generate target responses by grounding on trustworthy search results."
}