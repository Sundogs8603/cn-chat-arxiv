{
    "title": "Adversarial Speaker Disentanglement Using Unannotated External Data for Self-supervised Representation Based Voice Conversion. (arXiv:2305.09167v1 [cs.SD])",
    "abstract": "Nowadays, recognition-synthesis-based methods have been quite popular with voice conversion (VC). By introducing linguistics features with good disentangling characters extracted from an automatic speech recognition (ASR) model, the VC performance achieved considerable breakthroughs. Recently, self-supervised learning (SSL) methods trained with a large-scale unannotated speech corpus have been applied to downstream tasks focusing on the content information, which is suitable for VC tasks. However, a huge amount of speaker information in SSL representations degrades timbre similarity and the quality of converted speech significantly. To address this problem, we proposed a high-similarity any-to-one voice conversion method with the input of SSL representations. We incorporated adversarial training mechanisms in the synthesis module using external unannotated corpora. Two auxiliary discriminators were trained to distinguish whether a sequence of mel-spectrograms has been converted by the ",
    "link": "http://arxiv.org/abs/2305.09167",
    "context": "Title: Adversarial Speaker Disentanglement Using Unannotated External Data for Self-supervised Representation Based Voice Conversion. (arXiv:2305.09167v1 [cs.SD])\nAbstract: Nowadays, recognition-synthesis-based methods have been quite popular with voice conversion (VC). By introducing linguistics features with good disentangling characters extracted from an automatic speech recognition (ASR) model, the VC performance achieved considerable breakthroughs. Recently, self-supervised learning (SSL) methods trained with a large-scale unannotated speech corpus have been applied to downstream tasks focusing on the content information, which is suitable for VC tasks. However, a huge amount of speaker information in SSL representations degrades timbre similarity and the quality of converted speech significantly. To address this problem, we proposed a high-similarity any-to-one voice conversion method with the input of SSL representations. We incorporated adversarial training mechanisms in the synthesis module using external unannotated corpora. Two auxiliary discriminators were trained to distinguish whether a sequence of mel-spectrograms has been converted by the ",
    "path": "papers/23/05/2305.09167.json",
    "total_tokens": 725,
    "tldr": "本文提出了一种利用无标注外部语音数据进行对抗说话者分解和以自监督为基础的表征语音转换的方法。通过引入从自动语音识别 (ASR) 模型中提取的良好分解特征，与语音识别和合成相结合，本文的方法在语音转换方面取得了显着的突破。同时，通过对合成模块引入对抗训练机制，并利用外部无标注语音数据对其进行训练，可以在保持语音一致性的同时获得更好的转换效果。"
}