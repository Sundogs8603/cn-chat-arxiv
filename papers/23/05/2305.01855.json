{
    "title": "Multimodal Data Augmentation for Image Captioning using Diffusion Models. (arXiv:2305.01855v1 [cs.CV])",
    "abstract": "Image captioning, an important vision-language task, often requires a tremendous number of finely labeled image-caption pairs for learning the underlying alignment between images and texts. In this paper, we proposed a multimodal data augmentation method, leveraging a recent text-to-image model called Stable Diffusion, to expand the training set via high-quality generation of image-caption pairs. Extensive experiments on the MS COCO dataset demonstrate the advantages of our approach over several benchmark methods, and particularly a significant boost when having fewer training instances. In addition, models trained on our augmented datasets also outperform prior unpaired image captioning methods by a large margin. Finally, further improvement regarding the training efficiency and effectiveness can be obtained after intentionally filtering the generated data based on quality assessment.",
    "link": "http://arxiv.org/abs/2305.01855",
    "context": "Title: Multimodal Data Augmentation for Image Captioning using Diffusion Models. (arXiv:2305.01855v1 [cs.CV])\nAbstract: Image captioning, an important vision-language task, often requires a tremendous number of finely labeled image-caption pairs for learning the underlying alignment between images and texts. In this paper, we proposed a multimodal data augmentation method, leveraging a recent text-to-image model called Stable Diffusion, to expand the training set via high-quality generation of image-caption pairs. Extensive experiments on the MS COCO dataset demonstrate the advantages of our approach over several benchmark methods, and particularly a significant boost when having fewer training instances. In addition, models trained on our augmented datasets also outperform prior unpaired image captioning methods by a large margin. Finally, further improvement regarding the training efficiency and effectiveness can be obtained after intentionally filtering the generated data based on quality assessment.",
    "path": "papers/23/05/2305.01855.json",
    "total_tokens": 847,
    "translated_title": "基于扩增数据的扩散模型多模态图像描述",
    "translated_abstract": "图像描述是一项重要的视觉-语言任务，常常需要大量精细标注的图像-描述对来学习图像和文本之间的对齐关系。本文提出了一种多模态数据扩增方法，利用最新的文本到图像模型 Stable Diffusion 来扩展训练集，高质量生成图像-描述对。在 MS COCO 数据集上的广泛实验表明，我们的方法优于几个基准方法，在训练数据较少的情况下尤其表现出显著的提升。此外，我们扩增数据集训练的模型在性能上也超过了先前的未配对图像描述方法。最后，通过质量评估有意地筛选生成的数据，可进一步提高训练效率和效果。",
    "tldr": "本文提出了一种基于扩增数据的扩散模型多模态图像描述方法，用于生成高质量的图像-描述对，并在 MS COCO 数据集上实验表明其优于几个基准方法，并且在训练数据较少的情况下表现出显著的提升。"
}