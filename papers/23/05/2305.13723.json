{
    "title": "PromptClass: Weakly-Supervised Text Classification with Prompting Enhanced Noise-Robust Self-Training. (arXiv:2305.13723v1 [cs.CL])",
    "abstract": "Recently proposed weakly-supervised text classification settings train a classifier using the label name of each target class as the only supervision. Such weakly-supervised settings have been gaining increasing attention since they can largely reduce human annotation efforts compared to fully-supervised and semi-supervised settings. Most existing methods follow the strategy that first uses the label names as static features to generate pseudo labels, which are then used for classifier training. While reasonable, such a commonly adopted framework suffers from two limitations: (1) words can have different meanings in different contexts, so using label names for context-free matching can induce very noisy pseudo labels; and (2) the errors made in the pseudo label generation stage will directly propagate to the classifier training stage without a chance of being corrected. In this paper, we propose a new method, PromptClass, consisting of two modules: (1) a pseudo label acquisition module",
    "link": "http://arxiv.org/abs/2305.13723",
    "context": "Title: PromptClass: Weakly-Supervised Text Classification with Prompting Enhanced Noise-Robust Self-Training. (arXiv:2305.13723v1 [cs.CL])\nAbstract: Recently proposed weakly-supervised text classification settings train a classifier using the label name of each target class as the only supervision. Such weakly-supervised settings have been gaining increasing attention since they can largely reduce human annotation efforts compared to fully-supervised and semi-supervised settings. Most existing methods follow the strategy that first uses the label names as static features to generate pseudo labels, which are then used for classifier training. While reasonable, such a commonly adopted framework suffers from two limitations: (1) words can have different meanings in different contexts, so using label names for context-free matching can induce very noisy pseudo labels; and (2) the errors made in the pseudo label generation stage will directly propagate to the classifier training stage without a chance of being corrected. In this paper, we propose a new method, PromptClass, consisting of two modules: (1) a pseudo label acquisition module",
    "path": "papers/23/05/2305.13723.json",
    "total_tokens": 820,
    "translated_title": "PromptClass: 利用提示增强噪声鲁棒的自训练，进行弱监督文本分类",
    "translated_abstract": "最近提出的弱监督文本分类模型，仅使用每个目标类别的标签名作为唯一的监督。这种方法相比于完全监督和半监督模型能大大减少人类注释的工作量，因此受到了越来越多的关注。该方法主要使用标签名来生成伪标签，然后用于训练分类器。然而，由于同一单词在不同的上下文中会有不同的含义，因此仅仅使用标签名进行匹配会导致非常嘈杂的伪标签。此外，在伪标签生成阶段产生的错误将直接传播到分类器训练阶段，无法被纠正。本文提出了一种新的方法PromptClass，包含两个模块：(1)伪标签获取模块",
    "tldr": "提出了一种新的叫PromptClass的弱监督文本分类方法，通过利用提示增强学习，生成噪声鲁棒性更强的伪标签和自我训练。",
    "en_tdlr": "PromptClass is a weakly-supervised text classification method that enhances noise-robust self-training with prompts to generate more accurate pseudo labels in context-free matching."
}