{
    "title": "DeepGate2: Functionality-Aware Circuit Representation Learning. (arXiv:2305.16373v1 [cs.LG])",
    "abstract": "Circuit representation learning aims to obtain neural representations of circuit elements and has emerged as a promising research direction that can be applied to various EDA and logic reasoning tasks. Existing solutions, such as DeepGate, have the potential to embed both circuit structural information and functional behavior. However, their capabilities are limited due to weak supervision or flawed model design, resulting in unsatisfactory performance in downstream tasks. In this paper, we introduce DeepGate2, a novel functionality-aware learning framework that significantly improves upon the original DeepGate solution in terms of both learning effectiveness and efficiency. Our approach involves using pairwise truth table differences between sampled logic gates as training supervision, along with a well-designed and scalable loss function that explicitly considers circuit functionality. Additionally, we consider inherent circuit characteristics and design an efficient one-round graph ",
    "link": "http://arxiv.org/abs/2305.16373",
    "context": "Title: DeepGate2: Functionality-Aware Circuit Representation Learning. (arXiv:2305.16373v1 [cs.LG])\nAbstract: Circuit representation learning aims to obtain neural representations of circuit elements and has emerged as a promising research direction that can be applied to various EDA and logic reasoning tasks. Existing solutions, such as DeepGate, have the potential to embed both circuit structural information and functional behavior. However, their capabilities are limited due to weak supervision or flawed model design, resulting in unsatisfactory performance in downstream tasks. In this paper, we introduce DeepGate2, a novel functionality-aware learning framework that significantly improves upon the original DeepGate solution in terms of both learning effectiveness and efficiency. Our approach involves using pairwise truth table differences between sampled logic gates as training supervision, along with a well-designed and scalable loss function that explicitly considers circuit functionality. Additionally, we consider inherent circuit characteristics and design an efficient one-round graph ",
    "path": "papers/23/05/2305.16373.json",
    "total_tokens": 840,
    "translated_title": "DeepGate2: 功能感知的电路表示学习",
    "translated_abstract": "电路表示学习旨在获得电路元件的神经表示，并已成为可以应用于各种EDA和逻辑推理任务的有前途的研究方向。现有的解决方案，例如DeepGate，可以嵌入电路结构信息和功能行为。然而，它们的能力受到弱监督或错误的模型设计的限制，导致下游任务的性能令人不满意。在本文中，我们介绍了DeepGate2，这是一个新颖的功能感知学习框架，其在学习效果和效率方面显着优于原DeepGate解决方案。我们的方法涉及使用样本逻辑门之间的成对真值表差异作为训练监督，以及一个经过精心设计和可扩展的损失函数，明确考虑电路功能。此外，我们考虑电路的固有特性，并设计了一个高效的一轮图表达方法，以实现更好的性能。",
    "tldr": "本文介绍了DeepGate2, 一个新的功能感知学习框架，其通过利用成对真值表差异作为训练监督，明确考虑电路功能，来提高电路表示学习的学习效果和效率。",
    "en_tdlr": "This paper introduces DeepGate2, a novel functionality-aware learning framework, which improves the learning effectiveness and efficiency of circuit representation learning by using pairwise truth table differences as training supervision, explicitly considering circuit functionality."
}