{
    "title": "Evaluating Prompt-based Question Answering for Object Prediction in the Open Research Knowledge Graph. (arXiv:2305.12900v2 [cs.CL] UPDATED)",
    "abstract": "There have been many recent investigations into prompt-based training of transformer language models for new text genres in low-resource settings. The prompt-based training approach has been found to be effective in generalizing pre-trained or fine-tuned models for transfer to resource-scarce settings. This work, for the first time, reports results on adopting prompt-based training of transformers for \\textit{scholarly knowledge graph object prediction}. The work is unique in the following two main aspects. 1) It deviates from the other works proposing entity and relation extraction pipelines for predicting objects of a scholarly knowledge graph. 2) While other works have tested the method on text genera relatively close to the general knowledge domain, we test the method for a significantly different domain, i.e. scholarly knowledge, in turn testing the linguistic, probabilistic, and factual generalizability of these large-scale transformer models. We find that (i) per expectations, t",
    "link": "http://arxiv.org/abs/2305.12900",
    "context": "Title: Evaluating Prompt-based Question Answering for Object Prediction in the Open Research Knowledge Graph. (arXiv:2305.12900v2 [cs.CL] UPDATED)\nAbstract: There have been many recent investigations into prompt-based training of transformer language models for new text genres in low-resource settings. The prompt-based training approach has been found to be effective in generalizing pre-trained or fine-tuned models for transfer to resource-scarce settings. This work, for the first time, reports results on adopting prompt-based training of transformers for \\textit{scholarly knowledge graph object prediction}. The work is unique in the following two main aspects. 1) It deviates from the other works proposing entity and relation extraction pipelines for predicting objects of a scholarly knowledge graph. 2) While other works have tested the method on text genera relatively close to the general knowledge domain, we test the method for a significantly different domain, i.e. scholarly knowledge, in turn testing the linguistic, probabilistic, and factual generalizability of these large-scale transformer models. We find that (i) per expectations, t",
    "path": "papers/23/05/2305.12900.json",
    "total_tokens": 1068,
    "translated_title": "基于提示的问题回答应用于开放研究知识图谱中的对象预测评估",
    "translated_abstract": "最近对于基于提示的训练方法在低资源环境下对转换器语言模型进行新文本体裁训练的调查有很多。发现基于提示的训练方法对于通用预训练或微调模型以适应资源缺乏的环境有很好的效果。本研究首次报道了采用基于提示训练transformers进行“学术知识图谱对象预测”的结果。该研究具有以下两个主要特点。1）它偏离了其他提出用于预测学术知识图谱对象的实体和关系提取流程的研究。2）在其他研究中测试了该方法对于与通用知识领域相对接近的文本体裁，而我们测试了该方法适用于显著不同的学术知识领域，从而测试这些大规模transformers模型的语言，概率和事实的普适性。我们发现（i）符合预期，使用提示进行微调的transformers优于基线；（ii）与先前研究中看到的模式不同，预先训练的transformers并不能始终足以胜任学术对象预测的任务，结果表明提示确实有助于改进抽取预训练模型所获得的语义信息的泛化能力。",
    "tldr": "本研究采用基于提示的训练方法，在学术知识图谱对象预测领域进行了大规模transformers模型的评估和测试，发现提示的使用可以改进pre-trained transformers的泛化能力。",
    "en_tdlr": "This study evaluates and tests the effectiveness of prompt-based training of large-scale Transformers models for scholarly knowledge graph object prediction, and finds that the use of prompts improves the generalizability of pre-trained Transformers beyond semantic information obtained through pre-training."
}