{
    "title": "Improving Classifier Robustness through Active Generation of Pairwise Counterfactuals. (arXiv:2305.13535v1 [cs.CL])",
    "abstract": "Counterfactual Data Augmentation (CDA) is a commonly used technique for improving robustness in natural language classifiers. However, one fundamental challenge is how to discover meaningful counterfactuals and efficiently label them, with minimal human labeling cost. Most existing methods either completely rely on human-annotated labels, an expensive process which limits the scale of counterfactual data, or implicitly assume label invariance, which may mislead the model with incorrect labels. In this paper, we present a novel framework that utilizes counterfactual generative models to generate a large number of diverse counterfactuals by actively sampling from regions of uncertainty, and then automatically label them with a learned pairwise classifier. Our key insight is that we can more correctly label the generated counterfactuals by training a pairwise classifier that interpolates the relationship between the original example and the counterfactual. We demonstrate that with a small",
    "link": "http://arxiv.org/abs/2305.13535",
    "context": "Title: Improving Classifier Robustness through Active Generation of Pairwise Counterfactuals. (arXiv:2305.13535v1 [cs.CL])\nAbstract: Counterfactual Data Augmentation (CDA) is a commonly used technique for improving robustness in natural language classifiers. However, one fundamental challenge is how to discover meaningful counterfactuals and efficiently label them, with minimal human labeling cost. Most existing methods either completely rely on human-annotated labels, an expensive process which limits the scale of counterfactual data, or implicitly assume label invariance, which may mislead the model with incorrect labels. In this paper, we present a novel framework that utilizes counterfactual generative models to generate a large number of diverse counterfactuals by actively sampling from regions of uncertainty, and then automatically label them with a learned pairwise classifier. Our key insight is that we can more correctly label the generated counterfactuals by training a pairwise classifier that interpolates the relationship between the original example and the counterfactual. We demonstrate that with a small",
    "path": "papers/23/05/2305.13535.json",
    "total_tokens": 999,
    "translated_title": "通过主动生成成对反事实数据来提高分类器的鲁棒性",
    "translated_abstract": "对抗事实数据增强技术（CDA）是提高自然语言分类器鲁棒性的常用技术。然而，如何发现有意义的反事实数据并有效地标记它们是一个根本性挑战，需要尽可能降低人工标记成本。大多数现有方法要么完全依赖于人工标注的标签，这是一个昂贵的过程，限制了反事实数据的规模，要么隐含地假设标签不变性，这可能会误导模型产生错误的标签。本文提出了一个新的框架，利用反事实生成模型从不确定性区域主动抽样生成大量不同的反事实数据，然后用学习的成对分类器自动标记它们。我们的关键洞见是，通过训练一个成对分类器来插值原始样例和反事实数据之间的关系，我们可以更正确地标记生成的反事实数据。我们证明，在小规模的人工标记下，我们的方法可以实现高质量的反事实数据增强，显著提高自然语言分类器的鲁棒性。",
    "tldr": "本论文提出一种利用反事实生成模型来主动抽样生成大量不同的反事实数据，并自动标记它们的框架。通过训练一个成对分类器来插值原始样例和反事实数据之间的关系，可以更正确地标记生成的反事实数据，从而显著提高自然语言分类器的鲁棒性。",
    "en_tdlr": "This paper proposes a framework that utilizes counterfactual generative models to actively sample and automatically label a large number of diverse counterfactuals, and improves the robustness of natural language classifiers significantly by interpolating the relationship between the original example and the counterfactual through training a pairwise classifier."
}