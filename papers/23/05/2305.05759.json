{
    "title": "Ranking & Reweighting Improves Group Distributional Robustness. (arXiv:2305.05759v1 [cs.LG])",
    "abstract": "Recent work has shown that standard training via empirical risk minimization (ERM) can produce models that achieve high accuracy on average but low accuracy on underrepresented groups due to the prevalence of spurious features. A predominant approach to tackle this group robustness problem minimizes the worst group error (akin to a minimax strategy) on the training data, hoping it will generalize well on the testing data. However, this is often suboptimal, especially when the out-of-distribution (OOD) test data contains previously unseen groups. Inspired by ideas from the information retrieval and learning-to-rank literature, this paper first proposes to use Discounted Cumulative Gain (DCG) as a metric of model quality for facilitating better hyperparameter tuning and model selection. Being a ranking-based metric, DCG weights multiple poorly-performing groups (instead of considering just the group with the worst performance). As a natural next step, we build on our results to propose a",
    "link": "http://arxiv.org/abs/2305.05759",
    "context": "Title: Ranking & Reweighting Improves Group Distributional Robustness. (arXiv:2305.05759v1 [cs.LG])\nAbstract: Recent work has shown that standard training via empirical risk minimization (ERM) can produce models that achieve high accuracy on average but low accuracy on underrepresented groups due to the prevalence of spurious features. A predominant approach to tackle this group robustness problem minimizes the worst group error (akin to a minimax strategy) on the training data, hoping it will generalize well on the testing data. However, this is often suboptimal, especially when the out-of-distribution (OOD) test data contains previously unseen groups. Inspired by ideas from the information retrieval and learning-to-rank literature, this paper first proposes to use Discounted Cumulative Gain (DCG) as a metric of model quality for facilitating better hyperparameter tuning and model selection. Being a ranking-based metric, DCG weights multiple poorly-performing groups (instead of considering just the group with the worst performance). As a natural next step, we build on our results to propose a",
    "path": "papers/23/05/2305.05759.json",
    "total_tokens": 1055,
    "translated_title": "排名和重新加权提高了组的分布鲁棒性",
    "translated_abstract": "最近的研究表明，通过经验风险最小化（ERM）进行标准训练可能会产生在平均精度上表现出色但在低代表性组上准确性较低的模型，这是由于表征中虚假特征的普遍存在所致。解决这个组鲁棒性问题的主要方法是在训练数据上最小化最坏的组误差（类似于极小值策略），希望它会在测试数据上有良好的泛化性能。然而，这种方法往往是次优的，尤其是当测试数据集中包含以前未见过的组时。本文受信息检索和Learning-to-Rank文献的启发，首先提出使用折扣累积增益（DCG）作为模型质量度量标准，以促进更好的超参数调整和模型选择。作为一种基于排序的度量标准，DCG加权多个性能较差的组（而不仅仅是考虑性能最差的组）。作为自然的下一步，我们基于这些结果提出了一种新的组重新加权方法，在训练期间鼓励模型集中于低代表性的组。在几个基准数据集上的实验证明，我们提出的方法优于先前的最先进方法，并显著提高了对组不平衡的鲁棒性。",
    "tldr": "本文提出了一种利用折扣累积增益（DCG）排序并加权处理训练数据以提高模型对低代表性组的鲁棒性的方法，实验证明其优于先前方法。",
    "en_tdlr": "This paper proposes a method that uses Discounted Cumulative Gain (DCG) to rank and weight the training data for better group robustness of the model, and experiments show that it outperforms previous methods."
}