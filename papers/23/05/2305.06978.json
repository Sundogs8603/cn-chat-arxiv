{
    "title": "Meta-hallucinator: Towards Few-Shot Cross-Modality Cardiac Image Segmentation. (arXiv:2305.06978v1 [cs.CV])",
    "abstract": "Domain shift and label scarcity heavily limit deep learning applications to various medical image analysis tasks. Unsupervised domain adaptation (UDA) techniques have recently achieved promising cross-modality medical image segmentation by transferring knowledge from a label-rich source domain to an unlabeled target domain. However, it is also difficult to collect annotations from the source domain in many clinical applications, rendering most prior works suboptimal with the label-scarce source domain, particularly for few-shot scenarios, where only a few source labels are accessible. To achieve efficient few-shot cross-modality segmentation, we propose a novel transformation-consistent meta-hallucination framework, meta-hallucinator, with the goal of learning to diversify data distributions and generate useful examples for enhancing cross-modality performance. In our framework, hallucination and segmentation models are jointly trained with the gradient-based meta-learning strategy to ",
    "link": "http://arxiv.org/abs/2305.06978",
    "context": "Title: Meta-hallucinator: Towards Few-Shot Cross-Modality Cardiac Image Segmentation. (arXiv:2305.06978v1 [cs.CV])\nAbstract: Domain shift and label scarcity heavily limit deep learning applications to various medical image analysis tasks. Unsupervised domain adaptation (UDA) techniques have recently achieved promising cross-modality medical image segmentation by transferring knowledge from a label-rich source domain to an unlabeled target domain. However, it is also difficult to collect annotations from the source domain in many clinical applications, rendering most prior works suboptimal with the label-scarce source domain, particularly for few-shot scenarios, where only a few source labels are accessible. To achieve efficient few-shot cross-modality segmentation, we propose a novel transformation-consistent meta-hallucination framework, meta-hallucinator, with the goal of learning to diversify data distributions and generate useful examples for enhancing cross-modality performance. In our framework, hallucination and segmentation models are jointly trained with the gradient-based meta-learning strategy to ",
    "path": "papers/23/05/2305.06978.json",
    "total_tokens": 1049,
    "translated_title": "元幻觉者：针对少样本跨模态心脏图像分割的探索",
    "translated_abstract": "领域转移和标签稀缺严重限制了深度学习应用于各种医学图像分析任务。最近，无监督领域自适应技术通过从标签丰富的源领域向未标记的目标领域转移知识，实现了有前途的跨模态医学图像分割。然而，在许多临床应用中，从源领域收集注释也很困难，导致大多数先前的工作在标签稀缺的源领域特别是在只有少量源标签可用的情况下不够完美。为了实现有效的少样本跨模态分割，我们提出了一种新颖的变换一致元幻觉框架，即“元幻觉者”，旨在学习多样化的数据分布并生成有用的示例以提高跨模态性能。在我们的框架中，利用基于梯度的元学习策略联合训练了幻觉和分割模型，以适应仅有少量标注样本的新任务。实验结果表明，我们提出的框架在大脑MRI和心脏MRI数据集上优于最先进的少样本医学图像分割方法。",
    "tldr": "该研究提出了一种基于元学习的元幻觉框架，旨在实现针对少样本跨模态心脏图像分割的有效方法。实验结果表明，该框架优于最先进的少样本医学图像分割方法。",
    "en_tdlr": "This research proposes a novel transformation-consistent meta-hallucination framework, called meta-hallucinator, with the goal of achieving efficient few-shot cross-modality cardiac image segmentation. The experiments on both brain MRI and cardiac MRI datasets demonstrate that this framework outperforms state-of-the-art few-shot medical image segmentation methods."
}