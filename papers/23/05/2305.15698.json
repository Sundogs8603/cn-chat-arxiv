{
    "title": "Rethink Diversity in Deep Learning Testing. (arXiv:2305.15698v1 [cs.SE])",
    "abstract": "Deep neural networks (DNNs) have demonstrated extraordinary capabilities and are an integral part of modern software systems. However, they also suffer from various vulnerabilities such as adversarial attacks and unfairness. Testing deep learning (DL) systems is therefore an important task, to detect and mitigate those vulnerabilities. Motivated by the success of traditional software testing, which often employs diversity heuristics, various diversity measures on DNNs have been proposed to help efficiently expose the buggy behavior of DNNs. In this work, we argue that many DNN testing tasks should be treated as directed testing problems rather than general-purpose testing tasks, because these tasks are specific and well-defined. Hence, the diversity-based approach is less effective.  Following our argument based on the semantics of DNNs and the testing goal, we derive $6$ metrics that can be used for DNN testing and carefully analyze their application scopes. We empirically show their ",
    "link": "http://arxiv.org/abs/2305.15698",
    "context": "Title: Rethink Diversity in Deep Learning Testing. (arXiv:2305.15698v1 [cs.SE])\nAbstract: Deep neural networks (DNNs) have demonstrated extraordinary capabilities and are an integral part of modern software systems. However, they also suffer from various vulnerabilities such as adversarial attacks and unfairness. Testing deep learning (DL) systems is therefore an important task, to detect and mitigate those vulnerabilities. Motivated by the success of traditional software testing, which often employs diversity heuristics, various diversity measures on DNNs have been proposed to help efficiently expose the buggy behavior of DNNs. In this work, we argue that many DNN testing tasks should be treated as directed testing problems rather than general-purpose testing tasks, because these tasks are specific and well-defined. Hence, the diversity-based approach is less effective.  Following our argument based on the semantics of DNNs and the testing goal, we derive $6$ metrics that can be used for DNN testing and carefully analyze their application scopes. We empirically show their ",
    "path": "papers/23/05/2305.15698.json",
    "total_tokens": 855,
    "translated_title": "重新思考深度学习测试中的多样性",
    "translated_abstract": "深度神经网络（DNNs）展现了非凡的能力，是现代软件系统的重要组成部分。然而，它们也面临着各种漏洞，如对抗攻击和不公平性。因此，测试深度学习（DL）系统是一项重要任务，以检测和减轻这些漏洞。受传统软件测试成功的启发，提出了各种DNN的多样性度量，以帮助有效地暴露DNNs的buggy行为。在本文中，我们认为许多DNN测试任务应该被视为定向测试问题而不是通用测试任务，因为这些任务是具体和明确定义的。因此，基于多样性的方法效果较差。遵循我们的测试目标和DNN语义的论证，我们推导出6个指标，可以用于DNN测试，并仔细分析它们的应用范围。我们通过经验性结果显示它们的应用性。",
    "tldr": "本文提出针对深度学习测试的六个具体指标来检测和缓解其漏洞，认为许多DNN测试任务应该是定向测试问题而不是通用测试任务。",
    "en_tdlr": "This paper proposes six specific metrics for testing deep neural networks (DNNs) to detect and mitigate their vulnerabilities. The paper argues that many DNN testing tasks should be treated as directed testing problems, and not general-purpose testing tasks."
}