{
    "title": "Auditing Cross-Cultural Consistency of Human-Annotated Labels for Recommendation Systems. (arXiv:2305.05917v1 [cs.IR])",
    "abstract": "Recommendation systems increasingly depend on massive human-labeled datasets; however, the human annotators hired to generate these labels increasingly come from homogeneous backgrounds. This poses an issue when downstream predictive models -- based on these labels -- are applied globally to a heterogeneous set of users. We study this disconnect with respect to the labels themselves, asking whether they are ``consistently conceptualized'' across annotators of different demographics. In a case study of video game labels, we conduct a survey on 5,174 gamers, identify a subset of inconsistently conceptualized game labels, perform causal analyses, and suggest both cultural and linguistic reasons for cross-country differences in label annotation. We further demonstrate that predictive models of game annotations perform better on global train sets as opposed to homogeneous (single-country) train sets. Finally, we provide a generalizable framework for practitioners to audit their own data ann",
    "link": "http://arxiv.org/abs/2305.05917",
    "context": "Title: Auditing Cross-Cultural Consistency of Human-Annotated Labels for Recommendation Systems. (arXiv:2305.05917v1 [cs.IR])\nAbstract: Recommendation systems increasingly depend on massive human-labeled datasets; however, the human annotators hired to generate these labels increasingly come from homogeneous backgrounds. This poses an issue when downstream predictive models -- based on these labels -- are applied globally to a heterogeneous set of users. We study this disconnect with respect to the labels themselves, asking whether they are ``consistently conceptualized'' across annotators of different demographics. In a case study of video game labels, we conduct a survey on 5,174 gamers, identify a subset of inconsistently conceptualized game labels, perform causal analyses, and suggest both cultural and linguistic reasons for cross-country differences in label annotation. We further demonstrate that predictive models of game annotations perform better on global train sets as opposed to homogeneous (single-country) train sets. Finally, we provide a generalizable framework for practitioners to audit their own data ann",
    "path": "papers/23/05/2305.05917.json",
    "total_tokens": 927,
    "translated_title": "评估基于人工注释标签的推荐系统跨文化一致性",
    "translated_abstract": "推荐系统越来越依赖于大规模的人工标记数据集；然而，生成这些标记的人类注释者越来越来自同质化的背景。这在将基于这些标签的下游预测模型应用于异构用户群时会带来问题。我们研究了这种断裂与标签本身的关系，询问是否跨不同人口统计学注释者“一致概念化”。在视频游戏标签的案例研究中，我们对5174名游戏玩家进行了一项调查，确定了一组不一致概念化的游戏标签子集，进行因果分析，并提出了跨国标注的文化和语言差异的原因。我们进一步证明，与同质化（单个国家）训练集相比，游戏标注的预测模型在全球训练集上表现更好。最后，我们提供了一个通用框架，供从业人员审核自己的数据集。",
    "tldr": "本文研究了基于人工注释标签的推荐系统中的跨文化一致性问题，提出了一组不一致概念化的游戏标签子集，并对跨国标注的文化和语言差异的原因进行了分析。作者还提供了一个通用框架，供从业人员审核自己的数据集。",
    "en_tdlr": "This paper investigates the issue of cross-cultural consistency in human-annotated labels for recommendation systems. The authors identify a subset of inconsistently conceptualized game labels and provide cultural and linguistic reasons for cross-country differences in label annotation. They also present a framework for practitioners to audit their own data sets."
}