{
    "title": "TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models. (arXiv:2305.11171v2 [cs.CL] UPDATED)",
    "abstract": "Factual consistency evaluation is often conducted using Natural Language Inference (NLI) models, yet these models exhibit limited success in evaluating summaries. Previous work improved such models with synthetic training data. However, the data is typically based on perturbed human-written summaries, which often differ in their characteristics from real model-generated summaries and have limited coverage of possible factual errors. Alternatively, large language models (LLMs) have recently shown promising results in directly evaluating generative tasks, but are too computationally expensive for practical use. Motivated by these limitations, we introduce TrueTeacher, a method for generating synthetic data by annotating diverse model-generated summaries using a LLM. Unlike prior work, TrueTeacher does not rely on human-written summaries, and is multilingual by nature. Experiments on the TRUE benchmark show that a student model trained using our data, substantially outperforms both the st",
    "link": "http://arxiv.org/abs/2305.11171",
    "context": "Title: TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models. (arXiv:2305.11171v2 [cs.CL] UPDATED)\nAbstract: Factual consistency evaluation is often conducted using Natural Language Inference (NLI) models, yet these models exhibit limited success in evaluating summaries. Previous work improved such models with synthetic training data. However, the data is typically based on perturbed human-written summaries, which often differ in their characteristics from real model-generated summaries and have limited coverage of possible factual errors. Alternatively, large language models (LLMs) have recently shown promising results in directly evaluating generative tasks, but are too computationally expensive for practical use. Motivated by these limitations, we introduce TrueTeacher, a method for generating synthetic data by annotating diverse model-generated summaries using a LLM. Unlike prior work, TrueTeacher does not rely on human-written summaries, and is multilingual by nature. Experiments on the TRUE benchmark show that a student model trained using our data, substantially outperforms both the st",
    "path": "papers/23/05/2305.11171.json",
    "total_tokens": 903,
    "translated_title": "TrueTeacher: 使用大语言模型学习事实一致性评估",
    "translated_abstract": "事实一致性评估通常使用自然语言推理模型进行，然而这些模型在评估摘要时取得的成功有限。以往的工作通过合成训练数据改进了此类模型。然而，这些数据通常基于扰动的人工编写摘要，与真实的模型生成摘要在特性上常常存在差异，并且对可能存在的事实错误的覆盖范围有限。另一方面，大型语言模型（LLM）最近在直接评估生成任务方面显示了有希望的结果，但计算开销过大，无法实际应用。出于对这些限制的动机，我们引入了TrueTeacher，一种使用LLM注释多样的模型生成摘要来生成合成数据的方法。与以往的工作不同，TrueTeacher不依赖于人工编写的摘要，并且具有多语言特性。在TRUE基准测试上的实验表明，使用我们的数据训练的学生模型在性能上远远超过了NLI模型和之前的工作。",
    "tldr": "TrueTeacher是一种使用大型语言模型生成合成数据来进行事实一致性评估的方法，相较于传统方法，TrueTeacher不依赖于人工编写的摘要，多语言特性，实验证明能够显著提升模型的性能。",
    "en_tdlr": "TrueTeacher is a method for evaluating factual consistency using large language models by generating synthetic data. Unlike previous methods, TrueTeacher does not rely on human-written summaries and is multilingual by nature. Experimental results demonstrate its significantly improved performance compared to traditional approaches."
}