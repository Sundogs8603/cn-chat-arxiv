{
    "title": "Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation. (arXiv:2305.15541v1 [cs.CL])",
    "abstract": "Translating natural language sentences to first-order logic (NL-FOL translation) is a longstanding challenge in the NLP and formal logic literature. This paper introduces LogicLLaMA, a LLaMA-7B model fine-tuned for NL-FOL translation using LoRA on a single GPU. LogicLLaMA is capable of directly translating natural language into FOL rules, which outperforms GPT-3.5. LogicLLaMA is also equipped to correct FOL rules predicted by GPT-3.5, and can achieve similar performance as GPT-4 with a fraction of the cost. This correction ability was achieved by a novel supervised fine-tuning (SFT) + reinforcement learning with human feedback (RLHF) framework, which initially trains on synthetically perturbed NL-FOL pairs to encourage chain-of-thought reasoning and then fine-tunes with RLHF on GPT-3.5 outputs using a FOL verifier as the reward model.  To train LogicLLaMA, we present MALLS (large language $\\textbf{M}$odel gener$\\textbf{A}$ted N$\\textbf{L}$-FO$\\textbf{L}$ pair$\\textbf{S}$), a dataset of",
    "link": "http://arxiv.org/abs/2305.15541",
    "context": "Title: Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation. (arXiv:2305.15541v1 [cs.CL])\nAbstract: Translating natural language sentences to first-order logic (NL-FOL translation) is a longstanding challenge in the NLP and formal logic literature. This paper introduces LogicLLaMA, a LLaMA-7B model fine-tuned for NL-FOL translation using LoRA on a single GPU. LogicLLaMA is capable of directly translating natural language into FOL rules, which outperforms GPT-3.5. LogicLLaMA is also equipped to correct FOL rules predicted by GPT-3.5, and can achieve similar performance as GPT-4 with a fraction of the cost. This correction ability was achieved by a novel supervised fine-tuning (SFT) + reinforcement learning with human feedback (RLHF) framework, which initially trains on synthetically perturbed NL-FOL pairs to encourage chain-of-thought reasoning and then fine-tunes with RLHF on GPT-3.5 outputs using a FOL verifier as the reward model.  To train LogicLLaMA, we present MALLS (large language $\\textbf{M}$odel gener$\\textbf{A}$ted N$\\textbf{L}$-FO$\\textbf{L}$ pair$\\textbf{S}$), a dataset of",
    "path": "papers/23/05/2305.15541.json",
    "total_tokens": 1084,
    "tldr": "LogicLLaMA是一个在单个GPU上fine-tuned的LLaMA-7B模型，能够直接将自然语言翻译为FOL规则，表现优于GPT-3.5，在改正GPT-3.5预测的FOL规则时，能够以更优性价比实现类似GPT-4的性能。"
}