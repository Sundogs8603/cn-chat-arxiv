{
    "title": "DreamPaint: Few-Shot Inpainting of E-Commerce Items for Virtual Try-On without 3D Modeling. (arXiv:2305.01257v1 [cs.CV])",
    "abstract": "We introduce DreamPaint, a framework to intelligently inpaint any e-commerce product on any user-provided context image. The context image can be, for example, the user's own image for virtual try-on of clothes from the e-commerce catalog on themselves, the user's room image for virtual try-on of a piece of furniture from the e-commerce catalog in their room, etc. As opposed to previous augmented-reality (AR)-based virtual try-on methods, DreamPaint does not use, nor does it require, 3D modeling of neither the e-commerce product nor the user context. Instead, it directly uses 2D images of the product as available in product catalog database, and a 2D picture of the context, for example taken from the user's phone camera. The method relies on few-shot fine tuning a pre-trained diffusion model with the masked latents (e.g., Masked DreamBooth) of the catalog images per item, whose weights are then loaded on a pre-trained inpainting module that is capable of preserving the characteristics ",
    "link": "http://arxiv.org/abs/2305.01257",
    "context": "Title: DreamPaint: Few-Shot Inpainting of E-Commerce Items for Virtual Try-On without 3D Modeling. (arXiv:2305.01257v1 [cs.CV])\nAbstract: We introduce DreamPaint, a framework to intelligently inpaint any e-commerce product on any user-provided context image. The context image can be, for example, the user's own image for virtual try-on of clothes from the e-commerce catalog on themselves, the user's room image for virtual try-on of a piece of furniture from the e-commerce catalog in their room, etc. As opposed to previous augmented-reality (AR)-based virtual try-on methods, DreamPaint does not use, nor does it require, 3D modeling of neither the e-commerce product nor the user context. Instead, it directly uses 2D images of the product as available in product catalog database, and a 2D picture of the context, for example taken from the user's phone camera. The method relies on few-shot fine tuning a pre-trained diffusion model with the masked latents (e.g., Masked DreamBooth) of the catalog images per item, whose weights are then loaded on a pre-trained inpainting module that is capable of preserving the characteristics ",
    "path": "papers/23/05/2305.01257.json",
    "total_tokens": 885,
    "translated_title": "DreamPaint: 无需3D建模的电商商品试穿Few-Shot修复",
    "translated_abstract": "我们介绍了 DreamPaint，这是一个能够智能修复电商产品在用户提供的任意背景图像上的框架。例如，用户可以使用自己的图像来试穿电商目录中的衣服，或者使用自己房间的图像来在其中试放电商目录中的家具等。与以前的增强现实（AR）虚拟试穿方法不同，DreamPaint 不使用，也不需要电商产品或用户环境的 3D 建模。相反，它直接使用目录数据库中可用的产品的 2D 图像和上下文的 2D 图像，例如从用户的手机相机中拍摄的图像。该方法依靠少量样本微调预训练扩散模型及其产品目录图像下的遮罩潜变量（例如，Masked DreamBooth）的权重，然后将其加载到能够保留属性的预训练修复模块上。",
    "tldr": "DreamPaint是一个无需3D建模的电商商品试穿Few-Shot修复框架，可以在任意用户环境下对商品图像进行修复，具有较高的修复精度。",
    "en_tdlr": "DreamPaint is a Few-Shot inpainting framework for e-commerce items virtual try-on without 3D modeling, which achieves high accuracy by directly using 2D images of the product and context without the need for 3D modeling."
}