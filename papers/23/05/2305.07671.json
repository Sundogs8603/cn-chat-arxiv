{
    "title": "LatentPINNs: Generative physics-informed neural networks via a latent representation learning. (arXiv:2305.07671v1 [cs.LG])",
    "abstract": "Physics-informed neural networks (PINNs) are promising to replace conventional partial differential equation (PDE) solvers by offering more accurate and flexible PDE solutions. However, they are hampered by the relatively slow convergence and the need to perform additional, potentially expensive, training for different PDE parameters. To solve this limitation, we introduce latentPINN, a framework that utilizes latent representations of the PDE parameters as additional (to the coordinates) inputs into PINNs and allows for training over the distribution of these parameters. Motivated by the recent progress on generative models, we promote the use of latent diffusion models to learn compressed latent representations of the PDE parameters distribution and act as input parameters to NN functional solutions. We use a two-stage training scheme in which the first stage, we learn the latent representations for the distribution of PDE parameters. In the second stage, we train a physics-informed ",
    "link": "http://arxiv.org/abs/2305.07671",
    "context": "Title: LatentPINNs: Generative physics-informed neural networks via a latent representation learning. (arXiv:2305.07671v1 [cs.LG])\nAbstract: Physics-informed neural networks (PINNs) are promising to replace conventional partial differential equation (PDE) solvers by offering more accurate and flexible PDE solutions. However, they are hampered by the relatively slow convergence and the need to perform additional, potentially expensive, training for different PDE parameters. To solve this limitation, we introduce latentPINN, a framework that utilizes latent representations of the PDE parameters as additional (to the coordinates) inputs into PINNs and allows for training over the distribution of these parameters. Motivated by the recent progress on generative models, we promote the use of latent diffusion models to learn compressed latent representations of the PDE parameters distribution and act as input parameters to NN functional solutions. We use a two-stage training scheme in which the first stage, we learn the latent representations for the distribution of PDE parameters. In the second stage, we train a physics-informed ",
    "path": "papers/23/05/2305.07671.json",
    "total_tokens": 1132,
    "translated_title": "LatentPINNs：通过潜在表示学习实现的物理学约束神经网络",
    "translated_abstract": "物理学约束神经网络(PINNs)通过对偏微分方程(PDE)求解进行物理学约束，提供更加精确和灵活的PDE解决方案。然而，PINNs的训练速度相对较慢且需要对不同的PDE参数进行额外的、可能昂贵的训练。为了解决这个问题，我们引入了latentPINN，这是一个利用PDE参数潜在表示作为PINN附加输入的框架，并允许在这些参数的分布上进行训练。我们使用潜在扩散模型学习PDE参数分布的压缩潜在表示，并训练一个受物理学约束的神经网络，使其能够精确求解PDE。",
    "tldr": "LatentPINNs是一个利用潜在表示学习实现的物理学约束神经网络，通过潜在扩散模型的压缩表示，可以更快速、更有效地求解偏微分方程(PDE)。",
    "en_tdlr": "LatentPINNs is a physics-informed neural network that utilizes latent representation learning and compresses the distribution of PDE parameters through latent diffusion models to achieve faster and more accurate solutions to partial differential equations (PDEs)."
}