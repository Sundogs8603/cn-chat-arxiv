{
    "title": "Self-supervised representations in speech-based depression detection. (arXiv:2305.12263v2 [cs.CL] UPDATED)",
    "abstract": "This paper proposes handling training data sparsity in speech-based automatic depression detection (SDD) using foundation models pre-trained with self-supervised learning (SSL). An analysis of SSL representations derived from different layers of pre-trained foundation models is first presented for SDD, which provides insight to suitable indicator for depression detection. Knowledge transfer is then performed from automatic speech recognition (ASR) and emotion recognition to SDD by fine-tuning the foundation models. Results show that the uses of oracle and ASR transcriptions yield similar SDD performance when the hidden representations of the ASR model is incorporated along with the ASR textual information. By integrating representations from multiple foundation models, state-of-the-art SDD results based on real ASR were achieved on the DAIC-WOZ dataset.",
    "link": "http://arxiv.org/abs/2305.12263",
    "context": "Title: Self-supervised representations in speech-based depression detection. (arXiv:2305.12263v2 [cs.CL] UPDATED)\nAbstract: This paper proposes handling training data sparsity in speech-based automatic depression detection (SDD) using foundation models pre-trained with self-supervised learning (SSL). An analysis of SSL representations derived from different layers of pre-trained foundation models is first presented for SDD, which provides insight to suitable indicator for depression detection. Knowledge transfer is then performed from automatic speech recognition (ASR) and emotion recognition to SDD by fine-tuning the foundation models. Results show that the uses of oracle and ASR transcriptions yield similar SDD performance when the hidden representations of the ASR model is incorporated along with the ASR textual information. By integrating representations from multiple foundation models, state-of-the-art SDD results based on real ASR were achieved on the DAIC-WOZ dataset.",
    "path": "papers/23/05/2305.12263.json",
    "total_tokens": 893,
    "translated_title": "基于自监督学习的语音交流中自我监督表示法在抑郁症检测中的应用",
    "translated_abstract": "本文提出使用基于自监督学习（SSL）预训练的基础模型来处理语音交流中自动抑郁症检测（SDD）训练数据的稀疏性。首先，对从不同层次的预训练基础模型中得到的SSL表示进行了SDD分析，从而为抑郁症检测提供了合适的指标见解。然后，通过微调基础模型，从自动语音识别（ASR）和情感识别转移知识到SDD。结果表明，在将ASR模型的隐藏表示与ASR文本信息相结合时，使用oracle和ASR转录产生了类似的SDD性能。通过整合来自多个基础模型的表示，在DAIC-WOZ数据集上实现了基于真实ASR的最先进的SDD结果。",
    "tldr": "本文使用基于自监督学习的预训练基础模型解决了语音交流中自动抑郁症检测训练数据稀疏性的问题，并通过微调基础模型将自动语音识别和情感识别的知识转移到抑郁症检测中。实验结果表明，在DAIC-WOZ数据集上实现了基于真实ASR的最先进的抑郁症检测性能。",
    "en_tdlr": "This paper addresses the issue of training data sparsity in speech-based automatic depression detection by utilizing self-supervised learning and fine-tuning foundation models. It demonstrates improved performance on the DAIC-WOZ dataset by incorporating knowledge from automatic speech recognition and emotion recognition."
}