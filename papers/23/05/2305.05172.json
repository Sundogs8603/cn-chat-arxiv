{
    "title": "Logic for Explainable AI. (arXiv:2305.05172v1 [cs.AI])",
    "abstract": "A central quest in explainable AI relates to understanding the decisions made by (learned) classifiers. There are three dimensions of this understanding that have been receiving significant attention in recent years. The first dimension relates to characterizing conditions on instances that are necessary and sufficient for decisions, therefore providing abstractions of instances that can be viewed as the \"reasons behind decisions.\" The next dimension relates to characterizing minimal conditions that are sufficient for a decision, therefore identifying maximal aspects of the instance that are irrelevant to the decision. The last dimension relates to characterizing minimal conditions that are necessary for a decision, therefore identifying minimal perturbations to the instance that yield alternate decisions. We discuss in this tutorial a comprehensive, semantical and computational theory of explainability along these dimensions which is based on some recent developments in symbolic logic",
    "link": "http://arxiv.org/abs/2305.05172",
    "context": "Title: Logic for Explainable AI. (arXiv:2305.05172v1 [cs.AI])\nAbstract: A central quest in explainable AI relates to understanding the decisions made by (learned) classifiers. There are three dimensions of this understanding that have been receiving significant attention in recent years. The first dimension relates to characterizing conditions on instances that are necessary and sufficient for decisions, therefore providing abstractions of instances that can be viewed as the \"reasons behind decisions.\" The next dimension relates to characterizing minimal conditions that are sufficient for a decision, therefore identifying maximal aspects of the instance that are irrelevant to the decision. The last dimension relates to characterizing minimal conditions that are necessary for a decision, therefore identifying minimal perturbations to the instance that yield alternate decisions. We discuss in this tutorial a comprehensive, semantical and computational theory of explainability along these dimensions which is based on some recent developments in symbolic logic",
    "path": "papers/23/05/2305.05172.json",
    "total_tokens": 796,
    "translated_title": "可解释性人工智能的逻辑",
    "translated_abstract": "可解释性人工智能的核心问题在于理解（学习）分类器所做出的决策。这种理解有三个方面，在近年来得到了显著关注。第一维与为判断决策所必要和充分的实例条件有关，从而提供了可视化的实例抽象，可视为“决策背后的原因”。下一维与描述足以作出决策的最小条件有关，从而确定了与决策无关的实例最大方面。最后一个维度将其移动到了决策，即标识对实例进行最小扰动以产生替代决策所必需的最小条件。我们在本教程中讨论了沿这些方面的可解释性的全面、语义和计算理论，这是基于符号逻辑的一些最新发展。",
    "tldr": "本文介绍了一种基于符号逻辑的综合、语义和计算理论，以探讨可解释性人工智能的三个维度，以深入理解分类器所做出的决策。",
    "en_tdlr": "This paper introduces a comprehensive, semantic, and computational theory based on symbolic logic to explore the three dimensions of explainable artificial intelligence, in order to gain a deeper understanding of the decisions made by classifiers."
}