{
    "title": "Deception by Omission: Using Adversarial Missingness to Poison Causal Structure Learning. (arXiv:2305.20043v1 [cs.LG])",
    "abstract": "Inference of causal structures from observational data is a key component of causal machine learning; in practice, this data may be incompletely observed. Prior work has demonstrated that adversarial perturbations of completely observed training data may be used to force the learning of inaccurate causal structural models (SCMs). However, when the data can be audited for correctness (e.g., it is crytographically signed by its source), this adversarial mechanism is invalidated. This work introduces a novel attack methodology wherein the adversary deceptively omits a portion of the true training data to bias the learned causal structures in a desired manner. Theoretically sound attack mechanisms are derived for the case of arbitrary SCMs, and a sample-efficient learning-based heuristic is given for Gaussian SCMs. Experimental validation of these approaches on real and synthetic data sets demonstrates the effectiveness of adversarial missingness attacks at deceiving popular causal structu",
    "link": "http://arxiv.org/abs/2305.20043",
    "context": "Title: Deception by Omission: Using Adversarial Missingness to Poison Causal Structure Learning. (arXiv:2305.20043v1 [cs.LG])\nAbstract: Inference of causal structures from observational data is a key component of causal machine learning; in practice, this data may be incompletely observed. Prior work has demonstrated that adversarial perturbations of completely observed training data may be used to force the learning of inaccurate causal structural models (SCMs). However, when the data can be audited for correctness (e.g., it is crytographically signed by its source), this adversarial mechanism is invalidated. This work introduces a novel attack methodology wherein the adversary deceptively omits a portion of the true training data to bias the learned causal structures in a desired manner. Theoretically sound attack mechanisms are derived for the case of arbitrary SCMs, and a sample-efficient learning-based heuristic is given for Gaussian SCMs. Experimental validation of these approaches on real and synthetic data sets demonstrates the effectiveness of adversarial missingness attacks at deceiving popular causal structu",
    "path": "papers/23/05/2305.20043.json",
    "total_tokens": 920,
    "translated_title": "遗漏欺骗：使用对抗性缺失来污染因果结构学习",
    "translated_abstract": "从观测数据推断因果结构是因果机器学习的重要组成部分；在实践中，这些数据可能存在不完全观测的问题。此前的研究已经证明，对完全观测的训练数据进行对抗性扰动可能会导致学习到的因果结构模型（SCMs）不准确。然而，当数据可以进行正确性审计时（例如，它是由其源加密签名的），这种对抗性机制就会被驳回。本文引入了一种新的攻击方法，其中对手欺骗性地遗漏了部分真实的训练数据，以偏向所需的方式来影响学习到的因果结构。针对任意SCMs的攻击机制被理论上证明是有用的，对于高斯SCMs，该文还给出了一种高效的基于学习的启发式方法。在真实和合成数据集上进行的实验验证了这些方法的有效性，并证明了缺失攻击对欺骗流行的因果结构学习方法的有效性。",
    "tldr": "本文提出了一种新的攻击方法，其中对手欺骗性地遗漏了部分真实的训练数据，以偏向所需的方式来影响学习到的因果结构。",
    "en_tdlr": "This paper proposes a novel attack methodology where the adversary deceptively omits a portion of the true training data to bias the learned causal structures in a desired manner. The experimental validation proves the effectiveness of adversarial missingness attacks at deceiving popular causal structure learning methods."
}