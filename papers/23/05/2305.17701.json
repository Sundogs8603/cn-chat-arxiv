{
    "title": "KoSBi: A Dataset for Mitigating Social Bias Risks Towards Safer Large Language Model Application. (arXiv:2305.17701v2 [cs.CL] UPDATED)",
    "abstract": "Large language models (LLMs) learn not only natural text generation abilities but also social biases against different demographic groups from real-world data. This poses a critical risk when deploying LLM-based applications. Existing research and resources are not readily applicable in South Korea due to the differences in language and culture, both of which significantly affect the biases and targeted demographic groups. This limitation requires localized social bias datasets to ensure the safe and effective deployment of LLMs. To this end, we present KO SB I, a new social bias dataset of 34k pairs of contexts and sentences in Korean covering 72 demographic groups in 15 categories. We find that through filtering-based moderation, social biases in generated content can be reduced by 16.47%p on average for HyperCLOVA (30B and 82B), and GPT-3.",
    "link": "http://arxiv.org/abs/2305.17701",
    "context": "Title: KoSBi: A Dataset for Mitigating Social Bias Risks Towards Safer Large Language Model Application. (arXiv:2305.17701v2 [cs.CL] UPDATED)\nAbstract: Large language models (LLMs) learn not only natural text generation abilities but also social biases against different demographic groups from real-world data. This poses a critical risk when deploying LLM-based applications. Existing research and resources are not readily applicable in South Korea due to the differences in language and culture, both of which significantly affect the biases and targeted demographic groups. This limitation requires localized social bias datasets to ensure the safe and effective deployment of LLMs. To this end, we present KO SB I, a new social bias dataset of 34k pairs of contexts and sentences in Korean covering 72 demographic groups in 15 categories. We find that through filtering-based moderation, social biases in generated content can be reduced by 16.47%p on average for HyperCLOVA (30B and 82B), and GPT-3.",
    "path": "papers/23/05/2305.17701.json",
    "total_tokens": 887,
    "translated_title": "KoSBi: 一份用于减轻社会偏见的数据集，以确保更安全的大型语言模型应用 (arXiv: 2305.17701v2 [cs.CL] UPDATED)",
    "translated_abstract": "大型语言模型 (LLM) 不仅能够学习自然文本生成能力，而且还能通过真实世界的数据学习对不同人口群体的社会偏见，这在部署基于 LLM 的应用程序时构成了关键风险。由于语言和文化的差异显著影响偏见和目标人口群体，因此，现有的研究和资源在韩国并不适用。为了解决这一限制，我们提出了一份新的社会偏见数据集 KoSBi，该数据集包含 72 个人口群体在 15 个类别中的 34k 类语境和句子。我们发现通过基于过滤的中介处理，可以将生成内容中的社会偏差平均降低 16.47%p，对 HyperCLOVA（30B 和 82B）和 GPT-3 均适用。",
    "tldr": "KoSBi是一个新的社会偏见数据集，通过基于过滤的中介处理，可以将生成内容中的社会偏差平均降低16.47%p，适用于韩国语言文化背景的大型语言模型应用程序。",
    "en_tdlr": "KoSBi is a new social bias dataset that can mitigate social biases in generated content by an average of 16.47%p through filtering-based moderation, and it's suitable for large language model applications with Korean language and culture backgrounds."
}