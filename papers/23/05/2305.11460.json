{
    "title": "Self-Agreement: A Framework for Fine-tuning Language Models to Find Agreement among Diverse Opinions. (arXiv:2305.11460v1 [cs.CL])",
    "abstract": "Finding an agreement among diverse opinions is a challenging topic in multiagent systems. Recently, large language models (LLMs) have shown great potential in addressing this challenge due to their remarkable capabilities in comprehending human opinions and generating human-like text. However, they typically rely on extensive human-annotated data. In this paper, we propose Self-Agreement, a novel framework for fine-tuning LLMs to autonomously find agreement using data generated by LLM itself. Specifically, our approach employs the generative pre-trained transformer-3 (GPT-3) to generate multiple opinions for each question in a question dataset and create several agreement candidates among these opinions. Then, a bidirectional encoder representations from transformers (BERT)-based model evaluates the agreement score of each agreement candidate and selects the one with the highest agreement score. This process yields a dataset of question-opinion-agreements, which we use to fine-tune a p",
    "link": "http://arxiv.org/abs/2305.11460",
    "context": "Title: Self-Agreement: A Framework for Fine-tuning Language Models to Find Agreement among Diverse Opinions. (arXiv:2305.11460v1 [cs.CL])\nAbstract: Finding an agreement among diverse opinions is a challenging topic in multiagent systems. Recently, large language models (LLMs) have shown great potential in addressing this challenge due to their remarkable capabilities in comprehending human opinions and generating human-like text. However, they typically rely on extensive human-annotated data. In this paper, we propose Self-Agreement, a novel framework for fine-tuning LLMs to autonomously find agreement using data generated by LLM itself. Specifically, our approach employs the generative pre-trained transformer-3 (GPT-3) to generate multiple opinions for each question in a question dataset and create several agreement candidates among these opinions. Then, a bidirectional encoder representations from transformers (BERT)-based model evaluates the agreement score of each agreement candidate and selects the one with the highest agreement score. This process yields a dataset of question-opinion-agreements, which we use to fine-tune a p",
    "path": "papers/23/05/2305.11460.json",
    "total_tokens": 926,
    "translated_title": "自我协议：微调语言模型以在不同意见之间找到共识的框架",
    "translated_abstract": "在多智能体系统中找到不同意见之间的共识是一个具有挑战性的话题。最近，大型语言模型(LLMs)在解决这一挑战方面表现出了巨大的潜力，因为它们在理解人类观点和生成类人文本方面具有卓越的能力。然而，它们通常依赖于大量的人工标注数据。在本文中，我们提出了一种名为自我协议(Self-Agreement)的新框架，用于微调LLMs以自主地找到共识，并使用LLM自动生成的数据。具体而言，我们的方法使用生成式预训练变压器3(GPT-3)为问题数据集中的每个问题生成多个意见，并为这些意见创建多个共识候选项。然后，基于双向编码器表示来自变压器(BERT)的模型评估每个共识候选项的一致性得分，并选择得分最高的共识候选项。这个过程产生了一个问题-意见-共识数据集，我们使用它来微调一个模型。",
    "tldr": "本文提出了一种名为自我协议(Self-Agreement)的新框架，用于微调LLMs以自主地找到共识，并使用LLM自动生成的数据。",
    "en_tdlr": "The paper proposes a new framework called Self-Agreement, which fine-tunes large language models (LLMs) to autonomously find agreement among diverse opinions using data generated by LLM itself. This approach offers a solution to the challenge of finding agreement in multiagent systems without relying on extensive human-annotated data."
}