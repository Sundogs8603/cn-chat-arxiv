{
    "title": "Randomized Smoothing with Masked Inference for Adversarially Robust Text Classifications. (arXiv:2305.06522v1 [cs.CL])",
    "abstract": "Large-scale pre-trained language models have shown outstanding performance in a variety of NLP tasks. However, they are also known to be significantly brittle against specifically crafted adversarial examples, leading to increasing interest in probing the adversarial robustness of NLP systems. We introduce RSMI, a novel two-stage framework that combines randomized smoothing (RS) with masked inference (MI) to improve the adversarial robustness of NLP systems. RS transforms a classifier into a smoothed classifier to obtain robust representations, whereas MI forces a model to exploit the surrounding context of a masked token in an input sequence. RSMI improves adversarial robustness by 2 to 3 times over existing state-of-the-art methods on benchmark datasets. We also perform in-depth qualitative analysis to validate the effectiveness of the different stages of RSMI and probe the impact of its components through extensive ablations. By empirically proving the stability of RSMI, we put it f",
    "link": "http://arxiv.org/abs/2305.06522",
    "context": "Title: Randomized Smoothing with Masked Inference for Adversarially Robust Text Classifications. (arXiv:2305.06522v1 [cs.CL])\nAbstract: Large-scale pre-trained language models have shown outstanding performance in a variety of NLP tasks. However, they are also known to be significantly brittle against specifically crafted adversarial examples, leading to increasing interest in probing the adversarial robustness of NLP systems. We introduce RSMI, a novel two-stage framework that combines randomized smoothing (RS) with masked inference (MI) to improve the adversarial robustness of NLP systems. RS transforms a classifier into a smoothed classifier to obtain robust representations, whereas MI forces a model to exploit the surrounding context of a masked token in an input sequence. RSMI improves adversarial robustness by 2 to 3 times over existing state-of-the-art methods on benchmark datasets. We also perform in-depth qualitative analysis to validate the effectiveness of the different stages of RSMI and probe the impact of its components through extensive ablations. By empirically proving the stability of RSMI, we put it f",
    "path": "papers/23/05/2305.06522.json",
    "total_tokens": 958,
    "translated_title": "随机平滑和掩码推理用于提高文本分类的对抗鲁棒性",
    "translated_abstract": "大规模预训练的语言模型在各种 NLP 任务上表现出色，但它们也被知道对特定的对抗性例子存在脆弱性，因此越来越多关注 NLP 系统的对抗鲁棒性。我们引入了 RSMI，一种新的两阶段框架，它将随机平滑（RS）与掩码推理（MI）相结合，以提高 NLP 系统的对抗鲁棒性。RS将分类器转换为平滑的分类器，以获得稳健的表示，而MI强制模型利用输入序列中一个掩蔽标记的周围上下文。RSMI在基准数据集上比现有最先进方法将对抗鲁棒性提高2到3倍。我们还进行了深入的定性分析，以验证 RSMI 不同阶段的有效性，并通过广泛的消融研究探究其构成部分的影响。通过实证证明 RSMI 的稳定性，我们将其推向实际应用。",
    "tldr": "该论文介绍了一种新的两阶段框架 RSMI，结合了随机平滑和掩码推理，以提高 NLP 系统的对抗鲁棒性，经过基准数据集测试，相较于现有最先进方法将对抗鲁棒性提高2到3倍。",
    "en_tdlr": "The paper proposes a novel two-stage framework RSMI, which combines randomized smoothing with masked inference to improve adversarial robustness of NLP systems. RSMI achieves a 2 to 3 times improvement in adversarial robustness over existing state-of-the-art methods on benchmark datasets."
}