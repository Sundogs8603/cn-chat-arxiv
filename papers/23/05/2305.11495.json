{
    "title": "Nonconvex Robust High-Order Tensor Completion Using Randomized Low-Rank Approximation. (arXiv:2305.11495v1 [cs.LG])",
    "abstract": "Within the tensor singular value decomposition (T-SVD) framework, existing robust low-rank tensor completion approaches have made great achievements in various areas of science and engineering. Nevertheless, these methods involve the T-SVD based low-rank approximation, which suffers from high computational costs when dealing with large-scale tensor data. Moreover, most of them are only applicable to third-order tensors. Against these issues, in this article, two efficient low-rank tensor approximation approaches fusing randomized techniques are first devised under the order-d (d >= 3) T-SVD framework. On this basis, we then further investigate the robust high-order tensor completion (RHTC) problem, in which a double nonconvex model along with its corresponding fast optimization algorithms with convergence guarantees are developed. To the best of our knowledge, this is the first study to incorporate the randomized low-rank approximation into the RHTC problem. Empirical studies on large-",
    "link": "http://arxiv.org/abs/2305.11495",
    "context": "Title: Nonconvex Robust High-Order Tensor Completion Using Randomized Low-Rank Approximation. (arXiv:2305.11495v1 [cs.LG])\nAbstract: Within the tensor singular value decomposition (T-SVD) framework, existing robust low-rank tensor completion approaches have made great achievements in various areas of science and engineering. Nevertheless, these methods involve the T-SVD based low-rank approximation, which suffers from high computational costs when dealing with large-scale tensor data. Moreover, most of them are only applicable to third-order tensors. Against these issues, in this article, two efficient low-rank tensor approximation approaches fusing randomized techniques are first devised under the order-d (d >= 3) T-SVD framework. On this basis, we then further investigate the robust high-order tensor completion (RHTC) problem, in which a double nonconvex model along with its corresponding fast optimization algorithms with convergence guarantees are developed. To the best of our knowledge, this is the first study to incorporate the randomized low-rank approximation into the RHTC problem. Empirical studies on large-",
    "path": "papers/23/05/2305.11495.json",
    "total_tokens": 999,
    "translated_title": "基于随机低秩逼近的非凸鲁棒高阶张量完成",
    "translated_abstract": "在张量奇异值分解（T-SVD）框架下，现有的稳健低秩张量完成方法在科学和工程的各个领域取得了巨大的成就。然而，这些方法涉及基于T-SVD的低秩逼近，在处理大规模张量数据时面临高计算成本的问题。此外，它们中的大多数仅适用于三阶张量。针对这些问题，在本文中，我们首先在d阶（d>=3）T-SVD框架下设计了两种融合随机技术的高效低秩张量逼近方法。在此基础上，我们进一步探讨了鲁棒高阶张量完成（RHTC）问题，开发了双非凸模型及其相应的快速优化算法，并提供了收敛保证。据我们所知，这是第一次将随机低秩逼近纳入RHTC问题的研究。对大规模合成和真实世界的高阶张量完成任务的实证研究表明，与现有方法相比，所提出的算法具有卓越的性能。",
    "tldr": "本文提出了两种高效低秩张量逼近方法和双非凸模型及其相应的快速优化算法，用于解决鲁棒高阶张量完成问题，并在大规模合成和真实世界的任务上证明了其优越性能。",
    "en_tdlr": "This paper proposes two efficient low-rank tensor approximation methods and a double nonconvex model with its corresponding fast optimization algorithms to solve the robust high-order tensor completion problem under the d-order T-SVD framework. The proposed algorithms are demonstrated to have superior performance on large-scale synthetic and real-world tasks compared with existing methods."
}