{
    "title": "FastFit: Towards Real-Time Iterative Neural Vocoder by Replacing U-Net Encoder With Multiple STFTs. (arXiv:2305.10823v1 [eess.AS])",
    "abstract": "This paper presents FastFit, a novel neural vocoder architecture that replaces the U-Net encoder with multiple short-time Fourier transforms (STFTs) to achieve faster generation rates without sacrificing sample quality. We replaced each encoder block with an STFT, with parameters equal to the temporal resolution of each decoder block, leading to the skip connection. FastFit reduces the number of parameters and the generation time of the model by almost half while maintaining high fidelity. Through objective and subjective evaluations, we demonstrated that the proposed model achieves nearly twice the generation speed of baseline iteration-based vocoders while maintaining high sound quality. We further showed that FastFit produces sound qualities similar to those of other baselines in text-to-speech evaluation scenarios, including multi-speaker and zero-shot text-to-speech.",
    "link": "http://arxiv.org/abs/2305.10823",
    "context": "Title: FastFit: Towards Real-Time Iterative Neural Vocoder by Replacing U-Net Encoder With Multiple STFTs. (arXiv:2305.10823v1 [eess.AS])\nAbstract: This paper presents FastFit, a novel neural vocoder architecture that replaces the U-Net encoder with multiple short-time Fourier transforms (STFTs) to achieve faster generation rates without sacrificing sample quality. We replaced each encoder block with an STFT, with parameters equal to the temporal resolution of each decoder block, leading to the skip connection. FastFit reduces the number of parameters and the generation time of the model by almost half while maintaining high fidelity. Through objective and subjective evaluations, we demonstrated that the proposed model achieves nearly twice the generation speed of baseline iteration-based vocoders while maintaining high sound quality. We further showed that FastFit produces sound qualities similar to those of other baselines in text-to-speech evaluation scenarios, including multi-speaker and zero-shot text-to-speech.",
    "path": "papers/23/05/2305.10823.json",
    "total_tokens": 870,
    "translated_title": "FastFit: 用多个STFT替换U-Net编码器实现实时迭代神经声码器",
    "translated_abstract": "本文提出了一种新颖的神经声码器结构FastFit，通过使用多个短时傅里叶变换（STFT）替换U-Net编码器，在不损失音频质量的情况下实现更快的生成速度。我们将每个编码器块都替换为一个STFT，其参数等于每个解码器块的时间分辨率，从而形成跳跃连接。FastFit几乎将模型的参数数量和生成时间减少了一半，同时保持高保真度。通过客观和主观评估，我们证明了该模型在保持高音频质量的同时，实现了基准迭代声码器近两倍的生成速度。我们进一步展示了FastFit在文本转语音评估场景中，包括多说话人和零样本文本转语音中，产生类似于其他基线的音频质量。",
    "tldr": "本文提出了FastFit，一种使用多个STFT替换U-Net编码器的声音生成算法，将模型参数数量和生成时间减少了一半，并在保持高保真度的同时实现了近两倍的生成速度。",
    "en_tdlr": "This paper proposes FastFit, a neural vocoder algorithm that replaces the U-Net encoder with multiple STFTs, reducing the number of parameters and generation time by almost half while maintaining high fidelity. Through objective and subjective evaluations, FastFit achieves nearly twice the generation speed of baseline iteration-based vocoders while producing sound qualities similar to other baselines in text-to-speech evaluation scenarios."
}