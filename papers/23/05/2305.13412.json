{
    "title": "Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method. (arXiv:2305.13412v1 [cs.CL])",
    "abstract": "Automatic summarization generates concise summaries that contain key ideas of source documents. As the most mainstream datasets for the news sub-domain, CNN/DailyMail and BBC XSum have been widely used for performance benchmarking. However, the reference summaries of those datasets turn out to be noisy, mainly in terms of factual hallucination and information redundancy. To address this challenge, we first annotate new expert-writing Element-aware test sets following the \"Lasswell Communication Model\" proposed by Lasswell (1948), allowing reference summaries to focus on more fine-grained news elements objectively and comprehensively. Utilizing the new test sets, we observe the surprising zero-shot summary ability of LLMs, which addresses the issue of the inconsistent results between human preference and automatic evaluation metrics of LLMs' zero-shot summaries in prior work. Further, we propose a Summary Chain-of-Thought (SumCoT) technique to elicit LLMs to generate summaries step by s",
    "link": "http://arxiv.org/abs/2305.13412",
    "context": "Title: Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method. (arXiv:2305.13412v1 [cs.CL])\nAbstract: Automatic summarization generates concise summaries that contain key ideas of source documents. As the most mainstream datasets for the news sub-domain, CNN/DailyMail and BBC XSum have been widely used for performance benchmarking. However, the reference summaries of those datasets turn out to be noisy, mainly in terms of factual hallucination and information redundancy. To address this challenge, we first annotate new expert-writing Element-aware test sets following the \"Lasswell Communication Model\" proposed by Lasswell (1948), allowing reference summaries to focus on more fine-grained news elements objectively and comprehensively. Utilizing the new test sets, we observe the surprising zero-shot summary ability of LLMs, which addresses the issue of the inconsistent results between human preference and automatic evaluation metrics of LLMs' zero-shot summaries in prior work. Further, we propose a Summary Chain-of-Thought (SumCoT) technique to elicit LLMs to generate summaries step by s",
    "path": "papers/23/05/2305.13412.json",
    "total_tokens": 1189,
    "translated_title": "大语言模型的元素感知文摘：专家对齐评估和思路链技术",
    "translated_abstract": "自动摘要生成包含源文件关键思想的简洁摘要。CNN / DailyMail和BBC XSum作为新闻领域的最主流数据集，已被广泛用于性能基准测试。然而，这些数据集的参考摘要证明是嘈杂的，主要体现在事实幻觉和信息冗余方面。为了应对这一挑战，我们首先按照Lasswell（1948）提出的“Lasswell通讯模型”注释了新的专家编写的元素感知测试集，允许参考摘要客观全面地关注更细粒度的新闻元素。利用新的测试集，我们观察到LLMs惊人的零-shot文摘能力，解决了LLMs的零-shot文摘在先前工作中的人类偏好和自动评估指标之间不一致结果的问题。此外，我们提出了一个Summary Chain-of-Thought（SumCoT）技术，以逐步引导LLMs生成摘要，以更好地处理连贯性和相关性。在CNN / DailyMail和我们的新元素感知测试集上的实验结果表明，SumCoT在各个方面显著提高了LLM生成的摘要质量。作为主要应用，我们展示元素感知文摘可以在推荐场景中受益于用户意图理解，在实际电影摘要数据集上产生最高7％的准确率改善。",
    "tldr": "通过新的元素感知测试集为自动文摘提供更细粒度的参考摘要，使用 LLMS 以零-shot方式生成摘要，提出 SumCoT 技术以改进连贯性和相关性，并在多个数据集上进行实验，为推荐场景中的用户意图理解提供了7％的准确率改善。",
    "en_tdlr": "This paper introduces a new expert-writing Element-aware test set for automatic summarization and proposes a Summary Chain-of-Thought (SumCoT) technique to improve the coherence and relevance of large language models' generated summaries. Additionally, the paper examines the surprising zero-shot summary ability of LLMs and shows that Element-aware summarization can benefit user intent understanding in recommendation scenarios with up to 7% accuracy improvement on a real-world movie summarization dataset."
}