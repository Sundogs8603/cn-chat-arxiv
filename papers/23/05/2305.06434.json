{
    "title": "Word Grounded Graph Convolutional Network. (arXiv:2305.06434v1 [cs.CL])",
    "abstract": "Graph Convolutional Networks (GCNs) have shown strong performance in learning text representations for various tasks such as text classification, due to its expressive power in modeling graph structure data (e.g., a literature citation network). Most existing GCNs are limited to deal with documents included in a pre-defined graph, i.e., it cannot be generalized to out-of-graph documents. To address this issue, we propose to transform the document graph into a word graph, to decouple data samples (i.e., documents in training and test sets) and a GCN model by using a document-independent graph. Such word-level GCN could therefore naturally inference out-of-graph documents in an inductive way. The proposed Word-level Graph (WGraph) can not only implicitly learning word presentation with commonly-used word co-occurrences in corpora, but also incorporate extra global semantic dependency derived from inter-document relationships (e.g., literature citations). An inductive Word-grounded Graph ",
    "link": "http://arxiv.org/abs/2305.06434",
    "context": "Title: Word Grounded Graph Convolutional Network. (arXiv:2305.06434v1 [cs.CL])\nAbstract: Graph Convolutional Networks (GCNs) have shown strong performance in learning text representations for various tasks such as text classification, due to its expressive power in modeling graph structure data (e.g., a literature citation network). Most existing GCNs are limited to deal with documents included in a pre-defined graph, i.e., it cannot be generalized to out-of-graph documents. To address this issue, we propose to transform the document graph into a word graph, to decouple data samples (i.e., documents in training and test sets) and a GCN model by using a document-independent graph. Such word-level GCN could therefore naturally inference out-of-graph documents in an inductive way. The proposed Word-level Graph (WGraph) can not only implicitly learning word presentation with commonly-used word co-occurrences in corpora, but also incorporate extra global semantic dependency derived from inter-document relationships (e.g., literature citations). An inductive Word-grounded Graph ",
    "path": "papers/23/05/2305.06434.json",
    "total_tokens": 996,
    "translated_title": "基于词语的图卷积网络",
    "translated_abstract": "图卷积网络（GCNs）在学习文本表示方面表现出较强的性能，特别是在建模图结构数据（如文献引用网络）方面，对于各种任务如文本分类等都有良好的表现。大多数现有的GCNs仅限于处理预定义图中的文档，即不能推广到图外文档。为了解决这个问题，我们提出将文档图转化为词图，通过使用独立于文档的图来解耦数据样本（即训练和测试集中的文档）和GCN模型。这种基于词级的GCN因此可以自然地归纳地推理出图外文档。提出了基于WGraph的归纳词语图卷积网络（WGCN），它可以对单词级文本实例（如不在语料库中的文档）进行归纳推理。在四个基准数据集上的实验表明，WGCN优于现有方法，通过图形方法联合建模词级和文档级信息的有效性。",
    "tldr": "该论文提出了一种基于词语的图卷积网络模型，可以在处理图外文档时进行归纳推理；该模型在多个基准数据集上表现出较好的性能，同时表明了基于图的方法联合建模词级和文档级信息的有效性。",
    "en_tdlr": "This paper proposes a word-grounded graph convolutional network (WGCN) model that can perform inductive reasoning for out-of-graph documents, which is superior to state-of-the-art methods on multiple benchmark datasets, indicating the effectiveness of jointly modeling word-level and document-level information via a graph-based approach."
}