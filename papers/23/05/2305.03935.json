{
    "title": "Improved Techniques for Maximum Likelihood Estimation for Diffusion ODEs. (arXiv:2305.03935v1 [cs.LG])",
    "abstract": "Diffusion models have exhibited excellent performance in various domains. The probability flow ordinary differential equation (ODE) of diffusion models (i.e., diffusion ODEs) is a particular case of continuous normalizing flows (CNFs), which enables deterministic inference and exact likelihood evaluation. However, the likelihood estimation results by diffusion ODEs are still far from those of the state-of-the-art likelihood-based generative models. In this work, we propose several improved techniques for maximum likelihood estimation for diffusion ODEs, including both training and evaluation perspectives. For training, we propose velocity parameterization and explore variance reduction techniques for faster convergence. We also derive an error-bounded high-order flow matching objective for finetuning, which improves the ODE likelihood and smooths its trajectory. For evaluation, we propose a novel training-free truncated-normal dequantization to fill the training-evaluation gap commonly",
    "link": "http://arxiv.org/abs/2305.03935",
    "context": "Title: Improved Techniques for Maximum Likelihood Estimation for Diffusion ODEs. (arXiv:2305.03935v1 [cs.LG])\nAbstract: Diffusion models have exhibited excellent performance in various domains. The probability flow ordinary differential equation (ODE) of diffusion models (i.e., diffusion ODEs) is a particular case of continuous normalizing flows (CNFs), which enables deterministic inference and exact likelihood evaluation. However, the likelihood estimation results by diffusion ODEs are still far from those of the state-of-the-art likelihood-based generative models. In this work, we propose several improved techniques for maximum likelihood estimation for diffusion ODEs, including both training and evaluation perspectives. For training, we propose velocity parameterization and explore variance reduction techniques for faster convergence. We also derive an error-bounded high-order flow matching objective for finetuning, which improves the ODE likelihood and smooths its trajectory. For evaluation, we propose a novel training-free truncated-normal dequantization to fill the training-evaluation gap commonly",
    "path": "papers/23/05/2305.03935.json",
    "total_tokens": 946,
    "translated_title": "基于扩散ODEs最大似然估计的改进技术",
    "translated_abstract": "扩散模型在各领域中表现出良好的性能。扩散模型的概率流常微分方程（ODE）（即扩散ODE）是连续归一化流（CNFs）的一个特例，它使得确定性推断和精确似然评估成为可能。然而，与最先进的基于似然的生成模型相比，扩散ODE的似然估计结果仍有很大差距。在本文中，我们提出了一些改进的技术，包括训练和评估两个方面，用于扩散ODE的最大似然估计。对于训练，我们提出了速度参数化，并探索方差减少技术以加快收敛速度。我们还设计了一个误差有界的高阶流匹配目标用于微调，从而提高ODE的似然估计并平滑其轨迹。对于评估，我们提出了一种新颖的无须训练的截断正态去量化方法来填补训练-评估间的差距。",
    "tldr": "本文提出了基于扩散ODEs最大似然估计的改进技术，包括速度参数化和方差减少技术等用于训练的技术，以及误差有界的高阶流匹配目标用于微调和截断正态去量化方法用于评估。",
    "en_tdlr": "This paper proposes improved techniques for maximum likelihood estimation for diffusion ODEs, including velocity parameterization, variance reduction techniques for training, as well as error-bounded high-order flow matching objective for fine-tuning. A novel training-free truncated-normal dequantization is also proposed for evaluation."
}