{
    "title": "Enhancing Gappy Speech Audio Signals with Generative Adversarial Networks. (arXiv:2305.05780v1 [cs.SD])",
    "abstract": "Gaps, dropouts and short clips of corrupted audio are a common problem and particularly annoying when they occur in speech. This paper uses machine learning to regenerate gaps of up to 320ms in an audio speech signal. Audio regeneration is translated into image regeneration by transforming audio into a Mel-spectrogram and using image in-painting to regenerate the gaps. The full Mel-spectrogram is then transferred back to audio using the Parallel-WaveGAN vocoder and integrated into the audio stream. Using a sample of 1300 spoken audio clips of between 1 and 10 seconds taken from the publicly-available LJSpeech dataset our results show regeneration of audio gaps in close to real time using GANs with a GPU equipped system. As expected, the smaller the gap in the audio, the better the quality of the filled gaps. On a gap of 240ms the average mean opinion score (MOS) for the best performing models was 3.737, on a scale of 1 (worst) to 5 (best) which is sufficient for a human to perceive as ",
    "link": "http://arxiv.org/abs/2305.05780",
    "context": "Title: Enhancing Gappy Speech Audio Signals with Generative Adversarial Networks. (arXiv:2305.05780v1 [cs.SD])\nAbstract: Gaps, dropouts and short clips of corrupted audio are a common problem and particularly annoying when they occur in speech. This paper uses machine learning to regenerate gaps of up to 320ms in an audio speech signal. Audio regeneration is translated into image regeneration by transforming audio into a Mel-spectrogram and using image in-painting to regenerate the gaps. The full Mel-spectrogram is then transferred back to audio using the Parallel-WaveGAN vocoder and integrated into the audio stream. Using a sample of 1300 spoken audio clips of between 1 and 10 seconds taken from the publicly-available LJSpeech dataset our results show regeneration of audio gaps in close to real time using GANs with a GPU equipped system. As expected, the smaller the gap in the audio, the better the quality of the filled gaps. On a gap of 240ms the average mean opinion score (MOS) for the best performing models was 3.737, on a scale of 1 (worst) to 5 (best) which is sufficient for a human to perceive as ",
    "path": "papers/23/05/2305.05780.json",
    "total_tokens": 926,
    "translated_title": "利用生成对抗网络增强有噪音的语音信号的间隔",
    "translated_abstract": "语音中的噪声、漏报和片段丢失是常见问题，尤其是在语音识别等应用中影响很大。本文利用机器学习方法增强320ms内的语音信号中的间隔。通过将音频转换为Mel-频谱图并使用图像修复技术进行间隔恢复。最终将完整的Mel-频谱图转换回音频，并使用Parallel-WaveGAN声码器集成到音频流中。研究结果表明，使用具有GPU的GAN系统实现接近实时的音频间隔重建。与预期相符，音频中间隔越小，填充后的质量就越好。在240ms的间隔上，最佳的模型的平均意见分数（MOS）为3.737，这足以被人类感知为好的音频质量。",
    "tldr": "本文利用机器学习和生成对抗网络提出了一种方法，通过将语音转换为Mel频谱图并使用图像修复技术进行间隔恢复，实现了接近实时的音频间隔重建，填充后的质量与原始数据相近，可以有效提高语音信号的质量。",
    "en_tdlr": "This paper proposes a method using machine learning with Generative Adversarial Networks to regenerate gaps in speech audio signals in close to real-time. By transforming speech audio into Mel-spectrogram and using image in-painting to regenerate the gaps, the quality of the filled gaps is close to the original data, which can effectively improve the quality of speech signals."
}