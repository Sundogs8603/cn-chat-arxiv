{
    "title": "DeepFilterNet: Perceptually Motivated Real-Time Speech Enhancement. (arXiv:2305.08227v1 [eess.AS])",
    "abstract": "Multi-frame algorithms for single-channel speech enhancement are able to take advantage from short-time correlations within the speech signal. Deep Filtering (DF) was proposed to directly estimate a complex filter in frequency domain to take advantage of these correlations. In this work, we present a real-time speech enhancement demo using DeepFilterNet. DeepFilterNet's efficiency is enabled by exploiting domain knowledge of speech production and psychoacoustic perception. Our model is able to match state-of-the-art speech enhancement benchmarks while achieving a real-time-factor of 0.19 on a single threaded notebook CPU. The framework as well as pretrained weights have been published under an open source license.",
    "link": "http://arxiv.org/abs/2305.08227",
    "context": "Title: DeepFilterNet: Perceptually Motivated Real-Time Speech Enhancement. (arXiv:2305.08227v1 [eess.AS])\nAbstract: Multi-frame algorithms for single-channel speech enhancement are able to take advantage from short-time correlations within the speech signal. Deep Filtering (DF) was proposed to directly estimate a complex filter in frequency domain to take advantage of these correlations. In this work, we present a real-time speech enhancement demo using DeepFilterNet. DeepFilterNet's efficiency is enabled by exploiting domain knowledge of speech production and psychoacoustic perception. Our model is able to match state-of-the-art speech enhancement benchmarks while achieving a real-time-factor of 0.19 on a single threaded notebook CPU. The framework as well as pretrained weights have been published under an open source license.",
    "path": "papers/23/05/2305.08227.json",
    "total_tokens": 764,
    "translated_title": "DeepFilterNet: 基于感知的实时语音增强",
    "translated_abstract": "单通道语音增强的多帧算法能够利用语音信号中的短时相关性。Deep Filtering(DF) 提出了直接在频域估计复杂滤波器以利用这些相关性。本文提出了使用DeepFilterNet进行实时语音增强的演示。DeepFilterNet的效率是通过利用语音生产和心理声学感知领域的知识实现的。我们的模型能够匹配最先进的语音增强基准，同时在单线程笔记本电脑上实现了0.19的实时因子。该框架以及预先训练的权重已经发表了开源许可证。",
    "tldr": "DeepFilterNet是一个基于感知的实时语音增强框架，利用语音生产和心理声学感知领域的知识实现高效率。在单线程笔记本电脑上实现了0.19的实时因子，在匹配最先进的语音增强基准方面表现出色。",
    "en_tdlr": "DeepFilterNet is a perception-motivated real-time speech enhancement framework, which achieves high efficiency by exploiting domain knowledge of speech production and psychoacoustic perception. With 0.19 real-time factor on a single threaded notebook CPU, it matches state-of-the-art speech enhancement benchmarks."
}