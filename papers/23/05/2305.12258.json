{
    "title": "Constructing Code-mixed Universal Dependency Forest for Unbiased Cross-lingual Relation Extraction. (arXiv:2305.12258v2 [cs.CL] UPDATED)",
    "abstract": "Latest efforts on cross-lingual relation extraction (XRE) aggressively leverage the language-consistent structural features from the universal dependency (UD) resource, while they may largely suffer from biased transfer (e.g., either target-biased or source-biased) due to the inevitable linguistic disparity between languages. In this work, we investigate an unbiased UD-based XRE transfer by constructing a type of code-mixed UD forest. We first translate the sentence of the source language to the parallel target-side language, for both of which we parse the UD tree respectively. Then, we merge the source-/target-side UD structures as a unified code-mixed UD forest. With such forest features, the gaps of UD-based XRE between the training and predicting phases can be effectively closed. We conduct experiments on the ACE XRE benchmark datasets, where the results demonstrate that the proposed code-mixed UD forests help unbiased UD-based XRE transfer, with which we achieve significant XRE pe",
    "link": "http://arxiv.org/abs/2305.12258",
    "context": "Title: Constructing Code-mixed Universal Dependency Forest for Unbiased Cross-lingual Relation Extraction. (arXiv:2305.12258v2 [cs.CL] UPDATED)\nAbstract: Latest efforts on cross-lingual relation extraction (XRE) aggressively leverage the language-consistent structural features from the universal dependency (UD) resource, while they may largely suffer from biased transfer (e.g., either target-biased or source-biased) due to the inevitable linguistic disparity between languages. In this work, we investigate an unbiased UD-based XRE transfer by constructing a type of code-mixed UD forest. We first translate the sentence of the source language to the parallel target-side language, for both of which we parse the UD tree respectively. Then, we merge the source-/target-side UD structures as a unified code-mixed UD forest. With such forest features, the gaps of UD-based XRE between the training and predicting phases can be effectively closed. We conduct experiments on the ACE XRE benchmark datasets, where the results demonstrate that the proposed code-mixed UD forests help unbiased UD-based XRE transfer, with which we achieve significant XRE pe",
    "path": "papers/23/05/2305.12258.json",
    "total_tokens": 970,
    "translated_title": "为无偏的跨语言关系抽取构建混合编码的通用依存森林",
    "translated_abstract": "最近的跨语言关系抽取研究采用通用依存（UD）资源的语言一致性结构特征，但由于语言的不可避免差异，很容易遭受受偏转移（例如目标偏差或源偏差）。在本文中，我们通过构建一种类型的混合编码UD树，研究了一种无偏的UD树跨语言关系抽取转移。首先将源语言的句子翻译成平行的目标语言，对两种语言都分别解析UD树，然后将源语言/目标语言的UD结构合并为统一的混合编码UD树。通过这样的森林特征，UD树的跨语言关系抽取训练和预测阶段之间的差距可以有效缩小。我们在ACE XRE基准数据集上进行实验，结果表明，所提出的混合编码UD森林有助于无偏的UD树跨语言关系抽取转移，并实现了显着的跨语言关系抽取性能提升。",
    "tldr": "本文提出了一种无偏的UD树跨语言关系抽取转移方法，通过构建混合编码UD树，有助于弥合训练和预测阶段之间差距从而实现显著的跨语言关系抽取性能提升。",
    "en_tdlr": "This paper proposes an unbiased transfer method for cross-lingual relation extraction by constructing a code-mixed UD tree. By merging source- and target-side UD structures, the proposed method effectively closes the gap between the training and predicting phases, achieving significant performance improvement."
}