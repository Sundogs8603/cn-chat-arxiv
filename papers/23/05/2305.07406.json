{
    "title": "Two-in-One: A Model Hijacking Attack Against Text Generation Models. (arXiv:2305.07406v1 [cs.CR])",
    "abstract": "Machine learning has progressed significantly in various applications ranging from face recognition to text generation. However, its success has been accompanied by different attacks. Recently a new attack has been proposed which raises both accountability and parasitic computing risks, namely the model hijacking attack. Nevertheless, this attack has only focused on image classification tasks. In this work, we broaden the scope of this attack to include text generation and classification models, hence showing its broader applicability. More concretely, we propose a new model hijacking attack, Ditto, that can hijack different text classification tasks into multiple generation ones, e.g., language translation, text summarization, and language modeling. We use a range of text benchmark datasets such as SST-2, TweetEval, AGnews, QNLI, and IMDB to evaluate the performance of our attacks. Our results show that by using Ditto, an adversary can successfully hijack text generation models withou",
    "link": "http://arxiv.org/abs/2305.07406",
    "context": "Title: Two-in-One: A Model Hijacking Attack Against Text Generation Models. (arXiv:2305.07406v1 [cs.CR])\nAbstract: Machine learning has progressed significantly in various applications ranging from face recognition to text generation. However, its success has been accompanied by different attacks. Recently a new attack has been proposed which raises both accountability and parasitic computing risks, namely the model hijacking attack. Nevertheless, this attack has only focused on image classification tasks. In this work, we broaden the scope of this attack to include text generation and classification models, hence showing its broader applicability. More concretely, we propose a new model hijacking attack, Ditto, that can hijack different text classification tasks into multiple generation ones, e.g., language translation, text summarization, and language modeling. We use a range of text benchmark datasets such as SST-2, TweetEval, AGnews, QNLI, and IMDB to evaluate the performance of our attacks. Our results show that by using Ditto, an adversary can successfully hijack text generation models withou",
    "path": "papers/23/05/2305.07406.json",
    "total_tokens": 895,
    "translated_title": "两合一：一种针对文本生成模型的模型劫持攻击",
    "translated_abstract": "机器学习在各种应用中取得了显著进展，从人脸识别到文本生成。然而，它的成功也伴随着各种攻击。最近提出了一种新的攻击，即模型劫持攻击，该攻击提高了问责和寄生计算的风险。但是，该攻击仅集中于图像分类任务。在本文中，我们将此攻击的范围扩大到包括文本生成和分类模型，从而展示其更广泛的适用性。具体而言，我们提出了一种新的模型劫持攻击——Ditto，它可以将不同的文本分类任务劫持为多个生成任务，例如语言翻译、文本摘要和语言建模。我们使用一系列文本基准数据集（如SST-2、TweetEval、AGnews、QNLI和IMDB）来评估我们攻击的性能。我们的结果表明，使用Ditto，攻击者可以成功地劫持文本生成模型。",
    "tldr": "本文扩展了模型劫持攻击的范围，提出了一种名为Ditto的攻击方法，能够将不同的文本分类任务劫持为多个生成任务，并使用多个基准数据集验证了攻击的成功性。",
    "en_tdlr": "This paper broadens the scope of model hijacking attacks and proposes a new attack method named Ditto, which can hijack different text classification tasks into multiple generation ones. The authors validate the effectiveness of the attack using various benchmark datasets."
}