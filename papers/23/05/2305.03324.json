{
    "title": "Augmenting Low-Resource Text Classification with Graph-Grounded Pre-training and Prompting. (arXiv:2305.03324v1 [cs.IR])",
    "abstract": "Text classification is a fundamental problem in information retrieval with many real-world applications, such as predicting the topics of online articles and the categories of e-commerce product descriptions. However, low-resource text classification, with few or no labeled samples, poses a serious concern for supervised learning. Meanwhile, many text data are inherently grounded on a network structure, such as a hyperlink/citation network for online articles, and a user-item purchase network for e-commerce products. These graph structures capture rich semantic relationships, which can potentially augment low-resource text classification. In this paper, we propose a novel model called Graph-Grounded Pre-training and Prompting (G2P2) to address low-resource text classification in a two-pronged approach. During pre-training, we propose three graph interaction-based contrastive strategies to jointly pre-train a graph-text model; during downstream classification, we explore prompting for t",
    "link": "http://arxiv.org/abs/2305.03324",
    "context": "Title: Augmenting Low-Resource Text Classification with Graph-Grounded Pre-training and Prompting. (arXiv:2305.03324v1 [cs.IR])\nAbstract: Text classification is a fundamental problem in information retrieval with many real-world applications, such as predicting the topics of online articles and the categories of e-commerce product descriptions. However, low-resource text classification, with few or no labeled samples, poses a serious concern for supervised learning. Meanwhile, many text data are inherently grounded on a network structure, such as a hyperlink/citation network for online articles, and a user-item purchase network for e-commerce products. These graph structures capture rich semantic relationships, which can potentially augment low-resource text classification. In this paper, we propose a novel model called Graph-Grounded Pre-training and Prompting (G2P2) to address low-resource text classification in a two-pronged approach. During pre-training, we propose three graph interaction-based contrastive strategies to jointly pre-train a graph-text model; during downstream classification, we explore prompting for t",
    "path": "papers/23/05/2305.03324.json",
    "total_tokens": 986,
    "translated_title": "用图谱预训练和提示增强低资源文本分类",
    "translated_abstract": "文本分类是信息检索中的一个基本问题，具有许多实际应用，例如预测在线文章的主题和电子商务产品描述的类别。然而，低资源文本分类，没有或只有很少标记样本，对于监督学习来说是一个严重的问题。同时，许多文本数据本质上基于网络结构，例如在线文章的超链接/引用网络和电子商务产品的用户-项目购买网络。这些图形结构捕捉了丰富的语义关系，可以潜在地增强低资源文本分类。本文提出了一种新颖的模型，称为图形基础预训练和提示（G2P2），以两个方面解决低资源文本分类。在预训练期间，我们提出了三种基于图形交互的对比策略，以联合预训练图形-文本模型；在下游分类过程中，我们探索提示进行从高资源到低资源任务的迁移学习。在四个低资源基准测试上的实验表明，G2P2显着优于先前的最先进方法，我们的分析表明，图形接地和提示策略对于利用辅助知识进行低资源文本分类是有效的。",
    "tldr": "本文提出一种名为G2P2的模型，使用图谱预训练和提示的方式增强低资源文本分类，实验证明该模型优于现有的最先进方法。",
    "en_tdlr": "This paper proposes a model called G2P2 for low-resource text classification using graph-grounded pre-training and prompting, which outperforms previous state-of-the-art methods according to experiments on four benchmarks."
}