{
    "title": "Modular Domain Adaptation for Conformer-Based Streaming ASR. (arXiv:2305.13408v1 [eess.AS])",
    "abstract": "Speech data from different domains has distinct acoustic and linguistic characteristics. It is common to train a single multidomain model such as a Conformer transducer for speech recognition on a mixture of data from all domains. However, changing data in one domain or adding a new domain would require the multidomain model to be retrained. To this end, we propose a framework called modular domain adaptation (MDA) that enables a single model to process multidomain data while keeping all parameters domain-specific, i.e., each parameter is only trained by data from one domain. On a streaming Conformer transducer trained only on video caption data, experimental results show that an MDA-based model can reach similar performance as the multidomain model on other domains such as voice search and dictation by adding per-domain adapters and per-domain feed-forward networks in the Conformer encoder.",
    "link": "http://arxiv.org/abs/2305.13408",
    "context": "Title: Modular Domain Adaptation for Conformer-Based Streaming ASR. (arXiv:2305.13408v1 [eess.AS])\nAbstract: Speech data from different domains has distinct acoustic and linguistic characteristics. It is common to train a single multidomain model such as a Conformer transducer for speech recognition on a mixture of data from all domains. However, changing data in one domain or adding a new domain would require the multidomain model to be retrained. To this end, we propose a framework called modular domain adaptation (MDA) that enables a single model to process multidomain data while keeping all parameters domain-specific, i.e., each parameter is only trained by data from one domain. On a streaming Conformer transducer trained only on video caption data, experimental results show that an MDA-based model can reach similar performance as the multidomain model on other domains such as voice search and dictation by adding per-domain adapters and per-domain feed-forward networks in the Conformer encoder.",
    "path": "papers/23/05/2305.13408.json",
    "total_tokens": 936,
    "translated_title": "基于 Conformer 的流式语音识别模块化领域自适应",
    "translated_abstract": "不同领域的语音数据具有不同的声学和语言特征。通常在所有领域的混合数据上训练单个多域模型，如Conformer transducer语音识别器。但是，更改一个领域的数据或添加新领域会要求重新训练多领域模型。为此，我们提出了一种称为模块化领域适应（MDA）的框架，它可以使单个模型处理多领域数据，同时保持所有参数特定于领域，即每个参数仅由一个领域的数据训练。在仅使用视频字幕数据训练的流式Conformer transducer上，实验结果显示，通过在Conformer encoder中添加每个领域的适配器和逐领域的前馈网络，基于MDA的模型可以实现与多领域模型类似的性能在其他领域，如语音搜索和听写中。",
    "tldr": "论文提出了一种名为模块化领域适应的框架，使单个Conformer模型处理多领域数据，同时保持参数领域特异性，通过在Conformer编码器中添加每个领域的适配器和逐领域的前馈网络，可以在不重新训练多领域模型的情况下在其他领域（如语音搜索和听写）中达到类似的性能。",
    "en_tdlr": "This paper proposes a framework called Modular Domain Adaptation (MDA) that enables a single Conformer model to process multidomain data while keeping parameters domain-specific, achieving similar performance in other domains such as voice search and dictation without retraining the multidomain model by adding per-domain adapters and per-domain feed-forward networks in the Conformer encoder."
}