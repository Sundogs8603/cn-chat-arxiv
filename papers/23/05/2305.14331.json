{
    "title": "What Else Do I Need to Know? The Effect of Background Information on Users' Reliance on QA Systems. (arXiv:2305.14331v2 [cs.CL] UPDATED)",
    "abstract": "NLP systems have shown impressive performance at answering questions by retrieving relevant context. However, with the increasingly large models, it is impossible and often undesirable to constrain models' knowledge or reasoning to only the retrieved context. This leads to a mismatch between the information that the models access to derive the answer and the information that is available to the user to assess the model predicted answer. In this work, we study how users interact with QA systems in the absence of sufficient information to assess their predictions. Further, we ask whether adding the requisite background helps mitigate users' over-reliance on predictions. Our study reveals that users rely on model predictions even in the absence of sufficient information needed to assess the model's correctness. Providing the relevant background, however, helps users better catch model errors, reducing over-reliance on incorrect predictions. On the flip side, background information also in",
    "link": "http://arxiv.org/abs/2305.14331",
    "context": "Title: What Else Do I Need to Know? The Effect of Background Information on Users' Reliance on QA Systems. (arXiv:2305.14331v2 [cs.CL] UPDATED)\nAbstract: NLP systems have shown impressive performance at answering questions by retrieving relevant context. However, with the increasingly large models, it is impossible and often undesirable to constrain models' knowledge or reasoning to only the retrieved context. This leads to a mismatch between the information that the models access to derive the answer and the information that is available to the user to assess the model predicted answer. In this work, we study how users interact with QA systems in the absence of sufficient information to assess their predictions. Further, we ask whether adding the requisite background helps mitigate users' over-reliance on predictions. Our study reveals that users rely on model predictions even in the absence of sufficient information needed to assess the model's correctness. Providing the relevant background, however, helps users better catch model errors, reducing over-reliance on incorrect predictions. On the flip side, background information also in",
    "path": "papers/23/05/2305.14331.json",
    "total_tokens": 923,
    "translated_title": "用户对于QA系统的背景信息依赖的影响研究",
    "translated_abstract": "NLP系统在通过检索相关上下文来回答问题方面表现出色。然而，随着模型越来越大，仅限于检索到的上下文来限制模型的知识或推理是不可能的且通常也不可取的。这导致了模型从中提取答案的信息与用户用来评估模型预测答案的信息之间的不匹配。在本研究中，我们研究了在缺乏足够信息来评估预测时用户如何与QA系统交互。此外，我们还询问是否添加必要的背景信息有助于减少用户对预测的过度依赖。我们的研究发现，即使在缺乏足够信息来评估模型正确性的情况下，用户仍然依赖于模型的预测。然而，提供相关背景信息有助于用户更好地发现模型错误，减少对不正确预测的依赖。而背景信息的添加也可能增加用户对模型的过度依赖。",
    "tldr": "本研究调查了用户在评估模型预测时缺乏足够信息时与QA系统的交互方式，并发现即使缺乏这些信息，用户仍然过度依赖于模型的预测。然而，提供相关背景信息有助于减少对错误预测的依赖。",
    "en_tdlr": "This study investigates how users interact with QA systems when lacking sufficient information to assess model predictions, and finds that users still heavily rely on model predictions even without this information. However, providing relevant background information helps reduce reliance on incorrect predictions."
}