{
    "title": "Sample and Predict Your Latent: Modality-free Sequential Disentanglement via Contrastive Estimation. (arXiv:2305.15924v1 [cs.LG])",
    "abstract": "Unsupervised disentanglement is a long-standing challenge in representation learning. Recently, self-supervised techniques achieved impressive results in the sequential setting, where data is time-dependent. However, the latter methods employ modality-based data augmentations and random sampling or solve auxiliary tasks. In this work, we propose to avoid that by generating, sampling, and comparing empirical distributions from the underlying variational model. Unlike existing work, we introduce a self-supervised sequential disentanglement framework based on contrastive estimation with no external signals, while using common batch sizes and samples from the latent space itself. In practice, we propose a unified, efficient, and easy-to-code sampling strategy for semantically similar and dissimilar views of the data. We evaluate our approach on video, audio, and time series benchmarks. Our method presents state-of-the-art results in comparison to existing techniques. The code is available ",
    "link": "http://arxiv.org/abs/2305.15924",
    "context": "Title: Sample and Predict Your Latent: Modality-free Sequential Disentanglement via Contrastive Estimation. (arXiv:2305.15924v1 [cs.LG])\nAbstract: Unsupervised disentanglement is a long-standing challenge in representation learning. Recently, self-supervised techniques achieved impressive results in the sequential setting, where data is time-dependent. However, the latter methods employ modality-based data augmentations and random sampling or solve auxiliary tasks. In this work, we propose to avoid that by generating, sampling, and comparing empirical distributions from the underlying variational model. Unlike existing work, we introduce a self-supervised sequential disentanglement framework based on contrastive estimation with no external signals, while using common batch sizes and samples from the latent space itself. In practice, we propose a unified, efficient, and easy-to-code sampling strategy for semantically similar and dissimilar views of the data. We evaluate our approach on video, audio, and time series benchmarks. Our method presents state-of-the-art results in comparison to existing techniques. The code is available ",
    "path": "papers/23/05/2305.15924.json",
    "total_tokens": 1001,
    "translated_title": "通过对比估计进行无模态串行分离：样本和预测潜在信息",
    "translated_abstract": "无监督的分离学习一直是表示学习中的难题。最近，自监督技术在时间依赖型数据的顺序设置中取得了令人印象深刻的结果。然而，后者的方法采用基于模态的数据增强和随机抽样，或者解决辅助任务。在本文中，我们提出通过从基础变分模型生成、采样和比较经验分布来避免这种情况。与现有工作不同，我们引入了一个基于对比估计的自监督顺序分离框架，没有外部信号，同时使用普通批量大小和来自潜在空间本身的样本。在实践中，我们提出了一种统一的、高效的、易于编码的采样策略，用于语义上相似和不相似的数据视图。我们在视频、音频和时间序列基准测试上评估了我们的方法。与现有技术相比，我们的方法呈现出最先进的结果。代码可用。",
    "tldr": "本文提出了一种无模态串行分离框架，基于对比估计进行自监督，具有无外部信号、常用批量大小、样本集自身潜在空间等特点，可以解决无监督的分离学习。作者提出了一种采样策略，可以处理语义上相似和不相似的数据视图，并在视频、音频和时间序列基准测试上展现出最先进的结果。",
    "en_tdlr": "This paper proposes a modality-free sequential disentanglement framework based on contrastive estimation, which is self-supervised without external signals, and uses common batch sizes and samples from the latent space itself. The proposed sampling strategy can handle semantically similar and dissimilar views of the data, and achieves state-of-the-art results on video, audio, and time series benchmarks."
}