{
    "title": "How Effective Are Neural Networks for Fixing Security Vulnerabilities. (arXiv:2305.18607v1 [cs.SE])",
    "abstract": "Security vulnerability repair is a difficult task that is in dire need of automation. Two groups of techniques have shown promise: (1) large code language models (LLMs) that have been pre-trained on source code for tasks such as code completion, and (2) automated program repair (APR) techniques that use deep learning (DL) models to automatically fix software bugs.  This paper is the first to study and compare Java vulnerability repair capabilities of LLMs and DL-based APR models. The contributions include that we (1) apply and evaluate five LLMs (Codex, CodeGen, CodeT5, PLBART and InCoder), four fine-tuned LLMs, and four DL-based APR techniques on two real-world Java vulnerability benchmarks (Vul4J and VJBench), (2) design code transformations to address the training and test data overlapping threat to Codex, (3) create a new Java vulnerability repair benchmark VJBench, and its transformed version VJBench-trans and (4) evaluate LLMs and APR techniques on the transformed vulnerabilities",
    "link": "http://arxiv.org/abs/2305.18607",
    "context": "Title: How Effective Are Neural Networks for Fixing Security Vulnerabilities. (arXiv:2305.18607v1 [cs.SE])\nAbstract: Security vulnerability repair is a difficult task that is in dire need of automation. Two groups of techniques have shown promise: (1) large code language models (LLMs) that have been pre-trained on source code for tasks such as code completion, and (2) automated program repair (APR) techniques that use deep learning (DL) models to automatically fix software bugs.  This paper is the first to study and compare Java vulnerability repair capabilities of LLMs and DL-based APR models. The contributions include that we (1) apply and evaluate five LLMs (Codex, CodeGen, CodeT5, PLBART and InCoder), four fine-tuned LLMs, and four DL-based APR techniques on two real-world Java vulnerability benchmarks (Vul4J and VJBench), (2) design code transformations to address the training and test data overlapping threat to Codex, (3) create a new Java vulnerability repair benchmark VJBench, and its transformed version VJBench-trans and (4) evaluate LLMs and APR techniques on the transformed vulnerabilities",
    "path": "papers/23/05/2305.18607.json",
    "total_tokens": 943,
    "translated_title": "神经网络修复安全漏洞的有效性有多高？",
    "translated_abstract": "安全漏洞修复是一项需要自动化的困难任务。两组技术表现出了希望：（1）大型代码语言模型（LLMs），它们已经针对代码完成等任务进行了预训练，以及（2）使用深度学习（DL）模型自动修复软件错误的自动化程序修复（APR）技术。本文是首次研究和比较LLMs和DL-based APR模型在Java漏洞修复能力方面的论文。这项工作的贡献包括：（1）将并评估五个LLMs（Codex、CodeGen、CodeT5、PLBART和InCoder）、四个精细调整的LLMs和四种基于DL的APR技术在两个真实世界的Java漏洞基准（Vul4J和VJBench）上，（2）设计代码转换来解决对Codex的训练和测试数据重叠威胁，（3）创建一个新的Java漏洞修复基准VJBench，以及它的转化版本VJBench-trans，（4）评估LLMs和APR技术对转化的漏洞。",
    "tldr": "这篇论文比较了使用大型代码语言模型和自动化程序修复技术修复Java漏洞的能力，并提供了新的Java漏洞修复基准。在两个真实的Java漏洞基准上进行评估。",
    "en_tdlr": "This paper compares the capabilities of large code language models and automated program repair techniques in fixing Java vulnerabilities and provides a new Java vulnerability repair benchmark, evaluating on two real-world Java vulnerability benchmarks."
}