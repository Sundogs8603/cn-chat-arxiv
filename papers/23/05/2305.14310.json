{
    "title": "Navigating Prompt Complexity for Zero-Shot Classification: A Study of Large Language Models in Computational Social Science. (arXiv:2305.14310v2 [cs.CL] UPDATED)",
    "abstract": "Instruction-tuned Large Language Models (LLMs) have exhibited impressive language understanding and the capacity to generate responses that follow specific prompts. However, due to the computational demands associated with training these models, their applications often adopt a zero-shot setting. In this paper, we evaluate the zero-shot performance of two publicly accessible LLMs, ChatGPT and OpenAssistant, in the context of six Computational Social Science classification tasks, while also investigating the effects of various prompting strategies. Our experiments investigate the impact of prompt complexity, including the effect of incorporating label definitions into the prompt; use of synonyms for label names; and the influence of integrating past memories during foundation model training. The findings indicate that in a zero-shot setting, current LLMs are unable to match the performance of smaller, fine-tuned baseline transformer models (such as BERT-large). Additionally, we find tha",
    "link": "http://arxiv.org/abs/2305.14310",
    "context": "Title: Navigating Prompt Complexity for Zero-Shot Classification: A Study of Large Language Models in Computational Social Science. (arXiv:2305.14310v2 [cs.CL] UPDATED)\nAbstract: Instruction-tuned Large Language Models (LLMs) have exhibited impressive language understanding and the capacity to generate responses that follow specific prompts. However, due to the computational demands associated with training these models, their applications often adopt a zero-shot setting. In this paper, we evaluate the zero-shot performance of two publicly accessible LLMs, ChatGPT and OpenAssistant, in the context of six Computational Social Science classification tasks, while also investigating the effects of various prompting strategies. Our experiments investigate the impact of prompt complexity, including the effect of incorporating label definitions into the prompt; use of synonyms for label names; and the influence of integrating past memories during foundation model training. The findings indicate that in a zero-shot setting, current LLMs are unable to match the performance of smaller, fine-tuned baseline transformer models (such as BERT-large). Additionally, we find tha",
    "path": "papers/23/05/2305.14310.json",
    "total_tokens": 923,
    "translated_title": "零样本分类中的提示复杂性导航：一项关于大型语言模型在计算社会科学中的研究",
    "translated_abstract": "语言调整的大型语言模型(LLMs)展示出了令人印象深刻的语言理解能力，并且具有根据特定提示生成响应的能力。然而，由于训练这些模型所需的计算需求，它们的应用通常采用零样本设置。在本文中，我们评估了两个公开可访问的LLM，ChatGPT和OpenAssistant在六个计算社会科学分类任务的零样本性能，同时还研究了各种提示策略的影响。我们的实验调查了提示复杂性的影响，包括在提示中加入标签定义的效果；使用标签名称的同义词；以及在基础模型训练过程中整合过去记忆的影响。研究结果表明，在零样本设置下，目前的LLMs无法达到较小的微调基线转换模型（如BERT-large）的性能。此外，我们发现...",
    "tldr": "本研究通过评估两个大型语言模型在六个计算社会科学分类任务中的零样本性能，并研究了各种提示策略的影响。结果显示，当前的大型语言模型在零样本设置下无法与较小的微调基线模型相媲美。",
    "en_tdlr": "This study evaluates the zero-shot performance of two large language models in six Computational Social Science classification tasks and investigates the effects of various prompting strategies. The findings indicate that current large language models are unable to match the performance of smaller, fine-tuned baseline models in a zero-shot setting."
}