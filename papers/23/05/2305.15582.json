{
    "title": "Balancing Effect of Training Dataset Distribution of Multiple Styles for Multi-Style Text Transfer. (arXiv:2305.15582v1 [cs.CL])",
    "abstract": "Text style transfer is an exciting task within the field of natural language generation that is often plagued by the need for high-quality paired datasets. Furthermore, training a model for multi-attribute text style transfer requires datasets with sufficient support across all combinations of the considered stylistic attributes, adding to the challenges of training a style transfer model. This paper explores the impact of training data input diversity on the quality of the generated text from the multi-style transfer model. We construct a pseudo-parallel dataset by devising heuristics to adjust the style distribution in the training samples. We balance our training dataset using marginal and joint distributions to train our style transfer models. We observe that a balanced dataset produces more effective control effects over multiple styles than an imbalanced or skewed one. Through quantitative analysis, we explore the impact of multiple style distributions in training data on style-t",
    "link": "http://arxiv.org/abs/2305.15582",
    "context": "Title: Balancing Effect of Training Dataset Distribution of Multiple Styles for Multi-Style Text Transfer. (arXiv:2305.15582v1 [cs.CL])\nAbstract: Text style transfer is an exciting task within the field of natural language generation that is often plagued by the need for high-quality paired datasets. Furthermore, training a model for multi-attribute text style transfer requires datasets with sufficient support across all combinations of the considered stylistic attributes, adding to the challenges of training a style transfer model. This paper explores the impact of training data input diversity on the quality of the generated text from the multi-style transfer model. We construct a pseudo-parallel dataset by devising heuristics to adjust the style distribution in the training samples. We balance our training dataset using marginal and joint distributions to train our style transfer models. We observe that a balanced dataset produces more effective control effects over multiple styles than an imbalanced or skewed one. Through quantitative analysis, we explore the impact of multiple style distributions in training data on style-t",
    "path": "papers/23/05/2305.15582.json",
    "total_tokens": 866,
    "translated_title": "多样化训练数据分布对多种文本风格转换的平衡效应",
    "translated_abstract": "文本风格转换是自然语言生成领域中一个激动人心的任务，但需要高质量的成对数据。对于多属性文本风格转换，训练模型需要具有足够支持所有考虑风格属性组合的数据集，增加了训练模型的难度。本文探讨了训练数据输入多样性对多风格转换模型生成文本质量的影响。我们通过设计启发式方法调整训练样本中的风格分布，构建了一个伪平行数据集。通过边际和联合分布平衡我们的训练数据集，训练我们的风格转换模型。我们观察到，平衡的数据集比不平衡或倾斜的数据集产生更有效的多种风格控制效果。通过定量分析，我们探讨了训练数据中多种风格分布对文本风格转换性能的影响。",
    "tldr": "本文探讨了训练数据输入多样性对多种文本风格转换模型生成文本质量的影响，通过平衡训练数据集中的风格分布，可以产生更有效的多种风格控制效果。",
    "en_tdlr": "This paper explores the impact of training data input diversity on the quality of the generated text from multi-style transfer model, and balancing the style distribution in the training dataset can produce more effective control effects over multiple styles."
}