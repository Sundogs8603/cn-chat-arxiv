{
    "title": "A Dual Semantic-Aware Recurrent Global-Adaptive Network For Vision-and-Language Navigation. (arXiv:2305.03602v1 [cs.CV])",
    "abstract": "Vision-and-Language Navigation (VLN) is a realistic but challenging task that requires an agent to locate the target region using verbal and visual cues. While significant advancements have been achieved recently, there are still two broad limitations: (1) The explicit information mining for significant guiding semantics concealed in both vision and language is still under-explored; (2) The previously structured map method provides the average historical appearance of visited nodes, while it ignores distinctive contributions of various images and potent information retention in the reasoning process. This work proposes a dual semantic-aware recurrent global-adaptive network (DSRG) to address the above problems. First, DSRG proposes an instruction-guidance linguistic module (IGL) and an appearance-semantics visual module (ASV) for boosting vision and language semantic learning respectively. For the memory mechanism, a global adaptive aggregation module (GAA) is devised for explicit pano",
    "link": "http://arxiv.org/abs/2305.03602",
    "context": "Title: A Dual Semantic-Aware Recurrent Global-Adaptive Network For Vision-and-Language Navigation. (arXiv:2305.03602v1 [cs.CV])\nAbstract: Vision-and-Language Navigation (VLN) is a realistic but challenging task that requires an agent to locate the target region using verbal and visual cues. While significant advancements have been achieved recently, there are still two broad limitations: (1) The explicit information mining for significant guiding semantics concealed in both vision and language is still under-explored; (2) The previously structured map method provides the average historical appearance of visited nodes, while it ignores distinctive contributions of various images and potent information retention in the reasoning process. This work proposes a dual semantic-aware recurrent global-adaptive network (DSRG) to address the above problems. First, DSRG proposes an instruction-guidance linguistic module (IGL) and an appearance-semantics visual module (ASV) for boosting vision and language semantic learning respectively. For the memory mechanism, a global adaptive aggregation module (GAA) is devised for explicit pano",
    "path": "papers/23/05/2305.03602.json",
    "total_tokens": 773,
    "translated_title": "一种双重语义感知的全局适应循环网络用于视觉语言导航",
    "translated_abstract": "视觉语言导航是一项现实但具有挑战性的任务，需要代理使用语言和视觉线索定位目标区域。本文提出了一种双重语义感知的全局适应循环网络 (DSRG) 来解决该问题。首先，DSRG 提出了一个指导语言模块 (IGL) 和一个外观语义视觉模块 (ASV) 分别提高视觉和语言语义学习。对于内存机制，还引入了全局自适应聚合模块 (GAA)。",
    "tldr": "本文提出了一种双重语义感知的全局适应循环网络，通过引入指导语言模块和外观语义视觉模块，以及全局自适应聚合模块，提高了在视觉语言导航中的语义学习。",
    "en_tdlr": "This paper proposes a dual semantic-aware recurrent global-adaptive network (DSRG) to boost semantic learning in vision-and-language navigation, by introducing an instruction-guidance linguistic module, an appearance-semantics visual module, and a global adaptive aggregation module."
}