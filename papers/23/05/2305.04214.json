{
    "title": "PiML Toolbox for Interpretable Machine Learning Model Development and Validation. (arXiv:2305.04214v1 [cs.LG])",
    "abstract": "PiML (read $\\pi$-ML, /`pai.`em.`el/) is an integrated and open-access Python toolbox for interpretable machine learning model development and model diagnostics. It is designed with machine learning workflows in both low-code and high-code modes, including data pipeline, model training, model interpretation and explanation, and model diagnostics and comparison. The toolbox supports a growing list of interpretable models (e.g. GAM, GAMI-Net, XGB2) with inherent local and/or global interpretability. It also supports model-agnostic explainability tools (e.g. PFI, PDP, LIME, SHAP) and a powerful suite of model-agnostic diagnostics (e.g. weakness, uncertainty, robustness, fairness). Integration of PiML models and tests to existing MLOps platforms for quality assurance are enabled by flexible high-code APIs. Furthermore, PiML toolbox comes with a comprehensive user guide and hands-on examples, including the applications for model development and validation in banking. The project is available",
    "link": "http://arxiv.org/abs/2305.04214",
    "context": "Title: PiML Toolbox for Interpretable Machine Learning Model Development and Validation. (arXiv:2305.04214v1 [cs.LG])\nAbstract: PiML (read $\\pi$-ML, /`pai.`em.`el/) is an integrated and open-access Python toolbox for interpretable machine learning model development and model diagnostics. It is designed with machine learning workflows in both low-code and high-code modes, including data pipeline, model training, model interpretation and explanation, and model diagnostics and comparison. The toolbox supports a growing list of interpretable models (e.g. GAM, GAMI-Net, XGB2) with inherent local and/or global interpretability. It also supports model-agnostic explainability tools (e.g. PFI, PDP, LIME, SHAP) and a powerful suite of model-agnostic diagnostics (e.g. weakness, uncertainty, robustness, fairness). Integration of PiML models and tests to existing MLOps platforms for quality assurance are enabled by flexible high-code APIs. Furthermore, PiML toolbox comes with a comprehensive user guide and hands-on examples, including the applications for model development and validation in banking. The project is available",
    "path": "papers/23/05/2305.04214.json",
    "total_tokens": 948,
    "translated_title": "PiML工具箱：可解释机器学习模型的开发和验证",
    "translated_abstract": "PiML是一个综合且开放的Python工具箱，用于可解释机器学习模型的开发和模型诊断。它设计了低代码和高代码两种机器学习工作流，包括数据管道、模型训练、模型解释和说明以及模型诊断和比较。该工具箱支持日益增长的可解释模型（例如GAM、GAMI-Net、XGB2），具有本地和/或全局可解释性。它还支持模型无关的可解释性工具（例如PFI、PDP、LIME、SHAP）和一个强大的模型无关诊断套件（例如弱点、不确定性、鲁棒性、公平性）。通过灵活的高代码 API，将 PiML 模型和测试集成到现有的 MLOps 平台以实现质量保证。此外，PiML 工具箱还带有综合的用户指南和实践例子，包括银行业中的模型开发和验证应用。该项目可通过arXiv:2305.04214v1[cs.LG]获取。",
    "tldr": "PiML工具箱是一个综合的Python工具箱，可用于开发和诊断可解释机器学习模型，包括日益增长的可解释模型、模型无关的可解释性工具和模型无关的诊断工具，还支持与MLOps平台的集成和质量保证。"
}