{
    "title": "THUIR@COLIEE 2023: Incorporating Structural Knowledge into Pre-trained Language Models for Legal Case Retrieval. (arXiv:2305.06812v1 [cs.IR])",
    "abstract": "Legal case retrieval techniques play an essential role in modern intelligent legal systems. As an annually well-known international competition, COLIEE is aiming to achieve the state-of-the-art retrieval model for legal texts. This paper summarizes the approach of the championship team THUIR in COLIEE 2023. To be specific, we design structure-aware pre-trained language models to enhance the understanding of legal cases. Furthermore, we propose heuristic pre-processing and post-processing approaches to reduce the influence of irrelevant messages. In the end, learning-to-rank methods are employed to merge features with different dimensions. Experimental results demonstrate the superiority of our proposal. Official results show that our run has the best performance among all submissions. The implementation of our method can be found at https://github.com/CSHaitao/THUIR-COLIEE2023.",
    "link": "http://arxiv.org/abs/2305.06812",
    "context": "Title: THUIR@COLIEE 2023: Incorporating Structural Knowledge into Pre-trained Language Models for Legal Case Retrieval. (arXiv:2305.06812v1 [cs.IR])\nAbstract: Legal case retrieval techniques play an essential role in modern intelligent legal systems. As an annually well-known international competition, COLIEE is aiming to achieve the state-of-the-art retrieval model for legal texts. This paper summarizes the approach of the championship team THUIR in COLIEE 2023. To be specific, we design structure-aware pre-trained language models to enhance the understanding of legal cases. Furthermore, we propose heuristic pre-processing and post-processing approaches to reduce the influence of irrelevant messages. In the end, learning-to-rank methods are employed to merge features with different dimensions. Experimental results demonstrate the superiority of our proposal. Official results show that our run has the best performance among all submissions. The implementation of our method can be found at https://github.com/CSHaitao/THUIR-COLIEE2023.",
    "path": "papers/23/05/2305.06812.json",
    "total_tokens": 894,
    "translated_title": "THUIR@COLIEE 2023: 将结构化知识融入预训练语言模型中用于法律案例检索",
    "translated_abstract": "法律案例检索技术在现代智能法律系统中起着重要作用，而作为一项年度知名国际比赛，COLIEE旨在实现针对法律文本的最先进检索模型。本文总结了冠军团队THUIR在COLIEE 2023的方法，具体而言，我们设计了结构感知的预训练语言模型以增强对法律案例的理解。此外，我们还提出了启发式预处理和后处理方法以减少无关信息的影响。最后，我们采用学习排序方法将具有不同维度的特征合并。实验结果表明我们的方案具有卓越的优势，官方结果显示我们的运行效果在所有提交中表现最佳。我们的方法实现可在https://github.com/CSHaitao/THUIR-COLIEE2023找到。",
    "tldr": "本文总结了THUIR在COLIEE 2023比赛中的冠军方案，其将结构化知识融入预训练语言模型，提出启发式预处理和后处理方法，采用学习排序方法进行特征合并，实验结果显示其具有卓越的优势。",
    "en_tdlr": "This paper summarizes the championship approach of THUIR in COLIEE 2023, which incorporates structural knowledge into pre-trained language models, proposes heuristic pre-processing and post-processing approaches, and employs learning-to-rank methods for feature merging, with experimental results demonstrating its superiority."
}