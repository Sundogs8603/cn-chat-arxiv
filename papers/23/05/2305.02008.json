{
    "title": "Zenseact Open Dataset: A large-scale and diverse multimodal dataset for autonomous driving. (arXiv:2305.02008v1 [cs.CV])",
    "abstract": "Existing datasets for autonomous driving (AD) often lack diversity and long-range capabilities, focusing instead on 360{\\deg} perception and temporal reasoning. To address this gap, we introduce Zenseact Open Dataset (ZOD), a large-scale and diverse multimodal dataset collected over two years in various European countries, covering an area 9x that of existing datasets. ZOD boasts the highest range and resolution sensors among comparable datasets, coupled with detailed keyframe annotations for 2D and 3D objects (up to 245m), road instance/semantic segmentation, traffic sign recognition, and road classification. We believe that this unique combination will facilitate breakthroughs in long-range perception and multi-task learning. The dataset is composed of Frames, Sequences, and Drives, designed to encompass both data diversity and support for spatio-temporal learning, sensor fusion, localization, and mapping. Frames consist of 100k curated camera images with two seconds of other support",
    "link": "http://arxiv.org/abs/2305.02008",
    "context": "Title: Zenseact Open Dataset: A large-scale and diverse multimodal dataset for autonomous driving. (arXiv:2305.02008v1 [cs.CV])\nAbstract: Existing datasets for autonomous driving (AD) often lack diversity and long-range capabilities, focusing instead on 360{\\deg} perception and temporal reasoning. To address this gap, we introduce Zenseact Open Dataset (ZOD), a large-scale and diverse multimodal dataset collected over two years in various European countries, covering an area 9x that of existing datasets. ZOD boasts the highest range and resolution sensors among comparable datasets, coupled with detailed keyframe annotations for 2D and 3D objects (up to 245m), road instance/semantic segmentation, traffic sign recognition, and road classification. We believe that this unique combination will facilitate breakthroughs in long-range perception and multi-task learning. The dataset is composed of Frames, Sequences, and Drives, designed to encompass both data diversity and support for spatio-temporal learning, sensor fusion, localization, and mapping. Frames consist of 100k curated camera images with two seconds of other support",
    "path": "papers/23/05/2305.02008.json",
    "total_tokens": 920,
    "translated_title": "Zenseact开放数据集：一个大规模且多样化的自动驾驶多模态数据集",
    "translated_abstract": "现有的自动驾驶（AD）数据集通常缺乏多样性和长程能力，而更关注于 360度感知和时间推理。为填补这一缺口，我们介绍了Zenseact开放数据集（ZOD），这是一个在欧洲各国收集两年的大规模且多样化的多模态数据集，覆盖面积是现有数据集的9倍。与可比较数据集相比，ZOD拥有最高范围和分辨率传感器，同时配备了2D和3D对象（长达245m）、道路实例/语义分割、交通标志识别和道路分类的详细关键帧注释。我们相信这种独特组合将有助于突破长程感知和多任务学习难题。该数据集由Frames、 Sequences和 Drives三部分组成，旨在包含数据多样性，支持时空学习、传感器融合、定位和映射。Frames由10万个筛选后的相机图像和两秒钟的其他支持数据组成。",
    "tldr": "Zenseact Open Dataset是一个大规模、多样化且覆盖范围广的自动驾驶数据集，具有最高范围和分辨率的传感器以及详细的关键帧注释，专注于长程感知和多任务学习。",
    "en_tdlr": "Zenseact Open Dataset is a large-scale and diverse autonomous driving dataset with sensors that boast the highest range and resolution, detailed keyframe annotations, and a focus on long-range perception and multi-task learning."
}