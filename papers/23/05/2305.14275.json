{
    "title": "Amortized Variational Inference with Coverage Guarantees. (arXiv:2305.14275v2 [stat.ME] UPDATED)",
    "abstract": "Amortized variational inference produces a posterior approximation that can be rapidly computed given any new observation. Unfortunately, there are few guarantees about the quality of these approximate posteriors. We propose Conformalized Amortized Neural Variational Inference (CANVI), a procedure that is scalable, easily implemented, and provides guaranteed marginal coverage. Given a collection of candidate amortized posterior approximators, CANVI constructs conformalized predictors based on each candidate, compares the predictors using a metric known as predictive efficiency, and returns the most efficient predictor. CANVI ensures that the resulting predictor constructs regions that contain the truth with a user-specified level of probability. CANVI is agnostic to design decisions in formulating the candidate approximators and only requires access to samples from the forward model, permitting its use in likelihood-free settings. We prove lower bounds on the predictive efficiency of t",
    "link": "http://arxiv.org/abs/2305.14275",
    "context": "Title: Amortized Variational Inference with Coverage Guarantees. (arXiv:2305.14275v2 [stat.ME] UPDATED)\nAbstract: Amortized variational inference produces a posterior approximation that can be rapidly computed given any new observation. Unfortunately, there are few guarantees about the quality of these approximate posteriors. We propose Conformalized Amortized Neural Variational Inference (CANVI), a procedure that is scalable, easily implemented, and provides guaranteed marginal coverage. Given a collection of candidate amortized posterior approximators, CANVI constructs conformalized predictors based on each candidate, compares the predictors using a metric known as predictive efficiency, and returns the most efficient predictor. CANVI ensures that the resulting predictor constructs regions that contain the truth with a user-specified level of probability. CANVI is agnostic to design decisions in formulating the candidate approximators and only requires access to samples from the forward model, permitting its use in likelihood-free settings. We prove lower bounds on the predictive efficiency of t",
    "path": "papers/23/05/2305.14275.json",
    "total_tokens": 899,
    "translated_title": "具有覆盖保证的分摊变分推断",
    "translated_abstract": "分摊变分推断产生了一个后验近似，可以快速计算给定任何新观测。然而，对于这些近似后验的质量，很少有保证。我们提出了一种称为CANVI的一致化分摊神经变分推断的方法，该方法可扩展、易于实现，并提供了保证的边际覆盖。给定一系列候选的分摊后验近似器，CANVI基于每个候选构建一致化预测器，使用预测效率这个度量标准比较预测器，并返回最高效的预测器。CANVI确保所得到的预测器构建的区域以用户指定的概率水平包含真实值。CANVI对候选近似器的制定决策不关心，并且只需要访问前向模型的样本，可以在无似然的情况下使用。我们证明了预测效率的下界。",
    "tldr": "提出了一种称为CANVI的方法，通过构建一致化预测器并使用预测效率进行比较，来提供具有保证的后验近似结果。该方法可以快速计算，易于实现，并且对于候选近似器的设计决策无需关注。此外，CANVI能够在无似然的情况下使用。"
}