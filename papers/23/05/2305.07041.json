{
    "title": "Fairness in Machine Learning meets with Equity in Healthcare. (arXiv:2305.07041v1 [cs.LG])",
    "abstract": "With the growing utilization of machine learning in healthcare, there is increasing potential to enhance healthcare outcomes and efficiency. However, this also brings the risk of perpetuating biases in data and model design that can harm certain protected groups based on factors such as age, gender, and race. This study proposes an artificial intelligence framework, grounded in software engineering principles, for identifying and mitigating biases in data and models while ensuring fairness in healthcare settings. A case study is presented to demonstrate how systematic biases in data can lead to amplified biases in model predictions, and machine learning methods are suggested to prevent such biases. Future research aims to test and validate the proposed ML framework in real-world clinical settings to evaluate its impact on promoting health equity.",
    "link": "http://arxiv.org/abs/2305.07041",
    "context": "Title: Fairness in Machine Learning meets with Equity in Healthcare. (arXiv:2305.07041v1 [cs.LG])\nAbstract: With the growing utilization of machine learning in healthcare, there is increasing potential to enhance healthcare outcomes and efficiency. However, this also brings the risk of perpetuating biases in data and model design that can harm certain protected groups based on factors such as age, gender, and race. This study proposes an artificial intelligence framework, grounded in software engineering principles, for identifying and mitigating biases in data and models while ensuring fairness in healthcare settings. A case study is presented to demonstrate how systematic biases in data can lead to amplified biases in model predictions, and machine learning methods are suggested to prevent such biases. Future research aims to test and validate the proposed ML framework in real-world clinical settings to evaluate its impact on promoting health equity.",
    "path": "papers/23/05/2305.07041.json",
    "total_tokens": 894,
    "translated_title": "机器学习中的公正性与医疗保健中的平等相遇",
    "translated_abstract": "随着机器学习在医疗保健中的日益应用，提高医疗保健效果和效率的潜力不断增加。然而，这也带来了潜在的风险，即在数据和模型设计中延续偏见，从而伤害某些受保护群体，如年龄、性别和种族。本研究提出了一个基于软件工程原理的人工智能框架，用于在确保医疗保健公正的同时，识别和减轻数据和模型中的偏见。通过案例研究展示了数据中系统性偏见如何导致模型预测中的放大偏见，并提出机器学习方法以预防此类偏见。未来的研究旨在在真实临床环境中测试和验证所提出的ML框架，以评估其在促进健康公平方面的影响。",
    "tldr": "本文提出了一个基于软件工程原理的人工智能框架，用于在确保医疗保健公正的同时，识别和减轻数据和模型中的偏见。未来的研究旨在在真实临床环境中测试和验证框架，以评估其在促进健康公平方面的影响。",
    "en_tdlr": "This study proposes an artificial intelligence framework, grounded in software engineering principles, for identifying and mitigating biases in data and models while ensuring fairness in healthcare settings. Future research aims to test and validate the proposed ML framework in real-world clinical settings to evaluate its impact on promoting health equity."
}