{
    "title": "ANetQA: A Large-scale Benchmark for Fine-grained Compositional Reasoning over Untrimmed Videos. (arXiv:2305.02519v1 [cs.CV])",
    "abstract": "Building benchmarks to systemically analyze different capabilities of video question answering (VideoQA) models is challenging yet crucial. Existing benchmarks often use non-compositional simple questions and suffer from language biases, making it difficult to diagnose model weaknesses incisively. A recent benchmark AGQA poses a promising paradigm to generate QA pairs automatically from pre-annotated scene graphs, enabling it to measure diverse reasoning abilities with granular control. However, its questions have limitations in reasoning about the fine-grained semantics in videos as such information is absent in its scene graphs. To this end, we present ANetQA, a large-scale benchmark that supports fine-grained compositional reasoning over the challenging untrimmed videos from ActivityNet. Similar to AGQA, the QA pairs in ANetQA are automatically generated from annotated video scene graphs. The fine-grained properties of ANetQA are reflected in the following: (i) untrimmed videos with",
    "link": "http://arxiv.org/abs/2305.02519",
    "context": "Title: ANetQA: A Large-scale Benchmark for Fine-grained Compositional Reasoning over Untrimmed Videos. (arXiv:2305.02519v1 [cs.CV])\nAbstract: Building benchmarks to systemically analyze different capabilities of video question answering (VideoQA) models is challenging yet crucial. Existing benchmarks often use non-compositional simple questions and suffer from language biases, making it difficult to diagnose model weaknesses incisively. A recent benchmark AGQA poses a promising paradigm to generate QA pairs automatically from pre-annotated scene graphs, enabling it to measure diverse reasoning abilities with granular control. However, its questions have limitations in reasoning about the fine-grained semantics in videos as such information is absent in its scene graphs. To this end, we present ANetQA, a large-scale benchmark that supports fine-grained compositional reasoning over the challenging untrimmed videos from ActivityNet. Similar to AGQA, the QA pairs in ANetQA are automatically generated from annotated video scene graphs. The fine-grained properties of ANetQA are reflected in the following: (i) untrimmed videos with",
    "path": "papers/23/05/2305.02519.json",
    "total_tokens": 1006,
    "translated_title": "ANetQA：一个用于未剪辑视频精细组合推理的大规模基准测试",
    "translated_abstract": "建立基准测试来系统地分析视频问答（VideoQA）模型的不同能力具有挑战性但至关重要。现有的基准测试通常使用非组成形简单问题并遭受语言偏见，使得深入诊断模型弱点变得困难。最近的基准测试AGQA提出了一种有前途的范例，它可以从预注释场景图中自动生成QA对，使其能够以颗粒化的控制度量多样化的推理能力。然而，它的问题在于无法理解视频中细粒度的语义，因为这样的信息在其场景图中没有呈现。因此，我们提出了ANetQA，这是一个大规模基准测试，支持从ActivityNet的具有挑战性的未剪辑视频中进行精细的组合推理。与AGQA类似，ANetQA中的QA对是从已注释的视频场景图中自动生成的。ANetQA 的细粒度特性体现在以下几个方面：（i）未剪辑的视频，包含复杂动作以及多个动作序列；（ii）覆盖多样化的信息类型，包括对象、场景、属性等；（iii）丰富的问题类型，需要精细的组成式推理。",
    "tldr": "ANetQA是一个新的大规模基准测试，支持对未剪辑视频进行精细的组合推理。与现有的基准测试不同，ANetQA的问题类型需要精细的组成式推理，并覆盖多样化的信息类型，可以更加全面地评估VideoQA模型的性能。",
    "en_tdlr": "ANetQA is a new large-scale benchmark for fine-grained compositional reasoning over untrimmed videos. Different from existing benchmarks, ANetQA requires fine-grained compositional reasoning for various types of questions that cover diverse forms of information, thus enabling a more comprehensive evaluation of VideoQA models."
}