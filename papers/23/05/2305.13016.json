{
    "title": "Iterative Forward Tuning Boosts In-context Learning in Language Models. (arXiv:2305.13016v2 [cs.CL] UPDATED)",
    "abstract": "Large language models (LLMs) have exhibited an emergent in-context learning (ICL) ability. However, the ICL models that can solve ordinary cases are hardly extended to solve more complex tasks by processing the demonstration examples once. This single-turn ICL is incoordinate with the decision making process of humans by learning from analogy. In this paper, we propose an effective and efficient two-stage framework to boost ICL in LLMs by exploiting a dual form between Transformer attention and gradient descent-based optimization. Concretely, we divide the ICL process into \"Deep-Thinking\" and inference stages. The \"Deep-Thinking\" stage performs iterative forward optimization of demonstrations, which is expected to boost the reasoning abilities of LLMs at test time by \"thinking\" demonstrations multiple times. It produces accumulated meta-gradients by manipulating the Key-Value matrices in the self-attention modules of the Transformer. Then, the inference stage only takes the test query ",
    "link": "http://arxiv.org/abs/2305.13016",
    "context": "Title: Iterative Forward Tuning Boosts In-context Learning in Language Models. (arXiv:2305.13016v2 [cs.CL] UPDATED)\nAbstract: Large language models (LLMs) have exhibited an emergent in-context learning (ICL) ability. However, the ICL models that can solve ordinary cases are hardly extended to solve more complex tasks by processing the demonstration examples once. This single-turn ICL is incoordinate with the decision making process of humans by learning from analogy. In this paper, we propose an effective and efficient two-stage framework to boost ICL in LLMs by exploiting a dual form between Transformer attention and gradient descent-based optimization. Concretely, we divide the ICL process into \"Deep-Thinking\" and inference stages. The \"Deep-Thinking\" stage performs iterative forward optimization of demonstrations, which is expected to boost the reasoning abilities of LLMs at test time by \"thinking\" demonstrations multiple times. It produces accumulated meta-gradients by manipulating the Key-Value matrices in the self-attention modules of the Transformer. Then, the inference stage only takes the test query ",
    "path": "papers/23/05/2305.13016.json",
    "total_tokens": 976,
    "translated_title": "《迭代前向调整提升语言模型中上下文学习》",
    "translated_abstract": "大型语言模型具有紧密联系的上下文学习能力，但能够解决普通问题的上下文学习模型无法通过一次处理示范样例来解决更复杂的任务。本文提出了一种有效和高效的两阶段框架，通过开发Transformer注意力和基于梯度下降的优化之间的双重形式来提高LLMs中ICL的性能。具体而言，我们将ICL过程分为“深思熟虑”和推理阶段。在“深思熟虑”阶段中，通过多次迭代优化示范，并操纵Transformer中的自我注意模块中的Key-Value矩阵来生成元梯度，从而期望在测试时提高LLM的推理能力。推理阶段仅处理测试查询，而不需要再次考虑示范。",
    "tldr": "本文提出了一种两阶段框架来提高LLMs中ICL的性能，它将ICL过程分为“深思熟虑”和推理阶段。在“深思熟虑”阶段中，通过多次迭代优化示范，并操纵Transformer中的自我注意模块中的Key-Value矩阵来生成元梯度，从而期望在测试时提高LLM的推理能力。",
    "en_tdlr": "This paper proposes a two-stage framework to improve the in-context learning (ICL) performance in LLMs, dividing the ICL process into \"Deep-Thinking\" and inference stages. The \"Deep-Thinking\" stage performs iterative forward optimization of demonstrations, generating meta-gradients by manipulating the Key-Value matrices in the self-attention modules of the Transformer. The framework is expected to improve the reasoning abilities of LLMs at test time by boosting ICL."
}