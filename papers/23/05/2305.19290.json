{
    "title": "Global Layers: Non-IID Tabular Federated Learning. (arXiv:2305.19290v1 [cs.LG])",
    "abstract": "Data heterogeneity between clients remains a key challenge in Federated Learning (FL), particularly in the case of tabular data. This work presents Global Layers (GL), a novel partial model personalization method robust in the presence of joint distribution $P(X,Y)$ shift and mixed input/output spaces $X \\times Y$ across clients. To the best of our knowledge, GL is the first method capable of supporting both client-exclusive features and classes. We introduce two new benchmark experiments for tabular FL naturally partitioned from existing real world datasets: i) UCI Covertype split into 4 clients by \"wilderness area\" feature, and ii) UCI Heart Disease, SAHeart, UCI Heart Failure, each as clients. Empirical results in these experiments in the full-participant setting show that GL achieves better outcomes than Federated Averaging (FedAvg) and local-only training, with some clients even performing better than their centralized baseline.",
    "link": "http://arxiv.org/abs/2305.19290",
    "context": "Title: Global Layers: Non-IID Tabular Federated Learning. (arXiv:2305.19290v1 [cs.LG])\nAbstract: Data heterogeneity between clients remains a key challenge in Federated Learning (FL), particularly in the case of tabular data. This work presents Global Layers (GL), a novel partial model personalization method robust in the presence of joint distribution $P(X,Y)$ shift and mixed input/output spaces $X \\times Y$ across clients. To the best of our knowledge, GL is the first method capable of supporting both client-exclusive features and classes. We introduce two new benchmark experiments for tabular FL naturally partitioned from existing real world datasets: i) UCI Covertype split into 4 clients by \"wilderness area\" feature, and ii) UCI Heart Disease, SAHeart, UCI Heart Failure, each as clients. Empirical results in these experiments in the full-participant setting show that GL achieves better outcomes than Federated Averaging (FedAvg) and local-only training, with some clients even performing better than their centralized baseline.",
    "path": "papers/23/05/2305.19290.json",
    "total_tokens": 987,
    "translated_title": "全局层：非独立同分布的表格联邦学习",
    "translated_abstract": "客户端之间的数据异质性仍然是联邦学习（FL）中一个重要的挑战，尤其是在表格数据的情况下。本研究提出Global Layers（GL），这是一种新颖的偏模型个性化方法，能够在客户端之间具有联合分布 $P(X,Y)$ 转变和混合输入/输出空间 $X \\times Y$ 的情况下实现鲁棒性。据我们所知，GL是第一种能够支持客户端专有特征和类别的方法。我们从现有的真实数据集中自然地对表格FL进行了两个新的基准实验：i）将UCI Covertype分为4个具有“野外区域”特征的客户端，以及ii）将UCI Heart Disease、SAHeart、UCI Heart Failure分别作为客户端。在全员参与设置的实验中，实验结果显示GL的性能优于联邦平均（FedAvg）和仅本地训练的性能，甚至有些客户端的性能比他们的集中式基线还要好。",
    "tldr": "本文提出了一个新颖的偏模型个性化方法Global Layers (GL)，该方法是目前唯一一种能够支持客户端专有特征和类别的FL方法，在两个新的基准实验中，GL的性能优于联邦平均和仅本地训练的性能，甚至有些客户端的性能比他们的集中式基线还要好。",
    "en_tdlr": "The paper proposes a novel partial model personalization method called Global Layers (GL) for federated learning (FL) of tabular data, capable of supporting both client-exclusive features and classes. Empirical results show that GL outperforms Federated Averaging (FedAvg) and local-only training, with some clients even performing better than their centralized baseline. Two new benchmark experiments are also introduced for tabular FL."
}