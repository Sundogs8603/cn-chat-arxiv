{
    "title": "Code Execution with Pre-trained Language Models. (arXiv:2305.05383v1 [cs.PL])",
    "abstract": "Code execution is a fundamental aspect of programming language semantics that reflects the exact behavior of the code. However, most pre-trained models for code intelligence ignore the execution trace and only rely on source code and syntactic structures. In this paper, we investigate how well pre-trained models can understand and perform code execution. We develop a mutation-based data augmentation technique to create a large-scale and realistic Python dataset and task for code execution, which challenges existing models such as Codex. We then present CodeExecutor, a Transformer model that leverages code execution pre-training and curriculum learning to enhance its semantic comprehension. We evaluate CodeExecutor on code execution and show its promising performance and limitations. We also demonstrate its potential benefits for code intelligence tasks such as zero-shot code-to-code search and text-to-code generation. Our analysis provides insights into the learning and generalization ",
    "link": "http://arxiv.org/abs/2305.05383",
    "context": "Title: Code Execution with Pre-trained Language Models. (arXiv:2305.05383v1 [cs.PL])\nAbstract: Code execution is a fundamental aspect of programming language semantics that reflects the exact behavior of the code. However, most pre-trained models for code intelligence ignore the execution trace and only rely on source code and syntactic structures. In this paper, we investigate how well pre-trained models can understand and perform code execution. We develop a mutation-based data augmentation technique to create a large-scale and realistic Python dataset and task for code execution, which challenges existing models such as Codex. We then present CodeExecutor, a Transformer model that leverages code execution pre-training and curriculum learning to enhance its semantic comprehension. We evaluate CodeExecutor on code execution and show its promising performance and limitations. We also demonstrate its potential benefits for code intelligence tasks such as zero-shot code-to-code search and text-to-code generation. Our analysis provides insights into the learning and generalization ",
    "path": "papers/23/05/2305.05383.json",
    "total_tokens": 954,
    "translated_title": "预训练语言模型的代码执行能力研究",
    "translated_abstract": "代码执行是编程语言语义学中的基本方面，它反映了代码的确切行为。然而，大多数面向代码智能的预训练模型忽略了执行轨迹，只依靠源代码和句法结构。本文研究了预训练模型能否理解和执行代码。我们开发了一种基于变异的数据增强技术，创建了一个大规模和逼真的Python数据集和任务，挑战了现有的模型如Codex。然后，我们提出了CodeExecutor，一个利用代码执行预训练和课程学习来增强其语义理解的Transformer模型。我们对代码执行进行评估，并展示了其有望的表现和局限性。我们还展示了它在代码智能任务中的潜在好处，如零-shot代码到代码搜索和文本到代码生成。我们的分析提供了有关预训练语言模型学习和泛化的洞见，并为代码智能的研究开辟了新方向。",
    "tldr": "本文研究了预训练语言模型对代码执行的能力，并通过开发一种变异数据增强技术创建了一个大规模的Python数据集和任务，提出了CodeExecutor模型以增强语义理解，该模型在代码执行、零-shot代码到代码搜索和文本到代码生成等方面有潜在好处。",
    "en_tdlr": "This paper investigates the ability of pre-trained language models to perform code execution and proposes CodeExecutor, a transformer model that leverages code execution pre-training and curriculum learning to enhance its semantic comprehension. The authors developed a mutation-based data augmentation technique to create a large-scale and realistic Python dataset and task for code execution. The evaluation shows promising performance and potential benefits for code intelligence tasks such as zero-shot code-to-code search and text-to-code generation."
}