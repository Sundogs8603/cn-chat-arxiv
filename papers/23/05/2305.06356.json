{
    "title": "HumanRF: High-Fidelity Neural Radiance Fields for Humans in Motion. (arXiv:2305.06356v1 [cs.CV])",
    "abstract": "Representing human performance at high-fidelity is an essential building block in diverse applications, such as film production, computer games or videoconferencing. To close the gap to production-level quality, we introduce HumanRF, a 4D dynamic neural scene representation that captures full-body appearance in motion from multi-view video input, and enables playback from novel, unseen viewpoints. Our novel representation acts as a dynamic video encoding that captures fine details at high compression rates by factorizing space-time into a temporal matrix-vector decomposition. This allows us to obtain temporally coherent reconstructions of human actors for long sequences, while representing high-resolution details even in the context of challenging motion. While most research focuses on synthesizing at resolutions of 4MP or lower, we address the challenge of operating at 12MP. To this end, we introduce ActorsHQ, a novel multi-view dataset that provides 12MP footage from 160 cameras for ",
    "link": "http://arxiv.org/abs/2305.06356",
    "context": "Title: HumanRF: High-Fidelity Neural Radiance Fields for Humans in Motion. (arXiv:2305.06356v1 [cs.CV])\nAbstract: Representing human performance at high-fidelity is an essential building block in diverse applications, such as film production, computer games or videoconferencing. To close the gap to production-level quality, we introduce HumanRF, a 4D dynamic neural scene representation that captures full-body appearance in motion from multi-view video input, and enables playback from novel, unseen viewpoints. Our novel representation acts as a dynamic video encoding that captures fine details at high compression rates by factorizing space-time into a temporal matrix-vector decomposition. This allows us to obtain temporally coherent reconstructions of human actors for long sequences, while representing high-resolution details even in the context of challenging motion. While most research focuses on synthesizing at resolutions of 4MP or lower, we address the challenge of operating at 12MP. To this end, we introduce ActorsHQ, a novel multi-view dataset that provides 12MP footage from 160 cameras for ",
    "path": "papers/23/05/2305.06356.json",
    "total_tokens": 916,
    "translated_title": "HumanRF：用于运动中人的高保真神经辐射场",
    "translated_abstract": "在各种应用程序中，如电影制作、电脑游戏或视频会议中，高保真地表现人类表现是一个重要的构建块。为了接近生产级的质量，我们介绍了HumanRF，这是一个4D动态神经场景表示，从多视角视频输入中捕捉运动中的全身外貌，并使其可以在新的、看不见的视角下播放。我们的新型表示作为一个动态视频编码，通过将时空分解为一个时间矩阵向量分解，以高压缩率捕捉精细细节。这使我们可以为长序列获得时间上连贯的人物重建，并在具有挑战性的动作情况下表示高分辨率的细节。虽然大多数研究集中在合成4MP或更低分辨率，但我们解决了在12MP上操作的挑战。为此，我们介绍了ActorsHQ，这是一个新的多视角数据集，为160个摄像机提供了12MP的镜头。",
    "tldr": "具有4D动态场景表示的HumanRF能够从多视角视频输入中捕捉全身外貌，以高压缩率捕捉精细细节并支持高分辨率。ActorsHQ提供了12MP的镜头，为长序列获得时间上连贯的人物重建。"
}