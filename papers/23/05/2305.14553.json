{
    "title": "Adversarial Machine Learning and Cybersecurity: Risks, Challenges, and Legal Implications. (arXiv:2305.14553v1 [cs.CR])",
    "abstract": "In July 2022, the Center for Security and Emerging Technology (CSET) at Georgetown University and the Program on Geopolitics, Technology, and Governance at the Stanford Cyber Policy Center convened a workshop of experts to examine the relationship between vulnerabilities in artificial intelligence systems and more traditional types of software vulnerabilities. Topics discussed included the extent to which AI vulnerabilities can be handled under standard cybersecurity processes, the barriers currently preventing the accurate sharing of information about AI vulnerabilities, legal issues associated with adversarial attacks on AI systems, and potential areas where government support could improve AI vulnerability management and mitigation.  This report is meant to accomplish two things. First, it provides a high-level discussion of AI vulnerabilities, including the ways in which they are disanalogous to other types of vulnerabilities, and the current state of affairs regarding information ",
    "link": "http://arxiv.org/abs/2305.14553",
    "context": "Title: Adversarial Machine Learning and Cybersecurity: Risks, Challenges, and Legal Implications. (arXiv:2305.14553v1 [cs.CR])\nAbstract: In July 2022, the Center for Security and Emerging Technology (CSET) at Georgetown University and the Program on Geopolitics, Technology, and Governance at the Stanford Cyber Policy Center convened a workshop of experts to examine the relationship between vulnerabilities in artificial intelligence systems and more traditional types of software vulnerabilities. Topics discussed included the extent to which AI vulnerabilities can be handled under standard cybersecurity processes, the barriers currently preventing the accurate sharing of information about AI vulnerabilities, legal issues associated with adversarial attacks on AI systems, and potential areas where government support could improve AI vulnerability management and mitigation.  This report is meant to accomplish two things. First, it provides a high-level discussion of AI vulnerabilities, including the ways in which they are disanalogous to other types of vulnerabilities, and the current state of affairs regarding information ",
    "path": "papers/23/05/2305.14553.json",
    "total_tokens": 843,
    "translated_title": "对抗机器学习与网络安全：风险、挑战和法律影响",
    "translated_abstract": "2022年7月，乔治城大学安全与新兴技术中心（CSET）和斯坦福网络政策中心的地缘政治、技术和治理项目召集了一批专家，研究人工智能系统漏洞与传统软件漏洞之间的关系。讨论的主题包括AI漏洞在标准网络安全流程中的处理程度，目前阻止关于AI漏洞准确共享的障碍，对AI系统进行对抗攻击的法律问题，以及政府支持可能改善AI漏洞管理和缓解的潜在领域。本报告旨在完成两件事。首先，提供了对AI漏洞的高层次讨论，包括它们如何不同于其他类型的漏洞以及关于信息共享的现状。",
    "tldr": "本文讨论了人工智能系统漏洞与传统软件漏洞之间的关系，并提出了可能改善AI漏洞管理和缓解的潜在领域，以及对AI系统进行对抗攻击的法律问题。",
    "en_tdlr": "This paper discusses the relationship between vulnerabilities in artificial intelligence systems and more traditional types of software vulnerabilities, and proposes potential areas where government support could improve AI vulnerability management and mitigation, as well as legal issues associated with adversarial attacks on AI systems."
}