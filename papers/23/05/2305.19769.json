{
    "title": "Attention-Based Methods For Audio Question Answering. (arXiv:2305.19769v1 [cs.CL])",
    "abstract": "Audio question answering (AQA) is the task of producing natural language answers when a system is provided with audio and natural language questions. In this paper, we propose neural network architectures based on self-attention and cross-attention for the AQA task. The self-attention layers extract powerful audio and textual representations. The cross-attention maps audio features that are relevant to the textual features to produce answers. All our models are trained on the recently proposed Clotho-AQA dataset for both binary yes/no questions and single-word answer questions. Our results clearly show improvement over the reference method reported in the original paper. On the yes/no binary classification task, our proposed model achieves an accuracy of 68.3% compared to 62.7% in the reference model. For the single-word answers multiclass classifier, our model produces a top-1 and top-5 accuracy of 57.9% and 99.8% compared to 54.2% and 93.7% in the reference model respectively. We fur",
    "link": "http://arxiv.org/abs/2305.19769",
    "context": "Title: Attention-Based Methods For Audio Question Answering. (arXiv:2305.19769v1 [cs.CL])\nAbstract: Audio question answering (AQA) is the task of producing natural language answers when a system is provided with audio and natural language questions. In this paper, we propose neural network architectures based on self-attention and cross-attention for the AQA task. The self-attention layers extract powerful audio and textual representations. The cross-attention maps audio features that are relevant to the textual features to produce answers. All our models are trained on the recently proposed Clotho-AQA dataset for both binary yes/no questions and single-word answer questions. Our results clearly show improvement over the reference method reported in the original paper. On the yes/no binary classification task, our proposed model achieves an accuracy of 68.3% compared to 62.7% in the reference model. For the single-word answers multiclass classifier, our model produces a top-1 and top-5 accuracy of 57.9% and 99.8% compared to 54.2% and 93.7% in the reference model respectively. We fur",
    "path": "papers/23/05/2305.19769.json",
    "total_tokens": 903,
    "translated_title": "基于注意力机制的音频问答方法",
    "translated_abstract": "音频问答(AQA)是对于音频和自然语言提出问题时，生成自然语言回答的任务。本文提出了基于自注意力和交叉注意力的神经网络体系结构，用于音频问答任务。自我注意力层可以提取强大的音频和文本表示。交叉注意力将与文本特征相关的音频特征映射到答案中。我们的所有模型都在最近提出的Clotho-AQA数据集上进行了训练，用于二进制是/否问题和单词回答问题。结果清楚地显示出相对于原始论文中的参考方法改进。在是/否二进制分类任务中，我们的提出的模型相对于参考模型的准确率从62.7％提高到了68.3％。对于单词答案多类分类器，我们的模型分别产生了57.9％和99.8％的top-1和top-5准确率，相对于参考模型的54.2％和93.7％有了明显提高。",
    "tldr": "本文提出了一种基于自我注意力和交叉注意力的神经网络体系结构，用于音频问答任务。实验结果表明，相较于参考方法，该方法在Clotho-AQA数据集上的表现有明显提高。",
    "en_tdlr": "This paper proposes neural network architectures based on self-attention and cross-attention for audio question answering (AQA) task, and achieves improved performance on the Clotho-AQA dataset compared to the reference method."
}