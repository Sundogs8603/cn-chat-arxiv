{
    "title": "Attack Named Entity Recognition by Entity Boundary Interference. (arXiv:2305.05253v1 [cs.CL])",
    "abstract": "Named Entity Recognition (NER) is a cornerstone NLP task while its robustness has been given little attention. This paper rethinks the principles of NER attacks derived from sentence classification, as they can easily violate the label consistency between the original and adversarial NER examples. This is due to the fine-grained nature of NER, as even minor word changes in the sentence can result in the emergence or mutation of any entities, resulting in invalid adversarial examples. To this end, we propose a novel one-word modification NER attack based on a key insight, NER models are always vulnerable to the boundary position of an entity to make their decision. We thus strategically insert a new boundary into the sentence and trigger the Entity Boundary Interference that the victim model makes the wrong prediction either on this boundary word or on other words in the sentence. We call this attack Virtual Boundary Attack (ViBA), which is shown to be remarkably effective when attackin",
    "link": "http://arxiv.org/abs/2305.05253",
    "context": "Title: Attack Named Entity Recognition by Entity Boundary Interference. (arXiv:2305.05253v1 [cs.CL])\nAbstract: Named Entity Recognition (NER) is a cornerstone NLP task while its robustness has been given little attention. This paper rethinks the principles of NER attacks derived from sentence classification, as they can easily violate the label consistency between the original and adversarial NER examples. This is due to the fine-grained nature of NER, as even minor word changes in the sentence can result in the emergence or mutation of any entities, resulting in invalid adversarial examples. To this end, we propose a novel one-word modification NER attack based on a key insight, NER models are always vulnerable to the boundary position of an entity to make their decision. We thus strategically insert a new boundary into the sentence and trigger the Entity Boundary Interference that the victim model makes the wrong prediction either on this boundary word or on other words in the sentence. We call this attack Virtual Boundary Attack (ViBA), which is shown to be remarkably effective when attackin",
    "path": "papers/23/05/2305.05253.json",
    "total_tokens": 931,
    "translated_title": "实体边界干扰: 一种攻击命名实体识别的方法",
    "translated_abstract": "命名实体识别(NER)是NLP任务的基石，但其稳健性鲜受关注。本文重新思考了从句子分类派生的NER攻击原则，因为它们可以轻易违反原始和对抗性NER示例之间的标签一致性。这是由于NER的精细化性质，即句子中即使是微小的单词变化也会导致任何实体的出现或变异，从而导致无效的对抗性示例。为此，我们提出了一种基于NER实体边界位置的关键洞察的新型单词修改NER攻击。我们故意插入新的边界到句子中，触发实体边界干扰，在这个边界词或句子中的其他单词上，使受害模型做出错误预测。我们称这种攻击为虚拟边界攻击(ViBA)，在四个基准数据集上攻击最先进的NER模型时显示出了非常有效的结果。",
    "tldr": "本文提出了一种基于实体边界干扰的新型单词修改NER攻击——虚拟边界攻击(ViBA)，该攻击在四个基准数据集上攻击最先进的NER模型时显示出了非常有效的结果。",
    "en_tdlr": "This paper proposes a novel one-word modification NER attack called Virtual Boundary Attack (ViBA) based on the key insight that NER models are always vulnerable to the boundary position of an entity, which is remarkably effective in attacking state-of-the-art NER models on four benchmark datasets."
}