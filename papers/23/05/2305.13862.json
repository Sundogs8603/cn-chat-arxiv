{
    "title": "A Trip Towards Fairness: Bias and De-Biasing in Large Language Models. (arXiv:2305.13862v1 [cs.CL])",
    "abstract": "An outbreak in the popularity of transformer-based Language Models (such as GPT (Brown et al., 2020) and PaLM (Chowdhery et al., 2022)) has opened the doors to new Machine Learning applications. In particular, in Natural Language Processing and how pre-training from large text, corpora is essential in achieving remarkable results in downstream tasks. However, these Language Models seem to have inherent biases toward certain demographics reflected in their training data. While research has attempted to mitigate this problem, existing methods either fail to remove bias altogether, degrade performance, or are expensive. This paper examines the bias produced by promising Language Models when varying parameters and pre-training data. Finally, we propose a de-biasing technique that produces robust de-bias models that maintain performance on downstream tasks.",
    "link": "http://arxiv.org/abs/2305.13862",
    "context": "Title: A Trip Towards Fairness: Bias and De-Biasing in Large Language Models. (arXiv:2305.13862v1 [cs.CL])\nAbstract: An outbreak in the popularity of transformer-based Language Models (such as GPT (Brown et al., 2020) and PaLM (Chowdhery et al., 2022)) has opened the doors to new Machine Learning applications. In particular, in Natural Language Processing and how pre-training from large text, corpora is essential in achieving remarkable results in downstream tasks. However, these Language Models seem to have inherent biases toward certain demographics reflected in their training data. While research has attempted to mitigate this problem, existing methods either fail to remove bias altogether, degrade performance, or are expensive. This paper examines the bias produced by promising Language Models when varying parameters and pre-training data. Finally, we propose a de-biasing technique that produces robust de-bias models that maintain performance on downstream tasks.",
    "path": "papers/23/05/2305.13862.json",
    "total_tokens": 808,
    "translated_title": "公平之路：大型语言模型中的偏差及去偏差",
    "translated_abstract": "基于转换器的语言模型（如GPT（Brown等，2020）和PaLM（Chowdhery等，2022））的普及引发了新的机器学习应用。特别是，在自然语言处理中，从大型文本语料库中进行预训练对于在下游任务中取得显着结果至关重要。然而，这些语言模型似乎具有对某些人口统计数据偏见的固有偏差。尽管研究试图缓解这个问题，但现有的方法要么未能完全消除偏见，要么降低了性能，要么代价过高。本文研究了当不同参数和预训练数据时，这些有前途的语言模型产生的偏见。最后，我们提出了一种去偏差技术，可以产生在下游任务中保持性能的健壮的去偏差模型。",
    "tldr": "本文研究大型语言模型中的偏见问题，并提出了一种去偏差技术以产生在下游任务中表现良好的健壮去偏差模型。",
    "en_tdlr": "This paper examines biases in large language models and proposes a debiasing technique to produce robust models that perform well on downstream tasks."
}