{
    "title": "Short Answer Grading Using One-shot Prompting and Text Similarity Scoring Model. (arXiv:2305.18638v1 [cs.CL])",
    "abstract": "In this study, we developed an automated short answer grading (ASAG) model that provided both analytic scores and final holistic scores. Short answer items typically consist of multiple sub-questions, and providing an analytic score and the text span relevant to each sub-question can increase the interpretability of the automated scores. Furthermore, they can be used to generate actionable feedback for students. Despite these advantages, most studies have focused on predicting only holistic scores due to the difficulty in constructing dataset with manual annotations. To address this difficulty, we used large language model (LLM)-based one-shot prompting and a text similarity scoring model with domain adaptation using small manually annotated dataset. The accuracy and quadratic weighted kappa of our model were 0.67 and 0.71 on a subset of the publicly available ASAG dataset. The model achieved a substantial improvement over the majority baseline.",
    "link": "http://arxiv.org/abs/2305.18638",
    "context": "Title: Short Answer Grading Using One-shot Prompting and Text Similarity Scoring Model. (arXiv:2305.18638v1 [cs.CL])\nAbstract: In this study, we developed an automated short answer grading (ASAG) model that provided both analytic scores and final holistic scores. Short answer items typically consist of multiple sub-questions, and providing an analytic score and the text span relevant to each sub-question can increase the interpretability of the automated scores. Furthermore, they can be used to generate actionable feedback for students. Despite these advantages, most studies have focused on predicting only holistic scores due to the difficulty in constructing dataset with manual annotations. To address this difficulty, we used large language model (LLM)-based one-shot prompting and a text similarity scoring model with domain adaptation using small manually annotated dataset. The accuracy and quadratic weighted kappa of our model were 0.67 and 0.71 on a subset of the publicly available ASAG dataset. The model achieved a substantial improvement over the majority baseline.",
    "path": "papers/23/05/2305.18638.json",
    "total_tokens": 909,
    "translated_title": "采用一次提示和文本相似度评分模型进行短回答评分",
    "translated_abstract": "在这项研究中，我们开发了一种自动化的短回答评分（ASAG）模型，提供了分析得分和最终整体得分。为了增加自动化得分的可解释性，短回答项通常包含多个子问题，并且提供每个子问题相关的文本范围和分析得分可以增加其解释性。此外，它们可以用来为学生提供可执行的反馈。尽管具有这些优势，但由于难以构建手动注释数据集，大多数研究只关注预测整体得分。为解决这个问题，我们使用基于大型语言模型的一次提示和文本相似度评分模型，使用小规模手动注释的数据集进行领域适应。我们模型的准确度和二次加权kappa系数分别为0.67和0.71，这在公开可用的ASAG数据集的子集上取得了显着的改进。",
    "tldr": "本文提出了一种自动化的短回答评分（ASAG）模型，使用基于大型语言模型的一次提示和文本相似度评分模型，可以提供分析得分和最终整体得分，并使用小规模手动注释的数据集进行领域适应，取得了显著的改进。",
    "en_tdlr": "This study proposes an automated short answer grading (ASAG) model, which provides both analytic scores and final holistic scores using large language model (LLM)-based one-shot prompting and a text similarity scoring model with domain adaptation using small manually annotated dataset, achieving substantial improvement over the majority baseline."
}