{
    "title": "GDA: Generative Data Augmentation Techniques for Relation Extraction Tasks. (arXiv:2305.16663v1 [cs.CL])",
    "abstract": "Relation extraction (RE) tasks show promising performance in extracting relations from two entities mentioned in sentences, given sufficient annotations available during training. Such annotations would be labor-intensive to obtain in practice. Existing work adopts data augmentation techniques to generate pseudo-annotated sentences beyond limited annotations. These techniques neither preserve the semantic consistency of the original sentences when rule-based augmentations are adopted, nor preserve the syntax structure of sentences when expressing relations using seq2seq models, resulting in less diverse augmentations. In this work, we propose a dedicated augmentation technique for relational texts, named GDA, which uses two complementary modules to preserve both semantic consistency and syntax structures. We adopt a generative formulation and design a multi-tasking solution to achieve synergies. Furthermore, GDA adopts entity hints as the prior knowledge of the generative model to augm",
    "link": "http://arxiv.org/abs/2305.16663",
    "context": "Title: GDA: Generative Data Augmentation Techniques for Relation Extraction Tasks. (arXiv:2305.16663v1 [cs.CL])\nAbstract: Relation extraction (RE) tasks show promising performance in extracting relations from two entities mentioned in sentences, given sufficient annotations available during training. Such annotations would be labor-intensive to obtain in practice. Existing work adopts data augmentation techniques to generate pseudo-annotated sentences beyond limited annotations. These techniques neither preserve the semantic consistency of the original sentences when rule-based augmentations are adopted, nor preserve the syntax structure of sentences when expressing relations using seq2seq models, resulting in less diverse augmentations. In this work, we propose a dedicated augmentation technique for relational texts, named GDA, which uses two complementary modules to preserve both semantic consistency and syntax structures. We adopt a generative formulation and design a multi-tasking solution to achieve synergies. Furthermore, GDA adopts entity hints as the prior knowledge of the generative model to augm",
    "path": "papers/23/05/2305.16663.json",
    "total_tokens": 981,
    "translated_title": "GDA: 用于关系抽取任务的生成式数据增强技术",
    "translated_abstract": "在给定足够的训练标注时，关系抽取任务可以在句子中提取出两个实体之间的关系，表现出良好的性能。然而在实践中获得这种标注是费力的。现有的方法采用数据增强技术，在限制的标注范围之外生成伪标注句子。当采用基于规则的增强时，这些技术无法保持原始句子的语义一致性，并且在使用seq2seq模型表达关系时无法保持句子的语法结构， resulting in less diverse augmentations 。本文提出一个专门针对关系文本的增强技术，称为GDA，它使用两个互补模块来保持语义一致性和语法结构。我们采用生成式公式，并设计一个多任务解决方案以实现协同效应。此外，GDA采用实体提示作为生成模型的先验知识，将实体的上下文扩展到句子中。实验结果表明，GDA在两个公共数据集NYT10和SemEval2010 Task 8上实现了最先进的性能，并超越了现有的数据增强技术。",
    "tldr": "GDA是一个专门用于关系文本增强的技术，通过采用两个互补模块，保持语义和语法结构的一致性，并使用实体提示扩展上下文。实验结果表明GDA超越了现有增强技术，实现了最先进的性能。",
    "en_tdlr": "GDA is a dedicated data augmentation technique for relation text which preserves both semantic consistency and syntax structure using two complementary modules and extending context with entity hints. It outperforms existing techniques and achieves state-of-the-art performance on two public datasets."
}