{
    "title": "Sensitivity and Robustness of Large Language Models to Prompt Template in Japanese Text Classification Tasks. (arXiv:2305.08714v2 [cs.CL] UPDATED)",
    "abstract": "Prompt engineering relevance research has seen a notable surge in recent years, primarily driven by advancements in pre-trained language models and large language models. However, a critical issue has been identified within this domain: the inadequate of sensitivity and robustness of these models towards Prompt Templates, particularly in lesser-studied languages such as Japanese. This paper explores this issue through a comprehensive evaluation of several representative Large Language Models (LLMs) and a widely-utilized pre-trained model(PLM). These models are scrutinized using a benchmark dataset in Japanese, with the aim to assess and analyze the performance of the current multilingual models in this context. Our experimental results reveal startling discrepancies. A simple modification in the sentence structure of the Prompt Template led to a drastic drop in the accuracy of GPT-4 from 49.21 to 25.44. This observation underscores the fact that even the highly performance GPT-4 model ",
    "link": "http://arxiv.org/abs/2305.08714",
    "context": "Title: Sensitivity and Robustness of Large Language Models to Prompt Template in Japanese Text Classification Tasks. (arXiv:2305.08714v2 [cs.CL] UPDATED)\nAbstract: Prompt engineering relevance research has seen a notable surge in recent years, primarily driven by advancements in pre-trained language models and large language models. However, a critical issue has been identified within this domain: the inadequate of sensitivity and robustness of these models towards Prompt Templates, particularly in lesser-studied languages such as Japanese. This paper explores this issue through a comprehensive evaluation of several representative Large Language Models (LLMs) and a widely-utilized pre-trained model(PLM). These models are scrutinized using a benchmark dataset in Japanese, with the aim to assess and analyze the performance of the current multilingual models in this context. Our experimental results reveal startling discrepancies. A simple modification in the sentence structure of the Prompt Template led to a drastic drop in the accuracy of GPT-4 from 49.21 to 25.44. This observation underscores the fact that even the highly performance GPT-4 model ",
    "path": "papers/23/05/2305.08714.json",
    "total_tokens": 946,
    "translated_title": "大型语言模型在日语文本分类中对提示模板的敏感性和鲁棒性研究",
    "translated_abstract": "近年来，预训练语言模型和大型语言模型的先进发展主导了提示工程相关研究的显著增长。然而，这一领域存在一个关键问题：这些模型对于提示模板的敏感性和鲁棒性不足，特别是在日语这样的较少研究的语言中。本文通过全面评估几个代表性的大型语言模型（LLMs）和一个广泛使用的预训练模型（PLM）来探讨这个问题。我们使用一组基准数据集对这些模型进行了审查，旨在评估和分析当前多语言模型在这种情况下的性能表现。我们的实验结果揭示了惊人的差异。一个简单的提示模板句子结构的修改导致GPT-4的准确率从49.21下降到了25.44。这一观察结果强调了即使是高性能的GPT-4模型也存在这一问题。",
    "tldr": "本研究评估了多个大型语言模型在日语文本分类中对提示模板的敏感性和鲁棒性，并揭示出即使是高性能的GPT-4模型在这一方面也存在问题。",
    "en_tdlr": "This paper evaluates the sensitivity and robustness of multiple large language models towards prompt templates in Japanese text classification tasks, highlighting the inadequacy of even high-performance models such as GPT-4 in this regard."
}