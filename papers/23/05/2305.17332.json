{
    "title": "Learning Capacity: A Measure of the Effective Dimensionality of a Model. (arXiv:2305.17332v1 [cs.LG])",
    "abstract": "We exploit a formal correspondence between thermodynamics and inference, where the number of samples can be thought of as the inverse temperature, to define a \"learning capacity'' which is a measure of the effective dimensionality of a model. We show that the learning capacity is a tiny fraction of the number of parameters for many deep networks trained on typical datasets, depends upon the number of samples used for training, and is numerically consistent with notions of capacity obtained from the PAC-Bayesian framework. The test error as a function of the learning capacity does not exhibit double descent. We show that the learning capacity of a model saturates at very small and very large sample sizes; this provides guidelines, as to whether one should procure more data or whether one should search for new architectures, to improve performance. We show how the learning capacity can be used to understand the effective dimensionality, even for non-parametric models such as random fores",
    "link": "http://arxiv.org/abs/2305.17332",
    "context": "Title: Learning Capacity: A Measure of the Effective Dimensionality of a Model. (arXiv:2305.17332v1 [cs.LG])\nAbstract: We exploit a formal correspondence between thermodynamics and inference, where the number of samples can be thought of as the inverse temperature, to define a \"learning capacity'' which is a measure of the effective dimensionality of a model. We show that the learning capacity is a tiny fraction of the number of parameters for many deep networks trained on typical datasets, depends upon the number of samples used for training, and is numerically consistent with notions of capacity obtained from the PAC-Bayesian framework. The test error as a function of the learning capacity does not exhibit double descent. We show that the learning capacity of a model saturates at very small and very large sample sizes; this provides guidelines, as to whether one should procure more data or whether one should search for new architectures, to improve performance. We show how the learning capacity can be used to understand the effective dimensionality, even for non-parametric models such as random fores",
    "path": "papers/23/05/2305.17332.json",
    "total_tokens": 826,
    "translated_title": "学习能力：模型有效维度的度量方式",
    "translated_abstract": "我们利用热力学和推理之间的正式对应关系，将样本数量视为反温度，定义了一种“学习能力”，这是模型有效维度的度量方式。我们发现，对于许多在典型数据集上训练的深度网络，学习能力仅占参数数量的一小部分，取决于用于训练的样本数量，并且在数值上与从PAC-Bayesian框架获得的能力概念一致。学习能力作为测试误差的函数不会出现双峰下降。我们展示了模型的学习能力在非常小和非常大的样本大小处饱和，这提供了指导，说明是否应该获取更多数据或者寻找新的体系结构以提高性能。我们展示了如何使用学习能力来理解有效维数，即使是非参数模型，如随机森林。",
    "tldr": "学习能力是一种度量模型有效维度的方法，它可以帮助我们判断是否需要获取更多数据或者寻找新的体系结构以提高性能。",
    "en_tdlr": "Learning capacity is a method to measure the effective dimensionality of a model, which can guide us to decide whether to acquire more data or search for new architectures for performance improvement."
}