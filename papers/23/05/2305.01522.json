{
    "title": "Safe Deployment for Counterfactual Learning to Rank with Exposure-Based Risk Minimization. (arXiv:2305.01522v1 [cs.IR])",
    "abstract": "Counterfactual learning to rank (CLTR) relies on exposure-based inverse propensity scoring (IPS), a LTR-specific adaptation of IPS to correct for position bias. While IPS can provide unbiased and consistent estimates, it often suffers from high variance. Especially when little click data is available, this variance can cause CLTR to learn sub-optimal ranking behavior. Consequently, existing CLTR methods bring significant risks with them, as naively deploying their models can result in very negative user experiences. We introduce a novel risk-aware CLTR method with theoretical guarantees for safe deployment. We apply a novel exposure-based concept of risk regularization to IPS estimation for LTR. Our risk regularization penalizes the mismatch between the ranking behavior of a learned model and a given safe model. Thereby, it ensures that learned ranking models stay close to a trusted model, when there is high uncertainty in IPS estimation, which greatly reduces the risks during deployme",
    "link": "http://arxiv.org/abs/2305.01522",
    "context": "Title: Safe Deployment for Counterfactual Learning to Rank with Exposure-Based Risk Minimization. (arXiv:2305.01522v1 [cs.IR])\nAbstract: Counterfactual learning to rank (CLTR) relies on exposure-based inverse propensity scoring (IPS), a LTR-specific adaptation of IPS to correct for position bias. While IPS can provide unbiased and consistent estimates, it often suffers from high variance. Especially when little click data is available, this variance can cause CLTR to learn sub-optimal ranking behavior. Consequently, existing CLTR methods bring significant risks with them, as naively deploying their models can result in very negative user experiences. We introduce a novel risk-aware CLTR method with theoretical guarantees for safe deployment. We apply a novel exposure-based concept of risk regularization to IPS estimation for LTR. Our risk regularization penalizes the mismatch between the ranking behavior of a learned model and a given safe model. Thereby, it ensures that learned ranking models stay close to a trusted model, when there is high uncertainty in IPS estimation, which greatly reduces the risks during deployme",
    "path": "papers/23/05/2305.01522.json",
    "total_tokens": 956,
    "translated_title": "带有基于曝光的风险最小化的反事实学习排序安全部署",
    "translated_abstract": "反事实学习排序（CLTR）依赖于基于曝光的倒数概率评分（IPS），一种LTR特定的自适应IPS来纠正位置偏差。虽然IPS可以提供无偏和一致的估计，但通常会受到高方差的影响。尤其是当可用点击数据很少时，这种方差可能会导致CLTR学习次优的排名行为。因此，现有的CLTR方法带来了重大风险，因为简单地部署它们的模型可能会导致用户体验非常差。我们引入了一种新的风险感知CLTR方法，具有安全部署的理论保证。我们对LTR的IPS估计应用了一种新的基于曝光的风险正则化概念。我们的风险正则化惩罚学习模型的排名行为与给定安全模型的不匹配。因此，在IPS估计存在高度不确定性时，它确保学习排名模型与可信模型保持接近，从而大大降低了部署过程中的风险。",
    "tldr": "该论文提出了一种新的反事实学习排序方法，通过基于曝光的风险正则化对IPS估计进行调整，以确保学习排名模型与给定的安全模型接近，从而在部署过程中降低风险。",
    "en_tdlr": "This paper proposes a novel risk-aware counterfactual learning to rank (CLTR) method with theoretical guarantees for safe deployment, which adjusts IPS estimation by exposure-based risk regularization to ensure that the learned ranking models stay close to a trusted model, greatly reducing the risks during deployment."
}