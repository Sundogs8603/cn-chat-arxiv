{
    "title": "Identify, Estimate and Bound the Uncertainty of Reinforcement Learning for Autonomous Driving. (arXiv:2305.07487v1 [cs.AI])",
    "abstract": "Deep reinforcement learning (DRL) has emerged as a promising approach for developing more intelligent autonomous vehicles (AVs). A typical DRL application on AVs is to train a neural network-based driving policy. However, the black-box nature of neural networks can result in unpredictable decision failures, making such AVs unreliable. To this end, this work proposes a method to identify and protect unreliable decisions of a DRL driving policy. The basic idea is to estimate and constrain the policy's performance uncertainty, which quantifies potential performance drop due to insufficient training data or network fitting errors. By constraining the uncertainty, the DRL model's performance is always greater than that of a baseline policy. The uncertainty caused by insufficient data is estimated by the bootstrapped method. Then, the uncertainty caused by the network fitting error is estimated using an ensemble network. Finally, a baseline policy is added as the performance lower bound to a",
    "link": "http://arxiv.org/abs/2305.07487",
    "context": "Title: Identify, Estimate and Bound the Uncertainty of Reinforcement Learning for Autonomous Driving. (arXiv:2305.07487v1 [cs.AI])\nAbstract: Deep reinforcement learning (DRL) has emerged as a promising approach for developing more intelligent autonomous vehicles (AVs). A typical DRL application on AVs is to train a neural network-based driving policy. However, the black-box nature of neural networks can result in unpredictable decision failures, making such AVs unreliable. To this end, this work proposes a method to identify and protect unreliable decisions of a DRL driving policy. The basic idea is to estimate and constrain the policy's performance uncertainty, which quantifies potential performance drop due to insufficient training data or network fitting errors. By constraining the uncertainty, the DRL model's performance is always greater than that of a baseline policy. The uncertainty caused by insufficient data is estimated by the bootstrapped method. Then, the uncertainty caused by the network fitting error is estimated using an ensemble network. Finally, a baseline policy is added as the performance lower bound to a",
    "path": "papers/23/05/2305.07487.json",
    "total_tokens": 938,
    "translated_title": "针对自动驾驶的深度强化学习不确定性的识别、评估和边界确定 (arXiv:2305.07487v1 [cs.AI])",
    "translated_abstract": "深度强化学习(DRL)已成为开发更智能化自动驾驶汽车(AVs)的一种有前途的方法。AVs上的典型DRL应用是训练基于神经网络的驾驶策略。然而，神经网络的黑盒特性可能导致不可预测的决策失误，使这些AVs不可靠。为此，本文提出了一种方法来识别和保护DRL驾驶策略的不可靠决策。基本思想是估计和限制策略的性能不确定性，该不确定性量化由于训练数据不足或网络拟合误差导致的潜在性能下降。通过限制不确定性，DRL模型的性能始终优于基线策略。由不足的数据引起的不确定性采用自助法估计。然后，使用集成网络估计由网络拟合误差引起的不确定性。最后，将基线策略添加为性能下限。",
    "tldr": "本文提出了一种方法来限制自动驾驶中深度强化学习模型的决策不可靠性，以保护决策的可靠性，该方法通过估计和限制策略的性能不确定性来实现。",
    "en_tdlr": "This paper proposes a method to restrict the decision uncertainty of deep reinforcement learning models in autonomous driving, to protect the reliability of the driving policy. The method achieves this by estimating and constraining the performance uncertainty of the policy caused by insufficient training data or network fitting errors."
}