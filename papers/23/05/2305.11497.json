{
    "title": "TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding. (arXiv:2305.11497v1 [cs.CV])",
    "abstract": "Prompt tuning has achieved great success in transferring the knowledge from large pretrained vision-language models into downstream tasks, and has dominated the performance on visual grounding (VG). However, almost all existing prompt tuning paradigms suffer from poor interpretability. In this paper, we argue that their poor interpretability is attributed to the holistic prompt generation and inference process. By \"holistic\", we mean that they usually directly learn a set of vectors as the prompt (i.e., prompt generation), and use the learned global prompt to augment the textual input for the VG model (i.e., prompt inference). To this end, we propose a new prompt construction paradigm with explicit explainable ability, named TreePrompt. Specifically, we first deconstruct a complex sentence into a tree, that is consistent with human reasoning. Then, following the syntax tree, we compose a structured prompt in a bottom-up manner. Thanks to this step-by-step prompt construction process, e",
    "link": "http://arxiv.org/abs/2305.11497",
    "context": "Title: TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding. (arXiv:2305.11497v1 [cs.CV])\nAbstract: Prompt tuning has achieved great success in transferring the knowledge from large pretrained vision-language models into downstream tasks, and has dominated the performance on visual grounding (VG). However, almost all existing prompt tuning paradigms suffer from poor interpretability. In this paper, we argue that their poor interpretability is attributed to the holistic prompt generation and inference process. By \"holistic\", we mean that they usually directly learn a set of vectors as the prompt (i.e., prompt generation), and use the learned global prompt to augment the textual input for the VG model (i.e., prompt inference). To this end, we propose a new prompt construction paradigm with explicit explainable ability, named TreePrompt. Specifically, we first deconstruct a complex sentence into a tree, that is consistent with human reasoning. Then, following the syntax tree, we compose a structured prompt in a bottom-up manner. Thanks to this step-by-step prompt construction process, e",
    "path": "papers/23/05/2305.11497.json",
    "total_tokens": 915,
    "translated_title": "TreePrompt：学习生成树形提示以实现可解释的视觉定位",
    "translated_abstract": "提示调整已经在将从大型预训练的视觉语言模型中的知识转移到下游任务方面取得了巨大的成功，并且已经支配了视觉定位（VG）的表现。然而，几乎所有现有的提示调整范例都遭受着可解释性差的问题。在本文中，我们认为其可解释性差是由于全局提示生成和推理过程造成的。通过“全局”，我们是指它们通常直接学习一组向量作为提示（即提示生成），并使用学习到的全局提示增强VG模型的文本输入（即提示推理）。为此，我们提出了一种具有显式可解释性的新型提示构建范例，称为TreePrompt。具体而言，我们首先将复杂的句子分解成一棵与人类推理一致的树。然后，按照语法树，我们从底向上以结构化提示的方式构成一个提示。由于这一步骤一步一步的提示构建过程，e",
    "tldr": "提示调整技术已经在视觉定位领域卓有成效，但现有的方法大多数可解释性不好。本文提出了一种新的提示构建方法，名为TreePrompt，通过将句子分解成树状结构进行逐步提示构建，提高了提示的可解释性。",
    "en_tdlr": "Prompt tuning has achieved great success in visual grounding tasks, but the lack of interpretability remains a challenge. This paper proposes a new prompt construction paradigm called TreePrompt, which deconstructs complex sentences into trees to improve interpretability."
}