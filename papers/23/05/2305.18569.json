{
    "title": "Fairness of ChatGPT. (arXiv:2305.18569v1 [cs.LG])",
    "abstract": "Understanding and addressing unfairness in LLMs are crucial for responsible AI deployment. However, there is a limited availability of quantitative analyses and in-depth studies regarding fairness evaluations in LLMs, especially when applying LLMs to high-stakes fields. This work aims to fill this gap by providing a systematic evaluation of the effectiveness and fairness of LLMs using ChatGPT as a study case. We focus on assessing ChatGPT's performance in high-takes fields including education, criminology, finance and healthcare. To make thorough evaluation, we consider both group fairness and individual fairness and we also observe the disparities in ChatGPT's outputs under a set of biased or unbiased prompts. This work contributes to a deeper understanding of LLMs' fairness performance, facilitates bias mitigation and fosters the development of responsible artificial intelligence systems.",
    "link": "http://arxiv.org/abs/2305.18569",
    "context": "Title: Fairness of ChatGPT. (arXiv:2305.18569v1 [cs.LG])\nAbstract: Understanding and addressing unfairness in LLMs are crucial for responsible AI deployment. However, there is a limited availability of quantitative analyses and in-depth studies regarding fairness evaluations in LLMs, especially when applying LLMs to high-stakes fields. This work aims to fill this gap by providing a systematic evaluation of the effectiveness and fairness of LLMs using ChatGPT as a study case. We focus on assessing ChatGPT's performance in high-takes fields including education, criminology, finance and healthcare. To make thorough evaluation, we consider both group fairness and individual fairness and we also observe the disparities in ChatGPT's outputs under a set of biased or unbiased prompts. This work contributes to a deeper understanding of LLMs' fairness performance, facilitates bias mitigation and fosters the development of responsible artificial intelligence systems.",
    "path": "papers/23/05/2305.18569.json",
    "total_tokens": 911,
    "translated_title": "ChatGPT的公平性评估",
    "translated_abstract": "理解和解决LLM中不公平的问题对于负责任的AI部署至关重要。然而，在将LLM应用于高风险领域时，尤其是关于公平评估方面，数量分析和深入研究的可用性有限。本文旨在提供一个使用ChatGPT作为研究案例的LLM有效性和公平性的系统评估，我们专注于评估ChatGPT在包括教育、犯罪学、金融和医疗保健等高风险领域的表现。为了进行全面的评估，我们考虑了群体公平性和个人公平性，并观察了在一系列有偏或无偏提示下ChatGPT输出的差异。该研究对于更深入的了解LLM的公平表现，便于偏见缓解，促进负责任的人工智能系统的发展具有意义。",
    "tldr": "本文提供了一个使用ChatGPT作为研究案例的LLM有效性和公平性的系统评估，旨在评估ChatGPT在高风险领域的表现，以提供更深入的了解LLM的公平表现，并为偏见缓解和负责任的人工智能系统的发展做出贡献。",
    "en_tdlr": "This paper provides a systematic evaluation of the effectiveness and fairness of LLMs using ChatGPT as a study case, focusing on assessing ChatGPT's performance in high-stakes fields and observing the disparities in ChatGPT's outputs under a set of biased or unbiased prompts. It aims to offer a deeper understanding of LLMs' fairness performance and contribute to bias mitigation and the development of responsible artificial intelligence systems."
}