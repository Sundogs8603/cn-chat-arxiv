{
    "title": "Automatic Generation of Attention Rules For Containment of Machine Learning Model Errors. (arXiv:2305.08115v1 [cs.LG])",
    "abstract": "Machine learning (ML) solutions are prevalent in many applications. However, many challenges exist in making these solutions business-grade. For instance, maintaining the error rate of the underlying ML models at an acceptably low level. Typically, the true relationship between feature inputs and the target feature to be predicted is uncertain, and hence statistical in nature. The approach we propose is to separate the observations that are the most likely to be predicted incorrectly into 'attention sets'. These can directly aid model diagnosis and improvement, and be used to decide on alternative courses of action for these problematic observations. We present several algorithms (`strategies') for determining optimal rules to separate these observations. In particular, we prefer strategies that use feature-based slicing because they are human-interpretable, model-agnostic, and require minimal supplementary inputs or knowledge. In addition, we show that these strategies outperform seve",
    "link": "http://arxiv.org/abs/2305.08115",
    "context": "Title: Automatic Generation of Attention Rules For Containment of Machine Learning Model Errors. (arXiv:2305.08115v1 [cs.LG])\nAbstract: Machine learning (ML) solutions are prevalent in many applications. However, many challenges exist in making these solutions business-grade. For instance, maintaining the error rate of the underlying ML models at an acceptably low level. Typically, the true relationship between feature inputs and the target feature to be predicted is uncertain, and hence statistical in nature. The approach we propose is to separate the observations that are the most likely to be predicted incorrectly into 'attention sets'. These can directly aid model diagnosis and improvement, and be used to decide on alternative courses of action for these problematic observations. We present several algorithms (`strategies') for determining optimal rules to separate these observations. In particular, we prefer strategies that use feature-based slicing because they are human-interpretable, model-agnostic, and require minimal supplementary inputs or knowledge. In addition, we show that these strategies outperform seve",
    "path": "papers/23/05/2305.08115.json",
    "total_tokens": 1198,
    "translated_title": "自动产生注意规则以限制机器学习模型错误",
    "translated_abstract": "机器学习解决方案在许多应用中得到了广泛应用，但在商业级别上使用仍然存在许多挑战，其中一个主要问题是将模型的误差率维持在可接受的水平。本文提出一种方法来将最有可能出现错误预测的观察结果分离为“注意集”，这些集合可以直接帮助模型诊断和改进，并用于决定这些问题观察结果的替代方案。作者提供了几种用于确定最佳规则以分离这些观察结果的算法（“策略”）。特别地，采用基于特征切片的策略，因为它们具有人类可解释性、模型无关性，并需要最少的辅助输入或知识。此外，作者还表明这些策略的性能优于其他方法。",
    "tldr": "本文提出了一种将最可能出错的观察结果分离成“注意集”的自动化方法，以帮助机器学习模型的诊断和改进。采用基于特征切片的策略，具有人类可解释性、模型无关性和较少的辅助输入或知识，而且相较于其他方法，该方法的性能表现更佳。",
    "en_tdlr": "This paper proposes an automated method to separate the most likely incorrect predictions into \"attention sets\" to aid in diagnosis and improvement of machine learning models. The authors provide several algorithms, or \"strategies,\" to determine optimal rules for separating these observations, with a preference for feature-based slicing due to its interpretability and model-agnostic nature. The performance of these strategies is shown to outperform other methods."
}