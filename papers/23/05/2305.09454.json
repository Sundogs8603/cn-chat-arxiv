{
    "title": "Rethinking the editing of generative adversarial networks: a method to estimate editing vectors based on dimension reduction. (arXiv:2305.09454v1 [cs.CV])",
    "abstract": "While Generative Adversarial Networks (GANs) have recently found applications in image editing, most previous GAN-based image editing methods require largescale datasets with semantic segmentation annotations for training, only provide high level control, or merely interpolate between different images. Previous researchers have proposed EditGAN for high-quality, high-precision semantic image editing with limited semantic annotations by finding `editing vectors'. However, it is noticed that there are many features that are not highly associated with semantics, and EditGAN may fail on them. Based on the orthogonality of latent space observed by EditGAN, we propose a method to estimate editing vectors that do not rely on semantic segmentation nor differentiable feature estimation network. Our method assumes that there is a correlation between the intensity distribution of features and the distribution of hidden vectors, and estimates the relationship between the above distributions by sam",
    "link": "http://arxiv.org/abs/2305.09454",
    "context": "Title: Rethinking the editing of generative adversarial networks: a method to estimate editing vectors based on dimension reduction. (arXiv:2305.09454v1 [cs.CV])\nAbstract: While Generative Adversarial Networks (GANs) have recently found applications in image editing, most previous GAN-based image editing methods require largescale datasets with semantic segmentation annotations for training, only provide high level control, or merely interpolate between different images. Previous researchers have proposed EditGAN for high-quality, high-precision semantic image editing with limited semantic annotations by finding `editing vectors'. However, it is noticed that there are many features that are not highly associated with semantics, and EditGAN may fail on them. Based on the orthogonality of latent space observed by EditGAN, we propose a method to estimate editing vectors that do not rely on semantic segmentation nor differentiable feature estimation network. Our method assumes that there is a correlation between the intensity distribution of features and the distribution of hidden vectors, and estimates the relationship between the above distributions by sam",
    "path": "papers/23/05/2305.09454.json",
    "total_tokens": 855,
    "translated_title": "重新思考生成对抗网络的编辑: 一种基于降维的编辑向量估计方法",
    "translated_abstract": "近年来，生成对抗网络（GANs）在图像编辑方面被广泛应用。然而，先前的GAN-based图像编辑方法大多需要大规模数据集的语义分割注释来进行训练，只能提供高级别控制或仅在不同图像之间进行插值。之前的研究者通过查找“编辑向量”提出了EditGAN，以获得高质量、高精度的语义图像编辑，而无需进行大量的语义注释。然而，存在许多与语义关联不高的特征，导致EditGAN可能在这些特征上失败。本文基于EditGAN所观察到的潜空间正交性，提出了一种估计编辑向量的方法，该法不依赖于语义分割或可微分的特征估计网络。本方法假设特征的强度分布与隐藏向量的分布之间存在相关性，并通过采样来估计上述分布之间的关系。",
    "tldr": "该论文提出了一种基于降维的编辑向量估计方法，用于高质量、高精度的语义图像编辑，不需要语义分割或可微分的特征估计网络。",
    "en_tdlr": "This paper proposes a method to estimate editing vectors based on dimension reduction, which enables high-quality, high-precision semantic image editing without semantic segmentation or differentiable feature estimation network."
}