{
    "title": "Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews. (arXiv:2305.11828v1 [cs.CL])",
    "abstract": "Medical systematic reviews are crucial for informing clinical decision making and healthcare policy. But producing such reviews is onerous and time-consuming. Thus, high-quality evidence synopses are not available for many questions and may be outdated even when they are available. Large language models (LLMs) are now capable of generating long-form texts, suggesting the tantalizing possibility of automatically generating literature reviews on demand. However, LLMs sometimes generate inaccurate (and potentially misleading) texts by hallucinating or omitting important information. In the healthcare context, this may render LLMs unusable at best and dangerous at worst. Most discussion surrounding the benefits and risks of LLMs have been divorced from specific applications. In this work, we seek to qualitatively characterize the potential utility and risks of LLMs for assisting in production of medical evidence reviews. We conducted 16 semi-structured interviews with international experts",
    "link": "http://arxiv.org/abs/2305.11828",
    "context": "Title: Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews. (arXiv:2305.11828v1 [cs.CL])\nAbstract: Medical systematic reviews are crucial for informing clinical decision making and healthcare policy. But producing such reviews is onerous and time-consuming. Thus, high-quality evidence synopses are not available for many questions and may be outdated even when they are available. Large language models (LLMs) are now capable of generating long-form texts, suggesting the tantalizing possibility of automatically generating literature reviews on demand. However, LLMs sometimes generate inaccurate (and potentially misleading) texts by hallucinating or omitting important information. In the healthcare context, this may render LLMs unusable at best and dangerous at worst. Most discussion surrounding the benefits and risks of LLMs have been divorced from specific applications. In this work, we seek to qualitatively characterize the potential utility and risks of LLMs for assisting in production of medical evidence reviews. We conducted 16 semi-structured interviews with international experts",
    "path": "papers/23/05/2305.11828.json",
    "total_tokens": 970,
    "translated_title": "LLM在医学系统综述中的潜在用途和风险评估",
    "translated_abstract": "医学系统综述对于制定临床决策和医疗政策至关重要。但是制作这样的综述很费力且耗时。因此，很多问题缺乏高质量的证据综述，即使这些综述可用，在审查过程中可能已经过时。现在，大型语言模型（LLM）已经能够生成长篇文本，这意味着自动生成文献综述的诱人可能性。然而，由于虚构或遗漏重要信息，LLM有时会产生不准确（甚至可能具有误导性）的文本。在医疗保健环境中，这可能使LLM在最好情况下无法使用，在最坏情况下会带来危险。对于LLM的益处和风险的大多数讨论与具体应用脱离了关系。在这项工作中，我们试图定性描述LLM在协助制作医学证据综述方面的潜在用途和风险。我们对16位国际专家进行了半结构化访谈。",
    "tldr": "本文研究了使用LLM协助制作医学证据综述的潜在用途和风险，指出LLM有可能自动生成文献综述，但由于可能出现虚构或遗漏信息的情况，LLM的使用需要谨慎。",
    "en_tdlr": "This paper investigates the potential uses and risks of using LLMs to assist in producing medical evidence reviews. While LLMs show promising ability to automatically generate literature reviews, the possibility of inaccuracies, including hallucinations or omissions of important information, poses potential harm for healthcare context. The authors suggest cautious consideration should be taken when utilizing LLMs in medical systematic reviews."
}