{
    "title": "Dynamically Conservative Self-Driving Planner for Long-Tail Cases. (arXiv:2305.07497v1 [cs.RO])",
    "abstract": "Self-driving vehicles (SDVs) are becoming reality but still suffer from \"long-tail\" challenges during natural driving: the SDVs will continually encounter rare, safety-critical cases that may not be included in the dataset they were trained. Some safety-assurance planners solve this problem by being conservative in all possible cases, which may significantly affect driving mobility. To this end, this work proposes a method to automatically adjust the conservative level according to each case's \"long-tail\" rate, named dynamically conservative planner (DCP). We first define the \"long-tail\" rate as an SDV's confidence to pass a driving case. The rate indicates the probability of safe-critical events and is estimated using the statistics bootstrapped method with historical data. Then, a reinforcement learning-based planner is designed to contain candidate policies with different conservative levels. The final policy is optimized based on the estimated \"long-tail\" rate. In this way, the DCP",
    "link": "http://arxiv.org/abs/2305.07497",
    "context": "Title: Dynamically Conservative Self-Driving Planner for Long-Tail Cases. (arXiv:2305.07497v1 [cs.RO])\nAbstract: Self-driving vehicles (SDVs) are becoming reality but still suffer from \"long-tail\" challenges during natural driving: the SDVs will continually encounter rare, safety-critical cases that may not be included in the dataset they were trained. Some safety-assurance planners solve this problem by being conservative in all possible cases, which may significantly affect driving mobility. To this end, this work proposes a method to automatically adjust the conservative level according to each case's \"long-tail\" rate, named dynamically conservative planner (DCP). We first define the \"long-tail\" rate as an SDV's confidence to pass a driving case. The rate indicates the probability of safe-critical events and is estimated using the statistics bootstrapped method with historical data. Then, a reinforcement learning-based planner is designed to contain candidate policies with different conservative levels. The final policy is optimized based on the estimated \"long-tail\" rate. In this way, the DCP",
    "path": "papers/23/05/2305.07497.json",
    "total_tokens": 934,
    "translated_title": "自适应保守型自动驾驶规划器的设计与实现",
    "translated_abstract": "自动驾驶汽车（SDVs）在实际驾驶中经常面临“长尾”挑战，即SDVs将不断遇到在其训练数据集中可能不存在的罕见安全关键情况。一些安全保证规划器通过在所有可能的情况下保守处理，来解决这个问题，但这可能会极大地影响驾驶能力。为此，本文提出了一种名为动态保守规划器（DCP）的方法，根据每种情况的“长尾”率自动调整保守程度。首先，我们将“长尾”率定义为SDV通过驾驶案例的信心水平。这个率表示安全关键事件的概率，并使用历史数据的统计自助法进行估计。然后，通过强化学习，设计了一个包含不同保守程度候选策略的规划器。最终策略基于估计的“长尾”率进行了优化。通过这种方式，DCP能够更好地应对长尾案例，提高安全性和驾驶性能。",
    "tldr": "本论文提出了一种动态保守规划器方法，能够根据每种情况的“长尾”率自动调整保守程度，以更好地应对SDVs在实际驾驶中遇到的罕见关键情况。",
    "en_tdlr": "This paper proposes a dynamically conservative planner method, which can automatically adjust the conservative level according to each case's \"long-tail\" rate to better address the rare critical cases that self-driving vehicles may encounter during natural driving."
}