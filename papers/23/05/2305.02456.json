{
    "title": "Streaming PCA for Markovian Data. (arXiv:2305.02456v1 [math.ST])",
    "abstract": "Since its inception in Erikki Oja's seminal paper in 1982, Oja's algorithm has become an established method for streaming principle component analysis (PCA). We study the problem of streaming PCA, where the data-points are sampled from an irreducible, aperiodic, and reversible Markov chain. Our goal is to estimate the top eigenvector of the unknown covariance matrix of the stationary distribution. This setting has implications in situations where data can only be sampled from a Markov Chain Monte Carlo (MCMC) type algorithm, and the goal is to do inference for parameters of the stationary distribution of this chain. Most convergence guarantees for Oja's algorithm in the literature assume that the data-points are sampled IID. For data streams with Markovian dependence, one typically downsamples the data to get a \"nearly\" independent data stream. In this paper, we obtain the first sharp rate for Oja's algorithm on the entire data, where we remove the logarithmic dependence on $n$ resulti",
    "link": "http://arxiv.org/abs/2305.02456",
    "context": "Title: Streaming PCA for Markovian Data. (arXiv:2305.02456v1 [math.ST])\nAbstract: Since its inception in Erikki Oja's seminal paper in 1982, Oja's algorithm has become an established method for streaming principle component analysis (PCA). We study the problem of streaming PCA, where the data-points are sampled from an irreducible, aperiodic, and reversible Markov chain. Our goal is to estimate the top eigenvector of the unknown covariance matrix of the stationary distribution. This setting has implications in situations where data can only be sampled from a Markov Chain Monte Carlo (MCMC) type algorithm, and the goal is to do inference for parameters of the stationary distribution of this chain. Most convergence guarantees for Oja's algorithm in the literature assume that the data-points are sampled IID. For data streams with Markovian dependence, one typically downsamples the data to get a \"nearly\" independent data stream. In this paper, we obtain the first sharp rate for Oja's algorithm on the entire data, where we remove the logarithmic dependence on $n$ resulti",
    "path": "papers/23/05/2305.02456.json",
    "total_tokens": 1045,
    "translated_title": "面向马尔可夫数据的流式PCA算法",
    "translated_abstract": "自从Oja在1982年的经典论文中首次提出以来，Oja算法已成为流式主成分分析(PCA)的一种常用方法。本文研究了流式PCA问题，其中数据点从一个不可约、无周期、可逆的马尔可夫链中采样。我们的目标是估计平稳分布的未知协方差矩阵的前一个特征向量。这种情况适用于只能从马尔可夫链蒙特卡罗(MCMC)类型的算法中采样数据，并且目标是对该链的平稳分布的参数进行推断的情况。现有文献中大多数Oja算法的收敛保证都假定数据点是IID采样的。对于具有马尔可夫依赖关系的数据流，人们通常对数据进行下采样以获得\"几乎\"独立的数据流。在本文中，我们获得了Oja算法在整个数据集上的第一个尖锐率，其中去掉了$n$的对数依赖性，结果是$\\mathcal{O}(n^{-1})$的速率。我们还提出了一种自适应方案来调整算法的步长，它在模拟和真实数据示例中都表现更好。",
    "tldr": "本文提出了一种面向马尔可夫数据采样的流式PCA算法，并获得了该算法在整个数据集上的第一个尖锐率，提高了算法的效率。同时，本文提出的自适应方案在模拟和真实数据示例中表现良好。",
    "en_tdlr": "This paper proposes a streaming PCA algorithm for data sampled from a Markov chain and obtains the first sharp rate for Oja's algorithm on the whole dataset, improving the efficiency of the algorithm. At the same time, the adaptive scheme proposed in this paper performs well in both simulated and real-data examples."
}