{
    "title": "Leveraging BERT Language Model for Arabic Long Document Classification. (arXiv:2305.03519v1 [cs.CL])",
    "abstract": "Given the number of Arabic speakers worldwide and the notably large amount of content in the web today in some fields such as law, medicine, or even news, documents of considerable length are produced regularly. Classifying those documents using traditional learning models is often impractical since extended length of the documents increases computational requirements to an unsustainable level. Thus, it is necessary to customize these models specifically for long textual documents. In this paper we propose two simple but effective models to classify long length Arabic documents. We also fine-tune two different models-namely, Longformer and RoBERT, for the same task and compare their results to our models. Both of our models outperform the Longformer and RoBERT in this task over two different datasets.",
    "link": "http://arxiv.org/abs/2305.03519",
    "context": "Title: Leveraging BERT Language Model for Arabic Long Document Classification. (arXiv:2305.03519v1 [cs.CL])\nAbstract: Given the number of Arabic speakers worldwide and the notably large amount of content in the web today in some fields such as law, medicine, or even news, documents of considerable length are produced regularly. Classifying those documents using traditional learning models is often impractical since extended length of the documents increases computational requirements to an unsustainable level. Thus, it is necessary to customize these models specifically for long textual documents. In this paper we propose two simple but effective models to classify long length Arabic documents. We also fine-tune two different models-namely, Longformer and RoBERT, for the same task and compare their results to our models. Both of our models outperform the Longformer and RoBERT in this task over two different datasets.",
    "path": "papers/23/05/2305.03519.json",
    "total_tokens": 793,
    "translated_title": "利用BERT语言模型对阿拉伯语长文档进行分类",
    "translated_abstract": "考虑到全球阿拉伯语使用者的数量以及在某些领域（如法律、医学甚至新闻）中网上的内容数量显著增长，长文档会被定期产生。使用传统学习模型对这些文档进行分类通常是不切实际的，因为文档的长度增加会使计算要求持续上升。因此，有必要专门为长文本文档定制这些模型。在本文中，我们提出了两个简单但有效的模型来分类阿拉伯语的长文档。我们还微调了两个不同的模型，即Longformer和RoBERT，完成了同样的任务，并将它们的结果与我们的模型进行了比较。我们的两个模型在两个不同的数据集中都优于Longformer和RoBERT。",
    "tldr": "本文研究了定制化的阿拉伯语长文档分类模型，提出了两个简单却有效的模型，并与Longformer和RoBERT进行了比较。结果表明，我们的模型在两个数据集上都优于Longformer和RoBERT。",
    "en_tdlr": "This paper proposes customized models for classifying Arabic long documents, including two simple and effective models and comparison with Longformer and RoBERT models. Results show that the proposed models outperform Longformer and RoBERT on two different datasets."
}