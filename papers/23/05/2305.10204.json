{
    "title": "Shielded Representations: Protecting Sensitive Attributes Through Iterative Gradient-Based Projection. (arXiv:2305.10204v1 [cs.CL])",
    "abstract": "Natural language processing models tend to learn and encode social biases present in the data. One popular approach for addressing such biases is to eliminate encoded information from the model's representations. However, current methods are restricted to removing only linearly encoded information. In this work, we propose Iterative Gradient-Based Projection (IGBP), a novel method for removing non-linear encoded concepts from neural representations. Our method consists of iteratively training neural classifiers to predict a particular attribute we seek to eliminate, followed by a projection of the representation on a hypersurface, such that the classifiers become oblivious to the target attribute. We evaluate the effectiveness of our method on the task of removing gender and race information as sensitive attributes. Our results demonstrate that IGBP is effective in mitigating bias through intrinsic and extrinsic evaluations, with minimal impact on downstream task accuracy.",
    "link": "http://arxiv.org/abs/2305.10204",
    "context": "Title: Shielded Representations: Protecting Sensitive Attributes Through Iterative Gradient-Based Projection. (arXiv:2305.10204v1 [cs.CL])\nAbstract: Natural language processing models tend to learn and encode social biases present in the data. One popular approach for addressing such biases is to eliminate encoded information from the model's representations. However, current methods are restricted to removing only linearly encoded information. In this work, we propose Iterative Gradient-Based Projection (IGBP), a novel method for removing non-linear encoded concepts from neural representations. Our method consists of iteratively training neural classifiers to predict a particular attribute we seek to eliminate, followed by a projection of the representation on a hypersurface, such that the classifiers become oblivious to the target attribute. We evaluate the effectiveness of our method on the task of removing gender and race information as sensitive attributes. Our results demonstrate that IGBP is effective in mitigating bias through intrinsic and extrinsic evaluations, with minimal impact on downstream task accuracy.",
    "path": "papers/23/05/2305.10204.json",
    "total_tokens": 956,
    "translated_title": "护盾式表示：通过迭代基于梯度的投影保护敏感属性",
    "translated_abstract": "自然语言处理模型倾向于学习和编码数据中存在的社会偏见。解决此类偏差的一种流行方法是消除模型表示中编码的信息。然而，当前的方法仅限于删除线性编码的信息。在这项工作中，我们提出了一种名为迭代梯度基础投影（IGBP）的新方法，用于从神经表示中删除非线性编码的概念。我们的方法包括通过迭代训练神经分类器来预测我们要消除的特定属性，然后将表示投影到一个超平面上，使得分类器对目标属性变得无意识。我们评估了我们的方法在消除性别和种族信息作为敏感属性的任务上的有效性。我们的结果表明，IGBP通过内在和外在评估在减轻偏见方面是有效的，并且对下游任务的准确性影响很小。",
    "tldr": "本文提出了一种名为迭代梯度基础投影（IGBP）的新方法，用于从神经表示中删除非线性编码的概念，以减轻模型的社会偏见。该方法通过迭代训练神经分类器来预测某个敏感属性，然后将表示投影到一个超平面上，使得分类器对目标属性变得无意识。实验证明，该方法在消除敏感属性方面是有效的，并且对下游任务的准确性影响很小。",
    "en_tdlr": "This paper proposes a method named Iterative Gradient-Based Projection (IGBP) to mitigate social biases in natural language processing models by removing non-linear encoded concepts from neural representations. The method involves iteratively training neural classifiers to predict a sensitive attribute, followed by projecting the representation on a hypersurface. The results demonstrate its effectiveness in removing sensitive attributes with minimal impact on downstream task accuracy."
}