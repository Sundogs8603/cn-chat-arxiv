{
    "title": "Toward $L_\\infty$-recovery of Nonlinear Functions: A Polynomial Sample Complexity Bound for Gaussian Random Fields. (arXiv:2305.00322v1 [cs.LG])",
    "abstract": "Many machine learning applications require learning a function with a small worst-case error over the entire input domain, that is, the $L_\\infty$-error, whereas most existing theoretical works only guarantee recovery in average errors such as the $L_2$-error. $L_\\infty$-recovery from polynomial samples is even impossible for seemingly simple function classes such as constant-norm infinite-width two-layer neural nets. This paper makes some initial steps beyond the impossibility results by leveraging the randomness in the ground-truth functions. We prove a polynomial sample complexity bound for random ground-truth functions drawn from Gaussian random fields. Our key technical novelty is to prove that the degree-$k$ spherical harmonics components of a function from Gaussian random field cannot be spiky in that their $L_\\infty$/$L_2$ ratios are upperbounded by $O(d \\sqrt{\\ln k})$ with high probability. In contrast, the worst-case $L_\\infty$/$L_2$ ratio for degree-$k$ spherical harmonics i",
    "link": "http://arxiv.org/abs/2305.00322",
    "context": "Title: Toward $L_\\infty$-recovery of Nonlinear Functions: A Polynomial Sample Complexity Bound for Gaussian Random Fields. (arXiv:2305.00322v1 [cs.LG])\nAbstract: Many machine learning applications require learning a function with a small worst-case error over the entire input domain, that is, the $L_\\infty$-error, whereas most existing theoretical works only guarantee recovery in average errors such as the $L_2$-error. $L_\\infty$-recovery from polynomial samples is even impossible for seemingly simple function classes such as constant-norm infinite-width two-layer neural nets. This paper makes some initial steps beyond the impossibility results by leveraging the randomness in the ground-truth functions. We prove a polynomial sample complexity bound for random ground-truth functions drawn from Gaussian random fields. Our key technical novelty is to prove that the degree-$k$ spherical harmonics components of a function from Gaussian random field cannot be spiky in that their $L_\\infty$/$L_2$ ratios are upperbounded by $O(d \\sqrt{\\ln k})$ with high probability. In contrast, the worst-case $L_\\infty$/$L_2$ ratio for degree-$k$ spherical harmonics i",
    "path": "papers/23/05/2305.00322.json",
    "total_tokens": 1125,
    "translated_title": "非线性函数的$L_\\infty$恢复：高斯随机场的多项式样本复杂度界限",
    "translated_abstract": "许多机器学习应用需要学习一个在整个输入域上具有小最坏情况误差的函数，即$L_\\infty$误差，而大多数现有的理论工作只保证平均误差的恢复，例如$L_2$误差。即使对于看似简单的函数类，如常数范数无限宽度双层神经网络，从多项式样本进行$L_\\infty$恢复也是不可能的。本文通过利用基础事实中的随机性，超越不可能性结果的一些初始步骤。我们证明了从高斯随机场中绘制的随机基础事实函数的多项式样本复杂度界限。我们的关键技术创新是证明了高斯随机场中的$k$阶球谐函数分量不能是尖锐的，即它们的$L_\\infty$/$L_2$比率高概率上限制为$O(d \\sqrt{\\ln k})$。相反，对于一般函数，$k$阶球谐函数的最坏$L_\\infty$/$L_2$比率是无界的。我们的工作为分析富函数类别的多项式样本的$L_\\infty$恢复的样本复杂度开辟了新的方向。",
    "tldr": "本文利用随机性证明了从高斯随机场中绘制的随机基础事实函数的$L_\\infty$-recovery可以使用多项式样本具有多项式样本复杂度边界。"
}