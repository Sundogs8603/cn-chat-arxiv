{
    "title": "On Influence Functions, Classification Influence, Relative Influence, Memorization and Generalization. (arXiv:2305.16094v1 [cs.LG])",
    "abstract": "Machine learning systems such as large scale recommendation systems or natural language processing systems are usually trained on billions of training points and are associated with hundreds of billions or trillions of parameters. Improving the learning process in such a way that both the training load is reduced and the model accuracy improved is highly desired. In this paper we take a first step toward solving this problem, studying influence functions from the perspective of simplifying the computations they involve. We discuss assumptions, under which influence computations can be performed on significantly fewer parameters. We also demonstrate that the sign of the influence value can indicate whether a training point is to memorize, as opposed to generalize upon. For this purpose we formally define what memorization means for a training point, as opposed to generalization. We conclude that influence functions can be made practical, even for large scale machine learning systems, an",
    "link": "http://arxiv.org/abs/2305.16094",
    "context": "Title: On Influence Functions, Classification Influence, Relative Influence, Memorization and Generalization. (arXiv:2305.16094v1 [cs.LG])\nAbstract: Machine learning systems such as large scale recommendation systems or natural language processing systems are usually trained on billions of training points and are associated with hundreds of billions or trillions of parameters. Improving the learning process in such a way that both the training load is reduced and the model accuracy improved is highly desired. In this paper we take a first step toward solving this problem, studying influence functions from the perspective of simplifying the computations they involve. We discuss assumptions, under which influence computations can be performed on significantly fewer parameters. We also demonstrate that the sign of the influence value can indicate whether a training point is to memorize, as opposed to generalize upon. For this purpose we formally define what memorization means for a training point, as opposed to generalization. We conclude that influence functions can be made practical, even for large scale machine learning systems, an",
    "path": "papers/23/05/2305.16094.json",
    "total_tokens": 843,
    "translated_title": "论影响函数、分类影响、相对影响、记忆和泛化",
    "translated_abstract": "通常情况下，诸如大规模推荐系统或自然语言处理系统之类的机器学习系统都要在数十亿的训练数据和数百亿或万亿个参数的支持下进行训练。如何改进学习过程，降低训练负荷，提高模型准确性是非常必要的。本文介绍了从简化涉及计算的影响函数的角度出发，探索解决这个问题的第一步。我们讨论了影响计算可以在显著更少的参数下进行的假设。我们还证明了影响值的符号可以指示训练点是用于记忆还是泛化。为此，我们正式定义了对于训练点而言什么是记忆和泛化。我们得出结论，即使对于大型机器学习系统，影响函数也可以实用化。",
    "tldr": "本论文通过简化涉及计算的影响函数，提高了大规模机器学习系统的训练效率并保证了模型的准确性，同时影响值的符号可以指示训练点是用于记忆还是泛化。",
    "en_tdlr": "This paper improves the training efficiency and model accuracy of large-scale machine learning systems by simplifying influence functions, and the sign of influence value can indicate whether a training point is used for memorization or generalization."
}