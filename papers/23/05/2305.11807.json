{
    "title": "On the Fairness Impacts of Private Ensembles Models. (arXiv:2305.11807v1 [cs.LG])",
    "abstract": "The Private Aggregation of Teacher Ensembles (PATE) is a machine learning framework that enables the creation of private models through the combination of multiple \"teacher\" models and a \"student\" model. The student model learns to predict an output based on the voting of the teachers, and the resulting model satisfies differential privacy. PATE has been shown to be effective in creating private models in semi-supervised settings or when protecting data labels is a priority. This paper explores whether the use of PATE can result in unfairness, and demonstrates that it can lead to accuracy disparities among groups of individuals. The paper also analyzes the algorithmic and data properties that contribute to these disproportionate impacts, why these aspects are affecting different groups disproportionately, and offers recommendations for mitigating these effects",
    "link": "http://arxiv.org/abs/2305.11807",
    "context": "Title: On the Fairness Impacts of Private Ensembles Models. (arXiv:2305.11807v1 [cs.LG])\nAbstract: The Private Aggregation of Teacher Ensembles (PATE) is a machine learning framework that enables the creation of private models through the combination of multiple \"teacher\" models and a \"student\" model. The student model learns to predict an output based on the voting of the teachers, and the resulting model satisfies differential privacy. PATE has been shown to be effective in creating private models in semi-supervised settings or when protecting data labels is a priority. This paper explores whether the use of PATE can result in unfairness, and demonstrates that it can lead to accuracy disparities among groups of individuals. The paper also analyzes the algorithmic and data properties that contribute to these disproportionate impacts, why these aspects are affecting different groups disproportionately, and offers recommendations for mitigating these effects",
    "path": "papers/23/05/2305.11807.json",
    "total_tokens": 815,
    "translated_title": "私有集成模型的公平影响研究",
    "translated_abstract": "私有教师集成（PATE）是一种机器学习框架，通过多个“教师”模型和一个“学生”模型的组合来创建私有模型。学生模型学习预测基于教师的投票的输出，生成的模型满足差分隐私。已经证明PATE在半监督设置或保护数据标签是优先的情况下创建私有模型是有效的。本文探讨了使用PATE是否会导致不公平，并证明它可能导致不同群体之间的准确性差异。本文还分析了算法和数据属性对这些不成比例的影响的贡献，以及为什么这些方面会不成比例地影响不同的群体，并提出了缓解这些影响的建议。",
    "tldr": "本文探讨了私有教师集成（PATE）模型是否会导致不公平性，并证明它可能导致不同群体之间的准确性差异。建议在PATE的应用中加入公平性考虑，以减少不公平性的影响。",
    "en_tdlr": "This paper explores the possibility of unfairness caused by private aggregation of teacher ensembles (PATE) and finds that it can lead to accuracy disparities among different groups. Recommendations are proposed to mitigate these effects and to include fairness considerations in the application of PATE."
}