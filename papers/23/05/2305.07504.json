{
    "title": "Calibration-Aware Bayesian Learning. (arXiv:2305.07504v1 [cs.LG])",
    "abstract": "Deep learning models, including modern systems like large language models, are well known to offer unreliable estimates of the uncertainty of their decisions. In order to improve the quality of the confidence levels, also known as calibration, of a model, common approaches entail the addition of either data-dependent or data-independent regularization terms to the training loss. Data-dependent regularizers have been recently introduced in the context of conventional frequentist learning to penalize deviations between confidence and accuracy. In contrast, data-independent regularizers are at the core of Bayesian learning, enforcing adherence of the variational distribution in the model parameter space to a prior density. The former approach is unable to quantify epistemic uncertainty, while the latter is severely affected by model misspecification. In light of the limitations of both methods, this paper proposes an integrated framework, referred to as calibration-aware Bayesian neural n",
    "link": "http://arxiv.org/abs/2305.07504",
    "context": "Title: Calibration-Aware Bayesian Learning. (arXiv:2305.07504v1 [cs.LG])\nAbstract: Deep learning models, including modern systems like large language models, are well known to offer unreliable estimates of the uncertainty of their decisions. In order to improve the quality of the confidence levels, also known as calibration, of a model, common approaches entail the addition of either data-dependent or data-independent regularization terms to the training loss. Data-dependent regularizers have been recently introduced in the context of conventional frequentist learning to penalize deviations between confidence and accuracy. In contrast, data-independent regularizers are at the core of Bayesian learning, enforcing adherence of the variational distribution in the model parameter space to a prior density. The former approach is unable to quantify epistemic uncertainty, while the latter is severely affected by model misspecification. In light of the limitations of both methods, this paper proposes an integrated framework, referred to as calibration-aware Bayesian neural n",
    "path": "papers/23/05/2305.07504.json",
    "total_tokens": 1020,
    "translated_title": "校准感知的贝叶斯学习",
    "translated_abstract": "深度学习模型，包括现代系统如大型语言模型，在提供其决策的不确定性方面往往无法提供可靠的估计。为了提高模型置信水平（也称为校准）的质量，常见的方法包括向训练损失添加基于数据的或基于数据无关的正则化项。在传统的频率派学习上最近引入了基于数据的正则化器，以惩罚置信度和准确度之间的偏差。相反，数据无关的正则化器在贝叶斯学习的核心，强制使模型参数空间中的变分分布服从先验密度。前一种方法无法量化认识不确定性，而后者则严重受到模型错误规范的影响。鉴于两种方法的局限性，本文提出了一个综合框架，称为校准感知的贝叶斯神经网络 (CAB)，用于共同解决深度神经网络中的校准和贝叶斯学习。所提出的框架涉及一种新颖的数据相关惩罚项，在训练过程中正则化模型的后验预测分布，从而提高模型的校准性。",
    "tldr": "本文提出了一个综合框架，称为校准感知的贝叶斯神经网络 (CAB)，用于共同解决深度神经网络中的校准和贝叶斯学习，通过在训练过程中正则化模型的后验预测分布来提高模型的校准性。",
    "en_tdlr": "This paper proposes an integrated framework, referred to as calibration-aware Bayesian neural networks (CAB), for jointly addressing calibration and Bayesian learning in deep neural networks, and improves the model's calibration by regularizing the posterior predictive distribution of the model during training."
}