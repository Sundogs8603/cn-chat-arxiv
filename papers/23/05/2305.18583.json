{
    "title": "Controllable Text-to-Image Generation with GPT-4. (arXiv:2305.18583v1 [cs.CV])",
    "abstract": "Current text-to-image generation models often struggle to follow textual instructions, especially the ones requiring spatial reasoning. On the other hand, Large Language Models (LLMs), such as GPT-4, have shown remarkable precision in generating code snippets for sketching out text inputs graphically, e.g., via TikZ. In this work, we introduce Control-GPT to guide the diffusion-based text-to-image pipelines with programmatic sketches generated by GPT-4, enhancing their abilities for instruction following. Control-GPT works by querying GPT-4 to write TikZ code, and the generated sketches are used as references alongside the text instructions for diffusion models (e.g., ControlNet) to generate photo-realistic images. One major challenge to training our pipeline is the lack of a dataset containing aligned text, images, and sketches. We address the issue by converting instance masks in existing datasets into polygons to mimic the sketches used at test time. As a result, Control-GPT greatly",
    "link": "http://arxiv.org/abs/2305.18583",
    "context": "Title: Controllable Text-to-Image Generation with GPT-4. (arXiv:2305.18583v1 [cs.CV])\nAbstract: Current text-to-image generation models often struggle to follow textual instructions, especially the ones requiring spatial reasoning. On the other hand, Large Language Models (LLMs), such as GPT-4, have shown remarkable precision in generating code snippets for sketching out text inputs graphically, e.g., via TikZ. In this work, we introduce Control-GPT to guide the diffusion-based text-to-image pipelines with programmatic sketches generated by GPT-4, enhancing their abilities for instruction following. Control-GPT works by querying GPT-4 to write TikZ code, and the generated sketches are used as references alongside the text instructions for diffusion models (e.g., ControlNet) to generate photo-realistic images. One major challenge to training our pipeline is the lack of a dataset containing aligned text, images, and sketches. We address the issue by converting instance masks in existing datasets into polygons to mimic the sketches used at test time. As a result, Control-GPT greatly",
    "path": "papers/23/05/2305.18583.json",
    "total_tokens": 892,
    "translated_title": "利用GPT-4进行可控文本生成的图像生成",
    "translated_abstract": "当前的文本到图像生成模型往往难以按照文本说明进行操作，特别是那些需要空间推理的模型。另一方面，大语言模型（LLMs），如GPT-4，在生成用于通过TikZ图解文本输入的代码片段方面表现出了极高的准确性。在这项工作中，我们引入了Control-GPT来为基于扩散的文本到图像管道提供指导，GPT-4生成编程草图，增强了他们遵循指示的能力。Control-GPT通过查询GPT-4来编写TikZ代码，生成的草图与文本说明一起用作扩散模型（例如ControlNet）生成逼真图像的参考资料。训练我们的管道的一个主要挑战是缺乏包含对准文本，图像和草图的数据集。我们通过将现有数据集中的实例掩码转换为多边形来模仿测试时使用的草图来解决这个问题。结果，Control-GPT极大地提高了文本到图像生成的可控性和保真度，取得了在几个基准数据集上的惊人成果。",
    "tldr": "利用GPT-4编写TikZ代码可提高文本到图像生成的控制性和保真度。",
    "en_tdlr": "Utilizing GPT-4 to write TikZ code enhances the controllability and fidelity of text-to-image generation."
}