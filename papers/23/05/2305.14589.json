{
    "title": "Attentive Continuous Generative Self-training for Unsupervised Domain Adaptive Medical Image Translation. (arXiv:2305.14589v1 [eess.IV])",
    "abstract": "Self-training is an important class of unsupervised domain adaptation (UDA) approaches that are used to mitigate the problem of domain shift, when applying knowledge learned from a labeled source domain to unlabeled and heterogeneous target domains. While self-training-based UDA has shown considerable promise on discriminative tasks, including classification and segmentation, through reliable pseudo-label filtering based on the maximum softmax probability, there is a paucity of prior work on self-training-based UDA for generative tasks, including image modality translation. To fill this gap, in this work, we seek to develop a generative self-training (GST) framework for domain adaptive image translation with continuous value prediction and regression objectives. Specifically, we quantify both aleatoric and epistemic uncertainties within our GST using variational Bayes learning to measure the reliability of synthesized data. We also introduce a self-attention scheme that de-emphasizes t",
    "link": "http://arxiv.org/abs/2305.14589",
    "context": "Title: Attentive Continuous Generative Self-training for Unsupervised Domain Adaptive Medical Image Translation. (arXiv:2305.14589v1 [eess.IV])\nAbstract: Self-training is an important class of unsupervised domain adaptation (UDA) approaches that are used to mitigate the problem of domain shift, when applying knowledge learned from a labeled source domain to unlabeled and heterogeneous target domains. While self-training-based UDA has shown considerable promise on discriminative tasks, including classification and segmentation, through reliable pseudo-label filtering based on the maximum softmax probability, there is a paucity of prior work on self-training-based UDA for generative tasks, including image modality translation. To fill this gap, in this work, we seek to develop a generative self-training (GST) framework for domain adaptive image translation with continuous value prediction and regression objectives. Specifically, we quantify both aleatoric and epistemic uncertainties within our GST using variational Bayes learning to measure the reliability of synthesized data. We also introduce a self-attention scheme that de-emphasizes t",
    "path": "papers/23/05/2305.14589.json",
    "total_tokens": 1119,
    "translated_title": "聚焦连续生成自训练模型用于无监督医学图像领域自适应翻译",
    "translated_abstract": "自训练是一类重要的无监督领域自适应方法，用于减轻将从标记源域学到的知识应用于未标记和异构目标域时出现的领域移位问题。虽然基于自我训练的领域自适应在包括分类和分割在内的判别任务中已显示出相当的优势，但通过最大softmax概率可靠的伪标签过滤，以生成性任务为基础的自训练领域自适应的先前研究缺乏。为了填补这一空白，我们在这项工作中，力求开发一种具有连续值预测和回归目标的生成自训练（GST）框架，用于领域自适应图像翻译。具体而言，我们使用变分贝叶斯学习来量化我们的GST中的不确定性，以测量合成数据的可靠性。我们还引入了一个自我注意机制，以减弱不相关区域的翻译，以提高生成图像的保真度。实验表明，我们的方法在两个具有挑战性的领域自适应基准上优于先前的无监督方法，分别是跨模态的磁共振成像合成和多对比度的磁共振成像合成。",
    "tldr": "通过引入聚焦机制和方差贝叶斯学习来提高可靠性，开发了一种聚焦连续生成自训练模型，用于无监督医学图像领域自适应翻译任务，且已在多项实验中表现出超越其他无监督方法的优势。",
    "en_tdlr": "This paper proposes an attentive continuous generative self-training model for unsupervised domain adaptive medical image translation, which utilizes a self-attention scheme and variational Bayes learning to enhance reliability. The model outperforms prior unsupervised methods in challenging benchmarks for cross-modality magnetic resonance imaging synthesis and multi-contrast MRI synthesis."
}