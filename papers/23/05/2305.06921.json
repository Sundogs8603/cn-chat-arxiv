{
    "title": "How to Use Reinforcement Learning to Facilitate Future Electricity Market Design? Part 2: Method and Applications. (arXiv:2305.06921v1 [cs.GT])",
    "abstract": "This two-part paper develops a paradigmatic theory and detailed methods of the joint electricity market design using reinforcement-learning (RL)-based simulation. In Part 2, this theory is further demonstrated by elaborating detailed methods of designing an electricity spot market (ESM), together with a reserved capacity product (RC) in the ancillary service market (ASM) and a virtual bidding (VB) product in the financial market (FM). Following the theory proposed in Part 1, firstly, market design options in the joint market are specified. Then, the Markov game model is developed, in which we show how to incorporate market design options and uncertain risks in model formulation. A multi-agent policy proximal optimization (MAPPO) algorithm is elaborated, as a practical implementation of the generalized market simulation method developed in Part 1. Finally, the case study demonstrates how to pick the best market design options by using some of the market operation performance indicators ",
    "link": "http://arxiv.org/abs/2305.06921",
    "context": "Title: How to Use Reinforcement Learning to Facilitate Future Electricity Market Design? Part 2: Method and Applications. (arXiv:2305.06921v1 [cs.GT])\nAbstract: This two-part paper develops a paradigmatic theory and detailed methods of the joint electricity market design using reinforcement-learning (RL)-based simulation. In Part 2, this theory is further demonstrated by elaborating detailed methods of designing an electricity spot market (ESM), together with a reserved capacity product (RC) in the ancillary service market (ASM) and a virtual bidding (VB) product in the financial market (FM). Following the theory proposed in Part 1, firstly, market design options in the joint market are specified. Then, the Markov game model is developed, in which we show how to incorporate market design options and uncertain risks in model formulation. A multi-agent policy proximal optimization (MAPPO) algorithm is elaborated, as a practical implementation of the generalized market simulation method developed in Part 1. Finally, the case study demonstrates how to pick the best market design options by using some of the market operation performance indicators ",
    "path": "papers/23/05/2305.06921.json",
    "total_tokens": 967,
    "translated_title": "如何使用强化学习促进未来的电力市场设计？第二部分：方法和应用",
    "translated_abstract": "本为两部分的论文发展了一种范式理论和详细的方法，利用基于强化学习（RL）的模拟来联合电力市场设计。在第二部分中，通过阐述详细的方法设计电力现货市场（ESM）、辅助服务市场（ASM）中的保留能力产品（RC）和金融市场（FM）中的虚拟竞标（VB）产品来进一步演示这一理论。根据第一部分提出的理论，首先确定联合市场中的市场设计选项。接着，开发了马尔科夫博弈模型，展示了如何将市场设计选项和不确定风险纳入模型公式中。详细阐述了一种多智能体策略近端优化（MAPPO）算法，作为第一部分开发的广义市场模拟方法的实际实现。最后，通过使用一些市场运行绩效指标，案例研究演示如何选择最佳市场设计选项。",
    "tldr": "本文开发了一种基于强化学习的模拟方法来联合设计电力市场，详细阐述了设计电力现货市场、辅助服务市场中的保留能力产品和金融市场中的虚拟竞标产品的方法，并通过案例研究演示了如何选择最佳市场设计选项。",
    "en_tdlr": "This two-part paper proposes a reinforcement learning-based simulation method for joint electricity market design, and elaborates detailed methods for designing an electricity spot market, reserved capacity product in the ancillary service market, and virtual bidding product in the financial market. Through a case study, the paper demonstrates how to select the best market design options using performance indicators."
}