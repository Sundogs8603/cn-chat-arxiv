{
    "title": "Learning from Children: Improving Image-Caption Pretraining via Curriculum. (arXiv:2305.17540v2 [cs.CV] UPDATED)",
    "abstract": "Image-caption pretraining has been quite successfully used for downstream vision tasks like zero-shot image classification and object detection. However, image-caption pretraining is still a hard problem -- it requires multiple concepts (nouns) from captions to be aligned to several objects in images. To tackle this problem, we go to the roots -- the best learner, children. We take inspiration from cognitive science studies dealing with children's language learning to propose a curriculum learning framework. The learning begins with easy-to-align image caption pairs containing one concept per caption. The difficulty is progressively increased with each new phase by adding one more concept per caption. Correspondingly, the knowledge acquired in each learning phase is utilized in subsequent phases to effectively constrain the learning problem to aligning one new concept-object pair in each phase. We show that this learning strategy improves over vanilla image-caption training in various ",
    "link": "http://arxiv.org/abs/2305.17540",
    "context": "Title: Learning from Children: Improving Image-Caption Pretraining via Curriculum. (arXiv:2305.17540v2 [cs.CV] UPDATED)\nAbstract: Image-caption pretraining has been quite successfully used for downstream vision tasks like zero-shot image classification and object detection. However, image-caption pretraining is still a hard problem -- it requires multiple concepts (nouns) from captions to be aligned to several objects in images. To tackle this problem, we go to the roots -- the best learner, children. We take inspiration from cognitive science studies dealing with children's language learning to propose a curriculum learning framework. The learning begins with easy-to-align image caption pairs containing one concept per caption. The difficulty is progressively increased with each new phase by adding one more concept per caption. Correspondingly, the knowledge acquired in each learning phase is utilized in subsequent phases to effectively constrain the learning problem to aligning one new concept-object pair in each phase. We show that this learning strategy improves over vanilla image-caption training in various ",
    "path": "papers/23/05/2305.17540.json",
    "total_tokens": 874,
    "translated_title": "从孩子身上学习：通过课程学习改进图像字幕预训练",
    "translated_abstract": "图像字幕预训练已经被广泛用于零样本图像分类和物体检测等下游视觉任务，但仍然是一个难题，需要将字幕中的多个概念与图片中的多个对象对齐。为了解决这个问题，研究者们从最优秀的学习者——孩子们身上汲取灵感，提出了一种课程学习框架，最开始使用易于对齐一组概念的图像字幕配对进行学习，然后逐渐增加难度，每个新阶段都逐渐增加一个概念，利用每个学习阶段获取的知识在后续阶段中帮助对齐一个新的概念-对象对。我们展示了这种学习策略在各种基准测试中对原始的图像字幕训练的改进效果。",
    "tldr": "本研究借鉴孩子语言学习的方法，提出了一种课程学习框架，通过逐渐增加新概念的对齐来改进图像字幕预训练，提高其在各种下游视觉任务中的表现。",
    "en_tdlr": "This paper proposes a curriculum learning framework inspired by children's language learning to improve image-caption pretraining by gradually increasing the alignment difficulty, and shows its effectiveness in various downstream vision tasks on popular benchmarks."
}