{
    "title": "ESCOXLM-R: Multilingual Taxonomy-driven Pre-training for the Job Market Domain. (arXiv:2305.12092v1 [cs.CL])",
    "abstract": "The increasing number of benchmarks for Natural Language Processing (NLP) tasks in the computational job market domain highlights the demand for methods that can handle job-related tasks such as skill extraction, skill classification, job title classification, and de-identification. While some approaches have been developed that are specific to the job market domain, there is a lack of generalized, multilingual models and benchmarks for these tasks. In this study, we introduce a language model called ESCOXLM-R, based on XLM-R, which uses domain-adaptive pre-training on the European Skills, Competences, Qualifications and Occupations (ESCO) taxonomy, covering 27 languages. The pre-training objectives for ESCOXLM-R include dynamic masked language modeling and a novel additional objective for inducing multilingual taxonomical ESCO relations. We comprehensively evaluate the performance of ESCOXLM-R on 6 sequence labeling and 3 classification tasks in 4 languages and find that it achieves s",
    "link": "http://arxiv.org/abs/2305.12092",
    "context": "Title: ESCOXLM-R: Multilingual Taxonomy-driven Pre-training for the Job Market Domain. (arXiv:2305.12092v1 [cs.CL])\nAbstract: The increasing number of benchmarks for Natural Language Processing (NLP) tasks in the computational job market domain highlights the demand for methods that can handle job-related tasks such as skill extraction, skill classification, job title classification, and de-identification. While some approaches have been developed that are specific to the job market domain, there is a lack of generalized, multilingual models and benchmarks for these tasks. In this study, we introduce a language model called ESCOXLM-R, based on XLM-R, which uses domain-adaptive pre-training on the European Skills, Competences, Qualifications and Occupations (ESCO) taxonomy, covering 27 languages. The pre-training objectives for ESCOXLM-R include dynamic masked language modeling and a novel additional objective for inducing multilingual taxonomical ESCO relations. We comprehensively evaluate the performance of ESCOXLM-R on 6 sequence labeling and 3 classification tasks in 4 languages and find that it achieves s",
    "path": "papers/23/05/2305.12092.json",
    "total_tokens": 902,
    "translated_title": "ESCOXLM-R: 多语言的基于分类法的职业培训",
    "translated_abstract": "自然语言处理（NLP）任务的基准数量在计算职业市场领域不断增加，强调需要能够处理与技能提取、技能分类、工作标题分类和去标识符等方面相关的职相关任务的方法。虽然已经开发了一些特定于职业市场领域的方法，但缺乏通用的、多语言的模型和这些任务的基准。在本研究中，我们介绍了一种语言模型，称为ESCOXLM-R，它是基于XLM-R的，使用欧洲技能、竞争力、资格和职业ESCO分类法的领域自适应预训练，覆盖27种语言。ESCOXLM-R的预训练目标包括动态遮盖语言建模和引入多语言分类ESCOS关系的新型附加目标。我们在4种语言上对ESCOXLM-R的6个序列标签任务和3个分类任务进行全面评估，发现它取得了极好的表现。",
    "tldr": "本论文提出了一种名为ESCOXLM-R的多语言语言模型，它使用领域自适应预训练技术，能够成功地处理职业市场领域的多项任务。",
    "en_tdlr": "This paper introduces a multilingual language model, ESCOXLM-R, which is based on XLM-R and uses domain-adaptive pre-training on the European Skills, Competences, Qualifications and Occupations (ESCO) taxonomy to handle various tasks related to the job market domain."
}