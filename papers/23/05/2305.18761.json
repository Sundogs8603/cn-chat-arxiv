{
    "title": "Identifying Spurious Biases Early in Training through the Lens of Simplicity Bias",
    "abstract": "arXiv:2305.18761v2 Announce Type: replace  Abstract: Neural networks trained with (stochastic) gradient descent have an inductive bias towards learning simpler solutions. This makes them highly prone to learning spurious correlations in the training data, that may not hold at test time. In this work, we provide the first theoretical analysis of the effect of simplicity bias on learning spurious correlations. Notably, we show that examples with spurious features are provably separable based on the model's output early in training. We further illustrate that if spurious features have a small enough noise-to-signal ratio, the network's output on the majority of examples is almost exclusively determined by the spurious features, leading to poor worst-group test accuracy. Finally, we propose SPARE, which identifies spurious correlations early in training and utilizes importance sampling to alleviate their effect. Empirically, we demonstrate that SPARE outperforms state-of-the-art methods by",
    "link": "https://arxiv.org/abs/2305.18761",
    "context": "Title: Identifying Spurious Biases Early in Training through the Lens of Simplicity Bias\nAbstract: arXiv:2305.18761v2 Announce Type: replace  Abstract: Neural networks trained with (stochastic) gradient descent have an inductive bias towards learning simpler solutions. This makes them highly prone to learning spurious correlations in the training data, that may not hold at test time. In this work, we provide the first theoretical analysis of the effect of simplicity bias on learning spurious correlations. Notably, we show that examples with spurious features are provably separable based on the model's output early in training. We further illustrate that if spurious features have a small enough noise-to-signal ratio, the network's output on the majority of examples is almost exclusively determined by the spurious features, leading to poor worst-group test accuracy. Finally, we propose SPARE, which identifies spurious correlations early in training and utilizes importance sampling to alleviate their effect. Empirically, we demonstrate that SPARE outperforms state-of-the-art methods by",
    "path": "papers/23/05/2305.18761.json",
    "total_tokens": 904,
    "translated_title": "透过简单性偏见的视角早期识别训练中的虚假偏见",
    "translated_abstract": "使用（随机）梯度下降训练的神经网络具有朝向学习更简单解决方案的归纳偏见。这使得它们极易于学习训练数据中的虚假相关性，在测试时可能不成立。在这项工作中，我们首次提供了对简单性偏见对学习虚假相关性的影响的理论分析。值得注意的是，我们展示了早期训练中基于模型输出可以明确分离出具有虚假特征的示例。我们进一步说明，如果虚假特征的噪声信号比足够小，网络在大多数示例上的输出几乎完全由虚假特征决定，导致较差的最坏组测试精度。最后，我们提出了SPARE，它可以在训练早期识别虚假相关性并利用重要性抽样来减轻其影响。实验证明，SPARE的表现优于最先进的方法。",
    "tldr": "本研究通过理论分析揭示了简单性偏见对学习虚假相关性的影响，提出了早期识别和缓解虚假相关性的方法SPARE，并在实验证明其优于目前最先进的方法。",
    "en_tdlr": "This study reveals the impact of simplicity bias on learning spurious correlations through theoretical analysis, proposes the method SPARE for early identification and alleviation of spurious correlations, and demonstrates its superiority over state-of-the-art methods empirically."
}