{
    "title": "Unbiased Gradient Boosting Decision Tree with Unbiased Feature Importance. (arXiv:2305.10696v1 [cs.LG])",
    "abstract": "Gradient Boosting Decision Tree (GBDT) has achieved remarkable success in a wide variety of applications. The split finding algorithm, which determines the tree construction process, is one of the most crucial components of GBDT. However, the split finding algorithm has long been criticized for its bias towards features with a large number of potential splits. This bias introduces severe interpretability and overfitting issues in GBDT. To this end, we provide a fine-grained analysis of bias in GBDT and demonstrate that the bias originates from 1) the systematic bias in the gain estimation of each split and 2) the bias in the split finding algorithm resulting from the use of the same data to evaluate the split improvement and determine the best split. Based on the analysis, we propose unbiased gain, a new unbiased measurement of gain importance using out-of-bag samples. Moreover, we incorporate the unbiased property into the split finding algorithm and develop UnbiasedGBM to solve the o",
    "link": "http://arxiv.org/abs/2305.10696",
    "context": "Title: Unbiased Gradient Boosting Decision Tree with Unbiased Feature Importance. (arXiv:2305.10696v1 [cs.LG])\nAbstract: Gradient Boosting Decision Tree (GBDT) has achieved remarkable success in a wide variety of applications. The split finding algorithm, which determines the tree construction process, is one of the most crucial components of GBDT. However, the split finding algorithm has long been criticized for its bias towards features with a large number of potential splits. This bias introduces severe interpretability and overfitting issues in GBDT. To this end, we provide a fine-grained analysis of bias in GBDT and demonstrate that the bias originates from 1) the systematic bias in the gain estimation of each split and 2) the bias in the split finding algorithm resulting from the use of the same data to evaluate the split improvement and determine the best split. Based on the analysis, we propose unbiased gain, a new unbiased measurement of gain importance using out-of-bag samples. Moreover, we incorporate the unbiased property into the split finding algorithm and develop UnbiasedGBM to solve the o",
    "path": "papers/23/05/2305.10696.json",
    "total_tokens": 913,
    "translated_title": "无偏置特征重要性的无偏梯度提升决策树",
    "translated_abstract": "梯度提升决策树（GBDT）在各种应用中取得了显著的成功。决策树的构建过程是GBDT中最关键的组成部分之一。然而，长期以来，决策树算法一直因其对具有大量潜在分裂的特征的偏见而受到批评。这种偏见在GBDT中引入了严重的可解释性和过拟合问题。因此，我们对GBDT的偏差进行了细致的分析，并表明偏差源于1）每个分裂增益估计中的系统性偏差和2）由于使用相同数据评估分裂改进并确定最佳分裂而导致的分裂发现算法中的偏差。基于这种分析，我们提出了无偏增益，这是一种新的使用袋外样本进行测量的增益重要性的无偏方法。此外，我们将无偏属性纳入到分裂发现算法中，并开发了UnbiasedGBM来解决GBDT中的偏见问题。",
    "tldr": "本文提出了UnbiasedGBM方法以解决梯度提升决策树（GBDT）中特征选择过程中的偏见问题，并提出了无偏增益进行对特征重要性的测量。",
    "en_tdlr": "This paper proposes UnbiasedGBM to solve the bias problem in feature selection process of Gradient Boosting Decision Tree (GBDT), and introduces unbiased gain to measure the importance of features."
}