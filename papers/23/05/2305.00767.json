{
    "title": "RViDeformer: Efficient Raw Video Denoising Transformer with a Larger Benchmark Dataset. (arXiv:2305.00767v1 [cs.CV])",
    "abstract": "In recent years, raw video denoising has garnered increased attention due to the consistency with the imaging process and well-studied noise modeling in the raw domain. However, two problems still hinder the denoising performance. Firstly, there is no large dataset with realistic motions for supervised raw video denoising, as capturing noisy and clean frames for real dynamic scenes is difficult. To address this, we propose recapturing existing high-resolution videos displayed on a 4K screen with high-low ISO settings to construct noisy-clean paired frames. In this way, we construct a video denoising dataset (named as ReCRVD) with 120 groups of noisy-clean videos, whose ISO values ranging from 1600 to 25600. Secondly, while non-local temporal-spatial attention is beneficial for denoising, it often leads to heavy computation costs. We propose an efficient raw video denoising transformer network (RViDeformer) that explores both short and long-distance correlations. Specifically, we propos",
    "link": "http://arxiv.org/abs/2305.00767",
    "context": "Title: RViDeformer: Efficient Raw Video Denoising Transformer with a Larger Benchmark Dataset. (arXiv:2305.00767v1 [cs.CV])\nAbstract: In recent years, raw video denoising has garnered increased attention due to the consistency with the imaging process and well-studied noise modeling in the raw domain. However, two problems still hinder the denoising performance. Firstly, there is no large dataset with realistic motions for supervised raw video denoising, as capturing noisy and clean frames for real dynamic scenes is difficult. To address this, we propose recapturing existing high-resolution videos displayed on a 4K screen with high-low ISO settings to construct noisy-clean paired frames. In this way, we construct a video denoising dataset (named as ReCRVD) with 120 groups of noisy-clean videos, whose ISO values ranging from 1600 to 25600. Secondly, while non-local temporal-spatial attention is beneficial for denoising, it often leads to heavy computation costs. We propose an efficient raw video denoising transformer network (RViDeformer) that explores both short and long-distance correlations. Specifically, we propos",
    "path": "papers/23/05/2305.00767.json",
    "total_tokens": 1115,
    "translated_title": "RViDeformer：具有更大基准数据集的高效原始视频去噪变换器",
    "translated_abstract": "近年来，由于与成像过程的一致性和原始领域中成熟的噪声建模，原始视频去噪引起了越来越多的关注。然而，仍存在两个问题阻碍了去噪性能。首先，对于受控的原始视频去噪来说，没有具有真实运动的大型数据集，因为为真实动态场景捕捉噪声和清晰帧是困难的。为了解决这个问题，我们提出重新捕捉以高低ISO设置显示的现有高分辨率视频以构建噪声-清晰配对帧。这样，我们构建一个视频去噪数据集（命名为ReCRVD），其中包括120组噪声-清晰视频，其ISO值从1600到25600不等。其次，虽然非本地时空关注对于去噪有益，但它通常导致沉重的计算成本。为此，我们提出了一种高效的原始视频去噪变换器网络（RViDeformer），它探索了短距离和长距离相关性。具体而言，我们提出了一个空间变换器，用于处理本地视觉特征以减少空间冗余并加速计算。此外，为了解决长程噪声相关性，我们采用了一种新的时间变换器网络，同时模型化非本地时空依赖关系。",
    "tldr": "本文提出了RViDeformer原始视频去噪变换器及其配套数据集ReCRVD，其中利用高低ISO设置重新捕捉现有视频以构建噪声-清晰对，同时探索了非本地时空依赖关系的解决方案。",
    "en_tdlr": "This paper proposes an efficient raw video denoising transformer network RViDeformer and constructs a larger dataset ReCRVD by recapturing existing high-resolution videos with high-low ISO settings for realistic motions. The network explores both spatial and temporal correlations, utilizing a spatial transformer and a novel temporal transformer for non-local dependencies."
}