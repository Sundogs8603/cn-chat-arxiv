{
    "title": "DDDM-VC: Decoupled Denoising Diffusion Models with Disentangled Representation and Prior Mixup for Verified Robust Voice Conversion. (arXiv:2305.15816v1 [eess.AS])",
    "abstract": "Diffusion-based generative models have exhibited powerful generative performance in recent years. However, as many attributes exist in the data distribution and owing to several limitations of sharing the model parameters across all levels of the generation process, it remains challenging to control specific styles for each attribute. To address the above problem, this paper presents decoupled denoising diffusion models (DDDMs) with disentangled representations, which can control the style for each attribute in generative models. We apply DDDMs to voice conversion (VC) tasks to address the challenges of disentangling and controlling each speech attribute (e.g., linguistic information, intonation, and timbre). First, we use a self-supervised representation to disentangle the speech representation. Subsequently, the DDDMs are applied to resynthesize the speech from the disentangled representations for denoising with respect to each attribute. Moreover, we also propose the prior mixup for",
    "link": "http://arxiv.org/abs/2305.15816",
    "context": "Title: DDDM-VC: Decoupled Denoising Diffusion Models with Disentangled Representation and Prior Mixup for Verified Robust Voice Conversion. (arXiv:2305.15816v1 [eess.AS])\nAbstract: Diffusion-based generative models have exhibited powerful generative performance in recent years. However, as many attributes exist in the data distribution and owing to several limitations of sharing the model parameters across all levels of the generation process, it remains challenging to control specific styles for each attribute. To address the above problem, this paper presents decoupled denoising diffusion models (DDDMs) with disentangled representations, which can control the style for each attribute in generative models. We apply DDDMs to voice conversion (VC) tasks to address the challenges of disentangling and controlling each speech attribute (e.g., linguistic information, intonation, and timbre). First, we use a self-supervised representation to disentangle the speech representation. Subsequently, the DDDMs are applied to resynthesize the speech from the disentangled representations for denoising with respect to each attribute. Moreover, we also propose the prior mixup for",
    "path": "papers/23/05/2305.15816.json",
    "total_tokens": 969,
    "tldr": "本文提出了解耦的去噪扩散模型(DDDMs)，使用自监督表示分离语音表示，并通过DDDMs对每个属性进行去噪，解决了控制每个语音属性的挑战。此外，该文还提出了优先混合来增强模型的鲁棒性。",
    "en_tdlr": "This paper proposes decoupled denoising diffusion models (DDDMs) with disentangled representations, which separate and control each speech attribute in generative models. DDDMs are applied to resynthesize the speech from the disentangled representations for denoising with respect to each attribute and prior mixup is introduced to enhance the robustness of the model."
}