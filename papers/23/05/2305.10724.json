{
    "title": "Segment Any Anomaly without Training via Hybrid Prompt Regularization. (arXiv:2305.10724v1 [cs.CV])",
    "abstract": "We present a novel framework, i.e., Segment Any Anomaly + (SAA+), for zero-shot anomaly segmentation with hybrid prompt regularization to improve the adaptability of modern foundation models. Existing anomaly segmentation models typically rely on domain-specific fine-tuning, limiting their generalization across countless anomaly patterns. In this work, inspired by the great zero-shot generalization ability of foundation models like Segment Anything, we first explore their assembly to leverage diverse multi-modal prior knowledge for anomaly localization. For non-parameter foundation model adaptation to anomaly segmentation, we further introduce hybrid prompts derived from domain expert knowledge and target image context as regularization. Our proposed SAA+ model achieves state-of-the-art performance on several anomaly segmentation benchmarks, including VisA, MVTec-AD, MTD, and KSDD2, in the zero-shot setting. We will release the code at \\href{https://github.com/caoyunkang/Segment-Any-An",
    "link": "http://arxiv.org/abs/2305.10724",
    "context": "Title: Segment Any Anomaly without Training via Hybrid Prompt Regularization. (arXiv:2305.10724v1 [cs.CV])\nAbstract: We present a novel framework, i.e., Segment Any Anomaly + (SAA+), for zero-shot anomaly segmentation with hybrid prompt regularization to improve the adaptability of modern foundation models. Existing anomaly segmentation models typically rely on domain-specific fine-tuning, limiting their generalization across countless anomaly patterns. In this work, inspired by the great zero-shot generalization ability of foundation models like Segment Anything, we first explore their assembly to leverage diverse multi-modal prior knowledge for anomaly localization. For non-parameter foundation model adaptation to anomaly segmentation, we further introduce hybrid prompts derived from domain expert knowledge and target image context as regularization. Our proposed SAA+ model achieves state-of-the-art performance on several anomaly segmentation benchmarks, including VisA, MVTec-AD, MTD, and KSDD2, in the zero-shot setting. We will release the code at \\href{https://github.com/caoyunkang/Segment-Any-An",
    "path": "papers/23/05/2305.10724.json",
    "total_tokens": 862,
    "translated_title": "通过混合提示正则化无需训练即可分割任何异常",
    "translated_abstract": "我们提出了一个新的框架，即“Segment Any Anomaly + (SAA+)”，采用混合提示正则化技术进行零样本异常分割，以提高现代基础模型的适应性。现有的异常分割模型通常依赖于领域特定的微调，限制了它们在无数异常模式之间的泛化能力。在本工作中，我们首先探索了基础模型的零样本泛化能力，利用不同的多模态先验知识进行异常定位。为了使基础模型适应于异常分割，我们进一步引入了基于领域专家知识和目标图像上下文的混合提示作为正则化项。我们的SAA+模型在包括VisA、MVTec-AD、MTD和KSDD2在内的多个零样本异常分割基准数据集上取得了最先进的性能。我们将在\\href{https://github.com/caoyunkang/Segment-Any-An}{https://github.com/caoyunkang/Segment-Any-An}发布代码。",
    "tldr": "本文提出了SAA+框架，采用混合提示正则化技术进行零样本异常分割，并在多个基准数据集上取得了最先进的性能。"
}