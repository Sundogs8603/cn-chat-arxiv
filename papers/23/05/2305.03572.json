{
    "title": "Learn how to Prune Pixels for Multi-view Neural Image-based Synthesis. (arXiv:2305.03572v1 [cs.MM])",
    "abstract": "Image-based rendering techniques stand at the core of an immersive experience for the user, as they generate novel views given a set of multiple input images. Since they have shown good performance in terms of objective and subjective quality, the research community devotes great effort to their improvement. However, the large volume of data necessary to render at the receiver's side hinders applications in limited bandwidth environments or prevents their employment in real-time applications. We present LeHoPP, a method for input pixel pruning, where we examine the importance of each input pixel concerning the rendered view, and we avoid the use of irrelevant pixels. Even without retraining the image-based rendering network, our approach shows a good trade-off between synthesis quality and pixel rate. When tested in the general neural rendering framework, compared to other pruning baselines, LeHoPP gains between $0.9$ dB and $3.6$ dB on average.",
    "link": "http://arxiv.org/abs/2305.03572",
    "context": "Title: Learn how to Prune Pixels for Multi-view Neural Image-based Synthesis. (arXiv:2305.03572v1 [cs.MM])\nAbstract: Image-based rendering techniques stand at the core of an immersive experience for the user, as they generate novel views given a set of multiple input images. Since they have shown good performance in terms of objective and subjective quality, the research community devotes great effort to their improvement. However, the large volume of data necessary to render at the receiver's side hinders applications in limited bandwidth environments or prevents their employment in real-time applications. We present LeHoPP, a method for input pixel pruning, where we examine the importance of each input pixel concerning the rendered view, and we avoid the use of irrelevant pixels. Even without retraining the image-based rendering network, our approach shows a good trade-off between synthesis quality and pixel rate. When tested in the general neural rendering framework, compared to other pruning baselines, LeHoPP gains between $0.9$ dB and $3.6$ dB on average.",
    "path": "papers/23/05/2305.03572.json",
    "total_tokens": 853,
    "translated_title": "学习如何为多视角神经图像合成修剪像素",
    "translated_abstract": "基于图像的渲染技术是用户沉浸式体验的核心，它们在给定多个输入图像的情况下生成新视图。由于它们在客观和主观质量方面表现良好，因此研究社区致力于它们的改进。然而，处于带宽有限的环境中时所需数据的大量使得在实时应用中的应用受到限制。我们提出了LeHoPP方法，通过检查每个输入像素对于渲染的视图的重要性并避免使用不相关的像素的方法进行输入像素修剪。即使不重新训练基于图像的渲染网络，我们的方法显示出合成质量和像素率之间的良好平衡。在测试神经渲染框架时，与其他修剪基线相比，LeHoPP平均增益在0.9 dB到3.6 dB之间。",
    "tldr": "LeHoPP是一种有效的方法进行输入像素修剪，可以在不重新训练基于图像的渲染网络的情况下，在合成质量和像素率之间达到良好平衡，提高图像合成的效率。",
    "en_tdlr": "LeHoPP is an effective method for input pixel pruning, which can achieve a good balance between synthesis quality and pixel rate without retraining the image-based rendering network, improving the efficiency of image synthesis."
}