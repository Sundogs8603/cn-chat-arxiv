{
    "title": "Tram: A Token-level Retrieval-augmented Mechanism for Source Code Summarization. (arXiv:2305.11074v1 [cs.AI])",
    "abstract": "Automatically generating human-readable text describing the functionality of a program is the intent of source code summarization. Although Neural Language Models achieve significant performance in this field, an emerging trend is combining neural models with external knowledge. Most previous approaches rely on the sentence-level retrieval and combination paradigm (retrieval of similar code snippets and use of the corresponding code and summary pairs) on the encoder side. However, this paradigm is coarse-grained and cannot directly take advantage of the high-quality retrieved summary tokens on the decoder side. In this paper, we explore a fine-grained token-level retrieval-augmented mechanism on the decoder side to help the vanilla neural model generate a better code summary. Furthermore, to mitigate the limitation of token-level retrieval on capturing contextual code semantics, we propose to integrate code semantics into summary tokens. Extensive experiments and human evaluation revea",
    "link": "http://arxiv.org/abs/2305.11074",
    "context": "Title: Tram: A Token-level Retrieval-augmented Mechanism for Source Code Summarization. (arXiv:2305.11074v1 [cs.AI])\nAbstract: Automatically generating human-readable text describing the functionality of a program is the intent of source code summarization. Although Neural Language Models achieve significant performance in this field, an emerging trend is combining neural models with external knowledge. Most previous approaches rely on the sentence-level retrieval and combination paradigm (retrieval of similar code snippets and use of the corresponding code and summary pairs) on the encoder side. However, this paradigm is coarse-grained and cannot directly take advantage of the high-quality retrieved summary tokens on the decoder side. In this paper, we explore a fine-grained token-level retrieval-augmented mechanism on the decoder side to help the vanilla neural model generate a better code summary. Furthermore, to mitigate the limitation of token-level retrieval on capturing contextual code semantics, we propose to integrate code semantics into summary tokens. Extensive experiments and human evaluation revea",
    "path": "papers/23/05/2305.11074.json",
    "total_tokens": 938,
    "translated_title": "Tram：一个源代码摘要的令牌级检索增强机制",
    "translated_abstract": "自动生成人类可读的文本以描述程序的功能是源代码摘要的目标。虽然神经语言模型在这个领域取得了显著的性能，但结合神经模型和外部知识的新趋势正在兴起。大多数先前的方法依赖于句子级别的检索和组合范式（检索类似的代码片段并使用相应的代码和摘要对来编码）。然而，这种范式是粗粒度的，不能直接利用解码器端高质量的检索摘要令牌。本文中，我们探讨了一种精细的令牌级别检索增强机制，在解码器端帮助原始神经模型生成更好的代码摘要。此外，为了缓解令牌级别检索在捕捉上下文代码语义方面的局限性，我们提出将代码语义集成到摘要令牌中。大量的实验和人类评估表明，我们提出的方法Tram在Java和Python源代码摘要任务上均优于最先进的方法。",
    "tldr": "Tram是一种源代码摘要的令牌级别检索增强机制，它在解码器端精细检索帮助神经模型生成更准确的摘要，并在Java和Python源代码摘要任务上表现优异。",
    "en_tdlr": "Tram is a token-level retrieval-augmented mechanism for source code summarization, which helps the neural model generate more accurate summary by fine-grained retrieval on the decoder side, and outperforms state-of-the-art methods on Java and Python source code summarization tasks."
}