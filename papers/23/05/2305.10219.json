{
    "title": "Separability and Scatteredness (S&S) Ratio-Based Efficient SVM Regularization Parameter, Kernel, and Kernel Parameter Selection. (arXiv:2305.10219v1 [stat.ML])",
    "abstract": "Support Vector Machine (SVM) is a robust machine learning algorithm with broad applications in classification, regression, and outlier detection. SVM requires tuning the regularization parameter (RP) which controls the model capacity and the generalization performance. Conventionally, the optimum RP is found by comparison of a range of values through the Cross-Validation (CV) procedure. In addition, for non-linearly separable data, the SVM uses kernels where a set of kernels, each with a set of parameters, denoted as a grid of kernels, are considered. The optimal choice of RP and the grid of kernels is through the grid-search of CV. By stochastically analyzing the behavior of the regularization parameter, this work shows that the SVM performance can be modeled as a function of separability and scatteredness (S&S) of the data. Separability is a measure of the distance between classes, and scatteredness is the ratio of the spread of data points. In particular, for the hinge loss cost fun",
    "link": "http://arxiv.org/abs/2305.10219",
    "context": "Title: Separability and Scatteredness (S&S) Ratio-Based Efficient SVM Regularization Parameter, Kernel, and Kernel Parameter Selection. (arXiv:2305.10219v1 [stat.ML])\nAbstract: Support Vector Machine (SVM) is a robust machine learning algorithm with broad applications in classification, regression, and outlier detection. SVM requires tuning the regularization parameter (RP) which controls the model capacity and the generalization performance. Conventionally, the optimum RP is found by comparison of a range of values through the Cross-Validation (CV) procedure. In addition, for non-linearly separable data, the SVM uses kernels where a set of kernels, each with a set of parameters, denoted as a grid of kernels, are considered. The optimal choice of RP and the grid of kernels is through the grid-search of CV. By stochastically analyzing the behavior of the regularization parameter, this work shows that the SVM performance can be modeled as a function of separability and scatteredness (S&S) of the data. Separability is a measure of the distance between classes, and scatteredness is the ratio of the spread of data points. In particular, for the hinge loss cost fun",
    "path": "papers/23/05/2305.10219.json",
    "total_tokens": 1040,
    "translated_title": "基于可分性和离散度比的SVM正则化参数、核函数和核参数选择方法",
    "translated_abstract": "支持向量机（SVM）是一种具有广泛应用的鲁棒机器学习算法，可用于分类、回归和异常值检测。SVM需要调整正则化参数（RP）来控制模型容量和泛化性能。传统上，通过交叉验证（CV）过程对一系列备选RP进行比较以找到最佳RP。此外，对于非线性可分数据，SVM使用核函数，在核函数的网格中选择一组具有一组参数的核函数。RP和核网格的最佳选择是通过CV的网格搜索获得的。通过随机分析正则化参数的行为，本文展示了SVM性能可以建模为数据的可分性和离散度（S&S）的函数。可分性是类别之间距离的度量，离散度是数据点的传播比率。特别地，对于铰链损失成本函数，S&S比可以有效地估计最优RP。此外，本文提出了一种基于S&S比的高效选择核函数及其参数方法。在各种基准数据集上比较了所提出方法与传统方法的性能，结果表明，所提出方法具有更少的需要调整的超参数且性能优异或可比。",
    "tldr": "该文通过分析数据的可分性和离散度，提出了一种基于S&S比的有效SVM正则化参数、核函数和核参数选择方法，表现较传统方法更优。",
    "en_tdlr": "This paper proposes an efficient SVM regularization parameter, kernel, and kernel parameter selection method based on the S&S ratio, which is derived from the analysis of the data separability and scatteredness. The proposed method outperforms conventional methods on various benchmark datasets with fewer hyperparameters to tune."
}