{
    "title": "Scalable Mask Annotation for Video Text Spotting. (arXiv:2305.01443v1 [cs.CV])",
    "abstract": "Video text spotting refers to localizing, recognizing, and tracking textual elements such as captions, logos, license plates, signs, and other forms of text within consecutive video frames. However, current datasets available for this task rely on quadrilateral ground truth annotations, which may result in including excessive background content and inaccurate text boundaries. Furthermore, methods trained on these datasets often produce prediction results in the form of quadrilateral boxes, which limits their ability to handle complex scenarios such as dense or curved text. To address these issues, we propose a scalable mask annotation pipeline called SAMText for video text spotting. SAMText leverages the SAM model to generate mask annotations for scene text images or video frames at scale. Using SAMText, we have created a large-scale dataset, SAMText-9M, that contains over 2,400 video clips sourced from existing datasets and over 9 million mask annotations. We have also conducted a tho",
    "link": "http://arxiv.org/abs/2305.01443",
    "context": "Title: Scalable Mask Annotation for Video Text Spotting. (arXiv:2305.01443v1 [cs.CV])\nAbstract: Video text spotting refers to localizing, recognizing, and tracking textual elements such as captions, logos, license plates, signs, and other forms of text within consecutive video frames. However, current datasets available for this task rely on quadrilateral ground truth annotations, which may result in including excessive background content and inaccurate text boundaries. Furthermore, methods trained on these datasets often produce prediction results in the form of quadrilateral boxes, which limits their ability to handle complex scenarios such as dense or curved text. To address these issues, we propose a scalable mask annotation pipeline called SAMText for video text spotting. SAMText leverages the SAM model to generate mask annotations for scene text images or video frames at scale. Using SAMText, we have created a large-scale dataset, SAMText-9M, that contains over 2,400 video clips sourced from existing datasets and over 9 million mask annotations. We have also conducted a tho",
    "path": "papers/23/05/2305.01443.json",
    "total_tokens": 876,
    "tldr": "本文提出了一种名为SAMText的可扩展遮罩注释流水线，用于视频文本定位。利用此方法，可以生成更为准确的文本边界注释，并用此方法创造了大规模数据集SAMText-9M。"
}