{
    "title": "ComSL: A Composite Speech-Language Model for End-to-End Speech-to-Text Translation. (arXiv:2305.14838v2 [cs.CL] UPDATED)",
    "abstract": "Joint speech-language training is challenging due to the large demand for training data and GPU consumption, as well as the modality gap between speech and language. We present ComSL, a speech-language model built atop a composite architecture of public pretrained speech-only and language-only models and optimized data-efficiently for spoken language tasks. Particularly, we propose to incorporate cross-modality learning into transfer learning and conduct them simultaneously for downstream tasks in a multi-task learning manner. Our approach has demonstrated effectiveness in end-to-end speech-to-text translation tasks, achieving a new state-of-the-art average BLEU score of 31.5 on the multilingual speech to English text translation task for 21 languages, as measured on the public CoVoST2 evaluation set.",
    "link": "http://arxiv.org/abs/2305.14838",
    "context": "Title: ComSL: A Composite Speech-Language Model for End-to-End Speech-to-Text Translation. (arXiv:2305.14838v2 [cs.CL] UPDATED)\nAbstract: Joint speech-language training is challenging due to the large demand for training data and GPU consumption, as well as the modality gap between speech and language. We present ComSL, a speech-language model built atop a composite architecture of public pretrained speech-only and language-only models and optimized data-efficiently for spoken language tasks. Particularly, we propose to incorporate cross-modality learning into transfer learning and conduct them simultaneously for downstream tasks in a multi-task learning manner. Our approach has demonstrated effectiveness in end-to-end speech-to-text translation tasks, achieving a new state-of-the-art average BLEU score of 31.5 on the multilingual speech to English text translation task for 21 languages, as measured on the public CoVoST2 evaluation set.",
    "path": "papers/23/05/2305.14838.json",
    "total_tokens": 857,
    "translated_title": "ComSL:一种用于端到端语音到文本翻译的复合语音-语言模型",
    "translated_abstract": "由于训练数据和GPU消耗量大以及语音和语言之间的模态差异，联合语音-语言训练是具有挑战性的。我们提出了ComSL，它是建立在公共预训练的仅语音和仅语言模型的复合架构之上的语音-语言模型，并且通过优化数据效率，针对口语任务进行了相应的训练。特别地，我们提出将跨模态学习纳入迁移学习并以多任务学习的方式同时进行。我们的方法在端到端语音到文本翻译任务中表现出了很好的效果，在21种语言的多语种语音到英文文本翻译任务上，以公开的CoVoST2评估集上的平均BLEU分数达到了31.5，达到了新的最高水平。",
    "tldr": "ComSL是一种复合语音-语言模型，通过将跨模态学习纳入迁移学习并以多任务学习的方式进行训练，实现了在端到端语音到文本翻译任务中的新的最高BLEU分数。 (31.5 on CoVoST2 evaluation set，21种语言)"
}