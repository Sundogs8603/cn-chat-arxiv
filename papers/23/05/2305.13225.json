{
    "title": "Multi-Task Instruction Tuning of LLaMa for Specific Scenarios: A Preliminary Study on Writing Assistance. (arXiv:2305.13225v2 [cs.CL] UPDATED)",
    "abstract": "Proprietary Large Language Models (LLMs), such as ChatGPT, have garnered significant attention due to their exceptional capabilities in handling a diverse range of tasks. Recent studies demonstrate that open-sourced smaller foundational models, such as 7B-size LLaMA, can also display remarkable proficiency in tackling diverse tasks when fine-tuned using instruction-driven data. In this work, we investigate a practical problem setting where the primary focus is on one or a few particular tasks rather than general-purpose instruction following, and explore whether LLMs can be beneficial and further improved for such targeted scenarios. We choose the writing-assistant scenario as the testbed, which includes seven writing tasks. We collect training data for these tasks, reframe them in an instruction-following format, and subsequently refine the LLM, specifically LLaMA, via instruction tuning. Experimental results show that fine-tuning LLaMA on writing instruction data significantly improv",
    "link": "http://arxiv.org/abs/2305.13225",
    "context": "Title: Multi-Task Instruction Tuning of LLaMa for Specific Scenarios: A Preliminary Study on Writing Assistance. (arXiv:2305.13225v2 [cs.CL] UPDATED)\nAbstract: Proprietary Large Language Models (LLMs), such as ChatGPT, have garnered significant attention due to their exceptional capabilities in handling a diverse range of tasks. Recent studies demonstrate that open-sourced smaller foundational models, such as 7B-size LLaMA, can also display remarkable proficiency in tackling diverse tasks when fine-tuned using instruction-driven data. In this work, we investigate a practical problem setting where the primary focus is on one or a few particular tasks rather than general-purpose instruction following, and explore whether LLMs can be beneficial and further improved for such targeted scenarios. We choose the writing-assistant scenario as the testbed, which includes seven writing tasks. We collect training data for these tasks, reframe them in an instruction-following format, and subsequently refine the LLM, specifically LLaMA, via instruction tuning. Experimental results show that fine-tuning LLaMA on writing instruction data significantly improv",
    "path": "papers/23/05/2305.13225.json",
    "total_tokens": 749,
    "translated_title": "多任务指令调整LLaMa以适应特定场景：关于写作辅助的初步研究",
    "translated_abstract": "针对一些特定任务而非通用指令遵循，我们研究了一种实际问题设置，并探索了LLMs在这些有针对性场景中是否有利和可以进一步改进。我们选择了写作辅助作为测试平台，其中包括七个写作任务。我们收集了这些任务的训练数据，按照指令遵循的格式重新构建，并通过指令调整对LLM，特别是LLaMa进行优化。实验结果表明，使用写作指令数据对LLaMa进行微调显著改善了性能。",
    "tldr": "这项研究探索了将LLMs应用于特定任务的可能性，通过在写作辅助场景中进行指令调整，取得了显著的改进。",
    "en_tdlr": "This study explores the possibility of applying LLMs to specific tasks, and achieves significant improvement by instruction tuning in the writing assistance scenario."
}