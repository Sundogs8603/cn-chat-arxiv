{
    "title": "Information Screening whilst Exploiting! Multimodal Relation Extraction with Feature Denoising and Multimodal Topic Modeling. (arXiv:2305.11719v1 [cs.CV])",
    "abstract": "Existing research on multimodal relation extraction (MRE) faces two co-existing challenges, internal-information over-utilization and external-information under-exploitation. To combat that, we propose a novel framework that simultaneously implements the idea of internal-information screening and external-information exploiting. First, we represent the fine-grained semantic structures of the input image and text with the visual and textual scene graphs, which are further fused into a unified cross-modal graph (CMG). Based on CMG, we perform structure refinement with the guidance of the graph information bottleneck principle, actively denoising the less-informative features. Next, we perform topic modeling over the input image and text, incorporating latent multimodal topic features to enrich the contexts. On the benchmark MRE dataset, our system outperforms the current best model significantly. With further in-depth analyses, we reveal the great potential of our method for the MRE task",
    "link": "http://arxiv.org/abs/2305.11719",
    "context": "Title: Information Screening whilst Exploiting! Multimodal Relation Extraction with Feature Denoising and Multimodal Topic Modeling. (arXiv:2305.11719v1 [cs.CV])\nAbstract: Existing research on multimodal relation extraction (MRE) faces two co-existing challenges, internal-information over-utilization and external-information under-exploitation. To combat that, we propose a novel framework that simultaneously implements the idea of internal-information screening and external-information exploiting. First, we represent the fine-grained semantic structures of the input image and text with the visual and textual scene graphs, which are further fused into a unified cross-modal graph (CMG). Based on CMG, we perform structure refinement with the guidance of the graph information bottleneck principle, actively denoising the less-informative features. Next, we perform topic modeling over the input image and text, incorporating latent multimodal topic features to enrich the contexts. On the benchmark MRE dataset, our system outperforms the current best model significantly. With further in-depth analyses, we reveal the great potential of our method for the MRE task",
    "path": "papers/23/05/2305.11719.json",
    "total_tokens": 1014,
    "translated_title": "利用特征去噪和多模态主题建模的多模态关系抽取中的信息筛选",
    "translated_abstract": "现有的多模态关系抽取(MRE)研究面临着两个共存的挑战，即内部信息过度利用和外部信息未能充分利用。为了应对这个问题，我们提出了一个新的框架，同时实现了内部信息筛选和外部信息利用的思想。首先，我们用视觉和文本场景图表示输入图像和文本的细粒度语义结构，将其进一步融合成一个统一的跨模态图(CMG)。基于CMG，我们利用图形信息瓶颈原理进行结构细化，主动去除不太具有信息量的特征。接下来，我们对输入图像和文本进行主题建模，将潜在的多模态主题特征融入其中以丰富上下文。在基准MRE数据集上，我们的系统显著优于当前最佳模型。通过进一步深入的分析，我们揭示了我们的方法在MRE任务中具有巨大的潜力。",
    "tldr": "该论文提出了一种新的多模态关系抽取框架，结合了内部信息筛选和外部信息利用的思想。通过视觉和文本场景图表示输入的细粒度语义结构，并利用图形信息瓶颈原理进行结构细化和特征去噪，同时运用主题建模丰富上下文，该系统在基准MRE数据集上表现优异，具有巨大的潜力。",
    "en_tdlr": "The paper proposes a novel multimodal relation extraction framework that combines internal-information screening and external-information exploiting. By representing the input's fine-grained semantic structures with visual and textual scene graphs and refining them with the graph information bottleneck principle, along with incorporating latent multimodal topic features to enrich the contexts through topic modeling, the system significantly outperforms the current best model on the benchmark MRE dataset, revealing great potential for the MRE task."
}