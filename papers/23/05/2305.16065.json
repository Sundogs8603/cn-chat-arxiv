{
    "title": "ASR and Emotional Speech: A Word-Level Investigation of the Mutual Impact of Speech and Emotion Recognition. (arXiv:2305.16065v2 [eess.AS] UPDATED)",
    "abstract": "In Speech Emotion Recognition (SER), textual data is often used alongside audio signals to address their inherent variability. However, the reliance on human annotated text in most research hinders the development of practical SER systems. To overcome this challenge, we investigate how Automatic Speech Recognition (ASR) performs on emotional speech by analyzing the ASR performance on emotion corpora and examining the distribution of word errors and confidence scores in ASR transcripts to gain insight into how emotion affects ASR. We utilize four ASR systems, namely Kaldi ASR, wav2vec2, Conformer, and Whisper, and three corpora: IEMOCAP, MOSI, and MELD to ensure generalizability. Additionally, we conduct text-based SER on ASR transcripts with increasing word error rates to investigate how ASR affects SER. The objective of this study is to uncover the relationship and mutual impact of ASR and SER, in order to facilitate ASR adaptation to emotional speech and the use of SER in real world.",
    "link": "http://arxiv.org/abs/2305.16065",
    "context": "Title: ASR and Emotional Speech: A Word-Level Investigation of the Mutual Impact of Speech and Emotion Recognition. (arXiv:2305.16065v2 [eess.AS] UPDATED)\nAbstract: In Speech Emotion Recognition (SER), textual data is often used alongside audio signals to address their inherent variability. However, the reliance on human annotated text in most research hinders the development of practical SER systems. To overcome this challenge, we investigate how Automatic Speech Recognition (ASR) performs on emotional speech by analyzing the ASR performance on emotion corpora and examining the distribution of word errors and confidence scores in ASR transcripts to gain insight into how emotion affects ASR. We utilize four ASR systems, namely Kaldi ASR, wav2vec2, Conformer, and Whisper, and three corpora: IEMOCAP, MOSI, and MELD to ensure generalizability. Additionally, we conduct text-based SER on ASR transcripts with increasing word error rates to investigate how ASR affects SER. The objective of this study is to uncover the relationship and mutual impact of ASR and SER, in order to facilitate ASR adaptation to emotional speech and the use of SER in real world.",
    "path": "papers/23/05/2305.16065.json",
    "total_tokens": 1023,
    "translated_title": "ASR技术与情感语音：对语音与情感识别相互影响的单词级探索",
    "translated_abstract": "在语音情感识别（SER）中，为了应对固有的变异性，通常会使用文本数据来辅助音频信号。然而，大多数研究中依赖于人工标注的文本数据，这阻碍了实用化SER系统的发展。为了克服这个挑战，我们使用四个ASR系统（分别是Kaldi ASR、wav2vec2、Conformer和Whisper）和三个语料库（IEMOCAP、MOSI和MELD）来分析情感语音上的ASR表现，并且通过分析ASR转录中的词错误和置信度分布来了解情感如何影响ASR。此外，我们对具有不断增加单词错误率的ASR转录进行基于文本的情感识别，以研究ASR如何影响SER。本研究的目标是揭示ASR和SER之间的关系和相互影响，以促进ASR技术对情感语音的适应和SER技术在实际中的应用。",
    "tldr": "本论文研究了ASR技术在情感语音上的表现，并探究了情感如何影响ASR。同时，还研究了ASR对基于文本的情感识别的影响。该研究旨在揭示ASR和SER之间的关系和相互影响，以促进ASR技术对情感语音的适应和SER技术在实际中的应用。",
    "en_tdlr": "This paper investigates the performance of Automatic Speech Recognition (ASR) on emotional speech and how emotion affects ASR. The study also explores the impact of ASR on text-based Speech Emotion Recognition (SER) with increasing word error rates. The objective is to uncover the relationship and mutual impact of ASR and SER, in order to facilitate ASR adaptation to emotional speech and the use of SER in real world."
}