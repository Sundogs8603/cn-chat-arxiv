{
    "title": "RAMario: Experimental Approach to Reptile Algorithm -- Reinforcement Learning for Mario. (arXiv:2305.09655v1 [cs.LG])",
    "abstract": "This research paper presents an experimental approach to using the Reptile algorithm for reinforcement learning to train a neural network to play Super Mario Bros. We implement the Reptile algorithm using the Super Mario Bros Gym library and TensorFlow in Python, creating a neural network model with a single convolutional layer, a flatten layer, and a dense layer. We define the optimizer and use the Reptile class to create an instance of the Reptile meta-learning algorithm. We train the model using multiple tasks and episodes, choosing actions using the current weights of the neural network model, taking those actions in the environment, and updating the model weights using the Reptile algorithm. We evaluate the performance of the algorithm by printing the total reward for each episode. In addition, we compare the performance of the Reptile algorithm approach to two other popular reinforcement learning algorithms, Proximal Policy Optimization (PPO) and Deep Q-Network (DQN), applied to ",
    "link": "http://arxiv.org/abs/2305.09655",
    "context": "Title: RAMario: Experimental Approach to Reptile Algorithm -- Reinforcement Learning for Mario. (arXiv:2305.09655v1 [cs.LG])\nAbstract: This research paper presents an experimental approach to using the Reptile algorithm for reinforcement learning to train a neural network to play Super Mario Bros. We implement the Reptile algorithm using the Super Mario Bros Gym library and TensorFlow in Python, creating a neural network model with a single convolutional layer, a flatten layer, and a dense layer. We define the optimizer and use the Reptile class to create an instance of the Reptile meta-learning algorithm. We train the model using multiple tasks and episodes, choosing actions using the current weights of the neural network model, taking those actions in the environment, and updating the model weights using the Reptile algorithm. We evaluate the performance of the algorithm by printing the total reward for each episode. In addition, we compare the performance of the Reptile algorithm approach to two other popular reinforcement learning algorithms, Proximal Policy Optimization (PPO) and Deep Q-Network (DQN), applied to ",
    "path": "papers/23/05/2305.09655.json",
    "total_tokens": 883,
    "tldr": "本论文使用Reptile算法，实验性地探究强化学习在超级马里奥游戏中的应用。结果表明，Reptile算法的表现优于PPO和DQN算法。",
    "en_tdlr": "This paper presents an experimental approach to using the Reptile algorithm for reinforcement learning to train a neural network to play Super Mario Bros. The results show that the performance of the Reptile algorithm is superior to the PPO and DQN algorithms."
}