{
    "title": "A Fractional Graph Laplacian Approach to Oversmoothing. (arXiv:2305.13084v2 [cs.LG] UPDATED)",
    "abstract": "Graph neural networks (GNNs) have shown state-of-the-art performances in various applications. However, GNNs often struggle to capture long-range dependencies in graphs due to oversmoothing. In this paper, we generalize the concept of oversmoothing from undirected to directed graphs. To this aim, we extend the notion of Dirichlet energy by considering a directed symmetrically normalized Laplacian. As vanilla graph convolutional networks are prone to oversmooth, we adopt a neural graph ODE framework. Specifically, we propose fractional graph Laplacian neural ODEs, which describe non-local dynamics. We prove that our approach allows propagating information between distant nodes while maintaining a low probability of long-distance jumps. Moreover, we show that our method is more flexible with respect to the convergence of the graph's Dirichlet energy, thereby mitigating oversmoothing. We conduct extensive experiments on synthetic and real-world graphs, both directed and undirected, demons",
    "link": "http://arxiv.org/abs/2305.13084",
    "context": "Title: A Fractional Graph Laplacian Approach to Oversmoothing. (arXiv:2305.13084v2 [cs.LG] UPDATED)\nAbstract: Graph neural networks (GNNs) have shown state-of-the-art performances in various applications. However, GNNs often struggle to capture long-range dependencies in graphs due to oversmoothing. In this paper, we generalize the concept of oversmoothing from undirected to directed graphs. To this aim, we extend the notion of Dirichlet energy by considering a directed symmetrically normalized Laplacian. As vanilla graph convolutional networks are prone to oversmooth, we adopt a neural graph ODE framework. Specifically, we propose fractional graph Laplacian neural ODEs, which describe non-local dynamics. We prove that our approach allows propagating information between distant nodes while maintaining a low probability of long-distance jumps. Moreover, we show that our method is more flexible with respect to the convergence of the graph's Dirichlet energy, thereby mitigating oversmoothing. We conduct extensive experiments on synthetic and real-world graphs, both directed and undirected, demons",
    "path": "papers/23/05/2305.13084.json",
    "total_tokens": 980,
    "translated_title": "一种针对过度平滑的分数图拉普拉斯方法",
    "translated_abstract": "图神经网络在各种应用中显示出最先进的性能。然而，由于过度平滑，GNN经常难以捕捉图中的长距离依赖关系。在本文中，我们将过度平滑的概念从无向图推广到有向图。为此，我们通过考虑一个有向对称归一化拉普拉斯来扩展Dirichlet能量的概念。由于传统的图卷积网络容易出现过度平滑的问题，我们采用了神经图ODE框架。具体地，我们提出了分数图拉普拉斯神经ODE，描述了非局部动力学。我们证明了我们的方法允许在远处节点之间传播信息，同时保持低概率的远距离跳跃。而且，我们展示了我们的方法在图的Dirichlet能量收敛方面更加灵活，从而减轻了过度平滑的问题。我们在合成和实际图上进行了大量实验，包括有向和无向图。",
    "tldr": "本文提出了一种针对过度平滑问题的分数图拉普拉斯方法，通过采用神经图ODE框架来描述非局部动力学，允许在远处节点之间传播信息，同时保持低概率的远距离跳跃，进而减轻过度平滑问题，并在合成和实际图上进行了广泛实验验证。",
    "en_tdlr": "This paper presents a fractional graph Laplacian approach to address the oversmoothing problem in graph neural networks. By adopting a neural graph ODE framework, it allows information propagation between distant nodes while maintaining a low probability of long-distance jumps, thereby mitigating the issue of oversmoothing. Extensive experiments on synthetic and real-world graphs demonstrate the effectiveness of the proposed method."
}