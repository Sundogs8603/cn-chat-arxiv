{
    "title": "Shared and Private Information Learning in Multimodal Sentiment Analysis with Deep Modal Alignment and Self-supervised Multi-Task Learning",
    "abstract": "arXiv:2305.08473v2 Announce Type: replace  Abstract: Designing an effective representation learning method for multimodal sentiment analysis tasks is a crucial research direction. The challenge lies in learning both shared and private information in a complete modal representation, which is difficult with uniform multimodal labels and a raw feature fusion approach. In this work, we propose a deep modal shared information learning module based on the covariance matrix to capture the shared information between modalities. Additionally, we use a label generation module based on a self-supervised learning strategy to capture the private information of the modalities. Our module is plug-and-play in multimodal tasks, and by changing the parameterization, it can adjust the information exchange relationship between the modes and learn the private or shared information between the specified modes. We also employ a multi-task learning strategy to help the model focus its attention on the modal d",
    "link": "https://arxiv.org/abs/2305.08473",
    "context": "Title: Shared and Private Information Learning in Multimodal Sentiment Analysis with Deep Modal Alignment and Self-supervised Multi-Task Learning\nAbstract: arXiv:2305.08473v2 Announce Type: replace  Abstract: Designing an effective representation learning method for multimodal sentiment analysis tasks is a crucial research direction. The challenge lies in learning both shared and private information in a complete modal representation, which is difficult with uniform multimodal labels and a raw feature fusion approach. In this work, we propose a deep modal shared information learning module based on the covariance matrix to capture the shared information between modalities. Additionally, we use a label generation module based on a self-supervised learning strategy to capture the private information of the modalities. Our module is plug-and-play in multimodal tasks, and by changing the parameterization, it can adjust the information exchange relationship between the modes and learn the private or shared information between the specified modes. We also employ a multi-task learning strategy to help the model focus its attention on the modal d",
    "path": "papers/23/05/2305.08473.json",
    "total_tokens": 881,
    "translated_title": "深度模态对齐和自监督多任务学习中的多模态情感分析中的共享和私有信息学习",
    "translated_abstract": "在多模态情感分析任务中设计一个有效的表示学习方法是一个关键的研究方向。挑战在于学习完整模态表示中的共享信息和私有信息，这在统一的多模态标签和原始特征融合方法中是困难的。在这项工作中，我们提出了一个基于协方差矩阵的深度模态共享信息学习模块，用于捕捉模态之间的共享信息。此外，我们使用了基于自监督学习策略的标签生成模块来捕捉模态的私有信息。我们的模块在多模态任务中是即插即用的，通过改变参数化，可以调整模态之间的信息交换关系，并学习指定模式之间的私有或共享信息。我们还采用了多任务学习策略，帮助模型将注意力集中在模态d上。",
    "tldr": "该论文提出了一种深度模态共享信息学习模块和基于自监督学习策略的标签生成模块，用于在多模态情感分析中学习共享和私有信息，可根据参数化调整不同模态之间的信息交换关系。"
}