{
    "title": "DeepFire2: A Convolutional Spiking Neural Network Accelerator on FPGAs. (arXiv:2305.05187v1 [cs.NE])",
    "abstract": "Brain-inspired spiking neural networks (SNNs) replace the multiply-accumulate operations of traditional neural networks by integrate-and-fire neurons, with the goal of achieving greater energy efficiency. Specialized hardware implementations of those neurons clearly have advantages over general-purpose devices in terms of power and performance, but exhibit poor scalability when it comes to accelerating large neural networks. DeepFire2 introduces a hardware architecture which can map large network layers efficiently across multiple super logic regions in a multi-die FPGA. That gives more control over resource allocation and parallelism, benefiting both throughput and energy consumption. Avoiding the use of lookup tables to implement the AND operations of an SNN, prevents the layer size to be limited by logic resources. A deep pipeline does not only lead to an increased clock speed of up to 600 MHz. We double the throughput and power efficiency compared to our previous version of DeepFir",
    "link": "http://arxiv.org/abs/2305.05187",
    "context": "Title: DeepFire2: A Convolutional Spiking Neural Network Accelerator on FPGAs. (arXiv:2305.05187v1 [cs.NE])\nAbstract: Brain-inspired spiking neural networks (SNNs) replace the multiply-accumulate operations of traditional neural networks by integrate-and-fire neurons, with the goal of achieving greater energy efficiency. Specialized hardware implementations of those neurons clearly have advantages over general-purpose devices in terms of power and performance, but exhibit poor scalability when it comes to accelerating large neural networks. DeepFire2 introduces a hardware architecture which can map large network layers efficiently across multiple super logic regions in a multi-die FPGA. That gives more control over resource allocation and parallelism, benefiting both throughput and energy consumption. Avoiding the use of lookup tables to implement the AND operations of an SNN, prevents the layer size to be limited by logic resources. A deep pipeline does not only lead to an increased clock speed of up to 600 MHz. We double the throughput and power efficiency compared to our previous version of DeepFir",
    "path": "papers/23/05/2305.05187.json",
    "total_tokens": 897,
    "translated_title": "深度神经网络加速器DeepFire2：基于FPGA的卷积脉冲神经网络",
    "translated_abstract": "以仿生学脉冲神经网络（SNN）代替传统神经网络的乘加操作，从而实现更高的能量效率。但当加速大型神经网络时，专用硬件实现这些神经元在功率和性能方面具有优势，但具有较差的可扩展性。DeepFire2引入了一种硬件架构，可以有效地将大型网络层映射到多个超级逻辑区域中的多个芯片上。这给了更多的资源分配和并行性控制，从而使吞吐量和能量消耗受益。避免使用查找表来实现SNN的AND运算，避免了逻辑资源限制层大小。深度流水线不仅可以将时钟速度提高高达600 MHz，而且与DeepFire上一个版本相比，我们将吞吐量和功率效率提高了一倍。",
    "tldr": "本文介绍了一种基于FPGA的深度神经网络加速器DeepFire2，通过利用多芯片的超级逻辑区域映射大型网络层，避免了逻辑资源限制层大小，同时通过深度流水线提高了时钟速度，将吞吐量和功率效率提高了一倍。",
    "en_tdlr": "This article introduces a DeepFire2, a FPGA-based deep neural network accelerator that maps large network layers across multiple super logic regions to avoid logic resource constraints and uses a deep pipeline to increase clock speed, thereby doubling throughput and power efficiency."
}