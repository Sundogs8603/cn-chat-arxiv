{
    "title": "Robustified Learning for Online Optimization with Memory Costs. (arXiv:2305.00677v1 [cs.LG])",
    "abstract": "Online optimization with memory costs has many real-world applications, where sequential actions are made without knowing the future input. Nonetheless, the memory cost couples the actions over time, adding substantial challenges. Conventionally, this problem has been approached by various expert-designed online algorithms with the goal of achieving bounded worst-case competitive ratios, but the resulting average performance is often unsatisfactory. On the other hand, emerging machine learning (ML) based optimizers can improve the average performance, but suffer from the lack of worst-case performance robustness. In this paper, we propose a novel expert-robustified learning (ERL) approach, achieving {both} good average performance and robustness. More concretely, for robustness, ERL introduces a novel projection operator that robustifies ML actions by utilizing an expert online algorithm; for average performance, ERL trains the ML optimizer based on a recurrent architecture by explicit",
    "link": "http://arxiv.org/abs/2305.00677",
    "context": "Title: Robustified Learning for Online Optimization with Memory Costs. (arXiv:2305.00677v1 [cs.LG])\nAbstract: Online optimization with memory costs has many real-world applications, where sequential actions are made without knowing the future input. Nonetheless, the memory cost couples the actions over time, adding substantial challenges. Conventionally, this problem has been approached by various expert-designed online algorithms with the goal of achieving bounded worst-case competitive ratios, but the resulting average performance is often unsatisfactory. On the other hand, emerging machine learning (ML) based optimizers can improve the average performance, but suffer from the lack of worst-case performance robustness. In this paper, we propose a novel expert-robustified learning (ERL) approach, achieving {both} good average performance and robustness. More concretely, for robustness, ERL introduces a novel projection operator that robustifies ML actions by utilizing an expert online algorithm; for average performance, ERL trains the ML optimizer based on a recurrent architecture by explicit",
    "path": "papers/23/05/2305.00677.json",
    "total_tokens": 873,
    "translated_title": "用于内存成本的在线优化的鲁棒学习",
    "translated_abstract": "在线优化的内存成本有许多实际应用，其中顺序操作在不知道未来输入的情况下进行。然而，内存成本将随时间耦合的操作添加了重大挑战。传统上，通过各种专家设计的在线算法来解决这个问题，目标是实现有界的最坏情况竞争比，但结果的平均性能通常不令人满意。另一方面，新兴的基于机器学习（ML）的优化器可以提高平均性能，但缺乏最坏情况性能鲁棒性。在本文中，我们提出了一种新颖的专家鲁棒学习（ERL）方法，既实现了良好的平均性能又具有鲁棒性。更具体地，为了实现鲁棒性，ERL引入了一种新颖的投影算子，通过利用专家在线算法来使ML操作具有鲁棒性；为了实现平均性能，ERL使用基于递归结构的ML优化器进行训练，明确",
    "tldr": "本文提出了一种新颖的专家鲁棒学习（ERL）方法，在内存成本的在线优化中实现了良好的平均性能和鲁棒性。"
}