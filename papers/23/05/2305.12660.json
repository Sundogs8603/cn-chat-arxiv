{
    "title": "Beneath Surface Similarity: Large Language Models Make Reasonable Scientific Analogies after Structure Abduction. (arXiv:2305.12660v2 [cs.CL] UPDATED)",
    "abstract": "The vital role of analogical reasoning in human cognition allows us to grasp novel concepts by linking them with familiar ones through shared relational structures. Despite the attention previous research has given to word analogies, this work suggests that Large Language Models (LLMs) often overlook the structures that underpin these analogies, raising questions about the efficacy of word analogies as a measure of analogical reasoning skills akin to human cognition. In response to this, our paper introduces a task of analogical structure abduction, grounded in cognitive psychology, designed to abduce structures that form an analogy between two systems. In support of this task, we establish a benchmark called SCAR, containing 400 scientific analogies from 13 distinct fields, tailored for evaluating analogical reasoning with structure abduction. The empirical evidence underlines the continued challenges faced by LLMs, including ChatGPT and GPT-4, in mastering this task, signifying the n",
    "link": "http://arxiv.org/abs/2305.12660",
    "context": "Title: Beneath Surface Similarity: Large Language Models Make Reasonable Scientific Analogies after Structure Abduction. (arXiv:2305.12660v2 [cs.CL] UPDATED)\nAbstract: The vital role of analogical reasoning in human cognition allows us to grasp novel concepts by linking them with familiar ones through shared relational structures. Despite the attention previous research has given to word analogies, this work suggests that Large Language Models (LLMs) often overlook the structures that underpin these analogies, raising questions about the efficacy of word analogies as a measure of analogical reasoning skills akin to human cognition. In response to this, our paper introduces a task of analogical structure abduction, grounded in cognitive psychology, designed to abduce structures that form an analogy between two systems. In support of this task, we establish a benchmark called SCAR, containing 400 scientific analogies from 13 distinct fields, tailored for evaluating analogical reasoning with structure abduction. The empirical evidence underlines the continued challenges faced by LLMs, including ChatGPT and GPT-4, in mastering this task, signifying the n",
    "path": "papers/23/05/2305.12660.json",
    "total_tokens": 864,
    "translated_title": "表面相似性之下：大型语言模型通过结构推理进行合理的科学类比",
    "translated_abstract": "人类认知中类比推理的重要作用使我们能够通过共享的关系结构将新概念与熟悉的概念联系起来。尽管先前的研究关注于词语类比，但本研究表明，大型语言模型（LLMs）经常忽视构成这些类比的结构，这引发了对词语类比作为类比推理技能（类似于人类认知）的有效性的质疑。为了解决这个问题，我们的论文引入了一种基于认知心理学的类比结构推理任务，旨在推断出连接两个系统之间的类比结构。为了支持这个任务，我们建立了一个名为SCAR的基准，包含来自13个不同领域的400个科学类比，旨在评估利用结构推理的类比推理能力。实证证据强调了LLMs，包括ChatGPT和GPT-4，在掌握这个任务上依然面临的挑战。",
    "tldr": "本论文介绍了一种基于结构推理的类比结构推断任务，旨在解决大型语言模型在进行科学类比时忽视结构的问题。",
    "en_tdlr": "This paper introduces a task of analogical structure abduction, aimed at addressing the issue of large language models overlooking structures in scientific analogies."
}