{
    "title": "Cascaded Cross-Attention Networks for Data-Efficient Whole-Slide Image Classification Using Transformers. (arXiv:2305.06963v1 [cs.CV])",
    "abstract": "Whole-Slide Imaging allows for the capturing and digitization of high-resolution images of histological specimen. An automated analysis of such images using deep learning models is therefore of high demand. The transformer architecture has been proposed as a possible candidate for effectively leveraging the high-resolution information. Here, the whole-slide image is partitioned into smaller image patches and feature tokens are extracted from these image patches. However, while the conventional transformer allows for a simultaneous processing of a large set of input tokens, the computational demand scales quadratically with the number of input tokens and thus quadratically with the number of image patches. To address this problem we propose a novel cascaded cross-attention network (CCAN) based on the cross-attention mechanism that scales linearly with the number of extracted patches. Our experiments demonstrate that this architecture is at least on-par with and even outperforms other at",
    "link": "http://arxiv.org/abs/2305.06963",
    "context": "Title: Cascaded Cross-Attention Networks for Data-Efficient Whole-Slide Image Classification Using Transformers. (arXiv:2305.06963v1 [cs.CV])\nAbstract: Whole-Slide Imaging allows for the capturing and digitization of high-resolution images of histological specimen. An automated analysis of such images using deep learning models is therefore of high demand. The transformer architecture has been proposed as a possible candidate for effectively leveraging the high-resolution information. Here, the whole-slide image is partitioned into smaller image patches and feature tokens are extracted from these image patches. However, while the conventional transformer allows for a simultaneous processing of a large set of input tokens, the computational demand scales quadratically with the number of input tokens and thus quadratically with the number of image patches. To address this problem we propose a novel cascaded cross-attention network (CCAN) based on the cross-attention mechanism that scales linearly with the number of extracted patches. Our experiments demonstrate that this architecture is at least on-par with and even outperforms other at",
    "path": "papers/23/05/2305.06963.json",
    "total_tokens": 888,
    "translated_title": "基于级联交叉关注网络的转换器用于数据有效的整张图像分类",
    "translated_abstract": "整张图像成像技术允许对组织学标本进行高分辨率成像和数字化。深度学习模型对这些图像的自动分析因此需求极高。转换器架构被提出作为有效利用高分辨率信息的可能候选者，把整张图像划分为多个图像块，从这些图像块中提取特征标记。然而，传统转换器允许同时处理大量输入标记，但计算量随着输入标记数和图像块数的增加呈平方级增长。为了解决这个问题，我们提出了一种基于交叉注意力机制的新型级联交叉关注网络（CCAN），其计算复杂度随着提取的图像块数呈线性增长。我们的实验表明，这种架构至少与其他方法相当甚至更好。",
    "tldr": "本论文提出了一种新的级联交叉关注网络（CCAN），以线性复杂度处理大量提取出来的图像块，解决了传统转换器计算复杂度呈平方级增长的问题，该方法用于整张图像分类效果至少与其他方法相当，甚至更好。",
    "en_tdlr": "This paper proposes a novel cascaded cross-attention network (CCAN) which is able to process a large set of extracted image patches with linear complexity, resolving the quadratic computing complexity of conventional transformers. Results demonstrate that the CCAN is at least as effective if not better than traditional methods for whole-slide image classification using deep learning models."
}