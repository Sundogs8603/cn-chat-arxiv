{
    "title": "Neural Markov Jump Processes. (arXiv:2305.19744v1 [cs.LG])",
    "abstract": "Markov jump processes are continuous-time stochastic processes with a wide range of applications in both natural and social sciences. Despite their widespread use, inference in these models is highly non-trivial and typically proceeds via either Monte Carlo or expectation-maximization methods. In this work we introduce an alternative, variational inference algorithm for Markov jump processes which relies on neural ordinary differential equations, and is trainable via back-propagation. Our methodology learns neural, continuous-time representations of the observed data, that are used to approximate the initial distribution and time-dependent transition probability rates of the posterior Markov jump process. The time-independent rates of the prior process are in contrast trained akin to generative adversarial networks. We test our approach on synthetic data sampled from ground-truth Markov jump processes, experimental switching ion channel data and molecular dynamics simulations. Source c",
    "link": "http://arxiv.org/abs/2305.19744",
    "context": "Title: Neural Markov Jump Processes. (arXiv:2305.19744v1 [cs.LG])\nAbstract: Markov jump processes are continuous-time stochastic processes with a wide range of applications in both natural and social sciences. Despite their widespread use, inference in these models is highly non-trivial and typically proceeds via either Monte Carlo or expectation-maximization methods. In this work we introduce an alternative, variational inference algorithm for Markov jump processes which relies on neural ordinary differential equations, and is trainable via back-propagation. Our methodology learns neural, continuous-time representations of the observed data, that are used to approximate the initial distribution and time-dependent transition probability rates of the posterior Markov jump process. The time-independent rates of the prior process are in contrast trained akin to generative adversarial networks. We test our approach on synthetic data sampled from ground-truth Markov jump processes, experimental switching ion channel data and molecular dynamics simulations. Source c",
    "path": "papers/23/05/2305.19744.json",
    "total_tokens": 943,
    "translated_title": "神经马尔可夫跳跃过程",
    "translated_abstract": "马尔可夫跳跃过程是具有广泛应用的连续时间随机过程，被广泛应用于自然和社会科学领域。尽管它们被广泛使用，但这些模型中的推断是非常复杂的，通常需要通过蒙特卡罗或期望最大化方法进行。本文介绍了一种基于神经常微分方程的马尔可夫跳跃过程的变分推断算法，并可通过反向传播进行训练。该方法学习了观测数据的神经连续时间表示，用于近似后验马尔可夫跳跃过程的初始分布和时间相关的转移概率率。相比之下，先验过程的时间无关率则像生成对抗网络一样进行训练。我们在合成数据上测试了我们的方法，这些数据是从真实的马尔可夫跳跃过程、实验性开关离子通道数据和分子动力学模拟中采样得到的。",
    "tldr": "介绍了一种基于神经常微分方程的马尔可夫跳跃过程的变分推断算法，可通过反向传播进行训练，用于近似后验马尔可夫跳跃过程的初始分布和时间相关的转移概率率，同时在先验过程的时间无关率上也有很好的表现。",
    "en_tdlr": "This paper proposes a variational inference algorithm based on neural ordinary differential equations for Markov jump processes, which can be trained via back-propagation. The methodology learns neural continuous-time representations of the observed data, approximating initial distribution and time-dependent transition probability rates of the posterior Markov jump process, while the time-independent rates of the prior process are trained akin to generative adversarial networks. The approach is tested on synthetic data, experimental switching ion channel data, and molecular dynamics simulations."
}