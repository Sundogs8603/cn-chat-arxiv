{
    "title": "Attacking Pre-trained Recommendation. (arXiv:2305.03995v1 [cs.IR])",
    "abstract": "Recently, a series of pioneer studies have shown the potency of pre-trained models in sequential recommendation, illuminating the path of building an omniscient unified pre-trained recommendation model for different downstream recommendation tasks. Despite these advancements, the vulnerabilities of classical recommender systems also exist in pre-trained recommendation in a new form, while the security of pre-trained recommendation model is still unexplored, which may threaten its widely practical applications. In this study, we propose a novel framework for backdoor attacking in pre-trained recommendation. We demonstrate the provider of the pre-trained model can easily insert a backdoor in pre-training, thereby increasing the exposure rates of target items to target user groups. Specifically, we design two novel and effective backdoor attacks: basic replacement and prompt-enhanced, under various recommendation pre-training usage scenarios. Experimental results on real-world datasets sh",
    "link": "http://arxiv.org/abs/2305.03995",
    "context": "Title: Attacking Pre-trained Recommendation. (arXiv:2305.03995v1 [cs.IR])\nAbstract: Recently, a series of pioneer studies have shown the potency of pre-trained models in sequential recommendation, illuminating the path of building an omniscient unified pre-trained recommendation model for different downstream recommendation tasks. Despite these advancements, the vulnerabilities of classical recommender systems also exist in pre-trained recommendation in a new form, while the security of pre-trained recommendation model is still unexplored, which may threaten its widely practical applications. In this study, we propose a novel framework for backdoor attacking in pre-trained recommendation. We demonstrate the provider of the pre-trained model can easily insert a backdoor in pre-training, thereby increasing the exposure rates of target items to target user groups. Specifically, we design two novel and effective backdoor attacks: basic replacement and prompt-enhanced, under various recommendation pre-training usage scenarios. Experimental results on real-world datasets sh",
    "path": "papers/23/05/2305.03995.json",
    "total_tokens": 887,
    "translated_title": "针对预训练推荐模型的攻击",
    "translated_abstract": "最近的一系列研究表明了预训练模型在序列推荐中的有效性，为建立适用于不同下游推荐任务的智能统一预训练推荐模型铺平了道路。尽管取得了这些进展，但是经典推荐系统的漏洞也以一种新形式存在于预训练推荐中，同时预训练推荐模型的安全性仍未被开发，这可能会威胁其广泛的实际应用。在本研究中，我们提出了一种针对预训练推荐的后门攻击新框架。我们证明了预训练模型的提供者可以很容易地在预训练中插入后门，从而增加目标物品面向目标用户群体的曝光率。具体地，我们设计了两种新颖有效的后门攻击：基本替换和提示增强，在各种推荐预训练使用情况下。在实际数据集上的实验结果表明，",
    "tldr": "本文提出了一种新的后门攻击预训练推荐模型的框架，并通过实验证明预训练模型的提供者可以很容易地将后门插入其中。这可能加剧了目标用户群对目标物品的曝光率。",
    "en_tdlr": "This study proposes a new framework for backdoor attacking in pre-trained recommendation models, and demonstrates through experiments that the provider of the pre-trained model can easily insert a backdoor, potentially increasing the exposure rates of target items to target user groups."
}