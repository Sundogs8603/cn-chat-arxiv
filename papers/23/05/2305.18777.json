{
    "title": "Adaptive Conditional Quantile Neural Processes. (arXiv:2305.18777v1 [cs.LG])",
    "abstract": "Neural processes are a family of probabilistic models that inherit the flexibility of neural networks to parameterize stochastic processes. Despite providing well-calibrated predictions, especially in regression problems, and quick adaptation to new tasks, the Gaussian assumption that is commonly used to represent the predictive likelihood fails to capture more complicated distributions such as multimodal ones. To overcome this limitation, we propose Conditional Quantile Neural Processes (CQNPs), a new member of the neural processes family, which exploits the attractive properties of quantile regression in modeling the distributions irrespective of their form. By introducing an extension of quantile regression where the model learns to focus on estimating informative quantiles, we show that the sampling efficiency and prediction accuracy can be further enhanced. Our experiments with real and synthetic datasets demonstrate substantial improvements in predictive performance compared to t",
    "link": "http://arxiv.org/abs/2305.18777",
    "context": "Title: Adaptive Conditional Quantile Neural Processes. (arXiv:2305.18777v1 [cs.LG])\nAbstract: Neural processes are a family of probabilistic models that inherit the flexibility of neural networks to parameterize stochastic processes. Despite providing well-calibrated predictions, especially in regression problems, and quick adaptation to new tasks, the Gaussian assumption that is commonly used to represent the predictive likelihood fails to capture more complicated distributions such as multimodal ones. To overcome this limitation, we propose Conditional Quantile Neural Processes (CQNPs), a new member of the neural processes family, which exploits the attractive properties of quantile regression in modeling the distributions irrespective of their form. By introducing an extension of quantile regression where the model learns to focus on estimating informative quantiles, we show that the sampling efficiency and prediction accuracy can be further enhanced. Our experiments with real and synthetic datasets demonstrate substantial improvements in predictive performance compared to t",
    "path": "papers/23/05/2305.18777.json",
    "total_tokens": 873,
    "translated_abstract": "神经过程是一类借鉴了神经网络的灵活性来参数化随机过程的概率模型。尽管在回归问题中提供了良好的预测，以及快速适应新任务的优点，但通常用于表示预测似然的高斯假设无法捕捉到诸如多峰分布之类的更为复杂的分布。为了克服这一限制，我们提出了条件分位数神经过程(CQNPs)，它是神经过程家族的新成员，利用了分位数回归在建模分布方面的优良特性。通过引入分位数回归的扩展，使模型学习专注于估计有信息量的分位数，我们展示了采样效率和预测精度可以进一步提高。我们在真实和合成数据集上的实验表明，与传统神经过程相比，预测性能得到了显著的提升。",
    "tldr": "本论文提出了条件分位数神经过程(CQNPs)，并通过引入分位数回归的扩展来估计有信息量的分位数，克服了高斯假设对于多峰分布的限制，从而大幅提高了预测性能。"
}