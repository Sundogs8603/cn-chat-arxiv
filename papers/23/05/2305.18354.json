{
    "title": "LLMs and the Abstraction and Reasoning Corpus: Successes, Failures, and the Importance of Object-based Representations. (arXiv:2305.18354v1 [cs.CL])",
    "abstract": "Can a Large Language Model (LLM) solve simple abstract reasoning problems? We explore this broad question through a systematic analysis of GPT on the Abstraction and Reasoning Corpus (ARC), a representative benchmark of abstract reasoning ability from limited examples in which solutions require some \"core knowledge\" of concepts such as objects, goal states, counting, and basic geometry. GPT-4 solves only 13/50 of the most straightforward ARC tasks when using textual encodings for their two-dimensional input-output grids. Our failure analysis reveals that GPT-4's capacity to identify objects and reason about them is significantly influenced by the sequential nature of the text that represents an object within a text encoding of a task. To test this hypothesis, we design a new benchmark, the 1D-ARC, which consists of one-dimensional (array-like) tasks that are more conducive to GPT-based reasoning, and where it indeed performs better than on the (2D) ARC. To alleviate this issue, we prop",
    "link": "http://arxiv.org/abs/2305.18354",
    "context": "Title: LLMs and the Abstraction and Reasoning Corpus: Successes, Failures, and the Importance of Object-based Representations. (arXiv:2305.18354v1 [cs.CL])\nAbstract: Can a Large Language Model (LLM) solve simple abstract reasoning problems? We explore this broad question through a systematic analysis of GPT on the Abstraction and Reasoning Corpus (ARC), a representative benchmark of abstract reasoning ability from limited examples in which solutions require some \"core knowledge\" of concepts such as objects, goal states, counting, and basic geometry. GPT-4 solves only 13/50 of the most straightforward ARC tasks when using textual encodings for their two-dimensional input-output grids. Our failure analysis reveals that GPT-4's capacity to identify objects and reason about them is significantly influenced by the sequential nature of the text that represents an object within a text encoding of a task. To test this hypothesis, we design a new benchmark, the 1D-ARC, which consists of one-dimensional (array-like) tasks that are more conducive to GPT-based reasoning, and where it indeed performs better than on the (2D) ARC. To alleviate this issue, we prop",
    "path": "papers/23/05/2305.18354.json",
    "total_tokens": 1169,
    "translated_title": "LLM和抽象推理语料库：成功、失败与基于对象表示的重要性",
    "translated_abstract": "一个大型语言模型（LLM）能否解决简单的抽象推理问题？我们通过系统地分析GPT在抽象推理语料库（ARC）上的表现来探索这个广泛的问题，这是一个代表性的基准，从有限的例子中要求我们有些关于概念（如对象、目标状态、计数和基本几何）的“核心知识”以解决问题。当使用文本编码对二维输入输出网格的ARC任务进行编码时，GPT-4仅解决了50个最简单的任务中的13个。我们的失败分析显示，GPT-4识别对象并推理它们的能力受到表示任务中对象的文本的顺序性的显著影响。为了验证这个假设，我们设计了一个新的基准，1D-ARC，它由更有利于基于GPT的推理的一维（类似数组）任务组成，在这些任务上，GPT的表现确实比在（2D）ARC上更好。为了减轻这个问题，我们提出了一种新的基于对象的编码方案，它保留了对象之间的基本空间关系并实现了更好的推理。使用这种编码，GPT-4在ARC上的成功率大大提高，达到了45/50。我们的工作强调了使用基于对象的表示方法进行抽象推理任务的重要性，并揭示了LLM基于推理系统的局限性和机遇。",
    "tldr": "本文通过分析GPT模型在抽象推理语料库上的表现，发现GPT在抽象推理任务中存在需要核心概念“核心知识”的限制。通过使用基于对象的表示方法和新的1D-ARC基准，GPT在抽象推理任务中取得了较好的表现。",
    "en_tdlr": "The paper investigates whether large language models (LLMs) can solve simple abstract reasoning problems through a systematic analysis of GPT on the Abstraction and Reasoning Corpus (ARC). The study reveals that GPT has limitations in identifying objects and reasoning about them due to the sequential nature of text encoding. The proposed solution is to use object-based encoding, which leads to significant improvement in GPT's performance in the ARC."
}