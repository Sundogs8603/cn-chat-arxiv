{
    "title": "Adaptive loose optimization for robust question answering. (arXiv:2305.03971v1 [cs.CL])",
    "abstract": "Question answering methods are well-known for leveraging data bias, such as the language prior in visual question answering and the position bias in machine reading comprehension (extractive question answering). Current debiasing methods often come at the cost of significant in-distribution performance to achieve favorable out-of-distribution generalizability, while non-debiasing methods sacrifice a considerable amount of out-of-distribution performance in order to obtain high in-distribution performance. Therefore, it is challenging for them to deal with the complicated changing real-world situations. In this paper, we propose a simple yet effective novel loss function with adaptive loose optimization, which seeks to make the best of both worlds for question answering. Our main technical contribution is to reduce the loss adaptively according to the ratio between the previous and current optimization state on mini-batch training data. This loose optimization can be used to prevent non",
    "link": "http://arxiv.org/abs/2305.03971",
    "context": "Title: Adaptive loose optimization for robust question answering. (arXiv:2305.03971v1 [cs.CL])\nAbstract: Question answering methods are well-known for leveraging data bias, such as the language prior in visual question answering and the position bias in machine reading comprehension (extractive question answering). Current debiasing methods often come at the cost of significant in-distribution performance to achieve favorable out-of-distribution generalizability, while non-debiasing methods sacrifice a considerable amount of out-of-distribution performance in order to obtain high in-distribution performance. Therefore, it is challenging for them to deal with the complicated changing real-world situations. In this paper, we propose a simple yet effective novel loss function with adaptive loose optimization, which seeks to make the best of both worlds for question answering. Our main technical contribution is to reduce the loss adaptively according to the ratio between the previous and current optimization state on mini-batch training data. This loose optimization can be used to prevent non",
    "path": "papers/23/05/2305.03971.json",
    "total_tokens": 951,
    "translated_title": "自适应宽松优化用于强韧问答系统",
    "translated_abstract": "问答方法以利用数据偏差为特点，如视觉问答中的语言先验和机器阅读理解（抽取式问答）中的位置偏差。目前的去偏方法往往以在分布内表现不佳为代价获得有利的分布外泛化能力，而不去偏方法则在获得高分布内表现的同时牺牲了相当数量的分布外表现。因此，它们难以应对复杂变化的现实世界情况。本文提出了一种简单而有效的新型自适应宽松优化损失函数，为问答系统综合两者最佳表现而努力。我们的主要技术贡献是根据小批量训练数据上先前和当前优化状态之间的比率自适应地减少损失。这种宽松优化可以用来防止非凸优化陷入局部最小值，并帮助模型学习更好的表示。实验证明，我们的方法在各种基准测试中与最先进的方法具有竞争性能，同时表现出对对抗性攻击的强韧性。",
    "tldr": "本论文提出了一种简单而有效的自适应宽松优化损失函数，用于为问答系统综合内外分布的最佳表现，并显示了对对抗攻击的强韧性。",
    "en_tdlr": "This paper proposes a simple and effective adaptive loose optimization loss function for question answering to achieve the best performance both in and out of distribution, while exhibiting robustness to adversarial attacks."
}