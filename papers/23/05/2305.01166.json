{
    "title": "Solving Inverse Problems with Score-Based Generative Priors learned from Noisy Data. (arXiv:2305.01166v1 [cs.LG])",
    "abstract": "We present SURE-Score: an approach for learning score-based generative models using training samples corrupted by additive Gaussian noise. When a large training set of clean samples is available, solving inverse problems via score-based (diffusion) generative models trained on the underlying fully-sampled data distribution has recently been shown to outperform end-to-end supervised deep learning. In practice, such a large collection of training data may be prohibitively expensive to acquire in the first place. In this work, we present an approach for approximately learning a score-based generative model of the clean distribution, from noisy training data. We formulate and justify a novel loss function that leverages Stein's unbiased risk estimate to jointly denoise the data and learn the score function via denoising score matching, while using only the noisy samples. We demonstrate the generality of SURE-Score by learning priors and applying posterior sampling to ill-posed inverse prob",
    "link": "http://arxiv.org/abs/2305.01166",
    "context": "Title: Solving Inverse Problems with Score-Based Generative Priors learned from Noisy Data. (arXiv:2305.01166v1 [cs.LG])\nAbstract: We present SURE-Score: an approach for learning score-based generative models using training samples corrupted by additive Gaussian noise. When a large training set of clean samples is available, solving inverse problems via score-based (diffusion) generative models trained on the underlying fully-sampled data distribution has recently been shown to outperform end-to-end supervised deep learning. In practice, such a large collection of training data may be prohibitively expensive to acquire in the first place. In this work, we present an approach for approximately learning a score-based generative model of the clean distribution, from noisy training data. We formulate and justify a novel loss function that leverages Stein's unbiased risk estimate to jointly denoise the data and learn the score function via denoising score matching, while using only the noisy samples. We demonstrate the generality of SURE-Score by learning priors and applying posterior sampling to ill-posed inverse prob",
    "path": "papers/23/05/2305.01166.json",
    "total_tokens": 1021,
    "translated_title": "从带噪声数据中学习基于得分的生成式先验来解决反问题",
    "translated_abstract": "我们提出了SURE-Score：一种利用加性高斯噪声所污染的训练样本来学习得分-based生成模型的方法。当有一个大型干净样本的训练集可用时，最近已经证明，通过在下面的完全采样数据分布上训练得分-based（扩散）生成模型来解决反问题，胜过一步到位的监督式深度学习。在实践中，这样一个庞大的训练数据集可能在一开始获取时是难以负担的。在这项工作中，我们提出了一种方法，从噪声训练数据中大约学习干净分布的基于得分的生成模型。我们制定并证明了一种新颖的损失函数，利用Stein的无偏风险估计来通过除噪得分匹配连续地除去数据和学习得分函数，同时仅使用噪声样本。我们通过学习先验并应用后验采样到图像重建、图像修补和超分辨率等反问题上展示了SURE-Score的普遍性。我们的方法在医学成像、显微镜和摄影等反问题的一系列领域中实现了最先进的结果。",
    "tldr": "本研究提出了一种从带噪声数据中学习基于得分的生成式先验的方法，能够广泛应用于图像重建、图像修补、超分辨率等反问题，实现最先进的结果。",
    "en_tdlr": "This study proposes a method for learning score-based generative priors from noisy data, which can be widely used in inverse problems such as image reconstruction, inpainting, and super-resolution, achieving state-of-the-art results in various fields including medical imaging, microscopy, and photography."
}