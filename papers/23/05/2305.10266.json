{
    "title": "Searching for Needles in a Haystack: On the Role of Incidental Bilingualism in PaLM's Translation Capability. (arXiv:2305.10266v1 [cs.CL])",
    "abstract": "Large, multilingual language models exhibit surprisingly good zero- or few-shot machine translation capabilities, despite having never seen the intentionally-included translation examples provided to typical neural translation systems. We investigate the role of incidental bilingualism -- the unintentional consumption of bilingual signals, including translation examples -- in explaining the translation capabilities of large language models, taking the Pathways Language Model (PaLM) as a case study. We introduce a mixed-method approach to measure and understand incidental bilingualism at scale. We show that PaLM is exposed to over 30 million translation pairs across at least 44 languages. Furthermore, the amount of incidental bilingual content is highly correlated with the amount of monolingual in-language content for non-English languages. We relate incidental bilingual content to zero-shot prompts and show that it can be used to mine new prompts to improve PaLM's out-of-English zero-s",
    "link": "http://arxiv.org/abs/2305.10266",
    "context": "Title: Searching for Needles in a Haystack: On the Role of Incidental Bilingualism in PaLM's Translation Capability. (arXiv:2305.10266v1 [cs.CL])\nAbstract: Large, multilingual language models exhibit surprisingly good zero- or few-shot machine translation capabilities, despite having never seen the intentionally-included translation examples provided to typical neural translation systems. We investigate the role of incidental bilingualism -- the unintentional consumption of bilingual signals, including translation examples -- in explaining the translation capabilities of large language models, taking the Pathways Language Model (PaLM) as a case study. We introduce a mixed-method approach to measure and understand incidental bilingualism at scale. We show that PaLM is exposed to over 30 million translation pairs across at least 44 languages. Furthermore, the amount of incidental bilingual content is highly correlated with the amount of monolingual in-language content for non-English languages. We relate incidental bilingual content to zero-shot prompts and show that it can be used to mine new prompts to improve PaLM's out-of-English zero-s",
    "path": "papers/23/05/2305.10266.json",
    "total_tokens": 904,
    "translated_title": "在大规模多语言语言模型中搜索针的作用：探究意外双语对于PaLM翻译能力的影响",
    "translated_abstract": "尽管从未见过传统神经机器翻译系统提供的有意的翻译样例，大型多语言语言模型展现出令人惊讶的零或少量样例翻译能力。我们调查了意外双语对于大型语言模型翻译能力的解释作用-包括有意提供的翻译样例在内的双语信号的非意外消费，以Pathways语言模型（PaLM）为案例进行研究。我们引入了一种混合方法来衡量和理解规模上的意外双语现象。我们展示了PaLM暴露于至少44种语言中的超过3000万个翻译对。此外，各种非英语语言的意外双语内容量与该语言的单语内语言内容量高度相关。我们将意外双语内容与零-shot提示相关联，并展示它可以被用于挖掘新提示，以提高PaLM的英语以外的零-shot翻译准确度。",
    "tldr": "本文探究了大型语言模型翻译能力中的意外双语现象，证明了PaLM模型利用意外双语内容可以改善零-shot翻译的准确性。",
    "en_tdlr": "This paper investigates the role of incidental bilingualism in the translation capabilities of large scale language models and demonstrates that PaLM model can improve its zero-shot translation accuracy by utilizing bilingual content consumed unintentionally."
}