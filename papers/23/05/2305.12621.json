{
    "title": "DermSynth3D: Synthesis of in-the-wild Annotated Dermatology Images. (arXiv:2305.12621v2 [eess.IV] UPDATED)",
    "abstract": "In recent years, deep learning (DL) has shown great potential in the field of dermatological image analysis. However, existing datasets in this domain have significant limitations, including a small number of image samples, limited disease conditions, insufficient annotations, and non-standardized image acquisitions. To address these shortcomings, we propose a novel framework called DermSynth3D. DermSynth3D blends skin disease patterns onto 3D textured meshes of human subjects using a differentiable renderer and generates 2D images from various camera viewpoints under chosen lighting conditions in diverse background scenes. Our method adheres to top-down rules that constrain the blending and rendering process to create 2D images with skin conditions that mimic in-the-wild acquisitions, ensuring more meaningful results. The framework generates photo-realistic 2D dermoscopy images and the corresponding dense annotations for semantic segmentation of the skin, skin conditions, body parts, ",
    "link": "http://arxiv.org/abs/2305.12621",
    "context": "Title: DermSynth3D: Synthesis of in-the-wild Annotated Dermatology Images. (arXiv:2305.12621v2 [eess.IV] UPDATED)\nAbstract: In recent years, deep learning (DL) has shown great potential in the field of dermatological image analysis. However, existing datasets in this domain have significant limitations, including a small number of image samples, limited disease conditions, insufficient annotations, and non-standardized image acquisitions. To address these shortcomings, we propose a novel framework called DermSynth3D. DermSynth3D blends skin disease patterns onto 3D textured meshes of human subjects using a differentiable renderer and generates 2D images from various camera viewpoints under chosen lighting conditions in diverse background scenes. Our method adheres to top-down rules that constrain the blending and rendering process to create 2D images with skin conditions that mimic in-the-wild acquisitions, ensuring more meaningful results. The framework generates photo-realistic 2D dermoscopy images and the corresponding dense annotations for semantic segmentation of the skin, skin conditions, body parts, ",
    "path": "papers/23/05/2305.12621.json",
    "total_tokens": 991,
    "translated_title": "DermSynth3D：野外注释皮肤科图像的综合",
    "translated_abstract": "近年来，深度学习在皮肤科图像分析领域展现出了巨大的潜力。然而，该领域现有的数据集存在显着限制，包括样本图像数量较少、疾病条件有限、注释不足以及非标准化图像采集。为了解决这些问题，我们提出了一种名为DermSynth3D的新框架。该框架使用可微分渲染器将皮肤病变模式混合到人体的三维纹理网格上，并在各种背景场景下采用不同视角和光照条件生成二维图像。我们的方法遵循自上而下的规则，限制混合和渲染过程，以创建具有野外照片感的皮肤条件的二维图像，确保更有意义的结果。该框架生成逼真的二维皮肤镜像图像，并生成对皮肤、皮肤状况、身体部位和头发区域进行语义分割的对应密集注释。",
    "tldr": "该论文提出了一种名为DermSynth3D的新框架，它使用可微分渲染器将皮肤病变模式混合到人体三维纹理网格上并生成逼真的二维皮肤镜像图像，同时提供对应的密集注释以进行语义分割。",
    "en_tdlr": "The paper proposes a novel framework called DermSynth3D to address the limitations of existing datasets in dermatological image analysis by generating photo-realistic 2D dermoscopy images with corresponding dense annotations for semantic segmentation of the skin, skin conditions, body parts, and hair regions using a differentiable renderer and adhering to top-down blending and rendering rules to ensure images with skin conditions that mimic in-the-wild acquisitions."
}