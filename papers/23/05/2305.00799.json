{
    "title": "How to address monotonicity for model risk management?. (arXiv:2305.00799v1 [cs.LG])",
    "abstract": "In this paper, we study the problem of establishing the accountability and fairness of transparent machine learning models through monotonicity. Although there have been numerous studies on individual monotonicity, pairwise monotonicity is often overlooked in the existing literature. This paper studies transparent neural networks in the presence of three types of monotonicity: individual monotonicity, weak pairwise monotonicity, and strong pairwise monotonicity. As a means of achieving monotonicity while maintaining transparency, we propose the monotonic groves of neural additive models. As a result of empirical examples, we demonstrate that monotonicity is often violated in practice and that monotonic groves of neural additive models are transparent, accountable, and fair.",
    "link": "http://arxiv.org/abs/2305.00799",
    "context": "Title: How to address monotonicity for model risk management?. (arXiv:2305.00799v1 [cs.LG])\nAbstract: In this paper, we study the problem of establishing the accountability and fairness of transparent machine learning models through monotonicity. Although there have been numerous studies on individual monotonicity, pairwise monotonicity is often overlooked in the existing literature. This paper studies transparent neural networks in the presence of three types of monotonicity: individual monotonicity, weak pairwise monotonicity, and strong pairwise monotonicity. As a means of achieving monotonicity while maintaining transparency, we propose the monotonic groves of neural additive models. As a result of empirical examples, we demonstrate that monotonicity is often violated in practice and that monotonic groves of neural additive models are transparent, accountable, and fair.",
    "path": "papers/23/05/2305.00799.json",
    "total_tokens": 792,
    "translated_title": "如何解决模型风险管理中的单调性问题？",
    "translated_abstract": "本文研究通过单调性确立透明机器学习模型的问责和公平性的问题。尽管已有大量研究关注个体单调性，但是现有文献经常忽略了成对单调性。本文研究了透明神经网络在存在三种单调性的情况下：个体单调性、弱成对单调性和强成对单调性。我们提出使用神经加性模型的单调的树丛来实现单调性和透明性的结合。通过实证示例，我们证明单调性通常在实践中被违反，而神经加性模型的单调树丛是透明、有问责性和公平的。",
    "tldr": "本文提出了使用神经加性模型的单调的树丛来实现单调性和透明性的结合，以确立透明机器学习模型的问责和公平性。通过实证示例，证明该方法透明、有问责性和公平，尤其对于避免单调性问题具有优势。",
    "en_tdlr": "This paper proposes the use of monotonic groves of neural additive models to establish accountability and fairness of transparent machine learning models through monotonicity. The method is shown to be transparent, accountable, and fair through empirical examples, with particular advantages in addressing the issue of monotonicity."
}