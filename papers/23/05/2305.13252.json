{
    "title": "\"According to ...\": Prompting Language Models Improves Quoting from Pre-Training Data",
    "abstract": "arXiv:2305.13252v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) may hallucinate and generate fake information, despite pre-training on factual data. Inspired by the journalistic device of \"according to sources\", we propose according-to prompting: directing LLMs to ground responses against previously observed text. To quantify this grounding, we propose a novel evaluation metric (QUIP-Score) that measures the extent to which model-produced answers are directly found in underlying text corpora. We illustrate with experiments on three corpora (Wikipedia, PubMed, and the U.S. legal tax code) that these prompts improve grounding under our metrics, with the additional benefit of often improving end-task performance. Furthermore, prompts that ask the model to decrease grounding (or to ground to other corpora) indeed decrease QUIP-Score, indicating the ability of LLMs to increase or decrease grounded generations on request.",
    "link": "https://arxiv.org/abs/2305.13252",
    "context": "Title: \"According to ...\": Prompting Language Models Improves Quoting from Pre-Training Data\nAbstract: arXiv:2305.13252v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) may hallucinate and generate fake information, despite pre-training on factual data. Inspired by the journalistic device of \"according to sources\", we propose according-to prompting: directing LLMs to ground responses against previously observed text. To quantify this grounding, we propose a novel evaluation metric (QUIP-Score) that measures the extent to which model-produced answers are directly found in underlying text corpora. We illustrate with experiments on three corpora (Wikipedia, PubMed, and the U.S. legal tax code) that these prompts improve grounding under our metrics, with the additional benefit of often improving end-task performance. Furthermore, prompts that ask the model to decrease grounding (or to ground to other corpora) indeed decrease QUIP-Score, indicating the ability of LLMs to increase or decrease grounded generations on request.",
    "path": "papers/23/05/2305.13252.json",
    "total_tokens": 893,
    "translated_title": "根据...：促使语言模型提高引用的能力",
    "translated_abstract": "大型语言模型（LLMs）可能会产生幻觉并生成虚假信息，尽管它们事先在事实数据上进行了训练。受“据悉”的新闻设备启发，我们提出了“根据”提示：指导LLMs将响应与先前观察到的文本相联系。为了量化这种基础性，我们提出了一种新颖的评估指标（QUIP-Score），用于衡量模型生成的答案在基础文本语料库中直接找到的程度。我们通过对三个语料库（维基百科、PubMed和美国法律税法典）进行实验来说明这些提示根据我们的度量标准改善了基础性，而且通常还提高了最终任务性能。此外，要求模型减少基础性（或者根据其他语料库）的提示确实降低了QUIP-Score，表明LLMs有能力根据要求增加或减少基础性生成。",
    "tldr": "提出了“根据”提示方法，通过引导大型语言模型在响应中参考先前观察到的文本来改进引用，并提出了一种新的评估指标（QUIP-Score）来度量模型生成的答案在文本语料库中的直接发现程度。",
    "en_tdlr": "Introducing the \"according-to\" prompting method, which improves quoting by directing large language models to ground responses against previously observed text, along with unveiling a novel evaluation metric (QUIP-Score) to measure the extent of finding model-produced answers directly in text corpora."
}