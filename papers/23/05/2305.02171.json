{
    "title": "Continual Reasoning: Non-Monotonic Reasoning in Neurosymbolic AI using Continual Learning. (arXiv:2305.02171v1 [cs.AI])",
    "abstract": "Despite the extensive investment and impressive recent progress at reasoning by similarity, deep learning continues to struggle with more complex forms of reasoning such as non-monotonic and commonsense reasoning. Non-monotonicity is a property of non-classical reasoning typically seen in commonsense reasoning, whereby a reasoning system is allowed (differently from classical logic) to jump to conclusions which may be retracted later, when new information becomes available. Neural-symbolic systems such as Logic Tensor Networks (LTN) have been shown to be effective at enabling deep neural networks to achieve reasoning capabilities. In this paper, we show that by combining a neural-symbolic system with methods from continual learning, LTN can obtain a higher level of accuracy when addressing non-monotonic reasoning tasks. Continual learning is added to LTNs by adopting a curriculum of learning from knowledge and data with recall. We call this process Continual Reasoning, a new methodolog",
    "link": "http://arxiv.org/abs/2305.02171",
    "context": "Title: Continual Reasoning: Non-Monotonic Reasoning in Neurosymbolic AI using Continual Learning. (arXiv:2305.02171v1 [cs.AI])\nAbstract: Despite the extensive investment and impressive recent progress at reasoning by similarity, deep learning continues to struggle with more complex forms of reasoning such as non-monotonic and commonsense reasoning. Non-monotonicity is a property of non-classical reasoning typically seen in commonsense reasoning, whereby a reasoning system is allowed (differently from classical logic) to jump to conclusions which may be retracted later, when new information becomes available. Neural-symbolic systems such as Logic Tensor Networks (LTN) have been shown to be effective at enabling deep neural networks to achieve reasoning capabilities. In this paper, we show that by combining a neural-symbolic system with methods from continual learning, LTN can obtain a higher level of accuracy when addressing non-monotonic reasoning tasks. Continual learning is added to LTNs by adopting a curriculum of learning from knowledge and data with recall. We call this process Continual Reasoning, a new methodolog",
    "path": "papers/23/05/2305.02171.json",
    "total_tokens": 876,
    "translated_title": "持续推理：在神经符号 AI 中使用持续学习进行非单调推理",
    "translated_abstract": "尽管已经在相似性推理方面进行了广泛投资和令人瞩目的最近进展，但深度学习在更复杂的推理形式，如非单调和常识推理方面仍然存在困难。非单调是非经典推理的一个特性，通常在常识推理中看到，推理系统允许（与古典逻辑不同）作出可能稍后被撤回的结论，当有新信息可用时。神经符号系统（如逻辑张量网络）已被证明能够有效地使深度神经网络具有推理能力。在本文中，我们展示了通过将神经符号系统与持续学习方法相结合，LTN在处理非单调推理任务时可以获得更高水平的准确性。我们通过采用从知识和数据中学习和回忆的学习课程将持续学习加入到LTN中。我们称这个过程为“持续推理”，这是一种新的方法论。",
    "tldr": "本文提出了一种持续推理的新方法，通过将神经符号系统与持续学习相结合，可以在处理非单调推理任务时获得更高的准确性。",
    "en_tdlr": "This paper proposes a new method of continual reasoning, which combines neural-symbolic systems with continual learning to achieve higher accuracy in non-monotonic reasoning tasks."
}