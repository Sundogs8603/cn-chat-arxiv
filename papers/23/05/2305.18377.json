{
    "title": "BadLabel: A Robust Perspective on Evaluating and Enhancing Label-noise Learning. (arXiv:2305.18377v1 [cs.LG])",
    "abstract": "Label-noise learning (LNL) aims to increase the model's generalization given training data with noisy labels. To facilitate practical LNL algorithms, researchers have proposed different label noise types, ranging from class-conditional to instance-dependent noises. In this paper, we introduce a novel label noise type called BadLabel, which can significantly degrade the performance of existing LNL algorithms by a large margin. BadLabel is crafted based on the label-flipping attack against standard classification, where specific samples are selected and their labels are flipped to other labels so that the loss values of clean and noisy labels become indistinguishable. To address the challenge posed by BadLabel, we further propose a robust LNL method that perturbs the labels in an adversarial manner at each epoch to make the loss values of clean and noisy labels again distinguishable. Once we select a small set of (mostly) clean labeled data, we can apply the techniques of semi-supervised",
    "link": "http://arxiv.org/abs/2305.18377",
    "context": "Title: BadLabel: A Robust Perspective on Evaluating and Enhancing Label-noise Learning. (arXiv:2305.18377v1 [cs.LG])\nAbstract: Label-noise learning (LNL) aims to increase the model's generalization given training data with noisy labels. To facilitate practical LNL algorithms, researchers have proposed different label noise types, ranging from class-conditional to instance-dependent noises. In this paper, we introduce a novel label noise type called BadLabel, which can significantly degrade the performance of existing LNL algorithms by a large margin. BadLabel is crafted based on the label-flipping attack against standard classification, where specific samples are selected and their labels are flipped to other labels so that the loss values of clean and noisy labels become indistinguishable. To address the challenge posed by BadLabel, we further propose a robust LNL method that perturbs the labels in an adversarial manner at each epoch to make the loss values of clean and noisy labels again distinguishable. Once we select a small set of (mostly) clean labeled data, we can apply the techniques of semi-supervised",
    "path": "papers/23/05/2305.18377.json",
    "total_tokens": 1198,
    "translated_title": "BadLabel: 评估与增强标签噪声学习的鲁棒性视角",
    "translated_abstract": "标签噪声学习旨在提高模型对带有噪声标签的训练数据的泛化能力。为了推进实用的标签噪声学习算法，研究人员提出了不同的标签噪声类型，从条件类噪声到实例依赖噪声不等。本文介绍了一种新的标签噪声类型BadLabel，可以通过标签翻转攻击显著降低现有LNL算法的性能。BadLabel基于标准分类的标签翻转攻击进行制作，选择特定样本并将其标签翻转为其他标签，使得干净标签和噪声标签的损失值变得无法区分。为了解决BadLabel带来的挑战，我们进一步提出了一种鲁棒的LNL方法，每个epoch对标签进行敌对扰动，使干净标签和噪声标签的损失值再次可区分。一旦选择了一小部分（大多数）干净标记数据，我们可以将半监督翻译技术应用到LNL中。我们在合成和真实数据集上评估了BadLabel类型和提出的鲁棒LNL方法。实验表明，在六个数据集上，BadLabel可以将七个现有LNL算法的性能降低高达60％。此外，我们提出的方法在合成和真实数据集上均表现出最先进的性能，比六个数据集上的七个现有LNL算法性能提高多达17％。",
    "tldr": "本文介绍了一种新的标签噪声类型BadLabel，它通过标签翻转攻击显著降低现有标签噪声学习（LNL）算法性能，因此提出了一种鲁棒的LNL方法，表现出在六个数据集上最先进的性能。",
    "en_tdlr": "This paper proposes a new label noise type called BadLabel, which significantly reduces the performance of existing Label-noise learning (LNL) algorithms by a large margin using the label-flipping attack. To address this challenge, a robust LNL method is proposed which achieves state-of-the-art performance on six datasets."
}