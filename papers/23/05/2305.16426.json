{
    "title": "Not wacky vs. definitely wacky: A study of scalar adverbs in pretrained language models. (arXiv:2305.16426v1 [cs.CL])",
    "abstract": "Vector space models of word meaning all share the assumption that words occurring in similar contexts have similar meanings. In such models, words that are similar in their topical associations but differ in their logical force tend to emerge as semantically close, creating well-known challenges for NLP applications that involve logical reasoning. Modern pretrained language models, such as BERT, RoBERTa and GPT-3 hold the promise of performing better on logical tasks than classic static word embeddings. However, reports are mixed about their success. In the current paper, we advance this discussion through a systematic study of scalar adverbs, an under-explored class of words with strong logical force. Using three different tasks, involving both naturalistic social media data and constructed examples, we investigate the extent to which BERT, RoBERTa, GPT-2 and GPT-3 exhibit general, human-like, knowledge of these common words. We ask: 1) Do the models distinguish amongst the three sema",
    "link": "http://arxiv.org/abs/2305.16426",
    "context": "Title: Not wacky vs. definitely wacky: A study of scalar adverbs in pretrained language models. (arXiv:2305.16426v1 [cs.CL])\nAbstract: Vector space models of word meaning all share the assumption that words occurring in similar contexts have similar meanings. In such models, words that are similar in their topical associations but differ in their logical force tend to emerge as semantically close, creating well-known challenges for NLP applications that involve logical reasoning. Modern pretrained language models, such as BERT, RoBERTa and GPT-3 hold the promise of performing better on logical tasks than classic static word embeddings. However, reports are mixed about their success. In the current paper, we advance this discussion through a systematic study of scalar adverbs, an under-explored class of words with strong logical force. Using three different tasks, involving both naturalistic social media data and constructed examples, we investigate the extent to which BERT, RoBERTa, GPT-2 and GPT-3 exhibit general, human-like, knowledge of these common words. We ask: 1) Do the models distinguish amongst the three sema",
    "path": "papers/23/05/2305.16426.json",
    "total_tokens": 948,
    "translated_title": "预训练语言模型中的“绝对”与“相对”副词研究",
    "translated_abstract": "词义向量空间模型假设出现在相似语境中的词具有相似的含义。这些模型中，类似于主题关联但在逻辑力度上不同的词往往被视为语义上相似，这对涉及逻辑推理的NLP应用造成了普遍挑战。关于现代预训练语言模型（如BERT、RoBERTa和GPT-3）在逻辑任务上表现优异的报告存在混杂的情况。本文通过系统研究标量副词，这是一类具有强烈逻辑力度的词汇，推进了这一讨论。通过使用三项不同的任务（包括自然的社交媒体数据和构造的示例），我们调查了BERT、RoBERTa、GPT-2和GPT-3在这些常见词语方面是否展现出一般的、类人的知识。我们问：1）这些模型能否区分这三个语义类型中的差异？",
    "tldr": "本文通过研究标量副词，探究了预训练语言模型中“绝对”与“相对”词的表现，在涉及逻辑推理的NLP应用中面临挑战。"
}