{
    "title": "Do LLMs Understand User Preferences? Evaluating LLMs On User Rating Prediction. (arXiv:2305.06474v1 [cs.IR])",
    "abstract": "Large Language Models (LLMs) have demonstrated exceptional capabilities in generalizing to new tasks in a zero-shot or few-shot manner. However, the extent to which LLMs can comprehend user preferences based on their previous behavior remains an emerging and still unclear research question. Traditionally, Collaborative Filtering (CF) has been the most effective method for these tasks, predominantly relying on the extensive volume of rating data. In contrast, LLMs typically demand considerably less data while maintaining an exhaustive world knowledge about each item, such as movies or products. In this paper, we conduct a thorough examination of both CF and LLMs within the classic task of user rating prediction, which involves predicting a user's rating for a candidate item based on their past ratings. We investigate various LLMs in different sizes, ranging from 250M to 540B parameters and evaluate their performance in zero-shot, few-shot, and fine-tuning scenarios. We conduct comprehen",
    "link": "http://arxiv.org/abs/2305.06474",
    "context": "Title: Do LLMs Understand User Preferences? Evaluating LLMs On User Rating Prediction. (arXiv:2305.06474v1 [cs.IR])\nAbstract: Large Language Models (LLMs) have demonstrated exceptional capabilities in generalizing to new tasks in a zero-shot or few-shot manner. However, the extent to which LLMs can comprehend user preferences based on their previous behavior remains an emerging and still unclear research question. Traditionally, Collaborative Filtering (CF) has been the most effective method for these tasks, predominantly relying on the extensive volume of rating data. In contrast, LLMs typically demand considerably less data while maintaining an exhaustive world knowledge about each item, such as movies or products. In this paper, we conduct a thorough examination of both CF and LLMs within the classic task of user rating prediction, which involves predicting a user's rating for a candidate item based on their past ratings. We investigate various LLMs in different sizes, ranging from 250M to 540B parameters and evaluate their performance in zero-shot, few-shot, and fine-tuning scenarios. We conduct comprehen",
    "path": "papers/23/05/2305.06474.json",
    "total_tokens": 907,
    "translated_title": "LLM是否能理解用户偏好？在用户评分预测任务中对LLM进行评估。",
    "translated_abstract": "大型语言模型(LLMs)在零样本或少样本情况下展现出了杰出的泛化能力。然而，LLMs在基于用户以前的行为推断用户偏好方面能力的程度还是一个尚不清楚的问题。传统上，协同过滤(CF)是这些任务中最有效的方法，主要依赖于大量的评分数据。相比之下，LLMs通常需要更少的数据，同时又保持了每个项目(如电影或产品)的详尽的世界知识。在本文中，我们对用户评分预测这一经典任务中的CF和LLMs进行了全面的比较。这一任务涉及基于用户过去的评分预测候选项目的评分。我们研究了不同大小的LLMs，从250M到540B个参数，并评估了它们在零样本、少样本和微调场景下的性能。",
    "tldr": "本文研究了大型语言模型（LLMs）在用户评分预测任务中的表现，与传统的协同过滤方法进行对比。结果发现LLMs能够在较少数据的情况下保持优秀的性能，并且在零样本和少样本情况下表现很好。",
    "en_tdlr": "This paper examines the performance of Large Language Models (LLMs) in the task of user rating prediction, and compares them with traditional Collaborative Filtering (CF) methods. The results show that LLMs can maintain excellent performance with less data, and perform well in zero-shot and few-shot scenarios."
}