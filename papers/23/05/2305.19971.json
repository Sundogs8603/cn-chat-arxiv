{
    "title": "Federated Learning in the Presence of Adversarial Client Unavailability",
    "abstract": "arXiv:2305.19971v2 Announce Type: replace  Abstract: Federated learning is a decentralized machine learning framework that enables collaborative model training without revealing raw data. Due to the diverse hardware and software limitations, a client may not always be available for the computation requests from the parameter server. An emerging line of research is devoted to tackling arbitrary client unavailability. However, existing work still imposes structural assumptions on the unavailability patterns, impeding their applicability in challenging scenarios wherein the unavailability patterns are beyond the control of the parameter server. Moreover, in harsh environments like battlefields, adversaries can selectively and adaptively silence specific clients. In this paper, we relax the structural assumptions and consider adversarial client unavailability. To quantify the degrees of client unavailability, we use the notion of $\\epsilon$-adversary dropout fraction. We show that simple v",
    "link": "https://arxiv.org/abs/2305.19971",
    "context": "Title: Federated Learning in the Presence of Adversarial Client Unavailability\nAbstract: arXiv:2305.19971v2 Announce Type: replace  Abstract: Federated learning is a decentralized machine learning framework that enables collaborative model training without revealing raw data. Due to the diverse hardware and software limitations, a client may not always be available for the computation requests from the parameter server. An emerging line of research is devoted to tackling arbitrary client unavailability. However, existing work still imposes structural assumptions on the unavailability patterns, impeding their applicability in challenging scenarios wherein the unavailability patterns are beyond the control of the parameter server. Moreover, in harsh environments like battlefields, adversaries can selectively and adaptively silence specific clients. In this paper, we relax the structural assumptions and consider adversarial client unavailability. To quantify the degrees of client unavailability, we use the notion of $\\epsilon$-adversary dropout fraction. We show that simple v",
    "path": "papers/23/05/2305.19971.json",
    "total_tokens": 804,
    "translated_title": "在存在恶意客户不可用的情况下的联邦学习",
    "translated_abstract": "联邦学习是一种分散式机器学习框架，可以在不泄露原始数据的情况下进行协作模型训练。由于各种硬件和软件限制，客户端可能并不总是可以响应参数服务器的计算请求。新兴的研究方向致力于解决任意客户端不可用问题。然而，现有工作仍对不可用模式施加结构性假设，限制了它们在不受参数服务器控制的具有挑战性情景中的适用性。此外，在像战场这样恶劣的环境中，对手可以选择性地和自适应地使特定客户端沉默。在本文中，我们放宽了结构性假设，并考虑了恶意客户端不可用性。为了量化客户端不可用的程度，我们使用了$\\epsilon$-对手丢包分数的概念。",
    "tldr": "放宽了结构性假设，研究了恶意客户端不可用的情况，引入了$\\epsilon$-对手丢包分数的概念。",
    "en_tdlr": "This paper relaxes structural assumptions, studies adversarial client unavailability, and introduces the concept of $\\epsilon$-adversary dropout fraction."
}