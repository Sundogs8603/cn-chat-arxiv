{
    "title": "Fair Differentially Private Federated Learning Framework. (arXiv:2305.13878v1 [cs.LG])",
    "abstract": "Federated learning (FL) is a distributed machine learning strategy that enables participants to collaborate and train a shared model without sharing their individual datasets. Privacy and fairness are crucial considerations in FL. While FL promotes privacy by minimizing the amount of user data stored on central servers, it still poses privacy risks that need to be addressed. Industry standards such as differential privacy, secure multi-party computation, homomorphic encryption, and secure aggregation protocols are followed to ensure privacy in FL. Fairness is also a critical issue in FL, as models can inherit biases present in local datasets, leading to unfair predictions. Balancing privacy and fairness in FL is a challenge, as privacy requires protecting user data while fairness requires representative training data. This paper presents a \"Fair Differentially Private Federated Learning Framework\" that addresses the challenges of generating a fair global model without validation data a",
    "link": "http://arxiv.org/abs/2305.13878",
    "context": "Title: Fair Differentially Private Federated Learning Framework. (arXiv:2305.13878v1 [cs.LG])\nAbstract: Federated learning (FL) is a distributed machine learning strategy that enables participants to collaborate and train a shared model without sharing their individual datasets. Privacy and fairness are crucial considerations in FL. While FL promotes privacy by minimizing the amount of user data stored on central servers, it still poses privacy risks that need to be addressed. Industry standards such as differential privacy, secure multi-party computation, homomorphic encryption, and secure aggregation protocols are followed to ensure privacy in FL. Fairness is also a critical issue in FL, as models can inherit biases present in local datasets, leading to unfair predictions. Balancing privacy and fairness in FL is a challenge, as privacy requires protecting user data while fairness requires representative training data. This paper presents a \"Fair Differentially Private Federated Learning Framework\" that addresses the challenges of generating a fair global model without validation data a",
    "path": "papers/23/05/2305.13878.json",
    "total_tokens": 1027,
    "translated_title": "《公平差分隐私联邦学习框架》",
    "translated_abstract": "联邦学习（FL）是一种分布式机器学习策略，使参与者能够在不共享个人数据集的情况下协作并训练共享模型。在FL中，隐私性和公平性至关重要。尽管FL通过最小化储存在中央服务器上的用户数据量来促进隐私保护，但仍存在需要解决的隐私风险。为了确保FL的隐私性，需要遵循差分隐私、安全多方计算、同态加密和安全聚合协议等行业标准。FL中的公平性也是一个关键问题，因为模型可能会继承局部数据集中存在的偏见，导致不公平的预测。平衡隐私性和公平性是一项挑战，因为隐私性要求保护用户数据，而公平性需要具有代表性的训练数据。本文提出了一个“公平差分隐私联邦学习框架”，解决了在不使用验证数据的情况下生成公平全局模型和保护用户隐私的挑战。该框架将公平性约束条件纳入差分隐私优化器，确保最终的全局模型没有偏差。实验结果表明，所提出的框架在确保隐私和公平性的同时，实现了与最先进的FL方法相当的性能。",
    "tldr": "本文提出了一个公平差分隐私联邦学习框架，通过将公平性约束条件纳入差分隐私优化器，实现了生成公平全局模型和保护用户隐私的目的。",
    "en_tdlr": "A Fair Differentially Private Federated Learning Framework is proposed, which incorporates fairness constraints into the differential privacy optimizer, achieving the goals of generating a fair global model and protecting user privacy."
}