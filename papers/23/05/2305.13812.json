{
    "title": "Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for Improved Vision-Language Compositionality. (arXiv:2305.13812v1 [cs.CL])",
    "abstract": "Contrastively trained vision-language models have achieved remarkable progress in vision and language representation learning, leading to state-of-the-art models for various downstream multimodal tasks. However, recent research has highlighted severe limitations of these models in their ability to perform compositional reasoning over objects, attributes, and relations. Scene graphs have emerged as an effective way to understand images compositionally. These are graph-structured semantic representations of images that contain objects, their attributes, and relations with other objects in a scene. In this work, we consider the scene graph parsed from text as a proxy for the image scene graph and propose a graph decomposition and augmentation framework along with a coarse-to-fine contrastive learning objective between images and text that aligns sentences of various complexities to the same image. Along with this, we propose novel negative mining techniques in the scene graph space for im",
    "link": "http://arxiv.org/abs/2305.13812",
    "context": "Title: Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for Improved Vision-Language Compositionality. (arXiv:2305.13812v1 [cs.CL])\nAbstract: Contrastively trained vision-language models have achieved remarkable progress in vision and language representation learning, leading to state-of-the-art models for various downstream multimodal tasks. However, recent research has highlighted severe limitations of these models in their ability to perform compositional reasoning over objects, attributes, and relations. Scene graphs have emerged as an effective way to understand images compositionally. These are graph-structured semantic representations of images that contain objects, their attributes, and relations with other objects in a scene. In this work, we consider the scene graph parsed from text as a proxy for the image scene graph and propose a graph decomposition and augmentation framework along with a coarse-to-fine contrastive learning objective between images and text that aligns sentences of various complexities to the same image. Along with this, we propose novel negative mining techniques in the scene graph space for im",
    "path": "papers/23/05/2305.13812.json",
    "total_tokens": 1096,
    "translated_title": "从图像-文本-图谱空间中进行粗到细的对比学习，提高视觉语言组合能力",
    "translated_abstract": "对比学习视觉语言模型已经在视觉和语言表示学习方面取得了显著进展，从而为各种下游多模态任务提供了最先进的模型。但是，最近的研究凸显了这些模型在对象、属性和关系的组成推理能力方面的严重限制。场景图已经成为一种理解图像组成的有效方式。这些是图像的图形结构化语义表示，包括场景中的对象、它们的属性和与场景中其他对象的关系。在本文中，我们将从文本中解析出的场景图视为图像场景图的代理，并提出了一种图分解和增强框架，以及从简单到复杂的对比学习目标，将各种复杂度的句子对齐到同一幅图像上。同时，我们还在场景图空间提出了新的负样本挖掘技术，用于改善对比学习。在三个视觉语言任务上的实验表明，我们的方法优于强大的视觉语言基线，特别是在对象、属性和关系的组成推理方面。",
    "tldr": "本研究提出了一种基于场景图的对比学习框架，通过将从文本中解析出的场景图视为图像场景图的代理，并对图进行分解和增强，从简单到复杂的对比学习以将各种复杂度的句子对齐到同一幅图像上，同时在场景图空间中提出了新的负样本挖掘技术，以改善视觉语言组合能力。"
}