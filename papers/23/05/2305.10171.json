{
    "title": "Goal-Conditioned Supervised Learning with Sub-Goal Prediction. (arXiv:2305.10171v1 [cs.LG])",
    "abstract": "Recently, a simple yet effective algorithm -- goal-conditioned supervised-learning (GCSL) -- was proposed to tackle goal-conditioned reinforcement-learning. GCSL is based on the principle of hindsight learning: by observing states visited in previously executed trajectories and treating them as attained goals, GCSL learns the corresponding actions via supervised learning. However, GCSL only learns a goal-conditioned policy, discarding other information in the process. Our insight is that the same hindsight principle can be used to learn to predict goal-conditioned sub-goals from the same trajectory. Based on this idea, we propose Trajectory Iterative Learner (TraIL), an extension of GCSL that further exploits the information in a trajectory, and uses it for learning to predict both actions and sub-goals. We investigate the settings in which TraIL can make better use of the data, and discover that for several popular problem settings, replacing real goals in GCSL with predicted TraIL su",
    "link": "http://arxiv.org/abs/2305.10171",
    "context": "Title: Goal-Conditioned Supervised Learning with Sub-Goal Prediction. (arXiv:2305.10171v1 [cs.LG])\nAbstract: Recently, a simple yet effective algorithm -- goal-conditioned supervised-learning (GCSL) -- was proposed to tackle goal-conditioned reinforcement-learning. GCSL is based on the principle of hindsight learning: by observing states visited in previously executed trajectories and treating them as attained goals, GCSL learns the corresponding actions via supervised learning. However, GCSL only learns a goal-conditioned policy, discarding other information in the process. Our insight is that the same hindsight principle can be used to learn to predict goal-conditioned sub-goals from the same trajectory. Based on this idea, we propose Trajectory Iterative Learner (TraIL), an extension of GCSL that further exploits the information in a trajectory, and uses it for learning to predict both actions and sub-goals. We investigate the settings in which TraIL can make better use of the data, and discover that for several popular problem settings, replacing real goals in GCSL with predicted TraIL su",
    "path": "papers/23/05/2305.10171.json",
    "total_tokens": 876,
    "translated_title": "带子目标预测的目标条件监督学习",
    "translated_abstract": "最近，提出了一种简单而有效的算法——基于目标条件的监督学习(GCSL)，以处理目标条件的强化学习。GCSL基于事后学习原则：通过观察先前执行的轨迹中访问的状态并将其视为达到的目标，GCSL通过监督学习学习相应的操作。然而，GCSL仅学习目标条件的策略，在此过程中丢弃其他信息。我们的洞察力是，同样的事后学习原则可用于从同一轨迹学习预测目标条件的子目标。基于这个想法，我们提出了Trajectory Iterative Learner(TraIL)，这是GCSL的扩展，进一步利用轨迹中的信息，并用于学习预测动作和子目标。我们研究了TraIL可以更好地利用数据的设置，并发现对于几个流行的问题设置，将GCSL中的真实目标替换为TraIL子目标可以显著提高性能。",
    "tldr": "本文提出了一种扩展GCSL算法的方法， TraIL利用轨迹中的信息预测子目标，以显著提高性能。",
    "en_tdlr": "The paper proposes Trajectory Iterative Learner(TraIL) to extend GCSL, which predicts sub-goals using information in trajectories via hindsight learning, and significantly improves the performance over GCSL in popular problem settings."
}