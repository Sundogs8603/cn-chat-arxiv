{
    "title": "Self-Checker: Plug-and-Play Modules for Fact-Checking with Large Language Models. (arXiv:2305.14623v1 [cs.CL])",
    "abstract": "Fact-checking is an essential task in NLP that is commonly utilized for validating the factual accuracy of claims. Prior work has mainly focused on fine-tuning pre-trained languages models on specific datasets, which can be computationally intensive and time-consuming. With the rapid development of large language models (LLMs), such as ChatGPT and GPT-3, researchers are now exploring their in-context learning capabilities for a wide range of tasks. In this paper, we aim to assess the capacity of LLMs for fact-checking by introducing Self-Checker, a framework comprising a set of plug-and-play modules that facilitate fact-checking by purely prompting LLMs in an almost zero-shot setting. This framework provides a fast and efficient way to construct fact-checking systems in low-resource environments. Empirical results demonstrate the potential of Self-Checker in utilizing LLMs for fact-checking. However, there is still significant room for improvement compared to SOTA fine-tuned models, wh",
    "link": "http://arxiv.org/abs/2305.14623",
    "context": "Title: Self-Checker: Plug-and-Play Modules for Fact-Checking with Large Language Models. (arXiv:2305.14623v1 [cs.CL])\nAbstract: Fact-checking is an essential task in NLP that is commonly utilized for validating the factual accuracy of claims. Prior work has mainly focused on fine-tuning pre-trained languages models on specific datasets, which can be computationally intensive and time-consuming. With the rapid development of large language models (LLMs), such as ChatGPT and GPT-3, researchers are now exploring their in-context learning capabilities for a wide range of tasks. In this paper, we aim to assess the capacity of LLMs for fact-checking by introducing Self-Checker, a framework comprising a set of plug-and-play modules that facilitate fact-checking by purely prompting LLMs in an almost zero-shot setting. This framework provides a fast and efficient way to construct fact-checking systems in low-resource environments. Empirical results demonstrate the potential of Self-Checker in utilizing LLMs for fact-checking. However, there is still significant room for improvement compared to SOTA fine-tuned models, wh",
    "path": "papers/23/05/2305.14623.json",
    "total_tokens": 945,
    "translated_title": "Self-Checker：用于基于大语言模型事实检查的即插即用模块",
    "translated_abstract": "事实检查是NLP中的一个重要任务，通常用于验证主张的事实准确性。以前的工作主要集中在对特定数据集进行预先训练的语言模型微调上，这可能需要大量的计算资源和时间。随着像ChatGPT和GPT-3这样的大型语言模型的快速发展，研究人员现在正在探索它们的上下文学习能力以执行各种任务。本文介绍了Self-Checker，这是一个框架，包括一组即插即用的模块，通过在几乎零次启动的情况下仅提示LLMs，从而便于对事实进行检查。该框架提供了在资源有限的环境中构建事实检查系统的快速高效方法。实证结果表明Self-Checker在利用LLMs进行事实检查方面具有潜力。然而，与SOTA微调模型相比仍有很大的改进空间，这表明需要进一步的研究和开发。",
    "tldr": "本文介绍了Self-Checker框架，它由即插即用的模块组成，能够在几乎零次启动的情况下利用大型语言模型进行快速高效的事实检查，这对于在资源有限的环境下构建事实检查系统非常有用。",
    "en_tdlr": "This paper introduces the Self-Checker framework, which consists of plug-and-play modules that enable fast and efficient fact-checking by prompting large language models in an almost zero-shot setting. This is useful for constructing fact-checking systems in low-resource environments."
}