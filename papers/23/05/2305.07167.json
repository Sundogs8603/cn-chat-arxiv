{
    "title": "OneCAD: One Classifier for All image Datasets using multimodal learning. (arXiv:2305.07167v1 [cs.CV])",
    "abstract": "Vision-Transformers (ViTs) and Convolutional neural networks (CNNs) are widely used Deep Neural Networks (DNNs) for classification task. These model architectures are dependent on the number of classes in the dataset it was trained on. Any change in number of classes leads to change (partial or full) in the model's architecture. This work addresses the question: Is it possible to create a number-of-class-agnostic model architecture?. This allows model's architecture to be independent of the dataset it is trained on. This work highlights the issues with the current architectures (ViTs and CNNs). Also, proposes a training and inference framework OneCAD (One Classifier for All image Datasets) to achieve close-to number-of-class-agnostic transformer model. To best of our knowledge this is the first work to use Mask-Image-Modeling (MIM) with multimodal learning for classification task to create a DNN model architecture agnostic to the number of classes. Preliminary results are shown on natu",
    "link": "http://arxiv.org/abs/2305.07167",
    "context": "Title: OneCAD: One Classifier for All image Datasets using multimodal learning. (arXiv:2305.07167v1 [cs.CV])\nAbstract: Vision-Transformers (ViTs) and Convolutional neural networks (CNNs) are widely used Deep Neural Networks (DNNs) for classification task. These model architectures are dependent on the number of classes in the dataset it was trained on. Any change in number of classes leads to change (partial or full) in the model's architecture. This work addresses the question: Is it possible to create a number-of-class-agnostic model architecture?. This allows model's architecture to be independent of the dataset it is trained on. This work highlights the issues with the current architectures (ViTs and CNNs). Also, proposes a training and inference framework OneCAD (One Classifier for All image Datasets) to achieve close-to number-of-class-agnostic transformer model. To best of our knowledge this is the first work to use Mask-Image-Modeling (MIM) with multimodal learning for classification task to create a DNN model architecture agnostic to the number of classes. Preliminary results are shown on natu",
    "path": "papers/23/05/2305.07167.json",
    "total_tokens": 945,
    "translated_title": "OneCAD: 使用多模态学习的单分类器适用于所有图像数据集",
    "translated_abstract": "视觉变换器(ViTs)和卷积神经网络(CNNs)是广泛使用的用于分类任务的深度神经网络(DNNs)。这些模型架构依赖于它所训练的数据集中类别数的数量。类别数的任何改变都会导致模型架构的改变(部分或全部)。本文探讨了一个问题：是否可能创建一个与类别数无关的模型架构？这样可以使模型架构与其所训练的数据集无关。本文强调了当前架构(ViTs和CNNs)存在的问题。同时，提出了一个训练和推断框架- OneCAD(适用于所有图像数据集的单分类器)，以实现接近与类别数无关的变压器模型。据我们所知，这是第一个使用多模态学习进行分类任务的Mask-Image-Modeling(MIM)，以创建一个与类别数无关的DNN模型架构的工作。初步结果已在自然图像分类任务上展示。",
    "tldr": "本文提出了一种训练和推断框架OneCAD，通过Mask-Image-Modeling(MIM)和多模态学习解决了当前架构(如ViTs和CNNs)存在的问题，并创建了一种可以适用于所有图像数据集且与类别数无关的DNN模型架构。",
    "en_tdlr": "This paper proposes a training and inference framework OneCAD, which solves the issues with current architectures (such as ViTs and CNNs) through Mask-Image-Modeling (MIM) and multimodal learning, and creates a DNN model architecture that can be applied to all image datasets and is agnostic to the number of classes."
}