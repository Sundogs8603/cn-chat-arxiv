{
    "title": "Mitigating Test-Time Bias for Fair Image Retrieval. (arXiv:2305.19329v1 [cs.CV])",
    "abstract": "We address the challenge of generating fair and unbiased image retrieval results given neutral textual queries (with no explicit gender or race connotations), while maintaining the utility (performance) of the underlying vision-language (VL) model. Previous methods aim to disentangle learned representations of images and text queries from gender and racial characteristics. However, we show these are inadequate at alleviating bias for the desired equal representation result, as there usually exists test-time bias in the target retrieval set. So motivated, we introduce a straightforward technique, Post-hoc Bias Mitigation (PBM), that post-processes the outputs from the pre-trained vision-language model. We evaluate our algorithm on real-world image search datasets, Occupation 1 and 2, as well as two large-scale image-text datasets, MS-COCO and Flickr30k. Our approach achieves the lowest bias, compared with various existing bias-mitigation methods, in text-based image retrieval result whi",
    "link": "http://arxiv.org/abs/2305.19329",
    "context": "Title: Mitigating Test-Time Bias for Fair Image Retrieval. (arXiv:2305.19329v1 [cs.CV])\nAbstract: We address the challenge of generating fair and unbiased image retrieval results given neutral textual queries (with no explicit gender or race connotations), while maintaining the utility (performance) of the underlying vision-language (VL) model. Previous methods aim to disentangle learned representations of images and text queries from gender and racial characteristics. However, we show these are inadequate at alleviating bias for the desired equal representation result, as there usually exists test-time bias in the target retrieval set. So motivated, we introduce a straightforward technique, Post-hoc Bias Mitigation (PBM), that post-processes the outputs from the pre-trained vision-language model. We evaluate our algorithm on real-world image search datasets, Occupation 1 and 2, as well as two large-scale image-text datasets, MS-COCO and Flickr30k. Our approach achieves the lowest bias, compared with various existing bias-mitigation methods, in text-based image retrieval result whi",
    "path": "papers/23/05/2305.19329.json",
    "total_tokens": 880,
    "translated_title": "缓解测试时间偏差，实现公平的图像检索",
    "translated_abstract": "本文解决了如何在中性文本查询的情况下（没有明确的性别或种族内涵）生成公平和无偏见的图像检索结果，同时保持底层视觉语言（VL）模型的效用（性能）的挑战。先前的方法旨在将图像和文本查询的学习表示与性别和种族特征分离。然而，我们发现这些方法不能减轻测试集中的偏差，从而实现所需的平等表示结果。出于这个动机，我们提出了一个简单的技术，后置偏差缓解（PBM），来后处理预训练视觉语言模型的输出。我们在实际图像搜索数据集Occupation 1和2，以及两个大规模的图像文本数据集MS-COCO和Flickr30k上评估了我们的算法。与各种现有的偏差缓解方法相比，我们的方法在基于文本的图像检索结果中实现了最低的偏差。",
    "tldr": "本文提出了后置偏差缓解（PBM）技术，解决了如何在中性文本查询的情况下实现公平的图像检索。该方法在实际数据集中实现了最低的偏差。",
    "en_tdlr": "This paper proposes the Post-hoc Bias Mitigation (PBM) technique to mitigate test-time bias for fair image retrieval with neutral textual queries, achieving the lowest bias compared to existing methods in text-based image retrieval results on real-world datasets."
}