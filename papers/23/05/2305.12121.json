{
    "title": "ACA-Net: Towards Lightweight Speaker Verification using Asymmetric Cross Attention. (arXiv:2305.12121v1 [cs.SD])",
    "abstract": "In this paper, we propose ACA-Net, a lightweight, global context-aware speaker embedding extractor for Speaker Verification (SV) that improves upon existing work by using Asymmetric Cross Attention (ACA) to replace temporal pooling. ACA is able to distill large, variable-length sequences into small, fixed-sized latents by attending a small query to large key and value matrices. In ACA-Net, we build a Multi-Layer Aggregation (MLA) block using ACA to generate fixed-sized identity vectors from variable-length inputs. Through global attention, ACA-Net acts as an efficient global feature extractor that adapts to temporal variability unlike existing SV models that apply a fixed function for pooling over the temporal dimension which may obscure information about the signal's non-stationary temporal variability. Our experiments on the WSJ0-1talker show ACA-Net outperforms a strong baseline by 5\\% relative improvement in EER using only 1/5 of the parameters.",
    "link": "http://arxiv.org/abs/2305.12121",
    "context": "Title: ACA-Net: Towards Lightweight Speaker Verification using Asymmetric Cross Attention. (arXiv:2305.12121v1 [cs.SD])\nAbstract: In this paper, we propose ACA-Net, a lightweight, global context-aware speaker embedding extractor for Speaker Verification (SV) that improves upon existing work by using Asymmetric Cross Attention (ACA) to replace temporal pooling. ACA is able to distill large, variable-length sequences into small, fixed-sized latents by attending a small query to large key and value matrices. In ACA-Net, we build a Multi-Layer Aggregation (MLA) block using ACA to generate fixed-sized identity vectors from variable-length inputs. Through global attention, ACA-Net acts as an efficient global feature extractor that adapts to temporal variability unlike existing SV models that apply a fixed function for pooling over the temporal dimension which may obscure information about the signal's non-stationary temporal variability. Our experiments on the WSJ0-1talker show ACA-Net outperforms a strong baseline by 5\\% relative improvement in EER using only 1/5 of the parameters.",
    "path": "papers/23/05/2305.12121.json",
    "total_tokens": 863,
    "translated_title": "ACA-Net: 采用不对称交叉注意力的轻量级说话人验证方法",
    "translated_abstract": "本文提出ACA-Net，一种轻量级的全局上下文感知说话人嵌入提取器，用于说话人验证。ACA-Net使用不对称交叉注意力(ACA)代替时间池化，将大的变长序列压缩成小的固定大小的向量。在ACA-Net中，我们构建了一个多层汇聚块，使用ACA从变长度输入中生成固定长度的身份向量。与现有的SV模型不同，ACA-Net通过全局注意力作为有效的全局特征提取器，适应时间变化而不是应用于时间维度的固定函数。我们在WSJ0-1talker数据集上的实验表明，仅使用1/5的参数，ACA-Net在EER方面相对于强基线提高了5%。",
    "tldr": "本文提出了一种轻量级的全局上下文感知说话人嵌入提取器，使用不对称交叉注意力(ACA)代替时间池化，具有高效的全局特征提取和适应时间变化的优点。",
    "en_tdlr": "This paper proposes a lightweight, global context-aware speaker embedding extractor for speaker verification, called ACA-Net, which uses asymmetric cross attention (ACA) to replace temporal pooling. ACA-Net provides an efficient global feature extraction method that adapts to temporal variability, outperforming existing models by providing fixed-sized identity vectors from variable-length inputs with only 1/5 of the parameters."
}