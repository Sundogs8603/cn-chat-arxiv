{
    "title": "Quantitatively Measuring and Contrastively Exploring Heterogeneity for Domain Generalization. (arXiv:2305.15889v1 [cs.LG])",
    "abstract": "Domain generalization (DG) is a prevalent problem in real-world applications, which aims to train well-generalized models for unseen target domains by utilizing several source domains. Since domain labels, i.e., which domain each data point is sampled from, naturally exist, most DG algorithms treat them as a kind of supervision information to improve the generalization performance. However, the original domain labels may not be the optimal supervision signal due to the lack of domain heterogeneity, i.e., the diversity among domains. For example, a sample in one domain may be closer to another domain, its original label thus can be the noise to disturb the generalization learning. Although some methods try to solve it by re-dividing domains and applying the newly generated dividing pattern, the pattern they choose may not be the most heterogeneous due to the lack of the metric for heterogeneity. In this paper, we point out that domain heterogeneity mainly lies in variant features under ",
    "link": "http://arxiv.org/abs/2305.15889",
    "context": "Title: Quantitatively Measuring and Contrastively Exploring Heterogeneity for Domain Generalization. (arXiv:2305.15889v1 [cs.LG])\nAbstract: Domain generalization (DG) is a prevalent problem in real-world applications, which aims to train well-generalized models for unseen target domains by utilizing several source domains. Since domain labels, i.e., which domain each data point is sampled from, naturally exist, most DG algorithms treat them as a kind of supervision information to improve the generalization performance. However, the original domain labels may not be the optimal supervision signal due to the lack of domain heterogeneity, i.e., the diversity among domains. For example, a sample in one domain may be closer to another domain, its original label thus can be the noise to disturb the generalization learning. Although some methods try to solve it by re-dividing domains and applying the newly generated dividing pattern, the pattern they choose may not be the most heterogeneous due to the lack of the metric for heterogeneity. In this paper, we point out that domain heterogeneity mainly lies in variant features under ",
    "path": "papers/23/05/2305.15889.json",
    "total_tokens": 1059,
    "translated_title": "针对领域泛化的异质性量化和对比探索",
    "translated_abstract": "领域泛化(DG)是现实世界应用中普遍存在的问题，通过利用几个源域训练出对未见过目标域进行有效泛化的模型。由于领域标签-即每个数据点来自哪个域自然存在，因此大多数DG算法将它们作为一种监督信息来提高泛化性能。然而，由于领域之间缺乏异质性，即领域之间的差异，原始的域标签可能不是最佳的监督信号。本文提出了一种新的度量标准Feature Heterogeneity Distance(FHD)来衡量领域的异质性，并引入一个新的实验模式CCDG，用于寻找最佳的监督信号来提高泛化。大量实验和消融研究表明，我们所提出的FHD度量标准和CCDG模式比其他最先进的方法更加有效和优越。",
    "tldr": "本文提出了一种Feature Heterogeneity Distance(FHD)度量标准来衡量领域的异质性，并引入了一个新的实验模式Contrastive Convergence for Domain Generalization (CCDG) 来寻找最佳的监督信号来提高泛化。实验表明，我们的方法比其他最先进的方法更加有效和优越。",
    "en_tdlr": "This paper proposes a novel metric, Feature Heterogeneity Distance (FHD), for measuring the heterogeneity of domains and introduces a new experimental paradigm, Contrastive Convergence for Domain Generalization (CCDG), to find the optimal supervision signal for improving generalization. The effectiveness and superiority of the proposed FHD metric and CCDG paradigm over other state-of-the-art methods are demonstrated through extensive experiments and ablation study."
}