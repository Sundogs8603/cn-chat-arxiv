{
    "title": "TIPS: Topologically Important Path Sampling for Anytime Neural Networks. (arXiv:2305.08021v1 [cs.LG])",
    "abstract": "Anytime neural networks (AnytimeNNs) are a promising solution to adaptively adjust the model complexity at runtime under various hardware resource constraints. However, the manually-designed AnytimeNNs are biased by designers' prior experience and thus provide sub-optimal solutions. To address the limitations of existing hand-crafted approaches, we first model the training process of AnytimeNNs as a discrete-time Markov chain (DTMC) and use it to identify the paths that contribute the most to the training of AnytimeNNs. Based on this new DTMC-based analysis, we further propose TIPS, a framework to automatically design AnytimeNNs under various hardware constraints. Our experimental results show that TIPS can improve the convergence rate and test accuracy of AnytimeNNs. Compared to the existing AnytimeNNs approaches, TIPS improves the accuracy by 2%-6.6% on multiple datasets and achieves SOTA accuracy-FLOPs tradeoffs.",
    "link": "http://arxiv.org/abs/2305.08021",
    "context": "Title: TIPS: Topologically Important Path Sampling for Anytime Neural Networks. (arXiv:2305.08021v1 [cs.LG])\nAbstract: Anytime neural networks (AnytimeNNs) are a promising solution to adaptively adjust the model complexity at runtime under various hardware resource constraints. However, the manually-designed AnytimeNNs are biased by designers' prior experience and thus provide sub-optimal solutions. To address the limitations of existing hand-crafted approaches, we first model the training process of AnytimeNNs as a discrete-time Markov chain (DTMC) and use it to identify the paths that contribute the most to the training of AnytimeNNs. Based on this new DTMC-based analysis, we further propose TIPS, a framework to automatically design AnytimeNNs under various hardware constraints. Our experimental results show that TIPS can improve the convergence rate and test accuracy of AnytimeNNs. Compared to the existing AnytimeNNs approaches, TIPS improves the accuracy by 2%-6.6% on multiple datasets and achieves SOTA accuracy-FLOPs tradeoffs.",
    "path": "papers/23/05/2305.08021.json",
    "total_tokens": 936,
    "translated_title": "TIPS：任何时候神经网络的拓扑重要路径采样",
    "translated_abstract": "任何时候神经网络(AnytimeNNs) 是一种能够在各种硬件资源约束下适应性调整模型复杂度的有前途的解决方案。然而，手动设计的 AnytimeNNs 往往会受到设计师先前经验的影响，从而提供次优解。为了解决现有手工方法的限制，我们首先将 AnytimeNNs 的训练过程建模为离散时间马尔可夫链(DTMC)，并利用它来识别对 AnytimeNNs 训练贡献最大的路径。基于这种新的 DTMC 基础分析，我们进一步提出了 TIPS (Topologically Important Path Sampling) 框架，以自动设计适应各种硬件约束的 AnytimeNNs。我们的实验结果表明，TIPS 能够提高 AnytimeNNs 的收敛速度和测试准确率。与现有 AnytimeNNs 方法相比，TIPS 在多个数据集上将准确率提高了 2%-6.6%，并实现了 SOTA 的准确率-FLOPs 折衷。",
    "tldr": "TIPS是一种自动设计AnytimeNNs框架，通过识别贡献最大的路径来提高收敛速度和测试准确率，比现有方法提高了2%-6.6%的准确率，在准确率-FLOPs之间取得了最佳平衡。",
    "en_tdlr": "TIPS is an automatic framework for designing AnytimeNNs that identifies the paths that contribute the most to improve the convergence rate and test accuracy. Compared to existing methods, it achieves 2%-6.6% higher accuracy and the best accuracy-FLOPs tradeoff."
}