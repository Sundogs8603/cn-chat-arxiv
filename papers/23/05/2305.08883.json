{
    "title": "Watermarking Text Generated by Black-Box Language Models. (arXiv:2305.08883v1 [cs.CL])",
    "abstract": "LLMs now exhibit human-like skills in various fields, leading to worries about misuse. Thus, detecting generated text is crucial. However, passive detection methods are stuck in domain specificity and limited adversarial robustness. To achieve reliable detection, a watermark-based method was proposed for white-box LLMs, allowing them to embed watermarks during text generation. The method involves randomly dividing the model vocabulary to obtain a special list and adjusting the probability distribution to promote the selection of words in the list. A detection algorithm aware of the list can identify the watermarked text. However, this method is not applicable in many real-world scenarios where only black-box language models are available. For instance, third-parties that develop API-based vertical applications cannot watermark text themselves because API providers only supply generated text and withhold probability distributions to shield their commercial interests. To allow third-part",
    "link": "http://arxiv.org/abs/2305.08883",
    "context": "Title: Watermarking Text Generated by Black-Box Language Models. (arXiv:2305.08883v1 [cs.CL])\nAbstract: LLMs now exhibit human-like skills in various fields, leading to worries about misuse. Thus, detecting generated text is crucial. However, passive detection methods are stuck in domain specificity and limited adversarial robustness. To achieve reliable detection, a watermark-based method was proposed for white-box LLMs, allowing them to embed watermarks during text generation. The method involves randomly dividing the model vocabulary to obtain a special list and adjusting the probability distribution to promote the selection of words in the list. A detection algorithm aware of the list can identify the watermarked text. However, this method is not applicable in many real-world scenarios where only black-box language models are available. For instance, third-parties that develop API-based vertical applications cannot watermark text themselves because API providers only supply generated text and withhold probability distributions to shield their commercial interests. To allow third-part",
    "path": "papers/23/05/2305.08883.json",
    "total_tokens": 948,
    "translated_title": "黑盒语言模型生成的水印文本",
    "translated_abstract": "LLM现在展示了在各领域中与人类类似的技能，引发人们对误用的担忧。因此，检测生成的文本至关重要。然而，被动式检测方法陷入了领域特异性和有限的对抗强度。为了实现可靠的检测，提出了一种基于水印的白盒LLM方法，使其能够在文本生成过程中嵌入水印。该方法涉及将模型词汇随机分割以获得特殊列表并调整概率分布以促进列表中单词的选择。一个知晓列表的检测算法可以识别带水印的文本。然而，这种方法在许多仅有黑盒语言模型的真实场景中不适用。为了允许第三方给由黑盒语言模型生成的文本加上水印，本文提出了一种利用转换器注意力图来获得词级反馈的新水印算法。实验结果表明，所提出的方法可以有效地给由黑盒语言模型生成的文本加上水印，而不影响文本生成的质量。",
    "tldr": "本研究提出了一种利用Transformer注意力图来获得词级反馈的新型黑盒LLM水印算法，实现对由黑盒语言模型生成的文本的水印保护。",
    "en_tdlr": "This paper presents a novel black-box LLM watermarking algorithm that utilizes Transformer attention maps to obtain word-level feedback, achieving watermark protection for text generated by black-box language models."
}