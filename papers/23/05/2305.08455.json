{
    "title": "Document Understanding Dataset and Evaluation (DUDE). (arXiv:2305.08455v2 [cs.CV] UPDATED)",
    "abstract": "We call on the Document AI (DocAI) community to reevaluate current methodologies and embrace the challenge of creating more practically-oriented benchmarks. Document Understanding Dataset and Evaluation (DUDE) seeks to remediate the halted research progress in understanding visually-rich documents (VRDs). We present a new dataset with novelties related to types of questions, answers, and document layouts based on multi-industry, multi-domain, and multi-page VRDs of various origins, and dates. Moreover, we are pushing the boundaries of current methods by creating multi-task and multi-domain evaluation setups that more accurately simulate real-world situations where powerful generalization and adaptation under low-resource settings are desired. DUDE aims to set a new standard as a more practical, long-standing benchmark for the community, and we hope that it will lead to future extensions and contributions that address real-world challenges. Finally, our work illustrates the importance o",
    "link": "http://arxiv.org/abs/2305.08455",
    "context": "Title: Document Understanding Dataset and Evaluation (DUDE). (arXiv:2305.08455v2 [cs.CV] UPDATED)\nAbstract: We call on the Document AI (DocAI) community to reevaluate current methodologies and embrace the challenge of creating more practically-oriented benchmarks. Document Understanding Dataset and Evaluation (DUDE) seeks to remediate the halted research progress in understanding visually-rich documents (VRDs). We present a new dataset with novelties related to types of questions, answers, and document layouts based on multi-industry, multi-domain, and multi-page VRDs of various origins, and dates. Moreover, we are pushing the boundaries of current methods by creating multi-task and multi-domain evaluation setups that more accurately simulate real-world situations where powerful generalization and adaptation under low-resource settings are desired. DUDE aims to set a new standard as a more practical, long-standing benchmark for the community, and we hope that it will lead to future extensions and contributions that address real-world challenges. Finally, our work illustrates the importance o",
    "path": "papers/23/05/2305.08455.json",
    "total_tokens": 880,
    "translated_title": "文档理解数据集和评估（DUDE）",
    "translated_abstract": "我们呼吁文档AI社区重新评估当前的方法论，拥抱创建更实际取向的基准测试的挑战。文档理解数据集和评估（DUDE）旨在纠正在理解视觉丰富文档（VRD）方面的研究进展停滞不前的情况。我们提供了一个新的数据集，其中包括与多行业、多领域和多页VRD相关的问题类型、答案和文档布局的创新，具有各种来源和日期。此外，我们通过创建多任务和多领域的评估设置来推动当前方法的边界，这些设置更准确地模拟了真实世界的情况，在这些情况下需要在低资源环境下进行强大的泛化和适应。DUDE旨在成为一个更实际、更长期的基准测试标准，并希望它会引领未来的扩展和贡献，以应对真实世界的挑战。最后，我们的工作说明了以下重要性。",
    "tldr": "DUDE推出了一个新的数据集和评估方法，旨在创造一个更实际的基准测试并推动当前方法的边界，以更准确地模拟真实世界的情况",
    "en_tdlr": "DUDE proposes a new dataset and evaluation method to create a more practical benchmark for understanding visually-rich documents (VRDs) and push the boundaries of current methods, with multi-task and multi-domain evaluation setups that accurately simulate real-world situations under low-resource settings."
}