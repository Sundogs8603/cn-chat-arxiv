{
    "title": "Assessing Linguistic Generalisation in Language Models: A Dataset for Brazilian Portuguese. (arXiv:2305.14070v2 [cs.CL] UPDATED)",
    "abstract": "Much recent effort has been devoted to creating large-scale language models. Nowadays, the most prominent approaches are based on deep neural networks, such as BERT. However, they lack transparency and interpretability, and are often seen as black boxes. This affects not only their applicability in downstream tasks but also the comparability of different architectures or even of the same model trained using different corpora or hyperparameters. In this paper, we propose a set of intrinsic evaluation tasks that inspect the linguistic information encoded in models developed for Brazilian Portuguese. These tasks are designed to evaluate how different language models generalise information related to grammatical structures and multiword expressions (MWEs), thus allowing for an assessment of whether the model has learned different linguistic phenomena. The dataset that was developed for these tasks is composed of a series of sentences with a single masked word and a cue phrase that helps in",
    "link": "http://arxiv.org/abs/2305.14070",
    "context": "Title: Assessing Linguistic Generalisation in Language Models: A Dataset for Brazilian Portuguese. (arXiv:2305.14070v2 [cs.CL] UPDATED)\nAbstract: Much recent effort has been devoted to creating large-scale language models. Nowadays, the most prominent approaches are based on deep neural networks, such as BERT. However, they lack transparency and interpretability, and are often seen as black boxes. This affects not only their applicability in downstream tasks but also the comparability of different architectures or even of the same model trained using different corpora or hyperparameters. In this paper, we propose a set of intrinsic evaluation tasks that inspect the linguistic information encoded in models developed for Brazilian Portuguese. These tasks are designed to evaluate how different language models generalise information related to grammatical structures and multiword expressions (MWEs), thus allowing for an assessment of whether the model has learned different linguistic phenomena. The dataset that was developed for these tasks is composed of a series of sentences with a single masked word and a cue phrase that helps in",
    "path": "papers/23/05/2305.14070.json",
    "total_tokens": 886,
    "translated_title": "评估语言模型的语言归纳能力：一份面向巴西葡萄牙语的数据集",
    "translated_abstract": "近年来，大量的研究精力被投入到创建大规模的语言模型中。目前最主流的方法基于深度神经网络，如BERT。但是，它们缺乏透明度和可解释性，往往被视为黑匣子。这不仅影响它们在下游任务中的适用性，也影响了不同架构甚至使用不同语料库或超参数训练的同一模型的可比性。本文提出了一组内在评估任务，检查用于巴西葡萄牙语的模型中编码的语言信息。这些任务旨在评估不同语言模型如何归纳与语法结构和多词表达式（MWE）相关的不同语言现象，从而评估模型是否学习了不同的语言现象。为这些任务开发的数据集由一系列具有单个屏蔽词和提示短语的句子组成，这有助于",
    "tldr": "本文提出了一组内部评估任务，用于评估用于巴西葡萄牙语的语言模型的语言归纳能力，同时开发了相应的数据集，以便于模型是否学习了不同的语言现象。"
}