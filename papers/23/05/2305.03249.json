{
    "title": "PMP: Learning to Physically Interact with Environments using Part-wise Motion Priors. (arXiv:2305.03249v1 [cs.GR])",
    "abstract": "We present a method to animate a character incorporating multiple part-wise motion priors (PMP). While previous works allow creating realistic articulated motions from reference data, the range of motion is largely limited by the available samples. Especially for the interaction-rich scenarios, it is impractical to attempt acquiring every possible interacting motion, as the combination of physical parameters increases exponentially. The proposed PMP allows us to assemble multiple part skills to animate a character, creating a diverse set of motions with different combinations of existing data. In our pipeline, we can train an agent with a wide range of part-wise priors. Therefore, each body part can obtain a kinematic insight of the style from the motion captures, or at the same time extract dynamics-related information from the additional part-specific simulation. For example, we can first train a general interaction skill, e.g. grasping, only for the dexterous part, and then combine ",
    "link": "http://arxiv.org/abs/2305.03249",
    "context": "Title: PMP: Learning to Physically Interact with Environments using Part-wise Motion Priors. (arXiv:2305.03249v1 [cs.GR])\nAbstract: We present a method to animate a character incorporating multiple part-wise motion priors (PMP). While previous works allow creating realistic articulated motions from reference data, the range of motion is largely limited by the available samples. Especially for the interaction-rich scenarios, it is impractical to attempt acquiring every possible interacting motion, as the combination of physical parameters increases exponentially. The proposed PMP allows us to assemble multiple part skills to animate a character, creating a diverse set of motions with different combinations of existing data. In our pipeline, we can train an agent with a wide range of part-wise priors. Therefore, each body part can obtain a kinematic insight of the style from the motion captures, or at the same time extract dynamics-related information from the additional part-specific simulation. For example, we can first train a general interaction skill, e.g. grasping, only for the dexterous part, and then combine ",
    "path": "papers/23/05/2305.03249.json",
    "total_tokens": 922,
    "translated_title": "PMP：使用分部运动先验学习与环境进行物理交互",
    "translated_abstract": "我们提出了一种使用多个分部运动先验（PMP）来动画化角色的方法。之前的研究允许根据参考数据创建逼真的关节运动，但运动范围很大程度上受到可用样本的限制。特别是对于充满交互的场景，试图获取每种可能的交互运动是不现实的，因为物理参数的组合呈指数增长。所提出的PMP允许我们组装多个分部技能以动画化角色，创建具有不同现有数据组合的多种动作集。在我们的管道中，我们可以使用广泛的分部先验训练代理。因此，每个身体部位可以从运动捕捉中获得一种动力学视角的风格，或者同时从附加的部分特定模拟中提取与动力学相关的信息。例如，我们可以先仅为器械手部分训练一般交互技能（例如抓握），然后再结合其他部分的动作。",
    "tldr": "该论文提出了一种使用多个分部运动先验(PMP)动画化角色的方法，可以创造出不同的动作集合，并提供了采用广泛的分部先验训练代理的方法。"
}