{
    "title": "Disincentivizing Polarization in Social Networks. (arXiv:2305.14537v1 [cs.CY])",
    "abstract": "On social networks, algorithmic personalization drives users into filter bubbles where they rarely see content that deviates from their interests. We present a model for content curation and personalization that avoids filter bubbles, along with algorithmic guarantees and nearly matching lower bounds. In our model, the platform interacts with $n$ users over $T$ timesteps, choosing content for each user from $k$ categories. The platform receives stochastic rewards as in a multi-arm bandit. To avoid filter bubbles, we draw on the intuition that if some users are shown some category of content, then all users should see at least a small amount of that content. We first analyze a naive formalization of this intuition and show it has unintended consequences: it leads to ``tyranny of the majority'' with the burden of diversification borne disproportionately by those with minority interests. This leads us to our model which distributes this burden more equitably. We require that the probabili",
    "link": "http://arxiv.org/abs/2305.14537",
    "context": "Title: Disincentivizing Polarization in Social Networks. (arXiv:2305.14537v1 [cs.CY])\nAbstract: On social networks, algorithmic personalization drives users into filter bubbles where they rarely see content that deviates from their interests. We present a model for content curation and personalization that avoids filter bubbles, along with algorithmic guarantees and nearly matching lower bounds. In our model, the platform interacts with $n$ users over $T$ timesteps, choosing content for each user from $k$ categories. The platform receives stochastic rewards as in a multi-arm bandit. To avoid filter bubbles, we draw on the intuition that if some users are shown some category of content, then all users should see at least a small amount of that content. We first analyze a naive formalization of this intuition and show it has unintended consequences: it leads to ``tyranny of the majority'' with the burden of diversification borne disproportionately by those with minority interests. This leads us to our model which distributes this burden more equitably. We require that the probabili",
    "path": "papers/23/05/2305.14537.json",
    "total_tokens": 857,
    "translated_title": "社交网络中的极端化防范",
    "translated_abstract": "在社交网络上，算法个性化将用户带入了过滤气泡中，很少看到偏离他们兴趣的内容。我们提出了一个避免过滤气泡的内容策划和个性化模型，以及算法保证和几乎匹配的下限。在我们的模型中，平台在$T$时间步长内与$n$用户进行互动，从$k$类别为每个用户选择内容。像多臂赌博机一样，平台接收随机奖励。为了避免过滤气泡，我们依赖于这样一个直觉：如果某些用户看到某些类别的内容，则所有用户都应该至少看到一小部分该内容。我们首先分析了这种直觉的一个天真的形式化，证明它具有意想不到的后果：它导致\"多数人的暴政\"，使少数兴趣的人分担了多样化的负担。这导致了我们的模型，更公平地分担了这种负担。",
    "tldr": "该论文提出了一种避免过滤气泡、更公平地分担多样化负担的社交网络内容策划和个性化模型。",
    "en_tdlr": "This paper proposes a content curation and personalization model for social networks that avoids filter bubbles and distributes the burden of diversification more equitably."
}