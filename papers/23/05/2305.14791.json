{
    "title": "Large Language Models as Counterfactual Generator: Strengths and Weaknesses. (arXiv:2305.14791v1 [cs.CL])",
    "abstract": "Large language models (LLMs) have demonstrated remarkable performance in a range of natural language understanding and generation tasks. Yet, their ability to generate counterfactuals, which can be used for areas like data augmentation, remains under-explored. This study aims to investigate the counterfactual generation capabilities of LLMs and analysis factors that influence this ability. First, we evaluate how effective are LLMs in counterfactual generation through data augmentation experiments for small language models (SLMs) across four tasks: sentiment analysis, natural language inference, named entity recognition, and relation extraction. While LLMs show promising enhancements in various settings, they struggle in complex tasks due to their self-limitations and the lack of logical guidance to produce counterfactuals that align with commonsense. Second, our analysis reveals the pivotal role of providing accurate task definitions and detailed step-by-step instructions to LLMs in ge",
    "link": "http://arxiv.org/abs/2305.14791",
    "context": "Title: Large Language Models as Counterfactual Generator: Strengths and Weaknesses. (arXiv:2305.14791v1 [cs.CL])\nAbstract: Large language models (LLMs) have demonstrated remarkable performance in a range of natural language understanding and generation tasks. Yet, their ability to generate counterfactuals, which can be used for areas like data augmentation, remains under-explored. This study aims to investigate the counterfactual generation capabilities of LLMs and analysis factors that influence this ability. First, we evaluate how effective are LLMs in counterfactual generation through data augmentation experiments for small language models (SLMs) across four tasks: sentiment analysis, natural language inference, named entity recognition, and relation extraction. While LLMs show promising enhancements in various settings, they struggle in complex tasks due to their self-limitations and the lack of logical guidance to produce counterfactuals that align with commonsense. Second, our analysis reveals the pivotal role of providing accurate task definitions and detailed step-by-step instructions to LLMs in ge",
    "path": "papers/23/05/2305.14791.json",
    "total_tokens": 912,
    "translated_title": "大型语言模型作为反事实生成器: 优势和劣势",
    "translated_abstract": "大型语言模型（LLMs）在自然语言理解和生成任务中表现出卓越的性能。然而，它们生成反事实的能力，如用于数据增强的反事实，仍未得到充分的研究。本研究旨在调查LLMs的反事实生成能力，并分析影响这种能力的因素。首先，我们通过在情感分析、自然语言推理、命名实体识别和关系抽取等四个任务中进行数据增强实验来评估LLMs在反事实生成方面的效果。虽然LLMs在各种设置中都表现出有希望的改进，但由于其自我限制和缺乏与常识相符的逻辑指导来生成反事实，它们在复杂任务中仍然面临困难。其次，我们的分析揭示了为LLMs提供准确的任务定义和详细的逐步指导在生成有效的反事实中发挥了关键作用。",
    "tldr": "本文研究了大型语言模型（LLMs）作为反事实生成器的能力，通过数据增强实验发现它们在各个任务中表现优异，但仍存在自我限制和缺乏逻辑指导等问题。",
    "en_tdlr": "This study explores the counterfactual generation capabilities of Large Language Models (LLMs), finding that they show promising enhancements in various tasks but struggle in complex ones due to self-limitations and lack of logical guidance. Accurate task definitions and detailed step-by-step instructions play a pivotal role in generating effective counterfactuals."
}