{
    "title": "Improving Fairness in AI Models on Electronic Health Records: The Case for Federated Learning Methods. (arXiv:2305.11386v1 [cs.LG])",
    "abstract": "Developing AI tools that preserve fairness is of critical importance, specifically in high-stakes applications such as those in healthcare. However, health AI models' overall prediction performance is often prioritized over the possible biases such models could have. In this study, we show one possible approach to mitigate bias concerns by having healthcare institutions collaborate through a federated learning paradigm (FL; which is a popular choice in healthcare settings). While FL methods with an emphasis on fairness have been previously proposed, their underlying model and local implementation techniques, as well as their possible applications to the healthcare domain remain widely underinvestigated. Therefore, we propose a comprehensive FL approach with adversarial debiasing and a fair aggregation method, suitable to various fairness metrics, in the healthcare domain where electronic health records are used. Not only our approach explicitly mitigates bias as part of the optimizatio",
    "link": "http://arxiv.org/abs/2305.11386",
    "context": "Title: Improving Fairness in AI Models on Electronic Health Records: The Case for Federated Learning Methods. (arXiv:2305.11386v1 [cs.LG])\nAbstract: Developing AI tools that preserve fairness is of critical importance, specifically in high-stakes applications such as those in healthcare. However, health AI models' overall prediction performance is often prioritized over the possible biases such models could have. In this study, we show one possible approach to mitigate bias concerns by having healthcare institutions collaborate through a federated learning paradigm (FL; which is a popular choice in healthcare settings). While FL methods with an emphasis on fairness have been previously proposed, their underlying model and local implementation techniques, as well as their possible applications to the healthcare domain remain widely underinvestigated. Therefore, we propose a comprehensive FL approach with adversarial debiasing and a fair aggregation method, suitable to various fairness metrics, in the healthcare domain where electronic health records are used. Not only our approach explicitly mitigates bias as part of the optimizatio",
    "path": "papers/23/05/2305.11386.json",
    "total_tokens": 920,
    "translated_title": "在电子健康记录中提高AI模型公平性：联邦学习方法的案例研究",
    "translated_abstract": "开发能够保持公平性的AI工具是至关重要的，特别是在医疗保健等高风险应用中。然而，医疗AI模型的整体预测性能通常优先于这些模型可能存在的偏见。在这项研究中，我们展示了一种可能的方法，通过医疗机构通过联邦学习范式（FL）合作来缓解偏见问题（这是医疗保健领域中广泛使用的一种选择）。虽然先前已经提出了注重公平性的FL方法，但它们的基本模型和本地实施技术，以及它们可能应用于医疗领域，仍然广泛未经研究。因此，我们在使用电子健康记录的医疗领域提出了一种全面的FL方法，其中包括对抗去偏见和公平聚合方法，适用于各种公平度量标准。我们的方法不仅明确地缓解了偏见作为优化的一部分，还提高了预测性能。",
    "tldr": "本研究提出了一种利用联邦学习方法来提高医疗AI模型公平性的方法，包括对抗去偏见和公平聚合方法，适用于各种公平度量标准，使医疗机构可以有效合作。",
    "en_tdlr": "This study proposes a federated learning approach with adversarial debiasing and fair aggregation method to mitigate bias in healthcare AI models, which enables healthcare institutions to collaborate effectively."
}