{
    "title": "CONA: A novel CONtext-Aware instruction paradigm for communication using large language model. (arXiv:2305.18620v1 [cs.CL])",
    "abstract": "We introduce CONA, a novel context-aware instruction paradigm for effective knowledge dissemination using generative pre-trained transformer (GPT) models. CONA is a flexible framework designed to leverage the capabilities of Large Language Models (LLMs) and incorporate DIKW (Data, Information, Knowledge, Wisdom) hierarchy to automatically instruct and optimise presentation content, anticipate potential audience inquiries, and provide context-aware answers that adaptive to the knowledge level of the audience group. The unique aspect of the CONA paradigm lies in its combination of an independent advisory mechanism and a recursive feedback loop rooted on the DIKW hierarchy. This synergy significantly enhances context-aware contents, ensuring they are accessible and easily comprehended by the audience. This paradigm is an early pioneer to explore new methods for knowledge dissemination and communication in the LLM era, offering effective support for everyday knowledge sharing scenarios. We",
    "link": "http://arxiv.org/abs/2305.18620",
    "context": "Title: CONA: A novel CONtext-Aware instruction paradigm for communication using large language model. (arXiv:2305.18620v1 [cs.CL])\nAbstract: We introduce CONA, a novel context-aware instruction paradigm for effective knowledge dissemination using generative pre-trained transformer (GPT) models. CONA is a flexible framework designed to leverage the capabilities of Large Language Models (LLMs) and incorporate DIKW (Data, Information, Knowledge, Wisdom) hierarchy to automatically instruct and optimise presentation content, anticipate potential audience inquiries, and provide context-aware answers that adaptive to the knowledge level of the audience group. The unique aspect of the CONA paradigm lies in its combination of an independent advisory mechanism and a recursive feedback loop rooted on the DIKW hierarchy. This synergy significantly enhances context-aware contents, ensuring they are accessible and easily comprehended by the audience. This paradigm is an early pioneer to explore new methods for knowledge dissemination and communication in the LLM era, offering effective support for everyday knowledge sharing scenarios. We",
    "path": "papers/23/05/2305.18620.json",
    "total_tokens": 870,
    "translated_title": "CONA: 一种新颖的基于上下文的指令范式，用于使用大型语言模型的通信",
    "translated_abstract": "我们介绍了CONA，这是一种新颖的基于上下文的指令范式，利用生成预训练转换器（GPT）模型有效进行知识传播。CONA是一个灵活的框架，旨在利用大型语言模型（LLMs）的能力，并结合DIKW（数据、信息、知识、智慧）层级自动指导和优化演示内容，预测潜在的听众问题，并适应听众群体的知识水平提供上下文感知型答案。CONA范式的独特之处在于其独立咨询机制和根植于DIKW层级的递归反馈循环的组合。这种协同作用显著提高了上下文感知内容，确保听众可以轻松理解和获取。这种范式是探索LLM时代的知识传播和沟通的新方法的早期先驱，为日常知识共享场景提供有效支持。",
    "tldr": "CONA是一种基于上下文的指令范式，利用大型语言模型，自动优化演示内容并提供上下文感知型答案，具有较高的上下文感知性和易理解性。",
    "en_tdlr": "CONA is a context-aware instruction paradigm that leverages large language models to automatically optimize presentation content and provide contextual answers with high accessibility and comprehensibility."
}