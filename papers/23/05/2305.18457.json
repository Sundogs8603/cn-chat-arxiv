{
    "title": "Learning Strong Graph Neural Networks with Weak Information. (arXiv:2305.18457v1 [cs.LG])",
    "abstract": "Graph Neural Networks (GNNs) have exhibited impressive performance in many graph learning tasks. Nevertheless, the performance of GNNs can deteriorate when the input graph data suffer from weak information, i.e., incomplete structure, incomplete features, and insufficient labels. Most prior studies, which attempt to learn from the graph data with a specific type of weak information, are far from effective in dealing with the scenario where diverse data deficiencies exist and mutually affect each other. To fill the gap, in this paper, we aim to develop an effective and principled approach to the problem of graph learning with weak information (GLWI). Based on the findings from our empirical analysis, we derive two design focal points for solving the problem of GLWI, i.e., enabling long-range propagation in GNNs and allowing information propagation to those stray nodes isolated from the largest connected component. Accordingly, we propose D$^2$PT, a dual-channel GNN framework that perfor",
    "link": "http://arxiv.org/abs/2305.18457",
    "context": "Title: Learning Strong Graph Neural Networks with Weak Information. (arXiv:2305.18457v1 [cs.LG])\nAbstract: Graph Neural Networks (GNNs) have exhibited impressive performance in many graph learning tasks. Nevertheless, the performance of GNNs can deteriorate when the input graph data suffer from weak information, i.e., incomplete structure, incomplete features, and insufficient labels. Most prior studies, which attempt to learn from the graph data with a specific type of weak information, are far from effective in dealing with the scenario where diverse data deficiencies exist and mutually affect each other. To fill the gap, in this paper, we aim to develop an effective and principled approach to the problem of graph learning with weak information (GLWI). Based on the findings from our empirical analysis, we derive two design focal points for solving the problem of GLWI, i.e., enabling long-range propagation in GNNs and allowing information propagation to those stray nodes isolated from the largest connected component. Accordingly, we propose D$^2$PT, a dual-channel GNN framework that perfor",
    "path": "papers/23/05/2305.18457.json",
    "total_tokens": 908,
    "translated_title": "学习强大的图神经网络在信息不足情况下",
    "translated_abstract": "图神经网络在许多图学习任务中表现出了令人印象深刻的性能。然而，当输入的图数据存在信息不足时（即不完整的结构、不完整的特征和不充分的标签），GNN的性能可能会下降。大多数此前的研究都试图从具有特定类型的信息不足的图数据中学习，但这远不足以有效应对各种数据缺失存在且相互影响的情况。为了填补这一空白，本文旨在开发一种有效和原则性的方法来解决具有弱信息的图学习问题(GLWI)。基于我们经验分析的发现，我们推导出了两个设计关键点来解决GLWI的问题，即在GNN中实现长程传播，并允许信息传播到那些与最大连接组件隔离的偏离节点。因此，我们提出了D$^2$PT，这是一个双通道的GNN框架",
    "tldr": "本文提出了D$^2$PT，一个双通道的GNN框架，以处理具有多种数据缺失且相互影响的情况，其关键点包括在GNN中实现长程传播和允许信息传播到偏离节点。",
    "en_tdlr": "This paper proposes a dual-channel GNN framework, D$^2$PT, to handle diverse data deficiencies that exist and mutually affect each other, with two design focal points of enabling long-range propagation in GNNs and allowing information propagation to those stray nodes isolated from the largest connected component."
}