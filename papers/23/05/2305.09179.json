{
    "title": "Ortho-ODE: Enhancing Robustness and of Neural ODEs against Adversarial Attacks. (arXiv:2305.09179v1 [cs.LG])",
    "abstract": "Neural Ordinary Differential Equations (NODEs) probed the usage of numerical solvers to solve the differential equation characterized by a Neural Network (NN), therefore initiating a new paradigm of deep learning models with infinite depth. NODEs were designed to tackle the irregular time series problem. However, NODEs have demonstrated robustness against various noises and adversarial attacks. This paper is about the natural robustness of NODEs and examines the cause behind such surprising behaviour. We show that by controlling the Lipschitz constant of the ODE dynamics the robustness can be significantly improved. We derive our approach from Grownwall's inequality. Further, we draw parallels between contractivity theory and Grownwall's inequality. Experimentally we corroborate the enhanced robustness on numerous datasets - MNIST, CIFAR-10, and CIFAR 100. We also present the impact of adaptive and non-adaptive solvers on the robustness of NODEs.",
    "link": "http://arxiv.org/abs/2305.09179",
    "context": "Title: Ortho-ODE: Enhancing Robustness and of Neural ODEs against Adversarial Attacks. (arXiv:2305.09179v1 [cs.LG])\nAbstract: Neural Ordinary Differential Equations (NODEs) probed the usage of numerical solvers to solve the differential equation characterized by a Neural Network (NN), therefore initiating a new paradigm of deep learning models with infinite depth. NODEs were designed to tackle the irregular time series problem. However, NODEs have demonstrated robustness against various noises and adversarial attacks. This paper is about the natural robustness of NODEs and examines the cause behind such surprising behaviour. We show that by controlling the Lipschitz constant of the ODE dynamics the robustness can be significantly improved. We derive our approach from Grownwall's inequality. Further, we draw parallels between contractivity theory and Grownwall's inequality. Experimentally we corroborate the enhanced robustness on numerous datasets - MNIST, CIFAR-10, and CIFAR 100. We also present the impact of adaptive and non-adaptive solvers on the robustness of NODEs.",
    "path": "papers/23/05/2305.09179.json",
    "total_tokens": 977,
    "translated_title": "Ortho-ODE：增强神经常微分方程对抗攻击的鲁棒性",
    "translated_abstract": "神经常微分方程（NODE）通过使用数值求解器来求解由神经网络（NN）表示的微分方程，从而引发了一种具有无限深度的新型深度学习模型范式。 NODE旨在解决不规则时间序列问题。然而，NODE对各种噪声和对抗性攻击表现出了鲁棒性。本文研究NODE的自然鲁棒性并考察其中令人惊讶行为的原因。我们表明，通过控制ODE动力学的Lipschitz常数，可以显着提高其鲁棒性。我们从Grownwall不等式中推导出我们的方法。此外，我们绘制收缩理论和Grownwall不等式之间的类比。实验上，我们在多个数据集（MNIST、CIFAR-10和CIFAR 100）上证实了增强的鲁棒性。我们还展示了自适应和非自适应求解器对NODE鲁棒性的影响。",
    "tldr": "本文研究了神经常微分方程（NODE）在面对噪声和对抗性攻击时所表现出的自然鲁棒性，并通过控制ODE动力学的Lipschitz常数来显著提高其鲁棒性。实验结果在多个数据集上得到了验证。",
    "en_tdlr": "This paper studies the natural robustness of Neural Ordinary Differential Equations (NODEs) and proposes controlling the Lipschitz constant of the ODE dynamics to significantly enhance their robustness against noise and adversarial attacks. The approach is derived from Grownwall's inequality and is experimentally validated on multiple datasets including MNIST, CIFAR-10, and CIFAR 100. The impact of adaptive and non-adaptive solvers on NODEs' robustness is also explored."
}