{
    "title": "Vision Transformers for Mobile Applications: A Short Survey. (arXiv:2305.19365v1 [cs.CV])",
    "abstract": "Vision Transformers (ViTs) have demonstrated state-of-the-art performance on many Computer Vision Tasks. Unfortunately, deploying these large-scale ViTs is resource-consuming and impossible for many mobile devices. While most in the community are building for larger and larger ViTs, we ask a completely opposite question: How small can a ViT be within the tradeoffs of accuracy and inference latency that make it suitable for mobile deployment? We look into a few ViTs specifically designed for mobile applications and observe that they modify the transformer's architecture or are built around the combination of CNN and transformer. Recent work has also attempted to create sparse ViT networks and proposed alternatives to the attention module. In this paper, we study these architectures, identify the challenges and analyze what really makes a vision transformer suitable for mobile applications. We aim to serve as a baseline for future research direction and hopefully lay the foundation to ch",
    "link": "http://arxiv.org/abs/2305.19365",
    "context": "Title: Vision Transformers for Mobile Applications: A Short Survey. (arXiv:2305.19365v1 [cs.CV])\nAbstract: Vision Transformers (ViTs) have demonstrated state-of-the-art performance on many Computer Vision Tasks. Unfortunately, deploying these large-scale ViTs is resource-consuming and impossible for many mobile devices. While most in the community are building for larger and larger ViTs, we ask a completely opposite question: How small can a ViT be within the tradeoffs of accuracy and inference latency that make it suitable for mobile deployment? We look into a few ViTs specifically designed for mobile applications and observe that they modify the transformer's architecture or are built around the combination of CNN and transformer. Recent work has also attempted to create sparse ViT networks and proposed alternatives to the attention module. In this paper, we study these architectures, identify the challenges and analyze what really makes a vision transformer suitable for mobile applications. We aim to serve as a baseline for future research direction and hopefully lay the foundation to ch",
    "path": "papers/23/05/2305.19365.json",
    "total_tokens": 880,
    "translated_title": "移动应用中的视觉Transformer: 一份简短调查",
    "translated_abstract": "视觉Transformer (ViT) 在许多计算机视觉任务上展现了最新的性能。然而，部署这些大规模的ViT对许多移动设备来说是资源消耗大且不可能的。本文提出了相反的问题：在精度和推理延迟的权衡考虑下，ViT可以多小，以使其适用于移动部署？我们研究了一些专为移动应用程序设计的ViT，并观察到它们修改了Transformer的架构或是围绕CNN和Transformer的组合而构建。最近的一些工作还尝试创建稀疏ViT网络并提出了关于注意力模块的替代方案。本文研究了这些架构，确定了挑战并分析了是什么使得Vision Transformer适用于移动应用。我们旨在为未来的研究方向提供基线，并希望打下移动计算机视觉领域的基础。",
    "tldr": "本文调查了在权衡精度和推理延迟的前提下，哪些因素使得Vision Transformer适用于移动部署，并研究了专门设计为移动应用的ViT的体系结构和挑战。"
}