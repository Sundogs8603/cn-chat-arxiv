{
    "title": "Semantic Segmentation with Bidirectional Language Models Improves Long-form ASR. (arXiv:2305.18419v1 [cs.CL])",
    "abstract": "We propose a method of segmenting long-form speech by separating semantically complete sentences within the utterance. This prevents the ASR decoder from needlessly processing faraway context while also preventing it from missing relevant context within the current sentence. Semantically complete sentence boundaries are typically demarcated by punctuation in written text; but unfortunately, spoken real-world utterances rarely contain punctuation. We address this limitation by distilling punctuation knowledge from a bidirectional teacher language model (LM) trained on written, punctuated text. We compare our segmenter, which is distilled from the LM teacher, against a segmenter distilled from a acoustic-pause-based teacher used in other works, on a streaming ASR pipeline. The pipeline with our segmenter achieves a 3.2% relative WER gain along with a 60 ms median end-of-segment latency reduction on a YouTube captioning task.",
    "link": "http://arxiv.org/abs/2305.18419",
    "context": "Title: Semantic Segmentation with Bidirectional Language Models Improves Long-form ASR. (arXiv:2305.18419v1 [cs.CL])\nAbstract: We propose a method of segmenting long-form speech by separating semantically complete sentences within the utterance. This prevents the ASR decoder from needlessly processing faraway context while also preventing it from missing relevant context within the current sentence. Semantically complete sentence boundaries are typically demarcated by punctuation in written text; but unfortunately, spoken real-world utterances rarely contain punctuation. We address this limitation by distilling punctuation knowledge from a bidirectional teacher language model (LM) trained on written, punctuated text. We compare our segmenter, which is distilled from the LM teacher, against a segmenter distilled from a acoustic-pause-based teacher used in other works, on a streaming ASR pipeline. The pipeline with our segmenter achieves a 3.2% relative WER gain along with a 60 ms median end-of-segment latency reduction on a YouTube captioning task.",
    "path": "papers/23/05/2305.18419.json",
    "total_tokens": 844,
    "translated_title": "采用双向语言模型进行语义分割，提高长篇音频识别的准确性",
    "translated_abstract": "我们提出了一种通过分离发音中的语义完整句子实现长篇音频分割的方法，这可以防止ASR解码器处理远距离上下文的无效信息，同时避免它错过当前句子中的相关信息。在书面文本中，语义完整的句子通常由标点符号分隔；但不幸的是，实际口语中的发音很少包含标点符号。因此，我们通过提炼从书面标点文本中训练的双向语言模型（LM）中的标点符号知识来解决这个问题。我们将从LM教师提炼的分割器与以其他方法使用基于声学停顿的教师提炼的分割器进行了比较，并在流媒体ASR管道上进行了测试。我们的分割器在YouTube字幕任务中实现了3.2%的相对WER增益以及60ms中位段末端延迟的减少。",
    "tldr": "本研究提出一种采用双向语言模型进行语义分割的方法，可以有效提高长篇音频识别的准确性和速度。",
    "en_tdlr": "This paper proposes a method of semantic segmentation using bidirectional language models, which can effectively improve the accuracy and speed of long-form speech recognition."
}