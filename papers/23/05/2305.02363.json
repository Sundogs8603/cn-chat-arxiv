{
    "title": "Entity Tracking in Language Models. (arXiv:2305.02363v1 [cs.CL])",
    "abstract": "Keeping track of how states and relations of entities change as a text or dialog unfolds is a key prerequisite to discourse understanding. Despite this fact, there have been few systematic investigations into the ability of large language models (LLMs) to track discourse entities. In this work, we present a task to probe to what extent a language model can infer the final state of an entity given an English description of the initial state and a series of state-changing operations. We use this task to first investigate whether Flan-T5, GPT-3 and GPT-3.5 can track the state of entities, and find that only GPT-3.5 models, which have been pretrained on large amounts of code, exhibit this ability. We then investigate whether smaller models pretrained primarily on text can learn to track entities, through finetuning T5 on several training/evaluation splits. While performance degrades for more complex splits, we find that even for splits with almost no lexical overlap between training and ev",
    "link": "http://arxiv.org/abs/2305.02363",
    "context": "Title: Entity Tracking in Language Models. (arXiv:2305.02363v1 [cs.CL])\nAbstract: Keeping track of how states and relations of entities change as a text or dialog unfolds is a key prerequisite to discourse understanding. Despite this fact, there have been few systematic investigations into the ability of large language models (LLMs) to track discourse entities. In this work, we present a task to probe to what extent a language model can infer the final state of an entity given an English description of the initial state and a series of state-changing operations. We use this task to first investigate whether Flan-T5, GPT-3 and GPT-3.5 can track the state of entities, and find that only GPT-3.5 models, which have been pretrained on large amounts of code, exhibit this ability. We then investigate whether smaller models pretrained primarily on text can learn to track entities, through finetuning T5 on several training/evaluation splits. While performance degrades for more complex splits, we find that even for splits with almost no lexical overlap between training and ev",
    "path": "papers/23/05/2305.02363.json",
    "total_tokens": 1114,
    "translated_title": "语言模型中的实体跟踪",
    "translated_abstract": "追踪操作对象的状态并跟踪它们随文本或对话的展开而发生的关系变化是理解话语的关键前提。尽管如此，对于大型语言模型（LLM）追踪话语实体的能力进行了很少的系统调查。在这项工作中，我们提出了一项任务，以探究语言模型在给定初始状态的英文描述和一系列状态更改操作的情况下能够推断出实体的最终状态的程度。",
    "tldr": "本文探究了大型语言模型追踪实体状态的能力，发现经过大量代码预训练的GPT-3.5模型表现最好，即使训练和评估中几乎没有词汇重叠的情况下，仍然可以获得不错的效果。",
    "en_tdlr": "This paper investigates the ability of large language models (LLMs) to track entity states, finding that GPT-3.5 models pre-trained on large amounts of code perform the best, and even for splits with almost no lexical overlap between training and evaluation, a good performance can still be achieved."
}