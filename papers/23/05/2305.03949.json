{
    "title": "Label-Free Multi-Domain Machine Translation with Stage-wise Training. (arXiv:2305.03949v1 [cs.CL])",
    "abstract": "Most multi-domain machine translation models rely on domain-annotated data. Unfortunately, domain labels are usually unavailable in both training processes and real translation scenarios. In this work, we propose a label-free multi-domain machine translation model which requires only a few or no domain-annotated data in training and no domain labels in inference. Our model is composed of three parts: a backbone model, a domain discriminator taking responsibility to discriminate data from different domains, and a set of experts that transfer the decoded features from generic to specific. We design a stage-wise training strategy and train the three parts sequentially. To leverage the extra domain knowledge and improve the training stability, in the discriminator training stage, domain differences are modeled explicitly with clustering and distilled into the discriminator through a multi-classification task. Meanwhile, the Gumbel-Max sampling is adopted as the routing scheme in the expert",
    "link": "http://arxiv.org/abs/2305.03949",
    "context": "Title: Label-Free Multi-Domain Machine Translation with Stage-wise Training. (arXiv:2305.03949v1 [cs.CL])\nAbstract: Most multi-domain machine translation models rely on domain-annotated data. Unfortunately, domain labels are usually unavailable in both training processes and real translation scenarios. In this work, we propose a label-free multi-domain machine translation model which requires only a few or no domain-annotated data in training and no domain labels in inference. Our model is composed of three parts: a backbone model, a domain discriminator taking responsibility to discriminate data from different domains, and a set of experts that transfer the decoded features from generic to specific. We design a stage-wise training strategy and train the three parts sequentially. To leverage the extra domain knowledge and improve the training stability, in the discriminator training stage, domain differences are modeled explicitly with clustering and distilled into the discriminator through a multi-classification task. Meanwhile, the Gumbel-Max sampling is adopted as the routing scheme in the expert",
    "path": "papers/23/05/2305.03949.json",
    "total_tokens": 946,
    "tldr": "本文提出了一种无标签多领域机器翻译模型，它在训练过程中只需要少量或不需要带有领域标注的数据，而在推理过程中也不需要领域标签，从而能够更好地应对实际翻译场景的需求。"
}