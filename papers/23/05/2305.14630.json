{
    "title": "Testing Causal Models of Word Meaning in GPT-3 and -4. (arXiv:2305.14630v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) have driven extraordinary improvements in NLP. However, it is unclear how such models represent lexical concepts-i.e., the meanings of the words they use. This paper evaluates the lexical representations of GPT-3 and GPT-4 through the lens of HIPE theory, a theory of concept representations which focuses on representations of words describing artifacts (such as \"mop\", \"pencil\", and \"whistle\"). The theory posits a causal graph that relates the meanings of such words to the form, use, and history of the objects to which they refer. We test LLMs using the same stimuli originally used by Chaigneau et al. (2004) to evaluate the theory in humans, and consider a variety of prompt designs. Our experiments concern judgements about causal outcomes, object function, and object naming. We find no evidence that GPT-3 encodes the causal structure hypothesized by HIPE, but do find evidence that GPT-4 encodes such structure. The results contribute to a growing body of rese",
    "link": "http://arxiv.org/abs/2305.14630",
    "context": "Title: Testing Causal Models of Word Meaning in GPT-3 and -4. (arXiv:2305.14630v1 [cs.CL])\nAbstract: Large Language Models (LLMs) have driven extraordinary improvements in NLP. However, it is unclear how such models represent lexical concepts-i.e., the meanings of the words they use. This paper evaluates the lexical representations of GPT-3 and GPT-4 through the lens of HIPE theory, a theory of concept representations which focuses on representations of words describing artifacts (such as \"mop\", \"pencil\", and \"whistle\"). The theory posits a causal graph that relates the meanings of such words to the form, use, and history of the objects to which they refer. We test LLMs using the same stimuli originally used by Chaigneau et al. (2004) to evaluate the theory in humans, and consider a variety of prompt designs. Our experiments concern judgements about causal outcomes, object function, and object naming. We find no evidence that GPT-3 encodes the causal structure hypothesized by HIPE, but do find evidence that GPT-4 encodes such structure. The results contribute to a growing body of rese",
    "path": "papers/23/05/2305.14630.json",
    "total_tokens": 935,
    "translated_title": "在GPT-3和GPT-4中测试词义因果模型",
    "translated_abstract": "大型语言模型（LLM）推动了自然语言处理的巨大改进。然而，这些模型如何表示词汇概念，即它们使用的单词的含义，尚不清楚。本文通过HIPE理论（一种概念表示理论，侧重于描述人造物品的词语的表示）评估了GPT-3和GPT-4的词汇表示。该理论提出了一个将这些词汇的含义与它们所描述的对象的形式、用途和历史联系起来的因果关系图。我们使用Chaigneau等人（2004）最初用于人类评估该理论的相同刺激来测试LLM，并考虑了多种提示设计。我们的实验涉及有关因果结果、对象功能和对象命名的判断。我们没有发现GPT-3编码HIPE假设的因果结构的证据，但是发现GPT-4编码了这样的结构。研究结果有助于更好地理解大型语言模型如何表示词义。",
    "tldr": "本文使用HIPE理论中描述的词义因果关系模型，对GPT-3和GPT-4的词汇表示进行了评估，发现GPT-3没有编码因果结构的证据，而GPT-4则有。",
    "en_tdlr": "This paper evaluates the lexical representations of GPT-3 and GPT-4 using the HIPE theory of concept representations and finds no evidence of causal structure in GPT-3, but does find it in GPT-4."
}