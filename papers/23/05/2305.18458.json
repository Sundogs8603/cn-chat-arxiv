{
    "title": "Conditional Support Alignment for Domain Adaptation with Label Shift. (arXiv:2305.18458v1 [cs.LG])",
    "abstract": "Unsupervised domain adaptation (UDA) refers to a domain adaptation framework in which a learning model is trained based on the labeled samples on the source domain and unlabelled ones in the target domain. The dominant existing methods in the field that rely on the classical covariate shift assumption to learn domain-invariant feature representation have yielded suboptimal performance under the label distribution shift between source and target domains. In this paper, we propose a novel conditional adversarial support alignment (CASA) whose aim is to minimize the conditional symmetric support divergence between the source's and target domain's feature representation distributions, aiming at a more helpful representation for the classification task. We also introduce a novel theoretical target risk bound, which justifies the merits of aligning the supports of conditional feature distributions compared to the existing marginal support alignment approach in the UDA settings. We then provi",
    "link": "http://arxiv.org/abs/2305.18458",
    "context": "Title: Conditional Support Alignment for Domain Adaptation with Label Shift. (arXiv:2305.18458v1 [cs.LG])\nAbstract: Unsupervised domain adaptation (UDA) refers to a domain adaptation framework in which a learning model is trained based on the labeled samples on the source domain and unlabelled ones in the target domain. The dominant existing methods in the field that rely on the classical covariate shift assumption to learn domain-invariant feature representation have yielded suboptimal performance under the label distribution shift between source and target domains. In this paper, we propose a novel conditional adversarial support alignment (CASA) whose aim is to minimize the conditional symmetric support divergence between the source's and target domain's feature representation distributions, aiming at a more helpful representation for the classification task. We also introduce a novel theoretical target risk bound, which justifies the merits of aligning the supports of conditional feature distributions compared to the existing marginal support alignment approach in the UDA settings. We then provi",
    "path": "papers/23/05/2305.18458.json",
    "total_tokens": 957,
    "translated_title": "带标签偏移的域适应中的条件支持对齐",
    "translated_abstract": "无监督域适应 (UDA) 是指一种域适应框架，在该框架中，学习模型基于源域上的标记样本和目标域中的未标记样本进行训练。领域内现有的主流方法依赖于经典的协变量偏移假设来学习域不变特征表示，在源域和目标域之间的标签分布偏移下，性能亚优。在本文中，我们提出了一种新颖的条件对抗支持对齐 (CASA)，其旨在最小化源域和目标域特征表示分布之间的条件对称支持分歧，以便更好地表示分类任务。我们还引入了一种新的理论目标风险界限，证明了调整条件特征分布支持与现有的UDA设置中的边缘支持对齐方法相比的优点。然后，我们提供了一种新的高效优化算法，可应用于大规模数据集。我们的实验结果表明，相对于多个基准数据集中的现有方法，我们的方法得到了显著的改进。",
    "tldr": "本文提出了一种新颖的条件对抗支持对齐方法，以最小化源域和目标域特征表示分布之间的条件对称支持分歧，针对标签分布偏移的域适应问题，相对现有的方法有显著提高。",
    "en_tdlr": "This paper proposes a novel conditional adversarial support alignment (CASA) method to minimize the conditional symmetric support divergence between source and target domain feature representation distributions, achieving significant improvements over existing methods for the label distribution shift problem in domain adaptation."
}