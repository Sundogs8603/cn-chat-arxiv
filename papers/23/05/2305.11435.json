{
    "title": "Syllable Discovery and Cross-Lingual Generalization in a Visually Grounded, Self-Supervised Speech Mode. (arXiv:2305.11435v1 [eess.AS])",
    "abstract": "In this paper, we show that representations capturing syllabic units emerge when training a self-supervised speech model with a visually-grounded training objective. We demonstrate that a nearly identical model architecture (HuBERT) trained with a masked language modeling loss does not exhibit this same ability, suggesting that the visual grounding objective is responsible for the emergence of this phenomenon. We propose the use of a minimum cut algorithm to automatically predict syllable boundaries in speech, followed by a 2-stage clustering method to group identical syllables together. We show that our model not only outperforms a state-of-the-art syllabic segmentation method on the language it was trained on (English), but also generalizes in a zero-shot fashion to Estonian. Finally, we show that the same model is capable of zero-shot generalization for a word segmentation task on 4 other languages from the Zerospeech Challenge, in some cases beating the previous state-of-the-art.",
    "link": "http://arxiv.org/abs/2305.11435",
    "context": "Title: Syllable Discovery and Cross-Lingual Generalization in a Visually Grounded, Self-Supervised Speech Mode. (arXiv:2305.11435v1 [eess.AS])\nAbstract: In this paper, we show that representations capturing syllabic units emerge when training a self-supervised speech model with a visually-grounded training objective. We demonstrate that a nearly identical model architecture (HuBERT) trained with a masked language modeling loss does not exhibit this same ability, suggesting that the visual grounding objective is responsible for the emergence of this phenomenon. We propose the use of a minimum cut algorithm to automatically predict syllable boundaries in speech, followed by a 2-stage clustering method to group identical syllables together. We show that our model not only outperforms a state-of-the-art syllabic segmentation method on the language it was trained on (English), but also generalizes in a zero-shot fashion to Estonian. Finally, we show that the same model is capable of zero-shot generalization for a word segmentation task on 4 other languages from the Zerospeech Challenge, in some cases beating the previous state-of-the-art.",
    "path": "papers/23/05/2305.11435.json",
    "total_tokens": 984,
    "translated_title": "基于视觉引导的自监督语音模型中的音节发现和跨语言泛化",
    "translated_abstract": "本文表明，在使用基于视觉引导的训练目标训练自监督语音模型时，能够捕捉到表示音节的单元的表征。我们证明了几乎相同的模型结构（HuBERT），在使用掩码语言建模损失进行训练时没有表现出这种能力，这表明视觉引导目标导致了这种现象的出现。我们提出使用最小割算法自动预测语音中的音节边界，然后使用两阶段聚类方法将相同的音节组合在一起。我们展示了，我们的模型不仅在训练的语言（英语）上优于最先进的音节分割方法，而且在爱沙尼亚语上以零样本的方式进行泛化。最后，我们展示了相同的模型能够进行4种其他语言的零样本单词分割任务泛化，在某些情况下击败了先前的最先进技术。",
    "tldr": "本文提出采用基于视觉引导的自监督语音模型进行音节发现和跨语言泛化。使用最小割算法和2阶段聚类方法自动预测语音中的音节边界。在英语上表现优于最先进的音节分割方法，并以零样本的方式在爱沙尼亚语上泛化。在其他语言上也取得了成功。",
    "en_tdlr": "This paper proposes syllable discovery and cross-lingual generalization using a visually grounded self-supervised speech model. It uses a minimum cut algorithm and 2-stage clustering method to automatically predict syllable boundaries in speech. It outperforms state-of-the-art syllabic segmentation method on English and generalizes zero-shot to Estonian and four other languages for word segmentation task."
}