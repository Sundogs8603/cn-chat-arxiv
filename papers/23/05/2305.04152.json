{
    "title": "Bayesian Over-the-Air FedAvg via Channel Driven Stochastic Gradient Langevin Dynamics. (arXiv:2305.04152v1 [cs.LG])",
    "abstract": "The recent development of scalable Bayesian inference methods has renewed interest in the adoption of Bayesian learning as an alternative to conventional frequentist learning that offers improved model calibration via uncertainty quantification. Recently, federated averaging Langevin dynamics (FALD) was introduced as a variant of federated averaging that can efficiently implement distributed Bayesian learning in the presence of noiseless communications. In this paper, we propose wireless FALD (WFALD), a novel protocol that realizes FALD in wireless systems by integrating over-the-air computation and channel-driven sampling for Monte Carlo updates. Unlike prior work on wireless Bayesian learning, WFALD enables (\\emph{i}) multiple local updates between communication rounds; and (\\emph{ii}) stochastic gradients computed by mini-batch. A convergence analysis is presented in terms of the 2-Wasserstein distance between the samples produced by WFALD and the targeted global posterior distribut",
    "link": "http://arxiv.org/abs/2305.04152",
    "context": "Title: Bayesian Over-the-Air FedAvg via Channel Driven Stochastic Gradient Langevin Dynamics. (arXiv:2305.04152v1 [cs.LG])\nAbstract: The recent development of scalable Bayesian inference methods has renewed interest in the adoption of Bayesian learning as an alternative to conventional frequentist learning that offers improved model calibration via uncertainty quantification. Recently, federated averaging Langevin dynamics (FALD) was introduced as a variant of federated averaging that can efficiently implement distributed Bayesian learning in the presence of noiseless communications. In this paper, we propose wireless FALD (WFALD), a novel protocol that realizes FALD in wireless systems by integrating over-the-air computation and channel-driven sampling for Monte Carlo updates. Unlike prior work on wireless Bayesian learning, WFALD enables (\\emph{i}) multiple local updates between communication rounds; and (\\emph{ii}) stochastic gradients computed by mini-batch. A convergence analysis is presented in terms of the 2-Wasserstein distance between the samples produced by WFALD and the targeted global posterior distribut",
    "path": "papers/23/05/2305.04152.json",
    "total_tokens": 939,
    "translated_title": "基于无线通信的通道驱动随机梯度 Langevin 动力学贝叶斯联邦平均",
    "translated_abstract": "可扩展贝叶斯推理方法的近期发展已经重新引起了对采用贝叶斯学习作为传统频率学习的替代方法的兴趣，其通过不确定性量化提供了改进的模型校准。最近，引入了联邦平均 Langevin 动力学(FALD)作为联邦平均的变体，可以在没有噪声的通信存在下有效地实现分布式贝叶斯学习。在本文中，我们提出了无线 FALD(WFALD)，这是一种新颖的协议，通过集成基于空中计算和基于通道驱动的 Monte Carlo 更新来实现无线系统中的 FALD。与先前的无线贝叶斯学习相比，WFALD 可以实现(i) 在通信回合之间多个本地更新；并且(ii) 由小批量计算的随机梯度。以 2-Wasserstein 距离为衡量标准，给出了样本收敛分析。",
    "tldr": "本文提出了无线 FALD 协议，可以在无噪声通信的情况下高效地在无线系统中实现分布式贝叶斯学习，实现了在通信回合之间多个本地更新以及由小批量计算的随机梯度，并进行了样本收敛分析。",
    "en_tdlr": "This paper proposes a wireless FALD protocol, which efficiently implements distributed Bayesian learning in wireless systems without noise. It enables multiple local updates between communication rounds and stochastic gradients computed by mini-batch. A convergence analysis is presented in terms of the 2-Wasserstein distance."
}