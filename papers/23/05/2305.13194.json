{
    "title": "SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization Evaluation. (arXiv:2305.13194v2 [cs.CL] UPDATED)",
    "abstract": "Reliable automatic evaluation of summarization systems is challenging due to the multifaceted and subjective nature of the task. This is especially the case for languages other than English, where human evaluations are scarce. In this work, we introduce SEAHORSE, a dataset for multilingual, multifaceted summarization evaluation. SEAHORSE consists of 96K summaries with human ratings along 6 dimensions of text quality: comprehensibility, repetition, grammar, attribution, main ideas, and conciseness, covering 6 languages, 9 systems and 4 datasets. As a result of its size and scope, SEAHORSE can serve both as a benchmark to evaluate learnt metrics, as well as a large-scale resource for training such metrics. We show that metrics trained with SEAHORSE achieve strong performance on the out-of-domain meta-evaluation benchmarks TRUE (Honovich et al., 2022) and mFACE (Aharoni et al., 2022). We make the SEAHORSE dataset and metrics publicly available for future research on multilingual and multi",
    "link": "http://arxiv.org/abs/2305.13194",
    "context": "Title: SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization Evaluation. (arXiv:2305.13194v2 [cs.CL] UPDATED)\nAbstract: Reliable automatic evaluation of summarization systems is challenging due to the multifaceted and subjective nature of the task. This is especially the case for languages other than English, where human evaluations are scarce. In this work, we introduce SEAHORSE, a dataset for multilingual, multifaceted summarization evaluation. SEAHORSE consists of 96K summaries with human ratings along 6 dimensions of text quality: comprehensibility, repetition, grammar, attribution, main ideas, and conciseness, covering 6 languages, 9 systems and 4 datasets. As a result of its size and scope, SEAHORSE can serve both as a benchmark to evaluate learnt metrics, as well as a large-scale resource for training such metrics. We show that metrics trained with SEAHORSE achieve strong performance on the out-of-domain meta-evaluation benchmarks TRUE (Honovich et al., 2022) and mFACE (Aharoni et al., 2022). We make the SEAHORSE dataset and metrics publicly available for future research on multilingual and multi",
    "path": "papers/23/05/2305.13194.json",
    "total_tokens": 1010,
    "translated_title": "SEAHORSE: 多语言、多方面摘要评估的数据集",
    "translated_abstract": "可靠的自动摘要评估由于任务的多方面和主观性质而具有挑战性。尤其对于除英语以外的语言，人工评估稀缺。在这项工作中，我们介绍了SEAHORSE，这是一个用于多语言、多方面摘要评估的数据集。SEAHORSE包含96K个摘要，涵盖了6种语言、9个系统和4个数据集，并根据文本质量的6个维度进行了人工评分：可理解性、重复性、语法、归因、主要观点和简洁性。由于其规模和范围的原因，SEAHORSE既可以作为评估学习度量的基准，也可以作为训练这些度量的大规模资源。我们展示了使用SEAHORSE训练的度量在领域外的元评估基准TRUE和mFACE上取得了很好的性能。我们将SEAHORSE数据集和度量公开提供，以供未来的多语言和多",
    "tldr": "SEAHORSE是一个用于多语言、多方面摘要评估的数据集，包含96K个摘要，涵盖6种语言、9个系统和4个数据集。SEAHORSE是一个用于评估学习度量和训练度量的大规模资源。使用SEAHORSE训练的度量在领域外的元评估基准上表现出了强大的性能。",
    "en_tdlr": "SEAHORSE is a dataset for multilingual, multifaceted summarization evaluation, consisting of 96K summaries in 6 languages, evaluated along 6 dimensions of text quality. It serves as a benchmark for evaluating learned metrics and a large-scale resource for training such metrics. Metrics trained with SEAHORSE achieve strong performance on out-of-domain meta-evaluation benchmarks."
}