{
    "title": "clembench: Using Game Play to Evaluate Chat-Optimized Language Models as Conversational Agents. (arXiv:2305.13455v1 [cs.CL])",
    "abstract": "Recent work has proposed a methodology for the systematic evaluation of \"Situated Language Understanding Agents\"-agents that operate in rich linguistic and non-linguistic contexts-through testing them in carefully constructed interactive settings. Other recent work has argued that Large Language Models (LLMs), if suitably set up, can be understood as (simulators of) such agents. A connection suggests itself, which this paper explores: Can LLMs be evaluated meaningfully by exposing them to constrained game-like settings that are built to challenge specific capabilities? As a proof of concept, this paper investigates five interaction settings, showing that current chat-optimised LLMs are, to an extent, capable to follow game-play instructions. Both this capability and the quality of the game play, measured by how well the objectives of the different games are met, follows the development cycle, with newer models performing better. The metrics even for the comparatively simple example gam",
    "link": "http://arxiv.org/abs/2305.13455",
    "context": "Title: clembench: Using Game Play to Evaluate Chat-Optimized Language Models as Conversational Agents. (arXiv:2305.13455v1 [cs.CL])\nAbstract: Recent work has proposed a methodology for the systematic evaluation of \"Situated Language Understanding Agents\"-agents that operate in rich linguistic and non-linguistic contexts-through testing them in carefully constructed interactive settings. Other recent work has argued that Large Language Models (LLMs), if suitably set up, can be understood as (simulators of) such agents. A connection suggests itself, which this paper explores: Can LLMs be evaluated meaningfully by exposing them to constrained game-like settings that are built to challenge specific capabilities? As a proof of concept, this paper investigates five interaction settings, showing that current chat-optimised LLMs are, to an extent, capable to follow game-play instructions. Both this capability and the quality of the game play, measured by how well the objectives of the different games are met, follows the development cycle, with newer models performing better. The metrics even for the comparatively simple example gam",
    "path": "papers/23/05/2305.13455.json",
    "total_tokens": 1115,
    "translated_title": "clembench：使用游戏来评估作为对话代理人的聊天优化语言模型",
    "translated_abstract": "最近的工作提出了一种针对“站立语言理解代理”的系统评估方法——代理在丰富的语言和非语言环境中运行，通过在精心构造的互动环境中进行测试来评估它们。其他最近的工作则认为，如果适当设置，大型语言模型（LLMs）可以被理解为这样的代理（的模拟器）。本文探讨了这种联系：是否可以通过让LLMs接触具有挑战性的受限游戏式环境来有意义地评估它们的能力？作为概念验证，本文研究了五种交互设置，表明当前的聊天优化LLMs在一定程度上能够遵循游戏玩法指令。这种能力和游戏玩法的质量（通过满足不同游戏目标的情况来衡量）都遵循着发展循环，新型模型表现更好。即使是相对简单的“井字游戏”示例游戏的指标也提供了模型在这些条件下的基本性能指示。这对于将LLMs开发为具有广泛适用性的对话代理人具有启示作用。",
    "tldr": "本论文探讨了大型语言模型在接触具有挑战性的受限游戏式环境下，能否有意义地评估它们的能力。作为概念验证，研究了五种交互设置，表明当前的聊天优化LLMs在一定程度上能够遵循游戏玩法指令。这对于将LLMs开发为具有广泛适用性的对话代理人具有启示作用。",
    "en_tdlr": "This paper explores whether Large Language Models (LLMs) can be meaningfully evaluated by exposing them to constrained game-like settings that are built to challenge specific capabilities. As a proof of concept, the paper investigates five interaction settings, showing that current chat-optimized LLMs are, to an extent, capable to follow game-play instructions. This has implications for the development of LLMs as conversational agents with broader applicability."
}