{
    "title": "RefGPT: Reference -> Truthful & Customized Dialogues Generation by GPTs and for GPTs. (arXiv:2305.14994v2 [cs.CL] UPDATED)",
    "abstract": "General chat models, like ChatGPT, have attained impressive capability to resolve a wide range of NLP tasks by tuning Large Language Models (LLMs) with high-quality instruction data. However, collecting human-written high-quality data, especially multi-turn dialogues, is expensive and unattainable for most people. Though previous studies have used powerful LLMs to generate the dialogues automatically, but they all suffer from generating untruthful dialogues because of the LLMs hallucination. Therefore, we propose a method called RefGPT to generate enormous truthful and customized dialogues without worrying about factual errors caused by the model hallucination. RefGPT solves the model hallucination in dialogue generation by restricting the LLMs to leverage the given reference instead of reciting their own knowledge to generate dialogues. Additionally, RefGPT adds detailed controls on every utterances to enable highly customization capability, which previous studies have ignored. On the",
    "link": "http://arxiv.org/abs/2305.14994",
    "context": "Title: RefGPT: Reference -> Truthful & Customized Dialogues Generation by GPTs and for GPTs. (arXiv:2305.14994v2 [cs.CL] UPDATED)\nAbstract: General chat models, like ChatGPT, have attained impressive capability to resolve a wide range of NLP tasks by tuning Large Language Models (LLMs) with high-quality instruction data. However, collecting human-written high-quality data, especially multi-turn dialogues, is expensive and unattainable for most people. Though previous studies have used powerful LLMs to generate the dialogues automatically, but they all suffer from generating untruthful dialogues because of the LLMs hallucination. Therefore, we propose a method called RefGPT to generate enormous truthful and customized dialogues without worrying about factual errors caused by the model hallucination. RefGPT solves the model hallucination in dialogue generation by restricting the LLMs to leverage the given reference instead of reciting their own knowledge to generate dialogues. Additionally, RefGPT adds detailed controls on every utterances to enable highly customization capability, which previous studies have ignored. On the",
    "path": "papers/23/05/2305.14994.json",
    "total_tokens": 872,
    "translated_title": "RefGPT: GPT模型中基于参考的真实且可学习化的对话生成",
    "translated_abstract": "ChatGPT等通用的聊天模型已经通过使用高质量指令数据调整大型语言模型（LLM）来解决各种NLP任务。然而，收集人类编写的高质量数据，尤其是多轮对话，对大多数人来说是昂贵且难以实现的。尽管以往的研究已经使用了强大的LLMs来自动生成对话，但由于LLMs存在幻觉，这些对话都无法完全真实。因此，我们提出了一种名为RefGPT的方法，可以生成大量真实且定制化的对话，而无需担心模型幻觉造成的事实错误。RefGPT通过限制LLMs使用给定参考而不是回忆自己的知识来生成对话，从而解决了对话生成中的模型幻觉。此外，RefGPT对每个话语都添加了详细的控制，使其具有高度定制化的能力，这是以往研究所忽略的。",
    "tldr": "RefGPT是一种基于参考的对话生成方法，可以生成大量真实且定制化的对话，并解决了对话生成中的模型幻觉问题。"
}