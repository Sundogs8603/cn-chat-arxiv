{
    "title": "Scaling Speech Technology to 1,000+ Languages. (arXiv:2305.13516v1 [cs.CL])",
    "abstract": "Expanding the language coverage of speech technology has the potential to improve access to information for many more people. However, current speech technology is restricted to about one hundred languages which is a small fraction of the over 7,000 languages spoken around the world. The Massively Multilingual Speech (MMS) project increases the number of supported languages by 10-40x, depending on the task. The main ingredients are a new dataset based on readings of publicly available religious texts and effectively leveraging self-supervised learning. We built pre-trained wav2vec 2.0 models covering 1,406 languages, a single multilingual automatic speech recognition model for 1,107 languages, speech synthesis models for the same number of languages, as well as a language identification model for 4,017 languages. Experiments show that our multilingual speech recognition model more than halves the word error rate of Whisper on 54 languages of the FLEURS benchmark while being trained on ",
    "link": "http://arxiv.org/abs/2305.13516",
    "context": "Title: Scaling Speech Technology to 1,000+ Languages. (arXiv:2305.13516v1 [cs.CL])\nAbstract: Expanding the language coverage of speech technology has the potential to improve access to information for many more people. However, current speech technology is restricted to about one hundred languages which is a small fraction of the over 7,000 languages spoken around the world. The Massively Multilingual Speech (MMS) project increases the number of supported languages by 10-40x, depending on the task. The main ingredients are a new dataset based on readings of publicly available religious texts and effectively leveraging self-supervised learning. We built pre-trained wav2vec 2.0 models covering 1,406 languages, a single multilingual automatic speech recognition model for 1,107 languages, speech synthesis models for the same number of languages, as well as a language identification model for 4,017 languages. Experiments show that our multilingual speech recognition model more than halves the word error rate of Whisper on 54 languages of the FLEURS benchmark while being trained on ",
    "path": "papers/23/05/2305.13516.json",
    "total_tokens": 933,
    "translated_title": "将语音技术扩展到1000+种语言",
    "translated_abstract": "扩展语音技术的语言覆盖范围对于许多人改善获取信息的机会具有潜在优势。然而，目前的语音技术仅限于约100种语言，而这只是世界上共使用的7000多种语言的一小部分。Massively Multilingual Speech (MMS)项目通过新数据集和有效利用自监督学习的方法，将受支持的语言数量增加了10-40倍。我们构建了预训练的wav2vec 2.0模型，覆盖了1406种语言，一个用于1107种语言的单一的多语种自动语音识别模型，相同数量的语音合成模型，以及一个用于4017种语言的语言识别模型。实验表明，我们的多语种语音识别模型在FLEURS基准测试的54种语言上可以将Whisper的单词错误率降至一半以上，而我们的模型是基于所有语种进行训练的。",
    "tldr": "该论文介绍了Massively Multilingual Speech (MMS)项目，该项目通过新的数据集和自监督学习的方法将受支持的语言数量增加了10-40倍。实验表明，MMS的多语种语音识别模型可以在FLEURS基准测试的54种语言上将单词错误率降至一半以上。"
}