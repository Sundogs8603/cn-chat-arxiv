{
    "title": "On Bias and Fairness in NLP: How to have a fairer text classification?. (arXiv:2305.12829v2 [cs.CL] UPDATED)",
    "abstract": "In this paper, we provide a holistic analysis of the different sources of bias, Upstream, Sample and Overampflication biases, in NLP models. We investigate how they impact the fairness of the task of text classification. We also investigate the impact of removing these biases using different debiasing techniques on the fairness of text classification. We found that overamplification bias is the most impactful bias on the fairness of text classification. And that removing overamplification bias by fine-tuning the LM models on a dataset with balanced representations of the different identity groups leads to fairer text classification models. Finally, we build on our findings and introduce practical guidelines on how to have a fairer text classification model.",
    "link": "http://arxiv.org/abs/2305.12829",
    "context": "Title: On Bias and Fairness in NLP: How to have a fairer text classification?. (arXiv:2305.12829v2 [cs.CL] UPDATED)\nAbstract: In this paper, we provide a holistic analysis of the different sources of bias, Upstream, Sample and Overampflication biases, in NLP models. We investigate how they impact the fairness of the task of text classification. We also investigate the impact of removing these biases using different debiasing techniques on the fairness of text classification. We found that overamplification bias is the most impactful bias on the fairness of text classification. And that removing overamplification bias by fine-tuning the LM models on a dataset with balanced representations of the different identity groups leads to fairer text classification models. Finally, we build on our findings and introduce practical guidelines on how to have a fairer text classification model.",
    "path": "papers/23/05/2305.12829.json",
    "total_tokens": 824,
    "translated_title": "论自然语言处理中的偏见和公平：如何构建更公正的文本分类？",
    "translated_abstract": "本文全面分析了自然语言处理模型中不同来源的偏见，即上游偏见、样本偏见和过度放大偏见，以及它们对文本分类任务公平性的影响。我们还研究了使用不同去偏方法消除这些偏见对文本分类公平性的影响。研究发现过度放大偏见对文本分类公平性的影响最大。将语言模型在平衡不同类别身份群体的数据集上进行微调，可以去除过度放大偏见，进而构建更公正的文本分类模型。最后，我们基于研究发现提出了构建更公正的文本分类模型的实用指南。",
    "tldr": "本文从上游偏见、样本偏见和过度放大偏见三方面分析了NLP模型中的偏见如何影响文本分类的公平性，并针对过度放大偏见通过微调语言模型达到公平分类效果。提出了构建公正文本分类模型的实用指南。",
    "en_tdlr": "This paper provides a comprehensive analysis of biases in NLP models, including upstream bias, sample bias, and overamplification bias, and their impact on the fairness of text classification. It suggests fine-tuning language models on a balanced dataset as a practical way to remove overamplification bias and achieve fairer text classification. Practical guidelines on how to build fair text classification models are also provided."
}