{
    "title": "VideoChat: Chat-Centric Video Understanding. (arXiv:2305.06355v1 [cs.CV])",
    "abstract": "In this study, we initiate an exploration into video understanding by introducing VideoChat, an end-to-end chat-centric video understanding system. It integrates video foundation models and large language models via a learnable neural interface, excelling in spatiotemporal reasoning, event localization, and causal relationship inference. To instructively tune this system, we propose a video-centric instruction dataset, composed of thousands of videos matched with detailed descriptions and conversations. This dataset emphasizes spatiotemporal reasoning and causal relationships, providing a valuable asset for training chat-centric video understanding systems. Preliminary qualitative experiments reveal our system's potential across a broad spectrum of video applications and set the standard for future research. Access our code and data at https://github.com/OpenGVLab/Ask-Anything",
    "link": "http://arxiv.org/abs/2305.06355",
    "context": "Title: VideoChat: Chat-Centric Video Understanding. (arXiv:2305.06355v1 [cs.CV])\nAbstract: In this study, we initiate an exploration into video understanding by introducing VideoChat, an end-to-end chat-centric video understanding system. It integrates video foundation models and large language models via a learnable neural interface, excelling in spatiotemporal reasoning, event localization, and causal relationship inference. To instructively tune this system, we propose a video-centric instruction dataset, composed of thousands of videos matched with detailed descriptions and conversations. This dataset emphasizes spatiotemporal reasoning and causal relationships, providing a valuable asset for training chat-centric video understanding systems. Preliminary qualitative experiments reveal our system's potential across a broad spectrum of video applications and set the standard for future research. Access our code and data at https://github.com/OpenGVLab/Ask-Anything",
    "path": "papers/23/05/2305.06355.json",
    "total_tokens": 872,
    "translated_title": "视频聊天：以聊天为核心的视频理解系统",
    "translated_abstract": "本文提出了视频聊天（VideoChat）——一个端到端的以聊天为核心的视频理解系统，它通过可学习的神经接口将视频基础模型和大型语言模型集成在一起，擅长于时空推理、事件定位和因果关系推断。为了教授该系统的使用，我们提出了一个视频为中心的指令数据集，包含成千上万个视频和详细的描述和对话，这个数据集强调时空推理和因果关系，为培训以聊天为核心的视频理解系统提供了宝贵的资产。初步的定性实验揭示了我们的系统在广泛的视频应用中的潜力，并为未来的研究设定了标准。我们的代码和数据可以在 https://github.com/OpenGVLab/Ask-Anything 上获取。",
    "tldr": "本文提出了以聊天为核心的视频理解系统VideoChat，它通过可学习的神经接口将视频基础模型和大型语言模型集成在一起，擅长于时空推理、事件定位和因果关系推断。作者还提出了一个视频为中心的指令数据集，初步实验表明该系统在广泛的视频应用中具有潜力。",
    "en_tdlr": "This paper proposes a chat-centric video understanding system, VideoChat, which integrates video foundation models and large language models via a learnable neural interface, excelling in spatiotemporal reasoning, event localization, and causal relationship inference. The authors also propose a video-centric instruction dataset emphasizing spatiotemporal reasoning and causal relationships. Preliminary experiments show the potential of the system in various video applications."
}