{
    "title": "Pseudo-Label Training and Model Inertia in Neural Machine Translation. (arXiv:2305.11808v1 [cs.CL])",
    "abstract": "Like many other machine learning applications, neural machine translation (NMT) benefits from over-parameterized deep neural models. However, these models have been observed to be brittle: NMT model predictions are sensitive to small input changes and can show significant variation across re-training or incremental model updates. This work studies a frequently used method in NMT, pseudo-label training (PLT), which is common to the related techniques of forward-translation (or self-training) and sequence-level knowledge distillation. While the effect of PLT on quality is well-documented, we highlight a lesser-known effect: PLT can enhance a model's stability to model updates and input perturbations, a set of properties we call model inertia. We study inertia effects under different training settings and we identify distribution simplification as a mechanism behind the observed results.",
    "link": "http://arxiv.org/abs/2305.11808",
    "context": "Title: Pseudo-Label Training and Model Inertia in Neural Machine Translation. (arXiv:2305.11808v1 [cs.CL])\nAbstract: Like many other machine learning applications, neural machine translation (NMT) benefits from over-parameterized deep neural models. However, these models have been observed to be brittle: NMT model predictions are sensitive to small input changes and can show significant variation across re-training or incremental model updates. This work studies a frequently used method in NMT, pseudo-label training (PLT), which is common to the related techniques of forward-translation (or self-training) and sequence-level knowledge distillation. While the effect of PLT on quality is well-documented, we highlight a lesser-known effect: PLT can enhance a model's stability to model updates and input perturbations, a set of properties we call model inertia. We study inertia effects under different training settings and we identify distribution simplification as a mechanism behind the observed results.",
    "path": "papers/23/05/2305.11808.json",
    "total_tokens": 902,
    "translated_title": "神经机器翻译中伪标签训练和模型惯性研究",
    "translated_abstract": "像许多其他机器学习应用一样，神经机器翻译（NMT）受益于过度参数化的深度神经模型。但是，这些模型被观察到是脆弱的：NMT模型预测对小的输入变化敏感，并且在重新训练或增量模型更新时会显示显着变化。本文研究了NMT中经常使用的伪标签训练（PLT），它是前向翻译（或自我训练）和序列级知识蒸馏等相关技术的常见训练方法。尽管PLT对质量的影响有充分的文献记载，但我们强调一个较少被人了解的影响：PLT可以增强模型对模型更新和输入扰动的稳定性，形成一组我们称之为模型惯性的特性。我们研究了不同训练设置下的惯性效应，并确定了分布简化是观察结果背后的机制。",
    "tldr": "本研究着重研究了NMT中经常使用的伪标签训练（PLT），发现PLT不仅会影响质量，而且可以增强模型对模型更新和输入扰动的稳定性，形成模型惯性。",
    "en_tdlr": "This study focuses on pseudo-label training (PLT) frequently used in NMT, and found that PLT not only affects the quality, but also enhances the stability of the model to model updates and input perturbations, forming model inertia."
}