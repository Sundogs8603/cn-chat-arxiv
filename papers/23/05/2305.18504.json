{
    "title": "Generalized Disparate Impact for Configurable Fairness Solutions in ML. (arXiv:2305.18504v1 [cs.LG])",
    "abstract": "We make two contributions in the field of AI fairness over continuous protected attributes. First, we show that the Hirschfeld-Gebelein-Renyi (HGR) indicator (the only one currently available for such a case) is valuable but subject to a few crucial limitations regarding semantics, interpretability, and robustness. Second, we introduce a family of indicators that are: 1) complementary to HGR in terms of semantics; 2) fully interpretable and transparent; 3) robust over finite samples; 4) configurable to suit specific applications. Our approach also allows us to define fine-grained constraints to permit certain types of dependence and forbid others selectively. By expanding the available options for continuous protected attributes, our approach represents a significant contribution to the area of fair artificial intelligence.",
    "link": "http://arxiv.org/abs/2305.18504",
    "context": "Title: Generalized Disparate Impact for Configurable Fairness Solutions in ML. (arXiv:2305.18504v1 [cs.LG])\nAbstract: We make two contributions in the field of AI fairness over continuous protected attributes. First, we show that the Hirschfeld-Gebelein-Renyi (HGR) indicator (the only one currently available for such a case) is valuable but subject to a few crucial limitations regarding semantics, interpretability, and robustness. Second, we introduce a family of indicators that are: 1) complementary to HGR in terms of semantics; 2) fully interpretable and transparent; 3) robust over finite samples; 4) configurable to suit specific applications. Our approach also allows us to define fine-grained constraints to permit certain types of dependence and forbid others selectively. By expanding the available options for continuous protected attributes, our approach represents a significant contribution to the area of fair artificial intelligence.",
    "path": "papers/23/05/2305.18504.json",
    "total_tokens": 893,
    "translated_title": "可配置公平性解决方案中的广义不同影响",
    "translated_abstract": "我们在连续保护属性的AI公平领域做了两项贡献。首先，我们展示了Hirschfeld-Gebelein-Renyi（HGR）指标（目前仅适用于这种情况）是有价值的，但受到一些关键限制，包括语义、可解释性和鲁棒性。其次，我们介绍了一族指标，在语义上是HGR的补充；具有充分的可解释性和透明性；在有限样本下鲁棒；可配置以适应特定应用程序。我们的方法还允许我们定义细粒度约束条件，以允许某些类型的依赖性并有选择地禁止其他类型的依赖。通过扩展连续保护属性的可用选项，我们的方法对公平人工智能领域表示出了重要的贡献。",
    "tldr": "这篇论文在AI公平领域的连续保护属性中，提出了一族指标，相比于现有的HGR指标，在语义上更为补充，具有充分的可解释性和透明性，在有限样本下鲁棒，可配置以适应特定应用程序，并允许定义细粒度约束条件。",
    "en_tdlr": "This paper proposes a family of indicators in the area of AI fairness over continuous protected attributes. These indicators are complementary to the current Hirschfeld-Gebelein-Renyi (HGR) indicator, fully interpretable and transparent, robust over finite samples, configurable for specific applications, and allow for defining fine-grained constraints. This approach represents a significant contribution to the field of fair artificial intelligence."
}