{
    "title": "COCKATIEL: COntinuous Concept ranKed ATtribution with Interpretable ELements for explaining neural net classifiers on NLP tasks. (arXiv:2305.06754v1 [cs.CL])",
    "abstract": "Transformer architectures are complex and their use in NLP, while it has engendered many successes, makes their interpretability or explainability challenging. Recent debates have shown that attention maps and attribution methods are unreliable (Pruthi et al., 2019; Brunner et al., 2019). In this paper, we present some of their limitations and introduce COCKATIEL, which successfully addresses some of them. COCKATIEL is a novel, post-hoc, concept-based, model-agnostic XAI technique that generates meaningful explanations from the last layer of a neural net model trained on an NLP classification task by using Non-Negative Matrix Factorization (NMF) to discover the concepts the model leverages to make predictions and by exploiting a Sensitivity Analysis to estimate accurately the importance of each of these concepts for the model. It does so without compromising the accuracy of the underlying model or requiring a new one to be trained. We conduct experiments in single and multi-aspect sent",
    "link": "http://arxiv.org/abs/2305.06754",
    "context": "Title: COCKATIEL: COntinuous Concept ranKed ATtribution with Interpretable ELements for explaining neural net classifiers on NLP tasks. (arXiv:2305.06754v1 [cs.CL])\nAbstract: Transformer architectures are complex and their use in NLP, while it has engendered many successes, makes their interpretability or explainability challenging. Recent debates have shown that attention maps and attribution methods are unreliable (Pruthi et al., 2019; Brunner et al., 2019). In this paper, we present some of their limitations and introduce COCKATIEL, which successfully addresses some of them. COCKATIEL is a novel, post-hoc, concept-based, model-agnostic XAI technique that generates meaningful explanations from the last layer of a neural net model trained on an NLP classification task by using Non-Negative Matrix Factorization (NMF) to discover the concepts the model leverages to make predictions and by exploiting a Sensitivity Analysis to estimate accurately the importance of each of these concepts for the model. It does so without compromising the accuracy of the underlying model or requiring a new one to be trained. We conduct experiments in single and multi-aspect sent",
    "path": "papers/23/05/2305.06754.json",
    "total_tokens": 990,
    "translated_title": "COCKATIEL:用可解释元素对NLP任务中的神经网络分类器进行连续概念排名带归因性解释",
    "translated_abstract": "Transformer结构复杂，其在NLP中的使用虽然取得了许多成功，但其可解释性或可解释性较为棘手。最近的争论表明，注意力图和归因方法不可靠，而我们在本文中介绍了其中一些局限性，同时介绍了COCKATIEL这一新型的模型无关的可解释性技术，它是一种后期方法，基于概念，用于从经过NLP分类任务训练的神经网络模型的最后一层中生成有意义的解释，通过使用非负矩阵分解(NMF)来发现模型利用来进行预测的概念，并利用敏感性分析来准确估计每个概念对模型的重要性，而不会影响底层模型的准确性或需要训练新模型。我们在单一和多方面的情感分析中进行实验，证明COCKATIEL比现有方法产生更有信息量和可靠的解释。",
    "tldr": "COCKATIEL是一种连续概念排名带归因性解释的技术，基于概念，用于从NLP分类任务的神经网络模型的最后一层中生成有意义的解释，且不会影响准确性或需要新模型，已证明比现有方法产生更有信息量和可靠的解释。",
    "en_tdlr": "COCKATIEL is a novel, concept-based, model-agnostic XAI technique for explaining neural net classifiers on NLP tasks, which generates meaningful explanations without compromising accuracy or requiring a new model, and has been demonstrated to produce more informative and reliable explanations than existing methods."
}