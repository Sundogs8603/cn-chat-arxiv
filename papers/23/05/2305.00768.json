{
    "title": "Heterogeneous Social Value Orientation Leads to Meaningful Diversity in Sequential Social Dilemmas. (arXiv:2305.00768v1 [cs.MA])",
    "abstract": "In social psychology, Social Value Orientation (SVO) describes an individual's propensity to allocate resources between themself and others. In reinforcement learning, SVO has been instantiated as an intrinsic motivation that remaps an agent's rewards based on particular target distributions of group reward. Prior studies show that groups of agents endowed with heterogeneous SVO learn diverse policies in settings that resemble the incentive structure of Prisoner's dilemma. Our work extends this body of results and demonstrates that (1) heterogeneous SVO leads to meaningfully diverse policies across a range of incentive structures in sequential social dilemmas, as measured by task-specific diversity metrics; and (2) learning a best response to such policy diversity leads to better zero-shot generalization in some situations. We show that these best-response agents learn policies that are conditioned on their co-players, which we posit is the reason for improved zero-shot generalization ",
    "link": "http://arxiv.org/abs/2305.00768",
    "context": "Title: Heterogeneous Social Value Orientation Leads to Meaningful Diversity in Sequential Social Dilemmas. (arXiv:2305.00768v1 [cs.MA])\nAbstract: In social psychology, Social Value Orientation (SVO) describes an individual's propensity to allocate resources between themself and others. In reinforcement learning, SVO has been instantiated as an intrinsic motivation that remaps an agent's rewards based on particular target distributions of group reward. Prior studies show that groups of agents endowed with heterogeneous SVO learn diverse policies in settings that resemble the incentive structure of Prisoner's dilemma. Our work extends this body of results and demonstrates that (1) heterogeneous SVO leads to meaningfully diverse policies across a range of incentive structures in sequential social dilemmas, as measured by task-specific diversity metrics; and (2) learning a best response to such policy diversity leads to better zero-shot generalization in some situations. We show that these best-response agents learn policies that are conditioned on their co-players, which we posit is the reason for improved zero-shot generalization ",
    "path": "papers/23/05/2305.00768.json",
    "total_tokens": 904,
    "translated_title": "异质性社交价值取向在序列社交困境中导致有意义的多样性",
    "translated_abstract": "在社会心理学中，社交价值取向（SVO）描述了个人在自我和他人之间分配资源的倾向性。在强化学习中，SVO被实例化为一种内在动机，根据特定的目标分配组奖励，重新映射代理的奖励。之前的研究表明，具有异质性SVO的代理组在类似囚徒困境的激励结构下学习了多样化的策略。我们的研究扩展了这一结果，并证明了(1)异质性SVO在序列社交困境中通过一系列的奖励结构导致策略的多样性，如任务特定的多样性指标所测量的那样；(2)针对这种策略多样性学习最佳应答在某些情况下可以更好地进行零样本推广。我们展示了这些最佳应答代理学习的策略是以他们的联合玩家为条件的，我们认为这是改进零样本推广的原因。",
    "tldr": "该论文研究表明，在序列社交困境中，异质性SVO导致多样化的策略，并通过学习最佳应答策略实现更好的零样本推广。",
    "en_tdlr": "This paper shows that heterogeneous SVO leads to diverse policies in sequential social dilemmas, and learning a best response to such policy diversity improves zero-shot generalization in some situations."
}