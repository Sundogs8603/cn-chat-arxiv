{
    "title": "Zero-Shot Listwise Document Reranking with a Large Language Model. (arXiv:2305.02156v1 [cs.IR])",
    "abstract": "Supervised ranking methods based on bi-encoder or cross-encoder architectures have shown success in multi-stage text ranking tasks, but they require large amounts of relevance judgments as training data. In this work, we propose Listwise Reranker with a Large Language Model (LRL), which achieves strong reranking effectiveness without using any task-specific training data. Different from the existing pointwise ranking methods, where documents are scored independently and ranked according to the scores, LRL directly generates a reordered list of document identifiers given the candidate documents. Experiments on three TREC web search datasets demonstrate that LRL not only outperforms zero-shot pointwise methods when reranking first-stage retrieval results, but can also act as a final-stage reranker to improve the top-ranked results of a pointwise method for improved efficiency. Additionally, we apply our approach to subsets of MIRACL, a recent multilingual retrieval dataset, with results ",
    "link": "http://arxiv.org/abs/2305.02156",
    "context": "Title: Zero-Shot Listwise Document Reranking with a Large Language Model. (arXiv:2305.02156v1 [cs.IR])\nAbstract: Supervised ranking methods based on bi-encoder or cross-encoder architectures have shown success in multi-stage text ranking tasks, but they require large amounts of relevance judgments as training data. In this work, we propose Listwise Reranker with a Large Language Model (LRL), which achieves strong reranking effectiveness without using any task-specific training data. Different from the existing pointwise ranking methods, where documents are scored independently and ranked according to the scores, LRL directly generates a reordered list of document identifiers given the candidate documents. Experiments on three TREC web search datasets demonstrate that LRL not only outperforms zero-shot pointwise methods when reranking first-stage retrieval results, but can also act as a final-stage reranker to improve the top-ranked results of a pointwise method for improved efficiency. Additionally, we apply our approach to subsets of MIRACL, a recent multilingual retrieval dataset, with results ",
    "path": "papers/23/05/2305.02156.json",
    "total_tokens": 962,
    "translated_title": "基于大型语言模型的零样本列表式文档重新排序",
    "translated_abstract": "基于双编码器或交叉编码器结构的监督排序方法已经在多阶段文本排序任务中取得了成功，但是它们需要大量相关性判断作为训练数据。在本文中，我们提出了一种使用大型语言模型的列表式重新排序器(LRL)，它可以在不使用任何特定任务训练数据的情况下实现强大的重新排序效果。LRL与现有的点式排名方法不同，在点式排名方法中，文档是独立得分并按分数排名，而LRL直接生成给定候选文档的重新排序文档标识符列表。在三个TREC网络搜索数据集上的实验表明，LRL不仅可以在重新排序第一阶段检索结果时优于零样本点式方法，还可以作为点式方法的最终阶段重新排序器，以提高效率并提高前几名的结果。此外，我们将我们的方法应用于MIRACL的子集，这是最近的一个多语言检索数据集，获得了令人满意的结果。",
    "tldr": "本文提出了一种基于大型语言模型的列表式重新排序器，可以在没有特定任务训练数据的情况下实现强大的重新排序效果，并在实验中取得了令人满意的结果。",
    "en_tdlr": "This paper proposes a Listwise Reranker with a Large Language Model (LRL) that achieves strong reranking effectiveness without using any task-specific training data. The LRL generates a reordered list of document identifiers given the candidate documents, and outperforms zero-shot pointwise methods in reranking first-stage retrieval results. Additionally, LRL can act as a final-stage reranker to improve the efficiency and top-ranked results of a pointwise method. The approach is evaluated on three TREC web search datasets and subsets of the MIRACL multilingual retrieval dataset, with promising results."
}