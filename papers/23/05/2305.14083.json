{
    "title": "Counterfactual Augmentation for Multimodal Learning Under Presentation Bias. (arXiv:2305.14083v2 [cs.LG] UPDATED)",
    "abstract": "In real-world machine learning systems, labels are often derived from user behaviors that the system wishes to encourage. Over time, new models must be trained as new training examples and features become available. However, feedback loops between users and models can bias future user behavior, inducing a presentation bias in the labels that compromises the ability to train new models. In this paper, we propose counterfactual augmentation, a novel causal method for correcting presentation bias using generated counterfactual labels. Our empirical evaluations demonstrate that counterfactual augmentation yields better downstream performance compared to both uncorrected models and existing bias-correction methods. Model analyses further indicate that the generated counterfactuals align closely with true counterfactuals in an oracle setting.",
    "link": "http://arxiv.org/abs/2305.14083",
    "context": "Title: Counterfactual Augmentation for Multimodal Learning Under Presentation Bias. (arXiv:2305.14083v2 [cs.LG] UPDATED)\nAbstract: In real-world machine learning systems, labels are often derived from user behaviors that the system wishes to encourage. Over time, new models must be trained as new training examples and features become available. However, feedback loops between users and models can bias future user behavior, inducing a presentation bias in the labels that compromises the ability to train new models. In this paper, we propose counterfactual augmentation, a novel causal method for correcting presentation bias using generated counterfactual labels. Our empirical evaluations demonstrate that counterfactual augmentation yields better downstream performance compared to both uncorrected models and existing bias-correction methods. Model analyses further indicate that the generated counterfactuals align closely with true counterfactuals in an oracle setting.",
    "path": "papers/23/05/2305.14083.json",
    "total_tokens": 874,
    "translated_title": "对于表示偏见下的多模态学习的反事实增强",
    "translated_abstract": "在现实世界的机器学习系统中，标签通常是从系统希望鼓励的用户行为中得出的。随着时间的推移，随着新的训练样本和特征的提供，需要训练新模型。然而，用户和模型之间的反馈循环可能导致未来用户行为的偏见，进而导致标签中的表示偏见，这损害了训练新模型的能力。在本文中，我们提出了一种新颖的因果方法，即反事实增强，通过生成的反事实标签来纠正表示偏见。我们的实证评估表明，相比未修正的模型和现有的偏见校正方法，反事实增强可以产生更好的下游性能。模型分析进一步表明，在理想情况下，生成的反事实与真实反事实密切相关。",
    "tldr": "本文提出了一种用于纠正表示偏见的新颖方法，即反事实增强。实证评估表明，反事实增强相比于未修正的模型和现有的偏见校正方法，可以获得更好的下游性能。模型分析进一步指出，在理想情况下，生成的反事实与真实反事实密切相关。",
    "en_tdlr": "This paper proposes a novel method called counterfactual augmentation for correcting presentation bias. Empirical evaluations show that counterfactual augmentation outperforms uncorrected models and existing bias-correction methods in terms of downstream performance. Model analyses further indicate that the generated counterfactuals closely resemble true counterfactuals in an ideal setting."
}