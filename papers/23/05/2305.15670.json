{
    "title": "Interpretable Machine Learning based on Functional ANOVA Framework: Algorithms and Comparisons. (arXiv:2305.15670v1 [stat.ML])",
    "abstract": "In the early days of machine learning (ML), the emphasis was on developing complex algorithms to achieve best predictive performance. To understand and explain the model results, one had to rely on post hoc explainability techniques, which are known to have limitations. Recently, with the recognition that interpretability is just as important, researchers are compromising on small increases in predictive performance to develop algorithms that are inherently interpretable. While doing so, the ML community has rediscovered the use of low-order functional ANOVA (fANOVA) models that have been known in the statistical literature for some time. This paper starts with a description of challenges with post hoc explainability and reviews the fANOVA framework with a focus on main effects and second-order interactions. This is followed by an overview of two recently developed techniques: Explainable Boosting Machines or EBM (Lou et al., 2013) and GAMI-Net (Yang et al., 2021b). The paper proposes ",
    "link": "http://arxiv.org/abs/2305.15670",
    "context": "Title: Interpretable Machine Learning based on Functional ANOVA Framework: Algorithms and Comparisons. (arXiv:2305.15670v1 [stat.ML])\nAbstract: In the early days of machine learning (ML), the emphasis was on developing complex algorithms to achieve best predictive performance. To understand and explain the model results, one had to rely on post hoc explainability techniques, which are known to have limitations. Recently, with the recognition that interpretability is just as important, researchers are compromising on small increases in predictive performance to develop algorithms that are inherently interpretable. While doing so, the ML community has rediscovered the use of low-order functional ANOVA (fANOVA) models that have been known in the statistical literature for some time. This paper starts with a description of challenges with post hoc explainability and reviews the fANOVA framework with a focus on main effects and second-order interactions. This is followed by an overview of two recently developed techniques: Explainable Boosting Machines or EBM (Lou et al., 2013) and GAMI-Net (Yang et al., 2021b). The paper proposes ",
    "path": "papers/23/05/2305.15670.json",
    "total_tokens": 997,
    "translated_title": "基于函数ANOVA框架的可解释机器学习: 算法及比较",
    "translated_abstract": "在机器学习早期，重点是开发复杂算法以获得最佳预测性能。为了理解和解释模型结果，必须依靠事后解释技术，这些技术已经被证明存在一定限制。最近，随着认识到可解释性同样重要，研究人员开始做出妥协来开发固有可解释性的算法而不是追求极致预测表现。在此过程中，机器学习社区重新发掘了函数ANOVA低阶模型的使用方法，这种方法在统计文献中已知。本文首先描述了事后可解释性面临的挑战，并重点介绍了主效应和二阶相互作用。接下来，概述了两种新开发的技术:可解释的增强机器（EBM）（Lou等人，2013）和GAMI-Net（Yang等人，2021b)。最后，本文提出了一个新算法，即基于FANOVA和GAM的可解释监督学习算法（FANGAM-EBM）。",
    "tldr": "本论文探讨了机器学习中可解释性的重要性，并介绍了函数ANOVA框架及其在可解释机器学习中的应用。此外，还概述了两种新开发的可解释性技术，并提出了一种新的算法——基于FANOVA和GAM的可解释的监督学习算法（FANGAM-EBM）。",
    "en_tdlr": "This paper discusses the importance of interpretability in machine learning and introduces the functional ANOVA framework and its application in interpretable machine learning. Additionally, it provides an overview of two recently developed explainable techniques and proposes a new algorithm - FANGAM-EBM - based on FANOVA and GAM for interpretable supervised learning."
}