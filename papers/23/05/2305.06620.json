{
    "title": "Improving Continual Relation Extraction by Distinguishing Analogous Semantics. (arXiv:2305.06620v1 [cs.CL])",
    "abstract": "Continual relation extraction (RE) aims to learn constantly emerging relations while avoiding forgetting the learned relations. Existing works store a small number of typical samples to re-train the model for alleviating forgetting. However, repeatedly replaying these samples may cause the overfitting problem. We conduct an empirical study on existing works and observe that their performance is severely affected by analogous relations. To address this issue, we propose a novel continual extraction model for analogous relations. Specifically, we design memory-insensitive relation prototypes and memory augmentation to overcome the overfitting problem. We also introduce integrated training and focal knowledge distillation to enhance the performance on analogous relations. Experimental results show the superiority of our model and demonstrate its effectiveness in distinguishing analogous relations and overcoming overfitting.",
    "link": "http://arxiv.org/abs/2305.06620",
    "context": "Title: Improving Continual Relation Extraction by Distinguishing Analogous Semantics. (arXiv:2305.06620v1 [cs.CL])\nAbstract: Continual relation extraction (RE) aims to learn constantly emerging relations while avoiding forgetting the learned relations. Existing works store a small number of typical samples to re-train the model for alleviating forgetting. However, repeatedly replaying these samples may cause the overfitting problem. We conduct an empirical study on existing works and observe that their performance is severely affected by analogous relations. To address this issue, we propose a novel continual extraction model for analogous relations. Specifically, we design memory-insensitive relation prototypes and memory augmentation to overcome the overfitting problem. We also introduce integrated training and focal knowledge distillation to enhance the performance on analogous relations. Experimental results show the superiority of our model and demonstrate its effectiveness in distinguishing analogous relations and overcoming overfitting.",
    "path": "papers/23/05/2305.06620.json",
    "total_tokens": 841,
    "translated_title": "区分类比语义以提升连续关系抽取",
    "translated_abstract": "连续关系抽取旨在学习不断出现的关系，同时避免遗忘已学习的关系。现有的方法是存储少量典型样本用于重新训练模型以缓解遗忘。然而，反复重放这些样本可能导致过拟合问题。本文对现有方法进行实证研究，发现类比关系严重影响性能。为解决这一问题，我们提出了一种针对类比关系的新型连续抽取模型，具有记忆无关的关系原型和记忆增强等设计，以克服过拟合问题；同时，引入综合训练和焦点知识蒸馏来增强在类比关系上的性能。实验结果表明，我们的模型表现卓越，且能够有效区分类比关系和克服过拟合。",
    "tldr": "本研究提出了一种针对类比关系的连续抽取模型，通过设计记忆无关的关系原型和记忆增强以克服过拟合问题，进而引入综合训练和焦点知识蒸馏以增强在类比关系上的性能。",
    "en_tdlr": "This study proposes a novel continual extraction model for analogous relations, which overcomes the overfitting problem by designing memory-insensitive relation prototypes and memory augmentation, and enhances the performance on analogous relations through integrated training and focal knowledge distillation."
}