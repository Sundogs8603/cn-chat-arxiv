{
    "title": "A Matter of Annotation: An Empirical Study on In Situ and Self-Recall Activity Annotations from Wearable Sensors",
    "abstract": "arXiv:2305.08752v2 Announce Type: replace-cross  Abstract: Research into the detection of human activities from wearable sensors is a highly active field, benefiting numerous applications, from ambulatory monitoring of healthcare patients via fitness coaching to streamlining manual work processes. We present an empirical study that compares 4 different commonly used annotation methods utilized in user studies that focus on in-the-wild data. These methods can be grouped in user-driven, in situ annotations - which are performed before or during the activity is recorded - and recall methods - where participants annotate their data in hindsight at the end of the day. Our study illustrates that different labeling methodologies directly impact the annotations' quality, as well as the capabilities of a deep learning classifier trained with the data respectively. We noticed that in situ methods produce less but more precise labels than recall methods. Furthermore, we combined an activity diary",
    "link": "https://arxiv.org/abs/2305.08752",
    "context": "Title: A Matter of Annotation: An Empirical Study on In Situ and Self-Recall Activity Annotations from Wearable Sensors\nAbstract: arXiv:2305.08752v2 Announce Type: replace-cross  Abstract: Research into the detection of human activities from wearable sensors is a highly active field, benefiting numerous applications, from ambulatory monitoring of healthcare patients via fitness coaching to streamlining manual work processes. We present an empirical study that compares 4 different commonly used annotation methods utilized in user studies that focus on in-the-wild data. These methods can be grouped in user-driven, in situ annotations - which are performed before or during the activity is recorded - and recall methods - where participants annotate their data in hindsight at the end of the day. Our study illustrates that different labeling methodologies directly impact the annotations' quality, as well as the capabilities of a deep learning classifier trained with the data respectively. We noticed that in situ methods produce less but more precise labels than recall methods. Furthermore, we combined an activity diary",
    "path": "papers/23/05/2305.08752.json",
    "total_tokens": 844,
    "translated_title": "注释问题：来自可穿戴传感器的原位和自我回忆活动注释的实证研究",
    "translated_abstract": "人们对从可穿戴传感器中检测人类活动的研究是一个高度活跃的领域，使许多应用受益，从通过健康护理患者的步行监测到健身指导再到简化手工作业流程。我们提出了一项实证研究，比较了在野外数据用户研究中使用的4种不同常用的注释方法。这些方法可以分为用户驱动的、原位注释-即在记录活动之前或期间执行的注释-和回忆方法-参与者在当天结束时追溯地对其数据进行标注。我们的研究表明，不同的标记方法直接影响注释的质量，以及相应数据训练的深度学习分类器的能力。我们注意到，原位方法产生的标签较少，但更精确，而回忆方法产生的标签较多，但不够精确。此外，我们还结合了一本活动日记",
    "tldr": "不同的标记方法对数据质量和深度学习分类器的性能有直接影响，原位方法产生的标签较少但更精确。",
    "en_tdlr": "Different labeling methods have a direct impact on data quality and the performance of deep learning classifiers, with in situ methods producing fewer but more precise labels."
}