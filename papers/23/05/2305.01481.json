{
    "title": "Great Models Think Alike: Improving Model Reliability via Inter-Model Latent Agreement. (arXiv:2305.01481v1 [cs.LG])",
    "abstract": "Reliable application of machine learning is of primary importance to the practical deployment of deep learning methods. A fundamental challenge is that models are often unreliable due to overconfidence. In this paper, we estimate a model's reliability by measuring \\emph{the agreement between its latent space, and the latent space of a foundation model}. However, it is challenging to measure the agreement between two different latent spaces due to their incoherence, \\eg, arbitrary rotations and different dimensionality. To overcome this incoherence issue, we design a \\emph{neighborhood agreement measure} between latent spaces and find that this agreement is surprisingly well-correlated with the reliability of a model's predictions. Further, we show that fusing neighborhood agreement into a model's predictive confidence in a post-hoc way significantly improves its reliability. Theoretical analysis and extensive experiments on failure detection across various datasets verify the effective",
    "link": "http://arxiv.org/abs/2305.01481",
    "context": "Title: Great Models Think Alike: Improving Model Reliability via Inter-Model Latent Agreement. (arXiv:2305.01481v1 [cs.LG])\nAbstract: Reliable application of machine learning is of primary importance to the practical deployment of deep learning methods. A fundamental challenge is that models are often unreliable due to overconfidence. In this paper, we estimate a model's reliability by measuring \\emph{the agreement between its latent space, and the latent space of a foundation model}. However, it is challenging to measure the agreement between two different latent spaces due to their incoherence, \\eg, arbitrary rotations and different dimensionality. To overcome this incoherence issue, we design a \\emph{neighborhood agreement measure} between latent spaces and find that this agreement is surprisingly well-correlated with the reliability of a model's predictions. Further, we show that fusing neighborhood agreement into a model's predictive confidence in a post-hoc way significantly improves its reliability. Theoretical analysis and extensive experiments on failure detection across various datasets verify the effective",
    "path": "papers/23/05/2305.01481.json",
    "total_tokens": 923,
    "translated_title": "模型之间的潜在一致性：提高机器学习模型可靠性的方法",
    "translated_abstract": "机器学习模型的可靠应用对于深度学习算法的实际部署至关重要。但是由于过度自信，模型经常是不可靠的。本文提出通过测量一个模型的潜在空间与另一个基础模型的潜在空间之间的一致性来估计模型的可靠性。然而，由于它们的不连贯性，即任意旋转和不同的维度，两个不同的潜在空间之间的一致性很难衡量。为了解决这个不连贯性问题，我们设计了一种潜在空间之间的“邻域一致性度量”，并发现这种一致性与模型预测的可靠性有惊人的相关性。此外，我们证明在后续的方式中将邻域一致性融入模型的预测置信度可以显著提高其可靠性。在各种数据集上的故障检测的理论分析和广泛实验验证了这种方法的有效性。",
    "tldr": "通过测量模型和一个基础模型的潜在空间之间的一致性来提高机器学习模型的可靠性。",
    "en_tdlr": "This paper proposes to improve the reliability of machine learning models by measuring the agreement between a model's latent space and the latent space of a foundation model. The authors designed a neighborhood agreement measure between latent spaces to overcome the incoherence issue and showed that fusing neighborhood agreement into a model's predictive confidence significantly improved its reliability. The effectiveness of this method was verified through theoretical analysis and extensive experiments on failure detection across various datasets."
}