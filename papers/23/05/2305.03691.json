{
    "title": "Mining bias-target Alignment from Voronoi Cells. (arXiv:2305.03691v1 [cs.LG])",
    "abstract": "Despite significant research efforts, deep neural networks are still vulnerable to biases: this raises concerns about their fairness and limits their generalization. In this paper, we propose a bias-agnostic approach to mitigate the impact of bias in deep neural networks. Unlike traditional debiasing approaches, we rely on a metric to quantify ``bias alignment/misalignment'' on target classes, and use this information to discourage the propagation of bias-target alignment information through the network. We conduct experiments on several commonly used datasets for debiasing and compare our method to supervised and bias-specific approaches. Our results indicate that the proposed method achieves comparable performance to state-of-the-art supervised approaches, although it is bias-agnostic, even in presence of multiple biases in the same sample.",
    "link": "http://arxiv.org/abs/2305.03691",
    "context": "Title: Mining bias-target Alignment from Voronoi Cells. (arXiv:2305.03691v1 [cs.LG])\nAbstract: Despite significant research efforts, deep neural networks are still vulnerable to biases: this raises concerns about their fairness and limits their generalization. In this paper, we propose a bias-agnostic approach to mitigate the impact of bias in deep neural networks. Unlike traditional debiasing approaches, we rely on a metric to quantify ``bias alignment/misalignment'' on target classes, and use this information to discourage the propagation of bias-target alignment information through the network. We conduct experiments on several commonly used datasets for debiasing and compare our method to supervised and bias-specific approaches. Our results indicate that the proposed method achieves comparable performance to state-of-the-art supervised approaches, although it is bias-agnostic, even in presence of multiple biases in the same sample.",
    "path": "papers/23/05/2305.03691.json",
    "total_tokens": 829,
    "translated_title": "从泰森多边形中挖掘偏见-目标对齐",
    "translated_abstract": "尽管进行了大量的研究，深度神经网络仍然容易出现偏差:这引起了他们公正性的担忧并限制了它们的泛化能力。在本文中，我们提出了一种偏见无关的方法来减轻深度神经网络中偏差的影响。与传统的去偏见方法不同，我们依靠一个指标来量化目标类别上的“偏见对齐/不对齐”，并利用此信息来避免通过网络传播偏见-目标对齐信息。我们在几个常用的去偏见数据集上进行实验，并将我们的方法与有监督和偏见特定的方法进行比较。我们的结果表明，尽管存在多个样本中的偏见，所提出的方法在不存在偏见的情况下实现了与最先进的有监督方法相当的性能。",
    "tldr": "本文提出了一种偏见无关的方法来减轻深度神经网络中偏差的影响，在目标类别上量化“偏见对齐/不对齐”，以避免通过网络传播偏见-目标对齐信息。",
    "en_tdlr": "This paper proposes a bias-agnostic approach to mitigate the impact of bias in deep neural networks, by quantifying \"bias alignment/misalignment\" on target classes and using it to avoid the propagation of bias-target alignment information through the network."
}