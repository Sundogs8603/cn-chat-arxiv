{
    "title": "Bias Beyond English: Counterfactual Tests for Bias in Sentiment Analysis in Four Languages. (arXiv:2305.11673v1 [cs.CL])",
    "abstract": "Sentiment analysis (SA) systems are used in many products and hundreds of languages. Gender and racial biases are well-studied in English SA systems, but understudied in other languages, with few resources for such studies. To remedy this, we build a counterfactual evaluation corpus for gender and racial/migrant bias in four languages. We demonstrate its usefulness by answering a simple but important question that an engineer might need to answer when deploying a system: What biases do systems import from pre-trained models when compared to a baseline with no pre-training? Our evaluation corpus, by virtue of being counterfactual, not only reveals which models have less bias, but also pinpoints changes in model bias behaviour, which enables more targeted mitigation strategies. We release our code and evaluation corpora to facilitate future research.",
    "link": "http://arxiv.org/abs/2305.11673",
    "context": "Title: Bias Beyond English: Counterfactual Tests for Bias in Sentiment Analysis in Four Languages. (arXiv:2305.11673v1 [cs.CL])\nAbstract: Sentiment analysis (SA) systems are used in many products and hundreds of languages. Gender and racial biases are well-studied in English SA systems, but understudied in other languages, with few resources for such studies. To remedy this, we build a counterfactual evaluation corpus for gender and racial/migrant bias in four languages. We demonstrate its usefulness by answering a simple but important question that an engineer might need to answer when deploying a system: What biases do systems import from pre-trained models when compared to a baseline with no pre-training? Our evaluation corpus, by virtue of being counterfactual, not only reveals which models have less bias, but also pinpoints changes in model bias behaviour, which enables more targeted mitigation strategies. We release our code and evaluation corpora to facilitate future research.",
    "path": "papers/23/05/2305.11673.json",
    "total_tokens": 895,
    "translated_title": "超越英语：四种语言情感分析中的偏差反事实测试",
    "translated_abstract": "情感分析（SA）系统在许多产品和数百种语言中使用。性别和种族偏见在英语SA系统中得到了很好的研究，但在其他语言中却鲜有研究资源。为了解决这个问题，我们建立了一个针对四种语言的性别和种族/移民偏见的反事实评估语料库。我们通过回答工程师在部署系统时可能需要回答的一个简单但重要的问题来证明其有用性：与没有预训练的基准线相比，系统从预训练模型中导入了哪些偏差？由于它是反事实的评估语料库，我们的评估语料库不仅揭示了哪些模型具有更少的偏差，而且还确定了模型偏差行为的变化，从而使更针对性的减轻策略成为可能。我们发布了我们的代码和评估语料库以便于未来的研究。",
    "tldr": "本研究针对四种语言建立了一个对性别和种族/移民偏见的反事实评估语料库，并通过回答关键问题揭示了系统从预训练模型中导入的偏差行为变化，为更有针对性地减轻策略提供了可能。",
    "en_tdlr": "This study builds a counterfactual evaluation corpus for gender and racial/migrant bias in sentiment analysis systems in four languages, and reveals changes in model bias behavior from pre-trained models, providing the possibility for more targeted mitigation strategies."
}