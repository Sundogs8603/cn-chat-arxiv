{
    "title": "Federated Learning Operations Made Simple with Flame. (arXiv:2305.05118v1 [cs.LG])",
    "abstract": "Distributed machine learning approaches, including a broad class of federated learning techniques, present a number of benefits when deploying machine learning applications over widely distributed infrastructures. To realize the expected benefits, however, introduces substantial operational challenges due to required application and configuration-level changes related to deployment-specific details. Such complexities can be greatly reduced by introducing higher-level abstractions -- role and channel -- using which federated learning applications are described as Topology Abstraction Graphs (TAGs). TAGs decouple the ML application logic from the underlying deployment details, making it possible to specialize the application deployment, thus reducing development effort and paving the way for improved automation and tuning. We present Flame, the first system that supports these abstractions, and demonstrate its benefits for several use cases.",
    "link": "http://arxiv.org/abs/2305.05118",
    "context": "Title: Federated Learning Operations Made Simple with Flame. (arXiv:2305.05118v1 [cs.LG])\nAbstract: Distributed machine learning approaches, including a broad class of federated learning techniques, present a number of benefits when deploying machine learning applications over widely distributed infrastructures. To realize the expected benefits, however, introduces substantial operational challenges due to required application and configuration-level changes related to deployment-specific details. Such complexities can be greatly reduced by introducing higher-level abstractions -- role and channel -- using which federated learning applications are described as Topology Abstraction Graphs (TAGs). TAGs decouple the ML application logic from the underlying deployment details, making it possible to specialize the application deployment, thus reducing development effort and paving the way for improved automation and tuning. We present Flame, the first system that supports these abstractions, and demonstrate its benefits for several use cases.",
    "path": "papers/23/05/2305.05118.json",
    "total_tokens": 838,
    "translated_title": "Flame：简化联邦学习操作的工具",
    "translated_abstract": "分布式机器学习方法，包括广泛的联邦学习技术，在广泛分布的基础架构上部署机器学习应用程序时带来了许多优点。然而，为了实现预期的效益，需要进行应用程序和配置级别的更改，这涉及部署特定的细节。通过引入更高级别的抽象——角色和通道，可以大大减少这些复杂性，并将联邦学习应用程序描述为拓扑抽象图（TAG）。TAG将ML应用程序逻辑与底层部署细节解耦，使得可以专门定制应用程序部署，从而降低开发工作量，并为改进自动化和调整铺平道路。我们推出了Flame，这是第一个支持这些抽象概念的系统，并演示了它对多个用例的好处。",
    "tldr": "Flame 是一个工具，通过引入高级抽象——角色和通道，将联邦学习应用程序描述为拓扑抽象图，解耦 ML 应用程序逻辑与底层部署细节，使得可以专门定制部署，减少开发工作，改进自动化和调整。",
    "en_tdlr": "Flame is a tool that describes federated learning applications as Topology Abstraction Graphs (TAGs) using higher-level abstractions -roles and channels- to decouple ML application logic from deployment details, which reduces development effort and paves the way for improved automation and tuning."
}