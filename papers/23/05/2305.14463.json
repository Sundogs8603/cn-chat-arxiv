{
    "title": "Towards Massively Multi-domain Multilingual Readability Assessment. (arXiv:2305.14463v1 [cs.CL])",
    "abstract": "We present ReadMe++, a massively multi-domain multilingual dataset for automatic readability assessment. Prior work on readability assessment has been mostly restricted to the English language and one or two text domains. Additionally, the readability levels of sentences used in many previous datasets are assumed on the document-level other than sentence-level, which raises doubt about the quality of previous evaluations. We address those gaps in the literature by providing an annotated dataset of 6,330 sentences in Arabic, English, and Hindi collected from 64 different domains of text. Unlike previous datasets, ReadMe++ offers more domain and language diversity and is manually annotated at a sentence level using the Common European Framework of Reference for Languages (CEFR) and through a Rank-and-Rate annotation framework that reduces subjectivity in annotation. Our experiments demonstrate that models fine-tuned using ReadMe++ achieve strong cross-lingual transfer capabilities and ge",
    "link": "http://arxiv.org/abs/2305.14463",
    "context": "Title: Towards Massively Multi-domain Multilingual Readability Assessment. (arXiv:2305.14463v1 [cs.CL])\nAbstract: We present ReadMe++, a massively multi-domain multilingual dataset for automatic readability assessment. Prior work on readability assessment has been mostly restricted to the English language and one or two text domains. Additionally, the readability levels of sentences used in many previous datasets are assumed on the document-level other than sentence-level, which raises doubt about the quality of previous evaluations. We address those gaps in the literature by providing an annotated dataset of 6,330 sentences in Arabic, English, and Hindi collected from 64 different domains of text. Unlike previous datasets, ReadMe++ offers more domain and language diversity and is manually annotated at a sentence level using the Common European Framework of Reference for Languages (CEFR) and through a Rank-and-Rate annotation framework that reduces subjectivity in annotation. Our experiments demonstrate that models fine-tuned using ReadMe++ achieve strong cross-lingual transfer capabilities and ge",
    "path": "papers/23/05/2305.14463.json",
    "total_tokens": 932,
    "tldr": "本研究提出了ReadMe++数据集，该数据集为自动可读性评估提供了大规模多领域多语言的注释数据。使用欧洲共同语言参考框架和Rank-and-Rate注释框架在句子级别上进行手动注释，这一数据集具有更强的跨语言转移能力。"
}