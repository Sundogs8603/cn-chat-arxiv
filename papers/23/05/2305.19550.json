{
    "title": "Spotlight Attention: Robust Object-Centric Learning With a Spatial Locality Prior. (arXiv:2305.19550v1 [cs.CV])",
    "abstract": "The aim of object-centric vision is to construct an explicit representation of the objects in a scene. This representation is obtained via a set of interchangeable modules called \\emph{slots} or \\emph{object files} that compete for local patches of an image. The competition has a weak inductive bias to preserve spatial continuity; consequently, one slot may claim patches scattered diffusely throughout the image. In contrast, the inductive bias of human vision is strong, to the degree that attention has classically been described with a spotlight metaphor. We incorporate a spatial-locality prior into state-of-the-art object-centric vision models and obtain significant improvements in segmenting objects in both synthetic and real-world datasets. Similar to human visual attention, the combination of image content and spatial constraints yield robust unsupervised object-centric learning, including less sensitivity to model hyperparameters.",
    "link": "http://arxiv.org/abs/2305.19550",
    "context": "Title: Spotlight Attention: Robust Object-Centric Learning With a Spatial Locality Prior. (arXiv:2305.19550v1 [cs.CV])\nAbstract: The aim of object-centric vision is to construct an explicit representation of the objects in a scene. This representation is obtained via a set of interchangeable modules called \\emph{slots} or \\emph{object files} that compete for local patches of an image. The competition has a weak inductive bias to preserve spatial continuity; consequently, one slot may claim patches scattered diffusely throughout the image. In contrast, the inductive bias of human vision is strong, to the degree that attention has classically been described with a spotlight metaphor. We incorporate a spatial-locality prior into state-of-the-art object-centric vision models and obtain significant improvements in segmenting objects in both synthetic and real-world datasets. Similar to human visual attention, the combination of image content and spatial constraints yield robust unsupervised object-centric learning, including less sensitivity to model hyperparameters.",
    "path": "papers/23/05/2305.19550.json",
    "total_tokens": 874,
    "translated_title": "Spotlight Attention: 具备空间局部性先验的鲁棒目标中心学习",
    "translated_abstract": "目标中心视觉的目的是构建场景中物体的显式表示。这种表示是通过一组可互换的模块(称为slot或对象文件)获得的，它们竞争图像的局部补丁。该竞争具有弱感性偏差，以保持空间连续性;因此，一个slot可能会宣称在整个图像中散布的补丁。与此相反，人类视觉的感性偏差很强，到了注意力经典用聚光灯比喻的程度。我们将空间局部性先验融入现代目标中心视觉模型，从而在合成和真实数据集中获得显着的物体分割改进。类似于人类视觉注意力，图像内容和空间约束的组合产生了具有鲁棒性的无监督目标中心学习，包括对模型超参数不太敏感。",
    "tldr": "该论文提出了一个新的目标中心学习方法，通过加入空间局部性先验来提高模型的鲁棒性，使模型在合成和真实数据上实现了显著的物体分割改进，并且对模型超参数不太敏感。",
    "en_tdlr": "This paper proposes a new object-centric learning method that improves the robustness of the model by incorporating a spatial-locality prior, achieving significant improvements in object segmentation on both synthetic and real-world datasets, and being less sensitive to model hyperparameters."
}