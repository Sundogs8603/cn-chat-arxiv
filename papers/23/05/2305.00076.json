{
    "title": "HausaNLP at SemEval-2023 Task 10: Transfer Learning, Synthetic Data and Side-Information for Multi-Level Sexism Classification. (arXiv:2305.00076v1 [cs.CL])",
    "abstract": "We present the findings of our participation in the SemEval-2023 Task 10: Explainable Detection of Online Sexism (EDOS) task, a shared task on offensive language (sexism) detection on English Gab and Reddit dataset. We investigated the effects of transferring two language models: XLM-T (sentiment classification) and HateBERT (same domain -- Reddit) for multi-level classification into Sexist or not Sexist, and other subsequent sub-classifications of the sexist data. We also use synthetic classification of unlabelled dataset and intermediary class information to maximize the performance of our models. We submitted a system in Task A, and it ranked 49th with F1-score of 0.82. This result showed to be competitive as it only under-performed the best system by 0.052% F1-score.",
    "link": "http://arxiv.org/abs/2305.00076",
    "context": "Title: HausaNLP at SemEval-2023 Task 10: Transfer Learning, Synthetic Data and Side-Information for Multi-Level Sexism Classification. (arXiv:2305.00076v1 [cs.CL])\nAbstract: We present the findings of our participation in the SemEval-2023 Task 10: Explainable Detection of Online Sexism (EDOS) task, a shared task on offensive language (sexism) detection on English Gab and Reddit dataset. We investigated the effects of transferring two language models: XLM-T (sentiment classification) and HateBERT (same domain -- Reddit) for multi-level classification into Sexist or not Sexist, and other subsequent sub-classifications of the sexist data. We also use synthetic classification of unlabelled dataset and intermediary class information to maximize the performance of our models. We submitted a system in Task A, and it ranked 49th with F1-score of 0.82. This result showed to be competitive as it only under-performed the best system by 0.052% F1-score.",
    "path": "papers/23/05/2305.00076.json",
    "total_tokens": 783,
    "translated_title": "HausaNLP在SemEval-2023 Task 10中的应用：基于迁移学习、合成数据和辅助信息的多层次性别歧视分类",
    "translated_abstract": "本文介绍我们参与 SemEval-2023 Task 10 的结果，这是一项针对英文Gab和Reddit数据集进行恶意语言（性别歧视）分类的任务。我们研究了使用两个语言模型进行迁移学习的效果：XLM-T（情感分类）和HateBERT（相同领域--Reddit）。我们还利用未标记数据的合成分类和中间类信息来最大化模型的性能。我们在Task A中提交了一个系统，排名第49名，F1分数为0.82。这个结果表明它很有竞争力，因为它只比最佳系统低0.052％的F1得分。",
    "tldr": "本研究探讨了使用迁移学习、合成数据和辅助信息来进行多层次性别歧视分类，并在SemEval-2023 Task 10中取得了具有竞争力的结果。",
    "en_tdlr": "This study investigates multi-level sexism classification using transfer learning, synthetic data, and side-information. The proposed approach achieved competitive results in SemEval-2023 Task 10."
}