{
    "title": "PromptRank: Unsupervised Keyphrase Extraction Using Prompt. (arXiv:2305.04490v2 [cs.IR] UPDATED)",
    "abstract": "The keyphrase extraction task refers to the automatic selection of phrases from a given document to summarize its core content. State-of-the-art (SOTA) performance has recently been achieved by embedding-based algorithms, which rank candidates according to how similar their embeddings are to document embeddings. However, such solutions either struggle with the document and candidate length discrepancies or fail to fully utilize the pre-trained language model (PLM) without further fine-tuning. To this end, in this paper, we propose a simple yet effective unsupervised approach, PromptRank, based on the PLM with an encoder-decoder architecture. Specifically, PromptRank feeds the document into the encoder and calculates the probability of generating the candidate with a designed prompt by the decoder. We extensively evaluate the proposed PromptRank on six widely used benchmarks. PromptRank outperforms the SOTA approach MDERank, improving the F1 score relatively by 34.18%, 24.87%, and 17.57",
    "link": "http://arxiv.org/abs/2305.04490",
    "context": "Title: PromptRank: Unsupervised Keyphrase Extraction Using Prompt. (arXiv:2305.04490v2 [cs.IR] UPDATED)\nAbstract: The keyphrase extraction task refers to the automatic selection of phrases from a given document to summarize its core content. State-of-the-art (SOTA) performance has recently been achieved by embedding-based algorithms, which rank candidates according to how similar their embeddings are to document embeddings. However, such solutions either struggle with the document and candidate length discrepancies or fail to fully utilize the pre-trained language model (PLM) without further fine-tuning. To this end, in this paper, we propose a simple yet effective unsupervised approach, PromptRank, based on the PLM with an encoder-decoder architecture. Specifically, PromptRank feeds the document into the encoder and calculates the probability of generating the candidate with a designed prompt by the decoder. We extensively evaluate the proposed PromptRank on six widely used benchmarks. PromptRank outperforms the SOTA approach MDERank, improving the F1 score relatively by 34.18%, 24.87%, and 17.57",
    "path": "papers/23/05/2305.04490.json",
    "total_tokens": 953,
    "translated_title": "PromptRank: 使用prompt的无监督关键词提取",
    "translated_abstract": "关键词提取任务是指自动从给定文档中选择短语来总结其核心内容。最近，基于嵌入的算法取得了最先进的性能，它们根据候选短语的嵌入与文档嵌入的相似程度对其进行排序。然而，这些解决方案要么在文档和候选短语长度不一致时难以处理，要么在没有进一步微调的情况下无法充分利用预训练语言模型（PLM）。为此，在本文中，我们提出了一种简单而有效的无监督方法PromptRank，它基于具有编码器-解码器架构的PLM。具体而言，PromptRank将文档输入编码器，并通过解码器计算生成包含设计的prompt的候选短语的概率。我们在六个广泛使用的基准测试上对提出的PromptRank进行了广泛评估。PromptRank在F1分数上相对于最先进的MDERank方法分别提高了34.18％，24.87％和17.57％。",
    "tldr": "本文提出了一种基于预训练语言模型的简单有效无监督关键词提取方法PromptRank，相对于最先进的MDERank方法在三个基准测试上分别提高了34.18％，24.87％和17.57％的F1分数。",
    "en_tdlr": "This paper proposes a simple and effective unsupervised approach, PromptRank, for keyphrase extraction based on pre-trained language model. PromptRank outperforms the state-of-the-art approach MDERank, with relative improvements of 34.18%, 24.87%, and 17.57% on three benchmark datasets."
}