{
    "title": "Multimodal Contextualized Plan Prediction for Embodied Task Completion. (arXiv:2305.06485v1 [cs.RO])",
    "abstract": "Task planning is an important component of traditional robotics systems enabling robots to compose fine grained skills to perform more complex tasks. Recent work building systems for translating natural language to executable actions for task completion in simulated embodied agents is focused on directly predicting low level action sequences that would be expected to be directly executable by a physical robot. In this work, we instead focus on predicting a higher level plan representation for one such embodied task completion dataset - TEACh, under the assumption that techniques for high-level plan prediction from natural language are expected to be more transferable to physical robot systems. We demonstrate that better plans can be predicted using multimodal context, and that plan prediction and plan execution modules are likely dependent on each other and hence it may not be ideal to fully decouple them. Further, we benchmark execution of oracle plans to quantify the scope for improv",
    "link": "http://arxiv.org/abs/2305.06485",
    "context": "Title: Multimodal Contextualized Plan Prediction for Embodied Task Completion. (arXiv:2305.06485v1 [cs.RO])\nAbstract: Task planning is an important component of traditional robotics systems enabling robots to compose fine grained skills to perform more complex tasks. Recent work building systems for translating natural language to executable actions for task completion in simulated embodied agents is focused on directly predicting low level action sequences that would be expected to be directly executable by a physical robot. In this work, we instead focus on predicting a higher level plan representation for one such embodied task completion dataset - TEACh, under the assumption that techniques for high-level plan prediction from natural language are expected to be more transferable to physical robot systems. We demonstrate that better plans can be predicted using multimodal context, and that plan prediction and plan execution modules are likely dependent on each other and hence it may not be ideal to fully decouple them. Further, we benchmark execution of oracle plans to quantify the scope for improv",
    "path": "papers/23/05/2305.06485.json",
    "total_tokens": 898,
    "translated_title": "多模态上下文化任务计划预测",
    "translated_abstract": "任务规划是传统机器人系统的重要组成部分，使机器人能够组合细粒度技能来执行更复杂的任务。最近的工作构建系统，将自然语言转换为可执行行动，以在模拟的具身化代理中完成任务，重点是直接预测可通过物理机器人直接执行的低级别行动序列。在本文中，我们转而专注于预测较高层次的计划表示，用于TEACh这样的具身化完成任务数据集，假设从自然语言中获得高层次计划预测的技术预计对物理机器人系统更具可转移性。我们证明可以使用多模态上下文预测更好的计划，并且计划预测和计划执行模块可能相互依赖，因此完全解耦可能不是理想的。此外，我们对理想计划的执行进行基准测试，以量化计划预测的改进空间。",
    "tldr": "本文提出了一种用于具身化完成任务数据集的多模态上下文化任务计划预测方法，并证明能够使用多模态上下文预测更好的计划，另外计划预测和计划执行模块可能相互依赖，完全解耦可能不是理想的。",
    "en_tdlr": "This paper proposes a multimodal contextualized plan prediction method for embodied task completion dataset, and demonstrates that better plans can be predicted using multimodal context. It also shows that plan prediction and plan execution modules are likely dependent on each other, implying that fully decoupling them may not be ideal."
}