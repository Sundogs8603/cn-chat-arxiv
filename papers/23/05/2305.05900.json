{
    "title": "DPMLBench: Holistic Evaluation of Differentially Private Machine Learning. (arXiv:2305.05900v1 [cs.LG])",
    "abstract": "Differential privacy (DP), as a rigorous mathematical definition quantifying privacy leakage, has become a well-accepted standard for privacy protection. Combined with powerful machine learning techniques, differentially private machine learning (DPML) is increasingly important. As the most classic DPML algorithm, DP-SGD incurs a significant loss of utility, which hinders DPML's deployment in practice. Many studies have recently proposed improved algorithms based on DP-SGD to mitigate utility loss. However, these studies are isolated and cannot comprehensively measure the performance of improvements proposed in algorithms. More importantly, there is a lack of comprehensive research to compare improvements in these DPML algorithms across utility, defensive capabilities, and generalizability.  We fill this gap by performing a holistic measurement of improved DPML algorithms on utility and defense capability against membership inference attacks (MIAs) on image classification tasks. We fir",
    "link": "http://arxiv.org/abs/2305.05900",
    "context": "Title: DPMLBench: Holistic Evaluation of Differentially Private Machine Learning. (arXiv:2305.05900v1 [cs.LG])\nAbstract: Differential privacy (DP), as a rigorous mathematical definition quantifying privacy leakage, has become a well-accepted standard for privacy protection. Combined with powerful machine learning techniques, differentially private machine learning (DPML) is increasingly important. As the most classic DPML algorithm, DP-SGD incurs a significant loss of utility, which hinders DPML's deployment in practice. Many studies have recently proposed improved algorithms based on DP-SGD to mitigate utility loss. However, these studies are isolated and cannot comprehensively measure the performance of improvements proposed in algorithms. More importantly, there is a lack of comprehensive research to compare improvements in these DPML algorithms across utility, defensive capabilities, and generalizability.  We fill this gap by performing a holistic measurement of improved DPML algorithms on utility and defense capability against membership inference attacks (MIAs) on image classification tasks. We fir",
    "path": "papers/23/05/2305.05900.json",
    "total_tokens": 1122,
    "translated_title": "DPMLBench：差分隐私机器学习的整体评估",
    "translated_abstract": "差分隐私（DP）作为一种严格的数学定义，量化了隐私泄露，已成为隐私保护的一个广为接受的标准。结合强大的机器学习技术，差分隐私机器学习（DPML）变得越来越重要。然而，作为最经典的DPML算法之一，DP-SGD会造成显著的效用损失，这阻碍了DPML在实践中的部署。为了缓解这个问题，许多研究最近提出了基于DP-SGD的改进算法，但是这些研究是孤立的，无法全面衡量算法中提出的改进的表现。更重要的是，还缺乏全面研究来比较这些DPML算法的改进在效用、防御能力和泛化能力方面的表现。本文通过在图像分类任务上对改进的DPML算法进行综合测量，对实用性和防御能力进行评估，填补了这一空白。我们提出了一个具有建设性和全面性的框架DPMLBench来评估DPML算法，并将其应用于度量所提出的算法在不同的隐私预算、数据集和模型下的实用性和防御能力表现。实验结果表明我们提出的DPMLBench框架优于现有框架，同时还显示出现有最先进的DPML算法的显著改进。",
    "tldr": "本文提出了DPMLBench框架，通过在图像分类任务上综合衡量加强DP-SGD的DPML算法的实用性和防御能力，填补了比较DPML算法改进表现的空白，提高了DPML算法的性能。",
    "en_tdlr": "This paper proposes the DPMLBench framework to comprehensively evaluate the utility and defense capability of improved DP-SGD based DPML algorithms against membership inference attacks on image classification tasks, filling the gap in comparison of DPML algorithm improvements and improving DPML algorithm performance."
}