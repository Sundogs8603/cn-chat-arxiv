{
    "title": "CHBias: Bias Evaluation and Mitigation of Chinese Conversational Language Models. (arXiv:2305.11262v1 [cs.CL])",
    "abstract": "\\textit{\\textbf{\\textcolor{red}{Warning}:} This paper contains content that may be offensive or upsetting.} Pretrained conversational agents have been exposed to safety issues, exhibiting a range of stereotypical human biases such as gender bias. However, there are still limited bias categories in current research, and most of them only focus on English. In this paper, we introduce a new Chinese dataset, CHBias, for bias evaluation and mitigation of Chinese conversational language models. Apart from those previous well-explored bias categories, CHBias includes under-explored bias categories, such as ageism and appearance biases, which received less attention. We evaluate two popular pretrained Chinese conversational models, CDial-GPT and EVA2.0, using CHBias. Furthermore, to mitigate different biases, we apply several debiasing methods to the Chinese pretrained models. Experimental results show that these Chinese pretrained models are potentially risky for generating texts that contain",
    "link": "http://arxiv.org/abs/2305.11262",
    "context": "Title: CHBias: Bias Evaluation and Mitigation of Chinese Conversational Language Models. (arXiv:2305.11262v1 [cs.CL])\nAbstract: \\textit{\\textbf{\\textcolor{red}{Warning}:} This paper contains content that may be offensive or upsetting.} Pretrained conversational agents have been exposed to safety issues, exhibiting a range of stereotypical human biases such as gender bias. However, there are still limited bias categories in current research, and most of them only focus on English. In this paper, we introduce a new Chinese dataset, CHBias, for bias evaluation and mitigation of Chinese conversational language models. Apart from those previous well-explored bias categories, CHBias includes under-explored bias categories, such as ageism and appearance biases, which received less attention. We evaluate two popular pretrained Chinese conversational models, CDial-GPT and EVA2.0, using CHBias. Furthermore, to mitigate different biases, we apply several debiasing methods to the Chinese pretrained models. Experimental results show that these Chinese pretrained models are potentially risky for generating texts that contain",
    "path": "papers/23/05/2305.11262.json",
    "total_tokens": 877,
    "translated_title": "CHBias: 中文对话语言模型的偏差评估与缓解",
    "translated_abstract": "预训练的对话代理已被暴露出安全问题，表现出一系列刻板化的人类偏见，例如性别偏见。然而，在当前研究中仍存在有限的偏见类别，而且大部分只针对英文。在本文中，我们介绍了一个新的中文数据集 CHBias，用于评估和缓解中文对话语言模型的偏见。除了之前已经深入研究的偏见类别外，CHBias包括了一些不太受关注的偏见类别，例如年龄歧视和外貌偏见。我们利用 CHBias 评估了两个流行的中文预训练对话模型 CDial-GPT 和 EVA2.0。此外，为了缓解不同的偏见，我们采用了几种去偏方法来处理中文预训练模型。实验结果表明，这些中文预训练模型可能会产生含有偏见的文本。",
    "tldr": "本文介绍了一个新的中文数据集，CHBias，用于评估和缓解中文对话语言模型的偏见。实验结果表明，这些中文预训练模型可能会产生含有偏见的文本。"
}