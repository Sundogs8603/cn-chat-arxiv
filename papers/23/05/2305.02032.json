{
    "title": "Unsupervised Mutual Transformer Learning for Multi-Gigapixel Whole Slide Image Classification. (arXiv:2305.02032v1 [cs.CV])",
    "abstract": "Classification of gigapixel Whole Slide Images (WSIs) is an important prediction task in the emerging area of computational pathology. There has been a surge of research in deep learning models for WSI classification with clinical applications such as cancer detection or prediction of molecular mutations from WSIs. Most methods require expensive and labor-intensive manual annotations by expert pathologists. Weakly supervised Multiple Instance Learning (MIL) methods have recently demonstrated excellent performance; however, they still require large slide-level labeled training datasets that need a careful inspection of each slide by an expert pathologist. In this work, we propose a fully unsupervised WSI classification algorithm based on mutual transformer learning. Instances from gigapixel WSI (i.e., image patches) are transformed into a latent space and then inverse-transformed to the original space. Using the transformation loss, pseudo-labels are generated and cleaned using a transf",
    "link": "http://arxiv.org/abs/2305.02032",
    "context": "Title: Unsupervised Mutual Transformer Learning for Multi-Gigapixel Whole Slide Image Classification. (arXiv:2305.02032v1 [cs.CV])\nAbstract: Classification of gigapixel Whole Slide Images (WSIs) is an important prediction task in the emerging area of computational pathology. There has been a surge of research in deep learning models for WSI classification with clinical applications such as cancer detection or prediction of molecular mutations from WSIs. Most methods require expensive and labor-intensive manual annotations by expert pathologists. Weakly supervised Multiple Instance Learning (MIL) methods have recently demonstrated excellent performance; however, they still require large slide-level labeled training datasets that need a careful inspection of each slide by an expert pathologist. In this work, we propose a fully unsupervised WSI classification algorithm based on mutual transformer learning. Instances from gigapixel WSI (i.e., image patches) are transformed into a latent space and then inverse-transformed to the original space. Using the transformation loss, pseudo-labels are generated and cleaned using a transf",
    "path": "papers/23/05/2305.02032.json",
    "total_tokens": 975,
    "translated_title": "无监督互相转换学习用于多吉格像素全切片图像分类",
    "translated_abstract": "在计算病理学的新兴领域中，吉格像素全切片图像（WSI）的分类是一项重要的预测任务。深度学习模型在 WSI 分类方面的研究成果急剧增加，其中包括肿瘤检测或从 WSI 预测分子突变等临床应用。大多数方法需要由专家病理学家进行昂贵和劳动密集型的手动注释。弱监督的多实例学习（MIL）方法最近表现出优异的性能；然而，它们仍需要大量标记的训练数据集，这需要专业病理学家对每个切片进行仔细检查。在本研究中，我们提出了一种完全无监督的基于互相转换学习的 WSI 分类算法。来自吉格像素 WSI（即图像补丁）的实例被转换成潜在空间，然后被反向转换到原始空间。使用转换损失，产生伪标签，并使用基于转换器的聚类方法进行清理。我们提出的方法在两个公开可用的多吉格像素 WSI 数据集上实现了最先进的性能，而不需要任何手动注释。",
    "tldr": "该论文提出一种基于无监督互相转换学习的算法，用于多吉格像素全切片图像分类，无需手动注释即可实现最先进的性能。",
    "en_tdlr": "This paper proposes a fully unsupervised algorithm for multi-gigapixel whole slide image classification based on mutual transformer learning, achieving state-of-the-art performance on two publicly available datasets without any manual annotations."
}