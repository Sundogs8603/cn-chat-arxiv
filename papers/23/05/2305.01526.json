{
    "title": "Huatuo-26M, a Large-scale Chinese Medical QA Dataset. (arXiv:2305.01526v1 [cs.CL])",
    "abstract": "In this paper, we release a largest ever medical Question Answering (QA) dataset with 26 million QA pairs. We benchmark many existing approaches in our dataset in terms of both retrieval and generation. Experimental results show that the existing models perform far lower than expected and the released dataset is still challenging in the pre-trained language model era. Moreover, we also experimentally show the benefit of the proposed dataset in many aspects: (i) trained models for other QA datasets in a zero-shot fashion; and (ii) as external knowledge for retrieval-augmented generation (RAG); and (iii) improving existing pre-trained language models by using the QA pairs as a pre-training corpus in continued training manner. We believe that this dataset will not only contribute to medical research but also facilitate both the patients and clinical doctors. See \\url{https://github.com/FreedomIntelligence/Huatuo-26M}.",
    "link": "http://arxiv.org/abs/2305.01526",
    "context": "Title: Huatuo-26M, a Large-scale Chinese Medical QA Dataset. (arXiv:2305.01526v1 [cs.CL])\nAbstract: In this paper, we release a largest ever medical Question Answering (QA) dataset with 26 million QA pairs. We benchmark many existing approaches in our dataset in terms of both retrieval and generation. Experimental results show that the existing models perform far lower than expected and the released dataset is still challenging in the pre-trained language model era. Moreover, we also experimentally show the benefit of the proposed dataset in many aspects: (i) trained models for other QA datasets in a zero-shot fashion; and (ii) as external knowledge for retrieval-augmented generation (RAG); and (iii) improving existing pre-trained language models by using the QA pairs as a pre-training corpus in continued training manner. We believe that this dataset will not only contribute to medical research but also facilitate both the patients and clinical doctors. See \\url{https://github.com/FreedomIntelligence/Huatuo-26M}.",
    "path": "papers/23/05/2305.01526.json",
    "total_tokens": 865,
    "translated_title": "Huatuo-26M：一份大规模的中医问答数据集",
    "translated_abstract": "本文中，我们发布了一份有着2600万个问答对的中医问答数据集，此为迄今为止最大型的数据集。我们以检索和生成两个方面对现有方法在此数据集上进行了基准测试。实验结果表明，现有模型的表现远低于预期，而且在预训练语言模型时代，发布的数据集仍然具有挑战性。此外，我们还实验性地展示了所提议数据集在以下方面的益处：（i）以零-shot的方式为其他问答数据集训练模型；（ii）作为检索增强生成（RAG）的外部知识；（iii）通过将问答对作为预训练语料库进行连续训练方式，提升现有预训练语言模型的性能。我们相信该数据集不仅将有助于医学研究，还将促进病人和临床医生的服务。请参考：\\url{https://github.com/FreedomIntelligence/Huatuo-26M}。",
    "tldr": "我们发布了一份最大的中医问答数据集，现有模型的表现远低于预期。此数据集可以用于其他QA数据集的零-shot学习并用作检索增强生成（RAG）的外部知识，在预训练语言模型时代仍然具有挑战性。"
}