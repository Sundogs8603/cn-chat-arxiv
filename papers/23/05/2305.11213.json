{
    "title": "Information-Ordered Bottlenecks for Adaptive Semantic Compression. (arXiv:2305.11213v1 [cs.LG])",
    "abstract": "We present the information-ordered bottleneck (IOB), a neural layer designed to adaptively compress data into latent variables ordered by likelihood maximization. Without retraining, IOB nodes can be truncated at any bottleneck width, capturing the most crucial information in the first latent variables. Unifying several previous approaches, we show that IOBs achieve near-optimal compression for a given encoding architecture and can assign ordering to latent signals in a manner that is semantically meaningful. IOBs demonstrate a remarkable ability to compress embeddings of image and text data, leveraging the performance of SOTA architectures such as CNNs, transformers, and diffusion models. Moreover, we introduce a novel theory for estimating global intrinsic dimensionality with IOBs and show that they recover SOTA dimensionality estimates for complex synthetic data. Furthermore, we showcase the utility of these models for exploratory analysis through applications on heterogeneous datas",
    "link": "http://arxiv.org/abs/2305.11213",
    "context": "Title: Information-Ordered Bottlenecks for Adaptive Semantic Compression. (arXiv:2305.11213v1 [cs.LG])\nAbstract: We present the information-ordered bottleneck (IOB), a neural layer designed to adaptively compress data into latent variables ordered by likelihood maximization. Without retraining, IOB nodes can be truncated at any bottleneck width, capturing the most crucial information in the first latent variables. Unifying several previous approaches, we show that IOBs achieve near-optimal compression for a given encoding architecture and can assign ordering to latent signals in a manner that is semantically meaningful. IOBs demonstrate a remarkable ability to compress embeddings of image and text data, leveraging the performance of SOTA architectures such as CNNs, transformers, and diffusion models. Moreover, we introduce a novel theory for estimating global intrinsic dimensionality with IOBs and show that they recover SOTA dimensionality estimates for complex synthetic data. Furthermore, we showcase the utility of these models for exploratory analysis through applications on heterogeneous datas",
    "path": "papers/23/05/2305.11213.json",
    "total_tokens": 959,
    "translated_title": "自适应语义压缩的信息排序瓶颈",
    "translated_abstract": "我们提出了信息排序瓶颈（IOB），这是一个神经层，旨在通过最大化可能性对数据进行自适应压缩，将其压缩成按顺序排列的潜在变量。在不重新训练的情况下，IOB节点可以在任何瓶颈宽度处截断，捕捉前几个潜在变量中最关键的信息。通过统一几种先前的方法，我们发现IOB实现了针对给定编码体系结构的近乎最优压缩，并可按含义有意义的方式对潜在信号进行排序。IOB展示了压缩图像和文本数据嵌入的卓越能力，利用了先进的架构（如CNN、transformer和扩散模型）的性能。此外，我们引入了一种用IOB估计全局固有维度的新理论，并展示了它们恢复复杂合成数据的SOTA维度估计。此外，我们展示了这些模型在异质数据的探索性分析中的实用性。",
    "tldr": "本文提出了信息排序瓶颈（IOB）技术，可以在不重新训练的情况下将数据自适应地压缩为按顺序排列的潜在变量，具有高效压缩图像和文本数据的能力，并可以排序信号并对全局固有维度进行估计。",
    "en_tdlr": "This paper presents the information-ordered bottleneck (IOB) technique, which can adaptively compress data into latent variables ordered by likelihood maximization without retraining, achieving near-optimal compression. IOBs can compress embeddings of image and text data efficiently and assign ordering to latent signals in a semantically meaningful manner. The paper also introduces a novel theory for estimating global intrinsic dimensionality with IOBs and demonstrates their utility for exploratory analysis on heterogeneous data."
}