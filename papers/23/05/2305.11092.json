{
    "title": "Universal Domain Adaptation from Foundation Models. (arXiv:2305.11092v1 [cs.LG])",
    "abstract": "Foundation models (e.g., CLIP or DINOv2) have shown their impressive learning and transferring capabilities on a wide range of visual tasks, by training on a large corpus of data and adapting to specific downstream tasks. It is, however, interesting that foundation models have not been fully explored for universal domain adaptation (UniDA), which is to learn models using labeled data in a source domain and unlabeled data in a target one, such that the learned models can successfully adapt to the target data. In this paper, we make comprehensive empirical studies of state-of-the-art UniDA methods using foundation models. We first demonstrate that, while foundation models greatly improve the performance of the baseline methods that train the models on the source data alone, existing UniDA methods generally fail to improve over the baseline. This suggests that new research efforts are very necessary for UniDA using foundation models. To this end, we propose a very simple method of target ",
    "link": "http://arxiv.org/abs/2305.11092",
    "context": "Title: Universal Domain Adaptation from Foundation Models. (arXiv:2305.11092v1 [cs.LG])\nAbstract: Foundation models (e.g., CLIP or DINOv2) have shown their impressive learning and transferring capabilities on a wide range of visual tasks, by training on a large corpus of data and adapting to specific downstream tasks. It is, however, interesting that foundation models have not been fully explored for universal domain adaptation (UniDA), which is to learn models using labeled data in a source domain and unlabeled data in a target one, such that the learned models can successfully adapt to the target data. In this paper, we make comprehensive empirical studies of state-of-the-art UniDA methods using foundation models. We first demonstrate that, while foundation models greatly improve the performance of the baseline methods that train the models on the source data alone, existing UniDA methods generally fail to improve over the baseline. This suggests that new research efforts are very necessary for UniDA using foundation models. To this end, we propose a very simple method of target ",
    "path": "papers/23/05/2305.11092.json",
    "total_tokens": 832,
    "translated_title": "基于基础模型的通用域适应",
    "translated_abstract": "基础模型（例如CLIP或DINOv2）已经展现了在广泛视觉任务中卓越的学习和转移能力，通过在大型数据语料库上训练并适应特定的下游任务。然而，有趣的是，基础模型尚未完全探索通用域适应（UniDA），即使用源域标记数据和目标域未标记数据学习模型，使学习模型能够成功适应目标数据。在本文中，我们利用基础模型对现有状态下的UniDA方法进行了全面的实证研究。我们首先证明，尽管基础模型极大地提高了仅在源数据上训练模型的基准方法的性能，但现有的UniDA方法通常不能超越基准。这表明，使用基础模型的UniDA需要新的研究努力。为此，我们提出了一种非常简单的目标方法。",
    "tldr": "本论文对基于基础模型的通用域适应进行了研究，发现当前的UniDA方法无法超越基准表现，提出了一个简单的目标方法。",
    "en_tdlr": "This paper investigates universal domain adaptation using foundation models, and finds that existing UniDA methods fail to improve over baseline performance. A simple target method is proposed."
}