{
    "title": "Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings. (arXiv:2305.13571v1 [cs.CL])",
    "abstract": "The use of positional embeddings in transformer language models is widely accepted. However, recent research has called into question the necessity of such embeddings. We further extend this inquiry by demonstrating that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through the shrinkage of self-attention variance. To quantify this variance, we derive the underlying distribution of each step within a transformer layer. Through empirical validation using a fully pretrained model, we show that the variance shrinkage effect still persists after extensive gradient updates. Our findings serve to justify the decision to discard positional embeddings and thus facilitate more efficient pretraining of transformer language models.",
    "link": "http://arxiv.org/abs/2305.13571",
    "context": "Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings. (arXiv:2305.13571v1 [cs.CL])\nAbstract: The use of positional embeddings in transformer language models is widely accepted. However, recent research has called into question the necessity of such embeddings. We further extend this inquiry by demonstrating that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through the shrinkage of self-attention variance. To quantify this variance, we derive the underlying distribution of each step within a transformer layer. Through empirical validation using a fully pretrained model, we show that the variance shrinkage effect still persists after extensive gradient updates. Our findings serve to justify the decision to discard positional embeddings and thus facilitate more efficient pretraining of transformer language models.",
    "path": "papers/23/05/2305.13571.json",
    "total_tokens": 759,
    "translated_title": "在无位置嵌入的Transformer语言模型的自注意力方差中存在潜在的位置信息",
    "translated_abstract": "Transformer语言模型通常使用位置嵌入，然而最近的研究质疑此类嵌入的必要性。我们通过展示随机初始化且无位置嵌入的冻结Transformer语言模型通过自注意力方差的收缩内在地编码了强的位置信息，进一步扩展了这一问题。我们通过推导Transformer层内每一步的底层分布来量化这一方差。通过使用完全预训练过的模型进行实证验证，我们证明即使经过了大量的渐进式更新梯度，方差收缩效应仍然存在。我们的发现证明了放弃位置嵌入的决策，并促进Transformer语言模型更有效的预训练。",
    "tldr": "该论文展示了在无位置嵌入的Transformer语言模型的自注意力方差中存在潜在的位置信息，并证明丢弃位置嵌入的决策可促进Transformer语言模型的更有效预训练。"
}