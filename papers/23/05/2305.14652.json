{
    "title": "Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion. (arXiv:2305.14652v1 [cs.CL])",
    "abstract": "Video multimodal fusion aims to integrate multimodal signals in videos, such as visual, audio and text, to make a complementary prediction with multiple modalities contents. However, unlike other image-text multimodal tasks, video has longer multimodal sequences with more redundancy and noise in both visual and audio modalities. Prior denoising methods like forget gate are coarse in the granularity of noise filtering. They often suppress the redundant and noisy information at the risk of losing critical information. Therefore, we propose a denoising bottleneck fusion (DBF) model for fine-grained video multimodal fusion. On the one hand, we employ a bottleneck mechanism to filter out noise and redundancy with a restrained receptive field. On the other hand, we use a mutual information maximization module to regulate the filter-out module to preserve key information within different modalities. Our DBF model achieves significant improvement over current state-of-the-art baselines on mult",
    "link": "http://arxiv.org/abs/2305.14652",
    "context": "Title: Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion. (arXiv:2305.14652v1 [cs.CL])\nAbstract: Video multimodal fusion aims to integrate multimodal signals in videos, such as visual, audio and text, to make a complementary prediction with multiple modalities contents. However, unlike other image-text multimodal tasks, video has longer multimodal sequences with more redundancy and noise in both visual and audio modalities. Prior denoising methods like forget gate are coarse in the granularity of noise filtering. They often suppress the redundant and noisy information at the risk of losing critical information. Therefore, we propose a denoising bottleneck fusion (DBF) model for fine-grained video multimodal fusion. On the one hand, we employ a bottleneck mechanism to filter out noise and redundancy with a restrained receptive field. On the other hand, we use a mutual information maximization module to regulate the filter-out module to preserve key information within different modalities. Our DBF model achieves significant improvement over current state-of-the-art baselines on mult",
    "path": "papers/23/05/2305.14652.json",
    "total_tokens": 917,
    "translated_title": "基于最大化互信息的视频多模态融合去噪瓶颈模型",
    "translated_abstract": "视频多模态融合旨在将视频中的多模态信号（如视觉、音频和文本）整合，以使用多模态内容进行补充预测。然而，与其他图像-文本多模态任务不同，视频具有更长的多模态序列，在视觉和音频模态中存在更多的冗余和噪声。因此，我们提出了一种用于细粒度视频多模态融合的去噪瓶颈融合（DBF）模型。我们一方面采用瓶颈机制，以限制的感受野过滤噪声和冗余信息。另一方面，我们使用最大化互信息模块来调节过滤模块，以保留不同模态中的关键信息。我们的DBF模型在多语言视频分类任务中显著优于当前最先进的基准模型。",
    "tldr": "本文提出了一种基于去噪瓶颈和最大化互信息的视频多模态融合模型（DBF），该模型可以细粒度地过滤掉冗余和噪声信息，同时保留不同模态中的关键信息，并在多语言视频分类任务中表现出显著优越性。",
    "en_tdlr": "This paper proposes a Denoising Bottleneck Fusion (DBF) model for fine-grained video multimodal fusion, utilizing a bottleneck mechanism and mutual information maximization to filter out noise and redundancy while preserving key information within different modalities. The DBF model achieves significant improvement over current state-of-the-art baselines on multilingual video classification tasks."
}