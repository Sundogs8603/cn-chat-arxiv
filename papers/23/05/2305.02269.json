{
    "title": "M2-CTTS: End-to-End Multi-scale Multi-modal Conversational Text-to-Speech Synthesis. (arXiv:2305.02269v1 [cs.SD])",
    "abstract": "Conversational text-to-speech (TTS) aims to synthesize speech with proper prosody of reply based on the historical conversation. However, it is still a challenge to comprehensively model the conversation, and a majority of conversational TTS systems only focus on extracting global information and omit local prosody features, which contain important fine-grained information like keywords and emphasis. Moreover, it is insufficient to only consider the textual features, and acoustic features also contain various prosody information. Hence, we propose M2-CTTS, an end-to-end multi-scale multi-modal conversational text-to-speech system, aiming to comprehensively utilize historical conversation and enhance prosodic expression. More specifically, we design a textual context module and an acoustic context module with both coarse-grained and fine-grained modeling. Experimental results demonstrate that our model mixed with fine-grained context information and additionally considering acoustic fea",
    "link": "http://arxiv.org/abs/2305.02269",
    "context": "Title: M2-CTTS: End-to-End Multi-scale Multi-modal Conversational Text-to-Speech Synthesis. (arXiv:2305.02269v1 [cs.SD])\nAbstract: Conversational text-to-speech (TTS) aims to synthesize speech with proper prosody of reply based on the historical conversation. However, it is still a challenge to comprehensively model the conversation, and a majority of conversational TTS systems only focus on extracting global information and omit local prosody features, which contain important fine-grained information like keywords and emphasis. Moreover, it is insufficient to only consider the textual features, and acoustic features also contain various prosody information. Hence, we propose M2-CTTS, an end-to-end multi-scale multi-modal conversational text-to-speech system, aiming to comprehensively utilize historical conversation and enhance prosodic expression. More specifically, we design a textual context module and an acoustic context module with both coarse-grained and fine-grained modeling. Experimental results demonstrate that our model mixed with fine-grained context information and additionally considering acoustic fea",
    "path": "papers/23/05/2305.02269.json",
    "total_tokens": 978,
    "translated_title": "M2-CTTS：端到端多尺度多模态会话文本到语音合成",
    "translated_abstract": "会话式文本到语音合成（TTS）旨在根据历史对话合成具有适当语调的回复语音。然而，全面建模对话仍然是一个挑战，大多数会话式TTS系统只关注提取全局信息并省略本地语调特征，而后者包含关键词和强调等重要的细粒度信息。此外，仅考虑文本特征是不足的，声学特征也包含各种语调信息。因此，我们提出了M2-CTTS，这是一个端到端多尺度多模态的会话文本到语音合成系统，旨在全面利用历史对话并增强语调表达。更具体地，我们设计了一个文本上下文模块和一个声学上下文模块，二者都进行了粗粒度和细粒度的建模。实验结果表明，我们的模型结合细粒度上下文信息并额外考虑声学特征可以有效增强会话式TTS性能，并在各种评估指标上优于几种最先进的模型。",
    "tldr": "M2-CTTS是一个端到端的多尺度多模态的会话文本到语音合成系统，相比于其他系统，它采用了粗粒度和细粒度的建模来全面利用历史对话，同时还考虑了声学特征，能够有效提高会话式TTS性能。",
    "en_tdlr": "M2-CTTS is an end-to-end multi-scale multi-modal conversational text-to-speech system that comprehensively utilizes historical conversation, enhances prosodic expression, and outperforms several state-of-the-art models by adopting both coarse-grained and fine-grained modeling and considering acoustic features."
}