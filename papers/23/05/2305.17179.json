{
    "title": "Tokenization Impacts Multilingual Language Modeling: Assessing Vocabulary Allocation and Overlap Across Languages. (arXiv:2305.17179v1 [cs.CL])",
    "abstract": "Multilingual language models have recently gained attention as a promising solution for representing multiple languages in a single model. In this paper, we propose new criteria to evaluate the quality of lexical representation and vocabulary overlap observed in sub-word tokenizers. Our findings show that the overlap of vocabulary across languages can be actually detrimental to certain downstream tasks (POS, dependency tree labeling). In contrast, NER and sentence-level tasks (cross-lingual retrieval, NLI) benefit from sharing vocabulary. We also observe that the coverage of the language-specific tokens in the multilingual vocabulary significantly impacts the word-level tasks. Our study offers a deeper understanding of the role of tokenizers in multilingual language models and guidelines for future model developers to choose the most suitable tokenizer for their specific application before undertaking costly model pre-training",
    "link": "http://arxiv.org/abs/2305.17179",
    "context": "Title: Tokenization Impacts Multilingual Language Modeling: Assessing Vocabulary Allocation and Overlap Across Languages. (arXiv:2305.17179v1 [cs.CL])\nAbstract: Multilingual language models have recently gained attention as a promising solution for representing multiple languages in a single model. In this paper, we propose new criteria to evaluate the quality of lexical representation and vocabulary overlap observed in sub-word tokenizers. Our findings show that the overlap of vocabulary across languages can be actually detrimental to certain downstream tasks (POS, dependency tree labeling). In contrast, NER and sentence-level tasks (cross-lingual retrieval, NLI) benefit from sharing vocabulary. We also observe that the coverage of the language-specific tokens in the multilingual vocabulary significantly impacts the word-level tasks. Our study offers a deeper understanding of the role of tokenizers in multilingual language models and guidelines for future model developers to choose the most suitable tokenizer for their specific application before undertaking costly model pre-training",
    "path": "papers/23/05/2305.17179.json",
    "total_tokens": 941,
    "translated_title": "分词对多语言语言建模的影响：评估跨语言词汇分配和重叠的新标准",
    "translated_abstract": "最近，多语言语言模型作为将多种语言表示为一个模型的有前途的解决方案而受到关注。本文提出了评估子词分词器中词汇表示和词汇重叠质量的新标准。研究发现，跨语言词汇的重叠实际上会对某些下游任务（POS，依赖树标注）产生不利影响。相反，共享词汇有助于NER和句子级任务（跨语言检索，NLI）。我们还观察到，多语言词汇中的语言特定标记覆盖范围显着影响单词级任务。本研究为深入了解分词器在多语言语言模型中的作用并为未来模型开发人员选择适合其特定应用的最合适的分词器提供指南。",
    "tldr": "本论文提出了新的标准来评估多语言语言模型中分词器的质量，并发现跨语言词汇的重叠会对某些下游任务产生不利影响，但共享词汇有助于其他任务。研究还发现，多语言词汇中的语言特定标记覆盖范围对单词级任务产生显著影响。这些发现对未来的模型开发人员选择最合适的分词器提供了指南。",
    "en_tdlr": "This paper proposes new criteria to evaluate the quality of lexical representation and vocabulary overlap observed in sub-word tokenizers in multilingual language models. The study finds that vocabulary overlap across languages can be detrimental to certain downstream tasks but beneficial for others, offering guidelines for future model development."
}