{
    "title": "MrTF: Model Refinery for Transductive Federated Learning. (arXiv:2305.04201v1 [cs.LG])",
    "abstract": "We consider a real-world scenario in which a newly-established pilot project needs to make inferences for newly-collected data with the help of other parties under privacy protection policies. Current federated learning (FL) paradigms are devoted to solving the data heterogeneity problem without considering the to-be-inferred data. We propose a novel learning paradigm named transductive federated learning (TFL) to simultaneously consider the structural information of the to-be-inferred data. On the one hand, the server could use the pre-available test samples to refine the aggregated models for robust model fusion, which tackles the data heterogeneity problem in FL. On the other hand, the refinery process incorporates test samples into training and could generate better predictions in a transductive manner. We propose several techniques including stabilized teachers, rectified distillation, and clustered label refinery to facilitate the model refinery process. Abundant experimental stu",
    "link": "http://arxiv.org/abs/2305.04201",
    "context": "Title: MrTF: Model Refinery for Transductive Federated Learning. (arXiv:2305.04201v1 [cs.LG])\nAbstract: We consider a real-world scenario in which a newly-established pilot project needs to make inferences for newly-collected data with the help of other parties under privacy protection policies. Current federated learning (FL) paradigms are devoted to solving the data heterogeneity problem without considering the to-be-inferred data. We propose a novel learning paradigm named transductive federated learning (TFL) to simultaneously consider the structural information of the to-be-inferred data. On the one hand, the server could use the pre-available test samples to refine the aggregated models for robust model fusion, which tackles the data heterogeneity problem in FL. On the other hand, the refinery process incorporates test samples into training and could generate better predictions in a transductive manner. We propose several techniques including stabilized teachers, rectified distillation, and clustered label refinery to facilitate the model refinery process. Abundant experimental stu",
    "path": "papers/23/05/2305.04201.json",
    "total_tokens": 976,
    "translated_title": "MrTF：面向传输联邦学习的模型精炼方法",
    "translated_abstract": "本文考虑了一个现实世界的场景，即在隐私保护政策下，一个新成立的试点项目需要借助其他方的帮助对新收集的数据进行推断。当前的联邦学习（FL）范例致力于解决数据异构问题，而没有考虑要推导的数据。我们提出了一种新的学习范例，称为传输联邦学习（TFL），以同时考虑要推导数据的结构信息。一方面，服务器可以使用预先可用的测试样本来优化合并模型，从而解决FL中的数据异构问题。另一方面，精炼过程将测试样本纳入训练中，并可以以传输方式生成更好的预测。我们提出了几种技术，包括稳定的教师、修正的蒸馏和聚类标签精炼，以促进模型精炼过程。大量的实验研究证明了我们提出的方法在各种设置中优于现有方法。",
    "tldr": "本文提出了一种名为传输联邦学习的新学习范例，以同时考虑数据异构和要推导数据的结构信息。采用稳定的教师、修正的蒸馏和聚类标签精炼等技术来促进模型精炼过程，并在大量实验中证明了该方法的优越性。",
    "en_tdlr": "This paper proposes a new learning paradigm called Transductive Federated Learning (TFL) that considers both the data heterogeneity and the structural information of the to-be-inferred data. The proposed approach uses techniques such as stabilized teachers, rectified distillation, and clustered label refinery to facilitate the model refinery process and outperforms state-of-the-art methods in various settings based on abundant experimental studies."
}