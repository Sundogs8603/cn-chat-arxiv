{
    "title": "Learning Rate Free Bayesian Inference in Constrained Domains. (arXiv:2305.14943v1 [stat.ML])",
    "abstract": "We introduce a suite of new particle-based algorithms for sampling on constrained domains which are entirely learning rate free. Our approach leverages coin betting ideas from convex optimisation, and the viewpoint of constrained sampling as a mirrored optimisation problem on the space of probability measures. Based on this viewpoint, we also introduce a unifying framework for several existing constrained sampling algorithms, including mirrored Langevin dynamics and mirrored Stein variational gradient descent. We demonstrate the performance of our algorithms on a range of numerical examples, including sampling from targets on the simplex, sampling with fairness constraints, and constrained sampling problems in post-selection inference. Our results indicate that our algorithms achieve competitive performance with existing constrained sampling methods, without the need to tune any hyperparameters.",
    "link": "http://arxiv.org/abs/2305.14943",
    "context": "Title: Learning Rate Free Bayesian Inference in Constrained Domains. (arXiv:2305.14943v1 [stat.ML])\nAbstract: We introduce a suite of new particle-based algorithms for sampling on constrained domains which are entirely learning rate free. Our approach leverages coin betting ideas from convex optimisation, and the viewpoint of constrained sampling as a mirrored optimisation problem on the space of probability measures. Based on this viewpoint, we also introduce a unifying framework for several existing constrained sampling algorithms, including mirrored Langevin dynamics and mirrored Stein variational gradient descent. We demonstrate the performance of our algorithms on a range of numerical examples, including sampling from targets on the simplex, sampling with fairness constraints, and constrained sampling problems in post-selection inference. Our results indicate that our algorithms achieve competitive performance with existing constrained sampling methods, without the need to tune any hyperparameters.",
    "path": "papers/23/05/2305.14943.json",
    "total_tokens": 793,
    "translated_title": "学习率无关的约束域Bayesian推断",
    "translated_abstract": "我们引入了一套新的基于粒子的算法，用于在约束域内进行采样，这是完全与学习率无关的。我们的方法利用了凸优化中的硬币投注思想，以及约束采样作为概率测度空间上镜像优化问题的观点。基于这个观点，我们还提出了一个统一框架，用于几种现有的约束采样算法，包括镜像Langevin动力学和镜像Stein变分梯度下降。我们在一系列的数值实验中展示了算法的性能，包括从单纯形目标进行采样、带公平性约束进行采样以及后选择推断中的约束采样问题。我们的结果表明，我们的算法在不需要调整任何超参数的情况下，实现了与现有约束采样方法相竞争的性能。",
    "tldr": "我们的算法是学习率无关的约束域采样算法，并提出了一个统一框架，能够处理多种约束采样问题，实现了与现有算法相竞争的性能。",
    "en_tdlr": "Our algorithm is a learning rate-free constrained domain sampling method, and we propose a unified framework to handle various constrained sampling problems, achieving competitive performance with existing methods without hyperparameter tuning."
}