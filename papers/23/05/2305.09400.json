{
    "title": "Consistent Multi-Granular Rationale Extraction for Explainable Multi-hop Fact Verification. (arXiv:2305.09400v1 [cs.CL])",
    "abstract": "The success of deep learning models on multi-hop fact verification has prompted researchers to understand the behavior behind their veracity. One possible way is erasure search: obtaining the rationale by entirely removing a subset of input without compromising the veracity prediction. Although extensively explored, existing approaches fall within the scope of the single-granular (tokens or sentences) explanation, which inevitably leads to explanation redundancy and inconsistency. To address such issues, this paper explores the viability of multi-granular rationale extraction with consistency and faithfulness for explainable multi-hop fact verification. In particular, given a pretrained veracity prediction model, both the token-level explainer and sentence-level explainer are trained simultaneously to obtain multi-granular rationales via differentiable masking. Meanwhile, three diagnostic properties (fidelity, consistency, salience) are introduced and applied to the training process, t",
    "link": "http://arxiv.org/abs/2305.09400",
    "context": "Title: Consistent Multi-Granular Rationale Extraction for Explainable Multi-hop Fact Verification. (arXiv:2305.09400v1 [cs.CL])\nAbstract: The success of deep learning models on multi-hop fact verification has prompted researchers to understand the behavior behind their veracity. One possible way is erasure search: obtaining the rationale by entirely removing a subset of input without compromising the veracity prediction. Although extensively explored, existing approaches fall within the scope of the single-granular (tokens or sentences) explanation, which inevitably leads to explanation redundancy and inconsistency. To address such issues, this paper explores the viability of multi-granular rationale extraction with consistency and faithfulness for explainable multi-hop fact verification. In particular, given a pretrained veracity prediction model, both the token-level explainer and sentence-level explainer are trained simultaneously to obtain multi-granular rationales via differentiable masking. Meanwhile, three diagnostic properties (fidelity, consistency, salience) are introduced and applied to the training process, t",
    "path": "papers/23/05/2305.09400.json",
    "total_tokens": 886,
    "translated_abstract": "深度学习模型在多跳事实验证上的成功促使研究者们了解其真实性背后的行为。一种可能的方式是擦除搜索：通过完全删除一部分输入来获得理由，而不会影响真实性预测。虽然已经广泛探索，但现有方法都属于单粒度（标记或句子）解释的范畴，这不可避免地导致解释冗余和不一致性。为了解决这些问题，本文探讨了带有一致性和忠实度的多粒度理由提取的可行性，以用于解释性多跳事实验证。具体来说，给定预训练的真实性预测模型，同时训练标记级别的解释器和句子级别的解释器，通过可微分蒙版获得多粒度理由。同时，引入并应用三个诊断属性（忠实度、一致性、显著性）到训练过程中，以提高解释的质量。",
    "tldr": "本文研究了解释性多跳事实验证中一致性的多粒度理由提取方法，通过训练标记级别和句子级别的解释器，获得了更高质量的解释。",
    "en_tdlr": "This paper explores the viability of multi-granular rationale extraction with consistency and faithfulness for explainable multi-hop fact verification, by training both token-level and sentence-level explainers simultaneously to obtain higher quality explanations."
}