{
    "title": "Learn to Unlearn: A Survey on Machine Unlearning. (arXiv:2305.07512v1 [cs.LG])",
    "abstract": "Machine Learning (ML) models contain private information, and implementing the right to be forgotten is a challenging privacy issue in many data applications. Machine unlearning has emerged as an alternative to remove sensitive data from a trained model, but completely retraining ML models is often not feasible. This survey provides a concise appraisal of Machine Unlearning techniques, encompassing both exact and approximate methods, probable attacks, and verification approaches. The survey compares the merits and limitations each method and evaluates their performance using the Deltagrad exact machine unlearning method. The survey also highlights challenges like the pressing need for a robust model for non-IID deletion to mitigate fairness issues. Overall, the survey provides a thorough synopsis of machine unlearning techniques and applications, noting future research directions in this evolving field. The survey aims to be a valuable resource for researchers and practitioners seeking",
    "link": "http://arxiv.org/abs/2305.07512",
    "context": "Title: Learn to Unlearn: A Survey on Machine Unlearning. (arXiv:2305.07512v1 [cs.LG])\nAbstract: Machine Learning (ML) models contain private information, and implementing the right to be forgotten is a challenging privacy issue in many data applications. Machine unlearning has emerged as an alternative to remove sensitive data from a trained model, but completely retraining ML models is often not feasible. This survey provides a concise appraisal of Machine Unlearning techniques, encompassing both exact and approximate methods, probable attacks, and verification approaches. The survey compares the merits and limitations each method and evaluates their performance using the Deltagrad exact machine unlearning method. The survey also highlights challenges like the pressing need for a robust model for non-IID deletion to mitigate fairness issues. Overall, the survey provides a thorough synopsis of machine unlearning techniques and applications, noting future research directions in this evolving field. The survey aims to be a valuable resource for researchers and practitioners seeking",
    "path": "papers/23/05/2305.07512.json",
    "total_tokens": 921,
    "translated_title": "学习去学习：机器去学习的综述",
    "translated_abstract": "机器学习模型包含私密信息，实现被遗忘权是许多数据应用的难题。机器去学习已成为从训练模型中删除敏感数据的替代方法，但重新训练机器学习模型往往是不可行的。本综述提供了机器去学习技术的简要评估，涵盖了精确和近似方法、可能的攻击以及验证方法。本综述比较了每种方法的优点和局限性，并使用Deltagrad精确机器去学习方法评估了它们的性能。本综述还强调了挑战，如非IID删除的强大模型，以缓解公平性问题。总的来说，本综述提供了机器去学习技术和应用的全面概述，并指出了这个不断发展的领域的未来研究方向。本综述旨在成为寻求机器去学习资料的研究人员和从业者的有价值资源。",
    "tldr": "本综述总结了机器去学习技术，用于从训练模型中删除敏感数据，但重新训练ML模型往往不可行。针对这个挑战，需要开发强大的模型以缓解公平性问题。",
    "en_tdlr": "This survey provides a concise appraisal of machine unlearning techniques, including exact and approximate methods, probable attacks, and verification approaches, and notes future research directions in this field. Machine unlearning has emerged as an alternative to remove sensitive data from trained models, but retraining is often not feasible. The survey underlines the need for robust models to mitigate fairness issues in non-IID deletion and compares the merits and limitations of each method."
}