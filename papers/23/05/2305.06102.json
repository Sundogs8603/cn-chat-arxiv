{
    "title": "Towards Better Graph Representation Learning with Parameterized Decomposition & Filtering. (arXiv:2305.06102v1 [cs.LG])",
    "abstract": "Proposing an effective and flexible matrix to represent a graph is a fundamental challenge that has been explored from multiple perspectives, e.g., filtering in Graph Fourier Transforms. In this work, we develop a novel and general framework which unifies many existing GNN models from the view of parameterized decomposition and filtering, and show how it helps to enhance the flexibility of GNNs while alleviating the smoothness and amplification issues of existing models. Essentially, we show that the extensively studied spectral graph convolutions with learnable polynomial filters are constrained variants of this formulation, and releasing these constraints enables our model to express the desired decomposition and filtering simultaneously. Based on this generalized framework, we develop models that are simple in implementation but achieve significant improvements and computational efficiency on a variety of graph learning tasks. Code is available at https://github.com/qslim/PDF.",
    "link": "http://arxiv.org/abs/2305.06102",
    "context": "Title: Towards Better Graph Representation Learning with Parameterized Decomposition & Filtering. (arXiv:2305.06102v1 [cs.LG])\nAbstract: Proposing an effective and flexible matrix to represent a graph is a fundamental challenge that has been explored from multiple perspectives, e.g., filtering in Graph Fourier Transforms. In this work, we develop a novel and general framework which unifies many existing GNN models from the view of parameterized decomposition and filtering, and show how it helps to enhance the flexibility of GNNs while alleviating the smoothness and amplification issues of existing models. Essentially, we show that the extensively studied spectral graph convolutions with learnable polynomial filters are constrained variants of this formulation, and releasing these constraints enables our model to express the desired decomposition and filtering simultaneously. Based on this generalized framework, we develop models that are simple in implementation but achieve significant improvements and computational efficiency on a variety of graph learning tasks. Code is available at https://github.com/qslim/PDF.",
    "path": "papers/23/05/2305.06102.json",
    "total_tokens": 918,
    "translated_title": "采用参数分解和滤波技术实现更好的图表征学习",
    "translated_abstract": "提出一种有效而灵活的矩阵来表示图形是一个基本的挑战，其已从多个角度进行了探索，例如，使用图傅里叶变换中的滤波。在本文中，我们从参数化分解和滤波的角度开发了一个新的通用框架，统一了许多现有的GNN模型，并展示了如何提高GNN的灵活性，同时减轻现有模型的平滑和放大问题。本质上，我们表明，具有可学习多项式滤波器的谱图卷积是这种表述的约束变体，放弃这些约束使我们的模型能够同时表达所需的分解和滤波。基于这个广义框架，我们开发的模型在实现上简单，但在各种图形学习任务中实现了显著的改进和计算效率。 代码可在 https://github.com/qslim/PDF 获得。",
    "tldr": "本研究提出一个新的通用框架，采用参数化分解和滤波，统一了现有的GNN模型，提高了GNN的灵活性，缓解了现有模型的平滑和放大问题，并开发了简单但有效的模型，在各种图形学习任务中实现了显著的改进和计算效率。",
    "en_tdlr": "This study proposes a new and general framework that unifies existing GNN models from the view of parameterized decomposition and filtering, enhancing the flexibility of GNNs and alleviating the smoothness and amplification issues of existing models. Simple yet effective models are developed and achieve significant improvements and computational efficiency on various graph learning tasks."
}