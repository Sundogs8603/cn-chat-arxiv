{
    "title": "Cooperative Thresholded Lasso for Sparse Linear Bandit. (arXiv:2305.19161v1 [cs.LG])",
    "abstract": "We present a novel approach to address the multi-agent sparse contextual linear bandit problem, in which the feature vectors have a high dimension $d$ whereas the reward function depends on only a limited set of features precisely $s_0 \\ll d$. Furthermore, the learning follows under information-sharing constraints. The proposed method employs Lasso regression for dimension reduction, allowing each agent to independently estimate an approximate set of main dimensions and share that information with others depending on the network's structure. The information is then aggregated through a specific process and shared with all agents. Each agent then resolves the problem with ridge regression focusing solely on the extracted dimensions. We represent algorithms for both a star-shaped network and a peer-to-peer network. The approaches effectively reduce communication costs while ensuring minimal cumulative regret per agent. Theoretically, we show that our proposed methods have a regret boun",
    "link": "http://arxiv.org/abs/2305.19161",
    "context": "Title: Cooperative Thresholded Lasso for Sparse Linear Bandit. (arXiv:2305.19161v1 [cs.LG])\nAbstract: We present a novel approach to address the multi-agent sparse contextual linear bandit problem, in which the feature vectors have a high dimension $d$ whereas the reward function depends on only a limited set of features precisely $s_0 \\ll d$. Furthermore, the learning follows under information-sharing constraints. The proposed method employs Lasso regression for dimension reduction, allowing each agent to independently estimate an approximate set of main dimensions and share that information with others depending on the network's structure. The information is then aggregated through a specific process and shared with all agents. Each agent then resolves the problem with ridge regression focusing solely on the extracted dimensions. We represent algorithms for both a star-shaped network and a peer-to-peer network. The approaches effectively reduce communication costs while ensuring minimal cumulative regret per agent. Theoretically, we show that our proposed methods have a regret boun",
    "path": "papers/23/05/2305.19161.json",
    "total_tokens": 1027,
    "translated_title": "合作阈值 Lasso 处理稀疏线性 Bandit 问题",
    "translated_abstract": "我们提出了一种新的方法来解决多智能体稀疏上下文线性 Bandit 问题，其中特征向量具有高维度 $d$，而奖励函数仅依赖于一组有限的特征，精确地为 $s_0 \\ll d$。此外，学习在信息共享约束下进行。所提出的方法采用 Lasso 回归进行降维，允许每个智能体独立估计一个近似的主维度集合，并根据网络结构与其他智能体共享该信息。然后通过特定的过程聚合信息并与所有智能体共享。然后，每个智能体只关注提取的维度，通过岭回归解决问题。我们提出了针对星形网络和点对点网络的算法。这些方法在确保每个智能体的最小累计遗憾的同时有效地降低了通信成本。理论上，我们证明了我们提出的方法具有 $O(s_0 \\sqrt{T \\log d})$ 和 $O(\\sqrt{s_0} \\sqrt{T \\log d})$ 的遗憾界，其中 $T$ 表示所有智能体玩游戏的回合数。",
    "tldr": "本论文提出了一种基于合作阈值 Lasso 的方法，解决多智能体稀疏上下文线性 Bandit 问题，该方法可以降维与信息共享，以降低通信成本，同时保证每个智能体的最小累计遗憾。",
    "en_tdlr": "This paper proposes a cooperative thresholded Lasso approach for addressing the multi-agent sparse contextual linear Bandit problem, which can reduce dimension and information sharing to lower communication costs while ensuring minimal cumulative regret per agent, with a regret bound of $O(s_0 \\sqrt{T \\log d})$ and $O(\\sqrt{s_0} \\sqrt{T \\log d})$ for specific network structures."
}