{
    "title": "Metric Tools for Sensitivity Analysis with Applications to Neural Networks. (arXiv:2305.02368v1 [cs.LG])",
    "abstract": "As Machine Learning models are considered for autonomous decisions with significant social impact, the need for understanding how these models work rises rapidly. Explainable Artificial Intelligence (XAI) aims to provide interpretations for predictions made by Machine Learning models, in order to make the model trustworthy and more transparent for the user. For example, selecting relevant input variables for the problem directly impacts the model's ability to learn and make accurate predictions, so obtaining information about input importance play a crucial role when training the model. One of the main XAI techniques to obtain input variable importance is the sensitivity analysis based on partial derivatives. However, existing literature of this method provide no justification of the aggregation metrics used to retrieved information from the partial derivatives.  In this paper, a theoretical framework is proposed to study sensitivities of ML models using metric techniques. From this me",
    "link": "http://arxiv.org/abs/2305.02368",
    "context": "Title: Metric Tools for Sensitivity Analysis with Applications to Neural Networks. (arXiv:2305.02368v1 [cs.LG])\nAbstract: As Machine Learning models are considered for autonomous decisions with significant social impact, the need for understanding how these models work rises rapidly. Explainable Artificial Intelligence (XAI) aims to provide interpretations for predictions made by Machine Learning models, in order to make the model trustworthy and more transparent for the user. For example, selecting relevant input variables for the problem directly impacts the model's ability to learn and make accurate predictions, so obtaining information about input importance play a crucial role when training the model. One of the main XAI techniques to obtain input variable importance is the sensitivity analysis based on partial derivatives. However, existing literature of this method provide no justification of the aggregation metrics used to retrieved information from the partial derivatives.  In this paper, a theoretical framework is proposed to study sensitivities of ML models using metric techniques. From this me",
    "path": "papers/23/05/2305.02368.json",
    "total_tokens": 862,
    "translated_title": "应用于神经网络的敏感性分析度量工具",
    "translated_abstract": "随着机器学习模型被考虑用于拥有重大社会影响的自主决策，了解这些模型如何工作的需求迅速增长。可解释人工智能(XAI)旨在为机器学习模型所做的预测提供解释，以使该模型对用户更具可信度和透明度。本文提出了一个理论框架，使用度量技巧来研究敏感度分析。从这个度量框架开始，介绍了新的聚合指标，以根据三种方法从偏导数中获取有价值的信息：局部扰动分析、全局扰动分析和混合方法。这些指标适用于任何可微分模型，并且它们的性能在神经网络模型上进行了说明。",
    "tldr": "本文提出了一种度量框架和新的聚合指标，用于敏感性分析，可以适用于任何可微分模型。其中新的聚合指标基于三种方法获取有价值的信息，并在神经网络模型上进行了验证。",
    "en_tdlr": "This paper proposes a metric framework and new aggregation metrics for sensitivity analysis, which are applicable to any differentiable model. These new aggregation metrics are based on three approaches and have been demonstrated on neural network models."
}