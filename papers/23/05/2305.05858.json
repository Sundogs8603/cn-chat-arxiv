{
    "title": "V\\=arta: A Large-Scale Headline-Generation Dataset for Indic Languages. (arXiv:2305.05858v1 [cs.CL])",
    "abstract": "We present V\\=arta, a large-scale multilingual dataset for headline generation in Indic languages. This dataset includes 41.8 million news articles in 14 different Indic languages (and English), which come from a variety of high-quality sources. To the best of our knowledge, this is the largest collection of curated articles for Indic languages currently available. We use the data collected in a series of experiments to answer important questions related to Indic NLP and multilinguality research in general. We show that the dataset is challenging even for state-of-the-art abstractive models and that they perform only slightly better than extractive baselines. Owing to its size, we also show that the dataset can be used to pretrain strong language models that outperform competitive baselines in both NLU and NLG benchmarks.",
    "link": "http://arxiv.org/abs/2305.05858",
    "context": "Title: V\\=arta: A Large-Scale Headline-Generation Dataset for Indic Languages. (arXiv:2305.05858v1 [cs.CL])\nAbstract: We present V\\=arta, a large-scale multilingual dataset for headline generation in Indic languages. This dataset includes 41.8 million news articles in 14 different Indic languages (and English), which come from a variety of high-quality sources. To the best of our knowledge, this is the largest collection of curated articles for Indic languages currently available. We use the data collected in a series of experiments to answer important questions related to Indic NLP and multilinguality research in general. We show that the dataset is challenging even for state-of-the-art abstractive models and that they perform only slightly better than extractive baselines. Owing to its size, we also show that the dataset can be used to pretrain strong language models that outperform competitive baselines in both NLU and NLG benchmarks.",
    "path": "papers/23/05/2305.05858.json",
    "total_tokens": 882,
    "translated_title": "V\\=arta：一个用于印度语言头条生成的大规模数据集",
    "translated_abstract": "本文介绍了 V\\=arta，这是一个用于印度语言头条生成的大规模多语言数据集。该数据集包含来自14种不同印度语言（和英语）的4180万条新闻文章，这些文章来自各种高质量来源。据我们所知，这是目前可用的印度语言精选文章最大的集合。我们使用收集到的数据进行一系列实验，以回答与印度语言处理和多语言研究相关的重要问题。我们表明即使对于最先进的抽象模型，该数据集也是有挑战性的，它们的表现也仅比抽取基线略优。由于其规模，我们还表明该数据集可用于预训练强语言模型，这些模型在自然语言理解和生成基准测试中均优于竞争基线。",
    "tldr": "本文介绍了一个用于印度语言头条生成的大规模多语言数据集 V\\=arta，包含来自14种不同印度语言（和英语）的4180万条新闻文章，可用于预训练强语言模型，并可用于回答与印度语言处理和多语言研究相关的重要问题。",
    "en_tdlr": "This paper introduces a large-scale multilingual dataset V\\=arta for headline generation in Indic languages, which includes 41.8 million news articles in 14 different Indic languages (and English), and can be used for pretraining strong language models and answering important questions related to Indic NLP and multilinguality research."
}