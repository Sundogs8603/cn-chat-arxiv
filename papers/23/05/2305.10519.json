{
    "title": "Statistical Knowledge Assessment for Generative Language Models. (arXiv:2305.10519v1 [cs.CL])",
    "abstract": "Generative Language Models (GLMs) have demonstrated capabilities to store factual knowledge and answer queries efficiently. Given varying prompts, does a GLM consistently generate factually correct answers? In this paper, we introduce a statistical knowledge assessment framework guided by latent variables and the KaRR metric, which quantifies a model's knowledge by computing its continuous probability across diverse text forms. We conduct a comprehensive comparison of knowledge across 14 GLMs using our framework, including LLaMA, Alpaca, OPT, and others. Our statistical knowledge assessment encompasses 600 relation types and exhibits a strong correlation (0.43 Kendall's $\\tau$) with human evaluation. Our findings reveal that the knowledge in GLMs with the same backbone architecture adheres to the scaling law, and that tuning on instruction-following data may compromise the model's ability to generate factually correct text consistently.",
    "link": "http://arxiv.org/abs/2305.10519",
    "context": "Title: Statistical Knowledge Assessment for Generative Language Models. (arXiv:2305.10519v1 [cs.CL])\nAbstract: Generative Language Models (GLMs) have demonstrated capabilities to store factual knowledge and answer queries efficiently. Given varying prompts, does a GLM consistently generate factually correct answers? In this paper, we introduce a statistical knowledge assessment framework guided by latent variables and the KaRR metric, which quantifies a model's knowledge by computing its continuous probability across diverse text forms. We conduct a comprehensive comparison of knowledge across 14 GLMs using our framework, including LLaMA, Alpaca, OPT, and others. Our statistical knowledge assessment encompasses 600 relation types and exhibits a strong correlation (0.43 Kendall's $\\tau$) with human evaluation. Our findings reveal that the knowledge in GLMs with the same backbone architecture adheres to the scaling law, and that tuning on instruction-following data may compromise the model's ability to generate factually correct text consistently.",
    "path": "papers/23/05/2305.10519.json",
    "total_tokens": 893,
    "translated_title": "生成式语言模型的统计知识评估",
    "translated_abstract": "生成式语言模型（GLMs）展示了存储事实知识和高效回答查询的能力。但是，给定不同的提示，GLM是否始终生成事实正确的答案？本文介绍了一个由潜变量和KaRR度量指导的统计知识评估框架，该度量通过计算模型在各种文本形式上的连续概率量化其知识。我们使用我们的框架对14种GLM的知识进行了全面比较，包括LLaMA、Alpaca、OPT和其他模型。我们的统计知识评估涵盖了600种关系类型，并显示出与人类评估的强相关性（0.43 Kendall's $\\tau$）。我们的发现揭示了具有相同支架结构的GLM的知识遵循缩放定律，并且在指令遵循数据上进行的微调可能会损害模型持续生成事实正确的文本的能力。",
    "tldr": "本文介绍了一个统计知识评估框架，用于评估生成式语言模型（GLMs）的知识输出。通过对14种GLMs进行综合比较，发现知识遵循缩放定律，而对指令遵循数据进行微调可能会损害模型的生成能力。",
    "en_tdlr": "This paper introduces a statistical knowledge assessment framework for evaluating the knowledge output of generative language models (GLMs). By conducting a comprehensive comparison of 14 GLMs, the study reveals that knowledge follows a scaling law and that tuning on instruction-following data may compromise the model's ability to generate factually correct text consistently."
}