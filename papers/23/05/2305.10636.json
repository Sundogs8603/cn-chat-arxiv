{
    "title": "Augmented Message Passing Stein Variational Gradient Descent. (arXiv:2305.10636v1 [cs.LG])",
    "abstract": "Stein Variational Gradient Descent (SVGD) is a popular particle-based method for Bayesian inference. However, its convergence suffers from the variance collapse, which reduces the accuracy and diversity of the estimation. In this paper, we study the isotropy property of finite particles during the convergence process and show that SVGD of finite particles cannot spread across the entire sample space. Instead, all particles tend to cluster around the particle center within a certain range and we provide an analytical bound for this cluster. To further improve the effectiveness of SVGD for high-dimensional problems, we propose the Augmented Message Passing SVGD (AUMP-SVGD) method, which is a two-stage optimization procedure that does not require sparsity of the target distribution, unlike the MP-SVGD method. Our algorithm achieves satisfactory accuracy and overcomes the variance collapse problem in various benchmark problems.",
    "link": "http://arxiv.org/abs/2305.10636",
    "context": "Title: Augmented Message Passing Stein Variational Gradient Descent. (arXiv:2305.10636v1 [cs.LG])\nAbstract: Stein Variational Gradient Descent (SVGD) is a popular particle-based method for Bayesian inference. However, its convergence suffers from the variance collapse, which reduces the accuracy and diversity of the estimation. In this paper, we study the isotropy property of finite particles during the convergence process and show that SVGD of finite particles cannot spread across the entire sample space. Instead, all particles tend to cluster around the particle center within a certain range and we provide an analytical bound for this cluster. To further improve the effectiveness of SVGD for high-dimensional problems, we propose the Augmented Message Passing SVGD (AUMP-SVGD) method, which is a two-stage optimization procedure that does not require sparsity of the target distribution, unlike the MP-SVGD method. Our algorithm achieves satisfactory accuracy and overcomes the variance collapse problem in various benchmark problems.",
    "path": "papers/23/05/2305.10636.json",
    "total_tokens": 899,
    "translated_title": "增强的消息传递斯坦变分梯度下降法",
    "translated_abstract": "Stein Variational Gradient Descent (SVGD)是一种用于贝叶斯推理的基于粒子的流行方法。然而，它的收敛性遭受方差崩溃的影响，这会降低估计的准确性和多样性。本文研究了收敛过程中有限粒子的等向性属性，表明有限粒子的SVGD无法在整个样本空间中传播。相反，所有粒子倾向于在一定范围内聚集在粒子中心周围，并且我们提供了此聚类的分析界限。为进一步改善SVGD在高维问题中的有效性，我们提出了增强消息传递斯坦变分梯度下降法(AUMP-SVGD)方法，这是一种两阶段优化过程，不需要目标分布的稀疏性，不像MP-SVGD方法。我们的算法在各种基准问题中实现了令人满意的准确性，并克服了方差崩溃问题。",
    "tldr": "本文提出了一种增强的消息传递斯坦变分梯度下降法(AUMP-SVGD)来应对 Stein Variational Gradient Descent (SVGD)方法的方差崩溃问题，我们的算法能够提高SVGD在高维问题中的有效性。",
    "en_tdlr": "This paper proposes an Augmented Message Passing SVGD (AUMP-SVGD) method to address the variance collapse problem in Stein Variational Gradient Descent (SVGD) and improve its effectiveness in high-dimensional problems. The algorithm achieves satisfactory accuracy in various benchmark problems."
}