{
    "title": "Joint Graph Learning and Model Fitting in Laplacian Regularized Stratified Models. (arXiv:2305.02573v1 [stat.ML])",
    "abstract": "Laplacian regularized stratified models (LRSM) are models that utilize the explicit or implicit network structure of the sub-problems as defined by the categorical features called strata (e.g., age, region, time, forecast horizon, etc.), and draw upon data from neighboring strata to enhance the parameter learning of each sub-problem. They have been widely applied in machine learning and signal processing problems, including but not limited to time series forecasting, representation learning, graph clustering, max-margin classification, and general few-shot learning. Nevertheless, existing works on LRSM have either assumed a known graph or are restricted to specific applications. In this paper, we start by showing the importance and sensitivity of graph weights in LRSM, and provably show that the sensitivity can be arbitrarily large when the parameter scales and sample sizes are heavily imbalanced across nodes. We then propose a generic approach to jointly learn the graph while fitting ",
    "link": "http://arxiv.org/abs/2305.02573",
    "context": "Title: Joint Graph Learning and Model Fitting in Laplacian Regularized Stratified Models. (arXiv:2305.02573v1 [stat.ML])\nAbstract: Laplacian regularized stratified models (LRSM) are models that utilize the explicit or implicit network structure of the sub-problems as defined by the categorical features called strata (e.g., age, region, time, forecast horizon, etc.), and draw upon data from neighboring strata to enhance the parameter learning of each sub-problem. They have been widely applied in machine learning and signal processing problems, including but not limited to time series forecasting, representation learning, graph clustering, max-margin classification, and general few-shot learning. Nevertheless, existing works on LRSM have either assumed a known graph or are restricted to specific applications. In this paper, we start by showing the importance and sensitivity of graph weights in LRSM, and provably show that the sensitivity can be arbitrarily large when the parameter scales and sample sizes are heavily imbalanced across nodes. We then propose a generic approach to jointly learn the graph while fitting ",
    "path": "papers/23/05/2305.02573.json",
    "total_tokens": 1100,
    "translated_title": "拉普拉斯正则化分层模型中的联合图学习和模型拟合",
    "translated_abstract": "拉普拉斯正则化分层模型（LRSM）是利用子问题的显式或隐式网络结构，由分类特征称为层（例如年龄、区域、时间、预测时间、等），并从相邻层中获取数据以增强每个子问题的参数学习。它们已广泛应用于机器学习和信号处理问题，包括但不限于时间序列预测，表示学习，图聚类，最大间隔分类和一般少量样本学习。然而，现有的LRSM研究要么假设已知图形，要么仅限于特定应用。在本文中，我们首先展示了LRSM中图权重的重要性和敏感性，并证明了当节点之间参数比例和样本量不平衡时，敏感性可能会任意增大。然后，我们提出了一种通用方法，在拟合模型的同时联合学习图，适用于广泛的LRSM问题。具体而言，我们制定了联合图学习和模型拟合问题，并通过交替学习图（通过稀疏逆协方差估计）和拟合模型（通过近端梯度下降）来解决它。我们的方法不仅在合成和真实世界数据集上实现了最先进的性能，还揭示了有关问题的有趣图案和结构。",
    "tldr": "本文提出了一种联合图学习和模型拟合的通用方法，适用于广泛的LRSM问题，并在合成和真实世界数据集上实现了最先进的性能。"
}