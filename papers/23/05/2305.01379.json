{
    "title": "LogSpecT: Feasible Graph Learning Model from Stationary Signals with Recovery Guarantees. (arXiv:2305.01379v1 [stat.ML])",
    "abstract": "Graph learning from signals is a core task in Graph Signal Processing (GSP). One of the most commonly used models to learn graphs from stationary signals is SpecT. However, its practical formulation rSpecT is known to be sensitive to hyperparameter selection and, even worse, to suffer from infeasibility. In this paper, we give the first condition that guarantees the infeasibility of rSpecT and design a novel model (LogSpecT) and its practical formulation (rLogSpecT) to overcome this issue. Contrary to rSpecT, the novel practical model rLogSpecT is always feasible. Furthermore, we provide recovery guarantees of rLogSpecT, which are derived from modern optimization tools related to epi-convergence. These tools could be of independent interest and significant for various learning problems. To demonstrate the advantages of rLogSpecT in practice, a highly efficient algorithm based on the linearized alternating direction method of multipliers (L-ADMM) is proposed. The subproblems of L-ADMM a",
    "link": "http://arxiv.org/abs/2305.01379",
    "context": "Title: LogSpecT: Feasible Graph Learning Model from Stationary Signals with Recovery Guarantees. (arXiv:2305.01379v1 [stat.ML])\nAbstract: Graph learning from signals is a core task in Graph Signal Processing (GSP). One of the most commonly used models to learn graphs from stationary signals is SpecT. However, its practical formulation rSpecT is known to be sensitive to hyperparameter selection and, even worse, to suffer from infeasibility. In this paper, we give the first condition that guarantees the infeasibility of rSpecT and design a novel model (LogSpecT) and its practical formulation (rLogSpecT) to overcome this issue. Contrary to rSpecT, the novel practical model rLogSpecT is always feasible. Furthermore, we provide recovery guarantees of rLogSpecT, which are derived from modern optimization tools related to epi-convergence. These tools could be of independent interest and significant for various learning problems. To demonstrate the advantages of rLogSpecT in practice, a highly efficient algorithm based on the linearized alternating direction method of multipliers (L-ADMM) is proposed. The subproblems of L-ADMM a",
    "path": "papers/23/05/2305.01379.json",
    "total_tokens": 956,
    "translated_title": "LogSpecT: 从平稳信号中学习可行的图形学习模型并具备恢复保证",
    "translated_abstract": "信号图形学习是图形信号处理（GSP）中的核心任务。学习平稳信号图形最常用的模型之一是SpecT。然而，它的实际公式rSpecT被认为对超参数选择敏感，并且更糟的是，容易无法实现。在本文中，我们首次给出保证rSpecT无法实现的条件，并设计了一种新模型（LogSpecT）及其实际公式（rLogSpecT）来解决这个问题。与rSpecT不同，新的实用模型rLogSpecT始终是可行的。此外，我们还提供了rLogSpecT的恢复保证，这些保证来自于与epi-converg​​ence相关的现代优化工具。这些工具对于各种学习问题都具有独立的利益和重要性。为了展示rLogSpecT在实践中的优点，我们提出了一种基于线性化交替方向乘子方法（L-ADMM）的高效算法。L-ADMM的子问题",
    "tldr": "本文提出了一种新的图形学习模型LogSpecT及其实际公式rLogSpecT，以解决现有模型rSpecT敏感超参数选择、不可行的问题。本文提供了rLogSpecT的恢复保证，并提出了基于L-ADMM的高效算法。",
    "en_tdlr": "This paper proposes a new graph learning model LogSpecT and its practical formulation rLogSpecT to address the sensitivity and infeasibility issues of the existing model rSpecT. Recovery guarantees of rLogSpecT are provided and an efficient algorithm based on L-ADMM is proposed."
}