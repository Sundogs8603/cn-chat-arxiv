{
    "title": "Memorization for Good: Encryption with Autoregressive Language Models. (arXiv:2305.10445v1 [cs.CL])",
    "abstract": "Over-parameterized neural language models (LMs) can memorize and recite long sequences of training data. While such memorization is normally associated with undesired properties such as overfitting and information leaking, our work casts memorization as an unexplored capability of LMs. We propose the first symmetric encryption algorithm with autoregressive language models (SELM). We show that autoregressive LMs can encode arbitrary data into a compact real-valued vector (i.e., encryption) and then losslessly decode the vector to the original message (i.e., decryption) via random subspace optimization and greedy decoding. While SELM is not amenable to conventional cryptanalysis, we investigate its security through a novel empirical variant of the classic IND-CPA (indistinguishability under chosen-plaintext attack) game. Our code and datasets are available at https://github.com/OSU-NLP-Group/SELM.",
    "link": "http://arxiv.org/abs/2305.10445",
    "context": "Title: Memorization for Good: Encryption with Autoregressive Language Models. (arXiv:2305.10445v1 [cs.CL])\nAbstract: Over-parameterized neural language models (LMs) can memorize and recite long sequences of training data. While such memorization is normally associated with undesired properties such as overfitting and information leaking, our work casts memorization as an unexplored capability of LMs. We propose the first symmetric encryption algorithm with autoregressive language models (SELM). We show that autoregressive LMs can encode arbitrary data into a compact real-valued vector (i.e., encryption) and then losslessly decode the vector to the original message (i.e., decryption) via random subspace optimization and greedy decoding. While SELM is not amenable to conventional cryptanalysis, we investigate its security through a novel empirical variant of the classic IND-CPA (indistinguishability under chosen-plaintext attack) game. Our code and datasets are available at https://github.com/OSU-NLP-Group/SELM.",
    "path": "papers/23/05/2305.10445.json",
    "total_tokens": 906,
    "translated_title": "记忆有益：自回归语言模型的加密",
    "translated_abstract": "过度参数化的神经语言模型（LM）可以记忆和背诵大量训练数据。虽然这种记忆通常被认为具有不良属性，例如过度拟合和信息泄漏，但我们的工作将记忆视为LM的一种未开发的能力。我们提出了第一个使用自回归语言模型进行对称加密的算法（SELM）。我们证明，自回归LM可以将任意数据编码为紧凑的实值向量（即加密），然后通过随机子空间优化和贪心解码将向量无损解码为原始消息（即解密）。虽然SELM不易受传统加密分析方法攻破，但我们通过一种新颖的实证变体，研究它的安全性。我们的代码和数据集可在https://github.com/OSU-NLP-Group/SELM 上获得。",
    "tldr": "该论文提出了第一个使用自回归语言模型进行对称加密的算法（SELM），其中算法可以将任意数据编码为紧凑的实值向量（即加密），然后通过随机子空间优化和贪心解码将向量无损解码为原始消息（即解密），并且SELM在加密分析方面的安全性能较高。",
    "en_tdlr": "The paper proposes the first symmetric encryption algorithm with autoregressive language models (SELM), which can encode arbitrary data into a compact real-valued vector (i.e., encryption) and then decode the vector to the original message losslessly (i.e., decryption) via random subspace optimization and greedy decoding. SELM is highly secure against cryptanalysis."
}