{
    "title": "Blank-regularized CTC for Frame Skipping in Neural Transducer. (arXiv:2305.11558v1 [eess.AS])",
    "abstract": "Neural Transducer and connectionist temporal classification (CTC) are popular end-to-end automatic speech recognition systems. Due to their frame-synchronous design, blank symbols are introduced to address the length mismatch between acoustic frames and output tokens, which might bring redundant computation. Previous studies managed to accelerate the training and inference of neural Transducers by discarding frames based on the blank symbols predicted by a co-trained CTC. However, there is no guarantee that the co-trained CTC can maximize the ratio of blank symbols. This paper proposes two novel regularization methods to explicitly encourage more blanks by constraining the self-loop of non-blank symbols in the CTC. It is interesting to find that the frame reduction ratio of the neural Transducer can approach the theoretical boundary. Experiments on LibriSpeech corpus show that our proposed method accelerates the inference of neural Transducer by 4 times without sacrificing performance.",
    "link": "http://arxiv.org/abs/2305.11558",
    "context": "Title: Blank-regularized CTC for Frame Skipping in Neural Transducer. (arXiv:2305.11558v1 [eess.AS])\nAbstract: Neural Transducer and connectionist temporal classification (CTC) are popular end-to-end automatic speech recognition systems. Due to their frame-synchronous design, blank symbols are introduced to address the length mismatch between acoustic frames and output tokens, which might bring redundant computation. Previous studies managed to accelerate the training and inference of neural Transducers by discarding frames based on the blank symbols predicted by a co-trained CTC. However, there is no guarantee that the co-trained CTC can maximize the ratio of blank symbols. This paper proposes two novel regularization methods to explicitly encourage more blanks by constraining the self-loop of non-blank symbols in the CTC. It is interesting to find that the frame reduction ratio of the neural Transducer can approach the theoretical boundary. Experiments on LibriSpeech corpus show that our proposed method accelerates the inference of neural Transducer by 4 times without sacrificing performance.",
    "path": "papers/23/05/2305.11558.json",
    "total_tokens": 876,
    "translated_title": "在神经转录器中使用空白正则化CTC解决帧跳过问题",
    "translated_abstract": "神经转录器和连接时序分类（CTC）都是常见的端到端语音识别系统。由于其基于帧同步设计，引入了空白符号以解决声学帧和输出令牌之间的长度不匹配，这可能带来冗余计算。先前的研究通过丢弃由联合训练的CTC预测的空白符号，来加速神经转录器的训练和推理。然而，联合训练的CTC不能保证最大化空白符号的比例。本文提出了两种新的正则化方法，通过限制CTC中的非空白符号的自环，明确地鼓励更多的空白符号。有趣的是，神经转录器的帧降低率可以接近理论边界。在LibriSpeech语料库上的实验表明，我们的方法可以在不降低性能的情况下将神经转录器的推理加速4倍。",
    "tldr": "本文提出两种新的正则化方法，通过限制CTC中的非空白符号的自环，明确地鼓励更多的空白符号，并成功将神经转录器的推理加速4倍，而不降低性能。",
    "en_tdlr": "This paper proposes two novel regularization methods to explicitly encourage more blanks by constraining the self-loop of non-blank symbols in the CTC, and successfully accelerates the inference of the neural transducer by 4 times without sacrificing performance."
}