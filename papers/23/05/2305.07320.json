{
    "title": "ActUp: Analyzing and Consolidating tSNE and UMAP. (arXiv:2305.07320v1 [cs.LG])",
    "abstract": "tSNE and UMAP are popular dimensionality reduction algorithms due to their speed and interpretable low-dimensional embeddings. Despite their popularity, however, little work has been done to study their full span of differences. We theoretically and experimentally evaluate the space of parameters in both tSNE and UMAP and observe that a single one -- the normalization -- is responsible for switching between them. This, in turn, implies that a majority of the algorithmic differences can be toggled without affecting the embeddings. We discuss the implications this has on several theoretic claims behind UMAP, as well as how to reconcile them with existing tSNE interpretations.  Based on our analysis, we provide a method (\\ourmethod) that combines previously incompatible techniques from tSNE and UMAP and can replicate the results of either algorithm. This allows our method to incorporate further improvements, such as an acceleration that obtains either method's outputs faster than UMAP. We",
    "link": "http://arxiv.org/abs/2305.07320",
    "context": "Title: ActUp: Analyzing and Consolidating tSNE and UMAP. (arXiv:2305.07320v1 [cs.LG])\nAbstract: tSNE and UMAP are popular dimensionality reduction algorithms due to their speed and interpretable low-dimensional embeddings. Despite their popularity, however, little work has been done to study their full span of differences. We theoretically and experimentally evaluate the space of parameters in both tSNE and UMAP and observe that a single one -- the normalization -- is responsible for switching between them. This, in turn, implies that a majority of the algorithmic differences can be toggled without affecting the embeddings. We discuss the implications this has on several theoretic claims behind UMAP, as well as how to reconcile them with existing tSNE interpretations.  Based on our analysis, we provide a method (\\ourmethod) that combines previously incompatible techniques from tSNE and UMAP and can replicate the results of either algorithm. This allows our method to incorporate further improvements, such as an acceleration that obtains either method's outputs faster than UMAP. We",
    "path": "papers/23/05/2305.07320.json",
    "total_tokens": 914,
    "translated_title": "ActUp: 分析和整合tSNE和UMAP",
    "translated_abstract": "tSNE和UMAP是由于它们的速度和可解释的低维嵌入而受欢迎的降维算法。然而，尽管它们很受欢迎，但很少有人研究它们的全部差异。我们在理论和实验上评估了tSNE和UMAP中的参数空间，并发现只有一个参数-规范化-可以在它们之间切换。这反过来意味着，大多数算法差异可以切换而不影响嵌入。我们讨论了这对UMAP背后的几个理论主张的影响，以及如何将它们与现有的tSNE解释相和谐。根据我们的分析，我们提供了一种方法(\\ourmethod)，它结合了之前不兼容的tSNE和UMAP技术，并可以复制任一算法的结果。这使得我们的方法可以进一步改进，例如加速，可以更快地获得UMAP的输出结果。",
    "tldr": "本文分析了tSNE和UMAP的参数空间，并发现归一化参数可以在两者之间切换，并提出了一种方法(\\ourmethod)可以结合之前不兼容的tSNE和UMAP技术，即可以复制任意算法的结果，同时还可以加速获得UMAP的输出结果。",
    "en_tdlr": "This paper analyzes the parameter space of tSNE and UMAP, and finds that the normalization parameter can switch between the two. Additionally, the authors propose a method (\\ourmethod) that combines previously incompatible techniques from tSNE and UMAP, allowing for replication of either algorithm's results and accelerated output obtainment for UMAP."
}