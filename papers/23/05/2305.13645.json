{
    "title": "mPMR: A Multilingual Pre-trained Machine Reader at Scale. (arXiv:2305.13645v1 [cs.CL])",
    "abstract": "We present multilingual Pre-trained Machine Reader (mPMR), a novel method for multilingual machine reading comprehension (MRC)-style pre-training. mPMR aims to guide multilingual pre-trained language models (mPLMs) to perform natural language understanding (NLU) including both sequence classification and span extraction in multiple languages. To achieve cross-lingual generalization when only source-language fine-tuning data is available, existing mPLMs solely transfer NLU capability from a source language to target languages. In contrast, mPMR allows the direct inheritance of multilingual NLU capability from the MRC-style pre-training to downstream tasks. Therefore, mPMR acquires better NLU capability for target languages. mPMR also provides a unified solver for tackling cross-lingual span extraction and sequence classification, thereby enabling the extraction of rationales to explain the sentence-pair classification process.",
    "link": "http://arxiv.org/abs/2305.13645",
    "context": "Title: mPMR: A Multilingual Pre-trained Machine Reader at Scale. (arXiv:2305.13645v1 [cs.CL])\nAbstract: We present multilingual Pre-trained Machine Reader (mPMR), a novel method for multilingual machine reading comprehension (MRC)-style pre-training. mPMR aims to guide multilingual pre-trained language models (mPLMs) to perform natural language understanding (NLU) including both sequence classification and span extraction in multiple languages. To achieve cross-lingual generalization when only source-language fine-tuning data is available, existing mPLMs solely transfer NLU capability from a source language to target languages. In contrast, mPMR allows the direct inheritance of multilingual NLU capability from the MRC-style pre-training to downstream tasks. Therefore, mPMR acquires better NLU capability for target languages. mPMR also provides a unified solver for tackling cross-lingual span extraction and sequence classification, thereby enabling the extraction of rationales to explain the sentence-pair classification process.",
    "path": "papers/23/05/2305.13645.json",
    "total_tokens": 899,
    "translated_title": "mPMR：一种规模化的多语言预训练机器阅读器",
    "translated_abstract": "我们提出了一种名为mPMR的多语言预训练机器阅读器，用于多语言机器阅读理解（MRC）风格的预训练。mPMR旨在指导多语言预训练语言模型（mPLMs）在多种语言中执行自然语言理解（NLU），包括序列分类和跨度提取。与现有的mPLMs仅从源语言转移NLU能力到目标语言以实现跨语言泛化不同，mPMR允许直接从MRC风格的预训练继承多语言NLU能力到下游任务。因此，mPMR获得了更好的目标语言NLU能力。mPMR还提供了一个统一的求解器，用于处理跨语言跨度提取和序列分类，从而能够提取理由来解释句对分类过程。",
    "tldr": "mPMR是一种多语言预训练机器阅读器，能够有效进行自然语言理解，包括序列分类和跨度提取，从而实现跨语言泛化，提高目标语言的NLU能力，并实现跨语言跨度提取和序列分类的统一求解，以便解释句对分类过程。",
    "en_tdlr": "mPMR is a multilingual pre-trained machine reader that can perform natural language understanding, including sequence classification and span extraction, with cross-lingual generalization to improve target language NLU capability. It also provides a unified solver for cross-lingual span extraction and sequence classification, enabling extraction of rationales to explain sentence-pair classification process."
}