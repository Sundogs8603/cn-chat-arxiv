{
    "title": "Transfer Learning for Fine-grained Classification Using Semi-supervised Learning and Visual Transformers. (arXiv:2305.10018v1 [cs.CV])",
    "abstract": "Fine-grained classification is a challenging task that involves identifying subtle differences between objects within the same category. This task is particularly challenging in scenarios where data is scarce. Visual transformers (ViT) have recently emerged as a powerful tool for image classification, due to their ability to learn highly expressive representations of visual data using self-attention mechanisms. In this work, we explore Semi-ViT, a ViT model fine tuned using semi-supervised learning techniques, suitable for situations where we have lack of annotated data. This is particularly common in e-commerce, where images are readily available but labels are noisy, nonexistent, or expensive to obtain. Our results demonstrate that Semi-ViT outperforms traditional convolutional neural networks (CNN) and ViTs, even when fine-tuned with limited annotated data. These findings indicate that Semi-ViTs hold significant promise for applications that require precise and fine-grained classifi",
    "link": "http://arxiv.org/abs/2305.10018",
    "context": "Title: Transfer Learning for Fine-grained Classification Using Semi-supervised Learning and Visual Transformers. (arXiv:2305.10018v1 [cs.CV])\nAbstract: Fine-grained classification is a challenging task that involves identifying subtle differences between objects within the same category. This task is particularly challenging in scenarios where data is scarce. Visual transformers (ViT) have recently emerged as a powerful tool for image classification, due to their ability to learn highly expressive representations of visual data using self-attention mechanisms. In this work, we explore Semi-ViT, a ViT model fine tuned using semi-supervised learning techniques, suitable for situations where we have lack of annotated data. This is particularly common in e-commerce, where images are readily available but labels are noisy, nonexistent, or expensive to obtain. Our results demonstrate that Semi-ViT outperforms traditional convolutional neural networks (CNN) and ViTs, even when fine-tuned with limited annotated data. These findings indicate that Semi-ViTs hold significant promise for applications that require precise and fine-grained classifi",
    "path": "papers/23/05/2305.10018.json",
    "total_tokens": 902,
    "translated_title": "利用半监督学习和视觉Transformer进行细粒度分类的迁移学习",
    "translated_abstract": "细粒度分类是一项具有挑战性的任务，涉及识别同一类别内物体之间微小差异。在数据稀缺的情况下，这项任务尤其具有挑战性。由于其使用自注意力机制学习视觉数据高度表现力的能力，视觉Transformer（ViT）最近已成为图像分类的强大工具。在本研究中，我们探讨了半监督ViT，一种应用于缺乏注释数据情况下的ViT模型微调的半监督学习技术，这在电子商务中特别常见，其中图像易于获取但标签有噪音、不存在或获取昂贵。我们的结果表明，即使使用有限的注释数据进行微调，半监督ViT仍然优于传统的卷积神经网络（CNN）和ViT。这些发现表明，半监督ViT在需要精确和细粒度分类的应用中具有重要的前景。",
    "tldr": "使用半监督学习技术对ViT模型进行微调，可用于缺乏注释数据的细粒度分类任务，比传统CNN和ViT都表现更好，有助于解决电子商务中图像标注问题。"
}