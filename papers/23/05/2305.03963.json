{
    "title": "Beyond the Model: Data Pre-processing Attack to Deep Learning Models in Android Apps. (arXiv:2305.03963v1 [cs.CR])",
    "abstract": "The increasing popularity of deep learning (DL) models and the advantages of computing, including low latency and bandwidth savings on smartphones, have led to the emergence of intelligent mobile applications, also known as DL apps, in recent years. However, this technological development has also given rise to several security concerns, including adversarial examples, model stealing, and data poisoning issues. Existing works on attacks and countermeasures for on-device DL models have primarily focused on the models themselves. However, scant attention has been paid to the impact of data processing disturbance on the model inference. This knowledge disparity highlights the need for additional research to fully comprehend and address security issues related to data processing for on-device models. In this paper, we introduce a data processing-based attacks against real-world DL apps. In particular, our attack could influence the performance and latency of the model without affecting the",
    "link": "http://arxiv.org/abs/2305.03963",
    "context": "Title: Beyond the Model: Data Pre-processing Attack to Deep Learning Models in Android Apps. (arXiv:2305.03963v1 [cs.CR])\nAbstract: The increasing popularity of deep learning (DL) models and the advantages of computing, including low latency and bandwidth savings on smartphones, have led to the emergence of intelligent mobile applications, also known as DL apps, in recent years. However, this technological development has also given rise to several security concerns, including adversarial examples, model stealing, and data poisoning issues. Existing works on attacks and countermeasures for on-device DL models have primarily focused on the models themselves. However, scant attention has been paid to the impact of data processing disturbance on the model inference. This knowledge disparity highlights the need for additional research to fully comprehend and address security issues related to data processing for on-device models. In this paper, we introduce a data processing-based attacks against real-world DL apps. In particular, our attack could influence the performance and latency of the model without affecting the",
    "path": "papers/23/05/2305.03963.json",
    "total_tokens": 834,
    "translated_title": "超越模型：Android应用中针对深度学习模型的数据预处理攻击",
    "translated_abstract": "近年来，深度学习模型和智能手机低延迟和节省带宽等优点推动了智能移动应用的发展，也称为传统应用，但这种技术进展也引发了许多安全问题，包括对抗性示例、模型窃取和数据污染问题。现有攻击和针对设备上深度学习模型的对策，主要集中在模型本身，而很少关注数据处理对模型推理的影响。这种知识差距凸显了需要进一步研究，以全面理解和解决与设备上的模型相关的安全问题。本论文介绍了一种基于数据处理的攻击方法，针对实际应用中的深度学习应用进行攻击。我们的攻击能够影响模型的性能和延迟，而不会影响。",
    "tldr": "本论文针对深度学习模型安全问题提出了基于数据处理的攻击方法，通过攻击可以影响模型性能和延迟，而不影响模型本身。",
    "en_tdlr": "This paper presents a data processing-based attack to address security concerns related to on-device deep learning models in Android apps. The attack can affect the performance and latency of the model without compromising the model itself."
}