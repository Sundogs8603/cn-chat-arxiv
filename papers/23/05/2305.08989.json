{
    "title": "LoViT: Long Video Transformer for Surgical Phase Recognition. (arXiv:2305.08989v1 [cs.CV])",
    "abstract": "Online surgical phase recognition plays a significant role towards building contextual tools that could quantify performance and oversee the execution of surgical workflows. Current approaches are limited since they train spatial feature extractors using frame-level supervision that could lead to incorrect predictions due to similar frames appearing at different phases, and poorly fuse local and global features due to computational constraints which can affect the analysis of long videos commonly encountered in surgical interventions. In this paper, we present a two-stage method, called Long Video Transformer (LoViT) for fusing short- and long-term temporal information that combines a temporally-rich spatial feature extractor and a multi-scale temporal aggregator consisting of two cascaded L-Trans modules based on self-attention, followed by a G-Informer module based on ProbSparse self-attention for processing global temporal information. The multi-scale temporal head then combines loc",
    "link": "http://arxiv.org/abs/2305.08989",
    "context": "Title: LoViT: Long Video Transformer for Surgical Phase Recognition. (arXiv:2305.08989v1 [cs.CV])\nAbstract: Online surgical phase recognition plays a significant role towards building contextual tools that could quantify performance and oversee the execution of surgical workflows. Current approaches are limited since they train spatial feature extractors using frame-level supervision that could lead to incorrect predictions due to similar frames appearing at different phases, and poorly fuse local and global features due to computational constraints which can affect the analysis of long videos commonly encountered in surgical interventions. In this paper, we present a two-stage method, called Long Video Transformer (LoViT) for fusing short- and long-term temporal information that combines a temporally-rich spatial feature extractor and a multi-scale temporal aggregator consisting of two cascaded L-Trans modules based on self-attention, followed by a G-Informer module based on ProbSparse self-attention for processing global temporal information. The multi-scale temporal head then combines loc",
    "path": "papers/23/05/2305.08989.json",
    "total_tokens": 928,
    "translated_title": "LoViT: 用于手术阶段识别的长视频Transformer",
    "translated_abstract": "在构建能够量化表现并监督手术流程执行的上下文工具方面，在线手术阶段识别发挥着重要作用。目前的方法有限，因为它们使用基于帧级监督的空间特征提取器进行训练，这可能会导致由于相似帧在不同阶段出现而导致的错误预测，并且由于计算限制而未能很好地融合本地和全局特征，这可能影响手术干预中通常遇到的长视频的分析。在本文中，我们提出了一种名为LoViT的两阶段方法，用于融合短期和长期时间信息，它结合了一个时间丰富的空间特征提取器和一个多尺度时间聚合器，后者由基于自注意力的两个级联L-Trans模块和一个基于ProbSparse自注意力的G-Informer模块组成，用于处理全局时间信息。然后，多尺度时间头结合本地和全局特征来识别长视频中的手术阶段。我们展示了LoViT在两个公共手术数据集上优于现有方法。",
    "tldr": "LoViT是一种用于手术阶段识别的长视频Transformer，它通过结合时间丰富的空间特征提取器和多尺度时间聚合器来对长视频进行分析，优于现有方法。"
}