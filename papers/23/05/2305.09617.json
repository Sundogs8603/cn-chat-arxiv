{
    "title": "Towards Expert-Level Medical Question Answering with Large Language Models. (arXiv:2305.09617v1 [cs.CL])",
    "abstract": "Recent artificial intelligence (AI) systems have reached milestones in \"grand challenges\" ranging from Go to protein-folding. The capability to retrieve medical knowledge, reason over it, and answer medical questions comparably to physicians has long been viewed as one such grand challenge.  Large language models (LLMs) have catalyzed significant progress in medical question answering; Med-PaLM was the first model to exceed a \"passing\" score in US Medical Licensing Examination (USMLE) style questions with a score of 67.2% on the MedQA dataset. However, this and other prior work suggested significant room for improvement, especially when models' answers were compared to clinicians' answers. Here we present Med-PaLM 2, which bridges these gaps by leveraging a combination of base LLM improvements (PaLM 2), medical domain finetuning, and prompting strategies including a novel ensemble refinement approach.  Med-PaLM 2 scored up to 86.5% on the MedQA dataset, improving upon Med-PaLM by over ",
    "link": "http://arxiv.org/abs/2305.09617",
    "context": "Title: Towards Expert-Level Medical Question Answering with Large Language Models. (arXiv:2305.09617v1 [cs.CL])\nAbstract: Recent artificial intelligence (AI) systems have reached milestones in \"grand challenges\" ranging from Go to protein-folding. The capability to retrieve medical knowledge, reason over it, and answer medical questions comparably to physicians has long been viewed as one such grand challenge.  Large language models (LLMs) have catalyzed significant progress in medical question answering; Med-PaLM was the first model to exceed a \"passing\" score in US Medical Licensing Examination (USMLE) style questions with a score of 67.2% on the MedQA dataset. However, this and other prior work suggested significant room for improvement, especially when models' answers were compared to clinicians' answers. Here we present Med-PaLM 2, which bridges these gaps by leveraging a combination of base LLM improvements (PaLM 2), medical domain finetuning, and prompting strategies including a novel ensemble refinement approach.  Med-PaLM 2 scored up to 86.5% on the MedQA dataset, improving upon Med-PaLM by over ",
    "path": "papers/23/05/2305.09617.json",
    "total_tokens": 998,
    "translated_title": "大型语言模型在医学问答中的应用：迈向医学专家级别的问答能力",
    "translated_abstract": "近年来，人工智能系统在诸如围棋和蛋白质折叠等“宏伟挑战”方面取得了里程碑式的进展。但回答医学问题并像医生一样进行推理被认为也是一种宏伟挑战。大型语言模型在医学问答方面取得了重大进展；Med-PaLM是第一个在MedQA数据集上以67.2％的分数超过美国医疗执业考试（USMLE）样式问题的“及格”分数的模型。 然而，对比模型答案和医生答案，这项和其他先前工作表明还有很大的改进空间。本文提出了Med-PaLM2，通过利用基础LLM改进（PaLM2）、医学领域微调和提示策略（包括新颖的集成精炼方法）来弥合这些差距。在MedQA数据集上，Med-PaLM2的得分可达86.5％，比Med-PaLM提高了超过11％。",
    "tldr": "本研究提出了Med-PaLM2，通过结合基础LLM改进、医学领域微调和提示策略，并用新颖的集成精炼方法，实现了在MedQA数据集上达到86.5%的医学问答准确率，迈向医学专家级别的问答能力。",
    "en_tdlr": "This study proposes Med-PaLM2, which combines base LLM improvements, medical domain finetuning, and prompting strategies (including a novel ensemble refinement approach) to bridge the gap between models' answers and clinicians' answers. The model achieved an accuracy rate of 86.5% on the MedQA dataset, moving towards expert-level medical question answering."
}