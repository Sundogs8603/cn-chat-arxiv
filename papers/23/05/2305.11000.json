{
    "title": "SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities. (arXiv:2305.11000v1 [cs.CL])",
    "abstract": "Multi-modal large language models are regarded as a crucial step towards Artificial General Intelligence (AGI) and have garnered significant interest with the emergence of ChatGPT. However, current speech-language models typically adopt the cascade paradigm, preventing inter-modal knowledge transfer. In this paper, we propose SpeechGPT, a large language model with intrinsic cross-modal conversational abilities, capable of perceiving and generating multi-model content. With discrete speech representations, we first construct SpeechInstruct, a large-scale cross-modal speech instruction dataset. Additionally, we employ a three-stage training strategy that includes modality-adaptation pre-training, cross-modal instruction fine-tuning, and chain-of-modality instruction fine-tuning. The experimental results demonstrate that SpeechGPT has an impressive capacity to follow multi-modal human instructions and highlight the potential of handling multiple modalities with one model. Demos are shown ",
    "link": "http://arxiv.org/abs/2305.11000",
    "context": "Title: SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities. (arXiv:2305.11000v1 [cs.CL])\nAbstract: Multi-modal large language models are regarded as a crucial step towards Artificial General Intelligence (AGI) and have garnered significant interest with the emergence of ChatGPT. However, current speech-language models typically adopt the cascade paradigm, preventing inter-modal knowledge transfer. In this paper, we propose SpeechGPT, a large language model with intrinsic cross-modal conversational abilities, capable of perceiving and generating multi-model content. With discrete speech representations, we first construct SpeechInstruct, a large-scale cross-modal speech instruction dataset. Additionally, we employ a three-stage training strategy that includes modality-adaptation pre-training, cross-modal instruction fine-tuning, and chain-of-modality instruction fine-tuning. The experimental results demonstrate that SpeechGPT has an impressive capacity to follow multi-modal human instructions and highlight the potential of handling multiple modalities with one model. Demos are shown ",
    "path": "papers/23/05/2305.11000.json",
    "total_tokens": 883,
    "translated_title": "SpeechGPT: 用本质跨模态会话能力赋能大型语言模型",
    "translated_abstract": "多模态大型语言模型被认为是迈向人工通用智能（AGI）的重要一步，随着ChatGPT的出现，它们已经引起了广泛的关注。然而，目前的语音-语言模型通常采用级联范式，阻止了跨模态知识的转移。在本文中，我们提出了SpeechGPT，这是一个具有本质跨模态会话能力的大型语言模型，能够感知和生成多模态内容。通过离散化的语音表示，我们首先构建了SpeechInstruct，一个大规模的跨模态语音指令数据集。此外，我们采用了三阶段的训练策略，包括模态自适应预训练、跨模态指令微调和模态链指令微调。实验结果表明，SpeechGPT具有按照多模态人类指令的能力，并突显了使用一个模型处理多个模态的潜力。",
    "tldr": "SpeechGPT是一个具有本质跨模态会话能力的大型语言模型，能够感知和生成多模态内容，可按照多模态人类指令的能力，并突显了使用一个模型处理多个模态的潜力。",
    "en_tdlr": "SpeechGPT is a large language model with intrinsic cross-modal conversational abilities, capable of perceiving and generating multi-modal content, has an impressive capacity to follow multi-modal human instructions, and highlights the potential of handling multiple modalities with one model."
}