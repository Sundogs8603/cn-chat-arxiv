{
    "title": "Exploring Contrast Consistency of Open-Domain Question Answering Systems on Minimally Edited Questions. (arXiv:2305.14441v1 [cs.CL])",
    "abstract": "Contrast consistency, the ability of a model to make consistently correct predictions in the presence of perturbations, is an essential aspect in NLP. While studied in tasks such as sentiment analysis and reading comprehension, it remains unexplored in open-domain question answering (OpenQA) due to the difficulty of collecting perturbed questions that satisfy factuality requirements. In this work, we collect minimally edited questions as challenging contrast sets to evaluate OpenQA models. Our collection approach combines both human annotation and large language model generation. We find that the widely used dense passage retriever (DPR) performs poorly on our contrast sets, despite fitting the training set well and performing competitively on standard test sets. To address this issue, we introduce a simple and effective query-side contrastive loss with the aid of data augmentation to improve DPR training. Our experiments on the contrast sets demonstrate that DPR's contrast consistency",
    "link": "http://arxiv.org/abs/2305.14441",
    "context": "Title: Exploring Contrast Consistency of Open-Domain Question Answering Systems on Minimally Edited Questions. (arXiv:2305.14441v1 [cs.CL])\nAbstract: Contrast consistency, the ability of a model to make consistently correct predictions in the presence of perturbations, is an essential aspect in NLP. While studied in tasks such as sentiment analysis and reading comprehension, it remains unexplored in open-domain question answering (OpenQA) due to the difficulty of collecting perturbed questions that satisfy factuality requirements. In this work, we collect minimally edited questions as challenging contrast sets to evaluate OpenQA models. Our collection approach combines both human annotation and large language model generation. We find that the widely used dense passage retriever (DPR) performs poorly on our contrast sets, despite fitting the training set well and performing competitively on standard test sets. To address this issue, we introduce a simple and effective query-side contrastive loss with the aid of data augmentation to improve DPR training. Our experiments on the contrast sets demonstrate that DPR's contrast consistency",
    "path": "papers/23/05/2305.14441.json",
    "total_tokens": 975,
    "translated_title": "开放领域问答系统在最小编辑问题上的对比一致性探究",
    "translated_abstract": "对比一致性是NLP中的一个关键方面，是模型在存在扰动的情况下进行一致正确预测的能力。尽管在情感分析和阅读理解等任务中已经有所研究，但在开放式领域问答（OpenQA）中仍未被探讨，主要是由于难以收集到符合事实要求的扰动问题。针对此问题，我们采用了人工标注和大型语言模型生成相结合的方式收集了最小编辑问题，作为具有挑战性的对比集合，用于评估OpenQA模型。实验结果表明，尽管对训练集拟合良好且在标准测试集上表现竞争力，但广泛使用的密集式段落取回器（DPR）在我们的对比集合上表现不佳。为了解决这个问题，我们引入了一种简单有效的查询端对比损失，结合数据增强来改进DPR的训练。我们对对比集合进行的实验表明，DPR的对比一致性得到了改善。",
    "tldr": "本文针对开放领域问答系统中存在的对比一致性问题，通过收集最小编辑问题构建了具有挑战性的对比集合，发现广泛使用的DPR在对比集合上表现不佳，引入了查询端对比损失和数据增强来改善DPR的训练，并进行实验验证。",
    "en_tdlr": "This paper addresses the contrast consistency issue in open-domain question answering systems and introduces a challenging contrast set of minimally edited questions. The widely used dense passage retriever (DPR) was found to perform poorly on the contrast set, prompting the introduction of a query-side contrastive loss with data augmentation to improve DPR training. Experiment results validate the effectiveness of this approach."
}