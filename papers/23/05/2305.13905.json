{
    "title": "EfficientSpeech: An On-Device Text to Speech Model. (arXiv:2305.13905v1 [eess.AS])",
    "abstract": "State of the art (SOTA) neural text to speech (TTS) models can generate natural-sounding synthetic voices. These models are characterized by large memory footprints and substantial number of operations due to the long-standing focus on speech quality with cloud inference in mind. Neural TTS models are generally not designed to perform standalone speech syntheses on resource-constrained and no Internet access edge devices. In this work, an efficient neural TTS called EfficientSpeech that synthesizes speech on an ARM CPU in real-time is proposed. EfficientSpeech uses a shallow non-autoregressive pyramid-structure transformer forming a U-Network. EfficientSpeech has 266k parameters and consumes 90 MFLOPS only or about 1% of the size and amount of computation in modern compact models such as Mixer-TTS. EfficientSpeech achieves an average mel generation real-time factor of 104.3 on an RPi4. Human evaluation shows only a slight degradation in audio quality as compared to FastSpeech2.",
    "link": "http://arxiv.org/abs/2305.13905",
    "context": "Title: EfficientSpeech: An On-Device Text to Speech Model. (arXiv:2305.13905v1 [eess.AS])\nAbstract: State of the art (SOTA) neural text to speech (TTS) models can generate natural-sounding synthetic voices. These models are characterized by large memory footprints and substantial number of operations due to the long-standing focus on speech quality with cloud inference in mind. Neural TTS models are generally not designed to perform standalone speech syntheses on resource-constrained and no Internet access edge devices. In this work, an efficient neural TTS called EfficientSpeech that synthesizes speech on an ARM CPU in real-time is proposed. EfficientSpeech uses a shallow non-autoregressive pyramid-structure transformer forming a U-Network. EfficientSpeech has 266k parameters and consumes 90 MFLOPS only or about 1% of the size and amount of computation in modern compact models such as Mixer-TTS. EfficientSpeech achieves an average mel generation real-time factor of 104.3 on an RPi4. Human evaluation shows only a slight degradation in audio quality as compared to FastSpeech2.",
    "path": "papers/23/05/2305.13905.json",
    "total_tokens": 832,
    "translated_title": "EfficientSpeech：一种在设备上的文本到语音模型",
    "translated_abstract": "最先进的神经文本到语音（TTS）模型能够生成自然的合成语音，但却因为长期专注于在云端推理的语音质量而导致存储容量大、操作数量大。神经TTS模型通常不适用于资源受限且没有互联网访问设备上的独立语音合成。本文提出了一种名为EfficientSpeech的高效神经TTS模型，能够在ARM CPU上实时合成语音。该模型使用一个浅的非自回归金字塔结构变压器构成的U型网络，只有266k参数，并消耗90 MFLOPS，约为现代紧凑型模型Mixer-TTS大小和计算量的1％。EfficientSpeech在RPi4上实现平均103.4的实时梅尔生成速度。人工评估显示，与FastSpeech2相比，音频质量仅略微降低。",
    "tldr": "EfficientSpeech是一种在ARM CPU上实时生成语音的高效神经TTS模型，具有较小的存储需求和计算量，表现良好。",
    "en_tdlr": "EfficientSpeech is an efficient neural text-to-speech model that can synthesize speech in real-time on ARM CPU, with small storage requirements and computational cost, and performs well."
}