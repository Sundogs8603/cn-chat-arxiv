{
    "title": "What You See is What You Read? Improving Text-Image Alignment Evaluation. (arXiv:2305.10400v1 [cs.CL])",
    "abstract": "Automatically determining whether a text and a corresponding image are semantically aligned is a significant challenge for vision-language models, with applications in generative text-to-image and image-to-text tasks. In this work, we study methods for automatic text-image alignment evaluation. We first introduce SeeTRUE: a comprehensive evaluation set, spanning multiple datasets from both text-to-image and image-to-text generation tasks, with human judgements for whether a given text-image pair is semantically aligned. We then describe two automatic methods to determine alignment: the first involving a pipeline based on question generation and visual question answering models, and the second employing an end-to-end classification approach by finetuning multimodal pretrained models. Both methods surpass prior approaches in various text-image alignment tasks, with significant improvements in challenging cases that involve complex composition or unnatural images. Finally, we demonstrate ",
    "link": "http://arxiv.org/abs/2305.10400",
    "context": "Title: What You See is What You Read? Improving Text-Image Alignment Evaluation. (arXiv:2305.10400v1 [cs.CL])\nAbstract: Automatically determining whether a text and a corresponding image are semantically aligned is a significant challenge for vision-language models, with applications in generative text-to-image and image-to-text tasks. In this work, we study methods for automatic text-image alignment evaluation. We first introduce SeeTRUE: a comprehensive evaluation set, spanning multiple datasets from both text-to-image and image-to-text generation tasks, with human judgements for whether a given text-image pair is semantically aligned. We then describe two automatic methods to determine alignment: the first involving a pipeline based on question generation and visual question answering models, and the second employing an end-to-end classification approach by finetuning multimodal pretrained models. Both methods surpass prior approaches in various text-image alignment tasks, with significant improvements in challenging cases that involve complex composition or unnatural images. Finally, we demonstrate ",
    "path": "papers/23/05/2305.10400.json",
    "total_tokens": 941,
    "translated_title": "你看到的就是你读到的? 改进文本-图像对齐评估方法",
    "translated_abstract": "自动确定文本和相应的图像是否语义上对齐是视觉语言模型面临的一项重要挑战，应用于生成文本到图像和图像到文本任务。在本研究中，我们研究了自动文本-图像对齐评估方法。我们首先介绍了SeeTRUE：一个全面的评估集，涵盖了从文本到图像和图像到文本生成任务的多个数据集，并具有人类的判断，判断给定的文本-图像对是否语义上对齐。然后，我们描述了两种自动确定对齐的方法：第一种是基于问题生成和视觉问题回答模型的管道，第二种是通过微调多模态预训练模型的端到端分类方法。这两种方法在各种文本-图像对齐任务中均超越了先前的方法，在涉及复杂组合或非自然图像的挑战性案例中有显着改进。最后，我们证明即使最先进的模型在这个任务上还有很大的改进空间，这激励了未来在这个领域的研究。",
    "tldr": "本研究介绍了SeeTRUE评估集和两种自动文本-图像对齐方法，这些方法在各种对齐任务中均取得了显着改进，在复杂组合或非自然图像的挑战性案例中表现出色。",
    "en_tdlr": "This paper presents the SeeTRUE evaluation set and two automatic methods for text-image alignment evaluation, achieving significant improvements in various alignment tasks and challenging cases involving complex composition or unnatural images."
}