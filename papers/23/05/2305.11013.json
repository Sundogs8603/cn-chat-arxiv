{
    "title": "FunASR: A Fundamental End-to-End Speech Recognition Toolkit. (arXiv:2305.11013v1 [cs.SD])",
    "abstract": "This paper introduces FunASR, an open-source speech recognition toolkit designed to bridge the gap between academic research and industrial applications. FunASR offers models trained on large-scale industrial corpora and the ability to deploy them in applications. The toolkit's flagship model, Paraformer, is a non-autoregressive end-to-end speech recognition model that has been trained on a manually annotated Mandarin speech recognition dataset that contains 60,000 hours of speech. To improve the performance of Paraformer, we have added timestamp prediction and hotword customization capabilities to the standard Paraformer backbone. In addition, to facilitate model deployment, we have open-sourced a voice activity detection model based on the Feedforward Sequential Memory Network (FSMN-VAD) and a text post-processing punctuation model based on the controllable time-delay Transformer (CT-Transformer), both of which were trained on industrial corpora. These functional modules provide a so",
    "link": "http://arxiv.org/abs/2305.11013",
    "context": "Title: FunASR: A Fundamental End-to-End Speech Recognition Toolkit. (arXiv:2305.11013v1 [cs.SD])\nAbstract: This paper introduces FunASR, an open-source speech recognition toolkit designed to bridge the gap between academic research and industrial applications. FunASR offers models trained on large-scale industrial corpora and the ability to deploy them in applications. The toolkit's flagship model, Paraformer, is a non-autoregressive end-to-end speech recognition model that has been trained on a manually annotated Mandarin speech recognition dataset that contains 60,000 hours of speech. To improve the performance of Paraformer, we have added timestamp prediction and hotword customization capabilities to the standard Paraformer backbone. In addition, to facilitate model deployment, we have open-sourced a voice activity detection model based on the Feedforward Sequential Memory Network (FSMN-VAD) and a text post-processing punctuation model based on the controllable time-delay Transformer (CT-Transformer), both of which were trained on industrial corpora. These functional modules provide a so",
    "path": "papers/23/05/2305.11013.json",
    "total_tokens": 964,
    "translated_title": "FunASR: 一款基础的端到端语音识别工具箱",
    "translated_abstract": "本文介绍了FunASR，一款开源的语音识别工具箱，旨在弥合学术研究和工业应用之间的差距。FunASR提供了在应用中使用的经过大规模工业语料库训练的模型。该工具箱的旗舰模型Paraformer是一个非自回归的端到端语音识别模型，已在手工注释的包含60,000小时语音的中文语音识别数据集上进行了训练。为了提高Paraformer的性能，我们在标准Paraformer骨干中添加了时间戳预测和热词定制能力。此外，为了促进模型部署，我们开源了一个基于前馈序列记忆网络（FSMN-VAD）的语音活动检测模型和一个基于可控时延Transformer（CT-Transformer）的文本后处理标点模型，这两个模型都是在工业语料库上训练的。这些功能模块提供了一种实用的方式来提高语音识别性能和易用性。",
    "tldr": "本文介绍了一款名为FunASR的基础语音识别工具箱，其中的Paraformer模型是一个在60万小时语音数据集上训练的非自回归的端到端语音识别模型，工具箱还提供了包括语音活动检测和文本标点功能在内的多个工具模块，以提高语音识别性能和易用性。",
    "en_tdlr": "This paper introduces FunASR, a fundamental speech recognition toolkit that includes the non-autoregressive end-to-end speech recognition model Paraformer trained on 60,000 hours of Mandarin speech data, as well as other functional modules such as voice activity detection and text post-processing. The goal is to bridge the gap between academic research and industrial applications."
}