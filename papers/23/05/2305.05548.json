{
    "title": "CIT-EmotionNet: CNN Interactive Transformer Network for EEG Emotion Recognition. (arXiv:2305.05548v1 [eess.SP])",
    "abstract": "Emotion recognition using Electroencephalogram (EEG) signals has emerged as a significant research challenge in affective computing and intelligent interaction. However, effectively combining global and local features of EEG signals to improve performance in emotion recognition is still a difficult task. In this study, we propose a novel CNN Interactive Transformer Network for EEG Emotion Recognition, known as CIT-EmotionNet, which efficiently integrates global and local features of EEG signals. Initially, we convert raw EEG signals into spatial-frequency representations, which serve as inputs. Then, we integrate Convolutional Neural Network (CNN) and Transformer within a single framework in a parallel manner. Finally, we design a CNN interactive Transformer module, which facilitates the interaction and fusion of local and global features, thereby enhancing the model's ability to extract both types of features from EEG spatial-frequency representations. The proposed CIT-EmotionNet outp",
    "link": "http://arxiv.org/abs/2305.05548",
    "context": "Title: CIT-EmotionNet: CNN Interactive Transformer Network for EEG Emotion Recognition. (arXiv:2305.05548v1 [eess.SP])\nAbstract: Emotion recognition using Electroencephalogram (EEG) signals has emerged as a significant research challenge in affective computing and intelligent interaction. However, effectively combining global and local features of EEG signals to improve performance in emotion recognition is still a difficult task. In this study, we propose a novel CNN Interactive Transformer Network for EEG Emotion Recognition, known as CIT-EmotionNet, which efficiently integrates global and local features of EEG signals. Initially, we convert raw EEG signals into spatial-frequency representations, which serve as inputs. Then, we integrate Convolutional Neural Network (CNN) and Transformer within a single framework in a parallel manner. Finally, we design a CNN interactive Transformer module, which facilitates the interaction and fusion of local and global features, thereby enhancing the model's ability to extract both types of features from EEG spatial-frequency representations. The proposed CIT-EmotionNet outp",
    "path": "papers/23/05/2305.05548.json",
    "total_tokens": 977,
    "translated_title": "CIT-EmotionNet：用于EEG情绪识别的CNN交互式Transformer网络",
    "translated_abstract": "利用脑电信号进行情绪识别是情感计算和智能交互中的一个重要研究挑战。然而，有效地将脑电信号的全局和局部特征相结合以提高情绪识别的性能仍然是一项困难任务。本研究提出了一种新颖的CNN交互式Transformer网络，用于EEG情绪识别，称为CIT-EmotionNet，它能够有效地集成EEG信号的全局和局部特征。我们首先将原始EEG信号转换为空间频率表示，作为输入。然后在单个框架内并行地集成了卷积神经网络（CNN）和Transformer。最后，我们设计了一个CNN交互式Transformer模块，促进局部和全局特征的交互和融合，从而增强了模型从EEG空间频率表示中提取两种类型特征的能力。提出的CIT-EmotionNet在公开数据集上优于传统EEG情绪识别方法，并达到了最先进的性能，证明了我们提出的方法的有效性。",
    "tldr": "本研究提出了一种新颖的CNN交互式Transformer网络，用于EEG情绪识别，集成了全局和局部特征，通过CNN交互式Transformer模块促进局部和全局特征的交互和融合，获得了最先进的性能。",
    "en_tdlr": "A novel CNN Interactive Transformer Network named CIT-EmotionNet is proposed for EEG Emotion Recognition, which integrates both global and local features using spatial-frequency representations. The CNN interactive Transformer module is designed to facilitate the interaction and fusion of local and global features, leading to state-of-the-art performance on publicly available datasets."
}