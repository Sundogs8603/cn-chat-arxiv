{
    "title": "PiVe: Prompting with Iterative Verification Improving Graph-based Generative Capability of LLMs",
    "abstract": "Large language models (LLMs) have shown great abilities of solving various natural language tasks in different domains. Due to the training objective of LLMs and their pre-training data, LLMs are not very well equipped for tasks involving structured data generation. We propose a framework, Prompting with Iterative Verification (PiVe), to improve graph-based generative capability of LLMs. We show how a small language model could be trained to act as a verifier module for the output of an LLM(i.e., ChatGPT, GPT-4), and to iteratively improve its performance via fine-grained corrective instructions. We also show how the verifier module could apply iterative corrections offline for a more cost-effective solution to the text-to-graph generation task. Experiments on three graph-based datasets show consistent improvement gained via PiVe. Additionally, we create GenWiki-HIQ and highlight that the verifier module can be used as a data augmentation tool to help improve the quality of automatical",
    "link": "https://arxiv.org/abs/2305.12392",
    "context": "Title: PiVe: Prompting with Iterative Verification Improving Graph-based Generative Capability of LLMs\nAbstract: Large language models (LLMs) have shown great abilities of solving various natural language tasks in different domains. Due to the training objective of LLMs and their pre-training data, LLMs are not very well equipped for tasks involving structured data generation. We propose a framework, Prompting with Iterative Verification (PiVe), to improve graph-based generative capability of LLMs. We show how a small language model could be trained to act as a verifier module for the output of an LLM(i.e., ChatGPT, GPT-4), and to iteratively improve its performance via fine-grained corrective instructions. We also show how the verifier module could apply iterative corrections offline for a more cost-effective solution to the text-to-graph generation task. Experiments on three graph-based datasets show consistent improvement gained via PiVe. Additionally, we create GenWiki-HIQ and highlight that the verifier module can be used as a data augmentation tool to help improve the quality of automatical",
    "path": "papers/23/05/2305.12392.json",
    "total_tokens": 932,
    "translated_title": "PiVe：通过迭代验证提升LLMs的基于图的生成能力的提示方法",
    "translated_abstract": "大型语言模型(LLMs)在解决各种不同领域的自然语言任务方面展示了强大的能力。由于LLMs的训练目标和预训练数据，LLMs对涉及结构化数据生成的任务并不非常适用。我们提出了一个名为\"PiVe\"的框架，通过迭代验证来提升LLMs的基于图的生成能力。我们展示了如何训练一个小型语言模型作为LLMs的输出的验证模块(例如ChatGPT，GPT-4)，通过精细的纠正指令来迭代改进其性能。我们还展示了验证模块如何在离线环境中应用迭代校正，以获得更经济高效的文本到图形生成任务解决方案。在三个基于图的数据集上的实验结果表明，通过PiVe的方法能够持续改善结果。此外，我们创建了GenWiki-HIQ数据集，并强调验证模块可以作为数据增强工具，帮助提高自动生成的结果质量。",
    "tldr": "提出了一个名为\"PiVe\"的框架，通过迭代验证来提升LLMs的基于图的生成能力。实验结果表明，PiVe方法在三个基于图的数据集上取得了一致的改善，并且验证模块可以作为数据增强工具帮助提高结果质量。"
}