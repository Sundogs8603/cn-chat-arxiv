{
    "title": "Can NLP Models Correctly Reason Over Contexts that Break the Common Assumptions?. (arXiv:2305.12096v1 [cs.CL])",
    "abstract": "Pre-training on large corpora of text enables the language models to acquire a vast amount of factual and commonsense knowledge which allows them to achieve remarkable performance on a variety of language understanding tasks. They typically acquire this knowledge by learning from the pre-training text and capturing certain patterns from it. However, real-world settings often present scenarios that do not abide by these patterns i.e. scenarios that break the common assumptions. Can state-of-the-art NLP models correctly reason over the contexts of such scenarios?  Addressing the above question, in this paper, we investigate the ability of models to correctly reason over contexts that break the common assumptions. To this end, we first systematically create evaluation data in which each data instance consists of (a) a common assumption, (b) a context that follows the assumption, (c) a context that breaks the assumption, and (d) questions based on the contexts. Then, through evaluations on",
    "link": "http://arxiv.org/abs/2305.12096",
    "context": "Title: Can NLP Models Correctly Reason Over Contexts that Break the Common Assumptions?. (arXiv:2305.12096v1 [cs.CL])\nAbstract: Pre-training on large corpora of text enables the language models to acquire a vast amount of factual and commonsense knowledge which allows them to achieve remarkable performance on a variety of language understanding tasks. They typically acquire this knowledge by learning from the pre-training text and capturing certain patterns from it. However, real-world settings often present scenarios that do not abide by these patterns i.e. scenarios that break the common assumptions. Can state-of-the-art NLP models correctly reason over the contexts of such scenarios?  Addressing the above question, in this paper, we investigate the ability of models to correctly reason over contexts that break the common assumptions. To this end, we first systematically create evaluation data in which each data instance consists of (a) a common assumption, (b) a context that follows the assumption, (c) a context that breaks the assumption, and (d) questions based on the contexts. Then, through evaluations on",
    "path": "papers/23/05/2305.12096.json",
    "total_tokens": 798,
    "translated_title": "NLP模型能否正确处理打破常见假设的情境推理?",
    "translated_abstract": "在大规模文本预训练的基础上，语言模型可以获取丰富的事实和常识知识，从而在各种语言理解任务中获得非凡的性能。然而，现实世界中经常出现不符合这些规律的情况，即打破常见假设的场景。最先进的NLP模型能否正确地推理这些情况的语境呢？本文研究了模型正确处理打破常见假设的情境的能力。为此，我们首先系统地创建了评估数据，每个数据实例都包括一个常见假设、一个遵循该假设的语境、一个打破该假设的语境和基于这些语境的问题。然后，在实验中对模型进行了评估。",
    "tldr": "本文研究了最先进的NLP模型能否正确地推理打破常见假设的情况的语境，并系统地创建了相应的评估数据。"
}