{
    "title": "Introspective Tips: Large Language Model for In-Context Decision Making. (arXiv:2305.11598v1 [cs.AI])",
    "abstract": "The emergence of large language models (LLMs) has substantially influenced natural language processing, demonstrating exceptional results across various tasks. In this study, we employ ``Introspective Tips\" to facilitate LLMs in self-optimizing their decision-making. By introspectively examining trajectories, LLM refines its policy by generating succinct and valuable tips. Our method enhances the agent's performance in both few-shot and zero-shot learning situations by considering three essential scenarios: learning from the agent's past experiences, integrating expert demonstrations, and generalizing across diverse games. Importantly, we accomplish these improvements without fine-tuning the LLM parameters; rather, we adjust the prompt to generalize insights from the three aforementioned situations. Our framework not only supports but also emphasizes the advantage of employing LLM in in-contxt decision-making. Experiments involving over 100 games in TextWorld illustrate the superior pe",
    "link": "http://arxiv.org/abs/2305.11598",
    "context": "Title: Introspective Tips: Large Language Model for In-Context Decision Making. (arXiv:2305.11598v1 [cs.AI])\nAbstract: The emergence of large language models (LLMs) has substantially influenced natural language processing, demonstrating exceptional results across various tasks. In this study, we employ ``Introspective Tips\" to facilitate LLMs in self-optimizing their decision-making. By introspectively examining trajectories, LLM refines its policy by generating succinct and valuable tips. Our method enhances the agent's performance in both few-shot and zero-shot learning situations by considering three essential scenarios: learning from the agent's past experiences, integrating expert demonstrations, and generalizing across diverse games. Importantly, we accomplish these improvements without fine-tuning the LLM parameters; rather, we adjust the prompt to generalize insights from the three aforementioned situations. Our framework not only supports but also emphasizes the advantage of employing LLM in in-contxt decision-making. Experiments involving over 100 games in TextWorld illustrate the superior pe",
    "path": "papers/23/05/2305.11598.json",
    "total_tokens": 901,
    "translated_title": "内省技巧：上下文决策制定下的大型语言模型",
    "translated_abstract": "大型语言模型（LLMs）的出现在自然语言处理方面产生了巨大影响，在各种任务中展示出卓越的结果。本研究利用“内省技巧”来促进LLMs在自我优化决策制定方面发挥作用。通过内省地检查轨迹，LLM生成简洁而有价值的提示来改善其策略。我们的方法通过考虑三种重要情境来提高代理在少样本和零样本学习情况下的性能：从代理过去的经验中学习、整合专家演示和在不同游戏之间进行泛化。重要的是，我们在不调整LLM参数的情况下，通过调整提示来从这三种情况中概括见解来实现这些改进。我们的框架不仅支持而且强调了在上下文决策制定中采用LLM的优势。在TextWorld中涉及超过100个游戏的实验表明了我们所提出的方法的卓越性能。",
    "tldr": "本文研究了内省技巧对大型语言模型在上下文决策制定中的应用，通过内省轨迹生成简洁有价值的提示，不调整LLM参数就能提高代理的性能。",
    "en_tdlr": "This paper investigates the application of introspective tips to large language models for in-context decision making, which enhances the performance of the agent by generating succinct and valuable tips through introspectively examining trajectories, without fine-tuning LLM parameters."
}