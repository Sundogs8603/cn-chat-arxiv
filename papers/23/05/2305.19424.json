{
    "title": "Quantifying Overfitting: Evaluating Neural Network Performance through Analysis of Null Space. (arXiv:2305.19424v1 [cs.LG])",
    "abstract": "Machine learning models that are overfitted/overtrained are more vulnerable to knowledge leakage, which poses a risk to privacy. Suppose we download or receive a model from a third-party collaborator without knowing its training accuracy. How can we determine if it has been overfitted or overtrained on its training data? It's possible that the model was intentionally over-trained to make it vulnerable during testing. While an overfitted or overtrained model may perform well on testing data and even some generalization tests, we can't be sure it's not over-fitted. Conducting a comprehensive generalization test is also expensive. The goal of this paper is to address these issues and ensure the privacy and generalization of our method using only testing data. To achieve this, we analyze the null space in the last layer of neural networks, which enables us to quantify overfitting without access to training data or knowledge of the accuracy of those data. We evaluated our approach on variou",
    "link": "http://arxiv.org/abs/2305.19424",
    "context": "Title: Quantifying Overfitting: Evaluating Neural Network Performance through Analysis of Null Space. (arXiv:2305.19424v1 [cs.LG])\nAbstract: Machine learning models that are overfitted/overtrained are more vulnerable to knowledge leakage, which poses a risk to privacy. Suppose we download or receive a model from a third-party collaborator without knowing its training accuracy. How can we determine if it has been overfitted or overtrained on its training data? It's possible that the model was intentionally over-trained to make it vulnerable during testing. While an overfitted or overtrained model may perform well on testing data and even some generalization tests, we can't be sure it's not over-fitted. Conducting a comprehensive generalization test is also expensive. The goal of this paper is to address these issues and ensure the privacy and generalization of our method using only testing data. To achieve this, we analyze the null space in the last layer of neural networks, which enables us to quantify overfitting without access to training data or knowledge of the accuracy of those data. We evaluated our approach on variou",
    "path": "papers/23/05/2305.19424.json",
    "total_tokens": 767,
    "translated_title": "量化过拟合：通过零空间分析评估神经网络性能",
    "translated_abstract": "机器学习模型若过拟合/训练，则更容易受到知识泄漏的威胁，从而对隐私构成风险。本文针对如何在不知道模型的训练准确性的情况下，确定模型是否过拟合或过训练而提出了解决方案。通过分析神经网络最后一层的零空间，我们可以量化过拟合，而不需要访问训练数据或知道那些数据的准确性，从而保证了方法的隐私性和泛化性能。",
    "tldr": "本研究量化了过拟合问题，通过神经网络最后一层的零空间分析来评估模型性能并保证了神经网络的隐私和泛化性能。",
    "en_tdlr": "This paper quantifies overfitting by analyzing the null space in the last layer of neural networks, providing a solution to evaluating model performance without access to training data or knowledge of its accuracy, thus ensuring privacy and generalization."
}