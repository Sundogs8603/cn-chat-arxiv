{
    "title": "The Treachery of Images: Bayesian Scene Keypoints for Deep Policy Learning in Robotic Manipulation. (arXiv:2305.04718v2 [cs.RO] UPDATED)",
    "abstract": "In policy learning for robotic manipulation, sample efficiency is of paramount importance. Thus, learning and extracting more compact representations from camera observations is a promising avenue. However, current methods often assume full observability of the scene and struggle with scale invariance. In many tasks and settings, this assumption does not hold as objects in the scene are often occluded or lie outside the field of view of the camera, rendering the camera observation ambiguous with regard to their location. To tackle this problem, we present BASK, a Bayesian approach to tracking scale-invariant keypoints over time. Our approach successfully resolves inherent ambiguities in images, enabling keypoint tracking on symmetrical objects and occluded and out-of-view objects. We employ our method to learn challenging multi-object robot manipulation tasks from wrist camera observations and demonstrate superior utility for policy learning compared to other representation learning te",
    "link": "http://arxiv.org/abs/2305.04718",
    "context": "Title: The Treachery of Images: Bayesian Scene Keypoints for Deep Policy Learning in Robotic Manipulation. (arXiv:2305.04718v2 [cs.RO] UPDATED)\nAbstract: In policy learning for robotic manipulation, sample efficiency is of paramount importance. Thus, learning and extracting more compact representations from camera observations is a promising avenue. However, current methods often assume full observability of the scene and struggle with scale invariance. In many tasks and settings, this assumption does not hold as objects in the scene are often occluded or lie outside the field of view of the camera, rendering the camera observation ambiguous with regard to their location. To tackle this problem, we present BASK, a Bayesian approach to tracking scale-invariant keypoints over time. Our approach successfully resolves inherent ambiguities in images, enabling keypoint tracking on symmetrical objects and occluded and out-of-view objects. We employ our method to learn challenging multi-object robot manipulation tasks from wrist camera observations and demonstrate superior utility for policy learning compared to other representation learning te",
    "path": "papers/23/05/2305.04718.json",
    "total_tokens": 993,
    "translated_title": "图像的背叛：贝叶斯场景关键点在机器人操作中的深度策略学习",
    "translated_abstract": "在机器人操作的策略学习中，样本效率至关重要。因此，从相机观察中学习和提取更紧凑的表示是一个有前途的途径。然而，当前的方法常常假设场景的完全可观测性，并且对于尺度不变性的处理存在困难。在许多任务和情景中，这个假设并不成立，因为场景中的物体经常被遮挡或者位于相机的视野之外，导致相机观察在物体位置方面产生歧义。为了解决这个问题，我们提出了BASK，一种贝叶斯方法来跟踪随时间变化的尺度不变关键点。我们的方法成功地解决了图像中固有的歧义问题，实现了对对称物体和遮挡和视野之外的物体的关键点跟踪。我们利用我们的方法从手腕相机观察中学习具有挑战性的多物体机器人操作任务，并与其他表示学习方法相比，展示了更出色的策略学习效果。",
    "tldr": "该论文介绍了一种用于机器人操作中的深度策略学习的贝叶斯场景关键点跟踪方法。该方法通过解决图像中的歧义问题，实现了对于对称物体和遮挡和视野之外物体的关键点跟踪，提高了相机观察的效用，对于策略学习具有优势。",
    "en_tdlr": "This paper presents a Bayesian approach for tracking scene keypoints in robotic manipulation, which improves the utility of camera observations by resolving ambiguities and enabling keypoint tracking on symmetrical objects and occluded and out-of-view objects. The method demonstrates superior performance for policy learning compared to other representation learning approaches."
}