{
    "title": "BitGNN: Unleashing the Performance Potential of Binary Graph Neural Networks on GPUs. (arXiv:2305.02522v1 [cs.DC])",
    "abstract": "Recent studies have shown that Binary Graph Neural Networks (GNNs) are promising for saving computations of GNNs through binarized tensors. Prior work, however, mainly focused on algorithm designs or training techniques, leaving it open to how to materialize the performance potential on accelerator hardware fully. This work redesigns the binary GNN inference backend from the efficiency perspective. It fills the gap by proposing a series of abstractions and techniques to map binary GNNs and their computations best to fit the nature of bit manipulations on GPUs. Results on real-world graphs with GCNs, GraphSAGE, and GraphSAINT show that the proposed techniques outperform state-of-the-art binary GNN implementations by 8-22X with the same accuracy maintained. BitGNN code is publicly available.",
    "link": "http://arxiv.org/abs/2305.02522",
    "context": "Title: BitGNN: Unleashing the Performance Potential of Binary Graph Neural Networks on GPUs. (arXiv:2305.02522v1 [cs.DC])\nAbstract: Recent studies have shown that Binary Graph Neural Networks (GNNs) are promising for saving computations of GNNs through binarized tensors. Prior work, however, mainly focused on algorithm designs or training techniques, leaving it open to how to materialize the performance potential on accelerator hardware fully. This work redesigns the binary GNN inference backend from the efficiency perspective. It fills the gap by proposing a series of abstractions and techniques to map binary GNNs and their computations best to fit the nature of bit manipulations on GPUs. Results on real-world graphs with GCNs, GraphSAGE, and GraphSAINT show that the proposed techniques outperform state-of-the-art binary GNN implementations by 8-22X with the same accuracy maintained. BitGNN code is publicly available.",
    "path": "papers/23/05/2305.02522.json",
    "total_tokens": 852,
    "translated_title": "BitGNN：释放二进制图神经网络在GPU上的性能潜力",
    "translated_abstract": "最近的研究表明，通过对张量进行二值化，二进制图神经网络（GNN）可以节省GNN计算的计算量。然而，先前的工作主要集中在算法设计或训练技术上，没有完全实现将性能潜力显现到加速器硬件上的方法。本文从效率的角度重新设计了二进制GNN推理后端，并提出了一系列抽象和技术，以最佳地映射二进制GNN及其计算，以适应GPU上的位操作的特性。在使用GCNs、GraphSAGE和GraphSAINT的真实图上，实验结果表明，所提出的技术在保持相同准确性的同时，比最先进的二进制GNN实现提高了8-22倍。BitGNN代码已公开发布。",
    "tldr": "本文提出了一种从效率角度重新设计的二进制GNN推理后端算法，用于充分发挥GPU上位操作的特性，实验结果表明提出的算法比最先进的二进制GNN实现提高了8-22倍的性能，保持相同准确性。",
    "en_tdlr": "This paper proposes a redesigned binary graph neural network (GNN) inference backend algorithm from an efficiency perspective, which optimally maps binary GNN and computations to fit the nature of bit manipulations on GPUs. Experimental results show an 8-22X performance improvement with the same accuracy maintained compared to state-of-the-art binary GNN implementations. The proposed BitGNN algorithm is publicly available."
}