{
    "title": "Federated Variational Inference: Towards Improved Personalization and Generalization. (arXiv:2305.13672v1 [cs.LG])",
    "abstract": "Conventional federated learning algorithms train a single global model by leveraging all participating clients' data. However, due to heterogeneity in client generative distributions and predictive models, these approaches may not appropriately approximate the predictive process, converge to an optimal state, or generalize to new clients. We study personalization and generalization in stateless cross-device federated learning setups assuming heterogeneity in client data distributions and predictive models. We first propose a hierarchical generative model and formalize it using Bayesian Inference. We then approximate this process using Variational Inference to train our model efficiently. We call this algorithm Federated Variational Inference (FedVI). We use PAC-Bayes analysis to provide generalization bounds for FedVI. We evaluate our model on FEMNIST and CIFAR-100 image classification and show that FedVI beats the state-of-the-art on both tasks.",
    "link": "http://arxiv.org/abs/2305.13672",
    "context": "Title: Federated Variational Inference: Towards Improved Personalization and Generalization. (arXiv:2305.13672v1 [cs.LG])\nAbstract: Conventional federated learning algorithms train a single global model by leveraging all participating clients' data. However, due to heterogeneity in client generative distributions and predictive models, these approaches may not appropriately approximate the predictive process, converge to an optimal state, or generalize to new clients. We study personalization and generalization in stateless cross-device federated learning setups assuming heterogeneity in client data distributions and predictive models. We first propose a hierarchical generative model and formalize it using Bayesian Inference. We then approximate this process using Variational Inference to train our model efficiently. We call this algorithm Federated Variational Inference (FedVI). We use PAC-Bayes analysis to provide generalization bounds for FedVI. We evaluate our model on FEMNIST and CIFAR-100 image classification and show that FedVI beats the state-of-the-art on both tasks.",
    "path": "papers/23/05/2305.13672.json",
    "total_tokens": 858,
    "translated_title": "联邦变异推断：迈向个性化和泛化的改进",
    "translated_abstract": "传统的联邦学习算法通过利用所有参与客户端的数据来训练单个全局模型。然而，由于客户生成分布和预测模型的异质性，这些方法可能不适当地近似预测过程、收敛到最优状态或泛化到新客户端。我们研究在假设客户数据分布和预测模型的异质性的状态下，跨设备联邦学习设置中的个性化和泛化。我们首先提出了一种分层生成模型，并使用贝叶斯推断加以规范化。然后，我们使用变分推断来有效地训练我们的模型。我们称此算法为联邦变分推断（FedVI）。我们使用PAC-Bayes分析为FedVI提供了泛化界限。我们在FEMNIST和CIFAR-100图像分类上评估了我们的模型，并展示了FedVI在两个任务上均超越了现有技术水平。",
    "tldr": "本文提出了一种名为联邦变分推断的算法，用于跨设备联邦学习中的个性化和泛化，并在图像分类中超越了现有技术。"
}