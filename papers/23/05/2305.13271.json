{
    "title": "MAGDiff: Covariate Data Set Shift Detection via Activation Graphs of Deep Neural Networks. (arXiv:2305.13271v1 [stat.ML])",
    "abstract": "Despite their successful application to a variety of tasks, neural networks remain limited, like other machine learning methods, by their sensitivity to shifts in the data: their performance can be severely impacted by differences in distribution between the data on which they were trained and that on which they are deployed. In this article, we propose a new family of representations, called MAGDiff, that we extract from any given neural network classifier and that allows for efficient covariate data shift detection without the need to train a new model dedicated to this task. These representations are computed by comparing the activation graphs of the neural network for samples belonging to the training distribution and to the target distribution, and yield powerful data- and task-adapted statistics for the two-sample tests commonly used for data set shift detection. We demonstrate this empirically by measuring the statistical powers of two-sample Kolmogorov-Smirnov (KS) tests on sev",
    "link": "http://arxiv.org/abs/2305.13271",
    "context": "Title: MAGDiff: Covariate Data Set Shift Detection via Activation Graphs of Deep Neural Networks. (arXiv:2305.13271v1 [stat.ML])\nAbstract: Despite their successful application to a variety of tasks, neural networks remain limited, like other machine learning methods, by their sensitivity to shifts in the data: their performance can be severely impacted by differences in distribution between the data on which they were trained and that on which they are deployed. In this article, we propose a new family of representations, called MAGDiff, that we extract from any given neural network classifier and that allows for efficient covariate data shift detection without the need to train a new model dedicated to this task. These representations are computed by comparing the activation graphs of the neural network for samples belonging to the training distribution and to the target distribution, and yield powerful data- and task-adapted statistics for the two-sample tests commonly used for data set shift detection. We demonstrate this empirically by measuring the statistical powers of two-sample Kolmogorov-Smirnov (KS) tests on sev",
    "path": "papers/23/05/2305.13271.json",
    "total_tokens": 886,
    "translated_title": "MAGDiff: 利用深度神经网络激活图检测协变数据集转移",
    "translated_abstract": "尽管神经网络被广泛应用于各种任务，但像其他机器学习方法一样，它们受到数据转移的影响，在训练数据与实际应用数据之间分布存在差异时，其性能会受到严重影响。本文提出了一种称为 MAGDiff 的新表示方法，可以从任何给定的神经网络分类器中提取出来，并且可以有效地检测协变数据集转移，而不需要训练专门用于此任务的新模型。这些表示形式是通过比较神经网络激活图来计算的，对于属于训练分布和目标分布的样本，提供了强大的数据和任务自适应统计量，用于检测常用的数据集转移的两个样本测试。我们通过测量两个样本 Kolmogorov-Smirnov（KS）测试的统计功率进行了实证验证。",
    "tldr": "MAGDiff是一种新的表示法，可以从神经网络分类器中提取，可以有效地检测协变数据集转移，而不需要训练新模型。这可以通过对比神经网络激活图来计算，并通过两个样本 Kolmogorov-Smirnov 测试进行实证验证。",
    "en_tdlr": "MAGDiff is a new representation that can be extracted from a neural network classifier and efficiently detect covariate data set shift without training a new model. It is computed by comparing activation graphs of neural networks and is validated through empirical studies using two-sample Kolmogorov-Smirnov tests."
}