{
    "title": "When Giant Language Brains Just Aren't Enough! Domain Pizzazz with Knowledge Sparkle Dust. (arXiv:2305.07230v1 [cs.CL])",
    "abstract": "Large language models (LLMs) have significantly advanced the field of natural language processing, with GPT models at the forefront. While their remarkable performance spans a range of tasks, adapting LLMs for real-world business scenarios still poses challenges warranting further investigation. This paper presents an empirical analysis aimed at bridging the gap in adapting LLMs to practical use cases. To do that, we select the question answering (QA) task of insurance as a case study due to its challenge of reasoning. Based on the task we design a new model relied on LLMs which are empowered by domain-specific knowledge extracted from insurance policy rulebooks. The domain-specific knowledge helps LLMs to understand new concepts of insurance for domain adaptation. Preliminary results on real QA pairs show that knowledge enhancement from policy rulebooks significantly improves the reasoning ability of GPT-3.5 of 50.4% in terms of accuracy. The analysis also indicates that existing publ",
    "link": "http://arxiv.org/abs/2305.07230",
    "context": "Title: When Giant Language Brains Just Aren't Enough! Domain Pizzazz with Knowledge Sparkle Dust. (arXiv:2305.07230v1 [cs.CL])\nAbstract: Large language models (LLMs) have significantly advanced the field of natural language processing, with GPT models at the forefront. While their remarkable performance spans a range of tasks, adapting LLMs for real-world business scenarios still poses challenges warranting further investigation. This paper presents an empirical analysis aimed at bridging the gap in adapting LLMs to practical use cases. To do that, we select the question answering (QA) task of insurance as a case study due to its challenge of reasoning. Based on the task we design a new model relied on LLMs which are empowered by domain-specific knowledge extracted from insurance policy rulebooks. The domain-specific knowledge helps LLMs to understand new concepts of insurance for domain adaptation. Preliminary results on real QA pairs show that knowledge enhancement from policy rulebooks significantly improves the reasoning ability of GPT-3.5 of 50.4% in terms of accuracy. The analysis also indicates that existing publ",
    "path": "papers/23/05/2305.07230.json",
    "total_tokens": 1015,
    "translated_title": "当超级语言模型不足以满足业务需求：领域特定知识提升自然语言处理性能",
    "translated_abstract": "大型语言模型（LLMs）已经显著地推动了自然语言处理领域的进展，GPT模型处于领先地位。虽然它们在许多任务上的表现令人惊叹，但将LLMs用于真实世界的业务场景仍然面临挑战，并需要进一步研究。本文提出了一种经验分析，旨在弥合将LLMs适应于实际使用情况的差距。为此，我们选择保险问答（QA）任务作为案例研究，因为它具有推理的挑战。基于该任务，我们设计了一种新模型，依赖于从保险政策手册中提取的领域特定知识，使LLMs能够理解保险的新概念进行领域适应。实际QA对的初步结果表明，从政策手册中提取的知识显著提高了GPT-3.5的推理能力，准确性提高了50.4％。分析还表明，现有的公开评估标准可能不足以评估LLMs在实际场景中的性能。",
    "tldr": "本文将保险问答作为案例研究，提出了一种新模型，通过从保险政策手册中提取领域特定知识来增强LLMs的性能，实现领域适应，从而显著提高推理准确性。"
}