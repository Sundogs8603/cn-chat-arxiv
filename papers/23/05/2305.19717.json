{
    "title": "Is Rewiring Actually Helpful in Graph Neural Networks?. (arXiv:2305.19717v1 [cs.LG])",
    "abstract": "Graph neural networks compute node representations by performing multiple message-passing steps that consist in local aggregations of node features. Having deep models that can leverage longer-range interactions between nodes is hindered by the issues of over-smoothing and over-squashing. In particular, the latter is attributed to the graph topology which guides the message-passing, causing a node representation to become insensitive to information contained at distant nodes. Many graph rewiring methods have been proposed to remedy or mitigate this problem. However, properly evaluating the benefits of these methods is made difficult by the coupling of over-squashing with other issues strictly related to model training, such as vanishing gradients. Therefore, we propose an evaluation setting based on message-passing models that do not require training to compute node and graph representations. We perform a systematic experimental comparison on real-world node and graph classification ta",
    "link": "http://arxiv.org/abs/2305.19717",
    "context": "Title: Is Rewiring Actually Helpful in Graph Neural Networks?. (arXiv:2305.19717v1 [cs.LG])\nAbstract: Graph neural networks compute node representations by performing multiple message-passing steps that consist in local aggregations of node features. Having deep models that can leverage longer-range interactions between nodes is hindered by the issues of over-smoothing and over-squashing. In particular, the latter is attributed to the graph topology which guides the message-passing, causing a node representation to become insensitive to information contained at distant nodes. Many graph rewiring methods have been proposed to remedy or mitigate this problem. However, properly evaluating the benefits of these methods is made difficult by the coupling of over-squashing with other issues strictly related to model training, such as vanishing gradients. Therefore, we propose an evaluation setting based on message-passing models that do not require training to compute node and graph representations. We perform a systematic experimental comparison on real-world node and graph classification ta",
    "path": "papers/23/05/2305.19717.json",
    "total_tokens": 824,
    "translated_title": "图神经网络中的改连是否真正有用？",
    "translated_abstract": "图神经网络通过执行多个消息传递步骤来计算节点表示，这些步骤包括节点特征的本地聚合。但是，深层模型能够利用节点之间更长距离的交互的问题受到了过度平滑和过度压缩的影响。而后者归因于指导消息传递的图拓扑，导致节点表示对包含在远程节点上的信息不敏感。许多改连方法已被提出来解决或减轻这个问题。然而，由于过度压缩与其他与模型训练密切相关的问题（如消失的梯度）相耦合，所以正确评估这些方法的好处是困难的。因此，我们提出了一种基于消息传递模型的评估设置，这些模型不需要训练即可计算节点和图表示。我们在真实世界的节点和图分类任务上进行了系统的实验比较。",
    "tldr": "本文研究了图神经网络中的改连方法是否有用，提出了一种新的评估设置，并在真实世界的节点和图分类任务上进行了系统的实验比较。",
    "en_tdlr": "This paper investigates the effectiveness of graph rewiring methods in graph neural networks, proposes a new evaluation setting, and conducts systematic experiments on real-world node and graph classification tasks."
}