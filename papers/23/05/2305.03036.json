{
    "title": "Learning Hand-Held Object Reconstruction from In-The-Wild Videos. (arXiv:2305.03036v1 [cs.CV])",
    "abstract": "Prior works for reconstructing hand-held objects from a single image rely on direct 3D shape supervision which is challenging to gather in real world at scale. Consequently, these approaches do not generalize well when presented with novel objects in in-the-wild settings. While 3D supervision is a major bottleneck, there is an abundance of in-the-wild raw video data showing hand-object interactions. In this paper, we automatically extract 3D supervision (via multiview 2D supervision) from such raw video data to scale up the learning of models for hand-held object reconstruction. This requires tackling two key challenges: unknown camera pose and occlusion. For the former, we use hand pose (predicted from existing techniques, e.g. FrankMocap) as a proxy for object pose. For the latter, we learn data-driven 3D shape priors using synthetic objects from the ObMan dataset. We use these indirect 3D cues to train occupancy networks that predict the 3D shape of objects from a single RGB image. ",
    "link": "http://arxiv.org/abs/2305.03036",
    "context": "Title: Learning Hand-Held Object Reconstruction from In-The-Wild Videos. (arXiv:2305.03036v1 [cs.CV])\nAbstract: Prior works for reconstructing hand-held objects from a single image rely on direct 3D shape supervision which is challenging to gather in real world at scale. Consequently, these approaches do not generalize well when presented with novel objects in in-the-wild settings. While 3D supervision is a major bottleneck, there is an abundance of in-the-wild raw video data showing hand-object interactions. In this paper, we automatically extract 3D supervision (via multiview 2D supervision) from such raw video data to scale up the learning of models for hand-held object reconstruction. This requires tackling two key challenges: unknown camera pose and occlusion. For the former, we use hand pose (predicted from existing techniques, e.g. FrankMocap) as a proxy for object pose. For the latter, we learn data-driven 3D shape priors using synthetic objects from the ObMan dataset. We use these indirect 3D cues to train occupancy networks that predict the 3D shape of objects from a single RGB image. ",
    "path": "papers/23/05/2305.03036.json",
    "total_tokens": 976,
    "translated_title": "从野外视频中学习手持物体重建",
    "translated_abstract": "先前的单影像手持物体重建方法依赖于难以在真实世界中规模化收集的直接3D形状监督，因此这些方法在野外环境下面对新颖物体时难以推广。本文从生动的野外原始视频数据中自动提取三维监督，并通过多视角二维监督来扩展手持物体重建模型的学习。这需要应对两个关键挑战：未知的相机姿势和遮挡。对于前者，我们使用手部姿势作为物体姿势的代理。对于后者，我们使用ObMan数据集中合成的物体来学习数据驱动的三维形状先验知识。我们使用这些间接的三维线索来训练占据网络，从单个RGB图像预测物体的三维形状。",
    "tldr": "本研究提出了一种从野外视频中自动提取三维监督来扩展手持物体重建模型的学习方法。通过使用手部姿势作为物体姿势的代理和学习数据驱动的三维形状先验知识等方法，有效地解决了未知相机姿势和遮挡等问题，从而通过从单个RGB图像预测物体三维形状的占据网络得到了优秀的结果。",
    "en_tdlr": "This paper proposes a method to extend the learning of models for hand-held object reconstruction by automatically extracting 3D supervision from in-the-wild raw video data. It effectively addresses the challenges of unknown camera pose and occlusion by using hand pose as a proxy for object pose and learning data-driven 3D shape priors, achieving excellent results with occupancy networks predicting the 3D shape of objects from a single RGB image."
}