{
    "title": "Pointwise Representational Similarity. (arXiv:2305.19294v1 [cs.LG])",
    "abstract": "With the increasing reliance on deep neural networks, it is important to develop ways to better understand their learned representations. Representation similarity measures have emerged as a popular tool for examining learned representations However, existing measures only provide aggregate estimates of similarity at a global level, i.e. over a set of representations for N input examples. As such, these measures are not well-suited for investigating representations at a local level, i.e. representations of a single input example. Local similarity measures are needed, for instance, to understand which individual input representations are affected by training interventions to models (e.g. to be more fair and unbiased) or are at greater risk of being misclassified. In this work, we fill in this gap and propose Pointwise Normalized Kernel Alignment (PNKA), a measure that quantifies how similarly an individual input is represented in two representation spaces. Intuitively, PNKA compares the",
    "link": "http://arxiv.org/abs/2305.19294",
    "context": "Title: Pointwise Representational Similarity. (arXiv:2305.19294v1 [cs.LG])\nAbstract: With the increasing reliance on deep neural networks, it is important to develop ways to better understand their learned representations. Representation similarity measures have emerged as a popular tool for examining learned representations However, existing measures only provide aggregate estimates of similarity at a global level, i.e. over a set of representations for N input examples. As such, these measures are not well-suited for investigating representations at a local level, i.e. representations of a single input example. Local similarity measures are needed, for instance, to understand which individual input representations are affected by training interventions to models (e.g. to be more fair and unbiased) or are at greater risk of being misclassified. In this work, we fill in this gap and propose Pointwise Normalized Kernel Alignment (PNKA), a measure that quantifies how similarly an individual input is represented in two representation spaces. Intuitively, PNKA compares the",
    "path": "papers/23/05/2305.19294.json",
    "total_tokens": 817,
    "translated_title": "个别点表示相似性",
    "translated_abstract": "随着对深度神经网络的依赖性越来越大，发展更好地理解它们所学表示方式的方法变得越来越重要。表征相似性度量已经成为了一种常用工具，用于检查学习到的表示。然而，现有的度量只能在全局层面上对相似性进行汇总估计，即在N个输入示例的一组表示中进行。因此，这些度量不适合于在局部层面上调查表示，即单个输入示例的表示。例如，我们需要局部相似性度量，以了解哪些单个输入表示受到了模型训练干预的影响（例如，更公平和无偏）或更容易被错误分类。在本文中，我们填补了这一空白并提出了PNKA（Pointwise Normalized Kernel Alignment），它对比度量了在两个表示空间中一个个别输入的表示相似程度。",
    "tldr": "本文介绍了 PNKA，一种可以量化单个输入在两个表示空间中的相似度的方法，填补了全局相似性度量不能局部调查表示的空白。"
}