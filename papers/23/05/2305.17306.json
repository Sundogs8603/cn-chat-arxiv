{
    "title": "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance. (arXiv:2305.17306v1 [cs.CL])",
    "abstract": "As large language models (LLMs) are continuously being developed, their evaluation becomes increasingly important yet challenging. This work proposes Chain-of-Thought Hub, an open-source evaluation suite on the multi-step reasoning capabilities of large language models. We are interested in this setting for two reasons: (1) from the behavior of GPT and PaLM model family, we observe that complex reasoning is likely to be a key differentiator between weaker and stronger LLMs; (2) we envisage large language models to become the next-generation computational platform and foster an ecosystem of LLM-based new applications, this naturally requires the foundation models to perform complex tasks that often involve the composition of linguistic and logical operations. Our approach is to compile a suite of challenging reasoning benchmarks to track the progress of LLMs. Our current results show that: (1) model scale clearly correlates with reasoning capabilities; (2) As of May 2023, Claude-v1.3 an",
    "link": "http://arxiv.org/abs/2305.17306",
    "context": "Title: Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance. (arXiv:2305.17306v1 [cs.CL])\nAbstract: As large language models (LLMs) are continuously being developed, their evaluation becomes increasingly important yet challenging. This work proposes Chain-of-Thought Hub, an open-source evaluation suite on the multi-step reasoning capabilities of large language models. We are interested in this setting for two reasons: (1) from the behavior of GPT and PaLM model family, we observe that complex reasoning is likely to be a key differentiator between weaker and stronger LLMs; (2) we envisage large language models to become the next-generation computational platform and foster an ecosystem of LLM-based new applications, this naturally requires the foundation models to perform complex tasks that often involve the composition of linguistic and logical operations. Our approach is to compile a suite of challenging reasoning benchmarks to track the progress of LLMs. Our current results show that: (1) model scale clearly correlates with reasoning capabilities; (2) As of May 2023, Claude-v1.3 an",
    "path": "papers/23/05/2305.17306.json",
    "total_tokens": 1021,
    "translated_title": "“Chain-of-Thought Hub: 连续测量大型语言模型推理表现的努力”",
    "translated_abstract": "“随着大型语言模型（LLMs）的不断发展，它们的评估变得越来越重要但也更具挑战性。本文提出了 Chain-of-Thought Hub，这是一个开源的评估套件，旨在评估大型语言模型的多步推理能力。我们之所以对这个设置感兴趣，是因为 (1) 从 GPT 和 PaLM 模型家族的行为中，我们观察到复杂的推理很可能是一个更弱和更强的LLMs之间的关键区别； (2) 我们预见大型语言模型将成为下一代计算平台，并促进基于LLM的新应用的生态系统，这自然需要基础模型执行常常涉及语言和逻辑操作组合的复杂任务。我们的方法是编制一系列具有挑战性的推理基准，以跟踪LLMs的进展。我们目前的结果表明：(1) 模型规模显然与推理能力相关；(2) 截至2023年5月，Claude-v1.3 是迄今为止推理能力最强的LLM 。”",
    "tldr": "本文介绍了一个名为 Chain-of-Thought Hub 的开源评估套件，目的是评估大型语言模型的多步推理能力。它是为了追踪LLMs进展而编制的具有挑战性的推理基准。目前的研究结果表明，模型规模与推理能力相关，而 Claude-v1.3 是迄今为止推理能力最强的LLM。",
    "en_tdlr": "This paper introduces an open-source evaluation suite called Chain-of-Thought Hub, which aims to evaluate the multi-step reasoning capabilities of large language models. It is developed to track the progress of LLMs with challenging reasoning benchmarks. The current results indicate that model scale correlates with reasoning performance, and Claude-v1.3 is currently the strongest LLM in terms of reasoning capabilities."
}