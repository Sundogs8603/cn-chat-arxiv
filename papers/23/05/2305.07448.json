{
    "title": "Deep Deterministic Policy Gradient for End-to-End Communication Systems without Prior Channel Knowledge. (arXiv:2305.07448v1 [cs.NI])",
    "abstract": "End-to-End (E2E) learning-based concept has been recently introduced to jointly optimize both the transmitter and the receiver in wireless communication systems. Unfortunately, this E2E learning architecture requires a prior differentiable channel model to jointly train the deep neural networks (DNNs) at the transceivers, which is hardly obtained in practice. This paper aims to solve this issue by developing a deep deterministic policy gradient (DDPG)-based framework. In particular, the proposed solution uses the loss value of the receiver DNN as the reward to train the transmitter DNN. The simulation results then show that our proposed solution can jointly train the transmitter and the receiver without requiring the prior channel model. In addition, we demonstrate that the proposed DDPG-based solution can achieve better detection performance compared to the state-of-the-art solutions.",
    "link": "http://arxiv.org/abs/2305.07448",
    "context": "Title: Deep Deterministic Policy Gradient for End-to-End Communication Systems without Prior Channel Knowledge. (arXiv:2305.07448v1 [cs.NI])\nAbstract: End-to-End (E2E) learning-based concept has been recently introduced to jointly optimize both the transmitter and the receiver in wireless communication systems. Unfortunately, this E2E learning architecture requires a prior differentiable channel model to jointly train the deep neural networks (DNNs) at the transceivers, which is hardly obtained in practice. This paper aims to solve this issue by developing a deep deterministic policy gradient (DDPG)-based framework. In particular, the proposed solution uses the loss value of the receiver DNN as the reward to train the transmitter DNN. The simulation results then show that our proposed solution can jointly train the transmitter and the receiver without requiring the prior channel model. In addition, we demonstrate that the proposed DDPG-based solution can achieve better detection performance compared to the state-of-the-art solutions.",
    "path": "papers/23/05/2305.07448.json",
    "total_tokens": 877,
    "translated_title": "无先验信道知识的端到端通信系统的深度确定性策略梯度",
    "translated_abstract": "最近引入了端到端（E2E）基于学习的概念，以共同优化无线通信系统中的发送器和接收器。不幸的是，这种E2E学习架构需要先前的可微分信道模型来共同训练发射接收器的深度神经网络（DNNs），这在实践中几乎不可能。本文旨在通过开发基于深度确定性策略梯度（DDPG）的框架来解决这个问题。特别地，所提出的解决方案使用接收器DNN的损失值作为奖励来训练发射器DNN。模拟结果显示，我们的提议可以共同训练发射器和接收器而不需要先前的信道模型。此外，我们证明所提出的基于DDPG的解决方案可以实现比现有解决方案更好的检测性能。",
    "tldr": "本研究提出了一种基于深度确定性策略梯度（DDPG）的框架来解决无先验信道知识的端到端通信系统中发射器和接收器联合训练的问题。与现有方案相比，该方法可以获得更好的检测性能。",
    "en_tdlr": "This paper proposes a deep deterministic policy gradient (DDPG)-based framework to solve the joint training problem of the transmitter and the receiver in end-to-end communication systems without prior channel knowledge. The proposed approach achieves better detection performance than existing solutions."
}