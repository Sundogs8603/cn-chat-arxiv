{
    "title": "Generative and Pseudo-Relevant Feedback for Sparse, Dense and Learned Sparse Retrieval. (arXiv:2305.07477v1 [cs.IR])",
    "abstract": "Pseudo-relevance feedback (PRF) is a classical approach to address lexical mismatch by enriching the query using first-pass retrieval. Moreover, recent work on generative-relevance feedback (GRF) shows that query expansion models using text generated from large language models can improve sparse retrieval without depending on first-pass retrieval effectiveness. This work extends GRF to dense and learned sparse retrieval paradigms with experiments over six standard document ranking benchmarks. We find that GRF improves over comparable PRF techniques by around 10% on both precision and recall-oriented measures. Nonetheless, query analysis shows that GRF and PRF have contrasting benefits, with GRF providing external context not present in first-pass retrieval, whereas PRF grounds the query to the information contained within the target corpus. Thus, we propose combining generative and pseudo-relevance feedback ranking signals to achieve the benefits of both feedback classes, which signifi",
    "link": "http://arxiv.org/abs/2305.07477",
    "context": "Title: Generative and Pseudo-Relevant Feedback for Sparse, Dense and Learned Sparse Retrieval. (arXiv:2305.07477v1 [cs.IR])\nAbstract: Pseudo-relevance feedback (PRF) is a classical approach to address lexical mismatch by enriching the query using first-pass retrieval. Moreover, recent work on generative-relevance feedback (GRF) shows that query expansion models using text generated from large language models can improve sparse retrieval without depending on first-pass retrieval effectiveness. This work extends GRF to dense and learned sparse retrieval paradigms with experiments over six standard document ranking benchmarks. We find that GRF improves over comparable PRF techniques by around 10% on both precision and recall-oriented measures. Nonetheless, query analysis shows that GRF and PRF have contrasting benefits, with GRF providing external context not present in first-pass retrieval, whereas PRF grounds the query to the information contained within the target corpus. Thus, we propose combining generative and pseudo-relevance feedback ranking signals to achieve the benefits of both feedback classes, which signifi",
    "path": "papers/23/05/2305.07477.json",
    "total_tokens": 958,
    "translated_title": "生成式和伪相关反馈在稀疏、稠密和学习稀疏检索中的应用",
    "translated_abstract": "伪相关反馈（PRF）是一种经典的方法，通过使用第一次检索来丰富查询来解决词汇不匹配的问题。此外，最近的生成式相关反馈（GRF）工作表明，使用大型语言模型生成的文本进行查询扩展模型可以改善稀疏检索，而无需依赖于第一次检索的效果。本文将GRF扩展到稠密和学习稀疏检索范例，并在六个标准文档排序基准测试中进行实验。我们发现，GRF在精确度和召回率方面的表现均比类似的PRF技术提高了约10%。然而，查询分析显示，GRF和PRF具有相反的优点，GRF提供了外部上下文，而PRF则将查询基于目标语料库中包含的信息。因此，我们建议将生成式和伪相关反馈排名信号结合起来，以实现两个反馈类别的好处。",
    "tldr": "本文研究将生成式和伪相关反馈在稀疏、稠密和学习稀疏检索中的应用。实验表明，相比类似的伪相关反馈技术，生成式相关反馈可以提高约10%的精确度和召回率。同时，我们提出将两种反馈信号结合起来以实现它们的优势。",
    "en_tdlr": "This paper proposes to apply generative and pseudo-relevant feedback in sparse, dense, and learned sparse retrieval. Experiments show that generative-relevance feedback can improve precision and recall by 10% compared to comparable pseudo-relevance feedback techniques. Combining the two feedback signals is suggested to achieve the benefits of both."
}