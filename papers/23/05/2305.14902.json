{
    "title": "M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection",
    "abstract": "arXiv:2305.14902v2 Announce Type: replace  Abstract: Large language models (LLMs) have demonstrated remarkable capability to generate fluent responses to a wide variety of user queries. However, this has also raised concerns about the potential misuse of such texts in journalism, education, and academia. In this study, we strive to create automated systems that can detect machine-generated texts and pinpoint potential misuse. We first introduce a large-scale benchmark \\textbf{M4}, which is a multi-generator, multi-domain, and multi-lingual corpus for machine-generated text detection. Through an extensive empirical study of this dataset, we show that it is challenging for detectors to generalize well on instances from unseen domains or LLMs. In such cases, detectors tend to misclassify machine-generated text as human-written. These results show that the problem is far from solved and that there is a lot of room for improvement. We believe that our dataset will enable future research tow",
    "link": "https://arxiv.org/abs/2305.14902",
    "context": "Title: M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection\nAbstract: arXiv:2305.14902v2 Announce Type: replace  Abstract: Large language models (LLMs) have demonstrated remarkable capability to generate fluent responses to a wide variety of user queries. However, this has also raised concerns about the potential misuse of such texts in journalism, education, and academia. In this study, we strive to create automated systems that can detect machine-generated texts and pinpoint potential misuse. We first introduce a large-scale benchmark \\textbf{M4}, which is a multi-generator, multi-domain, and multi-lingual corpus for machine-generated text detection. Through an extensive empirical study of this dataset, we show that it is challenging for detectors to generalize well on instances from unseen domains or LLMs. In such cases, detectors tend to misclassify machine-generated text as human-written. These results show that the problem is far from solved and that there is a lot of room for improvement. We believe that our dataset will enable future research tow",
    "path": "papers/23/05/2305.14902.json",
    "total_tokens": 909,
    "translated_title": "M4: 多生成器、多领域和多语言黑匣子机器生成文本检测",
    "translated_abstract": "大型语言模型（LLMs）已经展示出在回答各种用户查询时生成流畅回答的显著能力。然而，这也引发了对这些文本在新闻、教育和学术领域潜在误用的担忧。在本研究中，我们努力创建可以检测机器生成文本并指出潜在误用的自动系统。我们首先引入了一个大规模基准M4，这是一个多生成器、多领域和多语言的用于机器生成文本检测的语料库。通过对这个数据集的广泛实证研究，我们展示了检测器很难在来自未见领域或LLMs的实例上很好地泛化。在这种情况下，检测器往往会误将机器生成的文本分类为人工编写的。这些结果表明，这个问题还远未解决，还有很大的改进空间。我们相信我们的数据集将促进未来研究。",
    "tldr": "大型语言模型产生的文本可能被滥用，研究引入了名为M4的跨领域、多语言语料库，揭示了检测器在未知领域或模型上泛化的困难，指出存在改进空间。",
    "en_tdlr": "Text generated by large language models may be misused, the study introduces a cross-domain, multilingual corpus named M4, revealing the challenges for detectors to generalize on unseen domains or models, indicating room for improvement."
}