{
    "title": "MultiTabQA: Generating Tabular Answers for Multi-Table Question Answering. (arXiv:2305.12820v2 [cs.CL] UPDATED)",
    "abstract": "Recent advances in tabular question answering (QA) with large language models are constrained in their coverage and only answer questions over a single table. However, real-world queries are complex in nature, often over multiple tables in a relational database or web page. Single table questions do not involve common table operations such as set operations, Cartesian products (joins), or nested queries. Furthermore, multi-table operations often result in a tabular output, which necessitates table generation capabilities of tabular QA models. To fill this gap, we propose a new task of answering questions over multiple tables. Our model, MultiTabQA, not only answers questions over multiple tables, but also generalizes to generate tabular answers. To enable effective training, we build a pre-training dataset comprising of 132,645 SQL queries and tabular answers. Further, we evaluate the generated tables by introducing table-specific metrics of varying strictness assessing various levels ",
    "link": "http://arxiv.org/abs/2305.12820",
    "context": "Title: MultiTabQA: Generating Tabular Answers for Multi-Table Question Answering. (arXiv:2305.12820v2 [cs.CL] UPDATED)\nAbstract: Recent advances in tabular question answering (QA) with large language models are constrained in their coverage and only answer questions over a single table. However, real-world queries are complex in nature, often over multiple tables in a relational database or web page. Single table questions do not involve common table operations such as set operations, Cartesian products (joins), or nested queries. Furthermore, multi-table operations often result in a tabular output, which necessitates table generation capabilities of tabular QA models. To fill this gap, we propose a new task of answering questions over multiple tables. Our model, MultiTabQA, not only answers questions over multiple tables, but also generalizes to generate tabular answers. To enable effective training, we build a pre-training dataset comprising of 132,645 SQL queries and tabular answers. Further, we evaluate the generated tables by introducing table-specific metrics of varying strictness assessing various levels ",
    "path": "papers/23/05/2305.12820.json",
    "total_tokens": 928,
    "translated_title": "MultiTabQA：针对多表问题回答生成表格答案",
    "translated_abstract": "近期，使用大型语言模型进行表格问答的研究取得了一定进展，但其覆盖面还受限于答复单表问题。然而，现实中查询具有复杂性，常跨越多个关系数据库或网页表格。对于单表问题，不涉及常见的表格操作，如集合运算、笛卡尔积（连接）或嵌套查询。此外，多表操作通常会产生表格输出，这就需要表格QA模型有生成表格的能力。为了填补这一空白，我们提出了一个新任务，即回答多表问题。我们的模型MultiTabQA不仅回答多表问题，还可以泛化地生成表格答案。为了使训练更有效，我们建立了一个包含132,645个SQL查询和表格答案的预训练数据集。此外，我们通过引入不同严格程度的特定于表格的度量标准对生成的表格进行了评估，评估实验表明，MultiTabQA在新任务上的表现大大优于现有基线。",
    "tldr": "本文提出一项新任务，即回答多表问题。 我们的新模型MultiTabQA不仅可以回答多表问题，还可以泛化地生成表格答案，并在实验中表现出比现有基线更好的性能。",
    "en_tdlr": "The paper proposes a new task of answering questions over multiple tables and presents a new model MultiTabQA which not only can answer multi-table questions but can also generalize to generate tabular answers with better performance than existing baselines according to the experiment evaluation."
}