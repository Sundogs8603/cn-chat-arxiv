{
    "title": "A Mechanistic Interpretation of Arithmetic Reasoning in Language Models using Causal Mediation Analysis. (arXiv:2305.15054v2 [cs.CL] UPDATED)",
    "abstract": "Mathematical reasoning in large language models (LMs) has garnered significant attention in recent work, but there is a limited understanding of how these models process and store information related to arithmetic tasks within their architecture. In order to improve our understanding of this aspect of language models, we present a mechanistic interpretation of Transformer-based LMs on arithmetic questions using a causal mediation analysis framework. By intervening on the activations of specific model components and measuring the resulting changes in predicted probabilities, we identify the subset of parameters responsible for specific predictions. This provides insights into how information related to arithmetic is processed by LMs. Our experimental results indicate that LMs process the input by transmitting the information relevant to the query from mid-sequence early layers to the final token using the attention mechanism. Then, this information is processed by a set of MLP modules, ",
    "link": "http://arxiv.org/abs/2305.15054",
    "context": "Title: A Mechanistic Interpretation of Arithmetic Reasoning in Language Models using Causal Mediation Analysis. (arXiv:2305.15054v2 [cs.CL] UPDATED)\nAbstract: Mathematical reasoning in large language models (LMs) has garnered significant attention in recent work, but there is a limited understanding of how these models process and store information related to arithmetic tasks within their architecture. In order to improve our understanding of this aspect of language models, we present a mechanistic interpretation of Transformer-based LMs on arithmetic questions using a causal mediation analysis framework. By intervening on the activations of specific model components and measuring the resulting changes in predicted probabilities, we identify the subset of parameters responsible for specific predictions. This provides insights into how information related to arithmetic is processed by LMs. Our experimental results indicate that LMs process the input by transmitting the information relevant to the query from mid-sequence early layers to the final token using the attention mechanism. Then, this information is processed by a set of MLP modules, ",
    "path": "papers/23/05/2305.15054.json",
    "total_tokens": 805,
    "translated_title": "使用因果中介分析解释语言模型中的算术推理",
    "translated_abstract": "近期的研究对大型语言模型中的数学推理引起了重要关注，但对于这些模型如何处理和存储与算术任务相关的信息的理解还很有限。为了加深我们对语言模型这一方面的理解，我们提出了使用因果中介分析框架对基于Transformer的语言模型在算术问题上进行机制解释。通过对特定模型组件的激活进行干预并测量预测概率的变化，我们确定了特定预测所负责的参数子集。这为我们了解语言模型如何处理与算术相关的信息提供了见解。实验结果表明，语言模型通过使用注意机制将与查询相关的信息从中间层传输到最终的令牌，然后通过一组MLP模块处理这些信息。",
    "tldr": "本研究通过因果中介分析框架对基于Transformer的语言模型在算术问题上进行了机制解释，发现语言模型通过注意机制传输与查询相关的信息，并通过一组MLP模块进行处理。"
}