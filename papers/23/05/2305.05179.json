{
    "title": "Simplicial Hopfield networks. (arXiv:2305.05179v1 [cs.NE])",
    "abstract": "Hopfield networks are artificial neural networks which store memory patterns on the states of their neurons by choosing recurrent connection weights and update rules such that the energy landscape of the network forms attractors around the memories. How many stable, sufficiently-attracting memory patterns can we store in such a network using $N$ neurons? The answer depends on the choice of weights and update rule. Inspired by setwise connectivity in biology, we extend Hopfield networks by adding setwise connections and embedding these connections in a simplicial complex. Simplicial complexes are higher dimensional analogues of graphs which naturally represent collections of pairwise and setwise relationships. We show that our simplicial Hopfield networks increase memory storage capacity. Surprisingly, even when connections are limited to a small random subset of equivalent size to an all-pairwise network, our networks still outperform their pairwise counterparts. Such scenarios include",
    "link": "http://arxiv.org/abs/2305.05179",
    "context": "Title: Simplicial Hopfield networks. (arXiv:2305.05179v1 [cs.NE])\nAbstract: Hopfield networks are artificial neural networks which store memory patterns on the states of their neurons by choosing recurrent connection weights and update rules such that the energy landscape of the network forms attractors around the memories. How many stable, sufficiently-attracting memory patterns can we store in such a network using $N$ neurons? The answer depends on the choice of weights and update rule. Inspired by setwise connectivity in biology, we extend Hopfield networks by adding setwise connections and embedding these connections in a simplicial complex. Simplicial complexes are higher dimensional analogues of graphs which naturally represent collections of pairwise and setwise relationships. We show that our simplicial Hopfield networks increase memory storage capacity. Surprisingly, even when connections are limited to a small random subset of equivalent size to an all-pairwise network, our networks still outperform their pairwise counterparts. Such scenarios include",
    "path": "papers/23/05/2305.05179.json",
    "total_tokens": 817,
    "translated_title": "简单形式化 Hopfield网络",
    "translated_abstract": "Hopfield网络是一种人工神经网络，它通过选择循环连接权重和更新规则，在其神经元状态上存储记忆模式，使网络的能量景观围绕记忆处形成吸引子。我们可以使用$N$个神经元来存储多少个稳定的、具有足够吸引力的记忆模式，答案取决于权重和更新规则的选择。受生物学中集合连接的启发，我们通过添加集合连接并将这些连接嵌入到一个单纯复合体中来扩展Hopfield网络。单纯复合体是图形的高维类比，自然表示成对和集合关系的集合。我们证明了我们的单纯形 Hopfield 网络可以增加存储容量。令人惊讶的是，即使连接仅限于等于全对网络的小的随机子集，我们的网络仍然优于其成对的对应物。这种情况包括...（待补充）",
    "tldr": "展示了一种简单的形式化 Hopfield 神经网络，通过添加集合连接并将这些连接嵌入到一个单纯复合体中，可增加存储容量。"
}