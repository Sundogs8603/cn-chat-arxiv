{
    "title": "Raising the Bar for Certified Adversarial Robustness with Diffusion Models. (arXiv:2305.10388v1 [cs.LG])",
    "abstract": "Certified defenses against adversarial attacks offer formal guarantees on the robustness of a model, making them more reliable than empirical methods such as adversarial training, whose effectiveness is often later reduced by unseen attacks. Still, the limited certified robustness that is currently achievable has been a bottleneck for their practical adoption. Gowal et al. and Wang et al. have shown that generating additional training data using state-of-the-art diffusion models can considerably improve the robustness of adversarial training. In this work, we demonstrate that a similar approach can substantially improve deterministic certified defenses. In addition, we provide a list of recommendations to scale the robustness of certified training approaches. One of our main insights is that the generalization gap, i.e., the difference between the training and test accuracy of the original model, is a good predictor of the magnitude of the robustness improvement when using additional g",
    "link": "http://arxiv.org/abs/2305.10388",
    "context": "Title: Raising the Bar for Certified Adversarial Robustness with Diffusion Models. (arXiv:2305.10388v1 [cs.LG])\nAbstract: Certified defenses against adversarial attacks offer formal guarantees on the robustness of a model, making them more reliable than empirical methods such as adversarial training, whose effectiveness is often later reduced by unseen attacks. Still, the limited certified robustness that is currently achievable has been a bottleneck for their practical adoption. Gowal et al. and Wang et al. have shown that generating additional training data using state-of-the-art diffusion models can considerably improve the robustness of adversarial training. In this work, we demonstrate that a similar approach can substantially improve deterministic certified defenses. In addition, we provide a list of recommendations to scale the robustness of certified training approaches. One of our main insights is that the generalization gap, i.e., the difference between the training and test accuracy of the original model, is a good predictor of the magnitude of the robustness improvement when using additional g",
    "path": "papers/23/05/2305.10388.json",
    "total_tokens": 908,
    "translated_title": "基于扩散模型的认证对抗性鲁棒性打破现有记录",
    "translated_abstract": "证明对抗攻击防御提供了模型鲁棒性的形式保证，使其比经验方法如对抗性训练更可靠，后者的有效性通常会被未知攻击削弱。然而，目前可实现的认证鲁棒性受限，已成为实际采用的瓶颈。Gowal等人和Wang等人已经表明，使用最先进的扩散模型生成额外的训练数据可以显著提高对抗训练的鲁棒性，本文证明类似的方法也可以显著提高确定性认证防御的鲁棒性。此外，我们提供了一系列建议，以扩展认证训练方法的鲁棒性。我们的主要见解之一是，即，广义间隙，即原始模型的训练和测试准确性之间的差异，是使用额外数据进行训练时鲁棒性改善幅度的良好预测指标。",
    "tldr": "本研究提出使用扩散模型生成训练数据来提高认证防御模型的鲁棒性，并给出了扩展这一方法的建议，证明了广义间隙是一个良好的预测指标。"
}