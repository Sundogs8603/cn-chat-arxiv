{
    "title": "The Tunnel Effect: Building Data Representations in Deep Neural Networks. (arXiv:2305.19753v1 [cs.LG])",
    "abstract": "Deep neural networks are widely known for their remarkable effectiveness across various tasks, with the consensus that deeper networks implicitly learn more complex data representations. This paper shows that sufficiently deep networks trained for supervised image classification split into two distinct parts that contribute to the resulting data representations differently. The initial layers create linearly-separable representations, while the subsequent layers, which we refer to as \\textit{the tunnel}, compress these representations and have a minimal impact on the overall performance. We explore the tunnel's behavior through comprehensive empirical studies, highlighting that it emerges early in the training process. Its depth depends on the relation between the network's capacity and task complexity. Furthermore, we show that the tunnel degrades out-of-distribution generalization and discuss its implications for continual learning.",
    "link": "http://arxiv.org/abs/2305.19753",
    "context": "Title: The Tunnel Effect: Building Data Representations in Deep Neural Networks. (arXiv:2305.19753v1 [cs.LG])\nAbstract: Deep neural networks are widely known for their remarkable effectiveness across various tasks, with the consensus that deeper networks implicitly learn more complex data representations. This paper shows that sufficiently deep networks trained for supervised image classification split into two distinct parts that contribute to the resulting data representations differently. The initial layers create linearly-separable representations, while the subsequent layers, which we refer to as \\textit{the tunnel}, compress these representations and have a minimal impact on the overall performance. We explore the tunnel's behavior through comprehensive empirical studies, highlighting that it emerges early in the training process. Its depth depends on the relation between the network's capacity and task complexity. Furthermore, we show that the tunnel degrades out-of-distribution generalization and discuss its implications for continual learning.",
    "path": "papers/23/05/2305.19753.json",
    "total_tokens": 926,
    "translated_title": "隧道效应：深度神经网络中的数据表示构建",
    "translated_abstract": "深度神经网络以其在各种任务上的卓越表现而闻名，人们普遍认为更深的网络隐含着对更复杂数据表示的理解。本文表明，训练有素的用于监督图像分类的深度网络分为两个不同的部分，它们对最终数据表示的形成起着不同的作用：最初的层构建了线性可分的表示形式，而随后的层（我们称之为“隧道”）则压缩这些表示形式，并对整体性能影响不大。我们通过全面的实证研究探讨了隧道的行为，发现它会在训练过程中的早期出现，隧道的深度取决于网络容量与任务复杂度之间的关系。此外，我们表明，隧道会削弱网络在超出分布的泛化性能，并讨论了这对于持续学习的影响。",
    "tldr": "本文研究表明，深度神经网络中存在一种名为“隧道”的现象，它在网络的训练早期就出现，并且对最终的数据表示起到了压缩作用。其中，初始层构建了线性可分表示形式，而随后的层压缩这些表示形式并对整体性能影响不大。然而，隧道会削弱网络在超出分布的泛化性能。",
    "en_tdlr": "This paper discovers the \"tunnel effect\" in deep neural networks, which emerges early in the training process and compresses data representations without impacting overall performance. The initial layers create linearly-separable representations, while the subsequent layers in the \"tunnel\" compress these representations. However, the tunnel degrades out-of-distribution generalization."
}