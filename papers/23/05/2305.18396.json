{
    "title": "LLMs Can Understand Encrypted Prompt: Towards Privacy-Computing Friendly Transformers. (arXiv:2305.18396v1 [cs.LG])",
    "abstract": "Prior works have attempted to build private inference frameworks for transformer-based large language models (LLMs) in a server-client setting, where the server holds the model parameters and the client inputs the private data for inference. However, these frameworks impose significant overhead when the private inputs are forward propagated through the original LLMs. In this paper, we show that substituting the computation- and communication-heavy operators in the transformer architecture with privacy-computing friendly approximations can greatly reduce the private inference costs with minor impact on model performance. Compared to the state-of-the-art Iron (NeurIPS 2022), our privacy-computing friendly model inference pipeline achieves a $5\\times$ acceleration in computation and an 80\\% reduction in communication overhead, while retaining nearly identical accuracy.",
    "link": "http://arxiv.org/abs/2305.18396",
    "context": "Title: LLMs Can Understand Encrypted Prompt: Towards Privacy-Computing Friendly Transformers. (arXiv:2305.18396v1 [cs.LG])\nAbstract: Prior works have attempted to build private inference frameworks for transformer-based large language models (LLMs) in a server-client setting, where the server holds the model parameters and the client inputs the private data for inference. However, these frameworks impose significant overhead when the private inputs are forward propagated through the original LLMs. In this paper, we show that substituting the computation- and communication-heavy operators in the transformer architecture with privacy-computing friendly approximations can greatly reduce the private inference costs with minor impact on model performance. Compared to the state-of-the-art Iron (NeurIPS 2022), our privacy-computing friendly model inference pipeline achieves a $5\\times$ acceleration in computation and an 80\\% reduction in communication overhead, while retaining nearly identical accuracy.",
    "path": "papers/23/05/2305.18396.json",
    "total_tokens": 860,
    "translated_title": "LLM可以理解加密提示：面向隐私计算友好的Transformers",
    "translated_abstract": "先前的研究尝试在服务器客户端环境中为基于transformer的大型语言模型 (LLMs) 构建私有推断框架，其中服务器持有模型参数，客户端输入私有数据进行推断。然而，当私有输入通过原始LLMs进行前向传播时，这些框架会产生显着的开销。在本文中，我们展示了通过用隐私计算友好的近似替换transformer架构中计算和通信密集的运算符可以大大降低私有推断成本，对模型性能的影响微乎其微。与最新的Iron（NeurIPS 2022）相比，我们的隐私计算友好的模型推断管道在计算上实现了$5 \\times$的加速，在通信开销上实现了80\\%的降低，同时几乎保持了相同的准确性。",
    "tldr": "本文中，研究人员通过使用隐私计算友好的近似方法替换transformer架构中计算和通信密集的运算符，实现了大幅降低私有推断成本的效果，并在保持准确性的前提下实现了计算加速和通信开销降低。",
    "en_tdlr": "In this paper, substitution of computation- and communication-heavy operators in transformer architecture with privacy-computing friendly approximations greatly reduces private inference costs while having minor impact on accuracy. It achieves $5\\times$ acceleration in computation and an 80\\% reduction in communication overhead compared to the state-of-the-art."
}