{
    "title": "Training Energy-Based Normalizing Flow with Score-Matching Objectives. (arXiv:2305.15267v1 [cs.LG])",
    "abstract": "In this paper, we establish a connection between the parameterization of flow-based and energy-based generative models, and present a new flow-based modeling approach called energy-based normalizing flow (EBFlow). We demonstrate that by optimizing EBFlow with score-matching objectives, the computation of Jacobian determinants for linear transformations can be entirely bypassed. This feature enables the use of arbitrary linear layers in the construction of flow-based models without increasing the computational time complexity of each training iteration from $\\mathcal{O}(D^2L)$ to $\\mathcal{O}(D^3L)$ for an $L$-layered model that accepts $D$-dimensional inputs. This makes the training of EBFlow more efficient than the commonly-adopted maximum likelihood training method. In addition to the reduction in runtime, we enhance the training stability and empirical performance of EBFlow through a number of techniques developed based on our analysis on the score-matching methods. The experimental",
    "link": "http://arxiv.org/abs/2305.15267",
    "context": "Title: Training Energy-Based Normalizing Flow with Score-Matching Objectives. (arXiv:2305.15267v1 [cs.LG])\nAbstract: In this paper, we establish a connection between the parameterization of flow-based and energy-based generative models, and present a new flow-based modeling approach called energy-based normalizing flow (EBFlow). We demonstrate that by optimizing EBFlow with score-matching objectives, the computation of Jacobian determinants for linear transformations can be entirely bypassed. This feature enables the use of arbitrary linear layers in the construction of flow-based models without increasing the computational time complexity of each training iteration from $\\mathcal{O}(D^2L)$ to $\\mathcal{O}(D^3L)$ for an $L$-layered model that accepts $D$-dimensional inputs. This makes the training of EBFlow more efficient than the commonly-adopted maximum likelihood training method. In addition to the reduction in runtime, we enhance the training stability and empirical performance of EBFlow through a number of techniques developed based on our analysis on the score-matching methods. The experimental",
    "path": "papers/23/05/2305.15267.json",
    "total_tokens": 887,
    "translated_title": "训练基于能量的归一化流模型的得分匹配目标",
    "translated_abstract": "本文建立了流模型和能量模型参数化之间的联系，并提出了一种新的基于能量的归一化流建模方法（EBFlow）。我们展示了通过得分匹配目标优化EBFlow，可以完全避开线性变换的雅可比行列式计算。这使得EBFlow在构建基于流的模型时使用任意线性层，而不会使每个训练迭代的计算时间复杂度从$\\mathcal{O}(D^2L)$增加到$\\mathcal{O}(D^3L)$，其中$L$为层数，$D$为输入维度。这使得EBFlow的训练比常用的最大似然训练方法更高效。除了减少运行时间外，我们通过基于分值匹配方法的分析开发了一些技术，以增强EBFlow的训练稳定性和实证表现。",
    "tldr": "本文提出一种新的基于能量的归一化流模型（EBFlow），通过得分匹配目标优化使其训练更高效，同时开发一些技术增强EBFlow的训练稳定性和实证表现。",
    "en_tdlr": "This paper proposes a new method called energy-based normalizing flow (EBFlow) for flow-based modeling. By optimizing EBFlow with score-matching objectives, the computational time complexity for each training iteration can be reduced, making it more efficient than the commonly-adopted maximum likelihood training method. Techniques are also developed to enhance the training stability and empirical performance of EBFlow based on score-matching methods."
}