{
    "title": "Replicable Reinforcement Learning. (arXiv:2305.15284v2 [cs.LG] UPDATED)",
    "abstract": "The replicability crisis in the social, behavioral, and data sciences has led to the formulation of algorithm frameworks for replicability -- i.e., a requirement that an algorithm produce identical outputs (with high probability) when run on two different samples from the same underlying distribution. While still in its infancy, provably replicable algorithms have been developed for many fundamental tasks in machine learning and statistics, including statistical query learning, the heavy hitters problem, and distribution testing. In this work we initiate the study of replicable reinforcement learning, providing a provably replicable algorithm for parallel value iteration, and a provably replicable version of R-max in the episodic setting. These are the first formal replicability results for control problems, which present different challenges for replication than batch learning settings.",
    "link": "http://arxiv.org/abs/2305.15284",
    "context": "Title: Replicable Reinforcement Learning. (arXiv:2305.15284v2 [cs.LG] UPDATED)\nAbstract: The replicability crisis in the social, behavioral, and data sciences has led to the formulation of algorithm frameworks for replicability -- i.e., a requirement that an algorithm produce identical outputs (with high probability) when run on two different samples from the same underlying distribution. While still in its infancy, provably replicable algorithms have been developed for many fundamental tasks in machine learning and statistics, including statistical query learning, the heavy hitters problem, and distribution testing. In this work we initiate the study of replicable reinforcement learning, providing a provably replicable algorithm for parallel value iteration, and a provably replicable version of R-max in the episodic setting. These are the first formal replicability results for control problems, which present different challenges for replication than batch learning settings.",
    "path": "papers/23/05/2305.15284.json",
    "total_tokens": 728,
    "translated_title": "可复现强化学习",
    "translated_abstract": "在社会、行为和数据科学中，可重复性危机导致了算法框架的形成，即要求算法在从相同的底层分布提取的两个不同样本上运行时产生相同的输出（概率高）。虽然仍处于初期阶段，但在机器学习和统计学中的许多基本任务，包括统计查询学习、重要项问题和分布测试，都已经开发出了可证明可复现算法。在这项工作中，我们开始研究可复现强化学习，并提供了并行值迭代的可证复制算法以及一个在连续设置中可证复制的R-max。这是控制问题的第一个正式可复制性结果，这些问题在批量学习环境中提出了不同的复制挑战。",
    "tldr": "本篇论文提供了可复制的强化学习算法，是控制问题的第一个正式的可复制性结果",
    "en_tdlr": "This paper provides a replicable reinforcement learning algorithm, which is the first formal replicability result for control problems."
}