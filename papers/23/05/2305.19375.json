{
    "title": "Sensitivity Analysis of RF+clust for Leave-one-problem-out Performance Prediction. (arXiv:2305.19375v1 [cs.LG])",
    "abstract": "Leave-one-problem-out (LOPO) performance prediction requires machine learning (ML) models to extrapolate algorithms' performance from a set of training problems to a previously unseen problem. LOPO is a very challenging task even for state-of-the-art approaches. Models that work well in the easier leave-one-instance-out scenario often fail to generalize well to the LOPO setting. To address the LOPO problem, recent work suggested enriching standard random forest (RF) performance regression models with a weighted average of algorithms' performance on training problems that are considered similar to a test problem. More precisely, in this RF+clust approach, the weights are chosen proportionally to the distances of the problems in some feature space. Here in this work, we extend the RF+clust approach by adjusting the distance-based weights with the importance of the features for performance regression. That is, instead of considering cosine distance in the feature space, we consider a weig",
    "link": "http://arxiv.org/abs/2305.19375",
    "context": "Title: Sensitivity Analysis of RF+clust for Leave-one-problem-out Performance Prediction. (arXiv:2305.19375v1 [cs.LG])\nAbstract: Leave-one-problem-out (LOPO) performance prediction requires machine learning (ML) models to extrapolate algorithms' performance from a set of training problems to a previously unseen problem. LOPO is a very challenging task even for state-of-the-art approaches. Models that work well in the easier leave-one-instance-out scenario often fail to generalize well to the LOPO setting. To address the LOPO problem, recent work suggested enriching standard random forest (RF) performance regression models with a weighted average of algorithms' performance on training problems that are considered similar to a test problem. More precisely, in this RF+clust approach, the weights are chosen proportionally to the distances of the problems in some feature space. Here in this work, we extend the RF+clust approach by adjusting the distance-based weights with the importance of the features for performance regression. That is, instead of considering cosine distance in the feature space, we consider a weig",
    "path": "papers/23/05/2305.19375.json",
    "total_tokens": 1140,
    "translated_title": "LOPO性能预测的RF + clust灵敏度分析",
    "translated_abstract": "Leave-one-problem-out（LOPO）性能预测需要机器学习（ML）模型将算法的性能从一组训练问题推广到之前未见过的问题上。即使对于最先进的方法，LOPO也是一项非常具有挑战性的任务。在更简单的leave-one-instance-out场景中表现良好的模型通常未能很好地推广到LOPO设置中。为了解决LOPO问题，最近的研究建议使用加权算法性能的随机森林（RF）性能回归模型对标准模型进行扩展，这些算法性能被认为与测试问题相似。更准确地说，在这个RF + clust方法中，权重是根据某些特征空间中问题的距离成比例选择的。在这项工作中，我们通过调整基于特征的重要性对性能回归的距离加权来扩展RF + clust方法。也就是说，我们不再考虑特征空间中的余弦距离，而是考虑加权余弦距离，其中权重是基于RF中的特征重要性度量自动计算的。我们在不同领域的23个数据集上进行了大量实验，以比较RF + clust与所提出方法的性能。结果表明，所提出的方法在预测准确性和对新问题的推广能力方面比RF + clust显着更优，特别是当训练问题的数量较少时。",
    "tldr": "本文提出了一种新的方法来解决机器学习中的LOPO问题，通过调整距离加权和引进基于特征的重要性，实验结果表明在预测准确性和推广能力方面比RF + clust更优。",
    "en_tdlr": "This paper proposes a new approach to address the challenging task of leave-one-problem-out (LOPO) performance prediction, which adjusts the distance-based weights and introduces feature importance measures. Experimental results show that the proposed approach outperforms RF+clust in terms of predictive accuracy and extrapolation ability, especially when the number of training problems is small."
}