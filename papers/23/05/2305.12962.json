{
    "title": "Distilling ChatGPT for Explainable Automated Student Answer Assessment. (arXiv:2305.12962v2 [cs.CL] UPDATED)",
    "abstract": "Providing explainable and faithful feedback is crucial for automated student answer assessment. In this paper, we introduce a novel framework that explores using ChatGPT, a cutting-edge large language model, for the concurrent tasks of student answer scoring and rationale generation. We identify the appropriate instructions by prompting ChatGPT with different templates to collect the rationales, where inconsistent rationales are refined to align with marking standards. The refined ChatGPT outputs enable us to fine-tune a smaller language model that simultaneously assesses student answers and provides rationales. Extensive experiments on the benchmark dataset show that the proposed method improves the overall QWK score by 11% compared to ChatGPT. Furthermore, our thorough analysis and human evaluation demonstrate that the rationales generated by our proposed method are comparable to those of ChatGPT. Our approach provides a viable solution to achieve explainable automated assessment in ",
    "link": "http://arxiv.org/abs/2305.12962",
    "context": "Title: Distilling ChatGPT for Explainable Automated Student Answer Assessment. (arXiv:2305.12962v2 [cs.CL] UPDATED)\nAbstract: Providing explainable and faithful feedback is crucial for automated student answer assessment. In this paper, we introduce a novel framework that explores using ChatGPT, a cutting-edge large language model, for the concurrent tasks of student answer scoring and rationale generation. We identify the appropriate instructions by prompting ChatGPT with different templates to collect the rationales, where inconsistent rationales are refined to align with marking standards. The refined ChatGPT outputs enable us to fine-tune a smaller language model that simultaneously assesses student answers and provides rationales. Extensive experiments on the benchmark dataset show that the proposed method improves the overall QWK score by 11% compared to ChatGPT. Furthermore, our thorough analysis and human evaluation demonstrate that the rationales generated by our proposed method are comparable to those of ChatGPT. Our approach provides a viable solution to achieve explainable automated assessment in ",
    "path": "papers/23/05/2305.12962.json",
    "total_tokens": 925,
    "translated_title": "使用ChatGPT进行可解释的自动学生答案评估",
    "translated_abstract": "提供可解释和可信的反馈对于自动学生答案评估至关重要。在本文中，我们介绍了一种新颖的框架，探索使用ChatGPT，一种尖端的大型语言模型，用于学生答案评分和理由生成的并发任务。我们通过使用不同的模板提示ChatGPT收集理由来确定适当的说明，其中不一致的理由被修正以符合标记标准。精细调整的ChatGPT输出使我们能够微调一个更小的语言模型，同时评估学生答案并提供理由。对基准数据集的大量实验证明，与ChatGPT相比，提出的方法将整体QWK评分提高了11%。此外，我们的彻底分析和人工评估表明，我们提出的方法生成的理由与ChatGPT的理由相当。我们的方法为实现可解释的自动评估提供了可行的解决方案。",
    "tldr": "本文提出了一种使用ChatGPT进行解释性的自动学生答案评估的新框架。通过采用不同的模板指导ChatGPT收集理由，修正不一致的理由以符合标准，并通过微调一个更小的语言模型，同时评估学生答案和提供理由。实验证明，该方法相对于ChatGPT将整体QWK评分提高了11%。",
    "en_tdlr": "This paper introduces a novel framework for explainable automated student answer assessment using ChatGPT. By prompting ChatGPT with different templates to collect rationales, refining inconsistent rationales to align with standards, and fine-tuning a smaller language model, this method improves the overall QWK score by 11% compared to ChatGPT."
}