{
    "title": "A Whisper transformer for audio captioning trained with synthetic captions and transfer learning. (arXiv:2305.09690v1 [cs.SD])",
    "abstract": "The field of audio captioning has seen significant advancements in recent years, driven by the availability of large-scale audio datasets and advancements in deep learning techniques. In this technical report, we present our approach to audio captioning, focusing on the use of a pretrained speech-to-text Whisper model and pretraining on synthetic captions. We discuss our training procedures and present our experiments' results, which include model size variations, dataset mixtures, and other hyperparameters. Our findings demonstrate the impact of different training strategies on the performance of the audio captioning model. Our code and trained models are publicly available on GitHub and Hugging Face Hub.",
    "link": "http://arxiv.org/abs/2305.09690",
    "context": "Title: A Whisper transformer for audio captioning trained with synthetic captions and transfer learning. (arXiv:2305.09690v1 [cs.SD])\nAbstract: The field of audio captioning has seen significant advancements in recent years, driven by the availability of large-scale audio datasets and advancements in deep learning techniques. In this technical report, we present our approach to audio captioning, focusing on the use of a pretrained speech-to-text Whisper model and pretraining on synthetic captions. We discuss our training procedures and present our experiments' results, which include model size variations, dataset mixtures, and other hyperparameters. Our findings demonstrate the impact of different training strategies on the performance of the audio captioning model. Our code and trained models are publicly available on GitHub and Hugging Face Hub.",
    "path": "papers/23/05/2305.09690.json",
    "total_tokens": 759,
    "translated_title": "用合成字幕和迁移学习训练的音频描述模型Whisper Transformer的研究(arXiv:2305.09690v1 [cs.SD])",
    "translated_abstract": "随着大规模音频数据集的出现和深度学习技术的进步，音频描述领域在近年来取得了显著的进展。在这篇技术报告中，我们介绍了一种音频描述的方法，重点关注预训练的语音转文本Whisper模型和用于合成字幕的预训练。我们讨论了我们的训练过程，并呈现了我们的实验结果，包括模型大小变化、数据集混合和其他超参数。我们的发现表明了不同训练策略对音频描述模型性能的影响。我们的代码和训练模型公开在GitHub和Hugging Face Hub上。",
    "tldr": "这篇论文介绍了一种音频描述方法，采用预训练的Whisper模型和合成字幕的预训练。实验结果表明，不同的训练策略会影响音频描述模型的性能。",
    "en_tdlr": "This paper presents an approach to audio captioning using a pretrained speech-to-text Whisper model and pretraining on synthetic captions. The experiments demonstrate the impact of different training strategies on the performance of the audio captioning model."
}