{
    "title": "Probabilistic Computation with Emerging Covariance: Towards Efficient Uncertainty Quantification. (arXiv:2305.19265v2 [cs.LG] UPDATED)",
    "abstract": "Building robust, interpretable, and secure artificial intelligence system requires some degree of quantifying and representing uncertainty via a probabilistic perspective, as it allows to mimic human cognitive abilities. However, probabilistic computation presents significant challenges due to its inherent complexity. In this paper, we develop an efficient and interpretable probabilistic computation framework by truncating the probabilistic representation up to its first two moments, i.e., mean and covariance. We instantiate the framework by training a deterministic surrogate of a stochastic network that learns the complex probabilistic representation via combinations of simple activations, encapsulating the non-linearities coupling of the mean and covariance. We show that when the mean is supervised for optimizing the task objective, the unsupervised covariance spontaneously emerging from the non-linear coupling with the mean faithfully captures the uncertainty associated with model p",
    "link": "http://arxiv.org/abs/2305.19265",
    "context": "Title: Probabilistic Computation with Emerging Covariance: Towards Efficient Uncertainty Quantification. (arXiv:2305.19265v2 [cs.LG] UPDATED)\nAbstract: Building robust, interpretable, and secure artificial intelligence system requires some degree of quantifying and representing uncertainty via a probabilistic perspective, as it allows to mimic human cognitive abilities. However, probabilistic computation presents significant challenges due to its inherent complexity. In this paper, we develop an efficient and interpretable probabilistic computation framework by truncating the probabilistic representation up to its first two moments, i.e., mean and covariance. We instantiate the framework by training a deterministic surrogate of a stochastic network that learns the complex probabilistic representation via combinations of simple activations, encapsulating the non-linearities coupling of the mean and covariance. We show that when the mean is supervised for optimizing the task objective, the unsupervised covariance spontaneously emerging from the non-linear coupling with the mean faithfully captures the uncertainty associated with model p",
    "path": "papers/23/05/2305.19265.json",
    "total_tokens": 883,
    "translated_title": "利用新兴协方差进行概率计算：走向高效的不确定性量化",
    "translated_abstract": "建立鲁棒性、可解释性和安全性强的人工智能系统需要通过概率视角量化和表示不确定性，因为这可以模仿人类的认知能力。然而，概率计算由于其固有的复杂性而面临重大挑战。本文通过截断概率表示的前两个矩，即平均值和协方差，开发了一个高效、可解释的概率计算框架。我们通过训练随机网络的确定性替代品来实例化该框架，该网络通过简单激活的组合学习复杂的概率表示，封装了平均值和协方差的非线性耦合。我们表明，当平均值受到监督以优化任务目标时，从其与协方差的非线性耦合中自发出现的无监督协方差忠实地捕捉了与模型预测的不确定性相关的信息。",
    "tldr": "本文开发了一个高效、可解释的概率计算框架，通过监督平均值优化任务目标，从非线性耦合中自发出现的无监督协方差忠实地捕捉了与模型预测的不确定性相关的信息。",
    "en_tdlr": "This paper develops an efficient and interpretable probabilistic computation framework, which captures the uncertainty associated with model predictions through unsupervised covariance that spontaneously emerges from the non-linear coupling of the mean in a deterministic surrogate of a stochastic network trained to optimize the task objective."
}