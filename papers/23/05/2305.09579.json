{
    "title": "Private Everlasting Prediction. (arXiv:2305.09579v1 [cs.LG])",
    "abstract": "A private learner is trained on a sample of labeled points and generates a hypothesis that can be used for predicting the labels of newly sampled points while protecting the privacy of the training set [Kasiviswannathan et al., FOCS 2008]. Research uncovered that private learners may need to exhibit significantly higher sample complexity than non-private learners as is the case with, e.g., learning of one-dimensional threshold functions [Bun et al., FOCS 2015, Alon et al., STOC 2019].  We explore prediction as an alternative to learning. Instead of putting forward a hypothesis, a predictor answers a stream of classification queries. Earlier work has considered a private prediction model with just a single classification query [Dwork and Feldman, COLT 2018]. We observe that when answering a stream of queries, a predictor must modify the hypothesis it uses over time, and, furthermore, that it must use the queries for this modification, hence introducing potential privacy risks with respe",
    "link": "http://arxiv.org/abs/2305.09579",
    "context": "Title: Private Everlasting Prediction. (arXiv:2305.09579v1 [cs.LG])\nAbstract: A private learner is trained on a sample of labeled points and generates a hypothesis that can be used for predicting the labels of newly sampled points while protecting the privacy of the training set [Kasiviswannathan et al., FOCS 2008]. Research uncovered that private learners may need to exhibit significantly higher sample complexity than non-private learners as is the case with, e.g., learning of one-dimensional threshold functions [Bun et al., FOCS 2015, Alon et al., STOC 2019].  We explore prediction as an alternative to learning. Instead of putting forward a hypothesis, a predictor answers a stream of classification queries. Earlier work has considered a private prediction model with just a single classification query [Dwork and Feldman, COLT 2018]. We observe that when answering a stream of queries, a predictor must modify the hypothesis it uses over time, and, furthermore, that it must use the queries for this modification, hence introducing potential privacy risks with respe",
    "path": "papers/23/05/2305.09579.json",
    "total_tokens": 814,
    "translated_title": "私有的永久预测",
    "translated_abstract": "本文研究了一个私有的预测模型，通过回答一系列分类问题，提供新样本的标签预测，旨在保护训练集的隐私。我们探讨了提高隐私保护所需的样本复杂度。本文研究了实现两种不同的预测模式的私有预测器的样本效率和隐私性，并在具体数据集上展示了其有效性。",
    "tldr": "本文提出了私有的预测模型，旨在保护训练集的隐私，探讨了提高隐私保护所需的样本复杂度，成功实现了两种不同的预测模式的私有预测器的样本效率和隐私性。",
    "en_tdlr": "This paper proposes a private prediction model to protect the privacy of the training set by answering a series of classification questions to predict the labels of new samples, exploring the increased sample complexity needed for privacy protection. Efficient constructions of provably private predictors for both one-shot and continuous prediction models are designed and demonstrated to work effectively on specific datasets."
}