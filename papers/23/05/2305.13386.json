{
    "title": "Can LLMs facilitate interpretation of pre-trained language models?. (arXiv:2305.13386v1 [cs.CL])",
    "abstract": "Work done to uncover the knowledge encoded within pre-trained language models, rely on annotated corpora or human-in-the-loop methods. However, these approaches are limited in terms of scalability and the scope of interpretation. We propose using a large language model, ChatGPT, as an annotator to enable fine-grained interpretation analysis of pre-trained language models. We discover latent concepts within pre-trained language models by applying hierarchical clustering over contextualized representations and then annotate these concepts using GPT annotations. Our findings demonstrate that ChatGPT produces accurate and semantically richer annotations compared to human-annotated concepts. Additionally, we showcase how GPT-based annotations empower interpretation analysis methodologies of which we demonstrate two: probing framework and neuron interpretation. To facilitate further exploration and experimentation in this field, we have made available a substantial ConceptNet dataset compris",
    "link": "http://arxiv.org/abs/2305.13386",
    "context": "Title: Can LLMs facilitate interpretation of pre-trained language models?. (arXiv:2305.13386v1 [cs.CL])\nAbstract: Work done to uncover the knowledge encoded within pre-trained language models, rely on annotated corpora or human-in-the-loop methods. However, these approaches are limited in terms of scalability and the scope of interpretation. We propose using a large language model, ChatGPT, as an annotator to enable fine-grained interpretation analysis of pre-trained language models. We discover latent concepts within pre-trained language models by applying hierarchical clustering over contextualized representations and then annotate these concepts using GPT annotations. Our findings demonstrate that ChatGPT produces accurate and semantically richer annotations compared to human-annotated concepts. Additionally, we showcase how GPT-based annotations empower interpretation analysis methodologies of which we demonstrate two: probing framework and neuron interpretation. To facilitate further exploration and experimentation in this field, we have made available a substantial ConceptNet dataset compris",
    "path": "papers/23/05/2305.13386.json",
    "total_tokens": 924,
    "translated_title": "LLMs是否可以促进预先训练的语言模型的解释？",
    "translated_abstract": "揭示预先训练的语言模型中编码的知识的工作依赖于带注释的语料库或人在环路方法。然而，这些方法在可伸缩性和解释范围方面存在限制。我们提议使用一个大型语言模型ChatGPT作为注释器，以便对预训练语言模型进行细粒度解释分析。通过在上下文表示上应用分层聚类，我们发现预先训练的语言模型中的潜在概念，然后使用GPT注释对这些概念进行注释。我们的研究发现，与人工注释的概念相比，ChatGPT产生了更准确和语义更丰富的注释。此外，我们展示了基于GPT注释的解释分析方法，其中我们展示了两种：探针框架和神经元解释。为了促进在这个领域的进一步探索和实验，我们提供了一个重要的概念网数据集。",
    "tldr": "该论文提出使用大型语言模型ChatGPT作为注释器以便对预训练语言模型进行细粒度解释分析，发现ChatGPT产生了更准确和语义更丰富的注释。同时，基于GPT注释的解释分析方法可以帮助进一步探索和实验。",
    "en_tdlr": "The paper proposes using the large language model ChatGPT as an annotator for fine-grained interpretation analysis of pre-trained language models and demonstrates that ChatGPT produces more accurate and semantically richer annotations compared to human-annotated concepts. The paper also showcases how GPT-based annotations empower interpretation analysis methodologies and provides a ConceptNet dataset for further exploration and experimentation in this field."
}