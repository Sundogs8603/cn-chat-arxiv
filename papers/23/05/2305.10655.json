{
    "title": "DeepEdit: Deep Editable Learning for Interactive Segmentation of 3D Medical Images. (arXiv:2305.10655v1 [eess.IV])",
    "abstract": "Automatic segmentation of medical images is a key step for diagnostic and interventional tasks. However, achieving this requires large amounts of annotated volumes, which can be tedious and time-consuming task for expert annotators. In this paper, we introduce DeepEdit, a deep learning-based method for volumetric medical image annotation, that allows automatic and semi-automatic segmentation, and click-based refinement. DeepEdit combines the power of two methods: a non-interactive (i.e. automatic segmentation using nnU-Net, UNET or UNETR) and an interactive segmentation method (i.e. DeepGrow), into a single deep learning model. It allows easy integration of uncertainty-based ranking strategies (i.e. aleatoric and epistemic uncertainty computation) and active learning. We propose and implement a method for training DeepEdit by using standard training combined with user interaction simulation. Once trained, DeepEdit allows clinicians to quickly segment their datasets by using the algorit",
    "link": "http://arxiv.org/abs/2305.10655",
    "context": "Title: DeepEdit: Deep Editable Learning for Interactive Segmentation of 3D Medical Images. (arXiv:2305.10655v1 [eess.IV])\nAbstract: Automatic segmentation of medical images is a key step for diagnostic and interventional tasks. However, achieving this requires large amounts of annotated volumes, which can be tedious and time-consuming task for expert annotators. In this paper, we introduce DeepEdit, a deep learning-based method for volumetric medical image annotation, that allows automatic and semi-automatic segmentation, and click-based refinement. DeepEdit combines the power of two methods: a non-interactive (i.e. automatic segmentation using nnU-Net, UNET or UNETR) and an interactive segmentation method (i.e. DeepGrow), into a single deep learning model. It allows easy integration of uncertainty-based ranking strategies (i.e. aleatoric and epistemic uncertainty computation) and active learning. We propose and implement a method for training DeepEdit by using standard training combined with user interaction simulation. Once trained, DeepEdit allows clinicians to quickly segment their datasets by using the algorit",
    "path": "papers/23/05/2305.10655.json",
    "total_tokens": 1046,
    "translated_title": "DeepEdit：基于深度可编辑学习的医学图像交互式分割",
    "translated_abstract": "医学图像自动分割是诊断和介入任务的关键步骤。然而，实现这一任务需要大量的标注图像，这对专家标注者来说可能是烦琐且耗时的工作。本文介绍了DeepEdit，一种基于深度学习的体积医学图像注释方法，它允许自动和半自动分割，并通过点击-based修正进行互动分割。DeepEdit将两种方法的优势相结合：非交互式（即使用nnU-Net、UNET或UNETR进行自动分割）和交互式分割方法（即DeepGrow），合并为一个单一的深度学习模型。它允许轻松集成基于不确定性的排名策略（即aleatoric和epistemic不确定性计算）和主动学习。我们提出并实现了一种方法，通过使用标准培训和用户交互仿真来训练DeepEdit。一旦训练完成，医生可以使用算法将体积医学图像进行半自动分割，并通过用户交互（如点击）来优化分割结果。实验结果表明，DeepEdit优于最先进的方法，并显着减少了专家标注者的注释时间和工作量。",
    "tldr": "DeepEdit是一种基于深度学习的医学图像注释方法，它结合了自动和交互式分割，允许非常快速的数据集分割，且通过用户交互（如点击）可以进一步优化分割结果。",
    "en_tdlr": "DeepEdit is a deep learning-based method for volumetric medical image annotation that combines automatic and interactive segmentation, allowing for fast dataset segmentation and further segmentation refinement through user interactions such as clicks. The method outperforms state-of-the-art methods and significantly reduces annotation time and effort for expert annotators."
}