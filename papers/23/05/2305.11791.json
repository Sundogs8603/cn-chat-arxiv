{
    "title": "Enhancing Few-shot NER with Prompt Ordering based Data Augmentation. (arXiv:2305.11791v1 [cs.CL])",
    "abstract": "Recently, data augmentation (DA) methods have been proven to be effective for pre-trained language models (PLMs) in low-resource settings, including few-shot named entity recognition (NER). However, conventional NER DA methods are mostly aimed at sequence labeling models, i.e., token-level classification, and few are compatible with unified autoregressive generation frameworks, which can handle a wider range of NER tasks, such as nested NER. Furthermore, these generation frameworks have a strong assumption that the entities will appear in the target sequence with the same left-to-right order as the source sequence. In this paper, we claim that there is no need to keep this strict order, and more diversified but reasonable target entity sequences can be provided during the training stage as a novel DA method. Nevertheless, a naive mixture of augmented data can confuse the model since one source sequence will then be paired with different target sequences. Therefore, we propose a simple ",
    "link": "http://arxiv.org/abs/2305.11791",
    "context": "Title: Enhancing Few-shot NER with Prompt Ordering based Data Augmentation. (arXiv:2305.11791v1 [cs.CL])\nAbstract: Recently, data augmentation (DA) methods have been proven to be effective for pre-trained language models (PLMs) in low-resource settings, including few-shot named entity recognition (NER). However, conventional NER DA methods are mostly aimed at sequence labeling models, i.e., token-level classification, and few are compatible with unified autoregressive generation frameworks, which can handle a wider range of NER tasks, such as nested NER. Furthermore, these generation frameworks have a strong assumption that the entities will appear in the target sequence with the same left-to-right order as the source sequence. In this paper, we claim that there is no need to keep this strict order, and more diversified but reasonable target entity sequences can be provided during the training stage as a novel DA method. Nevertheless, a naive mixture of augmented data can confuse the model since one source sequence will then be paired with different target sequences. Therefore, we propose a simple ",
    "path": "papers/23/05/2305.11791.json",
    "total_tokens": 925,
    "translated_title": "基于Prompt Ordering的数据增强增强Few-shot NER的效果",
    "translated_abstract": "近期, 数据增强方法已被证明对于预训练语言模型在低资源环境下的Few-shot命名实体识别(NER)任务有效.然而,传统的NER数据增强方法大多针对序列标注模型即标记级分类,并且其适用性有限,难以处理嵌套的NER等任务 .本文提出,在训练过程中可以通过为模型提供更多样化但合理的目标实体序列的方式,来提高NER模型在Few-shot任务下的泛化性和鲁棒性。同时,我们提出了基于Prompt Ordering的简单实用的技术,将生成的不同目标实体序列按可理解的顺序组合,以更好地帮助模型理解NER任务。通过实验证明本方法具有优异的性能。",
    "tldr": "本文提出了一种基于Prompt Ordering的数据增强方法来提高Few-shot NER的鲁棒性和泛化性，不同但合理的目标序列提供了更多的多样性。实验证明该方法可扩展性好，比传统方法更有效。",
    "en_tdlr": "This paper proposes a Prompt Ordering based data augmentation method to improve the robustness and generalization of Few-shot NER. Different but reasonable target sequences provide more diversity. The method is proved to be more effective than traditional ones and has better scalability."
}