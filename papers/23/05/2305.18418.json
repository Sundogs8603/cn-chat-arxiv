{
    "title": "Just a Glimpse: Rethinking Temporal Information for Video Continual Learning. (arXiv:2305.18418v1 [cs.CV])",
    "abstract": "Class-incremental learning is one of the most important settings for the study of Continual Learning, as it closely resembles real-world application scenarios. With constrained memory sizes, catastrophic forgetting arises as the number of classes/tasks increases. Studying continual learning in the video domain poses even more challenges, as video data contains a large number of frames, which places a higher burden on the replay memory. The current common practice is to sub-sample frames from the video stream and store them in the replay memory. In this paper, we propose SMILE a novel replay mechanism for effective video continual learning based on individual/single frames. Through extensive experimentation, we show that under extreme memory constraints, video diversity plays a more significant role than temporal information. Therefore, our method focuses on learning from a small number of frames that represent a large number of unique videos. On three representative video datasets, Kin",
    "link": "http://arxiv.org/abs/2305.18418",
    "context": "Title: Just a Glimpse: Rethinking Temporal Information for Video Continual Learning. (arXiv:2305.18418v1 [cs.CV])\nAbstract: Class-incremental learning is one of the most important settings for the study of Continual Learning, as it closely resembles real-world application scenarios. With constrained memory sizes, catastrophic forgetting arises as the number of classes/tasks increases. Studying continual learning in the video domain poses even more challenges, as video data contains a large number of frames, which places a higher burden on the replay memory. The current common practice is to sub-sample frames from the video stream and store them in the replay memory. In this paper, we propose SMILE a novel replay mechanism for effective video continual learning based on individual/single frames. Through extensive experimentation, we show that under extreme memory constraints, video diversity plays a more significant role than temporal information. Therefore, our method focuses on learning from a small number of frames that represent a large number of unique videos. On three representative video datasets, Kin",
    "path": "papers/23/05/2305.18418.json",
    "total_tokens": 858,
    "translated_title": "一瞥：重新思考视频不断学习中的时间信息",
    "translated_abstract": "增量学习是连续学习研究中最重要的设置之一，因为它与现实世界的应用场景密切相关。随着类别/任务数量的增加，由于受到内存大小的限制，灾难性遗忘会出现。在视频领域研究持续学习面临更大的挑战，因为视频数据包含大量帧，这会使回放记忆负担更重。目前的常见做法是从视频流中对帧进行子采样，并将其存储在回放记忆中。在本文中，我们提出了一种基于单个帧的新型重播机制SMILE，用于有效的视频连续学习。通过大量实验，我们表明在极端内存限制下，视频的多样性比时间信息更重要。因此，我们的方法侧重于从代表大量独特视频的少量帧中学习。我们在三个代表性视频数据集Kin上进行了实验。",
    "tldr": "本文提出了一种基于单个帧的新型重播机制SMILE，用于有效的视频连续学习。实验表明，在内存受到极端限制时，视频的多样性比时间信息更重要。",
    "en_tdlr": "This paper proposes a novel replay mechanism SMILE based on individual frames for effective video continual learning. The experiments show that under extreme memory constraints, video diversity plays a more significant role than temporal information."
}