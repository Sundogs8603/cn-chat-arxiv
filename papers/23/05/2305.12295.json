{
    "title": "Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning. (arXiv:2305.12295v2 [cs.CL] UPDATED)",
    "abstract": "Large Language Models (LLMs) have shown human-like reasoning abilities but still struggle with complex logical problems. This paper introduces a novel framework, Logic-LM, which integrates LLMs with symbolic solvers to improve logical problem-solving. Our method first utilizes LLMs to translate a natural language problem into a symbolic formulation. Afterward, a deterministic symbolic solver performs inference on the formulated problem. We also introduce a self-refinement module, which utilizes the symbolic solver's error messages to revise symbolic formalizations. We demonstrate Logic-LM's effectiveness on five logical reasoning datasets: ProofWriter, PrOntoQA, FOLIO, LogicalDeduction, and AR-LSAT. On average, Logic-LM achieves a significant performance boost of 39.2% over using LLM alone with standard prompting and 18.4% over LLM with chain-of-thought prompting. Our findings suggest that Logic-LM, by combining LLMs with symbolic logic, offers a promising avenue for faithful logical r",
    "link": "http://arxiv.org/abs/2305.12295",
    "context": "Title: Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning. (arXiv:2305.12295v2 [cs.CL] UPDATED)\nAbstract: Large Language Models (LLMs) have shown human-like reasoning abilities but still struggle with complex logical problems. This paper introduces a novel framework, Logic-LM, which integrates LLMs with symbolic solvers to improve logical problem-solving. Our method first utilizes LLMs to translate a natural language problem into a symbolic formulation. Afterward, a deterministic symbolic solver performs inference on the formulated problem. We also introduce a self-refinement module, which utilizes the symbolic solver's error messages to revise symbolic formalizations. We demonstrate Logic-LM's effectiveness on five logical reasoning datasets: ProofWriter, PrOntoQA, FOLIO, LogicalDeduction, and AR-LSAT. On average, Logic-LM achieves a significant performance boost of 39.2% over using LLM alone with standard prompting and 18.4% over LLM with chain-of-thought prompting. Our findings suggest that Logic-LM, by combining LLMs with symbolic logic, offers a promising avenue for faithful logical r",
    "path": "papers/23/05/2305.12295.json",
    "total_tokens": 1122,
    "translated_title": "Logic-LM：通过符号求解器增强大型语言模型在准确逻辑推理方面的能力",
    "translated_abstract": "大型语言模型(LLMs)已经展示了人类一样的推理能力，但仍然在复杂的逻辑问题上遇到困难。本文提出了一种新颖的框架，Logic-LM，将LLMs与符号求解器集成，以改进逻辑问题的解决能力。我们的方法首先利用LLMs将自然语言问题转化为符号化表述。然后，确定性符号求解器对问题进行推理。我们还引入了自我完善模块，利用符号求解器的错误信息修正符号化表示。通过在五个逻辑推理数据集ProofWriter、PrOntoQA、FOLIO、LogicalDeduction和AR-LSAT上的实验证明了Logic-LM的有效性。平均而言，Logic-LM相比仅使用LLMs的标准提示可以显著提高39.2%的性能，相比使用LLMs的思维链提示可以提高18.4%的性能。我们的研究结果表明，通过将LLMs与符号逻辑相结合，Logic-LM为准确的逻辑推理提供了一个有前途的途径。",
    "tldr": "本文介绍了一种名为Logic-LM的新框架，它将大型语言模型与符号求解器结合起来，以提升在复杂逻辑问题上的推理能力。通过将自然语言问题转化为符号表达，并利用确定性符号求解器进行推理，我们的方法能够有效地改进准确逻辑推理。实验证明，Logic-LM在多个逻辑推理数据集上取得了显著的性能提升，并且相比使用标准提示或思维链提示，效果分别提高了39.2%和18.4%。这表明将大型语言模型与符号逻辑相结合是实现准确逻辑推理的一个有前途的方法。",
    "en_tdlr": "This paper introduces a novel framework called Logic-LM, which combines large language models with symbolic solvers to improve logical reasoning. By translating natural language problems into symbolic formulations and utilizing deterministic symbolic solvers, Logic-LM shows significant performance improvement in accurate logical reasoning compared to using standard prompting or chain-of-thought prompting. This approach of integrating large language models with symbolic logic offers a promising avenue for faithful logical reasoning."
}