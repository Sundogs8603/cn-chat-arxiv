{
    "title": "Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy. (arXiv:2305.15294v2 [cs.CL] UPDATED)",
    "abstract": "Large language models are powerful text processors and reasoners, but are still subject to limitations including outdated knowledge and hallucinations, which necessitates connecting them to the world. Retrieval-augmented large language models have raised extensive attention for grounding model generation on external knowledge. However, retrievers struggle to capture relevance, especially for queries with complex information needs. Recent work has proposed to improve relevance modeling by having large language models actively involved in retrieval, i.e., to improve retrieval with generation. In this paper, we show that strong performance can be achieved by a method we call Iter-RetGen, which synergizes retrieval and generation in an iterative manner. A model output shows what might be needed to finish a task, and thus provides an informative context for retrieving more relevant knowledge which in turn helps generate a better output in the next iteration. Compared with recent work which ",
    "link": "http://arxiv.org/abs/2305.15294",
    "context": "Title: Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy. (arXiv:2305.15294v2 [cs.CL] UPDATED)\nAbstract: Large language models are powerful text processors and reasoners, but are still subject to limitations including outdated knowledge and hallucinations, which necessitates connecting them to the world. Retrieval-augmented large language models have raised extensive attention for grounding model generation on external knowledge. However, retrievers struggle to capture relevance, especially for queries with complex information needs. Recent work has proposed to improve relevance modeling by having large language models actively involved in retrieval, i.e., to improve retrieval with generation. In this paper, we show that strong performance can be achieved by a method we call Iter-RetGen, which synergizes retrieval and generation in an iterative manner. A model output shows what might be needed to finish a task, and thus provides an informative context for retrieving more relevant knowledge which in turn helps generate a better output in the next iteration. Compared with recent work which ",
    "path": "papers/23/05/2305.15294.json",
    "total_tokens": 839,
    "translated_title": "用迭代检索-生成协同增强检索增强的大型语言模型",
    "translated_abstract": "大型语言模型是强大的文本处理器和推理器，但仍然受到诸如过时知识和幻觉等限制，这需要将它们与现实世界连接起来。检索增强的大型语言模型已经引起了广泛的关注，以在外部知识上打下模型生成的基础。然而，检索器往往难以捕捉到复杂信息需求的相关性。最近的工作提出通过使大型语言模型积极参与检索来改善相关性建模，即通过生成来改善检索。在本文中，我们展示了一种我们称之为迭代检索-生成（Iter-RetGen）的方法，通过迭代方式协同检索和生成可以实现强大的性能。模型输出展示了完成任务所需的内容，因此为检索更相关的知识提供了信息上下文，进而有助于在下一次迭代中生成更好的输出。",
    "tldr": "本文提出了一种被称为迭代检索-生成的方法，通过迭代地协同检索和生成，改善了检索增强的大型语言模型的性能。",
    "en_tdlr": "The paper proposes an iterative retrieval-generation method called Iter-RetGen, which improves the performance of retrieval-augmented large language models by synergizing retrieval and generation in an iterative manner."
}