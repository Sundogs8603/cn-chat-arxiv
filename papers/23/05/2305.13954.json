{
    "title": "Robust Instruction Optimization for Large Language Models with Distribution Shifts. (arXiv:2305.13954v1 [cs.CL])",
    "abstract": "Large Language Models have demonstrated significant ability in accomplishing a wide range of Natural Language Processing (NLP) tasks. However, their performance is highly sensitive to the even minor changes in the phrasing of the task instructions, leading to a line of research in automatic instruction optimization towards better performance for NLP tasks. Unfortunately, existing methods for instruction optimization fail to consider the distribution shift between the seen training data and the unseen test data, where testing on unseen group of data with a different distribution could potentially lead to performance drop. In this paper, we take an initial step of investigating the problem of LLM instruction optimization across data groups with distribution shifts. We find that the optimal instructions do encounter performance drops on LLM under certain distribution shifts. To this end, we propose a framework to derive more robust optimal instructions that improve the performance on the ",
    "link": "http://arxiv.org/abs/2305.13954",
    "context": "Title: Robust Instruction Optimization for Large Language Models with Distribution Shifts. (arXiv:2305.13954v1 [cs.CL])\nAbstract: Large Language Models have demonstrated significant ability in accomplishing a wide range of Natural Language Processing (NLP) tasks. However, their performance is highly sensitive to the even minor changes in the phrasing of the task instructions, leading to a line of research in automatic instruction optimization towards better performance for NLP tasks. Unfortunately, existing methods for instruction optimization fail to consider the distribution shift between the seen training data and the unseen test data, where testing on unseen group of data with a different distribution could potentially lead to performance drop. In this paper, we take an initial step of investigating the problem of LLM instruction optimization across data groups with distribution shifts. We find that the optimal instructions do encounter performance drops on LLM under certain distribution shifts. To this end, we propose a framework to derive more robust optimal instructions that improve the performance on the ",
    "path": "papers/23/05/2305.13954.json",
    "total_tokens": 757,
    "translated_abstract": "大型语言模型在自然语言处理任务中展现出了重大的性能优势。然而，它们对任务指令微小变化高度敏感，导致自动指令优化的研究。不幸的是，现有的指令优化方法未考虑训练和测试数据之间的分布偏移，在分布不同的未见过的测试数据上测试可能会导致性能下降。在本文中，我们首先探究了跨数据组之间的LLM指令优化问题。结果表明，在某些分布偏移下，优化指令确实会降低LLM的性能。因此，我们提出了一个框架来得到更稳健的指令优化，并提高在不同的数据分布上的性能。",
    "tldr": "本文提出了一个框架来处理分布偏移下的大型语言模型指令优化问题，以提高在未知数据下的性能表现。",
    "en_tdlr": "This paper proposes a framework to address the instruction optimization problem in large language models with distribution shifts, and aims to improve the performance on unseen data with different distributions."
}