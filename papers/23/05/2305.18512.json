{
    "title": "A Rainbow in Deep Network Black Boxes. (arXiv:2305.18512v1 [cs.LG])",
    "abstract": "We introduce rainbow networks as a probabilistic model of trained deep neural networks. The model cascades random feature maps whose weight distributions are learned. It assumes that dependencies between weights at different layers are reduced to rotations which align the input activations. Neuron weights within a layer are independent after this alignment. Their activations define kernels which become deterministic in the infinite-width limit. This is verified numerically for ResNets trained on the ImageNet dataset. We also show that the learned weight distributions have low-rank covariances. Rainbow networks thus alternate between linear dimension reductions and non-linear high-dimensional embeddings with white random features. Gaussian rainbow networks are defined with Gaussian weight distributions. These models are validated numerically on image classification on the CIFAR-10 dataset, with wavelet scattering networks. We further show that during training, SGD updates the weight cov",
    "link": "http://arxiv.org/abs/2305.18512",
    "context": "Title: A Rainbow in Deep Network Black Boxes. (arXiv:2305.18512v1 [cs.LG])\nAbstract: We introduce rainbow networks as a probabilistic model of trained deep neural networks. The model cascades random feature maps whose weight distributions are learned. It assumes that dependencies between weights at different layers are reduced to rotations which align the input activations. Neuron weights within a layer are independent after this alignment. Their activations define kernels which become deterministic in the infinite-width limit. This is verified numerically for ResNets trained on the ImageNet dataset. We also show that the learned weight distributions have low-rank covariances. Rainbow networks thus alternate between linear dimension reductions and non-linear high-dimensional embeddings with white random features. Gaussian rainbow networks are defined with Gaussian weight distributions. These models are validated numerically on image classification on the CIFAR-10 dataset, with wavelet scattering networks. We further show that during training, SGD updates the weight cov",
    "path": "papers/23/05/2305.18512.json",
    "total_tokens": 910,
    "translated_title": "深度网络黑盒中的彩虹",
    "translated_abstract": "我们引入了彩虹网络作为训练好的深度神经网络的概率模型。该模型级联随机特征映射，其权重分布是可以学习的。它假设不同层之间的权重依赖性被减少到将输入激活对准的旋转。层内的神经元权重在这种对齐后是相互独立的。它们的激活定义了在无穷宽度极限下变得确定的内核。这在ImageNet数据集上训练的ResNets中通过数字验证。我们还发现，学习的权重分布具有低秩协方差。因此，彩虹网络在线性降维和非线性高维嵌入与白色随机特征之间交替。我们提供了具有高斯权重分布的高斯彩虹网络定义。这些模型在使用小波散射网络进行CIFAR-10图像分类方面进行了数字验证。我们还证明了，在训练期间，SGD更新权重的协方差。",
    "tldr": "彩虹网络是训练深度神经网络的概率模型，通过层内神经元权重互相独立的对齐和随机特征映射来进行线性降维和非线性高维嵌入，在ImageNet和CIFAR-10数据集上进行验证。",
    "en_tdlr": "Rainbow networks are a probabilistic model for trained deep neural networks that perform linear dimension reductions and non-linear high-dimensional embeddings with random feature maps, while assuming aligned input activations and independent neuron weights within a layer. They are validated numerically on ImageNet and CIFAR-10 datasets."
}