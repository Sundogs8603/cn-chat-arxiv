{
    "title": "Query Rewriting for Retrieval-Augmented Large Language Models. (arXiv:2305.14283v2 [cs.CL] UPDATED)",
    "abstract": "Large Language Models (LLMs) play powerful, black-box readers in the retrieve-then-read pipeline, making remarkable progress in knowledge-intensive tasks. This work introduces a new framework, Rewrite-Retrieve-Read instead of the previous retrieve-then-read for the retrieval-augmented LLMs from the perspective of the query rewriting. Unlike prior studies focusing on adapting either the retriever or the reader, our approach pays attention to the adaptation of the search query itself, for there is inevitably a gap between the input text and the needed knowledge in retrieval. We first prompt an LLM to generate the query, then use a web search engine to retrieve contexts. Furthermore, to better align the query to the frozen modules, we propose a trainable scheme for our pipeline. A small language model is adopted as a trainable rewriter to cater to the black-box LLM reader. The rewriter is trained using the feedback of the LLM reader by reinforcement learning. Evaluation is conducted on do",
    "link": "http://arxiv.org/abs/2305.14283",
    "context": "Title: Query Rewriting for Retrieval-Augmented Large Language Models. (arXiv:2305.14283v2 [cs.CL] UPDATED)\nAbstract: Large Language Models (LLMs) play powerful, black-box readers in the retrieve-then-read pipeline, making remarkable progress in knowledge-intensive tasks. This work introduces a new framework, Rewrite-Retrieve-Read instead of the previous retrieve-then-read for the retrieval-augmented LLMs from the perspective of the query rewriting. Unlike prior studies focusing on adapting either the retriever or the reader, our approach pays attention to the adaptation of the search query itself, for there is inevitably a gap between the input text and the needed knowledge in retrieval. We first prompt an LLM to generate the query, then use a web search engine to retrieve contexts. Furthermore, to better align the query to the frozen modules, we propose a trainable scheme for our pipeline. A small language model is adopted as a trainable rewriter to cater to the black-box LLM reader. The rewriter is trained using the feedback of the LLM reader by reinforcement learning. Evaluation is conducted on do",
    "path": "papers/23/05/2305.14283.json",
    "total_tokens": 988,
    "translated_title": "检索增强的大型语言模型的查询重写",
    "translated_abstract": "大型语言模型（LLMs）在检索后阅读流程中充当强大的黑盒读者，在知识密集任务中取得了显著的进展。本研究从查询重写的角度引入了一个新的框架，即重新写入-检索-阅读，而不是之前的检索后阅读方法，用于检索增强的LLMs。与以往侧重于调整检索器或阅读器的研究不同，我们的方法关注的是搜索查询本身的适应性，因为输入文本与检索所需知识之间不可避免存在差距。我们首先提示LLM生成查询，然后使用网络搜索引擎来检索上下文。此外，为了更好地使查询与冻结模块对齐，我们提出了一个可训练的方案。采用一个小型语言模型作为可训练的重写器，以适应黑盒LLM阅读器。通过强化学习，使用LLM阅读器的反馈训练重写器。在Do任务数据集上进行了评估。",
    "tldr": "该论文介绍了一种新的框架，即查询重写-检索-阅读，用于检索增强的大型语言模型。通过关注搜索查询本身的适应性，采用可训练的重写器来更好地对齐查询与冻结模块，从而改善了检索的效果。实验结果表明该方法在知识密集任务上取得了显著的进展。"
}