{
    "title": "Query Expansion by Prompting Large Language Models. (arXiv:2305.03653v1 [cs.IR])",
    "abstract": "Query expansion is a widely used technique to improve the recall of search systems. In this paper, we propose an approach to query expansion that leverages the generative abilities of Large Language Models (LLMs). Unlike traditional query expansion approaches such as Pseudo-Relevance Feedback (PRF) that relies on retrieving a good set of pseudo-relevant documents to expand queries, we rely on the generative and creative abilities of an LLM and leverage the knowledge inherent in the model. We study a variety of different prompts, including zero-shot, few-shot and Chain-of-Thought (CoT). We find that CoT prompts are especially useful for query expansion as these prompts instruct the model to break queries down step-by-step and can provide a large number of terms related to the original query. Experimental results on MS-MARCO and BEIR demonstrate that query expansions generated by LLMs can be more powerful than traditional query expansion methods.",
    "link": "http://arxiv.org/abs/2305.03653",
    "context": "Title: Query Expansion by Prompting Large Language Models. (arXiv:2305.03653v1 [cs.IR])\nAbstract: Query expansion is a widely used technique to improve the recall of search systems. In this paper, we propose an approach to query expansion that leverages the generative abilities of Large Language Models (LLMs). Unlike traditional query expansion approaches such as Pseudo-Relevance Feedback (PRF) that relies on retrieving a good set of pseudo-relevant documents to expand queries, we rely on the generative and creative abilities of an LLM and leverage the knowledge inherent in the model. We study a variety of different prompts, including zero-shot, few-shot and Chain-of-Thought (CoT). We find that CoT prompts are especially useful for query expansion as these prompts instruct the model to break queries down step-by-step and can provide a large number of terms related to the original query. Experimental results on MS-MARCO and BEIR demonstrate that query expansions generated by LLMs can be more powerful than traditional query expansion methods.",
    "path": "papers/23/05/2305.03653.json",
    "total_tokens": 810,
    "translated_title": "利用大语言模型促进查询扩展",
    "translated_abstract": "查询扩展是提高搜索系统召回率的常用技术。本文提出了一种利用大型语言模型（LLM）的生成能力进行查询扩展的方法。与传统的查询扩展方法如“伪相关反馈”（PRF）依赖于检索一组好的伪相关文档来扩展查询相比，我们依赖LLM的生成和创造能力，并利用模型固有的知识。我们研究了各种不同的提示，包括零-shot、few-shot和Chain-of-Thought（CoT）。我们发现CoT提示对于查询扩展特别有用，因为这些提示指示模型逐步分解查询，并可以提供与原始查询相关的大量术语。在MS-MARCO和BEIR上的实验结果表明，LLM生成的查询扩展可以比传统的查询扩展方法更具优势。",
    "tldr": "本文提出了一种利用大型语言模型进行查询扩展的方法，相比传统方法具有更好的表现，特别是Chain-of-Thought提示对于查询扩展有着重要的作用。",
    "en_tdlr": "This paper proposes an approach to query expansion that leverages the generative abilities of Large Language Models (LLMs), which shows better performance than traditional methods, especially with the use of Chain-of-Thought prompt."
}