{
    "title": "Counterfactual reasoning: Testing language models' understanding of hypothetical scenarios. (arXiv:2305.16572v1 [cs.CL])",
    "abstract": "Current pre-trained language models have enabled remarkable improvements in downstream tasks, but it remains difficult to distinguish effects of statistical correlation from more systematic logical reasoning grounded on the understanding of real world. We tease these factors apart by leveraging counterfactual conditionals, which force language models to predict unusual consequences based on hypothetical propositions. We introduce a set of tests from psycholinguistic experiments, as well as larger-scale controlled datasets, to probe counterfactual predictions from five pre-trained language models. We find that models are consistently able to override real-world knowledge in counterfactual scenarios, and that this effect is more robust in case of stronger baseline world knowledge -- however, we also find that for most models this effect appears largely to be driven by simple lexical cues. When we mitigate effects of both world knowledge and lexical cues to test knowledge of linguistic nu",
    "link": "http://arxiv.org/abs/2305.16572",
    "context": "Title: Counterfactual reasoning: Testing language models' understanding of hypothetical scenarios. (arXiv:2305.16572v1 [cs.CL])\nAbstract: Current pre-trained language models have enabled remarkable improvements in downstream tasks, but it remains difficult to distinguish effects of statistical correlation from more systematic logical reasoning grounded on the understanding of real world. We tease these factors apart by leveraging counterfactual conditionals, which force language models to predict unusual consequences based on hypothetical propositions. We introduce a set of tests from psycholinguistic experiments, as well as larger-scale controlled datasets, to probe counterfactual predictions from five pre-trained language models. We find that models are consistently able to override real-world knowledge in counterfactual scenarios, and that this effect is more robust in case of stronger baseline world knowledge -- however, we also find that for most models this effect appears largely to be driven by simple lexical cues. When we mitigate effects of both world knowledge and lexical cues to test knowledge of linguistic nu",
    "path": "papers/23/05/2305.16572.json",
    "total_tokens": 883,
    "translated_title": "反事实推理：测试语言模型对假设情景的理解",
    "translated_abstract": "当前预先训练的语言模型在下游任务中取得了显著进展，但仍然难以区分统计相关性和更系统的基于对真实世界理解的逻辑推理的效果。我们通过利用反事实条件将这些因素分开，强制语言模型根据假设提议预测异常后果。我们引入了一系列来自心理语言学实验以及更大规模的受控数据集的测试，以探测五个预先训练的语言模型的反事实预测。我们发现，模型通常能够在反事实情景中覆盖真实世界的知识，并且在更强的基线世界知识案例中，这种效应更为强大--然而，我们还发现，对于大多数模型，这种效应似乎在很大程度上是由简单的词汇线索驱动的。当我们缓解世界知识和词汇线索的影响以测试语言的语言学自由程度时",
    "tldr": "本文通过反事实条件测试了五个预先训练的语言模型的能力，发现这些模型通常能够在反事实情景中覆盖真实世界的知识，但这种效应通常由简单的词汇线索驱动。"
}