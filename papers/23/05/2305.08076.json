{
    "title": "Improving Defensive Distillation using Teacher Assistant. (arXiv:2305.08076v1 [cs.CV])",
    "abstract": "Adversarial attacks pose a significant threat to the security and safety of deep neural networks being applied to modern applications. More specifically, in computer vision-based tasks, experts can use the knowledge of model architecture to create adversarial samples imperceptible to the human eye. These attacks can lead to security problems in popular applications such as self-driving cars, face recognition, etc. Hence, building networks which are robust to such attacks is highly desirable and essential. Among the various methods present in literature, defensive distillation has shown promise in recent years. Using knowledge distillation, researchers have been able to create models robust against some of those attacks. However, more attacks have been developed exposing weakness in defensive distillation. In this project, we derive inspiration from teacher assistant knowledge distillation and propose that introducing an assistant network can improve the robustness of the distilled mode",
    "link": "http://arxiv.org/abs/2305.08076",
    "context": "Title: Improving Defensive Distillation using Teacher Assistant. (arXiv:2305.08076v1 [cs.CV])\nAbstract: Adversarial attacks pose a significant threat to the security and safety of deep neural networks being applied to modern applications. More specifically, in computer vision-based tasks, experts can use the knowledge of model architecture to create adversarial samples imperceptible to the human eye. These attacks can lead to security problems in popular applications such as self-driving cars, face recognition, etc. Hence, building networks which are robust to such attacks is highly desirable and essential. Among the various methods present in literature, defensive distillation has shown promise in recent years. Using knowledge distillation, researchers have been able to create models robust against some of those attacks. However, more attacks have been developed exposing weakness in defensive distillation. In this project, we derive inspiration from teacher assistant knowledge distillation and propose that introducing an assistant network can improve the robustness of the distilled mode",
    "path": "papers/23/05/2305.08076.json",
    "total_tokens": 889,
    "translated_title": "利用教师助手提高防御性蒸馏",
    "translated_abstract": "对抗攻击对现代应用中应用的深度神经网络的安全性和稳定性构成重大威胁。在基于计算机视觉的任务中，专家可以利用模型结构的知识来创建人类视觉无法察觉的对抗样本。这些攻击可能会导致流行的应用程序（如自动驾驶汽车、人脸识别等）存在安全问题。因此，建立对此类攻击具有鲁棒性的网络是非常必要和重要的。在文献中，防御性蒸馏是最有前途的方法之一。使用知识蒸馏，研究人员已经能够创建对一些攻击具有鲁棒性的模型。但是，越来越多的攻击被开发出来，暴露了防御性蒸馏的弱点。在这个项目中，我们从教师助手知识蒸馏中获得灵感，并提出引入辅助网络可以提高蒸馏模型的鲁棒性。",
    "tldr": "该论文阐述了对抗攻击对深度神经网络的威胁，介绍了防御性蒸馏的方法并提出了利用教师助手来提高网络的鲁棒性。",
    "en_tdlr": "This paper discusses the threat of adversarial attacks to deep neural networks and introduces the method of defensive distillation. It proposes the use of a teacher assistant network to improve the robustness of the distilled model."
}