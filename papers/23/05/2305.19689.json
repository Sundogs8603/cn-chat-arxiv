{
    "title": "Assessing Word Importance Using Models Trained for Semantic Tasks. (arXiv:2305.19689v1 [cs.CL])",
    "abstract": "Many NLP tasks require to automatically identify the most significant words in a text. In this work, we derive word significance from models trained to solve semantic task: Natural Language Inference and Paraphrase Identification. Using an attribution method aimed to explain the predictions of these models, we derive importance scores for each input token. We evaluate their relevance using a so-called cross-task evaluation: Analyzing the performance of one model on an input masked according to the other model's weight, we show that our method is robust with respect to the choice of the initial task. Additionally, we investigate the scores from the syntax point of view and observe interesting patterns, e.g. words closer to the root of a syntactic tree receive higher importance scores. Altogether, these observations suggest that our method can be used to identify important words in sentences without any explicit word importance labeling in training.",
    "link": "http://arxiv.org/abs/2305.19689",
    "context": "Title: Assessing Word Importance Using Models Trained for Semantic Tasks. (arXiv:2305.19689v1 [cs.CL])\nAbstract: Many NLP tasks require to automatically identify the most significant words in a text. In this work, we derive word significance from models trained to solve semantic task: Natural Language Inference and Paraphrase Identification. Using an attribution method aimed to explain the predictions of these models, we derive importance scores for each input token. We evaluate their relevance using a so-called cross-task evaluation: Analyzing the performance of one model on an input masked according to the other model's weight, we show that our method is robust with respect to the choice of the initial task. Additionally, we investigate the scores from the syntax point of view and observe interesting patterns, e.g. words closer to the root of a syntactic tree receive higher importance scores. Altogether, these observations suggest that our method can be used to identify important words in sentences without any explicit word importance labeling in training.",
    "path": "papers/23/05/2305.19689.json",
    "total_tokens": 863,
    "translated_title": "利用训练用于语义任务的模型评估词语重要性",
    "translated_abstract": "许多自然语言处理任务需要自动识别文本中最重要的单词。本文从训练用于解决自然语言推理和释义识别的模型中得到单词重要性。我们使用一种旨在解释这些模型预测的属性方法，为每个输入令牌导出重要性得分。我们使用所谓的交叉任务评估来评估它们的相关性：分析一个模型在按照另一个模型权重屏蔽的输入上的表现，我们展示了我们的方法对于初始任务的选择是稳健的。此外，我们从语法的角度研究了分数，并观察到有趣的模式，例如更接近语法树根的单词接收较高的重要性得分。总之，这些观察结果表明我们的方法可以用于在训练中没有任何显式单词重要性标签的情况下识别句子中重要的单词。",
    "tldr": "本文介绍了一种从解决语义任务的模型中推导出单词重要性的方法，并证明其稳健性，可以在无需显式单词重要性标签的情况下识别句子中重要的单词。",
    "en_tdlr": "This paper proposes a method to derive word importance from models trained for semantic tasks, and demonstrates its robustness by cross-task evaluation. The method can identify important words in sentences without explicit word importance labeling in training."
}