{
    "title": "Alternating Gradient Descent and Mixture-of-Experts for Integrated Multimodal Perception. (arXiv:2305.06324v1 [cs.CV])",
    "abstract": "We present Integrated Multimodal Perception (IMP), a simple and scalable multimodal multi-task training and modeling approach. IMP integrates multimodal inputs including image, video, text, and audio into a single Transformer encoder with minimal modality-specific components. IMP makes use of a novel design that combines Alternating Gradient Descent (AGD) and Mixture-of-Experts (MoE) for efficient model \\& task scaling. We conduct extensive empirical studies about IMP and reveal the following key insights: 1) performing gradient descent updates by alternating on diverse heterogeneous modalities, loss functions, and tasks, while also varying input resolutions, efficiently improves multimodal understanding. 2) model sparsification with MoE on a single modality-agnostic encoder substantially improves the performance, outperforming dense models that use modality-specific encoders or additional fusion layers and greatly mitigating the conflicts between modalities. IMP achieves competitive p",
    "link": "http://arxiv.org/abs/2305.06324",
    "context": "Title: Alternating Gradient Descent and Mixture-of-Experts for Integrated Multimodal Perception. (arXiv:2305.06324v1 [cs.CV])\nAbstract: We present Integrated Multimodal Perception (IMP), a simple and scalable multimodal multi-task training and modeling approach. IMP integrates multimodal inputs including image, video, text, and audio into a single Transformer encoder with minimal modality-specific components. IMP makes use of a novel design that combines Alternating Gradient Descent (AGD) and Mixture-of-Experts (MoE) for efficient model \\& task scaling. We conduct extensive empirical studies about IMP and reveal the following key insights: 1) performing gradient descent updates by alternating on diverse heterogeneous modalities, loss functions, and tasks, while also varying input resolutions, efficiently improves multimodal understanding. 2) model sparsification with MoE on a single modality-agnostic encoder substantially improves the performance, outperforming dense models that use modality-specific encoders or additional fusion layers and greatly mitigating the conflicts between modalities. IMP achieves competitive p",
    "path": "papers/23/05/2305.06324.json",
    "total_tokens": 991,
    "translated_title": "AGD和MoE用于集成多模态感知",
    "translated_abstract": "本文提出了一种简单可扩展的多模态多任务训练和建模方法——集成多模态感知（IMP）。IMP将图像、视频、文本和音频等多模态输入集成到单个Transformer编码器中，并具有最小的模态特定组件。IMP使用了一种新颖的设计，将交替梯度下降法（AGD）和混合专家（MoE）相结合，以实现高效的模型和任务扩展。通过广泛的实证研究，我们揭示了以下关键见解：1）在多样化的异构模态、损失函数和任务上交替执行梯度下降更新，并同时改变输入分辨率，可以有效提高多模态理解。2）在单一的模态不可知编码器上使用MoE进行模型稀疏化可以显著提高性能，胜过使用模态特定编码器或额外融合层的稠密模型，并大大缓解模态之间的冲突。IMP在三个多模态基准测试中取得了具有竞争力的性能，胜过了大部分已发表的方法。",
    "tldr": "本文提出了集成多模态感知（IMP）方法，将多模态输入集成到单个编码器中，采用交替梯度下降法（AGD）和混合专家（MoE）相结合的方法实现高效的模型和任务扩展，取得了在多个基准测试中具有竞争力的性能表现。",
    "en_tdlr": "This paper proposes an approach called Integrated Multimodal Perception (IMP), which integrates multiple modalities into a single Transformer encoder with minimal modality-specific components, and uses a combination of Alternating Gradient Descent (AGD) and Mixture-of-Experts (MoE) for efficient model and task scaling. The approach achieves competitive performance on multiple benchmarks and outperforms most published methods."
}