{
    "title": "Approximation-Generalization Trade-offs under (Approximate) Group Equivariance. (arXiv:2305.17592v1 [cs.LG])",
    "abstract": "The explicit incorporation of task-specific inductive biases through symmetry has emerged as a general design precept in the development of high-performance machine learning models. For example, group equivariant neural networks have demonstrated impressive performance across various domains and applications such as protein and drug design. A prevalent intuition about such models is that the integration of relevant symmetry results in enhanced generalization. Moreover, it is posited that when the data and/or the model may only exhibit $\\textit{approximate}$ or $\\textit{partial}$ symmetry, the optimal or best-performing model is one where the model symmetry aligns with the data symmetry. In this paper, we conduct a formal unified investigation of these intuitions. To begin, we present general quantitative bounds that demonstrate how models capturing task-specific symmetries lead to improved generalization. In fact, our results do not require the transformations to be finite or even form",
    "link": "http://arxiv.org/abs/2305.17592",
    "context": "Title: Approximation-Generalization Trade-offs under (Approximate) Group Equivariance. (arXiv:2305.17592v1 [cs.LG])\nAbstract: The explicit incorporation of task-specific inductive biases through symmetry has emerged as a general design precept in the development of high-performance machine learning models. For example, group equivariant neural networks have demonstrated impressive performance across various domains and applications such as protein and drug design. A prevalent intuition about such models is that the integration of relevant symmetry results in enhanced generalization. Moreover, it is posited that when the data and/or the model may only exhibit $\\textit{approximate}$ or $\\textit{partial}$ symmetry, the optimal or best-performing model is one where the model symmetry aligns with the data symmetry. In this paper, we conduct a formal unified investigation of these intuitions. To begin, we present general quantitative bounds that demonstrate how models capturing task-specific symmetries lead to improved generalization. In fact, our results do not require the transformations to be finite or even form",
    "path": "papers/23/05/2305.17592.json",
    "total_tokens": 920,
    "translated_title": "(近似)群等变性下的逼近-泛化权衡",
    "translated_abstract": "通过对称性明确地引入任务特定的归纳偏差已成为高性能机器学习模型开发中的常规设计准则。例如，群等变神经网络在蛋白质和药物设计等各个领域和应用中展现了卓越的性能。这种模型的普遍感觉是，将相关对称性整合到模型中会增强泛化能力。此外，有人认为，当数据和/或模型只能表现出$\\textit{近似}$或$\\textit{部分}$对称性时，最优或最好性能的模型是一个模型对齐于数据对称性的模型。在本文中，我们对这些直觉进行了正式的统一研究。首先，我们提出一般的数量界限，证明捕获任务特定对称性的模型将导致改进的泛化。事实上，我们的结果不要求变换是有限的，甚至不需要形成完整的....",
    "tldr": "本论文详细研究了通过对称性明确地引入任务特定的归纳偏差所导致的逼近-泛化权衡，并且证明了这种模型在捕获任务特定对称性的同时会改进泛化。这一结果对于提高机器学习领域的性能具有非常大的帮助。",
    "en_tdlr": "This paper conducts a formal investigation on the approximation-generalization trade-offs resulting from incorporating task-specific inductive biases through symmetry, and demonstrates how models capturing task-specific symmetries can lead to improved generalization. The results have important implications in improving performance in machine learning."
}