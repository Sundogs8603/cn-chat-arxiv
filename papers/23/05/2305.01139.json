{
    "title": "Stratified Adversarial Robustness with Rejection. (arXiv:2305.01139v1 [cs.LG])",
    "abstract": "Recently, there is an emerging interest in adversarially training a classifier with a rejection option (also known as a selective classifier) for boosting adversarial robustness. While rejection can incur a cost in many applications, existing studies typically associate zero cost with rejecting perturbed inputs, which can result in the rejection of numerous slightly-perturbed inputs that could be correctly classified. In this work, we study adversarially-robust classification with rejection in the stratified rejection setting, where the rejection cost is modeled by rejection loss functions monotonically non-increasing in the perturbation magnitude. We theoretically analyze the stratified rejection setting and propose a novel defense method -- Adversarial Training with Consistent Prediction-based Rejection (CPR) -- for building a robust selective classifier. Experiments on image datasets demonstrate that the proposed method significantly outperforms existing methods under strong adaptiv",
    "link": "http://arxiv.org/abs/2305.01139",
    "context": "Title: Stratified Adversarial Robustness with Rejection. (arXiv:2305.01139v1 [cs.LG])\nAbstract: Recently, there is an emerging interest in adversarially training a classifier with a rejection option (also known as a selective classifier) for boosting adversarial robustness. While rejection can incur a cost in many applications, existing studies typically associate zero cost with rejecting perturbed inputs, which can result in the rejection of numerous slightly-perturbed inputs that could be correctly classified. In this work, we study adversarially-robust classification with rejection in the stratified rejection setting, where the rejection cost is modeled by rejection loss functions monotonically non-increasing in the perturbation magnitude. We theoretically analyze the stratified rejection setting and propose a novel defense method -- Adversarial Training with Consistent Prediction-based Rejection (CPR) -- for building a robust selective classifier. Experiments on image datasets demonstrate that the proposed method significantly outperforms existing methods under strong adaptiv",
    "path": "papers/23/05/2305.01139.json",
    "total_tokens": 912,
    "translated_title": "分层对抗鲁棒性与拒绝",
    "translated_abstract": "最近出现了一种对分类器进行有选择性地训练的对抗性方法——拒绝预测，用于增强对抗鲁棒性。虽然在许多应用中，拒绝预测会带来一定的成本，但现有研究通常将被扰动的输入的拒绝与零成本相关联，这可能会导致拒绝大量可以被正确分类的轻度扰动输入。本文研究了在分层拒绝设置下的对抗鲁棒分类，并且通过拒绝损失函数在扰动幅度上单调不减地建模来模拟拒绝成本。我们从理论上分析了分层拒绝设置，并提出了一种新的防御方法——基于一致预测的拒绝对抗训练（CPR）——用于构建鲁棒的选择性分类器。针对图像数据集进行的实验表明，所提出的方法在强适应性下明显优于现有方法。",
    "tldr": "本文提出了一种新的防御方法——基于一致预测的拒绝对抗训练（CPR），用于构建鲁棒的选择性分类器。该方法可以在分层拒绝设置下进行对抗鲁棒分类，并且在实验中表现出很好的性能。",
    "en_tdlr": "The paper proposes a novel defense method, Adversarial Training with Consistent Prediction-based Rejection (CPR), for building a robust selective classifier. It can perform adversarial robust classification with rejection in the stratified rejection setting and outperforms existing methods in experiments."
}