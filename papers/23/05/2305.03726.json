{
    "title": "Otter: A Multi-Modal Model with In-Context Instruction Tuning. (arXiv:2305.03726v1 [cs.CV])",
    "abstract": "Large language models (LLMs) have demonstrated significant universal capabilities as few/zero-shot learners in various tasks due to their pre-training on vast amounts of text data, as exemplified by GPT-3, which boosted to InstrctGPT and ChatGPT, effectively following natural language instructions to accomplish real-world tasks. In this paper, we propose to introduce instruction tuning into multi-modal models, motivated by the Flamingo model's upstream interleaved format pretraining dataset. We adopt a similar approach to construct our MultI-Modal In-Context Instruction Tuning (MIMIC-IT) dataset. We then introduce Otter, a multi-modal model based on OpenFlamingo (open-sourced version of DeepMind's Flamingo), trained on MIMIC-IT and showcasing improved instruction-following ability and in-context learning. We also optimize OpenFlamingo's implementation for researchers, democratizing the required training resources from 1$\\times$ A100 GPU to 4$\\times$ RTX-3090 GPUs, and integrate both Op",
    "link": "http://arxiv.org/abs/2305.03726",
    "context": "Title: Otter: A Multi-Modal Model with In-Context Instruction Tuning. (arXiv:2305.03726v1 [cs.CV])\nAbstract: Large language models (LLMs) have demonstrated significant universal capabilities as few/zero-shot learners in various tasks due to their pre-training on vast amounts of text data, as exemplified by GPT-3, which boosted to InstrctGPT and ChatGPT, effectively following natural language instructions to accomplish real-world tasks. In this paper, we propose to introduce instruction tuning into multi-modal models, motivated by the Flamingo model's upstream interleaved format pretraining dataset. We adopt a similar approach to construct our MultI-Modal In-Context Instruction Tuning (MIMIC-IT) dataset. We then introduce Otter, a multi-modal model based on OpenFlamingo (open-sourced version of DeepMind's Flamingo), trained on MIMIC-IT and showcasing improved instruction-following ability and in-context learning. We also optimize OpenFlamingo's implementation for researchers, democratizing the required training resources from 1$\\times$ A100 GPU to 4$\\times$ RTX-3090 GPUs, and integrate both Op",
    "path": "papers/23/05/2305.03726.json",
    "total_tokens": 923,
    "translated_title": "Otter: 一种多模态模型及其上下文指令调整方法",
    "translated_abstract": "巨大的语言模型(LLMs)由于预训练了大量文本数据而展示出在各种任务中以零/少数据学习的显著普适能力，例如GPT-3，它推出了InstrctGPT和ChatGPT，能够通过自然语言指令完成真实世界的任务。本文提出了将指令调整引入到多模态模型中的想法，受到Flamingo模型上游交替格式预训练数据集的启发。我们采用类似的方法构建了我们的MultI-Modal In-Context Instruction Tuning (MIMIC-IT)数据集。我们提出了Otter，一种基于OpenFlamingo的多模态模型(DeepMind的Flamingo的开源版本)，它在MIMIC-IT上进行训练，并展示了更好的指令跟随能力和上下文学习能力。我们还针对研究人员优化了OpenFlamingo的实现，将所需的训练资源从1个A100 GPU降至4个RTX-3090 GPU，从而使研究更具民主性。",
    "tldr": "Otter是一种多模态模型，引入了指令调整方法，基于OpenFlamingo训练，能够更好地指令跟随和上下文学习。",
    "en_tdlr": "Otter is a multi-modal model that introduces instruction tuning, trained on OpenFlamingo and showcasing improved instruction-following ability and in-context learning. It optimizes OpenFlamingo's implementation for researchers, democratizing the required training resources."
}