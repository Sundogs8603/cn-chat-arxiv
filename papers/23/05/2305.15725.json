{
    "title": "Learn to Not Link: Exploring NIL Prediction in Entity Linking. (arXiv:2305.15725v1 [cs.CL])",
    "abstract": "Entity linking models have achieved significant success via utilizing pretrained language models to capture semantic features. However, the NIL prediction problem, which aims to identify mentions without a corresponding entity in the knowledge base, has received insufficient attention. We categorize mentions linking to NIL into Missing Entity and Non-Entity Phrase, and propose an entity linking dataset NEL that focuses on the NIL prediction problem. NEL takes ambiguous entities as seeds, collects relevant mention context in the Wikipedia corpus, and ensures the presence of mentions linking to NIL by human annotation and entity masking. We conduct a series of experiments with the widely used bi-encoder and cross-encoder entity linking models, results show that both types of NIL mentions in training data have a significant influence on the accuracy of NIL prediction. Our code and dataset can be accessed at https://github.com/solitaryzero/NIL_EL",
    "link": "http://arxiv.org/abs/2305.15725",
    "context": "Title: Learn to Not Link: Exploring NIL Prediction in Entity Linking. (arXiv:2305.15725v1 [cs.CL])\nAbstract: Entity linking models have achieved significant success via utilizing pretrained language models to capture semantic features. However, the NIL prediction problem, which aims to identify mentions without a corresponding entity in the knowledge base, has received insufficient attention. We categorize mentions linking to NIL into Missing Entity and Non-Entity Phrase, and propose an entity linking dataset NEL that focuses on the NIL prediction problem. NEL takes ambiguous entities as seeds, collects relevant mention context in the Wikipedia corpus, and ensures the presence of mentions linking to NIL by human annotation and entity masking. We conduct a series of experiments with the widely used bi-encoder and cross-encoder entity linking models, results show that both types of NIL mentions in training data have a significant influence on the accuracy of NIL prediction. Our code and dataset can be accessed at https://github.com/solitaryzero/NIL_EL",
    "path": "papers/23/05/2305.15725.json",
    "total_tokens": 839,
    "translated_title": "学习不链接：探索实体链接中的NIL预测",
    "translated_abstract": "实体链接模型通过利用预训练的语言模型捕捉语义特征已取得重大成功，然而对于寻找没有相应知识库实体的提及的NIL预测问题尚未得到足够关注。我们将链接到NIL的提及分为缺失实体和非实体短语，并提出了一个实体链接数据集NEL，重点关注NIL预测问题。NEL以不明确的实体作为种子，在维基百科语料库中收集相关的提及上下文，并通过人工注释和实体屏蔽确保链接到NIL的提及的存在。我们使用广泛使用的双编码器和交叉编码器实体链接模型进行了一系列实验，结果表明在训练数据中，这两种类型的NIL提及对NIL预测的准确性有显着影响。我们的代码和数据集可以在 https://github.com/solitaryzero/NIL_EL 上获取。",
    "tldr": "该论文提出了一个实体链接数据集NEL及其对NIL预测问题的分类方法，研究结果表明在训练数据中，缺失实体和非实体短语均对NIL预测的准确性具有显著影响。",
    "en_tdlr": "This paper proposes an entity linking dataset NEL and its classification method for the NIL prediction problem. The results show that both missing entity and non-entity phrase in the training data significantly affect the accuracy of NIL prediction."
}