{
    "title": "Visually-Situated Natural Language Understanding with Contrastive Reading Model and Frozen Large Language Models. (arXiv:2305.15080v2 [cs.CL] UPDATED)",
    "abstract": "Recent advances in Large Language Models (LLMs) have stimulated a surge of research aimed at extending their applications to the visual domain. While these models exhibit promise in generating abstract image captions and facilitating natural conversations, their performance on text-rich images still requires improvement. In this paper, we introduce Contrastive Reading Model (Cream), a novel neural architecture designed to enhance the language-image understanding capability of LLMs by capturing intricate details that are often overlooked in existing methods. Cream combines vision and auxiliary encoders, fortified by a contrastive feature alignment technique, to achieve a more effective comprehension of language information in visually situated contexts within the images. Our approach bridges the gap between vision and language understanding, paving the way for the development of more sophisticated Document Intelligence Assistants. Through rigorous evaluations across diverse visually-sit",
    "link": "http://arxiv.org/abs/2305.15080",
    "context": "Title: Visually-Situated Natural Language Understanding with Contrastive Reading Model and Frozen Large Language Models. (arXiv:2305.15080v2 [cs.CL] UPDATED)\nAbstract: Recent advances in Large Language Models (LLMs) have stimulated a surge of research aimed at extending their applications to the visual domain. While these models exhibit promise in generating abstract image captions and facilitating natural conversations, their performance on text-rich images still requires improvement. In this paper, we introduce Contrastive Reading Model (Cream), a novel neural architecture designed to enhance the language-image understanding capability of LLMs by capturing intricate details that are often overlooked in existing methods. Cream combines vision and auxiliary encoders, fortified by a contrastive feature alignment technique, to achieve a more effective comprehension of language information in visually situated contexts within the images. Our approach bridges the gap between vision and language understanding, paving the way for the development of more sophisticated Document Intelligence Assistants. Through rigorous evaluations across diverse visually-sit",
    "path": "papers/23/05/2305.15080.json",
    "total_tokens": 958,
    "translated_title": "通过对比阅读模型和冻结大型语言模型进行视觉定位自然语言理解",
    "translated_abstract": "最近大型语言模型的进展刺激了对将其应用扩展到视觉领域的研究潮流。尽管这些模型在生成抽象图像标题和促进自然对话方面表现出了潜力，但它们在文本丰富的图像上的表现仍需要改进。本文介绍了一种名为对比阅读模型（Cream）的新型神经架构，旨在通过捕捉现有方法常常忽视的复杂细节，提升大型语言模型在语言-图像理解能力方面的性能。Cream结合了视觉和辅助编码器，并借助对比特征对齐技术来实现对图像中视觉定位上下文中语言信息的更有效理解。我们的方法弥合了视觉与语言理解之间的差距，为更复杂的文档智能助手的开发铺平了道路。通过对不同视觉定位上下文中的严格评估，我们验证了该方法的有效性。",
    "tldr": "本文介绍了一种名为对比阅读模型（Cream）的新型神经架构，旨在通过捕捉复杂细节，提升大型语言模型在语言-图像理解能力方面的性能。该方法通过视觉和辅助编码器及对比特征对齐技术实现了对视觉定位上下文中语言信息的更有效理解。",
    "en_tdlr": "This paper introduces a novel neural architecture called Contrastive Reading Model (Cream), aimed at enhancing the language-image understanding capability of Large Language Models (LLMs) by capturing intricate details. The approach combines vision and auxiliary encoders with contrastive feature alignment technique to achieve more effective comprehension of language information in visually situated contexts."
}