{
    "title": "Scene Graph as Pivoting: Inference-time Image-free Unsupervised Multimodal Machine Translation with Visual Scene Hallucination. (arXiv:2305.12256v2 [cs.CL] UPDATED)",
    "abstract": "In this work, we investigate a more realistic unsupervised multimodal machine translation (UMMT) setup, inference-time image-free UMMT, where the model is trained with source-text image pairs, and tested with only source-text inputs. First, we represent the input images and texts with the visual and language scene graphs (SG), where such fine-grained vision-language features ensure a holistic understanding of the semantics. To enable pure-text input during inference, we devise a visual scene hallucination mechanism that dynamically generates pseudo visual SG from the given textual SG. Several SG-pivoting based learning objectives are introduced for unsupervised translation training. On the benchmark Multi30K data, our SG-based method outperforms the best-performing baseline by significant BLEU scores on the task and setup, helping yield translations with better completeness, relevance and fluency without relying on paired images. Further in-depth analyses reveal how our model advances ",
    "link": "http://arxiv.org/abs/2305.12256",
    "context": "Title: Scene Graph as Pivoting: Inference-time Image-free Unsupervised Multimodal Machine Translation with Visual Scene Hallucination. (arXiv:2305.12256v2 [cs.CL] UPDATED)\nAbstract: In this work, we investigate a more realistic unsupervised multimodal machine translation (UMMT) setup, inference-time image-free UMMT, where the model is trained with source-text image pairs, and tested with only source-text inputs. First, we represent the input images and texts with the visual and language scene graphs (SG), where such fine-grained vision-language features ensure a holistic understanding of the semantics. To enable pure-text input during inference, we devise a visual scene hallucination mechanism that dynamically generates pseudo visual SG from the given textual SG. Several SG-pivoting based learning objectives are introduced for unsupervised translation training. On the benchmark Multi30K data, our SG-based method outperforms the best-performing baseline by significant BLEU scores on the task and setup, helping yield translations with better completeness, relevance and fluency without relying on paired images. Further in-depth analyses reveal how our model advances ",
    "path": "papers/23/05/2305.12256.json",
    "total_tokens": 917,
    "translated_title": "以情景图为轴心: 推理时基于图像无监督多模态机器翻译的视觉情景幻化方法",
    "translated_abstract": "本文研究了更现实的无监督多模态机器翻译（UMMT）的推理时基于图像无监督多模态机器翻译(Ummt)。我们首先使用视觉和语言情景图(SG)来表示输入的图像和文本，通过SG表示方法可以确保对语义的整体理解。为了在推理过程中实现纯文本输入，我们设计了一种视觉情景幻化机制，可以从给定的文本SG动态生成伪视觉SG。我们引入了几种基于SG轴心的学习目标，以实现无监督翻译训练。在基准数据集Multi30K上，我们的SG方法在任务和设置上的 BLEU 得分显著高于最佳基线，有助于产生更完整、相关和流畅的翻译，而不需要依赖成对的图像。进一步的深入分析揭示了我们的模型如何推进UMMT任务。",
    "tldr": "本研究提出了一种基于情景图的轴心方法，通过动态生成伪视觉情景图来实现推理过程中的纯文本输入，从而实现了无监督多模态机器翻译任务。",
    "en_tdlr": "This paper proposes a SG-pivoting approach that uses visual and language scene graphs to represent input images and texts, and dynamically generates pseudo visual SG for pure-text input during inference, achieving unsupervised multimodal machine translation without paired images on benchmark data sets."
}