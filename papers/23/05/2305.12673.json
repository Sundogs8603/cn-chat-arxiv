{
    "title": "Efficient Bilateral Cross-Modality Cluster Matching for Unsupervised Visible-Infrared Person ReID. (arXiv:2305.12673v2 [cs.CV] UPDATED)",
    "abstract": "Unsupervised visible-infrared person re-identification (USL-VI-ReID) aims to match pedestrian images of the same identity from different modalities without annotations. Existing works mainly focus on alleviating the modality gap by aligning instance-level features of the unlabeled samples. However, the relationships between cross-modality clusters are not well explored. To this end, we propose a novel bilateral cluster matching-based learning framework to reduce the modality gap by matching cross-modality clusters. Specifically, we design a Many-to-many Bilateral Cross-Modality Cluster Matching (MBCCM) algorithm through optimizing the maximum matching problem in a bipartite graph. Then, the matched pairwise clusters utilize shared visible and infrared pseudo-labels during the model training. Under such a supervisory signal, a Modality-Specific and Modality-Agnostic (MSMA) contrastive learning framework is proposed to align features jointly at a cluster-level. Meanwhile, the cross-modal",
    "link": "http://arxiv.org/abs/2305.12673",
    "context": "Title: Efficient Bilateral Cross-Modality Cluster Matching for Unsupervised Visible-Infrared Person ReID. (arXiv:2305.12673v2 [cs.CV] UPDATED)\nAbstract: Unsupervised visible-infrared person re-identification (USL-VI-ReID) aims to match pedestrian images of the same identity from different modalities without annotations. Existing works mainly focus on alleviating the modality gap by aligning instance-level features of the unlabeled samples. However, the relationships between cross-modality clusters are not well explored. To this end, we propose a novel bilateral cluster matching-based learning framework to reduce the modality gap by matching cross-modality clusters. Specifically, we design a Many-to-many Bilateral Cross-Modality Cluster Matching (MBCCM) algorithm through optimizing the maximum matching problem in a bipartite graph. Then, the matched pairwise clusters utilize shared visible and infrared pseudo-labels during the model training. Under such a supervisory signal, a Modality-Specific and Modality-Agnostic (MSMA) contrastive learning framework is proposed to align features jointly at a cluster-level. Meanwhile, the cross-modal",
    "path": "papers/23/05/2305.12673.json",
    "total_tokens": 934,
    "translated_title": "高效的双边跨模态聚类匹配用于无监督可见光-红外人物识别",
    "translated_abstract": "无监督的可见光-红外人物识别（USL-VI-ReID）旨在在没有注释的情况下匹配来自不同模态的行人图像中相同身份的样本。本文针对没有很好探索跨模态聚类关系的问题，提出了一种新颖的双向聚类匹配学习框架，通过匹配跨模态聚类来减少模态差异。我们通过在二分图中优化最大匹配问题设计了一个多对多双边跨模态聚类匹配（MBCCM）算法。然后，匹配的成对聚类在模型训练期间利用共享的可见光和红外伪标签。在这样的监督信号下，提出了一种模态特定和模态不可知（MSMA）对比学习框架，以在聚类级别上共同对齐特征。同时，跨模态的模态特定和模态不可知特征也被考虑进去。",
    "tldr": "该文提出了一种通过匹配跨模态聚类来减少模态差异的双向聚类匹配学习框架，同时提出了模态特定和模态不可知对比学习框架来共同对齐特征。",
    "en_tdlr": "This paper proposes a bilateral cluster matching-based learning framework to reduce modality gap by matching cross-modality clusters, and a Modality-Specific and Modality-Agnostic contrastive learning framework to jointly align features at a cluster-level."
}