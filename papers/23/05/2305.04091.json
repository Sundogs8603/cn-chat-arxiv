{
    "title": "Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models. (arXiv:2305.04091v1 [cs.CL])",
    "abstract": "Large language models (LLMs) have recently been shown to deliver impressive performance in various NLP tasks. To tackle multi-step reasoning tasks, few-shot chain-of-thought (CoT) prompting includes a few manually crafted step-by-step reasoning demonstrations which enable LLMs to explicitly generate reasoning steps and improve their reasoning task accuracy. To eliminate the manual effort, Zero-shot-CoT concatenates the target problem statement with \"Let's think step by step\" as an input prompt to LLMs. Despite the success of Zero-shot-CoT, it still suffers from three pitfalls: calculation errors, missing-step errors, and semantic misunderstanding errors. To address the missing-step errors, we propose Plan-and-Solve (PS) Prompting. It consists of two components: first, devising a plan to divide the entire task into smaller subtasks, and then carrying out the subtasks according to the plan. To address the calculation errors and improve the quality of generated reasoning steps, we extend ",
    "link": "http://arxiv.org/abs/2305.04091",
    "context": "Title: Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models. (arXiv:2305.04091v1 [cs.CL])\nAbstract: Large language models (LLMs) have recently been shown to deliver impressive performance in various NLP tasks. To tackle multi-step reasoning tasks, few-shot chain-of-thought (CoT) prompting includes a few manually crafted step-by-step reasoning demonstrations which enable LLMs to explicitly generate reasoning steps and improve their reasoning task accuracy. To eliminate the manual effort, Zero-shot-CoT concatenates the target problem statement with \"Let's think step by step\" as an input prompt to LLMs. Despite the success of Zero-shot-CoT, it still suffers from three pitfalls: calculation errors, missing-step errors, and semantic misunderstanding errors. To address the missing-step errors, we propose Plan-and-Solve (PS) Prompting. It consists of two components: first, devising a plan to divide the entire task into smaller subtasks, and then carrying out the subtasks according to the plan. To address the calculation errors and improve the quality of generated reasoning steps, we extend ",
    "path": "papers/23/05/2305.04091.json",
    "total_tokens": 1059,
    "translated_title": "计划和解决提示：通过大型语言模型改善零样本思考链推理",
    "translated_abstract": "最近，大型语言模型（LLMs）在各种自然语言处理任务中表现出惊人的性能。为了解决多步骤推理任务，少样本的思维链（CoT）提示包括一些手工制作的逐步推理演示，使LLMs能够明确生成推理步骤并提高其推理任务准确性。为了消除手动劳动，零样本思维链将目标问题陈述与“让我们逐步思考”连接起来作为输入提示LLMs。尽管零样本-CoT取得了成功，但仍存在计算错误、缺失步骤错误和语义误解错误的问题。为了解决缺失步骤错误，我们提出了计划和解决（PS）提示。它包含两个组成部分：首先，制定计划将整个任务划分为较小的子任务，然后按照计划执行子任务。为了解决计算错误并提高生成推理步骤的质量，我们将输入提示扩展到包括简单算术计算的示例。我们的实验表明，PS提示在思维链推理任务的准确性方面胜过了零样本CoT。",
    "tldr": "本研究提出了一种计划和解决的提示方法来改善零样本思考链推理，该方法包括两个组成部分：制定计划将任务划分为子任务，并按计划执行子任务；将输入提示扩展到包括简单算术计算的示例。实验结果显示，该方法胜过了零样本-CoT。",
    "en_tdlr": "This paper proposes a Plan-and-Solve prompting method to improve zero-shot chain-of-thought reasoning, which consists of dividing the task into subtasks and carrying them out according to a plan, and extending the input prompt to include examples of arithmetic calculations. The method outperforms zero-shot CoT according to the experimental results."
}