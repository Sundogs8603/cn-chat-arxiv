{
    "title": "LaFTer: Label-Free Tuning of Zero-shot Classifier using Language and Unlabeled Image Collections. (arXiv:2305.18287v2 [cs.CV] UPDATED)",
    "abstract": "Recently, large-scale pre-trained Vision and Language (VL) models have set a new state-of-the-art (SOTA) in zero-shot visual classification enabling open-vocabulary recognition of potentially unlimited set of categories defined as simple language prompts. However, despite these great advances, the performance of these zeroshot classifiers still falls short of the results of dedicated (closed category set) classifiers trained with supervised fine tuning. In this paper we show, for the first time, how to reduce this gap without any labels and without any paired VL data, using an unlabeled image collection and a set of texts auto-generated using a Large Language Model (LLM) describing the categories of interest and effectively substituting labeled visual instances of those categories. Using our label-free approach, we are able to attain significant performance improvements over the zero-shot performance of the base VL model and other contemporary methods and baselines on a wide variety of",
    "link": "http://arxiv.org/abs/2305.18287",
    "context": "Title: LaFTer: Label-Free Tuning of Zero-shot Classifier using Language and Unlabeled Image Collections. (arXiv:2305.18287v2 [cs.CV] UPDATED)\nAbstract: Recently, large-scale pre-trained Vision and Language (VL) models have set a new state-of-the-art (SOTA) in zero-shot visual classification enabling open-vocabulary recognition of potentially unlimited set of categories defined as simple language prompts. However, despite these great advances, the performance of these zeroshot classifiers still falls short of the results of dedicated (closed category set) classifiers trained with supervised fine tuning. In this paper we show, for the first time, how to reduce this gap without any labels and without any paired VL data, using an unlabeled image collection and a set of texts auto-generated using a Large Language Model (LLM) describing the categories of interest and effectively substituting labeled visual instances of those categories. Using our label-free approach, we are able to attain significant performance improvements over the zero-shot performance of the base VL model and other contemporary methods and baselines on a wide variety of",
    "path": "papers/23/05/2305.18287.json",
    "total_tokens": 911,
    "translated_title": "LaFTer: 使用语言和无标签图像集进行无标签调整的零样本分类器",
    "translated_abstract": "最近，大规模预训练的视觉和语言（VL）模型在零样本视觉分类中取得了新的最先进（SOTA）的成果，实现了使用简单语言提示定义的潜在无限类别的开放词汇识别。然而，尽管取得了这些巨大的进展，这些零样本分类器的性能仍然不及经过监督微调训练的专用（封闭类别集）分类器的结果。在本文中，我们首次展示了如何在没有任何标签和任何配对的VL数据的情况下缩小这个差距，使用一个无标签图像集和使用大型语言模型（LLM）生成的一组描述感兴趣类别的文本，有效地替代那些类别的标记视觉实例。使用我们的无标签方法，我们能够在各种不同的情况下显著提高基本VL模型和其他当代方法和基准的零样本性能。",
    "tldr": "本文首次展示了如何通过使用无标签图像集和自动生成的大量语言模型文本来缩小零样本分类器与有标签分类器之间的性能差距，从而在无需任何标签和配对的情况下提高了零样本分类器的性能。"
}