{
    "title": "\"Oops, Did I Just Say That?\" Testing and Repairing Unethical Suggestions of Large Language Models with Suggest-Critique-Reflect Process. (arXiv:2305.02626v1 [cs.SE])",
    "abstract": "As the popularity of large language models (LLMs) soars across various applications, ensuring their alignment with human values has become a paramount concern. In particular, given that LLMs have great potential to serve as general-purpose AI assistants in daily life, their subtly unethical suggestions become a serious and real concern. Tackling the challenge of automatically testing and repairing unethical suggestions is thus demanding.  This paper introduces the first framework for testing and repairing unethical suggestions made by LLMs. We first propose ETHICSSUITE, a test suite that presents complex, contextualized, and realistic moral scenarios to test LLMs. We then propose a novel suggest-critic-reflect (SCR) process, serving as an automated test oracle to detect unethical suggestions. We recast deciding if LLMs yield unethical suggestions (a hard problem; often requiring human expertise and costly to decide) into a PCR task that can be automatically checked for violation. Moreo",
    "link": "http://arxiv.org/abs/2305.02626",
    "context": "Title: \"Oops, Did I Just Say That?\" Testing and Repairing Unethical Suggestions of Large Language Models with Suggest-Critique-Reflect Process. (arXiv:2305.02626v1 [cs.SE])\nAbstract: As the popularity of large language models (LLMs) soars across various applications, ensuring their alignment with human values has become a paramount concern. In particular, given that LLMs have great potential to serve as general-purpose AI assistants in daily life, their subtly unethical suggestions become a serious and real concern. Tackling the challenge of automatically testing and repairing unethical suggestions is thus demanding.  This paper introduces the first framework for testing and repairing unethical suggestions made by LLMs. We first propose ETHICSSUITE, a test suite that presents complex, contextualized, and realistic moral scenarios to test LLMs. We then propose a novel suggest-critic-reflect (SCR) process, serving as an automated test oracle to detect unethical suggestions. We recast deciding if LLMs yield unethical suggestions (a hard problem; often requiring human expertise and costly to decide) into a PCR task that can be automatically checked for violation. Moreo",
    "path": "papers/23/05/2305.02626.json",
    "total_tokens": 998,
    "translated_title": "“哎呀，我刚刚说了什么？”用建议-批判-反思过程测试和修复大型语言模型的不道德建议",
    "translated_abstract": "随着大型语言模型（LLM）在各种应用中的流行，确保它们与人类价值观相一致已成为一个重要关注点。特别是，考虑到LLM有望成为日常生活中通用的人工智能助手，它们微妙的不道德建议成为了一个严重而现实的问题。因此，自动化测试和修复不道德建议的挑战是很大的。本文介绍了第一个测试和修复LLM不道德建议的框架。我首先提出了ETHICSSUITE，一个测试套件，用于测试LLM的复杂、情境化和现实的道德场景。然后我提出了一种新颖的建议-批判-反思（SCR）过程，作为自动化测试预言，用于检测不道德建议。我们将判断LLM是否产生不道德建议（通常需要人类专业知识和成本较高）转化为一个可以自动检查违规的PCR任务。此外，SCR过程还提供了修复不道德建议的反馈。",
    "tldr": "随着大型语言模型(LLM)在各种应用中的流行，本文提出了第一个测试和修复LLM在道德准则上失当建议的框架，并引入ETHICSSUITE测试套件和建议-批判-反思(SCR)过程以自动检测和修复LLM的不道德建议。"
}