{
    "title": "Regret Matching+: (In)Stability and Fast Convergence in Games. (arXiv:2305.14709v1 [cs.GT])",
    "abstract": "Regret Matching+ (RM+) and its variants are important algorithms for solving large-scale games. However, a theoretical understanding of their success in practice is still a mystery. Moreover, recent advances on fast convergence in games are limited to no-regret algorithms such as online mirror descent, which satisfy stability. In this paper, we first give counterexamples showing that RM+ and its predictive version can be unstable, which might cause other players to suffer large regret. We then provide two fixes: restarting and chopping off the positive orthant that RM+ works in. We show that these fixes are sufficient to get $O(T^{1/4})$ individual regret and $O(1)$ social regret in normal-form games via RM+ with predictions. We also apply our stabilizing techniques to clairvoyant updates in the uncoupled learning setting for RM+ and prove desirable results akin to recent works for Clairvoyant online mirror descent. Our experiments show the advantages of our algorithms over vanilla RM+",
    "link": "http://arxiv.org/abs/2305.14709",
    "context": "Title: Regret Matching+: (In)Stability and Fast Convergence in Games. (arXiv:2305.14709v1 [cs.GT])\nAbstract: Regret Matching+ (RM+) and its variants are important algorithms for solving large-scale games. However, a theoretical understanding of their success in practice is still a mystery. Moreover, recent advances on fast convergence in games are limited to no-regret algorithms such as online mirror descent, which satisfy stability. In this paper, we first give counterexamples showing that RM+ and its predictive version can be unstable, which might cause other players to suffer large regret. We then provide two fixes: restarting and chopping off the positive orthant that RM+ works in. We show that these fixes are sufficient to get $O(T^{1/4})$ individual regret and $O(1)$ social regret in normal-form games via RM+ with predictions. We also apply our stabilizing techniques to clairvoyant updates in the uncoupled learning setting for RM+ and prove desirable results akin to recent works for Clairvoyant online mirror descent. Our experiments show the advantages of our algorithms over vanilla RM+",
    "path": "papers/23/05/2305.14709.json",
    "total_tokens": 913,
    "translated_title": "Regret Matching+：游戏中的（不）稳定性和快速收敛",
    "translated_abstract": "Regret Matching+（RM +）及其变体是解决大规模游戏的重要算法。然而，它们在实践中成功的理论理解仍然是一个谜。此外，最近关于游戏中快速收敛的进展仅限于无遗憾算法，如在线镜像下降，其满足稳定性。本文首先提供反例，展示RM +及其预测版本可能不稳定，这可能会导致其他玩家遭受巨大的遗憾。然后，我们提供两种修复方法：重新启动和截断RM +所在的正半轴。我们证明，通过具有预测的RM + 进行上述修复就足以在正态形式的游戏中获得$ O（T ^ {1/4}）$个体遗憾和$ O（1）$社会遗憾。我们还将我们的稳定技术应用于RM + 的自足学习中的光明更新，并证明了类似于最近Clairvoyant在线镜像下降工作的良好结果。我们的实验显示了我们的算法优于原始的RM +。",
    "tldr": "本文研究了Regret Matching+算法的稳定性和快速收敛问题，并提供了两种修复方法，实验结果表明这些修复方法比原算法更有效。",
    "en_tdlr": "This paper investigates the stability and fast convergence issues of the Regret Matching+ algorithm and provides two fixing methods. Experimental results demonstrate that these fixes are more effective than the original algorithm."
}