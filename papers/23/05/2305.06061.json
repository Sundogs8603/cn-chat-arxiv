{
    "title": "Visual Tuning. (arXiv:2305.06061v1 [cs.CV])",
    "abstract": "Fine-tuning visual models has been widely shown promising performance on many downstream visual tasks. With the surprising development of pre-trained visual foundation models, visual tuning jumped out of the standard modus operandi that fine-tunes the whole pre-trained model or just the fully connected layer. Instead, recent advances can achieve superior performance than full-tuning the whole pre-trained parameters by updating far fewer parameters, enabling edge devices and downstream applications to reuse the increasingly large foundation models deployed on the cloud. With the aim of helping researchers get the full picture and future directions of visual tuning, this survey characterizes a large and thoughtful selection of recent works, providing a systematic and comprehensive overview of existing work and models. Specifically, it provides a detailed background of visual tuning and categorizes recent visual tuning techniques into five groups: prompt tuning, adapter tuning, parameter ",
    "link": "http://arxiv.org/abs/2305.06061",
    "context": "Title: Visual Tuning. (arXiv:2305.06061v1 [cs.CV])\nAbstract: Fine-tuning visual models has been widely shown promising performance on many downstream visual tasks. With the surprising development of pre-trained visual foundation models, visual tuning jumped out of the standard modus operandi that fine-tunes the whole pre-trained model or just the fully connected layer. Instead, recent advances can achieve superior performance than full-tuning the whole pre-trained parameters by updating far fewer parameters, enabling edge devices and downstream applications to reuse the increasingly large foundation models deployed on the cloud. With the aim of helping researchers get the full picture and future directions of visual tuning, this survey characterizes a large and thoughtful selection of recent works, providing a systematic and comprehensive overview of existing work and models. Specifically, it provides a detailed background of visual tuning and categorizes recent visual tuning techniques into five groups: prompt tuning, adapter tuning, parameter ",
    "path": "papers/23/05/2305.06061.json",
    "total_tokens": 952,
    "translated_title": "视觉调整",
    "translated_abstract": "对视觉模型进行微调已被广泛证明在许多下游视觉任务中具有有前途的表现。随着预训练视觉基础模型的惊人发展，视觉调整跳出了标准的模式操作，即微调整个预训练模型或仅微调完全连接层。相反，近期的进展可以通过更新更少的参数实现比全面微调整个预训练参数更优异的表现，使边缘设备和下游应用程序可以重复使用部署在云端的日益庞大的基础模型。为了帮助研究人员全面了解视觉调整的全貌和未来方向，本综述描绘了大量的近期研究作品，提供了现有工作和模型系统和全面的概述。具体而言，它提供了视觉调整的详细背景，并将最近的视觉调整技术分为五组：提示调整、适配器调整、参数翻译、紧凑调整和模块调整。本文还强调了当前视觉调整技术的限制和挑战，并提出了几个未来研究方向。",
    "tldr": "本文综述了视觉调整的发展与现状，将近期的视觉调整技术分为五类，包括提示调整、适配器调整、参数翻译、紧凑调整和模块调整，并提出了未来研究方向。",
    "en_tdlr": "This survey characterizes recent developments in visual tuning, categorizing techniques into five groups: prompt tuning, adapter tuning, parameter translation, compact tuning, and module tuning. The survey highlights the limitations and challenges of current techniques and suggests future research directions."
}