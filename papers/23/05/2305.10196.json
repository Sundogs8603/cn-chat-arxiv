{
    "title": "A Survey on Zero Pronoun Translation. (arXiv:2305.10196v1 [cs.CL])",
    "abstract": "Zero pronouns (ZPs) are frequently omitted in pro-drop languages (e.g. Chinese, Hungarian, and Hindi), but should be recalled in non-pro-drop languages (e.g. English). This phenomenon has been studied extensively in machine translation (MT), as it poses a significant challenge for MT systems due to the difficulty in determining the correct antecedent for the pronoun. This survey paper highlights the major works that have been undertaken in zero pronoun translation (ZPT) after the neural revolution, so that researchers can recognise the current state and future directions of this field. We provide an organisation of the literature based on evolution, dataset, method and evaluation. In addition, we compare and analyze competing models and evaluation metrics on different benchmarks. We uncover a number of insightful findings such as: 1) ZPT is in line with the development trend of large language model; 2) data limitation causes learning bias in languages and domains; 3) performance improv",
    "link": "http://arxiv.org/abs/2305.10196",
    "context": "Title: A Survey on Zero Pronoun Translation. (arXiv:2305.10196v1 [cs.CL])\nAbstract: Zero pronouns (ZPs) are frequently omitted in pro-drop languages (e.g. Chinese, Hungarian, and Hindi), but should be recalled in non-pro-drop languages (e.g. English). This phenomenon has been studied extensively in machine translation (MT), as it poses a significant challenge for MT systems due to the difficulty in determining the correct antecedent for the pronoun. This survey paper highlights the major works that have been undertaken in zero pronoun translation (ZPT) after the neural revolution, so that researchers can recognise the current state and future directions of this field. We provide an organisation of the literature based on evolution, dataset, method and evaluation. In addition, we compare and analyze competing models and evaluation metrics on different benchmarks. We uncover a number of insightful findings such as: 1) ZPT is in line with the development trend of large language model; 2) data limitation causes learning bias in languages and domains; 3) performance improv",
    "path": "papers/23/05/2305.10196.json",
    "total_tokens": 936,
    "translated_title": "零代词翻译综述",
    "translated_abstract": "零代词（ZP）通常在类似中文、匈牙利语和印地语这样的丢省略，而在非丢失省份诸如英语中，应当进行回应。这一现象在机器翻译（MT）领域中得到了广泛的研究，因为它很难确定代词的正确先行词，这是MT系统面临的重要挑战。本文总结了神经网络全面推展之后在零代词翻译（ZPT）方面所做的重要工作，以便研究人员了解当前状态和未来方向。我们根据演变、数据集、方法和评估提供了一份文献组织形式。此外，我们还比较和分析了在不同基准测试上的竞争模型和评估指标。我们挖掘了一些有益的发现，例如：1）ZPT符合大型语言模型的发展趋势；2）数据限制会在不同语言和领域中产生学习偏差；3）通过多任务或迁移学习可以实现性能提升。",
    "tldr": "本文总结了零代词翻译（ZPT）领域神经网络全面推广后的重要工作，发现大型语言模型、多任务或迁移学习都可以实现ZPT的性能提升。",
    "en_tdlr": "This survey paper summarizes the important work in the field of zero pronoun translation (ZPT) after the full-scale promotion of neural networks, and finds that large language models, multi-task or transfer learning all can improve the performance of ZPT."
}