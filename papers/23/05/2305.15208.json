{
    "title": "Generalized Bayesian Inference for Scientific Simulators via Amortized Cost Estimation. (arXiv:2305.15208v1 [stat.ML])",
    "abstract": "Simulation-based inference (SBI) enables amortized Bayesian inference for simulators with implicit likelihoods. But when we are primarily interested in the quality of predictive simulations, or when the model cannot exactly reproduce the observed data (i.e., is misspecified), targeting the Bayesian posterior may be overly restrictive. Generalized Bayesian Inference (GBI) aims to robustify inference for (misspecified) simulator models, replacing the likelihood-function with a cost function that evaluates the goodness of parameters relative to data. However, GBI methods generally require running multiple simulations to estimate the cost function at each parameter value during inference, making the approach computationally infeasible for even moderately complex simulators. Here, we propose amortized cost estimation (ACE) for GBI to address this challenge: We train a neural network to approximate the cost function, which we define as the expected distance between simulations produced by a ",
    "link": "http://arxiv.org/abs/2305.15208",
    "context": "Title: Generalized Bayesian Inference for Scientific Simulators via Amortized Cost Estimation. (arXiv:2305.15208v1 [stat.ML])\nAbstract: Simulation-based inference (SBI) enables amortized Bayesian inference for simulators with implicit likelihoods. But when we are primarily interested in the quality of predictive simulations, or when the model cannot exactly reproduce the observed data (i.e., is misspecified), targeting the Bayesian posterior may be overly restrictive. Generalized Bayesian Inference (GBI) aims to robustify inference for (misspecified) simulator models, replacing the likelihood-function with a cost function that evaluates the goodness of parameters relative to data. However, GBI methods generally require running multiple simulations to estimate the cost function at each parameter value during inference, making the approach computationally infeasible for even moderately complex simulators. Here, we propose amortized cost estimation (ACE) for GBI to address this challenge: We train a neural network to approximate the cost function, which we define as the expected distance between simulations produced by a ",
    "path": "papers/23/05/2305.15208.json",
    "total_tokens": 963,
    "translated_title": "广义贝叶斯推理方法：通过摊销成本评估为科学模拟器提供贝叶斯推理",
    "translated_abstract": "基于模拟的推理方法(SBI)通过内含的可能性，为模拟器提供摊销式的贝叶斯推理。但是当我们主要关注的是预测模拟的质量，或者当模型不能完全重现观测数据(即存在缺陷)，以贝叶斯后验为目标就可能过于严格。广义贝叶斯推理(GBI)旨在加强对(有缺陷的)模拟器模型的推理，用评估参数相对于数据的好坏的成本函数替换似然函数。然而，GBI方法通常需要运行多个模拟，以在推理期间估计每个参数值的成本函数，使得即使在中等复杂的模拟程序中也难以计算。在这里，我们提出了基于摊销成本评估(ACE)的广义贝叶斯推理方法，以解决这个挑战：我们训练神经网络来近似成本函数，将成本函数定义为由潜在参数生成的模拟之间的期望距离。",
    "tldr": "提出了摊销成本估计方法，能够解决广义贝叶斯推理方法中多个模拟的计算问题，从而为深度神经网络提供了一种处理高维度、复杂复现，且贝叶斯后验未必是最佳方案的科学模拟器的优化方法。",
    "en_tdlr": "Proposed amortized cost estimation method, which solves the computational problem of multiple simulations in generalized Bayesian inference, provides a way for deep neural networks to optimize scientific simulators with high dimensionality, complex replication, and Bayesian posterior not necessarily being an optimal solution."
}