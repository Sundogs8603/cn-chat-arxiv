{
    "title": "TMR: Text-to-Motion Retrieval Using Contrastive 3D Human Motion Synthesis. (arXiv:2305.00976v1 [cs.CV])",
    "abstract": "In this paper, we present TMR, a simple yet effective approach for text to 3D human motion retrieval. While previous work has only treated retrieval as a proxy evaluation metric, we tackle it as a standalone task. Our method extends the state-of-the-art text-to-motion synthesis model TEMOS, and incorporates a contrastive loss to better structure the cross-modal latent space. We show that maintaining the motion generation loss, along with the contrastive training, is crucial to obtain good performance. We introduce a benchmark for evaluation and provide an in-depth analysis by reporting results on several protocols. Our extensive experiments on the KIT-ML and HumanML3D datasets show that TMR outperforms the prior work by a significant margin, for example reducing the median rank from 54 to 19. Finally, we showcase the potential of our approach on moment retrieval. Our code and models are publicly available.",
    "link": "http://arxiv.org/abs/2305.00976",
    "context": "Title: TMR: Text-to-Motion Retrieval Using Contrastive 3D Human Motion Synthesis. (arXiv:2305.00976v1 [cs.CV])\nAbstract: In this paper, we present TMR, a simple yet effective approach for text to 3D human motion retrieval. While previous work has only treated retrieval as a proxy evaluation metric, we tackle it as a standalone task. Our method extends the state-of-the-art text-to-motion synthesis model TEMOS, and incorporates a contrastive loss to better structure the cross-modal latent space. We show that maintaining the motion generation loss, along with the contrastive training, is crucial to obtain good performance. We introduce a benchmark for evaluation and provide an in-depth analysis by reporting results on several protocols. Our extensive experiments on the KIT-ML and HumanML3D datasets show that TMR outperforms the prior work by a significant margin, for example reducing the median rank from 54 to 19. Finally, we showcase the potential of our approach on moment retrieval. Our code and models are publicly available.",
    "path": "papers/23/05/2305.00976.json",
    "total_tokens": 923,
    "translated_title": "TMR:使用对比3D人体运动合成的文本到运动检索",
    "translated_abstract": "本文提出了一种名为TMR的简单而有效的方法，用于将文本转换为3D人体运动。与之前的工作仅将检索视为代理评估指标不同，我们将其作为一个独立的任务来解决。我们的方法扩展了最先进的文本到动作合成模型TEMOS，并结合对比损失来更好地构造跨模态的潜在空间。我们表明保持运动生成损失和对比性训练至关重要，以获得良好的性能。我们引入了一个基准来进行评估，并通过报告几个协议的结果进行了深入分析。我们在KIT-ML和HumanML3D数据集上进行的广泛实验表明，TMR比先前的工作表现出明显的优势，例如将中位数排名从54降至19。最后，我们展示了我们方法在时刻检索方面的潜力。我们的代码和模型是公开可用的。",
    "tldr": "本文介绍了一种名为TMR的方法，用于将文本转换为3D人体运动。它在先前的工作中取得了明显的优势，并通过引入对比性损失的方法来更好地建立跨模态潜在空间结构。结果表明，保持运动生成损失和对比性训练至关重要。",
    "en_tdlr": "This paper presents TMR, a method for converting text to 3D human motion, which outperforms prior work significantly by incorporating contrastive loss to better structure the cross-modal latent space. Results show that maintaining the motion generation loss, along with contrastive training, is crucial for good performance."
}