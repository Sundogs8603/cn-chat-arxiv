{
    "title": "Summarizing, Simplifying, and Synthesizing Medical Evidence Using GPT-3 (with Varying Success). (arXiv:2305.06299v1 [cs.CL])",
    "abstract": "Large language models, particularly GPT-3, are able to produce high quality summaries of general domain news articles in few- and zero-shot settings. However, it is unclear if such models are similarly capable in more specialized, high-stakes domains such as biomedicine. In this paper, we enlist domain experts (individuals with medical training) to evaluate summaries of biomedical articles generated by GPT-3, given zero supervision. We consider both single- and multi-document settings. In the former, GPT-3 is tasked with generating regular and plain-language summaries of articles describing randomized controlled trials; in the latter, we assess the degree to which GPT-3 is able to \\emph{synthesize} evidence reported across a collection of articles. We design an annotation scheme for evaluating model outputs, with an emphasis on assessing the factual accuracy of generated summaries. We find that while GPT-3 is able to summarize and simplify single biomedical articles faithfully, it stru",
    "link": "http://arxiv.org/abs/2305.06299",
    "context": "Title: Summarizing, Simplifying, and Synthesizing Medical Evidence Using GPT-3 (with Varying Success). (arXiv:2305.06299v1 [cs.CL])\nAbstract: Large language models, particularly GPT-3, are able to produce high quality summaries of general domain news articles in few- and zero-shot settings. However, it is unclear if such models are similarly capable in more specialized, high-stakes domains such as biomedicine. In this paper, we enlist domain experts (individuals with medical training) to evaluate summaries of biomedical articles generated by GPT-3, given zero supervision. We consider both single- and multi-document settings. In the former, GPT-3 is tasked with generating regular and plain-language summaries of articles describing randomized controlled trials; in the latter, we assess the degree to which GPT-3 is able to \\emph{synthesize} evidence reported across a collection of articles. We design an annotation scheme for evaluating model outputs, with an emphasis on assessing the factual accuracy of generated summaries. We find that while GPT-3 is able to summarize and simplify single biomedical articles faithfully, it stru",
    "path": "papers/23/05/2305.06299.json",
    "total_tokens": 935,
    "translated_title": "使用GPT-3对医学证据进行总结、简化和综合（成果参差不齐）",
    "translated_abstract": "大型语言模型，特别是GPT-3，能够在几乎没有监督的情况下生成一流的普通领域新闻文章摘要。但是，尚不清楚这样的模型是否在更专业和高风险的领域，如生物医学中同样具备这样的能力。本文中，我们请领域专家（具备医学培训的人）评估由GPT-3生成的生物医学文章摘要，并考虑单一和多文档摘要情况。前者中，GPT-3的任务是生成描述随机对照试验的文章的常规和简明语言摘要；后者中，我们评估GPT-3在整个文章集中综合报告的程度。我们设计了一个注释方案来评估模型输出，并重点评估生成摘要的事实准确性。我们发现，虽然GPT-3能够忠实地总结和简化单个生物医学文章，但它在综合多个文章所提供的证据方面表现不佳。",
    "tldr": "本文评估了GPT-3在生物医学领域中生成文章摘要的能力，发现它对单个文章的总结和简化效果较好，但在综合多篇文章中所报告的证据方面表现欠佳。"
}