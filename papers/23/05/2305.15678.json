{
    "title": "Revisiting non-English Text Simplification: A Unified Multilingual Benchmark. (arXiv:2305.15678v1 [cs.CL])",
    "abstract": "Recent advancements in high-quality, large-scale English resources have pushed the frontier of English Automatic Text Simplification (ATS) research. However, less work has been done on multilingual text simplification due to the lack of a diverse evaluation benchmark that covers complex-simple sentence pairs in many languages. This paper introduces the MultiSim benchmark, a collection of 27 resources in 12 distinct languages containing over 1.7 million complex-simple sentence pairs. This benchmark will encourage research in developing more effective multilingual text simplification models and evaluation metrics. Our experiments using MultiSim with pre-trained multilingual language models reveal exciting performance improvements from multilingual training in non-English settings. We observe strong performance from Russian in zero-shot cross-lingual transfer to low-resource languages. We further show that few-shot prompting with BLOOM-176b achieves comparable quality to reference simplif",
    "link": "http://arxiv.org/abs/2305.15678",
    "context": "Title: Revisiting non-English Text Simplification: A Unified Multilingual Benchmark. (arXiv:2305.15678v1 [cs.CL])\nAbstract: Recent advancements in high-quality, large-scale English resources have pushed the frontier of English Automatic Text Simplification (ATS) research. However, less work has been done on multilingual text simplification due to the lack of a diverse evaluation benchmark that covers complex-simple sentence pairs in many languages. This paper introduces the MultiSim benchmark, a collection of 27 resources in 12 distinct languages containing over 1.7 million complex-simple sentence pairs. This benchmark will encourage research in developing more effective multilingual text simplification models and evaluation metrics. Our experiments using MultiSim with pre-trained multilingual language models reveal exciting performance improvements from multilingual training in non-English settings. We observe strong performance from Russian in zero-shot cross-lingual transfer to low-resource languages. We further show that few-shot prompting with BLOOM-176b achieves comparable quality to reference simplif",
    "path": "papers/23/05/2305.15678.json",
    "total_tokens": 967,
    "translated_title": "重新审视非英语文本简化：一个统一的多语言基准",
    "translated_abstract": "最近英语自动文本简化（ATS）研究中高质量、大规模的英语资源的进展将英语ATS研究的前沿推向了更高的水平。然而，由于缺乏一个覆盖多种语言中的复杂-简洁句子对的多样化评估基准，对多语言文本简化的研究工作较少。本文介绍了MultiSim基准，这是一个收集了12种不同语言中超过1.7百万个复杂-简单句子对的27个资源的集合。这个基准将鼓励研究开发更有效的多语言文本简化模型和评估指标。我们使用MultiSim与预训练的多语言语言模型进行的实验显示，在非英语环境中进行多语言训练可以带来令人兴奋的性能提升。我们观察到俄语在零-shot跨语言转移到低资源语言的强大表现。我们进一步展示使用BLOOM-176b的少量提示可以达到可比的参考简化质量。",
    "tldr": "这篇论文介绍了MultiSim基准，它包含了27个资源、12种语言超过1.7百万个复杂-简单的句子对。使用该基准进行预训练的多语言语言模型可以在非英语环境中带来令人兴奋的性能提升，并且俄语在跨语言转移方面表现出强大的性能。",
    "en_tdlr": "This paper introduces the MultiSim benchmark, which includes over 1.7 million complex-simple sentence pairs in 27 resources and 12 languages. Pre-trained multilingual language models using this benchmark show exciting performance improvements in non-English settings, and Russian exhibits strong performance in cross-lingual transfer."
}