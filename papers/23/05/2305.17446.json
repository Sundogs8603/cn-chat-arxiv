{
    "title": "Fine-tuning Happens in Tiny Subspaces: Exploring Intrinsic Task-specific Subspaces of Pre-trained Language Models. (arXiv:2305.17446v2 [cs.CL] UPDATED)",
    "abstract": "Pre-trained language models (PLMs) are known to be overly parameterized and have significant redundancy, indicating a small degree of freedom of the PLMs. Motivated by the observation, in this paper, we study the problem of re-parameterizing and fine-tuning PLMs from a new perspective: Discovery of intrinsic task-specific subspace. Specifically, by exploiting the dynamics of the fine-tuning process for a given task, the parameter optimization trajectory is learned to uncover its intrinsic task-specific subspace. A key finding is that PLMs can be effectively fine-tuned in the subspace with a small number of free parameters. Beyond, we observe some outlier dimensions emerging during fine-tuning in the subspace. Disabling these dimensions degrades the model performance significantly. This suggests that these dimensions are crucial to induce task-specific knowledge to downstream tasks.",
    "link": "http://arxiv.org/abs/2305.17446",
    "context": "Title: Fine-tuning Happens in Tiny Subspaces: Exploring Intrinsic Task-specific Subspaces of Pre-trained Language Models. (arXiv:2305.17446v2 [cs.CL] UPDATED)\nAbstract: Pre-trained language models (PLMs) are known to be overly parameterized and have significant redundancy, indicating a small degree of freedom of the PLMs. Motivated by the observation, in this paper, we study the problem of re-parameterizing and fine-tuning PLMs from a new perspective: Discovery of intrinsic task-specific subspace. Specifically, by exploiting the dynamics of the fine-tuning process for a given task, the parameter optimization trajectory is learned to uncover its intrinsic task-specific subspace. A key finding is that PLMs can be effectively fine-tuned in the subspace with a small number of free parameters. Beyond, we observe some outlier dimensions emerging during fine-tuning in the subspace. Disabling these dimensions degrades the model performance significantly. This suggests that these dimensions are crucial to induce task-specific knowledge to downstream tasks.",
    "path": "papers/23/05/2305.17446.json",
    "total_tokens": 867,
    "translated_title": "微小子空间中发生微调: 探索预训练语言模型的内在任务特定子空间",
    "translated_abstract": "已知预训练语言模型（PLMs）过度参数化并具有显著的冗余，表明PLMs的自由度较小。本文从新的角度研究了重新参数化和微调PLMs的问题：发现内在的任务特定子空间。具体地，通过利用给定任务的微调过程的动态，学习了参数优化轨迹以揭示其内在的任务特定子空间。一个关键发现是，在子空间中，PLMs可以通过少量的自由参数进行有效的微调。此外，我们观察到在子空间的微调过程中出现了一些异常维度。禁用这些维度会严重降低模型性能。这表明这些维度对于引入任务特定知识到下游任务是至关重要的。",
    "tldr": "该论文通过发现预训练语言模型的内在任务特定子空间，提出了一种重新参数化和微调模型的新方法。研究发现在该子空间中，只需少量自由参数即可有效微调模型，并且某些维度对于引入任务特定知识至关重要。"
}