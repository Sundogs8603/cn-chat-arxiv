{
    "title": "Securing Distributed SGD against Gradient Leakage Threats. (arXiv:2305.06473v1 [cs.LG])",
    "abstract": "This paper presents a holistic approach to gradient leakage resilient distributed Stochastic Gradient Descent (SGD). First, we analyze two types of strategies for privacy-enhanced federated learning: (i) gradient pruning with random selection or low-rank filtering and (ii) gradient perturbation with additive random noise or differential privacy noise. We analyze the inherent limitations of these approaches and their underlying impact on privacy guarantee, model accuracy, and attack resilience. Next, we present a gradient leakage resilient approach to securing distributed SGD in federated learning, with differential privacy controlled noise as the tool. Unlike conventional methods with the per-client federated noise injection and fixed noise parameter strategy, our approach keeps track of the trend of per-example gradient updates. It makes adaptive noise injection closely aligned throughout the federated model training. Finally, we provide an empirical privacy analysis on the privacy gu",
    "link": "http://arxiv.org/abs/2305.06473",
    "context": "Title: Securing Distributed SGD against Gradient Leakage Threats. (arXiv:2305.06473v1 [cs.LG])\nAbstract: This paper presents a holistic approach to gradient leakage resilient distributed Stochastic Gradient Descent (SGD). First, we analyze two types of strategies for privacy-enhanced federated learning: (i) gradient pruning with random selection or low-rank filtering and (ii) gradient perturbation with additive random noise or differential privacy noise. We analyze the inherent limitations of these approaches and their underlying impact on privacy guarantee, model accuracy, and attack resilience. Next, we present a gradient leakage resilient approach to securing distributed SGD in federated learning, with differential privacy controlled noise as the tool. Unlike conventional methods with the per-client federated noise injection and fixed noise parameter strategy, our approach keeps track of the trend of per-example gradient updates. It makes adaptive noise injection closely aligned throughout the federated model training. Finally, we provide an empirical privacy analysis on the privacy gu",
    "path": "papers/23/05/2305.06473.json",
    "total_tokens": 870,
    "translated_title": "针对梯度泄漏威胁的分布式SGD安全方法",
    "translated_abstract": "本文介绍了一种用于防止梯度泄漏的综合方法，以确保分布式随机梯度下降算法的安全。首先，我们分析了两种隐私增强联邦学习策略：（i）使用随机选择或低秩滤波的梯度剪枝，以及（ii）使用加性随机噪声或差分隐私噪声的梯度扰动。我们分析了这些方法的固有限制以及它们对隐私保证、模型准确度和攻击韧性的影响。接下来，我们提出了一种基于差分隐私控制噪声的梯度泄漏保护方法-保护分布式SGD的联邦学习。与传统方法不同，我们的方法跟踪每个示例的梯度更新趋势，使得自适应噪声注入在联邦模型训练中保持紧密对齐。最后，我们对隐私保护进行了实证分析。",
    "tldr": "本文提出了一种用于防止梯度泄漏的综合方法，使得联邦学习中的分布式SGD更具隐私、准确性和攻击韧性。",
    "en_tdlr": "This paper proposes a holistic approach to prevent gradient leakage, thereby making distributed SGD in federated learning more privacy-preserving, accurate, and attack-resilient."
}