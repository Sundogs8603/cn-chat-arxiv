{
    "title": "Deep Learning-based Spatio Temporal Facial Feature Visual Speech Recognition. (arXiv:2305.00552v1 [cs.CV])",
    "abstract": "In low-resource computing contexts, such as smartphones and other tiny devices, Both deep learning and machine learning are being used in a lot of identification systems. as authentication techniques. The transparent, contactless, and non-invasive nature of these face recognition technologies driven by AI has led to their meteoric rise in popularity in recent years. While they are mostly successful, there are still methods to get inside without permission by utilising things like pictures, masks, glasses, etc. In this research, we present an alternate authentication process that makes use of both facial recognition and the individual's distinctive temporal facial feature motions while they speak a password. Because the suggested methodology allows for a password to be specified in any language, it is not limited by language. The suggested model attained an accuracy of 96.1% when tested on the industry-standard MIRACL-VC1 dataset, demonstrating its efficacy as a reliable and powerful so",
    "link": "http://arxiv.org/abs/2305.00552",
    "context": "Title: Deep Learning-based Spatio Temporal Facial Feature Visual Speech Recognition. (arXiv:2305.00552v1 [cs.CV])\nAbstract: In low-resource computing contexts, such as smartphones and other tiny devices, Both deep learning and machine learning are being used in a lot of identification systems. as authentication techniques. The transparent, contactless, and non-invasive nature of these face recognition technologies driven by AI has led to their meteoric rise in popularity in recent years. While they are mostly successful, there are still methods to get inside without permission by utilising things like pictures, masks, glasses, etc. In this research, we present an alternate authentication process that makes use of both facial recognition and the individual's distinctive temporal facial feature motions while they speak a password. Because the suggested methodology allows for a password to be specified in any language, it is not limited by language. The suggested model attained an accuracy of 96.1% when tested on the industry-standard MIRACL-VC1 dataset, demonstrating its efficacy as a reliable and powerful so",
    "path": "papers/23/05/2305.00552.json",
    "total_tokens": 935,
    "translated_title": "基于深度学习的时空面部特征可视化语音识别",
    "translated_abstract": "在低资源计算环境（如智能手机和其他小型设备）中，深度学习和机器学习被用于许多身份识别系统中作为认证技术。人工智能驱动的这些面部识别技术的透明、非接触和非侵入性质使其近年来在人们中的普及度急剧上升。虽然它们大多都很成功，但仍然存在通过利用图片、面具、眼镜等方式未经许可进入的方法。在本研究中，我们提出了一种替代认证过程，利用了面部识别和个体在讲密码时的独特时空面部特征运动。由于建议的方法允许在任何语言中指定密码，因此不受语言限制。在工业标准MIRACL-VC1数据集上测试时，建议的模型达到了96.1％的准确率，展示了它作为一种可靠而强大的认证技术的有效性。",
    "tldr": "本研究提出了一种基于深度学习的时空面部特征可视化语音识别认证技术，结合面部识别和个体讲密码时的独特时空面部特征运动，成功在工业标准数据集上达到96.1％的准确率。",
    "en_tdlr": "This research proposes a deep learning-based spatio temporal facial feature visual speech recognition authentication method, combining facial recognition and the individual's distinctive temporal facial feature motions while they speak a password. The proposed model achieved an accuracy of 96.1% on industry-standard dataset, demonstrating its efficacy as a reliable and powerful authentication technology."
}