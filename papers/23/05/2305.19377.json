{
    "title": "Benign Overfitting in Deep Neural Networks under Lazy Training. (arXiv:2305.19377v1 [cs.LG])",
    "abstract": "This paper focuses on over-parameterized deep neural networks (DNNs) with ReLU activation functions and proves that when the data distribution is well-separated, DNNs can achieve Bayes-optimal test error for classification while obtaining (nearly) zero-training error under the lazy training regime. For this purpose, we unify three interrelated concepts of overparameterization, benign overfitting, and the Lipschitz constant of DNNs. Our results indicate that interpolating with smoother functions leads to better generalization. Furthermore, we investigate the special case where interpolating smooth ground-truth functions is performed by DNNs under the Neural Tangent Kernel (NTK) regime for generalization. Our result demonstrates that the generalization error converges to a constant order that only depends on label noise and initialization noise, which theoretically verifies benign overfitting. Our analysis provides a tight lower bound on the normalized margin under non-smooth activation ",
    "link": "http://arxiv.org/abs/2305.19377",
    "context": "Title: Benign Overfitting in Deep Neural Networks under Lazy Training. (arXiv:2305.19377v1 [cs.LG])\nAbstract: This paper focuses on over-parameterized deep neural networks (DNNs) with ReLU activation functions and proves that when the data distribution is well-separated, DNNs can achieve Bayes-optimal test error for classification while obtaining (nearly) zero-training error under the lazy training regime. For this purpose, we unify three interrelated concepts of overparameterization, benign overfitting, and the Lipschitz constant of DNNs. Our results indicate that interpolating with smoother functions leads to better generalization. Furthermore, we investigate the special case where interpolating smooth ground-truth functions is performed by DNNs under the Neural Tangent Kernel (NTK) regime for generalization. Our result demonstrates that the generalization error converges to a constant order that only depends on label noise and initialization noise, which theoretically verifies benign overfitting. Our analysis provides a tight lower bound on the normalized margin under non-smooth activation ",
    "path": "papers/23/05/2305.19377.json",
    "total_tokens": 1139,
    "translated_title": "惰性训练下深层神经网络中的良性过拟合",
    "translated_abstract": "本文研究了采用ReLU激活函数的超参数化深度神经网络，并证明了在数据分布良好分离时，采用惰性训练方法可以使DNN分类实现贝叶斯最优测试误差，同时获得（几乎）零训练误差。为此，我们统一了超参数化、良性过拟合和DNN Lipschitz常数这三个相互关联的概念。研究结果表明，插值平滑可以带来更好的泛化性能。此外，我们还探讨了神经切向核法进行插值平滑的情况，证明了泛化误差收敛到仅取决于标签噪声和初始化噪声的常数阶，理论上证实了良性过拟合现象。我们的分析还提供了非平滑激活函数下归一化边缘的严格下界。",
    "tldr": "本论文证明了在惰性训练期间，超参数化深度神经网络存在良性过拟合现象，可在数据分布良好分离时实现贝叶斯最优测试误差。通过插值平滑可以带来更好的泛化性能。",
    "en_tdlr": "This paper proves the existence of benign overfitting in over-parameterized deep neural networks (DNNs) with ReLU activation functions under lazy training regime, which can achieve Bayes-optimal test error while obtaining (nearly) zero-training error when the data distribution is well-separated. Interpolating with smoother functions leads to better generalization. Results under the Neural Tangent Kernel (NTK) regime demonstrate that the generalization error converges to a constant order, theoretically verifying benign overfitting."
}