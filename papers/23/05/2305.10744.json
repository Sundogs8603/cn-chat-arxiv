{
    "title": "Online Resource Allocation in Episodic Markov Decision Processes. (arXiv:2305.10744v1 [cs.DS])",
    "abstract": "This paper studies a long-term resource allocation problem over multiple periods where each period requires a multi-stage decision-making process. We formulate the problem as an online resource allocation problem in an episodic finite-horizon Markov decision process with unknown non-stationary transitions and stochastic non-stationary reward and resource consumption functions for each episode. We provide an equivalent online linear programming reformulation based on occupancy measures, for which we develop an online mirror descent algorithm. Our online dual mirror descent algorithm for resource allocation deals with uncertainties and errors in estimating the true feasible set, which is of independent interest. We prove that under stochastic reward and resource consumption functions, the expected regret of the online mirror descent algorithm is bounded by $O(\\rho^{-1}{H^{3/2}}S\\sqrt{AT})$ where $\\rho\\in(0,1)$ is the budget parameter, $H$ is the length of the horizon, $S$ and $A$ are the",
    "link": "http://arxiv.org/abs/2305.10744",
    "context": "Title: Online Resource Allocation in Episodic Markov Decision Processes. (arXiv:2305.10744v1 [cs.DS])\nAbstract: This paper studies a long-term resource allocation problem over multiple periods where each period requires a multi-stage decision-making process. We formulate the problem as an online resource allocation problem in an episodic finite-horizon Markov decision process with unknown non-stationary transitions and stochastic non-stationary reward and resource consumption functions for each episode. We provide an equivalent online linear programming reformulation based on occupancy measures, for which we develop an online mirror descent algorithm. Our online dual mirror descent algorithm for resource allocation deals with uncertainties and errors in estimating the true feasible set, which is of independent interest. We prove that under stochastic reward and resource consumption functions, the expected regret of the online mirror descent algorithm is bounded by $O(\\rho^{-1}{H^{3/2}}S\\sqrt{AT})$ where $\\rho\\in(0,1)$ is the budget parameter, $H$ is the length of the horizon, $S$ and $A$ are the",
    "path": "papers/23/05/2305.10744.json",
    "total_tokens": 978,
    "translated_title": "面向剧集式马尔可夫决策过程的在线资源分配问题",
    "translated_abstract": "本文研究了一个长期的资源分配问题，它需要在多个时间段内进行多阶段的决策过程。我们将这个问题形式化为一个剧集式有限时间段的马尔可夫决策过程中的在线资源分配问题，其中转换和奖励以及每一次的资源消耗函数都是非定态的。我们提供了一种等效的在线线性规划重构方法，基于占有度量，为此我们开发了一种在线镜像下降算法。我们的资源分配在线镜像下降算法处理了在估算真实可行集时的不确定性和误差，这是相对独立的。我们证明，对于随机奖励和资源消耗函数，在线镜像下降算法的期望遗憾受到界限约束，其界限受到 $O(\\rho^{-1}{H^{3/2}}S\\sqrt{AT})$ 的约束，其中 $\\rho\\in(0,1)$ 是预算参数，$H$ 是地平线长度，$S$ 和 $A$ 是. . .",
    "tldr": "本文将长期资源分配问题形式化为剧集式MDP模型，提出在面临转换和奖励特性不确定的情况下进行在线资源分配问题的解决方案。该方案基于占有度量提供在线镜像下降算法，其期望遗憾受到界限约束 $O(\\rho^{-1}{H^{3/2}}S\\sqrt{AT})$ ."
}