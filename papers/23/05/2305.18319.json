{
    "title": "Automated Feedback Generation for a Chemistry Database and Abstracting Exercise. (arXiv:2305.18319v1 [cs.CL])",
    "abstract": "Timely feedback is an important part of teaching and learning. Here we describe how a readily available neural network transformer (machine-learning) model (BERT) can be used to give feedback on the structure of the response to an abstracting exercise where students are asked to summarise the contents of a published article after finding it from a publication database. The dataset contained 207 submissions from two consecutive years of the course, summarising a total of 21 different papers from the primary literature. The model was pre-trained using an available dataset (approx. 15,000 samples) and then fine-tuned on 80% of the submitted dataset. This fine tuning was seen to be important. The sentences in the student submissions are characterised into three classes - background, technique and observation - which allows a comparison of how each submission is structured. Comparing the structure of the students' abstract a large collection of those from the PubMed database shows that stud",
    "link": "http://arxiv.org/abs/2305.18319",
    "context": "Title: Automated Feedback Generation for a Chemistry Database and Abstracting Exercise. (arXiv:2305.18319v1 [cs.CL])\nAbstract: Timely feedback is an important part of teaching and learning. Here we describe how a readily available neural network transformer (machine-learning) model (BERT) can be used to give feedback on the structure of the response to an abstracting exercise where students are asked to summarise the contents of a published article after finding it from a publication database. The dataset contained 207 submissions from two consecutive years of the course, summarising a total of 21 different papers from the primary literature. The model was pre-trained using an available dataset (approx. 15,000 samples) and then fine-tuned on 80% of the submitted dataset. This fine tuning was seen to be important. The sentences in the student submissions are characterised into three classes - background, technique and observation - which allows a comparison of how each submission is structured. Comparing the structure of the students' abstract a large collection of those from the PubMed database shows that stud",
    "path": "papers/23/05/2305.18319.json",
    "total_tokens": 880,
    "translated_title": "化学数据库和摘要练习的自动生成反馈",
    "translated_abstract": "及时的反馈对于教学和学习来说非常重要。本文描述了如何利用现成的神经网络变换器（机器学习）模型（BERT）来对摘要练习的答案结构进行反馈。在这项任务中，要求学生们从出版数据库中找到一篇文章并对其内容进行总结。数据集包括207个提交品，总共摘要了21篇来自主要文献的文章。该模型使用一个现有的数据集（约15,000个样本）进行了预训练，然后在80%的已提交数据集上进行了微调，这一步骤被认为是重要的。学生提交的句子被归为三类——背景、技术和观察——这使得可以将每个提交品的结构进行比较。通过比较学生的摘要结构以及来自PubMed数据库的大量摘要，可以发现...",
    "tldr": "本研究利用BERT模型，对化学数据库中摘要练习的答案结构进行反馈，该模型在学生提交的句子中将其归为三类，即背景、技术和观察，提供了一种方法对学生作业进行自动化反馈。",
    "en_tdlr": "This paper describes how to use a neural network transformer model, BERT, to provide feedback on the structure of abstracting exercise answers for a chemistry database. The model categorizes student sentences into three classes - background, technique and observation - and provides a method of automated feedback on student assignments."
}