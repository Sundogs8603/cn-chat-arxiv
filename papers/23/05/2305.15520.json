{
    "title": "Exploring Automatically Perturbed Natural Language Explanations in Relation Extraction. (arXiv:2305.15520v1 [cs.CL])",
    "abstract": "Previous research has demonstrated that natural language explanations provide valuable inductive biases that guide models, thereby improving the generalization ability and data efficiency. In this paper, we undertake a systematic examination of the effectiveness of these explanations. Remarkably, we find that corrupted explanations with diminished inductive biases can achieve competitive or superior performance compared to the original explanations. Our findings furnish novel insights into the characteristics of natural language explanations in the following ways: (1) the impact of explanations varies across different training styles and datasets, with previously believed improvements primarily observed in frozen language models. (2) While previous research has attributed the effect of explanations solely to their inductive biases, our study shows that the effect persists even when the explanations are completely corrupted. We propose that the main effect is due to the provision of add",
    "link": "http://arxiv.org/abs/2305.15520",
    "context": "Title: Exploring Automatically Perturbed Natural Language Explanations in Relation Extraction. (arXiv:2305.15520v1 [cs.CL])\nAbstract: Previous research has demonstrated that natural language explanations provide valuable inductive biases that guide models, thereby improving the generalization ability and data efficiency. In this paper, we undertake a systematic examination of the effectiveness of these explanations. Remarkably, we find that corrupted explanations with diminished inductive biases can achieve competitive or superior performance compared to the original explanations. Our findings furnish novel insights into the characteristics of natural language explanations in the following ways: (1) the impact of explanations varies across different training styles and datasets, with previously believed improvements primarily observed in frozen language models. (2) While previous research has attributed the effect of explanations solely to their inductive biases, our study shows that the effect persists even when the explanations are completely corrupted. We propose that the main effect is due to the provision of add",
    "path": "papers/23/05/2305.15520.json",
    "total_tokens": 819,
    "translated_title": "探索在关系抽取中自动扰动自然语言解释的有效性",
    "translated_abstract": "先前的研究已经表明，自然语言解释为模型提供重要的归纳偏好，从而提高了其泛化能力和数据效率。本文系统地研究了这些解释的有效性。引人注目的是，我们发现带有降低归纳偏好的扰动解释可以达到与原始解释相当或更好的性能。我们的发现为自然语言解释的特征提供了新的见解：（1）解释的影响因训练风格和数据集而异，以前认为的改进主要在冻结语言模型中观察到。（2）尽管以前的研究将解释的影响归因于它们的归纳偏好，但我们的研究表明，即使完全扰动解释，效果仍然存在。我们认为主要影响是提供了额外的信息和方面。",
    "tldr": "本文研究了自然语言解释在关系抽取中的有效性，发现扰动解释也能够达到相当甚至更好的效果，这提供了新的见解。",
    "en_tdlr": "This paper systematically examines the effectiveness of natural language explanations in relation extraction and finds that corrupted explanations with reduced inductive biases can achieve competitive or even better performance. This provides novel insights into the characteristics of natural language explanations."
}