{
    "title": "Federated Ensemble-Directed Offline Reinforcement Learning. (arXiv:2305.03097v1 [cs.LG])",
    "abstract": "We consider the problem of federated offline reinforcement learning (RL), a scenario under which distributed learning agents must collaboratively learn a high-quality control policy only using small pre-collected datasets generated according to different unknown behavior policies. Naively combining a standard offline RL approach with a standard federated learning approach to solve this problem can lead to poorly performing policies. In response, we develop the Federated Ensemble-Directed Offline Reinforcement Learning Algorithm (FEDORA), which distills the collective wisdom of the clients using an ensemble learning approach. We develop the FEDORA codebase to utilize distributed compute resources on a federated learning platform. We show that FEDORA significantly outperforms other approaches, including offline RL over the combined data pool, in various complex continuous control environments and real world datasets. Finally, we demonstrate the performance of FEDORA in the real-world on ",
    "link": "http://arxiv.org/abs/2305.03097",
    "context": "Title: Federated Ensemble-Directed Offline Reinforcement Learning. (arXiv:2305.03097v1 [cs.LG])\nAbstract: We consider the problem of federated offline reinforcement learning (RL), a scenario under which distributed learning agents must collaboratively learn a high-quality control policy only using small pre-collected datasets generated according to different unknown behavior policies. Naively combining a standard offline RL approach with a standard federated learning approach to solve this problem can lead to poorly performing policies. In response, we develop the Federated Ensemble-Directed Offline Reinforcement Learning Algorithm (FEDORA), which distills the collective wisdom of the clients using an ensemble learning approach. We develop the FEDORA codebase to utilize distributed compute resources on a federated learning platform. We show that FEDORA significantly outperforms other approaches, including offline RL over the combined data pool, in various complex continuous control environments and real world datasets. Finally, we demonstrate the performance of FEDORA in the real-world on ",
    "path": "papers/23/05/2305.03097.json",
    "total_tokens": 940,
    "translated_title": "联邦集成指导的离线强化学习算法",
    "translated_abstract": "本文考虑了联邦离线强化学习问题。在这一场景下，分布式的学习代理必须仅使用由不同的未知的行为策略生成的小型预先收集的数据集协作学习出高质量的控制策略。笨拙地将标准离线强化学习方法与标准联邦学习方法组合来解决这个问题可能会导致表现不佳的策略。我们因此设计了Federated Ensemble-Directed Offline Reinforcement Learning Algorithm (FEDORA)，通过集成学习方法提炼客户群体的集体智慧。我们开发了FEDORA代码库，利用联邦学习平台上的分布式计算资源。我们证明了FEDORA在各种复杂的连续控制环境和真实世界数据集中均显著优于其他方法，包括在合并的数据汇总中进行离线强化学习。最后，我们展示了FEDORA在真实世界中的表现。",
    "tldr": "本文开发了一种名为FEDORA的联邦集成指导的离线强化学习算法，通过集成学习方法提炼客户群体的集体智慧，显著优于其他方法，包括在合并的数据汇总中进行离线强化学习，在各种复杂的连续控制环境和真实世界数据集中进行了实验。",
    "en_tdlr": "This paper develops a federated ensemble-directed offline reinforcement learning algorithm called FEDORA, which distills the collective wisdom of the clients using an ensemble learning approach and significantly outperforms other methods, including offline RL over the combined data pool, in various complex continuous control environments and real world datasets."
}