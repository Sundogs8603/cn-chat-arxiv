{
    "title": "From Adversarial Arms Race to Model-centric Evaluation: Motivating a Unified Automatic Robustness Evaluation Framework. (arXiv:2305.18503v1 [cs.CL])",
    "abstract": "Textual adversarial attacks can discover models' weaknesses by adding semantic-preserved but misleading perturbations to the inputs. The long-lasting adversarial attack-and-defense arms race in Natural Language Processing (NLP) is algorithm-centric, providing valuable techniques for automatic robustness evaluation. However, the existing practice of robustness evaluation may exhibit issues of incomprehensive evaluation, impractical evaluation protocol, and invalid adversarial samples. In this paper, we aim to set up a unified automatic robustness evaluation framework, shifting towards model-centric evaluation to further exploit the advantages of adversarial attacks. To address the above challenges, we first determine robustness evaluation dimensions based on model capabilities and specify the reasonable algorithm to generate adversarial samples for each dimension. Then we establish the evaluation protocol, including evaluation settings and metrics, under realistic demands. Finally, we u",
    "link": "http://arxiv.org/abs/2305.18503",
    "context": "Title: From Adversarial Arms Race to Model-centric Evaluation: Motivating a Unified Automatic Robustness Evaluation Framework. (arXiv:2305.18503v1 [cs.CL])\nAbstract: Textual adversarial attacks can discover models' weaknesses by adding semantic-preserved but misleading perturbations to the inputs. The long-lasting adversarial attack-and-defense arms race in Natural Language Processing (NLP) is algorithm-centric, providing valuable techniques for automatic robustness evaluation. However, the existing practice of robustness evaluation may exhibit issues of incomprehensive evaluation, impractical evaluation protocol, and invalid adversarial samples. In this paper, we aim to set up a unified automatic robustness evaluation framework, shifting towards model-centric evaluation to further exploit the advantages of adversarial attacks. To address the above challenges, we first determine robustness evaluation dimensions based on model capabilities and specify the reasonable algorithm to generate adversarial samples for each dimension. Then we establish the evaluation protocol, including evaluation settings and metrics, under realistic demands. Finally, we u",
    "path": "papers/23/05/2305.18503.json",
    "total_tokens": 977,
    "translated_title": "从对抗性竞争到以模型为中心的评价：推动一个统一的自动鲁棒性评估框架",
    "translated_abstract": "文本对抗攻击可以通过向输入添加语义保留但具有误导性的扰动来发现模型的弱点。自然语言处理（NLP）中长期的对抗性攻击和防御竞争是算法中心的，为自动鲁棒性评估提供了有价值的技术。但是，现有的鲁棒性评估实践可能存在评估不全面、评估协议不实用以及对抗样本失效等问题。本文旨在建立一个统一的自动鲁棒性评估框架，向以模型为中心的评估转型，进一步利用对抗攻击的优势。为了解决上述挑战，我们首先基于模型能力确定鲁棒性评估维度，并针对每个维度指定合理的算法来生成对抗样本。然后，我们建立了评估协议，包括评估设置和指标，以满足实际需求。最后，我们利用该框架在多个数据集上进行实验，并探讨了其在不同场景下的适用性和局限性。",
    "tldr": "本文旨在建立一个统一的自动鲁棒性评估框架，向以模型为中心的评估转型，利用对抗攻击的优势。研究者们根据模型能力确定鲁棒性评估维度，并针对每个维度指定合理的算法来生成对抗样本。",
    "en_tdlr": "This paper aims to establish a unified automatic robustness evaluation framework, shifting towards model-centric evaluation and exploiting the advantages of adversarial attacks. Researchers determine robustness evaluation dimensions based on model capabilities and specify the reasonable algorithm to generate adversarial samples for each dimension."
}