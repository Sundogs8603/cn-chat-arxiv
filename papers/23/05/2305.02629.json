{
    "title": "Integrating Psychometrics and Computing Perspectives on Bias and Fairness in Affective Computing: A Case Study of Automated Video Interviews. (arXiv:2305.02629v1 [cs.LG])",
    "abstract": "We provide a psychometric-grounded exposition of bias and fairness as applied to a typical machine learning pipeline for affective computing. We expand on an interpersonal communication framework to elucidate how to identify sources of bias that may arise in the process of inferring human emotions and other psychological constructs from observed behavior. Various methods and metrics for measuring fairness and bias are discussed along with pertinent implications within the United States legal context. We illustrate how to measure some types of bias and fairness in a case study involving automatic personality and hireability inference from multimodal data collected in video interviews for mock job applications. We encourage affective computing researchers and practitioners to encapsulate bias and fairness in their research processes and products and to consider their role, agency, and responsibility in promoting equitable and just systems.",
    "link": "http://arxiv.org/abs/2305.02629",
    "context": "Title: Integrating Psychometrics and Computing Perspectives on Bias and Fairness in Affective Computing: A Case Study of Automated Video Interviews. (arXiv:2305.02629v1 [cs.LG])\nAbstract: We provide a psychometric-grounded exposition of bias and fairness as applied to a typical machine learning pipeline for affective computing. We expand on an interpersonal communication framework to elucidate how to identify sources of bias that may arise in the process of inferring human emotions and other psychological constructs from observed behavior. Various methods and metrics for measuring fairness and bias are discussed along with pertinent implications within the United States legal context. We illustrate how to measure some types of bias and fairness in a case study involving automatic personality and hireability inference from multimodal data collected in video interviews for mock job applications. We encourage affective computing researchers and practitioners to encapsulate bias and fairness in their research processes and products and to consider their role, agency, and responsibility in promoting equitable and just systems.",
    "path": "papers/23/05/2305.02629.json",
    "total_tokens": 968,
    "translated_title": "将心理测量学和计算视角整合于情感计算中的偏见和公平性：自动视频面试的案例研究",
    "translated_abstract": "本文提供了一个基于心理测量学的对偏见和公平性在情感计算的机器学习流程中的应用的论述。我们扩展了人际交流框架，阐明了如何确定在推断人类情感和其他心理结构时可能出现的偏见来源。讨论了衡量公平性和偏见的各种方法和指标，以及它们在美国法律背景下的相关影响。我们通过一个案例研究来说明如何在自动视频面试中从多模态数据中测量一些类型的偏见和公平性，以推断应聘者的人格和可雇佣性。我们鼓励情感计算研究人员和从业者将偏见和公平性纳入研究过程和产品中，并考虑他们在促进公平合理系统方面的作用、代理和责任。",
    "tldr": "本研究基于心理测量学提供了情感计算中偏见和公平性的一个例子。我们讨论了在美国法律背景下衡量公平性和偏见的各种方法和指标，并在自动视频面试中从多模态数据中测量了一些类型的偏见和公平性。我们鼓励情感计算研究人员和从业者将偏见和公平性纳入研究过程和产品中，并考虑他们在促进公平合理系统方面的作用、代理和责任。",
    "en_tdlr": "This study provides an example of bias and fairness in affective computing based on psychometrics. We discuss various methods and metrics for measuring fairness and bias in the context of US law, and measure some types of bias and fairness in automatic video interviews. We encourage researchers and practitioners to consider their role in promoting equitable and just systems."
}