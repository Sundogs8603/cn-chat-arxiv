{
    "title": "Can Fair Federated Learning reduce the need for Personalisation?. (arXiv:2305.02728v1 [cs.LG])",
    "abstract": "Federated Learning (FL) enables training ML models on edge clients without sharing data. However, the federated model's performance on local data varies, disincentivising the participation of clients who benefit little from FL. Fair FL reduces accuracy disparity by focusing on clients with higher losses while personalisation locally fine-tunes the model. Personalisation provides a participation incentive when an FL model underperforms relative to one trained locally. For situations where the federated model provides a lower accuracy than a model trained entirely locally by a client, personalisation improves the accuracy of the pre-trained federated weights to be similar to or exceed those of the local client model. This paper evaluates two Fair FL (FFL) algorithms as starting points for personalisation. Our results show that FFL provides no benefit to relative performance in a language task and may double the number of underperforming clients for an image task. Instead, we propose Pers",
    "link": "http://arxiv.org/abs/2305.02728",
    "context": "Title: Can Fair Federated Learning reduce the need for Personalisation?. (arXiv:2305.02728v1 [cs.LG])\nAbstract: Federated Learning (FL) enables training ML models on edge clients without sharing data. However, the federated model's performance on local data varies, disincentivising the participation of clients who benefit little from FL. Fair FL reduces accuracy disparity by focusing on clients with higher losses while personalisation locally fine-tunes the model. Personalisation provides a participation incentive when an FL model underperforms relative to one trained locally. For situations where the federated model provides a lower accuracy than a model trained entirely locally by a client, personalisation improves the accuracy of the pre-trained federated weights to be similar to or exceed those of the local client model. This paper evaluates two Fair FL (FFL) algorithms as starting points for personalisation. Our results show that FFL provides no benefit to relative performance in a language task and may double the number of underperforming clients for an image task. Instead, we propose Pers",
    "path": "papers/23/05/2305.02728.json",
    "total_tokens": 968,
    "translated_title": "公正联邦学习可以减少个性化需求吗？",
    "translated_abstract": "联邦学习（FL）使得在不共享数据的情况下在边缘客户端上训练ML模型成为可能。然而，联邦模型在本地数据上的性能会有所差异，这会造成对于没有从FL中受益的客户端参与的不利影响。公正FL通过关注损失更高的客户端来减少准确性差异，而个性化调整则在本地微调模型。在FL模型相对于本地训练模型表现较差时，个性化提供了参与激励。本文评估了两种公正FL算法作为个性化的起点。结果表明，基于公正FL的方法对于语言任务并没有产生相对性能优势，并且在图像任务中可能会使表现不佳的客户端数量增加一倍。相反，我们提出了个性化公正联邦学习（PFL），并展示了在语言和图像任务中减少准确性差异的同时，在FL模型相对于本地模型表现较差时提供了参与激励。",
    "tldr": "本文探索了联邦学习的公正性与个性化需求的关系，提出个性化公正联邦学习（PFL）算法，能够解决准确性差异以及在FL模型表现不佳时提供参与激励的问题。",
    "en_tdlr": "This paper explores the relationship between fairness and personalization in federated learning, proposes a Personalised Fair Federated Learning (PFL) algorithm, which can solve the problem of accuracy disparity and provide participation incentives when the federated model underperforms relative to local models."
}