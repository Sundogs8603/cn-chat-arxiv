{
    "title": "Neural Foundations of Mental Simulation: Future Prediction of Latent Representations on Dynamic Scenes. (arXiv:2305.11772v1 [cs.AI])",
    "abstract": "Humans and animals have a rich and flexible understanding of the physical world, which enables them to infer the underlying dynamical trajectories of objects and events, plausible future states, and use that to plan and anticipate the consequences of actions. However, the neural mechanisms underlying these computations are unclear. We combine a goal-driven modeling approach with dense neurophysiological data and high-throughput human behavioral readouts to directly impinge on this question. Specifically, we construct and evaluate several classes of sensory-cognitive networks to predict the future state of rich, ethologically-relevant environments, ranging from self-supervised end-to-end models with pixel-wise or object-centric objectives, to models that future predict in the latent space of purely static image-based or dynamic video-based pretrained foundation models. We find strong differentiation across these model classes in their ability to predict neural and behavioral data both w",
    "link": "http://arxiv.org/abs/2305.11772",
    "context": "Title: Neural Foundations of Mental Simulation: Future Prediction of Latent Representations on Dynamic Scenes. (arXiv:2305.11772v1 [cs.AI])\nAbstract: Humans and animals have a rich and flexible understanding of the physical world, which enables them to infer the underlying dynamical trajectories of objects and events, plausible future states, and use that to plan and anticipate the consequences of actions. However, the neural mechanisms underlying these computations are unclear. We combine a goal-driven modeling approach with dense neurophysiological data and high-throughput human behavioral readouts to directly impinge on this question. Specifically, we construct and evaluate several classes of sensory-cognitive networks to predict the future state of rich, ethologically-relevant environments, ranging from self-supervised end-to-end models with pixel-wise or object-centric objectives, to models that future predict in the latent space of purely static image-based or dynamic video-based pretrained foundation models. We find strong differentiation across these model classes in their ability to predict neural and behavioral data both w",
    "path": "papers/23/05/2305.11772.json",
    "total_tokens": 973,
    "translated_title": "神经基础中的心理模拟：预测动态场景中的潜在表现",
    "translated_abstract": "人和动物对物理世界有着丰富而灵活的理解，能够推断出事件的基本动态轨迹，预测未来可能出现的状态，并利用这些信息规划和预测行为的后果。然而，这些计算背后的神经机制尚不清楚。本文采用目标驱动的建模方法，结合密集的神经生理学数据和高通量的人类行为输出来探究这个问题。具体来说，我们构建和评估了几类感知-认知网络来预测丰富、具有行为学意义的环境的未来状态，从像素或面向对象目标的自主监督端到端模型，到将纯静态基于图像或动态视频的预训练基础模型的潜在空间进行未来预测的模型。我们发现这些模型类别在其预测神经和行为数据的能力上有很强的差异，无论在其培训领域内或外，这种差异反映了效率、普遍性和可解释性之间的基本权衡。",
    "tldr": "本研究探究了人类和动物如何推断物理世界的基本动态轨迹以及如何预测未来可能出现的状态，并评估了几类感知-认知网络的预测能力，发现在效率、普遍性和可解释性间存在权衡。",
    "en_tdlr": "This study investigates how humans and animals infer the fundamental dynamical trajectories of the physical world and predict possible future states, evaluates the predictive ability of several classes of sensory-cognitive networks, and finds a trade-off between efficiency, generalization, and interpretability."
}