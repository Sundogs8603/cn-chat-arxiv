{
    "title": "Uncertainty Quantification in Deep Neural Networks through Statistical Inference on Latent Space. (arXiv:2305.10840v1 [cs.LG])",
    "abstract": "Uncertainty-quantification methods are applied to estimate the confidence of deep-neural-networks classifiers over their predictions. However, most widely used methods are known to be overconfident. We address this problem by developing an algorithm that exploits the latent-space representation of data points fed into the network, to assess the accuracy of their prediction. Using the latent-space representation generated by the fraction of training set that the network classifies correctly, we build a statistical model that is able to capture the likelihood of a given prediction. We show on a synthetic dataset that commonly used methods are mostly overconfident. Overconfidence occurs also for predictions made on data points that are outside the distribution that generated the training data. In contrast, our method can detect such out-of-distribution data points as inaccurately predicted, thus aiding in the automatic detection of outliers.",
    "link": "http://arxiv.org/abs/2305.10840",
    "context": "Title: Uncertainty Quantification in Deep Neural Networks through Statistical Inference on Latent Space. (arXiv:2305.10840v1 [cs.LG])\nAbstract: Uncertainty-quantification methods are applied to estimate the confidence of deep-neural-networks classifiers over their predictions. However, most widely used methods are known to be overconfident. We address this problem by developing an algorithm that exploits the latent-space representation of data points fed into the network, to assess the accuracy of their prediction. Using the latent-space representation generated by the fraction of training set that the network classifies correctly, we build a statistical model that is able to capture the likelihood of a given prediction. We show on a synthetic dataset that commonly used methods are mostly overconfident. Overconfidence occurs also for predictions made on data points that are outside the distribution that generated the training data. In contrast, our method can detect such out-of-distribution data points as inaccurately predicted, thus aiding in the automatic detection of outliers.",
    "path": "papers/23/05/2305.10840.json",
    "total_tokens": 783,
    "translated_title": "基于潜在空间的统计推断方法在深度神经网络中的不确定性量化",
    "translated_abstract": "本文提出了一种基于潜在空间表征的算法，通过对深度神经网络所处理数据点的精确度进行评估，来解决当前广泛使用的评估方法“过于自信”的问题。具体地，我们使用了网络能够正确分类的部分训练集所生成的潜在空间表示，并以此建立了能够捕捉预测结果可能性的统计模型。在合成数据集上的测试表明，常用方法一般存在“过于自信”的问题，甚至对训练数据生成分布之外的数据点依然如此。与之相比，我们的方法可以发现精度欠佳的数据点，因此对于异常值的自动侦测是有帮助的。",
    "tldr": "本研究提出了一种利用深度神经网络潜在空间表征进行不确定性量化的方法，该方法可以检测数据点的精确度并帮助自动侦测异常值。",
    "en_tdlr": "This study proposes an uncertainty quantification method for deep neural networks based on latent space representation, which can detect the accuracy of data points and aid in automatic detection of outliers."
}