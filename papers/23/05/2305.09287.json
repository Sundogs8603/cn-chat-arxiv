{
    "title": "AdversarialWord Dilution as Text Data Augmentation in Low-Resource Regime. (arXiv:2305.09287v1 [cs.CL])",
    "abstract": "Data augmentation is widely used in text classification, especially in the low-resource regime where a few examples for each class are available during training. Despite the success, generating data augmentations as hard positive examples that may increase their effectiveness is under-explored. This paper proposes an Adversarial Word Dilution (AWD) method that can generate hard positive examples as text data augmentations to train the low-resource text classification model efficiently. Our idea of augmenting the text data is to dilute the embedding of strong positive words by weighted mixing with unknown-word embedding, making the augmented inputs hard to be recognized as positive by the classification model. We adversarially learn the dilution weights through a constrained min-max optimization process with the guidance of the labels. Empirical studies on three benchmark datasets show that AWD can generate more effective data augmentations and outperform the state-of-the-art text data ",
    "link": "http://arxiv.org/abs/2305.09287",
    "context": "Title: AdversarialWord Dilution as Text Data Augmentation in Low-Resource Regime. (arXiv:2305.09287v1 [cs.CL])\nAbstract: Data augmentation is widely used in text classification, especially in the low-resource regime where a few examples for each class are available during training. Despite the success, generating data augmentations as hard positive examples that may increase their effectiveness is under-explored. This paper proposes an Adversarial Word Dilution (AWD) method that can generate hard positive examples as text data augmentations to train the low-resource text classification model efficiently. Our idea of augmenting the text data is to dilute the embedding of strong positive words by weighted mixing with unknown-word embedding, making the augmented inputs hard to be recognized as positive by the classification model. We adversarially learn the dilution weights through a constrained min-max optimization process with the guidance of the labels. Empirical studies on three benchmark datasets show that AWD can generate more effective data augmentations and outperform the state-of-the-art text data ",
    "path": "papers/23/05/2305.09287.json",
    "total_tokens": 958,
    "translated_title": "对抗性词汇稀释作为低资源情况下的文本数据增强方法",
    "translated_abstract": "在低资源情况下，数据增强被广泛应用于文本分类中。然而，如何生成硬正例用作数据增强的有效方法却仍有待探索。本文提出了一种对抗性词汇稀释方法，该方法能够生成硬正例作为文本数据增强，从而有效地训练低资源文本分类模型。",
    "tldr": "本文提出了一种对抗性词汇稀释方法，用于作为低资源情况下的文本数据增强方法，能够生成硬正例以有效地训练文本分类模型。",
    "en_tdlr": "This paper proposes an adversarial word dilution method as text data augmentation for low-resource text classification, which generates hard positive examples to effectively train classification model and outperforms state-of-the-art methods on three benchmark datasets."
}