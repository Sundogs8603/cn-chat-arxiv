{
    "title": "Variational Bayesian Framework for Advanced Image Generation with Domain-Related Variables. (arXiv:2305.13872v1 [cs.CV])",
    "abstract": "Deep generative models (DGMs) and their conditional counterparts provide a powerful ability for general-purpose generative modeling of data distributions. However, it remains challenging for existing methods to address advanced conditional generative problems without annotations, which can enable multiple applications like image-to-image translation and image editing. We present a unified Bayesian framework for such problems, which introduces an inference stage on latent variables within the learning process. In particular, we propose a variational Bayesian image translation network (VBITN) that enables multiple image translation and editing tasks. Comprehensive experiments show the effectiveness of our method on unsupervised image-to-image translation, and demonstrate the novel advanced capabilities for semantic editing and mixed domain translation.",
    "link": "http://arxiv.org/abs/2305.13872",
    "context": "Title: Variational Bayesian Framework for Advanced Image Generation with Domain-Related Variables. (arXiv:2305.13872v1 [cs.CV])\nAbstract: Deep generative models (DGMs) and their conditional counterparts provide a powerful ability for general-purpose generative modeling of data distributions. However, it remains challenging for existing methods to address advanced conditional generative problems without annotations, which can enable multiple applications like image-to-image translation and image editing. We present a unified Bayesian framework for such problems, which introduces an inference stage on latent variables within the learning process. In particular, we propose a variational Bayesian image translation network (VBITN) that enables multiple image translation and editing tasks. Comprehensive experiments show the effectiveness of our method on unsupervised image-to-image translation, and demonstrate the novel advanced capabilities for semantic editing and mixed domain translation.",
    "path": "papers/23/05/2305.13872.json",
    "total_tokens": 821,
    "translated_title": "具有领域相关变量的高级图像生成的变分贝叶斯框架",
    "translated_abstract": "深度生成模型（DGM）以及它们的条件表征为数据分布提供了强大的通用生成建模能力。然而，缺乏注释的情况下，现有方法仍然难以解决高级条件生成问题，而这种方法能够实现多种应用，如图像到图像的转换和图像编辑。我们提出了一个统一的贝叶斯框架，引入了学习过程中潜在变量的推断阶段，特别是我们提出了一个变分贝叶斯图像翻译网络（VBITN），它可以实现多种图像翻译和编辑任务。全面的实验展示了我们方法在无监督图像到图像转换上的有效性，并展示了语义编辑和混合域翻译的创新高级能力。",
    "tldr": "本文提出一种统一的贝叶斯框架，利用变分推断技术实现高级条件生成问题，并提出了一种变分贝叶斯图像翻译网络（VBITN），可以实现无监督图像到图像转换、语义编辑和混合域翻译等任务。"
}