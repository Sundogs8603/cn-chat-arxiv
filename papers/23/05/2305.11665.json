{
    "title": "A Generic Performance Model for Deep Learning in a Distributed Environment. (arXiv:2305.11665v1 [cs.DC])",
    "abstract": "Performance modelling of a deep learning application is essential to improve and quantify the efficiency of the model framework. However, existing performance models are mostly case-specific, with limited capability for the new deep learning frameworks/applications. In this paper, we propose a generic performance model of an application in a distributed environment with a generic expression of the application execution time that considers the influence of both intrinsic factors/operations (e.g. algorithmic parameters/internal operations) and extrinsic scaling factors (e.g. the number of processors, data chunks and batch size). We formulate it as a global optimization problem and solve it using regularization on a cost function and differential evolution algorithm to find the best-fit values of the constants in the generic expression to match the experimentally determined computation time. We have evaluated the proposed model on three deep learning frameworks (i.e., TensorFlow, MXnet, a",
    "link": "http://arxiv.org/abs/2305.11665",
    "context": "Title: A Generic Performance Model for Deep Learning in a Distributed Environment. (arXiv:2305.11665v1 [cs.DC])\nAbstract: Performance modelling of a deep learning application is essential to improve and quantify the efficiency of the model framework. However, existing performance models are mostly case-specific, with limited capability for the new deep learning frameworks/applications. In this paper, we propose a generic performance model of an application in a distributed environment with a generic expression of the application execution time that considers the influence of both intrinsic factors/operations (e.g. algorithmic parameters/internal operations) and extrinsic scaling factors (e.g. the number of processors, data chunks and batch size). We formulate it as a global optimization problem and solve it using regularization on a cost function and differential evolution algorithm to find the best-fit values of the constants in the generic expression to match the experimentally determined computation time. We have evaluated the proposed model on three deep learning frameworks (i.e., TensorFlow, MXnet, a",
    "path": "papers/23/05/2305.11665.json",
    "total_tokens": 934,
    "translated_title": "一种深度学习分布式环境下的通用性能模型",
    "translated_abstract": "对深度学习应用的性能建模对于改进和量化模型框架的效率至关重要。然而，现有的性能模型大多都是特定于案例的，对于新的深度学习框架/应用程序的能力有限。本文提出了一种分布式环境下应用程序的通用性能模型，其中包含了应用程序执行时间的通用表达式，考虑了内在因素/操作（例如算法参数/内部操作）和外在扩展因素（例如处理器数量、数据块和批次大小）的影响。我们将其制定为全局优化问题，并使用正则化成本函数和差分进化算法来解决，以找到最佳拟合常数值的通用表达式，以匹配实验确定的计算时间。我们已经在三个深度学习框架（TensorFlow、MXnet、PyTorch）上评估了所提出的模型。",
    "tldr": "本文提出了一个适用于分布式环境下各类深度学习应用程序的通用性能模型，可解决现有性能模型特定于案例的问题，并将内在与外在因素考虑在内。通过正则化和差分进化算法，找到最佳拟合常数值的通用表达式，以提高和量化模型框架的效率。",
    "en_tdlr": "This paper proposes a generic performance model for various deep learning applications in a distributed environment. The model addresses the issue of existing performance models being case-specific and takes into account both intrinsic and extrinsic factors. Regularization and differential evolution algorithm are used to find the best-fit constants for the generic expression of application execution time, improving and quantifying model framework efficiency. The proposed model was evaluated on TensorFlow, MXnet, and PyTorch frameworks."
}