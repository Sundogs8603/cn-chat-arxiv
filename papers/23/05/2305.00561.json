{
    "title": "Model-free Motion Planning of Autonomous Agents for Complex Tasks in Partially Observable Environments. (arXiv:2305.00561v1 [cs.AI])",
    "abstract": "Motion planning of autonomous agents in partially known environments with incomplete information is a challenging problem, particularly for complex tasks. This paper proposes a model-free reinforcement learning approach to address this problem. We formulate motion planning as a probabilistic-labeled partially observable Markov decision process (PL-POMDP) problem and use linear temporal logic (LTL) to express the complex task. The LTL formula is then converted to a limit-deterministic generalized B\\\"uchi automaton (LDGBA). The problem is redefined as finding an optimal policy on the product of PL-POMDP with LDGBA based on model-checking techniques to satisfy the complex task. We implement deep Q learning with long short-term memory (LSTM) to process the observation history and task recognition. Our contributions include the proposed method, the utilization of LTL and LDGBA, and the LSTM-enhanced deep Q learning. We demonstrate the applicability of the proposed method by conducting simul",
    "link": "http://arxiv.org/abs/2305.00561",
    "context": "Title: Model-free Motion Planning of Autonomous Agents for Complex Tasks in Partially Observable Environments. (arXiv:2305.00561v1 [cs.AI])\nAbstract: Motion planning of autonomous agents in partially known environments with incomplete information is a challenging problem, particularly for complex tasks. This paper proposes a model-free reinforcement learning approach to address this problem. We formulate motion planning as a probabilistic-labeled partially observable Markov decision process (PL-POMDP) problem and use linear temporal logic (LTL) to express the complex task. The LTL formula is then converted to a limit-deterministic generalized B\\\"uchi automaton (LDGBA). The problem is redefined as finding an optimal policy on the product of PL-POMDP with LDGBA based on model-checking techniques to satisfy the complex task. We implement deep Q learning with long short-term memory (LSTM) to process the observation history and task recognition. Our contributions include the proposed method, the utilization of LTL and LDGBA, and the LSTM-enhanced deep Q learning. We demonstrate the applicability of the proposed method by conducting simul",
    "path": "papers/23/05/2305.00561.json",
    "total_tokens": 963,
    "translated_title": "面向部分可观察环境中复杂任务的自主智能体无模型运动规划",
    "translated_abstract": "在部分已知且信息不完备的环境中，自主智能体的运动规划是一个具有挑战性的问题，尤其是对于复杂任务而言。本文提出了一种无模型强化学习方法来解决这个问题。我们将运动规划建模为一个概率标记的部分可观测马尔可夫决策过程（PL-POMDP）问题，并使用线性时态逻辑（LTL）来表达复杂任务。然后将LTL公式转换为极限确定性广义布氏自动机（LDGBA）。基于模型检测技术，将问题重新定义为在PL-POMDP与LDGBA的乘积上找到最优策略以满足复杂任务。我们实现了深度Q学习与长短时记忆网络（LSTM）来处理观察历史和任务识别。我们的贡献包括提出的方法、LTL和LDGBA的利用以及LSTM增强的深度Q学习。我们通过进行仿真实验展示了所提出方法的适用性。",
    "tldr": "本文提出了一种无模型强化学习方法，利用线性时态逻辑和极限确定性广义布氏自动机来解决部分可观察环境下自主智能体复杂任务的运动规划，该方法利用深度Q学习与LSTM增强技术。",
    "en_tdlr": "This paper proposes a model-free reinforcement learning method that uses linear temporal logic and limit-deterministic generalized B\\\"uchi automaton to solve the motion planning problem of autonomous agents for complex tasks in partially observable environments. The proposed method utilizes deep Q learning with LSTM enhancement."
}