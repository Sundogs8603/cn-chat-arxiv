{
    "title": "Introduction to dynamical mean-field theory of generic random neural networks. (arXiv:2305.08459v2 [cond-mat.dis-nn] UPDATED)",
    "abstract": "Dynamical mean-field theory is a powerful physics tool used to analyze the typical behavior of neural networks, where neurons can be recurrently connected, or multiple layers of neurons can be stacked. However, it is not easy for beginners to access the essence of this tool and the underlying physics. Here, we give a pedagogical introduction of this method in a particular example of generic random neural networks, where neurons are randomly and fully connected by correlated synapses and therefore the network exhibits rich emergent collective dynamics. We also review related past and recent important works applying this tool. In addition, a physically transparent and alternative method, namely the dynamical cavity method, is also introduced to derive exactly the same results. The numerical implementation of solving the integro-differential mean-field equations is also detailed, with an illustration of exploring the fluctuation dissipation theorem.",
    "link": "http://arxiv.org/abs/2305.08459",
    "context": "Title: Introduction to dynamical mean-field theory of generic random neural networks. (arXiv:2305.08459v2 [cond-mat.dis-nn] UPDATED)\nAbstract: Dynamical mean-field theory is a powerful physics tool used to analyze the typical behavior of neural networks, where neurons can be recurrently connected, or multiple layers of neurons can be stacked. However, it is not easy for beginners to access the essence of this tool and the underlying physics. Here, we give a pedagogical introduction of this method in a particular example of generic random neural networks, where neurons are randomly and fully connected by correlated synapses and therefore the network exhibits rich emergent collective dynamics. We also review related past and recent important works applying this tool. In addition, a physically transparent and alternative method, namely the dynamical cavity method, is also introduced to derive exactly the same results. The numerical implementation of solving the integro-differential mean-field equations is also detailed, with an illustration of exploring the fluctuation dissipation theorem.",
    "path": "papers/23/05/2305.08459.json",
    "total_tokens": 861,
    "translated_title": "通用随机神经网络动力学平均场理论入门",
    "translated_abstract": "动力学平均场理论是一种强大的物理工具，用于分析神经网络的典型行为，其中神经元可以循环连接，或者可以堆叠多层神经元。然而，对于初学者来说，很难接触到此工具和基础物理的精髓。在这里，我们以通用随机神经网络为例，给出了这种方法的教育性介绍，在此类网络中，神经元通过相关突触随机而完全连接，因此网络表现出丰富的集体动态。我们还回顾了应用此工具的相关过去和最近重要作品。此外，还介绍了一种物理上透明的替代方法，即动态腔方法，该方法导出了完全相同的结果。详细介绍了求解积分微分平均场方程的数值实现，以及探索波动耗散定理的说明。",
    "tldr": "本文针对通用随机神经网络，介绍了动力学平均场理论及其数值实现方法，并引入了一种物理上透明的替代方法，以探索网络的集体动态。",
    "en_tdlr": "This paper provides a pedagogical introduction to the dynamical mean-field theory for generic random neural networks, and discusses its numerical implementation as well as an alternative method. The paper aims to analyze the emergent collective dynamics of the network and review related past and recent works applying this tool."
}