{
    "title": "Stochastic Modified Equations and Dynamics of Dropout Algorithm. (arXiv:2305.15850v1 [cs.LG])",
    "abstract": "Dropout is a widely utilized regularization technique in the training of neural networks, nevertheless, its underlying mechanism and its impact on achieving good generalization abilities remain poorly understood. In this work, we derive the stochastic modified equations for analyzing the dynamics of dropout, where its discrete iteration process is approximated by a class of stochastic differential equations. In order to investigate the underlying mechanism by which dropout facilitates the identification of flatter minima, we study the noise structure of the derived stochastic modified equation for dropout. By drawing upon the structural resemblance between the Hessian and covariance through several intuitive approximations, we empirically demonstrate the universal presence of the inverse variance-flatness relation and the Hessian-variance relation, throughout the training process of dropout. These theoretical and empirical findings make a substantial contribution to our understanding o",
    "link": "http://arxiv.org/abs/2305.15850",
    "context": "Title: Stochastic Modified Equations and Dynamics of Dropout Algorithm. (arXiv:2305.15850v1 [cs.LG])\nAbstract: Dropout is a widely utilized regularization technique in the training of neural networks, nevertheless, its underlying mechanism and its impact on achieving good generalization abilities remain poorly understood. In this work, we derive the stochastic modified equations for analyzing the dynamics of dropout, where its discrete iteration process is approximated by a class of stochastic differential equations. In order to investigate the underlying mechanism by which dropout facilitates the identification of flatter minima, we study the noise structure of the derived stochastic modified equation for dropout. By drawing upon the structural resemblance between the Hessian and covariance through several intuitive approximations, we empirically demonstrate the universal presence of the inverse variance-flatness relation and the Hessian-variance relation, throughout the training process of dropout. These theoretical and empirical findings make a substantial contribution to our understanding o",
    "path": "papers/23/05/2305.15850.json",
    "total_tokens": 890,
    "translated_title": "随机修改方程和Dropout算法的动力学",
    "translated_abstract": "Dropout是神经网络训练中广泛使用的正则化技术之一，然而它的潜在机制以及对于实现良好泛化能力的影响仍不甚了解。在本文中，我们推导出了用于分析Dropout动态的随机修改方程，其中它的离散迭代过程被一类随机微分方程所近似。为了研究Dropout如何促进识别更平坦的极值点的潜在机制，我们研究了所推导出的Dropout随机修改方程的噪声结构。通过利用海森矩阵和协方差之间的结构相似性进行几个直观的近似，我们实证了逆方差-平坦关系和海森矩阵-方差关系贯穿于Dropout的整个训练过程中。这些理论和实证发现对于我们深入理解Dropout有所贡献。",
    "tldr": "本文中，通过推导出用于分析Dropout动态的随机修改方程，研究了Dropout如何促进识别更平坦的极值点的潜在机制，并实证了逆方差-平坦关系和海森矩阵-方差关系贯穿于Dropout的整个训练过程中。",
    "en_tdlr": "This paper derives stochastic modified equations for analyzing the dynamics of dropout, studies its impact on the identification of flatter minima, demonstrates the presence of the inverse variance-flatness relation and the Hessian-variance relation throughout the training process, contributing to a deeper understanding of the regularization technique."
}