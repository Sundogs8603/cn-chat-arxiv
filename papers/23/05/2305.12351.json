{
    "title": "Are Your Explanations Reliable? Investigating the Stability of LIME in Explaining Text Classifiers by Marrying XAI and Adversarial Attack. (arXiv:2305.12351v2 [cs.LG] UPDATED)",
    "abstract": "LIME has emerged as one of the most commonly referenced tools in explainable AI (XAI) frameworks that is integrated into critical machine learning applications--e.g., healthcare and finance. However, its stability remains little explored, especially in the context of text data, due to the unique text-space constraints. To address these challenges, in this paper, we first evaluate the inherent instability of LIME on text data to establish a baseline, and then propose a novel algorithm XAIFooler to perturb text inputs and manipulate explanations that casts investigation on the stability of LIME as a text perturbation optimization problem. XAIFooler conforms to the constraints to preserve text semantics and original prediction with small perturbations, and introduces Rank-biased Overlap (RBO) as a key part to guide the optimization of XAIFooler that satisfies all the requirements for explanation similarity measure. Extensive experiments on real-world text datasets demonstrate that XAIFool",
    "link": "http://arxiv.org/abs/2305.12351",
    "context": "Title: Are Your Explanations Reliable? Investigating the Stability of LIME in Explaining Text Classifiers by Marrying XAI and Adversarial Attack. (arXiv:2305.12351v2 [cs.LG] UPDATED)\nAbstract: LIME has emerged as one of the most commonly referenced tools in explainable AI (XAI) frameworks that is integrated into critical machine learning applications--e.g., healthcare and finance. However, its stability remains little explored, especially in the context of text data, due to the unique text-space constraints. To address these challenges, in this paper, we first evaluate the inherent instability of LIME on text data to establish a baseline, and then propose a novel algorithm XAIFooler to perturb text inputs and manipulate explanations that casts investigation on the stability of LIME as a text perturbation optimization problem. XAIFooler conforms to the constraints to preserve text semantics and original prediction with small perturbations, and introduces Rank-biased Overlap (RBO) as a key part to guide the optimization of XAIFooler that satisfies all the requirements for explanation similarity measure. Extensive experiments on real-world text datasets demonstrate that XAIFool",
    "path": "papers/23/05/2305.12351.json",
    "total_tokens": 947,
    "translated_title": "你的解释可靠吗？通过融合XAI和对抗攻击来探究LIME在解释文本分类器中的稳定性",
    "translated_abstract": "LIME已经成为可解释AI（XAI）框架中最常被引用的工具之一，在关键的机器学习应用中集成其中，例如医疗保健和金融。然而，尤其是在文本数据的背景下，其稳定性仍然鲜为人知，这是由于文本空间的独特约束。为了解决这些挑战，本文首先评估了LIME在文本数据上固有的不稳定性，以建立基准，然后提出了一种新颖的算法XAIFooler，以扰动文本输入并操纵解释，将LIME的稳定性作为一个文本扰动优化问题进行研究。XAIFooler符合约束条件，保留了文本语义和原始预测，并引入了Rank-biased Overlap（RBO）作为XAIFooler优化的关键部分，以满足所有解释相似度测量的要求。在真实的文本数据集上进行了大量实验，证明了XAIFool的可行性。",
    "tldr": "本文研究了解释AI中常用的工具LIME在文本数据上的稳定性，并提出了一种新算法XAIFooler来扰动文本输入并操纵解释，以解决这个问题。",
    "en_tdlr": "This paper investigates the stability of the commonly used tool LIME in explainable AI (XAI) on text data, and proposes a novel algorithm, XAIFooler, to perturb text inputs and manipulate explanations to address this issue."
}