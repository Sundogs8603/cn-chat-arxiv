{
    "title": "Cross-Entropy Estimators for Sequential Experiment Design with Reinforcement Learning. (arXiv:2305.18435v1 [cs.LG])",
    "abstract": "Reinforcement learning can effectively learn amortised design policies for designing sequences of experiments. However, current methods rely on contrastive estimators of expected information gain, which require an exponential number of contrastive samples to achieve an unbiased estimation. We propose an alternative lower bound estimator, based on the cross-entropy of the joint model distribution and a flexible proposal distribution. This proposal distribution approximates the true posterior of the model parameters given the experimental history and the design policy. Our estimator requires no contrastive samples, can achieve more accurate estimates of high information gains, allows learning of superior design policies, and is compatible with implicit probabilistic models. We assess our algorithm's performance in various tasks, including continuous and discrete designs and explicit and implicit likelihoods.",
    "link": "http://arxiv.org/abs/2305.18435",
    "context": "Title: Cross-Entropy Estimators for Sequential Experiment Design with Reinforcement Learning. (arXiv:2305.18435v1 [cs.LG])\nAbstract: Reinforcement learning can effectively learn amortised design policies for designing sequences of experiments. However, current methods rely on contrastive estimators of expected information gain, which require an exponential number of contrastive samples to achieve an unbiased estimation. We propose an alternative lower bound estimator, based on the cross-entropy of the joint model distribution and a flexible proposal distribution. This proposal distribution approximates the true posterior of the model parameters given the experimental history and the design policy. Our estimator requires no contrastive samples, can achieve more accurate estimates of high information gains, allows learning of superior design policies, and is compatible with implicit probabilistic models. We assess our algorithm's performance in various tasks, including continuous and discrete designs and explicit and implicit likelihoods.",
    "path": "papers/23/05/2305.18435.json",
    "total_tokens": 824,
    "translated_title": "用于强化学习顺序实验设计的交叉熵估计器",
    "translated_abstract": "强化学习可有效地学习设计实验序列的摊销设计策略。然而，当前的方法依赖于期望信息增益的对比估计器，需要指数级的对比样本来达到无偏估计。我们提出了一种基于联合模型分布和灵活的提议分布的备选下界估计器。提议分布逼近模型参数在实验历史和设计策略条件下给定的真实后验分布。我们的估计器不需要对比样本，可以实现更准确的高信息增益估计，允许学习更优秀的设计策略，并且与隐式概率模型兼容。我们评估了我们算法在各种任务中的性能，包括连续和离散设计以及显式和隐式可能性。",
    "tldr": "这篇论文提出了一个基于交叉熵估计器的备选下界估计方法，这个方法不需要对比样本，可以更精确地估计高信息增益，允许学习更优秀的设计策略，并且与隐式概率模型兼容。"
}