{
    "title": "WebIE: Faithful and Robust Information Extraction on the Web. (arXiv:2305.14293v2 [cs.CL] UPDATED)",
    "abstract": "Extracting structured and grounded fact triples from raw text is a fundamental task in Information Extraction (IE). Existing IE datasets are typically collected from Wikipedia articles, using hyperlinks to link entities to the Wikidata knowledge base. However, models trained only on Wikipedia have limitations when applied to web domains, which often contain noisy text or text that does not have any factual information. We present WebIE, the first large-scale, entity-linked closed IE dataset consisting of 1.6M sentences automatically collected from the English Common Crawl corpus. WebIE also includes negative examples, i.e. sentences without fact triples, to better reflect the data on the web. We annotate ~21K triples from WebIE through crowdsourcing and introduce mWebIE, a translation of the annotated set in four other languages: French, Spanish, Portuguese, and Hindi. We evaluate the in-domain, out-of-domain, and zero-shot cross-lingual performance of generative IE models and find mod",
    "link": "http://arxiv.org/abs/2305.14293",
    "context": "Title: WebIE: Faithful and Robust Information Extraction on the Web. (arXiv:2305.14293v2 [cs.CL] UPDATED)\nAbstract: Extracting structured and grounded fact triples from raw text is a fundamental task in Information Extraction (IE). Existing IE datasets are typically collected from Wikipedia articles, using hyperlinks to link entities to the Wikidata knowledge base. However, models trained only on Wikipedia have limitations when applied to web domains, which often contain noisy text or text that does not have any factual information. We present WebIE, the first large-scale, entity-linked closed IE dataset consisting of 1.6M sentences automatically collected from the English Common Crawl corpus. WebIE also includes negative examples, i.e. sentences without fact triples, to better reflect the data on the web. We annotate ~21K triples from WebIE through crowdsourcing and introduce mWebIE, a translation of the annotated set in four other languages: French, Spanish, Portuguese, and Hindi. We evaluate the in-domain, out-of-domain, and zero-shot cross-lingual performance of generative IE models and find mod",
    "path": "papers/23/05/2305.14293.json",
    "total_tokens": 911,
    "translated_title": "WebIE：基于网络的信息提取的准确性和鲁棒性",
    "translated_abstract": "从原始文本中提取结构化和有实际意义的三元组是信息提取（IE）中的一项基本任务。现有的IE数据集通常是从维基百科文章中收集的，使用超链接将实体与Wikidata知识库链接起来。然而，仅在维基百科上训练的模型在应用于网页领域时存在局限性，因为这些领域经常包含嘈杂或没有任何实际信息的文本。本文提出WebIE，这是第一个大规模的、实体关联闭合的IE数据集，包含从英语Common Crawl语料库中自动收集的160万个句子。WebIE还包括负例，即没有事实三元组的句子，以更好地反映网络数据。我们通过众包对WebIE进行了大约21000个三元组的注释，并介绍了mWebIE，这是注释集在法语、西班牙语、葡萄牙语和印地语中的翻译。我们评估了生成式IE模型在域内、域外和零样本跨语言性能，并发现模型在WebIE数据集上表现出良好",
    "tldr": "WebIE提出了一个大规模的、实体关联闭合的IE数据集，以更好地反映网络数据，并评估了生成式IE模型的性能，表现出良好的结果。"
}