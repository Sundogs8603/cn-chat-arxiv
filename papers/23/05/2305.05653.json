{
    "title": "Could AI be the Great Filter? What Astrobiology can Teach the Intelligence Community about Anthropogenic Risks. (arXiv:2305.05653v1 [cs.CY])",
    "abstract": "Where is everybody? This phrase distills the foreboding of what has come to be known as the Fermi Paradox - the disquieting idea that, if extraterrestrial life is probable in the Universe, then why have we not encountered it? This conundrum has puzzled scholars for decades, and many hypotheses have been proposed suggesting both naturalistic and sociological explanations. One intriguing hypothesis is known as the Great Filter, which suggests that some event required for the emergence of intelligent life is extremely unlikely, hence the cosmic silence. A logically equivalent version of this hypothesis and one that should give us pause - suggests that some catastrophic event is likely to occur that prevents life's expansion throughout the cosmos. This could be a naturally occurring event, or more disconcertingly, something that intelligent beings do to themselves that leads to their own extinction. From an intelligence perspective, framing global catastrophic risk (particularly risks of",
    "link": "http://arxiv.org/abs/2305.05653",
    "context": "Title: Could AI be the Great Filter? What Astrobiology can Teach the Intelligence Community about Anthropogenic Risks. (arXiv:2305.05653v1 [cs.CY])\nAbstract: Where is everybody? This phrase distills the foreboding of what has come to be known as the Fermi Paradox - the disquieting idea that, if extraterrestrial life is probable in the Universe, then why have we not encountered it? This conundrum has puzzled scholars for decades, and many hypotheses have been proposed suggesting both naturalistic and sociological explanations. One intriguing hypothesis is known as the Great Filter, which suggests that some event required for the emergence of intelligent life is extremely unlikely, hence the cosmic silence. A logically equivalent version of this hypothesis and one that should give us pause - suggests that some catastrophic event is likely to occur that prevents life's expansion throughout the cosmos. This could be a naturally occurring event, or more disconcertingly, something that intelligent beings do to themselves that leads to their own extinction. From an intelligence perspective, framing global catastrophic risk (particularly risks of",
    "path": "papers/23/05/2305.05653.json",
    "total_tokens": 1181,
    "translated_title": "AI 是否可能成为大过滤器？天体生物学能够告诉情报界关于人类起源风险的东西",
    "translated_abstract": "“人在哪里？”这个问题涵盖了费米悖论中的不安，即如果宇宙中存在概率较高的外星生命，则为什么我们还没有遇到它？这个谜团已经困扰学者数十年，提出了许多假说，既包括自然的也包括社会学的解释。其中一个有趣的假设被称为大过滤器，它建议生命进化所需的某些事件极不可能发生，因此宇宙保持着沉默。这个和它逻辑等价的假设应该使我们停下来思考——某些灾难性事件很可能会发生，从而阻止了生命在宇宙中的扩张。这可能是一种自然事件，或更令人不安的是，是智慧生物为自己引发的导致自己灭绝的事件。从情报角度来看，在天体生物学的背景下构建全球灾难性风险（特别是人类起源风险）有助于我们更好地理解宇宙中智慧生命可能的稀有性以及可能存在的种类。在本文中，我们探讨人工智能（AI）的发展如何揭示大过滤器可能在我们前面的重要提示。我们认为，通过认识到 AI 在大规模全球风险中的潜在作用，情报界可以获得有价值的洞察力，减少存在风险。",
    "tldr": "本文探讨了人工智能对大过滤器假设的可能性以及如何在天体生物学的背景下理解全球灾难性风险，并指出了情报界通过认识到AI在大规模全球风险中的潜在作用获得有价值洞察的必要性。",
    "en_tdlr": "This paper explores the possibility of AI in the Great Filter hypothesis and how understanding global catastrophic risks in the context of astrobiology can provide valuable insights for the Intelligence Community. It also highlights the importance of recognizing AI's potential role in large-scale global risks."
}