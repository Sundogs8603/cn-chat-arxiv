{
    "title": "CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers. (arXiv:2305.17455v2 [cs.CV] UPDATED)",
    "abstract": "Recent vision-language models have achieved tremendous progress far beyond what we ever expected. However, their computational costs are also dramatically growing with rapid development, especially for the large models. It makes model acceleration exceedingly critical in a scenario of limited resources. Although extensively studied for unimodal models, the acceleration for multimodal models, especially the vision-language Transformers, is relatively under-explored. To pursue more efficient and accessible vision-language Transformers, this paper introduces \\textbf{Cross}-\\textbf{G}uided \\textbf{E}nsemble of \\textbf{T}okens (\\textbf{\\emph{CrossGET}}), a universal acceleration framework for vision-language Transformers. This framework adaptively combines tokens through real-time, cross-modal guidance, thereby achieving substantial acceleration while keeping high performance. \\textit{CrossGET} has two key innovations: 1) \\textit{Cross-Guided Matching and Ensemble}. \\textit{CrossGET} incorp",
    "link": "http://arxiv.org/abs/2305.17455",
    "context": "Title: CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers. (arXiv:2305.17455v2 [cs.CV] UPDATED)\nAbstract: Recent vision-language models have achieved tremendous progress far beyond what we ever expected. However, their computational costs are also dramatically growing with rapid development, especially for the large models. It makes model acceleration exceedingly critical in a scenario of limited resources. Although extensively studied for unimodal models, the acceleration for multimodal models, especially the vision-language Transformers, is relatively under-explored. To pursue more efficient and accessible vision-language Transformers, this paper introduces \\textbf{Cross}-\\textbf{G}uided \\textbf{E}nsemble of \\textbf{T}okens (\\textbf{\\emph{CrossGET}}), a universal acceleration framework for vision-language Transformers. This framework adaptively combines tokens through real-time, cross-modal guidance, thereby achieving substantial acceleration while keeping high performance. \\textit{CrossGET} has two key innovations: 1) \\textit{Cross-Guided Matching and Ensemble}. \\textit{CrossGET} incorp",
    "path": "papers/23/05/2305.17455.json",
    "total_tokens": 881,
    "translated_title": "CrossGET: 跨导引的令牌集合用于加速视觉-语言转换器",
    "translated_abstract": "最近，视觉-语言模型取得了巨大的进展，远远超出了我们的预期。然而，它们的计算成本随着快速发展也在大幅增长，特别是对于大型模型而言。在资源有限的情况下，模型加速变得极其关键。尽管对于单模态模型进行了广泛的研究，但对于多模态模型，特别是视觉-语言转换器的加速仍然相对不足。为了追求更高效和可访问的视觉-语言转换器，本文介绍了一种称为CrossGET的跨导引令牌集合的通用加速框架。该框架通过实时的跨模态导引，自适应地结合令牌，从而实现大幅加速而保持高性能。CrossGET的两个关键创新点是：1) 跨导引匹配和集合。CrossGET将跨导引的匹配和集合应用到视觉-语言转换器中，",
    "tldr": "CrossGET是一种通用的加速框架，通过实时的跨模态导引，自适应地结合令牌，实现了视觉-语言转换器的大幅加速。",
    "en_tdlr": "CrossGET is a universal acceleration framework for vision-language Transformers that achieves substantial acceleration by adaptively combining tokens through real-time, cross-modal guidance."
}