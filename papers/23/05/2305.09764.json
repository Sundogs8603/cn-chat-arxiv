{
    "title": "Application-Agnostic Language Modeling for On-Device ASR. (arXiv:2305.09764v1 [cs.CL])",
    "abstract": "On-device automatic speech recognition systems face several challenges compared to server-based systems. They have to meet stricter constraints in terms of speed, disk size and memory while maintaining the same accuracy. Often they have to serve several applications with different distributions at once, such as communicating with a virtual assistant and speech-to-text. The simplest solution to serve multiple applications is to build application-specific (language) models, but this leads to an increase in memory. Therefore, we explore different data- and architecture-driven language modeling approaches to build a single application-agnostic model. We propose two novel feed-forward architectures that find an optimal trade off between different on-device constraints. In comparison to the application-specific solution, one of our novel approaches reduces the disk size by half, while maintaining speed and accuracy of the original model.",
    "link": "http://arxiv.org/abs/2305.09764",
    "context": "Title: Application-Agnostic Language Modeling for On-Device ASR. (arXiv:2305.09764v1 [cs.CL])\nAbstract: On-device automatic speech recognition systems face several challenges compared to server-based systems. They have to meet stricter constraints in terms of speed, disk size and memory while maintaining the same accuracy. Often they have to serve several applications with different distributions at once, such as communicating with a virtual assistant and speech-to-text. The simplest solution to serve multiple applications is to build application-specific (language) models, but this leads to an increase in memory. Therefore, we explore different data- and architecture-driven language modeling approaches to build a single application-agnostic model. We propose two novel feed-forward architectures that find an optimal trade off between different on-device constraints. In comparison to the application-specific solution, one of our novel approaches reduces the disk size by half, while maintaining speed and accuracy of the original model.",
    "path": "papers/23/05/2305.09764.json",
    "total_tokens": 836,
    "translated_title": "设备上无应用语言建模指导的自动语音识别",
    "translated_abstract": "与基于服务器的系统相比，设备上的自动语音识别系统面临着许多挑战。它们必须在保持相同准确性的同时满足更严格的速度、磁盘大小和内存的限制。通常，它们必须为多个具有不同分配的应用程序提供服务，例如与虚拟助手通信和语音转文本等。为了为多个应用程序提供服务，最简单的解决方案是构建特定于应用程序的(语言)模型，但这会增加内存。因此，我们探索了不同的数据和架构驱动的语言建模方法，以构建一个单一的无应用指导的模型。我们提出了两种新的前向体系结构，可以找到在不同设备限制之间的最佳折衷。与特定于应用程序的解决方案相比，我们的一种新方法将磁盘大小减半，同时保持了原模型的速度和准确性。",
    "tldr": "本文提出了两种新的前向体系结构用于无应用指导的语言建模，以帮助设备上的自动语音识别系统克服速度、磁盘和内存等限制。",
    "en_tdlr": "This paper proposes two new feed-forward architectures for application-agnostic language modeling to help on-device automatic speech recognition systems overcome constraints such as speed, disk size, and memory."
}