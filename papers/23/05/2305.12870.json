{
    "title": "Lion: Adversarial Distillation of Proprietary Large Language Models. (arXiv:2305.12870v2 [cs.CL] UPDATED)",
    "abstract": "The practice of transferring knowledge from a sophisticated, proprietary large language model (LLM) to a compact, open-source LLM has garnered considerable attention. Previous works have focused on a unidirectional knowledge distillation way by aligning the responses of the student model with those of the teacher model to a set of instructions. Nevertheless, they overlooked the possibility of incorporating any reciprocal \"feedback\"--identifying challenging instructions where the student model's performance falls short--to boost the student model's proficiency iteratively. To this end, we propose a novel adversarial distillation framework for a more efficient knowledge transfer. Leveraging the versatile role adaptability of LLMs, we prompt the teacher model to identify \"hard\" instructions and generate new \"hard\" instructions for the student model, creating a three-stage adversarial loop of imitation, discrimination, and generation. By applying this adversarial framework, we successfully",
    "link": "http://arxiv.org/abs/2305.12870",
    "context": "Title: Lion: Adversarial Distillation of Proprietary Large Language Models. (arXiv:2305.12870v2 [cs.CL] UPDATED)\nAbstract: The practice of transferring knowledge from a sophisticated, proprietary large language model (LLM) to a compact, open-source LLM has garnered considerable attention. Previous works have focused on a unidirectional knowledge distillation way by aligning the responses of the student model with those of the teacher model to a set of instructions. Nevertheless, they overlooked the possibility of incorporating any reciprocal \"feedback\"--identifying challenging instructions where the student model's performance falls short--to boost the student model's proficiency iteratively. To this end, we propose a novel adversarial distillation framework for a more efficient knowledge transfer. Leveraging the versatile role adaptability of LLMs, we prompt the teacher model to identify \"hard\" instructions and generate new \"hard\" instructions for the student model, creating a three-stage adversarial loop of imitation, discrimination, and generation. By applying this adversarial framework, we successfully",
    "path": "papers/23/05/2305.12870.json",
    "total_tokens": 992,
    "translated_title": "Lion: 私有大型语言模型对抗性蒸馏",
    "translated_abstract": "从复杂的私有大型语言模型（LLM）向紧凑的开源LLM转移知识的做法引起了广泛关注。先前的研究主要集中在通过将学生模型的响应与教师模型的响应对齐到一组指令来进行单向知识蒸馏。然而，他们忽视了在扩展学习中学生模型表现不佳的挑战性指令的可能性，从而可以迭代地提高学生模型的能力。为此，我们提出了一种新颖的对抗性蒸馏框架，以实现更高效的知识转移。通过利用LLMs的多功能角色适应性，我们促使教师模型识别“难”的指令并为学生模型生成新的“难”的指令，创建了一个三阶段的对抗循环：模仿、辨别和生成。通过应用这种对抗性框架，我们成功地实现了知识的迁移。",
    "tldr": "本研究介绍了一种名为Lion的对抗性蒸馏框架，用于实现从复杂的私有大型语言模型向紧凑的开源模型的知识转移。该框架通过迭代地提高学生模型的能力，利用教师模型的适应性来生成更具挑战性的指令，并通过模仿、辨别和生成的三阶段对抗循环来促进知识的迁移。",
    "en_tdlr": "This study presents a novel adversarial distillation framework called Lion for transferring knowledge from a sophisticated, proprietary large language model (LLM) to a compact, open-source LLM. By leveraging the adaptive nature of LLMs, Lion iteratively improves the student model by generating challenging instructions identified by the teacher model, using a three-stage adversarial loop of imitation, discrimination, and generation."
}