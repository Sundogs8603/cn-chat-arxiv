{
    "title": "Quantifying Association Capabilities of Large Language Models and Its Implications on Privacy Leakage",
    "abstract": "The advancement of large language models (LLMs) brings notable improvements across various applications, while simultaneously raising concerns about potential private data exposure. One notable capability of LLMs is their ability to form associations between different pieces of information, but this raises concerns when it comes to personally identifiable information (PII). This paper delves into the association capabilities of language models, aiming to uncover the factors that influence their proficiency in associating information. Our study reveals that as models scale up, their capacity to associate entities/information intensifies, particularly when target pairs demonstrate shorter co-occurrence distances or higher co-occurrence frequencies. However, there is a distinct performance gap when associating commonsense knowledge versus PII, with the latter showing lower accuracy. Despite the proportion of accurately predicted PII being relatively small, LLMs still demonstrate the capab",
    "link": "https://arxiv.org/abs/2305.12707",
    "context": "Title: Quantifying Association Capabilities of Large Language Models and Its Implications on Privacy Leakage\nAbstract: The advancement of large language models (LLMs) brings notable improvements across various applications, while simultaneously raising concerns about potential private data exposure. One notable capability of LLMs is their ability to form associations between different pieces of information, but this raises concerns when it comes to personally identifiable information (PII). This paper delves into the association capabilities of language models, aiming to uncover the factors that influence their proficiency in associating information. Our study reveals that as models scale up, their capacity to associate entities/information intensifies, particularly when target pairs demonstrate shorter co-occurrence distances or higher co-occurrence frequencies. However, there is a distinct performance gap when associating commonsense knowledge versus PII, with the latter showing lower accuracy. Despite the proportion of accurately predicted PII being relatively small, LLMs still demonstrate the capab",
    "path": "papers/23/05/2305.12707.json",
    "total_tokens": 925,
    "translated_title": "量化大型语言模型的关联能力及其对隐私泄露的影响",
    "translated_abstract": "大型语言模型（LLMs）的进步在各种应用中带来了显著的改进，与此同时也引发了对潜在私人数据泄露的担忧。其中一个显著的LLMs能力是它们能够形成不同信息之间的关联，但这在涉及个人可识别信息（PII）时引发了担忧。本文深入研究了语言模型的关联能力，旨在揭示影响其关联信息能力的因素。我们的研究发现，随着模型规模的扩大，其关联实体/信息的能力增强，特别是当目标对展示更短的共现距离或更高的共现频率时。然而，在关联常识知识与PII方面存在明显的性能差距，后者的准确性较低。尽管准确预测PII的比例相对较小，但LLMs仍然表现出了这种能力。",
    "tldr": "本文研究了大型语言模型的关联能力，并揭示了其对隐私泄露的影响。研究发现，随着模型规模的增加，模型在关联实体/信息方面的能力增强。然而，与常识知识相比，模型在关联个人可识别信息方面的准确性较低。",
    "en_tdlr": "This paper explores the association capabilities of large language models (LLMs) and reveals their implications on privacy leakage. The study finds that as models scale up, their ability to associate entities/information intensifies. However, there is a lower accuracy when it comes to associating personally identifiable information (PII) compared to commonsense knowledge."
}