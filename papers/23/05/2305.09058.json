{
    "title": "Private Training Set Inspection in MLaaS. (arXiv:2305.09058v1 [cs.LG])",
    "abstract": "Machine Learning as a Service (MLaaS) is a popular cloud-based solution for customers who aim to use an ML model but lack training data, computation resources, or expertise in ML. In this case, the training datasets are typically a private possession of the ML or data companies and are inaccessible to the customers, but the customers still need an approach to confirm that the training datasets meet their expectations and fulfil regulatory measures like fairness. However, no existing work addresses the above customers' concerns. This work is the first attempt to solve this problem, taking data origin as an entry point. We first define origin membership measurement and based on this, we then define diversity and fairness metrics to address customers' concerns. We then propose a strategy to estimate the values of these two metrics in the inaccessible training dataset, combining shadow training techniques from membership inference and an efficient featurization scheme in multiple instance ",
    "link": "http://arxiv.org/abs/2305.09058",
    "context": "Title: Private Training Set Inspection in MLaaS. (arXiv:2305.09058v1 [cs.LG])\nAbstract: Machine Learning as a Service (MLaaS) is a popular cloud-based solution for customers who aim to use an ML model but lack training data, computation resources, or expertise in ML. In this case, the training datasets are typically a private possession of the ML or data companies and are inaccessible to the customers, but the customers still need an approach to confirm that the training datasets meet their expectations and fulfil regulatory measures like fairness. However, no existing work addresses the above customers' concerns. This work is the first attempt to solve this problem, taking data origin as an entry point. We first define origin membership measurement and based on this, we then define diversity and fairness metrics to address customers' concerns. We then propose a strategy to estimate the values of these two metrics in the inaccessible training dataset, combining shadow training techniques from membership inference and an efficient featurization scheme in multiple instance ",
    "path": "papers/23/05/2305.09058.json",
    "total_tokens": 810,
    "translated_title": "MLaaS中的私有训练集检查",
    "translated_abstract": "机器学习作为一种服务（MLaaS）是一种流行的基于云的解决方案，适用于希望使用ML模型但缺乏训练数据、计算资源或ML专业知识的客户。然而，对于客户而言，训练数据集通常是ML或数据公司的私有财产，无法访问，但客户仍然需要一种方法来确认训练数据集符合他们的期望并符合公平性等监管要求。本文第一次尝试从数据来源入手解决这一问题，并提出了基于起源成员关系度量的多样性和公平度量标准，结合成员推断中的阴影训练技术和高效特征化方案，提出了一种策略来估算无法访问的训练数据集中这两个度量标准的值。",
    "tldr": "本文尝试解决MLaaS中私有训练集检查的问题，提出了基于起源成员关系度量的多样性和公平度量标准，并给出了估算值的策略。",
    "en_tdlr": "This paper proposes a solution to the problem of private training set inspection in MLaaS by defining diversity and fairness metrics based on origin membership measurement, and provides a strategy for estimating these metrics' values in the inaccessible training dataset."
}