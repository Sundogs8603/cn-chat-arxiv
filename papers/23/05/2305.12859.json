{
    "title": "Flying Adversarial Patches: Manipulating the Behavior of Deep Learning-based Autonomous Multirotors. (arXiv:2305.12859v2 [cs.RO] UPDATED)",
    "abstract": "Autonomous flying robots, e.g. multirotors, often rely on a neural network that makes predictions based on a camera image. These deep learning (DL) models can compute surprising results if applied to input images outside the training domain. Adversarial attacks exploit this fault, for example, by computing small images, so-called adversarial patches, that can be placed in the environment to manipulate the neural network's prediction. We introduce flying adversarial patches, where an image is mounted on another flying robot and therefore can be placed anywhere in the field of view of a victim multirotor. For an effective attack, we compare three methods that simultaneously optimize the adversarial patch and its position in the input image. We perform an empirical validation on a publicly available DL model and dataset for autonomous multirotors. Ultimately, our attacking multirotor would be able to gain full control over the motions of the victim multirotor.",
    "link": "http://arxiv.org/abs/2305.12859",
    "context": "Title: Flying Adversarial Patches: Manipulating the Behavior of Deep Learning-based Autonomous Multirotors. (arXiv:2305.12859v2 [cs.RO] UPDATED)\nAbstract: Autonomous flying robots, e.g. multirotors, often rely on a neural network that makes predictions based on a camera image. These deep learning (DL) models can compute surprising results if applied to input images outside the training domain. Adversarial attacks exploit this fault, for example, by computing small images, so-called adversarial patches, that can be placed in the environment to manipulate the neural network's prediction. We introduce flying adversarial patches, where an image is mounted on another flying robot and therefore can be placed anywhere in the field of view of a victim multirotor. For an effective attack, we compare three methods that simultaneously optimize the adversarial patch and its position in the input image. We perform an empirical validation on a publicly available DL model and dataset for autonomous multirotors. Ultimately, our attacking multirotor would be able to gain full control over the motions of the victim multirotor.",
    "path": "papers/23/05/2305.12859.json",
    "total_tokens": 925,
    "translated_title": "飞行对抗贴片：操纵基于深度学习的自主多旋翼行为",
    "translated_abstract": "自主飞行机器人，如多旋翼，通常依靠神经网络根据摄像头图像进行预测。如果将这些深度学习（DL）模型应用于训练领域之外的输入图像，可能会得到出人意料的结果。对抗攻击利用了这个缺陷，例如通过计算小图像，即所谓的对抗贴片，将其放置在环境中，以操纵神经网络的预测。我们引入了飞行对抗贴片，其中一个图像被安装在另一个飞行机器人上，因此可以放置在受害多旋翼的任何视野中。为了有效攻击，我们比较了同时优化对抗贴片及其在输入图像中的位置的三种方法。我们对公开可用的用于自主多旋翼的DL模型和数据集进行了实证验证。最终，我们的攻击多旋翼能够完全控制受害多旋翼的运动。",
    "tldr": "该论文介绍了一种称为飞行对抗贴片的方法，利用神经网络的弱点，通过在飞行中携带的图像来操纵自主多旋翼的行为，实现对受害多旋翼的完全控制。",
    "en_tdlr": "This paper presents a method called flying adversarial patches, which leverages the vulnerability of neural networks to manipulate the behavior of autonomous multirotors by carrying images in flight and achieve full control over the victim multirotor."
}