{
    "title": "Mesh2SSM: From Surface Meshes to Statistical Shape Models of Anatomy. (arXiv:2305.07805v1 [cs.CV])",
    "abstract": "Statistical shape modeling is the computational process of discovering significant shape parameters from segmented anatomies captured by medical images (such as MRI and CT scans), which can fully describe subject-specific anatomy in the context of a population. The presence of substantial non-linear variability in human anatomy often makes the traditional shape modeling process challenging. Deep learning techniques can learn complex non-linear representations of shapes and generate statistical shape models that are more faithful to the underlying population-level variability. However, existing deep learning models still have limitations and require established/optimized shape models for training. We propose Mesh2SSM, a new approach that leverages unsupervised, permutation-invariant representation learning to estimate how to deform a template point cloud to subject-specific meshes, forming a correspondence-based shape model. Mesh2SSM can also learn a population-specific template, reduci",
    "link": "http://arxiv.org/abs/2305.07805",
    "context": "Title: Mesh2SSM: From Surface Meshes to Statistical Shape Models of Anatomy. (arXiv:2305.07805v1 [cs.CV])\nAbstract: Statistical shape modeling is the computational process of discovering significant shape parameters from segmented anatomies captured by medical images (such as MRI and CT scans), which can fully describe subject-specific anatomy in the context of a population. The presence of substantial non-linear variability in human anatomy often makes the traditional shape modeling process challenging. Deep learning techniques can learn complex non-linear representations of shapes and generate statistical shape models that are more faithful to the underlying population-level variability. However, existing deep learning models still have limitations and require established/optimized shape models for training. We propose Mesh2SSM, a new approach that leverages unsupervised, permutation-invariant representation learning to estimate how to deform a template point cloud to subject-specific meshes, forming a correspondence-based shape model. Mesh2SSM can also learn a population-specific template, reduci",
    "path": "papers/23/05/2305.07805.json",
    "total_tokens": 851,
    "translated_title": "Mesh2SSM: 从表面网格到解剖学统计形态模型",
    "translated_abstract": "统计形态建模是从医学图像（如MRI和CT扫描）中捕获的分割解剖结构中发现显著形态参数的计算过程，可全面描述种群中特定主体的解剖学。由于人体解剖结构中存在大量的非线性变异，传统的形态建模过程常常面临挑战。深度学习技术可以学习到复杂的非线性形态表示，并生成更忠实于基础种群变异的统计形态模型。然而，现有的深度学习模型仍然存在局限性，需要已建立/优化的形态模型进行训练。我们提出了Mesh2SSM，一种新的方法，利用无监督、排列不变的表示学习来估计如何将模板点云变形为特定主体的网格，形成基于对应关系的形态模型。Mesh2SSM还可以学习种群特定的模板，从而减少了数据对齐的需要。",
    "tldr": "Mesh2SSM是一种基于无监督排列不变表示学习的方法，可以将模板点云变形为特定主体的网格，形成基于对应关系的解剖学统计形态模型。",
    "en_tdlr": "Mesh2SSM is an approach based on unsupervised permutation-invariant representation learning to deform a template point cloud to subject-specific meshes, forming a correspondence-based statistical shape model of anatomy."
}