{
    "title": "Learning Video-Conditioned Policies for Unseen Manipulation Tasks. (arXiv:2305.06289v1 [cs.RO])",
    "abstract": "The ability to specify robot commands by a non-expert user is critical for building generalist agents capable of solving a large variety of tasks. One convenient way to specify the intended robot goal is by a video of a person demonstrating the target task. While prior work typically aims to imitate human demonstrations performed in robot environments, here we focus on a more realistic and challenging setup with demonstrations recorded in natural and diverse human environments. We propose Video-conditioned Policy learning (ViP), a data-driven approach that maps human demonstrations of previously unseen tasks to robot manipulation skills. To this end, we learn our policy to generate appropriate actions given current scene observations and a video of the target task. To encourage generalization to new tasks, we avoid particular tasks during training and learn our policy from unlabelled robot trajectories and corresponding robot videos. Both robot and human videos in our framework are rep",
    "link": "http://arxiv.org/abs/2305.06289",
    "context": "Title: Learning Video-Conditioned Policies for Unseen Manipulation Tasks. (arXiv:2305.06289v1 [cs.RO])\nAbstract: The ability to specify robot commands by a non-expert user is critical for building generalist agents capable of solving a large variety of tasks. One convenient way to specify the intended robot goal is by a video of a person demonstrating the target task. While prior work typically aims to imitate human demonstrations performed in robot environments, here we focus on a more realistic and challenging setup with demonstrations recorded in natural and diverse human environments. We propose Video-conditioned Policy learning (ViP), a data-driven approach that maps human demonstrations of previously unseen tasks to robot manipulation skills. To this end, we learn our policy to generate appropriate actions given current scene observations and a video of the target task. To encourage generalization to new tasks, we avoid particular tasks during training and learn our policy from unlabelled robot trajectories and corresponding robot videos. Both robot and human videos in our framework are rep",
    "path": "papers/23/05/2305.06289.json",
    "total_tokens": 649,
    "translated_title": "学习基于视频的无人任务策略",
    "translated_abstract": "实现非专业用户指定机器人命令是构建通用智能体能够解决各种任务的关键。通过人示范目标任务的视频来指定目标机器人目标是一种方便的方式，我们提出了基于视频的策略学习（ViP），将已经看不见的任务的人示范映射到机器人操作技能。",
    "tldr": "该论文提出了一种名为 ViP 的新方法，将人类的任务演示视频映射到机器人操作技能中，实现了人机交互中指定任务的目标。",
    "en_tdlr": "This paper proposes a new approach called ViP which maps human task demonstration videos to robot manipulation skills, facilitating goal specification in human-robot interaction."
}