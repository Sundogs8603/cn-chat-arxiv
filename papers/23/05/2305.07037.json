{
    "title": "Rethink Depth Separation with Intra-layer Links. (arXiv:2305.07037v1 [cs.LG])",
    "abstract": "The depth separation theory is nowadays widely accepted as an effective explanation for the power of depth, which consists of two parts: i) there exists a function representable by a deep network; ii) such a function cannot be represented by a shallow network whose width is lower than a threshold. However, this theory is established for feedforward networks. Few studies, if not none, considered the depth separation theory in the context of shortcuts which are the most common network types in solving real-world problems. Here, we find that adding intra-layer links can modify the depth separation theory. First, we report that adding intra-layer links can greatly improve a network's representation capability through bound estimation, explicit construction, and functional space analysis. Then, we modify the depth separation theory by showing that a shallow network with intra-layer links does not need to go as wide as before to express some hard functions constructed by a deep network. Such",
    "link": "http://arxiv.org/abs/2305.07037",
    "context": "Title: Rethink Depth Separation with Intra-layer Links. (arXiv:2305.07037v1 [cs.LG])\nAbstract: The depth separation theory is nowadays widely accepted as an effective explanation for the power of depth, which consists of two parts: i) there exists a function representable by a deep network; ii) such a function cannot be represented by a shallow network whose width is lower than a threshold. However, this theory is established for feedforward networks. Few studies, if not none, considered the depth separation theory in the context of shortcuts which are the most common network types in solving real-world problems. Here, we find that adding intra-layer links can modify the depth separation theory. First, we report that adding intra-layer links can greatly improve a network's representation capability through bound estimation, explicit construction, and functional space analysis. Then, we modify the depth separation theory by showing that a shallow network with intra-layer links does not need to go as wide as before to express some hard functions constructed by a deep network. Such",
    "path": "papers/23/05/2305.07037.json",
    "total_tokens": 837,
    "translated_title": "通过内部层连接重新思考深度分离",
    "translated_abstract": "深度分离理论现在被广泛认为是深度神经网络优越性的一个有效解释，它由两部分组成：i）存在一种可以由深度网络表示的函数；ii）这样的函数不能由宽度低于某一阈值的浅层网络表示。然而，这个理论是建立在前馈网络上的。很少有研究在向解决现实问题的最常见的网络类型——快捷网络中考虑深度分离理论。本文发现，添加内部层连接可以修改深度分离理论。首先，我们报告了通过界限估计、显式构造和功能空间分析可以通过添加内部层连接显著提高网络的表示能力。然后，我们通过展示一个带有内部层连接的浅层网络不需要像之前一样变得宽来表示由深层网络构造的一些困难函数来修改深度分离理论。",
    "tldr": "添加内部层连接可以显著提高网络的表示能力，并修改深度分离理论，使得带有内部层连接的浅层网络可以表示深层网络的一些困难函数。",
    "en_tdlr": "Adding intra-layer links can significantly enhance network representation capability and modify the depth separation theory, enabling a shallow network with intra-layer links to express some hard functions of a deep network."
}