{
    "title": "Adaptation of Tongue Ultrasound-Based Silent Speech Interfaces Using Spatial Transformer Networks. (arXiv:2305.19130v2 [cs.SD] UPDATED)",
    "abstract": "Thanks to the latest deep learning algorithms, silent speech interfaces (SSI) are now able to synthesize intelligible speech from articulatory movement data under certain conditions. However, the resulting models are rather speaker-specific, making a quick switch between users troublesome. Even for the same speaker, these models perform poorly cross-session, i.e. after dismounting and re-mounting the recording equipment. To aid quick speaker and session adaptation of ultrasound tongue imaging-based SSI models, we extend our deep networks with a spatial transformer network (STN) module, capable of performing an affine transformation on the input images. Although the STN part takes up only about 10% of the network, our experiments show that adapting just the STN module might allow to reduce MSE by 88% on the average, compared to retraining the whole network. The improvement is even larger (around 92%) when adapting the network to different recording sessions from the same speaker.",
    "link": "http://arxiv.org/abs/2305.19130",
    "context": "Title: Adaptation of Tongue Ultrasound-Based Silent Speech Interfaces Using Spatial Transformer Networks. (arXiv:2305.19130v2 [cs.SD] UPDATED)\nAbstract: Thanks to the latest deep learning algorithms, silent speech interfaces (SSI) are now able to synthesize intelligible speech from articulatory movement data under certain conditions. However, the resulting models are rather speaker-specific, making a quick switch between users troublesome. Even for the same speaker, these models perform poorly cross-session, i.e. after dismounting and re-mounting the recording equipment. To aid quick speaker and session adaptation of ultrasound tongue imaging-based SSI models, we extend our deep networks with a spatial transformer network (STN) module, capable of performing an affine transformation on the input images. Although the STN part takes up only about 10% of the network, our experiments show that adapting just the STN module might allow to reduce MSE by 88% on the average, compared to retraining the whole network. The improvement is even larger (around 92%) when adapting the network to different recording sessions from the same speaker.",
    "path": "papers/23/05/2305.19130.json",
    "total_tokens": 947,
    "translated_title": "基于空间转换网络的舌部超声无声语音接口的适应性研究",
    "translated_abstract": "最新的深度学习算法能够在一定条件下，从发音运动数据中合成可懂的语音，这些成果来自于无声语音接口（SSI）。然而，所得到的模型往往特定于某一说话人，使得在不同用户之间进行快速切换变得麻烦。即使是同一个讲者，在不同时间进行模型应用效果也较差。为了帮助舌部超声图像为基础的 SSI 模型快速适应到不同的用户和会话，我们扩展了深度网络，并利用空间转换网络 (STN) 模块，能够对输入图像进行仿射变换。虽然 STN 只占网络的约 10%，但实验表明，仅适应 STN 模块就可以将均方误差平均减少 88%，而不重新训练整个网络。当将网络适应到同一讲者的不同记录会话时，改进效果更大（大约 92%）。",
    "tldr": "采用空间转换网络模块，可使舌部超声图像为基础的无声语音接口模型快速适应到不同的用户和会话，且能显著降低均方误差。",
    "en_tdlr": "This study proposes incorporating a spatial transformer network (STN) module to aid quick adaptation of ultrasound tongue imaging-based silent speech interfaces (SSI) models to different users and sessions. Results show that adapting just the STN module can significantly reduce the mean squared error (MSE) by up to 88%, compared to retraining the entire network, with an even greater improvement (around 92%) for different recording sessions from the same speaker."
}