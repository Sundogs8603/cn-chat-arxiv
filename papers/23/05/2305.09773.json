{
    "title": "Towards Modeling Human Attention from Eye Movements for Neural Source Code Summarization. (arXiv:2305.09773v1 [cs.SE])",
    "abstract": "Neural source code summarization is the task of generating natural language descriptions of source code behavior using neural networks. A fundamental component of most neural models is an attention mechanism. The attention mechanism learns to connect features in source code to specific words to use when generating natural language descriptions. Humans also pay attention to some features in code more than others. This human attention reflects experience and high-level cognition well beyond the capability of any current neural model. In this paper, we use data from published eye-tracking experiments to create a model of this human attention. The model predicts which words in source code are the most important for code summarization. Next, we augment a baseline neural code summarization approach using our model of human attention. We observe an improvement in prediction performance of the augmented approach in line with other bio-inspired neural models.",
    "link": "http://arxiv.org/abs/2305.09773",
    "context": "Title: Towards Modeling Human Attention from Eye Movements for Neural Source Code Summarization. (arXiv:2305.09773v1 [cs.SE])\nAbstract: Neural source code summarization is the task of generating natural language descriptions of source code behavior using neural networks. A fundamental component of most neural models is an attention mechanism. The attention mechanism learns to connect features in source code to specific words to use when generating natural language descriptions. Humans also pay attention to some features in code more than others. This human attention reflects experience and high-level cognition well beyond the capability of any current neural model. In this paper, we use data from published eye-tracking experiments to create a model of this human attention. The model predicts which words in source code are the most important for code summarization. Next, we augment a baseline neural code summarization approach using our model of human attention. We observe an improvement in prediction performance of the augmented approach in line with other bio-inspired neural models.",
    "path": "papers/23/05/2305.09773.json",
    "total_tokens": 790,
    "translated_title": "基于眼动数据的人类注意力建模在神经源代码摘要中的应用",
    "translated_abstract": "神经源代码摘要是使用神经网络生成源代码行为自然语言描述的任务。大多数神经模型的基本组成部分是注意机制。注意机制学习将源代码中的特征与生成自然语言描述时要使用的特定单词连接起来。人类在编码中也会更加关注某些特定的特征。这种人类关注反映了经验和高水平认知，远超任何当前神经模型的能力。本文利用已发布的眼动实验数据创建了人类注意力模型，并预测源代码中最重要的单词，以增强基线神经代码摘要方法。我们观察到增强方法的预测性能有所提升，这与其他生物启发式神经模型的表现相符。",
    "tldr": "利用眼动数据对人类的注意力进行建模，并将模型应用于基于神经网络的源代码摘要中，预测源代码中最重要的单词并增强了基线模型的预测性能。",
    "en_tdlr": "The paper models human attention using eye-tracking data and applies the model to neural source code summarization, predicting the most important words in source code and improving the prediction performance of the baseline model."
}