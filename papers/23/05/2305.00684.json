{
    "title": "On the Complexity of Multi-Agent Decision Making: From Learning in Games to Partial Monitoring. (arXiv:2305.00684v1 [cs.LG])",
    "abstract": "A central problem in the theory of multi-agent reinforcement learning (MARL) is to understand what structural conditions and algorithmic principles lead to sample-efficient learning guarantees, and how these considerations change as we move from few to many agents. We study this question in a general framework for interactive decision making with multiple agents, encompassing Markov games with function approximation and normal-form games with bandit feedback. We focus on equilibrium computation, in which a centralized learning algorithm aims to compute an equilibrium by controlling multiple agents that interact with an unknown environment. Our main contributions are:  - We provide upper and lower bounds on the optimal sample complexity for multi-agent decision making based on a multi-agent generalization of the Decision-Estimation Coefficient, a complexity measure introduced by Foster et al. (2021) in the single-agent counterpart to our setting. Compared to the best results for the sin",
    "link": "http://arxiv.org/abs/2305.00684",
    "context": "Title: On the Complexity of Multi-Agent Decision Making: From Learning in Games to Partial Monitoring. (arXiv:2305.00684v1 [cs.LG])\nAbstract: A central problem in the theory of multi-agent reinforcement learning (MARL) is to understand what structural conditions and algorithmic principles lead to sample-efficient learning guarantees, and how these considerations change as we move from few to many agents. We study this question in a general framework for interactive decision making with multiple agents, encompassing Markov games with function approximation and normal-form games with bandit feedback. We focus on equilibrium computation, in which a centralized learning algorithm aims to compute an equilibrium by controlling multiple agents that interact with an unknown environment. Our main contributions are:  - We provide upper and lower bounds on the optimal sample complexity for multi-agent decision making based on a multi-agent generalization of the Decision-Estimation Coefficient, a complexity measure introduced by Foster et al. (2021) in the single-agent counterpart to our setting. Compared to the best results for the sin",
    "path": "papers/23/05/2305.00684.json",
    "total_tokens": 1280,
    "translated_title": "关于多智能体决策制定的复杂性：从游戏学习到局部监控。",
    "translated_abstract": "多智能体强化学习（MARL）中的一个核心问题是理解结构条件和算法原则会导致哪些样本有效的学习保证，并且在我们从少数智能体转移到多数智能体时，这些考虑如何发生变化。本文在多智能体互动决策的一般框架下研究了这个问题，包括具有函数逼近的马尔可夫博弈和带有赌徒反馈的正则式博弈。我们关注均衡计算，其中集中式学习算法旨在通过控制与未知环境交互的多个智能体来计算均衡。我们的主要贡献是：1. 我们基于由Foster等人（2021）在单智能体情况下引入的复杂度度量方法—决策-估计系数，为多智能体决策制定了最佳样本复杂度的上界和下界。与单智能体情况下的最佳结果相比，我们表明多智能体情况下的问题在智能体数量方面可能呈指数级难度。2. 我们提出了一种新颖的算法，用于在具有函数逼近的大型马尔可夫博弈中进行高效的均衡计算，该算法基于乐观镜像下降法的原理。我们为我们的方法建立了样本复杂度界限，这些界限改进了先前在带有赌徒反馈的游戏中的工作。3. 我们考虑局部监控，这是一种反馈类型，其中决策制定者只观察智能体动作的摘要信息而不是全部信息。我们开发了我们算法的一个变体，该算法实现了此设置的收敛速度最优，与先前工作建立的下界相比。",
    "tldr": "本文研究了多智能体决策制定的样本有效、均衡计算和局部监控问题，提出了复杂度上下界和算法，并发现多智能体情况下可能呈指数级难度。",
    "en_tdlr": "This paper studies the problems of sample-efficient learning, equilibrium computation, and partial monitoring in multi-agent decision making, providing complexity bounds and novel algorithms, and revealing the potential exponential hardness of the multi-agent setting."
}