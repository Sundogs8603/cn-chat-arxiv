{
    "title": "Online Platt Scaling with Calibeating. (arXiv:2305.00070v1 [cs.LG])",
    "abstract": "We present an online post-hoc calibration method, called Online Platt Scaling (OPS), which combines the Platt scaling technique with online logistic regression. We demonstrate that OPS smoothly adapts between i.i.d. and non-i.i.d. settings with distribution drift. Further, in scenarios where the best Platt scaling model is itself miscalibrated, we enhance OPS by incorporating a recently developed technique called calibeating to make it more robust. Theoretically, our resulting OPS+calibeating method is guaranteed to be calibrated for adversarial outcome sequences. Empirically, it is effective on a range of synthetic and real-world datasets, with and without distribution drifts, achieving superior performance without hyperparameter tuning. Finally, we extend all OPS ideas to the beta scaling method.",
    "link": "http://arxiv.org/abs/2305.00070",
    "context": "Title: Online Platt Scaling with Calibeating. (arXiv:2305.00070v1 [cs.LG])\nAbstract: We present an online post-hoc calibration method, called Online Platt Scaling (OPS), which combines the Platt scaling technique with online logistic regression. We demonstrate that OPS smoothly adapts between i.i.d. and non-i.i.d. settings with distribution drift. Further, in scenarios where the best Platt scaling model is itself miscalibrated, we enhance OPS by incorporating a recently developed technique called calibeating to make it more robust. Theoretically, our resulting OPS+calibeating method is guaranteed to be calibrated for adversarial outcome sequences. Empirically, it is effective on a range of synthetic and real-world datasets, with and without distribution drifts, achieving superior performance without hyperparameter tuning. Finally, we extend all OPS ideas to the beta scaling method.",
    "path": "papers/23/05/2305.00070.json",
    "total_tokens": 867,
    "translated_title": "在线Platt缩放及其校准方法",
    "translated_abstract": "我们提出了一种在线后校准方法，称为在线Platt缩放(OPS)，它将Platt缩放技术与在线逻辑回归相结合。我们展示了OPS如何在分布漂移的i.i.d.和非i.i.d.情况下平稳适应。此外，当最佳的Platt缩放模型本身被错误校准时，我们使用一种最近开发的称为calibeating的技术来增强OPS，使其更加鲁棒。理论上，我们得到的OPS+calibeating方法对于对抗性结果序列是保证校准的。在实验上，它在一系列合成和真实数据集上均表现出卓越的性能，无需超参数调整。最后，我们将所有OPS思想扩展到beta缩放方法。",
    "tldr": "本文提出了一种在线Platt缩放及其校准方法，其理论基础强大，可以处理分布漂移和对抗性结果序列，无需超参数调整，在一系列合成和真实数据集上表现出卓越的性能。",
    "en_tdlr": "The paper introduces an online method, called Online Platt Scaling (OPS) that combines the Platt scaling technique with online logistic regression for post-hoc calibration, and enhances it with the calibeating technique when the best Platt scaling model is itself miscalibrated, and extends all OPS ideas to the beta scaling method. OPS is shown to smoothly adapt between i.i.d. and non-i.i.d. settings with distribution drift, and the OPS+calibeating method is guaranteed to be calibrated for adversarial outcome sequences. Empirically, OPS achieves superior performance without hyperparameter tuning on a range of synthetic and real-world datasets."
}