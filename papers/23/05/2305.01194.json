{
    "title": "The Pipeline System of ASR and NLU with MLM-based Data Augmentation toward STOP Low-resource Challenge. (arXiv:2305.01194v1 [cs.CL])",
    "abstract": "This paper describes our system for the low-resource domain adaptation track (Track 3) in Spoken Language Understanding Grand Challenge, which is a part of ICASSP Signal Processing Grand Challenge 2023. In the track, we adopt a pipeline approach of ASR and NLU. For ASR, we fine-tune Whisper for each domain with upsampling. For NLU, we fine-tune BART on all the Track3 data and then on low-resource domain data. We apply masked LM (MLM) -based data augmentation, where some of input tokens and corresponding target labels are replaced using MLM. We also apply a retrieval-based approach, where model input is augmented with similar training samples. As a result, we achieved exact match (EM) accuracy 63.3/75.0 (average: 69.15) for reminder/weather domain, and won the 1st place at the challenge.",
    "link": "http://arxiv.org/abs/2305.01194",
    "context": "Title: The Pipeline System of ASR and NLU with MLM-based Data Augmentation toward STOP Low-resource Challenge. (arXiv:2305.01194v1 [cs.CL])\nAbstract: This paper describes our system for the low-resource domain adaptation track (Track 3) in Spoken Language Understanding Grand Challenge, which is a part of ICASSP Signal Processing Grand Challenge 2023. In the track, we adopt a pipeline approach of ASR and NLU. For ASR, we fine-tune Whisper for each domain with upsampling. For NLU, we fine-tune BART on all the Track3 data and then on low-resource domain data. We apply masked LM (MLM) -based data augmentation, where some of input tokens and corresponding target labels are replaced using MLM. We also apply a retrieval-based approach, where model input is augmented with similar training samples. As a result, we achieved exact match (EM) accuracy 63.3/75.0 (average: 69.15) for reminder/weather domain, and won the 1st place at the challenge.",
    "path": "papers/23/05/2305.01194.json",
    "total_tokens": 976,
    "translated_title": "基于MLM数据增强的ASR和NLU管道系统应对STOP低资源挑战",
    "translated_abstract": "本文描述了我们在ICASSP信号处理大赛2023的口语理解大挑战（Spoken Language Understanding Grand Challenge）低资源领域适应赛道（Track3）中采用的ASR和NLU的管道方法。针对ASR，我们使用上采样 fine-tune Whisper 以适应每个领域。针对NLU，我们 fine-tune BART 在所有 Track3 数据上，然后在低资源域数据上进行 fine-tune。我们应用了基于遮盖的LM（MLM）数据增强，其中一些输入标记和相应的目标标签使用 MLM 进行替换。我们还采用了基于检索的方法，模型输入与类似的训练样本一起进行增强。结果，我们在提醒/天气领域实现了63.3 / 75.0（平均：69.15）的精确匹配（EM）准确度，获得了该挑战的第一名。",
    "tldr": "本文介绍了在低资源适应题目中使用的ASR和NLU的管道方法。在ASR中，使用上采样的Whisper对每个领域进行Feine-tune；在NLU中，使用MLM技术进行数据增强并使用基于检索的方法扩充数据。最终，我们在提醒/天气领域获得了高精确匹配准确度并获得了挑战的第一名。"
}