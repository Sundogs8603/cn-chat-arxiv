{
    "title": "Toward Understanding Generative Data Augmentation. (arXiv:2305.17476v1 [cs.LG])",
    "abstract": "Generative data augmentation, which scales datasets by obtaining fake labeled examples from a trained conditional generative model, boosts classification performance in various learning tasks including (semi-)supervised learning, few-shot learning, and adversarially robust learning. However, little work has theoretically investigated the effect of generative data augmentation. To fill this gap, we establish a general stability bound in this not independently and identically distributed (non-i.i.d.) setting, where the learned distribution is dependent on the original train set and generally not the same as the true distribution. Our theoretical result includes the divergence between the learned distribution and the true distribution. It shows that generative data augmentation can enjoy a faster learning rate when the order of divergence term is $o(\\max\\left( \\log(m)\\beta_m, 1 / \\sqrt{m})\\right)$, where $m$ is the train set size and $\\beta_m$ is the corresponding stability constant. We f",
    "link": "http://arxiv.org/abs/2305.17476",
    "context": "Title: Toward Understanding Generative Data Augmentation. (arXiv:2305.17476v1 [cs.LG])\nAbstract: Generative data augmentation, which scales datasets by obtaining fake labeled examples from a trained conditional generative model, boosts classification performance in various learning tasks including (semi-)supervised learning, few-shot learning, and adversarially robust learning. However, little work has theoretically investigated the effect of generative data augmentation. To fill this gap, we establish a general stability bound in this not independently and identically distributed (non-i.i.d.) setting, where the learned distribution is dependent on the original train set and generally not the same as the true distribution. Our theoretical result includes the divergence between the learned distribution and the true distribution. It shows that generative data augmentation can enjoy a faster learning rate when the order of divergence term is $o(\\max\\left( \\log(m)\\beta_m, 1 / \\sqrt{m})\\right)$, where $m$ is the train set size and $\\beta_m$ is the corresponding stability constant. We f",
    "path": "papers/23/05/2305.17476.json",
    "total_tokens": 1003,
    "translated_title": "探究生成式数据增广的意义",
    "translated_abstract": "通过从训练的有条件生成模型中获得虚假的标记示例，生成式数据增广可以扩展数据集，并提高各种学习任务（包括（半）监督学习、少样本学习和对抗性鲁棒学习）中的分类性能。然而，目前很少有理论工作探究生成式数据增广的效果。为了填补这一空白，我们在这个非独立和同分布（non-i.i.d.）的设置中建立了一个普遍的稳定性界限，其中学习的分布依赖于原始训练集，通常与真实分布不同。我们的理论结果包括学习分布和真实分布之间的差异。结果表明，当发散项的阶数为$ o(\\max\\left( \\log(m)\\beta_m, 1 / \\sqrt{m})\\right)$时，生成式数据增广可以享受更快的学习速率，其中$m$为训练集大小，$\\beta_m$为相应的稳定性常数。我们发现，界限的大小与发散阶数和训练集大小成正比，这表明生成式数据增广的效果与生成模型的选择和训练集的大小密切相关。",
    "tldr": "生成式数据增广通过从训练的生成模型中获得虚假的标记示例，提高分类性能；本文建立了一个普遍的稳定性界限，并发现其效果与生成模型的选择和训练集大小密切相关。",
    "en_tdlr": "Generative data augmentation improves classification performance by obtaining fake labeled examples from a trained generative model. This article establishes a general stability bound and shows that its effect is tightly related to the choice of generative models and the size of the train set."
}