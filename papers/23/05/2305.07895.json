{
    "title": "On the Hidden Mystery of OCR in Large Multimodal Models. (arXiv:2305.07895v1 [cs.CV])",
    "abstract": "Large models have recently played a dominant role in natural language processing and multimodal vision-language learning. It remains less explored about their efficacy in text-related visual tasks. We conducted a comprehensive study of existing publicly available multimodal models, evaluating their performance in text recognition, text-based visual question answering, and key information extraction. Our findings reveal strengths and weaknesses in these models, which primarily rely on semantic understanding for word recognition and exhibit inferior perception of individual character shapes. They also display indifference towards text length and have limited capabilities in detecting fine-grained features in images. Consequently, these results demonstrate that even the current most powerful large multimodal models cannot match domain-specific methods in traditional text tasks and face greater challenges in more complex tasks. Most importantly, the baseline results showcased in this study",
    "link": "http://arxiv.org/abs/2305.07895",
    "context": "Title: On the Hidden Mystery of OCR in Large Multimodal Models. (arXiv:2305.07895v1 [cs.CV])\nAbstract: Large models have recently played a dominant role in natural language processing and multimodal vision-language learning. It remains less explored about their efficacy in text-related visual tasks. We conducted a comprehensive study of existing publicly available multimodal models, evaluating their performance in text recognition, text-based visual question answering, and key information extraction. Our findings reveal strengths and weaknesses in these models, which primarily rely on semantic understanding for word recognition and exhibit inferior perception of individual character shapes. They also display indifference towards text length and have limited capabilities in detecting fine-grained features in images. Consequently, these results demonstrate that even the current most powerful large multimodal models cannot match domain-specific methods in traditional text tasks and face greater challenges in more complex tasks. Most importantly, the baseline results showcased in this study",
    "path": "papers/23/05/2305.07895.json",
    "total_tokens": 1013,
    "translated_title": "关于大型多模态模型中OCR的隐秘之谜",
    "translated_abstract": "近来，大型模型在自然语言处理和多模态视觉语言学习中扮演着支配性的角色。关于它们在文本相关的视觉任务中有效性的探索仍不够。我们对现有公开可用的多模态模型进行了全面的研究，评估了它们在文本识别、基于文本的视觉问答和关键信息提取方面的表现。我们的研究结果揭示了这些模型的优劣势，它们主要依赖于语义理解来识别单词，并表现出较差的对单个字符形状的感知。它们对文本长度漠不关心，在检测图像的细粒度特征方面具有有限的能力。因此，这些结果表明，即使当前最强大的大型多模态模型也无法与传统文本任务的领域特定方法相匹配，并在更复杂的任务中面临更大的挑战。最重要的是，本研究展示的基线结果揭示了大型多模态模型中OCR的隐秘之谜，仍需要进一步探索。",
    "tldr": "本研究全面评估了现有大型多模态模型在文本相关的视觉任务中的表现，结果显示这些模型虽然在语义理解方面表现优异，但对单个字符形状的感知有限，对图像的细粒度特征检测能力也不足，不能与传统领域特定方法相匹配，并仍需进一步探索它们在OCR中的表现。",
    "en_tdlr": "This study comprehensively evaluates the performance of existing large multimodal models in text-related visual tasks and reveals that, while these models exhibit strong performance in semantic understanding, they have limited perception of individual character shapes and are incapable of detecting fine-grained features in images, indicating that these models cannot match domain-specific methods in traditional text tasks and require further exploration in optical character recognition in large multimodal models."
}