{
    "title": "Personalized Predictive ASR for Latency Reduction in Voice Assistants. (arXiv:2305.13794v1 [cs.CL])",
    "abstract": "Streaming Automatic Speech Recognition (ASR) in voice assistants can utilize prefetching to partially hide the latency of response generation. Prefetching involves passing a preliminary ASR hypothesis to downstream systems in order to prefetch and cache a response. If the final ASR hypothesis after endpoint detection matches the preliminary one, the cached response can be delivered to the user, thus saving latency. In this paper, we extend this idea by introducing predictive automatic speech recognition, where we predict the full utterance from a partially observed utterance, and prefetch the response based on the predicted utterance. We introduce two personalization approaches and investigate the tradeoff between potential latency gains from successful predictions and the cost increase from failed predictions. We evaluate our methods on an internal voice assistant dataset as well as the public SLURP dataset.",
    "link": "http://arxiv.org/abs/2305.13794",
    "context": "Title: Personalized Predictive ASR for Latency Reduction in Voice Assistants. (arXiv:2305.13794v1 [cs.CL])\nAbstract: Streaming Automatic Speech Recognition (ASR) in voice assistants can utilize prefetching to partially hide the latency of response generation. Prefetching involves passing a preliminary ASR hypothesis to downstream systems in order to prefetch and cache a response. If the final ASR hypothesis after endpoint detection matches the preliminary one, the cached response can be delivered to the user, thus saving latency. In this paper, we extend this idea by introducing predictive automatic speech recognition, where we predict the full utterance from a partially observed utterance, and prefetch the response based on the predicted utterance. We introduce two personalization approaches and investigate the tradeoff between potential latency gains from successful predictions and the cost increase from failed predictions. We evaluate our methods on an internal voice assistant dataset as well as the public SLURP dataset.",
    "path": "papers/23/05/2305.13794.json",
    "total_tokens": 835,
    "translated_title": "个性化预测ASR在语音助手中的延迟降低",
    "translated_abstract": "语音助手中的流式自动语音识别（ASR）可以利用预取来部分隐藏响应生成的延迟。预取涉及将初步的ASR假设传递给下游系统，以预取和缓存响应。如果终点检测后的最终ASR假设与初步假设匹配，则可以将缓存的响应交付给用户，从而节省延迟。在本文中，我们通过引入基于部分观察到的话语预测完整话语，并根据预测话语预取响应的预测自动语音识别，扩展了这个想法。我们引入了两种个性化方法，并研究了成功预测的潜在延迟增益与预测失败的成本增加之间的权衡。我们在内部语音助手数据集以及公共SLURP数据集上评估了我们的方法。",
    "tldr": "本文介绍了一种个性化预测ASR方法，可以降低语音助手中的延迟，通过预测完整话语来预取响应，并探讨了成功预测和失败预测之间的权衡。",
    "en_tdlr": "This paper introduces a personalized predictive ASR method for reducing latency in voice assistants. It prefetches responses based on predicted full utterances from partially observed ones. The tradeoff between successful predictions and the cost increase from failed predictions is investigated."
}