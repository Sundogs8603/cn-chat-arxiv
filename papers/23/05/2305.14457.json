{
    "title": "Pre-training Language Models for Comparative Reasoning. (arXiv:2305.14457v1 [cs.CL])",
    "abstract": "In this paper, we propose a novel framework to pre-train language models for enhancing their abilities of comparative reasoning over texts. While recent research has developed models for NLP tasks that require comparative reasoning, they suffer from costly manual data labeling and limited generalizability to different tasks. Our approach involves a scalable method for collecting data for text-based entity comparison, which leverages both structured and unstructured data, and the design of three novel pre-training tasks. Evaluation on a range of downstream tasks including comparative question answering, question generation, and summarization shows that our pre-training framework significantly improves the comparative reasoning abilities of language models, especially under low-resource conditions. This work also releases the first integrated benchmark for comparative reasoning over texts.",
    "link": "http://arxiv.org/abs/2305.14457",
    "context": "Title: Pre-training Language Models for Comparative Reasoning. (arXiv:2305.14457v1 [cs.CL])\nAbstract: In this paper, we propose a novel framework to pre-train language models for enhancing their abilities of comparative reasoning over texts. While recent research has developed models for NLP tasks that require comparative reasoning, they suffer from costly manual data labeling and limited generalizability to different tasks. Our approach involves a scalable method for collecting data for text-based entity comparison, which leverages both structured and unstructured data, and the design of three novel pre-training tasks. Evaluation on a range of downstream tasks including comparative question answering, question generation, and summarization shows that our pre-training framework significantly improves the comparative reasoning abilities of language models, especially under low-resource conditions. This work also releases the first integrated benchmark for comparative reasoning over texts.",
    "path": "papers/23/05/2305.14457.json",
    "total_tokens": 766,
    "translated_title": "为比较推理预训练语言模型",
    "translated_abstract": "本文提出了一种新框架，用于预训练语言模型以增强其在文本比较推理方面的能力。我们的方法涉及可扩展的用于收集基于文本实体比较数据的方法，并设计了三个新的预训练任务。在多个下游任务，包括比较问答、问句生成和摘要生成方面的评估表明，我们的预训练框架大大提高了语言模型的比较推理能力，尤其是在资源匮乏的情况下。此外，本工作还发布了第一个比较推理综合基准。",
    "tldr": "本文提出一种预训练语言模型的新框架，旨在增强其在比较推理方面的能力。通过使用可扩展的基于文本实体比较数据的方法和新的预训练任务，该框架得到了显著的结果。",
    "en_tdlr": "This paper proposes a new framework for pre-training language models to enhance their abilities of comparative reasoning over texts. By using a scalable method for collecting text-based entity comparison data and designing novel pre-training tasks, the framework significantly improves the models' comparative reasoning abilities, especially under low-resource conditions. The paper also introduces the first integrated benchmark for comparative reasoning over texts."
}