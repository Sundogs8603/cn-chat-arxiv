{
    "title": "Revisiting Sentence Union Generation as a Testbed for Text Consolidation. (arXiv:2305.15605v1 [cs.CL])",
    "abstract": "Tasks involving text generation based on multiple input texts, such as multi-document summarization, long-form question answering and contemporary dialogue applications, challenge models for their ability to properly consolidate partly-overlapping multi-text information. However, these tasks entangle the consolidation phase with the often subjective and ill-defined content selection requirement, impeding proper assessment of models' consolidation capabilities. In this paper, we suggest revisiting the sentence union generation task as an effective well-defined testbed for assessing text consolidation capabilities, decoupling the consolidation challenge from subjective content selection. To support research on this task, we present refined annotation methodology and tools for crowdsourcing sentence union, create the largest union dataset to date and provide an analysis of its rich coverage of various consolidation aspects. We then propose a comprehensive evaluation protocol for union gen",
    "link": "http://arxiv.org/abs/2305.15605",
    "context": "Title: Revisiting Sentence Union Generation as a Testbed for Text Consolidation. (arXiv:2305.15605v1 [cs.CL])\nAbstract: Tasks involving text generation based on multiple input texts, such as multi-document summarization, long-form question answering and contemporary dialogue applications, challenge models for their ability to properly consolidate partly-overlapping multi-text information. However, these tasks entangle the consolidation phase with the often subjective and ill-defined content selection requirement, impeding proper assessment of models' consolidation capabilities. In this paper, we suggest revisiting the sentence union generation task as an effective well-defined testbed for assessing text consolidation capabilities, decoupling the consolidation challenge from subjective content selection. To support research on this task, we present refined annotation methodology and tools for crowdsourcing sentence union, create the largest union dataset to date and provide an analysis of its rich coverage of various consolidation aspects. We then propose a comprehensive evaluation protocol for union gen",
    "path": "papers/23/05/2305.15605.json",
    "total_tokens": 1047,
    "translated_title": "作为文本整合测试基准的句子联合生成的再探讨",
    "translated_abstract": "基于多个输入文本生成文本的任务（例如多文档摘要、长篇问题回答和现代对话应用）挑战模型对于适当整合部分重叠的多文本信息的能力。然而，这些任务将整合阶段与常常主观和定义不明确的内容选择要求相结合，阻碍了模型整合能力的适当评估。在本文中，我们建议重新考虑句子联合生成任务作为一个有效的定义明确的测试基准，评估文本整合能力，并将整合挑战与主观内容选择分离开来。为了支持这个任务的研究，我们提出了精细的注释方法和工具，用于众包句子联合，创建了迄今为止最大的联合数据集，并提供了其丰富的各种整合方面的覆盖率分析。然后，我们提出了一个全面的联合生成评估协议，包括自动和人为评估，并报告了几个最先进模型的结果。我们的实验研究表明，即使是先进的模型也难以应对一些关键的整合方面，表明在这个任务中有明显的改进空间。",
    "tldr": "本文提出将句子联合生成任务作为一个有效的测试基准，以评估文本整合的能力。该任务将整合挑战与主观内容选择分离开来，并提供了精细的注释方法和工具。实验研究表明，即使是先进的模型也难以应对一些关键的整合方面，表明在这个任务中有明显的改进空间。",
    "en_tdlr": "The paper proposes revisiting the sentence union generation task as an effective testbed for assessing text consolidation capabilities, decoupling the consolidation challenge from subjective content selection. The refined annotation methodology and tools are provided to support research on this task. Experimental results show that even advanced models struggle with some key consolidation aspects, indicating a clear room for improvement in this task."
}