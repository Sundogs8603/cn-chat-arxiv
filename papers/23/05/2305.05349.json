{
    "title": "Towards the Characterization of Representations Learned via Capsule-based Network Architectures. (arXiv:2305.05349v1 [cs.LG])",
    "abstract": "Capsule Networks (CapsNets) have been re-introduced as a more compact and interpretable alternative to standard deep neural networks. While recent efforts have proved their compression capabilities, to date, their interpretability properties have not been fully assessed. Here, we conduct a systematic and principled study towards assessing the interpretability of these types of networks. Moreover, we pay special attention towards analyzing the level to which part-whole relationships are indeed encoded within the learned representation. Our analysis in the MNIST, SVHN, PASCAL-part and CelebA datasets suggest that the representations encoded in CapsNets might not be as disentangled nor strictly related to parts-whole relationships as is commonly stated in the literature.",
    "link": "http://arxiv.org/abs/2305.05349",
    "context": "Title: Towards the Characterization of Representations Learned via Capsule-based Network Architectures. (arXiv:2305.05349v1 [cs.LG])\nAbstract: Capsule Networks (CapsNets) have been re-introduced as a more compact and interpretable alternative to standard deep neural networks. While recent efforts have proved their compression capabilities, to date, their interpretability properties have not been fully assessed. Here, we conduct a systematic and principled study towards assessing the interpretability of these types of networks. Moreover, we pay special attention towards analyzing the level to which part-whole relationships are indeed encoded within the learned representation. Our analysis in the MNIST, SVHN, PASCAL-part and CelebA datasets suggest that the representations encoded in CapsNets might not be as disentangled nor strictly related to parts-whole relationships as is commonly stated in the literature.",
    "path": "papers/23/05/2305.05349.json",
    "total_tokens": 754,
    "translated_title": "旨在表征基于胶囊网络架构学习的表示方法",
    "translated_abstract": "胶囊网络作为标准深度神经网络的一种更为紧凑和可解释的替代方法而重新引入。尽管最近的研究证明了其压缩能力，但至今尚未完全评估其可解释性质。在这里，我们进行了一项系统而原则性的研究，以评估这种类型网络的可解释性。此外，我们特别注意分析所学到的表示中是否确实编码了部分-整体关系的水平。在MNIST、SVHN、PASCAL-part和CelebA数据集中的分析表明，在CapsNets中编码的表示可能既不像文献中通常所述的那样分离，也不是严格与部分-整体关系相关的。",
    "tldr": "本研究旨在评估胶囊网络架构学习的表示方法及其可解释性，发现其编码的表示可能与部分-整体关系并不严格相关。",
    "en_tdlr": "This study aims to evaluate the representation and interpretability of Capsule Networks (CapsNets), and finds that the encoded representations may not be strictly related to part-whole relationships as commonly stated in the literature."
}