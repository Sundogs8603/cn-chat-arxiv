{
    "title": "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization. (arXiv:2305.00374v1 [cs.LG])",
    "abstract": "Adversarial contrastive learning (ACL), without requiring labels, incorporates adversarial data with standard contrastive learning (SCL) and outputs a robust representation which is generalizable and resistant to adversarial attacks and common corruptions. The style-independence property of representations has been validated to be beneficial in improving robustness transferability. Standard invariant regularization (SIR) has been proposed to make the learned representations via SCL to be independent of the style factors. However, how to equip robust representations learned via ACL with the style-independence property is still unclear so far. To this end, we leverage the technique of causal reasoning to propose an adversarial invariant regularization (AIR) that enforces robust representations learned via ACL to be style-independent. Then, we enhance ACL using invariant regularization (IR), which is a weighted sum of SIR and AIR. Theoretically, we show that AIR implicitly encourages the ",
    "link": "http://arxiv.org/abs/2305.00374",
    "context": "Title: Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization. (arXiv:2305.00374v1 [cs.LG])\nAbstract: Adversarial contrastive learning (ACL), without requiring labels, incorporates adversarial data with standard contrastive learning (SCL) and outputs a robust representation which is generalizable and resistant to adversarial attacks and common corruptions. The style-independence property of representations has been validated to be beneficial in improving robustness transferability. Standard invariant regularization (SIR) has been proposed to make the learned representations via SCL to be independent of the style factors. However, how to equip robust representations learned via ACL with the style-independence property is still unclear so far. To this end, we leverage the technique of causal reasoning to propose an adversarial invariant regularization (AIR) that enforces robust representations learned via ACL to be style-independent. Then, we enhance ACL using invariant regularization (IR), which is a weighted sum of SIR and AIR. Theoretically, we show that AIR implicitly encourages the ",
    "path": "papers/23/05/2305.00374.json",
    "total_tokens": 1130,
    "translated_title": "通过对抗性不变正则化增强对抗性对比学习",
    "translated_abstract": "对抗性对比学习(ACL)无需标签，将对抗性数据与标准对比学习(SCL)相结合，输出一个具有鲁棒性的表示，可泛化且抵抗对抗性攻击和常见污染。表示的样式独立属性已经被证明有助于提高鲁棒性的转移。标准不变正则化(SIR)已经被提出，使SCL通过学习的表示不受样式因素的影响。然而，如何通过ACL获得具有样式独立性质的鲁棒表示仍然不清楚。为此，我们利用因果推理技术，提出了一种对抗性不变正则化(AIR)，强制通过ACL学习到的鲁棒表示具有样式独立性。然后，我们使用不变正则化(IR)增强ACL，它是SIR和AIR的加权总和。理论上，我们证明AIR通过防止模型依赖样式因素来获得高对比分数，隐式地促进了ACL的鲁棒性。实验上，我们证明了我们提出的方法在各种对抗攻击和常见污染下显著提高了ACL的鲁棒性，并在多个基准测试中实现了最先进的性能。",
    "tldr": "本文提出了一种对抗性不变正则化方法（AIR）来强制对抗性对比学习（ACL）的学习表示呈现样式独立性，并用加权SIR和AIR实现ACL的鲁棒性增强。实验证实，该方法在各种对抗攻击和常见污染下均显著提高ACL的鲁棒性，并在多个基准测试中实现了最先进的性能。",
    "en_tdlr": "This paper proposes an adversarial invariant regularization (AIR) method to enforce the style-independence property of learned representations in adversarial contrastive learning (ACL), and enhances ACL's robustness through a weighted combination of SIR and AIR. Experimentally, this approach significantly improves the robustness of ACL against various adversarial attacks and common corruptions, achieving state-of-the-art performance on multiple benchmarks."
}