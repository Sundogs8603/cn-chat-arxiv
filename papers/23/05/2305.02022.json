{
    "title": "LearnDefend: Learning to Defend against Targeted Model-Poisoning Attacks on Federated Learning. (arXiv:2305.02022v1 [cs.LG])",
    "abstract": "Targeted model poisoning attacks pose a significant threat to federated learning systems. Recent studies show that edge-case targeted attacks, which target a small fraction of the input space are nearly impossible to counter using existing fixed defense strategies. In this paper, we strive to design a learned-defense strategy against such attacks, using a small defense dataset. The defense dataset can be collected by the central authority of the federated learning task, and should contain a mix of poisoned and clean examples. The proposed framework, LearnDefend, estimates the probability of a client update being malicious. The examples in defense dataset need not be pre-marked as poisoned or clean. We also learn a poisoned data detector model which can be used to mark each example in the defense dataset as clean or poisoned. We estimate the poisoned data detector and the client importance models in a coupled optimization approach. Our experiments demonstrate that LearnDefend is capable",
    "link": "http://arxiv.org/abs/2305.02022",
    "context": "Title: LearnDefend: Learning to Defend against Targeted Model-Poisoning Attacks on Federated Learning. (arXiv:2305.02022v1 [cs.LG])\nAbstract: Targeted model poisoning attacks pose a significant threat to federated learning systems. Recent studies show that edge-case targeted attacks, which target a small fraction of the input space are nearly impossible to counter using existing fixed defense strategies. In this paper, we strive to design a learned-defense strategy against such attacks, using a small defense dataset. The defense dataset can be collected by the central authority of the federated learning task, and should contain a mix of poisoned and clean examples. The proposed framework, LearnDefend, estimates the probability of a client update being malicious. The examples in defense dataset need not be pre-marked as poisoned or clean. We also learn a poisoned data detector model which can be used to mark each example in the defense dataset as clean or poisoned. We estimate the poisoned data detector and the client importance models in a coupled optimization approach. Our experiments demonstrate that LearnDefend is capable",
    "path": "papers/23/05/2305.02022.json",
    "total_tokens": 1039,
    "translated_title": "LearnDefend：学习对抗联邦学习中的有针对性的模型中毒攻击",
    "translated_abstract": "面向联邦学习系统的有针对性模型中毒攻击构成了巨大的威胁。最近的研究显示，目标边缘案例型攻击（对输入空间的一小部分进行针对性攻击）几乎无法通过现有的防御策略进行反击。本文旨在通过使用较小的防御数据集设计一种学习防御策略来应对此类攻击。防御数据集可以由联邦学习任务的中央管理机构收集，其中应包含一些被污染的和没有被污染的示例。所提出的框架LearnDefend会估计客户端更新具有恶意的概率。防御数据集中的示例不需要事先标记为被污染或未被污染。我们还学习了一个可用于标记防御数据集中每个示例为干净或污染的毒数据检测器模型。我们使用耦合的优化方法来估计毒数据检测器和客户端重要性模型。我们的实验表明，LearnDefend能够成功应对有针对性模型中毒攻击。",
    "tldr": "LearnDefend是一种学习防御策略，能够有效地对抗联邦学习系统中的有针对性模型中毒攻击。它使用一个较小的防御数据集，估计客户端更新被污染的概率，通过学习毒数据检测器模型并使用耦合的优化方法估计毒数据检测器和客户端重要性模型。",
    "en_tdlr": "LearnDefend is a learning defense strategy that can effectively defend against targeted model-poisoning attacks in federated learning systems. It uses a small defense dataset to estimate the probability of a client update being malicious. A poisoned data detector model is learned and used to label clean and poisoned examples, and coupled optimization is used to estimate the poisoned data detector and client importance models."
}