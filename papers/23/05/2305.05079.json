{
    "title": "A Unified Evaluation Framework for Novelty Detection and Accommodation in NLP with an Instantiation in Authorship Attribution. (arXiv:2305.05079v1 [cs.CL])",
    "abstract": "State-of-the-art natural language processing models have been shown to achieve remarkable performance in 'closed-world' settings where all the labels in the evaluation set are known at training time. However, in real-world settings, 'novel' instances that do not belong to any known class are often observed. This renders the ability to deal with novelties crucial. To initiate a systematic research in this important area of 'dealing with novelties', we introduce 'NoveltyTask', a multi-stage task to evaluate a system's performance on pipelined novelty 'detection' and 'accommodation' tasks. We provide mathematical formulation of NoveltyTask and instantiate it with the authorship attribution task that pertains to identifying the correct author of a given text. We use Amazon reviews corpus and compile a large dataset (consisting of 250k instances across 200 authors/labels) for NoveltyTask. We conduct comprehensive experiments and explore several baseline methods for the task. Our results sho",
    "link": "http://arxiv.org/abs/2305.05079",
    "context": "Title: A Unified Evaluation Framework for Novelty Detection and Accommodation in NLP with an Instantiation in Authorship Attribution. (arXiv:2305.05079v1 [cs.CL])\nAbstract: State-of-the-art natural language processing models have been shown to achieve remarkable performance in 'closed-world' settings where all the labels in the evaluation set are known at training time. However, in real-world settings, 'novel' instances that do not belong to any known class are often observed. This renders the ability to deal with novelties crucial. To initiate a systematic research in this important area of 'dealing with novelties', we introduce 'NoveltyTask', a multi-stage task to evaluate a system's performance on pipelined novelty 'detection' and 'accommodation' tasks. We provide mathematical formulation of NoveltyTask and instantiate it with the authorship attribution task that pertains to identifying the correct author of a given text. We use Amazon reviews corpus and compile a large dataset (consisting of 250k instances across 200 authors/labels) for NoveltyTask. We conduct comprehensive experiments and explore several baseline methods for the task. Our results sho",
    "path": "papers/23/05/2305.05079.json",
    "total_tokens": 1084,
    "translated_title": "NLP中处理新颖性检测和适应性的统一评估框架，以作者归属为例",
    "translated_abstract": "最先进的自然语言处理模型已经在“封闭的世界”设置中表现出非凡的性能，其中训练集中的所有标签在评估集合中都是已知的。然而，在现实世界中，通常会观察到不属于任何已知类别的“新颖”实例，这使得处理新颖性的能力至关重要。为了引发对“处理新颖性”的这一重要领域的系统性研究，我们引入了“NoveltyTask”，这是一个多阶段任务，用于评估系统在流水线新颖性“检测”和“适应性”任务上的性能。我们提供了NoveltyTask的数学公式，并以作者归属任务为例进行实例化，该任务涉及识别给定文本的正确作者。我们使用了亚马逊评论语料库，并为NoveltyTask编制了一个大型数据集（包括来自200个作者/标签的250k个实例）。我们进行了全面的实验，并探索了任务的几个基准方法。我们的结果表明，处理新颖性实例的问题具有挑战性，需要专门的技术。我们还提出了一种新颖性检测和适应性的统一评估框架，可以应用于除作者归属以外的各种NLP任务。",
    "tldr": "本文提出了一个新颖性检测和适应性的统一评估框架，以作者归属任务为例进行了实例化，并使用多阶段任务的NoveltyTask评估了系统的性能，结果表明该领域的处理新颖性实例的问题非常具有挑战性。"
}