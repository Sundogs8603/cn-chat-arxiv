{
    "title": "Unified Demonstration Retriever for In-Context Learning. (arXiv:2305.04320v2 [cs.CL] UPDATED)",
    "abstract": "In-context learning is a new learning paradigm where a language model conditions on a few input-output pairs (demonstrations) and a test input, and directly outputs the prediction. It has been shown highly dependent on the provided demonstrations and thus promotes the research of demonstration retrieval: given a test input, relevant examples are retrieved from the training set to serve as informative demonstrations for in-context learning. While previous works focus on training task-specific retrievers for several tasks separately, these methods are often hard to transfer and scale on various tasks, and separately trained retrievers incur a lot of parameter storage and deployment cost. In this paper, we propose Unified Demonstration Retriever (\\textbf{UDR}), a single model to retrieve demonstrations for a wide range of tasks. To train UDR, we cast various tasks' training signals into a unified list-wise ranking formulation by language model's feedback. Then we propose a multi-task list",
    "link": "http://arxiv.org/abs/2305.04320",
    "context": "Title: Unified Demonstration Retriever for In-Context Learning. (arXiv:2305.04320v2 [cs.CL] UPDATED)\nAbstract: In-context learning is a new learning paradigm where a language model conditions on a few input-output pairs (demonstrations) and a test input, and directly outputs the prediction. It has been shown highly dependent on the provided demonstrations and thus promotes the research of demonstration retrieval: given a test input, relevant examples are retrieved from the training set to serve as informative demonstrations for in-context learning. While previous works focus on training task-specific retrievers for several tasks separately, these methods are often hard to transfer and scale on various tasks, and separately trained retrievers incur a lot of parameter storage and deployment cost. In this paper, we propose Unified Demonstration Retriever (\\textbf{UDR}), a single model to retrieve demonstrations for a wide range of tasks. To train UDR, we cast various tasks' training signals into a unified list-wise ranking formulation by language model's feedback. Then we propose a multi-task list",
    "path": "papers/23/05/2305.04320.json",
    "total_tokens": 781,
    "translated_title": "统一的上下文学习演示检索器",
    "translated_abstract": "上下文学习是一种新的学习范式，其中语言模型在少量输入-输出对（演示）和测试输入的条件下，直接输出预测结果。研究表明它高度依赖于提供的演示，并促进了演示检索的研究：根据测试输入从训练集中检索相关示例，为上下文学习提供信息丰富的演示。本文提出了统一的演示检索器（UDR），用于为广泛的任务检索演示；通过使用语言模型的反馈将各种任务的训练信号转换为统一的列表排序公式来训练UDR。",
    "tldr": "本文提出了一种统一的演示检索器UDR，可用于广泛的任务检索演示，在训练时使用语言模型的反馈来将各种任务的训练信号转换为统一的列表排序公式。"
}