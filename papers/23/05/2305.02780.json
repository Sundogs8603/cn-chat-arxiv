{
    "title": "Interpretable Regional Descriptors: Hyperbox-Based Local Explanations. (arXiv:2305.02780v1 [stat.ML])",
    "abstract": "This work introduces interpretable regional descriptors, or IRDs, for local, model-agnostic interpretations. IRDs are hyperboxes that describe how an observation's feature values can be changed without affecting its prediction. They justify a prediction by providing a set of \"even if\" arguments (semi-factual explanations), and they indicate which features affect a prediction and whether pointwise biases or implausibilities exist. A concrete use case shows that this is valuable for both machine learning modelers and persons subject to a decision. We formalize the search for IRDs as an optimization problem and introduce a unifying framework for computing IRDs that covers desiderata, initialization techniques, and a post-processing method. We show how existing hyperbox methods can be adapted to fit into this unified framework. A benchmark study compares the methods based on several quality measures and identifies two strategies to improve IRDs.",
    "link": "http://arxiv.org/abs/2305.02780",
    "context": "Title: Interpretable Regional Descriptors: Hyperbox-Based Local Explanations. (arXiv:2305.02780v1 [stat.ML])\nAbstract: This work introduces interpretable regional descriptors, or IRDs, for local, model-agnostic interpretations. IRDs are hyperboxes that describe how an observation's feature values can be changed without affecting its prediction. They justify a prediction by providing a set of \"even if\" arguments (semi-factual explanations), and they indicate which features affect a prediction and whether pointwise biases or implausibilities exist. A concrete use case shows that this is valuable for both machine learning modelers and persons subject to a decision. We formalize the search for IRDs as an optimization problem and introduce a unifying framework for computing IRDs that covers desiderata, initialization techniques, and a post-processing method. We show how existing hyperbox methods can be adapted to fit into this unified framework. A benchmark study compares the methods based on several quality measures and identifies two strategies to improve IRDs.",
    "path": "papers/23/05/2305.02780.json",
    "total_tokens": 891,
    "translated_title": "可解释的区域描述符：基于超立方体的局部解释",
    "translated_abstract": "本文介绍了一种用于模型无关的局部解释的可解释的区域描述符（IRDs），它们是描述观测值特征值可更改而不影响其预测的超立方体。通过提供一组“即使是”参数（半事实的解释），它们证明了一个预测，并指出哪些特征影响了预测以及是否存在点偏差或不可信。一个具体的用例展示了它对于机器学习模型的构建者和决策受影响人员都是有价值的。我们将IRDs的搜索形式化为一个优化问题，并引入了一个计算IRDs的统一框架，包括期望、初始化技术和后处理方法。我们展示了如何将现有的超立方体方法适应到这个统一框架中。一项基准研究比较了基于多个质量指标的方法，并确定了两种改进IRDs的策略。",
    "tldr": "本文介绍了一种可解释的区域描述符，它是一种模型无关的局部解释方法，通过描述超立方体来预测特征值可更改但不影响预测结果，并提供\"即使是\"参数，揭示决策的特征和偏差。",
    "en_tdlr": "This paper presents interpretable regional descriptors (IRDs) as a model-agnostic local explanation method. IRDs describe hyperboxes to predict feature values that can be changed without affecting the prediction, justify a prediction by providing even-if arguments, and reveal decision features and biases."
}