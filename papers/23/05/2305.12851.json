{
    "title": "Enhancing Coherence of Extractive Summarization with Multitask Learning. (arXiv:2305.12851v2 [cs.CL] UPDATED)",
    "abstract": "This study proposes a multitask learning architecture for extractive summarization with coherence boosting. The architecture contains an extractive summarizer and coherent discriminator module. The coherent discriminator is trained online on the sentence vectors of the augmented textual input, thus improving its general ability of judging whether the input sentences are coherent. Meanwhile, we maximize the coherent scores from the coherent discriminator by updating the parameters of the summarizer. To make the extractive sentences trainable in a differentiable manner, we introduce two strategies, including pre-trained converting model (model-based) and converting matrix (MAT-based) that merge sentence representations. Experiments show that our proposed method significantly improves the proportion of consecutive sentences in the extracted summaries based on their positions in the original article (i.e., automatic sentence-level coherence metric), while the goodness in terms of other aut",
    "link": "http://arxiv.org/abs/2305.12851",
    "context": "Title: Enhancing Coherence of Extractive Summarization with Multitask Learning. (arXiv:2305.12851v2 [cs.CL] UPDATED)\nAbstract: This study proposes a multitask learning architecture for extractive summarization with coherence boosting. The architecture contains an extractive summarizer and coherent discriminator module. The coherent discriminator is trained online on the sentence vectors of the augmented textual input, thus improving its general ability of judging whether the input sentences are coherent. Meanwhile, we maximize the coherent scores from the coherent discriminator by updating the parameters of the summarizer. To make the extractive sentences trainable in a differentiable manner, we introduce two strategies, including pre-trained converting model (model-based) and converting matrix (MAT-based) that merge sentence representations. Experiments show that our proposed method significantly improves the proportion of consecutive sentences in the extracted summaries based on their positions in the original article (i.e., automatic sentence-level coherence metric), while the goodness in terms of other aut",
    "path": "papers/23/05/2305.12851.json",
    "total_tokens": 854,
    "translated_title": "使用多任务学习增强抽取式摘要的连贯性",
    "translated_abstract": "本研究提出了一种使用多任务学习架构来增强抽取式摘要的连贯性的方法。该架构包含一个抽取式摘要生成器和一个连贯性判别器模块。连贯性判别器通过在线训练增强了对输入句子连贯性的判断能力。同时，我们通过更新摘要生成器的参数来最大化连贯性判别器的连贯性分数。为了能够以可微分的方式训练抽取式摘要，我们引入了两种策略，包括预训练转换模型和转换矩阵方法，用于合并句子表示。实验证明，我们提出的方法显著提高了抽取式摘要中连贯句子在原始文章中按位置的比例（即自动句子级连贯度指标），而在其他自动评价指标方面也表现出良好的性能。",
    "tldr": "本研究提出了一种使用多任务学习架构来增强抽取式摘要的连贯性的方法。实验证明，该方法显著提高了抽取式摘要的连贯性，并在其他评价指标方面也表现出良好的性能。",
    "en_tdlr": "This study proposes a multitask learning architecture to enhance the coherence of extractive summarization. Experiments show that this method significantly improves the coherence of extractive summaries and performs well in other evaluation metrics."
}