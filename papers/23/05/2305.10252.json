{
    "title": "Sharpness & Shift-Aware Self-Supervised Learning. (arXiv:2305.10252v1 [cs.LG])",
    "abstract": "Self-supervised learning aims to extract meaningful features from unlabeled data for further downstream tasks. In this paper, we consider classification as a downstream task in phase 2 and develop rigorous theories to realize the factors that implicitly influence the general loss of this classification task. Our theories signify that sharpness-aware feature extractors benefit the classification task in phase 2 and the existing data shift between the ideal (i.e., the ideal one used in theory development) and practical (i.e., the practical one used in implementation) distributions to generate positive pairs also remarkably affects this classification task. Further harvesting these theoretical findings, we propose to minimize the sharpness of the feature extractor and a new Fourier-based data augmentation technique to relieve the data shift in the distributions generating positive pairs, reaching Sharpness & Shift-Aware Contrastive Learning (SSA-CLR). We conduct extensive experiments to v",
    "link": "http://arxiv.org/abs/2305.10252",
    "context": "Title: Sharpness & Shift-Aware Self-Supervised Learning. (arXiv:2305.10252v1 [cs.LG])\nAbstract: Self-supervised learning aims to extract meaningful features from unlabeled data for further downstream tasks. In this paper, we consider classification as a downstream task in phase 2 and develop rigorous theories to realize the factors that implicitly influence the general loss of this classification task. Our theories signify that sharpness-aware feature extractors benefit the classification task in phase 2 and the existing data shift between the ideal (i.e., the ideal one used in theory development) and practical (i.e., the practical one used in implementation) distributions to generate positive pairs also remarkably affects this classification task. Further harvesting these theoretical findings, we propose to minimize the sharpness of the feature extractor and a new Fourier-based data augmentation technique to relieve the data shift in the distributions generating positive pairs, reaching Sharpness & Shift-Aware Contrastive Learning (SSA-CLR). We conduct extensive experiments to v",
    "path": "papers/23/05/2305.10252.json",
    "total_tokens": 918,
    "translated_title": "锐度与位移感知的自监督学习",
    "translated_abstract": "自监督学习旨在从无标签数据中提取有意义的特征以进行下游任务。本文考虑分类作为第二阶段下游任务，并开发了严密的理论来实现影响该分类任务的隐含因素。我们的理论表明，锐度感知的特征提取器有利于第二阶段的分类任务，并且理论开发中的理想分布与实际实现中的实际分布之间的数据位移也极大地影响了该分类任务。进一步利用这些理论发现，我们提出了最小化特征提取器的锐度和一种新的基于傅里叶变换的数据增强技术，以缓解实现中分布位移的影响，从而实现了锐度和位移感知的对比学习(SSA-CLR)。我们进行了大量实验以验证我们方法的有效性。",
    "tldr": "本文针对自监督学习中的分类下游任务，开发了锐度与数据位移感知理论并提出了基于对比学习的方法(SSA-CLR)，通过特征提取器锐度最小化与傅里叶变换数据增强技术缓解理想分布与实际分布间的数据位移，实现了对分类任务的改进。",
    "en_tdlr": "This paper proposes a Sharpness & Shift-Aware Contrastive Learning (SSA-CLR) method for self-supervised learning with classification as the downstream task. The authors develop theories that show the importance of sharpness-aware feature extractors and the effect of the data shift between the ideal and practical distributions. The proposed method minimizes the sharpness of the feature extractor and uses a Fourier-based data augmentation technique to alleviate the data shift, resulting in improved performance on the classification task."
}