{
    "title": "Table Detection for Visually Rich Document Images. (arXiv:2305.19181v2 [cs.CV] UPDATED)",
    "abstract": "Table Detection (TD) is a fundamental task to enable visually rich document understanding, which requires the model to extract information without information loss. However, popular Intersection over Union (IoU) based evaluation metrics and IoU-based loss functions for the detection models cannot directly represent the degree of information loss for the prediction results. Therefore, we propose to decouple IoU into a ground truth coverage term and a prediction coverage term, in which the former can be used to measure the information loss of the prediction results. Besides, considering the sparse distribution of tables in document images, we use SparseR-CNN as the base model and further improve the model by using Gaussian Noise Augmented Image Size region proposals and many-to-one label assignments. Results under comprehensive experiments show that the proposed method can consistently outperform state-of-the-art methods with different IoU-based metrics under various datasets and demonst",
    "link": "http://arxiv.org/abs/2305.19181",
    "context": "Title: Table Detection for Visually Rich Document Images. (arXiv:2305.19181v2 [cs.CV] UPDATED)\nAbstract: Table Detection (TD) is a fundamental task to enable visually rich document understanding, which requires the model to extract information without information loss. However, popular Intersection over Union (IoU) based evaluation metrics and IoU-based loss functions for the detection models cannot directly represent the degree of information loss for the prediction results. Therefore, we propose to decouple IoU into a ground truth coverage term and a prediction coverage term, in which the former can be used to measure the information loss of the prediction results. Besides, considering the sparse distribution of tables in document images, we use SparseR-CNN as the base model and further improve the model by using Gaussian Noise Augmented Image Size region proposals and many-to-one label assignments. Results under comprehensive experiments show that the proposed method can consistently outperform state-of-the-art methods with different IoU-based metrics under various datasets and demonst",
    "path": "papers/23/05/2305.19181.json",
    "total_tokens": 926,
    "translated_title": "可视丰富文件图像的表格检测",
    "translated_abstract": "表格检测是实现可视丰富文件理解的基本任务，需要模型在提取信息时避免信息丢失。然而，常用的交叉联合（IoU）评估指标和基于IoU的检测模型损失函数无法直接表示预测结果的信息丢失程度。因此，我们提出将IoU分解为真实覆盖项和预测覆盖项，其中前者可以用于衡量预测结果的信息丢失。此外，考虑到文档图像中表格的稀疏分布，我们使用SparseR-CNN作为基础模型，并通过使用高斯噪声增强的图像大小区域提案和多对一标签分配来进一步改进模型。全面实验结果表明，所提出的方法可以在不同IoU指标下的各种数据集上始终优于最先进的方法，并展示了其有效性。",
    "tldr": "本研究提出了一种在可视丰富文件图像中进行表格检测的方法。通过将IoU分解为真实覆盖项和预测覆盖项来衡量预测结果的信息丢失程度。此外，通过使用高斯噪声增强的图像大小区域提案和多对一标签分配，进一步改进模型。实验证明，该方法能够在不同数据集上优于最先进方法。",
    "en_tdlr": "This research proposes a method for table detection in visually rich document images. It measures the information loss of prediction results by decoupling IoU into ground truth coverage and prediction coverage terms. Furthermore, the model is improved by using Gaussian Noise Augmented Image Size region proposals and many-to-one label assignments. Experimental results demonstrate that the proposed method outperforms state-of-the-art methods on different datasets."
}