{
    "title": "On enhancing the robustness of Vision Transformers: Defensive Diffusion. (arXiv:2305.08031v1 [cs.CV])",
    "abstract": "Privacy and confidentiality of medical data are of utmost importance in healthcare settings. ViTs, the SOTA vision model, rely on large amounts of patient data for training, which raises concerns about data security and the potential for unauthorized access. Adversaries may exploit vulnerabilities in ViTs to extract sensitive patient information and compromising patient privacy. This work address these vulnerabilities to ensure the trustworthiness and reliability of ViTs in medical applications. In this work, we introduced a defensive diffusion technique as an adversarial purifier to eliminate adversarial noise introduced by attackers in the original image. By utilizing the denoising capabilities of the diffusion model, we employ a reverse diffusion process to effectively eliminate the adversarial noise from the attack sample, resulting in a cleaner image that is then fed into the ViT blocks. Our findings demonstrate the effectiveness of the diffusion model in eliminating attack-agnost",
    "link": "http://arxiv.org/abs/2305.08031",
    "context": "Title: On enhancing the robustness of Vision Transformers: Defensive Diffusion. (arXiv:2305.08031v1 [cs.CV])\nAbstract: Privacy and confidentiality of medical data are of utmost importance in healthcare settings. ViTs, the SOTA vision model, rely on large amounts of patient data for training, which raises concerns about data security and the potential for unauthorized access. Adversaries may exploit vulnerabilities in ViTs to extract sensitive patient information and compromising patient privacy. This work address these vulnerabilities to ensure the trustworthiness and reliability of ViTs in medical applications. In this work, we introduced a defensive diffusion technique as an adversarial purifier to eliminate adversarial noise introduced by attackers in the original image. By utilizing the denoising capabilities of the diffusion model, we employ a reverse diffusion process to effectively eliminate the adversarial noise from the attack sample, resulting in a cleaner image that is then fed into the ViT blocks. Our findings demonstrate the effectiveness of the diffusion model in eliminating attack-agnost",
    "path": "papers/23/05/2305.08031.json",
    "total_tokens": 972,
    "translated_title": "提高视觉Transformer的鲁棒性：防御性扩散",
    "translated_abstract": "医疗数据的隐私和保密性在医疗保健环境中至关重要。ViTs是目前最先进的视觉模型，依赖于大量的患者数据进行训练，这引发了有关数据安全和潜在未经授权的访问的担忧。攻击者可能利用ViTs中的漏洞提取敏感患者信息，从而危及患者隐私。本文针对这些漏洞，以确保ViTs在医疗应用中的可信性和可靠性，引入了一种防御性扩散技术作为对抗性净化器，以消除攻击者在原始图像中引入的对抗性噪声。通过利用扩散模型的去噪能力，我们采用反向扩散过程有效地消除攻击示例中的对抗性噪声，从而得到一个更干净的图像，然后将其输入ViT模块。我们的研究结果表明，扩散模型在消除对抗性攻击扰动方面非常有效，从而提高了医疗应用中ViT模型的鲁棒性和可靠性。",
    "tldr": "本文提出了一种防御性扩散技术作为对抗性净化器，以消除攻击者在原始图像中引入的对抗性噪声，从而提高了ViT模型在医疗应用中的鲁棒性和可靠性。"
}