{
    "title": "Best-Effort Adaptation. (arXiv:2305.05816v1 [cs.LG])",
    "abstract": "We study a problem of best-effort adaptation motivated by several applications and considerations, which consists of determining an accurate predictor for a target domain, for which a moderate amount of labeled samples are available, while leveraging information from another domain for which substantially more labeled samples are at one's disposal. We present a new and general discrepancy-based theoretical analysis of sample reweighting methods, including bounds holding uniformly over the weights. We show how these bounds can guide the design of learning algorithms that we discuss in detail. We further show that our learning guarantees and algorithms provide improved solutions for standard domain adaptation problems, for which few labeled data or none are available from the target domain. We finally report the results of a series of experiments demonstrating the effectiveness of our best-effort adaptation and domain adaptation algorithms, as well as comparisons with several baselines. ",
    "link": "http://arxiv.org/abs/2305.05816",
    "context": "Title: Best-Effort Adaptation. (arXiv:2305.05816v1 [cs.LG])\nAbstract: We study a problem of best-effort adaptation motivated by several applications and considerations, which consists of determining an accurate predictor for a target domain, for which a moderate amount of labeled samples are available, while leveraging information from another domain for which substantially more labeled samples are at one's disposal. We present a new and general discrepancy-based theoretical analysis of sample reweighting methods, including bounds holding uniformly over the weights. We show how these bounds can guide the design of learning algorithms that we discuss in detail. We further show that our learning guarantees and algorithms provide improved solutions for standard domain adaptation problems, for which few labeled data or none are available from the target domain. We finally report the results of a series of experiments demonstrating the effectiveness of our best-effort adaptation and domain adaptation algorithms, as well as comparisons with several baselines. ",
    "path": "papers/23/05/2305.05816.json",
    "total_tokens": 832,
    "translated_title": "最佳努力适应性",
    "translated_abstract": "我们研究了一个由多个应用和考虑因素激发出的最佳努力适应性问题，其中包括确定一个精确的预测器以用于目标域，虽然只有适量的已标记样本可用，但利用来自另一个拥有大量已标记样本的域的信息。我们提出了一种新的和通用的基于差异的理论分析样本重新加权方法，包括在权重上均匀保持的界限。我们展示了这些边界如何指导我们详细讨论的学习算法的设计。我们进一步展示了我们的学习保证和算法为标准域适应性问题提供了改进的解决方案，其中目标域只有少量标记数据或没有标记数据可用。最后，我们报告了一系列实验的结果，展示了我们的最佳努力适应性和域适应算法的有效性，以及与几个基线的比较。",
    "tldr": "研究了最佳努力适应性问题，提出了一种新的基于差异的理论分析方法以及用于标准域适应性问题的改进学习算法，表现出很好的实验效果。",
    "en_tdlr": "This paper studies the problem of best-effort adaptation, proposes a new discrepancy-based theoretical analysis method and improved learning algorithm for standard domain adaptation problems, and shows good experimental results."
}