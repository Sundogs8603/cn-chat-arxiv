{
    "title": "RECKONING: Reasoning through Dynamic Knowledge Encoding. (arXiv:2305.06349v1 [cs.CL])",
    "abstract": "Recent studies on transformer-based language models show that they can answer questions by reasoning over knowledge provided as part of the context (i.e., in-context reasoning). However, since the available knowledge is often not filtered for a particular question, in-context reasoning can be sensitive to distractor facts, additional content that is irrelevant to a question but that may be relevant for a different question (i.e., not necessarily random noise). In these situations, the model fails to distinguish the knowledge that is necessary to answer the question, leading to spurious reasoning and degraded performance. This reasoning failure contrasts with the model's apparent ability to distinguish its contextual knowledge from all the knowledge it has memorized during pre-training. Following this observation, we propose teaching the model to reason more robustly by folding the provided contextual knowledge into the model's parameters before presenting it with a question. Our method",
    "link": "http://arxiv.org/abs/2305.06349",
    "context": "Title: RECKONING: Reasoning through Dynamic Knowledge Encoding. (arXiv:2305.06349v1 [cs.CL])\nAbstract: Recent studies on transformer-based language models show that they can answer questions by reasoning over knowledge provided as part of the context (i.e., in-context reasoning). However, since the available knowledge is often not filtered for a particular question, in-context reasoning can be sensitive to distractor facts, additional content that is irrelevant to a question but that may be relevant for a different question (i.e., not necessarily random noise). In these situations, the model fails to distinguish the knowledge that is necessary to answer the question, leading to spurious reasoning and degraded performance. This reasoning failure contrasts with the model's apparent ability to distinguish its contextual knowledge from all the knowledge it has memorized during pre-training. Following this observation, we propose teaching the model to reason more robustly by folding the provided contextual knowledge into the model's parameters before presenting it with a question. Our method",
    "path": "papers/23/05/2305.06349.json",
    "total_tokens": 806,
    "tldr": "本文提出RECKONING，一种将上下文知识折叠到模型参数中的方法，用于增强模型推理的鲁棒性和性能。",
    "en_tdlr": "This paper proposes a method called RECKONING for enhancing the robustness and performance of models in reasoning, by folding the contextual knowledge into the model's parameters."
}