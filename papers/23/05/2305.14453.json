{
    "title": "On Robustness of Finetuned Transformer-based NLP Models. (arXiv:2305.14453v1 [cs.CL])",
    "abstract": "Transformer-based pretrained models like BERT, GPT-2 and T5 have been finetuned for a large number of natural language processing (NLP) tasks, and have been shown to be very effective. However, while finetuning, what changes across layers in these models with respect to pretrained checkpoints is under-studied. Further, how robust are these models to perturbations in input text? Does the robustness vary depending on the NLP task for which the models have been finetuned? While there exists some work on studying robustness of BERT finetuned for a few NLP tasks, there is no rigorous study which compares this robustness across encoder only, decoder only and encoder-decoder models.  In this paper, we study the robustness of three language models (BERT, GPT-2 and T5) with eight different text perturbations on the General Language Understanding Evaluation (GLUE) benchmark. Also, we use two metrics (CKA and STIR) to quantify changes between pretrained and finetuned language model representation",
    "link": "http://arxiv.org/abs/2305.14453",
    "context": "Title: On Robustness of Finetuned Transformer-based NLP Models. (arXiv:2305.14453v1 [cs.CL])\nAbstract: Transformer-based pretrained models like BERT, GPT-2 and T5 have been finetuned for a large number of natural language processing (NLP) tasks, and have been shown to be very effective. However, while finetuning, what changes across layers in these models with respect to pretrained checkpoints is under-studied. Further, how robust are these models to perturbations in input text? Does the robustness vary depending on the NLP task for which the models have been finetuned? While there exists some work on studying robustness of BERT finetuned for a few NLP tasks, there is no rigorous study which compares this robustness across encoder only, decoder only and encoder-decoder models.  In this paper, we study the robustness of three language models (BERT, GPT-2 and T5) with eight different text perturbations on the General Language Understanding Evaluation (GLUE) benchmark. Also, we use two metrics (CKA and STIR) to quantify changes between pretrained and finetuned language model representation",
    "path": "papers/23/05/2305.14453.json",
    "total_tokens": 873,
    "translated_title": "关于Transformer-based NLP模型的鲁棒性的研究",
    "translated_abstract": "Transformer-based的预训练模型如BERT、GPT-2和T5已经被用于大量自然语言处理任务的fine-tuning，被证明非常有效。然而，在fine-tuning过程中，这些模型各层与预训练检查点相比的变化尚未得到深入研究。此外，这些模型对文本输入的扰动的鲁棒性如何？这种鲁棒性是否因模型fine-tuning的NLP任务而异？本文研究了三种语言模型（BERT、GPT-2和T5）在General Language Understanding Evaluation（GLUE）基准测试上对八种不同文本扰动的鲁棒性。此外，我们使用两个指标（CKA和STIR）来量化fine-tuning后的语言模型表示与预训练表示之间的变化。",
    "tldr": "本文研究了BERT、GPT-2和T5这三种语言模型对文本扰动的鲁棒性，通过量化fine-tuning后的语言模型表示与预训练表示的差异来探究模型的变化程度。"
}