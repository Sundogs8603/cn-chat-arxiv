{
    "title": "Input-Aware Dynamic Timestep Spiking Neural Networks for Efficient In-Memory Computing. (arXiv:2305.17346v1 [cs.NE])",
    "abstract": "Spiking Neural Networks (SNNs) have recently attracted widespread research interest as an efficient alternative to traditional Artificial Neural Networks (ANNs) because of their capability to process sparse and binary spike information and avoid expensive multiplication operations. Although the efficiency of SNNs can be realized on the In-Memory Computing (IMC) architecture, we show that the energy cost and latency of SNNs scale linearly with the number of timesteps used on IMC hardware. Therefore, in order to maximize the efficiency of SNNs, we propose input-aware Dynamic Timestep SNN (DT-SNN), a novel algorithmic solution to dynamically determine the number of timesteps during inference on an input-dependent basis. By calculating the entropy of the accumulated output after each timestep, we can compare it to a predefined threshold and decide if the information processed at the current timestep is sufficient for a confident prediction. We deploy DT-SNN on an IMC architecture and show ",
    "link": "http://arxiv.org/abs/2305.17346",
    "context": "Title: Input-Aware Dynamic Timestep Spiking Neural Networks for Efficient In-Memory Computing. (arXiv:2305.17346v1 [cs.NE])\nAbstract: Spiking Neural Networks (SNNs) have recently attracted widespread research interest as an efficient alternative to traditional Artificial Neural Networks (ANNs) because of their capability to process sparse and binary spike information and avoid expensive multiplication operations. Although the efficiency of SNNs can be realized on the In-Memory Computing (IMC) architecture, we show that the energy cost and latency of SNNs scale linearly with the number of timesteps used on IMC hardware. Therefore, in order to maximize the efficiency of SNNs, we propose input-aware Dynamic Timestep SNN (DT-SNN), a novel algorithmic solution to dynamically determine the number of timesteps during inference on an input-dependent basis. By calculating the entropy of the accumulated output after each timestep, we can compare it to a predefined threshold and decide if the information processed at the current timestep is sufficient for a confident prediction. We deploy DT-SNN on an IMC architecture and show ",
    "path": "papers/23/05/2305.17346.json",
    "total_tokens": 886,
    "translated_title": "输入感知的动态时间步长脉冲神经网络用于高效的内存计算",
    "translated_abstract": "最近，由于脉冲神经网络（SNN）能够处理稀疏和二进制脉冲信息，并避免昂贵的乘法操作，因此已经引起了广泛的研究兴趣。虽然SNN在内存计算（IMC）架构上的效率可以实现，但我们发现SNN的能量成本和延迟随着在IMC硬件上使用的时间步长数量呈线性增长。因此，为了最大化SNN的效率，我们提出了一种输入感知的动态时间步长SNN（DT-SNN）算法解决方案，该解决方案可以在推理过程中动态确定时间步长的数量，而且还根据输入数据的特性进行调整。具体地，通过在每个时间步长后计算输出的熵，并将其与预定义的阈值进行比较，可以决定当前时间步长处理的信息是否足以进行有信心的预测。我们将DT-SNN部署在IMC架构上，并展示了...",
    "tldr": "DT-SNN是一种输入感知的动态时间步长脉冲神经网络算法解决方案， 可以根据数据特性动态确定时间步长的数量，从而将SNN的效率最大化。",
    "en_tdlr": "DT-SNN is an input-aware dynamic timestep spiking neural network algorithmic solution that can dynamically determine the number of timesteps based on input data characteristics, thus maximizing the efficiency of SNNs."
}