{
    "title": "Compositional diversity in visual concept learning. (arXiv:2305.19374v1 [cs.CV])",
    "abstract": "Humans leverage compositionality to efficiently learn new concepts, understanding how familiar parts can combine together to form novel objects. In contrast, popular computer vision models struggle to make the same types of inferences, requiring more data and generalizing less flexibly than people do. Here, we study these distinctively human abilities across a range of different types of visual composition, examining how people classify and generate ``alien figures'' with rich relational structure. We also develop a Bayesian program induction model which searches for the best programs for generating the candidate visual figures, utilizing a large program space containing different compositional mechanisms and abstractions. In few shot classification tasks, we find that people and the program induction model can make a range of meaningful compositional generalizations, with the model providing a strong account of the experimental data as well as interpretable parameters that reveal huma",
    "link": "http://arxiv.org/abs/2305.19374",
    "context": "Title: Compositional diversity in visual concept learning. (arXiv:2305.19374v1 [cs.CV])\nAbstract: Humans leverage compositionality to efficiently learn new concepts, understanding how familiar parts can combine together to form novel objects. In contrast, popular computer vision models struggle to make the same types of inferences, requiring more data and generalizing less flexibly than people do. Here, we study these distinctively human abilities across a range of different types of visual composition, examining how people classify and generate ``alien figures'' with rich relational structure. We also develop a Bayesian program induction model which searches for the best programs for generating the candidate visual figures, utilizing a large program space containing different compositional mechanisms and abstractions. In few shot classification tasks, we find that people and the program induction model can make a range of meaningful compositional generalizations, with the model providing a strong account of the experimental data as well as interpretable parameters that reveal huma",
    "path": "papers/23/05/2305.19374.json",
    "total_tokens": 849,
    "translated_title": "视觉概念学习中的组合多样性",
    "translated_abstract": "人类利用组合性来有效地学习新概念，理解熟悉部件如何组合在一起形成新颖对象。相比之下，流行的计算机视觉模型难以进行相同类型的推理，需要更多数据，并且不如人类具有灵活的泛化能力。本文研究这些人类特有的能力在不同类型的视觉组合中的表现，研究人类如何对具有丰富关系结构的“外星人图形”进行分类和生成。我们还开发了一个贝叶斯程序归纳模型，搜索生成候选视觉图形的最佳程序，利用包含不同组合机制和抽象的大型程序空间。在少样本分类任务中，我们发现人类和程序归纳模型可以进行许多有意义的组合泛化，模型提供了实验数据的强有力解释以及显示人类式组合推理的可解释参数。",
    "tldr": "本文研究了人类如何利用组合性进行视觉概念学习，开发了一个程序归纳模型来生成候选视觉图形，发现人类和模型都可以进行多样的组合泛化。",
    "en_tdlr": "This paper studies how humans leverage compositional reasoning in visual concept learning and develops a program induction model to generate candidate visual figures. The results show that both humans and the model are capable of making diverse compositional generalizations."
}