{
    "title": "Masked Trajectory Models for Prediction, Representation, and Control. (arXiv:2305.02968v1 [cs.LG])",
    "abstract": "We introduce Masked Trajectory Models (MTM) as a generic abstraction for sequential decision making. MTM takes a trajectory, such as a state-action sequence, and aims to reconstruct the trajectory conditioned on random subsets of the same trajectory. By training with a highly randomized masking pattern, MTM learns versatile networks that can take on different roles or capabilities, by simply choosing appropriate masks at inference time. For example, the same MTM network can be used as a forward dynamics model, inverse dynamics model, or even an offline RL agent. Through extensive experiments in several continuous control tasks, we show that the same MTM network -- i.e. same weights -- can match or outperform specialized networks trained for the aforementioned capabilities. Additionally, we find that state representations learned by MTM can significantly accelerate the learning speed of traditional RL algorithms. Finally, in offline RL benchmarks, we find that MTM is competitive with sp",
    "link": "http://arxiv.org/abs/2305.02968",
    "context": "Title: Masked Trajectory Models for Prediction, Representation, and Control. (arXiv:2305.02968v1 [cs.LG])\nAbstract: We introduce Masked Trajectory Models (MTM) as a generic abstraction for sequential decision making. MTM takes a trajectory, such as a state-action sequence, and aims to reconstruct the trajectory conditioned on random subsets of the same trajectory. By training with a highly randomized masking pattern, MTM learns versatile networks that can take on different roles or capabilities, by simply choosing appropriate masks at inference time. For example, the same MTM network can be used as a forward dynamics model, inverse dynamics model, or even an offline RL agent. Through extensive experiments in several continuous control tasks, we show that the same MTM network -- i.e. same weights -- can match or outperform specialized networks trained for the aforementioned capabilities. Additionally, we find that state representations learned by MTM can significantly accelerate the learning speed of traditional RL algorithms. Finally, in offline RL benchmarks, we find that MTM is competitive with sp",
    "path": "papers/23/05/2305.02968.json",
    "total_tokens": 1074,
    "tldr": "研究介绍了一种用于序列决策制定的通用抽象模型，即蒙版轨迹模型 (MTM)。通过在相同轨迹的随机子集上重构轨迹，MTM 实现了多种能力。同一 MTM 网络在几个连续控制任务中的实验表明，可以与专门为这些任务训练的网络相匹配或胜过其性能。MTM 学习的状态表示有助于加速传统 RL 算法的学习速度。在离线 RL 基准测试中，MTM 表现稳定并具有竞争力。"
}