{
    "title": "Improving Stability in Decision Tree Models. (arXiv:2305.17299v1 [stat.ML])",
    "abstract": "Owing to their inherently interpretable structure, decision trees are commonly used in applications where interpretability is essential. Recent work has focused on improving various aspects of decision trees, including their predictive power and robustness; however, their instability, albeit well-documented, has been addressed to a lesser extent. In this paper, we take a step towards the stabilization of decision tree models through the lens of real-world health care applications due to the relevance of stability and interpretability in this space. We introduce a new distance metric for decision trees and use it to determine a tree's level of stability. We propose a novel methodology to train stable decision trees and investigate the existence of trade-offs that are inherent to decision tree models - including between stability, predictive power, and interpretability. We demonstrate the value of the proposed methodology through an extensive quantitative and qualitative analysis of six ",
    "link": "http://arxiv.org/abs/2305.17299",
    "context": "Title: Improving Stability in Decision Tree Models. (arXiv:2305.17299v1 [stat.ML])\nAbstract: Owing to their inherently interpretable structure, decision trees are commonly used in applications where interpretability is essential. Recent work has focused on improving various aspects of decision trees, including their predictive power and robustness; however, their instability, albeit well-documented, has been addressed to a lesser extent. In this paper, we take a step towards the stabilization of decision tree models through the lens of real-world health care applications due to the relevance of stability and interpretability in this space. We introduce a new distance metric for decision trees and use it to determine a tree's level of stability. We propose a novel methodology to train stable decision trees and investigate the existence of trade-offs that are inherent to decision tree models - including between stability, predictive power, and interpretability. We demonstrate the value of the proposed methodology through an extensive quantitative and qualitative analysis of six ",
    "path": "papers/23/05/2305.17299.json",
    "total_tokens": 920,
    "translated_title": "提高决策树模型的稳定性",
    "translated_abstract": "由于其结构易于理解，决策树通常在需要可解释性的应用中被广泛使用。近期的工作集中于改进决策树的各个方面，包括预测能力和鲁棒性；然而，其不稳定性虽然有充分的记录，但却得到了较少的关注。本文通过实际的医疗应用的视角，提出了稳定化决策树模型的一小步。由于稳定性和可解释性在医疗领域具有重要性，我们介绍了一种新的决策树距离度量，并将其用于确定树的稳定水平。我们提出了一种新的培训稳定决策树的方法，并调查了决策树模型之间不可避免的权衡，包括在稳定性、预测能力和可解释性之间。我们通过对六个数据集的广泛定量和定性分析展示了所提议方法的价值。",
    "tldr": "本文通过医疗应用的视角，提出了一种新的决策树距离度量，并用它来确定树的稳定水平。我们提出了一种新的培训稳定决策树的方法，并探究稳定性、预测能力和可解释性之间不可避免的权衡。",
    "en_tdlr": "This paper proposes a new distance metric for decision trees to determine their level of stability and introduces a novel methodology to train stable decision trees. Trade-offs between stability, predictive power, and interpretability are investigated, and the value of the proposed methodology is demonstrated through extensive analysis of six datasets in the healthcare field."
}