{
    "title": "Self-supervised Predictive Coding Models Encode Speaker and Phonetic Information in Orthogonal Subspaces. (arXiv:2305.12464v2 [cs.CL] UPDATED)",
    "abstract": "Self-supervised speech representations are known to encode both speaker and phonetic information, but how they are distributed in the high-dimensional space remains largely unexplored. We hypothesize that they are encoded in orthogonal subspaces, a property that lends itself to simple disentanglement. Applying principal component analysis to representations of two predictive coding models, we identify two subspaces that capture speaker and phonetic variances, and confirm that they are nearly orthogonal. Based on this property, we propose a new speaker normalization method which collapses the subspace that encodes speaker information, without requiring transcriptions. Probing experiments show that our method effectively eliminates speaker information and outperforms a previous baseline in phone discrimination tasks. Moreover, the approach generalizes and can be used to remove information of unseen speakers.",
    "link": "http://arxiv.org/abs/2305.12464",
    "context": "Title: Self-supervised Predictive Coding Models Encode Speaker and Phonetic Information in Orthogonal Subspaces. (arXiv:2305.12464v2 [cs.CL] UPDATED)\nAbstract: Self-supervised speech representations are known to encode both speaker and phonetic information, but how they are distributed in the high-dimensional space remains largely unexplored. We hypothesize that they are encoded in orthogonal subspaces, a property that lends itself to simple disentanglement. Applying principal component analysis to representations of two predictive coding models, we identify two subspaces that capture speaker and phonetic variances, and confirm that they are nearly orthogonal. Based on this property, we propose a new speaker normalization method which collapses the subspace that encodes speaker information, without requiring transcriptions. Probing experiments show that our method effectively eliminates speaker information and outperforms a previous baseline in phone discrimination tasks. Moreover, the approach generalizes and can be used to remove information of unseen speakers.",
    "path": "papers/23/05/2305.12464.json",
    "total_tokens": 841,
    "translated_title": "自监督预测编码模型用正交子空间编码说话者和语音信息",
    "translated_abstract": "已知自监督语音表示编码了说话者和语音信息，但它们在高维空间中的分布情况仍未深入研究。我们假设它们被编码在正交子空间中，这种特性有助于简单的解缠。应用主成分分析到两个预测编码模型的表示中，我们确定了两个子空间，捕捉到的是说话者和语音变化，并确认它们几乎正交。基于这个特性，我们提出了一种新的说话者归一化方法，它折叠编码说话者信息的子空间，无需转录。探析实验表明，我们的方法有效消除了说话者信息，并在音位辨别任务中优于之前的基线。此外，该方法具有普适性，可用于消除未知说话者的信息。",
    "tldr": "这篇论文提出了一种自监督预测编码模型，可以把说话者和语音信息编码在正交子空间，进而提出一种新的无需转录的说话者归一化方法，有效消除了说话者信息，并在音位辨别任务中优于之前的基线。",
    "en_tdlr": "This paper proposes self-supervised predictive coding models that encode speaker and phonetic information in orthogonal subspaces, and presents a new speaker normalization method that effectively removes speaker information without requiring transcriptions, outperforming previous baselines in phone discrimination tasks."
}