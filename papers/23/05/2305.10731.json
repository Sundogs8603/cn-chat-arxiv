{
    "title": "Analyzing Norm Violations in Live-Stream Chat. (arXiv:2305.10731v1 [cs.CL])",
    "abstract": "Toxic language, such as hate speech, can deter users from participating in online communities and enjoying popular platforms. Previous approaches to detecting toxic language and norm violations have been primarily concerned with conversations from online forums and social media, such as Reddit and Twitter. These approaches are less effective when applied to conversations on live-streaming platforms, such as Twitch and YouTube Live, as each comment is only visible for a limited time and lacks a thread structure that establishes its relationship with other comments. In this work, we share the first NLP study dedicated to detecting norm violations in conversations on live-streaming platforms. We define norm violation categories in live-stream chats and annotate 4,583 moderated comments from Twitch. We articulate several facets of live-stream data that differ from other forums, and demonstrate that existing models perform poorly in this setting. By conducting a user study, we identify the ",
    "link": "http://arxiv.org/abs/2305.10731",
    "context": "Title: Analyzing Norm Violations in Live-Stream Chat. (arXiv:2305.10731v1 [cs.CL])\nAbstract: Toxic language, such as hate speech, can deter users from participating in online communities and enjoying popular platforms. Previous approaches to detecting toxic language and norm violations have been primarily concerned with conversations from online forums and social media, such as Reddit and Twitter. These approaches are less effective when applied to conversations on live-streaming platforms, such as Twitch and YouTube Live, as each comment is only visible for a limited time and lacks a thread structure that establishes its relationship with other comments. In this work, we share the first NLP study dedicated to detecting norm violations in conversations on live-streaming platforms. We define norm violation categories in live-stream chats and annotate 4,583 moderated comments from Twitch. We articulate several facets of live-stream data that differ from other forums, and demonstrate that existing models perform poorly in this setting. By conducting a user study, we identify the ",
    "path": "papers/23/05/2305.10731.json",
    "total_tokens": 908,
    "translated_title": "在直播聊天中分析规范违背现象",
    "translated_abstract": "毒性言语，如仇恨言论，可能会阻止用户参与在线社区和流行平台，影响他们的体验。以前的检测工具主要关注于在线论坛和社交媒体（如Reddit和Twitter）的对话。但是，将这些方法应用于直播平台（如Twitch和YouTube Live）中的对话时，由于每个评论仅可见一段时间，并且缺少与其他评论建立关系的线程结构，因此这些方法的效果较差。本文分享了第一次针对在直播平台上检测规范违背现象的自然语言处理研究。我们在Twitch上对4,583个受过审查的评论进行了分类别标注，并定义了直播聊天中的规范违反类别。我们讨论了直播数据与其他论坛的几个区别，并证明了当前的模型在这种情况下表现不佳。通过一项用户研究，我们确定了文本和语音中规范违背之间的差异，并揭示了直播聊天规范形成的见解。",
    "tldr": "本文分享了第一次针对在直播平台上检测规范违背现象的自然语言处理研究，通过分类别标注和用户研究，揭示了直播聊天规范形成的见解。",
    "en_tdlr": "This article shares the first NLP study dedicated to detecting norm violations in conversations on live-streaming platforms. By annotating and conducting a user study, insights are revealed on how live-stream chat norms are formed."
}