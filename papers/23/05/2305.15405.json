{
    "title": "Textless Low-Resource Speech-to-Speech Translation With Unit Language Models",
    "abstract": "arXiv:2305.15405v2 Announce Type: replace  Abstract: Existing speech-to-speech translation models fall into two camps: textless models trained with hundreds of hours of parallel speech data or unsupervised models that leverage text as an intermediate step. Both approaches limit building speech-to-speech translation models for a wide range of languages, as they exclude languages that are primarily spoken and language pairs that lack large-scale parallel speech data. We present a new framework for training textless low-resource speech-to-speech translation (S2ST) systems that only need dozens of hours of parallel speech data. We reformulate S2ST as a unit-to-unit seq2seq translation task, and start by pretraining a model on large-scale monolingual speech data. Then, we finetune it with a small amount of parallel speech data ($20-60$ hours). Lastly, we improve model performance through an unsupervised backtranslation objective. We train and evaluate our models for English-to-German, Germa",
    "link": "https://arxiv.org/abs/2305.15405",
    "context": "Title: Textless Low-Resource Speech-to-Speech Translation With Unit Language Models\nAbstract: arXiv:2305.15405v2 Announce Type: replace  Abstract: Existing speech-to-speech translation models fall into two camps: textless models trained with hundreds of hours of parallel speech data or unsupervised models that leverage text as an intermediate step. Both approaches limit building speech-to-speech translation models for a wide range of languages, as they exclude languages that are primarily spoken and language pairs that lack large-scale parallel speech data. We present a new framework for training textless low-resource speech-to-speech translation (S2ST) systems that only need dozens of hours of parallel speech data. We reformulate S2ST as a unit-to-unit seq2seq translation task, and start by pretraining a model on large-scale monolingual speech data. Then, we finetune it with a small amount of parallel speech data ($20-60$ hours). Lastly, we improve model performance through an unsupervised backtranslation objective. We train and evaluate our models for English-to-German, Germa",
    "path": "papers/23/05/2305.15405.json",
    "total_tokens": 917,
    "translated_title": "具有单元语言模型的无文本低资源语音到语音翻译",
    "translated_abstract": "现有的语音到语音翻译模型大致分为两类：使用数百小时平行语音数据训练的无文本模型，或者将文本作为中间步骤的无监督模型。这两种方法限制了为广泛语言构建语音到语音翻译模型的可能性，因为它们排除了主要口语的语言以及缺乏大规模平行语音数据的语言对。我们提出了一个新的框架，用于训练只需要几十小时平行语音数据的无文本低资源语音到语音翻译（S2ST）系统。我们将S2ST重新构建为一个单元到单元的序列到序列翻译任务，并首先在大规模单语言语音数据上进行预训练。然后，我们使用少量平行语音数据（$20-60$小时）对其进行微调。最后，我们通过无监督反向翻译目标改善模型性能。我们为英语到德语，德语",
    "tldr": "提出了一种新的框架，用于训练只需要几十小时平行语音数据的无文本低资源语音到语音翻译系统，并通过单元到单元的序列到序列翻译任务和无监督反向翻译目标来提高模型性能",
    "en_tdlr": "Introducing a new framework for training textless low-resource speech-to-speech translation systems with only dozens of hours of parallel speech data, improving model performance through a unit-to-unit seq2seq translation task and an unsupervised backtranslation objective."
}