{
    "title": "Federated Conformal Predictors for Distributed Uncertainty Quantification. (arXiv:2305.17564v2 [cs.LG] UPDATED)",
    "abstract": "Conformal prediction is emerging as a popular paradigm for providing rigorous uncertainty quantification in machine learning since it can be easily applied as a post-processing step to already trained models. In this paper, we extend conformal prediction to the federated learning setting. The main challenge we face is data heterogeneity across the clients - this violates the fundamental tenet of exchangeability required for conformal prediction. We propose a weaker notion of partial exchangeability, better suited to the FL setting, and use it to develop the Federated Conformal Prediction (FCP) framework. We show FCP enjoys rigorous theoretical guarantees and excellent empirical performance on several computer vision and medical imaging datasets. Our results demonstrate a practical approach to incorporating meaningful uncertainty quantification in distributed and heterogeneous environments. We provide code used in our experiments https://github.com/clu5/federated-conformal.",
    "link": "http://arxiv.org/abs/2305.17564",
    "context": "Title: Federated Conformal Predictors for Distributed Uncertainty Quantification. (arXiv:2305.17564v2 [cs.LG] UPDATED)\nAbstract: Conformal prediction is emerging as a popular paradigm for providing rigorous uncertainty quantification in machine learning since it can be easily applied as a post-processing step to already trained models. In this paper, we extend conformal prediction to the federated learning setting. The main challenge we face is data heterogeneity across the clients - this violates the fundamental tenet of exchangeability required for conformal prediction. We propose a weaker notion of partial exchangeability, better suited to the FL setting, and use it to develop the Federated Conformal Prediction (FCP) framework. We show FCP enjoys rigorous theoretical guarantees and excellent empirical performance on several computer vision and medical imaging datasets. Our results demonstrate a practical approach to incorporating meaningful uncertainty quantification in distributed and heterogeneous environments. We provide code used in our experiments https://github.com/clu5/federated-conformal.",
    "path": "papers/23/05/2305.17564.json",
    "total_tokens": 891,
    "translated_title": "分布式不确定性量化的联邦符合预测器",
    "translated_abstract": "由于可以轻松应用为后处理步骤以已经训练过的模型中，符合预测逐渐成为提供机器学习中严格不确定性量化的流行范式。本文将符合预测推广到联邦学习设置。我们面临的主要挑战是客户端之间的数据异质性，这违反了符合预测所需的交换性的基本原则。我们提出了一个较弱的部分交换性概念，更适合于此种情况，并使用它来开发联邦符合预测（FCP）框架。我们展示了FCP具有严格的理论保证，在几个计算机视觉和医学成像数据集上具有优秀的经验性能。我们的结果展示了在分布式和异质环境中融入有意义的不确定性量化的实用方法。我们提供了我们实验中使用的代码 https://github.com/clu5/federated-conformal。",
    "tldr": "本文将符合预测推广到联邦学习设置，提出联邦符合预测（FCP）框架，处理了数据集异质性的问题。实验结果表明，FCP具有严格的理论保证，在分布式和异质环境中有效。",
    "en_tdlr": "This paper extends conformal prediction to the setting of federated learning by proposing the Federated Conformal Prediction (FCP) framework, which addresses the issue of data heterogeneity across clients. The empirical results demonstrate that FCP enjoys rigorous theoretical guarantees and performs well in distributed and heterogeneous environments."
}