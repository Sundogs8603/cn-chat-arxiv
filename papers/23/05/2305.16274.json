{
    "title": "Non-adversarial training of Neural SDEs with signature kernel scores. (arXiv:2305.16274v1 [stat.ML])",
    "abstract": "Neural SDEs are continuous-time generative models for sequential data. State-of-the-art performance for irregular time series generation has been previously obtained by training these models adversarially as GANs. However, as typical for GAN architectures, training is notoriously unstable, often suffers from mode collapse, and requires specialised techniques such as weight clipping and gradient penalty to mitigate these issues. In this paper, we introduce a novel class of scoring rules on pathspace based on signature kernels and use them as objective for training Neural SDEs non-adversarially. By showing strict properness of such kernel scores and consistency of the corresponding estimators, we provide existence and uniqueness guarantees for the minimiser. With this formulation, evaluating the generator-discriminator pair amounts to solving a system of linear path-dependent PDEs which allows for memory-efficient adjoint-based backpropagation. Moreover, because the proposed kernel score",
    "link": "http://arxiv.org/abs/2305.16274",
    "context": "Title: Non-adversarial training of Neural SDEs with signature kernel scores. (arXiv:2305.16274v1 [stat.ML])\nAbstract: Neural SDEs are continuous-time generative models for sequential data. State-of-the-art performance for irregular time series generation has been previously obtained by training these models adversarially as GANs. However, as typical for GAN architectures, training is notoriously unstable, often suffers from mode collapse, and requires specialised techniques such as weight clipping and gradient penalty to mitigate these issues. In this paper, we introduce a novel class of scoring rules on pathspace based on signature kernels and use them as objective for training Neural SDEs non-adversarially. By showing strict properness of such kernel scores and consistency of the corresponding estimators, we provide existence and uniqueness guarantees for the minimiser. With this formulation, evaluating the generator-discriminator pair amounts to solving a system of linear path-dependent PDEs which allows for memory-efficient adjoint-based backpropagation. Moreover, because the proposed kernel score",
    "path": "papers/23/05/2305.16274.json",
    "total_tokens": 921,
    "translated_title": "无对抗训练的神经SDE与签名内核评分",
    "translated_abstract": "神经SDE是用于生成序列数据的连续时间生成模型。之前通过对抗性训练，将这些模型作为GAN获得了无规则时间序列生成的最新成果。然而，像GAN体系结构一样，训练极不稳定，经常受到模式崩溃的困扰，并需要专门的技术，如重量剪切和梯度惩罚，以缓解这些问题。在本文中，我们介绍了一种基于签名内核的路径空间上新型的评分规则，并将其作为非对抗性训练神经SDE的目标。通过展示此类内核分数的严格适当以及相应的估计器的一致性，我们为极小化器提供了存在和唯一性保证。通过这种公式，评估生成器-判别器对等于解决一组线性路径相关的PDE，这允许记忆效率的伴随反向传播。此外，因为所提出的内核分数，我们不需要通过动态编程方法对评分进行微分，这对于计算效率更高。",
    "tldr": "该研究提出一种非对抗性训练神经SDE的新方法，使用基于签名内核的评分规则代替传统的GAN方法。新方法由于不需要进行动态规划运算，具有计算效率更高的特点。",
    "en_tdlr": "This paper proposes a novel non-adversarial training method for neural SDEs, using signature kernel scores instead of traditional GAN methods. The new method has higher computational efficiency as it eliminates the need for dynamic programming operations."
}