{
    "title": "Hardware-aware Training Techniques for Improving Robustness of Ex-Situ Neural Network Transfer onto Passive TiO2 ReRAM Crossbars. (arXiv:2305.18495v1 [cs.AR])",
    "abstract": "Passive resistive random access memory (ReRAM) crossbar arrays, a promising emerging technology used for analog matrix-vector multiplications, are far superior to their active (1T1R) counterparts in terms of the integration density. However, current transfers of neural network weights into the conductance state of the memory devices in the crossbar architecture are accompanied by significant losses in precision due to hardware variabilities such as sneak path currents, biasing scheme effects and conductance tuning imprecision. In this work, training approaches that adapt techniques such as dropout, the reparametrization trick and regularization to TiO2 crossbar variabilities are proposed in order to generate models that are better adapted to their hardware transfers. The viability of this approach is demonstrated by comparing the outputs and precision of the proposed hardware-aware network with those of a regular fully connected network over a few thousand weight transfers using the ha",
    "link": "http://arxiv.org/abs/2305.18495",
    "context": "Title: Hardware-aware Training Techniques for Improving Robustness of Ex-Situ Neural Network Transfer onto Passive TiO2 ReRAM Crossbars. (arXiv:2305.18495v1 [cs.AR])\nAbstract: Passive resistive random access memory (ReRAM) crossbar arrays, a promising emerging technology used for analog matrix-vector multiplications, are far superior to their active (1T1R) counterparts in terms of the integration density. However, current transfers of neural network weights into the conductance state of the memory devices in the crossbar architecture are accompanied by significant losses in precision due to hardware variabilities such as sneak path currents, biasing scheme effects and conductance tuning imprecision. In this work, training approaches that adapt techniques such as dropout, the reparametrization trick and regularization to TiO2 crossbar variabilities are proposed in order to generate models that are better adapted to their hardware transfers. The viability of this approach is demonstrated by comparing the outputs and precision of the proposed hardware-aware network with those of a regular fully connected network over a few thousand weight transfers using the ha",
    "path": "papers/23/05/2305.18495.json",
    "total_tokens": 927,
    "translated_title": "提高Ex-Situ神经网络传输到被动TiO2 ReRAM十字架上的鲁棒性的硬件感知训练技术",
    "translated_abstract": "被动电阻式随机存取存储器（ReRAM）十字架阵列是一种有前途的新兴技术，用于模拟矩阵向量乘法，与主动电阻式晶体管与电阻器的组合（1T1R）相比具有更高的集成密度。然而，由于硬件变异性，如偷跑路径电流、偏置方案效应和电导调谐不准确等，当前将神经网络权重传输到十字架结构中存储器设备的电导态时精度有显著损失。本文提出了将dropout、重新参数化技巧和正则化等方法用于适应TiO2交叉棒的变异性的训练方法，从而生成更适合其硬件传输的模型。通过使用斯坦福大学的硬件模拟器，在数千次权重传输中比较所提出的硬件感知网络和常规全连接网络的输出和精度来演示这种方法的可行性。",
    "tldr": "本文提出了一种通过应用dropout、重新参数化技巧和正则化等训练方法，提高被动TiO2 ReRAM交叉棒硬件传输神经网络权重的精度的方案。",
    "en_tdlr": "This paper proposes a hardware-aware training approach using techniques such as dropout, reparametrization, and regularization to improve the precision of neural network weights transferred onto passive TiO2 ReRAM crossbars, demonstrating its viability through comparison with a regular fully connected network."
}