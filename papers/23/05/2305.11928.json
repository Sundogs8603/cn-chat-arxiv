{
    "title": "Energy-frugal and Interpretable AI Hardware Design using Learning Automata. (arXiv:2305.11928v1 [cs.AI])",
    "abstract": "Energy efficiency is a crucial requirement for enabling powerful artificial intelligence applications at the microedge. Hardware acceleration with frugal architectural allocation is an effective method for reducing energy. Many emerging applications also require the systems design to incorporate interpretable decision models to establish responsibility and transparency. The design needs to provision for additional resources to provide reachable states in real-world data scenarios, defining conflicting design tradeoffs between energy efficiency. is challenging.  Recently a new machine learning algorithm, called the Tsetlin machine, has been proposed. The algorithm is fundamentally based on the principles of finite-state automata and benefits from natural logic underpinning rather than arithmetic. In this paper, we investigate methods of energy-frugal artificial intelligence hardware design by suitably tuning the hyperparameters, while maintaining high learning efficacy. To demonstrate i",
    "link": "http://arxiv.org/abs/2305.11928",
    "context": "Title: Energy-frugal and Interpretable AI Hardware Design using Learning Automata. (arXiv:2305.11928v1 [cs.AI])\nAbstract: Energy efficiency is a crucial requirement for enabling powerful artificial intelligence applications at the microedge. Hardware acceleration with frugal architectural allocation is an effective method for reducing energy. Many emerging applications also require the systems design to incorporate interpretable decision models to establish responsibility and transparency. The design needs to provision for additional resources to provide reachable states in real-world data scenarios, defining conflicting design tradeoffs between energy efficiency. is challenging.  Recently a new machine learning algorithm, called the Tsetlin machine, has been proposed. The algorithm is fundamentally based on the principles of finite-state automata and benefits from natural logic underpinning rather than arithmetic. In this paper, we investigate methods of energy-frugal artificial intelligence hardware design by suitably tuning the hyperparameters, while maintaining high learning efficacy. To demonstrate i",
    "path": "papers/23/05/2305.11928.json",
    "total_tokens": 957,
    "translated_title": "使用学习自动机的节能且可解释AI硬件设计",
    "translated_abstract": "在微边缘计算环境下，能效是实现强大人工智能应用的重要需求。通过节能的计算资源配置实现硬件加速是降低能耗的有效方法。然而，许多新兴应用还需要采用可解释决策模型，以确立责任和透明度。在真实数据场景中提供可达状态需要额外的资源，这给能效设计带来了冲突性的挑战。最近，提出了一种新的机器学习算法——Tsetlin机器，该算法基于有限状态自动机原理，与算术不同，受益于自然逻辑支撑。本文研究了如何通过适当调整超参数来实现节能的人工智能硬件设计，并保持高效的学习效果。为了展示其潜力，我们在不同的优化技术下在可编程逻辑门阵列（FPGAs）上实现了Tsetlin机器算法，并使用标准基准数据集评估其性能。实验结果表明，通过利用学习自动机，我们可以在不牺牲模型的解释性和准确性的情况下，实现显著的能源节约。",
    "tldr": "本论文通过使用学习自动机实现了节能的AI硬件设计，同时保持了模型的解释性和准确性。",
    "en_tdlr": "This paper presents energy-frugal AI hardware design using learning automata and demonstrates the potential of the Tsetlin machine algorithm on FPGAs with different optimization techniques, achieving significant energy savings while maintaining the interpretability and accuracy of the model."
}