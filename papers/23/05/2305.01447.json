{
    "title": "Multimodal Neural Databases. (arXiv:2305.01447v1 [cs.MM])",
    "abstract": "The rise in loosely-structured data available through text, images, and other modalities has called for new ways of querying them. Multimedia Information Retrieval has filled this gap and has witnessed exciting progress in recent years. Tasks such as search and retrieval of extensive multimedia archives have undergone massive performance improvements, driven to a large extent by recent developments in multimodal deep learning. However, methods in this field remain limited in the kinds of queries they support and, in particular, their inability to answer database-like queries. For this reason, inspired by recent work on neural databases, we propose a new framework, which we name Multimodal Neural Databases (MMNDBs). MMNDBs can answer complex database-like queries that involve reasoning over different input modalities, such as text and images, at scale. In this paper, we present the first architecture able to fulfill this set of requirements and test it with several baselines, showing th",
    "link": "http://arxiv.org/abs/2305.01447",
    "context": "Title: Multimodal Neural Databases. (arXiv:2305.01447v1 [cs.MM])\nAbstract: The rise in loosely-structured data available through text, images, and other modalities has called for new ways of querying them. Multimedia Information Retrieval has filled this gap and has witnessed exciting progress in recent years. Tasks such as search and retrieval of extensive multimedia archives have undergone massive performance improvements, driven to a large extent by recent developments in multimodal deep learning. However, methods in this field remain limited in the kinds of queries they support and, in particular, their inability to answer database-like queries. For this reason, inspired by recent work on neural databases, we propose a new framework, which we name Multimodal Neural Databases (MMNDBs). MMNDBs can answer complex database-like queries that involve reasoning over different input modalities, such as text and images, at scale. In this paper, we present the first architecture able to fulfill this set of requirements and test it with several baselines, showing th",
    "path": "papers/23/05/2305.01447.json",
    "total_tokens": 853,
    "translated_title": "多模态神经数据库",
    "translated_abstract": "近年来，文本、图像和其他模态的松散结构数据的增加呼吁新的查询方法。多媒体信息检索填补了这个空白并在最近几年取得了令人兴奋的进展。检索大规模多媒体档案的任务已经经历了巨大的性能提升，这在很大程度上是由于多模态深度学习的最近发展所推动的。然而，这个领域的方法在它们所支持的查询类型上仍然受到限制，尤其是它们无法回答类似数据库的查询。因此，受神经数据库的最新工作启发，我们提出了一个新框架，命名为多模态神经数据库（MMNDBs）。MMNDBs可以回答涉及不同输入模态（例如文本和图像）的推理的复杂类似数据库的查询。在本文中，我们提出了第一个能够满足这一系列要求的架构，并通过几个基线测试了它的性能。",
    "tldr": "本文提出了多模态神经数据库框架（MMNDBs），可以回答涉及文本和图像等不同输入模态的复杂查询，具有类似数据库的功能。",
    "en_tdlr": "This paper proposes a framework called Multimodal Neural Databases (MMNDBs) that can answer complex, database-like queries involving different input modalities such as text and images."
}