{
    "title": "Abductive Commonsense Reasoning Exploiting Mutually Exclusive Explanations. (arXiv:2305.14618v1 [cs.CL])",
    "abstract": "Abductive reasoning aims to find plausible explanations for an event. This style of reasoning is critical for commonsense tasks where there are often multiple plausible explanations. Existing approaches for abductive reasoning in natural language processing (NLP) often rely on manually generated annotations for supervision; however, such annotations can be subjective and biased. Instead of using direct supervision, this work proposes an approach for abductive commonsense reasoning that exploits the fact that only a subset of explanations is correct for a given context. The method uses posterior regularization to enforce a mutual exclusion constraint, encouraging the model to learn the distinction between fluent explanations and plausible ones. We evaluate our approach on a diverse set of abductive reasoning datasets; experimental results show that our approach outperforms or is comparable to directly applying pretrained language models in a zero-shot manner and other knowledge-augmente",
    "link": "http://arxiv.org/abs/2305.14618",
    "context": "Title: Abductive Commonsense Reasoning Exploiting Mutually Exclusive Explanations. (arXiv:2305.14618v1 [cs.CL])\nAbstract: Abductive reasoning aims to find plausible explanations for an event. This style of reasoning is critical for commonsense tasks where there are often multiple plausible explanations. Existing approaches for abductive reasoning in natural language processing (NLP) often rely on manually generated annotations for supervision; however, such annotations can be subjective and biased. Instead of using direct supervision, this work proposes an approach for abductive commonsense reasoning that exploits the fact that only a subset of explanations is correct for a given context. The method uses posterior regularization to enforce a mutual exclusion constraint, encouraging the model to learn the distinction between fluent explanations and plausible ones. We evaluate our approach on a diverse set of abductive reasoning datasets; experimental results show that our approach outperforms or is comparable to directly applying pretrained language models in a zero-shot manner and other knowledge-augmente",
    "path": "papers/23/05/2305.14618.json",
    "total_tokens": 845,
    "translated_title": "通过互斥解释开展诱导式常识推理",
    "translated_abstract": "诱导式推理旨在寻找一个事件的可能解释。在常识任务中，存在着多种合理的解释形式，因此诱导式推理对于这类任务至关重要。现有的自然语言处理中，关于诱导式推理的方法通常依赖于手工标注的数据，但是这种标注往往带有主观性和偏见。本文提出了一种诱导式常识推理的方法，这种方法利用了一个事实，即对于给定的上下文，只有解释的一个子集是正确的。本方法利用后验规范化来施加互斥约束，鼓励模型学习流畅解释和合理的解释之间的区别。我们在各类诱导式推理数据集上对该方法进行了评估；实验结果表明，我们的方法在零-shot情况下优于或与直接应用预训练语言模型和其他知识增强方法相当。",
    "tldr": "本论文提出一种基于互斥解释的诱导式常识推理方法，结果表明在各类诱导式推理数据集上优于或与预训练语言模型和其他知识增强方法相当。"
}