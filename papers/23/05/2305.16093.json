{
    "title": "End-to-End Simultaneous Speech Translation with Differentiable Segmentation. (arXiv:2305.16093v2 [cs.CL] UPDATED)",
    "abstract": "End-to-end simultaneous speech translation (SimulST) outputs translation while receiving the streaming speech inputs (a.k.a. streaming speech translation), and hence needs to segment the speech inputs and then translate based on the current received speech. However, segmenting the speech inputs at unfavorable moments can disrupt the acoustic integrity and adversely affect the performance of the translation model. Therefore, learning to segment the speech inputs at those moments that are beneficial for the translation model to produce high-quality translation is the key to SimulST. Existing SimulST methods, either using the fixed-length segmentation or external segmentation model, always separate segmentation from the underlying translation model, where the gap results in segmentation outcomes that are not necessarily beneficial for the translation process. In this paper, we propose Differentiable Segmentation (DiSeg) for SimulST to directly learn segmentation from the underlying transl",
    "link": "http://arxiv.org/abs/2305.16093",
    "context": "Title: End-to-End Simultaneous Speech Translation with Differentiable Segmentation. (arXiv:2305.16093v2 [cs.CL] UPDATED)\nAbstract: End-to-end simultaneous speech translation (SimulST) outputs translation while receiving the streaming speech inputs (a.k.a. streaming speech translation), and hence needs to segment the speech inputs and then translate based on the current received speech. However, segmenting the speech inputs at unfavorable moments can disrupt the acoustic integrity and adversely affect the performance of the translation model. Therefore, learning to segment the speech inputs at those moments that are beneficial for the translation model to produce high-quality translation is the key to SimulST. Existing SimulST methods, either using the fixed-length segmentation or external segmentation model, always separate segmentation from the underlying translation model, where the gap results in segmentation outcomes that are not necessarily beneficial for the translation process. In this paper, we propose Differentiable Segmentation (DiSeg) for SimulST to directly learn segmentation from the underlying transl",
    "path": "papers/23/05/2305.16093.json",
    "total_tokens": 869,
    "translated_abstract": "端到端同时语音翻译(SimuIST)可以在接收流式语音输入的同时输出翻译结果,因此需要对语音输入进行分段，并基于当前接收到的语音进行翻译。然而，在不利的时刻对语音输入进行分段可能会破坏声学完整性，从而对翻译模型产生负面影响。因此，学习在有利于翻译模型产生高质量翻译的那些时刻分段语音输入是SimulST的关键。现有的SimulST方法，要么使用固定长度的分割方法，要么使用外部分割模型，这两种方法都会将分割和翻译模型分离，这种分离会使分割结果不一定有利于翻译过程。本文提出了一种针对SimulST的可分离分割（DiSeg）方法，直接从基础翻译模型中学习分割，并在翻译质量和实时性方面获得了显著的改进。",
    "tldr": "本文提出了一种针对SimulST的DiSeg方法，该方法可以直接从基础翻译模型中学习分割，并在翻译质量和实时性方面获得了显著的改进。"
}