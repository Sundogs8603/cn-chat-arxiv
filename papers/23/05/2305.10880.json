{
    "title": "Functional sufficient dimension reduction through information maximization with application to classification. (arXiv:2305.10880v1 [stat.ML])",
    "abstract": "Considering the case where the response variable is a categorical variable and the predictor is a random function, two novel functional sufficient dimensional reduction (FSDR) methods are proposed based on mutual information and square loss mutual information. Compared to the classical FSDR methods, such as functional sliced inverse regression and functional sliced average variance estimation, the proposed methods are appealing because they are capable of estimating multiple effective dimension reduction directions in the case of a relatively small number of categories, especially for the binary response. Moreover, the proposed methods do not require the restrictive linear conditional mean assumption and the constant covariance assumption. They avoid the inverse problem of the covariance operator which is often encountered in the functional sufficient dimension reduction. The functional principal component analysis with truncation be used as a regularization mechanism. Under some mild ",
    "link": "http://arxiv.org/abs/2305.10880",
    "context": "Title: Functional sufficient dimension reduction through information maximization with application to classification. (arXiv:2305.10880v1 [stat.ML])\nAbstract: Considering the case where the response variable is a categorical variable and the predictor is a random function, two novel functional sufficient dimensional reduction (FSDR) methods are proposed based on mutual information and square loss mutual information. Compared to the classical FSDR methods, such as functional sliced inverse regression and functional sliced average variance estimation, the proposed methods are appealing because they are capable of estimating multiple effective dimension reduction directions in the case of a relatively small number of categories, especially for the binary response. Moreover, the proposed methods do not require the restrictive linear conditional mean assumption and the constant covariance assumption. They avoid the inverse problem of the covariance operator which is often encountered in the functional sufficient dimension reduction. The functional principal component analysis with truncation be used as a regularization mechanism. Under some mild ",
    "path": "papers/23/05/2305.10880.json",
    "total_tokens": 901,
    "tldr": "本研究提出两种新型的函数充分降维（FSDR）方法，基于互信息和平方损失互信息，不需要限制性线性条件平均值假设和常数协方差假设，能够在相对较少的类别情况下估计多个有效的降维方向，尤其是用于二元响应的情况。",
    "en_tdlr": "This paper proposes two novel functional sufficient dimensional reduction (FSDR) methods based on mutual information and square loss mutual information for the case where the response variable is a categorical variable and the predictor is a random function. These methods are appealing as they can estimate multiple effective dimension reduction directions with a relatively small number of categories, particularly for binary response, and do not require the restrictive linear conditional mean assumption and constant covariance assumption."
}