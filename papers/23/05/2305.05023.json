{
    "title": "Domain Agnostic Image-to-image Translation using Low-Resolution Conditioning. (arXiv:2305.05023v1 [eess.IV])",
    "abstract": "Generally, image-to-image translation (i2i) methods aim at learning mappings across domains with the assumption that the images used for translation share content (e.g., pose) but have their own domain-specific information (a.k.a. style). Conditioned on a target image, such methods extract the target style and combine it with the source image content, keeping coherence between the domains. In our proposal, we depart from this traditional view and instead consider the scenario where the target domain is represented by a very low-resolution (LR) image, proposing a domain-agnostic i2i method for fine-grained problems, where the domains are related. More specifically, our domain-agnostic approach aims at generating an image that combines visual features from the source image with low-frequency information (e.g. pose, color) of the LR target image. To do so, we present a novel approach that relies on training the generative model to produce images that both share distinctive information of ",
    "link": "http://arxiv.org/abs/2305.05023",
    "context": "Title: Domain Agnostic Image-to-image Translation using Low-Resolution Conditioning. (arXiv:2305.05023v1 [eess.IV])\nAbstract: Generally, image-to-image translation (i2i) methods aim at learning mappings across domains with the assumption that the images used for translation share content (e.g., pose) but have their own domain-specific information (a.k.a. style). Conditioned on a target image, such methods extract the target style and combine it with the source image content, keeping coherence between the domains. In our proposal, we depart from this traditional view and instead consider the scenario where the target domain is represented by a very low-resolution (LR) image, proposing a domain-agnostic i2i method for fine-grained problems, where the domains are related. More specifically, our domain-agnostic approach aims at generating an image that combines visual features from the source image with low-frequency information (e.g. pose, color) of the LR target image. To do so, we present a novel approach that relies on training the generative model to produce images that both share distinctive information of ",
    "path": "papers/23/05/2305.05023.json",
    "total_tokens": 812,
    "translated_title": "低分辨率条件下的领域无关的图像翻译",
    "translated_abstract": "图像翻译方法旨在学习跨领域的映射，假定用于翻译的图像共享内容，但具有自己的领域特定信息（即风格）。本文提出了一种领域无关的图像翻译方法，旨在解决细粒度问题，其中领域相关。具体而言，我们的领域无关方法旨在生成一幅图像，将源图像的可视特征与低频信息（例如姿势、颜色）相结合。我们提出了一种新的方法，通过训练生成模型来产生同时具有源图像的独特信息和低分辨率目标图像信息的图像。",
    "tldr": "本文提出了一种低分辨率条件下的领域无关的图像翻译方法，实现了源图像的可视特征与低分辨率目标图像的信息相结合，解决了领域相关的细粒度问题。"
}