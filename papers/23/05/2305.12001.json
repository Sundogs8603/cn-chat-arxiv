{
    "title": "OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models. (arXiv:2305.12001v1 [cs.CL])",
    "abstract": "In this paper, we conduct a thorough investigation into the reasoning capabilities of Large Language Models (LLMs), focusing specifically on the Open Pretrained Transformers (OPT) models as a representative of such models. Our study entails finetuning three different sizes of OPT on a carefully curated reasoning corpus, resulting in two sets of finetuned models: OPT-R, finetuned without explanations, and OPT-RE, finetuned with explanations. We then evaluate all models on 57 out-of-domain tasks drawn from the SUPER-NATURALINSTRUCTIONS benchmark, covering 26 distinct reasoning skills, utilizing three prompting techniques. Through a comprehensive grid of 27 configurations and 6,156 test evaluations, we investigate the dimensions of finetuning, prompting, and scale to understand the role of explanations on different reasoning skills. Our findings reveal that having explanations in the fewshot exemplar has no significant impact on the model's performance when the model is finetuned, while p",
    "link": "http://arxiv.org/abs/2305.12001",
    "context": "Title: OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models. (arXiv:2305.12001v1 [cs.CL])\nAbstract: In this paper, we conduct a thorough investigation into the reasoning capabilities of Large Language Models (LLMs), focusing specifically on the Open Pretrained Transformers (OPT) models as a representative of such models. Our study entails finetuning three different sizes of OPT on a carefully curated reasoning corpus, resulting in two sets of finetuned models: OPT-R, finetuned without explanations, and OPT-RE, finetuned with explanations. We then evaluate all models on 57 out-of-domain tasks drawn from the SUPER-NATURALINSTRUCTIONS benchmark, covering 26 distinct reasoning skills, utilizing three prompting techniques. Through a comprehensive grid of 27 configurations and 6,156 test evaluations, we investigate the dimensions of finetuning, prompting, and scale to understand the role of explanations on different reasoning skills. Our findings reveal that having explanations in the fewshot exemplar has no significant impact on the model's performance when the model is finetuned, while p",
    "path": "papers/23/05/2305.12001.json",
    "total_tokens": 903,
    "translated_title": "OPT-R: 探究解释在大型语言模型微调与提示推理技能中的作用",
    "translated_abstract": "本文对大型语言模型（LLMs）的推理能力进行了全面研究，特别关注代表这种模型的Open Pretrained Transformers（OPT）模型。我们在精心策划的推理语料库上微调了三种不同大小的OPT，得到了两组微调模型：没有解释的OPT-R和带有解释的OPT-RE。然后，我们利用三种提示技术对所有模型在来自SUPER-NATURAL INSTRUCTIONS基准测试的57个域外任务上进行评估，涵盖26个不同的推理技能。通过一个全面的27个配置和6,156个测试评估矩阵，我们研究了微调、提示和规模的维度，以了解在不同推理技能方面解释的作用。我们的研究发现，在模型微调时，fewshot示例中有没有解释对模型的性能没有显著影响，而在提示模型时使用解释可提高模型在某些推理技能上的性能。",
    "tldr": "本文探究了大型语言模型的推理能力，证明解释在模型微调过程中对性能影响不显著，但在提示模型时使用解释可提高模型在某些推理技能上的性能。",
    "en_tdlr": "This paper explores the reasoning abilities of Large Language Models (LLMs), and finds that having explanations in model finetuning doesn't significantly affect performance, while using explanations in prompting can improve model performance in some reasoning skills."
}