{
    "title": "Adaptive PD Control using Deep Reinforcement Learning for Local-Remote Teleoperation with Stochastic Time Delays. (arXiv:2305.16979v2 [cs.AI] UPDATED)",
    "abstract": "Local-remote systems allow robots to execute complex tasks in hazardous environments such as space and nuclear power stations. However, establishing accurate positional mapping between local and remote devices can be difficult due to time delays that can compromise system performance and stability. Enhancing the synchronicity and stability of local-remote systems is vital for enabling robots to interact with environments at greater distances and under highly challenging network conditions, including time delays. We introduce an adaptive control method employing reinforcement learning to tackle the time-delayed control problem. By adjusting controller parameters in real-time, this adaptive controller compensates for stochastic delays and improves synchronicity between local and remote robotic manipulators. To improve the adaptive PD controller's performance, we devise a model-based reinforcement learning approach that effectively incorporates multi-step delays into the learning framewor",
    "link": "http://arxiv.org/abs/2305.16979",
    "context": "Title: Adaptive PD Control using Deep Reinforcement Learning for Local-Remote Teleoperation with Stochastic Time Delays. (arXiv:2305.16979v2 [cs.AI] UPDATED)\nAbstract: Local-remote systems allow robots to execute complex tasks in hazardous environments such as space and nuclear power stations. However, establishing accurate positional mapping between local and remote devices can be difficult due to time delays that can compromise system performance and stability. Enhancing the synchronicity and stability of local-remote systems is vital for enabling robots to interact with environments at greater distances and under highly challenging network conditions, including time delays. We introduce an adaptive control method employing reinforcement learning to tackle the time-delayed control problem. By adjusting controller parameters in real-time, this adaptive controller compensates for stochastic delays and improves synchronicity between local and remote robotic manipulators. To improve the adaptive PD controller's performance, we devise a model-based reinforcement learning approach that effectively incorporates multi-step delays into the learning framewor",
    "path": "papers/23/05/2305.16979.json",
    "total_tokens": 916,
    "translated_title": "使用深度强化学习的自适应PD控制在具有随机时延的局部-远程遥操作中",
    "translated_abstract": "局部-远程系统允许机器人在危险环境中执行复杂任务，如太空和核电站。然而，由于可能威胁到系统性能和稳定性的时延，确立局部和远程设备之间的准确位置映射可能很困难。增强局部-远程系统的同步性和稳定性对于使机器人能够在更远距离和高度挑战的网络环境中与环境交互至关重要，包括时延。我们引入了一种采用强化学习来解决时延控制问题的自适应控制方法。通过实时调整控制器参数，这种自适应控制器可以补偿随机延迟并改善局部和远程机器人操作器之间的同步性。为了提高自适应PD控制器的性能，我们设计了一种基于模型的强化学习方法，有效地将多步延迟纳入到学习框架中。",
    "tldr": "本论文引入了一种使用深度强化学习来解决局部-远程遥操作中的时延问题的自适应PD控制方法，通过实时调整控制器参数，改善同步性和稳定性，并克服了随机延迟带来的挑战。",
    "en_tdlr": "This paper introduces an adaptive PD control method using deep reinforcement learning to address the time-delay problem in local-remote teleoperation. By adjusting controller parameters in real-time, it improves synchronicity and stability, overcoming the challenges posed by stochastic delays."
}