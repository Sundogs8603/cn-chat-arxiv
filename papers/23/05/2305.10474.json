{
    "title": "Preserve Your Own Correlation: A Noise Prior for Video Diffusion Models. (arXiv:2305.10474v1 [cs.CV])",
    "abstract": "Despite tremendous progress in generating high-quality images using diffusion models, synthesizing a sequence of animated frames that are both photorealistic and temporally coherent is still in its infancy. While off-the-shelf billion-scale datasets for image generation are available, collecting similar video data of the same scale is still challenging. Also, training a video diffusion model is computationally much more expensive than its image counterpart. In this work, we explore finetuning a pretrained image diffusion model with video data as a practical solution for the video synthesis task. We find that naively extending the image noise prior to video noise prior in video diffusion leads to sub-optimal performance. Our carefully designed video noise prior leads to substantially better performance. Extensive experimental validation shows that our model, Preserve Your Own Correlation (PYoCo), attains SOTA zero-shot text-to-video results on the UCF-101 and MSR-VTT benchmarks. It also",
    "link": "http://arxiv.org/abs/2305.10474",
    "context": "Title: Preserve Your Own Correlation: A Noise Prior for Video Diffusion Models. (arXiv:2305.10474v1 [cs.CV])\nAbstract: Despite tremendous progress in generating high-quality images using diffusion models, synthesizing a sequence of animated frames that are both photorealistic and temporally coherent is still in its infancy. While off-the-shelf billion-scale datasets for image generation are available, collecting similar video data of the same scale is still challenging. Also, training a video diffusion model is computationally much more expensive than its image counterpart. In this work, we explore finetuning a pretrained image diffusion model with video data as a practical solution for the video synthesis task. We find that naively extending the image noise prior to video noise prior in video diffusion leads to sub-optimal performance. Our carefully designed video noise prior leads to substantially better performance. Extensive experimental validation shows that our model, Preserve Your Own Correlation (PYoCo), attains SOTA zero-shot text-to-video results on the UCF-101 and MSR-VTT benchmarks. It also",
    "path": "papers/23/05/2305.10474.json",
    "total_tokens": 935,
    "translated_title": "保留你自己的相关性：用于视频扩散模型的噪声先验",
    "translated_abstract": "尽管扩散模型在生成高质量图像方面取得了巨大进展，但合成连续的动画帧，既具有光真实感，又具有时间相关性仍处于起步阶段。在可以使用成亿级图像数据集的同时，收集相似规模的视频数据仍然具有挑战性。此外，与其图像对应的模型相比，训练视频扩散模型的计算代价更高。在本文中，我们探讨了使用视频数据微调预训练的图像扩散模型作为视频合成任务的实用解决方案。我们发现，在视频扩散中天真地将图像噪声先验扩展为视频噪声先验会导致次优的性能。我们设计了一种精心设计的视频噪声先验，其在视频扩散中具有显著的更好性能。广泛的实验验证表明，我们的模型 Preserve Your Own Correlation (PYoCo) 在 UCF-101 和 MSR-VTT 基准测试中获得了零样本文本对视频的最佳结果。",
    "tldr": "本论文介绍了一种新的视频噪声先验，用于微调图像扩散模型，以实现更高质量的视频合成。经过广泛的实验验证，该模型已经取得了UCF-101和MSR-VTT基准测试的最佳结果。"
}