{
    "title": "A Sequence-to-Sequence Approach for Arabic Pronoun Resolution. (arXiv:2305.11529v1 [cs.CL])",
    "abstract": "This paper proposes a sequence-to-sequence learning approach for Arabic pronoun resolution, which explores the effectiveness of using advanced natural language processing (NLP) techniques, specifically Bi-LSTM and the BERT pre-trained Language Model, in solving the pronoun resolution problem in Arabic. The proposed approach is evaluated on the AnATAr dataset, and its performance is compared to several baseline models, including traditional machine learning models and handcrafted feature-based models. Our results demonstrate that the proposed model outperforms the baseline models, which include KNN, logistic regression, and SVM, across all metrics. In addition, we explore the effectiveness of various modifications to the model, including concatenating the anaphor text beside the paragraph text as input, adding a mask to focus on candidate scores, and filtering candidates based on gender and number agreement with the anaphor. Our results show that these modifications significantly improv",
    "link": "http://arxiv.org/abs/2305.11529",
    "context": "Title: A Sequence-to-Sequence Approach for Arabic Pronoun Resolution. (arXiv:2305.11529v1 [cs.CL])\nAbstract: This paper proposes a sequence-to-sequence learning approach for Arabic pronoun resolution, which explores the effectiveness of using advanced natural language processing (NLP) techniques, specifically Bi-LSTM and the BERT pre-trained Language Model, in solving the pronoun resolution problem in Arabic. The proposed approach is evaluated on the AnATAr dataset, and its performance is compared to several baseline models, including traditional machine learning models and handcrafted feature-based models. Our results demonstrate that the proposed model outperforms the baseline models, which include KNN, logistic regression, and SVM, across all metrics. In addition, we explore the effectiveness of various modifications to the model, including concatenating the anaphor text beside the paragraph text as input, adding a mask to focus on candidate scores, and filtering candidates based on gender and number agreement with the anaphor. Our results show that these modifications significantly improv",
    "path": "papers/23/05/2305.11529.json",
    "total_tokens": 897,
    "translated_title": "一种用于解决阿拉伯语代词消解问题的序列到序列方法",
    "translated_abstract": "本文提出了一种序列到序列学习方法，探索了使用先进的自然语言处理(NLP)技术，特别是Bi-LSTM和BERT预训练语言模型，在解决阿拉伯语代词消解问题方面的有效性。该方法在AnATAr数据集上进行评估，并与几种基线模型进行比较，包括传统的机器学习模型和手工特征模型。我们的结果表明，该模型在所有指标上都优于基线模型，包括KNN、逻辑回归和SVM。此外，我们探讨了对模型的各种修改的有效性，包括将指代词文本与段落文本连接作为输入、添加掩码以关注候选分数以及基于指代词的性别和数量协议来过滤候选项。我们的结果表明，这些修改显著提高了模型的性能。",
    "tldr": "本文提出了一种序列到序列学习方法，用于解决阿拉伯语代词消解问题。该模型在AnATAr数据集上优于传统的机器学习模型和手工特征模型。研究者还探讨了一些对模型的修改，这些修改显著提高了模型的性能。",
    "en_tdlr": "This paper proposes a sequence-to-sequence learning approach for Arabic pronoun resolution, which outperforms traditional machine learning models and handcrafted feature-based models on the AnATAr dataset. The authors also explore various modifications to the model, which significantly improve its performance."
}