{
    "title": "Point-GCC: Universal Self-supervised 3D Scene Pre-training via Geometry-Color Contrast. (arXiv:2305.19623v1 [cs.CV])",
    "abstract": "Geometry and color information provided by the point clouds are both crucial for 3D scene understanding. Two pieces of information characterize the different aspects of point clouds, but existing methods lack an elaborate design for the discrimination and relevance. Hence we explore a 3D self-supervised paradigm that can better utilize the relations of point cloud information. Specifically, we propose a universal 3D scene pre-training framework via Geometry-Color Contrast (Point-GCC), which aligns geometry and color information using a Siamese network. To take care of actual application tasks, we design (i) hierarchical supervision with point-level contrast and reconstruct and object-level contrast based on the novel deep clustering module to close the gap between pre-training and downstream tasks; (ii) architecture-agnostic backbone to adapt for various downstream models. Benefiting from the object-level representation associated with downstream tasks, Point-GCC can directly evaluate ",
    "link": "http://arxiv.org/abs/2305.19623",
    "context": "Title: Point-GCC: Universal Self-supervised 3D Scene Pre-training via Geometry-Color Contrast. (arXiv:2305.19623v1 [cs.CV])\nAbstract: Geometry and color information provided by the point clouds are both crucial for 3D scene understanding. Two pieces of information characterize the different aspects of point clouds, but existing methods lack an elaborate design for the discrimination and relevance. Hence we explore a 3D self-supervised paradigm that can better utilize the relations of point cloud information. Specifically, we propose a universal 3D scene pre-training framework via Geometry-Color Contrast (Point-GCC), which aligns geometry and color information using a Siamese network. To take care of actual application tasks, we design (i) hierarchical supervision with point-level contrast and reconstruct and object-level contrast based on the novel deep clustering module to close the gap between pre-training and downstream tasks; (ii) architecture-agnostic backbone to adapt for various downstream models. Benefiting from the object-level representation associated with downstream tasks, Point-GCC can directly evaluate ",
    "path": "papers/23/05/2305.19623.json",
    "total_tokens": 869,
    "translated_title": "Point-GCC: 基于几何-颜色对比的通用自监督三维场景预训练",
    "translated_abstract": "点云提供的几何和颜色信息对于三维场景理解都非常重要，然而现有方法在区分和相关性方面缺乏精细设计，因此提出了一种可以更好地利用点云信息关系的三维自监督范式。具体来说，提出了一种通过 Siamese 网络对齐几何和颜色信息的通用三维场景预训练框架 Point-GCC。为了照顾实际应用任务，设计了（i）基于新颖的深度聚类模块的点级对比和重建和物体级对比的分层监督，来缩小预训练和下游任务之间的差距；（ii）架构无关的骨干网络，以适应各种下游模型。由于与下游任务相关联的物体级表示，Point-GCC 可以直接评估。",
    "tldr": "Point-GCC提出了一种通过几何-颜色对比进行通用自监督三维场景预训练的方法，并设计了分层监督和架构无关的骨干网络，以缩小预训练和下游任务之间的差距。"
}