{
    "title": "Evaluation of medium-large Language Models at zero-shot closed book generative question answering. (arXiv:2305.11991v1 [cs.CL])",
    "abstract": "Large language models (LLMs) have garnered significant attention, but the definition of \"large\" lacks clarity. This paper focuses on medium-sized lan-guage models (MLMs), defined as having at least six billion parameters but less than 100 billion. The study evaluates MLMs regarding zero-shot genera-tive question answering, which requires models to provide elaborate answers without external document retrieval. The paper introduces an own test da-taset and presents results from human evaluation. Results show that combin-ing the best answers from different MLMs yielded an overall correct answer rate of 82.7% which is better than the 60.9% of ChatGPT. The best MLM achieved 46.4% and has 7B parameters, which highlights the importance of using appropriate training data for fine-tuning rather than solely relying on the number of parameters. More fine-grained feedback should be used to further improve the quality of answers.",
    "link": "http://arxiv.org/abs/2305.11991",
    "context": "Title: Evaluation of medium-large Language Models at zero-shot closed book generative question answering. (arXiv:2305.11991v1 [cs.CL])\nAbstract: Large language models (LLMs) have garnered significant attention, but the definition of \"large\" lacks clarity. This paper focuses on medium-sized lan-guage models (MLMs), defined as having at least six billion parameters but less than 100 billion. The study evaluates MLMs regarding zero-shot genera-tive question answering, which requires models to provide elaborate answers without external document retrieval. The paper introduces an own test da-taset and presents results from human evaluation. Results show that combin-ing the best answers from different MLMs yielded an overall correct answer rate of 82.7% which is better than the 60.9% of ChatGPT. The best MLM achieved 46.4% and has 7B parameters, which highlights the importance of using appropriate training data for fine-tuning rather than solely relying on the number of parameters. More fine-grained feedback should be used to further improve the quality of answers.",
    "path": "papers/23/05/2305.11991.json",
    "total_tokens": 891,
    "translated_title": "在零-shot封闭生成式问答中评估大小为中型-大型语言模型",
    "translated_abstract": "大型语言模型（LLMs）引起了重要关注，但“大”这个定义缺乏清晰度。本文关注中型语言模型（MLMs），这被定义为具有至少60亿参数但少于1000亿的模型。本研究评估MLMs在零-shot生成式问答方面的表现，这要求模型提供详细的答案而无需外部文档检索。本文引入了一个新的测试数据集，并给出了人类评估的结果，结果显示将不同MLMs的最佳答案组合可以实现82.7%的整体正确率，优于ChatGPT的60.9%。表现最好的MLM实现了46.4%，其具有70亿参数，强调了使用适当的训练数据进行微调的重要性，而不是仅仅依赖于参数数量。更细粒度的反馈应该被用于进一步提高答案的质量。",
    "tldr": "本文评估了大小为中型的语言模型在没有外部检索的情况下完成问答任务的表现，结果表明使用适当的训练数据进行模型微调比单纯依赖参数数量更重要，最好的模型实现了46.4%的正确率。",
    "en_tdlr": "This paper evaluates medium-sized language models' performance on generative question answering without external document retrieval, highlights the importance of appropriate training data in model fine-tuning rather than solely relying on the number of parameters, and achieves 46.4% accuracy with the best model."
}