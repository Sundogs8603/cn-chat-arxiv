{
    "title": "MTLSegFormer: Multi-task Learning with Transformers for Semantic Segmentation in Precision Agriculture. (arXiv:2305.02813v1 [cs.CV])",
    "abstract": "Multi-task learning has proven to be effective in improving the performance of correlated tasks. Most of the existing methods use a backbone to extract initial features with independent branches for each task, and the exchange of information between the branches usually occurs through the concatenation or sum of the feature maps of the branches. However, this type of information exchange does not directly consider the local characteristics of the image nor the level of importance or correlation between the tasks. In this paper, we propose a semantic segmentation method, MTLSegFormer, which combines multi-task learning and attention mechanisms. After the backbone feature extraction, two feature maps are learned for each task. The first map is proposed to learn features related to its task, while the second map is obtained by applying learned visual attention to locally re-weigh the feature maps of the other tasks. In this way, weights are assigned to local regions of the image of other ",
    "link": "http://arxiv.org/abs/2305.02813",
    "context": "Title: MTLSegFormer: Multi-task Learning with Transformers for Semantic Segmentation in Precision Agriculture. (arXiv:2305.02813v1 [cs.CV])\nAbstract: Multi-task learning has proven to be effective in improving the performance of correlated tasks. Most of the existing methods use a backbone to extract initial features with independent branches for each task, and the exchange of information between the branches usually occurs through the concatenation or sum of the feature maps of the branches. However, this type of information exchange does not directly consider the local characteristics of the image nor the level of importance or correlation between the tasks. In this paper, we propose a semantic segmentation method, MTLSegFormer, which combines multi-task learning and attention mechanisms. After the backbone feature extraction, two feature maps are learned for each task. The first map is proposed to learn features related to its task, while the second map is obtained by applying learned visual attention to locally re-weigh the feature maps of the other tasks. In this way, weights are assigned to local regions of the image of other ",
    "path": "papers/23/05/2305.02813.json",
    "total_tokens": 963,
    "translated_title": "基于Transformer的多任务学习在农业精细化中的应用",
    "translated_abstract": "多任务学习已被证明在提高相关任务的性能方面非常有效。大多数现有的方法使用主干网提取独立任务的初始特征，并通过将分支的特征图连接或求和来实现分支之间的信息交换。然而，这种信息交换并没有直接考虑图像的局部特征以及任务间的重要程度或相关性。本文提出了一种语义分割方法MTLSegFormer，它结合了多任务学习和注意机制。在主干网特征提取后，为每个任务学习两个特征图。第一个特征图旨在学习与其任务相关的特征，而第二个特征图是通过应用学习到的视觉注意力来对其他任务的特征图进行局部加权得到的。通过这种方式，为其他任务的图像局部区域分配了权重，显着提高了每个任务的分割性能。我们在精细化农业领域中评估了我们的方法，包括两个任务：作物排查和作物分类。实验结果表明，我们提出的方法在两个任务中均优于现有的最新方法。",
    "tldr": "提出了一种基于Transformer和注意机制的语义分割方法MTLSegFormer，在精细化农业领域中的作物排查和作物分类任务中表现优于现有最新方法。",
    "en_tdlr": "The paper proposes a semantic segmentation method, MTLSegFormer, that combines multi-task learning and attention mechanisms, and outperforms state-of-the-art methods in crop row detection and classification tasks in precision agriculture."
}