{
    "title": "DUB: Discrete Unit Back-translation for Speech Translation. (arXiv:2305.11411v1 [cs.CL])",
    "abstract": "How can speech-to-text translation (ST) perform as well as machine translation (MT)? The key point is to bridge the modality gap between speech and text so that useful MT techniques can be applied to ST. Recently, the approach of representing speech with unsupervised discrete units yields a new way to ease the modality problem. This motivates us to propose Discrete Unit Back-translation (DUB) to answer two questions: (1) Is it better to represent speech with discrete units than with continuous features in direct ST? (2) How much benefit can useful MT techniques bring to ST? With DUB, the back-translation technique can successfully be applied on direct ST and obtains an average boost of 5.5 BLEU on MuST-C En-De/Fr/Es. In the low-resource language scenario, our method achieves comparable performance to existing methods that rely on large-scale external data. Code and models are available at https://github.com/0nutation/DUB.",
    "link": "http://arxiv.org/abs/2305.11411",
    "context": "Title: DUB: Discrete Unit Back-translation for Speech Translation. (arXiv:2305.11411v1 [cs.CL])\nAbstract: How can speech-to-text translation (ST) perform as well as machine translation (MT)? The key point is to bridge the modality gap between speech and text so that useful MT techniques can be applied to ST. Recently, the approach of representing speech with unsupervised discrete units yields a new way to ease the modality problem. This motivates us to propose Discrete Unit Back-translation (DUB) to answer two questions: (1) Is it better to represent speech with discrete units than with continuous features in direct ST? (2) How much benefit can useful MT techniques bring to ST? With DUB, the back-translation technique can successfully be applied on direct ST and obtains an average boost of 5.5 BLEU on MuST-C En-De/Fr/Es. In the low-resource language scenario, our method achieves comparable performance to existing methods that rely on large-scale external data. Code and models are available at https://github.com/0nutation/DUB.",
    "path": "papers/23/05/2305.11411.json",
    "total_tokens": 878,
    "translated_title": "DUB: 离散单元反向翻译用于语音翻译",
    "translated_abstract": "如何使语音到文本翻译（ST）与机器翻译（MT）相当？关键在于弥合语音和文本之间的模态差距，使得有用的MT技术可以应用于ST。最近，用无监督离散单元表示语音方法可以缓解模态问题。这激发了我们提出了离散单元反向翻译（DUB）以回答两个问题：（1）在直接ST中，用离散单元表示语音是否比使用连续特征更好？（2）有用的MT技术可以为ST带来多少收益？通过DUB，反向翻译技术可以成功应用于直接ST，并在MuST-C En-De / Fr / Es上平均提升了5.5 BLEU。在资源受限的语言环境下，我们的方法实现了与依赖大规模外部数据的现有方法相当的性能。代码/models可在https://github.com/0nutation/DUB获取。",
    "tldr": "离散单元反向翻译方法成功将有用的MT技术应用在直接ST上，平均提升了5.5 BLEU，可以缓解语音和文本之间的模态问题。",
    "en_tdlr": "DUB successfully applies useful MT techniques to direct ST through discrete unit back-translation, resulting in an average boost of 5.5 BLEU and easing the modality problem between speech and text."
}