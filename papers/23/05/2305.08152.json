{
    "title": "STORYWARS: A Dataset and Instruction Tuning Baselines for Collaborative Story Understanding and Generation. (arXiv:2305.08152v1 [cs.CL])",
    "abstract": "Collaborative stories, which are texts created through the collaborative efforts of multiple authors with different writing styles and intentions, pose unique challenges for NLP models. Understanding and generating such stories remains an underexplored area due to the lack of open-domain corpora. To address this, we introduce STORYWARS, a new dataset of over 40,000 collaborative stories written by 9,400 different authors from an online platform. We design 12 task types, comprising 7 understanding and 5 generation task types, on STORYWARS, deriving 101 diverse story-related tasks in total as a multi-task benchmark covering all fully-supervised, few-shot, and zero-shot scenarios. Furthermore, we present our instruction-tuned model, INSTRUCTSTORY, for the story tasks showing that instruction tuning, in addition to achieving superior results in zero-shot and few-shot scenarios, can also obtain the best performance on the fully-supervised tasks in STORYWARS, establishing strong multi-task b",
    "link": "http://arxiv.org/abs/2305.08152",
    "context": "Title: STORYWARS: A Dataset and Instruction Tuning Baselines for Collaborative Story Understanding and Generation. (arXiv:2305.08152v1 [cs.CL])\nAbstract: Collaborative stories, which are texts created through the collaborative efforts of multiple authors with different writing styles and intentions, pose unique challenges for NLP models. Understanding and generating such stories remains an underexplored area due to the lack of open-domain corpora. To address this, we introduce STORYWARS, a new dataset of over 40,000 collaborative stories written by 9,400 different authors from an online platform. We design 12 task types, comprising 7 understanding and 5 generation task types, on STORYWARS, deriving 101 diverse story-related tasks in total as a multi-task benchmark covering all fully-supervised, few-shot, and zero-shot scenarios. Furthermore, we present our instruction-tuned model, INSTRUCTSTORY, for the story tasks showing that instruction tuning, in addition to achieving superior results in zero-shot and few-shot scenarios, can also obtain the best performance on the fully-supervised tasks in STORYWARS, establishing strong multi-task b",
    "path": "papers/23/05/2305.08152.json",
    "total_tokens": 935,
    "translated_title": "STORYWARS: 一个协作故事理解和生成的数据集和指令调整基线",
    "translated_abstract": "协作故事是由多名不同写作风格和意图的作者共同创作的文本，对自然语言处理模型提出了独特的挑战。由于缺乏开放领域语料库，理解和生成此类故事仍然是一个较少涉足的领域。为了解决这个问题，我们引入了 STORYWARS，这是一个由在线平台上的9,400多位不同作者撰写的超过40,000个协作故事的新数据集。我们在 STORYWARS 上设计了12种任务类型，包括7种理解和5种生成任务类型，总共推导出101种多样的故事相关任务作为覆盖所有全监督、少样本和零样本场景的多任务基准测试。此外，我们提出了我们的指令调整模型 INSTRUCTSTORY，用于展示处理故事任务，当在零样本和少样本场景下取得卓越结果时，指令调整不仅能够在全监督任务中获得最佳性能，还可以建立强大的多任务基线。",
    "tldr": "该论文提出了一个名为STORYWARS的新数据集，可以用于协作故事理解和生成任务。作者通过指令调整的方式建立了 INSTRUCTSTORY 模型，成功地在全监督、少样本和零样本场景下处理故事任务。",
    "en_tdlr": "The paper introduces a new dataset named STORYWARS for collaborative story understanding and generation task. An instruction-tuned model, INSTRUCTSTORY, is proposed and shows superior results in fully-supervised, few-shot, and zero-shot scenarios."
}