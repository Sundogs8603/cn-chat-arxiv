{
    "title": "Make-An-Audio 2: Temporal-Enhanced Text-to-Audio Generation. (arXiv:2305.18474v1 [cs.SD])",
    "abstract": "Large diffusion models have been successful in text-to-audio (T2A) synthesis tasks, but they often suffer from common issues such as semantic misalignment and poor temporal consistency due to limited natural language understanding and data scarcity. Additionally, 2D spatial structures widely used in T2A works lead to unsatisfactory audio quality when generating variable-length audio samples since they do not adequately prioritize temporal information. To address these challenges, we propose Make-an-Audio 2, a latent diffusion-based T2A method that builds on the success of Make-an-Audio. Our approach includes several techniques to improve semantic alignment and temporal consistency: Firstly, we use pre-trained large language models (LLMs) to parse the text into structured <event & order> pairs for better temporal information capture. We also introduce another structured-text encoder to aid in learning semantic alignment during the diffusion denoising process. To improve the performance ",
    "link": "http://arxiv.org/abs/2305.18474",
    "context": "Title: Make-An-Audio 2: Temporal-Enhanced Text-to-Audio Generation. (arXiv:2305.18474v1 [cs.SD])\nAbstract: Large diffusion models have been successful in text-to-audio (T2A) synthesis tasks, but they often suffer from common issues such as semantic misalignment and poor temporal consistency due to limited natural language understanding and data scarcity. Additionally, 2D spatial structures widely used in T2A works lead to unsatisfactory audio quality when generating variable-length audio samples since they do not adequately prioritize temporal information. To address these challenges, we propose Make-an-Audio 2, a latent diffusion-based T2A method that builds on the success of Make-an-Audio. Our approach includes several techniques to improve semantic alignment and temporal consistency: Firstly, we use pre-trained large language models (LLMs) to parse the text into structured <event & order> pairs for better temporal information capture. We also introduce another structured-text encoder to aid in learning semantic alignment during the diffusion denoising process. To improve the performance ",
    "path": "papers/23/05/2305.18474.json",
    "total_tokens": 937,
    "tldr": "该论文提出了一种增强时序的文字转音频生成技术——Make-an-Audio 2，通过使用大型语言模型解析文本来捕捉时序信息，提高语义对齐和时序一致性。它可用于生成可变长度音频样本，提高音频质量。"
}