{
    "title": "A Closer Look at In-Context Learning under Distribution Shifts. (arXiv:2305.16704v1 [cs.LG])",
    "abstract": "In-context learning, a capability that enables a model to learn from input examples on the fly without necessitating weight updates, is a defining characteristic of large language models. In this work, we follow the setting proposed in (Garg et al., 2022) to better understand the generality and limitations of in-context learning from the lens of the simple yet fundamental task of linear regression. The key question we aim to address is: Are transformers more adept than some natural and simpler architectures at performing in-context learning under varying distribution shifts? To compare transformers, we propose to use a simple architecture based on set-based Multi-Layer Perceptrons (MLPs). We find that both transformers and set-based MLPs exhibit in-context learning under in-distribution evaluations, but transformers more closely emulate the performance of ordinary least squares (OLS). Transformers also display better resilience to mild distribution shifts, where set-based MLPs falter. ",
    "link": "http://arxiv.org/abs/2305.16704",
    "context": "Title: A Closer Look at In-Context Learning under Distribution Shifts. (arXiv:2305.16704v1 [cs.LG])\nAbstract: In-context learning, a capability that enables a model to learn from input examples on the fly without necessitating weight updates, is a defining characteristic of large language models. In this work, we follow the setting proposed in (Garg et al., 2022) to better understand the generality and limitations of in-context learning from the lens of the simple yet fundamental task of linear regression. The key question we aim to address is: Are transformers more adept than some natural and simpler architectures at performing in-context learning under varying distribution shifts? To compare transformers, we propose to use a simple architecture based on set-based Multi-Layer Perceptrons (MLPs). We find that both transformers and set-based MLPs exhibit in-context learning under in-distribution evaluations, but transformers more closely emulate the performance of ordinary least squares (OLS). Transformers also display better resilience to mild distribution shifts, where set-based MLPs falter. ",
    "path": "papers/23/05/2305.16704.json",
    "total_tokens": 923,
    "translated_title": "探究分布漂移下的上下文学习：以线性回归为例",
    "translated_abstract": "上下文学习是大型语言模型的一个定义特征，它使模型能够在不需要进行权重更新的情况下即时地从输入样例中学习。本文旨在通过线性回归这一简单而基础的任务，遵循（Garg et al., 2022）提出的设置，从简单的基于集合的多层感知器（MLP）架构的角度，更好地理解上下文学习的普适性和局限性。我们研究的核心问题是：在变化的分布漂移下，变压器是否比一些自然且更简单的架构更擅长执行上下文学习？我们发现，在分布内评估下，变压器和基于集合的MLP模型都表现出了上下文学习的能力，但是变压器更接近于最小二乘法（OLS）的表现。在分布漂移较小的情况下，变压器的韧性也比基于集合的MLP模型更好。",
    "tldr": "本文探究了分布漂移下的上下文学习，比较了变压器和基于集合的MLP模型的性能，发现二者在分布内评估中都表现出上下文学习的能力，但在防范较小的分布漂移方面，变压器更胜一筹。"
}