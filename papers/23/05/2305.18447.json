{
    "title": "Unleashing the Power of Randomization in Auditing Differentially Private ML. (arXiv:2305.18447v1 [cs.LG])",
    "abstract": "We present a rigorous methodology for auditing differentially private machine learning algorithms by adding multiple carefully designed examples called canaries. We take a first principles approach based on three key components. First, we introduce Lifted Differential Privacy (LiDP) that expands the definition of differential privacy to handle randomized datasets. This gives us the freedom to design randomized canaries. Second, we audit LiDP by trying to distinguish between the model trained with $K$ canaries versus $K - 1$ canaries in the dataset, leaving one canary out. By drawing the canaries i.i.d., LiDP can leverage the symmetry in the design and reuse each privately trained model to run multiple statistical tests, one for each canary. Third, we introduce novel confidence intervals that take advantage of the multiple test statistics by adapting to the empirical higher-order correlations. Together, this new recipe demonstrates significant improvements in sample complexity, both the",
    "link": "http://arxiv.org/abs/2305.18447",
    "context": "Title: Unleashing the Power of Randomization in Auditing Differentially Private ML. (arXiv:2305.18447v1 [cs.LG])\nAbstract: We present a rigorous methodology for auditing differentially private machine learning algorithms by adding multiple carefully designed examples called canaries. We take a first principles approach based on three key components. First, we introduce Lifted Differential Privacy (LiDP) that expands the definition of differential privacy to handle randomized datasets. This gives us the freedom to design randomized canaries. Second, we audit LiDP by trying to distinguish between the model trained with $K$ canaries versus $K - 1$ canaries in the dataset, leaving one canary out. By drawing the canaries i.i.d., LiDP can leverage the symmetry in the design and reuse each privately trained model to run multiple statistical tests, one for each canary. Third, we introduce novel confidence intervals that take advantage of the multiple test statistics by adapting to the empirical higher-order correlations. Together, this new recipe demonstrates significant improvements in sample complexity, both the",
    "path": "papers/23/05/2305.18447.json",
    "total_tokens": 930,
    "translated_title": "发挥随机化在差分隐私机器学习审计中的作用",
    "translated_abstract": "我们提出了一种严格的方法，通过添加多个精心设计的示例(称为canaries)，来审计差分隐私机器学习算法。我们采用基于三个关键组件的第一原则方法。首先，我们介绍了扩展差分隐私定义来处理随机数据集的Lifted Differential Privacy (LiDP)。这赋予了我们设计随机化的canaries的自由。其次，我们通过尝试区分训练有$K$个canaries和训练没有一个canary时的模型来审计LiDP，即留出一个canary。利用canaries的i.i.d，LiDP可以利用设计中的对称性并复用每个私有训练模型来运行多个统计测试，一个针对每个canary。第三，我们引入了新的置信区间，通过适应经验高阶相关性来利用多个测试统计量。总之，这个新配方展示了在样本复杂度方面的显著改进，同时保证了严格的差分隐私。",
    "tldr": "本论文为差分隐私机器学习算法的审计提出了一种严格的方法，通过设计随机化的canaries来增强模型的容错能力和可解释性，同时在样本复杂度方面得到显著改进。",
    "en_tdlr": "This paper proposes a rigorous methodology for auditing differentially private machine learning algorithms by designing randomized examples called canaries, which not only enhances the fault tolerance and interpretability of the model, but also significantly improves the sample complexity. The methodology is based on a first principles approach incorporating Lifted Differential Privacy (LiDP) and novel confidence intervals that adapt to the empirical higher-order correlations."
}