{
    "title": "Toxicity Inspector: A Framework to Evaluate Ground Truth in Toxicity Detection Through Feedback. (arXiv:2305.10433v1 [cs.CL])",
    "abstract": "Toxic language is difficult to define, as it is not monolithic and has many variations in perceptions of toxicity. This challenge of detecting toxic language is increased by the highly contextual and subjectivity of its interpretation, which can degrade the reliability of datasets and negatively affect detection model performance. To fill this void, this paper introduces a toxicity inspector framework that incorporates a human-in-the-loop pipeline with the aim of enhancing the reliability of toxicity benchmark datasets by centering the evaluator's values through an iterative feedback cycle. The centerpiece of this framework is the iterative feedback process, which is guided by two metric types (hard and soft) that provide evaluators and dataset creators with insightful examination to balance the tradeoff between performance gains and toxicity avoidance.",
    "link": "http://arxiv.org/abs/2305.10433",
    "context": "Title: Toxicity Inspector: A Framework to Evaluate Ground Truth in Toxicity Detection Through Feedback. (arXiv:2305.10433v1 [cs.CL])\nAbstract: Toxic language is difficult to define, as it is not monolithic and has many variations in perceptions of toxicity. This challenge of detecting toxic language is increased by the highly contextual and subjectivity of its interpretation, which can degrade the reliability of datasets and negatively affect detection model performance. To fill this void, this paper introduces a toxicity inspector framework that incorporates a human-in-the-loop pipeline with the aim of enhancing the reliability of toxicity benchmark datasets by centering the evaluator's values through an iterative feedback cycle. The centerpiece of this framework is the iterative feedback process, which is guided by two metric types (hard and soft) that provide evaluators and dataset creators with insightful examination to balance the tradeoff between performance gains and toxicity avoidance.",
    "path": "papers/23/05/2305.10433.json",
    "total_tokens": 736,
    "translated_title": "毒性检测与反馈的数据真实性评估框架",
    "translated_abstract": "毒性语言的定义并不明确，因为其存在许多变体和感知差异。其高度的情景依赖性和主观性解释增加了检测毒性语言的挑战，可能会降低数据集的可靠性并对检测模型性能产生负面影响。为填补这一空白，本文介绍了一个毒性检测框架，结合了人工参与的流程，旨在通过迭代反馈循环来提高毒性基准数据集的可靠性，并通过两种指标（硬性和软性）来平衡性能和毒性避免之间的权衡。",
    "tldr": "本文介绍了一个毒性检测框架，通过迭代反馈循环提高毒性数据集的可靠性，并通过两种指标平衡性能和毒性避免之间的权衡。",
    "en_tdlr": "This paper introduces a toxicity detection framework that enhances the reliability of toxicity benchmark datasets through an iterative feedback process guided by two metric types, balancing the tradeoff between performance gains and toxicity avoidance."
}