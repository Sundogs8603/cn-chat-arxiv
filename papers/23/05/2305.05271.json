{
    "title": "Robust Acoustic and Semantic Contextual Biasing in Neural Transducers for Speech Recognition. (arXiv:2305.05271v1 [cs.CL])",
    "abstract": "Attention-based contextual biasing approaches have shown significant improvements in the recognition of generic and/or personal rare-words in End-to-End Automatic Speech Recognition (E2E ASR) systems like neural transducers. These approaches employ cross-attention to bias the model towards specific contextual entities injected as bias-phrases to the model. Prior approaches typically relied on subword encoders for encoding the bias phrases. However, subword tokenizations are coarse and fail to capture granular pronunciation information which is crucial for biasing based on acoustic similarity. In this work, we propose to use lightweight character representations to encode fine-grained pronunciation features to improve contextual biasing guided by acoustic similarity between the audio and the contextual entities (termed acoustic biasing). We further integrate pretrained neural language model (NLM) based encoders to encode the utterance's semantic context along with contextual entities to",
    "link": "http://arxiv.org/abs/2305.05271",
    "context": "Title: Robust Acoustic and Semantic Contextual Biasing in Neural Transducers for Speech Recognition. (arXiv:2305.05271v1 [cs.CL])\nAbstract: Attention-based contextual biasing approaches have shown significant improvements in the recognition of generic and/or personal rare-words in End-to-End Automatic Speech Recognition (E2E ASR) systems like neural transducers. These approaches employ cross-attention to bias the model towards specific contextual entities injected as bias-phrases to the model. Prior approaches typically relied on subword encoders for encoding the bias phrases. However, subword tokenizations are coarse and fail to capture granular pronunciation information which is crucial for biasing based on acoustic similarity. In this work, we propose to use lightweight character representations to encode fine-grained pronunciation features to improve contextual biasing guided by acoustic similarity between the audio and the contextual entities (termed acoustic biasing). We further integrate pretrained neural language model (NLM) based encoders to encode the utterance's semantic context along with contextual entities to",
    "path": "papers/23/05/2305.05271.json",
    "total_tokens": 960,
    "translated_title": "神经变换器中的鲁棒性语音和语义上下文偏置",
    "translated_abstract": "基于注意力机制的上下文偏置方法已经在端到端自动语音识别（E2E ASR）系统中，如神经变换器中，展现出重要的改进，特别是对于大众的或个性化的罕见词的识别更是如此。这些方法采用交叉注意力来将模型偏置于注入为偏置短语的特定上下文实体。先前的方法通常依赖于子单词编码器来编码偏置短语。然而，子单词标记粗糙，无法捕捉关键的发音信息，这对于基于声音相似性的偏置至关重要。在这项工作中，我们提议使用轻量级字符表示来编码细粒度的发音特征，以改善受声音相似性引导的上下文偏置（称为声学偏置）。我们进一步整合预训练的基于神经语言模型(NLM)的编码器，将话语的语义上下文与上下文实体一起编码以提高下文偏置性能。",
    "tldr": "本文提出了一种使用轻量级字符表示编码细粒度发音特征的方法，称为声学偏置，以提高针对声音相似性引导的上下文偏置，在神经变换器等自动语音识别系统性能中重要的改进。"
}