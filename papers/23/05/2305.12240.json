{
    "title": "Bridging Active Exploration and Uncertainty-Aware Deployment Using Probabilistic Ensemble Neural Network Dynamics. (arXiv:2305.12240v2 [cs.RO] UPDATED)",
    "abstract": "In recent years, learning-based control in robotics has gained significant attention due to its capability to address complex tasks in real-world environments. With the advances in machine learning algorithms and computational capabilities, this approach is becoming increasingly important for solving challenging control problems in robotics by learning unknown or partially known robot dynamics. Active exploration, in which a robot directs itself to states that yield the highest information gain, is essential for efficient data collection and minimizing human supervision. Similarly, uncertainty-aware deployment has been a growing concern in robotic control, as uncertain actions informed by the learned model can lead to unstable motions or failure. However, active exploration and uncertainty-aware deployment have been studied independently, and there is limited literature that seamlessly integrates them. This paper presents a unified model-based reinforcement learning framework that brid",
    "link": "http://arxiv.org/abs/2305.12240",
    "context": "Title: Bridging Active Exploration and Uncertainty-Aware Deployment Using Probabilistic Ensemble Neural Network Dynamics. (arXiv:2305.12240v2 [cs.RO] UPDATED)\nAbstract: In recent years, learning-based control in robotics has gained significant attention due to its capability to address complex tasks in real-world environments. With the advances in machine learning algorithms and computational capabilities, this approach is becoming increasingly important for solving challenging control problems in robotics by learning unknown or partially known robot dynamics. Active exploration, in which a robot directs itself to states that yield the highest information gain, is essential for efficient data collection and minimizing human supervision. Similarly, uncertainty-aware deployment has been a growing concern in robotic control, as uncertain actions informed by the learned model can lead to unstable motions or failure. However, active exploration and uncertainty-aware deployment have been studied independently, and there is limited literature that seamlessly integrates them. This paper presents a unified model-based reinforcement learning framework that brid",
    "path": "papers/23/05/2305.12240.json",
    "total_tokens": 1073,
    "translated_title": "基于概率集成神经网络动态学习的主动探索和不确定性感知的机器人控制",
    "translated_abstract": "近年来，机器学习-based的机器人控制因其在解决实际环境中的复杂任务的能力而引起了重视。 随着机器学习算法和计算能力的进步，该方法越来越重要，以通过学习未知或部分已知的机器人动态来解决机器人控制中的挑战性问题。 主动探索是数据有效收集和最小化人类监督的关键，它使机器人指引自己到导致最高信息增益的状态。 同样，不确定性感知是机器人控制中一个不断增长的关注点，因为由所学模型提供支持的不确定动作可能导致不稳定的运动或失败。 但是，主动探索和不确定性感知已经独立研究，并且缺乏无缝集成它们的文献。 本文提出了一个统一的基于模型的强化学习框架，用于桥接机器人控制中的主动探索和不确定性感知。 该框架使用概率集成神经网络动态模型来捕获所学系统动态中的不确定性，并引导机器人在避免不确定区域的同时高效地探索状态空间。 该提出的方法在几个基准任务上表现优于其他最先进的方法，证明了统一框架的有效性。",
    "tldr": "本文提出了一个基于概率集成神经网络动态模型的统一机器人控制框架，用于桥接主动探索和不确定性感知。该方法在几个基准任务上表现出优异的效果。",
    "en_tdlr": "This paper proposes a unified framework for robot control based on a probabilistic ensemble neural network dynamics model, which bridges active exploration and uncertainty-aware deployment. The proposed approach outperforms other state-of-the-art methods on several benchmark tasks."
}