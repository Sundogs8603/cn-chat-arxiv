{
    "title": "Unleashing the Potential of Unsupervised Deep Outlier Detection through Automated Training Stopping. (arXiv:2305.16777v1 [cs.LG])",
    "abstract": "Outlier detection (OD) has received continuous research interests due to its wide applications. With the development of deep learning, increasingly deep OD algorithms are proposed. Despite the availability of numerous deep OD models, existing research has reported that the performance of deep models is extremely sensitive to the configuration of hyperparameters (HPs). However, the selection of HPs for deep OD models remains a notoriously difficult task due to the lack of any labels and long list of HPs. In our study. we shed light on an essential factor, training time, that can introduce significant variation in the performance of deep model. Even the performance is stable across other HPs, training time itself can cause a serious HP sensitivity issue. Motivated by this finding, we are dedicated to formulating a strategy to terminate model training at the optimal iteration. Specifically, we propose a novel metric called loss entropy to internally evaluate the model performance during t",
    "link": "http://arxiv.org/abs/2305.16777",
    "context": "Title: Unleashing the Potential of Unsupervised Deep Outlier Detection through Automated Training Stopping. (arXiv:2305.16777v1 [cs.LG])\nAbstract: Outlier detection (OD) has received continuous research interests due to its wide applications. With the development of deep learning, increasingly deep OD algorithms are proposed. Despite the availability of numerous deep OD models, existing research has reported that the performance of deep models is extremely sensitive to the configuration of hyperparameters (HPs). However, the selection of HPs for deep OD models remains a notoriously difficult task due to the lack of any labels and long list of HPs. In our study. we shed light on an essential factor, training time, that can introduce significant variation in the performance of deep model. Even the performance is stable across other HPs, training time itself can cause a serious HP sensitivity issue. Motivated by this finding, we are dedicated to formulating a strategy to terminate model training at the optimal iteration. Specifically, we propose a novel metric called loss entropy to internally evaluate the model performance during t",
    "path": "papers/23/05/2305.16777.json",
    "total_tokens": 915,
    "translated_abstract": "由于其广泛应用，异常检测（OD）一直受到持续的研究关注。随着深度学习的发展，越来越多的深度OD算法被提出。尽管存在许多深度OD模型，但现有研究报告称，深度模型的性能极其敏感于超参数（HP）的配置。然而，由于缺乏任何标签和长列表的HP，深度OD模型的HP选择仍然是一个臭名昭著的难题。在我们的研究中，我们揭示了一个重要因素——训练时间，它可能会在深度模型的性能中引入显着的变化。即使性能在其他HP上是稳定的，训练时间本身也可能导致严重的HP敏感问题。基于这一发现，我们致力于制定一种策略，在最优迭代中终止模型训练。具体来说，我们提出了一种称为损失熵的新指标，在训练过程中内部评估模型性能。",
    "tldr": "本论文发现训练时间可能引入深度模型性能的显着变化，提出一种称为损失熵的新指标，在最优迭代中终止模型训练。",
    "en_tdlr": "This paper discovers that training time may introduce significant variation in the performance of deep models, proposes a novel metric called loss entropy to evaluate the model performance during training, and formulates a strategy to terminate model training at the optimal iteration."
}