{
    "title": "PrOnto: Language Model Evaluations for 859 Languages",
    "abstract": "arXiv:2305.12612v2 Announce Type: replace  Abstract: Evaluation datasets are critical resources for measuring the quality of pretrained language models. However, due to the high cost of dataset annotation, these resources are scarce for most languages other than English, making it difficult to assess the quality of language models. In this work, we present a new method for evaluation dataset construction which enables any language with a New Testament translation to receive a suite of evaluation datasets suitable for pretrained language model evaluation. The method critically involves aligning verses with those in the New Testament portion of English OntoNotes, and then projecting annotations from English to the target language, with no manual annotation required. We apply this method to 1051 New Testament translations in 859 and make them publicly available. Additionally, we conduct experiments which demonstrate the efficacy of our method for creating evaluation tasks which can assess",
    "link": "https://arxiv.org/abs/2305.12612",
    "context": "Title: PrOnto: Language Model Evaluations for 859 Languages\nAbstract: arXiv:2305.12612v2 Announce Type: replace  Abstract: Evaluation datasets are critical resources for measuring the quality of pretrained language models. However, due to the high cost of dataset annotation, these resources are scarce for most languages other than English, making it difficult to assess the quality of language models. In this work, we present a new method for evaluation dataset construction which enables any language with a New Testament translation to receive a suite of evaluation datasets suitable for pretrained language model evaluation. The method critically involves aligning verses with those in the New Testament portion of English OntoNotes, and then projecting annotations from English to the target language, with no manual annotation required. We apply this method to 1051 New Testament translations in 859 and make them publicly available. Additionally, we conduct experiments which demonstrate the efficacy of our method for creating evaluation tasks which can assess",
    "path": "papers/23/05/2305.12612.json",
    "total_tokens": 926,
    "translated_title": "PrOnto：为859种语言进行语言模型评估",
    "translated_abstract": "arXiv:2305.12612v2 公告类型：替换 摘要：评估数据集对于衡量预训练语言模型的质量至关重要。然而，由于数据集标注成本较高，这些资源对于除英语以外的大多数语言来说是稀缺的，这使得评估语言模型的质量变得困难。在这项工作中，我们提出了一种新的评估数据集构建方法，该方法使得任何一种具有新约翻译的语言都能获得一套适用于预训练语言模型评估的评估数据集。该方法的关键在于将语句与英文OntoNotes新约部分中的语句进行对齐，然后将英文标注投影到目标语言中，无需手动标注。我们将该方法应用于859种语言的1051种新约翻译，并将其公开可用。另外，我们进行了实验证明了我们的方法对于创建能够评估任务的功效。",
    "tldr": "本研究提出了一种新的评估数据集构建方法，可以为任何具有新约翻译的语言提供预训练语言模型评估的评估数据集，无需手动标注，通过将语句与英文OntoNotes中的语句对齐并投影标注到目标语言。这项工作使得在859种语言中进行语言模型评估成为可能。",
    "en_tdlr": "A new method for constructing evaluation datasets is introduced in this work, enabling evaluation of pretrained language models for languages with New Testament translations without manual annotation, achieved by aligning verses with those in English OntoNotes and projecting annotations to the target language. This work makes it possible to evaluate language models in 859 languages."
}