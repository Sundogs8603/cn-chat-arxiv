{
    "title": "Inference at Scale Significance Testing for Large Search and Recommendation Experiments. (arXiv:2305.02461v1 [cs.IR])",
    "abstract": "A number of information retrieval studies have been done to assess which statistical techniques are appropriate for comparing systems. However, these studies are focused on TREC-style experiments, which typically have fewer than 100 topics. There is no similar line of work for large search and recommendation experiments; such studies typically have thousands of topics or users and much sparser relevance judgements, so it is not clear if recommendations for analyzing traditional TREC experiments apply to these settings. In this paper, we empirically study the behavior of significance tests with large search and recommendation evaluation data. Our results show that the Wilcoxon and Sign tests show significantly higher Type-1 error rates for large sample sizes than the bootstrap, randomization and t-tests, which were more consistent with the expected error rate. While the statistical tests displayed differences in their power for smaller sample sizes, they showed no difference in their po",
    "link": "http://arxiv.org/abs/2305.02461",
    "context": "Title: Inference at Scale Significance Testing for Large Search and Recommendation Experiments. (arXiv:2305.02461v1 [cs.IR])\nAbstract: A number of information retrieval studies have been done to assess which statistical techniques are appropriate for comparing systems. However, these studies are focused on TREC-style experiments, which typically have fewer than 100 topics. There is no similar line of work for large search and recommendation experiments; such studies typically have thousands of topics or users and much sparser relevance judgements, so it is not clear if recommendations for analyzing traditional TREC experiments apply to these settings. In this paper, we empirically study the behavior of significance tests with large search and recommendation evaluation data. Our results show that the Wilcoxon and Sign tests show significantly higher Type-1 error rates for large sample sizes than the bootstrap, randomization and t-tests, which were more consistent with the expected error rate. While the statistical tests displayed differences in their power for smaller sample sizes, they showed no difference in their po",
    "path": "papers/23/05/2305.02461.json",
    "total_tokens": 864,
    "translated_title": "大规模搜索和推荐实验的显著性检验",
    "translated_abstract": "许多信息检索研究已经进行了评估，以确定哪种统计技术适用于比较系统。然而，这些研究集中于TREC样式的实验，通常少于100个主题。没有类似的研究适用于大规模搜索和推荐实验；这些研究通常涉及数千个主题或用户以及更稀疏的相关性判断，因此不清楚分析传统TREC实验的建议是否适用于这些情况。在本文中，我们实证研究了大规模搜索和推荐评估数据的显著性检验行为。我们的结果显示，Wilcoxon和Sign测试显示出显著更高的1型错误率，而不是更一致符合预期错误率的bootstrap、随机化和t测试。虽然统计测试在样本较小时显示出功率差异，但在功率相同时显示出没有区别。",
    "tldr": "本文研究了大规模搜索和推荐实验的显著性检验行为，结果发现在大样本下Wilcoxon和Sign测试的1型错误率显著更高，建议在这种情况下使用bootstrap、随机化和t测试。",
    "en_tdlr": "This paper studies the significance testing behavior of large search and recommendation experiments, and the results show that Wilcoxon and Sign tests have significantly higher Type-1 error rates for large sample sizes, and suggest using bootstrap, randomization and t-tests instead."
}