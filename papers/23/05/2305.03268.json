{
    "title": "Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework. (arXiv:2305.03268v1 [cs.CL])",
    "abstract": "As large language models (LLMs) have become the norm in NLP, demonstrating good performance in generation and reasoning tasks, one of its most fatal disadvantages is the lack of factual correctness. Generating unfactual texts not only leads to lower performances but also degrades the trust and validity of their applications. Chain-of-Thought (CoT) prompting improves trust and model performance on complex reasoning tasks by generating interpretable reasoning chains, but still suffers from factuality concerns in knowledge-intensive tasks. In this paper, we propose the Verify-and-Edit framework for CoT prompting, which seeks to increase prediction factuality by post-editing reasoning chains according to external knowledge. Building on top of GPT-3, our framework lead to accuracy improvements in multiple open-domain question-answering tasks.",
    "link": "http://arxiv.org/abs/2305.03268",
    "context": "Title: Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework. (arXiv:2305.03268v1 [cs.CL])\nAbstract: As large language models (LLMs) have become the norm in NLP, demonstrating good performance in generation and reasoning tasks, one of its most fatal disadvantages is the lack of factual correctness. Generating unfactual texts not only leads to lower performances but also degrades the trust and validity of their applications. Chain-of-Thought (CoT) prompting improves trust and model performance on complex reasoning tasks by generating interpretable reasoning chains, but still suffers from factuality concerns in knowledge-intensive tasks. In this paper, we propose the Verify-and-Edit framework for CoT prompting, which seeks to increase prediction factuality by post-editing reasoning chains according to external knowledge. Building on top of GPT-3, our framework lead to accuracy improvements in multiple open-domain question-answering tasks.",
    "path": "papers/23/05/2305.03268.json",
    "total_tokens": 787,
    "translated_title": "Verify-and-Edit: 一种知识增强的思路链框架",
    "translated_abstract": "随着大规模语言模型（LLMs）在NLP中成为常态，在生成和推理任务中表现良好，其最致命的缺点之一是缺乏事实正确性。生成不准确的文本不仅导致表现下降，而且降低了其应用的信任和有效性。思路链（CoT）提示通过生成可解释的推理链，在复杂的推理任务上提高信任和模型性能，但在知识密集型任务中仍存在事实问题。本文提出了Verify-and-Edit框架，用于CoT提示，该框架通过根据外部知识后编辑推理链，从而提高预测的准确性。在GPT-3的基础上构建的我们的框架在多个开放领域的问答任务中提高了准确性。",
    "tldr": "本文介绍了Verify-and-Edit框架，该框架通过根据外部知识后编辑推理链，提高CoT提示的预测准确性。",
    "en_tdlr": "This paper proposes the Verify-and-Edit framework for CoT prompting, which aims to increase prediction factuality by post-editing reasoning chains according to external knowledge, leading to accuracy improvements in multiple open-domain question-answering tasks."
}