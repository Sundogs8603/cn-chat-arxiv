{
    "title": "Knowledge Transfer from Teachers to Learners in Growing-Batch Reinforcement Learning. (arXiv:2305.03870v1 [cs.LG])",
    "abstract": "Standard approaches to sequential decision-making exploit an agent's ability to continually interact with its environment and improve its control policy. However, due to safety, ethical, and practicality constraints, this type of trial-and-error experimentation is often infeasible in many real-world domains such as healthcare and robotics. Instead, control policies in these domains are typically trained offline from previously logged data or in a growing-batch manner. In this setting a fixed policy is deployed to the environment and used to gather an entire batch of new data before being aggregated with past batches and used to update the policy. This improvement cycle can then be repeated multiple times. While a limited number of such cycles is feasible in real-world domains, the quantity and diversity of the resulting data are much lower than in the standard continually-interacting approach. However, data collection in these domains is often performed in conjunction with human expert",
    "link": "http://arxiv.org/abs/2305.03870",
    "context": "Title: Knowledge Transfer from Teachers to Learners in Growing-Batch Reinforcement Learning. (arXiv:2305.03870v1 [cs.LG])\nAbstract: Standard approaches to sequential decision-making exploit an agent's ability to continually interact with its environment and improve its control policy. However, due to safety, ethical, and practicality constraints, this type of trial-and-error experimentation is often infeasible in many real-world domains such as healthcare and robotics. Instead, control policies in these domains are typically trained offline from previously logged data or in a growing-batch manner. In this setting a fixed policy is deployed to the environment and used to gather an entire batch of new data before being aggregated with past batches and used to update the policy. This improvement cycle can then be repeated multiple times. While a limited number of such cycles is feasible in real-world domains, the quantity and diversity of the resulting data are much lower than in the standard continually-interacting approach. However, data collection in these domains is often performed in conjunction with human expert",
    "path": "papers/23/05/2305.03870.json",
    "total_tokens": 905,
    "translated_title": "在增长批量强化学习中教师向学习者的知识转移",
    "translated_abstract": "序贯决策制定的标准方法利用了智能体不断与其环境交互和改善其控制策略的能力。然而，由于安全、伦理和实用性的限制，这种试错实验方法在许多实际领域（如医疗保健和机器人技术）中往往不可行。在这种情况下，这些领域中的控制策略通常是通过以先前记录的数据为基础进行离线训练或逐步扩展进行训练的。在这个设置中，固定的策略被部署到环境中，并用于收集一整个批次的新数据，然后与过去的批次汇总并用于更新策略。可以多次重复这个改进周期。虽然在实际领域中有限数量的这样的周期是可行的，但产生的数据数量和多样性远远低于标准的不断交互方法。但是，在这些领域中进行数据收集通常是与人类专家协作的。",
    "tldr": "本研究讨论了实际领域中离线训练或增长批量训练的限制，提出了一种教师向学习者进行知识转移的方法，使得数据数量和多样性得到提高。",
    "en_tdlr": "This study discusses the limitations of offline or growing-batch training in real-world domains, and proposes a method of knowledge transfer from teachers to learners, which improves the quantity and diversity of data."
}