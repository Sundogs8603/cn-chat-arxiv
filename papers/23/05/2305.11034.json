{
    "title": "Trading Syntax Trees for Wordpieces: Target-oriented Opinion Words Extraction with Wordpieces and Aspect Enhancement. (arXiv:2305.11034v1 [cs.CL])",
    "abstract": "State-of-the-art target-oriented opinion word extraction (TOWE) models typically use BERT-based text encoders that operate on the word level, along with graph convolutional networks (GCNs) that incorporate syntactic information extracted from syntax trees. These methods achieve limited gains with GCNs and have difficulty using BERT wordpieces. Meanwhile, BERT wordpieces are known to be effective at representing rare words or words with insufficient context information. To address this issue, this work trades syntax trees for BERT wordpieces by entirely removing the GCN component from the methods' architectures. To enhance TOWE performance, we tackle the issue of aspect representation loss during encoding. Instead of solely utilizing a sentence as the input, we use a sentence-aspect pair. Our relatively simple approach achieves state-of-the-art results on benchmark datasets and should serve as a strong baseline for further research.",
    "link": "http://arxiv.org/abs/2305.11034",
    "context": "Title: Trading Syntax Trees for Wordpieces: Target-oriented Opinion Words Extraction with Wordpieces and Aspect Enhancement. (arXiv:2305.11034v1 [cs.CL])\nAbstract: State-of-the-art target-oriented opinion word extraction (TOWE) models typically use BERT-based text encoders that operate on the word level, along with graph convolutional networks (GCNs) that incorporate syntactic information extracted from syntax trees. These methods achieve limited gains with GCNs and have difficulty using BERT wordpieces. Meanwhile, BERT wordpieces are known to be effective at representing rare words or words with insufficient context information. To address this issue, this work trades syntax trees for BERT wordpieces by entirely removing the GCN component from the methods' architectures. To enhance TOWE performance, we tackle the issue of aspect representation loss during encoding. Instead of solely utilizing a sentence as the input, we use a sentence-aspect pair. Our relatively simple approach achieves state-of-the-art results on benchmark datasets and should serve as a strong baseline for further research.",
    "path": "papers/23/05/2305.11034.json",
    "total_tokens": 887,
    "translated_title": "通过使用Wordpieces和增强Aspect来进行以目标为导向的意见词提取",
    "translated_abstract": "目前最先进的以目标为导向的意见词提取（TOWE）模型通常使用基于BERT的文本编码器，操作在单词级别上，以及图卷积网络（GCN），这些网络可以将从句法树中提取的句法信息纳入模型中。然而，这些方法在使用GCN时仅取得了有限的增益，并且使用BERT wordpieces时存在困难。与此同时，已知BERT wordpieces在表示罕见的单词或上下文信息不足的单词方面非常有效。为解决这个问题，本文通过完全消除方法结构中的GCN组件，以Wordpieces来交换句法树。为了增强TOWE的性能，我们解决了在编码过程中方面表示丢失的问题。与其仅仅使用句子作为输入，我们使用句子 - 方面对。我们的相对简单的方法在基准数据集上取得了最先进的结果，并应作为进一步研究的强有力基线。",
    "tldr": "本文提出了一种使用Wordpieces替换语法树来进行以目标为导向的意见词提取的方法，并使用句子 - 方面对来增强性能。该方法在基准数据集上取得了最先进的结果。",
    "en_tdlr": "This paper proposes a method for target-oriented opinion word extraction that trades syntax trees for BERT wordpieces and enhances performance through sentence-aspect pairs. The relatively simple approach achieves state-of-the-art results on benchmark datasets and serves as a strong baseline for further research."
}