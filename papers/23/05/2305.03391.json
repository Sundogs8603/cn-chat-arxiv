{
    "title": "Compressing audio CNNs with graph centrality based filter pruning. (arXiv:2305.03391v1 [cs.SD])",
    "abstract": "Convolutional neural networks (CNNs) are commonplace in high-performing solutions to many real-world problems, such as audio classification. CNNs have many parameters and filters, with some having a larger impact on the performance than others. This means that networks may contain many unnecessary filters, increasing a CNN's computation and memory requirements while providing limited performance benefits. To make CNNs more efficient, we propose a pruning framework that eliminates filters with the highest \"commonality\". We measure this commonality using the graph-theoretic concept of \"centrality\". We hypothesise that a filter with a high centrality should be eliminated as it represents commonality and can be replaced by other filters without affecting the performance of a network much. An experimental evaluation of the proposed framework is performed on acoustic scene classification and audio tagging. On the DCASE 2021 Task 1A baseline network, our proposed method reduces computations p",
    "link": "http://arxiv.org/abs/2305.03391",
    "context": "Title: Compressing audio CNNs with graph centrality based filter pruning. (arXiv:2305.03391v1 [cs.SD])\nAbstract: Convolutional neural networks (CNNs) are commonplace in high-performing solutions to many real-world problems, such as audio classification. CNNs have many parameters and filters, with some having a larger impact on the performance than others. This means that networks may contain many unnecessary filters, increasing a CNN's computation and memory requirements while providing limited performance benefits. To make CNNs more efficient, we propose a pruning framework that eliminates filters with the highest \"commonality\". We measure this commonality using the graph-theoretic concept of \"centrality\". We hypothesise that a filter with a high centrality should be eliminated as it represents commonality and can be replaced by other filters without affecting the performance of a network much. An experimental evaluation of the proposed framework is performed on acoustic scene classification and audio tagging. On the DCASE 2021 Task 1A baseline network, our proposed method reduces computations p",
    "path": "papers/23/05/2305.03391.json",
    "total_tokens": 898,
    "translated_title": "基于图中心性滤波剪枝的音频卷积神经网络压缩",
    "translated_abstract": "卷积神经网络（CNN）在解决许多现实世界问题，如音频分类中，已经成为常见的高性能解决方案。但是，CNN具有许多参数和滤波器，其中一些对性能的影响比其他更大。这意味着网络可能包含许多不必要的滤波器，增加了CNN的计算和内存需求，同时提供有限的性能优势。为了使CNN更高效，我们提出了一种剪枝框架，消除具有最高“共通性”的滤波器。我们使用图论的“中心性”概念来衡量这种共通性。我们假设具有高中心性的滤波器应该被消除，因为它代表了共通性，并且可以用其他滤波器替换而不太影响网络的性能。我们对提出的框架进行了实验评估，应用于声学场景分类和音频标记。在DCASE 2021任务1A基线网络上，我们的方法减少了95％的计算和97％的存储。",
    "tldr": "本文提出一种基于图中心性的滤波器剪枝压缩框架，用于音频卷积神经网络，该方法可减少95％的计算和97％的存储。",
    "en_tdlr": "This paper proposes a graph centrality based filter pruning framework for compressing audio CNNs. The proposed method reduces computations by 95% and storage by 97%."
}