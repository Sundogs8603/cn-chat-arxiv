{
    "title": "Meta-Polyp: a baseline for efficient Polyp segmentation. (arXiv:2305.07848v1 [eess.IV])",
    "abstract": "In recent years, polyp segmentation has gained significant importance, and many methods have been developed using CNN, Vision Transformer, and Transformer techniques to achieve competitive results. However, these methods often face difficulties when dealing with out-of-distribution datasets, missing boundaries, and small polyps. In 2022, Meta-Former was introduced as a new baseline for vision, which not only improved the performance of multi-task computer vision but also addressed the limitations of the Vision Transformer and CNN family backbones. To further enhance segmentation, we propose a fusion of Meta-Former with UNet, along with the introduction of a Multi-scale Upsampling block with a level-up combination in the decoder stage to enhance the texture, also we propose the Convformer block base on the idea of the Meta-former to enhance the crucial information of the local feature. These blocks enable the combination of global information, such as the overall shape of the polyp, wit",
    "link": "http://arxiv.org/abs/2305.07848",
    "context": "Title: Meta-Polyp: a baseline for efficient Polyp segmentation. (arXiv:2305.07848v1 [eess.IV])\nAbstract: In recent years, polyp segmentation has gained significant importance, and many methods have been developed using CNN, Vision Transformer, and Transformer techniques to achieve competitive results. However, these methods often face difficulties when dealing with out-of-distribution datasets, missing boundaries, and small polyps. In 2022, Meta-Former was introduced as a new baseline for vision, which not only improved the performance of multi-task computer vision but also addressed the limitations of the Vision Transformer and CNN family backbones. To further enhance segmentation, we propose a fusion of Meta-Former with UNet, along with the introduction of a Multi-scale Upsampling block with a level-up combination in the decoder stage to enhance the texture, also we propose the Convformer block base on the idea of the Meta-former to enhance the crucial information of the local feature. These blocks enable the combination of global information, such as the overall shape of the polyp, wit",
    "path": "papers/23/05/2305.07848.json",
    "total_tokens": 916,
    "translated_title": "Meta-Polyp：高效息肉分割的基准线。",
    "translated_abstract": "近年来，息肉分割变得越来越重要，并且许多方法利用CNN、Vision Transformer和Transformer技术开发以实现竞争性结果。然而，这些方法在处理分布外数据集、缺失边界和小息肉时经常遇到困难。在2022年，Meta-Former作为一种新的视觉基准线被引入，它不仅提高了多任务计算机视觉的性能，而且解决了Vision Transformer和CNN家族骨架的局限性。为了进一步增强分割，我们提出了Meta-Former与UNet的融合，同时在解码器阶段引入了多尺度上采样块与级联组合，以增强纹理；此外，我们提出了Convformer块，基于Meta-Former的思想，以加强局部特征的关键信息。这些块将全局信息（例如息肉的整体形状）与局部信息相结合，提高了进行息肉分割的效率。",
    "tldr": "本研究提出Meta-Polyp，将Meta-Former与UNet融合并引入多尺度上采样块和Convformer块，解决了CNN和Vision Transformer在处理分布外数据集、缺失边界和小息肉时遇到的困难，提高了息肉分割的效率。",
    "en_tdlr": "The proposed Meta-Polyp method combines Meta-Former and UNet with multi-scale upsampling and Convformer block to improve polyp segmentation efficiency, addressing the limitations faced by CNN and Vision Transformer when dealing with out-of-distribution datasets, missing boundaries, and small polyps."
}