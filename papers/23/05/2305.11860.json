{
    "title": "Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs. (arXiv:2305.11860v1 [cs.CL])",
    "abstract": "A popular approach for improving the correctness of output from large language models (LLMs) is Self-Consistency - poll the LLM multiple times and output the most frequent solution. Existing Self-Consistency techniques always draw a constant number of samples per question, where a better approach will be to non-uniformly distribute the available budget based on the amount of agreement in the samples drawn so far. In response, we introduce Adaptive-Consistency, a cost-efficient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion. Our experiments over 13 datasets and two LLMs demonstrate that Adaptive-Consistency reduces sample budget by up to 6.0 times with an average accuracy drop of less than 0.1%.",
    "link": "http://arxiv.org/abs/2305.11860",
    "context": "Title: Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs. (arXiv:2305.11860v1 [cs.CL])\nAbstract: A popular approach for improving the correctness of output from large language models (LLMs) is Self-Consistency - poll the LLM multiple times and output the most frequent solution. Existing Self-Consistency techniques always draw a constant number of samples per question, where a better approach will be to non-uniformly distribute the available budget based on the amount of agreement in the samples drawn so far. In response, we introduce Adaptive-Consistency, a cost-efficient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion. Our experiments over 13 datasets and two LLMs demonstrate that Adaptive-Consistency reduces sample budget by up to 6.0 times with an average accuracy drop of less than 0.1%.",
    "path": "papers/23/05/2305.11860.json",
    "total_tokens": 819,
    "translated_title": "分步采样：用自适应一致性提高大型语言模型的有效推理",
    "translated_abstract": "改良大型语言模型 (LLMs) 输出正确性的一个流行方法是使用自一致性——对 LLM 进行多次投票并输出最频繁的解决方案。现有的自一致性技术都是每个问题都会固定采集一定数量的样本，而更好的方法是根据已经采集到的样本之间的一致性非均匀地分配预算。为此，我们提出了一种名为自适应一致性 (Adaptive-Consistency) 的成本有效、与模型无关的技术，它使用轻量级停止准则动态调整每个问题的样本数量。我们在 13 个数据集和两个 LLM 上的实验表明，自适应一致性可以将样本预算降低多达 6 倍，并且平均准确度降低不到 0.1%。",
    "tldr": "本文提出了一种名为自适应一致性 (Adaptive-Consistency) 的技术，可以动态调整每个问题的样本数量，从而有效减少样本预算，并较小程度地降低了平均准确度",
    "en_tdlr": "This paper proposes a cost-efficient and model-agnostic technique called Adaptive-Consistency, which dynamically adjusts the number of samples per question, to reduce sample budget while maintaining high accuracy for output from large language models."
}