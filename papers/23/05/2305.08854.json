{
    "title": "Laughing Matters: Introducing Laughing-Face Generation using Diffusion Models. (arXiv:2305.08854v2 [cs.CV] UPDATED)",
    "abstract": "Speech-driven animation has gained significant traction in recent years, with current methods achieving near-photorealistic results. However, the field remains underexplored regarding non-verbal communication despite evidence demonstrating its importance in human interaction. In particular, generating laughter sequences presents a unique challenge due to the intricacy and nuances of this behaviour. This paper aims to bridge this gap by proposing a novel model capable of generating realistic laughter sequences, given a still portrait and an audio clip containing laughter. We highlight the failure cases of traditional facial animation methods and leverage recent advances in diffusion models to produce convincing laughter videos. We train our model on a diverse set of laughter datasets and introduce an evaluation metric specifically designed for laughter. When compared with previous speech-driven approaches, our model achieves state-of-the-art performance across all metrics, even when the",
    "link": "http://arxiv.org/abs/2305.08854",
    "context": "Title: Laughing Matters: Introducing Laughing-Face Generation using Diffusion Models. (arXiv:2305.08854v2 [cs.CV] UPDATED)\nAbstract: Speech-driven animation has gained significant traction in recent years, with current methods achieving near-photorealistic results. However, the field remains underexplored regarding non-verbal communication despite evidence demonstrating its importance in human interaction. In particular, generating laughter sequences presents a unique challenge due to the intricacy and nuances of this behaviour. This paper aims to bridge this gap by proposing a novel model capable of generating realistic laughter sequences, given a still portrait and an audio clip containing laughter. We highlight the failure cases of traditional facial animation methods and leverage recent advances in diffusion models to produce convincing laughter videos. We train our model on a diverse set of laughter datasets and introduce an evaluation metric specifically designed for laughter. When compared with previous speech-driven approaches, our model achieves state-of-the-art performance across all metrics, even when the",
    "path": "papers/23/05/2305.08854.json",
    "total_tokens": 810,
    "translated_title": "笑声很重要：引入使用扩散模型生成笑脸的方法",
    "translated_abstract": "近年来，基于语音的动画在提高真实感方面取得了显著进展，但在非语言交流方面仍然很少有研究。本文提出了一种新颖的模型，能够根据静态肖像和包含笑声的音频剪辑生成逼真的笑脸序列。我们强调了传统面部动画方法的失败案例，并利用最近扩散模型的进展产生令人信服的笑脸视频。我们使用各种各样的笑声数据集对模型进行训练，并引入了一种专门设计用于笑声的评估指标。与之前的基于语音的方法相比，我们的模型在所有指标上均取得了最先进的性能，甚至在...",
    "tldr": "该论文提出了一种新颖的模型，利用扩散模型生成逼真的笑脸序列，以填补非语言交流领域的研究空白。与传统方法相比，该模型在所有指标上都取得了最先进的性能。",
    "en_tdlr": "This paper proposes a novel model that utilizes diffusion models to generate realistic sequences of laughing faces, addressing the underexplored area of non-verbal communication. Compared to traditional methods, the model achieves state-of-the-art performance across all metrics."
}