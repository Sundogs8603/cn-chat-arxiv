{
    "title": "Causal Interventions-based Few-Shot Named Entity Recognition. (arXiv:2305.01914v1 [cs.CL])",
    "abstract": "Few-shot named entity recognition (NER) systems aims at recognizing new classes of entities based on a few labeled samples. A significant challenge in the few-shot regime is prone to overfitting than the tasks with abundant samples. The heavy overfitting in few-shot learning is mainly led by spurious correlation caused by the few samples selection bias. To alleviate the problem of the spurious correlation in the few-shot NER, in this paper, we propose a causal intervention-based few-shot NER method. Based on the prototypical network, the method intervenes in the context and prototype via backdoor adjustment during training. In particular, intervening in the context of the one-shot scenario is very difficult, so we intervene in the prototype via incremental learning, which can also avoid catastrophic forgetting. Our experiments on different benchmarks show that our approach achieves new state-of-the-art results (achieving up to 29% absolute improvement and 12% on average for all tasks).",
    "link": "http://arxiv.org/abs/2305.01914",
    "context": "Title: Causal Interventions-based Few-Shot Named Entity Recognition. (arXiv:2305.01914v1 [cs.CL])\nAbstract: Few-shot named entity recognition (NER) systems aims at recognizing new classes of entities based on a few labeled samples. A significant challenge in the few-shot regime is prone to overfitting than the tasks with abundant samples. The heavy overfitting in few-shot learning is mainly led by spurious correlation caused by the few samples selection bias. To alleviate the problem of the spurious correlation in the few-shot NER, in this paper, we propose a causal intervention-based few-shot NER method. Based on the prototypical network, the method intervenes in the context and prototype via backdoor adjustment during training. In particular, intervening in the context of the one-shot scenario is very difficult, so we intervene in the prototype via incremental learning, which can also avoid catastrophic forgetting. Our experiments on different benchmarks show that our approach achieves new state-of-the-art results (achieving up to 29% absolute improvement and 12% on average for all tasks).",
    "path": "papers/23/05/2305.01914.json",
    "total_tokens": 887,
    "translated_title": "基于因果干预的小样本命名实体识别",
    "translated_abstract": "小样本命名实体识别系统旨在基于少量标记样本，识别新类别的实体。在小样本情况下，与大量样本任务相比，系统容易出现过度拟合的问题。小样本学习中的过度拟合主要是由少样本选择偏差导致的虚假相关性引起的。为了缓解小样本命名实体识别中虚假相关性的问题，本文提出了一种基于因果干预的小样本命名实体识别方法。该方法基于原型网络，在训练期间通过后门调整介入上下文和原型。特别是，介入一个样本场景的上下文非常困难，因此我们通过增量学习来介入原型，这也可以避免灾难性忘却的问题。我们在不同的基准测试上进行了实验，结果表明该方法实现了新的最优结果（对于所有任务，平均能够实现29％的绝对提高和12％的提高）。",
    "tldr": "本文提出了一种基于因果干预的小样本命名实体识别方法，该方法使用增量学习来介入原型以避免灾难性忘却问题，实现了在不同基准测试上新的最优结果。",
    "en_tdlr": "This paper proposes a causal intervention-based few-shot named entity recognition method, which intervenes in prototypes via incremental learning to avoid catastrophic forgetting, achieving new state-of-the-art results on different benchmarks."
}