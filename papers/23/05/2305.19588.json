{
    "title": "Active causal structure learning with advice. (arXiv:2305.19588v1 [cs.LG])",
    "abstract": "We introduce the problem of active causal structure learning with advice. In the typical well-studied setting, the learning algorithm is given the essential graph for the observational distribution and is asked to recover the underlying causal directed acyclic graph (DAG) $G^*$ while minimizing the number of interventions made. In our setting, we are additionally given side information about $G^*$ as advice, e.g. a DAG $G$ purported to be $G^*$. We ask whether the learning algorithm can benefit from the advice when it is close to being correct, while still having worst-case guarantees even when the advice is arbitrarily bad. Our work is in the same space as the growing body of research on algorithms with predictions. When the advice is a DAG $G$, we design an adaptive search algorithm to recover $G^*$ whose intervention cost is at most $O(\\max\\{1, \\log \\psi\\})$ times the cost for verifying $G^*$; here, $\\psi$ is a distance measure between $G$ and $G^*$ that is upper bounded by the numb",
    "link": "http://arxiv.org/abs/2305.19588",
    "context": "Title: Active causal structure learning with advice. (arXiv:2305.19588v1 [cs.LG])\nAbstract: We introduce the problem of active causal structure learning with advice. In the typical well-studied setting, the learning algorithm is given the essential graph for the observational distribution and is asked to recover the underlying causal directed acyclic graph (DAG) $G^*$ while minimizing the number of interventions made. In our setting, we are additionally given side information about $G^*$ as advice, e.g. a DAG $G$ purported to be $G^*$. We ask whether the learning algorithm can benefit from the advice when it is close to being correct, while still having worst-case guarantees even when the advice is arbitrarily bad. Our work is in the same space as the growing body of research on algorithms with predictions. When the advice is a DAG $G$, we design an adaptive search algorithm to recover $G^*$ whose intervention cost is at most $O(\\max\\{1, \\log \\psi\\})$ times the cost for verifying $G^*$; here, $\\psi$ is a distance measure between $G$ and $G^*$ that is upper bounded by the numb",
    "path": "papers/23/05/2305.19588.json",
    "total_tokens": 966,
    "translated_title": "带建议的主动因果结构学习",
    "translated_abstract": "我们引入了带建议的主动因果结构学习问题。在典型的研究中，学习算法针对观测分布获得本质图，并被要求在最小化干预次数的同时恢复出潜在的因果有向无环图(DAG) $G^*$。在我们的问题设定中，除了关于 $G^*$的必要信息外，例如一个声称是 $G^*$的DAG $G$，我们还会额外获得关于 $G^*$的侧面信息。我们想知道，当建议接近正确时，学习算法是否可以从建议中受益，同时即使建议是任意糟糕的情况下，仍然具有最坏情况下的保证。我们的工作与关于带预测算法的不断增加的研究领域相同。当建议是有向无环图$G$时，我们设计了自适应搜索算法来恢复 $G^*$，其干预成本最多为验证$G^*$的成本的$O(max\\{1, \\log \\psi\\})$倍。这里，$\\psi$是$G$和$G^*$之间的距离度量，它被上界约束。",
    "tldr": "本研究提出了带建议的主动因果结构学习问题，并设计了一个自适应搜索算法，可以从建议中受益，即使建议是任意糟糕的情况下，仍然具有最坏情况下的保证。"
}