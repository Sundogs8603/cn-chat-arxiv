{
    "title": "Client Selection for Federated Policy Optimization with Environment Heterogeneity. (arXiv:2305.10978v1 [cs.LG])",
    "abstract": "The development of Policy Iteration (PI) has inspired many recent algorithms for Reinforcement Learning (RL), including several policy gradient methods, that gained both theoretical soundness and empirical success on a variety of tasks. The theory of PI is rich in the context of centralized learning, but its study is still in the infant stage under the federated setting. This paper explores the federated version of Approximate PI (API) and derives its error bound, taking into account the approximation error introduced by environment heterogeneity. We theoretically prove that a proper client selection scheme can reduce this error bound. Based on the theoretical result, we propose a client selection algorithm to alleviate the additional approximation error caused by environment heterogeneity. Experiment results show that the proposed algorithm outperforms other biased and unbiased client selection methods on the federated mountain car problem by effectively selecting clients with a lower",
    "link": "http://arxiv.org/abs/2305.10978",
    "context": "Title: Client Selection for Federated Policy Optimization with Environment Heterogeneity. (arXiv:2305.10978v1 [cs.LG])\nAbstract: The development of Policy Iteration (PI) has inspired many recent algorithms for Reinforcement Learning (RL), including several policy gradient methods, that gained both theoretical soundness and empirical success on a variety of tasks. The theory of PI is rich in the context of centralized learning, but its study is still in the infant stage under the federated setting. This paper explores the federated version of Approximate PI (API) and derives its error bound, taking into account the approximation error introduced by environment heterogeneity. We theoretically prove that a proper client selection scheme can reduce this error bound. Based on the theoretical result, we propose a client selection algorithm to alleviate the additional approximation error caused by environment heterogeneity. Experiment results show that the proposed algorithm outperforms other biased and unbiased client selection methods on the federated mountain car problem by effectively selecting clients with a lower",
    "path": "papers/23/05/2305.10978.json",
    "total_tokens": 920,
    "tldr": "本文探讨了带有环境异质性的联邦学习中近似策略迭代算法，并提出了一种客户端选择算法，通过选择具有较低示例误差的客户端，降低了误差界。该算法在联邦山车问题上表现出较好的性能。",
    "en_tdlr": "This paper explores the federated version of Approximate Policy Iteration (API) with environment heterogeneity and proposes a client selection algorithm to reduce the error bound by selecting clients with lower example errors. The proposed algorithm outperforms other biased and unbiased client selection methods on the federated mountain car problem."
}