{
    "title": "Instance-Adaptive Video Compression: Improving Neural Codecs by Training on the Test Set. (arXiv:2111.10302v2 [eess.IV] UPDATED)",
    "abstract": "We introduce a video compression algorithm based on instance-adaptive learning. On each video sequence to be transmitted, we finetune a pretrained compression model. The optimal parameters are transmitted to the receiver along with the latent code. By entropy-coding the parameter updates under a suitable mixture model prior, we ensure that the network parameters can be encoded efficiently. This instance-adaptive compression algorithm is agnostic about the choice of base model and has the potential to improve any neural video codec. On UVG, HEVC, and Xiph datasets, our codec improves the performance of a scale-space flow model by between 21% and 27% BD-rate savings, and that of a state-of-the-art B-frame model by 17 to 20% BD-rate savings. We also demonstrate that instance-adaptive finetuning improves the robustness to domain shift. Finally, our approach reduces the capacity requirements of compression models. We show that it enables a competitive performance even after reducing the net",
    "link": "http://arxiv.org/abs/2111.10302",
    "context": "Title: Instance-Adaptive Video Compression: Improving Neural Codecs by Training on the Test Set. (arXiv:2111.10302v2 [eess.IV] UPDATED)\nAbstract: We introduce a video compression algorithm based on instance-adaptive learning. On each video sequence to be transmitted, we finetune a pretrained compression model. The optimal parameters are transmitted to the receiver along with the latent code. By entropy-coding the parameter updates under a suitable mixture model prior, we ensure that the network parameters can be encoded efficiently. This instance-adaptive compression algorithm is agnostic about the choice of base model and has the potential to improve any neural video codec. On UVG, HEVC, and Xiph datasets, our codec improves the performance of a scale-space flow model by between 21% and 27% BD-rate savings, and that of a state-of-the-art B-frame model by 17 to 20% BD-rate savings. We also demonstrate that instance-adaptive finetuning improves the robustness to domain shift. Finally, our approach reduces the capacity requirements of compression models. We show that it enables a competitive performance even after reducing the net",
    "path": "papers/21/11/2111.10302.json",
    "total_tokens": 984,
    "translated_title": "实例自适应视频压缩：通过对测试集进行训练来提高神经编解码器",
    "translated_abstract": "我们介绍了一种基于实例自适应学习的视频压缩算法。在要传输的每个视频序列上，我们微调预训练的压缩模型。最优参数与潜在编码一起传输到接收端。通过在适当的混合模型先验下熵编码参数更新，我们确保网络参数可以高效地编码。这种实例自适应压缩算法对于基模型的选择是不可知的，有潜力提高任何神经视频编解码器的性能。在UVG、HEVC和Xiph数据集上，我们的编解码器将流空间模型的性能提高了21%至27%的BD-rate节省，以及最先进的B帧模型的17%至20%的BD-rate节省。我们还展示了实例自适应微调改善了对领域转移的鲁棒性。最后，我们的方法减少了压缩模型的容量需求。我们展示了即使减少网络大小，我们的方法带来了有竞争力的性能。",
    "tldr": "该论文提出了一种基于实例自适应学习的视频压缩算法，通过对测试集进行训练来提高神经编解码器的性能，并将最优参数与潜在编码一起传输到接收端。该算法在多个数据集上有着显著的性能提升，并且可以提高任何神经视频编解码器的性能。",
    "en_tdlr": "This paper proposes an instance-adaptive video compression algorithm that improves the performance of neural codecs by finetuning a pre-trained model on each video sequence to be transmitted, and transmitting the optimal parameters along with the latent code. The algorithm achieves significant performance improvements on multiple datasets and has the potential to improve any neural video codec."
}