{
    "title": "Learning Robust Output Control Barrier Functions from Safe Expert Demonstrations",
    "abstract": "arXiv:2111.09971v3 Announce Type: replace-cross  Abstract: This paper addresses learning safe output feedback control laws from partial observations of expert demonstrations. We assume that a model of the system dynamics and a state estimator are available along with corresponding error bounds, e.g., estimated from data in practice. We first propose robust output control barrier functions (ROCBFs) as a means to guarantee safety, as defined through controlled forward invariance of a safe set. We then formulate an optimization problem to learn ROCBFs from expert demonstrations that exhibit safe system behavior, e.g., data collected from a human operator or an expert controller. When the parametrization of the ROCBF is linear, then we show that, under mild assumptions, the optimization problem is convex. Along with the optimization problem, we provide verifiable conditions in terms of the density of the data, smoothness of the system model and state estimator, and the size of the error bo",
    "link": "https://arxiv.org/abs/2111.09971",
    "context": "Title: Learning Robust Output Control Barrier Functions from Safe Expert Demonstrations\nAbstract: arXiv:2111.09971v3 Announce Type: replace-cross  Abstract: This paper addresses learning safe output feedback control laws from partial observations of expert demonstrations. We assume that a model of the system dynamics and a state estimator are available along with corresponding error bounds, e.g., estimated from data in practice. We first propose robust output control barrier functions (ROCBFs) as a means to guarantee safety, as defined through controlled forward invariance of a safe set. We then formulate an optimization problem to learn ROCBFs from expert demonstrations that exhibit safe system behavior, e.g., data collected from a human operator or an expert controller. When the parametrization of the ROCBF is linear, then we show that, under mild assumptions, the optimization problem is convex. Along with the optimization problem, we provide verifiable conditions in terms of the density of the data, smoothness of the system model and state estimator, and the size of the error bo",
    "path": "papers/21/11/2111.09971.json",
    "total_tokens": 822,
    "translated_title": "从安全专家演示中学习健壮的输出控制屏障函数",
    "translated_abstract": "这篇论文解决了从专家演示的部分观测中学习安全输出反馈控制律的问题。假设系统动态模型和状态估计器可用，并带有相应的误差界限，例如，可以从实践中的数据估计得出。我们首先提出了健壮的输出控制屏障函数（ROCBFs）作为确保安全的手段，通过控制安全集的控制前不变性来定义安全性。然后，我们制定了一个优化问题，从表现出安全系统行为的专家演示中学习ROCBFs，例如从人操纵员或专家控制器收集的数据。当ROCBF的参数化是线性时，我们表明，在温和的假设下，优化问题是凸的。除了优化问题，我们还提供了可验证的条件，涉及数据的密度、系统模型和状态估计器的平滑性，以及误差边界的大小。",
    "tldr": "从专家演示中学习健壮的输出控制屏障函数以确保安全性，当参数化为线性时，优化问题是凸的。",
    "en_tdlr": "Learning robust output control barrier functions from expert demonstrations to ensure safety, with the optimization problem being convex when parameterized linearly."
}