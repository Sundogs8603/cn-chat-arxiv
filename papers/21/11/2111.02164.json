{
    "title": "Data structure > labels? Unsupervised heuristics for SVM hyperparameter estimation",
    "abstract": "arXiv:2111.02164v2 Announce Type: replace  Abstract: Classification is one of the main areas of pattern recognition research, and within it, Support Vector Machine (SVM) is one of the most popular methods outside of field of deep learning -- and a de-facto reference for many Machine Learning approaches. Its performance is determined by parameter selection, which is usually achieved by a time-consuming grid search cross-validation procedure (GSCV). That method, however relies on the availability and quality of labelled examples and thus, when those are limited can be hindered. To address that problem, there exist several unsupervised heuristics that take advantage of the characteristics of the dataset for selecting parameters instead of using class label information. While an order of magnitude faster, they are scarcely used under the assumption that their results are significantly worse than those of grid search. To challenge that assumption, we have proposed improved heuristics for SV",
    "link": "https://arxiv.org/abs/2111.02164",
    "context": "Title: Data structure > labels? Unsupervised heuristics for SVM hyperparameter estimation\nAbstract: arXiv:2111.02164v2 Announce Type: replace  Abstract: Classification is one of the main areas of pattern recognition research, and within it, Support Vector Machine (SVM) is one of the most popular methods outside of field of deep learning -- and a de-facto reference for many Machine Learning approaches. Its performance is determined by parameter selection, which is usually achieved by a time-consuming grid search cross-validation procedure (GSCV). That method, however relies on the availability and quality of labelled examples and thus, when those are limited can be hindered. To address that problem, there exist several unsupervised heuristics that take advantage of the characteristics of the dataset for selecting parameters instead of using class label information. While an order of magnitude faster, they are scarcely used under the assumption that their results are significantly worse than those of grid search. To challenge that assumption, we have proposed improved heuristics for SV",
    "path": "papers/21/11/2111.02164.json",
    "total_tokens": 813,
    "translated_title": "数据结构>标签？无监督启发式SVM超参数估计",
    "translated_abstract": "分类是模式识别研究的主要领域之一，在其中，支持向量机（SVM）是除了深度学习领域以外最流行的方法之一，并且是许多机器学习方法的事实参考。SVM的性能取决于参数选择，通常通过耗时的网格搜索交叉验证过程（GSCV）来实现。然而，该方法依赖于标记示例的可用性和质量，当这些标记受限时可能会受阻。为解决这一问题，存在几种无监督启发式方法，利用数据集的特征来选择参数，而不是使用类标签信息。虽然速度快一个数量级，但它们很少被使用，因为人们认为它们的结果明显比网格搜索差。为了挑战这种假设，我们提出了改进的SVM超参数heuristics。",
    "tldr": "提出了一种对支持向量机超参数进行改进的无监督启发式方法，以解决在缺乏标记示例的情况下，减少对类标签信息依赖的问题。",
    "en_tdlr": "Proposed improved unsupervised heuristics for SVM hyperparameter estimation to reduce reliance on class label information in the absence of labeled examples."
}