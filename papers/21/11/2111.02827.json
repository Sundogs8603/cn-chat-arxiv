{
    "title": "Towards Learning to Speak and Hear Through Multi-Agent Communication over a Continuous Acoustic Channel. (arXiv:2111.02827v2 [cs.CL] UPDATED)",
    "abstract": "Multi-agent reinforcement learning has been used as an effective means to study emergent communication between agents, yet little focus has been given to continuous acoustic communication. This would be more akin to human language acquisition; human infants acquire language in large part through continuous signalling with their caregivers. We therefore ask: Are we able to observe emergent language between agents with a continuous communication channel? Our goal is to provide a platform to begin bridging the gap between human and agent communication, allowing us to analyse continuous signals, how they emerge, their characteristics, and how they relate to human language acquisition. We propose a messaging environment where a Speaker agent needs to convey a set of attributes to a Listener over a noisy acoustic channel. Using DQN to train our agents, we show that: (1) unlike the discrete case, the acoustic Speaker learns redundancy to improve Listener coherency, (2) the acoustic Speaker de",
    "link": "http://arxiv.org/abs/2111.02827",
    "context": "Title: Towards Learning to Speak and Hear Through Multi-Agent Communication over a Continuous Acoustic Channel. (arXiv:2111.02827v2 [cs.CL] UPDATED)\nAbstract: Multi-agent reinforcement learning has been used as an effective means to study emergent communication between agents, yet little focus has been given to continuous acoustic communication. This would be more akin to human language acquisition; human infants acquire language in large part through continuous signalling with their caregivers. We therefore ask: Are we able to observe emergent language between agents with a continuous communication channel? Our goal is to provide a platform to begin bridging the gap between human and agent communication, allowing us to analyse continuous signals, how they emerge, their characteristics, and how they relate to human language acquisition. We propose a messaging environment where a Speaker agent needs to convey a set of attributes to a Listener over a noisy acoustic channel. Using DQN to train our agents, we show that: (1) unlike the discrete case, the acoustic Speaker learns redundancy to improve Listener coherency, (2) the acoustic Speaker de",
    "path": "papers/21/11/2111.02827.json",
    "total_tokens": 837,
    "translated_title": "通过连续声学通道进行多智能体通讯学习听说能力的实现",
    "translated_abstract": "多智能体强化学习已成为研究智能体间新兴通讯的有效手段，但对于连续声学通讯却鲜有研究。这更类似于人类获得语言的方式；人类婴儿主要通过与看护者的连续信号交互来习得语言。因此，我们现在的目标是提供一个平台，以开始填补人类和智能体通信之间的差距，让我们能够分析连续信号以及它们产生的方式，它们的特征以及它们与人类语言习得的关系。",
    "tldr": "本研究旨在通过提供一个智能体间的消息传递环境，使得智能体能够通过连续声学通道进行通讯并观察到新兴语言的产生与特点，结果表明：与离散型信号不同，声学讲话者学习使用冗余信息以提高侦听者的连贯性。",
    "en_tdlr": "This study aims to bridge the gap between human and agent communication by providing a messaging environment for agents to communicate through a continuous acoustic channel, allowing observation of emergent language and its characteristics. Results show that, unlike in the discrete case, the acoustic speaker learns redundancy to improve listener coherency."
}