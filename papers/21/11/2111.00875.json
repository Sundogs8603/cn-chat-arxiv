{
    "title": "A moment-matching metric for latent variable generative models. (arXiv:2111.00875v2 [cs.LG] UPDATED)",
    "abstract": "It can be difficult to assess the quality of a fitted model when facing unsupervised learning problems. Latent variable models, such as variation autoencoders and Gaussian mixture models, are often trained with likelihood-based approaches. In scope of Goodhart's law, when a metric becomes a target it ceases to be a good metric and therefore we should not use likelihood to assess the quality of the fit of these models. The solution we propose is a new metric for model comparison or regularization that relies on moments. The concept is to study the difference between the data moments and the model moments using a matrix norm, such as the Frobenius norm. We show how to use this new metric for model comparison and then for regularization. It is common to draw samples from the fitted distribution when evaluating latent variable models and we show that our proposed metric is faster to compute and has a smaller variance that this alternative. We conclude this article with a proof of concept o",
    "link": "http://arxiv.org/abs/2111.00875",
    "context": "Title: A moment-matching metric for latent variable generative models. (arXiv:2111.00875v2 [cs.LG] UPDATED)\nAbstract: It can be difficult to assess the quality of a fitted model when facing unsupervised learning problems. Latent variable models, such as variation autoencoders and Gaussian mixture models, are often trained with likelihood-based approaches. In scope of Goodhart's law, when a metric becomes a target it ceases to be a good metric and therefore we should not use likelihood to assess the quality of the fit of these models. The solution we propose is a new metric for model comparison or regularization that relies on moments. The concept is to study the difference between the data moments and the model moments using a matrix norm, such as the Frobenius norm. We show how to use this new metric for model comparison and then for regularization. It is common to draw samples from the fitted distribution when evaluating latent variable models and we show that our proposed metric is faster to compute and has a smaller variance that this alternative. We conclude this article with a proof of concept o",
    "path": "papers/21/11/2111.00875.json",
    "total_tokens": 794,
    "translated_title": "一种用于潜变量生成模型的矩匹配度量方法",
    "translated_abstract": "面对无监督学习问题时，评估拟合模型的质量是困难的。潜变量模型，如变分自编码器和高斯混合模型，通常使用基于似然的方法进行训练。本文提出了一种新的用于模型比较或正则化的度量方法，该方法依赖于矩。其概念是使用矩范数（如弗罗贝尼乌斯范数）研究数据矩和模型矩之间的差异。我们展示了如何使用这个新的度量方法进行模型比较和正则化，并证明了该方法的可行性。",
    "tldr": "本文提出了一种用于比较和正则化潜变量生成模型的新型矩匹配度量方法，该方法通过研究数据矩和模型矩之间的差异来评估拟合模型质量。",
    "en_tdlr": "This paper proposes a novel moment-matching metric for comparing and regularizing latent variable generative models, which evaluates the quality of fitted models by studying the difference between data moments and model moments using a matrix norm."
}