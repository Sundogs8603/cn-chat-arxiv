{
    "title": "MARS via LASSO. (arXiv:2111.11694v2 [math.ST] UPDATED)",
    "abstract": "Multivariate adaptive regression splines (MARS) is a popular method for nonparametric regression introduced by Friedman in 1991. MARS fits simple nonlinear and non-additive functions to regression data. We propose and study a natural lasso variant of the MARS method. Our method is based on least squares estimation over a convex class of functions obtained by considering infinite-dimensional linear combinations of functions in the MARS basis and imposing a variation based complexity constraint. Our estimator can be computed via finite-dimensional convex optimization, although it is defined as a solution to an infinite-dimensional optimization problem. Under a few standard design assumptions, we prove that our estimator achieves a rate of convergence that depends only logarithmically on dimension and thus avoids the usual curse of dimensionality to some extent. We also show that our method is naturally connected to nonparametric estimation techniques based on smoothness constraints. We i",
    "link": "http://arxiv.org/abs/2111.11694",
    "context": "Title: MARS via LASSO. (arXiv:2111.11694v2 [math.ST] UPDATED)\nAbstract: Multivariate adaptive regression splines (MARS) is a popular method for nonparametric regression introduced by Friedman in 1991. MARS fits simple nonlinear and non-additive functions to regression data. We propose and study a natural lasso variant of the MARS method. Our method is based on least squares estimation over a convex class of functions obtained by considering infinite-dimensional linear combinations of functions in the MARS basis and imposing a variation based complexity constraint. Our estimator can be computed via finite-dimensional convex optimization, although it is defined as a solution to an infinite-dimensional optimization problem. Under a few standard design assumptions, we prove that our estimator achieves a rate of convergence that depends only logarithmically on dimension and thus avoids the usual curse of dimensionality to some extent. We also show that our method is naturally connected to nonparametric estimation techniques based on smoothness constraints. We i",
    "path": "papers/21/11/2111.11694.json",
    "total_tokens": 848,
    "translated_title": "MARS via LASSO.（arXiv:2111.11694v2 [math.ST] 已更新）",
    "translated_abstract": "多元自适应回归样条（Multivariate Adaptive Regression Splines，MARS）是Friedman在1991年提出的一种非参数回归方法。MARS将简单的非线性和非加性函数拟合到回归数据上。本文提出并研究了MARS方法的一种自然lasso变体。我们的方法是基于最小二乘估计，通过考虑MARS基础函数的无限维线性组合并强加基于变分的复杂度约束条件来获得函数的凸类。虽然我们的估计是定义为无限维优化问题的解，但其可以通过有限维凸优化来计算。在一些标准设计假设下，我们证明了我们的估计器仅在维度上对数收敛，因此在一定程度上避免了通常的维度灾难。我们还表明，我们的方法自然地与基于平滑性约束的非参数估计技术相联系。",
    "tldr": "本文提出了一种自然lasso变体的MARS方法，通过减少对维度的依赖来获得收敛率，并与使用平滑性约束的非参数估计技术联系在一起。"
}