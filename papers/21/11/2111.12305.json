{
    "title": "Thundernna: a white box adversarial attack. (arXiv:2111.12305v2 [cs.LG] UPDATED)",
    "abstract": "The existing work shows that the neural network trained by naive gradient-based optimization method is prone to adversarial attacks, adds small malicious on the ordinary input is enough to make the neural network wrong. At the same time, the attack against a neural network is the key to improving its robustness. The training against adversarial examples can make neural networks resist some kinds of adversarial attacks. At the same time, the adversarial attack against a neural network can also reveal some characteristics of the neural network, a complex high-dimensional non-linear function, as discussed in previous work.  In This project, we develop a first-order method to attack the neural network. Compare with other first-order attacks, our method has a much higher success rate. Furthermore, it is much faster than second-order attacks and multi-steps first-order attacks.",
    "link": "http://arxiv.org/abs/2111.12305",
    "context": "Title: Thundernna: a white box adversarial attack. (arXiv:2111.12305v2 [cs.LG] UPDATED)\nAbstract: The existing work shows that the neural network trained by naive gradient-based optimization method is prone to adversarial attacks, adds small malicious on the ordinary input is enough to make the neural network wrong. At the same time, the attack against a neural network is the key to improving its robustness. The training against adversarial examples can make neural networks resist some kinds of adversarial attacks. At the same time, the adversarial attack against a neural network can also reveal some characteristics of the neural network, a complex high-dimensional non-linear function, as discussed in previous work.  In This project, we develop a first-order method to attack the neural network. Compare with other first-order attacks, our method has a much higher success rate. Furthermore, it is much faster than second-order attacks and multi-steps first-order attacks.",
    "path": "papers/21/11/2111.12305.json",
    "total_tokens": 808,
    "translated_title": "Thundernna: 一种白盒对抗攻击",
    "translated_abstract": "存在的研究证明，使用朴素的基于梯度的优化方法训练的神经网络容易受到对抗攻击，只要在普通输入上加入少量恶意信息就足以使神经网络出错。与此同时，对神经网络进行攻击是提高其鲁棒性的关键。针对对抗性样本的训练可以使神经网络抵抗某些类型的对抗攻击。同时，对神经网络进行对抗攻击也可以揭示一些特征，如之前的工作所讨论的复杂的高维非线性函数。在这个项目中，我们开发了一种一阶方法来攻击神经网络。与其他一阶攻击相比，我们的方法具有更高的成功率。此外，它比二阶攻击和多步一阶攻击快得多。",
    "tldr": "本研究提出了一种名为Thundernna的白盒对抗攻击方法，通过开发一种一阶优化方法，该方法在攻击神经网络时具有更高的成功率和更快的速度。",
    "en_tdlr": "This study presents Thundernna, a white box adversarial attack method, which achieves higher success rate and faster speed in attacking neural networks through the development of a first-order optimization method."
}