{
    "title": "Generalizing Graph Neural Networks on Out-Of-Distribution Graphs",
    "abstract": "arXiv:2111.10657v3 Announce Type: replace-cross  Abstract: Graph Neural Networks (GNNs) are proposed without considering the agnostic distribution shifts between training and testing graphs, inducing the degeneration of the generalization ability of GNNs on Out-Of-Distribution (OOD) settings. The fundamental reason for such degeneration is that most GNNs are developed based on the I.I.D hypothesis. In such a setting, GNNs tend to exploit subtle statistical correlations existing in the training set for predictions, even though it is a spurious correlation. However, such spurious correlations may change in testing environments, leading to the failure of GNNs. Therefore, eliminating the impact of spurious correlations is crucial for stable GNNs. To this end, we propose a general causal representation framework, called StableGNN. The main idea is to extract high-level representations from graph data first and resort to the distinguishing ability of causal inference to help the model get ri",
    "link": "https://arxiv.org/abs/2111.10657",
    "context": "Title: Generalizing Graph Neural Networks on Out-Of-Distribution Graphs\nAbstract: arXiv:2111.10657v3 Announce Type: replace-cross  Abstract: Graph Neural Networks (GNNs) are proposed without considering the agnostic distribution shifts between training and testing graphs, inducing the degeneration of the generalization ability of GNNs on Out-Of-Distribution (OOD) settings. The fundamental reason for such degeneration is that most GNNs are developed based on the I.I.D hypothesis. In such a setting, GNNs tend to exploit subtle statistical correlations existing in the training set for predictions, even though it is a spurious correlation. However, such spurious correlations may change in testing environments, leading to the failure of GNNs. Therefore, eliminating the impact of spurious correlations is crucial for stable GNNs. To this end, we propose a general causal representation framework, called StableGNN. The main idea is to extract high-level representations from graph data first and resort to the distinguishing ability of causal inference to help the model get ri",
    "path": "papers/21/11/2111.10657.json",
    "total_tokens": 844,
    "translated_title": "在分布外图上推广图神经网络",
    "translated_abstract": "图神经网络（GNNs）在没有考虑训练和测试图之间的分布差异的情况下提出，导致GNNs在分布外（OOD）设置上的泛化能力下降。这种退化的根本原因是大多数GNNs是基于独立同分布假设开发的。在这种设置中，GNNs倾向于利用训练集中存在的细微统计相关性进行预测，即使这是一种伪相关性。然而，这种伪相关性在测试环境中可能会改变，导致GNNs失败。因此，消除伪相关性的影响对于稳定的GNNs至关重要。为此，我们提出了一个名为StableGNN的通用因果表示框架。主要思想是首先从图数据中提取高级表示，然后借助因果推断的区分能力来帮助模型获得稳定的预测效果。",
    "tldr": "提出了一个名为StableGNN的通用因果表示框架，通过提取高级图表示并利用因果推断的区分能力，帮助模型在分布外图上实现稳定的泛化能力。",
    "en_tdlr": "Introduced a general causal representation framework called StableGNN, which extracts high-level graph representations and utilizes the distinguishing ability of causal inference to help the model achieve stable generalization on out-of-distribution graphs."
}