{
    "title": "Data-Efficient Deep Reinforcement Learning for Attitude Control of Fixed-Wing UAVs: Field Experiments. (arXiv:2111.04153v2 [eess.SY] UPDATED)",
    "abstract": "Attitude control of fixed-wing unmanned aerial vehicles (UAVs) is a difficult control problem in part due to uncertain nonlinear dynamics, actuator constraints, and coupled longitudinal and lateral motions. Current state-of-the-art autopilots are based on linear control and are thus limited in their effectiveness and performance. Deep reinforcement learning (DRL) is a machine learning method to automatically discover optimal control laws through interaction with the controlled system, which can handle complex nonlinear dynamics. We show in this paper that DRL can successfully learn to perform attitude control of a fixed-wing UAV operating directly on the original nonlinear dynamics, requiring as little as three minutes of flight data. We initially train our model in a simulation environment and then deploy the learned controller on the UAV in flight tests, demonstrating comparable performance to the state-of-the-art ArduPlane proportional-integral-derivative (PID) attitude controller w",
    "link": "http://arxiv.org/abs/2111.04153",
    "context": "Title: Data-Efficient Deep Reinforcement Learning for Attitude Control of Fixed-Wing UAVs: Field Experiments. (arXiv:2111.04153v2 [eess.SY] UPDATED)\nAbstract: Attitude control of fixed-wing unmanned aerial vehicles (UAVs) is a difficult control problem in part due to uncertain nonlinear dynamics, actuator constraints, and coupled longitudinal and lateral motions. Current state-of-the-art autopilots are based on linear control and are thus limited in their effectiveness and performance. Deep reinforcement learning (DRL) is a machine learning method to automatically discover optimal control laws through interaction with the controlled system, which can handle complex nonlinear dynamics. We show in this paper that DRL can successfully learn to perform attitude control of a fixed-wing UAV operating directly on the original nonlinear dynamics, requiring as little as three minutes of flight data. We initially train our model in a simulation environment and then deploy the learned controller on the UAV in flight tests, demonstrating comparable performance to the state-of-the-art ArduPlane proportional-integral-derivative (PID) attitude controller w",
    "path": "papers/21/11/2111.04153.json",
    "total_tokens": 865,
    "translated_title": "固定翼无人机姿态控制的数据高效深度强化学习：现场实验",
    "translated_abstract": "由于存在不确定的非线性动力学、执行机构约束以及纵向和横向运动的耦合，固定翼无人机的姿态控制是一个难题。目前最先进的自动驾驶仍基于线性控制，其有效性和性能受到限制。本文研究表明，深度强化学习（DRL）可以成功学习直接操作原始非线性动力学的固定翼无人机的姿态控制，只需要三分钟的飞行数据。我们首先在仿真环境中训练模型，然后在飞行测试中将学习的控制器应用于无人机上，其表现与现有的ArduPlane比例积分微分（PID）姿态控制器相当。",
    "tldr": "本文使用深度强化学习算法成功实现了对固定翼无人机的姿态控制，只需三分钟的飞行数据。该算法可以直接操作原始非线性动力学，相较于现有技术具备了更好的性能和有效性。",
    "en_tdlr": "This paper demonstrates the successful use of deep reinforcement learning (DRL) algorithm to achieve attitude control of fixed-wing UAVs, with as little as three minutes of flight data. The algorithm can directly operate on the original nonlinear dynamics, and shows better performance and effectiveness compared to the current state-of-the-art technology."
}