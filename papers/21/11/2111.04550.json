{
    "title": "ARFED: Attack-Resistant Federated averaging based on outlier elimination. (arXiv:2111.04550v2 [cs.LG] UPDATED)",
    "abstract": "In federated learning, each participant trains its local model with its own data and a global model is formed at a trusted server by aggregating model updates coming from these participants. Since the server has no effect and visibility on the training procedure of the participants to ensure privacy, the global model becomes vulnerable to attacks such as data poisoning and model poisoning. Although many defense algorithms have recently been proposed to address these attacks, they often make strong assumptions that do not agree with the nature of federated learning, such as assuming Non-IID datasets. Moreover, they mostly lack comprehensive experimental analyses. In this work, we propose a defense algorithm called ARFED that does not make any assumptions about data distribution, update similarity of participants, or the ratio of the malicious participants. ARFED mainly considers the outlier status of participant updates for each layer of the model architecture based on the distance to t",
    "link": "http://arxiv.org/abs/2111.04550",
    "context": "Title: ARFED: Attack-Resistant Federated averaging based on outlier elimination. (arXiv:2111.04550v2 [cs.LG] UPDATED)\nAbstract: In federated learning, each participant trains its local model with its own data and a global model is formed at a trusted server by aggregating model updates coming from these participants. Since the server has no effect and visibility on the training procedure of the participants to ensure privacy, the global model becomes vulnerable to attacks such as data poisoning and model poisoning. Although many defense algorithms have recently been proposed to address these attacks, they often make strong assumptions that do not agree with the nature of federated learning, such as assuming Non-IID datasets. Moreover, they mostly lack comprehensive experimental analyses. In this work, we propose a defense algorithm called ARFED that does not make any assumptions about data distribution, update similarity of participants, or the ratio of the malicious participants. ARFED mainly considers the outlier status of participant updates for each layer of the model architecture based on the distance to t",
    "path": "papers/21/11/2111.04550.json",
    "total_tokens": 1082,
    "translated_title": "基于异常值消除的防攻击联邦学习算法ARFED",
    "translated_abstract": "在联邦学习中，每个参与者使用自己的数据训练本地模型，而全局模型是由集成来自这些参与者的模型更新的可信服务器形成的。由于服务器对参与者的训练过程没有影响与可见性以确保隐私，全局模型容易受到数据污染和模型污染等攻击。虽然最近提出了许多用于解决这些攻击的防御算法，但它们经常做出与联邦学习性质不符的强假设，例如假设非IID数据集。此外，它们大多缺乏综合实验分析。在本研究中，提出了一种名为ARFED的防御算法，它不对数据分布、参与者更新的相似性或恶意参与者的比率做任何假设。ARFED主要考虑模型体系结构每一层参与者更新的离群状态，基于到转换版本更新的距离，消除离群值。我们针对包括数据污染、模型污染和混合攻击在内的各种攻击，在基准联邦学习数据集上评估了ARFED。结果表明，ARFED在保持非IID和IID数据集高准确性的同时实现了最先进的防攻击鲁棒性能。",
    "tldr": "ARFED是一种防御算法，能够消除模型更新中的离群值，不需要假设数据分布、更新相似性或恶意参与者比率，实现了在基准联邦学习数据集上的最先进的防攻击鲁棒性能。",
    "en_tdlr": "ARFED is a defense algorithm that eliminates outliers in model updates without assuming data distribution, update similarity, or the ratio of malicious participants. It achieves state-of-the-art attack resilience performance on benchmark federated learning datasets against various attacks including data and model poisoning."
}