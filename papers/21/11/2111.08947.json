{
    "title": "Fast Yet Effective Machine Unlearning. (arXiv:2111.08947v5 [cs.LG] UPDATED)",
    "abstract": "Unlearning the data observed during the training of a machine learning (ML) model is an important task that can play a pivotal role in fortifying the privacy and security of ML-based applications. This paper raises the following questions: (i) can we unlearn a single or multiple class(es) of data from a ML model without looking at the full training data even once? (ii) can we make the process of unlearning fast and scalable to large datasets, and generalize it to different deep networks? We introduce a novel machine unlearning framework with error-maximizing noise generation and impair-repair based weight manipulation that offers an efficient solution to the above questions. An error-maximizing noise matrix is learned for the class to be unlearned using the original model. The noise matrix is used to manipulate the model weights to unlearn the targeted class of data. We introduce impair and repair steps for a controlled manipulation of the network weights. In the impair step, the noise",
    "link": "http://arxiv.org/abs/2111.08947",
    "context": "Title: Fast Yet Effective Machine Unlearning. (arXiv:2111.08947v5 [cs.LG] UPDATED)\nAbstract: Unlearning the data observed during the training of a machine learning (ML) model is an important task that can play a pivotal role in fortifying the privacy and security of ML-based applications. This paper raises the following questions: (i) can we unlearn a single or multiple class(es) of data from a ML model without looking at the full training data even once? (ii) can we make the process of unlearning fast and scalable to large datasets, and generalize it to different deep networks? We introduce a novel machine unlearning framework with error-maximizing noise generation and impair-repair based weight manipulation that offers an efficient solution to the above questions. An error-maximizing noise matrix is learned for the class to be unlearned using the original model. The noise matrix is used to manipulate the model weights to unlearn the targeted class of data. We introduce impair and repair steps for a controlled manipulation of the network weights. In the impair step, the noise",
    "path": "papers/21/11/2111.08947.json",
    "total_tokens": 1058,
    "translated_title": "快速有效的机器数据遗忘",
    "translated_abstract": "对机器学习模型在训练中观测到的数据进行遗忘是一项重要任务，可以在加强基于机器学习的应用程序的隐私和安全方面发挥关键作用。本文提出了以下问题：（i）我们能否在不查看完整训练数据的情况下，从机器学习模型中删除单个或多个类别的数据？（ii）我们能否使快速的遗忘过程适用于大型数据集，并推广到不同的深度网络？我们引入了一种新的机器数据遗忘框架，采用误差最大化的噪声生成和损伤-修复的权重操作，为上述问题提供了高效的解决方案。通过使用原始模型学习一个针对待遗忘类别的误差最大化噪声矩阵，并利用该噪声矩阵操作模型权重以遗忘目标类别的数据。我们引入损伤和修复步骤来控制网络权重的操作。在损伤步骤中，将噪声矩阵应用于与目标类别相对应的神经元的权重。在修复步骤中，使用剩余的训练数据对操作后的权重进行微调。各种基准实验表明了我们所提出的方法的有效性和高效性。",
    "tldr": "本文提出了一种快速且有效的机器数据遗忘框架，该框架采用误差最大化的噪声生成和损伤-修复的权重操作来删除机器学习模型中的特定数据，同时具有较高的适用性和效率。",
    "en_tdlr": "This paper proposes a fast and effective machine unlearning framework with error-maximizing noise generation and impair-repair based weight manipulation, which can remove specific data from machine learning models without accessing the full training data, while maintaining high applicability and efficiency."
}