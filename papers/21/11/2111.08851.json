{
    "title": "Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities. (arXiv:2111.08851v5 [cs.LG] UPDATED)",
    "abstract": "In recent times, deep neural networks achieved outstanding predictive performance on various classification and pattern recognition tasks. However, many real-world prediction problems have ordinal response variables, and this ordering information is ignored by conventional classification losses such as the multi-category cross-entropy. Ordinal regression methods for deep neural networks address this. One such method is the CORAL method, which is based on an earlier binary label extension framework and achieves rank consistency among its output layer tasks by imposing a weight-sharing constraint. However, while earlier experiments showed that CORAL's rank consistency is beneficial for performance, it is limited by a weight-sharing constraint in a neural network's fully connected output layer, which may restrict the expressiveness and capacity of a network trained using CORAL. We propose a new method for rank-consistent ordinal regression without this limitation. Our rank-consistent ordi",
    "link": "http://arxiv.org/abs/2111.08851",
    "context": "Title: Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities. (arXiv:2111.08851v5 [cs.LG] UPDATED)\nAbstract: In recent times, deep neural networks achieved outstanding predictive performance on various classification and pattern recognition tasks. However, many real-world prediction problems have ordinal response variables, and this ordering information is ignored by conventional classification losses such as the multi-category cross-entropy. Ordinal regression methods for deep neural networks address this. One such method is the CORAL method, which is based on an earlier binary label extension framework and achieves rank consistency among its output layer tasks by imposing a weight-sharing constraint. However, while earlier experiments showed that CORAL's rank consistency is beneficial for performance, it is limited by a weight-sharing constraint in a neural network's fully connected output layer, which may restrict the expressiveness and capacity of a network trained using CORAL. We propose a new method for rank-consistent ordinal regression without this limitation. Our rank-consistent ordi",
    "path": "papers/21/11/2111.08851.json",
    "total_tokens": 815,
    "translated_title": "基于条件概率的深度神经网络在排序一致序回归中的应用",
    "translated_abstract": "近年来，深度神经网络在各种分类和模式识别任务中取得了出色的预测性能。然而，许多实际的预测问题具有序响应变量，并且传统的分类损失函数忽略了这种排序信息。基于深度神经网络的序回归方法解决了这个问题。本文提出了一种新的方法，该方法基于建立每个序分类的条件概率的深度神经结构，从而保证模型的输出概率在预测标签类别中保持其排序一致性。",
    "tldr": "本文提出新的一种排除限制的排序一致性序回归方法，基于深度神经网络和条件概率的建模，可以在保持输出概率排序一致性的同时，提高了模型的表现。",
    "en_tdlr": "This paper proposes a new method for rank-consistent ordinal regression based on a novel deep neural architecture modeling conditional probabilities for each ordinal category. The method achieves competitive performance while overcoming the limitations of other methods."
}