{
    "title": "Decentralized Federated Learning through Proxy Model Sharing. (arXiv:2111.11343v2 [cs.LG] UPDATED)",
    "abstract": "Institutions in highly regulated domains such as finance and healthcare often have restrictive rules around data sharing. Federated learning is a distributed learning framework that enables multi-institutional collaborations on decentralized data with improved protection for each collaborator's data privacy. In this paper, we propose a communication-efficient scheme for decentralized federated learning called ProxyFL, or proxy-based federated learning. Each participant in ProxyFL maintains two models, a private model, and a publicly shared proxy model designed to protect the participant's privacy. Proxy models allow efficient information exchange among participants without the need of a centralized server. The proposed method eliminates a significant limitation of canonical federated learning by allowing model heterogeneity; each participant can have a private model with any architecture. Furthermore, our protocol for communication by proxy leads to stronger privacy guarantees using di",
    "link": "http://arxiv.org/abs/2111.11343",
    "context": "Title: Decentralized Federated Learning through Proxy Model Sharing. (arXiv:2111.11343v2 [cs.LG] UPDATED)\nAbstract: Institutions in highly regulated domains such as finance and healthcare often have restrictive rules around data sharing. Federated learning is a distributed learning framework that enables multi-institutional collaborations on decentralized data with improved protection for each collaborator's data privacy. In this paper, we propose a communication-efficient scheme for decentralized federated learning called ProxyFL, or proxy-based federated learning. Each participant in ProxyFL maintains two models, a private model, and a publicly shared proxy model designed to protect the participant's privacy. Proxy models allow efficient information exchange among participants without the need of a centralized server. The proposed method eliminates a significant limitation of canonical federated learning by allowing model heterogeneity; each participant can have a private model with any architecture. Furthermore, our protocol for communication by proxy leads to stronger privacy guarantees using di",
    "path": "papers/21/11/2111.11343.json",
    "total_tokens": 858,
    "tldr": "提出了一种名为ProxyFL或基于代理的分散联邦学习的通信高效方案，有效解决了联邦学习中模型异构性的限制性问题，并提高了隐私保护。",
    "en_tdlr": "ProxyFL, a communication-efficient scheme for decentralized federated learning, is proposed to address the limiting issue of model heterogeneity in canonical federated learning and to enhance privacy protection by maintaining private and publicly shared proxy models."
}