{
    "title": "Inducing Meaningful Units from Character Sequences with Dynamic Capacity Slot Attention. (arXiv:2102.01223v3 [cs.CL] UPDATED)",
    "abstract": "Characters do not convey meaning, but sequences of characters do. We propose an unsupervised distributional method to learn the abstract meaningful units in a sequence of characters. Rather than segmenting the sequence, our Dynamic Capacity Slot Attention model discovers continuous representations of the objects in the sequence, extending an architecture for object discovery in images. We train our model on different languages and evaluate the quality of the obtained representations with forward and reverse probing classifiers. These experiments show that our model succeeds in discovering units which are similar to those proposed previously in form, content and level of abstraction, and which show promise for capturing meaningful information at a higher level of abstraction.",
    "link": "http://arxiv.org/abs/2102.01223",
    "context": "Title: Inducing Meaningful Units from Character Sequences with Dynamic Capacity Slot Attention. (arXiv:2102.01223v3 [cs.CL] UPDATED)\nAbstract: Characters do not convey meaning, but sequences of characters do. We propose an unsupervised distributional method to learn the abstract meaningful units in a sequence of characters. Rather than segmenting the sequence, our Dynamic Capacity Slot Attention model discovers continuous representations of the objects in the sequence, extending an architecture for object discovery in images. We train our model on different languages and evaluate the quality of the obtained representations with forward and reverse probing classifiers. These experiments show that our model succeeds in discovering units which are similar to those proposed previously in form, content and level of abstraction, and which show promise for capturing meaningful information at a higher level of abstraction.",
    "path": "papers/21/02/2102.01223.json",
    "total_tokens": 766,
    "translated_title": "使用动态容量槽注意力从字符序列中诱导有意义的单元",
    "translated_abstract": "字符本身并不传达意义，但字符序列却可以。我们提出了一种无监督的分布式方法，用于学习字符序列中的抽象有意义单元。我们的动态容量槽注意力模型不是对序列进行分割，而是发现序列中对象的连续表示，扩展了图像中对象发现的架构。我们对不同语言训练模型，并使用正向和反向探测分类器评估所得到表示的质量。实验证明，我们的模型成功地发现了与先前提出的单元在形式、内容和抽象级别上相似的单元，并显示了在更高级别的抽象中捕捉有意义信息的潜力。",
    "tldr": "该论文提出了一种无监督的分布式方法，使用动态容量槽注意力模型从字符序列中学习抽象有意义单元，成功发现了与先前提出的单元相似的、适用于更高级别抽象的可捕捉有意义信息的单元。",
    "en_tdlr": "This paper proposes an unsupervised distributional method, using the Dynamic Capacity Slot Attention model, to learn abstract meaningful units from character sequences. It successfully discovers units similar to those proposed previously, which can capture meaningful information at a higher level of abstraction."
}