{
    "title": "Robust Principal Component Analysis: A Median of Means Approach. (arXiv:2102.03403v2 [stat.ML] UPDATED)",
    "abstract": "Principal Component Analysis (PCA) is a fundamental tool for data visualization, denoising, and dimensionality reduction. It is widely popular in Statistics, Machine Learning, Computer Vision, and related fields. However, PCA is well-known to fall prey to outliers and often fails to detect the true underlying low-dimensional structure within the dataset. Following the Median of Means (MoM) philosophy, recent supervised learning methods have shown great success in dealing with outlying observations without much compromise to their large sample theoretical properties. This paper proposes a PCA procedure based on the MoM principle. Called the \\textbf{M}edian of \\textbf{M}eans \\textbf{P}rincipal \\textbf{C}omponent \\textbf{A}nalysis (MoMPCA), the proposed method is not only computationally appealing but also achieves optimal convergence rates under minimal assumptions. In particular, we explore the non-asymptotic error bounds of the obtained solution via the aid of the Rademacher complexiti",
    "link": "http://arxiv.org/abs/2102.03403",
    "context": "Title: Robust Principal Component Analysis: A Median of Means Approach. (arXiv:2102.03403v2 [stat.ML] UPDATED)\nAbstract: Principal Component Analysis (PCA) is a fundamental tool for data visualization, denoising, and dimensionality reduction. It is widely popular in Statistics, Machine Learning, Computer Vision, and related fields. However, PCA is well-known to fall prey to outliers and often fails to detect the true underlying low-dimensional structure within the dataset. Following the Median of Means (MoM) philosophy, recent supervised learning methods have shown great success in dealing with outlying observations without much compromise to their large sample theoretical properties. This paper proposes a PCA procedure based on the MoM principle. Called the \\textbf{M}edian of \\textbf{M}eans \\textbf{P}rincipal \\textbf{C}omponent \\textbf{A}nalysis (MoMPCA), the proposed method is not only computationally appealing but also achieves optimal convergence rates under minimal assumptions. In particular, we explore the non-asymptotic error bounds of the obtained solution via the aid of the Rademacher complexiti",
    "path": "papers/21/02/2102.03403.json",
    "total_tokens": 804,
    "translated_title": "鲁棒主成分分析：一种中位数求和的方法",
    "translated_abstract": "主成分分析（PCA）是数据可视化、去噪和降维的基本工具。它在统计学、机器学习、计算机视觉等领域广泛应用。然而，PCA容易受到异常值的影响，往往无法检测到数据集中真实的低维结构。本文提出了一种基于中位数求和原则的PCA方法，称为中位数求和主成分分析（MoMPCA）。该方法不仅在计算上具有吸引力，而且在最小假设条件下实现了最优收敛速度。具体来说，我们通过Rademacher复杂度来探索所得解的非渐近误差界限。",
    "tldr": "本文提出了一种基于中位数求和原则的PCA方法，称为中位数求和主成分分析（MoMPCA），以应对异常值对PCA的影响，并在最小假设条件下实现了最优收敛速度。",
    "en_tdlr": "This paper proposes a PCA procedure based on the Median of Means (MoM) principle, called MoMPCA, to address the impact of outliers on PCA and achieve optimal convergence rates under minimal assumptions."
}