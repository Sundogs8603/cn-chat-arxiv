{
    "title": "STS-GAN: Can We Synthesize Solid Texture with High Fidelity from Arbitrary 2D Exemplar?. (arXiv:2102.03973v7 [cs.CV] UPDATED)",
    "abstract": "Solid texture synthesis (STS), an effective way to extend a 2D exemplar to a 3D solid volume, exhibits advantages in computational photography. However, existing methods generally fail to accurately learn arbitrary textures, which may result in the failure to synthesize solid textures with high fidelity. In this paper, we propose a novel generative adversarial nets-based framework (STS-GAN) to extend the given 2D exemplar to arbitrary 3D solid textures. In STS-GAN, multi-scale 2D texture discriminators evaluate the similarity between the given 2D exemplar and slices from the generated 3D texture, promoting the 3D texture generator synthesizing realistic solid textures. Finally, experiments demonstrate that the proposed method can generate high-fidelity solid textures with similar visual characteristics to the 2D exemplar.",
    "link": "http://arxiv.org/abs/2102.03973",
    "context": "Title: STS-GAN: Can We Synthesize Solid Texture with High Fidelity from Arbitrary 2D Exemplar?. (arXiv:2102.03973v7 [cs.CV] UPDATED)\nAbstract: Solid texture synthesis (STS), an effective way to extend a 2D exemplar to a 3D solid volume, exhibits advantages in computational photography. However, existing methods generally fail to accurately learn arbitrary textures, which may result in the failure to synthesize solid textures with high fidelity. In this paper, we propose a novel generative adversarial nets-based framework (STS-GAN) to extend the given 2D exemplar to arbitrary 3D solid textures. In STS-GAN, multi-scale 2D texture discriminators evaluate the similarity between the given 2D exemplar and slices from the generated 3D texture, promoting the 3D texture generator synthesizing realistic solid textures. Finally, experiments demonstrate that the proposed method can generate high-fidelity solid textures with similar visual characteristics to the 2D exemplar.",
    "path": "papers/21/02/2102.03973.json",
    "total_tokens": 839,
    "translated_title": "STS-GAN: 我们能否从任意2D示例合成高保真度的实体纹理？",
    "translated_abstract": "实体纹理合成（STS）是将2D示例扩展到3D实体体积的有效方法，在计算摄影中具有优势。然而，现有方法通常无法准确学习任意纹理，这可能导致合成高保真度实体纹理的失败。本文提出了一种新的基于生成对抗网络的框架（STS-GAN），将给定的2D示例扩展到任意3D实体纹理。在STS-GAN中，多尺度2D纹理鉴别器评估给定的2D示例与生成的3D纹理切片之间的相似性，促进3D纹理生成器合成逼真的实体纹理。最后，实验证明所提出的方法能够生成具有与2D示例类似的视觉特征的高保真度实体纹理。",
    "tldr": "本文提出了一种名为STS-GAN的基于生成对抗网络的框架，能够将给定的2D示例扩展到任意3D实体纹理，并合成具有高保真度和相似特征的实体纹理。",
    "en_tdlr": "This paper introduces a novel generative adversarial nets-based framework (STS-GAN) that can extend a given 2D exemplar to arbitrary 3D solid textures and synthesize solid textures with high fidelity and similar characteristics."
}