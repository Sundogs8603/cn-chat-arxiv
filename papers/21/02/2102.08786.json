{
    "title": "Walking Out of the Weisfeiler Leman Hierarchy: Graph Learning Beyond Message Passing. (arXiv:2102.08786v3 [cs.LG] UPDATED)",
    "abstract": "We propose CRaWl, a novel neural network architecture for graph learning. Like graph neural networks, CRaWl layers update node features on a graph and thus can freely be combined or interleaved with GNN layers. Yet CRaWl operates fundamentally different from message passing graph neural networks. CRaWl layers extract and aggregate information on subgraphs appearing along random walks through a graph using 1D Convolutions. Thereby it detects long range interactions and computes non-local features. As the theoretical basis for our approach, we prove a theorem stating that the expressiveness of CRaWl is incomparable with that of the Weisfeiler Leman algorithm and hence with graph neural networks. That is, there are functions expressible by CRaWl, but not by GNNs and vice versa. This result extends to higher levels of the Weisfeiler Leman hierarchy and thus to higher-order GNNs. Empirically, we show that CRaWl matches state-of-the-art GNN architectures across a multitude of benchmark datas",
    "link": "http://arxiv.org/abs/2102.08786",
    "context": "Title: Walking Out of the Weisfeiler Leman Hierarchy: Graph Learning Beyond Message Passing. (arXiv:2102.08786v3 [cs.LG] UPDATED)\nAbstract: We propose CRaWl, a novel neural network architecture for graph learning. Like graph neural networks, CRaWl layers update node features on a graph and thus can freely be combined or interleaved with GNN layers. Yet CRaWl operates fundamentally different from message passing graph neural networks. CRaWl layers extract and aggregate information on subgraphs appearing along random walks through a graph using 1D Convolutions. Thereby it detects long range interactions and computes non-local features. As the theoretical basis for our approach, we prove a theorem stating that the expressiveness of CRaWl is incomparable with that of the Weisfeiler Leman algorithm and hence with graph neural networks. That is, there are functions expressible by CRaWl, but not by GNNs and vice versa. This result extends to higher levels of the Weisfeiler Leman hierarchy and thus to higher-order GNNs. Empirically, we show that CRaWl matches state-of-the-art GNN architectures across a multitude of benchmark datas",
    "path": "papers/21/02/2102.08786.json",
    "total_tokens": 1075,
    "translated_title": "走出Weisfeiler Leman层次结构：超越消息传递的图学习",
    "translated_abstract": "我们提出了一种新颖的用于图学习的神经网络架构CRaWl。与图神经网络类似，CRaWl层在图上更新节点特征，因此可以自由地与GNN层进行组合或交错使用。然而，CRaWl与消息传递图神经网络在本质上有着不同的操作方式。CRaWl层利用一维卷积从通过图中的随机游走出现的子图中提取和聚合信息，从而检测长程相互作用并计算非局部特征。作为我们方法的理论基础，我们证明了一个定理，即CRaWl的表达能力与Weisfeiler Leman算法以及图神经网络是无法比较的。也就是说，CRaWl能够表达的函数，图神经网络无法表达，反之亦然。此结果可以扩展到Weisfeiler Leman层次的更高级别，从而也适用于高阶GNN。实验证明，CRaWl在多个基准数据集上与最先进的GNN架构相匹配。",
    "tldr": "我们提出了一种名为CRaWl的图学习神经网络架构，它通过利用随机游走过程中出现的子图来提取和聚合信息，从而检测长程相互作用并计算非局部特征。我们证明了CRaWl的表达能力与Weisfeiler Leman算法和图神经网络不可比较，实验证明它在多个基准数据集上与最先进的GNN架构相匹配。",
    "en_tdlr": "We propose CRaWl, a novel neural network architecture for graph learning that operates fundamentally different from message passing graph neural networks. CRaWl extracts and aggregates information on subgraphs appearing along random walks to detect long range interactions and compute non-local features. Our results show that CRaWl's expressiveness is incomparable with that of the Weisfeiler Leman algorithm and graph neural networks, and empirically it matches state-of-the-art GNN architectures across various benchmark datasets."
}