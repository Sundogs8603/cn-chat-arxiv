{
    "title": "Near-Optimal Algorithms for Private Online Learning in a Stochastic Environment. (arXiv:2102.07929v2 [cs.LG] UPDATED)",
    "abstract": "We consider two variants of private stochastic online learning. The first variant is differentially private stochastic bandits. Previously, Sajed and Sheffet (2019) devised the DP Successive Elimination (DP-SE) algorithm that achieves the optimal $ O \\biggl(\\sum\\limits_{1\\le j \\le K: \\Delta_j >0} \\frac{ \\log T}{ \\Delta_j} + \\frac{ K\\log T}{\\epsilon} \\biggr)$ problem-dependent regret bound, where $K$ is the number of arms, $\\Delta_j$ is the mean reward gap of arm $j$, $T$ is the time horizon, and $\\epsilon$ is the required privacy parameter. However, like other elimination style algorithms, it is not an anytime algorithm. Until now, it was not known whether UCB-based algorithms could achieve this optimal regret bound. We present an anytime, UCB-based algorithm that achieves optimality. Our experiments show that the UCB-based algorithm is competitive with DP-SE. The second variant is the full information version of private stochastic online learning. Specifically, for the problem of deci",
    "link": "http://arxiv.org/abs/2102.07929",
    "context": "Title: Near-Optimal Algorithms for Private Online Learning in a Stochastic Environment. (arXiv:2102.07929v2 [cs.LG] UPDATED)\nAbstract: We consider two variants of private stochastic online learning. The first variant is differentially private stochastic bandits. Previously, Sajed and Sheffet (2019) devised the DP Successive Elimination (DP-SE) algorithm that achieves the optimal $ O \\biggl(\\sum\\limits_{1\\le j \\le K: \\Delta_j >0} \\frac{ \\log T}{ \\Delta_j} + \\frac{ K\\log T}{\\epsilon} \\biggr)$ problem-dependent regret bound, where $K$ is the number of arms, $\\Delta_j$ is the mean reward gap of arm $j$, $T$ is the time horizon, and $\\epsilon$ is the required privacy parameter. However, like other elimination style algorithms, it is not an anytime algorithm. Until now, it was not known whether UCB-based algorithms could achieve this optimal regret bound. We present an anytime, UCB-based algorithm that achieves optimality. Our experiments show that the UCB-based algorithm is competitive with DP-SE. The second variant is the full information version of private stochastic online learning. Specifically, for the problem of deci",
    "path": "papers/21/02/2102.07929.json",
    "total_tokens": 780,
    "translated_title": "隐私在线随机学习的近似最优算法。",
    "translated_abstract": "本文研究了两种私有随机在线学习的变体。第一种变体是差分隐私的随机赌博机算法。本文提出了一种随时可用的基于UCB的算法，可以达到最优性能。第二种变体是私有随机在线学习的完全信息版本。我们提出了一种新的算法，可同时获得隐私和性能的良好表现。",
    "tldr": "本文提出了两种隐私在线随机学习的算法，包括差分隐私的随机赌博机算法和私有随机在线学习的完全信息版本。其中，我们提出的随时可用的基于UCB的算法达到了最优性能。"
}