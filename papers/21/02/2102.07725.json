{
    "title": "Neural Network Compression for Noisy Storage Devices. (arXiv:2102.07725v2 [cs.LG] UPDATED)",
    "abstract": "Compression and efficient storage of neural network (NN) parameters is critical for applications that run on resource-constrained devices. Despite the significant progress in NN model compression, there has been considerably less investigation in the actual \\textit{physical} storage of NN parameters. Conventionally, model compression and physical storage are decoupled, as digital storage media with error-correcting codes (ECCs) provide robust error-free storage. However, this decoupled approach is inefficient as it ignores the overparameterization present in most NNs and forces the memory device to allocate the same amount of resources to every bit of information regardless of its importance. In this work, we investigate analog memory devices as an alternative to digital media -- one that naturally provides a way to add more protection for significant bits unlike its counterpart, but is noisy and may compromise the stored model's performance if used naively. We develop a variety of rob",
    "link": "http://arxiv.org/abs/2102.07725",
    "context": "Title: Neural Network Compression for Noisy Storage Devices. (arXiv:2102.07725v2 [cs.LG] UPDATED)\nAbstract: Compression and efficient storage of neural network (NN) parameters is critical for applications that run on resource-constrained devices. Despite the significant progress in NN model compression, there has been considerably less investigation in the actual \\textit{physical} storage of NN parameters. Conventionally, model compression and physical storage are decoupled, as digital storage media with error-correcting codes (ECCs) provide robust error-free storage. However, this decoupled approach is inefficient as it ignores the overparameterization present in most NNs and forces the memory device to allocate the same amount of resources to every bit of information regardless of its importance. In this work, we investigate analog memory devices as an alternative to digital media -- one that naturally provides a way to add more protection for significant bits unlike its counterpart, but is noisy and may compromise the stored model's performance if used naively. We develop a variety of rob",
    "path": "papers/21/02/2102.07725.json",
    "total_tokens": 935,
    "translated_title": "噪声存储设备的神经网络压缩",
    "translated_abstract": "对神经网络（NN）参数的压缩和高效存储对于在资源受限设备上运行的应用程序至关重要。尽管在NN模型压缩方面取得了重大进展，但对NN参数的实际物理存储进行了相对较少的研究。我们研究了使用类比存储设备作为数字介质的替代方案，这种方法自然地提供了一种添加更多重要位保护的方法，但存在噪声并可能损害存储模型的性能。我们开发了多种针对模拟存储设备属性的鲁棒NN压缩技术，并证明了它们在注入噪声的几个基准数据集上的有效性。与最先进的数字压缩方法相比，我们的技术将NN的存储效率提高了一个数量级。",
    "tldr": "本文研究了神经网络在使用噪声存储设备时的压缩与存储问题，提出了适用于模拟存储设备的鲁棒压缩技术，相对于数字压缩方法，有效提高了NN的存储效率。",
    "en_tdlr": "This paper investigates the compression and storage efficiency of neural networks (NNs) for resource-constrained devices using analog storage devices. The authors develop robust NN compression techniques tailored to the properties of analog storage devices and show that they improve storage efficiency by up to an order of magnitude compared to state-of-the-art digital compression methods, thus providing a solution that could benefit applications with noisy storage devices."
}