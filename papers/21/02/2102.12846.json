{
    "title": "QNLP in Practice: Running Compositional Models of Meaning on a Quantum Computer. (arXiv:2102.12846v2 [cs.CL] UPDATED)",
    "abstract": "Quantum Natural Language Processing (QNLP) deals with the design and implementation of NLP models intended to be run on quantum hardware. In this paper, we present results on the first NLP experiments conducted on Noisy Intermediate-Scale Quantum (NISQ) computers for datasets of size greater than 100 sentences. Exploiting the formal similarity of the compositional model of meaning by Coecke, Sadrzadeh and Clark (2010) with quantum theory, we create representations for sentences that have a natural mapping to quantum circuits. We use these representations to implement and successfully train NLP models that solve simple sentence classification tasks on quantum hardware. We conduct quantum simulations that compare the syntax-sensitive model of Coecke et al. with two baselines that use less or no syntax; specifically, we implement the quantum analogues of a \"bag-of-words\" model, where syntax is not taken into account at all, and of a word-sequence model, where only word order is respected.",
    "link": "http://arxiv.org/abs/2102.12846",
    "context": "Title: QNLP in Practice: Running Compositional Models of Meaning on a Quantum Computer. (arXiv:2102.12846v2 [cs.CL] UPDATED)\nAbstract: Quantum Natural Language Processing (QNLP) deals with the design and implementation of NLP models intended to be run on quantum hardware. In this paper, we present results on the first NLP experiments conducted on Noisy Intermediate-Scale Quantum (NISQ) computers for datasets of size greater than 100 sentences. Exploiting the formal similarity of the compositional model of meaning by Coecke, Sadrzadeh and Clark (2010) with quantum theory, we create representations for sentences that have a natural mapping to quantum circuits. We use these representations to implement and successfully train NLP models that solve simple sentence classification tasks on quantum hardware. We conduct quantum simulations that compare the syntax-sensitive model of Coecke et al. with two baselines that use less or no syntax; specifically, we implement the quantum analogues of a \"bag-of-words\" model, where syntax is not taken into account at all, and of a word-sequence model, where only word order is respected.",
    "path": "papers/21/02/2102.12846.json",
    "total_tokens": 940,
    "translated_title": "实践中的QNLP：在量子计算机上运行组合模型的含义。",
    "translated_abstract": "量子自然语言处理（QNLP）涉及设计和实现旨在在量子硬件上运行的NLP模型。在本文中，我们介绍了在嘈杂的中间规模量子（NISQ）计算机上进行的首个大于100个句子数据集的NLP实验结果。利用由Coecke、Sadrzadeh和Clark（2010）提出的含义组合模型与量子理论的形式相似性，我们创建了具有自然映射到量子电路的句子表示。我们使用这些表示来实现并成功训练在量子硬件上解决简单句子分类任务的NLP模型。我们进行了量子模拟，比较了Coecke等人的语法敏感模型与使用较少或无语法的两个基线，具体而言，我们实现了“词袋”模型的量子模拟，其中根本不考虑语法，以及单词序列模型的量子模拟，仅尊重单词顺序。",
    "tldr": "本文介绍了在嘈杂的中间规模量子计算机上进行的首个大于100个句子数据集的NLP实验结果，成功地训练了解决简单句子分类任务的NLP模型，证明了组合模型的含义与量子理论具有形式相似性。",
    "en_tdlr": "This paper presents the first NLP experiments conducted on Noisy Intermediate-Scale Quantum computers for datasets of size greater than 100 sentences, successfully showing the training of NLP models that solve simple sentence classification tasks on quantum hardware and demonstrating the formal similarity between the compositional model of meaning and quantum theory."
}