{
    "title": "Non-stationary Online Learning with Memory and Non-stochastic Control. (arXiv:2102.03758v4 [cs.LG] UPDATED)",
    "abstract": "We study the problem of Online Convex Optimization (OCO) with memory, which allows loss functions to depend on past decisions and thus captures temporal effects of learning problems. In this paper, we introduce dynamic policy regret as the performance measure to design algorithms robust to non-stationary environments, which competes algorithms' decisions with a sequence of changing comparators. We propose a novel algorithm for OCO with memory that provably enjoys an optimal dynamic policy regret in terms of time horizon, non-stationarity measure, and memory length. The key technical challenge is how to control the switching cost, the cumulative movements of player's decisions, which is neatly addressed by a novel switching-cost-aware online ensemble approach equipped with a new meta-base decomposition of dynamic policy regret and a careful design of meta-learner and base-learner that explicitly regularizes the switching cost. The results are further applied to tackle non-stationarity i",
    "link": "http://arxiv.org/abs/2102.03758",
    "context": "Title: Non-stationary Online Learning with Memory and Non-stochastic Control. (arXiv:2102.03758v4 [cs.LG] UPDATED)\nAbstract: We study the problem of Online Convex Optimization (OCO) with memory, which allows loss functions to depend on past decisions and thus captures temporal effects of learning problems. In this paper, we introduce dynamic policy regret as the performance measure to design algorithms robust to non-stationary environments, which competes algorithms' decisions with a sequence of changing comparators. We propose a novel algorithm for OCO with memory that provably enjoys an optimal dynamic policy regret in terms of time horizon, non-stationarity measure, and memory length. The key technical challenge is how to control the switching cost, the cumulative movements of player's decisions, which is neatly addressed by a novel switching-cost-aware online ensemble approach equipped with a new meta-base decomposition of dynamic policy regret and a careful design of meta-learner and base-learner that explicitly regularizes the switching cost. The results are further applied to tackle non-stationarity i",
    "path": "papers/21/02/2102.03758.json",
    "total_tokens": 930,
    "translated_title": "非平稳在线学习中的记忆与非随机控制问题",
    "translated_abstract": "本文研究了具有记忆的在线凸优化问题（OCO），其中损失函数可以依赖于过去的决策，从而捕捉到学习问题的时间效应。我们引入了动态策略遗憾作为性能度量，以设计在非平稳环境下鲁棒的算法，该算法将算法的决策与一系列变化的比较器进行竞争。我们提出了一种新的OCO记忆算法，它在时间跨度、非平稳度量和记忆长度方面保证了最佳的动态策略遗憾。关键技术挑战是如何控制切换成本，即参与者决策的累积移动量，这个问题通过一种新颖的切换成本感知在线合奏方法得到了巧妙解决，该方法采用了动态策略遗憾的新的元基分解和一个精心设计的元学习器和基学习器，以显式地规范化切换成本。",
    "tldr": "本文研究了具有记忆的非平稳在线凸优化问题，引入了动态策略遗憾作为性能度量，并提出了一种算法，通过新颖的切换成本感知在线合奏方法解决了切换成本的关键技术挑战。",
    "en_tdlr": "This paper studies the problem of non-stationary online convex optimization with memory. It introduces dynamic policy regret as a performance measure and proposes a novel algorithm that addresses the key technical challenge of controlling the switching cost using a switching-cost-aware online ensemble approach."
}