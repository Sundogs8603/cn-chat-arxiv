{
    "title": "Towards Adversarial-Resilient Deep Neural Networks for False Data Injection Attack Detection in Power Grids. (arXiv:2102.09057v2 [cs.CR] UPDATED)",
    "abstract": "False data injection attacks (FDIAs) pose a significant security threat to power system state estimation. To detect such attacks, recent studies have proposed machine learning (ML) techniques, particularly deep neural networks (DNNs). However, most of these methods fail to account for the risk posed by adversarial measurements, which can compromise the reliability of DNNs in various ML applications. In this paper, we present a DNN-based FDIA detection approach that is resilient to adversarial attacks. We first analyze several adversarial defense mechanisms used in computer vision and show their inherent limitations in FDIA detection. We then propose an adversarial-resilient DNN detection framework for FDIA that incorporates random input padding in both the training and inference phases. Our simulations, based on an IEEE standard power system, demonstrate that this framework significantly reduces the effectiveness of adversarial attacks while having a negligible impact on the DNNs' dete",
    "link": "http://arxiv.org/abs/2102.09057",
    "context": "Title: Towards Adversarial-Resilient Deep Neural Networks for False Data Injection Attack Detection in Power Grids. (arXiv:2102.09057v2 [cs.CR] UPDATED)\nAbstract: False data injection attacks (FDIAs) pose a significant security threat to power system state estimation. To detect such attacks, recent studies have proposed machine learning (ML) techniques, particularly deep neural networks (DNNs). However, most of these methods fail to account for the risk posed by adversarial measurements, which can compromise the reliability of DNNs in various ML applications. In this paper, we present a DNN-based FDIA detection approach that is resilient to adversarial attacks. We first analyze several adversarial defense mechanisms used in computer vision and show their inherent limitations in FDIA detection. We then propose an adversarial-resilient DNN detection framework for FDIA that incorporates random input padding in both the training and inference phases. Our simulations, based on an IEEE standard power system, demonstrate that this framework significantly reduces the effectiveness of adversarial attacks while having a negligible impact on the DNNs' dete",
    "path": "papers/21/02/2102.09057.json",
    "total_tokens": 974,
    "translated_title": "针对电力系统中虚假数据攻击检测的对抗性深度神经网络研究",
    "translated_abstract": "虚假数据注入攻击（FDIA）对电力系统状态估计造成了重大安全威胁。为了检测这种攻击，近期的研究提出了机器学习（ML）技术，特别是深度神经网络（DNNs）。然而，这些方法中大多数未能考虑对抗性测量带来的风险，这可能危及各种ML应用中DNNs的可靠性。在本文中，我们提出了一种对抗性网络，用于FDIA检测。我们首先分析了计算机视觉中使用的几种对抗防御机制，并展示了它们在FDIA检测中的固有限制。接着，我们提出了一种对抗攻击弹性的DNN检测框架来检测FDIA，在训练和推理阶段都采用随机输入填充技术。我们基于IEEE标准电力系统进行的仿真实验表明，这种框架显著降低了对抗攻击的有效性，同时对DNN在FDIA检测中的检测性能的影响非常小。",
    "tldr": "本文提出了一种对抗性深度神经网络方法，用于电力系统中虚假数据注入攻击检测，并在训练和推理阶段采用随机输入填充技术，从而显著减少对抗攻击的有效性。"
}