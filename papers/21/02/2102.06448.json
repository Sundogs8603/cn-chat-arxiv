{
    "title": "The MSR-Video to Text Dataset with Clean Annotations",
    "abstract": "arXiv:2102.06448v4 Announce Type: replace-cross  Abstract: Video captioning automatically generates short descriptions of the video content, usually in form of a single sentence. Many methods have been proposed for solving this task. A large dataset called MSR Video to Text (MSR-VTT) is often used as the benchmark dataset for testing the performance of the methods. However, we found that the human annotations, i.e., the descriptions of video contents in the dataset are quite noisy, e.g., there are many duplicate captions and many captions contain grammatical problems. These problems may pose difficulties to video captioning models for learning underlying patterns. We cleaned the MSR-VTT annotations by removing these problems, then tested several typical video captioning models on the cleaned dataset. Experimental results showed that data cleaning boosted the performances of the models measured by popular quantitative metrics. We recruited subjects to evaluate the results of a model tra",
    "link": "https://arxiv.org/abs/2102.06448",
    "context": "Title: The MSR-Video to Text Dataset with Clean Annotations\nAbstract: arXiv:2102.06448v4 Announce Type: replace-cross  Abstract: Video captioning automatically generates short descriptions of the video content, usually in form of a single sentence. Many methods have been proposed for solving this task. A large dataset called MSR Video to Text (MSR-VTT) is often used as the benchmark dataset for testing the performance of the methods. However, we found that the human annotations, i.e., the descriptions of video contents in the dataset are quite noisy, e.g., there are many duplicate captions and many captions contain grammatical problems. These problems may pose difficulties to video captioning models for learning underlying patterns. We cleaned the MSR-VTT annotations by removing these problems, then tested several typical video captioning models on the cleaned dataset. Experimental results showed that data cleaning boosted the performances of the models measured by popular quantitative metrics. We recruited subjects to evaluate the results of a model tra",
    "path": "papers/21/02/2102.06448.json",
    "total_tokens": 754,
    "translated_title": "具有干净标注的MSR-Video to Text数据集",
    "translated_abstract": "视频字幕自动生成视频内容的简短描述，通常是一句话的形式。已经提出了许多解决这一任务的方法。一个名为MSR Video to Text（MSR-VTT）的大型数据集经常被用作测试这些方法性能的基准数据集。然而，我们发现数据集中的人工标注，即视频内容描述，存在相当多的噪音，例如许多重复字幕和许多字幕包含语法问题。这些问题可能会给视频字幕模型学习底层模式带来困难。我们通过消除这些问题来清理MSR-VTT的标注，然后在清理后的数据集上测试了几种典型的视频字幕模型。实验结果显示，数据清洗提升了模型的性能，以流行的定量指标衡量。我们招募了受试者来评估模型的结果。",
    "tldr": "清洗了MSR-VTT数据集中的标注，提高了视频字幕模型的性能。",
    "en_tdlr": "Cleaning the annotations in the MSR-VTT dataset improved the performance of video captioning models."
}