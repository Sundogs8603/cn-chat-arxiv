{
    "title": "Learning Optimal Strategies for Temporal Tasks in Stochastic Games. (arXiv:2102.04307v3 [cs.AI] UPDATED)",
    "abstract": "Synthesis from linear temporal logic (LTL) specifications provides assured controllers for systems operating in stochastic and potentially adversarial environments. Automatic synthesis tools, however, require a model of the environment to construct controllers. In this work, we introduce a model-free reinforcement learning (RL) approach to derive controllers from given LTL specifications even when the environment is completely unknown. We model the problem as a stochastic game (SG) between the controller and the adversarial environment; we then learn optimal control strategies that maximize the probability of satisfying the LTL specifications against the worst-case environment behavior. We first construct a product game using the deterministic parity automaton (DPA) translated from the given LTL specification. By deriving distinct rewards and discount factors from the acceptance condition of the DPA, we reduce the maximization of the worst-case probability of satisfying the LTL specifi",
    "link": "http://arxiv.org/abs/2102.04307",
    "context": "Title: Learning Optimal Strategies for Temporal Tasks in Stochastic Games. (arXiv:2102.04307v3 [cs.AI] UPDATED)\nAbstract: Synthesis from linear temporal logic (LTL) specifications provides assured controllers for systems operating in stochastic and potentially adversarial environments. Automatic synthesis tools, however, require a model of the environment to construct controllers. In this work, we introduce a model-free reinforcement learning (RL) approach to derive controllers from given LTL specifications even when the environment is completely unknown. We model the problem as a stochastic game (SG) between the controller and the adversarial environment; we then learn optimal control strategies that maximize the probability of satisfying the LTL specifications against the worst-case environment behavior. We first construct a product game using the deterministic parity automaton (DPA) translated from the given LTL specification. By deriving distinct rewards and discount factors from the acceptance condition of the DPA, we reduce the maximization of the worst-case probability of satisfying the LTL specifi",
    "path": "papers/21/02/2102.04307.json",
    "total_tokens": 960,
    "translated_title": "在随机博弈中学习时态任务的最优策略",
    "translated_abstract": "从线性时态逻辑（LTL）规范中进行合成可以为在随机和潜在对抗环境中运行的系统提供保证的控制器。然而，自动合成工具需要一个环境模型来构建控制器。在这项工作中，我们引入了一种无模型强化学习（RL）方法，用于从给定的LTL规范中推导控制器，即使环境完全未知。我们将问题建模为控制器和对抗环境之间的随机博弈（SG），然后学习最优控制策略，以最大化满足LTL规范的概率，抵抗最坏情况下的环境行为。我们首先使用从给定LTL规范翻译的确定性奇偶自动机（DPA）构建一个乘积博弈。通过从DPA接受条件导出不同的奖励和折扣因子，我们将最大化最坏情况下满足LTL规范的概率的问题简化为一个强化学习问题。",
    "tldr": "本论文提出了一种无模型强化学习方法，用于从给定的LTL规范中学习最优控制策略，即使环境完全未知。该方法通过将问题建模为控制器和对抗环境之间的随机博弈，最大化满足LTL规范的概率，抵抗最坏情况下的环境行为。",
    "en_tdlr": "This paper introduces a model-free reinforcement learning approach to derive optimal control strategies from given LTL specifications even when the environment is completely unknown. The method models the problem as a stochastic game between the controller and the adversarial environment, aiming to maximize the probability of satisfying the LTL specifications against the worst-case environment behavior."
}