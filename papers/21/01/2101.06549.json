{
    "title": "AdvSim: Generating Safety-Critical Scenarios for Self-Driving Vehicles. (arXiv:2101.06549v4 [cs.RO] UPDATED)",
    "abstract": "As self-driving systems become better, simulating scenarios where the autonomy stack may fail becomes more important. Traditionally, those scenarios are generated for a few scenes with respect to the planning module that takes ground-truth actor states as input. This does not scale and cannot identify all possible autonomy failures, such as perception failures due to occlusion. In this paper, we propose AdvSim, an adversarial framework to generate safety-critical scenarios for any LiDAR-based autonomy system. Given an initial traffic scenario, AdvSim modifies the actors' trajectories in a physically plausible manner and updates the LiDAR sensor data to match the perturbed world. Importantly, by simulating directly from sensor data, we obtain adversarial scenarios that are safety-critical for the full autonomy stack. Our experiments show that our approach is general and can identify thousands of semantically meaningful safety-critical scenarios for a wide range of modern self-driving sy",
    "link": "http://arxiv.org/abs/2101.06549",
    "context": "Title: AdvSim: Generating Safety-Critical Scenarios for Self-Driving Vehicles. (arXiv:2101.06549v4 [cs.RO] UPDATED)\nAbstract: As self-driving systems become better, simulating scenarios where the autonomy stack may fail becomes more important. Traditionally, those scenarios are generated for a few scenes with respect to the planning module that takes ground-truth actor states as input. This does not scale and cannot identify all possible autonomy failures, such as perception failures due to occlusion. In this paper, we propose AdvSim, an adversarial framework to generate safety-critical scenarios for any LiDAR-based autonomy system. Given an initial traffic scenario, AdvSim modifies the actors' trajectories in a physically plausible manner and updates the LiDAR sensor data to match the perturbed world. Importantly, by simulating directly from sensor data, we obtain adversarial scenarios that are safety-critical for the full autonomy stack. Our experiments show that our approach is general and can identify thousands of semantically meaningful safety-critical scenarios for a wide range of modern self-driving sy",
    "path": "papers/21/01/2101.06549.json",
    "total_tokens": 932,
    "translated_title": "AdvSim: 生成自动驾驶车辆的安全关键场景",
    "translated_abstract": "随着自动驾驶系统的不断提升，模拟可能出现自主堆栈失败的情况变得越来越重要。传统上，这些场景只为规划模块生成了一些相对较少的场景，其输入为地面真实车辆状态。这不具有可扩展性，并且无法识别所有可能的自主失败，例如由于遮挡导致的感知故障。本文提出了AdvSim，一个对于任何基于激光雷达的自主系统生成安全关键场景的对抗性框架。给定一个初始交通场景，AdvSim以物理可行的方式修改参与者的轨迹并更新激光雷达传感器数据以匹配受扰动的世界。重要的是，通过直接从传感器数据进行模拟，我们获得安全关键场景，适用于完整的自主堆栈。我们的实验表明，我们的方法具有普适性，可以识别出大量具有语义意义的安全关键场景，适用于现代自动驾驶系统的各种情况。",
    "tldr": "提出了AdvSim框架，利用对抗性方法生成自动驾驶车辆的安全关键场景，具有可扩展性，适用于任何基于激光雷达的自主系统，可以识别各种具有语义意义的安全关键场景。",
    "en_tdlr": "AdvSim framework is proposed to generate safety-critical scenarios for self-driving vehicles using adversarial methods, which is scalable for any LiDAR-based autonomy system, and can identify various semantically meaningful safety-critical scenarios."
}