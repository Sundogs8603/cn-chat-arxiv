{
    "title": "ISP Distillation. (arXiv:2101.10203v3 [cs.CV] UPDATED)",
    "abstract": "Nowadays, many of the images captured are `observed' by machines only and not by humans, e.g., in autonomous systems. High-level machine vision models, such as object recognition or semantic segmentation, assume images are transformed into some canonical image space by the camera \\ans{Image Signal Processor (ISP)}. However, the camera ISP is optimized for producing visually pleasing images for human observers and not for machines. Therefore, one may spare the ISP compute time and apply vision models directly to RAW images. Yet, it has been shown that training such models directly on RAW images results in a performance drop. To mitigate this drop, we use a RAW and RGB image pairs dataset, which can be easily acquired with no human labeling. We then train a model that is applied directly to the RAW data by using knowledge distillation such that the model predictions for RAW images will be aligned with the predictions of an off-the-shelf pre-trained model for processed RGB images. Our exp",
    "link": "http://arxiv.org/abs/2101.10203",
    "context": "Title: ISP Distillation. (arXiv:2101.10203v3 [cs.CV] UPDATED)\nAbstract: Nowadays, many of the images captured are `observed' by machines only and not by humans, e.g., in autonomous systems. High-level machine vision models, such as object recognition or semantic segmentation, assume images are transformed into some canonical image space by the camera \\ans{Image Signal Processor (ISP)}. However, the camera ISP is optimized for producing visually pleasing images for human observers and not for machines. Therefore, one may spare the ISP compute time and apply vision models directly to RAW images. Yet, it has been shown that training such models directly on RAW images results in a performance drop. To mitigate this drop, we use a RAW and RGB image pairs dataset, which can be easily acquired with no human labeling. We then train a model that is applied directly to the RAW data by using knowledge distillation such that the model predictions for RAW images will be aligned with the predictions of an off-the-shelf pre-trained model for processed RGB images. Our exp",
    "path": "papers/21/01/2101.10203.json",
    "total_tokens": 961,
    "translated_title": "ISP精馏",
    "translated_abstract": "如今，许多图像只能由机器而不是人类“观察”，例如在自动系统中。高级机器视觉模型（如对象识别或语义分割）假定相机将图像转换为某个规范化的图像空间，即图像信号处理器（ISP）。然而，相机ISP优化的是为人类观察者生成视觉上令人愉悦的图像，而不是机器。因此，我们可能会省略ISP的计算时间，直接将视觉模型应用于RAW图像。然而，直接在RAW图像上训练这些模型会导致性能下降。为了缓解这种下降，我们使用了一个RAW和RGB图像对数据集，该数据集可以轻松获取且无需人工标记。然后，我们使用知识蒸馏来训练一个直接应用于RAW数据的模型，使得该模型对于RAW图像的预测与已处理的RGB图像的预测相匹配。我们在语义分割和目标检测任务上的实验表明，我们提出的ISP精馏方法可以持续而显著地提高直接应用机器视觉模型于RAW图像的性能。",
    "tldr": "该论文介绍了一种称为ISP精馏的方法，通过使用知识蒸馏将RAW图像的预测与经过处理的RGB图像的预测相匹配，成功地提高了直接将机器视觉模型应用于RAW图像的性能。",
    "en_tdlr": "This paper presents a method called ISP distillation, which aligns the predictions of RAW images with those of processed RGB images through knowledge distillation, and successfully improves the performance of applying machine vision models directly to RAW images."
}