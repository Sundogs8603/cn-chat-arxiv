{
    "title": "Fundamental limits and algorithms for sparse linear regression with sublinear sparsity. (arXiv:2101.11156v6 [cs.IT] UPDATED)",
    "abstract": "We establish exact asymptotic expressions for the normalized mutual information and minimum mean-square-error (MMSE) of sparse linear regression in the sub-linear sparsity regime. Our result is achieved by a generalization of the adaptive interpolation method in Bayesian inference for linear regimes to sub-linear ones. A modification of the well-known approximate message passing algorithm to approach the MMSE fundamental limit is also proposed, and its state evolution is rigorously analyzed. Our results show that the traditional linear assumption between the signal dimension and number of observations in the replica and adaptive interpolation methods is not necessary for sparse signals. They also show how to modify the existing well-known AMP algorithms for linear regimes to sub-linear ones.",
    "link": "http://arxiv.org/abs/2101.11156",
    "context": "Title: Fundamental limits and algorithms for sparse linear regression with sublinear sparsity. (arXiv:2101.11156v6 [cs.IT] UPDATED)\nAbstract: We establish exact asymptotic expressions for the normalized mutual information and minimum mean-square-error (MMSE) of sparse linear regression in the sub-linear sparsity regime. Our result is achieved by a generalization of the adaptive interpolation method in Bayesian inference for linear regimes to sub-linear ones. A modification of the well-known approximate message passing algorithm to approach the MMSE fundamental limit is also proposed, and its state evolution is rigorously analyzed. Our results show that the traditional linear assumption between the signal dimension and number of observations in the replica and adaptive interpolation methods is not necessary for sparse signals. They also show how to modify the existing well-known AMP algorithms for linear regimes to sub-linear ones.",
    "path": "papers/21/01/2101.11156.json",
    "total_tokens": 869,
    "translated_title": "稀疏线性回归中的基本极限和算法与次线性稀疏性。",
    "translated_abstract": "我们在次线性稀疏性区间建立了稀疏线性回归的归一化互信息和最小均方误差（MMSE）的精确渐近表达式。我们通过将贝叶斯推断中线性区域的自适应插值方法推广到次线性区域来实现我们的结果。我们还提出了一种修改着名的近似信息传递算法以接近MMSE基本极限的方法，并对其状态演化进行了严格分析。我们的结果表明，对于稀疏信号，复制和自适应插值方法中信号维数和观测个数之间的传统线性假设是不必要的。它们还展示了如何将现有的着名的线性区域的AMP算法修改为次线性区域。",
    "tldr": "本文通过将贝叶斯推断中线性区域的自适应插值方法推广到次线性区域，建立了稀疏线性回归的归一化互信息和最小均方误差的精确渐近表达式，并提出了一种修改近似信息传递算法以接近最小均方误差基本极限的方法。",
    "en_tdlr": "This paper establishes exact asymptotic expressions for the normalized mutual information and minimum mean-square-error of sparse linear regression in the sub-linear sparsity regime by generalizing the adaptive interpolation method in Bayesian inference for linear regimes to sub-linear ones. It also proposes a modification of the approximate message passing algorithm to approach the MMSE fundamental limit and shows how to modify existing AMP algorithms for linear regimes to sub-linear ones."
}