{
    "title": "A Symmetric Loss Perspective of Reliable Machine Learning. (arXiv:2101.01366v2 [stat.ML] UPDATED)",
    "abstract": "When minimizing the empirical risk in binary classification, it is a common practice to replace the zero-one loss with a surrogate loss to make the learning objective feasible to optimize. Examples of well-known surrogate losses for binary classification include the logistic loss, hinge loss, and sigmoid loss. It is known that the choice of a surrogate loss can highly influence the performance of the trained classifier and therefore it should be carefully chosen. Recently, surrogate losses that satisfy a certain symmetric condition (aka., symmetric losses) have demonstrated their usefulness in learning from corrupted labels. In this article, we provide an overview of symmetric losses and their applications. First, we review how a symmetric loss can yield robust classification from corrupted labels in balanced error rate (BER) minimization and area under the receiver operating characteristic curve (AUC) maximization. Then, we demonstrate how the robust AUC maximization method can benefi",
    "link": "http://arxiv.org/abs/2101.01366",
    "context": "Title: A Symmetric Loss Perspective of Reliable Machine Learning. (arXiv:2101.01366v2 [stat.ML] UPDATED)\nAbstract: When minimizing the empirical risk in binary classification, it is a common practice to replace the zero-one loss with a surrogate loss to make the learning objective feasible to optimize. Examples of well-known surrogate losses for binary classification include the logistic loss, hinge loss, and sigmoid loss. It is known that the choice of a surrogate loss can highly influence the performance of the trained classifier and therefore it should be carefully chosen. Recently, surrogate losses that satisfy a certain symmetric condition (aka., symmetric losses) have demonstrated their usefulness in learning from corrupted labels. In this article, we provide an overview of symmetric losses and their applications. First, we review how a symmetric loss can yield robust classification from corrupted labels in balanced error rate (BER) minimization and area under the receiver operating characteristic curve (AUC) maximization. Then, we demonstrate how the robust AUC maximization method can benefi",
    "path": "papers/21/01/2101.01366.json",
    "total_tokens": 838,
    "translated_title": "可靠机器学习的对称损失视角",
    "translated_abstract": "当在二元分类中最小化经验风险时，常常将零一损失替换为代理损失，以使学习目标易于优化。二元分类的代理损失例如逻辑损失，hinge损失和sigmoid损失广为人知。已知代理损失的选择会极大地影响训练分类器的性能，因此应该仔细选择。最近，满足某些对称条件（称为对称损失）的代理损失已经证明了它们在学习来自损坏标签的数据方面的实用性。在本文中，我们提供对称损失及其应用的概述。首先，我们回顾了对称损失如何在平衡误差率（BER）最小化和操作特征曲线下面积（AUC）最大化中产生鲁棒分类的方法。然后，我们演示了鲁棒AUC最大化方法可以受益于受损标签，尤其是与其他代理损失相比。",
    "tldr": "对称损失是一种新型的代理损失，能够使得学习过程对于受损标签更加鲁棒，从而提高分类器的性能。"
}