{
    "title": "SANSformers: Self-Supervised Forecasting in Electronic Health Records with Attention-Free Models. (arXiv:2108.13672v3 [cs.LG] UPDATED)",
    "abstract": "The application of Transformer neural networks to Electronic Health Records (EHR) is challenging due to the distinct, multidimensional sequential structure of EHR data, often leading to underperformance when compared to simpler linear models. Thus, the advantages of Transformers, such as efficient transfer learning and improved scalability are not fully exploited in EHR applications. To overcome these challenges, we introduce SANSformer, a novel attention-free sequential model designed specifically with inductive biases to cater for the unique characteristics of EHR data.  Our main application area is predicting future healthcare utilization, a crucial task for effectively allocating healthcare resources. This task becomes particularly difficult when dealing with divergent patient subgroups. These subgroups, characterized by unique health trajectories and often small in size, such as patients with rare diseases, require specialized modeling approaches. To address this, we adopt a self-",
    "link": "http://arxiv.org/abs/2108.13672",
    "context": "Title: SANSformers: Self-Supervised Forecasting in Electronic Health Records with Attention-Free Models. (arXiv:2108.13672v3 [cs.LG] UPDATED)\nAbstract: The application of Transformer neural networks to Electronic Health Records (EHR) is challenging due to the distinct, multidimensional sequential structure of EHR data, often leading to underperformance when compared to simpler linear models. Thus, the advantages of Transformers, such as efficient transfer learning and improved scalability are not fully exploited in EHR applications. To overcome these challenges, we introduce SANSformer, a novel attention-free sequential model designed specifically with inductive biases to cater for the unique characteristics of EHR data.  Our main application area is predicting future healthcare utilization, a crucial task for effectively allocating healthcare resources. This task becomes particularly difficult when dealing with divergent patient subgroups. These subgroups, characterized by unique health trajectories and often small in size, such as patients with rare diseases, require specialized modeling approaches. To address this, we adopt a self-",
    "path": "papers/21/08/2108.13672.json",
    "total_tokens": 970,
    "translated_title": "SANSformers: 无注意力模型在电子健康记录中的自我监督预测",
    "translated_abstract": "Transformer神经网络在电子健康记录（EHR）中的应用面临挑战，由于EHR数据具有独特的多维顺序结构，所以与简单的线性模型相比往往表现不佳。因此，Transformer的优势，如高效的迁移学习和改进的可扩展性，在EHR应用中没有得到充分利用。为了克服这些挑战，我们引入了SANSformer，这是一种新颖的无注意力序列模型，专门设计以适应EHR数据的独特特征。我们的主要应用领域是预测未来的医疗资源利用，这是有效分配医疗资源的关键任务。当处理不同的患者子组时，这个任务变得特别困难。这些被唯一的健康轨迹所特征化的子组，往往规模较小，如罕见疾病患者，需要特殊的建模方法。为了解决这个问题，我们采用了一种自我监督的方法，将多个子组的预测任务转化为一个整体的预测任务。",
    "tldr": "使用无注意力的序列模型SANSformer在电子健康记录中进行自我监督预测，充分挖掘了Transformer在EHR应用中的优势。主要应用于预测未来的医疗资源利用，特别适用于处理不同患者子组，如罕见疾病患者。",
    "en_tdlr": "SANSformer, an attention-free sequential model, is applied to Electronic Health Records for self-supervised forecasting. It fully exploits the advantages of Transformers in EHR applications and is particularly useful for predicting future healthcare utilization, especially in diverse patient subgroups such as patients with rare diseases."
}