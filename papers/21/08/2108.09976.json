{
    "title": "Revealing the Distributional Vulnerability of Discriminators by Implicit Generators. (arXiv:2108.09976v4 [cs.LG] UPDATED)",
    "abstract": "In deep neural learning, a discriminator trained on in-distribution (ID) samples may make high-confidence predictions on out-of-distribution (OOD) samples. This triggers a significant matter for robust, trustworthy and safe deep learning. The issue is primarily caused by the limited ID samples observable in training the discriminator when OOD samples are unavailable. We propose a general approach for \\textit{fine-tuning discriminators by implicit generators} (FIG). FIG is grounded on information theory and applicable to standard discriminators without retraining. It improves the ability of a standard discriminator in distinguishing ID and OOD samples by generating and penalizing its specific OOD samples. According to the Shannon entropy, an energy-based implicit generator is inferred from a discriminator without extra training costs. Then, a Langevin dynamic sampler draws specific OOD samples for the implicit generator. Lastly, we design a regularizer fitting the design principle of th",
    "link": "http://arxiv.org/abs/2108.09976",
    "context": "Title: Revealing the Distributional Vulnerability of Discriminators by Implicit Generators. (arXiv:2108.09976v4 [cs.LG] UPDATED)\nAbstract: In deep neural learning, a discriminator trained on in-distribution (ID) samples may make high-confidence predictions on out-of-distribution (OOD) samples. This triggers a significant matter for robust, trustworthy and safe deep learning. The issue is primarily caused by the limited ID samples observable in training the discriminator when OOD samples are unavailable. We propose a general approach for \\textit{fine-tuning discriminators by implicit generators} (FIG). FIG is grounded on information theory and applicable to standard discriminators without retraining. It improves the ability of a standard discriminator in distinguishing ID and OOD samples by generating and penalizing its specific OOD samples. According to the Shannon entropy, an energy-based implicit generator is inferred from a discriminator without extra training costs. Then, a Langevin dynamic sampler draws specific OOD samples for the implicit generator. Lastly, we design a regularizer fitting the design principle of th",
    "path": "papers/21/08/2108.09976.json",
    "total_tokens": 931,
    "translated_title": "通过隐式生成器揭示辨别器的分布脆弱性",
    "translated_abstract": "在深度神经学习中，通过在分布样本上训练的辨别器可能对分布外样本做出高置信度的预测。这对于强大、可靠和安全的深度学习来说是一个重要问题。这个问题主要是由于在训练辨别器时，由于分布外样本不可用，只能观测到有限的分布内样本所导致的。我们提出了一种通过隐式生成器进行辨别器微调的通用方法（FIG）。FIG以信息理论为基础，并适用于标准辨别器而无需重新训练。它通过生成和惩罚特定的分布外样本来提高标准辨别器在区分分布内样本和分布外样本方面的能力。根据香农熵，我们从辨别器中推断出一种基于能量的隐式生成器，而不需要额外的训练成本。然后，Langevin动力学采样器为隐式生成器绘制特定的分布外样本。最后，我们设计了一个符合设计原则的正则化器来适应该方法的设计原则。",
    "tldr": "通过隐式生成器的微调，我们揭示了辨别器在分布上的脆弱性。我们的方法通过生成和惩罚特定的分布外样本来提高辨别器在分布内和分布外样本上的区分能力。",
    "en_tdlr": "By fine-tuning with an implicit generator, we reveal the vulnerability of discriminators to distributional shifts. Our approach improves the discriminator's ability to distinguish in-distribution and out-of-distribution samples by generating and penalizing specific out-of-distribution samples."
}