{
    "title": "Towards Out-Of-Distribution Generalization: A Survey. (arXiv:2108.13624v2 [cs.LG] UPDATED)",
    "abstract": "Traditional machine learning paradigms are based on the assumption that both training and test data follow the same statistical pattern, which is mathematically referred to as Independent and Identically Distributed ($i.i.d.$). However, in real-world applications, this $i.i.d.$ assumption often fails to hold due to unforeseen distributional shifts, leading to considerable degradation in model performance upon deployment. This observed discrepancy indicates the significance of investigating the Out-of-Distribution (OOD) generalization problem. OOD generalization is an emerging topic of machine learning research that focuses on complex scenarios wherein the distributions of the test data differ from those of the training data. This paper represents the first comprehensive, systematic review of OOD generalization, encompassing a spectrum of aspects from problem definition, methodological development, and evaluation procedures, to the implications and future directions of the field. Our di",
    "link": "http://arxiv.org/abs/2108.13624",
    "context": "Title: Towards Out-Of-Distribution Generalization: A Survey. (arXiv:2108.13624v2 [cs.LG] UPDATED)\nAbstract: Traditional machine learning paradigms are based on the assumption that both training and test data follow the same statistical pattern, which is mathematically referred to as Independent and Identically Distributed ($i.i.d.$). However, in real-world applications, this $i.i.d.$ assumption often fails to hold due to unforeseen distributional shifts, leading to considerable degradation in model performance upon deployment. This observed discrepancy indicates the significance of investigating the Out-of-Distribution (OOD) generalization problem. OOD generalization is an emerging topic of machine learning research that focuses on complex scenarios wherein the distributions of the test data differ from those of the training data. This paper represents the first comprehensive, systematic review of OOD generalization, encompassing a spectrum of aspects from problem definition, methodological development, and evaluation procedures, to the implications and future directions of the field. Our di",
    "path": "papers/21/08/2108.13624.json",
    "total_tokens": 874,
    "translated_title": "走向超出分布泛化：一项调查",
    "translated_abstract": "传统的机器学习范式基于训练数据和测试数据遵循相同的统计模式的假设，数学上称为独立同分布（$i.i.d.$）。然而，在真实世界的应用中，由于未预料到的分布转变，这种$i.i.d.$假设经常不成立，导致模型在部署时性能大大降低。这种观察到的差异表明了研究超出分布（OOD）泛化问题的重要性。OOD泛化是机器学习研究的一个新兴主题，重点关注测试数据的分布与训练数据不同的复杂场景。本文是对OOD泛化的首次全面、系统的回顾，涵盖了从问题定义、方法论发展和评估程序到领域的意义和未来方向的一系列方面。",
    "tldr": "这项研究调查了超出分布泛化的问题，该问题涉及到当测试数据的分布与训练数据不同时，模型性能下降的情况。这是对该问题的首次全面回顾，涵盖了问题定义、方法论发展、评估程序以及领域的意义和未来方向。",
    "en_tdlr": "This research surveys the problem of out-of-distribution generalization, which involves the degradation in model performance when the distribution of test data differs from that of the training data. It provides a comprehensive review of the problem, including problem definition, methodological development, evaluation procedures, and the implications and future directions of the field."
}