{
    "title": "LLVIP: A Visible-infrared Paired Dataset for Low-light Vision. (arXiv:2108.10831v4 [cs.CV] UPDATED)",
    "abstract": "It is very challenging for various visual tasks such as image fusion, pedestrian detection and image-to-image translation in low light conditions due to the loss of effective target areas. In this case, infrared and visible images can be used together to provide both rich detail information and effective target areas. In this paper, we present LLVIP, a visible-infrared paired dataset for low-light vision. This dataset contains 30976 images, or 15488 pairs, most of which were taken at very dark scenes, and all of the images are strictly aligned in time and space. Pedestrians in the dataset are labeled. We compare the dataset with other visible-infrared datasets and evaluate the performance of some popular visual algorithms including image fusion, pedestrian detection and image-to-image translation on the dataset. The experimental results demonstrate the complementary effect of fusion on image information, and find the deficiency of existing algorithms of the three visual tasks in very l",
    "link": "http://arxiv.org/abs/2108.10831",
    "context": "Title: LLVIP: A Visible-infrared Paired Dataset for Low-light Vision. (arXiv:2108.10831v4 [cs.CV] UPDATED)\nAbstract: It is very challenging for various visual tasks such as image fusion, pedestrian detection and image-to-image translation in low light conditions due to the loss of effective target areas. In this case, infrared and visible images can be used together to provide both rich detail information and effective target areas. In this paper, we present LLVIP, a visible-infrared paired dataset for low-light vision. This dataset contains 30976 images, or 15488 pairs, most of which were taken at very dark scenes, and all of the images are strictly aligned in time and space. Pedestrians in the dataset are labeled. We compare the dataset with other visible-infrared datasets and evaluate the performance of some popular visual algorithms including image fusion, pedestrian detection and image-to-image translation on the dataset. The experimental results demonstrate the complementary effect of fusion on image information, and find the deficiency of existing algorithms of the three visual tasks in very l",
    "path": "papers/21/08/2108.10831.json",
    "total_tokens": 993,
    "translated_title": "LLVIP：适用于低光视觉的可见-红外成对数据集",
    "translated_abstract": "在低光条件下，由于有效目标区域的丢失，各种视觉任务（如图像融合，行人检测和图像到图像翻译）都面临巨大挑战。此时，可见光和红外图像可以一起使用，提供丰富的细节信息和有效的目标区域。提出了一个适用于低光视觉的可见-红外成对数据集LLVIP。该数据集包含30976张图像，或15488对图像，大多数图像拍摄于非常黑暗的场景，并且所有图像在时间和空间上严格对齐。数据集中的行人已被标记。将数据集与其他可见-红外数据集进行比较，并在数据集上评估了一些流行的视觉算法（包括图像融合，行人检测和图像到图像翻译）的性能。实验结果证明了融合对图像信息的补充效果，并发现了三个视觉任务现有算法在非常低光条件下的不足之处。",
    "tldr": "提出了适用于低光视觉的可见-红外成对数据集LLVIP，数据集包含30976张图像，解决了在低光条件下各种视觉任务缺失有效目标区域的挑战。行人已被标注，实验结果证明了融合对图像信息的补充效果，揭示了现有算法在非常低光条件下的不足之处。",
    "en_tdlr": "LLVIP is a visible-infrared paired dataset for low-light vision, which contains 30976 images, and solves the challenge of the loss of effective target areas in various visual tasks under low-light conditions. Pedestrians are labeled and the experimental results demonstrate the complementary effect of fusion on image information, revealing the deficiencies of existing algorithms in very low-light conditions."
}