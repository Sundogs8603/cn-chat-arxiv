{
    "title": "INVIGORATE: Interactive Visual Grounding and Grasping in Clutter. (arXiv:2108.11092v1 [cs.RO] CROSS LISTED)",
    "abstract": "This paper presents INVIGORATE, a robot system that interacts with human through natural language and grasps a specified object in clutter. The objects may occlude, obstruct, or even stack on top of one another. INVIGORATE embodies several challenges: (i) infer the target object among other occluding objects, from input language expressions and RGB images, (ii) infer object blocking relationships (OBRs) from the images, and (iii) synthesize a multi-step plan to ask questions that disambiguate the target object and to grasp it successfully. We train separate neural networks for object detection, for visual grounding, for question generation, and for OBR detection and grasping. They allow for unrestricted object categories and language expressions, subject to the training datasets. However, errors in visual perception and ambiguity in human languages are inevitable and negatively impact the robot's performance. To overcome these uncertainties, we build a partially observable Markov decis",
    "link": "http://arxiv.org/abs/2108.11092",
    "context": "Title: INVIGORATE: Interactive Visual Grounding and Grasping in Clutter. (arXiv:2108.11092v1 [cs.RO] CROSS LISTED)\nAbstract: This paper presents INVIGORATE, a robot system that interacts with human through natural language and grasps a specified object in clutter. The objects may occlude, obstruct, or even stack on top of one another. INVIGORATE embodies several challenges: (i) infer the target object among other occluding objects, from input language expressions and RGB images, (ii) infer object blocking relationships (OBRs) from the images, and (iii) synthesize a multi-step plan to ask questions that disambiguate the target object and to grasp it successfully. We train separate neural networks for object detection, for visual grounding, for question generation, and for OBR detection and grasping. They allow for unrestricted object categories and language expressions, subject to the training datasets. However, errors in visual perception and ambiguity in human languages are inevitable and negatively impact the robot's performance. To overcome these uncertainties, we build a partially observable Markov decis",
    "path": "papers/21/08/2108.11092.json",
    "total_tokens": 977,
    "translated_title": "INVIGORATE: 互动视觉场景理解和抓取",
    "translated_abstract": "本文介绍了INVIGORATE，一个通过自然语言与人类进行交互并在杂乱环境中抓取指定物体的机器人系统。在这种杂乱环境中，物体可能会相互遮挡、阻挡甚至叠放在一起。INVIGORATE面临着几个挑战：（i）从输入的语言表达和RGB图像中推断出目标物体，而忽略其他遮挡物体；（ii）从图像中推断出物体的阻挡关系（OBR）；（iii）生成一个多步计划，通过提问消除目标物体的歧义并成功抓取它。我们为目标检测、视觉场景理解、问题生成和OBR检测以及抓取训练了独立的神经网络。它们可以处理任意的物体类别和语言表达，只要有相应的训练数据集。然而，视觉感知中的误差以及人类语言中的歧义不可避免地会对机器人的性能产生负面影响。为了克服这些不确定性，我们建立了一个部分可观察的马尔可夫决策模型。",
    "tldr": "INVIGORATE是一个通过自然语言与人类进行交互并在杂乱环境中抓取指定物体的机器人系统。该系统能够推断目标物体、推断物体阻挡关系，并生成多步计划来消除歧义并成功抓取目标物体。",
    "en_tdlr": "INVIGORATE is a robot system that interacts with humans through natural language and grasps specified objects in cluttered environments. It can infer the target object, infer object blocking relationships, and generate multi-step plans to disambiguate and successfully grasp the target object."
}