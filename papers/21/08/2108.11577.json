{
    "title": "Machine Unlearning of Features and Labels. (arXiv:2108.11577v4 [cs.LG] UPDATED)",
    "abstract": "Removing information from a machine learning model is a non-trivial task that requires to partially revert the training process. This task is unavoidable when sensitive data, such as credit card numbers or passwords, accidentally enter the model and need to be removed afterwards. Recently, different concepts for machine unlearning have been proposed to address this problem. While these approaches are effective in removing individual data points, they do not scale to scenarios where larger groups of features and labels need to be reverted. In this paper, we propose the first method for unlearning features and labels. Our approach builds on the concept of influence functions and realizes unlearning through closed-form updates of model parameters. It enables to adapt the influence of training data on a learning model retrospectively, thereby correcting data leaks and privacy issues. For learning models with strongly convex loss functions, our method provides certified unlearning with theo",
    "link": "http://arxiv.org/abs/2108.11577",
    "context": "Title: Machine Unlearning of Features and Labels. (arXiv:2108.11577v4 [cs.LG] UPDATED)\nAbstract: Removing information from a machine learning model is a non-trivial task that requires to partially revert the training process. This task is unavoidable when sensitive data, such as credit card numbers or passwords, accidentally enter the model and need to be removed afterwards. Recently, different concepts for machine unlearning have been proposed to address this problem. While these approaches are effective in removing individual data points, they do not scale to scenarios where larger groups of features and labels need to be reverted. In this paper, we propose the first method for unlearning features and labels. Our approach builds on the concept of influence functions and realizes unlearning through closed-form updates of model parameters. It enables to adapt the influence of training data on a learning model retrospectively, thereby correcting data leaks and privacy issues. For learning models with strongly convex loss functions, our method provides certified unlearning with theo",
    "path": "papers/21/08/2108.11577.json",
    "total_tokens": 879,
    "translated_title": "特征和标签的机器退训练",
    "translated_abstract": "从机器学习模型中删除信息是一项非常复杂的任务，需要部分撤销训练过程。当敏感数据（如信用卡号码或密码）意外进入模型并需要之后删除时，这项任务是不可避免的。最近，已经提出了不同的机器退训练概念来解决这个问题。虽然这些方法在删除个别数据点方面是有效的，但在需要撤销较大组的特征和标签的情况下并不适用。在本文中，我们提出了第一种特征和标签的退训练方法。我们的方法基于影响函数的概念，并通过模型参数的封闭形式更新实现退训练。它能够对学习模型上的训练数据的影响进行回溯性调整，从而纠正数据泄露和隐私问题。对于具有强凸损失函数的学习模型，我们的方法提供了具有理论支持的退训练。",
    "tldr": "本文提出了一种针对特征和标签的机器退训练方法，通过影响函数和模型参数的封闭形式更新，能够回溯性地调整训练数据对学习模型的影响，实现数据泄露和隐私问题的纠正。",
    "en_tdlr": "This paper proposes a method for unlearning features and labels in machine learning models, utilizing influence functions and closed-form updates of model parameters, enabling retrospective adjustment of the influence of training data on the model, thus addressing data leaks and privacy issues."
}