{
    "title": "Efficient Algorithms for Learning from Coarse Labels. (arXiv:2108.09805v2 [cs.LG] UPDATED)",
    "abstract": "For many learning problems one may not have access to fine grained label information; e.g., an image can be labeled as husky, dog, or even animal depending on the expertise of the annotator. In this work, we formalize these settings and study the problem of learning from such coarse data. Instead of observing the actual labels from a set $\\mathcal{Z}$, we observe coarse labels corresponding to a partition of $\\mathcal{Z}$ (or a mixture of partitions).  Our main algorithmic result is that essentially any problem learnable from fine grained labels can also be learned efficiently when the coarse data are sufficiently informative. We obtain our result through a generic reduction for answering Statistical Queries (SQ) over fine grained labels given only coarse labels. The number of coarse labels required depends polynomially on the information distortion due to coarsening and the number of fine labels $|\\mathcal{Z}|$.  We also investigate the case of (infinitely many) real valued labels foc",
    "link": "http://arxiv.org/abs/2108.09805",
    "context": "Title: Efficient Algorithms for Learning from Coarse Labels. (arXiv:2108.09805v2 [cs.LG] UPDATED)\nAbstract: For many learning problems one may not have access to fine grained label information; e.g., an image can be labeled as husky, dog, or even animal depending on the expertise of the annotator. In this work, we formalize these settings and study the problem of learning from such coarse data. Instead of observing the actual labels from a set $\\mathcal{Z}$, we observe coarse labels corresponding to a partition of $\\mathcal{Z}$ (or a mixture of partitions).  Our main algorithmic result is that essentially any problem learnable from fine grained labels can also be learned efficiently when the coarse data are sufficiently informative. We obtain our result through a generic reduction for answering Statistical Queries (SQ) over fine grained labels given only coarse labels. The number of coarse labels required depends polynomially on the information distortion due to coarsening and the number of fine labels $|\\mathcal{Z}|$.  We also investigate the case of (infinitely many) real valued labels foc",
    "path": "papers/21/08/2108.09805.json",
    "total_tokens": 944,
    "translated_title": "学习粗标签的高效算法",
    "translated_abstract": "对于许多学习问题，我们可能无法访问细粒度标签信息；例如，根据注释者的专业知识，一幅图像可以被标记为哈士奇、狗甚至动物。本文对这些情况进行了形式化，并研究了从此类粗数据学习的问题。我们不是观察来自集合 $\\mathcal{Z}$ 的实际标签，而是观察对应于 $\\mathcal{Z}$ 的划分（或多种划分的混合）的粗标签。我们的主要算法结果是：几乎任何可从细粒度标签中学习的问题，当粗数据足够信息时也可以高效地学习。我们通过泛化减少回答统计查询（SQ) 的方式来获得结果，只给出粗标签而不是细标签。所需粗标签数量与粗糙化信息失真和细标签数量 $|\\mathcal{Z}|$ 成多项式关系。我们还研究了（无限多个）实值标签的情况。",
    "tldr": "本文研究了从粗糙数据中学习的问题，提出了一种高效的算法，只需足够信息的粗标签即可在从细标签中学习的任何问题上进行学习。"
}