{
    "title": "Transformer-based deep imitation learning for dual-arm robot manipulation",
    "abstract": "arXiv:2108.00385v2 Announce Type: replace-cross  Abstract: Deep imitation learning is promising for solving dexterous manipulation tasks because it does not require an environment model and pre-programmed robot behavior. However, its application to dual-arm manipulation tasks remains challenging. In a dual-arm manipulation setup, the increased number of state dimensions caused by the additional robot manipulators causes distractions and results in poor performance of the neural networks. We address this issue using a self-attention mechanism that computes dependencies between elements in a sequential input and focuses on important elements. A Transformer, a variant of self-attention architecture, is applied to deep imitation learning to solve dual-arm manipulation tasks in the real world. The proposed method has been tested on dual-arm manipulation tasks using a real robot. The experimental results demonstrated that the Transformer-based deep imitation learning architecture can attend ",
    "link": "https://arxiv.org/abs/2108.00385",
    "context": "Title: Transformer-based deep imitation learning for dual-arm robot manipulation\nAbstract: arXiv:2108.00385v2 Announce Type: replace-cross  Abstract: Deep imitation learning is promising for solving dexterous manipulation tasks because it does not require an environment model and pre-programmed robot behavior. However, its application to dual-arm manipulation tasks remains challenging. In a dual-arm manipulation setup, the increased number of state dimensions caused by the additional robot manipulators causes distractions and results in poor performance of the neural networks. We address this issue using a self-attention mechanism that computes dependencies between elements in a sequential input and focuses on important elements. A Transformer, a variant of self-attention architecture, is applied to deep imitation learning to solve dual-arm manipulation tasks in the real world. The proposed method has been tested on dual-arm manipulation tasks using a real robot. The experimental results demonstrated that the Transformer-based deep imitation learning architecture can attend ",
    "path": "papers/21/08/2108.00385.json",
    "total_tokens": 773,
    "translated_title": "基于Transformer的双臂机器人操作的深度模仿学习",
    "translated_abstract": "深度模仿学习对解决熟练操作任务具有潜力，因为它不需要环境模型和预编程的机器人行为。然而，将其应用于双臂操作任务仍具有挑战性。在双臂操作设置中，由于附加机器人操作器引起的状态维度增加，导致了神经网络性能不佳。我们通过使用一种自注意力机制来解决这个问题，该机制计算顺序输入中元素之间的依赖关系，并专注于重要元素。Transformer，作为自注意力架构的一种变体，被应用于深度模仿学习中，以解决真实世界中的双臂操作任务。所提出的方法已在真实机器人上的双臂操作任务上进行了测试。实验结果表明，基于Transformer的深度模仿学习架构可以进行关注",
    "tldr": "使用Transformer的深度模仿学习结构成功解决了双臂机器人操作任务中神经网络性能不佳的问题",
    "en_tdlr": "The Transformer-based deep imitation learning architecture successfully addresses the issue of poor neural network performance in dual-arm robot manipulation tasks."
}