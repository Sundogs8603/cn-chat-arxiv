{
    "title": "Evaluating the Tradeoff Between Abstractiveness and Factuality in Abstractive Summarization. (arXiv:2108.02859v2 [cs.CL] UPDATED)",
    "abstract": "Neural models for abstractive summarization tend to generate output that is fluent and well-formed but lacks semantic faithfulness, or factuality, with respect to the input documents. In this paper, we analyze the tradeoff between abstractiveness and factuality of generated summaries across multiple datasets and models, using extensive human evaluations of factuality. In our analysis, we visualize the rates of change in factuality as we gradually increase abstractiveness using a decoding constraint, and we observe that, while increased abstractiveness generally leads to a drop in factuality, the rate of factuality decay depends on factors such as the data that the system was trained on. We introduce two datasets with human factuality judgements; one containing 10.2k generated summaries with systematically varied degrees of abstractiveness; the other containing 4.2k summaries from five different summarization models. We propose new factuality metrics that adjust for the degree of abstra",
    "link": "http://arxiv.org/abs/2108.02859",
    "context": "Title: Evaluating the Tradeoff Between Abstractiveness and Factuality in Abstractive Summarization. (arXiv:2108.02859v2 [cs.CL] UPDATED)\nAbstract: Neural models for abstractive summarization tend to generate output that is fluent and well-formed but lacks semantic faithfulness, or factuality, with respect to the input documents. In this paper, we analyze the tradeoff between abstractiveness and factuality of generated summaries across multiple datasets and models, using extensive human evaluations of factuality. In our analysis, we visualize the rates of change in factuality as we gradually increase abstractiveness using a decoding constraint, and we observe that, while increased abstractiveness generally leads to a drop in factuality, the rate of factuality decay depends on factors such as the data that the system was trained on. We introduce two datasets with human factuality judgements; one containing 10.2k generated summaries with systematically varied degrees of abstractiveness; the other containing 4.2k summaries from five different summarization models. We propose new factuality metrics that adjust for the degree of abstra",
    "path": "papers/21/08/2108.02859.json",
    "total_tokens": 987,
    "translated_title": "在抽象化摘要中权衡抽象性和事实性的评估",
    "translated_abstract": "抽象化摘要的神经模型往往会生成流畅而形式良好的输出，但与输入文档的语义忠实度或事实性不一致。在本文中，我们使用对事实性的人类评估，分析了多个数据集和模型生成的摘要中抽象性和事实性之间的权衡。在我们的分析中，我们使用解码约束逐渐增加抽象性，可视化了事实性的变化率，并观察到，虽然抽象性的增加通常会导致事实性的下降，但事实性的衰减率取决于系统的训练数据等因素。我们引入了两个包含人类事实判断的数据集；一个包含10.2k个生成的摘要，具有系统地变化的抽象程度；另一个包含来自五个不同摘要模型的4.2k个摘要。我们提出了新的事实度指标，调整了抽象程度的程度。",
    "tldr": "本文分析了抽象化摘要中抽象性和事实性之间的权衡，并引入了两个包含人类事实判断的数据集。研究表明，虽然抽象性的增加通常会导致事实性的下降，但事实性的衰减率取决于系统的训练数据等因素。同时，新的事实度指标可以调整抽象程度的程度，弥补事实性的不足。",
    "en_tdlr": "This paper analyzes the tradeoff between abstractiveness and factuality in abstractive summarization, introduces two datasets with human factuality judgements, and proposes new factuality metrics that adjust for the degree of abstraction. The study shows that, while increased abstractiveness generally leads to a drop in factuality, the rate of factuality decay depends on factors such as the data that the system was trained on."
}