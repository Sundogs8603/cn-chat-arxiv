{
    "title": "Quantization Backdoors to Deep Learning Commercial Frameworks. (arXiv:2108.09187v3 [cs.CR] UPDATED)",
    "abstract": "Currently, there is a burgeoning demand for deploying deep learning (DL) models on ubiquitous edge Internet of Things (IoT) devices attributed to their low latency and high privacy preservation. However, DL models are often large in size and require large-scale computation, which prevents them from being placed directly onto IoT devices, where resources are constrained and 32-bit floating-point (float-32) operations are unavailable. Commercial framework (i.e., a set of toolkits) empowered model quantization is a pragmatic solution that enables DL deployment on mobile devices and embedded systems by effortlessly post-quantizing a large high-precision model (e.g., float-32) into a small low-precision model (e.g., int-8) while retaining the model inference accuracy. However, their usability might be threatened by security vulnerabilities.  This work reveals that the standard quantization toolkits can be abused to activate a backdoor. We demonstrate that a full-precision backdoored model w",
    "link": "http://arxiv.org/abs/2108.09187",
    "context": "Title: Quantization Backdoors to Deep Learning Commercial Frameworks. (arXiv:2108.09187v3 [cs.CR] UPDATED)\nAbstract: Currently, there is a burgeoning demand for deploying deep learning (DL) models on ubiquitous edge Internet of Things (IoT) devices attributed to their low latency and high privacy preservation. However, DL models are often large in size and require large-scale computation, which prevents them from being placed directly onto IoT devices, where resources are constrained and 32-bit floating-point (float-32) operations are unavailable. Commercial framework (i.e., a set of toolkits) empowered model quantization is a pragmatic solution that enables DL deployment on mobile devices and embedded systems by effortlessly post-quantizing a large high-precision model (e.g., float-32) into a small low-precision model (e.g., int-8) while retaining the model inference accuracy. However, their usability might be threatened by security vulnerabilities.  This work reveals that the standard quantization toolkits can be abused to activate a backdoor. We demonstrate that a full-precision backdoored model w",
    "path": "papers/21/08/2108.09187.json",
    "total_tokens": 1140,
    "translated_title": "深度学习商业框架的量化后门",
    "translated_abstract": "目前，由于低延迟和高隐私保护，越来越多的深度学习模型被部署在无处不在的边缘物联网设备上。",
    "tldr": "本文揭示了商业框架中潜在的深度学习模型后门安全漏洞，可以通过量化攻击实现后门触发并逃避检测，从而危及已部署的模型安全，可能导致未经授权的数据访问。"
}