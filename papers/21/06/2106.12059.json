{
    "title": "Stochastic Batch Acquisition: A Simple Baseline for Deep Active Learning. (arXiv:2106.12059v3 [cs.LG] UPDATED)",
    "abstract": "We examine a simple stochastic strategy for adapting well-known single-point acquisition functions to allow batch active learning. Unlike acquiring the top-K points from the pool set, score- or rank-based sampling takes into account that acquisition scores change as new data are acquired. This simple strategy for adapting standard single-sample acquisition strategies can even perform just as well as compute-intensive state-of-the-art batch acquisition functions, like BatchBALD or BADGE, while using orders of magnitude less compute. In addition to providing a practical option for machine learning practitioners, the surprising success of the proposed method in a wide range of experimental settings raises a difficult question for the field: when are these expensive batch acquisition methods pulling their weight?",
    "link": "http://arxiv.org/abs/2106.12059",
    "context": "Title: Stochastic Batch Acquisition: A Simple Baseline for Deep Active Learning. (arXiv:2106.12059v3 [cs.LG] UPDATED)\nAbstract: We examine a simple stochastic strategy for adapting well-known single-point acquisition functions to allow batch active learning. Unlike acquiring the top-K points from the pool set, score- or rank-based sampling takes into account that acquisition scores change as new data are acquired. This simple strategy for adapting standard single-sample acquisition strategies can even perform just as well as compute-intensive state-of-the-art batch acquisition functions, like BatchBALD or BADGE, while using orders of magnitude less compute. In addition to providing a practical option for machine learning practitioners, the surprising success of the proposed method in a wide range of experimental settings raises a difficult question for the field: when are these expensive batch acquisition methods pulling their weight?",
    "path": "papers/21/06/2106.12059.json",
    "total_tokens": 759,
    "translated_title": "随机批量获取：深度主动学习的简单基准方法",
    "translated_abstract": "本文研究了一种简单的随机策略，用于将众所周知的单点获取函数适应于批量主动学习。与从池集合中获取前K个点不同，基于分数或排名的采样考虑到获取数据后采集分数的变化。这种简单的策略可以与计算密集型的最新批量采集函数（如BatchBALD或BADGE）一样表现出色，并且使用的计算资源数量级较少。除了为机器学习从业者提供了一个实用选项外，在各种实验环境中提出的方法的意外成功还为这个领域提出了一个困难的问题：这些昂贵的批量采集方法何时才能发挥作用？",
    "tldr": "研究了一种简单的随机策略，用于将单点获取函数适应于批量主动学习，与计算密集型的批量采集函数相比，性能相当，但使用的计算资源更少。",
    "en_tdlr": "Explored a simple stochastic strategy to adapt single-point acquisition functions for batch active learning, which performs similarly to compute-intensive batch acquisition functions but with significantly less computational resources used."
}