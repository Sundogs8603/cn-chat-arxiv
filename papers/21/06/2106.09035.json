{
    "title": "Regularization of Mixture Models for Robust Principal Graph Learning. (arXiv:2106.09035v2 [cs.LG] UPDATED)",
    "abstract": "A regularized version of Mixture Models is proposed to learn a principal graph from a distribution of $D$-dimensional data points. In the particular case of manifold learning for ridge detection, we assume that the underlying manifold can be modeled as a graph structure acting like a topological prior for the Gaussian clusters turning the problem into a maximum a posteriori estimation. Parameters of the model are iteratively estimated through an Expectation-Maximization procedure making the learning of the structure computationally efficient with guaranteed convergence for any graph prior in a polynomial time. We also embed in the formalism a natural way to make the algorithm robust to outliers of the pattern and heteroscedasticity of the manifold sampling coherently with the graph structure. The method uses a graph prior given by the minimum spanning tree that we extend using random sub-samplings of the dataset to take into account cycles that can be observed in the spatial distributi",
    "link": "http://arxiv.org/abs/2106.09035",
    "context": "Title: Regularization of Mixture Models for Robust Principal Graph Learning. (arXiv:2106.09035v2 [cs.LG] UPDATED)\nAbstract: A regularized version of Mixture Models is proposed to learn a principal graph from a distribution of $D$-dimensional data points. In the particular case of manifold learning for ridge detection, we assume that the underlying manifold can be modeled as a graph structure acting like a topological prior for the Gaussian clusters turning the problem into a maximum a posteriori estimation. Parameters of the model are iteratively estimated through an Expectation-Maximization procedure making the learning of the structure computationally efficient with guaranteed convergence for any graph prior in a polynomial time. We also embed in the formalism a natural way to make the algorithm robust to outliers of the pattern and heteroscedasticity of the manifold sampling coherently with the graph structure. The method uses a graph prior given by the minimum spanning tree that we extend using random sub-samplings of the dataset to take into account cycles that can be observed in the spatial distributi",
    "path": "papers/21/06/2106.09035.json",
    "total_tokens": 828,
    "translated_title": "鲁棒主图学习的混合模型正则化",
    "translated_abstract": "提出了混合模型的正则化版本，用于从$D$维数据点的分布中学习主图。在用于脊检测的流形学习的特殊情况下，我们假设潜在流形可以建模为拓扑先验作用下的高斯聚类图结构，从而将问题转化为最大后验估计。模型的参数通过期望最大化算法进行迭代估计，使得结构的学习在任何图先验下都具有多项式时间的收敛保证，同时结合图结构的一致性，以自然的方式使算法对异常值和流形采样的异方差具有鲁棒性。该方法使用由最小生成树给出的图先验，通过对数据集进行随机子采样来扩展图的范围，以考虑在空间分布中观察到的循环。",
    "tldr": "本文提出了一种正则化的混合模型方法，用于从数据分布中学习主图，能够处理脊检测中的流形学习问题以及异常值和异方差等问题。",
    "en_tdlr": "This paper proposes a regularized version of mixture models for learning a principal graph from data distribution, effectively handling manifold learning for ridge detection and robustness to outliers and heteroscedasticity."
}