{
    "title": "A Targeted Assessment of Incremental Processing in Neural LanguageModels and Humans. (arXiv:2106.03232v2 [cs.CL] UPDATED)",
    "abstract": "We present a targeted, scaled-up comparison of incremental processing in humans and neural language models by collecting by-word reaction time data for sixteen different syntactic test suites across a range of structural phenomena. Human reaction time data comes from a novel online experimental paradigm called the Interpolated Maze task. We compare human reaction times to by-word probabilities for four contemporary language models, with different architectures and trained on a range of data set sizes. We find that across many phenomena, both humans and language models show increased processing difficulty in ungrammatical sentence regions with human and model `accuracy' scores (a la Marvin and Linzen(2018)) about equal. However, although language model outputs match humans in direction, we show that models systematically under-predict the difference in magnitude of incremental processing difficulty between grammatical and ungrammatical sentences. Specifically, when models encounter synt",
    "link": "http://arxiv.org/abs/2106.03232",
    "context": "Title: A Targeted Assessment of Incremental Processing in Neural LanguageModels and Humans. (arXiv:2106.03232v2 [cs.CL] UPDATED)\nAbstract: We present a targeted, scaled-up comparison of incremental processing in humans and neural language models by collecting by-word reaction time data for sixteen different syntactic test suites across a range of structural phenomena. Human reaction time data comes from a novel online experimental paradigm called the Interpolated Maze task. We compare human reaction times to by-word probabilities for four contemporary language models, with different architectures and trained on a range of data set sizes. We find that across many phenomena, both humans and language models show increased processing difficulty in ungrammatical sentence regions with human and model `accuracy' scores (a la Marvin and Linzen(2018)) about equal. However, although language model outputs match humans in direction, we show that models systematically under-predict the difference in magnitude of incremental processing difficulty between grammatical and ungrammatical sentences. Specifically, when models encounter synt",
    "path": "papers/21/06/2106.03232.json",
    "total_tokens": 912,
    "translated_title": "神经语言模型和人类的增量处理的有针对性评估",
    "translated_abstract": "我们通过收集跨越多种结构现象的十六个不同句法测试套件的逐词反应时间数据，提出了一种针对神经语言模型和人类增量处理的有针对性、规模化比较。人类反应时间数据来自一种称为\"Interpolated Maze\"任务的新型在线实验范例。我们将人类反应时间与四种不同架构、训练数据集大小范围的当代语言模型的逐词概率进行比较。我们发现，在许多现象中，无论是人类还是语言模型，在语法错误的句子区域都显示出了增加的处理困难，人类和模型的“准确度”得分（类似于Marvin和Linzen(2018)）大致相等。然而，尽管语言模型的输出与人类的方向相匹配，我们表明模型在预测语法和非语法句子之间增量处理困难差异的幅度上系统性地低估了。具体而言，当模型遇到句法错误时，模型在增量处理困难的差异大小上低估了。",
    "tldr": "本研究通过收集了人类和神经语言模型在逐词反应时间上的数据进行了比较，发现无论是人类还是模型，都在语法错误句子区域表现出了增加的处理困难。然而，模型在预测语法和非语法句子之间增量处理困难差异的幅度上存在系统性低估。"
}