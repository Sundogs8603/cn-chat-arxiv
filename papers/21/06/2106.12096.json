{
    "title": "Learning Identity-Preserving Transformations on Data Manifolds. (arXiv:2106.12096v2 [cs.LG] UPDATED)",
    "abstract": "Many machine learning techniques incorporate identity-preserving transformations into their models to generalize their performance to previously unseen data. These transformations are typically selected from a set of functions that are known to maintain the identity of an input when applied (e.g., rotation, translation, flipping, and scaling). However, there are many natural variations that cannot be labeled for supervision or defined through examination of the data. As suggested by the manifold hypothesis, many of these natural variations live on or near a low-dimensional, nonlinear manifold. Several techniques represent manifold variations through a set of learned Lie group operators that define directions of motion on the manifold. However, these approaches are limited because they require transformation labels when training their models and they lack a method for determining which regions of the manifold are appropriate for applying each specific operator. We address these limitati",
    "link": "http://arxiv.org/abs/2106.12096",
    "context": "Title: Learning Identity-Preserving Transformations on Data Manifolds. (arXiv:2106.12096v2 [cs.LG] UPDATED)\nAbstract: Many machine learning techniques incorporate identity-preserving transformations into their models to generalize their performance to previously unseen data. These transformations are typically selected from a set of functions that are known to maintain the identity of an input when applied (e.g., rotation, translation, flipping, and scaling). However, there are many natural variations that cannot be labeled for supervision or defined through examination of the data. As suggested by the manifold hypothesis, many of these natural variations live on or near a low-dimensional, nonlinear manifold. Several techniques represent manifold variations through a set of learned Lie group operators that define directions of motion on the manifold. However, these approaches are limited because they require transformation labels when training their models and they lack a method for determining which regions of the manifold are appropriate for applying each specific operator. We address these limitati",
    "path": "papers/21/06/2106.12096.json",
    "total_tokens": 1136,
    "translated_title": "学习数据流形上的保持身份的变换",
    "translated_abstract": "许多机器学习技术将保持身份的变换纳入其模型中，以将其性能推广到以前未见过的数据。然而，这些变换通常是从一组已知可以维持输入身份的函数中选择的（例如旋转、平移、翻转和缩放）。然而，有许多自然变化无法进行标记监督或通过数据检查来定义。如浸入式学习假设所示，许多这些自然变化存在于或靠近低维非线性流形上。几种技术通过一组学习的李群算子来表示流形变化，这些算子定义了流形上的运动方向。然而，这些方法的局限在于它们在训练其模型时需要变换标签，并且缺乏一种确定每个特定算子适用于流形的哪些区域的方法。我们通过提出一种新的方法来解决这些限制，该方法直接从数据流形中学习保持身份的变换，而无需在训练过程中标记变换数据。我们的方法基于一种修改的变分自编码器，该自编码器在端到端训练中学习生成模型和一组本地自适应的保持身份的变换。我们的实验表明，我们的方法能够学习有用的变换，从而改善模型在具有挑战性的图像分类和少样本学习任务中的推广性能。",
    "tldr": "本论文提出了一种新方法，可以直接从数据流形中学习保持身份的变换，而无需在训练期间标记变换数据。该方法基于变分自编码器，可以学习一组本地自适应的保持身份的变换，可以提高模型在具有挑战性的图像分类和少样本学习任务上的推广性能。",
    "en_tdlr": "This paper proposes a novel approach to learning identity-preserving transformations directly from data manifolds without labeled transformation data during training, based on a modified Variational Autoencoder that learns a set of locally adaptive identity-preserving transformations. The approach can improve the generalization performance of the model on challenging image classification and few-shot learning tasks."
}