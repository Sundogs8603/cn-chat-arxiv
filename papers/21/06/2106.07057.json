{
    "title": "FairCanary: Rapid Continuous Explainable Fairness. (arXiv:2106.07057v4 [cs.LG] UPDATED)",
    "abstract": "Systems that offer continuous model monitoring have emerged in response to (1) well-documented failures of deployed Machine Learning (ML) and Artificial Intelligence (AI) models and (2) new regulatory requirements impacting these models. Existing monitoring systems continuously track the performance of deployed ML models and compute feature importance (a.k.a. explanations) for each prediction to help developers identify the root causes of emergent model performance problems.  We present Quantile Demographic Drift (QDD), a novel model bias quantification metric that uses quantile binning to measure differences in the overall prediction distributions over subgroups. QDD is ideal for continuous monitoring scenarios, does not suffer from the statistical limitations of conventional threshold-based bias metrics, and does not require outcome labels (which may not be available at runtime). We incorporate QDD into a continuous model monitoring system, called FairCanary, that reuses existing exp",
    "link": "http://arxiv.org/abs/2106.07057",
    "context": "Title: FairCanary: Rapid Continuous Explainable Fairness. (arXiv:2106.07057v4 [cs.LG] UPDATED)\nAbstract: Systems that offer continuous model monitoring have emerged in response to (1) well-documented failures of deployed Machine Learning (ML) and Artificial Intelligence (AI) models and (2) new regulatory requirements impacting these models. Existing monitoring systems continuously track the performance of deployed ML models and compute feature importance (a.k.a. explanations) for each prediction to help developers identify the root causes of emergent model performance problems.  We present Quantile Demographic Drift (QDD), a novel model bias quantification metric that uses quantile binning to measure differences in the overall prediction distributions over subgroups. QDD is ideal for continuous monitoring scenarios, does not suffer from the statistical limitations of conventional threshold-based bias metrics, and does not require outcome labels (which may not be available at runtime). We incorporate QDD into a continuous model monitoring system, called FairCanary, that reuses existing exp",
    "path": "papers/21/06/2106.07057.json",
    "total_tokens": 1013,
    "translated_title": "FairCanary: 快速持续的可解释公平性监控系统",
    "translated_abstract": "针对已部署的机器学习(ML)和人工智能(AI)模型的失败和新的法规要求，出现了提供持续模型监控的系统。现有的监控系统持续跟踪已部署的ML模型的性能，并为每个预测计算特征重要性(即解释)，以帮助开发人员确定新出现的模型性能问题的根本原因。我们提出量化人口漂移(QDD)，一种新的模型偏差量化度量，使用分位数分组来度量子组之间整体预测分布的差异。QDD非常适合于连续监控场景，不会受到传统基于阈值偏差度量的统计限制，并且不需要结果标签(可能无法在运行时获得)。我们将QDD纳入连续模型监控系统FairCanary中，该系统重用现有的实验基础设施，利用最先进的可解释性方法提供快速、持续且可解释的公平性分析。FairCanary在几个实际数据集上进行了评估，并向开发人员提供可操作性见解，以提高其ML模型的公平性。",
    "tldr": "FairCanary是一个持续模型监控系统，使用量化人口漂移(QDD)度量模型偏差，避免传统阈值偏差度量的统计限制，可以提供可解释的公平性分析，并在多个实际数据集上实现了可操作性见解。",
    "en_tdlr": "FairCanary is a continuous model monitoring system that uses Quantile Demographic Drift (QDD) to measure model bias, avoiding statistical limitations of conventional threshold-based bias metrics. It provides explainable fairness analysis and actionable insights to improve fairness in ML models, demonstrated on several real-world datasets."
}