{
    "title": "FL-Market: Trading Private Models in Federated Learning. (arXiv:2106.04384v4 [cs.LG] UPDATED)",
    "abstract": "The difficulty in acquiring a sufficient amount of training data is a major bottleneck for machine learning (ML) based data analytics. Recently, commoditizing ML models has been proposed as an economical and moderate solution to ML-oriented data acquisition. However, existing model marketplaces assume that the broker can access data owners' private training data, which may not be realistic in practice. In this paper, to promote trustworthy data acquisition for ML tasks, we propose FL-Market, a locally private model marketplace that protects privacy not only against model buyers but also against the untrusted broker. FL-Market decouples ML from the need to centrally gather training data on the broker's side using federated learning, an emerging privacy-preserving ML paradigm in which data owners collaboratively train an ML model by uploading local gradients (to be aggregated into a global gradient for model updating). Then, FL-Market enables data owners to locally perturb their gradient",
    "link": "http://arxiv.org/abs/2106.04384",
    "context": "Title: FL-Market: Trading Private Models in Federated Learning. (arXiv:2106.04384v4 [cs.LG] UPDATED)\nAbstract: The difficulty in acquiring a sufficient amount of training data is a major bottleneck for machine learning (ML) based data analytics. Recently, commoditizing ML models has been proposed as an economical and moderate solution to ML-oriented data acquisition. However, existing model marketplaces assume that the broker can access data owners' private training data, which may not be realistic in practice. In this paper, to promote trustworthy data acquisition for ML tasks, we propose FL-Market, a locally private model marketplace that protects privacy not only against model buyers but also against the untrusted broker. FL-Market decouples ML from the need to centrally gather training data on the broker's side using federated learning, an emerging privacy-preserving ML paradigm in which data owners collaboratively train an ML model by uploading local gradients (to be aggregated into a global gradient for model updating). Then, FL-Market enables data owners to locally perturb their gradient",
    "path": "papers/21/06/2106.04384.json",
    "total_tokens": 890,
    "translated_title": "FL-Market: 在联邦学习中交易私有模型",
    "translated_abstract": "对于基于机器学习（ML）的数据分析而言，获取足够的训练数据是一个主要瓶颈。近年来，把ML模型商品化已被提出作为一种经济且适度的数据获取解决方案。然而，现有的模型交易市场假定经纪人可以访问数据所有者的私有训练数据，这在实践中可能并不现实。为了促进可信数据获取，本文提出FL-Market，一种本地私有模型交易市场，不仅可以保护模型买家的隐私，还可以保护不可信赖的经纪人。FL-Market使用联邦学习（一种新兴的隐私保护ML范例，其中数据所有者通过上传本地梯度（即将聚合为用于更新模型的全局梯度）来协作地训练ML模型）将ML与经纪人集中收集训练数据的需求解耦。然后，FL-Market使数据所有者可以本地扰动其梯度，以进一步保护隐私。",
    "tldr": "本文提出FL-Market，一种隐私保护的本地私有模型交易市场，使用联邦学习解耦ML与经纪人集中收集训练数据的需求。",
    "en_tdlr": "This paper proposes FL-Market, a locally private model marketplace that uses federated learning to decouple the need for centralized gathering of training data on the broker's side, aiming to promote trustworthy data acquisition for machine learning tasks while protecting privacy."
}