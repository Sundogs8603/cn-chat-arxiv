{
    "title": "Learning Audio-Visual Dereverberation. (arXiv:2106.07732v2 [cs.SD] UPDATED)",
    "abstract": "Reverberation not only degrades the quality of speech for human perception, but also severely impacts the accuracy of automatic speech recognition. Prior work attempts to remove reverberation based on the audio modality only. Our idea is to learn to dereverberate speech from audio-visual observations. The visual environment surrounding a human speaker reveals important cues about the room geometry, materials, and speaker location, all of which influence the precise reverberation effects. We introduce Visually-Informed Dereverberation of Audio (VIDA), an end-to-end approach that learns to remove reverberation based on both the observed monaural sound and visual scene. In support of this new task, we develop a large-scale dataset SoundSpaces-Speech that uses realistic acoustic renderings of speech in real-world 3D scans of homes offering a variety of room acoustics. Demonstrating our approach on both simulated and real imagery for speech enhancement, speech recognition, and speaker ident",
    "link": "http://arxiv.org/abs/2106.07732",
    "context": "Title: Learning Audio-Visual Dereverberation. (arXiv:2106.07732v2 [cs.SD] UPDATED)\nAbstract: Reverberation not only degrades the quality of speech for human perception, but also severely impacts the accuracy of automatic speech recognition. Prior work attempts to remove reverberation based on the audio modality only. Our idea is to learn to dereverberate speech from audio-visual observations. The visual environment surrounding a human speaker reveals important cues about the room geometry, materials, and speaker location, all of which influence the precise reverberation effects. We introduce Visually-Informed Dereverberation of Audio (VIDA), an end-to-end approach that learns to remove reverberation based on both the observed monaural sound and visual scene. In support of this new task, we develop a large-scale dataset SoundSpaces-Speech that uses realistic acoustic renderings of speech in real-world 3D scans of homes offering a variety of room acoustics. Demonstrating our approach on both simulated and real imagery for speech enhancement, speech recognition, and speaker ident",
    "path": "papers/21/06/2106.07732.json",
    "total_tokens": 1030,
    "translated_title": "音频-视频去混响学习",
    "translated_abstract": "混响不仅会降低人类感知语音的质量，还会严重影响自动语音识别的准确性。我们提出了利用音视频观测学习去混响说话的想法。人类说话者周围的视觉环境揭示了关于房间几何形状、材料和说话者位置的重要线索，它们都会影响混响的精确效果。我们介绍了一种名为“基于视觉信息的音频去混响”（VIDA）的端到端方法，它可以学习基于观察到的单声道声音和视觉场景去除混响。为了支持这项新任务，我们开发了一个大规模的数据集SoundSpaces-Speech，在真实世界的3D房屋扫描中使用逼真的语音声学渲染，提供了各种房间声学。我们在模拟和实际影像上展示了VIDA在语音增强、语音识别和说话者识别任务上的效果，表明VIDA优于基于音频的先前方法，融合视觉信息有助于捕捉重要线索，从而使去混响更有效。",
    "tldr": "VIDA是一种音视频结合的去混响方法，能够更有效地去除混响，提高语音增强、语音识别和说话者识别的性能。 SoundSpaces-Speech是一个新的大规模数据集，提供了真实世界中各种房间声学的逼真语音声学渲染。",
    "en_tdlr": "VIDA is an audio-visual approach for dereverberation, capable of removing reverberation more effectively, improving the performance of speech enhancement, speech recognition, and speaker identification. SoundSpaces-Speech is a new large-scale dataset that provides realistic acoustic renderings of speech in real-world settings with a variety of room acoustics."
}