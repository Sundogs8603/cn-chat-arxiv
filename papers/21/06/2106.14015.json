{
    "title": "Contextual Inverse Optimization: Offline and Online Learning. (arXiv:2106.14015v3 [cs.LG] UPDATED)",
    "abstract": "We study the problems of offline and online contextual optimization with feedback information, where instead of observing the loss, we observe, after-the-fact, the optimal action an oracle with full knowledge of the objective function would have taken. We aim to minimize regret, which is defined as the difference between our losses and the ones incurred by an all-knowing oracle. In the offline setting, the decision-maker has information available from past periods and needs to make one decision, while in the online setting, the decision-maker optimizes decisions dynamically over time based a new set of feasible actions and contextual functions in each period. For the offline setting, we characterize the optimal minimax policy, establishing the performance that can be achieved as a function of the underlying geometry of the information induced by the data. In the online setting, we leverage this geometric characterization to optimize the cumulative regret. We develop an algorithm that y",
    "link": "http://arxiv.org/abs/2106.14015",
    "context": "Title: Contextual Inverse Optimization: Offline and Online Learning. (arXiv:2106.14015v3 [cs.LG] UPDATED)\nAbstract: We study the problems of offline and online contextual optimization with feedback information, where instead of observing the loss, we observe, after-the-fact, the optimal action an oracle with full knowledge of the objective function would have taken. We aim to minimize regret, which is defined as the difference between our losses and the ones incurred by an all-knowing oracle. In the offline setting, the decision-maker has information available from past periods and needs to make one decision, while in the online setting, the decision-maker optimizes decisions dynamically over time based a new set of feasible actions and contextual functions in each period. For the offline setting, we characterize the optimal minimax policy, establishing the performance that can be achieved as a function of the underlying geometry of the information induced by the data. In the online setting, we leverage this geometric characterization to optimize the cumulative regret. We develop an algorithm that y",
    "path": "papers/21/06/2106.14015.json",
    "total_tokens": 853,
    "translated_title": "上下文逆优化：离线和在线学习",
    "translated_abstract": "我们研究了具有反馈信息的离线和在线情境优化问题，其中我们观察到的不是损失，而是一个具有完全了解目标函数的预测神经网络将会采取的最佳动作。我们的目标是最小化后悔，后悔定义为我们的损失与全知预测神经网络产生的损失之间的差异。在离线情境中，决策者可以获得过去时期的信息并需要做出一个决策，而在在线情境中，决策者根据每个时期的新一组可行动作和情境函数来动态优化决策。对于离线情境，我们将最优极小极大策略特征化，确定了可以作为数据产生的信息的基础几何形状的函数表现。在在线情境中，我们利用这种几何特征来优化累积后悔。我们开发了算法来找到累积后悔的最小化策略。",
    "tldr": "这项研究研究了具有反馈信息的离线和在线情境优化问题，通过观察最佳动作并最小化后悔来优化决策制定。",
    "en_tdlr": "This study investigates the problems of offline and online contextual optimization with feedback information, aiming to optimize decision-making by observing optimal actions and minimizing regret."
}