{
    "title": "Is Homophily a Necessity for Graph Neural Networks?. (arXiv:2106.06134v4 [cs.LG] UPDATED)",
    "abstract": "Graph neural networks (GNNs) have shown great prowess in learning representations suitable for numerous graph-based machine learning tasks. When applied to semi-supervised node classification, GNNs are widely believed to work well due to the homophily assumption (\"like attracts like\"), and fail to generalize to heterophilous graphs where dissimilar nodes connect. Recent works design new architectures to overcome such heterophily-related limitations, citing poor baseline performance and new architecture improvements on a few heterophilous graph benchmark datasets as evidence for this notion. In our experiments, we empirically find that standard graph convolutional networks (GCNs) can actually achieve better performance than such carefully designed methods on some commonly used heterophilous graphs. This motivates us to reconsider whether homophily is truly necessary for good GNN performance. We find that this claim is not quite true, and in fact, GCNs can achieve strong performance on h",
    "link": "http://arxiv.org/abs/2106.06134",
    "context": "Title: Is Homophily a Necessity for Graph Neural Networks?. (arXiv:2106.06134v4 [cs.LG] UPDATED)\nAbstract: Graph neural networks (GNNs) have shown great prowess in learning representations suitable for numerous graph-based machine learning tasks. When applied to semi-supervised node classification, GNNs are widely believed to work well due to the homophily assumption (\"like attracts like\"), and fail to generalize to heterophilous graphs where dissimilar nodes connect. Recent works design new architectures to overcome such heterophily-related limitations, citing poor baseline performance and new architecture improvements on a few heterophilous graph benchmark datasets as evidence for this notion. In our experiments, we empirically find that standard graph convolutional networks (GCNs) can actually achieve better performance than such carefully designed methods on some commonly used heterophilous graphs. This motivates us to reconsider whether homophily is truly necessary for good GNN performance. We find that this claim is not quite true, and in fact, GCNs can achieve strong performance on h",
    "path": "papers/21/06/2106.06134.json",
    "total_tokens": 925,
    "translated_title": "“同质性对于图神经网络是必要的吗？”",
    "translated_abstract": "图神经网络（GNN）在学习适用于众多基于图的机器学习任务的表示方面显示出极强的能力。当应用于半监督节点分类时，由于同质性假设（“类似相互吸引”），人们普遍认为GNN可以很好地工作，但在异质性图中（连接不相似节点的图）无法泛化。最近的研究通过设计新的架构来克服这种与异质性相关的限制，引用了贫弱的基准性能以及在一些异质性图基准数据集上的新架构改进作为证据。在我们的实验证明，标准的图卷积网络（GCN）实际上在一些常用的异质性图上可以实现比这些精心设计的方法更好的性能。这激励我们重新思考同质性是否真正对于良好的GNN性能是必要的。我们发现这种说法并不完全正确，事实上，GCN可以在异质性图上实现强大的性能。",
    "tldr": "“同质性对于良好的图神经网络性能是否必要的”这一问题在研究中得到了重新评估。实验证明，标准的图卷积网络（GCNs）在一些常用的异质性图上可以实现比精心设计的方法更好的性能。",
    "en_tdlr": "The necessity of homophily for good performance in graph neural networks (GNNs) is re-evaluated. Empirical experiments show that standard graph convolutional networks (GCNs) can achieve better performance than carefully designed methods on some commonly used heterophilous graphs."
}