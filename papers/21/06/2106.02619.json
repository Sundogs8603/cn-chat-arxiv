{
    "title": "Forward Super-Resolution: How Can GANs Learn Hierarchical Generative Models for Real-World Distributions. (arXiv:2106.02619v2 [cs.LG] UPDATED)",
    "abstract": "Generative adversarial networks (GANs) are among the most successful models for learning high-complexity, real-world distributions. However, in theory, due to the highly non-convex, non-concave landscape of the minmax training objective, GAN remains one of the least understood deep learning models. In this work, we formally study how GANs can efficiently learn certain hierarchically generated distributions that are close to the distribution of real-life images. We prove that when a distribution has a structure that we refer to as Forward Super-Resolution, then simply training generative adversarial networks using stochastic gradient descent ascent (SGDA) can learn this distribution efficiently, both in sample and time complexities. We also provide empirical evidence that our assumption \"forward super-resolution\" is very natural in practice, and the underlying learning mechanisms that we study in this paper (to allow us efficiently train GAN via SGDA in theory) simulates the actual lear",
    "link": "http://arxiv.org/abs/2106.02619",
    "context": "Title: Forward Super-Resolution: How Can GANs Learn Hierarchical Generative Models for Real-World Distributions. (arXiv:2106.02619v2 [cs.LG] UPDATED)\nAbstract: Generative adversarial networks (GANs) are among the most successful models for learning high-complexity, real-world distributions. However, in theory, due to the highly non-convex, non-concave landscape of the minmax training objective, GAN remains one of the least understood deep learning models. In this work, we formally study how GANs can efficiently learn certain hierarchically generated distributions that are close to the distribution of real-life images. We prove that when a distribution has a structure that we refer to as Forward Super-Resolution, then simply training generative adversarial networks using stochastic gradient descent ascent (SGDA) can learn this distribution efficiently, both in sample and time complexities. We also provide empirical evidence that our assumption \"forward super-resolution\" is very natural in practice, and the underlying learning mechanisms that we study in this paper (to allow us efficiently train GAN via SGDA in theory) simulates the actual lear",
    "path": "papers/21/06/2106.02619.json",
    "total_tokens": 955,
    "translated_title": "前向超分辨率：GAN如何学习逼近真实世界分布的分层生成模型",
    "translated_abstract": "生成对抗网络（GAN）是学习高复杂度真实世界分布的最成功模型之一。然而，由于最小最大训练目标的高度非凸、非凹特性，GAN在理论上仍然是深度学习模型中最难理解的。本文正式研究了GAN如何有效地学习那些接近真实图像分布的分层生成分布。我们证明了，当一个分布具有我们所称的前向超分辨率结构时，通过随机梯度下降上升（SGDA）简单地训练GAN就能够有效地学习这个分布，无论是样本还是时间复杂度。我们还提供了实证证据，表明我们所假设的“前向超分辨率”在实践中非常自然，而我们在本文中研究的底层学习机制（通过SGDA理论上允许我们高效地训练GAN）模拟了实际的学习过程。",
    "tldr": "本文研究了GAN如何有效地学习那些接近真实图像分布的分层生成分布，当一个分布具有前向超分辨率结构时，通过SGDA简单地训练GAN就能够实现高效学习。",
    "en_tdlr": "This paper investigates how GANs can efficiently learn certain hierarchically generated distributions that are close to the distribution of real-life images. By proving that when a distribution has a structure called Forward Super-Resolution, GAN can learn this effectively via SGDA, both in sample and time complexities. Empirical evidence shows that this assumption is natural and the underlying learning mechanisms in this paper simulate the actual learning process."
}