{
    "title": "Private Federated Learning Without a Trusted Server: Optimal Algorithms for Convex Losses. (arXiv:2106.09779v7 [cs.LG] UPDATED)",
    "abstract": "This paper studies federated learning (FL)--especially cross-silo FL--with data from people who do not trust the server or other silos. In this setting, each silo (e.g. hospital) has data from different people (e.g. patients) and must maintain the privacy of each person's data (e.g. medical record), even if the server or other silos act as adversarial eavesdroppers. This requirement motivates the study of Inter-Silo Record-Level Differential Privacy (ISRL-DP), which requires silo i's communications to satisfy record/item-level differential privacy (DP). ISRL-DP ensures that the data of each person (e.g. patient) in silo i (e.g. hospital i) cannot be leaked. ISRL-DP is different from well-studied privacy notions. Central and user-level DP assume that people trust the server/other silos. On the other end of the spectrum, local DP assumes that people do not trust anyone at all (even their own silo). Sitting between central and local DP, ISRL-DP makes the realistic assumption (in cross-sil",
    "link": "http://arxiv.org/abs/2106.09779",
    "context": "Title: Private Federated Learning Without a Trusted Server: Optimal Algorithms for Convex Losses. (arXiv:2106.09779v7 [cs.LG] UPDATED)\nAbstract: This paper studies federated learning (FL)--especially cross-silo FL--with data from people who do not trust the server or other silos. In this setting, each silo (e.g. hospital) has data from different people (e.g. patients) and must maintain the privacy of each person's data (e.g. medical record), even if the server or other silos act as adversarial eavesdroppers. This requirement motivates the study of Inter-Silo Record-Level Differential Privacy (ISRL-DP), which requires silo i's communications to satisfy record/item-level differential privacy (DP). ISRL-DP ensures that the data of each person (e.g. patient) in silo i (e.g. hospital i) cannot be leaked. ISRL-DP is different from well-studied privacy notions. Central and user-level DP assume that people trust the server/other silos. On the other end of the spectrum, local DP assumes that people do not trust anyone at all (even their own silo). Sitting between central and local DP, ISRL-DP makes the realistic assumption (in cross-sil",
    "path": "papers/21/06/2106.09779.json",
    "total_tokens": 1037,
    "translated_title": "无需信任的私有联邦学习：凸损失函数的最优算法",
    "translated_abstract": "本文探讨了联邦学习（FL）的研究，特别是跨数据源（跨 silo）FL，这些数据源的数据主人都不信任服务器或其他 silos。在这种情况下，每个数据源（例如医院）都有来自不同人（例如患者）的数据，并且必须维护每个人（例如医疗记录）数据的隐私，即使服务器或其他数据源是恶意监听者。这种要求促进了对跨 silo 记录级差分隐私（ISRL-DP）的研究，它要求 silo i 的通信满足记录 / 项目级差分隐私 (DP)。ISRL-DP 确保 silo i 中每个人（例如患者）的数据都不会泄漏。ISRL-DP 不同于各种已有的隐私概念。中心和用户级差分隐私假定人们信任服务器/其他数据源。在极端情况下，本地DP 假定人们根本不信任任何人（甚至是他们自己的数据源）。ISRL-DP 处于中心和本地DP 之间，使得在跨 silo 的真实情况下具有现实意义。",
    "tldr": "本文研究了无需信任服务器或其他数据源的跨 silo 联邦学习，考虑了跨 silo 记录级差分隐私 ISRL-DP。该算法可以确保来自每个人的数据都不会被泄漏。",
    "en_tdlr": "This paper proposes optimal algorithms for convex losses in private federated learning without a trusted server. The focus is on cross-silo FL in which each silo maintains the privacy of each person's data using Inter-Silo Record-Level Differential Privacy (ISRL-DP) to prevent data leakage, even if the server or other silos act as adversarial eavesdroppers."
}