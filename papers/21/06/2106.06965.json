{
    "title": "Contrastive Attention for Automatic Chest X-ray Report Generation. (arXiv:2106.06965v5 [cs.CV] UPDATED)",
    "abstract": "Recently, chest X-ray report generation, which aims to automatically generate descriptions of given chest X-ray images, has received growing research interests. The key challenge of chest X-ray report generation is to accurately capture and describe the abnormal regions. In most cases, the normal regions dominate the entire chest X-ray image, and the corresponding descriptions of these normal regions dominate the final report. Due to such data bias, learning-based models may fail to attend to abnormal regions. In this work, to effectively capture and describe abnormal regions, we propose the Contrastive Attention (CA) model. Instead of solely focusing on the current input image, the CA model compares the current input image with normal images to distill the contrastive information. The acquired contrastive information can better represent the visual features of abnormal regions. According to the experiments on the public IU-X-ray and MIMIC-CXR datasets, incorporating our CA into severa",
    "link": "http://arxiv.org/abs/2106.06965",
    "context": "Title: Contrastive Attention for Automatic Chest X-ray Report Generation. (arXiv:2106.06965v5 [cs.CV] UPDATED)\nAbstract: Recently, chest X-ray report generation, which aims to automatically generate descriptions of given chest X-ray images, has received growing research interests. The key challenge of chest X-ray report generation is to accurately capture and describe the abnormal regions. In most cases, the normal regions dominate the entire chest X-ray image, and the corresponding descriptions of these normal regions dominate the final report. Due to such data bias, learning-based models may fail to attend to abnormal regions. In this work, to effectively capture and describe abnormal regions, we propose the Contrastive Attention (CA) model. Instead of solely focusing on the current input image, the CA model compares the current input image with normal images to distill the contrastive information. The acquired contrastive information can better represent the visual features of abnormal regions. According to the experiments on the public IU-X-ray and MIMIC-CXR datasets, incorporating our CA into severa",
    "path": "papers/21/06/2106.06965.json",
    "total_tokens": 917,
    "translated_title": "自动胸部X光报告生成的对比注意力模型研究",
    "translated_abstract": "最近，自动生成给定胸部X光图像描述的胸部X光报告生成引起了越来越多的研究兴趣。胸部X光报告生成的关键挑战是准确捕捉和描述异常区域。在大多数情况下，正常区域占据整个胸部X光图像的主导地位，并且这些正常区域的描述占据了最终报告的主导地位。由于这种数据偏差，基于学习的模型可能无法关注异常区域。为了有效地捕捉和描述异常区域，我们提出了对比注意力（CA）模型。该CA模型不仅关注当前输入图像，还将其与正常图像进行比较，以提取对比信息。获取的对比信息可以更好地表示异常区域的视觉特征。根据在公共IU-X光和MIMIC-CXR数据集上的实验，将我们的CA纳入多种基线模型中，其结果证明了我们的方法的有效性和优越性。",
    "tldr": "本文提出对比注意力（CA）模型来准确捕捉和描述自动生成胸部X光图像描述中的异常区域，该模型将当前输入图像与正常图像进行比较以提取对比信息。实验结果证明了该方法的有效性和优越性。",
    "en_tdlr": "This paper proposes a Contrastive Attention (CA) model to accurately capture and describe abnormal regions in automatically generated chest X-ray reports. The model compares the input image with normal images to extract contrastive information, which better represents visual features of abnormal regions. Experimental results demonstrate the effectiveness and superiority of the proposed method."
}