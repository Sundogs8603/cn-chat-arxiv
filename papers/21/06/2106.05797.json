{
    "title": "Linear Classifiers Under Infinite Imbalance. (arXiv:2106.05797v2 [stat.ML] UPDATED)",
    "abstract": "We study the behavior of linear discriminant functions for binary classification in the infinite-imbalance limit, where the sample size of one class grows without bound while the sample size of the other remains fixed. The coefficients of the classifier minimize an empirical loss specified through a weight function. We show that for a broad class of weight functions, the intercept diverges but the rest of the coefficient vector has a finite almost sure limit under infinite imbalance, extending prior work on logistic regression. The limit depends on the left-tail growth rate of the weight function, for which we distinguish two cases: subexponential and exponential. The limiting coefficient vectors reflect robustness or conservatism properties in the sense that they optimize against certain worst-case alternatives. In the subexponential case, the limit is equivalent to an implicit choice of upsampling distribution for the minority class. We apply these ideas in a credit risk setting, wit",
    "link": "http://arxiv.org/abs/2106.05797",
    "context": "Title: Linear Classifiers Under Infinite Imbalance. (arXiv:2106.05797v2 [stat.ML] UPDATED)\nAbstract: We study the behavior of linear discriminant functions for binary classification in the infinite-imbalance limit, where the sample size of one class grows without bound while the sample size of the other remains fixed. The coefficients of the classifier minimize an empirical loss specified through a weight function. We show that for a broad class of weight functions, the intercept diverges but the rest of the coefficient vector has a finite almost sure limit under infinite imbalance, extending prior work on logistic regression. The limit depends on the left-tail growth rate of the weight function, for which we distinguish two cases: subexponential and exponential. The limiting coefficient vectors reflect robustness or conservatism properties in the sense that they optimize against certain worst-case alternatives. In the subexponential case, the limit is equivalent to an implicit choice of upsampling distribution for the minority class. We apply these ideas in a credit risk setting, wit",
    "path": "papers/21/06/2106.05797.json",
    "total_tokens": 1033,
    "translated_title": "无限不平衡下的线性分类器研究",
    "translated_abstract": "本研究探讨了在一个类别的样本数量增长到无穷大而另一个类别的样本数量保持不变的情况下，二元分类中的线性判别函数的行为。分类器的系数通过一个权重函数指定的经验损失最小化。我们展示了，对于广泛的权重函数类，截距发散但其余系数向量在无穷不平衡情况下具有一个有限的几乎肯定的极限，这扩展了之前对逻辑回归的研究。极限依赖于权重函数的左尾增长速率，对此我们区分了两种情况：亚指数和指数。极限系数向量反映了稳健性或保守性属性，因为它们优化了某些最坏情况的替代方法。在亚指数情况下，极限等价于少数类的上采样分布的隐式选择。我们在信用风险设置中应用了这些思想。",
    "tldr": "研究了在无限不平衡情况下的线性分类器，通过权重函数指定的经验损失最小化系数。截距发散但其余系数向量有一个有限的几乎肯定的极限，极限依赖于权重函数的左尾增长速率。极限系数向量反映稳健性或保守性属性，而在亚指数情况下，极限等价于少数类的上采样分布的隐式选择。"
}