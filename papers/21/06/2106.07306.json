{
    "title": "Constraining Linear-chain CRFs to Regular Languages. (arXiv:2106.07306v6 [cs.LG] UPDATED)",
    "abstract": "A major challenge in structured prediction is to represent the interdependencies within output structures. When outputs are structured as sequences, linear-chain conditional random fields (CRFs) are a widely used model class which can learn \\textit{local} dependencies in the output. However, the CRF's Markov assumption makes it impossible for CRFs to represent distributions with \\textit{nonlocal} dependencies, and standard CRFs are unable to respect nonlocal constraints of the data (such as global arity constraints on output labels). We present a generalization of CRFs that can enforce a broad class of constraints, including nonlocal ones, by specifying the space of possible output structures as a regular language $\\mathcal{L}$. The resulting regular-constrained CRF (RegCCRF) has the same formal properties as a standard CRF, but assigns zero probability to all label sequences not in $\\mathcal{L}$. Notably, RegCCRFs can incorporate their constraints during training, while related models",
    "link": "http://arxiv.org/abs/2106.07306",
    "context": "Title: Constraining Linear-chain CRFs to Regular Languages. (arXiv:2106.07306v6 [cs.LG] UPDATED)\nAbstract: A major challenge in structured prediction is to represent the interdependencies within output structures. When outputs are structured as sequences, linear-chain conditional random fields (CRFs) are a widely used model class which can learn \\textit{local} dependencies in the output. However, the CRF's Markov assumption makes it impossible for CRFs to represent distributions with \\textit{nonlocal} dependencies, and standard CRFs are unable to respect nonlocal constraints of the data (such as global arity constraints on output labels). We present a generalization of CRFs that can enforce a broad class of constraints, including nonlocal ones, by specifying the space of possible output structures as a regular language $\\mathcal{L}$. The resulting regular-constrained CRF (RegCCRF) has the same formal properties as a standard CRF, but assigns zero probability to all label sequences not in $\\mathcal{L}$. Notably, RegCCRFs can incorporate their constraints during training, while related models",
    "path": "papers/21/06/2106.07306.json",
    "total_tokens": 878,
    "translated_title": "限制线性链条件随机场到正则语言的方法",
    "translated_abstract": "结构预测中的一个重要挑战是表示输出结构中的相互依赖关系。当输出以序列形式结构化时，线性链条件随机场（CRFs）是一种广泛使用的模型类，可以学习输出中的“局部”依赖关系。然而，CRF的马尔可夫假设使得CRFs无法表示具有“非局部”依赖关系的分布，并且标准CRFs无法满足数据的非局部约束（例如输出标签的全局性约束）。我们提出了一种CRFs的推广形式，可以通过将可能的输出结构空间指定为正则语言$\\mathcal{L}$来强制执行广泛的约束，包括非局部约束。结果的正则约束CRF（RegCCRF）具有与标准CRF相同的形式属性，但对于不在$\\mathcal{L}$中的所有标签序列分配零概率。值得注意的是，RegCCRFs可以在训练过程中引入约束，与相关模型不同。",
    "tldr": "本文提出了一种将线性链条件随机场（CRFs）限制到正则语言的方法，该方法可以对广泛的约束进行建模，并允许在训练过程中引入这些约束。",
    "en_tdlr": "The paper introduces a method to constrain linear-chain conditional random fields (CRFs) to regular languages, enabling modeling of a wide range of constraints and incorporating them during training."
}