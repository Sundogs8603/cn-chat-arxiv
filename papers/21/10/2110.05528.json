{
    "title": "Smoothed Separable Nonnegative Matrix Factorization. (arXiv:2110.05528v2 [eess.SP] UPDATED)",
    "abstract": "Given a set of data points belonging to the convex hull of a set of vertices, a key problem in linear algebra, signal processing, data analysis and machine learning is to estimate these vertices in the presence of noise. Many algorithms have been developed under the assumption that there is at least one nearby data point to each vertex; two of the most widely used ones are vertex component analysis (VCA) and the successive projection algorithm (SPA). This assumption is known as the pure-pixel assumption in blind hyperspectral unmixing, and as the separability assumption in nonnegative matrix factorization. More recently, Bhattacharyya and Kannan (ACM-SIAM Symposium on Discrete Algorithms, 2020) proposed an algorithm for learning a latent simplex (ALLS) that relies on the assumption that there is more than one nearby data point to each vertex. In that scenario, ALLS is probalistically more robust to noise than algorithms based on the separability assumption. In this paper, inspired by A",
    "link": "http://arxiv.org/abs/2110.05528",
    "context": "Title: Smoothed Separable Nonnegative Matrix Factorization. (arXiv:2110.05528v2 [eess.SP] UPDATED)\nAbstract: Given a set of data points belonging to the convex hull of a set of vertices, a key problem in linear algebra, signal processing, data analysis and machine learning is to estimate these vertices in the presence of noise. Many algorithms have been developed under the assumption that there is at least one nearby data point to each vertex; two of the most widely used ones are vertex component analysis (VCA) and the successive projection algorithm (SPA). This assumption is known as the pure-pixel assumption in blind hyperspectral unmixing, and as the separability assumption in nonnegative matrix factorization. More recently, Bhattacharyya and Kannan (ACM-SIAM Symposium on Discrete Algorithms, 2020) proposed an algorithm for learning a latent simplex (ALLS) that relies on the assumption that there is more than one nearby data point to each vertex. In that scenario, ALLS is probalistically more robust to noise than algorithms based on the separability assumption. In this paper, inspired by A",
    "path": "papers/21/10/2110.05528.json",
    "total_tokens": 892,
    "translated_title": "平滑可分非负矩阵分解",
    "translated_abstract": "该论文提出了一种新算法--平滑可分非负矩阵分解（SSNMF），该算法基于一个经过平滑的可分离性假设，被制定为一个凸优化问题来抵抗在‘纯像素假设’存在的情况下噪声的干扰。该算法的有效实施和广泛实验表明，它可以保证在特定噪声水平内收敛到非负矩阵分解，且得出真实顶点。",
    "tldr": "该算法基于平滑的可分离性假设，提出一种新的平滑可分非负矩阵分解（SSNMF）算法，能够有效地抵抗在‘纯像素假设’存在的噪声干扰",
    "en_tdlr": "The paper proposes a new algorithm called smoothed separable nonnegative matrix factorization (SSNMF), which is based on a smoothed version of the separability assumption and is formulated as a convex optimization problem to resist noise interference in the presence of the pure-pixel assumption."
}