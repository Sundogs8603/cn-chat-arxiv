{
    "title": "Accelerating Distributed Deep Reinforcement Learning by In-Network Experience Sampling. (arXiv:2110.13506v3 [cs.DC] UPDATED)",
    "abstract": "A computing cluster that interconnects multiple compute nodes is used to accelerate distributed reinforcement learning based on DQN (Deep Q-Network). In distributed reinforcement learning, Actor nodes acquire experiences by interacting with a given environment and a Learner node optimizes their DQN model. Since data transfer between Actor and Learner nodes increases depending on the number of Actor nodes and their experience size, communication overhead between them is one of major performance bottlenecks. In this paper, their communication is accelerated by DPDK-based network optimizations, and DPDK-based low-latency experience replay memory server is deployed between Actor and Learner nodes interconnected with a 40GbE (40Gbit Ethernet) network. Evaluation results show that, as a network optimization technique, kernel bypassing by DPDK reduces network access latencies to a shared memory server by 32.7% to 58.9%. As another network optimization technique, an in-network experience repla",
    "link": "http://arxiv.org/abs/2110.13506",
    "raw_ret": "{\n    \"translated_title\": \"通过网络内经验采样加速分布式深度强化学习\",\n    \"translated_abstract\": \"利用互连多个计算节点的计算集群来加速基于DQN（Deep Q-Network）的分布式强化学习。在分布式强化学习中，Actor节点通过与给定环境交互获取经验，而Learner节点优化其DQN模型。由于Actor和Learner节点之间的数据传输随着Actor节点数量和其经验大小的增加而增加，因此它们之间的通信开销是主要的性能瓶颈之一。本文通过DPDK-based网络优化加速其通信，并在Actor和Learner节点之间部署了基于DPDK的低延迟经验重放内存服务器，这些节点用40GbE（40Gbit Ethernet）网络相互连接。评估结果显示，作为一种网络优化技术，DPDK的内核绕过将共享内存服务器的网络访问延迟降低了32.7％至58.9％。作为另一种网络优化技术，内置经验重放使通信过程减少，从而加快了模型的优化速度。\",\n    \"tldr\": \"本文提出了利用DPDK技术加速Actor节点和Learner节点之间的通信，并在40GbE网络中部署了低延迟经验重放内存服务器，显著提高了模型优化速度\"\n}<|im_sep|>",
    "total_tokens": 872,
    "ret": {
        "translated_title": "通过网络内经验采样加速分布式深度强化学习",
        "translated_abstract": "利用互连多个计算节点的计算集群来加速基于DQN（Deep Q-Network）的分布式强化学习。在分布式强化学习中，Actor节点通过与给定环境交互获取经验，而Learner节点优化其DQN模型。由于Actor和Learner节点之间的数据传输随着Actor节点数量和其经验大小的增加而增加，因此它们之间的通信开销是主要的性能瓶颈之一。本文通过DPDK-based网络优化加速其通信，并在Actor和Learner节点之间部署了基于DPDK的低延迟经验重放内存服务器，这些节点用40GbE（40Gbit Ethernet）网络相互连接。评估结果显示，作为一种网络优化技术，DPDK的内核绕过将共享内存服务器的网络访问延迟降低了32.7％至58.9％。作为另一种网络优化技术，内置经验重放使通信过程减少，从而加快了模型的优化速度。",
        "tldr": "本文提出了利用DPDK技术加速Actor节点和Learner节点之间的通信，并在40GbE网络中部署了低延迟经验重放内存服务器，显著提高了模型优化速度"
    }
}