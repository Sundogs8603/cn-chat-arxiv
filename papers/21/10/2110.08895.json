{
    "title": "DECAR: Deep Clustering for learning general-purpose Audio Representations. (arXiv:2110.08895v4 [cs.SD] UPDATED)",
    "abstract": "We introduce DECAR, a self-supervised pre-training approach for learning general-purpose audio representations. Our system is based on clustering: it utilizes an offline clustering step to provide target labels that act as pseudo-labels for solving a prediction task. We develop on top of recent advances in self-supervised learning for computer vision and design a lightweight, easy-to-use self-supervised pre-training scheme. We pre-train DECAR embeddings on a balanced subset of the large-scale Audioset dataset and transfer those representations to 9 downstream classification tasks, including speech, music, animal sounds, and acoustic scenes. Furthermore, we conduct ablation studies identifying key design choices and also make all our code and pre-trained models publicly available.",
    "link": "http://arxiv.org/abs/2110.08895",
    "context": "Title: DECAR: Deep Clustering for learning general-purpose Audio Representations. (arXiv:2110.08895v4 [cs.SD] UPDATED)\nAbstract: We introduce DECAR, a self-supervised pre-training approach for learning general-purpose audio representations. Our system is based on clustering: it utilizes an offline clustering step to provide target labels that act as pseudo-labels for solving a prediction task. We develop on top of recent advances in self-supervised learning for computer vision and design a lightweight, easy-to-use self-supervised pre-training scheme. We pre-train DECAR embeddings on a balanced subset of the large-scale Audioset dataset and transfer those representations to 9 downstream classification tasks, including speech, music, animal sounds, and acoustic scenes. Furthermore, we conduct ablation studies identifying key design choices and also make all our code and pre-trained models publicly available.",
    "path": "papers/21/10/2110.08895.json",
    "total_tokens": 796,
    "translated_title": "DECAR: 基于深度聚类的通用音频表示学习方法",
    "translated_abstract": "本文提出了DECAR，一种自监督的音频通用表示预训练方法。我们的系统基于聚类，利用离线聚类步骤提供目标标签，作为伪标签来解决预测任务。我们在计算机视觉领域的自监督学习的最新进展基础上，设计了一个轻量级、易于使用的自监督预训练方案。我们在大规模Audioset数据集的平衡子集上预训练DECAR嵌入，并将这些表示传递到9个下游分类任务，包括语音、音乐、动物声音和声学场景。此外，我们进行了消融研究，并公开了所有代码和预训练模型。",
    "tldr": "本文提出了一种基于深度聚类的自监督方法DECAR，用于学习通用的音频表示。该方法建立在先前自学习算法的基础之上，利用离线聚类的伪标签来解决预测任务，并在大规模Audioset数据集的平衡子集上进行了验证。",
    "en_tdlr": "The paper proposes a self-supervised pre-training approach DECAR for learning general-purpose audio representations based on offline clustering step, and transfer them to various downstream classification tasks. The authors also release their code and pre-trained models."
}