{
    "title": "Quantifying Epistemic Uncertainty in Deep Learning. (arXiv:2110.12122v4 [cs.LG] UPDATED)",
    "abstract": "Uncertainty quantification is at the core of the reliability and robustness of machine learning. In this paper, we provide a theoretical framework to dissect the uncertainty, especially the \\textit{epistemic} component, in deep learning into \\textit{procedural variability} (from the training procedure) and \\textit{data variability} (from the training data), which is the first such attempt in the literature to our best knowledge. We then propose two approaches to estimate these uncertainties, one based on influence function and one on batching. We demonstrate how our approaches overcome the computational difficulties in applying classical statistical methods. Experimental evaluations on multiple problem settings corroborate our theory and illustrate how our framework and estimation can provide direct guidance on modeling and data collection efforts.",
    "link": "http://arxiv.org/abs/2110.12122",
    "context": "Title: Quantifying Epistemic Uncertainty in Deep Learning. (arXiv:2110.12122v4 [cs.LG] UPDATED)\nAbstract: Uncertainty quantification is at the core of the reliability and robustness of machine learning. In this paper, we provide a theoretical framework to dissect the uncertainty, especially the \\textit{epistemic} component, in deep learning into \\textit{procedural variability} (from the training procedure) and \\textit{data variability} (from the training data), which is the first such attempt in the literature to our best knowledge. We then propose two approaches to estimate these uncertainties, one based on influence function and one on batching. We demonstrate how our approaches overcome the computational difficulties in applying classical statistical methods. Experimental evaluations on multiple problem settings corroborate our theory and illustrate how our framework and estimation can provide direct guidance on modeling and data collection efforts.",
    "path": "papers/21/10/2110.12122.json",
    "total_tokens": 819,
    "translated_title": "深度学习中认识不确定性的量化",
    "translated_abstract": "不确定性量化是机器学习可靠性和鲁棒性的核心。本文提供了一个理论框架来分解深度学习中的不确定性，特别是\\textit {认识成分}；分为\\textit {程序变异性}(来自训练过程)和\\textit {数据变异性} (来自训练数据)，这是文献中首次尝试。然后我们提出两种方法来估计这些不确定性，一种是基于影响函数的方法，另一种是批次化的方法。我们展示了我们的方法如何克服在应用经典统计方法时遇到的计算困难。多个问题设置的实验评估证实了我们的理论，并说明了我们的框架和估计如何提供对建模和数据收集工作的直接指导。",
    "tldr": "本文提供了一个理论框架来分解深度学习中的不确定性，并提出了两种方法来估计这些不确定性，这些方法使我们能够克服在使用传统统计方法时遇到的困难，从而为建模和数据收集提供直接的指导。",
    "en_tdlr": "This paper provides a theoretical framework to decompose uncertainty, especially the epistemic component, in deep learning, and proposes two approaches to estimate these uncertainties, which help overcome computational difficulties when using classical statistical methods and provide direct guidance on modeling and data collection efforts."
}