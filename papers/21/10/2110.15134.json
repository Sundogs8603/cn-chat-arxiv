{
    "title": "An Analysis of Programming Course Evaluations Before and After the Introduction of an Autograder. (arXiv:2110.15134v2 [cs.HC] UPDATED)",
    "abstract": "Commonly, introductory programming courses in higher education institutions have hundreds of participating students eager to learn to program. The manual effort for reviewing the submitted source code and for providing feedback can no longer be managed. Manually reviewing the submitted homework can be subjective and unfair, particularly if many tutors are responsible for grading. Different autograders can help in this situation; however, there is a lack of knowledge about how autograders can impact students' overall perception of programming classes and teaching. This is relevant for course organizers and institutions to keep their programming courses attractive while coping with increasing students.  This paper studies the answers to the standardized university evaluation questionnaires of multiple large-scale foundational computer science courses which recently introduced autograding. The differences before and after this intervention are analyzed. By incorporating additional observa",
    "link": "http://arxiv.org/abs/2110.15134",
    "context": "Title: An Analysis of Programming Course Evaluations Before and After the Introduction of an Autograder. (arXiv:2110.15134v2 [cs.HC] UPDATED)\nAbstract: Commonly, introductory programming courses in higher education institutions have hundreds of participating students eager to learn to program. The manual effort for reviewing the submitted source code and for providing feedback can no longer be managed. Manually reviewing the submitted homework can be subjective and unfair, particularly if many tutors are responsible for grading. Different autograders can help in this situation; however, there is a lack of knowledge about how autograders can impact students' overall perception of programming classes and teaching. This is relevant for course organizers and institutions to keep their programming courses attractive while coping with increasing students.  This paper studies the answers to the standardized university evaluation questionnaires of multiple large-scale foundational computer science courses which recently introduced autograding. The differences before and after this intervention are analyzed. By incorporating additional observa",
    "path": "papers/21/10/2110.15134.json",
    "total_tokens": 866,
    "translated_title": "引入自动评分系统前后编程课程评估的分析",
    "translated_abstract": "在高等教育机构中，常见的入门编程课程有数百名参与学生渴望学习编程。人工评审提交的源代码和提供反馈的工作量已经无法管理。手动评审提交的作业可能存在主观和不公平的问题，尤其是如果有多个助教负责评分。不同的自动评分系统可以在这种情况下提供帮助；然而，目前对于自动评分系统如何影响学生对编程课程和教学的整体感知缺乏了解。这对于课程组织者和机构在应对不断增加的学生数量时保持编程课程的吸引力具有重要意义。本文研究了最近引入自动评分系统的多个大规模基础计算机科学课程的标准化大学评估问卷的回答。分析了介入前后的差异。通过纳入其他观察角度，探讨了自动评分系统的潜在影响。",
    "tldr": "本研究分析了引入自动评分系统前后多个大规模计算机科学基础课程的评估结果，探讨了自动评分系统对学生对编程课程和教学感知的影响。",
    "en_tdlr": "This study analyzes the evaluations of multiple large-scale computer science foundational courses before and after the introduction of an autograder, exploring the impact of autograders on students' perception of programming classes and teaching."
}