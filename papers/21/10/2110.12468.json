{
    "title": "SCORE: Spurious COrrelation REduction for Offline Reinforcement Learning. (arXiv:2110.12468v2 [cs.LG] UPDATED)",
    "abstract": "Offline reinforcement learning (RL) harnesses the power of massive datasets for resolving sequential decision problems. Most existing papers only discuss defending against out-of-distribution (OOD) actions while we investigate a broader issue, the spurious correlations between epistemic uncertainty and decision-making, an essential factor that causes suboptimality. In this paper, we propose Spurious COrrelation REduction (SCORE) for offline RL, a practically effective and theoretically provable algorithm. We empirically show that SCORE achieves the SoTA performance with 3.1x acceleration on various tasks in a standard benchmark (D4RL). The proposed algorithm introduces an annealing behavior cloning regularizer to help produce a high-quality estimation of uncertainty which is critical for eliminating spurious correlations from suboptimality. Theoretically, we justify the rationality of the proposed method and prove its convergence to the optimal policy with a sublinear rate under mild a",
    "link": "http://arxiv.org/abs/2110.12468",
    "context": "Title: SCORE: Spurious COrrelation REduction for Offline Reinforcement Learning. (arXiv:2110.12468v2 [cs.LG] UPDATED)\nAbstract: Offline reinforcement learning (RL) harnesses the power of massive datasets for resolving sequential decision problems. Most existing papers only discuss defending against out-of-distribution (OOD) actions while we investigate a broader issue, the spurious correlations between epistemic uncertainty and decision-making, an essential factor that causes suboptimality. In this paper, we propose Spurious COrrelation REduction (SCORE) for offline RL, a practically effective and theoretically provable algorithm. We empirically show that SCORE achieves the SoTA performance with 3.1x acceleration on various tasks in a standard benchmark (D4RL). The proposed algorithm introduces an annealing behavior cloning regularizer to help produce a high-quality estimation of uncertainty which is critical for eliminating spurious correlations from suboptimality. Theoretically, we justify the rationality of the proposed method and prove its convergence to the optimal policy with a sublinear rate under mild a",
    "path": "papers/21/10/2110.12468.json",
    "total_tokens": 889,
    "translated_title": "SCORE：用于离线强化学习的虚假相关性降低",
    "translated_abstract": "离线强化学习（RL）利用大规模数据集解决序贯决策问题。大多数现有论文只讨论了对抗分布外（OOD）行为的防御，而本文研究了更广泛的问题，即认知不确定性与决策之间的虚假相关性，这是导致次优性的一个重要因素。本文提出了一种实用有效且理论上可证明的算法：用于离线RL的虚假相关性降低（SCORE）。我们通过实验证明，SCORE在标准基准（D4RL）上的各种任务中以3.1倍加速率实现了SoTA性能。所提算法引入了一个退火行为克隆正则化器来帮助生成高质量的不确定性估计，这对于消除次优性中的虚假相关性至关重要。理论上，我们证明了所提方法的合理性，并证明了在温和的条件下其收敛到最优策略的次线性率。",
    "tldr": "本文提出了SCORE算法，用于离线强化学习中的虚假相关性降低。通过引入退火行为克隆正则化器，SCORE实现了SoTA性能，并消除了次优性中的虚假相关性。"
}