{
    "title": "Bridge the Gap Between CV and NLP! A Gradient-based Textual Adversarial Attack Framework. (arXiv:2110.15317v4 [cs.CL] UPDATED)",
    "abstract": "Despite recent success on various tasks, deep learning techniques still perform poorly on adversarial examples with small perturbations. While optimization-based methods for adversarial attacks are well-explored in the field of computer vision, it is impractical to directly apply them in natural language processing due to the discrete nature of the text. To address the problem, we propose a unified framework to extend the existing optimization-based adversarial attack methods in the vision domain to craft textual adversarial samples. In this framework, continuously optimized perturbations are added to the embedding layer and amplified in the forward propagation process. Then the final perturbed latent representations are decoded with a masked language model head to obtain potential adversarial samples. In this paper, we instantiate our framework with an attack algorithm named Textual Projected Gradient Descent (T-PGD). We find our algorithm effective even using proxy gradient informati",
    "link": "http://arxiv.org/abs/2110.15317",
    "context": "Title: Bridge the Gap Between CV and NLP! A Gradient-based Textual Adversarial Attack Framework. (arXiv:2110.15317v4 [cs.CL] UPDATED)\nAbstract: Despite recent success on various tasks, deep learning techniques still perform poorly on adversarial examples with small perturbations. While optimization-based methods for adversarial attacks are well-explored in the field of computer vision, it is impractical to directly apply them in natural language processing due to the discrete nature of the text. To address the problem, we propose a unified framework to extend the existing optimization-based adversarial attack methods in the vision domain to craft textual adversarial samples. In this framework, continuously optimized perturbations are added to the embedding layer and amplified in the forward propagation process. Then the final perturbed latent representations are decoded with a masked language model head to obtain potential adversarial samples. In this paper, we instantiate our framework with an attack algorithm named Textual Projected Gradient Descent (T-PGD). We find our algorithm effective even using proxy gradient informati",
    "path": "papers/21/10/2110.15317.json",
    "total_tokens": 1223,
    "translated_title": "桥接计算机视觉与自然语言处理间的鸿沟！一种基于梯度的文本对抗攻击框架。",
    "translated_abstract": "尽管深度学习在各种任务上取得了最近的成功，但在小扰动的对抗样本上仍表现不佳。优化类的对抗攻击方法虽已在计算机视觉领域得到了很好的研究，但由于文本的离散性质，直接将这些方法应用于自然语言处理是不切实际的。为了解决这个问题，我们提出了一个统一的框架，将现有的视觉域优化类对抗攻击方法扩展到文本对抗样本的制造上。在这个框架中，我们通过在嵌入层上持续优化扰动，并在前向传播过程中放大这些扰动。随后，使用遮罩语言模型头对最终扰动的潜在代表进行解码，以获取可能的对抗样本。在本文中，我们使用了一种名为文本投影梯度下降（T-PGD）的攻击算法来实例化我们的框架。我们发现即使在文本领域中常见的使用代理梯度信息的情况下，我们的算法也具有很好的效果。此外，我们对各种语言任务进行了广泛的评估，包括情感分析、文本分类和命名实体识别。实验结果表明，我们提出的框架实现了制造近乎不可察觉的通用和定向文本对抗样本的最新技术水平。",
    "tldr": "该论文提出了一种针对文本对抗攻击的框架，通过在嵌入层上持续优化扰动并放大这些扰动，使用遮罩语言模型头对最终扰动的潜在代表进行解码，以获取可能的对抗样本，进行了广泛的评估，并在各种语言任务上取得了制造近乎不可察觉的通用和定向文本对抗样本的最新技术水平。",
    "en_tdlr": "This paper proposes a gradient-based framework for crafting textual adversarial examples by continuously optimizing perturbations in the embedding layer and amplifying them in the forward propagation process, and using a masked language model head to decode the final perturbed latent representation. Extensive evaluations are performed on various language tasks, and the proposed framework achieves state-of-the-art performance in crafting imperceptible universal and targeted textual adversarial examples."
}