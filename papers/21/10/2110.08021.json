{
    "title": "StreaMulT: Streaming Multimodal Transformer for Heterogeneous and Arbitrary Long Sequential Data",
    "abstract": "arXiv:2110.08021v2 Announce Type: replace-cross  Abstract: The increasing complexity of Industry 4.0 systems brings new challenges regarding predictive maintenance tasks such as fault detection and diagnosis. A corresponding and realistic setting includes multi-source data streams from different modalities, such as sensors measurements time series, machine images, textual maintenance reports, etc. These heterogeneous multimodal streams also differ in their acquisition frequency, may embed temporally unaligned information and can be arbitrarily long, depending on the considered system and task. Whereas multimodal fusion has been largely studied in a static setting, to the best of our knowledge, there exists no previous work considering arbitrarily long multimodal streams alongside with related tasks such as prediction across time. Thus, in this paper, we first formalize this paradigm of heterogeneous multimodal learning in a streaming setting as a new one. To tackle this challenge, we p",
    "link": "https://arxiv.org/abs/2110.08021",
    "context": "Title: StreaMulT: Streaming Multimodal Transformer for Heterogeneous and Arbitrary Long Sequential Data\nAbstract: arXiv:2110.08021v2 Announce Type: replace-cross  Abstract: The increasing complexity of Industry 4.0 systems brings new challenges regarding predictive maintenance tasks such as fault detection and diagnosis. A corresponding and realistic setting includes multi-source data streams from different modalities, such as sensors measurements time series, machine images, textual maintenance reports, etc. These heterogeneous multimodal streams also differ in their acquisition frequency, may embed temporally unaligned information and can be arbitrarily long, depending on the considered system and task. Whereas multimodal fusion has been largely studied in a static setting, to the best of our knowledge, there exists no previous work considering arbitrarily long multimodal streams alongside with related tasks such as prediction across time. Thus, in this paper, we first formalize this paradigm of heterogeneous multimodal learning in a streaming setting as a new one. To tackle this challenge, we p",
    "path": "papers/21/10/2110.08021.json",
    "total_tokens": 841,
    "translated_title": "StreaMulT: 流式多模态Transformer用于异构和任意长的序列数据",
    "translated_abstract": "随着工业4.0系统复杂性的增加，预测性维护任务（如故障检测和诊断）带来了新的挑战。相应而实际的情景包括来自不同模态的多源数据流，如传感器测量时间序列、机器图像、文本维护报告等。这些异构多模态流在其采集频率上也不同，可能包含时间上不对齐的信息，并且可以任意长，取决于所考虑的系统和任务。虽然多模态融合在静态环境中已被广泛研究，但据我们所知，以往的工作中没有考虑过与相关任务（如跨时间预测）一起考虑任意长的多模态流。因此，在本文中，我们首先将这种异构多模态学习范式形式化为一种新型的流式设置。为了解决这一挑战，我们...",
    "tldr": "提出一种新的流式多模态Transformer模型，用于处理异构和任意长的序列数据，解决了在预测性维护任务中多源数据流的融合和跨时间预测的挑战。",
    "en_tdlr": "Introducing a novel streaming multimodal Transformer model to address heterogeneous and arbitrarily long sequential data, resolving challenges in fusing multi-source data streams and predicting across time in predictive maintenance tasks."
}