{
    "title": "CyTran: A Cycle-Consistent Transformer with Multi-Level Consistency for Non-Contrast to Contrast CT Translation. (arXiv:2110.06400v3 [eess.IV] UPDATED)",
    "abstract": "We propose a novel approach to translate unpaired contrast computed tomography (CT) scans to non-contrast CT scans and the other way around. Solving this task has two important applications: (i) to automatically generate contrast CT scans for patients for whom injecting contrast substance is not an option, and (ii) to enhance the alignment between contrast and non-contrast CT by reducing the differences induced by the contrast substance before registration. Our approach is based on cycle-consistent generative adversarial convolutional transformers, for short, CyTran. Our neural model can be trained on unpaired images, due to the integration of a multi-level cycle-consistency loss. Aside from the standard cycle-consistency loss applied at the image level, we propose to apply additional cycle-consistency losses between intermediate feature representations, which enforces the model to be cycle-consistent at multiple representations levels, leading to superior results. To deal with high-re",
    "link": "http://arxiv.org/abs/2110.06400",
    "context": "Title: CyTran: A Cycle-Consistent Transformer with Multi-Level Consistency for Non-Contrast to Contrast CT Translation. (arXiv:2110.06400v3 [eess.IV] UPDATED)\nAbstract: We propose a novel approach to translate unpaired contrast computed tomography (CT) scans to non-contrast CT scans and the other way around. Solving this task has two important applications: (i) to automatically generate contrast CT scans for patients for whom injecting contrast substance is not an option, and (ii) to enhance the alignment between contrast and non-contrast CT by reducing the differences induced by the contrast substance before registration. Our approach is based on cycle-consistent generative adversarial convolutional transformers, for short, CyTran. Our neural model can be trained on unpaired images, due to the integration of a multi-level cycle-consistency loss. Aside from the standard cycle-consistency loss applied at the image level, we propose to apply additional cycle-consistency losses between intermediate feature representations, which enforces the model to be cycle-consistent at multiple representations levels, leading to superior results. To deal with high-re",
    "path": "papers/21/10/2110.06400.json",
    "total_tokens": 1260,
    "translated_title": "CyTran: 一种多级连贯性的循环一致 Transformer 方法，用于非对比度到对比度 CT 扫描的翻译",
    "translated_abstract": "我们提出了一种新颖的方法，将非对比 CT 扫描和对比 CT 扫描相互翻译。解决这一问题有两个重要应用：(i) 为那些不能注射对比剂的患者自动生成对比 CT 扫描，(ii) 通过减少对比剂引起的差异来增强对比和非对比 CT 扫描的对齐。我们的方法基于循环一致的生成对抗卷积 Transformer 模型，简称 CyTran。由于整合了多级循环一致性损失函数，我们的神经模型可以在未成对图像上进行训练。除了在图像级别应用标准的循环一致性损失函数外，我们提出在中间特征表达之间应用额外的循环一致性损失函数，强制模型在多个表示层面上保持循环一致性，从而获得更好的结果。为应对非对比度和对比度 CT 扫描之间的高分辨率细节和大变异，我们引入了一种新的对比损失函数，不仅可以提高翻译图像的质量，还可以增强翻译和目标图像之间的相似性。实验表明，CyTran 在非对比度到对比度和对比度到非对比度 CT 扫描的翻译任务上优于现有的最先进模型。",
    "tldr": "CyTran 是一种基于循环一致的生成对抗卷积 Transformer 模型，通过多级循环一致性损失函数和一种新的对比损失函数实现了非对比度和对比度 CT 扫描的翻译，可为不能注射对比剂的患者自动生成对比 CT 扫描，同时增强对比和非对比 CT 扫描的对齐。 CyTran outperforms state-of-the-art models for both non-contrast to contrast and contrast to non-contrast CT translation tasks.",
    "en_tdlr": "CyTran is a cycle-consistent generative adversarial convolutional transformer model that utilizes a multi-level cycle-consistency loss and a novel contrastive loss function to translate between non-contrast and contrast computed tomography (CT) scans. The model has important applications in generating contrast CT scans for patients unable to receive contrast substance and in improving the alignment between contrast and non-contrast CT scans. CyTran outperforms existing models in both non-contrast to contrast and contrast to non-contrast CT translation tasks."
}