{
    "title": "Understanding Multimodal Procedural Knowledge by Sequencing Multimodal Instructional Manuals",
    "abstract": "arXiv:2110.08486v4 Announce Type: replace  Abstract: The ability to sequence unordered events is an essential skill to comprehend and reason about real world task procedures, which often requires thorough understanding of temporal common sense and multimodal information, as these procedures are often communicated through a combination of texts and images. Such capability is essential for applications such as sequential task planning and multi-source instruction summarization. While humans are capable of reasoning about and sequencing unordered multimodal procedural instructions, whether current machine learning models have such essential capability is still an open question. In this work, we benchmark models' capability of reasoning over and sequencing unordered multimodal instructions by curating datasets from popular online instructional manuals and collecting comprehensive human annotations. We find models not only perform significantly worse than humans but also seem incapable of e",
    "link": "https://arxiv.org/abs/2110.08486",
    "context": "Title: Understanding Multimodal Procedural Knowledge by Sequencing Multimodal Instructional Manuals\nAbstract: arXiv:2110.08486v4 Announce Type: replace  Abstract: The ability to sequence unordered events is an essential skill to comprehend and reason about real world task procedures, which often requires thorough understanding of temporal common sense and multimodal information, as these procedures are often communicated through a combination of texts and images. Such capability is essential for applications such as sequential task planning and multi-source instruction summarization. While humans are capable of reasoning about and sequencing unordered multimodal procedural instructions, whether current machine learning models have such essential capability is still an open question. In this work, we benchmark models' capability of reasoning over and sequencing unordered multimodal instructions by curating datasets from popular online instructional manuals and collecting comprehensive human annotations. We find models not only perform significantly worse than humans but also seem incapable of e",
    "path": "papers/21/10/2110.08486.json",
    "total_tokens": 820,
    "translated_title": "通过对多模态指导手册进行排序来理解多模态程序化知识",
    "translated_abstract": "漫游指导无序事件的能力是理解和推理现实世界任务程序的基本技能，通常需要对时间常识和多模态信息有深入的理解，因为这些程序通常通过文本和图像的组合进行传达。这种能力对于顺序任务规划和多源指导摘要等应用至关重要。虽然人类能够推理和排序无序的多模态程序指导，但当前机器学习模型是否具有这种基本能力仍然是一个未解之谜。在这项工作中，我们通过整理来自热门在线指导手册的数据集并收集了全面的人类注释，来对模型推理和排序无序的多模态指导进行基准测试。我们发现模型不仅性能显著低于人类，而且似乎无法...",
    "tldr": "本研究通过整理数据集并收集全面的人类注释，对机器学习模型在推理和排序无序的多模态指导方面的能力进行基准测试，发现模型表现不仅显著低于人类，而且似乎无法具备这种基本能力。",
    "en_tdlr": "This study benchmarks machine learning models' capability of reasoning over and sequencing unordered multimodal instructions by curating datasets and collecting comprehensive human annotations, finding that the models not only perform significantly worse than humans but also seem incapable of possessing such essential capability."
}