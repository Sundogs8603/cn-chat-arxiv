{
    "title": "Game Theory for Adversarial Attacks and Defenses. (arXiv:2110.06166v4 [cs.LG] UPDATED)",
    "abstract": "Adversarial attacks can generate adversarial inputs by applying small but intentionally worst-case perturbations to samples from the dataset, which leads to even state-of-the-art deep neural networks outputting incorrect answers with high confidence. Hence, some adversarial defense techniques are developed to improve the security and robustness of the models and avoid them being attacked. Gradually, a game-like competition between attackers and defenders formed, in which both players would attempt to play their best strategies against each other while maximizing their own payoffs. To solve the game, each player would choose an optimal strategy against the opponent based on the prediction of the opponent's strategy choice. In this work, we are on the defensive side to apply game-theoretic approaches on defending against attacks. We use two randomization methods, random initialization and stochastic activation pruning, to create diversity of networks. Furthermore, we use one denoising te",
    "link": "http://arxiv.org/abs/2110.06166",
    "context": "Title: Game Theory for Adversarial Attacks and Defenses. (arXiv:2110.06166v4 [cs.LG] UPDATED)\nAbstract: Adversarial attacks can generate adversarial inputs by applying small but intentionally worst-case perturbations to samples from the dataset, which leads to even state-of-the-art deep neural networks outputting incorrect answers with high confidence. Hence, some adversarial defense techniques are developed to improve the security and robustness of the models and avoid them being attacked. Gradually, a game-like competition between attackers and defenders formed, in which both players would attempt to play their best strategies against each other while maximizing their own payoffs. To solve the game, each player would choose an optimal strategy against the opponent based on the prediction of the opponent's strategy choice. In this work, we are on the defensive side to apply game-theoretic approaches on defending against attacks. We use two randomization methods, random initialization and stochastic activation pruning, to create diversity of networks. Furthermore, we use one denoising te",
    "path": "papers/21/10/2110.06166.json",
    "total_tokens": 886,
    "translated_title": "对抗性攻击和防御的博弈论",
    "translated_abstract": "对抗性攻击通过对数据集中的样本施加小但有意的最坏情况扰动来生成对抗性输入，这导致即使是最先进的深度神经网络也会以高置信度输出错误答案。因此，一些对抗性防御技术被开发出来来提高模型的安全性和稳健性，并避免它们被攻击。逐渐形成了攻击者和防御者之间的类似于游戏的竞争，双方都试图在彼此之间发挥最佳策略，同时最大化自己的回报。为了解决这个游戏，每个玩家根据对手的策略选择的预测来选择对手的最优策略。在这项工作中，我们站在防守的角度，运用博弈论方法来防御攻击。我们使用两种随机化方法，随机初始化和随机激活修剪，来创建网络的多样性。此外，我们使用一种去噪方法来减少对抗性扰动对模型的影响。",
    "tldr": "这项工作利用博弈论方法在防御对抗性攻击上取得了重要进展，通过随机化方法和去噪技术提高了网络的安全性和稳健性。",
    "en_tdlr": "This work makes significant progress in defending against adversarial attacks using game theory, improving network security and robustness through randomization methods and denoising techniques."
}