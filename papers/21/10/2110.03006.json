{
    "title": "Unsupervised Selective Labeling for More Effective Semi-Supervised Learning. (arXiv:2110.03006v4 [cs.LG] UPDATED)",
    "abstract": "Given an unlabeled dataset and an annotation budget, we study how to selectively label a fixed number of instances so that semi-supervised learning (SSL) on such a partially labeled dataset is most effective. We focus on selecting the right data to label, in addition to usual SSL's propagating labels from labeled data to the rest unlabeled data. This instance selection task is challenging, as without any labeled data we do not know what the objective of learning should be. Intuitively, no matter what the downstream task is, instances to be labeled must be representative and diverse: The former would facilitate label propagation to unlabeled data, whereas the latter would ensure coverage of the entire dataset. We capture this idea by selecting cluster prototypes, either in a pretrained feature space, or along with feature optimization, both without labels. Our unsupervised selective labeling consistently improves SSL methods over state-of-the-art active learning given labeled data, by 8",
    "link": "http://arxiv.org/abs/2110.03006",
    "context": "Title: Unsupervised Selective Labeling for More Effective Semi-Supervised Learning. (arXiv:2110.03006v4 [cs.LG] UPDATED)\nAbstract: Given an unlabeled dataset and an annotation budget, we study how to selectively label a fixed number of instances so that semi-supervised learning (SSL) on such a partially labeled dataset is most effective. We focus on selecting the right data to label, in addition to usual SSL's propagating labels from labeled data to the rest unlabeled data. This instance selection task is challenging, as without any labeled data we do not know what the objective of learning should be. Intuitively, no matter what the downstream task is, instances to be labeled must be representative and diverse: The former would facilitate label propagation to unlabeled data, whereas the latter would ensure coverage of the entire dataset. We capture this idea by selecting cluster prototypes, either in a pretrained feature space, or along with feature optimization, both without labels. Our unsupervised selective labeling consistently improves SSL methods over state-of-the-art active learning given labeled data, by 8",
    "path": "papers/21/10/2110.03006.json",
    "total_tokens": 962,
    "translated_title": "无监督选择性标注以实现更有效的半监督学习",
    "translated_abstract": "针对一个无标签数据集和一个注释预算，我们研究了如何有选择地标注固定数量的实例，以便在这样一个部分标记的数据集上进行半监督学习（SSL）更加有效。我们关注选择适当的数据进行标注，除了通常的SSL将标签从有标记数据传播到其余未标记数据的过程。这个实例选择任务很有挑战性，因为在没有任何有标记数据的情况下，我们不知道学习的目标应该是什么。直观地说，无论下游任务是什么，要标注的实例必须是具有代表性和多样性的：前者有助于将标签传播到未标记数据，而后者保证了整个数据集的覆盖范围。我们通过在预训练特征空间中选择聚类原型或在特征优化过程中选择聚类原型来捕捉这个想法，而都不需要标签。我们的无监督选择性标注方法在有标记数据的情况下始终比最先进的主动学习方法提高了8％。",
    "tldr": "本文研究了在半监督学习中如何选择性地标注无标签数据，以提高学习效果。作者提出了一种无监督的选择性标注方法，通过选择聚类原型来获得代表性和多样性的标注数据，证明了该方法在性能上优于传统的主动学习方法。",
    "en_tdlr": "This paper investigates how to selectively label unlabeled data in semi-supervised learning to improve learning performance. The authors propose an unsupervised selective labeling method that selects cluster prototypes to obtain representative and diverse labeled instances, and demonstrate its superiority over traditional active learning methods in terms of performance."
}