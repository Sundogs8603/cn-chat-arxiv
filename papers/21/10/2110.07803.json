{
    "title": "Attacking Open-domain Question Answering by Injecting Misinformation. (arXiv:2110.07803v3 [cs.CL] UPDATED)",
    "abstract": "With a rise in false, inaccurate, and misleading information in propaganda, news, and social media, real-world Question Answering (QA) systems face the challenges of synthesizing and reasoning over misinformation-polluted contexts to derive correct answers. This urgency gives rise to the need to make QA systems robust to misinformation, a topic previously unexplored. We study the risk of misinformation to QA models by investigating the sensitivity of open-domain QA models to corpus pollution with misinformation documents. We curate both human-written and model-generated false documents that we inject into the evidence corpus of QA models and assess the impact on the performance of these systems. Experiments show that QA models are vulnerable to even small amounts of evidence contamination brought by misinformation, with large absolute performance drops on all models. Misinformation attack brings more threat when fake documents are produced at scale by neural models or the attacker targ",
    "link": "http://arxiv.org/abs/2110.07803",
    "context": "Title: Attacking Open-domain Question Answering by Injecting Misinformation. (arXiv:2110.07803v3 [cs.CL] UPDATED)\nAbstract: With a rise in false, inaccurate, and misleading information in propaganda, news, and social media, real-world Question Answering (QA) systems face the challenges of synthesizing and reasoning over misinformation-polluted contexts to derive correct answers. This urgency gives rise to the need to make QA systems robust to misinformation, a topic previously unexplored. We study the risk of misinformation to QA models by investigating the sensitivity of open-domain QA models to corpus pollution with misinformation documents. We curate both human-written and model-generated false documents that we inject into the evidence corpus of QA models and assess the impact on the performance of these systems. Experiments show that QA models are vulnerable to even small amounts of evidence contamination brought by misinformation, with large absolute performance drops on all models. Misinformation attack brings more threat when fake documents are produced at scale by neural models or the attacker targ",
    "path": "papers/21/10/2110.07803.json",
    "total_tokens": 900,
    "translated_title": "将错误信息注入进行开放领域问答的攻击",
    "translated_abstract": "随着宣传、新闻和社交媒体中虚假、不准确和误导性信息的增加，现实世界中的问答系统面临着在被错误信息污染的语境中综合和推理以得出正确答案的挑战。这种紧迫性促使我们需要使问答系统对错误信息具备鲁棒性，而这是之前未被探索的一个主题。我们通过调查开放领域问答模型对带有错误信息文档的语料库污染的敏感性，来研究错误信息对问答模型的风险。我们整理了人工撰写和模型生成的虚假文档，将其注入到问答模型的证据语料库中，并评估这些系统性能的影响。实验证明，即使少量的错误信息污染也会使问答模型脆弱，所有模型的性能都会大幅度下降。当神经模型批量生成虚假文档时或攻击者针对问答模型时，错误信息攻击的威胁更大。",
    "tldr": "本研究探究了将错误信息注入问答系统的攻击，并发现问答模型对于错误信息具有脆弱性，即使少量错误信息的污染也会导致性能大幅下降。",
    "en_tdlr": "This study investigates the attacks on question answering systems by injecting misinformation, and finds that QA models are vulnerable to misinformation, with even a small amount of contamination leading to significant performance drops."
}