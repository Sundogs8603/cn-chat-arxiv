{
    "title": "Observations on K-image Expansion of Image-Mixing Augmentation for Classification. (arXiv:2110.04248v2 [cs.CV] UPDATED)",
    "abstract": "Image-mixing augmentations (e.g., Mixup and CutMix), which typically involve mixing two images, have become the de-facto training techniques for image classification. Despite their huge success in image classification, the number of images to be mixed has not been elucidated in the literature: only the naive K-image expansion has been shown to lead to performance degradation. This study derives a new K-image mixing augmentation based on the stick-breaking process under Dirichlet prior distribution. We demonstrate the superiority of our K-image expansion augmentation over conventional two-image mixing augmentation methods through extensive experiments and analyses: (1) more robust and generalized classifiers; (2) a more desirable loss landscape shape; (3) better adversarial robustness. Moreover, we show that our probabilistic model can measure the sample-wise uncertainty and boost the efficiency for network architecture search by achieving a 7-fold reduction in the search time. Code wil",
    "link": "http://arxiv.org/abs/2110.04248",
    "context": "Title: Observations on K-image Expansion of Image-Mixing Augmentation for Classification. (arXiv:2110.04248v2 [cs.CV] UPDATED)\nAbstract: Image-mixing augmentations (e.g., Mixup and CutMix), which typically involve mixing two images, have become the de-facto training techniques for image classification. Despite their huge success in image classification, the number of images to be mixed has not been elucidated in the literature: only the naive K-image expansion has been shown to lead to performance degradation. This study derives a new K-image mixing augmentation based on the stick-breaking process under Dirichlet prior distribution. We demonstrate the superiority of our K-image expansion augmentation over conventional two-image mixing augmentation methods through extensive experiments and analyses: (1) more robust and generalized classifiers; (2) a more desirable loss landscape shape; (3) better adversarial robustness. Moreover, we show that our probabilistic model can measure the sample-wise uncertainty and boost the efficiency for network architecture search by achieving a 7-fold reduction in the search time. Code wil",
    "path": "papers/21/10/2110.04248.json",
    "total_tokens": 874,
    "translated_title": "论分类问题中图像混合数据增强方法的 K-image 扩展探讨",
    "translated_abstract": "图像混合增强技术（例如 Mixup 和 CutMix）已成为图像分类训练技术的事实标准。然而，目前文献中并未阐明混合图像数目的问题：只有朴素的 K-image 扩展已被证明会导致性能下降。本研究基于狄利克雷先验分布的棍子分拆过程提出了一种新的 K-image 混合增强方法。通过广泛的实验和分析，我们证明了我们的 K-image 扩展增强方法优于传统的双图像混合增强方法：(1) 产生更健壮和广义的分类器；(2) 更优良的损失景观形状；(3) 更好的对抗鲁棒性。此外，我们展示了我们的概率模型可以衡量每个样本的不确定性，并通过实现搜索时间减少了 7 倍，从而提高了网络架构搜索的效率。",
    "tldr": "本文提出一种新的 K-image 混合增强方法，通过基于狄利克雷先验分布的棍子分拆，可以得到更健壮、广义的分类器，并具有更好的对抗鲁棒性。",
    "en_tdlr": "This paper proposes a new K-image mixing augmentation method based on stick-breaking process under Dirichlet prior distribution, which can produce more robust and generalized classifiers with better adversarial robustness."
}