{
    "title": "Don't Knock! Rowhammer at the Backdoor of DNN Models. (arXiv:2110.07683v3 [cs.LG] UPDATED)",
    "abstract": "State-of-the-art deep neural networks (DNNs) have been proven to be vulnerable to adversarial manipulation and backdoor attacks. Backdoored models deviate from expected behavior on inputs with predefined triggers while retaining performance on clean data. Recent works focus on software simulation of backdoor injection during the inference phase by modifying network weights, which we find often unrealistic in practice due to restrictions in hardware.  In contrast, in this work for the first time, we present an end-to-end backdoor injection attack realized on actual hardware on a classifier model using Rowhammer as the fault injection method. To this end, we first investigate the viability of backdoor injection attacks in real-life deployments of DNNs on hardware and address such practical issues in hardware implementation from a novel optimization perspective. We are motivated by the fact that vulnerable memory locations are very rare, device-specific, and sparsely distributed. Conseque",
    "link": "http://arxiv.org/abs/2110.07683",
    "context": "Title: Don't Knock! Rowhammer at the Backdoor of DNN Models. (arXiv:2110.07683v3 [cs.LG] UPDATED)\nAbstract: State-of-the-art deep neural networks (DNNs) have been proven to be vulnerable to adversarial manipulation and backdoor attacks. Backdoored models deviate from expected behavior on inputs with predefined triggers while retaining performance on clean data. Recent works focus on software simulation of backdoor injection during the inference phase by modifying network weights, which we find often unrealistic in practice due to restrictions in hardware.  In contrast, in this work for the first time, we present an end-to-end backdoor injection attack realized on actual hardware on a classifier model using Rowhammer as the fault injection method. To this end, we first investigate the viability of backdoor injection attacks in real-life deployments of DNNs on hardware and address such practical issues in hardware implementation from a novel optimization perspective. We are motivated by the fact that vulnerable memory locations are very rare, device-specific, and sparsely distributed. Conseque",
    "path": "papers/21/10/2110.07683.json",
    "total_tokens": 905,
    "translated_title": "别敲门！Rowhammer攻击进入DNN模型的后门",
    "translated_abstract": "现代深度神经网络（DNN）已被证明容易受到对抗性操纵和后门攻击的影响。后门模型在预先定义的触发器输入的情况下会偏离预期行为，而在干净数据上保持性能。最近的研究集中于在推断阶段通过修改网络权重对后门注入进行软件模拟，然而由于硬件限制，这种方式在实际应用中往往不太现实。与此相反，在本研究中，我们首次提出了一种基于Rowhammer作为故障注入方法的实际硬件上的端到端后门注入攻击方法，用于对分类器模型进行攻击。为此，我们首先研究了在硬件上实际部署DNNs中后门注入攻击的可行性，并从新颖的优化角度解决了这些实际问题。我们的动机在于易受攻击的内存位置非常罕见、特定于设备并且稀疏分布。",
    "tldr": "本研究首次提出了一种基于Rowhammer方法的端到端后门注入攻击方法，可在实际硬件上攻击分类器模型。通过新颖的优化角度解决了硬件实现中的实际问题。",
    "en_tdlr": "This study presents, for the first time, an end-to-end backdoor injection attack realized on actual hardware on a classifier model using Rowhammer as the fault injection method. Practical issues in hardware implementation were addressed from a novel optimization perspective."
}