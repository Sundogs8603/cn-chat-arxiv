{
    "title": "Generating Symbolic Reasoning Problems with Transformer GANs. (arXiv:2110.10054v3 [cs.LG] UPDATED)",
    "abstract": "We study the capabilities of GANs and Wasserstein GANs equipped with Transformer encoders to generate sensible and challenging training data for symbolic reasoning domains. We conduct experiments on two problem domains where Transformers have been successfully applied recently: symbolic mathematics and temporal specifications in verification. Even without autoregression, our GAN models produce syntactically correct instances. We show that the generated data can be used as a substitute for real training data when training a classifier, and, especially, that training data can be generated from a dataset that is too small to be trained on directly. Using a GAN setting also allows us to alter the target distribution: We show that by adding a classifier uncertainty part to the generator objective, we obtain a dataset that is even harder to solve for a temporal logic classifier than our original dataset.",
    "link": "http://arxiv.org/abs/2110.10054",
    "context": "Title: Generating Symbolic Reasoning Problems with Transformer GANs. (arXiv:2110.10054v3 [cs.LG] UPDATED)\nAbstract: We study the capabilities of GANs and Wasserstein GANs equipped with Transformer encoders to generate sensible and challenging training data for symbolic reasoning domains. We conduct experiments on two problem domains where Transformers have been successfully applied recently: symbolic mathematics and temporal specifications in verification. Even without autoregression, our GAN models produce syntactically correct instances. We show that the generated data can be used as a substitute for real training data when training a classifier, and, especially, that training data can be generated from a dataset that is too small to be trained on directly. Using a GAN setting also allows us to alter the target distribution: We show that by adding a classifier uncertainty part to the generator objective, we obtain a dataset that is even harder to solve for a temporal logic classifier than our original dataset.",
    "path": "papers/21/10/2110.10054.json",
    "total_tokens": 775,
    "translated_title": "利用Transformer GAN生成符号推理问题",
    "translated_abstract": "本文研究了使用Transformer编码器的GAN和Wasserstein GAN的能力，在符号推理领域生成有意义且具有挑战性的训练数据。我们在两个问题领域上进行了实验：符号数学和验证中的时间规范。即使没有自回归，我们的GAN模型也会产生语法正确的实例。我们展示了生成的数据可用作分类器训练的替代真实训练数据，并且，尤其是当数据集太小无法直接训练时，可以从数据集中生成训练数据。使用GAN的设置还允许我们修改目标分布：我们展示了通过在生成器目标中添加分类器不确定性部分，我们获得的数据集比原始数据集更难以为一个时间逻辑分类器所解决。",
    "tldr": "本文使用Transformer GAN生成符号推理问题的训练数据，生成的数据可用于替代真实训练数据，并且可用于修改目标分布，达到更好的训练效果。",
    "en_tdlr": "This paper uses Transformer GANs to generate training data for symbolic reasoning problems, which can be used as a substitute for real training data and can be used to modify the target distribution for better training outcomes."
}