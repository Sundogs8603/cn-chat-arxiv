{
    "title": "Simplest Streaming Trees. (arXiv:2110.08483v6 [cs.LG] UPDATED)",
    "abstract": "Decision forests, including random forests and gradient boosting trees, remain the leading machine learning methods for many real-world data problems, especially on tabular data. However, most of the current implementations only operate in batch mode, and therefore cannot incrementally update when more data arrive. Several previous works developed streaming trees and ensembles to overcome this limitation. Nonetheless, we found that those state-of-the-art algorithms suffer from a number of drawbacks, including low accuracy on some problems and high memory usage on others. We therefore developed the simplest possible extension of decision trees: given new data, simply update existing trees by continuing to grow them, and replace some old trees with new ones to control the total number of trees. In a benchmark suite containing 72 classification problems (the OpenML-CC18 data suite), we illustrate that our approach, Stream Decision Forest (SDF), does not suffer from either of the aforement",
    "link": "http://arxiv.org/abs/2110.08483",
    "context": "Title: Simplest Streaming Trees. (arXiv:2110.08483v6 [cs.LG] UPDATED)\nAbstract: Decision forests, including random forests and gradient boosting trees, remain the leading machine learning methods for many real-world data problems, especially on tabular data. However, most of the current implementations only operate in batch mode, and therefore cannot incrementally update when more data arrive. Several previous works developed streaming trees and ensembles to overcome this limitation. Nonetheless, we found that those state-of-the-art algorithms suffer from a number of drawbacks, including low accuracy on some problems and high memory usage on others. We therefore developed the simplest possible extension of decision trees: given new data, simply update existing trees by continuing to grow them, and replace some old trees with new ones to control the total number of trees. In a benchmark suite containing 72 classification problems (the OpenML-CC18 data suite), we illustrate that our approach, Stream Decision Forest (SDF), does not suffer from either of the aforement",
    "path": "papers/21/10/2110.08483.json",
    "total_tokens": 889,
    "translated_title": "最简易的流式决策树",
    "translated_abstract": "决策森林，包括随机森林和梯度提升树，在许多实际数据问题上仍然是主流的机器学习方法，特别是在表格数据上。然而，大部分当前的实现只能以批处理模式运行，因此不能在有更多数据到达时进行增量更新。之前有几项工作开发了流式决策树和集成来克服这个限制。然而，我们发现这些最新算法存在一些问题，包括在某些问题上精度低和在其他问题上内存使用量大。因此，我们开发了最简单的决策树扩展：给定新数据时，通过继续生长现有树来更新它们，并用新树替换一些旧树来控制总树的数量。在包含72个分类问题的基准套件（OpenML-CC18数据套件）中，我们证明了我们的方法Stream Decision Forest（SDF）既不遭受上述问题的困扰",
    "tldr": "我们提出了最简单的决策树扩展，通过继续生长现有树来更新它们，并用新树替换一些旧树来控制总树的数量。在72个分类问题的基准套件中，我们的方法在精度和内存使用方面表现优异。"
}