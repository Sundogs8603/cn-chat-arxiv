{
    "title": "Combining Differential Privacy and Byzantine Resilience in Distributed SGD. (arXiv:2110.03991v4 [cs.LG] UPDATED)",
    "abstract": "Privacy and Byzantine resilience (BR) are two crucial requirements of modern-day distributed machine learning. The two concepts have been extensively studied individually but the question of how to combine them effectively remains unanswered. This paper contributes to addressing this question by studying the extent to which the distributed SGD algorithm, in the standard parameter-server architecture, can learn an accurate model despite (a) a fraction of the workers being malicious (Byzantine), and (b) the other fraction, whilst being honest, providing noisy information to the server to ensure differential privacy (DP). We first observe that the integration of standard practices in DP and BR is not straightforward. In fact, we show that many existing results on the convergence of distributed SGD under Byzantine faults, especially those relying on $(\\alpha,f)$-Byzantine resilience, are rendered invalid when honest workers enforce DP. To circumvent this shortcoming, we revisit the theory ",
    "link": "http://arxiv.org/abs/2110.03991",
    "context": "Title: Combining Differential Privacy and Byzantine Resilience in Distributed SGD. (arXiv:2110.03991v4 [cs.LG] UPDATED)\nAbstract: Privacy and Byzantine resilience (BR) are two crucial requirements of modern-day distributed machine learning. The two concepts have been extensively studied individually but the question of how to combine them effectively remains unanswered. This paper contributes to addressing this question by studying the extent to which the distributed SGD algorithm, in the standard parameter-server architecture, can learn an accurate model despite (a) a fraction of the workers being malicious (Byzantine), and (b) the other fraction, whilst being honest, providing noisy information to the server to ensure differential privacy (DP). We first observe that the integration of standard practices in DP and BR is not straightforward. In fact, we show that many existing results on the convergence of distributed SGD under Byzantine faults, especially those relying on $(\\alpha,f)$-Byzantine resilience, are rendered invalid when honest workers enforce DP. To circumvent this shortcoming, we revisit the theory ",
    "path": "papers/21/10/2110.03991.json",
    "total_tokens": 880,
    "translated_title": "在分布式SGD中结合差分隐私和拜占庭弹性",
    "translated_abstract": "隐私和拜占庭弹性（BR）是现代分布式机器学习的两个关键要求。这两个概念在过去已经被广泛研究，但如何有效地将它们结合起来的问题仍然没有答案。本文通过研究在标准参数服务器架构中，分布式SGD算法在存在恶意（拜占庭）工作者的情况下，以及其他诚实工作者提供噪声信息以确保差分隐私的情况下，能够学习准确模型的程度来回答这个问题。我们首先观察到标准差分隐私和拜占庭弹性实践的整合并不简单。实际上，我们发现许多现有的关于分布式SGD收敛性的结果，在诚实工作者实施差分隐私时无效，特别是那些依赖于$(\\alpha,f)$-拜占庭弹性的结果。为了克服这个缺点，我们重新审视了理论.",
    "tldr": "本文研究了在分布式机器学习中将差分隐私和拜占庭弹性结合起来的问题，并发现现有的方法在差分隐私的约束下无效。"
}