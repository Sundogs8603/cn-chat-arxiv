{
    "title": "Robustness of Graph Neural Networks at Scale. (arXiv:2110.14038v4 [cs.LG] UPDATED)",
    "abstract": "Graph Neural Networks (GNNs) are increasingly important given their popularity and the diversity of applications. Yet, existing studies of their vulnerability to adversarial attacks rely on relatively small graphs. We address this gap and study how to attack and defend GNNs at scale. We propose two sparsity-aware first-order optimization attacks that maintain an efficient representation despite optimizing over a number of parameters which is quadratic in the number of nodes. We show that common surrogate losses are not well-suited for global attacks on GNNs. Our alternatives can double the attack strength. Moreover, to improve GNNs' reliability we design a robust aggregation function, Soft Median, resulting in an effective defense at all scales. We evaluate our attacks and defense with standard GNNs on graphs more than 100 times larger compared to previous work. We even scale one order of magnitude further by extending our techniques to a scalable GNN.",
    "link": "http://arxiv.org/abs/2110.14038",
    "context": "Title: Robustness of Graph Neural Networks at Scale. (arXiv:2110.14038v4 [cs.LG] UPDATED)\nAbstract: Graph Neural Networks (GNNs) are increasingly important given their popularity and the diversity of applications. Yet, existing studies of their vulnerability to adversarial attacks rely on relatively small graphs. We address this gap and study how to attack and defend GNNs at scale. We propose two sparsity-aware first-order optimization attacks that maintain an efficient representation despite optimizing over a number of parameters which is quadratic in the number of nodes. We show that common surrogate losses are not well-suited for global attacks on GNNs. Our alternatives can double the attack strength. Moreover, to improve GNNs' reliability we design a robust aggregation function, Soft Median, resulting in an effective defense at all scales. We evaluate our attacks and defense with standard GNNs on graphs more than 100 times larger compared to previous work. We even scale one order of magnitude further by extending our techniques to a scalable GNN.",
    "path": "papers/21/10/2110.14038.json",
    "total_tokens": 933,
    "translated_title": "规模下图神经网络的鲁棒性",
    "translated_abstract": "图神经网络（GNNs）由于其广泛的应用和受欢迎程度而变得越来越重要。然而，针对对抗攻击的现有研究只依赖于相对较小的图形。本文填补了这一空白，研究了如何在规模下攻击和防御GNNs。我们提出了两种稀疏感知的一阶优化攻击，尽管优化参数数量与节点数量二次关联，但仍保持高效的表示。我们发现公共代理损失不适合用于全局攻击GNNs，而我们的替代方案可以将攻击力翻倍。此外，为了提高GNNs的可靠性，我们设计了一个鲁棒性聚合函数，Soft Median，得到了在所有规模下的有效防御。我们以标准GNNs为基础，对比以前的研究，评估了我们的攻击和防御方法在100倍以上的图形上的效果。我们甚至通过将我们的技术扩展到可扩展的GNN，将规模进一步扩展了一个数量级。",
    "tldr": "本文研究了规模下如何攻击和防御图神经网络（GNNs），提出了稀疏感知的一阶优化攻击和鲁棒性聚合函数Soft Median，有效提高了GNNs的可靠性和攻击力。",
    "en_tdlr": "This paper studies how to attack and defend Graph Neural Networks (GNNs) at scale, proposes sparsity-aware first-order optimization attacks and a robust aggregation function Soft Median, and shows significant improvement in GNNs' reliability and attack strength."
}