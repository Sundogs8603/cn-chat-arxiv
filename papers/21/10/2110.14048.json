{
    "title": "Conflict-Averse Gradient Descent for Multi-task Learning",
    "abstract": "arXiv:2110.14048v2 Announce Type: replace-cross  Abstract: The goal of multi-task learning is to enable more efficient learning than single task learning by sharing model structures for a diverse set of tasks. A standard multi-task learning objective is to minimize the average loss across all tasks. While straightforward, using this objective often results in much worse final performance for each task than learning them independently. A major challenge in optimizing a multi-task model is the conflicting gradients, where gradients of different task objectives are not well aligned so that following the average gradient direction can be detrimental to specific tasks' performance. Previous work has proposed several heuristics to manipulate the task gradients for mitigating this problem. But most of them lack convergence guarantee and/or could converge to any Pareto-stationary point. In this paper, we introduce Conflict-Averse Gradient descent (CAGrad) which minimizes the average loss funct",
    "link": "https://arxiv.org/abs/2110.14048",
    "context": "Title: Conflict-Averse Gradient Descent for Multi-task Learning\nAbstract: arXiv:2110.14048v2 Announce Type: replace-cross  Abstract: The goal of multi-task learning is to enable more efficient learning than single task learning by sharing model structures for a diverse set of tasks. A standard multi-task learning objective is to minimize the average loss across all tasks. While straightforward, using this objective often results in much worse final performance for each task than learning them independently. A major challenge in optimizing a multi-task model is the conflicting gradients, where gradients of different task objectives are not well aligned so that following the average gradient direction can be detrimental to specific tasks' performance. Previous work has proposed several heuristics to manipulate the task gradients for mitigating this problem. But most of them lack convergence guarantee and/or could converge to any Pareto-stationary point. In this paper, we introduce Conflict-Averse Gradient descent (CAGrad) which minimizes the average loss funct",
    "path": "papers/21/10/2110.14048.json",
    "total_tokens": 863,
    "translated_title": "冲突回避梯度下降用于多任务学习",
    "translated_abstract": "多任务学习的目标是通过共享模型结构来实现比单任务学习更高效的学习，以适应各种任务。标准的多任务学习目标是最小化所有任务的平均损失。然而，使用这个目标通常会导致每个任务的最终表现比独立学习它们时更差。在优化多任务模型中的一个主要挑战是冲突梯度，即不同任务目标的梯度不太一致，因此遵循平均梯度方向可能对特定任务的性能有害。先前的研究提出了几种启发式方法来操纵任务梯度以缓解这个问题。但是大多数方法缺乏收敛保证和/或可能收敛到任何帕累托稳定点。在本文中，我们介绍了一种叫做冲突回避梯度下降（CAGrad）的方法，通过最小化平均损失函数",
    "tldr": "冲突回避梯度下降（CAGrad）是针对多任务学习中梯度冲突问题提出的方法，旨在解决不同任务梯度不一致导致的性能下降挑战。",
    "en_tdlr": "Conflict-Averse Gradient descent (CAGrad) is proposed to address the issue of conflicting gradients in multi-task learning, aiming to overcome the performance degradation caused by inconsistent gradients from different tasks."
}