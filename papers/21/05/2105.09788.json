{
    "title": "Distributed Adaptive Nearest Neighbor Classifier: Algorithm and Theory. (arXiv:2105.09788v2 [stat.ML] UPDATED)",
    "abstract": "When data is of an extraordinarily large size or physically stored in different locations, the distributed nearest neighbor (NN) classifier is an attractive tool for classification. We propose a novel distributed adaptive NN classifier for which the number of nearest neighbors is a tuning parameter stochastically chosen by a data-driven criterion. An early stopping rule is proposed when searching for the optimal tuning parameter, which not only speeds up the computation but also improves the finite sample performance of the proposed Algorithm. Convergence rate of excess risk of the distributed adaptive NN classifier is investigated under various sub-sample size compositions. In particular, we show that when the sub-sample sizes are sufficiently large, the proposed classifier achieves the nearly optimal convergence rate. Effectiveness of the proposed approach is demonstrated through simulation studies as well as an empirical application to a real-world dataset.",
    "link": "http://arxiv.org/abs/2105.09788",
    "context": "Title: Distributed Adaptive Nearest Neighbor Classifier: Algorithm and Theory. (arXiv:2105.09788v2 [stat.ML] UPDATED)\nAbstract: When data is of an extraordinarily large size or physically stored in different locations, the distributed nearest neighbor (NN) classifier is an attractive tool for classification. We propose a novel distributed adaptive NN classifier for which the number of nearest neighbors is a tuning parameter stochastically chosen by a data-driven criterion. An early stopping rule is proposed when searching for the optimal tuning parameter, which not only speeds up the computation but also improves the finite sample performance of the proposed Algorithm. Convergence rate of excess risk of the distributed adaptive NN classifier is investigated under various sub-sample size compositions. In particular, we show that when the sub-sample sizes are sufficiently large, the proposed classifier achieves the nearly optimal convergence rate. Effectiveness of the proposed approach is demonstrated through simulation studies as well as an empirical application to a real-world dataset.",
    "path": "papers/21/05/2105.09788.json",
    "total_tokens": 896,
    "translated_title": "分布式自适应最近邻分类器：算法和理论",
    "translated_abstract": "当数据规模异常庞大或分布在不同的位置上时，分布式最近邻（NN）分类器是一种吸引人的分类工具。我们提出了一种新颖的分布式自适应NN分类器，其中最近邻数是由数据驱动准则随机选择的调优参数。在寻找最优调优参数时提出了一种早期停止规则，这不仅加快了计算速度，还改善了所提算法的有限样本性能。在各种子样本大小组合下，研究了分布式自适应NN分类器的超额风险收敛速度。特别地，我们证明了当子样本大小足够大时，所提分类器实现了近乎最优的收敛速度。通过模拟研究和对真实世界数据集的实证应用，证明了所提方法的有效性。",
    "tldr": "提出一种新颖的分布式自适应NN分类器，通过随机选择数据驱动准则来调优最近邻数，提出了早期停止规则，实现了加速计算和改善有限样本性能。通过研究证明，当子样本大小足够大时，分类器实现了近乎最优的收敛速度。有效性已通过模拟和实证应用得到验证。",
    "en_tdlr": "The paper proposes a novel distributed adaptive NN classifier, which uses a data-driven criterion to stochastically choose the number of nearest neighbors and introduces an early stopping rule to improve computation speed and finite sample performance. The convergence rate of excess risk for various sub-sample size compositions is investigated, and the effectiveness is demonstrated through simulation studies and an empirical application to a real-world dataset."
}