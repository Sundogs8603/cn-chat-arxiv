{
    "title": "Can We Faithfully Represent Masked States to Compute Shapley Values on a DNN?. (arXiv:2105.10719v4 [cs.LG] UPDATED)",
    "abstract": "Masking some input variables of a deep neural network (DNN) and computing output changes on the masked input sample represent a typical way to compute attributions of input variables in the sample. People usually mask an input variable using its baseline value. However, there is no theory to examine whether baseline value faithfully represents the absence of an input variable, \\emph{i.e.,} removing all signals from the input variable. Fortunately, recent studies show that the inference score of a DNN can be strictly disentangled into a set of causal patterns (or concepts) encoded by the DNN. Therefore, we propose to use causal patterns to examine the faithfulness of baseline values. More crucially, it is proven that causal patterns can be explained as the elementary rationale of the Shapley value. Furthermore, we propose a method to learn optimal baseline values, and experimental results have demonstrated its effectiveness.",
    "link": "http://arxiv.org/abs/2105.10719",
    "context": "Title: Can We Faithfully Represent Masked States to Compute Shapley Values on a DNN?. (arXiv:2105.10719v4 [cs.LG] UPDATED)\nAbstract: Masking some input variables of a deep neural network (DNN) and computing output changes on the masked input sample represent a typical way to compute attributions of input variables in the sample. People usually mask an input variable using its baseline value. However, there is no theory to examine whether baseline value faithfully represents the absence of an input variable, \\emph{i.e.,} removing all signals from the input variable. Fortunately, recent studies show that the inference score of a DNN can be strictly disentangled into a set of causal patterns (or concepts) encoded by the DNN. Therefore, we propose to use causal patterns to examine the faithfulness of baseline values. More crucially, it is proven that causal patterns can be explained as the elementary rationale of the Shapley value. Furthermore, we propose a method to learn optimal baseline values, and experimental results have demonstrated its effectiveness.",
    "path": "papers/21/05/2105.10719.json",
    "total_tokens": 849,
    "translated_title": "我们是否能够准确地表示掩码状态以计算DNN的Shapley值?",
    "translated_abstract": "在深度神经网络（DNN）中掩盖一些输入变量，并计算掩盖后的输入样本的输出变化，是计算样本输入变量属性的典型方法。人们通常使用基准值来屏蔽输入变量。然而，没有理论来验证基准值是否准确地代表了输入变量缺失的情况，即去除了输入变量的所有信号。幸运的是，最近的研究表明，DNN的推理得分可以严格地分解为DNN编码的一组因果模式（或概念）。因此，我们建议使用因果模式来检查基准值的准确性。更为重要的是，已经证明因果模式可以解释为Shapley值的基本理由。此外，我们提出了一种学习最优基准值的方法，并且实验结果证明了它的有效性。",
    "tldr": "本文提出了一种新的方法，使用因果模式来检查输入变量基准值的准确性，并使用这种方法计算Shapley值，同时提出了一种学习最优基准值的方法，并证明了其有效性。",
    "en_tdlr": "This paper proposes a new method to examine the accuracy of baseline values for input variables using causal patterns, and computes Shapley values using this method. Additionally, the paper presents a method to learn the optimal baseline values and demonstrates its effectiveness."
}