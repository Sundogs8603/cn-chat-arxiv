{
    "title": "Paying Attention to Astronomical Transients: Introducing the Time-series Transformer for Photometric Classification. (arXiv:2105.06178v3 [astro-ph.IM] UPDATED)",
    "abstract": "Future surveys such as the Legacy Survey of Space and Time (LSST) of the Vera C. Rubin Observatory will observe an order of magnitude more astrophysical transient events than any previous survey before. With this deluge of photometric data, it will be impossible for all such events to be classified by humans alone. Recent efforts have sought to leverage machine learning methods to tackle the challenge of astronomical transient classification, with ever improving success. Transformers are a recently developed deep learning architecture, first proposed for natural language processing, that have shown a great deal of recent success. In this work we develop a new transformer architecture, which uses multi-head self attention at its core, for general multi-variate time-series data. Furthermore, the proposed time-series transformer architecture supports the inclusion of an arbitrary number of additional features, while also offering interpretability. We apply the time-series transformer to t",
    "link": "http://arxiv.org/abs/2105.06178",
    "context": "Title: Paying Attention to Astronomical Transients: Introducing the Time-series Transformer for Photometric Classification. (arXiv:2105.06178v3 [astro-ph.IM] UPDATED)\nAbstract: Future surveys such as the Legacy Survey of Space and Time (LSST) of the Vera C. Rubin Observatory will observe an order of magnitude more astrophysical transient events than any previous survey before. With this deluge of photometric data, it will be impossible for all such events to be classified by humans alone. Recent efforts have sought to leverage machine learning methods to tackle the challenge of astronomical transient classification, with ever improving success. Transformers are a recently developed deep learning architecture, first proposed for natural language processing, that have shown a great deal of recent success. In this work we develop a new transformer architecture, which uses multi-head self attention at its core, for general multi-variate time-series data. Furthermore, the proposed time-series transformer architecture supports the inclusion of an arbitrary number of additional features, while also offering interpretability. We apply the time-series transformer to t",
    "path": "papers/21/05/2105.06178.json",
    "total_tokens": 944,
    "translated_title": "关注天体暂变现象：介绍基于时间序列变换器的光度分类方法",
    "translated_abstract": "未来的勘测项目，如鲁宾天文台的遗产空间与时间勘测(LSST)，将观测到比以往任何一项勘测都多一个数量级的天体暂变事件。在这种大量的光度数据中，单靠人类无法对所有这些事件进行分类。近期的研究致力于利用机器学习方法解决天体暂变分类的挑战，并取得了不断提升的成功。变换器是一种最近发展起来的深度学习架构，最初用于自然语言处理，并且最近取得了很大的成功。本研究开发了一种新的变换器架构，其核心是多头自注意力机制，适用于一般的多变量时间序列数据。此外，所提出的时间序列变换器架构支持导入任意数量的附加特征，并提供可解释性。我们将时间序列变换器应用于光度分类，并展示了其在多个数据集上的显著性能。",
    "tldr": "本研究介绍了一种基于时间序列变换器的光度分类方法，用于处理未来大规模的天体暂变数据。这种变换器架构支持多变量时间序列数据，并可灵活添加附加特征，同时还提供了可解释性。在多个数据集上的实验证明了其显著性能。",
    "en_tdlr": "This paper introduces a photometric classification method using the time-series transformer architecture, which is capable of handling large-scale astronomical transient data. The proposed transformer architecture supports multi-variate time-series data and allows the inclusion of additional features, providing interpretability. Experimental results on multiple datasets demonstrate its significant performance improvement."
}