{
    "title": "Diffusion Mechanism in Residual Neural Network: Theory and Applications. (arXiv:2105.03155v5 [cs.LG] UPDATED)",
    "abstract": "Diffusion, a fundamental internal mechanism emerging in many physical processes, describes the interaction among different objects. In many learning tasks with limited training samples, the diffusion connects the labeled and unlabeled data points and is a critical component for achieving high classification accuracy. Many existing deep learning approaches directly impose the fusion loss when training neural networks. In this work, inspired by the convection-diffusion ordinary differential equations (ODEs), we propose a novel diffusion residual network (Diff-ResNet), internally introduces diffusion into the architectures of neural networks. Under the structured data assumption, it is proved that the proposed diffusion block can increase the distance-diameter ratio that improves the separability of inter-class points and reduces the distance among local intra-class points. Moreover, this property can be easily adopted by the residual networks for constructing the separable hyperplanes. E",
    "link": "http://arxiv.org/abs/2105.03155",
    "context": "Title: Diffusion Mechanism in Residual Neural Network: Theory and Applications. (arXiv:2105.03155v5 [cs.LG] UPDATED)\nAbstract: Diffusion, a fundamental internal mechanism emerging in many physical processes, describes the interaction among different objects. In many learning tasks with limited training samples, the diffusion connects the labeled and unlabeled data points and is a critical component for achieving high classification accuracy. Many existing deep learning approaches directly impose the fusion loss when training neural networks. In this work, inspired by the convection-diffusion ordinary differential equations (ODEs), we propose a novel diffusion residual network (Diff-ResNet), internally introduces diffusion into the architectures of neural networks. Under the structured data assumption, it is proved that the proposed diffusion block can increase the distance-diameter ratio that improves the separability of inter-class points and reduces the distance among local intra-class points. Moreover, this property can be easily adopted by the residual networks for constructing the separable hyperplanes. E",
    "path": "papers/21/05/2105.03155.json",
    "total_tokens": 892,
    "translated_title": "残差神经网络中的扩散机制：理论与应用",
    "translated_abstract": "扩散是许多物理过程中出现的基本内部机制，描述了不同对象之间的相互作用。在许多具有有限训练样本的学习任务中，扩散连接了标记和未标记的数据点，是实现高分类精度的关键组成部分。许多现有的深度学习方法在训练神经网络时直接施加融合损失。在本文中，受对流-扩散常微分方程的启发，我们提出了一种新颖的扩散残差网络（Diff-ResNet），内部将扩散引入神经网络的架构中。在假定具有结构化数据的情况下，证明了所提出的扩散块可以增加距离直径比，从而改善了类间点的可分性并减少了局部类内点之间的距离。此外，这种性质可以被残差网络轻松采用以构建可分离的超平面。",
    "tldr": "本文提出了一种扩散残差网络，该网络在神经网络架构中内部引入了扩散机制，能够提高数据点之间的距离直径比，从而提高了类间点的可分性，减少了类内点之间的距离。",
    "en_tdlr": "This paper proposes a diffusion residual network that introduces diffusion mechanism internally into the neural network architecture, which can increase the distance-diameter ratio among data points and improve the separability of inter-class points while reducing the distance among local intra-class points."
}