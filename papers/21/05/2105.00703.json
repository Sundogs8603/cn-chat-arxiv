{
    "title": "Causality-based Counterfactual Explanation for Classification Models. (arXiv:2105.00703v3 [cs.LG] UPDATED)",
    "abstract": "Counterfactual explanation is one branch of interpretable machine learning that produces a perturbation sample to change the model's original decision. The generated samples can act as a recommendation for end-users to achieve their desired outputs. Most of the current counterfactual explanation approaches are the gradient-based method, which can only optimize the differentiable loss functions with continuous variables. Accordingly, the gradient-free methods are proposed to handle the categorical variables, which however have several major limitations: 1) causal relationships among features are typically ignored when generating the counterfactuals, possibly resulting in impractical guidelines for decision-makers; 2) the counterfactual explanation algorithm requires a great deal of effort into parameter tuning for dertermining the optimal weight for each loss functions which must be conducted repeatedly for different datasets and settings. In this work, to address the above limitations,",
    "link": "http://arxiv.org/abs/2105.00703",
    "context": "Title: Causality-based Counterfactual Explanation for Classification Models. (arXiv:2105.00703v3 [cs.LG] UPDATED)\nAbstract: Counterfactual explanation is one branch of interpretable machine learning that produces a perturbation sample to change the model's original decision. The generated samples can act as a recommendation for end-users to achieve their desired outputs. Most of the current counterfactual explanation approaches are the gradient-based method, which can only optimize the differentiable loss functions with continuous variables. Accordingly, the gradient-free methods are proposed to handle the categorical variables, which however have several major limitations: 1) causal relationships among features are typically ignored when generating the counterfactuals, possibly resulting in impractical guidelines for decision-makers; 2) the counterfactual explanation algorithm requires a great deal of effort into parameter tuning for dertermining the optimal weight for each loss functions which must be conducted repeatedly for different datasets and settings. In this work, to address the above limitations,",
    "path": "papers/21/05/2105.00703.json",
    "total_tokens": 1031,
    "translated_title": "基于因果关系的分类模型反事实解释方法",
    "translated_abstract": "反事实解释是可解释机器学习的一个分支，它产生扰动样本以改变模型的原始决策。生成的样本可以作为建议，帮助最终用户实现他们所需的结果。大多数当前反事实解释方法是基于梯度的方法，只能优化连续变量的可微损失函数。据此，基于梯度的方法无法处理分类变量，因此提出了基于梯度的方法来解决这个问题。然而，这些方法存在几个主要限制：1）生成反事实时通常忽略特征之间的因果关系，可能导致对决策者的指导不切实际。2）反事实解释算法需要大量的参数调整，以确定每个损失函数的最优权重，这必须为不同的数据集和设置重复进行。本文提出了一种基于因果关系的反事实解释方法，以解决上述限制。该方法考虑特征之间的因果关系，处理连续和分类变量，无需任何用户指定的超参数。对不同数据集进行的实验结果表明，与其他最先进的方法相比，所提出的方法在模型准确性和生成的反事实样本质量方面表现出更好的性能。",
    "tldr": "本论文提出了一种基于因果关系的反事实解释方法，可同时处理连续和分类变量，生成的样本具有实用性指导意义，在实验中表现出更好的性能。",
    "en_tdlr": "This paper proposes a causality-based counterfactual explanation approach that can handle both continuous and categorical variables, and takes into account the causal relationships among features. Experimental results demonstrate that the proposed method generates more practical and effective counterfactual samples, and outperforms other state-of-the-art approaches in both model's accuracy and quality of generated samples."
}