{
    "title": "Regret-Optimal LQR Control. (arXiv:2105.01244v2 [math.OC] UPDATED)",
    "abstract": "We consider the infinite-horizon LQR control problem. Motivated by competitive analysis in online learning, as a criterion for controller design we introduce the dynamic regret, defined as the difference between the LQR cost of a causal controller (that has only access to past disturbances) and the LQR cost of the \\emph{unique} clairvoyant one (that has also access to future disturbances) that is known to dominate all other controllers. The regret itself is a function of the disturbances, and we propose to find a causal controller that minimizes the worst-case regret over all bounded energy disturbances. The resulting controller has the interpretation of guaranteeing the smallest regret compared to the best non-causal controller that can see the future. We derive explicit formulas for the optimal regret and for the regret-optimal controller for the state-space setting. These explicit solutions are obtained by showing that the regret-optimal control problem can be reduced to a Nehari ex",
    "link": "http://arxiv.org/abs/2105.01244",
    "context": "Title: Regret-Optimal LQR Control. (arXiv:2105.01244v2 [math.OC] UPDATED)\nAbstract: We consider the infinite-horizon LQR control problem. Motivated by competitive analysis in online learning, as a criterion for controller design we introduce the dynamic regret, defined as the difference between the LQR cost of a causal controller (that has only access to past disturbances) and the LQR cost of the \\emph{unique} clairvoyant one (that has also access to future disturbances) that is known to dominate all other controllers. The regret itself is a function of the disturbances, and we propose to find a causal controller that minimizes the worst-case regret over all bounded energy disturbances. The resulting controller has the interpretation of guaranteeing the smallest regret compared to the best non-causal controller that can see the future. We derive explicit formulas for the optimal regret and for the regret-optimal controller for the state-space setting. These explicit solutions are obtained by showing that the regret-optimal control problem can be reduced to a Nehari ex",
    "path": "papers/21/05/2105.01244.json",
    "total_tokens": 892,
    "translated_title": "后悔最小LQR控制",
    "translated_abstract": "本文考虑了无限时间LQR控制问题。受在线学习竞争分析的启发，我们引入动态后悔作为控制器设计的标准。动态后悔是指因果控制器（仅具有过去干扰的访问权限）的LQR成本与已知优于其他所有控制器的唯一预知控制器（也具有未来干扰的访问权限）的LQR成本之间的差异。后悔本身是干扰的函数，我们建议找到一个能够最小化所有有界能量干扰下的最坏情况下后悔的因果控制器。得到的控制器的解释是，与能够看到未来的最佳非因果控制器相比，保证了最小的后悔。我们推导出状态空间设置的最优后悔和后悔最优控制器的显式公式。通过证明后悔最优控制问题可以归约为Nehari指数问题，得到了这些显式解。",
    "tldr": "本文提出了一种动态后悔，通过在所有有界干扰下找到最小化最坏情况下后悔的因果控制器，实现了后悔最小LQR控制。",
    "en_tdlr": "This paper proposes a regret-optimal LQR control method, which introduces dynamic regret and finds a causal controller that minimizes the worst-case regret over all bounded energy disturbances. Explicit formulas for the optimal regret and for the regret-optimal controller are derived for the state-space setting."
}