{
    "title": "Attention for Image Registration (AiR): an unsupervised Transformer approach. (arXiv:2105.02282v2 [cs.CV] UPDATED)",
    "abstract": "Image registration is a crucial task in signal processing, but it often encounters issues with stability and efficiency. Non-learning registration approaches rely on optimizing similarity metrics between fixed and moving images, which can be expensive in terms of time and space complexity. This problem can be exacerbated when the images are large or there are significant deformations between them. Recently, deep learning, specifically convolutional neural network (CNN)-based methods, have been explored as an effective solution to the weaknesses of non-learning approaches. To further advance learning approaches in image registration, we introduce an attention mechanism in the deformable image registration problem. Our proposed approach is based on a Transformer framework called AiR, which can be efficiently trained on GPGPU devices. We treat the image registration problem as a language translation task and use the Transformer to learn the deformation field. The method learns an unsuperv",
    "link": "http://arxiv.org/abs/2105.02282",
    "context": "Title: Attention for Image Registration (AiR): an unsupervised Transformer approach. (arXiv:2105.02282v2 [cs.CV] UPDATED)\nAbstract: Image registration is a crucial task in signal processing, but it often encounters issues with stability and efficiency. Non-learning registration approaches rely on optimizing similarity metrics between fixed and moving images, which can be expensive in terms of time and space complexity. This problem can be exacerbated when the images are large or there are significant deformations between them. Recently, deep learning, specifically convolutional neural network (CNN)-based methods, have been explored as an effective solution to the weaknesses of non-learning approaches. To further advance learning approaches in image registration, we introduce an attention mechanism in the deformable image registration problem. Our proposed approach is based on a Transformer framework called AiR, which can be efficiently trained on GPGPU devices. We treat the image registration problem as a language translation task and use the Transformer to learn the deformation field. The method learns an unsuperv",
    "path": "papers/21/05/2105.02282.json",
    "total_tokens": 992,
    "translated_title": "图像配准中的注意力机制（AiR）：一种无监督的Transformer方法",
    "translated_abstract": "图像配准是信号处理中的一项关键任务，但它经常遇到稳定性和效率问题。非学习配准方法依赖于优化固定图像和移动图像之间的相似度指标，这可能在时间和空间复杂度方面变得昂贵。当图像较大或它们之间存在明显的形变时，这个问题可能会加剧。最近，深度学习，特别是基于卷积神经网络（CNN）的方法，被探索作为非学习方法弱点的有效解决方案。为了进一步推进图像配准中的学习方法，我们在可变形图像配准问题中引入了注意力机制。我们提出的方法基于一种Transformer框架称为AiR，可以在GPGPU设备上高效训练。我们将图像配准问题视为语言翻译任务，并使用Transformer学习变形场。该方法学习了一种无监督的配准方法，无需标记数据或地面真实形变场。我们在各种数据集上进行实验，并展示了我们的方法在精度和效率方面优于现有的最先进方法。",
    "tldr": "这篇论文提出了一种新颖的图像配准方法，名为AiR，它利用Transformer框架和注意力机制来学习变形场，无需标记数据或地面真实形变场。实验结果表明，该方法在精度和效率方面优于现有的最先进方法。"
}