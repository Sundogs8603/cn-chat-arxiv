{
    "title": "Multi-layer Perceptron Trainability Explained via Variability. (arXiv:2105.08911v3 [cs.LG] UPDATED)",
    "abstract": "Despite the tremendous successes of deep neural networks (DNNs) in various applications, many fundamental aspects of deep learning remain incompletely understood, including DNN trainability. In a trainability study, one aims to discern what makes one DNN model easier to train than another under comparable conditions. In particular, our study focuses on multi-layer perceptron (MLP) models equipped with the same number of parameters. We introduce a new notion called variability to help explain the benefits of deep learning and the difficulties in training very deep MLPs. Simply put, variability of a neural network represents the richness of landscape patterns in the data space with respect to well-scaled random weights. We empirically show that variability is positively correlated to the number of activations and negatively correlated to a phenomenon called \"Collapse to Constant\", which is related but not identical to the well-known vanishing gradient phenomenon. Experiments on a small s",
    "link": "http://arxiv.org/abs/2105.08911",
    "context": "Title: Multi-layer Perceptron Trainability Explained via Variability. (arXiv:2105.08911v3 [cs.LG] UPDATED)\nAbstract: Despite the tremendous successes of deep neural networks (DNNs) in various applications, many fundamental aspects of deep learning remain incompletely understood, including DNN trainability. In a trainability study, one aims to discern what makes one DNN model easier to train than another under comparable conditions. In particular, our study focuses on multi-layer perceptron (MLP) models equipped with the same number of parameters. We introduce a new notion called variability to help explain the benefits of deep learning and the difficulties in training very deep MLPs. Simply put, variability of a neural network represents the richness of landscape patterns in the data space with respect to well-scaled random weights. We empirically show that variability is positively correlated to the number of activations and negatively correlated to a phenomenon called \"Collapse to Constant\", which is related but not identical to the well-known vanishing gradient phenomenon. Experiments on a small s",
    "path": "papers/21/05/2105.08911.json",
    "total_tokens": 996,
    "translated_title": "通过变异性解释多层感知器的可训练性",
    "translated_abstract": "尽管深度神经网络在各种应用中取得了巨大的成功，但深度学习的许多基本方面仍未完全理解，包括DNN的可训练性。本研究旨在辨别在相似条件下，什么使一个DNN模型比另一个更容易训练。特别地，我们的研究集中在带有相同参数数量的多层感知器 (MLP) 模型上。我们引入了一个新概念 - 变异性，以帮助解释深度学习的好处以及在训练非常深的 MLP 时所遇到的困难。简单地说，神经网络的变异性代表了数据空间中与良好缩放的随机权重相关的地形模式的丰富性。我们从实证上证明，变异性与激活数量呈正相关，与\"坍塌到常数\"现象呈负相关，后者与众所周知的梯度消失现象相关但并不完全相同。在一个小规模的数据集上的实验证明，变异性是 MLP 可训练性的一个准确预测指标。",
    "tldr": "本研究旨在解释多层感知器的可训练性，引入了一个新概念 - 变异性，与 MLP 的激活数量呈正相关，与\"坍塌到常数\"现象呈负相关，是 MLP 可训练性的一个准确预测指标。",
    "en_tdlr": "This study introduces a new concept of variability to explain the trainability of multi-layer perceptrons (MLPs). It shows that variability is positively correlated with the number of activations and negatively correlated with the phenomenon of \"Collapse to Constant,\" which is related to but not identical to the vanishing gradient phenomenon. The study demonstrates that variability is an accurate predictor of MLP trainability."
}