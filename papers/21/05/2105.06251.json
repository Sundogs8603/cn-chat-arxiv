{
    "title": "Learning Weakly Convex Sets in Metric Spaces",
    "abstract": "arXiv:2105.06251v2 Announce Type: replace  Abstract: One of the central problems studied in the theory of machine learning is the question of whether, for a given class of hypotheses, it is possible to efficiently find a {consistent} hypothesis, i.e., which has zero training error. While problems involving {\\em convex} hypotheses have been extensively studied, the question of whether efficient learning is possible for non-convex hypotheses composed of possibly several disconnected regions is still less understood. Although it has been shown quite a while ago that efficient learning of weakly convex hypotheses, a parameterized relaxation of convex hypotheses, is possible for the special case of Boolean functions, the question of whether this idea can be developed into a generic paradigm has not been studied yet. In this paper, we provide a positive answer and show that the consistent hypothesis finding problem can indeed be solved in polynomial time for a broad class of weakly convex hy",
    "link": "https://arxiv.org/abs/2105.06251",
    "context": "Title: Learning Weakly Convex Sets in Metric Spaces\nAbstract: arXiv:2105.06251v2 Announce Type: replace  Abstract: One of the central problems studied in the theory of machine learning is the question of whether, for a given class of hypotheses, it is possible to efficiently find a {consistent} hypothesis, i.e., which has zero training error. While problems involving {\\em convex} hypotheses have been extensively studied, the question of whether efficient learning is possible for non-convex hypotheses composed of possibly several disconnected regions is still less understood. Although it has been shown quite a while ago that efficient learning of weakly convex hypotheses, a parameterized relaxation of convex hypotheses, is possible for the special case of Boolean functions, the question of whether this idea can be developed into a generic paradigm has not been studied yet. In this paper, we provide a positive answer and show that the consistent hypothesis finding problem can indeed be solved in polynomial time for a broad class of weakly convex hy",
    "path": "papers/21/05/2105.06251.json",
    "total_tokens": 795,
    "translated_title": "在度量空间中学习弱凸集合",
    "translated_abstract": "机器学习理论中研究的一个核心问题是对于给定类别的假设，是否可能有效地找到一个{一致的}假设，即具有零训练误差的假设。尽管涉及{\\em 凸}假设的问题已得到广泛研究，但对于由可能有几个不连续区域组成的非凸假设是否可以进行有效学习的问题仍不太清楚。虽然很久以前就已经表明对于布尔函数的特殊情况可以有效地学习弱凸假设（凸假设的参数化调整），但至今尚未研究这个想法是否可以发展为通用范式。在本文中，我们给出了积极答复，并展示了一种广泛类别的弱凸假设的一致假设找到问题确实可以在多项式时间内解决。",
    "tldr": "本文表明可以在多项式时间内解决一致的假设找到问题，并展示了一种广泛类别的弱凸假设。"
}