{
    "title": "Epistemic Neural Networks. (arXiv:2107.08924v8 [cs.LG] UPDATED)",
    "abstract": "Intelligence relies on an agent's knowledge of what it does not know. This capability can be assessed based on the quality of joint predictions of labels across multiple inputs. In principle, ensemble-based approaches produce effective joint predictions, but the computational costs of training large ensembles can become prohibitive. We introduce the epinet: an architecture that can supplement any conventional neural network, including large pretrained models, and can be trained with modest incremental computation to estimate uncertainty. With an epinet, conventional neural networks outperform very large ensembles, consisting of hundreds or more particles, with orders of magnitude less computation. The epinet does not fit the traditional framework of Bayesian neural networks. To accommodate development of approaches beyond BNNs, such as the epinet, we introduce the epistemic neural network (ENN) as an interface for models that produce joint predictions.",
    "link": "http://arxiv.org/abs/2107.08924",
    "context": "Title: Epistemic Neural Networks. (arXiv:2107.08924v8 [cs.LG] UPDATED)\nAbstract: Intelligence relies on an agent's knowledge of what it does not know. This capability can be assessed based on the quality of joint predictions of labels across multiple inputs. In principle, ensemble-based approaches produce effective joint predictions, but the computational costs of training large ensembles can become prohibitive. We introduce the epinet: an architecture that can supplement any conventional neural network, including large pretrained models, and can be trained with modest incremental computation to estimate uncertainty. With an epinet, conventional neural networks outperform very large ensembles, consisting of hundreds or more particles, with orders of magnitude less computation. The epinet does not fit the traditional framework of Bayesian neural networks. To accommodate development of approaches beyond BNNs, such as the epinet, we introduce the epistemic neural network (ENN) as an interface for models that produce joint predictions.",
    "path": "papers/21/07/2107.08924.json",
    "total_tokens": 891,
    "translated_title": "认知神经网络",
    "translated_abstract": "智能依赖于智能体对其不知道的事物的了解。智能体预测多个输入标签的质量可以评估其对这种能力的掌握程度。集成式方法在原则上可以产生有效的预测，但训练大规模的集成模型的计算成本很高，从而可能会变得禁止。我们引入了Epinet：一种可以加强任何传统神经网络（包括大型预训练模型）的架构，并且可以通过适量级别的递增计算训练来估计不确定性。用Epinet，传统神经网络可以在计算成本大幅下降的情况下胜过由数百个或更多粒子组成的大型集成，同时不需要符合贝叶斯神经网络的传统框架。为了适应超越BNN的方法的发展，例如Epinet，我们介绍了作为产生联合预测模型的接口的知识神经网络（ENN）。",
    "tldr": "该论文提出了一种能够通过适量级别的递增计算来估计神经网络不确定性的Epistemic神经网络框架，使得传统神经网络能够在计算成本大幅下降的情况下超越大型集成模型，为模型联合预测的方法提供了一种新的接口。",
    "en_tdlr": "The paper introduces Epistemic Neural Networks (ENN), a framework that estimates neural network uncertainty with modest incremental computation and creates a new interface for joint prediction models. This enables traditional neural networks to outperform large ensembles with significantly less computation cost."
}