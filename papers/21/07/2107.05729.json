{
    "title": "Generalization of graph network inferences in higher-order graphical models. (arXiv:2107.05729v2 [cs.AI] UPDATED)",
    "abstract": "Probabilistic graphical models provide a powerful tool to describe complex statistical structure, with many real-world applications in science and engineering from controlling robotic arms to understanding neuronal computations. A major challenge for these graphical models is that inferences such as marginalization are intractable for general graphs. These inferences are often approximated by a distributed message-passing algorithm such as Belief Propagation, which does not always perform well on graphs with cycles, nor can it always be easily specified for complex continuous probability distributions. Such difficulties arise frequently in expressive graphical models that include intractable higher-order interactions. In this paper we define the Recurrent Factor Graph Neural Network (RF-GNN) to achieve fast approximate inference on graphical models that involve many-variable interactions. Experimental results on several families of graphical models demonstrate the out-of-distribution g",
    "link": "http://arxiv.org/abs/2107.05729",
    "context": "Title: Generalization of graph network inferences in higher-order graphical models. (arXiv:2107.05729v2 [cs.AI] UPDATED)\nAbstract: Probabilistic graphical models provide a powerful tool to describe complex statistical structure, with many real-world applications in science and engineering from controlling robotic arms to understanding neuronal computations. A major challenge for these graphical models is that inferences such as marginalization are intractable for general graphs. These inferences are often approximated by a distributed message-passing algorithm such as Belief Propagation, which does not always perform well on graphs with cycles, nor can it always be easily specified for complex continuous probability distributions. Such difficulties arise frequently in expressive graphical models that include intractable higher-order interactions. In this paper we define the Recurrent Factor Graph Neural Network (RF-GNN) to achieve fast approximate inference on graphical models that involve many-variable interactions. Experimental results on several families of graphical models demonstrate the out-of-distribution g",
    "path": "papers/21/07/2107.05729.json",
    "total_tokens": 964,
    "translated_title": "高阶图形模型中图网络推断的一般化",
    "translated_abstract": "概率图模型提供了一种描述复杂统计结构的强大工具，具有从控制机器人手臂到理解神经计算等许多科学和工程实际应用。这些图形模型的主要挑战是，在一般图形条件下，如边际化等推断是不可行的。这些推断通常由分布式消息传递算法（例如信任传播）近似，但是它不总能在具有循环的图形上表现良好，并且不总能轻松指定复杂的连续概率分布。在具有不可计算高阶交互作用的表达性图形模型中，这些困难经常出现。在本文中，我们定义了递归因子图神经网络（RF-GNN），以实现对涉及多变量相互作用的图形模型的快速近似推断。在几个图形模型家族的实验结果证明了RF-GNN在训练数据集之外的分布下的一般化，展示了RF-GNN在表达性图形模型中快速且准确地执行推断的潜力。",
    "tldr": "本论文提出了递归因子图神经网络(RF-GNN)，用于实现对涉及多变量相互作用的图形模型的快速近似推断。在多个图形模型家族的实验中展示了RF-GNN在表达性图形模型中快速且准确地执行推断的潜力。",
    "en_tdlr": "This paper proposes Recurrent Factor Graph Neural Network (RF-GNN) for fast approximate inference on graphical models that involve many-variable interactions. Experimental results on several families of graphical models demonstrate the potential of RF-GNN to perform inference accurately and quickly in expressive graphical models beyond the training datasets."
}