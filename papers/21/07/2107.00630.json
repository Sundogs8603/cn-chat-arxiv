{
    "title": "Variational Diffusion Models. (arXiv:2107.00630v6 [cs.LG] UPDATED)",
    "abstract": "Diffusion-based generative models have demonstrated a capacity for perceptually impressive synthesis, but can they also be great likelihood-based models? We answer this in the affirmative, and introduce a family of diffusion-based generative models that obtain state-of-the-art likelihoods on standard image density estimation benchmarks. Unlike other diffusion-based models, our method allows for efficient optimization of the noise schedule jointly with the rest of the model. We show that the variational lower bound (VLB) simplifies to a remarkably short expression in terms of the signal-to-noise ratio of the diffused data, thereby improving our theoretical understanding of this model class. Using this insight, we prove an equivalence between several models proposed in the literature. In addition, we show that the continuous-time VLB is invariant to the noise schedule, except for the signal-to-noise ratio at its endpoints. This enables us to learn a noise schedule that minimizes the vari",
    "link": "http://arxiv.org/abs/2107.00630",
    "context": "Title: Variational Diffusion Models. (arXiv:2107.00630v6 [cs.LG] UPDATED)\nAbstract: Diffusion-based generative models have demonstrated a capacity for perceptually impressive synthesis, but can they also be great likelihood-based models? We answer this in the affirmative, and introduce a family of diffusion-based generative models that obtain state-of-the-art likelihoods on standard image density estimation benchmarks. Unlike other diffusion-based models, our method allows for efficient optimization of the noise schedule jointly with the rest of the model. We show that the variational lower bound (VLB) simplifies to a remarkably short expression in terms of the signal-to-noise ratio of the diffused data, thereby improving our theoretical understanding of this model class. Using this insight, we prove an equivalence between several models proposed in the literature. In addition, we show that the continuous-time VLB is invariant to the noise schedule, except for the signal-to-noise ratio at its endpoints. This enables us to learn a noise schedule that minimizes the vari",
    "path": "papers/21/07/2107.00630.json",
    "total_tokens": 1035,
    "translated_title": "变分扩散模型",
    "translated_abstract": "基于扩散的生成模型已经展示了令人印象深刻的合成能力，但它们也能成为很好的基于可能性的模型吗？我们回答了这个问题，并引入了一族基于扩散的生成模型，在标准图像密度估计基准上获得了最先进的可能性。与其他基于扩散的模型不同，我们的方法允许与模型的其余部分共同有效地优化噪声时间表。我们表明，在扩散数据的信噪比方面，变分下限（VLB）简化为一个非常简短的表达式，从而改善了我们对该模型类的理论理解。利用这一见解，我们证明了文献中提出的几个模型之间的等价性。此外，我们表明，连续时间VLB对于噪声时间表是不变的，除了其端点处的信噪比。这使我们能够学习一种噪声时间表，该表针对信噪比最小化变分下限。我们的实验证明，我们的方法在包括CIFAR-10， CelebA-HQ和FFHQ在内的几个基准测试上实现了良好的性能，无论是可能性还是视觉质量。",
    "tldr": "该论文提出了一族基于扩散的生成模型，通过对噪声时间表的有效优化，这些模型在图像密度估计基准测试中获得了最先进的可能性和视觉质量。",
    "en_tdlr": "This paper proposes a family of diffusion-based generative models that achieve state-of-the-art likelihoods and visual quality on image density estimation benchmarks by effectively optimizing the noise schedule. The method allows for joint optimization of the noise schedule with the rest of the model, and the variational lower bound simplifies to a short expression in terms of the signal-to-noise ratio of the diffused data, improving our understanding of this model class."
}