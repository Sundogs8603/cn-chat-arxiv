{
    "title": "Finite-time Analysis of Globally Nonstationary Multi-Armed Bandits. (arXiv:2107.11419v2 [stat.ML] UPDATED)",
    "abstract": "We consider nonstationary multi-armed bandit problems where the model parameters of the arms change over time. We introduce the adaptive resetting bandit (ADR-bandit), a bandit algorithm class that leverages adaptive windowing techniques from literature on data streams. We first provide new guarantees on the quality of estimators resulting from adaptive windowing techniques, which are of independent interest. Furthermore, we conduct a finite-time analysis of ADR-bandit in two typical environments: an abrupt environment where changes occur instantaneously and a gradual environment where changes occur progressively. We demonstrate that ADR-bandit has nearly optimal performance when abrupt or gradual changes occur in a coordinated manner that we call global changes. We demonstrate that forced exploration is unnecessary when we assume such global changes. Unlike the existing nonstationary bandit algorithms, ADR-bandit has optimal performance in stationary environments as well as nonstation",
    "link": "http://arxiv.org/abs/2107.11419",
    "context": "Title: Finite-time Analysis of Globally Nonstationary Multi-Armed Bandits. (arXiv:2107.11419v2 [stat.ML] UPDATED)\nAbstract: We consider nonstationary multi-armed bandit problems where the model parameters of the arms change over time. We introduce the adaptive resetting bandit (ADR-bandit), a bandit algorithm class that leverages adaptive windowing techniques from literature on data streams. We first provide new guarantees on the quality of estimators resulting from adaptive windowing techniques, which are of independent interest. Furthermore, we conduct a finite-time analysis of ADR-bandit in two typical environments: an abrupt environment where changes occur instantaneously and a gradual environment where changes occur progressively. We demonstrate that ADR-bandit has nearly optimal performance when abrupt or gradual changes occur in a coordinated manner that we call global changes. We demonstrate that forced exploration is unnecessary when we assume such global changes. Unlike the existing nonstationary bandit algorithms, ADR-bandit has optimal performance in stationary environments as well as nonstation",
    "path": "papers/21/07/2107.11419.json",
    "total_tokens": 991,
    "translated_title": "具有全局非稳态的有限时间分析的多臂赌博机问题",
    "translated_abstract": "我们考虑模型参数随时间变化的非稳态多臂赌博机问题。我们引入了自适应重置赌博机(ADR-bandit)，这是一个利用数据流文献中的自适应窗口技术的赌博机算法类。我们首先提供了关于自适应窗口技术产生的估计器质量的新保证，这对于独立的研究是有意义的。此外，我们在两种典型环境下对ADR-bandit进行了有限时间分析：一种是突变环境，其中变化是瞬时发生的；另一种是渐变环境，其中变化是逐渐发生的。我们证明了当突变或渐变的变化以我们称为全局变化的协同方式发生时，ADR-bandit具有几乎最优的性能。我们证明了在假设这种全局变化的情况下，强制探索是不必要的。与现有的非稳态赌博机算法不同，ADR-bandit在稳定环境和非稳态环境中均具有最优的性能。",
    "tldr": "本文研究了模型参数随时间变化的非稳态多臂赌博机问题，引入了自适应重置赌博机(ADR-bandit)算法，通过有限时间分析证明了ADR-bandit在全局变化的情况下具有几乎最优的性能，并且在稳定环境和非稳态环境中均具有最优的性能。",
    "en_tdlr": "This paper investigates the problem of nonstationary multi-armed bandits with time-varying model parameters, introduces the adaptive resetting bandit (ADR-bandit) algorithm, and provides a finite-time analysis that demonstrates the nearly optimal performance of ADR-bandit when global changes occur. ADR-bandit also achieves optimal performance in both stationary and nonstationary environments."
}