{
    "title": "FairBalance: How to Achieve Equalized Odds With Data Pre-processing. (arXiv:2107.08310v4 [cs.LG] UPDATED)",
    "abstract": "This research seeks to benefit the software engineering society by providing a simple yet effective pre-processing approach to achieve equalized odds fairness in machine learning software. Fairness issues have attracted increasing attention since machine learning software is increasingly used for high-stakes and high-risk decisions. Amongst all the existing fairness notions, this work specifically targets \"equalized odds\" given its advantage in always allowing perfect classifiers. Equalized odds requires that members of every demographic group do not receive disparate mistreatment. Prior works either optimize for an equalized odds related metric during the learning process like a black-box, or manipulate the training data following some intuition. This work studies the root cause of the violation of equalized odds and how to tackle it. We found that equalizing the class distribution in each demographic group with sample weights is a necessary condition for achieving equalized odds with",
    "link": "http://arxiv.org/abs/2107.08310",
    "context": "Title: FairBalance: How to Achieve Equalized Odds With Data Pre-processing. (arXiv:2107.08310v4 [cs.LG] UPDATED)\nAbstract: This research seeks to benefit the software engineering society by providing a simple yet effective pre-processing approach to achieve equalized odds fairness in machine learning software. Fairness issues have attracted increasing attention since machine learning software is increasingly used for high-stakes and high-risk decisions. Amongst all the existing fairness notions, this work specifically targets \"equalized odds\" given its advantage in always allowing perfect classifiers. Equalized odds requires that members of every demographic group do not receive disparate mistreatment. Prior works either optimize for an equalized odds related metric during the learning process like a black-box, or manipulate the training data following some intuition. This work studies the root cause of the violation of equalized odds and how to tackle it. We found that equalizing the class distribution in each demographic group with sample weights is a necessary condition for achieving equalized odds with",
    "path": "papers/21/07/2107.08310.json",
    "total_tokens": 865,
    "translated_title": "FairBalance：如何通过数据预处理实现等几率性。",
    "translated_abstract": "本研究旨在通过提供一种简单而有效的预处理方法，在机器学习软件中实现平等机会平等。随着机器学习软件在高风险和高风险决策中的应用越来越多，公平性问题引起了越来越多的关注。在所有现有的公平性概念中，本文特别针对“等几率性”，因为它在始终允许完美分类器方面具有优势。等几率要求每个族群的成员都不会受到不同的待遇。先前的工作要么在学习过程中优化与等几率有关的指标，如黑盒，要么遵循一些直觉来操纵训练数据。本文研究了违反等几率的根本原因以及如何解决它。我们发现，使用样本权重平衡每个族群中的类别分布是实现等几率所必需的条件。",
    "tldr": "本研究提供了一种简单而有效的预处理方法，旨在实现机器学习软件的等几率公平性问题，通过平衡每个族群中的类别分布，以达到这一目标。",
    "en_tdlr": "This research provides a simple yet effective pre-processing approach for achieving equalized odds fairness in machine learning software. By balancing the class distribution in each demographic group with sample weights, the study aims to tackle the root cause of the violation of equalized odds."
}