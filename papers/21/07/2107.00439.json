{
    "title": "What do End-to-End Speech Models Learn about Speaker, Language and Channel Information? A Layer-wise and Neuron-level Analysis. (arXiv:2107.00439v2 [cs.CL] UPDATED)",
    "abstract": "Deep neural networks are inherently opaque and challenging to interpret. Unlike hand-crafted feature-based models, we struggle to comprehend the concepts learned and how they interact within these models. This understanding is crucial not only for debugging purposes but also for ensuring fairness in ethical decision-making. In our study, we conduct a post-hoc functional interpretability analysis of pretrained speech models using the probing framework [1]. Specifically, we analyze utterance-level representations of speech models trained for various tasks such as speaker recognition and dialect identification. We conduct layer and neuron-wise analyses, probing for speaker, language, and channel properties. Our study aims to answer the following questions: i) what information is captured within the representations? ii) how is it represented and distributed? and iii) can we identify a minimal subset of the network that possesses this information?  Our results reveal several novel findings,",
    "link": "http://arxiv.org/abs/2107.00439",
    "context": "Title: What do End-to-End Speech Models Learn about Speaker, Language and Channel Information? A Layer-wise and Neuron-level Analysis. (arXiv:2107.00439v2 [cs.CL] UPDATED)\nAbstract: Deep neural networks are inherently opaque and challenging to interpret. Unlike hand-crafted feature-based models, we struggle to comprehend the concepts learned and how they interact within these models. This understanding is crucial not only for debugging purposes but also for ensuring fairness in ethical decision-making. In our study, we conduct a post-hoc functional interpretability analysis of pretrained speech models using the probing framework [1]. Specifically, we analyze utterance-level representations of speech models trained for various tasks such as speaker recognition and dialect identification. We conduct layer and neuron-wise analyses, probing for speaker, language, and channel properties. Our study aims to answer the following questions: i) what information is captured within the representations? ii) how is it represented and distributed? and iii) can we identify a minimal subset of the network that possesses this information?  Our results reveal several novel findings,",
    "path": "papers/21/07/2107.00439.json",
    "total_tokens": 952,
    "translated_title": "端到端语音模型学习了哪些关于说话人、语言和信道信息？一项层面和神经元水平的分析",
    "translated_abstract": "深度神经网络天生难以解释和理解。与手工特征模型不同，我们难以理解这些模型学习了哪些概念以及它们如何相互作用。这种理解不仅对于调试目的至关重要，而且对于确保道德决策中的公正性也很重要。在本研究中，我们使用探测框架[1]对预训练语音模型进行事后功能解释性分析。具体而言，我们分析了针对不同任务（如说话人识别和方言识别）进行训练的语音模型的话语水平表示。我们进行了层面和神经元水平的分析，探索说话人、语言和信道属性。我们的研究旨在回答以下问题：i）表示中捕获了哪些信息？ii）它是如何表示和分布的？以及iii）我们能否确定拥有此信息的网络的最小子集？我们的结果揭示了一些新的发现，",
    "tldr": "本研究通过对训练完成的语音模型进行层面和神经元水平的分析，探索了其中关于说话人、语言和信道属性的信息捕获情况。其研究结果有助于解释模型学习的关键特征及其在实现公正性决策方面的应用。",
    "en_tdlr": "This study conducts a layer-wise and neuron-level analysis of pretrained speech models to explore the information captured about speaker, language, and channel properties. The results can help interpret the key features learned by the models and their applications in achieving fairness in decision-making."
}