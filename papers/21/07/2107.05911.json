{
    "title": "Model Transferability With Responsive Decision Subjects. (arXiv:2107.05911v4 [cs.LG] UPDATED)",
    "abstract": "Given an algorithmic predictor that is accurate on some source population consisting of strategic human decision subjects, will it remain accurate if the population respond to it? In our setting, an agent or a user corresponds to a sample $(X,Y)$ drawn from a distribution $\\cal{D}$ and will face a model $h$ and its classification result $h(X)$. Agents can modify $X$ to adapt to $h$, which will incur a distribution shift on $(X,Y)$. Our formulation is motivated by applications where the deployed machine learning models are subjected to human agents, and will ultimately face responsive and interactive data distributions. We formalize the discussions of the transferability of a model by studying how the performance of the model trained on the available source distribution (data) would translate to the performance on its induced domain. We provide both upper bounds for the performance gap due to the induced domain shift, as well as lower bounds for the trade-offs that a classifier has to s",
    "link": "http://arxiv.org/abs/2107.05911",
    "context": "Title: Model Transferability With Responsive Decision Subjects. (arXiv:2107.05911v4 [cs.LG] UPDATED)\nAbstract: Given an algorithmic predictor that is accurate on some source population consisting of strategic human decision subjects, will it remain accurate if the population respond to it? In our setting, an agent or a user corresponds to a sample $(X,Y)$ drawn from a distribution $\\cal{D}$ and will face a model $h$ and its classification result $h(X)$. Agents can modify $X$ to adapt to $h$, which will incur a distribution shift on $(X,Y)$. Our formulation is motivated by applications where the deployed machine learning models are subjected to human agents, and will ultimately face responsive and interactive data distributions. We formalize the discussions of the transferability of a model by studying how the performance of the model trained on the available source distribution (data) would translate to the performance on its induced domain. We provide both upper bounds for the performance gap due to the induced domain shift, as well as lower bounds for the trade-offs that a classifier has to s",
    "path": "papers/21/07/2107.05911.json",
    "total_tokens": 1014,
    "translated_title": "响应式决策主体下的模型可迁移性研究",
    "translated_abstract": "在人类智能决策参与的一些数据集上，如果存在一个准确的算法预测器，那么它在这些数据集上的准确率是否会被保持呢？在我们的背景设置中，一个代理人或用户对应于从分布$D$中抽样得到的一个样本$(X,Y)$，并面临着模型$h$及其分类结果$h(X)$。代理人可以修改$X$以适应$h$，这将对$(X,Y)$产生分布偏移。我们的设置是受到了机器学习模型被人类代理人使用并最终面对响应式和交互式数据分布的应用案例的启发。我们通过研究模型在可用源分布（数据）上训练的性能如何转化为其诱导域中性能来系统化地讨论模型的可迁移性。我们提供了由于诱导域偏移而导致的性能差距的上界，以及分类器必须满足的权衡的下界。我们的理论刻画了预测器、策略空间选择和偏移性质对可迁移性程度的影响。",
    "tldr": "本论文研究在响应式和交互式数据分布下，算法预测器的可迁移性问题，提供了性能差距的上界和分类器必须满足的权衡的下界，并刻画了预测器、策略空间选择和偏移性质对可迁移性程度的影响。",
    "en_tdlr": "This paper studies the transferability of algorithmic predictors on datasets with strategic and interactive human decision subjects, provides upper bounds for the performance gap due to distribution shift, and characterizes the impact of predictor choice, strategy space, and shift nature on transferability."
}