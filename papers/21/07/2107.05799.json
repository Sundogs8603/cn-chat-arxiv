{
    "title": "Human Attention during Goal-directed Reading Comprehension Relies on Task Optimization. (arXiv:2107.05799v2 [cs.CL] UPDATED)",
    "abstract": "The computational principles underlying attention allocation in complex goal-directed tasks remain elusive. Goal-directed reading, i.e., reading a passage to answer a question in mind, is a common real-world task that strongly engages attention. Here, we investigate what computational models can explain attention distribution in this complex task. We show that the reading time on each word is predicted by the attention weights in transformer-based deep neural networks (DNNs) optimized to perform the same reading task. Eye-tracking further reveals that readers separately attend to basic text features and question-relevant information during first-pass reading and rereading, respectively. Similarly, text features and question relevance separately modulate attention weights in shallow and deep DNN layers. Furthermore, when readers scan a passage without a question in mind, their reading time is predicted by DNNs optimized for a word prediction task. Therefore, attention during real-world ",
    "link": "http://arxiv.org/abs/2107.05799",
    "context": "Title: Human Attention during Goal-directed Reading Comprehension Relies on Task Optimization. (arXiv:2107.05799v2 [cs.CL] UPDATED)\nAbstract: The computational principles underlying attention allocation in complex goal-directed tasks remain elusive. Goal-directed reading, i.e., reading a passage to answer a question in mind, is a common real-world task that strongly engages attention. Here, we investigate what computational models can explain attention distribution in this complex task. We show that the reading time on each word is predicted by the attention weights in transformer-based deep neural networks (DNNs) optimized to perform the same reading task. Eye-tracking further reveals that readers separately attend to basic text features and question-relevant information during first-pass reading and rereading, respectively. Similarly, text features and question relevance separately modulate attention weights in shallow and deep DNN layers. Furthermore, when readers scan a passage without a question in mind, their reading time is predicted by DNNs optimized for a word prediction task. Therefore, attention during real-world ",
    "path": "papers/21/07/2107.05799.json",
    "total_tokens": 1028,
    "translated_title": "人的注意力在目标定向阅读理解时依赖于任务优化",
    "translated_abstract": "复杂任务中关注力分配的计算原则仍然不明确。目标定向阅读，即阅读一篇文章以回答脑海中的问题，是一种强烈引发注意力的常见真实世界任务。在这里，我们研究了什么计算模型可以解释这种复杂任务中的关注力分配。我们展示了在基于Transformer的深度神经网络（DNN）中，优化执行相同阅读任务的关注权重可以预测每个单词上的阅读时间。眼动跟踪进一步揭示了读者在第一遍阅读和重新阅读过程中分别关注基本文本特征和与问题相关的信息。类似地，文本特征和问题相关性在浅层和深层DNN层中分别调节注意力权重。此外，当读者在脑海中没有问题的情况下扫描一篇文章时，他们的阅读时间可以由为单词预测任务优化的DNN预测。因此，在真实世界的阅读中关注力分配依赖于任务优化。",
    "tldr": "本文研究了阅读理解中人类关注力分配的计算模型。研究表明，在执行相同的阅读任务时，深度神经网络可以预测每个单词的阅读时间，读者在第一遍阅读和重新阅读过程中分别关注基本文本特征和与问题相关的信息，并且文本特征和问题相关性会分别调节注意力权重。",
    "en_tdlr": "This paper investigates the computational model of human attention distribution during goal-directed reading comprehension. The study shows that deep neural networks optimized for reading tasks can predict the reading time of each word, and readers separately attend to basic text features and question-relevant information during first-pass reading and rereading. Text features and question relevance can also modulate attention weights in different DNN layers. Moreover, when readers scan a passage without a question in mind, their reading time can be predicted by DNNs optimized for a word prediction task."
}