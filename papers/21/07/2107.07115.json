{
    "title": "Principal component analysis for Gaussian process posteriors. (arXiv:2107.07115v2 [stat.ML] UPDATED)",
    "abstract": "This paper proposes an extension of principal component analysis for Gaussian process (GP) posteriors, denoted by GP-PCA. Since GP-PCA estimates a low-dimensional space of GP posteriors, it can be used for meta-learning, which is a framework for improving the performance of target tasks by estimating a structure of a set of tasks. The issue is how to define a structure of a set of GPs with an infinite-dimensional parameter, such as coordinate system and a divergence. In this study, we reduce the infiniteness of GP to the finite-dimensional case under the information geometrical framework by considering a space of GP posteriors that have the same prior. In addition, we propose an approximation method of GP-PCA based on variational inference and demonstrate the effectiveness of GP-PCA as meta-learning through experiments.",
    "link": "http://arxiv.org/abs/2107.07115",
    "context": "Title: Principal component analysis for Gaussian process posteriors. (arXiv:2107.07115v2 [stat.ML] UPDATED)\nAbstract: This paper proposes an extension of principal component analysis for Gaussian process (GP) posteriors, denoted by GP-PCA. Since GP-PCA estimates a low-dimensional space of GP posteriors, it can be used for meta-learning, which is a framework for improving the performance of target tasks by estimating a structure of a set of tasks. The issue is how to define a structure of a set of GPs with an infinite-dimensional parameter, such as coordinate system and a divergence. In this study, we reduce the infiniteness of GP to the finite-dimensional case under the information geometrical framework by considering a space of GP posteriors that have the same prior. In addition, we propose an approximation method of GP-PCA based on variational inference and demonstrate the effectiveness of GP-PCA as meta-learning through experiments.",
    "path": "papers/21/07/2107.07115.json",
    "total_tokens": 789,
    "translated_title": "高斯过程后验的主成分分析",
    "translated_abstract": "本文提出了高斯过程后验的主成分分析（GP-PCA）扩展。由于GP-PCA估计了一个低维度的GP后验空间，因此可以用于元学习，这是一种通过估计一组任务的结构来提高目标任务性能的框架。本研究通过考虑具有相同先验的GP后验空间，在信息几何框架下将GP的无限维度问题缩减为有限维度的情况，从而解决了如何定义一组具有无限维参数（如坐标系和发散）的GP的结构的问题。此外，我们提出了一种基于变分推理的GP-PCA近似方法，并通过实验证明了GP-PCA作为元学习的有效性。",
    "tldr": "本文提出了高斯过程后验的主成分分析扩展，解决了如何定义一组具有无限维参数的GP的结构的问题，并且证明了通过元学习提高目标任务性能的有效性。",
    "en_tdlr": "This paper proposes an extension of principal component analysis for Gaussian process (GP) posteriors, which provides a solution to defining the structure of a set of GPs with an infinite-dimensional parameter, and demonstrates the effectiveness of using GP-PCA for meta-learning to improve the performance of target tasks."
}