{
    "title": "Insights from Generative Modeling for Neural Video Compression. (arXiv:2107.13136v2 [eess.IV] UPDATED)",
    "abstract": "While recent machine learning research has revealed connections between deep generative models such as VAEs and rate-distortion losses used in learned compression, most of this work has focused on images. In a similar spirit, we view recently proposed neural video coding algorithms through the lens of deep autoregressive and latent variable modeling. We present these codecs as instances of a generalized stochastic temporal autoregressive transform, and propose new avenues for further improvements inspired by normalizing flows and structured priors. We propose several architectures that yield state-of-the-art video compression performance on high-resolution video and discuss their tradeoffs and ablations. In particular, we propose (i) improved temporal autoregressive transforms, (ii) improved entropy models with structured and temporal dependencies, and (iii) variable bitrate versions of our algorithms. Since our improvements are compatible with a large class of existing models, we prov",
    "link": "http://arxiv.org/abs/2107.13136",
    "context": "Title: Insights from Generative Modeling for Neural Video Compression. (arXiv:2107.13136v2 [eess.IV] UPDATED)\nAbstract: While recent machine learning research has revealed connections between deep generative models such as VAEs and rate-distortion losses used in learned compression, most of this work has focused on images. In a similar spirit, we view recently proposed neural video coding algorithms through the lens of deep autoregressive and latent variable modeling. We present these codecs as instances of a generalized stochastic temporal autoregressive transform, and propose new avenues for further improvements inspired by normalizing flows and structured priors. We propose several architectures that yield state-of-the-art video compression performance on high-resolution video and discuss their tradeoffs and ablations. In particular, we propose (i) improved temporal autoregressive transforms, (ii) improved entropy models with structured and temporal dependencies, and (iii) variable bitrate versions of our algorithms. Since our improvements are compatible with a large class of existing models, we prov",
    "path": "papers/21/07/2107.13136.json",
    "total_tokens": 926,
    "translated_title": "从生成模型中获取神经视频压缩的洞见",
    "translated_abstract": "最近的机器学习研究揭示了深度生成模型（如VAEs）与学习压缩中使用的率失真损失之间的联系，但大部分工作都集中在图像上。在相似的思路下，我们通过深度自回归和潜变量建模的视角来观察最近提出的神经视频编码算法。我们将这些编码器视为广义随机时序自回归变换的实例，并提出了受归一化流和结构先验启发的进一步改进方法。我们提出了几种架构，使得在高分辨率视频上获得了最先进的视频压缩性能，并讨论了它们的权衡和消融。特别地，我们提出了（i）改进的时序自回归变换，（ii）带有结构和时序依赖性的改进熵模型，以及（iii）我们算法的可变码率版本。由于我们的改进与大量现有模型兼容，我们提供了实证结果来验证其有效性。",
    "tldr": "本论文基于生成模型，通过深度自回归和潜变量建模的方法，对神经视频编码算法进行了改进。提出了改进的时序自回归变换、改进的熵模型以及可变码率版本算法，并在高分辨率视频上取得了最先进的压缩性能。",
    "en_tdlr": "This paper proposes improvements for neural video coding algorithms based on generative modeling, by utilizing deep autoregressive and latent variable modeling. The improvements include enhanced temporal autoregressive transforms, improved entropy models with structured and temporal dependencies, and variable bitrate versions. These advancements demonstrate state-of-the-art compression performance for high-resolution videos."
}