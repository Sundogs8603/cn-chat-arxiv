{
    "title": "Small-Text: Active Learning for Text Classification in Python. (arXiv:2107.10314v7 [cs.LG] UPDATED)",
    "abstract": "We introduce small-text, an easy-to-use active learning library, which offers pool-based active learning for single- and multi-label text classification in Python. It features numerous pre-implemented state-of-the-art query strategies, including some that leverage the GPU. Standardized interfaces allow the combination of a variety of classifiers, query strategies, and stopping criteria, facilitating a quick mix and match, and enabling a rapid and convenient development of both active learning experiments and applications. With the objective of making various classifiers and query strategies accessible for active learning, small-text integrates several well-known machine learning libraries, namely scikit-learn, PyTorch, and Hugging Face transformers. The latter integrations are optionally installable extensions, so GPUs can be used but are not required. Using this new library, we investigate the performance of the recently published SetFit training paradigm, which we compare to vanilla ",
    "link": "http://arxiv.org/abs/2107.10314",
    "context": "Title: Small-Text: Active Learning for Text Classification in Python. (arXiv:2107.10314v7 [cs.LG] UPDATED)\nAbstract: We introduce small-text, an easy-to-use active learning library, which offers pool-based active learning for single- and multi-label text classification in Python. It features numerous pre-implemented state-of-the-art query strategies, including some that leverage the GPU. Standardized interfaces allow the combination of a variety of classifiers, query strategies, and stopping criteria, facilitating a quick mix and match, and enabling a rapid and convenient development of both active learning experiments and applications. With the objective of making various classifiers and query strategies accessible for active learning, small-text integrates several well-known machine learning libraries, namely scikit-learn, PyTorch, and Hugging Face transformers. The latter integrations are optionally installable extensions, so GPUs can be used but are not required. Using this new library, we investigate the performance of the recently published SetFit training paradigm, which we compare to vanilla ",
    "path": "papers/21/07/2107.10314.json",
    "total_tokens": 888,
    "translated_title": "Small-Text: Python中的文本分类主动学习",
    "translated_abstract": "我们引入了一个易于使用的主动学习库small-text，提供Python中的池式主动学习，用于单标签和多标签文本分类。它提供了许多预先实现的最先进的查询策略，包括一些利用GPU的策略。标准化的接口允许组合各种分类器、查询策略和停止准则，便于快速混搭，方便快速开发主动学习实验和应用。为了使各种分类器和查询策略对主动学习可访问，small-text集成了几个著名的机器学习库，包括scikit-learn、PyTorch和Hugging Face transformers。后两个集成是可选安装的扩展，因此可以使用GPU，但不是必需的。使用这个新库，我们研究了最近发布的SetFit训练范式的性能，将其与普通方法进行了比较。",
    "tldr": "Small-Text是一个Python中的易于使用的主动学习库，用于文本分类，它集成了多种先进的查询策略和著名的机器学习库，支持单标签和多标签分类。研究者使用该库调研了最新的SetFit训练范式的性能，并与传统方法进行了比较。",
    "en_tdlr": "Small-Text is an easy-to-use active learning library in Python for text classification, integrating various advanced query strategies and well-known machine learning libraries. Researchers used this library to investigate the performance of the recent SetFit training paradigm, comparing it to traditional methods."
}