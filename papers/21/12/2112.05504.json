{
    "title": "BungeeNeRF: Progressive Neural Radiance Field for Extreme Multi-scale Scene Rendering. (arXiv:2112.05504v4 [cs.CV] UPDATED)",
    "abstract": "Neural radiance fields (NeRF) has achieved outstanding performance in modeling 3D objects and controlled scenes, usually under a single scale. In this work, we focus on multi-scale cases where large changes in imagery are observed at drastically different scales. This scenario vastly exists in real-world 3D environments, such as city scenes, with views ranging from satellite level that captures the overview of a city, to ground level imagery showing complex details of an architecture; and can also be commonly identified in landscape and delicate minecraft 3D models. The wide span of viewing positions within these scenes yields multi-scale renderings with very different levels of detail, which poses great challenges to neural radiance field and biases it towards compromised results. To address these issues, we introduce BungeeNeRF, a progressive neural radiance field that achieves level-of-detail rendering across drastically varied scales. Starting from fitting distant views with a shal",
    "link": "http://arxiv.org/abs/2112.05504",
    "context": "Title: BungeeNeRF: Progressive Neural Radiance Field for Extreme Multi-scale Scene Rendering. (arXiv:2112.05504v4 [cs.CV] UPDATED)\nAbstract: Neural radiance fields (NeRF) has achieved outstanding performance in modeling 3D objects and controlled scenes, usually under a single scale. In this work, we focus on multi-scale cases where large changes in imagery are observed at drastically different scales. This scenario vastly exists in real-world 3D environments, such as city scenes, with views ranging from satellite level that captures the overview of a city, to ground level imagery showing complex details of an architecture; and can also be commonly identified in landscape and delicate minecraft 3D models. The wide span of viewing positions within these scenes yields multi-scale renderings with very different levels of detail, which poses great challenges to neural radiance field and biases it towards compromised results. To address these issues, we introduce BungeeNeRF, a progressive neural radiance field that achieves level-of-detail rendering across drastically varied scales. Starting from fitting distant views with a shal",
    "path": "papers/21/12/2112.05504.json",
    "total_tokens": 1232,
    "translated_title": "BungeeNeRF：极端多尺度场景渲染的渐进式神经辐射场",
    "translated_abstract": "神经辐射场（NeRF）在建模三维物体和受控场景方面取得了出色的性能，通常在单一尺度下运行。本文着眼于多尺度情况，其中观察到图像在截然不同的尺度下存在巨大变化。这种情况在现实世界的三维环境中广泛存在，如城市场景，在卫星级别下捕捉一个城市的概述，到地面级别下显示建筑物的复杂细节；也常见于景观和精细的Minecraft 3D模型中。这些场景中广泛的视角范围产生了具有非常不同细节级别的多尺度渲染，这给神经辐射场带来了巨大的挑战并使其偏向妥协结果。我们引入了BungeeNeRF，它是一种渐进式神经辐射场，可在极端不同的尺度上实现逐层渲染。从用浅层网络拟合远距离视图开始，BungeeNeRF通过多个阶段逐步细化粗略的几何形状，由先前阶段的反馈和选择性调整不同尺度的贡献的注意力模块指导。我们的方法可以处理各种规模，并在所有规模上产生具有精细细节的高质量结果。我们在广泛的场景中展示了我们方法的有效性，包括城市景观、景观和Minecraft模型。",
    "tldr": "本文介绍了一种名为BungeeNeRF的渐进式神经辐射场，它可以在极端不同的尺度上实现逐层渲染，经过多个阶段逐步细化粗略的几何形状。该方法可以处理各种规模，并在所有规模上产生具有精细细节的高质量结果，广泛应用于城市景观、景观和Minecraft模型等场景。",
    "en_tdlr": "This paper presents a progressive neural radiance field called BungeeNeRF that achieves level-of-detail rendering across drastically varied scales, and can handle a wide range of scales, producing high-quality results with fine details at all scales. The method is demonstrated on various scenes, including cityscapes, landscapes, and Minecraft models."
}