{
    "title": "Infinite Neural Network Quantum States: Entanglement and Training Dynamics. (arXiv:2112.00723v2 [quant-ph] UPDATED)",
    "abstract": "We study infinite limits of neural network quantum states ($\\infty$-NNQS), which exhibit representation power through ensemble statistics, and also tractable gradient descent dynamics. Ensemble averages of Renyi entropies are expressed in terms of neural network correlators, and architectures that exhibit volume-law entanglement are presented. A general framework is developed for studying the gradient descent dynamics of neural network quantum states (NNQS), using a quantum state neural tangent kernel (QS-NTK). For $\\infty$-NNQS the training dynamics is simplified, since the QS-NTK becomes deterministic and constant. An analytic solution is derived for quantum state supervised learning, which allows an $\\infty$-NNQS to recover any target wavefunction. Numerical experiments on finite and infinite NNQS in the transverse field Ising model and Fermi Hubbard model demonstrate excellent agreement with theory. $\\infty$-NNQS opens up new opportunities for studying entanglement and training dyn",
    "link": "http://arxiv.org/abs/2112.00723",
    "context": "Title: Infinite Neural Network Quantum States: Entanglement and Training Dynamics. (arXiv:2112.00723v2 [quant-ph] UPDATED)\nAbstract: We study infinite limits of neural network quantum states ($\\infty$-NNQS), which exhibit representation power through ensemble statistics, and also tractable gradient descent dynamics. Ensemble averages of Renyi entropies are expressed in terms of neural network correlators, and architectures that exhibit volume-law entanglement are presented. A general framework is developed for studying the gradient descent dynamics of neural network quantum states (NNQS), using a quantum state neural tangent kernel (QS-NTK). For $\\infty$-NNQS the training dynamics is simplified, since the QS-NTK becomes deterministic and constant. An analytic solution is derived for quantum state supervised learning, which allows an $\\infty$-NNQS to recover any target wavefunction. Numerical experiments on finite and infinite NNQS in the transverse field Ising model and Fermi Hubbard model demonstrate excellent agreement with theory. $\\infty$-NNQS opens up new opportunities for studying entanglement and training dyn",
    "path": "papers/21/12/2112.00723.json",
    "total_tokens": 1071,
    "translated_title": "无限神经网络量子态：纠缠和训练动力学",
    "translated_abstract": "本文研究了神经网络量子态（∞-NNQS）的无限极限，通过集合统计表现出其表示能力，并且具有可行的梯度下降动力学。以神经网络相关子表达拉尼熵的集合平均值，呈现了体积定律纠缠的结构。使用量子态神经切线核（QS-NTK）开发了一个用于研究神经网络量子态（NNQS）梯度下降动力学的通用框架。对于∞-NNQS，训练动力学被简化，因为QS-NTK变得确定和恒定。对于量子态监督学习导出了一个解析解，允许∞-NNQS恢复任何目标波函数。在横向场伊辛模型和费米哈伯模型中对有限和无限NNQS进行了数值实验，与理论结果具有良好的一致性。∞-NNQS为研究纠缠和训练动力学提供了新的机会。",
    "tldr": "本研究探索了无限神经网络量子态（∞-NNQS），其通过集合统计表现出高度的表示能力和可行的梯度下降动力学。研究发现，通过神经网络相关子和量子态神经切线核投入到训练动力学中，可以简化神经网络量子态的训练过程并恢复任意目标波函数。对有限和无限NNQS进行的数值实验验证了理论结果，并为进一步研究纠缠和训练动力学提供了新的领域。"
}