{
    "title": "A Simplicity Bubble Problem in Formal-Theoretic Learning Systems. (arXiv:2112.12275v2 [cs.IT] UPDATED)",
    "abstract": "When mining large datasets in order to predict new data, limitations of the principles behind statistical machine learning pose a serious challenge not only to the Big Data deluge, but also to the traditional assumptions that data generating processes are biased toward low algorithmic complexity. Even when one assumes an underlying algorithmic-informational bias toward simplicity in finite dataset generators, we show that current approaches to machine learning (including deep learning, or any formal-theoretic hybrid mix of top-down AI and statistical machine learning approaches), can always be deceived, naturally or artificially, by sufficiently large datasets. In particular, we demonstrate that, for every learning algorithm (with or without access to a formal theory), there is a sufficiently large dataset size above which the algorithmic probability of an unpredictable deceiver is an upper bound (up to a multiplicative constant that only depends on the learning algorithm) for the algo",
    "link": "http://arxiv.org/abs/2112.12275",
    "context": "Title: A Simplicity Bubble Problem in Formal-Theoretic Learning Systems. (arXiv:2112.12275v2 [cs.IT] UPDATED)\nAbstract: When mining large datasets in order to predict new data, limitations of the principles behind statistical machine learning pose a serious challenge not only to the Big Data deluge, but also to the traditional assumptions that data generating processes are biased toward low algorithmic complexity. Even when one assumes an underlying algorithmic-informational bias toward simplicity in finite dataset generators, we show that current approaches to machine learning (including deep learning, or any formal-theoretic hybrid mix of top-down AI and statistical machine learning approaches), can always be deceived, naturally or artificially, by sufficiently large datasets. In particular, we demonstrate that, for every learning algorithm (with or without access to a formal theory), there is a sufficiently large dataset size above which the algorithmic probability of an unpredictable deceiver is an upper bound (up to a multiplicative constant that only depends on the learning algorithm) for the algo",
    "path": "papers/21/12/2112.12275.json",
    "total_tokens": 865,
    "translated_title": "形式理论学习系统中的简单性泡沫问题",
    "translated_abstract": "当挖掘大型数据集以预测新数据时，统计机器学习背后的原则限制不仅对大数据洪流构成严重挑战，还对数据生成过程偏向低算法复杂度的传统假设提出了挑战。即使假设有限的数据集生成器存在底层的算法信息偏好，我们也证明了当前的机器学习方法（包括深度学习或任何自上而下人工智能和统计机器学习方法的混合）总是可以被足够大的数据集自然地或人为地欺骗。特别地，我们证明了对于每个学习算法（无论是否有形式化理论的支持），都存在一个足够大的数据集大小，超过该大小，无法预测欺骗者的算法概率上界是该算法的算法概率上界（乘以仅依赖于学习算法的一个乘法常数）。",
    "tldr": "这篇论文证明了在机器学习中，对于每个算法都存在一个足够大的数据集大小，超过该大小，无法预测欺骗者的算法概率上界是该算法的算法概率上界。",
    "en_tdlr": "This paper proves that for every learning algorithm, there exists a sufficiently large dataset size above which the algorithmic probability of an unpredictable deceiver is an upper bound, up to a multiplicative constant that only depends on the learning algorithm."
}