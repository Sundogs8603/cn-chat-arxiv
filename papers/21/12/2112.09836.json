{
    "title": "Creativity of AI: Hierarchical Planning Model Learning for Facilitating Deep Reinforcement Learning. (arXiv:2112.09836v2 [cs.AI] UPDATED)",
    "abstract": "Despite of achieving great success in real-world applications, Deep Reinforcement Learning (DRL) is still suffering from three critical issues, i.e., data efficiency, lack of the interpretability and transferability. Recent research shows that embedding symbolic knowledge into DRL is promising in addressing those challenges. Inspired by this, we introduce a novel deep reinforcement learning framework with symbolic options. Our framework features a loop training procedure, which enables guiding the improvement of policy by planning with planning models (including action models and hierarchical task network models) and symbolic options learned from interactive trajectories automatically. The learned symbolic options alleviate the dense requirement of expert domain knowledge and provide inherent interpretability of policies. Moreover, the transferability and data efficiency can be further improved by planning with the symbolic planning models. To validate the effectiveness of our framewor",
    "link": "http://arxiv.org/abs/2112.09836",
    "context": "Title: Creativity of AI: Hierarchical Planning Model Learning for Facilitating Deep Reinforcement Learning. (arXiv:2112.09836v2 [cs.AI] UPDATED)\nAbstract: Despite of achieving great success in real-world applications, Deep Reinforcement Learning (DRL) is still suffering from three critical issues, i.e., data efficiency, lack of the interpretability and transferability. Recent research shows that embedding symbolic knowledge into DRL is promising in addressing those challenges. Inspired by this, we introduce a novel deep reinforcement learning framework with symbolic options. Our framework features a loop training procedure, which enables guiding the improvement of policy by planning with planning models (including action models and hierarchical task network models) and symbolic options learned from interactive trajectories automatically. The learned symbolic options alleviate the dense requirement of expert domain knowledge and provide inherent interpretability of policies. Moreover, the transferability and data efficiency can be further improved by planning with the symbolic planning models. To validate the effectiveness of our framewor",
    "path": "papers/21/12/2112.09836.json",
    "total_tokens": 1010,
    "translated_title": "AI的创造力：用于促进深度强化学习的分层规划模型学习",
    "translated_abstract": "尽管在实际应用中取得了巨大成功，但深度强化学习(DRL)仍然面临三个关键问题，即数据效率、解释性的缺乏和可迁移性。最近的研究显示，在DRL中嵌入符号知识有望解决这些挑战。受此启发，我们引入了一种新颖的具有符号选项的深度强化学习框架。我们的框架具有一个循环训练过程，通过与交互轨迹学习的规划模型（包括动作模型和分层任务网络模型）和符号选项来引导策略的改进。学到的符号选项减轻了对专家领域知识的要求，并提供了策略的内在可解释性。此外，通过与符号规划模型的规划，可进一步提高可迁移性和数据效率。",
    "tldr": "该论文提出了一种新颖的深度强化学习框架，通过在DRL中嵌入符号知识，解决了数据效率、解释性缺乏和可迁移性等关键问题。该框架通过循环训练过程，并利用学习的规划模型和符号选项来引导策略的改进。学到的符号选项减轻了对专家领域知识的要求，并提供了策略的内在可解释性，同时通过与符号规划模型的规划进一步提高了可迁移性和数据效率。",
    "en_tdlr": "This paper introduces a novel deep reinforcement learning framework that addresses critical issues in DRL such as data efficiency, lack of interpretability, and transferability by embedding symbolic knowledge. The framework features a loop training procedure that guides policy improvement using learned planning models and symbolic options. The learned symbolic options alleviate the need for expert domain knowledge and provide inherent interpretability of policies, while planning with symbolic planning models further enhances transferability and data efficiency."
}