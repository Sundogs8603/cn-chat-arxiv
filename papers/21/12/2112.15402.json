{
    "title": "Relational Experience Replay: Continual Learning by Adaptively Tuning Task-wise Relationship. (arXiv:2112.15402v3 [cs.LG] UPDATED)",
    "abstract": "Continual learning is a promising machine learning paradigm to learn new tasks while retaining previously learned knowledge over streaming training data. Till now, rehearsal-based methods, keeping a small part of data from old tasks as a memory buffer, have shown good performance in mitigating catastrophic forgetting for previously learned knowledge. However, most of these methods typically treat each new task equally, which may not adequately consider the relationship or similarity between old and new tasks. Furthermore, these methods commonly neglect sample importance in the continual training process and result in sub-optimal performance on certain tasks. To address this challenging problem, we propose Relational Experience Replay (RER), a bi-level learning framework, to adaptively tune task-wise relationships and sample importance within each task to achieve a better `stability' and `plasticity' trade-off. As such, the proposed method is capable of accumulating new knowledge while ",
    "link": "http://arxiv.org/abs/2112.15402",
    "context": "Title: Relational Experience Replay: Continual Learning by Adaptively Tuning Task-wise Relationship. (arXiv:2112.15402v3 [cs.LG] UPDATED)\nAbstract: Continual learning is a promising machine learning paradigm to learn new tasks while retaining previously learned knowledge over streaming training data. Till now, rehearsal-based methods, keeping a small part of data from old tasks as a memory buffer, have shown good performance in mitigating catastrophic forgetting for previously learned knowledge. However, most of these methods typically treat each new task equally, which may not adequately consider the relationship or similarity between old and new tasks. Furthermore, these methods commonly neglect sample importance in the continual training process and result in sub-optimal performance on certain tasks. To address this challenging problem, we propose Relational Experience Replay (RER), a bi-level learning framework, to adaptively tune task-wise relationships and sample importance within each task to achieve a better `stability' and `plasticity' trade-off. As such, the proposed method is capable of accumulating new knowledge while ",
    "path": "papers/21/12/2112.15402.json",
    "total_tokens": 940,
    "translated_title": "关系经验回放：通过自适应调整任务之间的关系进行持续学习",
    "translated_abstract": "持续学习是一种有前景的机器学习范例，可以在流式训练数据上学习新任务的同时保留先前学到的知识。目前，基于回放的方法通过保留来自旧任务的一小部分数据作为内存缓冲区，在减轻先前学到的知识的灾难性遗忘方面表现良好。然而，大多数这些方法通常将每个新任务视为平等的，这可能不充分考虑旧任务和新任务之间的关系或相似性。此外，这些方法通常忽视了持续训练过程中样本的重要性，导致某些任务的性能不佳。为了解决这个具有挑战性的问题，我们提出了关系经验回放（RER），这是一个双层学习框架，通过自适应调整每个任务内的任务之间的关系和样本重要性，以实现更好的“稳定性”和“可塑性”之间的权衡。因此，所提出的方法能够在积累新知识的同时保持对先前知识的记忆。",
    "tldr": "本文提出了关系经验回放（RER）的方法来进行持续学习，通过自适应调整任务之间的关系和样本重要性，以平衡稳定性和可塑性的要求，从而减轻了灾难性遗忘问题并积累新知识。"
}