{
    "title": "Bounding Wasserstein distance with couplings. (arXiv:2112.03152v3 [stat.CO] UPDATED)",
    "abstract": "Markov chain Monte Carlo (MCMC) provides asymptotically consistent estimates of intractable posterior expectations as the number of iterations tends to infinity. However, in large data applications, MCMC can be computationally expensive per iteration. This has catalyzed interest in approximating MCMC in a manner that improves computational speed per iteration but does not produce asymptotically consistent estimates. In this article, we propose estimators based on couplings of Markov chains to assess the quality of such asymptotically biased sampling methods. The estimators give empirical upper bounds of the Wasserstein distance between the limiting distribution of the asymptotically biased sampling method and the original target distribution of interest. We establish theoretical guarantees for our upper bounds and show that our estimators can remain effective in high dimensions. We apply our quality measures to stochastic gradient MCMC, variational Bayes, and Laplace approximations for",
    "link": "http://arxiv.org/abs/2112.03152",
    "context": "Title: Bounding Wasserstein distance with couplings. (arXiv:2112.03152v3 [stat.CO] UPDATED)\nAbstract: Markov chain Monte Carlo (MCMC) provides asymptotically consistent estimates of intractable posterior expectations as the number of iterations tends to infinity. However, in large data applications, MCMC can be computationally expensive per iteration. This has catalyzed interest in approximating MCMC in a manner that improves computational speed per iteration but does not produce asymptotically consistent estimates. In this article, we propose estimators based on couplings of Markov chains to assess the quality of such asymptotically biased sampling methods. The estimators give empirical upper bounds of the Wasserstein distance between the limiting distribution of the asymptotically biased sampling method and the original target distribution of interest. We establish theoretical guarantees for our upper bounds and show that our estimators can remain effective in high dimensions. We apply our quality measures to stochastic gradient MCMC, variational Bayes, and Laplace approximations for",
    "path": "papers/21/12/2112.03152.json",
    "total_tokens": 917,
    "translated_title": "使用耦合方法界定Wasserstein距离",
    "translated_abstract": "马尔可夫链蒙特卡罗（MCMC）在迭代次数趋于无穷时提供了对难以计算的后验期望的渐近一致估计。然而，在大型数据应用中，MCMC每次迭代的计算成本很高。这促使人们对以提高每次迭代的计算速度为目标的MCMC近似方法产生了兴趣，但这些方法不会产生渐近一致估计。在本文中，我们提出了基于马尔可夫链耦合的估计器，用于评估这种渐近有偏采样方法的质量。这些估计器给出了渐近有偏采样方法的极限分布与原始目标分布之间的Wasserstein距离的经验上界。我们为我们的上界建立了理论保证，并表明我们的估计器在高维情况下仍然有效。我们将我们的质量度量应用于随机梯度MCMC、变分贝叶斯和拉普拉斯近似等方法。",
    "tldr": "该论文提出了基于马尔可夫链耦合的估计器，用于评估渐近有偏采样方法的质量，并给出了渐近有偏采样方法的极限分布与原始目标分布之间的Wasserstein距离的经验上界。",
    "en_tdlr": "This paper introduces estimators based on couplings of Markov chains to assess the quality of asymptotically biased sampling methods and provides empirical upper bounds of the Wasserstein distance between the limiting distribution of the asymptotically biased sampling method and the original target distribution."
}