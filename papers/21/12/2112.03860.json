{
    "title": "Differentiable Gaussianization Layers for Inverse Problems Regularized by Deep Generative Models. (arXiv:2112.03860v4 [cs.CV] UPDATED)",
    "abstract": "Deep generative models such as GANs, normalizing flows, and diffusion models are powerful regularizers for inverse problems. They exhibit great potential for helping reduce ill-posedness and attain high-quality results. However, the latent tensors of such deep generative models can fall out of the desired high-dimensional standard Gaussian distribution during inversion, particularly in the presence of data noise and inaccurate forward models, leading to low-fidelity solutions. To address this issue, we propose to reparameterize and Gaussianize the latent tensors using novel differentiable data-dependent layers wherein custom operators are defined by solving optimization problems. These proposed layers constrain inverse problems to obtain high-fidelity in-distribution solutions. We validate our technique on three inversion tasks: compressive-sensing MRI, image deblurring, and eikonal tomography (a nonlinear PDE-constrained inverse problem) using two representative deep generative models",
    "link": "http://arxiv.org/abs/2112.03860",
    "context": "Title: Differentiable Gaussianization Layers for Inverse Problems Regularized by Deep Generative Models. (arXiv:2112.03860v4 [cs.CV] UPDATED)\nAbstract: Deep generative models such as GANs, normalizing flows, and diffusion models are powerful regularizers for inverse problems. They exhibit great potential for helping reduce ill-posedness and attain high-quality results. However, the latent tensors of such deep generative models can fall out of the desired high-dimensional standard Gaussian distribution during inversion, particularly in the presence of data noise and inaccurate forward models, leading to low-fidelity solutions. To address this issue, we propose to reparameterize and Gaussianize the latent tensors using novel differentiable data-dependent layers wherein custom operators are defined by solving optimization problems. These proposed layers constrain inverse problems to obtain high-fidelity in-distribution solutions. We validate our technique on three inversion tasks: compressive-sensing MRI, image deblurring, and eikonal tomography (a nonlinear PDE-constrained inverse problem) using two representative deep generative models",
    "path": "papers/21/12/2112.03860.json",
    "total_tokens": 926,
    "translated_title": "可微分高斯化层用于深度生成模型正则化的逆问题",
    "translated_abstract": "深度生成模型如GAN、标准化流和扩散模型是逆问题的强大正则化器，可以帮助减小不适定性并获得高质量的结果。然而，在逆推过程中，这些模型的潜在张量可能会从期望的高维标准高斯分布中脱离，特别是在数据噪声和不准确的正向模型存在的情况下，会导致低保真度的解决方案。为解决这个问题，我们提出使用新颖的可微数据相关层重新参数化和高斯化潜在张量，其中使用自定义操作符解决优化问题。这些拟议的层将逆问题约束为获得高保真度的分布内解决方案。我们在三个反演任务（压缩感知MRI、图像去模糊和准确度受限的非线性偏微分方程反演问题“eikonal tomography”）上使用两种典型的深度生成模型进行了验证。",
    "tldr": "该论文提出了一种使用可微数据相关层进行重新参数化和高斯化潜在张量的方法，以约束逆问题为获得高保真度的分布内解决方案，有效解决深度生成模型逆问题中潜在张量偏离期望高斯分布的问题。",
    "en_tdlr": "This paper proposes a method that uses differentiable data-dependent layers to reparameterize and Gaussianize the latent tensors to constrain inverse problems and obtain high-fidelity in-distribution solutions, effectively addressing the issue of deep generative models' latent tensors deviating from the expected Gaussian distribution in inverse problems."
}