{
    "title": "A Black-box NLP Classifier Attacker. (arXiv:2112.11660v3 [cs.LG] UPDATED)",
    "abstract": "Deep neural networks have a wide range of applications in solving various real-world tasks and have achieved satisfactory results, in domains such as computer vision, image classification, and natural language processing. Meanwhile, the security and robustness of neural networks have become imperative, as diverse researches have shown the vulnerable aspects of neural networks. Case in point, in Natural language processing tasks, the neural network may be fooled by an attentively modified text, which has a high similarity to the original one. As per previous research, most of the studies are focused on the image domain; Different from image adversarial attacks, the text is represented in a discrete sequence, traditional image attack methods are not applicable in the NLP field. In this paper, we propose a word-level NLP sentiment classifier attack model, which includes a self-attention mechanism-based word selection method and a greedy search algorithm for word substitution. We experimen",
    "link": "http://arxiv.org/abs/2112.11660",
    "context": "Title: A Black-box NLP Classifier Attacker. (arXiv:2112.11660v3 [cs.LG] UPDATED)\nAbstract: Deep neural networks have a wide range of applications in solving various real-world tasks and have achieved satisfactory results, in domains such as computer vision, image classification, and natural language processing. Meanwhile, the security and robustness of neural networks have become imperative, as diverse researches have shown the vulnerable aspects of neural networks. Case in point, in Natural language processing tasks, the neural network may be fooled by an attentively modified text, which has a high similarity to the original one. As per previous research, most of the studies are focused on the image domain; Different from image adversarial attacks, the text is represented in a discrete sequence, traditional image attack methods are not applicable in the NLP field. In this paper, we propose a word-level NLP sentiment classifier attack model, which includes a self-attention mechanism-based word selection method and a greedy search algorithm for word substitution. We experimen",
    "path": "papers/21/12/2112.11660.json",
    "total_tokens": 872,
    "translated_title": "一个黑盒NLP分类器攻击器",
    "translated_abstract": "深度神经网络在解决各种现实世界任务中具有广泛的应用，并在计算机视觉、图像分类和自然语言处理等领域取得了令人满意的结果。与此同时，神经网络的安全性和鲁棒性已经变得非常重要，因为各种研究已经显示了神经网络的脆弱性。以自然语言处理任务为例，神经网络可能被一个与原始文本高度相似的、经过仔细修改的文本所迷惑。根据之前的研究，大部分研究都集中在图像领域；与图像对抗攻击不同，文本以离散序列表示，传统的图像攻击方法在NLP领域不适用。本文提出了一个基于自注意机制的词级NLP情感分类器攻击模型，其中包括基于词选择的自注意机制和贪婪搜索算法进行词替换。我们进行了实验验证...",
    "tldr": "本文提出了一个黑盒NLP分类器攻击模型，通过基于自注意机制的词选择和贪婪搜索算法进行词替换，解决了影响NLP领域传统图像攻击方法不适用的问题。",
    "en_tdlr": "This paper proposes a black-box NLP classifier attacker model that addresses the traditional image attack limitations in the NLP field by leveraging self-attention based word selection and greedy search algorithm for word substitution."
}