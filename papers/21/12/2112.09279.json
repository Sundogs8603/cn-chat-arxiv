{
    "title": "Robust Upper Bounds for Adversarial Training. (arXiv:2112.09279v2 [cs.LG] UPDATED)",
    "abstract": "Many state-of-the-art adversarial training methods for deep learning leverage upper bounds of the adversarial loss to provide security guarantees against adversarial attacks. Yet, these methods rely on convex relaxations to propagate lower and upper bounds for intermediate layers, which affect the tightness of the bound at the output layer. We introduce a new approach to adversarial training by minimizing an upper bound of the adversarial loss that is based on a holistic expansion of the network instead of separate bounds for each layer. This bound is facilitated by state-of-the-art tools from Robust Optimization; it has closed-form and can be effectively trained using backpropagation. We derive two new methods with the proposed approach. The first method (Approximated Robust Upper Bound or aRUB) uses the first order approximation of the network as well as basic tools from Linear Robust Optimization to obtain an empirical upper bound of the adversarial loss that can be easily implement",
    "link": "http://arxiv.org/abs/2112.09279",
    "context": "Title: Robust Upper Bounds for Adversarial Training. (arXiv:2112.09279v2 [cs.LG] UPDATED)\nAbstract: Many state-of-the-art adversarial training methods for deep learning leverage upper bounds of the adversarial loss to provide security guarantees against adversarial attacks. Yet, these methods rely on convex relaxations to propagate lower and upper bounds for intermediate layers, which affect the tightness of the bound at the output layer. We introduce a new approach to adversarial training by minimizing an upper bound of the adversarial loss that is based on a holistic expansion of the network instead of separate bounds for each layer. This bound is facilitated by state-of-the-art tools from Robust Optimization; it has closed-form and can be effectively trained using backpropagation. We derive two new methods with the proposed approach. The first method (Approximated Robust Upper Bound or aRUB) uses the first order approximation of the network as well as basic tools from Linear Robust Optimization to obtain an empirical upper bound of the adversarial loss that can be easily implement",
    "path": "papers/21/12/2112.09279.json",
    "total_tokens": 900,
    "translated_title": "稳健对抗性训练的强力上界",
    "translated_abstract": "为了提供对抗攻击的安全保证，许多最先进的深度学习对抗性训练方法利用对抗损失的上界。然而，这些方法依赖于凸松弛来传播中间层的下界和上界，这会影响输出层绑定的紧密性。我们引入了一种新的对抗性训练方法，通过最小化基于网络的整体展开的对抗损失上界来实现。该上界利用了稳健优化领域的最新工具，具有闭合形式，并且可以使用反向传播进行有效训练。我们提出了两种新方法来实现这种方法。第一种方法（近似稳健上界或aRUB）使用网络的一阶近似和线性稳健优化的基本工具，获得对抗损失的经验上界，可以轻松实现。",
    "tldr": "该论文提出了一种新的对抗性训练方法，通过最小化基于网络的整体展开的对抗损失上界来实现。与传统方法相比，该方法利用了最新的稳健优化领域的工具，可以在保证输出层绑定紧密性的同时，有效地进行训练。",
    "en_tdlr": "This paper proposes a new approach to adversarial training by minimizing an upper bound of the adversarial loss based on a holistic expansion of the network. The method leverages state-of-the-art tools from Robust Optimization and can be effectively trained using backpropagation. It achieves tighter bounds at the output layer compared to traditional methods."
}