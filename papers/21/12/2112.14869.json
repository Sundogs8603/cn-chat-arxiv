{
    "title": "Label Distributionally Robust Losses for Multi-class Classification: Consistency, Robustness and Adaptivity. (arXiv:2112.14869v2 [cs.LG] UPDATED)",
    "abstract": "We study a family of loss functions named label-distributionally robust (LDR) losses for multi-class classification that are formulated from distributionally robust optimization (DRO) perspective, where the uncertainty in the given label information are modeled and captured by taking the worse case of distributional weights. The benefits of this perspective are several fold: (i) it provides a unified framework to explain the classical cross-entropy (CE) loss and SVM loss and their variants, (ii) it includes a special family corresponding to the temperature-scaled CE loss, which is widely adopted but poorly understood; (iii) it allows us to achieve adaptivity to the uncertainty degree of label information at an instance level. Our contributions include: (1) we study both consistency and robustness by establishing top-$k$ ($\\forall k\\geq 1$) consistency of LDR losses for multi-class classification, and a negative result that a top-$1$ consistent and symmetric robust loss cannot achieve t",
    "link": "http://arxiv.org/abs/2112.14869",
    "context": "Title: Label Distributionally Robust Losses for Multi-class Classification: Consistency, Robustness and Adaptivity. (arXiv:2112.14869v2 [cs.LG] UPDATED)\nAbstract: We study a family of loss functions named label-distributionally robust (LDR) losses for multi-class classification that are formulated from distributionally robust optimization (DRO) perspective, where the uncertainty in the given label information are modeled and captured by taking the worse case of distributional weights. The benefits of this perspective are several fold: (i) it provides a unified framework to explain the classical cross-entropy (CE) loss and SVM loss and their variants, (ii) it includes a special family corresponding to the temperature-scaled CE loss, which is widely adopted but poorly understood; (iii) it allows us to achieve adaptivity to the uncertainty degree of label information at an instance level. Our contributions include: (1) we study both consistency and robustness by establishing top-$k$ ($\\forall k\\geq 1$) consistency of LDR losses for multi-class classification, and a negative result that a top-$1$ consistent and symmetric robust loss cannot achieve t",
    "path": "papers/21/12/2112.14869.json",
    "total_tokens": 986,
    "translated_abstract": "我们从分布鲁棒优化的角度研究了一类名为标签分布鲁棒损失（LDR）的多类分类损失函数，通过获取分布权重的最坏情形来对给定标签信息的不确定性进行建模和捕捉。此角度的好处有几个方面：（i）它提供了统一的框架来解释经典的交叉熵（CE）损失和支持向量机（SVM）损失及其变体，（ii）它包括一个对应于温度缩放的CE损失的特殊家族，这已经被广泛采用但了解不足；（iii）它允许我们在实例级别上实现对标签信息不确定性的自适应。我们的贡献包括：（1）建立了多类分类的LDR损失的前k($\\forall k\\geq1$)一致性和鲁棒性，（2）发现一个前1一致性和对称鲁棒损失不能达到一致性和鲁棒性的负面结果。",
    "tldr": "本论文研究了一种名为标签分布鲁棒损失（LDR）的多类分类损失函数，它可以统一解释交叉熵（CE）损失和支持向量机（SVM）损失及其变体，同时实现对标签信息不确定性的自适应。",
    "en_tdlr": "This paper studies a kind of multi-class loss function named label-distributionally robust (LDR) losses, which can provide a unified framework to explain the classical cross-entropy (CE) loss and SVM loss and their variants while achieving adaptivity to the uncertainty degree of label information at an instance level."
}