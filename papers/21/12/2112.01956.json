{
    "title": "Provably Valid and Diverse Mutations of Real-World Media Data for DNN Testing. (arXiv:2112.01956v2 [cs.LG] UPDATED)",
    "abstract": "Deep neural networks (DNNs) often accept high-dimensional media data (e.g., photos, text, and audio) and understand their perceptual content (e.g., a cat). To test DNNs, diverse inputs are needed to trigger mis-predictions. Some preliminary works use byte-level mutations or domain-specific filters (e.g., foggy), whose enabled mutations may be limited and likely error-prone. SOTA works employ deep generative models to generate (infinite) inputs. Also, to keep the mutated inputs perceptually valid (e.g., a cat remains a \"cat\" after mutation), existing efforts rely on imprecise and less generalizable heuristics.  This study revisits two key objectives in media input mutation - perception diversity (DIV) and validity (VAL) - in a rigorous manner based on manifold, a well-developed theory capturing perceptions of high-dimensional media data in a low-dimensional space. We show important results that DIV and VAL inextricably bound each other, and prove that SOTA generative model-based methods",
    "link": "http://arxiv.org/abs/2112.01956",
    "context": "Title: Provably Valid and Diverse Mutations of Real-World Media Data for DNN Testing. (arXiv:2112.01956v2 [cs.LG] UPDATED)\nAbstract: Deep neural networks (DNNs) often accept high-dimensional media data (e.g., photos, text, and audio) and understand their perceptual content (e.g., a cat). To test DNNs, diverse inputs are needed to trigger mis-predictions. Some preliminary works use byte-level mutations or domain-specific filters (e.g., foggy), whose enabled mutations may be limited and likely error-prone. SOTA works employ deep generative models to generate (infinite) inputs. Also, to keep the mutated inputs perceptually valid (e.g., a cat remains a \"cat\" after mutation), existing efforts rely on imprecise and less generalizable heuristics.  This study revisits two key objectives in media input mutation - perception diversity (DIV) and validity (VAL) - in a rigorous manner based on manifold, a well-developed theory capturing perceptions of high-dimensional media data in a low-dimensional space. We show important results that DIV and VAL inextricably bound each other, and prove that SOTA generative model-based methods",
    "path": "papers/21/12/2112.01956.json",
    "total_tokens": 960,
    "translated_title": "可证明有效且多样化的DNN测试中的真实媒体数据变异",
    "translated_abstract": "深度神经网络（DNN）通常接受高维的媒体数据（例如照片、文本和音频），并理解它们的感知内容（例如一只猫）。为了测试DNN，需要多样化的输入来触发错误预测。一些初步的工作使用字节级变异或领域特定的过滤器（例如，模糊），其启用的变异可能有限且容易出错。最先进的工作采用深度生成模型生成（无限的）输入。此外，为了保持变异后的输入在感知上有效（例如，一只猫在变异后仍然是“猫”），现有的研究依赖于不精确且不可泛化的启发式方法。本研究以流形为基础，在一个严格的方式中重新审视媒体输入变异中的两个关键目标 - 感知多样性（DIV）和有效性（VAL）。我们展示了DIV和VAL不可分割地相互绑定的重要结果，并证明了SOTA基于生成模型的方法。",
    "tldr": "本文通过流形理论的严格方法重新审视了媒体输入变异中的感知多样性（DIV）和有效性（VAL）两个关键目标，证明了它们不可分割地相互绑定，并证明了SOTA基于生成模型的方法的重要性。"
}