{
    "title": "A Theoretical View of Linear Backpropagation and Its Convergence. (arXiv:2112.11018v2 [cs.LG] UPDATED)",
    "abstract": "Backpropagation (BP) is widely used for calculating gradients in deep neural networks (DNNs). Applied often along with stochastic gradient descent (SGD) or its variants, BP is considered as a de-facto choice in a variety of machine learning tasks including DNN training and adversarial attack/defense. Recently, a linear variant of BP named LinBP was introduced for generating more transferable adversarial examples for performing black-box attacks, by Guo et al. Although it has been shown empirically effective in black-box attacks, theoretical studies and convergence analyses of such a method is lacking. This paper serves as a complement and somewhat an extension to Guo et al.'s paper, by providing theoretical analyses on LinBP in neural-network-involved learning tasks, including adversarial attack and model training. We demonstrate that, somewhat surprisingly, LinBP can lead to faster convergence in these tasks in the same hyper-parameter settings, compared to BP. We confirm our theoreti",
    "link": "http://arxiv.org/abs/2112.11018",
    "context": "Title: A Theoretical View of Linear Backpropagation and Its Convergence. (arXiv:2112.11018v2 [cs.LG] UPDATED)\nAbstract: Backpropagation (BP) is widely used for calculating gradients in deep neural networks (DNNs). Applied often along with stochastic gradient descent (SGD) or its variants, BP is considered as a de-facto choice in a variety of machine learning tasks including DNN training and adversarial attack/defense. Recently, a linear variant of BP named LinBP was introduced for generating more transferable adversarial examples for performing black-box attacks, by Guo et al. Although it has been shown empirically effective in black-box attacks, theoretical studies and convergence analyses of such a method is lacking. This paper serves as a complement and somewhat an extension to Guo et al.'s paper, by providing theoretical analyses on LinBP in neural-network-involved learning tasks, including adversarial attack and model training. We demonstrate that, somewhat surprisingly, LinBP can lead to faster convergence in these tasks in the same hyper-parameter settings, compared to BP. We confirm our theoreti",
    "path": "papers/21/12/2112.11018.json",
    "total_tokens": 922,
    "translated_title": "线性反向传播及其收敛性的理论视角",
    "translated_abstract": "反向传播（BP）被广泛用于计算深度神经网络（DNN）中的梯度。它通常与随机梯度下降（SGD）或其变种一起使用，在许多机器学习任务中被视为事实上的选择，包括DNN训练和对抗攻击/防御。最近，Guo等人提出了一种名为LinBP的线性BP变体，用于生成更具传递性的对抗样本，以进行黑盒攻击。虽然经验证明在黑盒攻击中有效，但对这种方法的理论研究和收敛性分析较为缺乏。本文作为Guo等人论文的补充和扩展，提供了对LinBP在涉及神经网络的学习任务中的理论分析，包括对抗攻击和模型训练。我们展示了令人惊讶的是，在相同的超参数设置下，与BP相比，LinBP在这些任务中能够实现更快的收敛。我们验证了我们的理论。",
    "tldr": "本文从理论上分析了线性反向传播（LinBP）在神经网络相关的学习任务中的性质，在对抗攻击和模型训练中，LinBP在相同的超参数设置下能够实现更快的收敛。"
}