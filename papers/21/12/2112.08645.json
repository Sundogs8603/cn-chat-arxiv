{
    "title": "Learning Interpretable Models Through Multi-Objective Neural Architecture Search. (arXiv:2112.08645v4 [cs.LG] UPDATED)",
    "abstract": "Monumental advances in deep learning have led to unprecedented achievements across various domains. While the performance of deep neural networks is indubitable, the architectural design and interpretability of such models are nontrivial. Research has been introduced to automate the design of neural network architectures through neural architecture search (NAS). Recent progress has made these methods more pragmatic by exploiting distributed computation and novel optimization algorithms. However, there is little work in optimizing architectures for interpretability. To this end, we propose a multi-objective distributed NAS framework that optimizes for both task performance and \"introspectability,\" a surrogate metric for aspects of interpretability. We leverage the non-dominated sorting genetic algorithm (NSGA-II) and explainable AI (XAI) techniques to reward architectures that can be better comprehended by domain experts. The framework is evaluated on several image classification datase",
    "link": "http://arxiv.org/abs/2112.08645",
    "context": "Title: Learning Interpretable Models Through Multi-Objective Neural Architecture Search. (arXiv:2112.08645v4 [cs.LG] UPDATED)\nAbstract: Monumental advances in deep learning have led to unprecedented achievements across various domains. While the performance of deep neural networks is indubitable, the architectural design and interpretability of such models are nontrivial. Research has been introduced to automate the design of neural network architectures through neural architecture search (NAS). Recent progress has made these methods more pragmatic by exploiting distributed computation and novel optimization algorithms. However, there is little work in optimizing architectures for interpretability. To this end, we propose a multi-objective distributed NAS framework that optimizes for both task performance and \"introspectability,\" a surrogate metric for aspects of interpretability. We leverage the non-dominated sorting genetic algorithm (NSGA-II) and explainable AI (XAI) techniques to reward architectures that can be better comprehended by domain experts. The framework is evaluated on several image classification datase",
    "path": "papers/21/12/2112.08645.json",
    "total_tokens": 915,
    "translated_title": "通过多目标神经架构搜索学习可解释模型",
    "translated_abstract": "深度学习的巨大进展在各个领域取得了前所未有的成就。尽管深度神经网络的性能无可置疑，但其架构设计和可解释性却并非易事。为了自动化神经网络架构设计，引入了神经架构搜索（NAS）的研究。最近的进展通过利用分布式计算和新颖的优化算法使这些方法更为实用。然而，在优化可解释性方面的研究仍相对较少。为此，我们提出了一个多目标分布式NAS框架，旨在优化任务性能和“可视识别性”，这是解释性的一种代理度量。我们利用非支配排序遗传算法（NSGA-II）和可解释人工智能（XAI）技术，奖励那些可以被领域专家更好理解的架构。该框架在几个图像分类数据集上进行了评估。",
    "tldr": "本研究提出了一种多目标分布式神经架构搜索框架，旨在优化深度神经网络的任务性能和可解释性。利用非支配排序遗传算法（NSGA-II）和可解释人工智能（XAI）技术，奖励那些可以被领域专家更好理解的架构。"
}