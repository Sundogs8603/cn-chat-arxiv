{
    "title": "Probabilistic Forecasting with Generative Networks via Scoring Rule Minimization",
    "abstract": "Probabilistic forecasting relies on past observations to provide a probability distribution for a future outcome, which is often evaluated against the realization using a scoring rule. Here, we perform probabilistic forecasting with generative neural networks, which parametrize distributions on high-dimensional spaces by transforming draws from a latent variable. Generative networks are typically trained in an adversarial framework. In contrast, we propose to train generative networks to minimize a predictive-sequential (or prequential) scoring rule on a recorded temporal sequence of the phenomenon of interest, which is appealing as it corresponds to the way forecasting systems are routinely evaluated. Adversarial-free minimization is possible for some scoring rules; hence, our framework avoids the cumbersome hyperparameter tuning and uncertainty underestimation due to unstable adversarial training, thus unlocking reliable use of generative networks in probabilistic forecasting. Furthe",
    "link": "https://arxiv.org/abs/2112.08217",
    "context": "Title: Probabilistic Forecasting with Generative Networks via Scoring Rule Minimization\nAbstract: Probabilistic forecasting relies on past observations to provide a probability distribution for a future outcome, which is often evaluated against the realization using a scoring rule. Here, we perform probabilistic forecasting with generative neural networks, which parametrize distributions on high-dimensional spaces by transforming draws from a latent variable. Generative networks are typically trained in an adversarial framework. In contrast, we propose to train generative networks to minimize a predictive-sequential (or prequential) scoring rule on a recorded temporal sequence of the phenomenon of interest, which is appealing as it corresponds to the way forecasting systems are routinely evaluated. Adversarial-free minimization is possible for some scoring rules; hence, our framework avoids the cumbersome hyperparameter tuning and uncertainty underestimation due to unstable adversarial training, thus unlocking reliable use of generative networks in probabilistic forecasting. Furthe",
    "path": "papers/21/12/2112.08217.json",
    "total_tokens": 829,
    "translated_title": "通过打分规则最小化实现生成网络的概率预测",
    "translated_abstract": "概率预测依赖于过去的观察结果，以提供未来结果的概率分布，并通过打分规则与实际结果进行评估。在这里，我们使用生成神经网络进行概率预测，通过转换潜在变量的抽样来参数化高维空间上的分布。生成网络通常在对抗性框架中进行训练。相比之下，我们提出使用预测序列打分规则在记录的时间序列中训练生成网络，这种方法与常规评估预测系统的方式相一致。对于某些打分规则，可以实现无对抗的最小化；因此，我们的框架避免了繁琐的超参数调整和由于不稳定的对抗训练而导致的不确定性低估，从而在概率预测中可靠地使用生成网络。",
    "tldr": "本论文提出了一种使用生成神经网络进行概率预测的方法，通过预测序列打分规则进行训练，避免了繁琐的超参数调整和不稳定的对抗训练，从而在概率预测中可靠地使用生成网络。",
    "en_tdlr": "This paper proposes a method for probabilistic forecasting using generative neural networks, trained through predictive-sequential scoring rule, which avoids cumbersome hyperparameter tuning and unstable adversarial training for reliable use of generative networks in probabilistic forecasting."
}