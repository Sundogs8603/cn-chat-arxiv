{
    "title": "Open Vocabulary Electroencephalography-To-Text Decoding and Zero-shot Sentiment Classification. (arXiv:2112.02690v3 [cs.AI] UPDATED)",
    "abstract": "State-of-the-art brain-to-text systems have achieved great success in decoding language directly from brain signals using neural networks. However, current approaches are limited to small closed vocabularies which are far from enough for natural communication. In addition, most of the high-performing approaches require data from invasive devices (e.g., ECoG). In this paper, we extend the problem to open vocabulary Electroencephalography(EEG)-To-Text Sequence-To-Sequence decoding and zero-shot sentence sentiment classification on natural reading tasks. We hypothesis that the human brain functions as a special text encoder and propose a novel framework leveraging pre-trained language models (e.g., BART). Our model achieves a 40.1% BLEU-1 score on EEG-To-Text decoding and a 55.6% F1 score on zero-shot EEG-based ternary sentiment classification, which significantly outperforms supervised baselines. Furthermore, we show that our proposed model can handle data from various subjects and sourc",
    "link": "http://arxiv.org/abs/2112.02690",
    "context": "Title: Open Vocabulary Electroencephalography-To-Text Decoding and Zero-shot Sentiment Classification. (arXiv:2112.02690v3 [cs.AI] UPDATED)\nAbstract: State-of-the-art brain-to-text systems have achieved great success in decoding language directly from brain signals using neural networks. However, current approaches are limited to small closed vocabularies which are far from enough for natural communication. In addition, most of the high-performing approaches require data from invasive devices (e.g., ECoG). In this paper, we extend the problem to open vocabulary Electroencephalography(EEG)-To-Text Sequence-To-Sequence decoding and zero-shot sentence sentiment classification on natural reading tasks. We hypothesis that the human brain functions as a special text encoder and propose a novel framework leveraging pre-trained language models (e.g., BART). Our model achieves a 40.1% BLEU-1 score on EEG-To-Text decoding and a 55.6% F1 score on zero-shot EEG-based ternary sentiment classification, which significantly outperforms supervised baselines. Furthermore, we show that our proposed model can handle data from various subjects and sourc",
    "path": "papers/21/12/2112.02690.json",
    "total_tokens": 935,
    "translated_title": "开放词汇的脑电图-文本解码与零-shot情感分类",
    "translated_abstract": "最新的脑电图-文本系统使用神经网络从脑信号中直接解码语言取得了巨大成功。然而，当前的方法仅限于小型封闭的词汇表，这对于自然交流来说远远不够。此外，大多数高性能方法需要来自侵入性设备（如ECoG）的数据。本文将问题扩展到开放词汇的脑电图-文本序列到序列解码和自然阅读任务的零-shot句子情感分类。我们假设人脑可以作为一个特殊的文本编码器，并提出了一个新颖的框架，利用预训练的语言模型（如BART）。我们的模型在脑电图-文本解码方面取得了40.1%的BLEU-1得分，在基于脑电图的零-shot三元情感分类方面取得了55.6%的F1得分，显著优于有监督的基线模型。此外，我们展示了我们提出的模型可以处理来自不同被试和来源的数据。",
    "tldr": "本文拓展了脑电图-文本解码的问题，实现了开放词汇的解码和零-shot情感分类。通过利用预训练的语言模型，我们的模型在解码和情感分类任务上明显优于现有方法。",
    "en_tdlr": "This paper extends the problem of electroencephalography (EEG)-to-text decoding and achieves open vocabulary decoding and zero-shot sentiment classification. By leveraging pre-trained language models, the proposed model significantly outperforms existing methods in both decoding and sentiment classification tasks."
}