{
    "title": "Improving Differentially Private SGD via Randomly Sparsified Gradients. (arXiv:2112.00845v3 [cs.LG] UPDATED)",
    "abstract": "Differentially private stochastic gradient descent (DP-SGD) has been widely adopted in deep learning to provide rigorously defined privacy, which requires gradient clipping to bound the maximum norm of individual gradients and additive isotropic Gaussian noise. With analysis of the convergence rate of DP-SGD in a non-convex setting, we identify that randomly sparsifying gradients before clipping and noisification adjusts a trade-off between internal components of the convergence bound and leads to a smaller upper bound when the noise is dominant. Additionally, our theoretical analysis and empirical evaluations show that the trade-off is not trivial but possibly a unique property of DP-SGD, as either canceling noisification or gradient clipping eliminates the trade-off in the bound. This observation is indicative, as it implies DP-SGD has special inherent room for (even simply random) gradient compression. To verify the observation and utilize it, we propose an efficient and lightweight",
    "link": "http://arxiv.org/abs/2112.00845",
    "context": "Title: Improving Differentially Private SGD via Randomly Sparsified Gradients. (arXiv:2112.00845v3 [cs.LG] UPDATED)\nAbstract: Differentially private stochastic gradient descent (DP-SGD) has been widely adopted in deep learning to provide rigorously defined privacy, which requires gradient clipping to bound the maximum norm of individual gradients and additive isotropic Gaussian noise. With analysis of the convergence rate of DP-SGD in a non-convex setting, we identify that randomly sparsifying gradients before clipping and noisification adjusts a trade-off between internal components of the convergence bound and leads to a smaller upper bound when the noise is dominant. Additionally, our theoretical analysis and empirical evaluations show that the trade-off is not trivial but possibly a unique property of DP-SGD, as either canceling noisification or gradient clipping eliminates the trade-off in the bound. This observation is indicative, as it implies DP-SGD has special inherent room for (even simply random) gradient compression. To verify the observation and utilize it, we propose an efficient and lightweight",
    "path": "papers/21/12/2112.00845.json",
    "total_tokens": 1008,
    "translated_title": "通过随机稀疏化梯度改进差分隐私随机梯度下降法",
    "translated_abstract": "差分隐私随机梯度下降法（DP-SGD）已被广泛应用于深度学习，以提供严格定义的隐私保护，该方法要求对梯度进行剪切以限制个体梯度的最大范数，并添加各向同性高斯噪声。通过在非凸环境中分析DP-SGD的收敛速度，我们发现，在剪切和添加噪声之前对梯度进行随机稀疏化可以调整收敛界的内部成分之间的权衡，并在噪声占主导地位时导致更小的上界。此外，我们的理论分析和实证评估表明，这种权衡并不是微不足道的，而可能是DP-SGD的一种独特属性，因为取消噪声化或梯度剪切都会消除界限中的权衡。这一观察是有指示性的，因为它意味着DP-SGD具有特殊的内在空间，可以进行（甚至仅仅是随机的）梯度压缩。为了验证这一观察并利用它，我们提出了一种高效且轻量级的方法",
    "tldr": "通过在差分隐私随机梯度下降法中对梯度进行随机稀疏化，我们找到了一个调整收敛界的方法，从而在噪声占主导地位时获得更小的上界。这个观察表明，差分隐私随机梯度下降法有特殊的梯度压缩潜力。"
}