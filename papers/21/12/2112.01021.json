{
    "title": "Fighting Fire with Fire: Contrastive Debiasing without Bias-free Data via Generative Bias-transformation. (arXiv:2112.01021v2 [cs.LG] UPDATED)",
    "abstract": "Deep neural networks (DNNs), despite their impressive ability to generalize over-capacity networks, often rely heavily on malignant bias as shortcuts instead of task-related information for discriminative tasks. To address this problem, recent studies utilize auxiliary information related to the bias, which is rarely obtainable in practice, or sift through a handful of bias-free samples for debiasing. However, the success of these methods is not always guaranteed due to the unfulfilled presumptions. In this paper, we propose a novel method, Contrastive Debiasing via Generative Bias-transformation (CDvG), which works without explicit bias labels or bias-free samples. Motivated by our observation that not only discriminative models but also image translation models tend to focus on the malignant bias, CDvG employs an image translation model to transform one bias mode into another while preserving the task-relevant information. Additionally, the bias-transformed views are set against each",
    "link": "http://arxiv.org/abs/2112.01021",
    "context": "Title: Fighting Fire with Fire: Contrastive Debiasing without Bias-free Data via Generative Bias-transformation. (arXiv:2112.01021v2 [cs.LG] UPDATED)\nAbstract: Deep neural networks (DNNs), despite their impressive ability to generalize over-capacity networks, often rely heavily on malignant bias as shortcuts instead of task-related information for discriminative tasks. To address this problem, recent studies utilize auxiliary information related to the bias, which is rarely obtainable in practice, or sift through a handful of bias-free samples for debiasing. However, the success of these methods is not always guaranteed due to the unfulfilled presumptions. In this paper, we propose a novel method, Contrastive Debiasing via Generative Bias-transformation (CDvG), which works without explicit bias labels or bias-free samples. Motivated by our observation that not only discriminative models but also image translation models tend to focus on the malignant bias, CDvG employs an image translation model to transform one bias mode into another while preserving the task-relevant information. Additionally, the bias-transformed views are set against each",
    "path": "papers/21/12/2112.01021.json",
    "total_tokens": 962,
    "translated_title": "以火攻敌：通过生成偏见转化进行对比去偏执，无需无偏样本",
    "translated_abstract": "深度神经网络（DNN）虽然能够以超过容量的网络进行泛化，但在判别任务中常常依赖恶性偏见作为近道，而不是任务相关信息。为了解决这个问题，最近的研究利用与偏见相关的辅助信息，但这在实践中很难获得，或者筛选出少量的无偏样本进行去偏执。然而，这些方法的成功并不总是能得到保证，因为假设不一定能满足。在本文中，我们提出了一种新颖的方法，即通过生成偏见转换的对比去偏执（CDvG），它在没有明确的偏见标签或无偏样本的情况下工作。受到我们的观察启发，不仅判别模型，而且图像翻译模型也倾向于关注恶性偏见，CDvG利用图像翻译模型将一个偏见模式转换为另一个偏见模式，同时保留任务相关信息。此外，偏见转换的视图相互进行对比。",
    "tldr": "本文提出了一种无需明确偏见标签或无偏样本的新方法，通过生成偏见转化，使用图像翻译模型将一个偏见模式转换成另一个，同时保留任务相关信息，以实现对比去偏执。",
    "en_tdlr": "This paper proposes a novel method, Contrastive Debiasing via Generative Bias-transformation (CDvG), which works without explicit bias labels or bias-free samples. It utilizes an image translation model to transform one bias mode into another while preserving task-relevant information, achieving debiasing through bias transformation."
}