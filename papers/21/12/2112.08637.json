{
    "title": "Analyzing the Limits of Self-Supervision in Handling Bias in Language. (arXiv:2112.08637v3 [cs.CL] UPDATED)",
    "abstract": "Prompting inputs with natural language task descriptions has emerged as a popular mechanism to elicit reasonably accurate outputs from large-scale generative language models with little to no in-context supervision. This also helps gain insight into how well language models capture the semantics of a wide range of downstream tasks purely from self-supervised pre-training on massive corpora of unlabeled text. Such models have naturally also been exposed to a lot of undesirable content like racist and sexist language and there is limited work on awareness of models along these dimensions. In this paper, we define and comprehensively evaluate how well such language models capture the semantics of four tasks for bias: diagnosis, identification, extraction and rephrasing. We define three broad classes of task descriptions for these tasks: statement, question, and completion, with numerous lexical variants within each class. We study the efficacy of prompting for each task using these classe",
    "link": "http://arxiv.org/abs/2112.08637",
    "context": "Title: Analyzing the Limits of Self-Supervision in Handling Bias in Language. (arXiv:2112.08637v3 [cs.CL] UPDATED)\nAbstract: Prompting inputs with natural language task descriptions has emerged as a popular mechanism to elicit reasonably accurate outputs from large-scale generative language models with little to no in-context supervision. This also helps gain insight into how well language models capture the semantics of a wide range of downstream tasks purely from self-supervised pre-training on massive corpora of unlabeled text. Such models have naturally also been exposed to a lot of undesirable content like racist and sexist language and there is limited work on awareness of models along these dimensions. In this paper, we define and comprehensively evaluate how well such language models capture the semantics of four tasks for bias: diagnosis, identification, extraction and rephrasing. We define three broad classes of task descriptions for these tasks: statement, question, and completion, with numerous lexical variants within each class. We study the efficacy of prompting for each task using these classe",
    "path": "papers/21/12/2112.08637.json",
    "total_tokens": 863,
    "translated_title": "分析自监督在处理语言偏见中的局限性",
    "translated_abstract": "使用自然语言任务描述作为提示输入已成为从大规模生成性语言模型中引出相对准确输出的流行机制，而同时又几乎没有上下文监督。这也有助于了解语言模型从无标记文本的大规模语言预训练中纯粹捕捉下游任务的语义的能力。这样的模型自然也暴露于许多不希望的内容，如种族主义和性别歧视的语言，目前对模型在这些方面的意识的研究有限。本文中，我们定义并全面评估这种语言模型在四个偏见任务（诊断、识别、提取和改写）中捕捉语义的能力。对于这些任务，我们定义了三类任务描述：陈述、问题和完成，并在每个类别中使用了许多词汇变体。我们研究了使用这些任务描述的提示对每个任务的有效性。",
    "tldr": "本文分析了自监督在处理语言偏见中的局限性，并定义了四个偏见任务（诊断、识别、提取和改写），通过使用不同类别的任务描述来评估语言模型对语义的捕捉能力。",
    "en_tdlr": "This paper analyzes the limits of self-supervision in handling bias in language and defines four bias tasks (diagnosis, identification, extraction, and rephrasing), evaluating the language model's ability to capture semantics through the use of different categories of task descriptions."
}