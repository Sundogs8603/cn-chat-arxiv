{
    "title": "Entropic Herding. (arXiv:2112.11616v2 [stat.ML] UPDATED)",
    "abstract": "Herding is a deterministic algorithm used to generate data points that can be regarded as random samples satisfying input moment conditions. The algorithm is based on the complex behavior of a high-dimensional dynamical system and is inspired by the maximum entropy principle of statistical inference. In this paper, we propose an extension of the herding algorithm, called entropic herding, which generates a sequence of distributions instead of points. Entropic herding is derived as the optimization of the target function obtained from the maximum entropy principle. Using the proposed entropic herding algorithm as a framework, we discuss a closer connection between herding and the maximum entropy principle. Specifically, we interpret the original herding algorithm as a tractable version of entropic herding, the ideal output distribution of which is mathematically represented. We further discuss how the complex behavior of the herding algorithm contributes to optimization. We argue that t",
    "link": "http://arxiv.org/abs/2112.11616",
    "context": "Title: Entropic Herding. (arXiv:2112.11616v2 [stat.ML] UPDATED)\nAbstract: Herding is a deterministic algorithm used to generate data points that can be regarded as random samples satisfying input moment conditions. The algorithm is based on the complex behavior of a high-dimensional dynamical system and is inspired by the maximum entropy principle of statistical inference. In this paper, we propose an extension of the herding algorithm, called entropic herding, which generates a sequence of distributions instead of points. Entropic herding is derived as the optimization of the target function obtained from the maximum entropy principle. Using the proposed entropic herding algorithm as a framework, we discuss a closer connection between herding and the maximum entropy principle. Specifically, we interpret the original herding algorithm as a tractable version of entropic herding, the ideal output distribution of which is mathematically represented. We further discuss how the complex behavior of the herding algorithm contributes to optimization. We argue that t",
    "path": "papers/21/12/2112.11616.json",
    "total_tokens": 851,
    "translated_abstract": "Herding是一种确定性算法，用于生成满足输入动量条件的随机样本数据点。该算法基于高维动力系统的复杂行为，并受到统计推断中最大熵原理的启发。本文提出了一种扩展版的Herding算法，称为熵引导算法，该算法生成一个分布序列而非数据点。熵引导被推导为从最大熵原理获得的目标函数的优化。利用所提出的熵引导算法作为框架，我们讨论了Herding与最大熵原理之间更为密切的联系。具体而言，我们将原始Herding算法解释为熵引导算法的可处理版本，其理想输出分布的数学表示。我们进一步讨论了Herding算法的复杂行为如何促进优化。我们认为熵引导算法是一种新的优化算法，并提供了理论分析与实验结果来支持我们的观点。",
    "tldr": "研究提出了一种基于最大熵原理的熵引导算法，它可以生成一个分布序列，与传统的随机采样方法相比，在某些场景下可以更高效地获取目标数据分布。",
    "en_tdlr": "The paper proposes an entropic herding algorithm based on the maximum entropy principle, which generates a sequence of distributions instead of points. It shows a closer connection between herding and the maximum entropy principle and argues that the algorithm can optimize the target distribution more efficiently than traditional random sampling methods in certain scenarios."
}