{
    "title": "You Only Need End-to-End Training for Long-Tailed Recognition. (arXiv:2112.05958v4 [cs.CV] UPDATED)",
    "abstract": "The generalization gap on the long-tailed data sets is largely owing to most categories only occupying a few training samples. Decoupled training achieves better performance by training backbone and classifier separately. What causes the poorer performance of end-to-end model training (e.g., logits margin-based methods)? In this work, we identify a key factor that affects the learning of the classifier: the channel-correlated features with low entropy before inputting into the classifier. From the perspective of information theory, we analyze why cross-entropy loss tends to produce highly correlated features on the imbalanced data. In addition, we theoretically analyze and prove its impacts on the gradients of classifier weights, the condition number of Hessian, and logits margin-based approach. Therefore, we firstly propose to use Channel Whitening to decorrelate (\"scatter\") the classifier's inputs for decoupling the weight update and reshaping the skewed decision boundary, which achi",
    "link": "http://arxiv.org/abs/2112.05958",
    "raw_ret": "{\n    \"translated_title\": \"只需端到端训练长尾识别\",\n    \"translated_abstract\": \"长尾数据集上的泛化差距很大程度上是由于大多数类别只占据了很少的训练样本。解耦训练通过分别训练主干和分类器来实现更好的性能。导致端到端模型训练(如基于logits margin的方法)表现较差的原因是什么？在这项工作中，我们确定了影响分类器学习的关键因素:在输入分类器之前具有低熵的通道相关特征。从信息理论的角度出发，我们分析了为什么交叉熵损失往往会在不平衡数据上产生高度相关的特征。此外，我们从理论上分析和证明了它对分类器权重的梯度、黑塞矩阵的条件数和logits margin-based方法的影响。因此，我们首次提出使用通道白化来去相关化(“散开”)分类器的输入，以解耦权重更新和重塑偏斜的决策边界，从而实现更好的性能。\",\n    \"tldr\": \"这项工作通过分析信息理论证明了长尾数据集上的泛化差距很大程度上是由于大多数类别只占据了很少的训练样本。它还提出使用通道白化来去相关化分类器的输入以获得更好的性能。\"\n}",
    "total_tokens": 888,
    "ret": {
        "translated_title": "只需端到端训练长尾识别",
        "translated_abstract": "长尾数据集上的泛化差距很大程度上是由于大多数类别只占据了很少的训练样本。解耦训练通过分别训练主干和分类器来实现更好的性能。导致端到端模型训练(如基于logits margin的方法)表现较差的原因是什么？在这项工作中，我们确定了影响分类器学习的关键因素:在输入分类器之前具有低熵的通道相关特征。从信息理论的角度出发，我们分析了为什么交叉熵损失往往会在不平衡数据上产生高度相关的特征。此外，我们从理论上分析和证明了它对分类器权重的梯度、黑塞矩阵的条件数和logits margin-based方法的影响。因此，我们首次提出使用通道白化来去相关化(“散开”)分类器的输入，以解耦权重更新和重塑偏斜的决策边界，从而实现更好的性能。",
        "tldr": "这项工作通过分析信息理论证明了长尾数据集上的泛化差距很大程度上是由于大多数类别只占据了很少的训练样本。它还提出使用通道白化来去相关化分类器的输入以获得更好的性能。"
    }
}