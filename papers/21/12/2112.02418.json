{
    "title": "YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for everyone. (arXiv:2112.02418v4 [cs.SD] UPDATED)",
    "abstract": "YourTTS brings the power of a multilingual approach to the task of zero-shot multi-speaker TTS. Our method builds upon the VITS model and adds several novel modifications for zero-shot multi-speaker and multilingual training. We achieved state-of-the-art (SOTA) results in zero-shot multi-speaker TTS and results comparable to SOTA in zero-shot voice conversion on the VCTK dataset. Additionally, our approach achieves promising results in a target language with a single-speaker dataset, opening possibilities for zero-shot multi-speaker TTS and zero-shot voice conversion systems in low-resource languages. Finally, it is possible to fine-tune the YourTTS model with less than 1 minute of speech and achieve state-of-the-art results in voice similarity and with reasonable quality. This is important to allow synthesis for speakers with a very different voice or recording characteristics from those seen during training.",
    "link": "http://arxiv.org/abs/2112.02418",
    "context": "Title: YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for everyone. (arXiv:2112.02418v4 [cs.SD] UPDATED)\nAbstract: YourTTS brings the power of a multilingual approach to the task of zero-shot multi-speaker TTS. Our method builds upon the VITS model and adds several novel modifications for zero-shot multi-speaker and multilingual training. We achieved state-of-the-art (SOTA) results in zero-shot multi-speaker TTS and results comparable to SOTA in zero-shot voice conversion on the VCTK dataset. Additionally, our approach achieves promising results in a target language with a single-speaker dataset, opening possibilities for zero-shot multi-speaker TTS and zero-shot voice conversion systems in low-resource languages. Finally, it is possible to fine-tune the YourTTS model with less than 1 minute of speech and achieve state-of-the-art results in voice similarity and with reasonable quality. This is important to allow synthesis for speakers with a very different voice or recording characteristics from those seen during training.",
    "path": "papers/21/12/2112.02418.json",
    "total_tokens": 852,
    "translated_title": "YourTTS：面向零数据多说话人语音合成和零数据语音转换",
    "translated_abstract": "YourTTS将多语言方法应用于零数据多说话人语音合成任务中。我们的方法基于VITS模型，并进行了几个新颖的修改，以实现零数据多说话人和多语言培训。我们在VCTK数据集上实现了零数据多说话人TTS的最新结果，并在零数据语音转换方面得到了与最新结果相当的结果。此外，我们的方法在单说话人数据集上实现了有前途的结果，为低资源语言的零数据多说话人TTS和零数据语音转换系统开辟了可能性。最后，通过少于1分钟的语音微调YourTTS模型，可以获得语音相似度方面的最新结果和合理的质量。这对于允许合成具有与训练期间不同的发言者声音或录制特征的讲话人非常重要。",
    "tldr": "YourTTS提出了一种新方法，实现了面向零数据多说话人的语音合成与零数据语音转换任务，并在相关数据集上实现了最新的最佳效果，并为低资源语言的零数据多说话人语音合成提供了可能性。",
    "en_tdlr": "YourTTS proposes a novel approach for zero-shot multi-speaker TTS and zero-shot voice conversion, achieving state-of-the-art results on relevant datasets and opening possibilities for low-resource languages."
}