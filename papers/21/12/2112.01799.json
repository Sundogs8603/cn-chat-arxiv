{
    "title": "Global Context with Discrete Diffusion in Vector Quantised Modelling for Image Generation",
    "abstract": "arXiv:2112.01799v1 Announce Type: cross  Abstract: The integration of Vector Quantised Variational AutoEncoder (VQ-VAE) with autoregressive models as generation part has yielded high-quality results on image generation. However, the autoregressive models will strictly follow the progressive scanning order during the sampling phase. This leads the existing VQ series models to hardly escape the trap of lacking global information. Denoising Diffusion Probabilistic Models (DDPM) in the continuous domain have shown a capability to capture the global context, while generating high-quality images. In the discrete state space, some works have demonstrated the potential to perform text generation and low resolution image generation. We show that with the help of a content-rich discrete visual codebook from VQ-VAE, the discrete diffusion model can also generate high fidelity images with global context, which compensates for the deficiency of the classical autoregressive model along pixel space. ",
    "link": "https://arxiv.org/abs/2112.01799",
    "context": "Title: Global Context with Discrete Diffusion in Vector Quantised Modelling for Image Generation\nAbstract: arXiv:2112.01799v1 Announce Type: cross  Abstract: The integration of Vector Quantised Variational AutoEncoder (VQ-VAE) with autoregressive models as generation part has yielded high-quality results on image generation. However, the autoregressive models will strictly follow the progressive scanning order during the sampling phase. This leads the existing VQ series models to hardly escape the trap of lacking global information. Denoising Diffusion Probabilistic Models (DDPM) in the continuous domain have shown a capability to capture the global context, while generating high-quality images. In the discrete state space, some works have demonstrated the potential to perform text generation and low resolution image generation. We show that with the help of a content-rich discrete visual codebook from VQ-VAE, the discrete diffusion model can also generate high fidelity images with global context, which compensates for the deficiency of the classical autoregressive model along pixel space. ",
    "path": "papers/21/12/2112.01799.json",
    "total_tokens": 909,
    "translated_title": "在矢量量化建模中应用离散扩散的全局背景在图像生成中的应用",
    "translated_abstract": "将矢量量化变分自动编码器（VQ-VAE）与自回归模型整合作为生成部分在图像生成上取得了高质量结果。然而，在采样阶段，自回归模型会严格遵循逐渐扫描顺序，这导致现有的VQ系列模型很难摆脱缺乏全局信息的困境。在连续域中，去噪扩散概率模型（DDPM）已经显示出捕捉全局背景的能力，同时生成高质量图像。在离散状态空间中，一些研究已经展示了执行文本生成和低分辨率图像生成的潜力。我们表明，通过从VQ-VAE获得内容丰富的离散视觉码书的帮助，离散扩散模型也能生成具有全局背景的高保真度图像，从而弥补了经典自回归模型在像素空间上的不足。",
    "tldr": "结合VQ-VAE的内容丰富的离散视觉码书，离散扩散模型能够生成具有全局背景的高保真度图像，弥补了传统自回归模型在像素空间中的不足。"
}