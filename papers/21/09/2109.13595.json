{
    "title": "The Fragility of Optimized Bandit Algorithms. (arXiv:2109.13595v6 [cs.LG] UPDATED)",
    "abstract": "Much of the literature on optimal design of bandit algorithms is based on minimization of expected regret. It is well known that designs that are optimal over certain exponential families can achieve expected regret that grows logarithmically in the number of arm plays, at a rate governed by the Lai-Robbins lower bound. In this paper, we show that when one uses such optimized designs, the regret distribution of the associated algorithms necessarily has a very heavy tail, specifically, that of a truncated Cauchy distribution. Furthermore, for $p>1$, the $p$'th moment of the regret distribution grows much faster than poly-logarithmically, in particular as a power of the total number of arm plays. We show that optimized UCB bandit designs are also fragile in an additional sense, namely when the problem is even slightly mis-specified, the regret can grow much faster than the conventional theory suggests. Our arguments are based on standard change-of-measure ideas, and indicate that the mos",
    "link": "http://arxiv.org/abs/2109.13595",
    "context": "Title: The Fragility of Optimized Bandit Algorithms. (arXiv:2109.13595v6 [cs.LG] UPDATED)\nAbstract: Much of the literature on optimal design of bandit algorithms is based on minimization of expected regret. It is well known that designs that are optimal over certain exponential families can achieve expected regret that grows logarithmically in the number of arm plays, at a rate governed by the Lai-Robbins lower bound. In this paper, we show that when one uses such optimized designs, the regret distribution of the associated algorithms necessarily has a very heavy tail, specifically, that of a truncated Cauchy distribution. Furthermore, for $p>1$, the $p$'th moment of the regret distribution grows much faster than poly-logarithmically, in particular as a power of the total number of arm plays. We show that optimized UCB bandit designs are also fragile in an additional sense, namely when the problem is even slightly mis-specified, the regret can grow much faster than the conventional theory suggests. Our arguments are based on standard change-of-measure ideas, and indicate that the mos",
    "path": "papers/21/09/2109.13595.json",
    "total_tokens": 990,
    "translated_title": "优化赌博算法的脆弱性",
    "translated_abstract": "大部分关于赌博算法最优设计的文献都是基于期望遗憾的最小化。已知对于某些指数族，最优设计在拉依-罗宾斯下界指导下，可实现期望遗憾以对数级别增长。本文表明，当使用这种最优设计时，关联算法的遗憾分布必然具有一个非常重的尾部，具体来说是截断柯西分布。此外，对于$p>1$，遗憾分布的$p$'th矩增长要比多对数级别快得多，特别是作为衣袖数的幂函数。我们表明，优化UCB赌博设计在另一个方面也很脆弱，即当问题略微错误时，遗憾可以比传统理论建议的增长得更快。我们的论点基于标准的措施改变思想，并表明最优设计可能导致一些不太可能发生的情况，因此应该以谨慎的方式对待。",
    "tldr": "本文表明，使用优化设计的赌博算法遗憾分布具有非常重的尾部，对于$p>1$，遗憾分布的$p$'th矩增长要比多对数级别快得多，当问题略微错误时，优化UCB赌博设计的遗憾可以比传统理论建议的增长得更快。",
    "en_tdlr": "This paper shows that using optimized designs for bandit algorithms can lead to a regret distribution with a heavy tail, and the $p$'th moment of the regret distribution grows much faster than poly-logarithmically. Optimized UCB bandit designs are also fragile in the sense that when the problem is slightly mis-specified, the regret can grow much faster than the conventional theory suggests."
}