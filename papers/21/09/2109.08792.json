{
    "title": "Learning to be Fair: A Consequentialist Approach to Equitable Decision-Making",
    "abstract": "In an attempt to make algorithms fair, the machine learning literature has largely focused on equalizing decisions, outcomes, or error rates across race or gender groups. To illustrate, consider a hypothetical government rideshare program that provides transportation assistance to low-income people with upcoming court dates. Following this literature, one might allocate rides to those with the highest estimated treatment effect per dollar, while constraining spending to be equal across race groups. That approach, however, ignores the downstream consequences of such constraints, and, as a result, can induce unexpected harms. For instance, if one demographic group lives farther from court, enforcing equal spending would necessarily mean fewer total rides provided, and potentially more people penalized for missing court. Here we present an alternative framework for designing equitable algorithms that foregrounds the consequences of decisions. In our approach, one first elicits stakeholder",
    "link": "https://arxiv.org/abs/2109.08792",
    "context": "Title: Learning to be Fair: A Consequentialist Approach to Equitable Decision-Making\nAbstract: In an attempt to make algorithms fair, the machine learning literature has largely focused on equalizing decisions, outcomes, or error rates across race or gender groups. To illustrate, consider a hypothetical government rideshare program that provides transportation assistance to low-income people with upcoming court dates. Following this literature, one might allocate rides to those with the highest estimated treatment effect per dollar, while constraining spending to be equal across race groups. That approach, however, ignores the downstream consequences of such constraints, and, as a result, can induce unexpected harms. For instance, if one demographic group lives farther from court, enforcing equal spending would necessarily mean fewer total rides provided, and potentially more people penalized for missing court. Here we present an alternative framework for designing equitable algorithms that foregrounds the consequences of decisions. In our approach, one first elicits stakeholder",
    "path": "papers/21/09/2109.08792.json",
    "total_tokens": 842,
    "translated_title": "学会公平：一种对公正决策的后果主义方法",
    "translated_abstract": "为了使算法公平，机器学习领域主要集中于在种族或性别群体间实现决策、结果或错误率的均衡。举个例子，考虑一个假设的政府共享出行项目，为即将上庭的低收入人群提供交通补助。遵循这个领域的研究，人们可能会根据每美元估计的治疗效果最高为标准分配乘车，同时限制各个种族群体的支出相等。然而，这种做法忽视了此类约束的下游后果，可能会导致意想不到的伤害。例如，如果某一人口群体距离法庭更远，实行平等支出必然意味着提供的总乘车次数减少，可能会导致更多人因缺席庭审而受到惩罚。本文提出了一种新的设计公平算法的框架，重点关注决策的后果。",
    "tldr": "本文提出了一种以后果为导向的设计公平算法的替代框架，这种方法主要考虑决策的后果，而非仅仅追求在种族或性别群体间的均衡。"
}