{
    "title": "Computer Vision Self-supervised Learning Methods on Time Series. (arXiv:2109.00783v4 [cs.LG] UPDATED)",
    "abstract": "Self-supervised learning (SSL) has had great success in both computer vision. Most of the current mainstream computer vision SSL frameworks are based on Siamese network architecture. These approaches often rely on cleverly crafted loss functions and training setups to avoid feature collapse. In this study, we evaluate if those computer-vision SSL frameworks are also effective on a different modality (\\textit{i.e.,} time series). The effectiveness is experimented and evaluated on the UCR and UEA archives, and we show that the computer vision SSL frameworks can be effective even for time series. In addition, we propose a new method that improves on the recently proposed VICReg method. Our method improves on a \\textit{covariance} term proposed in VICReg, and in addition we augment the head of the architecture by an iterative normalization layer that accelerates the convergence of the model.",
    "link": "http://arxiv.org/abs/2109.00783",
    "context": "Title: Computer Vision Self-supervised Learning Methods on Time Series. (arXiv:2109.00783v4 [cs.LG] UPDATED)\nAbstract: Self-supervised learning (SSL) has had great success in both computer vision. Most of the current mainstream computer vision SSL frameworks are based on Siamese network architecture. These approaches often rely on cleverly crafted loss functions and training setups to avoid feature collapse. In this study, we evaluate if those computer-vision SSL frameworks are also effective on a different modality (\\textit{i.e.,} time series). The effectiveness is experimented and evaluated on the UCR and UEA archives, and we show that the computer vision SSL frameworks can be effective even for time series. In addition, we propose a new method that improves on the recently proposed VICReg method. Our method improves on a \\textit{covariance} term proposed in VICReg, and in addition we augment the head of the architecture by an iterative normalization layer that accelerates the convergence of the model.",
    "path": "papers/21/09/2109.00783.json",
    "total_tokens": 845,
    "translated_title": "计算机视觉中基于自监督学习的时序方法",
    "translated_abstract": "自监督学习（SSL）在计算机视觉领域取得了巨大成功。目前主流的计算机视觉自监督学习框架大多基于Siamese网络架构。这些方法通常依赖于精心设计的损失函数和训练设置，以避免特征崩溃。本研究评估了这些计算机视觉自监督学习框架在不同模态（即时间序列）上的效果。我们在UCR和UEA档案上进行了实验证明，计算机视觉自监督学习框架在时间序列上同样有效。此外，我们提出了一种改进最近提出的VICReg方法的新方法。我们改进了VICReg中提出的一个“协方差”项，同时在架构的头部增加了一个迭代归一化层，加速了模型的收敛。",
    "tldr": "该研究评估了计算机视觉自监督学习框架在时间序列上的效果，并且提出了一种改进方法，通过改进协方差项和添加迭代归一化层，加速了模型的收敛。",
    "en_tdlr": "This study evaluates the effectiveness of computer vision self-supervised learning frameworks on time series data and proposes an improved method that accelerates model convergence by enhancing the covariance term and adding an iterative normalization layer to the architecture."
}