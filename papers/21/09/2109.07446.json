{
    "title": "When Does Translation Require Context? A Data-driven, Multilingual Exploration. (arXiv:2109.07446v2 [cs.CL] UPDATED)",
    "abstract": "Although proper handling of discourse significantly contributes to the quality of machine translation (MT), these improvements are not adequately measured in common translation quality metrics. Recent works in context-aware MT attempt to target a small set of discourse phenomena during evaluation, however not in a fully systematic way. In this paper, we develop the Multilingual Discourse-Aware (MuDA) benchmark, a series of taggers that identify and evaluate model performance on discourse phenomena in any given dataset. The choice of phenomena is inspired by a novel methodology to systematically identify translations requiring context. We confirm the difficulty of previously studied phenomena while uncovering others that were previously unaddressed. We find that common context-aware MT models make only marginal improvements over context-agnostic models, which suggests these models do not handle these ambiguities effectively. We release code and data for 14 language pairs to encourage th",
    "link": "http://arxiv.org/abs/2109.07446",
    "context": "Title: When Does Translation Require Context? A Data-driven, Multilingual Exploration. (arXiv:2109.07446v2 [cs.CL] UPDATED)\nAbstract: Although proper handling of discourse significantly contributes to the quality of machine translation (MT), these improvements are not adequately measured in common translation quality metrics. Recent works in context-aware MT attempt to target a small set of discourse phenomena during evaluation, however not in a fully systematic way. In this paper, we develop the Multilingual Discourse-Aware (MuDA) benchmark, a series of taggers that identify and evaluate model performance on discourse phenomena in any given dataset. The choice of phenomena is inspired by a novel methodology to systematically identify translations requiring context. We confirm the difficulty of previously studied phenomena while uncovering others that were previously unaddressed. We find that common context-aware MT models make only marginal improvements over context-agnostic models, which suggests these models do not handle these ambiguities effectively. We release code and data for 14 language pairs to encourage th",
    "path": "papers/21/09/2109.07446.json",
    "total_tokens": 926,
    "translated_title": "何时需要上下文翻译？一项数据驱动的、多语言的探索",
    "translated_abstract": "虽然正确处理语篇对机器翻译的质量有很大影响，但这些改进在常见的翻译质量评估指标中得不到充分衡量。最近的上下文感知机器翻译研究试图针对一小部分语篇现象进行评估，但缺乏完全系统化的方式。在本文中，我们开发了多语言语篇感知（MuDA）基准，这是一系列标记器，用于识别和评估给定数据集中的语篇现象的模型性能。选择的语篇现象受到一种新颖的方法的启发，该方法可系统地确定需要上下文的翻译。我们确认了之前研究的语篇现象的难度，并揭示了之前未解决的其他现象。我们发现常见的上下文感知机器翻译模型仅对上下文无关模型进行了轻微的改进，这表明这些模型并没有有效处理这些歧义。我们发布了14种语言对的代码和数据，以鼓励进一步研究。",
    "tldr": "本研究开发了多语言语篇感知基准，系统性地确定了需要上下文翻译的现象。发现上下文感知机器翻译模型对于解决这些现象的困难程度有限，为进一步研究提供了挑战。",
    "en_tdlr": "This study develops a multilingual discourse-aware benchmark to systematically identify translation phenomena requiring context. It reveals the limited effectiveness of context-aware machine translation models in handling these phenomena, providing a challenge for further research."
}