{
    "title": "Truth Discovery in Sequence Labels from Crowds. (arXiv:2109.04470v2 [cs.HC] UPDATED)",
    "abstract": "Annotation quality and quantity positively affect the learning performance of sequence labeling, a vital task in Natural Language Processing. Hiring domain experts to annotate a corpus is very costly in terms of money and time. Crowdsourcing platforms, such as Amazon Mechanical Turk (AMT), have been deployed to assist in this purpose. However, the annotations collected this way are prone to human errors due to the lack of expertise of the crowd workers. Existing literature in annotation aggregation assumes that annotations are independent and thus faces challenges when handling the sequential label aggregation tasks with complex dependencies. To conquer the challenges, we propose an optimization-based method that infers the ground truth labels using annotations provided by workers for sequential labeling tasks. The proposed Aggregation method for Sequential Labels from Crowds ($AggSLC$) jointly considers the characteristics of sequential labeling tasks, workers' reliabilities, and adva",
    "link": "http://arxiv.org/abs/2109.04470",
    "context": "Title: Truth Discovery in Sequence Labels from Crowds. (arXiv:2109.04470v2 [cs.HC] UPDATED)\nAbstract: Annotation quality and quantity positively affect the learning performance of sequence labeling, a vital task in Natural Language Processing. Hiring domain experts to annotate a corpus is very costly in terms of money and time. Crowdsourcing platforms, such as Amazon Mechanical Turk (AMT), have been deployed to assist in this purpose. However, the annotations collected this way are prone to human errors due to the lack of expertise of the crowd workers. Existing literature in annotation aggregation assumes that annotations are independent and thus faces challenges when handling the sequential label aggregation tasks with complex dependencies. To conquer the challenges, we propose an optimization-based method that infers the ground truth labels using annotations provided by workers for sequential labeling tasks. The proposed Aggregation method for Sequential Labels from Crowds ($AggSLC$) jointly considers the characteristics of sequential labeling tasks, workers' reliabilities, and adva",
    "path": "papers/21/09/2109.04470.json",
    "total_tokens": 853,
    "translated_title": "从众包数据中发现顺序标签中的真实性",
    "translated_abstract": "标注质量和数量对于自然语言处理中的顺序标签学习任务的性能有积极影响。雇佣领域专家对语料库进行标注在时间和金钱上非常昂贵。为了解决这个问题，已经开始使用众包平台（如Amazon Mechanical Turk）来辅助标注。然而，通过这种方式收集的标注容易受到众包工人专业知识不足而产生的人为错误的影响。现有的标注汇总方法假设标注是独立的，因此在处理具有复杂依赖关系的顺序标签汇总任务时面临挑战。为了解决这些挑战，我们提出了一种基于优化的方法，利用工作者提供的标注来推断顺序标签的真实值。我们提出的顺序标签汇总方法（$AggSLC$）同时考虑了顺序标签任务的特征、工作者可信度和优势。",
    "tldr": "本研究提出了一种基于优化的方法（$AggSLC$），从众包数据中推断顺序标签的真实值，以解决顺序标签汇总任务中的复杂依赖关系问题。",
    "en_tdlr": "This paper proposes an optimization-based method ($AggSLC$) to infer the ground truth labels from crowdsourced sequential labeling annotations, overcoming the challenge of handling complex dependencies in sequential label aggregation tasks."
}