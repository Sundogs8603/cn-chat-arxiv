{
    "title": "CounterNet: End-to-End Training of Prediction Aware Counterfactual Explanations. (arXiv:2109.07557v3 [cs.LG] UPDATED)",
    "abstract": "This work presents CounterNet, a novel end-to-end learning framework which integrates Machine Learning (ML) model training and the generation of corresponding counterfactual (CF) explanations into a single end-to-end pipeline. Counterfactual explanations offer a contrastive case, i.e., they attempt to find the smallest modification to the feature values of an instance that changes the prediction of the ML model on that instance to a predefined output. Prior techniques for generating CF explanations suffer from two major limitations: (i) all of them are post-hoc methods designed for use with proprietary ML models -- as a result, their procedure for generating CF explanations is uninformed by the training of the ML model, which leads to misalignment between model predictions and explanations; and (ii) most of them rely on solving separate time-intensive optimization problems to find CF explanations for each input data point (which negatively impacts their runtime). This work makes a nove",
    "link": "http://arxiv.org/abs/2109.07557",
    "context": "Title: CounterNet: End-to-End Training of Prediction Aware Counterfactual Explanations. (arXiv:2109.07557v3 [cs.LG] UPDATED)\nAbstract: This work presents CounterNet, a novel end-to-end learning framework which integrates Machine Learning (ML) model training and the generation of corresponding counterfactual (CF) explanations into a single end-to-end pipeline. Counterfactual explanations offer a contrastive case, i.e., they attempt to find the smallest modification to the feature values of an instance that changes the prediction of the ML model on that instance to a predefined output. Prior techniques for generating CF explanations suffer from two major limitations: (i) all of them are post-hoc methods designed for use with proprietary ML models -- as a result, their procedure for generating CF explanations is uninformed by the training of the ML model, which leads to misalignment between model predictions and explanations; and (ii) most of them rely on solving separate time-intensive optimization problems to find CF explanations for each input data point (which negatively impacts their runtime). This work makes a nove",
    "path": "papers/21/09/2109.07557.json",
    "total_tokens": 1085,
    "translated_title": "CounterNet：具有预测感知因果解释的端到端训练",
    "translated_abstract": "本文提出了一个新的端到端学习框架CounterNet，将机器学习模型训练和相应的因果解释生成结合在一起。因果解释提供了对照案例，即试图找到最小的修改特征值的实例，将ML模型对该实例的预测改变为预定义输出。之前生成因果解释的技术存在两个主要限制：它们都是针对专有ML模型的后续方法，并且它们的生成过程缺乏对ML模型的训练的启示，这导致了模型预测和解释之间的错位；大多数技术依赖于解决针对每个输入数据点的分离时限制的优化问题来找到CF解释(这对他们的运行时间有负面影响)。本文通过引入端到端框架CounterNet做出了新贡献，将机器学习模型训练与生成CF解释相结合。通过一起训练ML模型和生成CF解释，CounterNet解决了之前技术的限制，并提供了与模型预测和解释更好对齐的预测感知的CF解释。此外，CounterNet避免了对每个输入数据点解决分离的优化问题，从而减少了计算开销。",
    "tldr": "本文提出了一个新的端到端学习框架CounterNet，将机器学习模型训练和相应的因果解释生成结合在一起。CounterNet通过一起训练ML模型和生成CF解释来提供预测感知的CF解释，并减少计算开销。",
    "en_tdlr": "CounterNet is a novel end-to-end learning framework that integrates Machine Learning model training with the generation of corresponding counterfactual explanations. By jointly training the ML model and generating counterfactual explanations, CounterNet provides prediction-aware explanations with better alignment between model predictions and explanations, while also reducing computational overhead."
}