{
    "title": "Federated Ensemble Model-based Reinforcement Learning in Edge Computing. (arXiv:2109.05549v3 [cs.LG] UPDATED)",
    "abstract": "Federated learning (FL) is a privacy-preserving distributed machine learning paradigm that enables collaborative training among geographically distributed and heterogeneous devices without gathering their data. Extending FL beyond the supervised learning models, federated reinforcement learning (FRL) was proposed to handle sequential decision-making problems in edge computing systems. However, the existing FRL algorithms directly combine model-free RL with FL, thus often leading to high sample complexity and lacking theoretical guarantees. To address the challenges, we propose a novel FRL algorithm that effectively incorporates model-based RL and ensemble knowledge distillation into FL for the first time. Specifically, we utilise FL and knowledge distillation to create an ensemble of dynamics models for clients, and then train the policy by solely using the ensemble model without interacting with the environment. Furthermore, we theoretically prove that the monotonic improvement of the",
    "link": "http://arxiv.org/abs/2109.05549",
    "context": "Title: Federated Ensemble Model-based Reinforcement Learning in Edge Computing. (arXiv:2109.05549v3 [cs.LG] UPDATED)\nAbstract: Federated learning (FL) is a privacy-preserving distributed machine learning paradigm that enables collaborative training among geographically distributed and heterogeneous devices without gathering their data. Extending FL beyond the supervised learning models, federated reinforcement learning (FRL) was proposed to handle sequential decision-making problems in edge computing systems. However, the existing FRL algorithms directly combine model-free RL with FL, thus often leading to high sample complexity and lacking theoretical guarantees. To address the challenges, we propose a novel FRL algorithm that effectively incorporates model-based RL and ensemble knowledge distillation into FL for the first time. Specifically, we utilise FL and knowledge distillation to create an ensemble of dynamics models for clients, and then train the policy by solely using the ensemble model without interacting with the environment. Furthermore, we theoretically prove that the monotonic improvement of the",
    "path": "papers/21/09/2109.05549.json",
    "total_tokens": 941,
    "translated_title": "边缘计算中的联邦混合建模强化学习",
    "translated_abstract": "联邦学习（FL）是一种保护隐私的分布式机器学习范式，可以在不收集设备数据的情况下使地理上分布和异构的设备进行协作训练。为了将FL扩展到超出监督学习模型，提出了联邦强化学习（FRL）来处理边缘计算系统中的顺序决策问题。然而，现有的FRL算法直接将无模型强化学习与FL结合起来，因此往往导致高样本复杂度和缺乏理论保证。为了应对这些挑战，我们提出了一种新颖的FRL算法，它有效地将模型建模强化学习和集成知识蒸馏融入FL中。具体来说，我们利用FL和知识蒸馏为客户创建动态模型的集合，然后仅使用集合模型而不与环境交互，训练策略。此外，我们在理论上证明了单调改进的正确性。",
    "tldr": "本文提出了一种新颖的联邦强化学习算法，在边缘计算中使用联邦学习和知识蒸馏创建动态模型集合，通过仅使用集合模型而不与环境交互来训练策略，从而解决了现有算法中高样本复杂度和缺乏理论保证的问题。",
    "en_tdlr": "This paper proposes a novel federated reinforcement learning algorithm that utilizes federated learning and knowledge distillation to create a dynamic model ensemble for clients in edge computing. By solely using the ensemble model and not interacting with the environment, the proposed method addresses the issues of high sample complexity and lack of theoretical guarantees in existing algorithms."
}