{
    "title": "Optimal subgroup selection. (arXiv:2109.01077v2 [math.ST] UPDATED)",
    "abstract": "In clinical trials and other applications, we often see regions of the feature space that appear to exhibit interesting behaviour, but it is unclear whether these observed phenomena are reflected at the population level. Focusing on a regression setting, we consider the subgroup selection challenge of identifying a region of the feature space on which the regression function exceeds a pre-determined threshold. We formulate the problem as one of constrained optimisation, where we seek a low-complexity, data-dependent selection set on which, with a guaranteed probability, the regression function is uniformly at least as large as the threshold; subject to this constraint, we would like the region to contain as much mass under the marginal feature distribution as possible. This leads to a natural notion of regret, and our main contribution is to determine the minimax optimal rate for this regret in both the sample size and the Type I error probability. The rate involves a delicate interpla",
    "link": "http://arxiv.org/abs/2109.01077",
    "context": "Title: Optimal subgroup selection. (arXiv:2109.01077v2 [math.ST] UPDATED)\nAbstract: In clinical trials and other applications, we often see regions of the feature space that appear to exhibit interesting behaviour, but it is unclear whether these observed phenomena are reflected at the population level. Focusing on a regression setting, we consider the subgroup selection challenge of identifying a region of the feature space on which the regression function exceeds a pre-determined threshold. We formulate the problem as one of constrained optimisation, where we seek a low-complexity, data-dependent selection set on which, with a guaranteed probability, the regression function is uniformly at least as large as the threshold; subject to this constraint, we would like the region to contain as much mass under the marginal feature distribution as possible. This leads to a natural notion of regret, and our main contribution is to determine the minimax optimal rate for this regret in both the sample size and the Type I error probability. The rate involves a delicate interpla",
    "path": "papers/21/09/2109.01077.json",
    "total_tokens": 870,
    "translated_title": "最佳子群选择",
    "translated_abstract": "在临床试验和其他应用中，我们经常看到特征空间中出现了有趣的行为区域，但不清楚这些观察到的现象是否在总体水平上有所反映。针对回归设置，我们考虑子群选择挑战，即识别一个特征空间的区域，在该区域上，回归函数超过了预设的阈值。我们将这个问题形式化为一种约束优化问题，通过寻找一个低复杂度、数据相关的选择集，在这个选择集上，回归函数有至少与阈值一样大的概率，同时要求该区域在边缘特征分布下的质量尽可能大。这导致了一种自然的遗憾概念，我们的主要贡献是确定了遗憾在样本规模和第一类错误概率上的最优值。这个最优值涉及到样本大小和类型I错误概率的微妙相互影响。",
    "tldr": "在回归设置中，我们提出了一个子群选择挑战，以确定回归函数超过预设阈值的特征空间区域。我们的主要贡献是确定了在样本规模和类型I错误概率上遗憾的最佳速率。",
    "en_tdlr": "In a regression setting, we address the challenge of subgroup selection to identify a region in the feature space where the regression function exceeds a pre-determined threshold. Our main contribution is to determine the optimal rate of regret in sample size and Type I error probability."
}