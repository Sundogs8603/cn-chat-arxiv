{
    "title": "On the Noise Stability and Robustness of Adversarially Trained Networks on NVM Crossbars. (arXiv:2109.09060v2 [cs.LG] UPDATED)",
    "abstract": "Applications based on Deep Neural Networks (DNNs) have grown exponentially in the past decade. To match their increasing computational needs, several Non-Volatile Memory (NVM) crossbar based accelerators have been proposed. Recently, researchers have shown that apart from improved energy efficiency and performance, such approximate hardware also possess intrinsic robustness for defense against adversarial attacks. Prior works quantified this intrinsic robustness for vanilla DNNs trained on unperturbed inputs. However, adversarial training of DNNs is the benchmark technique for robustness, and sole reliance on intrinsic robustness of the hardware may not be sufficient. In this work, we explore the design of robust DNNs through the amalgamation of adversarial training and intrinsic robustness of NVM crossbar-based analog hardware. First, we study the noise stability of such networks on unperturbed inputs and observe that internal activations of adversarially trained networks have lower S",
    "link": "http://arxiv.org/abs/2109.09060",
    "context": "Title: On the Noise Stability and Robustness of Adversarially Trained Networks on NVM Crossbars. (arXiv:2109.09060v2 [cs.LG] UPDATED)\nAbstract: Applications based on Deep Neural Networks (DNNs) have grown exponentially in the past decade. To match their increasing computational needs, several Non-Volatile Memory (NVM) crossbar based accelerators have been proposed. Recently, researchers have shown that apart from improved energy efficiency and performance, such approximate hardware also possess intrinsic robustness for defense against adversarial attacks. Prior works quantified this intrinsic robustness for vanilla DNNs trained on unperturbed inputs. However, adversarial training of DNNs is the benchmark technique for robustness, and sole reliance on intrinsic robustness of the hardware may not be sufficient. In this work, we explore the design of robust DNNs through the amalgamation of adversarial training and intrinsic robustness of NVM crossbar-based analog hardware. First, we study the noise stability of such networks on unperturbed inputs and observe that internal activations of adversarially trained networks have lower S",
    "path": "papers/21/09/2109.09060.json",
    "total_tokens": 1024,
    "translated_title": "关于NVM交叉型存储器上对抗训练网络的噪声稳定性和鲁棒性",
    "translated_abstract": "深度神经网络应用在过去的十年中呈指数级增长。为了满足这些网络日益增长的计算需求，提出了几种基于非易失性存储器（NVM）交叉型存储器的加速器。最近的研究表明，除了显著提高能效和性能外，这种近似硬件还具有内在的鲁棒性，可以抵御对抗攻击。先前的研究针对未受干扰输入数据训练的基本DNN对其内在鲁棒性进行了量化。然而，对抗训练DNN已成为鲁棒性的基准技术，仅依靠硬件的内在鲁棒性可能不足以应对此类攻击。本文通过将对抗训练和NVM交互式存储器模拟硬件的内在鲁棒性相结合，探索了鲁棒DNN的设计。首先，我们研究了这些网络在未受干扰输入下的噪声稳定性，并观察到对抗训练的网络的内部激活拥有更低的S",
    "tldr": "本文研究结合对抗训练和NVM交叉型存储器内在鲁棒性的设计方法，探索如何设计鲁棒的DNN。对网络未受干扰输入数据下的噪声稳定性进行了研究，并发现对抗训练的网络具有更低的S值。",
    "en_tdlr": "This paper explores the design of robust DNNs through the amalgamation of adversarial training and intrinsic robustness of NVM crossbar-based analog hardware. It studies the noise stability of such networks on unperturbed inputs and observes that internal activations of adversarially trained networks have lower S values."
}