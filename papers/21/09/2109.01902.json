{
    "title": "Barycentric-alignment and reconstruction loss minimization for domain generalization. (arXiv:2109.01902v6 [cs.LG] UPDATED)",
    "abstract": "This paper advances the theory and practice of Domain Generalization (DG) in machine learning. We consider the typical DG setting where the hypothesis is composed of a representation mapping followed by a labeling function. Within this setting, the majority of popular DG methods aim to jointly learn the representation and the labeling functions by minimizing a well-known upper bound for the classification risk in the unseen domain. In practice, however, methods based on this theoretical upper bound ignore a term that cannot be directly optimized due to its dual dependence on both the representation mapping and the unknown optimal labeling function in the unseen domain. To bridge this gap between theory and practice, we introduce a new upper bound that is free of terms having such dual dependence, resulting in a fully optimizable risk upper bound for the unseen domain. Our derivation leverages classical and recent transport inequalities that link optimal transport metrics with informati",
    "link": "http://arxiv.org/abs/2109.01902",
    "context": "Title: Barycentric-alignment and reconstruction loss minimization for domain generalization. (arXiv:2109.01902v6 [cs.LG] UPDATED)\nAbstract: This paper advances the theory and practice of Domain Generalization (DG) in machine learning. We consider the typical DG setting where the hypothesis is composed of a representation mapping followed by a labeling function. Within this setting, the majority of popular DG methods aim to jointly learn the representation and the labeling functions by minimizing a well-known upper bound for the classification risk in the unseen domain. In practice, however, methods based on this theoretical upper bound ignore a term that cannot be directly optimized due to its dual dependence on both the representation mapping and the unknown optimal labeling function in the unseen domain. To bridge this gap between theory and practice, we introduce a new upper bound that is free of terms having such dual dependence, resulting in a fully optimizable risk upper bound for the unseen domain. Our derivation leverages classical and recent transport inequalities that link optimal transport metrics with informati",
    "path": "papers/21/09/2109.01902.json",
    "total_tokens": 852,
    "translated_title": "多个领域下通用的质心对齐和重构损失最小化领域归纳论文翻译",
    "translated_abstract": "本文推进了机器学习中领域归纳（DG）理论和实践。我们考虑了典型的DG设置，其中假设由表示映射和标记函数组成。在这个设置中，大多数流行的DG方法旨在通过最小化未见域中的分类风险的已知上界共同学习表示和标记函数。然而，在实践中，基于这个理论上界的方法忽略了一个由于其对表示映射和未知最优标记函数的双重依赖关系而无法直接优化的术语。为了弥合理论与实践之间的差距，我们引入了一个新的上界，它不包含这种双重依赖性的术语，从而产生了一个可以完全优化的未见域风险上界。我们的推导利用了将最优传输度量与信息相连的经典和最近的传输不等式。",
    "tldr": "本论文提出了一个新的理论上界，它不包含双重依赖性的术语，在领域归纳中优化了未见域的风险上界。",
    "en_tdlr": "This paper proposes a new theoretical upper bound that optimizes the risk upper bound for the unseen domain in domain generalization by removing terms with dual dependence, filling the gap between theory and practice."
}