{
    "title": "Task-Oriented Communication for Multi-Device Cooperative Edge Inference. (arXiv:2109.00172v3 [eess.SP] UPDATED)",
    "abstract": "This paper investigates task-oriented communication for multi-device cooperative edge inference, where a group of distributed low-end edge devices transmit the extracted features of local samples to a powerful edge server for inference. While cooperative edge inference can overcome the limited sensing capability of a single device, it substantially increases the communication overhead and may incur excessive latency. To enable low-latency cooperative inference, we propose a learning-based communication scheme that optimizes local feature extraction and distributed feature encoding in a task-oriented manner, i.e., to remove data redundancy and transmit information that is essential for the downstream inference task rather than reconstructing the data samples at the edge server. Specifically, we leverage an information bottleneck (IB) principle to extract the task-relevant feature at each edge device and adopt a distributed information bottleneck (DIB) framework to formalize a single-let",
    "link": "http://arxiv.org/abs/2109.00172",
    "context": "Title: Task-Oriented Communication for Multi-Device Cooperative Edge Inference. (arXiv:2109.00172v3 [eess.SP] UPDATED)\nAbstract: This paper investigates task-oriented communication for multi-device cooperative edge inference, where a group of distributed low-end edge devices transmit the extracted features of local samples to a powerful edge server for inference. While cooperative edge inference can overcome the limited sensing capability of a single device, it substantially increases the communication overhead and may incur excessive latency. To enable low-latency cooperative inference, we propose a learning-based communication scheme that optimizes local feature extraction and distributed feature encoding in a task-oriented manner, i.e., to remove data redundancy and transmit information that is essential for the downstream inference task rather than reconstructing the data samples at the edge server. Specifically, we leverage an information bottleneck (IB) principle to extract the task-relevant feature at each edge device and adopt a distributed information bottleneck (DIB) framework to formalize a single-let",
    "path": "papers/21/09/2109.00172.json",
    "total_tokens": 839,
    "translated_title": "多设备合作边缘推理的任务导向通信",
    "translated_abstract": "本文研究了多设备合作边缘推理的任务导向通信，在这种场景下，一组分布式低端边缘设备将本地样本提取的特征传输到强大的边缘服务器进行推理。尽管合作边缘推理可以克服单个设备的有限感知能力，但它大大增加了通信开销并可能引起过大的延迟。为了实现低延迟的合作推理，我们提出了一种基于学习的通信方案，通过任务导向的方式优化本地特征提取和分布式特征编码，即去除数据冗余并传输对下游推理任务而言至关重要的信息，而不是在边缘服务器上重新构建数据样本。具体而言，我们利用信息瓶颈 (IB) 原理在每个边缘设备上提取任务相关特征，并采用分布式信息瓶颈 (DIB) 框架对单个样本的相关特征进行形式化处理。",
    "tldr": "本文研究了多设备合作边缘推理的任务导向通信，通过优化本地特征提取和分布式特征编码，实现低延迟的合作推理。",
    "en_tdlr": "This paper investigates task-oriented communication for multi-device cooperative edge inference, optimizing local feature extraction and distributed feature encoding to achieve low-latency cooperative inference."
}