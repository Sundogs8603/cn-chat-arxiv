{
    "title": "Axiomatic Aggregations of Abductive Explanations. (arXiv:2109.03890v4 [cs.LG] UPDATED)",
    "abstract": "The recent criticisms of the robustness of post hoc model approximation explanation methods (like LIME and SHAP) have led to the rise of model-precise abductive explanations. For each data point, abductive explanations provide a minimal subset of features that are sufficient to generate the outcome. While theoretically sound and rigorous, abductive explanations suffer from a major issue -- there can be several valid abductive explanations for the same data point. In such cases, providing a single abductive explanation can be insufficient; on the other hand, providing all valid abductive explanations can be incomprehensible due to their size. In this work, we solve this issue by aggregating the many possible abductive explanations into feature importance scores. We propose three aggregation methods: two based on power indices from cooperative game theory and a third based on a well-known measure of causal strength. We characterize these three methods axiomatically, showing that each of ",
    "link": "http://arxiv.org/abs/2109.03890",
    "context": "Title: Axiomatic Aggregations of Abductive Explanations. (arXiv:2109.03890v4 [cs.LG] UPDATED)\nAbstract: The recent criticisms of the robustness of post hoc model approximation explanation methods (like LIME and SHAP) have led to the rise of model-precise abductive explanations. For each data point, abductive explanations provide a minimal subset of features that are sufficient to generate the outcome. While theoretically sound and rigorous, abductive explanations suffer from a major issue -- there can be several valid abductive explanations for the same data point. In such cases, providing a single abductive explanation can be insufficient; on the other hand, providing all valid abductive explanations can be incomprehensible due to their size. In this work, we solve this issue by aggregating the many possible abductive explanations into feature importance scores. We propose three aggregation methods: two based on power indices from cooperative game theory and a third based on a well-known measure of causal strength. We characterize these three methods axiomatically, showing that each of ",
    "path": "papers/21/09/2109.03890.json",
    "total_tokens": 897,
    "translated_title": "《推断解释的公理聚合》",
    "translated_abstract": "对后续模型逼近解释方法（如LIME和SHAP）的鲁棒性的近期批评导致了模型精确的推断解释的兴起。对于每个数据点，推断解释提供了一个足以生成结果的最小子集特征。尽管在理论上是严格和可靠的，但推断解释存在一个主要问题：同一数据点可以有多个有效的推断解释。在这种情况下，提供一个单一的推断解释可能是不足够的；另一方面，提供所有有效的推断解释可能由于其规模而难以理解。在这项工作中，我们通过将各种可能的推断解释聚合成特征重要性分数来解决这个问题。我们提出了三种聚合方法：两种基于合作博弈理论的权力指数方法和一种基于著名的因果强度度量的方法。我们从公理上对这三种方法进行了表征，证明每个方法都是良定义的且符合公理。",
    "tldr": "本论文提出了三种聚合方法，将各种可能的推断解释聚合成特征重要性分数，解决了推断解释中多个有效解释的问题。这些方法基于合作博弈理论的权力指数和已知的因果强度度量。",
    "en_tdlr": "This paper proposes three aggregation methods to combine multiple possible abductive explanations into feature importance scores, addressing the issue of multiple valid explanations in abductive explanations. These methods are based on power indices from cooperative game theory and a well-known measure of causal strength."
}