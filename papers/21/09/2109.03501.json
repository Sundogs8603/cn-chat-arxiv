{
    "title": "How do I update my model? On the resilience of Predictive Process Monitoring models to change. (arXiv:2109.03501v2 [cs.LG] UPDATED)",
    "abstract": "Existing well investigated Predictive Process Monitoring techniques typically construct a predictive model based on past process executions, and then use it to predict the future of new ongoing cases, without the possibility of updating it with new cases when they complete their execution. This can make Predictive Process Monitoring too rigid to deal with the variability of processes working in real environments that continuously evolve and/or exhibit new variant behaviours over time. As a solution to this problem, we evaluate the use of three different strategies that allow the periodic rediscovery or incremental construction of the predictive model so as to exploit new available data. The evaluation focuses on the performance of the new learned predictive models, in terms of accuracy and time, against the original one, and uses a number of real and synthetic datasets with and without explicit Concept Drift. The results provide an evidence of the potential of incremental learning algo",
    "link": "http://arxiv.org/abs/2109.03501",
    "context": "Title: How do I update my model? On the resilience of Predictive Process Monitoring models to change. (arXiv:2109.03501v2 [cs.LG] UPDATED)\nAbstract: Existing well investigated Predictive Process Monitoring techniques typically construct a predictive model based on past process executions, and then use it to predict the future of new ongoing cases, without the possibility of updating it with new cases when they complete their execution. This can make Predictive Process Monitoring too rigid to deal with the variability of processes working in real environments that continuously evolve and/or exhibit new variant behaviours over time. As a solution to this problem, we evaluate the use of three different strategies that allow the periodic rediscovery or incremental construction of the predictive model so as to exploit new available data. The evaluation focuses on the performance of the new learned predictive models, in terms of accuracy and time, against the original one, and uses a number of real and synthetic datasets with and without explicit Concept Drift. The results provide an evidence of the potential of incremental learning algo",
    "path": "papers/21/09/2109.03501.json",
    "total_tokens": 817,
    "translated_title": "我该如何更新我的模型？关于预测过程监控模型对变化的韧性。",
    "translated_abstract": "现有的经过充分研究的预测过程监控技术通常基于过去的流程执行构建预测模型，然后使用该模型预测新进行中案例的未来，无法通过新案例的执行来更新它。这使得预测过程监控对于在不断演变和/或随时间展现新变体行为的实际环境中的过程的可变性太过僵化。为解决这个问题，我们评估了三种不同的策略，允许周期性地重新发现或增量构建预测模型，以利用新的可用数据。评估重点放在新学习的预测模型的性能上，包括准确性和时间，与原始模型进行比较，并使用了一些真实和合成的数据集，包括明确的概念漂移和没有明确的概念漂移。结果证明了增量学习算法的潜力。",
    "tldr": "本研究针对预测过程监控模型的韧性问题，评估了三种不同策略，并发现增量学习算法具有潜力来解决预测模型的更新和可变性问题。"
}