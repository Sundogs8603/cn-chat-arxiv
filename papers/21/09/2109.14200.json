{
    "title": "Can phones, syllables, and words emerge as side-products of cross-situational audiovisual learning? -- A computational investigation",
    "abstract": "arXiv:2109.14200v2 Announce Type: replace-cross  Abstract: Decades of research has studied how language learning infants learn to discriminate speech sounds, segment words, and associate words with their meanings. While gradual development of such capabilities is unquestionable, the exact nature of these skills and the underlying mental representations yet remains unclear. In parallel, computational studies have shown that basic comprehension of speech can be achieved by statistical learning between speech and concurrent referentially ambiguous visual input. These models can operate without prior linguistic knowledge such as representations of linguistic units, and without learning mechanisms specifically targeted at such units. This has raised the question of to what extent knowledge of linguistic units, such as phone(me)s, syllables, and words, could actually emerge as latent representations supporting the translation between speech and representations in other modalities, and withou",
    "link": "https://arxiv.org/abs/2109.14200",
    "context": "Title: Can phones, syllables, and words emerge as side-products of cross-situational audiovisual learning? -- A computational investigation\nAbstract: arXiv:2109.14200v2 Announce Type: replace-cross  Abstract: Decades of research has studied how language learning infants learn to discriminate speech sounds, segment words, and associate words with their meanings. While gradual development of such capabilities is unquestionable, the exact nature of these skills and the underlying mental representations yet remains unclear. In parallel, computational studies have shown that basic comprehension of speech can be achieved by statistical learning between speech and concurrent referentially ambiguous visual input. These models can operate without prior linguistic knowledge such as representations of linguistic units, and without learning mechanisms specifically targeted at such units. This has raised the question of to what extent knowledge of linguistic units, such as phone(me)s, syllables, and words, could actually emerge as latent representations supporting the translation between speech and representations in other modalities, and withou",
    "path": "papers/21/09/2109.14200.json",
    "total_tokens": 864,
    "translated_title": "手机、音节和单词能否作为跨情境视听学习的副产品而出现？-- 一项计算研究",
    "translated_abstract": "数十年的研究探讨了语言学习婴儿如何学会区分语音，分割单词，以及将单词与其含义关联起来。尽管这些能力的逐渐发展是毋庸置疑的，但这些技能的确切性质和潜在的心理表征仍然不清楚。与此同时，计算研究表明，通过语音和同时具有指称不明确的视觉输入之间的统计学习，可以实现对基本语音的理解。这些模型可以在没有诸如语言单位的表征，以及没有专门针对这些单位的学习机制的情况下运行。这引发了一个问题，即在多大程度上，类似音素、音节和单词的语言单位的知识实际上能够作为潜在表征出现，支持语音与其他形式表征之间的转换，而不需要专门的学习机制来实现。",
    "tldr": "研究探讨了语言学习中，通过跨情境视听学习，音素、音节和单词能否作为副产品出现，并支持不同形式表征间的转换。",
    "en_tdlr": "The study investigates whether phones, syllables, and words can emerge as side-products in language learning through cross-situational audiovisual learning, supporting the translation between different forms of representations."
}