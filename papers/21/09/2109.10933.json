{
    "title": "On the equivalence of different adaptive batch size selection strategies for stochastic gradient descent methods. (arXiv:2109.10933v2 [math.OC] UPDATED)",
    "abstract": "In this study, we demonstrate that the norm test and inner product/orthogonality test presented in \\cite{Bol18} are equivalent in terms of the convergence rates associated with Stochastic Gradient Descent (SGD) methods if $\\epsilon^2=\\theta^2+\\nu^2$ with specific choices of $\\theta$ and $\\nu$. Here, $\\epsilon$ controls the relative statistical error of the norm of the gradient while $\\theta$ and $\\nu$ control the relative statistical error of the gradient in the direction of the gradient and in the direction orthogonal to the gradient, respectively. Furthermore, we demonstrate that the inner product/orthogonality test can be as inexpensive as the norm test in the best case scenario if $\\theta$ and $\\nu$ are optimally selected, but the inner product/orthogonality test will never be more computationally affordable than the norm test if $\\epsilon^2=\\theta^2+\\nu^2$. Finally, we present two stochastic optimization problems to illustrate our results.",
    "link": "http://arxiv.org/abs/2109.10933",
    "context": "Title: On the equivalence of different adaptive batch size selection strategies for stochastic gradient descent methods. (arXiv:2109.10933v2 [math.OC] UPDATED)\nAbstract: In this study, we demonstrate that the norm test and inner product/orthogonality test presented in \\cite{Bol18} are equivalent in terms of the convergence rates associated with Stochastic Gradient Descent (SGD) methods if $\\epsilon^2=\\theta^2+\\nu^2$ with specific choices of $\\theta$ and $\\nu$. Here, $\\epsilon$ controls the relative statistical error of the norm of the gradient while $\\theta$ and $\\nu$ control the relative statistical error of the gradient in the direction of the gradient and in the direction orthogonal to the gradient, respectively. Furthermore, we demonstrate that the inner product/orthogonality test can be as inexpensive as the norm test in the best case scenario if $\\theta$ and $\\nu$ are optimally selected, but the inner product/orthogonality test will never be more computationally affordable than the norm test if $\\epsilon^2=\\theta^2+\\nu^2$. Finally, we present two stochastic optimization problems to illustrate our results.",
    "path": "papers/21/09/2109.10933.json",
    "total_tokens": 925,
    "translated_title": "关于随机梯度下降方法的不同自适应批量大小选择策略的等价性研究",
    "translated_abstract": "本研究证明了在特定选择的Θ和ν下，\\cite{Bol18}中提出的范数测试和内积/正交性测试在随机梯度下降方法的收敛速度方面是等价的，其中ϵ²=θ²+ν²。这里，ϵ控制梯度范数的相对统计误差，而θ和ν分别控制梯度在梯度方向和梯度正交方向上的相对统计误差。此外，我们证明了在最理想情况下，内积/正交性测试可以像范数测试一样廉价，如果θ和ν被最优选择，但是如果ϵ²=θ²+ν²，内积/正交性测试永远不会比范数测试更具计算可承受性。最后，我们提供了两个随机优化问题来说明我们的结果。",
    "tldr": "本研究证明了在特定选择的Θ和ν下，范数测试和内积/正交性测试在随机梯度下降方法的收敛速度方面是等价的，同时指出在最理想情况下，内积/正交性测试可以像范数测试一样廉价。",
    "en_tdlr": "This study demonstrates the equivalence of norm testing and inner product/orthogonality testing in terms of convergence rates for stochastic gradient descent methods, under specific choices of θ and ν. It also highlights that in the best case scenario, inner product/orthogonality testing can be as inexpensive as norm testing."
}