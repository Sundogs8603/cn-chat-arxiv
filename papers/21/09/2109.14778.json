{
    "title": "CALDA: Improving Multi-Source Time Series Domain Adaptation with Contrastive Adversarial Learning. (arXiv:2109.14778v2 [cs.LG] UPDATED)",
    "abstract": "Unsupervised domain adaptation (UDA) provides a strategy for improving machine learning performance in data-rich (target) domains where ground truth labels are inaccessible but can be found in related (source) domains. In cases where meta-domain information such as label distributions is available, weak supervision can further boost performance. We propose a novel framework, CALDA, to tackle these two problems. CALDA synergistically combines the principles of contrastive learning and adversarial learning to robustly support multi-source UDA (MS-UDA) for time series data. Similar to prior methods, CALDA utilizes adversarial learning to align source and target feature representations. Unlike prior approaches, CALDA additionally leverages cross-source label information across domains. CALDA pulls examples with the same label close to each other, while pushing apart examples with different labels, reshaping the space through contrastive learning. Unlike prior contrastive adaptation methods",
    "link": "http://arxiv.org/abs/2109.14778",
    "context": "Title: CALDA: Improving Multi-Source Time Series Domain Adaptation with Contrastive Adversarial Learning. (arXiv:2109.14778v2 [cs.LG] UPDATED)\nAbstract: Unsupervised domain adaptation (UDA) provides a strategy for improving machine learning performance in data-rich (target) domains where ground truth labels are inaccessible but can be found in related (source) domains. In cases where meta-domain information such as label distributions is available, weak supervision can further boost performance. We propose a novel framework, CALDA, to tackle these two problems. CALDA synergistically combines the principles of contrastive learning and adversarial learning to robustly support multi-source UDA (MS-UDA) for time series data. Similar to prior methods, CALDA utilizes adversarial learning to align source and target feature representations. Unlike prior approaches, CALDA additionally leverages cross-source label information across domains. CALDA pulls examples with the same label close to each other, while pushing apart examples with different labels, reshaping the space through contrastive learning. Unlike prior contrastive adaptation methods",
    "path": "papers/21/09/2109.14778.json",
    "total_tokens": 901,
    "translated_title": "CALDA:改进多源时间序列域自适应方法与对比对抗学习",
    "translated_abstract": "无监督域自适应（UDA）提供了一种策略，用于改进数据丰富（目标）领域中机器学习性能，在这些领域中无法获得地面真实标签，但可以在相关（源）领域中找到。在具有元领域信息（如标签分布）的情况下，弱监督可以进一步提升性能。我们提出了一个新颖的框架CALDA来解决这两个问题。CALDA通过对比学习和对抗学习的原则，为时间序列数据的多源域自适应（MS-UDA）提供了强大的支持。与以前的方法类似，CALDA利用对抗学习来对齐源和目标特征表示。与以前的方法不同，CALDA还利用了跨域的跨源标签信息。CALDA将具有相同标签的示例彼此靠近，而将具有不同标签的示例分开，通过对比学习来重新塑造空间。与以前的对比自适应方法不同",
    "tldr": "CALDA是一种新颖的框架，使用对比学习和对抗学习的原则来提高多源时间序列域自适应方法。它通过对齐特征表示和利用跨域标签信息来提高性能。"
}