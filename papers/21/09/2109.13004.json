{
    "title": "Optimising for Interpretability: Convolutional Dynamic Alignment Networks. (arXiv:2109.13004v2 [stat.ML] UPDATED)",
    "abstract": "We introduce a new family of neural network models called Convolutional Dynamic Alignment Networks (CoDA Nets), which are performant classifiers with a high degree of inherent interpretability. Their core building blocks are Dynamic Alignment Units (DAUs), which are optimised to transform their inputs with dynamically computed weight vectors that align with task-relevant patterns. As a result, CoDA Nets model the classification prediction through a series of input-dependent linear transformations, allowing for linear decomposition of the output into individual input contributions. Given the alignment of the DAUs, the resulting contribution maps align with discriminative input patterns. These model-inherent decompositions are of high visual quality and outperform existing attribution methods under quantitative metrics. Further, CoDA Nets constitute performant classifiers, achieving on par results to ResNet and VGG models on e.g. CIFAR-10 and TinyImagenet. Lastly, CoDA Nets can be combin",
    "link": "http://arxiv.org/abs/2109.13004",
    "context": "Title: Optimising for Interpretability: Convolutional Dynamic Alignment Networks. (arXiv:2109.13004v2 [stat.ML] UPDATED)\nAbstract: We introduce a new family of neural network models called Convolutional Dynamic Alignment Networks (CoDA Nets), which are performant classifiers with a high degree of inherent interpretability. Their core building blocks are Dynamic Alignment Units (DAUs), which are optimised to transform their inputs with dynamically computed weight vectors that align with task-relevant patterns. As a result, CoDA Nets model the classification prediction through a series of input-dependent linear transformations, allowing for linear decomposition of the output into individual input contributions. Given the alignment of the DAUs, the resulting contribution maps align with discriminative input patterns. These model-inherent decompositions are of high visual quality and outperform existing attribution methods under quantitative metrics. Further, CoDA Nets constitute performant classifiers, achieving on par results to ResNet and VGG models on e.g. CIFAR-10 and TinyImagenet. Lastly, CoDA Nets can be combin",
    "path": "papers/21/09/2109.13004.json",
    "total_tokens": 961,
    "translated_title": "优化可解释性：卷积动态对齐网络",
    "translated_abstract": "我们引入了一种新的神经网络模型，称为卷积动态对齐网络（CoDA Nets），它是一种具有高度内在可解释性的性能分类器。它们的核心构建模块是动态对齐单元（DAUs），其经过优化后能够通过动态计算的权重向量将其输入转换为与任务相关模式对齐的形式。因此，CoDA Nets通过一系列依赖于输入的线性变换来模拟分类预测，允许将输出线性分解为各个输入的贡献。根据DAUs的对齐情况，得到的贡献映射与鉴别性输入模式相一致。这些模型固有的分解具有很高的视觉质量，在定量指标下优于现有的归因方法。此外，CoDA Nets是性能出色的分类器，在CIFAR-10和TinyImagenet等数据集上取得了与ResNet和VGG模型相媲美的结果。",
    "tldr": "CoDA Nets是一种性能良好的分类器，具有高度内在可解释性。它们通过动态对齐单元实现输入依赖的线性变换，并将输出线性分解为各个输入的贡献。这些模型在视觉质量和分类准确度上优于现有方法，并且在CIFAR-10和TinyImagenet等数据集上表现出与ResNet和VGG模型相媲美的性能。"
}