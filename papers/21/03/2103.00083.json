{
    "title": "Flexible Model Aggregation for Quantile Regression. (arXiv:2103.00083v5 [stat.ML] UPDATED)",
    "abstract": "Quantile regression is a fundamental problem in statistical learning motivated by a need to quantify uncertainty in predictions, or to model a diverse population without being overly reductive. For instance, epidemiological forecasts, cost estimates, and revenue predictions all benefit from being able to quantify the range of possible values accurately. As such, many models have been developed for this problem over many years of research in statistics, machine learning, and related fields. Rather than proposing yet another (new) algorithm for quantile regression we adopt a meta viewpoint: we investigate methods for aggregating any number of conditional quantile models, in order to improve accuracy and robustness. We consider weighted ensembles where weights may vary over not only individual models, but also over quantile levels, and feature values. All of the models we consider in this paper can be fit using modern deep learning toolkits, and hence are widely accessible (from an implem",
    "link": "http://arxiv.org/abs/2103.00083",
    "context": "Title: Flexible Model Aggregation for Quantile Regression. (arXiv:2103.00083v5 [stat.ML] UPDATED)\nAbstract: Quantile regression is a fundamental problem in statistical learning motivated by a need to quantify uncertainty in predictions, or to model a diverse population without being overly reductive. For instance, epidemiological forecasts, cost estimates, and revenue predictions all benefit from being able to quantify the range of possible values accurately. As such, many models have been developed for this problem over many years of research in statistics, machine learning, and related fields. Rather than proposing yet another (new) algorithm for quantile regression we adopt a meta viewpoint: we investigate methods for aggregating any number of conditional quantile models, in order to improve accuracy and robustness. We consider weighted ensembles where weights may vary over not only individual models, but also over quantile levels, and feature values. All of the models we consider in this paper can be fit using modern deep learning toolkits, and hence are widely accessible (from an implem",
    "path": "papers/21/03/2103.00083.json",
    "total_tokens": 796,
    "translated_title": "灵活的模型聚合方法用于分位数回归",
    "translated_abstract": "分位数回归是一种用于统计学习的基本问题，旨在量化预测的不确定性，或在不过度简化的情况下对多样化人群建模。本文研究聚合任意数量的条件分位数模型的方法，以提高准确性和鲁棒性，并考虑权重集成，权重不仅可以变化于单个模型，还可以变化于分位数水平和特征值。本文所考虑的所有模型均可使用现代深度学习工具包拟合，因此对许多从业者具有广泛的适用性（从实现的角度来看）。",
    "tldr": "本文研究聚合条件分位数模型的方法，提高分位数回归的准确性和鲁棒性，并提出了能够应用于现代深度学习工具包的多种模型，对许多从业者具有广泛的适用性。",
    "en_tdlr": "This paper investigates methods for aggregating conditional quantile models to improve the accuracy and robustness of quantile regression, and proposes multiple models that can be applied using modern deep learning toolkits, making them widely applicable to practitioners."
}