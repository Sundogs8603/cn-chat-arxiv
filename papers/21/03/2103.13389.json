{
    "title": "Generating Novel Scene Compositions from Single Images and Videos. (arXiv:2103.13389v4 [cs.CV] UPDATED)",
    "abstract": "Given a large dataset for training, generative adversarial networks (GANs) can achieve remarkable performance for the image synthesis task. However, training GANs in extremely low data regimes remains a challenge, as overfitting often occurs, leading to memorization or training divergence. In this work, we introduce SIV-GAN, an unconditional generative model that can generate new scene compositions from a single training image or a single video clip. We propose a two-branch discriminator architecture, with content and layout branches designed to judge internal content and scene layout realism separately from each other. This discriminator design enables synthesis of visually plausible, novel compositions of a scene, with varying content and layout, while preserving the context of the original sample. Compared to previous single image GANs, our model generates more diverse, higher quality images, while not being restricted to a single image setting. We further introduce a new challengin",
    "link": "http://arxiv.org/abs/2103.13389",
    "context": "Title: Generating Novel Scene Compositions from Single Images and Videos. (arXiv:2103.13389v4 [cs.CV] UPDATED)\nAbstract: Given a large dataset for training, generative adversarial networks (GANs) can achieve remarkable performance for the image synthesis task. However, training GANs in extremely low data regimes remains a challenge, as overfitting often occurs, leading to memorization or training divergence. In this work, we introduce SIV-GAN, an unconditional generative model that can generate new scene compositions from a single training image or a single video clip. We propose a two-branch discriminator architecture, with content and layout branches designed to judge internal content and scene layout realism separately from each other. This discriminator design enables synthesis of visually plausible, novel compositions of a scene, with varying content and layout, while preserving the context of the original sample. Compared to previous single image GANs, our model generates more diverse, higher quality images, while not being restricted to a single image setting. We further introduce a new challengin",
    "path": "papers/21/03/2103.13389.json",
    "total_tokens": 929,
    "translated_title": "从单个图像和视频中生成新颖的场景组合",
    "translated_abstract": "在训练数据集较大的情况下，生成对抗网络（GAN）可以在图像合成任务中取得显著的性能。然而，在极低数据环境中训练GAN仍然是一个挑战，因为往往会发生过拟合，导致记忆或训练发散。在本研究中，我们引入了SIV-GAN，这是一个无条件的生成模型，可以从单个训练图像或单个视频剪辑中生成新的场景组合。我们提出了一个具有内容和布局分支的两支鉴别器架构，分别设计用于判断内部内容和场景布局的真实性。这种鉴别器设计可以合成视觉上逼真、新颖的场景组合，具有不同的内容和布局，同时保留原始样本的上下文。与以前的单图像GAN相比，我们的模型生成了更多样化、质量更高的图像，同时不限于单个图像设置。我们进一步引入了一种新的具有挑战性的情况",
    "tldr": "本研究提出了SIV-GAN，一种无条件生成模型，可以从单个图像或视频中生成新的场景组合。通过引入内容和布局分支的鉴别器架构，该模型能够生成多样化、高质量的图像，并在保留上下文的同时保持视觉逼真。",
    "en_tdlr": "This paper introduces SIV-GAN, an unconditional generative model that can generate new scene compositions from a single image or video. By utilizing a two-branch discriminator architecture, the model is able to generate diverse and high-quality images while preserving the visual realism and context of the original sample."
}