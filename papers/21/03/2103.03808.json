{
    "title": "Two-step reinforcement learning for model-free redesign of nonlinear optimal regulator. (arXiv:2103.03808v3 [eess.SY] UPDATED)",
    "abstract": "In many practical control applications, the performance level of a closed-loop system degrades over time due to the change of plant characteristics. Thus, there is a strong need for redesigning a controller without going through the system modeling process, which is often difficult for closed-loop systems. Reinforcement learning (RL) is one of the promising approaches that enable model-free redesign of optimal controllers for nonlinear dynamical systems based only on the measurement of the closed-loop system. However, the learning process of RL usually requires a considerable number of trial-and-error experiments using the poorly controlled system that may accumulate wear on the plant. To overcome this limitation, we propose a model-free two-step design approach that improves the transient learning performance of RL in an optimal regulator redesign problem for unknown nonlinear systems. Specifically, we first design a linear control law that attains some degree of control performance i",
    "link": "http://arxiv.org/abs/2103.03808",
    "context": "Title: Two-step reinforcement learning for model-free redesign of nonlinear optimal regulator. (arXiv:2103.03808v3 [eess.SY] UPDATED)\nAbstract: In many practical control applications, the performance level of a closed-loop system degrades over time due to the change of plant characteristics. Thus, there is a strong need for redesigning a controller without going through the system modeling process, which is often difficult for closed-loop systems. Reinforcement learning (RL) is one of the promising approaches that enable model-free redesign of optimal controllers for nonlinear dynamical systems based only on the measurement of the closed-loop system. However, the learning process of RL usually requires a considerable number of trial-and-error experiments using the poorly controlled system that may accumulate wear on the plant. To overcome this limitation, we propose a model-free two-step design approach that improves the transient learning performance of RL in an optimal regulator redesign problem for unknown nonlinear systems. Specifically, we first design a linear control law that attains some degree of control performance i",
    "path": "papers/21/03/2103.03808.json",
    "total_tokens": 873,
    "translated_title": "两步强化学习用于非线性最优调节器无模型重新设计",
    "translated_abstract": "在许多实际控制应用中，闭环系统的性能随着工厂特性的改变而随时间降低。因此，需要重新设计控制器，而不需要进行系统建模过程，这对于闭环系统来说通常是困难的。强化学习（RL）是一种有前途的方法，它使非线性动态系统的无模型最优控制器可以仅基于闭环系统测量数据重新设计。然而，RL的学习过程通常需要使用控制不良的系统进行相当数量的试错实验，这可能会加速工厂的磨损。为了克服这个限制，我们提出了一种无模型的两步设计方法，它提高了RL在未知非线性系统的最优调节器重新设计问题中的暂态学习性能。具体来说，我们首先设计了一个线性控制律，以实现一定程度的控制性能",
    "tldr": "强化学习可以无模型地重新设计针对非线性系统的最优控制器。为了提高学习性能并减少实验次数，提出了一个无模型的两步设计方法，先设计线性控制律达到初步控制，再使用强化学习进一步优化。",
    "en_tdlr": "Reinforcement learning can redesign optimal controllers for nonlinear systems without model. To improve the learning performance and reduce experimentation, a two-step model-free design approach is proposed, which first designs a linear control law for preliminary control and then uses RL for further optimization."
}