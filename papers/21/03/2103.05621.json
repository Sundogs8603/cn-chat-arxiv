{
    "title": "The Common Intuition to Transfer Learning Can Win or Lose: Case Studies for Linear Regression. (arXiv:2103.05621v3 [cs.LG] UPDATED)",
    "abstract": "We study a fundamental transfer learning process from source to target linear regression tasks, including overparameterized settings where there are more learned parameters than data samples. The target task learning is addressed by using its training data together with the parameters previously computed for the source task. We define a transfer learning approach to the target task as a linear regression optimization with a regularization on the distance between the to-be-learned target parameters and the already-learned source parameters. We analytically characterize the generalization performance of our transfer learning approach and demonstrate its ability to resolve the peak in generalization errors in double descent phenomena of the minimum L2-norm solution to linear regression. Moreover, we show that for sufficiently related tasks, the optimally tuned transfer learning approach can outperform the optimally tuned ridge regression method, even when the true parameter vector conform",
    "link": "http://arxiv.org/abs/2103.05621",
    "context": "Title: The Common Intuition to Transfer Learning Can Win or Lose: Case Studies for Linear Regression. (arXiv:2103.05621v3 [cs.LG] UPDATED)\nAbstract: We study a fundamental transfer learning process from source to target linear regression tasks, including overparameterized settings where there are more learned parameters than data samples. The target task learning is addressed by using its training data together with the parameters previously computed for the source task. We define a transfer learning approach to the target task as a linear regression optimization with a regularization on the distance between the to-be-learned target parameters and the already-learned source parameters. We analytically characterize the generalization performance of our transfer learning approach and demonstrate its ability to resolve the peak in generalization errors in double descent phenomena of the minimum L2-norm solution to linear regression. Moreover, we show that for sufficiently related tasks, the optimally tuned transfer learning approach can outperform the optimally tuned ridge regression method, even when the true parameter vector conform",
    "path": "papers/21/03/2103.05621.json",
    "total_tokens": 960,
    "translated_title": "传输学习的共同直觉可以带来胜利或失败: 线性回归案例研究",
    "translated_abstract": "我们研究了从源回归任务到目标回归任务的基本传输学习过程，包括在有比数据样本更多的学习参数的过参数化设置中。目标任务的学习通过使用其训练数据和先前计算的源任务参数来解决。我们将目标任务的传输学习方法定义为带有正则化的线性回归优化，其中正则化项是待学习的目标参数与已学习的源参数之间的距离。我们分析地表征了我们的传输学习方法的泛化性能，并展示了它解决线性回归的最小L2范数解中的泛化误差峰值的能力。此外，我们证明了对于足够相关的任务来说，经过最佳调优的传输学习方法可以胜过最佳调优的岭回归方法，即使真实参数向量符合最小L2范数解。",
    "tldr": "本论文研究了传输学习的基本过程，针对线性回归任务，通过利用源任务参数和目标任务训练数据，提出了一种传输学习方法。我们分析了该方法的泛化性能，并展示了其在解决线性回归中的泛化误差峰值方面的能力。此外，我们证明了在足够相关的任务中，该传输学习方法可以优于岭回归方法。",
    "en_tdlr": "This paper investigates the fundamental process of transfer learning for linear regression tasks, proposing a transfer learning approach that utilizes source task parameters and target task training data. The authors analyze the generalization performance of this approach and demonstrate its ability to address the peak in generalization errors in linear regression. Additionally, they show that for sufficiently related tasks, the optimized transfer learning approach outperforms ridge regression."
}