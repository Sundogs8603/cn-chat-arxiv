{
    "title": "Human-Inspired Multi-Agent Navigation using Knowledge Distillation. (arXiv:2103.10000v5 [cs.RO] UPDATED)",
    "abstract": "Despite significant advancements in the field of multi-agent navigation, agents still lack the sophistication and intelligence that humans exhibit in multi-agent settings. In this paper, we propose a framework for learning a human-like general collision avoidance policy for agent-agent interactions in fully decentralized, multi-agent environments. Our approach uses knowledge distillation with reinforcement learning to shape the reward function based on expert policies extracted from human trajectory demonstrations through behavior cloning. We show that agents trained with our approach can take human-like trajectories in collision avoidance and goal-directed steering tasks not provided by the demonstrations, outperforming the experts as well as learning-based agents trained without knowledge distillation.",
    "link": "http://arxiv.org/abs/2103.10000",
    "context": "Title: Human-Inspired Multi-Agent Navigation using Knowledge Distillation. (arXiv:2103.10000v5 [cs.RO] UPDATED)\nAbstract: Despite significant advancements in the field of multi-agent navigation, agents still lack the sophistication and intelligence that humans exhibit in multi-agent settings. In this paper, we propose a framework for learning a human-like general collision avoidance policy for agent-agent interactions in fully decentralized, multi-agent environments. Our approach uses knowledge distillation with reinforcement learning to shape the reward function based on expert policies extracted from human trajectory demonstrations through behavior cloning. We show that agents trained with our approach can take human-like trajectories in collision avoidance and goal-directed steering tasks not provided by the demonstrations, outperforming the experts as well as learning-based agents trained without knowledge distillation.",
    "path": "papers/21/03/2103.10000.json",
    "total_tokens": 867,
    "translated_title": "基于知识蒸馏的人类启发多智能体导航",
    "translated_abstract": "尽管多智能体导航领域取得了显著进展，但智能体在多智能体环境中仍缺乏人类所展示的复杂性和智能。本文提出了一种学习人类般普遍的碰撞避免策略的框架，用于处理完全分散的多智能体环境中的智能体-智能体交互。我们的方法使用强化学习的知识蒸馏，根据通过行为克隆从人类轨迹演示中提取的专家策略来确定奖励函数。我们证明，通过我们的方法训练的智能体可以在碰撞避免和目标导向转向任务中采取人类般的轨迹，超过了专家和未经知识蒸馏训练的基于学习的智能体。",
    "tldr": "本文提出了一种基于知识蒸馏的框架，用于在多智能体环境中训练智能体采取人类般的碰撞避免策略。实验证明，通过该方法训练的智能体可以超越专家和未经知识蒸馏训练的智能体，在碰撞避免和目标导向转向任务中表现出优异的能力。",
    "en_tdlr": "This paper proposes a framework for training agents to adopt human-like collision avoidance strategies in multi-agent environments using knowledge distillation. The experiments show that agents trained with this approach outperform experts and learning-based agents in collision avoidance and goal-directed steering tasks."
}