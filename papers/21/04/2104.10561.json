{
    "title": "Covert Channel Attack to Federated Learning Systems. (arXiv:2104.10561v2 [cs.CR] UPDATED)",
    "abstract": "Federated learning (FL) goes beyond traditional, centralized machine learning by distributing model training among a large collection of edge clients. These clients cooperatively train a global, e.g., cloud-hosted, model without disclosing their local, private training data. The global model is then shared among all the participants which use it for local predictions. In this paper, we put forward a novel attacker model aiming at turning FL systems into covert channels to implement a stealth communication infrastructure. The main intuition is that, during federated training, a malicious sender can poison the global model by submitting purposely crafted examples. Although the effect of the model poisoning is negligible to other participants, and does not alter the overall model performance, it can be observed by a malicious receiver and used to transmit a single bit.",
    "link": "http://arxiv.org/abs/2104.10561",
    "context": "Title: Covert Channel Attack to Federated Learning Systems. (arXiv:2104.10561v2 [cs.CR] UPDATED)\nAbstract: Federated learning (FL) goes beyond traditional, centralized machine learning by distributing model training among a large collection of edge clients. These clients cooperatively train a global, e.g., cloud-hosted, model without disclosing their local, private training data. The global model is then shared among all the participants which use it for local predictions. In this paper, we put forward a novel attacker model aiming at turning FL systems into covert channels to implement a stealth communication infrastructure. The main intuition is that, during federated training, a malicious sender can poison the global model by submitting purposely crafted examples. Although the effect of the model poisoning is negligible to other participants, and does not alter the overall model performance, it can be observed by a malicious receiver and used to transmit a single bit.",
    "path": "papers/21/04/2104.10561.json",
    "total_tokens": 810,
    "translated_title": "对联邦学习系统的隐蔽信道攻击",
    "translated_abstract": "联邦学习通过在众多边缘客户端之间分布模型训练，超越了传统的集中式机器学习。这些客户端合作训练一个全局模型，而不会泄露他们的本地私有训练数据。然后，全局模型在所有参与者之间共享，用于本地预测。本文提出了一个新颖的攻击模型，旨在将联邦学习系统转化为隐蔽信道，实现隐秘的通信基础设施。主要思想是，在联邦训练期间，恶意发送者可以通过提交专门构造的样本来污染全局模型。虽然模型污染对其他参与者影响几乎可以忽略不计，也不会改变整体模型性能，但它可以被恶意接收者观察到，并用于传输一个比特位。",
    "tldr": "这篇论文介绍了一种针对联邦学习系统的新型攻击模型，通过在联邦训练期间污染全局模型实现隐蔽通信，而不影响模型性能。",
    "en_tdlr": "This paper presents a novel attack model against federated learning systems, where the global model is poisoned during federated training to enable covert communication without affecting model performance."
}