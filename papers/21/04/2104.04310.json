{
    "title": "Context-self contrastive pretraining for crop type semantic segmentation",
    "abstract": "In this paper, we propose a fully supervised pre-training scheme based on contrastive learning particularly tailored to dense classification tasks. The proposed Context-Self Contrastive Loss (CSCL) learns an embedding space that makes semantic boundaries pop-up by use of a similarity metric between every location in a training sample and its local context. For crop type semantic segmentation from Satellite Image Time Series (SITS) we find performance at parcel boundaries to be a critical bottleneck and explain how CSCL tackles the underlying cause of that problem, improving the state-of-the-art performance in this task. Additionally, using images from the Sentinel-2 (S2) satellite missions we compile the largest, to our knowledge, SITS dataset densely annotated by crop type and parcel identities, which we make publicly available together with the data generation pipeline. Using that data we find CSCL, even with minimal pre-training, to improve all respective baselines and present a pro",
    "link": "https://arxiv.org/abs/2104.04310",
    "context": "Title: Context-self contrastive pretraining for crop type semantic segmentation\nAbstract: In this paper, we propose a fully supervised pre-training scheme based on contrastive learning particularly tailored to dense classification tasks. The proposed Context-Self Contrastive Loss (CSCL) learns an embedding space that makes semantic boundaries pop-up by use of a similarity metric between every location in a training sample and its local context. For crop type semantic segmentation from Satellite Image Time Series (SITS) we find performance at parcel boundaries to be a critical bottleneck and explain how CSCL tackles the underlying cause of that problem, improving the state-of-the-art performance in this task. Additionally, using images from the Sentinel-2 (S2) satellite missions we compile the largest, to our knowledge, SITS dataset densely annotated by crop type and parcel identities, which we make publicly available together with the data generation pipeline. Using that data we find CSCL, even with minimal pre-training, to improve all respective baselines and present a pro",
    "path": "papers/21/04/2104.04310.json",
    "total_tokens": 928,
    "translated_title": "农作物类型语义分割的上下文自对比预训练",
    "translated_abstract": "本文提出了一种基于对比学习的全监督预训练方案，特别适用于密集分类任务。所提出的Context-Self对比损失（CSCL）通过在训练样本的每个位置和其局部上下文之间使用相似度度量来学习嵌入空间，使语义边界突出。针对卫星图像时间序列（SITS）中的农作物类型语义分割，我们发现地块边界的性能是一个关键瓶颈，并解释了CSCL如何解决该问题的潜在原因，改进了这一任务的最新技术表现。此外，我们利用来自Sentinel-2（S2）卫星任务的图像编制了目前我们所知的最大的密集注释的农作物类型和地块身份的SITS数据集，并将其连同数据生成流程公开。使用该数据，我们发现即使是最小的预训练，CSCL也能提高所有相应基准线，并展示一个先进的性能结果。",
    "tldr": "这项研究提出了一种针对农作物类型语义分割任务的上下文自对比预训练方法，通过学习嵌入空间的相似度度量，突出语义边界。实验结果表明，这种方法改善了该任务的最新技术表现，并提供了一个大规模的密集注释数据集以及数据生成流程。"
}