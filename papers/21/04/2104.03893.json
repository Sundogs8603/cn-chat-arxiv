{
    "title": "Multimodal Fusion of EMG and Vision for Human Grasp Intent Inference in Prosthetic Hand Control. (arXiv:2104.03893v4 [cs.RO] UPDATED)",
    "abstract": "Objective: For lower arm amputees, robotic prosthetic hands promise to regain the capability to perform daily living activities. Current control methods based on physiological signals such as electromyography (EMG) are prone to yielding poor inference outcomes due to motion artifacts, muscle fatigue, and many more. Vision sensors are a major source of information about the environment state and can play a vital role in inferring feasible and intended gestures. However, visual evidence is also susceptible to its own artifacts, most often due to object occlusion, lighting changes, etc. Multimodal evidence fusion using physiological and vision sensor measurements is a natural approach due to the complementary strengths of these modalities. Methods: In this paper, we present a Bayesian evidence fusion framework for grasp intent inference using eye-view video, eye-gaze, and EMG from the forearm processed by neural network models. We analyze individual and fused performance as a function of ",
    "link": "http://arxiv.org/abs/2104.03893",
    "context": "Title: Multimodal Fusion of EMG and Vision for Human Grasp Intent Inference in Prosthetic Hand Control. (arXiv:2104.03893v4 [cs.RO] UPDATED)\nAbstract: Objective: For lower arm amputees, robotic prosthetic hands promise to regain the capability to perform daily living activities. Current control methods based on physiological signals such as electromyography (EMG) are prone to yielding poor inference outcomes due to motion artifacts, muscle fatigue, and many more. Vision sensors are a major source of information about the environment state and can play a vital role in inferring feasible and intended gestures. However, visual evidence is also susceptible to its own artifacts, most often due to object occlusion, lighting changes, etc. Multimodal evidence fusion using physiological and vision sensor measurements is a natural approach due to the complementary strengths of these modalities. Methods: In this paper, we present a Bayesian evidence fusion framework for grasp intent inference using eye-view video, eye-gaze, and EMG from the forearm processed by neural network models. We analyze individual and fused performance as a function of ",
    "path": "papers/21/04/2104.03893.json",
    "total_tokens": 917,
    "translated_title": "人工智能假肢手控制中的肌电和视觉多模态融合",
    "translated_abstract": "目标：对于下肢截肢者，使用机器人假肢手可以恢复进行日常生活活动的能力。目前基于生理信号（如肌电）的控制方法容易因为运动伪迹、肌肉疲劳等原因导致推理结果不佳。视觉传感器是关于环境状态的重要信息来源，可以在推断可行和预期手势方面发挥重要作用。然而，视觉证据也容易受到自身伪迹的影响，最常见的原因是物体遮挡、光照变化等。使用生理和视觉传感器测量的多模态证据融合是一种自然的方法，因为这些模态具有互补的优势。方法：在本文中，我们提出了一个贝叶斯证据融合框架，用于使用眼睛视图视频、注视眼动和肌电从前臂进行握持意图推理。我们分析了个体和融合性能与某些因素的关系。",
    "tldr": "本文提出了一种使用眼睛视图视频、注视眼动和肌电进行握持意图推理的贝叶斯证据融合框架，在人工智能假肢手控制中具有重要应用价值。"
}