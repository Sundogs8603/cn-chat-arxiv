{
    "title": "The Factual Inconsistency Problem in Abstractive Text Summarization: A Survey. (arXiv:2104.14839v3 [cs.CL] UPDATED)",
    "abstract": "Recently, various neural encoder-decoder models pioneered by Seq2Seq framework have been proposed to achieve the goal of generating more abstractive summaries by learning to map input text to output text. At a high level, such neural models can freely generate summaries without any constraint on the words or phrases used. Moreover, their format is closer to human-edited summaries and output is more readable and fluent. However, the neural model's abstraction ability is a double-edged sword. A commonly observed problem with the generated summaries is the distortion or fabrication of factual information in the article. This inconsistency between the original text and the summary has caused various concerns over its applicability, and the previous evaluation methods of text summarization are not suitable for this issue. In response to the above problems, the current research direction is predominantly divided into two categories, one is to design fact-aware evaluation metrics to select ou",
    "link": "http://arxiv.org/abs/2104.14839",
    "context": "Title: The Factual Inconsistency Problem in Abstractive Text Summarization: A Survey. (arXiv:2104.14839v3 [cs.CL] UPDATED)\nAbstract: Recently, various neural encoder-decoder models pioneered by Seq2Seq framework have been proposed to achieve the goal of generating more abstractive summaries by learning to map input text to output text. At a high level, such neural models can freely generate summaries without any constraint on the words or phrases used. Moreover, their format is closer to human-edited summaries and output is more readable and fluent. However, the neural model's abstraction ability is a double-edged sword. A commonly observed problem with the generated summaries is the distortion or fabrication of factual information in the article. This inconsistency between the original text and the summary has caused various concerns over its applicability, and the previous evaluation methods of text summarization are not suitable for this issue. In response to the above problems, the current research direction is predominantly divided into two categories, one is to design fact-aware evaluation metrics to select ou",
    "path": "papers/21/04/2104.14839.json",
    "total_tokens": 879,
    "translated_title": "摘要文本自动概括中的事实不一致问题：综述",
    "translated_abstract": "最近，一些基于Seq2Seq框架的神经编解码模型被提出来，用于将输入转化为更为抽象的摘要文本。这些神经模型可以自由地生成摘要，没有对所使用单词或短语的任何限制，其格式更接近于人工编辑的摘要，输出更易读，流畅自然。然而，神经模型的抽象化能力是一把双刃剑。所生成摘要中常见的问题是文章事实性信息的扭曲或捏造。原文本和摘要的不一致性引起了各种关于其适用性的担忧，以及针对文本摘要的先前评估方法并不能解决这个问题。为了解决上述问题，当前的研究方向主要分为两类，一类是设计事实感知的评估指标来选择优秀的摘要文本，",
    "tldr": "摘要文本自动概括模型的抽象化能力对于生成准确摘要文本是双刃剑，研究主要关注设计事实感知的评估指标和改进模型的训练以减少事实不一致问题。",
    "en_tdlr": "Neural models for abstractive text summarization have the potential to generate more readable and fluent summaries. However, factual inconsistency between the original text and the summary is a commonly observed problem. Current research is focused on designing fact-aware evaluation metrics and improving model training to reduce this issue."
}