{
    "title": "Diverse Gaussian Noise Consistency Regularization for Robustness and Uncertainty Calibration. (arXiv:2104.01231v6 [cs.LG] UPDATED)",
    "abstract": "Deep neural networks achieve high prediction accuracy when the train and test distributions coincide. In practice though, various types of corruptions occur which deviate from this setup and cause severe performance degradations. Few methods have been proposed to address generalization in the presence of unforeseen domain shifts. In particular, digital noise corruptions arise commonly in practice during the image acquisition stage and present a significant challenge for current methods. In this paper, we propose a diverse Gaussian noise consistency regularization method for improving robustness of image classifiers under a variety of corruptions while still maintaining high clean accuracy. We derive bounds to motivate and understand the behavior of our Gaussian noise consistency regularization using a local loss landscape analysis. Our approach improves robustness against unforeseen noise corruptions by 4.2-18.4% over adversarial training and other strong diverse data augmentation base",
    "link": "http://arxiv.org/abs/2104.01231",
    "context": "Title: Diverse Gaussian Noise Consistency Regularization for Robustness and Uncertainty Calibration. (arXiv:2104.01231v6 [cs.LG] UPDATED)\nAbstract: Deep neural networks achieve high prediction accuracy when the train and test distributions coincide. In practice though, various types of corruptions occur which deviate from this setup and cause severe performance degradations. Few methods have been proposed to address generalization in the presence of unforeseen domain shifts. In particular, digital noise corruptions arise commonly in practice during the image acquisition stage and present a significant challenge for current methods. In this paper, we propose a diverse Gaussian noise consistency regularization method for improving robustness of image classifiers under a variety of corruptions while still maintaining high clean accuracy. We derive bounds to motivate and understand the behavior of our Gaussian noise consistency regularization using a local loss landscape analysis. Our approach improves robustness against unforeseen noise corruptions by 4.2-18.4% over adversarial training and other strong diverse data augmentation base",
    "path": "papers/21/04/2104.01231.json",
    "total_tokens": 956,
    "translated_title": "多样化高斯噪声一致性正则化用于鲁棒性和不确定性校准",
    "translated_abstract": "当训练和测试数据分布一致时，深度神经网络可以实现高水平的预测精度。然而，在实际情况中，各种类型的损坏会导致表现严重下降，这与预期的情况有所偏差。目前只有少数方法可以在出现未预见到的领域偏移时提高泛化能力。特别是，在图像获取阶段，数字噪声污染经常出现。我们提出了一种多样化高斯噪声一致性正则化方法，用于改进图像分类器在各种污染情况下的鲁棒性，同时仍保持较高的准确性。通过本地损失景观分析，我们导出界限，以激励和理解我们的高斯噪声一致性正则化的行为。相比于对抗性训练和其他强大的多样化数据增强基础，我们的方法可以将鲁棒性提高4.2-18.4％以应对未预见的噪声污染。",
    "tldr": "本研究提出了一种多样化高斯噪声一致性正则化方法，用于同时提高图像分类器的鲁棒性和准确性，与其他强大的多样化数据增强基础相比，可以将鲁棒性提高4.2-18.4％以应对未预见的噪声污染。",
    "en_tdlr": "This paper proposes a diverse Gaussian noise consistency regularization method to improve the robustness and accuracy of image classifiers. Compared to other strong diverse data augmentation methods, our approach can increase the robustness by 4.2-18.4% to handle unforeseen noise corruptions."
}