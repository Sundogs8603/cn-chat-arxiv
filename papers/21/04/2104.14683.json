{
    "title": "Deep Reinforcement Trading with Predictable Returns. (arXiv:2104.14683v3 [q-fin.PM] UPDATED)",
    "abstract": "Classical portfolio optimization often requires forecasting asset returns and their corresponding variances in spite of the low signal-to-noise ratio provided in the financial markets. Modern deep reinforcement learning (DRL) offers a framework for optimizing sequential trader decisions but lacks theoretical guarantees of convergence. On the other hand, the performances on real financial trading problems are strongly affected by the goodness of the signal used to predict returns. To disentangle the effects coming from return unpredictability from those coming from algorithm un-trainability, we investigate the performance of model-free DRL traders in a market environment with different known mean-reverting factors driving the dynamics. When the framework admits an exact dynamic programming solution, we can assess the limits and capabilities of different value-based algorithms to retrieve meaningful trading signals in a data-driven manner. We consider DRL agents that leverage classical s",
    "link": "http://arxiv.org/abs/2104.14683",
    "context": "Title: Deep Reinforcement Trading with Predictable Returns. (arXiv:2104.14683v3 [q-fin.PM] UPDATED)\nAbstract: Classical portfolio optimization often requires forecasting asset returns and their corresponding variances in spite of the low signal-to-noise ratio provided in the financial markets. Modern deep reinforcement learning (DRL) offers a framework for optimizing sequential trader decisions but lacks theoretical guarantees of convergence. On the other hand, the performances on real financial trading problems are strongly affected by the goodness of the signal used to predict returns. To disentangle the effects coming from return unpredictability from those coming from algorithm un-trainability, we investigate the performance of model-free DRL traders in a market environment with different known mean-reverting factors driving the dynamics. When the framework admits an exact dynamic programming solution, we can assess the limits and capabilities of different value-based algorithms to retrieve meaningful trading signals in a data-driven manner. We consider DRL agents that leverage classical s",
    "path": "papers/21/04/2104.14683.json",
    "total_tokens": 899,
    "translated_title": "可预测回报的深度强化交易",
    "translated_abstract": "传统投资组合优化在金融市场中无法提供高信噪比的情况下，需要预测资产回报及其相应的方差。现代深度强化学习提供了一种优化序列交易决策的框架，但缺乏收敛的理论保证。然而，预测回报的信号的质量对于真实金融交易问题的表现具有很强的影响。为了分离来自回报不可预测性和来自算法不可训练性的影响，我们研究了在具有不同已知均值回归驱动动态的市场环境中，无模型深度强化学习交易者的表现。当框架允许精确的动态规划解决方案时，我们可以评估不同价值算法检索有意义的交易信号的限制和能力。我们考虑利用经典的softmax策略和Dueling DQN的DRL代理商。",
    "tldr": "本论文研究了使用深度强化学习进行交易决策优化的框架的现代投资组合优化，探讨了预测回报信号的质量对真实金融交易问题表现的影响，并评估了不同算法检索有意义交易信号的限制和能力。",
    "en_tdlr": "This paper investigates the framework of using deep reinforcement learning to optimize trading decisions in modern portfolio optimization, explores the impact of the quality of predicted return signals on the performance of real financial trading problems, and evaluates the limitations and capabilities of different algorithms to retrieve meaningful trading signals."
}