{
    "title": "Wise-SrNet: A Novel Architecture for Enhancing Image Classification by Learning Spatial Resolution of Feature Maps. (arXiv:2104.12294v2 [cs.CV] UPDATED)",
    "abstract": "One of the main challenges since the advancement of convolutional neural networks is how to connect the extracted feature map to the final classification layer. VGG models used two sets of fully connected layers for the classification part of their architectures, which significantly increased the number of models' weights. ResNet and the next deep convolutional models used the Global Average Pooling (GAP) layer to compress the feature map and feed it to the classification layer. Although using the GAP layer reduces the computational cost, but also causes losing spatial resolution of the feature map, which results in decreasing learning efficiency. In this paper, we aim to tackle this problem by replacing the GAP layer with a new architecture called Wise-SrNet. It is inspired by the depthwise convolutional idea and is designed for processing spatial resolution while not increasing computational cost. We have evaluated our method using three different datasets: Intel Image Classification",
    "link": "http://arxiv.org/abs/2104.12294",
    "context": "Title: Wise-SrNet: A Novel Architecture for Enhancing Image Classification by Learning Spatial Resolution of Feature Maps. (arXiv:2104.12294v2 [cs.CV] UPDATED)\nAbstract: One of the main challenges since the advancement of convolutional neural networks is how to connect the extracted feature map to the final classification layer. VGG models used two sets of fully connected layers for the classification part of their architectures, which significantly increased the number of models' weights. ResNet and the next deep convolutional models used the Global Average Pooling (GAP) layer to compress the feature map and feed it to the classification layer. Although using the GAP layer reduces the computational cost, but also causes losing spatial resolution of the feature map, which results in decreasing learning efficiency. In this paper, we aim to tackle this problem by replacing the GAP layer with a new architecture called Wise-SrNet. It is inspired by the depthwise convolutional idea and is designed for processing spatial resolution while not increasing computational cost. We have evaluated our method using three different datasets: Intel Image Classification",
    "path": "papers/21/04/2104.12294.json",
    "total_tokens": 918,
    "translated_title": "Wise-SrNet: 一种增强图像分类的新型架构，通过学习特征图的空间分辨率",
    "translated_abstract": "自从卷积神经网络的发展以来，将提取的特征图与最终的分类层连接起来一直是主要的挑战之一。VGG模型使用两组全连接层用于架构的分类部分，这显著增加了模型权重的数量。ResNet等深度卷积模型使用全局平均池化（GAP）层将特征图压缩并输入分类层。尽管使用GAP层可以减少计算成本，但也会导致特征图的空间分辨率损失，从而降低学习效率。在本文中，我们通过使用一种名为Wise-SrNet的新型架构来解决这个问题。它受到了深度卷积思想的启发，并且专为处理空间分辨率而设计，同时不增加计算成本。我们使用三个不同的数据集对我们的方法进行了评估：Intel图像分类数据集...",
    "tldr": "本文提出了一种名为Wise-SrNet的新型架构，用于增强图像分类任务。该架构通过学习特征图的空间分辨率，解决了连接特征图和分类层之间的挑战。实验证明，该方法在不增加计算成本的情况下，有效提高了学习效率。"
}