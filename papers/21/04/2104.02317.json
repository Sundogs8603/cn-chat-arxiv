{
    "title": "A hybrid ensemble method with negative correlation learning for regression. (arXiv:2104.02317v4 [cs.LG] UPDATED)",
    "abstract": "Hybrid ensemble, an essential branch of ensembles, has flourished in the regression field, with studies confirming diversity's importance. However, previous ensembles consider diversity in the sub-model training stage, with limited improvement compared to single models. In contrast, this study automatically selects and weights sub-models from a heterogeneous model pool. It solves an optimization problem using an interior-point filtering linear-search algorithm. The objective function innovatively incorporates negative correlation learning as a penalty term, with which a diverse model subset can be selected. The best sub-models from each model class are selected to build the NCL ensemble, which performance is better than the simple average and other state-of-the-art weighting methods. It is also possible to improve the NCL ensemble with a regularization term in the objective function. In practice, it is difficult to conclude the optimal sub-model for a dataset prior due to the model unc",
    "link": "http://arxiv.org/abs/2104.02317",
    "context": "Title: A hybrid ensemble method with negative correlation learning for regression. (arXiv:2104.02317v4 [cs.LG] UPDATED)\nAbstract: Hybrid ensemble, an essential branch of ensembles, has flourished in the regression field, with studies confirming diversity's importance. However, previous ensembles consider diversity in the sub-model training stage, with limited improvement compared to single models. In contrast, this study automatically selects and weights sub-models from a heterogeneous model pool. It solves an optimization problem using an interior-point filtering linear-search algorithm. The objective function innovatively incorporates negative correlation learning as a penalty term, with which a diverse model subset can be selected. The best sub-models from each model class are selected to build the NCL ensemble, which performance is better than the simple average and other state-of-the-art weighting methods. It is also possible to improve the NCL ensemble with a regularization term in the objective function. In practice, it is difficult to conclude the optimal sub-model for a dataset prior due to the model unc",
    "path": "papers/21/04/2104.02317.json",
    "total_tokens": 841,
    "translated_title": "一种带有负相关学习的混合集成算法进行回归分析",
    "translated_abstract": "混合集成是集成学习中的一个重要分支，在回归领域得到了迅速发展，并证实了多样性的重要性。然而，以往的集成方法主要是在子模型训练阶段考虑多样性，改善效果有限。相比之下，这项研究从异构模型池中自动选择和加权子模型，并使用内点过滤线性搜索算法解决优化问题。目标函数创新地将负相关学习作为一个惩罚项，并选择多样化子模型子集。选择每个模型类的最佳子模型来构建NCL集成，其性能优于简单平均和其他最先进的加权方法。在目标函数中加入正则化项，还可以进一步改善NCL集成的效果。",
    "tldr": "该论文提出了一种带有负相关学习的混合集成算法，通过自动选择和加权子模型来解决在回归任务中模型不确定性问题，并在实验中表现出较好的性能。",
    "en_tdlr": "This paper proposes a hybrid ensemble method with negative correlation learning for regression, which automatically selects and weights sub-models to solve the problem of model uncertainty and achieves better performance in experiments."
}