{
    "title": "Recurrent Equilibrium Networks: Flexible Dynamic Models with Guaranteed Stability and Robustness. (arXiv:2104.05942v3 [cs.LG] UPDATED)",
    "abstract": "This paper introduces recurrent equilibrium networks (RENs), a new class of nonlinear dynamical models} for applications in machine learning, system identification and control. The new model class admits ``built in'' behavioural guarantees of stability and robustness. All models in the proposed class are contracting -- a strong form of nonlinear stability -- and models can satisfy prescribed incremental integral quadratic constraints (IQC), including Lipschitz bounds and incremental passivity. RENs are otherwise very flexible: they can represent all stable linear systems, all previously-known sets of contracting recurrent neural networks and echo state networks, all deep feedforward neural networks, and all stable Wiener/Hammerstein models, and can approximate all fading-memory and contracting nonlinear systems. RENs are parameterized directly by a vector in R^N, i.e. stability and robustness are ensured without parameter constraints, which simplifies learning since \\HL{generic methods",
    "link": "http://arxiv.org/abs/2104.05942",
    "context": "Title: Recurrent Equilibrium Networks: Flexible Dynamic Models with Guaranteed Stability and Robustness. (arXiv:2104.05942v3 [cs.LG] UPDATED)\nAbstract: This paper introduces recurrent equilibrium networks (RENs), a new class of nonlinear dynamical models} for applications in machine learning, system identification and control. The new model class admits ``built in'' behavioural guarantees of stability and robustness. All models in the proposed class are contracting -- a strong form of nonlinear stability -- and models can satisfy prescribed incremental integral quadratic constraints (IQC), including Lipschitz bounds and incremental passivity. RENs are otherwise very flexible: they can represent all stable linear systems, all previously-known sets of contracting recurrent neural networks and echo state networks, all deep feedforward neural networks, and all stable Wiener/Hammerstein models, and can approximate all fading-memory and contracting nonlinear systems. RENs are parameterized directly by a vector in R^N, i.e. stability and robustness are ensured without parameter constraints, which simplifies learning since \\HL{generic methods",
    "path": "papers/21/04/2104.05942.json",
    "total_tokens": 957,
    "translated_title": "递归均衡网络：具有稳定性和鲁棒性保证的灵活动力学模型",
    "translated_abstract": "本文介绍了递归均衡网络（RENs），一种用于机器学习、系统识别和控制的新型非线性动力学模型。这种新模型具有稳定性和鲁棒性的“内置”行为保证。所提出的模型类中的所有模型都是收缩的——一种强非线性稳定性形式——并且可以满足规定的增量积分二次约束（IQC），包括Lipschitz界限和增量被动性。RENs具有很强的灵活性：它们可以表示所有稳定的线性系统，所有先前已知的收缩递归神经网络和回声状态网络，所有深层前馈神经网络，以及所有稳定的Wiener/Hammerstein模型，并且可以近似所有褪色记忆和收缩非线性系统。RENs直接由R^N中的向量参数化，即在不受参数约束的情况下保证稳定性和鲁棒性，这简化了学习过程，因为通用方法可以用来直接学习RENs。",
    "tldr": "本文介绍了一种新型非线性动力学模型——递归均衡网络（RENs），它具有稳定性和鲁棒性的“内置”保证。RENs具有很强的灵活性，能表示多种系统，并用参数化方法简化了学习过程。",
    "en_tdlr": "This paper introduces a new class of nonlinear dynamical models called recurrent equilibrium networks (RENs) for machine learning, system identification, and control. RENs provide built-in guarantees of stability and robustness and are highly flexible, capable of representing various systems while simplifying the learning process through parameterization."
}