{
    "title": "Model selection of polynomial kernel regression. (arXiv:1503.02143v2 [cs.LG] UPDATED)",
    "abstract": "Polynomial kernel regression is one of the standard and state-of-the-art learning strategies. However, as is well known, the choices of the degree of polynomial kernel and the regularization parameter are still open in the realm of model selection. The first aim of this paper is to develop a strategy to select these parameters. On one hand, based on the worst-case learning rate analysis, we show that the regularization term in polynomial kernel regression is not necessary. In other words, the regularization parameter can decrease arbitrarily fast when the degree of the polynomial kernel is suitable tuned. On the other hand,taking account of the implementation of the algorithm, the regularization term is required. Summarily, the effect of the regularization term in polynomial kernel regression is only to circumvent the \" ill-condition\" of the kernel matrix. Based on this, the second purpose of this paper is to propose a new model selection strategy, and then design an efficient learning",
    "link": "http://arxiv.org/abs/1503.02143",
    "context": "Title: Model selection of polynomial kernel regression. (arXiv:1503.02143v2 [cs.LG] UPDATED)\nAbstract: Polynomial kernel regression is one of the standard and state-of-the-art learning strategies. However, as is well known, the choices of the degree of polynomial kernel and the regularization parameter are still open in the realm of model selection. The first aim of this paper is to develop a strategy to select these parameters. On one hand, based on the worst-case learning rate analysis, we show that the regularization term in polynomial kernel regression is not necessary. In other words, the regularization parameter can decrease arbitrarily fast when the degree of the polynomial kernel is suitable tuned. On the other hand,taking account of the implementation of the algorithm, the regularization term is required. Summarily, the effect of the regularization term in polynomial kernel regression is only to circumvent the \" ill-condition\" of the kernel matrix. Based on this, the second purpose of this paper is to propose a new model selection strategy, and then design an efficient learning",
    "path": "papers/15/03/1503.02143.json",
    "total_tokens": 861,
    "translated_title": "多项式核回归的模型选择",
    "translated_abstract": "多项式核回归是一种常用的和最先进的学习策略之一。然而，众所周知，在模型选择中，多项式核的次数和正则化参数的选择仍然是开放的问题。本文的第一个目标是开发一种策略来选择这些参数。一方面，基于最坏情况的学习速率分析，我们表明多项式核回归中的正则化项是不必要的；换句话说，当多项式核的次数适当调整时，正则化参数可以任意快地减小。另一方面，考虑到算法的实现，正则化项是必需的。综上所述，多项式核回归中正则化项的作用只是为了规避核矩阵的“病态”。本文的第二个目的是基于此提出一种新的模型选择策略，并设计一种有效的学习算法。",
    "tldr": "本文提出了一种新的模型选择策略，揭示了在多项式核回归中正则化项的作用只是为了规避核矩阵的“病态”，从而可选不加正则化项，并设计了一种有效的学习算法。",
    "en_tdlr": "This paper proposes a new model selection strategy for polynomial kernel regression, revealing that the regularization term is only necessary to handle the \"ill-condition\" of the kernel matrix and can be omitted with suitable tuning of the degree of the polynomial kernel. An efficient learning algorithm is also designed."
}