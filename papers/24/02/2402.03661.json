{
    "title": "Transductive Reward Inference on Graph",
    "abstract": "In this study, we present a transductive inference approach on that reward information propagation graph, which enables the effective estimation of rewards for unlabelled data in offline reinforcement learning. Reward inference is the key to learning effective policies in practical scenarios, while direct environmental interactions are either too costly or unethical and the reward functions are rarely accessible, such as in healthcare and robotics. Our research focuses on developing a reward inference method based on the contextual properties of information propagation on graphs that capitalizes on a constrained number of human reward annotations to infer rewards for unlabelled data. We leverage both the available data and limited reward annotations to construct a reward propagation graph, wherein the edge weights incorporate various influential factors pertaining to the rewards. Subsequently, we employ the constructed graph for transductive reward inference, thereby estimating rewards",
    "link": "https://arxiv.org/abs/2402.03661",
    "context": "Title: Transductive Reward Inference on Graph\nAbstract: In this study, we present a transductive inference approach on that reward information propagation graph, which enables the effective estimation of rewards for unlabelled data in offline reinforcement learning. Reward inference is the key to learning effective policies in practical scenarios, while direct environmental interactions are either too costly or unethical and the reward functions are rarely accessible, such as in healthcare and robotics. Our research focuses on developing a reward inference method based on the contextual properties of information propagation on graphs that capitalizes on a constrained number of human reward annotations to infer rewards for unlabelled data. We leverage both the available data and limited reward annotations to construct a reward propagation graph, wherein the edge weights incorporate various influential factors pertaining to the rewards. Subsequently, we employ the constructed graph for transductive reward inference, thereby estimating rewards",
    "path": "papers/24/02/2402.03661.json",
    "total_tokens": 881,
    "translated_title": "在图上进行传递式奖励推断",
    "translated_abstract": "在这项研究中，我们提出了一种在奖励信息传播图上进行传递式推断的方法，从而能够有效地估计离线强化学习中未标记数据的奖励。奖励推断是在实际场景中学习有效策略的关键，而直接的环境交互要么成本太高，要么是不道德的，并且很少有可访问的奖励函数，例如在医疗保健和机器人领域。我们的研究集中于开发一种基于图上信息传播的上下文特性的奖励推断方法，利用有限数量的人工奖励注释来推断未标记数据的奖励。我们利用可用数据和有限的奖励注释构建奖励传播图，其中边权重包含与奖励相关的各种影响因素。随后，我们使用构建的图进行传递式奖励推断，从而估计奖励。",
    "tldr": "该研究提出了一种在图上进行传递式奖励推断的方法，可以有效地估计离线强化学习中未标记数据的奖励。通过利用有限的人工奖励注释和可用数据构建奖励传播图，并利用图进行奖励推断，从而推断出未标记数据的奖励。"
}