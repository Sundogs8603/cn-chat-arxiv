{
    "title": "Multimodal-Enhanced Objectness Learner for Corner Case Detection in Autonomous Driving",
    "abstract": "Previous works on object detection have achieved high accuracy in closed-set scenarios, but their performance in open-world scenarios is not satisfactory. One of the challenging open-world problems is corner case detection in autonomous driving. Existing detectors struggle with these cases, relying heavily on visual appearance and exhibiting poor generalization ability. In this paper, we propose a solution by reducing the discrepancy between known and unknown classes and introduce a multimodal-enhanced objectness notion learner. Leveraging both vision-centric and image-text modalities, our semi-supervised learning framework imparts objectness knowledge to the student model, enabling class-aware detection. Our approach, Multimodal-Enhanced Objectness Learner (MENOL) for Corner Case Detection, significantly improves recall for novel classes with lower training costs. By achieving a 76.6% mAR-corner and 79.8% mAR-agnostic on the CODA-val dataset with just 5100 labeled training images, MEN",
    "link": "https://arxiv.org/abs/2402.02026",
    "context": "Title: Multimodal-Enhanced Objectness Learner for Corner Case Detection in Autonomous Driving\nAbstract: Previous works on object detection have achieved high accuracy in closed-set scenarios, but their performance in open-world scenarios is not satisfactory. One of the challenging open-world problems is corner case detection in autonomous driving. Existing detectors struggle with these cases, relying heavily on visual appearance and exhibiting poor generalization ability. In this paper, we propose a solution by reducing the discrepancy between known and unknown classes and introduce a multimodal-enhanced objectness notion learner. Leveraging both vision-centric and image-text modalities, our semi-supervised learning framework imparts objectness knowledge to the student model, enabling class-aware detection. Our approach, Multimodal-Enhanced Objectness Learner (MENOL) for Corner Case Detection, significantly improves recall for novel classes with lower training costs. By achieving a 76.6% mAR-corner and 79.8% mAR-agnostic on the CODA-val dataset with just 5100 labeled training images, MEN",
    "path": "papers/24/02/2402.02026.json",
    "total_tokens": 969,
    "translated_title": "自主驾驶中角落案例检测的多模态增强物件学习器",
    "translated_abstract": "在物体检测的先前工作中，封闭场景下的准确率较高，但在开放世界场景下的性能并不令人满意。其中一个具有挑战性的开放世界问题是自主驾驶中的角落案例检测。现有的检测器在这些案例中表现困难，过度依赖视觉外观，具有较差的泛化能力。本文提出了一种解决方案，通过减小已知类和未知类之间的差异，并引入多模态增强的物件学习器的概念。借助视觉中心和图像-文本两种形式，我们的半监督学习框架将物件学习器的知识传递给学生模型，实现了类别感知的检测。我们的方法——用于角落案例检测的多模态增强物件学习器（MENOL），显著提高了对新类别的召回率，并降低训练成本。在仅使用5100个标签训练图像的CODA-val数据集上，MENOL实现了76.6%的mAR-corner和79.8%的mAR-agnostic。",
    "tldr": "本文提出了一种用于角落案例检测的多模态增强物件学习器（MENOL）。该方法通过减小已知类和未知类之间的差异，并引入多模态的数据，显著提高了对新类别的召回率，并降低了训练成本。",
    "en_tdlr": "This paper proposes a multimodal-enhanced objectness learner (MENOL) for corner case detection. By reducing the discrepancy between known and unknown classes and leveraging multimodal data, the approach significantly improves recall for novel classes with lower training costs."
}