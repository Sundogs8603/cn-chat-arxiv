{
    "title": "On the Convergence of Differentially-Private Fine-tuning: To Linearly Probe or to Fully Fine-tune?",
    "abstract": "arXiv:2402.18905v1 Announce Type: cross  Abstract: Differentially private (DP) machine learning pipelines typically involve a two-phase process: non-private pre-training on a public dataset, followed by fine-tuning on private data using DP optimization techniques. In the DP setting, it has been observed that full fine-tuning may not always yield the best test accuracy, even for in-distribution data. This paper (1) analyzes the training dynamics of DP linear probing (LP) and full fine-tuning (FT), and (2) explores the phenomenon of sequential fine-tuning, starting with linear probing and transitioning to full fine-tuning (LP-FT), and its impact on test loss. We provide theoretical insights into the convergence of DP fine-tuning within an overparameterized neural network and establish a utility curve that determines the allocation of privacy budget between linear probing and full fine-tuning. The theoretical results are supported by empirical evaluations on various benchmarks and models.",
    "link": "https://arxiv.org/abs/2402.18905",
    "context": "Title: On the Convergence of Differentially-Private Fine-tuning: To Linearly Probe or to Fully Fine-tune?\nAbstract: arXiv:2402.18905v1 Announce Type: cross  Abstract: Differentially private (DP) machine learning pipelines typically involve a two-phase process: non-private pre-training on a public dataset, followed by fine-tuning on private data using DP optimization techniques. In the DP setting, it has been observed that full fine-tuning may not always yield the best test accuracy, even for in-distribution data. This paper (1) analyzes the training dynamics of DP linear probing (LP) and full fine-tuning (FT), and (2) explores the phenomenon of sequential fine-tuning, starting with linear probing and transitioning to full fine-tuning (LP-FT), and its impact on test loss. We provide theoretical insights into the convergence of DP fine-tuning within an overparameterized neural network and establish a utility curve that determines the allocation of privacy budget between linear probing and full fine-tuning. The theoretical results are supported by empirical evaluations on various benchmarks and models.",
    "path": "papers/24/02/2402.18905.json",
    "total_tokens": 977,
    "translated_title": "论差分隐私微调的收敛性：应线性探测还是完全微调？",
    "translated_abstract": "差分隐私（DP）机器学习流水线通常包括两个阶段的过程：在公共数据集上进行非私有预训练，然后使用DP优化技术在私有数据上进行微调。在DP设置中，已经观察到完全微调有时候并不总是产生最佳的测试准确度，即使对于分布内数据也是如此。本文（1）分析了DP线性探测（LP）和完全微调（FT）的训练动态，以及（2）探索了顺序微调的现象，从线性探测开始，过渡到完全微调（LP-FT），以及它对测试损失的影响。我们提供了有关DP微调在超参数化神经网络中的收敛性的理论洞见，并建立了一个确定隐私预算在线性探测和完全微调之间分配的效用曲线。理论结果得到了对各种基准和模型的经验评估支持。",
    "tldr": "本文分析了差分隐私线性探测（LP）和完全微调（FT）的训练动态，探索了从线性探测过渡到完全微调（LP-FT）的顺序微调现象及其对测试损失的影响，提供了关于在超参数化神经网络中差分隐私微调收敛性的理论洞见和隐私预算分配的效用曲线。",
    "en_tdlr": "This paper analyzes the training dynamics of differentially private linear probing (LP) and full fine-tuning (FT), explores the phenomenon of sequential fine-tuning from LP to FT and its impact on test loss, and provides theoretical insights into the convergence of differentially private fine-tuning in overparameterized neural networks and the utility curve for privacy budget allocation."
}