{
    "title": "Distinctive Image Captioning: Leveraging Ground Truth Captions in CLIP Guided Reinforcement Learning",
    "abstract": "arXiv:2402.13936v1 Announce Type: new  Abstract: Training image captioning models using teacher forcing results in very generic samples, whereas more distinctive captions can be very useful in retrieval applications or to produce alternative texts describing images for accessibility. Reinforcement Learning (RL) allows to use cross-modal retrieval similarity score between the generated caption and the input image as reward to guide the training, leading to more distinctive captions. Recent studies show that pre-trained cross-modal retrieval models can be used to provide this reward, completely eliminating the need for reference captions. However, we argue in this paper that Ground Truth (GT) captions can still be useful in this RL framework. We propose a new image captioning model training strategy that makes use of GT captions in different ways. Firstly, they can be used to train a simple MLP discriminator that serves as a regularization to prevent reward hacking and ensures the fluenc",
    "link": "https://arxiv.org/abs/2402.13936",
    "context": "Title: Distinctive Image Captioning: Leveraging Ground Truth Captions in CLIP Guided Reinforcement Learning\nAbstract: arXiv:2402.13936v1 Announce Type: new  Abstract: Training image captioning models using teacher forcing results in very generic samples, whereas more distinctive captions can be very useful in retrieval applications or to produce alternative texts describing images for accessibility. Reinforcement Learning (RL) allows to use cross-modal retrieval similarity score between the generated caption and the input image as reward to guide the training, leading to more distinctive captions. Recent studies show that pre-trained cross-modal retrieval models can be used to provide this reward, completely eliminating the need for reference captions. However, we argue in this paper that Ground Truth (GT) captions can still be useful in this RL framework. We propose a new image captioning model training strategy that makes use of GT captions in different ways. Firstly, they can be used to train a simple MLP discriminator that serves as a regularization to prevent reward hacking and ensures the fluenc",
    "path": "papers/24/02/2402.13936.json",
    "total_tokens": 894,
    "translated_title": "独特图像字幕：在CLIP引导强化学习中利用地面真实字幕",
    "translated_abstract": "使用教师强迫训练图像字幕模型会导致生成非常通用的样本，而更具有独特性的字幕在检索应用或为图像生成替代文本以增强可访问性方面非常有用。 强化学习（RL）允许使用生成字幕与输入图像之间的跨模态检索相似度分数作为奖励来指导训练，从而产生更具独特性的字幕。 最近的研究表明，预训练的跨模态检索模型可以用于提供这种奖励，从而完全消除了对参考字幕的需求。 然而，我们在本文中认为地面真实（GT）字幕在这种RL框架中仍然可以发挥作用。 我们提出了一种新的图像字幕模型训练策略，以不同方式利用GT字幕。 首先，它们可以用来训练一个简单的MLP鉴别器，作为正则化的一部分，以防止奖励作弊并确保流畅性。",
    "tldr": "论文提出了一种新的图像字幕模型训练策略，在强化学习框架中利用地面真实字幕，以提高生成字幕的独特性。",
    "en_tdlr": "The paper proposes a new training strategy for image captioning models that leverages ground truth captions in a reinforcement learning framework to enhance the uniqueness of the generated captions."
}