{
    "title": "Discovering Behavioral Modes in Deep Reinforcement Learning Policies Using Trajectory Clustering in Latent Space",
    "abstract": "arXiv:2402.12939v1 Announce Type: cross  Abstract: Understanding the behavior of deep reinforcement learning (DRL) agents is crucial for improving their performance and reliability. However, the complexity of their policies often makes them challenging to understand. In this paper, we introduce a new approach for investigating the behavior modes of DRL policies, which involves utilizing dimensionality reduction and trajectory clustering in the latent space of neural networks. Specifically, we use Pairwise Controlled Manifold Approximation Projection (PaCMAP) for dimensionality reduction and TRACLUS for trajectory clustering to analyze the latent space of a DRL policy trained on the Mountain Car control task. Our methodology helps identify diverse behavior patterns and suboptimal choices by the policy, thus allowing for targeted improvements. We demonstrate how our approach, combined with domain knowledge, can enhance a policy's performance in specific regions of the state space.",
    "link": "https://arxiv.org/abs/2402.12939",
    "context": "Title: Discovering Behavioral Modes in Deep Reinforcement Learning Policies Using Trajectory Clustering in Latent Space\nAbstract: arXiv:2402.12939v1 Announce Type: cross  Abstract: Understanding the behavior of deep reinforcement learning (DRL) agents is crucial for improving their performance and reliability. However, the complexity of their policies often makes them challenging to understand. In this paper, we introduce a new approach for investigating the behavior modes of DRL policies, which involves utilizing dimensionality reduction and trajectory clustering in the latent space of neural networks. Specifically, we use Pairwise Controlled Manifold Approximation Projection (PaCMAP) for dimensionality reduction and TRACLUS for trajectory clustering to analyze the latent space of a DRL policy trained on the Mountain Car control task. Our methodology helps identify diverse behavior patterns and suboptimal choices by the policy, thus allowing for targeted improvements. We demonstrate how our approach, combined with domain knowledge, can enhance a policy's performance in specific regions of the state space.",
    "path": "papers/24/02/2402.12939.json",
    "total_tokens": 853,
    "translated_title": "利用轨迹聚类在潜空间中发现深度强化学习策略的行为模式",
    "translated_abstract": "深度强化学习（DRL）代理的行为分析对于提高其性能和可靠性至关重要。然而，它们的策略复杂性往往使其难以理解。本文介绍了一种新方法，用于研究DRL策略的行为模式，该方法涉及在神经网络的潜空间中利用降维和轨迹聚类。具体地，我们使用Pairwise Controlled Manifold Approximation Projection（PaCMAP）进行降维和TRACLUS进行轨迹聚类，分析了在Mountain Car控制任务上训练的DRL策略的潜空间。我们的方法有助于识别多样的行为模式和策略的次优选择，从而实现有针对性的改进。我们展示了如何结合领域知识，可以增强策略在状态空间特定区域的性能。",
    "tldr": "通过利用轨迹聚类和降维技术在神经网络的潜空间中研究深度强化学习策略的行为模式，可以发现并改进其多样的行为模式和次优选择。",
    "en_tdlr": "By utilizing trajectory clustering and dimensionality reduction techniques in the latent space of neural networks, discovering and improving diverse behavior patterns and suboptimal choices of deep reinforcement learning policies is made possible."
}