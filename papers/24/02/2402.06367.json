{
    "title": "TEE4EHR: Transformer Event Encoder for Better Representation Learning in Electronic Health Records",
    "abstract": "Irregular sampling of time series in electronic health records (EHRs) is one of the main challenges for developing machine learning models. Additionally, the pattern of missing data in certain clinical variables is not at random but depends on the decisions of clinicians and the state of the patient. Point process is a mathematical framework for analyzing event sequence data that is consistent with irregular sampling patterns. Our model, TEE4EHR, is a transformer event encoder (TEE) with point process loss that encodes the pattern of laboratory tests in EHRs. The utility of our TEE has been investigated in a variety of benchmark event sequence datasets. Additionally, we conduct experiments on two real-world EHR databases to provide a more comprehensive evaluation of our model. Firstly, in a self-supervised learning approach, the TEE is jointly learned with an existing attention-based deep neural network which gives superior performance in negative log-likelihood and future event predic",
    "link": "https://arxiv.org/abs/2402.06367",
    "context": "Title: TEE4EHR: Transformer Event Encoder for Better Representation Learning in Electronic Health Records\nAbstract: Irregular sampling of time series in electronic health records (EHRs) is one of the main challenges for developing machine learning models. Additionally, the pattern of missing data in certain clinical variables is not at random but depends on the decisions of clinicians and the state of the patient. Point process is a mathematical framework for analyzing event sequence data that is consistent with irregular sampling patterns. Our model, TEE4EHR, is a transformer event encoder (TEE) with point process loss that encodes the pattern of laboratory tests in EHRs. The utility of our TEE has been investigated in a variety of benchmark event sequence datasets. Additionally, we conduct experiments on two real-world EHR databases to provide a more comprehensive evaluation of our model. Firstly, in a self-supervised learning approach, the TEE is jointly learned with an existing attention-based deep neural network which gives superior performance in negative log-likelihood and future event predic",
    "path": "papers/24/02/2402.06367.json",
    "total_tokens": 925,
    "translated_title": "TEE4EHR：用于更好地学习电子健康记录中表示的Transformer事件编码器",
    "translated_abstract": "电子健康记录（EHR）中时间序列的不规则采样是开发机器学习模型的主要挑战之一。此外，某些临床变量的缺失数据模式并非随机的，而是取决于临床医生的决策和患者的状态。点过程是一种数学框架，用于分析与不规则采样模式一致的事件序列数据。我们的模型TEE4EHR是一个具有点过程损失函数的Transformer事件编码器（TEE），它对EHR中的实验室检测模式进行编码。我们的TEE的效用已在各种基准事件序列数据集上进行了研究。此外，我们在两个实际的EHR数据库上进行了实验，以更全面地评估我们的模型。首先，在自监督学习方法中，TEE与现有的基于注意力的深度神经网络一起进行联合学习，这在负对数似然和未来事件预测方面具有卓越的性能。",
    "tldr": "TEE4EHR是一个使用点过程损失函数的Transformer事件编码器，用于编码电子健康记录中实验室测试的模式。它能够解决EHR中时间序列的不规则采样和缺失数据的挑战，并在各种基准数据集和实际数据库上展现出优越性能。",
    "en_tdlr": "TEE4EHR is a Transformer event encoder that utilizes point process loss for encoding the patterns of laboratory tests in electronic health records. It addresses the challenges of irregular sampling and missing data in EHRs, and demonstrates superior performance on various benchmark datasets and real-world databases."
}