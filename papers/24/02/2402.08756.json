{
    "title": "Learning How To Ask: Cycle-Consistency Refines Prompts in Multimodal Foundation Models",
    "abstract": "arXiv:2402.08756v1 Announce Type: new Abstract: When LLMs perform zero-shot inference, they typically use a prompt with a task specification, and generate a completion. However, there is no work to explore the possibility of the reverse - going from completion to task specification. In this paper, we employ both directions to perform cycle-supervised learning entirely in-context. Our goal is to create a forward map f : X -> Y (e.g. image -> generated caption), coupled with a backward map g : Y -> X (e.g. caption -> generated image) to construct a cycle-consistency \"loss\" (formulated as an update to the prompt) to enforce g(f(X)) ~= X. The technique, called CyclePrompt, uses cycle-consistency as a free supervisory signal to iteratively craft the prompt. Importantly, CyclePrompt reinforces model performance without expensive fine-tuning, without training data, and without the complexity of external environments (e.g. compilers, APIs). We demonstrate CyclePrompt in two domains: code gener",
    "link": "https://arxiv.org/abs/2402.08756",
    "context": "Title: Learning How To Ask: Cycle-Consistency Refines Prompts in Multimodal Foundation Models\nAbstract: arXiv:2402.08756v1 Announce Type: new Abstract: When LLMs perform zero-shot inference, they typically use a prompt with a task specification, and generate a completion. However, there is no work to explore the possibility of the reverse - going from completion to task specification. In this paper, we employ both directions to perform cycle-supervised learning entirely in-context. Our goal is to create a forward map f : X -> Y (e.g. image -> generated caption), coupled with a backward map g : Y -> X (e.g. caption -> generated image) to construct a cycle-consistency \"loss\" (formulated as an update to the prompt) to enforce g(f(X)) ~= X. The technique, called CyclePrompt, uses cycle-consistency as a free supervisory signal to iteratively craft the prompt. Importantly, CyclePrompt reinforces model performance without expensive fine-tuning, without training data, and without the complexity of external environments (e.g. compilers, APIs). We demonstrate CyclePrompt in two domains: code gener",
    "path": "papers/24/02/2402.08756.json",
    "total_tokens": 957,
    "translated_title": "学习如何提问：循环一致性在多模态基础模型中优化提示",
    "translated_abstract": "当LLMs进行零-shot推断时，通常会使用一个包含任务规范的提示，并生成一个完成度。然而，还没有探索从完成度到任务规范的可能性。本文采用双向循环监督学习，完全在上下文中执行。我们的目标是创建一个前向映射f: X -> Y（例如，图像 -> 生成的标题），以及一个逆向映射g: Y -> X（例如，标题 -> 生成的图像），来构建一个循环一致性的“损失”（以提示的更新形式），以强制g(f(X))约等于X。这种技术称为CyclePrompt，利用循环一致性作为自由监督信号来循环性地构建提示。重要的是，CyclePrompt可以在不昂贵的微调、没有训练数据和没有复杂外部环境（如编译器、API）的情况下增强模型性能。我们在两个领域中展示了CyclePrompt：代码生成和图像字幕生成。",
    "tldr": "本文提出了一种称为CyclePrompt的技术，通过循环一致性优化提示，在多模态基础模型中进行循环一致性的监督学习。这种技术实现了从完成度到任务规范的反向推导，并且可以在没有昂贵微调、训练数据和复杂外部环境的情况下增强模型性能。",
    "en_tdlr": "This paper introduces a technique called CyclePrompt, which performs cycle-supervised learning in multimodal foundation models by optimizing prompts using cycle-consistency. It enables reverse inference from completion to task specification and improves model performance without expensive fine-tuning, training data, or complex external environments."
}