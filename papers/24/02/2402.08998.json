{
    "title": "Nearly Minimax Optimal Regret for Learning Linear Mixture Stochastic Shortest Path",
    "abstract": "arXiv:2402.08998v1 Announce Type: new Abstract: We study the Stochastic Shortest Path (SSP) problem with a linear mixture transition kernel, where an agent repeatedly interacts with a stochastic environment and seeks to reach certain goal state while minimizing the cumulative cost. Existing works often assume a strictly positive lower bound of the cost function or an upper bound of the expected length for the optimal policy. In this paper, we propose a new algorithm to eliminate these restrictive assumptions. Our algorithm is based on extended value iteration with a fine-grained variance-aware confidence set, where the variance is estimated recursively from high-order moments. Our algorithm achieves an $\\tilde{\\mathcal O}(dB_*\\sqrt{K})$ regret bound, where $d$ is the dimension of the feature mapping in the linear transition kernel, $B_*$ is the upper bound of the total cumulative cost for the optimal policy, and $K$ is the number of episodes. Our regret upper bound matches the $\\Omega(",
    "link": "https://arxiv.org/abs/2402.08998",
    "context": "Title: Nearly Minimax Optimal Regret for Learning Linear Mixture Stochastic Shortest Path\nAbstract: arXiv:2402.08998v1 Announce Type: new Abstract: We study the Stochastic Shortest Path (SSP) problem with a linear mixture transition kernel, where an agent repeatedly interacts with a stochastic environment and seeks to reach certain goal state while minimizing the cumulative cost. Existing works often assume a strictly positive lower bound of the cost function or an upper bound of the expected length for the optimal policy. In this paper, we propose a new algorithm to eliminate these restrictive assumptions. Our algorithm is based on extended value iteration with a fine-grained variance-aware confidence set, where the variance is estimated recursively from high-order moments. Our algorithm achieves an $\\tilde{\\mathcal O}(dB_*\\sqrt{K})$ regret bound, where $d$ is the dimension of the feature mapping in the linear transition kernel, $B_*$ is the upper bound of the total cumulative cost for the optimal policy, and $K$ is the number of episodes. Our regret upper bound matches the $\\Omega(",
    "path": "papers/24/02/2402.08998.json",
    "total_tokens": 947,
    "translated_title": "学习线性混合随机最短路径的近似最小最大遗憾",
    "translated_abstract": "我们研究了具有线性混合转移核函数的随机最短路径（SSP）问题，其中一个代理重复与随机环境互动，并寻求达到特定目标状态同时最小化累积成本。现有的工作通常假设成本函数具有严格的正下界，或者期望长度的最优策略具有上界。在本文中，我们提出了一种新的算法来消除这些限制性假设。我们的算法基于带有精细化方差感知置信区间的扩展值迭代，其中方差从高阶矩递归估计得到。我们的算法实现了$\\tilde{\\mathcal O}(dB_*\\sqrt{K})$ 的遗憾界，其中$d$ 是线性转移核函数中特征映射的维度，$B_*$ 是最优策略的总累积成本的上界，$K$ 是剧集的数量。我们的遗憾上界与$\\Omega(.",
    "tldr": "本文研究了具有线性混合转移核函数的随机最短路径问题，并提出了一种无需限制性假设的新算法。该算法基于带有方差感知置信区间的扩展值迭代，并通过高阶矩的递归估计实现了近似最小最大遗憾界。"
}