{
    "title": "Adaptive Optimization for Prediction with Missing Data",
    "abstract": "When training predictive models on data with missing entries, the most widely used and versatile approach is a pipeline technique where we first impute missing entries and then compute predictions. In this paper, we view prediction with missing data as a two-stage adaptive optimization problem and propose a new class of models, adaptive linear regression models, where the regression coefficients adapt to the set of observed features. We show that some adaptive linear regression models are equivalent to learning an imputation rule and a downstream linear regression model simultaneously instead of sequentially. We leverage this joint-impute-then-regress interpretation to generalize our framework to non-linear models. In settings where data is strongly not missing at random, our methods achieve a 2-10% improvement in out-of-sample accuracy.",
    "link": "https://rss.arxiv.org/abs/2402.01543",
    "context": "Title: Adaptive Optimization for Prediction with Missing Data\nAbstract: When training predictive models on data with missing entries, the most widely used and versatile approach is a pipeline technique where we first impute missing entries and then compute predictions. In this paper, we view prediction with missing data as a two-stage adaptive optimization problem and propose a new class of models, adaptive linear regression models, where the regression coefficients adapt to the set of observed features. We show that some adaptive linear regression models are equivalent to learning an imputation rule and a downstream linear regression model simultaneously instead of sequentially. We leverage this joint-impute-then-regress interpretation to generalize our framework to non-linear models. In settings where data is strongly not missing at random, our methods achieve a 2-10% improvement in out-of-sample accuracy.",
    "path": "papers/24/02/2402.01543.json",
    "total_tokens": 834,
    "translated_title": "针对缺失数据预测的自适应优化方法",
    "translated_abstract": "在训练具有缺失条目的预测模型时，最常用和多功能的方法是一种流水线技术，首先填充缺失条目，然后计算预测结果。本文将缺失数据预测视为一个两阶段的自适应优化问题，并提出了一种新的模型类别，自适应线性回归模型，其中回归系数能够适应观测特征集。我们表明一些自适应线性回归模型等同于同时学习填充规则和下游线性回归模型而不是顺序学习。我们利用这种联合填充-回归的解释将我们的框架推广到非线性模型。在数据非完全随机缺失的情况下，我们的方法在样外准确性方面实现了2-10%的改进。",
    "tldr": "本文提出了一种针对缺失数据预测的自适应优化方法，通过自适应线性回归模型来适应观测特征集，并将填充规则和回归模型同时学习，相比顺序学习方法，在数据非完全随机缺失情况下，方法实现了2-10%的准确性改进。"
}