{
    "title": "PAC Learnability under Explanation-Preserving Graph Perturbations",
    "abstract": "Graphical models capture relations between entities in a wide range of applications including social networks, biology, and natural language processing, among others. Graph neural networks (GNN) are neural models that operate over graphs, enabling the model to leverage the complex relationships and dependencies in graph-structured data. A graph explanation is a subgraph which is an `almost sufficient' statistic of the input graph with respect to its classification label. Consequently, the classification label is invariant, with high probability, to perturbations of graph edges not belonging to its explanation subgraph. This work considers two methods for leveraging such perturbation invariances in the design and training of GNNs. First, explanation-assisted learning rules are considered. It is shown that the sample complexity of explanation-assisted learning can be arbitrarily smaller than explanation-agnostic learning. Next, explanation-assisted data augmentation is considered, where ",
    "link": "https://arxiv.org/abs/2402.05039",
    "context": "Title: PAC Learnability under Explanation-Preserving Graph Perturbations\nAbstract: Graphical models capture relations between entities in a wide range of applications including social networks, biology, and natural language processing, among others. Graph neural networks (GNN) are neural models that operate over graphs, enabling the model to leverage the complex relationships and dependencies in graph-structured data. A graph explanation is a subgraph which is an `almost sufficient' statistic of the input graph with respect to its classification label. Consequently, the classification label is invariant, with high probability, to perturbations of graph edges not belonging to its explanation subgraph. This work considers two methods for leveraging such perturbation invariances in the design and training of GNNs. First, explanation-assisted learning rules are considered. It is shown that the sample complexity of explanation-assisted learning can be arbitrarily smaller than explanation-agnostic learning. Next, explanation-assisted data augmentation is considered, where ",
    "path": "papers/24/02/2402.05039.json",
    "total_tokens": 831,
    "translated_title": "PAC学习理论在保持解释的图扰动下的适用性",
    "translated_abstract": "图模型在社交网络、生物学、自然语言处理等广泛应用中捕捉实体之间的关系。图神经网络（GNN）是一种能够处理图结构数据中的复杂关系和依赖关系的神经模型。图解释是一个子图，它是相对于其分类标签而言输入图的一个“几乎足够”的统计量。因此，分类标签对于不属于解释子图的图边的扰动是不变的，且具有较高的概率。本文考虑了两种利用这种扰动不变性设计和训练GNN的方法。首先，考虑了解释辅助学习规则。结果表明，解释辅助学习的样本复杂度可以任意小于解释不可知学习。接下来，考虑了解释辅助数据增强，其中",
    "tldr": "本研究考虑了在设计和训练GNN时利用解释辅助学习和解释辅助数据增强的方法，并发现解释辅助学习的样本复杂度可以任意小于解释不可知学习。",
    "en_tdlr": "This work investigates the utilization of explanation-assisted learning and explanation-assisted data augmentation in the design and training of graph neural networks (GNNs), showing that explanation-assisted learning can have much smaller sample complexity compared to explanation-agnostic learning."
}