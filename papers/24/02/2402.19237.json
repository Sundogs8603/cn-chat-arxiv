{
    "title": "Context-based Interpretable Spatio-Temporal Graph Convolutional Network for Human Motion Forecasting",
    "abstract": "arXiv:2402.19237v1 Announce Type: cross  Abstract: Human motion prediction is still an open problem extremely important for autonomous driving and safety applications. Due to the complex spatiotemporal relation of motion sequences, this remains a challenging problem not only for movement prediction but also to perform a preliminary interpretation of the joint connections. In this work, we present a Context-based Interpretable Spatio-Temporal Graph Convolutional Network (CIST-GCN), as an efficient 3D human pose forecasting model based on GCNs that encompasses specific layers, aiding model interpretability and providing information that might be useful when analyzing motion distribution and body behavior. Our architecture extracts meaningful information from pose sequences, aggregates displacements and accelerations into the input model, and finally predicts the output displacements. Extensive experiments on Human 3.6M, AMASS, 3DPW, and ExPI datasets demonstrate that CIST-GCN outperforms",
    "link": "https://arxiv.org/abs/2402.19237",
    "context": "Title: Context-based Interpretable Spatio-Temporal Graph Convolutional Network for Human Motion Forecasting\nAbstract: arXiv:2402.19237v1 Announce Type: cross  Abstract: Human motion prediction is still an open problem extremely important for autonomous driving and safety applications. Due to the complex spatiotemporal relation of motion sequences, this remains a challenging problem not only for movement prediction but also to perform a preliminary interpretation of the joint connections. In this work, we present a Context-based Interpretable Spatio-Temporal Graph Convolutional Network (CIST-GCN), as an efficient 3D human pose forecasting model based on GCNs that encompasses specific layers, aiding model interpretability and providing information that might be useful when analyzing motion distribution and body behavior. Our architecture extracts meaningful information from pose sequences, aggregates displacements and accelerations into the input model, and finally predicts the output displacements. Extensive experiments on Human 3.6M, AMASS, 3DPW, and ExPI datasets demonstrate that CIST-GCN outperforms",
    "path": "papers/24/02/2402.19237.json",
    "total_tokens": 828,
    "translated_title": "基于上下文的可解释的时空图卷积网络用于人体运动预测",
    "translated_abstract": "人类运动预测仍然是一个重要但困难的问题，对自动驾驶和安全应用非常重要。在本文中，我们提出了一种基于上下文的可解释的时空图卷积网络（CIST-GCN），作为一种有效的基于GCN的3D人体姿势预测模型，具有特定层，辅助模型可解释性，并提供在分析运动分布和身体行为时可能有用的信息。我们的架构从姿势序列中提取有意义的信息，将位移和加速度聚合到输入模型中，最终预测输出位移。在Human 3.6M、AMASS、3DPW和ExPI数据集上的广泛实验表明，CIST-GCN的性能优于其他方法。",
    "tldr": "提出了基于上下文的可解释的时空图卷积网络（CIST-GCN），用于人体运动预测，在提高模型可解释性的基础上融合了GCN，在多个数据集上实验证明其优于其他方法。"
}