{
    "title": "Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education",
    "abstract": "arXiv:2402.15027v1 Announce Type: cross  Abstract: This study investigates the acceptability of different artificial intelligence (AI) applications in education from a multi-stakeholder perspective, including students, teachers, and parents. Acknowledging the transformative potential of AI in education, it addresses concerns related to data privacy, AI agency, transparency, explainability and the ethical deployment of AI. Through a vignette methodology, participants were presented with four scenarios where AI's agency, transparency, explainability, and privacy were manipulated. After each scenario, participants completed a survey that captured their perceptions of AI's global utility, individual usefulness, justice, confidence, risk, and intention to use each scenario's AI if available. The data collection comprising a final sample of 1198 multi-stakeholder participants was distributed through a partner institution and social media campaigns and focused on individual responses to four ",
    "link": "https://arxiv.org/abs/2402.15027",
    "context": "Title: Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education\nAbstract: arXiv:2402.15027v1 Announce Type: cross  Abstract: This study investigates the acceptability of different artificial intelligence (AI) applications in education from a multi-stakeholder perspective, including students, teachers, and parents. Acknowledging the transformative potential of AI in education, it addresses concerns related to data privacy, AI agency, transparency, explainability and the ethical deployment of AI. Through a vignette methodology, participants were presented with four scenarios where AI's agency, transparency, explainability, and privacy were manipulated. After each scenario, participants completed a survey that captured their perceptions of AI's global utility, individual usefulness, justice, confidence, risk, and intention to use each scenario's AI if available. The data collection comprising a final sample of 1198 multi-stakeholder participants was distributed through a partner institution and social media campaigns and focused on individual responses to four ",
    "path": "papers/24/02/2402.15027.json",
    "total_tokens": 886,
    "translated_title": "多利益相关者视角下的负责任人工智能与教育可接受性研究",
    "translated_abstract": "本研究从多利益相关者的视角，包括学生、教师和家长，调查了教育中不同人工智能（AI）应用的可接受性。认识到人工智能在教育中的变革潜力，它关注了与数据隐私、AI代理、透明度、可解释性以及道德部署有关的问题。通过创景方法，参与者被呈现了四个场景，其中AI的代理、透明度、可解释性和隐私遭到操纵。在每个场景后，参与者完成了一个调查问卷，其中捕捉了他们对AI的全球效用、个人实用性、公正性、信心、风险以及若每个场景的AI可用话，他们打算使用的意图。数据收集涵盖了最终样本量为1198名多利益相关者参与者，通过一个合作机构和社交媒体活动分发，并重点关注了对四个场景的个体回应。",
    "tldr": "本研究从多利益相关者视角探讨了教育中不同人工智能应用的可接受性，关注数据隐私、AI代理、透明度、可解释性和道德部署等问题。"
}