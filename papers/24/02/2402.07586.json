{
    "title": "Unveiling Group-Specific Distributed Concept Drift: A Fairness Imperative in Federated Learning",
    "abstract": "In the evolving field of machine learning, ensuring fairness has become a critical concern, prompting the development of algorithms designed to mitigate discriminatory outcomes in decision-making processes. However, achieving fairness in the presence of group-specific concept drift remains an unexplored frontier, and our research represents pioneering efforts in this regard. Group-specific concept drift refers to situations where one group experiences concept drift over time while another does not, leading to a decrease in fairness even if accuracy remains fairly stable. Within the framework of federated learning, where clients collaboratively train models, its distributed nature further amplifies these challenges since each client can experience group-specific concept drift independently while still sharing the same underlying concept, creating a complex and dynamic environment for maintaining fairness. One of the significant contributions of our research is the formalization and intr",
    "link": "https://arxiv.org/abs/2402.07586",
    "context": "Title: Unveiling Group-Specific Distributed Concept Drift: A Fairness Imperative in Federated Learning\nAbstract: In the evolving field of machine learning, ensuring fairness has become a critical concern, prompting the development of algorithms designed to mitigate discriminatory outcomes in decision-making processes. However, achieving fairness in the presence of group-specific concept drift remains an unexplored frontier, and our research represents pioneering efforts in this regard. Group-specific concept drift refers to situations where one group experiences concept drift over time while another does not, leading to a decrease in fairness even if accuracy remains fairly stable. Within the framework of federated learning, where clients collaboratively train models, its distributed nature further amplifies these challenges since each client can experience group-specific concept drift independently while still sharing the same underlying concept, creating a complex and dynamic environment for maintaining fairness. One of the significant contributions of our research is the formalization and intr",
    "path": "papers/24/02/2402.07586.json",
    "total_tokens": 887,
    "translated_title": "揭示特定群体的分布式概念漂移: 联邦学习中的公平要求",
    "translated_abstract": "在机器学习领域的不断发展中，确保公平性已成为一个重要关注点，推动了开发旨在减少决策过程中歧视结果的算法。然而，在存在特定群体的概念漂移的情况下实现公平性仍然是一个未被探索的领域，我们的研究代表了在这方面的开拓性努力。特定群体的概念漂移是指一个群体随时间经历概念漂移，而另一个群体却没有，导致公平性下降，即使准确性保持相对稳定。在联邦学习的框架下，客户端共同训练模型，其分布式性质进一步放大了这些挑战，因为每个客户端可以独立经历特定群体的概念漂移，同时仍共享相同的基本概念，从而创造了一个复杂而动态的环境来维持公平性。我们研究的一个重要贡献之一是对群体特定的概念漂移进行形式化和内部化的过程。",
    "tldr": "该研究在联邦学习中的分布式环境下，首次探索了在存在特定群体概念漂移的情况下实现公平性的挑战和解决方案。"
}