{
    "title": "Tell Me More! Towards Implicit User Intention Understanding of Language Model Driven Agents",
    "abstract": "arXiv:2402.09205v1 Announce Type: cross Abstract: Current language model-driven agents often lack mechanisms for effective user participation, which is crucial given the vagueness commonly found in user instructions. Although adept at devising strategies and performing tasks, these agents struggle with seeking clarification and grasping precise user intentions. To bridge this gap, we introduce Intention-in-Interaction (IN3), a novel benchmark designed to inspect users' implicit intentions through explicit queries. Next, we propose the incorporation of model experts as the upstream in agent designs to enhance user-agent interaction. Employing IN3, we empirically train Mistral-Interact, a powerful model that proactively assesses task vagueness, inquires user intentions, and refines them into actionable goals before starting downstream agent task execution. Integrating it into the XAgent framework, we comprehensively evaluate the enhanced agent system regarding user instruction understand",
    "link": "https://arxiv.org/abs/2402.09205",
    "context": "Title: Tell Me More! Towards Implicit User Intention Understanding of Language Model Driven Agents\nAbstract: arXiv:2402.09205v1 Announce Type: cross Abstract: Current language model-driven agents often lack mechanisms for effective user participation, which is crucial given the vagueness commonly found in user instructions. Although adept at devising strategies and performing tasks, these agents struggle with seeking clarification and grasping precise user intentions. To bridge this gap, we introduce Intention-in-Interaction (IN3), a novel benchmark designed to inspect users' implicit intentions through explicit queries. Next, we propose the incorporation of model experts as the upstream in agent designs to enhance user-agent interaction. Employing IN3, we empirically train Mistral-Interact, a powerful model that proactively assesses task vagueness, inquires user intentions, and refines them into actionable goals before starting downstream agent task execution. Integrating it into the XAgent framework, we comprehensively evaluate the enhanced agent system regarding user instruction understand",
    "path": "papers/24/02/2402.09205.json",
    "total_tokens": 941,
    "translated_title": "告诉我更多！面向基于语言模型的智能代理的隐式用户意图理解",
    "translated_abstract": "当前的语言模型驱动代理常常缺乏有效的用户参与机制，考虑到用户指令中常见的模糊性，这是至关重要的。虽然这些代理在制定策略和执行任务方面表现出色，但在寻求澄清和抓住精确的用户意图方面却遇到了困难。为了填补这一差距，我们引入了Intention-in-Interaction (IN3) ，这是一个旨在通过明确的查询检查用户的隐含意图的新颖基准。接下来，我们提出将模型专家作为上游融入代理设计中，以增强用户-代理交互。利用IN3，我们经验性地训练了Mistral-Interact，这是一个强大的模型，它可以主动评估任务的模糊性，询问用户意图，并将其转化为可行的目标，然后开始下游代理任务执行。将其集成到XAgent框架中，我们对增强的代理系统进行了全面评估，以评估用户指令的理解能力。",
    "tldr": "该论文提出了一种面向基于语言模型的智能代理的隐式用户意图理解的方法。通过引入Intention-in-Interaction (IN3) 基准和在代理设计中融入模型专家，使得代理能够更好地与用户进行交互，并提升对用户指令的理解能力。",
    "en_tdlr": "This paper proposes an approach for implicit user intention understanding of language model-driven agents. By introducing the Intention-in-Interaction (IN3) benchmark and incorporating model experts in agent designs, the agents are able to interact more effectively with users and enhance their understanding of user instructions."
}