{
    "title": "Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation",
    "abstract": "arXiv:2402.18191v1 Announce Type: new  Abstract: With contributions from the open-source community, a vast amount of instruction tuning (IT) data has emerged. Given the significant resource allocation required by training and evaluating models, it is advantageous to have an efficient method for selecting high-quality IT data. However, existing methods for instruction data selection have limitations such as relying on fragile external APIs, being affected by biases in GPT models, or reducing the diversity of the selected instruction dataset. In this paper, we propose an industrial-friendly, expert-aligned and diversity-preserved instruction data selection method: Clustering and Ranking (CaR). CaR consists of two steps. The first step involves ranking instruction pairs using a scoring model that is well aligned with expert preferences (achieving an accuracy of 84.25%). The second step involves preserving dataset diversity through a clustering process.In our experiment, CaR selected a sub",
    "link": "https://arxiv.org/abs/2402.18191",
    "context": "Title: Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation\nAbstract: arXiv:2402.18191v1 Announce Type: new  Abstract: With contributions from the open-source community, a vast amount of instruction tuning (IT) data has emerged. Given the significant resource allocation required by training and evaluating models, it is advantageous to have an efficient method for selecting high-quality IT data. However, existing methods for instruction data selection have limitations such as relying on fragile external APIs, being affected by biases in GPT models, or reducing the diversity of the selected instruction dataset. In this paper, we propose an industrial-friendly, expert-aligned and diversity-preserved instruction data selection method: Clustering and Ranking (CaR). CaR consists of two steps. The first step involves ranking instruction pairs using a scoring model that is well aligned with expert preferences (achieving an accuracy of 84.25%). The second step involves preserving dataset diversity through a clustering process.In our experiment, CaR selected a sub",
    "path": "papers/24/02/2402.18191.json",
    "total_tokens": 829,
    "translated_title": "聚类与排序：通过专家定位质量估计实现保留多样性的指令选择",
    "translated_abstract": "随着开源社区的贡献，涌现了大量指令调优（IT）数据。鉴于训练和评估模型需要大量资源分配，因此有必要采用高效的方法选择高质量的IT数据。然而，现有的指令数据选择方法存在一些限制，比如依赖脆弱的外部API、受GPT模型偏见影响，或减少所选指令数据集的多样性。在本文中，我们提出了一种面向工业的、与专家定位相吻合并保留多样性的指令数据选择方法：聚类与排序（CaR）。CaR分为两个步骤。第一步涉及使用与专家偏好很好对齐的评分模型对指令对进行排名（准确率达到84.25%）。第二步通过聚类过程保留数据集多样性。在我们的实验中，CaR选择了一个子集",
    "tldr": "本文提出了一种聚类与排序方法（CaR），通过与专家偏好相一致的评分模型排名指令对，保留了数据集的多样性。",
    "en_tdlr": "This paper introduces a clustering and ranking method (CaR) that ranks instruction pairs using a scoring model aligned with expert preferences, preserving the diversity of the dataset."
}