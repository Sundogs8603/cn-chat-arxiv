{
    "title": "Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following",
    "abstract": "Diffusion models excel at modeling complex and multimodal trajectory distributions for decision-making and control. Reward-gradient guided denoising has been recently proposed to generate trajectories that maximize both a differentiable reward function and the likelihood under the data distribution captured by a diffusion model. Reward-gradient guided denoising requires a differentiable reward function fitted to both clean and noised samples, limiting its applicability as a general trajectory optimizer. In this paper, we propose DiffusionES, a method that combines gradient-free optimization with trajectory denoising to optimize black-box non-differentiable objectives while staying in the data manifold. Diffusion-ES samples trajectories during evolutionary search from a diffusion model and scores them using a black-box reward function. It mutates high-scoring trajectories using a truncated diffusion process that applies a small number of noising and denoising steps, allowing for much mo",
    "link": "https://arxiv.org/abs/2402.06559",
    "context": "Title: Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following\nAbstract: Diffusion models excel at modeling complex and multimodal trajectory distributions for decision-making and control. Reward-gradient guided denoising has been recently proposed to generate trajectories that maximize both a differentiable reward function and the likelihood under the data distribution captured by a diffusion model. Reward-gradient guided denoising requires a differentiable reward function fitted to both clean and noised samples, limiting its applicability as a general trajectory optimizer. In this paper, we propose DiffusionES, a method that combines gradient-free optimization with trajectory denoising to optimize black-box non-differentiable objectives while staying in the data manifold. Diffusion-ES samples trajectories during evolutionary search from a diffusion model and scores them using a black-box reward function. It mutates high-scoring trajectories using a truncated diffusion process that applies a small number of noising and denoising steps, allowing for much mo",
    "path": "papers/24/02/2402.06559.json",
    "total_tokens": 951,
    "translated_title": "Diffusion-ES:基于扩散的零梯度规划用于自动驾驶和零阶指令跟随",
    "translated_abstract": "扩散模型在决策和控制中对复杂和多模态轨迹分布建模有很强优势。最近提出了奖励梯度引导去噪方法，用于产生在扩散模型所捕获的数据分布下，同时最大化可微分奖励函数和似然性的轨迹。奖励梯度引导去噪需要一个适合于清洁和噪声样本的可微分奖励函数，从而限制了其作为一种通用轨迹优化器的适用性。在本文中，我们提出了DiffusionES，一种将无梯度优化和轨迹去噪相结合的方法，用于在数据流形中优化黑盒非可微目标。Diffusion-ES从扩散模型中采样轨迹，并使用黑盒奖励函数对其进行评分。它通过截断扩散过程对得分高的轨迹进行变异，该过程应用少量的噪声和去噪步骤，从而实现了更高的多样性和更好的可解释性。",
    "tldr": "本文提出了一种Diffusion-ES方法，它结合了无梯度优化和轨迹去噪技术，用于优化黑盒非可微目标。该方法通过从扩散模型中采样轨迹，并使用黑盒奖励函数对其进行评分，实现了更高的多样性和可解释性。"
}