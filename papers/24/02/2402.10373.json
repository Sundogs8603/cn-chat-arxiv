{
    "title": "BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains",
    "abstract": "arXiv:2402.10373v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated remarkable versatility in recent years, offering potential applications across specialized domains such as healthcare and medicine. Despite the availability of various open-source LLMs tailored for health contexts, adapting general-purpose LLMs to the medical domain presents significant challenges. In this paper, we introduce BioMistral, an open-source LLM tailored for the biomedical domain, utilizing Mistral as its foundation model and further pre-trained on PubMed Central. We conduct a comprehensive evaluation of BioMistral on a benchmark comprising 10 established medical question-answering (QA) tasks in English. We also explore lightweight models obtained through quantization and model merging approaches. Our results demonstrate BioMistral's superior performance compared to existing open-source medical models and its competitive edge against proprietary counterparts. Finally, to address",
    "link": "https://arxiv.org/abs/2402.10373",
    "context": "Title: BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains\nAbstract: arXiv:2402.10373v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated remarkable versatility in recent years, offering potential applications across specialized domains such as healthcare and medicine. Despite the availability of various open-source LLMs tailored for health contexts, adapting general-purpose LLMs to the medical domain presents significant challenges. In this paper, we introduce BioMistral, an open-source LLM tailored for the biomedical domain, utilizing Mistral as its foundation model and further pre-trained on PubMed Central. We conduct a comprehensive evaluation of BioMistral on a benchmark comprising 10 established medical question-answering (QA) tasks in English. We also explore lightweight models obtained through quantization and model merging approaches. Our results demonstrate BioMistral's superior performance compared to existing open-source medical models and its competitive edge against proprietary counterparts. Finally, to address",
    "path": "papers/24/02/2402.10373.json",
    "total_tokens": 858,
    "translated_title": "BioMistral：面向医学领域的开源预训练大型语言模型集合",
    "translated_abstract": "大型语言模型（LLMs）近年来展示出卓越的多功能性，为医疗保健和医学等专业领域提供潜在应用。尽管有各种针对健康领域定制的开源LLMs可用，但将通用LLMs调整到医学领域仍面临重大挑战。本文介绍了BioMistral，一种专为生物医学领域量身定制的开源LLM，采用Mistral作为基础模型，并在PubMed Central上进一步进行预训练。我们在包含10个已建立的英文医学问答（QA）任务的基准上对BioMistral进行了全面评估。我们还探讨通过量化和模型合并方法获得的轻量级模型。我们的结果表明，BioMistral相较于现有开源医学模型具有优越性能，并与专有对手具有竞争优势。最后，为了解决",
    "tldr": "BioMistral是一种面向生物医学领域的开源预训练大型语言模型集合，在医学问答任务中表现出优越性能并具有竞争优势。",
    "en_tdlr": "BioMistral is an open-source pretrained large language model collection tailored for the biomedical domain, demonstrating superior performance in medical question-answering tasks and competitive edge."
}