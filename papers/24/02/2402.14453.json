{
    "title": "Do LLMs Implicitly Determine the Suitable Text Difficulty for Users?",
    "abstract": "arXiv:2402.14453v1 Announce Type: new  Abstract: Education that suits the individual learning level is necessary to improve students' understanding. The first step in achieving this purpose by using large language models (LLMs) is to adjust the textual difficulty of the response to students. This work analyzes how LLMs can implicitly adjust text difficulty between user input and its generated text. To conduct the experiments, we created a new dataset from Stack-Overflow to explore the performance of question-answering-based conversation. Experimental results on the Stack-Overflow dataset and the TSCC dataset, including multi-turn conversation show that LLMs can implicitly handle text difficulty between user input and its generated response. We also observed that some LLMs can surpass humans in handling text difficulty and the importance of instruction-tuning.",
    "link": "https://arxiv.org/abs/2402.14453",
    "context": "Title: Do LLMs Implicitly Determine the Suitable Text Difficulty for Users?\nAbstract: arXiv:2402.14453v1 Announce Type: new  Abstract: Education that suits the individual learning level is necessary to improve students' understanding. The first step in achieving this purpose by using large language models (LLMs) is to adjust the textual difficulty of the response to students. This work analyzes how LLMs can implicitly adjust text difficulty between user input and its generated text. To conduct the experiments, we created a new dataset from Stack-Overflow to explore the performance of question-answering-based conversation. Experimental results on the Stack-Overflow dataset and the TSCC dataset, including multi-turn conversation show that LLMs can implicitly handle text difficulty between user input and its generated response. We also observed that some LLMs can surpass humans in handling text difficulty and the importance of instruction-tuning.",
    "path": "papers/24/02/2402.14453.json",
    "total_tokens": 729,
    "translated_title": "LLM是否隐含地确定用户的适宜文本难度?",
    "translated_abstract": "适应个体学习水平的教育对提高学生的理解力是必要的。利用大型语言模型（LLMs）实现这一目的的第一步是调整文本难度以适应学生。本文分析了LLMs如何在用户输入和生成的文本之间隐式调整文本难度。为了进行实验，我们从Stack Overflow创建了一个新的数据集，以探索基于问答的对话性能。在Stack Overflow数据集和TSCC数据集上进行的实验结果，包括多轮对话，表明LLMs可以隐式处理用户输入和生成的响应之间的文本难度。我们还观察到一些LLMs在处理文本难度和指导调整的重要性方面可以超越人类。",
    "tldr": "LLMs可以隐式处理用户输入和生成的响应之间的文本难度，有些LLMs在处理文本难度上甚至可以超越人类。",
    "en_tdlr": "LLMs can implicitly handle text difficulty between user input and generated response, with some LLMs even surpassing humans in handling text difficulty."
}