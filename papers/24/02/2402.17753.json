{
    "title": "Evaluating Very Long-Term Conversational Memory of LLM Agents",
    "abstract": "arXiv:2402.17753v1 Announce Type: cross  Abstract: Existing works on long-term open-domain dialogues focus on evaluating model responses within contexts spanning no more than five chat sessions. Despite advancements in long-context large language models (LLMs) and retrieval augmented generation (RAG) techniques, their efficacy in very long-term dialogues remains unexplored. To address this research gap, we introduce a machine-human pipeline to generate high-quality, very long-term dialogues by leveraging LLM-based agent architectures and grounding their dialogues on personas and temporal event graphs. Moreover, we equip each agent with the capability of sharing and reacting to images. The generated conversations are verified and edited by human annotators for long-range consistency and grounding to the event graphs. Using this pipeline, we collect LoCoMo, a dataset of very long-term conversations, each encompassing 300 turns and 9K tokens on avg., over up to 35 sessions. Based on LoCoM",
    "link": "https://arxiv.org/abs/2402.17753",
    "context": "Title: Evaluating Very Long-Term Conversational Memory of LLM Agents\nAbstract: arXiv:2402.17753v1 Announce Type: cross  Abstract: Existing works on long-term open-domain dialogues focus on evaluating model responses within contexts spanning no more than five chat sessions. Despite advancements in long-context large language models (LLMs) and retrieval augmented generation (RAG) techniques, their efficacy in very long-term dialogues remains unexplored. To address this research gap, we introduce a machine-human pipeline to generate high-quality, very long-term dialogues by leveraging LLM-based agent architectures and grounding their dialogues on personas and temporal event graphs. Moreover, we equip each agent with the capability of sharing and reacting to images. The generated conversations are verified and edited by human annotators for long-range consistency and grounding to the event graphs. Using this pipeline, we collect LoCoMo, a dataset of very long-term conversations, each encompassing 300 turns and 9K tokens on avg., over up to 35 sessions. Based on LoCoM",
    "path": "papers/24/02/2402.17753.json",
    "total_tokens": 873,
    "translated_title": "评估LLM代理的非常长期对话记忆",
    "translated_abstract": "长期开放领域对话方面的现有研究主要集中在评估模型响应，其上下文跨度不超过五个聊天会话。尽管长上下文大语言模型（LLMs）和检索增强生成（RAG）技术有所进展，但它们在非常长期对话中的有效性尚未被探索。为了解决这一研究空白，我们介绍了一种机器-人的流程，通过利用基于LLM的代理架构生成高质量的非常长期对话，并将其对话基于人物角色和时间事件图进行基础。此外，我们赋予每个代理分享和对图像做出反应的能力。生成的对话经人类注释员验证和编辑，以确保长期一致性和与事件图的基础相联系。使用此流程，我们收集了LoCoMo，一个非常长期对话的数据集，每个数据集包含300轮和平均9K令牌，最多达到35个会话。",
    "tldr": "通过引入机器-人流程，基于LLM代理架构并将其对话基于人物角色和时间事件图进行基础，成功创建了LoCoMo数据集，为非常长期对话的研究填补了空白。",
    "en_tdlr": "Filling the research gap on very long-term dialogues, a machine-human pipeline leveraging LLM agent architectures grounded on personas and temporal event graphs successfully created the LoCoMo dataset."
}