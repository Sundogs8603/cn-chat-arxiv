{
    "title": "Large Language Models as Data Augmenters for Cold-Start Item Recommendation",
    "abstract": "arXiv:2402.11724v1 Announce Type: new  Abstract: The reasoning and generalization capabilities of LLMs can help us better understand user preferences and item characteristics, offering exciting prospects to enhance recommendation systems. Though effective while user-item interactions are abundant, conventional recommendation systems struggle to recommend cold-start items without historical interactions. To address this, we propose utilizing LLMs as data augmenters to bridge the knowledge gap on cold-start items during training. We employ LLMs to infer user preferences for cold-start items based on textual description of user historical behaviors and new item descriptions. The augmented training signals are then incorporated into learning the downstream recommendation models through an auxiliary pairwise loss. Through experiments on public Amazon datasets, we demonstrate that LLMs can effectively augment the training signals for cold-start items, leading to significant improvements in c",
    "link": "https://arxiv.org/abs/2402.11724",
    "context": "Title: Large Language Models as Data Augmenters for Cold-Start Item Recommendation\nAbstract: arXiv:2402.11724v1 Announce Type: new  Abstract: The reasoning and generalization capabilities of LLMs can help us better understand user preferences and item characteristics, offering exciting prospects to enhance recommendation systems. Though effective while user-item interactions are abundant, conventional recommendation systems struggle to recommend cold-start items without historical interactions. To address this, we propose utilizing LLMs as data augmenters to bridge the knowledge gap on cold-start items during training. We employ LLMs to infer user preferences for cold-start items based on textual description of user historical behaviors and new item descriptions. The augmented training signals are then incorporated into learning the downstream recommendation models through an auxiliary pairwise loss. Through experiments on public Amazon datasets, we demonstrate that LLMs can effectively augment the training signals for cold-start items, leading to significant improvements in c",
    "path": "papers/24/02/2402.11724.json",
    "total_tokens": 918,
    "translated_title": "将大型语言模型用作冷启动物品推荐的数据增强器",
    "translated_abstract": "arXiv:2402.11724v1 公告类型: 新  摘要: LLM的推理和泛化能力可以帮助我们更好地理解用户偏好和物品特征，为增强推荐系统提供了令人兴奋的前景。虽然在用户物品交互丰富时很有效，但传统的推荐系统在没有历史交互的冷启动物品推荐方面存在困难。为了解决这个问题，我们提出利用LLM作为数据增强器，以在训练过程中弥合对冷启动物品的知识差距。我们利用LLM根据用户历史行为的文本描述和新物品描述推断用户对冷启动物品的偏好。然后将增强的训练信号通过辅助配对损失纳入到学习下游推荐模型中。通过在公共亚马逊数据集上的实验，我们证明LLM可以有效地增强冷启动物品的训练信号，从而显著提高了c",
    "tldr": "将大型语言模型用作数据增强器，以解决传统推荐系统在冷启动物品推荐方面的困难。通过结合LLM推断用户对冷启动物品的偏好并将增强的训练信号纳入推荐模型学习，实现对冷启动物品的显著提升。",
    "en_tdlr": "Using large language models as data augmenters to address the challenges of conventional recommendation systems in recommending cold-start items. By leveraging LLMs to infer user preferences for cold-start items and incorporating augmented training signals into recommendation model learning, significant improvements for cold-start items are achieved."
}