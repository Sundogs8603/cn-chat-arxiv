{
    "title": "Distilling LLMs' Decomposition Abilities into Compact Language Models",
    "abstract": "Large Language Models (LLMs) have demonstrated proficiency in their reasoning abilities, yet their large size presents scalability challenges and limits any further customization. In contrast, compact models offer customized training but often fall short in solving complex reasoning tasks. This study focuses on distilling the LLMs' decomposition skills into compact models using offline reinforcement learning. We leverage the advancements in the LLM`s capabilities to provide feedback and generate a specialized task-specific dataset for training compact models. The development of an AI-generated dataset and the establishment of baselines constitute the primary contributions of our work, underscoring the potential of compact models in replicating complex problem-solving skills.",
    "link": "https://arxiv.org/abs/2402.01812",
    "context": "Title: Distilling LLMs' Decomposition Abilities into Compact Language Models\nAbstract: Large Language Models (LLMs) have demonstrated proficiency in their reasoning abilities, yet their large size presents scalability challenges and limits any further customization. In contrast, compact models offer customized training but often fall short in solving complex reasoning tasks. This study focuses on distilling the LLMs' decomposition skills into compact models using offline reinforcement learning. We leverage the advancements in the LLM`s capabilities to provide feedback and generate a specialized task-specific dataset for training compact models. The development of an AI-generated dataset and the establishment of baselines constitute the primary contributions of our work, underscoring the potential of compact models in replicating complex problem-solving skills.",
    "path": "papers/24/02/2402.01812.json",
    "total_tokens": 762,
    "translated_title": "将LLMs的分解能力融入到紧凑语言模型中",
    "translated_abstract": "大型语言模型（LLMs）展示了其推理能力，但其庞大的大小带来了可扩展性挑战，并限制了进一步的定制。相比之下，紧凑模型提供了定制化培训，但在解决复杂推理任务方面往往不足。本研究着重于使用离线强化学习将LLMs的分解能力融入到紧凑模型中。我们利用LLM能力的进步，提供反馈并生成专门用于训练紧凑模型的特定任务数据集。通过开发一个由AI生成的数据集和建立基准，我们的工作主要贡献在于强调了紧凑模型在复制复杂问题解决能力方面的潜力。",
    "tldr": "本研究将LLMs的分解能力通过离线强化学习融入到紧凑模型中，通过开发AI生成的数据集和建立基准，突出了紧凑模型在复制复杂问题解决能力方面的潜力。",
    "en_tdlr": "This study integrates the decomposition abilities of LLMs into compact models using offline reinforcement learning, and highlights the potential of compact models in replicating complex problem-solving skills through the development of an AI-generated dataset and the establishment of baselines."
}