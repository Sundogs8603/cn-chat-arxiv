{
    "title": "Accuracy of TextFooler black box adversarial attacks on 01 loss sign activation neural network ensemble",
    "abstract": "Recent work has shown the defense of 01 loss sign activation neural networks against image classification adversarial attacks. A public challenge to attack the models on CIFAR10 dataset remains undefeated. We ask the following question in this study: are 01 loss sign activation neural networks hard to deceive with a popular black box text adversarial attack program called TextFooler? We study this question on four popular text classification datasets: IMDB reviews, Yelp reviews, MR sentiment classification, and AG news classification. We find that our 01 loss sign activation network is much harder to attack with TextFooler compared to sigmoid activation cross entropy and binary neural networks. We also study a 01 loss sign activation convolutional neural network with a novel global pooling step specific to sign activation networks. With this new variation we see a significant gain in adversarial accuracy rendering TextFooler practically useless against it. We make our code freely avail",
    "link": "https://arxiv.org/abs/2402.07347",
    "context": "Title: Accuracy of TextFooler black box adversarial attacks on 01 loss sign activation neural network ensemble\nAbstract: Recent work has shown the defense of 01 loss sign activation neural networks against image classification adversarial attacks. A public challenge to attack the models on CIFAR10 dataset remains undefeated. We ask the following question in this study: are 01 loss sign activation neural networks hard to deceive with a popular black box text adversarial attack program called TextFooler? We study this question on four popular text classification datasets: IMDB reviews, Yelp reviews, MR sentiment classification, and AG news classification. We find that our 01 loss sign activation network is much harder to attack with TextFooler compared to sigmoid activation cross entropy and binary neural networks. We also study a 01 loss sign activation convolutional neural network with a novel global pooling step specific to sign activation networks. With this new variation we see a significant gain in adversarial accuracy rendering TextFooler practically useless against it. We make our code freely avail",
    "path": "papers/24/02/2402.07347.json",
    "total_tokens": 946,
    "translated_title": "TextFooler黑盒对01 loss sign激活神经网络集成的攻击准确性",
    "translated_abstract": "最近的研究表明，01 loss sign激活神经网络在图像分类对抗攻击方面具有防御能力。针对CIFAR10数据集攻击模型的公共挑战仍然保持不败。在本研究中，我们提出以下问题：使用一种名为TextFooler的流行黑盒文本对抗攻击程序来欺骗01 loss sign激活神经网络困难吗？我们在四个流行的文本分类数据集上研究了这个问题：IMDB评论、Yelp评论、MR情感分类和AG新闻分类。我们发现，与sigmoid激活交叉熵和二进制神经网络相比，我们的01 loss sign激活网络更难受到TextFooler的攻击。我们还研究了一种01 loss sign激活卷积神经网络，它具有一种针对sign激活网络的新型全局汇集步骤。通过这种新的变体，我们看到了在对抗精确度方面的显著提高，使得TextFooler对它几乎无效。我们提供我们的代码供免费使用。",
    "tldr": "本研究研究了TextFooler黑盒对01 loss sign激活神经网络集成的攻击准确性。研究发现，相比于sigmoid激活交叉熵和二进制神经网络，使用01 loss sign激活的网络更难受到TextFooler的攻击，并且通过引入一种新的全局汇集步骤，进一步提高了对抗精确度，使TextFooler几乎无效化。"
}