{
    "title": "Hierarchical Invariance for Robust and Interpretable Vision Tasks at Larger Scales",
    "abstract": "arXiv:2402.15430v1 Announce Type: cross  Abstract: Developing robust and interpretable vision systems is a crucial step towards trustworthy artificial intelligence. In this regard, a promising paradigm considers embedding task-required invariant structures, e.g., geometric invariance, in the fundamental image representation. However, such invariant representations typically exhibit limited discriminability, limiting their applications in larger-scale trustworthy vision tasks. For this open problem, we conduct a systematic investigation of hierarchical invariance, exploring this topic from theoretical, practical, and application perspectives. At the theoretical level, we show how to construct over-complete invariants with a Convolutional Neural Networks (CNN)-like hierarchical architecture yet in a fully interpretable manner. The general blueprint, specific definitions, invariant properties, and numerical implementations are provided. At the practical level, we discuss how to customize ",
    "link": "https://arxiv.org/abs/2402.15430",
    "context": "Title: Hierarchical Invariance for Robust and Interpretable Vision Tasks at Larger Scales\nAbstract: arXiv:2402.15430v1 Announce Type: cross  Abstract: Developing robust and interpretable vision systems is a crucial step towards trustworthy artificial intelligence. In this regard, a promising paradigm considers embedding task-required invariant structures, e.g., geometric invariance, in the fundamental image representation. However, such invariant representations typically exhibit limited discriminability, limiting their applications in larger-scale trustworthy vision tasks. For this open problem, we conduct a systematic investigation of hierarchical invariance, exploring this topic from theoretical, practical, and application perspectives. At the theoretical level, we show how to construct over-complete invariants with a Convolutional Neural Networks (CNN)-like hierarchical architecture yet in a fully interpretable manner. The general blueprint, specific definitions, invariant properties, and numerical implementations are provided. At the practical level, we discuss how to customize ",
    "path": "papers/24/02/2402.15430.json",
    "total_tokens": 785,
    "translated_title": "较大尺度下用于稳健且可解释视觉任务的分层不变性",
    "translated_abstract": "开发稳健且可解释的视觉系统是迈向可靠人工智能的关键一步。在这方面，一个有前途的范式是考虑在基本图像表示中嵌入任务所需的不变结构，例如几何不变性。然而，这种不变的表示通常表现出有限的可区分性，限制了它们在更大规模的可靠视觉任务中的应用。针对这个开放性问题，我们从理论、实践和应用的角度对分层不变性进行了系统研究。在理论层面上，我们展示了如何以类似于卷积神经网络（CNN）的分层体系结构但以完全可解释的方式构建超完备不变性。我们提供了通用蓝图、具体定义、不变特性和数值实现。在实践层面上，我们讨论了如何定制不变性以适应更大规模的视觉任务。",
    "tldr": "通过分层不变性构建稳健且可解释的视觉系统，克服了不变性表示在较大规模的视觉任务中可区分性有限的问题。"
}