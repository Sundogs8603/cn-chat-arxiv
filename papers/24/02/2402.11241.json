{
    "title": "DiffPoint: Single and Multi-view Point Cloud Reconstruction with ViT Based Diffusion Model",
    "abstract": "arXiv:2402.11241v1 Announce Type: cross  Abstract: As the task of 2D-to-3D reconstruction has gained significant attention in various real-world scenarios, it becomes crucial to be able to generate high-quality point clouds. Despite the recent success of deep learning models in generating point clouds, there are still challenges in producing high-fidelity results due to the disparities between images and point clouds. While vision transformers (ViT) and diffusion models have shown promise in various vision tasks, their benefits for reconstructing point clouds from images have not been demonstrated yet. In this paper, we first propose a neat and powerful architecture called DiffPoint that combines ViT and diffusion models for the task of point cloud reconstruction. At each diffusion step, we divide the noisy point clouds into irregular patches. Then, using a standard ViT backbone that treats all inputs as tokens (including time information, image embeddings, and noisy patches), we train",
    "link": "https://arxiv.org/abs/2402.11241",
    "context": "Title: DiffPoint: Single and Multi-view Point Cloud Reconstruction with ViT Based Diffusion Model\nAbstract: arXiv:2402.11241v1 Announce Type: cross  Abstract: As the task of 2D-to-3D reconstruction has gained significant attention in various real-world scenarios, it becomes crucial to be able to generate high-quality point clouds. Despite the recent success of deep learning models in generating point clouds, there are still challenges in producing high-fidelity results due to the disparities between images and point clouds. While vision transformers (ViT) and diffusion models have shown promise in various vision tasks, their benefits for reconstructing point clouds from images have not been demonstrated yet. In this paper, we first propose a neat and powerful architecture called DiffPoint that combines ViT and diffusion models for the task of point cloud reconstruction. At each diffusion step, we divide the noisy point clouds into irregular patches. Then, using a standard ViT backbone that treats all inputs as tokens (including time information, image embeddings, and noisy patches), we train",
    "path": "papers/24/02/2402.11241.json",
    "total_tokens": 838,
    "translated_title": "DiffPoint: 使用基于ViT的扩散模型进行单视点和多视点点云重建",
    "translated_abstract": "随着在各种现实世界场景中2D到3D重建任务引起了显著关注，生成高质量点云变得至关重要。尽管深度学习模型在生成点云方面取得了最近的成功，但由于图像和点云之间的差异，仍然存在产生高保真结果的挑战。虽然视觉Transformer（ViT）和扩散模型在各种视觉任务中显示出潜力，但它们对从图像重建点云的好处尚未得到证明。在本文中，我们首先提出了一个简洁而强大的架构，名为DiffPoint，它结合了ViT和扩散模型来进行点云重建任务。在每个扩散步骤中，我们将带有噪声的点云分成不规则的补丁。然后，使用一个标准的ViT主干，将所有输入（包括时间信息、图像嵌入和有噪声的补丁）视为令牌，我们进行训练。",
    "tldr": "DiffPoint是一种结合了ViT和扩散模型的新型架构，用于实现点云重建任务。",
    "en_tdlr": "DiffPoint is a novel architecture that combines ViT and diffusion models for point cloud reconstruction task."
}