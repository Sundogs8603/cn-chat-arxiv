{
    "title": "SciAgent: Tool-augmented Language Models for Scientific Reasoning",
    "abstract": "arXiv:2402.11451v1 Announce Type: cross  Abstract: Scientific reasoning poses an excessive challenge for even the most advanced Large Language Models (LLMs). To make this task more practical and solvable for LLMs, we introduce a new task setting named tool-augmented scientific reasoning. This setting supplements LLMs with scalable toolsets, and shifts the focus from pursuing an omniscient problem solver to a proficient tool-user. To facilitate the research of such setting, we construct a tool-augmented training corpus named MathFunc which encompasses over 30,000 samples and roughly 6,000 tools. Building on MathFunc, we develop SciAgent to retrieve, understand and, if necessary, use tools for scientific problem solving. Additionally, we craft a benchmark, SciToolBench, spanning five scientific domains to evaluate LLMs' abilities with tool assistance. Extensive experiments on SciToolBench confirm the effectiveness of SciAgent. Notably, SciAgent-Mistral-7B surpasses other LLMs with the sa",
    "link": "https://arxiv.org/abs/2402.11451",
    "context": "Title: SciAgent: Tool-augmented Language Models for Scientific Reasoning\nAbstract: arXiv:2402.11451v1 Announce Type: cross  Abstract: Scientific reasoning poses an excessive challenge for even the most advanced Large Language Models (LLMs). To make this task more practical and solvable for LLMs, we introduce a new task setting named tool-augmented scientific reasoning. This setting supplements LLMs with scalable toolsets, and shifts the focus from pursuing an omniscient problem solver to a proficient tool-user. To facilitate the research of such setting, we construct a tool-augmented training corpus named MathFunc which encompasses over 30,000 samples and roughly 6,000 tools. Building on MathFunc, we develop SciAgent to retrieve, understand and, if necessary, use tools for scientific problem solving. Additionally, we craft a benchmark, SciToolBench, spanning five scientific domains to evaluate LLMs' abilities with tool assistance. Extensive experiments on SciToolBench confirm the effectiveness of SciAgent. Notably, SciAgent-Mistral-7B surpasses other LLMs with the sa",
    "path": "papers/24/02/2402.11451.json",
    "total_tokens": 894,
    "translated_title": "SciAgent: 工具增强型语言模型用于科学推理",
    "translated_abstract": "科学推理对于即使最先进的大型语言模型（LLMs）来说也是一项巨大挑战。为了使LLMs更加实用和可解决此任务，我们引入了一种名为工具增强型科学推理的新任务设置。这种设置通过为LLMs提供可扩展的工具集，将重点从追求全知问题求解器转变为熟练使用工具的人。为了促进这种设置的研究，我们构建了一个名为MathFunc的工具增强型训练语料库，涵盖了超过30,000个样本和大约6,000个工具。基于MathFunc，我们开发了SciAgent，用于检索、理解，以及必要时使用工具进行科学问题解决。此外，我们构建了一个名为SciToolBench的基准，涵盖五个科学领域，以评估LLMs在工具辅助下的能力。对SciToolBench进行的大量实验验证了SciAgent的有效性。值得注意的是，SciAgent-Mistral-7B超过了其他LLMs。",
    "tldr": "引入了工具增强型科学推理的新任务设置，通过提供可扩展的工具集，帮助大型语言模型在科学问题解决中变得更加实用和可解决。",
    "en_tdlr": "Introduced a new task setting of tool-augmented scientific reasoning, which enhances the practicality and solvability of Large Language Models (LLMs) in scientific problem solving by providing scalable toolsets."
}