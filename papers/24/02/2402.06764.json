{
    "title": "GLaM: Fine-Tuning Large Language Models for Domain Knowledge Graph Alignment via Neighborhood Partitioning and Generative Subgraph Encoding",
    "abstract": "Integrating large language models (LLMs) with knowledge graphs derived from domain-specific data represents an important advancement towards more powerful and factual reasoning. As these models grow more capable, it is crucial to enable them to perform multi-step inferences over real-world knowledge graphs while minimizing hallucination. While large language models excel at conversation and text generation, their ability to reason over domain-specialized graphs of interconnected entities remains limited. For example, can we query a LLM to identify the optimal contact in a professional network for a specific goal, based on relationships and attributes in a private database? The answer is no--such capabilities lie beyond current methods. However, this question underscores a critical technical gap that must be addressed. Many high-value applications in areas such as science, security, and e-commerce rely on proprietary knowledge graphs encoding unique structures, relationships, and logica",
    "link": "https://arxiv.org/abs/2402.06764",
    "context": "Title: GLaM: Fine-Tuning Large Language Models for Domain Knowledge Graph Alignment via Neighborhood Partitioning and Generative Subgraph Encoding\nAbstract: Integrating large language models (LLMs) with knowledge graphs derived from domain-specific data represents an important advancement towards more powerful and factual reasoning. As these models grow more capable, it is crucial to enable them to perform multi-step inferences over real-world knowledge graphs while minimizing hallucination. While large language models excel at conversation and text generation, their ability to reason over domain-specialized graphs of interconnected entities remains limited. For example, can we query a LLM to identify the optimal contact in a professional network for a specific goal, based on relationships and attributes in a private database? The answer is no--such capabilities lie beyond current methods. However, this question underscores a critical technical gap that must be addressed. Many high-value applications in areas such as science, security, and e-commerce rely on proprietary knowledge graphs encoding unique structures, relationships, and logica",
    "path": "papers/24/02/2402.06764.json",
    "total_tokens": 723,
    "translated_title": "通过邻域划分和生成子图编码对领域知识图对齐进行大型语言模型微调的GLaM研究",
    "translated_abstract": "将大型语言模型（LLMs）与从特定领域数据派生的知识图集成，代表了朝着更强大和事实推理的重要进展。随着这些模型变得越来越强大，使它们能够在现实世界的知识图上进行多步推理，并尽量减少虚构是至关重要的。然而，大型语言模型在处理互连实体的领域专用图时，能力仍然有限。因此，有必要填补这一技术上的重要差距。",
    "tldr": "该论文提出了GLaM方法，通过邻域划分和生成子图编码，对领域知识图进行大型语言模型的微调。该方法的创新之处在于能够实现对实际应用中的多步推理，并减少虚构。"
}