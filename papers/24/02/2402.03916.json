{
    "title": "Can Large Language Models Detect Rumors on Social Media?",
    "abstract": "In this work, we investigate to use Large Language Models (LLMs) for rumor detection on social media. However, it is challenging for LLMs to reason over the entire propagation information on social media, which contains news contents and numerous comments, due to LLMs may not concentrate on key clues in the complex propagation information, and have trouble in reasoning when facing massive and redundant information. Accordingly, we propose an LLM-empowered Rumor Detection (LeRuD) approach, in which we design prompts to teach LLMs to reason over important clues in news and comments, and divide the entire propagation information into a Chain-of-Propagation for reducing LLMs' burden. We conduct extensive experiments on the Twitter and Weibo datasets, and LeRuD outperforms several state-of-the-art rumor detection models by 2.4% to 7.6%. Meanwhile, by applying LLMs, LeRuD requires no data for training, and thus shows more promising rumor detection ability in few-shot or zero-shot scenarios.",
    "link": "https://arxiv.org/abs/2402.03916",
    "context": "Title: Can Large Language Models Detect Rumors on Social Media?\nAbstract: In this work, we investigate to use Large Language Models (LLMs) for rumor detection on social media. However, it is challenging for LLMs to reason over the entire propagation information on social media, which contains news contents and numerous comments, due to LLMs may not concentrate on key clues in the complex propagation information, and have trouble in reasoning when facing massive and redundant information. Accordingly, we propose an LLM-empowered Rumor Detection (LeRuD) approach, in which we design prompts to teach LLMs to reason over important clues in news and comments, and divide the entire propagation information into a Chain-of-Propagation for reducing LLMs' burden. We conduct extensive experiments on the Twitter and Weibo datasets, and LeRuD outperforms several state-of-the-art rumor detection models by 2.4% to 7.6%. Meanwhile, by applying LLMs, LeRuD requires no data for training, and thus shows more promising rumor detection ability in few-shot or zero-shot scenarios.",
    "path": "papers/24/02/2402.03916.json",
    "total_tokens": 1000,
    "translated_title": "大型语言模型能否检测社交媒体上的谣言？",
    "translated_abstract": "在这项工作中，我们研究了使用大型语言模型（LLMs）在社交媒体上进行谣言检测。然而，LLMs在推理整个传播信息时面临挑战，因为该信息包含新闻内容和大量评论，LLMs可能无法集中关注复杂传播信息中的关键线索，并且在面对大量和冗余信息时难以进行推理。因此，我们提出了一种基于LLMs增强的谣言检测（LeRuD）方法，在其中设计提示来教导LLMs关注新闻和评论中的重要线索，并将整个传播信息分解为传播链以减轻LLMs的负担。我们在Twitter和微博数据集上进行了大量实验证明，LeRuD的性能优于几种最先进的谣言检测模型，提升了2.4％至7.6％。同时，通过应用LLMs，LeRuD无需进行训练数据，并且在少样本或零样本情况下展现出更具有潜力的谣言检测能力。",
    "tldr": "本研究探讨了使用大型语言模型（LLMs）检测社交媒体上的谣言的可行性。通过设计提示来教导LLMs理解新闻和评论中的关键线索，并将传播信息分解为传播链，我们的LeRuD方法相对于其他最先进的模型在谣言检测方面取得了更好的性能，同时具备在少样本或零样本情况下更有潜力的应用。"
}