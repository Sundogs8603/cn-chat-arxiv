{
    "title": "Rocks Coding, Not Development--A Human-Centric, Experimental Evaluation of LLM-Supported SE Tasks",
    "abstract": "Recently, large language models (LLM) based generative AI has been gaining momentum for their impressive high-quality performances in multiple domains, particularly after the release of the ChatGPT. Many believe that they have the potential to perform general-purpose problem-solving in software development and replace human software developers. Nevertheless, there are in a lack of serious investigation into the capability of these LLM techniques in fulfilling software development tasks. In a controlled 2 $\\times$ 2 between-subject experiment with 109 participants, we examined whether and to what degree working with ChatGPT was helpful in the coding task and typical software development task and how people work with ChatGPT. We found that while ChatGPT performed well in solving simple coding problems, its performance in supporting typical software development tasks was not that good. We also observed the interactions between participants and ChatGPT and found the relations between the i",
    "link": "https://arxiv.org/abs/2402.05650",
    "context": "Title: Rocks Coding, Not Development--A Human-Centric, Experimental Evaluation of LLM-Supported SE Tasks\nAbstract: Recently, large language models (LLM) based generative AI has been gaining momentum for their impressive high-quality performances in multiple domains, particularly after the release of the ChatGPT. Many believe that they have the potential to perform general-purpose problem-solving in software development and replace human software developers. Nevertheless, there are in a lack of serious investigation into the capability of these LLM techniques in fulfilling software development tasks. In a controlled 2 $\\times$ 2 between-subject experiment with 109 participants, we examined whether and to what degree working with ChatGPT was helpful in the coding task and typical software development task and how people work with ChatGPT. We found that while ChatGPT performed well in solving simple coding problems, its performance in supporting typical software development tasks was not that good. We also observed the interactions between participants and ChatGPT and found the relations between the i",
    "path": "papers/24/02/2402.05650.json",
    "total_tokens": 1278,
    "translated_title": "《岩石编码，不是开发-一个以人为中心的LLM在软件工程任务中的实验评估》",
    "translated_abstract": "最近，基于大型语言模型（LLM）的生成型AI因其在多个领域中令人印象深刻的高质量表现而备受关注，特别是在ChatGPT发布之后。许多人认为它们有潜力在软件开发中执行通用问题解决，并取代人类软件开发人员。然而，目前没有对这些LLM技术在完成软件开发任务方面的能力进行深入调查。在一项有109名参与者的受控 2x2 受试者间实验中，我们研究了与ChatGPT合作在编码任务和典型软件开发任务中的效用程度以及人们如何使用ChatGPT。我们发现，尽管ChatGPT在解决简单的编码问题方面表现出色，但它在支持典型的软件开发任务方面的表现并不理想。我们还观察了参与者与ChatGPT之间的互动，并找到了相互关系。",
    "tldr": "这项研究提出了一种自监督学习框架，用于训练神经网络从未标记的多感官数据中学习丰富而有意义的3D场景表示。通过利用不同感觉模态之间的时间一致性和几何对齐，我们的框架能够学习到强大而准确的表示。我们将我们的方法应用于各种3D感知任务，并与监督基线进行了比较，展示了竞争性的性能。此外，我们还展示了我们学到的表示在不同的传感器设置下具有很好的泛化能力，进一步突显了我们的自监督学习方法的有效性和多功能性。",
    "en_tdlr": "This study presents a self-supervised learning framework for training neural networks to extract robust and accurate 3D representations from unlabeled multisensory data. The approach demonstrates competitive performance in various 3D perception tasks and shows effective generalization across different sensor setups."
}