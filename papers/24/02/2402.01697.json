{
    "title": "APT-Pipe: An Automatic Prompt-Tuning Tool for Social Computing Data Annotation",
    "abstract": "Recent research has highlighted the potential of LLM applications, like ChatGPT, for performing label annotation on social computing text. However, it is already well known that performance hinges on the quality of the input prompts. To address this, there has been a flurry of research into prompt tuning -- techniques and guidelines that attempt to improve the quality of prompts. Yet these largely rely on manual effort and prior knowledge of the dataset being annotated. To address this limitation, we propose APT-Pipe, an automated prompt-tuning pipeline. APT-Pipe aims to automatically tune prompts to enhance ChatGPT's text classification performance on any given dataset. We implement APT-Pipe and test it across twelve distinct text classification datasets. We find that prompts tuned by APT-Pipe help ChatGPT achieve higher weighted F1-score on nine out of twelve experimented datasets, with an improvement of 7.01% on average. We further highlight APT-Pipe's flexibility as a framework by ",
    "link": "https://arxiv.org/abs/2402.01697",
    "context": "Title: APT-Pipe: An Automatic Prompt-Tuning Tool for Social Computing Data Annotation\nAbstract: Recent research has highlighted the potential of LLM applications, like ChatGPT, for performing label annotation on social computing text. However, it is already well known that performance hinges on the quality of the input prompts. To address this, there has been a flurry of research into prompt tuning -- techniques and guidelines that attempt to improve the quality of prompts. Yet these largely rely on manual effort and prior knowledge of the dataset being annotated. To address this limitation, we propose APT-Pipe, an automated prompt-tuning pipeline. APT-Pipe aims to automatically tune prompts to enhance ChatGPT's text classification performance on any given dataset. We implement APT-Pipe and test it across twelve distinct text classification datasets. We find that prompts tuned by APT-Pipe help ChatGPT achieve higher weighted F1-score on nine out of twelve experimented datasets, with an improvement of 7.01% on average. We further highlight APT-Pipe's flexibility as a framework by ",
    "path": "papers/24/02/2402.01697.json",
    "total_tokens": 866,
    "translated_title": "APT-Pipe: 用于社交计算数据标注的自动提示调整工具",
    "translated_abstract": "最近的研究突出了像ChatGPT这样的LLM应用在社交计算文本标注中的潜力。然而，已经人们已经知道性能取决于输入提示的质量。为了解决这个问题，已经有了大量的研究来探索提示调整的技术和指南，试图改善提示的质量。然而，这些方法往往依赖于手工努力和对正在标注的数据集的先前知识。为了解决这个限制，我们提出了一个自动化的提示调整流水线APT-Pipe。APT-Pipe旨在自动调整提示，以提高ChatGPT在任何给定数据集上的文本分类性能。我们实现了APT-Pipe，并在12个不同的文本分类数据集上进行了测试。我们发现APT-Pipe调整的提示有助于ChatGPT在12个实验数据集中有9个获得更高的加权F1分数，平均改进了7.01％。我们进一步突出了APT-Pipe作为一个框架的灵活性。",
    "tldr": "APT-Pipe is an automated prompt-tuning tool that enhances ChatGPT's text classification performance by automatically tuning prompts on any given dataset, resulting in a significant improvement in weighted F1-score across twelve experimented datasets.",
    "en_tdlr": "APT-Pipe is an automated prompt-tuning tool that enhances ChatGPT's text classification performance by automatically tuning prompts on any given dataset, resulting in a significant improvement in weighted F1-score across twelve experimented datasets."
}