{
    "title": "Can Language Models Act as Knowledge Bases at Scale?",
    "abstract": "arXiv:2402.14273v1 Announce Type: new  Abstract: Large language models (LLMs) have demonstrated remarkable proficiency in understanding and generating responses to complex queries through large-scale pre-training. However, the efficacy of these models in memorizing and reasoning among large-scale structured knowledge, especially world knowledge that explicitly covers abundant factual information remains questionable. Addressing this gap, our research investigates whether LLMs can effectively store, recall, and reason with knowledge on a large scale comparable to latest knowledge bases (KBs) such as Wikidata. Specifically, we focus on three crucial aspects to study the viability: (1) the efficiency of LLMs with different sizes in memorizing the exact knowledge in the large-scale KB; (2) the flexibility of recalling the memorized knowledge in response to natural language queries; (3) the capability to infer new knowledge through reasoning. Our findings indicate that while LLMs hold promi",
    "link": "https://arxiv.org/abs/2402.14273",
    "context": "Title: Can Language Models Act as Knowledge Bases at Scale?\nAbstract: arXiv:2402.14273v1 Announce Type: new  Abstract: Large language models (LLMs) have demonstrated remarkable proficiency in understanding and generating responses to complex queries through large-scale pre-training. However, the efficacy of these models in memorizing and reasoning among large-scale structured knowledge, especially world knowledge that explicitly covers abundant factual information remains questionable. Addressing this gap, our research investigates whether LLMs can effectively store, recall, and reason with knowledge on a large scale comparable to latest knowledge bases (KBs) such as Wikidata. Specifically, we focus on three crucial aspects to study the viability: (1) the efficiency of LLMs with different sizes in memorizing the exact knowledge in the large-scale KB; (2) the flexibility of recalling the memorized knowledge in response to natural language queries; (3) the capability to infer new knowledge through reasoning. Our findings indicate that while LLMs hold promi",
    "path": "papers/24/02/2402.14273.json",
    "total_tokens": 830,
    "translated_title": "语言模型能否作为大规模知识库？",
    "translated_abstract": "大型语言模型(LLMs)已经在通过大规模预训练理解和生成复杂查询的过程中展现出了非凡的熟练程度。然而，这些模型在大规模结构化知识，特别是明确涵盖丰富事实信息的世界知识的记忆和推理能力仍然存在疑问。针对这一空白，我们的研究探讨了LLMs是否能够有效地存储、回忆和推理大规模知识，与最新知识库（KBs）如Wikidata相媲美。具体而言，我们专注于研究可行性的三个关键方面：(1) LLMs在记忆大规模KB中确切知识方面的效率；(2) 在自然语言查询的回应中回忆记忆知识的灵活性；(3) 通过推理推断新知识的能力。我们的研究结果表明，虽然LLMs具有潜力",
    "tldr": "大型语言模型在存储、回忆和推理大规模知识方面的表现被探讨，研究结果表明其具有一定的潜力。",
    "en_tdlr": "The study explores the performance of large language models in storing, recalling, and reasoning with large-scale knowledge, indicating a certain potential in these aspects."
}