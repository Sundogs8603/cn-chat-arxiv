{
    "title": "Analog-digital Scheduling for Federated Learning: A Communication-Efficient Approach",
    "abstract": "Over-the-air (OTA) computation has recently emerged as a communication-efficient Federated Learning (FL) paradigm to train machine learning models over wireless networks. However, its performance is limited by the device with the worst SNR, resulting in fast yet noisy updates. On the other hand, allocating orthogonal resource blocks (RB) to individual devices via digital channels mitigates the noise problem, at the cost of increased communication latency. In this paper, we address this discrepancy and present ADFL, a novel Analog-Digital FL scheme: in each round, the parameter server (PS) schedules each device to either upload its gradient via the analog OTA scheme or transmit its quantized gradient over an orthogonal RB using the ``digital\" scheme. Focusing on a single FL round, we cast the optimal scheduling problem as the minimization of the mean squared error (MSE) on the estimated global gradient at the PS, subject to a delay constraint, yielding the optimal device scheduling conf",
    "link": "https://arxiv.org/abs/2402.00318",
    "context": "Title: Analog-digital Scheduling for Federated Learning: A Communication-Efficient Approach\nAbstract: Over-the-air (OTA) computation has recently emerged as a communication-efficient Federated Learning (FL) paradigm to train machine learning models over wireless networks. However, its performance is limited by the device with the worst SNR, resulting in fast yet noisy updates. On the other hand, allocating orthogonal resource blocks (RB) to individual devices via digital channels mitigates the noise problem, at the cost of increased communication latency. In this paper, we address this discrepancy and present ADFL, a novel Analog-Digital FL scheme: in each round, the parameter server (PS) schedules each device to either upload its gradient via the analog OTA scheme or transmit its quantized gradient over an orthogonal RB using the ``digital\" scheme. Focusing on a single FL round, we cast the optimal scheduling problem as the minimization of the mean squared error (MSE) on the estimated global gradient at the PS, subject to a delay constraint, yielding the optimal device scheduling conf",
    "path": "papers/24/02/2402.00318.json",
    "total_tokens": 934,
    "translated_title": "模拟数字调度对于联邦学习的通信高效方法",
    "translated_abstract": "最近，通过无线网络进行机器学习模型训练的通信高效的联邦学习（FL）范式中出现了一种称为OTA计算的方法。然而，其性能受到信噪比最差的设备的限制，导致更新速度快但噪声较多。另一方面，通过数字通道将正交资源块（RB）分配给每个设备可以减轻噪声问题，但会增加通信延迟。在本文中，我们解决了这个差异，并提出了ADFL，一种新颖的模拟数字FL方案：在每一轮中，参数服务器（PS）将每个设备调度为通过模拟OTA方案上传其梯度，或者使用“数字”方案通过正交RB传输其量化梯度。针对单个FL轮次，我们将最优调度问题转化为最小化PS估计的全局梯度的均方误差（MSE）的问题，并在延迟约束下得到最优设备调度配置。",
    "tldr": "本文提出一种模拟数字FL方案，通过在每一轮中，通过模拟OTA方案上传梯度或者通过正交RB传输量化梯度的方式调度设备，解决了联邦学习中性能受限于信噪比最差设备问题的差异，以实现通信高效和降低噪声。",
    "en_tdlr": "This paper presents an analog-digital federated learning scheme, ADFL, which addresses the performance limitation in wireless networks by scheduling devices to either upload gradients via OTA or transmit quantized gradients over orthogonal resource blocks. This approach achieves communication efficiency and reduces noise by mitigating the impact of devices with poor signal-to-noise ratio."
}