{
    "title": "Interpreting Predictive Probabilities: Model Confidence or Human Label Variation?",
    "abstract": "arXiv:2402.16102v1 Announce Type: new  Abstract: With the rise of increasingly powerful and user-facing NLP systems, there is growing interest in assessing whether they have a good representation of uncertainty by evaluating the quality of their predictive distribution over outcomes. We identify two main perspectives that drive starkly different evaluation protocols. The first treats predictive probability as an indication of model confidence; the second as an indication of human label variation. We discuss their merits and limitations, and take the position that both are crucial for trustworthy and fair NLP systems, but that exploiting a single predictive distribution is limiting. We recommend tools and highlight exciting directions towards models with disentangled representations of uncertainty about predictions and uncertainty about human labels.",
    "link": "https://arxiv.org/abs/2402.16102",
    "context": "Title: Interpreting Predictive Probabilities: Model Confidence or Human Label Variation?\nAbstract: arXiv:2402.16102v1 Announce Type: new  Abstract: With the rise of increasingly powerful and user-facing NLP systems, there is growing interest in assessing whether they have a good representation of uncertainty by evaluating the quality of their predictive distribution over outcomes. We identify two main perspectives that drive starkly different evaluation protocols. The first treats predictive probability as an indication of model confidence; the second as an indication of human label variation. We discuss their merits and limitations, and take the position that both are crucial for trustworthy and fair NLP systems, but that exploiting a single predictive distribution is limiting. We recommend tools and highlight exciting directions towards models with disentangled representations of uncertainty about predictions and uncertainty about human labels.",
    "path": "papers/24/02/2402.16102.json",
    "total_tokens": 805,
    "translated_title": "解释预测概率：模型置信度还是人类标签变化？",
    "translated_abstract": "随着越来越强大且用户友好的自然语言处理系统的崛起，人们越来越关注评估它们是否能够很好地表示不确定性，通过评估其对结果的预测分布质量。我们确定了两种主要观点，它们推动了截然不同的评估协议。第一种将预测概率视为模型置信度的指示；第二种将其视为人类标签变化的指示。我们讨论它们的优点和局限性，并提出认为两者对于值得信赖和公平的自然语言处理系统都至关重要，但仅利用单个预测分布是有限的观点。我们建议工具并突出指向具有关于预测的不确定性和关于人类标签的不确定性脱钩表示模型的激动人心方向。",
    "tldr": "提出了两种主要观点：一种认为预测概率表明模型置信度，另一种认为预测概率表明人类标签变化。作者建议同时考虑这两种观点以提高自然语言处理系统的可靠性和公平性。",
    "en_tdlr": "The paper presents two main perspectives: one views predictive probabilities as indications of model confidence, while the other sees them as indications of human label variation. The authors recommend considering both perspectives to enhance the reliability and fairness of NLP systems."
}