{
    "title": "Control-Theoretic Techniques for Online Adaptation of Deep Neural Networks in Dynamical Systems",
    "abstract": "Deep neural networks (DNNs), trained with gradient-based optimization and backpropagation, are currently the primary tool in modern artificial intelligence, machine learning, and data science. In many applications, DNNs are trained offline, through supervised learning or reinforcement learning, and deployed online for inference. However, training DNNs with standard backpropagation and gradient-based optimization gives no intrinsic performance guarantees or bounds on the DNN, which is essential for applications such as controls. Additionally, many offline-training and online-inference problems, such as sim2real transfer of reinforcement learning policies, experience domain shift from the training distribution to the real-world distribution. To address these stability and transfer learning issues, we propose using techniques from control theory to update DNN parameters online. We formulate the fully-connected feedforward DNN as a continuous-time dynamical system, and we propose novel las",
    "link": "https://arxiv.org/abs/2402.00761",
    "context": "Title: Control-Theoretic Techniques for Online Adaptation of Deep Neural Networks in Dynamical Systems\nAbstract: Deep neural networks (DNNs), trained with gradient-based optimization and backpropagation, are currently the primary tool in modern artificial intelligence, machine learning, and data science. In many applications, DNNs are trained offline, through supervised learning or reinforcement learning, and deployed online for inference. However, training DNNs with standard backpropagation and gradient-based optimization gives no intrinsic performance guarantees or bounds on the DNN, which is essential for applications such as controls. Additionally, many offline-training and online-inference problems, such as sim2real transfer of reinforcement learning policies, experience domain shift from the training distribution to the real-world distribution. To address these stability and transfer learning issues, we propose using techniques from control theory to update DNN parameters online. We formulate the fully-connected feedforward DNN as a continuous-time dynamical system, and we propose novel las",
    "path": "papers/24/02/2402.00761.json",
    "total_tokens": 819,
    "translated_title": "动态系统中在线调整深度神经网络的控制理论技术",
    "translated_abstract": "深度神经网络（DNNs）是现代人工智能、机器学习和数据科学中主要的工具，通过梯度优化和反向传播进行训练。在许多应用中，DNNs通过监督学习或强化学习进行离线训练，并在线部署进行推断。然而，使用标准的反向传播和梯度优化训练DNNs无法提供DNN的固有性能保证或界限，这对于包括控制在内的应用非常重要。此外，许多离线训练和在线推断问题，如强化学习策略的模拟到实际转移，经历了从训练分布到现实世界分布的域偏移。为了解决这些稳定性和转移学习问题，我们提出使用控制理论的技术在线更新DNN参数。我们将全连接前向DNNs形式化为连续时间的动态系统，并提出了新的方法.",
    "tldr": "本论文提出在动态系统中使用控制理论技术在线调整深度神经网络参数，以解决稳定性和转移学习问题。",
    "en_tdlr": "This paper proposes using control-theoretic techniques to adapt deep neural network parameters online in dynamical systems to address stability and transfer learning issues."
}