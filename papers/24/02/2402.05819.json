{
    "title": "Integrating Self-supervised Speech Model with Pseudo Word-level Targets from Visually-grounded Speech Model",
    "abstract": "Recent advances in self-supervised speech models have shown significant improvement in many downstream tasks. However, these models predominantly centered on frame-level training objectives, which can fall short in spoken language understanding tasks that require semantic comprehension. Existing works often rely on additional speech-text data as intermediate targets, which is costly in the real-world setting. To address this challenge, we propose Pseudo-Word HuBERT (PW-HuBERT), a framework that integrates pseudo word-level targets into the training process, where the targets are derived from a visually-ground speech model, notably eliminating the need for speech-text paired data. Our experimental results on four spoken language understanding (SLU) benchmarks suggest the superiority of our model in capturing semantic information.",
    "link": "https://arxiv.org/abs/2402.05819",
    "context": "Title: Integrating Self-supervised Speech Model with Pseudo Word-level Targets from Visually-grounded Speech Model\nAbstract: Recent advances in self-supervised speech models have shown significant improvement in many downstream tasks. However, these models predominantly centered on frame-level training objectives, which can fall short in spoken language understanding tasks that require semantic comprehension. Existing works often rely on additional speech-text data as intermediate targets, which is costly in the real-world setting. To address this challenge, we propose Pseudo-Word HuBERT (PW-HuBERT), a framework that integrates pseudo word-level targets into the training process, where the targets are derived from a visually-ground speech model, notably eliminating the need for speech-text paired data. Our experimental results on four spoken language understanding (SLU) benchmarks suggest the superiority of our model in capturing semantic information.",
    "path": "papers/24/02/2402.05819.json",
    "total_tokens": 785,
    "translated_title": "将自我监督的语音模型与视觉语音模型生成的伪词级目标相结合",
    "translated_abstract": "最近自我监督的语音模型在许多下游任务中取得了显著的改进。然而，这些模型主要集中在帧级训练目标上，在需要语义理解的口语理解任务中可能不足够。现有的工作通常依赖于额外的语音-文本数据作为中间目标，这在实际环境中成本高昂。为了解决这个挑战，我们提出了Pseudo-Word HuBERT（PW-HuBERT）框架，该框架将伪词级目标整合到训练过程中，其中目标是从视觉语音模型中提取的，因此消除了对语音-文本配对数据的需求。我们在四个口语理解基准测试中的实验结果表明了我们模型在捕捉语义信息方面的优越性。",
    "tldr": "本文提出了PW-HuBERT框架，它通过将伪词级目标整合到训练过程中，从视觉语音模型中提取目标，从而在口语理解任务中展现出了优越性能。"
}