{
    "title": "RealDex: Towards Human-like Grasping for Robotic Dexterous Hand",
    "abstract": "arXiv:2402.13853v1 Announce Type: cross  Abstract: In this paper, we introduce RealDex, a pioneering dataset capturing authentic dexterous hand grasping motions infused with human behavioral patterns, enriched by multi-view and multimodal visual data. Utilizing a teleoperation system, we seamlessly synchronize human-robot hand poses in real time. This collection of human-like motions is crucial for training dexterous hands to mimic human movements more naturally and precisely. RealDex holds immense promise in advancing humanoid robot for automated perception, cognition, and manipulation in real-world scenarios. Moreover, we introduce a cutting-edge dexterous grasping motion generation framework, which aligns with human experience and enhances real-world applicability through effectively utilizing Multimodal Large Language Models. Extensive experiments have demonstrated the superior performance of our method on RealDex and other open datasets. The complete dataset and code will be made ",
    "link": "https://arxiv.org/abs/2402.13853",
    "context": "Title: RealDex: Towards Human-like Grasping for Robotic Dexterous Hand\nAbstract: arXiv:2402.13853v1 Announce Type: cross  Abstract: In this paper, we introduce RealDex, a pioneering dataset capturing authentic dexterous hand grasping motions infused with human behavioral patterns, enriched by multi-view and multimodal visual data. Utilizing a teleoperation system, we seamlessly synchronize human-robot hand poses in real time. This collection of human-like motions is crucial for training dexterous hands to mimic human movements more naturally and precisely. RealDex holds immense promise in advancing humanoid robot for automated perception, cognition, and manipulation in real-world scenarios. Moreover, we introduce a cutting-edge dexterous grasping motion generation framework, which aligns with human experience and enhances real-world applicability through effectively utilizing Multimodal Large Language Models. Extensive experiments have demonstrated the superior performance of our method on RealDex and other open datasets. The complete dataset and code will be made ",
    "path": "papers/24/02/2402.13853.json",
    "total_tokens": 940,
    "translated_title": "RealDex: 实现机器人灵巧手类人式抓取",
    "translated_abstract": "在本文中，我们介绍了RealDex，一个开创性的数据集，捕捉了融入了人类行为模式的真实灵巧手抓取动作，同时通过多视角和多模态视觉数据进行了丰富。利用远程操作系统，我们可以实时无缝同步人-机器人手姿势。这些类人动作的集合对于训练灵巧手更自然、更精确地模仿人类动作至关重要。RealDex在推动类人机器人在真实场景中自动感知、认知和操纵方面具有巨大潜力。此外，我们介绍了一种前沿的灵巧抓取动作生成框架，该框架符合人类经验，并通过有效利用多模态大型语言模型增强了在现实世界中的适用性。广泛的实验证明了我们的方法在RealDex和其他开放数据集上的优越性能。完整的数据集和代码将会公开发布。",
    "tldr": "RealDex数据集捕捉了真实的灵巧手抓取动作，利用多模态数据使得训练灵巧手更加自然和精确，同时提出了一种先进的灵巧抓取动作生成框架，有效利用多模态大型语言模型，在类人机器人的自动感知、认知和操纵方面具有巨大潜力。",
    "en_tdlr": "The RealDex dataset captures authentic dexterous hand grasping motions enriched by multi-modal data to train dexterous hands more naturally and precisely, along with introducing an advanced grasping motion generation framework that effectively utilizes multimodal large language models, showing great potential in automated perception, cognition, and manipulation for humanoid robots in real-world scenarios."
}