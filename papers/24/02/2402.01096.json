{
    "title": "Trustworthy Distributed AI Systems: Robustness, Privacy, and Governance",
    "abstract": "Emerging Distributed AI systems are revolutionizing big data computing and data processing capabilities with growing economic and societal impact. However, recent studies have identified new attack surfaces and risks caused by security, privacy, and fairness issues in AI systems. In this paper, we review representative techniques, algorithms, and theoretical foundations for trustworthy distributed AI through robustness guarantee, privacy protection, and fairness awareness in distributed learning. We first provide a brief overview of alternative architectures for distributed learning, discuss inherent vulnerabilities for security, privacy, and fairness of AI algorithms in distributed learning, and analyze why these problems are present in distributed learning regardless of specific architectures. Then we provide a unique taxonomy of countermeasures for trustworthy distributed AI, covering (1) robustness to evasion attacks and irregular queries at inference, and robustness to poisoning a",
    "link": "https://rss.arxiv.org/abs/2402.01096",
    "context": "Title: Trustworthy Distributed AI Systems: Robustness, Privacy, and Governance\nAbstract: Emerging Distributed AI systems are revolutionizing big data computing and data processing capabilities with growing economic and societal impact. However, recent studies have identified new attack surfaces and risks caused by security, privacy, and fairness issues in AI systems. In this paper, we review representative techniques, algorithms, and theoretical foundations for trustworthy distributed AI through robustness guarantee, privacy protection, and fairness awareness in distributed learning. We first provide a brief overview of alternative architectures for distributed learning, discuss inherent vulnerabilities for security, privacy, and fairness of AI algorithms in distributed learning, and analyze why these problems are present in distributed learning regardless of specific architectures. Then we provide a unique taxonomy of countermeasures for trustworthy distributed AI, covering (1) robustness to evasion attacks and irregular queries at inference, and robustness to poisoning a",
    "path": "papers/24/02/2402.01096.json",
    "total_tokens": 858,
    "translated_title": "可信的分布式AI系统：鲁棒性、隐私和治理",
    "translated_abstract": "新兴的分布式AI系统正在革新大数据计算和数据处理能力，并对经济和社会产生越来越大的影响。然而，最近的研究发现，AI系统中的安全、隐私和公平问题导致了新的攻击面和风险。在本文中，我们通过鲁棒性保证、隐私保护和公平意识在分布式学习中回顾了代表性的技术、算法和理论基础，以实现可信的分布式AI。我们首先提供了分布式学习的替代架构的简要概述，讨论了分布式学习中AI算法的安全、隐私和公平的固有漏洞，并分析了为什么这些问题在分布式学习中存在，而不管具体的架构如何。然后，我们提供了针对可信分布式AI的独特分类，涵盖了对推理中的逃避攻击和不规则查询的鲁棒性，以及对中毒攻击和数据泄露的隐私保护。",
    "tldr": "本文回顾了可信的分布式AI的代表性技术，包括鲁棒性保证、隐私保护和公平意识，以解决分布式学习中存在的安全、隐私和公平问题。",
    "en_tdlr": "This paper reviews representative techniques for trustworthy distributed AI, including robustness guarantee, privacy protection, and fairness awareness, to address the security, privacy, and fairness issues in distributed learning."
}