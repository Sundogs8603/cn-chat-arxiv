{
    "title": "Uncertainty Quantification of Graph Convolution Neural Network Models of Evolving Processes",
    "abstract": "arXiv:2402.11179v1 Announce Type: new  Abstract: The application of neural network models to scientific machine learning tasks has proliferated in recent years. In particular, neural network models have proved to be adept at modeling processes with spatial-temporal complexity. Nevertheless, these highly parameterized models have garnered skepticism in their ability to produce outputs with quantified error bounds over the regimes of interest. Hence there is a need to find uncertainty quantification methods that are suitable for neural networks. In this work we present comparisons of the parametric uncertainty quantification of neural networks modeling complex spatial-temporal processes with Hamiltonian Monte Carlo and Stein variational gradient descent and its projected variant. Specifically we apply these methods to graph convolutional neural network models of evolving systems modeled with recurrent neural network and neural ordinary differential equations architectures. We show that S",
    "link": "https://arxiv.org/abs/2402.11179",
    "context": "Title: Uncertainty Quantification of Graph Convolution Neural Network Models of Evolving Processes\nAbstract: arXiv:2402.11179v1 Announce Type: new  Abstract: The application of neural network models to scientific machine learning tasks has proliferated in recent years. In particular, neural network models have proved to be adept at modeling processes with spatial-temporal complexity. Nevertheless, these highly parameterized models have garnered skepticism in their ability to produce outputs with quantified error bounds over the regimes of interest. Hence there is a need to find uncertainty quantification methods that are suitable for neural networks. In this work we present comparisons of the parametric uncertainty quantification of neural networks modeling complex spatial-temporal processes with Hamiltonian Monte Carlo and Stein variational gradient descent and its projected variant. Specifically we apply these methods to graph convolutional neural network models of evolving systems modeled with recurrent neural network and neural ordinary differential equations architectures. We show that S",
    "path": "papers/24/02/2402.11179.json",
    "total_tokens": 846,
    "translated_title": "演化过程的图卷积神经网络模型的不确定性量化",
    "translated_abstract": "近年来，神经网络模型在科学机器学习任务中的应用不断增加。特别是，神经网络模型已被证明在建模具有时空复杂性的过程方面非常擅长。然而，这些高度参数化的模型在能够在感兴趣的区域内产生具有量化误差界限的输出方面引起了怀疑。因此，有必要找到适用于神经网络的不确定性量化方法。在这项工作中，我们对使用哈密顿蒙特卡洛和斯坦变分梯度下降以及其投影变体对建模复杂时空过程的神经网络进行参数不确定性量化的比较进行了展示。具体来说，我们将这些方法应用于使用递归神经网络和神经常微分方程架构建模的演化系统的图卷积神经网络模型。我们展示了S",
    "tldr": "本研究比较了使用哈密顿蒙特卡洛和斯坦变分梯度下降等方法，对建模复杂时空过程的神经网络进行参数不确定性量化，特别是应用于图卷积神经网络模型的演化过程，展示了..."
}