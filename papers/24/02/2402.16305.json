{
    "title": "Referee Can Play: An Alternative Approach to Conditional Generation via Model Inversion",
    "abstract": "arXiv:2402.16305v1 Announce Type: cross  Abstract: As a dominant force in text-to-image generation tasks, Diffusion Probabilistic Models (DPMs) face a critical challenge in controllability, struggling to adhere strictly to complex, multi-faceted instructions. In this work, we aim to address this alignment challenge for conditional generation tasks. First, we provide an alternative view of state-of-the-art DPMs as a way of inverting advanced Vision-Language Models (VLMs). With this formulation, we naturally propose a training-free approach that bypasses the conventional sampling process associated with DPMs. By directly optimizing images with the supervision of discriminative VLMs, the proposed method can potentially achieve a better text-image alignment. As proof of concept, we demonstrate the pipeline with the pre-trained BLIP-2 model and identify several key designs for improved image generation. To further enhance the image fidelity, a Score Distillation Sampling module of Stable Di",
    "link": "https://arxiv.org/abs/2402.16305",
    "context": "Title: Referee Can Play: An Alternative Approach to Conditional Generation via Model Inversion\nAbstract: arXiv:2402.16305v1 Announce Type: cross  Abstract: As a dominant force in text-to-image generation tasks, Diffusion Probabilistic Models (DPMs) face a critical challenge in controllability, struggling to adhere strictly to complex, multi-faceted instructions. In this work, we aim to address this alignment challenge for conditional generation tasks. First, we provide an alternative view of state-of-the-art DPMs as a way of inverting advanced Vision-Language Models (VLMs). With this formulation, we naturally propose a training-free approach that bypasses the conventional sampling process associated with DPMs. By directly optimizing images with the supervision of discriminative VLMs, the proposed method can potentially achieve a better text-image alignment. As proof of concept, we demonstrate the pipeline with the pre-trained BLIP-2 model and identify several key designs for improved image generation. To further enhance the image fidelity, a Score Distillation Sampling module of Stable Di",
    "path": "papers/24/02/2402.16305.json",
    "total_tokens": 903,
    "translated_title": "审稿员也可以参与：通过模型反演进行条件生成的替代方法",
    "translated_abstract": "作为文本到图像生成任务中占据主导地位的扩散概率模型（DPMs）面临着一个关键性挑战，即可控性方面的问题，难以严格遵守复杂、多方面的指令。在这项工作中，我们旨在解决条件生成任务中的这一协调挑战。首先，我们提供了一个替代观点，将现有最先进的DPMs视为反转先进视觉-语言模型（VLMs）的一种方式。通过这种表述，我们自然地提出了一种无需训练的方法，绕过与DPMs相关的传统采样过程。通过直接优化图像，并在有辨别力的VLMs的监督下，所提出的方法有潜力实现更好的文本图像对齐。作为概念的证明，我们演示了预训练的BLIP-2模型的流程，并确定了几个用于改进图像生成的关键设计。为进一步增强图像的保真度，我们提出了一个稳定的得分蒸馏采样模块。",
    "tldr": "通过模型反演提出了一种训练自由的方法，可以绕过传统的采样过程，直接优化图像并获得更好的文本图像对齐，为改进图像生成提供了关键设计。",
    "en_tdlr": "An alternative training-free method is proposed via model inversion to optimize images directly and achieve better text-image alignment, providing key designs for improved image generation."
}