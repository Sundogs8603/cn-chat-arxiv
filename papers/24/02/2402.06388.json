{
    "title": "On the Convergence Rate of the Stochastic Gradient Descent (SGD) and application to a modified policy gradient for the Multi Armed Bandit",
    "abstract": "We present a self-contained proof of the convergence rate of the Stochastic Gradient Descent (SGD) when the learning rate follows an inverse time decays schedule; we next apply the results to the convergence of a modified form of policy gradient Multi-Armed Bandit (MAB) with $L2$ regularization.",
    "link": "https://arxiv.org/abs/2402.06388",
    "context": "Title: On the Convergence Rate of the Stochastic Gradient Descent (SGD) and application to a modified policy gradient for the Multi Armed Bandit\nAbstract: We present a self-contained proof of the convergence rate of the Stochastic Gradient Descent (SGD) when the learning rate follows an inverse time decays schedule; we next apply the results to the convergence of a modified form of policy gradient Multi-Armed Bandit (MAB) with $L2$ regularization.",
    "path": "papers/24/02/2402.06388.json",
    "total_tokens": 628,
    "translated_title": "关于随机梯度下降（SGD）的收敛速度及其在修改的多臂赌博机上的策略梯度应用",
    "translated_abstract": "我们提出了一个自包含的证明，证明了当学习速率遵循逆时间衰减规则时，随机梯度下降（SGD）的收敛速度；接下来，我们将这些结果应用于带有L2正则化的修改的策略梯度多臂赌博机（MAB）的收敛性分析。",
    "tldr": "该论文证明了当学习速率按照逆时间衰减规则时，随机梯度下降（SGD）的收敛速度，并应用于修改的带有L2正则化的策略梯度多臂赌博机（MAB）的收敛性分析。",
    "en_tdlr": "This paper proves the convergence rate of Stochastic Gradient Descent (SGD) when the learning rate follows an inverse time decays schedule and applies it to the convergence analysis of a modified policy gradient Multi-Armed Bandit (MAB) with L2 regularization."
}