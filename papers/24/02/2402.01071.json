{
    "title": "Chameleon: Foundation Models for Fairness-aware Multi-modal Data Augmentation to Enhance Coverage of Minorities",
    "abstract": "The potential harms of the under-representation of minorities in training data, particularly in multi-modal settings, is a well-recognized concern. While there has been extensive effort in detecting such under-representation, resolution has remained a challenge. With recent advancements in generative AI, large language models and foundation models have emerged as versatile tools across various domains. In this paper, we propose Chameleon, a system that efficiently utilizes these tools to augment a data set with a minimal addition of synthetically generated tuples, in order to enhance the coverage of the under-represented groups. Our system follows a rejection sampling approach to ensure the generated tuples have a high quality and follow the underlying distribution. In order to minimize the rejection chance of the generated tuples, we propose multiple strategies for providing a guide for the foundation model. Our experiment results, in addition to confirming the efficiency of our propo",
    "link": "https://rss.arxiv.org/abs/2402.01071",
    "context": "Title: Chameleon: Foundation Models for Fairness-aware Multi-modal Data Augmentation to Enhance Coverage of Minorities\nAbstract: The potential harms of the under-representation of minorities in training data, particularly in multi-modal settings, is a well-recognized concern. While there has been extensive effort in detecting such under-representation, resolution has remained a challenge. With recent advancements in generative AI, large language models and foundation models have emerged as versatile tools across various domains. In this paper, we propose Chameleon, a system that efficiently utilizes these tools to augment a data set with a minimal addition of synthetically generated tuples, in order to enhance the coverage of the under-represented groups. Our system follows a rejection sampling approach to ensure the generated tuples have a high quality and follow the underlying distribution. In order to minimize the rejection chance of the generated tuples, we propose multiple strategies for providing a guide for the foundation model. Our experiment results, in addition to confirming the efficiency of our propo",
    "path": "papers/24/02/2402.01071.json",
    "total_tokens": 951,
    "translated_title": "变色龙：用于增强少数群体覆盖的公平感知多模态数据增强的基础模型",
    "translated_abstract": "少数群体在训练数据中的欠表示可能带来潜在的危害，尤其是在多模态情况下。尽管在检测这种欠表示方面已经进行了广泛的努力，但解决方案仍然具有挑战性。随着生成式人工智能和大型语言模型的最新进展，基础模型已经在各个领域中成为多功能工具。在本文中，我们提出了变色龙（Chameleon），这是一个系统，通过最少的合成生成的元组来增强数据集，以增强少数群体的覆盖范围。我们的系统采用了拒绝抽样的方法，以确保生成的元组具有高质量并遵循基础分布。为了最小化生成元组的拒绝几率，我们提出了多种策略来为基础模型提供指导。我们的实验结果不仅证实了我们提出的方法的效果，同时也表明了其高效性。",
    "tldr": "本文提出了名为变色龙的系统，利用生成式人工智能和大型语言模型增强少数群体在多模态数据中的覆盖范围。系统通过最少添加合成生成的元组的方式来实现数据增强，并采用拒绝抽样方法确保生成元组的高质量和分布一致。实验证明了该方法的高效性。",
    "en_tdlr": "This paper proposes a system called Chameleon that utilizes generative AI and large language models to enhance the coverage of minorities in multi-modal data. By augmenting the data set with synthetically generated tuples through a rejection sampling approach, the system ensures high-quality tuples that follow the underlying distribution. Experimental results demonstrate the efficiency of the proposed method."
}