{
    "title": "Rec-GPT4V: Multimodal Recommendation with Large Vision-Language Models",
    "abstract": "The development of large vision-language models (LVLMs) offers the potential to address challenges faced by traditional multimodal recommendations thanks to their proficient understanding of static images and textual dynamics. However, the application of LVLMs in this field is still limited due to the following complexities: First, LVLMs lack user preference knowledge as they are trained from vast general datasets. Second, LVLMs suffer setbacks in addressing multiple image dynamics in scenarios involving discrete, noisy, and redundant image sequences. To overcome these issues, we propose the novel reasoning scheme named Rec-GPT4V: Visual-Summary Thought (VST) of leveraging large vision-language models for multimodal recommendation. We utilize user history as in-context user preferences to address the first challenge. Next, we prompt LVLMs to generate item image summaries and utilize image comprehension in natural language space combined with item titles to query the user preferences ov",
    "link": "https://arxiv.org/abs/2402.08670",
    "context": "Title: Rec-GPT4V: Multimodal Recommendation with Large Vision-Language Models\nAbstract: The development of large vision-language models (LVLMs) offers the potential to address challenges faced by traditional multimodal recommendations thanks to their proficient understanding of static images and textual dynamics. However, the application of LVLMs in this field is still limited due to the following complexities: First, LVLMs lack user preference knowledge as they are trained from vast general datasets. Second, LVLMs suffer setbacks in addressing multiple image dynamics in scenarios involving discrete, noisy, and redundant image sequences. To overcome these issues, we propose the novel reasoning scheme named Rec-GPT4V: Visual-Summary Thought (VST) of leveraging large vision-language models for multimodal recommendation. We utilize user history as in-context user preferences to address the first challenge. Next, we prompt LVLMs to generate item image summaries and utilize image comprehension in natural language space combined with item titles to query the user preferences ov",
    "path": "papers/24/02/2402.08670.json",
    "total_tokens": 891,
    "translated_title": "Rec-GPT4V: 基于大规模视觉语言模型的多模态推荐",
    "translated_abstract": "大规模视觉语言模型（LVLM）的发展为传统多模态推荐的挑战提供了解决方案，因为它们能够熟练理解静态图像和文本动态。然而，LVLM在该领域的应用仍然受到以下复杂性的限制：首先，由于LVLM是从大量通用数据集中训练得到的，因此缺乏用户偏好知识。其次，在涉及离散、嘈杂和冗余图像序列的情景中，LVLM在处理多个图像动态方面存在困难。为了克服这些问题，我们提出了一种名为Rec-GPT4V的新颖推理方案：利用大规模视觉语言模型进行多模态推荐的视觉摘要思维（VST）。我们利用用户历史作为上下文中的用户偏好来解决第一个挑战。接下来，我们促使LVLM生成项目图像摘要，并利用自然语言空间中的图像理解和项目标题来查询用户偏好。",
    "tldr": "Rec-GPT4V是一种基于大规模视觉语言模型的多模态推荐算法，通过利用用户历史作为用户偏好信息并结合图像摘要和项目标题，实现了对多个图像动态的推荐。",
    "en_tdlr": "Rec-GPT4V is a multimodal recommendation algorithm based on large vision-language models. It addresses the challenges of user preference knowledge and multiple image dynamics by leveraging user history, generating item image summaries, and utilizing image comprehension and item titles."
}