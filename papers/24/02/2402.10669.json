{
    "title": "Humans or LLMs as the Judge? A Study on Judgement Biases",
    "abstract": "arXiv:2402.10669v1 Announce Type: new  Abstract: Adopting human and large language models (LLM) as judges (\\textit{a.k.a} human- and LLM-as-a-judge) for evaluating the performance of existing LLMs has recently gained attention. Nonetheless, this approach concurrently introduces potential biases from human and LLM judges, questioning the reliability of the evaluation results. In this paper, we propose a novel framework for investigating 5 types of biases for LLM and human judges. We curate a dataset with 142 samples referring to the revised Bloom's Taxonomy and conduct thousands of human and LLM evaluations. Results show that human and LLM judges are vulnerable to perturbations to various degrees, and that even the most cutting-edge judges possess considerable biases. We further exploit their weakness and conduct attacks on LLM judges. We hope that our work can notify the community of the vulnerability of human- and LLM-as-a-judge against perturbations, as well as the urgency of develop",
    "link": "https://arxiv.org/abs/2402.10669",
    "context": "Title: Humans or LLMs as the Judge? A Study on Judgement Biases\nAbstract: arXiv:2402.10669v1 Announce Type: new  Abstract: Adopting human and large language models (LLM) as judges (\\textit{a.k.a} human- and LLM-as-a-judge) for evaluating the performance of existing LLMs has recently gained attention. Nonetheless, this approach concurrently introduces potential biases from human and LLM judges, questioning the reliability of the evaluation results. In this paper, we propose a novel framework for investigating 5 types of biases for LLM and human judges. We curate a dataset with 142 samples referring to the revised Bloom's Taxonomy and conduct thousands of human and LLM evaluations. Results show that human and LLM judges are vulnerable to perturbations to various degrees, and that even the most cutting-edge judges possess considerable biases. We further exploit their weakness and conduct attacks on LLM judges. We hope that our work can notify the community of the vulnerability of human- and LLM-as-a-judge against perturbations, as well as the urgency of develop",
    "path": "papers/24/02/2402.10669.json",
    "total_tokens": 936,
    "translated_title": "人类还是大型语言模型作为裁判？一项关于判决偏见的研究",
    "translated_abstract": "采用人类和大型语言模型（LLM）作为裁判（即人类和LLM作为裁判）来评估现有LLM性能的做法近来备受关注。然而，这种方法同时可能引入人类和LLM裁判的潜在偏见，质疑评估结果的可靠性。本文提出了一种新颖的框架，用于研究LLM和人类裁判的5种偏见。我们整理了一个包含142个样本的数据集，涉及修订的布卢姆分类法，并进行了成千上万次的人类和LLM评估。结果表明，人类和LLM裁判在不同程度上都容易受到干扰，即使最尖端的裁判也存在相当大的偏见。我们进一步利用他们的弱点对LLM裁判进行攻击。希望我们的工作能提醒社群关于人类和LLM作为裁判在面对干扰时的脆弱性，以及发展的紧迫性。",
    "tldr": "提出了一种新框架来研究LLM和人类裁判的偏见，揭示人类和LLM裁判在面对干扰时的脆弱性，强调评估现有LLM性能的挑战。",
    "en_tdlr": "A novel framework was proposed to study biases of LLM and human judges, revealing the vulnerability of human and LLM judges to perturbations and emphasizing the challenges in evaluating the performance of existing LLMs."
}