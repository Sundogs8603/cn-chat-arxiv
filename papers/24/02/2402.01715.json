{
    "title": "ChatGPT vs Gemini vs LLaMA on Multilingual Sentiment Analysis",
    "abstract": "Automated sentiment analysis using Large Language Model (LLM)-based models like ChatGPT, Gemini or LLaMA2 is becoming widespread, both in academic research and in industrial applications. However, assessment and validation of their performance in case of ambiguous or ironic text is still poor. In this study, we constructed nuanced and ambiguous scenarios, we translated them in 10 languages, and we predicted their associated sentiment using popular LLMs. The results are validated against post-hoc human responses. Ambiguous scenarios are often well-coped by ChatGPT and Gemini, but we recognise significant biases and inconsistent performance across models and evaluated human languages. This work provides a standardised methodology for automated sentiment analysis evaluation and makes a call for action to further improve the algorithms and their underlying data, to improve their performance, interpretability and applicability.",
    "link": "https://arxiv.org/abs/2402.01715",
    "context": "Title: ChatGPT vs Gemini vs LLaMA on Multilingual Sentiment Analysis\nAbstract: Automated sentiment analysis using Large Language Model (LLM)-based models like ChatGPT, Gemini or LLaMA2 is becoming widespread, both in academic research and in industrial applications. However, assessment and validation of their performance in case of ambiguous or ironic text is still poor. In this study, we constructed nuanced and ambiguous scenarios, we translated them in 10 languages, and we predicted their associated sentiment using popular LLMs. The results are validated against post-hoc human responses. Ambiguous scenarios are often well-coped by ChatGPT and Gemini, but we recognise significant biases and inconsistent performance across models and evaluated human languages. This work provides a standardised methodology for automated sentiment analysis evaluation and makes a call for action to further improve the algorithms and their underlying data, to improve their performance, interpretability and applicability.",
    "path": "papers/24/02/2402.01715.json",
    "total_tokens": 948,
    "translated_title": "ChatGPT、Gemini和LLaMA2在多语言情感分析方面的比较",
    "translated_abstract": "使用ChatGPT、Gemini或LLaMA2等基于大型语言模型（LLM）的模型进行自动情感分析，如今在学术研究和工业应用中越来越普遍。然而，在处理模棱两可或具有讽刺意味的文本时，对它们的性能进行评估和验证仍然不足。在本研究中，我们构建了细致和模棱两可的情境，并将其翻译成10种语言，然后使用流行的LLM进行情感预测。结果经过事后验证的人类回应来验证。ChatGPT和Gemini通常对模棱两可的情境处理得很好，但我们发现模型和评估的人类语言之间存在显著的偏差和性能不一致。这项工作为自动情感分析提供了标准化的评估方法，并呼吁进一步改进算法及其基础数据，以提高性能、可解释性和适用性。",
    "tldr": "本研究对ChatGPT、Gemini和LLaMA2等多语言情感分析模型进行了比较，发现这些模型在处理模棱两可的情境时表现良好，但在不同语言和评估中存在显著的偏差和性能不一致。这项工作为自动情感分析提供了标准化的评估方法，并呼吁改进算法和数据，以提高性能、可解释性和适用性。",
    "en_tdlr": "This study compares ChatGPT, Gemini, and LLaMA2 for multilingual sentiment analysis and finds that these models perform well in handling ambiguous scenarios but show significant biases and inconsistent performance across different languages and evaluations. The study provides a standardized evaluation methodology for automated sentiment analysis and calls for improvements in algorithms and data to enhance performance, interpretability, and applicability."
}