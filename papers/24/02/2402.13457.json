{
    "title": "LLM Jailbreak Attack versus Defense Techniques -- A Comprehensive Study",
    "abstract": "arXiv:2402.13457v1 Announce Type: cross  Abstract: Large Language Models (LLMS) have increasingly become central to generating content with potential societal impacts. Notably, these models have demonstrated capabilities for generating content that could be deemed harmful. To mitigate these risks, researchers have adopted safety training techniques to align model outputs with societal values to curb the generation of malicious content. However, the phenomenon of \"jailbreaking\", where carefully crafted prompts elicit harmful responses from models, persists as a significant challenge. This research conducts a comprehensive analysis of existing studies on jailbreaking LLMs and their defense techniques. We meticulously investigate nine attack techniques and seven defense techniques applied across three distinct language models: Vicuna, LLama, and GPT-3.5 Turbo. We aim to evaluate the effectiveness of these attack and defense techniques. Our findings reveal that existing white-box attacks u",
    "link": "https://arxiv.org/abs/2402.13457",
    "context": "Title: LLM Jailbreak Attack versus Defense Techniques -- A Comprehensive Study\nAbstract: arXiv:2402.13457v1 Announce Type: cross  Abstract: Large Language Models (LLMS) have increasingly become central to generating content with potential societal impacts. Notably, these models have demonstrated capabilities for generating content that could be deemed harmful. To mitigate these risks, researchers have adopted safety training techniques to align model outputs with societal values to curb the generation of malicious content. However, the phenomenon of \"jailbreaking\", where carefully crafted prompts elicit harmful responses from models, persists as a significant challenge. This research conducts a comprehensive analysis of existing studies on jailbreaking LLMs and their defense techniques. We meticulously investigate nine attack techniques and seven defense techniques applied across three distinct language models: Vicuna, LLama, and GPT-3.5 Turbo. We aim to evaluate the effectiveness of these attack and defense techniques. Our findings reveal that existing white-box attacks u",
    "path": "papers/24/02/2402.13457.json",
    "total_tokens": 857,
    "translated_title": "LLM越狱攻击与防御技术—一项全面研究",
    "translated_abstract": "大型语言模型(LLMs)越来越成为产生具有潜在社会影响内容的核心。值得注意的是，这些模型展示了生成可能被视为有害的内容的能力。为了减轻这些风险，研究人员采用了安全训练技术，以使模型输出与社会价值观保持一致，以遏制对恶意内容的生成。然而，“越狱”现象，即精心制作的提示引发模型产生有害回应的情况，仍然是一个重要挑战。本研究对现有关于越狱LLMs及其防御技术的研究进行了全面分析。我们对三种不同语言模型的九种攻击技术和七种防御技术进行了细致调查：Vicuna、LLama和GPT-3.5 Turbo。我们旨在评估这些攻击和防御技术的有效性。我们的研究结果表明，现有的白盒攻击u",
    "tldr": "本研究对LLM模型的越狱攻击和防御技术进行了全面研究，揭示了现有攻击和防御技术的有效性。"
}