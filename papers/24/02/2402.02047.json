{
    "title": "Quality and Trust in LLM-generated Code",
    "abstract": "Machine learning models are widely used but can also often be wrong. Users would benefit from a reliable indication of whether a given output from a given model should be trusted, so a rational decision can be made whether to use the output or not. For example, outputs can be associated with a confidence measure; if this confidence measure is strongly associated with likelihood of correctness, then the model is said to be well-calibrated. In this case, for example, high-confidence outputs could be safely accepted, and low-confidence outputs rejected.   Calibration has so far been studied in non-generative (e.g., classification) settings, especially in Software Engineering. However, generated code can quite often be wrong: Developers need to know when they should e.g., directly use, use after careful review, or discard model-generated code; thus Calibration is vital in generative settings. However, the notion of correctness of generated code is non-trivial, and thus so is Calibration. I",
    "link": "https://arxiv.org/abs/2402.02047",
    "context": "Title: Quality and Trust in LLM-generated Code\nAbstract: Machine learning models are widely used but can also often be wrong. Users would benefit from a reliable indication of whether a given output from a given model should be trusted, so a rational decision can be made whether to use the output or not. For example, outputs can be associated with a confidence measure; if this confidence measure is strongly associated with likelihood of correctness, then the model is said to be well-calibrated. In this case, for example, high-confidence outputs could be safely accepted, and low-confidence outputs rejected.   Calibration has so far been studied in non-generative (e.g., classification) settings, especially in Software Engineering. However, generated code can quite often be wrong: Developers need to know when they should e.g., directly use, use after careful review, or discard model-generated code; thus Calibration is vital in generative settings. However, the notion of correctness of generated code is non-trivial, and thus so is Calibration. I",
    "path": "papers/24/02/2402.02047.json",
    "total_tokens": 798,
    "translated_title": "机器学习生成代码的质量和信任",
    "translated_abstract": "机器学习模型广泛应用，但常常会出错。用户需要可靠的指示，以确定给定模型的输出是否可信，从而可以做出理性决策是否使用该输出。例如，可以将输出与置信度相关联；如果置信度与正确性的可能性强相关，则称该模型为良好校准。在这种情况下，高置信度的输出可以安全接受，低置信度的输出可以拒绝。校准迄今主要在非生成性（例如分类）环境中进行研究，特别是在软件工程领域。然而，生成代码很容易出错：开发人员需要知道何时直接使用、经过仔细审查后使用或丢弃模型生成的代码，因此在生成环境中，校准非常重要。然而，生成代码的正确性概念并不简单，因此校准也是如此。",
    "tldr": "本论文研究了机器学习生成代码的质量和信任问题，提出了校准的重要性，并探讨了如何确定模型生成代码的正确性。",
    "en_tdlr": "This paper investigates the quality and trust in machine learning-generated code, emphasizes the importance of calibration, and explores approaches to determine the correctness of the generated code."
}