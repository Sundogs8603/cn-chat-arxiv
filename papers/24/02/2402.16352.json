{
    "title": "MathGenie: Generating Synthetic Data with Question Back-translation for Enhancing Mathematical Reasoning of LLMs",
    "abstract": "arXiv:2402.16352v1 Announce Type: cross  Abstract: Large language models (LLMs) have exhibited great potential in mathematical reasoning. However, there remains a performance gap in this area between existing open-source models and closed-source models such as GPT-4. In this paper, we introduce MathGenie, a novel method for generating diverse and reliable math problems from a small-scale problem-solution dataset (denoted as seed data). We augment the ground-truth solutions of our seed data and train a back-translation model to translate the augmented solutions back into new questions. Subsequently, we generate code-integrated solutions for the new questions. To ensure the correctness of the code-integrated solutions, we employ rationale-based strategy for solution verification. Various pretrained models, ranging from 7B to 70B, are trained on the newly curated data to test the effectiveness of the proposed augmentation technique, resulting in a family of models known as MathGenieLM. Th",
    "link": "https://arxiv.org/abs/2402.16352",
    "context": "Title: MathGenie: Generating Synthetic Data with Question Back-translation for Enhancing Mathematical Reasoning of LLMs\nAbstract: arXiv:2402.16352v1 Announce Type: cross  Abstract: Large language models (LLMs) have exhibited great potential in mathematical reasoning. However, there remains a performance gap in this area between existing open-source models and closed-source models such as GPT-4. In this paper, we introduce MathGenie, a novel method for generating diverse and reliable math problems from a small-scale problem-solution dataset (denoted as seed data). We augment the ground-truth solutions of our seed data and train a back-translation model to translate the augmented solutions back into new questions. Subsequently, we generate code-integrated solutions for the new questions. To ensure the correctness of the code-integrated solutions, we employ rationale-based strategy for solution verification. Various pretrained models, ranging from 7B to 70B, are trained on the newly curated data to test the effectiveness of the proposed augmentation technique, resulting in a family of models known as MathGenieLM. Th",
    "path": "papers/24/02/2402.16352.json",
    "total_tokens": 867,
    "translated_title": "MathGenie: 使用问题反向翻译生成合成数据，以增强LLMs的数学推理能力",
    "translated_abstract": "大型语言模型(LLMs)在数学推理方面展现出巨大潜力。然而，目前开源模型和GPT-4等闭源模型之间在这一领域仍存在性能差距。本文介绍了一种新颖的方法MathGenie，用于从小规模问题-解决方案数据集（称为种子数据）中生成多样且可靠的数学问题。我们扩充了种子数据的真实解决方案，并训练了一个反向翻译模型，将扩充的解决方案翻译回新问题。随后，我们为新问题生成了集成代码解决方案。为确保集成代码解决方案的正确性，我们采用了基于原理的解决方案验证策略。我们在新筛选的数据上对从7B到70B不等的各种预训练模型进行训练，以测试所提出的增强技术的有效性，从而产生了一个称为MathGenieLM的模型系列。",
    "tldr": "MathGenie通过问题反向翻译生成合成数据，用于增强LLMs的数学推理能力，并创造了一个家族化的模型系列MathGenieLM。"
}