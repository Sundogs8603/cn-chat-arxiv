{
    "title": "InfFeed: Influence Functions as a Feedback to Improve the Performance of Subjective Tasks",
    "abstract": "arXiv:2402.14702v1 Announce Type: new  Abstract: Recently, influence functions present an apparatus for achieving explainability for deep neural models by quantifying the perturbation of individual train instances that might impact a test prediction. Our objectives in this paper are twofold. First we incorporate influence functions as a feedback into the model to improve its performance. Second, in a dataset extension exercise, using influence functions to automatically identify data points that have been initially `silver' annotated by some existing method and need to be cross-checked (and corrected) by annotators to improve the model performance. To meet these objectives, in this paper, we introduce InfFeed, which uses influence functions to compute the influential instances for a target instance. Toward the first objective, we adjust the label of the target instance based on its influencer(s) label. In doing this, InfFeed outperforms the state-of-the-art baselines (including LLMs) b",
    "link": "https://arxiv.org/abs/2402.14702",
    "context": "Title: InfFeed: Influence Functions as a Feedback to Improve the Performance of Subjective Tasks\nAbstract: arXiv:2402.14702v1 Announce Type: new  Abstract: Recently, influence functions present an apparatus for achieving explainability for deep neural models by quantifying the perturbation of individual train instances that might impact a test prediction. Our objectives in this paper are twofold. First we incorporate influence functions as a feedback into the model to improve its performance. Second, in a dataset extension exercise, using influence functions to automatically identify data points that have been initially `silver' annotated by some existing method and need to be cross-checked (and corrected) by annotators to improve the model performance. To meet these objectives, in this paper, we introduce InfFeed, which uses influence functions to compute the influential instances for a target instance. Toward the first objective, we adjust the label of the target instance based on its influencer(s) label. In doing this, InfFeed outperforms the state-of-the-art baselines (including LLMs) b",
    "path": "papers/24/02/2402.14702.json",
    "total_tokens": 830,
    "translated_title": "InfFeed：将影响函数作为反馈以改善主观任务的表现",
    "translated_abstract": "最近，影响函数提供了一种工具，通过量化可能影响测试预测的个别训练实例的扰动，实现对深度神经模型的可解释性。本文的目标是双重的。首先，我们将影响函数作为反馈引入模型以改善其性能。其次，在数据集扩展练习中，使用影响函数自动识别最初由某些现有方法‘银’注释的数据点，并需要标注者交叉检查（和纠正）以改善模型性能。为了实现这些目标，本文引入了InfFeed，该方法使用影响函数计算目标实例的有影响力的实例。向第一个目标努力，我们根据其影响者的标签调整目标实例的标签。在此过程中，InfFeed的表现优于现有基线（包括LLMs）。",
    "tldr": "InfFeed将影响函数作为反馈，用于改善主观任务表现，并通过自动识别需要交叉检查的数据点以提高模型性能，在调整标签方面优于现有基线。",
    "en_tdlr": "InfFeed utilizes influence functions as feedback to enhance the performance of subjective tasks, outperforming existing baselines by automatically identifying data points requiring cross-checking and improving model performance through label adjustments based on influencers."
}