{
    "title": "Pointing out the Shortcomings of Relation Extraction Models with Semantically Motivated Adversarials",
    "abstract": "arXiv:2402.19076v1 Announce Type: new  Abstract: In recent years, large language models have achieved state-of-the-art performance across various NLP tasks. However, investigations have shown that these models tend to rely on shortcut features, leading to inaccurate predictions and causing the models to be unreliable at generalization to out-of-distribution (OOD) samples. For instance, in the context of relation extraction (RE), we would expect a model to identify the same relation independently of the entities involved in it. For example, consider the sentence \"Leonardo da Vinci painted the Mona Lisa\" expressing the created(Leonardo_da_Vinci, Mona_Lisa) relation. If we substiute \"Leonardo da Vinci\" with \"Barack Obama\", then the sentence still expresses the created relation. A robust model is supposed to detect the same relation in both cases. In this work, we describe several semantically-motivated strategies to generate adversarial examples by replacing entity mentions and investigat",
    "link": "https://arxiv.org/abs/2402.19076",
    "context": "Title: Pointing out the Shortcomings of Relation Extraction Models with Semantically Motivated Adversarials\nAbstract: arXiv:2402.19076v1 Announce Type: new  Abstract: In recent years, large language models have achieved state-of-the-art performance across various NLP tasks. However, investigations have shown that these models tend to rely on shortcut features, leading to inaccurate predictions and causing the models to be unreliable at generalization to out-of-distribution (OOD) samples. For instance, in the context of relation extraction (RE), we would expect a model to identify the same relation independently of the entities involved in it. For example, consider the sentence \"Leonardo da Vinci painted the Mona Lisa\" expressing the created(Leonardo_da_Vinci, Mona_Lisa) relation. If we substiute \"Leonardo da Vinci\" with \"Barack Obama\", then the sentence still expresses the created relation. A robust model is supposed to detect the same relation in both cases. In this work, we describe several semantically-motivated strategies to generate adversarial examples by replacing entity mentions and investigat",
    "path": "papers/24/02/2402.19076.json",
    "total_tokens": 697,
    "translated_title": "用语义驱动的对抗生成模型指出关系抽取模型的缺陷",
    "translated_abstract": "近年来，大型语言模型在各种自然语言处理任务中取得了最先进的性能。然而，调查显示这些模型往往依赖于捷径特性，导致不准确的预测，使模型在泛化到分布之外（OOD）样本时不可靠。本文介绍了几种基于语义动机的策略，通过替换实体提及来生成对抗性示例，以此来探究关系抽取模型的缺陷。",
    "tldr": "本文通过替换实体提及来生成对抗性示例，揭示了关系抽取模型的捷径特性缺陷",
    "en_tdlr": "This paper exposes the shortcut features of relation extraction models by generating adversarial examples through replacing entity mentions."
}