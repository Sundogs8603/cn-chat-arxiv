{
    "title": "SINR-Aware Deep Reinforcement Learning for Distributed Dynamic Channel Allocation in Cognitive Interference Networks",
    "abstract": "arXiv:2402.17773v1 Announce Type: cross  Abstract: We consider the problem of dynamic channel allocation (DCA) in cognitive communication networks with the goal of maximizing a global signal-to-interference-plus-noise ratio (SINR) measure under a specified target quality of service (QoS)-SINR for each network. The shared bandwidth is partitioned into K channels with frequency separation. In contrast to the majority of existing studies that assume perfect orthogonality or a one- to-one user-channel allocation mapping, this paper focuses on real-world systems experiencing inter-carrier interference (ICI) and channel reuse by multiple large-scale networks. This realistic scenario significantly increases the problem dimension, rendering existing algorithms inefficient. We propose a novel multi-agent reinforcement learning (RL) framework for distributed DCA, named Channel Allocation RL To Overlapped Networks (CARLTON). The CARLTON framework is based on the Centralized Training with Decentra",
    "link": "https://arxiv.org/abs/2402.17773",
    "context": "Title: SINR-Aware Deep Reinforcement Learning for Distributed Dynamic Channel Allocation in Cognitive Interference Networks\nAbstract: arXiv:2402.17773v1 Announce Type: cross  Abstract: We consider the problem of dynamic channel allocation (DCA) in cognitive communication networks with the goal of maximizing a global signal-to-interference-plus-noise ratio (SINR) measure under a specified target quality of service (QoS)-SINR for each network. The shared bandwidth is partitioned into K channels with frequency separation. In contrast to the majority of existing studies that assume perfect orthogonality or a one- to-one user-channel allocation mapping, this paper focuses on real-world systems experiencing inter-carrier interference (ICI) and channel reuse by multiple large-scale networks. This realistic scenario significantly increases the problem dimension, rendering existing algorithms inefficient. We propose a novel multi-agent reinforcement learning (RL) framework for distributed DCA, named Channel Allocation RL To Overlapped Networks (CARLTON). The CARLTON framework is based on the Centralized Training with Decentra",
    "path": "papers/24/02/2402.17773.json",
    "total_tokens": 881,
    "translated_title": "面向认知干扰网络中分布式动态信道分配的 SINR 感知深度强化学习",
    "translated_abstract": "我们考虑认知通信网络中动态信道分配（DCA）的问题，其目标是在为每个网络设定的目标服务质量（QoS）-SINR 下最大化全局信号干扰加噪声比（SINR）度量。共享带宽分为具有频率间隔的 K 个信道。与大多数现有研究假设完全正交性或一对一用户-信道分配映射不同，该论文专注于实际系统中遇到的载波间干扰（ICI）和多个大规模网络的信道重用。这种现实场景显著增加了问题的维度，使得现有算法效率低下。我们提出了一种为分布式 DCA 设计的新型多智能体强化学习（RL）框架，名为重叠网络中信道分配 RL（CARLTON）。CARLTON框架基于集中式训练，同时保持了去中心化",
    "tldr": "该论文提出了一种名为 CARLTON 的新型多智能体强化学习框架，用于分布式动态信道分配，以解决认知干扰网络中的信号干扰加噪声比最大化问题。",
    "en_tdlr": "This paper proposes a novel multi-agent reinforcement learning framework named CARLTON for distributed dynamic channel allocation to maximize the signal-to-interference-plus-noise ratio in cognitive interference networks."
}