{
    "title": "Can we soft prompt LLMs for graph learning tasks?",
    "abstract": "arXiv:2402.10359v1 Announce Type: cross  Abstract: Graph plays an important role in representing complex relationships in real-world applications such as social networks, biological data and citation networks. In recent years, Large Language Models (LLMs) have achieved tremendous success in various domains, which makes applying LLMs to graphs particularly appealing. However, directly applying LLMs to graph modalities presents unique challenges due to the discrepancy and mismatch between the graph and text modalities. Hence, to further investigate LLMs' potential for comprehending graph information, we introduce GraphPrompter, a novel framework designed to align graph information with LLMs via soft prompts. Specifically, GraphPrompter consists of two main components: a graph neural network to encode complex graph information and an LLM that effectively processes textual information. Comprehensive experiments on various benchmark datasets under node classification and link prediction tas",
    "link": "https://arxiv.org/abs/2402.10359",
    "context": "Title: Can we soft prompt LLMs for graph learning tasks?\nAbstract: arXiv:2402.10359v1 Announce Type: cross  Abstract: Graph plays an important role in representing complex relationships in real-world applications such as social networks, biological data and citation networks. In recent years, Large Language Models (LLMs) have achieved tremendous success in various domains, which makes applying LLMs to graphs particularly appealing. However, directly applying LLMs to graph modalities presents unique challenges due to the discrepancy and mismatch between the graph and text modalities. Hence, to further investigate LLMs' potential for comprehending graph information, we introduce GraphPrompter, a novel framework designed to align graph information with LLMs via soft prompts. Specifically, GraphPrompter consists of two main components: a graph neural network to encode complex graph information and an LLM that effectively processes textual information. Comprehensive experiments on various benchmark datasets under node classification and link prediction tas",
    "path": "papers/24/02/2402.10359.json",
    "total_tokens": 796,
    "translated_title": "我们能否用软提示LLMs来进行图学习任务？",
    "translated_abstract": "图在表示社交网络、生物数据和引用网络等现实世界应用中的复杂关系方面起着重要作用。最近，大型语言模型（LLMs）在各个领域取得了巨大成功，这使得将LLMs应用于图表格尤为诱人。然而，直接将LLMs应用于图表格形式存在独特挑战，因为图表格形式与文本形式之间存在差异和不匹配。因此，为了进一步探究LLMs理解图信息的潜力，我们引入了GraphPrompter，这是一个通过软提示来将图信息与LLMs对齐的新颖框架。具体而言，GraphPrompter包括两个主要组件：一个图神经网络用于编码复杂的图信息，以及一个能够有效处理文本信息的LLM。在不同基准数据集上进行了广泛实验，涵盖了节点分类和链接预测任务。",
    "tldr": "引入了GraphPrompter框架，通过软提示将图信息与LLMs对齐，以进一步探究LLMs理解图信息的潜力。",
    "en_tdlr": "Introduced the GraphPrompter framework to align graph information with LLMs via soft prompts for further investigation of LLMs' potential for understanding graph information."
}