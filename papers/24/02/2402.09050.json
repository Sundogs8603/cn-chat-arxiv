{
    "title": "End-to-End Training Induces Information Bottleneck through Layer-Role Differentiation: A Comparative Analysis with Layer-wise Training",
    "abstract": "arXiv:2402.09050v1 Announce Type: new Abstract: End-to-end (E2E) training, optimizing the entire model through error backpropagation, fundamentally supports the advancements of deep learning. Despite its high performance, E2E training faces the problems of memory consumption, parallel computing, and discrepancy with the functionalities of the actual brain. Various alternative methods have been proposed to overcome these difficulties; however, no one can yet match the performance of E2E training, thereby falling short in practicality. Furthermore, there is no deep understanding regarding differences in the trained model properties beyond the performance gap. In this paper, we reconsider why E2E training demonstrates a superior performance through a comparison with layer-wise training, a non-E2E method that locally sets errors. On the basis of the observation that E2E training has an advantage in propagating input information, we analyze the information plane dynamics of intermediate rep",
    "link": "https://arxiv.org/abs/2402.09050",
    "context": "Title: End-to-End Training Induces Information Bottleneck through Layer-Role Differentiation: A Comparative Analysis with Layer-wise Training\nAbstract: arXiv:2402.09050v1 Announce Type: new Abstract: End-to-end (E2E) training, optimizing the entire model through error backpropagation, fundamentally supports the advancements of deep learning. Despite its high performance, E2E training faces the problems of memory consumption, parallel computing, and discrepancy with the functionalities of the actual brain. Various alternative methods have been proposed to overcome these difficulties; however, no one can yet match the performance of E2E training, thereby falling short in practicality. Furthermore, there is no deep understanding regarding differences in the trained model properties beyond the performance gap. In this paper, we reconsider why E2E training demonstrates a superior performance through a comparison with layer-wise training, a non-E2E method that locally sets errors. On the basis of the observation that E2E training has an advantage in propagating input information, we analyze the information plane dynamics of intermediate rep",
    "path": "papers/24/02/2402.09050.json",
    "total_tokens": 918,
    "translated_title": "通过层角色差异化，端到端训练引发信息瓶颈：与逐层训练的比较分析",
    "translated_abstract": "端到端（E2E）训练通过误差反向传播优化整个模型，从根本上支持深度学习的进展。尽管其性能很高，但E2E训练面临内存消耗、并行计算和与实际大脑功能的不一致等问题。已经提出了各种替代方法来克服这些困难，然而目前还没有一种能够与E2E训练的性能匹配的方法，因此在实用性上存在不足。此外，对于训练模型性质的差异在性能差距之外缺乏深入的理解。在本文中，我们通过与逐层训练进行比较，重新考虑了为什么E2E训练表现出优越的性能，逐层训练是一种局部设置错误的非E2E方法。在观察到E2E训练在传播输入信息方面具有优势的基础上，我们分析了中间表示的信息平面动态。",
    "tldr": "本文通过与逐层训练的比较，重新考虑了为什么端到端训练表现出优越的性能，分析了信息传播方面的优势，并对训练模型的性质差异进行了深入理解。"
}