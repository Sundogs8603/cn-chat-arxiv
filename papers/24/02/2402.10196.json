{
    "title": "A Trembling House of Cards? Mapping Adversarial Attacks against Language Agents",
    "abstract": "arXiv:2402.10196v1 Announce Type: cross  Abstract: Language agents powered by large language models (LLMs) have seen exploding development. Their capability of using language as a vehicle for thought and communication lends an incredible level of flexibility and versatility. People have quickly capitalized on this capability to connect LLMs to a wide range of external components and environments: databases, tools, the Internet, robotic embodiment, etc. Many believe an unprecedentedly powerful automation technology is emerging. However, new automation technologies come with new safety risks, especially for intricate systems like language agents. There is a surprisingly large gap between the speed and scale of their development and deployment and our understanding of their safety risks. Are we building a house of cards? In this position paper, we present the first systematic effort in mapping adversarial attacks against language agents. We first present a unified conceptual framework for",
    "link": "https://arxiv.org/abs/2402.10196",
    "context": "Title: A Trembling House of Cards? Mapping Adversarial Attacks against Language Agents\nAbstract: arXiv:2402.10196v1 Announce Type: cross  Abstract: Language agents powered by large language models (LLMs) have seen exploding development. Their capability of using language as a vehicle for thought and communication lends an incredible level of flexibility and versatility. People have quickly capitalized on this capability to connect LLMs to a wide range of external components and environments: databases, tools, the Internet, robotic embodiment, etc. Many believe an unprecedentedly powerful automation technology is emerging. However, new automation technologies come with new safety risks, especially for intricate systems like language agents. There is a surprisingly large gap between the speed and scale of their development and deployment and our understanding of their safety risks. Are we building a house of cards? In this position paper, we present the first systematic effort in mapping adversarial attacks against language agents. We first present a unified conceptual framework for",
    "path": "papers/24/02/2402.10196.json",
    "total_tokens": 829,
    "translated_title": "一座摇摇欲坠的纸牌屋？对语言代理的敌对攻击的映射",
    "translated_abstract": "由大型语言模型（LLMs）驱动的语言代理在发展中迅猛。它们利用语言作为思想和交流的工具，赋予了无比的灵活性和多样性。人们迅速利用这种能力将LLMs连接到各种外部组件和环境中：数据库，工具，因特网，机器人实体等。许多人相信一种前所未有的强大自动化技术正在崛起。然而，新的自动化技术也带来了新的安全风险，特别是对于复杂的系统如语言代理。他们的开发和部署的速度和规模与我们对其安全风险的理解之间存在着令人惊讶的差距。我们是否正在建造一座纸牌屋？在本论文中，我们首次系统地对语言代理的敌对攻击进行了映射。我们首先提出了一个统一的概念框架",
    "tldr": "本文是第一个对语言代理的敌对攻击进行映射的系统化努力。它提供了一个统一的概念框架来研究这些攻击。这有助于我们理解语言代理的安全风险。"
}