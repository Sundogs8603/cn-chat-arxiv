{
    "title": "Tower: An Open Multilingual Large Language Model for Translation-Related Tasks",
    "abstract": "arXiv:2402.17733v1 Announce Type: new  Abstract: While general-purpose large language models (LLMs) demonstrate proficiency on multiple tasks within the domain of translation, approaches based on open LLMs are competitive only when specializing on a single task. In this paper, we propose a recipe for tailoring LLMs to multiple tasks present in translation workflows. We perform continued pretraining on a multilingual mixture of monolingual and parallel data, creating TowerBase, followed by finetuning on instructions relevant for translation processes, creating TowerInstruct. Our final model surpasses open alternatives on several tasks relevant to translation workflows and is competitive with general-purpose closed LLMs. To facilitate future research, we release the Tower models, our specialization dataset, an evaluation framework for LLMs focusing on the translation ecosystem, and a collection of model generations, including ours, on our benchmark.",
    "link": "https://arxiv.org/abs/2402.17733",
    "context": "Title: Tower: An Open Multilingual Large Language Model for Translation-Related Tasks\nAbstract: arXiv:2402.17733v1 Announce Type: new  Abstract: While general-purpose large language models (LLMs) demonstrate proficiency on multiple tasks within the domain of translation, approaches based on open LLMs are competitive only when specializing on a single task. In this paper, we propose a recipe for tailoring LLMs to multiple tasks present in translation workflows. We perform continued pretraining on a multilingual mixture of monolingual and parallel data, creating TowerBase, followed by finetuning on instructions relevant for translation processes, creating TowerInstruct. Our final model surpasses open alternatives on several tasks relevant to translation workflows and is competitive with general-purpose closed LLMs. To facilitate future research, we release the Tower models, our specialization dataset, an evaluation framework for LLMs focusing on the translation ecosystem, and a collection of model generations, including ours, on our benchmark.",
    "path": "papers/24/02/2402.17733.json",
    "total_tokens": 792,
    "translated_title": "Tower：一个面向翻译相关任务的开放多语言大语言模型",
    "translated_abstract": "在这篇论文中，我们提出了一种调整大语言模型（LLMs）以满足翻译流程中多个任务的方法。我们在多语言混合的单语和平行数据上进行持续预训练，创建TowerBase，然后在与翻译流程相关的说明上进行微调，创建TowerInstruct。我们的最终模型在几项与翻译流程相关的任务上超过了开放式替代方案，并与通用封闭式LLMs相竞争。为了促进未来的研究，我们发布了Tower模型，我们的专业数据集，针对翻译生态系统专注于LLMs的评估框架，以及我们的基准模型生成集合。",
    "tldr": "本文提出了一种方法，通过在多语言数据上进行预训练，再在翻译流程说明上进行微调，可以使大语言模型在翻译相关任务上超越开放替代方案并与通用封闭式大语言模型竞争。",
    "en_tdlr": "This paper presents a method that surpasses open alternatives and competes with general-purpose closed large language models in translation-related tasks by pretraining on multilingual data followed by fine-tuning on translation instructions."
}