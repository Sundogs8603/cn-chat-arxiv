{
    "title": "AnaloBench: Benchmarking the Identification of Abstract and Long-context Analogies",
    "abstract": "arXiv:2402.12370v1 Announce Type: cross  Abstract: Humans regularly engage in analogical thinking, relating personal experiences to current situations ($X$ is analogous to $Y$ because of $Z$). Analogical thinking allows humans to solve problems in creative ways, grasp difficult concepts, and articulate ideas more effectively. Can language models (LMs) do the same? To answer this question, we propose ANALOBENCH, a benchmark to determine analogical reasoning ability in LMs. Our benchmarking approach focuses on aspects of this ability that are common among humans: (i) recalling related experiences from a large amount of information, and (ii) applying analogical reasoning to complex and lengthy scenarios. We test a broad collection of proprietary models (e.g., GPT family, Claude V2) and open source models such as LLaMA2. As in prior results, scaling up LMs results in some performance boosts. Surprisingly, scale offers minimal gains when, (i) analogies involve lengthy scenarios, or (ii) rec",
    "link": "https://arxiv.org/abs/2402.12370",
    "context": "Title: AnaloBench: Benchmarking the Identification of Abstract and Long-context Analogies\nAbstract: arXiv:2402.12370v1 Announce Type: cross  Abstract: Humans regularly engage in analogical thinking, relating personal experiences to current situations ($X$ is analogous to $Y$ because of $Z$). Analogical thinking allows humans to solve problems in creative ways, grasp difficult concepts, and articulate ideas more effectively. Can language models (LMs) do the same? To answer this question, we propose ANALOBENCH, a benchmark to determine analogical reasoning ability in LMs. Our benchmarking approach focuses on aspects of this ability that are common among humans: (i) recalling related experiences from a large amount of information, and (ii) applying analogical reasoning to complex and lengthy scenarios. We test a broad collection of proprietary models (e.g., GPT family, Claude V2) and open source models such as LLaMA2. As in prior results, scaling up LMs results in some performance boosts. Surprisingly, scale offers minimal gains when, (i) analogies involve lengthy scenarios, or (ii) rec",
    "path": "papers/24/02/2402.12370.json",
    "total_tokens": 917,
    "translated_title": "AnaloBench：评估抽象和长上下文类比识别的基准",
    "translated_abstract": "人类经常进行类比思维，将个人经验与当前情况联系起来（$X$类似于$Y$是因为$Z$）。类比思维使人类能够用创造性方式解决问题，理解困难概念，更有效地表达想法。能否语言模型（LMs）也能做到这一点？为了回答这个问题，我们提出了ANALOBENCH，一个用于确定LMs类比推理能力的基准。我们的基准方法专注于人类之间共同的类比推理能力方面：（i）从大量信息中回忆相关经验，以及（ii）将类比推理应用于复杂和长度较长的场景。我们测试了大量专有模型（例如，GPT系列，Claude V2）和开源模型，如LLaMA2。与先前的结果一样，扩展LMs会带来一些性能提升。令人惊讶的是，在类比涉及长场景或回忆相关经验时，规模的提升带来的增益很小。",
    "tldr": "通过提出ANALOBENCH基准来评估语言模型（LMs）进行类比推理的能力，发现扩展LMs规模对于处理涉及长场景或相关经验回忆的类比时带来的性能提升较小。",
    "en_tdlr": "By proposing the ANALOBENCH benchmark to evaluate the ability of language models (LMs) for analogical reasoning, we find that scaling up LMs offers minimal performance gains when handling analogies with lengthy scenarios or related experience recalls."
}