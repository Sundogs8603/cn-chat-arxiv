{
    "title": "Hierarchical Bayes Approach to Personalized Federated Unsupervised Learning",
    "abstract": "arXiv:2402.12537v1 Announce Type: new  Abstract: Statistical heterogeneity of clients' local data is an important characteristic in federated learning, motivating personalized algorithms tailored to the local data statistics. Though there has been a plethora of algorithms proposed for personalized supervised learning, discovering the structure of local data through personalized unsupervised learning is less explored. We initiate a systematic study of such personalized unsupervised learning by developing algorithms based on optimization criteria inspired by a hierarchical Bayesian statistical framework. We develop adaptive algorithms that discover the balance between using limited local data and collaborative information. We do this in the context of two unsupervised learning tasks: personalized dimensionality reduction and personalized diffusion models. We develop convergence analyses for our adaptive algorithms which illustrate the dependence on problem parameters (e.g., heterogeneity",
    "link": "https://arxiv.org/abs/2402.12537",
    "context": "Title: Hierarchical Bayes Approach to Personalized Federated Unsupervised Learning\nAbstract: arXiv:2402.12537v1 Announce Type: new  Abstract: Statistical heterogeneity of clients' local data is an important characteristic in federated learning, motivating personalized algorithms tailored to the local data statistics. Though there has been a plethora of algorithms proposed for personalized supervised learning, discovering the structure of local data through personalized unsupervised learning is less explored. We initiate a systematic study of such personalized unsupervised learning by developing algorithms based on optimization criteria inspired by a hierarchical Bayesian statistical framework. We develop adaptive algorithms that discover the balance between using limited local data and collaborative information. We do this in the context of two unsupervised learning tasks: personalized dimensionality reduction and personalized diffusion models. We develop convergence analyses for our adaptive algorithms which illustrate the dependence on problem parameters (e.g., heterogeneity",
    "path": "papers/24/02/2402.12537.json",
    "total_tokens": 849,
    "translated_title": "针对个性化联邦无监督学习的分层贝叶斯方法",
    "translated_abstract": "客户本地数据的统计异质性是联邦学习中的重要特征，其促使个性化算法针对本地数据统计量进行定制。尽管已经提出了大量针对个性化监督学习的算法，但通过个性化无监督学习发现本地数据的结构却很少被探索。我们通过基于层次贝叶斯统计框架启动了对这种个性化无监督学习的系统研究。我们开发了基于优化标准的算法，这些算法受启发于层次贝叶斯统计框架。我们开发了适应性算法，发现了利用有限本地数据和协作信息之间的平衡。我们在两个无监督学习任务的背景下进行了这项工作：个性化降维和个性化扩散模型。我们为我们的自适应算法开发了收敛分析，这些分析展示了对问题参数（例如，异质性）的依赖性。",
    "tldr": "该论文提出了基于分层贝叶斯统计框架的算法，用于个性化无监督学习，其中开发了适应性算法来平衡利用有限本地数据和协作信息。",
    "en_tdlr": "This paper introduces algorithms based on a hierarchical Bayesian statistical framework for personalized unsupervised learning, developing adaptive algorithms to balance the use of limited local data and collaborative information."
}