{
    "title": "LCEN: A Novel Feature Selection Algorithm for Nonlinear, Interpretable Machine Learning Models",
    "abstract": "arXiv:2402.17120v1 Announce Type: new  Abstract: Interpretable architectures can have advantages over black-box architectures, and interpretability is essential for the application of machine learning in critical settings, such as aviation or medicine. However, the simplest, most commonly used interpretable architectures (such as LASSO or EN) are limited to linear predictions and have poor feature selection capabilities. In this work, we introduce the LASSO-Clip-EN (LCEN) algorithm for the creation of nonlinear, interpretable machine learning models. LCEN is tested on a wide variety of artificial and empirical datasets, creating more accurate, sparser models than other commonly used architectures. These experiments reveal that LCEN is robust against many issues typically present in datasets and modeling, including noise, multicollinearity, data scarcity, and hyperparameter variance. LCEN is also able to rediscover multiple physical laws from empirical data and, for processes with no kn",
    "link": "https://arxiv.org/abs/2402.17120",
    "context": "Title: LCEN: A Novel Feature Selection Algorithm for Nonlinear, Interpretable Machine Learning Models\nAbstract: arXiv:2402.17120v1 Announce Type: new  Abstract: Interpretable architectures can have advantages over black-box architectures, and interpretability is essential for the application of machine learning in critical settings, such as aviation or medicine. However, the simplest, most commonly used interpretable architectures (such as LASSO or EN) are limited to linear predictions and have poor feature selection capabilities. In this work, we introduce the LASSO-Clip-EN (LCEN) algorithm for the creation of nonlinear, interpretable machine learning models. LCEN is tested on a wide variety of artificial and empirical datasets, creating more accurate, sparser models than other commonly used architectures. These experiments reveal that LCEN is robust against many issues typically present in datasets and modeling, including noise, multicollinearity, data scarcity, and hyperparameter variance. LCEN is also able to rediscover multiple physical laws from empirical data and, for processes with no kn",
    "path": "papers/24/02/2402.17120.json",
    "total_tokens": 839,
    "translated_title": "LCEN：一种新型特征选择算法，用于非线性的可解释机器学习模型",
    "translated_abstract": "可解释的架构相对于黑盒架构具有优势，在关键领域如航空或医学中，可解释性对机器学习应用至关重要。然而，最简单、最常用的可解释架构（如LASSO或EN）仅限于线性预测，并且特征选择能力较差。在这项工作中，我们引入了LASSO-Clip-EN（LCEN）算法，用于创建非线性、可解释的机器学习模型。LCEN在多种人工和实证数据集上进行了测试，生成比其他常用架构更准确、更稀疏的模型。这些实验表明，LCEN对数据集和建模中通常存在的许多问题具有鲁棒性，包括噪声、多重共线性、数据稀缺和超参数方差。LCEN还能够从实证数据中重新发现多个物理定律，",
    "tldr": "LCEN算法是一种用于创建非线性、可解释机器学习模型的新型特征选择算法，能够更准确、更稀疏地生成模型，并具有鲁棒性。",
    "en_tdlr": "LCEN algorithm is a novel feature selection algorithm for creating nonlinear, interpretable machine learning models, generating more accurate and sparser models with robustness."
}