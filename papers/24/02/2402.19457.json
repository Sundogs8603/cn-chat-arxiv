{
    "title": "$\\texttt{COSMIC}$: Mutual Information for Task-Agnostic Summarization Evaluation",
    "abstract": "arXiv:2402.19457v1 Announce Type: cross  Abstract: Assessing the quality of summarizers poses significant challenges. In response, we propose a novel task-oriented evaluation approach that assesses summarizers based on their capacity to produce summaries that are useful for downstream tasks, while preserving task outcomes. We theoretically establish a direct relationship between the resulting error probability of these tasks and the mutual information between source texts and generated summaries. We introduce $\\texttt{COSMIC}$ as a practical implementation of this metric, demonstrating its strong correlation with human judgment-based metrics and its effectiveness in predicting downstream task performance. Comparative analyses against established metrics like $\\texttt{BERTScore}$ and $\\texttt{ROUGE}$ highlight the competitive performance of $\\texttt{COSMIC}$.",
    "link": "https://arxiv.org/abs/2402.19457",
    "context": "Title: $\\texttt{COSMIC}$: Mutual Information for Task-Agnostic Summarization Evaluation\nAbstract: arXiv:2402.19457v1 Announce Type: cross  Abstract: Assessing the quality of summarizers poses significant challenges. In response, we propose a novel task-oriented evaluation approach that assesses summarizers based on their capacity to produce summaries that are useful for downstream tasks, while preserving task outcomes. We theoretically establish a direct relationship between the resulting error probability of these tasks and the mutual information between source texts and generated summaries. We introduce $\\texttt{COSMIC}$ as a practical implementation of this metric, demonstrating its strong correlation with human judgment-based metrics and its effectiveness in predicting downstream task performance. Comparative analyses against established metrics like $\\texttt{BERTScore}$ and $\\texttt{ROUGE}$ highlight the competitive performance of $\\texttt{COSMIC}$.",
    "path": "papers/24/02/2402.19457.json",
    "total_tokens": 794,
    "translated_title": "$\\texttt{COSMIC}$: 相互信息用于任务无关摘要评估",
    "translated_abstract": "评估总结质量存在显著挑战。为此，我们提出了一种新颖的面向任务的评估方法，根据总结器生成对下游任务有用且保留任务结果的摘要能力。我们在理论上建立了这些任务的结果错误概率与源文本和生成摘要之间的相互信息之间的直接关系。我们引入了$\\texttt{COSMIC}$作为这一度量的实际实现，展示了它与基于人类判断的度量之间的强相关性，以及它在预测下游任务性能方面的有效性。对已建立的度量如$\\texttt{BERTScore}$和$\\texttt{ROUGE}$的比较分析凸显了$\\texttt{COSMIC}$的竞争性能。",
    "tldr": "$\\texttt{COSMIC}$是一种以相互信息为基础的新的摘要评估方法，有效预测下游任务表现，并与人类判断相关性强。竞争性能优于$\\texttt{BERTScore}$和$\\texttt{ROUGE}$。",
    "en_tdlr": "$\\texttt{COSMIC}$ is a novel summarization evaluation method based on mutual information, effectively predicting downstream task performance and showing strong correlation with human judgment, outperforming$\\texttt{BERTScore}$ and $\\texttt{ROUGE}$."
}