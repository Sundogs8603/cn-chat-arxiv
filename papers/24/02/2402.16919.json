{
    "title": "Personalized Federated Instruction Tuning via Neural Architecture Search",
    "abstract": "arXiv:2402.16919v1 Announce Type: new  Abstract: Federated Instruction Tuning (FIT) has shown the ability to achieve collaborative model instruction tuning among massive data owners without sharing private data. However, it still faces two key challenges, i.e., data and resource heterogeneity. Due to the varying data distribution and preferences among data owners, FIT cannot adapt to the personalized data of individual owners. Moreover, clients with superior computational abilities are constrained since they need to maintain the same fine-tuning architecture as the weaker clients. To address these issues, we propose a novel Personalized Federated Instruction Tuning (PerFIT) framework based on architecture search. Specifically, PerFIT allows each client to search for a personalized architecture by expanding the trainable parameter space of the global model followed by pruning the parameters to the original state. This procedure allows personalized instruction fine-tuning within expanded",
    "link": "https://arxiv.org/abs/2402.16919",
    "context": "Title: Personalized Federated Instruction Tuning via Neural Architecture Search\nAbstract: arXiv:2402.16919v1 Announce Type: new  Abstract: Federated Instruction Tuning (FIT) has shown the ability to achieve collaborative model instruction tuning among massive data owners without sharing private data. However, it still faces two key challenges, i.e., data and resource heterogeneity. Due to the varying data distribution and preferences among data owners, FIT cannot adapt to the personalized data of individual owners. Moreover, clients with superior computational abilities are constrained since they need to maintain the same fine-tuning architecture as the weaker clients. To address these issues, we propose a novel Personalized Federated Instruction Tuning (PerFIT) framework based on architecture search. Specifically, PerFIT allows each client to search for a personalized architecture by expanding the trainable parameter space of the global model followed by pruning the parameters to the original state. This procedure allows personalized instruction fine-tuning within expanded",
    "path": "papers/24/02/2402.16919.json",
    "total_tokens": 880,
    "translated_title": "通过神经结构搜索实现个性化的联邦指令调优",
    "translated_abstract": "Federated Instruction Tuning (FIT)已经表明在不共享私人数据的情况下，能够实现庞大数据所有者之间的协作模型指令调优能力。然而，它仍然面临两个关键挑战，即数据和资源的异质性。由于数据所有者之间的数据分布和偏好各不相同，FIT无法适应个人所有者的个性化数据。此外，具有优越计算能力的客户端受到限制，因为它们需要保持与较弱客户端相同的微调架构。为了解决这些问题，我们提出了一种基于体系结构搜索的新型个性化联邦指令调优（PerFIT）框架。具体而言，PerFIT允许每个客户端通过扩展全局模型的可训练参数空间来搜索个性化体系结构，然后将参数修剪到原始状态。该过程允许在扩展的情况下进行个性化指令微调。",
    "tldr": "提出了一种基于体系结构搜索的新型个性化联邦指令调优（PerFIT）框架，允许每个客户端通过扩展全局模型的可训练参数空间来搜索个性化体系结构，解决了FIT面临的数据和资源异质性问题。",
    "en_tdlr": "Proposed a novel Personalized Federated Instruction Tuning (PerFIT) framework based on architecture search, allowing each client to search for a personalized architecture by expanding the trainable parameter space of the global model, addressing the data and resource heterogeneity challenges faced by FIT."
}