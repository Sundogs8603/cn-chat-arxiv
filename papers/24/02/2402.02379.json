{
    "title": "Rethinking the Evaluation of Pre-trained Text-and-Layout Models from an Entity-Centric Perspective",
    "abstract": "Recently developed pre-trained text-and-layout models (PTLMs) have shown remarkable success in multiple information extraction tasks on visually-rich documents. However, the prevailing evaluation pipeline may not be sufficiently robust for assessing the information extraction ability of PTLMs, due to inadequate annotations within the benchmarks. Therefore, we claim the necessary standards for an ideal benchmark to evaluate the information extraction ability of PTLMs. We then introduce EC-FUNSD, an entity-centric benckmark designed for the evaluation of semantic entity recognition and entity linking on visually-rich documents. This dataset contains diverse formats of document layouts and annotations of semantic-driven entities and their relations. Moreover, this dataset disentangles the falsely coupled annotation of segment and entity that arises from the block-level annotation of FUNSD. Experiment results demonstrate that state-of-the-art PTLMs exhibit overfitting tendencies on the pre",
    "link": "https://arxiv.org/abs/2402.02379",
    "context": "Title: Rethinking the Evaluation of Pre-trained Text-and-Layout Models from an Entity-Centric Perspective\nAbstract: Recently developed pre-trained text-and-layout models (PTLMs) have shown remarkable success in multiple information extraction tasks on visually-rich documents. However, the prevailing evaluation pipeline may not be sufficiently robust for assessing the information extraction ability of PTLMs, due to inadequate annotations within the benchmarks. Therefore, we claim the necessary standards for an ideal benchmark to evaluate the information extraction ability of PTLMs. We then introduce EC-FUNSD, an entity-centric benckmark designed for the evaluation of semantic entity recognition and entity linking on visually-rich documents. This dataset contains diverse formats of document layouts and annotations of semantic-driven entities and their relations. Moreover, this dataset disentangles the falsely coupled annotation of segment and entity that arises from the block-level annotation of FUNSD. Experiment results demonstrate that state-of-the-art PTLMs exhibit overfitting tendencies on the pre",
    "path": "papers/24/02/2402.02379.json",
    "total_tokens": 926,
    "translated_title": "从实体中心的角度重新思考对预训练的文本和布局模型的评估",
    "translated_abstract": "最近开发的预训练的文本和布局模型（PTLMs）在视觉丰富的文档上的多个信息提取任务中取得了显著的成功。然而，由于基准数据中的注释不足，目前的评估流程可能不够稳健，无法充分评估PTLMs的信息提取能力。因此，我们提出了评估PTLMs信息提取能力的理想基准的必要标准。我们还介绍了EC-FUNSD，这是一个针对视觉丰富文档上语义实体识别和实体链接评估而设计的以实体为中心的基准数据集。该数据集包含不同格式的文档布局和语义驱动实体及其关系的注释。此外，该数据集还解开了由FUNSD的分段级注释带来的段落和实体错误耦合的问题。实验结果表明，最先进的PTLMs在预训练阶段存在过拟合的倾向。",
    "tldr": "本论文从实体中心的角度重新思考了对预训练的文本和布局模型的评估。提出了评估PTLMs信息提取能力的理想基准的标准，并介绍了针对该评估的EC-FUNSD数据集。实验结果表明，最先进的PTLMs在预训练阶段存在过拟合的倾向。"
}