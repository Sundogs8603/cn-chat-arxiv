{
    "title": "Improving Explainable Object-induced Model through Uncertainty for Automated Vehicles",
    "abstract": "arXiv:2402.15572v1 Announce Type: new  Abstract: The rapid evolution of automated vehicles (AVs) has the potential to provide safer, more efficient, and comfortable travel options. However, these systems face challenges regarding reliability in complex driving scenarios. Recent explainable AV architectures neglect crucial information related to inherent uncertainties while providing explanations for actions. To overcome such challenges, our study builds upon the \"object-induced\" model approach that prioritizes the role of objects in scenes for decision-making and integrates uncertainty assessment into the decision-making process using an evidential deep learning paradigm with a Beta prior. Additionally, we explore several advanced training strategies guided by uncertainty, including uncertainty-guided data reweighting and augmentation. Leveraging the BDD-OIA dataset, our findings underscore that the model, through these enhancements, not only offers a clearer comprehension of AV decisi",
    "link": "https://arxiv.org/abs/2402.15572",
    "context": "Title: Improving Explainable Object-induced Model through Uncertainty for Automated Vehicles\nAbstract: arXiv:2402.15572v1 Announce Type: new  Abstract: The rapid evolution of automated vehicles (AVs) has the potential to provide safer, more efficient, and comfortable travel options. However, these systems face challenges regarding reliability in complex driving scenarios. Recent explainable AV architectures neglect crucial information related to inherent uncertainties while providing explanations for actions. To overcome such challenges, our study builds upon the \"object-induced\" model approach that prioritizes the role of objects in scenes for decision-making and integrates uncertainty assessment into the decision-making process using an evidential deep learning paradigm with a Beta prior. Additionally, we explore several advanced training strategies guided by uncertainty, including uncertainty-guided data reweighting and augmentation. Leveraging the BDD-OIA dataset, our findings underscore that the model, through these enhancements, not only offers a clearer comprehension of AV decisi",
    "path": "papers/24/02/2402.15572.json",
    "total_tokens": 887,
    "translated_title": "通过不确定性改进可解释的物体诱导模型，以提高自动驾驶车辆的性能",
    "translated_abstract": "自动驾驶车辆（AV）的快速发展有望提供更安全、更高效和更舒适的出行选择。然而，这些系统在复杂驾驶场景中面临可靠性挑战。最近的可解释AV架构在提供动作解释时忽略了与内在不确定性相关的关键信息。为了克服这些挑战，我们的研究基于“物体诱导”模型方法，该方法强调场景中物体在决策中的作用，并使用具有Beta先验的证据深度学习范式将不确定性评估整合到决策过程中。此外，我们探讨了几种受不确定性引导的先进训练策略，包括受不确定性引导的数据重新加权和增强。通过利用BDD-OIA数据集，我们的研究结果强调，通过这些增强措施，该模型不仅提供了对AV决策更清晰的理解",
    "tldr": "本研究通过将不确定性评估整合到决策过程中，基于“物体诱导”模型方法并利用先进训练策略，改进了可解释的AV模型，在复杂驾驶场景中提供更清晰的决策理解",
    "en_tdlr": "This study improves the explainable AV model by integrating uncertainty assessment into the decision-making process, based on the \"object-induced\" model approach and advanced training strategies, offering a clearer understanding of decisions in complex driving scenarios."
}