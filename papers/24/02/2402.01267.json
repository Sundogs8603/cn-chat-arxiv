{
    "title": "The Human and the Mechanical: logos, truthfulness, and ChatGPT",
    "abstract": "The paper addresses the question of whether it is appropriate to talk about `mechanical minds' at all, and whether ChatGPT models can indeed be thought of as realizations of that. Our paper adds a semantic argument to the current debate. The act of human assertion requires the formation of a veridicality judgment. Modification of assertions with modals (John must be at home) and the use of subjective elements (John is obviously at home) indicate that the speaker is manipulating her judgments and, in a cooperative context, intends her epistemic state to be transparent to the addressee. Veridicality judgments are formed on the basis of two components: (i) evidence that relates to reality (exogenous evidence) and (ii) endogenous evidence, such as preferences and private beliefs. `Mechanical minds' lack these two components: (i) they do not relate to reality and (ii) do not have endogenous evidence. Therefore they lack the ability to form a belief about the world and a veridicality judgmen",
    "link": "https://rss.arxiv.org/abs/2402.01267",
    "context": "Title: The Human and the Mechanical: logos, truthfulness, and ChatGPT\nAbstract: The paper addresses the question of whether it is appropriate to talk about `mechanical minds' at all, and whether ChatGPT models can indeed be thought of as realizations of that. Our paper adds a semantic argument to the current debate. The act of human assertion requires the formation of a veridicality judgment. Modification of assertions with modals (John must be at home) and the use of subjective elements (John is obviously at home) indicate that the speaker is manipulating her judgments and, in a cooperative context, intends her epistemic state to be transparent to the addressee. Veridicality judgments are formed on the basis of two components: (i) evidence that relates to reality (exogenous evidence) and (ii) endogenous evidence, such as preferences and private beliefs. `Mechanical minds' lack these two components: (i) they do not relate to reality and (ii) do not have endogenous evidence. Therefore they lack the ability to form a belief about the world and a veridicality judgmen",
    "path": "papers/24/02/2402.01267.json",
    "total_tokens": 934,
    "translated_title": "人类与机器：逻辑、真实性与ChatGPT",
    "translated_abstract": "本论文探讨了是否适当地谈论“机械思维”，以及ChatGPT模型是否可以被视为实现了这一点。我们的论文在当前的讨论中添加了一个语义论证。人类断言的行为需要形成一个真实性判断。使用情态动词修饰断言（约翰一定在家）和使用主观元素（约翰明显在家）表明说话者正在操纵她的判断，在合作的语境中，意图将她的认知状态对话方透明化。真实性判断是基于两个组成部分形成的：（i）与现实相关的证据（外生证据）和（ii）与偏好和个人信念相关的内在证据。而“机械思维”缺乏这两个组成部分：（i）它们与现实无关，（ii）没有内在证据。因此它们缺乏对世界的信念形成和真实性判断的能力。",
    "tldr": "本论文通过语义论证，讨论了是否可以称之为“机械思维”，以及ChatGPT模型能否实现该思维。研究发现，“机械思维”缺乏与现实相关的证据和个人信念，因此无法形成对世界的信念和真实性判断。",
    "en_tdlr": "This paper presents a semantic argument on whether it is appropriate to refer to \"mechanical minds\" and if ChatGPT models can achieve that. The study reveals that \"mechanical minds\" lack the evidence related to reality and personal beliefs needed for forming beliefs about the world and making veridicality judgments."
}