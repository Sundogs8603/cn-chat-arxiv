{
    "title": "Stable Knowledge Editing in Large Language Models",
    "abstract": "arXiv:2402.13048v1 Announce Type: new  Abstract: Efficient knowledge editing of large language models is crucial for replacing obsolete information or incorporating specialized knowledge on a large scale. However, previous methods implicitly assume that knowledge is localized and isolated within the model, an assumption that oversimplifies the interconnected nature of model knowledge. The premise of localization results in an incomplete knowledge editing, whereas an isolated assumption may impair both other knowledge and general abilities. It introduces instability to the performance of the knowledge editing method. To transcend these assumptions, we introduce StableKE, a method adopts a novel perspective based on knowledge augmentation rather than knowledge localization. To overcome the expense of human labeling, StableKE integrates two automated knowledge augmentation strategies: Semantic Paraphrase Enhancement strategy, which diversifies knowledge descriptions to facilitate the teac",
    "link": "https://arxiv.org/abs/2402.13048",
    "context": "Title: Stable Knowledge Editing in Large Language Models\nAbstract: arXiv:2402.13048v1 Announce Type: new  Abstract: Efficient knowledge editing of large language models is crucial for replacing obsolete information or incorporating specialized knowledge on a large scale. However, previous methods implicitly assume that knowledge is localized and isolated within the model, an assumption that oversimplifies the interconnected nature of model knowledge. The premise of localization results in an incomplete knowledge editing, whereas an isolated assumption may impair both other knowledge and general abilities. It introduces instability to the performance of the knowledge editing method. To transcend these assumptions, we introduce StableKE, a method adopts a novel perspective based on knowledge augmentation rather than knowledge localization. To overcome the expense of human labeling, StableKE integrates two automated knowledge augmentation strategies: Semantic Paraphrase Enhancement strategy, which diversifies knowledge descriptions to facilitate the teac",
    "path": "papers/24/02/2402.13048.json",
    "total_tokens": 771,
    "translated_title": "大型语言模型中的稳定知识编辑",
    "translated_abstract": "大规模语言模型的高效知识编辑对于替换过时信息或大规模整合专业知识至关重要。然而，先前的方法隐式地假设知识在模型内是局部化且孤立的，这种假设过于简化了模型知识的相互关联性。局部化的前提导致知识编辑不完整，而孤立的假设可能损害其他知识和一般能力。这会给知识编辑方法的性能引入不稳定性。为超越这些假设，我们引入了StableKE，一种基于知识增强而非知识本地化的全新视角方法。为克服人工标注的成本，StableKE整合了两种自动知识增强策略：语义改写增强策略，这种策略通过多样化知识描述来促进教",
    "tldr": "提出了一种名为StableKE的方法，采用了基于知识增强而非知识本地化的新视角，以实现大规模语言模型中的稳定知识编辑。",
    "en_tdlr": "Introducing StableKE, a method that takes a new perspective based on knowledge augmentation rather than knowledge localization for stable knowledge editing in large language models."
}