{
    "title": "Quantifying neural network uncertainty under volatility clustering",
    "abstract": "arXiv:2402.14476v1 Announce Type: new  Abstract: Time-series with time-varying variance pose a unique challenge to uncertainty quantification (UQ) methods. Time-varying variance, such as volatility clustering as seen in financial time-series, can lead to large mismatch between predicted uncertainty and forecast error. Building on recent advances in neural network UQ literature, we extend and simplify Deep Evidential Regression and Deep Ensembles into a unified framework to deal with UQ under the presence of volatility clustering. We show that a Scale Mixture Distribution is a simpler alternative to the Normal-Inverse-Gamma prior that provides favorable complexity-accuracy trade-off. To illustrate the performance of our proposed approach, we apply it to two sets of financial time-series exhibiting volatility clustering: cryptocurrencies and U.S. equities.",
    "link": "https://arxiv.org/abs/2402.14476",
    "context": "Title: Quantifying neural network uncertainty under volatility clustering\nAbstract: arXiv:2402.14476v1 Announce Type: new  Abstract: Time-series with time-varying variance pose a unique challenge to uncertainty quantification (UQ) methods. Time-varying variance, such as volatility clustering as seen in financial time-series, can lead to large mismatch between predicted uncertainty and forecast error. Building on recent advances in neural network UQ literature, we extend and simplify Deep Evidential Regression and Deep Ensembles into a unified framework to deal with UQ under the presence of volatility clustering. We show that a Scale Mixture Distribution is a simpler alternative to the Normal-Inverse-Gamma prior that provides favorable complexity-accuracy trade-off. To illustrate the performance of our proposed approach, we apply it to two sets of financial time-series exhibiting volatility clustering: cryptocurrencies and U.S. equities.",
    "path": "papers/24/02/2402.14476.json",
    "total_tokens": 851,
    "translated_title": "在波动性聚类下量化神经网络不确定性",
    "translated_abstract": "时间序列具有时变方差，给不确定性量化（UQ）方法带来了独特挑战。时间变化的方差，例如在金融时间序列中看到的波动性聚类，会导致预测不确定性与预测误差之间出现较大的不匹配。借鉴神经网络不确定性量化文献的最新进展，我们将深度证据回归和深度集成扩展和简化为一个统一框架，以处理在波动性聚类存在时的UQ。我们展示了规模混合分布是正态逆伽马先验的一个更简单的替代方案，提供了有利的复杂度-准确度权衡。为了说明我们提出的方法的性能，我们将其应用于展示波动性聚类的两组金融时间序列：加密货币和美国股票。",
    "tldr": "通过将深度证据回归和深度集成扩展和简化为一个统一框架，我们提出了一个新方法来量化神经网络在波动性聚类下的不确定性，证明了规模混合分布是一个更简单的且具有良好复杂度-准确度权衡的替代方案。",
    "en_tdlr": "By extending and simplifying Deep Evidential Regression and Deep Ensembles into a unified framework, we propose a new approach to quantify neural network uncertainty under volatility clustering, demonstrating that a Scale Mixture Distribution is a simpler alternative with favorable complexity-accuracy trade-off."
}