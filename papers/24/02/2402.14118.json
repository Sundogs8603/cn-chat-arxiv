{
    "title": "Masked Matrix Multiplication for Emergent Sparsity",
    "abstract": "arXiv:2402.14118v1 Announce Type: cross  Abstract: Artificial intelligence workloads, especially transformer models, exhibit emergent sparsity in which computations perform selective sparse access to dense data. The workloads are inefficient on hardware designed for dense computations and do not map well onto sparse data representations. We build a vectorized and parallel matrix-multiplication system A X B = C that eliminates unnecessary computations and avoids branches based on a runtime evaluation of sparsity. We use a combination of dynamic code lookup to adapt to the specific sparsity encoded in the B matrix and preprocessing of sparsity maps of the A and B matrices to compute conditional branches once for the whole computation. For a wide range of sparsity, from 60% to 95% zeros, our implementation performs fewer instructions and increases performance when compared with Intel MKL's dense or sparse matrix multiply routines. Benefits can be as large as 2 times speedup and 4 times fe",
    "link": "https://arxiv.org/abs/2402.14118",
    "context": "Title: Masked Matrix Multiplication for Emergent Sparsity\nAbstract: arXiv:2402.14118v1 Announce Type: cross  Abstract: Artificial intelligence workloads, especially transformer models, exhibit emergent sparsity in which computations perform selective sparse access to dense data. The workloads are inefficient on hardware designed for dense computations and do not map well onto sparse data representations. We build a vectorized and parallel matrix-multiplication system A X B = C that eliminates unnecessary computations and avoids branches based on a runtime evaluation of sparsity. We use a combination of dynamic code lookup to adapt to the specific sparsity encoded in the B matrix and preprocessing of sparsity maps of the A and B matrices to compute conditional branches once for the whole computation. For a wide range of sparsity, from 60% to 95% zeros, our implementation performs fewer instructions and increases performance when compared with Intel MKL's dense or sparse matrix multiply routines. Benefits can be as large as 2 times speedup and 4 times fe",
    "path": "papers/24/02/2402.14118.json",
    "total_tokens": 887,
    "translated_title": "用于紧急稀疏性的掩码矩阵乘法",
    "translated_abstract": "人工智能工作负载，特别是变压器模型，表现出紧急稀疏性，在其中计算对稠密数据进行选择性稀疏访问。这些工作负载在为稠密计算设计的硬件上效率低下，并且无法很好地映射到稀疏数据表示上。我们构建了一个矩阵乘法系统 A X B = C，该系统通过对稀疏度的运行时评估消除了不必要的计算并避免了分支。我们使用动态代码查找和预处理 A 和 B 矩阵的稀疏图，来适应 B 矩阵中编码的具体稀疏性，并为整个计算仅计算一次条件分支。在从60%到95%的广泛稀疏度范围内，与英特尔MKL的稠密或稀疏矩阵乘法例程相比，我们的实现执行的指令更少并提高了性能。效果可以达到2倍加速和4倍费用。",
    "tldr": "提出了一种用于紧急稀疏性的掩码矩阵乘法系统，可以通过运行时评估稀疏度来消除不必要的计算和避免分支，实现了较低指令数和更高性能。",
    "en_tdlr": "A masked matrix multiplication system for emergent sparsity is proposed, which eliminates unnecessary computations and avoids branches based on a runtime evaluation of sparsity, achieving fewer instructions and higher performance."
}