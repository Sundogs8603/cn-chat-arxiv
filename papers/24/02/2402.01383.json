{
    "title": "LLM-based NLG Evaluation: Current Status and Challenges",
    "abstract": "Evaluating natural language generation (NLG) is a vital but challenging problem in artificial intelligence. Traditional evaluation metrics mainly capturing content (e.g. n-gram) overlap between system outputs and references are far from satisfactory, and large language models (LLMs) such as ChatGPT have demonstrated great potential in NLG evaluation in recent years. Various automatic evaluation methods based on LLMs have been proposed, including metrics derived from LLMs, prompting LLMs, and fine-tuning LLMs with labeled evaluation data. In this survey, we first give a taxonomy of LLM-based NLG evaluation methods, and discuss their pros and cons, respectively. We also discuss human-LLM collaboration for NLG evaluation. Lastly, we discuss several open problems in this area and point out future research directions.",
    "link": "https://rss.arxiv.org/abs/2402.01383",
    "context": "Title: LLM-based NLG Evaluation: Current Status and Challenges\nAbstract: Evaluating natural language generation (NLG) is a vital but challenging problem in artificial intelligence. Traditional evaluation metrics mainly capturing content (e.g. n-gram) overlap between system outputs and references are far from satisfactory, and large language models (LLMs) such as ChatGPT have demonstrated great potential in NLG evaluation in recent years. Various automatic evaluation methods based on LLMs have been proposed, including metrics derived from LLMs, prompting LLMs, and fine-tuning LLMs with labeled evaluation data. In this survey, we first give a taxonomy of LLM-based NLG evaluation methods, and discuss their pros and cons, respectively. We also discuss human-LLM collaboration for NLG evaluation. Lastly, we discuss several open problems in this area and point out future research directions.",
    "path": "papers/24/02/2402.01383.json",
    "total_tokens": 919,
    "translated_title": "基于LLM的自然语言生成评估：现状与挑战",
    "translated_abstract": "在人工智能领域，评估自然语言生成（NLG）是一个至关重要但挑战重重的问题。传统的评估指标主要通过系统输出和参考文本之间的内容（如n-gram）重叠度来捕捉，远远不够令人满意，而近年来，大型语言模型（LLM）如ChatGPT在NLG评估方面展现出巨大潜力。已经提出了基于LLM的各种自动评估方法，包括基于LLM导出的指标、引导LLM和使用带有标记评估数据的LLM微调。在这项调研中，我们首先给出了基于LLM的NLG评估方法的分类法，并分别讨论了它们的优势和劣势。我们还讨论了人类与LLM的合作用于NLG评估。最后，我们讨论了该领域中的几个待解决的问题，并指出了未来的研究方向。",
    "tldr": "这项调研介绍了基于大型语言模型（LLM）的自然语言生成（NLG）评估方法的现状，包括基于LLM导出的指标、引导LLM和使用带有标记评估数据的LLM微调，并讨论了人类与LLM的合作。同时指出了该领域的一些挑战和未来研究方向。",
    "en_tdlr": "This survey presents the current status of evaluation methods for natural language generation (NLG) based on large language models (LLMs), including metrics derived from LLMs, prompting LLMs, and fine-tuning LLMs with labeled evaluation data. Collaboration between humans and LLMs for NLG evaluation is also discussed. Several challenges and future research directions in this area are highlighted."
}