{
    "title": "Boosting Neural Representations for Videos with a Conditional Decoder",
    "abstract": "arXiv:2402.18152v1 Announce Type: cross  Abstract: Implicit neural representations (INRs) have emerged as a promising approach for video storage and processing, showing remarkable versatility across various video tasks. However, existing methods often fail to fully leverage their representation capabilities, primarily due to inadequate alignment of intermediate features during target frame decoding. This paper introduces a universal boosting framework for current implicit video representation approaches. Specifically, we utilize a conditional decoder with a temporal-aware affine transform module, which uses the frame index as a prior condition to effectively align intermediate features with target frames. Besides, we introduce a sinusoidal NeRV-like block to generate diverse intermediate features and achieve a more balanced parameter distribution, thereby enhancing the model's capacity. With a high-frequency information-preserving reconstruction loss, our approach successfully boosts m",
    "link": "https://arxiv.org/abs/2402.18152",
    "context": "Title: Boosting Neural Representations for Videos with a Conditional Decoder\nAbstract: arXiv:2402.18152v1 Announce Type: cross  Abstract: Implicit neural representations (INRs) have emerged as a promising approach for video storage and processing, showing remarkable versatility across various video tasks. However, existing methods often fail to fully leverage their representation capabilities, primarily due to inadequate alignment of intermediate features during target frame decoding. This paper introduces a universal boosting framework for current implicit video representation approaches. Specifically, we utilize a conditional decoder with a temporal-aware affine transform module, which uses the frame index as a prior condition to effectively align intermediate features with target frames. Besides, we introduce a sinusoidal NeRV-like block to generate diverse intermediate features and achieve a more balanced parameter distribution, thereby enhancing the model's capacity. With a high-frequency information-preserving reconstruction loss, our approach successfully boosts m",
    "path": "papers/24/02/2402.18152.json",
    "total_tokens": 748,
    "translated_title": "使用条件解码器增强视频的神经表示",
    "translated_abstract": "隐式神经表示（INRs）已经成为视频存储和处理的一种有前途的方法，在各种视频任务中展现出显著的多功能性。然而，由于目标帧解码过程中中间特征的不足对齐，现有方法往往未能充分利用其表示能力。本文引入了一个通用的增强框架来加强当前的隐式视频表示方法。具体来说，我们利用具有时间感知仿射变换模块的条件解码器，该模块使用帧索引作为先验条件，有效地将中间特征与目标帧对齐。此外，我们引入了一个正弦NeRV-like模块来生成多样化的中间特征，并实现更平衡的参数分布，从而增强了模型的容量。借助高频信息保留的重构损失，我们的方法成功地增强了m",
    "tldr": "引入条件解码器和NeRV-like模块的增强框架，以提高隐式视频表示方法的效果。",
    "en_tdlr": "Introducing a boosting framework with a conditional decoder and NeRV-like block to enhance implicit video representation methods."
}