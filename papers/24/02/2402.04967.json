{
    "title": "Text or Image? What is More Important in Cross-Domain Generalization Capabilities of Hate Meme Detection Models?",
    "abstract": "This paper delves into the formidable challenge of cross-domain generalization in multimodal hate meme detection, presenting compelling findings. We provide enough pieces of evidence supporting the hypothesis that only the textual component of hateful memes enables the existing multimodal classifier to generalize across different domains, while the image component proves highly sensitive to a specific training dataset. The evidence includes demonstrations showing that hate-text classifiers perform similarly to hate-meme classifiers in a zero-shot setting. Simultaneously, the introduction of captions generated from images of memes to the hate-meme classifier worsens performance by an average F1 of 0.02. Through blackbox explanations, we identify a substantial contribution of the text modality (average of 83%), which diminishes with the introduction of meme's image captions (52%). Additionally, our evaluation on a newly created confounder dataset reveals higher performance on text confou",
    "link": "https://arxiv.org/abs/2402.04967",
    "context": "Title: Text or Image? What is More Important in Cross-Domain Generalization Capabilities of Hate Meme Detection Models?\nAbstract: This paper delves into the formidable challenge of cross-domain generalization in multimodal hate meme detection, presenting compelling findings. We provide enough pieces of evidence supporting the hypothesis that only the textual component of hateful memes enables the existing multimodal classifier to generalize across different domains, while the image component proves highly sensitive to a specific training dataset. The evidence includes demonstrations showing that hate-text classifiers perform similarly to hate-meme classifiers in a zero-shot setting. Simultaneously, the introduction of captions generated from images of memes to the hate-meme classifier worsens performance by an average F1 of 0.02. Through blackbox explanations, we identify a substantial contribution of the text modality (average of 83%), which diminishes with the introduction of meme's image captions (52%). Additionally, our evaluation on a newly created confounder dataset reveals higher performance on text confou",
    "path": "papers/24/02/2402.04967.json",
    "total_tokens": 1097,
    "translated_title": "文本还是图像？对于跨领域泛化能力的仇恨迷因检测模型来说，什么更重要？",
    "translated_abstract": "本文深入探讨了多模式仇恨迷因检测中跨领域泛化的挑战，并提出了引人注目的研究结果。我们提供了足够的证据支持假设：只有仇恨迷因中的文本成分使得现有的多模式分类器能够在不同领域中进行泛化，而图像成分则对特定训练数据集非常敏感。证据包括演示，证明在零样本情况下，仇恨文本分类器的表现与仇恨迷因分类器相似。同时，将由迷因图像生成的标题引入到仇恨迷因分类器中，导致性能下降平均F1指标约为0.02。通过黑盒解释，我们确定了文本模态的重要贡献（平均83%），但引入迷因图像标题后贡献降低至52%。此外，我们还在新创建的混淆数据集上进行了评估，显示文本混淆因素的表现较好。",
    "tldr": "本文研究了多模式仇恨迷因检测中的跨领域泛化挑战，并发现仇恨迷因的文本部分对于泛化至不同领域的分类器至关重要，而图像部分对特定训练数据集敏感。实验证明仇恨文本分类器在零样本情况下表现类似于仇恨迷因分类器。黑盒解释表明文本模态对模型性能的贡献较大，但引入图像标题后贡献降低。新的混淆数据集评估显示文本混淆因素表现较好。",
    "en_tdlr": "This paper investigates the challenge of cross-domain generalization in multimodal hate meme detection and finds that the textual component of hate memes is crucial for the generalization of classifiers across different domains, while the image component is sensitive to specific training datasets. Experimental results show that hate-text classifiers perform similarly to hate-meme classifiers in a zero-shot setting. Blackbox explanations reveal that the text modality contributes significantly to the model's performance, but this contribution diminishes with the introduction of image captions. Evaluation on a newly created confounder dataset demonstrates better performance on text confounders."
}