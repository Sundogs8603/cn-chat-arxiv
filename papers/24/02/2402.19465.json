{
    "title": "Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models",
    "abstract": "arXiv:2402.19465v1 Announce Type: cross  Abstract: Ensuring the trustworthiness of large language models (LLMs) is crucial. Most studies concentrate on fully pre-trained LLMs to better understand and improve LLMs' trustworthiness. In this paper, to reveal the untapped potential of pre-training, we pioneer the exploration of LLMs' trustworthiness during this period, focusing on five key dimensions: reliability, privacy, toxicity, fairness, and robustness. To begin with, we apply linear probing to LLMs. The high probing accuracy suggests that \\textit{LLMs in early pre-training can already distinguish concepts in each trustworthiness dimension}. Therefore, to further uncover the hidden possibilities of pre-training, we extract steering vectors from a LLM's pre-training checkpoints to enhance the LLM's trustworthiness. Finally, inspired by~\\citet{choi2023understanding} that mutual information estimation is bounded by linear probing accuracy, we also probe LLMs with mutual information to in",
    "link": "https://arxiv.org/abs/2402.19465",
    "context": "Title: Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models\nAbstract: arXiv:2402.19465v1 Announce Type: cross  Abstract: Ensuring the trustworthiness of large language models (LLMs) is crucial. Most studies concentrate on fully pre-trained LLMs to better understand and improve LLMs' trustworthiness. In this paper, to reveal the untapped potential of pre-training, we pioneer the exploration of LLMs' trustworthiness during this period, focusing on five key dimensions: reliability, privacy, toxicity, fairness, and robustness. To begin with, we apply linear probing to LLMs. The high probing accuracy suggests that \\textit{LLMs in early pre-training can already distinguish concepts in each trustworthiness dimension}. Therefore, to further uncover the hidden possibilities of pre-training, we extract steering vectors from a LLM's pre-training checkpoints to enhance the LLM's trustworthiness. Finally, inspired by~\\citet{choi2023understanding} that mutual information estimation is bounded by linear probing accuracy, we also probe LLMs with mutual information to in",
    "path": "papers/24/02/2402.19465.json",
    "total_tokens": 970,
    "translated_title": "追踪可信度动态：重访大型语言模型的预训练期",
    "translated_abstract": "确保大型语言模型（LLMs）的可信度至关重要。大多数研究集中在充分预训练的LLMs上，以更好地理解和提高LLMs的可信度。本文旨在揭示预训练的潜力，首次探索了LLMs在此期间的可信度，专注于五个关键维度：可靠性、隐私、有害度、公平性和稳健性。我们首先对LLMs应用线性探测。高探测准确度表明，\\textit{早期预训练的LLMs已经能够区分每个可信度维度中的概念}。因此，为了进一步揭示预训练的潜在可能性，我们从LLM的预训练检查点中提取转向向量，以增强LLM的可信度。最后，受到~\\citet{choi2023understanding} 的启发，相互信息估计受线性探测准确度的限制，我们还用相互信息探测LLMs来探究",
    "tldr": "本文研究探索了大型语言模型在预训练期间的可信度，揭示了早期预训练LLMs已经能够区分各个可信度维度中的概念，提出了从预训练检查点中提取转向向量以增强LLM可信度的方法。"
}