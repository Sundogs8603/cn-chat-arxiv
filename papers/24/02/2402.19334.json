{
    "title": "Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge",
    "abstract": "arXiv:2402.19334v1 Announce Type: new  Abstract: The democratization of pre-trained language models through open-source initiatives has rapidly advanced innovation and expanded access to cutting-edge technologies. However, this openness also brings significant security risks, including backdoor attacks, where hidden malicious behaviors are triggered by specific inputs, compromising natural language processing (NLP) system integrity and reliability. This paper suggests that merging a backdoored model with other homogeneous models can remediate backdoor vulnerabilities even if such models are not entirely secure. In our experiments, we explore various models (BERT-Base, RoBERTa-Large, Llama2-7B, and Mistral-7B) and datasets (SST-2, OLID, AG News, and QNLI). Compared to multiple advanced defensive approaches, our method offers an effective and efficient inference-stage defense against backdoor attacks without additional resources or specific knowledge. Our approach consistently outperform",
    "link": "https://arxiv.org/abs/2402.19334",
    "context": "Title: Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge\nAbstract: arXiv:2402.19334v1 Announce Type: new  Abstract: The democratization of pre-trained language models through open-source initiatives has rapidly advanced innovation and expanded access to cutting-edge technologies. However, this openness also brings significant security risks, including backdoor attacks, where hidden malicious behaviors are triggered by specific inputs, compromising natural language processing (NLP) system integrity and reliability. This paper suggests that merging a backdoored model with other homogeneous models can remediate backdoor vulnerabilities even if such models are not entirely secure. In our experiments, we explore various models (BERT-Base, RoBERTa-Large, Llama2-7B, and Mistral-7B) and datasets (SST-2, OLID, AG News, and QNLI). Compared to multiple advanced defensive approaches, our method offers an effective and efficient inference-stage defense against backdoor attacks without additional resources or specific knowledge. Our approach consistently outperform",
    "path": "papers/24/02/2402.19334.json",
    "total_tokens": 852,
    "translated_title": "这里有一个免费午餐：使用模型合并消毒带后门的模型",
    "translated_abstract": "通过开源倡议使预训练语言模型民主化快速推动了创新，并扩大了对尖端技术的访问。然而，这种开放性也带来了重大安全风险，包括后门攻击，其中隐藏的恶意行为由特定输入触发，损害自然语言处理（NLP）系统的完整性和可靠性。本文建议通过将带后门的模型与其他同类模型合并，可以治疗后门漏洞，即使这些模型并非全部安全。在我们的实验中，我们探索了各种模型（BERT-Base、RoBERTa-Large、Llama2-7B和Mistral-7B）和数据集（SST-2、OLID、AG News和QNLI）。与多种先进的防御方法相比，我们的方法提供了一种有效且高效的推理阶段对抗后门攻击的防御，而无需额外资源或特定知识。我们的方法始终表现优秀",
    "tldr": "将带后门的模型与其他同类模型合并可以有效治疗后门漏洞，为后门攻击提供推理阶段的有效和高效防御",
    "en_tdlr": "Merging backdoored models with other homogeneous models can effectively remediate backdoor vulnerabilities, offering an effective and efficient defense against backdoor attacks in the inference stage."
}