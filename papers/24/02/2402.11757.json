{
    "title": "Large Language Models for Stemming: Promises, Pitfalls and Failures",
    "abstract": "arXiv:2402.11757v1 Announce Type: cross  Abstract: Text stemming is a natural language processing technique that is used to reduce words to their base form, also known as the root form. The use of stemming in IR has been shown to often improve the effectiveness of keyword-matching models such as BM25. However, traditional stemming methods, focusing solely on individual terms, overlook the richness of contextual information. Recognizing this gap, in this paper, we investigate the promising idea of using large language models (LLMs) to stem words by leveraging its capability of context understanding. With this respect, we identify three avenues, each characterised by different trade-offs in terms of computational cost, effectiveness and robustness : (1) use LLMs to stem the vocabulary for a collection, i.e., the set of unique words that appear in the collection (vocabulary stemming), (2) use LLMs to stem each document separately (contextual stemming), and (3) use LLMs to extract from eac",
    "link": "https://arxiv.org/abs/2402.11757",
    "context": "Title: Large Language Models for Stemming: Promises, Pitfalls and Failures\nAbstract: arXiv:2402.11757v1 Announce Type: cross  Abstract: Text stemming is a natural language processing technique that is used to reduce words to their base form, also known as the root form. The use of stemming in IR has been shown to often improve the effectiveness of keyword-matching models such as BM25. However, traditional stemming methods, focusing solely on individual terms, overlook the richness of contextual information. Recognizing this gap, in this paper, we investigate the promising idea of using large language models (LLMs) to stem words by leveraging its capability of context understanding. With this respect, we identify three avenues, each characterised by different trade-offs in terms of computational cost, effectiveness and robustness : (1) use LLMs to stem the vocabulary for a collection, i.e., the set of unique words that appear in the collection (vocabulary stemming), (2) use LLMs to stem each document separately (contextual stemming), and (3) use LLMs to extract from eac",
    "path": "papers/24/02/2402.11757.json",
    "total_tokens": 826,
    "translated_title": "大型语言模型用于词干提取：承诺、风险和失败",
    "translated_abstract": "文本词干提取是一种自然语言处理技术，用于将单词缩减为其基本形式，也称为根形式。传统的词干提取方法仅关注单个术语，忽视了上下文信息的丰富性。因此，在本文中，我们研究了利用大型语言模型（LLMs）通过利用其上下文理解能力来提取词干的有前途的想法。在这方面，我们确定了三种不同的权衡方案：（1）使用LLMs对集合的词汇进行提取，即出现在集合中的唯一单词集合（词汇提取），（2）将LLMs用于单独词根提取 (上下文提取)，(3) 使用LLMs从每个文档中提取",
    "tldr": "本文研究了使用大型语言模型来进行词干提取的有前途的想法，提出了三种不同的方法，每种方法在计算成本、有效性和稳健性方面具有不同的权衡。",
    "en_tdlr": "This paper investigates the promising idea of using large language models for stemming, proposing three different methods with trade-offs in computational cost, effectiveness, and robustness."
}