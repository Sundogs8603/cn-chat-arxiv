{
    "title": "Take the Bull by the Horns: Hard Sample-Reweighted Continual Training Improves LLM Generalization",
    "abstract": "arXiv:2402.14270v1 Announce Type: new  Abstract: In the rapidly advancing arena of large language models (LLMs), a key challenge is to enhance their capabilities amid a looming shortage of high-quality training data. Our study starts from an empirical strategy for the light continual training of LLMs using their original pre-training data sets, with a specific focus on selective retention of samples that incur moderately high losses. These samples are deemed informative and beneficial for model refinement, contrasting with the highest-loss samples, which would be discarded due to their correlation with data noise and complexity. We then formalize this strategy into a principled framework of Instance-Reweighted Distributionally Robust Optimization (IR-DRO). IR-DRO is designed to dynamically prioritize the training focus on informative samples through an instance reweighting mechanism, streamlined by a closed-form solution for straightforward integration into established training protoco",
    "link": "https://arxiv.org/abs/2402.14270",
    "context": "Title: Take the Bull by the Horns: Hard Sample-Reweighted Continual Training Improves LLM Generalization\nAbstract: arXiv:2402.14270v1 Announce Type: new  Abstract: In the rapidly advancing arena of large language models (LLMs), a key challenge is to enhance their capabilities amid a looming shortage of high-quality training data. Our study starts from an empirical strategy for the light continual training of LLMs using their original pre-training data sets, with a specific focus on selective retention of samples that incur moderately high losses. These samples are deemed informative and beneficial for model refinement, contrasting with the highest-loss samples, which would be discarded due to their correlation with data noise and complexity. We then formalize this strategy into a principled framework of Instance-Reweighted Distributionally Robust Optimization (IR-DRO). IR-DRO is designed to dynamically prioritize the training focus on informative samples through an instance reweighting mechanism, streamlined by a closed-form solution for straightforward integration into established training protoco",
    "path": "papers/24/02/2402.14270.json",
    "total_tokens": 875,
    "translated_title": "牛头角：硬样本加权持续训练改善LLM泛化能力",
    "translated_abstract": "在大语言模型（LLMs）快速发展的领域中，一个关键挑战是在高质量训练数据短缺的情况下增强它们的能力。我们的研究从一个轻量级持续训练LLMs的经验策略开始，使用它们的原始预训练数据集，重点关注导致中等损失的样本的选择性保留。这些样本被认为是信息丰富的，并且有助于模型的改进，与最高损失的样本形成对比，后者将由于与数据噪声和复杂性的相关性而被丢弃。然后，我们将这一策略形式化为基于实例加权的分布鲁棒优化（IR-DRO）的原则框架。IR-DRO旨在通过实例重新加权机制动态优先考虑训练的重点样本，由一个封闭形式解决方案简化，以便轻松整合到已建立的训练协议中。",
    "tldr": "通过硬样本加权持续训练的方法，该研究提出了IR-DRO框架，通过动态优先考虑训练中信息丰富的样本，以改善LLM泛化能力。",
    "en_tdlr": "By hard sample reweighted continual training, the study introduces the IR-DRO framework to dynamically prioritize informative samples during training to enhance LLM generalization."
}