{
    "title": "INSTRUCTIR: A Benchmark for Instruction Following of Information Retrieval Models",
    "abstract": "arXiv:2402.14334v1 Announce Type: new  Abstract: Despite the critical need to align search targets with users' intention, retrievers often only prioritize query information without delving into the users' intended search context. Enhancing the capability of retrievers to understand intentions and preferences of users, akin to language model instructions, has the potential to yield more aligned search targets. Prior studies restrict the application of instructions in information retrieval to a task description format, neglecting the broader context of diverse and evolving search scenarios. Furthermore, the prevailing benchmarks utilized for evaluation lack explicit tailoring to assess instruction-following ability, thereby hindering progress in this field. In response to these limitations, we propose a novel benchmark,INSTRUCTIR, specifically designed to evaluate instruction-following ability in information retrieval tasks. Our approach focuses on user-aligned instructions tailored to e",
    "link": "https://arxiv.org/abs/2402.14334",
    "context": "Title: INSTRUCTIR: A Benchmark for Instruction Following of Information Retrieval Models\nAbstract: arXiv:2402.14334v1 Announce Type: new  Abstract: Despite the critical need to align search targets with users' intention, retrievers often only prioritize query information without delving into the users' intended search context. Enhancing the capability of retrievers to understand intentions and preferences of users, akin to language model instructions, has the potential to yield more aligned search targets. Prior studies restrict the application of instructions in information retrieval to a task description format, neglecting the broader context of diverse and evolving search scenarios. Furthermore, the prevailing benchmarks utilized for evaluation lack explicit tailoring to assess instruction-following ability, thereby hindering progress in this field. In response to these limitations, we propose a novel benchmark,INSTRUCTIR, specifically designed to evaluate instruction-following ability in information retrieval tasks. Our approach focuses on user-aligned instructions tailored to e",
    "path": "papers/24/02/2402.14334.json",
    "total_tokens": 774,
    "translated_title": "INSTRUCTIR：信息检索模型指令遵循的基准",
    "translated_abstract": "尽管将搜索目标与用户意图对齐的需求至关重要，但检索器通常只优先考虑查询信息，而不深入了解用户的预期搜索上下文。增强检索器理解用户意图和偏好的能力，类似于语言模型指令，有望产生更对齐的搜索目标。先前的研究将指令在信息检索中的应用限制在任务描述格式上，忽略了多样化和不断发展的搜索场景的广泛背景。此外，用于评估的主流基准缺乏明确的定制以评估遵循指令的能力，从而阻碍了该领域的进展。为了应对这些局限，我们提出了一个新颖的基准，INSTRUCTIR，专门设计用于评估信息检索任务中的指令遵循能力。我们的方法侧重于针对用户量身定制的指令。",
    "tldr": "INSTRUCTIR是一个专门设计用于评估信息检索任务中指令遵循能力的新型基准。",
    "en_tdlr": "INSTRUCTIR is a novel benchmark specifically designed to evaluate the instruction-following ability in information retrieval tasks."
}