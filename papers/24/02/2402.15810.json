{
    "title": "OAG-Bench: A Human-Curated Benchmark for Academic Graph Mining",
    "abstract": "arXiv:2402.15810v1 Announce Type: cross  Abstract: With the rapid proliferation of scientific literature, versatile academic knowledge services increasingly rely on comprehensive academic graph mining. Despite the availability of public academic graphs, benchmarks, and datasets, these resources often fall short in multi-aspect and fine-grained annotations, are constrained to specific task types and domains, or lack underlying real academic graphs. In this paper, we present OAG-Bench, a comprehensive, multi-aspect, and fine-grained human-curated benchmark based on the Open Academic Graph (OAG). OAG-Bench covers 10 tasks, 20 datasets, 70+ baselines, and 120+ experimental results to date. We propose new data annotation strategies for certain tasks and offer a suite of data pre-processing codes, algorithm implementations, and standardized evaluation protocols to facilitate academic graph mining. Extensive experiments reveal that even advanced algorithms like large language models (LLMs) en",
    "link": "https://arxiv.org/abs/2402.15810",
    "context": "Title: OAG-Bench: A Human-Curated Benchmark for Academic Graph Mining\nAbstract: arXiv:2402.15810v1 Announce Type: cross  Abstract: With the rapid proliferation of scientific literature, versatile academic knowledge services increasingly rely on comprehensive academic graph mining. Despite the availability of public academic graphs, benchmarks, and datasets, these resources often fall short in multi-aspect and fine-grained annotations, are constrained to specific task types and domains, or lack underlying real academic graphs. In this paper, we present OAG-Bench, a comprehensive, multi-aspect, and fine-grained human-curated benchmark based on the Open Academic Graph (OAG). OAG-Bench covers 10 tasks, 20 datasets, 70+ baselines, and 120+ experimental results to date. We propose new data annotation strategies for certain tasks and offer a suite of data pre-processing codes, algorithm implementations, and standardized evaluation protocols to facilitate academic graph mining. Extensive experiments reveal that even advanced algorithms like large language models (LLMs) en",
    "path": "papers/24/02/2402.15810.json",
    "total_tokens": 890,
    "translated_title": "OAG-Bench：面向学术图挖掘的人工筛选基准",
    "translated_abstract": "随着科学文献的迅速增长，多功能的学术知识服务越来越依赖全面的学术图挖掘。尽管公开学术图、基准和数据集已经有了，但这些资源通常在多方面和细粒度注释方面存在不足，受限于特定任务类型和领域，或者缺乏真实学术图。本文提出了基于开放学术图（OAG）的全面、多方面和精细化人工筛选基准OAG-Bench。OAG-Bench涵盖了10个任务，20个数据集，70+个基准和120+个截至目前的实验结果。我们针对某些任务提出了新的数据注释策略，并提供一套数据预处理代码、算法实现和标准化评估协议，以促进学术图挖掘。大量实验表明，即使是大型语言模型（LLMs）这样的先进算法也会在某些任务上受限。",
    "tldr": "OAG-Bench是一个基于开放学术图的全面、多方面和精细化人工筛选基准，涵盖了多个任务、数据集、基准和实验结果，旨在促进学术图挖掘。"
}