{
    "title": "Comparing Hallucination Detection Metrics for Multilingual Generation",
    "abstract": "arXiv:2402.10496v1 Announce Type: cross  Abstract: While many automatic hallucination detection techniques have been proposed for English texts, their effectiveness in multilingual contexts remains unexplored. This paper aims to bridge the gap in understanding how these hallucination detection metrics perform on non-English languages. We evaluate the efficacy of various detection metrics, including lexical metrics like ROUGE and Named Entity Overlap and Natural Language Inference (NLI)-based metrics, at detecting hallucinations in biographical summaries in many languages; we also evaluate how correlated these different metrics are to gauge whether they measure the same phenomena. Our empirical analysis reveals that while lexical metrics show limited effectiveness, NLI-based metrics perform well in high-resource languages at the sentence level. In contrast, NLI-based metrics often fail to detect atomic fact hallucinations. Our findings highlight existing gaps in multilingual hallucinati",
    "link": "https://arxiv.org/abs/2402.10496",
    "context": "Title: Comparing Hallucination Detection Metrics for Multilingual Generation\nAbstract: arXiv:2402.10496v1 Announce Type: cross  Abstract: While many automatic hallucination detection techniques have been proposed for English texts, their effectiveness in multilingual contexts remains unexplored. This paper aims to bridge the gap in understanding how these hallucination detection metrics perform on non-English languages. We evaluate the efficacy of various detection metrics, including lexical metrics like ROUGE and Named Entity Overlap and Natural Language Inference (NLI)-based metrics, at detecting hallucinations in biographical summaries in many languages; we also evaluate how correlated these different metrics are to gauge whether they measure the same phenomena. Our empirical analysis reveals that while lexical metrics show limited effectiveness, NLI-based metrics perform well in high-resource languages at the sentence level. In contrast, NLI-based metrics often fail to detect atomic fact hallucinations. Our findings highlight existing gaps in multilingual hallucinati",
    "path": "papers/24/02/2402.10496.json",
    "total_tokens": 876,
    "translated_title": "比较多语言生成中幻觉检测指标",
    "translated_abstract": "尽管已提出许多针对英文文本的自动幻觉检测技术，但它们在多语言环境中的效果尚未被探索。本文旨在填补对这些幻觉检测指标在非英语语言上表现如何的认识上的差距。我们评估了各种检测指标的有效性，包括诸如ROUGE和命名实体重叠以及基于自然语言推理（NLI）的指标，在多种语言的传记摘要中检测幻觉；我们还评估这些不同指标之间的相关性，以判断它们是否衡量相同的现象。我们的实证分析显示，虽然词汇指标显示出有限的有效性，但基于NLI的指标在高资源语言中在句子级别表现良好。相反，NLI-based指标通常无法检测到原子事实幻觉。我们的研究结果突显了多语言幻觉检测中的现有差距。",
    "tldr": "本研究比较了多语言生成中不同幻觉检测指标的效果，发现基于自然语言推理（NLI）的指标在高资源语言的句子级别表现良好，但通常无法检测到原子事实幻觉。",
    "en_tdlr": "This study compares the effectiveness of different hallucination detection metrics in multilingual generation, revealing that NLI-based metrics perform well at the sentence level in high-resource languages but often fail to detect atomic fact hallucinations."
}