{
    "title": "Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models",
    "abstract": "Large Language Models (LLMs) demonstrate ever-increasing abilities in mathematical and algorithmic tasks, yet their geometric reasoning skills are underexplored. We investigate LLMs' abilities in constructive geometric problem-solving one of the most fundamental steps in the development of human mathematical reasoning. Our work reveals notable challenges that the state-of-the-art LLMs face in this domain despite many successes in similar areas. LLMs exhibit biases in target variable selection and struggle with 2D spatial relationships, often misrepresenting and hallucinating objects and their placements. To this end, we introduce a framework that formulates an LLMs-based multi-agents system that enhances their existing reasoning potential by conducting an internal dialogue. This work underscores LLMs' current limitations in geometric reasoning and improves geometric reasoning capabilities through self-correction, collaboration, and diverse role specializations.",
    "link": "https://arxiv.org/abs/2402.03877",
    "context": "Title: Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models\nAbstract: Large Language Models (LLMs) demonstrate ever-increasing abilities in mathematical and algorithmic tasks, yet their geometric reasoning skills are underexplored. We investigate LLMs' abilities in constructive geometric problem-solving one of the most fundamental steps in the development of human mathematical reasoning. Our work reveals notable challenges that the state-of-the-art LLMs face in this domain despite many successes in similar areas. LLMs exhibit biases in target variable selection and struggle with 2D spatial relationships, often misrepresenting and hallucinating objects and their placements. To this end, we introduce a framework that formulates an LLMs-based multi-agents system that enhances their existing reasoning potential by conducting an internal dialogue. This work underscores LLMs' current limitations in geometric reasoning and improves geometric reasoning capabilities through self-correction, collaboration, and diverse role specializations.",
    "path": "papers/24/02/2402.03877.json",
    "total_tokens": 963,
    "translated_title": "超越线条和圆圈：揭示大型语言模型中的几何推理差距",
    "translated_abstract": "大型语言模型（LLMs）在数学和算法任务方面展示了不断增长的能力，然而它们在几何推理方面的技能还未被充分探索。我们调查了LLMs在构造性几何问题解决中的能力，这是人类数学推理发展中最基础的步骤之一。我们的研究揭示了目前最先进的LLMs在这个领域面临的显著挑战，尽管在类似领域取得了许多成功。LLMs在目标变量选择方面存在偏见，并且在2D空间关系方面面临困难，经常会错误地表示和臆造对象及其放置位置。为此，我们引入了一个基于LLMs的多代理体系结构，通过进行内部对话来增强它们现有的推理潜力。这项工作强调了LLMs在几何推理中的现有限制，并通过自我纠正、协作和不同角色专业化来提高几何推理能力。",
    "tldr": "本文调查了大型语言模型（LLMs）在几何推理方面的能力，并发现了它们在目标变量选择和2D空间关系方面存在偏见和困难。通过引入基于LLMs的多代理体系结构，本研究提出了一种通过自我纠正、协作和不同角色专业化来提高LLMs几何推理能力的框架。",
    "en_tdlr": "This study investigates the abilities of large language models (LLMs) in geometric reasoning and identifies biases and difficulties they face in target variable selection and 2D spatial relationships. By introducing a multi-agents system based on LLMs, the research proposes a framework to enhance the geometric reasoning capabilities of LLMs through self-correction, collaboration, and diverse role specializations."
}