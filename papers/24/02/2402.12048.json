{
    "title": "Model Tailor: Mitigating Catastrophic Forgetting in Multi-modal Large Language Models",
    "abstract": "arXiv:2402.12048v1 Announce Type: new  Abstract: Catastrophic forgetting emerges as a critical challenge when fine-tuning multi-modal large language models (MLLMs), where improving performance on unseen tasks often leads to a significant performance drop on the original tasks. This paper presents a comprehensive analysis of catastrophic forgetting in MLLMs and introduces a post-training adjustment method called Model Tailor. Our method primarily preserves the pre-trained parameters while replacing a small number ($\\leq$ 10\\%) of fine-tuned parameters, maintaining $\\sim$ 99\\% effectiveness on original tasks versus pre-training, and achieving $\\sim$ 97\\% on new tasks compared to standard fine-tuning. Specifically, we derive a sparse mask to identify the \"model patch\", based on a fusion strategy that integrates salience and sensitivity analysis. Subsequently, a compensation mechanism is introduced to \"decorate the patch\", enhancing the model's performance on both target and original tasks",
    "link": "https://arxiv.org/abs/2402.12048",
    "context": "Title: Model Tailor: Mitigating Catastrophic Forgetting in Multi-modal Large Language Models\nAbstract: arXiv:2402.12048v1 Announce Type: new  Abstract: Catastrophic forgetting emerges as a critical challenge when fine-tuning multi-modal large language models (MLLMs), where improving performance on unseen tasks often leads to a significant performance drop on the original tasks. This paper presents a comprehensive analysis of catastrophic forgetting in MLLMs and introduces a post-training adjustment method called Model Tailor. Our method primarily preserves the pre-trained parameters while replacing a small number ($\\leq$ 10\\%) of fine-tuned parameters, maintaining $\\sim$ 99\\% effectiveness on original tasks versus pre-training, and achieving $\\sim$ 97\\% on new tasks compared to standard fine-tuning. Specifically, we derive a sparse mask to identify the \"model patch\", based on a fusion strategy that integrates salience and sensitivity analysis. Subsequently, a compensation mechanism is introduced to \"decorate the patch\", enhancing the model's performance on both target and original tasks",
    "path": "papers/24/02/2402.12048.json",
    "total_tokens": 929,
    "translated_title": "模型定制：在多模态大语言模型中缓解灾难性遗忘",
    "translated_abstract": "在微调多模态大语言模型（MLLMs）时，灾难性遗忘出现为一个关键挑战，这里优化未知任务的性能往往会导致原始任务的显著性能下降。本文对MLLMs中的灾难性遗忘进行了全面分析，并提出了一种名为Model Tailor的后训练调整方法。我们的方法主要保留了预训练参数，同时替换了少量（$\\leq$ 10\\%）微调参数，在原始任务上保持了与预训练时约99\\%的效果，并在新任务上相比标准微调实现了约97\\%的效果。具体来说，我们提出了一个稀疏掩码来识别“模型修补”，基于融合策略，该策略整合了显著性和敏感性分析。随后，引入了一种补偿机制来“装饰修补”，增强模型在目标任务和原始任务上的性能。",
    "tldr": "该论文提出了一种名为Model Tailor 的后训练调整方法，在多模态大语言模型中缓解了灾难性遗忘，通过保留预训练参数并替换少量微调参数，实现了对原始任务约99%的效果和对新任务约97%的效果。",
    "en_tdlr": "This paper introduces a post-training adjustment method called Model Tailor, which mitigates catastrophic forgetting in multi-modal large language models by preserving pre-trained parameters and replacing a small number of fine-tuned parameters, achieving around 99% effectiveness on original tasks and around 97% on new tasks."
}