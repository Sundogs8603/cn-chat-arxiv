{
    "title": "Learning by Reconstruction Produces Uninformative Features For Perception",
    "abstract": "arXiv:2402.11337v1 Announce Type: cross  Abstract: Input space reconstruction is an attractive representation learning paradigm. Despite interpretability of the reconstruction and generation, we identify a misalignment between learning by reconstruction, and learning for perception. We show that the former allocates a model's capacity towards a subspace of the data explaining the observed variance--a subspace with uninformative features for the latter. For example, the supervised TinyImagenet task with images projected onto the top subspace explaining 90\\% of the pixel variance can be solved with 45\\% test accuracy. Using the bottom subspace instead, accounting for only 20\\% of the pixel variance, reaches 55\\% test accuracy. The features for perception being learned last explains the need for long training time, e.g., with Masked Autoencoders. Learning by denoising is a popular strategy to alleviate that misalignment. We prove that while some noise strategies such as masking are indeed",
    "link": "https://arxiv.org/abs/2402.11337",
    "context": "Title: Learning by Reconstruction Produces Uninformative Features For Perception\nAbstract: arXiv:2402.11337v1 Announce Type: cross  Abstract: Input space reconstruction is an attractive representation learning paradigm. Despite interpretability of the reconstruction and generation, we identify a misalignment between learning by reconstruction, and learning for perception. We show that the former allocates a model's capacity towards a subspace of the data explaining the observed variance--a subspace with uninformative features for the latter. For example, the supervised TinyImagenet task with images projected onto the top subspace explaining 90\\% of the pixel variance can be solved with 45\\% test accuracy. Using the bottom subspace instead, accounting for only 20\\% of the pixel variance, reaches 55\\% test accuracy. The features for perception being learned last explains the need for long training time, e.g., with Masked Autoencoders. Learning by denoising is a popular strategy to alleviate that misalignment. We prove that while some noise strategies such as masking are indeed",
    "path": "papers/24/02/2402.11337.json",
    "total_tokens": 646,
    "translated_title": "通过重构学习产生对感知无用的特征",
    "translated_abstract": "输入空间重构是一种吸引人的表示学习范式。尽管重构和生成的可解释性，我们发现了通过重构学习与为感知学习之间的不一致性。我们展示了前者将模型的容量分配给解释观察到的方差的数据子空间--这是对后者无用的特征子空间。",
    "tldr": "重构学习所产生的特征对感知无用，需要通过其他策略如去噪学习来缓解这种不一致性。",
    "en_tdlr": "Features learned by reconstruction are uninformative for perception, and the misalignment can be alleviated by strategies like denoising learning."
}