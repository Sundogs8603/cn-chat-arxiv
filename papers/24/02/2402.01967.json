{
    "title": "MasonPerplexity at Multimodal Hate Speech Event Detection 2024: Hate Speech and Target Detection Using Transformer Ensembles",
    "abstract": "The automatic identification of offensive language such as hate speech is important to keep discussions civil in online communities. Identifying hate speech in multimodal content is a particularly challenging task because offensiveness can be manifested in either words or images or a juxtaposition of the two. This paper presents the MasonPerplexity submission for the Shared Task on Multimodal Hate Speech Event Detection at CASE 2024 at EACL 2024. The task is divided into two sub-tasks: sub-task A focuses on the identification of hate speech and sub-task B focuses on the identification of targets in text-embedded images during political events. We use an XLM-roBERTa-large model for sub-task A and an ensemble approach combining XLM-roBERTa-base, BERTweet-large, and BERT-base for sub-task B. Our approach obtained 0.8347 F1-score in sub-task A and 0.6741 F1-score in sub-task B ranking 3rd on both sub-tasks.",
    "link": "https://arxiv.org/abs/2402.01967",
    "context": "Title: MasonPerplexity at Multimodal Hate Speech Event Detection 2024: Hate Speech and Target Detection Using Transformer Ensembles\nAbstract: The automatic identification of offensive language such as hate speech is important to keep discussions civil in online communities. Identifying hate speech in multimodal content is a particularly challenging task because offensiveness can be manifested in either words or images or a juxtaposition of the two. This paper presents the MasonPerplexity submission for the Shared Task on Multimodal Hate Speech Event Detection at CASE 2024 at EACL 2024. The task is divided into two sub-tasks: sub-task A focuses on the identification of hate speech and sub-task B focuses on the identification of targets in text-embedded images during political events. We use an XLM-roBERTa-large model for sub-task A and an ensemble approach combining XLM-roBERTa-base, BERTweet-large, and BERT-base for sub-task B. Our approach obtained 0.8347 F1-score in sub-task A and 0.6741 F1-score in sub-task B ranking 3rd on both sub-tasks.",
    "path": "papers/24/02/2402.01967.json",
    "total_tokens": 930,
    "translated_title": "基于Transformer集成的多模态仇恨言论事件检测的MasonPerplexity方法",
    "translated_abstract": "在网络社区中，自动识别诸如仇恨言论之类的冒犯性语言对于维护讨论的文明十分重要。在多模态内容中识别仇恨言论是一项特别具有挑战性的任务，因为冒犯性既可以体现在文字上，也可以体现在图像上，或者两者同时存在。本文介绍了在EACL 2024的CASE 2024上共享任务“多模态仇恨言论事件检测”中的MasonPerplexity方法。该任务分为两个子任务：子任务A注重识别仇恨言论，子任务B注重识别政治事件中嵌入文本图像中的目标。我们使用了一个XLM-roBERTa-large模型来处理子任务A，并使用集成方法将XLM-roBERTa-base、BERTweet-large和BERT-base模型结合起来处理子任务B。我们的方法在子任务A中获得了0.8347的F1分数，在子任务B中获得了0.6741的F1分数，并在两个子任务中排名第三。",
    "tldr": "本文提出了一种名为MasonPerplexity的方法来解决多模态仇恨言论事件检测的问题。该方法采用Transformer集成的方式，在识别仇恨言论和识别文本图像中目标的任务中均取得了较好的成绩，分别排名第三。",
    "en_tdlr": "This paper presents the MasonPerplexity method for multimodal hate speech event detection. The method utilizes Transformer ensembles to achieve good performance in identifying hate speech and targets in text-embedded images, ranking 3rd in both tasks."
}