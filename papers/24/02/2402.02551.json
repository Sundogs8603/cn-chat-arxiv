{
    "title": "Obstacle Avoidance Deep Reinforcement Learning-Based Trajectory Planner with Robust Low-Level Control for Robotic Manipulators",
    "abstract": "In robotics, contemporary strategies are learning-based, characterized by a complex black-box nature and a lack of interpretability, which may pose challenges in ensuring stability and safety. To address these issues, we propose integrating an obstacle-free deep reinforcement learning (DRL) trajectory planner with a novel auto-tuning low- and joint-level control strategy, all while actively engaging in the learning phase through interactions with the environment. This approach circumvents the complexities associated with computations while also addressing nonrepetitive and random obstacle avoidance tasks. First, a model-free DRL agent to plan velocity-bounded and obstacle-free motion is employed for a manipulator with 'n' degrees of freedom (DoF) in task space through joint-level reasoning. This plan is then input into a robust subsystem-based adaptive controller, which produces the necessary torques, while the Cuckoo Search Optimization (CSO) algorithm enhances control gains to minimi",
    "link": "https://arxiv.org/abs/2402.02551",
    "context": "Title: Obstacle Avoidance Deep Reinforcement Learning-Based Trajectory Planner with Robust Low-Level Control for Robotic Manipulators\nAbstract: In robotics, contemporary strategies are learning-based, characterized by a complex black-box nature and a lack of interpretability, which may pose challenges in ensuring stability and safety. To address these issues, we propose integrating an obstacle-free deep reinforcement learning (DRL) trajectory planner with a novel auto-tuning low- and joint-level control strategy, all while actively engaging in the learning phase through interactions with the environment. This approach circumvents the complexities associated with computations while also addressing nonrepetitive and random obstacle avoidance tasks. First, a model-free DRL agent to plan velocity-bounded and obstacle-free motion is employed for a manipulator with 'n' degrees of freedom (DoF) in task space through joint-level reasoning. This plan is then input into a robust subsystem-based adaptive controller, which produces the necessary torques, while the Cuckoo Search Optimization (CSO) algorithm enhances control gains to minimi",
    "path": "papers/24/02/2402.02551.json",
    "total_tokens": 953,
    "translated_title": "基于深度强化学习的障碍物避障轨迹规划器与鲁棒低级控制的机器人操作器",
    "translated_abstract": "在机器人领域，现代策略往往是基于学习的，其特点是黑盒性质复杂，缺乏解释性，可能在确保稳定性和安全性方面带来挑战。为了解决这些问题，我们提出了将无障碍深度强化学习（DRL）轨迹规划器与新颖的自动调谐低级和关节级控制策略集成在一起，并通过与环境的交互积极参与学习阶段。这种方法绕过了与计算相关的复杂性，同时解决了非重复和随机的避障任务。首先，利用无模型DRL代理在关节级推理任务空间中进行速度限制和无障碍运动规划，然后将该规划输入到稳健的子系统自适应控制器中，产生所需的扭矩，而杜鹃搜索优化（CSO）算法增强了控制增益以最小化。",
    "tldr": "这篇论文提出了一种基于深度强化学习和鲁棒低级控制的机器人操作器的障碍物避障轨迹规划方法，该方法通过与环境的交互积极参与学习，绕过了计算复杂性，同时解决了非重复和随机的避障任务。",
    "en_tdlr": "This paper presents an obstacle avoidance trajectory planning method for robotic manipulators using deep reinforcement learning and robust low-level control, which actively engages in learning through interactions with the environment, circumventing computational complexities while addressing nonrepetitive and random obstacle avoidance tasks."
}