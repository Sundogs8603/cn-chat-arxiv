{
    "title": "You Only Need One Color Space: An Efficient Network for Low-light Image Enhancement",
    "abstract": "Low-Light Image Enhancement (LLIE) task tends to restore the details and visual information from corrupted low-light images. Most existing methods learn the mapping function between low/normal-light images by Deep Neural Networks (DNNs) on sRGB and HSV color space. Nevertheless, enhancement involves amplifying image signals, and applying these color spaces to low-light images with a low signal-to-noise ratio can introduce sensitivity and instability into the enhancement process. Consequently, this results in the presence of color artifacts and brightness artifacts in the enhanced images. To alleviate this problem, we propose a novel trainable color space, named Horizontal/Vertical-Intensity (HVI). It not only decouples brightness and color from RGB channels to mitigate the instability during enhancement but also adapts to low-light images in different illumination ranges due to the trainable parameters. Further, we design a novel Color and Intensity Decoupling Network (CIDNet) with two",
    "link": "https://arxiv.org/abs/2402.05809",
    "context": "Title: You Only Need One Color Space: An Efficient Network for Low-light Image Enhancement\nAbstract: Low-Light Image Enhancement (LLIE) task tends to restore the details and visual information from corrupted low-light images. Most existing methods learn the mapping function between low/normal-light images by Deep Neural Networks (DNNs) on sRGB and HSV color space. Nevertheless, enhancement involves amplifying image signals, and applying these color spaces to low-light images with a low signal-to-noise ratio can introduce sensitivity and instability into the enhancement process. Consequently, this results in the presence of color artifacts and brightness artifacts in the enhanced images. To alleviate this problem, we propose a novel trainable color space, named Horizontal/Vertical-Intensity (HVI). It not only decouples brightness and color from RGB channels to mitigate the instability during enhancement but also adapts to low-light images in different illumination ranges due to the trainable parameters. Further, we design a novel Color and Intensity Decoupling Network (CIDNet) with two",
    "path": "papers/24/02/2402.05809.json",
    "total_tokens": 920,
    "translated_title": "只需一个颜色空间：一种用于低光图像增强的高效网络",
    "translated_abstract": "低光图像增强（Low-Light Image Enhancement，LLIE）任务旨在从受损的低光图像中恢复细节和视觉信息。大多数现有方法通过深度神经网络（DNNs）在sRGB和HSV颜色空间上学习低/正常光图像之间的映射函数。然而，增强涉及放大图像信号，并且将这些颜色空间应用于信噪比低的低光图像可能会引入灵敏度和不稳定性，从而导致增强图像中存在颜色伪影和亮度伪影。为了缓解这个问题，我们提出了一种新的可训练颜色空间，称为水平/垂直强度（HVI）。它不仅将亮度和颜色从RGB通道分离出来以减轻增强过程中的不稳定性，而且由于可训练参数，它还适应不同光照范围的低光图像。此外，我们设计了一种新颖的颜色和强度解耦网络（CIDNet），含有两个部分。",
    "tldr": "本文提出了一种用于低光图像增强的高效网络，通过引入可训练的水平/垂直强度（HVI）颜色空间来解耦亮度和颜色，并设计了颜色和强度解耦网络（CIDNet）以改善增强过程中的稳定性。结果显示，该方法可以减少增强图像中的颜色和亮度伪影。"
}