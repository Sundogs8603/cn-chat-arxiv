{
    "title": "Less is More: Mitigating Multimodal Hallucination from an EOS Decision Perspective",
    "abstract": "arXiv:2402.14545v1 Announce Type: new  Abstract: Large Multimodal Models (LMMs) often suffer from multimodal hallucinations, wherein they may create content that is not present in the visual inputs. In this paper, we explore a new angle of this issue: overly detailed training data hinders the model's ability to timely terminate generation, leading to continued outputs beyond visual perception limits. By investigating how the model decides to terminate generation with EOS, the special end-of-sentence token, we find that the model assesses the completeness of the entire sequence by comparing the generated text with the image. This observation suggests that the model possesses an inherent potential of making proper EOS decisions based on its visual perception to avoid overly lengthy outputs. To take advantage of such potential, we explore two methods to mitigate multimodal hallucinations: a training objective that enables the model to reduce hallucinations by learning from regular instruc",
    "link": "https://arxiv.org/abs/2402.14545",
    "context": "Title: Less is More: Mitigating Multimodal Hallucination from an EOS Decision Perspective\nAbstract: arXiv:2402.14545v1 Announce Type: new  Abstract: Large Multimodal Models (LMMs) often suffer from multimodal hallucinations, wherein they may create content that is not present in the visual inputs. In this paper, we explore a new angle of this issue: overly detailed training data hinders the model's ability to timely terminate generation, leading to continued outputs beyond visual perception limits. By investigating how the model decides to terminate generation with EOS, the special end-of-sentence token, we find that the model assesses the completeness of the entire sequence by comparing the generated text with the image. This observation suggests that the model possesses an inherent potential of making proper EOS decisions based on its visual perception to avoid overly lengthy outputs. To take advantage of such potential, we explore two methods to mitigate multimodal hallucinations: a training objective that enables the model to reduce hallucinations by learning from regular instruc",
    "path": "papers/24/02/2402.14545.json",
    "total_tokens": 853,
    "translated_title": "减少是有益的：从EOS决策角度缓解多模态幻觉",
    "translated_abstract": "大型多模态模型（LMMs）经常遭受多模态幻觉，即它们可能创造出在视觉输入中并不存在的内容。本文探讨了这个问题的一个新角度：过于详细的训练数据妨碍了模型及时终止生成，导致超出视觉感知限制的持续输出。通过研究模型如何通过EOS（特殊的句子结尾标记）来决定终止生成，我们发现模型通过将生成的文本与图像进行比较来评估整个序列的完整性。这一观察表明，模型具有基于其视觉感知进行适当EOS决策的潜力，以避免过长的输出。为了利用这种潜力，我们探讨了两种缓解多模态幻觉的方法：通过学习常规指示实现模型减少幻觉的训练目标",
    "tldr": "本文研究了大型多模态模型中存在的多模态幻觉问题，发现通过模型基于视觉感知作出适当的EOS决策，可以减少持续输出，提出了两种缓解方法。",
    "en_tdlr": "This paper explores the issue of multimodal hallucinations in large multimodal models and proposes two methods to mitigate them by having the model make proper EOS decisions based on visual perception."
}