{
    "title": "Consistency Matters: Explore LLMs Consistency From a Black-Box Perspective",
    "abstract": "arXiv:2402.17411v1 Announce Type: new  Abstract: Nowadays both commercial and open-source academic LLM have become the mainstream models of NLP. However, there is still a lack of research on LLM consistency, meaning that throughout the various stages of LLM research and deployment, its internal parameters and capabilities should remain unchanged. This issue exists in both the industrial and academic sectors. The solution to this problem is often time-consuming and labor-intensive, and there is also an additional cost of secondary deployment, resulting in economic and time losses. To fill this gap, we build an LLM consistency task dataset and design several baselines. Additionally, we choose models of diverse scales for the main experiments. Specifically, in the LightGBM experiment, we used traditional NLG metrics (i.e., ROUGE, BLEU, METEOR) as the features needed for model training. The final result exceeds the manual evaluation and GPT3.5 as well as other models in the main experiment",
    "link": "https://arxiv.org/abs/2402.17411",
    "context": "Title: Consistency Matters: Explore LLMs Consistency From a Black-Box Perspective\nAbstract: arXiv:2402.17411v1 Announce Type: new  Abstract: Nowadays both commercial and open-source academic LLM have become the mainstream models of NLP. However, there is still a lack of research on LLM consistency, meaning that throughout the various stages of LLM research and deployment, its internal parameters and capabilities should remain unchanged. This issue exists in both the industrial and academic sectors. The solution to this problem is often time-consuming and labor-intensive, and there is also an additional cost of secondary deployment, resulting in economic and time losses. To fill this gap, we build an LLM consistency task dataset and design several baselines. Additionally, we choose models of diverse scales for the main experiments. Specifically, in the LightGBM experiment, we used traditional NLG metrics (i.e., ROUGE, BLEU, METEOR) as the features needed for model training. The final result exceeds the manual evaluation and GPT3.5 as well as other models in the main experiment",
    "path": "papers/24/02/2402.17411.json",
    "total_tokens": 878,
    "translated_title": "一致性至关重要：从黑盒角度探索LLMs的一致性",
    "translated_abstract": "现如今，商业和开源学术LLM已成为自然语言处理的主流模型。然而，对LLM一致性的研究仍然不足，这意味着在LLM研究和部署的各个阶段中，其内部参数和能力应保持不变。这一问题存在于工业和学术领域。解决这个问题通常耗时且劳力密集，还有额外的二次部署成本，导致经济和时间损失。为弥补这一空白，我们建立了一个LLM一致性任务数据集，并设计了几个基准。此外，我们选择了不同规模的模型进行主要实验。具体来说，在LightGBM实验中，我们使用传统的自然语言生成度量（如ROUGE、BLEU、METEOR）作为模型训练所需的特征。最终结果超过了人工评估以及GPT3.5和其他模型在主要实验中的表现。",
    "tldr": "该论文探讨了LLMs的一致性问题，提出了一种解决方案，并设计了数据集和基准模型进行实验，结果显示在一致性任务上超过了GPT3.5等模型",
    "en_tdlr": "This paper investigates the consistency of LLMs, proposes a solution, designs a dataset and baseline models for experiments, with results showing surpassing performance in consistency tasks compared to models like GPT3.5."
}