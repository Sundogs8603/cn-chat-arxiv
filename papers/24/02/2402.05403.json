{
    "title": "In-Context Principle Learning from Mistakes",
    "abstract": "In-context learning (ICL, also known as few-shot prompting) has been the standard method of adapting LLMs to downstream tasks, by learning from a few input-output examples. Nonetheless, all ICL-based approaches only learn from correct input-output pairs. In this paper, we revisit this paradigm, by learning more from the few given input-output examples. We introduce Learning Principles (LEAP): First, we intentionally induce the model to make mistakes on these few examples; then we reflect on these mistakes, and learn explicit task-specific \"principles\" from them, which help solve similar problems and avoid common mistakes; finally, we prompt the model to answer unseen test questions using the original few-shot examples and these learned general principles. We evaluate LEAP on a wide range of benchmarks, including multi-hop question answering (Hotpot QA), textual QA (DROP), Big-Bench Hard reasoning, and math problems (GSM8K and MATH); in all these benchmarks, LEAP improves the strongest ",
    "link": "https://arxiv.org/abs/2402.05403",
    "context": "Title: In-Context Principle Learning from Mistakes\nAbstract: In-context learning (ICL, also known as few-shot prompting) has been the standard method of adapting LLMs to downstream tasks, by learning from a few input-output examples. Nonetheless, all ICL-based approaches only learn from correct input-output pairs. In this paper, we revisit this paradigm, by learning more from the few given input-output examples. We introduce Learning Principles (LEAP): First, we intentionally induce the model to make mistakes on these few examples; then we reflect on these mistakes, and learn explicit task-specific \"principles\" from them, which help solve similar problems and avoid common mistakes; finally, we prompt the model to answer unseen test questions using the original few-shot examples and these learned general principles. We evaluate LEAP on a wide range of benchmarks, including multi-hop question answering (Hotpot QA), textual QA (DROP), Big-Bench Hard reasoning, and math problems (GSM8K and MATH); in all these benchmarks, LEAP improves the strongest ",
    "path": "papers/24/02/2402.05403.json",
    "total_tokens": 888,
    "translated_title": "从错误中学习的上下文准则学习",
    "translated_abstract": "上下文学习（ICL，也称为少样本提示）已成为将LLMs适应下游任务的标准方法，通过从少量的输入-输出示例中学习。然而，所有基于ICL的方法只从正确的输入-输出对中学习。在本文中，我们重新审视这一范例，通过从少给定的输入-输出示例中学习更多内容。我们引入了学习准则（LEAP）：首先，我们有意诱使模型在这些少量示例中犯错误；然后，我们反思这些错误，并从中学习显式的任务特定“准则”，这些准则有助于解决类似的问题并避免常见的错误；最后，我们使用原始的少样本示例和这些学到的通用准则来提示模型回答未见过的测试问题。我们在包括多跳问题回答（Hotpot QA）、文本问题回答（DROP）、Big-Bench困难推理和数学问题（GSM8K和MATH）在内的多个基准测试上评估了LEAP；在所有这些基准测试中，LEAP都有所改进。",
    "tldr": "本文提出了一种新的学习方法LEAP，通过让模型从少量输入-输出示例中犯错误，然后反思并学习准则，从而提升模型在各种任务上的表现。"
}