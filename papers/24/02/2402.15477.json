{
    "title": "Debiasing Machine Learning Models by Using Weakly Supervised Learning",
    "abstract": "arXiv:2402.15477v1 Announce Type: new  Abstract: We tackle the problem of bias mitigation of algorithmic decisions in a setting where both the output of the algorithm and the sensitive variable are continuous. Most of prior work deals with discrete sensitive variables, meaning that the biases are measured for subgroups of persons defined by a label, leaving out important algorithmic bias cases, where the sensitive variable is continuous. Typical examples are unfair decisions made with respect to the age or the financial status. In our work, we then propose a bias mitigation strategy for continuous sensitive variables, based on the notion of endogeneity which comes from the field of econometrics. In addition to solve this new problem, our bias mitigation strategy is a weakly supervised learning method which requires that a small portion of the data can be measured in a fair manner. It is model agnostic, in the sense that it does not make any hypothesis on the prediction model. It also m",
    "link": "https://arxiv.org/abs/2402.15477",
    "context": "Title: Debiasing Machine Learning Models by Using Weakly Supervised Learning\nAbstract: arXiv:2402.15477v1 Announce Type: new  Abstract: We tackle the problem of bias mitigation of algorithmic decisions in a setting where both the output of the algorithm and the sensitive variable are continuous. Most of prior work deals with discrete sensitive variables, meaning that the biases are measured for subgroups of persons defined by a label, leaving out important algorithmic bias cases, where the sensitive variable is continuous. Typical examples are unfair decisions made with respect to the age or the financial status. In our work, we then propose a bias mitigation strategy for continuous sensitive variables, based on the notion of endogeneity which comes from the field of econometrics. In addition to solve this new problem, our bias mitigation strategy is a weakly supervised learning method which requires that a small portion of the data can be measured in a fair manner. It is model agnostic, in the sense that it does not make any hypothesis on the prediction model. It also m",
    "path": "papers/24/02/2402.15477.json",
    "total_tokens": 875,
    "translated_title": "通过使用弱监督学习来消除机器学习模型的偏见",
    "translated_abstract": "我们在算法决策的偏见消除问题中探讨了一个情况，即算法的输出和敏感变量均为连续的情形。大部分先前的工作处理的是离散的敏感变量，这意味着偏见是针对由标签定义的人群子集进行测量的，而忽略了算法偏见的重要情况，即敏感变量是连续的。典型的例子是关于年龄或财务状况而做出的不公平决策。在我们的工作中，我们提出了一种针对连续敏感变量的偏见消除策略，该策略基于计量经济学领域的内生性概念。除了解决这个新问题，我们的偏见消除策略还是一种弱监督学习方法，它要求数据的一小部分可以以公平的方式进行测量。这种方法在模型上是无关的，即它不对预测模型进行任何假设。",
    "tldr": "提出了一种针对连续敏感变量的偏见消除策略，基于内生性概念并采用弱监督学习方法，无需对预测模型做任何假设",
    "en_tdlr": "Proposed a bias mitigation strategy for continuous sensitive variables, based on the concept of endogeneity and employing weakly supervised learning method without making any assumptions on the prediction model."
}