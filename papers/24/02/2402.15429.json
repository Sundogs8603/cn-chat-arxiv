{
    "title": "ProTIP: Probabilistic Robustness Verification on Text-to-Image Diffusion Models against Stochastic Perturbation",
    "abstract": "arXiv:2402.15429v1 Announce Type: cross  Abstract: Text-to-Image (T2I) Diffusion Models (DMs) have shown impressive abilities in generating high-quality images based on simple text descriptions. However, as is common with many Deep Learning (DL) models, DMs are subject to a lack of robustness. While there are attempts to evaluate the robustness of T2I DMs as a binary or worst-case problem, they cannot answer how robust in general the model is whenever an adversarial example (AE) can be found. In this study, we first introduce a probabilistic notion of T2I DMs' robustness; and then establish an efficient framework, ProTIP, to evaluate it with statistical guarantees. The main challenges stem from: i) the high computational cost of the generation process; and ii) determining if a perturbed input is an AE involves comparing two output distributions, which is fundamentally harder compared to other DL tasks like classification where an AE is identified upon misprediction of labels. To tackle",
    "link": "https://arxiv.org/abs/2402.15429",
    "context": "Title: ProTIP: Probabilistic Robustness Verification on Text-to-Image Diffusion Models against Stochastic Perturbation\nAbstract: arXiv:2402.15429v1 Announce Type: cross  Abstract: Text-to-Image (T2I) Diffusion Models (DMs) have shown impressive abilities in generating high-quality images based on simple text descriptions. However, as is common with many Deep Learning (DL) models, DMs are subject to a lack of robustness. While there are attempts to evaluate the robustness of T2I DMs as a binary or worst-case problem, they cannot answer how robust in general the model is whenever an adversarial example (AE) can be found. In this study, we first introduce a probabilistic notion of T2I DMs' robustness; and then establish an efficient framework, ProTIP, to evaluate it with statistical guarantees. The main challenges stem from: i) the high computational cost of the generation process; and ii) determining if a perturbed input is an AE involves comparing two output distributions, which is fundamentally harder compared to other DL tasks like classification where an AE is identified upon misprediction of labels. To tackle",
    "path": "papers/24/02/2402.15429.json",
    "total_tokens": 956,
    "translated_title": "ProTIP：针对文本到图像扩散模型抗随机扰动的概率鲁棒性验证",
    "translated_abstract": "文本到图像（T2I）扩散模型（DMs）展现了在简单文本描述基础上生成高质量图像的印象能力。然而，与许多深度学习（DL）模型一样，DMs存在缺乏鲁棒性的问题。在评估T2I DMs的鲁棒性时，存在以二元或最坏情况问题解方面的尝试，但无法回答模型在存在对抗性样本（AE）时的总体鲁棒性如何。本研究首先引入了T2I DMs鲁棒性的概率概念；然后建立了一个名为ProTIP的高效框架，用于具有统计保证的评估。主要挑战源自：i）生成过程的高计算成本；和ii）确定扰动输入是否为AE涉及比较两个输出分布，这与其他DL任务（如分类）不同，其中AE是在标签错误预测时被识别的。为解决这些挑战，",
    "tldr": "本研究引入了概率概念的文本到图像扩散模型鲁棒性，并建立了一个名为ProTIP的高效框架用于评估其统计保证，解决了生成过程的高计算成本和对抗性样本判断困难的问题",
    "en_tdlr": "This study introduces a probabilistic notion of robustness for text-to-image diffusion models and establishes an efficient framework called ProTIP to evaluate it with statistical guarantees, addressing challenges of high computational costs in the generation process and difficulty in determining adversarial examples."
}