{
    "title": "Examining Modality Incongruity in Multimodal Federated Learning for Medical Vision and Language-based Disease Detection",
    "abstract": "Multimodal Federated Learning (MMFL) utilizes multiple modalities in each client to build a more powerful Federated Learning (FL) model than its unimodal counterpart. However, the impact of missing modality in different clients, also called modality incongruity, has been greatly overlooked. This paper, for the first time, analyses the impact of modality incongruity and reveals its connection with data heterogeneity across participating clients. We particularly inspect whether incongruent MMFL with unimodal and multimodal clients is more beneficial than unimodal FL. Furthermore, we examine three potential routes of addressing this issue. Firstly, we study the effectiveness of various self-attention mechanisms towards incongruity-agnostic information fusion in MMFL. Secondly, we introduce a modality imputation network (MIN) pre-trained in a multimodal client for modality translation in unimodal clients and investigate its potential towards mitigating the missing modality problem. Thirdly",
    "link": "https://arxiv.org/abs/2402.05294",
    "context": "Title: Examining Modality Incongruity in Multimodal Federated Learning for Medical Vision and Language-based Disease Detection\nAbstract: Multimodal Federated Learning (MMFL) utilizes multiple modalities in each client to build a more powerful Federated Learning (FL) model than its unimodal counterpart. However, the impact of missing modality in different clients, also called modality incongruity, has been greatly overlooked. This paper, for the first time, analyses the impact of modality incongruity and reveals its connection with data heterogeneity across participating clients. We particularly inspect whether incongruent MMFL with unimodal and multimodal clients is more beneficial than unimodal FL. Furthermore, we examine three potential routes of addressing this issue. Firstly, we study the effectiveness of various self-attention mechanisms towards incongruity-agnostic information fusion in MMFL. Secondly, we introduce a modality imputation network (MIN) pre-trained in a multimodal client for modality translation in unimodal clients and investigate its potential towards mitigating the missing modality problem. Thirdly",
    "path": "papers/24/02/2402.05294.json",
    "total_tokens": 983,
    "translated_title": "检验医疗视觉和基于语言的疾病检测的多模态联邦学习中的模态不一致性",
    "translated_abstract": "多模态联邦学习（MMFL）利用每个客户端中的多个模态构建比其单模态对应物更强大的联邦学习（FL）模型。然而，不同客户端缺失模态的影响，也称为模态不一致性，一直被大大忽视。本文首次分析了模态不一致性的影响，并揭示了其与参与客户端之间的数据异质性的联系。我们特别检查了不一致的MMFL与单模态和多模态客户端相比是否更有益于单模态FL。此外，我们还研究了解决这个问题的三个潜在途径。首先，我们研究了各种自注意机制对于不考虑不一致性的信息融合在MMFL中的有效性。其次，我们在多模态客户端中引入了一个预先训练的模态插值网络（MIN）来解决单模态客户端中的模态翻译问题，并研究其减轻缺失模态问题的潜力。第三，我们...",
    "tldr": "本文首次分析了多模态联邦学习中的模态不一致性的影响，并揭示了其与参与客户端之间的数据异质性的联系。通过使用不考虑不一致性的信息融合机制和模态插值网络，在解决模态不一致性问题方面取得了一定的成果。",
    "en_tdlr": "This paper examines the impact of modality incongruity in multimodal federated learning and reveals its connection with data heterogeneity across participating clients. It achieves significant progress in addressing the modality incongruity problem through the use of incongruity-agnostic information fusion mechanisms and a modality imputation network."
}