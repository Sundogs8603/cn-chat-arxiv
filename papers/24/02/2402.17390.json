{
    "title": "Robustness-Congruent Adversarial Training for Secure Machine Learning Model Updates",
    "abstract": "arXiv:2402.17390v1 Announce Type: new  Abstract: Machine-learning models demand for periodic updates to improve their average accuracy, exploiting novel architectures and additional data. However, a newly-updated model may commit mistakes that the previous model did not make. Such misclassifications are referred to as negative flips, and experienced by users as a regression of performance. In this work, we show that this problem also affects robustness to adversarial examples, thereby hindering the development of secure model update practices. In particular, when updating a model to improve its adversarial robustness, some previously-ineffective adversarial examples may become misclassified, causing a regression in the perceived security of the system. We propose a novel technique, named robustness-congruent adversarial training, to address this issue. It amounts to fine-tuning a model with adversarial training, while constraining it to retain higher robustness on the adversarial examp",
    "link": "https://arxiv.org/abs/2402.17390",
    "context": "Title: Robustness-Congruent Adversarial Training for Secure Machine Learning Model Updates\nAbstract: arXiv:2402.17390v1 Announce Type: new  Abstract: Machine-learning models demand for periodic updates to improve their average accuracy, exploiting novel architectures and additional data. However, a newly-updated model may commit mistakes that the previous model did not make. Such misclassifications are referred to as negative flips, and experienced by users as a regression of performance. In this work, we show that this problem also affects robustness to adversarial examples, thereby hindering the development of secure model update practices. In particular, when updating a model to improve its adversarial robustness, some previously-ineffective adversarial examples may become misclassified, causing a regression in the perceived security of the system. We propose a novel technique, named robustness-congruent adversarial training, to address this issue. It amounts to fine-tuning a model with adversarial training, while constraining it to retain higher robustness on the adversarial examp",
    "path": "papers/24/02/2402.17390.json",
    "total_tokens": 838,
    "translated_title": "针对安全机器学习模型更新的鲁棒一致对抗训练",
    "translated_abstract": "机器学习模型需要定期更新以提高其平均准确度，利用新颖的架构和额外的数据。然而，新更新的模型可能会犯以前模型未曾犯过的错误。这种误分类被称为负翻转，并被用户体验为性能的退化。在本文中，我们展示了这个问题也影响对抗性样本的鲁棒性，从而阻碍了安全模型更新实践的发展。特别是，当更新模型以提高其对抗性鲁棒性时，一些先前无效的对抗性样本可能会被错误分类，导致系统安全性的认知退化。我们提出了一种名为鲁棒一致对抗训练的新技术来解决这个问题。它涉及使用对抗训练对模型进行微调，同时约束其在对抗性示例上保持更高的鲁棒性。",
    "tldr": "通过鲁棒一致对抗训练技术，解决了更新机器学习模型时对抗性鲁棒性和系统安全性的问题。"
}