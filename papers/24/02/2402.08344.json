{
    "title": "Implicit Bias in Noisy-SGD: With Applications to Differentially Private Training",
    "abstract": "Training Deep Neural Networks (DNNs) with small batches using Stochastic Gradient Descent (SGD) yields superior test performance compared to larger batches. The specific noise structure inherent to SGD is known to be responsible for this implicit bias. DP-SGD, used to ensure differential privacy (DP) in DNNs' training, adds Gaussian noise to the clipped gradients. Surprisingly, large-batch training still results in a significant decrease in performance, which poses an important challenge because strong DP guarantees necessitate the use of massive batches. We first show that the phenomenon extends to Noisy-SGD (DP-SGD without clipping), suggesting that the stochasticity (and not the clipping) is the cause of this implicit bias, even with additional isotropic Gaussian noise. We theoretically analyse the solutions obtained with continuous versions of Noisy-SGD for the Linear Least Square and Diagonal Linear Network settings, and reveal that the implicit bias is indeed amplified by the add",
    "link": "https://arxiv.org/abs/2402.08344",
    "context": "Title: Implicit Bias in Noisy-SGD: With Applications to Differentially Private Training\nAbstract: Training Deep Neural Networks (DNNs) with small batches using Stochastic Gradient Descent (SGD) yields superior test performance compared to larger batches. The specific noise structure inherent to SGD is known to be responsible for this implicit bias. DP-SGD, used to ensure differential privacy (DP) in DNNs' training, adds Gaussian noise to the clipped gradients. Surprisingly, large-batch training still results in a significant decrease in performance, which poses an important challenge because strong DP guarantees necessitate the use of massive batches. We first show that the phenomenon extends to Noisy-SGD (DP-SGD without clipping), suggesting that the stochasticity (and not the clipping) is the cause of this implicit bias, even with additional isotropic Gaussian noise. We theoretically analyse the solutions obtained with continuous versions of Noisy-SGD for the Linear Least Square and Diagonal Linear Network settings, and reveal that the implicit bias is indeed amplified by the add",
    "path": "papers/24/02/2402.08344.json",
    "total_tokens": 979,
    "translated_title": "在带有差分隐私训练的Noisy-SGD中的隐式偏差：及其在训练中的应用",
    "translated_abstract": "使用随机梯度下降(SGD)以小批量训练深度神经网络(DNN)相较于大批量训练能够获得更好的测试性能。SGD特定的噪声结构被认为是导致这种隐式偏差的原因。用于确保DNN训练中的差异隐私(DP)的DP-SGD会给剪裁梯度添加高斯噪声。令人惊讶的是，大批量训练仍然会导致显著的性能下降，这是一个重要的挑战，因为强DP保证需要使用大批量数据。我们首先展示了现象在Noisy-SGD（没有剪裁的DP-SGD）中的存在，这表明随机性（而不是剪裁）是这种隐式偏差的原因，即使加入了额外的各向同性高斯噪声。我们在线性最小二乘和对角线线性网络设置上对使用连续版本的Noisy-SGD获得的解进行了理论分析，并揭示了隐式偏差确实被加剧了。",
    "tldr": "通过使用带有差分隐私训练的Noisy-SGD方法，我们发现随机性而非剪裁梯度是导致训练过程中的隐式偏差的原因，并且这种偏差会被加剧，这对于使用巨大批量数据的强差分隐私保证构成重要挑战。",
    "en_tdlr": "By utilizing the Noisy-SGD approach with differential privacy training, we found that the implicit bias during training is caused by randomness rather than the clipping of gradients, and this bias is amplified, posing a significant challenge for strong differential privacy guarantees using massive batch data."
}