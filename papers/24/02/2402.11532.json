{
    "title": "Chain-of-Instructions: Compositional Instruction Tuning on Large Language Models",
    "abstract": "arXiv:2402.11532v1 Announce Type: new  Abstract: Fine-tuning large language models (LLMs) with a collection of large and diverse instructions has improved the model's generalization to different tasks, even for unseen tasks. However, most existing instruction datasets include only single instructions, and they struggle to follow complex instructions composed of multiple subtasks (Wang et al., 2023a). In this work, we propose a novel concept of compositional instructions called chain-of-instructions (CoI), where the output of one instruction becomes an input for the next like a chain. Unlike the conventional practice of solving single instruction tasks, our proposed method encourages a model to solve each subtask step by step until the final answer is reached. CoI-tuning (i.e., fine-tuning with CoI instructions) improves the model's ability to handle instructions composed of multiple subtasks. CoI-tuned models also outperformed baseline models on multilingual summarization, demonstratin",
    "link": "https://arxiv.org/abs/2402.11532",
    "context": "Title: Chain-of-Instructions: Compositional Instruction Tuning on Large Language Models\nAbstract: arXiv:2402.11532v1 Announce Type: new  Abstract: Fine-tuning large language models (LLMs) with a collection of large and diverse instructions has improved the model's generalization to different tasks, even for unseen tasks. However, most existing instruction datasets include only single instructions, and they struggle to follow complex instructions composed of multiple subtasks (Wang et al., 2023a). In this work, we propose a novel concept of compositional instructions called chain-of-instructions (CoI), where the output of one instruction becomes an input for the next like a chain. Unlike the conventional practice of solving single instruction tasks, our proposed method encourages a model to solve each subtask step by step until the final answer is reached. CoI-tuning (i.e., fine-tuning with CoI instructions) improves the model's ability to handle instructions composed of multiple subtasks. CoI-tuned models also outperformed baseline models on multilingual summarization, demonstratin",
    "path": "papers/24/02/2402.11532.json",
    "total_tokens": 828,
    "translated_title": "指令链：大型语言模型的组合指令调整",
    "translated_abstract": "使用一系列大型和多样化的指令对大型语言模型（LLMs）进行微调，提高了模型对不同任务的泛化能力，甚至对未曾见过的任务也适用。本研究提出了一种称为指令链（CoI）的新概念，其中一个指令的输出成为下一个指令的输入，就像一条链条。与解决单一指令任务的传统做法不同，我们提出的方法鼓励模型逐步解决每个子任务，直至得出最终答案。CoI调整（即使用CoI指令进行微调）提高了模型处理由多个子任务组成的指令能力。经CoI调整的模型在多语言摘要上也优于基准模型，证明....",
    "tldr": "提出了一种名为指令链（CoI）的新概念，通过逐步解决每个子任务来处理由多个子任务组成的指令，进而提高了大型语言模型（LLMs）的泛化能力和多语言摘要性能",
    "en_tdlr": "Introduced a new concept called Chain-of-Instructions (CoI) which enhances the generalization and multilingual summarization performance of large language models (LLMs) by sequentially solving each subtask in instructions composed of multiple subtasks."
}