{
    "title": "Learning Fair Ranking Policies via Differentiable Optimization of Ordered Weighted Averages",
    "abstract": "Learning to Rank (LTR) is one of the most widely used machine learning applications. It is a key component in platforms with profound societal impacts, including job search, healthcare information retrieval, and social media content feeds. Conventional LTR models have been shown to produce biases results, stimulating a discourse on how to address the disparities introduced by ranking systems that solely prioritize user relevance. However, while several models of fair learning to rank have been proposed, they suffer from deficiencies either in accuracy or efficiency, thus limiting their applicability to real-world ranking platforms. This paper shows how efficiently-solvable fair ranking models, based on the optimization of Ordered Weighted Average (OWA) functions, can be integrated into the training loop of an LTR model to achieve favorable balances between fairness, user utility, and runtime efficiency. In particular, this paper is the first to show how to backpropagate through constra",
    "link": "https://arxiv.org/abs/2402.05252",
    "context": "Title: Learning Fair Ranking Policies via Differentiable Optimization of Ordered Weighted Averages\nAbstract: Learning to Rank (LTR) is one of the most widely used machine learning applications. It is a key component in platforms with profound societal impacts, including job search, healthcare information retrieval, and social media content feeds. Conventional LTR models have been shown to produce biases results, stimulating a discourse on how to address the disparities introduced by ranking systems that solely prioritize user relevance. However, while several models of fair learning to rank have been proposed, they suffer from deficiencies either in accuracy or efficiency, thus limiting their applicability to real-world ranking platforms. This paper shows how efficiently-solvable fair ranking models, based on the optimization of Ordered Weighted Average (OWA) functions, can be integrated into the training loop of an LTR model to achieve favorable balances between fairness, user utility, and runtime efficiency. In particular, this paper is the first to show how to backpropagate through constra",
    "path": "papers/24/02/2402.05252.json",
    "total_tokens": 864,
    "translated_title": "通过可微分优化有序加权平均值学习公平排名策略",
    "translated_abstract": "学习排序（LTR）是最广泛使用的机器学习应用之一。它是具有深远社会影响的平台的关键组成部分，包括求职搜索、医疗信息检索和社交媒体内容推送。传统的LTR模型已经显示出产生偏见结果，引发了如何解决仅优先考虑用户相关性的排名系统引入的差异的讨论。然而，虽然已经提出了几种公平学习排序模型，但它们在准确性或效率方面存在缺陷，从而限制了它们在实际排名平台中的适用性。本文展示了如何将基于有序加权平均（OWA）函数的高效可解的公平排名模型集成到LTR模型的训练循环中，以实现公平性、用户效用和运行时效率之间的有利平衡。特别是，本文首次展示了如何通过约束优化反向传播。",
    "tldr": "本文介绍了一种通过优化有序加权平均值函数，在LTR模型的训练过程中集成高效的公平排名模型，实现公平性、用户效用和运行时效率之间的有利平衡。"
}