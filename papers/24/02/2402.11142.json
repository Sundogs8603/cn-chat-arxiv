{
    "title": "Grasping the Essentials: Tailoring Large Language Models for Zero-Shot Relation Extraction",
    "abstract": "arXiv:2402.11142v1 Announce Type: new  Abstract: Relation extraction (RE), a crucial task in NLP, aims to identify semantic relationships between entities mentioned in texts. Despite significant advancements in this field, existing models typically rely on extensive annotated data for training, which can be both costly and time-consuming to acquire. Moreover, these models often struggle to adapt to new or unseen relationships. In contrast, few-shot learning settings, which aim to reduce annotation requirements, may offer incomplete and biased supervision for understanding target relation semantics, leading to degraded and unstable performance. To provide the model with accurate and explicit descriptions of the relations types and meanwhile minimize the annotation requirements, we study the definition only zero-shot RE setting where only relation definitions expressed in natural language are used to train a RE model. Motivated by the strong synthetic data generation power of LLMs, we pr",
    "link": "https://arxiv.org/abs/2402.11142",
    "context": "Title: Grasping the Essentials: Tailoring Large Language Models for Zero-Shot Relation Extraction\nAbstract: arXiv:2402.11142v1 Announce Type: new  Abstract: Relation extraction (RE), a crucial task in NLP, aims to identify semantic relationships between entities mentioned in texts. Despite significant advancements in this field, existing models typically rely on extensive annotated data for training, which can be both costly and time-consuming to acquire. Moreover, these models often struggle to adapt to new or unseen relationships. In contrast, few-shot learning settings, which aim to reduce annotation requirements, may offer incomplete and biased supervision for understanding target relation semantics, leading to degraded and unstable performance. To provide the model with accurate and explicit descriptions of the relations types and meanwhile minimize the annotation requirements, we study the definition only zero-shot RE setting where only relation definitions expressed in natural language are used to train a RE model. Motivated by the strong synthetic data generation power of LLMs, we pr",
    "path": "papers/24/02/2402.11142.json",
    "total_tokens": 842,
    "translated_title": "把握要点：定制大型语言模型进行零-shot关系抽取",
    "translated_abstract": "关系抽取（RE）是自然语言处理中的一个关键任务，旨在识别文本中提及的实体之间的语义关系。尽管这一领域取得了显著进展，但现有模型通常依赖于大量的注释数据进行训练，获取这些数据可能既昂贵又耗时。此外，这些模型通常难以适应新的或未见过的关系。相比之下，少样本学习设置旨在减少注释要求，对于理解目标关系语义提供了不完整且有偏见的监督，导致性能下降且不稳定。为了为模型提供准确和明确的关系类型描述，同时最小化注释要求，我们研究了仅使用自然语言中表示的关系定义来训练RE模型的仅零-shot RE设置。受LLM（大型语言模型）强大的合成数据生成能力的启发，我们提出了一种",
    "tldr": "通过使用自然语言表达的关系定义来训练关系抽取模型的零-shot学习设置，从而为模型提供准确和明确的关系类型描述，并同时最小化注释要求。"
}