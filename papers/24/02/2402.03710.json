{
    "title": "Listen, Chat, and Edit: Text-Guided Soundscape Modification for Enhanced Auditory Experience",
    "abstract": "In daily life, we encounter a variety of sounds, both desirable and undesirable, with limited control over their presence and volume. Our work introduces \"Listen, Chat, and Edit\" (LCE), a novel multimodal sound mixture editor that modifies each sound source in a mixture based on user-provided text instructions. LCE distinguishes itself with a user-friendly chat interface and its unique ability to edit multiple sound sources simultaneously within a mixture, without needing to separate them. Users input open-vocabulary text prompts, which are interpreted by a large language model to create a semantic filter for editing the sound mixture. The system then decomposes the mixture into its components, applies the semantic filter, and reassembles it into the desired output. We developed a 160-hour dataset with over 100k mixtures, including speech and various audio sources, along with text prompts for diverse editing tasks like extraction, removal, and volume control. Our experiments demonstrat",
    "link": "https://arxiv.org/abs/2402.03710",
    "context": "Title: Listen, Chat, and Edit: Text-Guided Soundscape Modification for Enhanced Auditory Experience\nAbstract: In daily life, we encounter a variety of sounds, both desirable and undesirable, with limited control over their presence and volume. Our work introduces \"Listen, Chat, and Edit\" (LCE), a novel multimodal sound mixture editor that modifies each sound source in a mixture based on user-provided text instructions. LCE distinguishes itself with a user-friendly chat interface and its unique ability to edit multiple sound sources simultaneously within a mixture, without needing to separate them. Users input open-vocabulary text prompts, which are interpreted by a large language model to create a semantic filter for editing the sound mixture. The system then decomposes the mixture into its components, applies the semantic filter, and reassembles it into the desired output. We developed a 160-hour dataset with over 100k mixtures, including speech and various audio sources, along with text prompts for diverse editing tasks like extraction, removal, and volume control. Our experiments demonstrat",
    "path": "papers/24/02/2402.03710.json",
    "total_tokens": 900,
    "translated_title": "听、聊、编辑：基于文本指导的声景修改以增强听觉体验",
    "translated_abstract": "在日常生活中，我们遇到各种各样的声音，有些是我们期望的，有些是我们不希望的，对它们的存在和音量的控制有限。我们的工作引入了一种新颖的多模态声音混合编辑器\"听、聊、编辑\"(LCE)，该编辑器根据用户提供的文本指令修改混合中的每个声音源。LCE通过用户友好的聊天界面以及其在不需要将声音源分离的情况下同时对多个声音源进行编辑的能力而与众不同。用户输入开放性的文本提示，这些提示由大型语言模型解释，用于创建编辑声音混合的语义滤波器。系统然后将混合解析成其组成部分，应用语义滤波器，并将其重新组装成期望的输出。我们开发了一个包括语音和各种音频源以及用于不同编辑任务的文本提示的160小时数据集，包括提取、删除和音量控制。我们的实验证明。",
    "tldr": "本研究引入了一种新颖的多模态声音混合编辑器，通过用户提供的文本指令实现对声音源的修改，实现了同时编辑多个声音源的能力，无需将它们分离。实验证明了该编辑器的实用性和效果。",
    "en_tdlr": "This research introduces a novel multimodal sound mixture editor that modifies sound sources based on user-provided text instructions, allowing simultaneous editing of multiple sources within a mixture. Experimental results demonstrate the practicality and effectiveness of the editor."
}