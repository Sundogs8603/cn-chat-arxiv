{
    "title": "Chain-of-Specificity: An Iteratively Refining Method for Eliciting Knowledge from Large Language Models",
    "abstract": "arXiv:2402.15526v1 Announce Type: new  Abstract: Large Language Models (LLMs) exhibit remarkable generative capabilities, enabling the generation of valuable information. Despite these advancements, previous research found that LLMs sometimes struggle with adhering to specific constraints (e.g., in specific place or at specific time), at times even overlooking them, which leads to responses that are either too generic or not fully satisfactory. Existing approaches attempted to address this issue by decomposing or rewriting input instructions, yet they fall short in adequately emphasizing specific constraints and in unlocking the underlying knowledge (e.g., programming within the context of software development). In response, this paper proposes a simple yet effective method named Chain-of-Specificity (CoS). Specifically, CoS iteratively emphasizes the specific constraints in the input instructions, unlocks knowledge within LLMs, and refines responses. Experiments conducted on publicly ",
    "link": "https://arxiv.org/abs/2402.15526",
    "context": "Title: Chain-of-Specificity: An Iteratively Refining Method for Eliciting Knowledge from Large Language Models\nAbstract: arXiv:2402.15526v1 Announce Type: new  Abstract: Large Language Models (LLMs) exhibit remarkable generative capabilities, enabling the generation of valuable information. Despite these advancements, previous research found that LLMs sometimes struggle with adhering to specific constraints (e.g., in specific place or at specific time), at times even overlooking them, which leads to responses that are either too generic or not fully satisfactory. Existing approaches attempted to address this issue by decomposing or rewriting input instructions, yet they fall short in adequately emphasizing specific constraints and in unlocking the underlying knowledge (e.g., programming within the context of software development). In response, this paper proposes a simple yet effective method named Chain-of-Specificity (CoS). Specifically, CoS iteratively emphasizes the specific constraints in the input instructions, unlocks knowledge within LLMs, and refines responses. Experiments conducted on publicly ",
    "path": "papers/24/02/2402.15526.json",
    "total_tokens": 759,
    "translated_title": "Chain-of-Specificity: 一种从大型语言模型中提取知识的逐步精化方法",
    "translated_abstract": "大型语言模型(LLMs)展现出引人瞩目的生成能力，能够生成有价值的信息。然而，先前的研究发现，LLMs有时难以遵循具体的约束(如在特定地点或特定时间)，甚至有时会忽略这些约束，导致回应要么太笼统，要么不够满意。本文提出一种简单而有效的方法，名为Chain-of-Specificity (CoS)。具体而言，CoS迭代地强调输入指令中的具体约束，解锁LLMs内部的知识，并精化回应。",
    "tldr": "Chain-of-Specificity (CoS)是一种从大型语言模型中提取知识的逐步精化方法，能够在输入指令中迭代强调特定约束，解锁知识并改进回应。",
    "en_tdlr": "Chain-of-Specificity (CoS) is an iteratively refining method for eliciting knowledge from large language models, emphasizing specific constraints in input instructions, unlocking knowledge within LLMs, and refining responses."
}