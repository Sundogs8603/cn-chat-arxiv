{
    "title": "Multimodal Learned Sparse Retrieval for Image Suggestion",
    "abstract": "Learned Sparse Retrieval (LSR) is a group of neural methods designed to encode queries and documents into sparse lexical vectors. These vectors can be efficiently indexed and retrieved using an inverted index. While LSR has shown promise in text retrieval, its potential in multi-modal retrieval remains largely unexplored. Motivated by this, in this work, we explore the application of LSR in the multi-modal domain, i.e., we focus on Multi-Modal Learned Sparse Retrieval (MLSR). We conduct experiments using several MLSR model configurations and evaluate the performance on the image suggestion task. We find that solving the task solely based on the image content is challenging. Enriching the image content with its caption improves the model performance significantly, implying the importance of image captions to provide fine-grained concepts and context information of images. Our approach presents a practical and effective solution for training LSR retrieval models in multi-modal settings.",
    "link": "https://arxiv.org/abs/2402.07736",
    "context": "Title: Multimodal Learned Sparse Retrieval for Image Suggestion\nAbstract: Learned Sparse Retrieval (LSR) is a group of neural methods designed to encode queries and documents into sparse lexical vectors. These vectors can be efficiently indexed and retrieved using an inverted index. While LSR has shown promise in text retrieval, its potential in multi-modal retrieval remains largely unexplored. Motivated by this, in this work, we explore the application of LSR in the multi-modal domain, i.e., we focus on Multi-Modal Learned Sparse Retrieval (MLSR). We conduct experiments using several MLSR model configurations and evaluate the performance on the image suggestion task. We find that solving the task solely based on the image content is challenging. Enriching the image content with its caption improves the model performance significantly, implying the importance of image captions to provide fine-grained concepts and context information of images. Our approach presents a practical and effective solution for training LSR retrieval models in multi-modal settings.",
    "path": "papers/24/02/2402.07736.json",
    "total_tokens": 894,
    "translated_title": "图像建议的多模态学习稀疏检索",
    "translated_abstract": "学习稀疏检索（LSR）是一组设计用于将查询和文档编码成稀疏词汇向量的神经方法。这些向量可以通过倒排索引进行高效地索引和检索。虽然LSR在文本检索中表现出了潜力，但其在多模态检索中的潜力仍然未被充分探索。基于此，本文研究了LSR在多模态领域中的应用，即我们专注于多模态学习稀疏检索（MLSR）。我们使用多种MLSR模型配置进行实验，并评估图像建议任务的性能。我们发现仅基于图像内容解决该任务具有挑战性。通过丰富图像内容与其标题信息相结合，可以显著提高模型性能，这表明图像标题提供了图像的精细概念和上下文信息的重要性。我们的方法为多模态设置中训练LSR检索模型提供了实际而有效的解决方案。",
    "tldr": "该论文探索了在多模态领域中应用学习稀疏检索（LSR）的方法，通过丰富图像内容与其标题信息相结合，极大地提高了模型性能，提供了实际而有效的训练LSR检索模型的解决方案。"
}