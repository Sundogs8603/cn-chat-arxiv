{
    "title": "Deep Robot Sketching: An application of Deep Q-Learning Networks for human-like sketching",
    "abstract": "The current success of Reinforcement Learning algorithms for its performance in complex environments has inspired many recent theoretical approaches to cognitive science. Artistic environments are studied within the cognitive science community as rich, natural, multi-sensory, multi-cultural environments. In this work, we propose the introduction of Reinforcement Learning for improving the control of artistic robot applications. Deep Q-learning Neural Networks (DQN) is one of the most successful algorithms for the implementation of Reinforcement Learning in robotics. DQN methods generate complex control policies for the execution of complex robot applications in a wide set of environments. Current art painting robot applications use simple control laws that limits the adaptability of the frameworks to a set of simple environments. In this work, the introduction of DQN within an art painting robot application is proposed. The goal is to study how the introduction of a complex control pol",
    "link": "https://arxiv.org/abs/2402.00676",
    "context": "Title: Deep Robot Sketching: An application of Deep Q-Learning Networks for human-like sketching\nAbstract: The current success of Reinforcement Learning algorithms for its performance in complex environments has inspired many recent theoretical approaches to cognitive science. Artistic environments are studied within the cognitive science community as rich, natural, multi-sensory, multi-cultural environments. In this work, we propose the introduction of Reinforcement Learning for improving the control of artistic robot applications. Deep Q-learning Neural Networks (DQN) is one of the most successful algorithms for the implementation of Reinforcement Learning in robotics. DQN methods generate complex control policies for the execution of complex robot applications in a wide set of environments. Current art painting robot applications use simple control laws that limits the adaptability of the frameworks to a set of simple environments. In this work, the introduction of DQN within an art painting robot application is proposed. The goal is to study how the introduction of a complex control pol",
    "path": "papers/24/02/2402.00676.json",
    "total_tokens": 819,
    "translated_title": "深度机器人素描：深度Q学习网络在人类素描中的应用",
    "translated_abstract": "当前强化学习算法在复杂环境中的性能取得了巨大成功，这激发了许多最新的认知科学理论方法。艺术环境被认知科学界视为丰富、自然、多感官、多文化的环境。在这项工作中，我们提出使用强化学习改进艺术机器人应用的控制。深度Q学习神经网络（DQN）是在机器人中实现强化学习最成功的算法之一。DQN方法在各种环境中生成复杂的控制策略来执行复杂的机器人应用。当前的艺术绘画机器人应用使用简单的控制法则，限制了框架的适应性。本研究提出在艺术绘画机器人应用中引入DQN。目标是研究如何引入复杂的控制策略来改进艺术机器人应用的控制。",
    "tldr": "本研究提出在艺术机器人应用中引入深度Q学习网络，旨在改进艺术机器人应用的控制策略。"
}