{
    "title": "Uncertainty-Aware Explainable Recommendation with Large Language Models",
    "abstract": "Providing explanations within the recommendation system would boost user satisfaction and foster trust, especially by elaborating on the reasons for selecting recommended items tailored to the user. The predominant approach in this domain revolves around generating text-based explanations, with a notable emphasis on applying large language models (LLMs). However, refining LLMs for explainable recommendations proves impractical due to time constraints and computing resource limitations. As an alternative, the current approach involves training the prompt rather than the LLM. In this study, we developed a model that utilizes the ID vectors of user and item inputs as prompts for GPT-2. We employed a joint training mechanism within a multi-task learning framework to optimize both the recommendation task and explanation task. This strategy enables a more effective exploration of users' interests, improving recommendation effectiveness and user satisfaction. Through the experiments, our meth",
    "link": "https://arxiv.org/abs/2402.03366",
    "context": "Title: Uncertainty-Aware Explainable Recommendation with Large Language Models\nAbstract: Providing explanations within the recommendation system would boost user satisfaction and foster trust, especially by elaborating on the reasons for selecting recommended items tailored to the user. The predominant approach in this domain revolves around generating text-based explanations, with a notable emphasis on applying large language models (LLMs). However, refining LLMs for explainable recommendations proves impractical due to time constraints and computing resource limitations. As an alternative, the current approach involves training the prompt rather than the LLM. In this study, we developed a model that utilizes the ID vectors of user and item inputs as prompts for GPT-2. We employed a joint training mechanism within a multi-task learning framework to optimize both the recommendation task and explanation task. This strategy enables a more effective exploration of users' interests, improving recommendation effectiveness and user satisfaction. Through the experiments, our meth",
    "path": "papers/24/02/2402.03366.json",
    "total_tokens": 876,
    "translated_title": "带有大型语言模型的不确定性感知可解释推荐",
    "translated_abstract": "在推荐系统内提供解释能够提升用户满意度并建立信任，特别是通过详细说明为用户定制推荐项目的原因。当前领域中主要的方法是生成基于文本的解释，而大型语言模型（LLMs）的应用尤为突出。然而，由于时间和计算资源限制，改进LLMs以实现可解释的推荐在实践上是不可行的。作为替代方案，当前的方法是训练提示而不是LLM。在这项研究中，我们开发了一个模型，利用用户和项目输入的ID向量作为GPT-2的提示。我们在多任务学习框架中采用联合训练机制，优化推荐任务和解释任务。这种策略能够更有效地探索用户的兴趣，提高推荐效果和用户满意度。通过实验，我们的方法表现出...",
    "tldr": "这项研究开发了一个模型，通过训练用户和项目输入的ID向量作为提示，利用GPT-2实现不确定性感知的可解释推荐系统。该系统采用联合训练机制并在多任务学习框架中进行优化，能够更有效地探索用户的兴趣，提高推荐效果和用户满意度。",
    "en_tdlr": "This study develops a model that utilizes GPT-2 to achieve uncertainty-aware explainable recommendation system by training the ID vectors of user and item inputs as prompts. The system employs a joint training mechanism within a multi-task learning framework to optimize recommendation effectiveness and user satisfaction through more effective exploration of users' interests."
}