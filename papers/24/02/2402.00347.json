{
    "title": "Diverse Explanations from Data-driven and Domain-driven Perspectives for Machine Learning Models",
    "abstract": "Explanations of machine learning models are important, especially in scientific areas such as chemistry, biology, and physics, where they guide future laboratory experiments and resource requirements. These explanations can be derived from well-trained machine learning models (data-driven perspective) or specific domain knowledge (domain-driven perspective). However, there exist inconsistencies between these perspectives due to accurate yet misleading machine learning models and various stakeholders with specific needs, wants, or aims. This paper calls attention to these inconsistencies and suggests a way to find an accurate model with expected explanations that reinforce physical laws and meet stakeholders' requirements from a set of equally-good models, also known as Rashomon sets. Our goal is to foster a comprehensive understanding of these inconsistencies and ultimately contribute to the integration of eXplainable Artificial Intelligence (XAI) into scientific domains.",
    "link": "https://arxiv.org/abs/2402.00347",
    "context": "Title: Diverse Explanations from Data-driven and Domain-driven Perspectives for Machine Learning Models\nAbstract: Explanations of machine learning models are important, especially in scientific areas such as chemistry, biology, and physics, where they guide future laboratory experiments and resource requirements. These explanations can be derived from well-trained machine learning models (data-driven perspective) or specific domain knowledge (domain-driven perspective). However, there exist inconsistencies between these perspectives due to accurate yet misleading machine learning models and various stakeholders with specific needs, wants, or aims. This paper calls attention to these inconsistencies and suggests a way to find an accurate model with expected explanations that reinforce physical laws and meet stakeholders' requirements from a set of equally-good models, also known as Rashomon sets. Our goal is to foster a comprehensive understanding of these inconsistencies and ultimately contribute to the integration of eXplainable Artificial Intelligence (XAI) into scientific domains.",
    "path": "papers/24/02/2402.00347.json",
    "total_tokens": 908,
    "translated_title": "来自数据驱动和领域驱动视角的机器学习模型多样解释",
    "translated_abstract": "机器学习模型的解释是重要的，特别是在化学、生物和物理等科学领域中，它们指导未来的实验室实验和资源需求。这些解释可以从训练良好的机器学习模型（数据驱动视角）或特定领域知识（领域驱动视角）中获得。然而，由于准确但具有误导性的机器学习模型和具有特定需求、愿望或目标的各方存在不一致性。本文提出了对这些不一致性的关注，并提出了一种方法，从一组同样好的模型中找到一个具有预期解释的准确模型，以加强物理定律并满足利益相关者的要求，这些模型也被称为拉诗孟（Rashomon）模型集。我们的目标是促进对这些不一致性的全面理解，并最终为将可解释人工智能（XAI）整合到科学领域做出贡献。",
    "tldr": "本文关注机器学习模型解释的不一致性，提出了从一组同样好的模型中选择具备预期解释的准确模型的方法，以加强物理定律并满足利益相关者的要求，并为将可解释人工智能整合到科学领域做出贡献。"
}