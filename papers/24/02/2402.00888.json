{
    "title": "Security and Privacy Challenges of Large Language Models: A Survey",
    "abstract": "Large Language Models (LLMs) have demonstrated extraordinary capabilities and contributed to multiple fields, such as generating and summarizing text, language translation, and question-answering. Nowadays, LLM is becoming a very popular tool in computerized language processing tasks, with the capability to analyze complicated linguistic patterns and provide relevant and appropriate responses depending on the context. While offering significant advantages, these models are also vulnerable to security and privacy attacks, such as jailbreaking attacks, data poisoning attacks, and Personally Identifiable Information (PII) leakage attacks. This survey provides a thorough review of the security and privacy challenges of LLMs for both training data and users, along with the application-based risks in various domains, such as transportation, education, and healthcare. We assess the extent of LLM vulnerabilities, investigate emerging security and privacy attacks for LLMs, and review the potent",
    "link": "https://rss.arxiv.org/abs/2402.00888",
    "context": "Title: Security and Privacy Challenges of Large Language Models: A Survey\nAbstract: Large Language Models (LLMs) have demonstrated extraordinary capabilities and contributed to multiple fields, such as generating and summarizing text, language translation, and question-answering. Nowadays, LLM is becoming a very popular tool in computerized language processing tasks, with the capability to analyze complicated linguistic patterns and provide relevant and appropriate responses depending on the context. While offering significant advantages, these models are also vulnerable to security and privacy attacks, such as jailbreaking attacks, data poisoning attacks, and Personally Identifiable Information (PII) leakage attacks. This survey provides a thorough review of the security and privacy challenges of LLMs for both training data and users, along with the application-based risks in various domains, such as transportation, education, and healthcare. We assess the extent of LLM vulnerabilities, investigate emerging security and privacy attacks for LLMs, and review the potent",
    "path": "papers/24/02/2402.00888.json",
    "total_tokens": 905,
    "translated_title": "大型语言模型的安全和隐私挑战：一项调查",
    "translated_abstract": "大型语言模型（LLM）展示了非凡的能力，并在生成和总结文本、语言翻译和问答等多个领域做出了贡献。如今，LLM正在成为计算机语言处理任务中非常流行的工具，具备分析复杂语言模式并根据上下文提供相关和适当回答的能力。然而，尽管具有显著优势，这些模型也容易受到安全和隐私攻击的威胁，如越狱攻击、数据污染攻击和个人可识别信息泄露攻击。本调查全面审查了LLM的安全和隐私挑战，包括训练数据和用户方面的问题，以及在交通、教育和医疗等各个领域中应用带来的风险。我们评估了LLM的脆弱性程度，调查了出现的安全和隐私攻击，并对潜在的解决方法进行了回顾。",
    "tldr": "大型语言模型具有卓越的能力，但也面临着安全和隐私攻击的威胁。本调查全面审查了LLM的安全和隐私挑战，涵盖了训练数据、用户和应用风险等方面，并对解决方法进行了回顾。",
    "en_tdlr": "Large Language Models (LLMs) have extraordinary capabilities but are also vulnerable to security and privacy attacks. This survey thoroughly reviews the security and privacy challenges of LLMs, covering aspects such as training data, users, and application risks, and provides a review of potential solutions."
}