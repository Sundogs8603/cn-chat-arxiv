{
    "title": "LiGNN: Graph Neural Networks at LinkedIn",
    "abstract": "arXiv:2402.11139v1 Announce Type: cross  Abstract: In this paper, we present LiGNN, a deployed large-scale Graph Neural Networks (GNNs) Framework. We share our insight on developing and deployment of GNNs at large scale at LinkedIn. We present a set of algorithmic improvements to the quality of GNN representation learning including temporal graph architectures with long term losses, effective cold start solutions via graph densification, ID embeddings and multi-hop neighbor sampling. We explain how we built and sped up by 7x our large-scale training on LinkedIn graphs with adaptive sampling of neighbors, grouping and slicing of training data batches, specialized shared-memory queue and local gradient optimization. We summarize our deployment lessons and learnings gathered from A/B test experiments. The techniques presented in this work have contributed to an approximate relative improvements of 1% of Job application hearing back rate, 2% Ads CTR lift, 0.5% of Feed engaged daily active ",
    "link": "https://arxiv.org/abs/2402.11139",
    "context": "Title: LiGNN: Graph Neural Networks at LinkedIn\nAbstract: arXiv:2402.11139v1 Announce Type: cross  Abstract: In this paper, we present LiGNN, a deployed large-scale Graph Neural Networks (GNNs) Framework. We share our insight on developing and deployment of GNNs at large scale at LinkedIn. We present a set of algorithmic improvements to the quality of GNN representation learning including temporal graph architectures with long term losses, effective cold start solutions via graph densification, ID embeddings and multi-hop neighbor sampling. We explain how we built and sped up by 7x our large-scale training on LinkedIn graphs with adaptive sampling of neighbors, grouping and slicing of training data batches, specialized shared-memory queue and local gradient optimization. We summarize our deployment lessons and learnings gathered from A/B test experiments. The techniques presented in this work have contributed to an approximate relative improvements of 1% of Job application hearing back rate, 2% Ads CTR lift, 0.5% of Feed engaged daily active ",
    "path": "papers/24/02/2402.11139.json",
    "total_tokens": 924,
    "translated_title": "LiGNN: 领英上的图神经网络",
    "translated_abstract": "在本文中，我们提出了LiGNN，一种已部署的大规模图神经网络（GNNs）框架。我们分享了在领英上开发和部署GNNs的见解。我们提出了一组算法改进，包括具有长期损失的时间图架构，通过图密集化实现的有效冷启动解决方案，ID嵌入和多跳邻居采样，以改进GNN表示学习的质量。我们解释了如何通过邻居的自适应采样，对训练数据批次进行分组和切片，专门的共享内存队列和本地梯度优化将LinkedIn图的大规模训练加快7倍。我们总结了从A/B测试实验中获得的部署经验和教训。本文介绍的技术已经为工作申请回复率的相对改善率约为1％，广告点击率提升2％，Feed每日活跃用户提高0.5％做出了贡献。",
    "tldr": "本文介绍了在领英上开发和部署的LiGNN框架，包括对GNN表示学习的算法改进和大规模训练优化，为工作申请回复率、广告点击率和Feed每日活跃用户提高带来了约1%-2%的相对改善。",
    "en_tdlr": "This paper presents LiGNN, a deployed large-scale Graph Neural Networks (GNNs) Framework at LinkedIn, with algorithmic improvements for GNN representation learning and optimizations for large-scale training, contributing to approximately 1%-2% relative improvements in job application hearing back rate, Ads CTR lift, and Feed engaged daily active users."
}