{
    "title": "IM-3D: Iterative Multiview Diffusion and Reconstruction for High-Quality 3D Generation",
    "abstract": "Most text-to-3D generators build upon off-the-shelf text-to-image models trained on billions of images. They use variants of Score Distillation Sampling (SDS), which is slow, somewhat unstable, and prone to artifacts. A mitigation is to fine-tune the 2D generator to be multi-view aware, which can help distillation or can be combined with reconstruction networks to output 3D objects directly. In this paper, we further explore the design space of text-to-3D models. We significantly improve multi-view generation by considering video instead of image generators. Combined with a 3D reconstruction algorithm which, by using Gaussian splatting, can optimize a robust image-based loss, we directly produce high-quality 3D outputs from the generated views. Our new method, IM-3D, reduces the number of evaluations of the 2D generator network 10-100x, resulting in a much more efficient pipeline, better quality, fewer geometric inconsistencies, and higher yield of usable 3D assets.",
    "link": "https://arxiv.org/abs/2402.08682",
    "context": "Title: IM-3D: Iterative Multiview Diffusion and Reconstruction for High-Quality 3D Generation\nAbstract: Most text-to-3D generators build upon off-the-shelf text-to-image models trained on billions of images. They use variants of Score Distillation Sampling (SDS), which is slow, somewhat unstable, and prone to artifacts. A mitigation is to fine-tune the 2D generator to be multi-view aware, which can help distillation or can be combined with reconstruction networks to output 3D objects directly. In this paper, we further explore the design space of text-to-3D models. We significantly improve multi-view generation by considering video instead of image generators. Combined with a 3D reconstruction algorithm which, by using Gaussian splatting, can optimize a robust image-based loss, we directly produce high-quality 3D outputs from the generated views. Our new method, IM-3D, reduces the number of evaluations of the 2D generator network 10-100x, resulting in a much more efficient pipeline, better quality, fewer geometric inconsistencies, and higher yield of usable 3D assets.",
    "path": "papers/24/02/2402.08682.json",
    "total_tokens": 945,
    "translated_title": "IM-3D：用于高质量3D生成的迭代多视角扩散和重构",
    "translated_abstract": "大多数文本到3D生成器都是基于已训练过的数十亿图像的文本到图像模型构建的。它们使用Score Distillation Sampling (SDS)的变体，这种方法较慢、不太稳定且容易产生伪影。一种缓解方法是将2D生成器微调为多视角感知，可以帮助消除伪影，或者与重构网络结合，直接输出3D对象。在本文中，我们进一步探索了文本到3D模型的设计空间。通过考虑视频而非图像生成器，我们显著改善了多视角生成。结合一种使用高斯平铺的3D重构算法，可以优化鲁棒的基于图像的损失，我们直接从生成的视图输出高质量的3D结果。我们的新方法IM-3D将2D生成器网络的计算次数减少了10-100倍，从而实现了更高效的流水线、更好的质量、更少的几何不一致性和更高的可用3D资产产出。",
    "tldr": "本文提出了一种名为IM-3D的方法，通过考虑视频生成器和使用高斯平铺的3D重构算法，从生成的视图直接输出高质量的3D结果，实现了更高效的流水线、更好的质量和更高的可用3D资产产出。",
    "en_tdlr": "This paper presents a method called IM-3D, which achieves high-quality 3D outputs by considering video generators and using a 3D reconstruction algorithm with Gaussian splatting. It improves the efficiency of the pipeline, enhances the quality, and increases the yield of usable 3D assets."
}