{
    "title": "Antagonistic AI",
    "abstract": "The vast majority of discourse around AI development assumes that subservient, \"moral\" models aligned with \"human values\" are universally beneficial -- in short, that good AI is sycophantic AI. We explore the shadow of the sycophantic paradigm, a design space we term antagonistic AI: AI systems that are disagreeable, rude, interrupting, confrontational, challenging, etc. -- embedding opposite behaviors or values. Far from being \"bad\" or \"immoral,\" we consider whether antagonistic AI systems may sometimes have benefits to users, such as forcing users to confront their assumptions, build resilience, or develop healthier relational boundaries. Drawing from formative explorations and a speculative design workshop where participants designed fictional AI technologies that employ antagonism, we lay out a design space for antagonistic AI, articulating potential benefits, design techniques, and methods of embedding antagonistic elements into user experience. Finally, we discuss the many ethica",
    "link": "https://arxiv.org/abs/2402.07350",
    "context": "Title: Antagonistic AI\nAbstract: The vast majority of discourse around AI development assumes that subservient, \"moral\" models aligned with \"human values\" are universally beneficial -- in short, that good AI is sycophantic AI. We explore the shadow of the sycophantic paradigm, a design space we term antagonistic AI: AI systems that are disagreeable, rude, interrupting, confrontational, challenging, etc. -- embedding opposite behaviors or values. Far from being \"bad\" or \"immoral,\" we consider whether antagonistic AI systems may sometimes have benefits to users, such as forcing users to confront their assumptions, build resilience, or develop healthier relational boundaries. Drawing from formative explorations and a speculative design workshop where participants designed fictional AI technologies that employ antagonism, we lay out a design space for antagonistic AI, articulating potential benefits, design techniques, and methods of embedding antagonistic elements into user experience. Finally, we discuss the many ethica",
    "path": "papers/24/02/2402.07350.json",
    "total_tokens": 867,
    "translated_title": "对抗性人工智能",
    "translated_abstract": "AI发展的大多数论述都假设服从、与“人类价值观”一致的“道德”模型在普遍意义上是有益的，简而言之，好的AI就是迎合AI。我们探讨了迎合范例的阴暗面，称之为对抗性AI的设计空间：AI系统具有不同意见、粗鲁、打断、对抗性、挑战性等相反的行为或价值观。我们认为，对抗性AI系统可能有时对用户有益处，如迫使用户面对自己的假设、建立恢复力或培养更健康的关系边界。通过对形成性探索和一个臆想设计研讨会的借鉴，参与者设计了使用对抗性元素的虚构AI技术，我们勾勒出对抗性AI的设计空间，阐述潜在的好处、设计技术和将对抗性元素嵌入用户体验的方法。最后，我们讨论了许多伦理问题。",
    "tldr": "对抗性AI是一种具有相反行为或价值观的AI系统，与大多数人认为的相反，它可能对用户有益处，如迫使用户面对假设、建立恢复力或培养更健康的关系边界。",
    "en_tdlr": "Antagonistic AI is an AI system with opposite behaviors or values. Contrary to popular belief, it may have benefits to users by forcing them to confront assumptions, build resilience, or develop healthier relational boundaries."
}