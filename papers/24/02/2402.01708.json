{
    "title": "Not My Voice! A Taxonomy of Ethical and Safety Harms of Speech Generators",
    "abstract": "The rapid and wide-scale adoption of AI to generate human speech poses a range of significant ethical and safety risks to society that need to be addressed. For example, a growing number of speech generation incidents are associated with swatting attacks in the United States, where anonymous perpetrators create synthetic voices that call police officers to close down schools and hospitals, or to violently gain access to innocent citizens' homes. Incidents like this demonstrate that multimodal generative AI risks and harms do not exist in isolation, but arise from the interactions of multiple stakeholders and technical AI systems. In this paper we analyse speech generation incidents to study how patterns of specific harms arise. We find that specific harms can be categorised according to the exposure of affected individuals, that is to say whether they are a subject of, interact with, suffer due to, or are excluded from speech generation systems. Similarly, specific harms are also a con",
    "link": "https://arxiv.org/abs/2402.01708",
    "context": "Title: Not My Voice! A Taxonomy of Ethical and Safety Harms of Speech Generators\nAbstract: The rapid and wide-scale adoption of AI to generate human speech poses a range of significant ethical and safety risks to society that need to be addressed. For example, a growing number of speech generation incidents are associated with swatting attacks in the United States, where anonymous perpetrators create synthetic voices that call police officers to close down schools and hospitals, or to violently gain access to innocent citizens' homes. Incidents like this demonstrate that multimodal generative AI risks and harms do not exist in isolation, but arise from the interactions of multiple stakeholders and technical AI systems. In this paper we analyse speech generation incidents to study how patterns of specific harms arise. We find that specific harms can be categorised according to the exposure of affected individuals, that is to say whether they are a subject of, interact with, suffer due to, or are excluded from speech generation systems. Similarly, specific harms are also a con",
    "path": "papers/24/02/2402.01708.json",
    "total_tokens": 925,
    "translated_title": "不是我的声音！语音生成器的伦理和安全伤害分类法",
    "translated_abstract": "人工智能广泛采用语音生成技术给社会带来了一系列重大的伦理和安全风险，亟需解决。例如，在美国，越来越多的语音生成事件与警察受到恶作剧袭击有关，匿名行为者制造合成的声音打电话给警察，要求关闭学校和医院，或者以暴力手段进入无辜市民的家中。这样的事件表明，多模态生成人工智能的风险和伤害并不存在于孤立状态，而是源于多个利益相关者和技术人工智能系统之间的互动。本文通过分析语音生成事件，研究特定伤害模式的出现。我们发现特定伤害可以根据受影响个体的曝光程度进行分类，即他们是语音生成系统的主体、与之互动、受其影响或被排除在外。同样，特定伤害也与相关利益相关者和技术系统之间的相互作用有关。",
    "tldr": "语音生成技术的广泛应用给社会带来了伦理和安全风险。本文通过分析语音生成事件，总结出特定伤害模式，并将其分类。这些特定伤害涉及到受影响个体的曝光程度以及相关利益相关者和技术系统之间的相互作用。"
}