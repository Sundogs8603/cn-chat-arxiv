{
    "title": "LEIA: Facilitating Cross-Lingual Knowledge Transfer in Language Models with Entity-based Data Augmentation",
    "abstract": "arXiv:2402.11485v1 Announce Type: cross  Abstract: Adapting English-based large language models (LLMs) to other languages has become increasingly popular due to the efficiency and potential of cross-lingual transfer. However, existing language adaptation methods often overlook the benefits of cross-lingual supervision. In this study, we introduce LEIA, a language adaptation tuning method that utilizes Wikipedia entity names aligned across languages. This method involves augmenting the target language corpus with English entity names and training the model using left-to-right language modeling. We assess LEIA on diverse question answering datasets using 7B-parameter LLMs, demonstrating significant performance gains across various non-English languages. The source code is available at https://github.com/studio-ousia/leia.",
    "link": "https://arxiv.org/abs/2402.11485",
    "context": "Title: LEIA: Facilitating Cross-Lingual Knowledge Transfer in Language Models with Entity-based Data Augmentation\nAbstract: arXiv:2402.11485v1 Announce Type: cross  Abstract: Adapting English-based large language models (LLMs) to other languages has become increasingly popular due to the efficiency and potential of cross-lingual transfer. However, existing language adaptation methods often overlook the benefits of cross-lingual supervision. In this study, we introduce LEIA, a language adaptation tuning method that utilizes Wikipedia entity names aligned across languages. This method involves augmenting the target language corpus with English entity names and training the model using left-to-right language modeling. We assess LEIA on diverse question answering datasets using 7B-parameter LLMs, demonstrating significant performance gains across various non-English languages. The source code is available at https://github.com/studio-ousia/leia.",
    "path": "papers/24/02/2402.11485.json",
    "total_tokens": 805,
    "translated_title": "LEIA: 利用基于实体的数据增强在语言模型中促进跨语言知识转移",
    "translated_abstract": "将基于英语的大型语言模型（LLMs）适应其他语言的操作由于跨语言转移的效率和潜力而变得越来越受欢迎。然而，现有的语言适应方法常常忽视跨语言监督的好处。在本研究中，我们介绍LEIA，一种利用跨语言对齐的维基百科实体名称的语言适应调整方法。该方法涉及使用英语实体名称增强目标语言语料库，并使用从左到右的语言建模训练模型。我们在多样的问答数据集上评估LEIA，使用7B参数的LLMs，展示了在各种非英语语言上的显著性能增益。源代码可在https://github.com/studio-ousia/leia上获得。",
    "tldr": "LEIA是一种语言适应调整方法，利用维基百科实体名称跨语言增强目标语言语料库，通过左到右的语言建模训练，显著提高了各种非英语语言的表现。",
    "en_tdlr": "LEIA is a language adaptation tuning method that utilizes Wikipedia entity names aligned across languages to augment the target language corpus, demonstrating significant performance gains across various non-English languages through left-to-right language modeling."
}