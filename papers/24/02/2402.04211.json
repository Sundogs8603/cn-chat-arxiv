{
    "title": "Variational Shapley Network: A Probabilistic Approach to Self-Explaining Shapley values with Uncertainty Quantification",
    "abstract": "Shapley values have emerged as a foundational tool in machine learning (ML) for elucidating model decision-making processes. Despite their widespread adoption and unique ability to satisfy essential explainability axioms, computational challenges persist in their estimation when ($i$) evaluating a model over all possible subset of input feature combinations, ($ii$) estimating model marginals, and ($iii$) addressing variability in explanations. We introduce a novel, self-explaining method that simplifies the computation of Shapley values significantly, requiring only a single forward pass. Recognizing the deterministic treatment of Shapley values as a limitation, we explore incorporating a probabilistic framework to capture the inherent uncertainty in explanations. Unlike alternatives, our technique does not rely directly on the observed data space to estimate marginals; instead, it uses adaptable baseline values derived from a latent, feature-specific embedding space, generated by a no",
    "link": "https://arxiv.org/abs/2402.04211",
    "context": "Title: Variational Shapley Network: A Probabilistic Approach to Self-Explaining Shapley values with Uncertainty Quantification\nAbstract: Shapley values have emerged as a foundational tool in machine learning (ML) for elucidating model decision-making processes. Despite their widespread adoption and unique ability to satisfy essential explainability axioms, computational challenges persist in their estimation when ($i$) evaluating a model over all possible subset of input feature combinations, ($ii$) estimating model marginals, and ($iii$) addressing variability in explanations. We introduce a novel, self-explaining method that simplifies the computation of Shapley values significantly, requiring only a single forward pass. Recognizing the deterministic treatment of Shapley values as a limitation, we explore incorporating a probabilistic framework to capture the inherent uncertainty in explanations. Unlike alternatives, our technique does not rely directly on the observed data space to estimate marginals; instead, it uses adaptable baseline values derived from a latent, feature-specific embedding space, generated by a no",
    "path": "papers/24/02/2402.04211.json",
    "total_tokens": 889,
    "translated_title": "变分Shapley网络：一种概率化的方法用于具有不确定性量化的自解释Shapley值",
    "translated_abstract": "Shapley值已经成为机器学习中阐明模型决策过程的基础工具。尽管它们被广泛采用并具有满足重要可解释性公理的独特能力，但在估计过程中仍然存在计算挑战，包括（i）对模型在所有可能的输入特征组合上进行评估，（ii）估计模型的边际值，以及（iii）处理解释的可变性。我们提出了一种新颖的自解释方法，显著简化了Shapley值的计算，只需要一次前向传递。鉴于Shapley值的确定性处理被认为是一种限制，我们探索了将概率框架纳入其中以捕捉解释中固有的不确定性。与其他替代方法不同，我们的技术不直接依赖于观测数据空间来估计边际值；相反，它使用从潜在的、特定于特征的嵌入空间中派生出的可适应的基线值。",
    "tldr": "本研究引入了变分Shapley网络，通过概率化的方法简化了计算Shapley值的过程，并解决了估计模型边际值和处理解释可变性的挑战。",
    "en_tdlr": "The Variational Shapley Network is introduced as a probabilistic approach to simplify the computation of Shapley values, addressing challenges in estimating model marginals and handling variability in explanations."
}