{
    "title": "SpecFormer: Guarding Vision Transformer Robustness via Maximum Singular Value Penalization",
    "abstract": "Vision Transformers (ViTs) have gained prominence as a preferred choice for a wide range of computer vision tasks due to their exceptional performance. However, their widespread adoption has raised concerns about security in the face of malicious attacks. Most existing methods rely on empirical adjustments during the training process, lacking a clear theoretical foundation. In this study, we address this gap by introducing SpecFormer, specifically designed to enhance ViTs' resilience against adversarial attacks, with support from carefully derived theoretical guarantees. We establish local Lipschitz bounds for the self-attention layer and introduce a novel approach, Maximum Singular Value Penalization (MSVP), to attain precise control over these bounds. We seamlessly integrate MSVP into ViTs' attention layers, using the power iteration method for enhanced computational efficiency. The modified model, SpecFormer, effectively reduces the spectral norms of attention weight matrices, there",
    "link": "https://arxiv.org/abs/2402.03317",
    "context": "Title: SpecFormer: Guarding Vision Transformer Robustness via Maximum Singular Value Penalization\nAbstract: Vision Transformers (ViTs) have gained prominence as a preferred choice for a wide range of computer vision tasks due to their exceptional performance. However, their widespread adoption has raised concerns about security in the face of malicious attacks. Most existing methods rely on empirical adjustments during the training process, lacking a clear theoretical foundation. In this study, we address this gap by introducing SpecFormer, specifically designed to enhance ViTs' resilience against adversarial attacks, with support from carefully derived theoretical guarantees. We establish local Lipschitz bounds for the self-attention layer and introduce a novel approach, Maximum Singular Value Penalization (MSVP), to attain precise control over these bounds. We seamlessly integrate MSVP into ViTs' attention layers, using the power iteration method for enhanced computational efficiency. The modified model, SpecFormer, effectively reduces the spectral norms of attention weight matrices, there",
    "path": "papers/24/02/2402.03317.json",
    "total_tokens": 907,
    "translated_title": "SpecFormer：通过最大奇异值惩罚来保护视觉Transformer的稳健性",
    "translated_abstract": "视觉Transformer（ViTs）因其出色的性能而成为广泛使用的计算机视觉任务的首选。然而，其广泛应用引起了对面对恶意攻击时安全性的担忧。大多数现有方法依赖于训练过程中的经验调整，缺乏明确的理论基础。在本研究中，我们通过引入SpecFormer来填补这一空白，该方法专门设计用于增强ViTs对对抗性攻击的韧性，并得到了仔细推导的理论保证的支持。我们为自注意层建立了本地Lipschitz边界，并引入了一种新颖的方法，最大奇异值惩罚（MSVP），以精确控制这些边界。我们使用幂迭代方法将MSVP无缝集成到ViTs的注意力层中，以提高计算效率。修改后的模型SpecFormer有效地降低了注意力权重矩阵的谱范数，",
    "tldr": "该论文介绍了SpecFormer，一种通过最大奇异值惩罚来增强视觉Transformer（ViTs）对对抗性攻击的韧性的方法。该方法通过引入局部Lipschitz边界和最大奇异值惩罚方法（MSVP），有效地降低了注意力权重矩阵的谱范数。",
    "en_tdlr": "This paper introduces SpecFormer, a method that enhances the resilience of Vision Transformers (ViTs) against adversarial attacks through maximum singular value penalization. It effectively reduces the spectral norms of attention weight matrices by introducing local Lipschitz bounds and the Maximum Singular Value Penalization (MSVP) method."
}