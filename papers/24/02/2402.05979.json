{
    "title": "On the Standardization of Behavioral Use Clauses and Their Adoption for Responsible Licensing of AI",
    "abstract": "Growing concerns over negligent or malicious uses of AI have increased the appetite for tools that help manage the risks of the technology. In 2018, licenses with behaviorial-use clauses (commonly referred to as Responsible AI Licenses) were proposed to give developers a framework for releasing AI assets while specifying their users to mitigate negative applications. As of the end of 2023, on the order of 40,000 software and model repositories have adopted responsible AI licenses licenses. Notable models licensed with behavioral use clauses include BLOOM (language) and LLaMA2 (language), Stable Diffusion (image), and GRID (robotics). This paper explores why and how these licenses have been adopted, and why and how they have been adapted to fit particular use cases. We use a mixed-methods methodology of qualitative interviews, clustering of license clauses, and quantitative analysis of license adoption. Based on this evidence we take the position that responsible AI licenses need standa",
    "link": "https://arxiv.org/abs/2402.05979",
    "context": "Title: On the Standardization of Behavioral Use Clauses and Their Adoption for Responsible Licensing of AI\nAbstract: Growing concerns over negligent or malicious uses of AI have increased the appetite for tools that help manage the risks of the technology. In 2018, licenses with behaviorial-use clauses (commonly referred to as Responsible AI Licenses) were proposed to give developers a framework for releasing AI assets while specifying their users to mitigate negative applications. As of the end of 2023, on the order of 40,000 software and model repositories have adopted responsible AI licenses licenses. Notable models licensed with behavioral use clauses include BLOOM (language) and LLaMA2 (language), Stable Diffusion (image), and GRID (robotics). This paper explores why and how these licenses have been adopted, and why and how they have been adapted to fit particular use cases. We use a mixed-methods methodology of qualitative interviews, clustering of license clauses, and quantitative analysis of license adoption. Based on this evidence we take the position that responsible AI licenses need standa",
    "path": "papers/24/02/2402.05979.json",
    "total_tokens": 939,
    "translated_title": "关于行为使用条款的标准化及其用于负责任授权人工智能的采用",
    "translated_abstract": "对AI的疏忽或恶意使用的忧虑日益增长，这增加了对帮助管理技术风险的工具的需求。2018年，提出了带有行为使用条款（通常称为负责任AI许可证）的许可证，为开发者提供了发布AI资产的框架，同时指定其用户以减轻负面应用。截至2023年底，大约有40,000个软件和模型存储库采用了负责任AI许可证。采用行为使用条款的著名模型包括BLOOM（语言）和LLaMA2（语言）、Stable Diffusion（图像）和GRID（机器人）。本文探讨了这些许可证为何以及如何被采用，以及为何以及如何被改编以适应特定的使用情况。我们采用了定性访谈、许可证条款的聚类和许可证采用的定量分析的混合方法学。根据这些证据，我们认为负责任AI许可证需要标准化。",
    "tldr": "本文研究了行为使用条款的标准化及其用于负责任授权人工智能的采用。采用了定性访谈、许可证条款的聚类和许可证采用的定量分析的混合方法学。结论是负责任AI许可证需要标准化。",
    "en_tdlr": "This paper explores the standardization and adoption of behavioral use clauses for responsible licensing of AI. Based on qualitative interviews, clustering of license clauses, and quantitative analysis of license adoption, it concludes that responsible AI licenses need standardization."
}