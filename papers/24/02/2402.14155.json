{
    "title": "Can Similarity-Based Domain-Ordering Reduce Catastrophic Forgetting for Intent Recognition?",
    "abstract": "arXiv:2402.14155v1 Announce Type: cross  Abstract: Task-oriented dialogue systems are expected to handle a constantly expanding set of intents and domains even after they have been deployed to support more and more functionalities. To live up to this expectation, it becomes critical to mitigate the catastrophic forgetting problem (CF) that occurs in continual learning (CL) settings for a task such as intent recognition. While existing dialogue systems research has explored replay-based and regularization-based methods to this end, the effect of domain ordering on the CL performance of intent recognition models remains unexplored. If understood well, domain ordering has the potential to be an orthogonal technique that can be leveraged alongside existing techniques such as experience replay. Our work fills this gap by comparing the impact of three domain-ordering strategies (min-sum path, max-sum path, random) on the CL performance of a generative intent recognition model. Our findings r",
    "link": "https://arxiv.org/abs/2402.14155",
    "context": "Title: Can Similarity-Based Domain-Ordering Reduce Catastrophic Forgetting for Intent Recognition?\nAbstract: arXiv:2402.14155v1 Announce Type: cross  Abstract: Task-oriented dialogue systems are expected to handle a constantly expanding set of intents and domains even after they have been deployed to support more and more functionalities. To live up to this expectation, it becomes critical to mitigate the catastrophic forgetting problem (CF) that occurs in continual learning (CL) settings for a task such as intent recognition. While existing dialogue systems research has explored replay-based and regularization-based methods to this end, the effect of domain ordering on the CL performance of intent recognition models remains unexplored. If understood well, domain ordering has the potential to be an orthogonal technique that can be leveraged alongside existing techniques such as experience replay. Our work fills this gap by comparing the impact of three domain-ordering strategies (min-sum path, max-sum path, random) on the CL performance of a generative intent recognition model. Our findings r",
    "path": "papers/24/02/2402.14155.json",
    "total_tokens": 892,
    "translated_title": "基于相似性的领域排序能够减少意图识别中的灾难性遗忘吗？",
    "translated_abstract": "任务导向的对话系统被期望在部署后能够处理不断增长的意图和领域，甚至在支持越来越多功能的情况下也能做到。为了达到这个期望，就变得至关重要去减轻在诸如意图识别等任务的继续学习（CL）设置中发生的灾难性遗忘问题（CF）。虽然现有的对话系统研究已经探索了基于重放和正则化的方法以达到这个目的，但领域排序对意图识别模型的继续学习性能的影响尚未被探索。如果理解得当，领域排序有潜力成为一个能够与现有技术如经验重放并行使用的方法。我们的工作通过比较三种领域排序策略（最小和路径、最大和路径、随机）对生成式意图识别模型的继续学习性能的影响来填补这一空白。我们的发现表明",
    "tldr": "研究探讨了三种领域排序策略对生成式意图识别模型继续学习性能的影响，填补了现有研究中对此方面未探索的空白。"
}