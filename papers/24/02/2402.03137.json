{
    "title": "Sociolinguistically Informed Interpretability: A Case Study on Hinglish Emotion Classification",
    "abstract": "Emotion classification is a challenging task in NLP due to the inherent idiosyncratic and subjective nature of linguistic expression, especially with code-mixed data. Pre-trained language models (PLMs) have achieved high performance for many tasks and languages, but it remains to be seen whether these models learn and are robust to the differences in emotional expression across languages. Sociolinguistic studies have shown that Hinglish speakers switch to Hindi when expressing negative emotions and to English when expressing positive emotions. To understand if language models can learn these associations, we study the effect of language on emotion prediction across 3 PLMs on a Hinglish emotion classification dataset. Using LIME and token level language ID, we find that models do learn these associations between language choice and emotional expression. Moreover, having code-mixed data present in the pre-training can augment that learning when task-specific data is scarce. We also concl",
    "link": "https://arxiv.org/abs/2402.03137",
    "context": "Title: Sociolinguistically Informed Interpretability: A Case Study on Hinglish Emotion Classification\nAbstract: Emotion classification is a challenging task in NLP due to the inherent idiosyncratic and subjective nature of linguistic expression, especially with code-mixed data. Pre-trained language models (PLMs) have achieved high performance for many tasks and languages, but it remains to be seen whether these models learn and are robust to the differences in emotional expression across languages. Sociolinguistic studies have shown that Hinglish speakers switch to Hindi when expressing negative emotions and to English when expressing positive emotions. To understand if language models can learn these associations, we study the effect of language on emotion prediction across 3 PLMs on a Hinglish emotion classification dataset. Using LIME and token level language ID, we find that models do learn these associations between language choice and emotional expression. Moreover, having code-mixed data present in the pre-training can augment that learning when task-specific data is scarce. We also concl",
    "path": "papers/24/02/2402.03137.json",
    "total_tokens": 927,
    "translated_title": "社会语言学信息的解释性: 以Hinglish情感分类为例的案例研究",
    "translated_abstract": "情感分类是自然语言处理中一项具有挑战性的任务，因为语言表达具有固有的特殊性和主观性，尤其是在混合语言数据中。预训练语言模型（PLMs）已经在许多任务和语言中取得了很高的性能，但是否这些模型能够学习和适应不同语言间情感表达的差异仍然有待考验。社会语言学研究表明，Hinglish说话者在表达消极情绪时转用印地语，在表达积极情绪时转用英语。为了了解语言模型是否能学习这些关联，我们研究了3个PLMs在一个Hinglish情感分类数据集上语言对情感预测的影响。通过使用LIME和基于词元的语言ID，我们发现模型确实学习到了语言选择和情感表达之间的关联。此外，当任务特定数据稀缺时，预训练模型中存在混合语言数据可以增强这种学习。我们还得出结论，使用社会语言学信息可以提高情感分类的解释性。",
    "tldr": "通过研究Hinglish情感分类，我们发现预训练语言模型能够学习到语言选择与情感表达之间的关联，尤其是在混合语言数据存在时。这对于情感分类的解释性具有重要意义。",
    "en_tdlr": "By studying Hinglish emotion classification, we find that pre-trained language models can learn the associations between language choice and emotional expression, especially with mixed-language data present. This has important implications for the interpretability of emotion classification."
}