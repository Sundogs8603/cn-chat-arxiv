{
    "title": "BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering",
    "abstract": "arXiv:2402.11129v1 Announce Type: new  Abstract: Retrieval-augmented Large Language Models (LLMs) offer substantial benefits in enhancing performance across knowledge-intensive scenarios. However, these methods often face challenges with complex inputs and encounter difficulties due to noisy knowledge retrieval, notably hindering model effectiveness. To address this issue, we introduce BlendFilter, a novel approach that elevates retrieval-augmented LLMs by integrating query generation blending with knowledge filtering. BlendFilter proposes the blending process through its query generation method, which integrates both external and internal knowledge augmentation with the original query, ensuring comprehensive information gathering. Additionally, our distinctive knowledge filtering module capitalizes on the intrinsic capabilities of the LLM, effectively eliminating extraneous data. We conduct extensive experiments on three open-domain question answering benchmarks, and the findings clea",
    "link": "https://arxiv.org/abs/2402.11129",
    "context": "Title: BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering\nAbstract: arXiv:2402.11129v1 Announce Type: new  Abstract: Retrieval-augmented Large Language Models (LLMs) offer substantial benefits in enhancing performance across knowledge-intensive scenarios. However, these methods often face challenges with complex inputs and encounter difficulties due to noisy knowledge retrieval, notably hindering model effectiveness. To address this issue, we introduce BlendFilter, a novel approach that elevates retrieval-augmented LLMs by integrating query generation blending with knowledge filtering. BlendFilter proposes the blending process through its query generation method, which integrates both external and internal knowledge augmentation with the original query, ensuring comprehensive information gathering. Additionally, our distinctive knowledge filtering module capitalizes on the intrinsic capabilities of the LLM, effectively eliminating extraneous data. We conduct extensive experiments on three open-domain question answering benchmarks, and the findings clea",
    "path": "papers/24/02/2402.11129.json",
    "total_tokens": 835,
    "translated_title": "BlendFilter: 通过查询生成混合和知识过滤推进检索增强型大型语言模型",
    "translated_abstract": "arXiv:2402.11129v1 公告类型：新摘要：检索增强型大型语言模型（LLM）在提升知识密集型场景中的性能方面具有显著优势。然而，这些方法经常面临复杂输入的挑战，并且由于嘈杂的知识检索而遇到困难，明显阻碍了模型的有效性。为解决这个问题，我们引入了BlendFilter，一种通过将查询生成混合与知识过滤相结合来提升检索增强型LLM的新方法。BlendFilter提出了通过其查询生成方法的混合过程，该方法将外部知识和内部知识增强与原始查询相结合，确保全面收集信息。此外，我们独特的知识过滤模块充分利用了LLM的固有能力，有效消除了多余的数据。我们在三个开放域问答基准上进行了大量实验，结果表明",
    "tldr": "BlendFilter通过查询生成混合和知识过滤方法提升了检索增强型大型语言模型，在多领域的问答任务中取得了显著的性能提升。",
    "en_tdlr": "BlendFilter enhances retrieval-augmented large language models by blending query generation and knowledge filtering, achieving significant performance improvements in multi-domain question answering tasks."
}