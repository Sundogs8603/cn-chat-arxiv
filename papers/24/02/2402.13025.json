{
    "title": "CFEVER: A Chinese Fact Extraction and VERification Dataset",
    "abstract": "arXiv:2402.13025v1 Announce Type: cross  Abstract: We present CFEVER, a Chinese dataset designed for Fact Extraction and VERification. CFEVER comprises 30,012 manually created claims based on content in Chinese Wikipedia. Each claim in CFEVER is labeled as \"Supports\", \"Refutes\", or \"Not Enough Info\" to depict its degree of factualness. Similar to the FEVER dataset, claims in the \"Supports\" and \"Refutes\" categories are also annotated with corresponding evidence sentences sourced from single or multiple pages in Chinese Wikipedia. Our labeled dataset holds a Fleiss' kappa value of 0.7934 for five-way inter-annotator agreement. In addition, through the experiments with the state-of-the-art approaches developed on the FEVER dataset and a simple baseline for CFEVER, we demonstrate that our dataset is a new rigorous benchmark for factual extraction and verification, which can be further used for developing automated systems to alleviate human fact-checking efforts. CFEVER is available at htt",
    "link": "https://arxiv.org/abs/2402.13025",
    "context": "Title: CFEVER: A Chinese Fact Extraction and VERification Dataset\nAbstract: arXiv:2402.13025v1 Announce Type: cross  Abstract: We present CFEVER, a Chinese dataset designed for Fact Extraction and VERification. CFEVER comprises 30,012 manually created claims based on content in Chinese Wikipedia. Each claim in CFEVER is labeled as \"Supports\", \"Refutes\", or \"Not Enough Info\" to depict its degree of factualness. Similar to the FEVER dataset, claims in the \"Supports\" and \"Refutes\" categories are also annotated with corresponding evidence sentences sourced from single or multiple pages in Chinese Wikipedia. Our labeled dataset holds a Fleiss' kappa value of 0.7934 for five-way inter-annotator agreement. In addition, through the experiments with the state-of-the-art approaches developed on the FEVER dataset and a simple baseline for CFEVER, we demonstrate that our dataset is a new rigorous benchmark for factual extraction and verification, which can be further used for developing automated systems to alleviate human fact-checking efforts. CFEVER is available at htt",
    "path": "papers/24/02/2402.13025.json",
    "total_tokens": 849,
    "translated_title": "CFEVER：一个用于汉语事实提取和验证的数据集",
    "translated_abstract": "我们介绍了CFEVER，这是一个专为事实提取和验证而设计的汉语数据集。CFEVER包括30,012个基于中文维基百科内容手动创建的声明。每个CFEVER中的声明都标记为“支持”、“反驳”或“信息不足”，以描述其事实程度。类似于FEVER数据集，支持和反驳类别中的声明也标有对应的证据句，这些证据句取自中文维基百科的单个或多个页面。我们的标记数据集在五路标注者间一致性方面具有0.7934的Fleiss' kappa值。此外，通过对FEVER数据集上开发的最先进方法以及对CFEVER的简单基准的实验，我们证明了我们的数据集是一个新的苛刻事实提取和验证基准，可进一步用于开发自动化系统，减轻人类事实核查的工作量。CFEVER可在网址处获得。",
    "tldr": "CFEVER是一个为事实提取和验证而设计的汉语数据集，提供了严格的标准和对应证据，可用于开发自动化系统，减轻人工核查的工作量。",
    "en_tdlr": "CFEVER is a Chinese dataset designed for fact extraction and verification, providing rigorous standards and corresponding evidence for the development of automated systems to reduce manual fact-checking efforts."
}