{
    "title": "When in Doubt, Think Slow: Iterative Reasoning with Latent Imagination",
    "abstract": "arXiv:2402.15283v1 Announce Type: cross  Abstract: In an unfamiliar setting, a model-based reinforcement learning agent can be limited by the accuracy of its world model. In this work, we present a novel, training-free approach to improving the performance of such agents separately from planning and learning. We do so by applying iterative inference at decision-time, to fine-tune the inferred agent states based on the coherence of future state representations. Our approach achieves a consistent improvement in both reconstruction accuracy and task performance when applied to visual 3D navigation tasks. We go on to show that considering more future states further improves the performance of the agent in partially-observable environments, but not in a fully-observable one. Finally, we demonstrate that agents with less training pre-evaluation benefit most from our approach.",
    "link": "https://arxiv.org/abs/2402.15283",
    "context": "Title: When in Doubt, Think Slow: Iterative Reasoning with Latent Imagination\nAbstract: arXiv:2402.15283v1 Announce Type: cross  Abstract: In an unfamiliar setting, a model-based reinforcement learning agent can be limited by the accuracy of its world model. In this work, we present a novel, training-free approach to improving the performance of such agents separately from planning and learning. We do so by applying iterative inference at decision-time, to fine-tune the inferred agent states based on the coherence of future state representations. Our approach achieves a consistent improvement in both reconstruction accuracy and task performance when applied to visual 3D navigation tasks. We go on to show that considering more future states further improves the performance of the agent in partially-observable environments, but not in a fully-observable one. Finally, we demonstrate that agents with less training pre-evaluation benefit most from our approach.",
    "path": "papers/24/02/2402.15283.json",
    "total_tokens": 816,
    "translated_title": "犹豫时，要慢慢思考：具有潜在想象力的迭代推理",
    "translated_abstract": "在一个陌生的环境中，基于模型的强化学习代理可能会受到其世界模型准确性的限制。在这项工作中，我们提出了一种改进这类代理性能的新颖、无需训练的方法，与规划和学习分开。我们通过在决策时应用迭代推理来进行微调，以基于未来状态表示的连贯性来改进推断的代理状态。我们的方法在应用于视觉3D导航任务时，在重构精度和任务性能方面实现了一致的改进。我们进一步展示，在部分可观察环境中考虑更多的未来状态会进一步提高代理的性能，但在完全可观察的环境中不会。最后，我们证明训练预评估较少的代理从我们的方法中获益最多。",
    "tldr": "通过在决策时应用迭代推理来微调推断的代理状态，能够在视觉3D导航任务中取得一致的性能改进，并在部分可观察环境中得到更好的表现。",
    "en_tdlr": "By applying iterative reasoning at decision time to fine-tune the inferred agent states, consistent performance improvements can be achieved in visual 3D navigation tasks, with better performance in partially observable environments."
}