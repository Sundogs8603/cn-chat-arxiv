{
    "title": "On the Tip of the Tongue: Analyzing Conceptual Representation in Large Language Models with Reverse-Dictionary Probe",
    "abstract": "arXiv:2402.14404v1 Announce Type: cross  Abstract: Probing and enhancing large language models' reasoning capacity remains a crucial open question. Here we re-purpose the reverse dictionary task as a case study to probe LLMs' capacity for conceptual inference. We use in-context learning to guide the models to generate the term for an object concept implied in a linguistic description. Models robustly achieve high accuracy in this task, and their representation space encodes information about object categories and fine-grained features. Further experiments suggest that the conceptual inference ability as probed by the reverse-dictionary task predicts model's general reasoning performance across multiple benchmarks, despite similar syntactic generalization behaviors across models. Explorative analyses suggest that prompting LLMs with description$\\Rightarrow$word examples may induce generalization beyond surface-level differences in task construals and facilitate models on broader commons",
    "link": "https://arxiv.org/abs/2402.14404",
    "context": "Title: On the Tip of the Tongue: Analyzing Conceptual Representation in Large Language Models with Reverse-Dictionary Probe\nAbstract: arXiv:2402.14404v1 Announce Type: cross  Abstract: Probing and enhancing large language models' reasoning capacity remains a crucial open question. Here we re-purpose the reverse dictionary task as a case study to probe LLMs' capacity for conceptual inference. We use in-context learning to guide the models to generate the term for an object concept implied in a linguistic description. Models robustly achieve high accuracy in this task, and their representation space encodes information about object categories and fine-grained features. Further experiments suggest that the conceptual inference ability as probed by the reverse-dictionary task predicts model's general reasoning performance across multiple benchmarks, despite similar syntactic generalization behaviors across models. Explorative analyses suggest that prompting LLMs with description$\\Rightarrow$word examples may induce generalization beyond surface-level differences in task construals and facilitate models on broader commons",
    "path": "papers/24/02/2402.14404.json",
    "total_tokens": 887,
    "translated_title": "在巨大语言模型中分析概念表达：借助反向词典探查",
    "translated_abstract": "探查和增强大型语言模型的推理能力仍然是一个关键的未解问题。在这里，我们重新利用反向词典任务作为一个案例研究，来探查LLMs对概念推理的能力。我们使用上下文学习来引导模型生成一个语言描述中暗示的对象概念的术语。模型在这个任务中稳健地实现了高准确性，并且它们的表示空间编码了关于对象类别和细粒度特征的信息。进一步的实验表明，通过反向词典任务探查的概念推理能力能够预测模型在多个基准测试中的一般推理表现，尽管模型在句法泛化行为上表现相似。探索性分析表明，通过提示LLMs使用描述$\\Rightarrow$单词示例可能会诱导出超越任务构型表面差异的泛化，并促进模型对更广泛的共同性的研究",
    "tldr": "该论文通过重新利用反向词典任务的案例研究，探查了大型语言模型对概念推理的能力，发现模型在该任务中表现出高准确性，并且表示空间编码了有关对象类别和细粒度特征的信息，同时还发现该任务探查的概念推理能力能够预测模型在多个基准测试中的一般推理表现。"
}