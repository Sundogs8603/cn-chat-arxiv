{
    "title": "Interpreting Graph Neural Networks with In-Distributed Proxies",
    "abstract": "Graph Neural Networks (GNNs) have become a building block in graph data processing, with wide applications in critical domains. The growing needs to deploy GNNs in high-stakes applications necessitate explainability for users in the decision-making processes. A popular paradigm for the explainability of GNNs is to identify explainable subgraphs by comparing their labels with the ones of original graphs. This task is challenging due to the substantial distributional shift from the original graphs in the training set to the set of explainable subgraphs, which prevents accurate prediction of labels with the subgraphs. To address it, in this paper, we propose a novel method that generates proxy graphs for explainable subgraphs that are in the distribution of training data. We introduce a parametric method that employs graph generators to produce proxy graphs. A new training objective based on information theory is designed to ensure that proxy graphs not only adhere to the distribution of ",
    "link": "https://arxiv.org/abs/2402.02036",
    "context": "Title: Interpreting Graph Neural Networks with In-Distributed Proxies\nAbstract: Graph Neural Networks (GNNs) have become a building block in graph data processing, with wide applications in critical domains. The growing needs to deploy GNNs in high-stakes applications necessitate explainability for users in the decision-making processes. A popular paradigm for the explainability of GNNs is to identify explainable subgraphs by comparing their labels with the ones of original graphs. This task is challenging due to the substantial distributional shift from the original graphs in the training set to the set of explainable subgraphs, which prevents accurate prediction of labels with the subgraphs. To address it, in this paper, we propose a novel method that generates proxy graphs for explainable subgraphs that are in the distribution of training data. We introduce a parametric method that employs graph generators to produce proxy graphs. A new training objective based on information theory is designed to ensure that proxy graphs not only adhere to the distribution of ",
    "path": "papers/24/02/2402.02036.json",
    "total_tokens": 835,
    "translated_title": "用分布式代理解释图神经网络",
    "translated_abstract": "图神经网络（GNN）已成为图数据处理的重要组成部分，在关键领域广泛应用。在高风险应用中部署GNN的不断增长需求需要用户在决策过程中能够解释其原因。解释GNN的流行范式是通过比较它们与原始图的标签来识别可解释的子图。由于训练集中原始图与可解释子图集之间存在显著的分布偏移，导致无法准确预测子图的标签，这是一个具有挑战性的任务。为了解决这个问题，在本文中，我们提出了一种新的方法，用于生成与训练数据分布相符的可解释子图的代理图。我们引入了一个使用图生成器生成代理图的参数化方法。基于信息论设计了一个新的训练目标，以确保代理图不仅遵循训练数据的分布，而且便于解释。",
    "tldr": "该论文提出了一种翻译图神经网络中可解释子图的代理图的新方法，解决了训练数据分布与可解释子图集之间的分布偏移问题。",
    "en_tdlr": "This paper presents a novel method for generating proxy graphs for explainable subgraphs in graph neural networks (GNNs), addressing the distribution shift problem between the training data and the set of explainable subgraphs."
}