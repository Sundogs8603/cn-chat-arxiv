{
    "title": "Gl\\'orIA - A Generative and Open Large Language Model for Portuguese",
    "abstract": "arXiv:2402.12969v1 Announce Type: cross  Abstract: Significant strides have been made in natural language tasks, largely attributed to the emergence of powerful large language models (LLMs). These models, pre-trained on extensive and diverse corpora, have become increasingly capable of comprehending the intricacies of language. Despite the abundance of LLMs for many high-resource languages, the availability of such models remains limited for European Portuguese. We introduce Gl\\'orIA, a robust European Portuguese decoder LLM. To pre-train Gl\\'orIA, we assembled a comprehensive PT-PT text corpus comprising 35 billion tokens from various sources. We present our pre-training methodology, followed by an assessment of the model's effectiveness on multiple downstream tasks. Additionally, to evaluate our models' language modeling capabilities, we introduce CALAME-PT (Context-Aware LAnguage Modeling Evaluation for Portuguese), the first Portuguese zero-shot language-modeling benchmark. Evaluat",
    "link": "https://arxiv.org/abs/2402.12969",
    "context": "Title: Gl\\'orIA - A Generative and Open Large Language Model for Portuguese\nAbstract: arXiv:2402.12969v1 Announce Type: cross  Abstract: Significant strides have been made in natural language tasks, largely attributed to the emergence of powerful large language models (LLMs). These models, pre-trained on extensive and diverse corpora, have become increasingly capable of comprehending the intricacies of language. Despite the abundance of LLMs for many high-resource languages, the availability of such models remains limited for European Portuguese. We introduce Gl\\'orIA, a robust European Portuguese decoder LLM. To pre-train Gl\\'orIA, we assembled a comprehensive PT-PT text corpus comprising 35 billion tokens from various sources. We present our pre-training methodology, followed by an assessment of the model's effectiveness on multiple downstream tasks. Additionally, to evaluate our models' language modeling capabilities, we introduce CALAME-PT (Context-Aware LAnguage Modeling Evaluation for Portuguese), the first Portuguese zero-shot language-modeling benchmark. Evaluat",
    "path": "papers/24/02/2402.12969.json",
    "total_tokens": 916,
    "translated_title": "Gl'orIA - 一种用于葡萄牙语的生成式开放大型语言模型",
    "translated_abstract": "自然语言任务取得了显著进展，这在很大程度上归因于强大的大型语言模型（LLMs）的出现。尽管许多高资源语言都有丰富的LLM，但欧洲葡萄牙语的这种模型仍然有限。我们介绍了一种强大的欧洲葡萄牙语解码器LLM——Gl'orIA。为了对Gl'orIA进行预训练，我们收集了一个包含来自各个来源的350亿个tokens的全面PT-PT文本语料库。我们展示了我们的预训练方法，然后评估了模型在多个下游任务上的有效性。此外，为了评估我们模型的语言建模能力，我们引入了CALAME-PT（葡萄牙语零样本语言建模基准），这是第一个葡萄牙语零样本语言建模基准。",
    "tldr": "Gl'orIA是一种专门为欧洲葡萄牙语设计的强大解码器大型语言模型，通过对350亿个tokens的全面PT-PT文本语料库预训练，为欧洲葡萄牙语提供了解决方案，并引入了CALAME-PT，这是第一个葡萄牙语零样本语言建模基准。",
    "en_tdlr": "Gl'orIA is a powerful decoder large language model designed specifically for European Portuguese, pre-trained on a comprehensive PT-PT text corpus of 35 billion tokens, providing a solution for European Portuguese and introducing CALAME-PT, the first Portuguese zero-shot language-modeling benchmark."
}