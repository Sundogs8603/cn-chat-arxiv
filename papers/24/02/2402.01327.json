{
    "title": "Supervised Algorithmic Fairness in Distribution Shifts: A Survey",
    "abstract": "Supervised fairness-aware machine learning under distribution shifts is an emerging field that addresses the challenge of maintaining equitable and unbiased predictions when faced with changes in data distributions from source to target domains. In real-world applications, machine learning models are often trained on a specific dataset but deployed in environments where the data distribution may shift over time due to various factors. This shift can lead to unfair predictions, disproportionately affecting certain groups characterized by sensitive attributes, such as race and gender. In this survey, we provide a summary of various types of distribution shifts and comprehensively investigate existing methods based on these shifts, highlighting six commonly used approaches in the literature. Additionally, this survey lists publicly available datasets and evaluation metrics for empirical studies. We further explore the interconnection with related research fields, discuss the significant c",
    "link": "https://rss.arxiv.org/abs/2402.01327",
    "context": "Title: Supervised Algorithmic Fairness in Distribution Shifts: A Survey\nAbstract: Supervised fairness-aware machine learning under distribution shifts is an emerging field that addresses the challenge of maintaining equitable and unbiased predictions when faced with changes in data distributions from source to target domains. In real-world applications, machine learning models are often trained on a specific dataset but deployed in environments where the data distribution may shift over time due to various factors. This shift can lead to unfair predictions, disproportionately affecting certain groups characterized by sensitive attributes, such as race and gender. In this survey, we provide a summary of various types of distribution shifts and comprehensively investigate existing methods based on these shifts, highlighting six commonly used approaches in the literature. Additionally, this survey lists publicly available datasets and evaluation metrics for empirical studies. We further explore the interconnection with related research fields, discuss the significant c",
    "path": "papers/24/02/2402.01327.json",
    "total_tokens": 895,
    "translated_title": "在分布变化中的监督算法公平性：一项综述",
    "translated_abstract": "在分布变化下的监督公平机器学习是一个新兴领域，解决了面对从源领域到目标领域的数据分布变化时，如何保持公平和无偏预测的挑战。在现实世界的应用中，机器学习模型通常是在特定数据集上进行训练，但在部署时，数据分布可能因各种因素而随时间发生变化。这种变化可能导致不公平的预测，对特定通过敏感属性（如种族和性别）来表征的群体产生不均衡的影响。在这项调查中，我们对各种类型的分布变化进行了总结，并全面调查了基于这些变化的现有方法，在文献中突出了六种常用的方法。此外，这份调查列出了用于实证研究的公开可用数据集和评估指标。我们进一步探讨了与相关研究领域的交互关系，并讨论了其中的重要创新和贡献。",
    "tldr": "这篇综述研究了分布变化下的监督公平机器学习领域，调查了各种类型的分布变化和现有的解决方法，并列举了公开数据集和评估指标。研究发现六种常用的方法，并探讨了与相关研究领域的交互关系。",
    "en_tdlr": "This survey investigates the field of supervised fairness-aware machine learning under distribution shifts, summarizing various types of shifts and existing methods. It also provides a list of publicly available datasets and evaluation metrics and explores the interconnection with related research fields."
}