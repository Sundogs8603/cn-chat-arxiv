{
    "title": "Confidence-Aware Multi-Field Model Calibration",
    "abstract": "arXiv:2402.17655v1 Announce Type: new  Abstract: Accurately predicting the probabilities of user feedback, such as clicks and conversions, is critical for ad ranking and bidding. However, there often exist unwanted mismatches between predicted probabilities and true likelihoods due to the shift of data distributions and intrinsic model biases. Calibration aims to address this issue by post-processing model predictions, and field-aware calibration can adjust model output on different feature field values to satisfy fine-grained advertising demands. Unfortunately, the observed samples corresponding to certain field values can be too limited to make confident calibrations, which may yield bias amplification and online disturbance. In this paper, we propose a confidence-aware multi-field calibration method, which adaptively adjusts the calibration intensity based on the confidence levels derived from sample statistics. It also utilizes multiple feature fields for joint model calibration wi",
    "link": "https://arxiv.org/abs/2402.17655",
    "context": "Title: Confidence-Aware Multi-Field Model Calibration\nAbstract: arXiv:2402.17655v1 Announce Type: new  Abstract: Accurately predicting the probabilities of user feedback, such as clicks and conversions, is critical for ad ranking and bidding. However, there often exist unwanted mismatches between predicted probabilities and true likelihoods due to the shift of data distributions and intrinsic model biases. Calibration aims to address this issue by post-processing model predictions, and field-aware calibration can adjust model output on different feature field values to satisfy fine-grained advertising demands. Unfortunately, the observed samples corresponding to certain field values can be too limited to make confident calibrations, which may yield bias amplification and online disturbance. In this paper, we propose a confidence-aware multi-field calibration method, which adaptively adjusts the calibration intensity based on the confidence levels derived from sample statistics. It also utilizes multiple feature fields for joint model calibration wi",
    "path": "papers/24/02/2402.17655.json",
    "total_tokens": 830,
    "translated_title": "基于置信度的多字段模型校准",
    "translated_abstract": "预测用户反馈概率（如点击和转换）对于广告排名和竞价至关重要。然而，由于数据分布的转移和固有模型偏差，预测概率与真实可能性之间经常存在不希望的不一致。校准旨在通过后处理模型预测来解决此问题，而基于字段的校准可以调整不同特征字段值上的模型输出，以满足细粒度的广告需求。不幸的是，对应于某些字段值的观察样本可能太有限，无法进行有信心的校准，这可能导致偏差放大和在线干扰。在本文中，我们提出了一种基于置信度的多字段校准方法，根据样本统计推导的置信水平自适应调整校准强度。它还利用多个特征字段进行联合模型校准。",
    "tldr": "本研究提出了一种基于置信度的多字段校准方法，通过根据样本统计推导的置信水平自适应调整校准强度，以解决校准过程中存在的偏差放大和在线干扰问题。",
    "en_tdlr": "This paper introduces a confidence-aware multi-field calibration method that adaptively adjusts the calibration intensity based on confidence levels derived from sample statistics to address bias amplification and online disturbance during the calibration process."
}