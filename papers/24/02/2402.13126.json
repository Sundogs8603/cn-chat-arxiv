{
    "title": "VGMShield: Mitigating Misuse of Video Generative Models",
    "abstract": "arXiv:2402.13126v1 Announce Type: cross  Abstract: With the rapid advancement in video generation, people can conveniently utilize video generation models to create videos tailored to their specific desires. Nevertheless, there are also growing concerns about their potential misuse in creating and disseminating false information.   In this work, we introduce VGMShield: a set of three straightforward but pioneering mitigations through the lifecycle of fake video generation. We start from \\textit{fake video detection} trying to understand whether there is uniqueness in generated videos and whether we can differentiate them from real videos; then, we investigate the \\textit{tracing} problem, which maps a fake video back to a model that generates it. Towards these, we propose to leverage pre-trained models that focus on {\\it spatial-temporal dynamics} as the backbone to identify inconsistencies in videos. Through experiments on seven state-of-the-art open-source models, we demonstrate that",
    "link": "https://arxiv.org/abs/2402.13126",
    "context": "Title: VGMShield: Mitigating Misuse of Video Generative Models\nAbstract: arXiv:2402.13126v1 Announce Type: cross  Abstract: With the rapid advancement in video generation, people can conveniently utilize video generation models to create videos tailored to their specific desires. Nevertheless, there are also growing concerns about their potential misuse in creating and disseminating false information.   In this work, we introduce VGMShield: a set of three straightforward but pioneering mitigations through the lifecycle of fake video generation. We start from \\textit{fake video detection} trying to understand whether there is uniqueness in generated videos and whether we can differentiate them from real videos; then, we investigate the \\textit{tracing} problem, which maps a fake video back to a model that generates it. Towards these, we propose to leverage pre-trained models that focus on {\\it spatial-temporal dynamics} as the backbone to identify inconsistencies in videos. Through experiments on seven state-of-the-art open-source models, we demonstrate that",
    "path": "papers/24/02/2402.13126.json",
    "total_tokens": 852,
    "translated_title": "VGMShield：缓解视频生成模型的误用",
    "translated_abstract": "随着视频生成技术的快速发展，人们可以方便地利用视频生成模型创建符合其特定需求的视频。然而，人们也越来越担心这些技术被用于创作和传播虚假信息。在这项工作中，我们介绍了VGMShield：一套包含三项直接但开创性的措施，用于防范虚假视频生成过程中可能出现的问题。我们首先从“虚假视频检测”开始，尝试理解生成的视频中是否存在独特性，以及我们是否能够区分它们与真实视频的不同；然后，我们探讨“溯源”问题，即将一段虚假视频追溯回生成它的模型。为此，我们提出利用预训练的关注“时空动态”的模型作为骨干，以识别视频中的不一致性。通过对七个最先进的开源模型进行实验，我们证明了...",
    "tldr": "VGMShield提出了三项简单但开创性的措施，通过检测虚假视频、溯源问题和利用预训练的空间-时间动态模型，防范视频生成模型的误用。",
    "en_tdlr": "VGMShield introduces three straightforward but pioneering mitigations to address the misuse of video generative models, including fake video detection, tracing fake videos back to their generators, and leveraging pre-trained models focusing on spatial-temporal dynamics."
}