{
    "title": "Shadowcast: Stealthy Data Poisoning Attacks Against Vision-Language Models",
    "abstract": "Vision-Language Models (VLMs) excel in generating textual responses from visual inputs, yet their versatility raises significant security concerns. This study takes the first step in exposing VLMs' susceptibility to data poisoning attacks that can manipulate responses to innocuous, everyday prompts. We introduce Shadowcast, a stealthy data poisoning attack method where poison samples are visually indistinguishable from benign images with matching texts. Shadowcast demonstrates effectiveness in two attack types. The first is Label Attack, tricking VLMs into misidentifying class labels, such as confusing Donald Trump for Joe Biden. The second is Persuasion Attack, which leverages VLMs' text generation capabilities to craft narratives, such as portraying junk food as health food, through persuasive and seemingly rational descriptions. We show that Shadowcast are highly effective in achieving attacker's intentions using as few as 50 poison samples. Moreover, these poison samples remain eff",
    "link": "https://arxiv.org/abs/2402.06659",
    "context": "Title: Shadowcast: Stealthy Data Poisoning Attacks Against Vision-Language Models\nAbstract: Vision-Language Models (VLMs) excel in generating textual responses from visual inputs, yet their versatility raises significant security concerns. This study takes the first step in exposing VLMs' susceptibility to data poisoning attacks that can manipulate responses to innocuous, everyday prompts. We introduce Shadowcast, a stealthy data poisoning attack method where poison samples are visually indistinguishable from benign images with matching texts. Shadowcast demonstrates effectiveness in two attack types. The first is Label Attack, tricking VLMs into misidentifying class labels, such as confusing Donald Trump for Joe Biden. The second is Persuasion Attack, which leverages VLMs' text generation capabilities to craft narratives, such as portraying junk food as health food, through persuasive and seemingly rational descriptions. We show that Shadowcast are highly effective in achieving attacker's intentions using as few as 50 poison samples. Moreover, these poison samples remain eff",
    "path": "papers/24/02/2402.06659.json",
    "total_tokens": 971,
    "translated_title": "Shadowcast: 隐秘的数据污染攻击对抗视觉语言模型",
    "translated_abstract": "视觉语言模型（VLM）能够从视觉输入中生成文本响应，然而它们的多功能性带来了重大的安全隐患。本研究首次揭示了VLM对数据污染攻击的易受性，这些攻击可以操纵对无害的日常提示的响应。我们引入了一种名为Shadowcast的隐秘数据污染攻击方法，其中毒样本在视觉上与具有匹配文本的良性图像难以区分。Shadowcast在两种攻击类型中展示出了有效性。第一种是标签攻击，使VLM误识别类别标签，例如混淆唐纳德·特朗普和乔·拜登等人。第二种是说服攻击，利用VLM的文本生成能力来编写故事，例如通过有说服力和看似合理的描述将垃圾食品描绘成健康食品。我们展示了Shadowcast使用仅50个毒样本就能高度有效地实现攻击者的意图。此外，这些毒样本仍然保持有效。",
    "tldr": "Shadowcast是一种隐秘的数据污染攻击方法，可以通过伪装成良性图像和匹配文本来操纵视觉语言模型的响应。它包括标签攻击和说服攻击，可以混淆类别标签并编写有说服力的描述。使用仅50个毒样本，Shadowcast能够高效实现攻击者的意图。",
    "en_tdlr": "Shadowcast is a stealthy data poisoning attack method that manipulates the responses of vision-language models by disguising as benign images with matching texts. It includes label attack and persuasion attack, which confuse class labels and generate persuasive descriptions. With as few as 50 poison samples, Shadowcast achieves attacker's intentions effectively."
}