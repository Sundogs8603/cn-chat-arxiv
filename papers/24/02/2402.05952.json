{
    "title": "Advancing Graph Representation Learning with Large Language Models: A Comprehensive Survey of Techniques",
    "abstract": "The integration of Large Language Models (LLMs) with Graph Representation Learning (GRL) marks a significant evolution in analyzing complex data structures. This collaboration harnesses the sophisticated linguistic capabilities of LLMs to improve the contextual understanding and adaptability of graph models, thereby broadening the scope and potential of GRL. Despite a growing body of research dedicated to integrating LLMs into the graph domain, a comprehensive review that deeply analyzes the core components and operations within these models is notably lacking. Our survey fills this gap by proposing a novel taxonomy that breaks down these models into primary components and operation techniques from a novel technical perspective. We further dissect recent literature into two primary components including knowledge extractors and organizers, and two operation techniques including integration and training stratigies, shedding light on effective model design and training strategies. Additio",
    "link": "https://arxiv.org/abs/2402.05952",
    "context": "Title: Advancing Graph Representation Learning with Large Language Models: A Comprehensive Survey of Techniques\nAbstract: The integration of Large Language Models (LLMs) with Graph Representation Learning (GRL) marks a significant evolution in analyzing complex data structures. This collaboration harnesses the sophisticated linguistic capabilities of LLMs to improve the contextual understanding and adaptability of graph models, thereby broadening the scope and potential of GRL. Despite a growing body of research dedicated to integrating LLMs into the graph domain, a comprehensive review that deeply analyzes the core components and operations within these models is notably lacking. Our survey fills this gap by proposing a novel taxonomy that breaks down these models into primary components and operation techniques from a novel technical perspective. We further dissect recent literature into two primary components including knowledge extractors and organizers, and two operation techniques including integration and training stratigies, shedding light on effective model design and training strategies. Additio",
    "path": "papers/24/02/2402.05952.json",
    "total_tokens": 877,
    "translated_title": "利用大型语言模型推进图表示学习：技术全面调查",
    "translated_abstract": "大型语言模型（LLM）与图表示学习（GRL）的整合标志着分析复杂数据结构的重大进展。这种合作利用LLM的先进语言能力来改进图模型的上下文理解能力和适应性，从而拓宽了GRL的范围和潜力。尽管已经有大量的研究致力于将LLM集成到图领域中，但缺乏一份深入分析这些模型核心组成部分和操作技术的全面综述。我们的调查通过提出一种新颖的分类法来分解这些模型为主要组成部分和操作技术，从新的技术角度深入分析。我们进一步将最近的文献分解为两个主要组成部分，包括知识提取器和组织者，以及两个操作技术，包括集成和训练策略，揭示出有效的模型设计和训练策略的要点。",
    "tldr": "本综述调查了将大型语言模型（LLM）与图表示学习（GRL）相结合的技术，并提供了一个新颖的分类法，深入分析了这些模型的核心组成部分和操作技术，为有效的模型设计和训练策略提供了新的视角。",
    "en_tdlr": "This survey investigates the integration of Large Language Models (LLMs) with Graph Representation Learning (GRL) and provides a novel taxonomy that analyzes the core components and operation techniques of these models, offering new insights for effective model design and training strategies."
}