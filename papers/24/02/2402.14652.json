{
    "title": "Cleaner Pretraining Corpus Curation with Neural Web Scraping",
    "abstract": "arXiv:2402.14652v1 Announce Type: new  Abstract: The web contains large-scale, diverse, and abundant information to satisfy the information-seeking needs of humans. Through meticulous data collection, preprocessing, and curation, webpages can be used as a fundamental data resource for language model pretraining. However, when confronted with the progressively revolutionized and intricate nature of webpages, rule-based/feature-based web scrapers are becoming increasingly inadequate. This paper presents a simple, fast, and effective Neural web Scraper (NeuScraper) to help extract primary and clean text contents from webpages. Experimental results show that NeuScraper surpasses the baseline scrapers by achieving more than a 20% improvement, demonstrating its potential in extracting higher-quality data to facilitate the language model pretraining. All of the code is available at https://github.com/OpenMatch/NeuScraper.",
    "link": "https://arxiv.org/abs/2402.14652",
    "context": "Title: Cleaner Pretraining Corpus Curation with Neural Web Scraping\nAbstract: arXiv:2402.14652v1 Announce Type: new  Abstract: The web contains large-scale, diverse, and abundant information to satisfy the information-seeking needs of humans. Through meticulous data collection, preprocessing, and curation, webpages can be used as a fundamental data resource for language model pretraining. However, when confronted with the progressively revolutionized and intricate nature of webpages, rule-based/feature-based web scrapers are becoming increasingly inadequate. This paper presents a simple, fast, and effective Neural web Scraper (NeuScraper) to help extract primary and clean text contents from webpages. Experimental results show that NeuScraper surpasses the baseline scrapers by achieving more than a 20% improvement, demonstrating its potential in extracting higher-quality data to facilitate the language model pretraining. All of the code is available at https://github.com/OpenMatch/NeuScraper.",
    "path": "papers/24/02/2402.14652.json",
    "total_tokens": 831,
    "translated_title": "使用神经网络网络抓取进行更清洁的预训练语料库筛选",
    "translated_abstract": "arXiv:2402.14652v1 公告类型: 新的 摘要: 网络包含大规模、多样化和丰富信息，以满足人类的信息需求。通过细致的数据收集、预处理和整理，网页可以被用作语言模型预训练的基本数据资源。然而，面对不断革新和复杂的网页特性，基于规则/特征的网络抓取器变得越来越不足够。本文提出了一个简单、快速、有效的神经网络网络抓取器（NeuScraper），帮助从网页中提取主要和干净的文本内容。实验结果显示NeuScraper超越了基准抓取器，实现了超过20%的改进，展示了其在提取更高质量数据以促进语言模型预训练方面的潜力。所有代码都可以在https://github.com/OpenMatch/NeuScraper找到。",
    "tldr": "使用神经网络网络抓取器NeuScraper可以从网页中提取干净的文本内容，并且实现了超过20%的改进，有助于提高语言模型的预训练质量",
    "en_tdlr": "NeuScraper, a neural web scraper, helps extract clean text content from webpages with over 20% improvement, demonstrating its potential for enhancing the quality of language model pretraining."
}