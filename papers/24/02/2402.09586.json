{
    "title": "WERank: Towards Rank Degradation Prevention for Self-Supervised Learning Using Weight Regularization",
    "abstract": "arXiv:2402.09586v1 Announce Type: new  Abstract: A common phenomena confining the representation quality in Self-Supervised Learning (SSL) is dimensional collapse (also known as rank degeneration), where the learned representations are mapped to a low dimensional subspace of the representation space. The State-of-the-Art SSL methods have shown to suffer from dimensional collapse and fall behind maintaining full rank. Recent approaches to prevent this problem have proposed using contrastive losses, regularization techniques, or architectural tricks. We propose WERank, a new regularizer on the weight parameters of the network to prevent rank degeneration at different layers of the network. We provide empirical evidence and mathematical justification to demonstrate the effectiveness of the proposed regularization method in preventing dimensional collapse. We verify the impact of WERank on graph SSL where dimensional collapse is more pronounced due to the lack of proper data augmentation. ",
    "link": "https://arxiv.org/abs/2402.09586",
    "context": "Title: WERank: Towards Rank Degradation Prevention for Self-Supervised Learning Using Weight Regularization\nAbstract: arXiv:2402.09586v1 Announce Type: new  Abstract: A common phenomena confining the representation quality in Self-Supervised Learning (SSL) is dimensional collapse (also known as rank degeneration), where the learned representations are mapped to a low dimensional subspace of the representation space. The State-of-the-Art SSL methods have shown to suffer from dimensional collapse and fall behind maintaining full rank. Recent approaches to prevent this problem have proposed using contrastive losses, regularization techniques, or architectural tricks. We propose WERank, a new regularizer on the weight parameters of the network to prevent rank degeneration at different layers of the network. We provide empirical evidence and mathematical justification to demonstrate the effectiveness of the proposed regularization method in preventing dimensional collapse. We verify the impact of WERank on graph SSL where dimensional collapse is more pronounced due to the lack of proper data augmentation. ",
    "path": "papers/24/02/2402.09586.json",
    "total_tokens": 786,
    "translated_title": "WERank: 针对自监督学习中的等级退化预防的权重正规化方法",
    "translated_abstract": "自监督学习中常见的问题是维度坍塌（也称为等级退化），其中学到的表示被映射到表示空间的低维子空间。最新的防止该问题的方法包括使用对比损失、正则化技术或架构技巧。本文提出了一种新的网络权重正则化方法WERank，用于预防网络不同层次的维度坍塌。我们通过实证和数学论证证明了该正则化方法在防止维度坍塌方面的有效性。我们还验证了在图像自监督学习中WERank的影响，由于缺乏适当的数据增强，维度坍塌更加明显。",
    "tldr": "本文提出了一个新的网络权重正则化方法WERank，用于防止自监督学习中的维度坍塌问题。通过实验证明了该方法的有效性，并在图像自监督学习中进行了验证。",
    "en_tdlr": "This paper proposes a new weight regularization method called WERank to prevent rank degeneration in self-supervised learning. The effectiveness of the method is demonstrated through empirical evidence and it is validated in graph SSL."
}