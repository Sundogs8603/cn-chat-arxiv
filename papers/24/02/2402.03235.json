{
    "title": "ActiveAnno3D - An Active Learning Framework for Multi-Modal 3D Object Detection",
    "abstract": "The curation of large-scale datasets is still costly and requires much time and resources. Data is often manually labeled, and the challenge of creating high-quality datasets remains. In this work, we fill the research gap using active learning for multi-modal 3D object detection. We propose ActiveAnno3D, an active learning framework to select data samples for labeling that are of maximum informativeness for training. We explore various continuous training methods and integrate the most efficient method regarding computational demand and detection performance. Furthermore, we perform extensive experiments and ablation studies with BEVFusion and PV-RCNN on the nuScenes and TUM Traffic Intersection dataset. We show that we can achieve almost the same performance with PV-RCNN and the entropy-based query strategy when using only half of the training data (77.25 mAP compared to 83.50 mAP) of the TUM Traffic Intersection dataset. BEVFusion achieved an mAP of 64.31 when using half of the trai",
    "link": "https://arxiv.org/abs/2402.03235",
    "context": "Title: ActiveAnno3D - An Active Learning Framework for Multi-Modal 3D Object Detection\nAbstract: The curation of large-scale datasets is still costly and requires much time and resources. Data is often manually labeled, and the challenge of creating high-quality datasets remains. In this work, we fill the research gap using active learning for multi-modal 3D object detection. We propose ActiveAnno3D, an active learning framework to select data samples for labeling that are of maximum informativeness for training. We explore various continuous training methods and integrate the most efficient method regarding computational demand and detection performance. Furthermore, we perform extensive experiments and ablation studies with BEVFusion and PV-RCNN on the nuScenes and TUM Traffic Intersection dataset. We show that we can achieve almost the same performance with PV-RCNN and the entropy-based query strategy when using only half of the training data (77.25 mAP compared to 83.50 mAP) of the TUM Traffic Intersection dataset. BEVFusion achieved an mAP of 64.31 when using half of the trai",
    "path": "papers/24/02/2402.03235.json",
    "total_tokens": 930,
    "translated_title": "ActiveAnno3D - 一种用于多模态3D物体检测的主动学习框架",
    "translated_abstract": "大规模数据集的筛选仍然需要大量的时间和资源，数据通常需要人工标注，创建高质量数据集的难题依然存在。在这项工作中，我们使用主动学习的方法来解决多模态3D物体检测中的研究空白。我们提出了ActiveAnno3D，一个用于选择最具信息量的训练数据样本进行标注的主动学习框架。我们探索了各种连续训练方法，并集成了在计算需求和检测性能方面最高效的方法。此外，我们对nuScenes和TUM Traffic Intersection数据集进行了大量实验和消融研究，使用BEVFusion和PV-RCNN进行了测试。我们展示了当仅使用TUM Traffic Intersection数据集的一半训练数据（77.25 mAP相比于83.50 mAP）时，使用PV-RCNN和基于熵的查询策略几乎可以达到相同的性能，而BEVFusion则在使用一半的训练数据时获得了64.31的mAP。",
    "tldr": "这项工作提出了一种用于多模态3D物体检测的主动学习框架ActiveAnno3D。通过选择最具信息量的训练数据样本进行标注，我们能够在使用一半的训练数据时实现与传统方法相近的检测性能。",
    "en_tdlr": "This work proposes an active learning framework called ActiveAnno3D for multi-modal 3D object detection. By selecting training data samples with maximum informativeness for labeling, we achieve comparable detection performance with traditional methods using only half of the training data."
}