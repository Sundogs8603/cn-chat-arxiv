{
    "title": "Cause and Effect: Can Large Language Models Truly Understand Causality?",
    "abstract": "arXiv:2402.18139v1 Announce Type: cross  Abstract: With the rise of Large Language Models(LLMs), it has become crucial to understand their capabilities and limitations in deciphering and explaining the complex web of causal relationships that language entails. Current methods use either explicit or implicit causal reasoning, yet there is a strong need for a unified approach combining both to tackle a wide array of causal relationships more effectively. This research proposes a novel architecture called Context Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to enhance causal reasoning and explainability. The proposed framework incorporates an explicit causal detection module with ConceptNet and counterfactual statements, as well as implicit causal detection through LLMs. Our framework goes one step further with a layer of counterfactual explanations to accentuate LLMs understanding of causality. The knowledge from ConceptNet enhances the performance of multi",
    "link": "https://arxiv.org/abs/2402.18139",
    "context": "Title: Cause and Effect: Can Large Language Models Truly Understand Causality?\nAbstract: arXiv:2402.18139v1 Announce Type: cross  Abstract: With the rise of Large Language Models(LLMs), it has become crucial to understand their capabilities and limitations in deciphering and explaining the complex web of causal relationships that language entails. Current methods use either explicit or implicit causal reasoning, yet there is a strong need for a unified approach combining both to tackle a wide array of causal relationships more effectively. This research proposes a novel architecture called Context Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to enhance causal reasoning and explainability. The proposed framework incorporates an explicit causal detection module with ConceptNet and counterfactual statements, as well as implicit causal detection through LLMs. Our framework goes one step further with a layer of counterfactual explanations to accentuate LLMs understanding of causality. The knowledge from ConceptNet enhances the performance of multi",
    "path": "papers/24/02/2402.18139.json",
    "total_tokens": 837,
    "translated_title": "因果关系：大型语言模型真正理解因果关系吗？",
    "translated_abstract": "随着大型语言模型（LLMs）的兴起，理解它们在解读和解释语言所涉及的复杂因果关系的能力和局限性变得至关重要。目前的方法使用明确或隐含的因果推理，然而迫切需要一种统一的方法，将两者结合起来更有效地处理各种因果关系。本研究提出了一种新颖的架构，称为具有反事实分析的上下文感知推理增强（CARE CA）框架，以增强因果推理和可解释性。所提出的框架将 ConceptNet 和反事实陈述中的明确因果检测模块以及通过LLMs进行的隐含因果检测相结合。我们的框架通过一层反事实解释进一步突出LLMs对因果关系的理解。ConceptNet 中的知识提高了多",
    "tldr": "本研究提出了一种名为CARE CA的新型架构，通过结合显式因果检测模块和反事实陈述、以及隐含因果检测模块，旨在增强大型语言模型对因果关系的理解能力。"
}