{
    "title": "Break the Breakout: Reinventing LM Defense Against Jailbreak Attacks with Self-Refinement",
    "abstract": "arXiv:2402.15180v1 Announce Type: cross  Abstract: Caution: This paper includes offensive words that could potentially cause unpleasantness. Language models (LMs) are vulnerable to exploitation for adversarial misuse. Training LMs for safety alignment is extensive and makes it hard to respond to fast-developing attacks immediately, such as jailbreaks. We propose self-refine with formatting that achieves outstanding safety even in non-safety-aligned LMs and evaluate our method alongside several defense baselines, demonstrating that it is the safest training-free method against jailbreak attacks. Additionally, we proposed a formatting method that improves the efficiency of the self-refine process while reducing attack success rates in fewer iterations. We've also observed that non-safety-aligned LMs outperform safety-aligned LMs in safety tasks by giving more helpful and safe responses. In conclusion, our findings can achieve less safety risk with fewer computational costs, allowing non-",
    "link": "https://arxiv.org/abs/2402.15180",
    "context": "Title: Break the Breakout: Reinventing LM Defense Against Jailbreak Attacks with Self-Refinement\nAbstract: arXiv:2402.15180v1 Announce Type: cross  Abstract: Caution: This paper includes offensive words that could potentially cause unpleasantness. Language models (LMs) are vulnerable to exploitation for adversarial misuse. Training LMs for safety alignment is extensive and makes it hard to respond to fast-developing attacks immediately, such as jailbreaks. We propose self-refine with formatting that achieves outstanding safety even in non-safety-aligned LMs and evaluate our method alongside several defense baselines, demonstrating that it is the safest training-free method against jailbreak attacks. Additionally, we proposed a formatting method that improves the efficiency of the self-refine process while reducing attack success rates in fewer iterations. We've also observed that non-safety-aligned LMs outperform safety-aligned LMs in safety tasks by giving more helpful and safe responses. In conclusion, our findings can achieve less safety risk with fewer computational costs, allowing non-",
    "path": "papers/24/02/2402.15180.json",
    "total_tokens": 891,
    "translated_title": "打破Breakout: 用自我完善重新定义LM对抗越狱攻击的防御",
    "translated_abstract": "警告：本文包含可能引起不快的冒犯性词语。语言模型（LMs）容易被利用进行恶意滥用。对LM进行安全对齐的训练非常复杂，使得难以立即应对快速发展的攻击，如越狱攻击。我们提出了一种通过格式自我完善的方法，即使在非安全对齐的LMs中也能实现出色的安全性，并将我们的方法与几种防御基线进行评估，表明这是针对越狱攻击最安全的无训练方法。此外，我们提出了一种改进自我完善过程效率的格式化方法，同时在较少迭代中降低攻击成功率。我们还观察到非安全对齐的LM在安全任务中表现优于安全对齐的LM，因为它们给出更有用且更安全的回复。总之，我们的发现能够在较少的计算成本下实现更少的安全风险。",
    "tldr": "提出了一种通过自我完善和格式化改进LMs对抗越狱攻击的方法，即使在非安全对齐的LMs中也具有出色的安全性，同时降低攻击成功率。",
    "en_tdlr": "Introduced a method to enhance LM defense against jailbreak attacks through self-refinement and formatting, achieving outstanding safety even in non-safety-aligned LMs, while reducing attack success rates."
}