{
    "title": "Graph Learning with Distributional Edge Layouts",
    "abstract": "arXiv:2402.16402v1 Announce Type: cross  Abstract: Graph Neural Networks (GNNs) learn from graph-structured data by passing local messages between neighboring nodes along edges on certain topological layouts. Typically, these topological layouts in modern GNNs are deterministically computed (e.g., attention-based GNNs) or locally sampled (e.g., GraphSage) under heuristic assumptions. In this paper, we for the first time pose that these layouts can be globally sampled via Langevin dynamics following Boltzmann distribution equipped with explicit physical energy, leading to higher feasibility in the physical world. We argue that such a collection of sampled/optimized layouts can capture the wide energy distribution and bring extra expressivity on top of WL-test, therefore easing downstream tasks. As such, we propose Distributional Edge Layouts (DELs) to serve as a complement to a variety of GNNs. DEL is a pre-processing strategy independent of subsequent GNN variants, thus being highly fl",
    "link": "https://arxiv.org/abs/2402.16402",
    "context": "Title: Graph Learning with Distributional Edge Layouts\nAbstract: arXiv:2402.16402v1 Announce Type: cross  Abstract: Graph Neural Networks (GNNs) learn from graph-structured data by passing local messages between neighboring nodes along edges on certain topological layouts. Typically, these topological layouts in modern GNNs are deterministically computed (e.g., attention-based GNNs) or locally sampled (e.g., GraphSage) under heuristic assumptions. In this paper, we for the first time pose that these layouts can be globally sampled via Langevin dynamics following Boltzmann distribution equipped with explicit physical energy, leading to higher feasibility in the physical world. We argue that such a collection of sampled/optimized layouts can capture the wide energy distribution and bring extra expressivity on top of WL-test, therefore easing downstream tasks. As such, we propose Distributional Edge Layouts (DELs) to serve as a complement to a variety of GNNs. DEL is a pre-processing strategy independent of subsequent GNN variants, thus being highly fl",
    "path": "papers/24/02/2402.16402.json",
    "total_tokens": 889,
    "translated_title": "基于分布式边布局的图学习",
    "translated_abstract": "图神经网络（GNNs）通过在某些拓扑布局上沿着边在相邻节点之间传递局部信息来学习图结构数据。在现代GNNs中，这些拓扑布局通常是按照确定性计算（例如，基于注意力的GNNs）或在启发性假设下本地采样（例如，GraphSage）的。本文首次提出这些布局可以通过Langevin动力学全局采样，遵循配备明确物理能量的玻尔兹曼分布，从而在物理世界中更具可行性。我们认为这样一组采样/优化的布局可以捕获广泛的能量分布，并在WL-test之上带来额外的表达能力，因此有助于简化下游任务。因此，我们提出了分布式边布局（DELs）作为各种GNNs的补充。DEL是一个与后续GNN变种无关的预处理策略，因此非常灵活。",
    "tldr": "图神经网络中提出了一种新的全局布局采样方法，Distributional Edge Layouts（DELs），通过Langevin动力学和玻尔兹曼分布，能够捕获广泛的能量分布，提供额外的表达能力，有助于简化下游任务。",
    "en_tdlr": "A new global layout sampling method, Distributional Edge Layouts (DELs), is proposed in graph neural networks, which utilizes Langevin dynamics and Boltzmann distribution to capture wide energy distribution, provide additional expressivity, and facilitate downstream tasks."
}