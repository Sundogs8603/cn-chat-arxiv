{
    "title": "Both Matter: Enhancing the Emotional Intelligence of Large Language Models without Compromising the General Intelligence",
    "abstract": "arXiv:2402.10073v1 Announce Type: new  Abstract: Emotional Intelligence (EI), consisting of emotion perception, emotion cognition and emotion expression, plays the critical roles in improving user interaction experience for the current large language model (LLM) based conversational general AI assistants. Previous works mainly focus on raising the emotion perception ability of them via naive fine-tuning on EI-related classification or regression tasks. However, this leads to the incomplete enhancement of EI and catastrophic forgetting of the general intelligence (GI). To this end, we first introduce \\textsc{EiBench}, a large-scale collection of EI-related tasks in the text-to-text formation with task instructions that covers all three aspects of EI, which lays a solid foundation for the comprehensive EI enhancement of LLMs. Then a novel \\underline{\\textbf{Mo}}dular \\underline{\\textbf{E}}motional \\underline{\\textbf{I}}ntelligence enhancement method (\\textbf{MoEI}), consisting of Modular",
    "link": "https://arxiv.org/abs/2402.10073",
    "context": "Title: Both Matter: Enhancing the Emotional Intelligence of Large Language Models without Compromising the General Intelligence\nAbstract: arXiv:2402.10073v1 Announce Type: new  Abstract: Emotional Intelligence (EI), consisting of emotion perception, emotion cognition and emotion expression, plays the critical roles in improving user interaction experience for the current large language model (LLM) based conversational general AI assistants. Previous works mainly focus on raising the emotion perception ability of them via naive fine-tuning on EI-related classification or regression tasks. However, this leads to the incomplete enhancement of EI and catastrophic forgetting of the general intelligence (GI). To this end, we first introduce \\textsc{EiBench}, a large-scale collection of EI-related tasks in the text-to-text formation with task instructions that covers all three aspects of EI, which lays a solid foundation for the comprehensive EI enhancement of LLMs. Then a novel \\underline{\\textbf{Mo}}dular \\underline{\\textbf{E}}motional \\underline{\\textbf{I}}ntelligence enhancement method (\\textbf{MoEI}), consisting of Modular",
    "path": "papers/24/02/2402.10073.json",
    "total_tokens": 980,
    "translated_title": "同时重视：在不损害普适智能的情感智能大语言模型中增强情绪智力",
    "translated_abstract": "情感智力（EI）包括情感感知、情感认知和情感表达，在提高当前基于大语言模型（LLM）的对话式普适人工智能助手与用户交互体验方面起着关键作用。先前的工作主要集中在通过对EI相关的分类或回归任务的天真微调提高其情感感知能力。然而，这导致了EI的不完全增强和对普适智能的灾难性遗忘。为此，我们首先引入了一个大规模的以文本为基础的EI相关任务集合\\textsc{EiBench}，其中包括了覆盖了EI的三个方面的任务指示，为综合增强LLM的EI奠定了坚实的基础。然后，提出了一种新颖的模块化情绪智力增强方法（\\textbf{MoEI}），包含了模块化的训练过程和情感智力增强器的集成，以同时提高EI和保持普适智能。",
    "tldr": "本论文提出了一个称为\\textbf{MoEI}的方法，通过引入一个大规模的EI相关任务集合\\textsc{EiBench}并采用模块化的训练过程和情感智力增强器的集成，综合提高了LLM的情感智力（EI）而不损害其普适智能（GI）。",
    "en_tdlr": "This paper proposes a method called \\textbf{MoEI}, which comprehensively enhances emotional intelligence (EI) of LLMs without compromising their general intelligence (GI), by introducing a large-scale collection of EI-related tasks called \\textsc{EiBench} and using a modular training process and integration of emotional intelligence enhancers."
}