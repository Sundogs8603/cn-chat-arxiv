{
    "title": "Constrained Decoding for Cross-lingual Label Projection",
    "abstract": "Zero-shot cross-lingual transfer utilizing multilingual LLMs has become a popular learning paradigm for low-resource languages with no labeled training data. However, for NLP tasks that involve fine-grained predictions on words and phrases, the performance of zero-shot cross-lingual transfer learning lags far behind supervised fine-tuning methods. Therefore, it is common to exploit translation and label projection to further improve the performance by (1) translating training data that is available in a high-resource language (e.g., English) together with the gold labels into low-resource languages, and/or (2) translating test data in low-resource languages to a high-source language to run inference on, then projecting the predicted span-level labels back onto the original test data. However, state-of-the-art marker-based label projection methods suffer from translation quality degradation due to the extra label markers injected in the input to the translation model. In this work, we e",
    "link": "https://arxiv.org/abs/2402.03131",
    "context": "Title: Constrained Decoding for Cross-lingual Label Projection\nAbstract: Zero-shot cross-lingual transfer utilizing multilingual LLMs has become a popular learning paradigm for low-resource languages with no labeled training data. However, for NLP tasks that involve fine-grained predictions on words and phrases, the performance of zero-shot cross-lingual transfer learning lags far behind supervised fine-tuning methods. Therefore, it is common to exploit translation and label projection to further improve the performance by (1) translating training data that is available in a high-resource language (e.g., English) together with the gold labels into low-resource languages, and/or (2) translating test data in low-resource languages to a high-source language to run inference on, then projecting the predicted span-level labels back onto the original test data. However, state-of-the-art marker-based label projection methods suffer from translation quality degradation due to the extra label markers injected in the input to the translation model. In this work, we e",
    "path": "papers/24/02/2402.03131.json",
    "total_tokens": 833,
    "translated_title": "用于跨语言标签投影的约束解码",
    "translated_abstract": "在没有标记训练数据的情况下，利用多语言LLM进行零样本跨语言迁移已成为一种流行的学习范式，用于低资源语言。然而，在涉及对单词和短语进行细粒度预测的NLP任务中，零样本跨语言迁移学习的性能远远落后于监督微调方法。因此，通常利用翻译和标签投影来进一步提高性能，具体来说(1)将可用的以及带有黄金标签的训练数据从高资源语言(例如英语)翻译到低资源语言，和/或(2)将低资源语言中的测试数据翻译成高资源语言进行推理，然后将预测的跨度级别标签投射回原始测试数据。然而，最先进的基于标记的标签投影方法由于在输入到翻译模型的过程中注入了额外标记，导致翻译质量下降。本文中，我们提出了一种解决这个问题的方法。",
    "tldr": "本文提出了一种解决零样本跨语言迁移学习中翻译质量下降问题的方法。",
    "en_tdlr": "This paper presents an approach to address the issue of translation quality degradation in zero-shot cross-lingual transfer learning."
}