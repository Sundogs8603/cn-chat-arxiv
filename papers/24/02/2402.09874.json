{
    "title": "Camouflage is all you need: Evaluating and Enhancing Language Model Robustness Against Camouflage Adversarial Attacks",
    "abstract": "arXiv:2402.09874v1 Announce Type: new  Abstract: Adversarial attacks represent a substantial challenge in Natural Language Processing (NLP). This study undertakes a systematic exploration of this challenge in two distinct phases: vulnerability evaluation and resilience enhancement of Transformer-based models under adversarial attacks.   In the evaluation phase, we assess the susceptibility of three Transformer configurations, encoder-decoder, encoder-only, and decoder-only setups, to adversarial attacks of escalating complexity across datasets containing offensive language and misinformation. Encoder-only models manifest a 14% and 21% performance drop in offensive language detection and misinformation detection tasks, respectively. Decoder-only models register a 16% decrease in both tasks, while encoder-decoder models exhibit a maximum performance drop of 14% and 26% in the respective tasks.   The resilience-enhancement phase employs adversarial training, integrating pre-camouflaged an",
    "link": "https://arxiv.org/abs/2402.09874",
    "context": "Title: Camouflage is all you need: Evaluating and Enhancing Language Model Robustness Against Camouflage Adversarial Attacks\nAbstract: arXiv:2402.09874v1 Announce Type: new  Abstract: Adversarial attacks represent a substantial challenge in Natural Language Processing (NLP). This study undertakes a systematic exploration of this challenge in two distinct phases: vulnerability evaluation and resilience enhancement of Transformer-based models under adversarial attacks.   In the evaluation phase, we assess the susceptibility of three Transformer configurations, encoder-decoder, encoder-only, and decoder-only setups, to adversarial attacks of escalating complexity across datasets containing offensive language and misinformation. Encoder-only models manifest a 14% and 21% performance drop in offensive language detection and misinformation detection tasks, respectively. Decoder-only models register a 16% decrease in both tasks, while encoder-decoder models exhibit a maximum performance drop of 14% and 26% in the respective tasks.   The resilience-enhancement phase employs adversarial training, integrating pre-camouflaged an",
    "path": "papers/24/02/2402.09874.json",
    "total_tokens": 880,
    "translated_title": "伪装就是你所需要的：评估和增强语言模型对伪装性对抗攻击的鲁棒性",
    "translated_abstract": "对抗攻击在自然语言处理（NLP）中构成了一个重大挑战。本研究对Transformer-based模型在对抗攻击下的脆弱性评估和鲁棒性增强进行了系统的探索。在评估阶段，我们评估了包含冒犯性语言和虚假信息的数据集上，三个Transformer配置（编码器-解码器、仅编码器和仅解码器）对不断升级的复杂性的对抗攻击的敏感性。仅编码器模型在冒犯性语言检测和虚假信息检测任务中分别表现出14%和21%的性能下降。仅解码器模型在两个任务中都出现了16%的降低，而编码器-解码器模型在相应任务中的最大性能下降为14%和26%。",
    "tldr": "该研究评估和增强了语言模型对伪装性对抗攻击的鲁棒性。在对三种Transformer配置进行评估后发现，仅编码器模型在冒犯性语言检测和虚假信息检测任务中表现出最高的性能下降。",
    "en_tdlr": "This study evaluates and enhances the robustness of language models against camouflage adversarial attacks. Evaluating three different Transformer configurations, the study finds that encoder-only models exhibit the highest performance drop in offensive language detection and misinformation detection tasks."
}