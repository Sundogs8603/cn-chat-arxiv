{
    "title": "Can GNN be Good Adapter for LLMs?",
    "abstract": "arXiv:2402.12984v1 Announce Type: cross  Abstract: Recently, large language models (LLMs) have demonstrated superior capabilities in understanding and zero-shot learning on textual data, promising significant advances for many text-related domains. In the graph domain, various real-world scenarios also involve textual data, where tasks and node features can be described by text. These text-attributed graphs (TAGs) have broad applications in social media, recommendation systems, etc. Thus, this paper explores how to utilize LLMs to model TAGs. Previous methods for TAG modeling are based on million-scale LMs. When scaled up to billion-scale LLMs, they face huge challenges in computational costs. Additionally, they also ignore the zero-shot inference capabilities of LLMs. Therefore, we propose GraphAdapter, which uses a graph neural network (GNN) as an efficient adapter in collaboration with LLMs to tackle TAGs. In terms of efficiency, the GNN adapter introduces only a few trainable param",
    "link": "https://arxiv.org/abs/2402.12984",
    "context": "Title: Can GNN be Good Adapter for LLMs?\nAbstract: arXiv:2402.12984v1 Announce Type: cross  Abstract: Recently, large language models (LLMs) have demonstrated superior capabilities in understanding and zero-shot learning on textual data, promising significant advances for many text-related domains. In the graph domain, various real-world scenarios also involve textual data, where tasks and node features can be described by text. These text-attributed graphs (TAGs) have broad applications in social media, recommendation systems, etc. Thus, this paper explores how to utilize LLMs to model TAGs. Previous methods for TAG modeling are based on million-scale LMs. When scaled up to billion-scale LLMs, they face huge challenges in computational costs. Additionally, they also ignore the zero-shot inference capabilities of LLMs. Therefore, we propose GraphAdapter, which uses a graph neural network (GNN) as an efficient adapter in collaboration with LLMs to tackle TAGs. In terms of efficiency, the GNN adapter introduces only a few trainable param",
    "path": "papers/24/02/2402.12984.json",
    "total_tokens": 670,
    "translated_title": "GNN是否可以成为LLMs的良好适配器？",
    "translated_abstract": "最近，大型语言模型（LLMs）在理解文本数据和零次学习方面展示了出色的能力，为许多与文本相关的领域带来了显著进展。本文探讨了如何利用LLMs来建模文本属性图（TAGs）。我们提出了GraphAdapter，它使用图神经网络（GNN）作为LLMs的高效适配器，以应对TAGs。",
    "tldr": "本文提出了GraphAdapter，利用图神经网络（GNN）作为高效适配器，与LLMs协同处理文本属性图（TAGs）。"
}