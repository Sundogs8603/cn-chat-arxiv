{
    "title": "The Information of Large Language Model Geometry",
    "abstract": "This paper investigates the information encoded in the embeddings of large language models (LLMs). We conduct simulations to analyze the representation entropy and discover a power law relationship with model sizes. Building upon this observation, we propose a theory based on (conditional) entropy to elucidate the scaling law phenomenon. Furthermore, we delve into the auto-regressive structure of LLMs and examine the relationship between the last token and previous context tokens using information theory and regression techniques. Specifically, we establish a theoretical connection between the information gain of new tokens and ridge regression. Additionally, we explore the effectiveness of Lasso regression in selecting meaningful tokens, which sometimes outperforms the closely related attention weights. Finally, we conduct controlled experiments, and find that information is distributed across tokens, rather than being concentrated in specific \"meaningful\" tokens alone.",
    "link": "https://arxiv.org/abs/2402.03471",
    "context": "Title: The Information of Large Language Model Geometry\nAbstract: This paper investigates the information encoded in the embeddings of large language models (LLMs). We conduct simulations to analyze the representation entropy and discover a power law relationship with model sizes. Building upon this observation, we propose a theory based on (conditional) entropy to elucidate the scaling law phenomenon. Furthermore, we delve into the auto-regressive structure of LLMs and examine the relationship between the last token and previous context tokens using information theory and regression techniques. Specifically, we establish a theoretical connection between the information gain of new tokens and ridge regression. Additionally, we explore the effectiveness of Lasso regression in selecting meaningful tokens, which sometimes outperforms the closely related attention weights. Finally, we conduct controlled experiments, and find that information is distributed across tokens, rather than being concentrated in specific \"meaningful\" tokens alone.",
    "path": "papers/24/02/2402.03471.json",
    "total_tokens": 912,
    "translated_title": "大型语言模型几何信息的研究",
    "translated_abstract": "本文研究了大型语言模型中嵌入的信息编码。我们进行了模拟实验，分析了表示熵，并发现了与模型大小呈幂律关系的现象。基于这一观察，我们提出了一个基于（条件）熵的理论来解释这种规模定律现象。此外，我们深入探讨了LLMs的自回归结构，并使用信息理论和回归技术来分析最后一个标记与之前上下文标记之间的关系。具体而言，我们建立了新标记的信息增益与岭回归之间的理论联系。此外，我们还探索了Lasso回归在选择有意义的标记方面的有效性，有时表现优于紧密相关的注意力权重。最后，我们进行了对比实验，并发现信息分布在标记之间，而不仅仅集中在特定的“有意义”的标记上。",
    "tldr": "论文研究了大型语言模型中嵌入的信息编码，并发现表示熵与模型大小呈幂律关系。通过信息理论和回归技术，建立了新标记的信息增益与岭回归之间的理论联系，并探索了Lasso回归在选择有意义的标记方面的有效性。实验结果表明，信息在标记之间分布，而不仅仅集中在特定的“有意义”的标记上。",
    "en_tdlr": "This paper investigates the information encoded in the embeddings of large language models (LLMs) and discovers a power law relationship between representation entropy and model sizes. The paper establishes a theoretical connection between the information gain of new tokens and ridge regression, and explores the effectiveness of Lasso regression in selecting meaningful tokens. Experimental results suggest that the information is distributed across tokens, rather than being concentrated in specific \"meaningful\" tokens alone."
}