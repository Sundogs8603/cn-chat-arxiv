{
    "title": "Sourcerer: Sample-based Maximum Entropy Source Distribution Estimation",
    "abstract": "Scientific modeling applications often require estimating a distribution of parameters consistent with a dataset of observations - an inference task also known as source distribution estimation. This problem can be ill-posed, however, since many different source distributions might produce the same distribution of data-consistent simulations. To make a principled choice among many equally valid sources, we propose an approach which targets the maximum entropy distribution, i.e., prioritizes retaining as much uncertainty as possible. Our method is purely sample-based - leveraging the Sliced-Wasserstein distance to measure the discrepancy between the dataset and simulations - and thus suitable for simulators with intractable likelihoods. We benchmark our method on several tasks, and show that it can recover source distributions with substantially higher entropy without sacrificing the fidelity of the simulations. Finally, to demonstrate the utility of our approach, we infer source distri",
    "link": "https://arxiv.org/abs/2402.07808",
    "context": "Title: Sourcerer: Sample-based Maximum Entropy Source Distribution Estimation\nAbstract: Scientific modeling applications often require estimating a distribution of parameters consistent with a dataset of observations - an inference task also known as source distribution estimation. This problem can be ill-posed, however, since many different source distributions might produce the same distribution of data-consistent simulations. To make a principled choice among many equally valid sources, we propose an approach which targets the maximum entropy distribution, i.e., prioritizes retaining as much uncertainty as possible. Our method is purely sample-based - leveraging the Sliced-Wasserstein distance to measure the discrepancy between the dataset and simulations - and thus suitable for simulators with intractable likelihoods. We benchmark our method on several tasks, and show that it can recover source distributions with substantially higher entropy without sacrificing the fidelity of the simulations. Finally, to demonstrate the utility of our approach, we infer source distri",
    "path": "papers/24/02/2402.07808.json",
    "total_tokens": 925,
    "translated_title": "Sourcerer: 基于样本的最大熵源分布估计",
    "translated_abstract": "科学建模应用通常需要估计与观测数据集一致的参数分布，被称为源分布估计的推理任务。然而，这个问题可能是不适定的，因为许多不同的源分布可能产生相同的数据分布一致的模拟结果。为了在众多同样有效的源中做出有原则的选择，我们提出了一种目标最大熵分布的方法，即优先保留尽可能多的不确定性。我们的方法完全基于样本，利用切片-瓦石坦斯坦距离来衡量数据集与模拟之间的差异，因此适用于具有难以处理的似然函数的模拟器。我们在几个任务上对我们的方法进行了基准测试，并表明它可以恢复具有更高熵的源分布，而不牺牲模拟的准确性。最后，为了证明我们方法的实用性，我们推断源分布...",
    "tldr": "本论文提出了一种基于样本的最大熵源分布估计方法，通过优先保留不确定性来选择合适的源分布。该方法利用切片-瓦石坦斯坦距离对数据集和模拟进行衡量，适用于具有难以处理似然函数的模拟器。实验表明，该方法可以恢复更高熵的源分布，同时保持模拟的准确性。",
    "en_tdlr": "This paper presents a sample-based maximum entropy source distribution estimation method, which prioritizes retaining uncertainty to choose appropriate source distributions. The method leverages the Sliced-Wasserstein distance to measure the discrepancy between the dataset and simulations, and is suitable for simulators with intractable likelihoods. Experimental results show that the method can recover source distributions with higher entropy while maintaining simulation fidelity."
}