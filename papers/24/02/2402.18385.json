{
    "title": "The First Place Solution of WSDM Cup 2024: Leveraging Large Language Models for Conversational Multi-Doc QA",
    "abstract": "arXiv:2402.18385v1 Announce Type: new  Abstract: Conversational multi-doc question answering aims to answer specific questions based on the retrieved documents as well as the contextual conversations. In this paper, we introduce our winning approach for the \"Conversational Multi-Doc QA\" challenge in WSDM Cup 2024, which exploits the superior natural language understanding and generation capability of Large Language Models (LLMs). We first adapt LLMs to the task, then devise a hybrid training strategy to make the most of in-domain unlabeled data. Moreover, an advanced text embedding model is adopted to filter out potentially irrelevant documents and several approaches are designed and compared for the model ensemble. Equipped with all these techniques, our solution finally ranked 1st place in WSDM Cup 2024, surpassing its rivals to a large extent. The source codes have been released at https://github.com/zhangzhao219/WSDM-Cup-2024.",
    "link": "https://arxiv.org/abs/2402.18385",
    "context": "Title: The First Place Solution of WSDM Cup 2024: Leveraging Large Language Models for Conversational Multi-Doc QA\nAbstract: arXiv:2402.18385v1 Announce Type: new  Abstract: Conversational multi-doc question answering aims to answer specific questions based on the retrieved documents as well as the contextual conversations. In this paper, we introduce our winning approach for the \"Conversational Multi-Doc QA\" challenge in WSDM Cup 2024, which exploits the superior natural language understanding and generation capability of Large Language Models (LLMs). We first adapt LLMs to the task, then devise a hybrid training strategy to make the most of in-domain unlabeled data. Moreover, an advanced text embedding model is adopted to filter out potentially irrelevant documents and several approaches are designed and compared for the model ensemble. Equipped with all these techniques, our solution finally ranked 1st place in WSDM Cup 2024, surpassing its rivals to a large extent. The source codes have been released at https://github.com/zhangzhao219/WSDM-Cup-2024.",
    "path": "papers/24/02/2402.18385.json",
    "total_tokens": 957,
    "translated_title": "WSDM Cup 2024的第一名解决方案：利用大型语言模型进行会话式多文档问答",
    "translated_abstract": "会话式多文档问答旨在根据检索到的文档以及上下文对话来回答特定问题。本文介绍了我们在WSDM Cup 2024“会话式多文档问答”挑战中的获胜方法，利用了大型语言模型（LLMs）卓越的自然语言理解和生成能力。我们首先将LLMs改编为此任务，然后设计了混合训练策略，充分利用领域内无标签数据。此外，采用了先进的文本嵌入模型来过滤掉潜在的不相关文档，并为模型集成设计和比较了几种方法。凭借所有这些技术，我们的解决方案最终在WSDM Cup 2024中排名第一，大大超越了竞争对手。源代码已发布在https://github.com/zhangzhao219/WSDM-Cup-2024。",
    "tldr": "本文介绍了在WSDM Cup 2024中获胜的方法，利用大型语言模型（LLMs）的卓越自然语言理解和生成能力，通过改编LLMs、设计混合训练策略、采用先进的文本嵌入模型、以及模型集成等多种技术，最终在会话式多文档问答方面取得了第一名。",
    "en_tdlr": "This paper introduces the winning approach at WSDM Cup 2024, leveraging the superior natural language understanding and generation capabilities of Large Language Models (LLMs) through adapting LLMs, devising a hybrid training strategy, adopting advanced text embedding model, and model ensemble, ultimately achieving 1st place in conversational multi-doc QA."
}