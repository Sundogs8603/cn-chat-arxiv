{
    "title": "When Benchmarks are Targets: Revealing the Sensitivity of Large Language Model Leaderboards",
    "abstract": "Large Language Model (LLM) leaderboards based on benchmark rankings are regularly used to guide practitioners in model selection. Often, the published leaderboard rankings are taken at face value - we show this is a (potentially costly) mistake. Under existing leaderboards, the relative performance of LLMs is highly sensitive to (often minute) details. We show that for popular multiple choice question benchmarks (e.g. MMLU) minor perturbations to the benchmark, such as changing the order of choices or the method of answer selection, result in changes in rankings up to 8 positions. We explain this phenomenon by conducting systematic experiments over three broad categories of benchmark perturbations and identifying the sources of this behavior. Our analysis results in several best-practice recommendations, including the advantage of a hybrid scoring method for answer selection. Our study highlights the dangers of relying on simple benchmark evaluations and charts the path for more robust",
    "link": "https://arxiv.org/abs/2402.01781",
    "context": "Title: When Benchmarks are Targets: Revealing the Sensitivity of Large Language Model Leaderboards\nAbstract: Large Language Model (LLM) leaderboards based on benchmark rankings are regularly used to guide practitioners in model selection. Often, the published leaderboard rankings are taken at face value - we show this is a (potentially costly) mistake. Under existing leaderboards, the relative performance of LLMs is highly sensitive to (often minute) details. We show that for popular multiple choice question benchmarks (e.g. MMLU) minor perturbations to the benchmark, such as changing the order of choices or the method of answer selection, result in changes in rankings up to 8 positions. We explain this phenomenon by conducting systematic experiments over three broad categories of benchmark perturbations and identifying the sources of this behavior. Our analysis results in several best-practice recommendations, including the advantage of a hybrid scoring method for answer selection. Our study highlights the dangers of relying on simple benchmark evaluations and charts the path for more robust",
    "path": "papers/24/02/2402.01781.json",
    "total_tokens": 911,
    "translated_title": "当基准成为目标：揭示大型语言模型排行榜的敏感性",
    "translated_abstract": "基于基准排名的大型语言模型(LLM)排行榜经常被用来指导实践者在模型选择中。通常，发布的排行榜排名被直接接受 - 我们表明这是一个（潜在昂贵的）错误。在现有的排行榜下，LLM的相对性能对（通常微小的）细节非常敏感。我们展示了对于流行的多项选择题基准（例如MMLU），对基准的微小扰动，如改变选项顺序或答案选择方法，会导致排名变化达到8个位置。我们通过对三个广泛的基准扰动类别进行系统实验并确定这一行为的来源来解释这一现象。我们的分析得出了几个最佳实践建议，包括选择优化的混合评分方法来进行答案选择。我们的研究强调了依赖简单基准评估的风险，并为更健壮的模型评估提供了指导道路。",
    "tldr": "依赖基准排行榜的大型语言模型评估存在较高敏感性，微小的扰动会导致排名的显著变化。研究结果提供了几个最佳实践建议，包括选择混合评分方法来提高答案选择的性能。",
    "en_tdlr": "Evaluations of large language models based on benchmark rankings are highly sensitive to minor perturbations, resulting in significant changes in rankings. This study provides several best-practice recommendations, including the use of a hybrid scoring method for improved answer selection performance."
}