{
    "title": "Few-Shot Learning on Graphs: from Meta-learning to Pre-training and Prompting",
    "abstract": "Graph representation learning, a critical step in graph-centric tasks, has seen significant advancements. Earlier techniques often operate in an end-to-end setting, where performance heavily relies on the availability of ample labeled data. This constraint has spurred the emergence of few-shot learning on graphs, where only a few task-specific labels are available for each task. Given the extensive literature in this field, this survey endeavors to synthesize recent developments, provide comparative insights, and identify future directions. We systematically categorize existing studies into three major families: meta-learning approaches, pre-training approaches, and hybrid approaches, with a finer-grained classification in each family to aid readers in their method selection process. Within each category, we analyze the relationships among these methods and compare their strengths and limitations. Finally, we outline prospective future directions for few-shot learning on graphs to cata",
    "link": "https://rss.arxiv.org/abs/2402.01440",
    "context": "Title: Few-Shot Learning on Graphs: from Meta-learning to Pre-training and Prompting\nAbstract: Graph representation learning, a critical step in graph-centric tasks, has seen significant advancements. Earlier techniques often operate in an end-to-end setting, where performance heavily relies on the availability of ample labeled data. This constraint has spurred the emergence of few-shot learning on graphs, where only a few task-specific labels are available for each task. Given the extensive literature in this field, this survey endeavors to synthesize recent developments, provide comparative insights, and identify future directions. We systematically categorize existing studies into three major families: meta-learning approaches, pre-training approaches, and hybrid approaches, with a finer-grained classification in each family to aid readers in their method selection process. Within each category, we analyze the relationships among these methods and compare their strengths and limitations. Finally, we outline prospective future directions for few-shot learning on graphs to cata",
    "path": "papers/24/02/2402.01440.json",
    "total_tokens": 849,
    "translated_title": "在图上的小样本学习：从元学习到预训练和提示",
    "translated_abstract": "图表示学习是图中心任务中的关键步骤，在这方面已经取得了重大进展。早期的技术通常在端到端的设置中运行，性能严重依赖于充足的标记数据的可用性。这个限制引发了图上的小样本学习的出现，其中每个任务只有少量的任务特定标签可用。鉴于这个领域的广泛文献，本综述试图综合最近的发展，提供比较性的见解，并确定未来的方向。我们将现有的研究系统地分为三个主要类别：元学习方法、预训练方法和混合方法，并在每个类别中进行细粒度的分类，以帮助读者进行方法选择。在每个类别中，我们分析这些方法之间的关系并比较它们的优缺点。最后，我们概述了图上的小样本学习未来的方向。",
    "tldr": "本文综述了图上的小样本学习的最新发展，将现有的研究方法划分为元学习、预训练和混合方法三大类别，并对它们的优缺点进行了比较。还提出了未来的研究方向。",
    "en_tdlr": "This survey synthesizes recent developments in few-shot learning on graphs, categorizing existing methods into meta-learning, pre-training, and hybrid approaches, and comparing their strengths and limitations. Future research directions are also outlined."
}