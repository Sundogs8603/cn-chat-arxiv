{
    "title": "SymBa: Symbolic Backward Chaining for Multi-step Natural Language Reasoning",
    "abstract": "arXiv:2402.12806v1 Announce Type: new  Abstract: Large Language Models (LLMs) have recently demonstrated remarkable reasoning ability as in Chain-of-thought prompting, but faithful multi-step reasoning remains a challenge. We specifically focus on backward chaining, where the query is recursively decomposed using logical rules until proven. To address the limitations of current backward chaining implementations, we propose SymBa (Symbolic Backward Chaining). In SymBa, the symbolic top-down solver controls the entire proof process and the LLM is called to generate a single reasoning step only when the solver encounters a dead end. By this novel solver-LLM integration, while being able to produce an interpretable, structured proof, SymBa achieves significant improvement in performance, proof faithfulness, and efficiency in diverse multi-step reasoning benchmarks (ProofWriter, Birds-Electricity, GSM8k, CLUTRR-TF, ECtHR Article 6) compared to backward chaining baselines.",
    "link": "https://arxiv.org/abs/2402.12806",
    "context": "Title: SymBa: Symbolic Backward Chaining for Multi-step Natural Language Reasoning\nAbstract: arXiv:2402.12806v1 Announce Type: new  Abstract: Large Language Models (LLMs) have recently demonstrated remarkable reasoning ability as in Chain-of-thought prompting, but faithful multi-step reasoning remains a challenge. We specifically focus on backward chaining, where the query is recursively decomposed using logical rules until proven. To address the limitations of current backward chaining implementations, we propose SymBa (Symbolic Backward Chaining). In SymBa, the symbolic top-down solver controls the entire proof process and the LLM is called to generate a single reasoning step only when the solver encounters a dead end. By this novel solver-LLM integration, while being able to produce an interpretable, structured proof, SymBa achieves significant improvement in performance, proof faithfulness, and efficiency in diverse multi-step reasoning benchmarks (ProofWriter, Birds-Electricity, GSM8k, CLUTRR-TF, ECtHR Article 6) compared to backward chaining baselines.",
    "path": "papers/24/02/2402.12806.json",
    "total_tokens": 829,
    "translated_title": "SymBa：符号化向后推理用于多步自然语言推理",
    "translated_abstract": "最近大型语言模型（LLMs）展示了在一系列思维提示中出色的推理能力，但忠实的多步推理依然是一个挑战。我们专注于向后推理，即通过逻辑规则递归地分解查询，直到证明为止。为了解决当前向后推理实现的局限性，我们提出了SymBa（符号化向后推理）。在SymBa中，符号化自顶向下求解器控制整个证明过程，当求解器遇到死胡同时，才调用LLM生成单个推理步骤。通过这种新颖的求解器-LLM集成，SymBa在各种多步推理基准（ProofWriter，Birds-Electricity，GSM8k，CLUTRR-TF，ECtHR Article 6）中相比向后推理基线取得了性能、证明忠实性和效率显著提高，能够生成可解释的结构化证明。",
    "tldr": "SymBa提出了一种符号化向后推理方法，在多步自然语言推理中取得了显著的性能和效率提升，能够生成可解释的结构化证明。",
    "en_tdlr": "SymBa introduces a symbolic backward chaining approach that significantly improves performance and efficiency in multi-step natural language reasoning, capable of generating interpretable structured proofs."
}