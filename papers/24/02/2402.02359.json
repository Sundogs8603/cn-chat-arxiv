{
    "title": "Incremental Quasi-Newton Methods with Faster Superlinear Convergence Rates",
    "abstract": "We consider the finite-sum optimization problem, where each component function is strongly convex and has Lipschitz continuous gradient and Hessian. The recently proposed incremental quasi-Newton method is based on BFGS update and achieves a local superlinear convergence rate that is dependent on the condition number of the problem. This paper proposes a more efficient quasi-Newton method by incorporating the symmetric rank-1 update into the incremental framework, which results in the condition-number-free local superlinear convergence rate. Furthermore, we can boost our method by applying the block update on the Hessian approximation, which leads to an even faster local convergence rate. The numerical experiments show the proposed methods significantly outperform the baseline methods.",
    "link": "https://arxiv.org/abs/2402.02359",
    "context": "Title: Incremental Quasi-Newton Methods with Faster Superlinear Convergence Rates\nAbstract: We consider the finite-sum optimization problem, where each component function is strongly convex and has Lipschitz continuous gradient and Hessian. The recently proposed incremental quasi-Newton method is based on BFGS update and achieves a local superlinear convergence rate that is dependent on the condition number of the problem. This paper proposes a more efficient quasi-Newton method by incorporating the symmetric rank-1 update into the incremental framework, which results in the condition-number-free local superlinear convergence rate. Furthermore, we can boost our method by applying the block update on the Hessian approximation, which leads to an even faster local convergence rate. The numerical experiments show the proposed methods significantly outperform the baseline methods.",
    "path": "papers/24/02/2402.02359.json",
    "total_tokens": 751,
    "translated_title": "具有更快超线性收敛速率的增量拟牛顿方法",
    "translated_abstract": "本文考虑了有限和优化问题，其中每个分量函数都是强凸的，并且具有Lipschitz连续的梯度和Hessian矩阵。最近提出的增量拟牛顿方法基于BFGS更新，达到了依赖于问题条件数的局部超线性收敛速率。本文提出了一种更高效的拟牛顿方法，通过将对称秩一更新结合到增量框架中，从而实现了无条件数的局部超线性收敛速率。此外，我们可以通过在Hessian近似值上应用块更新来提升我们的方法，从而导致更快的局部收敛速率。数值实验表明，所提出的方法明显优于基线方法。",
    "tldr": "本文提出了一种更高效的增量拟牛顿方法，通过引入对称秩一更新和块更新的方式，实现了无条件数的局部超线性收敛速率，并且在数值实验中取得了显著优于基线方法的结果。",
    "en_tdlr": "This paper proposes a more efficient incremental quasi-Newton method by incorporating symmetric rank-1 update and block update, achieving condition-number-free local superlinear convergence rate, and outperforming baseline methods in numerical experiments."
}