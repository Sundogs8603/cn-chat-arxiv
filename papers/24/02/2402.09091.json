{
    "title": "Play Guessing Game with LLM: Indirect Jailbreak Attack with Implicit Clues",
    "abstract": "arXiv:2402.09091v1 Announce Type: cross Abstract: With the development of LLMs, the security threats of LLMs are getting more and more attention. Numerous jailbreak attacks have been proposed to assess the security defense of LLMs. Current jailbreak attacks primarily utilize scenario camouflage techniques. However their explicitly mention of malicious intent will be easily recognized and defended by LLMs. In this paper, we propose an indirect jailbreak attack approach, Puzzler, which can bypass the LLM's defense strategy and obtain malicious response by implicitly providing LLMs with some clues about the original malicious query. In addition, inspired by the wisdom of ''When unable to attack, defend'' from Sun Tzu's Art of War, we adopt a defensive stance to gather clues about the original malicious query through LLMs. Extensive experimental results show that Puzzler achieves a query success rate of 96.6% on closed-source LLMs, which is 57.9%-82.7% higher than baselines. Furthermore, w",
    "link": "https://arxiv.org/abs/2402.09091",
    "context": "Title: Play Guessing Game with LLM: Indirect Jailbreak Attack with Implicit Clues\nAbstract: arXiv:2402.09091v1 Announce Type: cross Abstract: With the development of LLMs, the security threats of LLMs are getting more and more attention. Numerous jailbreak attacks have been proposed to assess the security defense of LLMs. Current jailbreak attacks primarily utilize scenario camouflage techniques. However their explicitly mention of malicious intent will be easily recognized and defended by LLMs. In this paper, we propose an indirect jailbreak attack approach, Puzzler, which can bypass the LLM's defense strategy and obtain malicious response by implicitly providing LLMs with some clues about the original malicious query. In addition, inspired by the wisdom of ''When unable to attack, defend'' from Sun Tzu's Art of War, we adopt a defensive stance to gather clues about the original malicious query through LLMs. Extensive experimental results show that Puzzler achieves a query success rate of 96.6% on closed-source LLMs, which is 57.9%-82.7% higher than baselines. Furthermore, w",
    "path": "papers/24/02/2402.09091.json",
    "total_tokens": 899,
    "translated_title": "与LLM玩猜谜游戏: 通过隐含提示的间接越狱攻击",
    "translated_abstract": "随着LLM的发展，LLM的安全威胁越来越受到关注。许多越狱攻击已经提出来评估LLM的安全防御。目前的越狱攻击主要使用场景伪装技术。然而，它们对恶意意图的明确提及很容易被LLM识别和防御。在本文中，我们提出了一种间接越狱攻击方法，名为Puzzler，它可以通过隐含地为LLM提供一些有关原始恶意查询的提示来绕过LLM的防御策略并获取恶意响应。此外，受孙子的《孙子兵法》中“当攻无法攻，守”智慧的启发，我们采取了一种防御姿态来通过LLM收集关于原始恶意查询的线索。大量的实验结果表明，Puzzler在闭源LLM上的查询成功率为96.6%，比基准线高57.9%-82.7%。",
    "tldr": "通过提供隐含的线索，Puzzler通过绕过LLM的防御策略，在间接方式下实现了越狱攻击，成功率高达96.6%。",
    "en_tdlr": "Puzzler achieves a jailbreak attack with a success rate of 96.6% on closed-source LLMs by bypassing their defense strategy through implicitly providing clues."
}