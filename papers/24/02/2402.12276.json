{
    "title": "Explain then Rank: Scale Calibration of Neural Rankers Using Natural Language Explanations from Large Language Models",
    "abstract": "arXiv:2402.12276v1 Announce Type: new  Abstract: The process of scale calibration in ranking systems involves adjusting the outputs of rankers to correspond with significant qualities like click-through rates or relevance, crucial for mirroring real-world value and thereby boosting the system's effectiveness and reliability. Although there has been research on calibrated ranking losses within learning-to-rank models, the particular issue of adjusting the scale for neural rankers, which excel in handling textual information, has not been thoroughly examined. Neural ranking models are adept at processing text data, yet the application of existing scale calibration techniques to these models poses significant challenges due to their complexity and the intensive training they require, often resulting in suboptimal outcomes.   This study delves into the potential of large language models (LLMs) to provide uncertainty measurements for a query and document pair that correlate with the scale-c",
    "link": "https://arxiv.org/abs/2402.12276",
    "context": "Title: Explain then Rank: Scale Calibration of Neural Rankers Using Natural Language Explanations from Large Language Models\nAbstract: arXiv:2402.12276v1 Announce Type: new  Abstract: The process of scale calibration in ranking systems involves adjusting the outputs of rankers to correspond with significant qualities like click-through rates or relevance, crucial for mirroring real-world value and thereby boosting the system's effectiveness and reliability. Although there has been research on calibrated ranking losses within learning-to-rank models, the particular issue of adjusting the scale for neural rankers, which excel in handling textual information, has not been thoroughly examined. Neural ranking models are adept at processing text data, yet the application of existing scale calibration techniques to these models poses significant challenges due to their complexity and the intensive training they require, often resulting in suboptimal outcomes.   This study delves into the potential of large language models (LLMs) to provide uncertainty measurements for a query and document pair that correlate with the scale-c",
    "path": "papers/24/02/2402.12276.json",
    "total_tokens": 797,
    "translated_title": "用大型语言模型的自然语言解释进行神经排序器的规模校准解释和排名",
    "translated_abstract": "排名系统中的规模校准过程涉及调整排序器的输出，以使其与重要品质（如点击率或相关性）相对应，这对于反映现实价值以及提高系统的效果和可靠性至关重要。虽然已经研究了学习排序模型中的校准排序损失，但调整神经排序器的规模的特定问题，这些模型擅长处理文本信息，尚未得到充分研究。神经排序模型擅长处理文本数据，但将现有规模校准技术应用到这些模型会面临重大挑战，因为它们的复杂性和需要大量训练，往往导致次优结果。",
    "tldr": "本研究探讨了大型语言模型（LLMs）利用提供与规模校准相关的查询和文档对的不确定性测量的潜力，以解决神经排序器的规模校准问题。"
}