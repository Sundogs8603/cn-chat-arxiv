{
    "title": "LVCHAT: Facilitating Long Video Comprehension",
    "abstract": "arXiv:2402.12079v1 Announce Type: cross  Abstract: Enabling large language models (LLMs) to read videos is vital for multimodal LLMs. Existing works show promise on short videos whereas long video (longer than e.g.~1 minute) comprehension remains challenging. The major problem lies in the over-compression of videos, i.e., the encoded video representations are not enough to represent the whole video. To address this issue, we propose Long Video Chat (LVChat), where Frame-Scalable Encoding (FSE) is introduced to dynamically adjust the number of embeddings in alignment with the duration of the video to ensure long videos are not overly compressed into a few embeddings. To deal with long videos whose length is beyond videos seen during training, we propose Interleaved Frame Encoding (IFE), repeating positional embedding and interleaving multiple groups of videos to enable long video input, avoiding performance degradation due to overly long videos. Experimental results show that LVChat sig",
    "link": "https://arxiv.org/abs/2402.12079",
    "context": "Title: LVCHAT: Facilitating Long Video Comprehension\nAbstract: arXiv:2402.12079v1 Announce Type: cross  Abstract: Enabling large language models (LLMs) to read videos is vital for multimodal LLMs. Existing works show promise on short videos whereas long video (longer than e.g.~1 minute) comprehension remains challenging. The major problem lies in the over-compression of videos, i.e., the encoded video representations are not enough to represent the whole video. To address this issue, we propose Long Video Chat (LVChat), where Frame-Scalable Encoding (FSE) is introduced to dynamically adjust the number of embeddings in alignment with the duration of the video to ensure long videos are not overly compressed into a few embeddings. To deal with long videos whose length is beyond videos seen during training, we propose Interleaved Frame Encoding (IFE), repeating positional embedding and interleaving multiple groups of videos to enable long video input, avoiding performance degradation due to overly long videos. Experimental results show that LVChat sig",
    "path": "papers/24/02/2402.12079.json",
    "total_tokens": 777,
    "translated_title": "LVCHAT: 促进长视频理解",
    "translated_abstract": "启用大型语言模型（LLMs）读取视频对于多模式LLMs至关重要。现有作品展示了对短视频的希望，而长视频（超过1分钟）的理解仍然具有挑战性。主要问题在于视频的过度压缩，即编码视频表示不足以代表整个视频。为了解决这个问题，我们提出了Long Video Chat（LVChat），其中引入了Frame-Scalable编码（FSE），以动态调整嵌入数量，与视频持续时间对齐，确保长视频不会被过度压缩为少数嵌入。为了处理长度超出训练过程中所见视频的长视频，我们提出了Interleaved Frame Encoding（IFE），重复位置嵌入和交错多组视频，以实现长视频输入，避免因视频过长而导致性能降低。实验结果表明LVChat sig",
    "tldr": "LVChat 提出了 Frame-Scalable 编码和 Interleaved Frame Encoding（IFE）来解决长视频理解中的问题。",
    "en_tdlr": "LVChat proposes Frame-Scalable encoding and Interleaved Frame Encoding (IFE) to address the challenges of long video comprehension."
}