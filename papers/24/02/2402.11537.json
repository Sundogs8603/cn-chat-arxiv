{
    "title": "Deciphering the lmpact of Pretraining Data on Large Language Models through Machine Unlearning",
    "abstract": "arXiv:2402.11537v1 Announce Type: cross  Abstract: Through pretraining on a corpus with various sources, Large Language Models (LLMs) have gained impressive performance. However, the impact of each component of the pretraining corpus remains opaque. As a result, the organization of the pretraining corpus is still empirical and may deviate from the optimal. To address this issue, we systematically analyze the impact of 48 datasets from 5 major categories of pretraining data of LLMs and measure their impacts on LLMs using benchmarks about nine major categories of model capabilities. Our analyses provide empirical results about the contribution of multiple corpora on the performances of LLMs, along with their joint impact patterns, including complementary, orthogonal, and correlational relationships. We also identify a set of ``high-impact data'' such as Books that is significantly related to a set of model capabilities. These findings provide insights into the organization of data to sup",
    "link": "https://arxiv.org/abs/2402.11537",
    "context": "Title: Deciphering the lmpact of Pretraining Data on Large Language Models through Machine Unlearning\nAbstract: arXiv:2402.11537v1 Announce Type: cross  Abstract: Through pretraining on a corpus with various sources, Large Language Models (LLMs) have gained impressive performance. However, the impact of each component of the pretraining corpus remains opaque. As a result, the organization of the pretraining corpus is still empirical and may deviate from the optimal. To address this issue, we systematically analyze the impact of 48 datasets from 5 major categories of pretraining data of LLMs and measure their impacts on LLMs using benchmarks about nine major categories of model capabilities. Our analyses provide empirical results about the contribution of multiple corpora on the performances of LLMs, along with their joint impact patterns, including complementary, orthogonal, and correlational relationships. We also identify a set of ``high-impact data'' such as Books that is significantly related to a set of model capabilities. These findings provide insights into the organization of data to sup",
    "path": "papers/24/02/2402.11537.json",
    "total_tokens": 918,
    "translated_title": "通过机器去学习研究预训练数据对大型语言模型的影响",
    "translated_abstract": "通过在具有各种来源的语料库上进行预训练，大型语言模型（LLMs）取得了令人印象深刻的性能。然而，预训练语料库的每个组成部分的影响仍然不明确。因此，预训练语料库的组织仍然是经验性的，并且可能偏离最佳状态。为了解决这个问题，我们系统地分析了来自LLMs预训练数据的5个主要类别的48个数据集的影响，并使用关于九个主要模型能力类别的基准来衡量它们对LLMs的影响。我们的分析提供了关于多个语料库对LLMs性能贡献的实证结果，以及它们的联合影响模式，包括互补的、正交的和相关的关系。我们还确定了一组“高影响数据”，如书籍，与一组模型能力相关联。这些发现为我们提供了关于组织数据以支持LLMs优化的见解。",
    "tldr": "通过对五个主要类别的预训练数据的48个数据集进行系统分析，研究了它们对大型语言模型性能的影响，并发现了一些“高影响数据”，如书籍，与模型能力相关联，为LLMs的优化提供了见解。",
    "en_tdlr": "Systematically analyze the impact of 48 datasets from 5 major categories of pretraining data on Large Language Models (LLMs), identifying \"high-impact data\" such as Books significantly related to model capabilities, providing insights for LLMs optimization."
}