{
    "title": "Expressive Whole-Body Control for Humanoid Robots",
    "abstract": "arXiv:2402.16796v2 Announce Type: replace-cross  Abstract: Can we enable humanoid robots to generate rich, diverse, and expressive motions in the real world? We propose to learn a whole-body control policy on a human-sized robot to mimic human motions as realistic as possible. To train such a policy, we leverage the large-scale human motion capture data from the graphics community in a Reinforcement Learning framework. However, directly performing imitation learning with the motion capture dataset would not work on the real humanoid robot, given the large gap in degrees of freedom and physical capabilities. Our method Expressive Whole-Body Control (Exbody) tackles this problem by encouraging the upper humanoid body to imitate a reference motion, while relaxing the imitation constraint on its two legs and only requiring them to follow a given velocity robustly. With training in simulation and Sim2Real transfer, our policy can control a humanoid robot to walk in different styles, shake h",
    "link": "https://arxiv.org/abs/2402.16796",
    "context": "Title: Expressive Whole-Body Control for Humanoid Robots\nAbstract: arXiv:2402.16796v2 Announce Type: replace-cross  Abstract: Can we enable humanoid robots to generate rich, diverse, and expressive motions in the real world? We propose to learn a whole-body control policy on a human-sized robot to mimic human motions as realistic as possible. To train such a policy, we leverage the large-scale human motion capture data from the graphics community in a Reinforcement Learning framework. However, directly performing imitation learning with the motion capture dataset would not work on the real humanoid robot, given the large gap in degrees of freedom and physical capabilities. Our method Expressive Whole-Body Control (Exbody) tackles this problem by encouraging the upper humanoid body to imitate a reference motion, while relaxing the imitation constraint on its two legs and only requiring them to follow a given velocity robustly. With training in simulation and Sim2Real transfer, our policy can control a humanoid robot to walk in different styles, shake h",
    "path": "papers/24/02/2402.16796.json",
    "total_tokens": 924,
    "translated_title": "人形机器人的表现全身控制",
    "translated_abstract": "我们提出在真实世界中让人形机器人生成丰富、多样和富有表现力的动作。我们建议在一个人类大小的机器人上学习一个全身控制策略，以尽可能逼真地模仿人类动作。为了训练这样一个策略，我们在强化学习框架中利用了来自图形学界的大规模人体动作捕捉数据。然而，直接使用动作捕捉数据集进行模仿学习在真实人形机器人上并不奏效，因为在自由度和物理能力方面存在较大差距。我们的方法——表现全身控制(Exbody)通过鼓励上半身模仿参考运动来解决这个问题，同时松开对其两条腿的模仿约束，只要求它们稳固地遵循给定的速度。通过在模拟环境中训练和Sim2Real转移，我们的策略能够控制人形机器人以不同风格行走，摇晃等。",
    "tldr": "我们提出了一种表现全身控制（Exbody）方法，通过在人类大小的机器人上学习全身控制策略，使其能够模仿人类动作，并通过在模拟环境中训练和Sim2Real转移，实现控制人形机器人以不同风格行走、摇晃等。",
    "en_tdlr": "We propose the Exbody method for expressive whole-body control, which enables a human-sized robot to mimic human motions and control the humanoid robot to walk in different styles, shake, etc. through training in a simulation environment and Sim2Real transfer."
}