{
    "title": "I can't see it but I can Fine-tune it: On Encrypted Fine-tuning of Transformers using Fully Homomorphic Encryption",
    "abstract": "arXiv:2402.09059v1 Announce Type: cross Abstract: In today's machine learning landscape, fine-tuning pretrained transformer models has emerged as an essential technique, particularly in scenarios where access to task-aligned training data is limited. However, challenges surface when data sharing encounters obstacles due to stringent privacy regulations or user apprehension regarding personal information disclosure. Earlier works based on secure multiparty computation (SMC) and fully homomorphic encryption (FHE) for privacy-preserving machine learning (PPML) focused more on privacy-preserving inference than privacy-preserving training. In response, we introduce BlindTuner, a privacy-preserving fine-tuning system that enables transformer training exclusively on homomorphically encrypted data for image classification. Our extensive experimentation validates BlindTuner's effectiveness by demonstrating comparable accuracy to non-encrypted models. Notably, our findings highlight a substantia",
    "link": "https://arxiv.org/abs/2402.09059",
    "context": "Title: I can't see it but I can Fine-tune it: On Encrypted Fine-tuning of Transformers using Fully Homomorphic Encryption\nAbstract: arXiv:2402.09059v1 Announce Type: cross Abstract: In today's machine learning landscape, fine-tuning pretrained transformer models has emerged as an essential technique, particularly in scenarios where access to task-aligned training data is limited. However, challenges surface when data sharing encounters obstacles due to stringent privacy regulations or user apprehension regarding personal information disclosure. Earlier works based on secure multiparty computation (SMC) and fully homomorphic encryption (FHE) for privacy-preserving machine learning (PPML) focused more on privacy-preserving inference than privacy-preserving training. In response, we introduce BlindTuner, a privacy-preserving fine-tuning system that enables transformer training exclusively on homomorphically encrypted data for image classification. Our extensive experimentation validates BlindTuner's effectiveness by demonstrating comparable accuracy to non-encrypted models. Notably, our findings highlight a substantia",
    "path": "papers/24/02/2402.09059.json",
    "total_tokens": 885,
    "translated_title": "我看不见它，但我可以微调它：使用全同态加密对Transformer进行加密微调",
    "translated_abstract": "在当前的机器学习环境中，微调预训练的Transformer模型已经成为一种重要的技术，特别是在训练数据有限的情况下。然而，当数据共享遇到障碍时，如严格的隐私法规或用户对个人信息披露的担忧，就会出现挑战。早期基于安全多方计算（SMC）和全同态加密（FHE）的隐私保护机器学习（PPML）的工作更注重隐私保护的推理而不是隐私保护的训练。为此，我们引入了BlindTuner，一种隐私保护的微调系统，可实现对Transformer模型基于全同态加密数据的训练，用于图像分类。我们进行了大量实验验证了BlindTuner的有效性，并证明其与非加密模型相比准确性相当。值得注意的是，我们的研究结果突出了一些重要的创新和贡献。",
    "tldr": "本文介绍了一种使用全同态加密进行隐私保护微调的系统BlindTuner，它可以在图像分类任务中实现对Transformer模型的隐私保护训练，并在准确性上与非加密模型相当。",
    "en_tdlr": "This paper introduces BlindTuner, a privacy-preserving fine-tuning system that uses fully homomorphic encryption for training Transformer models in image classification. The system achieves comparable accuracy to non-encrypted models, demonstrating its effectiveness in privacy-preserving training."
}