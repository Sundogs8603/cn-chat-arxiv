{
    "title": "Bias in Opinion Summarisation from Pre-training to Adaptation: A Case Study in Political Bias",
    "abstract": "Opinion summarisation aims to summarise the salient information and opinions presented in documents such as product reviews, discussion forums, and social media texts into short summaries that enable users to effectively understand the opinions therein. Generating biased summaries has the risk of potentially swaying public opinion. Previous studies focused on studying bias in opinion summarisation using extractive models, but limited research has paid attention to abstractive summarisation models. In this study, using political bias as a case study, we first establish a methodology to quantify bias in abstractive models, then trace it from the pre-trained models to the task of summarising social media opinions using different models and adaptation methods. We find that most models exhibit intrinsic bias. Using a social media text summarisation dataset and contrasting various adaptation methods, we find that tuning a smaller number of parameters is less biased compared to standard fine-",
    "link": "https://arxiv.org/abs/2402.00322",
    "context": "Title: Bias in Opinion Summarisation from Pre-training to Adaptation: A Case Study in Political Bias\nAbstract: Opinion summarisation aims to summarise the salient information and opinions presented in documents such as product reviews, discussion forums, and social media texts into short summaries that enable users to effectively understand the opinions therein. Generating biased summaries has the risk of potentially swaying public opinion. Previous studies focused on studying bias in opinion summarisation using extractive models, but limited research has paid attention to abstractive summarisation models. In this study, using political bias as a case study, we first establish a methodology to quantify bias in abstractive models, then trace it from the pre-trained models to the task of summarising social media opinions using different models and adaptation methods. We find that most models exhibit intrinsic bias. Using a social media text summarisation dataset and contrasting various adaptation methods, we find that tuning a smaller number of parameters is less biased compared to standard fine-",
    "path": "papers/24/02/2402.00322.json",
    "total_tokens": 908,
    "translated_title": "从预训练到适应过程中的观点摘要偏见：政治偏见的案例研究",
    "translated_abstract": "观点摘要的目标是将产品评价、讨论论坛和社交媒体文本等文件中呈现的重要信息和意见总结成简洁的摘要，使用户能够有效地了解其中的意见。生成有偏见的摘要可能会影响公众舆论。先前的研究主要关注使用抽取模型研究观点摘要的偏见，但对于生成模型的研究有限。在本研究中，以政治偏见为案例，我们首先建立了一种量化生成模型偏见的方法，然后从预训练模型追溯到使用不同模型和适应方法进行社交媒体观点摘要的任务。我们发现大多数模型存在固有偏见。使用社交媒体文本摘要数据集，对比了各种适应方法，我们发现调整较少参数的模型相比标准的微调模型更加无偏见。",
    "tldr": "本研究通过以政治偏见为例，量化了生成模型中的偏见，并发现大多数模型存在固有偏见。通过对比各种适应方法，在社交媒体观点摘要任务中发现，调整较少参数的模型相对于标准微调模型来说具有较少的偏见。",
    "en_tdlr": "This study quantifies bias in generative models, with a focus on political bias, and finds that most models exhibit inherent bias. By comparing various adaptation methods, it is found that models with fewer tuned parameters have less bias in the task of summarizing social media opinions."
}