{
    "title": "Delving into Multi-modal Multi-task Foundation Models for Road Scene Understanding: From Learning Paradigm Perspectives",
    "abstract": "Foundation models have indeed made a profound impact on various fields, emerging as pivotal components that significantly shape the capabilities of intelligent systems. In the context of intelligent vehicles, leveraging the power of foundation models has proven to be transformative, offering notable advancements in visual understanding. Equipped with multi-modal and multi-task learning capabilities, multi-modal multi-task visual understanding foundation models (MM-VUFMs) effectively process and fuse data from diverse modalities and simultaneously handle various driving-related tasks with powerful adaptability, contributing to a more holistic understanding of the surrounding scene. In this survey, we present a systematic analysis of MM-VUFMs specifically designed for road scenes. Our objective is not only to provide a comprehensive overview of common practices, referring to task-specific models, unified multi-modal models, unified multi-task models, and foundation model prompting techni",
    "link": "https://arxiv.org/abs/2402.02968",
    "context": "Title: Delving into Multi-modal Multi-task Foundation Models for Road Scene Understanding: From Learning Paradigm Perspectives\nAbstract: Foundation models have indeed made a profound impact on various fields, emerging as pivotal components that significantly shape the capabilities of intelligent systems. In the context of intelligent vehicles, leveraging the power of foundation models has proven to be transformative, offering notable advancements in visual understanding. Equipped with multi-modal and multi-task learning capabilities, multi-modal multi-task visual understanding foundation models (MM-VUFMs) effectively process and fuse data from diverse modalities and simultaneously handle various driving-related tasks with powerful adaptability, contributing to a more holistic understanding of the surrounding scene. In this survey, we present a systematic analysis of MM-VUFMs specifically designed for road scenes. Our objective is not only to provide a comprehensive overview of common practices, referring to task-specific models, unified multi-modal models, unified multi-task models, and foundation model prompting techni",
    "path": "papers/24/02/2402.02968.json",
    "total_tokens": 908,
    "translated_title": "探究多模态多任务基础模型用于道路场景理解：从学习视角的观点",
    "translated_abstract": "基础模型的确对各个领域产生了深远的影响，成为显著塑造智能系统能力的关键组件。在智能车辆的背景下，利用基础模型的力量已被证明具有变革性，显著推进了视觉理解的进展。多模态多任务视觉理解基础模型(MM-VUFMs)具备多模态和多任务学习能力，能够有效地处理和融合来自不同模态的数据，并同时处理各种与驾驶相关的任务，具备强大的适应性，为对周围场景的更全面理解做出贡献。在本调查中，我们对专门设计用于道路场景的MM-VUFMs进行了系统分析。我们的目标不仅是提供对常见实践的综合概述，涉及任务特定模型、统一的多模态模型、统一的多任务模型和基础模型促进技术。",
    "tldr": "本调查对多模态多任务视觉理解基础模型在道路场景中的应用进行了系统分析，展示了其多模态和多任务学习能力，在处理各种驾驶相关任务方面具有强大的适应性，为实现对周围场景的更全面理解做出了重要贡献。",
    "en_tdlr": "This survey provides a systematic analysis of the application of multi-modal multi-task visual understanding foundation models (MM-VUFMs) in road scenes, showcasing their abilities in multi-modal and multi-task learning, powerful adaptability in handling various driving-related tasks, and significant contributions to achieving a more comprehensive understanding of the surrounding scene."
}