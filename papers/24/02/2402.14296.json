{
    "title": "Mitigating Biases of Large Language Models in Stance Detection with Calibration",
    "abstract": "arXiv:2402.14296v1 Announce Type: new  Abstract: Large language models (LLMs) have achieved remarkable progress in many natural language processing tasks. However, our experiment reveals that, in stance detection tasks, LLMs may generate biased stances due to spurious sentiment-stance correlation and preference towards certain individuals and topics, thus harming their performance. Therefore, in this paper, we propose to Mitigate Biases of LLMs in stance detection with Calibration (MB-Cal). In which, a novel gated calibration network is devised to mitigate the biases on the stance reasoning results from LLMs. Further, to make the calibration more accurate and generalizable, we construct counterfactual augmented data to rectify stance biases. Experimental results on in-target and zero-shot stance detection tasks show that the proposed MB-Cal can effectively mitigate biases of LLMs, achieving state-of-the-art results.",
    "link": "https://arxiv.org/abs/2402.14296",
    "context": "Title: Mitigating Biases of Large Language Models in Stance Detection with Calibration\nAbstract: arXiv:2402.14296v1 Announce Type: new  Abstract: Large language models (LLMs) have achieved remarkable progress in many natural language processing tasks. However, our experiment reveals that, in stance detection tasks, LLMs may generate biased stances due to spurious sentiment-stance correlation and preference towards certain individuals and topics, thus harming their performance. Therefore, in this paper, we propose to Mitigate Biases of LLMs in stance detection with Calibration (MB-Cal). In which, a novel gated calibration network is devised to mitigate the biases on the stance reasoning results from LLMs. Further, to make the calibration more accurate and generalizable, we construct counterfactual augmented data to rectify stance biases. Experimental results on in-target and zero-shot stance detection tasks show that the proposed MB-Cal can effectively mitigate biases of LLMs, achieving state-of-the-art results.",
    "path": "papers/24/02/2402.14296.json",
    "total_tokens": 843,
    "translated_title": "在立场检测中通过校准减轻大语言模型的偏见",
    "translated_abstract": "大语言模型（LLMs）在许多自然语言处理任务中取得了显著进展。然而，我们的实验证明，在立场检测任务中，LLMs可能会生成偏见立场，这是由于虚假情感-立场相关性和对某些个人和主题的偏好，从而损害了它们的性能。因此，在本文中，我们提出通过校准来减轻LLMs在立场检测中的偏见（MB-Cal）。在其中，设计了一种新颖的门控校准网络，以减轻LLMs产生的立场推理结果上的偏见。此外，为了使校准更准确和可推广，我们构建了反事实增强数据来矫正立场偏见。针对目标和零射击立场检测任务的实验结果表明，所提出的MB-Cal可以有效减轻LLMs的偏见，取得了最先进的结果。",
    "tldr": "本文提出了一种通过校准来减轻大语言模型在立场检测中偏见的方法，设计了门控校准网络并构建了反事实增强数据，实验证明其效果显著。",
    "en_tdlr": "This paper proposes a method to mitigate biases of large language models in stance detection through calibration, by designing a gated calibration network and constructing counterfactual augmented data, with experimental results showing significant effectiveness."
}