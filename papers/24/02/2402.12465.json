{
    "title": "Neuro-mimetic Task-free Unsupervised Online Learning with Continual Self-Organizing Maps",
    "abstract": "arXiv:2402.12465v1 Announce Type: new  Abstract: An intelligent system capable of continual learning is one that can process and extract knowledge from potentially infinitely long streams of pattern vectors. The major challenge that makes crafting such a system difficult is known as catastrophic forgetting - an agent, such as one based on artificial neural networks (ANNs), struggles to retain previously acquired knowledge when learning from new samples. Furthermore, ensuring that knowledge is preserved for previous tasks becomes more challenging when input is not supplemented with task boundary information. Although forgetting in the context of ANNs has been studied extensively, there still exists far less work investigating it in terms of unsupervised architectures such as the venerable self-organizing map (SOM), a neural model often used in clustering and dimensionality reduction. While the internal mechanisms of SOMs could, in principle, yield sparse representations that improve mem",
    "link": "https://arxiv.org/abs/2402.12465",
    "context": "Title: Neuro-mimetic Task-free Unsupervised Online Learning with Continual Self-Organizing Maps\nAbstract: arXiv:2402.12465v1 Announce Type: new  Abstract: An intelligent system capable of continual learning is one that can process and extract knowledge from potentially infinitely long streams of pattern vectors. The major challenge that makes crafting such a system difficult is known as catastrophic forgetting - an agent, such as one based on artificial neural networks (ANNs), struggles to retain previously acquired knowledge when learning from new samples. Furthermore, ensuring that knowledge is preserved for previous tasks becomes more challenging when input is not supplemented with task boundary information. Although forgetting in the context of ANNs has been studied extensively, there still exists far less work investigating it in terms of unsupervised architectures such as the venerable self-organizing map (SOM), a neural model often used in clustering and dimensionality reduction. While the internal mechanisms of SOMs could, in principle, yield sparse representations that improve mem",
    "path": "papers/24/02/2402.12465.json",
    "total_tokens": 856,
    "translated_title": "具有持续自组织映射的神经仿真无任务无监督在线学习",
    "translated_abstract": "一种具有持续学习能力的智能系统能够从潜在的无限长的模式向量流中提取知识。这种系统面临的主要挑战是灾难性遗忘，即当学习新样本时，如基于人工神经网络（ANNs）的代理无法保留先前获得的知识。此外，并没有补充任务边界信息的输入会使为以前的任务保留知识变得更具挑战性。尽管在人工神经网络的背景下对遗忘进行了广泛研究，但在无监督架构方面的研究工作还远远不够，比如著名的自组织映射（SOM），这是一种常用于聚类和降维的神经模型。尽管SOM的内部机制原则上可能产生改进记忆的稀疏表示",
    "tldr": "该研究提出了一种具有持续学习能力的神经仿真系统，克服了灾难性遗忘问题，并研究了在无监督架构中的应用，尤其是自组织映射模型。",
    "en_tdlr": "The study introduces a neuro-mimetic system capable of continual learning to address catastrophic forgetting issue and explores its application in unsupervised architectures, particularly the self-organizing map model."
}