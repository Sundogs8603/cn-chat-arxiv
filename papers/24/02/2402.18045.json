{
    "title": "Multi-FAct: Assessing Multilingual LLMs' Multi-Regional Knowledge using FActScore",
    "abstract": "arXiv:2402.18045v1 Announce Type: new  Abstract: Large Language Models (LLMs) are prone to factuality hallucination, generating text that contradicts established knowledge. While extensive research has addressed this in English, little is known about multilingual LLMs. This paper systematically evaluates multilingual LLMs' factual accuracy across languages and geographic regions. We introduce a novel pipeline for multilingual factuality evaluation, adapting FActScore(Min et al., 2023) for diverse languages. Our analysis across nine languages reveals that English consistently outperforms others in factual accuracy and quantity of generated facts. Furthermore, multilingual models demonstrate a bias towards factual information from Western continents. These findings highlight the need for improved multilingual factuality assessment and underscore geographical biases in LLMs' fact generation.",
    "link": "https://arxiv.org/abs/2402.18045",
    "context": "Title: Multi-FAct: Assessing Multilingual LLMs' Multi-Regional Knowledge using FActScore\nAbstract: arXiv:2402.18045v1 Announce Type: new  Abstract: Large Language Models (LLMs) are prone to factuality hallucination, generating text that contradicts established knowledge. While extensive research has addressed this in English, little is known about multilingual LLMs. This paper systematically evaluates multilingual LLMs' factual accuracy across languages and geographic regions. We introduce a novel pipeline for multilingual factuality evaluation, adapting FActScore(Min et al., 2023) for diverse languages. Our analysis across nine languages reveals that English consistently outperforms others in factual accuracy and quantity of generated facts. Furthermore, multilingual models demonstrate a bias towards factual information from Western continents. These findings highlight the need for improved multilingual factuality assessment and underscore geographical biases in LLMs' fact generation.",
    "path": "papers/24/02/2402.18045.json",
    "total_tokens": 824,
    "translated_title": "Multi-FAct: 使用FActScore评估多语言LLM的多区域知识",
    "translated_abstract": "大型语言模型（LLMs）容易出现事实上的幻觉，生成与已知知识相矛盾的文本。尽管广泛研究了英语中的这一问题，但对于多语言LLMs知之甚少。本文系统评估了多语言LLMs跨语言和地理区域的事实准确性。我们引入了一个新颖的多语言事实评估流程，将FActScore（Min等，2023）改编为多样化语言。我们在九种语言上的分析显示，英语在事实准确性和生成事实数量方面始终表现优异。此外，多语言模型展现出对来自西方大陆的事实信息的偏见。这些发现突显了对改进多语言事实性评估的需求，并强调了LLMs的事实生成中的地理偏见。",
    "tldr": "本文系统评估了多语言LLMs跨语言和地理区域的事实准确性，并发现英语在事实准确性和生成事实数量方面优于其他语言，同时多语言模型存在对来自西方大陆事实信息的偏见。",
    "en_tdlr": "This paper systematically evaluates the factual accuracy of multilingual LLMs across languages and geographic regions, finding that English outperforms other languages in factual accuracy and quantity of generated facts, while multilingual models demonstrate bias towards factual information from Western continents."
}