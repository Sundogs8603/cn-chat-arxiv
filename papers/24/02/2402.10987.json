{
    "title": "WilKE: Wise-Layer Knowledge Editor for Lifelong Knowledge Editing",
    "abstract": "arXiv:2402.10987v1 Announce Type: cross  Abstract: Knowledge editing aims to rectify inaccuracies in large language models (LLMs) without costly retraining for outdated or erroneous knowledge. However, current knowledge editing methods primarily focus on single editing, failing to meet the requirements for lifelong editing. In this paper, lifelong editing is synonymous with lifelong knowledge editing. This study reveals a performance degradation encountered by knowledge editing in lifelong editing, characterized by toxicity buildup and toxicity flash, with the primary cause identified as pattern unmatch. We introduce a knowledge editing approach named WilKE, which selects editing layer based on the pattern matching degree of editing knowledge across different layers. Experimental results demonstrate that, in lifelong editing, WilKE exhibits an average improvement of 46.2\\% and 67.8\\% on editing GPT2-XL and GPT-J relative to state-of-the-art knowledge editing methods.",
    "link": "https://arxiv.org/abs/2402.10987",
    "context": "Title: WilKE: Wise-Layer Knowledge Editor for Lifelong Knowledge Editing\nAbstract: arXiv:2402.10987v1 Announce Type: cross  Abstract: Knowledge editing aims to rectify inaccuracies in large language models (LLMs) without costly retraining for outdated or erroneous knowledge. However, current knowledge editing methods primarily focus on single editing, failing to meet the requirements for lifelong editing. In this paper, lifelong editing is synonymous with lifelong knowledge editing. This study reveals a performance degradation encountered by knowledge editing in lifelong editing, characterized by toxicity buildup and toxicity flash, with the primary cause identified as pattern unmatch. We introduce a knowledge editing approach named WilKE, which selects editing layer based on the pattern matching degree of editing knowledge across different layers. Experimental results demonstrate that, in lifelong editing, WilKE exhibits an average improvement of 46.2\\% and 67.8\\% on editing GPT2-XL and GPT-J relative to state-of-the-art knowledge editing methods.",
    "path": "papers/24/02/2402.10987.json",
    "total_tokens": 878,
    "translated_title": "WilKE：智慧层知识编辑器用于终身知识编辑",
    "translated_abstract": "知识编辑旨在纠正大型语言模型（LLMs）中的不准确性，而无需为过时或错误的知识进行昂贵的重新训练。然而，当前的知识编辑方法主要集中于单次编辑，未能满足终身编辑的要求。本文中，终身编辑与终身知识编辑同义。本研究揭示了知识编辑在终身编辑中遇到的性能下降问题，其特征为毒性积累和毒性闪现，主要原因是模式不匹配。我们介绍了一种名为WilKE的知识编辑方法，它根据不同层级中编辑知识的模式匹配程度选择编辑层。实验结果表明，在终身编辑中，相对于最先进的知识编辑方法，WilKE在编辑GPT2-XL和GPT-J方面分别平均改进了46.2%和67.8%。",
    "tldr": "该研究提出了一种名为WilKE的知识编辑方法，通过选择编辑层来匹配不同层级中的知识编辑模式程度，在终身编辑中相比最先进的方法平均展现了46.2%和67.8%的改进。",
    "en_tdlr": "This study introduces a knowledge editing approach named WilKE, which improves editing performance in lifelong editing by selecting editing layer based on the pattern matching degree of knowledge editing across different layers, demonstrating an average improvement of 46.2% and 67.8% relative to state-of-the-art methods on editing GPT2-XL and GPT-J."
}