{
    "title": "In-Context Learning Demonstration Selection via Influence Analysis",
    "abstract": "arXiv:2402.11750v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated their In-Context Learning (ICL) capabilities which provides an opportunity to perform few shot learning without any gradient update. Despite its multiple benefits, ICL generalization performance is sensitive to the selected demonstrations. Selecting effective demonstrations for ICL is still an open research challenge. To address this challenge, we propose a demonstration selection method called InfICL which analyzes influences of training samples through influence functions. Identifying highly influential training samples can potentially aid in uplifting the ICL generalization performance. To limit the running cost of InfICL, we only employ the LLM to generate sample embeddings, and don't perform any costly fine tuning. We perform empirical study on multiple real-world datasets and show merits of our InfICL against state-of-the-art baselines.",
    "link": "https://arxiv.org/abs/2402.11750",
    "context": "Title: In-Context Learning Demonstration Selection via Influence Analysis\nAbstract: arXiv:2402.11750v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated their In-Context Learning (ICL) capabilities which provides an opportunity to perform few shot learning without any gradient update. Despite its multiple benefits, ICL generalization performance is sensitive to the selected demonstrations. Selecting effective demonstrations for ICL is still an open research challenge. To address this challenge, we propose a demonstration selection method called InfICL which analyzes influences of training samples through influence functions. Identifying highly influential training samples can potentially aid in uplifting the ICL generalization performance. To limit the running cost of InfICL, we only employ the LLM to generate sample embeddings, and don't perform any costly fine tuning. We perform empirical study on multiple real-world datasets and show merits of our InfICL against state-of-the-art baselines.",
    "path": "papers/24/02/2402.11750.json",
    "total_tokens": 802,
    "translated_title": "通过影响分析进行上下文学习演示选择",
    "translated_abstract": "大型语言模型（LLM）展示了其具有上下文学习（ICL）能力，这提供了进行少样本学习的机会，而无需任何梯度更新。尽管具有多重好处，ICL的泛化性能对所选演示敏感。选择用于ICL的有效演示仍然是一个开放的研究挑战。为了解决这一挑战，我们提出了一种名为InfICL的演示选择方法，该方法通过影响函数分析训练样本的影响。鉴别高度有影响力的训练样本可能有助于提升ICL的泛化性能。为了限制InfICL的运行成本，我们仅利用LLM生成样本嵌入，并不执行任何昂贵的微调。我们在多个真实世界数据集上进行实证研究，并展示了我们的InfICL相对于最先进基线方法的优点。",
    "tldr": "通过分析训练样本的影响，提出一种名为InfICL的演示选择方法，可以帮助提升上下文学习的泛化性能。",
    "en_tdlr": "A demonstration selection method called InfICL is proposed to improve the generalization performance of In-Context Learning by analyzing the influences of training samples."
}