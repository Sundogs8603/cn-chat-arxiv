{
    "title": "De-identification is not always enough",
    "abstract": "For sharing privacy-sensitive data, de-identification is commonly regarded as adequate for safeguarding privacy. Synthetic data is also being considered as a privacy-preserving alternative. Recent successes with numerical and tabular data generative models and the breakthroughs in large generative language models raise the question of whether synthetically generated clinical notes could be a viable alternative to real notes for research purposes. In this work, we demonstrated that (i) de-identification of real clinical notes does not protect records against a membership inference attack, (ii) proposed a novel approach to generate synthetic clinical notes using the current state-of-the-art large language models, (iii) evaluated the performance of the synthetically generated notes in a clinical domain task, and (iv) proposed a way to mount a membership inference attack where the target model is trained with synthetic data. We observed that when synthetically generated notes closely match",
    "link": "https://arxiv.org/abs/2402.00179",
    "context": "Title: De-identification is not always enough\nAbstract: For sharing privacy-sensitive data, de-identification is commonly regarded as adequate for safeguarding privacy. Synthetic data is also being considered as a privacy-preserving alternative. Recent successes with numerical and tabular data generative models and the breakthroughs in large generative language models raise the question of whether synthetically generated clinical notes could be a viable alternative to real notes for research purposes. In this work, we demonstrated that (i) de-identification of real clinical notes does not protect records against a membership inference attack, (ii) proposed a novel approach to generate synthetic clinical notes using the current state-of-the-art large language models, (iii) evaluated the performance of the synthetically generated notes in a clinical domain task, and (iv) proposed a way to mount a membership inference attack where the target model is trained with synthetic data. We observed that when synthetically generated notes closely match",
    "path": "papers/24/02/2402.00179.json",
    "total_tokens": 899,
    "translated_title": "不仅仅去识别可能是不够的",
    "translated_abstract": "对于共享隐私敏感数据，常常将去识别视为足够保护隐私的措施。合成数据也被认为是一种保护隐私的替代方法。最近在生成数值和表格数据模型方面取得的成功以及大型生成语言模型的突破引发了一个问题：合成的临床笔记是否可以作为研究目的的真实笔记的可行替代品。在这项工作中，我们证明了：（i）对真实临床笔记的去识别并不能保护记录免遭会员推理攻击；（ii）提出了一种使用当前最先进的大型语言模型生成合成临床笔记的新方法；（iii）在临床领域任务中评估了合成生成笔记的性能；（iv）提出了一种利用合成数据训练目标模型的会员推理攻击方法。我们观察到，当合成生成的笔记与真实笔记相似时，这种攻击的成功率增加。",
    "tldr": "研究表明，仅仅进行去识别操作并不能有效保护隐私。本文提出了使用大型语言模型生成合成临床笔记的方法，并评估了其在临床任务中的性能。同时，还发现利用合成数据训练模型可以提高会员推理攻击的成功率。"
}