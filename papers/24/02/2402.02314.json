{
    "title": "Selecting Large Language Model to Fine-tune via Rectified Scaling Law",
    "abstract": "The ever-growing ecosystem of LLMs has posed a challenge in selecting the most appropriate pre-trained model to fine-tune amidst a sea of options. Given constrained resources, fine-tuning all models and making selections afterward is unrealistic. In this work, we formulate this resource-constrained selection task into predicting fine-tuning performance and illustrate its natural connection with scaling laws. Unlike pre-training, We find that the fine-tuning scaling curve includes not just the well-known \"power phase\" but also the previously unobserved \"pre-power phase\". We also explain why existing scaling laws fail to capture this phase transition phenomenon both theoretically and empirically. To address this, we introduce the concept of \"pre-learned data size\" into our rectified scaling law, which overcomes theoretical limitations and fits experimental results much better. By leveraging our law, we propose a novel LLM selection algorithm that selects the near-optimal model with hundr",
    "link": "https://arxiv.org/abs/2402.02314",
    "context": "Title: Selecting Large Language Model to Fine-tune via Rectified Scaling Law\nAbstract: The ever-growing ecosystem of LLMs has posed a challenge in selecting the most appropriate pre-trained model to fine-tune amidst a sea of options. Given constrained resources, fine-tuning all models and making selections afterward is unrealistic. In this work, we formulate this resource-constrained selection task into predicting fine-tuning performance and illustrate its natural connection with scaling laws. Unlike pre-training, We find that the fine-tuning scaling curve includes not just the well-known \"power phase\" but also the previously unobserved \"pre-power phase\". We also explain why existing scaling laws fail to capture this phase transition phenomenon both theoretically and empirically. To address this, we introduce the concept of \"pre-learned data size\" into our rectified scaling law, which overcomes theoretical limitations and fits experimental results much better. By leveraging our law, we propose a novel LLM selection algorithm that selects the near-optimal model with hundr",
    "path": "papers/24/02/2402.02314.json",
    "total_tokens": 923,
    "translated_title": "通过修正的缩放定律选择大型语言模型进行微调",
    "translated_abstract": "在日益增长的语言模型生态系统中，在众多选项中选择最合适的预训练模型进行微调成为了一个挑战。在资源受限的情况下，微调所有模型然后再进行选择是不现实的。在本文中，我们将这个资源受限的选择任务转化为预测微调性能，并且展示其与缩放定律之间的自然联系。与预训练不同，我们发现微调的缩放曲线不仅包括众所周知的“功率阶段”，还包括以前未被观察到的“预功率阶段”。我们还解释了为什么现有的缩放定律无法理论和实证地捕捉到这种相变现象。为了解决这个问题，我们将“预学习数据大小”概念引入到我们的修正缩放定律中，这克服了理论上的限制，并更好地适应实验结果。通过利用我们的定律，我们提出了一种新颖的语言模型选择算法，可以选择接近最优的模型。",
    "tldr": "该论文研究了在资源受限的情况下如何选择合适的预训练语言模型进行微调的问题。通过引入修正的缩放定律和预学习数据大小的概念，作者提出了一种新颖的模型选择算法，可以选择接近最优的模型。",
    "en_tdlr": "This paper investigates the problem of selecting an appropriate pre-trained language model for fine-tuning under resource constraints. By introducing a rectified scaling law and the concept of pre-learned data size, the authors propose a novel model selection algorithm that can choose a near-optimal model."
}