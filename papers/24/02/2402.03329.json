{
    "title": "Unsupervised Salient Patch Selection for Data-Efficient Reinforcement Learning",
    "abstract": "To improve the sample efficiency of vision-based deep reinforcement learning (RL), we propose a novel method, called SPIRL, to automatically extract important patches from input images. Following Masked Auto-Encoders, SPIRL is based on Vision Transformer models pre-trained in a self-supervised fashion to reconstruct images from randomly-sampled patches. These pre-trained models can then be exploited to detect and select salient patches, defined as hard to reconstruct from neighboring patches. In RL, the SPIRL agent processes selected salient patches via an attention module. We empirically validate SPIRL on Atari games to test its data-efficiency against relevant state-of-the-art methods, including some traditional model-based methods and keypoint-based models. In addition, we analyze our model's interpretability capabilities.",
    "link": "https://arxiv.org/abs/2402.03329",
    "context": "Title: Unsupervised Salient Patch Selection for Data-Efficient Reinforcement Learning\nAbstract: To improve the sample efficiency of vision-based deep reinforcement learning (RL), we propose a novel method, called SPIRL, to automatically extract important patches from input images. Following Masked Auto-Encoders, SPIRL is based on Vision Transformer models pre-trained in a self-supervised fashion to reconstruct images from randomly-sampled patches. These pre-trained models can then be exploited to detect and select salient patches, defined as hard to reconstruct from neighboring patches. In RL, the SPIRL agent processes selected salient patches via an attention module. We empirically validate SPIRL on Atari games to test its data-efficiency against relevant state-of-the-art methods, including some traditional model-based methods and keypoint-based models. In addition, we analyze our model's interpretability capabilities.",
    "path": "papers/24/02/2402.03329.json",
    "total_tokens": 911,
    "translated_title": "无监督显著性补丁选择用于数据高效的强化学习",
    "translated_abstract": "为了提高基于视觉的深度强化学习的样本效率，我们提出了一种新颖的方法，称为SPIRL，用于自动从输入图像中提取重要的补丁。SPIRL基于经过自监督训练的Vision Transformer模型，通过随机采样的补丁对图像进行重构。然后利用这些经过预训练的模型来检测和选择显著的补丁，这些补丁在邻近补丁中难以重构。在强化学习中，SPIRL代理利用注意力模块处理选中的显著补丁。我们在Atari游戏上经验验证了SPIRL的数据效率，将其与相关的最先进方法，包括一些传统的基于模型的方法和基于关键点的模型进行比较。此外，我们还分析了我们模型的可解释性能力。",
    "tldr": "本文提出了一种无监督的方法，通过自动提取图像中的重要补丁来改善基于视觉的深度强化学习的样本效率。这种方法利用经过自监督训练的Vision Transformer模型来检测和选择难以重构的显著补丁，并在强化学习中使用注意力模块进行处理。在实验证明了这种方法的数据效率，并分析了其模型的可解释性能力。",
    "en_tdlr": "This paper proposes an unsupervised method to improve the sample efficiency of vision-based deep reinforcement learning by automatically extracting important patches from input images. The method utilizes pre-trained Vision Transformer models to detect and select salient patches that are hard to reconstruct, and processes them using an attention module in reinforcement learning. The method is shown to be data-efficient and has interpretability capabilities."
}