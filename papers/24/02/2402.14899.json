{
    "title": "Stop Reasoning! When Multimodal LLMs with Chain-of-Thought Reasoning Meets Adversarial Images",
    "abstract": "arXiv:2402.14899v1 Announce Type: cross  Abstract: Recently, Multimodal LLMs (MLLMs) have shown a great ability to understand images. However, like traditional vision models, they are still vulnerable to adversarial images. Meanwhile, Chain-of-Thought (CoT) reasoning has been widely explored on MLLMs, which not only improves model's performance, but also enhances model's explainability by giving intermediate reasoning steps. Nevertheless, there is still a lack of study regarding MLLMs' adversarial robustness with CoT and an understanding of what the rationale looks like when MLLMs infer wrong answers with adversarial images. Our research evaluates the adversarial robustness of MLLMs when employing CoT reasoning, finding that CoT marginally improves adversarial robustness against existing attack methods. Moreover, we introduce a novel stop-reasoning attack technique that effectively bypasses the CoT-induced robustness enhancements. Finally, we demonstrate the alterations in CoT reasonin",
    "link": "https://arxiv.org/abs/2402.14899",
    "context": "Title: Stop Reasoning! When Multimodal LLMs with Chain-of-Thought Reasoning Meets Adversarial Images\nAbstract: arXiv:2402.14899v1 Announce Type: cross  Abstract: Recently, Multimodal LLMs (MLLMs) have shown a great ability to understand images. However, like traditional vision models, they are still vulnerable to adversarial images. Meanwhile, Chain-of-Thought (CoT) reasoning has been widely explored on MLLMs, which not only improves model's performance, but also enhances model's explainability by giving intermediate reasoning steps. Nevertheless, there is still a lack of study regarding MLLMs' adversarial robustness with CoT and an understanding of what the rationale looks like when MLLMs infer wrong answers with adversarial images. Our research evaluates the adversarial robustness of MLLMs when employing CoT reasoning, finding that CoT marginally improves adversarial robustness against existing attack methods. Moreover, we introduce a novel stop-reasoning attack technique that effectively bypasses the CoT-induced robustness enhancements. Finally, we demonstrate the alterations in CoT reasonin",
    "path": "papers/24/02/2402.14899.json",
    "total_tokens": 954,
    "translated_title": "停止推理！当多模态LLMs与串联推理遇到对抗性图像",
    "translated_abstract": "最近，多模态LLMs（MLLMs）展示了很强的理解图像的能力。然而，像传统视觉模型一样，它们仍然容易受到对抗性图像的攻击。与此同时，串联推理（CoT）已经被广泛应用在MLLMs上，不仅提高了模型的性能，而且通过提供中间推理步骤来增强模型的可解释性。然而，目前还缺乏关于MLLMs在CoT下的对抗鲁棒性的研究，以及在MLLMs用对抗性图像推断错误答案时推理的合理性。我们的研究评估了采用CoT推理时MLLMs的对抗鲁棒性，发现CoT在一定程度上提高了对抗性鲁棒性，抵抗了已有的攻击方法。此外，我们引入了一种新的停止推理攻击技术，可以有效地规避CoT引起的鲁棒性增强。最后，我们展示了CoT推理的变化。",
    "tldr": "该研究评估了多模态LLMs在采用串联推理时的对抗鲁棒性，发现串联推理在一定程度上提高了对抗性鲁棒性，但引入了一种新的停止推理攻击技术成功规避了这种增强。"
}