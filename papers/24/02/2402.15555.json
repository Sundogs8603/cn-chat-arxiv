{
    "title": "Deep Networks Always Grok and Here is Why",
    "abstract": "arXiv:2402.15555v1 Announce Type: cross  Abstract: Grokking, or delayed generalization, is a phenomenon where generalization in a deep neural network (DNN) occurs long after achieving near zero training error. Previous studies have reported the occurrence of grokking in specific controlled settings, such as DNNs initialized with large-norm parameters or transformers trained on algorithmic datasets. We demonstrate that grokking is actually much more widespread and materializes in a wide range of practical settings, such as training of a convolutional neural network (CNN) on CIFAR10 or a Resnet on Imagenette. We introduce the new concept of delayed robustness, whereby a DNN groks adversarial examples and becomes robust, long after interpolation and/or generalization. We develop an analytical explanation for the emergence of both delayed generalization and delayed robustness based on a new measure of the local complexity of a DNN's input-output mapping. Our local complexity measures the d",
    "link": "https://arxiv.org/abs/2402.15555",
    "context": "Title: Deep Networks Always Grok and Here is Why\nAbstract: arXiv:2402.15555v1 Announce Type: cross  Abstract: Grokking, or delayed generalization, is a phenomenon where generalization in a deep neural network (DNN) occurs long after achieving near zero training error. Previous studies have reported the occurrence of grokking in specific controlled settings, such as DNNs initialized with large-norm parameters or transformers trained on algorithmic datasets. We demonstrate that grokking is actually much more widespread and materializes in a wide range of practical settings, such as training of a convolutional neural network (CNN) on CIFAR10 or a Resnet on Imagenette. We introduce the new concept of delayed robustness, whereby a DNN groks adversarial examples and becomes robust, long after interpolation and/or generalization. We develop an analytical explanation for the emergence of both delayed generalization and delayed robustness based on a new measure of the local complexity of a DNN's input-output mapping. Our local complexity measures the d",
    "path": "papers/24/02/2402.15555.json",
    "total_tokens": 895,
    "translated_title": "深度神经网络总是理解并且这就是原因",
    "translated_abstract": "Grokking，或者延迟泛化，是指深度神经网络（DNN）在达到接近于零的训练误差后很长时间内才发生泛化的现象。先前的研究报告了在特定受控环境中出现grokking的情况，例如使用大范数参数初始化的DNN或者在算法数据集上训练的transformers。我们展示了grokking实际上更加普遍，并且在广泛的实际环境中呈现，例如在CIFAR10上训练的卷积神经网络（CNN）或者在Imagenette上训练的Resnet。我们引入了延迟鲁棒性的新概念，即DNN在插值和/或泛化之后对抗示例进行理解并变得鲁棒。我们针对DNN的输入-输出映射的局部复杂度提出了出现延迟泛化和延迟鲁棒性的解释。我们的局部复杂度衡量了DNN输入-输出映射的复杂程度。",
    "tldr": "深度神经网络存在延迟泛化和延迟鲁棒性现象，在各种实际环境中普遍存在，并基于新的局部复杂度度量提供了解释。",
    "en_tdlr": "Deep neural networks exhibit phenomena of delayed generalization and delayed robustness, which are prevalent in various practical settings, and are explained based on a new measure of the local complexity of the DNN's input-output mapping."
}