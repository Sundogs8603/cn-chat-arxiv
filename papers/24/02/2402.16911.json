{
    "title": "Trustworthy Personalized Bayesian Federated Learning via Posterior Fine-Tune",
    "abstract": "arXiv:2402.16911v1 Announce Type: new  Abstract: Performance degradation owing to data heterogeneity and low output interpretability are the most significant challenges faced by federated learning in practical applications. Personalized federated learning diverges from traditional approaches, as it no longer seeks to train a single model, but instead tailors a unique personalized model for each client. However, previous work focused only on personalization from the perspective of neural network parameters and lack of robustness and interpretability. In this work, we establish a novel framework for personalized federated learning, incorporating Bayesian methodology which enhances the algorithm's ability to quantify uncertainty. Furthermore, we introduce normalizing flow to achieve personalization from the parameter posterior perspective and theoretically analyze the impact of normalizing flow on out-of-distribution (OOD) detection for Bayesian neural networks. Finally, we evaluated our ",
    "link": "https://arxiv.org/abs/2402.16911",
    "context": "Title: Trustworthy Personalized Bayesian Federated Learning via Posterior Fine-Tune\nAbstract: arXiv:2402.16911v1 Announce Type: new  Abstract: Performance degradation owing to data heterogeneity and low output interpretability are the most significant challenges faced by federated learning in practical applications. Personalized federated learning diverges from traditional approaches, as it no longer seeks to train a single model, but instead tailors a unique personalized model for each client. However, previous work focused only on personalization from the perspective of neural network parameters and lack of robustness and interpretability. In this work, we establish a novel framework for personalized federated learning, incorporating Bayesian methodology which enhances the algorithm's ability to quantify uncertainty. Furthermore, we introduce normalizing flow to achieve personalization from the parameter posterior perspective and theoretically analyze the impact of normalizing flow on out-of-distribution (OOD) detection for Bayesian neural networks. Finally, we evaluated our ",
    "path": "papers/24/02/2402.16911.json",
    "total_tokens": 843,
    "translated_title": "基于后验微调的可信个性化贝叶斯联邦学习",
    "translated_abstract": "数据异质性和低输出可解释性导致的性能下降是联邦学习在实际应用中面临的最大挑战。个性化联邦学习不同于传统方法，不再试图训练单个模型，而是为每个客户定制独特的个性化模型。我们建立了一个新颖的框架，将贝叶斯方法融入个性化联邦学习中，增强了算法量化不确定性的能力。此外，我们引入了正则化流来实现从参数后验角度的个性化，并在理论上分析了正则化流对贝叶斯神经网络的超分布检测的影响。最后，我们评估了我们的方法。",
    "tldr": "本研究针对联邦学习面临的数据异质性和低输出可解释性挑战，提出了一个新颖的个性化联邦学习框架，融合了贝叶斯方法和正则化流，在参数后验角度实现个性化，提高了算法对不确定性的量化能力，并在理论上分析了对贝叶斯神经网络的超分布检测影响。",
    "en_tdlr": "This study introduces a novel framework for personalized federated learning by incorporating Bayesian methodology and normalizing flow, which enhances the algorithm's ability to quantify uncertainty and improves out-of-distribution detection for Bayesian neural networks."
}