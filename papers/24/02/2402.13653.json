{
    "title": "PQA: Zero-shot Protein Question Answering for Free-form Scientific Enquiry with Large Language Models",
    "abstract": "arXiv:2402.13653v1 Announce Type: new  Abstract: We introduce the novel task of zero-shot Protein Question Answering (PQA) for free-form scientific enquiry. Given a previously unseen protein sequence and a natural language question, the task is to deliver a scientifically accurate answer. This task not only supports future biological research, but could also provide a test bed for assessing the scientific precision of large language models (LLMs). We contribute the first specialized dataset for PQA model training, containing 257K protein sequences annotated with 1.97M scientific question-answer pairs. Additionally, we propose and study several novel biologically relevant benchmarks for scientific PQA. Employing two robust multi-modal architectures, we establish an initial state-of-the-art performance for PQA and reveal key performance factors through ablation studies. Our comprehensive PQA framework, named Pika, including dataset, code, model checkpoints, and a user-friendly demo, is o",
    "link": "https://arxiv.org/abs/2402.13653",
    "context": "Title: PQA: Zero-shot Protein Question Answering for Free-form Scientific Enquiry with Large Language Models\nAbstract: arXiv:2402.13653v1 Announce Type: new  Abstract: We introduce the novel task of zero-shot Protein Question Answering (PQA) for free-form scientific enquiry. Given a previously unseen protein sequence and a natural language question, the task is to deliver a scientifically accurate answer. This task not only supports future biological research, but could also provide a test bed for assessing the scientific precision of large language models (LLMs). We contribute the first specialized dataset for PQA model training, containing 257K protein sequences annotated with 1.97M scientific question-answer pairs. Additionally, we propose and study several novel biologically relevant benchmarks for scientific PQA. Employing two robust multi-modal architectures, we establish an initial state-of-the-art performance for PQA and reveal key performance factors through ablation studies. Our comprehensive PQA framework, named Pika, including dataset, code, model checkpoints, and a user-friendly demo, is o",
    "path": "papers/24/02/2402.13653.json",
    "total_tokens": 914,
    "translated_title": "PQA：零样本蛋白质问题回答与大型语言模型进行自由科学探究",
    "translated_abstract": "我们引入了零样本蛋白质问题回答（PQA）这一新颖任务，用于自由形式科学探究。给定一个以前未见过的蛋白质序列和一个自然语言问题，任务是提供一个科学上准确的答案。这一任务不仅支持未来的生物研究，还可以为评估大型语言模型（LLMs）的科学精度提供一个测试基准。我们贡献了第一个专门用于PQA模型训练的数据集，其中包含257K个蛋白质序列，注释有1.97M个科学问题-答案对。此外，我们提出并研究了几个新颖的与生物相关的科学PQA基准。通过两种强大的多模态架构，我们建立了PQA的最新技术水平，并通过消融研究揭示了关键性能因素。我们的全面PQA框架，名为Pika，包括数据集、代码、模型检查点和一个用户友好的演示。",
    "tldr": "零样本蛋白质问题回答任务，提供专门数据集并建立了PQA框架，包含生物相关的科学PQA基准，通过多模态架构取得了最新技术水平。"
}