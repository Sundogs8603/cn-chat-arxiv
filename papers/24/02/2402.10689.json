{
    "title": "Multi-Cultural Commonsense Knowledge Distillation",
    "abstract": "arXiv:2402.10689v1 Announce Type: new  Abstract: Despite recent progress, large language models (LLMs) still face the challenge of appropriately reacting to the intricacies of social and cultural conventions. This paper presents MANGO, a methodology for distilling high-accuracy, high-recall assertions of cultural knowledge. We judiciously and iteratively prompt LLMs for this purpose from two entry points, concepts and cultures. Outputs are consolidated via clustering and generative summarization. Running the MANGO method with GPT-3.5 as underlying LLM yields 167K high-accuracy assertions for 30K concepts and 11K cultures, surpassing prior resources by a large margin. For extrinsic evaluation, we explore augmenting dialogue systems with cultural knowledge assertions. We find that adding knowledge from MANGO improves the overall quality, specificity, and cultural sensitivity of dialogue responses, as judged by human annotators. Data and code are available for download.",
    "link": "https://arxiv.org/abs/2402.10689",
    "context": "Title: Multi-Cultural Commonsense Knowledge Distillation\nAbstract: arXiv:2402.10689v1 Announce Type: new  Abstract: Despite recent progress, large language models (LLMs) still face the challenge of appropriately reacting to the intricacies of social and cultural conventions. This paper presents MANGO, a methodology for distilling high-accuracy, high-recall assertions of cultural knowledge. We judiciously and iteratively prompt LLMs for this purpose from two entry points, concepts and cultures. Outputs are consolidated via clustering and generative summarization. Running the MANGO method with GPT-3.5 as underlying LLM yields 167K high-accuracy assertions for 30K concepts and 11K cultures, surpassing prior resources by a large margin. For extrinsic evaluation, we explore augmenting dialogue systems with cultural knowledge assertions. We find that adding knowledge from MANGO improves the overall quality, specificity, and cultural sensitivity of dialogue responses, as judged by human annotators. Data and code are available for download.",
    "path": "papers/24/02/2402.10689.json",
    "total_tokens": 907,
    "translated_title": "多元文化常识知识蒸馏",
    "translated_abstract": "尽管最近取得了一定进展，但大型语言模型（LLMs）仍然面临着适当应对社会和文化惯例的挑战。本文提出了MANGO，一种用于提炼高准确度、高召回率文化知识断言的方法论。我们从概念和文化两个入口点谨慎而迭代地提示LLMs进行这一目的。通过聚类和生成摘要将输出结果巩固。运行MANGO方法，以GPT-3.5作为底层LLM，为30K个概念和11K个文化提供了167K个高准确度断言，大幅超过先前的资源。为了外部评估，我们探索了将对话系统与文化知识断言相结合的方法。我们发现，添加来自MANGO的知识可以提升对话回应的整体质量、特异性和文化敏感性，这是由人类标注者评判的。数据和代码可供下载。",
    "tldr": "提出了一种MANGO方法，通过从概念和文化两个入口点谨慎而迭代地提示LLMs，提炼高准确度、高召回率的文化知识断言，提供了大量高准确度断言，能够改善对话系统回应的质量、特异性和文化敏感性。",
    "en_tdlr": "Introduced the MANGO method that distills high-accuracy, high-recall cultural knowledge assertions by judiciously and iteratively prompting LLMs from two entry points, providing a large number of high-accuracy assertions, which can improve the quality, specificity, and cultural sensitivity of dialogue responses."
}