{
    "title": "Physics-informed machine learning as a kernel method",
    "abstract": "Physics-informed machine learning combines the expressiveness of data-based approaches with the interpretability of physical models. In this context, we consider a general regression problem where the empirical risk is regularized by a partial differential equation that quantifies the physical inconsistency. We prove that for linear differential priors, the problem can be formulated as a kernel regression task. Taking advantage of kernel theory, we derive convergence rates for the minimizer of the regularized risk and show that it converges at least at the Sobolev minimax rate. However, faster rates can be achieved, depending on the physical error. This principle is illustrated with a one-dimensional example, supporting the claim that regularizing the empirical risk with physical information can be beneficial to the statistical performance of estimators.",
    "link": "https://arxiv.org/abs/2402.07514",
    "context": "Title: Physics-informed machine learning as a kernel method\nAbstract: Physics-informed machine learning combines the expressiveness of data-based approaches with the interpretability of physical models. In this context, we consider a general regression problem where the empirical risk is regularized by a partial differential equation that quantifies the physical inconsistency. We prove that for linear differential priors, the problem can be formulated as a kernel regression task. Taking advantage of kernel theory, we derive convergence rates for the minimizer of the regularized risk and show that it converges at least at the Sobolev minimax rate. However, faster rates can be achieved, depending on the physical error. This principle is illustrated with a one-dimensional example, supporting the claim that regularizing the empirical risk with physical information can be beneficial to the statistical performance of estimators.",
    "path": "papers/24/02/2402.07514.json",
    "total_tokens": 750,
    "translated_title": "物理约束的机器学习作为一种核方法",
    "translated_abstract": "物理约束的机器学习将基于数据的方法的表达能力与物理模型的可解释性相结合。在这种背景下，我们考虑一个普通的回归问题，其中经验风险由一个偏微分方程正则化，该方程量化了物理不一致性。我们证明对于线性微分先验，该问题可以被表述为核回归任务。利用核理论，我们推导出正则化风险的最小化器的收敛速度，并表明它至少以Sobolev最小化速度收敛。然而，根据物理误差的不同，可以实现更快的收敛速度。通过一个一维示例来说明这个原理，支持一个论点：使用物理信息来正则化经验风险对估计器的统计性能有益。",
    "tldr": "物理约束的机器学习结合了数据方法的表达能力与物理模型的可解释性，可以用于正则化经验风险并提高估计器的统计性能。"
}