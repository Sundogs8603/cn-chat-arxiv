{
    "title": "Scalable and reliable deep transfer learning for intelligent fault detection via multi-scale neural processes embedded with knowledge",
    "abstract": "arXiv:2402.12729v1 Announce Type: cross  Abstract: Deep transfer learning (DTL) is a fundamental method in the field of Intelligent Fault Detection (IFD). It aims to mitigate the degradation of method performance that arises from the discrepancies in data distribution between training set (source domain) and testing set (target domain). Considering the fact that fault data collection is challenging and certain faults are scarce, DTL-based methods face the limitation of available observable data, which reduces the detection performance of the methods in the target domain. Furthermore, DTL-based methods lack comprehensive uncertainty analysis that is essential for building reliable IFD systems. To address the aforementioned problems, this paper proposes a novel DTL-based method known as Neural Processes-based deep transfer learning with graph convolution network (GTNP). Feature-based transfer strategy of GTNP bridges the data distribution discrepancies of source domain and target domain ",
    "link": "https://arxiv.org/abs/2402.12729",
    "context": "Title: Scalable and reliable deep transfer learning for intelligent fault detection via multi-scale neural processes embedded with knowledge\nAbstract: arXiv:2402.12729v1 Announce Type: cross  Abstract: Deep transfer learning (DTL) is a fundamental method in the field of Intelligent Fault Detection (IFD). It aims to mitigate the degradation of method performance that arises from the discrepancies in data distribution between training set (source domain) and testing set (target domain). Considering the fact that fault data collection is challenging and certain faults are scarce, DTL-based methods face the limitation of available observable data, which reduces the detection performance of the methods in the target domain. Furthermore, DTL-based methods lack comprehensive uncertainty analysis that is essential for building reliable IFD systems. To address the aforementioned problems, this paper proposes a novel DTL-based method known as Neural Processes-based deep transfer learning with graph convolution network (GTNP). Feature-based transfer strategy of GTNP bridges the data distribution discrepancies of source domain and target domain ",
    "path": "papers/24/02/2402.12729.json",
    "total_tokens": 741,
    "translated_title": "可扩展可靠的多尺度神经过程嵌入知识用于智能故障检测的深度迁移学习",
    "translated_abstract": "深度迁移学习（DTL）是智能故障检测（IFD）领域中的一种基本方法，旨在减轻训练集（源域）和测试集（目标域）之间数据分布不一致导致方法性能下降的问题。本文提出了一种名为基于神经过程的图卷积网络（GTNP）的新颖的DTL方法，可以解决数据分布不一致和可靠性问题。",
    "tldr": "提出了一种名为GTNP的神经过程深度迁移学习方法，通过特征传输策略弥合源域和目标域的数据分布差异，解决了数据稀缺和缺乏可靠性分析的问题",
    "en_tdlr": "A novel DTL method named GTNP is proposed, which bridges the data distribution gap between source and target domains through feature-based transfer strategy, addressing the issues of data scarcity and lack of reliability analysis."
}