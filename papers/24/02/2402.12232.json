{
    "title": "Kernel KMeans clustering splits for end-to-end unsupervised decision trees",
    "abstract": "arXiv:2402.12232v1 Announce Type: cross  Abstract: Trees are convenient models for obtaining explainable predictions on relatively small datasets. Although there are many proposals for the end-to-end construction of such trees in supervised learning, learning a tree end-to-end for clustering without labels remains an open challenge. As most works focus on interpreting with trees the result of another clustering algorithm, we present here a novel end-to-end trained unsupervised binary tree for clustering: Kauri. This method performs a greedy maximisation of the kernel KMeans objective without requiring the definition of centroids. We compare this model on multiple datasets with recent unsupervised trees and show that Kauri performs identically when using a linear kernel. For other kernels, Kauri often outperforms the concatenation of kernel KMeans and a CART decision tree.",
    "link": "https://arxiv.org/abs/2402.12232",
    "context": "Title: Kernel KMeans clustering splits for end-to-end unsupervised decision trees\nAbstract: arXiv:2402.12232v1 Announce Type: cross  Abstract: Trees are convenient models for obtaining explainable predictions on relatively small datasets. Although there are many proposals for the end-to-end construction of such trees in supervised learning, learning a tree end-to-end for clustering without labels remains an open challenge. As most works focus on interpreting with trees the result of another clustering algorithm, we present here a novel end-to-end trained unsupervised binary tree for clustering: Kauri. This method performs a greedy maximisation of the kernel KMeans objective without requiring the definition of centroids. We compare this model on multiple datasets with recent unsupervised trees and show that Kauri performs identically when using a linear kernel. For other kernels, Kauri often outperforms the concatenation of kernel KMeans and a CART decision tree.",
    "path": "papers/24/02/2402.12232.json",
    "total_tokens": 843,
    "translated_title": "将 Kernel KMeans 聚类拆分用于端到端无监督决策树",
    "translated_abstract": "树是获取对相对较小数据集进行可解释预测的便利模型。虽然有很多关于监督学习中端到端构建这种树的提议，但在没有标签的情况下学习用于聚类的树仍然是一个未解决的挑战。大多数作品主要集中于使用树来解释另一个聚类算法的结果，我们在这里提出了一种新颖的端到端训练的无监督二叉树用于聚类：Kauri。该方法通过贪婪最大化 kernel KMeans 目标来执行，而无需定义质心。我们在多个数据集上将此模型与最近的无监督树进行比较，并展示当使用线性核时，Kauri 的性能相同。对于其他内核，Kauri 在许多情况下表现优于内核 KMeans 和 CART 决策树的串联。",
    "tldr": "提出了一种新颖的端到端训练的无监督二叉树用于聚类，称为Kauri，通过贪婪最大化 kernel KMeans 目标来执行，无需定义质心，并在多个数据集上展示其性能优于其他方法。",
    "en_tdlr": "Proposed a novel end-to-end trained unsupervised binary tree for clustering, called Kauri, which performs a greedy maximization of the kernel KMeans objective without needing to define centroids, showing superior performance on multiple datasets compared to other methods."
}