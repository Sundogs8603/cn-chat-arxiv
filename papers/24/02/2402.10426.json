{
    "title": "DELL: Generating Reactions and Explanations for LLM-Based Misinformation Detection",
    "abstract": "arXiv:2402.10426v1 Announce Type: new  Abstract: Large language models are limited by challenges in factuality and hallucinations to be directly employed off-the-shelf for judging the veracity of news articles, where factual accuracy is paramount. In this work, we propose DELL that identifies three key stages in misinformation detection where LLMs could be incorporated as part of the pipeline: 1) LLMs could \\emph{generate news reactions} to represent diverse perspectives and simulate user-news interaction networks; 2) LLMs could \\emph{generate explanations} for proxy tasks (e.g., sentiment, stance) to enrich the contexts of news articles and produce experts specializing in various aspects of news understanding; 3) LLMs could \\emph{merge task-specific experts} and provide an overall prediction by incorporating the predictions and confidence scores of varying experts. Extensive experiments on seven datasets with three LLMs demonstrate that DELL outperforms state-of-the-art baselines by u",
    "link": "https://arxiv.org/abs/2402.10426",
    "context": "Title: DELL: Generating Reactions and Explanations for LLM-Based Misinformation Detection\nAbstract: arXiv:2402.10426v1 Announce Type: new  Abstract: Large language models are limited by challenges in factuality and hallucinations to be directly employed off-the-shelf for judging the veracity of news articles, where factual accuracy is paramount. In this work, we propose DELL that identifies three key stages in misinformation detection where LLMs could be incorporated as part of the pipeline: 1) LLMs could \\emph{generate news reactions} to represent diverse perspectives and simulate user-news interaction networks; 2) LLMs could \\emph{generate explanations} for proxy tasks (e.g., sentiment, stance) to enrich the contexts of news articles and produce experts specializing in various aspects of news understanding; 3) LLMs could \\emph{merge task-specific experts} and provide an overall prediction by incorporating the predictions and confidence scores of varying experts. Extensive experiments on seven datasets with three LLMs demonstrate that DELL outperforms state-of-the-art baselines by u",
    "path": "papers/24/02/2402.10426.json",
    "total_tokens": 843,
    "translated_title": "DELL: 基于LLM的虚假信息检测生成反应和解释",
    "translated_abstract": "大型语言模型受事实性和幻觉方面的挑战所限，因此无法直接用于新闻文章真实性的判断，而事实准确性是至关重要的。在这项工作中，我们提出了DELL，它确定了虚假信息检测中LLM可以作为管道的一部分的三个关键阶段：1）LLM可以生成新闻反应来代表不同视角并模拟用户-新闻交互网络；2）LLM可以为代理任务（如情感、立场）生成解释，以丰富新闻文章的背景并产生专门研究新闻不同方面的专家；3）LLM可以合并任务特定的专家，并通过结合不同专家的预测和置信度分数来提供整体预测。对七个数据集进行的大量实验表明，DELL的性能优于现有的基线方法。",
    "tldr": "DELL提出了一个新的方法，将LLMs整合到虚假信息检测的管道中，通过生成新闻反应和解释来提升对新闻文章真实性的判断准确性。",
    "en_tdlr": "DELL introduces a novel approach to incorporate LLMs into the pipeline of misinformation detection by generating news reactions and explanations to enhance the accuracy of assessing the veracity of news articles."
}