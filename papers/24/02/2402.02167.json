{
    "title": "Vi(E)va LLM! A Conceptual Stack for Evaluating and Interpreting Generative AI-based Visualizations",
    "abstract": "The automatic generation of visualizations is an old task that, through the years, has shown more and more interest from the research and practitioner communities. Recently, large language models (LLM) have become an interesting option for supporting generative tasks related to visualization, demonstrating initial promising results. At the same time, several pitfalls, like the multiple ways of instructing an LLM to generate the desired result, the different perspectives leading the generation (code-based, image-based, grammar-based), and the presence of hallucinations even for the visualization generation task, make their usage less affordable than expected. Following similar initiatives for benchmarking LLMs, this paper copes with the problem of modeling the evaluation of a generated visualization through an LLM. We propose a theoretical evaluation stack, EvaLLM, that decomposes the evaluation effort in its atomic components, characterizes their nature, and provides an overview of how",
    "link": "https://arxiv.org/abs/2402.02167",
    "context": "Title: Vi(E)va LLM! A Conceptual Stack for Evaluating and Interpreting Generative AI-based Visualizations\nAbstract: The automatic generation of visualizations is an old task that, through the years, has shown more and more interest from the research and practitioner communities. Recently, large language models (LLM) have become an interesting option for supporting generative tasks related to visualization, demonstrating initial promising results. At the same time, several pitfalls, like the multiple ways of instructing an LLM to generate the desired result, the different perspectives leading the generation (code-based, image-based, grammar-based), and the presence of hallucinations even for the visualization generation task, make their usage less affordable than expected. Following similar initiatives for benchmarking LLMs, this paper copes with the problem of modeling the evaluation of a generated visualization through an LLM. We propose a theoretical evaluation stack, EvaLLM, that decomposes the evaluation effort in its atomic components, characterizes their nature, and provides an overview of how",
    "path": "papers/24/02/2402.02167.json",
    "total_tokens": 873,
    "translated_title": "Vi(E)va LLM！一个用于评估和解释生成AI可视化的概念模型栈",
    "translated_abstract": "自动生成可视化是一项古老的任务，多年来越来越受到研究和实践社区的关注。最近，大型语言模型（LLM）已成为支持与可视化相关的生成任务的有趣选择，并展示了初步的有希望的结果。与此同时，存在诸多问题，如指导LLM生成所需结果的多种方式，引导生成的不同视角（基于代码、基于图像、基于语法），以及即使在可视化生成任务中也存在的幻觉，使得它们的使用不如预期的那样可行。在类似为LLM进行基准测试的倡议下，本文针对通过LLM对生成的可视化建模的评估问题进行了研究。我们提出了一个理论上的评估模型栈，EvaLLM，它将评估工作分解为其原子组成部分，并对其性质进行了描述，并概述了如何进行评估的概述。",
    "tldr": "这篇论文介绍了一个名为EvaLLM的概念模型栈，用于评估和解释基于生成AI的可视化。它解决了使用大型语言模型生成可视化时遇到的问题，并提出了一种理论评估的方法。",
    "en_tdlr": "This paper introduces a conceptual stack called EvaLLM for evaluating and interpreting generative AI-based visualizations. It addresses the issues encountered when using large language models for visualization generation and proposes a theoretical evaluation approach."
}