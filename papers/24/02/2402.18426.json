{
    "title": "A Relational Inductive Bias for Dimensional Abstraction in Neural Networks",
    "abstract": "arXiv:2402.18426v1 Announce Type: new  Abstract: The human cognitive system exhibits remarkable flexibility and generalization capabilities, partly due to its ability to form low-dimensional, compositional representations of the environment. In contrast, standard neural network architectures often struggle with abstract reasoning tasks, overfitting, and requiring extensive data for training. This paper investigates the impact of the relational bottleneck -- a mechanism that focuses processing on relations among inputs -- on the learning of factorized representations conducive to compositional coding and the attendant flexibility of processing. We demonstrate that such a bottleneck not only improves generalization and learning efficiency, but also aligns network performance with human-like behavioral biases. Networks trained with the relational bottleneck developed orthogonal representations of feature dimensions latent in the dataset, reflecting the factorized structure thought to unde",
    "link": "https://arxiv.org/abs/2402.18426",
    "context": "Title: A Relational Inductive Bias for Dimensional Abstraction in Neural Networks\nAbstract: arXiv:2402.18426v1 Announce Type: new  Abstract: The human cognitive system exhibits remarkable flexibility and generalization capabilities, partly due to its ability to form low-dimensional, compositional representations of the environment. In contrast, standard neural network architectures often struggle with abstract reasoning tasks, overfitting, and requiring extensive data for training. This paper investigates the impact of the relational bottleneck -- a mechanism that focuses processing on relations among inputs -- on the learning of factorized representations conducive to compositional coding and the attendant flexibility of processing. We demonstrate that such a bottleneck not only improves generalization and learning efficiency, but also aligns network performance with human-like behavioral biases. Networks trained with the relational bottleneck developed orthogonal representations of feature dimensions latent in the dataset, reflecting the factorized structure thought to unde",
    "path": "papers/24/02/2402.18426.json",
    "total_tokens": 876,
    "translated_title": "神经网络中关系归纳偏好对维度抽象的影响",
    "translated_abstract": "人类认知系统表现出卓越的灵活性和泛化能力，部分原因在于其能够形成环境的低维、组合表示。相比之下，标准神经网络架构常常在抽象推理任务、过拟合和需要大量数据进行训练时遇到困难。本文研究了关系瓶颈的影响 - 这是一种将处理集中在输入之间关系上的机制 - 对学习有利于组成编码和相应处理灵活性的分解表示的影响。我们证明这种瓶颈不仅提高了泛化和学习效率，还使网络表现与类似人类的行为偏好一致。经过关系瓶颈训练的网络发展出了在数据集中潜在的特征维度上正交的表示，反映了被认为存在的分解结构。",
    "tldr": "研究了神经网络中关系归纳偏好对维度抽象的影响，并证明关系瓶颈机制能够提高泛化和学习效率，使网络表现与人类行为偏好一致。 - 关系瓶颈改善神经网络处理抽象任务的能力，促进网络在维度上进行组合编码，提高处理灵活性。",
    "en_tdlr": "Investigated the impact of relational inductive bias on dimensional abstraction in neural networks, demonstrating the improvement in generalization and learning efficiency. The relational bottleneck mechanism aligns network performance with human-like behavioral biases, developing orthogonal representations of feature dimensions in the dataset."
}