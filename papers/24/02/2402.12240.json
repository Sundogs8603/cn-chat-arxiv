{
    "title": "BEARS Make Neuro-Symbolic Models Aware of their Reasoning Shortcuts",
    "abstract": "arXiv:2402.12240v1 Announce Type: cross  Abstract: Neuro-Symbolic (NeSy) predictors that conform to symbolic knowledge - encoding, e.g., safety constraints - can be affected by Reasoning Shortcuts (RSs): They learn concepts consistent with the symbolic knowledge by exploiting unintended semantics. RSs compromise reliability and generalization and, as we show in this paper, they are linked to NeSy models being overconfident about the predicted concepts. Unfortunately, the only trustworthy mitigation strategy requires collecting costly dense supervision over the concepts. Rather than attempting to avoid RSs altogether, we propose to ensure NeSy models are aware of the semantic ambiguity of the concepts they learn, thus enabling their users to identify and distrust low-quality concepts. Starting from three simple desiderata, we derive bears (BE Aware of Reasoning Shortcuts), an ensembling technique that calibrates the model's concept-level confidence without compromising prediction accura",
    "link": "https://arxiv.org/abs/2402.12240",
    "context": "Title: BEARS Make Neuro-Symbolic Models Aware of their Reasoning Shortcuts\nAbstract: arXiv:2402.12240v1 Announce Type: cross  Abstract: Neuro-Symbolic (NeSy) predictors that conform to symbolic knowledge - encoding, e.g., safety constraints - can be affected by Reasoning Shortcuts (RSs): They learn concepts consistent with the symbolic knowledge by exploiting unintended semantics. RSs compromise reliability and generalization and, as we show in this paper, they are linked to NeSy models being overconfident about the predicted concepts. Unfortunately, the only trustworthy mitigation strategy requires collecting costly dense supervision over the concepts. Rather than attempting to avoid RSs altogether, we propose to ensure NeSy models are aware of the semantic ambiguity of the concepts they learn, thus enabling their users to identify and distrust low-quality concepts. Starting from three simple desiderata, we derive bears (BE Aware of Reasoning Shortcuts), an ensembling technique that calibrates the model's concept-level confidence without compromising prediction accura",
    "path": "papers/24/02/2402.12240.json",
    "total_tokens": 882,
    "translated_title": "BEARS 让神经符号模型意识到它们的推理捷径",
    "translated_abstract": "Neuro-Symbolic (NeSy)预测器符合符号知识-编码，例如安全约束，可能受到推理捷径（RSs）的影响：它们通过利用非预期的语义来学习与符号知识一致的概念。 RSs损害了可靠性和泛化，并且正如我们在本文中所展示的，它们与NeSy模型对预测概念过于自信有关。不幸的是，唯一可靠的缓解策略需要对概念进行昂贵的密集监督。我们提出的方法不是试图完全避免RSs，而是要确保NeSy模型意识到它们学习的概念的语义模糊性，从而使用户能够识别和怀疑低质量的概念。从三个简单的设计要求开始，我们得出bears（BE Aware of Reasoning Shortcuts），这是一种集成技术，可以校准模型的概念级信心，而不会损害预测准确性。",
    "tldr": "BEARS是一种集成技术，可以让神经符号模型意识到它们学习的概念的语义模糊性，帮助用户识别和怀疑低质量概念。",
    "en_tdlr": "BEARS is an ensemble technique that enables neuro-symbolic models to be aware of the semantic ambiguity of the concepts they learn, helping users identify and distrust low-quality concepts."
}