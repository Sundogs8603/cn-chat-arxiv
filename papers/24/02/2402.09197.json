{
    "title": "Implementing local-explainability in Gradient Boosting Trees: Feature Contribution",
    "abstract": "arXiv:2402.09197v1 Announce Type: new Abstract: Gradient Boost Decision Trees (GBDT) is a powerful additive model based on tree ensembles. Its nature makes GBDT a black-box model even though there are multiple explainable artificial intelligence (XAI) models obtaining information by reinterpreting the model globally and locally. Each tree of the ensemble is a transparent model itself but the final outcome is the result of a sum of these trees and it is not easy to clarify.   In this paper, a feature contribution method for GBDT is developed. The proposed method takes advantage of the GBDT architecture to calculate the contribution of each feature using the residue of each node. This algorithm allows to calculate the sequence of node decisions given a prediction.   Theoretical proofs and multiple experiments have been carried out to demonstrate the performance of our method which is not only a local explicability model for the GBDT algorithm but also a unique option that reflects GBDTs ",
    "link": "https://arxiv.org/abs/2402.09197",
    "context": "Title: Implementing local-explainability in Gradient Boosting Trees: Feature Contribution\nAbstract: arXiv:2402.09197v1 Announce Type: new Abstract: Gradient Boost Decision Trees (GBDT) is a powerful additive model based on tree ensembles. Its nature makes GBDT a black-box model even though there are multiple explainable artificial intelligence (XAI) models obtaining information by reinterpreting the model globally and locally. Each tree of the ensemble is a transparent model itself but the final outcome is the result of a sum of these trees and it is not easy to clarify.   In this paper, a feature contribution method for GBDT is developed. The proposed method takes advantage of the GBDT architecture to calculate the contribution of each feature using the residue of each node. This algorithm allows to calculate the sequence of node decisions given a prediction.   Theoretical proofs and multiple experiments have been carried out to demonstrate the performance of our method which is not only a local explicability model for the GBDT algorithm but also a unique option that reflects GBDTs ",
    "path": "papers/24/02/2402.09197.json",
    "total_tokens": 864,
    "translated_title": "在梯度提升决策树中实现局部可解释性：特征贡献",
    "translated_abstract": "Gradient Boosting Decision Trees (GBDT)是基于树集成的强大的加法模型。尽管有多个可解释的人工智能(XAI)模型通过重新解释全局和局部的模型来获取信息，但是GBDT的本质让它成为一个黑盒模型。集成中的每棵树都是一个透明的模型，但最终的结果是这些树的总和，很难澄清。本文提出了一种针对GBDT的特征贡献方法。该方法利用GBDT的架构，通过计算每个节点的残差来计算每个特征的贡献。该算法可以计算给定预测的节点决策序列。通过理论证明和多个实验证明了我们方法的性能，它不仅是GBDT算法的局部可解释性模型，也是反映GBDT的独特选择。",
    "tldr": "本文提出了一个针对GBDT的特征贡献方法，通过计算每个节点的残差来实现局部可解释性。这种方法是GBDT算法的局部可解释性模型，也是一种独特的选择。"
}