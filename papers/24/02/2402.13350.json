{
    "title": "PIRB: A Comprehensive Benchmark of Polish Dense and Hybrid Text Retrieval Methods",
    "abstract": "arXiv:2402.13350v1 Announce Type: new  Abstract: We present Polish Information Retrieval Benchmark (PIRB), a comprehensive evaluation framework encompassing 41 text information retrieval tasks for Polish. The benchmark incorporates existing datasets as well as 10 new, previously unpublished datasets covering diverse topics such as medicine, law, business, physics, and linguistics. We conduct an extensive evaluation of over 20 dense and sparse retrieval models, including the baseline models trained by us as well as other available Polish and multilingual methods. Finally, we introduce a three-step process for training highly effective language-specific retrievers, consisting of knowledge distillation, supervised fine-tuning, and building sparse-dense hybrid retrievers using a lightweight rescoring model. In order to validate our approach, we train new text encoders for Polish and compare their results with previously evaluated methods. Our dense models outperform the best solutions avai",
    "link": "https://arxiv.org/abs/2402.13350",
    "context": "Title: PIRB: A Comprehensive Benchmark of Polish Dense and Hybrid Text Retrieval Methods\nAbstract: arXiv:2402.13350v1 Announce Type: new  Abstract: We present Polish Information Retrieval Benchmark (PIRB), a comprehensive evaluation framework encompassing 41 text information retrieval tasks for Polish. The benchmark incorporates existing datasets as well as 10 new, previously unpublished datasets covering diverse topics such as medicine, law, business, physics, and linguistics. We conduct an extensive evaluation of over 20 dense and sparse retrieval models, including the baseline models trained by us as well as other available Polish and multilingual methods. Finally, we introduce a three-step process for training highly effective language-specific retrievers, consisting of knowledge distillation, supervised fine-tuning, and building sparse-dense hybrid retrievers using a lightweight rescoring model. In order to validate our approach, we train new text encoders for Polish and compare their results with previously evaluated methods. Our dense models outperform the best solutions avai",
    "path": "papers/24/02/2402.13350.json",
    "total_tokens": 916,
    "translated_title": "PIRB：波兰密集和混合文本检索方法的综合基准评估",
    "translated_abstract": "我们介绍了波兰信息检索基准（PIRB），这是一个全面的评估框架，涵盖了波兰语的41个文本信息检索任务。该基准包括现有数据集以及10个新的、以前未公开的数据集，涵盖了医学、法律、商业、物理和语言学等多样主题。我们进行了超过20个密集和稀疏检索模型的广泛评估，包括我们训练的基准模型以及其他可用的波兰语和多语言方法。最后，我们介绍了一个用于训练高效特定语言检索器的三步流程，包括知识蒸馏、监督微调以及使用轻量级重新评分模型构建稀疏-密集混合检索器。为了验证我们的方法，我们为波兰语训练了新的文本编码器，并将其结果与先前评估过的方法进行了比较。我们的密集模型优于现有的最佳解决方案",
    "tldr": "PIRB提出了一个全面的波兰文本信息检索基准，包含41个任务，评估了超过20种密集和稀疏检索模型，并引入了一个三步训练流程来构建高效的特定语言检索器，最后验证了他们的方法的优越性",
    "en_tdlr": "PIRB introduces a comprehensive benchmark for Polish text information retrieval, encompassing 41 tasks, evaluating over 20 dense and sparse retrieval models, and introducing a three-step training process to build highly effective language-specific retrievers, with validation showing superiority of their approach"
}