{
    "title": "Multi-level protein pre-training with Vabs-Net",
    "abstract": "In recent years, there has been a surge in the development of 3D structure-based pre-trained protein models, representing a significant advancement over pre-trained protein language models in various downstream tasks. However, most existing structure-based pre-trained models primarily focus on the residue level, i.e., alpha carbon atoms, while ignoring other atoms like side chain atoms. We argue that modeling proteins at both residue and atom levels is important since the side chain atoms can also be crucial for numerous downstream tasks, for example, molecular docking. Nevertheless, we find that naively combining residue and atom information during pre-training typically fails. We identify a key reason is the information leakage caused by the inclusion of atom structure in the input, which renders residue-level pre-training tasks trivial and results in insufficiently expressive residue representations. To address this issue, we introduce a span mask pre-training strategy on 3D protein",
    "link": "https://rss.arxiv.org/abs/2402.01481",
    "context": "Title: Multi-level protein pre-training with Vabs-Net\nAbstract: In recent years, there has been a surge in the development of 3D structure-based pre-trained protein models, representing a significant advancement over pre-trained protein language models in various downstream tasks. However, most existing structure-based pre-trained models primarily focus on the residue level, i.e., alpha carbon atoms, while ignoring other atoms like side chain atoms. We argue that modeling proteins at both residue and atom levels is important since the side chain atoms can also be crucial for numerous downstream tasks, for example, molecular docking. Nevertheless, we find that naively combining residue and atom information during pre-training typically fails. We identify a key reason is the information leakage caused by the inclusion of atom structure in the input, which renders residue-level pre-training tasks trivial and results in insufficiently expressive residue representations. To address this issue, we introduce a span mask pre-training strategy on 3D protein",
    "path": "papers/24/02/2402.01481.json",
    "total_tokens": 1002,
    "translated_title": "用Vabs-Net进行多级蛋白质预训练",
    "translated_abstract": "最近几年，三维结构预训练蛋白质模型的发展迅猛，相较于预训练蛋白质语言模型，在各种下游任务中取得了重大进展。然而，大多数现有的基于结构的预训练模型主要关注残基水平，即α碳原子，而忽略了其他原子，如侧链原子。我们认为，在残基和原子水平上对蛋白质进行建模很重要，因为侧链原子对于许多下游任务（如分子对接）也是至关重要的。然而，我们发现在预训练中天真地组合残基和原子信息通常会失败。我们发现，信息泄漏是包含原子结构的输入导致残基级预训练任务变得琐碎并导致残基表示不够充分的一个关键原因。为了解决这个问题，我们引入了一种基于跨度掩码预训练策略的三维蛋白质预训练方法。",
    "tldr": "这篇论文介绍了一种使用Vabs-Net进行多级蛋白质预训练的方法。当前大多数基于结构的预训练模型仅关注残基水平，但忽略了侧链原子的重要性。为了解决这个问题，论文提出了一种新的预训练策略，引入了跨度掩码，以在三维蛋白质预训练中同时建模残基和原子水平的信息，并改善了残基表示的表达能力。"
}