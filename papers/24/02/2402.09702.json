{
    "title": "Sparse and Faithful Explanations Without Sparse Models",
    "abstract": "arXiv:2402.09702v1 Announce Type: new  Abstract: Even if a model is not globally sparse, it is possible for decisions made from that model to be accurately and faithfully described by a small number of features. For instance, an application for a large loan might be denied to someone because they have no credit history, which overwhelms any evidence towards their creditworthiness. In this work, we introduce the Sparse Explanation Value (SEV), a new way of measuring sparsity in machine learning models. In the loan denial example above, the SEV is 1 because only one factor is needed to explain why the loan was denied. SEV is a measure of decision sparsity rather than overall model sparsity, and we are able to show that many machine learning models -- even if they are not sparse -- actually have low decision sparsity, as measured by SEV. SEV is defined using movements over a hypercube, allowing SEV to be defined consistently over various model classes, with movement restrictions reflectin",
    "link": "https://arxiv.org/abs/2402.09702",
    "context": "Title: Sparse and Faithful Explanations Without Sparse Models\nAbstract: arXiv:2402.09702v1 Announce Type: new  Abstract: Even if a model is not globally sparse, it is possible for decisions made from that model to be accurately and faithfully described by a small number of features. For instance, an application for a large loan might be denied to someone because they have no credit history, which overwhelms any evidence towards their creditworthiness. In this work, we introduce the Sparse Explanation Value (SEV), a new way of measuring sparsity in machine learning models. In the loan denial example above, the SEV is 1 because only one factor is needed to explain why the loan was denied. SEV is a measure of decision sparsity rather than overall model sparsity, and we are able to show that many machine learning models -- even if they are not sparse -- actually have low decision sparsity, as measured by SEV. SEV is defined using movements over a hypercube, allowing SEV to be defined consistently over various model classes, with movement restrictions reflectin",
    "path": "papers/24/02/2402.09702.json",
    "total_tokens": 946,
    "translated_title": "无需稀疏模型的稀疏且准确的解释",
    "translated_abstract": "即使模型不满足全局的稀疏性，决策仍然可以用少量的特征准确地描述。例如，对于某人而言，尽管没有信用历史，但申请大笔贷款可能会被拒绝，这就忽视了与其信用价值相关的任何证据。在本论文中，我们引入了稀疏解释值（SEV），这是一种衡量机器学习模型稀疏性的新方法。在以上贷款拒绝的例子中，SEV为1，因为只需要一个因素来解释为什么贷款被拒绝。SEV是对决策稀疏性的衡量，而不是对整体模型稀疏性的衡量，并且我们能够证明许多机器学习模型——即使它们不是稀疏的——实际上在SEV的衡量下具有低决策稀疏性。SEV使用超立方体上的移动进行定义，使得SEV能够在各种模型类别上一致地定义，其中移动限制反映了模型的性质。",
    "tldr": "引入了稀疏解释值(SEV)，用于衡量机器学习模型的决策稀疏性。即使模型不是稀疏的，许多机器学习模型在SEV的衡量下仍具有低决策稀疏性。",
    "en_tdlr": "Introducing Sparse Explanation Value (SEV) for measuring decision sparsity in machine learning models, even when the models themselves are not sparse. Many machine learning models exhibit low decision sparsity as measured by SEV."
}