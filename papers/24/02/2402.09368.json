{
    "title": "Magic-Me: Identity-Specific Video Customized Diffusion",
    "abstract": "arXiv:2402.09368v1 Announce Type: cross Abstract: Creating content for a specific identity (ID) has shown significant interest in the field of generative models. In the field of text-to-image generation (T2I), subject-driven content generation has achieved great progress with the ID in the images controllable. However, extending it to video generation is not well explored. In this work, we propose a simple yet effective subject identity controllable video generation framework, termed Video Custom Diffusion (VCD). With a specified subject ID defined by a few images, VCD reinforces the identity information extraction and injects frame-wise correlation at the initialization stage for stable video outputs with identity preserved to a large extent. To achieve this, we propose three novel components that are essential for high-quality ID preservation: 1) an ID module trained with the cropped identity by prompt-to-segmentation to disentangle the ID information and the background noise for mor",
    "link": "https://arxiv.org/abs/2402.09368",
    "context": "Title: Magic-Me: Identity-Specific Video Customized Diffusion\nAbstract: arXiv:2402.09368v1 Announce Type: cross Abstract: Creating content for a specific identity (ID) has shown significant interest in the field of generative models. In the field of text-to-image generation (T2I), subject-driven content generation has achieved great progress with the ID in the images controllable. However, extending it to video generation is not well explored. In this work, we propose a simple yet effective subject identity controllable video generation framework, termed Video Custom Diffusion (VCD). With a specified subject ID defined by a few images, VCD reinforces the identity information extraction and injects frame-wise correlation at the initialization stage for stable video outputs with identity preserved to a large extent. To achieve this, we propose three novel components that are essential for high-quality ID preservation: 1) an ID module trained with the cropped identity by prompt-to-segmentation to disentangle the ID information and the background noise for mor",
    "path": "papers/24/02/2402.09368.json",
    "total_tokens": 915,
    "translated_title": "Magic-Me: 特定身份视频定制扩散",
    "translated_abstract": "在生成模型领域，为特定身份（ID）创建内容已经引起了很大的兴趣。在文本到图像生成（T2I）领域中，以主题驱动的内容生成已经取得了巨大的进展，使得图像中的ID可控。然而，将其扩展到视频生成领域还没有得到很好的探索。在这项工作中，我们提出了一个简单但有效的主题身份可控视频生成框架，称为视频定制扩散（VCD）。通过几个指定的图像定义一个特定的主题ID，VCD加强了身份信息的提取，并在初始化阶段注入逐帧相关性，从而使得视频输出在很大程度上保持了身份的一致性。为了实现这一点，我们提出了三个对于高质量身份保留至关重要的创新组件：1）使用prompt-to-segmentation对身份进行裁剪训练的ID模块，以解开ID信息和背景噪声的联系。",
    "tldr": "本研究提出了一个名为视频定制扩散（VCD）的简单而有效的主题身份可控视频生成框架，通过指定的图像定义主题ID，并加强身份信息提取和逐帧相关性注入，实现了稳定且在很大程度上保持身份一致性的视频输出。",
    "en_tdlr": "This study proposes a simple yet effective framework for subject identity controllable video generation, called Video Custom Diffusion (VCD). By defining a subject ID with specified images and reinforcing identity information extraction and frame-wise correlation injection, stable video outputs with preserved identity to a large extent are achieved."
}