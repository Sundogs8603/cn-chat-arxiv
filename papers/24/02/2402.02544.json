{
    "title": "LHRS-Bot: Empowering Remote Sensing with VGI-Enhanced Large Multimodal Language Model",
    "abstract": "The revolutionary capabilities of large language models (LLMs) have paved the way for multimodal large language models (MLLMs) and fostered diverse applications across various specialized domains. In the remote sensing (RS) field, however, the diverse geographical landscapes and varied objects in RS imagery are not adequately considered in recent MLLM endeavors. To bridge this gap, we construct a large-scale RS image-text dataset, LHRS-Align, and an informative RS-specific instruction dataset, LHRS-Instruct, leveraging the extensive volunteered geographic information (VGI) and globally available RS images. Building on this foundation, we introduce LHRS-Bot, an MLLM tailored for RS image understanding through a novel multi-level vision-language alignment strategy and a curriculum learning method. Comprehensive experiments demonstrate that LHRS-Bot exhibits a profound understanding of RS images and the ability to perform nuanced reasoning within the RS domain.",
    "link": "https://arxiv.org/abs/2402.02544",
    "context": "Title: LHRS-Bot: Empowering Remote Sensing with VGI-Enhanced Large Multimodal Language Model\nAbstract: The revolutionary capabilities of large language models (LLMs) have paved the way for multimodal large language models (MLLMs) and fostered diverse applications across various specialized domains. In the remote sensing (RS) field, however, the diverse geographical landscapes and varied objects in RS imagery are not adequately considered in recent MLLM endeavors. To bridge this gap, we construct a large-scale RS image-text dataset, LHRS-Align, and an informative RS-specific instruction dataset, LHRS-Instruct, leveraging the extensive volunteered geographic information (VGI) and globally available RS images. Building on this foundation, we introduce LHRS-Bot, an MLLM tailored for RS image understanding through a novel multi-level vision-language alignment strategy and a curriculum learning method. Comprehensive experiments demonstrate that LHRS-Bot exhibits a profound understanding of RS images and the ability to perform nuanced reasoning within the RS domain.",
    "path": "papers/24/02/2402.02544.json",
    "total_tokens": 1003,
    "translated_title": "LHRS-Bot：利用VGI增强的大型多模态语言模型赋能遥感领域",
    "translated_abstract": "大型语言模型（LLMs）的革命性能力开创了多模态大型语言模型（MLLMs）并促进了在各个专业领域的多样化应用。然而，在遥感（RS）领域中，近期的MLLM努力未能充分考虑到遥感图像中多样的地理景观和物体。为了弥补这一差距，我们构建了一个大规模的RS图像-文本数据集LHRS-Align，以及一个信息丰富的RS特定指导数据集LHRS-Instruct，利用丰富的自愿地理信息（VGI）和全球可用的RS图像。在此基础上，我们引入了LHRS-Bot，一种针对RS图像理解的MLLM，通过一种新颖的多层次视觉-语言对齐策略和课程学习方法。全面的实验证明，LHRS-Bot展现出对RS图像的深刻理解以及在RS领域内进行细致推理的能力。",
    "tldr": "LHRS-Bot 是一个利用自愿地理信息(VGI)增强的大型多模态语言模型，旨在解决近期MLLM在遥感领域中未对多样的地理景观和物体进行充分考虑的问题。通过引入多层次视觉-语言对齐策略和课程学习方法，LHRS-Bot展现出对RS图像的深刻理解以及在RS领域内进行细致推理的能力。",
    "en_tdlr": "LHRS-Bot is a large multimodal language model enhanced by volunteered geographic information (VGI) that aims to address the lack of consideration for diverse geographical landscapes and objects in recent multimodal language model (MLLM) research for remote sensing (RS). By introducing a novel multilevel vision-language alignment strategy and curriculum learning method, LHRS-Bot demonstrates a profound understanding of RS images and the ability to perform nuanced reasoning within the RS domain."
}