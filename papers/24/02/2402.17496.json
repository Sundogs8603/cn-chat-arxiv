{
    "title": "Emotional Voice Messages (EMOVOME) database: emotion recognition in spontaneous voice messages",
    "abstract": "arXiv:2402.17496v1 Announce Type: cross  Abstract: Emotional Voice Messages (EMOVOME) is a spontaneous speech dataset containing 999 audio messages from real conversations on a messaging app from 100 Spanish speakers, gender balanced. Voice messages were produced in-the-wild conditions before participants were recruited, avoiding any conscious bias due to laboratory environment. Audios were labeled in valence and arousal dimensions by three non-experts and two experts, which were then combined to obtain a final label per dimension. The experts also provided an extra label corresponding to seven emotion categories. To set a baseline for future investigations using EMOVOME, we implemented emotion recognition models using both speech and audio transcriptions. For speech, we used the standard eGeMAPS feature set and support vector machines, obtaining 49.27% and 44.71% unweighted accuracy for valence and arousal respectively. For text, we fine-tuned a multilingual BERT model and achieved 61",
    "link": "https://arxiv.org/abs/2402.17496",
    "context": "Title: Emotional Voice Messages (EMOVOME) database: emotion recognition in spontaneous voice messages\nAbstract: arXiv:2402.17496v1 Announce Type: cross  Abstract: Emotional Voice Messages (EMOVOME) is a spontaneous speech dataset containing 999 audio messages from real conversations on a messaging app from 100 Spanish speakers, gender balanced. Voice messages were produced in-the-wild conditions before participants were recruited, avoiding any conscious bias due to laboratory environment. Audios were labeled in valence and arousal dimensions by three non-experts and two experts, which were then combined to obtain a final label per dimension. The experts also provided an extra label corresponding to seven emotion categories. To set a baseline for future investigations using EMOVOME, we implemented emotion recognition models using both speech and audio transcriptions. For speech, we used the standard eGeMAPS feature set and support vector machines, obtaining 49.27% and 44.71% unweighted accuracy for valence and arousal respectively. For text, we fine-tuned a multilingual BERT model and achieved 61",
    "path": "papers/24/02/2402.17496.json",
    "total_tokens": 959,
    "translated_title": "Emotional Voice Messages (EMOVOME)数据库：自发情感语音消息中的情感识别",
    "translated_abstract": "Emotional Voice Messages (EMOVOME)是一个自发语音数据集，包含来自100名西班牙说话者、男女性平衡的999条真实会话中的音频消息，这些消息通过一个消息应用程序产生，在参与者被招募之前在野外环境中制作，避免了由于实验室环境而产生的任何意识偏见。音频按照三个非专家和两个专家的认可在valence和arousal维度上进行了标记，然后将它们结合以获得每个维度的最终标签。专家还提供了对应于七种情感类别的额外标签。为了为将来使用EMOVOME进行调查设定基准，我们使用了语音和音频转录来实现情感识别模型。对于语音部分，我们使用了标准的eGeMAPS特征集和支持向量机，分别获得了49.27%和44.71%的valence和arousal未加权准确度。对于文本部分，我们对一个多语言BERT模型进行了微调，并实现了61%的情感识别准确度。",
    "tldr": "该研究介绍了Emotional Voice Messages (EMOVOME)数据库，其中包含来自100名西班牙说话者的999条自发语音消息，通过专家和非专家的标记实现了在valence和arousal维度上的情感识别，并尝试使用语音和文本转录实现情感识别模型。",
    "en_tdlr": "This study presents the Emotional Voice Messages (EMOVOME) database, consisting of 999 spontaneous voice messages from 100 Spanish speakers, with emotion recognition in valence and arousal dimensions achieved through labeling by experts and non-experts, and attempts emotion recognition models using both speech and text transcriptions."
}