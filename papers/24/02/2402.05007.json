{
    "title": "Example-based Explanations for Random Forests using Machine Unlearning",
    "abstract": "Tree-based machine learning models, such as decision trees and random forests, have been hugely successful in classification tasks primarily because of their predictive power in supervised learning tasks and ease of interpretation. Despite their popularity and power, these models have been found to produce unexpected or discriminatory outcomes. Given their overwhelming success for most tasks, it is of interest to identify sources of their unexpected and discriminatory behavior. However, there has not been much work on understanding and debugging tree-based classifiers in the context of fairness.   We introduce FairDebugger, a system that utilizes recent advances in machine unlearning research to identify training data subsets responsible for instances of fairness violations in the outcomes of a random forest classifier. FairDebugger generates top-$k$ explanations (in the form of coherent training data subsets) for model unfairness. Toward this goal, FairDebugger first utilizes machine ",
    "link": "https://arxiv.org/abs/2402.05007",
    "context": "Title: Example-based Explanations for Random Forests using Machine Unlearning\nAbstract: Tree-based machine learning models, such as decision trees and random forests, have been hugely successful in classification tasks primarily because of their predictive power in supervised learning tasks and ease of interpretation. Despite their popularity and power, these models have been found to produce unexpected or discriminatory outcomes. Given their overwhelming success for most tasks, it is of interest to identify sources of their unexpected and discriminatory behavior. However, there has not been much work on understanding and debugging tree-based classifiers in the context of fairness.   We introduce FairDebugger, a system that utilizes recent advances in machine unlearning research to identify training data subsets responsible for instances of fairness violations in the outcomes of a random forest classifier. FairDebugger generates top-$k$ explanations (in the form of coherent training data subsets) for model unfairness. Toward this goal, FairDebugger first utilizes machine ",
    "path": "papers/24/02/2402.05007.json",
    "total_tokens": 853,
    "translated_title": "基于示例的机器学习去解释随机森林",
    "translated_abstract": "基于树的机器学习模型，例如决策树和随机森林，在分类任务中取得了巨大的成功，主要是因为它们在监督学习任务中的预测能力和易于解释性。尽管它们受到广泛的欢迎和认可，但这些模型也被发现会产生意外或具有歧视性的结果。鉴于它们对于大多数任务的巨大成功，有必要找出它们意外和具有歧视性行为的原因。然而，在公平性背景下，理解和调试基于树的分类器的研究工作还不多。我们引入了FairDebugger，这是一个利用机器学习去辨识导致随机森林分类器结果中公平性违规的训练数据子集的新型研究成果的系统。FairDebugger生成前-k个解释（以一致的训练数据子集的形式）来解释模型的不公平性。为了实现这个目标，FairDebugger首先利用机器学习去辨识出导致模型不公平的训练数据子集。",
    "tldr": "FairDebugger是一个利用机器学习去解释随机森林的系统，在公平性背景下找出导致模型不公平的训练数据子集。",
    "en_tdlr": "FairDebugger is a system that utilizes machine learning to explain random forests, identifying training data subsets responsible for model unfairness in the context of fairness."
}