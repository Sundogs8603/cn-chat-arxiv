{
    "title": "Repeated Contracting with Multiple Non-Myopic Agents: Policy Regret and Limited Liability",
    "abstract": "arXiv:2402.17108v1 Announce Type: cross  Abstract: We study a repeated contracting setting in which a Principal adaptively chooses amongst $k$ Agents at each of $T$ rounds. The Agents are non-myopic, and so a mechanism for the Principal induces a $T$-round extensive form game amongst the Agents. We give several results aimed at understanding an under-explored aspect of contract theory -- the game induced when choosing an Agent to contract with. First, we show that this game admits a pure-strategy \\emph{non-responsive} equilibrium amongst the Agents -- informally an equilibrium in which the Agent's actions depend on the history of realized states of nature, but not on the history of each other's actions, and so avoids the complexities of collusion and threats. Next, we show that if the Principal selects Agents using a \\emph{monotone} bandit algorithm, then for any concave contract, in any such equilibrium, the Principal obtains no regret to contracting with the best Agent in hindsight -",
    "link": "https://arxiv.org/abs/2402.17108",
    "context": "Title: Repeated Contracting with Multiple Non-Myopic Agents: Policy Regret and Limited Liability\nAbstract: arXiv:2402.17108v1 Announce Type: cross  Abstract: We study a repeated contracting setting in which a Principal adaptively chooses amongst $k$ Agents at each of $T$ rounds. The Agents are non-myopic, and so a mechanism for the Principal induces a $T$-round extensive form game amongst the Agents. We give several results aimed at understanding an under-explored aspect of contract theory -- the game induced when choosing an Agent to contract with. First, we show that this game admits a pure-strategy \\emph{non-responsive} equilibrium amongst the Agents -- informally an equilibrium in which the Agent's actions depend on the history of realized states of nature, but not on the history of each other's actions, and so avoids the complexities of collusion and threats. Next, we show that if the Principal selects Agents using a \\emph{monotone} bandit algorithm, then for any concave contract, in any such equilibrium, the Principal obtains no regret to contracting with the best Agent in hindsight -",
    "path": "papers/24/02/2402.17108.json",
    "total_tokens": 929,
    "translated_title": "多个非近视代理的重复合同：政策后悔和有限责任",
    "translated_abstract": "我们研究了一个重复合同设置，在这个设置中，委托人在每一轮中选择$k$名代理。代理不是近视的，所以委托人的机制引发了一场在代理之间进行的$T$轮广泛形式的博弈。我们得出了几个旨在理解合同理论中一个少有探讨的方面的结果 - 即在选择与之签订合同的代理时引发的博弈。首先，我们展示了这场博弈允许代理之间存在一个纯策略的\\emph{非响应}均衡——非正式地说，这是一个均衡状态，代理的行动取决于实现状态的历史，但不取决于彼此行动的历史，从而避免了勾结和威胁的复杂性。接下来，我们证明如果委托人使用一个\\emph{单调}摇臂算法来选择代理，那么对于任何凹合同，在这样一个均衡状态下，委托人对事后选择与最佳代理签订合同没有后悔。",
    "tldr": "该研究揭示了在选择代理人进行合同时产生的博弈，展示了出色的纯策略均衡以及对于任何凹合同的政策后悔优势。"
}