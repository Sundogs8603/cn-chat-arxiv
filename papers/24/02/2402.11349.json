{
    "title": "Tasks That Language Models Don't Learn",
    "abstract": "arXiv:2402.11349v1 Announce Type: cross  Abstract: We argue that there are certain properties of language that our current large language models (LLMs) don't learn. We present an empirical investigation of visual-auditory properties of language through a series of tasks, termed H-TEST. This benchmark highlights a fundamental gap between human linguistic comprehension, which naturally integrates sensory experiences, and the sensory-deprived processing capabilities of LLMs. In support of our hypothesis, 1. deliberate reasoning (Chain-of-Thought), 2. few-shot examples, or 3. stronger LLM from the same model family (LLaMA 2 13B -> LLaMA 2 70B) do not trivially bring improvements in H-TEST performance. Therefore, we make a particular connection to the philosophical case of Mary, who learns about the world in a sensory-deprived environment (Jackson, 1986). Our experiments show that some of the strongest proprietary LLMs stay near random chance baseline accuracy of 50%, highlighting the limit",
    "link": "https://arxiv.org/abs/2402.11349",
    "context": "Title: Tasks That Language Models Don't Learn\nAbstract: arXiv:2402.11349v1 Announce Type: cross  Abstract: We argue that there are certain properties of language that our current large language models (LLMs) don't learn. We present an empirical investigation of visual-auditory properties of language through a series of tasks, termed H-TEST. This benchmark highlights a fundamental gap between human linguistic comprehension, which naturally integrates sensory experiences, and the sensory-deprived processing capabilities of LLMs. In support of our hypothesis, 1. deliberate reasoning (Chain-of-Thought), 2. few-shot examples, or 3. stronger LLM from the same model family (LLaMA 2 13B -> LLaMA 2 70B) do not trivially bring improvements in H-TEST performance. Therefore, we make a particular connection to the philosophical case of Mary, who learns about the world in a sensory-deprived environment (Jackson, 1986). Our experiments show that some of the strongest proprietary LLMs stay near random chance baseline accuracy of 50%, highlighting the limit",
    "path": "papers/24/02/2402.11349.json",
    "total_tokens": 861,
    "translated_title": "语言模型未学习的任务",
    "translated_abstract": "我们认为，我们目前的大型语言模型（LLMs）没有学习到语言的某些特性。我们通过一系列任务（称为H-TEST）对语言的视听特性进行了实证研究。这一基准测试突显了人类语言理解与LLMs的感官受限处理能力之间的根本差距。支持我们的假设，1. 故意推理（思维链），2. 少量案例，或3. 同一模型系列的更强大LLM（LLaMA 2 13B->LLaMA 2 70B）并不能简单地带来H-TEST性能的改善。因此，我们特别将其与玛丽的哲学案例联系起来，她在感官受限环境中了解世界（Jackson，1986）。我们的实验表明，一些最强大的专有LLMs的表现接近于随机基准准确率50％，突显了极限。",
    "tldr": "大型语言模型没有学习到语言的视听特性，在新的任务基准测试中表现较差，暴露了人类语言理解与语言模型感官处理能力之间的根本差距。"
}