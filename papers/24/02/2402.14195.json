{
    "title": "Learning to Reduce: Optimal Representations of Structured Data in Prompting Large Language Models",
    "abstract": "arXiv:2402.14195v1 Announce Type: new  Abstract: Large Language Models (LLMs) have been widely used as general-purpose AI agents showing comparable performance on many downstream tasks. However, existing work shows that it is challenging for LLMs to integrate structured data (e.g. KG, tables, DBs) into their prompts; LLMs need to either understand long text data or select the most relevant evidence prior to inference, and both approaches are not trivial.   In this paper, we propose a framework, Learning to Reduce, that fine-tunes a language model to generate a reduced version of an input context, given a task description and context input. The model learns to reduce the input context using On-Policy Reinforcement Learning and aims to improve the reasoning performance of a fixed LLM. Experimental results illustrate that our model not only achieves comparable accuracies in selecting the relevant evidence from an input context, but also shows generalizability on different datasets. We fur",
    "link": "https://arxiv.org/abs/2402.14195",
    "context": "Title: Learning to Reduce: Optimal Representations of Structured Data in Prompting Large Language Models\nAbstract: arXiv:2402.14195v1 Announce Type: new  Abstract: Large Language Models (LLMs) have been widely used as general-purpose AI agents showing comparable performance on many downstream tasks. However, existing work shows that it is challenging for LLMs to integrate structured data (e.g. KG, tables, DBs) into their prompts; LLMs need to either understand long text data or select the most relevant evidence prior to inference, and both approaches are not trivial.   In this paper, we propose a framework, Learning to Reduce, that fine-tunes a language model to generate a reduced version of an input context, given a task description and context input. The model learns to reduce the input context using On-Policy Reinforcement Learning and aims to improve the reasoning performance of a fixed LLM. Experimental results illustrate that our model not only achieves comparable accuracies in selecting the relevant evidence from an input context, but also shows generalizability on different datasets. We fur",
    "path": "papers/24/02/2402.14195.json",
    "total_tokens": 876,
    "translated_title": "学习减少: 在向大型语言模型提供结构化数据时的最佳表示",
    "translated_abstract": "大型语言模型（LLMs）被广泛用作通用人工智能代理，展示出在许多下游任务上表现出可比较的性能。然而，现有研究表明，LLMs很难将结构化数据（例如KG、表格、数据库）整合到其提示中；LLMs需要在推理之前要么理解长文本数据，要么选择最相关的证据，而这两种方法都不是微不足道的。 本文提出了一个名为学习减少（Learning to Reduce）的框架，通过微调语言模型，根据任务描述和上下文输入生成输入上下文的精简版本。该模型通过On-Policy强化学习学习减少输入上下文，并旨在提高固定LLM的推理性能。实验结果表明，我们的模型不仅在从输入上下文中选择相关证据方面取得了可比较的准确性，而且在不同数据集上表现出了通用性。",
    "tldr": "该研究提出了一个名为学习减少的框架，利用强化学习减少输入上下文，以提高固定大型语言模型的推理性能，并展现了在不同数据集上的泛化能力。",
    "en_tdlr": "This study introduces a framework called Learning to Reduce, which uses reinforcement learning to reduce input context to enhance the reasoning performance of fixed large language models, demonstrating generalizability on different datasets."
}