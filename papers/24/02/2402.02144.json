{
    "title": "Probing Critical Learning Dynamics of PLMs for Hate Speech Detection",
    "abstract": "Despite the widespread adoption, there is a lack of research into how various critical aspects of pretrained language models (PLMs) affect their performance in hate speech detection. Through five research questions, our findings and recommendations lay the groundwork for empirically investigating different aspects of PLMs' use in hate speech detection. We deep dive into comparing different pretrained models, evaluating their seed robustness, finetuning settings, and the impact of pretraining data collection time. Our analysis reveals early peaks for downstream tasks during pretraining, the limited benefit of employing a more recent pretraining corpus, and the significance of specific layers during finetuning. We further call into question the use of domain-specific models and highlight the need for dynamic datasets for benchmarking hate speech detection.",
    "link": "https://arxiv.org/abs/2402.02144",
    "context": "Title: Probing Critical Learning Dynamics of PLMs for Hate Speech Detection\nAbstract: Despite the widespread adoption, there is a lack of research into how various critical aspects of pretrained language models (PLMs) affect their performance in hate speech detection. Through five research questions, our findings and recommendations lay the groundwork for empirically investigating different aspects of PLMs' use in hate speech detection. We deep dive into comparing different pretrained models, evaluating their seed robustness, finetuning settings, and the impact of pretraining data collection time. Our analysis reveals early peaks for downstream tasks during pretraining, the limited benefit of employing a more recent pretraining corpus, and the significance of specific layers during finetuning. We further call into question the use of domain-specific models and highlight the need for dynamic datasets for benchmarking hate speech detection.",
    "path": "papers/24/02/2402.02144.json",
    "total_tokens": 917,
    "translated_title": "探究预训练语言模型在检测仇恨言论中的关键学习动态",
    "translated_abstract": "尽管广泛应用，但缺乏关于预训练语言模型（PLMs）各种关键方面如何影响其在检测仇恨言论中的性能的研究。通过五个研究问题，我们的发现和建议为实证研究PLMs在检测仇恨言论中的不同方面打下了基础。我们深入比较了不同的预训练模型，评估了它们的鲁棒性、微调设置以及预训练数据收集时间的影响。我们的分析揭示了预训练过程中下游任务的早期峰值，采用更新的预训练语料库带来的有限益处，以及微调过程中特定层次的重要性。我们进一步对使用领域特定模型提出质疑，并强调了用于基准测试仇恨言论检测的动态数据集的需求。",
    "tldr": "该论文探究了预训练语言模型在检测仇恨言论中的关键学习动态，提出了深入的研究问题，并通过比较不同模型、评估鲁棒性、微调设置和预训练数据收集时间的影响等方面的分析结果，为研究者在仇恨言论检测领域提供了实证基础和建议。",
    "en_tdlr": "This paper investigates the critical learning dynamics of pretrained language models (PLMs) in hate speech detection, providing empirical findings and recommendations for researchers in this field. Through comparing different models, evaluating robustness, finetuning settings, and pretraining data collection time, the authors highlight the importance of specific layers during finetuning and the need for dynamic datasets for benchmarking hate speech detection."
}