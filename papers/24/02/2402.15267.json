{
    "title": "Adversarial Robustness of Deep Learning-based Malware Detectors via (De)Randomized Smoothing",
    "abstract": "arXiv:2402.15267v1 Announce Type: cross  Abstract: Deep learning-based malware detectors have been shown to be susceptible to adversarial malware examples, i.e. malware examples that have been deliberately manipulated in order to avoid detection. In light of the vulnerability of deep learning detectors to subtle input file modifications, we propose a practical defense against adversarial malware examples inspired by (de)randomized smoothing. In this work, we reduce the chances of sampling adversarial content injected by malware authors by selecting correlated subsets of bytes, rather than using Gaussian noise to randomize inputs like in the Computer Vision (CV) domain. During training, our ablation-based smoothing scheme trains a base classifier to make classifications on a subset of contiguous bytes or chunk of bytes. At test time, a large number of chunks are then classified by a base classifier and the consensus among these classifications is then reported as the final prediction. W",
    "link": "https://arxiv.org/abs/2402.15267",
    "context": "Title: Adversarial Robustness of Deep Learning-based Malware Detectors via (De)Randomized Smoothing\nAbstract: arXiv:2402.15267v1 Announce Type: cross  Abstract: Deep learning-based malware detectors have been shown to be susceptible to adversarial malware examples, i.e. malware examples that have been deliberately manipulated in order to avoid detection. In light of the vulnerability of deep learning detectors to subtle input file modifications, we propose a practical defense against adversarial malware examples inspired by (de)randomized smoothing. In this work, we reduce the chances of sampling adversarial content injected by malware authors by selecting correlated subsets of bytes, rather than using Gaussian noise to randomize inputs like in the Computer Vision (CV) domain. During training, our ablation-based smoothing scheme trains a base classifier to make classifications on a subset of contiguous bytes or chunk of bytes. At test time, a large number of chunks are then classified by a base classifier and the consensus among these classifications is then reported as the final prediction. W",
    "path": "papers/24/02/2402.15267.json",
    "total_tokens": 908,
    "translated_title": "通过（去）随机平滑提高基于深度学习的恶意软件检测器的对抗鲁棒性",
    "translated_abstract": "基于深度学习的恶意软件检测器已被证明容易受到对抗性恶意软件示例的攻击，即恶意软件示例经过故意操纵以避免检测。鉴于深度学习检测器对微妙输入文件修改的脆弱性，我们提出了一种受（去）随机平滑启发的针对对抗性恶意软件示例的实用防御方法。本文中，我们通过选择相关的字节子集而不是像计算机视觉（CV）领域那样使用高斯噪声来随机化输入，来降低被恶意软件作者注入的对抗内容被采样的几率。在训练期间，我们的去除基于消融的平滑方案训练一个基本分类器对一部分连续字节或字节块进行分类。在测试时，基本分类器对大量字节块进行分类，最后预测结果是这些分类中的一致性。",
    "tldr": "通过选择相关的字节子集替代高斯噪声，在训练中进行基于消融的平滑方案，加强了基于深度学习的恶意软件检测器对抗性恶意软件示例的鲁棒性。",
    "en_tdlr": "The paper strengthens the adversarial robustness of deep learning-based malware detectors by selecting correlated subsets of bytes instead of using Gaussian noise, and implementing an ablation-based smoothing scheme during training."
}