{
    "title": "PreFLMR: Scaling Up Fine-Grained Late-Interaction Multi-modal Retrievers",
    "abstract": "Large Multimodal Models (LMMs) excel in natural language and visual understanding but are challenged by exacting tasks such as Knowledge-based Visual Question Answering (KB-VQA) which involve the retrieval of relevant information from document collections to use in shaping answers to questions. We present an extensive training and evaluation framework, M2KR, for KB-VQA. M2KR contains a collection of vision and language tasks which we have incorporated into a single suite of benchmark tasks for training and evaluating general-purpose multi-modal retrievers. We use M2KR to develop PreFLMR, a pre-trained version of the recently developed Fine-grained Late-interaction Multi-modal Retriever (FLMR) approach to KB-VQA, and we report new state-of-the-art results across a range of tasks. We also present investigations into the scaling behaviors of PreFLMR intended to be useful in future developments in general-purpose multi-modal retrievers.",
    "link": "https://arxiv.org/abs/2402.08327",
    "context": "Title: PreFLMR: Scaling Up Fine-Grained Late-Interaction Multi-modal Retrievers\nAbstract: Large Multimodal Models (LMMs) excel in natural language and visual understanding but are challenged by exacting tasks such as Knowledge-based Visual Question Answering (KB-VQA) which involve the retrieval of relevant information from document collections to use in shaping answers to questions. We present an extensive training and evaluation framework, M2KR, for KB-VQA. M2KR contains a collection of vision and language tasks which we have incorporated into a single suite of benchmark tasks for training and evaluating general-purpose multi-modal retrievers. We use M2KR to develop PreFLMR, a pre-trained version of the recently developed Fine-grained Late-interaction Multi-modal Retriever (FLMR) approach to KB-VQA, and we report new state-of-the-art results across a range of tasks. We also present investigations into the scaling behaviors of PreFLMR intended to be useful in future developments in general-purpose multi-modal retrievers.",
    "path": "papers/24/02/2402.08327.json",
    "total_tokens": 950,
    "translated_title": "PreFLMR: 扩展细粒度迟交互多模态检索器",
    "translated_abstract": "大型多模态模型(LMMs)在自然语言和视觉理解方面表现出色，但在诸如基于知识的视觉问答(KB-VQA)这样的严格任务中，却面临着从文档集合中检索相关信息以用于塑造问题答案的挑战。我们提出了一个广泛的训练和评估框架M2KR，用于KB-VQA。M2KR包含了一系列的视觉和语言任务，我们将其整合为一个用于训练和评估通用多模态检索器的基准任务套件。我们使用M2KR开发了PreFLMR，这是最近开发的细粒度迟交互多模态检索器(FLMR)方法的预训练版本，并且我们报告了一系列任务中的新的最先进结果。我们还对PreFLMR的扩展行为进行了研究，旨在对未来发展的通用多模态检索器有所帮助。",
    "tldr": "PreFLMR是一种扩展细粒度迟交互多模态检索器，用于解决知识式视觉问答任务。该方法通过训练和评估框架M2KR进行了开发，并在多个任务中取得了新的最先进结果。此外，还对PreFLMR的扩展行为进行了研究，为通用多模态检索器的未来发展提供了有用的启示。",
    "en_tdlr": "PreFLMR is an extended fine-grained late-interaction multi-modal retriever used for knowledge-based visual question answering. The approach is developed using the training and evaluation framework M2KR and achieves new state-of-the-art results across multiple tasks. Additionally, investigations into the scaling behaviors of PreFLMR provide useful insights for future developments in general-purpose multi-modal retrievers."
}