{
    "title": "Panoramic Image Inpainting With Gated Convolution And Contextual Reconstruction Loss",
    "abstract": "Deep learning-based methods have demonstrated encouraging results in tackling the task of panoramic image inpainting. However, it is challenging for existing methods to distinguish valid pixels from invalid pixels and find suitable references for corrupted areas, thus leading to artifacts in the inpainted results. In response to these challenges, we propose a panoramic image inpainting framework that consists of a Face Generator, a Cube Generator, a side branch, and two discriminators. We use the Cubemap Projection (CMP) format as network input. The generator employs gated convolutions to distinguish valid pixels from invalid ones, while a side branch is designed utilizing contextual reconstruction (CR) loss to guide the generators to find the most suitable reference patch for inpainting the missing region. The proposed method is compared with state-of-the-art (SOTA) methods on SUN360 Street View dataset in terms of PSNR and SSIM. Experimental results and ablation study demonstrate tha",
    "link": "https://arxiv.org/abs/2402.02936",
    "context": "Title: Panoramic Image Inpainting With Gated Convolution And Contextual Reconstruction Loss\nAbstract: Deep learning-based methods have demonstrated encouraging results in tackling the task of panoramic image inpainting. However, it is challenging for existing methods to distinguish valid pixels from invalid pixels and find suitable references for corrupted areas, thus leading to artifacts in the inpainted results. In response to these challenges, we propose a panoramic image inpainting framework that consists of a Face Generator, a Cube Generator, a side branch, and two discriminators. We use the Cubemap Projection (CMP) format as network input. The generator employs gated convolutions to distinguish valid pixels from invalid ones, while a side branch is designed utilizing contextual reconstruction (CR) loss to guide the generators to find the most suitable reference patch for inpainting the missing region. The proposed method is compared with state-of-the-art (SOTA) methods on SUN360 Street View dataset in terms of PSNR and SSIM. Experimental results and ablation study demonstrate tha",
    "path": "papers/24/02/2402.02936.json",
    "total_tokens": 877,
    "translated_title": "具有门控卷积和上下文重建损失的全景图像修复",
    "translated_abstract": "基于深度学习的方法在处理全景图像修补任务中取得了令人鼓舞的结果。然而，现有的方法很难区分有效像素和无效像素，并找到合适的参考区域来修补受损区域，从而导致修复结果中出现伪影。为了应对这些挑战，我们提出了一个全景图像修复框架，包括一个Face生成器，一个Cube生成器，一个侧分支和两个判别器。我们使用立方体映射（CMP）格式作为网络输入。生成器采用门控卷积来区分有效像素和无效像素，同时设计了一个侧分支，利用上下文重建（CR）损失来指导生成器找到最适合修复缺失区域的参考补丁。在PSNR和SSIM指标下，将所提出的方法与最先进的方法在SUN360街景数据集上进行了比较。实验结果和消融研究表明，",
    "tldr": "本论文提出了一种全景图像修复框架，采用门控卷积来区分有效像素和无效像素，并利用上下文重建损失来引导生成器找到最适合修复缺失区域的参考补丁。",
    "en_tdlr": "This paper proposes a panoramic image inpainting framework that uses gated convolutions to distinguish valid pixels from invalid ones, and utilizes contextual reconstruction loss to guide the generator in finding the most suitable reference patch for inpainting the missing region."
}