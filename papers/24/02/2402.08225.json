{
    "title": "Improving Black-box Robustness with In-Context Rewriting",
    "abstract": "Machine learning models often excel on in-distribution (ID) data but struggle with unseen out-of-distribution (OOD) inputs. Most techniques for improving OOD robustness are not applicable to settings where the model is effectively a black box, such as when the weights are frozen, retraining is costly, or the model is leveraged via an API. Test-time augmentation (TTA) is a simple post-hoc technique for improving robustness that sidesteps black-box constraints by aggregating predictions across multiple augmentations of the test input. TTA has seen limited use in NLP due to the challenge of generating effective natural language augmentations. In this work, we propose LLM-TTA, which uses LLM-generated augmentations as TTA's augmentation function. LLM-TTA outperforms conventional augmentation functions across sentiment, toxicity, and news classification tasks for BERT and T5 models, with BERT's OOD robustness improving by an average of 4.30 percentage points without regressing average ID pe",
    "link": "https://arxiv.org/abs/2402.08225",
    "context": "Title: Improving Black-box Robustness with In-Context Rewriting\nAbstract: Machine learning models often excel on in-distribution (ID) data but struggle with unseen out-of-distribution (OOD) inputs. Most techniques for improving OOD robustness are not applicable to settings where the model is effectively a black box, such as when the weights are frozen, retraining is costly, or the model is leveraged via an API. Test-time augmentation (TTA) is a simple post-hoc technique for improving robustness that sidesteps black-box constraints by aggregating predictions across multiple augmentations of the test input. TTA has seen limited use in NLP due to the challenge of generating effective natural language augmentations. In this work, we propose LLM-TTA, which uses LLM-generated augmentations as TTA's augmentation function. LLM-TTA outperforms conventional augmentation functions across sentiment, toxicity, and news classification tasks for BERT and T5 models, with BERT's OOD robustness improving by an average of 4.30 percentage points without regressing average ID pe",
    "path": "papers/24/02/2402.08225.json",
    "total_tokens": 1012,
    "translated_title": "用上下文重写提高黑盒模型的鲁棒性",
    "translated_abstract": "机器学习模型在分布内（ID）数据上表现优秀，但在未见过的分布外（OOD）输入上表现困难。大多数提高OOD鲁棒性的技术在模型是黑盒的情况下不适用，例如权重被冻结，重新训练成本高，或者通过API使用模型。测试时间增强（TTA）是一种简单的事后技术，通过对测试输入的多个增强进行预测聚合来绕过黑盒约束来提高鲁棒性。由于生成有效的自然语言增强的挑战，TTA在自然语言处理中的应用受到限制。在这项研究中，我们提出了LLM-TTA，它使用LLM生成的增强作为TTA的增强函数。LLM-TTA在BERT和T5模型的情感、毒性和新闻分类任务中优于传统的增强函数，BERT的OOD鲁棒性提高了平均4.30个百分点而不会减退平均ID pe。",
    "tldr": "本文提出了一种名为LLM-TTA的方法，通过使用LLM生成的增强作为测试时间增强（TTA）的增强函数，提高了黑盒模型的鲁棒性。在BERT和T5模型的情感、毒性和新闻分类任务中，LLM-TTA优于传统的增强函数，使BERT的分布外鲁棒性平均提高了4.30个百分点，而不降低分布内性能。",
    "en_tdlr": "This paper proposes LLM-TTA, a method that improves black-box model robustness by using LLM-generated augmentations as the augmentation function for test-time augmentation (TTA). LLM-TTA outperforms conventional augmentation functions in sentiment, toxicity, and news classification tasks for BERT and T5 models, with an average improvement of 4.30 percentage points in out-of-distribution (OOD) robustness for BERT without regressing in-distribution (ID) performance."
}