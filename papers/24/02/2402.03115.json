{
    "title": "Discovering interpretable models of scientific image data with deep learning",
    "abstract": "How can we find interpretable, domain-appropriate models of natural phenomena given some complex, raw data such as images? Can we use such models to derive scientific insight from the data? In this paper, we propose some methods for achieving this. In particular, we implement disentangled representation learning, sparse deep neural network training and symbolic regression, and assess their usefulness in forming interpretable models of complex image data. We demonstrate their relevance to the field of bioimaging using a well-studied test problem of classifying cell states in microscopy data. We find that such methods can produce highly parsimonious models that achieve $\\sim98\\%$ of the accuracy of black-box benchmark models, with a tiny fraction of the complexity. We explore the utility of such interpretable models in producing scientific explanations of the underlying biological phenomenon.",
    "link": "https://arxiv.org/abs/2402.03115",
    "context": "Title: Discovering interpretable models of scientific image data with deep learning\nAbstract: How can we find interpretable, domain-appropriate models of natural phenomena given some complex, raw data such as images? Can we use such models to derive scientific insight from the data? In this paper, we propose some methods for achieving this. In particular, we implement disentangled representation learning, sparse deep neural network training and symbolic regression, and assess their usefulness in forming interpretable models of complex image data. We demonstrate their relevance to the field of bioimaging using a well-studied test problem of classifying cell states in microscopy data. We find that such methods can produce highly parsimonious models that achieve $\\sim98\\%$ of the accuracy of black-box benchmark models, with a tiny fraction of the complexity. We explore the utility of such interpretable models in producing scientific explanations of the underlying biological phenomenon.",
    "path": "papers/24/02/2402.03115.json",
    "total_tokens": 860,
    "translated_title": "用深度学习发现可解释的科学图像数据模型",
    "translated_abstract": "如何在给定一些复杂的原始数据，如图像，情况下找到可解释的、与领域相关的自然现象模型？我们能否利用这些模型从数据中得出科学见解？本文提出了一些方法来实现这一目标。特别地，我们实现了解耦表示学习、稀疏深度神经网络训练和符号回归，并评估了它们在形成可解释的复杂图像数据模型方面的实用性。我们使用一个已经研究过的显微镜观察细胞状态分类的测试问题来证明它们与生物成像领域的相关性。我们发现这些方法可以产生高度简约的模型，其准确率达到黑盒基准模型的约98%，但复杂度仅为其一小部分。我们探讨了这些可解释模型在解释潜在生物现象方面的实用性。",
    "tldr": "本文提出了使用解耦表示学习、稀疏深度神经网络训练和符号回归的方法，在复杂图像数据中形成高度简约且准确性可媲美黑盒模型的可解释模型，进一步探讨了这些模型在解释生物现象方面的应用。",
    "en_tdlr": "This paper proposes methods for forming highly parsimonious and accurate interpretable models in complex image data using disentangled representation learning, sparse deep neural network training, and symbolic regression. The utility of such models in explaining biological phenomena is further explored."
}