{
    "title": "Prompting Explicit and Implicit Knowledge for Multi-hop Question Answering Based on Human Reading Process",
    "abstract": "arXiv:2402.19350v1 Announce Type: new  Abstract: Pre-trained language models (PLMs) leverage chains-of-thought (CoT) to simulate human reasoning and inference processes, achieving proficient performance in multi-hop QA. However, a gap persists between PLMs' reasoning abilities and those of humans when tackling complex problems. Psychological studies suggest a vital connection between explicit information in passages and human prior knowledge during reading. Nevertheless, current research has given insufficient attention to linking input passages and PLMs' pre-training-based knowledge from the perspective of human cognition studies. In this study, we introduce a \\textbf{P}rompting \\textbf{E}xplicit and \\textbf{I}mplicit knowledge (PEI) framework, which uses prompts to connect explicit and implicit knowledge, aligning with human reading process for multi-hop QA. We consider the input passages as explicit knowledge, employing them to elicit implicit knowledge through unified prompt reason",
    "link": "https://arxiv.org/abs/2402.19350",
    "context": "Title: Prompting Explicit and Implicit Knowledge for Multi-hop Question Answering Based on Human Reading Process\nAbstract: arXiv:2402.19350v1 Announce Type: new  Abstract: Pre-trained language models (PLMs) leverage chains-of-thought (CoT) to simulate human reasoning and inference processes, achieving proficient performance in multi-hop QA. However, a gap persists between PLMs' reasoning abilities and those of humans when tackling complex problems. Psychological studies suggest a vital connection between explicit information in passages and human prior knowledge during reading. Nevertheless, current research has given insufficient attention to linking input passages and PLMs' pre-training-based knowledge from the perspective of human cognition studies. In this study, we introduce a \\textbf{P}rompting \\textbf{E}xplicit and \\textbf{I}mplicit knowledge (PEI) framework, which uses prompts to connect explicit and implicit knowledge, aligning with human reading process for multi-hop QA. We consider the input passages as explicit knowledge, employing them to elicit implicit knowledge through unified prompt reason",
    "path": "papers/24/02/2402.19350.json",
    "total_tokens": 855,
    "translated_title": "基于人类阅读过程的多跳问题回答中促进显式和隐式知识",
    "translated_abstract": "预训练语言模型（PLMs）利用思维链（CoT）模拟人类推理和推断过程，实现了在多跳QA方面高效的性能。然而，当处理复杂问题时，PLMs的推理能力和人类之间仍存在差距。心理学研究表明，在阅读过程中，输入文段中的显式信息与人类先验知识之间存在重要联系。然而，当前的研究未能充分关注从人类认知研究的角度链接输入文段和基于PLMs预训练知识。在本研究中，我们引入了一个促进显式和隐式知识（PEI）框架，使用提示连接显式和隐式知识，与人类阅读过程对齐，用于多跳QA。我们将输入文段视为显式知识，利用它们通过统一提示推导隐式知识。",
    "tldr": "该研究引入了一个促进显式和隐式知识的框架，用于多跳问题回答，从人类阅读过程的角度连接输入文段和预训练知识。",
    "en_tdlr": "This study introduces a framework that promotes explicit and implicit knowledge for multi-hop question answering, linking input passages and pre-training knowledge from the perspective of human reading process."
}