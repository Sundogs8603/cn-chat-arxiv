{
    "title": "PANDA: Preference Adaptation for Enhancing Domain-Specific Abilities of LLMs",
    "abstract": "arXiv:2402.12835v1 Announce Type: cross  Abstract: While Large language models (LLMs) have demonstrated considerable capabilities across various natural language tasks, they often fall short of the performance achieved by domain-specific state-of-the-art models. One potential approach to enhance domain-specific capabilities of LLMs involves fine-tuning them using corresponding datasets. However, this method can be both resource and time-intensive, and not applicable to closed-source commercial LLMs. In this paper, we propose Preference Adaptation for Enhancing Domain-specific Abilities of LLMs (PANDA), a method designed to augment the domain-specific capabilities of LLMs by leveraging insights from the response preference of expert models without requiring fine-tuning. Our experimental results reveal that PANDA significantly enhances the domain-specific ability of LLMs on text classification and interactive decision tasks. Moreover, LLM with PANDA even outperforms the expert model that",
    "link": "https://arxiv.org/abs/2402.12835",
    "context": "Title: PANDA: Preference Adaptation for Enhancing Domain-Specific Abilities of LLMs\nAbstract: arXiv:2402.12835v1 Announce Type: cross  Abstract: While Large language models (LLMs) have demonstrated considerable capabilities across various natural language tasks, they often fall short of the performance achieved by domain-specific state-of-the-art models. One potential approach to enhance domain-specific capabilities of LLMs involves fine-tuning them using corresponding datasets. However, this method can be both resource and time-intensive, and not applicable to closed-source commercial LLMs. In this paper, we propose Preference Adaptation for Enhancing Domain-specific Abilities of LLMs (PANDA), a method designed to augment the domain-specific capabilities of LLMs by leveraging insights from the response preference of expert models without requiring fine-tuning. Our experimental results reveal that PANDA significantly enhances the domain-specific ability of LLMs on text classification and interactive decision tasks. Moreover, LLM with PANDA even outperforms the expert model that",
    "path": "papers/24/02/2402.12835.json",
    "total_tokens": 828,
    "translated_title": "PANDA: 用于增强LLMs领域特定能力的偏好适应方法",
    "translated_abstract": "大型语言模型（LLMs）在各种自然语言任务中展示出相当大的能力，但它们通常无法达到特定领域最先进模型的性能水平。增强LLMs领域特定能力的一种潜在方法是使用相应的数据集对其进行微调。然而，这种方法既耗费资源又耗时，并且无法应用于封闭源商业LLMs。在本文中，我们提出了一种称为PANDA的偏好适应方法，旨在通过利用专家模型响应偏好的见解来增强LLMs的领域特定能力，而无需进行微调。我们的实验结果显示，PANDA显著提升了LLMs在文本分类和交互式决策任务上的领域特定能力。此外，具有PANDA的LLM甚至超过了专家模型",
    "tldr": "PANDA是一种旨在增强LLMs领域特定能力的方法，通过利用专家模型响应偏好的见解，无需微调即可实现显著改进。",
    "en_tdlr": "PANDA is a method designed to enhance the domain-specific capabilities of LLMs by leveraging insights from the response preference of expert models without requiring fine-tuning, achieving significant improvements."
}