{
    "title": "Disparate Impact on Group Accuracy of Linearization for Private Inference",
    "abstract": "Ensuring privacy-preserving inference on cryptographically secure data is a well-known computational challenge. To alleviate the bottleneck of costly cryptographic computations in non-linear activations, recent methods have suggested linearizing a targeted portion of these activations in neural networks. This technique results in significantly reduced runtimes with often negligible impacts on accuracy. In this paper, we demonstrate that such computational benefits may lead to increased fairness costs. Specifically, we find that reducing the number of ReLU activations disproportionately decreases the accuracy for minority groups compared to majority groups. To explain these observations, we provide a mathematical interpretation under restricted assumptions about the nature of the decision boundary, while also showing the prevalence of this problem across widely used datasets and architectures. Finally, we show how a simple procedure altering the fine-tuning step for linearized models ca",
    "link": "https://arxiv.org/abs/2402.03629",
    "context": "Title: Disparate Impact on Group Accuracy of Linearization for Private Inference\nAbstract: Ensuring privacy-preserving inference on cryptographically secure data is a well-known computational challenge. To alleviate the bottleneck of costly cryptographic computations in non-linear activations, recent methods have suggested linearizing a targeted portion of these activations in neural networks. This technique results in significantly reduced runtimes with often negligible impacts on accuracy. In this paper, we demonstrate that such computational benefits may lead to increased fairness costs. Specifically, we find that reducing the number of ReLU activations disproportionately decreases the accuracy for minority groups compared to majority groups. To explain these observations, we provide a mathematical interpretation under restricted assumptions about the nature of the decision boundary, while also showing the prevalence of this problem across widely used datasets and architectures. Finally, we show how a simple procedure altering the fine-tuning step for linearized models ca",
    "path": "papers/24/02/2402.03629.json",
    "total_tokens": 907,
    "translated_title": "私有推断的线性化对群体准确性的不对称影响",
    "translated_abstract": "确保对具有密码安全性的数据进行隐私保护的推断是一个众所周知的计算挑战。为了减轻非线性激活函数中昂贵的加密计算的瓶颈，最近的方法建议在线性神经网络中线性化目标部分的激活函数。这种技术可以显著减少运行时间，对准确性的影响往往可以忽略不计。在本文中，我们证明了这种计算优势可能导致公平性成本增加。具体而言，我们发现减少ReLU激活函数数量会不成比例地降低少数群体的准确性，而对于多数群体则几乎没有影响。为了解释这些观察结果，我们在对决策边界性质进行限制性假设的基础上提供了数学解释，同时还展示了这个问题在广泛使用的数据集和体系结构中的普遍性。最后，我们展示了如何通过简单的程序改变线性模型的微调步骤来解决这个问题。",
    "tldr": "本文研究了线性化对隐私推断中群体准确性的影响，发现减少ReLU激活函数数量会不成比例地降低少数群体的准确性，而对于多数群体则几乎没有影响。采用简单的微调步骤可以解决这个问题。"
}