{
    "title": "Scaling the Authoring of AutoTutors with Large Language Models",
    "abstract": "arXiv:2402.09216v1 Announce Type: new Abstract: Large Language Models (LLMs) have found several use cases in education, ranging from automatic question generation to essay evaluation. In this paper, we explore the potential of using Large Language Models (LLMs) to author Intelligent Tutoring Systems. A common pitfall of LLMs is their straying from desired pedagogical strategies such as leaking the answer to the student, and in general, providing no guarantees. We posit that while LLMs with certain guardrails can take the place of subject experts, the overall pedagogical design still needs to be handcrafted for the best learning results. Based on this principle, we create a sample end-to-end tutoring system named MWPTutor, which uses LLMs to fill in the state space of a pre-defined finite state transducer. This approach retains the structure and the pedagogy of traditional tutoring systems that has been developed over the years by learning scientists but brings in additional flexibility",
    "link": "https://arxiv.org/abs/2402.09216",
    "context": "Title: Scaling the Authoring of AutoTutors with Large Language Models\nAbstract: arXiv:2402.09216v1 Announce Type: new Abstract: Large Language Models (LLMs) have found several use cases in education, ranging from automatic question generation to essay evaluation. In this paper, we explore the potential of using Large Language Models (LLMs) to author Intelligent Tutoring Systems. A common pitfall of LLMs is their straying from desired pedagogical strategies such as leaking the answer to the student, and in general, providing no guarantees. We posit that while LLMs with certain guardrails can take the place of subject experts, the overall pedagogical design still needs to be handcrafted for the best learning results. Based on this principle, we create a sample end-to-end tutoring system named MWPTutor, which uses LLMs to fill in the state space of a pre-defined finite state transducer. This approach retains the structure and the pedagogy of traditional tutoring systems that has been developed over the years by learning scientists but brings in additional flexibility",
    "path": "papers/24/02/2402.09216.json",
    "total_tokens": 849,
    "translated_title": "使用大型语言模型扩展AutoTutor的创作",
    "translated_abstract": "大型语言模型（LLMs）在教育领域有多种用途，从自动题目生成到作文评估。本文探讨了使用大型语言模型（LLMs）来撰写智能辅导系统的潜力。LLMs的一个常见问题是它们容易偏离所期望的教学策略，例如泄露答案给学生，总体上提供的保证很少。我们认为，虽然带有某些限制的LLMs可以取代学科专家的位置，但整体的教学设计仍需手工制作以取得最佳学习效果。基于这一原则，我们创建了一个示例的端到端辅导系统，命名为MWPTutor，它使用LLMs填充预定义有限状态转换器的状态空间。这种方法保留了多年来由学习科学家开发的传统辅导系统的结构和教学法，同时引入了额外的灵活性。",
    "tldr": "本文研究使用大型语言模型（LLMs）来撰写智能辅导系统的潜力，提出了保留传统辅导系统结构和教学法的方法。",
    "en_tdlr": "This paper explores the potential of using Large Language Models (LLMs) to author Intelligent Tutoring Systems and proposes an approach that retains the structure and pedagogy of traditional tutoring systems while bringing in additional flexibility."
}