{
    "title": "Gradual Residuals Alignment: A Dual-Stream Framework for GAN Inversion and Image Attribute Editing",
    "abstract": "arXiv:2402.14398v1 Announce Type: cross  Abstract: GAN-based image attribute editing firstly leverages GAN Inversion to project real images into the latent space of GAN and then manipulates corresponding latent codes. Recent inversion methods mainly utilize additional high-bit features to improve image details preservation, as low-bit codes cannot faithfully reconstruct source images, leading to the loss of details. However, during editing, existing works fail to accurately complement the lost details and suffer from poor editability. The main reason is they inject all the lost details indiscriminately at one time, which inherently induces the position and quantity of details to overfit source images, resulting in inconsistent content and artifacts in edited images. This work argues that details should be gradually injected into both the reconstruction and editing process in a multi-stage coarse-to-fine manner for better detail preservation and high editability. Therefore, a novel dual",
    "link": "https://arxiv.org/abs/2402.14398",
    "context": "Title: Gradual Residuals Alignment: A Dual-Stream Framework for GAN Inversion and Image Attribute Editing\nAbstract: arXiv:2402.14398v1 Announce Type: cross  Abstract: GAN-based image attribute editing firstly leverages GAN Inversion to project real images into the latent space of GAN and then manipulates corresponding latent codes. Recent inversion methods mainly utilize additional high-bit features to improve image details preservation, as low-bit codes cannot faithfully reconstruct source images, leading to the loss of details. However, during editing, existing works fail to accurately complement the lost details and suffer from poor editability. The main reason is they inject all the lost details indiscriminately at one time, which inherently induces the position and quantity of details to overfit source images, resulting in inconsistent content and artifacts in edited images. This work argues that details should be gradually injected into both the reconstruction and editing process in a multi-stage coarse-to-fine manner for better detail preservation and high editability. Therefore, a novel dual",
    "path": "papers/24/02/2402.14398.json",
    "total_tokens": 855,
    "translated_title": "逐渐残余对齐：GAN反演和图像属性编辑的双流框架",
    "translated_abstract": "GAN基础的图像属性编辑首先利用GAN反演将真实图像投影到GAN的潜在空间，然后操作相应的潜在代码。最近的反演方法主要利用额外的高比特特征来提高图像细节的保留，因为低比特代码无法忠实重构源图像，导致细节丢失。然而，在编辑过程中，现有工作未能准确补充丢失的细节，并且在编辑性上存在问题。主要原因是它们一次性注入所有丢失的细节，这在本质上导致细节的位置和数量过度拟合源图像，导致编辑后的图像中存在不一致的内容和伪影。该工作认为应该以多阶段粗到细的方式逐渐将细节注入到重构和编辑过程中，以获得更好的细节保留和高编辑性。",
    "tldr": "本研究提出了逐步残余对齐的双流框架，通过多阶段粗到细的方式逐渐将细节注入到重构和编辑过程中，以提高细节保留和编辑性。",
    "en_tdlr": "This study introduces a dual-stream framework for gradual residuals alignment, advocating for a multi-stage coarse-to-fine approach to inject details gradually into both the reconstruction and editing process, aiming for better detail preservation and editability."
}