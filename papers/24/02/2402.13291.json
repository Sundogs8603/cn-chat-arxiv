{
    "title": "DeepCode AI Fix: Fixing Security Vulnerabilities with Large Language Models",
    "abstract": "arXiv:2402.13291v1 Announce Type: cross  Abstract: The automated program repair field has attracted substantial interest over the years, but despite significant research efforts, creating a system that works well for complex semantic bugs such as security vulnerabilities has proven difficult. A promising direction to solve this challenge is by leveraging large language models (LLMs), which are increasingly used to solve various programming tasks. In this paper, we investigate the effectiveness of LLMs for solving code-repair task. We show that the task is difficult as it requires the model to learn long-range code relationships, a task that inherently relies on extensive amounts of training data. At the same time, creating a large, clean dataset for complex program bugs and their corresponding fixes is non-trivial. We propose a technique to address these challenges with a new approach for querying and fine-tuning LLMs. The idea is to use program analysis to limit the LLM's attention me",
    "link": "https://arxiv.org/abs/2402.13291",
    "context": "Title: DeepCode AI Fix: Fixing Security Vulnerabilities with Large Language Models\nAbstract: arXiv:2402.13291v1 Announce Type: cross  Abstract: The automated program repair field has attracted substantial interest over the years, but despite significant research efforts, creating a system that works well for complex semantic bugs such as security vulnerabilities has proven difficult. A promising direction to solve this challenge is by leveraging large language models (LLMs), which are increasingly used to solve various programming tasks. In this paper, we investigate the effectiveness of LLMs for solving code-repair task. We show that the task is difficult as it requires the model to learn long-range code relationships, a task that inherently relies on extensive amounts of training data. At the same time, creating a large, clean dataset for complex program bugs and their corresponding fixes is non-trivial. We propose a technique to address these challenges with a new approach for querying and fine-tuning LLMs. The idea is to use program analysis to limit the LLM's attention me",
    "path": "papers/24/02/2402.13291.json",
    "total_tokens": 818,
    "translated_title": "DeepCode AI Fix: 使用大型语言模型修复安全漏洞",
    "translated_abstract": "自动程序修复领域能引起广泛关注，但尽管有大量研究工作，创建一个对于复杂语义错误（如安全漏洞）效果良好的系统仍然很困难。解决这一挑战的一个有前途的方向是利用越来越多地用于解决各种编程任务的大型语言模型（LLMs）。本文研究了LLMs在解决代码修复任务中的有效性。我们表明这个任务很困难，因为它要求模型学习长距离的代码关系，这是一个天然依赖大量训练数据的任务。同时，为复杂程序错误和其对应修复创建一个大型且干净的数据集并不是一个简单的事情。我们提出了一种方法来应对这些挑战，通过一种新的查询和微调LLMs的方法。这个想法是利用程序分析来限制LLMs的关注度。",
    "tldr": "使用大型语言模型修复复杂语义bug，通过新的查询和微调方法来解决长距离代码关系学习的挑战。",
    "en_tdlr": "Fixing complex semantic bugs with large language models using a novel query and fine-tuning approach to address the challenge of learning long-range code relationships."
}