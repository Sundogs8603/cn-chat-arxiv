{
    "title": "A Statistical Analysis of Wasserstein Autoencoders for Intrinsically Low-dimensional Data",
    "abstract": "arXiv:2402.15710v1 Announce Type: new  Abstract: Variational Autoencoders (VAEs) have gained significant popularity among researchers as a powerful tool for understanding unknown distributions based on limited samples. This popularity stems partly from their impressive performance and partly from their ability to provide meaningful feature representations in the latent space. Wasserstein Autoencoders (WAEs), a variant of VAEs, aim to not only improve model efficiency but also interpretability. However, there has been limited focus on analyzing their statistical guarantees. The matter is further complicated by the fact that the data distributions to which WAEs are applied - such as natural images - are often presumed to possess an underlying low-dimensional structure within a high-dimensional feature space, which current theory does not adequately account for, rendering known bounds inefficient. To bridge the gap between the theory and practice of WAEs, in this paper, we show that WAEs ",
    "link": "https://arxiv.org/abs/2402.15710",
    "context": "Title: A Statistical Analysis of Wasserstein Autoencoders for Intrinsically Low-dimensional Data\nAbstract: arXiv:2402.15710v1 Announce Type: new  Abstract: Variational Autoencoders (VAEs) have gained significant popularity among researchers as a powerful tool for understanding unknown distributions based on limited samples. This popularity stems partly from their impressive performance and partly from their ability to provide meaningful feature representations in the latent space. Wasserstein Autoencoders (WAEs), a variant of VAEs, aim to not only improve model efficiency but also interpretability. However, there has been limited focus on analyzing their statistical guarantees. The matter is further complicated by the fact that the data distributions to which WAEs are applied - such as natural images - are often presumed to possess an underlying low-dimensional structure within a high-dimensional feature space, which current theory does not adequately account for, rendering known bounds inefficient. To bridge the gap between the theory and practice of WAEs, in this paper, we show that WAEs ",
    "path": "papers/24/02/2402.15710.json",
    "total_tokens": 805,
    "translated_title": "对内在低维数据的Wasserstein自编码器的统计分析",
    "translated_abstract": "变分自编码器(Variational Autoencoders, VAEs)在研究人员中广受欢迎，被认为是理解基于有限样本的未知分布的强大工具。这种受欢迎程度部分源于其出色的性能，部分源于其能够在潜在空间中提供有意义的特征表示。Wasserstein自编码器(WAEs)是VAEs的一种变体，旨在不仅提高模型效率，而且提高可解释性。然而，对其统计保证的分析受到了限制。由于WAEs所应用的数据分布（例如自然图像）通常被认为在高维特征空间中具有低维结构，而当前的理论并未充分考虑这一点，导致已知的界限效率低下。为弥合WAEs理论与实践之间的差距，在本文中，我们展示了WAEs...",
    "tldr": "本文从统计分析的角度探讨了Wasserstein自编码器用于内在低维数据的特性与局限。",
    "en_tdlr": "This paper provides a statistical analysis on the characteristics and limitations of Wasserstein autoencoders for intrinsically low-dimensional data."
}