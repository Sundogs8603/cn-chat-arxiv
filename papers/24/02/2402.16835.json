{
    "title": "Eight Methods to Evaluate Robust Unlearning in LLMs",
    "abstract": "arXiv:2402.16835v1 Announce Type: new  Abstract: Machine unlearning can be useful for removing harmful capabilities and memorized text from large language models (LLMs), but there are not yet standardized methods for rigorously evaluating it. In this paper, we first survey techniques and limitations of existing unlearning evaluations. Second, we apply a comprehensive set of tests for the robustness and competitiveness of unlearning in the \"Who's Harry Potter\" (WHP) model from Eldan and Russinovich (2023). While WHP's unlearning generalizes well when evaluated with the \"Familiarity\" metric from Eldan and Russinovich, we find i) higher-than-baseline amounts of knowledge can reliably be extracted, ii) WHP performs on par with the original model on Harry Potter Q&A tasks, iii) it represents latent knowledge comparably to the original model, and iv) there is collateral unlearning in related domains. Overall, our results highlight the importance of comprehensive unlearning evaluation that av",
    "link": "https://arxiv.org/abs/2402.16835",
    "context": "Title: Eight Methods to Evaluate Robust Unlearning in LLMs\nAbstract: arXiv:2402.16835v1 Announce Type: new  Abstract: Machine unlearning can be useful for removing harmful capabilities and memorized text from large language models (LLMs), but there are not yet standardized methods for rigorously evaluating it. In this paper, we first survey techniques and limitations of existing unlearning evaluations. Second, we apply a comprehensive set of tests for the robustness and competitiveness of unlearning in the \"Who's Harry Potter\" (WHP) model from Eldan and Russinovich (2023). While WHP's unlearning generalizes well when evaluated with the \"Familiarity\" metric from Eldan and Russinovich, we find i) higher-than-baseline amounts of knowledge can reliably be extracted, ii) WHP performs on par with the original model on Harry Potter Q&A tasks, iii) it represents latent knowledge comparably to the original model, and iv) there is collateral unlearning in related domains. Overall, our results highlight the importance of comprehensive unlearning evaluation that av",
    "path": "papers/24/02/2402.16835.json",
    "total_tokens": 950,
    "translated_title": "评估LLMs中强大遗忘的八种方法",
    "translated_abstract": "arXiv:2402.16835v1 类型公告：新摘要：机器遗忘可用于从大型语言模型（LLMs）中删除有害能力和记忆文本，但目前尚无标准化方法严格评估它。本文首先调查现有遗忘评估的技术和局限性。其次，我们对Eldan和Russinovich（2023年）的“谁是哈利波特”（WHP）模型的遗忘的稳健性和竞争力应用了广泛的测试集。虽然使用Eldan和Russinovich的“熟悉度”指标评估WHP的遗忘具有很好的泛化能力，但我们发现：i）可以可靠地提取高于基准线的知识量，ii）在哈利波特问答任务上，WHP的表现与原始模型相当，iii）它以与原始模型相当的方式代表潜在知识，iv）在相关领域存在旁路遗忘。总体而言，我们的结果突出了全面评估遗忘的重要性。",
    "tldr": "本文调查了现有遗忘评估方法的技术和局限性，并在\"Who's Harry Potter\" (WHP)模型上应用了一系列测试，发现WHP的遗忘表现具有泛化能力、与原始模型相当，并在相关领域存在旁路遗忘。"
}