{
    "title": "GenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstruction",
    "abstract": "arXiv:2402.16174v1 Announce Type: cross  Abstract: While recent advances in neural radiance field enable realistic digitization for large-scale scenes, the image-capturing process is still time-consuming and labor-intensive. Previous works attempt to automate this process using the Next-Best-View (NBV) policy for active 3D reconstruction. However, the existing NBV policies heavily rely on hand-crafted criteria, limited action space, or per-scene optimized representations. These constraints limit their cross-dataset generalizability. To overcome them, we propose GenNBV, an end-to-end generalizable NBV policy. Our policy adopts a reinforcement learning (RL)-based framework and extends typical limited action space to 5D free space. It empowers our agent drone to scan from any viewpoint, and even interact with unseen geometries during training. To boost the cross-dataset generalizability, we also propose a novel multi-source state embedding, including geometric, semantic, and action repres",
    "link": "https://arxiv.org/abs/2402.16174",
    "context": "Title: GenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstruction\nAbstract: arXiv:2402.16174v1 Announce Type: cross  Abstract: While recent advances in neural radiance field enable realistic digitization for large-scale scenes, the image-capturing process is still time-consuming and labor-intensive. Previous works attempt to automate this process using the Next-Best-View (NBV) policy for active 3D reconstruction. However, the existing NBV policies heavily rely on hand-crafted criteria, limited action space, or per-scene optimized representations. These constraints limit their cross-dataset generalizability. To overcome them, we propose GenNBV, an end-to-end generalizable NBV policy. Our policy adopts a reinforcement learning (RL)-based framework and extends typical limited action space to 5D free space. It empowers our agent drone to scan from any viewpoint, and even interact with unseen geometries during training. To boost the cross-dataset generalizability, we also propose a novel multi-source state embedding, including geometric, semantic, and action repres",
    "path": "papers/24/02/2402.16174.json",
    "total_tokens": 1025,
    "translated_title": "GenNBV: 通用的主动式三维重建下一最佳视角策略",
    "translated_abstract": "最近的神经辐射场的技术进步实现了大规模场景的真实数字化, 但是图像捕获过程仍然耗时且劳动密集。先前的研究尝试使用主动式三维重建的下一最佳视角（NBV）策略来自动化这一过程。然而，现有的NBV策略严重依赖手工设计的标准、有限的动作空间，或者是针对每个场景优化的表示。这些约束限制了它们在跨数据集中的泛化能力。为了克服这些问题，我们提出了GenNBV，一个端到端通用的NBV策略。我们的策略采用基于强化学习（RL）的框架，将典型有限的动作空间扩展到5D自由空间。它赋予了我们的代理机无人机在训练过程中可以从任何视角进行扫描，甚至可以与未见几何体进行交互。为了增强跨数据集的泛化能力，我们还提出了一种新颖的多源状态嵌入，包括几何、语义和动作表示。",
    "tldr": "GenNBV提出了一种端到端的通用的下一最佳视角策略，通过采用强化学习框架和扩展到5D自由空间的动作空间，实现了无人机从任意视角进行扫描，甚至与未知几何体进行交互的能力，同时提出了多源状态嵌入以增强跨数据集的泛化能力。",
    "en_tdlr": "GenNBV proposes an end-to-end generalizable next-best-view policy that enables a drone agent to scan from any viewpoint and even interact with unseen geometries, by adopting a reinforcement learning framework and extending the action space to 5D free space, while also introducing a multi-source state embedding to boost cross-dataset generalizability."
}