{
    "title": "Low-Resource Cross-Domain Singing Voice Synthesis via Reduced Self-Supervised Speech Representations",
    "abstract": "In this paper, we propose a singing voice synthesis model, Karaoker-SSL, that is trained only on text and speech data as a typical multi-speaker acoustic model. It is a low-resource pipeline that does not utilize any singing data end-to-end, since its vocoder is also trained on speech data. Karaoker-SSL is conditioned by self-supervised speech representations in an unsupervised manner. We preprocess these representations by selecting only a subset of their task-correlated dimensions. The conditioning module is indirectly guided to capture style information during training by multi-tasking. This is achieved with a Conformer-based module, which predicts the pitch from the acoustic model's output. Thus, Karaoker-SSL allows singing voice synthesis without reliance on hand-crafted and domain-specific features. There are also no requirements for text alignments or lyrics timestamps. To refine the voice quality, we employ a U-Net discriminator that is conditioned on the target speaker and fol",
    "link": "https://rss.arxiv.org/abs/2402.01520",
    "context": "Title: Low-Resource Cross-Domain Singing Voice Synthesis via Reduced Self-Supervised Speech Representations\nAbstract: In this paper, we propose a singing voice synthesis model, Karaoker-SSL, that is trained only on text and speech data as a typical multi-speaker acoustic model. It is a low-resource pipeline that does not utilize any singing data end-to-end, since its vocoder is also trained on speech data. Karaoker-SSL is conditioned by self-supervised speech representations in an unsupervised manner. We preprocess these representations by selecting only a subset of their task-correlated dimensions. The conditioning module is indirectly guided to capture style information during training by multi-tasking. This is achieved with a Conformer-based module, which predicts the pitch from the acoustic model's output. Thus, Karaoker-SSL allows singing voice synthesis without reliance on hand-crafted and domain-specific features. There are also no requirements for text alignments or lyrics timestamps. To refine the voice quality, we employ a U-Net discriminator that is conditioned on the target speaker and fol",
    "path": "papers/24/02/2402.01520.json",
    "total_tokens": 888,
    "translated_title": "通过减少自监督语音表示来实现低资源跨领域歌声合成",
    "translated_abstract": "本文提出了一种名为Karaoker-SSL的歌声合成模型，它只通过文本和语音数据进行训练，作为一个典型的多人语音模型。这是一个低资源的流程，不需要端到端地使用任何歌唱数据，因为其声码器也是在语音数据上进行训练的。Karaoker-SSL以无监督的方式通过自监督语音表示进行条件化。我们通过选择与任务相关的维度的子集来预处理这些表示。在训练过程中，条件模块间接地通过多任务设置来指导捕捉风格信息。这是通过一个基于Conformer的模块实现的，该模块从声学模型的输出中预测音高。因此，Karaoker-SSL允许进行歌声合成，而无需依赖手工制作的领域特定特征。也不需要文本对齐或歌词时间戳。为了改善声音质量，我们采用了一个以目标说话者为条件的U-Net鉴别器。",
    "tldr": "提出了一种低资源跨领域歌声合成模型Karaoker-SSL，通过减少自监督语音表示和引入Conformer模块来实现无需使用歌唱数据和手工特征的合成过程。"
}