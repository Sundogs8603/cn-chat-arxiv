{
    "title": "Comparing Template-based and Template-free Language Model Probing",
    "abstract": "The differences between cloze-task language model (LM) probing with 1) expert-made templates and 2) naturally-occurring text have often been overlooked. Here, we evaluate 16 different LMs on 10 probing English datasets -- 4 template-based and 6 template-free -- in general and biomedical domains to answer the following research questions: (RQ1) Do model rankings differ between the two approaches? (RQ2) Do models' absolute scores differ between the two approaches? (RQ3) Do the answers to RQ1 and RQ2 differ between general and domain-specific models? Our findings are: 1) Template-free and template-based approaches often rank models differently, except for the top domain-specific models. 2) Scores decrease by up to 42% Acc@1 when comparing parallel template-free and template-based prompts. 3) Perplexity is negatively correlated with accuracy in the template-free approach, but, counter-intuitively, they are positively correlated for template-based probing. 4) Models tend to predict the same",
    "link": "https://arxiv.org/abs/2402.00123",
    "context": "Title: Comparing Template-based and Template-free Language Model Probing\nAbstract: The differences between cloze-task language model (LM) probing with 1) expert-made templates and 2) naturally-occurring text have often been overlooked. Here, we evaluate 16 different LMs on 10 probing English datasets -- 4 template-based and 6 template-free -- in general and biomedical domains to answer the following research questions: (RQ1) Do model rankings differ between the two approaches? (RQ2) Do models' absolute scores differ between the two approaches? (RQ3) Do the answers to RQ1 and RQ2 differ between general and domain-specific models? Our findings are: 1) Template-free and template-based approaches often rank models differently, except for the top domain-specific models. 2) Scores decrease by up to 42% Acc@1 when comparing parallel template-free and template-based prompts. 3) Perplexity is negatively correlated with accuracy in the template-free approach, but, counter-intuitively, they are positively correlated for template-based probing. 4) Models tend to predict the same",
    "path": "papers/24/02/2402.00123.json",
    "total_tokens": 902,
    "translated_title": "比较基于模板和非模板语言模型的探测方法",
    "translated_abstract": "以专家制作的模板和自然发生的文本为基础的语言模型探测方法的差异经常被忽视。在这里，我们评估了16种不同的语言模型在10个英文探测数据集上的性能，其中包括4个基于模板的和6个非模板的数据集，并针对以下研究问题进行了回答：（RQ1）模型排名在两种方法中是否不同？（RQ2）模型的绝对得分在两种方法中是否不同？（RQ3）RQ1和RQ2的答案在一般和领域特定模型之间是否不同？我们的发现是：1）除了顶级的领域特定模型外，基于模板和非模板方法通常排名不同。2）与平行的非模板和模板提示相比，准确度下降了最多42%。3）在非模板方法中，困惑度与准确度呈负相关，但是在基于模板的探测中，它们呈正相关，这与直觉相反。4）模型倾向于预测相同的内容。",
    "tldr": "本文比较了基于模板和非模板语言模型的探测方法，发现它们在模型排名、绝对得分和与困惑度的关系等方面存在差异。",
    "en_tdlr": "This paper compares template-based and template-free language model probing methods and finds differences in model rankings, absolute scores, and the relationship with perplexity."
}