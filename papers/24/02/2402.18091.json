{
    "title": "Polos: Multimodal Metric Learning from Human Feedback for Image Captioning",
    "abstract": "arXiv:2402.18091v1 Announce Type: cross  Abstract: Establishing an automatic evaluation metric that closely aligns with human judgments is essential for effectively developing image captioning models. Recent data-driven metrics have demonstrated a stronger correlation with human judgments than classic metrics such as CIDEr; however they lack sufficient capabilities to handle hallucinations and generalize across diverse images and texts partially because they compute scalar similarities merely using embeddings learned from tasks unrelated to image captioning evaluation. In this study, we propose Polos, a supervised automatic evaluation metric for image captioning models. Polos computes scores from multimodal inputs, using a parallel feature extraction mechanism that leverages embeddings trained through large-scale contrastive learning. To train Polos, we introduce Multimodal Metric Learning from Human Feedback (M$^2$LHF), a framework for developing metrics based on human feedback. We co",
    "link": "https://arxiv.org/abs/2402.18091",
    "context": "Title: Polos: Multimodal Metric Learning from Human Feedback for Image Captioning\nAbstract: arXiv:2402.18091v1 Announce Type: cross  Abstract: Establishing an automatic evaluation metric that closely aligns with human judgments is essential for effectively developing image captioning models. Recent data-driven metrics have demonstrated a stronger correlation with human judgments than classic metrics such as CIDEr; however they lack sufficient capabilities to handle hallucinations and generalize across diverse images and texts partially because they compute scalar similarities merely using embeddings learned from tasks unrelated to image captioning evaluation. In this study, we propose Polos, a supervised automatic evaluation metric for image captioning models. Polos computes scores from multimodal inputs, using a parallel feature extraction mechanism that leverages embeddings trained through large-scale contrastive learning. To train Polos, we introduce Multimodal Metric Learning from Human Feedback (M$^2$LHF), a framework for developing metrics based on human feedback. We co",
    "path": "papers/24/02/2402.18091.json",
    "total_tokens": 834,
    "translated_title": "Polos：从人类反馈学习的多模式度量用于图像字幕生成",
    "translated_abstract": "建立一个与人类判断紧密对齐的自动评估指标对于有效开发图像字幕生成模型至关重要。最近的数据驱动指标表现出比传统指标如CIDEr更强的与人类判断相关性；然而，它们缺乏足够的能力来处理幻觉，并且跨各种图像和文本泛化部分是因为它们仅仅使用从与图像字幕生成评估无关的任务学习的嵌入计算标量相似性。在这项研究中，我们提出了Polos，一种用于图像字幕生成模型的监督自动评估指标。Polos从多模式输入中计算得分，使用一个并行特征提取机制，利用通过大规模对比学习训练的嵌入。为了训练Polos，我们引入了基于人类反馈的多模态度量学习（M$^2$LHF）框架，用于开发度量方法。",
    "tldr": "提出了一种使用多模态输入和基于人类反馈的框架训练的自动评估指标Polos，旨在有效开发图像字幕生成模型。",
    "en_tdlr": "Introduced Polos, an automatic evaluation metric trained using multimodal inputs and a framework based on human feedback, aiming to effectively develop image captioning models."
}