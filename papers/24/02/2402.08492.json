{
    "title": "The Application of ChatGPT in Responding to Questions Related to the Boston Bowel Preparation Scale",
    "abstract": "Background: Colonoscopy, a crucial diagnostic tool in gastroenterology, depends heavily on superior bowel preparation. ChatGPT, a large language model with emergent intelligence which also exhibits potential in medical applications. This study aims to assess the accuracy and consistency of ChatGPT in using the Boston Bowel Preparation Scale (BBPS) for colonoscopy assessment. Methods: We retrospectively collected 233 colonoscopy images from 2020 to 2023. These images were evaluated using the BBPS by 3 senior endoscopists and 3 novice endoscopists. Additionally, ChatGPT also assessed these images, having been divided into three groups and undergone specific Fine-tuning. Consistency was evaluated through two rounds of testing. Results: In the initial round, ChatGPT's accuracy varied between 48.93% and 62.66%, trailing the endoscopists' accuracy of 76.68% to 77.83%. Kappa values for ChatGPT was between 0.52 and 0.53, compared to 0.75 to 0.87 for the endoscopists. Conclusion: While ChatGPT ",
    "link": "https://arxiv.org/abs/2402.08492",
    "context": "Title: The Application of ChatGPT in Responding to Questions Related to the Boston Bowel Preparation Scale\nAbstract: Background: Colonoscopy, a crucial diagnostic tool in gastroenterology, depends heavily on superior bowel preparation. ChatGPT, a large language model with emergent intelligence which also exhibits potential in medical applications. This study aims to assess the accuracy and consistency of ChatGPT in using the Boston Bowel Preparation Scale (BBPS) for colonoscopy assessment. Methods: We retrospectively collected 233 colonoscopy images from 2020 to 2023. These images were evaluated using the BBPS by 3 senior endoscopists and 3 novice endoscopists. Additionally, ChatGPT also assessed these images, having been divided into three groups and undergone specific Fine-tuning. Consistency was evaluated through two rounds of testing. Results: In the initial round, ChatGPT's accuracy varied between 48.93% and 62.66%, trailing the endoscopists' accuracy of 76.68% to 77.83%. Kappa values for ChatGPT was between 0.52 and 0.53, compared to 0.75 to 0.87 for the endoscopists. Conclusion: While ChatGPT ",
    "path": "papers/24/02/2402.08492.json",
    "total_tokens": 1061,
    "translated_title": "ChatGPT在回答与波士顿肠准备评分相关问题时的应用",
    "translated_abstract": "背景：结肠镜检查是胃肠学中的关键诊断工具，严重依赖良好的肠准备。ChatGPT是一个具有新兴智能的大型语言模型，也在医学应用中显示出潜力。本研究旨在评估ChatGPT在使用波士顿肠准备评分（BBPS）进行结肠镜评估时的准确性和一致性。方法：我们回顾性收集了2020年至2023年间的233个结肠镜图像，这些图像由3名资深内镜医生和3名初级内镜医生使用BBPS进行评估。此外，ChatGPT也对这些图像进行了评估，分为三组并进行了特定的微调。通过两轮测试评估一致性。结果：在初始轮中，ChatGPT的准确率在48.93%和62.66%之间变化，低于内镜医生的准确率（76.68%到77.83%）。ChatGPT的Kappa值为0.52到0.53，而内镜医生的Kappa值为0.75到0.87。结论：尽管ChatGPT在使用BBPS进行结肠镜评估时的准确性和一致性相对较低，但它仍具有潜力成为辅助工具。",
    "tldr": "本研究评估了ChatGPT在使用波士顿肠准备评分（BBPS）进行结肠镜评估时的准确性和一致性，发现其准确率较内镜医生低，但仍有成为辅助工具的潜力。",
    "en_tdlr": "This study assessed the accuracy and consistency of ChatGPT in using the Boston Bowel Preparation Scale (BBPS) for colonoscopy assessment. It found that ChatGPT had lower accuracy compared to endoscopists, but still had potential as an auxiliary tool."
}