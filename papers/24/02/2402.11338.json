{
    "title": "Fair Classification with Partial Feedback: An Exploration-Based Data-Collection Approach",
    "abstract": "arXiv:2402.11338v1 Announce Type: cross  Abstract: In many predictive contexts (e.g., credit lending), true outcomes are only observed for samples that were positively classified in the past. These past observations, in turn, form training datasets for classifiers that make future predictions. However, such training datasets lack information about the outcomes of samples that were (incorrectly) negatively classified in the past and can lead to erroneous classifiers. We present an approach that trains a classifier using available data and comes with a family of exploration strategies to collect outcome data about subpopulations that otherwise would have been ignored. For any exploration strategy, the approach comes with guarantees that (1) all sub-populations are explored, (2) the fraction of false positives is bounded, and (3) the trained classifier converges to a \"desired\" classifier. The right exploration strategy is context-dependent; it can be chosen to improve learning guarantees ",
    "link": "https://arxiv.org/abs/2402.11338",
    "context": "Title: Fair Classification with Partial Feedback: An Exploration-Based Data-Collection Approach\nAbstract: arXiv:2402.11338v1 Announce Type: cross  Abstract: In many predictive contexts (e.g., credit lending), true outcomes are only observed for samples that were positively classified in the past. These past observations, in turn, form training datasets for classifiers that make future predictions. However, such training datasets lack information about the outcomes of samples that were (incorrectly) negatively classified in the past and can lead to erroneous classifiers. We present an approach that trains a classifier using available data and comes with a family of exploration strategies to collect outcome data about subpopulations that otherwise would have been ignored. For any exploration strategy, the approach comes with guarantees that (1) all sub-populations are explored, (2) the fraction of false positives is bounded, and (3) the trained classifier converges to a \"desired\" classifier. The right exploration strategy is context-dependent; it can be chosen to improve learning guarantees ",
    "path": "papers/24/02/2402.11338.json",
    "total_tokens": 880,
    "translated_title": "具有部分反馈的公平分类：一种基于探索的数据收集方法",
    "translated_abstract": "在许多预测场景（例如信贷放款）中，只有过去被积极分类的样本才会观察到真实结果。这些过去的观察结果形成了用于训练分类器以进行未来预测的训练数据集。然而，这样的训练数据集缺乏关于过去（错误地）被负面分类的样本结果的信息，可能导致错误的分类器。我们提出了一种方法，利用可用数据训练分类器，并提供一系列探索策略来收集关于否则会被忽略的子群体的结果数据。对于任何探索策略，该方法都具有以下保证：（1）所有子群体都得到了探索，（2）假阳性的比例受到了限制，（3）训练的分类器收敛到一个“期望”的分类器。正确的探索策略取决于上下文；它可以选择以改善学习保证",
    "tldr": "该方法提出了一种基于探索的数据收集方法，能够在缺乏部分反馈信息的情况下训练分类器，并提供了一系列策略来确保所有子群体都被探索、防止错误分类、以及收敛到期望的分类器。"
}