{
    "title": "Infusing Hierarchical Guidance into Prompt Tuning: A Parameter-Efficient Framework for Multi-level Implicit Discourse Relation Recognition",
    "abstract": "arXiv:2402.15080v1 Announce Type: new  Abstract: Multi-level implicit discourse relation recognition (MIDRR) aims at identifying hierarchical discourse relations among arguments. Previous methods achieve the promotion through fine-tuning PLMs. However, due to the data scarcity and the task gap, the pre-trained feature space cannot be accurately tuned to the task-specific space, which even aggravates the collapse of the vanilla space. Besides, the comprehension of hierarchical semantics for MIDRR makes the conversion much harder. In this paper, we propose a prompt-based Parameter-Efficient Multi-level IDRR (PEMI) framework to solve the above problems. First, we leverage parameter-efficient prompt tuning to drive the inputted arguments to match the pre-trained space and realize the approximation with few parameters. Furthermore, we propose a hierarchical label refining (HLR) method for the prompt verbalizer to deeply integrate hierarchical guidance into the prompt tuning. Finally, our mo",
    "link": "https://arxiv.org/abs/2402.15080",
    "context": "Title: Infusing Hierarchical Guidance into Prompt Tuning: A Parameter-Efficient Framework for Multi-level Implicit Discourse Relation Recognition\nAbstract: arXiv:2402.15080v1 Announce Type: new  Abstract: Multi-level implicit discourse relation recognition (MIDRR) aims at identifying hierarchical discourse relations among arguments. Previous methods achieve the promotion through fine-tuning PLMs. However, due to the data scarcity and the task gap, the pre-trained feature space cannot be accurately tuned to the task-specific space, which even aggravates the collapse of the vanilla space. Besides, the comprehension of hierarchical semantics for MIDRR makes the conversion much harder. In this paper, we propose a prompt-based Parameter-Efficient Multi-level IDRR (PEMI) framework to solve the above problems. First, we leverage parameter-efficient prompt tuning to drive the inputted arguments to match the pre-trained space and realize the approximation with few parameters. Furthermore, we propose a hierarchical label refining (HLR) method for the prompt verbalizer to deeply integrate hierarchical guidance into the prompt tuning. Finally, our mo",
    "path": "papers/24/02/2402.15080.json",
    "total_tokens": 855,
    "translated_title": "将层级指导融入提示调整：一种用于多层次隐式话语关系识别的参数高效框架",
    "translated_abstract": "多层次隐式话语关系识别(MIDRR)旨在识别论点之间的层次话语关系。先前的方法通过微调PLM来实现推广。然而，由于数据稀缺和任务差距，预训练特征空间无法准确调整到特定任务空间，甚至加剧了基础空间的崩溃。此外，对于MIDRR的层次语义理解使得转换更加困难。在本文中，我们提出了一种基于提示的参数高效多层次IDRR（PEMI）框架来解决以上问题。首先，我们利用参数高效的提示调整将输入的论点驱动到匹配预训练空间并利用少量参数实现近似。此外，我们提出了一种层级标签细化（HLR）方法，用于让提示表达器深度整合层级指导到提示调整中。",
    "tldr": "提出了一种基于提示调整的参数高效框架，通过层级标签细化方法深度整合层级指导，用于解决多层次隐式话语关系识别中的问题",
    "en_tdlr": "Proposed a parameter-efficient framework based on prompt tuning, integrating hierarchical guidance deeply through a hierarchical label refining method to address issues in multi-level implicit discourse relation recognition."
}