{
    "title": "Foundation Model Makes Clustering a Better Initialization for Active Learning",
    "abstract": "Active learning selects the most informative samples from the unlabeled dataset to annotate in the context of a limited annotation budget. While numerous methods have been proposed for subsequent sample selection based on an initialized model, scant attention has been paid to the indispensable phase of active learning: selecting samples for model initialization. Most of the previous studies resort to random sampling or naive clustering. However, random sampling is prone to fluctuation, and naive clustering suffers from convergence speed, particularly when dealing with high-dimensional data such as imaging data. In this work, we propose to integrate foundation models with clustering methods to select samples for active learning initialization. Foundation models refer to those trained on massive datasets by the self-supervised paradigm and capable of generating informative and compacted embeddings for various downstream tasks. Leveraging these embeddings to replace raw features such as p",
    "link": "https://arxiv.org/abs/2402.02561",
    "context": "Title: Foundation Model Makes Clustering a Better Initialization for Active Learning\nAbstract: Active learning selects the most informative samples from the unlabeled dataset to annotate in the context of a limited annotation budget. While numerous methods have been proposed for subsequent sample selection based on an initialized model, scant attention has been paid to the indispensable phase of active learning: selecting samples for model initialization. Most of the previous studies resort to random sampling or naive clustering. However, random sampling is prone to fluctuation, and naive clustering suffers from convergence speed, particularly when dealing with high-dimensional data such as imaging data. In this work, we propose to integrate foundation models with clustering methods to select samples for active learning initialization. Foundation models refer to those trained on massive datasets by the self-supervised paradigm and capable of generating informative and compacted embeddings for various downstream tasks. Leveraging these embeddings to replace raw features such as p",
    "path": "papers/24/02/2402.02561.json",
    "total_tokens": 851,
    "translated_title": "基于基础模型的聚类优化主动学习初始化方法",
    "translated_abstract": "主动学习是从未标记的数据集中选择最具信息量的样本进行标注，以满足有限的标注预算。尽管已经有许多方法针对初始化模型后的样本选择进行了研究，但对于主动学习必不可少的初始化阶段，却没有引起足够的关注。先前的研究中大多数都采用随机抽样或者简单的聚类方法。然而，随机抽样容易产生波动，而简单聚类在处理高维数据（如图像数据）时收敛速度慢。在本研究中，我们提出将基础模型与聚类方法结合，用于选择主动学习初始化阶段的样本。基础模型是指在自监督范式下在大规模数据集上训练的模型，能够生成信息丰富且紧凑的嵌入表示，用于各种下游任务。",
    "tldr": "本研究提出了一种基于基础模型和聚类方法的主动学习初始化方案，用于选择最具信息量的样本。基础模型是通过自监督训练在大规模数据集上训练得到的，并能生成适用于各种下游任务的紧凑嵌入表示。",
    "en_tdlr": "This study proposes a method for active learning initialization based on foundation models and clustering, which selects the most informative samples. Foundation models are trained on massive datasets using self-supervised learning and generate compact embeddings suitable for various downstream tasks."
}