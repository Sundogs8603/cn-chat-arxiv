{
    "title": "Regulation Games for Trustworthy Machine Learning",
    "abstract": "Existing work on trustworthy machine learning (ML) often concentrates on individual aspects of trust, such as fairness or privacy. Additionally, many techniques overlook the distinction between those who train ML models and those responsible for assessing their trustworthiness. To address these issues, we propose a framework that views trustworthy ML as a multi-objective multi-agent optimization problem. This naturally lends itself to a game-theoretic formulation we call regulation games. We illustrate a particular game instance, the SpecGame in which we model the relationship between an ML model builder and fairness and privacy regulators. Regulators wish to design penalties that enforce compliance with their specification, but do not want to discourage builders from participation. Seeking such socially optimal (i.e., efficient for all agents) solutions to the game, we introduce ParetoPlay. This novel equilibrium search algorithm ensures that agents remain on the Pareto frontier of th",
    "link": "https://arxiv.org/abs/2402.03540",
    "context": "Title: Regulation Games for Trustworthy Machine Learning\nAbstract: Existing work on trustworthy machine learning (ML) often concentrates on individual aspects of trust, such as fairness or privacy. Additionally, many techniques overlook the distinction between those who train ML models and those responsible for assessing their trustworthiness. To address these issues, we propose a framework that views trustworthy ML as a multi-objective multi-agent optimization problem. This naturally lends itself to a game-theoretic formulation we call regulation games. We illustrate a particular game instance, the SpecGame in which we model the relationship between an ML model builder and fairness and privacy regulators. Regulators wish to design penalties that enforce compliance with their specification, but do not want to discourage builders from participation. Seeking such socially optimal (i.e., efficient for all agents) solutions to the game, we introduce ParetoPlay. This novel equilibrium search algorithm ensures that agents remain on the Pareto frontier of th",
    "path": "papers/24/02/2402.03540.json",
    "total_tokens": 886,
    "translated_title": "《可信机器学习的调节游戏》",
    "translated_abstract": "现有的关于可信机器学习的研究往往集中在信任的个别方面，如公平性或隐私。此外，许多技术忽视了训练机器学习模型的人和负责评估其可信度的人之间的区别。为了解决这些问题，我们提出了一个框架，将可信机器学习视为多目标多主体优化问题。这自然地导致了一个称为调节游戏的博弈论形式。我们介绍了一个特定的游戏实例——SpecGame，其中我们建模了机器学习模型构建者与公平性和隐私监管者之间的关系。监管者希望设计处罚措施来强制执行他们的规范，但不希望阻止构建者的参与。为了寻找这种社会最优（即对所有代理方都有效）的游戏解决方案，我们引入了ParetoPlay。这种新型均衡搜索算法确保代理方始终保持在Pareto前沿上。",
    "tldr": "本论文提出了一个以调节游戏为基础的框架，将可信机器学习视为多目标多主体优化问题。通过引入ParetoPlay算法，寻找社会最优的游戏解决方案，该算法能够确保代理方始终保持在Pareto前沿上。"
}