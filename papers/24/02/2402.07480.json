{
    "title": "Topological Safeguard for Evasion Attack based on the Interpretability of Artificial Neural Network Behavior",
    "abstract": "In the last years, Deep Learning technology has been proposed in different fields, bringing many advances in each of them, but identifying new threats in these solutions regarding cybersecurity. Those implemented models have brought several vulnerabilities associated with Deep Learning technology. Moreover, those allow taking advantage of the implemented model, obtaining private information, and even modifying the model's decision-making. Therefore, interest in studying those vulnerabilities/attacks and designing defenses to avoid or fight them is gaining prominence among researchers. In particular, the widely known evasion attack is being analyzed by researchers; thus, several defenses to avoid such a threat can be found in the literature. Since the presentation of the L-BFG algorithm, this threat concerns the research community. However, it continues developing new and ingenious countermeasures since there is no perfect defense for all the known evasion algorithms. In this work, a no",
    "link": "https://arxiv.org/abs/2402.07480",
    "context": "Title: Topological Safeguard for Evasion Attack based on the Interpretability of Artificial Neural Network Behavior\nAbstract: In the last years, Deep Learning technology has been proposed in different fields, bringing many advances in each of them, but identifying new threats in these solutions regarding cybersecurity. Those implemented models have brought several vulnerabilities associated with Deep Learning technology. Moreover, those allow taking advantage of the implemented model, obtaining private information, and even modifying the model's decision-making. Therefore, interest in studying those vulnerabilities/attacks and designing defenses to avoid or fight them is gaining prominence among researchers. In particular, the widely known evasion attack is being analyzed by researchers; thus, several defenses to avoid such a threat can be found in the literature. Since the presentation of the L-BFG algorithm, this threat concerns the research community. However, it continues developing new and ingenious countermeasures since there is no perfect defense for all the known evasion algorithms. In this work, a no",
    "path": "papers/24/02/2402.07480.json",
    "total_tokens": 985,
    "translated_title": "基于人工神经网络行为可解释性的逃避攻击的拓扑保护",
    "translated_abstract": "在过去几年中，深度学习技术已经在不同领域提出，为每个领域带来了许多进展，但这也带来了关于网络安全方面的新威胁。这些实施的模型带来了与深度学习技术相关的几种漏洞。此外，它们允许利用这些模型，获得私人信息，甚至修改模型的决策。因此，对这些漏洞/攻击进行研究并设计防御措施以避免或对抗它们的兴趣在研究中日益突出。特别是，著名的逃避攻击正在被研究人员分析，因此在文献中可以找到几种避免此威胁的防御措施。自L-BFG算法提出以来，这种威胁一直关注研究界。然而，由于没有适用于所有已知逃避算法的完美防御，因此仍在不断开发新的巧妙对策。",
    "tldr": "本文提出了一种基于人工神经网络行为解释性的拓扑保护方法，用于对抗逃避攻击。在过去几年中，深度学习技术的应用日益广泛，但也带来了新的网络安全威胁。逃避攻击是其中一种常见攻击，本文旨在设计一种能够对抗该攻击的有效防御方法。",
    "en_tdlr": "This paper proposes a topological safeguard method based on the interpretability of artificial neural network behavior to counter evasion attacks. In recent years, Deep Learning technology has been widely applied but also introduced new cybersecurity threats. Evasion attacks are a common type of attack, and this paper aims to design an effective defense method against such attacks."
}