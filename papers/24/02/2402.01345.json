{
    "title": "Skip $\\textbackslash n$: A simple method to reduce hallucination in Large Vision-Language Models",
    "abstract": "Recent advancements in large vision-language models (LVLMs) have demonstrated impressive capability in visual information understanding with human language. Despite these advances, LVLMs still face challenges with multimodal hallucination, such as generating text descriptions of objects that are not present in the visual information. However, the underlying fundamental reasons of multimodal hallucinations remain poorly explored. In this paper, we propose a new perspective, suggesting that the inherent biases in LVLMs might be a key factor in hallucinations. Specifically, we systematically identify a semantic shift bias related to paragraph breaks ('$\\textbackslash n\\textbackslash n$'), where the content before and after '$\\textbackslash n\\textbackslash n$' in the training data frequently exhibit significant semantic changes. This pattern leads the model to infer that the contents following '$\\textbackslash n\\textbackslash n$' should be obviously different from the preceding contents wi",
    "link": "https://rss.arxiv.org/abs/2402.01345",
    "context": "Title: Skip $\\textbackslash n$: A simple method to reduce hallucination in Large Vision-Language Models\nAbstract: Recent advancements in large vision-language models (LVLMs) have demonstrated impressive capability in visual information understanding with human language. Despite these advances, LVLMs still face challenges with multimodal hallucination, such as generating text descriptions of objects that are not present in the visual information. However, the underlying fundamental reasons of multimodal hallucinations remain poorly explored. In this paper, we propose a new perspective, suggesting that the inherent biases in LVLMs might be a key factor in hallucinations. Specifically, we systematically identify a semantic shift bias related to paragraph breaks ('$\\textbackslash n\\textbackslash n$'), where the content before and after '$\\textbackslash n\\textbackslash n$' in the training data frequently exhibit significant semantic changes. This pattern leads the model to infer that the contents following '$\\textbackslash n\\textbackslash n$' should be obviously different from the preceding contents wi",
    "path": "papers/24/02/2402.01345.json",
    "total_tokens": 942,
    "translated_title": "跳过$\\textbackslash n$: 一种简单的方法减少大规模视觉-语言模型中的幻觉",
    "translated_abstract": "最近大规模视觉-语言模型（LVLMs）的进展展示了其在视觉信息理解与人类语言方面的令人印象深刻的能力。尽管取得了这些进展，LVLMs仍然面临多模态幻觉的挑战，例如生成与视觉信息中不存在的对象相关的文本描述。然而，多模态幻觉的根本原因仍然未被充分探索。在本文中，我们提出了一个新的视角，认为LVLMs中固有的偏见可能是幻觉的关键因素。具体而言，我们系统地确定了与段落分割符（'$\\textbackslash n\\textbackslash n$'）相关的语义漂移偏差，即在训练数据中，在“$\\textbackslash n\\textbackslash n$”之前和之后的内容经常表现出显著的语义改变。这种模式使得模型推断在“$\\textbackslash n\\textbackslash n$”之后的内容应明显不同于前面的内容。",
    "tldr": "本文提出了一种新的视角，指出LVLMs中固有的偏见可能是多模态幻觉的关键因素。通过系统识别与段落分割符相关的语义漂移偏差，我们发现模型在训练数据中经常遇到明显的内容语义变化，导致幻觉的产生。",
    "en_tdlr": "This paper proposes a new perspective that inherent biases in LVLMs might be a key factor in multimodal hallucinations. By systematically identifying a semantic shift bias related to paragraph breaks, the study reveals that the model often encounters significant semantic changes in the content, leading to the generation of hallucinations."
}