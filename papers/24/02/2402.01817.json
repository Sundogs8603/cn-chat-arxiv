{
    "title": "LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks",
    "abstract": "There is considerable confusion about the role of Large Language Models (LLMs) in planning and reasoning tasks. On one side are over-optimistic claims that LLMs can indeed do these tasks with just the right prompting or self-verification strategies. On the other side are perhaps over-pessimistic claims that all that LLMs are good for in planning/reasoning tasks are as mere translators of the problem specification from one syntactic format to another, and ship the problem off to external symbolic solvers. In this position paper, we take the view that both these extremes are misguided. We argue that auto-regressive LLMs cannot, by themselves, do planning or self-verification (which is after all a form of reasoning), and shed some light on the reasons for misunderstandings in the literature. We will also argue that LLMs should be viewed as universal approximate knowledge sources that have much more meaningful roles to play in planning/reasoning tasks beyond simple front-end/back-end forma",
    "link": "https://arxiv.org/abs/2402.01817",
    "context": "Title: LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks\nAbstract: There is considerable confusion about the role of Large Language Models (LLMs) in planning and reasoning tasks. On one side are over-optimistic claims that LLMs can indeed do these tasks with just the right prompting or self-verification strategies. On the other side are perhaps over-pessimistic claims that all that LLMs are good for in planning/reasoning tasks are as mere translators of the problem specification from one syntactic format to another, and ship the problem off to external symbolic solvers. In this position paper, we take the view that both these extremes are misguided. We argue that auto-regressive LLMs cannot, by themselves, do planning or self-verification (which is after all a form of reasoning), and shed some light on the reasons for misunderstandings in the literature. We will also argue that LLMs should be viewed as universal approximate knowledge sources that have much more meaningful roles to play in planning/reasoning tasks beyond simple front-end/back-end forma",
    "path": "papers/24/02/2402.01817.json",
    "total_tokens": 827,
    "translated_title": "LLMs无法规划，但可以在LLM-Modulo框架中帮助规划",
    "translated_abstract": "关于大型语言模型（LLMs）在规划和推理任务中的角色存在很大的困惑。一方面有人过于乐观地声称只需正确提示或自我验证策略，LLMs就能完成这些任务。另一方面，也有人过于悲观地认为LLMs在规划/推理任务中仅能作为问题规范的简单翻译器，并将问题交给外部符号求解器。在这篇立场文章中，我们认为这两种极端观点都是错误的。我们认为自回归LLMs本身不能进行规划或自我验证（毕竟这是一种推理形式），并对文献中的误解原因进行了一些阐述。我们还将辩称LLMs应该被视为具有更有意义的角色的通用近似知识源，能在规划/推理任务中发挥更大的作用。",
    "tldr": "LLMs无法独自进行规划或自我验证，但在规划/推理任务中可以作为通用近似知识源发挥更大作用。",
    "en_tdlr": "LLMs cannot plan or self-verify on their own, but they can serve as universal approximate knowledge sources to play a greater role in planning/reasoning tasks."
}