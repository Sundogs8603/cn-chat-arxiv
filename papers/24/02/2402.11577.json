{
    "title": "Extensible Embedding: A Flexible Multipler For LLM's Context Length",
    "abstract": "arXiv:2402.11577v1 Announce Type: new  Abstract: Large language models (LLMs) call for extension of context to handle many critical applications. However, the existing approaches are prone to expensive costs and inferior quality of context extension. In this work, we propose Extensible Embedding, which realizes high-quality extension of LLM's context with strong flexibility and cost-effectiveness. Extensible embedding stand as an enhancement of typical token embedding, which represents the information for an extensible scope of context instead of a single token. By leveraging such compact input units of higher information density, the LLM can access to a vast scope of context even with a small context window. Extensible embedding is systematically optimized in architecture and training method, which leads to multiple advantages. 1) High flexibility of context extension, which flexibly supports ad-hoc extension of diverse context lengths. 2) Strong sample efficiency of training, which e",
    "link": "https://arxiv.org/abs/2402.11577",
    "context": "Title: Extensible Embedding: A Flexible Multipler For LLM's Context Length\nAbstract: arXiv:2402.11577v1 Announce Type: new  Abstract: Large language models (LLMs) call for extension of context to handle many critical applications. However, the existing approaches are prone to expensive costs and inferior quality of context extension. In this work, we propose Extensible Embedding, which realizes high-quality extension of LLM's context with strong flexibility and cost-effectiveness. Extensible embedding stand as an enhancement of typical token embedding, which represents the information for an extensible scope of context instead of a single token. By leveraging such compact input units of higher information density, the LLM can access to a vast scope of context even with a small context window. Extensible embedding is systematically optimized in architecture and training method, which leads to multiple advantages. 1) High flexibility of context extension, which flexibly supports ad-hoc extension of diverse context lengths. 2) Strong sample efficiency of training, which e",
    "path": "papers/24/02/2402.11577.json",
    "total_tokens": 782,
    "translated_title": "可扩展嵌入：LLM上下文长度的灵活多功能器",
    "translated_abstract": "大语言模型（LLMs）需要扩展上下文以处理许多关键应用，但现有方法存在昂贵的成本和较差的上下文扩展质量。在本文中，我们提出了可扩展嵌入，实现了对LLM上下文的高质量扩展，具有强大的灵活性和成本效益。可扩展嵌入是一种 typica1令牌嵌入的增强，表示了一个可扩展范围的上下文信息，而不是单个标记。通过利用这种信息密度更高的紧凑输入单元，LLM即使在较小的上下文窗口中也可以访问广泛的上下文范围。可扩展嵌入在体系结构和训练方法上得到了系统优化，带来了多重优势。",
    "tldr": "提出了可扩展嵌入方法，实现了对LLM上下文的高质量扩展，具有强大的灵活性和成本效益。"
}