{
    "title": "ALERT-Transformer: Bridging Asynchronous and Synchronous Machine Learning for Real-Time Event-based Spatio-Temporal Data",
    "abstract": "We seek to enable classic processing of continuous ultra-sparse spatiotemporal data generated by event-based sensors with dense machine learning models. We propose a novel hybrid pipeline composed of asynchronous sensing and synchronous processing that combines several ideas: (1) an embedding based on PointNet models -- the ALERT module -- that can continuously integrate new and dismiss old events thanks to a leakage mechanism, (2) a flexible readout of the embedded data that allows to feed any downstream model with always up-to-date features at any sampling rate, (3) exploiting the input sparsity in a patch-based approach inspired by Vision Transformer to optimize the efficiency of the method. These embeddings are then processed by a transformer model trained for object and gesture recognition. Using this approach, we achieve performances at the state-of-the-art with a lower latency than competitors. We also demonstrate that our asynchronous model can operate at any desired sampling r",
    "link": "https://rss.arxiv.org/abs/2402.01393",
    "context": "Title: ALERT-Transformer: Bridging Asynchronous and Synchronous Machine Learning for Real-Time Event-based Spatio-Temporal Data\nAbstract: We seek to enable classic processing of continuous ultra-sparse spatiotemporal data generated by event-based sensors with dense machine learning models. We propose a novel hybrid pipeline composed of asynchronous sensing and synchronous processing that combines several ideas: (1) an embedding based on PointNet models -- the ALERT module -- that can continuously integrate new and dismiss old events thanks to a leakage mechanism, (2) a flexible readout of the embedded data that allows to feed any downstream model with always up-to-date features at any sampling rate, (3) exploiting the input sparsity in a patch-based approach inspired by Vision Transformer to optimize the efficiency of the method. These embeddings are then processed by a transformer model trained for object and gesture recognition. Using this approach, we achieve performances at the state-of-the-art with a lower latency than competitors. We also demonstrate that our asynchronous model can operate at any desired sampling r",
    "path": "papers/24/02/2402.01393.json",
    "total_tokens": 921,
    "translated_title": "ALERT-Transformer: 将异步和同步机器学习桥接在实时事件驱动的时空数据上",
    "translated_abstract": "我们旨在通过稠密机器学习模型，实现对由事件感应器产生的连续超稀疏时空数据的经典处理。我们提出了一种新颖的混合管道，由异步感知和同步处理组成，结合了几个思路：（1）基于PointNet模型的嵌入——ALERT模块，可以通过泄漏机制不断整合新事件并消除旧事件，（2）嵌入数据的灵活读取，可以以任何采样率将始终最新的特征输入到下游模型中，（3）借鉴Vision Transformer的基于块的方法来利用输入的稀疏性以优化方法的效率。这些嵌入然后由一个经过对象和手势识别训练的Transformer模型进行处理。使用这种方法，我们实现了比竞争对手更低的延迟，达到了最新技术水平的性能。我们还证明了我们的异步模型可以以任何所需的采样率进行操作。",
    "tldr": "ALERT-Transformer是一种将异步感知与同步处理相结合的新颖桥接方式，通过ALERT模块、灵活的数据读取和基于块的稀疏性优化，实现了对实时事件驱动时空数据的经典处理，其性能超过竞争对手并具有较低的延迟。",
    "en_tdlr": "ALERT-Transformer is a novel bridging approach that combines asynchronous sensing and synchronous processing, achieving classic processing of real-time event-driven spatio-temporal data through the ALERT module, flexible data readout, and block-based sparsity optimization. It outperforms competitors with lower latency."
}