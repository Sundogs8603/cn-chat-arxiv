{
    "title": "Can LLM Generate Culturally Relevant Commonsense QA Data? Case Study in Indonesian and Sundanese",
    "abstract": "arXiv:2402.17302v1 Announce Type: new  Abstract: Large Language Models (LLMs) are increasingly being used to generate synthetic data for training and evaluating models. However, it is unclear whether they can generate a good quality of question answering (QA) dataset that incorporates knowledge and cultural nuance embedded in a language, especially for low-resource languages. In this study, we investigate the effectiveness of using LLMs in generating culturally relevant commonsense QA datasets for Indonesian and Sundanese languages. To do so, we create datasets for these languages using various methods involving both LLMs and human annotators. Our experiments show that the current best-performing LLM, GPT-4 Turbo, is capable of generating questions with adequate knowledge in Indonesian but not in Sundanese, highlighting the performance discrepancy between medium- and lower-resource languages. We also benchmark various LLMs on our generated datasets and find that they perform better on ",
    "link": "https://arxiv.org/abs/2402.17302",
    "context": "Title: Can LLM Generate Culturally Relevant Commonsense QA Data? Case Study in Indonesian and Sundanese\nAbstract: arXiv:2402.17302v1 Announce Type: new  Abstract: Large Language Models (LLMs) are increasingly being used to generate synthetic data for training and evaluating models. However, it is unclear whether they can generate a good quality of question answering (QA) dataset that incorporates knowledge and cultural nuance embedded in a language, especially for low-resource languages. In this study, we investigate the effectiveness of using LLMs in generating culturally relevant commonsense QA datasets for Indonesian and Sundanese languages. To do so, we create datasets for these languages using various methods involving both LLMs and human annotators. Our experiments show that the current best-performing LLM, GPT-4 Turbo, is capable of generating questions with adequate knowledge in Indonesian but not in Sundanese, highlighting the performance discrepancy between medium- and lower-resource languages. We also benchmark various LLMs on our generated datasets and find that they perform better on ",
    "path": "papers/24/02/2402.17302.json",
    "total_tokens": 863,
    "translated_title": "LLM能否生成与文化相关的常识性问答数据？印尼和巽他语的案例研究",
    "translated_abstract": "大型语言模型(LLMs)越来越多地被用于生成合成数据以训练和评估模型。然而，目前尚不清楚它们是否能够生成一个融入语言中知识和文化细微差别的高质量问答(QA)数据集，尤其是对于资源匮乏的语言。在这项研究中，我们调查了使用LLMs生成印尼语和巽他语文化相关常识性问答数据集的有效性。为此，我们使用包括LLMs和人类标注者在内的各种方法为这些语言创建数据集。我们的实验表明，目前性能最佳的LLM，GPT-4 Turbo，能够生成印尼语中具有足够知识的问题，但在巽他语中却不行，突出了中低资源语言之间的性能差距。我们还在我们生成的数据集上对各种LLMs进行基准测试，发现它们在......",
    "tldr": "LLM使用在印尼语方面能够生成具有足够知识的问题，但在巽他语方面表现不佳，突显中低资源语言之间的性能差距。",
    "en_tdlr": "LLM can generate questions with adequate knowledge in Indonesian but performs poorly in Sundanese, highlighting the performance discrepancy between medium- and lower-resource languages."
}