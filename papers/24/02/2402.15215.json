{
    "title": "Item-side Fairness of Large Language Model-based Recommendation System",
    "abstract": "arXiv:2402.15215v1 Announce Type: new  Abstract: Recommendation systems for Web content distribution intricately connect to the information access and exposure opportunities for vulnerable populations. The emergence of Large Language Models-based Recommendation System (LRS) may introduce additional societal challenges to recommendation systems due to the inherent biases in Large Language Models (LLMs). From the perspective of item-side fairness, there remains a lack of comprehensive investigation into the item-side fairness of LRS given the unique characteristics of LRS compared to conventional recommendation systems. To bridge this gap, this study examines the property of LRS with respect to item-side fairness and reveals the influencing factors of both historical users' interactions and inherent semantic biases of LLMs, shedding light on the need to extend conventional item-side fairness methods for LRS. Towards this goal, we develop a concise and effective framework called IFairLRS ",
    "link": "https://arxiv.org/abs/2402.15215",
    "context": "Title: Item-side Fairness of Large Language Model-based Recommendation System\nAbstract: arXiv:2402.15215v1 Announce Type: new  Abstract: Recommendation systems for Web content distribution intricately connect to the information access and exposure opportunities for vulnerable populations. The emergence of Large Language Models-based Recommendation System (LRS) may introduce additional societal challenges to recommendation systems due to the inherent biases in Large Language Models (LLMs). From the perspective of item-side fairness, there remains a lack of comprehensive investigation into the item-side fairness of LRS given the unique characteristics of LRS compared to conventional recommendation systems. To bridge this gap, this study examines the property of LRS with respect to item-side fairness and reveals the influencing factors of both historical users' interactions and inherent semantic biases of LLMs, shedding light on the need to extend conventional item-side fairness methods for LRS. Towards this goal, we develop a concise and effective framework called IFairLRS ",
    "path": "papers/24/02/2402.15215.json",
    "total_tokens": 879,
    "translated_title": "基于大型语言模型的推荐系统的物品侧公平性",
    "translated_abstract": "arXiv:2402.15215v1 公告类型: 新 推荐系统对Web内容分发密切关联着弱势群体的信息获取和暴露机会。基于大型语言模型(LRS)的推荐系统的出现可能由于大型语言模型(LLMs)内在偏见而向推荐系统引入额外的社会挑战。从物品侧公平性的视角看，鉴于LRS与传统推荐系统相比的独特特性，关于LRS的物品侧公平性仍缺乏全面的调查。为弥补这一差距，本研究审视了LRS的属性与物品侧公平性，并揭示了历史用户交互和LLMs固有语义偏见的影响因素，揭示了需要扩展传统物品侧公平性方法以适用于LRS的需求。为实现这一目标，我们开发了一个简洁有效的框架称为IFairLRS。",
    "tldr": "该研究从物品侧公平性的角度探讨了基于大型语言模型的推荐系统，揭示了历史用户交互和模型固有语义偏见对其公平性的影响因素，提出了扩展传统公平性方法以适用于该推荐系统的需求。"
}