{
    "title": "Succint Interaction-Aware Explanations",
    "abstract": "SHAP is a popular approach to explain black-box models by revealing the importance of individual features. As it ignores feature interactions, SHAP explanations can be confusing up to misleading. NSHAP, on the other hand, reports the additive importance for all subsets of features. While this does include all interacting sets of features, it also leads to an exponentially sized, difficult to interpret explanation. In this paper, we propose to combine the best of these two worlds, by partitioning the features into parts that significantly interact, and use these parts to compose a succinct, interpretable, additive explanation. We derive a criterion by which to measure the representativeness of such a partition for a models behavior, traded off against the complexity of the resulting explanation. To efficiently find the best partition out of super-exponentially many, we show how to prune sub-optimal solutions using a statistical test, which not only improves runtime but also helps to det",
    "link": "https://arxiv.org/abs/2402.05566",
    "context": "Title: Succint Interaction-Aware Explanations\nAbstract: SHAP is a popular approach to explain black-box models by revealing the importance of individual features. As it ignores feature interactions, SHAP explanations can be confusing up to misleading. NSHAP, on the other hand, reports the additive importance for all subsets of features. While this does include all interacting sets of features, it also leads to an exponentially sized, difficult to interpret explanation. In this paper, we propose to combine the best of these two worlds, by partitioning the features into parts that significantly interact, and use these parts to compose a succinct, interpretable, additive explanation. We derive a criterion by which to measure the representativeness of such a partition for a models behavior, traded off against the complexity of the resulting explanation. To efficiently find the best partition out of super-exponentially many, we show how to prune sub-optimal solutions using a statistical test, which not only improves runtime but also helps to det",
    "path": "papers/24/02/2402.05566.json",
    "total_tokens": 875,
    "translated_title": "简明考虑交互的解释",
    "translated_abstract": "SHAP是一种流行的解释黑箱模型的方法，通过揭示各个特征的重要性来进行解释。由于忽略了特征之间的交互作用，SHAP的解释可能会令人困惑甚至误导。另一方面，NSHAP报告了所有特征子集的加性重要性。虽然这包含了所有相互作用的特征集，但也导致了一个指数级大小的难以解释的解释。在本文中，我们提出了将这两个方法的优点结合起来的方法，将特征分成显著交互的部分，并使用这些部分构成简明、易解释的加性解释。我们提出了一个标准来衡量这种分区对模型行为的代表性，折衷于得到的解释的复杂性。为了高效地从超指数数量中找到最佳分区，我们展示了如何使用统计检验来剪枝次优解，不仅提高了运行时间，还有助于解释。",
    "tldr": "本文提出了一种结合了SHAP和NSHAP的方法，通过将特征分成显著交互的部分，构建了一种简明、易解释的加性解释，并通过统计检验剪枝次优解，提高了解释的运行效率。",
    "en_tdlr": "This paper proposes a method that combines the benefits of SHAP and NSHAP by partitioning features into interacting parts, creating a succinct and interpretable additive explanation. By using a statistical test to prune sub-optimal solutions, the method improves the runtime of the explanation."
}