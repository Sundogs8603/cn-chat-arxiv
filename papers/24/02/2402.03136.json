{
    "title": "Mastering Zero-Shot Interactions in Cooperative and Competitive Simultaneous Games",
    "abstract": "The combination of self-play and planning has achieved great successes in sequential games, for instance in Chess and Go. However, adapting algorithms such as AlphaZero to simultaneous games poses a new challenge. In these games, missing information about concurrent actions of other agents is a limiting factor as they may select different Nash equilibria or do not play optimally at all. Thus, it is vital to model the behavior of the other agents when interacting with them in simultaneous games. To this end, we propose Albatross: AlphaZero for Learning Bounded-rational Agents and Temperature-based Response Optimization using Simulated Self-play. Albatross learns to play the novel equilibrium concept of a Smooth Best Response Logit Equilibrium (SBRLE), which enables cooperation and competition with agents of any playing strength. We perform an extensive evaluation of Albatross on a set of cooperative and competitive simultaneous perfect-information games. In contrast to AlphaZero, Albatr",
    "link": "https://arxiv.org/abs/2402.03136",
    "context": "Title: Mastering Zero-Shot Interactions in Cooperative and Competitive Simultaneous Games\nAbstract: The combination of self-play and planning has achieved great successes in sequential games, for instance in Chess and Go. However, adapting algorithms such as AlphaZero to simultaneous games poses a new challenge. In these games, missing information about concurrent actions of other agents is a limiting factor as they may select different Nash equilibria or do not play optimally at all. Thus, it is vital to model the behavior of the other agents when interacting with them in simultaneous games. To this end, we propose Albatross: AlphaZero for Learning Bounded-rational Agents and Temperature-based Response Optimization using Simulated Self-play. Albatross learns to play the novel equilibrium concept of a Smooth Best Response Logit Equilibrium (SBRLE), which enables cooperation and competition with agents of any playing strength. We perform an extensive evaluation of Albatross on a set of cooperative and competitive simultaneous perfect-information games. In contrast to AlphaZero, Albatr",
    "path": "papers/24/02/2402.03136.json",
    "total_tokens": 917,
    "translated_title": "解决合作与竞争的同时博弈的零射击互动",
    "translated_abstract": "在顺序游戏中，自我对弈和规划的组合取得了巨大的成功，例如国际象棋和围棋。然而，将AlphaZero等算法调整到同时博弈中带来了新的挑战。在这些游戏中，对其他代理的同时行动缺乏信息是一个限制因素，因为它们可能选择不同的纳什均衡或者根本不最优地进行游戏。因此，在与其他代理博弈时，建模其行为是至关重要的。为此，我们提出了Albatross：使用模拟自我对弈来学习有界理性代理和基于温度的反应优化的AlphaZero。Albatross学习了一种新的均衡概念：平滑最佳反应极端均衡(SBRLE)，从而实现了与任何游戏实力的代理的合作和竞争。我们在一系列合作和竞争的同时完全信息游戏上对Albatross进行了广泛的评估。与AlphaZero相比，Albatross能够同时博弈，并且在不同游戏场景下表现出色。",
    "tldr": "我们提出了一种名为Albatross的算法，它使用模拟自我对弈学习合作和竞争的同时博弈中的有界理性代理行为，并成功实现了与任何游戏实力的代理的合作和竞争。",
    "en_tdlr": "We propose Albatross, an algorithm that learns the behavior of bounded-rational agents in cooperative and competitive simultaneous games through simulated self-play. It achieves successful cooperation and competition with agents of any playing strength."
}