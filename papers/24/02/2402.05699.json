{
    "title": "Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation",
    "abstract": "Aligning large language models (LLMs) with human values is imperative to mitigate potential adverse effects resulting from their misuse. Drawing from the sociological insight that acknowledging all parties' concerns is a key factor in shaping human values, this paper proposes a novel direction to align LLMs by themselves: social scene simulation. To achieve this, we present MATRIX, a novel social scene simulator that emulates realistic scenes around a user's input query, enabling the LLM to take social consequences into account before responding. MATRIX serves as a virtual rehearsal space, akin to a Monopolylogue, where the LLM performs diverse roles related to the query and practice by itself. To inject this alignment, we fine-tune the LLM with MATRIX-simulated data, ensuring adherence to human values without compromising inference speed. We theoretically show that the LLM with MATRIX outperforms Constitutional AI under mild assumptions. Finally, extensive experiments validate that ou",
    "link": "https://arxiv.org/abs/2402.05699",
    "context": "Title: Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation\nAbstract: Aligning large language models (LLMs) with human values is imperative to mitigate potential adverse effects resulting from their misuse. Drawing from the sociological insight that acknowledging all parties' concerns is a key factor in shaping human values, this paper proposes a novel direction to align LLMs by themselves: social scene simulation. To achieve this, we present MATRIX, a novel social scene simulator that emulates realistic scenes around a user's input query, enabling the LLM to take social consequences into account before responding. MATRIX serves as a virtual rehearsal space, akin to a Monopolylogue, where the LLM performs diverse roles related to the query and practice by itself. To inject this alignment, we fine-tune the LLM with MATRIX-simulated data, ensuring adherence to human values without compromising inference speed. We theoretically show that the LLM with MATRIX outperforms Constitutional AI under mild assumptions. Finally, extensive experiments validate that ou",
    "path": "papers/24/02/2402.05699.json",
    "total_tokens": 1055,
    "translated_title": "通过基于垄断对话的社交场景模拟实现大型语言模型的自对齐",
    "translated_abstract": "将大型语言模型(LLMs)与人类价值对齐，以减轻其被滥用造成的潜在不良影响，具有重要意义。本文借鉴社会学的见解，即认识到所有各方的关切是塑造人类价值观的关键因素，提出了一种自对齐LLMs的新方向：社交场景模拟。为此，我们提出了一个名为MATRIX的创新社交场景模拟器，它可以模拟用户输入查询周围的现实场景，使LLM在回答前能够考虑社交后果。MATRIX类似于一个“垄断对话”下的虚拟排练空间，LLM在其中扮演与查询相关的多个角色并进行自我实践。为了引入这种对齐能力，我们使用MATRIX模拟数据对LLM进行微调，确保其在不影响推理速度的情况下符合人类价值观。理论上，我们证明了在温和假设下，带有MATRIX的LLM胜过了宪法AI。最后，大量实验证实了我们的方法在多个任务上都取得了最佳性能。",
    "tldr": "本文提出了一个通过社交场景模拟来自对齐大型语言模型的方法，以减轻其被滥用造成的潜在不良影响。通过一个名为MATRIX的虚拟排练空间，LLM可以在回答查询前考虑社交后果，并通过MATRIX-simulated数据的微调，保持对人类价值的遵从和推理速度的平衡。实验证明，在温和假设下，带有MATRIX的LLM胜过了宪法AI。"
}