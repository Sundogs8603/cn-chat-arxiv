{
    "title": "On the Semantic Latent Space of Diffusion-Based Text-to-Speech Models",
    "abstract": "arXiv:2402.12423v1 Announce Type: cross  Abstract: The incorporation of Denoising Diffusion Models (DDMs) in the Text-to-Speech (TTS) domain is rising, providing great value in synthesizing high quality speech. Although they exhibit impressive audio quality, the extent of their semantic capabilities is unknown, and controlling their synthesized speech's vocal properties remains a challenge. Inspired by recent advances in image synthesis, we explore the latent space of frozen TTS models, which is composed of the latent bottleneck activations of the DDM's denoiser. We identify that this space contains rich semantic information, and outline several novel methods for finding semantic directions within it, both supervised and unsupervised. We then demonstrate how these enable off-the-shelf audio editing, without any further training, architectural changes or data requirements. We present evidence of the semantic and acoustic qualities of the edited audio, and provide supplemental samples: h",
    "link": "https://arxiv.org/abs/2402.12423",
    "context": "Title: On the Semantic Latent Space of Diffusion-Based Text-to-Speech Models\nAbstract: arXiv:2402.12423v1 Announce Type: cross  Abstract: The incorporation of Denoising Diffusion Models (DDMs) in the Text-to-Speech (TTS) domain is rising, providing great value in synthesizing high quality speech. Although they exhibit impressive audio quality, the extent of their semantic capabilities is unknown, and controlling their synthesized speech's vocal properties remains a challenge. Inspired by recent advances in image synthesis, we explore the latent space of frozen TTS models, which is composed of the latent bottleneck activations of the DDM's denoiser. We identify that this space contains rich semantic information, and outline several novel methods for finding semantic directions within it, both supervised and unsupervised. We then demonstrate how these enable off-the-shelf audio editing, without any further training, architectural changes or data requirements. We present evidence of the semantic and acoustic qualities of the edited audio, and provide supplemental samples: h",
    "path": "papers/24/02/2402.12423.json",
    "total_tokens": 907,
    "translated_title": "关于基于扩散的文本转语音模型的语义潜空间",
    "translated_abstract": "在文本转语音（TTS）领域，Denoising Diffusion Models (DDMs) 的引入日益增多，为合成高质量语音提供了巨大价值。尽管它们展示出令人印象深刻的音频质量，但它们的语义能力程度尚不明确，并且控制合成语音的声音特性仍然是一个挑战。受图像合成最新进展的启发，我们探索了冻结的TTS模型的潜空间，该空间由DDM去噪器的潜空间激活组成。我们发现这个空间包含丰富的语义信息，并概述了若干查找其中语义方向的新方法，包括监督和无监督方法。然后，我们演示了如何利用这些方法进行现成音频编辑，无需进一步训练、架构更改或数据需求。我们呈现了编辑后音频的语义和声学特质的证据，并提供了补充样本。",
    "tldr": "本研究在文本转语音模型中探索了冻结模型的潜空间，发现其中包含丰富的语义信息，并提出了一些新方法来找出其中的语义方向，从而实现了不经过额外训练、架构更改或数据需求就能进行音频编辑。",
    "en_tdlr": "This study explores the latent space of frozen Text-to-Speech models, revealing rich semantic information and introducing novel methods to identify semantic directions within it, enabling off-the-shelf audio editing without further training, architectural changes, or data requirements."
}