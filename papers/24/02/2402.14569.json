{
    "title": "Transformable Gaussian Reward Function for Socially-Aware Navigation with Deep Reinforcement Learning",
    "abstract": "arXiv:2402.14569v1 Announce Type: cross  Abstract: Robot navigation has transitioned from prioritizing obstacle avoidance to adopting socially aware navigation strategies that accommodate human presence. As a result, the recognition of socially aware navigation within dynamic human-centric environments has gained prominence in the field of robotics. Although reinforcement learning technique has fostered the advancement of socially aware navigation, defining appropriate reward functions, especially in congested environments, has posed a significant challenge. These rewards, crucial in guiding robot actions, demand intricate human-crafted design due to their complex nature and inability to be automatically set. The multitude of manually designed rewards poses issues with hyperparameter redundancy, imbalance, and inadequate representation of unique object characteristics. To address these challenges, we introduce a transformable gaussian reward function (TGRF). The TGRF significantly redu",
    "link": "https://arxiv.org/abs/2402.14569",
    "context": "Title: Transformable Gaussian Reward Function for Socially-Aware Navigation with Deep Reinforcement Learning\nAbstract: arXiv:2402.14569v1 Announce Type: cross  Abstract: Robot navigation has transitioned from prioritizing obstacle avoidance to adopting socially aware navigation strategies that accommodate human presence. As a result, the recognition of socially aware navigation within dynamic human-centric environments has gained prominence in the field of robotics. Although reinforcement learning technique has fostered the advancement of socially aware navigation, defining appropriate reward functions, especially in congested environments, has posed a significant challenge. These rewards, crucial in guiding robot actions, demand intricate human-crafted design due to their complex nature and inability to be automatically set. The multitude of manually designed rewards poses issues with hyperparameter redundancy, imbalance, and inadequate representation of unique object characteristics. To address these challenges, we introduce a transformable gaussian reward function (TGRF). The TGRF significantly redu",
    "path": "papers/24/02/2402.14569.json",
    "total_tokens": 804,
    "translated_title": "基于深度强化学习的社交感知导航的可变换高斯奖励函数",
    "translated_abstract": "机器人导航已经从优先考虑避障转变为采用社交感知导航策略来适应人类存在。因此，在动态人类中心环境中的社交感知导航的认知在机器人领域中变得重要。虽然强化学习技术推动了社交感知导航的进步，但在拥挤环境中定义适当的奖励函数仍然是一个重大挑战。这些奖励在引导机器人行为时至关重要，由于其复杂性和无法自动设置的特性，需要精心设计。大量手工设计的奖励带来了超参数冗余、不平衡以及无法充分表示独特对象特征的问题。为了解决这些挑战，我们引入了可变换高斯奖励函数（TGRF）。",
    "tldr": "引入了可变换高斯奖励函数(TGRF)来解决强化学习中社交感知导航奖励设计复杂、超参数冗余和不平衡的问题"
}