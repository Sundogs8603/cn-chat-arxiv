{
    "title": "Collaborative decoding of critical tokens for boosting factuality of large language models",
    "abstract": "arXiv:2402.17982v1 Announce Type: new  Abstract: The most common training pipeline for large language models includes pretraining, finetuning and aligning phases, with their respective resulting models, such as the pretrained model and the finetuned model. Finetuned and aligned models show improved abilities of instruction following and safe generation, however their abilities to stay factual about the world are impacted by the finetuning process. Furthermore, the common practice of using sampling during generation also increases chances of hallucination. In this work, we introduce a collaborative decoding framework to harness the high factuality within pretrained models through the concept of critical tokens. We first design a critical token classifier to decide which model to use for the next token, and subsequently generates the next token using different decoding strategies. Experiments with different models and datasets show that our decoding framework is able to reduce model hall",
    "link": "https://arxiv.org/abs/2402.17982",
    "context": "Title: Collaborative decoding of critical tokens for boosting factuality of large language models\nAbstract: arXiv:2402.17982v1 Announce Type: new  Abstract: The most common training pipeline for large language models includes pretraining, finetuning and aligning phases, with their respective resulting models, such as the pretrained model and the finetuned model. Finetuned and aligned models show improved abilities of instruction following and safe generation, however their abilities to stay factual about the world are impacted by the finetuning process. Furthermore, the common practice of using sampling during generation also increases chances of hallucination. In this work, we introduce a collaborative decoding framework to harness the high factuality within pretrained models through the concept of critical tokens. We first design a critical token classifier to decide which model to use for the next token, and subsequently generates the next token using different decoding strategies. Experiments with different models and datasets show that our decoding framework is able to reduce model hall",
    "path": "papers/24/02/2402.17982.json",
    "total_tokens": 827,
    "translated_title": "增强大型语言模型事实性的关键标记协同解码",
    "translated_abstract": "大型语言模型的常见训练流程包括预训练、微调和对齐阶段，产生相应的预训练模型和微调模型。微调和对齐模型表现出了改进的指令遵循和安全生成能力，然而它们在世界事实方面的能力受微调过程的影响。此外，在生成过程中常见的使用采样的做法也增加了幻觉的可能性。在本研究中，我们引入了一种协同解码框架，通过关键标记的概念利用预训练模型中的高事实性。我们首先设计了一个关键标记分类器来决定下一个标记使用哪个模型，然后使用不同的解码策略生成下一个标记。对不同模型和数据集进行的实验表明，我们的解码框架能够减少模型产生幻觉的情况。",
    "tldr": "引入协同解码框架通过关键标记概念利用预训练模型中的高事实性，设计关键标记分类器进行模型选择，有效降低幻觉生成。",
    "en_tdlr": "Introducing a collaborative decoding framework to leverage the high factuality within pretrained models through critical tokens, with a critical token classifier for model selection, effectively reducing hallucination during generation."
}