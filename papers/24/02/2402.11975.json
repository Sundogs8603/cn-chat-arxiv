{
    "title": "Compress to Impress: Unleashing the Potential of Compressive Memory in Real-World Long-Term Conversations",
    "abstract": "arXiv:2402.11975v1 Announce Type: new  Abstract: Existing retrieval-based methods have made significant strides in maintaining long-term conversations. However, these approaches face challenges in memory database management and accurate memory retrieval, hindering their efficacy in dynamic, real-world interactions. This study introduces a novel framework, COmpressive Memory-Enhanced Dialogue sYstems (COMEDY), which eschews traditional retrieval modules and memory databases. Instead, COMEDY adopts a ''One-for-All'' approach, utilizing a single language model to manage memory generation, compression, and response generation. Central to this framework is the concept of compressive memory, which intergrates session-specific summaries, user-bot dynamics, and past events into a concise memory format. To support COMEDY, we curated a large-scale Chinese instruction-tuning dataset, Dolphin, derived from real user-chatbot interactions. Comparative evaluations demonstrate COMEDY's superiority ove",
    "link": "https://arxiv.org/abs/2402.11975",
    "context": "Title: Compress to Impress: Unleashing the Potential of Compressive Memory in Real-World Long-Term Conversations\nAbstract: arXiv:2402.11975v1 Announce Type: new  Abstract: Existing retrieval-based methods have made significant strides in maintaining long-term conversations. However, these approaches face challenges in memory database management and accurate memory retrieval, hindering their efficacy in dynamic, real-world interactions. This study introduces a novel framework, COmpressive Memory-Enhanced Dialogue sYstems (COMEDY), which eschews traditional retrieval modules and memory databases. Instead, COMEDY adopts a ''One-for-All'' approach, utilizing a single language model to manage memory generation, compression, and response generation. Central to this framework is the concept of compressive memory, which intergrates session-specific summaries, user-bot dynamics, and past events into a concise memory format. To support COMEDY, we curated a large-scale Chinese instruction-tuning dataset, Dolphin, derived from real user-chatbot interactions. Comparative evaluations demonstrate COMEDY's superiority ove",
    "path": "papers/24/02/2402.11975.json",
    "total_tokens": 977,
    "translated_title": "压缩以引人注目：释放压缩记忆在现实世界长期对话中的潜力",
    "translated_abstract": "现有的基于检索的方法在维护长期对话方面取得了显著进展。然而，这些方法在记忆数据库管理和准确的记忆检索方面面临挑战，阻碍了它们在动态、真实世界互动中的有效性。该研究引入了一个新颖的框架，称为COmpressive Memory-Enhanced Dialogue sYstems（COMEDY），它摒弃了传统的检索模块和记忆数据库。相反，COMEDY采用了“一对多”方法，利用单一语言模型来管理记忆生成、压缩和响应生成。这一框架的核心概念是压缩记忆，它将会话特定摘要、用户-机器人动态和过去事件整合到简洁的记忆格式中。为了支持COMEDY，我们构建了一个大规模的中文指导调优数据集Dolphin，从真实用户-聊天机器人互动中得出。比较评估表明COMEDY的优越性。",
    "tldr": "提出了COmpressive Memory-Enhanced Dialogue sYstems（COMEDY）框架，通过“一对多”方法利用单一语言模型管理记忆生成、压缩和响应生成，核心概念是压缩记忆，支持大规模中文指导调优数据集Dolphin，比较评估证明了COMEDY的优越性。",
    "en_tdlr": "Introducing the COmpressive Memory-Enhanced Dialogue sYstems (COMEDY) framework that utilizes a \"One-for-All\" approach with a single language model to manage memory generation, compression, and response generation. The core concept of compressive memory, supported by a large-scale Chinese tuning dataset Dolphin, is proven superior through comparative evaluations."
}