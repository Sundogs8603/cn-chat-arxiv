{
    "title": "M$^3$Face: A Unified Multi-Modal Multilingual Framework for Human Face Generation and Editing",
    "abstract": "Human face generation and editing represent an essential task in the era of computer vision and the digital world. Recent studies have shown remarkable progress in multi-modal face generation and editing, for instance, using face segmentation to guide image generation. However, it may be challenging for some users to create these conditioning modalities manually. Thus, we introduce M3Face, a unified multi-modal multilingual framework for controllable face generation and editing. This framework enables users to utilize only text input to generate controlling modalities automatically, for instance, semantic segmentation or facial landmarks, and subsequently generate face images. We conduct extensive qualitative and quantitative experiments to showcase our frameworks face generation and editing capabilities. Additionally, we propose the M3CelebA Dataset, a large-scale multi-modal and multilingual face dataset containing high-quality images, semantic segmentations, facial landmarks, and di",
    "link": "https://arxiv.org/abs/2402.02369",
    "context": "Title: M$^3$Face: A Unified Multi-Modal Multilingual Framework for Human Face Generation and Editing\nAbstract: Human face generation and editing represent an essential task in the era of computer vision and the digital world. Recent studies have shown remarkable progress in multi-modal face generation and editing, for instance, using face segmentation to guide image generation. However, it may be challenging for some users to create these conditioning modalities manually. Thus, we introduce M3Face, a unified multi-modal multilingual framework for controllable face generation and editing. This framework enables users to utilize only text input to generate controlling modalities automatically, for instance, semantic segmentation or facial landmarks, and subsequently generate face images. We conduct extensive qualitative and quantitative experiments to showcase our frameworks face generation and editing capabilities. Additionally, we propose the M3CelebA Dataset, a large-scale multi-modal and multilingual face dataset containing high-quality images, semantic segmentations, facial landmarks, and di",
    "path": "papers/24/02/2402.02369.json",
    "total_tokens": 894,
    "translated_title": "M$^3$Face: 一种用于人脸生成和编辑的统一多模态多语言框架",
    "translated_abstract": "在计算机视觉和数字化世界的时代，人脸生成和编辑是一项重要任务。最近的研究在多模态人脸生成和编辑方面取得了显著进展，例如使用面部分割来指导图像生成。然而，对于一些用户来说，手动创建这些控制模态可能是具有挑战性的。因此，我们引入了M3Face，一种用于可控人脸生成和编辑的统一多模态多语言框架。该框架使用户能够仅使用文本输入自动生成控制模态，例如语义分割或面部特征点，并随后生成人脸图像。我们进行了大量的定性和定量实验，展示了我们框架在人脸生成和编辑能力方面的表现。此外，我们提出了M3CelebA数据集，这是一个包含高质量图像、语义分割、面部特征点和诊断信息的大规模多模态多语言人脸数据集。",
    "tldr": "M$^3$Face是一种统一多模态多语言框架，可以通过文本输入自动生成控制模态，并实现人脸的生成和编辑。同时，我们还提出了M3CelebA数据集，该数据集包含了高质量的多模态多语言人脸数据。",
    "en_tdlr": "M$^3$Face is a unified multi-modal multilingual framework that enables automated control modality generation and facilitates human face generation and editing using text input. The framework also includes the M3CelebA Dataset, a large-scale dataset containing high-quality multi-modal multilingual face data."
}