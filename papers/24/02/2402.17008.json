{
    "title": "Benchmarking LLMs on the Semantic Overlap Summarization Task",
    "abstract": "arXiv:2402.17008v1 Announce Type: new  Abstract: Semantic Overlap Summarization (SOS) is a constrained multi-document summarization task, where the constraint is to capture the common/overlapping information between two alternative narratives. While recent advancements in Large Language Models (LLMs) have achieved superior performance in numerous summarization tasks, a benchmarking study of the SOS task using LLMs is yet to be performed. As LLMs' responses are sensitive to slight variations in prompt design, a major challenge in conducting such a benchmarking study is to systematically explore a variety of prompts before drawing a reliable conclusion. Fortunately, very recently, the TELeR taxonomy has been proposed which can be used to design and explore various prompts for LLMs. Using this TELeR taxonomy and 15 popular LLMs, this paper comprehensively evaluates LLMs on the SOS Task, assessing their ability to summarize overlapping information from multiple alternative narratives. For ",
    "link": "https://arxiv.org/abs/2402.17008",
    "context": "Title: Benchmarking LLMs on the Semantic Overlap Summarization Task\nAbstract: arXiv:2402.17008v1 Announce Type: new  Abstract: Semantic Overlap Summarization (SOS) is a constrained multi-document summarization task, where the constraint is to capture the common/overlapping information between two alternative narratives. While recent advancements in Large Language Models (LLMs) have achieved superior performance in numerous summarization tasks, a benchmarking study of the SOS task using LLMs is yet to be performed. As LLMs' responses are sensitive to slight variations in prompt design, a major challenge in conducting such a benchmarking study is to systematically explore a variety of prompts before drawing a reliable conclusion. Fortunately, very recently, the TELeR taxonomy has been proposed which can be used to design and explore various prompts for LLMs. Using this TELeR taxonomy and 15 popular LLMs, this paper comprehensively evaluates LLMs on the SOS Task, assessing their ability to summarize overlapping information from multiple alternative narratives. For ",
    "path": "papers/24/02/2402.17008.json",
    "total_tokens": 855,
    "translated_title": "在语义重叠摘要任务上对LLMs进行基准测试",
    "translated_abstract": "Semantic Overlap Summarization (SOS)是一项受限的多文档摘要任务，其中约束是捕获两个不同叙述之间的共同/重叠信息。虽然最近大型语言模型（LLMs）在许多摘要任务中取得了优越的性能，但尚未进行过使用LLMs进行SOS任务的基准测试研究。由于LLMs的响应对提示设计中的细微变化很敏感，进行这样的基准测试研究的主要挑战是在得出可靠结论之前系统地探索各种提示。幸运的是，最近提出了TELeR分类法，可用于设计和探索LLMs的各种提示。利用这个TELeR分类法和15个流行的LLMs，本文全面评估了LLMs在SOS任务上的表现，评估它们从多个不同叙述中总结重叠信息的能力。",
    "tldr": "该论文对LLMs在Semantic Overlap Summarization任务上进行基准测试，使用TELeR分类法评估了15个流行的LLMs的性能，以评估它们总结多个不同叙述之间重叠信息的能力。"
}