{
    "title": "Putting Context in Context: the Impact of Discussion Structure on Text Classification",
    "abstract": "Current text classification approaches usually focus on the content to be classified. Contextual aspects (both linguistic and extra-linguistic) are usually neglected, even in tasks based on online discussions. Still in many cases the multi-party and multi-turn nature of the context from which these elements are selected can be fruitfully exploited. In this work, we propose a series of experiments on a large dataset for stance detection in English, in which we evaluate the contribution of different types of contextual information, i.e. linguistic, structural and temporal, by feeding them as natural language input into a transformer-based model. We also experiment with different amounts of training data and analyse the topology of local discussion networks in a privacy-compliant way. Results show that structural information can be highly beneficial to text classification but only under certain circumstances (e.g. depending on the amount of training data and on discussion chain complexity",
    "link": "https://arxiv.org/abs/2402.02975",
    "context": "Title: Putting Context in Context: the Impact of Discussion Structure on Text Classification\nAbstract: Current text classification approaches usually focus on the content to be classified. Contextual aspects (both linguistic and extra-linguistic) are usually neglected, even in tasks based on online discussions. Still in many cases the multi-party and multi-turn nature of the context from which these elements are selected can be fruitfully exploited. In this work, we propose a series of experiments on a large dataset for stance detection in English, in which we evaluate the contribution of different types of contextual information, i.e. linguistic, structural and temporal, by feeding them as natural language input into a transformer-based model. We also experiment with different amounts of training data and analyse the topology of local discussion networks in a privacy-compliant way. Results show that structural information can be highly beneficial to text classification but only under certain circumstances (e.g. depending on the amount of training data and on discussion chain complexity",
    "path": "papers/24/02/2402.02975.json",
    "total_tokens": 828,
    "translated_title": "将上下文放入上下文中：讨论结构对文本分类的影响",
    "translated_abstract": "当前的文本分类方法通常集中在要分类的内容上。即使是基于在线讨论的任务，通常也会忽略上下文方面（包括语言和额外的语言之外的方面）。然而，在许多情况下，可以充分利用选定元素的多方和多轮上下文性质。在这项工作中，我们在一个大规模的英文数据集上提出了一系列关于立场检测的实验，在这些实验中，我们通过将它们作为自然语言输入传入基于Transformer的模型中，评估了不同类型上下文信息（语言、结构和时间）的贡献。我们还尝试使用不同数量的训练数据，并以符合隐私要求的方式分析了局部讨论网络的拓扑。结果表明，结构信息可以对文本分类有很大的益处，但只在特定情况下才显著（例如，取决于训练数据的数量和讨论链的复杂性）。",
    "tldr": "本研究探讨了上下文结构对文本分类的影响，发现结构信息对于文本分类有很大的益处，但仅在特定情况下显著。",
    "en_tdlr": "This research investigates the impact of discussion structure on text classification, revealing that structural information can significantly benefit text classification, but only under certain circumstances."
}