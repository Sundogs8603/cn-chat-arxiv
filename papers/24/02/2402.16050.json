{
    "title": "LSTP: Language-guided Spatial-Temporal Prompt Learning for Long-form Video-Text Understanding",
    "abstract": "arXiv:2402.16050v1 Announce Type: cross  Abstract: Despite progress in video-language modeling, the computational challenge of interpreting long-form videos in response to task-specific linguistic queries persists, largely due to the complexity of high-dimensional video data and the misalignment between language and visual cues over space and time. To tackle this issue, we introduce a novel approach called Language-guided Spatial-Temporal Prompt Learning (LSTP). This approach features two key components: a Temporal Prompt Sampler (TPS) with optical flow prior that leverages temporal information to efficiently extract relevant video content, and a Spatial Prompt Solver (SPS) that adeptly captures the intricate spatial relationships between visual and textual elements. By harmonizing TPS and SPS with a cohesive training strategy, our framework significantly enhances computational efficiency, temporal understanding, and spatial-temporal alignment. Empirical evaluations across two challeng",
    "link": "https://arxiv.org/abs/2402.16050",
    "context": "Title: LSTP: Language-guided Spatial-Temporal Prompt Learning for Long-form Video-Text Understanding\nAbstract: arXiv:2402.16050v1 Announce Type: cross  Abstract: Despite progress in video-language modeling, the computational challenge of interpreting long-form videos in response to task-specific linguistic queries persists, largely due to the complexity of high-dimensional video data and the misalignment between language and visual cues over space and time. To tackle this issue, we introduce a novel approach called Language-guided Spatial-Temporal Prompt Learning (LSTP). This approach features two key components: a Temporal Prompt Sampler (TPS) with optical flow prior that leverages temporal information to efficiently extract relevant video content, and a Spatial Prompt Solver (SPS) that adeptly captures the intricate spatial relationships between visual and textual elements. By harmonizing TPS and SPS with a cohesive training strategy, our framework significantly enhances computational efficiency, temporal understanding, and spatial-temporal alignment. Empirical evaluations across two challeng",
    "path": "papers/24/02/2402.16050.json",
    "total_tokens": 885,
    "translated_title": "LSTP: 语言引导的时空提示学习用于长篇视频文本理解",
    "translated_abstract": "尽管视频语言建模取得了进展，但在回应特定任务的语言查询时解释长篇视频的计算挑战仍然存在，这主要是由于高维视频数据的复杂性和语言与空间和时间上视觉线索之间的不一致性。为解决这一问题，我们引入了一种名为语言引导的时空提示学习（LSTP）的新方法。该方法具有两个关键组件：利用光流先验的时间提示采样器（TPS），可利用时间信息有效提取相关视频内容；以及灵巧地捕捉视觉和文本元素之间复杂空间关系的空间提示求解器（SPS）。通过将TPS和SPS与一致的训练策略相协调，我们的框架显著提升了计算效率、时间理解和空间-时间对齐。在两个挑战中的实证评估显示，我们的方法优于现有技术。",
    "tldr": "LSTP提出了语言引导的时空提示学习方法，通过整合时间提示采样器（TPS）和空间提示求解器（SPS）以及一致的训练策略，显著提升了计算效率、时间理解和空间-时间对齐。",
    "en_tdlr": "LSTP proposes a Language-guided Spatial-Temporal Prompt Learning method, which significantly enhances computational efficiency, temporal understanding, and spatial-temporal alignment by integrating Temporal Prompt Sampler (TPS) and Spatial Prompt Solver (SPS) with a cohesive training strategy."
}