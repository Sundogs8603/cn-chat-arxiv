{
    "title": "What Does the Bot Say? Opportunities and Risks of Large Language Models in Social Media Bot Detection",
    "abstract": "Social media bot detection has always been an arms race between advancements in machine learning bot detectors and adversarial bot strategies to evade detection. In this work, we bring the arms race to the next level by investigating the opportunities and risks of state-of-the-art large language models (LLMs) in social bot detection. To investigate the opportunities, we design novel LLM-based bot detectors by proposing a mixture-of-heterogeneous-experts framework to divide and conquer diverse user information modalities. To illuminate the risks, we explore the possibility of LLM-guided manipulation of user textual and structured information to evade detection. Extensive experiments with three LLMs on two datasets demonstrate that instruction tuning on merely 1,000 annotated examples produces specialized LLMs that outperform state-of-the-art baselines by up to 9.1% on both datasets, while LLM-guided manipulation strategies could significantly bring down the performance of existing bot d",
    "link": "https://arxiv.org/abs/2402.00371",
    "context": "Title: What Does the Bot Say? Opportunities and Risks of Large Language Models in Social Media Bot Detection\nAbstract: Social media bot detection has always been an arms race between advancements in machine learning bot detectors and adversarial bot strategies to evade detection. In this work, we bring the arms race to the next level by investigating the opportunities and risks of state-of-the-art large language models (LLMs) in social bot detection. To investigate the opportunities, we design novel LLM-based bot detectors by proposing a mixture-of-heterogeneous-experts framework to divide and conquer diverse user information modalities. To illuminate the risks, we explore the possibility of LLM-guided manipulation of user textual and structured information to evade detection. Extensive experiments with three LLMs on two datasets demonstrate that instruction tuning on merely 1,000 annotated examples produces specialized LLMs that outperform state-of-the-art baselines by up to 9.1% on both datasets, while LLM-guided manipulation strategies could significantly bring down the performance of existing bot d",
    "path": "papers/24/02/2402.00371.json",
    "total_tokens": 1033,
    "translated_title": "机器人在社交媒体中的检测中，大规模语言模型的机会与风险。",
    "translated_abstract": "社交媒体机器人检测一直是机器学习机器人检测器和对抗机器人策略之间的一场军备竞赛。在这项工作中，我们通过研究最新的大规模语言模型（LLM）在社交机器人检测中的机会和风险，将这场军备竞赛提升到了一个新的水平。为了探索机会，我们设计了基于LLM的新颖机器人检测器，提出了一种混合异质专家框架，对不同的用户信息模态进行划分和征服。为了揭示风险，我们探讨了通过LLM引导用户文本和结构化信息操纵来逃避检测的可能性。在两个数据集上进行的大量实验证明，仅对1,000个注释示例进行指导调整就可以产生专业的LLM，其在两个数据集上的表现超过最先进的基线模型高达9.1%，而LLM引导的操纵策略可以显著降低现有机器人检测的性能。",
    "tldr": "本文研究了大语言模型（LLMs）在社交媒体机器人检测中的机遇和风险。通过提出混合异质专家框架，我们设计了新颖的LLM机器人检测器，并发现仅使用少量标注示例进行指导调整即可取得超过最先进基线模型的性能提升。然而，LLM引导的操纵策略可能会显著降低现有机器人检测的性能。"
}