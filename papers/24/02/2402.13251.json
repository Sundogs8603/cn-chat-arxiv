{
    "title": "FlashTex: Fast Relightable Mesh Texturing with LightControlNet",
    "abstract": "arXiv:2402.13251v1 Announce Type: cross  Abstract: Manually creating textures for 3D meshes is time-consuming, even for expert visual content creators. We propose a fast approach for automatically texturing an input 3D mesh based on a user-provided text prompt. Importantly, our approach disentangles lighting from surface material/reflectance in the resulting texture so that the mesh can be properly relit and rendered in any lighting environment. We introduce LightControlNet, a new text-to-image model based on the ControlNet architecture, which allows the specification of the desired lighting as a conditioning image to the model. Our text-to-texture pipeline then constructs the texture in two stages. The first stage produces a sparse set of visually consistent reference views of the mesh using LightControlNet. The second stage applies a texture optimization based on Score Distillation Sampling (SDS) that works with LightControlNet to increase the texture quality while disentangling surf",
    "link": "https://arxiv.org/abs/2402.13251",
    "context": "Title: FlashTex: Fast Relightable Mesh Texturing with LightControlNet\nAbstract: arXiv:2402.13251v1 Announce Type: cross  Abstract: Manually creating textures for 3D meshes is time-consuming, even for expert visual content creators. We propose a fast approach for automatically texturing an input 3D mesh based on a user-provided text prompt. Importantly, our approach disentangles lighting from surface material/reflectance in the resulting texture so that the mesh can be properly relit and rendered in any lighting environment. We introduce LightControlNet, a new text-to-image model based on the ControlNet architecture, which allows the specification of the desired lighting as a conditioning image to the model. Our text-to-texture pipeline then constructs the texture in two stages. The first stage produces a sparse set of visually consistent reference views of the mesh using LightControlNet. The second stage applies a texture optimization based on Score Distillation Sampling (SDS) that works with LightControlNet to increase the texture quality while disentangling surf",
    "path": "papers/24/02/2402.13251.json",
    "total_tokens": 882,
    "translated_title": "FlashTex：具有LightControlNet的快速可重塑网格纹理",
    "translated_abstract": "手动为3D网格创建纹理费时费力，即使对于专家视觉内容创建者也是如此。我们提出了一种快速方法，根据用户提供的文本提示自动为输入的3D网格着色。重要的是，我们的方法将照明与表面材质/反射在生成的纹理中解耦，以便网格可以在任何照明环境中正确重照和渲染。我们引入了LightControlNet，这是一种基于ControlNet架构的新文本到图像模型，允许将所需照明规格作为对模型的条件图像。我们的文本到纹理管道然后分两个阶段构建纹理。第一阶段使用LightControlNet生成网格的一组稀疏的视觉一致的参考视图。第二阶段应用基于分数蒸馏采样（SDS）的纹理优化，通过LightControlNet来提高纹理质量同时解耦表面材质",
    "tldr": "提出了FlashTex方法，基于LightControlNet实现了快速自动化3D网格纹理生成，实现了照明与表面材质的解耦，使得网格能够在任何照明环境下正确重照和渲染"
}