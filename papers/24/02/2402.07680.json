{
    "title": "AYDIV: Adaptable Yielding 3D Object Detection via Integrated Contextual Vision Transformer",
    "abstract": "Combining LiDAR and camera data has shown potential in enhancing short-distance object detection in autonomous driving systems. Yet, the fusion encounters difficulties with extended distance detection due to the contrast between LiDAR's sparse data and the dense resolution of cameras. Besides, discrepancies in the two data representations further complicate fusion methods. We introduce AYDIV, a novel framework integrating a tri-phase alignment process specifically designed to enhance long-distance detection even amidst data discrepancies. AYDIV consists of the Global Contextual Fusion Alignment Transformer (GCFAT), which improves the extraction of camera features and provides a deeper understanding of large-scale patterns; the Sparse Fused Feature Attention (SFFA), which fine-tunes the fusion of LiDAR and camera details; and the Volumetric Grid Attention (VGA) for a comprehensive spatial data fusion. AYDIV's performance on the Waymo Open Dataset (WOD) with an improvement of 1.24% in mA",
    "link": "https://arxiv.org/abs/2402.07680",
    "context": "Title: AYDIV: Adaptable Yielding 3D Object Detection via Integrated Contextual Vision Transformer\nAbstract: Combining LiDAR and camera data has shown potential in enhancing short-distance object detection in autonomous driving systems. Yet, the fusion encounters difficulties with extended distance detection due to the contrast between LiDAR's sparse data and the dense resolution of cameras. Besides, discrepancies in the two data representations further complicate fusion methods. We introduce AYDIV, a novel framework integrating a tri-phase alignment process specifically designed to enhance long-distance detection even amidst data discrepancies. AYDIV consists of the Global Contextual Fusion Alignment Transformer (GCFAT), which improves the extraction of camera features and provides a deeper understanding of large-scale patterns; the Sparse Fused Feature Attention (SFFA), which fine-tunes the fusion of LiDAR and camera details; and the Volumetric Grid Attention (VGA) for a comprehensive spatial data fusion. AYDIV's performance on the Waymo Open Dataset (WOD) with an improvement of 1.24% in mA",
    "path": "papers/24/02/2402.07680.json",
    "total_tokens": 1036,
    "translated_title": "AYDIV: 通过集成上下文视觉Transformer的可调节性3D物体检测",
    "translated_abstract": "结合LiDAR和相机数据在自动驾驶系统中增强短距离物体检测显示出潜力。然而，由于LiDAR的稀疏数据和相机的高密度分辨率之间的对比，融合在延伸距离检测方面遇到困难。此外，两种数据表示的差异进一步复杂化了融合方法。我们引入了AYDIV，这是一个新颖的框架，集成了一个特殊设计的三阶段对齐过程，专门用于增强在数据差异中延伸距离的检测能力。AYDIV包括全局上下文融合对齐变换器（GCFAT），它改善相机特征的提取并对大规模模式进行更深入的理解；稀疏融合特征注意力（SFFA），它对LiDAR和相机细节的融合进行微调；以及用于全面空间数据融合的体积网格注意力（VGA）。AYDIV在Waymo开放数据集（WOD）上的性能提升了1.24%的平均精度（mA）。",
    "tldr": "AYDIV是一个通过集成上下文视觉Transformer来增强3D物体检测的框架，特别设计了三阶段对齐过程来增强长距离的检测能力，包括改善相机特征提取、融合LiDAR和相机细节以及全面的空间数据融合。在Waymo开放数据集上，AYDIV的性能提高了1.24%的平均精度（mA）。",
    "en_tdlr": "AYDIV is a framework that enhances 3D object detection by integrating contextual vision transformers, specifically designed with a three-phase alignment process to improve long-distance detection, including improved camera feature extraction, fusion of LiDAR and camera details, and comprehensive spatial data fusion. AYDIV achieves a 1.24% improvement in mean average precision (mA) on the Waymo Open Dataset (WOD)."
}