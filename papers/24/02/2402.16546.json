{
    "title": "Beyond Accuracy: An Empirical Study on Unit Testing in Open-source Deep Learning Projects",
    "abstract": "arXiv:2402.16546v1 Announce Type: cross  Abstract: Deep Learning (DL) models have rapidly advanced, focusing on achieving high performance through testing model accuracy and robustness. However, it is unclear whether DL projects, as software systems, are tested thoroughly or functionally correct when there is a need to treat and test them like other software systems. Therefore, we empirically study the unit tests in open-source DL projects, analyzing 9,129 projects from GitHub. We find that: 1) unit tested DL projects have positive correlation with the open-source project metrics and have a higher acceptance rate of pull requests, 2) 68% of the sampled DL projects are not unit tested at all, 3) the layer and utilities (utils) of DL models have the most unit tests. Based on these findings and previous research outcomes, we built a mapping taxonomy between unit tests and faults in DL projects. We discuss the implications of our findings for developers and researchers and highlight the ne",
    "link": "https://arxiv.org/abs/2402.16546",
    "context": "Title: Beyond Accuracy: An Empirical Study on Unit Testing in Open-source Deep Learning Projects\nAbstract: arXiv:2402.16546v1 Announce Type: cross  Abstract: Deep Learning (DL) models have rapidly advanced, focusing on achieving high performance through testing model accuracy and robustness. However, it is unclear whether DL projects, as software systems, are tested thoroughly or functionally correct when there is a need to treat and test them like other software systems. Therefore, we empirically study the unit tests in open-source DL projects, analyzing 9,129 projects from GitHub. We find that: 1) unit tested DL projects have positive correlation with the open-source project metrics and have a higher acceptance rate of pull requests, 2) 68% of the sampled DL projects are not unit tested at all, 3) the layer and utilities (utils) of DL models have the most unit tests. Based on these findings and previous research outcomes, we built a mapping taxonomy between unit tests and faults in DL projects. We discuss the implications of our findings for developers and researchers and highlight the ne",
    "path": "papers/24/02/2402.16546.json",
    "total_tokens": 928,
    "translated_title": "超越准确性：开源深度学习项目中单元测试的实证研究",
    "translated_abstract": "深度学习（DL）模型已经快速发展，专注于通过测试模型的准确性和稳健性来实现高性能。然而，尚不清楚是否需要像对待和测试其他软件系统一样对待和测试DL项目这样的软件系统时，DL项目是否经过了彻底测试或功能正确。因此，我们对GitHub上的9,129个开源DL项目进行了实证研究，分析了其中的单元测试。我们发现：1）经过单元测试的DL项目与开源项目指标呈正相关，并且对拉取请求有更高的接受率，2）本样本DL项目中有68%根本没有进行单元测试，3）DL模型的层(layer)和实用程序(utils)具有最多的单元测试。基于这些发现和以前的研究成果，我们建立了单元测试和DL项目中的故障之间的映射分类法。我们讨论了我们的发现对开发人员和研究人员的影响，并强调了Ne的重要性。",
    "tldr": "通过对GitHub上9,129个开源DL项目的单元测试进行实证研究，发现经过单元测试的DL项目与开源项目指标呈正相关，68%的DL项目根本没有进行单元测试，并建立了单元测试和DL项目中故障之间的映射分类法。",
    "en_tdlr": "An empirical study on unit testing in 9,129 open-source DL projects on GitHub reveals that unit tested DL projects are positively correlated with open-source project metrics, 68% of DL projects are not unit tested at all, and a mapping taxonomy between unit tests and faults in DL projects is established."
}