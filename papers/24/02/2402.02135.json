{
    "title": "Do Moral Judgment and Reasoning Capability of LLMs Change with Language? A Study using the Multilingual Defining Issues Test",
    "abstract": "This paper explores the moral judgment and moral reasoning abilities exhibited by Large Language Models (LLMs) across languages through the Defining Issues Test. It is a well known fact that moral judgment depends on the language in which the question is asked. We extend the work of beyond English, to 5 new languages (Chinese, Hindi, Russian, Spanish and Swahili), and probe three LLMs -- ChatGPT, GPT-4 and Llama2Chat-70B -- that shows substantial multilingual text processing and generation abilities. Our study shows that the moral reasoning ability for all models, as indicated by the post-conventional score, is substantially inferior for Hindi and Swahili, compared to Spanish, Russian, Chinese and English, while there is no clear trend for the performance of the latter four languages. The moral judgments too vary considerably by the language.",
    "link": "https://arxiv.org/abs/2402.02135",
    "context": "Title: Do Moral Judgment and Reasoning Capability of LLMs Change with Language? A Study using the Multilingual Defining Issues Test\nAbstract: This paper explores the moral judgment and moral reasoning abilities exhibited by Large Language Models (LLMs) across languages through the Defining Issues Test. It is a well known fact that moral judgment depends on the language in which the question is asked. We extend the work of beyond English, to 5 new languages (Chinese, Hindi, Russian, Spanish and Swahili), and probe three LLMs -- ChatGPT, GPT-4 and Llama2Chat-70B -- that shows substantial multilingual text processing and generation abilities. Our study shows that the moral reasoning ability for all models, as indicated by the post-conventional score, is substantially inferior for Hindi and Swahili, compared to Spanish, Russian, Chinese and English, while there is no clear trend for the performance of the latter four languages. The moral judgments too vary considerably by the language.",
    "path": "papers/24/02/2402.02135.json",
    "total_tokens": 922,
    "translated_title": "语言对LLMs的道德判断和推理能力有影响吗？一项使用多语言定义问题测试的研究",
    "translated_abstract": "本文通过使用多语言定义问题测试探讨了大型语言模型（LLMs）在不同语言下展现的道德判断和道德推理能力。众所周知，道德判断取决于问题所使用的语言。我们将研究扩展到了除英语外的五种新语言（中文、印地语、俄语、西班牙语和斯瓦希里语），并对三个具有较强多语言文本处理和生成能力的LLMs（ChatGPT、GPT-4和Llama2Chat-70B）进行了探究。我们的研究发现，通过后柔性分数指示的道德推理能力在印地语和斯瓦希里语中显著低于西班牙语、俄语、中文和英语，而后四种语言的表现则没有明显的趋势。道德判断在不同语言中也存在较大差异。",
    "tldr": "本研究通过使用多语言定义问题测试，探讨了大型语言模型（LLMs）在不同语言下的道德判断和道德推理能力。研究发现，印地语和斯瓦希里语的道德推理能力明显低于其他语言，而道德判断也在不同语言下变化较大。",
    "en_tdlr": "This study examines the moral judgment and reasoning abilities of Large Language Models (LLMs) across different languages using the Multilingual Defining Issues Test. The findings indicate that the moral reasoning ability is significantly lower for Hindi and Swahili compared to other languages, and moral judgments also vary considerably across languages."
}