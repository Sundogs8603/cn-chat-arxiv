{
    "title": "An Accurate and Low-Parameter Machine Learning Architecture for Next Location Prediction",
    "abstract": "Next location prediction is a discipline that involves predicting a users next location. Its applications include resource allocation, quality of service, energy efficiency, and traffic management. This paper proposes an energy-efficient, small, and low parameter machine learning (ML) architecture for accurate next location prediction, deployable on modest base stations and edge devices. To accomplish this we ran a hundred hyperparameter experiments on the full human mobility patterns of an entire city, to determine an exact ML architecture that reached a plateau of accuracy with the least amount of model parameters. We successfully achieved a reduction in the number of model parameters within published ML architectures from 202 million down to 2 million. This reduced the total size of the model parameters from 791 MB down to 8 MB. Additionally, this decreased the training time by a factor of four, the amount of graphics processing unit (GPU) memory needed for training by a factor of t",
    "link": "https://arxiv.org/abs/2402.00306",
    "context": "Title: An Accurate and Low-Parameter Machine Learning Architecture for Next Location Prediction\nAbstract: Next location prediction is a discipline that involves predicting a users next location. Its applications include resource allocation, quality of service, energy efficiency, and traffic management. This paper proposes an energy-efficient, small, and low parameter machine learning (ML) architecture for accurate next location prediction, deployable on modest base stations and edge devices. To accomplish this we ran a hundred hyperparameter experiments on the full human mobility patterns of an entire city, to determine an exact ML architecture that reached a plateau of accuracy with the least amount of model parameters. We successfully achieved a reduction in the number of model parameters within published ML architectures from 202 million down to 2 million. This reduced the total size of the model parameters from 791 MB down to 8 MB. Additionally, this decreased the training time by a factor of four, the amount of graphics processing unit (GPU) memory needed for training by a factor of t",
    "path": "papers/24/02/2402.00306.json",
    "total_tokens": 878,
    "translated_title": "一个准确且低参数的机器学习架构用于下一个位置的预测",
    "translated_abstract": "下一个位置的预测是一门涉及预测用户下一个位置的学科。其应用包括资源分配、服务质量、能源效率和交通管理。本文提出了一种节能、小型和低参数的机器学习（ML）架构，用于准确的下一个位置预测，可部署在普通基站和边缘设备上。为了实现这一目标，我们对一个整个城市的完整人员流动模式进行了一百个超参数实验，以确定一个精确的ML架构，其准确度达到了最少数量的模型参数的平台。我们成功地将已发表的ML架构的模型参数数量从2.02亿减少到200万。这将模型参数的总大小从791 MB减少到8 MB。此外，训练时间减少了四倍，训练所需的图形处理单元（GPU）内存量也减少了一个因素。",
    "tldr": "本文提出了一个节能、小型且低参数的机器学习架构，用于准确预测用户的下一个位置。通过大量实验，成功将模型参数数量从2.02亿减少到200万，模型大小从791 MB减少到8 MB，训练时间减少了四倍。",
    "en_tdlr": "This paper proposes an energy-efficient, small, and low parameter machine learning architecture for accurate next location prediction. Through extensive experiments, the number of model parameters is reduced from 202 million to 2 million, the model size is reduced from 791 MB to 8 MB, and the training time is reduced by a factor of four."
}