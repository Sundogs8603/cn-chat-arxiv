{
    "title": "Multimodal Learned Sparse Retrieval with Probabilistic Expansion Control",
    "abstract": "arXiv:2402.17535v1 Announce Type: new  Abstract: Learned sparse retrieval (LSR) is a family of neural methods that encode queries and documents into sparse lexical vectors that can be indexed and retrieved efficiently with an inverted index. We explore the application of LSR to the multi-modal domain, with a focus on text-image retrieval. While LSR has seen success in text retrieval, its application in multimodal retrieval remains underexplored. Current approaches like LexLIP and STAIR require complex multi-step training on massive datasets. Our proposed approach efficiently transforms dense vectors from a frozen dense model into sparse lexical vectors. We address issues of high dimension co-activation and semantic deviation through a new training algorithm, using Bernoulli random variables to control query expansion. Experiments with two dense models (BLIP, ALBEF) and two datasets (MSCOCO, Flickr30k) show that our proposed algorithm effectively reduces co-activation and semantic devia",
    "link": "https://arxiv.org/abs/2402.17535",
    "context": "Title: Multimodal Learned Sparse Retrieval with Probabilistic Expansion Control\nAbstract: arXiv:2402.17535v1 Announce Type: new  Abstract: Learned sparse retrieval (LSR) is a family of neural methods that encode queries and documents into sparse lexical vectors that can be indexed and retrieved efficiently with an inverted index. We explore the application of LSR to the multi-modal domain, with a focus on text-image retrieval. While LSR has seen success in text retrieval, its application in multimodal retrieval remains underexplored. Current approaches like LexLIP and STAIR require complex multi-step training on massive datasets. Our proposed approach efficiently transforms dense vectors from a frozen dense model into sparse lexical vectors. We address issues of high dimension co-activation and semantic deviation through a new training algorithm, using Bernoulli random variables to control query expansion. Experiments with two dense models (BLIP, ALBEF) and two datasets (MSCOCO, Flickr30k) show that our proposed algorithm effectively reduces co-activation and semantic devia",
    "path": "papers/24/02/2402.17535.json",
    "total_tokens": 883,
    "translated_title": "具有概率扩展控制的多模态学习稀疏检索",
    "translated_abstract": "学习稀疏检索（LSR）是一类神经方法，将查询和文档编码为稀疏的词汇向量，可以通过倒排索引高效索引和检索。我们探讨了LSR在多模态领域的应用，重点关注文本-图像检索。虽然LSR在文本检索方面取得了成功，但它在多模态检索中的应用仍未得到充分探讨。当前的方法如LexLIP和STAIR需要对大规模数据集进行复杂的多步训练。我们提出的方法将来自冻结的稠密模型的密集向量有效地转换为稀疏的词汇向量。通过使用伯努利随机变量控制查询扩展，我们通过新的训练算法解决了高维共激活和语义偏差的问题。在两个密集模型（BLIP、ALBEF）和两个数据集（MSCOCO、Flickr30k）上进行的实验表明，我们提出的算法有效地减少了共激活和语义偏差。",
    "tldr": "提出了一种具有概率扩展控制的多模态学习稀疏检索方法，通过新的训练算法有效地减少了高维共激活和语义偏差。",
    "en_tdlr": "Introduced a multimodal learned sparse retrieval method with probabilistic expansion control, effectively reducing high dimension co-activation and semantic deviation through a new training algorithm."
}