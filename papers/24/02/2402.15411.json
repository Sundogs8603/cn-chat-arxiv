{
    "title": "Optimisic Information Directed Sampling",
    "abstract": "arXiv:2402.15411v1 Announce Type: new  Abstract: We study the problem of online learning in contextual bandit problems where the loss function is assumed to belong to a known parametric function class. We propose a new analytic framework for this setting that bridges the Bayesian theory of information-directed sampling due to Russo and Van Roy (2018) and the worst-case theory of Foster, Kakade, Qian, and Rakhlin (2021) based on the decision-estimation coefficient. Drawing from both lines of work, we propose a algorithmic template called Optimistic Information-Directed Sampling and show that it can achieve instance-dependent regret guarantees similar to the ones achievable by the classic Bayesian IDS method, but with the major advantage of not requiring any Bayesian assumptions. The key technical innovation of our analysis is introducing an optimistic surrogate model for the regret and using it to define a frequentist version of the Information Ratio of Russo and Van Roy (2018), and a l",
    "link": "https://arxiv.org/abs/2402.15411",
    "context": "Title: Optimisic Information Directed Sampling\nAbstract: arXiv:2402.15411v1 Announce Type: new  Abstract: We study the problem of online learning in contextual bandit problems where the loss function is assumed to belong to a known parametric function class. We propose a new analytic framework for this setting that bridges the Bayesian theory of information-directed sampling due to Russo and Van Roy (2018) and the worst-case theory of Foster, Kakade, Qian, and Rakhlin (2021) based on the decision-estimation coefficient. Drawing from both lines of work, we propose a algorithmic template called Optimistic Information-Directed Sampling and show that it can achieve instance-dependent regret guarantees similar to the ones achievable by the classic Bayesian IDS method, but with the major advantage of not requiring any Bayesian assumptions. The key technical innovation of our analysis is introducing an optimistic surrogate model for the regret and using it to define a frequentist version of the Information Ratio of Russo and Van Roy (2018), and a l",
    "path": "papers/24/02/2402.15411.json",
    "total_tokens": 830,
    "translated_title": "乐观信息导向采样",
    "translated_abstract": "我们研究在上下文强盗问题中的在线学习问题，其中损失函数被假定属于已知的参数函数类。我们提出了一个新的分析框架，它在贝叶斯理论和基于决策估计系数的最坏情形理论之间架起了桥梁。汲取这两方面的工作，我们提出了一种名为乐观信息导向采样的算法模板，并展示它能够实现类似于经典贝叶斯IDS方法可实现的实例相关遗憾保证，但却无需任何贝叶斯假设。我们分析的关键技术创新是引入了一个乐观的替代模型用于遗憾，并将其用于定义一个基于频率的基于Russo和Van Roy (2018)的信息比，以及一个...",
    "tldr": "提出了一种名为乐观信息导向采样的算法模板, 结合了贝叶斯理论和最坏情形理论，能够实现类似于贝叶斯方法的实例相关遗憾保证，但无需贝叶斯假设。",
    "en_tdlr": "Proposed a new algorithmic template called Optimistic Information-Directed Sampling that bridges Bayesian theory with worst-case theory, achieving instance-dependent regret guarantees similar to Bayesian methods without requiring Bayesian assumptions."
}