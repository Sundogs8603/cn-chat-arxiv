{
    "title": "Increasing Trust in Language Models through the Reuse of Verified Circuits",
    "abstract": "Language Models (LMs) are increasingly used for a wide range of prediction tasks, but their training can often neglect rare edge cases, reducing their reliability. Here, we define a stringent standard of trustworthiness whereby the task algorithm and circuit implementation must be verified, accounting for edge cases, with no known failure modes. We show that a transformer model can be trained to meet this standard if built using mathematically and logically specified frameworks. In this paper, we fully verify a model for n-digit integer addition. To exhibit the reusability of verified modules, we insert the trained integer addition model into an untrained model and train the combined model to perform both addition and subtraction. We find extensive reuse of the addition circuits for both tasks, easing verification of the more complex subtractor model. We discuss how inserting verified task modules into LMs can leverage model reuse to improve verifiability and trustworthiness of languag",
    "link": "https://arxiv.org/abs/2402.02619",
    "context": "Title: Increasing Trust in Language Models through the Reuse of Verified Circuits\nAbstract: Language Models (LMs) are increasingly used for a wide range of prediction tasks, but their training can often neglect rare edge cases, reducing their reliability. Here, we define a stringent standard of trustworthiness whereby the task algorithm and circuit implementation must be verified, accounting for edge cases, with no known failure modes. We show that a transformer model can be trained to meet this standard if built using mathematically and logically specified frameworks. In this paper, we fully verify a model for n-digit integer addition. To exhibit the reusability of verified modules, we insert the trained integer addition model into an untrained model and train the combined model to perform both addition and subtraction. We find extensive reuse of the addition circuits for both tasks, easing verification of the more complex subtractor model. We discuss how inserting verified task modules into LMs can leverage model reuse to improve verifiability and trustworthiness of languag",
    "path": "papers/24/02/2402.02619.json",
    "total_tokens": 1052,
    "translated_title": "通过重复使用经过验证的电路增加语言模型的可信度",
    "translated_abstract": "语言模型（LMs）在各种预测任务中的应用越来越广泛，但它们的训练经常忽略罕见的边界情况，降低了它们的可靠性。在本文中，我们定义了一个严格的可信度标准，即任务算法和电路实现必须经过验证，考虑到边界情况，并且没有已知的故障模式。我们展示了通过使用数学和逻辑规范的框架来构建变压器模型，可以训练出满足这一标准的模型。在本文中，我们对一个n位整数加法模型进行了完全验证。为了展示经过验证的模块的重复使用性，我们将训练好的整数加法模型插入到一个未经训练的模型中，并训练组合模型同时执行加法和减法。我们发现加法电路在这两个任务中得到了广泛的重复使用，从而简化了更复杂的减法模型的验证。我们讨论了如何将经过验证的任务模块插入到语言模型中，以利用模型的重复使用来提高可验证性和可信度。",
    "tldr": "本文介绍了一种通过重复使用经过验证的电路来增加语言模型的可信度的方法。研究者通过构建数学和逻辑规范的框架，并对一个n位整数加法模型进行完全验证。他们插入训练好的加法模型到一个未经训练的模型中，通过训练组合模型执行加法和减法。他们发现加法电路在这两个任务中得到了广泛的重复使用，从而简化了减法模型的验证。",
    "en_tdlr": "This paper presents a method to increase the trustworthiness of language models by reusing verified circuits. The researchers create a framework with mathematically and logically specified models and fully verify an n-digit integer addition model. They then insert the trained addition model into an untrained model and train the combined model to perform addition and subtraction tasks. They find that the addition circuits are extensively reused for both tasks, simplifying the verification of the more complex subtractor model."
}