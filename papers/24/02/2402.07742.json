{
    "title": "Asking Multimodal Clarifying Questions in Mixed-Initiative Conversational Search",
    "abstract": "In mixed-initiative conversational search systems, clarifying questions are used to help users who struggle to express their intentions in a single query. These questions aim to uncover user's information needs and resolve query ambiguities. We hypothesize that in scenarios where multimodal information is pertinent, the clarification process can be improved by using non-textual information. Therefore, we propose to add images to clarifying questions and formulate the novel task of asking multimodal clarifying questions in open-domain, mixed-initiative conversational search systems. To facilitate research into this task, we collect a dataset named Melon that contains over 4k multimodal clarifying questions, enriched with over 14k images. We also propose a multimodal query clarification model named Marto and adopt a prompt-based, generative fine-tuning strategy to perform the training of different stages with different prompts. Several analyses are conducted to understand the importance ",
    "link": "https://arxiv.org/abs/2402.07742",
    "context": "Title: Asking Multimodal Clarifying Questions in Mixed-Initiative Conversational Search\nAbstract: In mixed-initiative conversational search systems, clarifying questions are used to help users who struggle to express their intentions in a single query. These questions aim to uncover user's information needs and resolve query ambiguities. We hypothesize that in scenarios where multimodal information is pertinent, the clarification process can be improved by using non-textual information. Therefore, we propose to add images to clarifying questions and formulate the novel task of asking multimodal clarifying questions in open-domain, mixed-initiative conversational search systems. To facilitate research into this task, we collect a dataset named Melon that contains over 4k multimodal clarifying questions, enriched with over 14k images. We also propose a multimodal query clarification model named Marto and adopt a prompt-based, generative fine-tuning strategy to perform the training of different stages with different prompts. Several analyses are conducted to understand the importance ",
    "path": "papers/24/02/2402.07742.json",
    "total_tokens": 906,
    "translated_title": "在混合式主动对话搜索中提出多模态澄清问题",
    "translated_abstract": "在混合式主动对话搜索系统中，澄清问题被用于帮助那些难以用一个查询表达自己意图的用户。这些问题旨在揭示用户的信息需求并解决查询的歧义。我们假设，在与多模态信息相关的情景中，通过使用非文本信息可以改进澄清过程。因此，我们提出将图像添加到澄清问题中，并提出在开放域、混合式主动对话搜索系统中提出多模态澄清问题的新任务。为了促进对这个任务的研究，我们收集了一个名为Melon的数据集，其中包含超过4k个多模态澄清问题，并附带超过14k个图像。我们还提出了一个名为Marto的多模态查询澄清模型，并采用基于提示的生成微调策略，使用不同的提示来进行不同阶段的训练。进行了几个分析来理解重要因素。",
    "tldr": "本论文提出在混合式主动对话搜索中通过使用多模态信息来改进澄清问题的方法，并设计了一个名为Marto的多模态查询澄清模型。通过收集多模态澄清问题和图像的数据集Melon，并采用基于提示的训练策略，为进一步研究这一任务提供了便利。",
    "en_tdlr": "This paper proposes a method to improve clarifying questions in mixed-initiative conversational search by using multimodal information, and designs a multimodal query clarification model named Marto. The paper collects a dataset named Melon that contains multimodal clarifying questions and images, and adopts a prompt-based training strategy for further research on this task."
}