{
    "title": "Concurrent Learning of Policy and Unknown Safety Constraints in Reinforcement Learning",
    "abstract": "arXiv:2402.15893v1 Announce Type: cross  Abstract: Reinforcement learning (RL) has revolutionized decision-making across a wide range of domains over the past few decades. Yet, deploying RL policies in real-world scenarios presents the crucial challenge of ensuring safety. Traditional safe RL approaches have predominantly focused on incorporating predefined safety constraints into the policy learning process. However, this reliance on predefined safety constraints poses limitations in dynamic and unpredictable real-world settings where such constraints may not be available or sufficiently adaptable. Bridging this gap, we propose a novel approach that concurrently learns a safe RL control policy and identifies the unknown safety constraint parameters of a given environment. Initializing with a parametric signal temporal logic (pSTL) safety specification and a small initial labeled dataset, we frame the problem as a bilevel optimization task, intricately integrating constrained policy op",
    "link": "https://arxiv.org/abs/2402.15893",
    "context": "Title: Concurrent Learning of Policy and Unknown Safety Constraints in Reinforcement Learning\nAbstract: arXiv:2402.15893v1 Announce Type: cross  Abstract: Reinforcement learning (RL) has revolutionized decision-making across a wide range of domains over the past few decades. Yet, deploying RL policies in real-world scenarios presents the crucial challenge of ensuring safety. Traditional safe RL approaches have predominantly focused on incorporating predefined safety constraints into the policy learning process. However, this reliance on predefined safety constraints poses limitations in dynamic and unpredictable real-world settings where such constraints may not be available or sufficiently adaptable. Bridging this gap, we propose a novel approach that concurrently learns a safe RL control policy and identifies the unknown safety constraint parameters of a given environment. Initializing with a parametric signal temporal logic (pSTL) safety specification and a small initial labeled dataset, we frame the problem as a bilevel optimization task, intricately integrating constrained policy op",
    "path": "papers/24/02/2402.15893.json",
    "total_tokens": 796,
    "translated_title": "强化学习中并行学习策略和未知安全约束",
    "translated_abstract": "强化学习（RL）在过去几十年中已经彻底改变了跨多个领域的决策制定。然而，在实际场景中部署RL策略面临着确保安全的关键挑战。传统的安全RL方法主要集中于将预定义的安全约束纳入到策略学习过程中。然而，在动态和不可预测的实际环境中，这种对预定义安全约束的依赖在安全控制RL任务中具有限制，因为这些约束可能无法得到或不够适应。为弥补这一差距，我们提出了一种新颖的方法，同时学习安全的RL控制策略并确定给定环境的未知安全约束参数。通过使用一个参数化的信号时间逻辑（pSTL）安全规范和一个小的初始标记数据集进行初始化，我们将问题构建为一个双层优化任务，巧妙地将受限策略op",
    "tldr": "提出了一种同时学习安全RL控制策略和识别未知安全约束参数的新方法。",
    "en_tdlr": "Introduces a novel method for concurrently learning a safe RL control policy and identifying unknown safety constraint parameters."
}