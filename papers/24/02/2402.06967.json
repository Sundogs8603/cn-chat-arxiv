{
    "title": "Instruct Once, Chat Consistently in Multiple Rounds: An Efficient Tuning Framework for Dialogue",
    "abstract": "Tuning pretrained language models for dialogue generation has been a prevalent paradigm for building capable dialogue agents. Yet, traditional tuning narrowly views dialogue generation as resembling other language generation tasks, ignoring the role disparities between two speakers and the multi-round interactive process that dialogues ought to be. Such a manner leads to unsatisfactory chat consistency of the built agent. In this work, we emphasize the interactive, communicative nature of dialogue and argue that it is more feasible to model the speaker roles of agent and user separately, enabling the agent to adhere to its role consistently. We propose an efficient Multi-round Interactive Dialogue Tuning (Midi-Tuning) framework. It models the agent and user individually with two adapters built upon large language models, where they utilize utterances round by round in alternating order and are tuned via a round-level memory caching mechanism. Extensive experiments demonstrate that, our",
    "link": "https://arxiv.org/abs/2402.06967",
    "context": "Title: Instruct Once, Chat Consistently in Multiple Rounds: An Efficient Tuning Framework for Dialogue\nAbstract: Tuning pretrained language models for dialogue generation has been a prevalent paradigm for building capable dialogue agents. Yet, traditional tuning narrowly views dialogue generation as resembling other language generation tasks, ignoring the role disparities between two speakers and the multi-round interactive process that dialogues ought to be. Such a manner leads to unsatisfactory chat consistency of the built agent. In this work, we emphasize the interactive, communicative nature of dialogue and argue that it is more feasible to model the speaker roles of agent and user separately, enabling the agent to adhere to its role consistently. We propose an efficient Multi-round Interactive Dialogue Tuning (Midi-Tuning) framework. It models the agent and user individually with two adapters built upon large language models, where they utilize utterances round by round in alternating order and are tuned via a round-level memory caching mechanism. Extensive experiments demonstrate that, our",
    "path": "papers/24/02/2402.06967.json",
    "total_tokens": 896,
    "translated_title": "一次指导，多轮稳定对话：对话的高效调整框架",
    "translated_abstract": "调整预训练语言模型以实现对话生成已成为构建能力强大的对话代理的主流范式。然而，传统的调整方式狭隘地将对话生成视为类似其他语言生成任务的过程，忽视了对话者之间的角色差异和对话应具备的多轮交互过程。这种方式导致了所构建代理人的对话一致性不尽如人意。在本研究中，我们强调对话的交互性和沟通性，并认为分别对代理人和用户的讲话者角色进行建模更为可行，使得代理人能够保持一致的角色。我们提出了一种有效的多轮交互对话调整（Midi-Tuning）框架。该框架使用基于大型语言模型的两个适配器分别对代理人和用户进行建模，它们按轮次交替使用话语，并通过轮次级内存缓存机制进行调整。大量实验证明，我们的方法可以有效提高对话代理的一致性和稳定性。",
    "tldr": "本论文提出了一种名为Midi-Tuning的多轮交互对话调整框架，通过分别对代理人和用户建模，并利用轮次级内存缓存机制进行调整，实现了对话代理的一致性和稳定性。"
}