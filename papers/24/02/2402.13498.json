{
    "title": "The Lay Person's Guide to Biomedicine: Orchestrating Large Language Models",
    "abstract": "arXiv:2402.13498v1 Announce Type: new  Abstract: Automated lay summarisation (LS) aims to simplify complex technical documents into a more accessible format to non-experts. Existing approaches using pre-trained language models, possibly augmented with external background knowledge, tend to struggle with effective simplification and explanation. Moreover, automated methods that can effectively assess the `layness' of generated summaries are lacking. Recently, large language models (LLMs) have demonstrated a remarkable capacity for text simplification, background information generation, and text evaluation. This has motivated our systematic exploration into using LLMs to generate and evaluate lay summaries of biomedical articles. We propose a novel \\textit{Explain-then-Summarise} LS framework, which leverages LLMs to generate high-quality background knowledge to improve supervised LS. We also evaluate the performance of LLMs for zero-shot LS and propose two novel LLM-based LS evaluation ",
    "link": "https://arxiv.org/abs/2402.13498",
    "context": "Title: The Lay Person's Guide to Biomedicine: Orchestrating Large Language Models\nAbstract: arXiv:2402.13498v1 Announce Type: new  Abstract: Automated lay summarisation (LS) aims to simplify complex technical documents into a more accessible format to non-experts. Existing approaches using pre-trained language models, possibly augmented with external background knowledge, tend to struggle with effective simplification and explanation. Moreover, automated methods that can effectively assess the `layness' of generated summaries are lacking. Recently, large language models (LLMs) have demonstrated a remarkable capacity for text simplification, background information generation, and text evaluation. This has motivated our systematic exploration into using LLMs to generate and evaluate lay summaries of biomedical articles. We propose a novel \\textit{Explain-then-Summarise} LS framework, which leverages LLMs to generate high-quality background knowledge to improve supervised LS. We also evaluate the performance of LLMs for zero-shot LS and propose two novel LLM-based LS evaluation ",
    "path": "papers/24/02/2402.13498.json",
    "total_tokens": 896,
    "translated_title": "生物医学的平民指南：编排大型语言模型",
    "translated_abstract": "《arXiv：2402.13498v1》公告类型：新的摘要：自动化的平民总结（LS）旨在将复杂的技术文件简化为更易于非专业人士理解的格式。现有的使用预训练语言模型，可能辅以外部背景知识的方法往往在有效简化和解释方面存在困难。此外，能够有效评估生成摘要的“平民性”的自动化方法也缺乏。最近，大型语言模型（LLMs）展示了在文本简化、背景信息生成和文本评估方面的显着能力。这激发了我们对使用LLMs生成和评估生物医学文章的平民总结进行系统性探索。我们提出了一种新颖的“先解释后总结”LS框架，利用LLMs生成高质量的背景知识以改进监督的LS。我们还评估LLMs在零-shot LS方面的性能，并提出了两种基于LLM的新颖LS评估方法。",
    "tldr": "利用大型语言模型生成和评估生物医学文章的平民总结，提出了Explain-then-Summarise的新LS框架，并评估了LLMs在零-shot LS方面的表现和提出了两种新的LLM-based LS评估方法。",
    "en_tdlr": "Using large language models to generate and evaluate lay summaries of biomedical articles, proposing a new LS framework called Explain-then-Summarise, evaluating the performance of LLMs for zero-shot LS, and introducing two novel LLM-based LS evaluation methods."
}