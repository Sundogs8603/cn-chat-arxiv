{
    "title": "Direct Acquisition Optimization for Low-Budget Active Learning",
    "abstract": "Active Learning (AL) has gained prominence in integrating data-intensive machine learning (ML) models into domains with limited labeled data. However, its effectiveness diminishes significantly when the labeling budget is low. In this paper, we first empirically observe the performance degradation of existing AL algorithms in the low-budget settings, and then introduce Direct Acquisition Optimization (DAO), a novel AL algorithm that optimizes sample selections based on expected true loss reduction. Specifically, DAO utilizes influence functions to update model parameters and incorporates an additional acquisition strategy to mitigate bias in loss estimation. This approach facilitates a more accurate estimation of the overall error reduction, without extensive computations or reliance on labeled data. Experiments demonstrate DAO's effectiveness in low budget settings, outperforming state-of-the-arts approaches across seven benchmarks.",
    "link": "https://arxiv.org/abs/2402.06045",
    "context": "Title: Direct Acquisition Optimization for Low-Budget Active Learning\nAbstract: Active Learning (AL) has gained prominence in integrating data-intensive machine learning (ML) models into domains with limited labeled data. However, its effectiveness diminishes significantly when the labeling budget is low. In this paper, we first empirically observe the performance degradation of existing AL algorithms in the low-budget settings, and then introduce Direct Acquisition Optimization (DAO), a novel AL algorithm that optimizes sample selections based on expected true loss reduction. Specifically, DAO utilizes influence functions to update model parameters and incorporates an additional acquisition strategy to mitigate bias in loss estimation. This approach facilitates a more accurate estimation of the overall error reduction, without extensive computations or reliance on labeled data. Experiments demonstrate DAO's effectiveness in low budget settings, outperforming state-of-the-arts approaches across seven benchmarks.",
    "path": "papers/24/02/2402.06045.json",
    "total_tokens": 814,
    "translated_title": "针对低预算主动学习的直接采集优化",
    "translated_abstract": "主动学习（AL）在将数据密集型机器学习（ML）模型集成到有限标记数据领域中变得越来越重要，然而，当标记预算较低时其效果显著降低。在本文中，首先我们经验性地观察了现有低预算设置下AL算法的性能退化，并引入了一种新的AL算法——直接采集优化（DAO），该算法根据期望真实损失减少来优化样本选择。具体而言，DAO利用影响函数来更新模型参数，并结合额外的采集策略来减轻损失估计中的偏差。这种方法能够更准确地估计总体误差减少，而无需进行大量计算或依赖于有标签的数据。实验证明，在七个基准测试中，DAO在低预算设置下的有效性超过了最先进的方法。",
    "tldr": "本研究提出了一种针对低预算主动学习的直接采集优化算法（DAO），该算法可以更准确地估计总体误差减少，效果超过了现有的方法。"
}