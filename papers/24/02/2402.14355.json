{
    "title": "Rule or Story, Which is a Better Commonsense Expression for Talking with Large Language Models?",
    "abstract": "arXiv:2402.14355v1 Announce Type: new  Abstract: Building machines with commonsense has been a longstanding challenge in NLP due to the reporting bias of commonsense rules and the exposure bias of rule-based commonsense reasoning. In contrast, humans convey and pass down commonsense implicitly through stories. This paper investigates the inherent commonsense ability of large language models (LLMs) expressed through storytelling. We systematically investigate and compare stories and rules for retrieving and leveraging commonsense in LLMs. Experimental results on 28 commonsense QA datasets show that stories outperform rules as the expression for retrieving commonsense from LLMs, exhibiting higher generation confidence and commonsense accuracy. Moreover, stories are the more effective commonsense expression for answering questions regarding daily events, while rules are more effective for scientific questions. This aligns with the reporting bias of commonsense in text corpora. We further ",
    "link": "https://arxiv.org/abs/2402.14355",
    "context": "Title: Rule or Story, Which is a Better Commonsense Expression for Talking with Large Language Models?\nAbstract: arXiv:2402.14355v1 Announce Type: new  Abstract: Building machines with commonsense has been a longstanding challenge in NLP due to the reporting bias of commonsense rules and the exposure bias of rule-based commonsense reasoning. In contrast, humans convey and pass down commonsense implicitly through stories. This paper investigates the inherent commonsense ability of large language models (LLMs) expressed through storytelling. We systematically investigate and compare stories and rules for retrieving and leveraging commonsense in LLMs. Experimental results on 28 commonsense QA datasets show that stories outperform rules as the expression for retrieving commonsense from LLMs, exhibiting higher generation confidence and commonsense accuracy. Moreover, stories are the more effective commonsense expression for answering questions regarding daily events, while rules are more effective for scientific questions. This aligns with the reporting bias of commonsense in text corpora. We further ",
    "path": "papers/24/02/2402.14355.json",
    "total_tokens": 848,
    "translated_title": "是规则好还是故事更好的常识表达方式，基于大型语言模型？",
    "translated_abstract": "建立具备常识的机器一直是自然语言处理中长期存在的挑战，这是由于常识规则的报告偏差和基于规则的常识推理的暴露偏差所致。相反，人类通过故事隐含地传递和传承常识。本文研究了大型语言模型（LLMs）通过讲故事来表达固有的常识能力。我们系统地研究和比较了故事和规则在从LLMs检索和利用常识方面的表现。在28个常识问答数据集上的实验结果表明，故事优于规则作为从LLMs检索常识的表达形式，在生成信心和常识准确性方面表现更好。此外，故事是回答有关日常事件的问题的更有效常识表达方式，而规则对于科学问题更有效。这与文本语料库中的常识报告偏差一致。",
    "tldr": "本文研究了大型语言模型通过讲故事来表达固有的常识能力，实验结果显示故事优于规则作为从LLMs检索常识的表达形式。",
    "en_tdlr": "This paper investigates the inherent commonsense ability of large language models expressed through storytelling, with experimental results showing that stories outperform rules as the expression for retrieving commonsense from LLMs."
}