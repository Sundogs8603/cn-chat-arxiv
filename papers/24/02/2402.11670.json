{
    "title": "Challenging the Black Box: A Comprehensive Evaluation of Attribution Maps of CNN Applications in Agriculture and Forestry",
    "abstract": "arXiv:2402.11670v1 Announce Type: cross  Abstract: In this study, we explore the explainability of neural networks in agriculture and forestry, specifically in fertilizer treatment classification and wood identification. The opaque nature of these models, often considered 'black boxes', is addressed through an extensive evaluation of state-of-the-art Attribution Maps (AMs), also known as class activation maps (CAMs) or saliency maps. Our comprehensive qualitative and quantitative analysis of these AMs uncovers critical practical limitations. Findings reveal that AMs frequently fail to consistently highlight crucial features and often misalign with the features considered important by domain experts. These discrepancies raise substantial questions about the utility of AMs in understanding the decision-making process of neural networks. Our study provides critical insights into the trustworthiness and practicality of AMs within the agriculture and forestry sectors, thus facilitating a be",
    "link": "https://arxiv.org/abs/2402.11670",
    "context": "Title: Challenging the Black Box: A Comprehensive Evaluation of Attribution Maps of CNN Applications in Agriculture and Forestry\nAbstract: arXiv:2402.11670v1 Announce Type: cross  Abstract: In this study, we explore the explainability of neural networks in agriculture and forestry, specifically in fertilizer treatment classification and wood identification. The opaque nature of these models, often considered 'black boxes', is addressed through an extensive evaluation of state-of-the-art Attribution Maps (AMs), also known as class activation maps (CAMs) or saliency maps. Our comprehensive qualitative and quantitative analysis of these AMs uncovers critical practical limitations. Findings reveal that AMs frequently fail to consistently highlight crucial features and often misalign with the features considered important by domain experts. These discrepancies raise substantial questions about the utility of AMs in understanding the decision-making process of neural networks. Our study provides critical insights into the trustworthiness and practicality of AMs within the agriculture and forestry sectors, thus facilitating a be",
    "path": "papers/24/02/2402.11670.json",
    "total_tokens": 905,
    "translated_title": "挑战黑匣子：对在农业和林业中CNN应用的归因图进行全面评估",
    "translated_abstract": "在这项研究中，我们探讨神经网络在农业和林业中的可解释性，特别是在肥料处理分类和木材识别方面。通过对最先进的归因图进行全面评估，也称为类激活图或显著性图，解决了这些模型的不透明性，通常被认为是“黑匣子”。我们对这些归因图进行了全面的定性和定量分析，揭示了关键实际局限性。研究结果表明，归因图经常无法一致地突出关键特征，并且经常与领域专家认为重要的特征不一致。这些差异引发了关于归因图在理解神经网络决策过程中实用性的重大问题。我们的研究为农业和林业部门内归因图的可信度和实用性提供了关键见解，从而促进了一种",
    "tldr": "对于在农业和林业中CNN应用的归因图进行全面评估，发现这些图表往往未能准确突出关键特征，与领域专家认为重要的特征不一致，这引发了对于其在理解神经网络决策过程中实用性的重大问题。"
}