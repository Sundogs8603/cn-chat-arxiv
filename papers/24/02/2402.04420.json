{
    "title": "Measuring machine learning harms from stereotypes: requires understanding who is being harmed by which errors in what ways",
    "abstract": "As machine learning applications proliferate, we need an understanding of their potential for harm. However, current fairness metrics are rarely grounded in human psychological experiences of harm. Drawing on the social psychology of stereotypes, we use a case study of gender stereotypes in image search to examine how people react to machine learning errors. First, we use survey studies to show that not all machine learning errors reflect stereotypes nor are equally harmful. Then, in experimental studies we randomly expose participants to stereotype-reinforcing, -violating, and -neutral machine learning errors. We find stereotype-reinforcing errors induce more experientially (i.e., subjectively) harmful experiences, while having minimal changes to cognitive beliefs, attitudes, or behaviors. This experiential harm impacts women more than men. However, certain stereotype-violating errors are more experientially harmful for men, potentially due to perceived threats to masculinity. We conc",
    "link": "https://arxiv.org/abs/2402.04420",
    "context": "Title: Measuring machine learning harms from stereotypes: requires understanding who is being harmed by which errors in what ways\nAbstract: As machine learning applications proliferate, we need an understanding of their potential for harm. However, current fairness metrics are rarely grounded in human psychological experiences of harm. Drawing on the social psychology of stereotypes, we use a case study of gender stereotypes in image search to examine how people react to machine learning errors. First, we use survey studies to show that not all machine learning errors reflect stereotypes nor are equally harmful. Then, in experimental studies we randomly expose participants to stereotype-reinforcing, -violating, and -neutral machine learning errors. We find stereotype-reinforcing errors induce more experientially (i.e., subjectively) harmful experiences, while having minimal changes to cognitive beliefs, attitudes, or behaviors. This experiential harm impacts women more than men. However, certain stereotype-violating errors are more experientially harmful for men, potentially due to perceived threats to masculinity. We conc",
    "path": "papers/24/02/2402.04420.json",
    "total_tokens": 998,
    "translated_title": "测量机器学习中的刻板印象伤害：需要了解谁正在受到哪些错误以及以何种方式受到伤害",
    "translated_abstract": "随着机器学习应用的普及，我们需要了解它们可能造成的伤害。然而，当前的公平性指标很少基于人类对伤害的心理体验。借鉴刻板印象的社会心理学，我们以图像搜索中的性别刻板印象为案例研究，研究了人们对机器学习错误的反应。首先，我们使用调查研究表明，并非所有的机器学习错误都反映了刻板印象，也没有同样的伤害程度。然后，在实验研究中，我们随机使参与者接触到强化、违反和中性的机器学习错误。我们发现，强化刻板印象的错误引起更多主观上的伤害体验，但对认知信念、态度或行为的改变很小。这种体验上的伤害对女性影响更大。然而，某些违反刻板印象的错误对男性产生更大的主观上的伤害，可能是由于对男性阳刚性的威胁感知。",
    "tldr": "通过调查研究和实验研究，本文研究了机器学习错误对人们的影响，发现强化刻板印象的错误引起更多主观上的伤害体验，而违反刻板印象的错误对男性产生更大的主观上的伤害，有助于我们理解机器学习在引发刻板印象和伤害方面的作用。"
}