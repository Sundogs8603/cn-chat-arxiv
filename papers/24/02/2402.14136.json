{
    "title": "GDTM: An Indoor Geospatial Tracking Dataset with Distributed Multimodal Sensors",
    "abstract": "arXiv:2402.14136v1 Announce Type: cross  Abstract: Constantly locating moving objects, i.e., geospatial tracking, is essential for autonomous building infrastructure. Accurate and robust geospatial tracking often leverages multimodal sensor fusion algorithms, which require large datasets with time-aligned, synchronized data from various sensor types. However, such datasets are not readily available. Hence, we propose GDTM, a nine-hour dataset for multimodal object tracking with distributed multimodal sensors and reconfigurable sensor node placements. Our dataset enables the exploration of several research problems, such as optimizing architectures for processing multimodal data, and investigating models' robustness to adverse sensing conditions and sensor placement variances. A GitHub repository containing the code, sample data, and checkpoints of this work is available at https://github.com/nesl/GDTM.",
    "link": "https://arxiv.org/abs/2402.14136",
    "context": "Title: GDTM: An Indoor Geospatial Tracking Dataset with Distributed Multimodal Sensors\nAbstract: arXiv:2402.14136v1 Announce Type: cross  Abstract: Constantly locating moving objects, i.e., geospatial tracking, is essential for autonomous building infrastructure. Accurate and robust geospatial tracking often leverages multimodal sensor fusion algorithms, which require large datasets with time-aligned, synchronized data from various sensor types. However, such datasets are not readily available. Hence, we propose GDTM, a nine-hour dataset for multimodal object tracking with distributed multimodal sensors and reconfigurable sensor node placements. Our dataset enables the exploration of several research problems, such as optimizing architectures for processing multimodal data, and investigating models' robustness to adverse sensing conditions and sensor placement variances. A GitHub repository containing the code, sample data, and checkpoints of this work is available at https://github.com/nesl/GDTM.",
    "path": "papers/24/02/2402.14136.json",
    "total_tokens": 871,
    "translated_title": "GDTM：一个具有分布式多模态传感器的室内地理空间跟踪数据集",
    "translated_abstract": "不断定位移动物体，即地理空间跟踪，对于自主建筑基础设施至关重要。准确而稳健的地理空间跟踪通常利用多模态传感器融合算法，这些算法需要具有来自各种传感器类型的时间对齐、同步数据的大型数据集。然而，这样的数据集并不readily可获得。因此，我们提出了GDTM，一个具有分布式多模态传感器和可重新配置传感器节点位置的九小时多模态物体跟踪数据集。我们的数据集使得能够探索几个研究问题，例如优化处理多模态数据的体系结构，以及研究模型对恶劣传感条件和传感器放置变化的稳健性。这项工作的代码、示例数据和检查点可在https://github.com/nesl/GDTM 上找到。",
    "tldr": "GDTM提供了一个新的室内地理空间跟踪数据集，包含了分布式多模态传感器和可重新配置传感器节点位置，可以用于研究处理多模态数据的体系结构优化和模型对不良传感条件和传感器位置变化的稳健性。",
    "en_tdlr": "GDTM provides a new indoor geospatial tracking dataset with distributed multimodal sensors and reconfigurable sensor node placements, which can be utilized for research on optimizing architectures for processing multimodal data and investigating models' robustness to adverse sensing conditions and sensor placement variances."
}