{
    "title": "Translation Errors Significantly Impact Low-Resource Languages in Cross-Lingual Learning",
    "abstract": "Popular benchmarks (e.g., XNLI) used to evaluate cross-lingual language understanding consist of parallel versions of English evaluation sets in multiple target languages created with the help of professional translators. When creating such parallel data, it is critical to ensure high-quality translations for all target languages for an accurate characterization of cross-lingual transfer. In this work, we find that translation inconsistencies do exist and interestingly they disproportionally impact low-resource languages in XNLI. To identify such inconsistencies, we propose measuring the gap in performance between zero-shot evaluations on the human-translated and machine-translated target text across multiple target languages; relatively large gaps are indicative of translation errors. We also corroborate that translation errors exist for two target languages, namely Hindi and Urdu, by doing a manual reannotation of human-translated test instances in these two languages and finding poo",
    "link": "https://arxiv.org/abs/2402.02080",
    "context": "Title: Translation Errors Significantly Impact Low-Resource Languages in Cross-Lingual Learning\nAbstract: Popular benchmarks (e.g., XNLI) used to evaluate cross-lingual language understanding consist of parallel versions of English evaluation sets in multiple target languages created with the help of professional translators. When creating such parallel data, it is critical to ensure high-quality translations for all target languages for an accurate characterization of cross-lingual transfer. In this work, we find that translation inconsistencies do exist and interestingly they disproportionally impact low-resource languages in XNLI. To identify such inconsistencies, we propose measuring the gap in performance between zero-shot evaluations on the human-translated and machine-translated target text across multiple target languages; relatively large gaps are indicative of translation errors. We also corroborate that translation errors exist for two target languages, namely Hindi and Urdu, by doing a manual reannotation of human-translated test instances in these two languages and finding poo",
    "path": "papers/24/02/2402.02080.json",
    "total_tokens": 956,
    "translated_title": "翻译错误在交叉语言学习中对低资源语言有显著影响",
    "translated_abstract": "用于评估交叉语言理解的流行基准（例如XNLI）由英语评估集的多个目标语言平行版本组成，这些平行版本是在专业翻译人员的帮助下创建的。创建这样的平行数据时，对于准确描述交叉语言转移非常重要的是确保所有目标语言的高质量翻译。在本研究中，我们发现翻译不一致确实存在，并且有趣的是它们对XNLI中的低资源语言有不成比例的影响。为了识别这种不一致性，我们提出了一种通过测量在多个目标语言上对人工翻译和机器翻译目标文本进行零-shot评估的表现差距来衡量翻译错误的方法；表现差距较大表明存在翻译错误。我们还通过对这两种目标语言（印地语和乌尔都语）进行人工重新注释的方式，证实了翻译错误的存在。",
    "tldr": "研究发现，在交叉语言学习中，翻译错误对低资源语言有显著影响。通过测量在多个目标语言上的人工翻译和机器翻译的目标文本的零-shot评估的表现差距，可以识别翻译错误。此外，该研究还证实了印地语和乌尔都语存在翻译错误。",
    "en_tdlr": "The study finds that translation errors significantly impact low-resource languages in cross-lingual learning. By measuring the performance gap between zero-shot evaluations on human-translated and machine-translated target text across multiple languages, translation errors can be identified. Additionally, the study confirms the existence of translation errors in Hindi and Urdu."
}