{
    "title": "Under manipulations, are some AI models harder to audit?",
    "abstract": "arXiv:2402.09043v1 Announce Type: new Abstract: Auditors need robust methods to assess the compliance of web platforms with the law. However, since they hardly ever have access to the algorithm, implementation, or training data used by a platform, the problem is harder than a simple metric estimation. Within the recent framework of manipulation-proof auditing, we study in this paper the feasibility of robust audits in realistic settings, in which models exhibit large capacities. We first prove a constraining result: if a web platform uses models that may fit any data, no audit strategy -- whether active or not -- can outperform random sampling when estimating properties such as demographic parity. To better understand the conditions under which state-of-the-art auditing techniques may remain competitive, we then relate the manipulability of audits to the capacity of the targeted models, using the Rademacher complexity. We empirically validate these results on popular models of increasi",
    "link": "https://arxiv.org/abs/2402.09043",
    "context": "Title: Under manipulations, are some AI models harder to audit?\nAbstract: arXiv:2402.09043v1 Announce Type: new Abstract: Auditors need robust methods to assess the compliance of web platforms with the law. However, since they hardly ever have access to the algorithm, implementation, or training data used by a platform, the problem is harder than a simple metric estimation. Within the recent framework of manipulation-proof auditing, we study in this paper the feasibility of robust audits in realistic settings, in which models exhibit large capacities. We first prove a constraining result: if a web platform uses models that may fit any data, no audit strategy -- whether active or not -- can outperform random sampling when estimating properties such as demographic parity. To better understand the conditions under which state-of-the-art auditing techniques may remain competitive, we then relate the manipulability of audits to the capacity of the targeted models, using the Rademacher complexity. We empirically validate these results on popular models of increasi",
    "path": "papers/24/02/2402.09043.json",
    "total_tokens": 926,
    "translated_title": "人工智能模型的可审计性：在操纵下，是否有些模型更难以审计？",
    "translated_abstract": "审计员需要稳健的方法来评估网络平台是否符合法律规定。然而，由于他们很难获得平台使用的算法、实现或训练数据，这个问题比简单的度量估计更难。在最近的防操纵审计框架下，我们研究了在现实情况下进行稳健审计的可行性，其中模型具有较大的容量。我们首先证明了一个约束性结果：如果一个网络平台使用的模型可以适应任何数据，那么无论是主动还是非主动的审计策略，在估计诸如人口平衡性等性质时都无法超越随机抽样。为了更好地理解最先进的审计技术在何种条件下仍然具有竞争力，我们然后通过使用Rademacher复杂度将审计的可操纵性与目标模型的容量相关联。我们通过实证验证这些结果在流行的增加模型上的有效性。",
    "tldr": "本论文研究在操纵下，是否有些人工智能模型更难以审计，在模型可以适应任何数据的情况下，无论是主动还是非主动的审计策略都无法超越随机抽样。研究发现审计的可操纵性与目标模型的容量有关。",
    "en_tdlr": "This paper investigates whether some AI models are harder to audit under manipulations. The study finds that in scenarios where the models can fit any data, no audit strategy can outperform random sampling. The research also reveals a relationship between the manipulability of audits and the capacity of the targeted models."
}