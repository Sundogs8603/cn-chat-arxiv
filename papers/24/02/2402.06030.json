{
    "title": "Game-theoretic Counterfactual Explanation for Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have been a powerful tool for node classification tasks in complex networks. However, their decision-making processes remain a black-box to users, making it challenging to understand the reasoning behind their predictions. Counterfactual explanations (CFE) have shown promise in enhancing the interpretability of machine learning models. Prior approaches to compute CFE for GNNS often are learning-based approaches that require training additional graphs. In this paper, we propose a semivalue-based, non-learning approach to generate CFE for node classification tasks, eliminating the need for any additional training. Our results reveals that computing Banzhaf values requires lower sample complexity in identifying the counterfactual explanations compared to other popular methods such as computing Shapley values. Our empirical evidence indicates computing Banzhaf values can achieve up to a fourfold speed up compared to Shapley values. We also design a thresholding",
    "link": "https://arxiv.org/abs/2402.06030",
    "context": "Title: Game-theoretic Counterfactual Explanation for Graph Neural Networks\nAbstract: Graph Neural Networks (GNNs) have been a powerful tool for node classification tasks in complex networks. However, their decision-making processes remain a black-box to users, making it challenging to understand the reasoning behind their predictions. Counterfactual explanations (CFE) have shown promise in enhancing the interpretability of machine learning models. Prior approaches to compute CFE for GNNS often are learning-based approaches that require training additional graphs. In this paper, we propose a semivalue-based, non-learning approach to generate CFE for node classification tasks, eliminating the need for any additional training. Our results reveals that computing Banzhaf values requires lower sample complexity in identifying the counterfactual explanations compared to other popular methods such as computing Shapley values. Our empirical evidence indicates computing Banzhaf values can achieve up to a fourfold speed up compared to Shapley values. We also design a thresholding",
    "path": "papers/24/02/2402.06030.json",
    "total_tokens": 889,
    "translated_title": "博弈论对图神经网络的反事实解释",
    "translated_abstract": "图神经网络（GNNs）在复杂网络中的节点分类任务中是一种强大的工具。然而，它们的决策过程对用户来说仍然是一个黑盒子，这使得理解其预测背后的推理变得困难。反事实解释（CFE）已经显示出增强机器学习模型可解释性的潜力。先前的基于学习的方法计算GNNs的CFE通常需要训练额外的图形。在本文中，我们提出了一种基于半值的、非学习的方法来生成节点分类任务的CFE，消除了任何额外训练的需要。我们的结果表明，与计算Shapley值等其他流行方法相比，计算Banzhaf值需要更低的样本复杂性来识别反事实解释。我们的经验证据表明，与Shapley值相比，计算Banzhaf值可以实现四倍的加速。我们还设计了一个阈值化方法。",
    "tldr": "本文提出了一种半值法的、非学习的方法来生成图神经网络的反事实解释，消除了额外训练的需要。与其他流行的方法相比，计算Banzhaf值在识别反事实解释时需要更低的样本复杂性，并且可以实现四倍的加速。"
}