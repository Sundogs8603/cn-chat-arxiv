{
    "title": "TimeSeriesBench: An Industrial-Grade Benchmark for Time Series Anomaly Detection Models",
    "abstract": "arXiv:2402.10802v1 Announce Type: new  Abstract: Driven by the proliferation of real-world application scenarios and scales, time series anomaly detection (TSAD) has attracted considerable scholarly and industrial interest. However, existing algorithms exhibit a gap in terms of training paradigm, online detection paradigm, and evaluation criteria when compared to the actual needs of real-world industrial systems. Firstly, current algorithms typically train a specific model for each individual time series. In a large-scale online system with tens of thousands of curves, maintaining such a multitude of models is impractical. The performance of using merely one single unified model to detect anomalies remains unknown. Secondly, most TSAD models are trained on the historical part of a time series and are tested on its future segment. In distributed systems, however, there are frequent system deployments and upgrades, with new, previously unseen time series emerging daily. The performance o",
    "link": "https://arxiv.org/abs/2402.10802",
    "context": "Title: TimeSeriesBench: An Industrial-Grade Benchmark for Time Series Anomaly Detection Models\nAbstract: arXiv:2402.10802v1 Announce Type: new  Abstract: Driven by the proliferation of real-world application scenarios and scales, time series anomaly detection (TSAD) has attracted considerable scholarly and industrial interest. However, existing algorithms exhibit a gap in terms of training paradigm, online detection paradigm, and evaluation criteria when compared to the actual needs of real-world industrial systems. Firstly, current algorithms typically train a specific model for each individual time series. In a large-scale online system with tens of thousands of curves, maintaining such a multitude of models is impractical. The performance of using merely one single unified model to detect anomalies remains unknown. Secondly, most TSAD models are trained on the historical part of a time series and are tested on its future segment. In distributed systems, however, there are frequent system deployments and upgrades, with new, previously unseen time series emerging daily. The performance o",
    "path": "papers/24/02/2402.10802.json",
    "total_tokens": 860,
    "translated_title": "TimeSeriesBench：面向时间序列异常检测模型的工业级基准",
    "translated_abstract": "由于实际应用场景和规模的蔓延，时间序列异常检测（TSAD）引起了学术界和工业界的广泛兴趣。然而，与实际工业系统的需求相比，现有算法在训练范式、在线检测范式和评估标准方面存在差距。当前算法通常为每个单独的时间序列训练一个特定模型，然而在具有数以万计曲线的大规模在线系统中，维护这么多模型是不切实际的。仅使用一个统一模型来检测异常的性能尚不明确。大多数TSAD模型都是在时间序列的历史部分上进行训练，并在其未来部分上进行测试。然而，在分布式系统中，经常部署和升级系统，每天都会出现新的、以前没有见过的时间序列。使用历史数据所训练模型直接应用于新时间序列的性能也不明确。",
    "tldr": "时间序列异常检测模型的工业级基准TimeSeriesBench填补了当前算法在训练范式、在线检测范式和评估标准方面与实际需求之间的差距。",
    "en_tdlr": "TimeSeriesBench, an industrial-grade benchmark for time series anomaly detection models, addresses the gap between existing algorithms and the actual needs of real-world industrial systems in terms of training paradigm, online detection paradigm, and evaluation criteria."
}