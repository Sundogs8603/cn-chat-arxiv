{
    "title": "Attitudes Towards and Knowledge of Non-Consensual Synthetic Intimate Imagery in 10 Countries",
    "abstract": "Deepfake technology tools have become ubiquitous, \"democratizing\" the ability to manipulate images and videos. One popular use of such technology is the creation of sexually explicit content, which can then be posted and shared widely on the internet. This article examines attitudes and behaviors related to non-consensual synthetic intimate imagery (NSII) across over 16,000 respondents in 10 countries. Despite nascent societal awareness of NSII, NSII behaviors were considered harmful. In regards to prevalence, 2.2% of all respondents indicated personal victimization, and 1.8% all of respondents indicated perpetration behaviors. Respondents from countries with relevant legislation also reported perpetration and victimization experiences, suggesting legislative action alone is not a sufficient solution to deter perpetration. Technical considerations to reduce harms may include suggestions for how individuals can better monitor their presence online, as well as enforced platform policies ",
    "link": "https://arxiv.org/abs/2402.01721",
    "context": "Title: Attitudes Towards and Knowledge of Non-Consensual Synthetic Intimate Imagery in 10 Countries\nAbstract: Deepfake technology tools have become ubiquitous, \"democratizing\" the ability to manipulate images and videos. One popular use of such technology is the creation of sexually explicit content, which can then be posted and shared widely on the internet. This article examines attitudes and behaviors related to non-consensual synthetic intimate imagery (NSII) across over 16,000 respondents in 10 countries. Despite nascent societal awareness of NSII, NSII behaviors were considered harmful. In regards to prevalence, 2.2% of all respondents indicated personal victimization, and 1.8% all of respondents indicated perpetration behaviors. Respondents from countries with relevant legislation also reported perpetration and victimization experiences, suggesting legislative action alone is not a sufficient solution to deter perpetration. Technical considerations to reduce harms may include suggestions for how individuals can better monitor their presence online, as well as enforced platform policies ",
    "path": "papers/24/02/2402.01721.json",
    "total_tokens": 1010,
    "translated_title": "在10个国家的非自愿合成亲密图像的态度和知识",
    "translated_abstract": "深度伪造技术工具已经无处不在，\"民主化\"了操纵图像和视频的能力。这种技术的一个流行用途是创建性暴力内容，然后在互联网上广泛发布和共享。本文通过对10个国家的超过16,000名受访者的研究，研究了与非自愿合成亲密图像（NSII）相关的态度和行为。尽管社会对NSII的认识尚处于初级阶段，但NSII行为被认为是有害的。在普遍性方面，所有受访者中有2.2%的人表示曾受害，1.8%的人表示曾参与过这种行为。来自具有相关立法的国家的受访者也报告了参与和受害经历，这表明单靠立法行动并不足以阻止参与者的行为。减少伤害的技术考虑可能包括建议人们如何更好地监控自己在网上的存在，并执行平台政策。",
    "tldr": "本文研究了10个国家超过16,000名受访者对非自愿合成亲密图像的态度和行为；尽管社会对此仍认识不足，但这种行为被认为有害；约有2.2%的受访者表示曾受害，1.8%的受访者表示曾参与过此类行为；单靠立法行动并不足以解决问题，建议技术和平台政策的改进来减少伤害。",
    "en_tdlr": "This article examines attitudes and behaviors related to non-consensual synthetic intimate imagery (NSII) across 10 countries with over 16,000 respondents; despite limited societal awareness of NSII, it is considered harmful; approximately 2.2% of respondents reported victimization, and 1.8% reported perpetration; legislative action alone is insufficient, suggesting the need for technical and platform policy improvements to reduce harm."
}