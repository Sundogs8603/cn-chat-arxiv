{
    "title": "On the Self-Verification Limitations of Large Language Models on Reasoning and Planning Tasks",
    "abstract": "There has been considerable divergence of opinion on the reasoning abilities of Large Language Models (LLMs). While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that LLMs can self-critique and improve their own solutions in an iterative fashion. This belief seemingly rests on the assumption that verification of correctness should be easier than generation--a rather classical argument from computational complexity--which should be irrelevant to LLMs to the extent that what they are doing is approximate retrieval. In this paper, we set out to systematically investigate the effectiveness of iterative prompting in the context of reasoning and planning. We present a principled empirical study of the performance of GPT-4 in three domains: Game of 24, Graph Coloring, and STRIPS planning. We experiment both with the model critiq",
    "link": "https://arxiv.org/abs/2402.08115",
    "context": "Title: On the Self-Verification Limitations of Large Language Models on Reasoning and Planning Tasks\nAbstract: There has been considerable divergence of opinion on the reasoning abilities of Large Language Models (LLMs). While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that LLMs can self-critique and improve their own solutions in an iterative fashion. This belief seemingly rests on the assumption that verification of correctness should be easier than generation--a rather classical argument from computational complexity--which should be irrelevant to LLMs to the extent that what they are doing is approximate retrieval. In this paper, we set out to systematically investigate the effectiveness of iterative prompting in the context of reasoning and planning. We present a principled empirical study of the performance of GPT-4 in three domains: Game of 24, Graph Coloring, and STRIPS planning. We experiment both with the model critiq",
    "path": "papers/24/02/2402.08115.json",
    "total_tokens": 831,
    "translated_title": "关于大型语言模型在推理和规划任务中的自我验证限制问题",
    "translated_abstract": "关于大型语言模型（LLMs）的推理能力，存在着较大的观点差异。尽管最初对于推理可能会随着规模的扩大自动出现的乐观情绪已经受到了一系列反例的抑制，从乘法到简单规划，但仍然普遍认为LLMs可以自我批判并迭代改进其解决方案。这种信念似乎建立在验证正确性比生成更容易的假设上，这是一个典型的计算复杂性论证，对于LLMs来说应该是无关紧要的，因为它们所做的是近似检索。在本文中，我们系统地研究了推理和规划环境中迭代提示的有效性。 我们对GPT-4在三个领域（24点游戏、图着色和STRIPS规划）的性能进行了有原则的实证研究。我们对模型的批判性实验进行了探索。",
    "tldr": "这项研究对大型语言模型在推理和规划任务中的自我验证能力进行了系统研究，并发现了迭代提示的有效性。",
    "en_tdlr": "This study systematically investigates the self-verification capabilities of large language models in reasoning and planning tasks, and finds that iterative prompting is effective."
}