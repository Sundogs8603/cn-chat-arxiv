{
    "title": "DisDet: Exploring Detectability of Backdoor Attack on Diffusion Models",
    "abstract": "In the exciting generative AI era, the diffusion model has emerged as a very powerful and widely adopted content generation and editing tool for various data modalities, making the study of their potential security risks very necessary and critical. Very recently, some pioneering works have shown the vulnerability of the diffusion model against backdoor attacks, calling for in-depth analysis and investigation of the security challenges of this popular and fundamental AI technique.   In this paper, for the first time, we systematically explore the detectability of the poisoned noise input for the backdoored diffusion models, an important performance metric yet little explored in the existing works. Starting from the perspective of a defender, we first analyze the properties of the trigger pattern in the existing diffusion backdoor attacks, discovering the important role of distribution discrepancy in Trojan detection. Based on this finding, we propose a low-cost trigger detection mechan",
    "link": "https://arxiv.org/abs/2402.02739",
    "context": "Title: DisDet: Exploring Detectability of Backdoor Attack on Diffusion Models\nAbstract: In the exciting generative AI era, the diffusion model has emerged as a very powerful and widely adopted content generation and editing tool for various data modalities, making the study of their potential security risks very necessary and critical. Very recently, some pioneering works have shown the vulnerability of the diffusion model against backdoor attacks, calling for in-depth analysis and investigation of the security challenges of this popular and fundamental AI technique.   In this paper, for the first time, we systematically explore the detectability of the poisoned noise input for the backdoored diffusion models, an important performance metric yet little explored in the existing works. Starting from the perspective of a defender, we first analyze the properties of the trigger pattern in the existing diffusion backdoor attacks, discovering the important role of distribution discrepancy in Trojan detection. Based on this finding, we propose a low-cost trigger detection mechan",
    "path": "papers/24/02/2402.02739.json",
    "total_tokens": 880,
    "translated_title": "DisDet: 探索扩散模型中后门攻击的可检测性",
    "translated_abstract": "在令人兴奋的生成型AI时代中，扩散模型已成为一种非常强大且被广泛采用的内容生成和编辑工具，适用于各种数据模态，因此研究其潜在安全风险非常必要且关键。最近的一些开创性研究表明，扩散模型对于后门攻击的脆弱性，呼吁对这种流行且基础的AI技术的安全挑战进行深入分析和调查。在本文中，我们首次系统地探究了后门扩散模型中毒噪声输入的可检测性，这是一个重要的性能度量指标，但在现有研究中很少被探索。从防御者的角度出发，我们首先分析了现有扩散后门攻击中触发模式的属性，发现分布差异在木马检测中起着重要作用。基于这一发现，我们提出了一种低成本的触发检测机制。",
    "tldr": "本文首次系统地探究了后门扩散模型中毒噪声输入的可检测性，发现分布差异在木马检测中起着重要作用，并提出了一种低成本的触发检测机制。",
    "en_tdlr": "This paper systematically explores the detectability of poisoned noise input in backdoored diffusion models, uncovering the important role of distribution discrepancy in Trojan detection, and proposes a low-cost trigger detection mechanism."
}