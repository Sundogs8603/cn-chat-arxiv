{
    "title": "EcoRank: Budget-Constrained Text Re-ranking Using Large Language Models",
    "abstract": "arXiv:2402.10866v1 Announce Type: new  Abstract: Large Language Models (LLMs) have achieved state-of-the-art performance in text re-ranking. This process includes queries and candidate passages in the prompts, utilizing pointwise, listwise, and pairwise prompting strategies. A limitation of these ranking strategies with LLMs is their cost: the process can become expensive due to API charges, which are based on the number of input and output tokens. We study how to maximize the re-ranking performance given a budget, by navigating the vast search spaces of prompt choices, LLM APIs, and budget splits. We propose a suite of budget-constrained methods to perform text re-ranking using a set of LLM APIs. Our most efficient method, called EcoRank, is a two-layered pipeline that jointly optimizes decisions regarding budget allocation across prompt strategies and LLM APIs. Our experimental results on four popular QA and passage reranking datasets show that EcoRank outperforms other budget-aware ",
    "link": "https://arxiv.org/abs/2402.10866",
    "context": "Title: EcoRank: Budget-Constrained Text Re-ranking Using Large Language Models\nAbstract: arXiv:2402.10866v1 Announce Type: new  Abstract: Large Language Models (LLMs) have achieved state-of-the-art performance in text re-ranking. This process includes queries and candidate passages in the prompts, utilizing pointwise, listwise, and pairwise prompting strategies. A limitation of these ranking strategies with LLMs is their cost: the process can become expensive due to API charges, which are based on the number of input and output tokens. We study how to maximize the re-ranking performance given a budget, by navigating the vast search spaces of prompt choices, LLM APIs, and budget splits. We propose a suite of budget-constrained methods to perform text re-ranking using a set of LLM APIs. Our most efficient method, called EcoRank, is a two-layered pipeline that jointly optimizes decisions regarding budget allocation across prompt strategies and LLM APIs. Our experimental results on four popular QA and passage reranking datasets show that EcoRank outperforms other budget-aware ",
    "path": "papers/24/02/2402.10866.json",
    "total_tokens": 832,
    "translated_title": "EcoRank: 使用大型语言模型进行受限预算文本重新排序",
    "translated_abstract": "大型语言模型（LLMs）在文本重新排序中取得了最先进的性能。该过程包括在提示中使用查询和候选段落，利用点对点，列表式和成对提示策略。LLMs的这些排序策略的一个限制是它们的成本：由于API收费基于输入和输出令牌的数量，这个过程可能会变得昂贵。我们研究如何在给定预算的情况下最大化重新排序性能，通过导航提示选择，LLM API和预算分割的广阔搜索空间。我们提出了一套使用一组LLM API进行文本重新排序的受限预算方法。我们最有效的方法是EcoRank，它是一个两层管线，可以联合优化有关跨提示策略和LLM API的预算分配决策。我们在四个流行的QA和段重排序数据集上的实验结果显示，EcoRank优于其他具有预算意识的方法。",
    "tldr": "EcoRank是一个两层管线，通过联合优化有关预算分配和LLM API的决策来实现文本重新排序，在实验中表现优于其他预算感知方法。"
}