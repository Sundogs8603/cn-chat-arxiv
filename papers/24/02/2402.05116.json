{
    "title": "Quantifying Similarity: Text-Mining Approaches to Evaluate ChatGPT and Google Bard Content in Relation to BioMedical Literature",
    "abstract": "Background: The emergence of generative AI tools, empowered by Large Language Models (LLMs), has shown powerful capabilities in generating content. To date, the assessment of the usefulness of such content, generated by what is known as prompt engineering, has become an interesting research question. Objectives Using the mean of prompt engineering, we assess the similarity and closeness of such contents to real literature produced by scientists. Methods In this exploratory analysis, (1) we prompt-engineer ChatGPT and Google Bard to generate clinical content to be compared with literature counterparts, (2) we assess the similarities of the contents generated by comparing them with counterparts from biomedical literature. Our approach is to use text-mining approaches to compare documents and associated bigrams and to use network analysis to assess the terms' centrality. Results The experiments demonstrated that ChatGPT outperformed Google Bard in cosine document similarity (38% to 34%), ",
    "link": "https://arxiv.org/abs/2402.05116",
    "context": "Title: Quantifying Similarity: Text-Mining Approaches to Evaluate ChatGPT and Google Bard Content in Relation to BioMedical Literature\nAbstract: Background: The emergence of generative AI tools, empowered by Large Language Models (LLMs), has shown powerful capabilities in generating content. To date, the assessment of the usefulness of such content, generated by what is known as prompt engineering, has become an interesting research question. Objectives Using the mean of prompt engineering, we assess the similarity and closeness of such contents to real literature produced by scientists. Methods In this exploratory analysis, (1) we prompt-engineer ChatGPT and Google Bard to generate clinical content to be compared with literature counterparts, (2) we assess the similarities of the contents generated by comparing them with counterparts from biomedical literature. Our approach is to use text-mining approaches to compare documents and associated bigrams and to use network analysis to assess the terms' centrality. Results The experiments demonstrated that ChatGPT outperformed Google Bard in cosine document similarity (38% to 34%), ",
    "path": "papers/24/02/2402.05116.json",
    "total_tokens": 909,
    "translated_title": "量化相似性：使用文本挖掘方法评估ChatGPT和Google Bard生成内容与生物医学文献的关联性",
    "translated_abstract": "背景：在大语言模型（LLMs）的支持下，生成式人工智能工具的出现展示了强大的生成内容能力。到目前为止，评估通过所谓的提示工程生成的内容的有用性已经成为一个有趣的研究问题。目标：通过提示工程的平均值，我们评估这些内容与科学家产生的真实文献的相似性和接近程度。方法：在这个探索性分析中，（1）我们通过提示工程来生成ChatGPT和Google Bard的临床内容，以便与文献对应内容进行比较，（2）我们通过比较所生成内容与生物医学文献对应内容的相似性来评估它们之间的相似性。我们的方法是使用文本挖掘方法比较文档和相关的二元组，并使用网络分析来评估术语的中心性。结果：实验表明，ChatGPT在余弦文档相似性方面表现优于Google Bard（38%对34%），",
    "tldr": "本研究旨在通过文本挖掘方法评估ChatGPT和Google Bard生成的内容与生物医学文献之间的相似性。实验结果显示，在余弦文档相似性方面，ChatGPT表现优于Google Bard。",
    "en_tdlr": "This study aims to evaluate the similarity between the content generated by ChatGPT and Google Bard and biomedical literature using text-mining approaches. The results showed that ChatGPT outperformed Google Bard in terms of cosine document similarity."
}