{
    "title": "How to Train Data-Efficient LLMs",
    "abstract": "arXiv:2402.09668v1 Announce Type: cross  Abstract: The training of large language models (LLMs) is expensive. In this paper, we study data-efficient approaches for pre-training LLMs, i.e., techniques that aim to optimize the Pareto frontier of model quality and training resource/data consumption. We seek to understand the tradeoffs associated with data selection routines based on (i) expensive-to-compute data-quality estimates, and (ii) maximization of coverage and diversity-based measures in the feature space. Our first technique, Ask-LLM, leverages the zero-shot reasoning capabilities of instruction-tuned LLMs to directly assess the quality of a training example. To target coverage, we propose Density sampling, which models the data distribution to select a diverse sample. In our comparison of 19 samplers, involving hundreds of evaluation tasks and pre-training runs, we find that Ask-LLM and Density are the best methods in their respective categories. Coverage sampling can recover th",
    "link": "https://arxiv.org/abs/2402.09668",
    "context": "Title: How to Train Data-Efficient LLMs\nAbstract: arXiv:2402.09668v1 Announce Type: cross  Abstract: The training of large language models (LLMs) is expensive. In this paper, we study data-efficient approaches for pre-training LLMs, i.e., techniques that aim to optimize the Pareto frontier of model quality and training resource/data consumption. We seek to understand the tradeoffs associated with data selection routines based on (i) expensive-to-compute data-quality estimates, and (ii) maximization of coverage and diversity-based measures in the feature space. Our first technique, Ask-LLM, leverages the zero-shot reasoning capabilities of instruction-tuned LLMs to directly assess the quality of a training example. To target coverage, we propose Density sampling, which models the data distribution to select a diverse sample. In our comparison of 19 samplers, involving hundreds of evaluation tasks and pre-training runs, we find that Ask-LLM and Density are the best methods in their respective categories. Coverage sampling can recover th",
    "path": "papers/24/02/2402.09668.json",
    "total_tokens": 823,
    "translated_title": "如何训练数据高效的LLM模型",
    "translated_abstract": "大型语言模型（LLM）的训练十分昂贵。本文研究了用于预训练LLM的数据高效方法，即旨在优化模型质量和训练资源/数据消耗的帕累托前沿的技术。我们试图理解基于（i）昂贵的数据质量估计和（ii）基于特征空间的覆盖率和多样性测量的数据选择程序所带来的权衡。我们的第一种技术“Ask-LLM”利用调节指令的LLM的零样本推理能力来直接评估训练样例的质量。为了达到覆盖率，我们提出了密度采样，它根据数据分布选择多样的样本。在我们对19种采样器进行了数百个评估任务和预训练运行的对比研究中，我们发现Ask-LLM和Density是各自类别中最好的方法。",
    "tldr": "本文研究了如何训练数据高效的LLM模型，提出了Ask-LLM和Density两种优秀的数据选择方法。",
    "en_tdlr": "This paper explores data-efficient approaches for training large language models (LLMs) and proposes two effective methods, Ask-LLM and Density, for data selection."
}