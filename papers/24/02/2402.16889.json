{
    "title": "Generative Models are Self-Watermarked: Declaring Model Authentication through Re-Generation",
    "abstract": "arXiv:2402.16889v1 Announce Type: cross  Abstract: As machine- and AI-generated content proliferates, protecting the intellectual property of generative models has become imperative, yet verifying data ownership poses formidable challenges, particularly in cases of unauthorized reuse of generated data. The challenge of verifying data ownership is further amplified by using Machine Learning as a Service (MLaaS), which often functions as a black-box system.   Our work is dedicated to detecting data reuse from even an individual sample. Traditionally, watermarking has been leveraged to detect AI-generated content. However, unlike watermarking techniques that embed additional information as triggers into models or generated content, potentially compromising output quality, our approach identifies latent fingerprints inherently present within the outputs through re-generation. We propose an explainable verification procedure that attributes data ownership through re-generation, and further ",
    "link": "https://arxiv.org/abs/2402.16889",
    "context": "Title: Generative Models are Self-Watermarked: Declaring Model Authentication through Re-Generation\nAbstract: arXiv:2402.16889v1 Announce Type: cross  Abstract: As machine- and AI-generated content proliferates, protecting the intellectual property of generative models has become imperative, yet verifying data ownership poses formidable challenges, particularly in cases of unauthorized reuse of generated data. The challenge of verifying data ownership is further amplified by using Machine Learning as a Service (MLaaS), which often functions as a black-box system.   Our work is dedicated to detecting data reuse from even an individual sample. Traditionally, watermarking has been leveraged to detect AI-generated content. However, unlike watermarking techniques that embed additional information as triggers into models or generated content, potentially compromising output quality, our approach identifies latent fingerprints inherently present within the outputs through re-generation. We propose an explainable verification procedure that attributes data ownership through re-generation, and further ",
    "path": "papers/24/02/2402.16889.json",
    "total_tokens": 748,
    "translated_title": "生成模型具有自身水印：通过再生成声明模型认证",
    "translated_abstract": "随着机器和人工智能生成的内容不断增加，保护生成模型的知识产权已变得至关重要，然而验证数据所有权在未经授权重复使用生成数据的情况下面临着巨大挑战。我们的工作致力于检测即使是个别样本的数据重复使用。传统上，数字水印技术被利用来检测人工智能生成的内容。然而，与将附加信息嵌入模型或生成内容以作为触发器的水印技术不同，潜在损害输出质量，我们的方法通过重新生成识别在输出中固有存在的潜在指纹。我们提出了一个可解释的验证过程，通过再生成来归属数据所有权，进一步",
    "tldr": "该论文提出了一种通过再生成识别模型数据所有权的方法，避免了传统数字水印技术可能破坏输出质量的问题。",
    "en_tdlr": "The paper introduces a method to identify data ownership of models through re-generation, avoiding potential quality compromises of traditional digital watermarking techniques."
}