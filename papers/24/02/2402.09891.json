{
    "title": "Predictors from causal features do not generalize better to new domains",
    "abstract": "arXiv:2402.09891v1 Announce Type: new  Abstract: We study how well machine learning models trained on causal features generalize across domains. We consider 16 prediction tasks on tabular datasets covering applications in health, employment, education, social benefits, and politics. Each dataset comes with multiple domains, allowing us to test how well a model trained in one domain performs in another. For each prediction task, we select features that have a causal influence on the target of prediction. Our goal is to test the hypothesis that models trained on causal features generalize better across domains. Without exception, we find that predictors using all available features, regardless of causality, have better in-domain and out-of-domain accuracy than predictors using causal features. Moreover, even the absolute drop in accuracy from one domain to the other is no better for causal predictors than for models that use all features. If the goal is to generalize to new domains, prac",
    "link": "https://arxiv.org/abs/2402.09891",
    "context": "Title: Predictors from causal features do not generalize better to new domains\nAbstract: arXiv:2402.09891v1 Announce Type: new  Abstract: We study how well machine learning models trained on causal features generalize across domains. We consider 16 prediction tasks on tabular datasets covering applications in health, employment, education, social benefits, and politics. Each dataset comes with multiple domains, allowing us to test how well a model trained in one domain performs in another. For each prediction task, we select features that have a causal influence on the target of prediction. Our goal is to test the hypothesis that models trained on causal features generalize better across domains. Without exception, we find that predictors using all available features, regardless of causality, have better in-domain and out-of-domain accuracy than predictors using causal features. Moreover, even the absolute drop in accuracy from one domain to the other is no better for causal predictors than for models that use all features. If the goal is to generalize to new domains, prac",
    "path": "papers/24/02/2402.09891.json",
    "total_tokens": 851,
    "translated_title": "预测因果特征不能更好地推广到新领域",
    "translated_abstract": "我们研究了在不同领域中，基于因果特征训练的机器学习模型的泛化效果。我们考虑了涵盖健康、就业、教育、社会福利和政治等应用的16个表格数据集的预测任务。每个数据集都有多个领域，我们可以测试一个在一个领域训练的模型在另一个领域的表现。对于每个预测任务，我们选择对预测目标有因果影响的特征。我们的目标是测试基于因果特征训练的模型是否在不同领域中更好地泛化。我们发现，无论是否具有因果关系，使用所有可用特征的预测器都比使用因果特征的预测器在领域内外的准确性更高。而且，即使是从一个领域到另一个领域的准确性绝对下降对于因果预测器来说也不比使用所有特征的模型更好。如果目标是在新领域中泛化，实践中使用所有特征的预测器效果更好。",
    "tldr": "因果特征不能更好地推广到新领域，预测器使用所有特征的效果更好。",
    "en_tdlr": "Predictors using all features have better performance in generalizing to new domains than predictors using causal features."
}