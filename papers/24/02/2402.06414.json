{
    "title": "Trust the Process: Zero-Knowledge Machine Learning to Enhance Trust in Generative AI Interactions",
    "abstract": "Generative AI, exemplified by models like transformers, has opened up new possibilities in various domains but also raised concerns about fairness, transparency and reliability, especially in fields like medicine and law. This paper emphasizes the urgency of ensuring fairness and quality in these domains through generative AI. It explores using cryptographic techniques, particularly Zero-Knowledge Proofs (ZKPs), to address concerns regarding performance fairness and accuracy while protecting model privacy. Applying ZKPs to Machine Learning models, known as ZKML (Zero-Knowledge Machine Learning), enables independent validation of AI-generated content without revealing sensitive model information, promoting transparency and trust. ZKML enhances AI fairness by providing cryptographic audit trails for model predictions and ensuring uniform performance across users. We introduce snarkGPT, a practical ZKML implementation for transformers, to empower users to verify output accuracy and qualit",
    "link": "https://arxiv.org/abs/2402.06414",
    "context": "Title: Trust the Process: Zero-Knowledge Machine Learning to Enhance Trust in Generative AI Interactions\nAbstract: Generative AI, exemplified by models like transformers, has opened up new possibilities in various domains but also raised concerns about fairness, transparency and reliability, especially in fields like medicine and law. This paper emphasizes the urgency of ensuring fairness and quality in these domains through generative AI. It explores using cryptographic techniques, particularly Zero-Knowledge Proofs (ZKPs), to address concerns regarding performance fairness and accuracy while protecting model privacy. Applying ZKPs to Machine Learning models, known as ZKML (Zero-Knowledge Machine Learning), enables independent validation of AI-generated content without revealing sensitive model information, promoting transparency and trust. ZKML enhances AI fairness by providing cryptographic audit trails for model predictions and ensuring uniform performance across users. We introduce snarkGPT, a practical ZKML implementation for transformers, to empower users to verify output accuracy and qualit",
    "path": "papers/24/02/2402.06414.json",
    "total_tokens": 870,
    "translated_title": "相信过程：零知识机器学习增强生成式AI交互中的信任",
    "translated_abstract": "生成式AI（如transformers模型）在各个领域开辟了新的可能性，但也引发了公平性、透明度和可靠性方面的关切，尤其在医学和法律等领域。本文强调通过生成式AI确保这些领域的公平性和质量的紧迫性，并探索使用密码学技术，特别是零知识证明（ZKP），来解决性能公平性和准确性方面的问题，同时保护模型的隐私。将ZKP应用于机器学习模型，即零知识机器学习（ZKML），可以在不泄露敏感模型信息的情况下对AI生成内容进行独立验证，促进透明度和信任。ZKML通过为模型预测提供密码学审计痕迹，并确保用户之间的统一性能，提高了AI的公平性。我们介绍了snarkGPT，一个实际的transformers型ZKML实现，可以使用户验证输出的准确性和质量。",
    "tldr": "本文提出了使用零知识证明技术来解决生成式AI公平性和隐私保护的问题，并介绍了一个实际的ZKML实现，可以增强用户对生成式AI输出的信任和透明度。",
    "en_tdlr": "This paper proposes using Zero-Knowledge Proofs to address fairness and privacy concerns in generative AI, and introduces a practical implementation called ZKML to enhance trust and transparency in AI-generated content."
}