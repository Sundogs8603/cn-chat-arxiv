{
    "title": "Purifying Large Language Models by Ensembling a Small Language Model",
    "abstract": "arXiv:2402.14845v1 Announce Type: cross  Abstract: The emerging success of large language models (LLMs) heavily relies on collecting abundant training data from external (untrusted) sources. Despite substantial efforts devoted to data cleaning and curation, well-constructed LLMs have been reported to suffer from copyright infringement, data poisoning, and/or privacy violations, which would impede practical deployment of LLMs. In this study, we propose a simple and easily implementable method for purifying LLMs from the negative effects caused by uncurated data, namely, through ensembling LLMs with benign and small language models (SLMs). Aside from theoretical guarantees, we perform comprehensive experiments to empirically confirm the efficacy of ensembling LLMs with SLMs, which can effectively preserve the performance of LLMs while mitigating issues such as copyright infringement, data poisoning, and privacy violations.",
    "link": "https://arxiv.org/abs/2402.14845",
    "context": "Title: Purifying Large Language Models by Ensembling a Small Language Model\nAbstract: arXiv:2402.14845v1 Announce Type: cross  Abstract: The emerging success of large language models (LLMs) heavily relies on collecting abundant training data from external (untrusted) sources. Despite substantial efforts devoted to data cleaning and curation, well-constructed LLMs have been reported to suffer from copyright infringement, data poisoning, and/or privacy violations, which would impede practical deployment of LLMs. In this study, we propose a simple and easily implementable method for purifying LLMs from the negative effects caused by uncurated data, namely, through ensembling LLMs with benign and small language models (SLMs). Aside from theoretical guarantees, we perform comprehensive experiments to empirically confirm the efficacy of ensembling LLMs with SLMs, which can effectively preserve the performance of LLMs while mitigating issues such as copyright infringement, data poisoning, and privacy violations.",
    "path": "papers/24/02/2402.14845.json",
    "total_tokens": 818,
    "translated_title": "通过集成小型语言模型来净化大型语言模型",
    "translated_abstract": "大型语言模型（LLMs）的成功很大程度上取决于从外部（不受信任）来源收集丰富的训练数据。尽管已经付出了大量努力进行数据清洗和精心策划，但已有报道显示构建良好的LLMs存在版权侵权、数据污染和/或隐私侵犯问题，这将阻碍LLMs的实际部署。在本研究中，我们提出了一种简单易行的方法，通过将LLMs与良性小语言模型（SLMs）集成来净化LLMs免受未经筛选数据带来的负面影响。除了理论保证外，我们进行了全面实验，从经验证实，LLMs与SLMs集成可以有效保持LLMs的性能，同时减轻版权侵权、数据污染和隐私侵犯等问题。",
    "tldr": "通过将大型语言模型与小型语言模型集成，可以有效净化大型语言模型，保持其性能并减轻版权侵权、数据污染和隐私侵犯等问题",
    "en_tdlr": "Integrating large language models with small language models can effectively purify the large language models, maintain their performance, and alleviate issues such as copyright infringement, data poisoning, and privacy violations."
}