{
    "title": "BIDER: Bridging Knowledge Inconsistency for Efficient Retrieval-Augmented LLMs via Key Supporting Evidence",
    "abstract": "arXiv:2402.12174v1 Announce Type: new  Abstract: Retrieval-augmented large language models (LLMs) have demonstrated efficacy in knowledge-intensive tasks such as open-domain QA, addressing inherent challenges in knowledge update and factual inadequacy. However, inconsistencies between retrieval knowledge and the necessary knowledge for LLMs, leading to a decline in LLM's answer quality. This paper introduces BIDER, an approach that refines retrieval documents into Key Supporting Evidence (KSE) through knowledge synthesis, supervised fine-tuning (SFT), and preference alignment. We train BIDER by learning from crafting KSE, while maximizing its output to align with LLM's information acquisition preferences through reinforcement learning. Evaluations across five datasets show BIDER boosts LLMs' answer quality by 7% while reducing input content length in retrieval documents by 80%, outperforming existing methods. The proposed KSE simulation effectively equips LLMs with essential informatio",
    "link": "https://arxiv.org/abs/2402.12174",
    "context": "Title: BIDER: Bridging Knowledge Inconsistency for Efficient Retrieval-Augmented LLMs via Key Supporting Evidence\nAbstract: arXiv:2402.12174v1 Announce Type: new  Abstract: Retrieval-augmented large language models (LLMs) have demonstrated efficacy in knowledge-intensive tasks such as open-domain QA, addressing inherent challenges in knowledge update and factual inadequacy. However, inconsistencies between retrieval knowledge and the necessary knowledge for LLMs, leading to a decline in LLM's answer quality. This paper introduces BIDER, an approach that refines retrieval documents into Key Supporting Evidence (KSE) through knowledge synthesis, supervised fine-tuning (SFT), and preference alignment. We train BIDER by learning from crafting KSE, while maximizing its output to align with LLM's information acquisition preferences through reinforcement learning. Evaluations across five datasets show BIDER boosts LLMs' answer quality by 7% while reducing input content length in retrieval documents by 80%, outperforming existing methods. The proposed KSE simulation effectively equips LLMs with essential informatio",
    "path": "papers/24/02/2402.12174.json",
    "total_tokens": 858,
    "translated_title": "BIDER: 通过关键支持证据弥合有效检索增强的LLMs中的知识不一致性",
    "translated_abstract": "大规模语言模型（LLMs）在开放领域QA等知识密集型任务中表现出有效性，解决了知识更新和事实不足等固有挑战。然而，检索知识与LLMs所需知识之间的不一致性导致了LLMs答案质量下降。本文介绍了BIDER，一种通过知识综合、监督微调（SFT）和偏好对齐，将检索文档细化为关键支持证据（KSE）的方法。我们通过学习制定KSE来训练BIDER，同时通过强化学习将其输出最大化，以使其与LLMs的信息获取偏好保持一致。在五个数据集上的评估结果显示，BIDER提高了LLMs答案质量7％，同时将检索文档的输入内容长度减少了80％，优于现有方法。所提出的KSE模拟有效地为LLMs提供了必要的信息。",
    "tldr": "BIDER通过知识综合和偏好对齐，将检索文档转化为关键支持证据，从而提高了LLMs的答案质量并减少了输入内容长度。",
    "en_tdlr": "BIDER improves answer quality of LLMs and reduces input content length by refining retrieval documents into Key Supporting Evidence through knowledge synthesis and preference alignment."
}