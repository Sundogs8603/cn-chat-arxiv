{
    "title": "Structured World Modeling via Semantic Vector Quantization",
    "abstract": "Neural discrete representations are crucial components of modern neural networks. However, their main limitation is that the primary strategies such as VQ-VAE can only provide representations at the patch level. Therefore, one of the main goals of representation learning, acquiring structured, semantic, and compositional abstractions such as the color and shape of an object, remains elusive. In this paper, we present the first approach to semantic neural discrete representation learning. The proposed model, called Semantic Vector-Quantized Variational Autoencoder (SVQ), leverages recent advances in unsupervised object-centric learning to address this limitation. Specifically, we observe that a simple approach quantizing at the object level poses a significant challenge and propose constructing scene representations hierarchically, from low-level discrete concept schemas to object representations. Additionally, we suggest a novel method for structured semantic world modeling by training",
    "link": "https://rss.arxiv.org/abs/2402.01203",
    "context": "Title: Structured World Modeling via Semantic Vector Quantization\nAbstract: Neural discrete representations are crucial components of modern neural networks. However, their main limitation is that the primary strategies such as VQ-VAE can only provide representations at the patch level. Therefore, one of the main goals of representation learning, acquiring structured, semantic, and compositional abstractions such as the color and shape of an object, remains elusive. In this paper, we present the first approach to semantic neural discrete representation learning. The proposed model, called Semantic Vector-Quantized Variational Autoencoder (SVQ), leverages recent advances in unsupervised object-centric learning to address this limitation. Specifically, we observe that a simple approach quantizing at the object level poses a significant challenge and propose constructing scene representations hierarchically, from low-level discrete concept schemas to object representations. Additionally, we suggest a novel method for structured semantic world modeling by training",
    "path": "papers/24/02/2402.01203.json",
    "total_tokens": 857,
    "translated_title": "结构化世界建模通过语义向量量化",
    "translated_abstract": "神经离散表示是现代神经网络的关键组成部分。然而，其主要局限性是主要策略（如VQ-VAE）只能提供补丁级别的表示。因此，表示学习的主要目标之一，即获取结构化、语义化和组合抽象（如对象的颜色和形状），仍然难以实现。在本文中，我们提出了第一种用于语义神经离散表示学习的方法。所提出的模型，称为Semantic Vector-Quantized Variational Autoencoder (SVQ)，利用了最近在无监督物体中心学习方面的进展来解决这个局限性。具体而言，我们观察到，在对象级别上简单进行量化是一个重大挑战，并提出了从低级离散概念模式到对象表示逐层构建场景表示的方法。此外，我们提出了一种用于结构化语义世界建模的新方法，通过训练来实现该方法。",
    "tldr": "这篇论文提出了一种新方法，通过语义向量量化实现语义神经离散表示学习，解决了现有方法只能提供补丁级别表示的问题，并通过逐层构建场景表示和训练的方式实现了结构化语义世界建模。",
    "en_tdlr": "This paper presents a new approach to semantic neural discrete representation learning through semantic vector quantization, addressing the limitation of patch-level representation provided by existing methods, and achieves structured semantic world modeling through hierarchical construction of scene representations and training."
}