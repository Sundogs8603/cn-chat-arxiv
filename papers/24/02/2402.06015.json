{
    "title": "Exploring Visual Culture Awareness in GPT-4V: A Comprehensive Probing",
    "abstract": "Pretrained large Vision-Language models have drawn considerable interest in recent years due to their remarkable performance. Despite considerable efforts to assess these models from diverse perspectives, the extent of visual cultural awareness in the state-of-the-art GPT-4V model remains unexplored. To tackle this gap, we extensively probed GPT-4V using the MaRVL benchmark dataset, aiming to investigate its capabilities and limitations in visual understanding with a focus on cultural aspects. Specifically, we introduced three visual related tasks, i.e. caption classification, pairwise captioning, and culture tag selection, to systematically delve into fine-grained visual cultural evaluation. Experimental results indicate that GPT-4V excels at identifying cultural concepts but still exhibits weaker performance in low-resource languages, such as Tamil and Swahili. Notably, through human evaluation, GPT-4V proves to be more culturally relevant in image captioning tasks than the original ",
    "link": "https://arxiv.org/abs/2402.06015",
    "context": "Title: Exploring Visual Culture Awareness in GPT-4V: A Comprehensive Probing\nAbstract: Pretrained large Vision-Language models have drawn considerable interest in recent years due to their remarkable performance. Despite considerable efforts to assess these models from diverse perspectives, the extent of visual cultural awareness in the state-of-the-art GPT-4V model remains unexplored. To tackle this gap, we extensively probed GPT-4V using the MaRVL benchmark dataset, aiming to investigate its capabilities and limitations in visual understanding with a focus on cultural aspects. Specifically, we introduced three visual related tasks, i.e. caption classification, pairwise captioning, and culture tag selection, to systematically delve into fine-grained visual cultural evaluation. Experimental results indicate that GPT-4V excels at identifying cultural concepts but still exhibits weaker performance in low-resource languages, such as Tamil and Swahili. Notably, through human evaluation, GPT-4V proves to be more culturally relevant in image captioning tasks than the original ",
    "path": "papers/24/02/2402.06015.json",
    "total_tokens": 938,
    "translated_title": "在GPT-4V模型中探索视觉文化意识：一项全面探索",
    "translated_abstract": "预训练的大型视觉-语言模型近年来引起了 considerable的关注，其出色的性能令人印象深刻。尽管已经做出了多方面的努力来评估这些模型，但目前最先进的GPT-4V模型在视觉文化意识方面尚未被探索。为了填补这一空白，我们使用MaRVL基准数据集广泛探索了GPT-4V，旨在调查其在视觉理解方面，特别是文化方面的能力和限制。具体而言，我们引入了三个与视觉相关的任务，即标题分类、成对标题生成和文化标签选择，以系统地深入研究细粒度的视觉文化评估。实验结果表明，GPT-4V在识别文化概念方面表现出色，但在资源匮乏的语言（如泰米尔语和斯瓦希里语）中仍然表现较弱。值得注意的是，通过人工评估，GPT-4V在图像字幕任务中证明在文化相关性方面优于原文的表现。",
    "tldr": "通过在GPT-4V模型上进行全面的探索，我们发现该模型在识别文化概念方面表现出色，但在低资源语言中仍表现较弱。在图像字幕任务中，GPT-4V在文化相关性方面优于原文。",
    "en_tdlr": "Through comprehensive probing of the GPT-4V model, we found that it excels at identifying cultural concepts but exhibits weaker performance in low-resource languages. In image captioning tasks, GPT-4V shows better cultural relevance compared to the original."
}