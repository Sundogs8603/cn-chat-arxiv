{
    "title": "Advancing Large Language Models to Capture Varied Speaking Styles and Respond Properly in Spoken Conversations",
    "abstract": "arXiv:2402.12786v1 Announce Type: new  Abstract: In spoken dialogue, even if two current turns are the same sentence, their responses might still differ when they are spoken in different styles. The spoken styles, containing paralinguistic and prosodic information, mark the most significant difference between text and speech modality. When using text-only LLMs to model spoken dialogue, text-only LLMs cannot give different responses based on the speaking style of the current turn. In this paper, we focus on enabling LLMs to listen to the speaking styles and respond properly. Our goal is to teach the LLM that \"even if the sentences are identical if they are spoken in different styles, their corresponding responses might be different\". Since there is no suitable dataset for achieving this goal, we collect a speech-to-speech dataset, StyleTalk, with the following desired characteristics: when two current speeches have the same content but are spoken in different styles, their responses wil",
    "link": "https://arxiv.org/abs/2402.12786",
    "context": "Title: Advancing Large Language Models to Capture Varied Speaking Styles and Respond Properly in Spoken Conversations\nAbstract: arXiv:2402.12786v1 Announce Type: new  Abstract: In spoken dialogue, even if two current turns are the same sentence, their responses might still differ when they are spoken in different styles. The spoken styles, containing paralinguistic and prosodic information, mark the most significant difference between text and speech modality. When using text-only LLMs to model spoken dialogue, text-only LLMs cannot give different responses based on the speaking style of the current turn. In this paper, we focus on enabling LLMs to listen to the speaking styles and respond properly. Our goal is to teach the LLM that \"even if the sentences are identical if they are spoken in different styles, their corresponding responses might be different\". Since there is no suitable dataset for achieving this goal, we collect a speech-to-speech dataset, StyleTalk, with the following desired characteristics: when two current speeches have the same content but are spoken in different styles, their responses wil",
    "path": "papers/24/02/2402.12786.json",
    "total_tokens": 874,
    "translated_title": "将大型语言模型发展起来，以捕捉不同语言风格并在口语交流中做出恰当回应",
    "translated_abstract": "在口语对话中，即使两个当前对话是相同的句子，但当以不同风格发音时，它们的回应仍可能不同。语音风格包含语言附加信息和韵律信息，标志着文本和语音形式之间最显著的差异。使用仅文本的大型语言模型（LLMs）来建模口语对话时，纯文本的LLMs无法根据当前对话的语音风格给出不同的回应。本文旨在使LLMs能够倾听说话风格并作出恰当回应。我们的目标是教会LLM“即使句子相同，如果以不同风格说出，相应的回应可能会不同”。由于目前没有适合实现此目标的数据集，我们收集了一组语音对语音的数据集StyleTalk，具有以下所需特征：当两个当前语音具有相同内容但以不同风格说出时，它们的回应将",
    "tldr": "本文旨在让大型语言模型能够根据口语的不同语言风格做出恰当回应，并为此收集了一组适合训练的语音对语音数据集。",
    "en_tdlr": "This paper aims to enable large language models to respond properly based on varied speaking styles in spoken conversations, and collects a suitable speech-to-speech dataset for training."
}