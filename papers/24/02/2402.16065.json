{
    "title": "Training a Bilingual Language Model by Mapping Tokens onto a Shared Character Space",
    "abstract": "arXiv:2402.16065v1 Announce Type: new  Abstract: We train a bilingual Arabic-Hebrew language model using a transliterated version of Arabic texts in Hebrew, to ensure both languages are represented in the same script. Given the morphological, structural similarities, and the extensive number of cognates shared among Arabic and Hebrew, we assess the performance of a language model that employs a unified script for both languages, on machine translation which requires cross-lingual knowledge. The results are promising: our model outperforms a contrasting model which keeps the Arabic texts in the Arabic script, demonstrating the efficacy of the transliteration step. Despite being trained on a dataset approximately 60% smaller than that of other existing language models, our model appears to deliver comparable performance in machine translation across both translation directions.",
    "link": "https://arxiv.org/abs/2402.16065",
    "context": "Title: Training a Bilingual Language Model by Mapping Tokens onto a Shared Character Space\nAbstract: arXiv:2402.16065v1 Announce Type: new  Abstract: We train a bilingual Arabic-Hebrew language model using a transliterated version of Arabic texts in Hebrew, to ensure both languages are represented in the same script. Given the morphological, structural similarities, and the extensive number of cognates shared among Arabic and Hebrew, we assess the performance of a language model that employs a unified script for both languages, on machine translation which requires cross-lingual knowledge. The results are promising: our model outperforms a contrasting model which keeps the Arabic texts in the Arabic script, demonstrating the efficacy of the transliteration step. Despite being trained on a dataset approximately 60% smaller than that of other existing language models, our model appears to deliver comparable performance in machine translation across both translation directions.",
    "path": "papers/24/02/2402.16065.json",
    "total_tokens": 835,
    "translated_title": "通过将标记映射到共享字符空间来训练双语语言模型",
    "translated_abstract": "我们使用阿拉伯文文本的音译版本在希伯来语中训练了一个双语语言模型，以确保两种语言在同一脚本中表示。鉴于阿拉伯语和希伯来语之间的形态学、结构相似性以及大量共同词源词，我们评估了使用统一脚本表示两种语言的语言模型在需要跨语言知识的机器翻译上的表现。结果表明：我们的模型优于保持阿拉伯文本在阿拉伯脚本中的对比模型，展示了音译步骤的有效性。尽管我们的模型在数据集方面训练集大小约为其他现有语言模型的60％，但在机器翻译的两个方向上似乎提供了可比较的性能。",
    "tldr": "通过将标记映射到共享字符空间，研究了阿拉伯-希伯来双语语言模型训练。结果表明，使用同时表示两种语言的统一脚本的语言模型在机器翻译上表现出色，相比于保持原有脚本的模型有着更好的性能表现。"
}