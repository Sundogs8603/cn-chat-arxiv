{
    "title": "High-quality Data-to-Text Generation for Severely Under-Resourced Languages with Out-of-the-box Large Language Models",
    "abstract": "arXiv:2402.12267v1 Announce Type: new  Abstract: The performance of NLP methods for severely under-resourced languages cannot currently hope to match the state of the art in NLP methods for well resourced languages. We explore the extent to which pretrained large language models (LLMs) can bridge this gap, via the example of data-to-text generation for Irish, Welsh, Breton and Maltese. We test LLMs on these under-resourced languages and English, in a range of scenarios. We find that LLMs easily set the state of the art for the under-resourced languages by substantial margins, as measured by both automatic and human evaluations. For all our languages, human evaluation shows on-a-par performance with humans for our best systems, but BLEU scores collapse compared to English, casting doubt on the metric's suitability for evaluating non-task-specific systems. Overall, our results demonstrate the great potential of LLMs to bridge the performance gap for under-resourced languages.",
    "link": "https://arxiv.org/abs/2402.12267",
    "context": "Title: High-quality Data-to-Text Generation for Severely Under-Resourced Languages with Out-of-the-box Large Language Models\nAbstract: arXiv:2402.12267v1 Announce Type: new  Abstract: The performance of NLP methods for severely under-resourced languages cannot currently hope to match the state of the art in NLP methods for well resourced languages. We explore the extent to which pretrained large language models (LLMs) can bridge this gap, via the example of data-to-text generation for Irish, Welsh, Breton and Maltese. We test LLMs on these under-resourced languages and English, in a range of scenarios. We find that LLMs easily set the state of the art for the under-resourced languages by substantial margins, as measured by both automatic and human evaluations. For all our languages, human evaluation shows on-a-par performance with humans for our best systems, but BLEU scores collapse compared to English, casting doubt on the metric's suitability for evaluating non-task-specific systems. Overall, our results demonstrate the great potential of LLMs to bridge the performance gap for under-resourced languages.",
    "path": "papers/24/02/2402.12267.json",
    "total_tokens": 928,
    "translated_title": "针对严重资源匮乏语言的高质量数据文本生成与即插即用大语言模型",
    "translated_abstract": "NLP方法在资源丰富的语言领域的最新发展水平是无法期望在严重资源匮乏语言领域得到匹配的。我们通过爱尔兰语、威尔士语、布列塔尼语和马耳他语的数据文本生成为例，探讨预先训练的大型语言模型（LLMs）在这方面能够弥合这一差距的程度。我们在这些资源匮乏语言和英语上测试了LLMs，并在一系列场景中进行了测试。我们发现，LLMs以明显较大的优势轻松地刷新了资源匮乏语言的最新发展水平，无论是通过自动评估还是人工评估。对于我们所有的语言，人工评估显示我们最佳系统的性能与人类持平，但与英语相比，BLEU分数下降，这对于评估非任务特定系统的指标的适用性提出了疑问。总的来说，我们的结果表明LLMs在弥合资源匮乏语言性能差距方面具有巨大潜力。",
    "tldr": "大型语言模型(LLMs)在严重资源匮乏语言领域的数据文本生成中轻松刷新最新发展水平，展现出弥合性能差距的巨大潜力。",
    "en_tdlr": "Large Language Models (LLMs) easily set the state of the art in data-to-text generation for severely under-resourced languages, demonstrating great potential in bridging the performance gap."
}