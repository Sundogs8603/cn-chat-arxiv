{
    "title": "Investigating Continual Pretraining in Large Language Models: Insights and Implications",
    "abstract": "arXiv:2402.17400v1 Announce Type: new  Abstract: This paper studies the evolving domain of Continual Learning (CL) in large language models (LLMs), with a focus on developing strategies for efficient and sustainable training. Our primary emphasis is on continual domain-adaptive pretraining, a process designed to equip LLMs with the ability to integrate new information from various domains while retaining previously learned knowledge and enhancing cross-domain knowledge transfer without relying on domain-specific identification. Unlike previous studies, which mostly concentrate on a limited selection of tasks or domains and primarily aim to address the issue of forgetting, our research evaluates the adaptability and capabilities of LLMs to changing data landscapes in practical scenarios. To this end, we introduce a new benchmark designed to measure the adaptability of LLMs to these evolving data environments, offering a comprehensive framework for evaluation. We examine the impact of mo",
    "link": "https://arxiv.org/abs/2402.17400",
    "context": "Title: Investigating Continual Pretraining in Large Language Models: Insights and Implications\nAbstract: arXiv:2402.17400v1 Announce Type: new  Abstract: This paper studies the evolving domain of Continual Learning (CL) in large language models (LLMs), with a focus on developing strategies for efficient and sustainable training. Our primary emphasis is on continual domain-adaptive pretraining, a process designed to equip LLMs with the ability to integrate new information from various domains while retaining previously learned knowledge and enhancing cross-domain knowledge transfer without relying on domain-specific identification. Unlike previous studies, which mostly concentrate on a limited selection of tasks or domains and primarily aim to address the issue of forgetting, our research evaluates the adaptability and capabilities of LLMs to changing data landscapes in practical scenarios. To this end, we introduce a new benchmark designed to measure the adaptability of LLMs to these evolving data environments, offering a comprehensive framework for evaluation. We examine the impact of mo",
    "path": "papers/24/02/2402.17400.json",
    "total_tokens": 897,
    "translated_title": "探讨大型语言模型中的持续预训练：见解与影响",
    "translated_abstract": "本文研究了大型语言模型（LLMs）中不断学习（CL）领域的发展，重点是制定高效可持续培训策略。我们的主要重点是持续领域自适应预训练，这是一个旨在使LLMs能够整合来自不同领域的新信息，同时保留以前学到的知识，并增强跨领域知识转移能力而不依赖于特定领域识别的过程。与以往主要集中于有限任务或领域并主要旨在解决遗忘问题的先前研究不同，我们的研究评估了LLMs对实际情景中不断变化的数据景观的适应性和能力。为此，我们引入了一个新的基准，旨在衡量LLMs对这些不断演变的数据环境的适应性，提供了一个全面的评估框架。",
    "tldr": "本研究探讨了大型语言模型中的持续预训练领域，提出了一种能够在不同领域中整合新信息、保留已学知识并增强跨领域知识转移能力的策略，并引入了新的基准来评估模型的适应性。"
}