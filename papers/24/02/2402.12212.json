{
    "title": "Polarization of Autonomous Generative AI Agents Under Echo Chambers",
    "abstract": "arXiv:2402.12212v1 Announce Type: new  Abstract: Online social networks often create echo chambers where people only hear opinions reinforcing their beliefs. An echo chamber often generates polarization, leading to conflicts caused by people with radical opinions, such as the January 6, 2021, attack on the US Capitol. The echo chamber has been viewed as a human-specific problem, but this implicit assumption is becoming less reasonable as large language models, such as ChatGPT, acquire social abilities. In response to this situation, we investigated the potential for polarization to occur among a group of autonomous AI agents based on generative language models in an echo chamber environment. We had AI agents discuss specific topics and analyzed how the group's opinions changed as the discussion progressed. As a result, we found that the group of agents based on ChatGPT tended to become polarized in echo chamber environments. The analysis of opinion transitions shows that this result is",
    "link": "https://arxiv.org/abs/2402.12212",
    "context": "Title: Polarization of Autonomous Generative AI Agents Under Echo Chambers\nAbstract: arXiv:2402.12212v1 Announce Type: new  Abstract: Online social networks often create echo chambers where people only hear opinions reinforcing their beliefs. An echo chamber often generates polarization, leading to conflicts caused by people with radical opinions, such as the January 6, 2021, attack on the US Capitol. The echo chamber has been viewed as a human-specific problem, but this implicit assumption is becoming less reasonable as large language models, such as ChatGPT, acquire social abilities. In response to this situation, we investigated the potential for polarization to occur among a group of autonomous AI agents based on generative language models in an echo chamber environment. We had AI agents discuss specific topics and analyzed how the group's opinions changed as the discussion progressed. As a result, we found that the group of agents based on ChatGPT tended to become polarized in echo chamber environments. The analysis of opinion transitions shows that this result is",
    "path": "papers/24/02/2402.12212.json",
    "total_tokens": 833,
    "translated_title": "自主生成AI代理在回声室中的极化",
    "translated_abstract": "在线社交网络通常会产生回声室，使人们只听到与其信念相符的观点。回音室经常会产生极化，导致由持有激进观点的人引起的冲突，比如2021年1月6日对美国国会大厦的袭击。回音室被视为一种人类特有的问题，但随着诸如ChatGPT之类的大型语言模型获得社交能力，这种隐含的假设变得不太合理。针对这种情况，我们研究了基于生成语言模型的一组自主AI代理在回声室环境中发生极化的潜在可能性。我们让AI代理讨论特定主题，并分析了随着讨论的进行，群体意见如何变化。结果表明，基于ChatGPT的一组代理在回声室环境中往往会变得极化。意见转变的分析显示了这一结果",
    "tldr": "在回声室环境中，基于ChatGPT的自主生成AI代理往往会发生极化，这对于了解人工智能代理在社交网络中的行为具有重要意义",
    "en_tdlr": "AI agents based on ChatGPT tend to become polarized in echo chamber environments, shedding light on the behavior of artificial intelligence agents in social networks."
}