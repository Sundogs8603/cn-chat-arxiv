{
    "title": "Bryndza at ClimateActivism 2024: Stance, Target and Hate Event Detection via Retrieval-Augmented GPT-4 and LLaMA",
    "abstract": "This study details our approach for the CASE 2024 Shared Task on Climate Activism Stance and Hate Event Detection, focusing on Hate Speech Detection, Hate Speech Target Identification, and Stance Detection as classification challenges. We explored the capability of Large Language Models (LLMs), particularly GPT-4, in zero- or few-shot settings enhanced by retrieval augmentation and re-ranking for Tweet classification. Our goal was to determine if LLMs could match or surpass traditional methods in this context.   We conducted an ablation study with LLaMA for comparison, and our results indicate that our models significantly outperformed the baselines, securing second place in the Target Detection task. The code for our submission is available at https://github.com/NaiveNeuron/bryndza-case-2024",
    "link": "https://arxiv.org/abs/2402.06549",
    "context": "Title: Bryndza at ClimateActivism 2024: Stance, Target and Hate Event Detection via Retrieval-Augmented GPT-4 and LLaMA\nAbstract: This study details our approach for the CASE 2024 Shared Task on Climate Activism Stance and Hate Event Detection, focusing on Hate Speech Detection, Hate Speech Target Identification, and Stance Detection as classification challenges. We explored the capability of Large Language Models (LLMs), particularly GPT-4, in zero- or few-shot settings enhanced by retrieval augmentation and re-ranking for Tweet classification. Our goal was to determine if LLMs could match or surpass traditional methods in this context.   We conducted an ablation study with LLaMA for comparison, and our results indicate that our models significantly outperformed the baselines, securing second place in the Target Detection task. The code for our submission is available at https://github.com/NaiveNeuron/bryndza-case-2024",
    "path": "papers/24/02/2402.06549.json",
    "total_tokens": 848,
    "translated_title": "Bryndza在ClimateActivism 2024上: 通过检索增强的GPT-4和LLaMA进行立场、目标和仇恨事件检测",
    "translated_abstract": "本研究详细介绍了我们在CASE 2024气候行动立场和仇恨事件检测共享任务中的方法，重点关注仇恨言论检测、仇恨言论目标识别和立场检测作为分类挑战。我们探索了大型语言模型（LLM），特别是GPT-4，在零次或少次训练情况下通过检索增强和重新排序来进行推特分类的能力。我们的目标是确定在这个背景下，LLM能否与传统方法相匹配或超越。我们进行了LLaMA的消融研究以进行比较，结果表明我们的模型明显优于基准线，在目标检测任务中获得了第二名。我们提交的代码可以在https://github.com/NaiveNeuron/bryndza-case-2024获得。",
    "tldr": "该研究利用GPT-4和LLaMA模型，通过检索增强和重新排序的方式，在CASE 2024共享任务中取得了显著的成果，特别是在仇恨事件检测和目标识别方面表现出色。",
    "en_tdlr": "This study achieved significant results in the CASE 2024 shared task on climate activism stance and hate event detection, particularly in the area of hate speech detection and target identification, by utilizing GPT-4 and LLaMA models with retrieval augmentation and re-ranking."
}