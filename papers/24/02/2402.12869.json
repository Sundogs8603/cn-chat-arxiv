{
    "title": "Exploring the Impact of Table-to-Text Methods on Augmenting LLM-based Question Answering with Domain Hybrid Data",
    "abstract": "arXiv:2402.12869v1 Announce Type: new  Abstract: Augmenting Large Language Models (LLMs) for Question Answering (QA) with domain specific data has attracted wide attention. However, domain data often exists in a hybrid format, including text and semi-structured tables, posing challenges for the seamless integration of information. Table-to-Text Generation is a promising solution by facilitating the transformation of hybrid data into a uniformly text-formatted corpus. Although this technique has been widely studied by the NLP community, there is currently no comparative analysis on how corpora generated by different table-to-text methods affect the performance of QA systems. In this paper, we address this research gap in two steps. First, we innovatively integrate table-to-text generation into the framework of enhancing LLM-based QA systems with domain hybrid data. Then, we utilize this framework in real-world industrial data to conduct extensive experiments on two types of QA systems (",
    "link": "https://arxiv.org/abs/2402.12869",
    "context": "Title: Exploring the Impact of Table-to-Text Methods on Augmenting LLM-based Question Answering with Domain Hybrid Data\nAbstract: arXiv:2402.12869v1 Announce Type: new  Abstract: Augmenting Large Language Models (LLMs) for Question Answering (QA) with domain specific data has attracted wide attention. However, domain data often exists in a hybrid format, including text and semi-structured tables, posing challenges for the seamless integration of information. Table-to-Text Generation is a promising solution by facilitating the transformation of hybrid data into a uniformly text-formatted corpus. Although this technique has been widely studied by the NLP community, there is currently no comparative analysis on how corpora generated by different table-to-text methods affect the performance of QA systems. In this paper, we address this research gap in two steps. First, we innovatively integrate table-to-text generation into the framework of enhancing LLM-based QA systems with domain hybrid data. Then, we utilize this framework in real-world industrial data to conduct extensive experiments on two types of QA systems (",
    "path": "papers/24/02/2402.12869.json",
    "total_tokens": 866,
    "translated_title": "探索表格转文本方法对增强基于LLM的问答系统在领域混合数据上的影响",
    "translated_abstract": "大型语言模型（LLMs）在问答系统（QA）中使用领域特定数据进行增强已经引起了广泛关注。然而，领域数据通常以混合格式存在，包括文本和半结构化表格，对信息的无缝整合提出了挑战。表格转文本生成是一个有前途的解决方案，它通过将混合数据转化为统一文本格式的语料库。尽管这种技术已经被自然语言处理（NLP）社区广泛研究，但目前还没有比较分析不同表格转文本方法生成的语料库对QA系统性能的影响。本文分两步解决了这一研究空白。首先，我们将表格转文本生成创新地集成到增强基于LLM的QA系统与领域混合数据框架中。然后，我们利用这个框架在真实工业数据中进行了广泛实验，对两种类型的QA系统进行了测试（",
    "tldr": "本文探索了如何将表格转文本方法集成到LLM问答系统中，通过实验发现不同的表格转文本方法对QA系统性能的影响。",
    "en_tdlr": "This paper explores integrating table-to-text methods into LLM-based QA systems and experimentally discovers the impact of different table-to-text methods on QA system performance."
}