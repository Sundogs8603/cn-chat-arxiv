{
    "title": "Decoding News Narratives: A Critical Analysis of Large Language Models in Framing Bias Detection",
    "abstract": "arXiv:2402.11621v1 Announce Type: new  Abstract: This work contributes to the expanding research on the applicability of LLMs in social sciences by examining the performance of GPT-3.5 Turbo, GPT-4, and Flan-T5 models in detecting framing bias in news headlines through zero-shot, few-shot, and explainable prompting methods. A key insight from our evaluation is the notable efficacy of explainable prompting in enhancing the reliability of these models, highlighting the importance of explainable settings for social science research on framing bias. GPT-4, in particular, demonstrated enhanced performance in few-shot scenarios when presented with a range of relevant, in-domain examples. FLAN-T5's poor performance indicates that smaller models may require additional task-specific fine-tuning for identifying framing bias detection. Our study also found that models, particularly GPT-4, often misinterpret emotional language as an indicator of framing bias, underscoring the challenge of distingu",
    "link": "https://arxiv.org/abs/2402.11621",
    "context": "Title: Decoding News Narratives: A Critical Analysis of Large Language Models in Framing Bias Detection\nAbstract: arXiv:2402.11621v1 Announce Type: new  Abstract: This work contributes to the expanding research on the applicability of LLMs in social sciences by examining the performance of GPT-3.5 Turbo, GPT-4, and Flan-T5 models in detecting framing bias in news headlines through zero-shot, few-shot, and explainable prompting methods. A key insight from our evaluation is the notable efficacy of explainable prompting in enhancing the reliability of these models, highlighting the importance of explainable settings for social science research on framing bias. GPT-4, in particular, demonstrated enhanced performance in few-shot scenarios when presented with a range of relevant, in-domain examples. FLAN-T5's poor performance indicates that smaller models may require additional task-specific fine-tuning for identifying framing bias detection. Our study also found that models, particularly GPT-4, often misinterpret emotional language as an indicator of framing bias, underscoring the challenge of distingu",
    "path": "papers/24/02/2402.11621.json",
    "total_tokens": 1102,
    "translated_title": "解码新闻叙事：对大型语言模型在框架偏见检测中的关键分析",
    "translated_abstract": "这项工作通过检验GPT-3.5 Turbo、GPT-4和Flan-T5模型在通过零射、少射和可解释提示方法检测新闻标题中框架偏见的表现，为LLMs在社会科学中的适用性不断扩展的研究做出贡献。我们评估的一个关键洞察是，可解释提示在提升这些模型可靠性方面表现出显著效果，凸显了解释设置对于社会科学关于框架偏见的研究的重要性。特别是，GPT-4在提供一系列相关领域内例子时，表现出改进的少射情况下的性能。FLAN-T5的表现不佳表明较小的模型可能需要额外的任务特定微调以识别框架偏见检测。我们的研究还发现模型，特别是GPT-4，经常将情绪语言误解为框架偏见的指标，突显了区分的挑战。",
    "tldr": "通过研究GPT-3.5 Turbo、GPT-4和Flan-T5模型在识别新闻标题中框架偏见的性能，发现可解释提示能够显著提高这些模型的可靠性，GPT-4在少射场景中表现较好，而FLAN-T5的表现较差，指出较小模型可能需要更多任务特定微调。",
    "en_tdlr": "This work contributes to the expanding research on the applicability of LLMs in social sciences by examining the performance of GPT-3.5 Turbo, GPT-4, and Flan-T5 models in detecting framing bias in news headlines through zero-shot, few-shot, and explainable prompting methods. A key insight from our evaluation is the notable efficacy of explainable prompting in enhancing the reliability of these models, highlighting the importance of explainable settings for social science research on framing bias. GPT-4, in particular, demonstrated enhanced performance in few-shot scenarios when presented with a range of relevant, in-domain examples. FLAN-T5's poor performance indicates that smaller models may require additional task-specific fine-tuning for identifying framing bias detection. Our study also found that models, particularly GPT-4, often misinterpret emotional language as an indicator of framing bias, underscoring the challenge of distinguishing."
}