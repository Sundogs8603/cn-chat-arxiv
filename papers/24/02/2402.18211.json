{
    "title": "Catastrophic Overfitting: A Potential Blessing in Disguise",
    "abstract": "arXiv:2402.18211v1 Announce Type: new  Abstract: Fast Adversarial Training (FAT) has gained increasing attention within the research community owing to its efficacy in improving adversarial robustness. Particularly noteworthy is the challenge posed by catastrophic overfitting (CO) in this field. Although existing FAT approaches have made strides in mitigating CO, the ascent of adversarial robustness occurs with a non-negligible decline in classification accuracy on clean samples. To tackle this issue, we initially employ the feature activation differences between clean and adversarial examples to analyze the underlying causes of CO. Intriguingly, our findings reveal that CO can be attributed to the feature coverage induced by a few specific pathways. By intentionally manipulating feature activation differences in these pathways with well-designed regularization terms, we can effectively mitigate and induce CO, providing further evidence for this observation. Notably, models trained sta",
    "link": "https://arxiv.org/abs/2402.18211",
    "context": "Title: Catastrophic Overfitting: A Potential Blessing in Disguise\nAbstract: arXiv:2402.18211v1 Announce Type: new  Abstract: Fast Adversarial Training (FAT) has gained increasing attention within the research community owing to its efficacy in improving adversarial robustness. Particularly noteworthy is the challenge posed by catastrophic overfitting (CO) in this field. Although existing FAT approaches have made strides in mitigating CO, the ascent of adversarial robustness occurs with a non-negligible decline in classification accuracy on clean samples. To tackle this issue, we initially employ the feature activation differences between clean and adversarial examples to analyze the underlying causes of CO. Intriguingly, our findings reveal that CO can be attributed to the feature coverage induced by a few specific pathways. By intentionally manipulating feature activation differences in these pathways with well-designed regularization terms, we can effectively mitigate and induce CO, providing further evidence for this observation. Notably, models trained sta",
    "path": "papers/24/02/2402.18211.json",
    "total_tokens": 898,
    "translated_title": "灾难性过拟合：一个潜在的福祸相依之间",
    "translated_abstract": "利用快速对抗训练（Fast Adversarial Training，FAT）在改善对抗鲁棒性方面的有效性，引发研究界越来越多关注。尤其值得注意的是这一领域中所面临的灾难性过拟合（Catastrophic Overfitting, CO）挑战。虽然现有的FAT方法在减轻CO方面已经取得一定进展，但对抗性鲁棒性的提升伴随着对清洁样本分类准确性的不可忽略下降。为了解决这一问题，我们首先利用清洁和对抗样本之间的特征激活差异分析CO的潜在原因。有趣的是，我们的研究结果揭示了CO可以归因于由少量特定路径引起的特征覆盖。通过有针对性地操控这些路径中的特征激活差异并设计良好的正则项，我们可以有效减轻和诱导CO，为这一观察提供进一步证据。值得注意的是，训练的模型",
    "tldr": "研究利用特征激活差异分析灾难性过拟合的原因，针对性操控特定路径中的特征激活差异可有效减轻和诱导CO。",
    "en_tdlr": "The research analyzes the causes of catastrophic overfitting by using feature activation differences and effectively mitigates and induces CO by intentionally manipulating feature activation differences in specific pathways."
}