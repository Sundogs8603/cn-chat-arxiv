{
    "title": "Revisiting the Dataset Bias Problem from a Statistical Perspective",
    "abstract": "In this paper, we study the \"dataset bias\" problem from a statistical standpoint, and identify the main cause of the problem as the strong correlation between a class attribute u and a non-class attribute b in the input x, represented by p(u|b) differing significantly from p(u). Since p(u|b) appears as part of the sampling distributions in the standard maximum log-likelihood (MLL) objective, a model trained on a biased dataset via MLL inherently incorporates such correlation into its parameters, leading to poor generalization to unbiased test data. From this observation, we propose to mitigate dataset bias via either weighting the objective of each sample n by \\frac{1}{p(u_{n}|b_{n})} or sampling that sample with a weight proportional to \\frac{1}{p(u_{n}|b_{n})}. While both methods are statistically equivalent, the former proves more stable and effective in practice. Additionally, we establish a connection between our debiasing approach and causal reasoning, reinforcing our method's th",
    "link": "https://arxiv.org/abs/2402.03577",
    "context": "Title: Revisiting the Dataset Bias Problem from a Statistical Perspective\nAbstract: In this paper, we study the \"dataset bias\" problem from a statistical standpoint, and identify the main cause of the problem as the strong correlation between a class attribute u and a non-class attribute b in the input x, represented by p(u|b) differing significantly from p(u). Since p(u|b) appears as part of the sampling distributions in the standard maximum log-likelihood (MLL) objective, a model trained on a biased dataset via MLL inherently incorporates such correlation into its parameters, leading to poor generalization to unbiased test data. From this observation, we propose to mitigate dataset bias via either weighting the objective of each sample n by \\frac{1}{p(u_{n}|b_{n})} or sampling that sample with a weight proportional to \\frac{1}{p(u_{n}|b_{n})}. While both methods are statistically equivalent, the former proves more stable and effective in practice. Additionally, we establish a connection between our debiasing approach and causal reasoning, reinforcing our method's th",
    "path": "papers/24/02/2402.03577.json",
    "total_tokens": 994,
    "translated_title": "从统计学角度重新审视数据集偏差问题",
    "translated_abstract": "在本文中，我们从统计学的角度研究了“数据集偏差”问题，并确定了该问题的主要原因是输入x中类属性u与非类属性b之间的强相关性，由p(u|b)与p(u)显著不同所表示。由于p(u|b)出现在标准的最大对数似然（MLL）目标的抽样分布中，通过MLL在偏差数据集上训练的模型天然地将这种相关性纳入其参数中，导致对无偏测试数据的泛化能力差。基于这个观察，我们提出通过将每个样本n的目标加权为\\frac{1}{p(u_{n}|b_{n})}或者以与\\frac{1}{p(u_{n}|b_{n})}成比例的权重对样本进行采样来缓解数据集偏差。虽然这两种方法在统计上是等价的，但前者在实践中证明更稳定和有效。此外，我们建立了我们的去偏方法与因果推理之间的联系，加强了我们方法的思想。",
    "tldr": "本文从统计学的角度重新审视了“数据集偏差”问题，发现其主要原因是输入的类属性和非类属性之间的强相关性。通过在训练过程中考虑这种相关性，我们提出了一种缓解数据集偏差的方法，通过对每个样本的目标加权或以权重比例采样来实现。这种方法在实践中更加稳定和有效，并且与因果推理有一定的关联。",
    "en_tdlr": "This paper revisits the problem of dataset bias from a statistical perspective and identifies the strong correlation between a class attribute and a non-class attribute as the main cause. It proposes a method to mitigate dataset bias by weighting the objective of each sample or sampling with a weighted proportion. The approach is both statistically equivalent and more effective in practice, with potential connections to causal reasoning."
}