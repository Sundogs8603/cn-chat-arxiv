{
    "title": "Exploring the Efficacy of Large Language Models in Summarizing Mental Health Counseling Sessions: A Benchmark Study",
    "abstract": "arXiv:2402.19052v1 Announce Type: new  Abstract: Comprehensive summaries of sessions enable an effective continuity in mental health counseling, facilitating informed therapy planning. Yet, manual summarization presents a significant challenge, diverting experts' attention from the core counseling process. This study evaluates the effectiveness of state-of-the-art Large Language Models (LLMs) in selectively summarizing various components of therapy sessions through aspect-based summarization, aiming to benchmark their performance. We introduce MentalCLOUDS, a counseling-component guided summarization dataset consisting of 191 counseling sessions with summaries focused on three distinct counseling components (aka counseling aspects). Additionally, we assess the capabilities of 11 state-of-the-art LLMs in addressing the task of component-guided summarization in counseling. The generated summaries are evaluated quantitatively using standard summarization metrics and verified qualitatively",
    "link": "https://arxiv.org/abs/2402.19052",
    "context": "Title: Exploring the Efficacy of Large Language Models in Summarizing Mental Health Counseling Sessions: A Benchmark Study\nAbstract: arXiv:2402.19052v1 Announce Type: new  Abstract: Comprehensive summaries of sessions enable an effective continuity in mental health counseling, facilitating informed therapy planning. Yet, manual summarization presents a significant challenge, diverting experts' attention from the core counseling process. This study evaluates the effectiveness of state-of-the-art Large Language Models (LLMs) in selectively summarizing various components of therapy sessions through aspect-based summarization, aiming to benchmark their performance. We introduce MentalCLOUDS, a counseling-component guided summarization dataset consisting of 191 counseling sessions with summaries focused on three distinct counseling components (aka counseling aspects). Additionally, we assess the capabilities of 11 state-of-the-art LLMs in addressing the task of component-guided summarization in counseling. The generated summaries are evaluated quantitatively using standard summarization metrics and verified qualitatively",
    "path": "papers/24/02/2402.19052.json",
    "total_tokens": 858,
    "translated_title": "探索大型语言模型在总结心理健康咨询会话中的功效：基准研究",
    "translated_abstract": "全面总结会话有助于在心理健康咨询中有效地保持连续性，促进知情疗法规划。然而，手动总结存在重大挑战，分散专家注意力，偏离核心咨询流程。本研究评估了最先进的大型语言模型（LLMs）在通过基于方面的总结有选择性地总结各种疗法会话组件方面的效果，旨在对其性能进行基准测试。我们引入了MentalCLOUDS，一个由导师组件指导的总结数据集，包括191个重点关注三个不同辅导组件（也称为辅导方面）的辅导会话。此外，我们评估了11种最先进的LLM在解决辅导中基于组件的总结任务方面的能力。利用标准总结度量定量评估生成的总结，并在质量上验证",
    "tldr": "本研究评估大型语言模型在选择性总结心理健康咨询会话中的功效，并引入了MentalCLOUDS数据集作为基准，以探索其在辅导组件指导的总结任务中的性能。",
    "en_tdlr": "This study evaluates the efficacy of large language models in selectively summarizing mental health counseling sessions, introducing the MentalCLOUDS dataset as a benchmark for exploring their performance in component-guided summarization tasks."
}