{
    "title": "Retrieval-Augmented Score Distillation for Text-to-3D Generation",
    "abstract": "Text-to-3D generation has achieved significant success by incorporating powerful 2D diffusion models, but insufficient 3D prior knowledge also leads to the inconsistency of 3D geometry. Recently, since large-scale multi-view datasets have been released, fine-tuning the diffusion model on the multi-view datasets becomes a mainstream to solve the 3D inconsistency problem. However, it has confronted with fundamental difficulties regarding the limited quality and diversity of 3D data, compared with 2D data. To sidestep these trade-offs, we explore a retrieval-augmented approach tailored for score distillation, dubbed RetDream. We postulate that both expressiveness of 2D diffusion models and geometric consistency of 3D assets can be fully leveraged by employing the semantically relevant assets directly within the optimization process. To this end, we introduce novel framework for retrieval-based quality enhancement in text-to-3D generation. We leverage the retrieved asset to incorporate its",
    "link": "https://arxiv.org/abs/2402.02972",
    "context": "Title: Retrieval-Augmented Score Distillation for Text-to-3D Generation\nAbstract: Text-to-3D generation has achieved significant success by incorporating powerful 2D diffusion models, but insufficient 3D prior knowledge also leads to the inconsistency of 3D geometry. Recently, since large-scale multi-view datasets have been released, fine-tuning the diffusion model on the multi-view datasets becomes a mainstream to solve the 3D inconsistency problem. However, it has confronted with fundamental difficulties regarding the limited quality and diversity of 3D data, compared with 2D data. To sidestep these trade-offs, we explore a retrieval-augmented approach tailored for score distillation, dubbed RetDream. We postulate that both expressiveness of 2D diffusion models and geometric consistency of 3D assets can be fully leveraged by employing the semantically relevant assets directly within the optimization process. To this end, we introduce novel framework for retrieval-based quality enhancement in text-to-3D generation. We leverage the retrieved asset to incorporate its",
    "path": "papers/24/02/2402.02972.json",
    "total_tokens": 873,
    "translated_title": "检索增强的得分蒸馏用于文本到3D生成",
    "translated_abstract": "文本到3D生成通过引入强大的2D扩散模型取得了显著的成功，但不足的3D先验知识也导致了3D几何的不一致性。最近，由于发布了大规模的多视角数据集，将扩散模型在多视角数据集上进行微调成为解决3D一致性问题的主流方法。然而，与2D数据相比，3D数据的质量和多样性有限，这导致了困难。为了回避这些平衡问题，我们探索了一种针对得分蒸馏的检索增强方法，名为RetDream。我们假设通过在优化过程中直接使用语义相关的资源，可以充分利用2D扩散模型的表现力和3D资源的几何一致性。为此，我们引入了一种新的基于检索的质量增强框架，用于文本到3D生成。我们利用检索到的资源来融入其",
    "tldr": "RetDream是一种针对文本到3D生成的检索增强的得分蒸馏方法，通过直接使用语义相关的资源，可以充分利用2D扩散模型的表现力和3D资源的几何一致性。",
    "en_tdlr": "RetDream is a retrieval-augmented score distillation method for text-to-3D generation, which leverages the expressiveness of 2D diffusion models and the geometric consistency of 3D assets by directly using semantically relevant resources."
}