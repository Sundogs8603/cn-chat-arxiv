{
    "title": "Two-stage Generative Question Answering on Temporal Knowledge Graph Using Large Language Models",
    "abstract": "arXiv:2402.16568v1 Announce Type: new  Abstract: Temporal knowledge graph question answering (TKGQA) poses a significant challenge task, due to the temporal constraints hidden in questions and the answers sought from dynamic structured knowledge. Although large language models (LLMs) have made considerable progress in their reasoning ability over structured data, their application to the TKGQA task is a relatively unexplored area. This paper first proposes a novel generative temporal knowledge graph question answering framework, GenTKGQA, which guides LLMs to answer temporal questions through two phases: Subgraph Retrieval and Answer Generation. First, we exploit LLM's intrinsic knowledge to mine temporal constraints and structural links in the questions without extra training, thus narrowing down the subgraph search space in both temporal and structural dimensions. Next, we design virtual knowledge indicators to fuse the graph neural network signals of the subgraph and the text repres",
    "link": "https://arxiv.org/abs/2402.16568",
    "context": "Title: Two-stage Generative Question Answering on Temporal Knowledge Graph Using Large Language Models\nAbstract: arXiv:2402.16568v1 Announce Type: new  Abstract: Temporal knowledge graph question answering (TKGQA) poses a significant challenge task, due to the temporal constraints hidden in questions and the answers sought from dynamic structured knowledge. Although large language models (LLMs) have made considerable progress in their reasoning ability over structured data, their application to the TKGQA task is a relatively unexplored area. This paper first proposes a novel generative temporal knowledge graph question answering framework, GenTKGQA, which guides LLMs to answer temporal questions through two phases: Subgraph Retrieval and Answer Generation. First, we exploit LLM's intrinsic knowledge to mine temporal constraints and structural links in the questions without extra training, thus narrowing down the subgraph search space in both temporal and structural dimensions. Next, we design virtual knowledge indicators to fuse the graph neural network signals of the subgraph and the text repres",
    "path": "papers/24/02/2402.16568.json",
    "total_tokens": 851,
    "translated_title": "使用大型语言模型在时间知识图上进行两阶段生成式问答",
    "translated_abstract": "时间知识图问答(TKGQA)提出了一个重要的挑战任务，因为问题中隐藏着时间约束，并且从动态结构化知识中寻找答案。尽管大型语言模型(LLMs)在推理能力方面取得了相当大的进展，但它们在TKGQA任务中的应用是一个相对未开发的领域。本文首先提出了一种新颖的生成式时间知识图问答框架GenTKGQA，通过两个阶段引导LLMs回答时间性问题：子图检索和答案生成。首先，我们利用LLM的固有知识来挖掘问题中的时间约束和结构链接，无需额外训练，从而缩小了在时间和结构维度上的子图搜索空间。接下来，我们设计了虚拟知识指示器来融合子图和文本表示的图神经网络信号。",
    "tldr": "该论文提出了一种新颖的生成式时间知识图问答框架GenTKGQA，利用大型语言模型(LLMs)在时间知识图问答任务中的两阶段方法，即子图检索和答案生成。"
}