{
    "title": "Are Large Language Models Table-based Fact-Checkers?",
    "abstract": "Table-based Fact Verification (TFV) aims to extract the entailment relation between statements and structured tables. Existing TFV methods based on small-scaled models suffer from insufficient labeled data and weak zero-shot ability. Recently, the appearance of Large Language Models (LLMs) has gained lots of attraction in research fields. They have shown powerful zero-shot and in-context learning abilities on several NLP tasks, but their potential on TFV is still unknown. In this work, we implement a preliminary study about whether LLMs are table-based fact-checkers. In detail, we design diverse prompts to explore how the in-context learning can help LLMs in TFV, i.e., zero-shot and few-shot TFV capability. Besides, we carefully design and construct TFV instructions to study the performance gain brought by the instruction tuning of LLMs. Experimental results demonstrate that LLMs can achieve acceptable results on zero-shot and few-shot TFV with prompt engineering, while instruction-tun",
    "link": "https://arxiv.org/abs/2402.02549",
    "context": "Title: Are Large Language Models Table-based Fact-Checkers?\nAbstract: Table-based Fact Verification (TFV) aims to extract the entailment relation between statements and structured tables. Existing TFV methods based on small-scaled models suffer from insufficient labeled data and weak zero-shot ability. Recently, the appearance of Large Language Models (LLMs) has gained lots of attraction in research fields. They have shown powerful zero-shot and in-context learning abilities on several NLP tasks, but their potential on TFV is still unknown. In this work, we implement a preliminary study about whether LLMs are table-based fact-checkers. In detail, we design diverse prompts to explore how the in-context learning can help LLMs in TFV, i.e., zero-shot and few-shot TFV capability. Besides, we carefully design and construct TFV instructions to study the performance gain brought by the instruction tuning of LLMs. Experimental results demonstrate that LLMs can achieve acceptable results on zero-shot and few-shot TFV with prompt engineering, while instruction-tun",
    "path": "papers/24/02/2402.02549.json",
    "total_tokens": 924,
    "translated_title": "大型语言模型是否适合基于表格的事实检查？",
    "translated_abstract": "基于表格的事实验证（TFV）旨在提取语句和结构化表格之间的蕴涵关系。现有基于小规模模型的TFV方法在标注数据不足和零样本能力薄弱方面存在问题。近年来，大型语言模型（LLMs）在研究领域引起了广泛关注。它们在几个自然语言处理任务上展示了强大的零样本和上下文学习能力，但它们在TFV领域的潜力还不清楚。在本文中，我们进行了关于LLMs是否适合作为基于表格的事实检查器的初步研究。具体来说，我们设计了多样化的提示语来探索上下文学习如何帮助LLMs在TFV方面，即零样本和少样本TFV能力。此外，我们精心设计和构建了TFV指导以研究LLMs的指导调整带来的性能改进。实验结果表明，通过提示工程，LLMs在零样本和少样本TFV方面可以达到可接受的结果，而指导调整则进一步提升了性能。",
    "tldr": "本研究初步探讨了大型语言模型在基于表格的事实检查方面的潜力。实验结果表明，通过提示工程，大型语言模型在零样本和少样本的情况下可以实现可接受的表现。"
}