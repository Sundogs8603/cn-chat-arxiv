{
    "title": "Adaptive Skeleton Graph Decoding",
    "abstract": "arXiv:2402.12280v1 Announce Type: cross  Abstract: Large language models (LLMs) have seen significant adoption for natural language tasks, owing their success to massive numbers of model parameters (e.g., 70B+); however, LLM inference incurs significant computation and memory costs. Recent approaches propose parallel decoding strategies, such as Skeleton-of-Thought (SoT), to improve performance by breaking prompts down into sub-problems that can be decoded in parallel; however, they often suffer from reduced response quality. Our key insight is that we can request additional information, specifically dependencies and difficulty, when generating the sub-problems to improve both response quality and performance. In this paper, we propose Skeleton Graph Decoding (SGD), which uses dependencies exposed between sub-problems to support information forwarding between dependent sub-problems for improved quality while exposing parallelization opportunities for decoding independent sub-problems. ",
    "link": "https://arxiv.org/abs/2402.12280",
    "context": "Title: Adaptive Skeleton Graph Decoding\nAbstract: arXiv:2402.12280v1 Announce Type: cross  Abstract: Large language models (LLMs) have seen significant adoption for natural language tasks, owing their success to massive numbers of model parameters (e.g., 70B+); however, LLM inference incurs significant computation and memory costs. Recent approaches propose parallel decoding strategies, such as Skeleton-of-Thought (SoT), to improve performance by breaking prompts down into sub-problems that can be decoded in parallel; however, they often suffer from reduced response quality. Our key insight is that we can request additional information, specifically dependencies and difficulty, when generating the sub-problems to improve both response quality and performance. In this paper, we propose Skeleton Graph Decoding (SGD), which uses dependencies exposed between sub-problems to support information forwarding between dependent sub-problems for improved quality while exposing parallelization opportunities for decoding independent sub-problems. ",
    "path": "papers/24/02/2402.12280.json",
    "total_tokens": 791,
    "translated_title": "自适应骨架图解码",
    "translated_abstract": "大型语言模型（LLMs）已经在自然语言任务中得到广泛应用，其成功归因于大量的模型参数（例如，70亿+）；然而，LLM推断会产生巨大的计算和内存成本。最近的方法提出了并行解码策略，例如“思想骨架”（SoT），通过将提示分解为可以并行解码的子问题来改善性能；但是，它们往往在响应质量上遭受损失。我们的关键见解是，在生成子问题时，我们可以请求额外信息，特别是依赖关系和难度，以提高响应质量和性能。在本文中，我们提出了骨架图解码（SGD），利用子问题之间暴露的依赖关系，支持依赖子问题之间的信息转发，以提高质量，同时暴露独立子问题解码的并行化机会。",
    "tldr": "提出了骨架图解码（SGD）方法，利用子问题之间的依赖关系进行信息转发，改善响应质量且提高性能。",
    "en_tdlr": "Proposed Skeleton Graph Decoding (SGD) method utilizes dependencies between sub-problems for information forwarding, improving response quality and performance."
}