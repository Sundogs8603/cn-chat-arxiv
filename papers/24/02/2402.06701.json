{
    "title": "Privacy Profiles for Private Selection",
    "abstract": "Private selection mechanisms (e.g., Report Noisy Max, Sparse Vector) are fundamental primitives of differentially private (DP) data analysis with wide applications to private query release, voting, and hyperparameter tuning. Recent work (Liu and Talwar, 2019; Papernot and Steinke, 2022) has made significant progress in both generalizing private selection mechanisms and tightening their privacy analysis using modern numerical privacy accounting tools, e.g., R\\'enyi DP. But R\\'enyi DP is known to be lossy when $(\\epsilon,\\delta)$-DP is ultimately needed, and there is a trend to close the gap by directly handling privacy profiles, i.e., $\\delta$ as a function of $\\epsilon$ or its equivalent dual form known as $f$-DPs. In this paper, we work out an easy-to-use recipe that bounds the privacy profiles of ReportNoisyMax and PrivateTuning using the privacy profiles of the base algorithms they corral. Numerically, our approach improves over the RDP-based accounting in all regimes of interest an",
    "link": "https://arxiv.org/abs/2402.06701",
    "context": "Title: Privacy Profiles for Private Selection\nAbstract: Private selection mechanisms (e.g., Report Noisy Max, Sparse Vector) are fundamental primitives of differentially private (DP) data analysis with wide applications to private query release, voting, and hyperparameter tuning. Recent work (Liu and Talwar, 2019; Papernot and Steinke, 2022) has made significant progress in both generalizing private selection mechanisms and tightening their privacy analysis using modern numerical privacy accounting tools, e.g., R\\'enyi DP. But R\\'enyi DP is known to be lossy when $(\\epsilon,\\delta)$-DP is ultimately needed, and there is a trend to close the gap by directly handling privacy profiles, i.e., $\\delta$ as a function of $\\epsilon$ or its equivalent dual form known as $f$-DPs. In this paper, we work out an easy-to-use recipe that bounds the privacy profiles of ReportNoisyMax and PrivateTuning using the privacy profiles of the base algorithms they corral. Numerically, our approach improves over the RDP-based accounting in all regimes of interest an",
    "path": "papers/24/02/2402.06701.json",
    "total_tokens": 736,
    "translated_title": "针对私有选择的隐私配置文件",
    "translated_abstract": "私有选择机制是差分隐私数据分析的基本原语，广泛应用于私有查询发布、投票和超参数调整等领域。最近的研究在泛化私有选择机制和使用现代数值隐私账务工具（如R\\'enyi差分隐私）收敛隐私分析方面取得了重要进展。本文提出了一种易于使用的方法，通过限制基础算法的隐私配置文件来界定ReportNoisyMax和PrivateTuning的隐私配置文件。在数值上，我们的方法在所有感兴趣的区域都优于基于RDP的隐私账务方法。",
    "tldr": "本文提出了一种易于使用的方法，通过限制基础算法的隐私配置文件来界定ReportNoisyMax和PrivateTuning的隐私配置文件。",
    "en_tdlr": "This paper proposes an easy-to-use method that bounds the privacy profiles of ReportNoisyMax and PrivateTuning by restricting the privacy profiles of the base algorithms."
}