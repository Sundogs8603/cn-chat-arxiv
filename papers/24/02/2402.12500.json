{
    "title": "Integrating kNN with Foundation Models for Adaptable and Privacy-Aware Image Classification",
    "abstract": "arXiv:2402.12500v1 Announce Type: cross  Abstract: Traditional deep learning models implicity encode knowledge limiting their transparency and ability to adapt to data changes. Yet, this adaptability is vital for addressing user data privacy concerns. We address this limitation by storing embeddings of the underlying training data independently of the model weights, enabling dynamic data modifications without retraining. Specifically, our approach integrates the $k$-Nearest Neighbor ($k$-NN) classifier with a vision-based foundation model, pre-trained self-supervised on natural images, enhancing interpretability and adaptability. We share open-source implementations of a previously unpublished baseline method as well as our performance-improving contributions. Quantitative experiments confirm improved classification across established benchmark datasets and the method's applicability to distinct medical image classification tasks. Additionally, we assess the method's robustness in cont",
    "link": "https://arxiv.org/abs/2402.12500",
    "context": "Title: Integrating kNN with Foundation Models for Adaptable and Privacy-Aware Image Classification\nAbstract: arXiv:2402.12500v1 Announce Type: cross  Abstract: Traditional deep learning models implicity encode knowledge limiting their transparency and ability to adapt to data changes. Yet, this adaptability is vital for addressing user data privacy concerns. We address this limitation by storing embeddings of the underlying training data independently of the model weights, enabling dynamic data modifications without retraining. Specifically, our approach integrates the $k$-Nearest Neighbor ($k$-NN) classifier with a vision-based foundation model, pre-trained self-supervised on natural images, enhancing interpretability and adaptability. We share open-source implementations of a previously unpublished baseline method as well as our performance-improving contributions. Quantitative experiments confirm improved classification across established benchmark datasets and the method's applicability to distinct medical image classification tasks. Additionally, we assess the method's robustness in cont",
    "path": "papers/24/02/2402.12500.json",
    "total_tokens": 861,
    "translated_title": "将kNN与基础模型结合，实现适应性和注重隐私的图像分类",
    "translated_abstract": "传统的深度学习模型隐含地编码知识，限制了它们的透明度和适应数据变化的能力。然而，这种适应性对解决用户数据隐私问题至关重要。我们通过独立存储基础训练数据的嵌入来解决这一限制，而不是依赖模型权重，从而实现动态数据修改而无需重新训练。具体来说，我们的方法将k近邻（k-NN）分类器与基于视觉的基础模型集成，该模型在自然图像上进行了自监督预训练，提高了可解释性和适应性。我们共享了之前未公开的基线方法的开源实现，以及我们的性能提升贡献。定量实验证实了在已建立的基准数据集上改善分类效果以及该方法在不同医学图像分类任务中的适用性。此外，我们评估了该方法在cont",
    "tldr": "将kNN与自然图像上自监督预训练的基础模型结合，独立存储训练数据的嵌入，实现动态数据修改而无需重新训练，提升图像分类的可解释性和适应性"
}