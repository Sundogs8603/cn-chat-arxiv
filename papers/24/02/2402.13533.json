{
    "title": "FinGPT-HPC: Efficient Pretraining and Finetuning Large Language Models for Financial Applications with High-Performance Computing",
    "abstract": "arXiv:2402.13533v1 Announce Type: cross  Abstract: Large language models (LLMs) are computationally intensive. The computation workload and the memory footprint grow quadratically with the dimension (layer width). Most of LLMs' parameters come from the linear layers of the transformer structure and are highly redundant. These linear layers contribute more than 80% of the computation workload and 99% of the model size. To pretrain and finetune LLMs efficiently, there are three major challenges to address: 1) reducing redundancy of the linear layers; 2) reducing GPU memory footprint; 3) improving GPU utilization when using distributed training. Prior methods, such as LoRA and QLoRA, utilized low-rank matrices and quantization to reduce the number of trainable parameters and model size, respectively. However, the resulting model still consumes a large amount of GPU memory. In this paper, we present high-performance GPU-based methods that exploit low-rank structures to pretrain and finetun",
    "link": "https://arxiv.org/abs/2402.13533",
    "context": "Title: FinGPT-HPC: Efficient Pretraining and Finetuning Large Language Models for Financial Applications with High-Performance Computing\nAbstract: arXiv:2402.13533v1 Announce Type: cross  Abstract: Large language models (LLMs) are computationally intensive. The computation workload and the memory footprint grow quadratically with the dimension (layer width). Most of LLMs' parameters come from the linear layers of the transformer structure and are highly redundant. These linear layers contribute more than 80% of the computation workload and 99% of the model size. To pretrain and finetune LLMs efficiently, there are three major challenges to address: 1) reducing redundancy of the linear layers; 2) reducing GPU memory footprint; 3) improving GPU utilization when using distributed training. Prior methods, such as LoRA and QLoRA, utilized low-rank matrices and quantization to reduce the number of trainable parameters and model size, respectively. However, the resulting model still consumes a large amount of GPU memory. In this paper, we present high-performance GPU-based methods that exploit low-rank structures to pretrain and finetun",
    "path": "papers/24/02/2402.13533.json",
    "total_tokens": 926,
    "translated_title": "FinGPT-HPC: 高性能计算下用于金融应用的高效预训练和微调大型语言模型",
    "translated_abstract": "大型语言模型(LLMs)的计算密集性很高。计算工作量和内存占用量随维度(层宽度)的增加呈二次增长。大多数LLM参数来自变压器结构的线性层，具有高度冗余性。这些线性层贡献了超过80%的计算工作量和99%的模型大小。为了高效地预训练和微调LLMs，需要解决三个主要挑战：1) 减少线性层的冗余性；2) 减少GPU内存占用；3) 在使用分布式训练时提高GPU利用率。之前的方法，如LoRA和QLoRA，利用低秩矩阵和量化来分别减少可训练参数的数量和模型大小。然而， resulting model 仍然消耗大量GPU内存。在本文中，我们提出了基于高性能GPU的方法，利用低秩结构来预训练和微调。",
    "tldr": "该论文提出了一种基于高性能GPU的方法，利用低秩结构来高效地预训练和微调大型语言模型，解决了线性层冗余性、GPU内存占用和分布式训练中GPU利用率不足的挑战",
    "en_tdlr": "The paper introduces a GPU-based method that efficiently pretrains and fine-tunes large language models by leveraging low-rank structures, addressing challenges of redundancy in linear layers, GPU memory consumption, and inadequate GPU utilization in distributed training."
}