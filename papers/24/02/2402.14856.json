{
    "title": "Comparing Inferential Strategies of Humans and Large Language Models in Deductive Reasoning",
    "abstract": "arXiv:2402.14856v1 Announce Type: cross  Abstract: Deductive reasoning plays a pivotal role in the formulation of sound and cohesive arguments. It allows individuals to draw conclusions that logically follow, given the truth value of the information provided. Recent progress in the domain of large language models (LLMs) has showcased their capability in executing deductive reasoning tasks. Nonetheless, a significant portion of research primarily assesses the accuracy of LLMs in solving such tasks, often overlooking a deeper analysis of their reasoning behavior. In this study, we draw upon principles from cognitive psychology to examine inferential strategies employed by LLMs, through a detailed evaluation of their responses to propositional logic problems. Our findings indicate that LLMs display reasoning patterns akin to those observed in humans, including strategies like $\\textit{supposition following}$ or $\\textit{chain construction}$. Moreover, our research demonstrates that the ar",
    "link": "https://arxiv.org/abs/2402.14856",
    "context": "Title: Comparing Inferential Strategies of Humans and Large Language Models in Deductive Reasoning\nAbstract: arXiv:2402.14856v1 Announce Type: cross  Abstract: Deductive reasoning plays a pivotal role in the formulation of sound and cohesive arguments. It allows individuals to draw conclusions that logically follow, given the truth value of the information provided. Recent progress in the domain of large language models (LLMs) has showcased their capability in executing deductive reasoning tasks. Nonetheless, a significant portion of research primarily assesses the accuracy of LLMs in solving such tasks, often overlooking a deeper analysis of their reasoning behavior. In this study, we draw upon principles from cognitive psychology to examine inferential strategies employed by LLMs, through a detailed evaluation of their responses to propositional logic problems. Our findings indicate that LLMs display reasoning patterns akin to those observed in humans, including strategies like $\\textit{supposition following}$ or $\\textit{chain construction}$. Moreover, our research demonstrates that the ar",
    "path": "papers/24/02/2402.14856.json",
    "total_tokens": 859,
    "translated_title": "在推理思维中比较人类和大型语言模型的推理策略",
    "translated_abstract": "推理思维在制定健全和连贯论点方面扮演了关键角色。它允许个体根据所提供信息的真值得出逻辑上的结论。在大型语言模型（LLMs）领域的最新进展展示了它们在执行演绎推理任务方面的能力。然而，大部分研究主要评估LLMs在解决此类任务中的准确性，往往忽视了对其推理行为进行更深入的分析。在本研究中，我们借鉴认知心理学原理，通过对它们对命题逻辑问题的响应进行详细评估，来研究LLMs采用的推理策略。我们的研究结果表明，LLMs展现出类似于人类观察到的推理模式，包括诸如“假定跟随”或“链构建”等策略。此外，我们的研究证明了arXiv:2402.14856v1 Announce Type: cross",
    "tldr": "该研究通过对大型语言模型对命题逻辑问题的响应进行评估，揭示出它们展现出与人类类似的推理模式和策略。",
    "en_tdlr": "This study evaluates the responses of large language models to propositional logic problems, revealing that they exhibit reasoning patterns and strategies similar to humans."
}