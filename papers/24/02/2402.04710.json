{
    "title": "Incorporating Retrieval-based Causal Learning with Information Bottlenecks for Interpretable Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have gained considerable traction for their capability to effectively process topological data, yet their interpretability remains a critical concern. Current interpretation methods are dominated by post-hoc explanations to provide a transparent and intuitive understanding of GNNs. However, they have limited performance in interpreting complicated subgraphs and can't utilize the explanation to advance GNN predictions. On the other hand, transparent GNN models are proposed to capture critical subgraphs. While such methods could improve GNN predictions, they usually don't perform well on explanations. Thus, it is desired for a new strategy to better couple GNN explanation and prediction. In this study, we have developed a novel interpretable causal GNN framework that incorporates retrieval-based causal learning with Graph Information Bottleneck (GIB) theory. The framework could semi-parametrically retrieve crucial subgraphs detected by GIB and compress the ex",
    "link": "https://arxiv.org/abs/2402.04710",
    "context": "Title: Incorporating Retrieval-based Causal Learning with Information Bottlenecks for Interpretable Graph Neural Networks\nAbstract: Graph Neural Networks (GNNs) have gained considerable traction for their capability to effectively process topological data, yet their interpretability remains a critical concern. Current interpretation methods are dominated by post-hoc explanations to provide a transparent and intuitive understanding of GNNs. However, they have limited performance in interpreting complicated subgraphs and can't utilize the explanation to advance GNN predictions. On the other hand, transparent GNN models are proposed to capture critical subgraphs. While such methods could improve GNN predictions, they usually don't perform well on explanations. Thus, it is desired for a new strategy to better couple GNN explanation and prediction. In this study, we have developed a novel interpretable causal GNN framework that incorporates retrieval-based causal learning with Graph Information Bottleneck (GIB) theory. The framework could semi-parametrically retrieve crucial subgraphs detected by GIB and compress the ex",
    "path": "papers/24/02/2402.04710.json",
    "total_tokens": 889,
    "translated_title": "将检索式因果学习与信息瓶颈相结合，用于可解释的图神经网络",
    "translated_abstract": "图神经网络（GNN）因其有效处理拓扑数据的能力而受到广泛关注，但其可解释性仍然是一个关键问题。当前的解释方法主要依赖事后解释，以提供对GNN的透明和直观理解。然而，在解释复杂子图时，它们的性能有限，无法利用解释来改进GNN的预测。另一方面，提出了透明的GNN模型来捕捉关键子图。虽然这种方法可以改善GNN的预测，但在解释方面通常表现不佳。因此，需要一种新的策略更好地联系GNN的解释与预测。在本研究中，我们开发了一种新颖的、可解释的因果GNN框架，它将检索式因果学习与图信息瓶颈（GIB）理论相结合。该框架能够半参数地检索GIB检测到的关键子图，并压缩解释信息以提高预测性能。",
    "tldr": "本研究开发了一种新颖的、可解释的因果GNN框架，将检索式因果学习与图信息瓶颈相结合，能够有效地处理拓扑数据，并提供对GNN的透明和直观理解。",
    "en_tdlr": "We propose a novel interpretable causal GNN framework that combines retrieval-based causal learning with Graph Information Bottleneck theory, enabling effective processing of topological data and providing transparent and intuitive understanding of GNNs."
}