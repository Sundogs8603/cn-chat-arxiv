{
    "title": "Deep Clustering Using the Soft Silhouette Score: Towards Compact and Well-Separated Clusters",
    "abstract": "Unsupervised learning has gained prominence in the big data era, offering a means to extract valuable insights from unlabeled datasets. Deep clustering has emerged as an important unsupervised category, aiming to exploit the non-linear mapping capabilities of neural networks in order to enhance clustering performance. The majority of deep clustering literature focuses on minimizing the inner-cluster variability in some embedded space while keeping the learned representation consistent with the original high-dimensional dataset. In this work, we propose soft silhoutte, a probabilistic formulation of the silhouette coefficient. Soft silhouette rewards compact and distinctly separated clustering solutions like the conventional silhouette coefficient. When optimized within a deep clustering framework, soft silhouette guides the learned representations towards forming compact and well-separated clusters. In addition, we introduce an autoencoder-based deep learning architecture that is suita",
    "link": "https://arxiv.org/abs/2402.00608",
    "context": "Title: Deep Clustering Using the Soft Silhouette Score: Towards Compact and Well-Separated Clusters\nAbstract: Unsupervised learning has gained prominence in the big data era, offering a means to extract valuable insights from unlabeled datasets. Deep clustering has emerged as an important unsupervised category, aiming to exploit the non-linear mapping capabilities of neural networks in order to enhance clustering performance. The majority of deep clustering literature focuses on minimizing the inner-cluster variability in some embedded space while keeping the learned representation consistent with the original high-dimensional dataset. In this work, we propose soft silhoutte, a probabilistic formulation of the silhouette coefficient. Soft silhouette rewards compact and distinctly separated clustering solutions like the conventional silhouette coefficient. When optimized within a deep clustering framework, soft silhouette guides the learned representations towards forming compact and well-separated clusters. In addition, we introduce an autoencoder-based deep learning architecture that is suita",
    "path": "papers/24/02/2402.00608.json",
    "total_tokens": 878,
    "translated_title": "使用软轮廓分数的深度聚类：朝向紧凑且互相分离的簇",
    "translated_abstract": "在大数据时代，无监督学习因其能从未标记的数据集中提取有价值的见解而日益重要。深度聚类已成为重要的无监督学习方法之一，旨在利用神经网络的非线性映射能力来提升聚类性能。大部分深度聚类的文献都致力于在某个嵌入空间中最小化内部聚类变异性，同时保持学习到的表示与原始高维数据一致。本文提出了软轮廓，即轮廓系数的概率形式。软轮廓与传统的轮廓系数一样，奖励紧凑且明显分离的聚类解决方案。在深度聚类框架中优化软轮廓可以引导学习到的表示形成紧凑且互相分离的簇。此外，我们还介绍了一个基于自编码器的深度学习架构，适用于这种深度聚类方法。",
    "tldr": "本研究提出了软轮廓系数，通过在深度聚类中优化该系数，可以实现形成紧凑且互相分离的簇。同时引入了适用于该方法的自编码器深度学习架构。",
    "en_tdlr": "This research proposes a soft silhouette score that rewards compact and well-separated clusters in deep clustering, optimizing it leads to clusters with these characteristics. Additionally, an autoencoder-based deep learning architecture is introduced for this approach."
}