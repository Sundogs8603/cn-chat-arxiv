{
    "title": "Improving Neural-based Classification with Logical Background Knowledge",
    "abstract": "arXiv:2402.13019v1 Announce Type: new  Abstract: Neurosymbolic AI is a growing field of research aiming to combine neural networks learning capabilities with the reasoning abilities of symbolic systems. This hybridization can take many shapes. In this paper, we propose a new formalism for supervised multi-label classification with propositional background knowledge. We introduce a new neurosymbolic technique called semantic conditioning at inference, which only constrains the system during inference while leaving the training unaffected. We discuss its theoritical and practical advantages over two other popular neurosymbolic techniques: semantic conditioning and semantic regularization. We develop a new multi-scale methodology to evaluate how the benefits of a neurosymbolic technique evolve with the scale of the network. We then evaluate experimentally and compare the benefits of all three techniques across model scales on several datasets. Our results demonstrate that semantic conditi",
    "link": "https://arxiv.org/abs/2402.13019",
    "context": "Title: Improving Neural-based Classification with Logical Background Knowledge\nAbstract: arXiv:2402.13019v1 Announce Type: new  Abstract: Neurosymbolic AI is a growing field of research aiming to combine neural networks learning capabilities with the reasoning abilities of symbolic systems. This hybridization can take many shapes. In this paper, we propose a new formalism for supervised multi-label classification with propositional background knowledge. We introduce a new neurosymbolic technique called semantic conditioning at inference, which only constrains the system during inference while leaving the training unaffected. We discuss its theoritical and practical advantages over two other popular neurosymbolic techniques: semantic conditioning and semantic regularization. We develop a new multi-scale methodology to evaluate how the benefits of a neurosymbolic technique evolve with the scale of the network. We then evaluate experimentally and compare the benefits of all three techniques across model scales on several datasets. Our results demonstrate that semantic conditi",
    "path": "papers/24/02/2402.13019.json",
    "total_tokens": 922,
    "translated_title": "用逻辑背景知识提升基于神经网络的分类",
    "translated_abstract": "arXiv:2402.13019v1 公告类型:新 抽象:神经符号人工智能是一个日益发展的研究领域，旨在将神经网络学习能力与符号系统的推理能力相结合。这种混合可以采用多种形式。在本文中，我们提出了一种新的形式化方法，用于具有命题背景知识的监督式多标签分类。我们引入了一种名为在推理过程中的语义调节的新的神经符号技术，该技术仅在推理过程中约束系统，而不影响训练。我们讨论了它相对于另外两种流行的神经符号技术——语义调节和语义正则化的理论和实际优势。我们开发了一种新的多尺度方法，评估神经符号技术的好处随网络规模的变化而发展。然后，我们在几个数据集上实验评估并比较这三种技术的好处。我们的结果表明，语义调节…",
    "tldr": "本文提出了一种新的神经符号技术——在推理过程中的语义调节，该技术仅在推理过程中约束系统，而不影响训练，相对于其他两种常见神经符号技术具有理论和实际优势，在多尺度方法上的评估结果表明其对网络规模的好处。"
}