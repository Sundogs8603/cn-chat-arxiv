{
    "title": "BiVRec: Bidirectional View-based Multimodal Sequential Recommendation",
    "abstract": "arXiv:2402.17334v1 Announce Type: cross  Abstract: The integration of multimodal information into sequential recommender systems has attracted significant attention in recent research. In the initial stages of multimodal sequential recommendation models, the mainstream paradigm was ID-dominant recommendations, wherein multimodal information was fused as side information. However, due to their limitations in terms of transferability and information intrusion, another paradigm emerged, wherein multimodal features were employed directly for recommendation, enabling recommendation across datasets. Nonetheless, it overlooked user ID information, resulting in low information utilization and high training costs. To this end, we propose an innovative framework, BivRec, that jointly trains the recommendation tasks in both ID and multimodal views, leveraging their synergistic relationship to enhance recommendation performance bidirectionally. To tackle the information heterogeneity issue, we fir",
    "link": "https://arxiv.org/abs/2402.17334",
    "context": "Title: BiVRec: Bidirectional View-based Multimodal Sequential Recommendation\nAbstract: arXiv:2402.17334v1 Announce Type: cross  Abstract: The integration of multimodal information into sequential recommender systems has attracted significant attention in recent research. In the initial stages of multimodal sequential recommendation models, the mainstream paradigm was ID-dominant recommendations, wherein multimodal information was fused as side information. However, due to their limitations in terms of transferability and information intrusion, another paradigm emerged, wherein multimodal features were employed directly for recommendation, enabling recommendation across datasets. Nonetheless, it overlooked user ID information, resulting in low information utilization and high training costs. To this end, we propose an innovative framework, BivRec, that jointly trains the recommendation tasks in both ID and multimodal views, leveraging their synergistic relationship to enhance recommendation performance bidirectionally. To tackle the information heterogeneity issue, we fir",
    "path": "papers/24/02/2402.17334.json",
    "total_tokens": 771,
    "translated_title": "BiVRec: 双向基于视图的多模态顺序推荐",
    "translated_abstract": "多模态信息融入顺序推荐系统近来引起了研究的广泛关注。在多模态顺序推荐模型的初期阶段，主流范式是ID主导推荐，即多模态信息作为辅助信息进行融合。然而，由于其在可转移性和信息侵入方面的局限性，另一种范式出现了，即直接利用多模态特征进行推荐，实现跨数据集的推荐。尽管如此，它忽略了用户ID信息，导致信息利用率低和训练成本高。为此，我们提出了一个创新框架，BiVRec，通过联合训练ID和多模态视图中的推荐任务，利用它们之间的协同关系双向增强推荐性能。为了解决信息异构性问题，我们...",
    "tldr": "提出了一个创新框架 BiVRec，在推荐任务中联合训练 ID 和多模态视图，双向增强推荐性能。",
    "en_tdlr": "Proposed an innovative framework BiVRec that jointly trains the recommendation tasks in both ID and multimodal views, enhancing recommendation performance bidirectionally."
}