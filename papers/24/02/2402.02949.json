{
    "title": "Kernel PCA for Out-of-Distribution Detection",
    "abstract": "Out-of-Distribution (OoD) detection is vital for the reliability of Deep Neural Networks (DNNs). Existing works have shown the insufficiency of Principal Component Analysis (PCA) straightforwardly applied on the features of DNNs in detecting OoD data from In-Distribution (InD) data. The failure of PCA suggests that the network features residing in OoD and InD are not well separated by simply proceeding in a linear subspace, which instead can be resolved through proper nonlinear mappings. In this work, we leverage the framework of Kernel PCA (KPCA) for OoD detection, seeking subspaces where OoD and InD features are allocated with significantly different patterns. We devise two feature mappings that induce non-linear kernels in KPCA to advocate the separability between InD and OoD data in the subspace spanned by the principal components. Given any test sample, the reconstruction error in such subspace is then used to efficiently obtain the detection result with $\\mathcal{O}(1)$ time comp",
    "link": "https://arxiv.org/abs/2402.02949",
    "context": "Title: Kernel PCA for Out-of-Distribution Detection\nAbstract: Out-of-Distribution (OoD) detection is vital for the reliability of Deep Neural Networks (DNNs). Existing works have shown the insufficiency of Principal Component Analysis (PCA) straightforwardly applied on the features of DNNs in detecting OoD data from In-Distribution (InD) data. The failure of PCA suggests that the network features residing in OoD and InD are not well separated by simply proceeding in a linear subspace, which instead can be resolved through proper nonlinear mappings. In this work, we leverage the framework of Kernel PCA (KPCA) for OoD detection, seeking subspaces where OoD and InD features are allocated with significantly different patterns. We devise two feature mappings that induce non-linear kernels in KPCA to advocate the separability between InD and OoD data in the subspace spanned by the principal components. Given any test sample, the reconstruction error in such subspace is then used to efficiently obtain the detection result with $\\mathcal{O}(1)$ time comp",
    "path": "papers/24/02/2402.02949.json",
    "total_tokens": 870,
    "translated_title": "外分布检测的核PCA",
    "translated_abstract": "外分布（OoD）检测对于深度神经网络（DNN）的可靠性至关重要。现有的研究表明，直接应用于DNN特征的主成分分析（PCA）在检测来自内分布（InD）数据的OoD数据方面不足够。PCA的失败表明，仅通过在线性子空间中进行简单处理无法很好地将OoD和InD中的网络特征分离开来，而可以通过适当的非线性映射来解决。在这项工作中，我们利用核PCA（KPCA）框架进行OoD检测，寻找OoD和InD特征以显著不同的模式分配的子空间。我们设计了两种特征映射，在KPCA中引入非线性内核，以促进在主成分张成的子空间中InD和OoD数据之间的可分性。然后，通过在这种子空间中的重构误差，可以有效地得到$\\mathcal{O}(1)$时间复杂度的检测结果。",
    "tldr": "本论文提出了使用核PCA进行外分布检测的方法，通过在主成分子空间中引入非线性映射，实现了对内分布和外分布数据的有效区分。"
}