{
    "title": "FL-NAS: Towards Fairness of NAS for Resource Constrained Devices via Large Language Models",
    "abstract": "Neural Architecture Search (NAS) has become the de fecto tools in the industry in automating the design of deep neural networks for various applications, especially those driven by mobile and edge devices with limited computing resources. The emerging large language models (LLMs), due to their prowess, have also been incorporated into NAS recently and show some promising results. This paper conducts further exploration in this direction by considering three important design metrics simultaneously, i.e., model accuracy, fairness, and hardware deployment efficiency. We propose a novel LLM-based NAS framework, FL-NAS, in this paper, and show experimentally that FL-NAS can indeed find high-performing DNNs, beating state-of-the-art DNN models by orders-of-magnitude across almost all design considerations.",
    "link": "https://arxiv.org/abs/2402.06696",
    "context": "Title: FL-NAS: Towards Fairness of NAS for Resource Constrained Devices via Large Language Models\nAbstract: Neural Architecture Search (NAS) has become the de fecto tools in the industry in automating the design of deep neural networks for various applications, especially those driven by mobile and edge devices with limited computing resources. The emerging large language models (LLMs), due to their prowess, have also been incorporated into NAS recently and show some promising results. This paper conducts further exploration in this direction by considering three important design metrics simultaneously, i.e., model accuracy, fairness, and hardware deployment efficiency. We propose a novel LLM-based NAS framework, FL-NAS, in this paper, and show experimentally that FL-NAS can indeed find high-performing DNNs, beating state-of-the-art DNN models by orders-of-magnitude across almost all design considerations.",
    "path": "papers/24/02/2402.06696.json",
    "total_tokens": 782,
    "translated_title": "FL-NAS: 通过大型语言模型为资源受限设备实现公平的NAS",
    "translated_abstract": "神经架构搜索（NAS）已成为工业界自动设计深度神经网络的标准工具，尤其是对于计算资源有限的移动和边缘设备驱动的各种应用。最近，由于其卓越的性能，大型语言模型（LLM）也被纳入NAS，并显示出一些有希望的结果。本文通过同时考虑模型准确性、公平性和硬件部署效率三个重要的设计指标，进一步探索了这个方向。我们在本文中提出了一种基于LLM的NAS框架FL-NAS，并通过实验证明，FL-NAS确实能够找到性能优秀的DNN模型，几乎在所有设计考虑方面都比当前最先进的DNN模型有着数量级的提升。",
    "tldr": "本研究提出了一种名为FL-NAS的基于大型语言模型的神经架构搜索框架，该框架能够在模型准确性、公平性和硬件部署效率三个方面达到卓越的性能。",
    "en_tdlr": "This paper proposes a novel LLM-based NAS framework called FL-NAS, which achieves outstanding performance in terms of model accuracy, fairness, and hardware deployment efficiency."
}