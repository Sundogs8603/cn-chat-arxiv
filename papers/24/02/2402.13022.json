{
    "title": "SoMeLVLM: A Large Vision Language Model for Social Media Processing",
    "abstract": "arXiv:2402.13022v1 Announce Type: new  Abstract: The growth of social media, characterized by its multimodal nature, has led to the emergence of diverse phenomena and challenges, which calls for an effective approach to uniformly solve automated tasks. The powerful Large Vision Language Models make it possible to handle a variety of tasks simultaneously, but even with carefully designed prompting methods, the general domain models often fall short in aligning with the unique speaking style and context of social media tasks. In this paper, we introduce a Large Vision Language Model for Social Media Processing (SoMeLVLM), which is a cognitive framework equipped with five key capabilities including knowledge & comprehension, application, analysis, evaluation, and creation. SoMeLVLM is designed to understand and generate realistic social media behavior. We have developed a 654k multimodal social media instruction-tuning dataset to support our cognitive framework and fine-tune our model. Ou",
    "link": "https://arxiv.org/abs/2402.13022",
    "context": "Title: SoMeLVLM: A Large Vision Language Model for Social Media Processing\nAbstract: arXiv:2402.13022v1 Announce Type: new  Abstract: The growth of social media, characterized by its multimodal nature, has led to the emergence of diverse phenomena and challenges, which calls for an effective approach to uniformly solve automated tasks. The powerful Large Vision Language Models make it possible to handle a variety of tasks simultaneously, but even with carefully designed prompting methods, the general domain models often fall short in aligning with the unique speaking style and context of social media tasks. In this paper, we introduce a Large Vision Language Model for Social Media Processing (SoMeLVLM), which is a cognitive framework equipped with five key capabilities including knowledge & comprehension, application, analysis, evaluation, and creation. SoMeLVLM is designed to understand and generate realistic social media behavior. We have developed a 654k multimodal social media instruction-tuning dataset to support our cognitive framework and fine-tune our model. Ou",
    "path": "papers/24/02/2402.13022.json",
    "total_tokens": 859,
    "translated_title": "SoMeLVLM: 用于社交媒体处理的大型视觉语言模型",
    "translated_abstract": "社交媒体的增长以其多模式特性为特征，引发了各种现象和挑战的出现，这需要有效的方法来统一解决自动化任务。强大的大型视觉语言模型使同时处理各种任务成为可能，但即使通过精心设计的提示方法，通用领域模型在与社交媒体任务的独特言语风格和语境进行对齐方面仍有不足。本文介绍了一种用于社交媒体处理的大型视觉语言模型（SoMeLVLM），它是一个配备有知识和理解、应用、分析、评价和创造五个关键能力的认知框架。SoMeLVLM被设计为理解和生成逼真的社交媒体行为。我们开发了一个654k的多模式社交媒体指导调优数据集，以支持我们的认知框架和对模型进行微调。",
    "tldr": "SoMeLVLM是一种用于社交媒体处理的大型视觉语言模型，具有知识理解、应用、分析、评价和创造等五大关键能力，致力于理解和生成逼真的社交媒体行为。",
    "en_tdlr": "SoMeLVLM is a large vision language model for social media processing, equipped with five key capabilities including knowledge & comprehension, application, analysis, evaluation, and creation, aiming to understand and generate realistic social media behavior."
}