{
    "title": "Analyzing the Evaluation of Cross-Lingual Knowledge Transfer in Multilingual Language Models",
    "abstract": "Recent advances in training multilingual language models on large datasets seem to have shown promising results in knowledge transfer across languages and achieve high performance on downstream tasks. However, we question to what extent the current evaluation benchmarks and setups accurately measure zero-shot cross-lingual knowledge transfer. In this work, we challenge the assumption that high zero-shot performance on target tasks reflects high cross-lingual ability by introducing more challenging setups involving instances with multiple languages. Through extensive experiments and analysis, we show that the observed high performance of multilingual models can be largely attributed to factors not requiring the transfer of actual linguistic knowledge, such as task- and surface-level knowledge. More specifically, we observe what has been transferred across languages is mostly data artifacts and biases, especially for low-resource languages. Our findings highlight the overlooked drawbacks",
    "link": "https://arxiv.org/abs/2402.02099",
    "context": "Title: Analyzing the Evaluation of Cross-Lingual Knowledge Transfer in Multilingual Language Models\nAbstract: Recent advances in training multilingual language models on large datasets seem to have shown promising results in knowledge transfer across languages and achieve high performance on downstream tasks. However, we question to what extent the current evaluation benchmarks and setups accurately measure zero-shot cross-lingual knowledge transfer. In this work, we challenge the assumption that high zero-shot performance on target tasks reflects high cross-lingual ability by introducing more challenging setups involving instances with multiple languages. Through extensive experiments and analysis, we show that the observed high performance of multilingual models can be largely attributed to factors not requiring the transfer of actual linguistic knowledge, such as task- and surface-level knowledge. More specifically, we observe what has been transferred across languages is mostly data artifacts and biases, especially for low-resource languages. Our findings highlight the overlooked drawbacks",
    "path": "papers/24/02/2402.02099.json",
    "total_tokens": 858,
    "translated_title": "分析多语言语言模型中跨语言知识转移的评估",
    "translated_abstract": "最近在大规模数据集上训练的多语言语言模型似乎显示出在跨语言知识转移和下游任务上取得了很高的性能。然而，我们对当前的评估基准和设置能够准确衡量零-shot跨语言知识转移的程度表示质疑。在这项工作中，我们通过引入更具挑战性的设置，涉及多语言实例，挑战了高零-shot性能在目标任务中反映高跨语言能力的假设。通过广泛的实验和分析，我们展示了多语言模型的高性能主要归因于不需要转移实际语言知识的因素，如任务和表层知识。更具体地说，我们观察到跨语言传输的主要是数据工件和偏见，特别是对于低资源语言。我们的发现突显了被忽视的缺点。",
    "tldr": "分析了多语言语言模型中跨语言知识转移的评估方法和设置，发现高性能主要归因于非语言知识的因素，如任务和表层知识，并且跨语言传输的主要是数据工件和偏见，尤其是对于低资源语言。",
    "en_tdlr": "This paper analyzes the evaluation methods and setups for cross-lingual knowledge transfer in multilingual language models, revealing that high performance is mainly attributed to factors other than linguistic knowledge, such as task and surface-level knowledge. The transfer across languages mainly consists of data artifacts and biases, especially for low-resource languages."
}