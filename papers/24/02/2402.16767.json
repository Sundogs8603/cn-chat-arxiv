{
    "title": "CorpusBrain++: A Continual Generative Pre-Training Framework for Knowledge-Intensive Language Tasks",
    "abstract": "arXiv:2402.16767v1 Announce Type: cross  Abstract: Knowledge-intensive language tasks (KILTs) typically require retrieving relevant documents from trustworthy corpora, e.g., Wikipedia, to produce specific answers. Very recently, a pre-trained generative retrieval model for KILTs, named CorpusBrain, was proposed and reached new state-of-the-art retrieval performance. However, most existing research on KILTs, including CorpusBrain, has predominantly focused on a static document collection, overlooking the dynamic nature of real-world scenarios, where new documents are continuously being incorporated into the source corpus. To address this gap, it is crucial to explore the capability of retrieval models to effectively handle the dynamic retrieval scenario inherent in KILTs.   In this work, we first introduce the continual document learning (CDL) task for KILTs and build a novel benchmark dataset named KILT++ based on the original KILT dataset for evaluation. Then, we conduct a comprehensi",
    "link": "https://arxiv.org/abs/2402.16767",
    "context": "Title: CorpusBrain++: A Continual Generative Pre-Training Framework for Knowledge-Intensive Language Tasks\nAbstract: arXiv:2402.16767v1 Announce Type: cross  Abstract: Knowledge-intensive language tasks (KILTs) typically require retrieving relevant documents from trustworthy corpora, e.g., Wikipedia, to produce specific answers. Very recently, a pre-trained generative retrieval model for KILTs, named CorpusBrain, was proposed and reached new state-of-the-art retrieval performance. However, most existing research on KILTs, including CorpusBrain, has predominantly focused on a static document collection, overlooking the dynamic nature of real-world scenarios, where new documents are continuously being incorporated into the source corpus. To address this gap, it is crucial to explore the capability of retrieval models to effectively handle the dynamic retrieval scenario inherent in KILTs.   In this work, we first introduce the continual document learning (CDL) task for KILTs and build a novel benchmark dataset named KILT++ based on the original KILT dataset for evaluation. Then, we conduct a comprehensi",
    "path": "papers/24/02/2402.16767.json",
    "total_tokens": 871,
    "translated_title": "CorpusBrain++: 知识密集型语言任务的继续生成预训练框架",
    "translated_abstract": "知识密集型语言任务通常需要从可信的语料库（如维基百科）中检索相关文档以生成特定答案。最近，提出了用于知识密集型语言任务的预训练生成式检索模型CorpusBrain，并取得了新的检索性能最优结果。然而，大多数现有的关于知识密集型语言任务的研究，包括CorpusBrain，在很大程度上集中在静态文档集上，忽视了现实场景的动态性质，其中新文档持续地被纳入源语料库。为了填补这一空白，探索检索模型有效处理知识密集型语言任务中固有的动态检索场景的能力至关重要。在本文中，我们首先介绍了知识密集型语言任务的持续文档学习（CDL）任务，并基于原始KILT数据集构建了一个名为KILT++的新型评估基准数据集。",
    "tldr": "本研究介绍了知识密集型语言任务中的持续文档学习任务，并建立了一个新的评估数据集，旨在探索检索模型有效处理动态检索场景的能力。"
}