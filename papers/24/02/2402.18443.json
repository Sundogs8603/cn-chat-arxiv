{
    "title": "LeMo-NADe: Multi-Parameter Neural Architecture Discovery with LLMs",
    "abstract": "arXiv:2402.18443v1 Announce Type: cross  Abstract: Building efficient neural network architectures can be a time-consuming task requiring extensive expert knowledge. This task becomes particularly challenging for edge devices because one has to consider parameters such as power consumption during inferencing, model size, inferencing speed, and CO2 emissions. In this article, we introduce a novel framework designed to automatically discover new neural network architectures based on user-defined parameters, an expert system, and an LLM trained on a large amount of open-domain knowledge. The introduced framework (LeMo-NADe) is tailored to be used by non-AI experts, does not require a predetermined neural architecture search space, and considers a large set of edge device-specific parameters. We implement and validate this proposed neural architecture discovery framework using CIFAR-10, CIFAR-100, and ImageNet16-120 datasets while using GPT-4 Turbo and Gemini as the LLM component. We obser",
    "link": "https://arxiv.org/abs/2402.18443",
    "context": "Title: LeMo-NADe: Multi-Parameter Neural Architecture Discovery with LLMs\nAbstract: arXiv:2402.18443v1 Announce Type: cross  Abstract: Building efficient neural network architectures can be a time-consuming task requiring extensive expert knowledge. This task becomes particularly challenging for edge devices because one has to consider parameters such as power consumption during inferencing, model size, inferencing speed, and CO2 emissions. In this article, we introduce a novel framework designed to automatically discover new neural network architectures based on user-defined parameters, an expert system, and an LLM trained on a large amount of open-domain knowledge. The introduced framework (LeMo-NADe) is tailored to be used by non-AI experts, does not require a predetermined neural architecture search space, and considers a large set of edge device-specific parameters. We implement and validate this proposed neural architecture discovery framework using CIFAR-10, CIFAR-100, and ImageNet16-120 datasets while using GPT-4 Turbo and Gemini as the LLM component. We obser",
    "path": "papers/24/02/2402.18443.json",
    "total_tokens": 922,
    "translated_title": "LeMo-NADe: 基于LLMs的多参数神经架构发现",
    "translated_abstract": "建立高效的神经网络架构可能是一项耗时且需要广泛专业知识的任务。对于边缘设备来说，这项任务变得尤为具有挑战性，因为人们必须考虑推理过程中的功耗、模型大小、推理速度和CO2排放量等参数。在本文中，我们介绍了一种新颖的框架，旨在根据用户定义的参数、专家系统和在大量开放领域知识上训练的LLM，自动发现新的神经网络架构。引入的框架（LeMo-NADe）旨在供非人工智能专家使用，不需要预先确定的神经架构搜索空间，并考虑了大量边缘设备特定的参数。我们利用GPT-4 Turbo和Gemini作为LLM组件，在CIFAR-10、CIFAR-100和ImageNet16-120数据集上实施和验证了这一提出的神经架构发现框架。",
    "tldr": "LeMo-NADe是一种基于LLM的框架，旨在根据用户定义的参数、专家系统和大量开放领域知识，自动发现新的神经网络架构，适用于非AI专家，无需预设的搜索空间，并考虑了大量边缘设备特定的参数。",
    "en_tdlr": "LeMo-NADe is a framework based on LLMs designed to automatically discover new neural network architectures based on user-defined parameters, an expert system, and a large amount of open-domain knowledge, tailored for non-AI experts, without requiring a predetermined search space, and considering a large set of edge device-specific parameters."
}