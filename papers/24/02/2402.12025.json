{
    "title": "Speech Translation with Speech Foundation Models and Large Language Models: What is There and What is Missing?",
    "abstract": "arXiv:2402.12025v1 Announce Type: new  Abstract: The field of natural language processing (NLP) has recently witnessed a transformative shift with the emergence of foundation models, particularly Large Language Models (LLMs) that have revolutionized text-based NLP. This paradigm has extended to other modalities, including speech, where researchers are actively exploring the combination of Speech Foundation Models (SFMs) and LLMs into single, unified models capable of addressing multimodal tasks. Among such tasks, this paper focuses on speech-to-text translation (ST). By examining the published papers on the topic, we propose a unified view of the architectural solutions and training strategies presented so far, highlighting similarities and differences among them. Based on this examination, we not only organize the lessons learned but also show how diverse settings and evaluation approaches hinder the identification of the best-performing solution for each architectural building block ",
    "link": "https://arxiv.org/abs/2402.12025",
    "context": "Title: Speech Translation with Speech Foundation Models and Large Language Models: What is There and What is Missing?\nAbstract: arXiv:2402.12025v1 Announce Type: new  Abstract: The field of natural language processing (NLP) has recently witnessed a transformative shift with the emergence of foundation models, particularly Large Language Models (LLMs) that have revolutionized text-based NLP. This paradigm has extended to other modalities, including speech, where researchers are actively exploring the combination of Speech Foundation Models (SFMs) and LLMs into single, unified models capable of addressing multimodal tasks. Among such tasks, this paper focuses on speech-to-text translation (ST). By examining the published papers on the topic, we propose a unified view of the architectural solutions and training strategies presented so far, highlighting similarities and differences among them. Based on this examination, we not only organize the lessons learned but also show how diverse settings and evaluation approaches hinder the identification of the best-performing solution for each architectural building block ",
    "path": "papers/24/02/2402.12025.json",
    "total_tokens": 933,
    "translated_title": "使用语音基础模型和大语言模型的语音翻译：存在和缺失的内容是什么？",
    "translated_abstract": "自然语言处理（NLP）领域最近发生了一场变革性的转变，随着基础模型的出现，特别是彻底改变了基于文本的NLP的大型语言模型（LLMs）。这种范式已经扩展到其他形式，包括语音，在那里研究人员正在积极探索将语音基础模型（SFMs）和LLMs结合成单一的统一模型，以解决多模态任务。在这些任务中，本文着重于语音到文本翻译（ST）。通过审查该主题上发表的论文，我们提出了迄今为止提出的架构解决方案和训练策略的统一观点，强调它们之间的相似之处和差异之处。基于这一研究，我们不仅整理了所学到的经验教训，还展示了多样化的设置和评估方法如何阻碍对每个架构构建块的最佳性能解决方案的识别。",
    "tldr": "这项研究关注语音翻译领域的发展，通过将语音基础模型与大语言模型结合，为解决多模态任务提供了新的统一模型，但目前各种评估方法和设置多样性阻碍了确定每个架构构建块的最佳解决方案的识别。",
    "en_tdlr": "This study focuses on the advancement in speech translation by combining Speech Foundation Models with Large Language Models for addressing multimodal tasks, but the diversity in settings and evaluation methods hinders the identification of the best solution for each architectural building block."
}