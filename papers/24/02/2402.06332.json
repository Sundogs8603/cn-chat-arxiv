{
    "title": "InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning",
    "abstract": "The math abilities of large language models can represent their abstract reasoning ability. In this paper, we introduce and open-source our math reasoning LLMs InternLM-Math which is continue pre-trained from InternLM2. We unify chain-of-thought reasoning, reward modeling, formal reasoning, data augmentation, and code interpreter in a unified seq2seq format and supervise our model to be a versatile math reasoner, verifier, prover, and augmenter. These abilities can be used to develop the next math LLMs or self-iteration. InternLM-Math obtains open-sourced state-of-the-art performance under the setting of in-context learning, supervised fine-tuning, and code-assisted reasoning in various informal and formal benchmarks including GSM8K, MATH, Hungary math exam, MathBench-ZH, and MiniF2F. Our pre-trained model achieves 30.3 on the MiniF2F test set without fine-tuning. We further explore how to use LEAN to solve math problems and study its performance under the setting of multi-task learnin",
    "link": "https://arxiv.org/abs/2402.06332",
    "context": "Title: InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning\nAbstract: The math abilities of large language models can represent their abstract reasoning ability. In this paper, we introduce and open-source our math reasoning LLMs InternLM-Math which is continue pre-trained from InternLM2. We unify chain-of-thought reasoning, reward modeling, formal reasoning, data augmentation, and code interpreter in a unified seq2seq format and supervise our model to be a versatile math reasoner, verifier, prover, and augmenter. These abilities can be used to develop the next math LLMs or self-iteration. InternLM-Math obtains open-sourced state-of-the-art performance under the setting of in-context learning, supervised fine-tuning, and code-assisted reasoning in various informal and formal benchmarks including GSM8K, MATH, Hungary math exam, MathBench-ZH, and MiniF2F. Our pre-trained model achieves 30.3 on the MiniF2F test set without fine-tuning. We further explore how to use LEAN to solve math problems and study its performance under the setting of multi-task learnin",
    "path": "papers/24/02/2402.06332.json",
    "total_tokens": 1177,
    "translated_title": "InternLM-Math：面向可验证推理的开放数学大语言模型",
    "translated_abstract": "大型语言模型的数学能力可以表示其抽象推理能力。本文介绍并开源我们的数学推理LLMs InternLM-Math，该模型是从InternLM2继续预训练而来。我们以统一的seq2seq格式统一了逻辑推理、奖励建模、形式推理、数据增强和代码解释器，并且监督我们的模型成为一个多功能的数学推理器、验证器、证明器和增强器。这些能力可用于开发下一代数学LLMs或自身迭代。在包括GSM8K、MATH、匈牙利数学考试、MathBench-ZH和MiniF2F在内的各种非正式和正式基准测试中，InternLM-Math在上下文学习、监督微调和代码辅助推理的设置下取得了开源的最先进性能。我们的预训练模型在无微调的情况下，在MiniF2F测试集上达到了30.3。我们进一步研究了如何使用LEAN来解决数学问题，并研究了其在多任务学习设置下的性能。",
    "tldr": "在本文中，我们介绍了开源数学推理LLMs InternLM-Math，该模型以其数学能力代表了抽象推理能力。我们的模型以统一的方式整合了逻辑推理、奖励建模、形式推理、数据增强和代码解释器，并使用监督学习使其成为一个多功能的数学推理器、验证器、证明器和增强器。在各种基准测试中，包括GSM8K、MATH、匈牙利数学考试、MathBench-ZH和MiniF2F，在上下文学习、监督微调和代码辅助推理的设置下，InternLM-Math取得了开源的最先进性能。我们的预训练模型在MiniF2F测试集上达到了30.3的得分。我们还研究了如何使用LEAN解决数学问题，并探讨了其在多任务学习设置下的性能。"
}