{
    "title": "Improving Video Corpus Moment Retrieval with Partial Relevance Enhancement",
    "abstract": "arXiv:2402.13576v1 Announce Type: cross  Abstract: Video corpus moment retrieval~(VCMR) is a new video retrieval task aimed at retrieving a relevant moment from a large corpus of untrimmed videos using a natural language text as query. The relevance between the video and query is partial, mainly evident in two aspects: (1) Scope: The untrimmed video contains information-rich frames, and not all are relevant to the query. Strong correlation is typically observed only within the relevant moment, emphasizing the importance of capturing key content. (2) Modality: The relevance of query to different modalities varies; action descriptions align more with the visual elements, while character conversations are more related to textual information. Recognizing and addressing these modality-specific nuances is crucial for effective retrieval in VCMR. However, existing methods often treat all video contents equally, leading to sub-optimal moment retrieval. We argue that effectively capturing the p",
    "link": "https://arxiv.org/abs/2402.13576",
    "context": "Title: Improving Video Corpus Moment Retrieval with Partial Relevance Enhancement\nAbstract: arXiv:2402.13576v1 Announce Type: cross  Abstract: Video corpus moment retrieval~(VCMR) is a new video retrieval task aimed at retrieving a relevant moment from a large corpus of untrimmed videos using a natural language text as query. The relevance between the video and query is partial, mainly evident in two aspects: (1) Scope: The untrimmed video contains information-rich frames, and not all are relevant to the query. Strong correlation is typically observed only within the relevant moment, emphasizing the importance of capturing key content. (2) Modality: The relevance of query to different modalities varies; action descriptions align more with the visual elements, while character conversations are more related to textual information. Recognizing and addressing these modality-specific nuances is crucial for effective retrieval in VCMR. However, existing methods often treat all video contents equally, leading to sub-optimal moment retrieval. We argue that effectively capturing the p",
    "path": "papers/24/02/2402.13576.json",
    "total_tokens": 821,
    "translated_title": "通过部分相关性增强改进视频语料库时刻检索",
    "translated_abstract": "视频语料库时刻检索（VCMR）是一个新的视频检索任务，旨在使用自然语言文本作为查询，从大量未经修剪的视频语料库中检索相关时刻。视频与查询之间的相关性是部分的，主要体现在两个方面：（1）范围：未经修剪的视频包含信息丰富的帧，而并非所有帧都与查询相关。强相关性通常仅在相关时刻内观察到，强调捕捉关键内容的重要性。（2）模态：查询与不同模态的相关性不同；动作描述更倚赖于视觉元素，而角色对话与文本信息更相关。识别和解决这些模态特定的细微差别对于在VCMR中进行有效检索至关重要。然而，现有方法通常将所有视频内容平等对待，导致子优时刻检索。我们认为，有效捕捉p",
    "tldr": "通过部分相关性增强，该研究提出了改进视频语料库时刻检索的方法，以捕捉关键内容和处理不同模态之间的相关性差异。",
    "en_tdlr": "By enhancing partial relevance, this study proposes a method to improve video corpus moment retrieval by capturing key content and addressing the differences in relevance between different modalities."
}