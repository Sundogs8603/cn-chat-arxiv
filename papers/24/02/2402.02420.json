{
    "title": "Factuality of Large Language Models in the Year 2024",
    "abstract": "Large language models (LLMs), especially when instruction-tuned for chat, have become part of our daily lives, freeing people from the process of searching, extracting, and integrating information from multiple sources by offering a straightforward answer to a variety of questions in a single place. Unfortunately, in many cases, LLM responses are factually incorrect, which limits their applicability in real-world scenarios. As a result, research on evaluating and improving the factuality of LLMs has attracted a lot of research attention recently. In this survey, we critically analyze existing work with the aim to identify the major challenges and their associated causes, pointing out to potential solutions for improving the factuality of LLMs, and analyzing the obstacles to automated factuality evaluation for open-ended text generation. We further offer an outlook on where future research should go.",
    "link": "https://arxiv.org/abs/2402.02420",
    "context": "Title: Factuality of Large Language Models in the Year 2024\nAbstract: Large language models (LLMs), especially when instruction-tuned for chat, have become part of our daily lives, freeing people from the process of searching, extracting, and integrating information from multiple sources by offering a straightforward answer to a variety of questions in a single place. Unfortunately, in many cases, LLM responses are factually incorrect, which limits their applicability in real-world scenarios. As a result, research on evaluating and improving the factuality of LLMs has attracted a lot of research attention recently. In this survey, we critically analyze existing work with the aim to identify the major challenges and their associated causes, pointing out to potential solutions for improving the factuality of LLMs, and analyzing the obstacles to automated factuality evaluation for open-ended text generation. We further offer an outlook on where future research should go.",
    "path": "papers/24/02/2402.02420.json",
    "total_tokens": 850,
    "translated_title": "2024年大规模语言模型的真实性",
    "translated_abstract": "大规模语言模型（LLMs），尤其是在聊天方面进行指导调整后，已经成为我们日常生活的一部分，通过在一个地方直接回答各种问题，使人们从搜索、提取和整合多个信息源的过程中得到解脱。然而，很多情况下，LLM的回答是错误的，这限制了它们在现实场景中的适用性。因此，对于评估和提高LLM真实性的研究近年来引起了很多关注。在这项调查中，我们对现有的研究进行了批判性分析，旨在找出主要挑战及其原因，并指出改进LLM真实性的潜在解决方案，以及分析开放文本生成的自动真实性评估面临的障碍。我们还展望了未来研究的方向。",
    "tldr": "本文调查了大规模语言模型（LLM）的真实性问题，并对其现有研究进行了批判性分析，指出了改进LLM真实性的挑战和解决方案，以及自动真实性评估的障碍。未来的研究应该关注在这些方面的进一步工作。",
    "en_tdlr": "This survey critically analyzes the factuality of large language models (LLMs) and identifies the major challenges and potential solutions for improving their factuality. It also examines the obstacles to automated factuality evaluation for open-ended text generation. Future research should focus on addressing these issues."
}