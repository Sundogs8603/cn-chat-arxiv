{
    "title": "Few shot clinical entity recognition in three languages: Masked language models outperform LLM prompting",
    "abstract": "arXiv:2402.12801v1 Announce Type: new  Abstract: Large Language Models are becoming the go-to solution for many natural language processing tasks, including in specialized domains where their few-shot capacities are expected to yield high performance in low-resource settings. Herein, we aim to assess the performance of Large Language Models for few shot clinical entity recognition in multiple languages. We evaluate named entity recognition in English, French and Spanish using 8 in-domain (clinical) and 6 out-domain gold standard corpora. We assess the performance of 10 auto-regressive language models using prompting and 16 masked language models used for text encoding in a biLSTM-CRF supervised tagger. We create a few-shot set-up by limiting the amount of annotated data available to 100 sentences. Our experiments show that although larger prompt-based models tend to achieve competitive F-measure for named entity recognition outside the clinical domain, this level of performance does no",
    "link": "https://arxiv.org/abs/2402.12801",
    "context": "Title: Few shot clinical entity recognition in three languages: Masked language models outperform LLM prompting\nAbstract: arXiv:2402.12801v1 Announce Type: new  Abstract: Large Language Models are becoming the go-to solution for many natural language processing tasks, including in specialized domains where their few-shot capacities are expected to yield high performance in low-resource settings. Herein, we aim to assess the performance of Large Language Models for few shot clinical entity recognition in multiple languages. We evaluate named entity recognition in English, French and Spanish using 8 in-domain (clinical) and 6 out-domain gold standard corpora. We assess the performance of 10 auto-regressive language models using prompting and 16 masked language models used for text encoding in a biLSTM-CRF supervised tagger. We create a few-shot set-up by limiting the amount of annotated data available to 100 sentences. Our experiments show that although larger prompt-based models tend to achieve competitive F-measure for named entity recognition outside the clinical domain, this level of performance does no",
    "path": "papers/24/02/2402.12801.json",
    "total_tokens": 859,
    "translated_title": "三种语言中的少样本临床实体识别：掩盖语言模型胜过LLM提示",
    "translated_abstract": "大型语言模型正成为许多自然语言处理任务的首选解决方案，包括在专业领域中，人们期望它们的少样本能力能在资源匮乏的情况下获得高性能。本文旨在评估大型语言模型在多种语言中进行少样本临床实体识别的性能。我们使用8个领域内（临床）和6个领域外的黄金标准语料库，评估英语、法语和西班牙语中的命名实体识别。我们评估了10个自回归语言模型的性能，这些模型使用提示，并使用16个用于文本编码的掩盖语言模型作为BiLSTM-CRF监督标注器。我们通过限制可用的带标注数据量为100个句子来创建一个少样本设置。我们的实验表明，尽管更大的基于提示的模型往往在临床领域之外的命名实体识别中实现了有竞争力的F-measure，但这种性能水平并未。。。",
    "tldr": "掩盖语言模型在三种语言中的少样本临床实体识别中表现优异，胜过LLM提示方法",
    "en_tdlr": "Masked language models outperform LLM prompting in few-shot clinical entity recognition in three languages"
}