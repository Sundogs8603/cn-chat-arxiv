{
    "title": "SyntaxShap: Syntax-aware Explainability Method for Text Generation",
    "abstract": "arXiv:2402.09259v1 Announce Type: cross Abstract: To harness the power of large language models in safety-critical domains we need to ensure the explainability of their predictions. However, despite the significant attention to model interpretability, there remains an unexplored domain in explaining sequence-to-sequence tasks using methods tailored for textual data. This paper introduces SyntaxShap, a local, model-agnostic explainability method for text generation that takes into consideration the syntax in the text data. The presented work extends Shapley values to account for parsing-based syntactic dependencies. Taking a game theoric approach, SyntaxShap only considers coalitions constraint by the dependency tree. We adopt a model-based evaluation to compare SyntaxShap and its weighted form to state-of-the-art explainability methods adapted to text generation tasks, using diverse metrics including faithfulness, complexity, coherency, and semantic alignment of the explanations to the",
    "link": "https://arxiv.org/abs/2402.09259",
    "context": "Title: SyntaxShap: Syntax-aware Explainability Method for Text Generation\nAbstract: arXiv:2402.09259v1 Announce Type: cross Abstract: To harness the power of large language models in safety-critical domains we need to ensure the explainability of their predictions. However, despite the significant attention to model interpretability, there remains an unexplored domain in explaining sequence-to-sequence tasks using methods tailored for textual data. This paper introduces SyntaxShap, a local, model-agnostic explainability method for text generation that takes into consideration the syntax in the text data. The presented work extends Shapley values to account for parsing-based syntactic dependencies. Taking a game theoric approach, SyntaxShap only considers coalitions constraint by the dependency tree. We adopt a model-based evaluation to compare SyntaxShap and its weighted form to state-of-the-art explainability methods adapted to text generation tasks, using diverse metrics including faithfulness, complexity, coherency, and semantic alignment of the explanations to the",
    "path": "papers/24/02/2402.09259.json",
    "total_tokens": 933,
    "translated_title": "SyntaxShap：用于文本生成的语法感知可解释性方法",
    "translated_abstract": "为了在安全关键领域中利用大型语言模型的潜力，我们需要确保其预测的可解释性。然而，尽管模型可解释性受到了重要关注，但仍有一个尚未探索的领域，即使用针对文本数据量身定制的方法解释序列到序列任务。本文介绍了SyntaxShap，一种局部的、与模型无关的用于文本生成的可解释性方法，它考虑了文本数据中的语法。所提出的方法将Shapley值扩展到考虑基于解析的句法依赖关系。采用博弈论方法，SyntaxShap只考虑由依赖树约束的联盟。我们采用基于模型的评估来比较SyntaxShap及其加权形式与针对文本生成任务的最新可解释性方法，使用包括忠实度、复杂度、连贯性和解释与语义一致性的多样化指标。",
    "tldr": "本文介绍了一种局部的、与模型无关的用于文本生成的可解释性方法SyntaxShap，其通过考虑文本数据中的语法来扩展Shapley值以解释序列到序列任务。通过采用博弈论方法，SyntaxShap只考虑由依赖树约束的联盟，与其他最新的可解释性方法相比具有良好的性能。",
    "en_tdlr": "This paper introduces SyntaxShap, a local and model-agnostic explainability method for text generation, which extends the Shapley values by considering the syntax in the text data. Taking a game-theoretic approach, SyntaxShap only considers coalitions constrained by the dependency tree, providing good performance compared to other state-of-the-art explainability methods."
}