{
    "title": "Future Prediction Can be a Strong Evidence of Good History Representation in Partially Observable Environments",
    "abstract": "Learning a good history representation is one of the core challenges of reinforcement learning (RL) in partially observable environments. Recent works have shown the advantages of various auxiliary tasks for facilitating representation learning. However, the effectiveness of such auxiliary tasks has not been fully convincing, especially in partially observable environments that require long-term memorization and inference. In this empirical study, we investigate the effectiveness of future prediction for learning the representations of histories, possibly of extensive length, in partially observable environments. We first introduce an approach that decouples the task of learning history representations from policy optimization via future prediction. Then, our main contributions are two-fold: (a) we demonstrate that the performance of reinforcement learning is strongly correlated with the prediction accuracy of future observations in partially observable environments, and (b) our approa",
    "link": "https://arxiv.org/abs/2402.07102",
    "context": "Title: Future Prediction Can be a Strong Evidence of Good History Representation in Partially Observable Environments\nAbstract: Learning a good history representation is one of the core challenges of reinforcement learning (RL) in partially observable environments. Recent works have shown the advantages of various auxiliary tasks for facilitating representation learning. However, the effectiveness of such auxiliary tasks has not been fully convincing, especially in partially observable environments that require long-term memorization and inference. In this empirical study, we investigate the effectiveness of future prediction for learning the representations of histories, possibly of extensive length, in partially observable environments. We first introduce an approach that decouples the task of learning history representations from policy optimization via future prediction. Then, our main contributions are two-fold: (a) we demonstrate that the performance of reinforcement learning is strongly correlated with the prediction accuracy of future observations in partially observable environments, and (b) our approa",
    "path": "papers/24/02/2402.07102.json",
    "total_tokens": 797,
    "translated_title": "未来预测可以成为部分可观测环境中良好历史表达的有力证据",
    "translated_abstract": "学习良好的历史表达是部分可观测环境中强化学习的核心挑战之一。最近的研究表明，各种辅助任务对促进表达学习具有优势。然而，这些辅助任务的有效性尚未完全使人信服，特别是在需要长期记忆和推理的部分可观测环境中。在这个实证研究中，我们探讨了未来预测在学习部分可观测环境中历史表达时的有效性。我们首先提出了一种通过未来预测将学习历史表达与策略优化分离的方法。然后，我们的主要贡献有两个方面：（a）我们证明了强化学习的性能与部分可观测环境中未来观测的预测精度强相关，（b）我们的方法可以有效地学习部分可观测环境中长时间历史的表达方式。",
    "tldr": "未来预测在部分可观测环境中学习 History Representation 具有很强的相关性和有效性。",
    "en_tdlr": "Future prediction has strong correlation and effectiveness in learning History Representation in partially observable environments."
}