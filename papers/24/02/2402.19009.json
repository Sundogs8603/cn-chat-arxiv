{
    "title": "Generating, Reconstructing, and Representing Discrete and Continuous Data: Generalized Diffusion with Learnable Encoding-Decoding",
    "abstract": "arXiv:2402.19009v1 Announce Type: cross  Abstract: The vast applications of deep generative models are anchored in three core capabilities -- generating new instances, reconstructing inputs, and learning compact representations -- across various data types, such as discrete text/protein sequences and continuous images. Existing model families, like Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), autoregressive models, and diffusion models, generally excel in specific capabilities and data types but fall short in others. We introduce generalized diffusion with learnable encoder-decoder (DiLED), that seamlessly integrates the core capabilities for broad applicability and enhanced performance. DiLED generalizes the Gaussian noising-denoising in standard diffusion by introducing parameterized encoding-decoding. Crucially, DiLED is compatible with the well-established diffusion model objective and training recipes, allowing effective learning of the encoder-decoder ",
    "link": "https://arxiv.org/abs/2402.19009",
    "context": "Title: Generating, Reconstructing, and Representing Discrete and Continuous Data: Generalized Diffusion with Learnable Encoding-Decoding\nAbstract: arXiv:2402.19009v1 Announce Type: cross  Abstract: The vast applications of deep generative models are anchored in three core capabilities -- generating new instances, reconstructing inputs, and learning compact representations -- across various data types, such as discrete text/protein sequences and continuous images. Existing model families, like Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), autoregressive models, and diffusion models, generally excel in specific capabilities and data types but fall short in others. We introduce generalized diffusion with learnable encoder-decoder (DiLED), that seamlessly integrates the core capabilities for broad applicability and enhanced performance. DiLED generalizes the Gaussian noising-denoising in standard diffusion by introducing parameterized encoding-decoding. Crucially, DiLED is compatible with the well-established diffusion model objective and training recipes, allowing effective learning of the encoder-decoder ",
    "path": "papers/24/02/2402.19009.json",
    "total_tokens": 874,
    "translated_title": "生成、重建和表示离散和连续数据：具有可学习编码-解码器的广义扩散",
    "translated_abstract": "深度生成模型的广泛应用基于三项核心能力--生成新实例、重建输入和学习紧凑表示--跨不同数据类型，如离散文本/蛋白序列和连续图像。现有的模型家族，如变分自动编码器（VAEs）、生成对抗网络（GANs）、自回归模型和扩散模型，通常在特定能力和数据类型上表现优异，但在其他方面表现不佳。我们引入了具有可学习编码器-解码器的广义扩散（DiLED），它无缝地集成了广泛适用性和增强性能的核心能力。DiLED通过引入参数化编码-解码来将标准扩散中的高斯加噪-去噪进行了泛化。关键是，DiLED与成熟的扩散模型目标和训练方法兼容，可有效学习编码-解码器。",
    "tldr": "引入了具有可学习编码器-解码器的广义扩散（DiLED），用于在不同数据类型上无缝整合生成新实例、重建输入和学习紧凑表示，扩展了现有模型家族的性能。",
    "en_tdlr": "Introducing generalized diffusion with learnable encoder-decoder (DiLED) to seamlessly integrate generating new instances, reconstructing inputs, and learning compact representations across different data types, enhancing the performance of existing model families."
}