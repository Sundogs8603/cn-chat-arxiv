{
    "title": "Convergence Acceleration of Markov Chain Monte Carlo-based Gradient Descent by Deep Unfolding",
    "abstract": "arXiv:2402.13608v1 Announce Type: cross  Abstract: This study proposes a trainable sampling-based solver for combinatorial optimization problems (COPs) using a deep-learning technique called deep unfolding. The proposed solver is based on the Ohzeki method that combines Markov-chain Monte-Carlo (MCMC) and gradient descent, and its step sizes are trained by minimizing a loss function. In the training process, we propose a sampling-based gradient estimation that substitutes auto-differentiation with a variance estimation, thereby circumventing the failure of back propagation due to the non-differentiability of MCMC. The numerical results for a few COPs demonstrated that the proposed solver significantly accelerated the convergence speed compared with the original Ohzeki method.",
    "link": "https://arxiv.org/abs/2402.13608",
    "context": "Title: Convergence Acceleration of Markov Chain Monte Carlo-based Gradient Descent by Deep Unfolding\nAbstract: arXiv:2402.13608v1 Announce Type: cross  Abstract: This study proposes a trainable sampling-based solver for combinatorial optimization problems (COPs) using a deep-learning technique called deep unfolding. The proposed solver is based on the Ohzeki method that combines Markov-chain Monte-Carlo (MCMC) and gradient descent, and its step sizes are trained by minimizing a loss function. In the training process, we propose a sampling-based gradient estimation that substitutes auto-differentiation with a variance estimation, thereby circumventing the failure of back propagation due to the non-differentiability of MCMC. The numerical results for a few COPs demonstrated that the proposed solver significantly accelerated the convergence speed compared with the original Ohzeki method.",
    "path": "papers/24/02/2402.13608.json",
    "total_tokens": 822,
    "translated_title": "Markov Chain Monte Carlo梯度下降的收敛加速通过深度展开",
    "translated_abstract": "本研究提出了一种可训练的基于深度展开的采样求解器，用于组合优化问题（COPs），该求解器基于结合了马尔可夫链—蒙特卡洛（MCMC）和梯度下降的Ohzeki方法，并通过最小化损失函数来训练其步长。在训练过程中，我们提出了一种基于采样的梯度估计，用方差估计代替自动微分，从而规避了由于MCMC的不可微分性而导致反向传播失败的问题。少数COPs的数值结果表明，与原始的Ohzeki方法相比，提出的求解器显著加快了收敛速度。",
    "tldr": "提出了一种结合了MCMC和梯度下降的Ohzeki方法的可训练采样求解器，通过最小化损失函数训练步长，采用基于采样的梯度估计替代自动微分，并在数值实验中显示相对于原始方法显著加快了收敛速度",
    "en_tdlr": "A trainable sampling-based solver combining MCMC and gradient descent based on the Ohzeki method was proposed, where step sizes are trained by minimizing a loss function, a sampling-based gradient estimation was introduced to replace auto-differentiation, and numerical results showed significant acceleration in convergence speed compared to the original method."
}