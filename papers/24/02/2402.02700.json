{
    "title": "Sample Complexity Characterization for Linear Contextual MDPs",
    "abstract": "Contextual Markov decision processes (CMDPs) describe a class of reinforcement learning problems in which the transition kernels and reward functions can change over time with different MDPs indexed by a context variable. While CMDPs serve as an important framework to model many real-world applications with time-varying environments, they are largely unexplored from theoretical perspective. In this paper, we study CMDPs under two linear function approximation models: Model I with context-varying representations and common linear weights for all contexts; and Model II with common representations for all contexts and context-varying linear weights. For both models, we propose novel model-based algorithms and show that they enjoy guaranteed $\\epsilon$-suboptimality gap with desired polynomial sample complexity. In particular, instantiating our result for the first model to the tabular CMDP improves the existing result by removing the reachability assumption. Our result for the second mode",
    "link": "https://arxiv.org/abs/2402.02700",
    "context": "Title: Sample Complexity Characterization for Linear Contextual MDPs\nAbstract: Contextual Markov decision processes (CMDPs) describe a class of reinforcement learning problems in which the transition kernels and reward functions can change over time with different MDPs indexed by a context variable. While CMDPs serve as an important framework to model many real-world applications with time-varying environments, they are largely unexplored from theoretical perspective. In this paper, we study CMDPs under two linear function approximation models: Model I with context-varying representations and common linear weights for all contexts; and Model II with common representations for all contexts and context-varying linear weights. For both models, we propose novel model-based algorithms and show that they enjoy guaranteed $\\epsilon$-suboptimality gap with desired polynomial sample complexity. In particular, instantiating our result for the first model to the tabular CMDP improves the existing result by removing the reachability assumption. Our result for the second mode",
    "path": "papers/24/02/2402.02700.json",
    "total_tokens": 908,
    "translated_title": "线性上下文马尔可夫决策过程的样本复杂性表征",
    "translated_abstract": "上下文马尔可夫决策过程（CMDPs）描述了一类强化学习问题，其中转移内核和奖励函数可以随时间变化，并由一个上下文变量索引的不同MDPs。虽然CMDPs作为一个重要的框架，可以模拟具有时变环境的许多实际应用，但它们在理论上很少有研究。在本文中，我们研究了两个线性函数逼近模型下的CMDPs：模型I具有上下文变化表示和所有上下文公共线性权重；以及模型II具有所有上下文的公共表示和上下文变化的线性权重。对于这两个模型，我们提出了新颖的基于模型的算法，并证明它们具有所需多项式样本复杂性的保证的ε-次优间隙。特别是，将我们对第一个模型的结果实例化为表格CMDP，通过去除可达性假设，改进了现有结果。我们对第二个模型的结果。",
    "tldr": "本文研究了线性上下文马尔可夫决策过程（CMDPs）的样本复杂性表征，并提出了两种模型的新颖算法，证明它们具有所需的多项式样本复杂性。其中，对于第一个模型，通过去除可达性假设，改进了现有结果。",
    "en_tdlr": "This paper characterizes the sample complexity of linear contextual Markov decision processes (CMDPs) and proposes novel algorithms for two models, showing guaranteed polynomial sample complexity. Notably, the result for the first model improves upon existing work by removing the reachability assumption."
}