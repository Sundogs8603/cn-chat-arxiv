{
    "title": "Graph-enhanced Large Language Models in Asynchronous Plan Reasoning",
    "abstract": "Reasoning about asynchronous plans is challenging since it requires sequential and parallel planning to optimize time costs. Can large language models (LLMs) succeed at this task? Here, we present the first large-scale study investigating this question. We find that a representative set of closed and open-source LLMs, including GPT-4 and LLaMA-2, behave poorly when not supplied with illustrations about the task-solving process in our benchmark AsyncHow. We propose a novel technique called Plan Like a Graph (PLaG) that combines graphs with natural language prompts and achieves state-of-the-art results. We show that although PLaG can boost model performance, LLMs still suffer from drastic degradation when task complexity increases, highlighting the limits of utilizing LLMs for simulating digital devices. We see our study as an exciting step towards using LLMs as efficient autonomous agents.",
    "link": "https://arxiv.org/abs/2402.02805",
    "context": "Title: Graph-enhanced Large Language Models in Asynchronous Plan Reasoning\nAbstract: Reasoning about asynchronous plans is challenging since it requires sequential and parallel planning to optimize time costs. Can large language models (LLMs) succeed at this task? Here, we present the first large-scale study investigating this question. We find that a representative set of closed and open-source LLMs, including GPT-4 and LLaMA-2, behave poorly when not supplied with illustrations about the task-solving process in our benchmark AsyncHow. We propose a novel technique called Plan Like a Graph (PLaG) that combines graphs with natural language prompts and achieves state-of-the-art results. We show that although PLaG can boost model performance, LLMs still suffer from drastic degradation when task complexity increases, highlighting the limits of utilizing LLMs for simulating digital devices. We see our study as an exciting step towards using LLMs as efficient autonomous agents.",
    "path": "papers/24/02/2402.02805.json",
    "total_tokens": 1045,
    "translated_title": "异步计划推理中的图增强大型语言模型的研究",
    "translated_abstract": "异步计划推理具有挑战性，因为它需要顺序和并行规划以优化时间成本。大型语言模型(LLMs)能在这个任务中成功吗？在这里，我们进行了第一次大规模研究来探讨这个问题。我们发现一组代表性的闭源和开源LLMs，包括GPT-4和LLaMA-2，在我们的基准测试AsyncHow中，在没有提供任务解决过程的插图的情况下表现不佳。我们提出了一种称为Plan Like a Graph (PLaG)的新技术，它将图与自然语言提示相结合，实现了最先进的结果。我们展示了虽然PLaG能提升模型性能，但在任务复杂性增加时，LLMs仍然遭受严重降级，突出了利用LLMs模拟数字设备的局限性。我们将我们的研究视为将LLMs用作高效自主代理的一个令人兴奋的步骤。",
    "tldr": "本研究是关于使用大型语言模型(LLMs)进行异步计划推理的首次大规模研究。我们发现在没有提供任务解决过程插图的情况下，现有的LLMs表现不佳。为此，我们提出了一种称为Plan Like a Graph (PLaG)的新技术，通过将图与自然语言提示相结合，实现了最先进的结果。然而，当任务复杂性增加时，LLMs仍然存在严重降级的问题，突显了LLMs在模拟数字设备方面的局限性。这项研究为将LLMs作为高效自主代理迈出了重要一步。",
    "en_tdlr": "This study presents the first large-scale research on using large language models (LLMs) for asynchronous plan reasoning. Existing LLMs perform poorly without illustrations of the task-solving process, but a novel technique called Plan Like a Graph (PLaG) combining graphs with natural language prompts achieves state-of-the-art results. However, LLMs still suffer from severe degradation as task complexity increases, highlighting their limitations for simulating digital devices. This research is an exciting step towards utilizing LLMs as efficient autonomous agents."
}