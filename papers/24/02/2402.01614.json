{
    "title": "L2G2G: a Scalable Local-to-Global Network Embedding with Graph Autoencoders",
    "abstract": "For analysing real-world networks, graph representation learning is a popular tool. These methods, such as a graph autoencoder (GAE), typically rely on low-dimensional representations, also called embeddings, which are obtained through minimising a loss function; these embeddings are used with a decoder for downstream tasks such as node classification and edge prediction. While GAEs tend to be fairly accurate, they suffer from scalability issues. For improved speed, a Local2Global approach, which combines graph patch embeddings based on eigenvector synchronisation, was shown to be fast and achieve good accuracy. Here we propose L2G2G, a Local2Global method which improves GAE accuracy without sacrificing scalability. This improvement is achieved by dynamically synchronising the latent node representations, while training the GAEs. It also benefits from the decoder computing an only local patch loss. Hence, aligning the local embeddings in each epoch utilises more information from the gr",
    "link": "https://rss.arxiv.org/abs/2402.01614",
    "context": "Title: L2G2G: a Scalable Local-to-Global Network Embedding with Graph Autoencoders\nAbstract: For analysing real-world networks, graph representation learning is a popular tool. These methods, such as a graph autoencoder (GAE), typically rely on low-dimensional representations, also called embeddings, which are obtained through minimising a loss function; these embeddings are used with a decoder for downstream tasks such as node classification and edge prediction. While GAEs tend to be fairly accurate, they suffer from scalability issues. For improved speed, a Local2Global approach, which combines graph patch embeddings based on eigenvector synchronisation, was shown to be fast and achieve good accuracy. Here we propose L2G2G, a Local2Global method which improves GAE accuracy without sacrificing scalability. This improvement is achieved by dynamically synchronising the latent node representations, while training the GAEs. It also benefits from the decoder computing an only local patch loss. Hence, aligning the local embeddings in each epoch utilises more information from the gr",
    "path": "papers/24/02/2402.01614.json",
    "total_tokens": 902,
    "translated_title": "L2G2G: 一种可扩展的局部到全局网络嵌入方法，基于图自动编码器",
    "translated_abstract": "对于分析实际网络，图表示学习是一种常用工具。这些方法，如图自动编码器(GAE)，通常依赖于低维表示，也称为嵌入，通过最小化损失函数获得;这些嵌入与解码器一起用于节点分类和边预测等下游任务。虽然GAE往往相当准确，但存在可扩展性问题。为了改善速度，Local2Global方法通过基于特征向量同步的图块嵌入相结合，显示出快速且准确的效果。在这里，我们提出了L2G2G，一种_Local2Global方法，它在不牺牲可扩展性的情况下提高了GAE的准确性。这种改进是通过在训练GAE期间动态同步潜在节点表示来实现的。它还受益于解码器计算只有本地图块损失。因此，每个时代中的本地嵌入对齐利用了更多来自图的信息。",
    "tldr": "L2G2G是一种可扩展的局部到全局网络嵌入方法，通过动态同步潜在节点表示以提高GAE的准确性，并利用解码器计算只有本地图块损失，从而更好地利用了图的信息。",
    "en_tdlr": "L2G2G is a scalable local-to-global network embedding method that improves the accuracy of GAE by dynamically synchronizing latent node representations and utilizing a decoder to compute only local patch loss, thereby better utilizing the graph information."
}