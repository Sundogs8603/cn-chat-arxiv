{
    "title": "Rethinking Negative Instances for Generative Named Entity Recognition",
    "abstract": "arXiv:2402.16602v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities for generalizing in unseen tasks. In the Named Entity Recognition (NER) task, recent advancements have seen the remarkable improvement of LLMs in a broad range of entity domains via instruction tuning, by adopting entity-centric schema. In this work, we explore the potential enhancement of the existing methods by incorporating negative instances into training. Our experiments reveal that negative instances contribute to remarkable improvements by (1) introducing contextual information, and (2) clearly delineating label boundaries. Furthermore, we introduce a novel and efficient algorithm named Hierarchical Matching, which is tailored to transform unstructured predictions into structured entities. By integrating these components, we present GNER, a Generative NER system that shows improved zero-shot performance across unseen entity domains. Our comprehensive evaluation",
    "link": "https://arxiv.org/abs/2402.16602",
    "context": "Title: Rethinking Negative Instances for Generative Named Entity Recognition\nAbstract: arXiv:2402.16602v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities for generalizing in unseen tasks. In the Named Entity Recognition (NER) task, recent advancements have seen the remarkable improvement of LLMs in a broad range of entity domains via instruction tuning, by adopting entity-centric schema. In this work, we explore the potential enhancement of the existing methods by incorporating negative instances into training. Our experiments reveal that negative instances contribute to remarkable improvements by (1) introducing contextual information, and (2) clearly delineating label boundaries. Furthermore, we introduce a novel and efficient algorithm named Hierarchical Matching, which is tailored to transform unstructured predictions into structured entities. By integrating these components, we present GNER, a Generative NER system that shows improved zero-shot performance across unseen entity domains. Our comprehensive evaluation",
    "path": "papers/24/02/2402.16602.json",
    "total_tokens": 898,
    "translated_title": "重新思考生成式命名实体识别中的负例",
    "translated_abstract": "大型语言模型（LLMs）已经展示出在未知任务中擅长泛化的能力。最近在命名实体识别（NER）任务中，通过采用以实体为中心的模式调整，LLMs的显著改进已经在广泛的实体领域中得到展示。在这项工作中，我们探索通过将负例纳入训练来增强现有方法的潜力。我们的实验揭示了负例通过（1）引入上下文信息和（2）清晰划定标签边界而对改进产生显著影响。此外，我们介绍了一种名为Hierarchical Matching的新颖高效算法，旨在将非结构化预测转化为结构化实体。通过整合这些组件，我们提出了GNER，一个生成式NER系统，展示了跨未知实体领域的提升的零-shot性能。我们进行了全面评估。",
    "tldr": "本研究探索了在生成式命名实体识别中引入负例训练的潜力，结果表明负例的引入通过引入上下文信息和清晰划定标签边界来显著改进系统性能，并提出了一种名为Hierarchical Matching的新颖高效算法，进一步将非结构化预测转化为结构化实体。",
    "en_tdlr": "This study explores the potential of incorporating negative instances into training for generative named entity recognition, showing that the introduction of negative instances significantly improves system performance by introducing contextual information and clearly delineating label boundaries. The study also introduces a novel and efficient algorithm named Hierarchical Matching to further transform unstructured predictions into structured entities."
}