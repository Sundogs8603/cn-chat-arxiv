{
    "title": "Identifying Semantic Induction Heads to Understand In-Context Learning",
    "abstract": "arXiv:2402.13055v1 Announce Type: cross  Abstract: Although large language models (LLMs) have demonstrated remarkable performance, the lack of transparency in their inference logic raises concerns about their trustworthiness. To gain a better understanding of LLMs, we conduct a detailed analysis of the operations of attention heads and aim to better understand the in-context learning of LLMs. Specifically, we investigate whether attention heads encode two types of relationships between tokens present in natural languages: the syntactic dependency parsed from sentences and the relation within knowledge graphs. We find that certain attention heads exhibit a pattern where, when attending to head tokens, they recall tail tokens and increase the output logits of those tail tokens. More crucially, the formulation of such semantic induction heads has a close correlation with the emergence of the in-context learning ability of language models. The study of semantic attention heads advances our",
    "link": "https://arxiv.org/abs/2402.13055",
    "context": "Title: Identifying Semantic Induction Heads to Understand In-Context Learning\nAbstract: arXiv:2402.13055v1 Announce Type: cross  Abstract: Although large language models (LLMs) have demonstrated remarkable performance, the lack of transparency in their inference logic raises concerns about their trustworthiness. To gain a better understanding of LLMs, we conduct a detailed analysis of the operations of attention heads and aim to better understand the in-context learning of LLMs. Specifically, we investigate whether attention heads encode two types of relationships between tokens present in natural languages: the syntactic dependency parsed from sentences and the relation within knowledge graphs. We find that certain attention heads exhibit a pattern where, when attending to head tokens, they recall tail tokens and increase the output logits of those tail tokens. More crucially, the formulation of such semantic induction heads has a close correlation with the emergence of the in-context learning ability of language models. The study of semantic attention heads advances our",
    "path": "papers/24/02/2402.13055.json",
    "total_tokens": 814,
    "translated_title": "识别语义感应头以理解上下文学习",
    "translated_abstract": "虽然大型语言模型(LLMs)已经展示出卓越的性能，但它们推理逻辑的不透明性引发了对其可靠性的担忧。为了更好地理解LLMs，我们对注意力头的操作进行了详细分析，并旨在更好地理解LLMs的上下文学习。具体而言，我们研究了注意力头是否编码了自然语言中存在的两种类型的关系：从句子中解析的句法依赖和知识图中的关系。我们发现某些注意力头表现出一种模式，即当关注头标记时，它们会回忆起尾标记，并增加这些尾标记的输出逻辑。更重要的是，这种语义感应头的制定与语言模型上下文学习能力的出现存在密切关联。语义注意力头的研究推动了我们的",
    "tldr": "该研究通过分析注意力头的操作，揭示了结合了句法依赖和知识图关系的语义感应头的出现，从而更好地理解了大型语言模型的上下文学习能力。",
    "en_tdlr": "This study investigates the emergence of semantic induction heads combining syntactic dependencies and knowledge graph relations to enhance the understanding of in-context learning ability of large language models."
}