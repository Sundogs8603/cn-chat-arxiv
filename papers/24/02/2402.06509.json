{
    "title": "Asking the Right Question at the Right Time: Human and Model Uncertainty Guidance to Ask Clarification Questions",
    "abstract": "Clarification questions are an essential dialogue tool to signal misunderstanding, ambiguities, and under-specification in language use. While humans are able to resolve uncertainty by asking questions since childhood, modern dialogue systems struggle to generate effective questions. To make progress in this direction, in this work we take a collaborative dialogue task as a testbed and study how model uncertainty relates to human uncertainty -- an as yet under-explored problem. We show that model uncertainty does not mirror human clarification-seeking behavior, which suggests that using human clarification questions as supervision for deciding when to ask may not be the most effective way to resolve model uncertainty. To address this issue, we propose an approach to generating clarification questions based on model uncertainty estimation, compare it to several alternatives, and show that it leads to significant improvements in terms of task success. Our findings highlight the importanc",
    "link": "https://arxiv.org/abs/2402.06509",
    "context": "Title: Asking the Right Question at the Right Time: Human and Model Uncertainty Guidance to Ask Clarification Questions\nAbstract: Clarification questions are an essential dialogue tool to signal misunderstanding, ambiguities, and under-specification in language use. While humans are able to resolve uncertainty by asking questions since childhood, modern dialogue systems struggle to generate effective questions. To make progress in this direction, in this work we take a collaborative dialogue task as a testbed and study how model uncertainty relates to human uncertainty -- an as yet under-explored problem. We show that model uncertainty does not mirror human clarification-seeking behavior, which suggests that using human clarification questions as supervision for deciding when to ask may not be the most effective way to resolve model uncertainty. To address this issue, we propose an approach to generating clarification questions based on model uncertainty estimation, compare it to several alternatives, and show that it leads to significant improvements in terms of task success. Our findings highlight the importanc",
    "path": "papers/24/02/2402.06509.json",
    "total_tokens": 870,
    "translated_title": "在合适的时间提出正确的问题：人类和模型的不确定性指导下的澄清问题",
    "translated_abstract": "澄清问题是一种在语言使用中表达误解、歧义和未明示的重要对话工具。虽然人类能够通过提问来解决不确定性，但现代对话系统很难生成有效的问题。为了在这方面取得进展，本文以协作对话任务为测试平台，研究了模型不确定性与人类不确定性之间的关系——这是一个尚未深入研究的问题。我们发现，模型不确定性并不反映人类寻求澄清的行为，这表明使用人类澄清问题来决定何时提问可能不是解决模型不确定性最有效的方法。为了解决这个问题，我们提出了一种基于模型不确定性估计的生成澄清问题的方法，并与几种替代方法进行了比较，结果表明该方法在任务成功率方面取得了显著改进。我们的研究结果强调了这个问题的重要性。",
    "tldr": "本文研究了模型不确定性与人类不确定性之间的关系，并提出了一种基于模型不确定性估计的生成澄清问题的方法，为对话系统在决定何时提问提供了重要指导，并且在任务成功率方面取得了显著改进。"
}