{
    "title": "Wasserstein proximal operators describe score-based generative models and resolve memorization",
    "abstract": "We focus on the fundamental mathematical structure of score-based generative models (SGMs). We first formulate SGMs in terms of the Wasserstein proximal operator (WPO) and demonstrate that, via mean-field games (MFGs), the WPO formulation reveals mathematical structure that describes the inductive bias of diffusion and score-based models. In particular, MFGs yield optimality conditions in the form of a pair of coupled partial differential equations: a forward-controlled Fokker-Planck (FP) equation, and a backward Hamilton-Jacobi-Bellman (HJB) equation. Via a Cole-Hopf transformation and taking advantage of the fact that the cross-entropy can be related to a linear functional of the density, we show that the HJB equation is an uncontrolled FP equation. Second, with the mathematical structure at hand, we present an interpretable kernel-based model for the score function which dramatically improves the performance of SGMs in terms of training samples and training time. In addition, the WP",
    "link": "https://arxiv.org/abs/2402.06162",
    "context": "Title: Wasserstein proximal operators describe score-based generative models and resolve memorization\nAbstract: We focus on the fundamental mathematical structure of score-based generative models (SGMs). We first formulate SGMs in terms of the Wasserstein proximal operator (WPO) and demonstrate that, via mean-field games (MFGs), the WPO formulation reveals mathematical structure that describes the inductive bias of diffusion and score-based models. In particular, MFGs yield optimality conditions in the form of a pair of coupled partial differential equations: a forward-controlled Fokker-Planck (FP) equation, and a backward Hamilton-Jacobi-Bellman (HJB) equation. Via a Cole-Hopf transformation and taking advantage of the fact that the cross-entropy can be related to a linear functional of the density, we show that the HJB equation is an uncontrolled FP equation. Second, with the mathematical structure at hand, we present an interpretable kernel-based model for the score function which dramatically improves the performance of SGMs in terms of training samples and training time. In addition, the WP",
    "path": "papers/24/02/2402.06162.json",
    "total_tokens": 929,
    "translated_title": "Wasserstein近端算子描述基于分数的生成模型并解决记忆问题",
    "translated_abstract": "我们关注基于分数的生成模型（SGMs）的基本数学结构。我们首先用Wasserstein近端算子（WPO）来构建SGMs，并证明通过平均场博弈（MFGs），WPO的结构揭示了描述扩散和基于分数模型的归纳偏差的数学结构。特别是，MFGs以一对耦合的偏微分方程的形式给出了最优性条件：一种前向控制的Fokker-Planck（FP）方程和一种向后的Hamilton-Jacobi-Bellman（HJB）方程。通过Cole-Hopf变换并利用交叉熵可以与密度的线性泛函相关联的事实，我们证明了HJB方程是一种无控制的FP方程。其次，利用手头的数学结构，我们提出了一个可解释的基于核的得分函数模型，该模型极大地提高了SGMs在训练样本和训练时间方面的性能。",
    "tldr": "该论文研究了基于分数的生成模型的数学结构，通过Wasserstein近端算子和平均场博弈可以描述生成模型的归纳偏差，通过解耦合的偏微分方程可以获得优化条件，提出了一个可解释的基于核的得分函数模型，极大地提高了生成模型的性能。",
    "en_tdlr": "This paper investigates the mathematical structure of score-based generative models and reveals that Wasserstein proximal operators and mean-field games can describe the inductive bias of these models. The paper also presents an interpretable kernel-based model for the score function, which significantly enhances the performance of generative models."
}