{
    "title": "Retrieval Augmented End-to-End Spoken Dialog Models",
    "abstract": "We recently developed SLM, a joint speech and language model, which fuses a pretrained foundational speech model and a large language model (LLM), while preserving the in-context learning capability intrinsic to the pretrained LLM. In this paper, we apply SLM to speech dialog applications where the dialog states are inferred directly from the audio signal.   Task-oriented dialogs often contain domain-specific entities, i.e., restaurants, hotels, train stations, and city names, which are difficult to recognize, however, critical for the downstream applications. Inspired by the RAG (retrieval-augmented generation) paradigm, we propose a retrieval augmented SLM (ReSLM) that overcomes this weakness. We first train a speech retriever to retrieve text entities mentioned in the audio. The retrieved entities are then added as text inputs to the underlying SLM to bias model predictions. We evaluated ReSLM on speech MultiWoz task (DSTC-11 challenge), and found that this retrieval augmentation bo",
    "link": "https://arxiv.org/abs/2402.01828",
    "context": "Title: Retrieval Augmented End-to-End Spoken Dialog Models\nAbstract: We recently developed SLM, a joint speech and language model, which fuses a pretrained foundational speech model and a large language model (LLM), while preserving the in-context learning capability intrinsic to the pretrained LLM. In this paper, we apply SLM to speech dialog applications where the dialog states are inferred directly from the audio signal.   Task-oriented dialogs often contain domain-specific entities, i.e., restaurants, hotels, train stations, and city names, which are difficult to recognize, however, critical for the downstream applications. Inspired by the RAG (retrieval-augmented generation) paradigm, we propose a retrieval augmented SLM (ReSLM) that overcomes this weakness. We first train a speech retriever to retrieve text entities mentioned in the audio. The retrieved entities are then added as text inputs to the underlying SLM to bias model predictions. We evaluated ReSLM on speech MultiWoz task (DSTC-11 challenge), and found that this retrieval augmentation bo",
    "path": "papers/24/02/2402.01828.json",
    "total_tokens": 919,
    "translated_title": "检索增强的端到端口语对话模型",
    "translated_abstract": "我们最近开发了SLM，一种融合预训练语音模型和大型语言模型（LLM）的联合语音和语言模型，同时保留了预训练LLM的上下文学习能力。在本文中，我们将SLM应用于语音对话应用，其中对话状态直接从音频信号中推断出来。面向任务的对话经常包含特定领域的实体，例如餐馆、酒店、火车站和城市名称，这些实体很难识别，但对于后续应用非常关键。受到检索增强生成（retrieval-augmented generation）范式的启发，我们提出了一种检索增强的SLM（ReSLM），克服了这个弱点。我们首先训练了一个语音检索器，用于检索音频中提到的文本实体。然后，将检索到的实体作为文本输入添加到底层的SLM中，以偏置模型的预测。我们在语音MultiWoz任务（DSTC-11挑战）上评估了ReSLM，并发现这种检索增强技术改进了模型的性能。",
    "tldr": "这项研究介绍了一种检索增强的端到端口语对话模型（ReSLM），通过训练语音检索器获取音频中的文本实体，并将这些实体作为输入加入到模型中以提高性能。",
    "en_tdlr": "This paper presents a retrieval augmented end-to-end spoken dialog model (ReSLM), which improves performance by training a speech retriever to extract text entities from audio and incorporating them as inputs into the model."
}