{
    "title": "An Empirical Study Into What Matters for Calibrating Vision-Language Models",
    "abstract": "Vision--Language Models (VLMs) have emerged as the dominant approach for zero-shot recognition, adept at handling diverse scenarios and significant distribution changes. However, their deployment in risk-sensitive areas requires a deeper understanding of their uncertainty estimation capabilities, a relatively uncharted area. In this study, we explore the calibration properties of VLMs across different architectures, datasets, and training strategies. In particular, we analyze the uncertainty estimation performance of VLMs when calibrated in one domain, label set or hierarchy level, and tested in a different one. Our findings reveal that while VLMs are not inherently calibrated for uncertainty, temperature scaling significantly and consistently improves calibration, even across shifts in distribution and changes in label set. Moreover, VLMs can be calibrated with a very small set of examples. Through detailed experimentation, we highlight the potential applications and importance of our",
    "link": "https://arxiv.org/abs/2402.07417",
    "context": "Title: An Empirical Study Into What Matters for Calibrating Vision-Language Models\nAbstract: Vision--Language Models (VLMs) have emerged as the dominant approach for zero-shot recognition, adept at handling diverse scenarios and significant distribution changes. However, their deployment in risk-sensitive areas requires a deeper understanding of their uncertainty estimation capabilities, a relatively uncharted area. In this study, we explore the calibration properties of VLMs across different architectures, datasets, and training strategies. In particular, we analyze the uncertainty estimation performance of VLMs when calibrated in one domain, label set or hierarchy level, and tested in a different one. Our findings reveal that while VLMs are not inherently calibrated for uncertainty, temperature scaling significantly and consistently improves calibration, even across shifts in distribution and changes in label set. Moreover, VLMs can be calibrated with a very small set of examples. Through detailed experimentation, we highlight the potential applications and importance of our",
    "path": "papers/24/02/2402.07417.json",
    "total_tokens": 910,
    "translated_title": "一项关于校准视觉-语言模型的实证研究",
    "translated_abstract": "视觉-语言模型（VLMs）已成为零样本识别的主要方法，在处理多样化场景和重要分布变化方面表现出色。然而，将它们应用于风险敏感领域需要对其不确定性估计能力有更深入的了解，这是一个相对未知的领域。在这项研究中，我们探讨了不同架构、数据集和训练策略下VLMs的校准性质。特别是，当在一个领域、标签集或层次级别中进行校准时，我们分析了VLMs在不同领域中的不确定性估计性能。我们的发现表明，虽然VLMs本身并不具备校准不确定性的能力，但温度缩放可以显著且一致地提升校准性能，即使在分布转变和标签集变化的情况下也是如此。此外，VLMs可以通过很少的示例进行校准。通过详细的实验，我们突显了我们的研究的潜在应用和重要性。",
    "tldr": "本研究通过实证研究探索了视觉-语言模型(VLMs)的校准性质，并发现温度缩放可以显著提升校准性能，而且VLMs只需少量示例即可进行校准。",
    "en_tdlr": "This study empirically explores the calibration properties of Vision-Language Models (VLMs) and finds that temperature scaling significantly improves calibration performance. It also shows that VLMs can be calibrated with a small set of examples."
}