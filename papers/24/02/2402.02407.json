{
    "title": "Defining Neural Network Architecture through Polytope Structures of Dataset",
    "abstract": "Current theoretical and empirical research in neural networks suggests that complex datasets require large network architectures for thorough classification, yet the precise nature of this relationship remains unclear. This paper tackles this issue by defining upper and lower bounds for neural network widths, which are informed by the polytope structure of the dataset in question. We also delve into the application of these principles to simplicial complexes and specific manifold shapes, explaining how the requirement for network width varies in accordance with the geometric complexity of the dataset. Moreover, we develop an algorithm to investigate a converse situation where the polytope structure of a dataset can be inferred from its corresponding trained neural networks. Through our algorithm, it is established that popular datasets such as MNIST, Fashion-MNIST, and CIFAR10 can be efficiently encapsulated using no more than two polytopes with a small number of faces.",
    "link": "https://arxiv.org/abs/2402.02407",
    "context": "Title: Defining Neural Network Architecture through Polytope Structures of Dataset\nAbstract: Current theoretical and empirical research in neural networks suggests that complex datasets require large network architectures for thorough classification, yet the precise nature of this relationship remains unclear. This paper tackles this issue by defining upper and lower bounds for neural network widths, which are informed by the polytope structure of the dataset in question. We also delve into the application of these principles to simplicial complexes and specific manifold shapes, explaining how the requirement for network width varies in accordance with the geometric complexity of the dataset. Moreover, we develop an algorithm to investigate a converse situation where the polytope structure of a dataset can be inferred from its corresponding trained neural networks. Through our algorithm, it is established that popular datasets such as MNIST, Fashion-MNIST, and CIFAR10 can be efficiently encapsulated using no more than two polytopes with a small number of faces.",
    "path": "papers/24/02/2402.02407.json",
    "total_tokens": 805,
    "translated_title": "通过数据集的多面体结构定义神经网络架构",
    "translated_abstract": "当前神经网络的理论和实证研究表明，复杂的数据集需要大型网络架构进行彻底分类，然而这种关系的具体性质仍不清楚。本文通过定义神经网络宽度的上下界来解决这个问题，这些界限是由所讨论数据集的多面体结构所确定的。我们还深入探讨了这些原则在单纯复合体和特定多样曲面形状上的应用，解释了网络宽度需求如何根据数据集的几何复杂性而变化。此外，我们开发了一种算法来研究一种相反情况，即可以从相应的训练神经网络推断出数据集的多面体结构。通过我们的算法，我们确定了流行的数据集（如MNIST、Fashion-MNIST和CIFAR10）可以用只有少数面的两个多面体有效地表示。",
    "tldr": "本文通过定义上下界确定神经网络宽度，与数据集的几何复杂性相关。同时开发了一种算法，可以从训练好的神经网络中推断数据集的多面体结构。"
}