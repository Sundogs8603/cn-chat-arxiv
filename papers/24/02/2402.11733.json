{
    "title": "The Effectiveness of Random Forgetting for Robust Generalization",
    "abstract": "arXiv:2402.11733v1 Announce Type: cross  Abstract: Deep neural networks are susceptible to adversarial attacks, which can compromise their performance and accuracy. Adversarial Training (AT) has emerged as a popular approach for protecting neural networks against such attacks. However, a key challenge of AT is robust overfitting, where the network's robust performance on test data deteriorates with further training, thus hindering generalization. Motivated by the concept of active forgetting in the brain, we introduce a novel learning paradigm called \"Forget to Mitigate Overfitting (FOMO)\". FOMO alternates between the forgetting phase, which randomly forgets a subset of weights and regulates the model's information through weight reinitialization, and the relearning phase, which emphasizes learning generalizable features. Our experiments on benchmark datasets and adversarial attacks show that FOMO alleviates robust overfitting by significantly reducing the gap between the best and last",
    "link": "https://arxiv.org/abs/2402.11733",
    "context": "Title: The Effectiveness of Random Forgetting for Robust Generalization\nAbstract: arXiv:2402.11733v1 Announce Type: cross  Abstract: Deep neural networks are susceptible to adversarial attacks, which can compromise their performance and accuracy. Adversarial Training (AT) has emerged as a popular approach for protecting neural networks against such attacks. However, a key challenge of AT is robust overfitting, where the network's robust performance on test data deteriorates with further training, thus hindering generalization. Motivated by the concept of active forgetting in the brain, we introduce a novel learning paradigm called \"Forget to Mitigate Overfitting (FOMO)\". FOMO alternates between the forgetting phase, which randomly forgets a subset of weights and regulates the model's information through weight reinitialization, and the relearning phase, which emphasizes learning generalizable features. Our experiments on benchmark datasets and adversarial attacks show that FOMO alleviates robust overfitting by significantly reducing the gap between the best and last",
    "path": "papers/24/02/2402.11733.json",
    "total_tokens": 902,
    "translated_title": "随机遗忘对稳健泛化的效果",
    "translated_abstract": "深度神经网络容易受到对抗攻击，这可能损害它们的性能和准确性。对抗训练（AT）已经成为保护神经网络免受此类攻击的常见方法。然而，AT的关键挑战之一是稳健过拟合，即网络对测试数据的稳健性能随着进一步训练而恶化，从而妨碍泛化。受大脑中主动遗忘的概念启发，我们引入了一种名为“遗忘来减轻过拟合（FOMO）”的新型学习范式。FOMO在遗忘阶段随机遗忘部分权重并通过权重重新初始化调节模型的信息，然后在重新学习阶段强调学习可泛化的特征。我们在基准数据集和对抗攻击上的实验表明，FOMO通过显著减少最佳结果和最终结果之间的差距，缓解了稳健过拟合。",
    "tldr": "FOMO引入了一种新的学习范式，通过随机遗忘部分权重来调节信息并强调学习可泛化的特征，从而显著减少神经网络在对抗攻击下出现的稳健过拟合问题。",
    "en_tdlr": "FOMO introduces a novel learning paradigm that significantly mitigates robust overfitting in neural networks under adversarial attacks by randomly forgetting a subset of weights to regulate information and emphasize learning generalizable features."
}