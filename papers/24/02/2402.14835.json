{
    "title": "MIKE: A New Benchmark for Fine-grained Multimodal Entity Knowledge Editing",
    "abstract": "arXiv:2402.14835v1 Announce Type: cross  Abstract: Multimodal knowledge editing represents a critical advancement in enhancing the capabilities of Multimodal Large Language Models (MLLMs). Despite its potential, current benchmarks predominantly focus on coarse-grained knowledge, leaving the intricacies of fine-grained (FG) multimodal entity knowledge largely unexplored. This gap presents a notable challenge, as FG entity recognition is pivotal for the practical deployment and effectiveness of MLLMs in diverse real-world scenarios. To bridge this gap, we introduce MIKE, a comprehensive benchmark and dataset specifically designed for the FG multimodal entity knowledge editing. MIKE encompasses a suite of tasks tailored to assess different perspectives, including Vanilla Name Answering, Entity-Level Caption, and Complex-Scenario Recognition. In addition, a new form of knowledge editing, Multi-step Editing, is introduced to evaluate the editing efficiency. Through our extensive evaluations",
    "link": "https://arxiv.org/abs/2402.14835",
    "context": "Title: MIKE: A New Benchmark for Fine-grained Multimodal Entity Knowledge Editing\nAbstract: arXiv:2402.14835v1 Announce Type: cross  Abstract: Multimodal knowledge editing represents a critical advancement in enhancing the capabilities of Multimodal Large Language Models (MLLMs). Despite its potential, current benchmarks predominantly focus on coarse-grained knowledge, leaving the intricacies of fine-grained (FG) multimodal entity knowledge largely unexplored. This gap presents a notable challenge, as FG entity recognition is pivotal for the practical deployment and effectiveness of MLLMs in diverse real-world scenarios. To bridge this gap, we introduce MIKE, a comprehensive benchmark and dataset specifically designed for the FG multimodal entity knowledge editing. MIKE encompasses a suite of tasks tailored to assess different perspectives, including Vanilla Name Answering, Entity-Level Caption, and Complex-Scenario Recognition. In addition, a new form of knowledge editing, Multi-step Editing, is introduced to evaluate the editing efficiency. Through our extensive evaluations",
    "path": "papers/24/02/2402.14835.json",
    "total_tokens": 725,
    "translated_title": "MIKE：细粒度多模态实体知识编辑的新基准",
    "translated_abstract": "多模态知识编辑是增强多模态大语言模型（MLLMs）功能的重要进展。尽管其潜力巨大，但当前的基准主要集中在粗粒度知识上，细粒度多模态实体知识的复杂性大多未被探索。为了弥补这一差距，我们引入了MIKE，这是一个专门为细粒度多模态实体知识编辑设计的全面基准和数据集。",
    "tldr": "MIKE是一个针对细粒度多模态实体知识编辑的全面基准和数据集，突破了现有基准主要侧重于粗粒度知识的局限性，引入了新的知识编辑形式以评估编辑效率。",
    "en_tdlr": "MIKE is a comprehensive benchmark and dataset for fine-grained multimodal entity knowledge editing, addressing the current limitations of benchmarks focusing on coarse-grained knowledge and introducing a new form of knowledge editing to evaluate editing efficiency."
}