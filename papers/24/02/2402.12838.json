{
    "title": "Extending the Scope of Inference About Predictive Ability to Machine Learning Methods",
    "abstract": "arXiv:2402.12838v1 Announce Type: new  Abstract: Though out-of-sample forecast evaluation is systematically employed with modern machine learning methods and there exists a well-established classic inference theory for predictive ability, see, e.g., West (1996, Asymptotic Inference About Predictive Ability, \\textit{Econometrica}, 64, 1067-1084), such theory is not directly applicable to modern machine learners such as the Lasso in the high dimensional setting. We investigate under which conditions such extensions are possible. Two key properties for standard out-of-sample asymptotic inference to be valid with machine learning are (i) a zero-mean condition for the score of the prediction loss function; and (ii) a fast rate of convergence for the machine learner. Monte Carlo simulations confirm our theoretical findings. For accurate finite sample inferences with machine learning, we recommend a small out-of-sample vs in-sample size ratio. We illustrate the wide applicability of our resul",
    "link": "https://arxiv.org/abs/2402.12838",
    "context": "Title: Extending the Scope of Inference About Predictive Ability to Machine Learning Methods\nAbstract: arXiv:2402.12838v1 Announce Type: new  Abstract: Though out-of-sample forecast evaluation is systematically employed with modern machine learning methods and there exists a well-established classic inference theory for predictive ability, see, e.g., West (1996, Asymptotic Inference About Predictive Ability, \\textit{Econometrica}, 64, 1067-1084), such theory is not directly applicable to modern machine learners such as the Lasso in the high dimensional setting. We investigate under which conditions such extensions are possible. Two key properties for standard out-of-sample asymptotic inference to be valid with machine learning are (i) a zero-mean condition for the score of the prediction loss function; and (ii) a fast rate of convergence for the machine learner. Monte Carlo simulations confirm our theoretical findings. For accurate finite sample inferences with machine learning, we recommend a small out-of-sample vs in-sample size ratio. We illustrate the wide applicability of our resul",
    "path": "papers/24/02/2402.12838.json",
    "total_tokens": 843,
    "translated_title": "将关于预测能力的推理范围扩展到机器学习方法",
    "translated_abstract": "虽然现代机器学习方法系统地使用了样本外预测评估，已经建立了一个针对预测能力的经典推理理论，但这种理论不能直接应用于高维背景下的现代机器学习器，我们研究了在哪些条件下这种扩展是可能的。标准的样本外渐近推理要有效地应用于机器学习，需要两个关键属性：（i）预测损失函数得分的零均值条件；（ii）机器学习器的快速收敛速度。蒙特卡洛模拟证实了我们的理论发现。为了在机器学习中进行准确的有限样本推理，我们建议保持较小的样本外与样本内大小比。我们展示了我们结果的广泛适用性。",
    "tldr": "提出在高维背景下探讨现代机器学习方法的预测能力推理扩展的可能性，并建议在机器学习中保持较小的样本外与样本内大小比以实现准确的有限样本推理。",
    "en_tdlr": "Propose to explore the extension of predictive ability inference for modern machine learning methods in high-dimensional settings, and recommend maintaining a small out-of-sample vs in-sample size ratio for accurate finite sample inferences in machine learning."
}