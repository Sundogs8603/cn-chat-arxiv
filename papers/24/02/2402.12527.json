{
    "title": "The Edge-of-Reach Problem in Offline Model-Based Reinforcement Learning",
    "abstract": "arXiv:2402.12527v1 Announce Type: cross  Abstract: Offline reinforcement learning aims to enable agents to be trained from pre-collected datasets, however, this comes with the added challenge of estimating the value of behavior not covered in the dataset. Model-based methods offer a solution by allowing agents to collect additional synthetic data via rollouts in a learned dynamics model. The prevailing theoretical understanding is that this can then be viewed as online reinforcement learning in an approximate dynamics model, and any remaining gap is therefore assumed to be due to the imperfect dynamics model. Surprisingly, however, we find that if the learned dynamics model is replaced by the true error-free dynamics, existing model-based methods completely fail. This reveals a major misconception. Our subsequent investigation finds that the general procedure used in model-based algorithms results in the existence of a set of edge-of-reach states which trigger pathological value overes",
    "link": "https://arxiv.org/abs/2402.12527",
    "context": "Title: The Edge-of-Reach Problem in Offline Model-Based Reinforcement Learning\nAbstract: arXiv:2402.12527v1 Announce Type: cross  Abstract: Offline reinforcement learning aims to enable agents to be trained from pre-collected datasets, however, this comes with the added challenge of estimating the value of behavior not covered in the dataset. Model-based methods offer a solution by allowing agents to collect additional synthetic data via rollouts in a learned dynamics model. The prevailing theoretical understanding is that this can then be viewed as online reinforcement learning in an approximate dynamics model, and any remaining gap is therefore assumed to be due to the imperfect dynamics model. Surprisingly, however, we find that if the learned dynamics model is replaced by the true error-free dynamics, existing model-based methods completely fail. This reveals a major misconception. Our subsequent investigation finds that the general procedure used in model-based algorithms results in the existence of a set of edge-of-reach states which trigger pathological value overes",
    "path": "papers/24/02/2402.12527.json",
    "total_tokens": 766,
    "translated_title": "离线模型驱动强化学习中的边缘问题",
    "translated_abstract": "离线强化学习旨在使智能体能够从预先收集的数据集中进行训练，然而，由此带来了一个额外的挑战，即估计数据集中未涵盖的行为的价值。模型驱动方法通过允许智能体通过在学习动力学模型中进行展开进行收集额外的合成数据来提供解决方案。然而，令人惊讶的是，我们发现，如果学习的动力学模型被真实且无误差的动力学替代，现有的模型驱动方法将完全失败。这揭示了一个重大误解。我们的后续调查发现，模型驱动算法中使用的一般过程导致存在一组触发病态值过高的边缘状态。",
    "tldr": "学习的动力学模型被真实且无误差的动力学替代时，现有模型驱动方法将会完全失败，揭示出一个重大误解。",
    "en_tdlr": "Existing model-based methods completely fail when the learned dynamics model is replaced by the true error-free dynamics, revealing a major misconception."
}