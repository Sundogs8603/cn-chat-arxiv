{
    "title": "Pre-training Cross-lingual Open Domain Question Answering with Large-scale Synthetic Supervision",
    "abstract": "arXiv:2402.16508v1 Announce Type: new  Abstract: Cross-lingual question answering (CLQA) is a complex problem, comprising cross-lingual retrieval from a multilingual knowledge base, followed by answer generation either in English or the query language. Both steps are usually tackled by separate models, requiring substantial annotated datasets, and typically auxiliary resources, like machine translation systems to bridge between languages. In this paper, we show that CLQA can be addressed using a single encoder-decoder model. To effectively train this model, we propose a self-supervised method based on exploiting the cross-lingual link structure within Wikipedia. We demonstrate how linked Wikipedia pages can be used to synthesise supervisory signals for cross-lingual retrieval, through a form of cloze query, and generate more natural queries to supervise answer generation. Together, we show our approach, \\texttt{CLASS}, outperforms comparable methods on both supervised and zero-shot lan",
    "link": "https://arxiv.org/abs/2402.16508",
    "context": "Title: Pre-training Cross-lingual Open Domain Question Answering with Large-scale Synthetic Supervision\nAbstract: arXiv:2402.16508v1 Announce Type: new  Abstract: Cross-lingual question answering (CLQA) is a complex problem, comprising cross-lingual retrieval from a multilingual knowledge base, followed by answer generation either in English or the query language. Both steps are usually tackled by separate models, requiring substantial annotated datasets, and typically auxiliary resources, like machine translation systems to bridge between languages. In this paper, we show that CLQA can be addressed using a single encoder-decoder model. To effectively train this model, we propose a self-supervised method based on exploiting the cross-lingual link structure within Wikipedia. We demonstrate how linked Wikipedia pages can be used to synthesise supervisory signals for cross-lingual retrieval, through a form of cloze query, and generate more natural queries to supervise answer generation. Together, we show our approach, \\texttt{CLASS}, outperforms comparable methods on both supervised and zero-shot lan",
    "path": "papers/24/02/2402.16508.json",
    "total_tokens": 808,
    "translated_title": "使用大规模合成监督进行跨语言开放域问答的预训练",
    "translated_abstract": "跨语言问答（CLQA）是一个复杂的问题，包括从多语言知识库进行跨语言检索，然后在英语或查询语言中生成答案。本文展示了可以使用单个编码-解码模型来解决CLQA。为了有效训练这个模型，我们提出了一种基于利用维基百科内跨语言链接结构的自监督方法。我们展示了如何利用链接的维基百科页面来合成跨语言检索的监督信号，通过一种填空查询形式生成更自然的查询以监督答案生成。最后，我们展示了我们的方法CLASS在监督学习和零-shot情况下均优于可比方法。",
    "tldr": "本研究提出了一种基于自监督方法的单个编码-解码模型来解决跨语言问答问题，通过利用维基百科内的跨语言链接结构合成监督信号，取得了优于其他方法的效果。",
    "en_tdlr": "This paper introduces a single encoder-decoder model based on a self-supervised method to address cross-lingual question answering, achieving better performance by synthesizing supervisory signals from the cross-lingual link structure within Wikipedia."
}