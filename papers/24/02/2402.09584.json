{
    "title": "Large Language Model-Based Interpretable Machine Learning Control in Building Energy Systems",
    "abstract": "arXiv:2402.09584v1 Announce Type: new  Abstract: The potential of Machine Learning Control (MLC) in HVAC systems is hindered by its opaque nature and inference mechanisms, which is challenging for users and modelers to fully comprehend, ultimately leading to a lack of trust in MLC-based decision-making. To address this challenge, this paper investigates and explores Interpretable Machine Learning (IML), a branch of Machine Learning (ML) that enhances transparency and understanding of models and their inferences, to improve the credibility of MLC and its industrial application in HVAC systems. Specifically, we developed an innovative framework that combines the principles of Shapley values and the in-context learning feature of Large Language Models (LLMs). While the Shapley values are instrumental in dissecting the contributions of various features in ML models, LLM provides an in-depth understanding of rule-based parts in MLC; combining them, LLM further packages these insights into a",
    "link": "https://arxiv.org/abs/2402.09584",
    "context": "Title: Large Language Model-Based Interpretable Machine Learning Control in Building Energy Systems\nAbstract: arXiv:2402.09584v1 Announce Type: new  Abstract: The potential of Machine Learning Control (MLC) in HVAC systems is hindered by its opaque nature and inference mechanisms, which is challenging for users and modelers to fully comprehend, ultimately leading to a lack of trust in MLC-based decision-making. To address this challenge, this paper investigates and explores Interpretable Machine Learning (IML), a branch of Machine Learning (ML) that enhances transparency and understanding of models and their inferences, to improve the credibility of MLC and its industrial application in HVAC systems. Specifically, we developed an innovative framework that combines the principles of Shapley values and the in-context learning feature of Large Language Models (LLMs). While the Shapley values are instrumental in dissecting the contributions of various features in ML models, LLM provides an in-depth understanding of rule-based parts in MLC; combining them, LLM further packages these insights into a",
    "path": "papers/24/02/2402.09584.json",
    "total_tokens": 908,
    "translated_title": "基于大型语言模型的建筑能源系统机器学习控制的可解释性研究",
    "translated_abstract": "机器学习控制在暖通空调系统中的潜力受限于其不透明的性质和推理机制，这对于用户和建模者来说是具有挑战性的，难以完全理解，最终导致对基于机器学习控制的决策缺乏信任。为了解决这个挑战，本文研究和探索了可解释机器学习（IML），它是机器学习的一个分支，可以增强模型和推理的透明性和理解性，以提高MLC及其在暖通空调系统中的工业应用的可信度。具体而言，我们开发了一个创新性的框架，将Shapley值的原则和大型语言模型（LLMs）的上下文学习特性相结合。而Shapley值在解剖ML模型中各种特征的贡献方面起到了重要作用，LLM则可以深入理解MLC中基于规则的部分；将它们结合起来，LLM进一步将这些洞见打包到一个",
    "tldr": "本文研究了机器学习控制在建筑能源系统中的可解释性，通过将Shapley值和大型语言模型相结合，提高了机器学习控制模型的透明性和理解性。",
    "en_tdlr": "This paper investigates the interpretability of machine learning control in building energy systems, and enhances transparency and understanding of models by combining Shapley values and large language models."
}