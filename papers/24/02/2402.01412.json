{
    "title": "Bass Accompaniment Generation via Latent Diffusion",
    "abstract": "The ability to automatically generate music that appropriately matches an arbitrary input track is a challenging task. We present a novel controllable system for generating single stems to accompany musical mixes of arbitrary length. At the core of our method are audio autoencoders that efficiently compress audio waveform samples into invertible latent representations, and a conditional latent diffusion model that takes as input the latent encoding of a mix and generates the latent encoding of a corresponding stem. To provide control over the timbre of generated samples, we introduce a technique to ground the latent space to a user-provided reference style during diffusion sampling. For further improving audio quality, we adapt classifier-free guidance to avoid distortions at high guidance strengths when generating an unbounded latent space. We train our model on a dataset of pairs of mixes and matching bass stems. Quantitative experiments demonstrate that, given an input mix, the prop",
    "link": "https://rss.arxiv.org/abs/2402.01412",
    "context": "Title: Bass Accompaniment Generation via Latent Diffusion\nAbstract: The ability to automatically generate music that appropriately matches an arbitrary input track is a challenging task. We present a novel controllable system for generating single stems to accompany musical mixes of arbitrary length. At the core of our method are audio autoencoders that efficiently compress audio waveform samples into invertible latent representations, and a conditional latent diffusion model that takes as input the latent encoding of a mix and generates the latent encoding of a corresponding stem. To provide control over the timbre of generated samples, we introduce a technique to ground the latent space to a user-provided reference style during diffusion sampling. For further improving audio quality, we adapt classifier-free guidance to avoid distortions at high guidance strengths when generating an unbounded latent space. We train our model on a dataset of pairs of mixes and matching bass stems. Quantitative experiments demonstrate that, given an input mix, the prop",
    "path": "papers/24/02/2402.01412.json",
    "total_tokens": 954,
    "translated_title": "通过潜在扩散生成低音伴奏",
    "translated_abstract": "自动生成与任意输入轨道相匹配的音乐是一项具有挑战性的任务。我们提出了一种新颖的可控系统，用于生成与任意长度的音乐混音相配的单音轨。我们方法的核心是音频自动编码器，它可以将音频波形样本高效地压缩成可逆的潜在表示，以及一种条件潜在扩散模型，其以混音的潜在编码作为输入并生成相应音轨的潜在编码。为了对生成的样本的音色进行控制，我们引入了将潜在空间与用户提供的参考风格相连接的技术，用于扩散采样期间。为了进一步提高音频质量，我们调整了无需分类器的引导方法，以避免在生成无界潜在空间时产生失真。我们在一个包含混音与匹配低音音轨对的数据集上训练了我们的模型。定量实验证明，给定输入的混音，我们的模型可以生成与之匹配的低音音轨。",
    "tldr": "本论文提出了一种通过潜在扩散技术生成低音伴奏的方法。通过音频自动编码器将音频样本压缩成潜在表示，并结合条件潜在扩散模型生成对应的音轨。通过引入参考风格和调整引导方法，提供了对生成样本音色的控制和进一步提高音频质量。定量实验证明了该方法的有效性。",
    "en_tdlr": "This paper presents a method for generating bass accompaniment using latent diffusion. By compressing audio samples into latent representations and applying a conditional latent diffusion model, the system can generate corresponding stems. The technique also allows for control over the generated sample's timbre and improved audio quality. Quantitative experiments validate the effectiveness of the approach."
}