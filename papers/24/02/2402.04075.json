{
    "title": "Iterative Prompt Refinement for Radiation Oncology Symptom Extraction Using Teacher-Student Large Language Models",
    "abstract": "This study introduces a novel teacher-student architecture utilizing Large Language Models (LLMs) to improve prostate cancer radiotherapy symptom extraction from clinical notes. Mixtral, the student model, initially extracts symptoms, followed by GPT-4, the teacher model, which refines prompts based on Mixtral's performance. This iterative process involved 294 single symptom clinical notes across 12 symptoms, with up to 16 rounds of refinement per epoch. Results showed significant improvements in extracting symptoms from both single and multi-symptom notes. For 59 single symptom notes, accuracy increased from 0.51 to 0.71, precision from 0.52 to 0.82, recall from 0.52 to 0.72, and F1 score from 0.49 to 0.73. In 375 multi-symptom notes, accuracy rose from 0.24 to 0.43, precision from 0.6 to 0.76, recall from 0.24 to 0.43, and F1 score from 0.20 to 0.44. These results demonstrate the effectiveness of advanced prompt engineering in LLMs for radiation oncology use.",
    "link": "https://arxiv.org/abs/2402.04075",
    "context": "Title: Iterative Prompt Refinement for Radiation Oncology Symptom Extraction Using Teacher-Student Large Language Models\nAbstract: This study introduces a novel teacher-student architecture utilizing Large Language Models (LLMs) to improve prostate cancer radiotherapy symptom extraction from clinical notes. Mixtral, the student model, initially extracts symptoms, followed by GPT-4, the teacher model, which refines prompts based on Mixtral's performance. This iterative process involved 294 single symptom clinical notes across 12 symptoms, with up to 16 rounds of refinement per epoch. Results showed significant improvements in extracting symptoms from both single and multi-symptom notes. For 59 single symptom notes, accuracy increased from 0.51 to 0.71, precision from 0.52 to 0.82, recall from 0.52 to 0.72, and F1 score from 0.49 to 0.73. In 375 multi-symptom notes, accuracy rose from 0.24 to 0.43, precision from 0.6 to 0.76, recall from 0.24 to 0.43, and F1 score from 0.20 to 0.44. These results demonstrate the effectiveness of advanced prompt engineering in LLMs for radiation oncology use.",
    "path": "papers/24/02/2402.04075.json",
    "total_tokens": 1093,
    "translated_title": "使用师生大型语言模型的辐射肿瘤学症状提取的迭代提示细化",
    "translated_abstract": "本研究引入了一种新颖的师生架构，利用大型语言模型（LLMs）改进临床笔记中前列腺癌放射治疗症状的提取。学生模型Mixtral首先提取症状，然后教师模型GPT-4根据Mixtral的表现进行提示细化。该迭代过程涉及12种症状的294个单一症状临床笔记，每轮迭代最多进行16轮的细化。结果显示，无论是从单一症状笔记还是多症状笔记中提取症状都有显著改进。对于59个单一症状笔记，准确度从0.51增加到0.71，精确度从0.52增加到0.82，召回率从0.52增加到0.72，F1分数从0.49增加到0.73。在375个多症状笔记中，准确度从0.24增加到0.43，精确度从0.6增加到0.76，召回率从0.24增加到0.43，F1分数从0.20增加到0.44。这些结果表明，在辐射肿瘤学中，高级提示工程在LLMs中的有效性。",
    "tldr": "本研究使用师生大型语言模型和迭代提示细化的方法改进了从临床笔记中提取前列腺癌放射治疗症状的效果。研究结果表明，该方法在单一症状和多症状笔记中都取得了显著的提取准确度和精确度的提升。",
    "en_tdlr": "This study presents a novel method using teacher-student large language models and iterative prompt refinement to improve the extraction of prostate cancer radiotherapy symptoms from clinical notes. The results demonstrate significant improvements in accuracy and precision for both single and multi-symptom notes."
}