{
    "title": "Why and When LLM-Based Assistants Can Go Wrong: Investigating the Effectiveness of Prompt-Based Interactions for Software Help-Seeking",
    "abstract": "Large Language Model (LLM) assistants, such as ChatGPT, have emerged as potential alternatives to search methods for helping users navigate complex, feature-rich software. LLMs use vast training data from domain-specific texts, software manuals, and code repositories to mimic human-like interactions, offering tailored assistance, including step-by-step instructions. In this work, we investigated LLM-generated software guidance through a within-subject experiment with 16 participants and follow-up interviews. We compared a baseline LLM assistant with an LLM optimized for particular software contexts, SoftAIBot, which also offered guidelines for constructing appropriate prompts. We assessed task completion, perceived accuracy, relevance, and trust. Surprisingly, although SoftAIBot outperformed the baseline LLM, our results revealed no significant difference in LLM usage and user perceptions with or without prompt guidelines and the integration of domain context. Most users struggled to u",
    "link": "https://arxiv.org/abs/2402.08030",
    "context": "Title: Why and When LLM-Based Assistants Can Go Wrong: Investigating the Effectiveness of Prompt-Based Interactions for Software Help-Seeking\nAbstract: Large Language Model (LLM) assistants, such as ChatGPT, have emerged as potential alternatives to search methods for helping users navigate complex, feature-rich software. LLMs use vast training data from domain-specific texts, software manuals, and code repositories to mimic human-like interactions, offering tailored assistance, including step-by-step instructions. In this work, we investigated LLM-generated software guidance through a within-subject experiment with 16 participants and follow-up interviews. We compared a baseline LLM assistant with an LLM optimized for particular software contexts, SoftAIBot, which also offered guidelines for constructing appropriate prompts. We assessed task completion, perceived accuracy, relevance, and trust. Surprisingly, although SoftAIBot outperformed the baseline LLM, our results revealed no significant difference in LLM usage and user perceptions with or without prompt guidelines and the integration of domain context. Most users struggled to u",
    "path": "papers/24/02/2402.08030.json",
    "total_tokens": 968,
    "translated_title": "为什么和何时LLM助手可能出错：探究基于提示的交互对软件寻求帮助的有效性",
    "translated_abstract": "大型语言模型（LLM）助手，如ChatGPT，已成为帮助用户在复杂的、功能丰富的软件中导航的潜在替代方法。LLM使用来自特定领域文本、软件手册和代码库的大量训练数据来模拟人类般的交互，提供量身定制的帮助，包括逐步指导。本研究通过一项16名参与者的被试实验和后续访谈来调查LLM生成的软件指导。我们比较了基线LLM助手和针对特定软件环境进行优化的LLM，即SoftAIBot，后者还提供了构建适当提示的指南。我们评估了任务完成情况、感知准确性、相关性和信任度。令人惊讶的是，尽管SoftAIBot表现优于基准LLM，但我们的结果显示，在提示指南和领域上下文的融合与否对LLM的使用和用户感知没有显著差异。大多数用户在使用LLM时遇到困难。",
    "tldr": "本研究通过实验和访谈调查了大型语言模型(LLM)助手在软件帮助寻求中的有效性。结果显示，虽然优化后的LLM助手相较于基准LLM表现更好，但提示指南和领域上下文的融合与否对于LLM的使用和用户感知没有显著影响。",
    "en_tdlr": "This study investigates the effectiveness of large language model (LLM) assistants for software help-seeking. While an optimized LLM assistant performs better, the integration of prompt guidelines and domain context does not significantly affect LLM usage and user perceptions."
}