{
    "title": "CogBench: a large language model walks into a psychology lab",
    "abstract": "arXiv:2402.18225v1 Announce Type: cross  Abstract: Large language models (LLMs) have significantly advanced the field of artificial intelligence. Yet, evaluating them comprehensively remains challenging. We argue that this is partly due to the predominant focus on performance metrics in most benchmarks. This paper introduces CogBench, a benchmark that includes ten behavioral metrics derived from seven cognitive psychology experiments. This novel approach offers a toolkit for phenotyping LLMs' behavior. We apply CogBench to 35 LLMs, yielding a rich and diverse dataset. We analyze this data using statistical multilevel modeling techniques, accounting for the nested dependencies among fine-tuned versions of specific LLMs. Our study highlights the crucial role of model size and reinforcement learning from human feedback (RLHF) in improving performance and aligning with human behavior. Interestingly, we find that open-source models are less risk-prone than proprietary models and that fine-t",
    "link": "https://arxiv.org/abs/2402.18225",
    "context": "Title: CogBench: a large language model walks into a psychology lab\nAbstract: arXiv:2402.18225v1 Announce Type: cross  Abstract: Large language models (LLMs) have significantly advanced the field of artificial intelligence. Yet, evaluating them comprehensively remains challenging. We argue that this is partly due to the predominant focus on performance metrics in most benchmarks. This paper introduces CogBench, a benchmark that includes ten behavioral metrics derived from seven cognitive psychology experiments. This novel approach offers a toolkit for phenotyping LLMs' behavior. We apply CogBench to 35 LLMs, yielding a rich and diverse dataset. We analyze this data using statistical multilevel modeling techniques, accounting for the nested dependencies among fine-tuned versions of specific LLMs. Our study highlights the crucial role of model size and reinforcement learning from human feedback (RLHF) in improving performance and aligning with human behavior. Interestingly, we find that open-source models are less risk-prone than proprietary models and that fine-t",
    "path": "papers/24/02/2402.18225.json",
    "total_tokens": 935,
    "translated_title": "CogBench: 一个大型语言模型步入心理实验室",
    "translated_abstract": "大型语言模型（LLMs）显著推动了人工智能领域的发展。然而，对它们进行全面评估仍然具有挑战性。我们认为，这部分是由于大多数基准测试中对性能指标的主要关注。本文介绍了CogBench，这是一个基准测试，包括从七个认知心理学实验中衍生的十个行为指标。这种新颖方法为表型化LLMs的行为提供了一个工具包。我们将CogBench应用于35个LLMs，得到丰富多样的数据集。我们使用统计多层建模技术分析这些数据，考虑到特定LLMs的微调版本之间的嵌套依赖关系。我们的研究突出了模型大小和从人类反馈中学习的强化学习在改善性能并与人类行为保持一致方面的关键作用。有趣的是，我们发现开源模型比专有模型更少风险，并且精细调",
    "tldr": "CogBench提出了一个从七个认知心理学实验中衍生出十个行为指标的基准测试，为评估大型语言模型的行为提供了工具，研究发现模型大小和从人类反馈中学习的强化学习对性能改善和与人类行为一致具有重要作用。"
}