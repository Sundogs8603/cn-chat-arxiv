{
    "title": "An FPGA-Based Accelerator Enabling Efficient Support for CNNs with Arbitrary Kernel Sizes",
    "abstract": "arXiv:2402.14307v1 Announce Type: cross  Abstract: Convolutional neural networks (CNNs) with large kernels, drawing inspiration from the key operations of vision transformers (ViTs), have demonstrated impressive performance in various vision-based applications. To address the issue of computational efficiency degradation in existing designs for supporting large-kernel convolutions, an FPGA-based inference accelerator is proposed for the efficient deployment of CNNs with arbitrary kernel sizes. Firstly, a Z-flow method is presented to optimize the computing data flow by maximizing data reuse opportunity. Besides, the proposed design, incorporating the kernel-segmentation (Kseg) scheme, enables extended support for large-kernel convolutions, significantly reducing the storage requirements for overlapped data. Moreover, based on the analysis of typical block structures in emerging CNNs, vertical-fused (VF) and horizontal-fused (HF) methods are developed to optimize CNN deployments from bo",
    "link": "https://arxiv.org/abs/2402.14307",
    "context": "Title: An FPGA-Based Accelerator Enabling Efficient Support for CNNs with Arbitrary Kernel Sizes\nAbstract: arXiv:2402.14307v1 Announce Type: cross  Abstract: Convolutional neural networks (CNNs) with large kernels, drawing inspiration from the key operations of vision transformers (ViTs), have demonstrated impressive performance in various vision-based applications. To address the issue of computational efficiency degradation in existing designs for supporting large-kernel convolutions, an FPGA-based inference accelerator is proposed for the efficient deployment of CNNs with arbitrary kernel sizes. Firstly, a Z-flow method is presented to optimize the computing data flow by maximizing data reuse opportunity. Besides, the proposed design, incorporating the kernel-segmentation (Kseg) scheme, enables extended support for large-kernel convolutions, significantly reducing the storage requirements for overlapped data. Moreover, based on the analysis of typical block structures in emerging CNNs, vertical-fused (VF) and horizontal-fused (HF) methods are developed to optimize CNN deployments from bo",
    "path": "papers/24/02/2402.14307.json",
    "total_tokens": 842,
    "translated_title": "基于FPGA的加速器，支持任意卷积核大小的CNN",
    "translated_abstract": "卷积神经网络（CNN）引用视觉变换器（ViTs）的关键操作，具有大型卷积核，在各种基于视觉的应用中表现出色。为了解决现有设计在支持大型卷积核时计算效率下降的问题，提出了基于FPGA的推理加速器，用于高效部署具有任意内核大小的CNN。首先，提出了一种Z流方法，通过最大化数据重用机会来优化计算数据流。此外，所提出的设计结合卷积核分割（Kseg）方案，为大型卷积核提供了扩展支持，显著降低了重叠数据的存储需求。此外，通过对新兴CNN中典型块结构的分析，开发了垂直融合（VF）和水平融合（HF）方法，以优化CNN的部署。",
    "tldr": "该论文提出了基于FPGA的推理加速器，能够高效支持任意内核大小的CNN，通过Z流方法优化数据流、Kseg方案降低存储需求，以及VF和HF方法优化CNN部署。",
    "en_tdlr": "This paper presents an FPGA-based inference accelerator for efficiently supporting CNNs with arbitrary kernel sizes. It optimizes the data flow using the Z-flow method, reduces storage requirements with the Kseg scheme, and optimizes CNN deployments with VF and HF methods."
}