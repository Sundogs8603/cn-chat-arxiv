{
    "title": "TRAP: Targeted Random Adversarial Prompt Honeypot for Black-Box Identification",
    "abstract": "arXiv:2402.12991v1 Announce Type: cross  Abstract: Large Language Model (LLM) services and models often come with legal rules on who can use them and how they must use them. Assessing the compliance of the released LLMs is crucial, as these rules protect the interests of the LLM contributor and prevent misuse. In this context, we describe the novel problem of Black-box Identity Verification (BBIV). The goal is to determine whether a third-party application uses a certain LLM through its chat function. We propose a method called Targeted Random Adversarial Prompt (TRAP) that identifies the specific LLM in use. We repurpose adversarial suffixes, originally proposed for jailbreaking, to get a pre-defined answer from the target LLM, while other models give random answers. TRAP detects the target LLMs with over 95% true positive rate at under 0.2% false positive rate even after a single interaction. TRAP remains effective even if the LLM has minor changes that do not significantly alter the",
    "link": "https://arxiv.org/abs/2402.12991",
    "context": "Title: TRAP: Targeted Random Adversarial Prompt Honeypot for Black-Box Identification\nAbstract: arXiv:2402.12991v1 Announce Type: cross  Abstract: Large Language Model (LLM) services and models often come with legal rules on who can use them and how they must use them. Assessing the compliance of the released LLMs is crucial, as these rules protect the interests of the LLM contributor and prevent misuse. In this context, we describe the novel problem of Black-box Identity Verification (BBIV). The goal is to determine whether a third-party application uses a certain LLM through its chat function. We propose a method called Targeted Random Adversarial Prompt (TRAP) that identifies the specific LLM in use. We repurpose adversarial suffixes, originally proposed for jailbreaking, to get a pre-defined answer from the target LLM, while other models give random answers. TRAP detects the target LLMs with over 95% true positive rate at under 0.2% false positive rate even after a single interaction. TRAP remains effective even if the LLM has minor changes that do not significantly alter the",
    "path": "papers/24/02/2402.12991.json",
    "total_tokens": 936,
    "translated_title": "TRAP: 面向黑盒身份验证的有针对性随机对抗提示诱饵",
    "translated_abstract": "大型语言模型（LLM）服务和模型通常伴随着关于谁可以使用它们以及他们必须如何使用它们的法律规定。评估发布的LLMs的合规性是至关重要的，因为这些规定保护了LLM贡献者的利益并防止了滥用。在这种背景下，我们描述了黑盒身份验证（BBIV）的新问题。其目标是确定第三方应用是否通过其聊天功能使用某个特定的LLM。我们提出了一种名为目标随机对抗提示（TRAP）的方法，用于识别正在使用的具体LLM。我们重新利用了最初用于越狱的对抗性后缀，以从目标LLM获得预定义的答案，而其他模型则给出随机答案。TRAP可以在单次交互后以超过95%的真阳性率和低于0.2%的误报率检测目标LLMs。即使LLM有不会显著改变的细微变化，TRAP仍然有效。",
    "tldr": "TRAP提出了一种名为Targeted Random Adversarial Prompt (TRAP)的方法，用于识别特定LLM的使用，并在单次交互后以超过95%的真阳性率和低于0.2%的误报率检测目标LLMs。",
    "en_tdlr": "TRAP proposes a method called Targeted Random Adversarial Prompt (TRAP) to identify the specific LLM in use, achieving over 95% true positive rate and under 0.2% false positive rate even after a single interaction."
}