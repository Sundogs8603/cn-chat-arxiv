{
    "title": "A New Approach to Voice Authenticity",
    "abstract": "Voice faking, driven primarily by recent advances in text-to-speech (TTS) synthesis technology, poses significant societal challenges. Currently, the prevailing assumption is that unaltered human speech can be considered genuine, while fake speech comes from TTS synthesis. We argue that this binary distinction is oversimplified. For instance, altered playback speeds can be used for malicious purposes, like in the 'Drunken Nancy Pelosi' incident. Similarly, editing of audio clips can be done ethically, e.g., for brevity or summarization in news reporting or podcasts, but editing can also create misleading narratives. In this paper, we propose a conceptual shift away from the binary paradigm of audio being either 'fake' or 'real'. Instead, our focus is on pinpointing 'voice edits', which encompass traditional modifications like filters and cuts, as well as TTS synthesis and VC systems. We delineate 6 categories and curate a new challenge dataset rooted in the M-AILABS corpus, for which w",
    "link": "https://arxiv.org/abs/2402.06304",
    "context": "Title: A New Approach to Voice Authenticity\nAbstract: Voice faking, driven primarily by recent advances in text-to-speech (TTS) synthesis technology, poses significant societal challenges. Currently, the prevailing assumption is that unaltered human speech can be considered genuine, while fake speech comes from TTS synthesis. We argue that this binary distinction is oversimplified. For instance, altered playback speeds can be used for malicious purposes, like in the 'Drunken Nancy Pelosi' incident. Similarly, editing of audio clips can be done ethically, e.g., for brevity or summarization in news reporting or podcasts, but editing can also create misleading narratives. In this paper, we propose a conceptual shift away from the binary paradigm of audio being either 'fake' or 'real'. Instead, our focus is on pinpointing 'voice edits', which encompass traditional modifications like filters and cuts, as well as TTS synthesis and VC systems. We delineate 6 categories and curate a new challenge dataset rooted in the M-AILABS corpus, for which w",
    "path": "papers/24/02/2402.06304.json",
    "total_tokens": 930,
    "translated_title": "对语音真实性的一种新方法",
    "translated_abstract": "语音伪造主要由于最近文字转语音（TTS）合成技术的进展而带来了显著的社会挑战。目前，主流的假设是未经改动的人类语音被认为是真实的，而伪造的语音来自于TTS合成。我们认为这种二元区分是过于简化的。例如，通过改变播放速度可以用于恶意用途，比如“醉酒的南希·佩洛西”事件。同样地，音频剪辑的编辑可以在新闻报道或播客中进行道德的缩减或概括，但也可以制造误导性的叙述。在本文中，我们提出了一个概念上的转变，摆脱了将音频定义为“假”还是“真”的二元范式。相反，我们的重点是确定“语音编辑”，它包括传统修改，如滤波器和剪切，以及TTS合成和VC系统。我们划分了6个类别，并在M-AILABS语料库的基础上策划了一个新的挑战数据集。",
    "tldr": "这篇论文提出了一种新的思路，挑战传统的将音频定义为“假”或“真”的范式。研究者们将注意力放在了确定“语音编辑”上，这包括传统的修改以及TTS合成和VC系统。他们还提供了一个新的挑战数据集。",
    "en_tdlr": "This paper presents a novel approach that challenges the traditional binary paradigm of classifying audio as either \"fake\" or \"real\". The researchers shift their focus towards identifying \"voice edits\", which include both traditional modifications and TTS synthesis and VC systems. They also provide a new challenge dataset."
}