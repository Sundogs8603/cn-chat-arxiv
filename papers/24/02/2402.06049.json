{
    "title": "Limits of Large Language Models in Debating Humans",
    "abstract": "Large Language Models (LLMs) have shown remarkable promise in their ability to interact proficiently with humans. Subsequently, their potential use as artificial confederates and surrogates in sociological experiments involving conversation is an exciting prospect. But how viable is this idea? This paper endeavors to test the limits of current-day LLMs with a pre-registered study integrating real people with LLM agents acting as people. The study focuses on debate-based opinion consensus formation in three environments: humans only, agents and humans, and agents only. Our goal is to understand how LLM agents influence humans, and how capable they are in debating like humans. We find that LLMs can blend in and facilitate human productivity but are less convincing in debate, with their behavior ultimately deviating from human's. We elucidate these primary failings and anticipate that LLMs must evolve further before being viable debaters.",
    "link": "https://arxiv.org/abs/2402.06049",
    "context": "Title: Limits of Large Language Models in Debating Humans\nAbstract: Large Language Models (LLMs) have shown remarkable promise in their ability to interact proficiently with humans. Subsequently, their potential use as artificial confederates and surrogates in sociological experiments involving conversation is an exciting prospect. But how viable is this idea? This paper endeavors to test the limits of current-day LLMs with a pre-registered study integrating real people with LLM agents acting as people. The study focuses on debate-based opinion consensus formation in three environments: humans only, agents and humans, and agents only. Our goal is to understand how LLM agents influence humans, and how capable they are in debating like humans. We find that LLMs can blend in and facilitate human productivity but are less convincing in debate, with their behavior ultimately deviating from human's. We elucidate these primary failings and anticipate that LLMs must evolve further before being viable debaters.",
    "path": "papers/24/02/2402.06049.json",
    "total_tokens": 905,
    "translated_title": "大型语言模型在与人类辩论中的局限性",
    "translated_abstract": "大型语言模型(LLMs)在与人类的互动中展现出了显著的潜力。随后，将它们作为人工代表和替代品进行社会学实验的潜在应用是一个令人激动的前景。但是这个想法有多可行呢？本文试图通过一项预先注册的研究来测试现阶段LLMs的局限性，该研究将真实的人类与扮演人类的LLM代理结合起来。本研究着重探讨辩论为基础的意见共识形成在三种环境下的情况：仅人类、代理和人类、仅代理。我们的目标是理解LLM代理对人类的影响，并评估它们在辩论方面的能力是否与人类相似。我们发现LLMs能够融入并促进人类的工作效率，但在辩论中的说服力较弱，最终行为与人类有所偏离。我们阐明了这些主要缺陷，并预计在成为可行的辩手之前，LLMs必须进一步发展。",
    "tldr": "大型语言模型在与人类辩论中的能力有限，尽管它们能够融入和促进人类的工作效率，但在辩论中的说服力较弱。在成为可行的辩手之前，LLMs需要进一步发展。",
    "en_tdlr": "Large language models have limitations in debating with humans, as they can blend in and facilitate human productivity but are less convincing in debates. Further development is needed before they can be viable debaters."
}