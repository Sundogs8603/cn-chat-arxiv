{
    "title": "Multi-modal Stance Detection: New Datasets and Model",
    "abstract": "arXiv:2402.14298v1 Announce Type: new  Abstract: Stance detection is a challenging task that aims to identify public opinion from social media platforms with respect to specific targets. Previous work on stance detection largely focused on pure texts. In this paper, we study multi-modal stance detection for tweets consisting of texts and images, which are prevalent in today's fast-growing social media platforms where people often post multi-modal messages. To this end, we create five new multi-modal stance detection datasets of different domains based on Twitter, in which each example consists of a text and an image. In addition, we propose a simple yet effective Targeted Multi-modal Prompt Tuning framework (TMPT), where target information is leveraged to learn multi-modal stance features from textual and visual modalities. Experimental results on our three benchmark datasets show that the proposed TMPT achieves state-of-the-art performance in multi-modal stance detection.",
    "link": "https://arxiv.org/abs/2402.14298",
    "context": "Title: Multi-modal Stance Detection: New Datasets and Model\nAbstract: arXiv:2402.14298v1 Announce Type: new  Abstract: Stance detection is a challenging task that aims to identify public opinion from social media platforms with respect to specific targets. Previous work on stance detection largely focused on pure texts. In this paper, we study multi-modal stance detection for tweets consisting of texts and images, which are prevalent in today's fast-growing social media platforms where people often post multi-modal messages. To this end, we create five new multi-modal stance detection datasets of different domains based on Twitter, in which each example consists of a text and an image. In addition, we propose a simple yet effective Targeted Multi-modal Prompt Tuning framework (TMPT), where target information is leveraged to learn multi-modal stance features from textual and visual modalities. Experimental results on our three benchmark datasets show that the proposed TMPT achieves state-of-the-art performance in multi-modal stance detection.",
    "path": "papers/24/02/2402.14298.json",
    "total_tokens": 825,
    "translated_title": "多模式立场检测：新数据集和模型",
    "translated_abstract": "立场检测是一项具有挑战性的任务，旨在从社交媒体平台中识别针对特定目标的公众意见。以往的立场检测工作主要集中在纯文本上。本文研究了包含文本和图像的推文的多模式立场检测，这在当今快速增长的社交媒体平台上是普遍存在的，人们经常发布多模式消息。为此，我们基于Twitter创建了五个新的不同领域的多模式立场检测数据集，其中每个示例包含文本和图像。此外，我们提出了一个简单而有效的目标多模式提示调整（TMPT）框架，其中利用目标信息从文本和视觉模态中学习多模式立场特征。对我们的三个基准数据集的实验证结果表明，所提出的TMPT在多模式立场检测中实现了最先进的性能。",
    "tldr": "本文研究了多模式立场检测，提出了新的数据集和模型，并展示了所提出的TMPT框架在多模式立场检测中取得了最先进的性能",
    "en_tdlr": "This paper investigates multi-modal stance detection, introduces new datasets and models, and demonstrates that the proposed TMPT framework achieves state-of-the-art performance in multi-modal stance detection."
}