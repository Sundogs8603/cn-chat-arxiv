{
    "title": "Diversified Ensembling: An Experiment in Crowdsourced Machine Learning",
    "abstract": "arXiv:2402.10795v1 Announce Type: new  Abstract: Crowdsourced machine learning on competition platforms such as Kaggle is a popular and often effective method for generating accurate models. Typically, teams vie for the most accurate model, as measured by overall error on a holdout set, and it is common towards the end of such competitions for teams at the top of the leaderboard to ensemble or average their models outside the platform mechanism to get the final, best global model. In arXiv:2201.10408, the authors developed an alternative crowdsourcing framework in the context of fair machine learning, in order to integrate community feedback into models when subgroup unfairness is present and identifiable. There, unlike in classical crowdsourced ML, participants deliberately specialize their efforts by working on subproblems, such as demographic subgroups in the service of fairness. Here, we take a broader perspective on this work: we note that within this framework, participants may b",
    "link": "https://arxiv.org/abs/2402.10795",
    "context": "Title: Diversified Ensembling: An Experiment in Crowdsourced Machine Learning\nAbstract: arXiv:2402.10795v1 Announce Type: new  Abstract: Crowdsourced machine learning on competition platforms such as Kaggle is a popular and often effective method for generating accurate models. Typically, teams vie for the most accurate model, as measured by overall error on a holdout set, and it is common towards the end of such competitions for teams at the top of the leaderboard to ensemble or average their models outside the platform mechanism to get the final, best global model. In arXiv:2201.10408, the authors developed an alternative crowdsourcing framework in the context of fair machine learning, in order to integrate community feedback into models when subgroup unfairness is present and identifiable. There, unlike in classical crowdsourced ML, participants deliberately specialize their efforts by working on subproblems, such as demographic subgroups in the service of fairness. Here, we take a broader perspective on this work: we note that within this framework, participants may b",
    "path": "papers/24/02/2402.10795.json",
    "total_tokens": 938,
    "translated_title": "多样化集成：众包机器学习实验",
    "translated_abstract": "arXiv:2402.10795v1 公告类型：新的 摘要：在诸如Kaggle等竞赛平台上的众包机器学习是一种常见且通常有效的生成准确模型的方法。通常，团队竞争获得最准确的模型，通过在一个保留数据集上的整体误差来衡量，往往在这样的比赛快结束时，排行榜前几名的团队会在平台机制之外集成或平均他们的模型，得到最终、最好的全局模型。在arXiv:2201.10408中，作者们在公平机器学习的背景下开发出了一种替代的众包框架，以便在子组不公平存在且可识别时将社区反馈整合到模型中。在那里，与经典的众包ML不同，参与者们通过专注于子问题，如服务于公平性的人口子群，有意地专门化他们的努力。在这里，我们对这项工作提出了更广泛的观点：我们注意到在这个框架内，参与者可以从事更广泛的问题解决活动，协作以组装子问题的专家选择，并为各种子问题设计特定的损失函数是如何协助让更广泛的问题得以解决并得到解决方案的。",
    "tldr": "该论文提出了一种多样化集成的方法，允许参与者协作解决更广泛的问题，并能处理子组不公平性。"
}