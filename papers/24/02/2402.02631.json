{
    "title": "Learning to Understand: Identifying Interactions via the Mobius Transform",
    "abstract": "One of the most fundamental problems in machine learning is finding interpretable representations of the functions we learn. The Mobius transform is a useful tool for this because its coefficients correspond to unique importance scores on sets of input variables. The Mobius Transform is strongly related (and in some cases equivalent) to the concept of Shapley value, which is a widely used game-theoretic notion of importance. This work focuses on the (typical) regime where the fraction of non-zero Mobius coefficients (and thus interactions between inputs) is small compared to the set of all $2^n$ possible interactions between $n$ inputs. When there are $K = O(2^{n \\delta})$ with $\\delta \\leq \\frac{1}{3}$ non-zero coefficients chosen uniformly at random, our algorithm exactly recovers the Mobius transform in $O(Kn)$ samples and $O(Kn^2)$ time with vanishing error as $K \\rightarrow \\infty$, the first non-adaptive algorithm to do so. We also uncover a surprising connection between group te",
    "link": "https://arxiv.org/abs/2402.02631",
    "context": "Title: Learning to Understand: Identifying Interactions via the Mobius Transform\nAbstract: One of the most fundamental problems in machine learning is finding interpretable representations of the functions we learn. The Mobius transform is a useful tool for this because its coefficients correspond to unique importance scores on sets of input variables. The Mobius Transform is strongly related (and in some cases equivalent) to the concept of Shapley value, which is a widely used game-theoretic notion of importance. This work focuses on the (typical) regime where the fraction of non-zero Mobius coefficients (and thus interactions between inputs) is small compared to the set of all $2^n$ possible interactions between $n$ inputs. When there are $K = O(2^{n \\delta})$ with $\\delta \\leq \\frac{1}{3}$ non-zero coefficients chosen uniformly at random, our algorithm exactly recovers the Mobius transform in $O(Kn)$ samples and $O(Kn^2)$ time with vanishing error as $K \\rightarrow \\infty$, the first non-adaptive algorithm to do so. We also uncover a surprising connection between group te",
    "path": "papers/24/02/2402.02631.json",
    "total_tokens": 943,
    "translated_title": "学习理解：通过Mobius变换识别相互作用",
    "translated_abstract": "机器学习中最基本的问题之一是找到我们学习的函数的可解释表示。Mobius变换是一个有用的工具，因为它的系数对应于输入变量集合上的唯一重要性得分。Mobius变换与Shapley值的概念密切相关（在某些情况下是等价的），后者是一种广泛使用的博弈论重要性概念。本文关注的是在$n$个输入之间的所有$2^n$个可能交互之中，非零Mobius系数（和因此输入之间的相互作用）的比例小于非零系数总数的（典型）情况。当有$K = O(2^{n \\delta})$个，其中$\\delta \\leq \\frac{1}{3}$的非零系数以均匀随机方式选择时，我们的算法可以在$O(Kn)$个样本和$O(Kn^2)$的时间内完全恢复Mobius变换，并且随着$K \\rightarrow \\infty$，误差趋于零。这是第一个非自适应算法实现这一点。我们还发现了群体理论和信息论的令人惊讶的联系。",
    "tldr": "本文研究了通过Mobius变换识别相互作用的问题，提出了一种算法可以在非零系数较少的情况下精确恢复Mobius变换，并揭示了群体理论和信息论之间的联系。"
}