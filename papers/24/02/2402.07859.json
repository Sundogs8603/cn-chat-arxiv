{
    "title": "Lissard: Long and Simple Sequential Reasoning Datasets",
    "abstract": "Language models are now capable of solving tasks that require dealing with long sequences consisting of hundreds of thousands of tokens. However, they often fail on tasks that require repetitive use of simple rules, even on sequences that are much shorter than those seen during training. For example, state-of-the-art LLMs can find common items in two lists with up to 20 items but fail when lists have 80 items. In this paper, we introduce Lissard, a benchmark comprising seven tasks whose goal is to assess the ability of models to process and generate wide-range sequence lengths, requiring repetitive procedural execution. Our evaluation of open-source (Mistral-7B and Mixtral-8x7B) and proprietary models (GPT-3.5 and GPT-4) show a consistent decline in performance across all models as the complexity of the sequence increases. The datasets and code are available at https://github.com/unicamp-dl/Lissard",
    "link": "https://arxiv.org/abs/2402.07859",
    "context": "Title: Lissard: Long and Simple Sequential Reasoning Datasets\nAbstract: Language models are now capable of solving tasks that require dealing with long sequences consisting of hundreds of thousands of tokens. However, they often fail on tasks that require repetitive use of simple rules, even on sequences that are much shorter than those seen during training. For example, state-of-the-art LLMs can find common items in two lists with up to 20 items but fail when lists have 80 items. In this paper, we introduce Lissard, a benchmark comprising seven tasks whose goal is to assess the ability of models to process and generate wide-range sequence lengths, requiring repetitive procedural execution. Our evaluation of open-source (Mistral-7B and Mixtral-8x7B) and proprietary models (GPT-3.5 and GPT-4) show a consistent decline in performance across all models as the complexity of the sequence increases. The datasets and code are available at https://github.com/unicamp-dl/Lissard",
    "path": "papers/24/02/2402.07859.json",
    "total_tokens": 874,
    "translated_title": "Lissard：长而简单的顺序推理数据集",
    "translated_abstract": "语言模型现在能够解决需要处理数十万个标记的长序列的任务。然而，它们在需要重复使用简单规则的任务上常常失败，甚至在比训练中看到的序列要短得多的情况下也是如此。例如，最先进的LLMs可以在两个列表中找到共同项，列表中的项最多可达20个，但是当列表中的项达到80个时，它们会失败。在本文中，我们介绍了Lissard，这是一个包含七个任务的基准，旨在评估模型处理和生成各种序列长度的能力，需要重复的过程执行。我们评估了开源模型（Mistral-7B和Mixtral-8x7B）和专有模型（GPT-3.5和GPT-4），结果显示随着序列复杂性增加，所有模型的性能都呈一致下降趋势。数据集和代码可在https://github.com/unicamp-dl/Lissard获得。",
    "tldr": "Lissard是一个包含七个任务的基准，用于评估模型处理和生成各种序列长度的能力，需要重复的过程执行。评估结果显示随着序列复杂性增加，所有模型的性能都呈一致下降趋势。",
    "en_tdlr": "Lissard is a benchmark consisting of seven tasks to evaluate the ability of models to process and generate various sequence lengths, requiring repetitive procedural execution. The evaluation shows a consistent decline in performance across all models as the complexity of the sequence increases."
}