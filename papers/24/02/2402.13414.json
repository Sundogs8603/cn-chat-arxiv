{
    "title": "Harnessing Large Language Models as Post-hoc Correctors",
    "abstract": "arXiv:2402.13414v1 Announce Type: cross  Abstract: As Machine Learning (ML) models grow in size and demand higher-quality training data, the expenses associated with re-training and fine-tuning these models are escalating rapidly. Inspired by recent impressive achievements of Large Language Models (LLMs) in different fields, this paper delves into the question: can LLMs efficiently improve an ML's performance at a minimal cost? We show that, through our proposed training-free framework LlmCorr, an LLM can work as a post-hoc corrector to propose corrections for the predictions of an arbitrary ML model. In particular, we form a contextual knowledge database by incorporating the dataset's label information and the ML model's predictions on the validation dataset. Leveraging the in-context learning capability of LLMs, we ask the LLM to summarise the instances in which the ML model makes mistakes and the correlation between primary predictions and true labels. Following this, the LLM can tr",
    "link": "https://arxiv.org/abs/2402.13414",
    "context": "Title: Harnessing Large Language Models as Post-hoc Correctors\nAbstract: arXiv:2402.13414v1 Announce Type: cross  Abstract: As Machine Learning (ML) models grow in size and demand higher-quality training data, the expenses associated with re-training and fine-tuning these models are escalating rapidly. Inspired by recent impressive achievements of Large Language Models (LLMs) in different fields, this paper delves into the question: can LLMs efficiently improve an ML's performance at a minimal cost? We show that, through our proposed training-free framework LlmCorr, an LLM can work as a post-hoc corrector to propose corrections for the predictions of an arbitrary ML model. In particular, we form a contextual knowledge database by incorporating the dataset's label information and the ML model's predictions on the validation dataset. Leveraging the in-context learning capability of LLMs, we ask the LLM to summarise the instances in which the ML model makes mistakes and the correlation between primary predictions and true labels. Following this, the LLM can tr",
    "path": "papers/24/02/2402.13414.json",
    "total_tokens": 833,
    "translated_title": "将大型语言模型用作事后校正器",
    "translated_abstract": "随着机器学习（ML）模型的规模增长并需求更高质量的训练数据，与对这些模型进行重新训练和微调相关的费用正在迅速增加。受最近大型语言模型（LLMs）在不同领域取得的令人瞩目成就启发，本文探讨了一个问题：LLMs能否以极低成本有效地改善ML的性能？我们展示了，通过我们提出的无需训练的框架 LlmCorr，一个LLM可以作为事后校正器，为任意ML模型的预测提出修正。特别是，我们通过整合数据集的标签信息和ML模型对验证集的预测来形成一个上下文知识数据库。利用LLMs的上下文学习能力，我们要求LLM总结ML模型犯错误的实例以及主要预测与真实标签之间的相关性。随后，LLM可以",
    "tldr": "通过提出的无需训练的框架 LlmCorr，本文展示了一个LLM可以作为事后校正器，为任意ML模型的预测提出修正。",
    "en_tdlr": "This paper demonstrates that through the proposed training-free framework LlmCorr, a LLM can act as a post-hoc corrector to propose corrections for the predictions of any ML model."
}