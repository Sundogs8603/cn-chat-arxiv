{
    "title": "Fundamental Properties of Causal Entropy and Information Gain",
    "abstract": "Recent developments enable the quantification of causal control given a structural causal model (SCM). This has been accomplished by introducing quantities which encode changes in the entropy of one variable when intervening on another. These measures, named causal entropy and causal information gain, aim to address limitations in existing information theoretical approaches for machine learning tasks where causality plays a crucial role. They have not yet been properly mathematically studied. Our research contributes to the formal understanding of the notions of causal entropy and causal information gain by establishing and analyzing fundamental properties of these concepts, including bounds and chain rules. Furthermore, we elucidate the relationship between causal entropy and stochastic interventions. We also propose definitions for causal conditional entropy and causal conditional information gain. Overall, this exploration paves the way for enhancing causal machine learning tasks th",
    "link": "https://rss.arxiv.org/abs/2402.01341",
    "context": "Title: Fundamental Properties of Causal Entropy and Information Gain\nAbstract: Recent developments enable the quantification of causal control given a structural causal model (SCM). This has been accomplished by introducing quantities which encode changes in the entropy of one variable when intervening on another. These measures, named causal entropy and causal information gain, aim to address limitations in existing information theoretical approaches for machine learning tasks where causality plays a crucial role. They have not yet been properly mathematically studied. Our research contributes to the formal understanding of the notions of causal entropy and causal information gain by establishing and analyzing fundamental properties of these concepts, including bounds and chain rules. Furthermore, we elucidate the relationship between causal entropy and stochastic interventions. We also propose definitions for causal conditional entropy and causal conditional information gain. Overall, this exploration paves the way for enhancing causal machine learning tasks th",
    "path": "papers/24/02/2402.01341.json",
    "total_tokens": 824,
    "translated_title": "因果熵和信息增益的基本性质",
    "translated_abstract": "最近的发展使得能够量化在结构因果模型(SCM)下的因果控制。这是通过引入一些量来编码在干预另一个变量时某个变量熵的变化来实现的。这些量被命名为因果熵和因果信息增益，旨在解决现有信息论方法在因果性在机器学习任务中起关键作用时的局限性。我们的研究通过建立和分析这些概念的基本性质，包括界限和链规则，对因果熵和因果信息增益的概念进行了形式上的理解。此外，我们阐明了因果熵与随机干预的关系，并提出了因果条件熵和因果条件信息增益的定义。总体而言，这个探索为提升因果机器学习任务铺平了道路。",
    "tldr": "本研究通过建立和分析因果熵和因果信息增益的基本性质，包括界限和链规则，阐明了因果熵与随机干预的关系，并提出了因果条件熵和因果条件信息增益的定义，为提升因果机器学习任务铺平了道路。",
    "en_tdlr": "This research establishes and analyzes fundamental properties, including bounds and chain rules, of causal entropy and causal information gain. It elucidates the relationship between causal entropy and stochastic interventions and proposes definitions for causal conditional entropy and causal conditional information gain, paving the way for enhancing causal machine learning tasks."
}