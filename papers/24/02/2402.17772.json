{
    "title": "EEG2Rep: Enhancing Self-supervised EEG Representation Through Informative Masked Inputs",
    "abstract": "arXiv:2402.17772v1 Announce Type: cross  Abstract: Self-supervised approaches for electroencephalography (EEG) representation learning face three specific challenges inherent to EEG data: (1) The low signal-to-noise ratio which challenges the quality of the representation learned, (2) The wide range of amplitudes from very small to relatively large due to factors such as the inter-subject variability, risks the models to be dominated by higher amplitude ranges, and (3) The absence of explicit segmentation in the continuous-valued sequences which can result in less informative representations. To address these challenges, we introduce EEG2Rep, a self-prediction approach for self-supervised representation learning from EEG. Two core novel components of EEG2Rep are as follows: 1) Instead of learning to predict the masked input from raw EEG, EEG2Rep learns to predict masked input in latent representation space, and 2) Instead of conventional masking methods, EEG2Rep uses a new semantic sub",
    "link": "https://arxiv.org/abs/2402.17772",
    "context": "Title: EEG2Rep: Enhancing Self-supervised EEG Representation Through Informative Masked Inputs\nAbstract: arXiv:2402.17772v1 Announce Type: cross  Abstract: Self-supervised approaches for electroencephalography (EEG) representation learning face three specific challenges inherent to EEG data: (1) The low signal-to-noise ratio which challenges the quality of the representation learned, (2) The wide range of amplitudes from very small to relatively large due to factors such as the inter-subject variability, risks the models to be dominated by higher amplitude ranges, and (3) The absence of explicit segmentation in the continuous-valued sequences which can result in less informative representations. To address these challenges, we introduce EEG2Rep, a self-prediction approach for self-supervised representation learning from EEG. Two core novel components of EEG2Rep are as follows: 1) Instead of learning to predict the masked input from raw EEG, EEG2Rep learns to predict masked input in latent representation space, and 2) Instead of conventional masking methods, EEG2Rep uses a new semantic sub",
    "path": "papers/24/02/2402.17772.json",
    "total_tokens": 830,
    "translated_title": "EEG2Rep：通过信息化遮蔽输入增强自监督脑电图表示",
    "translated_abstract": "脑电图（EEG）表示学习的自监督方法面临EEG数据固有的三个特定挑战：（1）低信噪比挑战学到的表示质量，（2）振幅范围广，从非常小到相对较大，由于诸如受试者间变异性等因素，风险导致模型被高振幅范围主导，和（3）连续值序列中缺乏明确分割，可能导致信息较少的表示。为了解决这些挑战，我们引入了EEG2Rep，一种用于从EEG进行自监督表示学习的自预测方法。EEG2Rep的两个核心新颖组成部分如下：1）EEG2Rep不是学习从原始EEG预测遮蔽输入，而是学习在潜在表示空间中预测遮蔽输入，2）EEG2Rep不使用传统的遮蔽方法，而是使用一个新的语义子",
    "tldr": "EEG2Rep通过在潜在表示空间中预测遮蔽输入和使用新的语义子...",
    "en_tdlr": "EEG2Rep learns to predict masked input in latent representation space and uses a new semantic sub..."
}