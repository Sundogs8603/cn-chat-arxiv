{
    "title": "Consistency-Guided Temperature Scaling Using Style and Content Information for Out-of-Domain Calibration",
    "abstract": "arXiv:2402.15019v1 Announce Type: cross  Abstract: Research interests in the robustness of deep neural networks against domain shifts have been rapidly increasing in recent years. Most existing works, however, focus on improving the accuracy of the model, not the calibration performance which is another important requirement for trustworthy AI systems. Temperature scaling (TS), an accuracy-preserving post-hoc calibration method, has been proven to be effective in in-domain settings, but not in out-of-domain (OOD) due to the difficulty in obtaining a validation set for the unseen domain beforehand. In this paper, we propose consistency-guided temperature scaling (CTS), a new temperature scaling strategy that can significantly enhance the OOD calibration performance by providing mutual supervision among data samples in the source domains. Motivated by our observation that over-confidence stemming from inconsistent sample predictions is the main obstacle to OOD calibration, we propose to ",
    "link": "https://arxiv.org/abs/2402.15019",
    "context": "Title: Consistency-Guided Temperature Scaling Using Style and Content Information for Out-of-Domain Calibration\nAbstract: arXiv:2402.15019v1 Announce Type: cross  Abstract: Research interests in the robustness of deep neural networks against domain shifts have been rapidly increasing in recent years. Most existing works, however, focus on improving the accuracy of the model, not the calibration performance which is another important requirement for trustworthy AI systems. Temperature scaling (TS), an accuracy-preserving post-hoc calibration method, has been proven to be effective in in-domain settings, but not in out-of-domain (OOD) due to the difficulty in obtaining a validation set for the unseen domain beforehand. In this paper, we propose consistency-guided temperature scaling (CTS), a new temperature scaling strategy that can significantly enhance the OOD calibration performance by providing mutual supervision among data samples in the source domains. Motivated by our observation that over-confidence stemming from inconsistent sample predictions is the main obstacle to OOD calibration, we propose to ",
    "path": "papers/24/02/2402.15019.json",
    "total_tokens": 885,
    "translated_title": "使用样式和内容信息的一致性引导温度缩放用于域外校准",
    "translated_abstract": "近年来，关于深度神经网络对领域转移的鲁棒性越来越受到关注。然而，大多数现有研究都集中在提高模型的准确性上，而不是校准性能，而后者是值得信赖的AI系统的另一个重要要求。温度缩放（TS）作为一种可以保持准确性的事后校准方法，在领域内环境中已被证明是有效的，但在领域外（OOD）却不是，因为事先很难获取未见领域的验证集。在本文中，我们提出了一种新的温度缩放策略，一致性引导温度缩放（CTS），通过提供源域数据样本之间的相互监督，可以显著提高OOD校准性能。受到我们的观察到的发现，由于不一致的样本预测导致的过度自信是OOD校准的主要障碍，我们提出了一种新的校准策略。",
    "tldr": "提出了一种新的一致性引导温度缩放（CTS）策略，通过提供源域数据样本之间的相互监督，显著增强了域外（OOD）校准性能。",
    "en_tdlr": "Introduced a novel consistency-guided temperature scaling (CTS) strategy that significantly enhances out-of-domain (OOD) calibration performance by providing mutual supervision among data samples in the source domains."
}