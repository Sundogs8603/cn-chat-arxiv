{
    "title": "Evaluating and Improving Continual Learning in Spoken Language Understanding",
    "abstract": "arXiv:2402.10427v1 Announce Type: cross  Abstract: Continual learning has emerged as an increasingly important challenge across various tasks, including Spoken Language Understanding (SLU). In SLU, its objective is to effectively handle the emergence of new concepts and evolving environments. The evaluation of continual learning algorithms typically involves assessing the model's stability, plasticity, and generalizability as fundamental aspects of standards. However, existing continual learning metrics primarily focus on only one or two of the properties. They neglect the overall performance across all tasks, and do not adequately disentangle the plasticity versus stability/generalizability trade-offs within the model. In this work, we propose an evaluation methodology that provides a unified evaluation on stability, plasticity, and generalizability in continual learning. By employing the proposed metric, we demonstrate how introducing various knowledge distillations can improve diffe",
    "link": "https://arxiv.org/abs/2402.10427",
    "context": "Title: Evaluating and Improving Continual Learning in Spoken Language Understanding\nAbstract: arXiv:2402.10427v1 Announce Type: cross  Abstract: Continual learning has emerged as an increasingly important challenge across various tasks, including Spoken Language Understanding (SLU). In SLU, its objective is to effectively handle the emergence of new concepts and evolving environments. The evaluation of continual learning algorithms typically involves assessing the model's stability, plasticity, and generalizability as fundamental aspects of standards. However, existing continual learning metrics primarily focus on only one or two of the properties. They neglect the overall performance across all tasks, and do not adequately disentangle the plasticity versus stability/generalizability trade-offs within the model. In this work, we propose an evaluation methodology that provides a unified evaluation on stability, plasticity, and generalizability in continual learning. By employing the proposed metric, we demonstrate how introducing various knowledge distillations can improve diffe",
    "path": "papers/24/02/2402.10427.json",
    "total_tokens": 847,
    "translated_title": "评估和改进口语理解中的持续学习",
    "translated_abstract": "持续学习已经成为各种任务中越来越重要的挑战，包括口语理解。在口语理解中，其目标是有效处理新概念的出现和不断演变的环境。持续学习算法的评估通常涉及评估模型的稳定性、可塑性和泛化能力作为标准的基本方面。然而，现有的持续学习指标主要集中在其中一个或两个属性上。它们忽视了整体表现在所有任务上，并没有充分解开模型内的可塑性与稳定性/泛化能力之间的权衡。在本研究中，我们提出了一种评估方法，可以在持续学习中统一评估稳定性、可塑性和泛化能力。通过采用所提出的度量标准，我们演示了如何引入各种知识蒸馏来改进...",
    "tldr": "提出了一种评估方法来统一评估口语理解中的持续学习算法在稳定性、可塑性和泛化能力方面的整体表现，并展示了引入不同知识蒸馏如何改善模型性能。",
    "en_tdlr": "Proposed an evaluation methodology that provides a unified evaluation on stability, plasticity, and generalizability in continual learning in spoken language understanding, demonstrating how introducing various knowledge distillations can improve model performance."
}