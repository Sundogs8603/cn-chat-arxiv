{
    "title": "Arabic Synonym BERT-based Adversarial Examples for Text Classification",
    "abstract": "Text classification systems have been proven vulnerable to adversarial text examples, modified versions of the original text examples that are often unnoticed by human eyes, yet can force text classification models to alter their classification. Often, research works quantifying the impact of adversarial text attacks have been applied only to models trained in English. In this paper, we introduce the first word-level study of adversarial attacks in Arabic. Specifically, we use a synonym (word-level) attack using a Masked Language Modeling (MLM) task with a BERT model in a black-box setting to assess the robustness of the state-of-the-art text classification models to adversarial attacks in Arabic. To evaluate the grammatical and semantic similarities of the newly produced adversarial examples using our synonym BERT-based attack, we invite four human evaluators to assess and compare the produced adversarial examples with their original examples. We also study the transferability of thes",
    "link": "https://arxiv.org/abs/2402.03477",
    "context": "Title: Arabic Synonym BERT-based Adversarial Examples for Text Classification\nAbstract: Text classification systems have been proven vulnerable to adversarial text examples, modified versions of the original text examples that are often unnoticed by human eyes, yet can force text classification models to alter their classification. Often, research works quantifying the impact of adversarial text attacks have been applied only to models trained in English. In this paper, we introduce the first word-level study of adversarial attacks in Arabic. Specifically, we use a synonym (word-level) attack using a Masked Language Modeling (MLM) task with a BERT model in a black-box setting to assess the robustness of the state-of-the-art text classification models to adversarial attacks in Arabic. To evaluate the grammatical and semantic similarities of the newly produced adversarial examples using our synonym BERT-based attack, we invite four human evaluators to assess and compare the produced adversarial examples with their original examples. We also study the transferability of thes",
    "path": "papers/24/02/2402.03477.json",
    "total_tokens": 932,
    "translated_title": "基于阿拉伯文同义词BERT的文本分类对抗样本",
    "translated_abstract": "文本分类系统已被证明对于对抗性文本示例具有脆弱性，这些修改后的文本示例在人眼中往往不易察觉，但可以迫使文本分类模型改变其分类结果。目前，对于量化对抗性文本攻击影响的研究工作大多只应用于英文模型。本文首次介绍了阿拉伯文中对抗性攻击的词级研究。具体来说，我们使用基于BERT模型的蒙版语言建模（MLM）任务的同义词（词级）攻击方法，在黑盒设置中评估最先进的阿拉伯文本分类模型对对抗性攻击的鲁棒性。为了评估使用我们的同义词BERT攻击生成的对抗样本的语法和语义相似性，我们请四名人类评估员评估和比较生成的对抗样本与原样本之间的差异。我们还研究了这些对抗样本的可传递性。",
    "tldr": "本文首次在阿拉伯文中对文本分类模型进行了对抗攻击的词级研究，使用了基于同义词的BERT模型进行蒙版语言建模任务。通过评估生成的对抗样本与原样本的语法和语义相似性，研究了这些对抗样本的可传递性。"
}