{
    "title": "Navigator: A Decentralized Scheduler for Latency-Sensitive ML Workflows",
    "abstract": "arXiv:2402.17652v1 Announce Type: cross  Abstract: We consider ML query processing in distributed systems where GPU-enabled workers coordinate to execute complex queries: a computing style often seen in applications that interact with users in support of image processing and natural language processing. In such systems, coscheduling of GPU memory management and task placement represents a promising opportunity. We propose Navigator, a novel framework that unifies these functions to reduce job latency while using resources efficiently, placing tasks where data dependencies will be satisfied, collocating tasks from the same job (when this will not overload the host or its GPU), and efficiently managing GPU memory. Comparison with other state of the art schedulers shows a significant reduction in completion times while requiring the same amount or even fewer resources. In one case, just half the servers were needed for processing the same workload.",
    "link": "https://arxiv.org/abs/2402.17652",
    "context": "Title: Navigator: A Decentralized Scheduler for Latency-Sensitive ML Workflows\nAbstract: arXiv:2402.17652v1 Announce Type: cross  Abstract: We consider ML query processing in distributed systems where GPU-enabled workers coordinate to execute complex queries: a computing style often seen in applications that interact with users in support of image processing and natural language processing. In such systems, coscheduling of GPU memory management and task placement represents a promising opportunity. We propose Navigator, a novel framework that unifies these functions to reduce job latency while using resources efficiently, placing tasks where data dependencies will be satisfied, collocating tasks from the same job (when this will not overload the host or its GPU), and efficiently managing GPU memory. Comparison with other state of the art schedulers shows a significant reduction in completion times while requiring the same amount or even fewer resources. In one case, just half the servers were needed for processing the same workload.",
    "path": "papers/24/02/2402.17652.json",
    "total_tokens": 824,
    "translated_title": "导航器：面向延迟敏感ML工作流的分散式调度器",
    "translated_abstract": "我们考虑在分布式系统中进行ML查询处理，其中启用GPU的工作人员协调执行复杂查询：这种计算风格经常出现在与用户互动支持图像处理和自然语言处理的应用程序中。在这种系统中，GPU内存管理和任务放置的协同调度代表着一个有前途的机会。我们提出了Navigator，一个新颖的框架，统一了这些功能，以减少作业延迟，同时高效利用资源，将任务放置在数据依赖关系将得到满足的地方，将来自同一作业的任务放在一起（当这不会使主机或其GPU超载时），并高效地管理GPU内存。与其他最先进的调度器比较显示，在需要相同量甚至更少资源的情况下，完成时间显著减少。在一个案例中，仅需要一半的服务器来处理相同的工作负载。",
    "tldr": "提出了一种名为Navigator的新型框架，通过统一GPU内存管理和任务放置功能，以减少作业延迟，同时高效利用资源，比其他最先进的调度器表现出更显著的完成时间缩短。",
    "en_tdlr": "Introduced a novel framework called Navigator that reduces job latency, efficiently utilizes resources, and shows significant reduction in completion times compared to other state of the art schedulers."
}