{
    "title": "Inherent Diverse Redundant Safety Mechanisms for AI-based Software Elements in Automotive Applications",
    "abstract": "This paper explores the role and challenges of Artificial Intelligence (AI) algorithms, specifically AI-based software elements, in autonomous driving systems. These AI systems are fundamental in executing real-time critical functions in complex and high-dimensional environments. They handle vital tasks like multi-modal perception, cognition, and decision-making tasks such as motion planning, lane keeping, and emergency braking. A primary concern relates to the ability (and necessity) of AI models to generalize beyond their initial training data. This generalization issue becomes evident in real-time scenarios, where models frequently encounter inputs not represented in their training or validation data. In such cases, AI systems must still function effectively despite facing distributional or domain shifts. This paper investigates the risk associated with overconfident AI models in safety-critical applications like autonomous driving. To mitigate these risks, methods for training AI m",
    "link": "https://arxiv.org/abs/2402.08208",
    "context": "Title: Inherent Diverse Redundant Safety Mechanisms for AI-based Software Elements in Automotive Applications\nAbstract: This paper explores the role and challenges of Artificial Intelligence (AI) algorithms, specifically AI-based software elements, in autonomous driving systems. These AI systems are fundamental in executing real-time critical functions in complex and high-dimensional environments. They handle vital tasks like multi-modal perception, cognition, and decision-making tasks such as motion planning, lane keeping, and emergency braking. A primary concern relates to the ability (and necessity) of AI models to generalize beyond their initial training data. This generalization issue becomes evident in real-time scenarios, where models frequently encounter inputs not represented in their training or validation data. In such cases, AI systems must still function effectively despite facing distributional or domain shifts. This paper investigates the risk associated with overconfident AI models in safety-critical applications like autonomous driving. To mitigate these risks, methods for training AI m",
    "path": "papers/24/02/2402.08208.json",
    "total_tokens": 845,
    "translated_title": "自动驾驶应用中基于人工智能的软件元素固有多样化冗余安全机制",
    "translated_abstract": "本文探讨了人工智能算法在自动驾驶系统中的作用和挑战，特别是基于人工智能的软件元素。这些人工智能系统在复杂和高维环境中执行实时关键功能，处理多模态感知、认知和决策任务，如运动规划、车道保持和紧急制动。一个主要关注点是AI模型在初始训练数据之外如何进行泛化。这种泛化问题在实时场景中变得明显，模型经常遇到不在其训练或验证数据中表示的输入。在这种情况下，尽管面临分布或领域转移，AI系统仍必须有效地运行。本文调查了在自动驾驶等安全关键应用中，过度自信的AI模型带来的风险。为了减轻这些风险，本文提出了训练AI模型的一些方法。",
    "tldr": "本文研究了自动驾驶系统中基于人工智能的软件元素的作用和挑战，探讨了泛化问题以及过度自信的AI模型所带来的风险，并提出了解决方法。",
    "en_tdlr": "This paper explores the role and challenges of AI-based software elements in autonomous driving systems, investigates the generalization issue and risks of overconfident AI models, and proposes mitigation methods."
}