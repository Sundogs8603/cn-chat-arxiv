{
    "title": "LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History",
    "abstract": "arXiv:2402.18216v1 Announce Type: new  Abstract: With the recent emergence of powerful instruction-tuned large language models (LLMs), various helpful conversational Artificial Intelligence (AI) systems have been deployed across many applications. When prompted by users, these AI systems successfully perform a wide range of tasks as part of a conversation. To provide some sort of memory and context, such approaches typically condition their output on the entire conversational history. Although this sensitivity to the conversational history can often lead to improved performance on subsequent tasks, we find that performance can in fact also be negatively impacted, if there is a task-switch. To the best of our knowledge, our work makes the first attempt to formalize the study of such vulnerabilities and interference of tasks in conversational LLMs caused by task-switches in the conversational history. Our experiments across 5 datasets with 15 task switches using popular LLMs reveal that ",
    "link": "https://arxiv.org/abs/2402.18216",
    "context": "Title: LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History\nAbstract: arXiv:2402.18216v1 Announce Type: new  Abstract: With the recent emergence of powerful instruction-tuned large language models (LLMs), various helpful conversational Artificial Intelligence (AI) systems have been deployed across many applications. When prompted by users, these AI systems successfully perform a wide range of tasks as part of a conversation. To provide some sort of memory and context, such approaches typically condition their output on the entire conversational history. Although this sensitivity to the conversational history can often lead to improved performance on subsequent tasks, we find that performance can in fact also be negatively impacted, if there is a task-switch. To the best of our knowledge, our work makes the first attempt to formalize the study of such vulnerabilities and interference of tasks in conversational LLMs caused by task-switches in the conversational history. Our experiments across 5 datasets with 15 task switches using popular LLMs reveal that ",
    "path": "papers/24/02/2402.18216.json",
    "total_tokens": 829,
    "translated_title": "LLM任务干扰：关于对话历史中任务切换影响的初步研究",
    "translated_abstract": "最近强大的指令调整的大型语言模型(LLMs)的出现，使得各种有用的对话人工智能(AI)系统已经部署在许多应用中。当用户提出问题时，这些AI系统成功地作为对话的一部分执行各种任务。为了提供某种记忆和上下文，这些方法通常将输出条件限制在整个对话历史上。尽管对对话历史的敏感性经常会导致在随后的任务中表现提高，但我们发现，实际上如果有任务切换，表现也可能受到负面影响。据我们所知，我们的工作首次尝试正式研究对话LLMs中由于对话历史中的任务切换而引起的任务干扰和干扰的脆弱性。我们在5个数据集上进行了实验，使用了流行的LLMs进行了15次任务切换，结果表明",
    "tldr": "本研究初步探讨了对话中任务切换对LLM模型干扰的影响，发现任务切换可能导致性能下降。"
}