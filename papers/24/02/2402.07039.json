{
    "title": "Coordinated Disclosure for AI: Beyond Security Vulnerabilities",
    "abstract": "Harm reporting in the field of Artificial Intelligence (AI) currently operates on an ad hoc basis, lacking a structured process for disclosing or addressing algorithmic flaws. In contrast, the Coordinated Vulnerability Disclosure (CVD) ethos and ecosystem play a pivotal role in software security and transparency. Within the U.S. context, there has been a protracted legal and policy struggle to establish a safe harbor from the Computer Fraud and Abuse Act, aiming to foster institutional support for security researchers acting in good faith. Notably, algorithmic flaws in Machine Learning (ML) models present distinct challenges compared to traditional software vulnerabilities, warranting a specialized approach. To address this gap, we propose the implementation of a dedicated Coordinated Flaw Disclosure (CFD) framework tailored to the intricacies of machine learning and artificial intelligence issues. This paper delves into the historical landscape of disclosures in ML, encompassing the a",
    "link": "https://arxiv.org/abs/2402.07039",
    "context": "Title: Coordinated Disclosure for AI: Beyond Security Vulnerabilities\nAbstract: Harm reporting in the field of Artificial Intelligence (AI) currently operates on an ad hoc basis, lacking a structured process for disclosing or addressing algorithmic flaws. In contrast, the Coordinated Vulnerability Disclosure (CVD) ethos and ecosystem play a pivotal role in software security and transparency. Within the U.S. context, there has been a protracted legal and policy struggle to establish a safe harbor from the Computer Fraud and Abuse Act, aiming to foster institutional support for security researchers acting in good faith. Notably, algorithmic flaws in Machine Learning (ML) models present distinct challenges compared to traditional software vulnerabilities, warranting a specialized approach. To address this gap, we propose the implementation of a dedicated Coordinated Flaw Disclosure (CFD) framework tailored to the intricacies of machine learning and artificial intelligence issues. This paper delves into the historical landscape of disclosures in ML, encompassing the a",
    "path": "papers/24/02/2402.07039.json",
    "total_tokens": 889,
    "translated_title": "人工智能的协调披露：超越安全漏洞",
    "translated_abstract": "目前，人工智能领域的伤害报告在披露或解决算法缺陷方面仍然是一种临时性的操作，缺乏结构化的过程。相比之下，协调漏洞披露（CVD）的伦理和生态系统在软件安全和透明度方面发挥着关键作用。在美国的背景下，为了鼓励秉持善意行事的安全研究人员，建立一个安全防护条款以对抗计算机欺诈和滥用法案一直存在长期的法律和政策斗争。值得注意的是，机器学习（ML）模型中的算法缺陷与传统软件漏洞存在着不同的挑战，需要一种专门的方法。为了解决这一差距，我们提出了一种针对机器学习和人工智能问题特殊复杂性的专门协调缺陷披露（CFD）框架的实施。本文深入研究了ML中的披露历史背景，包括",
    "tldr": "这篇论文提出了一种针对机器学习和人工智能问题的协调缺陷披露（CFD）框架，以解决目前领域中缺乏结构化过程的问题。"
}