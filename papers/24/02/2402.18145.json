{
    "title": "Learning Intrinsic Dimension via Information Bottleneck for Explainable Aspect-based Sentiment Analysis",
    "abstract": "arXiv:2402.18145v1 Announce Type: new  Abstract: Gradient-based explanation methods are increasingly used to interpret neural models in natural language processing (NLP) due to their high fidelity. Such methods determine word-level importance using dimension-level gradient values through a norm function, often presuming equal significance for all gradient dimensions. However, in the context of Aspect-based Sentiment Analysis (ABSA), our preliminary research suggests that only specific dimensions are pertinent. To address this, we propose the Information Bottleneck-based Gradient (\\texttt{IBG}) explanation framework for ABSA. This framework leverages an information bottleneck to refine word embeddings into a concise intrinsic dimension, maintaining essential features and omitting unrelated information. Comprehensive tests show that our \\texttt{IBG} approach considerably improves both the models' performance and interpretability by identifying sentiment-aware features.",
    "link": "https://arxiv.org/abs/2402.18145",
    "context": "Title: Learning Intrinsic Dimension via Information Bottleneck for Explainable Aspect-based Sentiment Analysis\nAbstract: arXiv:2402.18145v1 Announce Type: new  Abstract: Gradient-based explanation methods are increasingly used to interpret neural models in natural language processing (NLP) due to their high fidelity. Such methods determine word-level importance using dimension-level gradient values through a norm function, often presuming equal significance for all gradient dimensions. However, in the context of Aspect-based Sentiment Analysis (ABSA), our preliminary research suggests that only specific dimensions are pertinent. To address this, we propose the Information Bottleneck-based Gradient (\\texttt{IBG}) explanation framework for ABSA. This framework leverages an information bottleneck to refine word embeddings into a concise intrinsic dimension, maintaining essential features and omitting unrelated information. Comprehensive tests show that our \\texttt{IBG} approach considerably improves both the models' performance and interpretability by identifying sentiment-aware features.",
    "path": "papers/24/02/2402.18145.json",
    "total_tokens": 841,
    "translated_title": "通过信息瓶颈学习内在维度，用于可解释的基于方面的情感分析",
    "translated_abstract": "基于梯度的解释方法越来越多地用于解释自然语言处理（NLP）中的神经模型，因为其高保真度。这些方法通过一种规范函数使用维度级梯度值来确定单词级重要性，通常假定所有梯度维度具有相等的重要性。然而，在基于方面的情感分析（ABSA）的背景下，我们的初步研究表明只有特定的维度是相关的。为了解决这个问题，我们提出了基于信息瓶颈梯度（IBG）解释框架用于ABSA。该框架利用信息瓶颈将单词嵌入调整为简明的内在维度，保留关键特征并省略无关信息。全面的测试表明，我们的IBG方法通过识别与情感相关的特征，显著改善了模型的性能和可解释性。",
    "tldr": "提出了基于信息瓶颈梯度（IBG）解释框架，通过将单词嵌入调整为简明的内在维度来提高基于方面的情感分析模型的性能和可解释性。",
    "en_tdlr": "Proposed the Information Bottleneck-based Gradient (IBG) explanation framework to improve the performance and interpretability of aspect-based sentiment analysis models by refining word embeddings into a concise intrinsic dimension."
}