{
    "title": "Landmark-based Localization using Stereo Vision and Deep Learning in GPS-Denied Battlefield Environment",
    "abstract": "arXiv:2402.12551v1 Announce Type: cross  Abstract: Localization in a battlefield environment is increasingly challenging as GPS connectivity is often denied or unreliable, and physical deployment of anchor nodes across wireless networks for localization can be difficult in hostile battlefield terrain. Existing range-free localization methods rely on radio-based anchors and their average hop distance which suffers from accuracy and stability in dynamic and sparse wireless network topology. Vision-based methods like SLAM and Visual Odometry use expensive sensor fusion techniques for map generation and pose estimation. This paper proposes a novel framework for localization in non-GPS battlefield environments using only the passive camera sensors and considering naturally existing or artificial landmarks as anchors. The proposed method utilizes a customcalibrated stereo vision camera for distance estimation and the YOLOv8s model, which is trained and fine-tuned with our real-world dataset ",
    "link": "https://arxiv.org/abs/2402.12551",
    "context": "Title: Landmark-based Localization using Stereo Vision and Deep Learning in GPS-Denied Battlefield Environment\nAbstract: arXiv:2402.12551v1 Announce Type: cross  Abstract: Localization in a battlefield environment is increasingly challenging as GPS connectivity is often denied or unreliable, and physical deployment of anchor nodes across wireless networks for localization can be difficult in hostile battlefield terrain. Existing range-free localization methods rely on radio-based anchors and their average hop distance which suffers from accuracy and stability in dynamic and sparse wireless network topology. Vision-based methods like SLAM and Visual Odometry use expensive sensor fusion techniques for map generation and pose estimation. This paper proposes a novel framework for localization in non-GPS battlefield environments using only the passive camera sensors and considering naturally existing or artificial landmarks as anchors. The proposed method utilizes a customcalibrated stereo vision camera for distance estimation and the YOLOv8s model, which is trained and fine-tuned with our real-world dataset ",
    "path": "papers/24/02/2402.12551.json",
    "total_tokens": 813,
    "translated_title": "在GPS受阻的战场环境中使用立体视觉和深度学习的基于地标的定位",
    "translated_abstract": "在战场环境中进行定位越来越具有挑战性，因为GPS连接通常受阻或不可靠，而在恶劣的战场地形中部署用于定位的锚节点可能会很困难。现有的无线网络定位方法依赖于基于无线电的锚定节点及其平均跳跃距离，这在动态和稀疏的无线网络拓扑中存在精度和稳定性问题。基于视觉的方法如SLAM和视觉里程计使用昂贵的传感器融合技术进行地图生成和姿态估计。本文提出了一种在非GPS战场环境中只利用被动摄像头传感器并考虑自然存在或人工设置的地标作为锚的定位新框架。所提出的方法利用定制校准的立体视觉摄像头进行距离估计，并使用经我们实际数据集训练和微调的YOLOv8s模型。",
    "tldr": "提出了一种在非GPS战场环境中使用立体视觉和深度学习的基于地标的定位方法"
}