{
    "title": "Machine Unlearning for Image-to-Image Generative Models",
    "abstract": "Machine unlearning has emerged as a new paradigm to deliberately forget data samples from a given model in order to adhere to stringent regulations. However, existing machine unlearning methods have been primarily focused on classification models, leaving the landscape of unlearning for generative models relatively unexplored. This paper serves as a bridge, addressing the gap by providing a unifying framework of machine unlearning for image-to-image generative models. Within this framework, we propose a computationally-efficient algorithm, underpinned by rigorous theoretical analysis, that demonstrates negligible performance degradation on the retain samples, while effectively removing the information from the forget samples. Empirical studies on two large-scale datasets, ImageNet-1K and Places-365, further show that our algorithm does not rely on the availability of the retain samples, which further complies with data retention policy. To our best knowledge, this work is the first tha",
    "link": "https://arxiv.org/abs/2402.00351",
    "context": "Title: Machine Unlearning for Image-to-Image Generative Models\nAbstract: Machine unlearning has emerged as a new paradigm to deliberately forget data samples from a given model in order to adhere to stringent regulations. However, existing machine unlearning methods have been primarily focused on classification models, leaving the landscape of unlearning for generative models relatively unexplored. This paper serves as a bridge, addressing the gap by providing a unifying framework of machine unlearning for image-to-image generative models. Within this framework, we propose a computationally-efficient algorithm, underpinned by rigorous theoretical analysis, that demonstrates negligible performance degradation on the retain samples, while effectively removing the information from the forget samples. Empirical studies on two large-scale datasets, ImageNet-1K and Places-365, further show that our algorithm does not rely on the availability of the retain samples, which further complies with data retention policy. To our best knowledge, this work is the first tha",
    "path": "papers/24/02/2402.00351.json",
    "total_tokens": 949,
    "translated_title": "图像到图像生成模型的机器遗忘",
    "translated_abstract": "机器遗忘已经成为一种新的范式，用于从给定模型中有意地遗忘数据样本以符合严格的规定。然而，现有的机器遗忘方法主要集中在分类模型上，对于生成模型的遗忘领域相对未被探索。本文作为一座桥梁，通过提供一个统一的框架来探讨图像到图像生成模型的机器遗忘问题。在该框架下，我们提出了一种计算效率高的算法，通过严格的理论分析证明在保留样本上性能下降可忽略，同时有效地从遗忘样本中删除信息。在两个大规模数据集ImageNet-1K和Places-365上的实证研究进一步表明，我们的算法不依赖于保留样本的可用性，进一步符合数据保留政策。据我们所知，这项工作是第一个进行图像到图像生成模型遗忘研究的工作。",
    "tldr": "本文提出了一种适用于图像到图像生成模型的机器遗忘方法，该方法通过提供一个统一的框架和一个高效的算法，实现在遗忘样本中删除信息且在保留样本上性能几乎没有下降。实证研究证明该方法不依赖于保留样本的可用性，符合数据保留政策。",
    "en_tdlr": "This paper proposes a machine unlearning method for image-to-image generative models that effectively removes information from forget samples while demonstrating negligible performance degradation on retain samples. The proposed method, which is based on a unifying framework and a computationally-efficient algorithm, has been empirically shown to comply with data retention policy without relying on the availability of retain samples. This work is the first to explore machine unlearning for image-to-image generative models."
}