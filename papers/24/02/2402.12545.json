{
    "title": "TrustScore: Reference-Free Evaluation of LLM Response Trustworthiness",
    "abstract": "arXiv:2402.12545v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities across various domains, prompting a surge in their practical applications. However, concerns have arisen regarding the trustworthiness of LLMs outputs, particularly in closed-book question-answering tasks, where non-experts may struggle to identify inaccuracies due to the absence of contextual or ground truth information. This paper introduces TrustScore, a framework based on the concept of Behavioral Consistency, which evaluates whether an LLMs response aligns with its intrinsic knowledge. Additionally, TrustScore can seamlessly integrate with fact-checking methods, which assesses alignment with external knowledge sources. The experimental results show that TrustScore achieves strong correlations with human judgments, surpassing existing reference-free metrics, and achieving results on par with reference-based metrics.",
    "link": "https://arxiv.org/abs/2402.12545",
    "context": "Title: TrustScore: Reference-Free Evaluation of LLM Response Trustworthiness\nAbstract: arXiv:2402.12545v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities across various domains, prompting a surge in their practical applications. However, concerns have arisen regarding the trustworthiness of LLMs outputs, particularly in closed-book question-answering tasks, where non-experts may struggle to identify inaccuracies due to the absence of contextual or ground truth information. This paper introduces TrustScore, a framework based on the concept of Behavioral Consistency, which evaluates whether an LLMs response aligns with its intrinsic knowledge. Additionally, TrustScore can seamlessly integrate with fact-checking methods, which assesses alignment with external knowledge sources. The experimental results show that TrustScore achieves strong correlations with human judgments, surpassing existing reference-free metrics, and achieving results on par with reference-based metrics.",
    "path": "papers/24/02/2402.12545.json",
    "total_tokens": 807,
    "translated_title": "TrustScore: 无参考评估LLM响应的可信度",
    "translated_abstract": "大型语言模型（LLMs）在各个领域展示了令人印象深刻的能力，引发了它们在实际应用中的激增。然而，人们对LLMs输出的可信度产生了担忧，特别是在封闭书问题回答任务中，非专家可能因缺少上下文或基准信息而难以识别不准确之处。本文介绍了TrustScore，一个基于行为一致性概念的框架，评估LLMs的响应是否与其内在知识相一致。此外，TrustScore可以无缝地与事实核查方法集成，评估与外部知识来源的一致性。实验结果显示，TrustScore与人类判断具有强大的相关性，超过了现有的无参考指标，并取得了与基准指标相当的结果。",
    "tldr": "TrustScore 是一个基于行为一致性概念的框架，用于评估大型语言模型（LLMs）的响应是否与其内在知识相一致，并成功实现了与人类判断高度相关的可信度评估。",
    "en_tdlr": "TrustScore is a framework based on the concept of Behavioral Consistency, which evaluates whether the responses of Large Language Models (LLMs) align with their intrinsic knowledge, achieving strong correlations with human judgments."
}