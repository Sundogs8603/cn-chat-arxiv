{
    "title": "Large Language Model Agent for Hyper-Parameter Optimization",
    "abstract": "Hyperparameter optimization is critical in modern machine learning, requiring expert knowledge, numerous trials, and high computational and human resources. Despite the advancements in Automated Machine Learning (AutoML), challenges in terms of trial efficiency, setup complexity, and interoperability still persist. To address these issues, we introduce a novel paradigm leveraging Large Language Models (LLMs) to automate hyperparameter optimization across diverse machine learning tasks, which is named AgentHPO (short for LLM Agent-based Hyperparameter Optimization). Specifically, AgentHPO processes the task information autonomously, conducts experiments with specific hyperparameters (HPs), and iteratively optimizes them based on historical trials. This human-like optimization process largely reduces the number of required trials, simplifies the setup process, and enhances interpretability and user trust, compared to traditional AutoML methods. Extensive empirical experiments conducted o",
    "link": "https://arxiv.org/abs/2402.01881",
    "context": "Title: Large Language Model Agent for Hyper-Parameter Optimization\nAbstract: Hyperparameter optimization is critical in modern machine learning, requiring expert knowledge, numerous trials, and high computational and human resources. Despite the advancements in Automated Machine Learning (AutoML), challenges in terms of trial efficiency, setup complexity, and interoperability still persist. To address these issues, we introduce a novel paradigm leveraging Large Language Models (LLMs) to automate hyperparameter optimization across diverse machine learning tasks, which is named AgentHPO (short for LLM Agent-based Hyperparameter Optimization). Specifically, AgentHPO processes the task information autonomously, conducts experiments with specific hyperparameters (HPs), and iteratively optimizes them based on historical trials. This human-like optimization process largely reduces the number of required trials, simplifies the setup process, and enhances interpretability and user trust, compared to traditional AutoML methods. Extensive empirical experiments conducted o",
    "path": "papers/24/02/2402.01881.json",
    "total_tokens": 791,
    "translated_title": "基于大规模语言模型的超参数优化的技术",
    "translated_abstract": "超参数优化在现代机器学习中至关重要，需要专业知识、大量实验以及高计算和人力资源。尽管自动化机器学习（AutoML）取得了一些进展，但试验效率、设置复杂性和互操作性方面仍存在挑战。为了解决这些问题，我们引入了一种新的范式，利用大规模语言模型（LLMs）来自动化不同机器学习任务的超参数优化，称为AgentHPO（LLM Agent-based Hyperparameter Optimization）。具体来说，AgentHPO自主处理任务信息，根据历史试验对特定超参数（HPs）进行实验，并进行迭代优化。与传统的AutoML方法相比，这种类似人类的优化过程极大地减少了所需的试验次数，简化了设置过程，并提升了解释性和用户信任。",
    "tldr": "基于大规模语言模型的AgentHPO技术通过自动化超参数优化，在机器学习任务中大大减少了试验次数，简化了设置过程，提升了解释性和用户信任。",
    "en_tdlr": "The AgentHPO technique, based on large language models, automates hyperparameter optimization, reducing the number of trials, simplifying setup, and increasing interpretability and user trust in machine learning tasks."
}