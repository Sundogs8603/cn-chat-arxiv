{
    "title": "Potential and Challenges of Model Editing for Social Debiasing",
    "abstract": "arXiv:2402.13462v1 Announce Type: cross  Abstract: Large language models (LLMs) trained on vast corpora suffer from inevitable stereotype biases. Mitigating these biases with fine-tuning could be both costly and data-hungry. Model editing methods, which focus on modifying LLMs in a post-hoc manner, are of great potential to address debiasing. However, it lacks a comprehensive study that facilitates both internal and external model editing methods, supports various bias types, as well as understands the pros and cons of applying editing methods to stereotypical debiasing. To mitigate this gap, we carefully formulate social debiasing into an editing problem and benchmark seven existing model editing algorithms on stereotypical debiasing, i.e., debias editing. Our findings in three scenarios reveal both the potential and challenges of debias editing: (1) Existing model editing methods can effectively preserve knowledge and mitigate biases, while the generalization of debias effect from ed",
    "link": "https://arxiv.org/abs/2402.13462",
    "context": "Title: Potential and Challenges of Model Editing for Social Debiasing\nAbstract: arXiv:2402.13462v1 Announce Type: cross  Abstract: Large language models (LLMs) trained on vast corpora suffer from inevitable stereotype biases. Mitigating these biases with fine-tuning could be both costly and data-hungry. Model editing methods, which focus on modifying LLMs in a post-hoc manner, are of great potential to address debiasing. However, it lacks a comprehensive study that facilitates both internal and external model editing methods, supports various bias types, as well as understands the pros and cons of applying editing methods to stereotypical debiasing. To mitigate this gap, we carefully formulate social debiasing into an editing problem and benchmark seven existing model editing algorithms on stereotypical debiasing, i.e., debias editing. Our findings in three scenarios reveal both the potential and challenges of debias editing: (1) Existing model editing methods can effectively preserve knowledge and mitigate biases, while the generalization of debias effect from ed",
    "path": "papers/24/02/2402.13462.json",
    "total_tokens": 869,
    "translated_title": "模型编辑在社交去偏见中的潜力与挑战",
    "translated_abstract": "在大量语料库上训练的大语言模型（LLMs）不可避免地存在刻板印象偏见。通过微调来减轻这些偏见可能既昂贵又需要大量数据。模型编辑方法专注于以事后方式修改LLMs，对于解决去偏见问题具有巨大潜力。然而，缺乏支持各种偏见类型，并了解应用编辑方法于去偏见过程中的利弊的综合研究。为填补这一差距，我们将社交去偏见仔细构建为一个编辑问题，并在刻板印象去偏见上对七种现有的模型编辑算法进行基准测试，即去偏见编辑。我们在三种情景下的研究结果展示了去偏见编辑的潜力与挑战：（1）现有的模型编辑方法可以有效保留知识并减轻偏见，同时也揭示了去偏见效果从编辑到应用的一般化过程。",
    "tldr": "模型编辑方法在社交去偏见中具有潜力，但也面临挑战，尤其是在支持不同偏见类型和理解编辑方法应用于去偏见过程中的利弊方面。",
    "en_tdlr": "Model editing methods show potential for social debiasing but face challenges, particularly in supporting various bias types and understanding the pros and cons of applying editing methods to the debiasing process."
}