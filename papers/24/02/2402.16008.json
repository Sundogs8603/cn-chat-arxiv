{
    "title": "Unmasking Dementia Detection by Masking Input Gradients: A JSM Approach to Model Interpretability and Precision",
    "abstract": "arXiv:2402.16008v1 Announce Type: cross  Abstract: The evolution of deep learning and artificial intelligence has significantly reshaped technological landscapes. However, their effective application in crucial sectors such as medicine demands more than just superior performance, but trustworthiness as well. While interpretability plays a pivotal role, existing explainable AI (XAI) approaches often do not reveal {\\em Clever Hans} behavior where a model makes (ungeneralizable) correct predictions using spurious correlations or biases in data. Likewise, current post-hoc XAI methods are susceptible to generating unjustified counterfactual examples. In this paper, we approach XAI with an innovative {\\em model debugging} methodology realized through Jacobian Saliency Map (JSM). To cast the problem into a concrete context, we employ Alzheimer's disease (AD) diagnosis as the use case, motivated by its significant impact on human lives and the formidable challenge in its early detection, stemm",
    "link": "https://arxiv.org/abs/2402.16008",
    "context": "Title: Unmasking Dementia Detection by Masking Input Gradients: A JSM Approach to Model Interpretability and Precision\nAbstract: arXiv:2402.16008v1 Announce Type: cross  Abstract: The evolution of deep learning and artificial intelligence has significantly reshaped technological landscapes. However, their effective application in crucial sectors such as medicine demands more than just superior performance, but trustworthiness as well. While interpretability plays a pivotal role, existing explainable AI (XAI) approaches often do not reveal {\\em Clever Hans} behavior where a model makes (ungeneralizable) correct predictions using spurious correlations or biases in data. Likewise, current post-hoc XAI methods are susceptible to generating unjustified counterfactual examples. In this paper, we approach XAI with an innovative {\\em model debugging} methodology realized through Jacobian Saliency Map (JSM). To cast the problem into a concrete context, we employ Alzheimer's disease (AD) diagnosis as the use case, motivated by its significant impact on human lives and the formidable challenge in its early detection, stemm",
    "path": "papers/24/02/2402.16008.json",
    "total_tokens": 948,
    "translated_title": "通过掩盖输入梯度揭示痴呆症检测：一种用于模型可解释性和精确性的JSM方法",
    "translated_abstract": "深度学习和人工智能的发展显著改变了技术格局。然而，在医学等关键领域中有效应用它们需要更多，不仅要有出色的性能，还要有可信赖性。虽然可解释性起着关键作用，但现有的可解释人工智能（XAI）方法经常无法揭示模型以数据中的偏见或偶然关联做出（不能泛化的）正确预测的“机智汉斯”行为。同样，当前的事后XAI方法容易生成不合理的反事实示例。在本文中，我们采用一种创新的“模型调试”方法来处理XAI，该方法通过雅各比显著性图（JSM）实现。为了使问题具体化，我们选择阿尔茨海默病（AD）诊断作为用例，这源于其对人类生活的重大影响以及对早期检测的巨大挑战。",
    "tldr": "通过Jacobson显著性地图（JSM）方法，本文提出了一种创新的模型调试方法，用于揭示深度学习模型中可能存在的偏见和不合理的认知，以提高其在医学领域（以阿尔茨海默病诊断为例）的可解释性和精确性。",
    "en_tdlr": "This paper proposes an innovative model debugging method using Jacobian Saliency Map (JSM) to reveal biases and unjustified reasoning in deep learning models, aiming to enhance their interpretability and precision in the medical domain with Alzheimer's disease diagnosis as a case study."
}