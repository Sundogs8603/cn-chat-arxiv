{
    "title": "ProPD: Dynamic Token Tree Pruning and Generation for LLM Parallel Decoding",
    "abstract": "arXiv:2402.13485v1 Announce Type: cross  Abstract: Recent advancements in generative large language models (LLMs) have significantly boosted the performance in natural language processing tasks. However, their efficiency is hampered by the inherent limitations in autoregressive token generation. While parallel decoding with token tree verification, e.g., Medusa, has been proposed to improve decoding parallelism and efficiency, it often struggles with maintaining contextual relationships due to its independent token prediction approach and incurs significant verification overhead, especially with large tree sizes and batch processing. In this paper, we propose ProPD, an efficient LLM parallel decoding framework based on dynamic token tree pruning and generation. ProPD features an advanced early pruning mechanism to efficiently eliminate unpromising token sequences to improve verification efficiency. Additionally, it introduces a dynamic token tree generation algorithm to balance the com",
    "link": "https://arxiv.org/abs/2402.13485",
    "context": "Title: ProPD: Dynamic Token Tree Pruning and Generation for LLM Parallel Decoding\nAbstract: arXiv:2402.13485v1 Announce Type: cross  Abstract: Recent advancements in generative large language models (LLMs) have significantly boosted the performance in natural language processing tasks. However, their efficiency is hampered by the inherent limitations in autoregressive token generation. While parallel decoding with token tree verification, e.g., Medusa, has been proposed to improve decoding parallelism and efficiency, it often struggles with maintaining contextual relationships due to its independent token prediction approach and incurs significant verification overhead, especially with large tree sizes and batch processing. In this paper, we propose ProPD, an efficient LLM parallel decoding framework based on dynamic token tree pruning and generation. ProPD features an advanced early pruning mechanism to efficiently eliminate unpromising token sequences to improve verification efficiency. Additionally, it introduces a dynamic token tree generation algorithm to balance the com",
    "path": "papers/24/02/2402.13485.json",
    "total_tokens": 828,
    "translated_title": "ProPD：LLM并行解码的动态令牌树修剪和生成",
    "translated_abstract": "近期生成式大型语言模型（LLMs）的进展显著提升了自然语言处理任务的性能。然而，它们的效率受到自回归令牌生成中固有限制的影响。尽管已经提出了带有令牌树验证的并行解码方法，例如Medusa，以改善解码并行性和效率，但由于其独立令牌预测方法以及大树大小和批处理时产生的显著验证开销，它经常难以保持上下文关系。在本文中，我们提出了ProPD，一种基于动态令牌树修剪和生成的高效LLM并行解码框架。ProPD具有一种先进的提前修剪机制，可以有效地消除不太可能的令牌序列以提高验证效率。此外，它引入了一种动态令牌树生成算法来平衡计算成本。",
    "tldr": "提出ProPD，一种基于动态令牌树修剪和生成的高效LLM并行解码框架，通过先进的提前修剪机制和动态令牌树生成算法来提高验证效率。",
    "en_tdlr": "Introducing ProPD, an efficient LLM parallel decoding framework based on dynamic token tree pruning and generation, which enhances verification efficiency through advanced early pruning mechanism and dynamic token tree generation algorithm."
}