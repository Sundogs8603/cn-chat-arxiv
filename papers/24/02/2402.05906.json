{
    "title": "Risk-Sensitive Multi-Agent Reinforcement Learning in Network Aggregative Markov Games",
    "abstract": "Classical multi-agent reinforcement learning (MARL) assumes risk neutrality and complete objectivity for agents. However, in settings where agents need to consider or model human economic or social preferences, a notion of risk must be incorporated into the RL optimization problem. This will be of greater importance in MARL where other human or non-human agents are involved, possibly with their own risk-sensitive policies. In this work, we consider risk-sensitive and non-cooperative MARL with cumulative prospect theory (CPT), a non-convex risk measure and a generalization of coherent measures of risk. CPT is capable of explaining loss aversion in humans and their tendency to overestimate/underestimate small/large probabilities. We propose a distributed sampling-based actor-critic (AC) algorithm with CPT risk for network aggregative Markov games (NAMGs), which we call Distributed Nested CPT-AC. Under a set of assumptions, we prove the convergence of the algorithm to a subjective notion ",
    "link": "https://arxiv.org/abs/2402.05906",
    "context": "Title: Risk-Sensitive Multi-Agent Reinforcement Learning in Network Aggregative Markov Games\nAbstract: Classical multi-agent reinforcement learning (MARL) assumes risk neutrality and complete objectivity for agents. However, in settings where agents need to consider or model human economic or social preferences, a notion of risk must be incorporated into the RL optimization problem. This will be of greater importance in MARL where other human or non-human agents are involved, possibly with their own risk-sensitive policies. In this work, we consider risk-sensitive and non-cooperative MARL with cumulative prospect theory (CPT), a non-convex risk measure and a generalization of coherent measures of risk. CPT is capable of explaining loss aversion in humans and their tendency to overestimate/underestimate small/large probabilities. We propose a distributed sampling-based actor-critic (AC) algorithm with CPT risk for network aggregative Markov games (NAMGs), which we call Distributed Nested CPT-AC. Under a set of assumptions, we prove the convergence of the algorithm to a subjective notion ",
    "path": "papers/24/02/2402.05906.json",
    "total_tokens": 1029,
    "translated_title": "网络聚合马尔可夫博弈中的风险敏感多智能体强化学习",
    "translated_abstract": "传统的多智能体强化学习（MARL）假设智能体对风险中性并具有完全客观性。然而，在智能体需要考虑或建模人类经济或社会偏好的情景中，必须将风险概念纳入强化学习优化问题中。在其他人类或非人类智能体参与，可能具有其自己的风险敏感策略的MARL中，这将更加重要。在这项工作中，我们考虑了具有累积前景理论（CPT）的风险敏感和非合作MARL，CPT是一种非凸风险度量，并且是风险协同度量的扩展。CPT能够解释人类的损失规避和他们对小概率/大概率的高估/低估倾向。我们提出了一种使用CPT风险的分布式基于采样的演员-评论家（AC）算法，用于网络聚合马尔可夫博弈（NAMGs），我们称之为分布式嵌套CPT-AC。在一系列假设下，我们证明了算法收敛到一种主观概念。",
    "tldr": "本论文研究了网络聚合马尔可夫博弈中的风险敏感多智能体强化学习，使用了累积前景理论作为风险度量，并提出了一种分布式嵌套CPT-AC算法。这项工作对于理解人类的损失规避和对概率的高估/低估倾向具有重要意义。",
    "en_tdlr": "This paper investigates risk-sensitive multi-agent reinforcement learning in network aggregative Markov games. It incorporates cumulative prospect theory as a risk measure and proposes a distributed nested CPT-AC algorithm. The work is important for understanding loss aversion in humans and their tendency to overestimate/underestimate probabilities."
}