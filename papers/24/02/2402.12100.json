{
    "title": "Groot: Adversarial Testing for Generative Text-to-Image Models with Tree-based Semantic Transformation",
    "abstract": "arXiv:2402.12100v1 Announce Type: cross  Abstract: With the prevalence of text-to-image generative models, their safety becomes a critical concern. adversarial testing techniques have been developed to probe whether such models can be prompted to produce Not-Safe-For-Work (NSFW) content. However, existing solutions face several challenges, including low success rate and inefficiency. We introduce Groot, the first automated framework leveraging tree-based semantic transformation for adversarial testing of text-to-image models. Groot employs semantic decomposition and sensitive element drowning strategies in conjunction with LLMs to systematically refine adversarial prompts. Our comprehensive evaluation confirms the efficacy of Groot, which not only exceeds the performance of current state-of-the-art approaches but also achieves a remarkable success rate (93.66%) on leading text-to-image models such as DALL-E 3 and Midjourney.",
    "link": "https://arxiv.org/abs/2402.12100",
    "context": "Title: Groot: Adversarial Testing for Generative Text-to-Image Models with Tree-based Semantic Transformation\nAbstract: arXiv:2402.12100v1 Announce Type: cross  Abstract: With the prevalence of text-to-image generative models, their safety becomes a critical concern. adversarial testing techniques have been developed to probe whether such models can be prompted to produce Not-Safe-For-Work (NSFW) content. However, existing solutions face several challenges, including low success rate and inefficiency. We introduce Groot, the first automated framework leveraging tree-based semantic transformation for adversarial testing of text-to-image models. Groot employs semantic decomposition and sensitive element drowning strategies in conjunction with LLMs to systematically refine adversarial prompts. Our comprehensive evaluation confirms the efficacy of Groot, which not only exceeds the performance of current state-of-the-art approaches but also achieves a remarkable success rate (93.66%) on leading text-to-image models such as DALL-E 3 and Midjourney.",
    "path": "papers/24/02/2402.12100.json",
    "total_tokens": 801,
    "translated_title": "Groot: 使用基于树的语义转换对生成式文本到图像模型进行对抗测试",
    "translated_abstract": "随着文本到图像生成模型的普及，其安全性变得至关重要。对抗性测试技术已被开发用于探测这类模型是否能被激发产生不安全内容。然而，现有的解决方案面临着低成功率和低效率等挑战。我们引入了 Groot，这是第一个利用基于树的语义转换进行文本到图像模型对抗测试的自动化框架。Groot 结合语义分解和敏感元素淹没策略，结合 LLMs 来系统地优化对抗性提示。我们的全面评估验证了 Groot 的有效性，它不仅超越了当前最先进方法的性能，而且在领先的文本到图像模型，如 DALL-E 3 和 Midjourney 上取得了显著的成功率（93.66%）。",
    "tldr": "Groot是第一个利用基于树的语义转换进行对抗测试文本到图像模型的自动化框架，成功率高达93.66%。",
    "en_tdlr": "Groot is the first automated framework leveraging tree-based semantic transformation for adversarial testing of text-to-image models, achieving a remarkable success rate of 93.66%."
}