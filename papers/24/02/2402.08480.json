{
    "title": "Revealing Decurve Flows for Generalized Graph Propagation",
    "abstract": "This study addresses the limitations of the traditional analysis of message-passing, central to graph learning, by defining {\\em \\textbf{generalized propagation}} with directed and weighted graphs. The significance manifest in two ways. \\textbf{Firstly}, we propose {\\em Generalized Propagation Neural Networks} (\\textbf{GPNNs}), a framework that unifies most propagation-based graph neural networks. By generating directed-weighted propagation graphs with adjacency function and connectivity function, GPNNs offer enhanced insights into attention mechanisms across various graph models. We delve into the trade-offs within the design space with empirical experiments and emphasize the crucial role of the adjacency function for model expressivity via theoretical analysis. \\textbf{Secondly}, we propose the {\\em Continuous Unified Ricci Curvature} (\\textbf{CURC}), an extension of celebrated {\\em Ollivier-Ricci Curvature} for directed and weighted graphs. Theoretically, we demonstrate that CURC po",
    "link": "https://arxiv.org/abs/2402.08480",
    "context": "Title: Revealing Decurve Flows for Generalized Graph Propagation\nAbstract: This study addresses the limitations of the traditional analysis of message-passing, central to graph learning, by defining {\\em \\textbf{generalized propagation}} with directed and weighted graphs. The significance manifest in two ways. \\textbf{Firstly}, we propose {\\em Generalized Propagation Neural Networks} (\\textbf{GPNNs}), a framework that unifies most propagation-based graph neural networks. By generating directed-weighted propagation graphs with adjacency function and connectivity function, GPNNs offer enhanced insights into attention mechanisms across various graph models. We delve into the trade-offs within the design space with empirical experiments and emphasize the crucial role of the adjacency function for model expressivity via theoretical analysis. \\textbf{Secondly}, we propose the {\\em Continuous Unified Ricci Curvature} (\\textbf{CURC}), an extension of celebrated {\\em Ollivier-Ricci Curvature} for directed and weighted graphs. Theoretically, we demonstrate that CURC po",
    "path": "papers/24/02/2402.08480.json",
    "total_tokens": 911,
    "translated_title": "揭示泛化图传播中的曲线流",
    "translated_abstract": "本研究通过定义具有定向和加权图的{\\em \\textbf{广义传播}}来解决传统信息传递分析的局限性，该分析方法对图学习至关重要。其重要性体现在两个方面。首先，我们提出了{\\em 广义传播神经网络}(\\textbf{GPNNs})，这是一个统一了大多数基于传播的图神经网络的框架。通过生成具有邻接函数和连接函数的定向-加权传播图，GPNNs可以增强对各种图模型中注意机制的洞察力。我们通过实证实验探讨了设计空间中的权衡，并通过理论分析强调了邻接函数对模型表达能力的关键作用。其次，我们提出了{\\em 连续统一里奇曲率}(\\textbf{CURC})，它是著名的{\\em 奥利维尔-里奇曲率}在定向和加权图上的扩展。理论上，我们证明了CURC能够揭示图结构中的关键信息，包括图的连通性和流动属性。",
    "tldr": "本研究提出了广义传播的概念，并设计了广义传播神经网络(GPNNs)和连续统一里奇曲率(CURC)方法，用于在定向和加权图上进行图传播分析和图结构的特性研究。",
    "en_tdlr": "This study introduces the concept of generalized propagation and proposes the Generalized Propagation Neural Networks (GPNNs) and Continuous Unified Ricci Curvature (CURC) methods for analyzing graph propagation and studying the characteristics of directed and weighted graphs."
}