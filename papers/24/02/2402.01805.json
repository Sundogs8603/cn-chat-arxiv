{
    "title": "Exploring the Limitations of Graph Reasoning in Large Language Models",
    "abstract": "Pretrained Large Language Models have demonstrated various types of reasoning capabilities through language-based prompts alone. However, in this paper, we test the depth of graph reasoning for 5 different LLMs (GPT-4, GPT-3.5, Claude-2, Llama-2 and Palm-2) through the problems of graph reasoning. In particular, we design 10 distinct problems of graph traversal, each representing increasing levels of complexity. Further, we analyze the performance of models across various settings such as varying sizes of graphs as well as different forms of k-shot prompting. We highlight various limitations, biases, and properties of LLMs through this benchmarking process, such as an inverse relation to the average degrees of freedom of traversal per node in graphs, the overall negative impact of k-shot prompting on graph reasoning tasks, and a positive response bias which prevents LLMs from identifying the absence of a valid solution. Finally, we propose a new prompting technique specially designed f",
    "link": "https://arxiv.org/abs/2402.01805",
    "context": "Title: Exploring the Limitations of Graph Reasoning in Large Language Models\nAbstract: Pretrained Large Language Models have demonstrated various types of reasoning capabilities through language-based prompts alone. However, in this paper, we test the depth of graph reasoning for 5 different LLMs (GPT-4, GPT-3.5, Claude-2, Llama-2 and Palm-2) through the problems of graph reasoning. In particular, we design 10 distinct problems of graph traversal, each representing increasing levels of complexity. Further, we analyze the performance of models across various settings such as varying sizes of graphs as well as different forms of k-shot prompting. We highlight various limitations, biases, and properties of LLMs through this benchmarking process, such as an inverse relation to the average degrees of freedom of traversal per node in graphs, the overall negative impact of k-shot prompting on graph reasoning tasks, and a positive response bias which prevents LLMs from identifying the absence of a valid solution. Finally, we propose a new prompting technique specially designed f",
    "path": "papers/24/02/2402.01805.json",
    "total_tokens": 979,
    "translated_title": "探索大型语言模型中图推理的局限性",
    "translated_abstract": "预训练的大型语言模型仅通过基于语言的提示就展示了各种类型的推理能力。然而，在本文中，我们通过图推理问题测试了5种不同的大型语言模型（GPT-4，GPT-3.5，Claude-2，Llama-2和Palm-2）的推理深度。特别地，我们设计了10个不同的图遍历问题，每个问题代表着逐步增加的复杂性水平。此外，我们通过对不同图大小以及不同形式的k-shot提示的设置分析了模型的性能。通过这个基准测试过程，我们凸显了LLMs的各种局限性、偏见和属性，比如与每个节点的遍历自由度的平均度数呈反向关系，k-shot提示对图推理任务的整体负面影响，以及积极的回应偏差导致LLMs无法识别有效解的缺失。最后，我们提出一种新的提示技术，专门用于图推理。",
    "tldr": "本文测试了5种不同的大型语言模型在图推理问题上的推理深度，并发现了LLMs的局限性、偏见和属性。我们发现LLMs对于节点遍历自由度的平均度数呈反向关系，k-shot提示对图推理任务有负面影响，并且LLMs存在积极的回应偏差，无法识别有效解的缺失。我们还提出了一种新的图推理提示技术。",
    "en_tdlr": "This paper explores the depth of graph reasoning in 5 different large language models and highlights the limitations, biases, and properties of these models. It reveals an inverse relation between the average degrees of freedom of traversal per node and the performance of the models, negative impact of k-shot prompting on graph reasoning tasks, and a positive response bias that prevents the models from identifying the absence of a valid solution. A new graph reasoning prompting technique is proposed."
}