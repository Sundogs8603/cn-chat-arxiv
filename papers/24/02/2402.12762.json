{
    "title": "Learning under Singularity: An Information Criterion improving WBIC and sBIC",
    "abstract": "arXiv:2402.12762v1 Announce Type: cross  Abstract: We introduce a novel Information Criterion (IC), termed Learning under Singularity (LS), designed to enhance the functionality of the Widely Applicable Bayes Information Criterion (WBIC) and the Singular Bayesian Information Criterion (sBIC). LS is effective without regularity constraints and demonstrates stability. Watanabe defined a statistical model or a learning machine as regular if the mapping from a parameter to a probability distribution is one-to-one and its Fisher information matrix is positive definite. In contrast, models not meeting these conditions are termed singular. Over the past decade, several information criteria for singular cases have been proposed, including WBIC and sBIC. WBIC is applicable in non-regular scenarios but faces challenges with large sample sizes and redundant estimation of known learning coefficients. Conversely, sBIC is limited in its broader application due to its dependence on maximum likelihood",
    "link": "https://arxiv.org/abs/2402.12762",
    "context": "Title: Learning under Singularity: An Information Criterion improving WBIC and sBIC\nAbstract: arXiv:2402.12762v1 Announce Type: cross  Abstract: We introduce a novel Information Criterion (IC), termed Learning under Singularity (LS), designed to enhance the functionality of the Widely Applicable Bayes Information Criterion (WBIC) and the Singular Bayesian Information Criterion (sBIC). LS is effective without regularity constraints and demonstrates stability. Watanabe defined a statistical model or a learning machine as regular if the mapping from a parameter to a probability distribution is one-to-one and its Fisher information matrix is positive definite. In contrast, models not meeting these conditions are termed singular. Over the past decade, several information criteria for singular cases have been proposed, including WBIC and sBIC. WBIC is applicable in non-regular scenarios but faces challenges with large sample sizes and redundant estimation of known learning coefficients. Conversely, sBIC is limited in its broader application due to its dependence on maximum likelihood",
    "path": "papers/24/02/2402.12762.json",
    "total_tokens": 862,
    "translated_title": "在奇异性下的学习：改进WBIC和sBIC的信息准则",
    "translated_abstract": "我们介绍了一种新颖的信息准则（IC），称为在奇异性下的学习（LS），旨在增强广泛适用的贝叶斯信息准则（WBIC）和奇异贝叶斯信息准则（sBIC）的功能。 LS在没有正则性约束的情况下是有效的，并表现出稳定性。Watanabe定义了一个统计模型或学习机器为正则，如果从参数到概率分布的映射是一对一的，并且其Fisher信息矩阵是正定的。相反，不符合这些条件的模型被称为奇异。 在过去的十年中，已经提出了几种奇异情况下的信息准则，包括WBIC和sBIC。 WBIC适用于非正则情况，但在样本量很大且已知学习系数估计冗余时面临挑战。 相反，sBIC在广泛应用方面存在限制，因为它依赖于最大似然估计。",
    "tldr": "LS信息准则旨在增强WBIC和sBIC的功能，有效处理非正则情况，具有稳定性，为奇异情况下的信息准则提供了新的方法",
    "en_tdlr": "The LS criterion aims to enhance the functionality of WBIC and sBIC, effectively handling non-regular scenarios, demonstrating stability, and providing a new approach to information criteria for singular cases."
}