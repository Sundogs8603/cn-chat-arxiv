{
    "title": "Reasoning Capacity in Multi-Agent Systems: Limitations, Challenges and Human-Centered Solutions",
    "abstract": "Remarkable performance of large language models (LLMs) in a variety of tasks brings forth many opportunities as well as challenges of utilizing them in production settings. Towards practical adoption of LLMs, multi-agent systems hold great promise to augment, integrate, and orchestrate LLMs in the larger context of enterprise platforms that use existing proprietary data and models to tackle complex real-world tasks. Despite the tremendous success of these systems, current approaches rely on narrow, single-focus objectives for optimization and evaluation, often overlooking potential constraints in real-world scenarios, including restricted budgets, resources and time. Furthermore, interpreting, analyzing, and debugging these systems requires different components to be evaluated in relation to one another. This demand is currently not feasible with existing methodologies. In this postion paper, we introduce the concept of reasoning capacity as a unifying criterion to enable integration o",
    "link": "https://rss.arxiv.org/abs/2402.01108",
    "context": "Title: Reasoning Capacity in Multi-Agent Systems: Limitations, Challenges and Human-Centered Solutions\nAbstract: Remarkable performance of large language models (LLMs) in a variety of tasks brings forth many opportunities as well as challenges of utilizing them in production settings. Towards practical adoption of LLMs, multi-agent systems hold great promise to augment, integrate, and orchestrate LLMs in the larger context of enterprise platforms that use existing proprietary data and models to tackle complex real-world tasks. Despite the tremendous success of these systems, current approaches rely on narrow, single-focus objectives for optimization and evaluation, often overlooking potential constraints in real-world scenarios, including restricted budgets, resources and time. Furthermore, interpreting, analyzing, and debugging these systems requires different components to be evaluated in relation to one another. This demand is currently not feasible with existing methodologies. In this postion paper, we introduce the concept of reasoning capacity as a unifying criterion to enable integration o",
    "path": "papers/24/02/2402.01108.json",
    "total_tokens": 839,
    "translated_title": "多智能体系统中的推理能力：局限性、挑战和以人为中心的解决方案",
    "translated_abstract": "大型语言模型（LLMs）在各种任务中展现出卓越的性能，为在生产环境中利用它们带来了许多机遇和挑战。为了实现LLMs的实际采用，多智能体系统在企业平台中具有增强、整合和协调LLMs的巨大潜力，该平台利用现有专有数据和模型来解决复杂的现实任务。尽管这些系统取得了巨大的成功，但当前的方法依赖于狭窄、单一目标的优化和评估，往往忽视现实情景中的潜在约束，包括有限的预算、资源和时间。此外，解释、分析和调试这些系统要求不同的组件之间进行相互评估，但现有方法无法满足这种需求。在本论文中，我们引入了推理能力的概念作为一个统一的标准，以实现集成和优化多智能体系统。",
    "tldr": "多智能体系统面临着利用大型语言模型的限制和挑战，需要引入推理能力作为统一的标准来实现系统的整合和优化。"
}