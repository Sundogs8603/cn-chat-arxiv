{
    "title": "Learning to Edit: Aligning LLMs with Knowledge Editing",
    "abstract": "arXiv:2402.11905v1 Announce Type: new  Abstract: Knowledge editing techniques, aiming to efficiently modify a minor proportion of knowledge in large language models (LLMs) without negatively impacting performance across other inputs, have garnered widespread attention. However, existing methods predominantly rely on memorizing the updated knowledge, impeding LLMs from effectively combining the new knowledge with their inherent knowledge when answering questions. To this end, we propose a Learning to Edit (LTE) framework, focusing on teaching LLMs to apply updated knowledge into input questions, inspired by the philosophy of \"Teach a man to fish.\" LTE features a two-phase process: (i) the Alignment Phase, which fine-tunes LLMs on a meticulously curated parallel dataset to make reliable, in-scope edits while preserving out-of-scope information and linguistic proficiency; and (ii) the Inference Phase, which employs a retrieval-based mechanism for real-time and mass knowledge editing. By c",
    "link": "https://arxiv.org/abs/2402.11905",
    "context": "Title: Learning to Edit: Aligning LLMs with Knowledge Editing\nAbstract: arXiv:2402.11905v1 Announce Type: new  Abstract: Knowledge editing techniques, aiming to efficiently modify a minor proportion of knowledge in large language models (LLMs) without negatively impacting performance across other inputs, have garnered widespread attention. However, existing methods predominantly rely on memorizing the updated knowledge, impeding LLMs from effectively combining the new knowledge with their inherent knowledge when answering questions. To this end, we propose a Learning to Edit (LTE) framework, focusing on teaching LLMs to apply updated knowledge into input questions, inspired by the philosophy of \"Teach a man to fish.\" LTE features a two-phase process: (i) the Alignment Phase, which fine-tunes LLMs on a meticulously curated parallel dataset to make reliable, in-scope edits while preserving out-of-scope information and linguistic proficiency; and (ii) the Inference Phase, which employs a retrieval-based mechanism for real-time and mass knowledge editing. By c",
    "path": "papers/24/02/2402.11905.json",
    "total_tokens": 864,
    "translated_title": "学习编写：将LLMs与知识编辑对齐",
    "translated_abstract": "知识编辑技术旨在高效修改大型语言模型（LLMs）中的少量知识，而不会对其他输入的性能产生负面影响，已经引起了广泛关注。然而，现有方法主要依赖于记忆更新后的知识，阻碍了LLMs有效地将新知识与其固有知识相结合以回答问题。为此，我们提出了一个名为“学习编写”（LTE）的框架，重点教导LLMs将更新后的知识应用于输入问题，灵感来自于“授人以鱼不如授人以渔”的理念。LTE具有两阶段过程：（i）对齐阶段，通过在精心筛选的平行数据集上微调LLMs，使其能够进行可靠的、范围内的编辑，同时保留范围外信息和语言能力；（ii）推理阶段，采用基于检索的机制进行实时和大规模知识编辑。",
    "tldr": "提出了一个名为Learning to Edit（LTE）的框架，教导LLMs将更新后的知识应用于输入问题，通过对齐阶段和推理阶段实现可靠的、范围内的文本编辑。",
    "en_tdlr": "Proposed a framework named Learning to Edit (LTE) to teach LLMs to apply updated knowledge into input questions, achieving reliable, in-scope text editing through the Alignment Phase and the Inference Phase."
}