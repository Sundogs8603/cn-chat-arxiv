{
    "title": "Selective \"Selective Prediction\": Reducing Unnecessary Abstention in Vision-Language Reasoning",
    "abstract": "arXiv:2402.15610v1 Announce Type: new  Abstract: Prior work on selective prediction minimizes incorrect predictions from vision-language models (VLMs) by allowing them to abstain from answering when uncertain. However, when deploying a vision-language system with low tolerance for inaccurate predictions, selective prediction may be over-cautious and abstain too frequently, even on many correct predictions. We introduce ReCoVERR, an inference-time algorithm to reduce the over-abstention of a selective vision-language system without decreasing prediction accuracy. When the VLM makes a low-confidence prediction, instead of abstaining ReCoVERR tries to find relevant clues in the image that provide additional evidence for the prediction. ReCoVERR uses an LLM to pose related questions to the VLM, collects high-confidence evidences, and if enough evidence confirms the prediction the system makes a prediction instead of abstaining. ReCoVERR enables two VLMs, BLIP2 and InstructBLIP, to answer u",
    "link": "https://arxiv.org/abs/2402.15610",
    "context": "Title: Selective \"Selective Prediction\": Reducing Unnecessary Abstention in Vision-Language Reasoning\nAbstract: arXiv:2402.15610v1 Announce Type: new  Abstract: Prior work on selective prediction minimizes incorrect predictions from vision-language models (VLMs) by allowing them to abstain from answering when uncertain. However, when deploying a vision-language system with low tolerance for inaccurate predictions, selective prediction may be over-cautious and abstain too frequently, even on many correct predictions. We introduce ReCoVERR, an inference-time algorithm to reduce the over-abstention of a selective vision-language system without decreasing prediction accuracy. When the VLM makes a low-confidence prediction, instead of abstaining ReCoVERR tries to find relevant clues in the image that provide additional evidence for the prediction. ReCoVERR uses an LLM to pose related questions to the VLM, collects high-confidence evidences, and if enough evidence confirms the prediction the system makes a prediction instead of abstaining. ReCoVERR enables two VLMs, BLIP2 and InstructBLIP, to answer u",
    "path": "papers/24/02/2402.15610.json",
    "total_tokens": 890,
    "translated_title": "选择“选择性预测”：减少视觉语言推理中不必要的弃权",
    "translated_abstract": "先前关于选择性预测的工作旨在通过允许视觉-语言模型（VLM）在不确定时放弃回答，以最小化错误预测。然而，当部署一个对不准确预测容忍度低的视觉-语言系统时，选择性预测可能过于谨慎，并且在许多正确预测上过于放弃。我们引入ReCoVERR，一种用于减少选择性视觉-语言系统过度放弃的推理时间算法，而不降低预测准确性。当VLM做出低置信度预测时，ReCoVERR尝试在图像中找到提供额外证据的相关线索，而不是放弃。ReCoVERR使用LLM向VLM提出相关问题，收集高置信度证据，如果足够的证据确认预测，则系统做出预测而不是放弃。ReCoVERR使两个VLM，BLIP2和InstructBLIP，能够回答。",
    "tldr": "引入了一种名为ReCoVERR的算法，能够在视觉-语言系统的推理过程中减少过度放弃，通过寻找图像中的相关线索提供额外证据来取代放弃，从而不降低预测准确性。",
    "en_tdlr": "Introduced an algorithm called ReCoVERR which reduces over-abstention in the inference process of vision-language systems by finding relevant clues in images to provide additional evidence instead of abstaining, without decreasing prediction accuracy."
}