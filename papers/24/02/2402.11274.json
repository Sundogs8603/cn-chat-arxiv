{
    "title": "TC-DiffRecon: Texture coordination MRI reconstruction method based on diffusion model and modified MF-UNet method",
    "abstract": "arXiv:2402.11274v1 Announce Type: cross  Abstract: Recently, diffusion models have gained significant attention as a novel set of deep learning-based generative methods. These models attempt to sample data from a Gaussian distribution that adheres to a target distribution, and have been successfully adapted to the reconstruction of MRI data. However, as an unconditional generative model, the diffusion model typically disrupts image coordination because of the consistent projection of data introduced by conditional bootstrap. This often results in image fragmentation and incoherence. Furthermore, the inherent limitations of the diffusion model often lead to excessive smoothing of the generated images. In the same vein, some deep learning-based models often suffer from poor generalization performance, meaning their effectiveness is greatly affected by different acceleration factors. To address these challenges, we propose a novel diffusion model-based MRI reconstruction method, named TC-",
    "link": "https://arxiv.org/abs/2402.11274",
    "context": "Title: TC-DiffRecon: Texture coordination MRI reconstruction method based on diffusion model and modified MF-UNet method\nAbstract: arXiv:2402.11274v1 Announce Type: cross  Abstract: Recently, diffusion models have gained significant attention as a novel set of deep learning-based generative methods. These models attempt to sample data from a Gaussian distribution that adheres to a target distribution, and have been successfully adapted to the reconstruction of MRI data. However, as an unconditional generative model, the diffusion model typically disrupts image coordination because of the consistent projection of data introduced by conditional bootstrap. This often results in image fragmentation and incoherence. Furthermore, the inherent limitations of the diffusion model often lead to excessive smoothing of the generated images. In the same vein, some deep learning-based models often suffer from poor generalization performance, meaning their effectiveness is greatly affected by different acceleration factors. To address these challenges, we propose a novel diffusion model-based MRI reconstruction method, named TC-",
    "path": "papers/24/02/2402.11274.json",
    "total_tokens": 837,
    "translated_title": "基于扩散模型和改进的MF-UNet方法的纹理协调MRI重建方法",
    "translated_abstract": "最近，扩散模型作为一种新型基于深度学习的生成方法引起了广泛关注。这些模型尝试从符合目标分布的高斯分布中对数据进行采样，并已成功地应用于MRI数据的重建。然而，作为一种无条件生成模型，扩散模型通常由于条件引导引入的一致数据投影而打破图像协调性。这经常导致图像的碎裂和不一致性。此外，扩散模型的固有局限性通常会导致生成图像过度平滑。在同一思路上，一些基于深度学习的模型经常表现出较差的泛化性能，意味着它们的有效性受到不同加速因子的极大影响。为了解决这些挑战，我们提出了一种名为TC-DiffRecon的基于扩散模型的MRI重建方法，",
    "tldr": "提出了一种基于扩散模型的MRI重建方法TC-DiffRecon，旨在解决扩散模型导致的图像碎裂和不一致性以及生成图像过度平滑等问题。",
    "en_tdlr": "Proposed a diffusion model-based MRI reconstruction method called TC-DiffRecon to address image fragmentation, incoherence caused by diffusion model, and excessive smoothing of generated images."
}