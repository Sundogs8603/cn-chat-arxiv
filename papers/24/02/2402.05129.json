{
    "title": "Best Practices for Text Annotation with Large Language Models",
    "abstract": "Large Language Models (LLMs) have ushered in a new era of text annotation, as their ease-of-use, high accuracy, and relatively low costs have meant that their use has exploded in recent months. However, the rapid growth of the field has meant that LLM-based annotation has become something of an academic Wild West: the lack of established practices and standards has led to concerns about the quality and validity of research. Researchers have warned that the ostensible simplicity of LLMs can be misleading, as they are prone to bias, misunderstandings, and unreliable results. Recognizing the transformative potential of LLMs, this paper proposes a comprehensive set of standards and best practices for their reliable, reproducible, and ethical use. These guidelines span critical areas such as model selection, prompt engineering, structured prompting, prompt stability analysis, rigorous model validation, and the consideration of ethical and legal implications. The paper emphasizes the need fo",
    "link": "https://arxiv.org/abs/2402.05129",
    "context": "Title: Best Practices for Text Annotation with Large Language Models\nAbstract: Large Language Models (LLMs) have ushered in a new era of text annotation, as their ease-of-use, high accuracy, and relatively low costs have meant that their use has exploded in recent months. However, the rapid growth of the field has meant that LLM-based annotation has become something of an academic Wild West: the lack of established practices and standards has led to concerns about the quality and validity of research. Researchers have warned that the ostensible simplicity of LLMs can be misleading, as they are prone to bias, misunderstandings, and unreliable results. Recognizing the transformative potential of LLMs, this paper proposes a comprehensive set of standards and best practices for their reliable, reproducible, and ethical use. These guidelines span critical areas such as model selection, prompt engineering, structured prompting, prompt stability analysis, rigorous model validation, and the consideration of ethical and legal implications. The paper emphasizes the need fo",
    "path": "papers/24/02/2402.05129.json",
    "total_tokens": 909,
    "translated_title": "大型语言模型文本标注的最佳实践",
    "translated_abstract": "大型语言模型（LLMs）开启了文本标注的新时代，由于其易用性、高准确性和相对较低的成本，导致最近几个月使用这种模型的增长迅猛。然而，这个领域的快速发展意味着基于LLM的标注成为了一种学术界的“野西”，缺乏建立的实践和标准导致了对研究的质量和有效性的担忧。研究人员警告说，LLM的显而易见的简单性可能会导致误导，因为它们容易受到偏见、误解和不可靠的结果的影响。本文旨在认识到LLM的变革潜力，提出了一套可靠、可重复和符合伦理要求的使用标准和最佳实践。这些指南涵盖了关键领域，如模型选择、提示工程、结构化提示、提示稳定性分析、严格的模型验证以及伦理和法律意识的考虑。本文强调了对全面的验证和透明度的需求。",
    "tldr": "大型语言模型的广泛使用在文本标注领域带来了许多挑战，这篇论文提出了一套可靠、可重复、符合伦理要求的使用标准和最佳实践，以解决相关问题。",
    "en_tdlr": "The widespread use of large language models in text annotation poses challenges in terms of reliability, reproducibility, and ethics. This paper proposes a comprehensive set of standards and best practices to address these issues."
}