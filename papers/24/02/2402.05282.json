{
    "title": "TreeForm: End-to-end Annotation and Evaluation for Form Document Parsing",
    "abstract": "Visually Rich Form Understanding (VRFU) poses a complex research problem due to the documents' highly structured nature and yet highly variable style and content. Current annotation schemes decompose form understanding and omit key hierarchical structure, making development and evaluation of end-to-end models difficult. In this paper, we propose a novel F1 metric to evaluate form parsers and describe a new content-agnostic, tree-based annotation scheme for VRFU: TreeForm. We provide methods to convert previous annotation schemes into TreeForm structures and evaluate TreeForm predictions using a modified version of the normalized tree-edit distance. We present initial baselines for our end-to-end performance metric and the TreeForm edit distance, averaged over the FUNSD and XFUND datasets, of 61.5 and 26.4 respectively. We hope that TreeForm encourages deeper research in annotating, modeling, and evaluating the complexities of form-like documents.",
    "link": "https://arxiv.org/abs/2402.05282",
    "context": "Title: TreeForm: End-to-end Annotation and Evaluation for Form Document Parsing\nAbstract: Visually Rich Form Understanding (VRFU) poses a complex research problem due to the documents' highly structured nature and yet highly variable style and content. Current annotation schemes decompose form understanding and omit key hierarchical structure, making development and evaluation of end-to-end models difficult. In this paper, we propose a novel F1 metric to evaluate form parsers and describe a new content-agnostic, tree-based annotation scheme for VRFU: TreeForm. We provide methods to convert previous annotation schemes into TreeForm structures and evaluate TreeForm predictions using a modified version of the normalized tree-edit distance. We present initial baselines for our end-to-end performance metric and the TreeForm edit distance, averaged over the FUNSD and XFUND datasets, of 61.5 and 26.4 respectively. We hope that TreeForm encourages deeper research in annotating, modeling, and evaluating the complexities of form-like documents.",
    "path": "papers/24/02/2402.05282.json",
    "total_tokens": 838,
    "translated_title": "TreeForm: 表单文档解析的端到端标注与评估",
    "translated_abstract": "由于文档的高度结构化特性以及高度变化的样式和内容，具有视觉丰富的表单理解（VRFU）提出了一个复杂的研究问题。当前的标注方案将表单理解分解，并省略了关键的层次结构，使得开发和评估端到端模型变得困难。在本文中，我们提出了一种新的F1度量方法来评估表单解析器，并描述了一种适用于VRFU的新的内容无关的基于树形的标注方案：TreeForm。我们提供了将以前的标注方案转换为TreeForm结构的方法，并使用修改后的标准化树编辑距离评估TreeForm的预测结果。我们基于FUNSD和XFUND数据集分别得到了端到端性能度量和TreeForm编辑距离的初步基线结果，分别为61.5和26.4。我们希望TreeForm能够促进对类似表单文档的复杂性进行更深入的标注、建模和评估的研究。",
    "tldr": "本文提出了一种TreeForm的标注方案和评估方法，旨在解决表单文档解析的端到端模型开发和评估的问题。",
    "en_tdlr": "This paper proposes a TreeForm annotation scheme and evaluation method to address the challenges in developing and evaluating end-to-end models for form document parsing."
}