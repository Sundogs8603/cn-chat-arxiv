{
    "title": "An introduction to graphical tensor notation for mechanistic interpretability",
    "abstract": "Graphical tensor notation is a simple way of denoting linear operations on tensors, originating from physics. Modern deep learning consists almost entirely of operations on or between tensors, so easily understanding tensor operations is quite important for understanding these systems. This is especially true when attempting to reverse-engineer the algorithms learned by a neural network in order to understand its behavior: a field known as mechanistic interpretability. It's often easy to get confused about which operations are happening between tensors and lose sight of the overall structure, but graphical tensor notation makes it easier to parse things at a glance and see interesting equivalences. The first half of this document introduces the notation and applies it to some decompositions (SVD, CP, Tucker, and tensor network decompositions), while the second half applies it to some existing some foundational approaches for mechanistically understanding language models, loosely follow",
    "link": "https://arxiv.org/abs/2402.01790",
    "context": "Title: An introduction to graphical tensor notation for mechanistic interpretability\nAbstract: Graphical tensor notation is a simple way of denoting linear operations on tensors, originating from physics. Modern deep learning consists almost entirely of operations on or between tensors, so easily understanding tensor operations is quite important for understanding these systems. This is especially true when attempting to reverse-engineer the algorithms learned by a neural network in order to understand its behavior: a field known as mechanistic interpretability. It's often easy to get confused about which operations are happening between tensors and lose sight of the overall structure, but graphical tensor notation makes it easier to parse things at a glance and see interesting equivalences. The first half of this document introduces the notation and applies it to some decompositions (SVD, CP, Tucker, and tensor network decompositions), while the second half applies it to some existing some foundational approaches for mechanistically understanding language models, loosely follow",
    "path": "papers/24/02/2402.01790.json",
    "total_tokens": 843,
    "translated_title": "一种用于机制可解释性的图形张量符号化的介绍",
    "translated_abstract": "图形张量符号化是一种简单的表示张量线性操作的方法，源自物理学。现代深度学习几乎完全由张量操作组成，因此理解张量操作对于理解这些系统非常重要。尤其是在试图反向工程神经网络学习的算法以理解其行为时，这一点尤为重要，这个领域被称为机制可解释性。在张量间进行的操作往往让人混淆，并且很难抓住整体结构，但图形张量符号化使得快速解析和发现有趣的等价关系更加容易。本文的前半部分介绍了这种符号化方法并将其应用于一些分解方法（SVD，CP，Tucker和张量网络分解），后半部分将其应用于一些现有的用于理解语言模型的基础方法，大致遵循",
    "tldr": "图形张量符号化是一种简单的表示张量操作的方法，对于理解深度学习系统和理解神经网络行为具有重要意义。本论文介绍了图形张量符号化的方法，并将其应用于不同的分解和解释语言模型的基础方法中。",
    "en_tdlr": "Graphical tensor notation is a simple method for representing tensor operations that is important for understanding deep learning systems and the behavior of neural networks. This paper introduces graphical tensor notation and applies it to various decompositions and foundational methods for interpreting language models."
}