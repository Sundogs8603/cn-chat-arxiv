{
    "title": "Noise-Adaptive Confidence Sets for Linear Bandits and Application to Bayesian Optimization",
    "abstract": "Adapting to a priori unknown noise level is a very important but challenging problem in sequential decision-making as efficient exploration typically requires knowledge of the noise level, which is often loosely specified. We report significant progress in addressing this issue in linear bandits in two respects. First, we propose a novel confidence set that is `semi-adaptive' to the unknown sub-Gaussian parameter $\\sigma_*^2$ in the sense that the (normalized) confidence width scales with $\\sqrt{d\\sigma_*^2 + \\sigma_0^2}$ where $d$ is the dimension and $\\sigma_0^2$ is the specified sub-Gaussian parameter (known) that can be much larger than $\\sigma_*^2$. This is a significant improvement over $\\sqrt{d\\sigma_0^2}$ of the standard confidence set of Abbasi-Yadkori et al. (2011), especially when $d$ is large. We show that this leads to an improved regret bound in linear bandits. Second, for bounded rewards, we propose a novel variance-adaptive confidence set that has a much improved numeri",
    "link": "https://arxiv.org/abs/2402.07341",
    "context": "Title: Noise-Adaptive Confidence Sets for Linear Bandits and Application to Bayesian Optimization\nAbstract: Adapting to a priori unknown noise level is a very important but challenging problem in sequential decision-making as efficient exploration typically requires knowledge of the noise level, which is often loosely specified. We report significant progress in addressing this issue in linear bandits in two respects. First, we propose a novel confidence set that is `semi-adaptive' to the unknown sub-Gaussian parameter $\\sigma_*^2$ in the sense that the (normalized) confidence width scales with $\\sqrt{d\\sigma_*^2 + \\sigma_0^2}$ where $d$ is the dimension and $\\sigma_0^2$ is the specified sub-Gaussian parameter (known) that can be much larger than $\\sigma_*^2$. This is a significant improvement over $\\sqrt{d\\sigma_0^2}$ of the standard confidence set of Abbasi-Yadkori et al. (2011), especially when $d$ is large. We show that this leads to an improved regret bound in linear bandits. Second, for bounded rewards, we propose a novel variance-adaptive confidence set that has a much improved numeri",
    "path": "papers/24/02/2402.07341.json",
    "total_tokens": 1043,
    "translated_title": "对线性强化学习领域的噪声自适应置信区间及其在贝叶斯优化中的应用",
    "translated_abstract": "在序贯决策中，适应未知噪声水平是一个非常重要但具有挑战性的问题，因为有效的探索通常需要对噪声水平有一定的了解，而噪声水平通常只能粗略地指定。我们在线性强化学习领域取得了显著进展，主要有两方面。首先，我们提出了一种新颖的置信区间，该置信区间在未知的亚高斯参数σ_*^2上是“半自适应”的，意味着（归一化的）置信宽度与√（dσ_*^2 + σ_0^2）成正比，其中d为维度，σ_0^2为指定的（已知）亚高斯参数，其值可能比σ_*^2大得多。相比于Abbasi-Yadkori等人（2011）的标准置信区间的√（dσ_0^2），这是一个显著的改进，特别是当d较大时。我们证明了这导致了线性强化学习中改进的后悔边界。其次，对于有界奖励，我们提出了一种新颖的方差自适应置信区间，具有更好的数值性能。",
    "tldr": "这项研究提出了一种对线性强化学习领域中未知噪声水平的自适应置信区间，与已有方法相比，在维度较大时具有显著的改进。此外，针对有界奖励，还提出了一种方差自适应置信区间，具有更好的数值性能。"
}