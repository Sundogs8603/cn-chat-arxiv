{
    "title": "Merging Facts, Crafting Fallacies: Evaluating the Contradictory Nature of Aggregated Factual Claims in Long-Form Generations",
    "abstract": "Long-form generations from large language models (LLMs) contains a mix of factual and non-factual claims, making evaluating factuality difficult. To evaluate factual precision of long-form generations in a more fine-grained way, prior works propose to decompose long-form generations into multiple verifiable facts and verify those facts independently. The factuality of the generation is the proportion of verifiable facts among all the facts. Such methods assume that combining factual claims forms a factual paragraph. This paper shows that the assumption can be violated due to entity ambiguity. We show that LLMs can generate paragraphs that contain verifiable facts, but the facts are combined to form a non-factual paragraph due to entity ambiguity. We further reveal that existing factual precision metrics, including FActScore and citation recall, cannot properly evaluate the factuality of these non-factual paragraphs. To address this, we introduce an enhanced metric, D-FActScore, specifi",
    "link": "https://arxiv.org/abs/2402.05629",
    "context": "Title: Merging Facts, Crafting Fallacies: Evaluating the Contradictory Nature of Aggregated Factual Claims in Long-Form Generations\nAbstract: Long-form generations from large language models (LLMs) contains a mix of factual and non-factual claims, making evaluating factuality difficult. To evaluate factual precision of long-form generations in a more fine-grained way, prior works propose to decompose long-form generations into multiple verifiable facts and verify those facts independently. The factuality of the generation is the proportion of verifiable facts among all the facts. Such methods assume that combining factual claims forms a factual paragraph. This paper shows that the assumption can be violated due to entity ambiguity. We show that LLMs can generate paragraphs that contain verifiable facts, but the facts are combined to form a non-factual paragraph due to entity ambiguity. We further reveal that existing factual precision metrics, including FActScore and citation recall, cannot properly evaluate the factuality of these non-factual paragraphs. To address this, we introduce an enhanced metric, D-FActScore, specifi",
    "path": "papers/24/02/2402.05629.json",
    "total_tokens": 977,
    "translated_title": "合并事实，塑造谬误：评估长文生成中聚合事实性主张的矛盾性质",
    "translated_abstract": "大型语言模型（LLMs）产生的长文生成物包含了一系列事实和非事实的主张，这使得评估事实性变得困难。为了以更精细的方式评估长文生成物的事实准确性，先前的研究提出将长文生成物分解为多个可验证的事实并独立验证这些事实。生成物的事实性是所有事实中可验证事实的比例。这些方法假设结合了事实主张形成了一个事实性段落。本文展示了这一假设可能因为实体模糊而被违反。我们展示了LLMs可以生成包含可验证事实的段落，但由于实体模糊，这些事实被结合形成了一个非事实的段落。我们进一步揭示了现有的事实准确度度量指标，包括FActScore和引用回顾，无法正确评估这些非事实段落的事实性。为了解决这个问题，我们引入了一种增强度量指标，D-FActScore，作为一个具体的解决方案。",
    "tldr": "该论文研究了长文生成中的事实性问题，发现大型语言模型在生成段落时可能会由于实体模糊而将可验证的事实组合成非事实的段落。现有的事实准确度评估方法无法正确评估这些非事实段落，作者提出了一种增强的度量指标来应对这个问题。"
}