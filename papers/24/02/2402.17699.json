{
    "title": "Gradient-based Discrete Sampling with Automatic Cyclical Scheduling",
    "abstract": "arXiv:2402.17699v1 Announce Type: new  Abstract: Discrete distributions, particularly in high-dimensional deep models, are often highly multimodal due to inherent discontinuities. While gradient-based discrete sampling has proven effective, it is susceptible to becoming trapped in local modes due to the gradient information. To tackle this challenge, we propose an automatic cyclical scheduling, designed for efficient and accurate sampling in multimodal discrete distributions. Our method contains three key components: (1) a cyclical step size schedule where large steps discover new modes and small steps exploit each mode; (2) a cyclical balancing schedule, ensuring ``balanced\" proposals for given step sizes and high efficiency of the Markov chain; and (3) an automatic tuning scheme for adjusting the hyperparameters in the cyclical schedules, allowing adaptability across diverse datasets with minimal tuning. We prove the non-asymptotic convergence and inference guarantee for our method i",
    "link": "https://arxiv.org/abs/2402.17699",
    "context": "Title: Gradient-based Discrete Sampling with Automatic Cyclical Scheduling\nAbstract: arXiv:2402.17699v1 Announce Type: new  Abstract: Discrete distributions, particularly in high-dimensional deep models, are often highly multimodal due to inherent discontinuities. While gradient-based discrete sampling has proven effective, it is susceptible to becoming trapped in local modes due to the gradient information. To tackle this challenge, we propose an automatic cyclical scheduling, designed for efficient and accurate sampling in multimodal discrete distributions. Our method contains three key components: (1) a cyclical step size schedule where large steps discover new modes and small steps exploit each mode; (2) a cyclical balancing schedule, ensuring ``balanced\" proposals for given step sizes and high efficiency of the Markov chain; and (3) an automatic tuning scheme for adjusting the hyperparameters in the cyclical schedules, allowing adaptability across diverse datasets with minimal tuning. We prove the non-asymptotic convergence and inference guarantee for our method i",
    "path": "papers/24/02/2402.17699.json",
    "total_tokens": 870,
    "translated_title": "使用自动循环调度的基于梯度的离散采样",
    "translated_abstract": "离散分布，特别是在高维深度模型中，通常由于固有的不连续性而呈现高度多模态。虽然基于梯度的离散采样已被证明是有效的，但由于梯度信息，它容易陷入局部模式。为了解决这一挑战，我们提出了一种自动循环调度，旨在实现对多模态离散分布进行高效准确的采样。我们的方法包括三个关键部分：（1）循环步长调度，其中大步长发现新模式，小步长利用每个模式；（2）循环平衡调度，确保给定步长的“平衡”提案和马尔可夫链的高效率；以及（3）自动调整方案，用于调整循环调度中的超参数，实现在各种数据集上的自适应性且需最小调整。我们证明了我们的方法的非渐近收敛和推断保证。",
    "tldr": "提出了一种使用自动循环调度的基于梯度的离散采样方法，有效应对高度多模态的离散分布，包括循环步长调度、循环平衡调度和自动调整超参数方案。",
    "en_tdlr": "Proposed a gradient-based discrete sampling method with automatic cyclical scheduling to address highly multimodal discrete distributions, including cyclical step size schedule, cyclical balancing schedule, and automatic hyperparameter tuning scheme."
}