{
    "title": "MPAT: Building Robust Deep Neural Networks against Textual Adversarial Attacks",
    "abstract": "arXiv:2402.18792v1 Announce Type: cross  Abstract: Deep neural networks have been proven to be vulnerable to adversarial examples and various methods have been proposed to defend against adversarial attacks for natural language processing tasks. However, previous defense methods have limitations in maintaining effective defense while ensuring the performance of the original task. In this paper, we propose a malicious perturbation based adversarial training method (MPAT) for building robust deep neural networks against textual adversarial attacks. Specifically, we construct a multi-level malicious example generation strategy to generate adversarial examples with malicious perturbations, which are used instead of original inputs for model training. Additionally, we employ a novel training objective function to ensure achieving the defense goal without compromising the performance on the original task. We conduct comprehensive experiments to evaluate our defense method by attacking five v",
    "link": "https://arxiv.org/abs/2402.18792",
    "context": "Title: MPAT: Building Robust Deep Neural Networks against Textual Adversarial Attacks\nAbstract: arXiv:2402.18792v1 Announce Type: cross  Abstract: Deep neural networks have been proven to be vulnerable to adversarial examples and various methods have been proposed to defend against adversarial attacks for natural language processing tasks. However, previous defense methods have limitations in maintaining effective defense while ensuring the performance of the original task. In this paper, we propose a malicious perturbation based adversarial training method (MPAT) for building robust deep neural networks against textual adversarial attacks. Specifically, we construct a multi-level malicious example generation strategy to generate adversarial examples with malicious perturbations, which are used instead of original inputs for model training. Additionally, we employ a novel training objective function to ensure achieving the defense goal without compromising the performance on the original task. We conduct comprehensive experiments to evaluate our defense method by attacking five v",
    "path": "papers/24/02/2402.18792.json",
    "total_tokens": 826,
    "translated_title": "MPAT: 抗击文本对抗攻击的鲁棒深度神经网络构建",
    "translated_abstract": "深度神经网络已被证明对于对抗性示例是脆弱的，并且已经提出了各种方法来防御自然语言处理任务的对抗攻击。然而，先前的防御方法在保持有效的防御同时确保原始任务性能方面存在局限性。本文提出了一种基于恶意扰动的对抗训练方法（MPAT），用于构建抵御文本对抗攻击的鲁棒深度神经网络。具体而言，我们构建了一个多级恶意示例生成策略，以生成带有恶意扰动的对抗性示例，这些示例被用来代替模型训练中的原始输入。此外，我们采用了一个新颖的训练目标函数，以确保达到防御目标而不损害原始任务上的性能。我们进行了全面的实验来评估我们的防御方法，通过攻击五个v",
    "tldr": "提出了一种基于恶意扰动的对抗训练方法（MPAT）来构建鲁棒的深度神经网络，用于抵御文本对抗攻击。",
    "en_tdlr": "Introduces a malicious perturbation based adversarial training method (MPAT) to build robust deep neural networks against textual adversarial attacks."
}