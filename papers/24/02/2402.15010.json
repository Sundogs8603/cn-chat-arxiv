{
    "title": "How Important Is Tokenization in French Medical Masked Language Models?",
    "abstract": "arXiv:2402.15010v1 Announce Type: cross  Abstract: Subword tokenization has become the prevailing standard in the field of natural language processing (NLP) over recent years, primarily due to the widespread utilization of pre-trained language models. This shift began with Byte-Pair Encoding (BPE) and was later followed by the adoption of SentencePiece and WordPiece. While subword tokenization consistently outperforms character and word-level tokenization, the precise factors contributing to its success remain unclear. Key aspects such as the optimal segmentation granularity for diverse tasks and languages, the influence of data sources on tokenizers, and the role of morphological information in Indo-European languages remain insufficiently explored. This is particularly pertinent for biomedical terminology, characterized by specific rules governing morpheme combinations. Despite the agglutinative nature of biomedical terminology, existing language models do not explicitly incorporate ",
    "link": "https://arxiv.org/abs/2402.15010",
    "context": "Title: How Important Is Tokenization in French Medical Masked Language Models?\nAbstract: arXiv:2402.15010v1 Announce Type: cross  Abstract: Subword tokenization has become the prevailing standard in the field of natural language processing (NLP) over recent years, primarily due to the widespread utilization of pre-trained language models. This shift began with Byte-Pair Encoding (BPE) and was later followed by the adoption of SentencePiece and WordPiece. While subword tokenization consistently outperforms character and word-level tokenization, the precise factors contributing to its success remain unclear. Key aspects such as the optimal segmentation granularity for diverse tasks and languages, the influence of data sources on tokenizers, and the role of morphological information in Indo-European languages remain insufficiently explored. This is particularly pertinent for biomedical terminology, characterized by specific rules governing morpheme combinations. Despite the agglutinative nature of biomedical terminology, existing language models do not explicitly incorporate ",
    "path": "papers/24/02/2402.15010.json",
    "total_tokens": 757,
    "translated_title": "法语医用口罩语言模型中的标记化有多重要？",
    "translated_abstract": "近年来，基于子词的标记化已成为自然语言处理（NLP）领域中的主流标准，主要是由于预训练语言模型的广泛应用。然而，导致其成功的确切因素，如不同任务和语言的最佳分割粒度，数据源对标记工具的影响以及形态信息在印欧语言中的作用，仍然不够清楚。这在生物医学术语方面尤为重要，其特点是具有管理形态素组合的特定规则。",
    "tldr": "子词标记化成为自然语言处理领域的主流标准，但其成功因素，如不同任务和语言的最佳分割粒度、数据源对标记工具的影响以及形态信息在印欧语言中的作用，仍不明确。",
    "en_tdlr": "Subword tokenization has become the prevailing standard in natural language processing (NLP), but factors contributing to its success, such as optimal segmentation granularity for diverse tasks and languages, influence of data sources on tokenizers, and the role of morphological information in Indo-European languages, remain unclear."
}