{
    "title": "Provable Traffic Rule Compliance in Safe Reinforcement Learning on the Open Sea",
    "abstract": "Autonomous vehicles have to obey traffic rules. These rules are often formalized using temporal logic, resulting in constraints that are hard to solve using optimization-based motion planners. Reinforcement Learning (RL) is a promising method to find motion plans adhering to temporal logic specifications. However, vanilla RL algorithms are based on random exploration, which is inherently unsafe. To address this issue, we propose a provably safe RL approach that always complies with traffic rules. As a specific application area, we consider vessels on the open sea, which must adhere to the Convention on the International Regulations for Preventing Collisions at Sea (COLREGS). We introduce an efficient verification approach that determines the compliance of actions with respect to the COLREGS formalized using temporal logic. Our action verification is integrated into the RL process so that the agent only selects verified actions. In contrast to agents that only integrate the traffic rule",
    "link": "https://arxiv.org/abs/2402.08502",
    "context": "Title: Provable Traffic Rule Compliance in Safe Reinforcement Learning on the Open Sea\nAbstract: Autonomous vehicles have to obey traffic rules. These rules are often formalized using temporal logic, resulting in constraints that are hard to solve using optimization-based motion planners. Reinforcement Learning (RL) is a promising method to find motion plans adhering to temporal logic specifications. However, vanilla RL algorithms are based on random exploration, which is inherently unsafe. To address this issue, we propose a provably safe RL approach that always complies with traffic rules. As a specific application area, we consider vessels on the open sea, which must adhere to the Convention on the International Regulations for Preventing Collisions at Sea (COLREGS). We introduce an efficient verification approach that determines the compliance of actions with respect to the COLREGS formalized using temporal logic. Our action verification is integrated into the RL process so that the agent only selects verified actions. In contrast to agents that only integrate the traffic rule",
    "path": "papers/24/02/2402.08502.json",
    "total_tokens": 885,
    "translated_title": "在开放海域上的安全强化学习中可证明的交通规则遵守",
    "translated_abstract": "自主车辆必须遵守交通规则。这些规则通常使用时态逻辑进行形式化，导致使用基于优化的运动规划器解决这些约束变得困难。强化学习（RL）是一种有前途的方法，可以找到符合时态逻辑规范的运动规划。然而，纯强化学习算法基于随机探索，这在本质上是不安全的。为了解决这个问题，我们提出了一种可证明安全的RL方法，始终遵守交通规则。作为一个特定的应用领域，我们考虑在开放海域上的船只，这些船只必须遵守《海上避碰规则公约》（COLREGS）的规定。我们介绍了一种高效的验证方法，用于确定行为与使用时态逻辑形式化的COLREGS的符合性。我们的行为验证被集成到RL过程中，以便智能体只选择经过验证的行为。与只集成交通规则的智能体相比，",
    "tldr": "这项研究提出了一种可证明安全的强化学习方法，用于在开放海域上的船只中遵守交通规则，并引入了一种有效的验证方法来确定行为是否符合COLREGS规则。",
    "en_tdlr": "This research proposes a provably safe reinforcement learning approach for compliance with traffic rules in vessels on the open sea, introducing an efficient verification method to determine the compliance of actions with the COLREGS regulations."
}