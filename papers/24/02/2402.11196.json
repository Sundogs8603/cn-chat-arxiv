{
    "title": "Maintaining Adversarial Robustness in Continuous Learning",
    "abstract": "arXiv:2402.11196v1 Announce Type: cross  Abstract: Adversarial robustness is essential for security and reliability of machine learning systems. However, the adversarial robustness gained by sophisticated defense algorithms is easily erased as the neural network evolves to learn new tasks. This vulnerability can be addressed by fostering a novel capability for neural networks, termed continual robust learning, which focuses on both the (classification) performance and adversarial robustness on previous tasks during continuous learning. To achieve continuous robust learning, we propose an approach called Double Gradient Projection that projects the gradients for weight updates orthogonally onto two crucial subspaces -- one for stabilizing the smoothed sample gradients and another for stabilizing the final outputs of the neural network. The experimental results on four benchmarks demonstrate that the proposed approach effectively maintains continuous robustness against strong adversarial",
    "link": "https://arxiv.org/abs/2402.11196",
    "context": "Title: Maintaining Adversarial Robustness in Continuous Learning\nAbstract: arXiv:2402.11196v1 Announce Type: cross  Abstract: Adversarial robustness is essential for security and reliability of machine learning systems. However, the adversarial robustness gained by sophisticated defense algorithms is easily erased as the neural network evolves to learn new tasks. This vulnerability can be addressed by fostering a novel capability for neural networks, termed continual robust learning, which focuses on both the (classification) performance and adversarial robustness on previous tasks during continuous learning. To achieve continuous robust learning, we propose an approach called Double Gradient Projection that projects the gradients for weight updates orthogonally onto two crucial subspaces -- one for stabilizing the smoothed sample gradients and another for stabilizing the final outputs of the neural network. The experimental results on four benchmarks demonstrate that the proposed approach effectively maintains continuous robustness against strong adversarial",
    "path": "papers/24/02/2402.11196.json",
    "total_tokens": 843,
    "translated_title": "在连续学习中保持对抗性鲁棒性",
    "translated_abstract": "对抗性鲁棒性对于机器学习系统的安全性和可靠性至关重要。然而，通过复杂的防御算法获得的对抗性鲁棒性在神经网络不断演化以学习新任务时很容易被抹去。这种脆弱性可以通过培养一种新颖的神经网络能力来解决，称为持续鲁棒学习，它在连续学习过程中关注前期任务的(分类)性能和对抗性鲁棒性。为了实现持续鲁棒学习，我们提出了一种称为双梯度投影的方法，将用于权重更新的梯度正交投影到两个关键子空间上 -- 一个用于稳定平滑样本梯度，另一个用于稳定神经网络的最终输出。在四个基准测试上的实验结果表明，所提出的方法有效地维持了对强对抗性的持续鲁棒性。",
    "tldr": "提出了一种名为双梯度投影的方法，通过将梯度投影到两个关键子空间来实现持续鲁棒学习，有效地维持了神经网络对抗性鲁棒性。",
    "en_tdlr": "Introduced a method called Double Gradient Projection that achieves continuous robust learning by projecting gradients onto two crucial subspaces, effectively maintaining adversarial robustness of neural networks."
}