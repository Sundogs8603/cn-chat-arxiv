{
    "title": "Algorithmic Arbitrariness in Content Moderation",
    "abstract": "arXiv:2402.16979v1 Announce Type: cross  Abstract: Machine learning (ML) is widely used to moderate online content. Despite its scalability relative to human moderation, the use of ML introduces unique challenges to content moderation. One such challenge is predictive multiplicity: multiple competing models for content classification may perform equally well on average, yet assign conflicting predictions to the same content. This multiplicity can result from seemingly innocuous choices during model development, such as random seed selection for parameter initialization. We experimentally demonstrate how content moderation tools can arbitrarily classify samples as toxic, leading to arbitrary restrictions on speech. We discuss these findings in terms of human rights set out by the International Covenant on Civil and Political Rights (ICCPR), namely freedom of expression, non-discrimination, and procedural justice. We analyze (i) the extent of predictive multiplicity among state-of-the-ar",
    "link": "https://arxiv.org/abs/2402.16979",
    "context": "Title: Algorithmic Arbitrariness in Content Moderation\nAbstract: arXiv:2402.16979v1 Announce Type: cross  Abstract: Machine learning (ML) is widely used to moderate online content. Despite its scalability relative to human moderation, the use of ML introduces unique challenges to content moderation. One such challenge is predictive multiplicity: multiple competing models for content classification may perform equally well on average, yet assign conflicting predictions to the same content. This multiplicity can result from seemingly innocuous choices during model development, such as random seed selection for parameter initialization. We experimentally demonstrate how content moderation tools can arbitrarily classify samples as toxic, leading to arbitrary restrictions on speech. We discuss these findings in terms of human rights set out by the International Covenant on Civil and Political Rights (ICCPR), namely freedom of expression, non-discrimination, and procedural justice. We analyze (i) the extent of predictive multiplicity among state-of-the-ar",
    "path": "papers/24/02/2402.16979.json",
    "total_tokens": 775,
    "translated_title": "内容审核中的算法武断性",
    "translated_abstract": "机器学习被广泛应用于在线内容审核。尽管相对于人工审核具有可扩展性，但使用机器学习在内容审核中引入了独特的挑战。其中之一是预测的多样性：针对内容分类的多个竞争模型可能在平均表现上同样出色，但对同一内容给出了冲突的预测。这种多样性可能源自模型开发过程中看似无害的选择，比如参数初始化的随机种子选择。我们通过实验证明内容审核工具如何可以武断地将样本分类为有毒的，导致言论受到武断的限制。我们从《国际公民和政治权利公约》所规定的人权角度，特别是言论自由、非歧视和程序公正，讨论了这些发现。我们分析了（i）最先进的审核工具之间预测多样性的程度。",
    "tldr": "机器学习在内容审核中引入了预测多样性的挑战，可能导致内容被武断分类并限制言论自由。",
    "en_tdlr": "The use of machine learning in content moderation introduces challenges with predictive multiplicity, potentially leading to arbitrary classification of content and restrictions on freedom of speech."
}