{
    "title": "Improving Diffusion Models for Inverse Problems Using Optimal Posterior Covariance",
    "abstract": "Recent diffusion models provide a promising zero-shot solution to noisy linear inverse problems without retraining for specific inverse problems. In this paper, we propose the first unified interpretation for existing zero-shot methods from the perspective of approximating the conditional posterior mean for the reverse diffusion process of conditional sampling. We reveal that recent methods are equivalent to making isotropic Gaussian approximations to intractable posterior distributions over clean images given diffused noisy images, with the only difference in the handcrafted design of isotropic posterior covariances. Inspired by this finding, we propose a general plug-and-play posterior covariance optimization based on maximum likelihood estimation to improve recent methods. To achieve optimal posterior covariance without retraining, we provide general solutions based on two approaches specifically designed to leverage pre-trained models with and without reverse covariances. Experimen",
    "link": "https://arxiv.org/abs/2402.02149",
    "context": "Title: Improving Diffusion Models for Inverse Problems Using Optimal Posterior Covariance\nAbstract: Recent diffusion models provide a promising zero-shot solution to noisy linear inverse problems without retraining for specific inverse problems. In this paper, we propose the first unified interpretation for existing zero-shot methods from the perspective of approximating the conditional posterior mean for the reverse diffusion process of conditional sampling. We reveal that recent methods are equivalent to making isotropic Gaussian approximations to intractable posterior distributions over clean images given diffused noisy images, with the only difference in the handcrafted design of isotropic posterior covariances. Inspired by this finding, we propose a general plug-and-play posterior covariance optimization based on maximum likelihood estimation to improve recent methods. To achieve optimal posterior covariance without retraining, we provide general solutions based on two approaches specifically designed to leverage pre-trained models with and without reverse covariances. Experimen",
    "path": "papers/24/02/2402.02149.json",
    "total_tokens": 1055,
    "translated_title": "改进无需重训练的传播模型用于逆问题，使用最优后验协方差",
    "translated_abstract": "最近的传播模型为嘈杂的线性逆问题提供了有希望的零样本解决方案，无需为特定的逆问题重新训练。本文从条件抽样的反向传播过程中近似后验均值的角度，提出了对现有零样本方法的第一个统一解释。我们揭示了最近的方法等价于对给定扩散噪声图像的干净图像的不可计算后验分布进行各向同性高斯近似，唯一的差别是各向同性后验协方差的手工设计。受到这一发现的启示，我们提出了一种基于最大似然估计的通用即插即用后验协方差优化方法，以改进最近的方法。为了实现无需重新训练的最优后验协方差，我们提供了基于两种方法的通用解决方案，这两种方法专门设计用于利用具有和不具有反向协方差的预训练模型。",
    "tldr": "本文提出了一种改进无需重训练的传播模型的方法，通过优化后验协方差，提供了一种零样本解决方案，用于嘈杂的线性逆问题。根据最近的方法等价于对给定扩散噪声图像的干净图像的不可计算后验分布进行各向同性高斯近似的发现，我们提出了一种通用即插即用的后验协方差优化方法。为了实现无需重新训练的最优后验协方差，我们提供了基于两种方法的通用解决方案，这两种方法专门设计用于利用具有和不具有反向协方差的预训练模型。",
    "en_tdlr": "This paper proposes a method to improve diffusion models for noisy linear inverse problems without retraining. By optimizing the posterior covariance, it provides a zero-shot solution for inverse problems. The method approximates the intractable posterior distributions using isotropic Gaussian approximations, and offers a general plug-and-play posterior covariance optimization method. The paper also provides general solutions for achieving optimal posterior covariance without retraining, leveraging pre-trained models with and without reverse covariances."
}