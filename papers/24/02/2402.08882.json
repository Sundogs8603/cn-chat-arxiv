{
    "title": "Moving Object Proposals with Deep Learned Optical Flow for Video Object Segmentation",
    "abstract": "arXiv:2402.08882v1 Announce Type: cross Abstract: Dynamic scene understanding is one of the most conspicuous field of interest among computer vision community. In order to enhance dynamic scene understanding, pixel-wise segmentation with neural networks is widely accepted. The latest researches on pixel-wise segmentation combined semantic and motion information and produced good performance. In this work, we propose a state of art architecture of neural networks to accurately and efficiently get the moving object proposals (MOP). We first train an unsupervised convolutional neural network (UnFlow) to generate optical flow estimation. Then we render the output of optical flow net to a fully convolutional SegNet model. The main contribution of our work is (1) Fine-tuning the pretrained optical flow model on the brand new DAVIS Dataset; (2) Leveraging fully convolutional neural networks with Encoder-Decoder architecture to segment objects. We developed the codes with TensorFlow, and execu",
    "link": "https://arxiv.org/abs/2402.08882",
    "context": "Title: Moving Object Proposals with Deep Learned Optical Flow for Video Object Segmentation\nAbstract: arXiv:2402.08882v1 Announce Type: cross Abstract: Dynamic scene understanding is one of the most conspicuous field of interest among computer vision community. In order to enhance dynamic scene understanding, pixel-wise segmentation with neural networks is widely accepted. The latest researches on pixel-wise segmentation combined semantic and motion information and produced good performance. In this work, we propose a state of art architecture of neural networks to accurately and efficiently get the moving object proposals (MOP). We first train an unsupervised convolutional neural network (UnFlow) to generate optical flow estimation. Then we render the output of optical flow net to a fully convolutional SegNet model. The main contribution of our work is (1) Fine-tuning the pretrained optical flow model on the brand new DAVIS Dataset; (2) Leveraging fully convolutional neural networks with Encoder-Decoder architecture to segment objects. We developed the codes with TensorFlow, and execu",
    "path": "papers/24/02/2402.08882.json",
    "total_tokens": 889,
    "translated_title": "使用深度学习的光流来进行移动物体提案，用于视频物体分割",
    "translated_abstract": "动态场景理解是计算机视觉领域中最引人注目的研究领域之一。为了增强动态场景理解，广泛应用了基于神经网络的像素级分割。最近的研究将语义信息和运动信息相结合，取得了良好的性能。在本研究中，我们提出了一种最先进的神经网络架构，能够准确高效地获取移动物体提案(MOP)。我们首先训练一个无监督的卷积神经网络(UnFlow)来生成光流估计。然后我们将光流网络的输出渲染到一个完全卷积的SegNet模型中。我们的工作主要贡献有：（1）在全新的DAVIS数据集上对预训练的光流模型进行微调；（2）利用编码器-解码器架构的完全卷积神经网络来进行物体分割。我们使用TensorFlow开发了相关代码，并进行了实验验证。",
    "tldr": "本研究提出了一种使用深度学习的光流进行视频物体分割的最新方法，并通过微调预训练的光流模型和使用完全卷积神经网络实现了准确和高效的移动物体提案生成。",
    "en_tdlr": "This paper proposes a state-of-the-art method using deep learned optical flow for video object segmentation, achieving accurate and efficient moving object proposals by fine-tuning a pretrained optical flow model and employing fullyconvolutional neural networks."
}