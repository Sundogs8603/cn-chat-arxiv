{
    "title": "On provable privacy vulnerabilities of graph representations",
    "abstract": "Graph representation learning (GRL) is critical for extracting insights from complex network structures, but it also raises security concerns due to potential privacy vulnerabilities in these representations. This paper investigates the structural vulnerabilities in graph neural models where sensitive topological information can be inferred through edge reconstruction attacks. Our research primarily addresses the theoretical underpinnings of cosine-similarity-based edge reconstruction attacks (COSERA), providing theoretical and empirical evidence that such attacks can perfectly reconstruct sparse Erdos Renyi graphs with independent random features as graph size increases. Conversely, we establish that sparsity is a critical factor for COSERA's effectiveness, as demonstrated through analysis and experiments on stochastic block models. Finally, we explore the resilience of (provably) private graph representations produced via noisy aggregation (NAG) mechanism against COSERA. We empirical",
    "link": "https://arxiv.org/abs/2402.04033",
    "context": "Title: On provable privacy vulnerabilities of graph representations\nAbstract: Graph representation learning (GRL) is critical for extracting insights from complex network structures, but it also raises security concerns due to potential privacy vulnerabilities in these representations. This paper investigates the structural vulnerabilities in graph neural models where sensitive topological information can be inferred through edge reconstruction attacks. Our research primarily addresses the theoretical underpinnings of cosine-similarity-based edge reconstruction attacks (COSERA), providing theoretical and empirical evidence that such attacks can perfectly reconstruct sparse Erdos Renyi graphs with independent random features as graph size increases. Conversely, we establish that sparsity is a critical factor for COSERA's effectiveness, as demonstrated through analysis and experiments on stochastic block models. Finally, we explore the resilience of (provably) private graph representations produced via noisy aggregation (NAG) mechanism against COSERA. We empirical",
    "path": "papers/24/02/2402.04033.json",
    "total_tokens": 840,
    "translated_title": "关于图形表示可证明的隐私漏洞",
    "translated_abstract": "图形表示学习(GRL)对于从复杂的网络结构中提取洞见至关重要，但也引发了安全问题，因为这些表示中可能存在隐私漏洞。本文研究了图神经模型中的结构性漏洞，可以通过边重构攻击推断出敏感的拓扑信息。我们的研究主要解决了基于余弦相似度的边重构攻击(COSERA)的理论基础，并提供了理论和实证证据，证明随着图的规模增加，这种攻击可以完美地重构稀疏的Erdos Renyi图与独立随机特征。反之，我们证明了稀疏性对COSERA的有效性至关重要，通过对随机块模型的分析和实验进行了验证。最后，我们探讨了通过噪声聚合(NAG)机制产生的(可证明的)隐私图表示对COSERA攻击的韧性。我们实证了...",
    "tldr": "研究揭示了图神经模型中的结构性漏洞，通过边重构攻击可以推断出敏感的拓扑信息，并探讨了噪声聚合机制产生的隐私图表示对该攻击的韧性。",
    "en_tdlr": "The research reveals structural vulnerabilities in graph neural models, where sensitive topological information can be inferred through edge reconstruction attacks, and explores the resilience of privacy-preserving graph representations produced by noisy aggregation mechanism against these attacks."
}