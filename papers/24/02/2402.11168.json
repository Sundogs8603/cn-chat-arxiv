{
    "title": "Trust Regions for Explanations via Black-Box Probabilistic Certification",
    "abstract": "arXiv:2402.11168v1 Announce Type: cross  Abstract: Given the black box nature of machine learning models, a plethora of explainability methods have been developed to decipher the factors behind individual decisions. In this paper, we introduce a novel problem of black box (probabilistic) explanation certification. We ask the question: Given a black box model with only query access, an explanation for an example and a quality metric (viz. fidelity, stability), can we find the largest hypercube (i.e., $\\ell_{\\infty}$ ball) centered at the example such that when the explanation is applied to all examples within the hypercube, (with high probability) a quality criterion is met (viz. fidelity greater than some value)? Being able to efficiently find such a \\emph{trust region} has multiple benefits: i) insight into model behavior in a \\emph{region}, with a \\emph{guarantee}; ii) ascertained \\emph{stability} of the explanation; iii) \\emph{explanation reuse}, which can save time, energy and mone",
    "link": "https://arxiv.org/abs/2402.11168",
    "context": "Title: Trust Regions for Explanations via Black-Box Probabilistic Certification\nAbstract: arXiv:2402.11168v1 Announce Type: cross  Abstract: Given the black box nature of machine learning models, a plethora of explainability methods have been developed to decipher the factors behind individual decisions. In this paper, we introduce a novel problem of black box (probabilistic) explanation certification. We ask the question: Given a black box model with only query access, an explanation for an example and a quality metric (viz. fidelity, stability), can we find the largest hypercube (i.e., $\\ell_{\\infty}$ ball) centered at the example such that when the explanation is applied to all examples within the hypercube, (with high probability) a quality criterion is met (viz. fidelity greater than some value)? Being able to efficiently find such a \\emph{trust region} has multiple benefits: i) insight into model behavior in a \\emph{region}, with a \\emph{guarantee}; ii) ascertained \\emph{stability} of the explanation; iii) \\emph{explanation reuse}, which can save time, energy and mone",
    "path": "papers/24/02/2402.11168.json",
    "total_tokens": 863,
    "translated_title": "基于信任区域的黑盒概率认证解释",
    "translated_abstract": "由于机器学习模型的黑盒性质，人们开发了大量的可解释性方法来解析个别决策背后的因素。本文提出了一个新颖的黑盒（概率性）解释认证问题。我们提出了一个问题：给定一个黑盒模型，只有查询访问权，一个示例的解释以及一个质量度量（如逼真度、稳定性），我们是否能找到最大的超立方体（即 $\\ell_{\\infty}$ 球），以示例为中心，使得当解释被应用于超立方体内的所有示例时（高概率下）质量标准得到满足（比如逼真度高于某个值）？能够高效地找到这样一个信任区域有多重好处：i）洞察模型在一个区域内的行为，具有保证；ii）解释的稳定性得到保证；iii）解释的重用，可以节省时间、精力和金钱。",
    "tldr": "通过黑盒概率认证解释的信任区域能够有效地洞察模型行为、保证解释的稳定性，并实现解释的重用",
    "en_tdlr": "Trust regions based on black-box probabilistic certification allow for effective insights into model behavior, guarantee explanation stability, and enable explanation reuse."
}