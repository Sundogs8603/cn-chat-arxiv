{
    "title": "Reviewer2: Optimizing Review Generation Through Prompt Generation",
    "abstract": "arXiv:2402.10886v1 Announce Type: new  Abstract: Recent developments in LLMs offer new opportunities for assisting authors in improving their work. In this paper, we envision a use case where authors can receive LLM-generated reviews that uncover weak points in the current draft. While initial methods for automated review generation already exist, these methods tend to produce reviews that lack detail, and they do not cover the range of opinions that human reviewers produce. To address this shortcoming, we propose an efficient two-stage review generation framework called Reviewer2. Unlike prior work, this approach explicitly models the distribution of possible aspects that the review may address. We show that this leads to more detailed reviews that better cover the range of aspects that human reviewers identify in the draft. As part of the research, we generate a large-scale review dataset of 27k papers and 99k reviews that we annotate with aspect prompts, which we make available as a",
    "link": "https://arxiv.org/abs/2402.10886",
    "context": "Title: Reviewer2: Optimizing Review Generation Through Prompt Generation\nAbstract: arXiv:2402.10886v1 Announce Type: new  Abstract: Recent developments in LLMs offer new opportunities for assisting authors in improving their work. In this paper, we envision a use case where authors can receive LLM-generated reviews that uncover weak points in the current draft. While initial methods for automated review generation already exist, these methods tend to produce reviews that lack detail, and they do not cover the range of opinions that human reviewers produce. To address this shortcoming, we propose an efficient two-stage review generation framework called Reviewer2. Unlike prior work, this approach explicitly models the distribution of possible aspects that the review may address. We show that this leads to more detailed reviews that better cover the range of aspects that human reviewers identify in the draft. As part of the research, we generate a large-scale review dataset of 27k papers and 99k reviews that we annotate with aspect prompts, which we make available as a",
    "path": "papers/24/02/2402.10886.json",
    "total_tokens": 851,
    "translated_title": "通过提示生成优化评论生成",
    "translated_abstract": "最近LLMs的发展为协助作者改进其作品提供了新机会。 本文设想了一个使用案例，即作者可以收到LLM生成的评论，揭示当前草稿中的弱点。 虽然已经存在用于自动生成评论的初始方法，但这些方法往往生成缺乏细节的评论，并且不能涵盖人类审稿人产生的各种意见。 为解决这一不足，我们提出了一种名为Reviewer2的高效二阶段评论生成框架。 与以往的工作不同，这种方法明确地模拟了评论可能涉及的各个方面的分布。 我们表明，这将导致更详细的评论，更好地涵盖人类审稿人在草稿中确定的各种方面。 作为研究的一部分，我们生成了一个包含27,000篇论文和99,000篇评论的大规模评论数据集，我们用方面提示进行了注释，并将其公开可用。",
    "tldr": "Reviewer2是一个高效的两阶段评论生成框架，通过明确建模评论可能涉及的各个方面的分布，生成更详细的评论，更好地涵盖人类审稿人在草稿中确定的各种方面。",
    "en_tdlr": "Reviewer2 is an efficient two-stage review generation framework that generates more detailed reviews and better covers the various aspects identified by human reviewers in the draft by explicitly modeling the distribution of possible aspects the review may address."
}