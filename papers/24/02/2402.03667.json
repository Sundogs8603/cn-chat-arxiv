{
    "title": "Large Language Models as an Indirect Reasoner: Contrapositive and Contradiction for Automated Reasoning",
    "abstract": "Recently, increasing attention has been focused drawn on to improve the ability of Large Language Models (LLMs) to perform complex reasoning. However, previous methods, such as Chain-of-Thought and Self-Consistency, mainly follow Direct Reasoning (DR) frameworks, so they will meet difficulty in solving numerous real-world tasks which can hardly be solved via DR. Therefore, to strengthen the reasoning power of LLMs, this paper proposes a novel Indirect Reasoning (IR) method that employs the logic of contrapositives and contradictions to tackle IR tasks such as factual reasoning and mathematic proof. Specifically, our methodology comprises two steps. Firstly, we leverage the logical equivalence of contrapositive to augment the data and rules to enhance the comprehensibility of LLMs. Secondly, we design a set of prompt templates to trigger LLMs to conduct IR based on proof by contradiction that is logically equivalent to the original DR process. Our IR method is simple yet effective and c",
    "link": "https://arxiv.org/abs/2402.03667",
    "context": "Title: Large Language Models as an Indirect Reasoner: Contrapositive and Contradiction for Automated Reasoning\nAbstract: Recently, increasing attention has been focused drawn on to improve the ability of Large Language Models (LLMs) to perform complex reasoning. However, previous methods, such as Chain-of-Thought and Self-Consistency, mainly follow Direct Reasoning (DR) frameworks, so they will meet difficulty in solving numerous real-world tasks which can hardly be solved via DR. Therefore, to strengthen the reasoning power of LLMs, this paper proposes a novel Indirect Reasoning (IR) method that employs the logic of contrapositives and contradictions to tackle IR tasks such as factual reasoning and mathematic proof. Specifically, our methodology comprises two steps. Firstly, we leverage the logical equivalence of contrapositive to augment the data and rules to enhance the comprehensibility of LLMs. Secondly, we design a set of prompt templates to trigger LLMs to conduct IR based on proof by contradiction that is logically equivalent to the original DR process. Our IR method is simple yet effective and c",
    "path": "papers/24/02/2402.03667.json",
    "total_tokens": 883,
    "translated_title": "大型语言模型作为间接推理器：对自动推理的反证和矛盾",
    "translated_abstract": "最近，人们越来越关注提高大型语言模型（LLMs）进行复杂推理的能力。然而，以前的方法主要是遵循直接推理（DR）框架，如“思维链”和“自一致性”，因此在解决很难通过DR解决的众多实际问题时会遇到困难。因此，为了增强LLMs的推理能力，本文提出了一种新颖的间接推理（IR）方法，该方法利用反证和矛盾的逻辑来处理事实推理和数学证明等IR任务。具体而言，我们的方法包括两个步骤。首先，我们利用反证的逻辑等价性来增强LLMs的数据和规则，以提高其可理解性。其次，我们设计了一组提示模板，触发LLMs进行基于矛盾证明的IR，其逻辑上等价于原始的DR过程。我们的IR方法简单而有效。",
    "tldr": "本文提出了一种大型语言模型的新型间接推理方法，使用反证和矛盾的逻辑来处理复杂推理任务，并通过增强数据和规则，以及设计提示模板的方式增强模型的推理能力。",
    "en_tdlr": "This paper proposes a novel indirect reasoning method for large language models, using the logic of contrapositives and contradictions to tackle complex reasoning tasks. By augmenting the data and rules and designing prompt templates, the model's reasoning capability is enhanced."
}