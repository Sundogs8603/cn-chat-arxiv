{
    "title": "Selective Learning: Towards Robust Calibration with Dynamic Regularization",
    "abstract": "Miscalibration in deep learning refers to there is a discrepancy between the predicted confidence and performance. This problem usually arises due to the overfitting problem, which is characterized by learning everything presented in the training set, resulting in overconfident predictions during testing. Existing methods typically address overfitting and mitigate the miscalibration by adding a maximum-entropy regularizer to the objective function. The objective can be understood as seeking a model that fits the ground-truth labels by increasing the confidence while also maximizing the entropy of predicted probabilities by decreasing the confidence. However, previous methods lack clear guidance on confidence adjustment, leading to conflicting objectives (increasing but also decreasing confidence). Therefore, we introduce a method called Dynamic Regularization (DReg), which aims to learn what should be learned during training thereby circumventing the confidence adjusting trade-off. At ",
    "link": "https://arxiv.org/abs/2402.08384",
    "context": "Title: Selective Learning: Towards Robust Calibration with Dynamic Regularization\nAbstract: Miscalibration in deep learning refers to there is a discrepancy between the predicted confidence and performance. This problem usually arises due to the overfitting problem, which is characterized by learning everything presented in the training set, resulting in overconfident predictions during testing. Existing methods typically address overfitting and mitigate the miscalibration by adding a maximum-entropy regularizer to the objective function. The objective can be understood as seeking a model that fits the ground-truth labels by increasing the confidence while also maximizing the entropy of predicted probabilities by decreasing the confidence. However, previous methods lack clear guidance on confidence adjustment, leading to conflicting objectives (increasing but also decreasing confidence). Therefore, we introduce a method called Dynamic Regularization (DReg), which aims to learn what should be learned during training thereby circumventing the confidence adjusting trade-off. At ",
    "path": "papers/24/02/2402.08384.json",
    "total_tokens": 834,
    "translated_title": "选择性学习：实现动态正则化的鲁棒校准",
    "translated_abstract": "深度学习中的误校准指的是预测的可信度与性能之间存在差异。这个问题通常是由过拟合问题引起的，过拟合问题的特点是学习训练集中呈现出的所有内容，导致在测试过程中进行过于自信的预测。现有方法通常通过在目标函数中添加最大熵正则化器来解决过拟合问题并缓解误校准问题。这个目标可以理解为寻找一个模型，通过增加可信度来适应实际标签，同时通过降低可信度来最大化预测概率的熵。然而，以前的方法缺乏对可信度调整的明确指导，导致目标冲突（增加但也降低可信度）。因此，我们引入了一种称为动态正则化（DReg）的方法，旨在通过训练学习应该学到什么，从而避免可信度调整的权衡。",
    "tldr": "本研究提出了一种名为动态正则化（DReg）的方法，通过训练学习应该学到什么，从而解决深度学习中的过拟合和误校准问题。",
    "en_tdlr": "This research introduces a method called Dynamic Regularization (DReg) that aims to address the overfitting and miscalibration problems in deep learning by learning what should be learned during training."
}