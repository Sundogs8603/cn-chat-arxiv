{
    "title": "Distilling Symbolic Priors for Concept Learning into Neural Networks",
    "abstract": "Humans can learn new concepts from a small number of examples by drawing on their inductive biases. These inductive biases have previously been captured by using Bayesian models defined over symbolic hypothesis spaces. Is it possible to create a neural network that displays the same inductive biases? We show that inductive biases that enable rapid concept learning can be instantiated in artificial neural networks by distilling a prior distribution from a symbolic Bayesian model via meta-learning, an approach for extracting the common structure from a set of tasks. By generating the set of tasks used in meta-learning from the prior distribution of a Bayesian model, we are able to transfer that prior into a neural network. We use this approach to create a neural network with an inductive bias towards concepts expressed as short logical formulas. Analyzing results from previous behavioral experiments in which people learned logical concepts from a few examples, we find that our meta-train",
    "link": "https://arxiv.org/abs/2402.07035",
    "context": "Title: Distilling Symbolic Priors for Concept Learning into Neural Networks\nAbstract: Humans can learn new concepts from a small number of examples by drawing on their inductive biases. These inductive biases have previously been captured by using Bayesian models defined over symbolic hypothesis spaces. Is it possible to create a neural network that displays the same inductive biases? We show that inductive biases that enable rapid concept learning can be instantiated in artificial neural networks by distilling a prior distribution from a symbolic Bayesian model via meta-learning, an approach for extracting the common structure from a set of tasks. By generating the set of tasks used in meta-learning from the prior distribution of a Bayesian model, we are able to transfer that prior into a neural network. We use this approach to create a neural network with an inductive bias towards concepts expressed as short logical formulas. Analyzing results from previous behavioral experiments in which people learned logical concepts from a few examples, we find that our meta-train",
    "path": "papers/24/02/2402.07035.json",
    "total_tokens": 874,
    "translated_title": "将符号先验知识融入神经网络的抽象概念学习",
    "translated_abstract": "人类可以通过利用归纳偏见从少量的示例中学习新的概念。这些归纳偏见先前已通过在符号假设空间上定义贝叶斯模型来捕捉。是否可能创建一个显示相同归纳偏见的神经网络？我们展示了通过元学习（一种从一组任务中提取共同结构的方法）将符号贝叶斯模型的先验分布提取到人工神经网络中，可以实例化能够快速学习概念的归纳偏见。通过以贝叶斯模型的先验分布生成元学习中使用的任务集，我们能够将该先验传输到神经网络中。我们利用这种方法创建了一个具有对以短逻辑公式表示的概念的归纳偏见的神经网络。通过分析先前人们从少量示例中学习逻辑概念的行为实验结果，我们发现我们的元训练方案可以使神经网络快速学习这些概念。",
    "tldr": "本论文通过元学习的方法，将符号贝叶斯模型的先验知识提取到神经网络中，使神经网络具有显示归纳偏见的能力，从而加快对抽象概念的学习。",
    "en_tdlr": "This paper demonstrates a method of distilling symbolic priors from a Bayesian model into neural networks via meta-learning, enabling the neural networks to display inductive biases and enhance rapid concept learning."
}