{
    "title": "Ocassionally Secure: A Comparative Analysis of Code Generation Assistants",
    "abstract": "$ $Large Language Models (LLMs) are being increasingly utilized in various applications, with code generations being a notable example. While previous research has shown that LLMs have the capability to generate both secure and insecure code, the literature does not take into account what factors help generate secure and effective code. Therefore in this paper we focus on identifying and understanding the conditions and contexts in which LLMs can be effectively and safely deployed in real-world scenarios to generate quality code. We conducted a comparative analysis of four advanced LLMs--GPT-3.5 and GPT-4 using ChatGPT and Bard and Gemini from Google--using 9 separate tasks to assess each model's code generation capabilities. We contextualized our study to represent the typical use cases of a real-life developer employing LLMs for everyday tasks as work. Additionally, we place an emphasis on security awareness which is represented through the use of two distinct versions of our develop",
    "link": "https://arxiv.org/abs/2402.00689",
    "context": "Title: Ocassionally Secure: A Comparative Analysis of Code Generation Assistants\nAbstract: $ $Large Language Models (LLMs) are being increasingly utilized in various applications, with code generations being a notable example. While previous research has shown that LLMs have the capability to generate both secure and insecure code, the literature does not take into account what factors help generate secure and effective code. Therefore in this paper we focus on identifying and understanding the conditions and contexts in which LLMs can be effectively and safely deployed in real-world scenarios to generate quality code. We conducted a comparative analysis of four advanced LLMs--GPT-3.5 and GPT-4 using ChatGPT and Bard and Gemini from Google--using 9 separate tasks to assess each model's code generation capabilities. We contextualized our study to represent the typical use cases of a real-life developer employing LLMs for everyday tasks as work. Additionally, we place an emphasis on security awareness which is represented through the use of two distinct versions of our develop",
    "path": "papers/24/02/2402.00689.json",
    "total_tokens": 846,
    "translated_title": "偶尔安全：代码生成辅助工具的比较分析",
    "translated_abstract": "大型语言模型(LLMs)在各种应用中的应用越来越广泛，代码生成就是一个显著的例子。以往的研究表明LLMs有能力生成安全和不安全的代码，但文献没有考虑到什么因素有助于生成安全和有效的代码。因此，本文重点是确定和理解在真实场景中LLMs能够有效和安全地部署来生成优质代码的条件和环境。我们对四个先进的LLMs进行了比较分析——使用ChatGPT和Bard的GPT-3.5和GPT-4，以及来自Google的Gemini——使用9个独立任务来评估每个模型的代码生成能力。我们将我们的研究置于一个典型的使用场景中，代表了开发人员在工作中使用LLMs进行日常任务的情况。此外，我们还强调了安全意识，通过使用我们开发的两个不同版本的工具来体现。",
    "tldr": "本文通过比较分析四种先进的LLMs在9个任务上的表现，确定和理解了在真实场景中有效且安全地部署LLMs生成优质代码的条件和环境。",
    "en_tdlr": "This paper identifies and understands the conditions and contexts in which advanced LLMs can be effectively and safely deployed in real-world scenarios to generate quality code, through a comparative analysis of four LLMs on nine tasks."
}