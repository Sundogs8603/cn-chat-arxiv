{
    "title": "How to Train your Antivirus: RL-based Hardening through the Problem-Space",
    "abstract": "arXiv:2402.19027v1 Announce Type: cross  Abstract: ML-based malware detection on dynamic analysis reports is vulnerable to both evasion and spurious correlations. In this work, we investigate a specific ML architecture employed in the pipeline of a widely-known commercial antivirus company, with the goal to harden it against adversarial malware. Adversarial training, the sole defensive technique that can confer empirical robustness, is not applicable out of the box in this domain, for the principal reason that gradient-based perturbations rarely map back to feasible problem-space programs. We introduce a novel Reinforcement Learning approach for constructing adversarial examples, a constituent part of adversarially training a model against evasion. Our approach comes with multiple advantages. It performs modifications that are feasible in the problem-space, and only those; thus it circumvents the inverse mapping problem. It also makes possible to provide theoretical guarantees on the r",
    "link": "https://arxiv.org/abs/2402.19027",
    "context": "Title: How to Train your Antivirus: RL-based Hardening through the Problem-Space\nAbstract: arXiv:2402.19027v1 Announce Type: cross  Abstract: ML-based malware detection on dynamic analysis reports is vulnerable to both evasion and spurious correlations. In this work, we investigate a specific ML architecture employed in the pipeline of a widely-known commercial antivirus company, with the goal to harden it against adversarial malware. Adversarial training, the sole defensive technique that can confer empirical robustness, is not applicable out of the box in this domain, for the principal reason that gradient-based perturbations rarely map back to feasible problem-space programs. We introduce a novel Reinforcement Learning approach for constructing adversarial examples, a constituent part of adversarially training a model against evasion. Our approach comes with multiple advantages. It performs modifications that are feasible in the problem-space, and only those; thus it circumvents the inverse mapping problem. It also makes possible to provide theoretical guarantees on the r",
    "path": "papers/24/02/2402.19027.json",
    "total_tokens": 670,
    "translated_title": "如何训练您的防病毒软件：基于强化学习的问题空间加固",
    "translated_abstract": "本文探讨了一种特定的机器学习架构，用于加固一家著名商业防病毒公司流程中的机器学习防御技术，以对抗恶意软件。我们引入了一种新颖的强化学习方法，用于构建对抗样本，这是对抗逃避攻击的模型训练的重要组成部分。",
    "tldr": "引入了一种基于强化学习的方法，可在问题空间内构建对抗样本，对抗防病毒软件中的恶意软件攻击。",
    "en_tdlr": "Introduced a reinforcement learning-based approach to construct adversarial examples in the problem space to counter malicious attacks in antivirus software."
}