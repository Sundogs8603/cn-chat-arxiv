{
    "title": "Exploring Multi-Document Information Consolidation for Scientific Sentiment Summarization",
    "abstract": "arXiv:2402.18005v1 Announce Type: cross  Abstract: Modern natural language generation systems with LLMs exhibit the capability to generate a plausible summary of multiple documents; however, it is uncertain if models truly possess the ability of information consolidation to generate summaries, especially on those source documents with opinionated information. To make scientific sentiment summarization more grounded, we hypothesize that in peer review human meta-reviewers follow a three-layer framework of sentiment consolidation to write meta-reviews and it represents the logic of summarizing scientific sentiments in meta-review generation. The framework is validated via human annotation. Based on the framework, we propose evaluation metrics to assess the quality of generated meta-reviews, and we find that the hypothesis of the sentiment consolidation framework works out empirically when we incorporate it as prompts for LLMs to generate meta-reviews in extensive experiments.",
    "link": "https://arxiv.org/abs/2402.18005",
    "context": "Title: Exploring Multi-Document Information Consolidation for Scientific Sentiment Summarization\nAbstract: arXiv:2402.18005v1 Announce Type: cross  Abstract: Modern natural language generation systems with LLMs exhibit the capability to generate a plausible summary of multiple documents; however, it is uncertain if models truly possess the ability of information consolidation to generate summaries, especially on those source documents with opinionated information. To make scientific sentiment summarization more grounded, we hypothesize that in peer review human meta-reviewers follow a three-layer framework of sentiment consolidation to write meta-reviews and it represents the logic of summarizing scientific sentiments in meta-review generation. The framework is validated via human annotation. Based on the framework, we propose evaluation metrics to assess the quality of generated meta-reviews, and we find that the hypothesis of the sentiment consolidation framework works out empirically when we incorporate it as prompts for LLMs to generate meta-reviews in extensive experiments.",
    "path": "papers/24/02/2402.18005.json",
    "total_tokens": 786,
    "translated_title": "探索科学情感总结的多文档信息整合",
    "translated_abstract": "现代自然语言生成系统具有生成多个文档的合理摘要的能力；然而，现在尚不确定模型是否真正具有整合信息的能力来生成总结，尤其是对那些包含个人意见信息的源文档。为了使科学情感总结更加扎实，我们假设在同行评审中，人类元审阅者遵循情感整合的三层框架来撰写元审阅，并且这代表了在元审阅生成过程中总结科学情感的逻辑。通过人类注释，验证了这一框架。基于该框架，我们提出了评估指标来评估生成的元审阅的质量，并且在广泛实验中发现，当我们将其作为LLMs生成元审阅的提示时，情感整合框架的假设在经验上是行得通的。",
    "tldr": "通过人类元审阅者的情感整合框架，提出评估指标并在实验中验证，指导LLMs生成科学元审阅的逻辑被验证可行。"
}