{
    "title": "Interactive Garment Recommendation with User in the Loop",
    "abstract": "arXiv:2402.11627v1 Announce Type: cross  Abstract: Recommending fashion items often leverages rich user profiles and makes targeted suggestions based on past history and previous purchases. In this paper, we work under the assumption that no prior knowledge is given about a user. We propose to build a user profile on the fly by integrating user reactions as we recommend complementary items to compose an outfit. We present a reinforcement learning agent capable of suggesting appropriate garments and ingesting user feedback so to improve its recommendations and maximize user satisfaction. To train such a model, we resort to a proxy model to be able to simulate having user feedback in the training loop. We experiment on the IQON3000 fashion dataset and we find that a reinforcement learning-based agent becomes capable of improving its recommendations by taking into account personal preferences. Furthermore, such task demonstrated to be hard for non-reinforcement models, that cannot exploit",
    "link": "https://arxiv.org/abs/2402.11627",
    "context": "Title: Interactive Garment Recommendation with User in the Loop\nAbstract: arXiv:2402.11627v1 Announce Type: cross  Abstract: Recommending fashion items often leverages rich user profiles and makes targeted suggestions based on past history and previous purchases. In this paper, we work under the assumption that no prior knowledge is given about a user. We propose to build a user profile on the fly by integrating user reactions as we recommend complementary items to compose an outfit. We present a reinforcement learning agent capable of suggesting appropriate garments and ingesting user feedback so to improve its recommendations and maximize user satisfaction. To train such a model, we resort to a proxy model to be able to simulate having user feedback in the training loop. We experiment on the IQON3000 fashion dataset and we find that a reinforcement learning-based agent becomes capable of improving its recommendations by taking into account personal preferences. Furthermore, such task demonstrated to be hard for non-reinforcement models, that cannot exploit",
    "path": "papers/24/02/2402.11627.json",
    "total_tokens": 816,
    "translated_title": "用户参与的交互式服装推荐系统",
    "translated_abstract": "推荐时尚物品通常利用丰富的用户资料，并根据过去的历史和以前的购买做出有针对性的建议。本文假设对用户没有先前知识。我们提出通过集成用户反馈实时构建用户资料，在推荐互补物品以组成服装时。我们提出了一种强化学习Agent，能够建议合适的服装并吸收用户反馈以改善推荐并最大化用户满意度。为了训练这样的模型，我们求助于一个代理模型，以便在训练循环中模拟获得用户反馈。我们在IQON3000时尚数据集上进行实验，发现基于强化学习的Agent能够通过考虑个人偏好来改善其推荐。此外，这样的任务对于无强化的模型来说是困难的，他们无法利用用户反馈。",
    "tldr": "提出一种交互式服装推荐系统，在推荐服装同时实时构建用户资料，通过强化学习Agent吸收用户反馈改善推荐，能够最大化用户满意度。"
}