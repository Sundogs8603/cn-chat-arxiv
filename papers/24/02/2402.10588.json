{
    "title": "Do Llamas Work in English? On the Latent Language of Multilingual Transformers",
    "abstract": "arXiv:2402.10588v1 Announce Type: new  Abstract: We ask whether multilingual language models trained on unbalanced, English-dominated corpora use English as an internal pivot language -- a question of key importance for understanding how language models function and the origins of linguistic bias. Focusing on the Llama-2 family of transformer models, our study uses carefully constructed non-English prompts with a unique correct single-token continuation. From layer to layer, transformers gradually map an input embedding of the final prompt token to an output embedding from which next-token probabilities are computed. Tracking intermediate embeddings through their high-dimensional space reveals three distinct phases, whereby intermediate embeddings (1) start far away from output token embeddings; (2) already allow for decoding a semantically correct next token in the middle layers, but give higher probability to its version in English than in the input language; (3) finally move into an",
    "link": "https://arxiv.org/abs/2402.10588",
    "context": "Title: Do Llamas Work in English? On the Latent Language of Multilingual Transformers\nAbstract: arXiv:2402.10588v1 Announce Type: new  Abstract: We ask whether multilingual language models trained on unbalanced, English-dominated corpora use English as an internal pivot language -- a question of key importance for understanding how language models function and the origins of linguistic bias. Focusing on the Llama-2 family of transformer models, our study uses carefully constructed non-English prompts with a unique correct single-token continuation. From layer to layer, transformers gradually map an input embedding of the final prompt token to an output embedding from which next-token probabilities are computed. Tracking intermediate embeddings through their high-dimensional space reveals three distinct phases, whereby intermediate embeddings (1) start far away from output token embeddings; (2) already allow for decoding a semantically correct next token in the middle layers, but give higher probability to its version in English than in the input language; (3) finally move into an",
    "path": "papers/24/02/2402.10588.json",
    "total_tokens": 888,
    "translated_title": "拉马在英语中有效吗？关于多语言变压器的潜在语言",
    "translated_abstract": "我们探讨了是否在不平衡、英语主导的语料库上训练的多语言语言模型使用英语作为内部枢纽语言的问题——这对于理解语言模型的功能方式以及语言偏见的起源至关重要。 我们关注Llama-2系列变压器模型，通过使用精心构建的非英语提示和唯一正确的单词延续来进行研究。 从一层到另一层，变压器逐渐将最终提示令牌的输入嵌入映射到输出嵌入，从中计算下一个令牌的概率。 通过跟踪其在高维空间中的中间嵌入，揭示了三个不同的阶段，即中间嵌入（1）开始远离输出令牌嵌入；（2）在中间层已经允许解码一个语义正确的下一个令牌，但更倾向于英语版本而不是输入语言的版本；（3）最终移动到",
    "tldr": "本研究通过对Llama-2系列变压器模型的研究发现，在多语言语言模型中存在英语作为内部枢纽语言的现象，这有助于理解语言模型的功能方式以及语言偏见的起源。",
    "en_tdlr": "This study reveals the phenomenon of English being used as an internal pivot language in multilingual language models, which contributes to understanding how language models function and the origins of linguistic bias."
}