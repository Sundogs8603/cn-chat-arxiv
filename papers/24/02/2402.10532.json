{
    "title": "Properties and Challenges of LLM-Generated Explanations",
    "abstract": "arXiv:2402.10532v1 Announce Type: cross  Abstract: The self-rationalising capabilities of large language models (LLMs) have been explored in restricted settings, using task/specific data sets. However, current LLMs do not (only) rely on specifically annotated data; nonetheless, they frequently explain their outputs. The properties of the generated explanations are influenced by the pre-training corpus and by the target data used for instruction fine-tuning. As the pre-training corpus includes a large amount of human-written explanations \"in the wild\", we hypothesise that LLMs adopt common properties of human explanations. By analysing the outputs for a multi-domain instruction fine-tuning data set, we find that generated explanations show selectivity and contain illustrative elements, but less frequently are subjective or misleading. We discuss reasons and consequences of the properties' presence or absence. In particular, we outline positive and negative implications depending on the ",
    "link": "https://arxiv.org/abs/2402.10532",
    "context": "Title: Properties and Challenges of LLM-Generated Explanations\nAbstract: arXiv:2402.10532v1 Announce Type: cross  Abstract: The self-rationalising capabilities of large language models (LLMs) have been explored in restricted settings, using task/specific data sets. However, current LLMs do not (only) rely on specifically annotated data; nonetheless, they frequently explain their outputs. The properties of the generated explanations are influenced by the pre-training corpus and by the target data used for instruction fine-tuning. As the pre-training corpus includes a large amount of human-written explanations \"in the wild\", we hypothesise that LLMs adopt common properties of human explanations. By analysing the outputs for a multi-domain instruction fine-tuning data set, we find that generated explanations show selectivity and contain illustrative elements, but less frequently are subjective or misleading. We discuss reasons and consequences of the properties' presence or absence. In particular, we outline positive and negative implications depending on the ",
    "path": "papers/24/02/2402.10532.json",
    "total_tokens": 846,
    "translated_title": "LLM生成的解释的特性和挑战",
    "translated_abstract": "大型语言模型（LLMs）的自我合理化能力在限定环境中得到了探索，使用特定任务/数据集。然而，当前LLMs并不（仅）依赖于特定注释的数据；然而，它们经常解释它们的输出。生成的解释的特性受预训练语料库和用于指导微调的目标数据的影响。由于预训练语料库包含大量野外人类编写的解释，我们假设LLMs采用了人类解释的共同特性。通过分析多域指导微调数据集的输出，我们发现生成的解释表现出选择性并包含说明性元素，但很少是主观或误导性的。我们讨论了属性存在或缺失的原因和后果。特别是，我们概述了根据LLMs预训练语料库和微调数据的性质，这些属性存在或缺失的积极和消极影响。",
    "tldr": "该研究探讨了大型语言模型生成的解释在多领域指导微调数据集上的特性，发现生成的解释表现出选择性和包含说明性元素，但较少是主观或误导性的。",
    "en_tdlr": "This study explores the properties of explanations generated by large language models on a multi-domain instruction fine-tuning dataset, finding that the generated explanations show selectivity and contain illustrative elements, but are less frequently subjective or misleading."
}