{
    "title": "Acquiring Linguistic Knowledge from Multimodal Input",
    "abstract": "arXiv:2402.17936v1 Announce Type: new  Abstract: In contrast to children, language models (LMs) exhibit considerably inferior data efficiency when acquiring language. In this submission to the BabyLM Challenge (Warstadt et al., 2023), we test the hypothesis that this data efficiency gap is partly caused by a lack of multimodal input and grounding in the learning environment of typical language models. Although previous work looking into this question found that multimodal training can even harm language-only performance, we speculate that these findings can be attributed to catastrophic forgetting of complex language due to fine-tuning on captions data. To test our hypothesis, we perform an ablation study on FLAVA (Singh et al., 2022), a multimodal vision-and-language model, independently varying the volume of text and vision input to quantify how much text data (if any) can be offset by vision at different data scales. We aim to limit catastrophic forgetting through a multitask pretra",
    "link": "https://arxiv.org/abs/2402.17936",
    "context": "Title: Acquiring Linguistic Knowledge from Multimodal Input\nAbstract: arXiv:2402.17936v1 Announce Type: new  Abstract: In contrast to children, language models (LMs) exhibit considerably inferior data efficiency when acquiring language. In this submission to the BabyLM Challenge (Warstadt et al., 2023), we test the hypothesis that this data efficiency gap is partly caused by a lack of multimodal input and grounding in the learning environment of typical language models. Although previous work looking into this question found that multimodal training can even harm language-only performance, we speculate that these findings can be attributed to catastrophic forgetting of complex language due to fine-tuning on captions data. To test our hypothesis, we perform an ablation study on FLAVA (Singh et al., 2022), a multimodal vision-and-language model, independently varying the volume of text and vision input to quantify how much text data (if any) can be offset by vision at different data scales. We aim to limit catastrophic forgetting through a multitask pretra",
    "path": "papers/24/02/2402.17936.json",
    "total_tokens": 921,
    "translated_title": "从多模态输入获取语言知识",
    "translated_abstract": "与儿童相比，语言模型（LMs）在获取语言时显示出明显较低的数据效率。本文提交给BabyLM挑战（Warstadt 等人，2023），我们验证了这一数据效率差距部分是由于典型语言模型学习环境中缺乏多模态输入和接地引起的假设。尽管先前针对这一问题的研究发现，多模态训练甚至可能对仅语言表现造成伤害，我们推测这些发现可以归因于对标题数据微调导致复杂语言的灾难性遗忘。为验证我们的假设，我们在FLAVA（Singh 等人，2022）上进行消融研究，这是一个多模态视觉语言模型，独立地变化文本和视觉输入的数量，以量化在不同数据范围下视觉输入可以弥补多少文本数据（如果有的话）。我们旨在通过多任务预训练来限制灾难性遗忘。",
    "tldr": "语言模型在获取语言知识时表现出较低的数据效率，研究发现这部分原因可能是由于缺乏多模态输入和接地。他们通过对FLAVA模型进行消融研究来验证假设，并试图通过多任务预训练来减少灾难性遗忘。",
    "en_tdlr": "Language models exhibit lower data efficiency in acquiring language, which may be partly due to the lack of multimodal input and grounding. The study conducted ablation on the FLAVA model to validate the hypothesis, aiming to reduce catastrophic forgetting through multitask pretraining."
}