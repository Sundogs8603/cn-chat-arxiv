{
    "title": "Event-aware Video Corpus Moment Retrieval",
    "abstract": "arXiv:2402.13566v1 Announce Type: cross  Abstract: Video Corpus Moment Retrieval (VCMR) is a practical video retrieval task focused on identifying a specific moment within a vast corpus of untrimmed videos using the natural language query. Existing methods for VCMR typically rely on frame-aware video retrieval, calculating similarities between the query and video frames to rank videos based on maximum frame similarity.However, this approach overlooks the semantic structure embedded within the information between frames, namely, the event, a crucial element for human comprehension of videos. Motivated by this, we propose EventFormer, a model that explicitly utilizes events within videos as fundamental units for video retrieval. The model extracts event representations through event reasoning and hierarchical event encoding. The event reasoning module groups consecutive and visually similar frame representations into events, while the hierarchical event encoding encodes information at bo",
    "link": "https://arxiv.org/abs/2402.13566",
    "context": "Title: Event-aware Video Corpus Moment Retrieval\nAbstract: arXiv:2402.13566v1 Announce Type: cross  Abstract: Video Corpus Moment Retrieval (VCMR) is a practical video retrieval task focused on identifying a specific moment within a vast corpus of untrimmed videos using the natural language query. Existing methods for VCMR typically rely on frame-aware video retrieval, calculating similarities between the query and video frames to rank videos based on maximum frame similarity.However, this approach overlooks the semantic structure embedded within the information between frames, namely, the event, a crucial element for human comprehension of videos. Motivated by this, we propose EventFormer, a model that explicitly utilizes events within videos as fundamental units for video retrieval. The model extracts event representations through event reasoning and hierarchical event encoding. The event reasoning module groups consecutive and visually similar frame representations into events, while the hierarchical event encoding encodes information at bo",
    "path": "papers/24/02/2402.13566.json",
    "total_tokens": 759,
    "translated_title": "基于事件感知的视频语料库时刻检索",
    "translated_abstract": "视频语料库时刻检索（VCMR）是一项实用的视频检索任务，重点是使用自然语言查询在庞大的未修剪视频语料库中识别特定时刻。现有的VCMR方法通常依赖于基于帧的视频检索，通过计算查询和视频帧之间的相似性来根据最大帧相似性对视频进行排序。然而，这种方法忽视了嵌入在帧间信息中的语义结构，即事件，这是人类理解视频的关键元素。受此启发，我们提出了EventFormer模型，该模型明确利用视频中的事件作为视频检索的基本单元。该模型通过事件推理和分层事件编码提取事件表示。事件推理模块将连续且视觉相似的帧表示分组成事件，而分层事件编码则在不同层次上编码信息。",
    "tldr": "提出了EventFormer模型，利用事件作为视频检索的基本单元，并通过事件推理和分层事件编码来提取事件表示。",
    "en_tdlr": "Introduced the EventFormer model that utilizes events as fundamental units for video retrieval and extracts event representations through event reasoning and hierarchical event encoding."
}