{
    "title": "A Transition System Abstraction Framework for Neural Network Dynamical System Models",
    "abstract": "arXiv:2402.11739v1 Announce Type: cross  Abstract: This paper proposes a transition system abstraction framework for neural network dynamical system models to enhance the model interpretability, with applications to complex dynamical systems such as human behavior learning and verification. To begin with, the localized working zone will be segmented into multiple localized partitions under the data-driven Maximum Entropy (ME) partitioning method. Then, the transition matrix will be obtained based on the set-valued reachability analysis of neural networks. Finally, applications to human handwriting dynamics learning and verification are given to validate our proposed abstraction framework, which demonstrates the advantages of enhancing the interpretability of the black-box model, i.e., our proposed framework is able to abstract a data-driven neural network model into a transition system, making the neural network model interpretable through verifying specifications described in Computat",
    "link": "https://arxiv.org/abs/2402.11739",
    "context": "Title: A Transition System Abstraction Framework for Neural Network Dynamical System Models\nAbstract: arXiv:2402.11739v1 Announce Type: cross  Abstract: This paper proposes a transition system abstraction framework for neural network dynamical system models to enhance the model interpretability, with applications to complex dynamical systems such as human behavior learning and verification. To begin with, the localized working zone will be segmented into multiple localized partitions under the data-driven Maximum Entropy (ME) partitioning method. Then, the transition matrix will be obtained based on the set-valued reachability analysis of neural networks. Finally, applications to human handwriting dynamics learning and verification are given to validate our proposed abstraction framework, which demonstrates the advantages of enhancing the interpretability of the black-box model, i.e., our proposed framework is able to abstract a data-driven neural network model into a transition system, making the neural network model interpretable through verifying specifications described in Computat",
    "path": "papers/24/02/2402.11739.json",
    "total_tokens": 780,
    "translated_title": "一个用于神经网络动力系统模型的过渡系统抽象框架",
    "translated_abstract": "本文提出了一个用于神经网络动力系统模型的过渡系统抽象框架，以提高模型的可解释性，应用于复杂动力系统，如人类行为学习和验证。首先，将局部工作区域根据数据驱动的最大熵（ME）划分方法分割为多个局部分区。然后，基于神经网络的集值可达性分析获得过渡矩阵。最后，给出了应用于人类手写动力学学习和验证的应用，以验证我们提出的抽象框架，展示了增强黑盒模型可解释性的优势，即我们提出的框架能够将数据驱动的神经网络模型抽象为一个过渡系统，通过验证在计算中描述的规范使神经网络模型变得可解释。",
    "tldr": "提出了一个过渡系统抽象框架，用于增强神经网络动力系统模型的可解释性，并通过人类手写动力学学习和验证应用进行验证。",
    "en_tdlr": "Proposed a transition system abstraction framework to enhance the interpretability of neural network dynamical system models, validated through applications in human handwriting dynamics learning and verification."
}