{
    "title": "Team QUST at SemEval-2024 Task 8: A Comprehensive Study of Monolingual and Multilingual Approaches for Detecting AI-generated Text",
    "abstract": "arXiv:2402.11934v1 Announce Type: cross  Abstract: This paper presents the participation of team QUST in Task 8 SemEval 2024. We first performed data augmentation and cleaning on the dataset to enhance model training efficiency and accuracy. In the monolingual task, we evaluated traditional deep-learning methods, multiscale positive-unlabeled framework (MPU), fine-tuning, adapters and ensemble methods. Then, we selected the top-performing models based on their accuracy from the monolingual models and evaluated them in subtasks A and B. The final model construction employed a stacking ensemble that combined fine-tuning with MPU. Our system achieved 8th (scored 8th in terms of accuracy, officially ranked 13th) place in the official test set in multilingual settings of subtask A. We release our system code at:https://github.com/warmth27/SemEval2024_QUST",
    "link": "https://arxiv.org/abs/2402.11934",
    "context": "Title: Team QUST at SemEval-2024 Task 8: A Comprehensive Study of Monolingual and Multilingual Approaches for Detecting AI-generated Text\nAbstract: arXiv:2402.11934v1 Announce Type: cross  Abstract: This paper presents the participation of team QUST in Task 8 SemEval 2024. We first performed data augmentation and cleaning on the dataset to enhance model training efficiency and accuracy. In the monolingual task, we evaluated traditional deep-learning methods, multiscale positive-unlabeled framework (MPU), fine-tuning, adapters and ensemble methods. Then, we selected the top-performing models based on their accuracy from the monolingual models and evaluated them in subtasks A and B. The final model construction employed a stacking ensemble that combined fine-tuning with MPU. Our system achieved 8th (scored 8th in terms of accuracy, officially ranked 13th) place in the official test set in multilingual settings of subtask A. We release our system code at:https://github.com/warmth27/SemEval2024_QUST",
    "path": "papers/24/02/2402.11934.json",
    "total_tokens": 898,
    "translated_title": "Team QUST在SemEval-2024任务8中的研究：单语和多语言方法对检测AI生成文本的全面研究",
    "translated_abstract": "本文介绍了团队QUST在SemEval 2024任务8中的参与情况。我们首先对数据集进行了增强和清洗，以提高模型训练的效率和准确性。在单语任务中，我们评估了传统的深度学习方法、多尺度正负无标记框架（MPU）、微调、适配器和集成方法。然后，我们从单语模型中选择了表现最佳的模型，并在子任务A和B中对它们进行评估。最终模型采用了将微调与MPU相结合的堆叠集成。在多语言环境的子任务A中，我们的系统在官方测试集中取得了第8名（在准确性方面排名第13）。我们在https://github.com/warmth27/SemEval2024_QUST发布了我们的系统代码。",
    "tldr": "本文研究了团队QUST在SemEval-2024任务8中的参与情况，通过数据增强和清洗提高了模型训练效率和准确性，在单语任务中评估了多种方法并最终采用堆叠集成模型，最终在多语言环境中取得了不错的排名。",
    "en_tdlr": "This paper presents Team QUST's study on participating in SemEval-2024 Task 8, enhancing model training efficiency and accuracy through data augmentation and cleaning, evaluating various methods in monolingual task, and achieving a good ranking in multilingual settings."
}