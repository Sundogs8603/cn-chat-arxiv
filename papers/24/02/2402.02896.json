{
    "title": "LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models",
    "abstract": "While both agent interaction and personalisation are vibrant topics in research on large language models (LLMs), there has been limited focus on the effect of language interaction on the behaviour of persona-conditioned LLM agents. Such an endeavour is important to ensure that agents remain consistent to their assigned traits yet are able to engage in open, naturalistic dialogues. In our experiments, we condition GPT-3.5 on personality profiles through prompting and create a two-group population of LLM agents using a simple variability-inducing sampling algorithm. We then administer personality tests and submit the agents to a collaborative writing task, finding that different profiles exhibit different degrees of personality consistency and linguistic alignment to their conversational partners. Our study seeks to lay the groundwork for better understanding of dialogue-based interaction between LLMs and highlights the need for new approaches to crafting robust, more human-like LLM pers",
    "link": "https://arxiv.org/abs/2402.02896",
    "context": "Title: LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models\nAbstract: While both agent interaction and personalisation are vibrant topics in research on large language models (LLMs), there has been limited focus on the effect of language interaction on the behaviour of persona-conditioned LLM agents. Such an endeavour is important to ensure that agents remain consistent to their assigned traits yet are able to engage in open, naturalistic dialogues. In our experiments, we condition GPT-3.5 on personality profiles through prompting and create a two-group population of LLM agents using a simple variability-inducing sampling algorithm. We then administer personality tests and submit the agents to a collaborative writing task, finding that different profiles exhibit different degrees of personality consistency and linguistic alignment to their conversational partners. Our study seeks to lay the groundwork for better understanding of dialogue-based interaction between LLMs and highlights the need for new approaches to crafting robust, more human-like LLM pers",
    "path": "papers/24/02/2402.02896.json",
    "total_tokens": 995,
    "translated_title": "LLM智能体的相互作用：测量个性一致性和语言对齐在大规模语言模型相互作用中的贡献",
    "translated_abstract": "尽管智能体相互作用和个性化在大规模语言模型（LLMs）研究中都是热门话题，但对语言相互作用对于个性化的LLM智能体行为的影响的关注有限。这样的努力对于确保智能体在保持其指定特征的同时能够进行开放的自然对话非常重要。在我们的实验中，我们通过提示将GPT-3.5调节到个性化配置，并使用简单的变异性引导抽样算法创建了一个双组群的LLM智能体人口。然后我们进行个性化测试，并将智能体提交到协同写作任务，发现不同配置表现出不同程度的个性一致性和语言对齐。我们的研究旨在为更好地理解LLMs之间基于对话的相互作用奠定基础，并凸显了需要新的方法来打造更强大、更类人的LLM智能体的需求。",
    "tldr": "本研究通过对大规模语言模型进行个性化配置，并探究了智能体之间的对话交互对个性一致性和语言对齐的影响。研究结果表明不同配置对话者展示了不同程度的个性一致性和语言对齐。这些发现为进一步理解LLMs之间基于对话的相互作用提供了基础，并强调了打造更具鲁棒性和类人化LLM智能体的新方法的需求。",
    "en_tdlr": "This study investigates the impact of dialogue interaction on personality consistency and linguistic alignment between Large Language Models (LLMs), finding that different profiles exhibit varying degrees of consistency and alignment. The results lay the groundwork for understanding dialogue-based interactions among LLMs and highlight the need for new approaches to crafting robust and more human-like LLM agents."
}