{
    "title": "Spot Check Equivalence: an Interpretable Metric for Information Elicitation Mechanisms",
    "abstract": "arXiv:2402.13567v1 Announce Type: cross  Abstract: Because high-quality data is like oxygen for AI systems, effectively eliciting information from crowdsourcing workers has become a first-order problem for developing high-performance machine learning algorithms. Two prevalent paradigms, spot-checking and peer prediction, enable the design of mechanisms to evaluate and incentivize high-quality data from human labelers. So far, at least three metrics have been proposed to compare the performances of these techniques [33, 8, 3]. However, different metrics lead to divergent and even contradictory results in various contexts. In this paper, we harmonize these divergent stories, showing that two of these metrics are actually the same within certain contexts and explain the divergence of the third. Moreover, we unify these different contexts by introducing \\textit{Spot Check Equivalence}, which offers an interpretable metric for the effectiveness of a peer prediction mechanism. Finally, we pr",
    "link": "https://arxiv.org/abs/2402.13567",
    "context": "Title: Spot Check Equivalence: an Interpretable Metric for Information Elicitation Mechanisms\nAbstract: arXiv:2402.13567v1 Announce Type: cross  Abstract: Because high-quality data is like oxygen for AI systems, effectively eliciting information from crowdsourcing workers has become a first-order problem for developing high-performance machine learning algorithms. Two prevalent paradigms, spot-checking and peer prediction, enable the design of mechanisms to evaluate and incentivize high-quality data from human labelers. So far, at least three metrics have been proposed to compare the performances of these techniques [33, 8, 3]. However, different metrics lead to divergent and even contradictory results in various contexts. In this paper, we harmonize these divergent stories, showing that two of these metrics are actually the same within certain contexts and explain the divergence of the third. Moreover, we unify these different contexts by introducing \\textit{Spot Check Equivalence}, which offers an interpretable metric for the effectiveness of a peer prediction mechanism. Finally, we pr",
    "path": "papers/24/02/2402.13567.json",
    "total_tokens": 796,
    "translated_title": "Spot Check Equivalence：一个可解释的信息引出机制度量",
    "translated_abstract": "由于高质量数据对于AI系统如同氧气一般重要，有效地从众包工作者中引出信息已成为开发高性能机器学习算法的首要问题。两种普遍的范式，即点检查和同行预测，使得设计机制来评估和激励来自人类标注者的高质量数据成为可能。到目前为止，至少提出了三种指标来比较这些技术的性能。然而，不同的指标在不同背景下导致了分歧甚至矛盾的结果。本文将调和这些不同的故事，展示其中两个指标在某些背景下实际上是相同的，并解释第三个的分歧。此外，我们通过引入\"点检查等价性\"来统一这些不同的背景，为同行预测机制的有效性提供了一个可解释的度量。最后，我们提出...（未完）",
    "tldr": "提出了\"点检查等价性\"，为同行预测机制的效力提供了一个可解释的度量"
}