{
    "title": "eXplainable Bayesian Multi-Perspective Generative Retrieval",
    "abstract": "Modern deterministic retrieval pipelines prioritize achieving state-of-the-art performance but often lack interpretability in decision-making. These models face challenges in assessing uncertainty, leading to overconfident predictions. To overcome these limitations, we integrate uncertainty calibration and interpretability into a retrieval pipeline. Specifically, we introduce Bayesian methodologies and multi-perspective retrieval to calibrate uncertainty within a retrieval pipeline. We incorporate techniques such as LIME and SHAP to analyze the behavior of a black-box reranker model. The importance scores derived from these explanation methodologies serve as supplementary relevance scores to enhance the base reranker model. We evaluate the resulting performance enhancements achieved through uncertainty calibration and interpretable reranking on Question Answering and Fact Checking tasks. Our methods demonstrate substantial performance improvements across three KILT datasets.",
    "link": "https://arxiv.org/abs/2402.02418",
    "context": "Title: eXplainable Bayesian Multi-Perspective Generative Retrieval\nAbstract: Modern deterministic retrieval pipelines prioritize achieving state-of-the-art performance but often lack interpretability in decision-making. These models face challenges in assessing uncertainty, leading to overconfident predictions. To overcome these limitations, we integrate uncertainty calibration and interpretability into a retrieval pipeline. Specifically, we introduce Bayesian methodologies and multi-perspective retrieval to calibrate uncertainty within a retrieval pipeline. We incorporate techniques such as LIME and SHAP to analyze the behavior of a black-box reranker model. The importance scores derived from these explanation methodologies serve as supplementary relevance scores to enhance the base reranker model. We evaluate the resulting performance enhancements achieved through uncertainty calibration and interpretable reranking on Question Answering and Fact Checking tasks. Our methods demonstrate substantial performance improvements across three KILT datasets.",
    "path": "papers/24/02/2402.02418.json",
    "total_tokens": 850,
    "translated_title": "可解释的贝叶斯多透视生成检索",
    "translated_abstract": "现代确定性检索流水线注重实现最先进的性能，但在决策过程中通常缺乏可解释性。这些模型在评估不确定性时面临挑战，导致过于自信的预测。为了克服这些限制，我们将不确定性校准和可解释性整合到检索流程中。具体而言，我们引入了贝叶斯方法和多透视检索来校准检索流程中的不确定性。我们结合LIME和SHAP等技术来分析黑盒重排序模型的行为。从这些解释方法中得出的重要性分数作为补充相关性分数，以增强基础重排序模型。我们在问答和事实检验任务上评估通过不确定性校准和可解释性重排实现的性能提升。我们的方法在三个KILT数据集上展示出了明显的性能改善。",
    "tldr": "本文将不确定性校准和可解释性整合到一个检索流程中，通过引入贝叶斯方法和多透视检索来校准不确定性。使用解释方法分析黑盒模型行为，并将重要性分数作为补充相关性分数，提升基础模型性能。实验证明我们的方法在问答和事实检验任务上显著提高了性能。",
    "en_tdlr": "This paper integrates uncertainty calibration and interpretability into a retrieval pipeline by introducing Bayesian methodologies and multi-perspective retrieval, which improves performance on question answering and fact checking tasks through uncertainty calibration and interpretable reranking."
}