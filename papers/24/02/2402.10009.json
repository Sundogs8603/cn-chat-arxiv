{
    "title": "Zero-Shot Unsupervised and Text-Based Audio Editing Using DDPM Inversion",
    "abstract": "arXiv:2402.10009v1 Announce Type: cross  Abstract: Editing signals using large pre-trained models, in a zero-shot manner, has recently seen rapid advancements in the image domain. However, this wave has yet to reach the audio domain. In this paper, we explore two zero-shot editing techniques for audio signals, which use DDPM inversion on pre-trained diffusion models. The first, adopted from the image domain, allows text-based editing. The second, is a novel approach for discovering semantically meaningful editing directions without supervision. When applied to music signals, this method exposes a range of musically interesting modifications, from controlling the participation of specific instruments to improvisations on the melody. Samples can be found on our examples page in https://hilamanor.github.io/AudioEditing/ and code can be found in https://github.com/hilamanor/AudioEditing/ .",
    "link": "https://arxiv.org/abs/2402.10009",
    "context": "Title: Zero-Shot Unsupervised and Text-Based Audio Editing Using DDPM Inversion\nAbstract: arXiv:2402.10009v1 Announce Type: cross  Abstract: Editing signals using large pre-trained models, in a zero-shot manner, has recently seen rapid advancements in the image domain. However, this wave has yet to reach the audio domain. In this paper, we explore two zero-shot editing techniques for audio signals, which use DDPM inversion on pre-trained diffusion models. The first, adopted from the image domain, allows text-based editing. The second, is a novel approach for discovering semantically meaningful editing directions without supervision. When applied to music signals, this method exposes a range of musically interesting modifications, from controlling the participation of specific instruments to improvisations on the melody. Samples can be found on our examples page in https://hilamanor.github.io/AudioEditing/ and code can be found in https://github.com/hilamanor/AudioEditing/ .",
    "path": "papers/24/02/2402.10009.json",
    "total_tokens": 819,
    "translated_title": "使用DDPM反转进行零样本无监督和基于文本的音频编辑",
    "translated_abstract": "使用大型预训练模型进行零样本编辑已经在图像领域取得了迅猛的发展，但在音频领域尚未出现。本文中，我们探索了两种基于DDPM反转的音频信号零样本编辑技术。第一种是从图像领域采用的方法，允许基于文本进行编辑。第二种是一种新颖的方法，可以在无监督情况下发现语义上有意义的编辑方向。当应用于音乐信号时，这种方法可以展现出一系列具有音乐兴趣的修改，从控制特定乐器的参与到对旋律进行即兴演奏。示例可以在我们的例子页面中找到：https://hilamanor.github.io/AudioEditing/ ，代码可以在 https://github.com/hilamanor/AudioEditing/ 找到。",
    "tldr": "本文研究了使用DDPM反转进行音频信号的零样本编辑技术，包括基于文本的编辑和无监督发现编辑方向。这些方法在音乐信号中展现了多样的音乐兴趣修改。",
    "en_tdlr": "This paper explores zero-shot editing techniques for audio signals using DDPM inversion, including text-based editing and unsupervised discovery of editing directions. These methods expose a range of musically interesting modifications in music signals."
}