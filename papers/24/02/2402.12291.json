{
    "title": "KARL: Knowledge-Aware Retrieval and Representations aid Retention and Learning in Students",
    "abstract": "arXiv:2402.12291v1 Announce Type: new  Abstract: Flashcard schedulers are tools that rely on 1) student models to predict the flashcards a student knows; and 2) teaching policies to schedule cards based on these predictions. Existing student models, however, only use flashcard-level features, like the student's past responses, ignoring the semantic ties of flashcards. Deep Knowledge Tracing (DKT) models can capture semantic relations with language models, but are inefficient, lack content-rich datasets for evaluation, and require robust teaching policies. To address these issues, we design KARL, a DKT-inspired student model that uses retrieval and BERT embeddings for efficient and accurate student recall predictions. To test KARL, we collect a new dataset of diverse study history on trivia questions. KARL bests existing student models in AUC and calibration error. Finally, we propose a novel teaching policy that exploits the predictive power of DKT models to deploy KARL online. Based o",
    "link": "https://arxiv.org/abs/2402.12291",
    "context": "Title: KARL: Knowledge-Aware Retrieval and Representations aid Retention and Learning in Students\nAbstract: arXiv:2402.12291v1 Announce Type: new  Abstract: Flashcard schedulers are tools that rely on 1) student models to predict the flashcards a student knows; and 2) teaching policies to schedule cards based on these predictions. Existing student models, however, only use flashcard-level features, like the student's past responses, ignoring the semantic ties of flashcards. Deep Knowledge Tracing (DKT) models can capture semantic relations with language models, but are inefficient, lack content-rich datasets for evaluation, and require robust teaching policies. To address these issues, we design KARL, a DKT-inspired student model that uses retrieval and BERT embeddings for efficient and accurate student recall predictions. To test KARL, we collect a new dataset of diverse study history on trivia questions. KARL bests existing student models in AUC and calibration error. Finally, we propose a novel teaching policy that exploits the predictive power of DKT models to deploy KARL online. Based o",
    "path": "papers/24/02/2402.12291.json",
    "total_tokens": 955,
    "translated_title": "KARL: 知识感知检索和表示帮助学生保持和学习",
    "translated_abstract": "Flashcard调度器是依赖于学生模型来预测学生掌握的单词卡，并使用教学策略根据这些预测安排词卡的工具。现有的学生模型仅使用单词卡级别的特征，比如学生的过去回答，忽略了单词卡之间的语义联系。深度知识跟踪（DKT）模型可以利用语言模型捕捉语义关系，但效率低下，缺乏内容丰富的数据集用于评估，并需要稳健的教学策略。为了解决这些问题，我们设计了KARL，这是受DKT启发的学生模型，利用检索和BERT嵌入以实现高效准确的学生记忆预测。为了测试KARL，我们收集了一个包含广泛学习历史关于琐事问题的新数据集。KARL在AUC和校准误差方面胜过现有的学生模型。最后，我们提出了一个新颖的教学策略，利用DKT模型的预测能力在线部署KARL。",
    "tldr": "KARL是一种基于DKT的学生模型，利用检索和BERT嵌入来实现高效准确的学生记忆预测，在AUC和校准误差方面优于现有学生模型，并提出了新颖的教学策略。",
    "en_tdlr": "KARL is a student model based on DKT that utilizes retrieval and BERT embeddings for efficient and accurate student recall predictions, outperforming existing student models in terms of AUC and calibration error, and introduces a novel teaching policy."
}