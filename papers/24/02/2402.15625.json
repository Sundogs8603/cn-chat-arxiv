{
    "title": "Learning Cyclic Causal Models from Incomplete Data",
    "abstract": "arXiv:2402.15625v1 Announce Type: cross  Abstract: Causal learning is a fundamental problem in statistics and science, offering insights into predicting the effects of unseen treatments on a system. Despite recent advances in this topic, most existing causal discovery algorithms operate under two key assumptions: (i) the underlying graph is acyclic, and (ii) the available data is complete. These assumptions can be problematic as many real-world systems contain feedback loops (e.g., biological systems), and practical scenarios frequently involve missing data. In this work, we propose a novel framework, named MissNODAGS, for learning cyclic causal graphs from partially missing data. Under the additive noise model, MissNODAGS learns the causal graph by alternating between imputing the missing data and maximizing the expected log-likelihood of the visible part of the data in each training step, following the principles of the expectation-maximization (EM) framework. Through synthetic exper",
    "link": "https://arxiv.org/abs/2402.15625",
    "context": "Title: Learning Cyclic Causal Models from Incomplete Data\nAbstract: arXiv:2402.15625v1 Announce Type: cross  Abstract: Causal learning is a fundamental problem in statistics and science, offering insights into predicting the effects of unseen treatments on a system. Despite recent advances in this topic, most existing causal discovery algorithms operate under two key assumptions: (i) the underlying graph is acyclic, and (ii) the available data is complete. These assumptions can be problematic as many real-world systems contain feedback loops (e.g., biological systems), and practical scenarios frequently involve missing data. In this work, we propose a novel framework, named MissNODAGS, for learning cyclic causal graphs from partially missing data. Under the additive noise model, MissNODAGS learns the causal graph by alternating between imputing the missing data and maximizing the expected log-likelihood of the visible part of the data in each training step, following the principles of the expectation-maximization (EM) framework. Through synthetic exper",
    "path": "papers/24/02/2402.15625.json",
    "total_tokens": 866,
    "translated_title": "从不完整数据中学习循环因果模型",
    "translated_abstract": "因果学习是统计学和科学中的一个基本问题，它可以帮助预测未见治疗对系统的影响。尽管最近在这个领域取得了进展，但大多数现有的因果发现算法都基于两个关键假设：(i) 潜在图是无环的，(ii) 可用数据是完整的。这些假设可能存在问题，因为许多现实世界中的系统包含反馈环路（例如生物系统），实际情况经常涉及缺失数据。在这项工作中，我们提出了一个名为MissNODAGS的新框架，用于从部分缺失数据中学习循环因果图。在加性噪声模型下，MissNODAGS通过在每个训练步骤中在替补缺失数据与最大化数据可见部分的预期对数似然之间交替学习因果图，遵循期望最大化（EM）框架的原则。",
    "tldr": "提出了一个名为MissNODAGS的框架，可以从部分缺失数据中学习循环因果图，通过交替替补缺失数据和最大化可见数据部分的预期对数似然来学习因果图。"
}