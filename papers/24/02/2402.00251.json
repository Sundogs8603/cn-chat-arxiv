{
    "title": "Efficient Non-Parametric Uncertainty Quantification for Black-Box Large Language Models and Decision Planning",
    "abstract": "Step-by-step decision planning with large language models (LLMs) is gaining attention in AI agent development. This paper focuses on decision planning with uncertainty estimation to address the hallucination problem in language models. Existing approaches are either white-box or computationally demanding, limiting use of black-box proprietary LLMs within budgets. The paper's first contribution is a non-parametric uncertainty quantification method for LLMs, efficiently estimating point-wise dependencies between input-decision on the fly with a single inference, without access to token logits. This estimator informs the statistical interpretation of decision trustworthiness. The second contribution outlines a systematic design for a decision-making agent, generating actions like ``turn on the bathroom light'' based on user prompts such as ``take a bath''. Users will be asked to provide preferences when more than one action has high estimated point-wise dependencies. In conclusion, our un",
    "link": "https://arxiv.org/abs/2402.00251",
    "context": "Title: Efficient Non-Parametric Uncertainty Quantification for Black-Box Large Language Models and Decision Planning\nAbstract: Step-by-step decision planning with large language models (LLMs) is gaining attention in AI agent development. This paper focuses on decision planning with uncertainty estimation to address the hallucination problem in language models. Existing approaches are either white-box or computationally demanding, limiting use of black-box proprietary LLMs within budgets. The paper's first contribution is a non-parametric uncertainty quantification method for LLMs, efficiently estimating point-wise dependencies between input-decision on the fly with a single inference, without access to token logits. This estimator informs the statistical interpretation of decision trustworthiness. The second contribution outlines a systematic design for a decision-making agent, generating actions like ``turn on the bathroom light'' based on user prompts such as ``take a bath''. Users will be asked to provide preferences when more than one action has high estimated point-wise dependencies. In conclusion, our un",
    "path": "papers/24/02/2402.00251.json",
    "total_tokens": 1012,
    "translated_title": "高效的非参数化不确定性量化方法用于黑盒大型语言模型和决策规划",
    "translated_abstract": "大型语言模型(LLMs)的逐步决策规划在人工智能代理的发展中受到关注。本文主要研究带有不确定性估计的决策规划，以解决语言模型中的幻觉问题。现有方法要么是白盒方法，要么是计算复杂，限制了黑盒专有LLMs的使用。本文的第一个贡献是一种非参数化的LLMs不确定性量化方法，通过单一推理有效地估计输入-决策之间的逐点依赖关系，而不需要访问令牌logits。该估计器提供了对决策可信度的统计解释。第二个贡献是一个系统化的决策代理设计，根据用户提示如“打开浴室灯”，生成动作。当有多个动作的估计逐点依赖性都很高时，用户将被要求提供偏好。总结地说，我们的未参数化不确定性量化方法提供了一种高效的决策规划方法，可以在黑盒大型语言模型中应用。",
    "tldr": "本文提出了一种高效的非参数化不确定性量化方法，用于黑盒大型语言模型和决策规划。该方法可以有效地估计输入-决策之间的逐点依赖关系，并提供统计上对决策可信度的解释。另外，本文还提出了一个系统化的决策代理设计，根据用户提示生成动作，并在存在多个高估计逐点依赖性的动作时要求用户提供偏好。",
    "en_tdlr": "This paper proposes an efficient non-parametric uncertainty quantification method for black-box large language models and decision planning. The method effectively estimates the point-wise dependencies between input-decision and provides statistical interpretation of decision trustworthiness. Additionally, a systematic design for a decision-making agent is presented, generating actions based on user prompts and considering user preferences when multiple actions have high estimated point-wise dependencies."
}