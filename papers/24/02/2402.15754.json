{
    "title": "HD-Eval: Aligning Large Language Model Evaluators Through Hierarchical Criteria Decomposition",
    "abstract": "arXiv:2402.15754v1 Announce Type: new  Abstract: Large language models (LLMs) have emerged as a promising alternative to expensive human evaluations. However, the alignment and coverage of LLM-based evaluations are often limited by the scope and potential bias of the evaluation prompts and criteria. To address this challenge, we propose HD-Eval, a novel framework that iteratively aligns LLM-based evaluators with human preference via Hierarchical Criteria Decomposition. HD-Eval inherits the essence from the evaluation mindset of human experts and enhances the alignment of LLM-based evaluators by decomposing a given evaluation task into finer-grained criteria, aggregating them according to estimated human preferences, pruning insignificant criteria with attribution, and further decomposing significant criteria. By integrating these steps within an iterative alignment training process, we obtain a hierarchical decomposition of criteria that comprehensively captures aspects of natural lang",
    "link": "https://arxiv.org/abs/2402.15754",
    "context": "Title: HD-Eval: Aligning Large Language Model Evaluators Through Hierarchical Criteria Decomposition\nAbstract: arXiv:2402.15754v1 Announce Type: new  Abstract: Large language models (LLMs) have emerged as a promising alternative to expensive human evaluations. However, the alignment and coverage of LLM-based evaluations are often limited by the scope and potential bias of the evaluation prompts and criteria. To address this challenge, we propose HD-Eval, a novel framework that iteratively aligns LLM-based evaluators with human preference via Hierarchical Criteria Decomposition. HD-Eval inherits the essence from the evaluation mindset of human experts and enhances the alignment of LLM-based evaluators by decomposing a given evaluation task into finer-grained criteria, aggregating them according to estimated human preferences, pruning insignificant criteria with attribution, and further decomposing significant criteria. By integrating these steps within an iterative alignment training process, we obtain a hierarchical decomposition of criteria that comprehensively captures aspects of natural lang",
    "path": "papers/24/02/2402.15754.json",
    "total_tokens": 859,
    "translated_title": "HD-Eval: 通过分层标准分解对齐大型语言模型评估器",
    "translated_abstract": "大型语言模型(LLMs)已经成为昂贵人工评估的一个有前景的替代方案。然而，基于LLMs的评估的对齐和覆盖通常受到评估提示和标准的范围和潜在偏见的限制。为了解决这一挑战，我们提出HD-Eval，这是一个新颖的框架，通过分层标准分解迭代对齐LLM-based评估器与人类喜好。HD-Eval继承了人类专家评估心态的精髓，并通过将给定的评估任务分解为更精细的标准、根据估计的人类偏好聚合它们、通过归因修剪不显著的标准以及进一步分解显著的标准来增强LLM的评估器的对齐。通过在迭代对齐训练过程中集成这些步骤，我们获得了一个全面捕捉自然语言方面的标准的分层分解。",
    "tldr": "提出了一个名为HD-Eval的框架，通过分层标准分解来对齐大型语言模型评估器与人类偏好，从而提升评估效果。"
}