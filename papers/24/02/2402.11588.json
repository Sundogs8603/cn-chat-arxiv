{
    "title": "SDiT: Spiking Diffusion Model with Transformer",
    "abstract": "arXiv:2402.11588v1 Announce Type: cross  Abstract: Spiking neural networks (SNNs) have low power consumption and bio-interpretable characteristics, and are considered to have tremendous potential for energy-efficient computing. However, the exploration of SNNs on image generation tasks remains very limited, and a unified and effective structure for SNN-based generative models has yet to be proposed. In this paper, we explore a novel diffusion model architecture within spiking neural networks. We utilize transformer to replace the commonly used U-net structure in mainstream diffusion models. It can generate higher quality images with relatively lower computational cost and shorter sampling time. It aims to provide an empirical baseline for research of generative models based on SNNs. Experiments on MNIST, Fashion-MNIST, and CIFAR-10 datasets demonstrate that our work is highly competitive compared to existing SNN generative models.",
    "link": "https://arxiv.org/abs/2402.11588",
    "context": "Title: SDiT: Spiking Diffusion Model with Transformer\nAbstract: arXiv:2402.11588v1 Announce Type: cross  Abstract: Spiking neural networks (SNNs) have low power consumption and bio-interpretable characteristics, and are considered to have tremendous potential for energy-efficient computing. However, the exploration of SNNs on image generation tasks remains very limited, and a unified and effective structure for SNN-based generative models has yet to be proposed. In this paper, we explore a novel diffusion model architecture within spiking neural networks. We utilize transformer to replace the commonly used U-net structure in mainstream diffusion models. It can generate higher quality images with relatively lower computational cost and shorter sampling time. It aims to provide an empirical baseline for research of generative models based on SNNs. Experiments on MNIST, Fashion-MNIST, and CIFAR-10 datasets demonstrate that our work is highly competitive compared to existing SNN generative models.",
    "path": "papers/24/02/2402.11588.json",
    "total_tokens": 849,
    "translated_title": "带Transformer的脉冲扩散模型",
    "translated_abstract": "脉冲神经网络（SNNs）具有低功耗和生物解释特性，被认为在节能计算方面有巨大潜力。然而，在图像生成任务中探索SNNs的工作仍然非常有限，尚未提出基于SNN的生成模型的统一且有效的结构。本文探讨了脉冲神经网络中的一种新型扩散模型架构。我们利用Transformer来取代主流扩散模型中常用的U-net结构。它能够以相对较低的计算成本和较短的采样时间生成质量更高的图像。它旨在为基于SNN的生成模型研究提供实证基准。在MNIST、Fashion-MNIST和CIFAR-10数据集上的实验证明，我们的工作与现有的SNN生成模型相比具有很高的竞争力。",
    "tldr": "本文提出了一种新颖的脉冲扩散模型架构，通过在脉冲神经网络中利用Transformer取代U-net结构，在图像生成任务中取得了较高质量的图像，并提供了基于SNN的生成模型研究的实证基准。"
}