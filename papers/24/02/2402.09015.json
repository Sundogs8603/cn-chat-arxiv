{
    "title": "Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications",
    "abstract": "arXiv:2402.09015v1 Announce Type: cross Abstract: The rapid development in the field of Large Language Models (LLMs) has led to a surge in applications that facilitate collaboration among multiple agents to assist humans in their daily tasks. However, a significant gap remains in assessing whether LLM-powered applications genuinely enhance user experience and task execution efficiency. This highlights the pressing need for methods to verify utility of LLM-powered applications, particularly by ensuring alignment between the application's functionality and end-user needs. We introduce AgentEval provides an implementation for the math problems}, a novel framework designed to simplify the utility verification process by automatically proposing a set of criteria tailored to the unique purpose of any given application. This allows for a comprehensive assessment, quantifying the utility of an application against the suggested criteria. We present a comprehensive analysis of the robustness of ",
    "link": "https://arxiv.org/abs/2402.09015",
    "context": "Title: Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications\nAbstract: arXiv:2402.09015v1 Announce Type: cross Abstract: The rapid development in the field of Large Language Models (LLMs) has led to a surge in applications that facilitate collaboration among multiple agents to assist humans in their daily tasks. However, a significant gap remains in assessing whether LLM-powered applications genuinely enhance user experience and task execution efficiency. This highlights the pressing need for methods to verify utility of LLM-powered applications, particularly by ensuring alignment between the application's functionality and end-user needs. We introduce AgentEval provides an implementation for the math problems}, a novel framework designed to simplify the utility verification process by automatically proposing a set of criteria tailored to the unique purpose of any given application. This allows for a comprehensive assessment, quantifying the utility of an application against the suggested criteria. We present a comprehensive analysis of the robustness of ",
    "path": "papers/24/02/2402.09015.json",
    "total_tokens": 874,
    "translated_title": "朝着更好的人机对齐方向：评估LLM驱动应用中的任务效用",
    "translated_abstract": "大型语言模型（LLM）领域的快速发展导致了一系列应用的出现，这些应用通过协助多个代理人与人类合作，帮助人们完成日常任务。然而，目前仍存在一个重大问题，即如何评估LLM驱动应用是否真正提升用户体验和任务执行效率。这凸显了验证LLM驱动应用效用的方法的迫切需求，特别是要确保应用程序的功能与最终用户的需求相一致。我们引入了AgentEval，它提供了一个实施数学问题的估测模型，这是一个新的框架，旨在通过自动提出一套针对任何给定应用程序独特目标的评估标准，简化效用验证过程。这样可以对应用程序的效用进行全面评估，并量化其与建议标准相比的表现。我们对该框架的稳健性进行了全面的分析。",
    "tldr": "本研究引入了AgentEval框架，用于评估LLM驱动应用的任务效用。该框架通过自动提出一套针对特定应用的评估标准，简化了效用验证过程，并对应用的效用进行了全面量化分析。",
    "en_tdlr": "This study introduces the AgentEval framework for assessing the task utility of LLM-powered applications. The framework simplifies the utility verification process by automatically proposing tailored evaluation criteria and provides a comprehensive analysis of the utility of the applications."
}