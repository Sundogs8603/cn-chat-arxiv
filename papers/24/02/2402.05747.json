{
    "title": "Jacquard V2: Refining Datasets using the Human In the Loop Data Correction Method",
    "abstract": "In the context of rapid advancements in industrial automation, vision-based robotic grasping plays an increasingly crucial role. In order to enhance visual recognition accuracy, the utilization of large-scale datasets is imperative for training models to acquire implicit knowledge related to the handling of various objects. Creating datasets from scratch is a time and labor-intensive process. Moreover, existing datasets often contain errors due to automated annotations aimed at expediency, making the improvement of these datasets a substantial research challenge. Consequently, several issues have been identified in the annotation of grasp bounding boxes within the popular Jacquard Grasp. We propose utilizing a Human-In-The-Loop(HIL) method to enhance dataset quality. This approach relies on backbone deep learning networks to predict object positions and orientations for robotic grasping. Predictions with Intersection over Union (IOU) values below 0.2 undergo an assessment by human oper",
    "link": "https://arxiv.org/abs/2402.05747",
    "context": "Title: Jacquard V2: Refining Datasets using the Human In the Loop Data Correction Method\nAbstract: In the context of rapid advancements in industrial automation, vision-based robotic grasping plays an increasingly crucial role. In order to enhance visual recognition accuracy, the utilization of large-scale datasets is imperative for training models to acquire implicit knowledge related to the handling of various objects. Creating datasets from scratch is a time and labor-intensive process. Moreover, existing datasets often contain errors due to automated annotations aimed at expediency, making the improvement of these datasets a substantial research challenge. Consequently, several issues have been identified in the annotation of grasp bounding boxes within the popular Jacquard Grasp. We propose utilizing a Human-In-The-Loop(HIL) method to enhance dataset quality. This approach relies on backbone deep learning networks to predict object positions and orientations for robotic grasping. Predictions with Intersection over Union (IOU) values below 0.2 undergo an assessment by human oper",
    "path": "papers/24/02/2402.05747.json",
    "total_tokens": 836,
    "translated_title": "Jacquard V2: 使用人机交互数据纠错方法改进数据集",
    "translated_abstract": "在工业自动化快速发展的背景下，基于视觉的机器人抓取在其中扮演着越来越关键的角色。为了提升视觉识别准确性，利用大规模数据集对模型进行训练以获取与处理各种物体相关的隐式知识至关重要。从头开始创建数据集是一项耗时且劳动密集的过程。此外，现有数据集常常由于为了快速标注而产生错误，因此改善这些数据集是一个重要的研究挑战。因此，在流行的Jacquard Grasp中，已经确定了一些在抓取边界框注释中的问题。我们提出利用一种人机交互的方法来提高数据集质量。这种方法依赖于骨干深度学习网络来预测机器人抓取的物体位置和方向。与Intersection over Union（IOU）值低于0.2的预测经过人工操作员评估。",
    "tldr": "本论文提出了一种使用人机交互数据纠错方法来改进数据集质量的方案，以提升视觉识别准确性和优化视觉机器人抓取的性能。",
    "en_tdlr": "This paper proposes a Human-In-The-Loop(HIL) method to enhance dataset quality, aiming to improve visual recognition accuracy and optimize the performance of vision-based robotic grasping."
}