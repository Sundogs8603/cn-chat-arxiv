{
    "title": "Nature-Inspired Local Propagation",
    "abstract": "The spectacular results achieved in machine learning, including the recent advances in generative AI, rely on large data collections. On the opposite, intelligent processes in nature arises without the need for such collections, but simply by online processing of the environmental information. In particular, natural learning processes rely on mechanisms where data representation and learning are intertwined in such a way to respect spatiotemporal locality. This paper shows that such a feature arises from a pre-algorithmic view of learning that is inspired by related studies in Theoretical Physics. We show that the algorithmic interpretation of the derived \"laws of learning\", which takes the structure of Hamiltonian equations, reduces to Backpropagation when the speed of propagation goes to infinity. This opens the doors to machine learning studies based on full on-line information processing that are based the replacement of Backpropagation with the proposed spatiotemporal local algori",
    "link": "https://arxiv.org/abs/2402.05959",
    "context": "Title: Nature-Inspired Local Propagation\nAbstract: The spectacular results achieved in machine learning, including the recent advances in generative AI, rely on large data collections. On the opposite, intelligent processes in nature arises without the need for such collections, but simply by online processing of the environmental information. In particular, natural learning processes rely on mechanisms where data representation and learning are intertwined in such a way to respect spatiotemporal locality. This paper shows that such a feature arises from a pre-algorithmic view of learning that is inspired by related studies in Theoretical Physics. We show that the algorithmic interpretation of the derived \"laws of learning\", which takes the structure of Hamiltonian equations, reduces to Backpropagation when the speed of propagation goes to infinity. This opens the doors to machine learning studies based on full on-line information processing that are based the replacement of Backpropagation with the proposed spatiotemporal local algori",
    "path": "papers/24/02/2402.05959.json",
    "total_tokens": 895,
    "translated_title": "自然启发的局部传播",
    "translated_abstract": "机器学习中取得的令人瞩目的成果，包括最近在生成性人工智能方面的进展，都依赖于大量的数据集。相反，自然界中的智能过程并不需要这样的数据集，而只需通过对环境信息的在线处理即可产生。特别是，自然学习过程依赖于数据表示和学习相互交织以尊重时空局部性的机制。本文展示了这种特性来自于对学习的预算法视角，该视角受到了理论物理学相关研究的启发。我们展示了当传播速度趋于无穷大时，所得到的“学习法则”的算法解释（采用哈密顿方程结构）将归结为反向传播算法。这为基于全面在线信息处理的机器学习研究开辟了新的道路，其中反向传播算法被提出的时空局部算法取代。",
    "tldr": "本文介绍了一种自然启发的局部传播算法，该算法通过在线处理环境信息而不依赖大量数据集，在机器学习领域具有潜力。这种算法的核心思想是结合数据表示和学习，以尊重时空局部性，并且当传播速度趋近于无穷大时，它等效于反向传播算法。",
    "en_tdlr": "This paper introduces a nature-inspired local propagation algorithm, which has the potential in machine learning field by online processing of environmental information and not relying on large data collections. The algorithm combines data representation and learning to respect spatiotemporal locality, and it becomes equivalent to Backpropagation when the propagation speed goes to infinity."
}