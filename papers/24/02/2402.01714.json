{
    "title": "TrICy: Trigger-guided Data-to-text Generation with Intent aware Attention-Copy",
    "abstract": "Data-to-text (D2T) generation is a crucial task in many natural language understanding (NLU) applications and forms the foundation of task-oriented dialog systems. In the context of conversational AI solutions that can work directly with local data on the user's device, architectures utilizing large pre-trained language models (PLMs) are impractical for on-device deployment due to a high memory footprint. To this end, we propose TrICy, a novel lightweight framework for an enhanced D2T task that generates text sequences based on the intent in context and may further be guided by user-provided triggers. We leverage an attention-copy mechanism to predict out-of-vocabulary (OOV) words accurately. Performance analyses on E2E NLG dataset (BLEU: 66.43%, ROUGE-L: 70.14%), WebNLG dataset (BLEU: Seen 64.08%, Unseen 52.35%), and our Custom dataset related to text messaging applications, showcase our architecture's effectiveness. Moreover, we show that by leveraging an optional trigger input, data",
    "link": "https://arxiv.org/abs/2402.01714",
    "context": "Title: TrICy: Trigger-guided Data-to-text Generation with Intent aware Attention-Copy\nAbstract: Data-to-text (D2T) generation is a crucial task in many natural language understanding (NLU) applications and forms the foundation of task-oriented dialog systems. In the context of conversational AI solutions that can work directly with local data on the user's device, architectures utilizing large pre-trained language models (PLMs) are impractical for on-device deployment due to a high memory footprint. To this end, we propose TrICy, a novel lightweight framework for an enhanced D2T task that generates text sequences based on the intent in context and may further be guided by user-provided triggers. We leverage an attention-copy mechanism to predict out-of-vocabulary (OOV) words accurately. Performance analyses on E2E NLG dataset (BLEU: 66.43%, ROUGE-L: 70.14%), WebNLG dataset (BLEU: Seen 64.08%, Unseen 52.35%), and our Custom dataset related to text messaging applications, showcase our architecture's effectiveness. Moreover, we show that by leveraging an optional trigger input, data",
    "path": "papers/24/02/2402.01714.json",
    "total_tokens": 943,
    "translated_title": "TrICy: 通过意图感知的关注-复制机制引导的数据到文本生成",
    "translated_abstract": "数据到文本（D2T）生成是许多自然语言理解（NLU）应用中的关键任务，也是面向任务导向对话系统的基础。在可以直接与用户设备上的本地数据一起工作的会话型人工智能解决方案中，利用大型预训练语言模型（PLMs）的架构由于高内存占用而无法在设备上部署。为此，我们提出了TrICy，一种新颖的轻量级框架，用于增强D2T任务，根据上下文中的意图生成文本序列，并可进一步由用户提供的触发器进行引导。我们利用关注-复制机制准确地预测了词汇表之外的词汇（OOV）。对E2E NLG数据集（BLEU：66.43％，ROUGE-L：70.14％），WebNLG数据集（BLEU：Seen 64.08％，Unseen 52.35％）和与文本消息应用相关的自定义数据集的性能分析展示了我们的架构的有效性。此外，我们展示了通过利用可选的触发器输入，数据",
    "tldr": "TrICy是一种轻量级框架，利用意图和触发器引导数据到文本生成任务，并通过关注-复制机制有效地处理了词汇表之外的词汇。实验结果表明其在不同数据集上取得了良好的性能。"
}