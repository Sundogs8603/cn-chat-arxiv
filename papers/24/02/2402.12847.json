{
    "title": "Instruction-tuned Language Models are Better Knowledge Learners",
    "abstract": "arXiv:2402.12847v1 Announce Type: cross  Abstract: In order for large language model (LLM)-based assistants to effectively adapt to evolving information needs, it must be possible to update their factual knowledge through continued training on new data. The standard recipe for doing so involves continued pre-training on new documents followed by instruction-tuning on question-answer (QA) pairs. However, we find that LLMs trained with this recipe struggle to answer questions, even though the perplexity of documents is minimized. We found that QA pairs are generally straightforward, while documents are more complex, weaving many factual statements together in an intricate manner. Therefore, we hypothesize that it is beneficial to expose LLMs to QA pairs before continued pre-training on documents so that the process of encoding knowledge from complex documents takes into account how this knowledge is accessed through questions. Based on this, we propose pre-instruction-tuning (PIT), a met",
    "link": "https://arxiv.org/abs/2402.12847",
    "context": "Title: Instruction-tuned Language Models are Better Knowledge Learners\nAbstract: arXiv:2402.12847v1 Announce Type: cross  Abstract: In order for large language model (LLM)-based assistants to effectively adapt to evolving information needs, it must be possible to update their factual knowledge through continued training on new data. The standard recipe for doing so involves continued pre-training on new documents followed by instruction-tuning on question-answer (QA) pairs. However, we find that LLMs trained with this recipe struggle to answer questions, even though the perplexity of documents is minimized. We found that QA pairs are generally straightforward, while documents are more complex, weaving many factual statements together in an intricate manner. Therefore, we hypothesize that it is beneficial to expose LLMs to QA pairs before continued pre-training on documents so that the process of encoding knowledge from complex documents takes into account how this knowledge is accessed through questions. Based on this, we propose pre-instruction-tuning (PIT), a met",
    "path": "papers/24/02/2402.12847.json",
    "total_tokens": 648,
    "translated_title": "调整过的语言模型更好的知识学习者",
    "translated_abstract": "为了使基于大语言模型（LLM）的助手能够有效地适应不断发展的信息需求，必须能够通过持续在新数据上训练来更新它们的事实知识。传统做法涉及在新文档上持续预培训，然后根据问题-答案（QA）对进行指导调整。",
    "tldr": "通过在持续预训练文档之前暴露LLM到问题-答案对，以便从复杂文档中编码知识，可以更好地适应知识访问方式。"
}