{
    "title": "Real-World Fluid Directed Rigid Body Control via Deep Reinforcement Learning",
    "abstract": "Recent advances in real-world applications of reinforcement learning (RL) have relied on the ability to accurately simulate systems at scale. However, domains such as fluid dynamical systems exhibit complex dynamic phenomena that are hard to simulate at high integration rates, limiting the direct application of modern deep RL algorithms to often expensive or safety critical hardware. In this work, we introduce \"Box o Flows\", a novel benchtop experimental control system for systematically evaluating RL algorithms in dynamic real-world scenarios. We describe the key components of the Box o Flows, and through a series of experiments demonstrate how state-of-the-art model-free RL algorithms can synthesize a variety of complex behaviors via simple reward specifications. Furthermore, we explore the role of offline RL in data-efficient hypothesis testing by reusing past experiences. We believe that the insights gained from this preliminary study and the availability of systems like the Box o ",
    "link": "https://arxiv.org/abs/2402.06102",
    "context": "Title: Real-World Fluid Directed Rigid Body Control via Deep Reinforcement Learning\nAbstract: Recent advances in real-world applications of reinforcement learning (RL) have relied on the ability to accurately simulate systems at scale. However, domains such as fluid dynamical systems exhibit complex dynamic phenomena that are hard to simulate at high integration rates, limiting the direct application of modern deep RL algorithms to often expensive or safety critical hardware. In this work, we introduce \"Box o Flows\", a novel benchtop experimental control system for systematically evaluating RL algorithms in dynamic real-world scenarios. We describe the key components of the Box o Flows, and through a series of experiments demonstrate how state-of-the-art model-free RL algorithms can synthesize a variety of complex behaviors via simple reward specifications. Furthermore, we explore the role of offline RL in data-efficient hypothesis testing by reusing past experiences. We believe that the insights gained from this preliminary study and the availability of systems like the Box o ",
    "path": "papers/24/02/2402.06102.json",
    "total_tokens": 902,
    "translated_title": "通过深度强化学习实现真实世界流体引导刚体控制",
    "translated_abstract": "最近在强化学习（RL）的真实世界应用中取得的进展依赖于能够准确模拟大规模系统的能力。然而，像流体动力学系统这样的领域展示了复杂的动态现象，很难以高积分速率进行模拟，从而限制了现代深度RL算法在昂贵或安全关键硬件上的直接应用。在这项工作中，我们引入了“流体盒子（Box o Flows）”，这是一个新颖的台式实验控制系统，用于在动态真实世界场景中系统地评估RL算法。我们描述了流体盒子的关键组件，并通过一系列实验展示了最先进的无模型RL算法如何通过简单的奖励规范合成各种复杂行为。此外，我们还探索了离线RL在数据高效假设测试中的作用，通过重用过去的经验。我们相信，从这项初步研究中获得的见解以及流体盒子等系统的可用性将推动RL在真实世界中的应用。",
    "tldr": "通过创建流体盒子实验控制系统，我们展示了在真实世界场景中使用深度强化学习算法合成复杂行为的能力，并探索了离线强化学习在数据高效假设测试中的潜力。",
    "en_tdlr": "By creating the Box o Flows experimental control system, we demonstrate the capability of using deep reinforcement learning algorithms to synthesize complex behaviors in real-world scenarios and explore the potential of offline reinforcement learning in data-efficient hypothesis testing."
}