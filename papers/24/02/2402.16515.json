{
    "title": "LLM-based Privacy Data Augmentation Guided by Knowledge Distillation with a Distribution Tutor for Medical Text Classification",
    "abstract": "arXiv:2402.16515v1 Announce Type: new  Abstract: As sufficient data are not always publically accessible for model training, researchers exploit limited data with advanced learning algorithms or expand the dataset via data augmentation (DA). Conducting DA in private domain requires private protection approaches (i.e. anonymization and perturbation), but those methods cannot provide protection guarantees. Differential privacy (DP) learning methods theoretically bound the protection but are not skilled at generating pseudo text samples with large models. In this paper, we transfer DP-based pseudo sample generation task to DP-based generated samples discrimination task, where we propose a DP-based DA method with a LLM and a DP-based discriminator for text classification on private domains. We construct a knowledge distillation model as the DP-based discriminator: teacher models, accessing private data, teaches students how to select private samples with calibrated noise to achieve DP. To ",
    "link": "https://arxiv.org/abs/2402.16515",
    "context": "Title: LLM-based Privacy Data Augmentation Guided by Knowledge Distillation with a Distribution Tutor for Medical Text Classification\nAbstract: arXiv:2402.16515v1 Announce Type: new  Abstract: As sufficient data are not always publically accessible for model training, researchers exploit limited data with advanced learning algorithms or expand the dataset via data augmentation (DA). Conducting DA in private domain requires private protection approaches (i.e. anonymization and perturbation), but those methods cannot provide protection guarantees. Differential privacy (DP) learning methods theoretically bound the protection but are not skilled at generating pseudo text samples with large models. In this paper, we transfer DP-based pseudo sample generation task to DP-based generated samples discrimination task, where we propose a DP-based DA method with a LLM and a DP-based discriminator for text classification on private domains. We construct a knowledge distillation model as the DP-based discriminator: teacher models, accessing private data, teaches students how to select private samples with calibrated noise to achieve DP. To ",
    "path": "papers/24/02/2402.16515.json",
    "total_tokens": 921,
    "translated_title": "基于LLM和分布导师的知识蒸馏引导下的隐私数据增强用于医学文本分类",
    "translated_abstract": "随着模型训练的数据并非始终公开可访问，研究人员利用先进的学习算法利用有限的数据或通过数据增强（DA）来扩展数据集。在私有领域进行DA需要隐私保护方法（如匿名化和扰动），但这些方法无法提供保护保证。差分隐私（DP）学习方法在理论上限制保护，但不擅长使用大模型生成伪文本样本。在本文中，我们将基于DP的伪样本生成任务转移为基于DP生成样本鉴别任务，提出了一种带LLM和基于DP鉴别器的DP-based DA方法，用于私有领域的文本分类。我们构建了一个知识蒸馏模型作为基于DP的鉴别器：教师模型访问私有数据，教导学生如何选择具有校准噪声的私有样本以实现DP。",
    "tldr": "提出一种基于LLM和分布导师的知识蒸馏引导下的隐私数据增强方法，用于医学文本分类，将DP-based伪样本生成任务转移到DP-based生成样本鉴别任务，通过教师模型教导学生如何选择带有校准噪声的私有样本以实现差分隐私。",
    "en_tdlr": "Proposed a privacy data augmentation method guided by LLM and a distribution tutor for medical text classification, transferring the task of DP-based pseudo sample generation to DP-based generated samples discrimination task, where teacher models instruct students on selecting private samples with calibrated noise for achieving differential privacy."
}