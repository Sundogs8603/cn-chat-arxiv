{
    "title": "OLMo: Accelerating the Science of Language Models",
    "abstract": "Language models (LMs) have become ubiquitous in both NLP research and in commercial product offerings. As their commercial importance has surged, the most powerful models have become closed off, gated behind proprietary interfaces, with important details of their training data, architectures, and development undisclosed. Given the importance of these details in scientifically studying these models, including their biases and potential risks, we believe it is essential for the research community to have access to powerful, truly open LMs. To this end, this technical report details the first release of OLMo, a state-of-the-art, truly Open Language Model and its framework to build and study the science of language modeling. Unlike most prior efforts that have only released model weights and inference code, we release OLMo and the whole framework, including training data and training and evaluation code. We hope this release will empower and strengthen the open research community and inspi",
    "link": "https://arxiv.org/abs/2402.00838",
    "context": "Title: OLMo: Accelerating the Science of Language Models\nAbstract: Language models (LMs) have become ubiquitous in both NLP research and in commercial product offerings. As their commercial importance has surged, the most powerful models have become closed off, gated behind proprietary interfaces, with important details of their training data, architectures, and development undisclosed. Given the importance of these details in scientifically studying these models, including their biases and potential risks, we believe it is essential for the research community to have access to powerful, truly open LMs. To this end, this technical report details the first release of OLMo, a state-of-the-art, truly Open Language Model and its framework to build and study the science of language modeling. Unlike most prior efforts that have only released model weights and inference code, we release OLMo and the whole framework, including training data and training and evaluation code. We hope this release will empower and strengthen the open research community and inspi",
    "path": "papers/24/02/2402.00838.json",
    "total_tokens": 801,
    "translated_title": "OLMo: 加速语言模型科学",
    "translated_abstract": "语言模型（LM）已广泛应用于自然语言处理研究和商业产品。随着商业重要性的增加，最强大的模型已经封闭起来，只能通过专有接口访问，其训练数据、架构和开发细节没有透露。考虑到这些细节对于科学研究这些模型的重要性，包括其偏见和潜在风险，我们认为研究社区有权访问强大而真正开放的LM。为此，本技术报告详细介绍了OLMo的首个版本，这是一种最先进、真正开放的语言模型，以及构建和研究语言建模科学的框架。与之前只发布模型权重和推理代码的努力不同，我们发布OLMo和整个框架，包括训练数据、训练和评估代码。我们希望这个发布能增强开放研究社区的能力，并激发更多的创新。",
    "tldr": "OLMo是一种真正开放的语言模型，旨在提供给研究社区强大的工具，以促进对语言模型科学的研究和创新。"
}