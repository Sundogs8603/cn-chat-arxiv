{
    "title": "Optimal Parameter and Neuron Pruning for Out-of-Distribution Detection",
    "abstract": "arXiv:2402.10062v1 Announce Type: new  Abstract: For a machine learning model deployed in real world scenarios, the ability of detecting out-of-distribution (OOD) samples is indispensable and challenging. Most existing OOD detection methods focused on exploring advanced training skills or training-free tricks to prevent the model from yielding overconfident confidence score for unknown samples. The training-based methods require expensive training cost and rely on OOD samples which are not always available, while most training-free methods can not efficiently utilize the prior information from the training data. In this work, we propose an \\textbf{O}ptimal \\textbf{P}arameter and \\textbf{N}euron \\textbf{P}runing (\\textbf{OPNP}) approach, which aims to identify and remove those parameters and neurons that lead to over-fitting. The main method is divided into two steps. In the first step, we evaluate the sensitivity of the model parameters and neurons by averaging gradients over all train",
    "link": "https://arxiv.org/abs/2402.10062",
    "context": "Title: Optimal Parameter and Neuron Pruning for Out-of-Distribution Detection\nAbstract: arXiv:2402.10062v1 Announce Type: new  Abstract: For a machine learning model deployed in real world scenarios, the ability of detecting out-of-distribution (OOD) samples is indispensable and challenging. Most existing OOD detection methods focused on exploring advanced training skills or training-free tricks to prevent the model from yielding overconfident confidence score for unknown samples. The training-based methods require expensive training cost and rely on OOD samples which are not always available, while most training-free methods can not efficiently utilize the prior information from the training data. In this work, we propose an \\textbf{O}ptimal \\textbf{P}arameter and \\textbf{N}euron \\textbf{P}runing (\\textbf{OPNP}) approach, which aims to identify and remove those parameters and neurons that lead to over-fitting. The main method is divided into two steps. In the first step, we evaluate the sensitivity of the model parameters and neurons by averaging gradients over all train",
    "path": "papers/24/02/2402.10062.json",
    "total_tokens": 871,
    "translated_title": "用于识别未知分布的最优参数和神经元剪枝方法",
    "translated_abstract": "对于在现实场景中部署的机器学习模型，识别未知分布（OOD）样本的能力是不可或缺且具有挑战性的。大多数已有的OOD检测方法关注于探索高级训练技巧或训练无关的技巧，以防止模型对未知样本产生过于自信的置信度分数。基于训练的方法需要昂贵的训练成本，并且依赖于并非始终可用的OOD样本，而大多数基于训练无关的方法无法有效利用训练数据的先验信息。在这项工作中，我们提出了一种名为OPNP（Optimal Parameter and Neuron Pruning）的方法，旨在识别并删除导致过度拟合的参数和神经元。主要方法分为两个步骤。在第一步中，我们通过对所有训练样本进行梯度平均来评估模型参数和神经元的敏感性。",
    "tldr": "提出了一种用于识别未知分布的最优参数和神经元剪枝方法（OPNP），通过评估模型参数和神经元的敏感性来解决OOD检测的问题。",
    "en_tdlr": "Proposed an optimal parameter and neuron pruning (OPNP) approach for detecting out-of-distribution samples, which evaluates the sensitivity of model parameters and neurons to address the challenge of OOD detection."
}