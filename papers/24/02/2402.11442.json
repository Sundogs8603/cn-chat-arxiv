{
    "title": "Can LLMs Reason with Rules? Logic Scaffolding for Stress-Testing and Improving LLMs",
    "abstract": "arXiv:2402.11442v1 Announce Type: new  Abstract: Large language models (LLMs) have achieved impressive human-like performance across various reasoning tasks. However, their mastery of underlying inferential rules still falls short of human capabilities. To investigate this, we propose a logic scaffolding inferential rule generation framework, to construct an inferential rule base, ULogic, comprising both primitive and compositional rules across five domains. Our analysis of GPT-series models over a rule subset reveals significant gaps in LLMs' logic understanding compared to human performance, especially in compositional and structural complex rules with certain bias patterns. We further distill these rules into a smaller-scale inference engine for flexible rule generation and enhancing downstream reasoning. Through a multi-judger evaluation, our inference engine proves effective in generating accurate, complex and abstract conclusions and premises, and improve various commonsense reas",
    "link": "https://arxiv.org/abs/2402.11442",
    "context": "Title: Can LLMs Reason with Rules? Logic Scaffolding for Stress-Testing and Improving LLMs\nAbstract: arXiv:2402.11442v1 Announce Type: new  Abstract: Large language models (LLMs) have achieved impressive human-like performance across various reasoning tasks. However, their mastery of underlying inferential rules still falls short of human capabilities. To investigate this, we propose a logic scaffolding inferential rule generation framework, to construct an inferential rule base, ULogic, comprising both primitive and compositional rules across five domains. Our analysis of GPT-series models over a rule subset reveals significant gaps in LLMs' logic understanding compared to human performance, especially in compositional and structural complex rules with certain bias patterns. We further distill these rules into a smaller-scale inference engine for flexible rule generation and enhancing downstream reasoning. Through a multi-judger evaluation, our inference engine proves effective in generating accurate, complex and abstract conclusions and premises, and improve various commonsense reas",
    "path": "papers/24/02/2402.11442.json",
    "total_tokens": 932,
    "translated_title": "能够与规则进行推理吗？逻辑支架用于压力测试和提升LLM",
    "translated_abstract": "大型语言模型(LLMs)在各种推理任务中取得了令人印象深刻的接近人类表现的成绩。然而，它们对于基础推理规则的掌握仍然不及人类能力。为了研究这一问题，我们提出了一个逻辑支架推理规则生成框架，构建了一个包含五个领域中基础和组合规则的推理规则库ULogic。我们对GPT系列模型在规则子集上的分析揭示出LLMs在逻辑理解方面与人类表现存在显著差距，特别是在具有某些偏见模式的组合和结构复杂规则中。我们进一步将这些规则提炼成一个更小规模的推理引擎，用于灵活地生成规则并增强下游推理。通过多评估人员评估，我们的推理引擎证明在生成准确、复杂和抽象的结论和前提方面表现出效果，可以改善各种常识推理。",
    "tldr": "提出了一个逻辑支架推理规则生成框架，通过构建包含基础和组合规则的推理规则库ULogic，揭示了LLMs在逻辑理解方面与人类表现的显著差距，并通过生成准确、复杂和抽象的推理结果来提升下游推理。"
}