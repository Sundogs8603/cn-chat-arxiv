{
    "title": "Label-Efficient Model Selection for Text Generation",
    "abstract": "Model selection for a given target task can be costly, as it may entail extensive annotation of the quality of outputs of different models. We introduce DiffUse, an efficient method to make an informed decision between candidate text generation models. DiffUse reduces the required amount of preference annotations, thus saving valuable time and resources in performing evaluation. DiffUse intelligently selects instances by clustering embeddings that represent the semantic differences between model outputs. Thus, it is able to identify a subset of examples that are more informative for preference decisions. Our method is model-agnostic, and can be applied to any text generation model. Moreover, we propose a practical iterative approach for dynamically determining how many instances to annotate. In a series of experiments over hundreds of model pairs, we demonstrate that DiffUse can dramatically reduce the required number of annotations -- by up to 75% -- while maintaining high evaluation ",
    "link": "https://arxiv.org/abs/2402.07891",
    "context": "Title: Label-Efficient Model Selection for Text Generation\nAbstract: Model selection for a given target task can be costly, as it may entail extensive annotation of the quality of outputs of different models. We introduce DiffUse, an efficient method to make an informed decision between candidate text generation models. DiffUse reduces the required amount of preference annotations, thus saving valuable time and resources in performing evaluation. DiffUse intelligently selects instances by clustering embeddings that represent the semantic differences between model outputs. Thus, it is able to identify a subset of examples that are more informative for preference decisions. Our method is model-agnostic, and can be applied to any text generation model. Moreover, we propose a practical iterative approach for dynamically determining how many instances to annotate. In a series of experiments over hundreds of model pairs, we demonstrate that DiffUse can dramatically reduce the required number of annotations -- by up to 75% -- while maintaining high evaluation ",
    "path": "papers/24/02/2402.07891.json",
    "total_tokens": 816,
    "translated_title": "标注效率高的文本生成模型选择",
    "translated_abstract": "针对给定目标任务的模型选择可能成本高昂，因为它可能需要对不同模型输出的质量进行广泛的注释。我们引入了DiffUse，一种有效的方法来在候选文本生成模型之间做出明智的决策。DiffUse减少了所需的偏好注释数量，从而节省了在评估中宝贵的时间和资源。DiffUse通过聚类表示模型输出之间的语义差异的嵌入来智能选择实例。因此，它能够识别出一些更有信息量的例子来进行偏好决策。我们的方法与模型无关，可以应用于任何文本生成模型。此外，我们提出了一种实用的迭代方法来动态确定要注释的实例数量。通过对数百个模型对进行一系列实验，我们证明了DiffUse可以显著减少所需的注释数量，最多可减少75%，同时保持高评估水平。",
    "tldr": "DiffUse是一种标注效率高的文本生成模型选择方法，它通过聚类文本语义差异的嵌入来选择更具信息量的实例，并能显著减少所需的注释数量。",
    "en_tdlr": "DiffUse is a label-efficient method for model selection in text generation. It intelligently selects informative instances based on clustered embeddings of semantic differences between model outputs, reducing the required amount of annotations by up to 75%."
}