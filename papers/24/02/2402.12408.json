{
    "title": "ModelGPT: Unleashing LLM's Capabilities for Tailored Model Generation",
    "abstract": "arXiv:2402.12408v1 Announce Type: cross  Abstract: The rapid advancement of Large Language Models (LLMs) has revolutionized various sectors by automating routine tasks, marking a step toward the realization of Artificial General Intelligence (AGI). However, they still struggle to accommodate the diverse and specific needs of users and simplify the utilization of AI models for the average user. In response, we propose ModelGPT, a novel framework designed to determine and generate AI models specifically tailored to the data or task descriptions provided by the user, leveraging the capabilities of LLMs. Given user requirements, ModelGPT is able to provide tailored models at most 270x faster than the previous paradigms (e.g. all-parameter or LoRA finetuning). Comprehensive experiments on NLP, CV, and Tabular datasets attest to the effectiveness of our framework in making AI models more accessible and user-friendly. Our code is available at https://github.com/IshiKura-a/ModelGPT.",
    "link": "https://arxiv.org/abs/2402.12408",
    "context": "Title: ModelGPT: Unleashing LLM's Capabilities for Tailored Model Generation\nAbstract: arXiv:2402.12408v1 Announce Type: cross  Abstract: The rapid advancement of Large Language Models (LLMs) has revolutionized various sectors by automating routine tasks, marking a step toward the realization of Artificial General Intelligence (AGI). However, they still struggle to accommodate the diverse and specific needs of users and simplify the utilization of AI models for the average user. In response, we propose ModelGPT, a novel framework designed to determine and generate AI models specifically tailored to the data or task descriptions provided by the user, leveraging the capabilities of LLMs. Given user requirements, ModelGPT is able to provide tailored models at most 270x faster than the previous paradigms (e.g. all-parameter or LoRA finetuning). Comprehensive experiments on NLP, CV, and Tabular datasets attest to the effectiveness of our framework in making AI models more accessible and user-friendly. Our code is available at https://github.com/IshiKura-a/ModelGPT.",
    "path": "papers/24/02/2402.12408.json",
    "total_tokens": 858,
    "translated_title": "ModelGPT：释放LLM的能力，为定制模型生成铺平道路",
    "translated_abstract": "大型语言模型（LLM）的快速发展通过自动化例行任务，标志着迈向人工通用智能（AGI）的实现迈出了一步，革新了各个行业。然而，它们仍然难以满足用户的多样化和特定需求，也难以简化AI模型对普通用户的利用。因此，我们提出了ModelGPT，这是一个新颖的框架，旨在根据用户提供的数据或任务描述来确定和生成特定定制的AI模型，利用了LLM的能力。ModelGPT能够根据用户需求提供的模型，比之前的范式（例如全参数或LoRA微调）快至多270倍。在NLP、CV和表格数据集上进行的全面实验证明了我们的框架在使AI模型更易访问和用户友好方面的效果。我们的代码可在 https://github.com/IshiKura-a/ModelGPT 找到。",
    "tldr": "ModelGPT是一个新颖的框架，通过利用LLM的能力，根据用户提供的数据或任务描述生成定制化的AI模型，让用户能够更快速和方便地使用AI模型。"
}