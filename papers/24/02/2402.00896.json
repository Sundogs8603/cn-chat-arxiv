{
    "title": "Privacy and Security Implications of Cloud-Based AI Services : A Survey",
    "abstract": "This paper details the privacy and security landscape in today's cloud ecosystem and identifies that there is a gap in addressing the risks introduced by machine learning models. As machine learning algorithms continue to evolve and find applications across diverse domains, the need to categorize and quantify privacy and security risks becomes increasingly critical. With the emerging trend of AI-as-a-Service (AIaaS), machine learned AI models (or ML models) are deployed on the cloud by model providers and used by model consumers. We first survey the AIaaS landscape to document the various kinds of liabilities that ML models, especially Deep Neural Networks pose and then introduce a taxonomy to bridge this gap by holistically examining the risks that creators and consumers of ML models are exposed to and their known defences till date. Such a structured approach will be beneficial for ML model providers to create robust solutions. Likewise, ML model consumers will find it valuable to ev",
    "link": "https://rss.arxiv.org/abs/2402.00896",
    "context": "Title: Privacy and Security Implications of Cloud-Based AI Services : A Survey\nAbstract: This paper details the privacy and security landscape in today's cloud ecosystem and identifies that there is a gap in addressing the risks introduced by machine learning models. As machine learning algorithms continue to evolve and find applications across diverse domains, the need to categorize and quantify privacy and security risks becomes increasingly critical. With the emerging trend of AI-as-a-Service (AIaaS), machine learned AI models (or ML models) are deployed on the cloud by model providers and used by model consumers. We first survey the AIaaS landscape to document the various kinds of liabilities that ML models, especially Deep Neural Networks pose and then introduce a taxonomy to bridge this gap by holistically examining the risks that creators and consumers of ML models are exposed to and their known defences till date. Such a structured approach will be beneficial for ML model providers to create robust solutions. Likewise, ML model consumers will find it valuable to ev",
    "path": "papers/24/02/2402.00896.json",
    "total_tokens": 931,
    "translated_title": "云基础人工智能服务的隐私和安全影响：一项调查",
    "translated_abstract": "本文详细介绍了当前云生态系统中的隐私和安全状况，并指出了机器学习模型引入风险的不足之处。随着机器学习算法不断发展并在各个领域应用，对隐私和安全风险进行分类和量化的需求变得越来越关键。随着AI作为服务(AIaaS)的新趋势出现，机器学习AI模型被模型提供者部署在云端，并被模型使用者使用。我们首先对AIaaS领域进行调查，记录了机器学习模型，特别是深度神经网络所引起的各种责任，并引入一个分类法来全面研究创造者和使用者所面临的风险及其已知的防御手段。这种结构化的方法对于机器学习模型提供者创建强大的解决方案将会很有益处。同样，机器学习模型的消费者也会发现它对于评估AI模型的隐私和安全风险很有价值。",
    "tldr": "本文调查了云基础人工智能服务的隐私和安全状况，发现机器学习模型引入的风险亟待解决。通过提出分类法来全面研究模型提供者和使用者所面临的风险及其防御手段，有助于创建强大的解决方案。"
}