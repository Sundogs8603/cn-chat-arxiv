{
    "title": "Few-Shot Fairness: Unveiling LLM's Potential for Fairness-Aware Classification",
    "abstract": "arXiv:2402.18502v1 Announce Type: new  Abstract: Employing Large Language Models (LLM) in various downstream applications such as classification is crucial, especially for smaller companies lacking the expertise and resources required for fine-tuning a model. Fairness in LLMs helps ensure inclusivity, equal representation based on factors such as race, gender and promotes responsible AI deployment. As the use of LLMs has become increasingly prevalent, it is essential to assess whether LLMs can generate fair outcomes when subjected to considerations of fairness. In this study, we introduce a framework outlining fairness regulations aligned with various fairness definitions, with each definition being modulated by varying degrees of abstraction. We explore the configuration for in-context learning and the procedure for selecting in-context demonstrations using RAG, while incorporating fairness rules into the process. Experiments conducted with different LLMs indicate that GPT-4 delivers ",
    "link": "https://arxiv.org/abs/2402.18502",
    "context": "Title: Few-Shot Fairness: Unveiling LLM's Potential for Fairness-Aware Classification\nAbstract: arXiv:2402.18502v1 Announce Type: new  Abstract: Employing Large Language Models (LLM) in various downstream applications such as classification is crucial, especially for smaller companies lacking the expertise and resources required for fine-tuning a model. Fairness in LLMs helps ensure inclusivity, equal representation based on factors such as race, gender and promotes responsible AI deployment. As the use of LLMs has become increasingly prevalent, it is essential to assess whether LLMs can generate fair outcomes when subjected to considerations of fairness. In this study, we introduce a framework outlining fairness regulations aligned with various fairness definitions, with each definition being modulated by varying degrees of abstraction. We explore the configuration for in-context learning and the procedure for selecting in-context demonstrations using RAG, while incorporating fairness rules into the process. Experiments conducted with different LLMs indicate that GPT-4 delivers ",
    "path": "papers/24/02/2402.18502.json",
    "total_tokens": 833,
    "translated_title": "少样本公平性：揭示LLM在公平意识分类中的潜力",
    "translated_abstract": "使用大型语言模型（LLM）在各种下游应用中进行分类是至关重要的，尤其对于缺乏对模型进行微调所需的专业知识和资源的小型公司而言。 LLM中的公平性有助于确保包容性，基于种族、性别等因素实现平等代表，并促进负责任的AI部署。随着LLM的使用日益普及，评估LLM在考虑公平性时能否产生公平的结果至关重要。 在这项研究中，我们引入了一个框架，概述了与各种公平定义对齐的公平法规，每个定义都由不同程度的抽象调节。 我们探讨了基于RAG的上下文学习配置和选择上下文演示的程序，并将公平规则纳入其中。对不同LLM进行的实验表明，GPT-4提供",
    "tldr": "本研究在公平性定义上引入了一个框架，探讨了LLM在公平性考虑下的生成公平结果的方法，包含对上下文学习配置和演示选择的探索。",
    "en_tdlr": "This study introduces a framework for fairness regulations aligned with various definitions, exploring how LLMs can generate fair outcomes under considerations of fairness including experimentation with in-context learning configurations and demonstration selection."
}