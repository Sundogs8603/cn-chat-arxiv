{
    "title": "XTSFormer: Cross-Temporal-Scale Transformer for Irregular Time Event Prediction",
    "abstract": "Event prediction aims to forecast the time and type of a future event based on a historical event sequence. Despite its significance, several challenges exist, including the irregularity of time intervals between consecutive events, the existence of cycles, periodicity, and multi-scale event interactions, as well as the high computational costs for long event sequences. Existing neural temporal point processes (TPPs) methods do not capture the multi-scale nature of event interactions, which is common in many real-world applications such as clinical event data. To address these issues, we propose the cross-temporal-scale transformer (XTSFormer), designed specifically for irregularly timed event data. Our model comprises two vital components: a novel Feature-based Cycle-aware Time Positional Encoding (FCPE) that adeptly captures the cyclical nature of time, and a hierarchical multi-scale temporal attention mechanism. These scales are determined by a bottom-up clustering algorithm. Extens",
    "link": "https://arxiv.org/abs/2402.02258",
    "context": "Title: XTSFormer: Cross-Temporal-Scale Transformer for Irregular Time Event Prediction\nAbstract: Event prediction aims to forecast the time and type of a future event based on a historical event sequence. Despite its significance, several challenges exist, including the irregularity of time intervals between consecutive events, the existence of cycles, periodicity, and multi-scale event interactions, as well as the high computational costs for long event sequences. Existing neural temporal point processes (TPPs) methods do not capture the multi-scale nature of event interactions, which is common in many real-world applications such as clinical event data. To address these issues, we propose the cross-temporal-scale transformer (XTSFormer), designed specifically for irregularly timed event data. Our model comprises two vital components: a novel Feature-based Cycle-aware Time Positional Encoding (FCPE) that adeptly captures the cyclical nature of time, and a hierarchical multi-scale temporal attention mechanism. These scales are determined by a bottom-up clustering algorithm. Extens",
    "path": "papers/24/02/2402.02258.json",
    "total_tokens": 879,
    "translated_title": "XTSFormer: 跨时空尺度的Transformer用于不规则时间事件预测",
    "translated_abstract": "事件预测旨在基于历史事件序列预测未来事件的时间和类型。尽管其重要性，但存在几个挑战，包括连续事件之间时间间隔的不规则性、循环、周期性和多尺度事件交互，以及长事件序列的高计算成本。现有的神经时间点过程（TPP）方法不能捕捉事件交互的多尺度特性，而这在许多实际应用中（如临床事件数据）很常见。为了解决这些问题，我们提出了跨时空尺度的Transformer（XTSFormer），特别适用于不规则时间事件数据。我们的模型包含两个关键组成部分：一种新颖的基于特征的循环感知时间位置编码（FCPE），能够灵活捕捉时间的循环性质，以及一个分层的多尺度时间注意机制。这些尺度由自底向上的聚类算法确定。",
    "tldr": "XTSFormer是一个用于不规则时间事件预测的跨时空尺度的Transformer模型，通过新颖的循环感知时间位置编码和分层的多尺度时间注意机制来解决不规则时间间隔、循环、周期性和多尺度事件交互等挑战。"
}