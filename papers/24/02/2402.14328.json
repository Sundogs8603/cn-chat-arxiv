{
    "title": "Understanding and Patching Compositional Reasoning in LLMs",
    "abstract": "arXiv:2402.14328v1 Announce Type: new  Abstract: LLMs have marked a revolutonary shift, yet they falter when faced with compositional reasoning tasks. Our research embarks on a quest to uncover the root causes of compositional reasoning failures of LLMs, uncovering that most of them stem from the improperly generated or leveraged implicit reasoning results. Inspired by our empirical findings, we resort to Logit Lens and an intervention experiment to dissect the inner hidden states of LLMs. This deep dive reveals that implicit reasoning results indeed surface within middle layers and play a causative role in shaping the final explicit reasoning results. Our exploration further locates multi-head self-attention (MHSA) modules within these layers, which emerge as the linchpins in accurate generation and leveraing of implicit reasoning results. Grounded on the above findings, we develop CREME, a lightweight method to patch errors in compositional reasoning via editing the located MHSA modu",
    "link": "https://arxiv.org/abs/2402.14328",
    "context": "Title: Understanding and Patching Compositional Reasoning in LLMs\nAbstract: arXiv:2402.14328v1 Announce Type: new  Abstract: LLMs have marked a revolutonary shift, yet they falter when faced with compositional reasoning tasks. Our research embarks on a quest to uncover the root causes of compositional reasoning failures of LLMs, uncovering that most of them stem from the improperly generated or leveraged implicit reasoning results. Inspired by our empirical findings, we resort to Logit Lens and an intervention experiment to dissect the inner hidden states of LLMs. This deep dive reveals that implicit reasoning results indeed surface within middle layers and play a causative role in shaping the final explicit reasoning results. Our exploration further locates multi-head self-attention (MHSA) modules within these layers, which emerge as the linchpins in accurate generation and leveraing of implicit reasoning results. Grounded on the above findings, we develop CREME, a lightweight method to patch errors in compositional reasoning via editing the located MHSA modu",
    "path": "papers/24/02/2402.14328.json",
    "total_tokens": 766,
    "translated_title": "理解和修补LLMs中的组成推理",
    "translated_abstract": "LLMs 在推理任务中遇到困难，本研究通过 Logit Lens 和干预实验深入研究了LLMs的内部隐藏状态，发现多数推理失败源自于不正确生成或利用的隐性推理结果。我们的研究揭示了隐性推理结果在中间层中的出现，并对最终显式推理结果的形成起到因果作用。我们的探索进一步发现了 MHSA 模块在这些层中的存在，成为准确生成和利用隐性推理结果的关键。基于以上发现，我们开发了 CREME，一种轻量级方法，通过编辑位于的 MHSA 模块来修补组合推理中的错误。",
    "tldr": "本研究通过 Logit Lens 和干预实验揭示了LLMs中隐性推理结果的重要性，开发了一种修补组合推理错误的轻量级方法。",
    "en_tdlr": "This research uncovers the importance of implicit reasoning results in LLMs through Logit Lens and intervention experiments, and develops a lightweight method to patch errors in compositional reasoning."
}