{
    "title": "A Curious Case of Searching for the Correlation between Training Data and Adversarial Robustness of Transformer Textual Models",
    "abstract": "arXiv:2402.11469v1 Announce Type: cross  Abstract: Existing works have shown that fine-tuned textual transformer models achieve state-of-the-art prediction performances but are also vulnerable to adversarial text perturbations. Traditional adversarial evaluation is often done \\textit{only after} fine-tuning the models and ignoring the training data. In this paper, we want to prove that there is also a strong correlation between training data and model robustness. To this end, we extract 13 different features representing a wide range of input fine-tuning corpora properties and use them to predict the adversarial robustness of the fine-tuned models. Focusing mostly on encoder-only transformer models BERT and RoBERTa with additional results for BART, ELECTRA and GPT2, we provide diverse evidence to support our argument. First, empirical analyses show that (a) extracted features can be used with a lightweight classifier such as Random Forest to effectively predict the attack success rate ",
    "link": "https://arxiv.org/abs/2402.11469",
    "context": "Title: A Curious Case of Searching for the Correlation between Training Data and Adversarial Robustness of Transformer Textual Models\nAbstract: arXiv:2402.11469v1 Announce Type: cross  Abstract: Existing works have shown that fine-tuned textual transformer models achieve state-of-the-art prediction performances but are also vulnerable to adversarial text perturbations. Traditional adversarial evaluation is often done \\textit{only after} fine-tuning the models and ignoring the training data. In this paper, we want to prove that there is also a strong correlation between training data and model robustness. To this end, we extract 13 different features representing a wide range of input fine-tuning corpora properties and use them to predict the adversarial robustness of the fine-tuned models. Focusing mostly on encoder-only transformer models BERT and RoBERTa with additional results for BART, ELECTRA and GPT2, we provide diverse evidence to support our argument. First, empirical analyses show that (a) extracted features can be used with a lightweight classifier such as Random Forest to effectively predict the attack success rate ",
    "path": "papers/24/02/2402.11469.json",
    "total_tokens": 863,
    "translated_title": "在搜索训练数据与Transformer文本模型对抗性稳健性之间的相关性时的一个有趣案例",
    "translated_abstract": "现有研究表明，经过微调的文本Transformer模型可以实现最先进的预测性能，但也容易受到对抗文本扰动的影响。传统的对抗性评估通常在对模型进行微调之后才进行，忽略了训练数据。本文旨在证明训练数据和模型鲁棒性之间也存在着强关联。为此，我们提取了代表广泛输入微调语料库属性的13种不同特征，并用它们来预测经过微调的模型的对抗性稳健性。我们主要关注仅编码器的Transformer模型BERT和RoBERTa，并附加了BART、ELECTRA和GPT2的其他结果，为我们的论点提供多样的证据。首先，经验证明，(a)提取的特征可与轻量级分类器（如随机森林）一起有效地预测攻击成功率。",
    "tldr": "本文研究了训练数据与模型鲁棒性之间的相关性，并提出通过提取不同特征来预测Transformer文本模型的对抗性稳健性的方法。"
}