{
    "title": "A generalized decision tree ensemble based on the NeuralNetworks architecture: Distributed Gradient Boosting Forest (DGBF)",
    "abstract": "Tree ensemble algorithms as RandomForest and GradientBoosting are currently the dominant methods for modeling discrete or tabular data, however, they are unable to perform a hierarchical representation learning from raw data as NeuralNetworks does thanks to its multi-layered structure, which is a key feature for DeepLearning problems and modeling unstructured data. This limitation is due to the fact that tree algorithms can not be trained with back-propagation because of their mathematical nature. However, in this work, we demonstrate that the mathematical formulation of bagging and boosting can be combined together to define a graph-structured-tree-ensemble algorithm with a distributed representation learning process between trees naturally (without using back-propagation). We call this novel approach Distributed Gradient Boosting Forest (DGBF) and we demonstrate that both RandomForest and GradientBoosting can be expressed as particular graph architectures of DGBT. Finally, we see tha",
    "link": "https://arxiv.org/abs/2402.03386",
    "context": "Title: A generalized decision tree ensemble based on the NeuralNetworks architecture: Distributed Gradient Boosting Forest (DGBF)\nAbstract: Tree ensemble algorithms as RandomForest and GradientBoosting are currently the dominant methods for modeling discrete or tabular data, however, they are unable to perform a hierarchical representation learning from raw data as NeuralNetworks does thanks to its multi-layered structure, which is a key feature for DeepLearning problems and modeling unstructured data. This limitation is due to the fact that tree algorithms can not be trained with back-propagation because of their mathematical nature. However, in this work, we demonstrate that the mathematical formulation of bagging and boosting can be combined together to define a graph-structured-tree-ensemble algorithm with a distributed representation learning process between trees naturally (without using back-propagation). We call this novel approach Distributed Gradient Boosting Forest (DGBF) and we demonstrate that both RandomForest and GradientBoosting can be expressed as particular graph architectures of DGBT. Finally, we see tha",
    "path": "papers/24/02/2402.03386.json",
    "total_tokens": 894,
    "translated_title": "基于神经网络结构的通用决策树集成：分布式梯度提升森林（DGBF）",
    "translated_abstract": "目前，随机森林和梯度提升是建模离散或表格数据的主要方法，然而，由于它们的数学特性，无法像神经网络那样从原始数据中进行分层表示学习，这是深度学习问题和建模非结构化数据的关键特征。然而，在本文中，我们证明了包和提升的数学公式可以合并在一起，定义一个图结构的树集成算法，并在树之间自然地进行分布式表示学习过程（无需使用反向传播）。我们将这种新颖的方法称为分布式梯度提升森林（DGBF），并证明了随机森林和梯度提升都可以表示为DGBF的特定图结构。最后，我们发现...（摘要截断）",
    "tldr": "本文提出了一种基于神经网络结构的通用决策树集成算法，分布式梯度提升森林（DGBF），通过将包和提升的数学公式结合起来，实现了树之间自然地进行分布式表示学习过程。该算法能够处理离散或表格数据，并具有建模非结构化数据的能力。",
    "en_tdlr": "This paper proposes a generalized decision tree ensemble algorithm, Distributed Gradient Boosting Forest (DGBF), based on the neural network architecture. By combining the mathematical formulation of bagging and boosting, this algorithm enables a distributed representation learning process among trees naturally. It can handle discrete or tabular data and model unstructured data."
}