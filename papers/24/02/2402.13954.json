{
    "title": "Measuring Social Biases in Masked Language Models by Proxy of Prediction Quality",
    "abstract": "arXiv:2402.13954v1 Announce Type: new  Abstract: Social and political scientists often aim to discover and measure distinct biases from text data representations (embeddings). Innovative transformer-based language models produce contextually-aware token embeddings and have achieved state-of-the-art performance for a variety of natural language tasks, but have been shown to encode unwanted biases for downstream applications. In this paper, we evaluate the social biases encoded by transformers trained with the masked language modeling objective using proposed proxy functions within an iterative masking experiment to measure the quality of transformer models' predictions, and assess the preference of MLMs towards disadvantaged and advantaged groups. We compare bias estimations with those produced by other evaluation methods using two benchmark datasets, finding relatively high religious and disability biases across considered MLMs and low gender bias in one dataset relative to the other. ",
    "link": "https://arxiv.org/abs/2402.13954",
    "context": "Title: Measuring Social Biases in Masked Language Models by Proxy of Prediction Quality\nAbstract: arXiv:2402.13954v1 Announce Type: new  Abstract: Social and political scientists often aim to discover and measure distinct biases from text data representations (embeddings). Innovative transformer-based language models produce contextually-aware token embeddings and have achieved state-of-the-art performance for a variety of natural language tasks, but have been shown to encode unwanted biases for downstream applications. In this paper, we evaluate the social biases encoded by transformers trained with the masked language modeling objective using proposed proxy functions within an iterative masking experiment to measure the quality of transformer models' predictions, and assess the preference of MLMs towards disadvantaged and advantaged groups. We compare bias estimations with those produced by other evaluation methods using two benchmark datasets, finding relatively high religious and disability biases across considered MLMs and low gender bias in one dataset relative to the other. ",
    "path": "papers/24/02/2402.13954.json",
    "total_tokens": 888,
    "translated_title": "通过预测质量间接测量掩盖语言模型中的社会偏见",
    "translated_abstract": "社会和政治科学家经常旨在从文本数据表示（嵌入）中发现和衡量不同的偏见。创新的基于转换器的语言模型生成具有上下文感知的令牌嵌入，并在各种自然语言任务中取得了最先进的性能，但已被证明在下游应用中编码了不需要的偏见。本文通过提出的代理函数在迭代屏蔽实验中评估由训练有遮蔽语言建模目标的转换器所编码的社会偏见，以测量转换器模型预测质量，并评估MLM对不利群体和有利群体的偏好。我们比较使用两个基准数据集的偏见估计与其他评估方法产生的偏见，发现考虑的MLMs中存在相对较高的宗教和残疾偏见，而相对于另一个数据集，一个数据集中存在较低的性别偏见。",
    "tldr": "本文通过提出的代理函数在迭代屏蔽实验中评估了转换器模型所编码的社会偏见，并比较了其与其他评估方法的偏见估计，发现转换器模型中存在相对较高的宗教和残疾偏见，而性别偏见则相对较低。"
}