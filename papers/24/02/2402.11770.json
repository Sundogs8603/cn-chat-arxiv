{
    "title": "Structured Chain-of-Thought Prompting for Few-Shot Generation of Content-Grounded QA Conversations",
    "abstract": "arXiv:2402.11770v1 Announce Type: new  Abstract: We introduce a structured chain-of-thought (SCoT) prompting approach to generating content-grounded multi-turn question-answer conversations using a pre-trained large language model (LLM). At the core of our proposal is a structured breakdown of the complex task into a number of states in a state machine, so that actions corresponding to various subtasks, e.g., content reading and utterance generation, can be executed in their own dedicated states. Each state leverages a unique set of resources including prompts and (optionally) additional tools to augment the generation process. Our experimental results show that SCoT prompting with designated states for hallucination mitigation increases agent faithfulness to grounding documents by up to 16.8%. When used as training data, our open-domain conversations synthesized from only 6 Wikipedia-based seed demonstrations train strong conversational QA agents; in out-of-domain evaluation, for exam",
    "link": "https://arxiv.org/abs/2402.11770",
    "context": "Title: Structured Chain-of-Thought Prompting for Few-Shot Generation of Content-Grounded QA Conversations\nAbstract: arXiv:2402.11770v1 Announce Type: new  Abstract: We introduce a structured chain-of-thought (SCoT) prompting approach to generating content-grounded multi-turn question-answer conversations using a pre-trained large language model (LLM). At the core of our proposal is a structured breakdown of the complex task into a number of states in a state machine, so that actions corresponding to various subtasks, e.g., content reading and utterance generation, can be executed in their own dedicated states. Each state leverages a unique set of resources including prompts and (optionally) additional tools to augment the generation process. Our experimental results show that SCoT prompting with designated states for hallucination mitigation increases agent faithfulness to grounding documents by up to 16.8%. When used as training data, our open-domain conversations synthesized from only 6 Wikipedia-based seed demonstrations train strong conversational QA agents; in out-of-domain evaluation, for exam",
    "path": "papers/24/02/2402.11770.json",
    "total_tokens": 839,
    "translated_title": "面向少样本生成的内容相关问答对话结构化思维启发",
    "translated_abstract": "我们引入了一种结构化思维链（SCoT）提示方法，使用预训练的大型语言模型（LLM）生成基于内容的多轮问答对话。我们的提议的核心是将复杂任务结构化分解为状态机中的多个状态，以便执行对应于各种子任务（例如内容阅读和话语生成）的动作。每个状态利用一组独特的资源，包括提示和（可选）额外工具以增强生成过程。我们的实验结果表明，对于幻觉减轻，使用具有指定状态的SCoT提示可以使对接地文档的代理忠诚度提高高达16.8％。当用作训练数据时，仅从6个基于维基百科的种子示范合成的开放域对话训练出强大的对话问答代理程序；在领域外评估中，",
    "tldr": "使用结构化思维链提示的方法，在少样本情况下生成内容相关的问答对话，提高了代理程序对基础文档的忠诚度，训练强大的对话问答代理。"
}