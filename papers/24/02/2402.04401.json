{
    "title": "Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning",
    "abstract": "Personalization in large language models (LLMs) is increasingly important, aiming to align LLM's interactions, content, and recommendations with individual user preferences. Recent advances in LLM personalization have spotlighted effective prompt design, by enriching user queries with non-parametric knowledge through behavior history retrieval and textual profiles. However, these approaches were limited due to a lack of model ownership, resulting in constrained customization and privacy issues. Moreover, they often failed to accurately capture user behavior patterns, especially in cases where user data were complex and dynamic. To address these shortcomings, we introduce One PEFT Per User (OPPU), which employs personalized parameter-efficient fine-tuning (PEFT) modules, to store user-specific behavior patterns and preferences. By plugging in users' personal PEFT parameters, they can own and use their LLMs personally. OPPU integrates parametric user knowledge in the personal PEFT parame",
    "link": "https://arxiv.org/abs/2402.04401",
    "context": "Title: Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning\nAbstract: Personalization in large language models (LLMs) is increasingly important, aiming to align LLM's interactions, content, and recommendations with individual user preferences. Recent advances in LLM personalization have spotlighted effective prompt design, by enriching user queries with non-parametric knowledge through behavior history retrieval and textual profiles. However, these approaches were limited due to a lack of model ownership, resulting in constrained customization and privacy issues. Moreover, they often failed to accurately capture user behavior patterns, especially in cases where user data were complex and dynamic. To address these shortcomings, we introduce One PEFT Per User (OPPU), which employs personalized parameter-efficient fine-tuning (PEFT) modules, to store user-specific behavior patterns and preferences. By plugging in users' personal PEFT parameters, they can own and use their LLMs personally. OPPU integrates parametric user knowledge in the personal PEFT parame",
    "path": "papers/24/02/2402.04401.json",
    "total_tokens": 849,
    "translated_title": "通过个性化参数高效调整实现大规模语言模型的民主化",
    "translated_abstract": "大规模语言模型（LLM）中的个性化越来越重要，旨在使LLM的交互、内容和推荐与个体用户偏好相一致。最近LLM个性化的进展聚焦于有效的提示设计，通过使用行为历史检索和文本概要等非参数化知识丰富用户查询。然而，由于缺乏模型所有权，这些方法受到了一定的限制，导致定制能力和隐私问题。此外，在复杂和动态用户数据的情况下，它们通常无法准确捕捉用户行为模式。为了解决这些缺点，我们引入了一种名为OPPU的方法，它采用个性化参数高效调整（PEFT）模块来存储用户特定的行为模式和偏好。通过插入用户的个人PEFT参数，他们可以拥有和使用他们的LLM。",
    "tldr": "这项研究通过个性化参数高效调整模块（PEFT）实现了大规模语言模型（LLM）的民主化，使用户能够拥有和使用他们自己的LLM，解决了传统方法中的定制能力和隐私问题。",
    "en_tdlr": "This research democratizes large language models (LLMs) by introducing personalized parameter-efficient fine-tuning (PEFT) modules, allowing users to own and use their own LLMs, and addressing issues of customization and privacy in traditional approaches."
}