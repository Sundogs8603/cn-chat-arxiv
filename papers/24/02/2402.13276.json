{
    "title": "When LLMs Meets Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection",
    "abstract": "arXiv:2402.13276v1 Announce Type: cross  Abstract: Depression is a critical concern in global mental health, prompting extensive research into AI-based detection methods. Among various AI technologies, Large Language Models (LLMs) stand out for their versatility in mental healthcare applications. However, their primary limitation arises from their exclusive dependence on textual input, which constrains their overall capabilities. Furthermore, the utilization of LLMs in identifying and analyzing depressive states is still relatively untapped. In this paper, we present an innovative approach to integrating acoustic speech information into the LLMs framework for multimodal depression detection. We investigate an efficient method for depression detection by integrating speech signals into LLMs utilizing Acoustic Landmarks. By incorporating acoustic landmarks, which are specific to the pronunciation of spoken words, our method adds critical dimensions to text transcripts. This integration a",
    "link": "https://arxiv.org/abs/2402.13276",
    "context": "Title: When LLMs Meets Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection\nAbstract: arXiv:2402.13276v1 Announce Type: cross  Abstract: Depression is a critical concern in global mental health, prompting extensive research into AI-based detection methods. Among various AI technologies, Large Language Models (LLMs) stand out for their versatility in mental healthcare applications. However, their primary limitation arises from their exclusive dependence on textual input, which constrains their overall capabilities. Furthermore, the utilization of LLMs in identifying and analyzing depressive states is still relatively untapped. In this paper, we present an innovative approach to integrating acoustic speech information into the LLMs framework for multimodal depression detection. We investigate an efficient method for depression detection by integrating speech signals into LLMs utilizing Acoustic Landmarks. By incorporating acoustic landmarks, which are specific to the pronunciation of spoken words, our method adds critical dimensions to text transcripts. This integration a",
    "path": "papers/24/02/2402.13276.json",
    "total_tokens": 830,
    "translated_title": "当LLMs遇到声学标志：一种高效地将语音集成到大型语言模型中用于抑郁检测的方法",
    "translated_abstract": "抑郁是全球心理健康中的一个严重关切，促使进行大量研究来探讨基于AI的检测方法。在各种AI技术中，大型语言模型（LLMs）因其在心理卫生应用中的多功能性而脱颖而出。然而，它们的主要局限性在于它们仅依赖于文本输入，这限制了它们的整体功能。此外，LLMs在识别和分析抑郁状态方面的利用仍相对未开发。在本文中，我们提出了一种创新方法，将声学语音信息集成到LLMs框架中，以用于多模式抑郁检测。我们研究了一种通过利用声学标志将语音信号集成到LLMs中的高效抑郁检测方法。通过整合声学标志，这些标志是特定于口语单词发音的，我们的方法为文本转录添加了关键维度。",
    "tldr": "本文提出了一种创新方法，将声学语音信息集成到LLMs框架中，以用于多模式抑郁检测。",
    "en_tdlr": "This paper presents an innovative approach to integrating acoustic speech information into the LLMs framework for multimodal depression detection."
}