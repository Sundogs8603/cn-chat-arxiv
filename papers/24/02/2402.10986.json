{
    "title": "FinTral: A Family of GPT-4 Level Multimodal Financial Large Language Models",
    "abstract": "arXiv:2402.10986v1 Announce Type: cross  Abstract: We introduce FinTral, a suite of state-of-the-art multimodal large language models (LLMs) built upon the Mistral-7b model and tailored for financial analysis. FinTral integrates textual, numerical, tabular, and image data. We enhance FinTral with domain-specific pretraining, instruction fine-tuning, and RLAIF training by exploiting a large collection of textual and visual datasets we curate for this work. We also introduce an extensive benchmark featuring nine tasks and 25 datasets for evaluation, including hallucinations in the financial domain. Our FinTral model trained with direct preference optimization employing advanced Tools and Retrieval methods, dubbed FinTral-DPO-T&R, demonstrates an exceptional zero-shot performance. It outperforms ChatGPT-3.5 in all tasks and surpasses GPT-4 in five out of nine tasks, marking a significant advancement in AI-driven financial technology. We also demonstrate that FinTral has the potential to e",
    "link": "https://arxiv.org/abs/2402.10986",
    "context": "Title: FinTral: A Family of GPT-4 Level Multimodal Financial Large Language Models\nAbstract: arXiv:2402.10986v1 Announce Type: cross  Abstract: We introduce FinTral, a suite of state-of-the-art multimodal large language models (LLMs) built upon the Mistral-7b model and tailored for financial analysis. FinTral integrates textual, numerical, tabular, and image data. We enhance FinTral with domain-specific pretraining, instruction fine-tuning, and RLAIF training by exploiting a large collection of textual and visual datasets we curate for this work. We also introduce an extensive benchmark featuring nine tasks and 25 datasets for evaluation, including hallucinations in the financial domain. Our FinTral model trained with direct preference optimization employing advanced Tools and Retrieval methods, dubbed FinTral-DPO-T&R, demonstrates an exceptional zero-shot performance. It outperforms ChatGPT-3.5 in all tasks and surpasses GPT-4 in five out of nine tasks, marking a significant advancement in AI-driven financial technology. We also demonstrate that FinTral has the potential to e",
    "path": "papers/24/02/2402.10986.json",
    "total_tokens": 937,
    "translated_title": "FinTral：一类GPT-4级别的多模态金融大型语言模型",
    "translated_abstract": "我们引入FinTral，这是一组基于Mistral-7b模型构建的一流多模态大型语言模型（LLMs），专门为金融分析定制。FinTral整合了文本、数字、表格和图像数据。我们通过利用为本研究策划的大量文本和视觉数据集，通过领域特定的预训练、指导微调和RLAIF训练增强了FinTral。我们还介绍了一个包含九个任务和25个数据集进行评估的广泛基准测试，其中包括金融领域的幻觉。我们的FinTral模型，通过采用先进的工具和检索方法进行直接偏好优化训练，命名为FinTral-DPO-T&R，展现了出色的零-shot性能。它在所有任务中均优于ChatGPT-3.5，并在九项任务中的五项中超越GPT-4，标志着人工智能驱动的金融技术的重要进步。我们还展示了FinTral具有潜力",
    "tldr": "FinTral是一类基于Mistral-7b模型的GPT-4级别多模态金融大型语言模型，通过领域特定的预训练和检索方法优化，在AI驱动金融技术中取得显著进展。"
}