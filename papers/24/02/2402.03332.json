{
    "title": "Cyclic Neural Network",
    "abstract": "This paper answers a fundamental question in artificial neural network (ANN) design: We do not need to build ANNs layer-by-layer sequentially to guarantee the Directed Acyclic Graph (DAG) property. Drawing inspiration from biological intelligence (BI), where neurons form a complex, graph-structured network, we introduce the groundbreaking Cyclic Neural Networks (Cyclic NNs). It emulates the flexible and dynamic graph nature of biological neural systems, allowing neuron connections in any graph-like structure, including cycles. This offers greater adaptability compared to the DAG structure of current ANNs. We further develop the Graph Over Multi-layer Perceptron, which is the first detailed model based on this new design paradigm. Experimental validation of the Cyclic NN's advantages on widely tested datasets in most generalized cases, demonstrating its superiority over current BP training methods through the use of a forward-forward (FF) training algorithm. This research illustrates a ",
    "link": "https://arxiv.org/abs/2402.03332",
    "context": "Title: Cyclic Neural Network\nAbstract: This paper answers a fundamental question in artificial neural network (ANN) design: We do not need to build ANNs layer-by-layer sequentially to guarantee the Directed Acyclic Graph (DAG) property. Drawing inspiration from biological intelligence (BI), where neurons form a complex, graph-structured network, we introduce the groundbreaking Cyclic Neural Networks (Cyclic NNs). It emulates the flexible and dynamic graph nature of biological neural systems, allowing neuron connections in any graph-like structure, including cycles. This offers greater adaptability compared to the DAG structure of current ANNs. We further develop the Graph Over Multi-layer Perceptron, which is the first detailed model based on this new design paradigm. Experimental validation of the Cyclic NN's advantages on widely tested datasets in most generalized cases, demonstrating its superiority over current BP training methods through the use of a forward-forward (FF) training algorithm. This research illustrates a ",
    "path": "papers/24/02/2402.03332.json",
    "total_tokens": 856,
    "translated_title": "循环神经网络",
    "translated_abstract": "本文回答了人工神经网络（ANN）设计中的一个基本问题：我们不需要按顺序逐层构建ANN来保证有向无环图（DAG）属性。受生物智能（BI）的启发，其中神经元形成了一个复杂的、图形结构的网络，我们引入了具有开创性意义的循环神经网络（Cyclic NNs）。它模拟了生物神经系统灵活动态的图形特性，允许神经元在包括环路在内的任何图形结构中进行连接。与当前ANN的DAG结构相比，这提供了更大的适应性。我们进一步发展了基于这种新设计范 paradigm的首个详细模型——图覆盖多层感知机。通过在广泛测试的数据集上进行实验证明了循环神经网络在大多数一般情况下的优势，通过使用前向训练算法（FF）证明了它相对于当前的BP训练方法的优越性。这项研究阐述了循环神经网络的创新和贡献。",
    "tldr": "本文介绍了一种具有创新性的循环神经网络（Cyclic NNs），可以模拟生物智能系统的灵活动态图形特性，并在广泛测试的数据集上验证了其优越性。",
    "en_tdlr": "This paper introduces a groundbreaking Cyclic Neural Network (Cyclic NNs) that emulates the flexible and dynamic graph nature of biological neural systems, demonstrating its superiority on widely tested datasets."
}