{
    "title": "Generalizability Under Sensor Failure: Tokenization + Transformers Enable More Robust Latent Spaces",
    "abstract": "arXiv:2402.18546v1 Announce Type: new  Abstract: A major goal in neuroscience is to discover neural data representations that generalize. This goal is challenged by variability along recording sessions (e.g. environment), subjects (e.g. varying neural structures), and sensors (e.g. sensor noise), among others. Recent work has begun to address generalization across sessions and subjects, but few study robustness to sensor failure which is highly prevalent in neuroscience experiments. In order to address these generalizability dimensions we first collect our own electroencephalography dataset with numerous sessions, subjects, and sensors, then study two time series models: EEGNet (Lawhern et al., 2018) and TOTEM (Talukder et al., 2024). EEGNet is a widely used convolutional neural network, while TOTEM is a discrete time series tokenizer and transformer model. We find that TOTEM outperforms or matches EEGNet across all generalizability cases. Finally through analysis of TOTEM's latent cod",
    "link": "https://arxiv.org/abs/2402.18546",
    "context": "Title: Generalizability Under Sensor Failure: Tokenization + Transformers Enable More Robust Latent Spaces\nAbstract: arXiv:2402.18546v1 Announce Type: new  Abstract: A major goal in neuroscience is to discover neural data representations that generalize. This goal is challenged by variability along recording sessions (e.g. environment), subjects (e.g. varying neural structures), and sensors (e.g. sensor noise), among others. Recent work has begun to address generalization across sessions and subjects, but few study robustness to sensor failure which is highly prevalent in neuroscience experiments. In order to address these generalizability dimensions we first collect our own electroencephalography dataset with numerous sessions, subjects, and sensors, then study two time series models: EEGNet (Lawhern et al., 2018) and TOTEM (Talukder et al., 2024). EEGNet is a widely used convolutional neural network, while TOTEM is a discrete time series tokenizer and transformer model. We find that TOTEM outperforms or matches EEGNet across all generalizability cases. Finally through analysis of TOTEM's latent cod",
    "path": "papers/24/02/2402.18546.json",
    "total_tokens": 890,
    "translated_title": "传感器故障下的泛化性能：Tokenization + Transformers 实现更健壮的潜在空间",
    "translated_abstract": "神经科学的一个主要目标是发现能够泛化的神经数据表示。这一目标受到记录会话（例如环境）、受试者（例如变化的神经结构）和传感器（例如传感器噪声）等因素的挑战。最近的工作已经开始解决跨会话和受试者的泛化问题，但很少有研究针对在神经科学实验中普遍存在的传感器故障的稳健性。为了解决这些泛化性维度，我们首先收集了我们自己的脑电图数据集，其中包含多个会话、受试者和传感器，然后研究了两个时间序列模型：EEGNet（Lawhern等人，2018）和TOTEM（Talukder等人，2024）。EEGNet 是一个广泛使用的卷积神经网络，而 TOTEM 是一个离散时间序列标记器和 Transformer 模型。我们发现，在所有泛化案例中，TOTEM 的表现优于或与 EEGNet 相匹配。最后，通过分析 TOTEM 的潜在编码",
    "tldr": "TOTEM模型在应对传感器故障的神经科学研究中实现了更好的泛化性能。",
    "en_tdlr": "TOTEM model achieves better generalizability in neuroscience research dealing with sensor failures."
}