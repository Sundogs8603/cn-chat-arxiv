{
    "title": "Tree Ensembles for Contextual Bandits",
    "abstract": "We propose a novel framework for contextual multi-armed bandits based on tree ensembles. Our framework integrates two widely used bandit methods, Upper Confidence Bound and Thompson Sampling, for both standard and combinatorial settings. We demonstrate the effectiveness of our framework via several experimental studies, employing XGBoost, a popular tree ensemble method. Compared to state-of-the-art methods based on neural networks, our methods exhibit superior performance in terms of both regret minimization and computational runtime, when applied to benchmark datasets and the real-world application of navigation over road networks.",
    "link": "https://arxiv.org/abs/2402.06963",
    "context": "Title: Tree Ensembles for Contextual Bandits\nAbstract: We propose a novel framework for contextual multi-armed bandits based on tree ensembles. Our framework integrates two widely used bandit methods, Upper Confidence Bound and Thompson Sampling, for both standard and combinatorial settings. We demonstrate the effectiveness of our framework via several experimental studies, employing XGBoost, a popular tree ensemble method. Compared to state-of-the-art methods based on neural networks, our methods exhibit superior performance in terms of both regret minimization and computational runtime, when applied to benchmark datasets and the real-world application of navigation over road networks.",
    "path": "papers/24/02/2402.06963.json",
    "total_tokens": 699,
    "translated_title": "基于树集成的情境多臂老虎机",
    "translated_abstract": "我们提出了一个基于树集成的情境多臂老虎机的新框架。我们的框架将两种广泛使用的老虎机方法，上信心界和汤普森抽样，整合到标准和组合设置中。通过使用流行的树集成方法XGBoost进行多次实验研究，我们展示了我们框架的有效性。当应用于基准数据集和道路网络导航的真实世界应用时，与基于神经网络的最先进方法相比，我们的方法在减少后悔和计算时间方面表现出更好的性能。",
    "tldr": "本论文提出了一种基于树集成的情境多臂老虎机新框架，通过整合两种广泛使用的老虎机方法，在标准和组合设置中实现了优于基于神经网络的方法的性能，在减少后悔和计算时间方面表现出更出色的性能。",
    "en_tdlr": "This paper proposes a novel framework for contextual multi-armed bandits based on tree ensembles, which integrates two widely used bandit methods and outperforms state-of-the-art methods based on neural networks in terms of regret minimization and computational runtime."
}