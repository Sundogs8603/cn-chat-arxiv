{
    "title": "Comprehensive Cognitive LLM Agent for Smartphone GUI Automation",
    "abstract": "arXiv:2402.11941v1 Announce Type: new  Abstract: Large language models (LLMs) have shown remarkable potential as human-like autonomous language agents to interact with real-world environments, especially for graphical user interface (GUI) automation. However, those GUI agents require comprehensive cognition ability including exhaustive perception and reliable action response. We propose \\underline{Co}mprehensive \\underline{Co}gnitive LLM \\underline{Agent}, CoCo-Agent, with two novel approaches, comprehensive environment perception (CEP) and conditional action prediction (CAP), to systematically improve the GUI automation performance. First, CEP facilitates the GUI perception through different aspects and granularity, including screenshots and complementary detailed layouts for the visual channel and historical actions for the textual channel. Second, CAP decomposes the action prediction into sub-problems: action type prediction and action target conditioned on the action type. With our",
    "link": "https://arxiv.org/abs/2402.11941",
    "context": "Title: Comprehensive Cognitive LLM Agent for Smartphone GUI Automation\nAbstract: arXiv:2402.11941v1 Announce Type: new  Abstract: Large language models (LLMs) have shown remarkable potential as human-like autonomous language agents to interact with real-world environments, especially for graphical user interface (GUI) automation. However, those GUI agents require comprehensive cognition ability including exhaustive perception and reliable action response. We propose \\underline{Co}mprehensive \\underline{Co}gnitive LLM \\underline{Agent}, CoCo-Agent, with two novel approaches, comprehensive environment perception (CEP) and conditional action prediction (CAP), to systematically improve the GUI automation performance. First, CEP facilitates the GUI perception through different aspects and granularity, including screenshots and complementary detailed layouts for the visual channel and historical actions for the textual channel. Second, CAP decomposes the action prediction into sub-problems: action type prediction and action target conditioned on the action type. With our",
    "path": "papers/24/02/2402.11941.json",
    "total_tokens": 780,
    "translated_title": "智能手机GUI自动化的全面认知LLM代理",
    "translated_abstract": "大型语言模型(LLMs)已经显示出作为人类般自主语言代理与现实环境进行交互的显著潜力，尤其在图形用户界面(GUI)自动化方面。然而，这些GUI代理需要全面的认知能力，包括详尽的感知和可靠的动作响应。我们提出了全面认知LLM代理，CoCo-Agent，采用了两种新方法，全面环境感知(CEP)和条件动作预测(CAP)，以系统性地提高GUI自动化性能。首先，CEP通过不同方面和粒度促进GUI感知，包括屏幕截图和用于视觉通道的补充详细布局，以及用于文本通道的历史动作。其次，CAP将动作预测分解为子问题：动作类型预测和条件化于动作类型的动作目标。",
    "tldr": "提出了全面认知LLM代理，通过全面环境感知和条件动作预测两种新方法系统性提高GUI自动化性能。"
}