{
    "title": "Plan-Grounded Large Language Models for Dual Goal Conversational Settings",
    "abstract": "Training Large Language Models (LLMs) to follow user instructions has been shown to supply the LLM with ample capacity to converse fluently while being aligned with humans. Yet, it is not completely clear how an LLM can lead a plan-grounded conversation in mixed-initiative settings where instructions flow in both directions of the conversation, i.e. both the LLM and the user provide instructions to one another. In this paper, we tackle a dual goal mixed-initiative conversational setting where the LLM not only grounds the conversation on an arbitrary plan but also seeks to satisfy both a procedural plan and user instructions. The LLM is then responsible for guiding the user through the plan and, at the same time, adapting to new circumstances, answering questions, and activating safety guardrails when needed. We propose a novel LLM that grounds the dialogue on a procedural plan, can take the dialogue initiative, and enforces guardrails on the system's behavior, while also improving the ",
    "link": "https://rss.arxiv.org/abs/2402.01053",
    "context": "Title: Plan-Grounded Large Language Models for Dual Goal Conversational Settings\nAbstract: Training Large Language Models (LLMs) to follow user instructions has been shown to supply the LLM with ample capacity to converse fluently while being aligned with humans. Yet, it is not completely clear how an LLM can lead a plan-grounded conversation in mixed-initiative settings where instructions flow in both directions of the conversation, i.e. both the LLM and the user provide instructions to one another. In this paper, we tackle a dual goal mixed-initiative conversational setting where the LLM not only grounds the conversation on an arbitrary plan but also seeks to satisfy both a procedural plan and user instructions. The LLM is then responsible for guiding the user through the plan and, at the same time, adapting to new circumstances, answering questions, and activating safety guardrails when needed. We propose a novel LLM that grounds the dialogue on a procedural plan, can take the dialogue initiative, and enforces guardrails on the system's behavior, while also improving the ",
    "path": "papers/24/02/2402.01053.json",
    "total_tokens": 883,
    "translated_title": "面向双重目标对话设置的计划驱动大型语言模型",
    "translated_abstract": "训练大型语言模型（LLM）遵循用户指令已被证明可以为LLM提供充足的能力以流利地进行对话并与人类对齐。然而，在双向对话流动指令的混合倡议设置中，LLM如何引导以计划为基础的对话还不完全清楚，即LLM和用户彼此提供指令。在本文中，我们解决了双重目标混合倡议对话设置的问题，LLM不仅在任意计划上基础对话，还致力于满足流程计划和用户指令。LLM负责引导用户完成计划，同时适应新的情况，回答问题，并在需要时激活安全防护措施。我们提出了一种新颖的LLM，它基于流程计划来进行对话，可以主动参与对话，并在系统行为上实施安全防护。",
    "tldr": "本研究针对双重目标对话设置提出了一种新型的计划驱动大型语言模型，该模型能够在任意计划上基础对话，主动引导用户完成计划，并在系统行为上实施安全防护。",
    "en_tdlr": "This paper proposes a novel plan-grounded large language model (LLM) for dual goal conversational settings, in which the LLM can guide the conversation based on a procedural plan, actively lead the user through the plan, and enforce safety precautions on the system's behavior."
}