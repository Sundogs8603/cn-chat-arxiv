{
    "title": "Human-Centered Privacy Research in the Age of Large Language Models",
    "abstract": "The emergence of large language models (LLMs), and their increased use in user-facing systems, has led to substantial privacy concerns. To date, research on these privacy concerns has been model-centered: exploring how LLMs lead to privacy risks like memorization, or can be used to infer personal characteristics about people from their content. We argue that there is a need for more research focusing on the human aspect of these privacy issues: e.g., research on how design paradigms for LLMs affect users' disclosure behaviors, users' mental models and preferences for privacy controls, and the design of tools, systems, and artifacts that empower end-users to reclaim ownership over their personal data. To build usable, efficient, and privacy-friendly systems powered by these models with imperfect privacy properties, our goal is to initiate discussions to outline an agenda for conducting human-centered research on privacy issues in LLM-powered systems. This Special Interest Group (SIG) ai",
    "link": "https://arxiv.org/abs/2402.01994",
    "context": "Title: Human-Centered Privacy Research in the Age of Large Language Models\nAbstract: The emergence of large language models (LLMs), and their increased use in user-facing systems, has led to substantial privacy concerns. To date, research on these privacy concerns has been model-centered: exploring how LLMs lead to privacy risks like memorization, or can be used to infer personal characteristics about people from their content. We argue that there is a need for more research focusing on the human aspect of these privacy issues: e.g., research on how design paradigms for LLMs affect users' disclosure behaviors, users' mental models and preferences for privacy controls, and the design of tools, systems, and artifacts that empower end-users to reclaim ownership over their personal data. To build usable, efficient, and privacy-friendly systems powered by these models with imperfect privacy properties, our goal is to initiate discussions to outline an agenda for conducting human-centered research on privacy issues in LLM-powered systems. This Special Interest Group (SIG) ai",
    "path": "papers/24/02/2402.01994.json",
    "total_tokens": 893,
    "translated_title": "大语言模型时代的以人为中心的隐私研究",
    "translated_abstract": "大型语言模型（LLMs）的出现及其在面向用户的系统中的广泛使用引起了重大的隐私担忧。迄今为止，对这些隐私问题的研究以模型为中心：探索LLMs如何导致隐私风险，例如记忆，或如何通过内容推断人们的个人特征。我们认为有必要进行更多研究，重点关注这些隐私问题的人类因素：例如研究LLMs设计范式如何影响用户的披露行为、用户的心理模型和隐私控制的偏好，以及设计工具、系统和工件以赋予终端用户对个人数据的所有权。为了构建可用、高效和注重隐私的系统，使其由这些具有不完善隐私属性的模型进行驱动，我们的目标是发起讨论，拟定一个以人为中心的研究议程，对LLMs加速系统中的隐私问题进行研究。",
    "tldr": "大语言模型带来了隐私担忧，现有研究着重于模型本身，我们认为有必要进行以人为中心的研究，关注用户的行为和偏好，设计工具和系统，使用户能够掌控个人数据的所有权。"
}