{
    "title": "Captions Are Worth a Thousand Words: Enhancing Product Retrieval with Pretrained Image-to-Text Models",
    "abstract": "This paper explores the usage of multimodal image-to-text models to enhance text-based item retrieval. We propose utilizing pre-trained image captioning and tagging models, such as instructBLIP and CLIP, to generate text-based product descriptions which are combined with existing text descriptions. Our work is particularly impactful for smaller eCommerce businesses who are unable to maintain the high-quality text descriptions necessary to effectively perform item retrieval for search and recommendation use cases. We evaluate the searchability of ground-truth text, image-generated text, and combinations of both texts on several subsets of Amazon's publicly available ESCI dataset. The results demonstrate the dual capability of our proposed models to enhance the retrieval of existing text and generate highly-searchable standalone descriptions.",
    "link": "https://arxiv.org/abs/2402.08532",
    "context": "Title: Captions Are Worth a Thousand Words: Enhancing Product Retrieval with Pretrained Image-to-Text Models\nAbstract: This paper explores the usage of multimodal image-to-text models to enhance text-based item retrieval. We propose utilizing pre-trained image captioning and tagging models, such as instructBLIP and CLIP, to generate text-based product descriptions which are combined with existing text descriptions. Our work is particularly impactful for smaller eCommerce businesses who are unable to maintain the high-quality text descriptions necessary to effectively perform item retrieval for search and recommendation use cases. We evaluate the searchability of ground-truth text, image-generated text, and combinations of both texts on several subsets of Amazon's publicly available ESCI dataset. The results demonstrate the dual capability of our proposed models to enhance the retrieval of existing text and generate highly-searchable standalone descriptions.",
    "path": "papers/24/02/2402.08532.json",
    "total_tokens": 757,
    "translated_title": "标题：字幕胜过千言万语：利用预训练的图像到文本模型增强产品检索",
    "translated_abstract": "本文探讨了使用多模态图像到文本模型来增强基于文本的物品检索的方法。我们提出利用预训练的图像字幕和标记模型，如instructBLIP和CLIP，生成基于文本的产品描述，并将其与现有的文本描述相结合。我们的工作对于无法维护高质量文本描述以有效地执行搜索和推荐用例的小型电子商务企业尤为重要。我们评估了Amazon公开可用的ESCI数据集的几个子集上的真实文本、图像生成文本以及两者的组合的可搜索性。结果表明，我们提出的模型具有增强现有文本检索和生成高度可搜索独立描述的双重能力。",
    "tldr": "本文研究了使用预训练的图像到文本模型来增强基于文本的物品检索，并证明了该模型能够提高现有文本的检索效果并生成高度可搜索的独立描述。",
    "en_tdlr": "This paper explores the usage of pretrained image-to-text models to enhance text-based item retrieval and demonstrates the capability of these models to improve existing text retrieval and generate highly searchable standalone descriptions."
}