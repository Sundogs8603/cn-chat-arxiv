{
    "title": "Discrete Neural Algorithmic Reasoning",
    "abstract": "arXiv:2402.11628v1 Announce Type: new  Abstract: Neural algorithmic reasoning aims to capture computations with neural networks via learning the models to imitate the execution of classical algorithms. While common architectures are expressive enough to contain the correct model in the weights space, current neural reasoners are struggling to generalize well on out-of-distribution data. On the other hand, classical computations are not affected by distribution shifts as they can be described as transitions between discrete computational states. In this work, we propose to force neural reasoners to maintain the execution trajectory as a combination of finite predefined states. Trained with supervision on the algorithm's state transitions, such models are able to perfectly align with the original algorithm. To show this, we evaluate our approach on the SALSA-CLRS benchmark, where we get perfect test scores for all tasks. Moreover, the proposed architectural choice allows us to prove the ",
    "link": "https://arxiv.org/abs/2402.11628",
    "context": "Title: Discrete Neural Algorithmic Reasoning\nAbstract: arXiv:2402.11628v1 Announce Type: new  Abstract: Neural algorithmic reasoning aims to capture computations with neural networks via learning the models to imitate the execution of classical algorithms. While common architectures are expressive enough to contain the correct model in the weights space, current neural reasoners are struggling to generalize well on out-of-distribution data. On the other hand, classical computations are not affected by distribution shifts as they can be described as transitions between discrete computational states. In this work, we propose to force neural reasoners to maintain the execution trajectory as a combination of finite predefined states. Trained with supervision on the algorithm's state transitions, such models are able to perfectly align with the original algorithm. To show this, we evaluate our approach on the SALSA-CLRS benchmark, where we get perfect test scores for all tasks. Moreover, the proposed architectural choice allows us to prove the ",
    "path": "papers/24/02/2402.11628.json",
    "total_tokens": 859,
    "translated_title": "离散神经算法推理",
    "translated_abstract": "神经算法推理旨在通过学习模仿经典算法的执行来捕捉神经网络中的计算。尽管常见的架构足够表达正确的模型在权重空间中，但当前的神经推理器在处理超出分布数据时面临泛化困难。另一方面，经典计算不受分布变化的影响，因为它们可以描述为离散计算状态之间的转换。在这项工作中，我们提出强制神经推理器将执行轨迹作为有限预定义状态的组合进行维护。通过对算法状态转换的监督训练，这种模型能够与原始算法完美对齐。为了证明这一点，我们在SALSA-CLRS基准测试上评估我们的方法，在那里我们为所有任务获得了完美的测试成绩。此外，所提出的架构选择使我们能够证明...",
    "tldr": "这项工作提出了一种强制神经推理器维护执行轨迹作为有限预定义状态组合的方法，通过对算法状态转换的监督训练，使模型能够与原始算法完美对齐，并在基准测试中取得了完美的测试成绩。",
    "en_tdlr": "This work introduces a method that forces neural reasoners to maintain the execution trajectory as a combination of finite predefined states, trains the model with supervision on the algorithm's state transitions to align perfectly with the original algorithm, and achieves perfect test scores on benchmark tasks."
}