{
    "title": "Reducing Hallucinations in Entity Abstract Summarization with Facts-Template Decomposition",
    "abstract": "arXiv:2402.18873v1 Announce Type: new  Abstract: Entity abstract summarization aims to generate a coherent description of a given entity based on a set of relevant Internet documents. Pretrained language models (PLMs) have achieved significant success in this task, but they may suffer from hallucinations, i.e. generating non-factual information about the entity. To address this issue, we decompose the summary into two components: Facts that represent the factual information about the given entity, which PLMs are prone to fabricate; and Template that comprises generic content with designated slots for facts, which PLMs can generate competently. Based on the facts-template decomposition, we propose SlotSum, an explainable framework for entity abstract summarization. SlotSum first creates the template and then predicts the fact for each template slot based on the input documents. Benefiting from our facts-template decomposition, SlotSum can easily locate errors and further rectify halluci",
    "link": "https://arxiv.org/abs/2402.18873",
    "context": "Title: Reducing Hallucinations in Entity Abstract Summarization with Facts-Template Decomposition\nAbstract: arXiv:2402.18873v1 Announce Type: new  Abstract: Entity abstract summarization aims to generate a coherent description of a given entity based on a set of relevant Internet documents. Pretrained language models (PLMs) have achieved significant success in this task, but they may suffer from hallucinations, i.e. generating non-factual information about the entity. To address this issue, we decompose the summary into two components: Facts that represent the factual information about the given entity, which PLMs are prone to fabricate; and Template that comprises generic content with designated slots for facts, which PLMs can generate competently. Based on the facts-template decomposition, we propose SlotSum, an explainable framework for entity abstract summarization. SlotSum first creates the template and then predicts the fact for each template slot based on the input documents. Benefiting from our facts-template decomposition, SlotSum can easily locate errors and further rectify halluci",
    "path": "papers/24/02/2402.18873.json",
    "total_tokens": 807,
    "translated_title": "通过事实-模板分解减少实体摘要中的幻觉",
    "translated_abstract": "实体摘要总结旨在基于一组相关的互联网文档生成一个给定实体的连贯描述。预训练语言模型（PLMs）在这一任务中取得了显著的成功，但可能会出现幻觉，即生成关于实体的非事实信息。为了解决这个问题，我们将摘要分解成两部分：表示给定实体的事实信息的事实，PLMs容易捏造；以及包含通用内容且为事实指定槽的模板，PLMs可以有效地生成。基于事实-模板分解，我们提出了SlotSum，一个可解释的实体摘要总结框架。SlotSum首先创建模板，然后根据输入文档预测每个模板槽的事实。受益于我们的事实-模板分解，SlotSum可以轻松定位错误，并进一步纠正幻觉。",
    "tldr": "通过事实-模板分解，提出了一个可解释的框架SlotSum，用于减少预训练语言模型在实体摘要中生成幻觉的问题。"
}