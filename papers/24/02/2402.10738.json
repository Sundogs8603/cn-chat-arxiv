{
    "title": "Let's Learn Step by Step: Enhancing In-Context Learning Ability with Curriculum Learning",
    "abstract": "arXiv:2402.10738v1 Announce Type: new  Abstract: Demonstration ordering, which is an important strategy for in-context learning (ICL), can significantly affects the performance of large language models (LLMs). However, most of the current approaches of ordering require additional knowledge and similarity calculation. We advocate the few-shot in-context curriculum learning (ICCL), a simple but effective demonstration ordering method for ICL, which implies gradually increasing the complexity of prompt demonstrations during the inference process. Then we design three experiments to discuss the effectiveness of ICCL, the formation mechanism of LLM's ICCL capability, and the impact of ordering subjects. Experimental results demonstrate that ICCL, developed during the instruction-tuning stage, is effective for open-source LLMs. Moreover, LLMs exhibit a weaker capacity compared to humans in discerning the difficulty levels of demonstrations. We release our code at https://github.com/61peng/cu",
    "link": "https://arxiv.org/abs/2402.10738",
    "context": "Title: Let's Learn Step by Step: Enhancing In-Context Learning Ability with Curriculum Learning\nAbstract: arXiv:2402.10738v1 Announce Type: new  Abstract: Demonstration ordering, which is an important strategy for in-context learning (ICL), can significantly affects the performance of large language models (LLMs). However, most of the current approaches of ordering require additional knowledge and similarity calculation. We advocate the few-shot in-context curriculum learning (ICCL), a simple but effective demonstration ordering method for ICL, which implies gradually increasing the complexity of prompt demonstrations during the inference process. Then we design three experiments to discuss the effectiveness of ICCL, the formation mechanism of LLM's ICCL capability, and the impact of ordering subjects. Experimental results demonstrate that ICCL, developed during the instruction-tuning stage, is effective for open-source LLMs. Moreover, LLMs exhibit a weaker capacity compared to humans in discerning the difficulty levels of demonstrations. We release our code at https://github.com/61peng/cu",
    "path": "papers/24/02/2402.10738.json",
    "total_tokens": 837,
    "translated_title": "让我们一步一步学习：通过课程学习增强上下文学习能力",
    "translated_abstract": "演示排序是上下文学习（ICL）的重要策略，可以显著影响大型语言模型（LLMs）的性能。然而，大部分当前的排序方法需要额外的知识和相似性计算。我们倡导少样本上下文课程学习（ICCL），这是一种简单而有效的ICL演示排序方法，其暗示在推理过程中逐渐增加提示演示的复杂性。然后，我们设计了三个实验，讨论ICCL的有效性，LLM的ICCL能力形成机制以及排序主题的影响。实验结果表明，ICCL在指导调整阶段开发，对于开源LLMs是有效的。此外，LLMs在辨别演示难度级别方面表现出比人类更弱的能力。我们在https://github.com/61peng/cu发布了我们的代码。",
    "tldr": "通过少样本上下文课程学习（ICCL）方法，逐渐增加提示演示的复杂性，有效提高了大型语言模型（LLMs）的性能，实验结果显示ICCL对开源LLMs有效。",
    "en_tdlr": "By gradually increasing the complexity of prompt demonstrations through few-shot in-context curriculum learning (ICCL), the performance of large language models (LLMs) is enhanced effectively, as demonstrated in experiments on open-source LLMs."
}