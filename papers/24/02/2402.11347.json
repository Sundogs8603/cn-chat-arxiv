{
    "title": "PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models",
    "abstract": "arXiv:2402.11347v1 Announce Type: new  Abstract: Crafting an ideal prompt for Large Language Models (LLMs) is a challenging task that demands significant resources and expert human input. Existing work treats the optimization of prompt instruction and in-context learning examples as distinct problems, leading to sub-optimal prompt performance. This research addresses this limitation by establishing a unified in-context prompt optimization framework, which aims to achieve joint optimization of the prompt instruction and examples. However, formulating such optimization in the discrete and high-dimensional natural language space introduces challenges in terms of convergence and computational efficiency. To overcome these issues, we present PhaseEvo, an efficient automatic prompt optimization framework that combines the generative capability of LLMs with the global search proficiency of evolution algorithms. Our framework features a multi-phase design incorporating innovative LLM-based mut",
    "link": "https://arxiv.org/abs/2402.11347",
    "context": "Title: PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models\nAbstract: arXiv:2402.11347v1 Announce Type: new  Abstract: Crafting an ideal prompt for Large Language Models (LLMs) is a challenging task that demands significant resources and expert human input. Existing work treats the optimization of prompt instruction and in-context learning examples as distinct problems, leading to sub-optimal prompt performance. This research addresses this limitation by establishing a unified in-context prompt optimization framework, which aims to achieve joint optimization of the prompt instruction and examples. However, formulating such optimization in the discrete and high-dimensional natural language space introduces challenges in terms of convergence and computational efficiency. To overcome these issues, we present PhaseEvo, an efficient automatic prompt optimization framework that combines the generative capability of LLMs with the global search proficiency of evolution algorithms. Our framework features a multi-phase design incorporating innovative LLM-based mut",
    "path": "papers/24/02/2402.11347.json",
    "total_tokens": 811,
    "translated_title": "PhaseEvo：面向大型语言模型的统一上下文提示优化",
    "translated_abstract": "制定大型语言模型（LLMs）的理想提示是一项具有挑战性的任务，需要显著的资源和专业人员的输入。现有工作将优化提示指令和上下文学习示例视为不同问题，导致提示性能次优。本研究通过建立统一的上下文提示优化框架来解决这一局限性，旨在实现提示指令和示例的联合优化。然而，在离散且高维的自然语言空间中制定这种优化引入了收敛和计算效率方面的挑战。为了克服这些问题，我们提出了PhaseEvo，这是一个结合了LLMs的生成能力和进化算法的全局搜索效率的高效自动提示优化框架。我们的框架采用多阶段设计，融合了创新的基于LLMs的变异",
    "tldr": "该研究提出了PhaseEvo，一个旨在实现提示指令和示例的联合优化的高效自动提示优化框架，结合了LLMs的生成能力和进化算法的全局搜索效率。",
    "en_tdlr": "This research introduces PhaseEvo, an efficient automatic prompt optimization framework that aims to achieve joint optimization of prompt instruction and examples by combining the generative capability of LLMs with the global search proficiency of evolution algorithms."
}