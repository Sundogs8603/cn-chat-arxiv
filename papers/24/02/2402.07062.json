{
    "title": "Fast UCB-type algorithms for stochastic bandits with heavy and super heavy symmetric noise",
    "abstract": "In this study, we propose a new method for constructing UCB-type algorithms for stochastic multi-armed bandits based on general convex optimization methods with an inexact oracle. We derive the regret bounds corresponding to the convergence rates of the optimization methods. We propose a new algorithm Clipped-SGD-UCB and show, both theoretically and empirically, that in the case of symmetric noise in the reward, we can achieve an $O(\\log T\\sqrt{KT\\log T})$ regret bound instead of $O\\left (T^{\\frac{1}{1+\\alpha}} K^{\\frac{\\alpha}{1+\\alpha}} \\right)$ for the case when the reward distribution satisfies $\\mathbb{E}_{X \\in D}[|X|^{1+\\alpha}] \\leq \\sigma^{1+\\alpha}$ ($\\alpha \\in (0, 1])$, i.e. perform better than it is assumed by the general lower bound for bandits with heavy-tails. Moreover, the same bound holds even when the reward distribution does not have the expectation, that is, when $\\alpha<0$.",
    "link": "https://arxiv.org/abs/2402.07062",
    "context": "Title: Fast UCB-type algorithms for stochastic bandits with heavy and super heavy symmetric noise\nAbstract: In this study, we propose a new method for constructing UCB-type algorithms for stochastic multi-armed bandits based on general convex optimization methods with an inexact oracle. We derive the regret bounds corresponding to the convergence rates of the optimization methods. We propose a new algorithm Clipped-SGD-UCB and show, both theoretically and empirically, that in the case of symmetric noise in the reward, we can achieve an $O(\\log T\\sqrt{KT\\log T})$ regret bound instead of $O\\left (T^{\\frac{1}{1+\\alpha}} K^{\\frac{\\alpha}{1+\\alpha}} \\right)$ for the case when the reward distribution satisfies $\\mathbb{E}_{X \\in D}[|X|^{1+\\alpha}] \\leq \\sigma^{1+\\alpha}$ ($\\alpha \\in (0, 1])$, i.e. perform better than it is assumed by the general lower bound for bandits with heavy-tails. Moreover, the same bound holds even when the reward distribution does not have the expectation, that is, when $\\alpha<0$.",
    "path": "papers/24/02/2402.07062.json",
    "total_tokens": 1020,
    "translated_title": "快速UCB类型算法用于具有重和超重对称噪声的随机赌博机问题",
    "translated_abstract": "在本研究中，我们提出了一种基于一般凸优化方法和不精确的预测模型的UCB类型算法构建方法，并推导了与优化方法收敛速度相对应的遗憾界。我们提出了一种新的算法Clipped-SGD-UCB，并通过理论和经验结果表明，在奖励中存在对称噪声的情况下，可以达到$O(\\log T\\sqrt{KT\\log T})$的遗憾界，而不是$O\\left (T^{\\frac{1}{1+\\alpha}} K^{\\frac{\\alpha}{1+\\alpha}} \\right)$，该界是当奖励分布满足$\\mathbb{E}_{X \\in D}[|X|^{1+\\alpha}] \\leq \\sigma^{1+\\alpha}$（$\\alpha \\in (0, 1]$）时的一般下界。此外，即使奖励分布没有期望，即，当$\\alpha<0$时，同样的界限也成立。",
    "tldr": "本研究提出了一种基于凸优化方法和不精确预测模型的新UCB类型算法，用于解决具有重和超重对称噪声的随机赌博机问题。通过理论和实验结果表明，在奖励中存在对称噪声的情况下，该算法能够达到更好的性能，相比于一般下界能够获得更小的遗憾界。即使奖励分布没有期望，该算法仍然有效。",
    "en_tdlr": "This study proposes a new UCB-type algorithm based on convex optimization methods and inexact prediction models for addressing stochastic bandits with heavy and super heavy symmetric noise. The algorithm, named Clipped-SGD-UCB, achieves better performance than the general lower bound by achieving a smaller regret bound in the presence of symmetric noise in the rewards. Furthermore, the algorithm remains effective even when the reward distribution does not have an expectation."
}