{
    "title": "Deep Homography Estimation for Visual Place Recognition",
    "abstract": "arXiv:2402.16086v1 Announce Type: cross  Abstract: Visual place recognition (VPR) is a fundamental task for many applications such as robot localization and augmented reality. Recently, the hierarchical VPR methods have received considerable attention due to the trade-off between accuracy and efficiency. They usually first use global features to retrieve the candidate images, then verify the spatial consistency of matched local features for re-ranking. However, the latter typically relies on the RANSAC algorithm for fitting homography, which is time-consuming and non-differentiable. This makes existing methods compromise to train the network only in global feature extraction. Here, we propose a transformer-based deep homography estimation (DHE) network that takes the dense feature map extracted by a backbone network as input and fits homography for fast and learnable geometric verification. Moreover, we design a re-projection error of inliers loss to train the DHE network without addit",
    "link": "https://arxiv.org/abs/2402.16086",
    "context": "Title: Deep Homography Estimation for Visual Place Recognition\nAbstract: arXiv:2402.16086v1 Announce Type: cross  Abstract: Visual place recognition (VPR) is a fundamental task for many applications such as robot localization and augmented reality. Recently, the hierarchical VPR methods have received considerable attention due to the trade-off between accuracy and efficiency. They usually first use global features to retrieve the candidate images, then verify the spatial consistency of matched local features for re-ranking. However, the latter typically relies on the RANSAC algorithm for fitting homography, which is time-consuming and non-differentiable. This makes existing methods compromise to train the network only in global feature extraction. Here, we propose a transformer-based deep homography estimation (DHE) network that takes the dense feature map extracted by a backbone network as input and fits homography for fast and learnable geometric verification. Moreover, we design a re-projection error of inliers loss to train the DHE network without addit",
    "path": "papers/24/02/2402.16086.json",
    "total_tokens": 790,
    "translated_title": "用于视觉地点识别的深度单应性估计",
    "translated_abstract": "视觉地点识别(VPR)是许多应用程序的基本任务，如机器人定位和增强现实。最近，由于准确性和效率之间的权衡，分层VPR方法受到了广泛关注。它们通常首先使用全局特征来检索候选图像，然后验证匹配的局部特征的空间一致性以进行重新排序。然而，后者通常依赖于RANSAC算法进行单应性拟合，这是耗时且不可微分的。这导致现有方法只能在全局特征提取中训练网络。在这里，我们提出了一种基于Transformer的深度单应性估计(DHE)网络，其以由主干网络提取的密集特征图为输入，并适合于快速和可学习的几何验证。此外，我们设计了一个内点重投影误差损失来训练DHE网络，无需添加额外......",
    "tldr": "提出了一种基于Transformer的深度单应性估计网络，用于快速和可学习的几何验证。",
    "en_tdlr": "Introduced a transformer-based deep homography estimation (DHE) network for fast and learnable geometric verification."
}