{
    "title": "SPML: A DSL for Defending Language Models Against Prompt Attacks",
    "abstract": "arXiv:2402.11755v1 Announce Type: cross  Abstract: Large language models (LLMs) have profoundly transformed natural language applications, with a growing reliance on instruction-based definitions for designing chatbots. However, post-deployment the chatbot definitions are fixed and are vulnerable to attacks by malicious users, emphasizing the need to prevent unethical applications and financial losses. Existing studies explore user prompts' impact on LLM-based chatbots, yet practical methods to contain attacks on application-specific chatbots remain unexplored. This paper presents System Prompt Meta Language (SPML), a domain-specific language for refining prompts and monitoring the inputs to the LLM-based chatbots. SPML actively checks attack prompts, ensuring user inputs align with chatbot definitions to prevent malicious execution on the LLM backbone, optimizing costs. It also streamlines chatbot definition crafting with programming language capabilities, overcoming natural language ",
    "link": "https://arxiv.org/abs/2402.11755",
    "context": "Title: SPML: A DSL for Defending Language Models Against Prompt Attacks\nAbstract: arXiv:2402.11755v1 Announce Type: cross  Abstract: Large language models (LLMs) have profoundly transformed natural language applications, with a growing reliance on instruction-based definitions for designing chatbots. However, post-deployment the chatbot definitions are fixed and are vulnerable to attacks by malicious users, emphasizing the need to prevent unethical applications and financial losses. Existing studies explore user prompts' impact on LLM-based chatbots, yet practical methods to contain attacks on application-specific chatbots remain unexplored. This paper presents System Prompt Meta Language (SPML), a domain-specific language for refining prompts and monitoring the inputs to the LLM-based chatbots. SPML actively checks attack prompts, ensuring user inputs align with chatbot definitions to prevent malicious execution on the LLM backbone, optimizing costs. It also streamlines chatbot definition crafting with programming language capabilities, overcoming natural language ",
    "path": "papers/24/02/2402.11755.json",
    "total_tokens": 855,
    "translated_title": "SPML: 一种用于防御语言模型受到提示攻击的领域特定语言",
    "translated_abstract": "大型语言模型（LLMs）已深刻改变了自然语言应用，越来越多地依赖于基于指令的定义来设计聊天机器人。然而，部署后，聊天机器人的定义是固定的，并且容易受到恶意用户的攻击，突出了防止不道德应用和财务损失的需要。现有研究探讨了用户提示对基于LLM的聊天机器人的影响，但尚未探索包含应用特定聊天机器人的攻击的实用方法。本文提出了系统提示元语言（SPML），这是一种用于优化提示并监控基于LLM的聊天机器人输入的领域特定语言。SPML主动检查攻击提示，确保用户输入与聊天机器人定义相符，防止在LLM主干上对其进行恶意执行，优化成本。它也通过编程语言能力简化了聊天机器人定义的制作，克服了自然语言的限制。",
    "tldr": "SPML是一种用于优化提示并监控基于大型语言模型聊天机器人输入的领域特定语言，用于防御恶意攻击并优化成本。",
    "en_tdlr": "SPML is a domain-specific language for refining prompts and monitoring inputs to LLM-based chatbots, aiming to defend against malicious attacks and optimize costs."
}