{
    "title": "Leveraging Digital Cousins for Ensemble Q-Learning in Large-Scale Wireless Networks",
    "abstract": "Optimizing large-scale wireless networks, including optimal resource management, power allocation, and throughput maximization, is inherently challenging due to their non-observable system dynamics and heterogeneous and complex nature. Herein, a novel ensemble Q-learning algorithm that addresses the performance and complexity challenges of the traditional Q-learning algorithm for optimizing wireless networks is presented. Ensemble learning with synthetic Markov Decision Processes is tailored to wireless networks via new models for approximating large state-space observable wireless networks. In particular, digital cousins are proposed as an extension of the traditional digital twin concept wherein multiple Q-learning algorithms on multiple synthetic Markovian environments are run in parallel and their outputs are fused into a single Q-function. Convergence analyses of key statistics and Q-functions and derivations of upper bounds on the estimation bias and variance are provided. Numeri",
    "link": "https://arxiv.org/abs/2402.08022",
    "context": "Title: Leveraging Digital Cousins for Ensemble Q-Learning in Large-Scale Wireless Networks\nAbstract: Optimizing large-scale wireless networks, including optimal resource management, power allocation, and throughput maximization, is inherently challenging due to their non-observable system dynamics and heterogeneous and complex nature. Herein, a novel ensemble Q-learning algorithm that addresses the performance and complexity challenges of the traditional Q-learning algorithm for optimizing wireless networks is presented. Ensemble learning with synthetic Markov Decision Processes is tailored to wireless networks via new models for approximating large state-space observable wireless networks. In particular, digital cousins are proposed as an extension of the traditional digital twin concept wherein multiple Q-learning algorithms on multiple synthetic Markovian environments are run in parallel and their outputs are fused into a single Q-function. Convergence analyses of key statistics and Q-functions and derivations of upper bounds on the estimation bias and variance are provided. Numeri",
    "path": "papers/24/02/2402.08022.json",
    "total_tokens": 836,
    "translated_title": "在大规模无线网络中利用数字堂兄来进行集成Q-Learning",
    "translated_abstract": "优化大规模无线网络，包括最优资源管理、功率分配和吞吐量最大化，是一项困难的任务，因为它们具有非可观测的系统动态和异构且复杂的特性。本文提出了一种新颖的集成Q-Learning算法，解决了传统Q-Learning算法优化无线网络时面临的性能和复杂性挑战。通过合成马尔可夫决策过程的集成学习，通过新模型逼近大状态空间可观测无线网络。特别地，提出了数字堂兄作为传统数字孪生概念的延伸，其中在多个合成马尔可夫环境上运行多个Q-Learning算法，并将它们的输出融合成一个单独的Q函数。提供了关键统计量和Q函数的收敛分析，以及对估计偏差和方差上限的推导。",
    "tldr": "本文提出了一种针对优化无线网络的传统Q-Learning算法面临的性能和复杂性挑战的新颖的集成Q-Learning算法，在大规模无线网络中利用数字堂兄来逼近可观测无线网络的大状态空间。",
    "en_tdlr": "This paper presents a novel ensemble Q-Learning algorithm to address the performance and complexity challenges of optimizing wireless networks. It leverages digital cousins to approximate the large state-space observable wireless networks in large-scale wireless networks."
}