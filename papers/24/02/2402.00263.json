{
    "title": "Does \\textsc{DetectGPT} Fully Utilize Perturbation? Selective Perturbation on Model-Based Contrastive Learning Detector would be Better",
    "abstract": "The burgeoning capabilities of large language models (LLMs) have raised growing concerns about abuse. DetectGPT, a zero-shot metric-based unsupervised machine-generated text detector, first introduces perturbation and shows great performance improvement. However, DetectGPT's random perturbation strategy might introduce noise, limiting the distinguishability and further performance improvements. Moreover, its logit regression module relies on setting the threshold, which harms the generalizability and applicability of individual or small-batch inputs. Hence, we propose a novel detector, \\modelname{}, which uses selective strategy perturbation to relieve the important information loss caused by random masking, and multi-pair contrastive learning to capture the implicit pattern information during perturbation, facilitating few-shot performance. The experiments show that \\modelname{} outperforms the SOTA method by 1.20\\% in accuracy on average on four public datasets. We further analyze th",
    "link": "https://arxiv.org/abs/2402.00263",
    "context": "Title: Does \\textsc{DetectGPT} Fully Utilize Perturbation? Selective Perturbation on Model-Based Contrastive Learning Detector would be Better\nAbstract: The burgeoning capabilities of large language models (LLMs) have raised growing concerns about abuse. DetectGPT, a zero-shot metric-based unsupervised machine-generated text detector, first introduces perturbation and shows great performance improvement. However, DetectGPT's random perturbation strategy might introduce noise, limiting the distinguishability and further performance improvements. Moreover, its logit regression module relies on setting the threshold, which harms the generalizability and applicability of individual or small-batch inputs. Hence, we propose a novel detector, \\modelname{}, which uses selective strategy perturbation to relieve the important information loss caused by random masking, and multi-pair contrastive learning to capture the implicit pattern information during perturbation, facilitating few-shot performance. The experiments show that \\modelname{} outperforms the SOTA method by 1.20\\% in accuracy on average on four public datasets. We further analyze th",
    "path": "papers/24/02/2402.00263.json",
    "total_tokens": 906,
    "translated_title": "DetectGPT是否充分利用了扰动？基于模型对比学习的选择性扰动会更好",
    "translated_abstract": "大型语言模型的不断发展引发了对其滥用的增长关注。DetectGPT是一种零-shot基于度量的无监督机器生成文本检测器，首次引入了扰动并展现了巨大的性能提升。然而，DetectGPT的随机扰动策略可能会引入噪声，限制了可区分性和进一步的性能提升。此外，它的逻辑回归模块依赖于设置阈值，这会影响个体或小批量输入的泛化性和适用性。因此，我们提出了一种新颖的检测器，模型名，它使用选择性策略扰动来缓解随机屏蔽所引起的重要信息丢失，并利用多对比学习捕捉扰动期间的隐含模式信息，便于少量样本的性能提升。实验结果表明，模型名在四个公共数据集上的平均准确率比SOTA方法高出1.20\\%。我们进一步分析了...",
    "tldr": "我们提出了一种新颖的检测器，模型名，它使用选择性策略扰动和多对比学习，在减少随机屏蔽引起的信息丢失的同时，进一步提升少样本和个体输入的性能。"
}