{
    "title": "PAL: Proxy-Guided Black-Box Attack on Large Language Models",
    "abstract": "arXiv:2402.09674v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have surged in popularity in recent months, but they have demonstrated concerning capabilities to generate harmful content when manipulated. While techniques like safety fine-tuning aim to minimize harmful use, recent works have shown that LLMs remain vulnerable to attacks that elicit toxic responses. In this work, we introduce the Proxy-Guided Attack on LLMs (PAL), the first optimization-based attack on LLMs in a black-box query-only setting. In particular, it relies on a surrogate model to guide the optimization and a sophisticated loss designed for real-world LLM APIs. Our attack achieves 84% attack success rate (ASR) on GPT-3.5-Turbo and 48% on Llama-2-7B, compared to 4% for the current state of the art. We also propose GCG++, an improvement to the GCG attack that reaches 94% ASR on white-box Llama-2-7B, and the Random-Search Attack on LLMs (RAL), a strong but simple baseline for query-based attacks. We",
    "link": "https://arxiv.org/abs/2402.09674",
    "context": "Title: PAL: Proxy-Guided Black-Box Attack on Large Language Models\nAbstract: arXiv:2402.09674v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have surged in popularity in recent months, but they have demonstrated concerning capabilities to generate harmful content when manipulated. While techniques like safety fine-tuning aim to minimize harmful use, recent works have shown that LLMs remain vulnerable to attacks that elicit toxic responses. In this work, we introduce the Proxy-Guided Attack on LLMs (PAL), the first optimization-based attack on LLMs in a black-box query-only setting. In particular, it relies on a surrogate model to guide the optimization and a sophisticated loss designed for real-world LLM APIs. Our attack achieves 84% attack success rate (ASR) on GPT-3.5-Turbo and 48% on Llama-2-7B, compared to 4% for the current state of the art. We also propose GCG++, an improvement to the GCG attack that reaches 94% ASR on white-box Llama-2-7B, and the Random-Search Attack on LLMs (RAL), a strong but simple baseline for query-based attacks. We",
    "path": "papers/24/02/2402.09674.json",
    "total_tokens": 956,
    "translated_title": "PAL：对大型语言模型的代理引导黑盒攻击",
    "translated_abstract": "大型语言模型（LLMs）近几个月来越来越受欢迎，但在被操纵时它们展示出的危险能力令人担忧。尽管安全微调等技术旨在最小化有害使用，但最近的研究表明，LLMs仍然容易受到引发有毒回应的攻击。在这项工作中，我们引入了对LLMs的代理引导攻击（PAL），这是第一个基于优化的对LLMs的黑盒仅查询攻击。具体而言，它依赖于一个替代模型来引导优化过程，并采用了针对真实世界LLM API设计的复杂损失函数。我们的攻击在GPT-3.5-Turbo上达到84%的攻击成功率（ASR），在Llama-2-7B上达到48%，而目前最先进的方法仅为4%。我们还提出了GCG++，这是对GCG攻击的改进，在白盒Llama-2-7B上达到了94%的ASR，以及基于查询的攻击的强有力但简单的基准方法——LLMs上的随机搜索攻击（RAL）。",
    "tldr": "PAL是第一个黑盒查询攻击大型语言模型的优化算法，通过代理模型引导优化过程，并使用复杂的损失函数，取得了较高的攻击成功率。",
    "en_tdlr": "PAL is the first optimization-based black-box attack on large language models, it achieves high attack success rate by using a proxy model to guide the optimization process and employing a sophisticated loss function."
}