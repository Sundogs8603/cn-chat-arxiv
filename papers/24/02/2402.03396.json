{
    "title": "UniTSyn: A Large-Scale Dataset Capable of Enhancing the Prowess of Large Language Models for Program Testing",
    "abstract": "The remarkable capability of large language models (LLMs) in generating high-quality code has drawn increasing attention in the software testing community. However, existing code LLMs often demonstrate unsatisfactory capabilities in generating accurate and complete tests since they were trained on code snippets collected without differentiating between code for testing purposes and other code. In this paper, we present a large-scale dataset UniTSyn, which is capable of enhancing the prowess of LLMs for Unit Test Synthesis. Associating tests with the tested functions is crucial for LLMs to infer the expected behavior and the logic paths to be verified. By leveraging Language Server Protocol, UniTSyn achieves the challenging goal of collecting focal-test pairs without per-project execution setups or per-language heuristics that tend to be fragile and difficult to scale. It contains 2.7 million focal-test pairs across five mainstream programming languages, making it possible to be utilize",
    "link": "https://arxiv.org/abs/2402.03396",
    "context": "Title: UniTSyn: A Large-Scale Dataset Capable of Enhancing the Prowess of Large Language Models for Program Testing\nAbstract: The remarkable capability of large language models (LLMs) in generating high-quality code has drawn increasing attention in the software testing community. However, existing code LLMs often demonstrate unsatisfactory capabilities in generating accurate and complete tests since they were trained on code snippets collected without differentiating between code for testing purposes and other code. In this paper, we present a large-scale dataset UniTSyn, which is capable of enhancing the prowess of LLMs for Unit Test Synthesis. Associating tests with the tested functions is crucial for LLMs to infer the expected behavior and the logic paths to be verified. By leveraging Language Server Protocol, UniTSyn achieves the challenging goal of collecting focal-test pairs without per-project execution setups or per-language heuristics that tend to be fragile and difficult to scale. It contains 2.7 million focal-test pairs across five mainstream programming languages, making it possible to be utilize",
    "path": "papers/24/02/2402.03396.json",
    "total_tokens": 874,
    "translated_title": "UniTSyn：一个可增强大型语言模型在程序测试中的能力的大规模数据集",
    "translated_abstract": "大型语言模型（LLM）在生成高质量代码方面的出色能力已经引起了软件测试社区的广泛关注。然而，现有的代码LLM在生成准确和完整的测试方面往往表现不佳，因为它们是在不区分测试目的代码和其他代码的情况下进行训练的。在本文中，我们提出了一个大规模数据集UniTSyn，它能够增强LLM在单元测试合成方面的能力。将测试与被测试函数进行关联对于LLM推断预期行为和要验证的逻辑路径至关重要。通过利用语言服务器协议，UniTSyn实现了在没有每个项目执行设置或易碎且难以扩展的每个语言启发式的情况下收集焦点测试对的挑战目标。它包含了五种主流编程语言的270万个焦点测试对，使其能够被应用于优化大型语言模型的能力。",
    "tldr": "本研究提出了UniTSyn，一个大型数据集，可以增强大型语言模型在程序测试中的能力。通过关联测试和被测试函数，UniTSyn能够提高模型在生成准确和完整的测试方面的表现。"
}