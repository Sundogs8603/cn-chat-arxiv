{
    "title": "Self-Debiasing Large Language Models: Zero-Shot Recognition and Reduction of Stereotypes",
    "abstract": "Large language models (LLMs) have shown remarkable advances in language generation and understanding but are also prone to exhibiting harmful social biases. While recognition of these behaviors has generated an abundance of bias mitigation techniques, most require modifications to the training data, model parameters, or decoding strategy, which may be infeasible without access to a trainable model. In this work, we leverage the zero-shot capabilities of LLMs to reduce stereotyping in a technique we introduce as zero-shot self-debiasing. With two approaches, self-debiasing via explanation and self-debiasing via reprompting, we show that self-debiasing can significantly reduce the degree of stereotyping across nine different social groups while relying only on the LLM itself and a simple prompt, with explanations correctly identifying invalid assumptions and reprompting delivering the greatest reductions in bias. We hope this work opens inquiry into other zero-shot techniques for bias mi",
    "link": "https://arxiv.org/abs/2402.01981",
    "context": "Title: Self-Debiasing Large Language Models: Zero-Shot Recognition and Reduction of Stereotypes\nAbstract: Large language models (LLMs) have shown remarkable advances in language generation and understanding but are also prone to exhibiting harmful social biases. While recognition of these behaviors has generated an abundance of bias mitigation techniques, most require modifications to the training data, model parameters, or decoding strategy, which may be infeasible without access to a trainable model. In this work, we leverage the zero-shot capabilities of LLMs to reduce stereotyping in a technique we introduce as zero-shot self-debiasing. With two approaches, self-debiasing via explanation and self-debiasing via reprompting, we show that self-debiasing can significantly reduce the degree of stereotyping across nine different social groups while relying only on the LLM itself and a simple prompt, with explanations correctly identifying invalid assumptions and reprompting delivering the greatest reductions in bias. We hope this work opens inquiry into other zero-shot techniques for bias mi",
    "path": "papers/24/02/2402.01981.json",
    "total_tokens": 985,
    "translated_title": "自我去偏差的大型语言模型：零-shot识别和降低刻板印象",
    "translated_abstract": "大型语言模型(LLMs)在语言生成和理解方面表现出了显著的进展，但也容易展示出有害的社会偏见。尽管已经提出了许多偏见缓解技术，但大多数需要对训练数据、模型参数或解码策略进行修改，这在没有可训练模型的情况下可能是不可行的。在这项工作中，我们利用LLMs的零-shot能力，引入了一种称为零-shot自我去偏差的技术来减少刻板印象。通过两种方法，即解释自我去偏差和重启自我去偏差，我们展示了自我去偏差可以显著减少九个不同社会群体的刻板印象程度，只依赖于LLM自身和简单的提示，其中解释正确地识别出无效的假设，而重启则产生了最大的偏见减少效果。我们希望这项工作能够开启对其他零-shot偏见缓解技术的研究。",
    "tldr": "本研究利用大型语言模型的零-shot能力提出了一种自我去偏差的技术，通过解释和重启两种方法，成功减少了九个不同社会群体的刻板印象程度，该技术不需要对训练数据、模型参数或解码策略进行修改，希望能启发其他零-shot偏见缓解技术的研究。"
}