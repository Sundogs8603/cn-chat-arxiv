{
    "title": "Empowering Federated Learning for Massive Models with NVIDIA FLARE",
    "abstract": "In the ever-evolving landscape of artificial intelligence (AI) and large language models (LLMs), handling and leveraging data effectively has become a critical challenge. Most state-of-the-art machine learning algorithms are data-centric. However, as the lifeblood of model performance, necessary data cannot always be centralized due to various factors such as privacy, regulation, geopolitics, copyright issues, and the sheer effort required to move vast datasets. In this paper, we explore how federated learning enabled by NVIDIA FLARE can address these challenges with easy and scalable integration capabilities, enabling parameter-efficient and full supervised fine-tuning of LLMs for natural language processing and biopharmaceutical applications to enhance their accuracy and robustness.",
    "link": "https://arxiv.org/abs/2402.07792",
    "context": "Title: Empowering Federated Learning for Massive Models with NVIDIA FLARE\nAbstract: In the ever-evolving landscape of artificial intelligence (AI) and large language models (LLMs), handling and leveraging data effectively has become a critical challenge. Most state-of-the-art machine learning algorithms are data-centric. However, as the lifeblood of model performance, necessary data cannot always be centralized due to various factors such as privacy, regulation, geopolitics, copyright issues, and the sheer effort required to move vast datasets. In this paper, we explore how federated learning enabled by NVIDIA FLARE can address these challenges with easy and scalable integration capabilities, enabling parameter-efficient and full supervised fine-tuning of LLMs for natural language processing and biopharmaceutical applications to enhance their accuracy and robustness.",
    "path": "papers/24/02/2402.07792.json",
    "total_tokens": 781,
    "translated_title": "使用NVIDIA FLARE来增强大规模模型的联邦学习",
    "translated_abstract": "在人工智能和大型语言模型的不断发展中，有效处理和利用数据已成为一个关键挑战。大多数最先进的机器学习算法都是以数据为中心的。然而，由于隐私、监管、地缘政治、版权问题以及移动大型数据集所需的巨大工作量等各种因素，必要的数据并不总是能够集中存储。在本文中，我们探讨了通过NVIDIA FLARE实现的联邦学习如何应对这些挑战，具备易于扩展集成的能力，使得自然语言处理和生物药物应用中的大型语言模型能够进行参数高效和全面监督微调，以提高其准确性和鲁棒性。",
    "tldr": "本研究探索了如何利用NVIDIA FLARE的联邦学习能力，解决了处理和利用分布式数据的挑战，并通过参数高效和全面监督微调大型语言模型，提高了自然语言处理和生物药物应用的准确性和鲁棒性。",
    "en_tdlr": "This paper explores how federated learning enabled by NVIDIA FLARE addresses challenges in handling and leveraging distributed data, and enhances the accuracy and robustness of large language models for natural language processing and biopharmaceutical applications through parameter-efficient and fully supervised fine-tuning."
}