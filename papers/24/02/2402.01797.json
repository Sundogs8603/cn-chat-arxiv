{
    "title": "Robust support vector machines via conic optimization",
    "abstract": "We consider the problem of learning support vector machines robust to uncertainty. It has been established in the literature that typical loss functions, including the hinge loss, are sensible to data perturbations and outliers, thus performing poorly in the setting considered. In contrast, using the 0-1 loss or a suitable non-convex approximation results in robust estimators, at the expense of large computational costs. In this paper we use mixed-integer optimization techniques to derive a new loss function that better approximates the 0-1 loss compared with existing alternatives, while preserving the convexity of the learning problem. In our computational results, we show that the proposed estimator is competitive with the standard SVMs with the hinge loss in outlier-free regimes and better in the presence of outliers.",
    "link": "https://arxiv.org/abs/2402.01797",
    "context": "Title: Robust support vector machines via conic optimization\nAbstract: We consider the problem of learning support vector machines robust to uncertainty. It has been established in the literature that typical loss functions, including the hinge loss, are sensible to data perturbations and outliers, thus performing poorly in the setting considered. In contrast, using the 0-1 loss or a suitable non-convex approximation results in robust estimators, at the expense of large computational costs. In this paper we use mixed-integer optimization techniques to derive a new loss function that better approximates the 0-1 loss compared with existing alternatives, while preserving the convexity of the learning problem. In our computational results, we show that the proposed estimator is competitive with the standard SVMs with the hinge loss in outlier-free regimes and better in the presence of outliers.",
    "path": "papers/24/02/2402.01797.json",
    "total_tokens": 844,
    "translated_title": "鲁棒支持向量机的锥优化方法",
    "translated_abstract": "我们考虑了在不确定性条件下学习鲁棒支持向量机的问题。文献中已经证明，典型的损失函数，包括铰链损失，对数据扰动和异常值非常敏感，在该设置下表现不佳。相比之下，使用0-1损失或适当的非凸逼近可以得到鲁棒的估计，但代价是计算成本较高。我们使用混合整数优化技术导出了一个新的损失函数，与现有的选择相比更好地逼近了0-1损失，同时保持了学习问题的凸性。在我们的计算结果中，我们展示了所提出的估计器在无异常值的情况下与带铰链损失的标准SVMs相竞争，在存在异常值的情况下更优秀。",
    "tldr": "本文通过混合整数优化技术提出了一种新的损失函数，用于学习鲁棒支持向量机。与现有的方法相比，该方法更好地逼近了0-1损失，同时保持了学习问题的凸性。在实验中表现与标准SVMs相竞争，在存在异常值的情况下表现更优秀。"
}