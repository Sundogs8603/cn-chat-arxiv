{
    "title": "Do Large Language Models Mirror Cognitive Language Processing?",
    "abstract": "arXiv:2402.18023v1 Announce Type: new  Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in text comprehension and logical reasoning, achiving or even surpassing human-level performance in numerous cognition tasks. As LLMs are trained from massive textual outputs of human language cognition, it is natural to ask whether LLMs mirror cognitive language processing. Or to what extend LLMs resemble cognitive language processing? In this paper, we propose a novel method that bridge between LLM representations and human cognition signals to evaluate how effectively LLMs simulate cognitive language processing. We employ Representational Similarity Analysis (RSA) to mearsure the alignment between 16 mainstream LLMs and fMRI signals of the brain. We empirically investigate the impact of a variety of factors (e.g., model scaling, alignment training, instruction appending) on such LLM-brain alignment. Experimental results indicate that model scaling is positively cor",
    "link": "https://arxiv.org/abs/2402.18023",
    "context": "Title: Do Large Language Models Mirror Cognitive Language Processing?\nAbstract: arXiv:2402.18023v1 Announce Type: new  Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in text comprehension and logical reasoning, achiving or even surpassing human-level performance in numerous cognition tasks. As LLMs are trained from massive textual outputs of human language cognition, it is natural to ask whether LLMs mirror cognitive language processing. Or to what extend LLMs resemble cognitive language processing? In this paper, we propose a novel method that bridge between LLM representations and human cognition signals to evaluate how effectively LLMs simulate cognitive language processing. We employ Representational Similarity Analysis (RSA) to mearsure the alignment between 16 mainstream LLMs and fMRI signals of the brain. We empirically investigate the impact of a variety of factors (e.g., model scaling, alignment training, instruction appending) on such LLM-brain alignment. Experimental results indicate that model scaling is positively cor",
    "path": "papers/24/02/2402.18023.json",
    "total_tokens": 827,
    "translated_title": "大型语言模型是否反映认知语言处理？",
    "translated_abstract": "大型语言模型（LLMs）在文本理解和逻辑推理方面展现出卓越能力，甚至在许多认知任务中实现甚至超越人类水平的表现。由于LLMs是从人类语言认知的大量文本产出中训练出来的，自然而然地会问LLMs是否反映认知语言处理，或LLMs在多大程度上类似于认知语言处理。本文提出了一种新颖的方法，用于连接LLMs表征和人类认知信号，以评估LLMs如何有效地模拟认知语言处理。我们采用表征相似性分析（RSA）来衡量16种主流LLMs与大脑fMRI信号之间的对齐程度。我们在实验中探讨了各种因素（例如模型规模、对齐训练、指导附加）对LLM-大脑对齐的影响。实验结果表明，模型规模与正相关",
    "tldr": "本文提出了一种新颖方法，通过将大型语言模型（LLMs）的表示与人类认知信号联系起来，评估LLMs模拟认知语言处理的效果。",
    "en_tdlr": "This paper introduces a novel method to evaluate how effectively large language models (LLMs) simulate cognitive language processing by bridging LLM representations with human cognition signals."
}