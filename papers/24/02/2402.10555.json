{
    "title": "SPAR: Personalized Content-Based Recommendation via Long Engagement Attention",
    "abstract": "arXiv:2402.10555v1 Announce Type: cross  Abstract: Leveraging users' long engagement histories is essential for personalized content recommendations. The success of pretrained language models (PLMs) in NLP has led to their use in encoding user histories and candidate items, framing content recommendations as textual semantic matching tasks. However, existing works still struggle with processing very long user historical text and insufficient user-item interaction. In this paper, we introduce a content-based recommendation framework, SPAR, which effectively tackles the challenges of holistic user interest extraction from the long user engagement history. It achieves so by leveraging PLM, poly-attention layers and attention sparsity mechanisms to encode user's history in a session-based manner. The user and item side features are sufficiently fused for engagement prediction while maintaining standalone representations for both sides, which is efficient for practical model deployment. Mor",
    "link": "https://arxiv.org/abs/2402.10555",
    "context": "Title: SPAR: Personalized Content-Based Recommendation via Long Engagement Attention\nAbstract: arXiv:2402.10555v1 Announce Type: cross  Abstract: Leveraging users' long engagement histories is essential for personalized content recommendations. The success of pretrained language models (PLMs) in NLP has led to their use in encoding user histories and candidate items, framing content recommendations as textual semantic matching tasks. However, existing works still struggle with processing very long user historical text and insufficient user-item interaction. In this paper, we introduce a content-based recommendation framework, SPAR, which effectively tackles the challenges of holistic user interest extraction from the long user engagement history. It achieves so by leveraging PLM, poly-attention layers and attention sparsity mechanisms to encode user's history in a session-based manner. The user and item side features are sufficiently fused for engagement prediction while maintaining standalone representations for both sides, which is efficient for practical model deployment. Mor",
    "path": "papers/24/02/2402.10555.json",
    "total_tokens": 833,
    "translated_title": "SPAR：通过长期参与注意力实现个性化基于内容的推荐",
    "translated_abstract": "利用用户长期参与历史对个性化内容推荐至关重要。预训练语言模型（PLMs）在自然语言处理领域的成功导致它们被用于编码用户历史和候选项，将内容推荐视为文本语义匹配任务。然而，现有工作仍然在处理非常长的用户历史文本和不足的用户-物品交互方面存在困难。本文介绍了一种基于内容的推荐框架SPAR，有效应对了从长期用户参与历史中提取全面用户兴趣的挑战。它通过利用PLM、多注意力层和注意力稀疏机制以会话为基础对用户的历史进行编码。用户和物品侧特征被充分融合进行参与预测，同时保持双方的独立表示，这对于实际模型部署是有效的。",
    "tldr": "SPAR是一个基于内容的推荐框架，通过利用PLM、多注意力层和注意力稀疏机制，在会话级别有效地处理长期用户参与历史，提取全面用户兴趣，实现个性化推荐。"
}