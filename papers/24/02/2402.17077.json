{
    "title": "Parallelized Spatiotemporal Binding",
    "abstract": "arXiv:2402.17077v1 Announce Type: new  Abstract: While modern best practices advocate for scalable architectures that support long-range interactions, object-centric models are yet to fully embrace these architectures. In particular, existing object-centric models for handling sequential inputs, due to their reliance on RNN-based implementation, show poor stability and capacity and are slow to train on long sequences. We introduce Parallelizable Spatiotemporal Binder or PSB, the first temporally-parallelizable slot learning architecture for sequential inputs. Unlike conventional RNN-based approaches, PSB produces object-centric representations, known as slots, for all time-steps in parallel. This is achieved by refining the initial slots across all time-steps through a fixed number of layers equipped with causal attention. By capitalizing on the parallelism induced by our architecture, the proposed model exhibits a significant boost in efficiency. In experiments, we test PSB extensivel",
    "link": "https://arxiv.org/abs/2402.17077",
    "context": "Title: Parallelized Spatiotemporal Binding\nAbstract: arXiv:2402.17077v1 Announce Type: new  Abstract: While modern best practices advocate for scalable architectures that support long-range interactions, object-centric models are yet to fully embrace these architectures. In particular, existing object-centric models for handling sequential inputs, due to their reliance on RNN-based implementation, show poor stability and capacity and are slow to train on long sequences. We introduce Parallelizable Spatiotemporal Binder or PSB, the first temporally-parallelizable slot learning architecture for sequential inputs. Unlike conventional RNN-based approaches, PSB produces object-centric representations, known as slots, for all time-steps in parallel. This is achieved by refining the initial slots across all time-steps through a fixed number of layers equipped with causal attention. By capitalizing on the parallelism induced by our architecture, the proposed model exhibits a significant boost in efficiency. In experiments, we test PSB extensivel",
    "path": "papers/24/02/2402.17077.json",
    "total_tokens": 848,
    "translated_title": "并行化时空绑定",
    "translated_abstract": "尽管现代最佳实践提倡支持远程交互的可扩展体系结构，但面向对象的模型仍未完全采用这些体系结构。具体而言，由于现有的面向对象模型依赖于基于RNN的实现，导致其稳定性和容量较差，并且在长序列上训练缓慢。我们引入了并行化时空绑定器或PSB，这是面向序列输入的第一个时间并行可学习体系结构。与传统的基于RNN的方法不同，PSB同时为所有时间步生成对象中心化表示，称为slots。通过在具有因果关注力的固定层数上精细化初始slots，我们得以在所有时间步骤上实现并行。通过充分利用我们体系结构所引入的并行性，所提出的模型在效率上显示出显著提升。在实验中，我们对PSB进行了广泛测试。",
    "tldr": "PSB是第一个针对序列输入进行时空并行化的槽学习架构，通过并行处理所有时间步骤中的对象中心表示，利用固定层数和因果关注力，显著提高了效率。"
}