{
    "title": "Subobject-level Image Tokenization",
    "abstract": "arXiv:2402.14327v1 Announce Type: cross  Abstract: Transformer-based vision models typically tokenize images into fixed-size square patches as input units, which lacks the adaptability to image content and overlooks the inherent pixel grouping structure. Inspired by the subword tokenization widely adopted in language models, we propose an image tokenizer at a subobject level, where the subobjects are represented by semantically meaningful image segments obtained by segmentation models (e.g., segment anything models). To implement a learning system based on subobject tokenization, we first introduced a Sequence-to-sequence AutoEncoder (SeqAE) to compress subobject segments of varying sizes and shapes into compact embedding vectors, then fed the subobject embeddings into a large language model for vision language learning. Empirical results demonstrated that our subobject-level tokenization significantly facilitates efficient learning of translating images into object and attribute descr",
    "link": "https://arxiv.org/abs/2402.14327",
    "context": "Title: Subobject-level Image Tokenization\nAbstract: arXiv:2402.14327v1 Announce Type: cross  Abstract: Transformer-based vision models typically tokenize images into fixed-size square patches as input units, which lacks the adaptability to image content and overlooks the inherent pixel grouping structure. Inspired by the subword tokenization widely adopted in language models, we propose an image tokenizer at a subobject level, where the subobjects are represented by semantically meaningful image segments obtained by segmentation models (e.g., segment anything models). To implement a learning system based on subobject tokenization, we first introduced a Sequence-to-sequence AutoEncoder (SeqAE) to compress subobject segments of varying sizes and shapes into compact embedding vectors, then fed the subobject embeddings into a large language model for vision language learning. Empirical results demonstrated that our subobject-level tokenization significantly facilitates efficient learning of translating images into object and attribute descr",
    "path": "papers/24/02/2402.14327.json",
    "total_tokens": 816,
    "translated_title": "子对象级图像标记化",
    "translated_abstract": "基于Transformer的视觉模型通常将图像标记为固定大小的方形补丁作为输入单元，这种方法缺乏对图像内容的适应性，并忽略了固有的像素分组结构。受语言模型广泛采用的子词标记化启发，我们提出了一种在子对象级别进行图像标记的方法，其中子对象由通过分割模型（例如，分割任何模型）获得的具有语义意义的图像段表示。为了实现基于子对象标记化的学习系统，我们首先引入了一个序列自编码器（SeqAE），将不同大小和形状的子对象段压缩为紧凑的嵌入向量，然后将子对象嵌入馈送到大型语言模型进行视觉语言学习。实证结果表明，我们的子对象级别标记化显著促进了有效地将图像转换为对象和属性描述的学习。",
    "tldr": "提出一种在子对象级别进行图像标记的方法，通过序列自编码器将子对象段压缩为紧凑的嵌入向量，实现了有效地将图像转换为对象和属性描述的学习。",
    "en_tdlr": "Proposed a method for image tokenization at a subobject level, compressing subobject segments into compact embedding vectors using a Sequence-to-sequence AutoEncoder, facilitating efficient learning of translating images into object and attribute descriptions."
}