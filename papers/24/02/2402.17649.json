{
    "title": "Beyond prompt brittleness: Evaluating the reliability and consistency of political worldviews in LLMs",
    "abstract": "arXiv:2402.17649v1 Announce Type: new  Abstract: Due to the widespread use of large language models (LLMs) in ubiquitous systems, we need to understand whether they embed a specific worldview and what these views reflect. Recent studies report that, prompted with political questionnaires, LLMs show left-liberal leanings. However, it is as yet unclear whether these leanings are reliable (robust to prompt variations) and whether the leaning is consistent across policies and political leaning. We propose a series of tests which assess the reliability and consistency of LLMs' stances on political statements based on a dataset of voting-advice questionnaires collected from seven EU countries and annotated for policy domains. We study LLMs ranging in size from 7B to 70B parameters and find that their reliability increases with parameter count. Larger models show overall stronger alignment with left-leaning parties but differ among policy programs: They evince a (left-wing) positive stance to",
    "link": "https://arxiv.org/abs/2402.17649",
    "context": "Title: Beyond prompt brittleness: Evaluating the reliability and consistency of political worldviews in LLMs\nAbstract: arXiv:2402.17649v1 Announce Type: new  Abstract: Due to the widespread use of large language models (LLMs) in ubiquitous systems, we need to understand whether they embed a specific worldview and what these views reflect. Recent studies report that, prompted with political questionnaires, LLMs show left-liberal leanings. However, it is as yet unclear whether these leanings are reliable (robust to prompt variations) and whether the leaning is consistent across policies and political leaning. We propose a series of tests which assess the reliability and consistency of LLMs' stances on political statements based on a dataset of voting-advice questionnaires collected from seven EU countries and annotated for policy domains. We study LLMs ranging in size from 7B to 70B parameters and find that their reliability increases with parameter count. Larger models show overall stronger alignment with left-leaning parties but differ among policy programs: They evince a (left-wing) positive stance to",
    "path": "papers/24/02/2402.17649.json",
    "total_tokens": 914,
    "translated_title": "超越提示脆弱性：评估LLMs中政治世界观的可靠性和一致性",
    "translated_abstract": "由于大型语言模型（LLMs）在广泛系统中的使用，我们需要了解它们是否嵌入了特定的世界观以及这些观点所反映的内容。最近的研究报告称，当用政治问卷进行提示时，LLMs表现出左倾自由倾向。然而，目前尚不清楚这些倾向是否可靠（对提示变化稳健）以及这种倾向是否在政策和政治倾向上保持一致。我们提出了一系列测试，评估了基于收集自七个欧盟国家的选举建议问卷并标注为政策领域的数据集上LLMs在政治声明上立场的可靠性和一致性。我们研究了参数从7B到70B的LLMs，并发现它们的可靠性随参数数量增加而增加。更大的模型显示总体上与左倾政党更强的一致性，但在政策方案中有所不同：它们表现出（左倾）积极的立场",
    "tldr": "该研究评估了大型语言模型中的政治世界观的可靠性和一致性，发现他们的可靠性随模型参数数量增加而增加，且在政策方案上有所不同。",
    "en_tdlr": "This study evaluates the reliability and consistency of political worldviews in large language models (LLMs), finding that their reliability increases with model parameter count, and they differ among policy programs."
}