{
    "title": "Assessing generalization capability of text ranking models in Polish",
    "abstract": "arXiv:2402.14318v1 Announce Type: new  Abstract: Retrieval-augmented generation (RAG) is becoming an increasingly popular technique for integrating internal knowledge bases with large language models. In a typical RAG pipeline, three models are used, responsible for the retrieval, reranking, and generation stages. In this article, we focus on the reranking problem for the Polish language, examining the performance of rerankers and comparing their results with available retrieval models. We conduct a comprehensive evaluation of existing models and those trained by us, utilizing a benchmark of 41 diverse information retrieval tasks for the Polish language. The results of our experiments show that most models struggle with out-of-domain generalization. However, a combination of effective optimization method and a large training dataset allows for building rerankers that are both compact in size and capable of generalization. The best of our models establishes a new state-of-the-art for re",
    "link": "https://arxiv.org/abs/2402.14318",
    "context": "Title: Assessing generalization capability of text ranking models in Polish\nAbstract: arXiv:2402.14318v1 Announce Type: new  Abstract: Retrieval-augmented generation (RAG) is becoming an increasingly popular technique for integrating internal knowledge bases with large language models. In a typical RAG pipeline, three models are used, responsible for the retrieval, reranking, and generation stages. In this article, we focus on the reranking problem for the Polish language, examining the performance of rerankers and comparing their results with available retrieval models. We conduct a comprehensive evaluation of existing models and those trained by us, utilizing a benchmark of 41 diverse information retrieval tasks for the Polish language. The results of our experiments show that most models struggle with out-of-domain generalization. However, a combination of effective optimization method and a large training dataset allows for building rerankers that are both compact in size and capable of generalization. The best of our models establishes a new state-of-the-art for re",
    "path": "papers/24/02/2402.14318.json",
    "total_tokens": 858,
    "translated_title": "评估波兰语文本排名模型的泛化能力",
    "translated_abstract": "arXiv:2402.14318v1 公告类型：新抽象：检索增强生成（RAG）正成为将内部知识库与大型语言模型集成的越来越流行的技术。在典型的RAG流水线中，使用三个模型，分别负责检索、重新排名和生成阶段。在本文中，我们专注于波兰语的重新排名问题，研究重新排名器的性能，并将其结果与可用的检索模型进行比较。我们对现有模型和我们训练的模型进行了全面评估，利用了一个由41个多样化信息检索任务组成的波兰语基准。我们实验证明，大多数模型都难以在领域外进行泛化。然而，有效的优化方法和大型训练数据集的结合允许构建既体积小又具有泛化能力的重新排名器。我们最佳的模型为重新建立了重新排名的新技术水平。",
    "tldr": "评估波兰语文本排名模型的泛化能力，研究表明，通过有效的优化方法和大型训练数据集的结合，可以构建既体积小又具有泛化能力的重新排名器。",
    "en_tdlr": "Assessing generalization capability of text ranking models in Polish. The study shows that by combining effective optimization methods and large training datasets, compact yet generalizable rerankers can be built."
}