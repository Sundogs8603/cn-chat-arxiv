{
    "title": "SceMQA: A Scientific College Entrance Level Multimodal Question Answering Benchmark",
    "abstract": "The paper introduces SceMQA, a novel benchmark for scientific multimodal question answering at the college entrance level. It addresses a critical educational phase often overlooked in existing benchmarks, spanning high school to pre-college levels. SceMQA focuses on core science subjects including Mathematics, Physics, Chemistry, and Biology. It features a blend of multiple-choice and free-response formats, ensuring a comprehensive evaluation of AI models' abilities. Additionally, our benchmark provides specific knowledge points for each problem and detailed explanations for each answer. SceMQA also uniquely presents problems with identical contexts but varied questions to facilitate a more thorough and accurate assessment of reasoning capabilities. In the experiment, we evaluate both open-source and close-source state-of-the-art Multimodal Large Language Models (MLLMs), across various experimental settings. The results show that further research and development are needed in developi",
    "link": "https://arxiv.org/abs/2402.05138",
    "context": "Title: SceMQA: A Scientific College Entrance Level Multimodal Question Answering Benchmark\nAbstract: The paper introduces SceMQA, a novel benchmark for scientific multimodal question answering at the college entrance level. It addresses a critical educational phase often overlooked in existing benchmarks, spanning high school to pre-college levels. SceMQA focuses on core science subjects including Mathematics, Physics, Chemistry, and Biology. It features a blend of multiple-choice and free-response formats, ensuring a comprehensive evaluation of AI models' abilities. Additionally, our benchmark provides specific knowledge points for each problem and detailed explanations for each answer. SceMQA also uniquely presents problems with identical contexts but varied questions to facilitate a more thorough and accurate assessment of reasoning capabilities. In the experiment, we evaluate both open-source and close-source state-of-the-art Multimodal Large Language Models (MLLMs), across various experimental settings. The results show that further research and development are needed in developi",
    "path": "papers/24/02/2402.05138.json",
    "total_tokens": 981,
    "translated_title": "SceMQA：一种科学类大学入学级多模态问题回答基准",
    "translated_abstract": "本文介绍了SceMQA，这是一种面向大学入学级科学类多模态问题回答的新型基准。它填补了现有基准中常常被忽视的关键教育阶段，涵盖了高中到大学预科的水平。SceMQA专注于核心科学科目，包括数学、物理学、化学和生物学。它融合了多项选择和自由回答的格式，确保对AI模型的能力进行全面评估。此外，我们的基准为每个问题提供了具体的知识点和详细的答案解释。SceMQA还独特地提供了相同背景但问题不同的问题，以促进对推理能力进行更全面和准确的评估。在实验中，我们对开源和闭源的最新多模态大语言模型（MLLMs）进行了评估，同时考虑了不同的实验设置。结果表明，在开发科学类大学入学级多模态问题回答方面，需要进一步的研究和发展。",
    "tldr": "SceMQA是一种科学类大学入学级多模态问题回答的基准，填补了现有基准中被忽视的教育阶段的空白。它包含核心科学科目，融合了多项选择和自由回答的格式，并提供详细的问题解析和答案解释。该基准还通过相同背景但问题不同的方式，促进了对推理能力更全面和准确的评估。",
    "en_tdlr": "SceMQA is a benchmark for scientific multimodal question answering at the college entrance level that addresses an educational phase often overlooked in existing benchmarks. It includes core science subjects, features a blend of multiple-choice and free-response formats, and provides detailed question analysis and answer explanations. The benchmark also facilitates a more thorough and accurate assessment of reasoning capabilities through presenting problems with identical contexts but varied questions."
}