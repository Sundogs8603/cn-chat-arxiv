{
    "title": "Retrieve Only When It Needs: Adaptive Retrieval Augmentation for Hallucination Mitigation in Large Language Models",
    "abstract": "arXiv:2402.10612v1 Announce Type: new  Abstract: Hallucinations pose a significant challenge for the practical implementation of large language models (LLMs). The utilization of parametric knowledge in generating factual content is constrained by the limited knowledge of LLMs, potentially resulting in internal hallucinations. While incorporating external information can help fill knowledge gaps, it also introduces the risk of irrelevant information, thereby increasing the likelihood of external hallucinations. A careful and balanced integration of the parametric knowledge within LLMs with external information is crucial to alleviate hallucinations. In this study, we present Rowen, a novel approach that enhances LLMs with a selective retrieval augmentation process tailored to address hallucinated outputs. This process is governed by a multilingual semantic-aware detection module, which evaluates the consistency of the perturbed responses across various languages for the same queries. Up",
    "link": "https://arxiv.org/abs/2402.10612",
    "context": "Title: Retrieve Only When It Needs: Adaptive Retrieval Augmentation for Hallucination Mitigation in Large Language Models\nAbstract: arXiv:2402.10612v1 Announce Type: new  Abstract: Hallucinations pose a significant challenge for the practical implementation of large language models (LLMs). The utilization of parametric knowledge in generating factual content is constrained by the limited knowledge of LLMs, potentially resulting in internal hallucinations. While incorporating external information can help fill knowledge gaps, it also introduces the risk of irrelevant information, thereby increasing the likelihood of external hallucinations. A careful and balanced integration of the parametric knowledge within LLMs with external information is crucial to alleviate hallucinations. In this study, we present Rowen, a novel approach that enhances LLMs with a selective retrieval augmentation process tailored to address hallucinated outputs. This process is governed by a multilingual semantic-aware detection module, which evaluates the consistency of the perturbed responses across various languages for the same queries. Up",
    "path": "papers/24/02/2402.10612.json",
    "total_tokens": 840,
    "translated_title": "仅在需要时检索：大型语言模型中的适应性检索增强以减轻幻觉",
    "translated_abstract": "幻觉对于大型语言模型（LLMs）的实际实施构成了显著挑战。生成事实内容时利用参数化知识受到LLMs有限知识的限制，可能导致内部幻觉。虽然整合外部信息可以填补知识空白，但也会引入无关信息的风险，从而增加外部幻觉的可能性。在LLMs内部平衡地整合参数化知识和外部信息对缓解幻觉至关重要。本研究中，我们提出Rowen，一种增强LLMs的新方法，其中包括一种选择性检索增强过程，旨在解决幻觉输出。该过程由一个多语义感知检测模块管理，该模块评估了对相同查询在不同语言中的扰动响应的一致性。",
    "tldr": "本研究提出了一种新方法Rowen，通过选择性检索增强过程，采用多语义感知检测模块来平衡参数化知识和外部信息，以减轻大型语言模型中的幻觉问题。",
    "en_tdlr": "This study presents a novel approach called Rowen, which balances parametric knowledge and external information through a selective retrieval augmentation process guided by a multilingual semantic-aware detection module to mitigate hallucinations in large language models."
}