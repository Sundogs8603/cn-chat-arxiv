{
    "title": "ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling",
    "abstract": "By combining natural language understanding and the generation capabilities and breadth of knowledge of large language models with image perception, recent large vision language models (LVLMs) have shown unprecedented reasoning capabilities in the real world. However, the generated text often suffers from inaccurate grounding in the visual input, resulting in errors such as hallucinating nonexistent scene elements, missing significant parts of the scene, and inferring incorrect attributes and relationships between objects. To address these issues, we introduce a novel framework, ViGoR (Visual Grounding Through Fine-Grained Reward Modeling) that utilizes fine-grained reward modeling to significantly enhance the visual grounding of LVLMs over pre-trained baselines. This improvement is efficiently achieved using much cheaper human evaluations instead of full supervisions, as well as automated methods. We show the effectiveness of our approach through numerous metrics on several benchmarks",
    "link": "https://arxiv.org/abs/2402.06118",
    "context": "Title: ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling\nAbstract: By combining natural language understanding and the generation capabilities and breadth of knowledge of large language models with image perception, recent large vision language models (LVLMs) have shown unprecedented reasoning capabilities in the real world. However, the generated text often suffers from inaccurate grounding in the visual input, resulting in errors such as hallucinating nonexistent scene elements, missing significant parts of the scene, and inferring incorrect attributes and relationships between objects. To address these issues, we introduce a novel framework, ViGoR (Visual Grounding Through Fine-Grained Reward Modeling) that utilizes fine-grained reward modeling to significantly enhance the visual grounding of LVLMs over pre-trained baselines. This improvement is efficiently achieved using much cheaper human evaluations instead of full supervisions, as well as automated methods. We show the effectiveness of our approach through numerous metrics on several benchmarks",
    "path": "papers/24/02/2402.06118.json",
    "total_tokens": 851,
    "translated_title": "ViGoR：通过细粒度奖励建模改进大规模视觉语言模型的视觉对接",
    "translated_abstract": "通过将自然语言理解、大语言模型的生成能力和广泛知识与图像感知相结合，最近的大规模视觉语言模型（LVLMs）在现实世界中展示了前所未有的推理能力。然而，生成的文本往往在视觉输入中存在不准确的对接，导致错误，如产生幻觉的不存在场景元素、遗漏重要的场景部分，以及推测对象之间的属性和关系时出现错误。为了解决这些问题，我们引入了一个新颖的框架ViGoR（通过细粒度奖励建模进行视觉对接），它利用细粒度奖励建模来显著提升基于预训练基线的LVLMs的视觉对接能力。这种改进通过使用比完全监督更便宜的人工评估和自动化方法高效实现。我们通过多个基准测试的多个指标展示了我们方法的有效性。",
    "tldr": "ViGoR通过细粒度奖励建模提高了大型视觉语言模型在视觉对接方面的性能，通过人工评估和自动化方法有效地解决了视觉对接中的误差问题。",
    "en_tdlr": "ViGoR improves the visual grounding performance of large vision language models by utilizing fine-grained reward modeling, addressing errors in visual grounding through human evaluations and automated methods."
}