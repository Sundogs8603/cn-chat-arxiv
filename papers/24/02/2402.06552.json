{
    "title": "Deceptive Path Planning via Reinforcement Learning with Graph Neural Networks",
    "abstract": "Deceptive path planning (DPP) is the problem of designing a path that hides its true goal from an outside observer. Existing methods for DPP rely on unrealistic assumptions, such as global state observability and perfect model knowledge, and are typically problem-specific, meaning that even minor changes to a previously solved problem can force expensive computation of an entirely new solution. Given these drawbacks, such methods do not generalize to unseen problem instances, lack scalability to realistic problem sizes, and preclude both on-the-fly tunability of deception levels and real-time adaptivity to changing environments. In this paper, we propose a reinforcement learning (RL)-based scheme for training policies to perform DPP over arbitrary weighted graphs that overcomes these issues. The core of our approach is the introduction of a local perception model for the agent, a new state space representation distilling the key components of the DPP problem, the use of graph neural ne",
    "link": "https://arxiv.org/abs/2402.06552",
    "context": "Title: Deceptive Path Planning via Reinforcement Learning with Graph Neural Networks\nAbstract: Deceptive path planning (DPP) is the problem of designing a path that hides its true goal from an outside observer. Existing methods for DPP rely on unrealistic assumptions, such as global state observability and perfect model knowledge, and are typically problem-specific, meaning that even minor changes to a previously solved problem can force expensive computation of an entirely new solution. Given these drawbacks, such methods do not generalize to unseen problem instances, lack scalability to realistic problem sizes, and preclude both on-the-fly tunability of deception levels and real-time adaptivity to changing environments. In this paper, we propose a reinforcement learning (RL)-based scheme for training policies to perform DPP over arbitrary weighted graphs that overcomes these issues. The core of our approach is the introduction of a local perception model for the agent, a new state space representation distilling the key components of the DPP problem, the use of graph neural ne",
    "path": "papers/24/02/2402.06552.json",
    "total_tokens": 859,
    "translated_title": "使用图神经网络的强化学习进行欺骗性路径规划",
    "translated_abstract": "欺骗性路径规划(DPP)是指设计一条路径，以隐藏其真实目标以免被外部观察者发现。现有的DPP方法依赖于不切实际的假设，如全局状态可观察性和完美的模型知识，并且通常是针对特定问题的，这意味着即使对先前解决的问题进行微小更改也会迫使重新计算整个新解。鉴于这些缺点，这些方法不能泛化到未见过的问题实例，缺乏适应现实问题规模的可扩展性，以及无法调整欺骗程度和实时适应环境变化。在本文中，我们提出了一种基于强化学习(RL)的方案，用于训练策略以在任意加权图上执行DPP，并克服了这些问题。我们方法的核心是引入了一个局部感知模型，一种新的状态空间表示，概括了DPP问题的关键组成部分，并使用了图神经网络。",
    "tldr": "本文提出了一种使用图神经网络的强化学习方法来进行欺骗性路径规划，克服了现有方法的局限性，并且具有普适性和实时适应性。",
    "en_tdlr": "This paper proposes a reinforcement learning approach using graph neural networks for deceptive path planning (DPP), overcoming limitations of existing methods and providing generality and real-time adaptivity."
}