{
    "title": "Extraction of nonlinearity in neural networks and model compression with Koopman operator",
    "abstract": "arXiv:2402.11740v1 Announce Type: new  Abstract: Nonlinearity plays a crucial role in deep neural networks. In this paper, we first investigate the degree to which the nonlinearity of the neural network is essential. For this purpose, we employ the Koopman operator, extended dynamic mode decomposition, and the tensor-train format. The results imply that restricted nonlinearity is enough for the classification of handwritten numbers. Then, we propose a model compression method for deep neural networks, which could be beneficial to handling large networks in resource-constrained environments. Leveraging the Koopman operator, the proposed method enables us to use linear algebra in the internal processing of neural networks. We numerically show that the proposed method performs comparably or better than conventional methods in highly compressed model settings for the handwritten number recognition task.",
    "link": "https://arxiv.org/abs/2402.11740",
    "context": "Title: Extraction of nonlinearity in neural networks and model compression with Koopman operator\nAbstract: arXiv:2402.11740v1 Announce Type: new  Abstract: Nonlinearity plays a crucial role in deep neural networks. In this paper, we first investigate the degree to which the nonlinearity of the neural network is essential. For this purpose, we employ the Koopman operator, extended dynamic mode decomposition, and the tensor-train format. The results imply that restricted nonlinearity is enough for the classification of handwritten numbers. Then, we propose a model compression method for deep neural networks, which could be beneficial to handling large networks in resource-constrained environments. Leveraging the Koopman operator, the proposed method enables us to use linear algebra in the internal processing of neural networks. We numerically show that the proposed method performs comparably or better than conventional methods in highly compressed model settings for the handwritten number recognition task.",
    "path": "papers/24/02/2402.11740.json",
    "total_tokens": 801,
    "translated_title": "利用Koopman算子提取神经网络中的非线性并进行模型压缩",
    "translated_abstract": "非线性在深度神经网络中起着至关重要的作用。在本文中，我们首先调查了神经网络的非线性对分类任务的关键程度。为此，我们采用Koopman算子、扩展动态模态分解和张量列车格式。结果表明，受限非线性已经足以进行手写数字的分类。接着，我们提出了一种用于深度神经网络的模型压缩方法，这对于在资源受限的环境中处理大型网络可能是有益的。利用Koopman算子，所提出的方法使我们可以在神经网络的内部处理中使用线性代数。数值结果表明，所提出的方法在高度压缩模型设置下在手写数字识别任务中的性能要么与传统方法相当，要么更好。",
    "tldr": "本论文使用Koopman算子提取神经网络中的非线性，证明了受限非线性已足够进行手写数字分类，并提出了一种模型压缩方法，能在资源受限环境中处理大型网络。"
}