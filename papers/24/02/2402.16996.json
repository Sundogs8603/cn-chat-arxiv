{
    "title": "Towards Decoding Brain Activity During Passive Listening of Speech",
    "abstract": "arXiv:2402.16996v1 Announce Type: cross  Abstract: The aim of the study is to investigate the complex mechanisms of speech perception and ultimately decode the electrical changes in the brain accruing while listening to speech. We attempt to decode heard speech from intracranial electroencephalographic (iEEG) data using deep learning methods. The goal is to aid the advancement of brain-computer interface (BCI) technology for speech synthesis, and, hopefully, to provide an additional perspective on the cognitive processes of speech perception. This approach diverges from the conventional focus on speech production and instead chooses to investigate neural representations of perceived speech. This angle opened up a complex perspective, potentially allowing us to study more sophisticated neural patterns. Leveraging the power of deep learning models, the research aimed to establish a connection between these intricate neural activities and the corresponding speech sounds. Despite the appro",
    "link": "https://arxiv.org/abs/2402.16996",
    "context": "Title: Towards Decoding Brain Activity During Passive Listening of Speech\nAbstract: arXiv:2402.16996v1 Announce Type: cross  Abstract: The aim of the study is to investigate the complex mechanisms of speech perception and ultimately decode the electrical changes in the brain accruing while listening to speech. We attempt to decode heard speech from intracranial electroencephalographic (iEEG) data using deep learning methods. The goal is to aid the advancement of brain-computer interface (BCI) technology for speech synthesis, and, hopefully, to provide an additional perspective on the cognitive processes of speech perception. This approach diverges from the conventional focus on speech production and instead chooses to investigate neural representations of perceived speech. This angle opened up a complex perspective, potentially allowing us to study more sophisticated neural patterns. Leveraging the power of deep learning models, the research aimed to establish a connection between these intricate neural activities and the corresponding speech sounds. Despite the appro",
    "path": "papers/24/02/2402.16996.json",
    "total_tokens": 888,
    "translated_title": "探索被动听取言语时大脑活动的解码",
    "translated_abstract": "该研究的目的是探究言语知觉的复杂机制，并最终解码在听取言语时大脑中产生的电信号变化。我们尝试利用深度学习方法从颅内脑电图（iEEG）数据中解码所听取的言语。旨在推动脑机接口（BCI）技术在言语合成方面的发展，并希望为言语知觉的认知过程提供额外视角。这种方法偏离了传统对言语产生的关注，转而选择研究所感知的言语的神经表示。这一视角打开了复杂的视野，有可能让我们研究更复杂的神经模式。利用深度学习模型的能力，研究旨在建立这些复杂的神经活动与相应言语声音之间的联系。尽管这种方法 diverges from the conventional focus on speech production and instead chooses to investigate neural representations of perceived speech. 该研究new angle opened up a complex perspective, potentially allowing us to study more sophisticated neural patterns.",
    "tldr": "本研究通过深度学习方法从颅内脑电图数据解码被动听取的言语，旨在推动脑机接口技术的言语合成应用，并提供对言语知觉认知过程的额外视角。"
}