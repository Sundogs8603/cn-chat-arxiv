{
    "title": "A New Era in LLM Security: Exploring Security Concerns in Real-World LLM-based Systems",
    "abstract": "arXiv:2402.18649v1 Announce Type: cross  Abstract: Large Language Model (LLM) systems are inherently compositional, with individual LLM serving as the core foundation with additional layers of objects such as plugins, sandbox, and so on. Along with the great potential, there are also increasing concerns over the security of such probabilistic intelligent systems. However, existing studies on LLM security often focus on individual LLM, but without examining the ecosystem through the lens of LLM systems with other objects (e.g., Frontend, Webtool, Sandbox, and so on). In this paper, we systematically analyze the security of LLM systems, instead of focusing on the individual LLMs. To do so, we build on top of the information flow and formulate the security of LLM systems as constraints on the alignment of the information flow within LLM and between LLM and other objects. Based on this construction and the unique probabilistic nature of LLM, the attack surface of the LLM system can be deco",
    "link": "https://arxiv.org/abs/2402.18649",
    "context": "Title: A New Era in LLM Security: Exploring Security Concerns in Real-World LLM-based Systems\nAbstract: arXiv:2402.18649v1 Announce Type: cross  Abstract: Large Language Model (LLM) systems are inherently compositional, with individual LLM serving as the core foundation with additional layers of objects such as plugins, sandbox, and so on. Along with the great potential, there are also increasing concerns over the security of such probabilistic intelligent systems. However, existing studies on LLM security often focus on individual LLM, but without examining the ecosystem through the lens of LLM systems with other objects (e.g., Frontend, Webtool, Sandbox, and so on). In this paper, we systematically analyze the security of LLM systems, instead of focusing on the individual LLMs. To do so, we build on top of the information flow and formulate the security of LLM systems as constraints on the alignment of the information flow within LLM and between LLM and other objects. Based on this construction and the unique probabilistic nature of LLM, the attack surface of the LLM system can be deco",
    "path": "papers/24/02/2402.18649.json",
    "total_tokens": 825,
    "translated_title": "LLM安全领域的新时代：探讨现实世界LLM系统中的安全问题",
    "translated_abstract": "大型语言模型（LLM）系统在本质上是组合的，单个LLM作为核心基础，带有插件、沙盒等附加层对象。除了巨大潜力外，人们对这种概率智能系统的安全性也日益关注。然而，现有关于LLM安全性的研究通常集中在个别LLM上，而没有通过LLM系统与其他对象（例如前端、Web工具、沙盒等）的视角来检视生态系统。在本文中，我们系统分析了LLM系统的安全性，而不是专注于个别LLM。为此，我们基于信息流构建，并将LLM系统的安全性表述为LLM内部以及LLM与其他对象之间信息流对齐的约束。基于这一构建以及LLM独特的概率性质，LLM系统的攻击面可以被控制。",
    "tldr": "本文系统分析了LLM系统的安全性，引入信息流对齐约束以控制LLM系统的攻击面",
    "en_tdlr": "This paper systematically analyzes the security of LLM systems by introducing constraints on the alignment of information flow to control the attack surface of LLM systems."
}