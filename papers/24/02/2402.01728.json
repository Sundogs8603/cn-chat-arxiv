{
    "title": "Hardware Phi-1.5B: A Large Language Model Encodes Hardware Domain Specific Knowledge",
    "abstract": "In the rapidly evolving semiconductor industry, where research, design, verification, and manufacturing are intricately linked, the potential of Large Language Models to revolutionize hardware design and security verification is immense. The primary challenge, however, lies in the complexity of hardware specific issues that are not adequately addressed by the natural language or software code knowledge typically acquired during the pretraining stage. Additionally, the scarcity of datasets specific to the hardware domain poses a significant hurdle in developing a foundational model. Addressing these challenges, this paper introduces Hardware Phi 1.5B, an innovative large language model specifically tailored for the hardware domain of the semiconductor industry. We have developed a specialized, tiered dataset comprising small, medium, and large subsets and focused our efforts on pretraining using the medium dataset. This approach harnesses the compact yet efficient architecture of the Ph",
    "link": "https://arxiv.org/abs/2402.01728",
    "context": "Title: Hardware Phi-1.5B: A Large Language Model Encodes Hardware Domain Specific Knowledge\nAbstract: In the rapidly evolving semiconductor industry, where research, design, verification, and manufacturing are intricately linked, the potential of Large Language Models to revolutionize hardware design and security verification is immense. The primary challenge, however, lies in the complexity of hardware specific issues that are not adequately addressed by the natural language or software code knowledge typically acquired during the pretraining stage. Additionally, the scarcity of datasets specific to the hardware domain poses a significant hurdle in developing a foundational model. Addressing these challenges, this paper introduces Hardware Phi 1.5B, an innovative large language model specifically tailored for the hardware domain of the semiconductor industry. We have developed a specialized, tiered dataset comprising small, medium, and large subsets and focused our efforts on pretraining using the medium dataset. This approach harnesses the compact yet efficient architecture of the Ph",
    "path": "papers/24/02/2402.01728.json",
    "total_tokens": 855,
    "translated_title": "硬件Phi-1.5B：一个大型语言模型编码硬件领域专业知识",
    "translated_abstract": "在快速发展的半导体产业中，研究、设计、验证和制造是紧密相连的，大型语言模型在革新硬件设计和安全验证方面有巨大潜力。然而，主要挑战在于硬件特定问题的复杂性，这些问题在预训练阶段通常不能充分解决自然语言或软件代码知识。此外，缺乏与硬件领域相关的数据集也是开发基础模型的重要障碍。针对这些挑战，本文介绍了硬件Phi 1.5B，这是一个专门针对半导体产业硬件领域的创新大型语言模型。我们开发了一个专业分层数据集，包括小、中和大型子集，并将重点放在使用中型数据集进行预训练。这种方法充分利用了Ph模型的紧凑但高效的架构。",
    "tldr": "硬件Phi-1.5B是一个专门针对半导体产业硬件领域的大型语言模型，通过预训练和专业分层数据集解决了硬件领域的复杂性和数据稀缺性问题。",
    "en_tdlr": "Hardware Phi-1.5B is a large language model specifically tailored for the hardware domain of the semiconductor industry. It addresses the complexity of hardware-specific issues and the scarcity of datasets through pretraining and a specialized, tiered dataset."
}