{
    "title": "All Language Models Large and Small",
    "abstract": "arXiv:2402.12061v1 Announce Type: cross  Abstract: Many leading language models (LMs) use high-intensity computational resources both during training and execution. This poses the challenge of lowering resource costs for deployment and faster execution of decision-making tasks among others. We introduce a novel plug-and-play LM framework named Language Optimising Network Distribution (LONDI) framework. LONDI learns to selectively employ large LMs only where complex decision-making and reasoning are required while using low-resource LMs everywhere else. LONDI consists of a system of two (off-)policy networks, an LM, a large LM (LLM), and a reinforcement learning module that uses switching controls to quickly learn which system states to call the LLM. We then introduce a variant of LONDI that maintains budget constraints on LLM calls and hence its resource usage. Theoretically, we prove LONDI learns the subset of system states to activate the LLM required to solve the task. We then prove",
    "link": "https://arxiv.org/abs/2402.12061",
    "context": "Title: All Language Models Large and Small\nAbstract: arXiv:2402.12061v1 Announce Type: cross  Abstract: Many leading language models (LMs) use high-intensity computational resources both during training and execution. This poses the challenge of lowering resource costs for deployment and faster execution of decision-making tasks among others. We introduce a novel plug-and-play LM framework named Language Optimising Network Distribution (LONDI) framework. LONDI learns to selectively employ large LMs only where complex decision-making and reasoning are required while using low-resource LMs everywhere else. LONDI consists of a system of two (off-)policy networks, an LM, a large LM (LLM), and a reinforcement learning module that uses switching controls to quickly learn which system states to call the LLM. We then introduce a variant of LONDI that maintains budget constraints on LLM calls and hence its resource usage. Theoretically, we prove LONDI learns the subset of system states to activate the LLM required to solve the task. We then prove",
    "path": "papers/24/02/2402.12061.json",
    "total_tokens": 813,
    "translated_title": "所有语言模型的大小都一样吗？",
    "translated_abstract": "许多领先的语言模型（LMs）在训练和执行过程中使用高强度计算资源，这对于降低部署资源成本和更快执行决策任务等方面提出了挑战。我们引入了一种名为语言优化网络分布（LONDI）框架的新型即插即用LM框架。 LONDI学会了在需要进行复杂决策和推理的地方选择性地使用大的LM，而在其他地方使用低资源的LM。 LONDI由两个（离线）策略网络系统、一个LM、一个大的LM（LLM)和一个使用开关控制快速学习何时调用LLM的强化学习模块组成。 然后，我们介绍了一种在LLM调用和资源使用方面保持预算约束的LONDI变体。 从理论上讲，我们证明了LONDI学习激活所需解决任务的LLM的系统状态子集。",
    "tldr": "LONDI框架可以在需要复杂决策和推理的地方选择性地使用大的语言模型，极大地降低了资源消耗。"
}