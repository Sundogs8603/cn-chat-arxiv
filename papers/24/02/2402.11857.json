{
    "title": "Communication-Efficient Distributed Learning with Local Immediate Error Compensation",
    "abstract": "arXiv:2402.11857v1 Announce Type: new  Abstract: Gradient compression with error compensation has attracted significant attention with the target of reducing the heavy communication overhead in distributed learning. However, existing compression methods either perform only unidirectional compression in one iteration with higher communication cost, or bidirectional compression with slower convergence rate. In this work, we propose the Local Immediate Error Compensated SGD (LIEC-SGD) optimization algorithm to break the above bottlenecks based on bidirectional compression and carefully designed compensation approaches. Specifically, the bidirectional compression technique is to reduce the communication cost, and the compensation technique compensates the local compression error to the model update immediately while only maintaining the global error variable on the server throughout the iterations to boost its efficacy. Theoretically, we prove that LIEC-SGD is superior to previous works in",
    "link": "https://arxiv.org/abs/2402.11857",
    "context": "Title: Communication-Efficient Distributed Learning with Local Immediate Error Compensation\nAbstract: arXiv:2402.11857v1 Announce Type: new  Abstract: Gradient compression with error compensation has attracted significant attention with the target of reducing the heavy communication overhead in distributed learning. However, existing compression methods either perform only unidirectional compression in one iteration with higher communication cost, or bidirectional compression with slower convergence rate. In this work, we propose the Local Immediate Error Compensated SGD (LIEC-SGD) optimization algorithm to break the above bottlenecks based on bidirectional compression and carefully designed compensation approaches. Specifically, the bidirectional compression technique is to reduce the communication cost, and the compensation technique compensates the local compression error to the model update immediately while only maintaining the global error variable on the server throughout the iterations to boost its efficacy. Theoretically, we prove that LIEC-SGD is superior to previous works in",
    "path": "papers/24/02/2402.11857.json",
    "total_tokens": 752,
    "translated_title": "具有本地即时误差补偿的通信高效分布式学习",
    "translated_abstract": "梯度压缩与误差补偿已经引起了人们的重视，目的是减少分布式学习中沉重的通信开销。然而，现有的压缩方法要么在一个迭代中只执行单向压缩，造成较高的通信成本，要么在收敛速度较慢的情况下执行双向压缩。在这项工作中，我们提出了基于双向压缩和精心设计的补偿策略来突破上述瓶颈的本地即时误差补偿SGD（LIEC-SGD）优化算法。",
    "tldr": "提出了Local Immediate Error Compensated SGD（LIEC-SGD）优化算法，通过双向压缩和精心设计的补偿策略来减少通信成本，实时补偿局部压缩误差，优于现有工作。",
    "en_tdlr": "Introduced the Local Immediate Error Compensated SGD (LIEC-SGD) optimization algorithm, which reduces communication cost through bidirectional compression and compensates local compression error in real time, outperforming existing works."
}