{
    "title": "Leveraging Large Language Models for Concept Graph Recovery and Question Answering in NLP Education",
    "abstract": "arXiv:2402.14293v1 Announce Type: new  Abstract: In the domain of Natural Language Processing (NLP), Large Language Models (LLMs) have demonstrated promise in text-generation tasks. However, their educational applications, particularly for domain-specific queries, remain underexplored. This study investigates LLMs' capabilities in educational scenarios, focusing on concept graph recovery and question-answering (QA). We assess LLMs' zero-shot performance in creating domain-specific concept graphs and introduce TutorQA, a new expert-verified NLP-focused benchmark for scientific graph reasoning and QA. TutorQA consists of five tasks with 500 QA pairs. To tackle TutorQA queries, we present CGLLM, a pipeline integrating concept graphs with LLMs for answering diverse questions. Our results indicate that LLMs' zero-shot concept graph recovery is competitive with supervised methods, showing an average 3% F1 score improvement. In TutorQA tasks, LLMs achieve up to 26% F1 score enhancement. Moreo",
    "link": "https://arxiv.org/abs/2402.14293",
    "context": "Title: Leveraging Large Language Models for Concept Graph Recovery and Question Answering in NLP Education\nAbstract: arXiv:2402.14293v1 Announce Type: new  Abstract: In the domain of Natural Language Processing (NLP), Large Language Models (LLMs) have demonstrated promise in text-generation tasks. However, their educational applications, particularly for domain-specific queries, remain underexplored. This study investigates LLMs' capabilities in educational scenarios, focusing on concept graph recovery and question-answering (QA). We assess LLMs' zero-shot performance in creating domain-specific concept graphs and introduce TutorQA, a new expert-verified NLP-focused benchmark for scientific graph reasoning and QA. TutorQA consists of five tasks with 500 QA pairs. To tackle TutorQA queries, we present CGLLM, a pipeline integrating concept graphs with LLMs for answering diverse questions. Our results indicate that LLMs' zero-shot concept graph recovery is competitive with supervised methods, showing an average 3% F1 score improvement. In TutorQA tasks, LLMs achieve up to 26% F1 score enhancement. Moreo",
    "path": "papers/24/02/2402.14293.json",
    "total_tokens": 950,
    "translated_title": "利用大型语言模型进行NLP教育中的概念图恢复和问答",
    "translated_abstract": "在自然语言处理（NLP）领域，大型语言模型（LLMs）在文本生成任务中表现出潜力。然而，它们在教育应用中，特别是针对领域特定查询的应用，仍未得到充分开发。本研究探讨了LLMs在教育场景中的能力，重点关注概念图恢复和问答（QA）。我们评估了LLMs在创建领域特定概念图方面的零-shot表现，并介绍了TutorQA，这是一个新的经过专家验证的针对科学图推理和QA的NLP基准。TutorQA包含五个任务，共500个QA对。为了解决TutorQA的查询，我们提出了CGLLM，这是一个将概念图与LLMs集成以回答各种问题的流水线。我们的结果表明，LLMs的零-shot概念图恢复与监督方法竞争力相当，平均F1分数提高了3%。在TutorQA任务中，LLMs的F1分数提高了高达26%。",
    "tldr": "本研究利用大型语言模型在教育中进行概念图恢复和问答，并提出了专门针对科学图推理和QA的新基准TutorQA，结果表明LLMs在零-shot概念图恢复和TutorQA任务中的表现优秀。",
    "en_tdlr": "This study leverages large language models for concept graph recovery and question answering in education, introducing a new benchmark called TutorQA for scientific graph reasoning and QA, showing competitive performance in zero-shot concept graph recovery and significant enhancements in TutorQA tasks."
}