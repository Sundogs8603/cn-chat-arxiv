{
    "title": "Can Large Language Models be Good Emotional Supporter? Mitigating Preference Bias on Emotional Support Conversation",
    "abstract": "arXiv:2402.13211v1 Announce Type: new  Abstract: Emotional Support Conversation (ESC) is a task aimed at alleviating individuals' emotional distress through daily conversation. Given its inherent complexity and non-intuitive nature, ESConv dataset incorporates support strategies to facilitate the generation of appropriate responses. Recently, despite the remarkable conversational ability of large language models (LLMs), previous studies have suggested that they often struggle with providing useful emotional support. Hence, this work initially analyzes the results of LLMs on ESConv, revealing challenges in selecting the correct strategy and a notable preference for a specific strategy. Motivated by these, we explore the impact of the inherent preference in LLMs on providing emotional support, and consequently, we observe that exhibiting high preference for specific strategies hinders effective emotional support, aggravating its robustness in predicting the appropriate strategy. Moreover",
    "link": "https://arxiv.org/abs/2402.13211",
    "context": "Title: Can Large Language Models be Good Emotional Supporter? Mitigating Preference Bias on Emotional Support Conversation\nAbstract: arXiv:2402.13211v1 Announce Type: new  Abstract: Emotional Support Conversation (ESC) is a task aimed at alleviating individuals' emotional distress through daily conversation. Given its inherent complexity and non-intuitive nature, ESConv dataset incorporates support strategies to facilitate the generation of appropriate responses. Recently, despite the remarkable conversational ability of large language models (LLMs), previous studies have suggested that they often struggle with providing useful emotional support. Hence, this work initially analyzes the results of LLMs on ESConv, revealing challenges in selecting the correct strategy and a notable preference for a specific strategy. Motivated by these, we explore the impact of the inherent preference in LLMs on providing emotional support, and consequently, we observe that exhibiting high preference for specific strategies hinders effective emotional support, aggravating its robustness in predicting the appropriate strategy. Moreover",
    "path": "papers/24/02/2402.13211.json",
    "total_tokens": 874,
    "translated_title": "大型语言模型能成为良好的情感支持者吗？减轻对情感支持对话中的偏好性偏差",
    "translated_abstract": "情感支持对话（ESC）是一项旨在通过日常对话缓解个体情感困扰的任务。鉴于其固有的复杂性和非直觉性质，ESConv数据集融入了支持策略，以促进生成适当的回应。最近，尽管大型语言模型（LLMs）具有卓越的对话能力，先前的研究表明它们在提供有用的情感支持方面经常遇到困难。因此，本研究首先分析了LLMs在ESConv上的结果，揭示了在选择正确策略和对特定策略的显著偏好方面存在的挑战。在这个基础上，我们探讨了LLMs固有偏好对提供情感支持的影响，因此我们观察到，展现出对特定策略的高偏好会阻碍有效的情感支持，加剧其在预测适当策略方面的鲁棒性。",
    "tldr": "分析了大型语言模型在情感支持对话中的表现，揭示了其存在的偏好性偏差问题，即对特定策略的过高偏好会阻碍有效的情感支持。",
    "en_tdlr": "Analyzed the performance of Large Language Models in Emotional Support Conversation, revealing the issue of preference bias, where a high preference for specific strategies hinders effective emotional support."
}