{
    "title": "Conversation Reconstruction Attack Against GPT Models",
    "abstract": "In recent times, significant advancements have been made in the field of large language models (LLMs), represented by GPT series models. To optimize task execution, users often engage in multi-round conversations with GPT models hosted in cloud environments. These multi-round conversations, potentially replete with private information, require transmission and storage within the cloud. However, this operational paradigm introduces additional attack surfaces. In this paper, we first introduce a specific Conversation Reconstruction Attack targeting GPT models. Our introduced Conversation Reconstruction Attack is composed of two steps: hijacking a session and reconstructing the conversations. Subsequently, we offer an exhaustive evaluation of the privacy risks inherent in conversations when GPT models are subjected to the proposed attack. However, GPT-4 demonstrates certain robustness to the proposed attacks. We then introduce two advanced attacks aimed at better reconstructing previous c",
    "link": "https://arxiv.org/abs/2402.02987",
    "context": "Title: Conversation Reconstruction Attack Against GPT Models\nAbstract: In recent times, significant advancements have been made in the field of large language models (LLMs), represented by GPT series models. To optimize task execution, users often engage in multi-round conversations with GPT models hosted in cloud environments. These multi-round conversations, potentially replete with private information, require transmission and storage within the cloud. However, this operational paradigm introduces additional attack surfaces. In this paper, we first introduce a specific Conversation Reconstruction Attack targeting GPT models. Our introduced Conversation Reconstruction Attack is composed of two steps: hijacking a session and reconstructing the conversations. Subsequently, we offer an exhaustive evaluation of the privacy risks inherent in conversations when GPT models are subjected to the proposed attack. However, GPT-4 demonstrates certain robustness to the proposed attacks. We then introduce two advanced attacks aimed at better reconstructing previous c",
    "path": "papers/24/02/2402.02987.json",
    "total_tokens": 853,
    "translated_title": "GPT 模型的对话重构攻击",
    "translated_abstract": "最近，在大型语言模型（LLM）领域取得了重要进展，其中 GPT 系列模型代表着最具代表性的成果。为了优化任务执行，用户经常与托管在云环境中的 GPT 模型进行多轮对话。这些多轮对话往往包含私人信息，需要在云中进行传输和存储。然而，这种操作模式引入了额外的攻击面。本文首先介绍了一种针对 GPT 模型的特定对话重构攻击。我们提出的对话重构攻击由两个步骤组成：劫持会话和重构对话。随后，我们对当 GPT 模型遭受该攻击时对话中固有的隐私风险进行了详尽评估。然而，GPT-4 对于该攻击具有一定的鲁棒性。接着，我们引入了两种高级攻击，旨在更好地重构以前的对话。",
    "tldr": "本文介绍了一种针对 GPT 模型的对话重构攻击，该攻击具有劫持会话和重构对话的两个步骤。通过对该攻击对 GPT 模型的隐私风险进行评估，发现 GPT-4 对该攻击具有一定的鲁棒性。"
}