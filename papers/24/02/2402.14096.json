{
    "title": "EyeTrans: Merging Human and Machine Attention for Neural Code Summarization",
    "abstract": "arXiv:2402.14096v1 Announce Type: cross  Abstract: Neural code summarization leverages deep learning models to automatically generate brief natural language summaries of code snippets. The development of Transformer models has led to extensive use of attention during model design. While existing work has primarily and almost exclusively focused on static properties of source code and related structural representations like the Abstract Syntax Tree (AST), few studies have considered human attention, that is, where programmers focus while examining and comprehending code. In this paper, we develop a method for incorporating human attention into machine attention to enhance neural code summarization. To facilitate this incorporation and vindicate this hypothesis, we introduce EyeTrans, which consists of three steps: (1) we conduct an extensive eye-tracking human study to collect and pre-analyze data for model training, (2) we devise a data-centric approach to integrate human attention wit",
    "link": "https://arxiv.org/abs/2402.14096",
    "context": "Title: EyeTrans: Merging Human and Machine Attention for Neural Code Summarization\nAbstract: arXiv:2402.14096v1 Announce Type: cross  Abstract: Neural code summarization leverages deep learning models to automatically generate brief natural language summaries of code snippets. The development of Transformer models has led to extensive use of attention during model design. While existing work has primarily and almost exclusively focused on static properties of source code and related structural representations like the Abstract Syntax Tree (AST), few studies have considered human attention, that is, where programmers focus while examining and comprehending code. In this paper, we develop a method for incorporating human attention into machine attention to enhance neural code summarization. To facilitate this incorporation and vindicate this hypothesis, we introduce EyeTrans, which consists of three steps: (1) we conduct an extensive eye-tracking human study to collect and pre-analyze data for model training, (2) we devise a data-centric approach to integrate human attention wit",
    "path": "papers/24/02/2402.14096.json",
    "total_tokens": 689,
    "translated_title": "EyeTrans: 合并人类和机器注意力以实现神经代码摘要",
    "translated_abstract": "Neural code summarization 利用深度学习模型自动生成代码片段的简要自然语言摘要。Transformer模型的发展导致在模型设计中广泛使用注意力机制。本文提出一种将人类注意力融入机器注意力以增强神经代码摘要的方法。为了实现这一融合并验证这一假设，引入了EyeTrans，包括三个步骤：(1) 进行了大量的眼动人类研究，收集和预分析数据用于模型训练，(2) 我们设计了一个以数据为中心的方法来整合人类注意力及",
    "tldr": "引入EyeTrans方法，将人类注意力融入机器注意力，以增强神经代码摘要能力。",
    "en_tdlr": "Introducing EyeTrans method to merge human attention with machine attention for enhanced neural code summarization."
}