{
    "title": "Privacy for Fairness: Information Obfuscation for Fair Representation Learning with Local Differential Privacy",
    "abstract": "arXiv:2402.10473v1 Announce Type: new  Abstract: As machine learning (ML) becomes more prevalent in human-centric applications, there is a growing emphasis on algorithmic fairness and privacy protection. While previous research has explored these areas as separate objectives, there is a growing recognition of the complex relationship between privacy and fairness. However, previous works have primarily focused on examining the interplay between privacy and fairness through empirical investigations, with limited attention given to theoretical exploration. This study aims to bridge this gap by introducing a theoretical framework that enables a comprehensive examination of their interrelation. We shall develop and analyze an information bottleneck (IB) based information obfuscation method with local differential privacy (LDP) for fair representation learning. In contrast to many empirical studies on fairness in ML, we show that the incorporation of LDP randomizers during the encoding proce",
    "link": "https://arxiv.org/abs/2402.10473",
    "context": "Title: Privacy for Fairness: Information Obfuscation for Fair Representation Learning with Local Differential Privacy\nAbstract: arXiv:2402.10473v1 Announce Type: new  Abstract: As machine learning (ML) becomes more prevalent in human-centric applications, there is a growing emphasis on algorithmic fairness and privacy protection. While previous research has explored these areas as separate objectives, there is a growing recognition of the complex relationship between privacy and fairness. However, previous works have primarily focused on examining the interplay between privacy and fairness through empirical investigations, with limited attention given to theoretical exploration. This study aims to bridge this gap by introducing a theoretical framework that enables a comprehensive examination of their interrelation. We shall develop and analyze an information bottleneck (IB) based information obfuscation method with local differential privacy (LDP) for fair representation learning. In contrast to many empirical studies on fairness in ML, we show that the incorporation of LDP randomizers during the encoding proce",
    "path": "papers/24/02/2402.10473.json",
    "total_tokens": 713,
    "translated_title": "隐私与公平：信息混淆用于带有局部差分隐私的公平表示学习",
    "translated_abstract": "随着机器学习在人类中心应用中变得越来越普遍，算法公平性和隐私保护日益受到重视。本研究旨在填补这一空白，在公平性机器学习中引入了信息瓶颈（IB）方法和局部差分隐私（LDP）相结合的信息混淆方法，以理论框架全面考察隐私与公平之间的相互关系。",
    "tldr": "该研究引入了信息瓶颈(IB)方法和局部差分隐私(LDP)相结合的信息混淆方法，以填补隐私与公平之间关系的理论研究空白。",
    "en_tdlr": "This study introduces a theoretical framework that combines an information bottleneck (IB) method and local differential privacy (LDP) for fair representation learning, bridging the gap in theoretical exploration of the relationship between privacy and fairness."
}