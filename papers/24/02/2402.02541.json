{
    "title": "Knowledge Generation for Zero-shot Knowledge-based VQA",
    "abstract": "Previous solutions to knowledge-based visual question answering~(K-VQA) retrieve knowledge from external knowledge bases and use supervised learning to train the K-VQA model. Recently pre-trained LLMs have been used as both a knowledge source and a zero-shot QA model for K-VQA and demonstrated promising results. However, these recent methods do not explicitly show the knowledge needed to answer the questions and thus lack interpretability. Inspired by recent work on knowledge generation from LLMs for text-based QA, in this work we propose and test a similar knowledge-generation-based K-VQA method, which first generates knowledge from an LLM and then incorporates the generated knowledge for K-VQA in a zero-shot manner. We evaluate our method on two K-VQA benchmarks and found that our method performs better than previous zero-shot K-VQA methods and our generated knowledge is generally relevant and helpful.",
    "link": "https://arxiv.org/abs/2402.02541",
    "context": "Title: Knowledge Generation for Zero-shot Knowledge-based VQA\nAbstract: Previous solutions to knowledge-based visual question answering~(K-VQA) retrieve knowledge from external knowledge bases and use supervised learning to train the K-VQA model. Recently pre-trained LLMs have been used as both a knowledge source and a zero-shot QA model for K-VQA and demonstrated promising results. However, these recent methods do not explicitly show the knowledge needed to answer the questions and thus lack interpretability. Inspired by recent work on knowledge generation from LLMs for text-based QA, in this work we propose and test a similar knowledge-generation-based K-VQA method, which first generates knowledge from an LLM and then incorporates the generated knowledge for K-VQA in a zero-shot manner. We evaluate our method on two K-VQA benchmarks and found that our method performs better than previous zero-shot K-VQA methods and our generated knowledge is generally relevant and helpful.",
    "path": "papers/24/02/2402.02541.json",
    "total_tokens": 858,
    "translated_title": "零样本基于知识的视觉问答的知识生成",
    "translated_abstract": "先前的知识化基于视觉问答（K-VQA）解决方案从外部知识库中检索知识，并使用监督学习来训练K-VQA模型。最近，预训练的语言模型被用作K-VQA的知识源和零样本QA模型，并展示了令人期待的结果。然而，这些最近的方法没有明确展示回答问题所需的知识，因此缺乏可解释性。受到最近关于从语言模型生成文本QA的工作的启发，我们在本文中提出并测试了一种类似的基于知识生成的K-VQA方法，该方法首先从语言模型中生成知识，然后以零样本的方式将生成的知识应用于K-VQA。我们在两个K-VQA基准测试上评估了我们的方法，发现我们的方法比之前的零样本K-VQA方法表现更好，我们生成的知识通常是相关且有帮助的。",
    "tldr": "本论文提出了一种使用预训练语言模型生成知识并应用于零样本基于知识的视觉问答的方法。实验证明该方法在两个基准测试上性能优于之前的方法，并生成的知识相关且有帮助。",
    "en_tdlr": "This paper proposes a method for zero-shot knowledge-based visual question answering (K-VQA) using pre-trained language models to generate knowledge. The method outperforms previous methods on two benchmarks and the generated knowledge is found to be relevant and helpful."
}