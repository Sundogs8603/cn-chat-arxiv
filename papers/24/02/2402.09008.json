{
    "title": "Multi-Query Focused Disaster Summarization via Instruction-Based Prompting",
    "abstract": "arXiv:2402.09008v1 Announce Type: new Abstract: Automatic summarization of mass-emergency events plays a critical role in disaster management. The second edition of CrisisFACTS aims to advance disaster summarization based on multi-stream fact-finding with a focus on web sources such as Twitter, Reddit, Facebook, and Webnews. Here, participants are asked to develop systems that can extract key facts from several disaster-related events, which ultimately serve as a summary. This paper describes our method to tackle this challenging task. We follow previous work and propose to use a combination of retrieval, reranking, and an embarrassingly simple instruction-following summarization. The two-stage retrieval pipeline relies on BM25 and MonoT5, while the summarizer module is based on the open-source Large Language Model (LLM) LLaMA-13b. For summarization, we explore a Question Answering (QA)-motivated prompting approach and find the evidence useful for extracting query-relevant facts. The a",
    "link": "https://arxiv.org/abs/2402.09008",
    "context": "Title: Multi-Query Focused Disaster Summarization via Instruction-Based Prompting\nAbstract: arXiv:2402.09008v1 Announce Type: new Abstract: Automatic summarization of mass-emergency events plays a critical role in disaster management. The second edition of CrisisFACTS aims to advance disaster summarization based on multi-stream fact-finding with a focus on web sources such as Twitter, Reddit, Facebook, and Webnews. Here, participants are asked to develop systems that can extract key facts from several disaster-related events, which ultimately serve as a summary. This paper describes our method to tackle this challenging task. We follow previous work and propose to use a combination of retrieval, reranking, and an embarrassingly simple instruction-following summarization. The two-stage retrieval pipeline relies on BM25 and MonoT5, while the summarizer module is based on the open-source Large Language Model (LLM) LLaMA-13b. For summarization, we explore a Question Answering (QA)-motivated prompting approach and find the evidence useful for extracting query-relevant facts. The a",
    "path": "papers/24/02/2402.09008.json",
    "total_tokens": 904,
    "translated_title": "通过基于指令的提示进行多查询关注的灾害摘要",
    "translated_abstract": "自动化灾害事件摘要在灾害管理中起着至关重要的作用。CrisisFACTS的第二版旨在通过基于多流事实查找的方式来推进灾害摘要，重点关注Twitter、Reddit、Facebook和Webnews等网络信息来源。在这里，参与者被要求开发能够从多个与灾害相关的事件中提取关键事实的系统，这些事实最终作为摘要。本文描述了我们解决这一具有挑战性任务的方法。我们遵循以前的工作，提出使用检索、重新排序和一个非常简单的遵循指令的摘要方法的组合。两阶段的检索流程依赖于BM25和MonoT5，而摘要器模块基于开源的大型语言模型（LLM）LLaMA-13b。对于摘要，我们探索了一个以问答为动机的提示方法，并发现这种证据对于提取与查询相关的事实是有用的。",
    "tldr": "本论文通过基于多流事实查找的方式来推进关于灾害事件的自动摘要，提出使用检索、重新排序和遵循指令的摘要方法的组合来解决这一挑战性任务，并探索了以问答为动机的提示方法来提取与查询相关的事实。"
}