{
    "title": "Stochastic Approximation with Delayed Updates: Finite-Time Rates under Markovian Sampling",
    "abstract": "arXiv:2402.11800v1 Announce Type: cross  Abstract: Motivated by applications in large-scale and multi-agent reinforcement learning, we study the non-asymptotic performance of stochastic approximation (SA) schemes with delayed updates under Markovian sampling. While the effect of delays has been extensively studied for optimization, the manner in which they interact with the underlying Markov process to shape the finite-time performance of SA remains poorly understood. In this context, our first main contribution is to show that under time-varying bounded delays, the delayed SA update rule guarantees exponentially fast convergence of the \\emph{last iterate} to a ball around the SA operator's fixed point. Notably, our bound is \\emph{tight} in its dependence on both the maximum delay $\\tau_{max}$, and the mixing time $\\tau_{mix}$. To achieve this tight bound, we develop a novel inductive proof technique that, unlike various existing delayed-optimization analyses, relies on establishing un",
    "link": "https://arxiv.org/abs/2402.11800",
    "context": "Title: Stochastic Approximation with Delayed Updates: Finite-Time Rates under Markovian Sampling\nAbstract: arXiv:2402.11800v1 Announce Type: cross  Abstract: Motivated by applications in large-scale and multi-agent reinforcement learning, we study the non-asymptotic performance of stochastic approximation (SA) schemes with delayed updates under Markovian sampling. While the effect of delays has been extensively studied for optimization, the manner in which they interact with the underlying Markov process to shape the finite-time performance of SA remains poorly understood. In this context, our first main contribution is to show that under time-varying bounded delays, the delayed SA update rule guarantees exponentially fast convergence of the \\emph{last iterate} to a ball around the SA operator's fixed point. Notably, our bound is \\emph{tight} in its dependence on both the maximum delay $\\tau_{max}$, and the mixing time $\\tau_{mix}$. To achieve this tight bound, we develop a novel inductive proof technique that, unlike various existing delayed-optimization analyses, relies on establishing un",
    "path": "papers/24/02/2402.11800.json",
    "total_tokens": 930,
    "translated_title": "具有延迟更新的随机逼近：马尔科夫采样下的有限时间速率",
    "translated_abstract": "受大规模和多智能体强化学习应用的启发，我们研究了在马尔科夫采样下具有延迟更新的随机逼近（SA）方案的非渐近性能。虽然延迟的影响在优化中得到了广泛研究，但它们与底层马尔科夫过程相互作用以塑造SA的有限时间性能的方式仍然不太清楚。在这个背景下，我们的第一个主要贡献是证明在时间变化有界延迟下，延迟的SA更新规则确保最后迭代收敛到SA运算符固定点周围的球体具有指数快速的速度。值得注意的是，我们的界限在依赖于最大延迟$\\tau_{max}$和混合时间$\\tau_{mix}$方面是\\emph{紧致的}。为了实现这一紧密界限，我们开发了一种新颖的归纳证明技术，与各种现有延迟优化分析不同，它依赖于建立未...",
    "tldr": "延迟更新的随机逼近方案在时间变化有界延迟下，保证了每次迭代快速收敛到固定点周围的球体，界限依赖于最大延迟和混合时间。",
    "en_tdlr": "The stochastic approximation scheme with delayed updates ensures fast convergence of each iteration to a ball around the fixed point under time-varying bounded delays, with bounds depending on the maximum delay and mixing time."
}