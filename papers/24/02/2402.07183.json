{
    "title": "A Random Ensemble of Encrypted Vision Transformers for Adversarially Robust Defense",
    "abstract": "Deep neural networks (DNNs) are well known to be vulnerable to adversarial examples (AEs). In previous studies, the use of models encrypted with a secret key was demonstrated to be robust against white-box attacks, but not against black-box ones. In this paper, we propose a novel method using the vision transformer (ViT) that is a random ensemble of encrypted models for enhancing robustness against both white-box and black-box attacks. In addition, a benchmark attack method, called AutoAttack, is applied to models to test adversarial robustness objectively. In experiments, the method was demonstrated to be robust against not only white-box attacks but also black-box ones in an image classification task on the CIFAR-10 and ImageNet datasets. The method was also compared with the state-of-the-art in a standardized benchmark for adversarial robustness, RobustBench, and it was verified to outperform conventional defenses in terms of clean accuracy and robust accuracy.",
    "link": "https://arxiv.org/abs/2402.07183",
    "context": "Title: A Random Ensemble of Encrypted Vision Transformers for Adversarially Robust Defense\nAbstract: Deep neural networks (DNNs) are well known to be vulnerable to adversarial examples (AEs). In previous studies, the use of models encrypted with a secret key was demonstrated to be robust against white-box attacks, but not against black-box ones. In this paper, we propose a novel method using the vision transformer (ViT) that is a random ensemble of encrypted models for enhancing robustness against both white-box and black-box attacks. In addition, a benchmark attack method, called AutoAttack, is applied to models to test adversarial robustness objectively. In experiments, the method was demonstrated to be robust against not only white-box attacks but also black-box ones in an image classification task on the CIFAR-10 and ImageNet datasets. The method was also compared with the state-of-the-art in a standardized benchmark for adversarial robustness, RobustBench, and it was verified to outperform conventional defenses in terms of clean accuracy and robust accuracy.",
    "path": "papers/24/02/2402.07183.json",
    "total_tokens": 932,
    "translated_title": "一个加密视觉Transformer的随机集成方法用于对抗性强化防御",
    "translated_abstract": "深度神经网络（DNN）已经被公认为易受对抗性样本（AEs）的攻击。在之前的研究中，使用秘密密钥加密的模型被证明可以抵抗白盒攻击，但对抗黑盒攻击则不行。本文提出了一种新方法，利用视觉Transformer（ViT）构造一个随机集成的加密模型，以增强对抗白盒和黑盒攻击的能力。此外，还使用了一个名为AutoAttack的基准攻击方法来客观测试模型的对抗性稳健性。在实验证明了该方法在CIFAR-10和ImageNet数据集上的图像分类任务中，不仅对抗白盒攻击具有强大的鲁棒性，还对抗黑盒攻击也具有强大的鲁棒性。该方法还在对抗鲁棒性的标准化基准RobustBench中与最先进的方法进行了比较，验证了在准确性和鲁棒准确性方面优于传统防御方法。",
    "tldr": "本文提出了一个新方法，利用视觉Transformer构造一个随机集成的加密模型，以增强对抗白盒和黑盒攻击的能力，并在多个实验中验证了其在图像分类任务中的鲁棒性和优越性能。"
}