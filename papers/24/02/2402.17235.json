{
    "title": "Stochastic Gradient Succeeds for Bandits",
    "abstract": "arXiv:2402.17235v1 Announce Type: new  Abstract: We show that the \\emph{stochastic gradient} bandit algorithm converges to a \\emph{globally optimal} policy at an $O(1/t)$ rate, even with a \\emph{constant} step size. Remarkably, global convergence of the stochastic gradient bandit algorithm has not been previously established, even though it is an old algorithm known to be applicable to bandits. The new result is achieved by establishing two novel technical findings: first, the noise of the stochastic updates in the gradient bandit algorithm satisfies a strong ``growth condition'' property, where the variance diminishes whenever progress becomes small, implying that additional noise control via diminishing step sizes is unnecessary; second, a form of ``weak exploration'' is automatically achieved through the stochastic gradient updates, since they prevent the action probabilities from decaying faster than $O(1/t)$, thus ensuring that every action is sampled infinitely often with probabi",
    "link": "https://arxiv.org/abs/2402.17235",
    "context": "Title: Stochastic Gradient Succeeds for Bandits\nAbstract: arXiv:2402.17235v1 Announce Type: new  Abstract: We show that the \\emph{stochastic gradient} bandit algorithm converges to a \\emph{globally optimal} policy at an $O(1/t)$ rate, even with a \\emph{constant} step size. Remarkably, global convergence of the stochastic gradient bandit algorithm has not been previously established, even though it is an old algorithm known to be applicable to bandits. The new result is achieved by establishing two novel technical findings: first, the noise of the stochastic updates in the gradient bandit algorithm satisfies a strong ``growth condition'' property, where the variance diminishes whenever progress becomes small, implying that additional noise control via diminishing step sizes is unnecessary; second, a form of ``weak exploration'' is automatically achieved through the stochastic gradient updates, since they prevent the action probabilities from decaying faster than $O(1/t)$, thus ensuring that every action is sampled infinitely often with probabi",
    "path": "papers/24/02/2402.17235.json",
    "total_tokens": 895,
    "translated_title": "随机梯度在赌博机问题中取得成功",
    "translated_abstract": "我们展示了\\emph{随机梯度}赌博机算法以$O(1/t)$的速度收敛到一个\\emph{全局最优}策略，即使采用\\emph{恒定}步长。值得注意的是，尽管随机梯度赌博机算法是一个已知适用于赌博机问题的古老算法，但其全局收敛性以前尚未被证实。通过建立两个新颖的技术发现，我们取得了这一新结果：首先，梯度赌博机算法中随机更新的噪声满足强“增长条件”属性，即当进展变小时，方差会减小，这意味着通过减小步长来控制额外噪声是不必要的；其次，通过随机梯度更新自动实现了一种形式的“弱探索”，因为它们阻止行动概率以比$O(1/t)$更快的速度衰减，从而确保每个动作被无限次采样的概率。",
    "tldr": "随机梯度赌博机算法以常数步长收敛到全局最优策略，无需额外的噪声控制，同时自动实现弱探索，确保每个动作被无限次采样。"
}