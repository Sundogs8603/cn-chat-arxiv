{
    "title": "Gemini Goes to Med School: Exploring the Capabilities of Multimodal Large Language Models on Medical Challenge Problems & Hallucinations",
    "abstract": "Large language models have the potential to be valuable in the healthcare industry, but it's crucial to verify their safety and effectiveness through rigorous evaluation. For this purpose, we comprehensively evaluated both open-source LLMs and Google's new multimodal LLM called Gemini across Medical reasoning, hallucination detection, and Medical Visual Question Answering tasks. While Gemini showed competence, it lagged behind state-of-the-art models like MedPaLM 2 and GPT-4 in diagnostic accuracy. Additionally, Gemini achieved an accuracy of 61.45\\% on the medical VQA dataset, significantly lower than GPT-4V's score of 88\\%. Our analysis revealed that Gemini is highly susceptible to hallucinations, overconfidence, and knowledge gaps, which indicate risks if deployed uncritically. We also performed a detailed analysis by medical subject and test type, providing actionable feedback for developers and clinicians. To mitigate risks, we applied prompting strategies that improved performanc",
    "link": "https://arxiv.org/abs/2402.07023",
    "context": "Title: Gemini Goes to Med School: Exploring the Capabilities of Multimodal Large Language Models on Medical Challenge Problems & Hallucinations\nAbstract: Large language models have the potential to be valuable in the healthcare industry, but it's crucial to verify their safety and effectiveness through rigorous evaluation. For this purpose, we comprehensively evaluated both open-source LLMs and Google's new multimodal LLM called Gemini across Medical reasoning, hallucination detection, and Medical Visual Question Answering tasks. While Gemini showed competence, it lagged behind state-of-the-art models like MedPaLM 2 and GPT-4 in diagnostic accuracy. Additionally, Gemini achieved an accuracy of 61.45\\% on the medical VQA dataset, significantly lower than GPT-4V's score of 88\\%. Our analysis revealed that Gemini is highly susceptible to hallucinations, overconfidence, and knowledge gaps, which indicate risks if deployed uncritically. We also performed a detailed analysis by medical subject and test type, providing actionable feedback for developers and clinicians. To mitigate risks, we applied prompting strategies that improved performanc",
    "path": "papers/24/02/2402.07023.json",
    "total_tokens": 995,
    "translated_title": "双子座进入医学院：探索多模态大型语言模型在医学挑战问题和幻觉上的能力",
    "translated_abstract": "大型语言模型在医疗行业具有潜在价值，但通过严格评估来验证其安全性和效果至关重要。为此，我们全面评估了开源LLM和谷歌的新型多模态LLM Gemini 在医学推理、幻觉检测和医学视觉问答任务上的能力。虽然Gemini表现出一定的能力，但在诊断准确性方面落后于MedPaLM 2和GPT-4等最先进模型。此外，Gemini在医学VQA数据集上的准确率为61.45％，明显低于GPT-4V的88％得分。我们的分析发现，Gemini极易出现幻觉、过度自信和知识盲点，这表明如果不加批判地部署，存在风险。我们还针对不同医学学科和测试类型进行了详细分析，为开发人员和临床医生提供了可操作的反馈。为了减少风险，我们采用了提示策略来提高性能。",
    "tldr": "该论文综合评估了开源LLM和谷歌的多模态LLM Gemini 在医学推理、幻觉检测和医学视觉问答任务上的能力。Gemini在诊断准确性方面落后于最先进模型，且易出现幻觉、过度自信和知识盲点。采用提示策略可以提高性能。"
}