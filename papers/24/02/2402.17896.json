{
    "title": "Researchy Questions: A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents",
    "abstract": "arXiv:2402.17896v1 Announce Type: cross  Abstract: Existing question answering (QA) datasets are no longer challenging to most powerful Large Language Models (LLMs). Traditional QA benchmarks like TriviaQA, NaturalQuestions, ELI5 and HotpotQA mainly study ``known unknowns'' with clear indications of both what information is missing, and how to find it to answer the question. Hence, good performance on these benchmarks provides a false sense of security. A yet unmet need of the NLP community is a bank of non-factoid, multi-perspective questions involving a great deal of unclear information needs, i.e. ``unknown uknowns''. We claim we can find such questions in search engine logs, which is surprising because most question-intent queries are indeed factoid. We present Researchy Questions, a dataset of search engine queries tediously filtered to be non-factoid, ``decompositional'' and multi-perspective. We show that users spend a lot of ``effort'' on these questions in terms of signals lik",
    "link": "https://arxiv.org/abs/2402.17896",
    "context": "Title: Researchy Questions: A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents\nAbstract: arXiv:2402.17896v1 Announce Type: cross  Abstract: Existing question answering (QA) datasets are no longer challenging to most powerful Large Language Models (LLMs). Traditional QA benchmarks like TriviaQA, NaturalQuestions, ELI5 and HotpotQA mainly study ``known unknowns'' with clear indications of both what information is missing, and how to find it to answer the question. Hence, good performance on these benchmarks provides a false sense of security. A yet unmet need of the NLP community is a bank of non-factoid, multi-perspective questions involving a great deal of unclear information needs, i.e. ``unknown uknowns''. We claim we can find such questions in search engine logs, which is surprising because most question-intent queries are indeed factoid. We present Researchy Questions, a dataset of search engine queries tediously filtered to be non-factoid, ``decompositional'' and multi-perspective. We show that users spend a lot of ``effort'' on these questions in terms of signals lik",
    "path": "papers/24/02/2402.17896.json",
    "total_tokens": 893,
    "translated_title": "研究性问题：LLM网络特工的多透视、分解问题数据集",
    "translated_abstract": "现有的问答（QA）数据集对于大多数强大的大型语言模型（LLMs）来说不再具有挑战性。传统的QA基准如TriviaQA、NaturalQuestions、ELI5和HotpotQA主要研究明确指示了缺少哪些信息以及如何找到这些信息来回答问题的“已知未知s”。因此，对这些基准的优秀表现提供了一种虚假的安全感。自然语言处理（NLP）社区尚未满足的需求是一个非事实型、多透视问题的银行，涉及大量不明确的信息需求，即“未知的未知s”。我们声称可以在搜索引擎日志中找到这样的问题，这令人惊讶，因为大多数问答意图查询实际上是事实型的。我们展示了Researchy Questions，一个经过繁琐过滤以变为非事实型、“分解式”和多透视的搜索引擎查询数据集。我们展示了用户在这些问题上投入了大量“努力”，这种努力表现为信号",
    "tldr": "提出了一个研究性问题数据集，其中包含非事实型、多透视的问题，能够挑战目前大型语言模型的表现。",
    "en_tdlr": "Proposed a dataset of researchy questions that are non-factoid and multi-perspective, challenging the performance of current large language models."
}