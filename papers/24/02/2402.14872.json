{
    "title": "Semantic Mirror Jailbreak: Genetic Algorithm Based Jailbreak Prompts Against Open-source LLMs",
    "abstract": "arXiv:2402.14872v1 Announce Type: cross  Abstract: Large Language Models (LLMs), used in creative writing, code generation, and translation, generate text based on input sequences but are vulnerable to jailbreak attacks, where crafted prompts induce harmful outputs. Most jailbreak prompt methods use a combination of jailbreak templates followed by questions to ask to create jailbreak prompts. However, existing jailbreak prompt designs generally suffer from excessive semantic differences, resulting in an inability to resist defenses that use simple semantic metrics as thresholds. Jailbreak prompts are semantically more varied than the original questions used for queries. In this paper, we introduce a Semantic Mirror Jailbreak (SMJ) approach that bypasses LLMs by generating jailbreak prompts that are semantically similar to the original question. We model the search for jailbreak prompts that satisfy both semantic similarity and jailbreak validity as a multi-objective optimization proble",
    "link": "https://arxiv.org/abs/2402.14872",
    "context": "Title: Semantic Mirror Jailbreak: Genetic Algorithm Based Jailbreak Prompts Against Open-source LLMs\nAbstract: arXiv:2402.14872v1 Announce Type: cross  Abstract: Large Language Models (LLMs), used in creative writing, code generation, and translation, generate text based on input sequences but are vulnerable to jailbreak attacks, where crafted prompts induce harmful outputs. Most jailbreak prompt methods use a combination of jailbreak templates followed by questions to ask to create jailbreak prompts. However, existing jailbreak prompt designs generally suffer from excessive semantic differences, resulting in an inability to resist defenses that use simple semantic metrics as thresholds. Jailbreak prompts are semantically more varied than the original questions used for queries. In this paper, we introduce a Semantic Mirror Jailbreak (SMJ) approach that bypasses LLMs by generating jailbreak prompts that are semantically similar to the original question. We model the search for jailbreak prompts that satisfy both semantic similarity and jailbreak validity as a multi-objective optimization proble",
    "path": "papers/24/02/2402.14872.json",
    "total_tokens": 851,
    "translated_title": "语义镜像越狱:基于遗传算法的针对开源LLM的越狱提示",
    "translated_abstract": "大型语言模型（LLMs）通常用于创意写作、代码生成和翻译，根据输入序列生成文本，但容易受到越狱攻击的影响，其中精心设计的提示会导致有害输出。大多数越狱提示方法使用一组越狱模板，然后跟随提出问题，创建越狱提示。然而，现有的越狱提示设计通常存在过多的语义差异，导致无法抵御使用简单语义度量作为阈值的防御。越狱提示在语义上比用于查询的原始问题更加多样化。在本文中，我们介绍了一种称为语义镜像越狱（SMJ）的方法，通过生成在语义上类似于原始问题的越狱提示来绕过LLMs。我们将寻找既满足语义相似性又具有越狱有效性的越狱提示建模为一个多目标优化问题。",
    "tldr": "本文提出了一种语义镜像越狱（SMJ）方法，通过生成在语义上类似于原始问题的越狱提示来绕过LLMs。",
    "en_tdlr": "This paper introduces a Semantic Mirror Jailbreak (SMJ) approach that bypasses LLMs by generating jailbreak prompts that are semantically similar to the original question."
}