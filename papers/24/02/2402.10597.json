{
    "title": "Efficiency at Scale: Investigating the Performance of Diminutive Language Models in Clinical Tasks",
    "abstract": "arXiv:2402.10597v1 Announce Type: cross  Abstract: The entry of large language models (LLMs) into research and commercial spaces has led to a trend of ever-larger models, with initial promises of generalisability, followed by a widespread desire to downsize and create specialised models without the need for complete fine-tuning, using Parameter Efficient Fine-tuning (PEFT) methods. We present an investigation into the suitability of different PEFT methods to clinical decision-making tasks, across a range of model sizes, including extremely small models with as few as $25$ million parameters.   Our analysis shows that the performance of most PEFT approaches varies significantly from one task to another, with the exception of LoRA, which maintains relatively high performance across all model sizes and tasks, typically approaching or matching full fine-tuned performance. The effectiveness of PEFT methods in the clinical domain is evident, particularly for specialised models which can oper",
    "link": "https://arxiv.org/abs/2402.10597",
    "context": "Title: Efficiency at Scale: Investigating the Performance of Diminutive Language Models in Clinical Tasks\nAbstract: arXiv:2402.10597v1 Announce Type: cross  Abstract: The entry of large language models (LLMs) into research and commercial spaces has led to a trend of ever-larger models, with initial promises of generalisability, followed by a widespread desire to downsize and create specialised models without the need for complete fine-tuning, using Parameter Efficient Fine-tuning (PEFT) methods. We present an investigation into the suitability of different PEFT methods to clinical decision-making tasks, across a range of model sizes, including extremely small models with as few as $25$ million parameters.   Our analysis shows that the performance of most PEFT approaches varies significantly from one task to another, with the exception of LoRA, which maintains relatively high performance across all model sizes and tasks, typically approaching or matching full fine-tuned performance. The effectiveness of PEFT methods in the clinical domain is evident, particularly for specialised models which can oper",
    "path": "papers/24/02/2402.10597.json",
    "total_tokens": 919,
    "translated_title": "规模效率：研究微小语言模型在临床任务中的性能",
    "translated_abstract": "大型语言模型（LLMs）进入研究和商业领域，引发了越来越大模型的趋势，最初承诺通用性，随后普遍希望缩小规模并创建专门模型，而无需进行完整微调，使用参数高效微调（PEFT）方法。我们对不同PEFT方法在临床决策任务中的适用性进行了调查，涵盖一系列模型规模，包括只有$25$百万参数的极小模型。我们的分析表明，大多数PEFT方法在不同任务之间的性能差异较大，除了LoRA外，LoRA在所有模型规模和任务中的性能保持相对较高，通常接近或达到完全微调性能。 PEFT方法在临床领域的有效性是显而易见的，特别是对于可以操作的专门模型",
    "tldr": "研究了不同Parameter Efficient Fine-tuning (PEFT)方法在临床决策任务中的适用性，发现除了LoRA外，大多数PEFT方法在各个模型规模和任务中性能不稳定，而LoRA在所有情况下性能都相对较高。PEFT方法在临床领域特别有效，尤其适用于可以操作的专门模型。",
    "en_tdlr": "Investigated the suitability of various Parameter Efficient Fine-tuning (PEFT) methods for clinical decision-making tasks, finding that most PEFT methods exhibit unstable performance across different model sizes and tasks except LoRA which maintains relatively high performance in all cases. PEFT methods are particularly effective in the clinical domain, especially for specialized models that can be operated."
}