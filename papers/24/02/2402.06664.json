{
    "title": "LLM Agents can Autonomously Hack Websites",
    "abstract": "In recent years, large language models (LLMs) have become increasingly capable and can now interact with tools (i.e., call functions), read documents, and recursively call themselves. As a result, these LLMs can now function autonomously as agents. With the rise in capabilities of these agents, recent work has speculated on how LLM agents would affect cybersecurity. However, not much is known about the offensive capabilities of LLM agents.   In this work, we show that LLM agents can autonomously hack websites, performing tasks as complex as blind database schema extraction and SQL injections without human feedback. Importantly, the agent does not need to know the vulnerability beforehand. This capability is uniquely enabled by frontier models that are highly capable of tool use and leveraging extended context. Namely, we show that GPT-4 is capable of such hacks, but existing open-source models are not. Finally, we show that GPT-4 is capable of autonomously finding vulnerabilities in we",
    "link": "https://arxiv.org/abs/2402.06664",
    "context": "Title: LLM Agents can Autonomously Hack Websites\nAbstract: In recent years, large language models (LLMs) have become increasingly capable and can now interact with tools (i.e., call functions), read documents, and recursively call themselves. As a result, these LLMs can now function autonomously as agents. With the rise in capabilities of these agents, recent work has speculated on how LLM agents would affect cybersecurity. However, not much is known about the offensive capabilities of LLM agents.   In this work, we show that LLM agents can autonomously hack websites, performing tasks as complex as blind database schema extraction and SQL injections without human feedback. Importantly, the agent does not need to know the vulnerability beforehand. This capability is uniquely enabled by frontier models that are highly capable of tool use and leveraging extended context. Namely, we show that GPT-4 is capable of such hacks, but existing open-source models are not. Finally, we show that GPT-4 is capable of autonomously finding vulnerabilities in we",
    "path": "papers/24/02/2402.06664.json",
    "total_tokens": 892,
    "translated_title": "LLM代理可以自主黑客网站",
    "translated_abstract": "近年来，大型语言模型（LLMs）变得越来越强大，现在可以与工具交互（即调用函数）、读取文档并递归调用自己。因此，这些LLMs现在可以自主作为代理人运作。随着这些代理人能力的提升，最近的研究已经推测LLM代理人将如何影响网络安全。然而，关于LLM代理人的攻击能力，我们还知之甚少。在本研究中，我们展示了LLM代理人可以自主黑客网站，执行诸如盲目数据库模式提取和SQL注入等复杂任务，无需人工反馈。重要的是，这种能力是由具有高度工具使用和利用扩展上下文能力的前沿模型所独特赋予的。我们展示了GPT-4能够进行这样的黑客攻击，但现有的开源模型则不能。最后，我们展示了GPT-4能够自主发现网站的漏洞。",
    "tldr": "这项研究展示了LLM代理可以自主进行网站黑客攻击，包括盲目数据库模式提取和SQL注入，而且不需要人工反馈。这种能力是由高度工具使用和利用扩展上下文能力的前沿模型赋予的。"
}