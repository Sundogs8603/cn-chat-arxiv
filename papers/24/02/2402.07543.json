{
    "title": "Show Me How It's Done: The Role of Explanations in Fine-Tuning Language Models",
    "abstract": "Our research demonstrates the significant benefits of using fine-tuning with explanations to enhance the performance of language models. Unlike prompting, which maintains the model's parameters, fine-tuning allows the model to learn and update its parameters during a training phase. In this study, we applied fine-tuning to various sized language models using data that contained explanations of the output rather than merely presenting the answers. We found that even smaller language models with as few as 60 million parameters benefited substantially from this approach. Interestingly, our results indicated that the detailed explanations were more beneficial to smaller models than larger ones, with the latter gaining nearly the same advantage from any form of explanation, irrespective of its length. Additionally, we demonstrate that the inclusion of explanations enables the models to solve tasks that they were not able to solve without explanations. Lastly, we argue that despite the chall",
    "link": "https://arxiv.org/abs/2402.07543",
    "context": "Title: Show Me How It's Done: The Role of Explanations in Fine-Tuning Language Models\nAbstract: Our research demonstrates the significant benefits of using fine-tuning with explanations to enhance the performance of language models. Unlike prompting, which maintains the model's parameters, fine-tuning allows the model to learn and update its parameters during a training phase. In this study, we applied fine-tuning to various sized language models using data that contained explanations of the output rather than merely presenting the answers. We found that even smaller language models with as few as 60 million parameters benefited substantially from this approach. Interestingly, our results indicated that the detailed explanations were more beneficial to smaller models than larger ones, with the latter gaining nearly the same advantage from any form of explanation, irrespective of its length. Additionally, we demonstrate that the inclusion of explanations enables the models to solve tasks that they were not able to solve without explanations. Lastly, we argue that despite the chall",
    "path": "papers/24/02/2402.07543.json",
    "total_tokens": 838,
    "translated_title": "给我看怎么做：解释在细调语言模型中的作用",
    "translated_abstract": "我们的研究证明了使用解释来增强语言模型性能的显著好处。与提示方式不同，细调允许模型在训练阶段学习和更新参数。在本研究中，我们应用细调的方法，使用包含输出解释而非仅呈现答案的数据来对不同大小的语言模型进行训练。我们发现，即使是只有6000万参数的较小语言模型也能从这种方法中获益。有趣的是，我们的结果表明，详细的解释对较小的模型更有益处，而对于较大的模型来说，无论解释的长度如何，都可以获得几乎相同的优势。此外，我们还证明了解释的加入使模型能够解决之前无法解决的任务。最后，我们认为尽管存在挑战，但解释在细调语言模型中起到了重要作用。",
    "tldr": "本研究证明了使用解释来改进语言模型性能的显著好处，尤其适用于较小的模型，解释的加入使模型能够解决之前无法解决的任务。"
}