{
    "title": "Pixel Sentence Representation Learning",
    "abstract": "Pretrained language models are long known to be subpar in capturing sentence and document-level semantics. Though heavily investigated, transferring perturbation-based methods from unsupervised visual representation learning to NLP remains an unsolved problem. This is largely due to the discreteness of subword units brought by tokenization of language models, limiting small perturbations of inputs to form semantics-preserved positive pairs. In this work, we conceptualize the learning of sentence-level textual semantics as a visual representation learning process. Drawing from cognitive and linguistic sciences, we introduce an unsupervised visual sentence representation learning framework, employing visually-grounded text perturbation methods like typos and word order shuffling, resonating with human cognitive patterns, and enabling perturbation to texts to be perceived as continuous. Our approach is further bolstered by large-scale unsupervised topical alignment training and natural la",
    "link": "https://arxiv.org/abs/2402.08183",
    "context": "Title: Pixel Sentence Representation Learning\nAbstract: Pretrained language models are long known to be subpar in capturing sentence and document-level semantics. Though heavily investigated, transferring perturbation-based methods from unsupervised visual representation learning to NLP remains an unsolved problem. This is largely due to the discreteness of subword units brought by tokenization of language models, limiting small perturbations of inputs to form semantics-preserved positive pairs. In this work, we conceptualize the learning of sentence-level textual semantics as a visual representation learning process. Drawing from cognitive and linguistic sciences, we introduce an unsupervised visual sentence representation learning framework, employing visually-grounded text perturbation methods like typos and word order shuffling, resonating with human cognitive patterns, and enabling perturbation to texts to be perceived as continuous. Our approach is further bolstered by large-scale unsupervised topical alignment training and natural la",
    "path": "papers/24/02/2402.08183.json",
    "total_tokens": 934,
    "translated_title": "像素句子表示学习",
    "translated_abstract": "预训练语言模型长期以来被认为在捕捉句子和文档级语义方面表现不佳。尽管已经进行了大量研究，但从无监督的视觉表示学习中将基于扰动的方法转移到自然语言处理仍然是一个尚未解决的问题。这在很大程度上是由于语言模型的分词所引入的子词单元的离散性，限制了对输入进行小扰动以形成保留语义的正向对。在这项工作中，我们将学习句子级文本语义视作一个视觉表示学习过程。借鉴认知和语言科学，我们引入了一个无监督的视觉句子表示学习框架，利用像打字错误和单词顺序混排等基于视觉基础文本扰动方法，与人类认知模式共鸣，并使文本的扰动被感知为连续。我们的方法进一步加强了大规模无监督的主题对齐训练和自然语言文本的仿真可视化条件。",
    "tldr": "本文提出了一种无监督的视觉句子表示学习框架，通过引入基于视觉基础文本扰动方法，如打字错误和单词顺序混排，借鉴认知和语言科学，以连续的方式感知文本的扰动，从而改善预训练语言模型在捕捉句子级文本语义方面的性能。",
    "en_tdlr": "This paper proposes an unsupervised visual sentence representation learning framework, which improves the performance of pretrained language models in capturing sentence-level textual semantics by introducing visually-grounded text perturbation methods such as typos and word order shuffling in a continuous manner, drawing from cognitive and linguistic sciences."
}