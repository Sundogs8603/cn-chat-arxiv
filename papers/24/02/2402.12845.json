{
    "title": "MORE-3S:Multimodal-based Offline Reinforcement Learning with Shared Semantic Spaces",
    "abstract": "arXiv:2402.12845v1 Announce Type: new  Abstract: Drawing upon the intuition that aligning different modalities to the same semantic embedding space would allow models to understand states and actions more easily, we propose a new perspective to the offline reinforcement learning (RL) challenge. More concretely, we transform it into a supervised learning task by integrating multimodal and pre-trained language models. Our approach incorporates state information derived from images and action-related data obtained from text, thereby bolstering RL training performance and promoting long-term strategic thinking. We emphasize the contextual understanding of language and demonstrate how decision-making in RL can benefit from aligning states' and actions' representation with languages' representation. Our method significantly outperforms current baselines as evidenced by evaluations conducted on Atari and OpenAI Gym environments. This contributes to advancing offline RL performance and efficie",
    "link": "https://arxiv.org/abs/2402.12845",
    "context": "Title: MORE-3S:Multimodal-based Offline Reinforcement Learning with Shared Semantic Spaces\nAbstract: arXiv:2402.12845v1 Announce Type: new  Abstract: Drawing upon the intuition that aligning different modalities to the same semantic embedding space would allow models to understand states and actions more easily, we propose a new perspective to the offline reinforcement learning (RL) challenge. More concretely, we transform it into a supervised learning task by integrating multimodal and pre-trained language models. Our approach incorporates state information derived from images and action-related data obtained from text, thereby bolstering RL training performance and promoting long-term strategic thinking. We emphasize the contextual understanding of language and demonstrate how decision-making in RL can benefit from aligning states' and actions' representation with languages' representation. Our method significantly outperforms current baselines as evidenced by evaluations conducted on Atari and OpenAI Gym environments. This contributes to advancing offline RL performance and efficie",
    "path": "papers/24/02/2402.12845.json",
    "total_tokens": 869,
    "translated_title": "基于多模态离线强化学习的共享语义空间",
    "translated_abstract": "基于对齐不同模态到相同语义嵌入空间可以使模型更容易理解状态和动作的直觉，我们提出了一个新的视角来解决离线强化学习挑战。更具体地，我们通过集成多模态和预训练语言模型将其转化为一个监督学习任务。我们的方法融合了从图像中得到的状态信息和从文本中获得的与动作相关的数据，从而增强了强化学习训练性能，并促进了长期战略思维。我们强调语言的情境理解，并展示了强化学习中如何从将状态和动作表示与语言表示对齐中受益。我们的方法在Atari和OpenAI Gym环境中的评估显示明显优于当前基准。这有助于推动离线强化学习性能和效率。",
    "tldr": "将不同模态对齐到相同的语义嵌入空间有利于提升离线强化学习性能，通过集成多模态和预训练语言模型，我们成功将其转化为一个监督学习任务，有助于增强强化学习训练性能并促进长期战略思维。",
    "en_tdlr": "Aligning different modalities to the same semantic embedding space improves offline reinforcement learning performance. By integrating multimodal and pre-trained language models, we successfully transform it into a supervised learning task, enhancing RL training performance and promoting long-term strategic thinking."
}