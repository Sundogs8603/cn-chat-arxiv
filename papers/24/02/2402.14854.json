{
    "title": "A Dual-Prompting for Interpretable Mental Health Language Models",
    "abstract": "arXiv:2402.14854v1 Announce Type: cross  Abstract: Despite the increasing demand for AI-based mental health monitoring tools, their practical utility for clinicians is limited by the lack of interpretability.The CLPsych 2024 Shared Task (Chim et al., 2024) aims to enhance the interpretability of Large Language Models (LLMs), particularly in mental health analysis, by providing evidence of suicidality through linguistic content. We propose a dual-prompting approach: (i) Knowledge-aware evidence extraction by leveraging the expert identity and a suicide dictionary with a mental health-specific LLM; and (ii) Evidence summarization by employing an LLM-based consistency evaluator. Comprehensive experiments demonstrate the effectiveness of combining domain-specific information, revealing performance improvements and the approach's potential to aid clinicians in assessing mental state progression.",
    "link": "https://arxiv.org/abs/2402.14854",
    "context": "Title: A Dual-Prompting for Interpretable Mental Health Language Models\nAbstract: arXiv:2402.14854v1 Announce Type: cross  Abstract: Despite the increasing demand for AI-based mental health monitoring tools, their practical utility for clinicians is limited by the lack of interpretability.The CLPsych 2024 Shared Task (Chim et al., 2024) aims to enhance the interpretability of Large Language Models (LLMs), particularly in mental health analysis, by providing evidence of suicidality through linguistic content. We propose a dual-prompting approach: (i) Knowledge-aware evidence extraction by leveraging the expert identity and a suicide dictionary with a mental health-specific LLM; and (ii) Evidence summarization by employing an LLM-based consistency evaluator. Comprehensive experiments demonstrate the effectiveness of combining domain-specific information, revealing performance improvements and the approach's potential to aid clinicians in assessing mental state progression.",
    "path": "papers/24/02/2402.14854.json",
    "total_tokens": 824,
    "translated_title": "一种可解释的心理健康语言模型的双提示方法",
    "translated_abstract": "尽管越来越多的人工智能心理健康监测工具的需求增加，但由于缺乏可解释性，它们对临床医生的实际效用有限。CLPsych 2024共享任务旨在通过提供自杀意识的证据来增强大型语言模型（LLM）的可解释性，特别是在心理健康分析领域。我们提出了一种双提示方法：（i）通过利用专家身份和自杀词典与心理健康特定LLM相结合，进行知识感知证据提取；以及（ii）通过使用基于LLM的一致性评估器来进行证据总结。全面的实验证明了结合领域特定信息的有效性，揭示了性能的提升和该方法在帮助临床医生评估心理状态进展方面的潜力。",
    "tldr": "提出了一种双提示方法，结合专家身份和自杀词典与心理健康特定LLM相结合，有效提升了在心理健康分析中的解释性和帮助临床医生评估心理状态进展。",
    "en_tdlr": "A dual-prompting method is proposed, combining expert identity and a suicide dictionary with mental health-specific LLM, effectively enhancing interpretability in mental health analysis and aiding clinicians in assessing mental state progression."
}