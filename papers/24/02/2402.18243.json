{
    "title": "Learning or Self-aligning? Rethinking Instruction Fine-tuning",
    "abstract": "arXiv:2402.18243v1 Announce Type: new  Abstract: Instruction Fine-tuning~(IFT) is a critical phase in building large language models~(LLMs). Previous works mainly focus on the IFT's role in the transfer of behavioral norms and the learning of additional world knowledge. However, the understanding of the underlying mechanisms of IFT remains significantly limited. In this paper, we design a knowledge intervention framework to decouple the potential underlying factors of IFT, thereby enabling individual analysis of different factors. Surprisingly, our experiments reveal that attempting to learn additional world knowledge through IFT often struggles to yield positive impacts and can even lead to markedly negative effects. Further, we discover that maintaining internal knowledge consistency before and after IFT is a critical factor for achieving successful IFT. Our findings reveal the underlying mechanisms of IFT and provide robust support for some very recent and potential future works.",
    "link": "https://arxiv.org/abs/2402.18243",
    "context": "Title: Learning or Self-aligning? Rethinking Instruction Fine-tuning\nAbstract: arXiv:2402.18243v1 Announce Type: new  Abstract: Instruction Fine-tuning~(IFT) is a critical phase in building large language models~(LLMs). Previous works mainly focus on the IFT's role in the transfer of behavioral norms and the learning of additional world knowledge. However, the understanding of the underlying mechanisms of IFT remains significantly limited. In this paper, we design a knowledge intervention framework to decouple the potential underlying factors of IFT, thereby enabling individual analysis of different factors. Surprisingly, our experiments reveal that attempting to learn additional world knowledge through IFT often struggles to yield positive impacts and can even lead to markedly negative effects. Further, we discover that maintaining internal knowledge consistency before and after IFT is a critical factor for achieving successful IFT. Our findings reveal the underlying mechanisms of IFT and provide robust support for some very recent and potential future works.",
    "path": "papers/24/02/2402.18243.json",
    "total_tokens": 854,
    "translated_title": "学习还是自我调整？重新思考指导微调",
    "translated_abstract": "指导微调（IFT）是构建大型语言模型（LLM）中至关重要的阶段。先前的研究主要关注IFT在行为规范传递和额外世界知识学习中的作用。然而，对IFT潜在机制的理解仍然相当有限。本文设计了一个知识干预框架，以解耦IFT的潜在因素，从而实现对不同因素的个体分析。令人惊讶的是，我们的实验揭示，通过IFT试图学习额外的世界知识往往难以产生积极影响，甚至可能导致明显负面影响。此外，我们发现在IFT之前和之后保持内部知识一致性是实现成功IFT的关键因素。我们的研究结果揭示了IFT的潜在机制，并为最新和潜在未来的研究提供了有力支持。",
    "tldr": "本研究揭示了指导微调的潜在机制，发现尝试通过指导微调学习额外世界知识往往难以产生积极影响，重点在于保持内部知识一致性。",
    "en_tdlr": "This study reveals the underlying mechanisms of Instruction Fine-tuning (IFT), finding that attempting to learn additional world knowledge through IFT often struggles to yield positive impacts, with the key factor being maintaining internal knowledge consistency."
}