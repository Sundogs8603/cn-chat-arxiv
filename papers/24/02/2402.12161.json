{
    "title": "Endowing Pre-trained Graph Models with Provable Fairness",
    "abstract": "arXiv:2402.12161v1 Announce Type: cross  Abstract: Pre-trained graph models (PGMs) aim to capture transferable inherent structural properties and apply them to different downstream tasks. Similar to pre-trained language models, PGMs also inherit biases from human society, resulting in discriminatory behavior in downstream applications. The debiasing process of existing fair methods is generally coupled with parameter optimization of GNNs. However, different downstream tasks may be associated with different sensitive attributes in reality, directly employing existing methods to improve the fairness of PGMs is inflexible and inefficient. Moreover, most of them lack a theoretical guarantee, i.e., provable lower bounds on the fairness of model predictions, which directly provides assurance in a practical scenario. To overcome these limitations, we propose a novel adapter-tuning framework that endows pre-trained \\textbf{Graph} models with \\textbf{P}rovable f\\textbf{A}i\\textbf{R}ness (called",
    "link": "https://arxiv.org/abs/2402.12161",
    "context": "Title: Endowing Pre-trained Graph Models with Provable Fairness\nAbstract: arXiv:2402.12161v1 Announce Type: cross  Abstract: Pre-trained graph models (PGMs) aim to capture transferable inherent structural properties and apply them to different downstream tasks. Similar to pre-trained language models, PGMs also inherit biases from human society, resulting in discriminatory behavior in downstream applications. The debiasing process of existing fair methods is generally coupled with parameter optimization of GNNs. However, different downstream tasks may be associated with different sensitive attributes in reality, directly employing existing methods to improve the fairness of PGMs is inflexible and inefficient. Moreover, most of them lack a theoretical guarantee, i.e., provable lower bounds on the fairness of model predictions, which directly provides assurance in a practical scenario. To overcome these limitations, we propose a novel adapter-tuning framework that endows pre-trained \\textbf{Graph} models with \\textbf{P}rovable f\\textbf{A}i\\textbf{R}ness (called",
    "path": "papers/24/02/2402.12161.json",
    "total_tokens": 827,
    "translated_title": "赋予预训练图模型具有可证明的公平性",
    "translated_abstract": "预训练图模型（PGMs）旨在捕捉可转移的固有结构属性，并将其应用于不同的下游任务。类似于预训练语言模型，PGMs也会继承人类社会中的偏见，导致在下游应用中出现歧视行为。现有公平方法的去偏见过程通常与GNNs的参数优化相结合。然而，不同的下游任务在现实中可能与不同的敏感属性相关联，直接采用现有方法改善PGMs的公平性是不灵活且低效的。此外，大多数方法缺乏理论保证，即对模型预测公平性的可证明下限，这直接提供了实际场景下的保证。为了克服这些限制，我们提出了一种新的适配器调优框架，赋予预训练\\textbf{图}模型具有\\textbf{可证明}的\\textbf{公}平\\textbf{性}（称为",
    "tldr": "提出了一种新的适配器调优框架，赋予预训练图模型具有可证明的公平性",
    "en_tdlr": "Introducing a novel adapter-tuning framework that endows pre-trained graph models with provable fairness."
}