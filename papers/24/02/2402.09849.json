{
    "title": "Recommendations for Baselines and Benchmarking Approximate Gaussian Processes",
    "abstract": "arXiv:2402.09849v1 Announce Type: new  Abstract: Gaussian processes (GPs) are a mature and widely-used component of the ML toolbox. One of their desirable qualities is automatic hyperparameter selection, which allows for training without user intervention. However, in many realistic settings, approximations are typically needed, which typically do require tuning. We argue that this requirement for tuning complicates evaluation, which has led to a lack of a clear recommendations on which method should be used in which situation. To address this, we make recommendations for comparing GP approximations based on a specification of what a user should expect from a method. In addition, we develop a training procedure for the variational method of Titsias [2009] that leaves no choices to the user, and show that this is a strong baseline that meets our specification. We conclude that benchmarking according to our suggestions gives a clearer view of the current state of the field, and uncovers ",
    "link": "https://arxiv.org/abs/2402.09849",
    "context": "Title: Recommendations for Baselines and Benchmarking Approximate Gaussian Processes\nAbstract: arXiv:2402.09849v1 Announce Type: new  Abstract: Gaussian processes (GPs) are a mature and widely-used component of the ML toolbox. One of their desirable qualities is automatic hyperparameter selection, which allows for training without user intervention. However, in many realistic settings, approximations are typically needed, which typically do require tuning. We argue that this requirement for tuning complicates evaluation, which has led to a lack of a clear recommendations on which method should be used in which situation. To address this, we make recommendations for comparing GP approximations based on a specification of what a user should expect from a method. In addition, we develop a training procedure for the variational method of Titsias [2009] that leaves no choices to the user, and show that this is a strong baseline that meets our specification. We conclude that benchmarking according to our suggestions gives a clearer view of the current state of the field, and uncovers ",
    "path": "papers/24/02/2402.09849.json",
    "total_tokens": 842,
    "translated_title": "对于基准线和基准测试近似高斯过程的建议",
    "translated_abstract": "Gaussian processes (GPs)是机器学习工具箱中成熟且广泛使用的组件。它们具有自动超参数选择的优点，可以实现无需用户干预的训练。然而，在许多现实情况下，通常需要使用近似方法，而这些方法通常需要调整。我们认为，这种调整要求使得评估变得复杂，这导致缺乏对在哪种情况下使用哪种方法的明确建议。为了解决这个问题，我们提出了对比GP近似方法的建议，基于用户对方法的期望的规范。此外，我们开发了一种训练程序，用于Titsias [2009]的变分方法，该方法不需要用户选择，并且证明这是符合我们规范的一个强大基准。我们得出结论，按照我们的建议进行基准测试可以更清晰地了解当前领域的状态，并发现……",
    "tldr": "对于基准线和基准测试近似高斯过程的研究，我们提出了对比方法的建议，并开发了一种训练程序，该程序不需要用户选择，并且证明这是一个符合要求的强大基准。",
    "en_tdlr": "In this paper, we provide recommendations for comparing GP approximations and develop a training procedure that requires no user intervention, serving as a strong baseline for benchmarking."
}