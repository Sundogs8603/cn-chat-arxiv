{
    "title": "Multi-Level GNN Preconditioner for Solving Large Scale Problems",
    "abstract": "Large-scale numerical simulations often come at the expense of daunting computations. High-Performance Computing has enhanced the process, but adapting legacy codes to leverage parallel GPU computations remains challenging. Meanwhile, Machine Learning models can harness GPU computations effectively but often struggle with generalization and accuracy. Graph Neural Networks (GNNs), in particular, are great for learning from unstructured data like meshes but are often limited to small-scale problems. Moreover, the capabilities of the trained model usually restrict the accuracy of the data-driven solution. To benefit from both worlds, this paper introduces a novel preconditioner integrating a GNN model within a multi-level Domain Decomposition framework. The proposed GNN-based preconditioner is used to enhance the efficiency of a Krylov method, resulting in a hybrid solver that can converge with any desired level of accuracy. The efficiency of the Krylov method greatly benefits from the GN",
    "link": "https://arxiv.org/abs/2402.08296",
    "context": "Title: Multi-Level GNN Preconditioner for Solving Large Scale Problems\nAbstract: Large-scale numerical simulations often come at the expense of daunting computations. High-Performance Computing has enhanced the process, but adapting legacy codes to leverage parallel GPU computations remains challenging. Meanwhile, Machine Learning models can harness GPU computations effectively but often struggle with generalization and accuracy. Graph Neural Networks (GNNs), in particular, are great for learning from unstructured data like meshes but are often limited to small-scale problems. Moreover, the capabilities of the trained model usually restrict the accuracy of the data-driven solution. To benefit from both worlds, this paper introduces a novel preconditioner integrating a GNN model within a multi-level Domain Decomposition framework. The proposed GNN-based preconditioner is used to enhance the efficiency of a Krylov method, resulting in a hybrid solver that can converge with any desired level of accuracy. The efficiency of the Krylov method greatly benefits from the GN",
    "path": "papers/24/02/2402.08296.json",
    "total_tokens": 881,
    "translated_title": "多层GNN预处理器用于解决大规模问题",
    "translated_abstract": "大规模数值模拟通常需要进行艰难的计算。高性能计算已经改进了这个过程，但是将传统代码适应并行GPU计算仍然具有挑战性。与此同时，机器学习模型可以有效地利用GPU计算，但往往在泛化和准确性方面遇到困难。图神经网络（GNN）特别适用于学习从网格等非结构化数据中，但往往受限于小规模问题。此外，所训练模型的能力通常限制了基于数据驱动的解决方案的准确性。为了同时从两个领域受益，本文介绍了一个新型的预处理器，将GNN模型与多层域分解框架集成在一起。所提出的基于GNN的预处理器用于增强Krylov方法的效率，从而产生一个混合求解器，可以以任何所需的准确性收敛。Krylov方法的效率从GNN预处理器中受益良多。",
    "tldr": "本论文介绍了一个多层GNN预处理器用于解决大规模问题，该预处理器集成了GNN模型和多层域分解框架，能够通过增强Krylov方法的效率以不同精度水平收敛。",
    "en_tdlr": "This paper presents a multi-level GNN preconditioner for solving large-scale problems, which integrates a GNN model within a multi-level Domain Decomposition framework. The proposed preconditioner enhances the efficiency of a Krylov method, allowing convergence with any desired level of accuracy."
}