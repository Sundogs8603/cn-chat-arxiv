{
    "title": "A Manifold Representation of the Key in Vision Transformers",
    "abstract": "Vision Transformers implement multi-head self-attention (MSA) via stacking multiple attention blocks. The query, key, and value are often intertwined and generated within those blocks via a single, shared linear transformation. This paper explores the concept of disentangling the key from the query and value, and adopting a manifold representation for the key. Our experiments reveal that decoupling and endowing the key with a manifold structure can enhance the model performance. Specifically, ViT-B exhibits a 0.87% increase in top-1 accuracy, while Swin-T sees a boost of 0.52% in top-1 accuracy on the ImageNet-1K dataset, with eight charts in the manifold key. Our approach also yields positive results in object detection and instance segmentation tasks on the COCO dataset. Through detailed ablation studies, we establish that these performance gains are not merely due to the simplicity of adding more parameters and computations. Future research may investigate strategies for cutting the",
    "link": "https://arxiv.org/abs/2402.00534",
    "context": "Title: A Manifold Representation of the Key in Vision Transformers\nAbstract: Vision Transformers implement multi-head self-attention (MSA) via stacking multiple attention blocks. The query, key, and value are often intertwined and generated within those blocks via a single, shared linear transformation. This paper explores the concept of disentangling the key from the query and value, and adopting a manifold representation for the key. Our experiments reveal that decoupling and endowing the key with a manifold structure can enhance the model performance. Specifically, ViT-B exhibits a 0.87% increase in top-1 accuracy, while Swin-T sees a boost of 0.52% in top-1 accuracy on the ImageNet-1K dataset, with eight charts in the manifold key. Our approach also yields positive results in object detection and instance segmentation tasks on the COCO dataset. Through detailed ablation studies, we establish that these performance gains are not merely due to the simplicity of adding more parameters and computations. Future research may investigate strategies for cutting the",
    "path": "papers/24/02/2402.00534.json",
    "total_tokens": 882,
    "translated_title": "视觉转换器中关键信息的流形表示",
    "translated_abstract": "视觉转换器通过堆叠多个注意力块实现了多头自注意力（MSA）。在这些块中，查询、关键信息和数值通常纠缠在一起，并通过单个共享线性变换生成。本文探索了将关键信息从查询和数值中解耦，并为关键信息采用流形表示的概念。我们的实验表明，解耦并赋予关键信息流形结构可以提升模型性能。具体而言，ViT-B在ImageNet-1K数据集上的top-1准确率提高了0.87％，而Swin-T则在top-1准确率上提高了0.52％，使用了八个流形关键图。我们的方法在COCO数据集上的目标检测和实例分割任务中也取得了积极的结果。通过详细的消融研究，我们证明了这些性能提升不仅仅是由于增加了更多参数和计算的简单性。未来的研究可以探索减少计算复杂度的策略。",
    "tldr": "该论文提出了一种在视觉转换器中将关键信息与查询和数值分离并采用流形表示的方法，实验证明这种方法能够提升模型性能，并在ImageNet-1K和COCO数据集上取得了积极的结果。",
    "en_tdlr": "This paper introduces a method to separate and represent the key information in vision transformers using a manifold structure, improving model performance and achieving positive results on ImageNet-1K and COCO datasets."
}