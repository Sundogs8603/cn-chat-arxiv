{
    "title": "On the Complexity of First-Order Methods in Stochastic Bilevel Optimization",
    "abstract": "We consider the problem of finding stationary points in Bilevel optimization when the lower-level problem is unconstrained and strongly convex. The problem has been extensively studied in recent years; the main technical challenge is to keep track of lower-level solutions $y^*(x)$ in response to the changes in the upper-level variables $x$. Subsequently, all existing approaches tie their analyses to a genie algorithm that knows lower-level solutions and, therefore, need not query any points far from them. We consider a dual question to such approaches: suppose we have an oracle, which we call $y^*$-aware, that returns an $O(\\epsilon)$-estimate of the lower-level solution, in addition to first-order gradient estimators {\\it locally unbiased} within the $\\Theta(\\epsilon)$-ball around $y^*(x)$. We study the complexity of finding stationary points with such an $y^*$-aware oracle: we propose a simple first-order method that converges to an $\\epsilon$ stationary point using $O(\\epsilon^{-6})",
    "link": "https://arxiv.org/abs/2402.07101",
    "context": "Title: On the Complexity of First-Order Methods in Stochastic Bilevel Optimization\nAbstract: We consider the problem of finding stationary points in Bilevel optimization when the lower-level problem is unconstrained and strongly convex. The problem has been extensively studied in recent years; the main technical challenge is to keep track of lower-level solutions $y^*(x)$ in response to the changes in the upper-level variables $x$. Subsequently, all existing approaches tie their analyses to a genie algorithm that knows lower-level solutions and, therefore, need not query any points far from them. We consider a dual question to such approaches: suppose we have an oracle, which we call $y^*$-aware, that returns an $O(\\epsilon)$-estimate of the lower-level solution, in addition to first-order gradient estimators {\\it locally unbiased} within the $\\Theta(\\epsilon)$-ball around $y^*(x)$. We study the complexity of finding stationary points with such an $y^*$-aware oracle: we propose a simple first-order method that converges to an $\\epsilon$ stationary point using $O(\\epsilon^{-6})",
    "path": "papers/24/02/2402.07101.json",
    "total_tokens": 916,
    "translated_title": "论随机双层优化问题中一阶方法的复杂性",
    "translated_abstract": "本文考虑了在下层问题无约束且强凸的条件下，寻找双层优化问题中的稳定点。该问题近年来得到了广泛研究；主要的技术挑战是跟踪下层解$y^*(x)$对上层变量$x$的变化。现有方法都将分析结果与一个能够知道下层解的神算法相关联，因此不需要查询离这些解太远的点。我们考虑了一个对这些方法的对偶问题：假设我们有一个被称为$y^*$-感知的预言机，它返回一个$O(\\epsilon)$的下层解估计，并且提供在距离$y^*(x)$的$\\Theta(\\epsilon)$球内处的一阶梯度估计器的局部无偏估计。我们研究了使用这样的$y^*$-感知预言机寻找稳定点的复杂性：我们提出了一种简单的一阶方法，它收敛到一个$\\epsilon$稳定点，使用$O(\\epsilon^{-6})$的次数是足够的。",
    "tldr": "本文研究了在随机双层优化中使用一阶方法的复杂性，提出了一种简单的方法，使用$O(\\epsilon^{-6})$次迭代可以收敛到一个$\\epsilon$稳定点。",
    "en_tdlr": "This paper investigates the complexity of using first-order methods in stochastic bilevel optimization and proposes a simple method that can converge to an $\\epsilon$ stationary point with $O(\\epsilon^{-6})$ iterations."
}