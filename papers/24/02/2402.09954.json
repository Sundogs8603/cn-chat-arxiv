{
    "title": "Crafting a Good Prompt or Providing Exemplary Dialogues? A Study of In-Context Learning for Persona-based Dialogue Generation",
    "abstract": "arXiv:2402.09954v1 Announce Type: new  Abstract: Previous in-context learning (ICL) research has focused on tasks such as classification, machine translation, text2table, etc., while studies on whether ICL can improve human-like dialogue generation are scarce. Our work fills this gap by systematically investigating the ICL capabilities of large language models (LLMs) in persona-based dialogue generation, conducting extensive experiments on high-quality real human Chinese dialogue datasets. From experimental results, we draw three conclusions: 1) adjusting prompt instructions is the most direct, effective, and economical way to improve generation quality; 2) randomly retrieving demonstrations (demos) achieves the best results, possibly due to the greater diversity and the amount of effective information; counter-intuitively, retrieving demos with a context identical to the query performs the worst; 3) even when we destroy the multi-turn associations and single-turn semantics in the demo",
    "link": "https://arxiv.org/abs/2402.09954",
    "context": "Title: Crafting a Good Prompt or Providing Exemplary Dialogues? A Study of In-Context Learning for Persona-based Dialogue Generation\nAbstract: arXiv:2402.09954v1 Announce Type: new  Abstract: Previous in-context learning (ICL) research has focused on tasks such as classification, machine translation, text2table, etc., while studies on whether ICL can improve human-like dialogue generation are scarce. Our work fills this gap by systematically investigating the ICL capabilities of large language models (LLMs) in persona-based dialogue generation, conducting extensive experiments on high-quality real human Chinese dialogue datasets. From experimental results, we draw three conclusions: 1) adjusting prompt instructions is the most direct, effective, and economical way to improve generation quality; 2) randomly retrieving demonstrations (demos) achieves the best results, possibly due to the greater diversity and the amount of effective information; counter-intuitively, retrieving demos with a context identical to the query performs the worst; 3) even when we destroy the multi-turn associations and single-turn semantics in the demo",
    "path": "papers/24/02/2402.09954.json",
    "total_tokens": 975,
    "translated_title": "制定良好提示还是提供出色的对话？关于基于上下文学习的角色生成对话的研究",
    "translated_abstract": "先前关于上下文学习（ICL）的研究主要侧重于分类、机器翻译、文本到表格等任务，而对于ICL能否改进生成类似人类对话的研究很少。我们的工作通过在高质量的真实人类对话数据集上进行广泛的实验，系统地研究了大型语言模型（LLMs）在基于角色生成对话方面的ICL能力。根据实验结果，我们得出三个结论：1）调整提示指令是提高生成质量最直接、有效和经济的方法；2）随机检索示范可以取得最佳的结果，可能是因为具有更多样化和有效信息的原因；与查询相同上下文的示范检索结果最差；3）即使破坏了示范中的多回合关联和单回合语义，对话生成仍然可以实现较好的效果。",
    "tldr": "本研究通过对大型语言模型在基于角色生成对话方面进行实验，发现调整提示指令可以最直接有效且经济地提高生成质量，并且随机检索示范会取得最佳结果，而查询相同上下文的示范检索效果最差。即使破坏了示范中的多回合关联和单回合语义，对话生成仍然有效。"
}