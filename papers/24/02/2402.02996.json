{
    "title": "Text-Guided Image Clustering",
    "abstract": "Image clustering divides a collection of images into meaningful groups, typically interpreted post-hoc via human-given annotations. Those are usually in the form of text, begging the question of using text as an abstraction for image clustering. Current image clustering methods, however, neglect the use of generated textual descriptions. We, therefore, propose Text-Guided Image Clustering, i.e., generating text using image captioning and visual question-answering (VQA) models and subsequently clustering the generated text. Further, we introduce a novel approach to inject task- or domain knowledge for clustering by prompting VQA models. Across eight diverse image clustering datasets, our results show that the obtained text representations often outperform image features. Additionally, we propose a counting-based cluster explainability method. Our evaluations show that the derived keyword-based explanations describe clusters better than the respective cluster accuracy suggests. Overall, ",
    "link": "https://arxiv.org/abs/2402.02996",
    "context": "Title: Text-Guided Image Clustering\nAbstract: Image clustering divides a collection of images into meaningful groups, typically interpreted post-hoc via human-given annotations. Those are usually in the form of text, begging the question of using text as an abstraction for image clustering. Current image clustering methods, however, neglect the use of generated textual descriptions. We, therefore, propose Text-Guided Image Clustering, i.e., generating text using image captioning and visual question-answering (VQA) models and subsequently clustering the generated text. Further, we introduce a novel approach to inject task- or domain knowledge for clustering by prompting VQA models. Across eight diverse image clustering datasets, our results show that the obtained text representations often outperform image features. Additionally, we propose a counting-based cluster explainability method. Our evaluations show that the derived keyword-based explanations describe clusters better than the respective cluster accuracy suggests. Overall, ",
    "path": "papers/24/02/2402.02996.json",
    "total_tokens": 901,
    "translated_title": "文本引导的图像聚类",
    "translated_abstract": "图像聚类将一组图像分成有意义的组，通常通过人工给出的注释进行解释。这些注释通常以文本形式存在，引发了使用文本作为图像聚类的抽象的问题。然而，当前的图像聚类方法忽视了生成的文本描述的使用。因此，我们提出了一种文本引导的图像聚类方法，即使用图像字幕和视觉问答（VQA）模型生成文本，然后对生成的文本进行聚类。此外，我们还介绍了一种通过提示VQA模型来注入任务或领域知识用于聚类的新方法。在八个不同的图像聚类数据集上，我们的结果表明，获得的文本表示通常优于图像特征。此外，我们提出了一种基于计数的聚类可解释性方法。我们的评估结果表明，基于关键词的解释比相应的聚类准确性更好地描述了聚类。总的来说，",
    "tldr": "这篇论文提出了一种文本引导的图像聚类方法，使用图像字幕和视觉问答模型生成文本，然后对生成的文本进行聚类，并通过注入任务或领域知识来改进聚类结果。实验证明，获得的文本表示通常优于图像特征，而基于关键词的解释可以更好地描述聚类。",
    "en_tdlr": "This paper proposes a text-guided image clustering method, in which text is generated using image captioning and visual question-answering models and then clustered. The method also incorporates task- or domain-specific knowledge to improve clustering results. Experimental results demonstrate that the obtained text representations often outperform image features, and keyword-based explanations provide better descriptions of the clusters."
}