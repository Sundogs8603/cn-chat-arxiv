{
    "title": "Theoretical Analysis of Leave-one-out Cross Validation for Non-differentiable Penalties under High-dimensional Settings",
    "abstract": "Despite a large and significant body of recent work focused on estimating the out-of-sample risk of regularized models in the high dimensional regime, a theoretical understanding of this problem for non-differentiable penalties such as generalized LASSO and nuclear norm is missing. In this paper we resolve this challenge. We study this problem in the proportional high dimensional regime where both the sample size n and number of features p are large, and n/p and the signal-to-noise ratio (per observation) remain finite. We provide finite sample upper bounds on the expected squared error of leave-one-out cross-validation (LO) in estimating the out-of-sample risk. The theoretical framework presented here provides a solid foundation for elucidating empirical findings that show the accuracy of LO.",
    "link": "https://arxiv.org/abs/2402.08543",
    "context": "Title: Theoretical Analysis of Leave-one-out Cross Validation for Non-differentiable Penalties under High-dimensional Settings\nAbstract: Despite a large and significant body of recent work focused on estimating the out-of-sample risk of regularized models in the high dimensional regime, a theoretical understanding of this problem for non-differentiable penalties such as generalized LASSO and nuclear norm is missing. In this paper we resolve this challenge. We study this problem in the proportional high dimensional regime where both the sample size n and number of features p are large, and n/p and the signal-to-noise ratio (per observation) remain finite. We provide finite sample upper bounds on the expected squared error of leave-one-out cross-validation (LO) in estimating the out-of-sample risk. The theoretical framework presented here provides a solid foundation for elucidating empirical findings that show the accuracy of LO.",
    "path": "papers/24/02/2402.08543.json",
    "total_tokens": 794,
    "translated_title": "在高维环境下，关于非可微惩罚项的LOOCV的理论分析",
    "translated_abstract": "尽管在高维情况下，关于正则化模型的非样条惩罚项（如推广的LASSO和核范数）的外样本风险估计有大量的重要工作，但对于这个问题的理论理解仍然缺失。在本文中，我们解决了这个挑战。我们在比例高维情况下研究了这个问题，其中样本量n和特征数p都很大，且n/p和信噪比（每个观测）保持有限。我们给出了LOOCV在估计外样本风险时的有限样本上界。本文提出的理论框架为阐明LOOCV的准确性提供了坚实的基础。",
    "tldr": "本文在高维环境下，针对非可微惩罚项（如推广的LASSO和核范数），通过研究LOOCV在估计外样本风险时的有限样本上界，解决了这个理论缺失的问题。",
    "en_tdlr": "This paper resolves the theoretical understanding gap of estimating out-of-sample risk for non-differentiable penalties under high-dimensional settings, such as generalized LASSO and nuclear norm, by providing finite sample upper bounds on the expected squared error of leave-one-out cross-validation (LO). This theoretical framework sheds light on the empirical accuracy of LO."
}