{
    "title": "A Generative Approach to Surrogate-based Black-box Attacks",
    "abstract": "Surrogate-based black-box attacks have exposed the heightened vulnerability of DNNs. These attacks are designed to craft adversarial examples for any samples with black-box target feedback for only a given set of samples. State-of-the-art surrogate-based attacks involve training a discriminative surrogate that mimics the target's outputs. The goal is to learn the decision boundaries of the target. The surrogate is then attacked by white-box attacks to craft adversarial examples similar to the original samples but belong to other classes. With limited samples, the discriminative surrogate fails to accurately learn the target's decision boundaries, and these surrogate-based attacks suffer from low success rates. Different from the discriminative approach, we propose a generative surrogate that learns the distribution of samples residing on or close to the target's decision boundaries. The distribution learned by the generative surrogate can be used to craft adversarial examples that have",
    "link": "https://arxiv.org/abs/2402.02732",
    "context": "Title: A Generative Approach to Surrogate-based Black-box Attacks\nAbstract: Surrogate-based black-box attacks have exposed the heightened vulnerability of DNNs. These attacks are designed to craft adversarial examples for any samples with black-box target feedback for only a given set of samples. State-of-the-art surrogate-based attacks involve training a discriminative surrogate that mimics the target's outputs. The goal is to learn the decision boundaries of the target. The surrogate is then attacked by white-box attacks to craft adversarial examples similar to the original samples but belong to other classes. With limited samples, the discriminative surrogate fails to accurately learn the target's decision boundaries, and these surrogate-based attacks suffer from low success rates. Different from the discriminative approach, we propose a generative surrogate that learns the distribution of samples residing on or close to the target's decision boundaries. The distribution learned by the generative surrogate can be used to craft adversarial examples that have",
    "path": "papers/24/02/2402.02732.json",
    "total_tokens": 830,
    "translated_title": "基于生成模型的黑盒替代攻击方法",
    "translated_abstract": "基于生成模型的黑盒替代攻击揭示了深度神经网络的易受攻击性。这些攻击旨在为给定的一组样本，通过黑盒目标反馈来生成对抗性样本。目前最先进的替代攻击方法是通过训练一个鉴别性替代模型来模拟目标模型的输出，以学习目标模型的决策边界。然后，白盒攻击针对替代模型生成与原始样本相似但属于其他类别的对抗性样本。然而，由于样本数量有限，鉴别性替代模型无法准确学习目标模型的决策边界，因此这些替代攻击方法的成功率较低。与鉴别性方法不同，我们提出了一种生成模型的替代方法，该模型学习目标模型决策边界附近或相邻样本的分布。通过生成模型学习的分布可以用于生成对抗性样本。",
    "tldr": "提出了一种基于生成模型的黑盒替代攻击方法，通过学习样本分布，生成对抗性样本，用于攻击深度神经网络。",
    "en_tdlr": "A generative approach to surrogate-based black-box attacks is proposed, where adversarial examples are crafted by learning the distribution of samples and attacking deep neural networks."
}