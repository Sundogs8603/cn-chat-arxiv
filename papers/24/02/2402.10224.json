{
    "title": "Human-Centric Goal Reasoning with Ripple-Down Rules",
    "abstract": "arXiv:2402.10224v1 Announce Type: cross  Abstract: ActorSim is a goal reasoning framework developed at the Naval Research Laboratory. Originally, all goal reasoning rules were hand-crafted. This work extends ActorSim with the capability of learning by demonstration, that is, when a human trainer disagrees with a decision made by the system, the trainer can take over and show the system the correct decision. The learning component uses Ripple-Down Rules (RDR) to build new decision rules to correctly handle similar cases in the future. The system is demonstrated using the RoboCup Rescue Agent Simulation, which simulates a city-wide disaster, requiring emergency services, including fire, ambulance and police, to be dispatched to different sites to evacuate civilians from dangerous situations. The RDRs are implemented in a scripting language, FrameScript, which is used to mediate between ActorSim and the agent simulator. Using Ripple-Down Rules, ActorSim can scale to an order of magnitude ",
    "link": "https://arxiv.org/abs/2402.10224",
    "context": "Title: Human-Centric Goal Reasoning with Ripple-Down Rules\nAbstract: arXiv:2402.10224v1 Announce Type: cross  Abstract: ActorSim is a goal reasoning framework developed at the Naval Research Laboratory. Originally, all goal reasoning rules were hand-crafted. This work extends ActorSim with the capability of learning by demonstration, that is, when a human trainer disagrees with a decision made by the system, the trainer can take over and show the system the correct decision. The learning component uses Ripple-Down Rules (RDR) to build new decision rules to correctly handle similar cases in the future. The system is demonstrated using the RoboCup Rescue Agent Simulation, which simulates a city-wide disaster, requiring emergency services, including fire, ambulance and police, to be dispatched to different sites to evacuate civilians from dangerous situations. The RDRs are implemented in a scripting language, FrameScript, which is used to mediate between ActorSim and the agent simulator. Using Ripple-Down Rules, ActorSim can scale to an order of magnitude ",
    "path": "papers/24/02/2402.10224.json",
    "total_tokens": 849,
    "translated_title": "人类为中心的目标推理与Ripple-Down规则",
    "translated_abstract": "ActorSim是在海军研究实验室开发的目标推理框架。最初，所有目标推理规则都是手工制作的。本作品通过展示学习的能力扩展了ActorSim，即当人类训练员与系统的决定不符时，训练员可以接管并向系统展示正确决策。学习组件使用Ripple-Down Rules（RDR）构建新的决策规则，以正确处理未来类似情况。该系统在RoboCup Rescue Agent Simulation中展示，该模拟器模拟了一个全市范围的灾难，需要紧急服务，包括消防、救护车和警察，派往不同地点从危险情况中撤离平民。RDRs实现在一个脚本语言FrameScript中，用于在ActorSim和代理模拟器之间进行调解。使用Ripple-Down Rules，ActorSim可以扩展一个数量级。",
    "tldr": "本文通过使用Ripple-Down Rules（RDR）扩展了ActorSim目标推理框架，使其能够通过示范学习并建立新的决策规则，以便在未来正确处理类似情况。",
    "en_tdlr": "This paper extends the ActorSim goal reasoning framework with the ability to learn by demonstration using Ripple-Down Rules (RDR) to build new decision rules for correctly handling similar cases in the future."
}