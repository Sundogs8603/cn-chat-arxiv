{
    "title": "GRAFFORD: A Benchmark Dataset for Testing the Knowledge of Object Affordances of Language and Vision Models",
    "abstract": "arXiv:2402.12881v1 Announce Type: new  Abstract: We investigate the knowledge of object affordances in pre-trained language models (LMs) and pre-trained Vision-Language models (VLMs). Transformers-based large pre-trained language models (PTLM) learn contextual representation from massive amounts of unlabeled text and are shown to perform impressively in downstream NLU tasks. In parallel, a growing body of literature shows that PTLMs fail inconsistently and non-intuitively, showing a lack of reasoning and grounding. To take a first step toward quantifying the effect of grounding (or lack thereof), we curate a novel and comprehensive dataset of object affordances -- GrAFFORD, characterized by 15 affordance classes. Unlike affordance datasets collected in vision and language domains, we annotate in-the-wild sentences with objects and affordances. Experimental results reveal that PTLMs exhibit limited reasoning abilities when it comes to uncommon object affordances. We also observe that pr",
    "link": "https://arxiv.org/abs/2402.12881",
    "context": "Title: GRAFFORD: A Benchmark Dataset for Testing the Knowledge of Object Affordances of Language and Vision Models\nAbstract: arXiv:2402.12881v1 Announce Type: new  Abstract: We investigate the knowledge of object affordances in pre-trained language models (LMs) and pre-trained Vision-Language models (VLMs). Transformers-based large pre-trained language models (PTLM) learn contextual representation from massive amounts of unlabeled text and are shown to perform impressively in downstream NLU tasks. In parallel, a growing body of literature shows that PTLMs fail inconsistently and non-intuitively, showing a lack of reasoning and grounding. To take a first step toward quantifying the effect of grounding (or lack thereof), we curate a novel and comprehensive dataset of object affordances -- GrAFFORD, characterized by 15 affordance classes. Unlike affordance datasets collected in vision and language domains, we annotate in-the-wild sentences with objects and affordances. Experimental results reveal that PTLMs exhibit limited reasoning abilities when it comes to uncommon object affordances. We also observe that pr",
    "path": "papers/24/02/2402.12881.json",
    "total_tokens": 917,
    "translated_title": "GRAFFORD: 用于测试语言和视觉模型对物体可供性知识的基准数据集",
    "translated_abstract": "我们调查了预训练语言模型（LMs）和预训练视觉-语言模型（VLMs）中关于物体可供性的知识。基于Transformer的大型预训练语言模型（PTLM）从大量未标记文本中学习上下文表示，并在下游NLU任务中表现出色。与此同时，越来越多的文献表明，PTLM在推理和基础方面存在不一致且不直观的失败。为了首次定量衡量基础（或缺乏）的影响，我们精心策划了一个关于物体可供性的新颖而全面的数据集-- GrAFFORD，包含15个可供性类别。与视觉和语言领域收集的可供性数据集不同，我们用现场句子标注了对象和可供性。实验结果显示，当涉及不常见的物体可供性时，PTLM表现出有限的推理能力。我们还观察到PTLM在理解不常见物体可供性时存在困难。",
    "tldr": "该论文提出了一个名为GRAFFORD的基准数据集，用于测试语言和视觉模型对物体可供性知识的表现，实验结果显示当前预训练语言模型在理解不常见物体可供性方面存在推理能力的局限。",
    "en_tdlr": "This paper introduces a benchmark dataset called GRAFFORD for testing the knowledge of object affordances in language and vision models, with experimental results showing limited reasoning abilities of current pre-trained language models in understanding uncommon object affordances."
}