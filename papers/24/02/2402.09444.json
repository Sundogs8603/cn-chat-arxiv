{
    "title": "Multimodal Action Quality Assessment",
    "abstract": "arXiv:2402.09444v1 Announce Type: cross  Abstract: Action quality assessment (AQA) is to assess how well an action is performed. Previous works perform modelling by only the use of visual information, ignoring audio information. We argue that although AQA is highly dependent on visual information, the audio is useful complementary information for improving the score regression accuracy, especially for sports with background music, such as figure skating and rhythmic gymnastics. To leverage multimodal information for AQA, i.e., RGB, optical flow and audio information, we propose a Progressive Adaptive Multimodal Fusion Network (PAMFN) that separately models modality-specific information and mixed-modality information. Our model consists of with three modality-specific branches that independently explore modality-specific information and a mixed-modality branch that progressively aggregates the modality-specific information from the modality-specific branches. To build the bridge between",
    "link": "https://arxiv.org/abs/2402.09444",
    "context": "Title: Multimodal Action Quality Assessment\nAbstract: arXiv:2402.09444v1 Announce Type: cross  Abstract: Action quality assessment (AQA) is to assess how well an action is performed. Previous works perform modelling by only the use of visual information, ignoring audio information. We argue that although AQA is highly dependent on visual information, the audio is useful complementary information for improving the score regression accuracy, especially for sports with background music, such as figure skating and rhythmic gymnastics. To leverage multimodal information for AQA, i.e., RGB, optical flow and audio information, we propose a Progressive Adaptive Multimodal Fusion Network (PAMFN) that separately models modality-specific information and mixed-modality information. Our model consists of with three modality-specific branches that independently explore modality-specific information and a mixed-modality branch that progressively aggregates the modality-specific information from the modality-specific branches. To build the bridge between",
    "path": "papers/24/02/2402.09444.json",
    "total_tokens": 798,
    "translated_title": "多模态动作质量评估",
    "translated_abstract": "行动质量评估（AQA）是评估动作执行情况的方法。以往的研究仅利用视觉信息进行建模，忽视了音频信息。我们认为，虽然AQA高度依赖视觉信息，但音频也是提高评分回归准确性的有用补充信息，特别是在具有背景音乐的运动项目中，如花样滑冰和韵律体操。为了利用多模态信息进行AQA，即RGB、光流和音频信息，我们提出了一个渐进自适应多模态融合网络（PAMFN），它分别对模态特定信息和混合模态信息进行建模。我们的模型由三个模态特定分支和一个混合模态分支组成，独立地探索模态特定信息，并渐进地聚合来自模态特定分支的模态特定信息。",
    "tldr": "该论文提出了一个名为PAMFN的渐进自适应多模态融合网络，用于多模态动作质量评估。该模型利用RGB、光流和音频信息，分别建模模态特定信息和混合模态信息，并通过充分利用音频信息，提高了评分回归的准确性。"
}