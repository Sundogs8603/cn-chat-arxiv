{
    "title": "Time Series Forecasting with LLMs: Understanding and Enhancing Model Capabilities",
    "abstract": "arXiv:2402.10835v1 Announce Type: new  Abstract: Large language models (LLMs) have been applied in many fields with rapid development in recent years. As a classic machine learning task, time series forecasting has recently received a boost from LLMs. However, there is a research gap in the LLMs' preferences in this field. In this paper, by comparing LLMs with traditional models, many properties of LLMs in time series prediction are found. For example, our study shows that LLMs excel in predicting time series with clear patterns and trends but face challenges with datasets lacking periodicity. We explain our findings through designing prompts to require LLMs to tell the period of the datasets. In addition, the input strategy is investigated, and it is found that incorporating external knowledge and adopting natural language paraphrases positively affects the predictive performance of LLMs for time series. Overall, this study contributes to insight into the advantages and limitations of",
    "link": "https://arxiv.org/abs/2402.10835",
    "context": "Title: Time Series Forecasting with LLMs: Understanding and Enhancing Model Capabilities\nAbstract: arXiv:2402.10835v1 Announce Type: new  Abstract: Large language models (LLMs) have been applied in many fields with rapid development in recent years. As a classic machine learning task, time series forecasting has recently received a boost from LLMs. However, there is a research gap in the LLMs' preferences in this field. In this paper, by comparing LLMs with traditional models, many properties of LLMs in time series prediction are found. For example, our study shows that LLMs excel in predicting time series with clear patterns and trends but face challenges with datasets lacking periodicity. We explain our findings through designing prompts to require LLMs to tell the period of the datasets. In addition, the input strategy is investigated, and it is found that incorporating external knowledge and adopting natural language paraphrases positively affects the predictive performance of LLMs for time series. Overall, this study contributes to insight into the advantages and limitations of",
    "path": "papers/24/02/2402.10835.json",
    "total_tokens": 985,
    "translated_title": "LLMs下的时间序列预测：理解和增强模型能力",
    "translated_abstract": "大语言模型(LLMs)近年来在许多领域得到迅速发展。作为一种经典的机器学习任务，时间序列预测最近从LLMs中获得了推动。然而，在这一领域，LLMs的偏好存在研究空白。通过将LLMs与传统模型进行比较，发现了LLMs在时间序列预测中的许多特性。例如，我们的研究表明，LLMs在预测具有明显模式和趋势的时间序列方面表现出色，但在缺乏周期性的数据集方面面临挑战。我们通过设计提示要求LLMs告知数据集的周期来解释我们的发现。此外，本文还研究了输入策略，发现融入外部知识和采用自然语言释义积极影响了LLMs在时间序列预测中的预测性能。总的来说，这项研究有助于洞察LLMs在时间序列预测中的优势和局限性。",
    "tldr": "本研究通过比较LLMs与传统模型，发现了LLMs在时间序列预测中的优势和局限性，指出LLMs在预测具有明显模式和趋势的时间序列方面表现出色，但在缺乏周期性的数据集方面面临挑战，同时指出融入外部知识和采用自然语言释义有助于提升LLMs在时间序列预测中的性能。",
    "en_tdlr": "This study compares LLMs with traditional models and identifies their strengths and limitations in time series forecasting, highlighting that LLMs excel in predicting time series with clear patterns and trends but face challenges with datasets lacking periodicity. Moreover, incorporating external knowledge and using natural language paraphrases enhance the predictive performance of LLMs in time series forecasting."
}