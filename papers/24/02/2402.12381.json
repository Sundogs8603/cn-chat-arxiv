{
    "title": "Constrained Multi-objective Optimization with Deep Reinforcement Learning Assisted Operator Selection",
    "abstract": "arXiv:2402.12381v1 Announce Type: new  Abstract: Solving constrained multi-objective optimization problems with evolutionary algorithms has attracted considerable attention. Various constrained multi-objective optimization evolutionary algorithms (CMOEAs) have been developed with the use of different algorithmic strategies, evolutionary operators, and constraint-handling techniques. The performance of CMOEAs may be heavily dependent on the operators used, however, it is usually difficult to select suitable operators for the problem at hand. Hence, improving operator selection is promising and necessary for CMOEAs. This work proposes an online operator selection framework assisted by Deep Reinforcement Learning. The dynamics of the population, including convergence, diversity, and feasibility, are regarded as the state; the candidate operators are considered as actions; and the improvement of the population state is treated as the reward. By using a Q-Network to learn a policy to estima",
    "link": "https://arxiv.org/abs/2402.12381",
    "context": "Title: Constrained Multi-objective Optimization with Deep Reinforcement Learning Assisted Operator Selection\nAbstract: arXiv:2402.12381v1 Announce Type: new  Abstract: Solving constrained multi-objective optimization problems with evolutionary algorithms has attracted considerable attention. Various constrained multi-objective optimization evolutionary algorithms (CMOEAs) have been developed with the use of different algorithmic strategies, evolutionary operators, and constraint-handling techniques. The performance of CMOEAs may be heavily dependent on the operators used, however, it is usually difficult to select suitable operators for the problem at hand. Hence, improving operator selection is promising and necessary for CMOEAs. This work proposes an online operator selection framework assisted by Deep Reinforcement Learning. The dynamics of the population, including convergence, diversity, and feasibility, are regarded as the state; the candidate operators are considered as actions; and the improvement of the population state is treated as the reward. By using a Q-Network to learn a policy to estima",
    "path": "papers/24/02/2402.12381.json",
    "total_tokens": 787,
    "translated_title": "使用深度强化学习辅助操作员选择的约束多目标优化",
    "translated_abstract": "解决带约束的多目标优化问题已经引起了相当大的关注。随着不同的算法策略、进化算子和约束处理技术的使用，已经开发了各种约束多目标优化进化算法（CMOEAs）。CMOEAs的性能可能严重依赖于所使用的操作员，然而，通常很难为手头的问题选择合适的操作员。因此，改进操作员的选择对CMOEAs是有前景的且是必要的。本文提出了一种由深度强化学习辅助的在线操作员选择框架。人口的动态性，包括收敛性、多样性和可行性，被视为状态；候选操作员被视为行动；人口状态的改善被视为奖励。通过使用Q网络来学习一个策略来估计",
    "tldr": "提出了一种由深度强化学习辅助的在线操作员选择框架，旨在改进约束多目标优化进化算法中操作员的选择问题",
    "en_tdlr": "Proposed an online operator selection framework assisted by Deep Reinforcement Learning to improve operator selection in constrained multi-objective optimization evolutionary algorithms."
}