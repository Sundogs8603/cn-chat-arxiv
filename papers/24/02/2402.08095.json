{
    "title": "Convergence Analysis of Discrete Diffusion Model: Exact Implementation through Uniformization",
    "abstract": "Diffusion models have achieved huge empirical success in data generation tasks. Recently, some efforts have been made to adapt the framework of diffusion models to discrete state space, providing a more natural approach for modeling intrinsically discrete data, such as language and graphs. This is achieved by formulating both the forward noising process and the corresponding reversed process as Continuous Time Markov Chains (CTMCs). In this paper, we investigate the theoretical properties of the discrete diffusion model. Specifically, we introduce an algorithm leveraging the uniformization of continuous Markov chains, implementing transitions on random time points. Under reasonable assumptions on the learning of the discrete score function, we derive Total Variation distance and KL divergence guarantees for sampling from any distribution on a hypercube. Our results align with state-of-the-art achievements for diffusion models in $\\mathbb{R}^d$ and further underscore the advantages of d",
    "link": "https://arxiv.org/abs/2402.08095",
    "context": "Title: Convergence Analysis of Discrete Diffusion Model: Exact Implementation through Uniformization\nAbstract: Diffusion models have achieved huge empirical success in data generation tasks. Recently, some efforts have been made to adapt the framework of diffusion models to discrete state space, providing a more natural approach for modeling intrinsically discrete data, such as language and graphs. This is achieved by formulating both the forward noising process and the corresponding reversed process as Continuous Time Markov Chains (CTMCs). In this paper, we investigate the theoretical properties of the discrete diffusion model. Specifically, we introduce an algorithm leveraging the uniformization of continuous Markov chains, implementing transitions on random time points. Under reasonable assumptions on the learning of the discrete score function, we derive Total Variation distance and KL divergence guarantees for sampling from any distribution on a hypercube. Our results align with state-of-the-art achievements for diffusion models in $\\mathbb{R}^d$ and further underscore the advantages of d",
    "path": "papers/24/02/2402.08095.json",
    "total_tokens": 901,
    "translated_title": "离散扩散模型的收敛分析：通过均匀化的确切实现",
    "translated_abstract": "扩散模型在数据生成任务中取得了巨大的经验成功。最近，一些努力已经被做出来，将扩散模型的框架适应到离散状态空间，为建模本质上是离散数据（如语言和图形）提供了一种更自然的方法。这通过将前向噪声过程和相应的逆过程都构建为连续时间马尔可夫链（CTMC）来实现。在本文中，我们研究了离散扩散模型的理论性质。具体而言，我们介绍了一种利用连续马尔可夫链均匀化的算法，在随机时间点上实现转移。在关于离散得分函数学习的合理假设下，我们得到了从超立方体上的任何分布进行采样所需的总变差距离和KL散度保证。我们的结果与在$\\mathbb{R}^d$中的扩散模型的最新成就相一致，并进一步强调了d的优势。",
    "tldr": "本文通过均匀化的方式确切实现了离散扩散模型，研究了其理论性质，并提供了关于采样的总变差距离和KL散度保证。这一方法在建模离散数据方面具有重要的应用价值。",
    "en_tdlr": "This paper presents an exact implementation of the discrete diffusion model through uniformization, investigates its theoretical properties, and provides guarantees on total variation distance and KL divergence for sampling. This approach has significant applications in modeling discrete data."
}