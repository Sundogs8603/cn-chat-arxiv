{
    "title": "HQA-Attack: Toward High Quality Black-Box Hard-Label Adversarial Attack on Text",
    "abstract": "Black-box hard-label adversarial attack on text is a practical and challenging task, as the text data space is inherently discrete and non-differentiable, and only the predicted label is accessible. Research on this problem is still in the embryonic stage and only a few methods are available. Nevertheless, existing methods rely on the complex heuristic algorithm or unreliable gradient estimation strategy, which probably fall into the local optimum and inevitably consume numerous queries, thus are difficult to craft satisfactory adversarial examples with high semantic similarity and low perturbation rate in a limited query budget. To alleviate above issues, we propose a simple yet effective framework to generate high quality textual adversarial examples under the black-box hard-label attack scenarios, named HQA-Attack. Specifically, after initializing an adversarial example randomly, HQA-attack first constantly substitutes original words back as many as possible, thus shrinking the pert",
    "link": "https://arxiv.org/abs/2402.01806",
    "context": "Title: HQA-Attack: Toward High Quality Black-Box Hard-Label Adversarial Attack on Text\nAbstract: Black-box hard-label adversarial attack on text is a practical and challenging task, as the text data space is inherently discrete and non-differentiable, and only the predicted label is accessible. Research on this problem is still in the embryonic stage and only a few methods are available. Nevertheless, existing methods rely on the complex heuristic algorithm or unreliable gradient estimation strategy, which probably fall into the local optimum and inevitably consume numerous queries, thus are difficult to craft satisfactory adversarial examples with high semantic similarity and low perturbation rate in a limited query budget. To alleviate above issues, we propose a simple yet effective framework to generate high quality textual adversarial examples under the black-box hard-label attack scenarios, named HQA-Attack. Specifically, after initializing an adversarial example randomly, HQA-attack first constantly substitutes original words back as many as possible, thus shrinking the pert",
    "path": "papers/24/02/2402.01806.json",
    "total_tokens": 915,
    "translated_title": "HQA-Attack: 面向高质量黑盒硬标签文本对抗攻击",
    "translated_abstract": "针对文本的黑盒硬标签对抗攻击是一项实际且具有挑战性的任务，因为文本数据空间本质上是离散且不可微分的，只能访问到预测标签。目前对这个问题的研究还处于初级阶段，只有少数几种方法可用。然而，现有的方法依赖于复杂的启发式算法或不可靠的梯度估计策略，很可能陷入局部最优解，并且在有限的查询预算下难以生成具有高语义相似度和低扰动率的令人满意的对抗样本。为了解决上述问题，我们提出了一种简单而有效的框架，用于在黑盒硬标签攻击场景下生成高质量的文本对抗样本，名为HQA-Attack。具体来说，HQA-Attack首先随机初始化对抗样本，然后不断尽可能地反向替换原始单词，从而缩小扰动。",
    "tldr": "HQA-Attack是一种针对黑盒硬标签文本对抗攻击的方法，通过简单有效的框架生成高质量的对抗样本，解决了现有方法在有限的查询预算下难以生成具有高语义相似度和低扰动率的问题。",
    "en_tdlr": "HQA-Attack is a method for black-box hard-label adversarial attack on text. It generates high quality adversarial examples using a simple and effective framework, addressing the challenge of generating adversarial examples with high semantic similarity and low perturbation rate under limited query budget, which existing methods struggle with."
}