{
    "title": "FairWire: Fair Graph Generation",
    "abstract": "Machine learning over graphs has recently attracted growing attention due to its ability to analyze and learn complex relations within critical interconnected systems. However, the disparate impact that is amplified by the use of biased graph structures in these algorithms has raised significant concerns for the deployment of them in real-world decision systems. In addition, while synthetic graph generation has become pivotal for privacy and scalability considerations, the impact of generative learning algorithms on the structural bias has not yet been investigated. Motivated by this, this work focuses on the analysis and mitigation of structural bias for both real and synthetic graphs. Specifically, we first theoretically analyze the sources of structural bias that result in disparity for the predictions of dyadic relations. To alleviate the identified bias factors, we design a novel fairness regularizer that offers a versatile use. Faced with the bias amplification in graph generatio",
    "link": "https://arxiv.org/abs/2402.04383",
    "context": "Title: FairWire: Fair Graph Generation\nAbstract: Machine learning over graphs has recently attracted growing attention due to its ability to analyze and learn complex relations within critical interconnected systems. However, the disparate impact that is amplified by the use of biased graph structures in these algorithms has raised significant concerns for the deployment of them in real-world decision systems. In addition, while synthetic graph generation has become pivotal for privacy and scalability considerations, the impact of generative learning algorithms on the structural bias has not yet been investigated. Motivated by this, this work focuses on the analysis and mitigation of structural bias for both real and synthetic graphs. Specifically, we first theoretically analyze the sources of structural bias that result in disparity for the predictions of dyadic relations. To alleviate the identified bias factors, we design a novel fairness regularizer that offers a versatile use. Faced with the bias amplification in graph generatio",
    "path": "papers/24/02/2402.04383.json",
    "total_tokens": 785,
    "translated_title": "公平图生成：公平性的图生成研究",
    "translated_abstract": "最近，基于图的机器学习因其分析和学习复杂关联的能力而引起了广泛关注，然而，在这些算法中使用的有偏图结构放大了不公平影响，在实际决策系统的部署中引起了重大关注。此外，尽管合成图生成对于隐私和可扩展性考虑已变得至关重要，但生成式学习算法对结构偏差的影响尚未得到调查。鉴于此，本研究侧重于分析和减轻真实和合成图的结构偏差。具体而言，我们首先理论分析造成二元关系预测不平等的结构偏差的来源。为了减轻所发现的偏差因素，我们设计了一种新的公平性正则化器，具有多种用途。鉴于图生成中的偏差放大问题",
    "tldr": "这项研究关注于分析和减轻真实和合成图中的结构偏差，通过设计一个多功能的公平性正则化器来缓解偏差影响。",
    "en_tdlr": "This research focuses on analyzing and mitigating structural bias in both real and synthetic graphs, addressing the amplification of bias through the design of a versatile fairness regularizer."
}