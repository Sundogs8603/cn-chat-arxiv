{
    "title": "KS-Lottery: Finding Certified Lottery Tickets for Multilingual Language Models",
    "abstract": "The lottery ticket hypothesis posits the existence of ``winning tickets'' within a randomly initialized neural network. Do winning tickets exist for LLMs in fine-tuning scenarios? How can we find such winning tickets? In this paper, we propose KS-Lottery, a method to identify a small subset of LLM parameters highly effective in multilingual fine-tuning. Our key idea is to use Kolmogorov-Smirnov Test to analyze the distribution shift of parameters before and after fine-tuning. We further theoretically prove that KS-Lottery can find the certified winning tickets in the embedding layer, fine-tuning on the found parameters is guaranteed to perform as well as full fine-tuning. Comparing KS-Lottery with other parameter-efficient tuning algorithms on translation tasks, the experimental results show that KS-Lottery finds a much smaller set of parameters for fine-tuning while achieving the comparable performance as full fine-tuning LLM. Surprisingly, we find that fine-tuning 18 tokens' embeddin",
    "link": "https://arxiv.org/abs/2402.02801",
    "context": "Title: KS-Lottery: Finding Certified Lottery Tickets for Multilingual Language Models\nAbstract: The lottery ticket hypothesis posits the existence of ``winning tickets'' within a randomly initialized neural network. Do winning tickets exist for LLMs in fine-tuning scenarios? How can we find such winning tickets? In this paper, we propose KS-Lottery, a method to identify a small subset of LLM parameters highly effective in multilingual fine-tuning. Our key idea is to use Kolmogorov-Smirnov Test to analyze the distribution shift of parameters before and after fine-tuning. We further theoretically prove that KS-Lottery can find the certified winning tickets in the embedding layer, fine-tuning on the found parameters is guaranteed to perform as well as full fine-tuning. Comparing KS-Lottery with other parameter-efficient tuning algorithms on translation tasks, the experimental results show that KS-Lottery finds a much smaller set of parameters for fine-tuning while achieving the comparable performance as full fine-tuning LLM. Surprisingly, we find that fine-tuning 18 tokens' embeddin",
    "path": "papers/24/02/2402.02801.json",
    "total_tokens": 921,
    "translated_title": "KS-Lottery: 寻找多语言语言模型中的认证彩票",
    "translated_abstract": "彩票票证假说认为在随机初始化的神经网络中存在“中奖票”。在微调场景中，语言模型中是否存在中奖票？我们如何找到这样的中奖票？在本文中，我们提出了KS-Lottery，一种用于识别在多语言微调中高度有效的LLM参数的方法。我们的核心思想是使用Kolmogorov-Smirnov检验来分析微调前后参数的分布偏移。我们进一步理论证明了KS-Lottery可以在嵌入层中找到认证的中奖票，微调这些参数可以保证与全面微调相同的性能。通过在翻译任务上将KS-Lottery与其他参数高效调优算法进行比较，实验结果表明，KS-Lottery找到了一个更小的参数集来进行微调，同时达到了与全面微调LLM相当的性能。令人惊讶的是，我们发现微调18个标记的嵌入层",
    "tldr": "KS-Lottery是一种寻找多语言语言模型中有效参数的方法，通过使用Kolmogorov-Smirnov检验来分析参数分布偏移，并证明了在嵌入层中可以找到认证的中奖票。这种方法可以在微调中获得与全面微调相当的性能，同时减少了所需的参数数量。",
    "en_tdlr": "KS-Lottery is a method for finding effective parameters in multilingual language models. It uses Kolmogorov-Smirnov test to analyze parameter distribution shifts and proves that certified winning tickets can be found in the embedding layer. This approach achieves comparable performance to full fine-tuning while reducing the number of parameters required."
}