{
    "title": "Incremental Sequence Labeling: A Tale of Two Shifts",
    "abstract": "arXiv:2402.10447v1 Announce Type: new  Abstract: The incremental sequence labeling task involves continuously learning new classes over time while retaining knowledge of the previous ones. Our investigation identifies two significant semantic shifts: E2O (where the model mislabels an old entity as a non-entity) and O2E (where the model labels a non-entity or old entity as a new entity). Previous research has predominantly focused on addressing the E2O problem, neglecting the O2E issue. This negligence results in a model bias towards classifying new data samples as belonging to the new class during the learning process. To address these challenges, we propose a novel framework, Incremental Sequential Labeling without Semantic Shifts (IS3). Motivated by the identified semantic shifts (E2O and O2E), IS3 aims to mitigate catastrophic forgetting in models. As for the E2O problem, we use knowledge distillation to maintain the model's discriminative ability for old entities. Simultaneously, t",
    "link": "https://arxiv.org/abs/2402.10447",
    "context": "Title: Incremental Sequence Labeling: A Tale of Two Shifts\nAbstract: arXiv:2402.10447v1 Announce Type: new  Abstract: The incremental sequence labeling task involves continuously learning new classes over time while retaining knowledge of the previous ones. Our investigation identifies two significant semantic shifts: E2O (where the model mislabels an old entity as a non-entity) and O2E (where the model labels a non-entity or old entity as a new entity). Previous research has predominantly focused on addressing the E2O problem, neglecting the O2E issue. This negligence results in a model bias towards classifying new data samples as belonging to the new class during the learning process. To address these challenges, we propose a novel framework, Incremental Sequential Labeling without Semantic Shifts (IS3). Motivated by the identified semantic shifts (E2O and O2E), IS3 aims to mitigate catastrophic forgetting in models. As for the E2O problem, we use knowledge distillation to maintain the model's discriminative ability for old entities. Simultaneously, t",
    "path": "papers/24/02/2402.10447.json",
    "total_tokens": 884,
    "translated_title": "增量序列标记：两种转变的故事",
    "translated_abstract": "增量序列标记任务涉及在保留对先前类别知识的同时，随时间不断学习新类别。我们的研究确定了两种重要的语义转变：E2O（模型将旧实体错误标记为非实体）和O2E（模型将非实体或旧实体标记为新实体）。先前的研究主要集中在解决E2O问题上，忽视了O2E问题。这种忽略导致模型在学习过程中对新数据样本进行分类时存在偏见，认为它们属于新类别。为了解决这些挑战，我们提出了一种新颖的框架，即无语义转变的增量顺序标记（IS3）。受到已确定的语义转变（E2O和O2E）的启发，IS3旨在缓解模型中的灾难性遗忘。至于E2O问题，我们使用知识蒸馏来维持模型对旧实体的判别能力。",
    "tldr": "提出了一种名为IS3的框架，旨在解决增量序列标记任务中的E2O和O2E两种重要的语义转变，通过使用知识蒸馏来维持对旧实体的判别能力。",
    "en_tdlr": "Introduced a framework called IS3 to address the two significant semantic shifts E2O and O2E in incremental sequence labeling task, by using knowledge distillation to maintain the discriminative ability for old entities."
}