{
    "title": "Confidence Matters: Revisiting Intrinsic Self-Correction Capabilities of Large Language Models",
    "abstract": "arXiv:2402.12563v1 Announce Type: cross  Abstract: The recent success of Large Language Models (LLMs) has catalyzed an increasing interest in their self-correction capabilities. This paper presents a comprehensive investigation into the intrinsic self-correction of LLMs, attempting to address the ongoing debate about its feasibility. Our research has identified an important latent factor - the ``confidence'' of LLMs - during the self-correction process. Overlooking this factor may cause the models to over-criticize themselves, resulting in unreliable conclusions regarding the efficacy of self-correction. We have experimentally observed that LLMs possess the capability to understand the ``confidence'' in their own responses. It motivates us to develop an ``If-or-Else'' (IoE) prompting framework, designed to guide LLMs in assessing their own ``confidence'', facilitating intrinsic self-corrections. We conduct extensive experiments and demonstrate that our IoE-based Prompt can achieve a co",
    "link": "https://arxiv.org/abs/2402.12563",
    "context": "Title: Confidence Matters: Revisiting Intrinsic Self-Correction Capabilities of Large Language Models\nAbstract: arXiv:2402.12563v1 Announce Type: cross  Abstract: The recent success of Large Language Models (LLMs) has catalyzed an increasing interest in their self-correction capabilities. This paper presents a comprehensive investigation into the intrinsic self-correction of LLMs, attempting to address the ongoing debate about its feasibility. Our research has identified an important latent factor - the ``confidence'' of LLMs - during the self-correction process. Overlooking this factor may cause the models to over-criticize themselves, resulting in unreliable conclusions regarding the efficacy of self-correction. We have experimentally observed that LLMs possess the capability to understand the ``confidence'' in their own responses. It motivates us to develop an ``If-or-Else'' (IoE) prompting framework, designed to guide LLMs in assessing their own ``confidence'', facilitating intrinsic self-corrections. We conduct extensive experiments and demonstrate that our IoE-based Prompt can achieve a co",
    "path": "papers/24/02/2402.12563.json",
    "total_tokens": 861,
    "translated_title": "信心至关重要：重新审视大型语言模型的内在自我校正能力",
    "translated_abstract": "大型语言模型（LLMs）的最近成功激发了对它们自我校正能力的越来越多的兴趣。本文对LLMs的内在自我校正进行了全面调查，试图解决关于其可行性的持续争论。我们的研究确定了一个重要的潜在因素 - LLMs的“信心” - 在自我校正过程中。忽视这一因素可能导致模型过度批评自己，从而导致对自校正效果的可靠结论不准确。我们实验观察到LLMs具有理解其自身回应“信心”的能力。这激励我们开发了一个“如果-否则”（IoE）提示框架，旨在引导LLMs评估其自身“信心”，促进内在自我校正。我们进行了大量实验证明，我们基于IoE的提示可以实现一",
    "tldr": "本文研究了大型语言模型的内在自我校正能力，并提出了一个“如果-否则”（IoE）提示框架，帮助模型评估自身“信心”并进行自我校正。",
    "en_tdlr": "This paper investigates the intrinsic self-correction capabilities of Large Language Models and introduces an \"If-or-Else\" (IoE) prompting framework to help the models assess their own \"confidence\" and facilitate self-correction."
}