{
    "title": "Enhancing Reinforcement Learning Agents with Local Guides",
    "abstract": "arXiv:2402.13930v1 Announce Type: new  Abstract: This paper addresses the problem of integrating local guide policies into a Reinforcement Learning agent. For this, we show how to adapt existing algorithms to this setting before introducing a novel algorithm based on a noisy policy-switching procedure. This approach builds on a proper Approximate Policy Evaluation (APE) scheme to provide a perturbation that carefully leads the local guides towards better actions. We evaluated our method on a set of classical Reinforcement Learning problems, including safety-critical systems where the agent cannot enter some areas at the risk of triggering catastrophic consequences. In all the proposed environments, our agent proved to be efficient at leveraging those policies to improve the performance of any APE-based Reinforcement Learning algorithm, especially in its first learning stages.",
    "link": "https://arxiv.org/abs/2402.13930",
    "context": "Title: Enhancing Reinforcement Learning Agents with Local Guides\nAbstract: arXiv:2402.13930v1 Announce Type: new  Abstract: This paper addresses the problem of integrating local guide policies into a Reinforcement Learning agent. For this, we show how to adapt existing algorithms to this setting before introducing a novel algorithm based on a noisy policy-switching procedure. This approach builds on a proper Approximate Policy Evaluation (APE) scheme to provide a perturbation that carefully leads the local guides towards better actions. We evaluated our method on a set of classical Reinforcement Learning problems, including safety-critical systems where the agent cannot enter some areas at the risk of triggering catastrophic consequences. In all the proposed environments, our agent proved to be efficient at leveraging those policies to improve the performance of any APE-based Reinforcement Learning algorithm, especially in its first learning stages.",
    "path": "papers/24/02/2402.13930.json",
    "total_tokens": 813,
    "translated_title": "使用本地指南增强强化学习代理",
    "translated_abstract": "本文解决了将本地指南策略整合进强化学习代理的问题。我们展示了如何调整现有算法以适应这种设置，然后介绍了一种基于噪声策略切换程序的新算法。该方法建立在适当的近似策略评估（APE）方案之上，通过精心引导本地指南朝着更好的行为方向进行扰动。我们在一组经典的强化学习问题上评估了我们的方法，包括对安全关键系统的评估，其中代理不能进入某些区域，以免触发灾难性后果。在所有提出的环境中，我们的代理都被证明在改进任何基于APE的强化学习算法的性能上是高效的，尤其是在其学习的最初阶段。",
    "tldr": "本文提出了一种添加本地指南策略到强化学习代理中的新算法，通过噪声策略切换程序和近似策略评估来引导本地指南，提高了在强化学习算法的性能，尤其在学习初期。",
    "en_tdlr": "This paper presents a new algorithm for integrating local guide policies into reinforcement learning agents, guiding the local guides through noisy policy-switching and approximate policy evaluation to enhance the performance of reinforcement learning algorithms, especially in the early stages of learning."
}