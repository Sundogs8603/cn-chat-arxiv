{
    "title": "Ouroboros: Speculative Decoding with Large Model Enhanced Drafting",
    "abstract": "arXiv:2402.13720v1 Announce Type: new  Abstract: Drafting-then-verifying decoding methods such as speculative decoding are widely adopted training-free methods to accelerate the inference of large language models (LLMs). Instead of employing an autoregressive process to decode tokens sequentially, speculative decoding initially creates drafts with an efficient small model. Then LLMs are required to conduct verification and correction in a non-autoregressive fashion to minimize time overhead. Generating longer drafts can lead to even more significant speedups once verified, but also incurs substantial trial and error costs if it fails. Suffering from the high verification failure probability, existing decoding methods cannot draft too much content for verification at one time, achieving sub-optimal inference acceleration. In this paper, we introduce Ouroboros, which constructs a phrase candidate pool from the verification process of LLMs to provide candidates for draft generation of the",
    "link": "https://arxiv.org/abs/2402.13720",
    "context": "Title: Ouroboros: Speculative Decoding with Large Model Enhanced Drafting\nAbstract: arXiv:2402.13720v1 Announce Type: new  Abstract: Drafting-then-verifying decoding methods such as speculative decoding are widely adopted training-free methods to accelerate the inference of large language models (LLMs). Instead of employing an autoregressive process to decode tokens sequentially, speculative decoding initially creates drafts with an efficient small model. Then LLMs are required to conduct verification and correction in a non-autoregressive fashion to minimize time overhead. Generating longer drafts can lead to even more significant speedups once verified, but also incurs substantial trial and error costs if it fails. Suffering from the high verification failure probability, existing decoding methods cannot draft too much content for verification at one time, achieving sub-optimal inference acceleration. In this paper, we introduce Ouroboros, which constructs a phrase candidate pool from the verification process of LLMs to provide candidates for draft generation of the",
    "path": "papers/24/02/2402.13720.json",
    "total_tokens": 650,
    "translated_title": "Ouroboros: 大模型增强草案的猜测解码技术",
    "translated_abstract": "通过构建短小高效的小模型起草草案，然后要求大语言模型以无自回归方式进行验证和修正，以最小化时间开销。当验证后可以生成更长的草稿，但也会导致相当大的尝试和错误成本。由于高验证失败概率，现有解码方法不能一次起草太多内容进行验证，实现次优的推理加速。",
    "tldr": "Ouroboros通过构建短小草案并引入候选短语池的方法提高了大语言模型推理的加速效率",
    "en_tdlr": "Ouroboros improves the acceleration efficiency of large language models inference by constructing concise drafts and introducing a pool of candidate phrases for drafting."
}