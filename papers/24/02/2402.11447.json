{
    "title": "In-Context Example Ordering Guided by Label Distributions",
    "abstract": "arXiv:2402.11447v1 Announce Type: new  Abstract: By allowing models to predict without task-specific training, in-context learning (ICL) with pretrained LLMs has enormous potential in NLP. However, a number of problems persist in ICL. In particular, its performance is sensitive to the choice and order of in-context examples. Given the same set of in-context examples with different orderings, model performance may vary between near random to near state-of-the-art. In this work, we formulate in-context example ordering as an optimization problem. We examine three problem settings that differ in the assumptions they make about what is known about the task. Inspired by the idea of learning from label proportions, we propose two principles for in-context example ordering guided by model's probability predictions. We apply our proposed principles to thirteen text classification datasets and nine different autoregressive LLMs with 700M to 13B parameters. We demonstrate that our approach outpe",
    "link": "https://arxiv.org/abs/2402.11447",
    "context": "Title: In-Context Example Ordering Guided by Label Distributions\nAbstract: arXiv:2402.11447v1 Announce Type: new  Abstract: By allowing models to predict without task-specific training, in-context learning (ICL) with pretrained LLMs has enormous potential in NLP. However, a number of problems persist in ICL. In particular, its performance is sensitive to the choice and order of in-context examples. Given the same set of in-context examples with different orderings, model performance may vary between near random to near state-of-the-art. In this work, we formulate in-context example ordering as an optimization problem. We examine three problem settings that differ in the assumptions they make about what is known about the task. Inspired by the idea of learning from label proportions, we propose two principles for in-context example ordering guided by model's probability predictions. We apply our proposed principles to thirteen text classification datasets and nine different autoregressive LLMs with 700M to 13B parameters. We demonstrate that our approach outpe",
    "path": "papers/24/02/2402.11447.json",
    "total_tokens": 839,
    "translated_title": "由标签分布引导的上下文示例排序",
    "translated_abstract": "通过允许模型在没有特定任务训练的情况下进行预测，利用预训练LLMs进行上下文学习（ICL）在自然语言处理中具有巨大潜力。然而，ICL仍然存在一些问题。特别是，其性能对于上下文示例的选择和排序非常敏感。给定具有不同排序的相同一组上下文示例，模型的性能可能在接近随机到接近最先进之间变化。在这项工作中，我们将上下文示例排序规定为一个优化问题。我们研究了三种问题设置，它们在对任务已知信息的假设方面有所不同。受到从标签比例中学习的想法的启发，我们提出了两个原则，用于根据模型的概率预测指导上下文示例排序。我们将我们提出的原则应用于十三个文本分类数据集和九个具有从700M到13B参数的不同自回归LLMs。我们展示了我们的方法优越性。",
    "tldr": "该论文提出了由模型的概率预测引导的上下文示例排序的原则，以提高上下文学习在自然语言处理中的性能。"
}