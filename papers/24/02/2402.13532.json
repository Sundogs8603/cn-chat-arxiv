{
    "title": "Backdoor Attacks on Dense Passage Retrievers for Disseminating Misinformation",
    "abstract": "arXiv:2402.13532v1 Announce Type: new  Abstract: Dense retrievers and retrieval-augmented language models have been widely used in various NLP applications. Despite being designed to deliver reliable and secure outcomes, the vulnerability of retrievers to potential attacks remains unclear, raising concerns about their security. In this paper, we introduce a novel scenario where the attackers aim to covertly disseminate targeted misinformation, such as hate speech or advertisement, through a retrieval system. To achieve this, we propose a perilous backdoor attack triggered by grammar errors in dense passage retrieval. Our approach ensures that attacked models can function normally for standard queries but are manipulated to return passages specified by the attacker when users unintentionally make grammatical mistakes in their queries. Extensive experiments demonstrate the effectiveness and stealthiness of our proposed attack method. When a user query is error-free, our model consistentl",
    "link": "https://arxiv.org/abs/2402.13532",
    "context": "Title: Backdoor Attacks on Dense Passage Retrievers for Disseminating Misinformation\nAbstract: arXiv:2402.13532v1 Announce Type: new  Abstract: Dense retrievers and retrieval-augmented language models have been widely used in various NLP applications. Despite being designed to deliver reliable and secure outcomes, the vulnerability of retrievers to potential attacks remains unclear, raising concerns about their security. In this paper, we introduce a novel scenario where the attackers aim to covertly disseminate targeted misinformation, such as hate speech or advertisement, through a retrieval system. To achieve this, we propose a perilous backdoor attack triggered by grammar errors in dense passage retrieval. Our approach ensures that attacked models can function normally for standard queries but are manipulated to return passages specified by the attacker when users unintentionally make grammatical mistakes in their queries. Extensive experiments demonstrate the effectiveness and stealthiness of our proposed attack method. When a user query is error-free, our model consistentl",
    "path": "papers/24/02/2402.13532.json",
    "total_tokens": 849,
    "translated_title": "密集通道检索器用于传播信息错误的后门攻击",
    "translated_abstract": "密集检索器和检索增强语言模型已广泛用于各种NLP应用，尽管设计用于提供可靠和安全的结果，但检索器对潜在攻击的脆弱性仍不清楚，引发人们对其安全性的关注。本文介绍了一种新颖的情景，攻击者旨在通过检索系统隐蔽传播定向错误信息，如仇恨言论或广告。为实现这一目标，我们提出了一种在密集通道检索中由语法错误触发的危险后门攻击。我们的方法确保被攻击的模型在标准查询下可以正常运行，但在用户在查询中意外地犯语法错误时，被篡改以返回攻击者指定的段落。大量实验展示了我们提出的攻击方法的有效性和隐蔽性。",
    "tldr": "本文介绍了一种后门攻击场景，攻击者通过利用密集通道检索的语法错误触发后门攻击，以秘密传播定向错误信息，如仇恨言论或广告，并通过实验证明了这种攻击方法的有效性和隐匿性。",
    "en_tdlr": "This paper presents a scenario of backdoor attack where the attackers covertly disseminate targeted misinformation, such as hate speech or advertisement, through a retrieval system by triggering grammar errors in dense passage retrieval, and demonstrates the effectiveness and stealthiness of this attack method through extensive experiments."
}