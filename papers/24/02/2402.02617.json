{
    "title": "Layer-Wise Analysis of Self-Supervised Acoustic Word Embeddings: A Study on Speech Emotion Recognition",
    "abstract": "The efficacy of self-supervised speech models has been validated, yet the optimal utilization of their representations remains challenging across diverse tasks. In this study, we delve into Acoustic Word Embeddings (AWEs), a fixed-length feature derived from continuous representations, to explore their advantages in specific tasks. AWEs have previously shown utility in capturing acoustic discriminability. In light of this, we propose measuring layer-wise similarity between AWEs and word embeddings, aiming to further investigate the inherent context within AWEs. Moreover, we evaluate the contribution of AWEs, in comparison to other types of speech features, in the context of Speech Emotion Recognition (SER). Through a comparative experiment and a layer-wise accuracy analysis on two distinct corpora, IEMOCAP and ESD, we explore differences between AWEs and raw self-supervised representations, as well as the proper utilization of AWEs alone and in combination with word embeddings. Our fin",
    "link": "https://arxiv.org/abs/2402.02617",
    "context": "Title: Layer-Wise Analysis of Self-Supervised Acoustic Word Embeddings: A Study on Speech Emotion Recognition\nAbstract: The efficacy of self-supervised speech models has been validated, yet the optimal utilization of their representations remains challenging across diverse tasks. In this study, we delve into Acoustic Word Embeddings (AWEs), a fixed-length feature derived from continuous representations, to explore their advantages in specific tasks. AWEs have previously shown utility in capturing acoustic discriminability. In light of this, we propose measuring layer-wise similarity between AWEs and word embeddings, aiming to further investigate the inherent context within AWEs. Moreover, we evaluate the contribution of AWEs, in comparison to other types of speech features, in the context of Speech Emotion Recognition (SER). Through a comparative experiment and a layer-wise accuracy analysis on two distinct corpora, IEMOCAP and ESD, we explore differences between AWEs and raw self-supervised representations, as well as the proper utilization of AWEs alone and in combination with word embeddings. Our fin",
    "path": "papers/24/02/2402.02617.json",
    "total_tokens": 1000,
    "translated_title": "自监督声学单词嵌入的逐层分析：基于语音情感识别的研究",
    "translated_abstract": "自监督语音模型的有效性已经得到验证，但其表示的最佳利用在不同任务中仍然具有挑战性。在这项研究中，我们深入探讨了声学单词嵌入（AWEs），这是一种从连续表示中得出的固定长度特征，以探索它们在特定任务中的优势。先前的研究表明AWEs在捕捉声学可辨性方面具有实用性。基于此，我们提出了衡量AWEs与单词嵌入之间逐层相似性的方法，旨在进一步研究AWEs中固有的上下文信息。此外，我们通过对两个不同语料库IEMOCAP和ESD的比较实验和逐层准确性分析，评估了AWEs与其他类型语音特征在语音情感识别中的贡献，并研究了AWEs与单词嵌入的合理利用方式。我们的研究结果揭示了AWEs与原始自监督表示之间的差异，以及AWEs单独或与单词嵌入结合使用的正确方法。",
    "tldr": "本研究通过对自监督声学单词嵌入进行逐层分析，探索其在特定任务中的优势，特别是在语音情感识别中的贡献。实验结果揭示了AWEs与原始自监督表示的差异，并提出了合理利用AWEs与单词嵌入的方法。",
    "en_tdlr": "This study conducts a layer-wise analysis of self-supervised acoustic word embeddings to explore their advantages in specific tasks, especially in speech emotion recognition. The results reveal the differences between AWEs and raw self-supervised representations and propose a proper utilization of AWEs in combination with word embeddings."
}