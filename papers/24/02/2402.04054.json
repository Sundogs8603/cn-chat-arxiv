{
    "title": "More Flexible PAC-Bayesian Meta-Learning by Learning Learning Algorithms",
    "abstract": "We introduce a new framework for studying meta-learning methods using PAC-Bayesian theory. Its main advantage over previous work is that it allows for more flexibility in how the transfer of knowledge between tasks is realized. For previous approaches, this could only happen indirectly, by means of learning prior distributions over models. In contrast, the new generalization bounds that we prove express the process of meta-learning much more directly as learning the learning algorithm that should be used for future tasks. The flexibility of our framework makes it suitable to analyze a wide range of meta-learning mechanisms and even design new mechanisms. Other than our theoretical contributions we also show empirically that our framework improves the prediction quality in practical meta-learning mechanisms.",
    "link": "https://arxiv.org/abs/2402.04054",
    "context": "Title: More Flexible PAC-Bayesian Meta-Learning by Learning Learning Algorithms\nAbstract: We introduce a new framework for studying meta-learning methods using PAC-Bayesian theory. Its main advantage over previous work is that it allows for more flexibility in how the transfer of knowledge between tasks is realized. For previous approaches, this could only happen indirectly, by means of learning prior distributions over models. In contrast, the new generalization bounds that we prove express the process of meta-learning much more directly as learning the learning algorithm that should be used for future tasks. The flexibility of our framework makes it suitable to analyze a wide range of meta-learning mechanisms and even design new mechanisms. Other than our theoretical contributions we also show empirically that our framework improves the prediction quality in practical meta-learning mechanisms.",
    "path": "papers/24/02/2402.04054.json",
    "total_tokens": 794,
    "translated_title": "通过学习学习算法，实现更灵活的PAC-Bayesian元学习",
    "translated_abstract": "我们引入了一种使用PAC-Bayesian理论研究元学习方法的新框架。与之前的工作相比，其主要优势在于它允许在任务之间的知识转移中更具灵活性。以往的方法只能通过学习模型的先验分布间接发生。相比之下，我们证明的新的泛化界限更直接地表达了元学习的过程，即学习适用于将来任务的学习算法。我们的框架的灵活性使其适用于分析各种元学习机制甚至设计新的机制。除了我们的理论贡献外，我们还在实际元学习机制中展示了我们的框架提高了预测质量。",
    "tldr": "通过学习学习算法，实现更灵活的PAC-Bayesian元学习，允许更灵活的任务之间的知识转移，提供新的泛化界限，可适用于分析和设计各种元学习机制，并在实际应用中改善了预测质量。"
}