{
    "title": "Challenges in Pre-Training Graph Neural Networks for Context-Based Fake News Detection: An Evaluation of Current Strategies and Resource Limitations",
    "abstract": "arXiv:2402.18179v1 Announce Type: new  Abstract: Pre-training of neural networks has recently revolutionized the field of Natural Language Processing (NLP) and has before demonstrated its effectiveness in computer vision. At the same time, advances around the detection of fake news were mainly driven by the context-based paradigm, where different types of signals (e.g. from social media) form graph-like structures that hold contextual information apart from the news article to classify. We propose to merge these two developments by applying pre-training of Graph Neural Networks (GNNs) in the domain of context-based fake news detection. Our experiments provide an evaluation of different pre-training strategies for graph-based misinformation detection and demonstrate that transfer learning does currently not lead to significant improvements over training a model from scratch in the domain. We argue that a major current issue is the lack of suitable large-scale resources that can be used ",
    "link": "https://arxiv.org/abs/2402.18179",
    "context": "Title: Challenges in Pre-Training Graph Neural Networks for Context-Based Fake News Detection: An Evaluation of Current Strategies and Resource Limitations\nAbstract: arXiv:2402.18179v1 Announce Type: new  Abstract: Pre-training of neural networks has recently revolutionized the field of Natural Language Processing (NLP) and has before demonstrated its effectiveness in computer vision. At the same time, advances around the detection of fake news were mainly driven by the context-based paradigm, where different types of signals (e.g. from social media) form graph-like structures that hold contextual information apart from the news article to classify. We propose to merge these two developments by applying pre-training of Graph Neural Networks (GNNs) in the domain of context-based fake news detection. Our experiments provide an evaluation of different pre-training strategies for graph-based misinformation detection and demonstrate that transfer learning does currently not lead to significant improvements over training a model from scratch in the domain. We argue that a major current issue is the lack of suitable large-scale resources that can be used ",
    "path": "papers/24/02/2402.18179.json",
    "total_tokens": 907,
    "translated_title": "针对基于上下文的假新闻检测预训练图神经网络的挑战：对当前策略和资源限制的评估",
    "translated_abstract": "神经网络的预训练最近在自然语言处理（NLP）领域彻底改变了局面，并且已经在计算机视觉领域证明了其有效性。同时，关于假新闻检测的进展主要受到基于上下文范式的驱动，其中来自社交媒体等不同类型信号形成类似图形结构，其中包含除新闻文章以外的上下文信息以进行分类。我们建议将这两个发展合并，通过在基于上下文的假新闻检测领域应用图神经网络（GNNs）的预训练。我们的实验评估了基于图的虚假信息检测的不同预训练策略，并证明了目前转移学习并未导致显着改进，优于从头开始训练模型。我们认为目前的主要问题是缺乏适用的大规模资源可以使用。",
    "tldr": "将神经网络预训练与图神经网络在基于上下文的假新闻检测领域相结合，评估了不同预训练策略，并指出目前转移学习并未显著改进模型性能，主要问题在于缺乏大规模资源。"
}