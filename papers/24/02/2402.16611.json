{
    "title": "Understanding the Dataset Practitioners Behind Large Language Model Development",
    "abstract": "arXiv:2402.16611v1 Announce Type: new  Abstract: As large language models (LLMs) become more advanced and impactful, it is increasingly important to scrutinize the data that they rely upon and produce. What is it to be a dataset practitioner doing this work? We approach this in two parts: first, we define the role of \"dataset practitioner\" by performing a retrospective analysis on the responsibilities of teams contributing to LLM development at Google. Then, we conduct semi-structured interviews with a cross-section of these practitioners (N=10). We find that data quality is the top priority. To evaluate data quality, practitioners either rely on their own intuition or write custom evaluation logic. There is a lack of consensus across practitioners on what quality is and how to evaluate it. We discuss potential reasons for this phenomenon and opportunities for alignment.",
    "link": "https://arxiv.org/abs/2402.16611",
    "context": "Title: Understanding the Dataset Practitioners Behind Large Language Model Development\nAbstract: arXiv:2402.16611v1 Announce Type: new  Abstract: As large language models (LLMs) become more advanced and impactful, it is increasingly important to scrutinize the data that they rely upon and produce. What is it to be a dataset practitioner doing this work? We approach this in two parts: first, we define the role of \"dataset practitioner\" by performing a retrospective analysis on the responsibilities of teams contributing to LLM development at Google. Then, we conduct semi-structured interviews with a cross-section of these practitioners (N=10). We find that data quality is the top priority. To evaluate data quality, practitioners either rely on their own intuition or write custom evaluation logic. There is a lack of consensus across practitioners on what quality is and how to evaluate it. We discuss potential reasons for this phenomenon and opportunities for alignment.",
    "path": "papers/24/02/2402.16611.json",
    "total_tokens": 754,
    "translated_title": "理解大型语言模型开发背后的数据集管理者",
    "translated_abstract": "随着大型语言模型(LLMs)变得越来越先进和有影响力，审视它们依赖和产生的数据变得越来越重要。本文探讨了数据集管理者的工作内容：首先，我们通过对谷歌贡献LLM开发团队责任的回顾性分析，定义了“数据集管理者”的角色。然后，我们对这些管理者进行了半结构化访谈（N=10）。我们发现数据质量是首要任务。为了评估数据质量，管理者要么凭直觉，要么编写自定义评估逻辑。管理者之间对数据质量的定义和评估方法缺乏共识。我们讨论了这种现象的潜在原因和实现一致性的机会。",
    "tldr": "数据质量是大型语言模型开发中数据集管理者的首要任务，但管理者间对于数据质量定义和评估方法缺乏共识。",
    "en_tdlr": "Data quality is the top priority for dataset practitioners in large language model development, but there is a lack of consensus among practitioners on the definition and evaluation methods of data quality."
}