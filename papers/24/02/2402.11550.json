{
    "title": "LongAgent: Scaling Language Models to 128k Context through Multi-Agent Collaboration",
    "abstract": "arXiv:2402.11550v1 Announce Type: cross  Abstract: Large language models (LLMs) have demonstrated impressive performance in understanding language and executing complex reasoning tasks. However, LLMs with long context windows have been notorious for their expensive training costs and high inference latency. Even the most advanced models such as GPT-4 and Claude2 often make mistakes when processing inputs of over $100k$ tokens, a phenomenon also known as \\textit{lost in the middle}. In this paper, we propose \\textsc{LongAgent}, a method based on multi-agent collaboration, which scales LLMs (e.g., LLaMA) to a context of 128K and demonstrates potential superiority in long-text processing compared to GPT-4. In \\textsc{LongAgent}, a leader is responsible for understanding user intent and directing team members to acquire information from documents. Due to members' hallucinations, it is non-trivial for a leader to obtain accurate information from the responses of dozens to hundreds of member",
    "link": "https://arxiv.org/abs/2402.11550",
    "context": "Title: LongAgent: Scaling Language Models to 128k Context through Multi-Agent Collaboration\nAbstract: arXiv:2402.11550v1 Announce Type: cross  Abstract: Large language models (LLMs) have demonstrated impressive performance in understanding language and executing complex reasoning tasks. However, LLMs with long context windows have been notorious for their expensive training costs and high inference latency. Even the most advanced models such as GPT-4 and Claude2 often make mistakes when processing inputs of over $100k$ tokens, a phenomenon also known as \\textit{lost in the middle}. In this paper, we propose \\textsc{LongAgent}, a method based on multi-agent collaboration, which scales LLMs (e.g., LLaMA) to a context of 128K and demonstrates potential superiority in long-text processing compared to GPT-4. In \\textsc{LongAgent}, a leader is responsible for understanding user intent and directing team members to acquire information from documents. Due to members' hallucinations, it is non-trivial for a leader to obtain accurate information from the responses of dozens to hundreds of member",
    "path": "papers/24/02/2402.11550.json",
    "total_tokens": 841,
    "translated_title": "LongAgent: 通过多智能体协作将语言模型扩展到128K上下文",
    "translated_abstract": "大型语言模型（LLMs）在理解语言和执行复杂推理任务方面表现出色。然而，具有长上下文窗口的LLMs以其昂贵的训练成本和高推理延迟而臭名昭著。即使是最先进的模型如GPT-4和Claude2在处理超过$100k$标记的输入时也经常出错，这种现象也被称为\\textit{中间迷失}。在本文中，我们提出了基于多智能体协作的方法\\textsc{LongAgent}，将LLMs（例如LLaMA）扩展到128K上下文，并展示出在长文本处理方面可能优于GPT-4的潜力。在\\textsc{LongAgent}中，一位领导者负责理解用户意图并指导团队成员从文档中获取信息。由于成员存在幻觉，领导者从几十到数百名成员的回应中获取准确信息并非易事。",
    "tldr": "LongAgent通过多智能体协作将语言模型扩展到128K上下文，并在长文本处理方面表现出潜在的优越性。",
    "en_tdlr": "LongAgent scales language models to 128K context through multi-agent collaboration and demonstrates potential superiority in long-text processing."
}