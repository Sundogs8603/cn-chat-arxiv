{
    "title": "The Da Vinci Code of Large Pre-trained Language Models: Deciphering Degenerate Knowledge Neurons",
    "abstract": "arXiv:2402.13731v1 Announce Type: cross  Abstract: This study explores the mechanism of factual knowledge storage in pre-trained language models (PLMs). Previous research suggests that factual knowledge is stored within multi-layer perceptron weights, and some storage units exhibit degeneracy, referred to as Degenerate Knowledge Neurons (DKNs). This paper provides a comprehensive definition of DKNs that covers both structural and functional aspects, pioneering the study of structures in PLMs' factual knowledge storage units. Based on this, we introduce the Neurological Topology Clustering method, which allows the formation of DKNs in any numbers and structures, leading to a more accurate DKN acquisition. Furthermore, we introduce the Neuro-Degeneracy Analytic Analysis Framework, which uniquely integrates model robustness, evolvability, and complexity for a holistic assessment of PLMs. Within this framework, our execution of 34 experiments across 2 PLMs, 4 datasets, and 6 settings highl",
    "link": "https://arxiv.org/abs/2402.13731",
    "context": "Title: The Da Vinci Code of Large Pre-trained Language Models: Deciphering Degenerate Knowledge Neurons\nAbstract: arXiv:2402.13731v1 Announce Type: cross  Abstract: This study explores the mechanism of factual knowledge storage in pre-trained language models (PLMs). Previous research suggests that factual knowledge is stored within multi-layer perceptron weights, and some storage units exhibit degeneracy, referred to as Degenerate Knowledge Neurons (DKNs). This paper provides a comprehensive definition of DKNs that covers both structural and functional aspects, pioneering the study of structures in PLMs' factual knowledge storage units. Based on this, we introduce the Neurological Topology Clustering method, which allows the formation of DKNs in any numbers and structures, leading to a more accurate DKN acquisition. Furthermore, we introduce the Neuro-Degeneracy Analytic Analysis Framework, which uniquely integrates model robustness, evolvability, and complexity for a holistic assessment of PLMs. Within this framework, our execution of 34 experiments across 2 PLMs, 4 datasets, and 6 settings highl",
    "path": "papers/24/02/2402.13731.json",
    "total_tokens": 920,
    "translated_title": "大型预训练语言模型的达芬奇密码：解读退化知识神经元",
    "translated_abstract": "本研究探讨了预训练语言模型（PLMs）中事实知识存储的机制。先前的研究表明，事实知识存储在多层感知器权重中，某些存储单元表现出退化性，称为退化知识神经元（Degenerate Knowledge Neurons, DKNs）。本文提供了一个涵盖结构和功能方面的DKNs全面定义，开创了对PLMs事实知识存储单元结构的研究。基于此，我们引入了神经拓扑聚类方法，该方法允许形成任意数量和结构的DKNs，从而实现更准确的DKN获取。此外，我们引入了神经退化分析框架，独特地整合了模型鲁棒性、可进化性和复杂性，以对PLMs进行全面评估。在该框架内，我们执行了34个实验，跨越2个PLMs、4个数据集和6个设置。",
    "tldr": "本研究提供了对预训练语言模型中退化知识神经元（DKNs）的全面定义，引入了神经拓扑聚类方法和神经退化分析框架，从而实现更准确的DKN获取。"
}