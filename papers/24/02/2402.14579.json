{
    "title": "Text Role Classification in Scientific Charts Using Multimodal Transformers",
    "abstract": "arXiv:2402.14579v1 Announce Type: cross  Abstract: Text role classification involves classifying the semantic role of textual elements within scientific charts. For this task, we propose to finetune two pretrained multimodal document layout analysis models, LayoutLMv3 and UDOP, on chart datasets. The transformers utilize the three modalities of text, image, and layout as input. We further investigate whether data augmentation and balancing methods help the performance of the models. The models are evaluated on various chart datasets, and results show that LayoutLMv3 outperforms UDOP in all experiments. LayoutLMv3 achieves the highest F1-macro score of 82.87 on the ICPR22 test dataset, beating the best-performing model from the ICPR22 CHART-Infographics challenge. Moreover, the robustness of the models is tested on a synthetic noisy dataset ICPR22-N. Finally, the generalizability of the models is evaluated on three chart datasets, CHIME-R, DeGruyter, and EconBiz, for which we added labe",
    "link": "https://arxiv.org/abs/2402.14579",
    "context": "Title: Text Role Classification in Scientific Charts Using Multimodal Transformers\nAbstract: arXiv:2402.14579v1 Announce Type: cross  Abstract: Text role classification involves classifying the semantic role of textual elements within scientific charts. For this task, we propose to finetune two pretrained multimodal document layout analysis models, LayoutLMv3 and UDOP, on chart datasets. The transformers utilize the three modalities of text, image, and layout as input. We further investigate whether data augmentation and balancing methods help the performance of the models. The models are evaluated on various chart datasets, and results show that LayoutLMv3 outperforms UDOP in all experiments. LayoutLMv3 achieves the highest F1-macro score of 82.87 on the ICPR22 test dataset, beating the best-performing model from the ICPR22 CHART-Infographics challenge. Moreover, the robustness of the models is tested on a synthetic noisy dataset ICPR22-N. Finally, the generalizability of the models is evaluated on three chart datasets, CHIME-R, DeGruyter, and EconBiz, for which we added labe",
    "path": "papers/24/02/2402.14579.json",
    "total_tokens": 888,
    "translated_title": "使用多模态Transformer在科学图表中进行文本角色分类",
    "translated_abstract": "文本角色分类涉及对科学图表中的文本元素的语义角色进行分类。对于这一任务，我们提出在图表数据集上对两个预训练的多模态文档布局分析模型LayoutLMv3和UDOP进行微调。这些Transformer利用文本、图像和布局三种模态作为输入。我们进一步探讨数据增强和平衡方法是否有助于模型的性能。这些模型在各种图表数据集上进行评估，结果显示LayoutLMv3在所有实验中均优于UDOP。LayoutLMv3在ICPR22测试数据集上实现了82.87的最高F1-macro分数，超过了ICPR22 CHART-Infographics挑战中表现最好的模型。此外，模型的鲁棒性在一个合成的嘈杂数据集ICPR22-N上进行了测试。最后，我们评估了模型在三个图表数据集CHIME-R、DeGruyter和EconBiz上的泛化性能，我们为这些数据集添加了标签。",
    "tldr": "该研究提出了使用多模态Transformer在科学图表中进行文本角色分类的方法，并在实验中发现LayoutLMv3在性能上优于UDOP，最高达到了82.87的F1-macro分数。",
    "en_tdlr": "This study proposes a method for text role classification in scientific charts using multimodal Transformers, finding that LayoutLMv3 outperforms UDOP in performance, achieving the highest F1-macro score of 82.87."
}