{
    "title": "Stochastic Modified Flows for Riemannian Stochastic Gradient Descent",
    "abstract": "We give quantitative estimates for the rate of convergence of Riemannian stochastic gradient descent (RSGD) to Riemannian gradient flow and to a diffusion process, the so-called Riemannian stochastic modified flow (RSMF). Using tools from stochastic differential geometry we show that, in the small learning rate regime, RSGD can be approximated by the solution to the RSMF driven by an infinite-dimensional Wiener process. The RSMF accounts for the random fluctuations of RSGD and, thereby, increases the order of approximation compared to the deterministic Riemannian gradient flow. The RSGD is build using the concept of a retraction map, that is, a cost efficient approximation of the exponential map, and we prove quantitative bounds for the weak error of the diffusion approximation under assumptions on the retraction map, the geometry of the manifold, and the random estimators of the gradient.",
    "link": "https://arxiv.org/abs/2402.03467",
    "context": "Title: Stochastic Modified Flows for Riemannian Stochastic Gradient Descent\nAbstract: We give quantitative estimates for the rate of convergence of Riemannian stochastic gradient descent (RSGD) to Riemannian gradient flow and to a diffusion process, the so-called Riemannian stochastic modified flow (RSMF). Using tools from stochastic differential geometry we show that, in the small learning rate regime, RSGD can be approximated by the solution to the RSMF driven by an infinite-dimensional Wiener process. The RSMF accounts for the random fluctuations of RSGD and, thereby, increases the order of approximation compared to the deterministic Riemannian gradient flow. The RSGD is build using the concept of a retraction map, that is, a cost efficient approximation of the exponential map, and we prove quantitative bounds for the weak error of the diffusion approximation under assumptions on the retraction map, the geometry of the manifold, and the random estimators of the gradient.",
    "path": "papers/24/02/2402.03467.json",
    "total_tokens": 869,
    "translated_title": "基于随机修改流的黎曼随机梯度下降",
    "translated_abstract": "我们对黎曼随机梯度下降（RSGD）收敛速度给出了定量估计，并将其与黎曼梯度流和扩散过程——黎曼随机修改流（RSMF）进行了比较。利用随机微分几何工具，我们证明在小学习率范围内，RSGD可以近似为由无穷维维纳过程驱动的RSMF的解。RSMF考虑到了RSGD的随机波动，从而提高了与确定性黎曼梯度流的逼近顺序。RSGD使用了重传递映射的概念，即对指数映射的一种成本效益近似，我们对扩散逼近的弱误差进行了定量界定，在重传递映射、流形几何和梯度的随机估计的假设下证明了这些界定。",
    "tldr": "本文研究了黎曼随机梯度下降（RSGD）的收敛速度，并介绍了一种基于随机修改流（RSMF）的扩散逼近方法，该方法可以提高对RSGD的近似精度。"
}