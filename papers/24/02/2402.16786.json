{
    "title": "Political Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in Large Language Models",
    "abstract": "arXiv:2402.16786v1 Announce Type: new  Abstract: Much recent work seeks to evaluate values and opinions in large language models (LLMs) using multiple-choice surveys and questionnaires. Most of this work is motivated by concerns around real-world LLM applications. For example, politically-biased LLMs may subtly influence society when they are used by millions of people. Such real-world concerns, however, stand in stark contrast to the artificiality of current evaluations: real users do not typically ask LLMs survey questions. Motivated by this discrepancy, we challenge the prevailing constrained evaluation paradigm for values and opinions in LLMs and explore more realistic unconstrained evaluations. As a case study, we focus on the popular Political Compass Test (PCT). In a systematic review, we find that most prior work using the PCT forces models to comply with the PCT's multiple-choice format. We show that models give substantively different answers when not forced; that answers cha",
    "link": "https://arxiv.org/abs/2402.16786",
    "context": "Title: Political Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in Large Language Models\nAbstract: arXiv:2402.16786v1 Announce Type: new  Abstract: Much recent work seeks to evaluate values and opinions in large language models (LLMs) using multiple-choice surveys and questionnaires. Most of this work is motivated by concerns around real-world LLM applications. For example, politically-biased LLMs may subtly influence society when they are used by millions of people. Such real-world concerns, however, stand in stark contrast to the artificiality of current evaluations: real users do not typically ask LLMs survey questions. Motivated by this discrepancy, we challenge the prevailing constrained evaluation paradigm for values and opinions in LLMs and explore more realistic unconstrained evaluations. As a case study, we focus on the popular Political Compass Test (PCT). In a systematic review, we find that most prior work using the PCT forces models to comply with the PCT's multiple-choice format. We show that models give substantively different answers when not forced; that answers cha",
    "path": "papers/24/02/2402.16786.json",
    "total_tokens": 862,
    "translated_title": "政治罗盘或旋转箭？朝着对大型语言模型中价值观和观点更有意义的评估",
    "translated_abstract": "最近的许多工作通过多项选择调查和问卷来评估大型语言模型（LLMs）中的价值观和观点。大多数工作的动机是源于对现实世界中LLM应用的担忧。然而，这种对现实世界的关注与当前评估的人为性形成鲜明对比：真实用户通常不会向LLMs提出调查问题。受到这种差异的启发，我们挑战了目前对LLMs中价值观和观点的约束评估范式，并探索了更现实的不受限制的评估。作为一个案例研究，我们专注于广受欢迎的政治罗盘测试（PCT）。在一个系统性评估中，我们发现大多数先前使用PCT的工作都强制模型遵守PCT的多项选择格式。我们展示了当不被强制时，模型给出的答案实质上是不同的；",
    "tldr": "挑战传统的受限评估范式，探索更真实的不受限制的对大型语言模型中价值观和观点的评估方法。"
}