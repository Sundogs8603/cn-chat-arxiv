{
    "title": "Rethinking Skill Extraction in the Job Market Domain using Large Language Models",
    "abstract": "Skill Extraction involves identifying skills and qualifications mentioned in documents such as job postings and resumes. The task is commonly tackled by training supervised models using a sequence labeling approach with BIO tags. However, the reliance on manually annotated data limits the generalizability of such approaches. Moreover, the common BIO setting limits the ability of the models to capture complex skill patterns and handle ambiguous mentions. In this paper, we explore the use of in-context learning to overcome these challenges, on a benchmark of 6 uniformized skill extraction datasets. Our approach leverages the few-shot learning capabilities of large language models (LLMs) to identify and extract skills from sentences. We show that LLMs, despite not being on par with traditional supervised models in terms of performance, can better handle syntactically complex skill mentions in skill extraction tasks.",
    "link": "https://arxiv.org/abs/2402.03832",
    "context": "Title: Rethinking Skill Extraction in the Job Market Domain using Large Language Models\nAbstract: Skill Extraction involves identifying skills and qualifications mentioned in documents such as job postings and resumes. The task is commonly tackled by training supervised models using a sequence labeling approach with BIO tags. However, the reliance on manually annotated data limits the generalizability of such approaches. Moreover, the common BIO setting limits the ability of the models to capture complex skill patterns and handle ambiguous mentions. In this paper, we explore the use of in-context learning to overcome these challenges, on a benchmark of 6 uniformized skill extraction datasets. Our approach leverages the few-shot learning capabilities of large language models (LLMs) to identify and extract skills from sentences. We show that LLMs, despite not being on par with traditional supervised models in terms of performance, can better handle syntactically complex skill mentions in skill extraction tasks.",
    "path": "papers/24/02/2402.03832.json",
    "total_tokens": 814,
    "translated_title": "用大型语言模型重新思考职场领域的技能提取",
    "translated_abstract": "技能提取是指在招聘岗位和简历等文档中识别提及的技能和背景要求。这项任务通常通过使用BIO标签的序列标注方法训练监督模型来解决。然而，依赖手工注释的数据限制了这种方法的泛化能力。此外，常见的BIO设置限制了模型捕捉复杂技能模式和处理模糊提及的能力。在本文中，我们探索了使用上下文学习来克服这些挑战，在一个包含6个统一化技能提取数据集的基准上进行实验。我们的方法利用了大型语言模型的少样本学习能力，从句子中识别和提取技能。我们表明，尽管在性能方面不及传统的监督模型，但大型语言模型能更好地处理在技能提取任务中句法复杂的技能提及。",
    "tldr": "本文探索了使用大型语言模型来解决职场领域技能提取的问题，提出了一种利用上下文学习的方法，并验证了该方法在处理句法复杂的技能提及时的有效性。",
    "en_tdlr": "This paper explores the use of large language models to tackle skill extraction in the job market, proposing an in-context learning approach and demonstrating its effectiveness in dealing with syntactically complex skill mentions."
}