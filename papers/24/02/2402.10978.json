{
    "title": "Language Models with Conformal Factuality Guarantees",
    "abstract": "arXiv:2402.10978v1 Announce Type: cross  Abstract: Guaranteeing the correctness and factuality of language model (LM) outputs is a major open problem. In this work, we propose conformal factuality, a framework that can ensure high probability correctness guarantees for LMs by connecting language modeling and conformal prediction. We observe that the correctness of an LM output is equivalent to an uncertainty quantification problem, where the uncertainty sets are defined as the entailment set of an LM's output. Using this connection, we show that conformal prediction in language models corresponds to a back-off algorithm that provides high probability correctness guarantees by progressively making LM outputs less specific (and expanding the associated uncertainty sets). This approach applies to any black-box LM and requires very few human-annotated samples. Evaluations of our approach on closed book QA (FActScore, NaturalQuestions) and reasoning tasks (MATH) show that our approach can p",
    "link": "https://arxiv.org/abs/2402.10978",
    "context": "Title: Language Models with Conformal Factuality Guarantees\nAbstract: arXiv:2402.10978v1 Announce Type: cross  Abstract: Guaranteeing the correctness and factuality of language model (LM) outputs is a major open problem. In this work, we propose conformal factuality, a framework that can ensure high probability correctness guarantees for LMs by connecting language modeling and conformal prediction. We observe that the correctness of an LM output is equivalent to an uncertainty quantification problem, where the uncertainty sets are defined as the entailment set of an LM's output. Using this connection, we show that conformal prediction in language models corresponds to a back-off algorithm that provides high probability correctness guarantees by progressively making LM outputs less specific (and expanding the associated uncertainty sets). This approach applies to any black-box LM and requires very few human-annotated samples. Evaluations of our approach on closed book QA (FActScore, NaturalQuestions) and reasoning tasks (MATH) show that our approach can p",
    "path": "papers/24/02/2402.10978.json",
    "total_tokens": 779,
    "translated_title": "具有符合事实性保证的语言模型",
    "translated_abstract": "语言模型（LM）输出的正确性和事实性保证是一个重要的开放问题。在这项工作中，我们提出了符合事实性，这是一个框架，可以通过连接语言建模和符合预测，确保LM的高概率正确性保证。我们观察到，LM输出的正确性等价于一个不确定性量化问题，其中不确定性集被定义为LM输出的蕴含集。利用这种联系，我们表明，语言模型中的符合预测对应于一种后退算法，通过逐渐使LM输出变得不太具体（并扩大相关的不确定性集）提供高概率的正确性保证。这种方法适用于任何黑盒LM，并且需要很少的人工注释样本。我们在封闭书籍QA（FActScore，NaturalQuestions）和推理任务（MATH）上对我们的方法进行评估，结果表明我们的方法可以p",
    "tldr": "提出了一种能够通过连接语言建模和符合预测为语言模型提供高概率正确性保证的框架。",
    "en_tdlr": "Propose a framework that can ensure high probability correctness guarantees for language models by connecting language modeling and conformal prediction."
}