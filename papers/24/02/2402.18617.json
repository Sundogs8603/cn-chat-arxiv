{
    "title": "ELA: Exploited Level Augmentation for Offline Learning in Zero-Sum Games",
    "abstract": "arXiv:2402.18617v1 Announce Type: cross  Abstract: Offline learning has become widely used due to its ability to derive effective policies from offline datasets gathered by expert demonstrators without interacting with the environment directly. Recent research has explored various ways to enhance offline learning efficiency by considering the characteristics (e.g., expertise level or multiple demonstrators) of the dataset. However, a different approach is necessary in the context of zero-sum games, where outcomes vary significantly based on the strategy of the opponent. In this study, we introduce a novel approach that uses unsupervised learning techniques to estimate the exploited level of each trajectory from the offline dataset of zero-sum games made by diverse demonstrators. Subsequently, we incorporate the estimated exploited level into the offline learning to maximize the influence of the dominant strategy. Our method enables interpretable exploited level estimation in multiple z",
    "link": "https://arxiv.org/abs/2402.18617",
    "context": "Title: ELA: Exploited Level Augmentation for Offline Learning in Zero-Sum Games\nAbstract: arXiv:2402.18617v1 Announce Type: cross  Abstract: Offline learning has become widely used due to its ability to derive effective policies from offline datasets gathered by expert demonstrators without interacting with the environment directly. Recent research has explored various ways to enhance offline learning efficiency by considering the characteristics (e.g., expertise level or multiple demonstrators) of the dataset. However, a different approach is necessary in the context of zero-sum games, where outcomes vary significantly based on the strategy of the opponent. In this study, we introduce a novel approach that uses unsupervised learning techniques to estimate the exploited level of each trajectory from the offline dataset of zero-sum games made by diverse demonstrators. Subsequently, we incorporate the estimated exploited level into the offline learning to maximize the influence of the dominant strategy. Our method enables interpretable exploited level estimation in multiple z",
    "path": "papers/24/02/2402.18617.json",
    "total_tokens": 913,
    "translated_title": "ELA：零和博弈中融入利用水平的离线学习",
    "translated_abstract": "离线学习由于能够从专家示范者收集的离线数据集中推导出有效策略而不需要直接与环境进行交互，已经被广泛使用。最近的研究探索了通过考虑数据集的特征（例如，专业水平或多个示范者）来增强离线学习效率的各种方式。然而，在零和博弈的背景下，需要一种不同的方法，因为结果根据对手的策略而显著变化。在本研究中，我们介绍了一种新颖的方法，利用无监督学习技术估计由不同示范者制作的零和博弈的离线数据集中每条轨迹的被利用水平。随后，我们将估计的被利用水平结合到离线学习中，以最大化支配策略的影响力。我们的方法实现了在多个示范者的零和博弈离线数据集中可解释的被利用水平估计。",
    "tldr": "该研究提出了一种新颖的方法，利用无监督学习技术估计不同示范者制作的零和博弈离线数据集中每条轨迹的被利用水平，并将其融入离线学习以最大化支配策略的影响力。",
    "en_tdlr": "This study introduces a novel approach that uses unsupervised learning techniques to estimate the exploited level of each trajectory from the offline dataset of zero-sum games made by diverse demonstrators and incorporates it into offline learning to maximize the influence of the dominant strategy."
}