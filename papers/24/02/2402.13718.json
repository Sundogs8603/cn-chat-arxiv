{
    "title": "$\\infty$Bench: Extending Long Context Evaluation Beyond 100K Tokens",
    "abstract": "arXiv:2402.13718v1 Announce Type: new  Abstract: Processing and reasoning over long contexts is crucial for many practical applications of Large Language Models (LLMs), such as document comprehension and agent construction. Despite recent strides in making LLMs process contexts with more than 100K tokens, there is currently a lack of a standardized benchmark to evaluate this long-context capability. Existing public benchmarks typically focus on contexts around 10K tokens, limiting the assessment and comparison of LLMs in processing longer contexts. In this paper, we propose $\\infty$Bench, the first LLM benchmark featuring an average data length surpassing 100K tokens. $\\infty$Bench comprises synthetic and realistic tasks spanning diverse domains, presented in both English and Chinese. The tasks in $\\infty$Bench are designed to require well understanding of long dependencies in contexts, and make simply retrieving a limited number of passages from contexts not sufficient for these tasks",
    "link": "https://arxiv.org/abs/2402.13718",
    "context": "Title: $\\infty$Bench: Extending Long Context Evaluation Beyond 100K Tokens\nAbstract: arXiv:2402.13718v1 Announce Type: new  Abstract: Processing and reasoning over long contexts is crucial for many practical applications of Large Language Models (LLMs), such as document comprehension and agent construction. Despite recent strides in making LLMs process contexts with more than 100K tokens, there is currently a lack of a standardized benchmark to evaluate this long-context capability. Existing public benchmarks typically focus on contexts around 10K tokens, limiting the assessment and comparison of LLMs in processing longer contexts. In this paper, we propose $\\infty$Bench, the first LLM benchmark featuring an average data length surpassing 100K tokens. $\\infty$Bench comprises synthetic and realistic tasks spanning diverse domains, presented in both English and Chinese. The tasks in $\\infty$Bench are designed to require well understanding of long dependencies in contexts, and make simply retrieving a limited number of passages from contexts not sufficient for these tasks",
    "path": "papers/24/02/2402.13718.json",
    "total_tokens": 740,
    "translated_title": "$\\infty$Bench: 将长上下文评估扩展至超过10万令牌",
    "translated_abstract": "处理和推理长上下文对于大型语言模型（LLMs）的许多实际应用至关重要，如文档理解和代理构建。本文提出$\\infty$Bench，第一个LLM基准，平均数据长度超过10万个令牌。$\\infty$Bench包含涵盖不同领域的合成和现实任务，以英文和中文呈现。$\\infty$Bench中的任务旨在需要深刻理解上下文中的长依赖性，并且简单地从上下文中检索有限数量的段落对于这些任务来说是不够的。",
    "tldr": "提出了$\\infty$Bench，第一个以平均数据长度超过10万个令牌的LLM基准，用于评估处理长上下文的能力",
    "en_tdlr": "The paper introduces $\\infty$Bench, the first LLM benchmark with an average data length surpassing 100K tokens, to evaluate the capability of processing long contexts."
}