{
    "title": "Characterizing Truthfulness in Large Language Model Generations with Local Intrinsic Dimension",
    "abstract": "arXiv:2402.18048v1 Announce Type: new  Abstract: We study how to characterize and predict the truthfulness of texts generated from large language models (LLMs), which serves as a crucial step in building trust between humans and LLMs. Although several approaches based on entropy or verbalized uncertainty have been proposed to calibrate model predictions, these methods are often intractable, sensitive to hyperparameters, and less reliable when applied in generative tasks with LLMs. In this paper, we suggest investigating internal activations and quantifying LLM's truthfulness using the local intrinsic dimension (LID) of model activations. Through experiments on four question answering (QA) datasets, we demonstrate the effectiveness ohttps://info.arxiv.org/help/prep#abstractsf our proposed method. Additionally, we study intrinsic dimensions in LLMs and their relations with model layers, autoregressive language modeling, and the training of LLMs, revealing that intrinsic dimensions can be",
    "link": "https://arxiv.org/abs/2402.18048",
    "context": "Title: Characterizing Truthfulness in Large Language Model Generations with Local Intrinsic Dimension\nAbstract: arXiv:2402.18048v1 Announce Type: new  Abstract: We study how to characterize and predict the truthfulness of texts generated from large language models (LLMs), which serves as a crucial step in building trust between humans and LLMs. Although several approaches based on entropy or verbalized uncertainty have been proposed to calibrate model predictions, these methods are often intractable, sensitive to hyperparameters, and less reliable when applied in generative tasks with LLMs. In this paper, we suggest investigating internal activations and quantifying LLM's truthfulness using the local intrinsic dimension (LID) of model activations. Through experiments on four question answering (QA) datasets, we demonstrate the effectiveness ohttps://info.arxiv.org/help/prep#abstractsf our proposed method. Additionally, we study intrinsic dimensions in LLMs and their relations with model layers, autoregressive language modeling, and the training of LLMs, revealing that intrinsic dimensions can be",
    "path": "papers/24/02/2402.18048.json",
    "total_tokens": 749,
    "translated_title": "用局部内在维度表征大型语言模型生成的真实性",
    "translated_abstract": "我们研究如何表征和预测从大型语言模型（LLMs）生成的文本的真实性，这在建立人类与LLMs之间的信任关系中起着至关重要的作用。我们建议通过研究内部激活并利用模型激活的局部内在维度（LID）来量化LLM的真实性。通过对四个问答（QA）数据集的实验，我们展示了我们提出的方法的有效性。此外，我们研究了LLMs中的内在维度及其与模型层、自回归语言建模以及LLMs的训练之间的关系，揭示了内在维度可以",
    "tldr": "本研究旨在通过使用局部内在维度来量化大型语言模型生成文本的真实性，实验证实了该方法的有效性。",
    "en_tdlr": "This study aims to quantify the truthfulness of texts generated from large language models using local intrinsic dimension, and demonstrates the effectiveness of this method through experiments."
}