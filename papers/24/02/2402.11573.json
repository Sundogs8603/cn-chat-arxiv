{
    "title": "BGE Landmark Embedding: A Chunking-Free Embedding Method For Retrieval Augmented Long-Context Large Language Models",
    "abstract": "arXiv:2402.11573v1 Announce Type: new  Abstract: Large language models (LLMs) call for extension of context to handle many critical applications. However, the existing approaches are prone to expensive costs and inferior quality of context extension. In this work, we proposeExtensible Embedding, which realizes high-quality extension of LLM's context with strong flexibility and cost-effectiveness. Extensible embedding stand as an enhancement of typical token embedding, which represents the information for an extensible scope of context instead of a single token. By leveraging such compact input units of higher information density, the LLM can access to a vast scope of context even with a small context window. Extensible embedding is systematically optimized in architecture and training method, which leads to multiple advantages. 1) High flexibility of context extension, which flexibly supports ad-hoc extension of diverse context lengths. 2) Strong sample efficiency of training, which en",
    "link": "https://arxiv.org/abs/2402.11573",
    "context": "Title: BGE Landmark Embedding: A Chunking-Free Embedding Method For Retrieval Augmented Long-Context Large Language Models\nAbstract: arXiv:2402.11573v1 Announce Type: new  Abstract: Large language models (LLMs) call for extension of context to handle many critical applications. However, the existing approaches are prone to expensive costs and inferior quality of context extension. In this work, we proposeExtensible Embedding, which realizes high-quality extension of LLM's context with strong flexibility and cost-effectiveness. Extensible embedding stand as an enhancement of typical token embedding, which represents the information for an extensible scope of context instead of a single token. By leveraging such compact input units of higher information density, the LLM can access to a vast scope of context even with a small context window. Extensible embedding is systematically optimized in architecture and training method, which leads to multiple advantages. 1) High flexibility of context extension, which flexibly supports ad-hoc extension of diverse context lengths. 2) Strong sample efficiency of training, which en",
    "path": "papers/24/02/2402.11573.json",
    "total_tokens": 910,
    "translated_title": "BGE地标嵌入：一种用于检索增强的长上下文大型语言模型的无块嵌入方法",
    "translated_abstract": "大型语言模型需要扩展上下文以处理许多关键应用，然而现有方法往往成本高昂且上下文扩展质量较低。在本文中，我们提出了可扩展嵌入，实现了具有强大灵活性和成本效益的LLM上下文的高质量扩展。可扩展嵌入作为典型令牌嵌入的增强，代表了可扩展范围上下文的信息，而不是单个令牌。通过利用这种信息密度更高的紧凑输入单元，LLM即使在小上下文窗口下也能访问广泛的上下文范围。可扩展嵌入在架构和训练方法上进行了系统优化，具有多个优势。1) 高度灵活的上下文扩展，灵活支持各种上下文长度的即时扩展。2) 强大的训练样本效率，使得...",
    "tldr": "可扩展嵌入方法提高了大型语言模型（LLM）的上下文扩展质量和成本效益，通过在架构和训练方法上进行系统优化，实现了上下文范围的灵活扩展和高效的训练样本效率。",
    "en_tdlr": "Extensible embedding method improves the quality and cost-effectiveness of context extension for large language models (LLMs), achieving flexible extension of context range and efficient training sample utilization through systematic optimization in architecture and training methods."
}