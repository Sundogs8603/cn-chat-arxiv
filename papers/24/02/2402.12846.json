{
    "title": "ConVQG: Contrastive Visual Question Generation with Multimodal Guidance",
    "abstract": "arXiv:2402.12846v1 Announce Type: cross  Abstract: Asking questions about visual environments is a crucial way for intelligent agents to understand rich multi-faceted scenes, raising the importance of Visual Question Generation (VQG) systems. Apart from being grounded to the image, existing VQG systems can use textual constraints, such as expected answers or knowledge triplets, to generate focused questions. These constraints allow VQG systems to specify the question content or leverage external commonsense knowledge that can not be obtained from the image content only. However, generating focused questions using textual constraints while enforcing a high relevance to the image content remains a challenge, as VQG systems often ignore one or both forms of grounding. In this work, we propose Contrastive Visual Question Generation (ConVQG), a method using a dual contrastive objective to discriminate questions generated using both modalities from those based on a single one. Experiments on",
    "link": "https://arxiv.org/abs/2402.12846",
    "context": "Title: ConVQG: Contrastive Visual Question Generation with Multimodal Guidance\nAbstract: arXiv:2402.12846v1 Announce Type: cross  Abstract: Asking questions about visual environments is a crucial way for intelligent agents to understand rich multi-faceted scenes, raising the importance of Visual Question Generation (VQG) systems. Apart from being grounded to the image, existing VQG systems can use textual constraints, such as expected answers or knowledge triplets, to generate focused questions. These constraints allow VQG systems to specify the question content or leverage external commonsense knowledge that can not be obtained from the image content only. However, generating focused questions using textual constraints while enforcing a high relevance to the image content remains a challenge, as VQG systems often ignore one or both forms of grounding. In this work, we propose Contrastive Visual Question Generation (ConVQG), a method using a dual contrastive objective to discriminate questions generated using both modalities from those based on a single one. Experiments on",
    "path": "papers/24/02/2402.12846.json",
    "total_tokens": 781,
    "translated_title": "ConVQG: 对比式带多模态引导的视觉问题生成",
    "translated_abstract": "询问关于视觉环境的问题是智能代理理解丰富多面场景的关键方式，这提高了视觉问题生成（VQG）系统的重要性。除了基于图像，现有的VQG系统可以使用文本约束，如期望回答或知识三元组，来生成专注问题。然而，使用文本约束生成专注问题的同时确保与图像内容的高度相关性仍然是一个挑战，因为VQG系统经常会忽视一个或两个控制形式。在这项工作中，我们提出了对比式视觉问题生成（ConVQG），一种使用双重对比目标来区分使用两种模态生成的问题和基于单一模式的问题的方法。",
    "tldr": "提出了ConVQG方法通过双重对比目标区分使用两种模态生成的问题和基于单一模式的问题，解决了在生成专注问题的同时确保与图像内容的高度相关性的挑战."
}