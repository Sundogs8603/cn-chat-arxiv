{
    "title": "Answer is All You Need: Instruction-following Text Embedding via Answering the Question",
    "abstract": "arXiv:2402.09642v1 Announce Type: new  Abstract: This work aims to build a text embedder that can capture characteristics of texts specified by user instructions. Despite its tremendous potential to deploy user-oriented embeddings, none of previous approaches provides a concrete solution for it. This paper offers a new viewpoint, which treats the instruction as a question about the input text and encodes the expected answers to obtain the representation accordingly. Intuitively, texts with the same (implicit) semantics would share similar answers following the instruction, thus leading to more similar embeddings. Specifically, we propose InBedder that instantiates this embed-via-answering idea by only fine-tuning language models on abstractive question answering tasks. InBedder demonstrates significantly improved instruction-following capabilities according to our proposed instruction awareness tests and instruction robustness tests, when applied to both large language models (LLMs) (e",
    "link": "https://arxiv.org/abs/2402.09642",
    "context": "Title: Answer is All You Need: Instruction-following Text Embedding via Answering the Question\nAbstract: arXiv:2402.09642v1 Announce Type: new  Abstract: This work aims to build a text embedder that can capture characteristics of texts specified by user instructions. Despite its tremendous potential to deploy user-oriented embeddings, none of previous approaches provides a concrete solution for it. This paper offers a new viewpoint, which treats the instruction as a question about the input text and encodes the expected answers to obtain the representation accordingly. Intuitively, texts with the same (implicit) semantics would share similar answers following the instruction, thus leading to more similar embeddings. Specifically, we propose InBedder that instantiates this embed-via-answering idea by only fine-tuning language models on abstractive question answering tasks. InBedder demonstrates significantly improved instruction-following capabilities according to our proposed instruction awareness tests and instruction robustness tests, when applied to both large language models (LLMs) (e",
    "path": "papers/24/02/2402.09642.json",
    "total_tokens": 832,
    "translated_title": "答案就是你需要的一切：通过回答问题进行指令遵循的文本嵌入",
    "translated_abstract": "这项工作旨在构建一个能够捕捉用户指令所指定的文本特征的文本嵌入器。尽管它在部署面向用户的嵌入方面具有巨大潜力，但之前的方法都没有提供具体的解决方案。本文提出了一个新的视角，将指令视为对输入文本的问题，并编码期望的答案以相应地获得表示。直观地说，遵循指令的文本应该有相似的答案，从而导致更相似的嵌入。具体而言，我们提出了InBedder，它通过在抽象性问题回答任务上对语言模型进行微调来实现该嵌入-via-answering思想。根据我们提出的指令意识测试和指令鲁棒性测试，InBedder在应用于大型语言模型（LLMs）",
    "tldr": "通过回答问题进行指令遵循的文本嵌入方法，通过将指令视为对输入文本的问题并编码期望的答案，从而获得更相似的嵌入效果。",
    "en_tdlr": "A text embedding method for instruction following, utilizing the idea of treating instructions as questions about the input text and encoding the expected answers to achieve more similar embeddings."
}