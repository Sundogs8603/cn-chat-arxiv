{
    "title": "Reward Design for Justifiable Sequential Decision-Making",
    "abstract": "arXiv:2402.15826v1 Announce Type: cross  Abstract: Equipping agents with the capacity to justify made decisions using supporting evidence represents a cornerstone of accountable decision-making. Furthermore, ensuring that justifications are in line with human expectations and societal norms is vital, especially in high-stakes situations such as healthcare. In this work, we propose the use of a debate-based reward model for reinforcement learning agents, where the outcome of a zero-sum debate game quantifies the justifiability of a decision in a particular state. This reward model is then used to train a justifiable policy, whose decisions can be more easily corroborated with supporting evidence. In the debate game, two argumentative agents take turns providing supporting evidence for two competing decisions. Given the proposed evidence, a proxy of a human judge evaluates which decision is better justified. We demonstrate the potential of our approach in learning policies for prescribin",
    "link": "https://arxiv.org/abs/2402.15826",
    "context": "Title: Reward Design for Justifiable Sequential Decision-Making\nAbstract: arXiv:2402.15826v1 Announce Type: cross  Abstract: Equipping agents with the capacity to justify made decisions using supporting evidence represents a cornerstone of accountable decision-making. Furthermore, ensuring that justifications are in line with human expectations and societal norms is vital, especially in high-stakes situations such as healthcare. In this work, we propose the use of a debate-based reward model for reinforcement learning agents, where the outcome of a zero-sum debate game quantifies the justifiability of a decision in a particular state. This reward model is then used to train a justifiable policy, whose decisions can be more easily corroborated with supporting evidence. In the debate game, two argumentative agents take turns providing supporting evidence for two competing decisions. Given the proposed evidence, a proxy of a human judge evaluates which decision is better justified. We demonstrate the potential of our approach in learning policies for prescribin",
    "path": "papers/24/02/2402.15826.json",
    "total_tokens": 807,
    "translated_title": "用于合理序贯决策的奖励设计",
    "translated_abstract": "将代理赋予能够使用支持证据来证明决策的能力是负责任决策的基石。此外，确保这些证明与人类期望和社会规范一致至关重要，特别是在高风险情况下，比如医疗保健。在这项工作中，我们提出了一个辩论型奖励模型，用于强化学习代理，其中零和辩论游戏的结果量化了在特定状态下的决策的合理性。然后使用该奖励模型来训练一个可以更容易地与支持证据相印证的可辩明策略。在辩论游戏中，两个辩护性代理轮流提供支持证据，支持两个竞争性决策。在提供的证据条件下，一个人类法官的代理评估哪个决策更合理。我们展示了我们的方法在学习处方策略方面的潜力。",
    "tldr": "代理通过辩论型奖励模型学习可辩明策略，以支持证据证明决策的合理性。",
    "en_tdlr": "Agents learn justifiable policies through a debate-based reward model to substantiate decision justifiability with supporting evidence."
}