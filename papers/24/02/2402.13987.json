{
    "title": "A Simple and Yet Fairly Effective Defense for Graph Neural Networks",
    "abstract": "arXiv:2402.13987v1 Announce Type: new  Abstract: Graph Neural Networks (GNNs) have emerged as the dominant approach for machine learning on graph-structured data. However, concerns have arisen regarding the vulnerability of GNNs to small adversarial perturbations. Existing defense methods against such perturbations suffer from high time complexity and can negatively impact the model's performance on clean graphs. To address these challenges, this paper introduces NoisyGNNs, a novel defense method that incorporates noise into the underlying model's architecture. We establish a theoretical connection between noise injection and the enhancement of GNN robustness, highlighting the effectiveness of our approach. We further conduct extensive empirical evaluations on the node classification task to validate our theoretical findings, focusing on two popular GNNs: the GCN and GIN. The results demonstrate that NoisyGNN achieves superior or comparable defense performance to existing methods while",
    "link": "https://arxiv.org/abs/2402.13987",
    "context": "Title: A Simple and Yet Fairly Effective Defense for Graph Neural Networks\nAbstract: arXiv:2402.13987v1 Announce Type: new  Abstract: Graph Neural Networks (GNNs) have emerged as the dominant approach for machine learning on graph-structured data. However, concerns have arisen regarding the vulnerability of GNNs to small adversarial perturbations. Existing defense methods against such perturbations suffer from high time complexity and can negatively impact the model's performance on clean graphs. To address these challenges, this paper introduces NoisyGNNs, a novel defense method that incorporates noise into the underlying model's architecture. We establish a theoretical connection between noise injection and the enhancement of GNN robustness, highlighting the effectiveness of our approach. We further conduct extensive empirical evaluations on the node classification task to validate our theoretical findings, focusing on two popular GNNs: the GCN and GIN. The results demonstrate that NoisyGNN achieves superior or comparable defense performance to existing methods while",
    "path": "papers/24/02/2402.13987.json",
    "total_tokens": 865,
    "translated_title": "一种简单且相当有效的图神经网络防御方法",
    "translated_abstract": "图神经网络（GNNs）已经成为处理图结构数据的机器学习中占主导地位的方法。然而，人们对GNN对小干扰的脆弱性提出了担忧。现有的防御方法针对这种干扰 suffer from high time complexity and can negatively impact the model's performance on clean graphs。为了应对这些挑战，本文引入了 NoisyGNNs，这是一种将噪声融入基础模型架构的新颖防御方法。我们建立了噪声注入与增强GNN鲁棒性之间的理论连接，突显了我们方法的有效性。我们进一步在节点分类任务上进行了广泛的实证评估，验证了我们的理论发现，重点关注了两种流行的GNNs：GCN和GIN。结果表明，NoisyGNN实现了优越或可比的防御性能",
    "tldr": "本文介绍了一种名为NoisyGNNs的新颖防御方法，通过将噪声引入基础模型的架构，建立了噪声注入与增强GNN鲁棒性之间的理论连接，实验证明其在节点分类任务上取得了优越或可比的防御性能。",
    "en_tdlr": "This paper introduces a novel defense method called NoisyGNNs, which establishes a theoretical connection between noise injection and the enhancement of GNN robustness, and empirical evaluations show its superior or comparable defense performance in the node classification task."
}