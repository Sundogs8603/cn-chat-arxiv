{
    "title": "Diffusion Model Based Visual Compensation Guidance and Visual Difference Analysis for No-Reference Image Quality Assessment",
    "abstract": "arXiv:2402.14401v1 Announce Type: cross  Abstract: Existing free-energy guided No-Reference Image Quality Assessment (NR-IQA) methods still suffer from finding a balance between learning feature information at the pixel level of the image and capturing high-level feature information and the efficient utilization of the obtained high-level feature information remains a challenge. As a novel class of state-of-the-art (SOTA) generative model, the diffusion model exhibits the capability to model intricate relationships, enabling a comprehensive understanding of images and possessing a better learning of both high-level and low-level visual features. In view of these, we pioneer the exploration of the diffusion model into the domain of NR-IQA. Firstly, we devise a new diffusion restoration network that leverages the produced enhanced image and noise-containing images, incorporating nonlinear features obtained during the denoising process of the diffusion model, as high-level visual informat",
    "link": "https://arxiv.org/abs/2402.14401",
    "context": "Title: Diffusion Model Based Visual Compensation Guidance and Visual Difference Analysis for No-Reference Image Quality Assessment\nAbstract: arXiv:2402.14401v1 Announce Type: cross  Abstract: Existing free-energy guided No-Reference Image Quality Assessment (NR-IQA) methods still suffer from finding a balance between learning feature information at the pixel level of the image and capturing high-level feature information and the efficient utilization of the obtained high-level feature information remains a challenge. As a novel class of state-of-the-art (SOTA) generative model, the diffusion model exhibits the capability to model intricate relationships, enabling a comprehensive understanding of images and possessing a better learning of both high-level and low-level visual features. In view of these, we pioneer the exploration of the diffusion model into the domain of NR-IQA. Firstly, we devise a new diffusion restoration network that leverages the produced enhanced image and noise-containing images, incorporating nonlinear features obtained during the denoising process of the diffusion model, as high-level visual informat",
    "path": "papers/24/02/2402.14401.json",
    "total_tokens": 840,
    "translated_title": "基于扩散模型的视觉补偿引导和视觉差异分析用于无参考图像质量评估",
    "translated_abstract": "现有的自由能引导的无参考图像质量评估(NR-IQA)方法仍然在找到在图像的像素级学习特征信息和捕获高级特征信息之间达到平衡以及高级特征信息的有效利用方面存在困难。作为一种新颖的领先技术(SOTA)生成模型类别，扩散模型展示了建模复杂关系的能力，能够全面理解图像，并具有更好地学习高级和低级视觉特征。鉴于此，我们首次将扩散模型探索到NR-IQA领域。首先，我们设计了一个新的扩散恢复网络，利用生成的增强图像和包含噪声的图像，将扩散模型去噪过程中获得的非线性特征作为高级视觉信息。",
    "tldr": "本研究将扩散模型引入无参考图像质量评估领域，设计了新的扩散恢复网络，提高了学习高级和低级视觉特征的效率。",
    "en_tdlr": "This study introduces the diffusion model into the field of no-reference image quality assessment, designs a new diffusion restoration network, and improves the efficiency of learning high-level and low-level visual features."
}