{
    "title": "What Linguistic Features and Languages are Important in LLM Translation?",
    "abstract": "arXiv:2402.13917v1 Announce Type: cross  Abstract: Large Language Models (LLMs) demonstrate strong capability across multiple tasks, including machine translation. Our study focuses on evaluating Llama2's machine translation capabilities and exploring how translation depends on languages in its training data. Our experiments show that the 7B Llama2 model yields above 10 BLEU score for all languages it has seen, but not always for languages it has not seen. Most gains for those unseen languages are observed the most with the model scale compared to using chat versions or adding shot count. Furthermore, our linguistic distance analysis reveals that syntactic similarity is not always the primary linguistic factor in determining translation quality. Interestingly, we discovered that under specific circumstances, some languages, despite having significantly less training data than English, exhibit strong correlations comparable to English. Our discoveries here give new perspectives for the ",
    "link": "https://arxiv.org/abs/2402.13917",
    "context": "Title: What Linguistic Features and Languages are Important in LLM Translation?\nAbstract: arXiv:2402.13917v1 Announce Type: cross  Abstract: Large Language Models (LLMs) demonstrate strong capability across multiple tasks, including machine translation. Our study focuses on evaluating Llama2's machine translation capabilities and exploring how translation depends on languages in its training data. Our experiments show that the 7B Llama2 model yields above 10 BLEU score for all languages it has seen, but not always for languages it has not seen. Most gains for those unseen languages are observed the most with the model scale compared to using chat versions or adding shot count. Furthermore, our linguistic distance analysis reveals that syntactic similarity is not always the primary linguistic factor in determining translation quality. Interestingly, we discovered that under specific circumstances, some languages, despite having significantly less training data than English, exhibit strong correlations comparable to English. Our discoveries here give new perspectives for the ",
    "path": "papers/24/02/2402.13917.json",
    "total_tokens": 925,
    "translated_title": "LLM翻译中的语言特征和重要语言是什么？",
    "translated_abstract": "arXiv：2402.13917v1 公告类型：跨领域 摘要：大型语言模型（LLMs）展示了在多个任务中具有强大能力，包括机器翻译。我们的研究重点在于评估Llama2的机器翻译能力，并探索翻译如何取决于其训练数据中的语言。我们的实验表明，7B Llama2模型对其所见的所有语言都可以获得超过10的BLEU分数，但并非总是对其未见的语言。对于这些未见语言，与使用聊天版本或添加少量数据相比，在模型规模上观察到的最大收益。此外，我们的语言距离分析显示，句法相似性并非始终是决定翻译质量的主要语言因素。有趣的是，我们发现在特定情况下，一些语言，尽管训练数据明显少于英语，却表现出与英语可比的强相关性。我们在这里的发现为研究提供了新的视角。",
    "tldr": "Llama2模型在翻译中表现出准确度高，部分未见语言需要更大规模的模型来提升翻译质量，另外语言的句法相似性并非翻译质量的主要因素，某些语言即使数据少依然表现出强相关性。",
    "en_tdlr": "The Llama2 model exhibits high translation accuracy, with some unseen languages requiring larger scale models for improved translation quality. Moreover, syntactic similarity of languages is not the primary factor for translation quality, and certain languages show strong correlations despite having less training data."
}