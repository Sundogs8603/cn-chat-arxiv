{
    "title": "Performance Assessment of ChatGPT vs Bard in Detecting Alzheimer's Dementia",
    "abstract": "Large language models (LLMs) find increasing applications in many fields. Here, three LLM chatbots (ChatGPT-3.5, ChatGPT-4 and Bard) are assessed - in their current form, as publicly available - for their ability to recognize Alzheimer's Dementia (AD) and Cognitively Normal (CN) individuals using textual input derived from spontaneous speech recordings. Zero-shot learning approach is used at two levels of independent queries, with the second query (chain-of-thought prompting) eliciting more detailed than the first. Each LLM chatbot's performance is evaluated on the prediction generated in terms of accuracy, sensitivity, specificity, precision and F1 score. LLM chatbots generated three-class outcome (\"AD\", \"CN\", or \"Unsure\"). When positively identifying AD, Bard produced highest true-positives (89% recall) and highest F1 score (71%), but tended to misidentify CN as AD, with high confidence (low \"Unsure\" rates); for positively identifying CN, GPT-4 resulted in the highest true-negatives ",
    "link": "https://arxiv.org/abs/2402.01751",
    "context": "Title: Performance Assessment of ChatGPT vs Bard in Detecting Alzheimer's Dementia\nAbstract: Large language models (LLMs) find increasing applications in many fields. Here, three LLM chatbots (ChatGPT-3.5, ChatGPT-4 and Bard) are assessed - in their current form, as publicly available - for their ability to recognize Alzheimer's Dementia (AD) and Cognitively Normal (CN) individuals using textual input derived from spontaneous speech recordings. Zero-shot learning approach is used at two levels of independent queries, with the second query (chain-of-thought prompting) eliciting more detailed than the first. Each LLM chatbot's performance is evaluated on the prediction generated in terms of accuracy, sensitivity, specificity, precision and F1 score. LLM chatbots generated three-class outcome (\"AD\", \"CN\", or \"Unsure\"). When positively identifying AD, Bard produced highest true-positives (89% recall) and highest F1 score (71%), but tended to misidentify CN as AD, with high confidence (low \"Unsure\" rates); for positively identifying CN, GPT-4 resulted in the highest true-negatives ",
    "path": "papers/24/02/2402.01751.json",
    "total_tokens": 1054,
    "translated_title": "ChatGPT与Bard在检测阿尔茨海默病痴呆的性能评估",
    "translated_abstract": "大型语言模型（LLM）在许多领域中有着越来越多的应用。本研究评估了三个LLM聊天机器人（ChatGPT-3.5，ChatGPT-4和Bard）在其当前公开形式下，使用从自发语音记录中提取的文本输入，对阿尔茨海默病痴呆（AD）和认知正常（CN）个体进行识别的能力。采用零样本学习方法，在两个独立查询级别上进行，第二个查询（思维链引导）比第一个查询产生更详细的结果。通过评估每个LLM聊天机器人在准确度、敏感度、特异度、精确度和F1得分方面生成的预测来评估LLM聊天机器人的性能。LLM聊天机器人生成了三类结果（\"AD\"，\"CN\"或\"Unsure\"）。在积极识别AD时，Bard产生了最高的真阳性（89%的召回率）和最高的F1得分（71%），但倾向于将CN错误地识别为AD，并具有较高的置信度（较低的\"Unsure\"率）；在积极识别CN时，GPT-4产生了最高的真阴性。",
    "tldr": "本研究评估了ChatGPT和Bard在识别阿尔茨海默病痴呆的能力，并发现Bard在积极识别AD方面表现最好，具有较高的召回率和F1得分，但可能会将CN错误地识别为AD。对于积极识别CN，GPT-4表现出最高的真阴性。",
    "en_tdlr": "This study assesses the ability of ChatGPT and Bard in detecting Alzheimer's dementia, finding that Bard performs best in positively identifying AD, with high recall and F1 score, but may misidentify CN as AD. For positively identifying CN, GPT-4 exhibits the highest true negatives."
}