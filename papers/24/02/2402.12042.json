{
    "title": "Linear bandits with polylogarithmic minimax regret",
    "abstract": "arXiv:2402.12042v1 Announce Type: cross  Abstract: We study a noise model for linear stochastic bandits for which the subgaussian noise parameter vanishes linearly as we select actions on the unit sphere closer and closer to the unknown vector. We introduce an algorithm for this problem that exhibits a minimax regret scaling as $\\log^3(T)$ in the time horizon $T$, in stark contrast the square root scaling of this regret for typical bandit algorithms. Our strategy, based on weighted least-squares estimation, achieves the eigenvalue relation $\\lambda_{\\min} ( V_t ) = \\Omega (\\sqrt{\\lambda_{\\max}(V_t ) })$ for the design matrix $V_t$ at each time step $t$ through geometrical arguments that are independent of the noise model and might be of independent interest. This allows us to tightly control the expected regret in each time step to be of the order $O(\\frac1{t})$, leading to the logarithmic scaling of the cumulative regret.",
    "link": "https://arxiv.org/abs/2402.12042",
    "context": "Title: Linear bandits with polylogarithmic minimax regret\nAbstract: arXiv:2402.12042v1 Announce Type: cross  Abstract: We study a noise model for linear stochastic bandits for which the subgaussian noise parameter vanishes linearly as we select actions on the unit sphere closer and closer to the unknown vector. We introduce an algorithm for this problem that exhibits a minimax regret scaling as $\\log^3(T)$ in the time horizon $T$, in stark contrast the square root scaling of this regret for typical bandit algorithms. Our strategy, based on weighted least-squares estimation, achieves the eigenvalue relation $\\lambda_{\\min} ( V_t ) = \\Omega (\\sqrt{\\lambda_{\\max}(V_t ) })$ for the design matrix $V_t$ at each time step $t$ through geometrical arguments that are independent of the noise model and might be of independent interest. This allows us to tightly control the expected regret in each time step to be of the order $O(\\frac1{t})$, leading to the logarithmic scaling of the cumulative regret.",
    "path": "papers/24/02/2402.12042.json",
    "total_tokens": 971,
    "translated_title": "具有多对数极小极小遗憾的线性赌博机",
    "translated_abstract": "我们研究了一种线性随机赌博机的噪声模型，对于该模型，当我们选择越来越接近未知向量的单位球上的动作时，亚高斯噪声参数以线性方式消失。我们针对这个问题引入了一种算法，其在时间长度$T$的情况下呈对数$^3（T）$的最小遗憾缩放，与典型赌博机算法的平方根遗憾缩放形成鲜明对比。我们的策略基于加权最小二乘估计，通过几何论证实现了设计矩阵$V_t$在每个时间步骤$t$处的特征值关系$\\lambda_{\\min} ( V_t ) = \\Omega (\\sqrt{\\lambda_{\\max}(V_t ) })$，这些几何论证与噪声模型无关，并可能具有独立的兴趣。这使我们能够严格控制每个时间步骤的期望遗憾为$O(\\frac1{t})$的数量级，从而导致累积遗憾的对数缩放。",
    "tldr": "该研究提出了一种新的线性赌博机算法，解决了线性随机赌博机中最小极小遗憾的多对数缩放问题，通过加权最小二乘估计实现对设计矩阵特征值关系的控制，实现了累积遗憾的对数缩放。",
    "en_tdlr": "This study introduces a novel algorithm for linear bandits that addresses the polylogarithmic minimax regret issue, controlling the eigenvalue relation of the design matrix through weighted least-squares estimation to achieve logarithmic scaling of cumulative regret."
}