{
    "title": "Toward Fully Self-Supervised Multi-Pitch Estimation",
    "abstract": "arXiv:2402.15569v1 Announce Type: cross  Abstract: Multi-pitch estimation is a decades-long research problem involving the detection of pitch activity associated with concurrent musical events within multi-instrument mixtures. Supervised learning techniques have demonstrated solid performance on more narrow characterizations of the task, but suffer from limitations concerning the shortage of large-scale and diverse polyphonic music datasets with multi-pitch annotations. We present a suite of self-supervised learning objectives for multi-pitch estimation, which encourage the concentration of support around harmonics, invariance to timbral transformations, and equivariance to geometric transformations. These objectives are sufficient to train an entirely convolutional autoencoder to produce multi-pitch salience-grams directly, without any fine-tuning. Despite training exclusively on a collection of synthetic single-note audio samples, our fully self-supervised framework generalizes to po",
    "link": "https://arxiv.org/abs/2402.15569",
    "context": "Title: Toward Fully Self-Supervised Multi-Pitch Estimation\nAbstract: arXiv:2402.15569v1 Announce Type: cross  Abstract: Multi-pitch estimation is a decades-long research problem involving the detection of pitch activity associated with concurrent musical events within multi-instrument mixtures. Supervised learning techniques have demonstrated solid performance on more narrow characterizations of the task, but suffer from limitations concerning the shortage of large-scale and diverse polyphonic music datasets with multi-pitch annotations. We present a suite of self-supervised learning objectives for multi-pitch estimation, which encourage the concentration of support around harmonics, invariance to timbral transformations, and equivariance to geometric transformations. These objectives are sufficient to train an entirely convolutional autoencoder to produce multi-pitch salience-grams directly, without any fine-tuning. Despite training exclusively on a collection of synthetic single-note audio samples, our fully self-supervised framework generalizes to po",
    "path": "papers/24/02/2402.15569.json",
    "total_tokens": 806,
    "translated_title": "实现完全自监督的多音高估计",
    "translated_abstract": "多音高估计是一个持续几十年的研究问题，涉及检测与多乐器混音中同时发生的音乐事件相关的音高活动。监督学习技术已经在任务的较窄特征描述上表现出色，但受到缺乏大规模和多样化的带有多音高标注的复音音乐数据集的限制。我们提出了一套自监督学习目标，用于多音高估计，这些目标鼓励支持围绕谐波中心、对音色转换不变以及对几何转换等变换等特性。这些目标足以训练完全基于卷积自动编码器，直接生成多音高显著图，无需任何微调。尽管仅在一组合成单音频样本上训练，我们的完全自监督框架具有泛化到 po",
    "tldr": "提出一套自监督学习目标，用于多音高估计，训练完全卷积自动编码器生成多音高显著图，无需微调",
    "en_tdlr": "Proposed a set of self-supervised learning objectives for multi-pitch estimation, training an entirely convolutional autoencoder to generate multi-pitch salience-grams directly without fine-tuning."
}