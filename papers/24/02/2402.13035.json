{
    "title": "Learning to Check: Unleashing Potentials for Self-Correction in Large Language Models",
    "abstract": "arXiv:2402.13035v1 Announce Type: cross  Abstract: Large language models (LLMs) have made significant strides in reasoning capabilities, with ongoing efforts to refine their reasoning through self-correction. However, recent studies suggest that self-correction can be limited or even counterproductive without external accurate knowledge, raising questions about the limits and effectiveness of self-correction. In this paper, we aim to enhance LLM's self-checking capabilities by meticulously designing training data, thereby improving the accuracy of self-correction. We conduct a detailed analysis of error types in mathematical reasoning and develop a tailored prompt, termed ``Step CoT Check''. Then we construct a checking-correction dataset for training models. After integrating the original CoT data and checking-correction data for training, we observe that models could improve their self-checking capabilities, thereby enhancing their self-correction capacity and eliminating the need fo",
    "link": "https://arxiv.org/abs/2402.13035",
    "context": "Title: Learning to Check: Unleashing Potentials for Self-Correction in Large Language Models\nAbstract: arXiv:2402.13035v1 Announce Type: cross  Abstract: Large language models (LLMs) have made significant strides in reasoning capabilities, with ongoing efforts to refine their reasoning through self-correction. However, recent studies suggest that self-correction can be limited or even counterproductive without external accurate knowledge, raising questions about the limits and effectiveness of self-correction. In this paper, we aim to enhance LLM's self-checking capabilities by meticulously designing training data, thereby improving the accuracy of self-correction. We conduct a detailed analysis of error types in mathematical reasoning and develop a tailored prompt, termed ``Step CoT Check''. Then we construct a checking-correction dataset for training models. After integrating the original CoT data and checking-correction data for training, we observe that models could improve their self-checking capabilities, thereby enhancing their self-correction capacity and eliminating the need fo",
    "path": "papers/24/02/2402.13035.json",
    "total_tokens": 831,
    "translated_title": "学习检查：释放大型语言模型自我校正的潜力",
    "translated_abstract": "大型语言模型（LLMs）在推理能力方面取得了显著进展，不断努力通过自我校正来完善推理。然而，最近的研究表明，没有外部准确知识的自我校正可能存在局限性甚至可能适得其反，这就引发了关于自我校正的限制和有效性的疑问。本文旨在通过精心设计训练数据来增强LLM的自检功能，从而提高自我校正的准确性。我们对数学推理中的错误类型进行了详细分析，并开发了一个量身定制的提示，称为“Step CoT Check”。然后我们构建了一个检查-校正数据集用于训练模型。在将原始CoT数据和检查校正数据整合后进行训练，我们观察到模型可以改善其自检能力，从而提高其自我校正能力并消除了需要",
    "tldr": "通过精心设计训练数据和构建检查-校正数据集，本研究增强了大型语言模型的自我校正能力，提高了自我校正的准确性。"
}