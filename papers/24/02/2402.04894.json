{
    "title": "Deep Reinforcement Learning with Dynamic Graphs for Adaptive Informative Path Planning",
    "abstract": "Autonomous robots are often employed for data collection due to their efficiency and low labour costs. A key task in robotic data acquisition is planning paths through an initially unknown environment to collect observations given platform-specific resource constraints, such as limited battery life. Adaptive online path planning in 3D environments is challenging due to the large set of valid actions and the presence of unknown occlusions. To address these issues, we propose a novel deep reinforcement learning approach for adaptively replanning robot paths to map targets of interest in unknown 3D environments. A key aspect of our approach is a dynamically constructed graph that restricts planning actions local to the robot, allowing us to quickly react to newly discovered obstacles and targets of interest. For replanning, we propose a new reward function that balances between exploring the unknown environment and exploiting online-collected data about the targets of interest. Our experi",
    "link": "https://arxiv.org/abs/2402.04894",
    "context": "Title: Deep Reinforcement Learning with Dynamic Graphs for Adaptive Informative Path Planning\nAbstract: Autonomous robots are often employed for data collection due to their efficiency and low labour costs. A key task in robotic data acquisition is planning paths through an initially unknown environment to collect observations given platform-specific resource constraints, such as limited battery life. Adaptive online path planning in 3D environments is challenging due to the large set of valid actions and the presence of unknown occlusions. To address these issues, we propose a novel deep reinforcement learning approach for adaptively replanning robot paths to map targets of interest in unknown 3D environments. A key aspect of our approach is a dynamically constructed graph that restricts planning actions local to the robot, allowing us to quickly react to newly discovered obstacles and targets of interest. For replanning, we propose a new reward function that balances between exploring the unknown environment and exploiting online-collected data about the targets of interest. Our experi",
    "path": "papers/24/02/2402.04894.json",
    "total_tokens": 855,
    "translated_title": "利用动态图的深度强化学习进行自适应信息路径规划",
    "translated_abstract": "自主机器人常常被用于数据收集，因为它们高效且劳动成本低。机器人数据采集的关键任务是在初始未知环境中规划路径，以满足平台特定的资源约束，例如有限的电池寿命。在三维环境中进行自适应在线路径规划面临着很多挑战，包括大量有效动作的存在以及未知遮挡物的存在。为了解决这些问题，我们提出了一种新颖的深度强化学习方法，用于自适应重新规划机器人路径以在未知的三维环境中映射出感兴趣的目标。我们方法的关键之处在于构建动态图，将规划动作限制在机器人附近，使我们能够快速响应新发现的障碍和感兴趣的目标。对于重新规划，我们提出了一种新的奖励函数，平衡探索未知环境和利用在线收集的有关感兴趣目标的数据。",
    "tldr": "提出了一种利用动态图的深度强化学习方法，用于自适应信息路径规划，能够在未知的三维环境中映射出感兴趣的目标。"
}