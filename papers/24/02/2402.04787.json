{
    "title": "A Hypothesis-Driven Framework for the Analysis of Self-Rationalising Models",
    "abstract": "The self-rationalising capabilities of LLMs are appealing because the generated explanations can give insights into the plausibility of the predictions. However, how faithful the explanations are to the predictions is questionable, raising the need to explore the patterns behind them further. To this end, we propose a hypothesis-driven statistical framework. We use a Bayesian network to implement a hypothesis about how a task (in our example, natural language inference) is solved, and its internal states are translated into natural language with templates. Those explanations are then compared to LLM-generated free-text explanations using automatic and human evaluations. This allows us to judge how similar the LLM's and the Bayesian network's decision processes are. We demonstrate the usage of our framework with an example hypothesis and two realisations in Bayesian networks. The resulting models do not exhibit a strong similarity to GPT-3.5. We discuss the implications of this as well ",
    "link": "https://arxiv.org/abs/2402.04787",
    "context": "Title: A Hypothesis-Driven Framework for the Analysis of Self-Rationalising Models\nAbstract: The self-rationalising capabilities of LLMs are appealing because the generated explanations can give insights into the plausibility of the predictions. However, how faithful the explanations are to the predictions is questionable, raising the need to explore the patterns behind them further. To this end, we propose a hypothesis-driven statistical framework. We use a Bayesian network to implement a hypothesis about how a task (in our example, natural language inference) is solved, and its internal states are translated into natural language with templates. Those explanations are then compared to LLM-generated free-text explanations using automatic and human evaluations. This allows us to judge how similar the LLM's and the Bayesian network's decision processes are. We demonstrate the usage of our framework with an example hypothesis and two realisations in Bayesian networks. The resulting models do not exhibit a strong similarity to GPT-3.5. We discuss the implications of this as well ",
    "path": "papers/24/02/2402.04787.json",
    "total_tokens": 938,
    "translated_title": "一种基于假设的自我合理模型分析框架",
    "translated_abstract": "LLM模型的自我合理能力很有吸引力，因为生成的解释可以揭示预测的合理性。然而，解释与预测之间的准确性是有问题的，因此需要进一步探索其中的模式。为此，我们提出了一种基于假设的统计框架。我们使用贝叶斯网络实现关于任务（在我们的例子中为自然语言推理）如何解决的假设，并将其内部状态通过模板转化为自然语言。然后使用自动和人工评估将这些解释与LLM生成的自由文本解释相比较，以评判LLM和贝叶斯网络的决策过程的相似性。我们使用一个例子假设和两种贝叶斯网络实现来演示我们的框架的应用。得到的模型与GPT-3.5没有明显的相似性。我们讨论了这一点的影响。",
    "tldr": "本研究提出了一种基于假设的统计框架，用于分析LLM模型的自我合理能力。通过将LLM生成的解释与贝叶斯网络的决策过程进行比较，可以评判两者的相似性。实验证明，生成的模型与GPT-3.5不相似。这一研究结果对于理解LLL模型的解释能力具有重要意义。",
    "en_tdlr": "This study presents a hypothesis-driven statistical framework for analyzing the self-rationalizing capabilities of LLM models. By comparing the explanations generated by LLM with the decision processes of a Bayesian network, the similarity between the two can be evaluated. The results demonstrate that the generated models are not similar to GPT-3.5, which holds significant implications for understanding the explanatory abilities of LLM models."
}