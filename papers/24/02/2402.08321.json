{
    "title": "Exploration by Optimization with Hybrid Regularizers: Logarithmic Regret with Adversarial Robustness in Partial Monitoring",
    "abstract": "Partial monitoring is a generic framework of online decision-making problems with limited observations. To make decisions from such limited observations, it is necessary to find an appropriate distribution for exploration. Recently, a powerful approach for this purpose, exploration by optimization (ExO), was proposed, which achieves the optimal bounds in adversarial environments with follow-the-regularized-leader for a wide range of online decision-making problems. However, a naive application of ExO in stochastic environments significantly degrades regret bounds. To resolve this problem in locally observable games, we first establish a novel framework and analysis for ExO with a hybrid regularizer. This development allows us to significantly improve the existing regret bounds of best-of-both-worlds (BOBW) algorithms, which achieves nearly optimal bounds both in stochastic and adversarial environments. In particular, we derive a stochastic regret bound of $O(\\sum_{a \\neq a^*} k^2 m^2 \\",
    "link": "https://arxiv.org/abs/2402.08321",
    "context": "Title: Exploration by Optimization with Hybrid Regularizers: Logarithmic Regret with Adversarial Robustness in Partial Monitoring\nAbstract: Partial monitoring is a generic framework of online decision-making problems with limited observations. To make decisions from such limited observations, it is necessary to find an appropriate distribution for exploration. Recently, a powerful approach for this purpose, exploration by optimization (ExO), was proposed, which achieves the optimal bounds in adversarial environments with follow-the-regularized-leader for a wide range of online decision-making problems. However, a naive application of ExO in stochastic environments significantly degrades regret bounds. To resolve this problem in locally observable games, we first establish a novel framework and analysis for ExO with a hybrid regularizer. This development allows us to significantly improve the existing regret bounds of best-of-both-worlds (BOBW) algorithms, which achieves nearly optimal bounds both in stochastic and adversarial environments. In particular, we derive a stochastic regret bound of $O(\\sum_{a \\neq a^*} k^2 m^2 \\",
    "path": "papers/24/02/2402.08321.json",
    "total_tokens": 912,
    "translated_title": "使用混合正则化器的优化探索：在部分监测中具有对抗鲁棒性的对数遗憾",
    "translated_abstract": "部分监测是一种具有有限观测的在线决策问题的通用框架。为了从这种有限观测中做出决策，需要找到一个适当的探索分布。最近，提出了一种用于此目的的强大方法，即通过优化进行探索（ExO），它利用追踪正则化最优方法，在广泛的在线决策问题中实现对抗环境下的最优界限。然而，在随机环境中纯粹应用ExO会显著降低遗憾界限。为了解决这个局部可观测游戏中的问题，我们首先建立了一个新颖的ExO与混合正则化器的框架和分析。这个发展使我们能够显著改进最佳双赢算法（BOBW）的现有遗憾界限，在随机和对抗环境中都实现了几乎最优的界限。特别地，我们得出了一个随机遗憾界限为$O(\\sum_{a \\neq a^*} k^2 m^2$",
    "tldr": "这篇论文介绍了一种在部分监测问题中探索优化的方法，通过使用混合正则化器可以提高在随机和对抗环境中的遗憾界限。",
    "en_tdlr": "This paper proposes a method for exploration by optimization in partial monitoring problems, and using a hybrid regularizer can improve regret bounds in both stochastic and adversarial environments."
}