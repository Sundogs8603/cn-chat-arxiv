{
    "title": "Learning Semantic Proxies from Visual Prompts for Parameter-Efficient Fine-Tuning in Deep Metric Learning",
    "abstract": "Deep Metric Learning (DML) has long attracted the attention of the machine learning community as a key objective. Existing solutions concentrate on fine-tuning the pre-trained models on conventional image datasets. As a result of the success of recent pre-trained models trained from larger-scale datasets, it is challenging to adapt the model to the DML tasks in the local data domain while retaining the previously gained knowledge. In this paper, we investigate parameter-efficient methods for fine-tuning the pre-trained model for DML tasks. In particular, we propose a novel and effective framework based on learning Visual Prompts (VPT) in the pre-trained Vision Transformers (ViT). Based on the conventional proxy-based DML paradigm, we augment the proxy by incorporating the semantic information from the input image and the ViT, in which we optimize the visual prompts for each class. We demonstrate that our new approximations with semantic information are superior to representative capabi",
    "link": "https://arxiv.org/abs/2402.02340",
    "context": "Title: Learning Semantic Proxies from Visual Prompts for Parameter-Efficient Fine-Tuning in Deep Metric Learning\nAbstract: Deep Metric Learning (DML) has long attracted the attention of the machine learning community as a key objective. Existing solutions concentrate on fine-tuning the pre-trained models on conventional image datasets. As a result of the success of recent pre-trained models trained from larger-scale datasets, it is challenging to adapt the model to the DML tasks in the local data domain while retaining the previously gained knowledge. In this paper, we investigate parameter-efficient methods for fine-tuning the pre-trained model for DML tasks. In particular, we propose a novel and effective framework based on learning Visual Prompts (VPT) in the pre-trained Vision Transformers (ViT). Based on the conventional proxy-based DML paradigm, we augment the proxy by incorporating the semantic information from the input image and the ViT, in which we optimize the visual prompts for each class. We demonstrate that our new approximations with semantic information are superior to representative capabi",
    "path": "papers/24/02/2402.02340.json",
    "total_tokens": 859,
    "translated_title": "从视觉提示中学习语义代理，为深度度量学习中的参数高效微调",
    "translated_abstract": "深度度量学习(DML)一直是机器学习社区关注的重点目标。现有解决方案集中于对传统图像数据集上进行预训练模型的微调。由于最近从更大规模数据集训练的预训练模型取得成功，将该模型适应本地数据域的DML任务，同时保留先前获得的知识，是具有挑战性的。在本文中，我们研究了用于DML任务的预训练模型的参数高效微调方法。特别是，我们提出了一种基于学习预训练视觉转换器(ViT)中的视觉提示(VPT)的新颖有效的框架。基于传统的基于代理的DML范例，我们通过将输入图像和ViT的语义信息结合到代理中来优化每个类别的视觉提示。我们证明了我们的新逼近方法在语义信息方面优于代表能力。",
    "tldr": "本论文提出了一种基于学习视觉提示的参数高效微调方法，能够在深度度量学习任务中使预训练模型适应本地数据域并保留先前获得的知识。",
    "en_tdlr": "This paper proposes a parameter-efficient fine-tuning method based on learning visual prompts, which adapts pre-trained models to local data domains in deep metric learning tasks while retaining previously gained knowledge."
}