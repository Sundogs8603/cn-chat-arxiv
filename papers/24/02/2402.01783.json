{
    "title": "Hierarchical Multi-Label Classification of Online Vaccine Concerns",
    "abstract": "Vaccine concerns are an ever-evolving target, and can shift quickly as seen during the COVID-19 pandemic. Identifying longitudinal trends in vaccine concerns and misinformation might inform the healthcare space by helping public health efforts strategically allocate resources or information campaigns. We explore the task of detecting vaccine concerns in online discourse using large language models (LLMs) in a zero-shot setting without the need for expensive training datasets. Since real-time monitoring of online sources requires large-scale inference, we explore cost-accuracy trade-offs of different prompting strategies and offer concrete takeaways that may inform choices in system designs for current applications. An analysis of different prompting strategies reveals that classifying the concerns over multiple passes through the LLM, each consisting a boolean question whether the text mentions a vaccine concern or not, works the best. Our results indicate that GPT-4 can strongly outpe",
    "link": "https://arxiv.org/abs/2402.01783",
    "context": "Title: Hierarchical Multi-Label Classification of Online Vaccine Concerns\nAbstract: Vaccine concerns are an ever-evolving target, and can shift quickly as seen during the COVID-19 pandemic. Identifying longitudinal trends in vaccine concerns and misinformation might inform the healthcare space by helping public health efforts strategically allocate resources or information campaigns. We explore the task of detecting vaccine concerns in online discourse using large language models (LLMs) in a zero-shot setting without the need for expensive training datasets. Since real-time monitoring of online sources requires large-scale inference, we explore cost-accuracy trade-offs of different prompting strategies and offer concrete takeaways that may inform choices in system designs for current applications. An analysis of different prompting strategies reveals that classifying the concerns over multiple passes through the LLM, each consisting a boolean question whether the text mentions a vaccine concern or not, works the best. Our results indicate that GPT-4 can strongly outpe",
    "path": "papers/24/02/2402.01783.json",
    "total_tokens": 866,
    "translated_title": "在线疫苗关注的分层多标签分类",
    "translated_abstract": "疫苗关注是一个不断发展的目标，可以在COVID-19大流行中快速变化。通过识别疫苗关注和错误信息的长期趋势，可以帮助公共卫生努力在资源或信息宣传上进行战略性分配。我们在零样本设置中使用大型语言模型（LLM）探索在在线讨论中检测疫苗关注的任务，无需昂贵的训练数据集。由于实时监控在线来源需要大规模推理，我们探索了不同提示策略的成本和准确性之间的权衡，并提供了可以为当前应用程序的系统设计选择提供信息的具体经验教训。对不同提示策略的分析表明，通过LLM多次进行分类，每次通过布尔问题判断文本是否提到疫苗关注，效果最好。我们的结果表明，GPT-4能够明显优于其他模型。",
    "tldr": "本文研究了在线疫苗关注的分层多标签分类任务，使用大型语言模型在零样本设置下检测疫苗关注，同时探索了不同提示策略的成本和准确性权衡，并提供了指导当前应用程序系统设计的具体经验教训。",
    "en_tdlr": "This paper explores the task of hierarchical multi-label classification of online vaccine concerns using large language models (LLMs) in a zero-shot setting. It examines different prompting strategies and offers concrete takeaways for system design choices in current applications. The results demonstrate that GPT-4 outperforms other models."
}