{
    "title": "Motion Guided Token Compression for Efficient Masked Video Modeling",
    "abstract": "arXiv:2402.18577v1 Announce Type: cross  Abstract: Recent developments in Transformers have achieved notable strides in enhancing video comprehension. Nonetheless, the O($N^2$) computation complexity associated with attention mechanisms presents substantial computational hurdles when dealing with the high dimensionality of videos. This challenge becomes particularly pronounced when striving to increase the frames per second (FPS) to enhance the motion capturing capabilities. Such a pursuit is likely to introduce redundancy and exacerbate the existing computational limitations. In this paper, we initiate by showcasing the enhanced performance achieved through an escalation in the FPS rate. Additionally, we present a novel approach, Motion Guided Token Compression (MGTC), to empower Transformer models to utilize a smaller yet more representative set of tokens for comprehensive video representation. Consequently, this yields substantial reductions in computational burden and remains seaml",
    "link": "https://arxiv.org/abs/2402.18577",
    "context": "Title: Motion Guided Token Compression for Efficient Masked Video Modeling\nAbstract: arXiv:2402.18577v1 Announce Type: cross  Abstract: Recent developments in Transformers have achieved notable strides in enhancing video comprehension. Nonetheless, the O($N^2$) computation complexity associated with attention mechanisms presents substantial computational hurdles when dealing with the high dimensionality of videos. This challenge becomes particularly pronounced when striving to increase the frames per second (FPS) to enhance the motion capturing capabilities. Such a pursuit is likely to introduce redundancy and exacerbate the existing computational limitations. In this paper, we initiate by showcasing the enhanced performance achieved through an escalation in the FPS rate. Additionally, we present a novel approach, Motion Guided Token Compression (MGTC), to empower Transformer models to utilize a smaller yet more representative set of tokens for comprehensive video representation. Consequently, this yields substantial reductions in computational burden and remains seaml",
    "path": "papers/24/02/2402.18577.json",
    "total_tokens": 789,
    "translated_title": "运动引导的令牌压缩用于高效的遮蔽视频建模",
    "translated_abstract": "近期Transformer模型在增强视频理解方面取得了显著进展。然而，由于注意力机制所带来的O($N^2$)计算复杂度使得面对视频的高维度时存在着相当大的计算障碍。当我们尝试增加每秒帧数（FPS）以提高运动捕捉能力时，这一挑战尤为突出。这样的追求很可能引入冗余，加剧现有的计算限制。本文首先展示了通过提高FPS率所实现的增强性能。此外，我们提出了一种新颖的方法，即运动引导的令牌压缩（MGTC），以赋能Transformer模型利用更小但更具代表性的令牌集来进行全面的视频表示。因此，这大大减少了计算负担，而且保持了整体",
    "tldr": "运动引导的令牌压缩（MGTC）方法旨在通过提供更小但更具代表性的令牌集来减少Transformer模型处理视频时的计算负担。",
    "en_tdlr": "The Motion Guided Token Compression (MGTC) method aims to reduce the computational burden of Transformer models when processing videos by providing a smaller yet more representative set of tokens."
}