{
    "title": "Fairly Evaluating Large Language Model-based Recommendation Needs Revisit the Cross-Entropy Loss",
    "abstract": "Large language models (LLMs) have gained much attention in the recommendation community; some studies have observed that LLMs, fine-tuned by the cross-entropy loss with a full softmax, could achieve state-of-the-art performance already. However, these claims are drawn from unobjective and unfair comparisons. In view of the substantial quantity of items in reality, conventional recommenders typically adopt a pointwise/pairwise loss function instead for training. This substitute however causes severe performance degradation, leading to under-estimation of conventional methods and over-confidence in the ranking capability of LLMs.   In this work, we theoretically justify the superiority of cross-entropy, and showcase that it can be adequately replaced by some elementary approximations with certain necessary modifications. The remarkable results across three public datasets corroborate that even in a practical sense, existing LLM-based methods are not as effective as claimed for next-item ",
    "link": "https://arxiv.org/abs/2402.06216",
    "context": "Title: Fairly Evaluating Large Language Model-based Recommendation Needs Revisit the Cross-Entropy Loss\nAbstract: Large language models (LLMs) have gained much attention in the recommendation community; some studies have observed that LLMs, fine-tuned by the cross-entropy loss with a full softmax, could achieve state-of-the-art performance already. However, these claims are drawn from unobjective and unfair comparisons. In view of the substantial quantity of items in reality, conventional recommenders typically adopt a pointwise/pairwise loss function instead for training. This substitute however causes severe performance degradation, leading to under-estimation of conventional methods and over-confidence in the ranking capability of LLMs.   In this work, we theoretically justify the superiority of cross-entropy, and showcase that it can be adequately replaced by some elementary approximations with certain necessary modifications. The remarkable results across three public datasets corroborate that even in a practical sense, existing LLM-based methods are not as effective as claimed for next-item ",
    "path": "papers/24/02/2402.06216.json",
    "total_tokens": 922,
    "translated_title": "公平评估基于大规模语言模型的推荐方法需要重新审视交叉熵损失",
    "translated_abstract": "大规模语言模型(LLM)在推荐领域引起了广泛关注；一些研究观察到，经过全softmax细调的LLM已经可以达到最先进的性能。然而，这些观点来自于主观和不公平的比较。鉴于现实中的大量物品，传统的推荐方法通常采用点对/点对损失函数进行训练。然而，这种替代方法会导致性能严重下降，低估传统方法的效果，并过高评估LLM的排序能力。本文从理论上证明了交叉熵的优越性，并展示了可以用一些基本近似方法进行适当替代的必要修改。在三个公共数据集上的显著结果证实，即使从实际意义上讲，现有的基于LLM的方法对于预测下一个项目的效果并不像宣称的那样有效。",
    "tldr": "本文指出现有的基于大规模语言模型的推荐方法在公平性和评估上存在问题，需要重新审视交叉熵损失并替代传统的点对/点对损失函数。并且通过理论和实验结果表明，现有的基于LLM的方法对于预测下一个项目的效果并不像宣称的那样有效。",
    "en_tdlr": "This paper points out the issues with existing large language model-based recommendation methods in terms of fairness and evaluation, calling for a reconsideration of the cross-entropy loss and a replacement of the traditional pointwise/pairwise loss function. Theoretical justifications and experimental results demonstrate that current LLM-based methods are not as effective as claimed in predicting the next item."
}