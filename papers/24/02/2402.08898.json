{
    "title": "UniEnc-CASSNAT: An Encoder-only Non-autoregressive ASR for Speech SSL Models",
    "abstract": "arXiv:2402.08898v1 Announce Type: cross Abstract: Non-autoregressive automatic speech recognition (NASR) models have gained attention due to their parallelism and fast inference. The encoder-based NASR, e.g. connectionist temporal classification (CTC), can be initialized from the speech foundation models (SFM) but does not account for any dependencies among intermediate tokens. The encoder-decoder-based NASR, like CTC alignment-based single-step non-autoregressive transformer (CASS-NAT), can mitigate the dependency problem but is not able to efficiently integrate SFM. Inspired by the success of recent work of speech-text joint pre-training with a shared transformer encoder, we propose a new encoder-based NASR, UniEnc-CASSNAT, to combine the advantages of CTC and CASS-NAT. UniEnc-CASSNAT consists of only an encoder as the major module, which can be the SFM. The encoder plays the role of both the CASS-NAT encoder and decoder by two forward passes. The first pass of the encoder accepts th",
    "link": "https://arxiv.org/abs/2402.08898",
    "context": "Title: UniEnc-CASSNAT: An Encoder-only Non-autoregressive ASR for Speech SSL Models\nAbstract: arXiv:2402.08898v1 Announce Type: cross Abstract: Non-autoregressive automatic speech recognition (NASR) models have gained attention due to their parallelism and fast inference. The encoder-based NASR, e.g. connectionist temporal classification (CTC), can be initialized from the speech foundation models (SFM) but does not account for any dependencies among intermediate tokens. The encoder-decoder-based NASR, like CTC alignment-based single-step non-autoregressive transformer (CASS-NAT), can mitigate the dependency problem but is not able to efficiently integrate SFM. Inspired by the success of recent work of speech-text joint pre-training with a shared transformer encoder, we propose a new encoder-based NASR, UniEnc-CASSNAT, to combine the advantages of CTC and CASS-NAT. UniEnc-CASSNAT consists of only an encoder as the major module, which can be the SFM. The encoder plays the role of both the CASS-NAT encoder and decoder by two forward passes. The first pass of the encoder accepts th",
    "path": "papers/24/02/2402.08898.json",
    "total_tokens": 935,
    "translated_title": "UniEnc-CASSNAT:一种仅有编码器的非自回归语音SSL模型的自动语音识别",
    "translated_abstract": "非自回归自动语音识别（NASR）模型以其并行性和快速推理而受到关注。基于编码器的NASR（例如连接主义时间分类（CTC））可以从语音基础模型（SFM）初始化，但不考虑中间标记之间的依赖关系。基于编码器-解码器的NASR（如基于CTC对齐的单步非自回归Transformer（CASS-NAT））可以缓解依赖问题，但不能有效地集成SFM。受最近使用共享Transformer编码器进行语音-文本联合预训练的成功启发，我们提出了一种新的基于编码器的NASR，UniEnc-CASSNAT，以结合CTC和CASS-NAT的优势。UniEnc-CASSNAT只由编码器作为主要模块组成，可以是SFM。编码器通过两次前向传递同时充当CASS-NAT编码器和解码器的角色。编码器的第一次传递接受...",
    "tldr": "UniEnc-CASSNAT是一种仅有编码器的非自回归语音SSL模型的自动语音识别，通过结合CTC和CASS-NAT的优势，同时充当编码器和解码器的角色，能有效集成SFM并缓解依赖问题。"
}