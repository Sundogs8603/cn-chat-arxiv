{
    "title": "Direct Evaluation of Chain-of-Thought in Multi-hop Reasoning with Knowledge Graphs",
    "abstract": "arXiv:2402.11199v1 Announce Type: new  Abstract: Large language models (LLMs) demonstrate strong reasoning abilities when prompted to generate chain-of-thought (CoT) explanations alongside answers. However, previous research on evaluating LLMs has solely focused on answer accuracy, neglecting the correctness of the generated CoT. In this paper, we delve deeper into the CoT reasoning capabilities of LLMs in multi-hop question answering by utilizing knowledge graphs (KGs). We propose a novel discriminative and generative CoT evaluation paradigm to assess LLMs' knowledge of reasoning and the accuracy of the generated CoT. Through experiments conducted on 5 different families of LLMs across 2 multi-hop question-answering datasets, we find that LLMs possess sufficient knowledge to perform reasoning. However, there exists a significant disparity between answer accuracy and faithfulness of the CoT reasoning generated by LLMs, indicating that they often arrive at correct answers through incorr",
    "link": "https://arxiv.org/abs/2402.11199",
    "context": "Title: Direct Evaluation of Chain-of-Thought in Multi-hop Reasoning with Knowledge Graphs\nAbstract: arXiv:2402.11199v1 Announce Type: new  Abstract: Large language models (LLMs) demonstrate strong reasoning abilities when prompted to generate chain-of-thought (CoT) explanations alongside answers. However, previous research on evaluating LLMs has solely focused on answer accuracy, neglecting the correctness of the generated CoT. In this paper, we delve deeper into the CoT reasoning capabilities of LLMs in multi-hop question answering by utilizing knowledge graphs (KGs). We propose a novel discriminative and generative CoT evaluation paradigm to assess LLMs' knowledge of reasoning and the accuracy of the generated CoT. Through experiments conducted on 5 different families of LLMs across 2 multi-hop question-answering datasets, we find that LLMs possess sufficient knowledge to perform reasoning. However, there exists a significant disparity between answer accuracy and faithfulness of the CoT reasoning generated by LLMs, indicating that they often arrive at correct answers through incorr",
    "path": "papers/24/02/2402.11199.json",
    "total_tokens": 879,
    "translated_title": "在知识图谱中对多跳推理中思维链的直接评估",
    "translated_abstract": "大型语言模型(LLMs)展示了强大的推理能力，当提示生成链式思维（CoT）解释时，以及答案。然而，先前关于LLMs评估的研究仅关注答案准确性，忽略了生成的CoT的正确性。在本文中，我们通过利用知识图谱（KGs），深入探讨LLMs在多跳问题回答中的CoT推理能力。我们提出了一种新颖的辨别式和生成式CoT评估范式，以评估LLMs的推理知识和生成CoT的准确性。通过在2个多跳问题回答数据集上对5个不同系列的LLMs进行的实验，我们发现LLMs具有足够的知识来执行推理。然而，LLMs生成的CoT推理的准确性与答案准确性之间存在显著差异，表明它们经常通过错误的方式得出正确答案。",
    "tldr": "本文通过利用知识图谱，提出了一种新颖的CoT推理能力评估模式，揭示了大型语言模型在多跳问题回答中推理知识和生成CoT的准确性之间的显著差异",
    "en_tdlr": "This paper proposes a novel CoT evaluation paradigm utilizing knowledge graphs, revealing a significant disparity between the reasoning knowledge and the accuracy of generated CoTs in multi-hop question answering by large language models."
}