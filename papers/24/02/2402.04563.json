{
    "title": "Attention Guided CAM: Visual Explanations of Vision Transformer Guided by Self-Attention",
    "abstract": "Vision Transformer(ViT) is one of the most widely used models in the computer vision field with its great performance on various tasks. In order to fully utilize the ViT-based architecture in various applications, proper visualization methods with a decent localization performance are necessary, but these methods employed in CNN-based models are still not available in ViT due to its unique structure. In this work, we propose an attention-guided visualization method applied to ViT that provides a high-level semantic explanation for its decision. Our method selectively aggregates the gradients directly propagated from the classification output to each self-attention, collecting the contribution of image features extracted from each location of the input image. These gradients are additionally guided by the normalized self-attention scores, which are the pairwise patch correlation scores. They are used to supplement the gradients on the patch-level context information efficiently detected",
    "link": "https://arxiv.org/abs/2402.04563",
    "context": "Title: Attention Guided CAM: Visual Explanations of Vision Transformer Guided by Self-Attention\nAbstract: Vision Transformer(ViT) is one of the most widely used models in the computer vision field with its great performance on various tasks. In order to fully utilize the ViT-based architecture in various applications, proper visualization methods with a decent localization performance are necessary, but these methods employed in CNN-based models are still not available in ViT due to its unique structure. In this work, we propose an attention-guided visualization method applied to ViT that provides a high-level semantic explanation for its decision. Our method selectively aggregates the gradients directly propagated from the classification output to each self-attention, collecting the contribution of image features extracted from each location of the input image. These gradients are additionally guided by the normalized self-attention scores, which are the pairwise patch correlation scores. They are used to supplement the gradients on the patch-level context information efficiently detected",
    "path": "papers/24/02/2402.04563.json",
    "total_tokens": 819,
    "translated_title": "基于注意力引导的CAM：自注意力指导下视觉变换器的视觉解释",
    "translated_abstract": "视觉变换器（ViT）是计算机视觉领域中最常用的模型之一，在各种任务上表现出色。为了充分利用ViT架构在各种应用中，需要适当的可视化方法并具有良好的定位性能，但由于其独特的结构，目前在CNN模型中使用的这些方法在ViT中仍然不可用。在这项工作中，我们提出了一种应用于ViT的注意力引导可视化方法，为其决策提供高级语义解释。我们的方法选择性地聚合从分类输出直接传播到每个自注意力的梯度，从而收集从输入图像的每个位置提取的图像特征的贡献。这些梯度还受到标准化的自注意力得分的指导，这些得分是成对的补丁相关性得分。它们用于有效检测补丁级上下文信息上的梯度。",
    "tldr": "本文提出了一种基于注意力引导的可视化方法，可以在视觉变换器中提供高级语义解释，以便充分利用其在各种应用中的潜力。",
    "en_tdlr": "This paper proposes an attention-guided visualization method that provides high-level semantic explanations in Vision Transformer, allowing to fully utilize its potential in various applications."
}