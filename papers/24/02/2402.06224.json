{
    "title": "Adaptive multi-gradient methods for quasiconvex vector optimization and applications to multi-task learning",
    "abstract": "We present an adaptive step-size method, which does not include line-search techniques, for solving a wide class of nonconvex multiobjective programming problems on an unbounded constraint set. We also prove convergence of a general approach under modest assumptions. More specifically, the convexity criterion might not be satisfied by the objective function. Unlike descent line-search algorithms, it does not require an initial step-size to be determined by a previously determined Lipschitz constant. The process's primary characteristic is its gradual step-size reduction up until a predetermined condition is met. It can be specifically applied to offer an innovative multi-gradient projection method for unbounded constrained optimization issues. Preliminary findings from a few computational examples confirm the accuracy of the strategy. We apply the proposed technique to some multi-task learning experiments to show its efficacy for large-scale challenges.",
    "link": "https://arxiv.org/abs/2402.06224",
    "context": "Title: Adaptive multi-gradient methods for quasiconvex vector optimization and applications to multi-task learning\nAbstract: We present an adaptive step-size method, which does not include line-search techniques, for solving a wide class of nonconvex multiobjective programming problems on an unbounded constraint set. We also prove convergence of a general approach under modest assumptions. More specifically, the convexity criterion might not be satisfied by the objective function. Unlike descent line-search algorithms, it does not require an initial step-size to be determined by a previously determined Lipschitz constant. The process's primary characteristic is its gradual step-size reduction up until a predetermined condition is met. It can be specifically applied to offer an innovative multi-gradient projection method for unbounded constrained optimization issues. Preliminary findings from a few computational examples confirm the accuracy of the strategy. We apply the proposed technique to some multi-task learning experiments to show its efficacy for large-scale challenges.",
    "path": "papers/24/02/2402.06224.json",
    "total_tokens": 830,
    "translated_title": "自适应多梯度方法用于拟凸向量优化及其在多任务学习中的应用",
    "translated_abstract": "我们提出了一种自适应步长方法，该方法不包括线搜索技术，用于解决一个广泛的非凸多目标规划问题在一个无界约束集上。我们还证明了在适度的假设下一个通用方法的收敛性。具体来说，目标函数可能不满足凸性标准。与下降线搜索算法不同，它不需要一个初始步长由之前确定的利普希茨常数来确定。过程的主要特点是直到达到预定条件才进行渐进步长的减小。它可以特别应用于为无界约束优化问题提供一种创新的多梯度投影方法。一些计算实例的初步结果证实了该策略的准确性。我们将所提出的技术应用到一些多任务学习实验中，以展示其在大规模挑战中的效果。",
    "tldr": "我们提出了一种自适应步长方法，用于解决一类广泛的非凸多目标规划问题，并应用于创新的多梯度投影方法和多任务学习，展示了其在大规模挑战中的效果。"
}