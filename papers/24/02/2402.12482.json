{
    "title": "SECP: A Speech Enhancement-Based Curation Pipeline For Scalable Acquisition Of Clean Speech",
    "abstract": "arXiv:2402.12482v1 Announce Type: cross  Abstract: As more speech technologies rely on a supervised deep learning approach with clean speech as the ground truth, a methodology to onboard said speech at scale is needed. However, this approach needs to minimize the dependency on human listening and annotation, only requiring a human-in-the-loop when needed. In this paper, we address this issue by outlining Speech Enhancement-based Curation Pipeline (SECP) which serves as a framework to onboard clean speech. This clean speech can then train a speech enhancement model, which can further refine the original dataset and thus close the iterative loop. By running two iterative rounds, we observe that enhanced output used as ground truth does not degrade model performance according to $\\Delta_{PESQ}$, a metric used in this paper. We also show through comparative mean opinion score (CMOS) based subjective tests that the highest and lowest bound of refined data is perceptually better than the ori",
    "link": "https://arxiv.org/abs/2402.12482",
    "context": "Title: SECP: A Speech Enhancement-Based Curation Pipeline For Scalable Acquisition Of Clean Speech\nAbstract: arXiv:2402.12482v1 Announce Type: cross  Abstract: As more speech technologies rely on a supervised deep learning approach with clean speech as the ground truth, a methodology to onboard said speech at scale is needed. However, this approach needs to minimize the dependency on human listening and annotation, only requiring a human-in-the-loop when needed. In this paper, we address this issue by outlining Speech Enhancement-based Curation Pipeline (SECP) which serves as a framework to onboard clean speech. This clean speech can then train a speech enhancement model, which can further refine the original dataset and thus close the iterative loop. By running two iterative rounds, we observe that enhanced output used as ground truth does not degrade model performance according to $\\Delta_{PESQ}$, a metric used in this paper. We also show through comparative mean opinion score (CMOS) based subjective tests that the highest and lowest bound of refined data is perceptually better than the ori",
    "path": "papers/24/02/2402.12482.json",
    "total_tokens": 933,
    "translated_title": "SECP：基于语音增强的策划管道，用于可扩展获取干净语音",
    "translated_abstract": "随着越来越多的语音技术依赖于以干净语音为基准的监督式深度学习方法，需要一种方法来在规模上接入这些语音。然而，这种方法需要最大程度地减少对人类听觉和注释的依赖，只在需要时需要人类介入。本文通过概述基于语音增强的策划管道（SECP）来解决这个问题，作为一个框架用来接入干净语音。这些干净语音可以用来训练语音增强模型，进一步改进原始数据集，从而关闭迭代循环。我们通过两轮迭代的实验观察到，作为基准的增强输出不会使模型性能根据本文使用的 $\\Delta_{PESQ}$ 指标下降。我们还通过基于比较均值意见评分（CMOS）的主观测试表明，优化数据的最高和最低边界在感知上优于原始数据。",
    "tldr": "提出了基于语音增强的策划管道（SECP），可以在规模上获取干净语音并训练语音增强模型，通过两轮迭代观察到增强输出作为基准不会降低模型性能，并通过主观测试证明优化数据在感知上优于原始数据。",
    "en_tdlr": "Introduced a Speech Enhancement-based Curation Pipeline (SECP) for acquiring clean speech at scale to train speech enhancement models, showing through two iterative rounds that enhanced output as ground truth does not degrade model performance, and demonstrating perceptual superiority of optimized data over the original through subjective tests."
}