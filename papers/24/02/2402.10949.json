{
    "title": "The Unreasonable Effectiveness of Eccentric Automatic Prompts",
    "abstract": "arXiv:2402.10949v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated remarkable problem-solving and basic mathematics abilities. However, their efficacy is highly contingent on the formulation of the prompt. This study endeavors to quantify the influence of incorporating \"positive thinking\" into the system message of the prompt, then compare that to systematic prompt optimization. We assess the performance of 60 combinations of system message snippets, tested with and without Chain of Thought prompting, across three models with parameters ranging from 7 to 70 billion on the GSM8K dataset. Our findings reveal that results do not universally generalize across models. In most instances, the inclusion of \"positive thinking\" prompts positively affected model performance. Notably, however, Llama2-70B exhibited an exception when not utilizing Chain of Thought, as the optimal system message was found to be none at all. Given the combinatorial complexity, and thus com",
    "link": "https://arxiv.org/abs/2402.10949",
    "context": "Title: The Unreasonable Effectiveness of Eccentric Automatic Prompts\nAbstract: arXiv:2402.10949v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated remarkable problem-solving and basic mathematics abilities. However, their efficacy is highly contingent on the formulation of the prompt. This study endeavors to quantify the influence of incorporating \"positive thinking\" into the system message of the prompt, then compare that to systematic prompt optimization. We assess the performance of 60 combinations of system message snippets, tested with and without Chain of Thought prompting, across three models with parameters ranging from 7 to 70 billion on the GSM8K dataset. Our findings reveal that results do not universally generalize across models. In most instances, the inclusion of \"positive thinking\" prompts positively affected model performance. Notably, however, Llama2-70B exhibited an exception when not utilizing Chain of Thought, as the optimal system message was found to be none at all. Given the combinatorial complexity, and thus com",
    "path": "papers/24/02/2402.10949.json",
    "total_tokens": 844,
    "translated_title": "异类自动提示的不合理有效性",
    "translated_abstract": "大型语言模型（LLMs）展示了出色的问题解决和基本数学能力。然而，它们的功效高度依赖于提示的制定。本研究旨在量化将“积极思考”纳入系统提示消息的影响，然后将其与系统化提示优化进行比较。我们评估了60种系统消息片段的性能，分别使用和不使用Chain of Thought提示，跨三个参数范围从70亿到70亿个变量的模型，在GSM8K数据集上进行测试。我们的发现表明，结果并不在所有模型中普遍适用。在大多数情况下，包括“积极思考”提示会积极影响模型性能。然而，值得注意的是，Llama2-70B在不使用Chain of Thought时是个例外，因为发现最佳系统消息实际上是没有消息。考虑到组合复杂性，以及其导至的加# Truncated due to exceeding character limit.",
    "tldr": "异类自动提示的不合理有效性研究了大型语言模型在处理各种提示时的表现，结果显示在大多数情况下，包括“积极思考”提示会对模型性能产生积极影响。"
}