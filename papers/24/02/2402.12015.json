{
    "title": "An Index Policy Based on Sarsa and Q-learning for Heterogeneous Smart Target Tracking",
    "abstract": "arXiv:2402.12015v1 Announce Type: cross  Abstract: In solving the non-myopic radar scheduling for multiple smart target tracking within an active and passive radar network, we need to consider both short-term enhanced tracking performance and a higher probability of target maneuvering in the future with active tracking. Acquiring the long-term tracking performance while scheduling the beam resources of active and passive radars poses a challenge. To address this challenge, we model this problem as a Markov decision process consisting of parallel restless bandit processes. Each bandit process is associated with a smart target, of which the estimation state evolves according to different discrete dynamic models for different actions - whether or not the target is being tracked. The discrete state is defined by the dynamic mode. The problem exhibits the curse of dimensionality, where optimal solutions are in general intractable. We resort to heuristics through the famous restless multi-ar",
    "link": "https://arxiv.org/abs/2402.12015",
    "context": "Title: An Index Policy Based on Sarsa and Q-learning for Heterogeneous Smart Target Tracking\nAbstract: arXiv:2402.12015v1 Announce Type: cross  Abstract: In solving the non-myopic radar scheduling for multiple smart target tracking within an active and passive radar network, we need to consider both short-term enhanced tracking performance and a higher probability of target maneuvering in the future with active tracking. Acquiring the long-term tracking performance while scheduling the beam resources of active and passive radars poses a challenge. To address this challenge, we model this problem as a Markov decision process consisting of parallel restless bandit processes. Each bandit process is associated with a smart target, of which the estimation state evolves according to different discrete dynamic models for different actions - whether or not the target is being tracked. The discrete state is defined by the dynamic mode. The problem exhibits the curse of dimensionality, where optimal solutions are in general intractable. We resort to heuristics through the famous restless multi-ar",
    "path": "papers/24/02/2402.12015.json",
    "total_tokens": 842,
    "translated_title": "基于Sarsa和Q-learning的异质智能目标跟踪索引策略",
    "translated_abstract": "在解决多个智能目标在主动和被动雷达网络中的非远见性雷达调度问题时，需要考虑短期增强跟踪性能和未来主动跟踪中目标机动性的概率。在调度主动和被动雷达的波束资源时获得长期跟踪性能带来挑战。为了解决这一挑战，我们将这个问题建模为由平行不平静老虎机过程组成的马尔可夫决策过程。每个老虎机过程与一个智能目标相关联，其估计状态根据不同的动作（目标是否被跟踪）而遵循不同的离散动态模型而演变。离散状态由动态模式定义。该问题呈现出维度诅咒，其中最优解通常难以处理。我们通过著名的不平静多臂老虎机启发式方法来求解。",
    "tldr": "基于Sarsa和Q-learning的智能目标跟踪索引策略，解决了雷达调度中短期性能和未来机动性的平衡挑战。",
    "en_tdlr": "An index policy for smart target tracking based on Sarsa and Q-learning balances short-term performance and future maneuverability challenges in radar scheduling."
}