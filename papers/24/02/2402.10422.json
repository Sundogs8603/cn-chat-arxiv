{
    "title": "Pushing the Limits of Zero-shot End-to-End Speech Translation",
    "abstract": "arXiv:2402.10422v1 Announce Type: new  Abstract: Data scarcity and the modality gap between the speech and text modalities are two major obstacles of end-to-end Speech Translation (ST) systems, thus hindering their performance. Prior work has attempted to mitigate these challenges by leveraging external MT data and optimizing distance metrics that bring closer the speech-text representations. However, achieving competitive results typically requires some ST data. For this reason, we introduce ZeroSwot, a method for zero-shot ST that bridges the modality gap without any paired ST data. Leveraging a novel CTC compression and Optimal Transport, we train a speech encoder using only ASR data, to align with the representation space of a massively multilingual MT model. The speech encoder seamlessly integrates with the MT model at inference, enabling direct translation from speech to text, across all languages supported by the MT model. Our experiments show that we can effectively close the m",
    "link": "https://arxiv.org/abs/2402.10422",
    "context": "Title: Pushing the Limits of Zero-shot End-to-End Speech Translation\nAbstract: arXiv:2402.10422v1 Announce Type: new  Abstract: Data scarcity and the modality gap between the speech and text modalities are two major obstacles of end-to-end Speech Translation (ST) systems, thus hindering their performance. Prior work has attempted to mitigate these challenges by leveraging external MT data and optimizing distance metrics that bring closer the speech-text representations. However, achieving competitive results typically requires some ST data. For this reason, we introduce ZeroSwot, a method for zero-shot ST that bridges the modality gap without any paired ST data. Leveraging a novel CTC compression and Optimal Transport, we train a speech encoder using only ASR data, to align with the representation space of a massively multilingual MT model. The speech encoder seamlessly integrates with the MT model at inference, enabling direct translation from speech to text, across all languages supported by the MT model. Our experiments show that we can effectively close the m",
    "path": "papers/24/02/2402.10422.json",
    "total_tokens": 916,
    "translated_title": "推动零-shot端到端语音翻译的极限",
    "translated_abstract": "数据稀缺和语音与文本模态之间的模态差距是端到端语音翻译（ST）系统的两个主要障碍，从而阻碍了其性能。 以往的工作尝试通过利用外部MT数据和优化距离度量来减轻这些挑战，从而使语音-文本表示更加接近。 然而，通常需要一些ST数据才能获得竞争性结果。 出于这个原因，我们介绍了ZeroSwot，这是一种零-shot ST方法，可以在没有任何配对的ST数据的情况下弥合模态差距。 利用一种新颖的CTC压缩和最优传输技术，我们只使用ASR数据训练语音编码器，以与一个大规模多语言MT模型的表示空间进行对齐。 语音编码器在推断时与MT模型无缝集成，使得可以直接在所有MT模型支持的语言中从语音翻译为文本。 我们的实验表明，我们可以有效地平滑地关闭m模态间的空间.",
    "tldr": "引入了ZeroSwot方法，实现了零-shot ST，通过CTC压缩和最优传输，仅利用ASR数据训练语音编码器，并与多语言MT模型在推断时无缝集成，实现直接从语音到文本的翻译。",
    "en_tdlr": "Introduced the ZeroSwot method, achieving zero-shot ST by training a speech encoder using only ASR data through CTC compression and Optimal Transport, seamlessly integrating with a multilingual MT model at inference for direct translation from speech to text across all supported languages."
}