{
    "title": "Empowering Large Language Model Agents through Action Learning",
    "abstract": "arXiv:2402.15809v1 Announce Type: new  Abstract: Large Language Model (LLM) Agents have recently garnered increasing interest yet they are limited in their ability to learn from trial and error, a key element of intelligent behavior. In this work, we argue that the capacity to learn new actions from experience is fundamental to the advancement of learning in LLM agents. While humans naturally expand their action spaces and develop skills through experiential learning, LLM agents typically operate within fixed action spaces, limiting their potential for growth. To address these challenges, our study explores open-action learning for language agents. We introduce a framework LearnAct with an iterative learning strategy to create and improve actions in the form of Python functions. In each iteration, LLM revises and updates the currently available actions based on the errors identified in unsuccessful training tasks, thereby enhancing action effectiveness. Our experimental evaluations acr",
    "link": "https://arxiv.org/abs/2402.15809",
    "context": "Title: Empowering Large Language Model Agents through Action Learning\nAbstract: arXiv:2402.15809v1 Announce Type: new  Abstract: Large Language Model (LLM) Agents have recently garnered increasing interest yet they are limited in their ability to learn from trial and error, a key element of intelligent behavior. In this work, we argue that the capacity to learn new actions from experience is fundamental to the advancement of learning in LLM agents. While humans naturally expand their action spaces and develop skills through experiential learning, LLM agents typically operate within fixed action spaces, limiting their potential for growth. To address these challenges, our study explores open-action learning for language agents. We introduce a framework LearnAct with an iterative learning strategy to create and improve actions in the form of Python functions. In each iteration, LLM revises and updates the currently available actions based on the errors identified in unsuccessful training tasks, thereby enhancing action effectiveness. Our experimental evaluations acr",
    "path": "papers/24/02/2402.15809.json",
    "total_tokens": 866,
    "translated_title": "通过行为学习增强大型语言模型代理",
    "translated_abstract": "大型语言模型（LLM）代理近来引起越来越多的关注，然而它们在从试错中学习的能力方面存在限制，这是智能行为的关键因素。本研究认为，从经验中学习新动作的能力对于LLM代理的学习进步至关重要。虽然人类自然地扩展他们的动作空间并通过经验学习发展技能，但LLM代理通常在固定的动作空间内操作，限制了它们的成长潜力。为解决这些挑战，我们的研究探讨了语言代理的开放式行为学习。我们提出了一个名为LearnAct的框架，采用迭代学习策略来创建和改进Python函数形式的动作。在每次迭代中，LLM根据在失败的训练任务中识别出的错误，修订和更新当前可用的动作，从而增强动作的有效性。我们的实验评估是...",
    "tldr": "学习新动作的能力对于大型语言模型代理的学习进步至关重要，本研究提出了开放式行为学习框架，通过迭代学习策略改进动作，增强代理的学习效果。"
}