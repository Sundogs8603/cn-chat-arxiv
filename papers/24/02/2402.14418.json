{
    "title": "Uncertainty-Aware Evaluation for Vision-Language Models",
    "abstract": "arXiv:2402.14418v1 Announce Type: cross  Abstract: Vision-Language Models like GPT-4, LLaVA, and CogVLM have surged in popularity recently due to their impressive performance in several vision-language tasks. Current evaluation methods, however, overlook an essential component: uncertainty, which is crucial for a comprehensive assessment of VLMs. Addressing this oversight, we present a benchmark incorporating uncertainty quantification into evaluating VLMs.   Our analysis spans 20+ VLMs, focusing on the multiple-choice Visual Question Answering (VQA) task. We examine models on 5 datasets that evaluate various vision-language capabilities.   Using conformal prediction as an uncertainty estimation approach, we demonstrate that the models' uncertainty is not aligned with their accuracy. Specifically, we show that models with the highest accuracy may also have the highest uncertainty, which confirms the importance of measuring it for VLMs. Our empirical findings also reveal a correlation b",
    "link": "https://arxiv.org/abs/2402.14418",
    "context": "Title: Uncertainty-Aware Evaluation for Vision-Language Models\nAbstract: arXiv:2402.14418v1 Announce Type: cross  Abstract: Vision-Language Models like GPT-4, LLaVA, and CogVLM have surged in popularity recently due to their impressive performance in several vision-language tasks. Current evaluation methods, however, overlook an essential component: uncertainty, which is crucial for a comprehensive assessment of VLMs. Addressing this oversight, we present a benchmark incorporating uncertainty quantification into evaluating VLMs.   Our analysis spans 20+ VLMs, focusing on the multiple-choice Visual Question Answering (VQA) task. We examine models on 5 datasets that evaluate various vision-language capabilities.   Using conformal prediction as an uncertainty estimation approach, we demonstrate that the models' uncertainty is not aligned with their accuracy. Specifically, we show that models with the highest accuracy may also have the highest uncertainty, which confirms the importance of measuring it for VLMs. Our empirical findings also reveal a correlation b",
    "path": "papers/24/02/2402.14418.json",
    "total_tokens": 862,
    "translated_title": "视觉语言模型的不确定性感知评估",
    "translated_abstract": "最近，像GPT-4、LLaVA和CogVLM这样的视觉语言模型因在几种视觉-语言任务中表现出色而变得越来越受欢迎。然而，当前的评估方法忽视了一个关键组成部分：不确定性，这对于全面评估VLMs非常重要。为了解决这一疏忽，我们提出了一个基准，将不确定性量化融入到评估VLMs中。我们的分析涵盖了20多个VLMs，重点关注多项选择视觉问答（VQA）任务。我们在评估各种视觉-语言能力的5个数据集上检验了模型。通过使用符合预测作为不确定性估计方法，我们证明了模型的不确定性与其准确性不一致。具体而言，我们表明准确性最高的模型可能也具有最高的不确定性，这证实了为VLMs测量其重要性。我们的实证发现还揭示了一种相关性，其",
    "tldr": "提出了一个新的基准来评估视觉语言模型，该基准将不确定性量化融入评估过程中，揭示了准确性最高的模型可能也具有最高不确定性的重要性。",
    "en_tdlr": "Propose a new benchmark for evaluating vision-language models, incorporating uncertainty quantification into the evaluation process, highlighting the importance of high accuracy models potentially having high uncertainties."
}