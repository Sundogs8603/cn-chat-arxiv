{
    "title": "Frequency Explains the Inverse Correlation of Large Language Models' Size, Training Data Amount, and Surprisal's Fit to Reading Times",
    "abstract": "Recent studies have shown that as Transformer-based language models become larger and are trained on very large amounts of data, the fit of their surprisal estimates to naturalistic human reading times degrades. The current work presents a series of analyses showing that word frequency is a key explanatory factor underlying these two trends. First, residual errors from four language model families on four corpora show that the inverse correlation between model size and fit to reading times is the strongest on the subset of least frequent words, which is driven by excessively accurate predictions of larger model variants. Additionally, training dynamics reveal that during later training steps, all model variants learn to predict rare words and that larger model variants do so more accurately, which explains the detrimental effect of both training data amount and model size on fit to reading times. Finally, a feature attribution analysis demonstrates that larger model variants are able t",
    "link": "https://arxiv.org/abs/2402.02255",
    "context": "Title: Frequency Explains the Inverse Correlation of Large Language Models' Size, Training Data Amount, and Surprisal's Fit to Reading Times\nAbstract: Recent studies have shown that as Transformer-based language models become larger and are trained on very large amounts of data, the fit of their surprisal estimates to naturalistic human reading times degrades. The current work presents a series of analyses showing that word frequency is a key explanatory factor underlying these two trends. First, residual errors from four language model families on four corpora show that the inverse correlation between model size and fit to reading times is the strongest on the subset of least frequent words, which is driven by excessively accurate predictions of larger model variants. Additionally, training dynamics reveal that during later training steps, all model variants learn to predict rare words and that larger model variants do so more accurately, which explains the detrimental effect of both training data amount and model size on fit to reading times. Finally, a feature attribution analysis demonstrates that larger model variants are able t",
    "path": "papers/24/02/2402.02255.json",
    "total_tokens": 1091,
    "translated_title": "频率解释了大型语言模型尺寸、训练数据量和惊讶程度适应阅读时间的反相关关系",
    "translated_abstract": "最近的研究表明，随着基于Transformer的语言模型变得越来越大并在大量数据上进行训练，它们的惊讶估计与自然人阅读时间的适应性下降。本研究通过一系列分析显示，词频是这两个趋势背后的关键解释因素。首先，来自四个语言模型家族在四个语料库上的残差误差显示，模型尺寸与适应阅读时间之间的反相关在最不频繁的词汇子集上最为显著，这是由较大模型变体过度准确的预测所推动。此外，训练动态显示，在后期训练步骤中，所有模型变体学习预测罕见的词汇，并且较大模型变体的预测更为准确，这解释了训练数据量和模型尺寸对适应阅读时间的负面影响。最后，特征归因分析证明较大的模型变体能够更好地预测罕见的词汇。",
    "tldr": "本研究发现，当基于Transformer的语言模型变得越来越大并且在大量数据上进行训练时，模型的惊讶估计与自然人阅读时间的适应性下降。而词频是解释这种适应性下降的关键因素，较大模型变体过度准确地预测了人群中最不频繁的词汇，而较大模型的训练过程中更准确地学习了罕见的词汇，这解释了训练数据量和模型尺寸对适应阅读时间的不利影响。",
    "en_tdlr": "This study reveals that as Transformer-based language models become larger and are trained on more data, their fit to human reading times decreases. The key factor behind this trend is word frequency, where larger models accurately predict the least frequent words in a way that impacts their fit to reading times. Additionally, larger models learn to predict rare words more accurately during training, which explains the negative effect of both training data amount and model size on their fit to reading times."
}