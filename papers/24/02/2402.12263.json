{
    "title": "Towards a tailored mixed-precision sub-8bit quantization scheme for Gated Recurrent Units using Genetic Algorithms",
    "abstract": "arXiv:2402.12263v1 Announce Type: new  Abstract: Despite the recent advances in model compression techniques for deep neural networks, deploying such models on ultra-low-power embedded devices still proves challenging. In particular, quantization schemes for Gated Recurrent Units (GRU) are difficult to tune due to their dependence on an internal state, preventing them from fully benefiting from sub-8bit quantization. In this work, we propose a modular integer quantization scheme for GRUs where the bit width of each operator can be selected independently. We then employ Genetic Algorithms (GA) to explore the vast search space of possible bit widths, simultaneously optimising for model size and accuracy. We evaluate our methods on four different sequential tasks and demonstrate that mixed-precision solutions exceed homogeneous-precision ones in terms of Pareto efficiency. In our results, we achieve a model size reduction between 25% and 55% while maintaining an accuracy comparable with t",
    "link": "https://arxiv.org/abs/2402.12263",
    "context": "Title: Towards a tailored mixed-precision sub-8bit quantization scheme for Gated Recurrent Units using Genetic Algorithms\nAbstract: arXiv:2402.12263v1 Announce Type: new  Abstract: Despite the recent advances in model compression techniques for deep neural networks, deploying such models on ultra-low-power embedded devices still proves challenging. In particular, quantization schemes for Gated Recurrent Units (GRU) are difficult to tune due to their dependence on an internal state, preventing them from fully benefiting from sub-8bit quantization. In this work, we propose a modular integer quantization scheme for GRUs where the bit width of each operator can be selected independently. We then employ Genetic Algorithms (GA) to explore the vast search space of possible bit widths, simultaneously optimising for model size and accuracy. We evaluate our methods on four different sequential tasks and demonstrate that mixed-precision solutions exceed homogeneous-precision ones in terms of Pareto efficiency. In our results, we achieve a model size reduction between 25% and 55% while maintaining an accuracy comparable with t",
    "path": "papers/24/02/2402.12263.json",
    "total_tokens": 985,
    "translated_title": "面向门控循环单元的定制混合精度低于8位量化方案的研究，使用遗传算法",
    "translated_abstract": "虽然深度神经网络模型压缩技术近年来取得了进展，但在超低功耗嵌入式设备上部署这些模型仍然具有挑战性。特别是针对门控循环单元（GRU）的量化方案很难调整，因为它们依赖于内部状态，无法充分从低于8位的量化中获益。在本研究中，我们提出了一种模块化整数量化方案，其中每个运算符的位宽可以独立选择。然后，我们采用遗传算法（GA）来探索可能位宽的庞大搜索空间，同时优化模型尺寸和准确性。我们在四个不同的顺序任务上评估了我们的方法，并表明混合精度解决方案在Pareto效率方面超过同质精度解决方案。在我们的结果中，我们实现了模型尺寸在25%至55%之间的缩减，同时保持了与t相当的准确性。",
    "tldr": "提出了面向门控循环单元的定制混合精度低于8位量化方案，使用遗传算法优化模型尺寸和准确性，在四个不同顺序任务上展示混合精度解决方案优于同质精度解决方案，实现了模型尺寸缩减25%至55%同时保持准确性。"
}