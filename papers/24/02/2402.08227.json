{
    "title": "Privacy-Preserving Language Model Inference with Instance Obfuscation",
    "abstract": "Language Models as a Service (LMaaS) offers convenient access for developers and researchers to perform inference using pre-trained language models. Nonetheless, the input data and the inference results containing private information are exposed as plaintext during the service call, leading to privacy issues. Recent studies have started tackling the privacy issue by transforming input data into privacy-preserving representation from the user-end with the techniques such as noise addition and content perturbation, while the exploration of inference result protection, namely decision privacy, is still a blank page. In order to maintain the black-box manner of LMaaS, conducting data privacy protection, especially for the decision, is a challenging task because the process has to be seamless to the models and accompanied by limited communication and computation overhead. We thus propose Instance-Obfuscated Inference (IOI) method, which focuses on addressing the decision privacy issue of na",
    "link": "https://arxiv.org/abs/2402.08227",
    "context": "Title: Privacy-Preserving Language Model Inference with Instance Obfuscation\nAbstract: Language Models as a Service (LMaaS) offers convenient access for developers and researchers to perform inference using pre-trained language models. Nonetheless, the input data and the inference results containing private information are exposed as plaintext during the service call, leading to privacy issues. Recent studies have started tackling the privacy issue by transforming input data into privacy-preserving representation from the user-end with the techniques such as noise addition and content perturbation, while the exploration of inference result protection, namely decision privacy, is still a blank page. In order to maintain the black-box manner of LMaaS, conducting data privacy protection, especially for the decision, is a challenging task because the process has to be seamless to the models and accompanied by limited communication and computation overhead. We thus propose Instance-Obfuscated Inference (IOI) method, which focuses on addressing the decision privacy issue of na",
    "path": "papers/24/02/2402.08227.json",
    "total_tokens": 888,
    "translated_title": "使用实例混淆的隐私保护语言模型推断",
    "translated_abstract": "语言模型作为一种服务（LMaaS），为开发者和研究人员提供了便利的访问方式，能够使用预训练的语言模型进行推断。然而，在服务调用过程中，输入数据和推断结果等包含私人信息的内容以明文形式暴露出来，导致了隐私问题。最近的研究开始通过从用户端开始的技术，如噪声添加和内容扰动，将输入数据转换为隐私保护的表示形式来解决隐私问题，然而推断结果的保护，即决策隐私，仍然是一个空白页。为了维持LMaaS的黑盒方式，进行数据隐私保护，尤其是对于决策的保护，是一项具有挑战性的任务，因为该过程必须对模型来说是无缝的，并伴随着有限的通信和计算开销。因此，我们提出了一种名为实例混淆推断（IOI）的方法，重点解决了决策隐私的问题。",
    "tldr": "本论文提出了一种名为实例混淆推断（IOI）的方法，该方法致力于解决语言模型推断中决策隐私问题，通过对输入数据进行转换和保护，实现了在维持模型黑盒的同时保护决策隐私。",
    "en_tdlr": "This paper proposes an approach called Instance-Obfuscated Inference (IOI) to address the decision privacy issue in language model inference, by transforming and protecting input data, it achieves the protection of decision privacy while maintaining the black-box model."
}