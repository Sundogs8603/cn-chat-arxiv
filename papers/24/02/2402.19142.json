{
    "title": "ProtoP-OD: Explainable Object Detection with Prototypical Parts",
    "abstract": "arXiv:2402.19142v1 Announce Type: cross  Abstract: Interpretation and visualization of the behavior of detection transformers tends to highlight the locations in the image that the model attends to, but it provides limited insight into the \\emph{semantics} that the model is focusing on. This paper introduces an extension to detection transformers that constructs prototypical local features and uses them in object detection. These custom features, which we call prototypical parts, are designed to be mutually exclusive and align with the classifications of the model. The proposed extension consists of a bottleneck module, the prototype neck, that computes a discretized representation of prototype activations and a new loss term that matches prototypes to object classes. This setup leads to interpretable representations in the prototype neck, allowing visual inspection of the image content perceived by the model and a better understanding of the model's reliability. We show experimentally",
    "link": "https://arxiv.org/abs/2402.19142",
    "context": "Title: ProtoP-OD: Explainable Object Detection with Prototypical Parts\nAbstract: arXiv:2402.19142v1 Announce Type: cross  Abstract: Interpretation and visualization of the behavior of detection transformers tends to highlight the locations in the image that the model attends to, but it provides limited insight into the \\emph{semantics} that the model is focusing on. This paper introduces an extension to detection transformers that constructs prototypical local features and uses them in object detection. These custom features, which we call prototypical parts, are designed to be mutually exclusive and align with the classifications of the model. The proposed extension consists of a bottleneck module, the prototype neck, that computes a discretized representation of prototype activations and a new loss term that matches prototypes to object classes. This setup leads to interpretable representations in the prototype neck, allowing visual inspection of the image content perceived by the model and a better understanding of the model's reliability. We show experimentally",
    "path": "papers/24/02/2402.19142.json",
    "total_tokens": 799,
    "translated_title": "ProtoP-OD: 具有典型部分的可解释目标检测",
    "translated_abstract": "理解和可视化检测变型器的行为往往会突出模型关注的图像位置，但对模型关注的\\emph{语义}提供有限的见解。本文介绍了一种扩展检测变压器，它构建典型的局部特征并在目标检测中使用这些特征。我们称之为典型部分的这些自定义特征旨在彼此互斥并与模型的分类一致。所提出的扩展包括一个瓶颈模块，原型颈，它计算原型激活的离散表示，并一个新的损失项，它将原型与对象类匹配。这一设置导致了原型颈中的可解释表示，允许对模型感知的图像内容进行视觉检查，并更好地理解模型的可靠性。我们通过实验证明",
    "tldr": "提出了ProtoP-OD，介绍了一种用于目标检测的可解释性扩展，通过构建典型的局部特征，提高模型对图像内容的可解释性和可靠性。"
}