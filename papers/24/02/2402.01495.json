{
    "title": "A Comparative Analysis of Conversational Large Language Models in Knowledge-Based Text Generation",
    "abstract": "Generating natural language text from graph-structured data is essential for conversational information seeking. Semantic triples derived from knowledge graphs can serve as a valuable source for grounding responses from conversational agents by providing a factual basis for the information they communicate. This is especially relevant in the context of large language models, which offer great potential for conversational interaction but are prone to hallucinating, omitting, or producing conflicting information. In this study, we conduct an empirical analysis of conversational large language models in generating natural language text from semantic triples. We compare four large language models of varying sizes with different prompting techniques. Through a series of benchmark experiments on the WebNLG dataset, we analyze the models' performance and identify the most common issues in the generated predictions. Our findings show that the capabilities of large language models in triple ver",
    "link": "https://rss.arxiv.org/abs/2402.01495",
    "context": "Title: A Comparative Analysis of Conversational Large Language Models in Knowledge-Based Text Generation\nAbstract: Generating natural language text from graph-structured data is essential for conversational information seeking. Semantic triples derived from knowledge graphs can serve as a valuable source for grounding responses from conversational agents by providing a factual basis for the information they communicate. This is especially relevant in the context of large language models, which offer great potential for conversational interaction but are prone to hallucinating, omitting, or producing conflicting information. In this study, we conduct an empirical analysis of conversational large language models in generating natural language text from semantic triples. We compare four large language models of varying sizes with different prompting techniques. Through a series of benchmark experiments on the WebNLG dataset, we analyze the models' performance and identify the most common issues in the generated predictions. Our findings show that the capabilities of large language models in triple ver",
    "path": "papers/24/02/2402.01495.json",
    "total_tokens": 747,
    "translated_title": "知识图生成对话式自然语言文本的比较分析",
    "translated_abstract": "从图结构数据中生成自然语言文本对于会话式信息搜索至关重要。从知识图中获得的语义三元组可以作为对话代理回应的基础，通过提供事实依据来传达信息。这在大型语言模型的背景下尤为重要，大型语言模型具有很大的会话交互潜力，但容易产生幻象、省略或产生冲突信息。在本研究中，我们对会话式大型语言模型在从语义三元组生成自然语言文本方面进行了实证分析。我们比较了四个不同大小的大型语言模型和不同启发式技术。通过在WebNLG数据集上进行一系列基准实验，我们分析了模型的性能，并确定了生成的预测中最常见的问题。我们的研究结果表明，大型语言模型在三元组验证",
    "tldr": "本研究对比了四个不同大小的大型语言模型在从语义三元组生成自然语言文本方面的性能，并发现了生成预测中最常见的问题。"
}