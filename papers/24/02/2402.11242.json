{
    "title": "Learning with Imbalanced Noisy Data by Preventing Bias in Sample Selection",
    "abstract": "arXiv:2402.11242v1 Announce Type: cross  Abstract: Learning with noisy labels has gained increasing attention because the inevitable imperfect labels in real-world scenarios can substantially hurt the deep model performance. Recent studies tend to regard low-loss samples as clean ones and discard high-loss ones to alleviate the negative impact of noisy labels. However, real-world datasets contain not only noisy labels but also class imbalance. The imbalance issue is prone to causing failure in the loss-based sample selection since the under-learning of tail classes also leans to produce high losses. To this end, we propose a simple yet effective method to address noisy labels in imbalanced datasets. Specifically, we propose Class-Balance-based sample Selection (CBS) to prevent the tail class samples from being neglected during training. We propose Confidence-based Sample Augmentation (CSA) for the chosen clean samples to enhance their reliability in the training process. To exploit sel",
    "link": "https://arxiv.org/abs/2402.11242",
    "context": "Title: Learning with Imbalanced Noisy Data by Preventing Bias in Sample Selection\nAbstract: arXiv:2402.11242v1 Announce Type: cross  Abstract: Learning with noisy labels has gained increasing attention because the inevitable imperfect labels in real-world scenarios can substantially hurt the deep model performance. Recent studies tend to regard low-loss samples as clean ones and discard high-loss ones to alleviate the negative impact of noisy labels. However, real-world datasets contain not only noisy labels but also class imbalance. The imbalance issue is prone to causing failure in the loss-based sample selection since the under-learning of tail classes also leans to produce high losses. To this end, we propose a simple yet effective method to address noisy labels in imbalanced datasets. Specifically, we propose Class-Balance-based sample Selection (CBS) to prevent the tail class samples from being neglected during training. We propose Confidence-based Sample Augmentation (CSA) for the chosen clean samples to enhance their reliability in the training process. To exploit sel",
    "path": "papers/24/02/2402.11242.json",
    "total_tokens": 894,
    "translated_title": "通过防止样本选择偏差来学习不平衡嘈杂数据",
    "translated_abstract": "学习具有嘈杂标签的方法引起了越来越多的关注，因为现实场景中不可避免的不完美标签会严重影响深度模型的性能。最近的研究倾向于将低损失样本视为干净样本，丢弃高损失样本以减轻嘈杂标签的负面影响。然而，现实世界的数据集不仅包含嘈杂标签，还包含类别不平衡。不平衡问题容易导致损失较大的尾部类别的学习不足，从而产生高损失。因此，我们提出了一种简单而有效的方法来处理不平衡数据中的嘈杂标签。具体来说，我们提出了基于类平衡的样本选择（CBS）来防止在训练过程中忽视尾部类别样本。我们提出了基于置信度的样本增强（CSA）以加强所选干净样本在训练过程中的可靠性。",
    "tldr": "提出了一种用于处理不平衡数据中嘈杂标签的方法，通过Class-Balance-based Sample Selection (CBS)防止忽视尾部类别样本，并通过Confidence-based Sample Augmentation (CSA)增强干净样本的可靠性。"
}