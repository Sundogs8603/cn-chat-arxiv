{
    "title": "Can Large Language Models Understand Context?",
    "abstract": "Understanding context is key to understanding human language, an ability which Large Language Models (LLMs) have been increasingly seen to demonstrate to an impressive extent. However, though the evaluation of LLMs encompasses various domains within the realm of Natural Language Processing, limited attention has been paid to probing their linguistic capability of understanding contextual features. This paper introduces a context understanding benchmark by adapting existing datasets to suit the evaluation of generative models. This benchmark comprises of four distinct tasks and nine datasets, all featuring prompts designed to assess the models' ability to understand context. First, we evaluate the performance of LLMs under the in-context learning pretraining scenario. Experimental results indicate that pre-trained dense models struggle with understanding more nuanced contextual features when compared to state-of-the-art fine-tuned models. Second, as LLM compression holds growing signifi",
    "link": "https://rss.arxiv.org/abs/2402.00858",
    "context": "Title: Can Large Language Models Understand Context?\nAbstract: Understanding context is key to understanding human language, an ability which Large Language Models (LLMs) have been increasingly seen to demonstrate to an impressive extent. However, though the evaluation of LLMs encompasses various domains within the realm of Natural Language Processing, limited attention has been paid to probing their linguistic capability of understanding contextual features. This paper introduces a context understanding benchmark by adapting existing datasets to suit the evaluation of generative models. This benchmark comprises of four distinct tasks and nine datasets, all featuring prompts designed to assess the models' ability to understand context. First, we evaluate the performance of LLMs under the in-context learning pretraining scenario. Experimental results indicate that pre-trained dense models struggle with understanding more nuanced contextual features when compared to state-of-the-art fine-tuned models. Second, as LLM compression holds growing signifi",
    "path": "papers/24/02/2402.00858.json",
    "total_tokens": 942,
    "translated_title": "大型语言模型能否理解上下文？",
    "translated_abstract": "理解上下文对于理解人类语言至关重要，大型语言模型（LLMs）已经展示出了令人印象深刻的理解能力。然而，尽管LLMs的评估涵盖了自然语言处理领域的各个领域，但对于探索其理解上下文特征的语言能力的关注有限。本文通过调整现有数据集以适应生成模型的评估，引入了一个上下文理解基准。该基准包括四个不同的任务和九个数据集，其中所有的提示都设计用于评估模型理解上下文的能力。首先，我们评估了在上下文学习预训练场景下LLMs的性能。实验结果表明，与最先进的微调模型相比，预训练的密集模型在理解更微妙的上下文特征方面存在困难。其次，由于LLM压缩越来越重要，我们评估了压缩模型在上下文理解任务上的性能。实验结果显示，通过压缩方法，可以在明显减少模型尺寸的同时维持相对较高的上下文理解能力。",
    "tldr": "本文提出了一个上下文理解基准，通过适应现有数据集以评估生成模型的理解上下文能力。实验结果表明，预训练的密集模型在理解更微妙的上下文特征方面存在困难，并且通过压缩方法可以在减小模型尺寸的同时保持相对较高的上下文理解能力。",
    "en_tdlr": "This paper introduces a context understanding benchmark for evaluating generative models' ability to understand context. Experimental results indicate that pre-trained dense models struggle with understanding more nuanced contextual features, and compressing the models can maintain relatively high context understanding capability while reducing model size."
}