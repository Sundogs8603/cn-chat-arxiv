{
    "title": "Set the Clock: Temporal Alignment of Pretrained Language Models",
    "abstract": "arXiv:2402.16797v1 Announce Type: new  Abstract: Language models (LMs) are trained on web text originating from many points in time and, in general, without any explicit temporal grounding. This work investigates the temporal chaos of pretrained LMs and explores various methods to align their internal knowledge to a target time, which we call \"temporal alignment.\" To do this, we first automatically construct a dataset containing 20K time-sensitive questions and their answers for each year from 2000 to 2023. Based on this dataset, we empirically show that pretrained LMs (e.g., LLaMa2), despite having a recent pretraining cutoff (e.g., 2022), mostly answer questions using earlier knowledge (e.g., in 2019). We then develop several methods, from prompting to finetuning, to align LMs to use their most recent knowledge when answering questions, and investigate various factors in this alignment. Our experiments show that aligning LLaMa2 to the year 2022 can boost its performance by up to 62% ",
    "link": "https://arxiv.org/abs/2402.16797",
    "context": "Title: Set the Clock: Temporal Alignment of Pretrained Language Models\nAbstract: arXiv:2402.16797v1 Announce Type: new  Abstract: Language models (LMs) are trained on web text originating from many points in time and, in general, without any explicit temporal grounding. This work investigates the temporal chaos of pretrained LMs and explores various methods to align their internal knowledge to a target time, which we call \"temporal alignment.\" To do this, we first automatically construct a dataset containing 20K time-sensitive questions and their answers for each year from 2000 to 2023. Based on this dataset, we empirically show that pretrained LMs (e.g., LLaMa2), despite having a recent pretraining cutoff (e.g., 2022), mostly answer questions using earlier knowledge (e.g., in 2019). We then develop several methods, from prompting to finetuning, to align LMs to use their most recent knowledge when answering questions, and investigate various factors in this alignment. Our experiments show that aligning LLaMa2 to the year 2022 can boost its performance by up to 62% ",
    "path": "papers/24/02/2402.16797.json",
    "total_tokens": 902,
    "translated_title": "设定时间：预训练语言模型的时间对齐",
    "translated_abstract": "语言模型（LMs）在来自不同时间点的网络文本上进行训练，通常没有任何明确的时间基础。本研究调查了预训练LMs的时间混乱，并探讨了将它们的内部知识对齐到目标时间的各种方法，我们称之为“时间对齐”。为此，我们首先自动构建了一个包含20K个时态问题及其答案的数据集，涵盖从2000年到2023年的每一年。根据这个数据集，我们在实践中表明，预训练的LMs（例如LLaMa2），尽管有最近的预训练截止日期（例如2022年），大多数使用更早的知识来回答问题（例如在2019年）。然后，我们开发了几种方法，从提示到微调，来对齐LMs在回答问题时使用最新的知识，并探讨了这种对齐中的各种因素。我们的实验证明，将LLaMa2对齐到2022年可以将其性能提高高达62%",
    "tldr": "该研究探讨了预训练语言模型的时间混乱问题，并提出了时间对齐的方法，实验证明将LMs对齐到最近时间可以显著提高性能",
    "en_tdlr": "This study investigates the temporal chaos of pretrained language models and proposes methods for temporal alignment, with experiments showing significant performance improvements by aligning LMs to the most recent time."
}