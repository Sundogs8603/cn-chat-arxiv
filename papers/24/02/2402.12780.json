{
    "title": "Tackling Byzantine Clients in Federated Learning",
    "abstract": "arXiv:2402.12780v1 Announce Type: new  Abstract: The possibility of adversarial (a.k.a., {\\em Byzantine}) clients makes federated learning (FL) prone to arbitrary manipulation. The natural approach to robustify FL against adversarial clients is to replace the simple averaging operation at the server in the standard $\\mathsf{FedAvg}$ algorithm by a \\emph{robust averaging rule}. While a significant amount of work has been devoted to studying the convergence of federated {\\em robust averaging} (which we denote by $\\mathsf{FedRo}$), prior work has largely ignored the impact of {\\em client subsampling} and {\\em local steps}, two fundamental FL characteristics. While client subsampling increases the effective fraction of Byzantine clients, local steps increase the drift between the local updates computed by honest (i.e., non-Byzantine) clients. Consequently, a careless deployment of $\\mathsf{FedRo}$ could yield poor performance. We validate this observation by presenting an in-depth analysis",
    "link": "https://arxiv.org/abs/2402.12780",
    "context": "Title: Tackling Byzantine Clients in Federated Learning\nAbstract: arXiv:2402.12780v1 Announce Type: new  Abstract: The possibility of adversarial (a.k.a., {\\em Byzantine}) clients makes federated learning (FL) prone to arbitrary manipulation. The natural approach to robustify FL against adversarial clients is to replace the simple averaging operation at the server in the standard $\\mathsf{FedAvg}$ algorithm by a \\emph{robust averaging rule}. While a significant amount of work has been devoted to studying the convergence of federated {\\em robust averaging} (which we denote by $\\mathsf{FedRo}$), prior work has largely ignored the impact of {\\em client subsampling} and {\\em local steps}, two fundamental FL characteristics. While client subsampling increases the effective fraction of Byzantine clients, local steps increase the drift between the local updates computed by honest (i.e., non-Byzantine) clients. Consequently, a careless deployment of $\\mathsf{FedRo}$ could yield poor performance. We validate this observation by presenting an in-depth analysis",
    "path": "papers/24/02/2402.12780.json",
    "total_tokens": 721,
    "translated_title": "处理联邦学习中的拜占庭客户问题",
    "translated_abstract": "通过替换标准$\\mathsf{FedAvg}$算法中服务器端的简单平均操作为\\emph{鲁棒平均规则}来使联邦学习(FL)抵御拜占庭式(adversarial)客户的可能性。 先前的研究大部分忽略了\\emph{客户子采样}和\\emph{本地步骤}对FL特性的影响。我们通过展示深入分析来验证这一观察。",
    "tldr": "研究通过引入鲁棒平均规则来抵御联邦学习中的拜占庭式客户，同时强调客户子采样和本地步骤对模型性能的重要影响。",
    "en_tdlr": "The study addresses adversarial clients in federated learning by introducing a robust averaging rule, highlighting the significant impact of client subsampling and local steps on model performance."
}