{
    "title": "Probabilistic Lipschitzness and the Stable Rank for Comparing Explanation Models",
    "abstract": "arXiv:2402.18863v1 Announce Type: new  Abstract: Explainability models are now prevalent within machine learning to address the black-box nature of neural networks. The question now is which explainability model is most effective. Probabilistic Lipschitzness has demonstrated that the smoothness of a neural network is fundamentally linked to the quality of post hoc explanations. In this work, we prove theoretical lower bounds on the probabilistic Lipschitzness of Integrated Gradients, LIME and SmoothGrad. We propose a novel metric using probabilistic Lipschitzness, normalised astuteness, to compare the robustness of explainability models. Further, we prove a link between the local Lipschitz constant of a neural network and its stable rank. We then demonstrate that the stable rank of a neural network provides a heuristic for the robustness of explainability models.",
    "link": "https://arxiv.org/abs/2402.18863",
    "context": "Title: Probabilistic Lipschitzness and the Stable Rank for Comparing Explanation Models\nAbstract: arXiv:2402.18863v1 Announce Type: new  Abstract: Explainability models are now prevalent within machine learning to address the black-box nature of neural networks. The question now is which explainability model is most effective. Probabilistic Lipschitzness has demonstrated that the smoothness of a neural network is fundamentally linked to the quality of post hoc explanations. In this work, we prove theoretical lower bounds on the probabilistic Lipschitzness of Integrated Gradients, LIME and SmoothGrad. We propose a novel metric using probabilistic Lipschitzness, normalised astuteness, to compare the robustness of explainability models. Further, we prove a link between the local Lipschitz constant of a neural network and its stable rank. We then demonstrate that the stable rank of a neural network provides a heuristic for the robustness of explainability models.",
    "path": "papers/24/02/2402.18863.json",
    "total_tokens": 749,
    "translated_title": "概率Lipschitz性和稳定秩用于比较解释模型",
    "translated_abstract": "解释性模型如今在机器学习中广泛应用，以解决神经网络的黑盒特性。现在的问题是哪种解释性模型最有效。概率Lipschitz性表明神经网络的平滑性与事后解释的质量基本相关。本文在对Integrated Gradients、LIME和SmoothGrad的概率Lipschitzness进行理论下限证明的基础上，提出了一种新的度量标准，使用概率Lipschitz性和归一化的聪明度来比较解释性模型的稳健性。此外，我们证明了神经网络的局部Lipschitz常数与其稳定秩之间的联系。然后我们证明神经网络的稳定秩提供了解释性模型稳健性的一种启发式方法。",
    "tldr": "概率Lipschitz性与稳定秩的研究为比较解释模型提供了新的角度和度量标准。"
}