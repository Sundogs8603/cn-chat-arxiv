{
    "title": "Debiased Offline Representation Learning for Fast Online Adaptation in Non-stationary Dynamics",
    "abstract": "arXiv:2402.11317v1 Announce Type: cross  Abstract: Developing policies that can adjust to non-stationary environments is essential for real-world reinforcement learning applications. However, learning such adaptable policies in offline settings, with only a limited set of pre-collected trajectories, presents significant challenges. A key difficulty arises because the limited offline data makes it hard for the context encoder to differentiate between changes in the environment dynamics and shifts in the behavior policy, often leading to context misassociations. To address this issue, we introduce a novel approach called Debiased Offline Representation for fast online Adaptation (DORA). DORA incorporates an information bottleneck principle that maximizes mutual information between the dynamics encoding and the environmental data, while minimizing mutual information between the dynamics encoding and the actions of the behavior policy. We present a practical implementation of DORA, leverag",
    "link": "https://arxiv.org/abs/2402.11317",
    "context": "Title: Debiased Offline Representation Learning for Fast Online Adaptation in Non-stationary Dynamics\nAbstract: arXiv:2402.11317v1 Announce Type: cross  Abstract: Developing policies that can adjust to non-stationary environments is essential for real-world reinforcement learning applications. However, learning such adaptable policies in offline settings, with only a limited set of pre-collected trajectories, presents significant challenges. A key difficulty arises because the limited offline data makes it hard for the context encoder to differentiate between changes in the environment dynamics and shifts in the behavior policy, often leading to context misassociations. To address this issue, we introduce a novel approach called Debiased Offline Representation for fast online Adaptation (DORA). DORA incorporates an information bottleneck principle that maximizes mutual information between the dynamics encoding and the environmental data, while minimizing mutual information between the dynamics encoding and the actions of the behavior policy. We present a practical implementation of DORA, leverag",
    "path": "papers/24/02/2402.11317.json",
    "total_tokens": 781,
    "translated_title": "针对非静态动态的快速在线调整的去偏置离线表示学习",
    "translated_abstract": "开发能够适应非静态环境的策略对于现实世界的强化学习应用至关重要。然而，在仅有一组有限的预先收集的轨迹的离线设置中学习这种适应性策略存在显著挑战。为了解决这个问题，我们引入了一种名为去偏置离线表示快速在线调整（DORA）的新方法。DORA融入了信息瓶颈原理，最大化了动态编码与环境数据之间的互信息，同时最小化了动态编码与行为策略的互信息。我们提出了DORA的实际实现，利用",
    "tldr": "提出了一种名为DORA的新方法，通过信息瓶颈原理在离线设置中学习适应性策略，解决了动态编码与环境数据之间的互信息与与行为策略的互信息之间的难题",
    "en_tdlr": "Introduced a new approach named DORA that addresses the challenge of learning adaptable policies in offline settings by maximizing mutual information between the dynamics encoding and the environmental data, while minimizing mutual information between the dynamics encoding and the actions of the behavior policy."
}