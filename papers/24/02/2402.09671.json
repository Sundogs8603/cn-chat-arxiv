{
    "title": "Exploiting Alpha Transparency In Language And Vision-Based AI Systems",
    "abstract": "arXiv:2402.09671v1 Announce Type: cross  Abstract: This investigation reveals a novel exploit derived from PNG image file formats, specifically their alpha transparency layer, and its potential to fool multiple AI vision systems. Our method uses this alpha layer as a clandestine channel invisible to human observers but fully actionable by AI image processors. The scope tested for the vulnerability spans representative vision systems from Apple, Microsoft, Google, Salesforce, Nvidia, and Facebook, highlighting the attack's potential breadth. This vulnerability challenges the security protocols of existing and fielded vision systems, from medical imaging to autonomous driving technologies. Our experiments demonstrate that the affected systems, which rely on convolutional neural networks or the latest multimodal language models, cannot quickly mitigate these vulnerabilities through simple patches or updates. Instead, they require retraining and architectural changes, indicating a persiste",
    "link": "https://arxiv.org/abs/2402.09671",
    "context": "Title: Exploiting Alpha Transparency In Language And Vision-Based AI Systems\nAbstract: arXiv:2402.09671v1 Announce Type: cross  Abstract: This investigation reveals a novel exploit derived from PNG image file formats, specifically their alpha transparency layer, and its potential to fool multiple AI vision systems. Our method uses this alpha layer as a clandestine channel invisible to human observers but fully actionable by AI image processors. The scope tested for the vulnerability spans representative vision systems from Apple, Microsoft, Google, Salesforce, Nvidia, and Facebook, highlighting the attack's potential breadth. This vulnerability challenges the security protocols of existing and fielded vision systems, from medical imaging to autonomous driving technologies. Our experiments demonstrate that the affected systems, which rely on convolutional neural networks or the latest multimodal language models, cannot quickly mitigate these vulnerabilities through simple patches or updates. Instead, they require retraining and architectural changes, indicating a persiste",
    "path": "papers/24/02/2402.09671.json",
    "total_tokens": 893,
    "translated_title": "利用语言和视觉AI系统中的Alpha透明性的探索",
    "translated_abstract": "这项研究揭示了一种新颖的利用PNG图像文件格式的漏洞，具体是它们的alpha透明层，并且展示了这个漏洞对多个AI视觉系统的欺骗潜力。我们的方法利用这个alpha透明层作为一个对人类观察者不可见但完全可操作的秘密通道来欺骗AI图像处理器。受漏洞测试的范围包括苹果、微软、谷歌、Salesforce、Nvidia和Facebook等代表性视觉系统，突显了攻击的潜在广度。这个漏洞对现有的和实际应用的视觉系统提出了安全协议的挑战，从医学成像到自动驾驶技术。我们的实验表明，受到影响的系统，无论是依赖卷积神经网络还是最新的多模态语言模型，都不能通过简单的补丁或更新快速地缓解这些漏洞。相反，它们需要重新训练和架构变化，表明这些漏洞是持久的。",
    "tldr": "这项研究揭示了利用PNG图像文件格式中的alpha透明层欺骗AI视觉系统的新漏洞，对现有的和实际应用的视觉系统提出了挑战。",
    "en_tdlr": "This investigation reveals a novel exploit derived from the alpha transparency layer in PNG image files, allowing for deception of AI vision systems. The vulnerability poses a challenge to existing and fielded vision systems, highlighting the need for retraining and architectural changes."
}