{
    "title": "UMAIR-FPS: User-aware Multi-modal Animation Illustration Recommendation Fusion with Painting Style",
    "abstract": "arXiv:2402.10381v1 Announce Type: cross  Abstract: The rapid advancement of high-quality image generation models based on AI has generated a deluge of anime illustrations. Recommending illustrations to users within massive data has become a challenging and popular task. However, existing anime recommendation systems have focused on text features but still need to integrate image features. In addition, most multi-modal recommendation research is constrained by tightly coupled datasets, limiting its applicability to anime illustrations. We propose the User-aware Multi-modal Animation Illustration Recommendation Fusion with Painting Style (UMAIR-FPS) to tackle these gaps. In the feature extract phase, for image features, we are the first to combine image painting style features with semantic features to construct a dual-output image encoder for enhancing representation. For text features, we obtain text embeddings based on fine-tuning Sentence-Transformers by incorporating domain knowledg",
    "link": "https://arxiv.org/abs/2402.10381",
    "context": "Title: UMAIR-FPS: User-aware Multi-modal Animation Illustration Recommendation Fusion with Painting Style\nAbstract: arXiv:2402.10381v1 Announce Type: cross  Abstract: The rapid advancement of high-quality image generation models based on AI has generated a deluge of anime illustrations. Recommending illustrations to users within massive data has become a challenging and popular task. However, existing anime recommendation systems have focused on text features but still need to integrate image features. In addition, most multi-modal recommendation research is constrained by tightly coupled datasets, limiting its applicability to anime illustrations. We propose the User-aware Multi-modal Animation Illustration Recommendation Fusion with Painting Style (UMAIR-FPS) to tackle these gaps. In the feature extract phase, for image features, we are the first to combine image painting style features with semantic features to construct a dual-output image encoder for enhancing representation. For text features, we obtain text embeddings based on fine-tuning Sentence-Transformers by incorporating domain knowledg",
    "path": "papers/24/02/2402.10381.json",
    "total_tokens": 848,
    "translated_title": "UMAIR-FPS：带绘画风格的用户感知多模态动画插画推荐融合",
    "translated_abstract": "高质量基于人工智能的图像生成模型的快速进步产生了大量的动漫插画。在海量数据中向用户推荐插画已成为一项具有挑战性和受欢迎的任务。然而，现有的动漫推荐系统侧重于文本特征，但仍需要整合图像特征。此外，大多数多模态推荐研究受到紧密耦合数据集的限制，限制了其对动漫插画的适用性。我们提出了带绘画风格的用户感知多模态动画插画推荐融合（UMAIR-FPS）来解决这些问题。在特征提取阶段，对于图像特征，我们首次结合图像绘画风格特征与语义特征来构建双输出图像编码器以增强表示。对于文本特征，我们基于Fine-tuning Sentence-Transformers获得文本嵌入，通过整合领域知识",
    "tldr": "UMAIR-FPS提出了一种新的用户感知多模态动画插画推荐系统，通过融合图像绘画风格特征和语义特征来增强表示。",
    "en_tdlr": "UMAIR-FPS proposes a novel user-aware multi-modal animation illustration recommendation system that enhances representation by fusing image painting style features and semantic features."
}