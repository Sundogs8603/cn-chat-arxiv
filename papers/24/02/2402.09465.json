{
    "title": "RLEEGNet: Integrating Brain-Computer Interfaces with Adaptive AI for Intuitive Responsiveness and High-Accuracy Motor Imagery Classification",
    "abstract": "arXiv:2402.09465v1 Announce Type: cross  Abstract: Current approaches to prosthetic control are limited by their reliance on traditional methods, which lack real-time adaptability and intuitive responsiveness. These limitations are particularly pronounced in assistive technologies designed for individuals with diverse cognitive states and motor intentions. In this paper, we introduce a framework that leverages Reinforcement Learning (RL) with Deep Q-Networks (DQN) for classification tasks. Additionally, we present a preprocessing technique using the Common Spatial Pattern (CSP) for multiclass motor imagery (MI) classification in a One-Versus-The-Rest (OVR) manner. The subsequent 'csp space' transformation retains the temporal dimension of EEG signals, crucial for extracting discriminative features. The integration of DQN with a 1D-CNN-LSTM architecture optimizes the decision-making process in real-time, thereby enhancing the system's adaptability to the user's evolving needs and intent",
    "link": "https://arxiv.org/abs/2402.09465",
    "context": "Title: RLEEGNet: Integrating Brain-Computer Interfaces with Adaptive AI for Intuitive Responsiveness and High-Accuracy Motor Imagery Classification\nAbstract: arXiv:2402.09465v1 Announce Type: cross  Abstract: Current approaches to prosthetic control are limited by their reliance on traditional methods, which lack real-time adaptability and intuitive responsiveness. These limitations are particularly pronounced in assistive technologies designed for individuals with diverse cognitive states and motor intentions. In this paper, we introduce a framework that leverages Reinforcement Learning (RL) with Deep Q-Networks (DQN) for classification tasks. Additionally, we present a preprocessing technique using the Common Spatial Pattern (CSP) for multiclass motor imagery (MI) classification in a One-Versus-The-Rest (OVR) manner. The subsequent 'csp space' transformation retains the temporal dimension of EEG signals, crucial for extracting discriminative features. The integration of DQN with a 1D-CNN-LSTM architecture optimizes the decision-making process in real-time, thereby enhancing the system's adaptability to the user's evolving needs and intent",
    "path": "papers/24/02/2402.09465.json",
    "total_tokens": 943,
    "translated_title": "RLEEGNet：将脑机接口与自适应人工智能结合，实现直观响应和高准确率的动作意象分类",
    "translated_abstract": "目前的假肢控制方法受传统方法的限制，缺乏实时适应性和直观响应能力，尤其在面对认知状态和运动意图多样的辅助技术时表现更为明显。本文介绍了一种利用强化学习（RL）与深度Q网络（DQN）进行分类任务的框架。此外，我们还提出了一种使用常空模式（CSP）进行多类动作意像（MI）分类的预处理技术，以\"一对其余（OVR）\"的方式进行分类。随后的“csp空间”转换保留了EEG信号的时间维度，对提取区分特征至关重要。DQN与1D-CNN-LSTM结构的集成在实时决策过程中优化了系统对用户不断变化的需求和意图的适应能力。",
    "tldr": "本文提出了RLEEGNet，这是一种将脑机接口与自适应人工智能结合的框架，能够实现直观响应和高准确率的动作意象分类。通过使用强化学习和深度Q网络进行分类任务，并结合常空模式预处理技术，该框架能够实时适应用户不断变化的需求和意图。",
    "en_tdlr": "This paper introduces RLEEGNet, a framework that integrates brain-computer interfaces with adaptive AI for intuitive responsiveness and high-accuracy motor imagery classification. By leveraging reinforcement learning and deep Q-networks for classification tasks, and incorporating common spatial pattern preprocessing technique, the framework is able to adapt in real-time to the user's evolving needs and intentions."
}