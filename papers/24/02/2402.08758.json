{
    "title": "Bayesian Strategic Classification",
    "abstract": "arXiv:2402.08758v1 Announce Type: new Abstract: In strategic classification, agents modify their features, at a cost, to ideally obtain a positive classification from the learner's classifier. The typical response of the learner is to carefully modify their classifier to be robust to such strategic behavior. When reasoning about agent manipulations, most papers that study strategic classification rely on the following strong assumption: agents fully know the exact parameters of the deployed classifier by the learner. This often is an unrealistic assumption when using complex or proprietary machine learning techniques in real-world prediction tasks.   We initiate the study of partial information release by the learner in strategic classification. We move away from the traditional assumption that agents have full knowledge of the classifier. Instead, we consider agents that have a common distributional prior on which classifier the learner is using. The learner in our model can reveal tr",
    "link": "https://arxiv.org/abs/2402.08758",
    "context": "Title: Bayesian Strategic Classification\nAbstract: arXiv:2402.08758v1 Announce Type: new Abstract: In strategic classification, agents modify their features, at a cost, to ideally obtain a positive classification from the learner's classifier. The typical response of the learner is to carefully modify their classifier to be robust to such strategic behavior. When reasoning about agent manipulations, most papers that study strategic classification rely on the following strong assumption: agents fully know the exact parameters of the deployed classifier by the learner. This often is an unrealistic assumption when using complex or proprietary machine learning techniques in real-world prediction tasks.   We initiate the study of partial information release by the learner in strategic classification. We move away from the traditional assumption that agents have full knowledge of the classifier. Instead, we consider agents that have a common distributional prior on which classifier the learner is using. The learner in our model can reveal tr",
    "path": "papers/24/02/2402.08758.json",
    "total_tokens": 732,
    "translated_title": "贝叶斯战略分类",
    "translated_abstract": "在战略分类中，代理者通过修改特征，在一定成本下，希望从学习者的分类器中得到正面分类。学习者通常会小心地修改他们的分类器，以便对代理者的战略行为具有鲁棒性。大多数研究战略分类的论文在考虑代理者操纵时依赖于以下强假设：代理者完全了解学习者所使用的分类器的确切参数。当在真实预测任务中使用复杂或专有的机器学习技术时，这通常是不现实的假设。",
    "tldr": "本研究从学习者部分信息公开的角度研究了战略分类，不再假设代理者完全了解分类器的参数，而是考虑代理者对学习者所使用的分类器有一个共同的分布先验。",
    "en_tdlr": "This paper introduces the concept of partial information release in strategic classification, moving away from the assumption that agents have full knowledge of the classifier. Instead, agents are considered to have a common distributional prior on which classifier the learner is using."
}