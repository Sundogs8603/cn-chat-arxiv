{
    "title": "Scaling Supervised Local Learning with Augmented Auxiliary Networks",
    "abstract": "arXiv:2402.17318v1 Announce Type: cross  Abstract: Deep neural networks are typically trained using global error signals that backpropagate (BP) end-to-end, which is not only biologically implausible but also suffers from the update locking problem and requires huge memory consumption. Local learning, which updates each layer independently with a gradient-isolated auxiliary network, offers a promising alternative to address the above problems. However, existing local learning methods are confronted with a large accuracy gap with the BP counterpart, particularly for large-scale networks. This is due to the weak coupling between local layers and their subsequent network layers, as there is no gradient communication across layers. To tackle this issue, we put forward an augmented local learning method, dubbed AugLocal. AugLocal constructs each hidden layer's auxiliary network by uniformly selecting a small subset of layers from its subsequent network layers to enhance their synergy. We al",
    "link": "https://arxiv.org/abs/2402.17318",
    "context": "Title: Scaling Supervised Local Learning with Augmented Auxiliary Networks\nAbstract: arXiv:2402.17318v1 Announce Type: cross  Abstract: Deep neural networks are typically trained using global error signals that backpropagate (BP) end-to-end, which is not only biologically implausible but also suffers from the update locking problem and requires huge memory consumption. Local learning, which updates each layer independently with a gradient-isolated auxiliary network, offers a promising alternative to address the above problems. However, existing local learning methods are confronted with a large accuracy gap with the BP counterpart, particularly for large-scale networks. This is due to the weak coupling between local layers and their subsequent network layers, as there is no gradient communication across layers. To tackle this issue, we put forward an augmented local learning method, dubbed AugLocal. AugLocal constructs each hidden layer's auxiliary network by uniformly selecting a small subset of layers from its subsequent network layers to enhance their synergy. We al",
    "path": "papers/24/02/2402.17318.json",
    "total_tokens": 713,
    "translated_title": "通过增强的辅助网络扩展监督本地学习",
    "translated_abstract": "深度神经网络通常使用全局误差信号进行端到端反向传播（BP）进行训练，这既不符合生物学实际，也存在更新锁定问题，并且需要大量内存消耗。本文提出了一种增强的本地学习方法，称为AugLocal。AugLocal通过从其后续网络层中均匀选择一小部分层来构建每个隐藏层的辅助网络，以增强它们的协同作用。",
    "tldr": "本文提出了一种增强的本地学习方法AugLocal，通过构建辅助网络来增强各隐藏层之间的协同作用，从而解决了本地学习方法在大规模网络中与BP方法之间存在的精度差距问题。",
    "en_tdlr": "This paper introduces an enhanced local learning method AugLocal, which constructs auxiliary networks to enhance the synergy between each hidden layer, addressing the accuracy gap issue between local learning methods and BP methods in large-scale networks."
}