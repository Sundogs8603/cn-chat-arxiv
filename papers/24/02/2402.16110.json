{
    "title": "Disentangled Graph Variational Auto-Encoder for Multimodal Recommendation with Interpretability",
    "abstract": "arXiv:2402.16110v1 Announce Type: new  Abstract: Multimodal recommender systems amalgamate multimodal information (e.g., textual descriptions, images) into a collaborative filtering framework to provide more accurate recommendations. While the incorporation of multimodal information could enhance the interpretability of these systems, current multimodal models represent users and items utilizing entangled numerical vectors, rendering them arduous to interpret. To address this, we propose a Disentangled Graph Variational Auto-Encoder (DGVAE) that aims to enhance both model and recommendation interpretability. DGVAE initially projects multimodal information into textual contents, such as converting images to text, by harnessing state-of-the-art multimodal pre-training technologies. It then constructs a frozen item-item graph and encodes the contents and interactions into two sets of disentangled representations utilizing a simplified residual graph convolutional network. DGVAE further re",
    "link": "https://arxiv.org/abs/2402.16110",
    "context": "Title: Disentangled Graph Variational Auto-Encoder for Multimodal Recommendation with Interpretability\nAbstract: arXiv:2402.16110v1 Announce Type: new  Abstract: Multimodal recommender systems amalgamate multimodal information (e.g., textual descriptions, images) into a collaborative filtering framework to provide more accurate recommendations. While the incorporation of multimodal information could enhance the interpretability of these systems, current multimodal models represent users and items utilizing entangled numerical vectors, rendering them arduous to interpret. To address this, we propose a Disentangled Graph Variational Auto-Encoder (DGVAE) that aims to enhance both model and recommendation interpretability. DGVAE initially projects multimodal information into textual contents, such as converting images to text, by harnessing state-of-the-art multimodal pre-training technologies. It then constructs a frozen item-item graph and encodes the contents and interactions into two sets of disentangled representations utilizing a simplified residual graph convolutional network. DGVAE further re",
    "path": "papers/24/02/2402.16110.json",
    "total_tokens": 767,
    "translated_title": "多模态推荐的解缠结图变分自编码器与可解释性",
    "translated_abstract": "多模态推荐系统将多模态信息（例如文本描述、图像）融合到协同过滤框架中，以提供更准确的推荐。然而，当前的多模态模型通过纠缠的数值向量表示用户和商品，使其难以解释。为了解决这个问题，我们提出了一种旨在增强模型和推荐可解释性的解缠结图变分自编码器（DGVAE）。DGVAE首先利用最先进的多模态预训练技术将多模态信息投影到文本内容中，例如将图像转换为文本。然后，它构建一个冻结的商品-商品图，并利用简化的残余图卷积网络将内容和交互编码成两组解缠表示。DGVAE进一步...",
    "tldr": "提出了一种解缠结图变分自编码器（DGVAE），旨在增强多模态推荐系统的模型和推荐可解释性。"
}