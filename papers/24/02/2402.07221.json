{
    "title": "The Reasons that Agents Act: Intention and Instrumental Goals",
    "abstract": "Intention is an important and challenging concept in AI. It is important because it underlies many other concepts we care about, such as agency, manipulation, legal responsibility, and blame. However, ascribing intent to AI systems is contentious, and there is no universally accepted theory of intention applicable to AI agents. We operationalise the intention with which an agent acts, relating to the reasons it chooses its decision. We introduce a formal definition of intention in structural causal influence models, grounded in the philosophy literature on intent and applicable to real-world machine learning systems. Through a number of examples and results, we show that our definition captures the intuitive notion of intent and satisfies desiderata set-out by past work. In addition, we show how our definition relates to past concepts, including actual causality, and the notion of instrumental goals, which is a core idea in the literature on safe AI agents. Finally, we demonstrate how ",
    "link": "https://arxiv.org/abs/2402.07221",
    "context": "Title: The Reasons that Agents Act: Intention and Instrumental Goals\nAbstract: Intention is an important and challenging concept in AI. It is important because it underlies many other concepts we care about, such as agency, manipulation, legal responsibility, and blame. However, ascribing intent to AI systems is contentious, and there is no universally accepted theory of intention applicable to AI agents. We operationalise the intention with which an agent acts, relating to the reasons it chooses its decision. We introduce a formal definition of intention in structural causal influence models, grounded in the philosophy literature on intent and applicable to real-world machine learning systems. Through a number of examples and results, we show that our definition captures the intuitive notion of intent and satisfies desiderata set-out by past work. In addition, we show how our definition relates to past concepts, including actual causality, and the notion of instrumental goals, which is a core idea in the literature on safe AI agents. Finally, we demonstrate how ",
    "path": "papers/24/02/2402.07221.json",
    "total_tokens": 948,
    "translated_title": "代理行为的原因：意图和工具性目标",
    "translated_abstract": "意图是人工智能中一个重要且具有挑战性的概念。它之所以重要，是因为它是许多其他我们关心的概念的基础，例如代理、操纵、法律责任和责备。然而，将意图归因于人工智能系统是有争议的，并且没有普遍接受的适用于人工智能代理的意图理论。我们通过将代理人行为的意图转化为其选择决策的原因，对意图进行了操作化定义。我们提出了一个在结构性因果影响模型中的意图定义，紧密结合在哲学文献中关于意图的观点，并适用于真实世界的机器学习系统。通过一些例子和结果，我们展示了我们的定义捕捉到了直观的意图概念，并符合过去研究的设定要求。此外，我们还展示了我们的定义与过去概念的关联，包括实际因果性和工具性目标的概念，后者是安全人工智能代理研究中的核心思想。最后，我们演示了我们的定义如何与实际机器学习系统中的实践相结合。",
    "tldr": "本论文提出了一个对代理行为意图的操作化定义，并通过一些例子和结果展示了其灵活性和适用性。这一定义有助于理解和解释机器学习系统的行为，以及相关概念如工具性目标的关系。",
    "en_tdlr": "This paper presents an operational definition of intention in agents' behavior and demonstrates its flexibility and applicability through examples and results. The definition helps understand and explain the behavior of machine learning systems, as well as its relationship with related concepts such as instrumental goals."
}