{
    "title": "Unlocking Instructive In-Context Learning with Tabular Prompting for Relational Triple Extraction",
    "abstract": "arXiv:2402.13741v1 Announce Type: cross  Abstract: The in-context learning (ICL) for relational triple extraction (RTE) has achieved promising performance, but still encounters two key challenges: (1) how to design effective prompts and (2) how to select proper demonstrations. Existing methods, however, fail to address these challenges appropriately. On the one hand, they usually recast RTE task to text-to-text prompting formats, which is unnatural and results in a mismatch between the output format at the pre-training time and the inference time for large language models (LLMs). On the other hand, they only utilize surface natural language features and lack consideration of triple semantics in sample selection. These issues are blocking improved performance in ICL for RTE, thus we aim to tackle prompt designing and sample selection challenges simultaneously. To this end, we devise a tabular prompting for RTE (\\textsc{TableIE}) which frames RTE task into a table generation task to inco",
    "link": "https://arxiv.org/abs/2402.13741",
    "context": "Title: Unlocking Instructive In-Context Learning with Tabular Prompting for Relational Triple Extraction\nAbstract: arXiv:2402.13741v1 Announce Type: cross  Abstract: The in-context learning (ICL) for relational triple extraction (RTE) has achieved promising performance, but still encounters two key challenges: (1) how to design effective prompts and (2) how to select proper demonstrations. Existing methods, however, fail to address these challenges appropriately. On the one hand, they usually recast RTE task to text-to-text prompting formats, which is unnatural and results in a mismatch between the output format at the pre-training time and the inference time for large language models (LLMs). On the other hand, they only utilize surface natural language features and lack consideration of triple semantics in sample selection. These issues are blocking improved performance in ICL for RTE, thus we aim to tackle prompt designing and sample selection challenges simultaneously. To this end, we devise a tabular prompting for RTE (\\textsc{TableIE}) which frames RTE task into a table generation task to inco",
    "path": "papers/24/02/2402.13741.json",
    "total_tokens": 810,
    "translated_title": "使用表格提示解锁关系三元组抽取的上下文学习",
    "translated_abstract": "关系三元组抽取（RTE）的上下文学习（ICL）取得了令人满意的表现，但仍然面临两个关键挑战：（1）如何设计有效的提示和（2）如何选择适当的演示。然而，现有方法未能适当解决这些挑战。一方面，它们通常将RTE任务重新定义为文本-文本提示格式，这是不自然的，导致在预训练时的输出格式和大型语言模型（LLMs）的推断时间之间不匹配。另一方面，它们只利用表面自然语言特征，缺乏在样本选择中考虑三元组语义。这些问题阻碍了ICL对RTE性能的改进，因此我们旨在同时解决提示设计和样本选择挑战。为此，我们设计了一个用于RTE的表格提示（TableIE），将RTE任务构建成一个表格生成任务以解决上述挑战。",
    "tldr": "设计了表格提示以解决关系三元组抽取中的提示设计和样本选择挑战。",
    "en_tdlr": "Designed tabular prompting to address the prompt designing and sample selection challenges in relational triple extraction."
}