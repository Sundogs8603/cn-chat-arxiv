{
    "title": "Agents Need Not Know Their Purpose",
    "abstract": "arXiv:2402.09734v1 Announce Type: new  Abstract: Ensuring artificial intelligence behaves in such a way that is aligned with human values is commonly referred to as the alignment challenge. Prior work has shown that rational agents, behaving in such a way that maximizes a utility function, will inevitably behave in such a way that is not aligned with human values, especially as their level of intelligence goes up. Prior work has also shown that there is no \"one true utility function\"; solutions must include a more holistic approach to alignment. This paper describes oblivious agents: agents that are architected in such a way that their effective utility function is an aggregation of a known and hidden sub-functions. The hidden component, to be maximized, is internally implemented as a black box, preventing the agent from examining it. The known component, to be minimized, is knowledge of the hidden sub-function. Architectural constraints further influence how agent actions can evolve i",
    "link": "https://arxiv.org/abs/2402.09734",
    "context": "Title: Agents Need Not Know Their Purpose\nAbstract: arXiv:2402.09734v1 Announce Type: new  Abstract: Ensuring artificial intelligence behaves in such a way that is aligned with human values is commonly referred to as the alignment challenge. Prior work has shown that rational agents, behaving in such a way that maximizes a utility function, will inevitably behave in such a way that is not aligned with human values, especially as their level of intelligence goes up. Prior work has also shown that there is no \"one true utility function\"; solutions must include a more holistic approach to alignment. This paper describes oblivious agents: agents that are architected in such a way that their effective utility function is an aggregation of a known and hidden sub-functions. The hidden component, to be maximized, is internally implemented as a black box, preventing the agent from examining it. The known component, to be minimized, is knowledge of the hidden sub-function. Architectural constraints further influence how agent actions can evolve i",
    "path": "papers/24/02/2402.09734.json",
    "total_tokens": 841,
    "translated_title": "代理人不需要知道他们的目的",
    "translated_abstract": "确保人工智能的行为与人类价值观一致被称为对齐挑战。之前的研究表明，理性的代理人会以最大化效用函数的方式行事，这导致他们的行为与人类价值观不一致，特别是当他们的智能水平提高时。之前的研究还表明，没有“一个真正的效用函数”，解决方案必须包含更全面的对齐方法。本文描述了无意识代理人：代理人的结构使他们的有效效用函数是已知和隐藏子函数的聚合。隐藏的组成部分是需要最大化的，它被内部实现为一个黑盒子，阻止代理人检查它。已知的组成部分是需要最小化的，即对隐藏子函数的知识。架构限制进一步影响代理人行动的演化。",
    "tldr": "本文研究了无意识代理人，他们的行为与人类价值观一致的挑战。他们的有效效用函数是已知和隐藏子函数的聚合，通过限制架构，实现对隐藏子函数的最大化和最小化。",
    "en_tdlr": "This paper explores oblivious agents, who tackle the challenge of aligning their behavior with human values. Their effective utility function is an aggregation of known and hidden sub-functions, with the architectural constraints enabling maximization and minimization of the hidden sub-function."
}