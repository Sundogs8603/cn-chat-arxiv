{
    "title": "FedRDF: A Robust and Dynamic Aggregation Function against Poisoning Attacks in Federated Learning",
    "abstract": "arXiv:2402.10082v1 Announce Type: new  Abstract: Federated Learning (FL) represents a promising approach to typical privacy concerns associated with centralized Machine Learning (ML) deployments. Despite its well-known advantages, FL is vulnerable to security attacks such as Byzantine behaviors and poisoning attacks, which can significantly degrade model performance and hinder convergence. The effectiveness of existing approaches to mitigate complex attacks, such as median, trimmed mean, or Krum aggregation functions, has been only partially demonstrated in the case of specific attacks. Our study introduces a novel robust aggregation mechanism utilizing the Fourier Transform (FT), which is able to effectively handling sophisticated attacks without prior knowledge of the number of attackers. Employing this data technique, weights generated by FL clients are projected into the frequency domain to ascertain their density function, selecting the one exhibiting the highest frequency. Conseq",
    "link": "https://arxiv.org/abs/2402.10082",
    "context": "Title: FedRDF: A Robust and Dynamic Aggregation Function against Poisoning Attacks in Federated Learning\nAbstract: arXiv:2402.10082v1 Announce Type: new  Abstract: Federated Learning (FL) represents a promising approach to typical privacy concerns associated with centralized Machine Learning (ML) deployments. Despite its well-known advantages, FL is vulnerable to security attacks such as Byzantine behaviors and poisoning attacks, which can significantly degrade model performance and hinder convergence. The effectiveness of existing approaches to mitigate complex attacks, such as median, trimmed mean, or Krum aggregation functions, has been only partially demonstrated in the case of specific attacks. Our study introduces a novel robust aggregation mechanism utilizing the Fourier Transform (FT), which is able to effectively handling sophisticated attacks without prior knowledge of the number of attackers. Employing this data technique, weights generated by FL clients are projected into the frequency domain to ascertain their density function, selecting the one exhibiting the highest frequency. Conseq",
    "path": "papers/24/02/2402.10082.json",
    "total_tokens": 832,
    "translated_title": "FedRDF: 一种针对联邦学习中毒化攻击的强大和动态聚合函数",
    "translated_abstract": "联邦学习（FL）是一种有前景的方法，可以解决集中式机器学习（ML）部署所带来的典型隐私问题。尽管FL具有众所周知的优点，但它容易受到安全攻击，如拜占庭行为和毒化攻击，这些攻击会严重影响模型性能和收敛。现有方法对于缓解复杂攻击（如中值、修剪均值或Krum聚合函数）的效果仅部分证明了在特定攻击情况下的有效性。我们的研究引入了一种新颖的鲁棒聚合机制，利用傅里叶变换（FT）来有效处理复杂攻击，而不需要对攻击者数量有先验知识。利用这种数据技术，FL客户端生成的权重被投影到频域以确定其密度函数，选择具有最高频率的密度函数。",
    "tldr": "FedRDF提出了一种新颖的鲁棒聚合机制，利用傅里叶变换来有效处理联邦学习中的复杂攻击，而不需要先验知识。",
    "en_tdlr": "FedRDF proposes a novel robust aggregation mechanism utilizing the Fourier Transform to effectively handle complex attacks in federated learning without prior knowledge."
}