{
    "title": "Explaining Text Classifiers with Counterfactual Representations",
    "abstract": "One well motivated explanation method for classifiers leverages counterfactuals which are hypothetical events identical to real observations in all aspects except for one categorical feature. Constructing such counterfactual poses specific challenges for texts, however, as some attribute values may not necessarily align with plausible real-world events. In this paper we propose a simple method for generating counterfactuals by intervening in the space of text representations which bypasses this limitation. We argue that our interventions are minimally disruptive and that they are theoretically sound as they align with counterfactuals as defined in Pearl's causal inference framework. To validate our method, we first conduct experiments on a synthetic dataset of counterfactuals, allowing for a direct comparison between classifier predictions based on ground truth counterfactuals (obtained through explicit text interventions) and our counterfactuals, derived through interventions in the r",
    "link": "https://arxiv.org/abs/2402.00711",
    "context": "Title: Explaining Text Classifiers with Counterfactual Representations\nAbstract: One well motivated explanation method for classifiers leverages counterfactuals which are hypothetical events identical to real observations in all aspects except for one categorical feature. Constructing such counterfactual poses specific challenges for texts, however, as some attribute values may not necessarily align with plausible real-world events. In this paper we propose a simple method for generating counterfactuals by intervening in the space of text representations which bypasses this limitation. We argue that our interventions are minimally disruptive and that they are theoretically sound as they align with counterfactuals as defined in Pearl's causal inference framework. To validate our method, we first conduct experiments on a synthetic dataset of counterfactuals, allowing for a direct comparison between classifier predictions based on ground truth counterfactuals (obtained through explicit text interventions) and our counterfactuals, derived through interventions in the r",
    "path": "papers/24/02/2402.00711.json",
    "total_tokens": 788,
    "translated_title": "使用反事实表示解释文本分类器",
    "translated_abstract": "一种基于反事实的解释方法可以为分类器提供合理的解释，其中反事实是指除了一个分类特征之外，与真实观察完全相同的假设事件。然而，在文本领域构建这种反事实存在特定挑战，因为某些属性值可能与现实世界的事件不一致。在这篇论文中，我们提出了一种简单的方法，通过对文本表示进行干预来生成反事实，从而克服了这个限制。我们认为我们的干预方法是最小程度的干扰，并且在理论上是可靠的，因为它们与Pearl的因果推断框架中定义的反事实是一致的。为了验证我们的方法，我们首先在合成数据集上进行实验，比较了基于真实反事实（通过明确的文本干预获得）和我们的反事实（通过对文本表示的干预得到）的分类器预测。",
    "tldr": "本论文提出了一种使用反事实表示解释文本分类器的方法，通过干预文本表示来生成反事实，并通过实验证实了方法的有效性。",
    "en_tdlr": "This paper proposes a method to explain text classifiers using counterfactual representations by intervening in the space of text representations, and validates the effectiveness of the method through experiments."
}