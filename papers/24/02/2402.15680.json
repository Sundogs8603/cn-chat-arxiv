{
    "title": "Overcoming Pitfalls in Graph Contrastive Learning Evaluation: Toward Comprehensive Benchmarks",
    "abstract": "arXiv:2402.15680v1 Announce Type: new  Abstract: The rise of self-supervised learning, which operates without the need for labeled data, has garnered significant interest within the graph learning community. This enthusiasm has led to the development of numerous Graph Contrastive Learning (GCL) techniques, all aiming to create a versatile graph encoder that leverages the wealth of unlabeled data for various downstream tasks. However, the current evaluation standards for GCL approaches are flawed due to the need for extensive hyper-parameter tuning during pre-training and the reliance on a single downstream task for assessment. These flaws can skew the evaluation away from the intended goals, potentially leading to misleading conclusions. In our paper, we thoroughly examine these shortcomings and offer fresh perspectives on how GCL methods are affected by hyper-parameter choices and the choice of downstream tasks for their evaluation. Additionally, we introduce an enhanced evaluation fr",
    "link": "https://arxiv.org/abs/2402.15680",
    "context": "Title: Overcoming Pitfalls in Graph Contrastive Learning Evaluation: Toward Comprehensive Benchmarks\nAbstract: arXiv:2402.15680v1 Announce Type: new  Abstract: The rise of self-supervised learning, which operates without the need for labeled data, has garnered significant interest within the graph learning community. This enthusiasm has led to the development of numerous Graph Contrastive Learning (GCL) techniques, all aiming to create a versatile graph encoder that leverages the wealth of unlabeled data for various downstream tasks. However, the current evaluation standards for GCL approaches are flawed due to the need for extensive hyper-parameter tuning during pre-training and the reliance on a single downstream task for assessment. These flaws can skew the evaluation away from the intended goals, potentially leading to misleading conclusions. In our paper, we thoroughly examine these shortcomings and offer fresh perspectives on how GCL methods are affected by hyper-parameter choices and the choice of downstream tasks for their evaluation. Additionally, we introduce an enhanced evaluation fr",
    "path": "papers/24/02/2402.15680.json",
    "total_tokens": 868,
    "translated_title": "克服图对比学习评估中的陷阱：走向全面基准",
    "translated_abstract": "arXiv:2402.15680v1 公告类型：新摘要：自监督学习的兴起使得图学习社区对其产生了极大的兴趣，而自监督学习无需标记数据。这种热情导致了许多图对比学习（GCL）技术的发展，其目标都是创建一个多功能的图编码器，利用大量未标记数据进行各种下游任务。然而，目前用于评估GCL方法的评估标准存在缺陷，因为在预训练期间需要进行大量超参数调整，并且依赖单一的下游任务进行评估。这些缺陷可能使评估偏离预期目标，潜在导致误导性结论。在我们的论文中，我们彻底研究了这些缺陷，并提出了新的观点，即GCL方法如何受超参数选择和选择用于评估的下游任务的影响。此外，我们引入了一个增强型评估框架。",
    "tldr": "本文深入研究了图对比学习方法评估中的缺陷，并提出了对超参数选择和下游任务选择影响的新观点，同时引入了一个增强型评估框架。",
    "en_tdlr": "This paper thoroughly examines the pitfalls in the evaluation of graph contrastive learning methods, offers fresh perspectives on the impact of hyper-parameter choices and downstream task selection, and introduces an enhanced evaluation framework."
}