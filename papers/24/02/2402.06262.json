{
    "title": "On the Efficacy of Eviction Policy for Key-Value Constrained Generative Language Model Inference",
    "abstract": "Despite the recent success associated with Large Language Models~(LLMs), they are notably cost-prohibitive to deploy in resource-constrained environments due to their excessive memory and computational demands. In addition to model parameters, the key-value cache is also stored in GPU memory, growing linearly with batch size and sequence length. As a remedy, recent works have proposed various eviction policies for maintaining the overhead of key-value cache under a given budget. This paper embarks on the efficacy of existing eviction policies in terms of \\textit{importance score calculation} and \\textit{eviction scope construction}. We identify the deficiency of prior policies in these two aspects and introduce RoCo, a \\underline{r}\\underline{o}bust \\underline{c}ache \\underline{o}mission policy based on temporal attention scores and robustness measures. Extensive experimentation spanning prefilling and auto-regressive decoding stages validates the superiority of RoCo. Finally, we relea",
    "link": "https://arxiv.org/abs/2402.06262",
    "context": "Title: On the Efficacy of Eviction Policy for Key-Value Constrained Generative Language Model Inference\nAbstract: Despite the recent success associated with Large Language Models~(LLMs), they are notably cost-prohibitive to deploy in resource-constrained environments due to their excessive memory and computational demands. In addition to model parameters, the key-value cache is also stored in GPU memory, growing linearly with batch size and sequence length. As a remedy, recent works have proposed various eviction policies for maintaining the overhead of key-value cache under a given budget. This paper embarks on the efficacy of existing eviction policies in terms of \\textit{importance score calculation} and \\textit{eviction scope construction}. We identify the deficiency of prior policies in these two aspects and introduce RoCo, a \\underline{r}\\underline{o}bust \\underline{c}ache \\underline{o}mission policy based on temporal attention scores and robustness measures. Extensive experimentation spanning prefilling and auto-regressive decoding stages validates the superiority of RoCo. Finally, we relea",
    "path": "papers/24/02/2402.06262.json",
    "total_tokens": 914,
    "translated_title": "关于针对键值约束生成语言模型推理的驱逐策略的有效性研究",
    "translated_abstract": "尽管大型语言模型（LLMs）在最近取得了成功，但由于它们对内存和计算资源的过度需求，它们在资源受限环境中部署仍然昂贵。除了模型参数外，键值缓存也存储在GPU内存中，随着批处理大小和序列长度的增加而线性增长。为此，最近的研究提出了各种针对给定预算下维护键值缓存开销的驱逐策略。本文着眼于现有驱逐策略在重要性评分计算和驱逐范围构建两个方面的效果。我们确定了先前策略在这两个方面的不足，并引入了基于时间注意力得分和鲁棒性度量的RoCo，一种强大的缓存驱逐策略。涵盖了预填充和自回归解码阶段的广泛实验验证了RoCo的优越性。最后，我们公开发布了RoCo的代码和模型供研究者使用。",
    "tldr": "本文研究了针对键值约束生成语言模型推理的驱逐策略的有效性，通过引入基于时间注意力得分和鲁棒性度量的RoCo策略，优于现有的策略。",
    "en_tdlr": "This paper investigates the effectiveness of eviction policies for key-value constrained generative language model inference. By introducing RoCo, a policy based on temporal attention scores and robustness measures, the study shows superiority over existing policies."
}