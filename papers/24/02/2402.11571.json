{
    "title": "Ain't Misbehavin' -- Using LLMs to Generate Expressive Robot Behavior in Conversations with the Tabletop Robot Haru",
    "abstract": "arXiv:2402.11571v1 Announce Type: cross  Abstract: Social robots aim to establish long-term bonds with humans through engaging conversation. However, traditional conversational approaches, reliant on scripted interactions, often fall short in maintaining engaging conversations. This paper addresses this limitation by integrating large language models (LLMs) into social robots to achieve more dynamic and expressive conversations. We introduce a fully-automated conversation system that leverages LLMs to generate robot responses with expressive behaviors, congruent with the robot's personality. We incorporate robot behavior with two modalities: 1) a text-to-speech (TTS) engine capable of various delivery styles, and 2) a library of physical actions for the robot. We develop a custom, state-of-the-art emotion recognition model to dynamically select the robot's tone of voice and utilize emojis from LLM output as cues for generating robot actions. A demo of our system is available here. To i",
    "link": "https://arxiv.org/abs/2402.11571",
    "context": "Title: Ain't Misbehavin' -- Using LLMs to Generate Expressive Robot Behavior in Conversations with the Tabletop Robot Haru\nAbstract: arXiv:2402.11571v1 Announce Type: cross  Abstract: Social robots aim to establish long-term bonds with humans through engaging conversation. However, traditional conversational approaches, reliant on scripted interactions, often fall short in maintaining engaging conversations. This paper addresses this limitation by integrating large language models (LLMs) into social robots to achieve more dynamic and expressive conversations. We introduce a fully-automated conversation system that leverages LLMs to generate robot responses with expressive behaviors, congruent with the robot's personality. We incorporate robot behavior with two modalities: 1) a text-to-speech (TTS) engine capable of various delivery styles, and 2) a library of physical actions for the robot. We develop a custom, state-of-the-art emotion recognition model to dynamically select the robot's tone of voice and utilize emojis from LLM output as cues for generating robot actions. A demo of our system is available here. To i",
    "path": "papers/24/02/2402.11571.json",
    "total_tokens": 882,
    "translated_title": "不调皮 —— 使用LLMs生成与台式机器人Haru对话中富有表现力的机器人行为",
    "translated_abstract": "社交机器人旨在通过引人入胜的对话与人类建立长期关系。然而，传统的对话方法依赖于脚本化互动，往往无法保持引人入胜的对话。本文通过将大型语言模型（LLMs）集成到社交机器人中，实现更动态和富有表现力的对话，从而解决了这一局限性。我们介绍了一个完全自动化的对话系统，利用LLMs生成具有表现力行为的机器人响应，与机器人个性一致。我们将机器人行为与两种形式结合起来：1）一个能够具备各种语调风格的文本转语音（TTS）引擎，以及2）机器人的一系列物理动作库。我们开发了一个自定义的最新情绪识别模型，动态选择机器人的语调，并利用LLM输出中的表情符号作为生成机器人动作的线索。我们的系统演示可在此处查看。",
    "tldr": "将大型语言模型集成到社交机器人中，实现更动态和富有表现力的对话，包括使用情绪识别模型，调整语调，并利用表情符号生成机器人动作。",
    "en_tdlr": "Integrating large language models into social robots to achieve more dynamic and expressive conversations, incorporating an emotion recognition model to adjust tone and using emojis to generate robot actions."
}