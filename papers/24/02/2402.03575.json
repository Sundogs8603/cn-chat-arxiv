{
    "title": "Toward Human-AI Alignment in Large-Scale Multi-Player Games",
    "abstract": "Achieving human-AI alignment in complex multi-agent games is crucial for creating trustworthy AI agents that enhance gameplay. We propose a method to evaluate this alignment using an interpretable task-sets framework, focusing on high-level behavioral tasks instead of low-level policies. Our approach has three components. First, we analyze extensive human gameplay data from Xbox's Bleeding Edge (100K+ games), uncovering behavioral patterns in a complex task space. This task space serves as a basis set for a behavior manifold capturing interpretable axes: fight-flight, explore-exploit, and solo-multi-agent. Second, we train an AI agent to play Bleeding Edge using a Generative Pretrained Causal Transformer and measure its behavior. Third, we project human and AI gameplay to the proposed behavior manifold to compare and contrast. This allows us to interpret differences in policy as higher-level behavioral concepts, e.g., we find that while human players exhibit variability in fight-flight",
    "link": "https://arxiv.org/abs/2402.03575",
    "context": "Title: Toward Human-AI Alignment in Large-Scale Multi-Player Games\nAbstract: Achieving human-AI alignment in complex multi-agent games is crucial for creating trustworthy AI agents that enhance gameplay. We propose a method to evaluate this alignment using an interpretable task-sets framework, focusing on high-level behavioral tasks instead of low-level policies. Our approach has three components. First, we analyze extensive human gameplay data from Xbox's Bleeding Edge (100K+ games), uncovering behavioral patterns in a complex task space. This task space serves as a basis set for a behavior manifold capturing interpretable axes: fight-flight, explore-exploit, and solo-multi-agent. Second, we train an AI agent to play Bleeding Edge using a Generative Pretrained Causal Transformer and measure its behavior. Third, we project human and AI gameplay to the proposed behavior manifold to compare and contrast. This allows us to interpret differences in policy as higher-level behavioral concepts, e.g., we find that while human players exhibit variability in fight-flight",
    "path": "papers/24/02/2402.03575.json",
    "total_tokens": 934,
    "translated_title": "在大规模多人游戏中实现人工智能与人类的协同",
    "translated_abstract": "在复杂的多智能体游戏中实现人工智能与人类的协同对于创建增强游戏体验的可信任的人工智能代理至关重要。我们提出了一种方法来评估这种协同，使用可解释的任务集框架，重点关注高级行为任务而非低级策略。我们的方法有三个组成部分。首先，我们分析了来自Xbox的Bleeding Edge（10万+游戏）的大量人类游戏数据，揭示了复杂任务空间中的行为模式。这个任务空间作为行为流形的基础集合，捕捉可解释的轴：战斗-逃跑、探索-利用以及单人-多人智能体。其次，我们训练一个使用生成预训练因果变换器的人工智能代理来玩Bleeding Edge，并测量其行为。第三，我们将人类和人工智能游戏映射到提出的行为流形中进行比较和对比。这样可以解释策略的差异，如，我们发现人类玩家在战斗-逃跑方面表现变化多样。",
    "tldr": "本研究提出了一种在大规模多人游戏中评估人工智能与人类协作的方法，通过分析人类游戏数据和训练AI代理来比较和对比人类和AI的行为差异，以识别高级行为概念。",
    "en_tdlr": "This paper proposes a method to evaluate human-AI alignment in large-scale multi-player games, analyzing human gameplay data and training AI agents to compare and contrast their behaviors in order to identify higher-level behavioral concepts."
}