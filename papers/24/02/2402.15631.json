{
    "title": "Fine-Grained Self-Endorsement Improves Factuality and Reasoning",
    "abstract": "arXiv:2402.15631v1 Announce Type: cross  Abstract: This work studies improving large language model (LLM) generations at inference time by mitigating fact-conflicting hallucinations. Particularly, we propose a self-endorsement framework that leverages the fine-grained fact-level comparisons across multiple sampled responses. Compared with prior ensemble methods (Wang et al., 2022;Chen et al., 2023)) that perform response-level selection, our approach can better alleviate hallucinations, especially for longform generation tasks. Our approach can broadly benefit smaller and open-source LLMs as it mainly conducts simple content-based comparisons. Experiments on Biographies show that our method can effectively improve the factuality of generations with simple and intuitive prompts across different scales of LLMs. Besides, comprehensive analyses on TriviaQA and GSM8K demonstrate the potential of self-endorsement for broader application.",
    "link": "https://arxiv.org/abs/2402.15631",
    "context": "Title: Fine-Grained Self-Endorsement Improves Factuality and Reasoning\nAbstract: arXiv:2402.15631v1 Announce Type: cross  Abstract: This work studies improving large language model (LLM) generations at inference time by mitigating fact-conflicting hallucinations. Particularly, we propose a self-endorsement framework that leverages the fine-grained fact-level comparisons across multiple sampled responses. Compared with prior ensemble methods (Wang et al., 2022;Chen et al., 2023)) that perform response-level selection, our approach can better alleviate hallucinations, especially for longform generation tasks. Our approach can broadly benefit smaller and open-source LLMs as it mainly conducts simple content-based comparisons. Experiments on Biographies show that our method can effectively improve the factuality of generations with simple and intuitive prompts across different scales of LLMs. Besides, comprehensive analyses on TriviaQA and GSM8K demonstrate the potential of self-endorsement for broader application.",
    "path": "papers/24/02/2402.15631.json",
    "total_tokens": 834,
    "translated_title": "细粒度的自认证可以提升事实性和推理能力",
    "translated_abstract": "这项工作研究了如何在推理时通过缓解存在事实冲突的幻觉来改善大型语言模型（LLM）生成。特别是，我们提出了一个自认证框架，利用跨多个抽样响应进行细粒度的事实级别比较。与先前的组合方法（王等，2022年；陈等，2023年）进行响应级别选择相比，我们的方法能够更好地减轻幻觉，特别是对于长篇生成任务。我们的方法可以广泛有益于较小和开源的LLM，因为它主要进行简单的基于内容的比较。在传记上的实验证明，我们的方法可以通过简单直观的提示有效改善不同规模的LLM生成的事实性。此外，对TriviaQA和GSM8K的全面分析展示了自认证在更广泛应用中的潜力。",
    "tldr": "提出了利用自认证框架进行细粒度事实级别比较的方法，能够更好地减轻大型语言模型生成过程中的幻觉，尤其适用于长篇生成任务。"
}