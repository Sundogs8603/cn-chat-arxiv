{
    "title": "Verifiable evaluations of machine learning models using zkSNARKs",
    "abstract": "In a world of increasing closed-source commercial machine learning models, model evaluations from developers must be taken at face value. These benchmark results, whether over task accuracy, bias evaluations, or safety checks, are traditionally impossible to verify by a model end-user without the costly or impossible process of re-performing the benchmark on black-box model outputs. This work presents a method of verifiable model evaluation using model inference through zkSNARKs. The resulting zero-knowledge computational proofs of model outputs over datasets can be packaged into verifiable evaluation attestations showing that models with fixed private weights achieve stated performance or fairness metrics over public inputs. These verifiable attestations can be performed on any standard neural network model with varying compute requirements. For the first time, we demonstrate this across a sample of real-world models and highlight key challenges and design solutions. This presents a n",
    "link": "https://arxiv.org/abs/2402.02675",
    "context": "Title: Verifiable evaluations of machine learning models using zkSNARKs\nAbstract: In a world of increasing closed-source commercial machine learning models, model evaluations from developers must be taken at face value. These benchmark results, whether over task accuracy, bias evaluations, or safety checks, are traditionally impossible to verify by a model end-user without the costly or impossible process of re-performing the benchmark on black-box model outputs. This work presents a method of verifiable model evaluation using model inference through zkSNARKs. The resulting zero-knowledge computational proofs of model outputs over datasets can be packaged into verifiable evaluation attestations showing that models with fixed private weights achieve stated performance or fairness metrics over public inputs. These verifiable attestations can be performed on any standard neural network model with varying compute requirements. For the first time, we demonstrate this across a sample of real-world models and highlight key challenges and design solutions. This presents a n",
    "path": "papers/24/02/2402.02675.json",
    "total_tokens": 871,
    "translated_title": "使用zkSNARKs进行可验证的机器学习模型评估",
    "translated_abstract": "在越来越多闭源商业机器学习模型的世界中，开发者的模型评估必须被当作面值接受。这些评估结果，无论是任务准确性、偏差评估还是安全检查，传统上无法通过重新执行黑箱模型输出的基准测试来进行验证。本研究提出了一种使用zkSNARKs进行可验证模型评估的方法。通过zkSNARKs进行模型推理，得到的模型输出的零知识计算证明可以打包成可验证的评估证明，显示具有固定私有权重的模型在公开输入上达到了所述的性能或公平性指标。这些可验证的评估证明可以在任何标准神经网络模型上进行，计算要求各不相同。我们首次在一系列真实模型上展示了这一点，并突出了关键挑战和设计解决方案。",
    "tldr": "本论文提出了一种使用zkSNARKs进行机器学习模型评估的方法。通过模型推理和零知识计算证明，可以提供可验证的评估证明，验证模型在公开输入上的性能和公平性指标。这有助于解决闭源商业机器学习模型评估可信性的问题。"
}