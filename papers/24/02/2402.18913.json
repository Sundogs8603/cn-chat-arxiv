{
    "title": "AdaMergeX: Cross-Lingual Transfer with Large Language Models via Adaptive Adapter Merging",
    "abstract": "arXiv:2402.18913v1 Announce Type: cross  Abstract: As an effective alternative to the direct fine-tuning on target tasks in specific languages, cross-lingual transfer addresses the challenges of limited training data by decoupling ''task ability'' and ''language ability'' by fine-tuning on the target task in the source language and another selected task in the target language, respectively. However, they fail to fully separate the task ability from the source language or the language ability from the chosen task. In this paper, we acknowledge the mutual reliance between task ability and language ability and direct our attention toward the gap between the target language and the source language on tasks. As the gap removes the impact of tasks, we assume that it remains consistent across tasks. Based on this assumption, we propose a new cross-lingual transfer method called $\\texttt{AdaMergeX}$ that utilizes adaptive adapter merging. By introducing a reference task, we can determine that ",
    "link": "https://arxiv.org/abs/2402.18913",
    "context": "Title: AdaMergeX: Cross-Lingual Transfer with Large Language Models via Adaptive Adapter Merging\nAbstract: arXiv:2402.18913v1 Announce Type: cross  Abstract: As an effective alternative to the direct fine-tuning on target tasks in specific languages, cross-lingual transfer addresses the challenges of limited training data by decoupling ''task ability'' and ''language ability'' by fine-tuning on the target task in the source language and another selected task in the target language, respectively. However, they fail to fully separate the task ability from the source language or the language ability from the chosen task. In this paper, we acknowledge the mutual reliance between task ability and language ability and direct our attention toward the gap between the target language and the source language on tasks. As the gap removes the impact of tasks, we assume that it remains consistent across tasks. Based on this assumption, we propose a new cross-lingual transfer method called $\\texttt{AdaMergeX}$ that utilizes adaptive adapter merging. By introducing a reference task, we can determine that ",
    "path": "papers/24/02/2402.18913.json",
    "total_tokens": 816,
    "translated_title": "AdaMergeX: 跨语言大语言模型的自适应适配器融合",
    "translated_abstract": "作为在特定语言的目标任务上进行直接微调的有效替代方案，跨语言转移通过在源语言上微调目标任务并在目标语言中选择另一个任务来解耦了有限训练数据的挑战，从而分离了“任务能力”和“语言能力”。然而，它们未能充分将任务能力与源语言或者语言能力与选择的任务完全分开。本文承认任务能力和语言能力之间的相互依赖，并将我们的注意力集中在目标语言和源语言之间的任务差距上。由于该差距消除了任务的影响，我们假定它在各任务间保持一致。基于这一假设，我们提出了一种名为 $\\texttt{AdaMergeX}$ 的新的跨语言转移方法，利用自适应适配器融合。",
    "tldr": "提出一种新的跨语言转移方法 $\\texttt{AdaMergeX}$，利用自适应适配器融合来解决任务能力和语言能力之间的关系。"
}