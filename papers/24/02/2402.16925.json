{
    "title": "Minimize Control Inputs for Strong Structural Controllability Using Reinforcement Learning with Graph Neural Network",
    "abstract": "arXiv:2402.16925v1 Announce Type: cross  Abstract: Strong structural controllability (SSC) guarantees networked system with linear-invariant dynamics controllable for all numerical realizations of parameters. Current research has established algebraic and graph-theoretic conditions of SSC for zero/nonzero or zero/nonzero/arbitrary structure. One relevant practical problem is how to fully control the system with the minimal number of input signals and identify which nodes must be imposed signals. Previous work shows that this optimization problem is NP-hard and it is difficult to find the solution. To solve this problem, we formulate the graph coloring process as a Markov decision process (MDP) according to the graph-theoretical condition of SSC for both zero/nonzero and zero/nonzero/arbitrary structure. We use Actor-critic method with Directed graph neural network which represents the color information of graph to optimize MDP. Our method is validated in a social influence network with",
    "link": "https://arxiv.org/abs/2402.16925",
    "context": "Title: Minimize Control Inputs for Strong Structural Controllability Using Reinforcement Learning with Graph Neural Network\nAbstract: arXiv:2402.16925v1 Announce Type: cross  Abstract: Strong structural controllability (SSC) guarantees networked system with linear-invariant dynamics controllable for all numerical realizations of parameters. Current research has established algebraic and graph-theoretic conditions of SSC for zero/nonzero or zero/nonzero/arbitrary structure. One relevant practical problem is how to fully control the system with the minimal number of input signals and identify which nodes must be imposed signals. Previous work shows that this optimization problem is NP-hard and it is difficult to find the solution. To solve this problem, we formulate the graph coloring process as a Markov decision process (MDP) according to the graph-theoretical condition of SSC for both zero/nonzero and zero/nonzero/arbitrary structure. We use Actor-critic method with Directed graph neural network which represents the color information of graph to optimize MDP. Our method is validated in a social influence network with",
    "path": "papers/24/02/2402.16925.json",
    "total_tokens": 849,
    "translated_title": "使用带有图神经网络的强结构可控性强化学习最小化控制输入",
    "translated_abstract": "强结构可控性(SSC)保证具有线性不变动力学的网络系统对于所有参数的数值实现都是可控的。当前研究已经为零/非零或零/非零/任意结构的SSC建立了代数和图论条件。一个相关的实际问题是如何用最少的输入信号完全控制系统，并确定必须施加信号的节点。先前的研究表明，这个优化问题是NP难的，很难找到解决方案。为了解决这个问题，我们根据零/非零和零/非零/任意结构的SSC的图论条件，将图着色过程构建为马尔可夫决策过程(MDP)。我们使用带有有向图神经网络的Actor-critic方法来表示图的着色信息以优化MDP。我们的方法在一个社交影响网络中得到了验证。",
    "tldr": "使用带有图神经网络的强化学习方法，将图着色问题形式化为马尔可夫决策过程，有效解决了强结构可控性条件下最小化控制输入的问题。",
    "en_tdlr": "By utilizing reinforcement learning with graph neural network, the optimization problem of minimizing control inputs under the condition of strong structural controllability is effectively addressed by formulating the graph coloring process as a Markov decision process."
}