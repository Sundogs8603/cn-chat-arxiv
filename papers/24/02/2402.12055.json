{
    "title": "Are LLM-based Evaluators Confusing NLG Quality Criteria?",
    "abstract": "arXiv:2402.12055v1 Announce Type: new  Abstract: Some prior work has shown that LLMs perform well in NLG evaluation for different tasks. However, we discover that LLMs seem to confuse different evaluation criteria, which reduces their reliability. For further verification, we first consider avoiding issues of inconsistent conceptualization and vague expression in existing NLG quality criteria themselves. So we summarize a clear hierarchical classification system for 11 common aspects with corresponding different criteria from previous studies involved. Inspired by behavioral testing, we elaborately design 18 types of aspect-targeted perturbation attacks for fine-grained analysis of the evaluation behaviors of different LLMs. We also conduct human annotations beyond the guidance of the classification system to validate the impact of the perturbations. Our experimental results reveal confusion issues inherent in LLMs, as well as other noteworthy phenomena, and necessitate further researc",
    "link": "https://arxiv.org/abs/2402.12055",
    "context": "Title: Are LLM-based Evaluators Confusing NLG Quality Criteria?\nAbstract: arXiv:2402.12055v1 Announce Type: new  Abstract: Some prior work has shown that LLMs perform well in NLG evaluation for different tasks. However, we discover that LLMs seem to confuse different evaluation criteria, which reduces their reliability. For further verification, we first consider avoiding issues of inconsistent conceptualization and vague expression in existing NLG quality criteria themselves. So we summarize a clear hierarchical classification system for 11 common aspects with corresponding different criteria from previous studies involved. Inspired by behavioral testing, we elaborately design 18 types of aspect-targeted perturbation attacks for fine-grained analysis of the evaluation behaviors of different LLMs. We also conduct human annotations beyond the guidance of the classification system to validate the impact of the perturbations. Our experimental results reveal confusion issues inherent in LLMs, as well as other noteworthy phenomena, and necessitate further researc",
    "path": "papers/24/02/2402.12055.json",
    "total_tokens": 898,
    "translated_title": "基于LLM的评估器是否混淆了自然语言生成（NLG）质量标准？",
    "translated_abstract": "一些先前的研究表明，LLMs在不同任务的NLG评估中表现良好。然而，我们发现LLMs似乎混淆了不同的评估标准，从而降低了它们的可靠性。为了进一步验证，我们首先考虑避免现有NLG质量标准中不一致概念化和模糊表达的问题本身。因此，我们总结了一个清晰的层次分类系统，其中包含来自先前研究的11个常见方面的相应不同标准。受行为测试启发，我们精心设计了18种针对不同LLMs评估行为的方面定向扰动攻击，以进行细粒度分析。我们还进行了超出分类系统指导范围的人类注释，以验证扰动的影响。我们的实验结果揭示了LLMs固有的混淆问题，以及其他值得关注的现象，并需要进一步研究。",
    "tldr": "LLMs在NLG评估中表现良好，但存在混淆不同评估标准的问题，研究提出了一个详细的分类系统和针对不同LLMs评估行为的扰动攻击，揭示了LLMs固有的混淆问题，并需要进一步研究。",
    "en_tdlr": "LLMs perform well in NLG evaluation but confuse different evaluation criteria, the study introduces a detailed classification system and perturbation attacks for different LLMs evaluation behaviors, revealing inherent confusion issues in LLMs and suggesting further research."
}