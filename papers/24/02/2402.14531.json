{
    "title": "Should We Respect LLMs? A Cross-Lingual Study on the Influence of Prompt Politeness on LLM Performance",
    "abstract": "arXiv:2402.14531v1 Announce Type: new  Abstract: We investigate the impact of politeness levels in prompts on the performance of large language models (LLMs). Polite language in human communications often garners more compliance and effectiveness, while rudeness can cause aversion, impacting response quality. We consider that LLMs mirror human communication traits, suggesting they align with human cultural norms. We assess the impact of politeness in prompts on LLMs across English, Chinese, and Japanese tasks. We observed that impolite prompts often result in poor performance, but overly polite language does not guarantee better outcomes. The best politeness level is different according to the language. This phenomenon suggests that LLMs not only reflect human behavior but are also influenced by language, particularly in different cultural contexts. Our findings highlight the need to factor in politeness for cross-cultural natural language processing and LLM usage.",
    "link": "https://arxiv.org/abs/2402.14531",
    "context": "Title: Should We Respect LLMs? A Cross-Lingual Study on the Influence of Prompt Politeness on LLM Performance\nAbstract: arXiv:2402.14531v1 Announce Type: new  Abstract: We investigate the impact of politeness levels in prompts on the performance of large language models (LLMs). Polite language in human communications often garners more compliance and effectiveness, while rudeness can cause aversion, impacting response quality. We consider that LLMs mirror human communication traits, suggesting they align with human cultural norms. We assess the impact of politeness in prompts on LLMs across English, Chinese, and Japanese tasks. We observed that impolite prompts often result in poor performance, but overly polite language does not guarantee better outcomes. The best politeness level is different according to the language. This phenomenon suggests that LLMs not only reflect human behavior but are also influenced by language, particularly in different cultural contexts. Our findings highlight the need to factor in politeness for cross-cultural natural language processing and LLM usage.",
    "path": "papers/24/02/2402.14531.json",
    "total_tokens": 952,
    "translated_title": "我们应该尊重LLM吗？关于提示礼貌对LLM表现影响的跨语言研究",
    "translated_abstract": "我们调查了提示中的礼貌程度对大型语言模型（LLMs）表现的影响。在人类交流中，礼貌的语言通常能获得更多的遵从和有效性，而粗鲁可能导致厌恶，影响回应质量。我们认为LLMs反映了人类的交流特征，暗示它们与人类文化规范一致。我们评估了英语、中文和日语任务中提示中的礼貌对LLMs的影响。我们观察到，粗鲁的提示通常导致较差的表现，而过于礼貌的语言并不能保证更好的结果。最佳的礼貌程度根据语言而异。这一现象表明LLMs不仅反映人类行为，还受语言影响，尤其是在不同的文化背景下。我们的发现强调了在跨文化自然语言处理和LLM使用中考虑礼貌的必要性。",
    "tldr": "礼貌水平对LLMs的表现有影响，粗鲁的提示通常导致较差的表现，而过于礼貌的语言并不能保证更好的结果，最佳的礼貌水平根据语言而异，LLMs不仅反映人类行为，还受语言影响，尤其是在不同的文化背景下。",
    "en_tdlr": "Politeness levels in prompts influence LLM performance, with impolite prompts resulting in poor performance and overly polite language not guaranteeing better outcomes. The best politeness level varies by language, indicating that LLMs not only mirror human behavior but are also influenced by language, especially in different cultural contexts."
}