{
    "title": "Reimagining Anomalies: What If Anomalies Were Normal?",
    "abstract": "arXiv:2402.14469v1 Announce Type: cross  Abstract: Deep learning-based methods have achieved a breakthrough in image anomaly detection, but their complexity introduces a considerable challenge to understanding why an instance is predicted to be anomalous. We introduce a novel explanation method that generates multiple counterfactual examples for each anomaly, capturing diverse concepts of anomalousness. A counterfactual example is a modification of the anomaly that is perceived as normal by the anomaly detector. The method provides a high-level semantic explanation of the mechanism that triggered the anomaly detector, allowing users to explore \"what-if scenarios.\" Qualitative and quantitative analyses across various image datasets show that the method applied to state-of-the-art anomaly detectors can achieve high-quality semantic explanations of detectors.",
    "link": "https://arxiv.org/abs/2402.14469",
    "context": "Title: Reimagining Anomalies: What If Anomalies Were Normal?\nAbstract: arXiv:2402.14469v1 Announce Type: cross  Abstract: Deep learning-based methods have achieved a breakthrough in image anomaly detection, but their complexity introduces a considerable challenge to understanding why an instance is predicted to be anomalous. We introduce a novel explanation method that generates multiple counterfactual examples for each anomaly, capturing diverse concepts of anomalousness. A counterfactual example is a modification of the anomaly that is perceived as normal by the anomaly detector. The method provides a high-level semantic explanation of the mechanism that triggered the anomaly detector, allowing users to explore \"what-if scenarios.\" Qualitative and quantitative analyses across various image datasets show that the method applied to state-of-the-art anomaly detectors can achieve high-quality semantic explanations of detectors.",
    "path": "papers/24/02/2402.14469.json",
    "total_tokens": 747,
    "translated_title": "重新构想异常：如果异常是正常的呢？",
    "translated_abstract": "基于深度学习的方法在图像异常检测方面取得了突破，但其复杂性给理解为何实例被预测为异常带来了相当大的挑战。我们引入了一种新颖的解释方法，为每个异常生成多个反事实示例，捕获异常的多样概念。反事实示例是对异常的修改，被异常检测器视为正常。该方法提供了触发异常检测器机制的高级语义解释，允许用户探索“假设情景”。对不同图像数据集进行的定性和定量分析显示，该方法应用于最先进的异常检测器可以实现对检测器的高质量语义解释。",
    "tldr": "方法提出了一种新颖的解释方法，生成多个反事实示例以捕获异常的多样概念，为用户提供对触发异常检测器机制的高级语义解释，允许探索“假设情景”。",
    "en_tdlr": "The method introduces a novel explanation approach by generating multiple counterfactual examples to capture diverse concepts of anomalies, providing users with high-level semantic explanations of the mechanism triggering the anomaly detector and enabling exploration of \"what-if scenarios\"."
}