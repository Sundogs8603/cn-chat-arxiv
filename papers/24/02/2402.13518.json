{
    "title": "RITFIS: Robust input testing framework for LLMs-based intelligent software",
    "abstract": "arXiv:2402.13518v1 Announce Type: cross  Abstract: The dependence of Natural Language Processing (NLP) intelligent software on Large Language Models (LLMs) is increasingly prominent, underscoring the necessity for robustness testing. Current testing methods focus solely on the robustness of LLM-based software to prompts. Given the complexity and diversity of real-world inputs, studying the robustness of LLMbased software in handling comprehensive inputs (including prompts and examples) is crucial for a thorough understanding of its performance.   To this end, this paper introduces RITFIS, a Robust Input Testing Framework for LLM-based Intelligent Software. To our knowledge, RITFIS is the first framework designed to assess the robustness of LLM-based intelligent software against natural language inputs. This framework, based on given threat models and prompts, primarily defines the testing process as a combinatorial optimization problem. Successful test cases are determined by a goal fu",
    "link": "https://arxiv.org/abs/2402.13518",
    "context": "Title: RITFIS: Robust input testing framework for LLMs-based intelligent software\nAbstract: arXiv:2402.13518v1 Announce Type: cross  Abstract: The dependence of Natural Language Processing (NLP) intelligent software on Large Language Models (LLMs) is increasingly prominent, underscoring the necessity for robustness testing. Current testing methods focus solely on the robustness of LLM-based software to prompts. Given the complexity and diversity of real-world inputs, studying the robustness of LLMbased software in handling comprehensive inputs (including prompts and examples) is crucial for a thorough understanding of its performance.   To this end, this paper introduces RITFIS, a Robust Input Testing Framework for LLM-based Intelligent Software. To our knowledge, RITFIS is the first framework designed to assess the robustness of LLM-based intelligent software against natural language inputs. This framework, based on given threat models and prompts, primarily defines the testing process as a combinatorial optimization problem. Successful test cases are determined by a goal fu",
    "path": "papers/24/02/2402.13518.json",
    "total_tokens": 875,
    "translated_title": "RITFIS: RITFIS：基于LLMs的智能软件强壮输入测试框架",
    "translated_abstract": "arXiv:2402.13518v1 公告类型：交叉 摘要：自然语言处理（NLP）智能软件对大型语言模型（LLMs）的依赖日益突出，强调了对鲁棒性测试的必要性。当前的测试方法仅关注基于LLM的软件对提示的鲁棒性。鉴于现实世界输入的复杂性和多样性，研究LLM-based软件处理全面输入（包括提示和示例）的鲁棒性对于全面了解其性能至关重要。 为此，本文介绍了RITFIS，一种用于LLM-based智能软件的鲁棒输入测试框架。据我们所知，RITFIS是第一个旨在评估LLM-based智能软件对自然语言输入的鲁棒性的框架。该框架基于给定的威胁模型和提示，主要将测试过程定义为组合优化问题。成功的测试案例由一个目标函数决定",
    "tldr": "RITFIS是第一个设计用于评估基于LLM的智能软件对自然语言输入鲁棒性的框架，通过将测试过程定义为组合优化问题来确定成功的测试案例。",
    "en_tdlr": "RITFIS is the first framework designed to assess the robustness of LLM-based intelligent software against natural language inputs by defining the testing process as a combinatorial optimization problem."
}