{
    "title": "A Data Centric Approach for Unsupervised Domain Generalization via Retrieval from Web Scale Multimodal Data",
    "abstract": "Domain generalization (DG) is an important problem that learns a model that can generalize to unseen test domains leveraging one or more source domains, under the assumption of shared label spaces. However, most DG methods assume access to abundant source data in the target label space, a requirement that proves overly stringent for numerous real-world applications, where acquiring the same label space as the target task is prohibitively expensive. For this setting, we tackle the multimodal version of the unsupervised domain generalization (UDG) problem, which uses a large task-agnostic unlabeled source dataset, such as LAION-2B during finetuning. Our framework does not explicitly assume any relationship between the source dataset and target task. Instead, it relies only on the premise that the source dataset can be efficiently searched in a joint vision-language space. For this multimodal UDG setting, we propose a novel method to build a small ($<$100K) subset of the source data in th",
    "link": "https://arxiv.org/abs/2402.04416",
    "context": "Title: A Data Centric Approach for Unsupervised Domain Generalization via Retrieval from Web Scale Multimodal Data\nAbstract: Domain generalization (DG) is an important problem that learns a model that can generalize to unseen test domains leveraging one or more source domains, under the assumption of shared label spaces. However, most DG methods assume access to abundant source data in the target label space, a requirement that proves overly stringent for numerous real-world applications, where acquiring the same label space as the target task is prohibitively expensive. For this setting, we tackle the multimodal version of the unsupervised domain generalization (UDG) problem, which uses a large task-agnostic unlabeled source dataset, such as LAION-2B during finetuning. Our framework does not explicitly assume any relationship between the source dataset and target task. Instead, it relies only on the premise that the source dataset can be efficiently searched in a joint vision-language space. For this multimodal UDG setting, we propose a novel method to build a small ($<$100K) subset of the source data in th",
    "path": "papers/24/02/2402.04416.json",
    "total_tokens": 946,
    "translated_title": "基于大规模多模态数据检索的无监督领域泛化的数据中心方法",
    "translated_abstract": "领域泛化(DG)是一个重要的问题，它通过利用一个或多个源领域在共享标签空间的假设下学习一个能够推广到未见测试领域的模型。然而，大多数DG方法假设可以访问丰富的目标标签空间中的源数据，这个要求在许多现实应用中太过严格，因为获取与目标任务相同的标签空间费用高昂。为了解决这个问题，我们处理了无监督领域泛化(UDG)问题的多模态版本，该问题使用一个大型的任务无关的未标记的源数据集，例如LAION-2B在微调期间。我们的框架不显式地假设源数据集与目标任务之间存在任何关系。相反，它只依赖于源数据集可以在联合视觉-语言空间中高效搜索的前提。针对这种多模态UDG设置，我们提出了一种新的方法来构建一个小型（小于100K）的源数据子集。",
    "tldr": "该论文基于大规模多模态数据检索，提出了一个无监督领域泛化的数据中心方法。在多模态无监督领域泛化问题中，通过构建一个小型的源数据子集，而不是依赖丰富的源数据，来解决目标标签空间数据获取困难的问题。",
    "en_tdlr": "This paper presents a data-centric approach for unsupervised domain generalization using retrieval from web scale multimodal data. It proposes a method to build a small subset of the source data in the multimodal unsupervised domain generalization setting, instead of relying on abundant source data in the target label space."
}