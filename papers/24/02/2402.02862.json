{
    "title": "Graph Neural Machine: A New Model for Learning with Tabular Data",
    "abstract": "In recent years, there has been a growing interest in mapping data from different domains to graph structures. Among others, neural network models such as the multi-layer perceptron (MLP) can be modeled as graphs. In fact, MLPs can be represented as directed acyclic graphs. Graph neural networks (GNNs) have recently become the standard tool for performing machine learning tasks on graphs. In this work, we show that an MLP is equivalent to an asynchronous message passing GNN model which operates on the MLP's graph representation. We then propose a new machine learning model for tabular data, the so-called Graph Neural Machine (GNM), which replaces the MLP's directed acyclic graph with a nearly complete graph and which employs a synchronous message passing scheme. We show that a single GNM model can simulate multiple MLP models. We evaluate the proposed model in several classification and regression datasets. In most cases, the GNM model outperforms the MLP architecture.",
    "link": "https://arxiv.org/abs/2402.02862",
    "context": "Title: Graph Neural Machine: A New Model for Learning with Tabular Data\nAbstract: In recent years, there has been a growing interest in mapping data from different domains to graph structures. Among others, neural network models such as the multi-layer perceptron (MLP) can be modeled as graphs. In fact, MLPs can be represented as directed acyclic graphs. Graph neural networks (GNNs) have recently become the standard tool for performing machine learning tasks on graphs. In this work, we show that an MLP is equivalent to an asynchronous message passing GNN model which operates on the MLP's graph representation. We then propose a new machine learning model for tabular data, the so-called Graph Neural Machine (GNM), which replaces the MLP's directed acyclic graph with a nearly complete graph and which employs a synchronous message passing scheme. We show that a single GNM model can simulate multiple MLP models. We evaluate the proposed model in several classification and regression datasets. In most cases, the GNM model outperforms the MLP architecture.",
    "path": "papers/24/02/2402.02862.json",
    "total_tokens": 921,
    "translated_title": "图神经机器：一种处理表格数据的新模型",
    "translated_abstract": "近年来，人们对将不同领域的数据映射到图结构的方法越来越感兴趣。神经网络模型如多层感知机（MLP）可以被建模为图。事实上，MLP可以表示为有向无环图。图神经网络（GNN）最近已成为在图上执行机器学习任务的标准工具。在这项工作中，我们展示了MLP等价于一个基于异步消息传递的GNN模型，该模型在MLP的图表示上操作。然后，我们提出了一种新的处理表格数据的机器学习模型，称为图神经机器（GNM），它用一个几乎完全图取代了MLP的有向无环图，并采用同步消息传递方案。我们表明单个GNM模型可以模拟多个MLP模型。我们在多个分类和回归数据集上评估了所提出的模型。在大多数情况下，GNM模型优于MLP架构。",
    "tldr": "本论文提出了一种新的机器学习模型，图神经机器（GNM），用于处理表格数据。GNM使用同步消息传递方案，并用几乎完全图代替了多层感知机（MLP）的有向无环图。实验结果表明，在多个数据集上，GNM模型的性能优于MLP架构。"
}