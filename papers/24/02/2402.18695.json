{
    "title": "Grounding Language Models for Visual Entity Recognition",
    "abstract": "arXiv:2402.18695v1 Announce Type: cross  Abstract: We introduce AutoVER, an Autoregressive model for Visual Entity Recognition. Our model extends an autoregressive Multi-modal Large Language Model by employing retrieval augmented constrained generation. It mitigates low performance on out-of-domain entities while excelling in queries that require visually-situated reasoning. Our method learns to distinguish similar entities within a vast label space by contrastively training on hard negative pairs in parallel with a sequence-to-sequence objective without an external retriever. During inference, a list of retrieved candidate answers explicitly guides language generation by removing invalid decoding paths. The proposed method achieves significant improvements across different dataset splits in the recently proposed Oven-Wiki benchmark. Accuracy on the Entity seen split rises from 32.7% to 61.5%. It also demonstrates superior performance on the unseen and query splits by a substantial dou",
    "link": "https://arxiv.org/abs/2402.18695",
    "context": "Title: Grounding Language Models for Visual Entity Recognition\nAbstract: arXiv:2402.18695v1 Announce Type: cross  Abstract: We introduce AutoVER, an Autoregressive model for Visual Entity Recognition. Our model extends an autoregressive Multi-modal Large Language Model by employing retrieval augmented constrained generation. It mitigates low performance on out-of-domain entities while excelling in queries that require visually-situated reasoning. Our method learns to distinguish similar entities within a vast label space by contrastively training on hard negative pairs in parallel with a sequence-to-sequence objective without an external retriever. During inference, a list of retrieved candidate answers explicitly guides language generation by removing invalid decoding paths. The proposed method achieves significant improvements across different dataset splits in the recently proposed Oven-Wiki benchmark. Accuracy on the Entity seen split rises from 32.7% to 61.5%. It also demonstrates superior performance on the unseen and query splits by a substantial dou",
    "path": "papers/24/02/2402.18695.json",
    "total_tokens": 867,
    "translated_title": "将语言模型应用在视觉实体识别上",
    "translated_abstract": "我们引入AutoVER，一种用于视觉实体识别的自回归模型。我们的模型通过使用检索增强的约束生成，扩展了自回归多模式大型语言模型。它在处理跨领域实体时减轻了低性能，在需要视觉推理的查询中表现出色。我们的方法通过在硬负对上进行对比训练，并在序列-序列目标中并行进行训练，学习在巨大的标签空间中区分相似的实体。在推断过程中，一系列检索的候选答案明确指导语言生成，通过消除无效的解码路径。所提出的方法在最近提出的Oven-Wiki基准测试的不同数据集拆分中实现了显著的改进。在已知实体拆分上的准确率从32.7%提高到61.5%。该方法还通过大幅度提升在未知和查询拆分上的性能，表现出卓越的表现。",
    "tldr": "通过AutoVER模型，我们提出了一种在视觉实体识别中应用自回归模型的方法，通过检索增强的约束生成，成功区分巨大标签空间中相似的实体，并在Oven-Wiki基准测试上取得显著进展。",
    "en_tdlr": "We propose a method of applying autoregressive models in visual entity recognition with AutoVER, which successfully distinguishes similar entities within vast label spaces through retrieval-augmented constrained generation and achieves significant progress in the Oven-Wiki benchmark."
}