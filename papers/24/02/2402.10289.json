{
    "title": "Thompson Sampling in Partially Observable Contextual Bandits",
    "abstract": "arXiv:2402.10289v1 Announce Type: cross  Abstract: Contextual bandits constitute a classical framework for decision-making under uncertainty. In this setting, the goal is to learn the arms of highest reward subject to contextual information, while the unknown reward parameters of each arm need to be learned by experimenting that specific arm. Accordingly, a fundamental problem is that of balancing exploration (i.e., pulling different arms to learn their parameters), versus exploitation (i.e., pulling the best arms to gain reward). To study this problem, the existing literature mostly considers perfectly observed contexts. However, the setting of partial context observations remains unexplored to date, despite being theoretically more general and practically more versatile. We study bandit policies for learning to select optimal arms based on the data of observations, which are noisy linear functions of the unobserved context vectors. Our theoretical analysis shows that the Thompson sam",
    "link": "https://arxiv.org/abs/2402.10289",
    "context": "Title: Thompson Sampling in Partially Observable Contextual Bandits\nAbstract: arXiv:2402.10289v1 Announce Type: cross  Abstract: Contextual bandits constitute a classical framework for decision-making under uncertainty. In this setting, the goal is to learn the arms of highest reward subject to contextual information, while the unknown reward parameters of each arm need to be learned by experimenting that specific arm. Accordingly, a fundamental problem is that of balancing exploration (i.e., pulling different arms to learn their parameters), versus exploitation (i.e., pulling the best arms to gain reward). To study this problem, the existing literature mostly considers perfectly observed contexts. However, the setting of partial context observations remains unexplored to date, despite being theoretically more general and practically more versatile. We study bandit policies for learning to select optimal arms based on the data of observations, which are noisy linear functions of the unobserved context vectors. Our theoretical analysis shows that the Thompson sam",
    "path": "papers/24/02/2402.10289.json",
    "total_tokens": 827,
    "translated_title": "Thompson Sampling在部分可观察的上下文特征臂老虎机中的应用",
    "translated_abstract": "上下文特征臂老虎机构成了一个经典的不确定性决策框架。在这种情况下，目标是在上下文信息的条件下学习具有最高奖励的臂，同时需要通过实验来学习每个臂的未知奖励参数。因此，一个基本问题是在探索（即拉动不同臂以学习它们的参数）和开发（即拉动最佳臂以获得奖励）之间取得平衡。现有文献大多考虑完全观察到的上下文情境。然而，尽管在理论上更一般且在实践中更有多样性，但部分上下文观察情景至今仍未被探索。我们研究了在观察数据是未观察到的上下文向量的噪声线性函数的情况下学习选择最佳臂的老虎机策略。我们的理论分析表明Thompson采样算法...",
    "tldr": "研究了在部分观察到的上下文特征老虎机中使用Thompson Sampling策略，以学习选择最佳臂的问题",
    "en_tdlr": "Investigated the problem of using Thompson Sampling strategy in partially observable contextual bandits to learn to select optimal arms based on the data of observations."
}