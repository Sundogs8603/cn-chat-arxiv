{
    "title": "Reliable LLM-based User Simulator for Task-Oriented Dialogue Systems",
    "abstract": "arXiv:2402.13374v1 Announce Type: new  Abstract: In the realm of dialogue systems, user simulation techniques have emerged as a game-changer, redefining the evaluation and enhancement of task-oriented dialogue (TOD) systems. These methods are crucial for replicating real user interactions, enabling applications like synthetic data augmentation, error detection, and robust evaluation. However, existing approaches often rely on rigid rule-based methods or on annotated data. This paper introduces DAUS, a Domain-Aware User Simulator. Leveraging large language models, we fine-tune DAUS on real examples of task-oriented dialogues. Results on two relevant benchmarks showcase significant improvements in terms of user goal fulfillment. Notably, we have observed that fine-tuning enhances the simulator's coherence with user goals, effectively mitigating hallucinations -- a major source of inconsistencies in simulator responses.",
    "link": "https://arxiv.org/abs/2402.13374",
    "context": "Title: Reliable LLM-based User Simulator for Task-Oriented Dialogue Systems\nAbstract: arXiv:2402.13374v1 Announce Type: new  Abstract: In the realm of dialogue systems, user simulation techniques have emerged as a game-changer, redefining the evaluation and enhancement of task-oriented dialogue (TOD) systems. These methods are crucial for replicating real user interactions, enabling applications like synthetic data augmentation, error detection, and robust evaluation. However, existing approaches often rely on rigid rule-based methods or on annotated data. This paper introduces DAUS, a Domain-Aware User Simulator. Leveraging large language models, we fine-tune DAUS on real examples of task-oriented dialogues. Results on two relevant benchmarks showcase significant improvements in terms of user goal fulfillment. Notably, we have observed that fine-tuning enhances the simulator's coherence with user goals, effectively mitigating hallucinations -- a major source of inconsistencies in simulator responses.",
    "path": "papers/24/02/2402.13374.json",
    "total_tokens": 837,
    "translated_title": "可靠的基于LLM的面向任务对话系统用户模拟器",
    "translated_abstract": "在对话系统领域，用户模拟技术已经成为一个颠覆性的创新，重新定义了任务导向对话（TOD）系统的评估和增强。这些方法对于复制真实用户交互至关重要，实现了合成数据增强、错误检测和鲁棒评估等应用。然而，现有方法往往依赖于严格的基于规则的方法或已标记的数据。本文介绍了DAUS，一个领域感知用户模拟器。利用大型语言模型，我们在真实任务导向对话的示例上对DAUS进行了微调。在两个相关基准测试上的结果展示了用户目标实现方面的显著改进。值得注意的是，我们观察到微调增强了模拟器与用户目标的一致性，有效地缓解了幻觉——模拟器响应中一致性的主要来源。",
    "tldr": "该论文介绍了DAUS，一个基于LLM的领域感知用户模拟器，通过在真实对话示例上进行微调，显著改进了用户目标实现，并有效减轻模拟器响应中的幻觉。",
    "en_tdlr": "This paper introduces DAUS, a Domain-Aware User Simulator that leverages large language models and fine-tuning on real examples of task-oriented dialogues to significantly improve user goal fulfillment and effectively mitigate hallucinations in simulator responses."
}