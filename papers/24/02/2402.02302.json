{
    "title": "Predicting positive transfer for improved low-resource speech recognition using acoustic pseudo-tokens",
    "abstract": "While massively multilingual speech models like wav2vec 2.0 XLSR-128 can be directly fine-tuned for automatic speech recognition (ASR), downstream performance can still be relatively poor on languages that are under-represented in the pre-training data. Continued pre-training on 70-200 hours of untranscribed speech in these languages can help -- but what about languages without that much recorded data? For such cases, we show that supplementing the target language with data from a similar, higher-resource 'donor' language can help. For example, continued pre-training on only 10 hours of low-resource Punjabi supplemented with 60 hours of donor Hindi is almost as good as continued pretraining on 70 hours of Punjabi. By contrast, sourcing data from less similar donors like Bengali does not improve ASR performance. To inform donor language selection, we propose a novel similarity metric based on the sequence distribution of induced acoustic units: the Acoustic Token Distribution Similarity",
    "link": "https://arxiv.org/abs/2402.02302",
    "context": "Title: Predicting positive transfer for improved low-resource speech recognition using acoustic pseudo-tokens\nAbstract: While massively multilingual speech models like wav2vec 2.0 XLSR-128 can be directly fine-tuned for automatic speech recognition (ASR), downstream performance can still be relatively poor on languages that are under-represented in the pre-training data. Continued pre-training on 70-200 hours of untranscribed speech in these languages can help -- but what about languages without that much recorded data? For such cases, we show that supplementing the target language with data from a similar, higher-resource 'donor' language can help. For example, continued pre-training on only 10 hours of low-resource Punjabi supplemented with 60 hours of donor Hindi is almost as good as continued pretraining on 70 hours of Punjabi. By contrast, sourcing data from less similar donors like Bengali does not improve ASR performance. To inform donor language selection, we propose a novel similarity metric based on the sequence distribution of induced acoustic units: the Acoustic Token Distribution Similarity",
    "path": "papers/24/02/2402.02302.json",
    "total_tokens": 943,
    "translated_title": "使用声学伪令牌预测改善低资源语音识别的积极迁移",
    "translated_abstract": "尽管像wav2vec 2.0 XLSR-128这样的大规模多语言语音模型可以直接进行自动语音识别(ASR)的微调，但在预训练数据中低资源语言占比相对较低的情况下，下游性能仍然相对较差。对于没有太多录制数据的语言，我们展示了通过在目标语言中补充来自相似、高资源的“捐赠”语言的数据可以提升性能。例如，仅使用10小时的低资源旁遮普语进行持续预训练，并辅助使用60小时的捐赠语言印地语的效果几乎与使用70小时的旁遮普语进行持续预训练相当。相比之下，来自不太相似的捐赠语言（如孟加拉语）的数据则无法改善ASR的性能。为了选择捐赠语言，我们提出了一种基于诱导声学单元序列分布的新颖相似度度量方法：声学令牌分布相似度。",
    "tldr": "本论文提出了使用声学伪令牌来预测改善低资源语音识别的积极迁移。通过在目标语言中补充来自相似、高资源的“捐赠”语言的数据，可以提高低资源语言在自动语音识别任务上的性能。",
    "en_tdlr": "This paper proposes using acoustic pseudo-tokens to predict positive transfer for improved low-resource speech recognition. By supplementing the target language with data from a similar, higher-resource 'donor' language, performance in low-resource languages can be enhanced in automatic speech recognition tasks."
}