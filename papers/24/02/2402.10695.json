{
    "title": "Unlink to Unlearn: Simplifying Edge Unlearning in GNNs",
    "abstract": "arXiv:2402.10695v1 Announce Type: cross  Abstract: As concerns over data privacy intensify, unlearning in Graph Neural Networks (GNNs) has emerged as a prominent research frontier in academia. This concept is pivotal in enforcing the right to be forgotten, which entails the selective removal of specific data from trained GNNs upon user request. Our research focuses on edge unlearning, a process of particular relevance to real-world applications, owing to its widespread applicability. Current state-of-the-art approaches like GNNDelete can eliminate the influence of specific edges, yet our research has revealed a critical limitation in these approaches, termed over-forgetting. It occurs when the unlearning process inadvertently removes excessive information beyond specific data, leading to a significant decline in prediction accuracy for the remaining edges. To address this issue, we have identified the loss functions of GNNDelete as the primary source of the over-forgetting phenomenon. ",
    "link": "https://arxiv.org/abs/2402.10695",
    "context": "Title: Unlink to Unlearn: Simplifying Edge Unlearning in GNNs\nAbstract: arXiv:2402.10695v1 Announce Type: cross  Abstract: As concerns over data privacy intensify, unlearning in Graph Neural Networks (GNNs) has emerged as a prominent research frontier in academia. This concept is pivotal in enforcing the right to be forgotten, which entails the selective removal of specific data from trained GNNs upon user request. Our research focuses on edge unlearning, a process of particular relevance to real-world applications, owing to its widespread applicability. Current state-of-the-art approaches like GNNDelete can eliminate the influence of specific edges, yet our research has revealed a critical limitation in these approaches, termed over-forgetting. It occurs when the unlearning process inadvertently removes excessive information beyond specific data, leading to a significant decline in prediction accuracy for the remaining edges. To address this issue, we have identified the loss functions of GNNDelete as the primary source of the over-forgetting phenomenon. ",
    "path": "papers/24/02/2402.10695.json",
    "total_tokens": 848,
    "translated_title": "与遗忘呼应的解除链接：简化GNN中的边解除",
    "translated_abstract": "随着对数据隐私的担忧加剧，图神经网络（GNN）中的解除学习已经成为学术界一个突出的研究前沿。这一概念在强调被遗忘权利方面起着关键作用，包括在用户请求时有选择性地从已训练的GNN中删除特定数据。我们的研究关注边的解除学习，这一过程对现实应用特别相关，因为它具有广泛的适用性。目前的最先进方法如GNNDelete可以消除特定边的影响，然而我们的研究揭示了这些方法的一个关键局限，称为过度遗忘。当解除学习过程无意中除去超出特定数据的过多信息时，会导致对剩余边的预测准确性显著下降。为了解决这个问题，我们确定了GNNDelete的损失函数作为过度遗忘现象的主要来源。",
    "tldr": "研究揭示了GNN中边解除过程的关键问题，即过度遗忘现象，提出了解决方法来解决损失函数引起的问题。",
    "en_tdlr": "The research identifies a critical issue in edge unlearning in GNNs, termed over-forgetting, and proposes a solution to address the problem caused by loss functions."
}