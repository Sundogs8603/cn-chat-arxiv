{
    "title": "(A)I Am Not a Lawyer, But...: Engaging Legal Experts towards Responsible LLM Policies for Legal Advice",
    "abstract": "The rapid proliferation of large language models (LLMs) as general purpose chatbots available to the public raises hopes around expanding access to professional guidance in law, medicine, and finance, while triggering concerns about public reliance on LLMs for high-stakes circumstances. Prior research has speculated on high-level ethical considerations but lacks concrete criteria determining when and why LLM chatbots should or should not provide professional assistance. Through examining the legal domain, we contribute a structured expert analysis to uncover nuanced policy considerations around using LLMs for professional advice, using methods inspired by case-based reasoning. We convened workshops with 20 legal experts and elicited dimensions on appropriate AI assistance for sample user queries (``cases''). We categorized our expert dimensions into: (1) user attributes, (2) query characteristics, (3) AI capabilities, and (4) impacts. Beyond known issues like hallucinations, experts re",
    "link": "https://arxiv.org/abs/2402.01864",
    "context": "Title: (A)I Am Not a Lawyer, But...: Engaging Legal Experts towards Responsible LLM Policies for Legal Advice\nAbstract: The rapid proliferation of large language models (LLMs) as general purpose chatbots available to the public raises hopes around expanding access to professional guidance in law, medicine, and finance, while triggering concerns about public reliance on LLMs for high-stakes circumstances. Prior research has speculated on high-level ethical considerations but lacks concrete criteria determining when and why LLM chatbots should or should not provide professional assistance. Through examining the legal domain, we contribute a structured expert analysis to uncover nuanced policy considerations around using LLMs for professional advice, using methods inspired by case-based reasoning. We convened workshops with 20 legal experts and elicited dimensions on appropriate AI assistance for sample user queries (``cases''). We categorized our expert dimensions into: (1) user attributes, (2) query characteristics, (3) AI capabilities, and (4) impacts. Beyond known issues like hallucinations, experts re",
    "path": "papers/24/02/2402.01864.json",
    "total_tokens": 986,
    "translated_title": "(A)我不是律师, 但是...: 向律师专家制定负责任的法律咨询的LLM政策",
    "translated_abstract": "大型语言模型(LLM)作为通用聊天机器人迅速扩散, 带来了扩大公众获得法律、医学和金融专业指导的希望, 同时引发了公众对LLM在重大事件中的依赖的担忧。之前的研究猜测了高层次的伦理考虑, 但缺乏具体的标准来确定LLM聊天机器人何时以及为什么应该或不应该提供专业帮助。通过研究法律领域, 我们进行了结构化的专家分析, 以发现关于使用LLM进行专业咨询的政策考虑的细微差别, 并采用案例推理的方法。我们与20名法律专家召开了研讨会, 并从样本用户查询(\"案例\")中提取出适当的AI辅助的维度。我们将专业维度分为: (1)用户属性, (2)查询特征, (3)AI能力, 和 (4)影响。除了已知的问题, 如幻觉, 专家们还",
    "tldr": "通过对法律领域进行调查，我们对使用大型语言模型（LLM）提供专业咨询的政策考虑进行了深入分析，通过基于案例的推理方法，从20名法律专家的讨论中提取了四个影响因素：用户属性、查询特征、AI能力和影响。",
    "en_tdlr": "We conducted a structured expert analysis on the use of large language models (LLMs) for professional advice in the legal domain, gathering input from 20 legal experts. Through case-based reasoning, we identified four factors that influence the appropriateness of AI assistance: user attributes, query characteristics, AI capabilities, and impacts."
}