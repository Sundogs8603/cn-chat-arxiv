{
    "title": "INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection",
    "abstract": "Knowledge hallucination have raised widespread concerns for the security and reliability of deployed LLMs. Previous efforts in detecting hallucinations have been employed at logit-level uncertainty estimation or language-level self-consistency evaluation, where the semantic information is inevitably lost during the token-decoding procedure. Thus, we propose to explore the dense semantic information retained within LLMs' \\textbf{IN}ternal \\textbf{S}tates for halluc\\textbf{I}nation \\textbf{DE}tection (\\textbf{INSIDE}). In particular, a simple yet effective \\textbf{EigenScore} metric is proposed to better evaluate responses' self-consistency, which exploits the eigenvalues of responses' covariance matrix to measure the semantic consistency/diversity in the dense embedding space. Furthermore, from the perspective of self-consistent hallucination detection, a test time feature clipping approach is explored to truncate extreme activations in the internal states, which reduces overconfident g",
    "link": "https://arxiv.org/abs/2402.03744",
    "context": "Title: INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection\nAbstract: Knowledge hallucination have raised widespread concerns for the security and reliability of deployed LLMs. Previous efforts in detecting hallucinations have been employed at logit-level uncertainty estimation or language-level self-consistency evaluation, where the semantic information is inevitably lost during the token-decoding procedure. Thus, we propose to explore the dense semantic information retained within LLMs' \\textbf{IN}ternal \\textbf{S}tates for halluc\\textbf{I}nation \\textbf{DE}tection (\\textbf{INSIDE}). In particular, a simple yet effective \\textbf{EigenScore} metric is proposed to better evaluate responses' self-consistency, which exploits the eigenvalues of responses' covariance matrix to measure the semantic consistency/diversity in the dense embedding space. Furthermore, from the perspective of self-consistent hallucination detection, a test time feature clipping approach is explored to truncate extreme activations in the internal states, which reduces overconfident g",
    "path": "papers/24/02/2402.03744.json",
    "total_tokens": 902,
    "translated_title": "INSIDE: LLMs的内部状态保留了幻觉检测的能力",
    "translated_abstract": "知识幻觉对部署的LLMs的安全性和可靠性提出了广泛关注。先前的努力主要集中在对幻觉的检测上，采用了逻辑级别的不确定性估计或语言级别的自洽性评估，在解码过程中不可避免地丢失了语义信息。因此，我们提出探索LLMs内部状态中保留的密集语义信息用于幻觉检测（INSIDE）。具体而言，我们提出了一种简单而有效的EigenScore度量方法，以更好地评估回答的自洽性，它利用回答的协方差矩阵的特征值来衡量密集嵌入空间中的语义一致性/多样性。此外，从自洽的幻觉检测角度出发，我们探索了一种测试时间的特征剪切方法，用于截断内部状态中的极端激活，以减少过度自信的估计。",
    "tldr": "该论文提出了一种在LLMs内部状态中保留密集语义信息的方法来进行幻觉检测。通过使用EigenScore度量方法评估回答的自洽性，并探索测试时间的特征剪切方法，以减少过度自信的估计。",
    "en_tdlr": "This paper proposes a method for hallucination detection in LLMs using dense semantic information retained in their internal states. It introduces EigenScore metric to evaluate responses' self-consistency and explores a test time feature clipping approach to reduce overconfident estimations."
}