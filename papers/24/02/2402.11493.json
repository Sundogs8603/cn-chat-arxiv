{
    "title": "Benchmarking Knowledge Boundary for Large Language Model: A Different Perspective on Model Evaluation",
    "abstract": "arXiv:2402.11493v1 Announce Type: new  Abstract: In recent years, substantial advancements have been made in the development of large language models, achieving remarkable performance across diverse tasks. To evaluate the knowledge ability of language models, previous studies have proposed lots of benchmarks based on question-answering pairs. We argue that it is not reliable and comprehensive to evaluate language models with a fixed question or limited paraphrases as the query, since language models are sensitive to prompt. Therefore, we introduce a novel concept named knowledge boundary to encompass both prompt-agnostic and prompt-sensitive knowledge within language models. Knowledge boundary avoids prompt sensitivity in language model evaluations, rendering them more dependable and robust. To explore the knowledge boundary for a given model, we propose projected gradient descent method with semantic constraints, a new algorithm designed to identify the optimal prompt for each piece o",
    "link": "https://arxiv.org/abs/2402.11493",
    "context": "Title: Benchmarking Knowledge Boundary for Large Language Model: A Different Perspective on Model Evaluation\nAbstract: arXiv:2402.11493v1 Announce Type: new  Abstract: In recent years, substantial advancements have been made in the development of large language models, achieving remarkable performance across diverse tasks. To evaluate the knowledge ability of language models, previous studies have proposed lots of benchmarks based on question-answering pairs. We argue that it is not reliable and comprehensive to evaluate language models with a fixed question or limited paraphrases as the query, since language models are sensitive to prompt. Therefore, we introduce a novel concept named knowledge boundary to encompass both prompt-agnostic and prompt-sensitive knowledge within language models. Knowledge boundary avoids prompt sensitivity in language model evaluations, rendering them more dependable and robust. To explore the knowledge boundary for a given model, we propose projected gradient descent method with semantic constraints, a new algorithm designed to identify the optimal prompt for each piece o",
    "path": "papers/24/02/2402.11493.json",
    "total_tokens": 838,
    "translated_title": "基于大语言模型的知识边界基准：对模型评估的另一种视角",
    "translated_abstract": "最近几年，在大语言模型的发展中取得了实质性进展，在各种任务中取得了显著的性能。为了评估语言模型的知识能力，先前的研究提出了许多基于问答对的基准。我们认为，使用固定问题或有限的释义作为查询来评估语言模型是不可靠和全面的，因为语言模型对提示很敏感。因此，我们引入了一个名为知识边界的新概念，以包含语言模型内的无提示和有提示敏感性知识。知识边界避免了语言模型评估中的提示敏感性，使其更可靠和稳健。为了探索给定模型的知识边界，我们提出了带有语义约束的投影梯度下降方法，这是一种旨在识别每个部分的最佳提示的新算法。",
    "tldr": "引入了知识边界的概念，以涵盖语言模型内的无提示和有提示敏感性知识，通过避免提示敏感性，使得语言模型评估更可靠和稳健。"
}