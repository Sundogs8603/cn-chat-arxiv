{
    "title": "Symbol Correctness in Deep Neural Networks Containing Symbolic Layers",
    "abstract": "To handle AI tasks that combine perception and logical reasoning, recent work introduces Neurosymbolic Deep Neural Networks (NS-DNNs), which contain -- in addition to traditional neural layers -- symbolic layers: symbolic expressions (e.g., SAT formulas, logic programs) that are evaluated by symbolic solvers during inference. We identify and formalize an intuitive, high-level principle that can guide the design and analysis of NS-DNNs: symbol correctness, the correctness of the intermediate symbols predicted by the neural layers with respect to a (generally unknown) ground-truth symbolic representation of the input data. We demonstrate that symbol correctness is a necessary property for NS-DNN explainability and transfer learning (despite being in general impossible to train for). Moreover, we show that the framework of symbol correctness provides a precise way to reason and communicate about model behavior at neural-symbolic boundaries, and gives insight into the fundamental tradeoffs",
    "link": "https://arxiv.org/abs/2402.03663",
    "context": "Title: Symbol Correctness in Deep Neural Networks Containing Symbolic Layers\nAbstract: To handle AI tasks that combine perception and logical reasoning, recent work introduces Neurosymbolic Deep Neural Networks (NS-DNNs), which contain -- in addition to traditional neural layers -- symbolic layers: symbolic expressions (e.g., SAT formulas, logic programs) that are evaluated by symbolic solvers during inference. We identify and formalize an intuitive, high-level principle that can guide the design and analysis of NS-DNNs: symbol correctness, the correctness of the intermediate symbols predicted by the neural layers with respect to a (generally unknown) ground-truth symbolic representation of the input data. We demonstrate that symbol correctness is a necessary property for NS-DNN explainability and transfer learning (despite being in general impossible to train for). Moreover, we show that the framework of symbol correctness provides a precise way to reason and communicate about model behavior at neural-symbolic boundaries, and gives insight into the fundamental tradeoffs",
    "path": "papers/24/02/2402.03663.json",
    "total_tokens": 918,
    "translated_title": "深度神经网络中包含符号层的符号正确性",
    "translated_abstract": "为了处理以感知和逻辑推理相结合的人工智能任务，最近的工作引入了神经符号深度神经网络（NS-DNNs），它们除了传统的神经层之外，还包含符号层：在推理过程中由符号求解器评估的符号表达式（例如，SAT公式，逻辑程序）。我们确定并形式化了一种直观、高层次的原则，可以指导NS-DNNs的设计和分析：符号正确性，即神经层对中间符号的正确性，相对于输入数据的（通常未知的）基本符号表示。我们证明了符号正确性是NS-DNN可解释性和迁移学习的必要特性（尽管通常无法进行训练）。此外，我们还展示了符号正确性框架在神经符号边界处推理和交流模型行为方面提供了一种精确的方法，并对基本权衡有了深入的理解。",
    "tldr": "本文介绍了神经符号深度神经网络（NS-DNNs）中的符号正确性原则，即用于推理的神经层对中间符号的预测必须与输入数据的符号表示相匹配。符号正确性是NS-DNN可解释性和迁移学习的必要特性，并为推理和交流模型行为提供了精确的方法。",
    "en_tdlr": "This paper introduces the principle of symbol correctness in Neurosymbolic Deep Neural Networks (NS-DNNs), stating that the predictions of the neural layers for intermediate symbols must match the symbolic representation of the input data. Symbol correctness is a necessary property for explainability and transfer learning in NS-DNNs, and provides a precise way to reason and communicate about model behavior."
}