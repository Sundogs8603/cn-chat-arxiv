{
    "title": "Mitigating Reward Hacking via Information-Theoretic Reward Modeling",
    "abstract": "arXiv:2402.09345v1 Announce Type: cross Abstract: Despite the success of reinforcement learning from human feedback (RLHF) in aligning language models with human values, reward hacking, also termed reward overoptimization, remains a critical challenge, which primarily stems from limitations in reward modeling, i.e., generalizability of the reward model and inconsistency in the preference dataset. In this work, we tackle this problem from an information theoretic-perspective, and propose a generalizable and robust framework for reward modeling, namely InfoRM, by introducing a variational information bottleneck objective to filter out irrelevant information and developing a mechanism for model complexity modulation. Notably, we further identify a correlation between overoptimization and outliers in the latent space, establishing InfoRM as a promising tool for detecting reward overoptimization. Inspired by this finding, we propose the Integrated Cluster Deviation Score (ICDS), which quant",
    "link": "https://arxiv.org/abs/2402.09345",
    "context": "Title: Mitigating Reward Hacking via Information-Theoretic Reward Modeling\nAbstract: arXiv:2402.09345v1 Announce Type: cross Abstract: Despite the success of reinforcement learning from human feedback (RLHF) in aligning language models with human values, reward hacking, also termed reward overoptimization, remains a critical challenge, which primarily stems from limitations in reward modeling, i.e., generalizability of the reward model and inconsistency in the preference dataset. In this work, we tackle this problem from an information theoretic-perspective, and propose a generalizable and robust framework for reward modeling, namely InfoRM, by introducing a variational information bottleneck objective to filter out irrelevant information and developing a mechanism for model complexity modulation. Notably, we further identify a correlation between overoptimization and outliers in the latent space, establishing InfoRM as a promising tool for detecting reward overoptimization. Inspired by this finding, we propose the Integrated Cluster Deviation Score (ICDS), which quant",
    "path": "papers/24/02/2402.09345.json",
    "total_tokens": 920,
    "translated_title": "通过信息论奖励建模来减轻奖励作弊问题",
    "translated_abstract": "尽管强化学习从人类反馈（RLHF）中的成功在与人类价值观的语言模型的对齐方面，奖励作弊问题，也被称为奖励过度优化，仍然是一个关键挑战，主要源于奖励建模的局限性，即奖励模型的泛化能力和偏好数据集的不一致性。在这项工作中，我们从信息论的视角来解决这个问题，并提出了一种可推广和鲁棒的奖励建模框架，称为InfoRM，通过引入变分信息瓶颈目标来过滤出不相关的信息，并开发一种模型复杂度调节机制。值得注意的是，我们进一步发现了过度优化与潜变量空间的异常值之间的相关性，将InfoRM作为检测奖励过度优化的一种有前途的工具。受到这一发现的启发，我们提出了集成聚类偏差得分（ICDS），用于量化过优化问题。",
    "tldr": "本文提出了一种名为InfoRM的奖励建模框架，通过引入变分信息瓶颈目标和模型复杂度调节机制，解决了奖励作弊问题，并利用集成聚类偏差得分（ICDS）来检测奖励过度优化。"
}