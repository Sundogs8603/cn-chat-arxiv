{
    "title": "Reformatted Alignment",
    "abstract": "arXiv:2402.12219v1 Announce Type: cross  Abstract: The quality of finetuning data is crucial for aligning large language models (LLMs) with human values. Current methods to improve data quality are either labor-intensive or prone to factual errors caused by LLM hallucinations. This paper explores elevating the quality of existing instruction data to better align with human values, introducing a simple and effective approach named ReAlign, which reformats the responses of instruction data into a format that better aligns with pre-established criteria and the collated evidence. This approach minimizes human annotation, hallucination, and the difficulty in scaling, remaining orthogonal to existing alignment techniques. Experimentally, ReAlign significantly boosts the general alignment ability, math reasoning, factuality, and readability of the LLMs.   Encouragingly, without introducing any additional data or advanced training techniques, and merely by reformatting the response, LLaMA-2-13",
    "link": "https://arxiv.org/abs/2402.12219",
    "context": "Title: Reformatted Alignment\nAbstract: arXiv:2402.12219v1 Announce Type: cross  Abstract: The quality of finetuning data is crucial for aligning large language models (LLMs) with human values. Current methods to improve data quality are either labor-intensive or prone to factual errors caused by LLM hallucinations. This paper explores elevating the quality of existing instruction data to better align with human values, introducing a simple and effective approach named ReAlign, which reformats the responses of instruction data into a format that better aligns with pre-established criteria and the collated evidence. This approach minimizes human annotation, hallucination, and the difficulty in scaling, remaining orthogonal to existing alignment techniques. Experimentally, ReAlign significantly boosts the general alignment ability, math reasoning, factuality, and readability of the LLMs.   Encouragingly, without introducing any additional data or advanced training techniques, and merely by reformatting the response, LLaMA-2-13",
    "path": "papers/24/02/2402.12219.json",
    "total_tokens": 836,
    "translated_title": "重新格式化对齐",
    "translated_abstract": "优化微调数据对于将大型语言模型（LLMs）与人类价值观对齐至关重要。当前改善数据质量的方法要么耗时费力，要么容易受到LLM幻觉引起的事实错误影响。本文探讨提升现有指导数据质量以更好地与人类价值观对齐的方法，引入了一种名为ReAlign的简单有效方法，它将指导数据的响应重新格式化为更符合预先建立标准和编译证据的格式。该方法最小化了人类注释、幻觉和扩展困难，与现有对齐技术正交。实验结果表明，ReAlign显著提升了LLMs的整体对齐能力、数学推理、事实性和可读性。令人鼓舞的是，在不引入任何额外数据或先进训练技术的情况下，仅通过重新格式化响应，LLaMA-2-13",
    "tldr": "本文提出了一种名为ReAlign的简单有效方法，通过重新格式化指导数据的响应，显著提升了大型语言模型（LLMs）与人类价值观的对齐能力。",
    "en_tdlr": "This paper introduces a simple and effective approach named ReAlign, which significantly boosts the alignment ability of large language models (LLMs) with human values by reformatting the responses of instruction data."
}