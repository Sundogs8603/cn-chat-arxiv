{
    "title": "Intersectional Two-sided Fairness in Recommendation",
    "abstract": "Fairness of recommender systems (RS) has attracted increasing attention recently. Based on the involved stakeholders, the fairness of RS can be divided into user fairness, item fairness, and two-sided fairness which considers both user and item fairness simultaneously. However, we argue that the intersectional two-sided unfairness may still exist even if the RS is two-sided fair, which is observed and shown by empirical studies on real-world data in this paper, and has not been well-studied previously. To mitigate this problem, we propose a novel approach called Intersectional Two-sided Fairness Recommendation (ITFR). Our method utilizes a sharpness-aware loss to perceive disadvantaged groups, and then uses collaborative loss balance to develop consistent distinguishing abilities for different intersectional groups. Additionally, predicted score normalization is leveraged to align positive predicted scores to fairly treat positives in different intersectional groups. Extensive experime",
    "link": "https://arxiv.org/abs/2402.02816",
    "context": "Title: Intersectional Two-sided Fairness in Recommendation\nAbstract: Fairness of recommender systems (RS) has attracted increasing attention recently. Based on the involved stakeholders, the fairness of RS can be divided into user fairness, item fairness, and two-sided fairness which considers both user and item fairness simultaneously. However, we argue that the intersectional two-sided unfairness may still exist even if the RS is two-sided fair, which is observed and shown by empirical studies on real-world data in this paper, and has not been well-studied previously. To mitigate this problem, we propose a novel approach called Intersectional Two-sided Fairness Recommendation (ITFR). Our method utilizes a sharpness-aware loss to perceive disadvantaged groups, and then uses collaborative loss balance to develop consistent distinguishing abilities for different intersectional groups. Additionally, predicted score normalization is leveraged to align positive predicted scores to fairly treat positives in different intersectional groups. Extensive experime",
    "path": "papers/24/02/2402.02816.json",
    "total_tokens": 1034,
    "translated_title": "推荐系统中的交叉双边公平性",
    "translated_abstract": "近年来，推荐系统的公平性引起了越来越多的关注。根据涉及的利益相关者，推荐系统的公平性可分为用户公平性、物品公平性和同时考虑用户和物品公平性的双边公平性。然而，我们认为即使推荐系统是双边公平的，交叉双边不公平仍然可能存在，这在本文使用真实世界数据的实证研究中得到了观察和展示，并且以前尚未得到很好的研究。为了缓解这个问题，我们提出了一种新方法，称为交叉双边公平推荐（ITFR）。我们的方法利用一个锐度感知损失来感知劣势群体，然后使用协作损失平衡来开发不同交叉群体的一致区分能力。此外，我们利用预测得分归一化来调整正面预测得分，以公平地对待不同交叉群体中的正例。广泛的实验结果表明，我们的方法在提高交叉双边公平性方面取得了显著的效果。",
    "tldr": "本文针对推荐系统中的交叉双边公平性问题，提出了一种名为交叉双边公平推荐（ITFR）的新方法，通过利用锐度感知损失感知劣势群体，使用协作损失平衡开发不同交叉群体的一致区分能力，并利用预测得分归一化来公平对待不同交叉群体中的正例。实验证明该方法在提高交叉双边公平性方面取得了显著效果。",
    "en_tdlr": "This paper proposes a novel approach called Intersectional Two-sided Fairness Recommendation (ITFR) to address the intersectional two-sided fairness problem in recommender systems. Our method utilizes a sharpness-aware loss to perceive disadvantaged groups, develops consistent distinguishing abilities for different intersectional groups through collaborative loss balance, and employs predicted score normalization to treat positives fairly in different intersectional groups. Extensive experiments demonstrate the significant effectiveness of our method in improving intersectional two-sided fairness."
}