{
    "title": "Minimax Optimality of Score-based Diffusion Models: Beyond the Density Lower Bound Assumptions",
    "abstract": "arXiv:2402.15602v1 Announce Type: cross  Abstract: We study the asymptotic error of score-based diffusion model sampling in large-sample scenarios from a non-parametric statistics perspective. We show that a kernel-based score estimator achieves an optimal mean square error of $\\widetilde{O}\\left(n^{-1} t^{-\\frac{d+2}{2}}(t^{\\frac{d}{2}} \\vee 1)\\right)$ for the score function of $p_0*\\mathcal{N}(0,t\\boldsymbol{I}_d)$, where $n$ and $d$ represent the sample size and the dimension, $t$ is bounded above and below by polynomials of $n$, and $p_0$ is an arbitrary sub-Gaussian distribution. As a consequence, this yields an $\\widetilde{O}\\left(n^{-1/2} t^{-\\frac{d}{4}}\\right)$ upper bound for the total variation error of the distribution of the sample generated by the diffusion model under a mere sub-Gaussian assumption. If in addition, $p_0$ belongs to the nonparametric family of the $\\beta$-Sobolev space with $\\beta\\le 2$, by adopting an early stopping strategy, we obtain that the diffusion",
    "link": "https://arxiv.org/abs/2402.15602",
    "context": "Title: Minimax Optimality of Score-based Diffusion Models: Beyond the Density Lower Bound Assumptions\nAbstract: arXiv:2402.15602v1 Announce Type: cross  Abstract: We study the asymptotic error of score-based diffusion model sampling in large-sample scenarios from a non-parametric statistics perspective. We show that a kernel-based score estimator achieves an optimal mean square error of $\\widetilde{O}\\left(n^{-1} t^{-\\frac{d+2}{2}}(t^{\\frac{d}{2}} \\vee 1)\\right)$ for the score function of $p_0*\\mathcal{N}(0,t\\boldsymbol{I}_d)$, where $n$ and $d$ represent the sample size and the dimension, $t$ is bounded above and below by polynomials of $n$, and $p_0$ is an arbitrary sub-Gaussian distribution. As a consequence, this yields an $\\widetilde{O}\\left(n^{-1/2} t^{-\\frac{d}{4}}\\right)$ upper bound for the total variation error of the distribution of the sample generated by the diffusion model under a mere sub-Gaussian assumption. If in addition, $p_0$ belongs to the nonparametric family of the $\\beta$-Sobolev space with $\\beta\\le 2$, by adopting an early stopping strategy, we obtain that the diffusion",
    "path": "papers/24/02/2402.15602.json",
    "total_tokens": 1053,
    "translated_title": "基于分数的扩散模型的极小化最优性：超越密度下界假设",
    "translated_abstract": "我们从非参数统计的角度研究了在大样本场景下得分扩散模型抽样的渐近误差。我们展示了基于核的得分估计器可以实现对 $p_0*\\mathcal{N}(0,t\\boldsymbol{I}_d)$ 的得分函数的最优均方误差为 $\\widetilde{O}\\left(n^{-1} t^{-\\frac{d+2}{2}}(t^{\\frac{d}{2}} \\vee 1)\\right)$，其中 $n$ 和 $d$ 分别代表样本大小和维度，$t$ 在上下受到 $n$ 的多项式的限制，并且 $p_0$ 是任意次亚高斯分布。因此，这导致在仅进行次高斯假设时，扩散模型生成的样本分布的总变差误差的上界为 $\\widetilde{O}\\left(n^{-1/2} t^{-\\frac{d}{4}}\\right)$。如果此外，$p_0$ 属于 $\\beta\\le 2$ 的 $\\beta$-Sobolev空间的非参数族，通过采用早停策略，我们得到该扩散模型的样本的分布的总变差误差的上界为 $\\widetilde{O}\\left(n^{-1/2} t^{-\\frac{d}{4}}\\right)$。",
    "tldr": "该研究展示了基于分数的扩散模型的采样具有极小均方误差，可以获得扩散模型生成样本的总变差误差的上界，这突破了仅做次高斯假设的限制。",
    "en_tdlr": "The study demonstrates that score-based diffusion model sampling achieves minimal mean square error and provides an upper bound on the total variation error of the generated samples, beyond the limitation of only making sub-Gaussian assumptions."
}