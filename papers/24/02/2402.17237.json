{
    "title": "Image-Text Matching with Multi-View Attention",
    "abstract": "arXiv:2402.17237v1 Announce Type: cross  Abstract: Existing two-stream models for image-text matching show good performance while ensuring retrieval speed and have received extensive attention from industry and academia. These methods use a single representation to encode image and text separately and get a matching score with cosine similarity or the inner product of vectors. However, the performance of the two-stream model is often sub-optimal. On the one hand, a single representation is challenging to cover complex content comprehensively. On the other hand, in this framework of lack of interaction, it is challenging to match multiple meanings which leads to information being ignored. To address the problems mentioned above and facilitate the performance of the two-stream model, we propose a multi-view attention approach for two-stream image-text matching MVAM (\\textbf{M}ulti-\\textbf{V}iew \\textbf{A}ttention \\textbf{M}odel). It first learns multiple image and text representations by",
    "link": "https://arxiv.org/abs/2402.17237",
    "context": "Title: Image-Text Matching with Multi-View Attention\nAbstract: arXiv:2402.17237v1 Announce Type: cross  Abstract: Existing two-stream models for image-text matching show good performance while ensuring retrieval speed and have received extensive attention from industry and academia. These methods use a single representation to encode image and text separately and get a matching score with cosine similarity or the inner product of vectors. However, the performance of the two-stream model is often sub-optimal. On the one hand, a single representation is challenging to cover complex content comprehensively. On the other hand, in this framework of lack of interaction, it is challenging to match multiple meanings which leads to information being ignored. To address the problems mentioned above and facilitate the performance of the two-stream model, we propose a multi-view attention approach for two-stream image-text matching MVAM (\\textbf{M}ulti-\\textbf{V}iew \\textbf{A}ttention \\textbf{M}odel). It first learns multiple image and text representations by",
    "path": "papers/24/02/2402.17237.json",
    "total_tokens": 804,
    "translated_title": "使用多视图注意力的图像文本匹配",
    "translated_abstract": "现有的用于图像文本匹配的双流模型在确保检索速度的同时表现出良好的性能，并受到工业界和学术界的广泛关注。这些方法使用单一表示来分别编码图像和文本，并使用余弦相似度或向量内积得到匹配分数。然而，双流模型的性能往往不太理想。一方面，单一表示难以全面覆盖复杂内容。另一方面，在这种缺乏交互的框架中，匹配多重含义是具有挑战性的，这导致信息被忽略。为了解决上述问题并促进双流模型的性能，我们提出了一种双流图像文本匹配的多视图注意力方法MVAM（多视图注意力模型）。",
    "tldr": "本研究提出了一种使用多视图注意力的双流图像文本匹配方法，以解决单一表示难以全面覆盖复杂内容和缺乏交互的挑战。",
    "en_tdlr": "This study introduces a multi-view attention approach for two-stream image-text matching to address challenges such as the inability of a single representation to cover complex content comprehensively and lack of interaction."
}