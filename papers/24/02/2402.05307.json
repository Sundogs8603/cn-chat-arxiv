{
    "title": "Three Pathways to Neurosymbolic Reinforcement Learning with Interpretable Model and Policy Networks",
    "abstract": "Neurosymbolic AI combines the interpretability, parsimony, and explicit reasoning of classical symbolic approaches with the statistical learning of data-driven neural approaches. Models and policies that are simultaneously differentiable and interpretable may be key enablers of this marriage. This paper demonstrates three pathways to implementing such models and policies in a real-world reinforcement learning setting. Specifically, we study a broad class of neural networks that build interpretable semantics directly into their architecture. We reveal and highlight both the potential and the essential difficulties of combining logic, simulation, and learning. One lesson is that learning benefits from continuity and differentiability, but classical logic is discrete and non-differentiable. The relaxation to real-valued, differentiable representations presents a trade-off; the more learnable, the less interpretable. Another lesson is that using logic in the context of a numerical simulati",
    "link": "https://arxiv.org/abs/2402.05307",
    "context": "Title: Three Pathways to Neurosymbolic Reinforcement Learning with Interpretable Model and Policy Networks\nAbstract: Neurosymbolic AI combines the interpretability, parsimony, and explicit reasoning of classical symbolic approaches with the statistical learning of data-driven neural approaches. Models and policies that are simultaneously differentiable and interpretable may be key enablers of this marriage. This paper demonstrates three pathways to implementing such models and policies in a real-world reinforcement learning setting. Specifically, we study a broad class of neural networks that build interpretable semantics directly into their architecture. We reveal and highlight both the potential and the essential difficulties of combining logic, simulation, and learning. One lesson is that learning benefits from continuity and differentiability, but classical logic is discrete and non-differentiable. The relaxation to real-valued, differentiable representations presents a trade-off; the more learnable, the less interpretable. Another lesson is that using logic in the context of a numerical simulati",
    "path": "papers/24/02/2402.05307.json",
    "total_tokens": 870,
    "translated_title": "具有可解释模型和策略网络的神经符号强化学习的三个路径",
    "translated_abstract": "神经符号人工智能将经典符号方法的可解释性、简约性和显式推理与数据驱动的神经方法的统计学习相结合。同时可微和可解释的模型和策略可能是这种结合的关键。本文在真实世界的强化学习环境中展示了实现这些模型和策略的三种路径。具体而言，我们研究了一类广泛的神经网络，这些网络在其架构中直接构建可解释的语义。我们揭示和强调了将逻辑、仿真和学习结合起来的潜力和基本困难。一个教训是学习受益于连续性和可微性，但经典逻辑是离散且不可微的。将逻辑松弛为实值的可微表示存在一个权衡；越可学习，越不可解释。另一个教训是在数值仿真环境中使用逻辑",
    "tldr": "本文探讨了实现具有可解释性的模型和策略的神经符号强化学习的三个路径，并揭示了学习的连续性和可微性的益处，以及将逻辑与数值仿真结合的难点。"
}