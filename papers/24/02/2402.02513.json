{
    "title": "Early stopping by correlating online indicators in neural networks",
    "abstract": "In order to minimize the generalization error in neural networks, a novel technique to identify overfitting phenomena when training the learner is formally introduced. This enables support of a reliable and trustworthy early stopping condition, thus improving the predictive power of that type of modeling. Our proposal exploits the correlation over time in a collection of online indicators, namely characteristic functions for indicating if a set of hypotheses are met, associated with a range of independent stopping conditions built from a canary judgment to evaluate the presence of overfitting. That way, we provide a formal basis for decision making in terms of interrupting the learning process.   As opposed to previous approaches focused on a single criterion, we take advantage of subsidiarities between independent assessments, thus seeking both a wider operating range and greater diagnostic reliability. With a view to illustrating the effectiveness of the halting condition described, ",
    "link": "https://arxiv.org/abs/2402.02513",
    "context": "Title: Early stopping by correlating online indicators in neural networks\nAbstract: In order to minimize the generalization error in neural networks, a novel technique to identify overfitting phenomena when training the learner is formally introduced. This enables support of a reliable and trustworthy early stopping condition, thus improving the predictive power of that type of modeling. Our proposal exploits the correlation over time in a collection of online indicators, namely characteristic functions for indicating if a set of hypotheses are met, associated with a range of independent stopping conditions built from a canary judgment to evaluate the presence of overfitting. That way, we provide a formal basis for decision making in terms of interrupting the learning process.   As opposed to previous approaches focused on a single criterion, we take advantage of subsidiarities between independent assessments, thus seeking both a wider operating range and greater diagnostic reliability. With a view to illustrating the effectiveness of the halting condition described, ",
    "path": "papers/24/02/2402.02513.json",
    "total_tokens": 800,
    "translated_title": "在神经网络中通过相关在线指标来提前停止",
    "translated_abstract": "为了最小化神经网络中的泛化误差，引入了一种新颖的技术来在训练学习者时识别过拟合现象。这使得支持可靠和可信的提前停止条件成为可能，从而提高了该类型建模的预测能力。我们的提议利用一系列在线指标的时间相关性，即用于指示一组假设是否满足的特征函数，与从金丝雀判断中构建的一系列独立停止条件相联系，以评估过拟合的存在。通过这种方式，我们为决策提供了形式化的基础，以中断学习过程。与之前专注于单一标准的方法相反，我们利用独立评估之间的附带效应，寻求更广泛的操作范围和更大的诊断可靠性。",
    "tldr": "本文提出了一种在神经网络中最小化泛化误差的新技术，通过利用一系列在线指标的时间相关性，找到过拟合现象，并提供了可靠的提前停止条件，从而提高了预测能力。",
    "en_tdlr": "This paper presents a novel technique in neural networks to minimize generalization error by identifying overfitting phenomena through the correlation of online indicators, providing reliable early stopping conditions and improving predictive power."
}