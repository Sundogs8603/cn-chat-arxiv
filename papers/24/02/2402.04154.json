{
    "title": "Read to Play (R2-Play): Decision Transformer with Multimodal Game Instruction",
    "abstract": "Developing a generalist agent is a longstanding objective in artificial intelligence. Previous efforts utilizing extensive offline datasets from various tasks demonstrate remarkable performance in multitasking scenarios within Reinforcement Learning.However, these works encounter challenges in extending their capabilities to new tasks.Recent approaches integrate textual guidance or visual trajectory into decision networks to provide task-specific contextual cues, representing a promising direction.However, it is observed that relying solely on textual guidance or visual trajectory is insufficient for accurately conveying the contextual information of tasks.This paper explores enhanced forms of task guidance for agents, enabling them to comprehend gameplay instructions, thereby facilitating a \"read-to-play\" capability.Drawing inspiration from the success of multimodal instruction tuning in visual tasks, we treat the visual-based RL task as a long-horizon vision task and construct a set ",
    "link": "https://arxiv.org/abs/2402.04154",
    "context": "Title: Read to Play (R2-Play): Decision Transformer with Multimodal Game Instruction\nAbstract: Developing a generalist agent is a longstanding objective in artificial intelligence. Previous efforts utilizing extensive offline datasets from various tasks demonstrate remarkable performance in multitasking scenarios within Reinforcement Learning.However, these works encounter challenges in extending their capabilities to new tasks.Recent approaches integrate textual guidance or visual trajectory into decision networks to provide task-specific contextual cues, representing a promising direction.However, it is observed that relying solely on textual guidance or visual trajectory is insufficient for accurately conveying the contextual information of tasks.This paper explores enhanced forms of task guidance for agents, enabling them to comprehend gameplay instructions, thereby facilitating a \"read-to-play\" capability.Drawing inspiration from the success of multimodal instruction tuning in visual tasks, we treat the visual-based RL task as a long-horizon vision task and construct a set ",
    "path": "papers/24/02/2402.04154.json",
    "total_tokens": 909,
    "translated_title": "《读玩游戏（R2-Play）: 多模态游戏指导下的决策 Transformer》",
    "translated_abstract": "在人工智能领域，开发一款通用智能体一直是一个长期的目标。先前的研究利用来自各种任务的大量离线数据集，在强化学习的多任务场景中表现出了出色的性能。然而，这些工作在扩展到新任务方面面临挑战。最近的方法将文本指导或视觉轨迹整合到决策网络中，提供任务特定的上下文提示，代表了一个有前途的方向。然而，观察到仅依赖于文本指导或视觉轨迹对于准确传达任务的上下文信息是不足够的。本文探索了增强智能体任务指导的形式，使其能够理解游戏指导，从而实现\"读玩游戏\"的能力。受到多模态指导调优在视觉任务中的成功启发，我们将基于视觉的强化学习任务视为一个长期视觉任务，并构建了一组... (内容太长，无法继续显示)",
    "tldr": "本论文探索了为智能体提供增强形式的任务指导，使其能够理解游戏指导并实现\"读玩游戏\"的能力。通过将多模态指导调优的成功应用于视觉任务中的强化学习任务，构建了一组... (内容太长，无法继续显示)"
}