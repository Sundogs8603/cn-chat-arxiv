{
    "title": "Rationality Report Cards: Assessing the Economic Rationality of Large Language Models",
    "abstract": "arXiv:2402.09552v1 Announce Type: new  Abstract: There is increasing interest in using LLMs as decision-making \"agents.\" Doing so includes many degrees of freedom: which model should be used; how should it be prompted; should it be asked to introspect, conduct chain-of-thought reasoning, etc? Settling these questions -- and more broadly, determining whether an LLM agent is reliable enough to be trusted -- requires a methodology for assessing such an agent's economic rationality. In this paper, we provide one. We begin by surveying the economic literature on rational decision making, taxonomizing a large set of fine-grained \"elements\" that an agent should exhibit, along with dependencies between them. We then propose a benchmark distribution that quantitatively scores an LLMs performance on these elements and, combined with a user-provided rubric, produces a \"rationality report card.\" Finally, we describe the results of a large-scale empirical experiment with 14 different LLMs, characte",
    "link": "https://arxiv.org/abs/2402.09552",
    "context": "Title: Rationality Report Cards: Assessing the Economic Rationality of Large Language Models\nAbstract: arXiv:2402.09552v1 Announce Type: new  Abstract: There is increasing interest in using LLMs as decision-making \"agents.\" Doing so includes many degrees of freedom: which model should be used; how should it be prompted; should it be asked to introspect, conduct chain-of-thought reasoning, etc? Settling these questions -- and more broadly, determining whether an LLM agent is reliable enough to be trusted -- requires a methodology for assessing such an agent's economic rationality. In this paper, we provide one. We begin by surveying the economic literature on rational decision making, taxonomizing a large set of fine-grained \"elements\" that an agent should exhibit, along with dependencies between them. We then propose a benchmark distribution that quantitatively scores an LLMs performance on these elements and, combined with a user-provided rubric, produces a \"rationality report card.\" Finally, we describe the results of a large-scale empirical experiment with 14 different LLMs, characte",
    "path": "papers/24/02/2402.09552.json",
    "total_tokens": 853,
    "translated_title": "理性报告卡：评估大型语言模型的经济合理性",
    "translated_abstract": "越来越多的人对将LLM用作决策\"代理人\"兴趣日益增加。这包括很多自由度：应该使用哪个模型；如何进行提示；是否要求其进行内省、进行思考链等。解决这些问题（更广泛地说，确定LLM代理人是否足够可靠以便获得信任）需要一种评估这种代理人经济合理性的方法论，在本文中我们提供了一个方法。我们首先对理性决策的经济文献进行了调研、将代理人应该展现的大量细粒度\"要素\"进行分类，并确定了它们之间的依赖关系。然后，我们提出了一个基准分布，以定量评分LLM在这些要素上的表现，并结合用户提供的评分标准，生成一份\"理性报告卡\"。最后，我们描述了与14种不同的LLM进行的大规模实证实验的结果。",
    "tldr": "本文在评估大型语言模型的经济合理性方面提出了一种方法，通过量化评分模型在各个要素上的表现并结合用户提供的评分标准，生成一份\"理性报告卡\"，以确定代理人是否足够可靠。"
}