{
    "title": "FedLion: Faster Adaptive Federated Optimization with Fewer Communication",
    "abstract": "arXiv:2402.09941v1 Announce Type: cross  Abstract: In Federated Learning (FL), a framework to train machine learning models across distributed data, well-known algorithms like FedAvg tend to have slow convergence rates, resulting in high communication costs during training. To address this challenge, we introduce FedLion, an adaptive federated optimization algorithm that seamlessly incorporates key elements from the recently proposed centralized adaptive algorithm, Lion (Chen et al. 2o23), into the FL framework. Through comprehensive evaluations on two widely adopted FL benchmarks, we demonstrate that FedLion outperforms previous state-of-the-art adaptive algorithms, including FAFED (Wu et al. 2023) and FedDA. Moreover, thanks to the use of signed gradients in local training, FedLion substantially reduces data transmission requirements during uplink communication when compared to existing adaptive algorithms, further reducing communication costs. Last but not least, this work also incl",
    "link": "https://arxiv.org/abs/2402.09941",
    "context": "Title: FedLion: Faster Adaptive Federated Optimization with Fewer Communication\nAbstract: arXiv:2402.09941v1 Announce Type: cross  Abstract: In Federated Learning (FL), a framework to train machine learning models across distributed data, well-known algorithms like FedAvg tend to have slow convergence rates, resulting in high communication costs during training. To address this challenge, we introduce FedLion, an adaptive federated optimization algorithm that seamlessly incorporates key elements from the recently proposed centralized adaptive algorithm, Lion (Chen et al. 2o23), into the FL framework. Through comprehensive evaluations on two widely adopted FL benchmarks, we demonstrate that FedLion outperforms previous state-of-the-art adaptive algorithms, including FAFED (Wu et al. 2023) and FedDA. Moreover, thanks to the use of signed gradients in local training, FedLion substantially reduces data transmission requirements during uplink communication when compared to existing adaptive algorithms, further reducing communication costs. Last but not least, this work also incl",
    "path": "papers/24/02/2402.09941.json",
    "total_tokens": 874,
    "translated_title": "FedLion: 更快的自适应联邦优化算法，通信更少",
    "translated_abstract": "在联邦学习（FL）中，一种跨分布式数据训练机器学习模型的框架中，像FedAvg这样的知名算法往往具有较慢的收敛速度，在训练过程中导致高通信成本。为了解决这个挑战，我们引入了FedLion，一种自适应联邦优化算法，无缝地将最近提出的集中式自适应算法Lion（Chen et al. 2023）的关键元素融入到FL框架中。通过对两个广泛采用的FL基准进行全面评估，我们证明了FedLion优于之前的最先进自适应算法，包括FAFED（Wu et al. 2023）和FedDA。此外，由于在本地训练中使用了有符号梯度，与现有的自适应算法相比，FedLion在上行通信过程中大大降低了数据传输要求，进一步降低了通信成本。",
    "tldr": "FedLion是一种自适应联邦优化算法，通过引入集中式自适应算法Lion的关键元素，实现了更快的收敛速度和更少的通信成本。经过广泛评估，FedLion优于之前的最先进自适应算法，并通过使用有符号梯度在本地训练中减少数据传输要求。"
}