{
    "title": "Re-Ex: Revising after Explanation Reduces the Factual Errors in LLM Responses",
    "abstract": "arXiv:2402.17097v1 Announce Type: cross  Abstract: Mitigating hallucination issues is one of the main challenges of LLMs we need to overcome, in order to reliably use them in real-world scenarios. Recently, various methods are proposed to check the factual errors in the LLM-generated texts and revise them accordingly, to reduce the hallucination issue. In this paper, we propose Re-Ex, a method of revising LLM-generated texts, which introduces a novel step dubbed as the factual error explanation step. Re-Ex revises the initial response of LLMs using 3-steps: first, external tools are used to get the evidences on the factual errors in the response; second, LLMs are instructed to explain the problematic parts of the response based on the evidences gathered in the first step; finally, LLMs revise the response using the explanation obtained in the second step. In addition to the explanation step, we propose new prompting techniques to reduce the amount of tokens and wall-clock time required",
    "link": "https://arxiv.org/abs/2402.17097",
    "context": "Title: Re-Ex: Revising after Explanation Reduces the Factual Errors in LLM Responses\nAbstract: arXiv:2402.17097v1 Announce Type: cross  Abstract: Mitigating hallucination issues is one of the main challenges of LLMs we need to overcome, in order to reliably use them in real-world scenarios. Recently, various methods are proposed to check the factual errors in the LLM-generated texts and revise them accordingly, to reduce the hallucination issue. In this paper, we propose Re-Ex, a method of revising LLM-generated texts, which introduces a novel step dubbed as the factual error explanation step. Re-Ex revises the initial response of LLMs using 3-steps: first, external tools are used to get the evidences on the factual errors in the response; second, LLMs are instructed to explain the problematic parts of the response based on the evidences gathered in the first step; finally, LLMs revise the response using the explanation obtained in the second step. In addition to the explanation step, we propose new prompting techniques to reduce the amount of tokens and wall-clock time required",
    "path": "papers/24/02/2402.17097.json",
    "total_tokens": 870,
    "translated_title": "修复: 在说明后修正LLM响应中的事实错误",
    "translated_abstract": "缓解幻觉问题是LLM的主要挑战之一，我们需要克服这一挑战，以便可靠地在现实场景中使用它们。最近，提出了各种方法来检查LLM生成的文本中的事实错误，并相应地进行修订，以减少幻觉问题。在本文中，我们提出了Re-Ex，一种修订LLM生成文本的方法，它引入了一个称为事实错误说明步骤的新步骤。 Re-Ex使用3个步骤对LLM的初始响应进行修订：首先，使用外部工具获取响应中事实错误的证据；第二，要求LLM根据第一步中收集的证据解释响应中的问题部分；最后，LLM使用在第二步中获得的解释对响应进行修订。除了说明步骤，我们还提出了新的提示技术，以减少所需的标记数量和挂钟时间。",
    "tldr": "提出了一种名为Re-Ex的方法，通过引入事实错误说明步骤来修正LLM生成文本中的事实错误，并提出了新的提示技术来减少所需的标记数量和挂钟时间"
}