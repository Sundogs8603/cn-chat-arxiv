{
    "title": "CyberMetric: A Benchmark Dataset for Evaluating Large Language Models Knowledge in Cybersecurity",
    "abstract": "Large Language Models (LLMs) excel across various domains, from computer vision to medical diagnostics. However, understanding the diverse landscape of cybersecurity, encompassing cryptography, reverse engineering, and managerial facets like risk assessment, presents a challenge, even for human experts. In this paper, we introduce CyberMetric, a benchmark dataset comprising 10,000 questions sourced from standards, certifications, research papers, books, and other publications in the cybersecurity domain. The questions are created through a collaborative process, i.e., merging expert knowledge with LLMs, including GPT-3.5 and Falcon-180B. Human experts spent over 200 hours verifying their accuracy and relevance. Beyond assessing LLMs' knowledge, the dataset's main goal is to facilitate a fair comparison between humans and different LLMs in cybersecurity. To achieve this, we carefully selected 80 questions covering a wide range of topics within cybersecurity and involved 30 participants ",
    "link": "https://arxiv.org/abs/2402.07688",
    "context": "Title: CyberMetric: A Benchmark Dataset for Evaluating Large Language Models Knowledge in Cybersecurity\nAbstract: Large Language Models (LLMs) excel across various domains, from computer vision to medical diagnostics. However, understanding the diverse landscape of cybersecurity, encompassing cryptography, reverse engineering, and managerial facets like risk assessment, presents a challenge, even for human experts. In this paper, we introduce CyberMetric, a benchmark dataset comprising 10,000 questions sourced from standards, certifications, research papers, books, and other publications in the cybersecurity domain. The questions are created through a collaborative process, i.e., merging expert knowledge with LLMs, including GPT-3.5 and Falcon-180B. Human experts spent over 200 hours verifying their accuracy and relevance. Beyond assessing LLMs' knowledge, the dataset's main goal is to facilitate a fair comparison between humans and different LLMs in cybersecurity. To achieve this, we carefully selected 80 questions covering a wide range of topics within cybersecurity and involved 30 participants ",
    "path": "papers/24/02/2402.07688.json",
    "total_tokens": 987,
    "translated_title": "CyberMetric: 一份用于评估大型语言模型在网络安全领域的知识的基准数据集",
    "translated_abstract": "大型语言模型（LLM）在各个领域都表现出色，从计算机视觉到医学诊断。然而，理解网络安全这个涵盖密码学、逆向工程和风险评估等多样化领域的挑战即使对于人类专家来说也是困难的。在本文中，我们介绍了CyberMetric，这是一个基准数据集，包含了来自网络安全领域的标准、认证、研究论文、书籍和其他出版物的1万个问题。这些问题通过一种协作过程创建，即将专家知识与LLM（包括GPT-3.5和Falcon-180B）相结合。人类专家花费了超过200小时验证其准确性和相关性。除了评估LLM的知识外，该数据集的主要目标是在网络安全领域中促进人类与不同LLM之间的公平比较。为了实现这一目标，我们精选了80个问题，涵盖了网络安全领域的多个主题，并让30个参与者参与其中。",
    "tldr": "CyberMetric是一个基准数据集，旨在评估大型语言模型在网络安全领域的知识。该数据集由10000个问题组成，通过合作过程将专家知识与LLMs相结合。除了评估LLMs的知识外，数据集的主要目标是促进人类与不同LLMs在网络安全领域中的公平比较。"
}