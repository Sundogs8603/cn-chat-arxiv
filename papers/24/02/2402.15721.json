{
    "title": "Hal-Eval: A Universal and Fine-grained Hallucination Evaluation Framework for Large Vision Language Models",
    "abstract": "arXiv:2402.15721v1 Announce Type: new  Abstract: Large Vision Language Models exhibit remarkable capabilities but struggle with hallucinations inconsistencies between images and their descriptions. Previous hallucination evaluation studies on LVLMs have identified hallucinations in terms of objects, attributes, and relations but overlooked complex hallucinations that create an entire narrative around a fictional entity. In this paper, we introduce a refined taxonomy of hallucinations, featuring a new category: Event Hallucination. We then utilize advanced LLMs to generate and filter fine grained hallucinatory data consisting of various types of hallucinations, with a particular focus on event hallucinations, laying the groundwork for integrating discriminative and generative evaluation methods within our universal evaluation framework. The proposed benchmark distinctively assesses LVLMs ability to tackle a broad spectrum of hallucinations, making it a reliable and comprehensive tool fo",
    "link": "https://arxiv.org/abs/2402.15721",
    "context": "Title: Hal-Eval: A Universal and Fine-grained Hallucination Evaluation Framework for Large Vision Language Models\nAbstract: arXiv:2402.15721v1 Announce Type: new  Abstract: Large Vision Language Models exhibit remarkable capabilities but struggle with hallucinations inconsistencies between images and their descriptions. Previous hallucination evaluation studies on LVLMs have identified hallucinations in terms of objects, attributes, and relations but overlooked complex hallucinations that create an entire narrative around a fictional entity. In this paper, we introduce a refined taxonomy of hallucinations, featuring a new category: Event Hallucination. We then utilize advanced LLMs to generate and filter fine grained hallucinatory data consisting of various types of hallucinations, with a particular focus on event hallucinations, laying the groundwork for integrating discriminative and generative evaluation methods within our universal evaluation framework. The proposed benchmark distinctively assesses LVLMs ability to tackle a broad spectrum of hallucinations, making it a reliable and comprehensive tool fo",
    "path": "papers/24/02/2402.15721.json",
    "total_tokens": 894,
    "translated_title": "Hal-Eval: 一种面向大型视觉语言模型的通用和细粒度幻觉评估框架",
    "translated_abstract": "大型视觉语言模型具有非凡的能力，但在图片和其描述之间存在幻觉不一致。以往对LVLMs进行的幻觉评估研究发现了关于对象、属性和关系的幻觉，但忽略了围绕虚构实体创建整个叙事的复杂幻觉。本文引入了一种精细的幻觉分类法，其中包括一个新的类别：事件幻觉。然后，我们利用先进的LLMs生成和过滤由各种类型的幻觉组成的细粒度幻觉数据，特别关注事件幻觉，为在我们的通用评估框架内集成辨别和生成评估方法奠定基础。所提出的基准可以独特地评估LVLMs处理广泛幻觉的能力，使其成为一个可靠和全面的工具。",
    "tldr": "本论文提出了Hal-Eval，一个通用和细粒度的幻觉评估框架，引入了新的幻觉分类法，专注于事件幻觉，通过生成和过滤细粒度幻觉数据来评估大型视觉语言模型对各种幻觉的处理能力。",
    "en_tdlr": "This paper proposes Hal-Eval, a universal and fine-grained hallucination evaluation framework, introduces a new taxonomy of hallucinations with a focus on event hallucinations, evaluates the ability of large vision language models to handle various types of hallucinations through generating and filtering fine-grained hallucinatory data."
}