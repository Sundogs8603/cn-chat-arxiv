{
    "title": "Batch Active Learning of Reward Functions from Human Preferences",
    "abstract": "arXiv:2402.15757v1 Announce Type: cross  Abstract: Data generation and labeling are often expensive in robot learning. Preference-based learning is a concept that enables reliable labeling by querying users with preference questions. Active querying methods are commonly employed in preference-based learning to generate more informative data at the expense of parallelization and computation time. In this paper, we develop a set of novel algorithms, batch active preference-based learning methods, that enable efficient learning of reward functions using as few data samples as possible while still having short query generation times and also retaining parallelizability. We introduce a method based on determinantal point processes (DPP) for active batch generation and several heuristic-based alternatives. Finally, we present our experimental results for a variety of robotics tasks in simulation. Our results suggest that our batch active learning algorithm requires only a few queries that ar",
    "link": "https://arxiv.org/abs/2402.15757",
    "context": "Title: Batch Active Learning of Reward Functions from Human Preferences\nAbstract: arXiv:2402.15757v1 Announce Type: cross  Abstract: Data generation and labeling are often expensive in robot learning. Preference-based learning is a concept that enables reliable labeling by querying users with preference questions. Active querying methods are commonly employed in preference-based learning to generate more informative data at the expense of parallelization and computation time. In this paper, we develop a set of novel algorithms, batch active preference-based learning methods, that enable efficient learning of reward functions using as few data samples as possible while still having short query generation times and also retaining parallelizability. We introduce a method based on determinantal point processes (DPP) for active batch generation and several heuristic-based alternatives. Finally, we present our experimental results for a variety of robotics tasks in simulation. Our results suggest that our batch active learning algorithm requires only a few queries that ar",
    "path": "papers/24/02/2402.15757.json",
    "total_tokens": 745,
    "translated_title": "从人类偏好中批量主动学习奖励函数",
    "translated_abstract": "数据生成和标记在机器人学习中往往成本高昂。基于偏好的学习是一个概念，通过向用户提出偏好问题来实现可靠的标记。本文中，我们开发了一组新算法，批量主动基于偏好的学习方法，能够使用尽可能少的数据样本有效学习奖励函数，同时具有较短的查询生成时间，并保持可并行化。我们介绍了一种基于确定性点过程（DPP）的方法，用于批量生成和几种基于启发式的替代方法。最后，我们在模拟中介绍了一些机器人学任务的实验结果。我们的结果表明，我们的批量主动学习算法仅需要少量查询。",
    "tldr": "本文提出了一种批量主动基于偏好的学习方法，通过少量数据样本有效学习奖励函数，同时保持查询生成时间短并可并行化。"
}