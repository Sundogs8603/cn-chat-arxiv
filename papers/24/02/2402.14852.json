{
    "title": "HumanEval on Latest GPT Models -- 2024",
    "abstract": "arXiv:2402.14852v1 Announce Type: cross  Abstract: In 2023, we are using the latest models of GPT-4 to advance program synthesis. The large language models have significantly improved the state-of-the-art for this purpose. To make these advancements more accessible, we have created a repository that connects these models to Huamn Eval. This dataset was initally developed to be used with a language model called CODEGEN on natural and programming language data. The utility of these trained models is showcased by demonstrating their competitive performance in zero-shot Python code generation on HumanEval tasks compared to previous state-of-the-art solutions. Additionally, this gives way to developing more multi-step paradigm synthesis. This benchmark features 160 diverse problem sets factorized into multistep prompts that our analysis shows significantly improves program synthesis over single-turn inputs. All code is open source at https://github.com/daniel442li/gpt-human-eval .",
    "link": "https://arxiv.org/abs/2402.14852",
    "context": "Title: HumanEval on Latest GPT Models -- 2024\nAbstract: arXiv:2402.14852v1 Announce Type: cross  Abstract: In 2023, we are using the latest models of GPT-4 to advance program synthesis. The large language models have significantly improved the state-of-the-art for this purpose. To make these advancements more accessible, we have created a repository that connects these models to Huamn Eval. This dataset was initally developed to be used with a language model called CODEGEN on natural and programming language data. The utility of these trained models is showcased by demonstrating their competitive performance in zero-shot Python code generation on HumanEval tasks compared to previous state-of-the-art solutions. Additionally, this gives way to developing more multi-step paradigm synthesis. This benchmark features 160 diverse problem sets factorized into multistep prompts that our analysis shows significantly improves program synthesis over single-turn inputs. All code is open source at https://github.com/daniel442li/gpt-human-eval .",
    "path": "papers/24/02/2402.14852.json",
    "total_tokens": 846,
    "translated_title": "最新GPT模型上的HumanEval -- 2024",
    "translated_abstract": "在2023年，我们正在使用最新的GPT-4模型来推进程序合成。这些大型语言模型显著改进了这一目的的最新技术。为了使这些进展更易于访问，我们创建了一个将这些模型连接到Human Eval的存储库。该数据集最初是为与名为CODEGEN的语言模型在自然语言和编程语言数据上使用而开发的。通过展示这些经过训练的模型在与以前的最先进解决方案相比在HumanEval任务上零样本Python代码生成中的竞争性性能，展示了这些训练模型的效用。此外，这为开发更多的多步骤范式综合创造了可能。这一基准测试包含160个多样化的问题集，这些问题集被分解成多步提示，我们的分析表明这显著改进了单轮输入上的程序综合。所有代码均以开源方式发布在https://github.com/daniel442li/gpt-human-eval。",
    "tldr": "使用最新的GPT-4模型在程序合成方面取得显著进展，通过在HumanEval任务中展示了在零样本Python代码生成中的竞争性性能和更多多步骤范式综合。",
    "en_tdlr": "Significantly advancing program synthesis with the latest GPT-4 models, showcasing competitive performance in zero-shot Python code generation on HumanEval tasks and enabling more multi-step paradigm synthesis."
}