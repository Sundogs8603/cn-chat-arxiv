{
    "title": "Disentanglement in Implicit Causal Models via Switch Variable",
    "abstract": "arXiv:2402.11124v1 Announce Type: new  Abstract: Learning causal representations from observational and interventional data in the absence of known ground-truth graph structures necessitates implicit latent causal representation learning. Implicitly learning causal mechanisms typically involves two categories of interventional data: hard and soft interventions. In real-world scenarios, soft interventions are often more realistic than hard interventions, as the latter require fully controlled environments. Unlike hard interventions, which directly force changes in a causal variable, soft interventions exert influence indirectly by affecting the causal mechanism. In this paper, we tackle implicit latent causal representation learning in a Variational Autoencoder (VAE) framework through soft interventions. Our approach models soft interventions effects by employing a causal mechanism switch variable designed to toggle between different causal mechanisms. In our experiments, we consistentl",
    "link": "https://arxiv.org/abs/2402.11124",
    "context": "Title: Disentanglement in Implicit Causal Models via Switch Variable\nAbstract: arXiv:2402.11124v1 Announce Type: new  Abstract: Learning causal representations from observational and interventional data in the absence of known ground-truth graph structures necessitates implicit latent causal representation learning. Implicitly learning causal mechanisms typically involves two categories of interventional data: hard and soft interventions. In real-world scenarios, soft interventions are often more realistic than hard interventions, as the latter require fully controlled environments. Unlike hard interventions, which directly force changes in a causal variable, soft interventions exert influence indirectly by affecting the causal mechanism. In this paper, we tackle implicit latent causal representation learning in a Variational Autoencoder (VAE) framework through soft interventions. Our approach models soft interventions effects by employing a causal mechanism switch variable designed to toggle between different causal mechanisms. In our experiments, we consistentl",
    "path": "papers/24/02/2402.11124.json",
    "total_tokens": 781,
    "translated_title": "通过开关变量在隐式因果模型中解开纠缠",
    "translated_abstract": "从观测和干预数据中学习因果表征，在没有已知的地面真实图结构的情况下，需要隐式潜在因果表征学习。隐式学习因果机制通常涉及两类干预数据：硬干预和软干预。在现实世界场景中，软干预通常比硬干预更现实，因为后者需要完全受控的环境。与直接强制改变因果变量的硬干预不同，软干预通过影响因果机制间接地产生影响。本文通过软干预在变分自动编码器（VAE）框架中处理隐式潜在因果表征学习。我们的方法通过使用一个旨在在不同因果机制之间切换的因果机制开关变量来建模软干预效果。在我们的实验中，我们始终保持",
    "tldr": "该论文通过软干预处理隐式潜在因果表征学习，在 Variational Autoencoder (VAE) 框架中引入了因果机制开关变量。",
    "en_tdlr": "This paper introduces a causal mechanism switch variable in a Variational Autoencoder (VAE) framework to handle implicit latent causal representation learning through soft interventions."
}