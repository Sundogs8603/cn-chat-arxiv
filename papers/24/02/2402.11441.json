{
    "title": "InfuserKI: Enhancing Large Language Models with Knowledge Graphs via Infuser-Guided Knowledge Integration",
    "abstract": "arXiv:2402.11441v1 Announce Type: cross  Abstract: Though Large Language Models (LLMs) have shown remarkable open-generation capabilities across diverse domains, they struggle with knowledge-intensive tasks. To alleviate this issue, knowledge integration methods have been proposed to enhance LLMs with domain-specific knowledge graphs using external modules. However, they suffer from data inefficiency as they require both known and unknown knowledge for fine-tuning. Thus, we study a novel problem of integrating unknown knowledge into LLMs efficiently without unnecessary overlap of known knowledge. Injecting new knowledge poses the risk of forgetting previously acquired knowledge. To tackle this, we propose a novel Infuser-Guided Knowledge Integration (InfuserKI) framework that utilizes transformer internal states to determine whether to enhance the original LLM output with additional information, thereby effectively mitigating knowledge forgetting. Evaluations on the UMLS-2.5k and MetaQ",
    "link": "https://arxiv.org/abs/2402.11441",
    "context": "Title: InfuserKI: Enhancing Large Language Models with Knowledge Graphs via Infuser-Guided Knowledge Integration\nAbstract: arXiv:2402.11441v1 Announce Type: cross  Abstract: Though Large Language Models (LLMs) have shown remarkable open-generation capabilities across diverse domains, they struggle with knowledge-intensive tasks. To alleviate this issue, knowledge integration methods have been proposed to enhance LLMs with domain-specific knowledge graphs using external modules. However, they suffer from data inefficiency as they require both known and unknown knowledge for fine-tuning. Thus, we study a novel problem of integrating unknown knowledge into LLMs efficiently without unnecessary overlap of known knowledge. Injecting new knowledge poses the risk of forgetting previously acquired knowledge. To tackle this, we propose a novel Infuser-Guided Knowledge Integration (InfuserKI) framework that utilizes transformer internal states to determine whether to enhance the original LLM output with additional information, thereby effectively mitigating knowledge forgetting. Evaluations on the UMLS-2.5k and MetaQ",
    "path": "papers/24/02/2402.11441.json",
    "total_tokens": 870,
    "translated_title": "InfuserKI：通过Infuser引导的知识集成增强大型语言模型与知识图谱",
    "translated_abstract": "大型语言模型（LLMs）在各个领域展现出卓越的开放式生成能力，但在知识密集型任务中表现不佳。为了缓解这一问题，提出了知识集成方法，利用外部模块将领域特定知识图谱与LLMs结合起来。然而，它们存在数据效率低的问题，因为它们需要已知和未知的知识来进行微调。因此，我们研究了一个新颖的问题，即如何在不重复已知知识的情况下有效地将未知知识集成到LLMs中。注入新知识会导致遗忘先前获得的知识的风险。为了解决这个问题，我们提出了一种新颖的Infuser-Guided Knowledge Integration（InfuserKI）框架，利用transformer内部状态来确定是否应该增强原始LLM输出信息，从而有效地减轻知识遗忘问题。在UMLS-2.5k和MetaQ上进行了评估。",
    "tldr": "提出了一种Infuser-Guided Knowledge Integration（InfuserKI）框架，利用transformer内部状态有效地将未知知识集成到大型语言模型中，从而缓解知识遗忘问题。",
    "en_tdlr": "Proposed an Infuser-Guided Knowledge Integration (InfuserKI) framework that efficiently integrates unknown knowledge into large language models using transformer internal states to mitigate knowledge forgetting."
}