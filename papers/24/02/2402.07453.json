{
    "title": "Bandit-Feedback Online Multiclass Classification: Variants and Tradeoffs",
    "abstract": "Consider the domain of multiclass classification within the adversarial online setting. What is the price of relying on bandit feedback as opposed to full information? To what extent can an adaptive adversary amplify the loss compared to an oblivious one? To what extent can a randomized learner reduce the loss compared to a deterministic one? We study these questions in the mistake bound model and provide nearly tight answers.   We demonstrate that the optimal mistake bound under bandit feedback is at most $O(k)$ times higher than the optimal mistake bound in the full information case, where $k$ represents the number of labels. This bound is tight and provides an answer to an open question previously posed and studied by Daniely and Helbertal ['13] and by Long ['17, '20], who focused on deterministic learners.   Moreover, we present nearly optimal bounds of $\\tilde{\\Theta}(k)$ on the gap between randomized and deterministic learners, as well as between adaptive and oblivious adversarie",
    "link": "https://arxiv.org/abs/2402.07453",
    "context": "Title: Bandit-Feedback Online Multiclass Classification: Variants and Tradeoffs\nAbstract: Consider the domain of multiclass classification within the adversarial online setting. What is the price of relying on bandit feedback as opposed to full information? To what extent can an adaptive adversary amplify the loss compared to an oblivious one? To what extent can a randomized learner reduce the loss compared to a deterministic one? We study these questions in the mistake bound model and provide nearly tight answers.   We demonstrate that the optimal mistake bound under bandit feedback is at most $O(k)$ times higher than the optimal mistake bound in the full information case, where $k$ represents the number of labels. This bound is tight and provides an answer to an open question previously posed and studied by Daniely and Helbertal ['13] and by Long ['17, '20], who focused on deterministic learners.   Moreover, we present nearly optimal bounds of $\\tilde{\\Theta}(k)$ on the gap between randomized and deterministic learners, as well as between adaptive and oblivious adversarie",
    "path": "papers/24/02/2402.07453.json",
    "total_tokens": 728,
    "translated_title": "Bandit-Feedback在线多类分类：变体和权衡",
    "translated_abstract": "在对抗在线环境中考虑多类分类领域。与提供完全信息相比，依赖于强盗反馈的代价是多少？自适应对手与无视对手相比，可以增加损失的程度有多大？随机学习者与确定性学习者相比，可以降低损失的程度有多大？我们在错误边界模型中研究了这些问题，并提供了几乎紧确的答案。",
    "tldr": "该论文研究了在对抗在线环境中多类分类中依赖于强盗反馈的代价，自适应对手和随机学习者与无视对手和确定性学习者之间的损失差距。",
    "en_tdlr": "This paper investigates the cost of relying on bandit feedback in multiclass classification within the adversarial online setting, as well as the extent to which an adaptive adversary and a randomized learner can amplify or reduce the loss compared to an oblivious adversary and a deterministic learner, respectively."
}