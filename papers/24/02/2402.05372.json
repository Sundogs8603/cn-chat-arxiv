{
    "title": "Reduced-order modeling of unsteady fluid flow using neural network ensembles",
    "abstract": "The use of deep learning has become increasingly popular in reduced-order models (ROMs) to obtain low-dimensional representations of full-order models. Convolutional autoencoders (CAEs) are often used to this end as they are adept at handling data that are spatially distributed, including solutions to partial differential equations. When applied to unsteady physics problems, ROMs also require a model for time-series prediction of the low-dimensional latent variables. Long short-term memory (LSTM) networks, a type of recurrent neural network useful for modeling sequential data, are frequently employed in data-driven ROMs for autoregressive time-series prediction. When making predictions at unseen design points over long time horizons, error propagation is a frequently encountered issue, where errors made early on can compound over time and lead to large inaccuracies. In this work, we propose using bagging, a commonly used ensemble learning technique, to develop a fully data-driven ROM f",
    "link": "https://arxiv.org/abs/2402.05372",
    "context": "Title: Reduced-order modeling of unsteady fluid flow using neural network ensembles\nAbstract: The use of deep learning has become increasingly popular in reduced-order models (ROMs) to obtain low-dimensional representations of full-order models. Convolutional autoencoders (CAEs) are often used to this end as they are adept at handling data that are spatially distributed, including solutions to partial differential equations. When applied to unsteady physics problems, ROMs also require a model for time-series prediction of the low-dimensional latent variables. Long short-term memory (LSTM) networks, a type of recurrent neural network useful for modeling sequential data, are frequently employed in data-driven ROMs for autoregressive time-series prediction. When making predictions at unseen design points over long time horizons, error propagation is a frequently encountered issue, where errors made early on can compound over time and lead to large inaccuracies. In this work, we propose using bagging, a commonly used ensemble learning technique, to develop a fully data-driven ROM f",
    "path": "papers/24/02/2402.05372.json",
    "total_tokens": 916,
    "translated_title": "使用神经网络集成的降阶建模方法研究非定常流体流动",
    "translated_abstract": "深度学习在降阶模型中的应用越来越普遍，以便获得完全模型的低维表示。在处理空间分布的数据（包括偏微分方程的解）时，通常使用卷积自编码器（CAEs）。在应用于非定常物理问题时，降阶模型还需要对低维潜变量的时间序列进行预测。长短期记忆（LSTM）网络是一种适用于建模序列数据的循环神经网络，在数据驱动的降阶模型中经常用于自回归时间序列预测。在未知设计点上进行长时间跨度的预测时，经常会遇到错误传播的问题，即早期错误可能会随着时间的推移而不断累积并导致较大的不准确性。在本研究中，我们提出使用集成学习技术中常用的装袋方法来开发一个完全数据驱动的降阶模型。",
    "tldr": "本论文关注使用神经网络集成方法进行非定常流体流动的降阶建模。研究使用卷积自编码器处理空间分布的数据，并使用长短期记忆网络进行时间序列预测。同时，引入集成学习技术中的装袋方法来解决错误传播的问题。"
}