{
    "title": "Topology-Informed Graph Transformer",
    "abstract": "Transformers have revolutionized performance in Natural Language Processing and Vision, paving the way for their integration with Graph Neural Networks (GNNs). One key challenge in enhancing graph transformers is strengthening the discriminative power of distinguishing isomorphisms of graphs, which plays a crucial role in boosting their predictive performances. To address this challenge, we introduce 'Topology-Informed Graph Transformer (TIGT)', a novel transformer enhancing both discriminative power in detecting graph isomorphisms and the overall performance of Graph Transformers. TIGT consists of four components: A topological positional embedding layer using non-isomorphic universal covers based on cyclic subgraphs of graphs to ensure unique graph representation: A dual-path message-passing layer to explicitly encode topological characteristics throughout the encoder layers: A global attention mechanism: And a graph information layer to recalibrate channel-wise graph features for be",
    "link": "https://arxiv.org/abs/2402.02005",
    "context": "Title: Topology-Informed Graph Transformer\nAbstract: Transformers have revolutionized performance in Natural Language Processing and Vision, paving the way for their integration with Graph Neural Networks (GNNs). One key challenge in enhancing graph transformers is strengthening the discriminative power of distinguishing isomorphisms of graphs, which plays a crucial role in boosting their predictive performances. To address this challenge, we introduce 'Topology-Informed Graph Transformer (TIGT)', a novel transformer enhancing both discriminative power in detecting graph isomorphisms and the overall performance of Graph Transformers. TIGT consists of four components: A topological positional embedding layer using non-isomorphic universal covers based on cyclic subgraphs of graphs to ensure unique graph representation: A dual-path message-passing layer to explicitly encode topological characteristics throughout the encoder layers: A global attention mechanism: And a graph information layer to recalibrate channel-wise graph features for be",
    "path": "papers/24/02/2402.02005.json",
    "total_tokens": 814,
    "translated_title": "基于拓扑信息的图形变换器",
    "translated_abstract": "变形器在自然语言处理和视觉领域中取得了突破性的成果，为与图神经网络（GNN）的集成铺平了道路。增强图形变换器的一个关键挑战是增强区分图的同构性的区分能力，这在提高它们的预测性能中起到关键作用。为了解决这个挑战，我们引入了一种新的变形器——“基于拓扑信息的图形变换器（TIGT）”，它增强了检测图同构性的区分能力和图形变换器的整体性能。TIGT由四个组件组成：一个使用基于图的循环子图的非同构卷上的拓扑位置嵌入层，以确保唯一的图表示；一个双路径消息传递层，以明确地编码拓扑特征；一个全局注意机制；和一个图信息层，用于重新校准通道级的图特征。",
    "tldr": "TIGT是一种基于拓扑信息的新型图形变换器，通过增强区分图同构性的能力和提高图形变换器性能，实现了对图同构性的检测和整体性能的增强。",
    "en_tdlr": "TIGT is a novel graph transformer that utilizes topology information to enhance the ability to distinguish isomorphisms of graphs and improve the overall performance of graph transformers."
}