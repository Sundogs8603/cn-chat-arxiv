{
    "title": "Rethinking Scaling Laws for Learning in Strategic Environments",
    "abstract": "The deployment of ever-larger machine learning models reflects a growing consensus that the more expressive the model$\\unicode{x2013}$and the more data one has access to$\\unicode{x2013}$the more one can improve performance. As models get deployed in a variety of real world scenarios, they inevitably face strategic environments. In this work, we consider the natural question of how the interplay of models and strategic interactions affects scaling laws. We find that strategic interactions can break the conventional view of scaling laws$\\unicode{x2013}$meaning that performance does not necessarily monotonically improve as models get larger and/ or more expressive (even with infinite data). We show the implications of this phenomenon in several contexts including strategic regression, strategic classification, and multi-agent reinforcement learning through examples of strategic environments in which$\\unicode{x2013}$by simply restricting the expressivity of one's model or policy class$\\uni",
    "link": "https://arxiv.org/abs/2402.07588",
    "context": "Title: Rethinking Scaling Laws for Learning in Strategic Environments\nAbstract: The deployment of ever-larger machine learning models reflects a growing consensus that the more expressive the model$\\unicode{x2013}$and the more data one has access to$\\unicode{x2013}$the more one can improve performance. As models get deployed in a variety of real world scenarios, they inevitably face strategic environments. In this work, we consider the natural question of how the interplay of models and strategic interactions affects scaling laws. We find that strategic interactions can break the conventional view of scaling laws$\\unicode{x2013}$meaning that performance does not necessarily monotonically improve as models get larger and/ or more expressive (even with infinite data). We show the implications of this phenomenon in several contexts including strategic regression, strategic classification, and multi-agent reinforcement learning through examples of strategic environments in which$\\unicode{x2013}$by simply restricting the expressivity of one's model or policy class$\\uni",
    "path": "papers/24/02/2402.07588.json",
    "total_tokens": 878,
    "translated_title": "重新思考战略环境中学习的比例定律",
    "translated_abstract": "越来越大的机器学习模型的部署反映出一个共识：模型越有表达能力，越拥有大量数据，就能改善性能。随着模型在各种真实场景中的部署，它们不可避免地面临着战略环境。本文考虑了模型与战略互动对比例定律的相互作用对性能的影响这个自然问题。我们发现战略互动可以打破传统的比例定律观点，即性能并不一定随着模型的扩大和/或表达能力的增强（即使有无限数据）而单调提高。我们通过战略回归、战略分类和多智能体强化学习的例子展示了这一现象的影响，这些例子展示了战略环境中的限制模型或策略类的表达能力即可。",
    "tldr": "本文重新思考了在战略环境中学习的比例定律，发现战略互动可以打破传统的观点，即模型越大或表达能力越强并不一定会随之提高性能。通过几个战略环境的例子，我们展示了这种现象的影响。",
    "en_tdlr": "This paper rethinks the scaling laws for learning in strategic environments and finds that strategic interactions can break the conventional view that larger and more expressive models will necessarily improve performance. Examples of strategic environments demonstrate the implications of this phenomenon."
}