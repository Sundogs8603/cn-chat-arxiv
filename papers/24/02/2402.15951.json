{
    "title": "GreenLLaMA: A Framework for Detoxification with Explanations",
    "abstract": "arXiv:2402.15951v1 Announce Type: cross  Abstract: Prior works on detoxification are scattered in the sense that they do not cover all aspects of detoxification needed in a real-world scenario. Notably, prior works restrict the task of developing detoxification models to only a seen subset of platforms, leaving the question of how the models would perform on unseen platforms unexplored. Additionally, these works do not address non-detoxifiability, a phenomenon whereby the toxic text cannot be detoxified without altering the meaning. We propose GreenLLaMA, the first comprehensive end-to-end detoxification framework, which attempts to alleviate the aforementioned limitations. We first introduce a cross-platform pseudo-parallel corpus applying multi-step data processing and generation strategies leveraging ChatGPT. We then train a suite of detoxification models with our cross-platform corpus. We show that our detoxification models outperform the SoTA model trained with human-annotated par",
    "link": "https://arxiv.org/abs/2402.15951",
    "context": "Title: GreenLLaMA: A Framework for Detoxification with Explanations\nAbstract: arXiv:2402.15951v1 Announce Type: cross  Abstract: Prior works on detoxification are scattered in the sense that they do not cover all aspects of detoxification needed in a real-world scenario. Notably, prior works restrict the task of developing detoxification models to only a seen subset of platforms, leaving the question of how the models would perform on unseen platforms unexplored. Additionally, these works do not address non-detoxifiability, a phenomenon whereby the toxic text cannot be detoxified without altering the meaning. We propose GreenLLaMA, the first comprehensive end-to-end detoxification framework, which attempts to alleviate the aforementioned limitations. We first introduce a cross-platform pseudo-parallel corpus applying multi-step data processing and generation strategies leveraging ChatGPT. We then train a suite of detoxification models with our cross-platform corpus. We show that our detoxification models outperform the SoTA model trained with human-annotated par",
    "path": "papers/24/02/2402.15951.json",
    "total_tokens": 829,
    "translated_title": "GreenLLaMA: 一种带有解释的解毒框架",
    "translated_abstract": "先前关于解毒的研究工作分散在某种程度上，因为它们并没有涵盖到真实场景中所需的所有解毒方面。值得注意的是，先前的研究将开发解毒模型的任务局限在仅见过的平台子集上，没有探讨模型在未知平台上的表现如何。此外，这些工作没有解决不可解毒性这一现象，即毒性文本无法在不改变含义的情况下进行解毒。我们提出了GreenLLaMA，这是第一个全面的端到端解毒框架，旨在减轻上述限制。我们首先介绍了一个跨平台伪并行语料库，应用多步数据处理和生成策略利用ChatGPT。然后，我们使用跨平台语料库训练一套解毒模型。我们展示了我们的解毒模型优于使用人工注释的最先进模型的表现。",
    "tldr": "GreenLLaMA是一种全面的端到端解毒框架，通过跨平台语料库训练出的模型优于当前最先进的模型。"
}