{
    "title": "A Multi-Aspect Framework for Counter Narrative Evaluation using Large Language Models",
    "abstract": "arXiv:2402.11676v1 Announce Type: cross  Abstract: Counter narratives - informed responses to hate speech contexts designed to refute hateful claims and de-escalate encounters - have emerged as an effective hate speech intervention strategy. While previous work has proposed automatic counter narrative generation methods to aid manual interventions, the evaluation of these approaches remains underdeveloped. Previous automatic metrics for counter narrative evaluation lack alignment with human judgment as they rely on superficial reference comparisons instead of incorporating key aspects of counter narrative quality as evaluation criteria. To address prior evaluation limitations, we propose a novel evaluation framework prompting LLMs to provide scores and feedback for generated counter narrative candidates using 5 defined aspects derived from guidelines from counter narrative specialized NGOs. We found that LLM evaluators achieve strong alignment to human-annotated scores and feedback and",
    "link": "https://arxiv.org/abs/2402.11676",
    "context": "Title: A Multi-Aspect Framework for Counter Narrative Evaluation using Large Language Models\nAbstract: arXiv:2402.11676v1 Announce Type: cross  Abstract: Counter narratives - informed responses to hate speech contexts designed to refute hateful claims and de-escalate encounters - have emerged as an effective hate speech intervention strategy. While previous work has proposed automatic counter narrative generation methods to aid manual interventions, the evaluation of these approaches remains underdeveloped. Previous automatic metrics for counter narrative evaluation lack alignment with human judgment as they rely on superficial reference comparisons instead of incorporating key aspects of counter narrative quality as evaluation criteria. To address prior evaluation limitations, we propose a novel evaluation framework prompting LLMs to provide scores and feedback for generated counter narrative candidates using 5 defined aspects derived from guidelines from counter narrative specialized NGOs. We found that LLM evaluators achieve strong alignment to human-annotated scores and feedback and",
    "path": "papers/24/02/2402.11676.json",
    "total_tokens": 800,
    "translated_title": "使用大型语言模型进行反叙事评估的多方面框架",
    "translated_abstract": "反叙事是对仇恨言论背景的知情回应，旨在驳斥仇恨主张并化解冲突，已成为一种有效的仇恨言论干预策略。先前的工作提出了自动生成反叙事的方法来辅助手动干预，但这些方法的评估仍未得到充分发展。先前用于反叙事评估的自动度量标准缺乏与人类判断的一致性，因为它们依赖于表面参考比较，而不是将反叙事质量的关键方面纳入评估标准。为解决先前的评估局限性，我们提出了一个新颖的评估框架，促使LLM提供生成的反叙事候选的得分和反馈，使用了来自专门NGO的反叙事指南中提取的5个定义的方面。",
    "tldr": "提出了一个多方面框架，使用大型语言模型评估反叙事，通过5个方面从专门 NGO 指南中提取定义的内容，以解决以往评估方法的局限性。",
    "en_tdlr": "Proposed a multi-aspect framework for evaluating counter narratives using large language models, extracting 5 defined aspects from guidelines of specialized NGOs to address limitations in previous evaluation methods."
}