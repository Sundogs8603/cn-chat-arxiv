{
    "title": "A General Theory for Kernel Packets: from state space model to compactly supported basis",
    "abstract": "It is well known that the state space (SS) model formulation of a Gaussian process (GP) can lower its training and prediction time both to O(n) for n data points. We prove that an $m$-dimensional SS model formulation of GP is equivalent to a concept we introduce as the general right Kernel Packet (KP): a transformation for the GP covariance function $K$ such that $\\sum_{i=0}^{m}a_iD_t^{(j)}K(t,t_i)=0$ holds for any $t \\leq t_1$, 0 $\\leq j \\leq m-1$, and $m+1$ consecutive points $t_i$, where ${D}_t^{(j)}f(t) $ denotes $j$-th order derivative acting on $t$. We extend this idea to the backward SS model formulation of the GP, leading to the concept of the left KP for next $m$ consecutive points: $\\sum_{i=0}^{m}b_i{D}_t^{(j)}K(t,t_{m+i})=0$ for any $t\\geq t_{2m}$. By combining both left and right KPs, we can prove that a suitable linear combination of these covariance functions yields $m$ compactly supported KP functions: $\\phi^{(j)}(t)=0$ for any $t\\not\\in(t_0,t_{2m})$ and $j=0,\\cdots,m-1$",
    "link": "https://arxiv.org/abs/2402.04022",
    "context": "Title: A General Theory for Kernel Packets: from state space model to compactly supported basis\nAbstract: It is well known that the state space (SS) model formulation of a Gaussian process (GP) can lower its training and prediction time both to O(n) for n data points. We prove that an $m$-dimensional SS model formulation of GP is equivalent to a concept we introduce as the general right Kernel Packet (KP): a transformation for the GP covariance function $K$ such that $\\sum_{i=0}^{m}a_iD_t^{(j)}K(t,t_i)=0$ holds for any $t \\leq t_1$, 0 $\\leq j \\leq m-1$, and $m+1$ consecutive points $t_i$, where ${D}_t^{(j)}f(t) $ denotes $j$-th order derivative acting on $t$. We extend this idea to the backward SS model formulation of the GP, leading to the concept of the left KP for next $m$ consecutive points: $\\sum_{i=0}^{m}b_i{D}_t^{(j)}K(t,t_{m+i})=0$ for any $t\\geq t_{2m}$. By combining both left and right KPs, we can prove that a suitable linear combination of these covariance functions yields $m$ compactly supported KP functions: $\\phi^{(j)}(t)=0$ for any $t\\not\\in(t_0,t_{2m})$ and $j=0,\\cdots,m-1$",
    "path": "papers/24/02/2402.04022.json",
    "total_tokens": 1109,
    "translated_title": "一种从状态空间模型到紧支持基的核分组的通用理论",
    "translated_abstract": "众所周知，高斯过程（GP）的状态空间（SS）模型公式可以将其训练和预测时间降低到O（n）（n为数据点个数）。我们证明了一个m维的GP的SS模型公式等价于我们引入的一个概念，称为通用右核分组（KP）：一种用于GP协方差函数K的变换，使得对于任意$t \\leq t_1$，$0 \\leq j \\leq m-1$和$m+1$个连续点$t_i$，都满足$\\sum_{i=0}^{m}a_iD_t^{(j)}K(t,t_i)=0$，其中${D}_t^{(j)}f(t)$表示在$t$上作用的第j阶导数。我们将这个思想扩展到了GP的向后SS模型公式，得到了下一个$m$个连续点的左核分组的概念：$\\sum_{i=0}^{m}b_i{D}_t^{(j)}K(t,t_{m+i})=0$，对于任意$t\\geq t_{2m}$。通过结合左右核分组，可以证明这些协方差函数的适当线性组合产生了$m$个紧支持的核分组函数：对于任意$t\\not\\in(t_0,t_{2m})$和$j=0,\\cdots,m-1$，$\\phi^{(j)}(t)=0$。",
    "tldr": "该论文提出了一种从状态空间模型到紧支持基的核分组的通用理论，该理论可以用于降低高斯过程的训练和预测时间，并且通过适当的线性组合产生了$m$个紧支持的核分组函数。",
    "en_tdlr": "This paper presents a general theory for kernel packets, which can be used to reduce the training and prediction time of Gaussian processes. The theory introduces the concepts of general right and left kernel packets, which can be combined to generate compactly supported kernel packet functions."
}