{
    "title": "Does the Generator Mind its Contexts? An Analysis of Generative Model Faithfulness under Context Transfer",
    "abstract": "arXiv:2402.14488v1 Announce Type: new  Abstract: The present study introduces the knowledge-augmented generator, which is specifically designed to produce information that remains grounded in contextual knowledge, regardless of alterations in the context. Previous research has predominantly focused on examining hallucinations stemming from static input, such as in the domains of summarization or machine translation. However, our investigation delves into the faithfulness of generative question answering in the presence of dynamic knowledge. Our objective is to explore the existence of hallucinations arising from parametric memory when contextual knowledge undergoes changes, while also analyzing the underlying causes for their occurrence. In order to efficiently address this issue, we propose a straightforward yet effective measure for detecting such hallucinations. Intriguingly, our investigation uncovers that all models exhibit a tendency to generate previous answers as hallucinations",
    "link": "https://arxiv.org/abs/2402.14488",
    "context": "Title: Does the Generator Mind its Contexts? An Analysis of Generative Model Faithfulness under Context Transfer\nAbstract: arXiv:2402.14488v1 Announce Type: new  Abstract: The present study introduces the knowledge-augmented generator, which is specifically designed to produce information that remains grounded in contextual knowledge, regardless of alterations in the context. Previous research has predominantly focused on examining hallucinations stemming from static input, such as in the domains of summarization or machine translation. However, our investigation delves into the faithfulness of generative question answering in the presence of dynamic knowledge. Our objective is to explore the existence of hallucinations arising from parametric memory when contextual knowledge undergoes changes, while also analyzing the underlying causes for their occurrence. In order to efficiently address this issue, we propose a straightforward yet effective measure for detecting such hallucinations. Intriguingly, our investigation uncovers that all models exhibit a tendency to generate previous answers as hallucinations",
    "path": "papers/24/02/2402.14488.json",
    "total_tokens": 816,
    "translated_title": "生成器是否关心其上下文？对上下文转移情况下生成模型忠实性的分析",
    "translated_abstract": "本研究引入了知识增强的生成器，旨在产生保持基于上下文知识的信息，无论上下文如何改变。先前的研究主要集中在检验源自静态输入的幻觉，例如在摘要或机器翻译领域。然而，我们的研究探讨了在动态知识存在的情况下生成式问答的忠实性。我们的目标是探索当上下文知识发生变化时由参数化内存产生幻觉的存在，并分析其发生的潜在原因。为了有效地解决这个问题，我们提出了一种简单而有效的方法来检测这种幻觉。有趣的是，我们的调查发现所有模型都有生成先前答案作为幻觉的倾向。",
    "tldr": "本研究引入了知识增强的生成器，旨在产生保持基于上下文知识的信息，无论上下文如何改变。调查发现所有模型都有生成先前答案作为幻觉的倾向。",
    "en_tdlr": "The study introduces a knowledge-augmented generator designed to produce information grounded in contextual knowledge, regardless of contextual changes. The investigation reveals a tendency in all models to generate previous answers as hallucinations."
}