{
    "title": "Entity-level Factual Adaptiveness of Fine-tuning based Abstractive Summarization Models",
    "abstract": "arXiv:2402.15162v1 Announce Type: cross  Abstract: Abstractive summarization models often generate factually inconsistent content particularly when the parametric knowledge of the model conflicts with the knowledge in the input document. In this paper, we analyze the robustness of fine-tuning based summarization models to the knowledge conflict, which we call factual adaptiveness. We utilize pre-trained language models to construct evaluation sets and find that factual adaptiveness is not strongly correlated with factual consistency on original datasets. Furthermore, we introduce a controllable counterfactual data augmentation method where the degree of knowledge conflict within the augmented data can be adjustable. Our experimental results on two pre-trained language models (PEGASUS and BART) and two fine-tuning datasets (XSum and CNN/DailyMail) demonstrate that our method enhances factual adaptiveness while achieving factual consistency on original datasets on par with the contrastiv",
    "link": "https://arxiv.org/abs/2402.15162",
    "context": "Title: Entity-level Factual Adaptiveness of Fine-tuning based Abstractive Summarization Models\nAbstract: arXiv:2402.15162v1 Announce Type: cross  Abstract: Abstractive summarization models often generate factually inconsistent content particularly when the parametric knowledge of the model conflicts with the knowledge in the input document. In this paper, we analyze the robustness of fine-tuning based summarization models to the knowledge conflict, which we call factual adaptiveness. We utilize pre-trained language models to construct evaluation sets and find that factual adaptiveness is not strongly correlated with factual consistency on original datasets. Furthermore, we introduce a controllable counterfactual data augmentation method where the degree of knowledge conflict within the augmented data can be adjustable. Our experimental results on two pre-trained language models (PEGASUS and BART) and two fine-tuning datasets (XSum and CNN/DailyMail) demonstrate that our method enhances factual adaptiveness while achieving factual consistency on original datasets on par with the contrastiv",
    "path": "papers/24/02/2402.15162.json",
    "total_tokens": 846,
    "translated_title": "基于微调的抽象式摘要模型的实体级事实适应性",
    "translated_abstract": "抽象式摘要模型在处理参数化知识与输入文档中的知识冲突时，往往生成事实不一致的内容。本文分析了基于微调的摘要模型对知识冲突的鲁棒性，即我们称之为事实适应性。我们利用预训练语言模型构建评估集，并发现事实适应性与原始数据集上的事实一致性并非强相关。此外，我们引入了一种可控的反事实数据增强方法，其中增强数据中的知识冲突程度是可调节的。我们在两个预训练语言模型（PEGASUS 和 BART）和两个微调数据集（XSum 和 CNN/DailyMail）上的实验结果表明，我们的方法增强了事实适应性，同时在原始数据集上实现了与对比方法相当的事实一致性。",
    "tldr": "分析了基于微调的摘要模型在处理知识冲突时的实体级事实适应性，并提出了一种反事实数据增强方法，实验结果表明该方法增强了事实适应性，同时保持了事实一致性。",
    "en_tdlr": "Analyzed the entity-level factual adaptiveness of fine-tuning based summarization models in handling knowledge conflicts and proposed a controllable counterfactual data augmentation method, with experimental results demonstrating enhanced factual adaptiveness while maintaining factual consistency."
}