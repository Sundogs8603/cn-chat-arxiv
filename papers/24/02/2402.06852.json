{
    "title": "ChemLLM: A Chemical Large Language Model",
    "abstract": "Large language models (LLMs) have made impressive progress in chemistry applications, including molecular property prediction, molecular generation, experimental protocol design, etc. However, the community lacks a dialogue-based model specifically designed for chemistry. The challenge arises from the fact that most chemical data and scientific knowledge are primarily stored in structured databases, and the direct use of these structured data compromises the model's ability to maintain coherent dialogue. To tackle this issue, we develop a novel template-based instruction construction method that transforms structured knowledge into plain dialogue, making it suitable for language model training. By leveraging this approach, we develop ChemLLM, the first large language model dedicated to chemistry, capable of performing various tasks across chemical disciplines with smooth dialogue interaction. ChemLLM beats GPT-3.5 on all three principal tasks in chemistry, i.e., name conversion, molecu",
    "link": "https://arxiv.org/abs/2402.06852",
    "context": "Title: ChemLLM: A Chemical Large Language Model\nAbstract: Large language models (LLMs) have made impressive progress in chemistry applications, including molecular property prediction, molecular generation, experimental protocol design, etc. However, the community lacks a dialogue-based model specifically designed for chemistry. The challenge arises from the fact that most chemical data and scientific knowledge are primarily stored in structured databases, and the direct use of these structured data compromises the model's ability to maintain coherent dialogue. To tackle this issue, we develop a novel template-based instruction construction method that transforms structured knowledge into plain dialogue, making it suitable for language model training. By leveraging this approach, we develop ChemLLM, the first large language model dedicated to chemistry, capable of performing various tasks across chemical disciplines with smooth dialogue interaction. ChemLLM beats GPT-3.5 on all three principal tasks in chemistry, i.e., name conversion, molecu",
    "path": "papers/24/02/2402.06852.json",
    "total_tokens": 871,
    "translated_title": "ChemLLM: 一个化学大型语言模型",
    "translated_abstract": "大型语言模型（LLM）在化学应用中取得了令人瞩目的进展，包括分子属性预测、分子生成、实验协议设计等。然而，该领域缺乏一个专门针对化学领域设计的基于对话的模型。这个挑战来自于事实，大多数化学数据和科学知识主要存储在结构化数据库中，直接使用这些结构化数据会影响模型维持连贯对话的能力。为了解决这个问题，我们开发了一种新颖的基于模板的指令构建方法，将结构化知识转化为简洁对话形式，适合于语言模型的训练。通过利用这种方法，我们开发了ChemLLM，第一个专门用于化学的大型语言模型，能够在化学领域的各种任务中进行平滑对话交互。ChemLLM在化学的三个主要任务，即名称转换、分子生成和实验协议设计方面，击败了GPT-3.5。",
    "tldr": "ChemLLM是第一个专门用于化学领域的大型语言模型，利用新颖的指令构建方法将结构化知识转化为对话形式，具有平滑对话交互的能力，并在化学的三个主要任务中击败了GPT-3.5。"
}