{
    "title": "Enhance DNN Adversarial Robustness and Efficiency via Injecting Noise to Non-Essential Neurons",
    "abstract": "Deep Neural Networks (DNNs) have revolutionized a wide range of industries, from healthcare and finance to automotive, by offering unparalleled capabilities in data analysis and decision-making. Despite their transforming impact, DNNs face two critical challenges: the vulnerability to adversarial attacks and the increasing computational costs associated with more complex and larger models. In this paper, we introduce an effective method designed to simultaneously enhance adversarial robustness and execution efficiency. Unlike prior studies that enhance robustness via uniformly injecting noise, we introduce a non-uniform noise injection algorithm, strategically applied at each DNN layer to disrupt adversarial perturbations introduced in attacks. By employing approximation techniques, our approach identifies and protects essential neurons while strategically introducing noise into non-essential neurons. Our experimental results demonstrate that our method successfully enhances both robus",
    "link": "https://arxiv.org/abs/2402.04325",
    "context": "Title: Enhance DNN Adversarial Robustness and Efficiency via Injecting Noise to Non-Essential Neurons\nAbstract: Deep Neural Networks (DNNs) have revolutionized a wide range of industries, from healthcare and finance to automotive, by offering unparalleled capabilities in data analysis and decision-making. Despite their transforming impact, DNNs face two critical challenges: the vulnerability to adversarial attacks and the increasing computational costs associated with more complex and larger models. In this paper, we introduce an effective method designed to simultaneously enhance adversarial robustness and execution efficiency. Unlike prior studies that enhance robustness via uniformly injecting noise, we introduce a non-uniform noise injection algorithm, strategically applied at each DNN layer to disrupt adversarial perturbations introduced in attacks. By employing approximation techniques, our approach identifies and protects essential neurons while strategically introducing noise into non-essential neurons. Our experimental results demonstrate that our method successfully enhances both robus",
    "path": "papers/24/02/2402.04325.json",
    "total_tokens": 964,
    "translated_title": "通过向非关键神经元注入噪音增强DNN对抗性鲁棒性和效率",
    "translated_abstract": "深度神经网络（DNN）通过在数据分析和决策方面提供无与伦比的能力，已经彻底改变了许多行业，从医疗和金融到汽车。尽管其具有的转型影响，DNN面临着两个关键挑战：对于对抗攻击的脆弱性和与更复杂和更大模型相关的计算成本的增加。本文介绍了一种有效的方法，旨在同时增强对抗鲁棒性和执行效率。与以往通过均匀注入噪音以增强鲁棒性的研究不同，我们引入了一种非均匀噪音注入算法， strategically applied at每一个DNN layer，以干扰攻击中引入的对抗扰动。通过采用近似技术，我们的方法识别并保护关键神经元，同时对非关键神经元策略性地引入噪音。我们的实验结果证明，我们的方法成功地增强了对抗鲁棒性和执行效率。",
    "tldr": "本文提出了一种有效的方法，通过向非关键神经元注入噪音来增强DNN的对抗鲁棒性和执行效率。与以往的方法不同，我们通过在每个DNN层上策略性地引入噪音来干扰对抗攻击。实验结果表明，我们的方法成功地提高了对抗鲁棒性和执行效率。",
    "en_tdlr": "This paper introduces an effective method to enhance the adversarial robustness and execution efficiency of DNNs by injecting noise into non-essential neurons. Unlike prior studies, our approach strategically disrupts adversarial perturbations by introducing noise at each DNN layer. Experimental results demonstrate its success in improving adversarial robustness and execution efficiency."
}