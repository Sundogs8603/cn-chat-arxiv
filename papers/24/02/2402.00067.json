{
    "title": "Online speaker diarization of meetings guided by speech separation",
    "abstract": "Overlapped speech is notoriously problematic for speaker diarization systems. Consequently, the use of speech separation has recently been proposed to improve their performance. Although promising, speech separation models struggle with realistic data because they are trained on simulated mixtures with a fixed number of speakers. In this work, we introduce a new speech separation-guided diarization scheme suitable for the online speaker diarization of long meeting recordings with a variable number of speakers, as present in the AMI corpus. We envisage ConvTasNet and DPRNN as alternatives for the separation networks, with two or three output sources. To obtain the speaker diarization result, voice activity detection is applied on each estimated source. The final model is fine-tuned end-to-end, after first adapting the separation to real data using AMI. The system operates on short segments, and inference is performed by stitching the local predictions using speaker embeddings and increm",
    "link": "https://arxiv.org/abs/2402.00067",
    "context": "Title: Online speaker diarization of meetings guided by speech separation\nAbstract: Overlapped speech is notoriously problematic for speaker diarization systems. Consequently, the use of speech separation has recently been proposed to improve their performance. Although promising, speech separation models struggle with realistic data because they are trained on simulated mixtures with a fixed number of speakers. In this work, we introduce a new speech separation-guided diarization scheme suitable for the online speaker diarization of long meeting recordings with a variable number of speakers, as present in the AMI corpus. We envisage ConvTasNet and DPRNN as alternatives for the separation networks, with two or three output sources. To obtain the speaker diarization result, voice activity detection is applied on each estimated source. The final model is fine-tuned end-to-end, after first adapting the separation to real data using AMI. The system operates on short segments, and inference is performed by stitching the local predictions using speaker embeddings and increm",
    "path": "papers/24/02/2402.00067.json",
    "total_tokens": 824,
    "translated_title": "会议时长在线说话人辨识引导的语音分离",
    "translated_abstract": "重叠语音对说话人辨识系统一直是问题。因此，最近提出了使用语音分离来改善其性能。尽管有前景，但是由于它们在具有固定人数的模拟混合物上进行训练，语音分离模型在现实数据上很难应对。在这项工作中，我们引入了一种适用于在线对长时间会议录音进行说话人辨识的语音分离引导方案，这些录音具有可变的说话人数量，就像在AMI语料库中一样。我们可以将ConvTasNet和DPRNN视为分离网络的替代方案，输出两个或三个源。为了得到说话人辨识结果，对每个估计的源应用语音活动检测。在首先使用AMI将分离模型适应于真实数据后，最终模型进行了端到端的微调。系统在短段上操作，使用说话人嵌入和增量式 stitching 以进行推断。",
    "tldr": "本研究提出了一种适用于在线对长时间会议录音进行说话人辨识的新颖方法，通过语音分离来引导辨识过程。该方法能有效处理具有可变说话人数量的真实数据，并通过微调模型实现端到端的优化。"
}