{
    "title": "Explorations of Self-Repair in Language Models",
    "abstract": "arXiv:2402.15390v1 Announce Type: cross  Abstract: Prior interpretability research studying narrow distributions has preliminarily identified self-repair, a phenomena where if components in large language models are ablated, later components will change their behavior to compensate. Our work builds off this past literature, demonstrating that self-repair exists on a variety of models families and sizes when ablating individual attention heads on the full training distribution. We further show that on the full training distribution self-repair is imperfect, as the original direct effect of the head is not fully restored, and noisy, since the degree of self-repair varies significantly across different prompts (sometimes overcorrecting beyond the original effect). We highlight two different mechanisms that contribute to self-repair, including changes in the final LayerNorm scaling factor (which can repair up to 30% of the direct effect) and sparse sets of neurons implementing Anti-Erasure",
    "link": "https://arxiv.org/abs/2402.15390",
    "context": "Title: Explorations of Self-Repair in Language Models\nAbstract: arXiv:2402.15390v1 Announce Type: cross  Abstract: Prior interpretability research studying narrow distributions has preliminarily identified self-repair, a phenomena where if components in large language models are ablated, later components will change their behavior to compensate. Our work builds off this past literature, demonstrating that self-repair exists on a variety of models families and sizes when ablating individual attention heads on the full training distribution. We further show that on the full training distribution self-repair is imperfect, as the original direct effect of the head is not fully restored, and noisy, since the degree of self-repair varies significantly across different prompts (sometimes overcorrecting beyond the original effect). We highlight two different mechanisms that contribute to self-repair, including changes in the final LayerNorm scaling factor (which can repair up to 30% of the direct effect) and sparse sets of neurons implementing Anti-Erasure",
    "path": "papers/24/02/2402.15390.json",
    "total_tokens": 869,
    "translated_title": "在语言模型中自修复的探索",
    "translated_abstract": "先前研究狭窄分布的可解释性发现了自修复现象，即如果剥离大型语言模型中的组件，后续组件会改变其行为以进行补偿。我们的工作基于这些过去的文献，展示了当在完整的训练分布上剥离单个注意力头时，自修复存在于各种模型家族和尺寸上。我们进一步表明，在完整的训练分布上，自修复是不完美的，因为头部的原始直接效果并未完全恢复，并且是嘈杂的，因为自修复程度在不同提示之间显著变化（有时超过原始效果）。我们强调了促成自修复的两种不同机制，包括最终LayerNorm缩放因子的变化（可修复直接效果的30%）以及实现反擦除的稀疏神经元集。",
    "tldr": "自修复现象存在于各种模型家族和尺寸上，但在完整的训练分布上是不完美和嘈杂的，有两种机制可促成自修复，包括最终LayerNorm缩放因子的变化和实现反擦除的稀疏神经元集。",
    "en_tdlr": "Self-repair phenomenon exists across various model families and sizes, but is imperfect and noisy on the full training distribution. Two mechanisms contribute to self-repair, including changes in the final LayerNorm scaling factor and sparse sets of neurons implementing Anti-Erasure."
}