{
    "title": "Alirector: Alignment-Enhanced Chinese Grammatical Error Corrector",
    "abstract": "Chinese grammatical error correction (CGEC) faces serious overcorrection challenges when employing autoregressive generative models such as sequence-to-sequence (Seq2Seq) models and decoder-only large language models (LLMs). While previous methods aim to address overcorrection in Seq2Seq models, they are difficult to adapt to decoder-only LLMs. In this paper, we propose an alignment-enhanced corrector for the overcorrection problem that applies to both Seq2Seq models and decoder-only LLMs. Our method first trains a correction model to generate an initial correction of the source sentence. Then, we combine the source sentence with the initial correction and feed it through an alignment model for another round of correction, aiming to enforce the alignment model to focus on potential overcorrection. Moreover, to enhance the model's ability to identify nuances, we further explore the reverse alignment of the source sentence and the initial correction. Finally, we transfer the alignment kn",
    "link": "https://arxiv.org/abs/2402.04601",
    "context": "Title: Alirector: Alignment-Enhanced Chinese Grammatical Error Corrector\nAbstract: Chinese grammatical error correction (CGEC) faces serious overcorrection challenges when employing autoregressive generative models such as sequence-to-sequence (Seq2Seq) models and decoder-only large language models (LLMs). While previous methods aim to address overcorrection in Seq2Seq models, they are difficult to adapt to decoder-only LLMs. In this paper, we propose an alignment-enhanced corrector for the overcorrection problem that applies to both Seq2Seq models and decoder-only LLMs. Our method first trains a correction model to generate an initial correction of the source sentence. Then, we combine the source sentence with the initial correction and feed it through an alignment model for another round of correction, aiming to enforce the alignment model to focus on potential overcorrection. Moreover, to enhance the model's ability to identify nuances, we further explore the reverse alignment of the source sentence and the initial correction. Finally, we transfer the alignment kn",
    "path": "papers/24/02/2402.04601.json",
    "total_tokens": 951,
    "translated_title": "Alirector: 提升对齐的中文语法错误修正器",
    "translated_abstract": "中文语法错误修正（CGEC）在使用自回归生成模型（如序列到序列模型和仅解码的大型语言模型）时面临严重的过度修正挑战。虽然以前的方法旨在解决序列到序列模型中的过度修正问题，但很难适应仅解码的大型语言模型。本文提出了一种提升对齐的解决方案，适用于序列到序列模型和仅解码的大型语言模型，并且能够解决过度修正问题。我们的方法首先训练一个修正模型，生成源句子的初始修正。然后，将源句子与初始修正结合起来，通过一个对齐模型进行另一轮修正，以促使对齐模型专注于潜在的过度修正。此外，为了增强模型识别细微差别的能力，我们进一步探索了源句子和初始修正的逆向对齐。最后，我们将对齐的知识转移到CGEC模型中，以提高修正效果。",
    "tldr": "本文提出了一种提升对齐的中文语法错误修正器，旨在解决使用自回归生成模型时面临的过度修正挑战。该方法适用于序列到序列模型和仅解码的大型语言模型，并通过对齐模型进行多轮修正，提高修正效果。"
}