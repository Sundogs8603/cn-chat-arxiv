{
    "title": "Stable Training of Normalizing Flows for High-dimensional Variational Inference",
    "abstract": "arXiv:2402.16408v1 Announce Type: cross  Abstract: Variational inference with normalizing flows (NFs) is an increasingly popular alternative to MCMC methods. In particular, NFs based on coupling layers (Real NVPs) are frequently used due to their good empirical performance. In theory, increasing the depth of normalizing flows should lead to more accurate posterior approximations. However, in practice, training deep normalizing flows for approximating high-dimensional posterior distributions is often infeasible due to the high variance of the stochastic gradients. In this work, we show that previous methods for stabilizing the variance of stochastic gradient descent can be insufficient to achieve stable training of Real NVPs. As the source of the problem, we identify that, during training, samples often exhibit unusual high values. As a remedy, we propose a combination of two methods: (1) soft-thresholding of the scale in Real NVPs, and (2) a bijective soft log transformation of the sam",
    "link": "https://arxiv.org/abs/2402.16408",
    "context": "Title: Stable Training of Normalizing Flows for High-dimensional Variational Inference\nAbstract: arXiv:2402.16408v1 Announce Type: cross  Abstract: Variational inference with normalizing flows (NFs) is an increasingly popular alternative to MCMC methods. In particular, NFs based on coupling layers (Real NVPs) are frequently used due to their good empirical performance. In theory, increasing the depth of normalizing flows should lead to more accurate posterior approximations. However, in practice, training deep normalizing flows for approximating high-dimensional posterior distributions is often infeasible due to the high variance of the stochastic gradients. In this work, we show that previous methods for stabilizing the variance of stochastic gradient descent can be insufficient to achieve stable training of Real NVPs. As the source of the problem, we identify that, during training, samples often exhibit unusual high values. As a remedy, we propose a combination of two methods: (1) soft-thresholding of the scale in Real NVPs, and (2) a bijective soft log transformation of the sam",
    "path": "papers/24/02/2402.16408.json",
    "total_tokens": 783,
    "translated_title": "高维变分推断中正规化流的稳定训练",
    "translated_abstract": "使用正规化流进行变分推断在取代MCMC方法方面越来越受欢迎。特别是基于耦合层（Real NVPs）的正规化流由于其良好的经验性能而经常使用。然而，在实践中，训练用于逼近高维后验分布的深层正规化流通常是不可行的，因为随机梯度的高方差。在这项工作中，我们展示了先前用于稳定随机梯度下降方差的方法可能不足以实现Real NVPs的稳定训练。我们确定问题的根源是，在训练期间，样本通常呈现异常高的值。为了解决这个问题，我们提出了两种方法的组合：（1）对Real NVPs中的尺度进行软阈值处理，以及（2）对样本进行双射软对数变换。",
    "tldr": "提出了稳定训练高维变分推断中正规化流的方法"
}