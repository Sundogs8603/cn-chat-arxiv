{
    "title": "Unleashing the Power of Imbalanced Modality Information for Multi-modal Knowledge Graph Completion",
    "abstract": "arXiv:2402.15444v1 Announce Type: new  Abstract: Multi-modal knowledge graph completion (MMKGC) aims to predict the missing triples in the multi-modal knowledge graphs by incorporating structural, visual, and textual information of entities into the discriminant models. The information from different modalities will work together to measure the triple plausibility. Existing MMKGC methods overlook the imbalance problem of modality information among entities, resulting in inadequate modal fusion and inefficient utilization of the raw modality information. To address the mentioned problems, we propose Adaptive Multi-modal Fusion and Modality Adversarial Training (AdaMF-MAT) to unleash the power of imbalanced modality information for MMKGC. AdaMF-MAT achieves multi-modal fusion with adaptive modality weights and further generates adversarial samples by modality-adversarial training to enhance the imbalanced modality information. Our approach is a co-design of the MMKGC model and training s",
    "link": "https://arxiv.org/abs/2402.15444",
    "context": "Title: Unleashing the Power of Imbalanced Modality Information for Multi-modal Knowledge Graph Completion\nAbstract: arXiv:2402.15444v1 Announce Type: new  Abstract: Multi-modal knowledge graph completion (MMKGC) aims to predict the missing triples in the multi-modal knowledge graphs by incorporating structural, visual, and textual information of entities into the discriminant models. The information from different modalities will work together to measure the triple plausibility. Existing MMKGC methods overlook the imbalance problem of modality information among entities, resulting in inadequate modal fusion and inefficient utilization of the raw modality information. To address the mentioned problems, we propose Adaptive Multi-modal Fusion and Modality Adversarial Training (AdaMF-MAT) to unleash the power of imbalanced modality information for MMKGC. AdaMF-MAT achieves multi-modal fusion with adaptive modality weights and further generates adversarial samples by modality-adversarial training to enhance the imbalanced modality information. Our approach is a co-design of the MMKGC model and training s",
    "path": "papers/24/02/2402.15444.json",
    "total_tokens": 839,
    "translated_title": "发挥不平衡模态信息在多模态知识图完成中的力量",
    "translated_abstract": "多模态知识图完成（MMKGC）旨在通过将实体的结构、视觉和文本信息纳入判别模型来预测多模态知识图中缺失的三元组。来自不同模态的信息将共同工作以衡量三元组的可能性。现有的MMKGC方法忽视了实体之间模态信息不平衡的问题，导致模态融合不足以及对原始模态信息的低效利用。为解决上述问题，我们提出了自适应多模态融合和模态对抗训练（AdaMF-MAT），以发挥不平衡模态信息在MMKGC中的力量。AdaMF-MAT通过自适应模态权重实现多模态融合，并通过模态对抗训练生成对抗样本，以增强不平衡模态信息。我们的方法是MMKGC模型和训练的协同设计。",
    "tldr": "提出了自适应多模态融合和模态对抗训练（AdaMF-MAT）方法，以解决多模态知识图完成中存在的模态信息不平衡问题，发挥不平衡模态信息的力量。"
}