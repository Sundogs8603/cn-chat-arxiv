{
    "title": "Increasing SAM Zero-Shot Performance on Multimodal Medical Images Using GPT-4 Generated Descriptive Prompts Without Human Annotation",
    "abstract": "arXiv:2402.15759v1 Announce Type: cross  Abstract: This study develops and evaluates a novel multimodal medical image zero-shot segmentation algorithm named Text-Visual-Prompt SAM (TV-SAM) without any manual annotations. TV-SAM incorporates and integrates large language model GPT-4, Vision Language Model GLIP, and Segment Anything Model (SAM), to autonomously generate descriptive text prompts and visual bounding box prompts from medical images, thereby enhancing SAM for zero-shot segmentation. Comprehensive evaluations are implemented on seven public datasets encompassing eight imaging modalities to demonstrate that TV-SAM can effectively segment unseen targets across various modalities without additional training, significantly outperforming SAM AUTO and GSAM, closely matching the performance of SAM BBOX with gold standard bounding box prompts, and surpassing the state-of-the-art on specific datasets like ISIC and WBC. The study indicates that TV-SAM serves as an effective multimodal ",
    "link": "https://arxiv.org/abs/2402.15759",
    "context": "Title: Increasing SAM Zero-Shot Performance on Multimodal Medical Images Using GPT-4 Generated Descriptive Prompts Without Human Annotation\nAbstract: arXiv:2402.15759v1 Announce Type: cross  Abstract: This study develops and evaluates a novel multimodal medical image zero-shot segmentation algorithm named Text-Visual-Prompt SAM (TV-SAM) without any manual annotations. TV-SAM incorporates and integrates large language model GPT-4, Vision Language Model GLIP, and Segment Anything Model (SAM), to autonomously generate descriptive text prompts and visual bounding box prompts from medical images, thereby enhancing SAM for zero-shot segmentation. Comprehensive evaluations are implemented on seven public datasets encompassing eight imaging modalities to demonstrate that TV-SAM can effectively segment unseen targets across various modalities without additional training, significantly outperforming SAM AUTO and GSAM, closely matching the performance of SAM BBOX with gold standard bounding box prompts, and surpassing the state-of-the-art on specific datasets like ISIC and WBC. The study indicates that TV-SAM serves as an effective multimodal ",
    "path": "papers/24/02/2402.15759.json",
    "total_tokens": 838,
    "translated_title": "使用GPT-4生成描述性提示提高多模态医学图像上的SAM零样本性能而无需人工标注",
    "translated_abstract": "本研究开发并评估了一种新型的多模态医学图像零样本分割算法，命名为文本-视觉-提示SAM（TV-SAM），无需任何手动标注。TV-SAM融合并整合了大型语言模型GPT-4、视觉语言模型GLIP和“Segment Anything Model”（SAM），从医学图像中自动生成描述性文本提示和视觉边界框提示，从而增强了SAM用于零样本分割。在七个公共数据集上进行了全面评估，涵盖八种成像模式，证明TV-SAM可以有效地跨各种模式分割未见过的目标而无需额外训练，明显优于SAM AUTO和GSAM, 与金标准边界框提示的SAM BBOX性能基本匹敌，并在特定数据集（如ISIC和WBC）上超越了现有技术水平。研究表明，TV-SAM是一种有效的多模态",
    "tldr": "使用GPT-4生成描述性提示，提高了多模态医学图像上的SAM零样本分割性能，无需人工标注。"
}