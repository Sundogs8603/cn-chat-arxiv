{
    "title": "Mixture of Link Predictors",
    "abstract": "Link prediction, which aims to forecast unseen connections in graphs, is a fundamental task in graph machine learning. Heuristic methods, leveraging a range of different pairwise measures such as common neighbors and shortest paths, often rival the performance of vanilla Graph Neural Networks (GNNs). Therefore, recent advancements in GNNs for link prediction (GNN4LP) have primarily focused on integrating one or a few types of pairwise information. In this work, we reveal that different node pairs within the same dataset necessitate varied pairwise information for accurate prediction and models that only apply the same pairwise information uniformly could achieve suboptimal performance. As a result, we propose a simple mixture of experts model Link-MoE for link prediction. Link-MoE utilizes various GNNs as experts and strategically selects the appropriate expert for each node pair based on various types of pairwise information. Experimental results across diverse real-world datasets dem",
    "link": "https://arxiv.org/abs/2402.08583",
    "context": "Title: Mixture of Link Predictors\nAbstract: Link prediction, which aims to forecast unseen connections in graphs, is a fundamental task in graph machine learning. Heuristic methods, leveraging a range of different pairwise measures such as common neighbors and shortest paths, often rival the performance of vanilla Graph Neural Networks (GNNs). Therefore, recent advancements in GNNs for link prediction (GNN4LP) have primarily focused on integrating one or a few types of pairwise information. In this work, we reveal that different node pairs within the same dataset necessitate varied pairwise information for accurate prediction and models that only apply the same pairwise information uniformly could achieve suboptimal performance. As a result, we propose a simple mixture of experts model Link-MoE for link prediction. Link-MoE utilizes various GNNs as experts and strategically selects the appropriate expert for each node pair based on various types of pairwise information. Experimental results across diverse real-world datasets dem",
    "path": "papers/24/02/2402.08583.json",
    "total_tokens": 828,
    "translated_title": "链接预测的混合模型",
    "translated_abstract": "链接预测是图机器学习中的一项基本任务，旨在预测图中未见连接。启发式方法利用一系列不同的成对度量，如共同邻居和最短路径，常常能够与纯粹的图神经网络（GNNs）性能相媲美。因此，近期GNNs在链接预测（GNN4LP）方面的进展主要集中在整合一种或少数几种成对信息上。在这项工作中，我们揭示了同一数据集中的不同节点对需要不同的成对信息进行准确预测，而只应用相同的成对信息的模型可能会导致次优性能。因此，我们提出了一种简单的专家模型Link-MoE用于链接预测。Link-MoE利用各种GNNs作为专家，并根据不同类型的成对信息为每个节点对选择合适的专家。在各种真实数据集上的实验结果表明，Link-MoE能够显著提高预测性能。",
    "tldr": "提出了一种用于链接预测的混合模型Link-MoE，通过选择合适的专家模型，利用不同类型的成对信息，能够显著提高预测性能。",
    "en_tdlr": "A mixture of experts model, Link-MoE, is proposed for link prediction, which improves prediction performance significantly by selecting appropriate expert models and utilizing different types of pairwise information."
}