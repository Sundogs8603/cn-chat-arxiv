{
    "title": "Interpretable Generative Adversarial Imitation Learning",
    "abstract": "arXiv:2402.10310v1 Announce Type: new  Abstract: Imitation learning methods have demonstrated considerable success in teaching autonomous systems complex tasks through expert demonstrations. However, a limitation of these methods is their lack of interpretability, particularly in understanding the specific task the learning agent aims to accomplish. In this paper, we propose a novel imitation learning method that combines Signal Temporal Logic (STL) inference and control synthesis, enabling the explicit representation of the task as an STL formula. This approach not only provides a clear understanding of the task but also allows for the incorporation of human knowledge and adaptation to new scenarios through manual adjustments of the STL formulae. Additionally, we employ a Generative Adversarial Network (GAN)-inspired training approach for both the inference and the control policy, effectively narrowing the gap between the expert and learned policies. The effectiveness of our algorithm",
    "link": "https://arxiv.org/abs/2402.10310",
    "context": "Title: Interpretable Generative Adversarial Imitation Learning\nAbstract: arXiv:2402.10310v1 Announce Type: new  Abstract: Imitation learning methods have demonstrated considerable success in teaching autonomous systems complex tasks through expert demonstrations. However, a limitation of these methods is their lack of interpretability, particularly in understanding the specific task the learning agent aims to accomplish. In this paper, we propose a novel imitation learning method that combines Signal Temporal Logic (STL) inference and control synthesis, enabling the explicit representation of the task as an STL formula. This approach not only provides a clear understanding of the task but also allows for the incorporation of human knowledge and adaptation to new scenarios through manual adjustments of the STL formulae. Additionally, we employ a Generative Adversarial Network (GAN)-inspired training approach for both the inference and the control policy, effectively narrowing the gap between the expert and learned policies. The effectiveness of our algorithm",
    "path": "papers/24/02/2402.10310.json",
    "total_tokens": 904,
    "translated_title": "可解释的生成对抗模仿学习",
    "translated_abstract": "仿真学习方法已经通过专家演示在教授自主系统复杂任务方面取得了相当大的成功。然而，这些方法的局限性在于它们缺乏可解释性，特别是在理解学习代理试图完成的具体任务方面。在本文中，我们提出了一种结合了信号时序逻辑（STL）推断和控制合成的新颖仿真学习方法，使任务可以明确表示为STL公式。这种方法不仅可以清晰地理解任务，还可以通过手动调整STL公式来将人类知识纳入并适应新场景。此外，我们采用了受生成对抗网络（GAN）启发的训练方法进行推断和控制策略，有效地缩小了专家策略和学习策略之间的差距。我们算法的有效性",
    "tldr": "提出了一种结合了信号时序逻辑（STL）推断和控制合成的新颖仿真学习方法，可以明确表示任务为STL公式，同时通过人为调整STL公式实现对人类知识的纳入和新场景的适应，还采用了生成对抗网络（GAN）启发的训练方法，有效缩小了专家策略和学习策略之间的差距",
    "en_tdlr": "Proposed a novel imitation learning method that combines Signal Temporal Logic (STL) inference and control synthesis to explicitly represent the task as an STL formula, enabling incorporation of human knowledge and adaptation to new scenarios through manual adjustments of the STL formulae, and employed a Generative Adversarial Network (GAN)-inspired training approach to effectively narrow the gap between the expert and learned policies"
}