{
    "title": "Primary and Secondary Factor Consistency as Domain Knowledge to Guide Happiness Computing in Online Assessment",
    "abstract": "arXiv:2402.12398v1 Announce Type: new  Abstract: Happiness computing based on large-scale online web data and machine learning methods is an emerging research topic that underpins a range of issues, from personal growth to social stability. Many advanced Machine Learning (ML) models with explanations are used to compute the happiness online assessment while maintaining high accuracy of results. However, domain knowledge constraints, such as the primary and secondary relations of happiness factors, are absent from these models, which limits the association between computing results and the right reasons for why they occurred. This article attempts to provide new insights into the explanation consistency from an empirical study perspective. Then we study how to represent and introduce domain knowledge constraints to make ML models more trustworthy. We achieve this through: (1) proving that multiple prediction models with additive factor attributions will have the desirable property of pr",
    "link": "https://arxiv.org/abs/2402.12398",
    "context": "Title: Primary and Secondary Factor Consistency as Domain Knowledge to Guide Happiness Computing in Online Assessment\nAbstract: arXiv:2402.12398v1 Announce Type: new  Abstract: Happiness computing based on large-scale online web data and machine learning methods is an emerging research topic that underpins a range of issues, from personal growth to social stability. Many advanced Machine Learning (ML) models with explanations are used to compute the happiness online assessment while maintaining high accuracy of results. However, domain knowledge constraints, such as the primary and secondary relations of happiness factors, are absent from these models, which limits the association between computing results and the right reasons for why they occurred. This article attempts to provide new insights into the explanation consistency from an empirical study perspective. Then we study how to represent and introduce domain knowledge constraints to make ML models more trustworthy. We achieve this through: (1) proving that multiple prediction models with additive factor attributions will have the desirable property of pr",
    "path": "papers/24/02/2402.12398.json",
    "total_tokens": 816,
    "translated_title": "在线评估中利用主次要因素一致性作为领域知识指导幸福计算",
    "translated_abstract": "基于大规模在线网络数据和机器学习方法的幸福计算是一个新兴的研究课题，支持个人成长和社会稳定等一系列问题。许多带有解释的先进机器学习（ML）模型被用于计算在线评估幸福，同时保持高准确性的结果。然而，这些模型缺乏主次幸福因素关系等领域知识约束，这限制了计算结果与发生的原因之间的关联。本文试图从经验研究的角度提供对解释一致性的新见解。然后我们研究如何表示和引入领域知识约束以使ML模型更加可信。我们通过以下方式实现这一目标：（1）证明具有附加因素归因的多个预测模型将具有良好的性质",
    "tldr": "本文尝试通过实证研究角度提供对解释一致性的新见解，并研究如何通过引入领域知识约束来使机器学习模型更加可信。",
    "en_tdlr": "This paper attempts to provide new insights into explanation consistency from an empirical study perspective, and investigate how to make machine learning models more trustworthy by introducing domain knowledge constraints."
}