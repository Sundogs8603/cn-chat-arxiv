{
    "title": "Long Is More for Alignment: A Simple but Tough-to-Beat Baseline for Instruction Fine-Tuning",
    "abstract": "There is a consensus that instruction fine-tuning of LLMs requires high-quality data, but what are they? LIMA (NeurIPS 2023) and AlpaGasus (ICLR 2024) are state-of-the-art methods for selecting such high-quality examples, either via manual curation or using GPT-3.5-Turbo as a quality scorer. We show that the extremely simple baseline of selecting the 1,000 instructions with longest responses from standard datasets can consistently outperform these sophisticated methods according to GPT-4 and PaLM-2 as judges, while remaining competitive on the OpenLLM benchmarks that test factual knowledge. We demonstrate this for several state-of-the-art LLMs (Llama-2-7B, Llama-2-13B, and Mistral-7B) and datasets (Alpaca-52k and Evol-Instruct-70k). In addition, a lightweight refinement of such long instructions can further improve the abilities of the fine-tuned LLMs, and allows us to obtain the 2nd highest-ranked Llama-2-7B-based model on AlpacaEval 2.0 while training on only 1,000 examples and no ex",
    "link": "https://arxiv.org/abs/2402.04833",
    "context": "Title: Long Is More for Alignment: A Simple but Tough-to-Beat Baseline for Instruction Fine-Tuning\nAbstract: There is a consensus that instruction fine-tuning of LLMs requires high-quality data, but what are they? LIMA (NeurIPS 2023) and AlpaGasus (ICLR 2024) are state-of-the-art methods for selecting such high-quality examples, either via manual curation or using GPT-3.5-Turbo as a quality scorer. We show that the extremely simple baseline of selecting the 1,000 instructions with longest responses from standard datasets can consistently outperform these sophisticated methods according to GPT-4 and PaLM-2 as judges, while remaining competitive on the OpenLLM benchmarks that test factual knowledge. We demonstrate this for several state-of-the-art LLMs (Llama-2-7B, Llama-2-13B, and Mistral-7B) and datasets (Alpaca-52k and Evol-Instruct-70k). In addition, a lightweight refinement of such long instructions can further improve the abilities of the fine-tuned LLMs, and allows us to obtain the 2nd highest-ranked Llama-2-7B-based model on AlpacaEval 2.0 while training on only 1,000 examples and no ex",
    "path": "papers/24/02/2402.04833.json",
    "total_tokens": 1023,
    "translated_title": "长度更长对齐更好：一种简单但难以望其项背的指导微调基准线",
    "translated_abstract": "有共识认为，对于语言模型的指导微调需要高质量的数据，但具体是什么呢？LIMA（NeurIPS 2023）和AlpaGasus（ICLR 2024）是选择这类高质量示例的最先进方法，它们要么通过手动整理要么使用GPT-3.5-Turbo作为质量评分器。我们展示了从标准数据集中选择响应最长的1,000条指示的极简基准线在GPT-4和PaLM-2的评判下始终能够胜过这些复杂方法，同时在测试基于事实知识的OpenLLM基准上保持竞争力。我们在几种最先进的语言模型（Llama-2-7B，Llama-2-13B和Mistral-7B）和数据集（Alpaca-52k和Evol-Instruct-70k）上进行了验证。此外，对这样的长指示进行轻量级改进可以进一步提高微调语言模型的能力，并使我们在只训练了1,000个例子且没有外部数据的情况下，在AlpacaEval 2.0上获得了基于Llama-2-7B的模型的第二高排名。",
    "tldr": "通过选择标准数据集中响应最长的1,000条指示作为基准线，可以在各种语言模型和数据集上实现对齐的高性能，同时对长指示进行轻量级改进进一步提升微调语言模型的能力。",
    "en_tdlr": "Selecting the 1,000 instructions with the longest responses from standard datasets as a baseline consistently outperforms state-of-the-art methods for instruction fine-tuning, and a lightweight refinement of these long instructions further improves the capabilities of fine-tuned language models."
}