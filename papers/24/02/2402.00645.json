{
    "title": "Spectrally Transformed Kernel Regression",
    "abstract": "Unlabeled data is a key component of modern machine learning. In general, the role of unlabeled data is to impose a form of smoothness, usually from the similarity information encoded in a base kernel, such as the $\\epsilon$-neighbor kernel or the adjacency matrix of a graph. This work revisits the classical idea of spectrally transformed kernel regression (STKR), and provides a new class of general and scalable STKR estimators able to leverage unlabeled data. Intuitively, via spectral transformation, STKR exploits the data distribution for which unlabeled data can provide additional information. First, we show that STKR is a principled and general approach, by characterizing a universal type of \"target smoothness\", and proving that any sufficiently smooth function can be learned by STKR. Second, we provide scalable STKR implementations for the inductive setting and a general transformation function, while prior work is mostly limited to the transductive setting. Third, we derive stati",
    "link": "https://arxiv.org/abs/2402.00645",
    "context": "Title: Spectrally Transformed Kernel Regression\nAbstract: Unlabeled data is a key component of modern machine learning. In general, the role of unlabeled data is to impose a form of smoothness, usually from the similarity information encoded in a base kernel, such as the $\\epsilon$-neighbor kernel or the adjacency matrix of a graph. This work revisits the classical idea of spectrally transformed kernel regression (STKR), and provides a new class of general and scalable STKR estimators able to leverage unlabeled data. Intuitively, via spectral transformation, STKR exploits the data distribution for which unlabeled data can provide additional information. First, we show that STKR is a principled and general approach, by characterizing a universal type of \"target smoothness\", and proving that any sufficiently smooth function can be learned by STKR. Second, we provide scalable STKR implementations for the inductive setting and a general transformation function, while prior work is mostly limited to the transductive setting. Third, we derive stati",
    "path": "papers/24/02/2402.00645.json",
    "total_tokens": 856,
    "translated_title": "光谱变换核回归",
    "translated_abstract": "无标签数据是现代机器学习的关键组成部分。一般来说，无标签数据的作用是通过基础核（如ε-邻居核或图的邻接矩阵）中编码的相似性信息来实现一种平滑性形式。本研究重新审视了光谱变换核回归（STKR）的经典思想，并提供了一类新的通用和可扩展的STKR估计器，能够利用无标签数据。通过光谱变换，STKR利用了无标签数据提供的数据分布的信息。首先，我们证明了STKR是一种原则性和通用性的方法，通过表征一种\"目标平滑性\"的通用类型，并证明任何充分平滑的函数都可以通过STKR学习。其次，我们提供了可扩展的STKR实现，适用于感知范式，并提供了一般的变换函数，而先前的工作大部分限于推导范式。第三，我们推导出统计属性...",
    "tldr": "光谱变换核回归是一种能够利用无标签数据的通用和可扩展的方法，具有学习充分平滑函数的能力，并且在感知范式中提供了可扩展的实现。",
    "en_tdlr": "Spectrally transformed kernel regression (STKR) is a general and scalable method that leverages unlabeled data, capable of learning sufficiently smooth functions and providing scalable implementations in the inductive setting."
}