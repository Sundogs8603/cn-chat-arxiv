{
    "title": "Case-Based or Rule-Based: How Do Transformers Do the Math?",
    "abstract": "arXiv:2402.17709v1 Announce Type: new  Abstract: Despite the impressive performance in a variety of complex tasks, modern large language models (LLMs) still have trouble dealing with some math problems that are simple and intuitive for humans, such as addition. While we can easily learn basic rules of addition and apply them to new problems of any length, LLMs struggle to do the same. Instead, they may rely on similar \"cases\" seen in the training corpus for help. We define these two different reasoning mechanisms as \"rule-based reasoning\" and \"case-based reasoning\". Since rule-based reasoning is essential for acquiring the systematic generalization ability, we aim to explore exactly whether transformers use rule-based or case-based reasoning for math problems. Through carefully designed intervention experiments on five math tasks, we confirm that transformers are performing case-based reasoning, no matter whether scratchpad is used, which aligns with the previous observations that tran",
    "link": "https://arxiv.org/abs/2402.17709",
    "context": "Title: Case-Based or Rule-Based: How Do Transformers Do the Math?\nAbstract: arXiv:2402.17709v1 Announce Type: new  Abstract: Despite the impressive performance in a variety of complex tasks, modern large language models (LLMs) still have trouble dealing with some math problems that are simple and intuitive for humans, such as addition. While we can easily learn basic rules of addition and apply them to new problems of any length, LLMs struggle to do the same. Instead, they may rely on similar \"cases\" seen in the training corpus for help. We define these two different reasoning mechanisms as \"rule-based reasoning\" and \"case-based reasoning\". Since rule-based reasoning is essential for acquiring the systematic generalization ability, we aim to explore exactly whether transformers use rule-based or case-based reasoning for math problems. Through carefully designed intervention experiments on five math tasks, we confirm that transformers are performing case-based reasoning, no matter whether scratchpad is used, which aligns with the previous observations that tran",
    "path": "papers/24/02/2402.17709.json",
    "total_tokens": 800,
    "translated_title": "基于案例还是基于规则：变压器如何进行数学计算？",
    "translated_abstract": "尽管现代大型语言模型在各种复杂任务中表现出色，但仍然难以处理一些对人类来说简单且直观的数学问题，例如加法。然而，我们可以轻松学习加法的基本规则，并将其应用于任意长度的新问题，而大型语言模型却难以做到。相反，它们可能依赖于在训练语料库中看到的类似“案例”来获取帮助。我们将这两种不同的推理机制定义为“基于规则的推理”和“基于案例的推理”。由于基于规则的推理对于获得系统化概括能力至关重要，我们旨在探究变压器究竟是使用基于规则还是基于案例的推理来解决数学问题。通过精心设计的五个数学任务的干预实验，我们确认变压器正在执行基于案例的推理，无论是否使用草稿本，这与之前的观察结果一致。",
    "tldr": "transformers在数学问题中采用基于案例的推理而非基于规则的推理。",
    "en_tdlr": "Transformers rely on case-based reasoning rather than rule-based reasoning for math problems."
}