{
    "title": "WanJuan-CC: A Safe and High-Quality Open-sourced English Webtext Dataset",
    "abstract": "arXiv:2402.19282v1 Announce Type: new  Abstract: This paper presents WanJuan-CC, a safe and high-quality open-sourced English webtext dataset derived from Common Crawl data. The study addresses the challenges of constructing large-scale pre-training datasets for language models, which require vast amounts of high-quality data. A comprehensive process was designed to handle Common Crawl data, including extraction, heuristic rule filtering, fuzzy deduplication, content safety filtering, and data quality filtering. From approximately 68 billion original English documents, we obtained 2.22T Tokens of safe data and selected 1.0T Tokens of high-quality data as part of WanJuan-CC. We have open-sourced 300B Tokens from this dataset. The paper also provides statistical information related to data quality, enabling users to select appropriate data according to their needs. To evaluate the quality and utility of the dataset, we trained 1B-parameter and 3B-parameter models using WanJuan-CC and ano",
    "link": "https://arxiv.org/abs/2402.19282",
    "context": "Title: WanJuan-CC: A Safe and High-Quality Open-sourced English Webtext Dataset\nAbstract: arXiv:2402.19282v1 Announce Type: new  Abstract: This paper presents WanJuan-CC, a safe and high-quality open-sourced English webtext dataset derived from Common Crawl data. The study addresses the challenges of constructing large-scale pre-training datasets for language models, which require vast amounts of high-quality data. A comprehensive process was designed to handle Common Crawl data, including extraction, heuristic rule filtering, fuzzy deduplication, content safety filtering, and data quality filtering. From approximately 68 billion original English documents, we obtained 2.22T Tokens of safe data and selected 1.0T Tokens of high-quality data as part of WanJuan-CC. We have open-sourced 300B Tokens from this dataset. The paper also provides statistical information related to data quality, enabling users to select appropriate data according to their needs. To evaluate the quality and utility of the dataset, we trained 1B-parameter and 3B-parameter models using WanJuan-CC and ano",
    "path": "papers/24/02/2402.19282.json",
    "total_tokens": 904,
    "translated_title": "WanJuan-CC：一个安全且高质量的开源英文网络文本数据集",
    "translated_abstract": "本文介绍了 WanJuan-CC，这是一个安全且高质量的开源英文网络文本数据集，来源于Common Crawl数据。研究解决了为语言模型构建大规模预训练数据集所面临的挑战，这需要大量高质量数据。设计了一个全面的流程来处理Common Crawl数据，包括提取、启发式规则过滤、模糊去重、内容安全过滤和数据质量过滤。从大约680亿个原始英文文档中，我们获得了22万亿标记的安全数据，并从中选出了10万亿标记的高质量数据作为WanJuan-CC的一部分。我们已经开源了这个数据集中的3000亿标记。该论文还提供了与数据质量相关的统计信息，使用户可以根据自己的需求选择适当的数据。为评估数据集的质量和实用性，我们使用WanJuan-CC训练了10亿参数和30亿参数的模型。",
    "tldr": "WanJuan-CC是一个安全高质量的开源英文网络文本数据集，通过处理大规模的Common Crawl数据并经过多项筛选和过滤步骤得到，为语言模型的预训练提供了重要资源。",
    "en_tdlr": "WanJuan-CC is a safe and high-quality open-sourced English webtext dataset derived from Common Crawl data, which went through a comprehensive process including extraction, heuristic rule filtering, fuzzy deduplication, content safety filtering, and data quality filtering, providing a significant resource for language model pre-training."
}