{
    "title": "HiGen: Hierarchy-Aware Sequence Generation for Hierarchical Text Classification",
    "abstract": "Hierarchical text classification (HTC) is a complex subtask under multi-label text classification, characterized by a hierarchical label taxonomy and data imbalance. The best-performing models aim to learn a static representation by combining document and hierarchical label information. However, the relevance of document sections can vary based on the hierarchy level, necessitating a dynamic document representation. To address this, we propose HiGen, a text-generation-based framework utilizing language models to encode dynamic text representations. We introduce a level-guided loss function to capture the relationship between text and label name semantics. Our approach incorporates a task-specific pretraining strategy, adapting the language model to in-domain knowledge and significantly enhancing performance for classes with limited examples. Furthermore, we present a new and valuable dataset called ENZYME, designed for HTC, which comprises articles from PubMed with the goal of predicti",
    "link": "https://arxiv.org/abs/2402.01696",
    "context": "Title: HiGen: Hierarchy-Aware Sequence Generation for Hierarchical Text Classification\nAbstract: Hierarchical text classification (HTC) is a complex subtask under multi-label text classification, characterized by a hierarchical label taxonomy and data imbalance. The best-performing models aim to learn a static representation by combining document and hierarchical label information. However, the relevance of document sections can vary based on the hierarchy level, necessitating a dynamic document representation. To address this, we propose HiGen, a text-generation-based framework utilizing language models to encode dynamic text representations. We introduce a level-guided loss function to capture the relationship between text and label name semantics. Our approach incorporates a task-specific pretraining strategy, adapting the language model to in-domain knowledge and significantly enhancing performance for classes with limited examples. Furthermore, we present a new and valuable dataset called ENZYME, designed for HTC, which comprises articles from PubMed with the goal of predicti",
    "path": "papers/24/02/2402.01696.json",
    "total_tokens": 878,
    "translated_title": "HiGen: 层次感知的层级文本分类序列生成",
    "translated_abstract": "层次文本分类（HTC）是多标签文本分类中的一个复杂子任务，其特点是具有层级标签分类法和数据不平衡。最佳性能模型旨在通过结合文档和层级标签信息来学习静态表示。然而，文档各个部分的相关性可能因层级水平的不同而变化，需要动态的文档表示。为了解决这个问题，我们提出了HiGen，一个利用语言模型编码动态文本表示的基于文本生成的框架。我们引入了一种层级引导的损失函数，以捕捉文本和标签名称语义之间的关系。我们的方法采用了一个特定任务的预训练策略，将语言模型调整到领域知识上，并显著提高了对样本有限的类别的性能。此外，我们还提供了一个命名为ENZYME的新颖和有价值的用于HTC的数据集，该数据集由来自PubMed的文章组成，旨在预测...",
    "tldr": "HiGen提出了一个基于文本生成的框架，利用语言模型来编码动态文本表示，在层次文本分类中考虑了文档各个部分的相关性，并引入了一个层级引导的损失函数。此外，还提供了一个新颖的用于HTC的数据集ENZYME。"
}