{
    "title": "Investigating the Impact of Data Contamination of Large Language Models in Text-to-SQL Translation",
    "abstract": "Understanding textual description to generate code seems to be an achieved capability of instruction-following Large Language Models (LLMs) in zero-shot scenario. However, there is a severe possibility that this translation ability may be influenced by having seen target textual descriptions and the related code. This effect is known as Data Contamination.   In this study, we investigate the impact of Data Contamination on the performance of GPT-3.5 in the Text-to-SQL code-generating tasks. Hence, we introduce a novel method to detect Data Contamination in GPTs and examine GPT-3.5's Text-to-SQL performances using the known Spider Dataset and our new unfamiliar dataset Termite. Furthermore, we analyze GPT-3.5's efficacy on databases with modified information via an adversarial table disconnection (ATD) approach, complicating Text-to-SQL tasks by removing structural pieces of information from the database. Our results indicate a significant performance drop in GPT-3.5 on the unfamiliar T",
    "link": "https://arxiv.org/abs/2402.08100",
    "context": "Title: Investigating the Impact of Data Contamination of Large Language Models in Text-to-SQL Translation\nAbstract: Understanding textual description to generate code seems to be an achieved capability of instruction-following Large Language Models (LLMs) in zero-shot scenario. However, there is a severe possibility that this translation ability may be influenced by having seen target textual descriptions and the related code. This effect is known as Data Contamination.   In this study, we investigate the impact of Data Contamination on the performance of GPT-3.5 in the Text-to-SQL code-generating tasks. Hence, we introduce a novel method to detect Data Contamination in GPTs and examine GPT-3.5's Text-to-SQL performances using the known Spider Dataset and our new unfamiliar dataset Termite. Furthermore, we analyze GPT-3.5's efficacy on databases with modified information via an adversarial table disconnection (ATD) approach, complicating Text-to-SQL tasks by removing structural pieces of information from the database. Our results indicate a significant performance drop in GPT-3.5 on the unfamiliar T",
    "path": "papers/24/02/2402.08100.json",
    "total_tokens": 999,
    "translated_title": "研究大型语言模型在文本到SQL翻译中数据污染的影响",
    "translated_abstract": "理解文本描述以生成代码似乎是零-shot场景下指令遵循大型语言模型（LLM）的一项已实现的能力。然而，可能会严重影响这种翻译能力的因素是已经见过目标的文本描述和相关代码。这种影响被称为数据污染。  在本研究中，我们调查了数据污染对GPT-3.5在文本到SQL代码生成任务中性能的影响。因此，我们提出了一种新的方法来检测GPTs中的数据污染，并使用已知的Spider数据集和我们的新的陌生数据集Termite来检查GPT-3.5在文本到SQL任务中的表现。此外，我们通过采用对抗性表断开（ATD）方法分析了GPT-3.5在具有修改信息的数据库上的效果，通过从数据库中删除结构信息来使文本到SQL任务复杂化。我们的研究结果表明，GPT-3.5在陌生的Termite数据集上表现出显著的性能下降。",
    "tldr": "本研究调查了大型语言模型在文本到SQL翻译中数据污染的影响。通过引入一种新的检测方法，研究人员发现GPT-3.5在陌生数据集上的性能显著下降。此外，通过采用对抗性表断开方法，研究人员还分析了GPT-3.5在修改信息的数据库上的效果。",
    "en_tdlr": "This study investigates the impact of data contamination on the performance of large language models in text-to-SQL translation tasks. The researchers introduce a new detection method and find a significant drop in performance of GPT-3.5 on unfamiliar datasets. Additionally, they analyze the efficacy of GPT-3.5 on databases with modified information using an adversarial table disconnection approach."
}