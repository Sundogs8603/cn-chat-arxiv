{
    "title": "Orchid: Flexible and Data-Dependent Convolution for Sequence Modeling",
    "abstract": "arXiv:2402.18508v1 Announce Type: new  Abstract: In the rapidly evolving landscape of deep learning, the quest for models that balance expressivity with computational efficiency has never been more critical. This paper introduces Orchid, a novel architecture that reimagines sequence modeling by incorporating a new data-dependent convolution mechanism. Orchid is designed to address the inherent limitations of traditional attention mechanisms, particularly their quadratic complexity, without compromising the ability to capture long-range dependencies and in-context learning. At the core of Orchid lies the data-dependent convolution layer, which dynamically adjusts its kernel conditioned on input data using a dedicated conditioning neural network. We design two simple conditioning networks that maintain shift equivariance in the adaptive convolution operation. The dynamic nature of data-dependent convolution kernel, coupled with gating operations, grants Orchid high expressivity while mai",
    "link": "https://arxiv.org/abs/2402.18508",
    "context": "Title: Orchid: Flexible and Data-Dependent Convolution for Sequence Modeling\nAbstract: arXiv:2402.18508v1 Announce Type: new  Abstract: In the rapidly evolving landscape of deep learning, the quest for models that balance expressivity with computational efficiency has never been more critical. This paper introduces Orchid, a novel architecture that reimagines sequence modeling by incorporating a new data-dependent convolution mechanism. Orchid is designed to address the inherent limitations of traditional attention mechanisms, particularly their quadratic complexity, without compromising the ability to capture long-range dependencies and in-context learning. At the core of Orchid lies the data-dependent convolution layer, which dynamically adjusts its kernel conditioned on input data using a dedicated conditioning neural network. We design two simple conditioning networks that maintain shift equivariance in the adaptive convolution operation. The dynamic nature of data-dependent convolution kernel, coupled with gating operations, grants Orchid high expressivity while mai",
    "path": "papers/24/02/2402.18508.json",
    "total_tokens": 796,
    "translated_title": "兰花：灵活且数据相关的卷积用于序列建模",
    "translated_abstract": "在深度学习不断发展的格局中，平衡表达能力与计算效率的模型已经变得至关重要。本文介绍了一种名为兰花（Orchid）的新型架构，通过包含一种新的数据相关卷积机制来重新构想序列建模。兰花旨在解决传统注意力机制固有的限制，特别是它们的二次复杂性，同时不影响捕捉远程依赖性和上下文学习的能力。兰花的核心是数据相关卷积层，它利用专门的条件化神经网络根据输入数据动态调整其卷积核。我们设计了两个简单的条件化网络，以在自适应卷积操作中维持平移等变性。数据相关卷积核的动态特性，加上门控操作，赋予了兰花高表达能力，同时维持了计算效率。",
    "tldr": "兰花引入了一种新的数据相关卷积机制，通过动态调整卷积核，实现了高表达能力和计算效率的平衡。",
    "en_tdlr": "Orchid introduces a new data-dependent convolution mechanism, achieving a balance between high expressivity and computational efficiency through dynamically adjusting the convolution kernel."
}