{
    "title": "Explaining Probabilistic Models with Distributional Values",
    "abstract": "arXiv:2402.09947v1 Announce Type: new  Abstract: A large branch of explainable machine learning is grounded in cooperative game theory. However, research indicates that game-theoretic explanations may mislead or be hard to interpret. We argue that often there is a critical mismatch between what one wishes to explain (e.g. the output of a classifier) and what current methods such as SHAP explain (e.g. the scalar probability of a class). This paper addresses such gap for probabilistic models by generalising cooperative games and value operators. We introduce the distributional values, random variables that track changes in the model output (e.g. flipping of the predicted class) and derive their analytic expressions for games with Gaussian, Bernoulli and Categorical payoffs. We further establish several characterising properties, and show that our framework provides fine-grained and insightful explanations with case studies on vision and language models.",
    "link": "https://arxiv.org/abs/2402.09947",
    "context": "Title: Explaining Probabilistic Models with Distributional Values\nAbstract: arXiv:2402.09947v1 Announce Type: new  Abstract: A large branch of explainable machine learning is grounded in cooperative game theory. However, research indicates that game-theoretic explanations may mislead or be hard to interpret. We argue that often there is a critical mismatch between what one wishes to explain (e.g. the output of a classifier) and what current methods such as SHAP explain (e.g. the scalar probability of a class). This paper addresses such gap for probabilistic models by generalising cooperative games and value operators. We introduce the distributional values, random variables that track changes in the model output (e.g. flipping of the predicted class) and derive their analytic expressions for games with Gaussian, Bernoulli and Categorical payoffs. We further establish several characterising properties, and show that our framework provides fine-grained and insightful explanations with case studies on vision and language models.",
    "path": "papers/24/02/2402.09947.json",
    "total_tokens": 857,
    "translated_title": "用分布值解释概率模型",
    "translated_abstract": "一个重要的可解释机器学习分支基于合作博弈理论。然而，研究表明博弈理论解释可能会误导或难以解释。我们认为通常存在着一个重要的不匹配，即人们希望解释的内容（例如分类器的输出）与当前的方法（例如SHAP）所解释的内容（例如类别的概率）之间。本文通过推广合作博弈和价值算子，来解决概率模型的这种差距。我们引入了分布值，这是一种随机变量，用于追踪模型输出的变化（例如预测类别的反转），并推导出了在具有高斯、伯努利和分类支付的博弈中的分布值的解析表达式。我们进一步建立了几个特性，并通过对视觉和语言模型的案例研究展示了我们的框架提供了细粒度和有洞察力的解释。",
    "tldr": "本文介绍了一种用于解释概率模型的方法，通过引入分布值来解决当前方法在解释模型输出时的不匹配问题，并通过案例研究展示了该方法提供的详细和有洞察力的解释。",
    "en_tdlr": "This paper introduces a method for explaining probabilistic models by addressing the mismatch between the desired explanation and current methods, using distributional values to track changes in the model output. Case studies demonstrate the detailed and insightful explanations provided by this approach."
}