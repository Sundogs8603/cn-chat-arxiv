{
    "title": "Green AI: A Preliminary Empirical Study on Energy Consumption in DL Models Across Different Runtime Infrastructures",
    "abstract": "arXiv:2402.13640v1 Announce Type: cross  Abstract: Deep Learning (DL) frameworks such as PyTorch and TensorFlow include runtime infrastructures responsible for executing trained models on target hardware, managing memory, data transfers, and multi-accelerator execution, if applicable. Additionally, it is a common practice to deploy pre-trained models on environments distinct from their native development settings. This led to the introduction of interchange formats such as ONNX, which includes its runtime infrastructure, and ONNX Runtime, which work as standard formats that can be used across diverse DL frameworks and languages. Even though these runtime infrastructures have a great impact on inference performance, no previous paper has investigated their energy efficiency. In this study, we monitor the energy consumption and inference time in the runtime infrastructures of three well-known DL frameworks as well as ONNX, using three various DL models. To have nuance in our investigatio",
    "link": "https://arxiv.org/abs/2402.13640",
    "context": "Title: Green AI: A Preliminary Empirical Study on Energy Consumption in DL Models Across Different Runtime Infrastructures\nAbstract: arXiv:2402.13640v1 Announce Type: cross  Abstract: Deep Learning (DL) frameworks such as PyTorch and TensorFlow include runtime infrastructures responsible for executing trained models on target hardware, managing memory, data transfers, and multi-accelerator execution, if applicable. Additionally, it is a common practice to deploy pre-trained models on environments distinct from their native development settings. This led to the introduction of interchange formats such as ONNX, which includes its runtime infrastructure, and ONNX Runtime, which work as standard formats that can be used across diverse DL frameworks and languages. Even though these runtime infrastructures have a great impact on inference performance, no previous paper has investigated their energy efficiency. In this study, we monitor the energy consumption and inference time in the runtime infrastructures of three well-known DL frameworks as well as ONNX, using three various DL models. To have nuance in our investigatio",
    "path": "papers/24/02/2402.13640.json",
    "total_tokens": 915,
    "translated_title": "绿色人工智能: 跨不同运行时基础设施的深度学习模型能耗初步实证研究",
    "translated_abstract": "arXiv:2402.13640v1 公告类型: 跨学科 摘要: 深度学习（DL）框架如PyTorch和TensorFlow包括运行时基础设施，负责在目标硬件上执行训练好的模型，并管理内存、数据传输以及多加速器执行（如果适用）。此外，将预训练模型部署到与其原生开发环境不同的环境是一种常见做法。这导致引入了诸如ONNX之类的交换格式，其中包括其运行时基础设施，以及ONNX Runtime，可作为可在不同DL框架和语言之间使用的标准格式。尽管这些运行时基础设施对推理性能有很大影响，但以前没有论文调查过它们的能源效率。在这项研究中，我们监测了三种知名DL框架以及ONNX的运行时基础设施中的能耗和推理时间，使用了三种不同的DL模型。为了使我们的调查更加细致",
    "tldr": "本研究通过监测三种知名DL框架以及ONNX的运行时基础设施中的能耗和推理时间，使用三种不同的DL模型，初步探究了它们的能源效率。"
}