{
    "title": "Gaussian Process Neural Additive Models",
    "abstract": "arXiv:2402.12518v1 Announce Type: cross  Abstract: Deep neural networks have revolutionized many fields, but their black-box nature also occasionally prevents their wider adoption in fields such as healthcare and finance, where interpretable and explainable models are required. The recent development of Neural Additive Models (NAMs) is a significant step in the direction of interpretable deep learning for tabular datasets. In this paper, we propose a new subclass of NAMs that use a single-layer neural network construction of the Gaussian process via random Fourier features, which we call Gaussian Process Neural Additive Models (GP-NAM). GP-NAMs have the advantage of a convex objective function and number of trainable parameters that grows linearly with feature dimensionality. It suffers no loss in performance compared to deeper NAM approaches because GPs are well-suited for learning complex non-parametric univariate functions. We demonstrate the performance of GP-NAM on several tabular",
    "link": "https://arxiv.org/abs/2402.12518",
    "context": "Title: Gaussian Process Neural Additive Models\nAbstract: arXiv:2402.12518v1 Announce Type: cross  Abstract: Deep neural networks have revolutionized many fields, but their black-box nature also occasionally prevents their wider adoption in fields such as healthcare and finance, where interpretable and explainable models are required. The recent development of Neural Additive Models (NAMs) is a significant step in the direction of interpretable deep learning for tabular datasets. In this paper, we propose a new subclass of NAMs that use a single-layer neural network construction of the Gaussian process via random Fourier features, which we call Gaussian Process Neural Additive Models (GP-NAM). GP-NAMs have the advantage of a convex objective function and number of trainable parameters that grows linearly with feature dimensionality. It suffers no loss in performance compared to deeper NAM approaches because GPs are well-suited for learning complex non-parametric univariate functions. We demonstrate the performance of GP-NAM on several tabular",
    "path": "papers/24/02/2402.12518.json",
    "total_tokens": 942,
    "translated_title": "高斯过程神经加性模型",
    "translated_abstract": "深度神经网络已经在许多领域引起了革命，但它们的黑盒特性有时也阻碍了它们在医疗保健和金融等领域的广泛应用，这些领域需要可解释和可解释的模型。最近发展出的神经加性模型（NAMs）是在面向表格数据集的可解释深度学习方向上迈出的重要一步。在本文中，我们提出了一种新的NAM子类，它使用通过随机傅里叶特征对高斯过程进行单层神经网络构建，我们称之为高斯过程神经加性模型（GP-NAM）。GP-NAM具有凸目标函数和随特征维度线性增长的可训练参数数量的优势。与更深的NAM方法相比，它在性能上没有损失，因为GPs非常适合学习复杂的非参数单变量函数。我们在多个表格数据集上展示了GP-NAM的性能。",
    "tldr": "本文提出了一种新的高斯过程神经加性模型（GP-NAM），通过随机傅里叶特征对高斯过程进行单层神经网络构建，可以实现具有凸目标函数和可训练参数数量随特征维度线性增长的优势，同时在性能上不亚于更深的NAM方法。",
    "en_tdlr": "This paper introduces a new subclass of Neural Additive Models (NAMs) called Gaussian Process Neural Additive Models (GP-NAM), which constructs Gaussian process via random Fourier features in a single-layer neural network, demonstrating advantages of convex objective function and linearly growing number of trainable parameters with feature dimensionality, while maintaining performance on par with deeper NAM approaches."
}