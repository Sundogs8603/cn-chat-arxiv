{
    "title": "Imagine, Initialize, and Explore: An Effective Exploration Method in Multi-Agent Reinforcement Learning",
    "abstract": "arXiv:2402.17978v1 Announce Type: cross  Abstract: Effective exploration is crucial to discovering optimal strategies for multi-agent reinforcement learning (MARL) in complex coordination tasks. Existing methods mainly utilize intrinsic rewards to enable committed exploration or use role-based learning for decomposing joint action spaces instead of directly conducting a collective search in the entire action-observation space. However, they often face challenges obtaining specific joint action sequences to reach successful states in long-horizon tasks. To address this limitation, we propose Imagine, Initialize, and Explore (IIE), a novel method that offers a promising solution for efficient multi-agent exploration in complex scenarios. IIE employs a transformer model to imagine how the agents reach a critical state that can influence each other's transition functions. Then, we initialize the environment at this state using a simulator before the exploration phase. We formulate the imag",
    "link": "https://arxiv.org/abs/2402.17978",
    "context": "Title: Imagine, Initialize, and Explore: An Effective Exploration Method in Multi-Agent Reinforcement Learning\nAbstract: arXiv:2402.17978v1 Announce Type: cross  Abstract: Effective exploration is crucial to discovering optimal strategies for multi-agent reinforcement learning (MARL) in complex coordination tasks. Existing methods mainly utilize intrinsic rewards to enable committed exploration or use role-based learning for decomposing joint action spaces instead of directly conducting a collective search in the entire action-observation space. However, they often face challenges obtaining specific joint action sequences to reach successful states in long-horizon tasks. To address this limitation, we propose Imagine, Initialize, and Explore (IIE), a novel method that offers a promising solution for efficient multi-agent exploration in complex scenarios. IIE employs a transformer model to imagine how the agents reach a critical state that can influence each other's transition functions. Then, we initialize the environment at this state using a simulator before the exploration phase. We formulate the imag",
    "path": "papers/24/02/2402.17978.json",
    "total_tokens": 837,
    "translated_title": "想象、初始化和探索：多智能体强化学习中的有效探索方法",
    "translated_abstract": "有效的探索对于在复杂协调任务中发现多智能体强化学习（MARL）的最佳策略至关重要。现有方法主要利用内在奖励来实现承诺的探索，或者使用基于角色的学习来分解联合动作空间，而不是直接在整个动作-观察空间中进行集体搜索。然而，在长时间跨度任务中，他们往往面临获取特定联合动作序列以达到成功状态的挑战。为解决这一局限性，我们提出了一种称为Imagine, Initialize, and Explore (IIE)的新方法，为复杂场景中的高效多智能体探索提供了一个有前途的解决方案。IIE利用一个变压器模型来想象智能体如何达到可以影响彼此转移函数的关键状态。然后，在探索阶段之前，我们通过模拟器在这个状态下初始化环境。我们制定了实现这种想象的方法。",
    "tldr": "提出了一种名为Imagine, Initialize, and Explore (IIE)的新方法，利用变压器模型在复杂场景中实现多智能体的有效探索。",
    "en_tdlr": "Introduced a new method called Imagine, Initialize, and Explore (IIE) that utilizes a transformer model for efficient exploration of multiple agents in complex scenarios."
}