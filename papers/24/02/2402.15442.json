{
    "title": "GROS: A General Robust Aggregation Strategy",
    "abstract": "arXiv:2402.15442v1 Announce Type: cross  Abstract: A new, very general, robust procedure for combining estimators in metric spaces is introduced GROS. The method is reminiscent of the well-known median of means, as described in \\cite{devroye2016sub}. Initially, the sample is divided into $K$ groups. Subsequently, an estimator is computed for each group. Finally, these $K$ estimators are combined using a robust procedure. We prove that this estimator is sub-Gaussian and we get its break-down point, in the sense of Donoho. The robust procedure involves a minimization problem on a general metric space, but we show that the same (up to a constant) sub-Gaussianity is obtained if the minimization is taken over the sample, making GROS feasible in practice. The performance of GROS is evaluated through five simulation studies: the first one focuses on classification using $k$-means, the second one on the multi-armed bandit problem, the third one on the regression problem. The fourth one is the ",
    "link": "https://arxiv.org/abs/2402.15442",
    "context": "Title: GROS: A General Robust Aggregation Strategy\nAbstract: arXiv:2402.15442v1 Announce Type: cross  Abstract: A new, very general, robust procedure for combining estimators in metric spaces is introduced GROS. The method is reminiscent of the well-known median of means, as described in \\cite{devroye2016sub}. Initially, the sample is divided into $K$ groups. Subsequently, an estimator is computed for each group. Finally, these $K$ estimators are combined using a robust procedure. We prove that this estimator is sub-Gaussian and we get its break-down point, in the sense of Donoho. The robust procedure involves a minimization problem on a general metric space, but we show that the same (up to a constant) sub-Gaussianity is obtained if the minimization is taken over the sample, making GROS feasible in practice. The performance of GROS is evaluated through five simulation studies: the first one focuses on classification using $k$-means, the second one on the multi-armed bandit problem, the third one on the regression problem. The fourth one is the ",
    "path": "papers/24/02/2402.15442.json",
    "total_tokens": 901,
    "translated_title": "GROS: 一个通用的稳健聚合策略",
    "translated_abstract": "这篇论文引入了一种新的非常通用的稳健程序，用于在度量空间中组合估计量，称为GROS。该方法类似于众所周知的均值中位数方法，在文献\\cite{devroye2016sub}中有描述。首先，样本被分成$K$组。随后，为每个组计算一个估计量。最后，利用稳健程序组合这$K$个估计量。我们证明这个估计量是次高斯的，并得到它的破裂点，即Donoho的意义下。稳健程序涉及一个在一般度量空间上的最小化问题，但我们表明，如果最小化在样本上进行，那么将获得相同（经常数相差）的次高斯性，使得GROS在实践中可行。通过五个模拟研究评估了GROS的性能：第一个研究着重于使用$k$-means进行分类，第二个研究着重于多臂老虎机问题，第三个研究着重于回归问题。第四个是...",
    "tldr": "GROS是一种新的稳健程序，用于在度量空间中组合估计量，具有次高斯特性，通过在样本上进行最小化可在实践中实现。",
    "en_tdlr": "GROS is a new robust procedure for combining estimators in metric spaces, possessing sub-Gaussianity and feasibility in practice by minimizing over the sample."
}