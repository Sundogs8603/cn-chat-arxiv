{
    "title": "Dynamic Explanation Selection Towards Successful User-Decision Support with Explainable AI",
    "abstract": "arXiv:2402.18016v1 Announce Type: cross  Abstract: This paper addresses the problem of how to select explanations for XAI (Explainable AI)-based Intelligent Decision Support Systems (IDSSs). IDSSs have shown promise in improving user decisions through XAI-generated explanations along with AI predictions. As the development of XAI made various explanations available, we believe that IDSSs can be greatly improved if they can strategically select explanations that guide users to better decisions. This paper proposes X-Selector, a method for dynamically selecting explanations. X-Selector aims to guide users to better decisions by predicting the impact of different combinations of explanations on user decisions. We compared X-Selector's performance with two naive strategies (all possible explanations and explanations only for the most likely prediction) and two baselines (no explanation and no AI support). The results suggest the potential of X-Selector to guide users to recommended decisio",
    "link": "https://arxiv.org/abs/2402.18016",
    "context": "Title: Dynamic Explanation Selection Towards Successful User-Decision Support with Explainable AI\nAbstract: arXiv:2402.18016v1 Announce Type: cross  Abstract: This paper addresses the problem of how to select explanations for XAI (Explainable AI)-based Intelligent Decision Support Systems (IDSSs). IDSSs have shown promise in improving user decisions through XAI-generated explanations along with AI predictions. As the development of XAI made various explanations available, we believe that IDSSs can be greatly improved if they can strategically select explanations that guide users to better decisions. This paper proposes X-Selector, a method for dynamically selecting explanations. X-Selector aims to guide users to better decisions by predicting the impact of different combinations of explanations on user decisions. We compared X-Selector's performance with two naive strategies (all possible explanations and explanations only for the most likely prediction) and two baselines (no explanation and no AI support). The results suggest the potential of X-Selector to guide users to recommended decisio",
    "path": "papers/24/02/2402.18016.json",
    "total_tokens": 837,
    "translated_title": "动态解释选择：实现可解释AI的成功用户决策支持",
    "translated_abstract": "本文解决了如何为基于可解释AI的智能决策支持系统(IDSSs)选择解释的问题。IDSSs通过可解释AI生成的解释以及AI预测展示了提高用户决策的潜力。由于可解释AI的发展提供了各种解释，我们认为如果能够有策略地选择指导用户做出更好决策的解释，IDSSs 的性能将得到极大提升。本文提出了X-Selector，一种动态选择解释的方法。X-Selector的目标是通过预测不同解释组合对用户决策的影响，引导用户做出更好的决策。我们将X-Selector的性能与两种朴素策略（所有可能的解释和仅针对最可能预测的解释）、以及两种基线方法（无解释和无AI支持）进行了比较。结果表明X-Selector有潜力引导用户做出推荐的决策。",
    "tldr": "该论文提出了一种名为X-Selector的方法，通过动态选择解释，预测不同解释组合对用户决策的影响，从而引导用户做出更好的决策。",
    "en_tdlr": "This paper introduces a method called X-Selector, which dynamically selects explanations to predict the impact of different combinations of explanations on user decisions, guiding users to make better decisions."
}