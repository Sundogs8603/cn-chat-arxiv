{
    "title": "Tuning In: Analysis of Audio Classifier Performance in Clinical Settings with Limited Data",
    "abstract": "arXiv:2402.10100v1 Announce Type: cross  Abstract: This study assesses deep learning models for audio classification in a clinical setting with the constraint of small datasets reflecting real-world prospective data collection. We analyze CNNs, including DenseNet and ConvNeXt, alongside transformer models like ViT, SWIN, and AST, and compare them against pre-trained audio models such as YAMNet and VGGish. Our method highlights the benefits of pre-training on large datasets before fine-tuning on specific clinical data. We prospectively collected two first-of-their-kind patient audio datasets from stroke patients. We investigated various preprocessing techniques, finding that RGB and grayscale spectrogram transformations affect model performance differently based on the priors they learn from pre-training. Our findings indicate CNNs can match or exceed transformer models in small dataset contexts, with DenseNet-Contrastive and AST models showing notable performance. This study highlights",
    "link": "https://arxiv.org/abs/2402.10100",
    "context": "Title: Tuning In: Analysis of Audio Classifier Performance in Clinical Settings with Limited Data\nAbstract: arXiv:2402.10100v1 Announce Type: cross  Abstract: This study assesses deep learning models for audio classification in a clinical setting with the constraint of small datasets reflecting real-world prospective data collection. We analyze CNNs, including DenseNet and ConvNeXt, alongside transformer models like ViT, SWIN, and AST, and compare them against pre-trained audio models such as YAMNet and VGGish. Our method highlights the benefits of pre-training on large datasets before fine-tuning on specific clinical data. We prospectively collected two first-of-their-kind patient audio datasets from stroke patients. We investigated various preprocessing techniques, finding that RGB and grayscale spectrogram transformations affect model performance differently based on the priors they learn from pre-training. Our findings indicate CNNs can match or exceed transformer models in small dataset contexts, with DenseNet-Contrastive and AST models showing notable performance. This study highlights",
    "path": "papers/24/02/2402.10100.json",
    "total_tokens": 951,
    "translated_title": "调谐：在临床设置中使用有限数据的音频分类器性能分析",
    "translated_abstract": "本研究评估了在临床设置中使用深度学习模型进行音频分类的效果，限制条件是以反映实际世界数据收集的小数据集为基础。我们分析了包括DenseNet和ConvNeXt在内的CNN模型，以及ViT、SWIN和AST等转换模型，并将它们与诸如YAMNet和VGGish的预训练音频模型进行比较。我们的方法强调了在特定临床数据上微调之前，在大数据集上进行预训练的好处。我们从卒中患者中新收集了两个前所未有的患者音频数据集。我们研究了各种预处理技术，发现基于它们从预训练中学习到的先验知识，RGB和灰度谱图转换对模型性能产生了不同的影响。我们的研究结果表明，CNN模型在小数据集环境中可以与转换模型相媲美或超越，其中DenseNet-Contrastive和AST模型表现突出。本研究强调了...",
    "tldr": "本研究评估了在临床设置中使用深度学习模型进行音频分类的效果，并发现在微调之前，预训练模型在大数据集上的性能对临床数据的影响较好。研究结果表明，CNN模型可以在小数据集环境中与转换模型相媲美或超越。",
    "en_tdlr": "This study evaluates the performance of deep learning models for audio classification in clinical settings and finds that pre-training models on large datasets before fine-tuning on clinical data has a positive impact. The results show that CNN models can match or exceed transformer models in small dataset contexts."
}