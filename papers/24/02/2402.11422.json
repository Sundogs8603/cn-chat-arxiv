{
    "title": "Mitigating Catastrophic Forgetting in Multi-domain Chinese Spelling Correction by Multi-stage Knowledge Transfer Framework",
    "abstract": "arXiv:2402.11422v1 Announce Type: new  Abstract: Chinese Spelling Correction (CSC) aims to detect and correct spelling errors in given sentences. Recently, multi-domain CSC has gradually attracted the attention of researchers because it is more practicable. In this paper, we focus on the key flaw of the CSC model when adapting to multi-domain scenarios: the tendency to forget previously acquired knowledge upon learning new domain-specific knowledge (i.e., catastrophic forgetting). To address this, we propose a novel model-agnostic Multi-stage Knowledge Transfer (MKT) framework, which utilizes a continuously evolving teacher model for knowledge transfer in each domain, rather than focusing solely on new domain knowledge. It deserves to be mentioned that we are the first to apply continual learning methods to the multi-domain CSC task. Experiments prove the effectiveness of our proposed method, and further analyses demonstrate the importance of overcoming catastrophic forgetting for impr",
    "link": "https://arxiv.org/abs/2402.11422",
    "context": "Title: Mitigating Catastrophic Forgetting in Multi-domain Chinese Spelling Correction by Multi-stage Knowledge Transfer Framework\nAbstract: arXiv:2402.11422v1 Announce Type: new  Abstract: Chinese Spelling Correction (CSC) aims to detect and correct spelling errors in given sentences. Recently, multi-domain CSC has gradually attracted the attention of researchers because it is more practicable. In this paper, we focus on the key flaw of the CSC model when adapting to multi-domain scenarios: the tendency to forget previously acquired knowledge upon learning new domain-specific knowledge (i.e., catastrophic forgetting). To address this, we propose a novel model-agnostic Multi-stage Knowledge Transfer (MKT) framework, which utilizes a continuously evolving teacher model for knowledge transfer in each domain, rather than focusing solely on new domain knowledge. It deserves to be mentioned that we are the first to apply continual learning methods to the multi-domain CSC task. Experiments prove the effectiveness of our proposed method, and further analyses demonstrate the importance of overcoming catastrophic forgetting for impr",
    "path": "papers/24/02/2402.11422.json",
    "total_tokens": 901,
    "translated_title": "多阶段知识迁移框架在多领域中文拼写校正中的防止灾难性遗忘",
    "translated_abstract": "中国会拼写校正（CSC）旨在检测和纠正给定句子中的拼写错误。最近，多领域CSC逐渐引起研究者的关注，因为它更加实用。本文关注CSC模型在适应多领域场景时存在的关键缺陷：学习新的领域特定知识时容易忘记先前获得的知识（即灾难性遗忘）。为解决这一问题，提出了一种新颖的模型无关的多阶段知识迁移（MKT）框架，该框架在每个领域中利用不断发展的教师模型进行知识迁移，而不仅仅专注于新领域知识。值得一提的是，我们是首次将连续学习方法应用于多领域CSC任务。实验证明了我们提出的方法的有效性，进一步分析展示了克服灾难性遗忘对于提高CSC性能的重要性。",
    "tldr": "提出了一个模型无关的多阶段知识迁移框架，通过不断发展的教师模型在多领域中防止CSC模型忘记先前获得的知识，实验证明了方法的有效性。",
    "en_tdlr": "Introduced a model-agnostic Multi-stage Knowledge Transfer framework that prevents CSC models from forgetting previously acquired knowledge in multi-domains by utilizing continuously evolving teacher models, with experiments demonstrating its effectiveness."
}