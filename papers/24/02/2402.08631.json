{
    "title": "Knowledge Editing on Black-box Large Language Models",
    "abstract": "Knowledge editing (KE) aims to efficiently and precisely modify the behavior of large language models (LLMs) to update specific knowledge without negatively influencing other knowledge. Current research primarily focuses on white-box LLMs editing, overlooking an important scenario: black-box LLMs editing, where LLMs are accessed through interfaces and only textual output is available. To address the limitations of existing evaluations that are not inapplicable to black-box LLM editing and lack comprehensiveness, we propose a multi-perspective evaluation framework, incorporating the assessment of style retention for the first time. To tackle privacy leaks of editing data and style over-editing in current methods, we introduce a novel postEdit framework, resolving privacy concerns through downstream post-processing and maintaining textual style consistency via fine-grained editing to original responses. Experiments and analysis on two benchmarks demonstrate that postEdit outperforms all ",
    "link": "https://arxiv.org/abs/2402.08631",
    "context": "Title: Knowledge Editing on Black-box Large Language Models\nAbstract: Knowledge editing (KE) aims to efficiently and precisely modify the behavior of large language models (LLMs) to update specific knowledge without negatively influencing other knowledge. Current research primarily focuses on white-box LLMs editing, overlooking an important scenario: black-box LLMs editing, where LLMs are accessed through interfaces and only textual output is available. To address the limitations of existing evaluations that are not inapplicable to black-box LLM editing and lack comprehensiveness, we propose a multi-perspective evaluation framework, incorporating the assessment of style retention for the first time. To tackle privacy leaks of editing data and style over-editing in current methods, we introduce a novel postEdit framework, resolving privacy concerns through downstream post-processing and maintaining textual style consistency via fine-grained editing to original responses. Experiments and analysis on two benchmarks demonstrate that postEdit outperforms all ",
    "path": "papers/24/02/2402.08631.json",
    "total_tokens": 847,
    "translated_title": "在黑盒大型语言模型上进行知识编辑",
    "translated_abstract": "知识编辑旨在高效、精确地修改大型语言模型的行为，以更新特定的知识，而不对其他知识产生负面影响。当前的研究主要集中在白盒语言模型编辑上，忽视了一个重要的场景：黑盒语言模型编辑，即通过接口访问语言模型，并仅可用文本输出。为了解决现有评估在黑盒语言模型编辑上不适用且缺乏全面性的局限性，我们提出了一种多角度评估框架，首次将风格保留的评估纳入其中。为了解决当前方法中的编辑数据隐私泄漏和风格过度编辑的问题，我们引入了一种新的postEdit框架，通过下游后处理解决隐私问题，并通过对原始回答进行细粒度编辑来保持文本风格一致性。在两个基准测试上的实验与分析表明，postEdit的性能超过了所有现有方法。",
    "tldr": "这项研究提出了在黑盒大型语言模型上进行知识编辑的方法，并引入了一种多角度评估框架和一种新的postEdit框架，以解决现有方法中的隐私和风格问题。"
}