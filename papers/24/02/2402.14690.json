{
    "title": "UFO: a Unified and Flexible Framework for Evaluating Factuality of Large Language Models",
    "abstract": "arXiv:2402.14690v1 Announce Type: new  Abstract: Large language models (LLMs) may generate text that lacks consistency with human knowledge, leading to factual inaccuracies or \\textit{hallucination}. Existing research for evaluating the factuality of LLMs involves extracting fact claims using an LLM and verifying them against a predefined fact source. However, these evaluation metrics are task-specific, and not scalable, and the substitutability of fact sources in different tasks is under-explored. To address these challenges, we categorize four available fact sources: human-written evidence, reference documents, search engine results, and LLM knowledge, along with five text generation tasks containing six representative datasets. Then, we propose \\texttt{UFO}, an LLM-based unified and flexible evaluation framework to verify facts against plug-and-play fact sources. We implement five evaluation scenarios based on this framework. Experimental results show that for most QA tasks, human-w",
    "link": "https://arxiv.org/abs/2402.14690",
    "context": "Title: UFO: a Unified and Flexible Framework for Evaluating Factuality of Large Language Models\nAbstract: arXiv:2402.14690v1 Announce Type: new  Abstract: Large language models (LLMs) may generate text that lacks consistency with human knowledge, leading to factual inaccuracies or \\textit{hallucination}. Existing research for evaluating the factuality of LLMs involves extracting fact claims using an LLM and verifying them against a predefined fact source. However, these evaluation metrics are task-specific, and not scalable, and the substitutability of fact sources in different tasks is under-explored. To address these challenges, we categorize four available fact sources: human-written evidence, reference documents, search engine results, and LLM knowledge, along with five text generation tasks containing six representative datasets. Then, we propose \\texttt{UFO}, an LLM-based unified and flexible evaluation framework to verify facts against plug-and-play fact sources. We implement five evaluation scenarios based on this framework. Experimental results show that for most QA tasks, human-w",
    "path": "papers/24/02/2402.14690.json",
    "total_tokens": 839,
    "translated_title": "UFO：评估大型语言模型事实性的统一灵活框架",
    "translated_abstract": "大型语言模型（LLMs）可能生成与人类知识不一致的文本，导致事实不准确或“幻觉”。现有研究评估LLMs的事实性涉及使用LLM提取事实主张，并将其与预定义的事实来源进行验证。然而，这些评估指标是任务特定的，并且不具有可扩展性，不同任务中事实来源的可替代性尚未得到充分探讨。为解决这些挑战，我们将四种可用事实来源进行分类：人类编写的证据、参考文献、搜索引擎结果和LLM知识，以及包含六个典型数据集的五个文本生成任务。然后，我们提出了\\texttt{UFO}，一种基于LLM的统一灵活评估框架，用于根据即插即用的事实来源验证事实。我们基于该框架实施了五个评估场景。实验证明，在大多数问答任务中，人类",
    "tldr": "提出了一种基于大型语言模型的统一灵活评估框架UFO，用于验证事实并支持即插即用的事实来源。",
    "en_tdlr": "Introduced a unified and flexible evaluation framework UFO based on large language models for fact verification against plug-and-play fact sources."
}