{
    "title": "Advancing Location-Invariant and Device-Agnostic Motion Activity Recognition on Wearable Devices",
    "abstract": "Wearable sensors have permeated into people's lives, ushering impactful applications in interactive systems and activity recognition. However, practitioners face significant obstacles when dealing with sensing heterogeneities, requiring custom models for different platforms. In this paper, we conduct a comprehensive evaluation of the generalizability of motion models across sensor locations. Our analysis highlights this challenge and identifies key on-body locations for building location-invariant models that can be integrated on any device. For this, we introduce the largest multi-location activity dataset (N=50, 200 cumulative hours), which we make publicly available. We also present deployable on-device motion models reaching 91.41% frame-level F1-score from a single model irrespective of sensor placements. Lastly, we investigate cross-location data synthesis, aiming to alleviate the laborious data collection tasks by synthesizing data in one location given data from another. These ",
    "link": "https://arxiv.org/abs/2402.03714",
    "context": "Title: Advancing Location-Invariant and Device-Agnostic Motion Activity Recognition on Wearable Devices\nAbstract: Wearable sensors have permeated into people's lives, ushering impactful applications in interactive systems and activity recognition. However, practitioners face significant obstacles when dealing with sensing heterogeneities, requiring custom models for different platforms. In this paper, we conduct a comprehensive evaluation of the generalizability of motion models across sensor locations. Our analysis highlights this challenge and identifies key on-body locations for building location-invariant models that can be integrated on any device. For this, we introduce the largest multi-location activity dataset (N=50, 200 cumulative hours), which we make publicly available. We also present deployable on-device motion models reaching 91.41% frame-level F1-score from a single model irrespective of sensor placements. Lastly, we investigate cross-location data synthesis, aiming to alleviate the laborious data collection tasks by synthesizing data in one location given data from another. These ",
    "path": "papers/24/02/2402.03714.json",
    "total_tokens": 900,
    "translated_title": "在可穿戴设备上推进位置无关和设备无关的动作活动识别",
    "translated_abstract": "可穿戴传感器已经渗透到人们的生活中，在交互系统和活动识别方面产生了重大影响。然而，从业者在处理感知异构性时面临着重大障碍，需要为不同的平台定制模型。在本文中，我们对跨传感器位置的动作模型的通用性进行了全面评估。我们的分析突显了这个挑战，并确定了用于构建位置无关模型的关键身体部位，这些模型可以集成到任何设备上。为此，我们引入了最大的多位置活动数据集（N=50，累计200小时），并将其公开。我们还提出了在设备上部署的动作模型，单个模型的帧级别F1得分达到91.41％，无论传感器放置如何。最后，我们研究了跨位置数据合成，旨在通过在一个位置合成另一个位置的数据，从而减轻繁琐的数据收集任务。",
    "tldr": "本文通过对跨传感器位置的动作模型的通用性进行全面评估，确定了用于构建位置无关模型的关键身体部位，并提出了在设备上部署的动作模型，单个模型的帧级别F1得分达到91.41％，无论传感器放置如何。"
}