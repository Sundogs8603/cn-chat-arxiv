{
    "title": "How do Large Language Models Learn In-Context? Query and Key Matrices of In-Context Heads are Two Towers for Metric Learning",
    "abstract": "We explore the mechanism of in-context learning and propose a hypothesis using locate-and-project method. In shallow layers, the features of demonstrations are merged into their corresponding labels, and the features of the input text are aggregated into the last token. In deep layers, in-context heads make great contributions. In each in-context head, the value-output matrix extracts the labels' features. Query and key matrices compute the attention weights between the input text and each demonstration. The larger the attention weight is, the more label information is transferred into the last token for predicting the next word. Query and key matrices can be regarded as two towers for learning the similarity metric between the input text and each demonstration. Based on this hypothesis, we explain why imbalanced labels and demonstration order affect predictions. We conduct experiments on GPT2 large, Llama 7B, 13B and 30B. The results can support our analysis. Overall, our study provid",
    "link": "https://arxiv.org/abs/2402.02872",
    "context": "Title: How do Large Language Models Learn In-Context? Query and Key Matrices of In-Context Heads are Two Towers for Metric Learning\nAbstract: We explore the mechanism of in-context learning and propose a hypothesis using locate-and-project method. In shallow layers, the features of demonstrations are merged into their corresponding labels, and the features of the input text are aggregated into the last token. In deep layers, in-context heads make great contributions. In each in-context head, the value-output matrix extracts the labels' features. Query and key matrices compute the attention weights between the input text and each demonstration. The larger the attention weight is, the more label information is transferred into the last token for predicting the next word. Query and key matrices can be regarded as two towers for learning the similarity metric between the input text and each demonstration. Based on this hypothesis, we explain why imbalanced labels and demonstration order affect predictions. We conduct experiments on GPT2 large, Llama 7B, 13B and 30B. The results can support our analysis. Overall, our study provid",
    "path": "papers/24/02/2402.02872.json",
    "total_tokens": 934,
    "translated_title": "大型语言模型如何进行上下文学习？查询和键矩阵是上下文头部进行度量学习的两个关键组成部分",
    "translated_abstract": "我们探索了上下文学习的机制，并提出了使用定位和投影方法的假设。在浅层中，演示的特征被合并到相应的标签中，输入文本的特征被聚合到最后一个标记中。在深层中，上下文头部发挥了重要作用。在每个上下文头部中，值-输出矩阵提取了标签的特征。查询和键矩阵计算了输入文本与每个演示之间的注意力权重。注意力权重越大，越多的标签信息被传输到最后一个标记中，用于预测下一个单词。查询和键矩阵可以被视为学习输入文本与每个演示之间相似度度量的两个关键组成部分。基于这个假设，我们解释了为什么不平衡的标签和演示顺序会影响预测。我们在GPT2大型、Llama 7B、13B和30B上进行了实验。结果支持我们的分析。总体而言，我们的研究提供了一个关于大型语言模型如何进行上下文学习的理论解释和验证。",
    "tldr": "本论文探索了大型语言模型如何进行上下文学习的机制，提出了一个使用定位和投影方法的假设。通过查询和键矩阵来计算输入文本与每个演示之间的注意力权重，以学习它们之间的相似度度量。实验证明了我们的分析。"
}