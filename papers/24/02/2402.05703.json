{
    "title": "Offline Risk-sensitive RL with Partial Observability to Enhance Performance in Human-Robot Teaming",
    "abstract": "The integration of physiological computing into mixed-initiative human-robot interaction systems offers valuable advantages in autonomous task allocation by incorporating real-time features as human state observations into the decision-making system. This approach may alleviate the cognitive load on human operators by intelligently allocating mission tasks between agents. Nevertheless, accommodating a diverse pool of human participants with varying physiological and behavioral measurements presents a substantial challenge. To address this, resorting to a probabilistic framework becomes necessary, given the inherent uncertainty and partial observability on the human's state. Recent research suggests to learn a Partially Observable Markov Decision Process (POMDP) model from a data set of previously collected experiences that can be solved using Offline Reinforcement Learning (ORL) methods. In the present work, we not only highlight the potential of partially observable representations an",
    "link": "https://arxiv.org/abs/2402.05703",
    "context": "Title: Offline Risk-sensitive RL with Partial Observability to Enhance Performance in Human-Robot Teaming\nAbstract: The integration of physiological computing into mixed-initiative human-robot interaction systems offers valuable advantages in autonomous task allocation by incorporating real-time features as human state observations into the decision-making system. This approach may alleviate the cognitive load on human operators by intelligently allocating mission tasks between agents. Nevertheless, accommodating a diverse pool of human participants with varying physiological and behavioral measurements presents a substantial challenge. To address this, resorting to a probabilistic framework becomes necessary, given the inherent uncertainty and partial observability on the human's state. Recent research suggests to learn a Partially Observable Markov Decision Process (POMDP) model from a data set of previously collected experiences that can be solved using Offline Reinforcement Learning (ORL) methods. In the present work, we not only highlight the potential of partially observable representations an",
    "path": "papers/24/02/2402.05703.json",
    "total_tokens": 837,
    "translated_title": "离线风险敏感强化学习结合部分可观察性，以提高人-机组合的表现",
    "translated_abstract": "将生理计算整合到混合倡议的人机交互系统中，通过将实时特征作为人类状态观测融入决策系统，可以在自主任务分配中提供有价值的优势。这种方法可以通过智能地分配任务来减轻人类操作员的认知负荷。然而，适应具有不同生理和行为测量结果的多样化人类参与者构成了一个重大挑战。为了解决这个问题，必须利用概率框架，考虑到人类状态的固有不确定性和部分可观察性。最近的研究建议使用离线强化学习（ORL）方法从先前收集的经验数据集中学习一个部分可观测马尔可夫决策过程（POMDP）模型。在本研究中，我们不仅强调部分可观察性表示的潜力，",
    "tldr": "本研究针对人-机组合中的性能提出了离线风险敏感强化学习算法，通过部分可观察性的建模，解决了多样化人类参与者的挑战。",
    "en_tdlr": "This study proposes an offline risk-sensitive reinforcement learning algorithm to enhance performance in human-robot teaming, addressing the challenge of accommodating diverse human participants through modeling partial observability."
}