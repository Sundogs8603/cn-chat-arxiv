{
    "title": "Verifiable Boosted Tree Ensembles",
    "abstract": "arXiv:2402.14988v1 Announce Type: new  Abstract: Verifiable learning advocates for training machine learning models amenable to efficient security verification. Prior research demonstrated that specific classes of decision tree ensembles -- called large-spread ensembles -- allow for robustness verification in polynomial time against any norm-based attacker. This study expands prior work on verifiable learning from basic ensemble methods (i.e., hard majority voting) to advanced boosted tree ensembles, such as those trained using XGBoost or LightGBM. Our formal results indicate that robustness verification is achievable in polynomial time when considering attackers based on the $L_\\infty$-norm, but remains NP-hard for other norm-based attackers. Nevertheless, we present a pseudo-polynomial time algorithm to verify robustness against attackers based on the $L_p$-norm for any $p \\in \\mathbb{N} \\cup \\{0\\}$, which in practice grants excellent performance. Our experimental evaluation shows th",
    "link": "https://arxiv.org/abs/2402.14988",
    "context": "Title: Verifiable Boosted Tree Ensembles\nAbstract: arXiv:2402.14988v1 Announce Type: new  Abstract: Verifiable learning advocates for training machine learning models amenable to efficient security verification. Prior research demonstrated that specific classes of decision tree ensembles -- called large-spread ensembles -- allow for robustness verification in polynomial time against any norm-based attacker. This study expands prior work on verifiable learning from basic ensemble methods (i.e., hard majority voting) to advanced boosted tree ensembles, such as those trained using XGBoost or LightGBM. Our formal results indicate that robustness verification is achievable in polynomial time when considering attackers based on the $L_\\infty$-norm, but remains NP-hard for other norm-based attackers. Nevertheless, we present a pseudo-polynomial time algorithm to verify robustness against attackers based on the $L_p$-norm for any $p \\in \\mathbb{N} \\cup \\{0\\}$, which in practice grants excellent performance. Our experimental evaluation shows th",
    "path": "papers/24/02/2402.14988.json",
    "total_tokens": 890,
    "translated_title": "可验证的提升树集成",
    "translated_abstract": "可验证学习倡导训练易于进行高效安全验证的机器学习模型。先前的研究表明，特定类的决策树集成，即称为大广泛集成，可以在多项式时间内针对任何基于范数的攻击者进行鲁棒性验证。本研究将可验证学习从基本集成方法（即硬多数投票）扩展到高级提升树集成，比如那些使用XGBoost或LightGBM训练的集成。我们的正式结果表明，在考虑基于$L_\\infty$-范数的攻击者时，鲁棒性验证可以在多项式时间内实现，但对于其他基于范数的攻击者来说仍然是NP难的。尽管如此，我们提出了一个伪多项式时间算法来验证针对基于$L_p$-范数的攻击者的鲁棒性，其中$p \\in \\mathbb{N} \\cup \\{0\\}$，在实践中具有出色的性能。我们的实验评估表明",
    "tldr": "本研究将可验证学习从基本集成方法扩展到高级提升树集成，提出了一个伪多项式时间算法来验证鲁棒性，对基于$L_p$-范数的攻击者具有出色的性能。",
    "en_tdlr": "This study expands verifiable learning from basic ensemble methods to advanced boosted tree ensembles and presents a pseudo-polynomial time algorithm to verify robustness against attackers based on the $L_p$-norm with excellent performance."
}