{
    "title": "Open-Vocabulary Segmentation with Unpaired Mask-Text Supervision",
    "abstract": "arXiv:2402.08960v1 Announce Type: cross Abstract: Contemporary cutting-edge open-vocabulary segmentation approaches commonly rely on image-mask-text triplets, yet this restricted annotation is labour-intensive and encounters scalability hurdles in complex real-world scenarios. Although some methods are proposed to reduce the annotation cost with only text supervision, the incompleteness of supervision severely limits the versatility and performance. In this paper, we liberate the strict correspondence between masks and texts by using independent image-mask and image-text pairs, which can be easily collected respectively. With this unpaired mask-text supervision, we propose a new weakly-supervised open-vocabulary segmentation framework (Uni-OVSeg) that leverages confident pairs of mask predictions and entities in text descriptions. Using the independent image-mask and image-text pairs, we predict a set of binary masks and associate them with entities by resorting to the CLIP embedding s",
    "link": "https://arxiv.org/abs/2402.08960",
    "context": "Title: Open-Vocabulary Segmentation with Unpaired Mask-Text Supervision\nAbstract: arXiv:2402.08960v1 Announce Type: cross Abstract: Contemporary cutting-edge open-vocabulary segmentation approaches commonly rely on image-mask-text triplets, yet this restricted annotation is labour-intensive and encounters scalability hurdles in complex real-world scenarios. Although some methods are proposed to reduce the annotation cost with only text supervision, the incompleteness of supervision severely limits the versatility and performance. In this paper, we liberate the strict correspondence between masks and texts by using independent image-mask and image-text pairs, which can be easily collected respectively. With this unpaired mask-text supervision, we propose a new weakly-supervised open-vocabulary segmentation framework (Uni-OVSeg) that leverages confident pairs of mask predictions and entities in text descriptions. Using the independent image-mask and image-text pairs, we predict a set of binary masks and associate them with entities by resorting to the CLIP embedding s",
    "path": "papers/24/02/2402.08960.json",
    "total_tokens": 898,
    "translated_title": "使用无配对的掩码-文本监督进行开放词汇分割",
    "translated_abstract": "当代尖端的开放词汇分割方法通常依赖于图像-掩码-文本三元组，然而这种受限的注释在复杂的现实场景中需要大量的人力，并且遇到了可扩展性的障碍。虽然已经提出了一些方法通过仅使用文本监督来减少注释的成本，但监督的不完整性严重限制了多样性和性能。在本文中，我们通过使用独立的图像-掩码和图像-文本对解放了掩码和文本之间的严格对应关系，这些对可以分别轻松收集。借助这种无配对的掩码-文本监督，我们提出了一种新的弱监督开放词汇分割框架(Uni-OVSeg)，它利用自信的掩码预测和文本描述中的实体。利用独立的图像-掩码和图像-文本对，我们预测了一组二进制掩码，并通过使用CLIP嵌入将它们与实体关联起来。",
    "tldr": "本文提出了一种通过使用无配对的掩码-文本监督方法来进行开放词汇分割的框架(Uni-OVSeg)，该方法通过独立的图像-掩码和图像-文本对提取二进制掩码并与实体关联。",
    "en_tdlr": "This paper proposes a framework (Uni-OVSeg) for open-vocabulary segmentation using unpaired mask-text supervision. The framework extracts binary masks and associates them with entities by utilizing independent image-mask and image-text pairs."
}