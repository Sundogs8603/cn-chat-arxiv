{
    "title": "Privacy-Preserving Low-Rank Adaptation for Latent Diffusion Models",
    "abstract": "arXiv:2402.11989v1 Announce Type: new  Abstract: Low-rank adaptation (LoRA) is an efficient strategy for adapting latent diffusion models (LDMs) on a training dataset to generate specific objects by minimizing the adaptation loss. However, adapted LDMs via LoRA are vulnerable to membership inference (MI) attacks that can judge whether a particular data point belongs to private training datasets, thus facing severe risks of privacy leakage. To defend against MI attacks, we make the first effort to propose a straightforward solution: privacy-preserving LoRA (PrivateLoRA). PrivateLoRA is formulated as a min-max optimization problem where a proxy attack model is trained by maximizing its MI gain while the LDM is adapted by minimizing the sum of the adaptation loss and the proxy attack model's MI gain. However, we empirically disclose that PrivateLoRA has the issue of unstable optimization due to the large fluctuation of the gradient scale which impedes adaptation. To mitigate this issue, w",
    "link": "https://arxiv.org/abs/2402.11989",
    "context": "Title: Privacy-Preserving Low-Rank Adaptation for Latent Diffusion Models\nAbstract: arXiv:2402.11989v1 Announce Type: new  Abstract: Low-rank adaptation (LoRA) is an efficient strategy for adapting latent diffusion models (LDMs) on a training dataset to generate specific objects by minimizing the adaptation loss. However, adapted LDMs via LoRA are vulnerable to membership inference (MI) attacks that can judge whether a particular data point belongs to private training datasets, thus facing severe risks of privacy leakage. To defend against MI attacks, we make the first effort to propose a straightforward solution: privacy-preserving LoRA (PrivateLoRA). PrivateLoRA is formulated as a min-max optimization problem where a proxy attack model is trained by maximizing its MI gain while the LDM is adapted by minimizing the sum of the adaptation loss and the proxy attack model's MI gain. However, we empirically disclose that PrivateLoRA has the issue of unstable optimization due to the large fluctuation of the gradient scale which impedes adaptation. To mitigate this issue, w",
    "path": "papers/24/02/2402.11989.json",
    "total_tokens": 877,
    "translated_title": "隐私保护的低秩适应Latent扩散模型",
    "translated_abstract": "低秩适应（LoRA）是一种有效的策略，用于通过最小化适应损失，自训练数据集中适应Latent扩散模型（LDM）以生成特定对象。然而，通过LoRA适应的LDM容易受到成员推断（MI）攻击的影响，这种攻击可以判断特定数据点是否属于私人训练数据集，因此面临严重的隐私泄露风险。为了抵御MI攻击，我们首次提出了一个直接的解决方案：隐私保护的LoRA（PrivateLoRA）。PrivateLoRA被构建为一个最小最大优化问题，其中通过最大化MI增益来训练代理攻击模型，而LDM则通过最小化适应损失和代理攻击模型的MI增益之和来进行调整。然而，我们在实践中发现PrivateLoRA存在稳定性优化问题，即由于梯度规模的大幅波动而妨碍适应。",
    "tldr": "提出了隐私保护的低秩适应解决方案PrivateLoRA，通过最小化适应损失和代理攻击模型的MI增益来抵御成员推断攻击。",
    "en_tdlr": "Proposed a privacy-preserving low-rank adaptation solution called PrivateLoRA, defending against membership inference attacks by minimizing the adaptation loss and the proxy attack model's MI gain."
}