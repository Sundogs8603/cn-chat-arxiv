{
    "title": "Addressing Order Sensitivity of In-Context Demonstration Examples in Causal Language Models",
    "abstract": "arXiv:2402.15637v1 Announce Type: new  Abstract: In-context learning has become a popular paradigm in natural language processing. However, its performance can be significantly influenced by the order of in-context demonstration examples. In this paper, we found that causal language models (CausalLMs) are more sensitive to this order compared to prefix language models (PrefixLMs). We attribute this phenomenon to the auto-regressive attention masks within CausalLMs, which restrict each token from accessing information from subsequent tokens. This results in different receptive fields for samples at different positions, thereby leading to representation disparities across positions. To tackle this challenge, we introduce an unsupervised fine-tuning method, termed the Information-Augmented and Consistency-Enhanced approach. This approach utilizes contrastive learning to align representations of in-context examples across different positions and introduces a consistency loss to ensure simi",
    "link": "https://arxiv.org/abs/2402.15637",
    "context": "Title: Addressing Order Sensitivity of In-Context Demonstration Examples in Causal Language Models\nAbstract: arXiv:2402.15637v1 Announce Type: new  Abstract: In-context learning has become a popular paradigm in natural language processing. However, its performance can be significantly influenced by the order of in-context demonstration examples. In this paper, we found that causal language models (CausalLMs) are more sensitive to this order compared to prefix language models (PrefixLMs). We attribute this phenomenon to the auto-regressive attention masks within CausalLMs, which restrict each token from accessing information from subsequent tokens. This results in different receptive fields for samples at different positions, thereby leading to representation disparities across positions. To tackle this challenge, we introduce an unsupervised fine-tuning method, termed the Information-Augmented and Consistency-Enhanced approach. This approach utilizes contrastive learning to align representations of in-context examples across different positions and introduces a consistency loss to ensure simi",
    "path": "papers/24/02/2402.15637.json",
    "total_tokens": 822,
    "translated_title": "处理因果语言模型中上下文示例对顺序敏感性的问题",
    "translated_abstract": "在自然语言处理中，上下文学习已经成为一种流行的范式。然而，其性能可能会受到上下文示例顺序的显著影响。在本文中，我们发现因果语言模型（CausalLMs）对此顺序比前缀语言模型（PrefixLMs）更敏感。我们将这一现象归因于CausalLMs中的自回归注意力掩模，这些掩模限制每个标记不能访问随后的标记的信息。这导致不同位置的样本具有不同的感受野，从而导致不同位置的表征差异。为了应对这一挑战，我们引入了一种无监督微调方法，称为信息增强和一致性增强方法。该方法利用对比学习来对齐不同位置上下文示例的表征，并引入一致性损失以确保相似性。",
    "tldr": "因果语言模型更容易受到上下文示例顺序的影响，为了解决这一挑战，提出了一种信息增强和一致性增强方法。",
    "en_tdlr": "Causal language models are more sensitive to the order of in-context demonstration examples, and to tackle this challenge, an Information-Augmented and Consistency-Enhanced approach is introduced."
}