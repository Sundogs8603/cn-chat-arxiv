{
    "title": "Cutting Off the Head Ends the Conflict: A Mechanism for Interpreting and Mitigating Knowledge Conflicts in Language Models",
    "abstract": "arXiv:2402.18154v1 Announce Type: cross  Abstract: Recently, retrieval augmentation and tool augmentation have demonstrated a remarkable capability to expand the internal memory boundaries of language models (LMs) by providing external context. However, internal memory and external context inevitably clash, leading to knowledge conflicts within LMs. In this paper, we aim to interpret the mechanism of knowledge conflicts through the lens of information flow, and then mitigate conflicts by precise interventions at the pivotal point. We find there are some attention heads with opposite effects in the later layers, where memory heads can recall knowledge from internal memory, and context heads can retrieve knowledge from external context. Moreover, we reveal that the pivotal point at which knowledge conflicts emerge in LMs is the integration of inconsistent information flows by memory heads and context heads. Inspired by the insights, we propose a novel method called Pruning Head via PatH ",
    "link": "https://arxiv.org/abs/2402.18154",
    "context": "Title: Cutting Off the Head Ends the Conflict: A Mechanism for Interpreting and Mitigating Knowledge Conflicts in Language Models\nAbstract: arXiv:2402.18154v1 Announce Type: cross  Abstract: Recently, retrieval augmentation and tool augmentation have demonstrated a remarkable capability to expand the internal memory boundaries of language models (LMs) by providing external context. However, internal memory and external context inevitably clash, leading to knowledge conflicts within LMs. In this paper, we aim to interpret the mechanism of knowledge conflicts through the lens of information flow, and then mitigate conflicts by precise interventions at the pivotal point. We find there are some attention heads with opposite effects in the later layers, where memory heads can recall knowledge from internal memory, and context heads can retrieve knowledge from external context. Moreover, we reveal that the pivotal point at which knowledge conflicts emerge in LMs is the integration of inconsistent information flows by memory heads and context heads. Inspired by the insights, we propose a novel method called Pruning Head via PatH ",
    "path": "papers/24/02/2402.18154.json",
    "total_tokens": 839,
    "translated_title": "切断头部终结冲突：解释和缓解语言模型中的知识冲突的机制",
    "translated_abstract": "最近，检索增强和工具增强展示了通过提供外部上下文来扩展语言模型（LMs）的内部记忆边界的显著能力。然而，内部记忆和外部上下文不可避免地发生冲突，导致LMs内部出现知识冲突。本文旨在通过信息流的视角解释知识冲突的机制，然后通过在关键点进行精确干预来缓解冲突。我们发现在后续层中有一些具有相反效果的注意力头，其中内存头可以从内部记忆中召回知识，而上下文头可以从外部上下文中检索知识。此外，我们揭示了LMs中知识冲突发生的关键点是内存头和上下文头整合不一致信息流的地方。受到这些见解的启发，我们提出了一种名为Pruning Head via PatH的新方法。",
    "tldr": "通过信息流的视角解释并干预语言模型中的知识冲突，提出了一种名为Pruning Head via PatH的方法来缓解冲突"
}