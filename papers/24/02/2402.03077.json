{
    "title": "Markov Persuasion Processes: Learning to Persuade from Scratch",
    "abstract": "In Bayesian persuasion, an informed sender strategically discloses information to a receiver so as to persuade them to undertake desirable actions. Recently, a growing attention has been devoted to settings in which sender and receivers interact sequentially. Recently, Markov persuasion processes (MPPs) have been introduced to capture sequential scenarios where a sender faces a stream of myopic receivers in a Markovian environment. The MPPs studied so far in the literature suffer from issues that prevent them from being fully operational in practice, e.g., they assume that the sender knows receivers' rewards. We fix such issues by addressing MPPs where the sender has no knowledge about the environment. We design a learning algorithm for the sender, working with partial feedback. We prove that its regret with respect to an optimal information-disclosure policy grows sublinearly in the number of episodes, as it is the case for the loss in persuasiveness cumulated while learning. Moreover",
    "link": "https://arxiv.org/abs/2402.03077",
    "context": "Title: Markov Persuasion Processes: Learning to Persuade from Scratch\nAbstract: In Bayesian persuasion, an informed sender strategically discloses information to a receiver so as to persuade them to undertake desirable actions. Recently, a growing attention has been devoted to settings in which sender and receivers interact sequentially. Recently, Markov persuasion processes (MPPs) have been introduced to capture sequential scenarios where a sender faces a stream of myopic receivers in a Markovian environment. The MPPs studied so far in the literature suffer from issues that prevent them from being fully operational in practice, e.g., they assume that the sender knows receivers' rewards. We fix such issues by addressing MPPs where the sender has no knowledge about the environment. We design a learning algorithm for the sender, working with partial feedback. We prove that its regret with respect to an optimal information-disclosure policy grows sublinearly in the number of episodes, as it is the case for the loss in persuasiveness cumulated while learning. Moreover",
    "path": "papers/24/02/2402.03077.json",
    "total_tokens": 997,
    "translated_title": "马尔可夫说服过程：从零开始学会说服",
    "translated_abstract": "在贝叶斯说服中，一个消息灵通的发送者可以策略性地向接收者透露信息，以说服他们采取期望的行动。最近，越来越多的关注点集中在发送者和接收者顺序交互的情境中。最近，引入了马尔可夫说服过程（MPPs）来捕捉在马尔可夫环境中，发送者面对一系列短视接收者的顺序情景。迄今为止，在文献中研究的MPPs存在一些问题，这些问题阻碍了它们在实践中的充分运作，例如，它们假设发送者知道接收者的奖励。我们通过处理发送者对环境没有任何了解的MPPs，解决了这些问题。我们设计了一个学习算法，用于发送者的部分反馈。我们证明了它的悔恨与最佳信息披露策略之间的差异以次线性增长，就像学习过程中累计的说服力损失一样。",
    "tldr": "这篇论文提出了马尔可夫说服过程模型，用于捕捉发送者和接收者顺序交互的情景。论文解决了现有模型中的问题，提供了针对发送者没有环境知识的解决方案。通过设计学习算法，证明了算法的性能。这个方法的总结要点是提出了马尔可夫说服过程模型，并提出了针对没有环境知识的发送者的学习算法。",
    "en_tdlr": "This paper introduces the Markov persuasion processes model to capture sequential interactions between a sender and receivers. It addresses the issues in existing models and provides a solution for senders with no knowledge about the environment. By designing a learning algorithm, the paper proves the algorithm's performance. The key takeaway is the proposed Markov persuasion processes model and the learning algorithm for senders with no environment knowledge."
}