{
    "title": "Topological Neural Networks: Mitigating the Bottlenecks of Graph Neural Networks via Higher-Order Interactions",
    "abstract": "The irreducible complexity of natural phenomena has led Graph Neural Networks to be employed as a standard model to perform representation learning tasks on graph-structured data. While their capacity to capture local and global patterns is remarkable, the implications associated with long-range and higher-order dependencies pose considerable challenges to such models. This work starts with a theoretical framework to reveal the impact of network's width, depth, and graph topology on the over-squashing phenomena in message-passing neural networks. Then, the work drifts towards, higher-order interactions and multi-relational inductive biases via Topological Neural Networks. Such models propagate messages through higher-dimensional structures, providing shortcuts or additional routes for information flow. With this construction, the underlying computational graph is no longer coupled with the input graph structure, thus mitigating the aforementioned bottlenecks while accounting also for h",
    "link": "https://arxiv.org/abs/2402.06908",
    "context": "Title: Topological Neural Networks: Mitigating the Bottlenecks of Graph Neural Networks via Higher-Order Interactions\nAbstract: The irreducible complexity of natural phenomena has led Graph Neural Networks to be employed as a standard model to perform representation learning tasks on graph-structured data. While their capacity to capture local and global patterns is remarkable, the implications associated with long-range and higher-order dependencies pose considerable challenges to such models. This work starts with a theoretical framework to reveal the impact of network's width, depth, and graph topology on the over-squashing phenomena in message-passing neural networks. Then, the work drifts towards, higher-order interactions and multi-relational inductive biases via Topological Neural Networks. Such models propagate messages through higher-dimensional structures, providing shortcuts or additional routes for information flow. With this construction, the underlying computational graph is no longer coupled with the input graph structure, thus mitigating the aforementioned bottlenecks while accounting also for h",
    "path": "papers/24/02/2402.06908.json",
    "total_tokens": 852,
    "translated_title": "高拓扑神经网络：通过高阶相互作用缓解图神经网络的瓶颈问题",
    "translated_abstract": "自然现象的不可约复杂性使得图神经网络成为在图结构数据上进行表示学习任务的标准模型。虽然它们能够捕捉局部和全局模式的能力令人印象深刻，但与长距离和高阶依赖相关的影响对这些模型提出了相当大的挑战。本文从理论框架入手，揭示了网络的宽度、深度和图拓扑对消息传递神经网络中过度压缩现象的影响。然后，本文通过高拓扑神经网络从高阶相互作用和多关系归纳偏置入手。这种模型通过高维结构传播消息，为信息流提供了快捷方式或额外的路径。通过这种构建，底层的计算图不再与输入图结构耦合，从而缓解了前面提到的瓶颈问题，同时还考虑了h。",
    "tldr": "本文研究了图神经网络的瓶颈问题，并提出了一种名为高拓扑神经网络的方法，通过引入高阶相互作用和多关系归纳偏置来缓解这些问题。",
    "en_tdlr": "This paper explores the bottlenecks of graph neural networks and proposes an approach called Topological Neural Networks, which mitigates these issues by introducing higher-order interactions and multi-relational inductive biases."
}