{
    "title": "Robust Training of Federated Models with Extremely Label Deficiency",
    "abstract": "arXiv:2402.14430v1 Announce Type: new  Abstract: Federated semi-supervised learning (FSSL) has emerged as a powerful paradigm for collaboratively training machine learning models using distributed data with label deficiency. Advanced FSSL methods predominantly focus on training a single model on each client. However, this approach could lead to a discrepancy between the objective functions of labeled and unlabeled data, resulting in gradient conflicts. To alleviate gradient conflict, we propose a novel twin-model paradigm, called Twin-sight, designed to enhance mutual guidance by providing insights from different perspectives of labeled and unlabeled data. In particular, Twin-sight concurrently trains a supervised model with a supervised objective function while training an unsupervised model using an unsupervised objective function. To enhance the synergy between these two models, Twin-sight introduces a neighbourhood-preserving constraint, which encourages the preservation of the nei",
    "link": "https://arxiv.org/abs/2402.14430",
    "context": "Title: Robust Training of Federated Models with Extremely Label Deficiency\nAbstract: arXiv:2402.14430v1 Announce Type: new  Abstract: Federated semi-supervised learning (FSSL) has emerged as a powerful paradigm for collaboratively training machine learning models using distributed data with label deficiency. Advanced FSSL methods predominantly focus on training a single model on each client. However, this approach could lead to a discrepancy between the objective functions of labeled and unlabeled data, resulting in gradient conflicts. To alleviate gradient conflict, we propose a novel twin-model paradigm, called Twin-sight, designed to enhance mutual guidance by providing insights from different perspectives of labeled and unlabeled data. In particular, Twin-sight concurrently trains a supervised model with a supervised objective function while training an unsupervised model using an unsupervised objective function. To enhance the synergy between these two models, Twin-sight introduces a neighbourhood-preserving constraint, which encourages the preservation of the nei",
    "path": "papers/24/02/2402.14430.json",
    "total_tokens": 878,
    "translated_title": "具有极端标签不足的联邦模型鲁棒训练",
    "translated_abstract": "联邦半监督学习（FSSL）已经成为一种强大的范式，用于协作训练具有标签不足的分布式数据的机器学习模型。鲁棒的FSSL方法主要集中于在每个客户端训练单个模型。然而，这种方法可能导致标记数据和无标记数据的目标函数之间存在差异，从而产生梯度冲突。为了减轻梯度冲突，我们提出了一种新颖的双模型范式，称为Twin-sight，旨在通过提供来自标记和未标记数据不同视角的见解来增强相互指导。特别地，Twin-sight同时训练一个具有监督目标函数的监督模型，同时使用无监督目标函数训练一个无监督模型。为了增强这两个模型之间的协同作用，Twin-sight引入了一个保持邻域的约束，促进邻域的保留",
    "tldr": "提出了一种名为Twin-sight的双模型范式，以增强联邦半监督学习中标签和无标签数据之间的互动，并通过引入邻域保持约束来提高这两个模型之间的协同作用",
    "en_tdlr": "Introducing a novel twin-model paradigm called Twin-sight to enhance the interaction between labeled and unlabeled data in federated semi-supervised learning, and improve synergy between the two models by introducing a neighborhood-preserving constraint."
}