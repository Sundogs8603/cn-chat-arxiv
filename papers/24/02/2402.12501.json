{
    "title": "Your Vision-Language Model Itself Is a Strong Filter: Towards High-Quality Instruction Tuning with Data Selection",
    "abstract": "arXiv:2402.12501v1 Announce Type: new  Abstract: Data selection in instruction tuning emerges as a pivotal process for acquiring high-quality data and training instruction-following large language models (LLMs), but it is still a new and unexplored research area for vision-language models (VLMs). Existing data selection approaches on LLMs either rely on single unreliable scores, or use downstream tasks for selection, which is time-consuming and can lead to potential over-fitting on the chosen evaluation datasets. To address this challenge, we introduce a novel dataset selection method, Self-Filter, that utilizes the VLM itself as a filter. This approach is inspired by the observation that VLMs benefit from training with the most challenging instructions. Self-Filter operates in two stages. In the first stage, we devise a scoring network to evaluate the difficulty of training instructions, which is co-trained with the VLM. In the second stage, we use the trained score net to measure the",
    "link": "https://arxiv.org/abs/2402.12501",
    "context": "Title: Your Vision-Language Model Itself Is a Strong Filter: Towards High-Quality Instruction Tuning with Data Selection\nAbstract: arXiv:2402.12501v1 Announce Type: new  Abstract: Data selection in instruction tuning emerges as a pivotal process for acquiring high-quality data and training instruction-following large language models (LLMs), but it is still a new and unexplored research area for vision-language models (VLMs). Existing data selection approaches on LLMs either rely on single unreliable scores, or use downstream tasks for selection, which is time-consuming and can lead to potential over-fitting on the chosen evaluation datasets. To address this challenge, we introduce a novel dataset selection method, Self-Filter, that utilizes the VLM itself as a filter. This approach is inspired by the observation that VLMs benefit from training with the most challenging instructions. Self-Filter operates in two stages. In the first stage, we devise a scoring network to evaluate the difficulty of training instructions, which is co-trained with the VLM. In the second stage, we use the trained score net to measure the",
    "path": "papers/24/02/2402.12501.json",
    "total_tokens": 779,
    "translated_title": "你的视觉语言模型本身就是一个强大的过滤器：朝向使用数据选择进行高质量指令调整",
    "translated_abstract": "在指令调整中进行数据选择成为获取高质量数据并训练大型语言模型（LLMs）的关键过程，但对于视觉语言模型（VLMs）而言，这仍然是一个新颖且未被探索的研究领域。为了解决现有LLMs上的数据选择方法要么依赖于单一不可靠的分数，要么使用下游任务进行选择，这既耗时又可能导致过拟合所选评估数据集的潜在问题。为了解决这一挑战，我们引入了一种新颖的数据集选择方法，Self-Filter，它利用VLM本身作为过滤器。",
    "tldr": "使用Self-Filter这种方法，利用VLM本身作为一个过滤器进行数据集选择，以获取高质量数据并训练指令-following大型语言模型。"
}