{
    "title": "Sym-Q: Adaptive Symbolic Regression via Sequential Decision-Making",
    "abstract": "Symbolic regression holds great potential for uncovering underlying mathematical and physical relationships from empirical data. While existing transformer-based models have recently achieved significant success in this domain, they face challenges in terms of generalizability and adaptability. Typically, in cases where the output expressions do not adequately fit experimental data, the models lack efficient mechanisms to adapt or modify the expression. This inflexibility hinders their application in real-world scenarios, particularly in discovering unknown physical or biological relationships. Inspired by how human experts refine and adapt expressions, we introduce Symbolic Q-network (Sym-Q), a novel reinforcement learning-based model that redefines symbolic regression as a sequential decision-making task. Sym-Q leverages supervised demonstrations and refines expressions based on reward signals indicating the quality of fitting precision. Its distinctive ability to manage the complexi",
    "link": "https://arxiv.org/abs/2402.05306",
    "context": "Title: Sym-Q: Adaptive Symbolic Regression via Sequential Decision-Making\nAbstract: Symbolic regression holds great potential for uncovering underlying mathematical and physical relationships from empirical data. While existing transformer-based models have recently achieved significant success in this domain, they face challenges in terms of generalizability and adaptability. Typically, in cases where the output expressions do not adequately fit experimental data, the models lack efficient mechanisms to adapt or modify the expression. This inflexibility hinders their application in real-world scenarios, particularly in discovering unknown physical or biological relationships. Inspired by how human experts refine and adapt expressions, we introduce Symbolic Q-network (Sym-Q), a novel reinforcement learning-based model that redefines symbolic regression as a sequential decision-making task. Sym-Q leverages supervised demonstrations and refines expressions based on reward signals indicating the quality of fitting precision. Its distinctive ability to manage the complexi",
    "path": "papers/24/02/2402.05306.json",
    "total_tokens": 891,
    "translated_title": "Sym-Q：通过顺序决策进行自适应符号回归",
    "translated_abstract": "符号回归具有从实证数据中揭示潜在数学和物理关系的巨大潜力。虽然现有的基于Transformer的模型在这个领域取得了显著成功，但它们在泛化性和适应性方面面临挑战。通常，当输出表达式不足以适应实验数据时，这些模型缺乏有效的机制来适应或修改表达式。这种缺乏灵活性限制了它们在实际场景中的应用，特别是在发现未知的物理或生物关系方面。受到人类专家如何改进和调整表达式的启发，我们引入了一种新颖的基于强化学习的模型Symbolic Q-network（Sym-Q），将符号回归重新定义为顺序决策任务。Sym-Q利用监督演示并根据奖励信号来改进表达式，奖励信号指示拟合精度的质量。它独特的能力可以处理复杂性。",
    "tldr": "Sym-Q是一个基于强化学习的模型，通过将符号回归重新定义为顺序决策任务来解决现有模型在泛化性和适应性方面的挑战。通过利用监督演示和奖励信号，Sym-Q能够根据拟合精度的质量改进表达式。"
}