{
    "title": "Fast Adversarial Attacks on Language Models In One GPU Minute",
    "abstract": "arXiv:2402.15570v1 Announce Type: cross  Abstract: In this paper, we introduce a novel class of fast, beam search-based adversarial attack (BEAST) for Language Models (LMs). BEAST employs interpretable parameters, enabling attackers to balance between attack speed, success rate, and the readability of adversarial prompts. The computational efficiency of BEAST facilitates us to investigate its applications on LMs for jailbreaking, eliciting hallucinations, and privacy attacks. Our gradient-free targeted attack can jailbreak aligned LMs with high attack success rates within one minute. For instance, BEAST can jailbreak Vicuna-7B-v1.5 under one minute with a success rate of 89% when compared to a gradient-based baseline that takes over an hour to achieve 70% success rate using a single Nvidia RTX A6000 48GB GPU. Additionally, we discover a unique outcome wherein our untargeted attack induces hallucinations in LM chatbots. Through human evaluations, we find that our untargeted attack cause",
    "link": "https://arxiv.org/abs/2402.15570",
    "context": "Title: Fast Adversarial Attacks on Language Models In One GPU Minute\nAbstract: arXiv:2402.15570v1 Announce Type: cross  Abstract: In this paper, we introduce a novel class of fast, beam search-based adversarial attack (BEAST) for Language Models (LMs). BEAST employs interpretable parameters, enabling attackers to balance between attack speed, success rate, and the readability of adversarial prompts. The computational efficiency of BEAST facilitates us to investigate its applications on LMs for jailbreaking, eliciting hallucinations, and privacy attacks. Our gradient-free targeted attack can jailbreak aligned LMs with high attack success rates within one minute. For instance, BEAST can jailbreak Vicuna-7B-v1.5 under one minute with a success rate of 89% when compared to a gradient-based baseline that takes over an hour to achieve 70% success rate using a single Nvidia RTX A6000 48GB GPU. Additionally, we discover a unique outcome wherein our untargeted attack induces hallucinations in LM chatbots. Through human evaluations, we find that our untargeted attack cause",
    "path": "papers/24/02/2402.15570.json",
    "total_tokens": 923,
    "translated_title": "一分钟内在语言模型上的快速对抗攻击",
    "translated_abstract": "在这篇论文中，我们介绍了一种新型的快速基于束搜索的语言模型对抗攻击（BEAST）。BEAST采用可解释的参数，使攻击者能够在攻击速度、成功率和对抗性提示的可读性之间取得平衡。BEAST的计算效率使我们能够研究其在语言模型中用于越狱、引发幻觉和隐私攻击的应用。我们的基于梯度的有针对性攻击可以在一分钟内越狱对齐的语言模型，攻击成功率很高。例如，与基于梯度的基准相比，BEAST可以在一分钟内越狱 Vicuna-7B-v1.5，成功率达到89%，而基准方法需要一个小时以上才能使用单个 Nvidia RTX A6000 48GB GPU 实现70%的成功率。此外，我们发现一个独特的结果，即我们的非有针对性攻击会导致语言模型聊天机器人产生幻觉。通过人类评估，我们发现我们的非有针对性攻击导致了",
    "tldr": "介绍了一种新型的基于束搜索的快速对抗攻击方法BEAST，能够在一分钟内高成功率地越狱对齐的语言模型，同时还能导致语言模型产生幻觉。",
    "en_tdlr": "Introducing a novel beam search-based fast adversarial attack method BEAST that can successfully jailbreak aligned language models within one minute with high success rate, and also induce hallucinations in language models."
}