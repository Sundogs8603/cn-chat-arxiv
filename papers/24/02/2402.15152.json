{
    "title": "On the Duality Between Sharpness-Aware Minimization and Adversarial Training",
    "abstract": "arXiv:2402.15152v1 Announce Type: cross  Abstract: Adversarial Training (AT), which adversarially perturb the input samples during training, has been acknowledged as one of the most effective defenses against adversarial attacks, yet suffers from a fundamental tradeoff that inevitably decreases clean accuracy. Instead of perturbing the samples, Sharpness-Aware Minimization (SAM) perturbs the model weights during training to find a more flat loss landscape and improve generalization. However, as SAM is designed for better clean accuracy, its effectiveness in enhancing adversarial robustness remains unexplored. In this work, considering the duality between SAM and AT, we investigate the adversarial robustness derived from SAM. Intriguingly, we find that using SAM alone can improve adversarial robustness. To understand this unexpected property of SAM, we first provide empirical and theoretical insights into how SAM can implicitly learn more robust features, and conduct comprehensive exper",
    "link": "https://arxiv.org/abs/2402.15152",
    "context": "Title: On the Duality Between Sharpness-Aware Minimization and Adversarial Training\nAbstract: arXiv:2402.15152v1 Announce Type: cross  Abstract: Adversarial Training (AT), which adversarially perturb the input samples during training, has been acknowledged as one of the most effective defenses against adversarial attacks, yet suffers from a fundamental tradeoff that inevitably decreases clean accuracy. Instead of perturbing the samples, Sharpness-Aware Minimization (SAM) perturbs the model weights during training to find a more flat loss landscape and improve generalization. However, as SAM is designed for better clean accuracy, its effectiveness in enhancing adversarial robustness remains unexplored. In this work, considering the duality between SAM and AT, we investigate the adversarial robustness derived from SAM. Intriguingly, we find that using SAM alone can improve adversarial robustness. To understand this unexpected property of SAM, we first provide empirical and theoretical insights into how SAM can implicitly learn more robust features, and conduct comprehensive exper",
    "path": "papers/24/02/2402.15152.json",
    "total_tokens": 890,
    "translated_title": "关于Sharpness-Aware最小化和对抗训练之间的对偶性",
    "translated_abstract": "对抗训练(Adversarial Training, AT)在训练过程中对输入样本进行对抗性扰动，被认为是对抗攻击中最有效的防御之一，但不可避免地存在一种基本的权衡，即必然会降低干净准确性。与对样本进行扰动不同，Sharpness-Aware最小化(SAM)在训练过程中对模型权重进行扰动，以寻找更平坦的损失曲面并提高泛化性能。然而，由于SAM旨在提高干净准确性，其在增强对抗稳健性方面的有效性尚未被探索。在本研究中，考虑到SAM和AT之间的对偶性，我们调查了从SAM中派生的对抗稳健性。有趣的是，我们发现单独使用SAM可以提高对抗稳健性。为了理解SAM的这种意外特性，我们首先提供了关于SAM如何隐式学习更鲁棒特征的经验和理论的见解，并进行了全面的实验。",
    "tldr": "通过研究Sharpness-Aware最小化(SAM)和对抗训练(AT)之间的对偶性，发现单独使用SAM可以提高对抗性能。",
    "en_tdlr": "Investigating the duality between Sharpness-Aware Minimization (SAM) and Adversarial Training (AT), it is discovered that using SAM alone can improve adversarial performance."
}