{
    "title": "Retrieval-based Full-length Wikipedia Generation for Emergent Events",
    "abstract": "arXiv:2402.18264v1 Announce Type: new  Abstract: In today's fast-paced world, the growing demand to quickly generate comprehensive and accurate Wikipedia documents for emerging events is both crucial and challenging. However, previous efforts in Wikipedia generation have often fallen short of meeting real-world requirements. Some approaches focus solely on generating segments of a complete Wikipedia document, while others overlook the importance of faithfulness in generation or fail to consider the influence of the pre-training corpus. In this paper, we simulate a real-world scenario where structured full-length Wikipedia documents are generated for emergent events using input retrieved from web sources. To ensure that Large Language Models (LLMs) are not trained on corpora related to recently occurred events, we select events that have taken place recently and introduce a new benchmark Wiki-GenBen, which consists of 309 events paired with their corresponding retrieved web pages for ge",
    "link": "https://arxiv.org/abs/2402.18264",
    "context": "Title: Retrieval-based Full-length Wikipedia Generation for Emergent Events\nAbstract: arXiv:2402.18264v1 Announce Type: new  Abstract: In today's fast-paced world, the growing demand to quickly generate comprehensive and accurate Wikipedia documents for emerging events is both crucial and challenging. However, previous efforts in Wikipedia generation have often fallen short of meeting real-world requirements. Some approaches focus solely on generating segments of a complete Wikipedia document, while others overlook the importance of faithfulness in generation or fail to consider the influence of the pre-training corpus. In this paper, we simulate a real-world scenario where structured full-length Wikipedia documents are generated for emergent events using input retrieved from web sources. To ensure that Large Language Models (LLMs) are not trained on corpora related to recently occurred events, we select events that have taken place recently and introduce a new benchmark Wiki-GenBen, which consists of 309 events paired with their corresponding retrieved web pages for ge",
    "path": "papers/24/02/2402.18264.json",
    "total_tokens": 813,
    "translated_title": "基于检索的应急事件全长维基百科生成",
    "translated_abstract": "在当今快节奏的世界中，迅速生成新兴事件全面准确的维基百科文档的需求日益重要且具有挑战性。然而，先前的维基百科生成工作往往未能满足现实需求。一些方法仅专注于生成完整维基百科文档的部分内容，而另一些则忽视了生成过程中忠实性的重要性，或未考虑预训练语料库的影响。本文中，我们模拟了一个真实世界场景，使用从网页来源检索的内容为新兴事件生成结构化的全长维基百科文档。为确保大型语言模型（LLMs）未经过基于最近发生事件的语料库训练，我们选择最近发生的事件并引入了一个新的基准 Wiki-GenBen，其中包含了309个事件及其对应的检索到的网页。",
    "tldr": "通过检索获取的Web来源信息，为新兴事件生成结构化的全长维基百科文档，避免大型语言模型在与最近发生事件相关的语料库上进行训练。",
    "en_tdlr": "Generating structured full-length Wikipedia documents for emergent events using information retrieved from web sources, while avoiding training Large Language Models on corpora related to recently occurred events."
}