{
    "title": "Enhance Reasoning for Large Language Models in the Game Werewolf",
    "abstract": "This paper presents an innovative framework that integrates Large Language Models (LLMs) with an external Thinker module to enhance the reasoning capabilities of LLM-based agents. Unlike augmenting LLMs with prompt engineering, Thinker directly harnesses knowledge from databases and employs various optimization techniques. The framework forms a reasoning hierarchy where LLMs handle intuitive System-1 tasks such as natural language processing, while the Thinker focuses on cognitive System-2 tasks that require complex logical analysis and domain-specific knowledge. Our framework is presented using a 9-player Werewolf game that demands dual-system reasoning. We introduce a communication protocol between LLMs and the Thinker, and train the Thinker using data from 18800 human sessions and reinforcement learning. Experiments demonstrate the framework's effectiveness in deductive reasoning, speech generation, and online game evaluation. Additionally, we fine-tune a 6B LLM to surpass GPT4 when",
    "link": "https://arxiv.org/abs/2402.02330",
    "context": "Title: Enhance Reasoning for Large Language Models in the Game Werewolf\nAbstract: This paper presents an innovative framework that integrates Large Language Models (LLMs) with an external Thinker module to enhance the reasoning capabilities of LLM-based agents. Unlike augmenting LLMs with prompt engineering, Thinker directly harnesses knowledge from databases and employs various optimization techniques. The framework forms a reasoning hierarchy where LLMs handle intuitive System-1 tasks such as natural language processing, while the Thinker focuses on cognitive System-2 tasks that require complex logical analysis and domain-specific knowledge. Our framework is presented using a 9-player Werewolf game that demands dual-system reasoning. We introduce a communication protocol between LLMs and the Thinker, and train the Thinker using data from 18800 human sessions and reinforcement learning. Experiments demonstrate the framework's effectiveness in deductive reasoning, speech generation, and online game evaluation. Additionally, we fine-tune a 6B LLM to surpass GPT4 when",
    "path": "papers/24/02/2402.02330.json",
    "total_tokens": 895,
    "translated_title": "在狼人游戏中增强大型语言模型的推理能力",
    "translated_abstract": "本文提出了一个创新的框架，将大型语言模型（LLM）与外部思考模块相结合，以增强基于LLM的代理的推理能力。与通过prompt工程增加LLM不同，思考者直接利用数据库中的知识，并采用各种优化技术。该框架形成了一个推理层次结构，在其中LLM处理直观的系统1任务，如自然语言处理，而思考者专注于需要复杂的逻辑分析和领域特定知识的认知系统2任务。我们以需要双系统推理的9人狼人游戏为例介绍了该框架。我们引入了LLM和思考者之间的通信协议，并使用来自18800个人类会话和强化学习的数据训练了思考者。实验证明了该框架在演绎推理、语音生成和在线游戏评估方面的有效性。此外，我们通过微调6B LLM，超越了GPT4。",
    "tldr": "本文提出了一个创新的框架，将大型语言模型（LLM）与外部思考模块相结合，以增强推理能力，通过引入通信协议和使用大量数据进行训练，展示了其在游戏推理、语音生成和在线评估方面的有效性。"
}