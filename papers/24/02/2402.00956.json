{
    "title": "Exploring Spatial Schema Intuitions in Large Language and Vision Models",
    "abstract": "Despite the ubiquity of large language models (LLMs) in AI research, the question of embodiment in LLMs remains underexplored, distinguishing them from embodied systems in robotics where sensory perception directly informs physical action. Our investigation navigates the intriguing terrain of whether LLMs, despite their non-embodied nature, effectively capture implicit human intuitions about fundamental, spatial building blocks of language. We employ insights from spatial cognitive foundations developed through early sensorimotor experiences, guiding our exploration through the reproduction of three psycholinguistic experiments. Surprisingly, correlations between model outputs and human responses emerge, revealing adaptability without a tangible connection to embodied experiences. Notable distinctions include polarized language model responses and reduced correlations in vision language models. This research contributes to a nuanced understanding of the interplay between language, spat",
    "link": "https://rss.arxiv.org/abs/2402.00956",
    "context": "Title: Exploring Spatial Schema Intuitions in Large Language and Vision Models\nAbstract: Despite the ubiquity of large language models (LLMs) in AI research, the question of embodiment in LLMs remains underexplored, distinguishing them from embodied systems in robotics where sensory perception directly informs physical action. Our investigation navigates the intriguing terrain of whether LLMs, despite their non-embodied nature, effectively capture implicit human intuitions about fundamental, spatial building blocks of language. We employ insights from spatial cognitive foundations developed through early sensorimotor experiences, guiding our exploration through the reproduction of three psycholinguistic experiments. Surprisingly, correlations between model outputs and human responses emerge, revealing adaptability without a tangible connection to embodied experiences. Notable distinctions include polarized language model responses and reduced correlations in vision language models. This research contributes to a nuanced understanding of the interplay between language, spat",
    "path": "papers/24/02/2402.00956.json",
    "total_tokens": 917,
    "translated_title": "在大型语言和视觉模型中探索空间模式直觉",
    "translated_abstract": "尽管大型语言模型（LLM）在人工智能研究中非常普遍，但关于LLM中的具身性问题还未得到充分探讨，这使它们不同于机器人中具体的具身系统，机器人可以通过感知直接指导行动。我们的研究探索了一个有趣的问题，即LLM是否能够有效地捕捉到人类对于语言中基本的空间构建块的隐含直觉，尽管它们是非具身的。我们运用从早期感知运动经验中发展出的空间认知基础的见解，通过再现三个心理语言学实验来指导我们的探索。令人惊讶的是，模型输出与人类回答之间出现了相关性，揭示了没有与具体经验有实质连接的适应能力。显著的区别包括极化的语言模型响应和视觉语言模型中降低的相关性。这项研究对于深入了解语言和空间的相互作用有着微妙的贡献。",
    "tldr": "通过再现心理语言学实验，研究发现大型语言模型（LLMs）尽管无具身性，却能够有效捕捉到人类对于语言中基本的空间构建块的隐含直觉，这对于理解语言和空间的相互作用具有重要意义。"
}