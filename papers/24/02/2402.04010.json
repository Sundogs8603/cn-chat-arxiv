{
    "title": "Efficient Availability Attacks against Supervised and Contrastive Learning Simultaneously",
    "abstract": "Availability attacks can prevent the unauthorized use of private data and commercial datasets by generating imperceptible noise and making unlearnable examples before release. Ideally, the obtained unlearnability prevents algorithms from training usable models. When supervised learning (SL) algorithms have failed, a malicious data collector possibly resorts to contrastive learning (CL) algorithms to bypass the protection. Through evaluation, we have found that most of the existing methods are unable to achieve both supervised and contrastive unlearnability, which poses risks to data protection. Different from recent methods based on contrastive error minimization, we employ contrastive-like data augmentations in supervised error minimization or maximization frameworks to obtain attacks effective for both SL and CL. Our proposed AUE and AAP attacks achieve state-of-the-art worst-case unlearnability across SL and CL algorithms with less computation consumption, showcasing prospects in re",
    "link": "https://arxiv.org/abs/2402.04010",
    "context": "Title: Efficient Availability Attacks against Supervised and Contrastive Learning Simultaneously\nAbstract: Availability attacks can prevent the unauthorized use of private data and commercial datasets by generating imperceptible noise and making unlearnable examples before release. Ideally, the obtained unlearnability prevents algorithms from training usable models. When supervised learning (SL) algorithms have failed, a malicious data collector possibly resorts to contrastive learning (CL) algorithms to bypass the protection. Through evaluation, we have found that most of the existing methods are unable to achieve both supervised and contrastive unlearnability, which poses risks to data protection. Different from recent methods based on contrastive error minimization, we employ contrastive-like data augmentations in supervised error minimization or maximization frameworks to obtain attacks effective for both SL and CL. Our proposed AUE and AAP attacks achieve state-of-the-art worst-case unlearnability across SL and CL algorithms with less computation consumption, showcasing prospects in re",
    "path": "papers/24/02/2402.04010.json",
    "total_tokens": 876,
    "translated_title": "针对监督和对比学习的高效可用性攻击",
    "translated_abstract": "可用性攻击可以通过生成难以察觉的噪音和制造不可学习的示例来防止私人数据和商业数据集的未经授权使用。当监督学习算法失败时，恶意的数据收集者可能会转向对比学习算法以绕过保护。通过评估，我们发现现有的大多数方法无法同时实现监督和对比的不可学习性，这给数据保护带来了风险。与基于对比误差最小化的最新方法不同，我们在监督误差最小化或最大化框架中使用类似对比的数据增强来获得对监督和对比学习均有效的攻击。我们提出的AUE和AAP攻击在减少计算消耗的前提下，实现了监督和对比学习算法的最新最坏情况的不可学习性，展示了未来的前景。",
    "tldr": "本文提出了一种高效的可用性攻击方法，可以同时针对监督学习和对比学习，通过生成难以察觉的噪音和制造不可学习的示例来防止未经授权使用数据，并实现了监督和对比学习算法的最新最坏情况的不可学习性。"
}