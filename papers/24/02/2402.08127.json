{
    "title": "Efficient Contextual Bandits with Uninformed Feedback Graphs",
    "abstract": "Bandits with feedback graphs are powerful online learning models that interpolate between the full information and classic bandit problems, capturing many real-life applications. A recent work by Zhang et al. (2023) studies the contextual version of this problem and proposes an efficient and optimal algorithm via a reduction to online regression. However, their algorithm crucially relies on seeing the feedback graph before making each decision, while in many applications, the feedback graph is uninformed, meaning that it is either only revealed after the learner makes her decision or even never fully revealed at all. This work develops the first contextual algorithm for such uninformed settings, via an efficient reduction to online regression over both the losses and the graphs. Importantly, we show that it is critical to learn the graphs using log loss instead of squared loss to obtain favorable regret guarantees. We also demonstrate the empirical effectiveness of our algorithm on a b",
    "link": "https://arxiv.org/abs/2402.08127",
    "context": "Title: Efficient Contextual Bandits with Uninformed Feedback Graphs\nAbstract: Bandits with feedback graphs are powerful online learning models that interpolate between the full information and classic bandit problems, capturing many real-life applications. A recent work by Zhang et al. (2023) studies the contextual version of this problem and proposes an efficient and optimal algorithm via a reduction to online regression. However, their algorithm crucially relies on seeing the feedback graph before making each decision, while in many applications, the feedback graph is uninformed, meaning that it is either only revealed after the learner makes her decision or even never fully revealed at all. This work develops the first contextual algorithm for such uninformed settings, via an efficient reduction to online regression over both the losses and the graphs. Importantly, we show that it is critical to learn the graphs using log loss instead of squared loss to obtain favorable regret guarantees. We also demonstrate the empirical effectiveness of our algorithm on a b",
    "path": "papers/24/02/2402.08127.json",
    "total_tokens": 832,
    "translated_title": "无信息反馈图的高效上下文赌率",
    "translated_abstract": "具有反馈图的赌率是强大的在线学习模型，可以插值完整信息和经典赌率问题，捕捉许多现实应用。最近，张等人（2023年）研究了这个问题的上下文版本，并提出了一种通过在线回归降低效率和最优化算法。然而，他们的算法在每个决策之前都关键依赖于看到反馈图，而在许多应用中，反馈图是未知的，意味着它只在学习者做出决策后才被揭示，甚至从未完全揭示。本文通过高效地将在线回归应用于损失和图形，为这种未知设置开发了首个上下文算法。重要的是，我们表明使用对数损失学习图形是关键的，以获得有利的懊悔保证。我们还在一系列实验中展示了我们算法的实证效果。",
    "tldr": "本文提出了第一个针对无信息设置的上下文算法，通过在线回归降低效率和最优化算法，关键是学习使用对数损失的图形以获得有利的后悔保证。",
    "en_tdlr": "This paper proposes the first contextual algorithm for uninformed settings, reducing efficiency with online regression and optimization algorithms, with a key focus on learning graphs using log loss to obtain favorable regret guarantees."
}