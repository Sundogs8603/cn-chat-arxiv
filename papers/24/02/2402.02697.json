{
    "title": "Deep Equilibrium Models are Almost Equivalent to Not-so-deep Explicit Models for High-dimensional Gaussian Mixtures",
    "abstract": "Deep equilibrium models (DEQs), as a typical implicit neural network, have demonstrated remarkable success on various tasks. There is, however, a lack of theoretical understanding of the connections and differences between implicit DEQs and explicit neural network models. In this paper, leveraging recent advances in random matrix theory (RMT), we perform an in-depth analysis on the eigenspectra of the conjugate kernel (CK) and neural tangent kernel (NTK) matrices for implicit DEQs, when the input data are drawn from a high-dimensional Gaussian mixture. We prove, in this setting, that the spectral behavior of these Implicit-CKs and NTKs depend on the DEQ activation function and initial weight variances, but only via a system of four nonlinear equations. As a direct consequence of this theoretical result, we demonstrate that a shallow explicit network can be carefully designed to produce the same CK or NTK as a given DEQ. Despite derived here for Gaussian mixture data, empirical results ",
    "link": "https://arxiv.org/abs/2402.02697",
    "context": "Title: Deep Equilibrium Models are Almost Equivalent to Not-so-deep Explicit Models for High-dimensional Gaussian Mixtures\nAbstract: Deep equilibrium models (DEQs), as a typical implicit neural network, have demonstrated remarkable success on various tasks. There is, however, a lack of theoretical understanding of the connections and differences between implicit DEQs and explicit neural network models. In this paper, leveraging recent advances in random matrix theory (RMT), we perform an in-depth analysis on the eigenspectra of the conjugate kernel (CK) and neural tangent kernel (NTK) matrices for implicit DEQs, when the input data are drawn from a high-dimensional Gaussian mixture. We prove, in this setting, that the spectral behavior of these Implicit-CKs and NTKs depend on the DEQ activation function and initial weight variances, but only via a system of four nonlinear equations. As a direct consequence of this theoretical result, we demonstrate that a shallow explicit network can be carefully designed to produce the same CK or NTK as a given DEQ. Despite derived here for Gaussian mixture data, empirical results ",
    "path": "papers/24/02/2402.02697.json",
    "total_tokens": 928,
    "translated_title": "深度均衡模型与高维高斯混合模型中不太深的显式模型几乎等价",
    "translated_abstract": "深度均衡模型（DEQs）作为典型的隐式神经网络，在各种任务上取得了显着的成功。然而，我们对隐式DEQ和显式神经网络模型之间的连接和差异缺乏理论上的理解。在本文中，我们借鉴最近在随机矩阵理论方面的进展，对高维高斯混合模型输入数据下，隐式DEQ的共轭核（CK）和神经切向核（NTK）矩阵的特征光谱进行了深入分析。我们在这个设置中证明了这些隐式-CKs和NTKs的光谱行为取决于DEQ激活函数和初始权重方差，但仅通过一组四个非线性方程。作为这一理论结果的直接影响，我们证明可以精心设计一个浅显式网络来产生与给定DEQ相同的CK或NTK。尽管这里是针对高斯混合数据推导的，经验结果表明",
    "tldr": "本文通过对深度均衡模型和显式神经网络模型进行理论分析和实验证明，在高维高斯混合数据下，可以通过设计浅显式网络来实现与给定深度均衡模型相同的特征光谱行为。",
    "en_tdlr": "This paper provides theoretical analysis and empirical evidence that demonstrates the possibility of achieving the same spectral behavior as a given deep equilibrium model by designing a shallow explicit neural network, specifically in the context of high-dimensional Gaussian mixture data."
}