{
    "title": "Beyond Text: Improving LLM's Decision Making for Robot Navigation via Vocal Cues",
    "abstract": "This work highlights a critical shortcoming in text-based Large Language Models (LLMs) used for human-robot interaction, demonstrating that text alone as a conversation modality falls short in such applications. While LLMs excel in processing text in these human conversations, they struggle with the nuances of verbal instructions in scenarios like social navigation, where ambiguity and uncertainty can erode trust in robotic and other AI systems. We can address this shortcoming by moving beyond text and additionally focusing on the paralinguistic features of these audio responses. These features are the aspects of spoken communication that do not involve the literal wording (lexical content) but convey meaning and nuance through how something is said. We present \"Beyond Text\"; an approach that improves LLM decision-making by integrating audio transcription along with a subsection of these features, which focus on the affect and more relevant in human-robot conversations. This approach n",
    "link": "https://arxiv.org/abs/2402.03494",
    "context": "Title: Beyond Text: Improving LLM's Decision Making for Robot Navigation via Vocal Cues\nAbstract: This work highlights a critical shortcoming in text-based Large Language Models (LLMs) used for human-robot interaction, demonstrating that text alone as a conversation modality falls short in such applications. While LLMs excel in processing text in these human conversations, they struggle with the nuances of verbal instructions in scenarios like social navigation, where ambiguity and uncertainty can erode trust in robotic and other AI systems. We can address this shortcoming by moving beyond text and additionally focusing on the paralinguistic features of these audio responses. These features are the aspects of spoken communication that do not involve the literal wording (lexical content) but convey meaning and nuance through how something is said. We present \"Beyond Text\"; an approach that improves LLM decision-making by integrating audio transcription along with a subsection of these features, which focus on the affect and more relevant in human-robot conversations. This approach n",
    "path": "papers/24/02/2402.03494.json",
    "total_tokens": 850,
    "translated_title": "超越文字：通过语音线索改善LLM在机器人导航中的决策能力",
    "translated_abstract": "这项工作强调了基于文本的大规模语言模型（LLM）在人机交互中的关键缺点，表明仅使用文本作为对话的模态在此类应用中存在不足之处。虽然LLM在处理文本方面在这些人机对话中非常出色，但在社交导航等情境下，他们在处理口头指令的细微之处时遇到了困难，其中的歧义和不确定性可能会削弱对机器人和其他人工智能系统的信任。我们可以通过超越文字，并重点关注这些音频回应的语音非言语特征来解决这个问题。这些特征是口头交流中不涉及文字措辞的方面，通过表达方式传达意义和细微差别。我们提出了“超越文字”；一种通过集成音频转录以及这些特征的部分来改善LLM决策能力的方法，这些特征侧重情感和更与人机对话相关。",
    "tldr": "本论文通过将语音转录和语音非言语特征整合到LLM决策中来改善机器人导航中的决策能力，超越了仅使用文字的限制。"
}