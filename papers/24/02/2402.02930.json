{
    "title": "Embedding Hardware Approximations in Discrete Genetic-based Training for Printed MLPs",
    "abstract": "Printed Electronics (PE) stands out as a promisingtechnology for widespread computing due to its distinct attributes, such as low costs and flexible manufacturing. Unlike traditional silicon-based technologies, PE enables stretchable, conformal,and non-toxic hardware. However, PE are constrained by larger feature sizes, making it challenging to implement complex circuits such as machine learning (ML) classifiers. Approximate computing has been proven to reduce the hardware cost of ML circuits such as Multilayer Perceptrons (MLPs). In this paper, we maximize the benefits of approximate computing by integrating hardware approximation into the MLP training process. Due to the discrete nature of hardware approximation, we propose and implement a genetic-based, approximate, hardware-aware training approach specifically designed for printed MLPs. For a 5% accuracy loss, our MLPs achieve over 5x area and power reduction compared to the baseline while outperforming state of-the-art approximate",
    "link": "https://arxiv.org/abs/2402.02930",
    "context": "Title: Embedding Hardware Approximations in Discrete Genetic-based Training for Printed MLPs\nAbstract: Printed Electronics (PE) stands out as a promisingtechnology for widespread computing due to its distinct attributes, such as low costs and flexible manufacturing. Unlike traditional silicon-based technologies, PE enables stretchable, conformal,and non-toxic hardware. However, PE are constrained by larger feature sizes, making it challenging to implement complex circuits such as machine learning (ML) classifiers. Approximate computing has been proven to reduce the hardware cost of ML circuits such as Multilayer Perceptrons (MLPs). In this paper, we maximize the benefits of approximate computing by integrating hardware approximation into the MLP training process. Due to the discrete nature of hardware approximation, we propose and implement a genetic-based, approximate, hardware-aware training approach specifically designed for printed MLPs. For a 5% accuracy loss, our MLPs achieve over 5x area and power reduction compared to the baseline while outperforming state of-the-art approximate",
    "path": "papers/24/02/2402.02930.json",
    "total_tokens": 973,
    "translated_title": "将硬件近似嵌入离散基因训练中以用于印刷多层感知器",
    "translated_abstract": "印刷电子是一种有着低成本和灵活制造等独特特点的有望广泛应用于计算领域的技术。与传统的硅基技术不同，印刷电子可以实现可伸缩、可适应、非毒性的硬件。然而，由于印刷电子的特性尺寸较大，要实现复杂的电路如机器学习分类器是具有挑战性的。近似计算被证明可以降低机器学习电路（如多层感知器）的硬件成本。在本文中，我们通过将硬件近似嵌入到多层感知器的训练过程中来最大化近似计算的益处。由于硬件近似的离散性，我们提出并实现了一种基于遗传算法的硬件感知训练方法，专门为印刷多层感知器设计。在5%的精度损失下，相比基线，我们的多层感知器在面积和功耗上实现了超过5倍的减少，并且超过了最先进的近似方法。",
    "tldr": "本文将硬件近似嵌入到印刷多层感知器的训练过程中，通过离散遗传算法实现了最大化硬件近似的效益，在5%的精度损失下，相比基线，实现了超过5倍的面积和功耗的减少，并且超过了最先进的近似方法。",
    "en_tdlr": "This paper integrates hardware approximation into the training process of printed MLPs using a discrete genetic algorithm, achieving over 5 times reduction in area and power compared to the baseline at a 5% accuracy loss, while surpassing state-of-the-art approximate methods."
}