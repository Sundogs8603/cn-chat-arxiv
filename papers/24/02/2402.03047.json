{
    "title": "PFDM: Parser-Free Virtual Try-on via Diffusion Model",
    "abstract": "Virtual try-on can significantly improve the garment shopping experiences in both online and in-store scenarios, attracting broad interest in computer vision. However, to achieve high-fidelity try-on performance, most state-of-the-art methods still rely on accurate segmentation masks, which are often produced by near-perfect parsers or manual labeling. To overcome the bottleneck, we propose a parser-free virtual try-on method based on the diffusion model (PFDM). Given two images, PFDM can \"wear\" garments on the target person seamlessly by implicitly warping without any other information. To learn the model effectively, we synthesize many pseudo-images and construct sample pairs by wearing various garments on persons. Supervised by the large-scale expanded dataset, we fuse the person and garment features using a proposed Garment Fusion Attention (GFA) mechanism. Experiments demonstrate that our proposed PFDM can successfully handle complex cases, synthesize high-fidelity images, and out",
    "link": "https://arxiv.org/abs/2402.03047",
    "context": "Title: PFDM: Parser-Free Virtual Try-on via Diffusion Model\nAbstract: Virtual try-on can significantly improve the garment shopping experiences in both online and in-store scenarios, attracting broad interest in computer vision. However, to achieve high-fidelity try-on performance, most state-of-the-art methods still rely on accurate segmentation masks, which are often produced by near-perfect parsers or manual labeling. To overcome the bottleneck, we propose a parser-free virtual try-on method based on the diffusion model (PFDM). Given two images, PFDM can \"wear\" garments on the target person seamlessly by implicitly warping without any other information. To learn the model effectively, we synthesize many pseudo-images and construct sample pairs by wearing various garments on persons. Supervised by the large-scale expanded dataset, we fuse the person and garment features using a proposed Garment Fusion Attention (GFA) mechanism. Experiments demonstrate that our proposed PFDM can successfully handle complex cases, synthesize high-fidelity images, and out",
    "path": "papers/24/02/2402.03047.json",
    "total_tokens": 920,
    "translated_title": "PFDM: 透过扩散模型的免解析器虚拟试穿",
    "translated_abstract": "虚拟试穿可以显著提高在线和实体购物中的服装购物体验，引起计算机视觉方面的广泛关注。然而，为了实现高保真度的试穿效果，大多数最先进的方法仍依赖于准确的分割掩码，这些掩码通常是由准确无误的解析器或手动标注生成的。为了克服这个瓶颈，我们提出了一种基于扩散模型（PFDM）的免解析器虚拟试穿方法。给定两个图像，PFDM可以通过隐式变形无缝地将服装“穿”在目标人物身上，而无需其他信息。为了有效学习该模型，我们合成了许多伪图像，并通过在人物上穿上各种服装构建样品对。在大规模扩展数据集的监督下，我们使用提出的服装融合注意力（GFA）机制融合人物和服装特征。实验表明，我们提出的PFDM能成功处理复杂情况、合成高保真度的图像，并且超过了现有方法。",
    "tldr": "PFDM是一种基于扩散模型的免解析器虚拟试穿方法，可以无缝地在目标人物身上“穿”上服装，无需准确的分割掩码，并通过服装融合注意力机制达到高保真度的试穿效果。"
}