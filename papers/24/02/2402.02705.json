{
    "title": "Representation Surgery for Multi-Task Model Merging",
    "abstract": "Multi-task learning (MTL) compresses the information from multiple tasks into a unified backbone to improve computational efficiency and generalization. Recent work directly merges multiple independently trained models to perform MTL instead of collecting their raw data for joint training, greatly expanding the application scenarios of MTL. However, by visualizing the representation distribution of existing model merging schemes, we find that the merged model often suffers from the dilemma of representation bias. That is, there is a significant discrepancy in the representation distribution between the merged and individual models, resulting in poor performance of merged MTL. In this paper, we propose a representation surgery solution called \"Surgery\" to reduce representation bias in the merged model. Specifically, Surgery is a lightweight task-specific module that takes the representation of the merged model as input and attempts to output the biases contained in the representation fr",
    "link": "https://arxiv.org/abs/2402.02705",
    "context": "Title: Representation Surgery for Multi-Task Model Merging\nAbstract: Multi-task learning (MTL) compresses the information from multiple tasks into a unified backbone to improve computational efficiency and generalization. Recent work directly merges multiple independently trained models to perform MTL instead of collecting their raw data for joint training, greatly expanding the application scenarios of MTL. However, by visualizing the representation distribution of existing model merging schemes, we find that the merged model often suffers from the dilemma of representation bias. That is, there is a significant discrepancy in the representation distribution between the merged and individual models, resulting in poor performance of merged MTL. In this paper, we propose a representation surgery solution called \"Surgery\" to reduce representation bias in the merged model. Specifically, Surgery is a lightweight task-specific module that takes the representation of the merged model as input and attempts to output the biases contained in the representation fr",
    "path": "papers/24/02/2402.02705.json",
    "total_tokens": 855,
    "translated_title": "多任务模型合并的表征手术",
    "translated_abstract": "多任务学习（MTL）将多个任务的信息压缩到一个统一的骨干模型中，以提高计算效率和泛化能力。最近的研究直接合并多个独立训练的模型来执行MTL，而不是收集它们的原始数据进行联合训练，从而极大地扩展了MTL的应用场景。然而，通过可视化现有模型合并方案的表示分布，我们发现合并模型往往面临表示偏差的困境。也就是说，合并模型与个体模型之间的表示分布存在明显的差异，导致合并MTL性能较差。在本文中，我们提出了一个称为“Surgery”的表征手术解决方案，以减少合并模型中的表示偏差。具体而言，“Surgery”是一个轻量级的任务专用模块，它以合并模型的表示为输入，并试图输出其中包含的偏差。",
    "tldr": "该论文提出了一种名为“Surgery”的表征手术解决方案，用于减少多任务模型合并中的表示偏差。该方法通过一个轻量级的任务专用模块，针对合并模型的表示进行修正，以提高合并模型的性能。"
}