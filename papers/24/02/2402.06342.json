{
    "title": "Promoting Target Data in Context-aware Neural Machine Translation",
    "abstract": "Standard context-aware neural machine translation (NMT) typically relies on parallel document-level data, exploiting both source and target contexts. Concatenation-based approaches in particular, still a strong baseline for document-level NMT, prepend source and/or target context sentences to the sentences to be translated, with model variants that exploit equal amounts of source and target data on each side achieving state-of-the-art results. In this work, we investigate whether target data should be further promoted within standard concatenation-based approaches, as most document-level phenomena rely on information that is present on the target language side. We evaluate novel concatenation-based variants where the target context is prepended to the source language, either in isolation or in combination with the source context. Experimental results in English-Russian and Basque-Spanish show that including target context in the source leads to large improvements on target language phe",
    "link": "https://arxiv.org/abs/2402.06342",
    "context": "Title: Promoting Target Data in Context-aware Neural Machine Translation\nAbstract: Standard context-aware neural machine translation (NMT) typically relies on parallel document-level data, exploiting both source and target contexts. Concatenation-based approaches in particular, still a strong baseline for document-level NMT, prepend source and/or target context sentences to the sentences to be translated, with model variants that exploit equal amounts of source and target data on each side achieving state-of-the-art results. In this work, we investigate whether target data should be further promoted within standard concatenation-based approaches, as most document-level phenomena rely on information that is present on the target language side. We evaluate novel concatenation-based variants where the target context is prepended to the source language, either in isolation or in combination with the source context. Experimental results in English-Russian and Basque-Spanish show that including target context in the source leads to large improvements on target language phe",
    "path": "papers/24/02/2402.06342.json",
    "total_tokens": 870,
    "translated_title": "促进上下文感知的神经机器翻译中的目标数据",
    "translated_abstract": "标准的上下文感知的神经机器翻译（NMT）通常依赖于并行的文档级数据，利用源语言和目标语言的上下文。尤其是基于拼接的方法仍然是文档级NMT的强有力基线，它在要被翻译的句子之前添加源语言和/或目标语言的上下文句子，并且在每一侧利用相等数量的源语言和目标语言数据的模型变体达到了最先进的结果。在这项工作中，我们探讨了在标准的基于拼接的方法中是否应该进一步提供目标数据，因为大多数文档级现象依赖于目标语言侧存在的信息。我们评估了新的基于拼接的变种，在源语言之前添加目标上下文，要么仅在源语言中添加，要么与源上下文组合。在英俄和巴斯克西班牙语的实验结果表明，在源语言中包含目标上下文可以显著提高目标语言现象。",
    "tldr": "本研究探讨了在上下文感知的神经机器翻译中是否应该进一步提升目标数据，实验证明在源语言中包含目标上下文可以显著提高目标语言现象。"
}