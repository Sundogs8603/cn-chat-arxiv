{
    "title": "Preliminary Report on Mantis Shrimp: a Multi-Survey Computer Vision Photometric Redshift Model",
    "abstract": "The availability of large, public, multi-modal astronomical datasets presents an opportunity to execute novel research that straddles the line between science of AI and science of astronomy. Photometric redshift estimation is a well-established subfield of astronomy. Prior works show that computer vision models typically outperform catalog-based models, but these models face additional complexities when incorporating images from more than one instrument or sensor. In this report, we detail our progress creating Mantis Shrimp, a multi-survey computer vision model for photometric redshift estimation that fuses ultra-violet (GALEX), optical (PanSTARRS), and infrared (UnWISE) imagery. We use deep learning interpretability diagnostics to measure how the model leverages information from the different inputs. We reason about the behavior of the CNNs from the interpretability metrics, specifically framing the result in terms of physically-grounded knowledge of galaxy properties.",
    "link": "https://arxiv.org/abs/2402.03535",
    "context": "Title: Preliminary Report on Mantis Shrimp: a Multi-Survey Computer Vision Photometric Redshift Model\nAbstract: The availability of large, public, multi-modal astronomical datasets presents an opportunity to execute novel research that straddles the line between science of AI and science of astronomy. Photometric redshift estimation is a well-established subfield of astronomy. Prior works show that computer vision models typically outperform catalog-based models, but these models face additional complexities when incorporating images from more than one instrument or sensor. In this report, we detail our progress creating Mantis Shrimp, a multi-survey computer vision model for photometric redshift estimation that fuses ultra-violet (GALEX), optical (PanSTARRS), and infrared (UnWISE) imagery. We use deep learning interpretability diagnostics to measure how the model leverages information from the different inputs. We reason about the behavior of the CNNs from the interpretability metrics, specifically framing the result in terms of physically-grounded knowledge of galaxy properties.",
    "path": "papers/24/02/2402.03535.json",
    "total_tokens": 885,
    "translated_title": "对虾的初步报告：多调查计算机视觉光度红移模型",
    "translated_abstract": "大型、公共、多模态天文数据集的可用性为跨科学与天文学的人工智能研究提供了机会。光度红移估计是天文学的一个成熟子领域。先前的研究表明，计算机视觉模型通常优于基于目录的模型，但是这些模型在融合来自多个仪器或传感器的图像时面临额外的复杂性。在本报告中，我们详细介绍了我们正在创建的Mantis Shrimp，一个用于光度红移估计的多调查计算机视觉模型，它融合了紫外线（GALEX）、光学（PanSTARRS）和红外（UnWISE）图像。我们使用深度学习可解释性诊断来衡量模型如何利用来自不同输入的信息。我们根据可解释性指标从物理上基于的星系属性的角度推理CNN的行为。",
    "tldr": "这项研究报道了Mantis Shrimp，一个基于计算机视觉的多调查光度红移模型，融合了紫外线、光学和红外图像，并使用深度学习可解释性诊断技术研究了其如何利用不同输入信息。",
    "en_tdlr": "This report presents Mantis Shrimp, a computer vision-based multi-survey model for photometric redshift estimation that combines ultraviolet, optical, and infrared images. The study uses deep learning interpretability diagnostics to analyze how the model leverages information from different inputs."
}