{
    "title": "Diversity Measurement and Subset Selection for Instruction Tuning Datasets",
    "abstract": "We aim to select data subsets for the fine-tuning of large language models to more effectively follow instructions. Prior work has emphasized the importance of diversity in dataset curation but relied on heuristics such as the number of tasks. In this paper, we use determinantal point processes to capture the diversity and quality of instruction tuning datasets for subset selection. We propose to measure dataset diversity with log determinant distance that is the distance between the dataset of interest and a maximally diverse reference dataset. Our experiments demonstrate that the proposed diversity measure in the normalized weight gradient space is correlated with downstream instruction-following performance. Consequently, it can be used to inform when data selection is the most helpful and to analyze dataset curation strategies. We demonstrate the utility of our approach on various instruction tuning datasets.",
    "link": "https://arxiv.org/abs/2402.02318",
    "context": "Title: Diversity Measurement and Subset Selection for Instruction Tuning Datasets\nAbstract: We aim to select data subsets for the fine-tuning of large language models to more effectively follow instructions. Prior work has emphasized the importance of diversity in dataset curation but relied on heuristics such as the number of tasks. In this paper, we use determinantal point processes to capture the diversity and quality of instruction tuning datasets for subset selection. We propose to measure dataset diversity with log determinant distance that is the distance between the dataset of interest and a maximally diverse reference dataset. Our experiments demonstrate that the proposed diversity measure in the normalized weight gradient space is correlated with downstream instruction-following performance. Consequently, it can be used to inform when data selection is the most helpful and to analyze dataset curation strategies. We demonstrate the utility of our approach on various instruction tuning datasets.",
    "path": "papers/24/02/2402.02318.json",
    "total_tokens": 884,
    "translated_title": "指令调整数据集的多样性度量和子集选择",
    "translated_abstract": "我们的目标是选择数据子集，以更有效地对大型语言模型进行微调，以更好地遵循指令。之前的研究强调了数据集构建中多样性的重要性，但依赖于启发式方法，如任务数量。在本文中，我们使用确定性点过程来捕捉指令调整数据集的多样性和质量，以进行子集选择。我们提出用对数行列式距离来衡量数据集的多样性，即感兴趣的数据集与最大多样性参考数据集之间的距离。我们的实验表明，归一化的权重梯度空间中所提出的多样性度量与下游指令遵循性能相关。因此，它可以用于指导何时最有帮助地进行数据选择，并分析数据集构建策略。我们在各种指令调整数据集上展示了我们方法的实用性。",
    "tldr": "本文提出了一种用于指令调整数据集的多样性度量和子集选择的方法，通过使用确定性点过程来捕捉数据集的多样性和质量，并通过对数行列式距离来衡量数据集的多样性。实验证明，在归一化的权重梯度空间中，提出的多样性度量与指令遵循性能相关，并可以用于指导数据选择和分析数据集构建策略。",
    "en_tdlr": "This paper proposes a method for diversity measurement and subset selection for instruction tuning datasets, using determinantal point processes to capture diversity and quality, and log determinant distance to measure diversity. Experimental results show that the proposed diversity measure is correlated with instruction-following performance and can inform data selection and analysis of dataset curation strategies."
}