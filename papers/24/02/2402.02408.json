{
    "title": "GLaPE: Gold Label-agnostic Prompt Evaluation and Optimization for Large Language Model",
    "abstract": "Despite the rapid progress of large language models (LLMs), their task performance remains sensitive to prompt design. Recent studies have explored leveraging the LLM itself as an optimizer to identify optimal prompts that maximize task accuracy. However, when evaluating prompts, such approaches heavily rely on elusive manually annotated gold labels to calculate task accuracy for each candidate prompt, which hinders the widespread implementation and generality. To overcome the limitation, this work proposes a gold label-agnostic prompt evaluation (GLaPE) to alleviate dependence on gold labels. Motivated by the observed correlation between self-consistency and the accuracy of the answer, we adopt self-consistency as the initial evaluation score. Subsequently, we refine the scores of prompts producing identical answers to be mutually consistent. Experimental results show that GLaPE provides reliable evaluations uniform with accuracy, even in the absence of gold labels. Moreover, on six p",
    "link": "https://arxiv.org/abs/2402.02408",
    "context": "Title: GLaPE: Gold Label-agnostic Prompt Evaluation and Optimization for Large Language Model\nAbstract: Despite the rapid progress of large language models (LLMs), their task performance remains sensitive to prompt design. Recent studies have explored leveraging the LLM itself as an optimizer to identify optimal prompts that maximize task accuracy. However, when evaluating prompts, such approaches heavily rely on elusive manually annotated gold labels to calculate task accuracy for each candidate prompt, which hinders the widespread implementation and generality. To overcome the limitation, this work proposes a gold label-agnostic prompt evaluation (GLaPE) to alleviate dependence on gold labels. Motivated by the observed correlation between self-consistency and the accuracy of the answer, we adopt self-consistency as the initial evaluation score. Subsequently, we refine the scores of prompts producing identical answers to be mutually consistent. Experimental results show that GLaPE provides reliable evaluations uniform with accuracy, even in the absence of gold labels. Moreover, on six p",
    "path": "papers/24/02/2402.02408.json",
    "total_tokens": 964,
    "translated_title": "GLaPE：大型语言模型的无依赖于金标签的提示评估与优化",
    "translated_abstract": "尽管大型语言模型（LLMs）取得了快速进展，但它们的任务性能仍然对提示设计敏感。最近的研究探索了利用LLM自身作为优化器来识别最大化任务准确性的最优提示。然而，在评估提示时，这些方法严重依赖于难以获取的手动标注的金标签，以计算每个候选提示的任务准确性，这阻碍了广泛的实施和通用性。为了克服这一限制，本研究提出了一种无依赖于金标签的提示评估方法（GLaPE），以减少对金标签的依赖。受到自一致性和答案准确性之间的相关性的启发，我们将自一致性作为初始评估分数。随后，我们对产生相同答案的提示进行得分的互相一致性的改进。实验结果表明，GLaPE在没有金标签的情况下提供了与准确性相一致的可靠评估。此外，对于六个任务，GLaPE在绝大部分情况下得到的评估结果与使用真实金标签评估的结果相似。",
    "tldr": "GLaPE提出了一种无依赖于金标签的提示评估方法，通过自一致性作为初始评估分数，进一步改进了产生相同答案的提示的得分的互相一致性，提供了与准确性相一致的可靠评估，即使在没有金标签的情况下。",
    "en_tdlr": "GLaPE proposes a gold label-agnostic prompt evaluation method that relies on self-consistency as the initial evaluation score and further improves the mutual consistency of prompts producing identical answers. It provides reliable evaluations consistent with accuracy, even in the absence of gold labels."
}