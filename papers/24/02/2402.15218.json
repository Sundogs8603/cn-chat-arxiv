{
    "title": "BSPA: Exploring Black-box Stealthy Prompt Attacks against Image Generators",
    "abstract": "arXiv:2402.15218v1 Announce Type: cross  Abstract: Extremely large image generators offer significant transformative potential across diverse sectors. It allows users to design specific prompts to generate realistic images through some black-box APIs. However, some studies reveal that image generators are notably susceptible to attacks and generate Not Suitable For Work (NSFW) contents by manually designed toxin texts, especially imperceptible to human observers. We urgently need a multitude of universal and transferable prompts to improve the safety of image generators, especially black-box-released APIs. Nevertheless, they are constrained by labor-intensive design processes and heavily reliant on the quality of the given instructions. To achieve this, we introduce a black-box stealthy prompt attack (BSPA) that adopts a retriever to simulate attacks from API users. It can effectively harness filter scores to tune the retrieval space of sensitive words for matching the input prompts, t",
    "link": "https://arxiv.org/abs/2402.15218",
    "context": "Title: BSPA: Exploring Black-box Stealthy Prompt Attacks against Image Generators\nAbstract: arXiv:2402.15218v1 Announce Type: cross  Abstract: Extremely large image generators offer significant transformative potential across diverse sectors. It allows users to design specific prompts to generate realistic images through some black-box APIs. However, some studies reveal that image generators are notably susceptible to attacks and generate Not Suitable For Work (NSFW) contents by manually designed toxin texts, especially imperceptible to human observers. We urgently need a multitude of universal and transferable prompts to improve the safety of image generators, especially black-box-released APIs. Nevertheless, they are constrained by labor-intensive design processes and heavily reliant on the quality of the given instructions. To achieve this, we introduce a black-box stealthy prompt attack (BSPA) that adopts a retriever to simulate attacks from API users. It can effectively harness filter scores to tune the retrieval space of sensitive words for matching the input prompts, t",
    "path": "papers/24/02/2402.15218.json",
    "total_tokens": 817,
    "translated_title": "探索图像生成器的黑匣子隐蔽提示攻击",
    "translated_abstract": "极其大型的图像生成器在各个领域提供了重大的变革潜力，使用户能够设计特定提示来通过一些黑匣子API生成逼真的图像。然而，一些研究表明图像生成器容易受到攻击，通过人工设计的毒素文本生成不适宜工作内容（NSFW），尤其是对人类观察者极难察觉。我们迫切需要大量通用且可迁移的提示，以提高图像生成器的安全性，尤其是黑盒发布的API。然而，它们受限于劳动密集型的设计流程，并且严重依赖于给定指令的质量。为了实现这一目标，我们引入了一种黑匣子隐蔽提示攻击（BSPA），采用检索器模拟API用户的攻击。它能有效利用过滤器评分来调整敏感词汇的检索空间，以匹配输入提示。",
    "tldr": "提出了一种黑匣子隐蔽提示攻击（BSPA），采用检索器模拟攻击，以提高图像生成器的安全性。",
    "en_tdlr": "Introducing a black-box stealthy prompt attack (BSPA) using a retriever to improve the safety of image generators."
}