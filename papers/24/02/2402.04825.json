{
    "title": "Fast Timing-Conditioned Latent Audio Diffusion",
    "abstract": "Generating long-form 44.1kHz stereo audio from text prompts can be computationally demanding. Further, most previous works do not tackle that music and sound effects naturally vary in their duration. Our research focuses on the efficient generation of long-form, variable-length stereo music and sounds at 44.1kHz using text prompts with a generative model. Stable Audio is based on latent diffusion, with its latent defined by a fully-convolutional variational autoencoder. It is conditioned on text prompts as well as timing embeddings, allowing for fine control over both the content and length of the generated music and sounds. Stable Audio is capable of rendering stereo signals of up to 95 sec at 44.1kHz in 8 sec on an A100 GPU. Despite its compute efficiency and fast inference, it is one of the best in two public text-to-music and -audio benchmarks and, differently from state-of-the-art models, can generate music with structure and stereo sounds.",
    "link": "https://arxiv.org/abs/2402.04825",
    "context": "Title: Fast Timing-Conditioned Latent Audio Diffusion\nAbstract: Generating long-form 44.1kHz stereo audio from text prompts can be computationally demanding. Further, most previous works do not tackle that music and sound effects naturally vary in their duration. Our research focuses on the efficient generation of long-form, variable-length stereo music and sounds at 44.1kHz using text prompts with a generative model. Stable Audio is based on latent diffusion, with its latent defined by a fully-convolutional variational autoencoder. It is conditioned on text prompts as well as timing embeddings, allowing for fine control over both the content and length of the generated music and sounds. Stable Audio is capable of rendering stereo signals of up to 95 sec at 44.1kHz in 8 sec on an A100 GPU. Despite its compute efficiency and fast inference, it is one of the best in two public text-to-music and -audio benchmarks and, differently from state-of-the-art models, can generate music with structure and stereo sounds.",
    "path": "papers/24/02/2402.04825.json",
    "total_tokens": 924,
    "translated_title": "快速定时条件下的潜在音频扩散",
    "translated_abstract": "从文本提示生成长篇44.1kHz立体声音频可能对计算要求很高。此外，大多数先前的工作并没有解决音乐和音效在持续时间上的自然变化问题。我们的研究专注于使用生成模型以高效方式生成长篇、可变长度的44.1kHz立体声音乐和音效。Stable Audio基于潜在扩散，其潜在性质由一个全卷积变分自编码器定义。它不仅基于文本提示进行条件化，还基于时间嵌入，使得可以对生成的音乐和音效的内容和长度进行精细控制。在A100 GPU上，Stable Audio能够在8秒内以44.1kHz的速度渲染长达95秒的立体声信号。尽管计算效率高且推理速度快，但它在两个公开的文本-音乐和音频基准中仍然是最好的，并且与最先进的模型不同，它可以生成具有结构和立体声音乐。",
    "tldr": "本研究提出了一种名为Stable Audio的生成模型，该模型利用潜在扩散和条件化技术，实现了高效生成44.1kHz立体声音乐和音效。与其他最先进的模型不同，Stable Audio能够生成具有结构和立体声的音乐，并在性能评估上表现出色。",
    "en_tdlr": "This paper introduces a generative model called Stable Audio that efficiently generates 44.1kHz stereo music and sound effects using latent diffusion and conditioning techniques. Unlike other state-of-the-art models, Stable Audio is capable of generating music with structure and stereo sound, and performs well in performance evaluations."
}