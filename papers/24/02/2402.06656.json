{
    "title": "DiffsFormer: A Diffusion Transformer on Stock Factor Augmentation",
    "abstract": "Machine learning models have demonstrated remarkable efficacy and efficiency in a wide range of stock forecasting tasks. However, the inherent challenges of data scarcity, including low signal-to-noise ratio (SNR) and data homogeneity, pose significant obstacles to accurate forecasting. To address this issue, we propose a novel approach that utilizes artificial intelligence-generated samples (AIGS) to enhance the training procedures. In our work, we introduce the Diffusion Model to generate stock factors with Transformer architecture (DiffsFormer). DiffsFormer is initially trained on a large-scale source domain, incorporating conditional guidance so as to capture global joint distribution. When presented with a specific downstream task, we employ DiffsFormer to augment the training procedure by editing existing samples. This editing step allows us to control the strength of the editing process, determining the extent to which the generated data deviates from the target domain. To evalu",
    "link": "https://arxiv.org/abs/2402.06656",
    "context": "Title: DiffsFormer: A Diffusion Transformer on Stock Factor Augmentation\nAbstract: Machine learning models have demonstrated remarkable efficacy and efficiency in a wide range of stock forecasting tasks. However, the inherent challenges of data scarcity, including low signal-to-noise ratio (SNR) and data homogeneity, pose significant obstacles to accurate forecasting. To address this issue, we propose a novel approach that utilizes artificial intelligence-generated samples (AIGS) to enhance the training procedures. In our work, we introduce the Diffusion Model to generate stock factors with Transformer architecture (DiffsFormer). DiffsFormer is initially trained on a large-scale source domain, incorporating conditional guidance so as to capture global joint distribution. When presented with a specific downstream task, we employ DiffsFormer to augment the training procedure by editing existing samples. This editing step allows us to control the strength of the editing process, determining the extent to which the generated data deviates from the target domain. To evalu",
    "path": "papers/24/02/2402.06656.json",
    "total_tokens": 800,
    "translated_title": "DiffsFormer: Diffusion Transformer在股票因子增强上的应用",
    "translated_abstract": "机器学习模型在各种股票预测任务中展示出了显著的效果和效率。然而，数据稀缺性带来的困难，如低信噪比和数据同质性，对准确预测构成了重大障碍。为了解决这个问题，我们提出了一种新颖的方法，利用人工智能生成的样本(AIGS)来增强训练过程。在我们的工作中，我们引入了Diffusion Model来生成具有Transformer架构的股票因子(DiffsFormer)。DiffsFormer首先在大规模源领域上进行训练，结合条件指导以捕捉全局联合分布。在特定的下游任务中，我们使用DiffsFormer来通过编辑现有样本来增强训练过程。这个编辑步骤允许我们控制编辑过程的强度，确定生成数据与目标领域的偏离程度。",
    "tldr": "DiffsFormer是一种利用Diffusion Transformer和人工智能生成样本的方法，用于在股票预测中解决数据稀缺性和数据同质性的问题。"
}