{
    "title": "Respect the model: Fine-grained and Robust Explanation with Sharing Ratio Decomposition",
    "abstract": "The truthfulness of existing explanation methods in authentically elucidating the underlying model's decision-making process has been questioned. Existing methods have deviated from faithfully representing the model, thus susceptible to adversarial attacks. To address this, we propose a novel eXplainable AI (XAI) method called SRD (Sharing Ratio Decomposition), which sincerely reflects the model's inference process, resulting in significantly enhanced robustness in our explanations. Different from the conventional emphasis on the neuronal level, we adopt a vector perspective to consider the intricate nonlinear interactions between filters. We also introduce an interesting observation termed Activation-Pattern-Only Prediction (APOP), letting us emphasize the importance of inactive neurons and redefine relevance encapsulating all relevant information including both active and inactive neurons. Our method, SRD, allows for the recursive decomposition of a Pointwise Feature Vector (PFV), pr",
    "link": "https://arxiv.org/abs/2402.03348",
    "context": "Title: Respect the model: Fine-grained and Robust Explanation with Sharing Ratio Decomposition\nAbstract: The truthfulness of existing explanation methods in authentically elucidating the underlying model's decision-making process has been questioned. Existing methods have deviated from faithfully representing the model, thus susceptible to adversarial attacks. To address this, we propose a novel eXplainable AI (XAI) method called SRD (Sharing Ratio Decomposition), which sincerely reflects the model's inference process, resulting in significantly enhanced robustness in our explanations. Different from the conventional emphasis on the neuronal level, we adopt a vector perspective to consider the intricate nonlinear interactions between filters. We also introduce an interesting observation termed Activation-Pattern-Only Prediction (APOP), letting us emphasize the importance of inactive neurons and redefine relevance encapsulating all relevant information including both active and inactive neurons. Our method, SRD, allows for the recursive decomposition of a Pointwise Feature Vector (PFV), pr",
    "path": "papers/24/02/2402.03348.json",
    "total_tokens": 883,
    "translated_title": "尊重模型: 细粒度且鲁棒的解释与共享比例分解",
    "translated_abstract": "对现有的解释方法能否真实阐明模型决策过程的真实性提出了质疑。现有方法偏离了对模型的忠实表达，因此容易受到对抗性攻击的影响。为了解决这个问题，我们提出了一种新颖的可解释性人工智能(XAI)方法，称为SRD(共享比例分解)，它真实地反映了模型的推理过程，从而显著提高了解释的鲁棒性。与传统的神经元级别强调不同，我们采用向量视角来考虑滤波器之间复杂的非线性交互。我们还引入了一个有趣的观察，称为仅激活模式预测(APOP)，让我们强调非活跃神经元的重要性，并重新定义相关性，包括活跃和非活跃神经元的所有相关信息。我们的方法SRD允许递归分解一个点特征向量(PFV)。",
    "tldr": "本论文提出了一种称为共享比例分解(SRD)的新颖解释方法，真实地反映了模型的推理过程，并在解释方面显著提高了鲁棒性。通过采用向量视角和考虑滤波器之间的复杂非线性交互，以及引入仅激活模式预测(APOP)方法，可以重新定义相关性并强调非活跃神经元的重要性。"
}