{
    "title": "Investigating Cultural Alignment of Large Language Models",
    "abstract": "arXiv:2402.13231v1 Announce Type: new  Abstract: The intricate relationship between language and culture has long been a subject of exploration within the realm of linguistic anthropology. Large Language Models (LLMs), promoted as repositories of collective human knowledge, raise a pivotal question: do these models genuinely encapsulate the diverse knowledge adopted by different cultures? Our study reveals that these models demonstrate greater cultural alignment along two dimensions -- firstly, when prompted with the dominant language of a specific culture, and secondly, when pretrained with a refined mixture of languages employed by that culture. We quantify cultural alignment by simulating sociological surveys, comparing model responses to those of actual survey participants as references. Specifically, we replicate a survey conducted in various regions of Egypt and the United States through prompting LLMs with different pretraining data mixtures in both Arabic and English with the p",
    "link": "https://arxiv.org/abs/2402.13231",
    "context": "Title: Investigating Cultural Alignment of Large Language Models\nAbstract: arXiv:2402.13231v1 Announce Type: new  Abstract: The intricate relationship between language and culture has long been a subject of exploration within the realm of linguistic anthropology. Large Language Models (LLMs), promoted as repositories of collective human knowledge, raise a pivotal question: do these models genuinely encapsulate the diverse knowledge adopted by different cultures? Our study reveals that these models demonstrate greater cultural alignment along two dimensions -- firstly, when prompted with the dominant language of a specific culture, and secondly, when pretrained with a refined mixture of languages employed by that culture. We quantify cultural alignment by simulating sociological surveys, comparing model responses to those of actual survey participants as references. Specifically, we replicate a survey conducted in various regions of Egypt and the United States through prompting LLMs with different pretraining data mixtures in both Arabic and English with the p",
    "path": "papers/24/02/2402.13231.json",
    "total_tokens": 806,
    "translated_title": "研究大型语言模型的文化整合",
    "translated_abstract": "长久以来，语言和文化之间错综复杂的关系一直是语言人类学领域探索的一个课题。被推广为集体人类知识库的大型语言模型（LLMs）提出一个关键问题：这些模型是否真正概括了不同文化所采用的多样知识？我们的研究发现，这些模型在两个维度上表现出更大的文化整合性 -- 首先，当提示使用特定文化的主导语言时，其次，当预先使用该文化采用的语言的精制混合进行预训练。我们通过模拟社会学调查来量化文化整合，将模型的响应与实际调查参与者作为参考进行比较。具体来说，我们通过将LLMs用阿拉伯语和英语以不同的预训练数据混合提示来复制在埃及和美国各地进行的调查。",
    "tldr": "研究发现大型语言模型在文化整合方面表现更佳，特别是通过与特定文化的主导语言提示或精制语言混合预训练。",
    "en_tdlr": "The study reveals that large language models demonstrate better cultural alignment, especially when prompted with the dominant language of a specific culture or pretrained with a refined mixture of languages from that culture."
}