{
    "title": "LongWanjuan: Towards Systematic Measurement for Long Text Quality",
    "abstract": "arXiv:2402.13583v1 Announce Type: new  Abstract: The quality of training data are crucial for enhancing the long-text capabilities of foundation models. Despite existing efforts to refine data quality through heuristic rules and evaluations based on data diversity and difficulty, there's a lack of systematic approaches specifically tailored for assessing long texts. Addressing this gap, our work systematically measures the quality of long texts by evaluating three fundamental linguistic dimensions: coherence, cohesion, and complexity. Drawing inspiration from the aforementioned three dimensions, we introduce a suite of metrics designed to evaluate the quality of long texts, encompassing both statistical and pre-trained language model-based ones. Leveraging these metrics, we present LongWanjuan, a bilingual dataset specifically tailored to enhance the training of language models for long-text tasks with over 160B tokens. In LongWanjuan, we categorize long texts into holistic, aggregated",
    "link": "https://arxiv.org/abs/2402.13583",
    "context": "Title: LongWanjuan: Towards Systematic Measurement for Long Text Quality\nAbstract: arXiv:2402.13583v1 Announce Type: new  Abstract: The quality of training data are crucial for enhancing the long-text capabilities of foundation models. Despite existing efforts to refine data quality through heuristic rules and evaluations based on data diversity and difficulty, there's a lack of systematic approaches specifically tailored for assessing long texts. Addressing this gap, our work systematically measures the quality of long texts by evaluating three fundamental linguistic dimensions: coherence, cohesion, and complexity. Drawing inspiration from the aforementioned three dimensions, we introduce a suite of metrics designed to evaluate the quality of long texts, encompassing both statistical and pre-trained language model-based ones. Leveraging these metrics, we present LongWanjuan, a bilingual dataset specifically tailored to enhance the training of language models for long-text tasks with over 160B tokens. In LongWanjuan, we categorize long texts into holistic, aggregated",
    "path": "papers/24/02/2402.13583.json",
    "total_tokens": 881,
    "translated_title": "LongWanjuan: 面向长文本质量的系统化衡量方法",
    "translated_abstract": "训练数据的质量对于增强基础模型的长文本能力至关重要。尽管通过启发式规则和基于数据多样性和难度的评估来提高数据质量的现有努力，但缺乏专门针对长文本评估的系统化方法。本研究针对这一差距，通过评估三个基本语言学维度（连贯性、凝聚力和复杂性）系统性衡量长文本的质量。受到这三个维度的启发，我们引入了一套旨在评估长文本质量的指标，包括统计和基于预训练语言模型的指标。利用这些指标，我们提出了LongWanjuan，这是一个专门设计用于增强语言模型长文本任务训练的双语数据集，包含超过1600亿标记。在LongWanjuan中，我们将长文本分类为整体性、汇总",
    "tldr": "本研究针对长文本评估的差距，引入了一套基于连贯性、凝聚力和复杂性等语言学维度的指标来系统性衡量长文本的质量，并提出了LongWanjuan数据集，有助于提升长文本任务的语言模型训练。"
}