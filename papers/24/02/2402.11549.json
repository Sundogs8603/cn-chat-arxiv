{
    "title": "Syntactic Language Change in English and German: Metrics, Parsers, and Convergences",
    "abstract": "arXiv:2402.11549v1 Announce Type: cross  Abstract: Many studies have shown that human languages tend to optimize for lower complexity and increased communication efficiency. Syntactic dependency distance, which measures the linear distance between dependent words, is often considered a key indicator of language processing difficulty and working memory load. The current paper looks at diachronic trends in syntactic language change in both English and German, using corpora of parliamentary debates from the last c. 160 years. We base our observations on five dependency parsers, including the widely used Stanford CoreNLP as well as 4 newer alternatives. Our analysis of syntactic language change goes beyond linear dependency distance and explores 15 metrics relevant to dependency distance minimization (DDM) and/or based on tree graph properties, such as the tree height and degree variance. Even though we have evidence that recent parsers trained on modern treebanks are not heavily affected ",
    "link": "https://arxiv.org/abs/2402.11549",
    "context": "Title: Syntactic Language Change in English and German: Metrics, Parsers, and Convergences\nAbstract: arXiv:2402.11549v1 Announce Type: cross  Abstract: Many studies have shown that human languages tend to optimize for lower complexity and increased communication efficiency. Syntactic dependency distance, which measures the linear distance between dependent words, is often considered a key indicator of language processing difficulty and working memory load. The current paper looks at diachronic trends in syntactic language change in both English and German, using corpora of parliamentary debates from the last c. 160 years. We base our observations on five dependency parsers, including the widely used Stanford CoreNLP as well as 4 newer alternatives. Our analysis of syntactic language change goes beyond linear dependency distance and explores 15 metrics relevant to dependency distance minimization (DDM) and/or based on tree graph properties, such as the tree height and degree variance. Even though we have evidence that recent parsers trained on modern treebanks are not heavily affected ",
    "path": "papers/24/02/2402.11549.json",
    "total_tokens": 914,
    "translated_title": "英语和德语的句法语言变化：度量、解析器和趋同",
    "translated_abstract": "许多研究表明，人类语言往往会优化语言结构以降低复杂性，增加交流效率。句法依存距离衡量了相关词汇之间的线性距离，通常被认为是语言处理困难和工作记忆负荷的关键指标。本文研究了英语和德语句法语言变化的历时趋势，使用了过去大约160年间的议会辩论语料库。我们基于5个依存句法解析器的观察结果，包括广泛使用的Stanford CoreNLP以及其他4个更新的替代方案。我们的句法语言变化分析超越了线性依存距离，探讨了与依存距离最小化（DDM）相关的15个度量标准，或者基于树图属性，比如树高和度变异。尽管我们有证据表明，最近基于现代树库训练的解析器并未受到重大影响。",
    "tldr": "本文研究英语和德语句法语言变化趋势，使用议会辩论语料库，探讨了句法依存距离最小化及基于树图属性的15个度量标准，揭示了现代解析器在这种变化中的影响。"
}