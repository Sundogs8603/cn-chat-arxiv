{
    "title": "REALM: RAG-Driven Enhancement of Multimodal Electronic Health Records Analysis via Large Language Models",
    "abstract": "The integration of multimodal Electronic Health Records (EHR) data has significantly improved clinical predictive capabilities. Leveraging clinical notes and multivariate time-series EHR, existing models often lack the medical context relevent to clinical tasks, prompting the incorporation of external knowledge, particularly from the knowledge graph (KG). Previous approaches with KG knowledge have primarily focused on structured knowledge extraction, neglecting unstructured data modalities and semantic high dimensional medical knowledge. In response, we propose REALM, a Retrieval-Augmented Generation (RAG) driven framework to enhance multimodal EHR representations that address these limitations. Firstly, we apply Large Language Model (LLM) to encode long context clinical notes and GRU model to encode time-series EHR data. Secondly, we prompt LLM to extract task-relevant medical entities and match entities in professionally labeled external knowledge graph (PrimeKG) with corresponding m",
    "link": "https://arxiv.org/abs/2402.07016",
    "context": "Title: REALM: RAG-Driven Enhancement of Multimodal Electronic Health Records Analysis via Large Language Models\nAbstract: The integration of multimodal Electronic Health Records (EHR) data has significantly improved clinical predictive capabilities. Leveraging clinical notes and multivariate time-series EHR, existing models often lack the medical context relevent to clinical tasks, prompting the incorporation of external knowledge, particularly from the knowledge graph (KG). Previous approaches with KG knowledge have primarily focused on structured knowledge extraction, neglecting unstructured data modalities and semantic high dimensional medical knowledge. In response, we propose REALM, a Retrieval-Augmented Generation (RAG) driven framework to enhance multimodal EHR representations that address these limitations. Firstly, we apply Large Language Model (LLM) to encode long context clinical notes and GRU model to encode time-series EHR data. Secondly, we prompt LLM to extract task-relevant medical entities and match entities in professionally labeled external knowledge graph (PrimeKG) with corresponding m",
    "path": "papers/24/02/2402.07016.json",
    "total_tokens": 806,
    "translated_title": "REALM:通过大型语言模型对多模态电子健康记录分析的增强推理",
    "translated_abstract": "多模态电子健康记录（EHR）数据的整合显著提高了临床预测能力。然而，现有模型在利用临床笔记和多变量时间序列EHR时往往缺乏与临床任务相关的医疗背景。为了解决这个问题，我们提出了REALM框架，通过检索增强生成（RAG）驱动来增强多模态EHR表征，进而解决这些限制。该框架首先应用大型语言模型（LLM）编码长上下文临床笔记，并应用GRU模型编码时间序列EHR数据；其次，我们指导LLM提取与任务相关的医学实体，并将实体与专业标注的外部知识图（PrimeKG）中的相应实体匹配。",
    "tldr": "REALM是一个通过大型语言模型和检索增强生成驱动的框架，用于增强多模态电子健康记录（EHR）的表征，以提高临床预测能力。",
    "en_tdlr": "REALM is a framework driven by large language models and retrieval-augmented generation (RAG) to enhance representations of multimodal Electronic Health Records (EHRs) and improve clinical predictive capabilities."
}