{
    "title": "SpeechCLIP+: Self-supervised multi-task representation learning for speech via CLIP and speech-image data",
    "abstract": "The recently proposed visually grounded speech model SpeechCLIP is an innovative framework that bridges speech and text through images via CLIP without relying on text transcription. On this basis, this paper introduces two extensions to SpeechCLIP. First, we apply the Continuous Integrate-and-Fire (CIF) module to replace a fixed number of CLS tokens in the cascaded architecture. Second, we propose a new hybrid architecture that merges the cascaded and parallel architectures of SpeechCLIP into a multi-task learning framework. Our experimental evaluation is performed on the Flickr8k and SpokenCOCO datasets. The results show that in the speech keyword extraction task, the CIF-based cascaded SpeechCLIP model outperforms the previous cascaded SpeechCLIP model using a fixed number of CLS tokens. Furthermore, through our hybrid architecture, cascaded task learning boosts the performance of the parallel branch in image-speech retrieval tasks.",
    "link": "https://arxiv.org/abs/2402.06959",
    "context": "Title: SpeechCLIP+: Self-supervised multi-task representation learning for speech via CLIP and speech-image data\nAbstract: The recently proposed visually grounded speech model SpeechCLIP is an innovative framework that bridges speech and text through images via CLIP without relying on text transcription. On this basis, this paper introduces two extensions to SpeechCLIP. First, we apply the Continuous Integrate-and-Fire (CIF) module to replace a fixed number of CLS tokens in the cascaded architecture. Second, we propose a new hybrid architecture that merges the cascaded and parallel architectures of SpeechCLIP into a multi-task learning framework. Our experimental evaluation is performed on the Flickr8k and SpokenCOCO datasets. The results show that in the speech keyword extraction task, the CIF-based cascaded SpeechCLIP model outperforms the previous cascaded SpeechCLIP model using a fixed number of CLS tokens. Furthermore, through our hybrid architecture, cascaded task learning boosts the performance of the parallel branch in image-speech retrieval tasks.",
    "path": "papers/24/02/2402.06959.json",
    "total_tokens": 858,
    "translated_title": "SpeechCLIP+: 基于CLIP和语音-图像数据的自监督多任务表示学习的语音模型",
    "translated_abstract": "最近提出的视觉化语音模型SpeechCLIP是一个创新的框架，通过CLIP将语音和文本与图像相连接，而无需依赖于文本转录。在此基础上，本文介绍了两个对SpeechCLIP的扩展。首先，我们应用了连续积分-放电（CIF）模块，用于替换级联架构中的固定数量的CLS令牌。其次，我们提出了一种新的混合架构，将SpeechCLIP的级联架构和并行架构合并为一个多任务学习框架。我们在Flickr8k和SpokenCOCO数据集上进行了实验评估。结果表明，在语音关键词提取任务中，基于CIF的级联SpeechCLIP模型表现优于之前使用固定数量CLS令牌的级联SpeechCLIP模型。此外，通过我们的混合架构，级联任务学习提升了图像-语音检索任务中并行分支的性能。",
    "tldr": "SpeechCLIP+通过应用CIF模块替换CLIP架构中的CLS令牌，并提出了一种混合架构，实现了在语音关键词提取和图像-语音检索任务中的性能提升。"
}