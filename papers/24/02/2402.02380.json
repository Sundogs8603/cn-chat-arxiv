{
    "title": "Evaluating Large Language Models in Analysing Classroom Dialogue",
    "abstract": "This study explores the application of Large Language Models (LLMs), specifically GPT-4, in the analysis of classroom dialogue, a crucial research task for both teaching diagnosis and quality improvement. Recognizing the knowledge-intensive and labor-intensive nature of traditional qualitative methods in educational research, this study investigates the potential of LLM to streamline and enhance the analysis process. The study involves datasets from a middle school, encompassing classroom dialogues across mathematics and Chinese classes. These dialogues were manually coded by educational experts and then analyzed using a customised GPT-4 model. This study focuses on comparing manual annotations with the outputs of GPT-4 to evaluate its efficacy in analyzing educational dialogues. Time efficiency, inter-coder agreement, and inter-coder reliability between human coders and GPT-4 are evaluated. Results indicate substantial time savings with GPT-4, and a high degree of consistency in codin",
    "link": "https://arxiv.org/abs/2402.02380",
    "context": "Title: Evaluating Large Language Models in Analysing Classroom Dialogue\nAbstract: This study explores the application of Large Language Models (LLMs), specifically GPT-4, in the analysis of classroom dialogue, a crucial research task for both teaching diagnosis and quality improvement. Recognizing the knowledge-intensive and labor-intensive nature of traditional qualitative methods in educational research, this study investigates the potential of LLM to streamline and enhance the analysis process. The study involves datasets from a middle school, encompassing classroom dialogues across mathematics and Chinese classes. These dialogues were manually coded by educational experts and then analyzed using a customised GPT-4 model. This study focuses on comparing manual annotations with the outputs of GPT-4 to evaluate its efficacy in analyzing educational dialogues. Time efficiency, inter-coder agreement, and inter-coder reliability between human coders and GPT-4 are evaluated. Results indicate substantial time savings with GPT-4, and a high degree of consistency in codin",
    "path": "papers/24/02/2402.02380.json",
    "total_tokens": 882,
    "translated_title": "在分析课堂对话时评估大型语言模型",
    "translated_abstract": "本研究探讨了大型语言模型（LLM），特别是GPT-4，在分析课堂对话中的应用，这是教学诊断和质量改进的重要研究任务。鉴于传统教育研究中知识密集和劳动密集的定性方法，本研究调查了LLM在优化和增强分析过程方面的潜力。该研究涉及中学的数据集，包括数学和语文课堂上的对话。这些对话由教育专家手动编码，然后使用定制的GPT-4模型进行分析。本研究侧重于比较手动注释与GPT-4的输出，以评估其在分析教育对话方面的效果。评估时间效率、编码者间一致性和编码者间可靠性之间的差异。结果表明，使用GPT-4可以显著节省时间，并在编码一致性方面具有很高的一致性。",
    "tldr": "本研究评估了大型语言模型（LLMs），特点是GPT-4，对课堂对话进行分析的应用。结果显示，GPT-4能够显著节省时间，且在编码一致性方面表现出很高的一致性。"
}