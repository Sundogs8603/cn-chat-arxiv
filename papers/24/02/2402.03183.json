{
    "title": "Predicting Configuration Performance in Multiple Environments with Sequential Meta-learning",
    "abstract": "Learning and predicting the performance of given software configurations are of high importance to many software engineering activities. While configurable software systems will almost certainly face diverse running environments (e.g., version, hardware, and workload), current work often either builds performance models under a single environment or fails to properly handle data from diverse settings, hence restricting their accuracy for new environments. In this paper, we target configuration performance learning under multiple environments. We do so by designing SeMPL - a meta-learning framework that learns the common understanding from configurations measured in distinct (meta) environments and generalizes them to the unforeseen, target environment. What makes it unique is that unlike common meta-learning frameworks (e.g., MAML and MetaSGD) that train the meta environments in parallel, we train them sequentially, one at a time. The order of training naturally allows discriminating t",
    "link": "https://arxiv.org/abs/2402.03183",
    "context": "Title: Predicting Configuration Performance in Multiple Environments with Sequential Meta-learning\nAbstract: Learning and predicting the performance of given software configurations are of high importance to many software engineering activities. While configurable software systems will almost certainly face diverse running environments (e.g., version, hardware, and workload), current work often either builds performance models under a single environment or fails to properly handle data from diverse settings, hence restricting their accuracy for new environments. In this paper, we target configuration performance learning under multiple environments. We do so by designing SeMPL - a meta-learning framework that learns the common understanding from configurations measured in distinct (meta) environments and generalizes them to the unforeseen, target environment. What makes it unique is that unlike common meta-learning frameworks (e.g., MAML and MetaSGD) that train the meta environments in parallel, we train them sequentially, one at a time. The order of training naturally allows discriminating t",
    "path": "papers/24/02/2402.03183.json",
    "total_tokens": 818,
    "translated_title": "用顺序元学习预测多个环境下的配置性能",
    "translated_abstract": "学习和预测给定软件配置的性能对许多软件工程活动非常重要。当前的工作通常在单个环境下构建性能模型或未能正确处理来自不同环境的数据，从而限制了对新环境的准确性。本文针对多个环境下的配置性能学习，设计了SeMPL - 一种元学习框架，它从不同(meta)环境中测量的配置中学习共同的理解，并将它们推广到未知的目标环境中。其独特之处在于，与常见的元学习框架（如MAML和MetaSGD）并行训练元环境不同，我们依次顺序训练它们。训练顺序自然地允许区分",
    "tldr": "本论文提出了一个顺序元学习框架SeMPL，可以在多个环境下学习和预测给定软件配置的性能。与现有方法不同的是，SeMPL通过依次顺序训练元环境，实现了更准确的对新环境的性能预测。"
}