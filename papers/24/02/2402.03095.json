{
    "title": "Transcending Adversarial Perturbations: Manifold-Aided Adversarial Examples with Legitimate Semantics",
    "abstract": "Deep neural networks were significantly vulnerable to adversarial examples manipulated by malicious tiny perturbations. Although most conventional adversarial attacks ensured the visual imperceptibility between adversarial examples and corresponding raw images by minimizing their geometric distance, these constraints on geometric distance led to limited attack transferability, inferior visual quality, and human-imperceptible interpretability. In this paper, we proposed a supervised semantic-transformation generative model to generate adversarial examples with real and legitimate semantics, wherein an unrestricted adversarial manifold containing continuous semantic variations was constructed for the first time to realize a legitimate transition from non-adversarial examples to adversarial ones. Comprehensive experiments on MNIST and industrial defect datasets showed that our adversarial examples not only exhibited better visual quality but also achieved superior attack transferability a",
    "link": "https://arxiv.org/abs/2402.03095",
    "context": "Title: Transcending Adversarial Perturbations: Manifold-Aided Adversarial Examples with Legitimate Semantics\nAbstract: Deep neural networks were significantly vulnerable to adversarial examples manipulated by malicious tiny perturbations. Although most conventional adversarial attacks ensured the visual imperceptibility between adversarial examples and corresponding raw images by minimizing their geometric distance, these constraints on geometric distance led to limited attack transferability, inferior visual quality, and human-imperceptible interpretability. In this paper, we proposed a supervised semantic-transformation generative model to generate adversarial examples with real and legitimate semantics, wherein an unrestricted adversarial manifold containing continuous semantic variations was constructed for the first time to realize a legitimate transition from non-adversarial examples to adversarial ones. Comprehensive experiments on MNIST and industrial defect datasets showed that our adversarial examples not only exhibited better visual quality but also achieved superior attack transferability a",
    "path": "papers/24/02/2402.03095.json",
    "total_tokens": 880,
    "translated_title": "超越对抗性扰动：通过合法语义的流形辅助对抗性样本",
    "translated_abstract": "深度神经网络对恶意微小扰动操纵的对抗性样本相当脆弱。尽管大多数传统对抗性攻击通过最小化对抗性样本和原始图像之间的几何距离来确保其视觉上的不可察觉性，但是这种几何距离的约束导致了有限的攻击可迁移性、较差的视觉质量和人类不可察觉的可解释性。本文提出了一个监督语义转换生成模型，用于生成具有真实和合法语义的对抗性样本，其中首次构建了一个不受限制的对抗性流形，其中包含连续的语义变化，实现了从非对抗性样本到对抗性样本的合法过渡。在MNIST和工业缺陷数据集上的综合实验表明，我们的对抗性样本不仅具有更好的视觉质量，而且具有更高的攻击可迁移性。",
    "tldr": "本文提出一种基于流形辅助的生成模型，能够生成具有真实和合法语义的对抗样本。实验结果表明，这些对抗样本不仅具有更好的视觉质量，而且能够实现更高的攻击可迁移性。",
    "en_tdlr": "This paper proposes a generative model aided by manifolds to generate adversarial examples with real and legitimate semantics. The experiments show that these adversarial examples not only have better visual quality but also achieve higher attack transferability."
}