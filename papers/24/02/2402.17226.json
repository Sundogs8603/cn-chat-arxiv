{
    "title": "Reasoning in Conversation: Solving Subjective Tasks through Dialogue Simulation for Large Language Models",
    "abstract": "arXiv:2402.17226v1 Announce Type: new  Abstract: Large Language Models (LLMs) have achieved remarkable performance in objective tasks such as open-domain question answering and mathematical reasoning, which can often be solved through recalling learned factual knowledge or chain-of-thought style reasoning. However, we find that the performance of LLMs in subjective tasks is still unsatisfactory, such as metaphor recognition, dark humor detection, etc. Compared to objective tasks, subjective tasks focus more on interpretation or emotional response rather than a universally accepted reasoning pathway. Based on the characteristics of the tasks and the strong dialogue-generation capabilities of LLMs, we propose RiC (Reasoning in Conversation), a method that focuses on solving subjective tasks through dialogue simulation. The motivation of RiC is to mine useful contextual information by simulating dialogues instead of supplying chain-of-thought style rationales, thereby offering potential u",
    "link": "https://arxiv.org/abs/2402.17226",
    "context": "Title: Reasoning in Conversation: Solving Subjective Tasks through Dialogue Simulation for Large Language Models\nAbstract: arXiv:2402.17226v1 Announce Type: new  Abstract: Large Language Models (LLMs) have achieved remarkable performance in objective tasks such as open-domain question answering and mathematical reasoning, which can often be solved through recalling learned factual knowledge or chain-of-thought style reasoning. However, we find that the performance of LLMs in subjective tasks is still unsatisfactory, such as metaphor recognition, dark humor detection, etc. Compared to objective tasks, subjective tasks focus more on interpretation or emotional response rather than a universally accepted reasoning pathway. Based on the characteristics of the tasks and the strong dialogue-generation capabilities of LLMs, we propose RiC (Reasoning in Conversation), a method that focuses on solving subjective tasks through dialogue simulation. The motivation of RiC is to mine useful contextual information by simulating dialogues instead of supplying chain-of-thought style rationales, thereby offering potential u",
    "path": "papers/24/02/2402.17226.json",
    "total_tokens": 832,
    "translated_title": "对话推理：通过对话模拟解决大型语言模型中的主观任务",
    "translated_abstract": "大型语言模型（LLMs）在客观任务中取得了显著的表现，比如开放域问答和数学推理，这些任务通常可以通过回忆学到的事实知识或思维链路式推理来解决。然而，我们发现LLMs在主观任务中的表现仍然令人不满，比如隐喻识别、黑暗幽默检测等。与客观任务相比，主观任务更注重解释或情感反应，而不是一个普遍接受的推理路径。基于任务特性和LLMs强大的对话生成能力，我们提出了RiC（对话推理），这是一种通过对话模拟解决主观任务的方法。RiC的动机是通过模拟对话来挖掘有用的上下文信息，而不是提供思维链路式的理由，从而提供潜在的",
    "tldr": "提出了RiC（对话推理）方法，旨在通过对话模拟解决大型语言模型中的主观任务，通过挖掘有用的上下文信息来填补客观推理方式的不足",
    "en_tdlr": "Introduced RiC (Reasoning in Conversation) method to address subjective tasks in large language models by simulating dialogues to mine useful contextual information, bridging the gap left by objective reasoning approaches."
}