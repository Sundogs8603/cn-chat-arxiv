{
    "title": "RAG-Driver: Generalisable Driving Explanations with Retrieval-Augmented In-Context Learning in Multi-Modal Large Language Model",
    "abstract": "arXiv:2402.10828v1 Announce Type: cross  Abstract: Robots powered by 'blackbox' models need to provide human-understandable explanations which we can trust. Hence, explainability plays a critical role in trustworthy autonomous decision-making to foster transparency and acceptance among end users, especially in complex autonomous driving. Recent advancements in Multi-Modal Large Language models (MLLMs) have shown promising potential in enhancing the explainability as a driving agent by producing control predictions along with natural language explanations. However, severe data scarcity due to expensive annotation costs and significant domain gaps between different datasets makes the development of a robust and generalisable system an extremely challenging task. Moreover, the prohibitively expensive training requirements of MLLM and the unsolved problem of catastrophic forgetting further limit their generalisability post-deployment. To address these challenges, we present RAG-Driver, a n",
    "link": "https://arxiv.org/abs/2402.10828",
    "context": "Title: RAG-Driver: Generalisable Driving Explanations with Retrieval-Augmented In-Context Learning in Multi-Modal Large Language Model\nAbstract: arXiv:2402.10828v1 Announce Type: cross  Abstract: Robots powered by 'blackbox' models need to provide human-understandable explanations which we can trust. Hence, explainability plays a critical role in trustworthy autonomous decision-making to foster transparency and acceptance among end users, especially in complex autonomous driving. Recent advancements in Multi-Modal Large Language models (MLLMs) have shown promising potential in enhancing the explainability as a driving agent by producing control predictions along with natural language explanations. However, severe data scarcity due to expensive annotation costs and significant domain gaps between different datasets makes the development of a robust and generalisable system an extremely challenging task. Moreover, the prohibitively expensive training requirements of MLLM and the unsolved problem of catastrophic forgetting further limit their generalisability post-deployment. To address these challenges, we present RAG-Driver, a n",
    "path": "papers/24/02/2402.10828.json",
    "total_tokens": 915,
    "translated_title": "RAG-Driver：在多模态大语言模型中通过检索增强上下文学习实现可泛化的驾驶解释",
    "translated_abstract": "由“黑匣子”模型驱动的机器人需要提供人类可信赖的可理解解释。因此，可解释性在可信任的自主决策中扮演着关键角色，以促进透明度和最终用户的接受度，特别是在复杂的自动驾驶场景中。最近多模态大语言模型（MLLMs）的进展显示出了增强解释性作为驾驶代理的潜力，通过产生控制预测以及自然语言解释。然而，由于昂贵的注释成本和不同数据集之间的显著领域差异，导致的严重数据稀缺使得开发一个强大且具有通用性的系统变得异常具有挑战性。此外，MLLM的训练要求昂贵，而灾难性遗忘问题的尚未解决也限制了它们在部署后的泛化能力。为了解决这些挑战，我们提出了RAG-Driver。",
    "tldr": "RAG-Driver 提出了一种适用于自动驾驶的通用化驾驶解释系统，通过检索增强上下文学习，解决了多模态大语言模型训练成本高、数据稀缺和泛化能力限制等问题。"
}