{
    "title": "How Paralingual are Paralinguistic Representations? A Case Study in Speech Emotion Recognition",
    "abstract": "Pre-trained Models (PTMs) have facilitated substantial progress in the field of Speech Emotion Recognition (SER). SER is an area with applications ranging from HumanComputer Interaction to Healthcare. Recent studies have leveraged various PTM representations as input features for downstream models for SER. PTM specifically pre-trained for paralinguistic tasks have obtained state-of-the-art (SOTA) performance for SER. However, such PTM haven't been evaluated for SER in multilingual settings and experimented only with English. So, we fill this gap, by performing a comprehensive comparative study of five PTMs (TRILLsson, wav2vec2, XLS-R, x-vector, Whisper) for assessing the effectiveness of paralingual PTM (TRILLsson) for SER across multiple languages. Representations from TRILLsson achieved the best performance among all the PTMs. This demonstrates that TRILLsson is able to effectively capture the various paralinguistic features from speech data for better SER. We also show that downstre",
    "link": "https://rss.arxiv.org/abs/2402.01579",
    "context": "Title: How Paralingual are Paralinguistic Representations? A Case Study in Speech Emotion Recognition\nAbstract: Pre-trained Models (PTMs) have facilitated substantial progress in the field of Speech Emotion Recognition (SER). SER is an area with applications ranging from HumanComputer Interaction to Healthcare. Recent studies have leveraged various PTM representations as input features for downstream models for SER. PTM specifically pre-trained for paralinguistic tasks have obtained state-of-the-art (SOTA) performance for SER. However, such PTM haven't been evaluated for SER in multilingual settings and experimented only with English. So, we fill this gap, by performing a comprehensive comparative study of five PTMs (TRILLsson, wav2vec2, XLS-R, x-vector, Whisper) for assessing the effectiveness of paralingual PTM (TRILLsson) for SER across multiple languages. Representations from TRILLsson achieved the best performance among all the PTMs. This demonstrates that TRILLsson is able to effectively capture the various paralinguistic features from speech data for better SER. We also show that downstre",
    "path": "papers/24/02/2402.01579.json",
    "total_tokens": 913,
    "translated_title": "多重语言环境下语音情感识别的跨语言预训练模型研究",
    "translated_abstract": "预训练模型（PTM）在语音情感识别（SER）领域取得了巨大进展。最近的研究利用各种PTM表示作为SER下游模型的输入特征。针对社交语言任务进行预训练的PTM在SER领域取得了最先进的性能。然而，这些PTM还没有在多语言环境下进行SER评估，且只涉及英语。因此，我们通过对五种PTM（TRILLsson、wav2vec2、XLS-R、x-vector、Whisper）进行全面比较研究，评估社交语言PTM（TRILLsson）在多种语言情境下对SER的效果。TRILLsson的表示在所有PTM中达到了最佳表现。这表明TRILLsson能够有效捕捉语音数据中的各种社交语言特征，从而提供更好的SER。",
    "tldr": "本研究通过比较研究五种预训练模型，评估了针对社交语言任务进行预训练的模型在多语言情境下对语音情感识别的效果。结果表明，TRILLsson模型能够有效地捕捉语音数据中的社交语言特征，提升了语音情感识别的性能。"
}