{
    "title": "D-Nikud: Enhancing Hebrew Diacritization with LSTM and Pretrained Models",
    "abstract": "D-Nikud, a novel approach to Hebrew diacritization that integrates the strengths of LSTM networks and BERT-based (transformer) pre-trained model. Inspired by the methodologies employed in Nakdimon, we integrate it with the TavBERT pre-trained model, our system incorporates advanced architectural choices and diverse training data. Our experiments showcase state-of-the-art results on several benchmark datasets, with a particular emphasis on modern texts and more specified diacritization like gender.",
    "link": "https://arxiv.org/abs/2402.00075",
    "context": "Title: D-Nikud: Enhancing Hebrew Diacritization with LSTM and Pretrained Models\nAbstract: D-Nikud, a novel approach to Hebrew diacritization that integrates the strengths of LSTM networks and BERT-based (transformer) pre-trained model. Inspired by the methodologies employed in Nakdimon, we integrate it with the TavBERT pre-trained model, our system incorporates advanced architectural choices and diverse training data. Our experiments showcase state-of-the-art results on several benchmark datasets, with a particular emphasis on modern texts and more specified diacritization like gender.",
    "path": "papers/24/02/2402.00075.json",
    "total_tokens": 639,
    "translated_title": "D-Nikud: 使用LSTM和预训练模型增强希伯来语的点音化",
    "translated_abstract": "D-Nikud是一种新颖的希伯来语点音化方法，它将LSTM网络和基于BERT的预训练模型的优势相结合。受Nakdimon方法的启发，我们将其与TavBERT预训练模型结合起来，系统中采用了先进的架构选择和多样化的训练数据。我们的实验在多个基准数据集上展示了最先进的结果，特别强调现代文本和更详细的点音化，如性别。",
    "tldr": "D-Nikud是一种新颖的希伯来语点音化方法，通过结合LSTM和BERT-based预训练模型，实现了最先进的结果，并且在现代文本和更详细的点音化方面表现出色。"
}