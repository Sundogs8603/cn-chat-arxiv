{
    "title": "Meta-Tasks: An alternative view on Meta-Learning Regularization",
    "abstract": "arXiv:2402.18599v1 Announce Type: cross  Abstract: Few-shot learning (FSL) is a challenging machine learning problem due to a scarcity of labeled data. The ability to generalize effectively on both novel and training tasks is a significant barrier to FSL. This paper proposes a novel solution that can generalize to both training and novel tasks while also utilizing unlabeled samples. The method refines the embedding model before updating the outer loop using unsupervised techniques as ``meta-tasks''. The experimental results show that our proposed method performs well on novel and training tasks, with faster and better convergence, lower generalization, and standard deviation error, indicating its potential for practical applications in FSL. The experimental results show that the proposed method outperforms prototypical networks by 3.9%.",
    "link": "https://arxiv.org/abs/2402.18599",
    "context": "Title: Meta-Tasks: An alternative view on Meta-Learning Regularization\nAbstract: arXiv:2402.18599v1 Announce Type: cross  Abstract: Few-shot learning (FSL) is a challenging machine learning problem due to a scarcity of labeled data. The ability to generalize effectively on both novel and training tasks is a significant barrier to FSL. This paper proposes a novel solution that can generalize to both training and novel tasks while also utilizing unlabeled samples. The method refines the embedding model before updating the outer loop using unsupervised techniques as ``meta-tasks''. The experimental results show that our proposed method performs well on novel and training tasks, with faster and better convergence, lower generalization, and standard deviation error, indicating its potential for practical applications in FSL. The experimental results show that the proposed method outperforms prototypical networks by 3.9%.",
    "path": "papers/24/02/2402.18599.json",
    "total_tokens": 803,
    "translated_title": "Meta-Tasks: 元学习正则化的另一种视角",
    "translated_abstract": "Few-shot learning (FSL)是一个具有挑战性的机器学习问题，因为标记数据稀缺。这篇论文提出了一种新颖的解决方案，可以泛化到训练和新颖的任务，同时利用未标记样本。该方法在更新外层循环之前，使用无监督技术对嵌入模型进行了细化，将其作为“元任务”。实验结果表明，我们提出的方法在新颖和训练任务上表现良好，收敛更快、更好，泛化误差和标准差更低，表明其在FSL中的实际应用潜力。实验结果表明，所提出的方法的表现比原型网络高出3.9%。",
    "tldr": "该论文提出了一种新颖的解决方案，通过使用meta-tasks作为元学习正则化的视角，实现了对训练和新颖任务的泛化，避免标记数据稀缺的困扰，并在实验中表现优越，相较于原型网络提高了3.9%的性能。",
    "en_tdlr": "This paper proposes a novel solution that achieves generalization to both training and novel tasks using meta-tasks as an alternative view on meta-learning regularization, avoiding the issue of scarce labeled data, and performs superiorly in experiments, surpassing prototypical networks by 3.9%."
}