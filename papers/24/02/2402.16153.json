{
    "title": "ChatMusician: Understanding and Generating Music Intrinsically with LLM",
    "abstract": "arXiv:2402.16153v1 Announce Type: cross  Abstract: While Large Language Models (LLMs) demonstrate impressive capabilities in text generation, we find that their ability has yet to be generalized to music, humanity's creative language. We introduce ChatMusician, an open-source LLM that integrates intrinsic musical abilities. It is based on continual pre-training and finetuning LLaMA2 on a text-compatible music representation, ABC notation, and the music is treated as a second language. ChatMusician can understand and generate music with a pure text tokenizer without any external multi-modal neural structures or tokenizers. Interestingly, endowing musical abilities does not harm language abilities, even achieving a slightly higher MMLU score. Our model is capable of composing well-structured, full-length music, conditioned on texts, chords, melodies, motifs, musical forms, etc, surpassing GPT-4 baseline. On our meticulously curated college-level music understanding benchmark, MusicTheory",
    "link": "https://arxiv.org/abs/2402.16153",
    "context": "Title: ChatMusician: Understanding and Generating Music Intrinsically with LLM\nAbstract: arXiv:2402.16153v1 Announce Type: cross  Abstract: While Large Language Models (LLMs) demonstrate impressive capabilities in text generation, we find that their ability has yet to be generalized to music, humanity's creative language. We introduce ChatMusician, an open-source LLM that integrates intrinsic musical abilities. It is based on continual pre-training and finetuning LLaMA2 on a text-compatible music representation, ABC notation, and the music is treated as a second language. ChatMusician can understand and generate music with a pure text tokenizer without any external multi-modal neural structures or tokenizers. Interestingly, endowing musical abilities does not harm language abilities, even achieving a slightly higher MMLU score. Our model is capable of composing well-structured, full-length music, conditioned on texts, chords, melodies, motifs, musical forms, etc, surpassing GPT-4 baseline. On our meticulously curated college-level music understanding benchmark, MusicTheory",
    "path": "papers/24/02/2402.16153.json",
    "total_tokens": 900,
    "translated_title": "ChatMusician：理解和生成具有LLM的音乐内在",
    "translated_abstract": "虽然大型语言模型（LLMs）在文本生成方面展现出令人印象深刻的能力，但我们发现它们的能力尚未推广到音乐，也就是人类的创造性语言。我们介绍了ChatMusician，这是一个开源的LLM，集成了内在的音乐能力。它基于对文本兼容的音乐表示法ABC记谱的持续预训练和微调LLaMA2，并且将音乐视为第二语言。ChatMusician可以使用纯文本标记器理解和生成音乐，而无需任何外部多模态神经结构或标记器。有趣的是，赋予音乐能力并不会损害语言能力，甚至可以达到略高的MMLU分数。我们的模型能够根据文本、和弦、旋律、主题、音乐形式等创作结构良好、完整长度的音乐，超越了GPT-4的基线。在我们精心策划的大学级音乐理解基准上，MusicTheory",
    "tldr": "ChatMusician 是一个集成了内在音乐能力的开源LLM，通过对文本兼容的音乐表示法进行持续预训练和微调，能够理解和生成音乐，表现优于GPT-4基准模型。"
}