{
    "title": "AutoPRM: Automating Procedural Supervision for Multi-Step Reasoning via Controllable Question Decomposition",
    "abstract": "arXiv:2402.11452v1 Announce Type: new  Abstract: Recent advancements in large language models (LLMs) have shown promise in multi-step reasoning tasks, yet their reliance on extensive manual labeling to provide procedural feedback remains a significant impediment. To address this challenge, in this paper, we propose a novel self-supervised framework AutoPRM that efficiently enhances the fine-tuning of LLMs for intricate reasoning challenges. Specifically, AutoPRM first decomposes complex problems into more manageable subquestions with a controllable granularity switch, then sequentially apply reinforcement learning to iteratively improve the subquestion solver. Additionally, we propose context-guided-decoding to avoid reward tampering and guide the subquestion solver towards the solution of the holistic problem. Extensive experiments show that AutoPRM significantly improves performance on mathematical and commonsense reasoning tasks over SOTA. More encouragingly, AutoPRM can be easily i",
    "link": "https://arxiv.org/abs/2402.11452",
    "context": "Title: AutoPRM: Automating Procedural Supervision for Multi-Step Reasoning via Controllable Question Decomposition\nAbstract: arXiv:2402.11452v1 Announce Type: new  Abstract: Recent advancements in large language models (LLMs) have shown promise in multi-step reasoning tasks, yet their reliance on extensive manual labeling to provide procedural feedback remains a significant impediment. To address this challenge, in this paper, we propose a novel self-supervised framework AutoPRM that efficiently enhances the fine-tuning of LLMs for intricate reasoning challenges. Specifically, AutoPRM first decomposes complex problems into more manageable subquestions with a controllable granularity switch, then sequentially apply reinforcement learning to iteratively improve the subquestion solver. Additionally, we propose context-guided-decoding to avoid reward tampering and guide the subquestion solver towards the solution of the holistic problem. Extensive experiments show that AutoPRM significantly improves performance on mathematical and commonsense reasoning tasks over SOTA. More encouragingly, AutoPRM can be easily i",
    "path": "papers/24/02/2402.11452.json",
    "total_tokens": 855,
    "translated_title": "AutoPRM: 通过可控问题分解自动化多步推理的过程监督",
    "translated_abstract": "大型语言模型（LLMs）的最新进展显示了在多步推理任务中的潜力，然而，它们对广泛的手动标注来提供程序反馈的依赖仍然是一个重大障碍。为了解决这一挑战，在本文中，我们提出了一种新颖的自监督框架AutoPRM，它有效地增强了LLMs对复杂推理挑战的微调。具体而言，AutoPRM首先通过可控粒度开关将复杂问题分解成更易管理的子问题，然后顺序应用强化学习来迭代改进子问题解决器。此外，我们提出了上下文引导解码来避免奖励篡改并引导子问题解决器朝向整体问题的解决方案。大量实验证明，AutoPRM在数学和常识推理任务上显著提高了性能，超过了SOTA。更令人鼓舞的是，AutoPRM可以轻松实现",
    "tldr": "提出了一种名为AutoPRM的自监督框架，通过可控问题分解和强化学习实现对复杂推理挑战的自动化监督和改进",
    "en_tdlr": "Introduced AutoPRM, a self-supervised framework that automates supervision and improvement for complex reasoning challenges through controllable question decomposition and reinforcement learning."
}