{
    "title": "Prompt-Based Bias Calibration for Better Zero/Few-Shot Learning of Language Models",
    "abstract": "arXiv:2402.10353v1 Announce Type: new  Abstract: Prompt learning is susceptible to intrinsic bias present in pre-trained language models (LMs), resulting in sub-optimal performance of prompt-based zero/few-shot learning. In this work, we propose a null-input prompting method to calibrate intrinsic bias encoded in pre-trained LMs. Different from prior efforts that address intrinsic bias primarily for social fairness and often involve excessive computational cost, our objective is to explore enhancing LMs' performance in downstream zero/few-shot learning while emphasizing the efficiency of intrinsic bias calibration. Specifically, we leverage a diverse set of auto-selected null-meaning inputs generated from GPT-4 to prompt pre-trained LMs for intrinsic bias probing. Utilizing the bias-reflected probability distribution, we formulate a distribution disparity loss for bias calibration, where we exclusively update bias parameters ($0.1\\%$ of total parameters) of LMs towards equal probabilit",
    "link": "https://arxiv.org/abs/2402.10353",
    "context": "Title: Prompt-Based Bias Calibration for Better Zero/Few-Shot Learning of Language Models\nAbstract: arXiv:2402.10353v1 Announce Type: new  Abstract: Prompt learning is susceptible to intrinsic bias present in pre-trained language models (LMs), resulting in sub-optimal performance of prompt-based zero/few-shot learning. In this work, we propose a null-input prompting method to calibrate intrinsic bias encoded in pre-trained LMs. Different from prior efforts that address intrinsic bias primarily for social fairness and often involve excessive computational cost, our objective is to explore enhancing LMs' performance in downstream zero/few-shot learning while emphasizing the efficiency of intrinsic bias calibration. Specifically, we leverage a diverse set of auto-selected null-meaning inputs generated from GPT-4 to prompt pre-trained LMs for intrinsic bias probing. Utilizing the bias-reflected probability distribution, we formulate a distribution disparity loss for bias calibration, where we exclusively update bias parameters ($0.1\\%$ of total parameters) of LMs towards equal probabilit",
    "path": "papers/24/02/2402.10353.json",
    "total_tokens": 862,
    "translated_title": "提升基于提示的语言模型零/少样本学习的偏差校准策略",
    "translated_abstract": "提示学习容易受到预训练语言模型中固有偏差的影响，导致基于提示的零/少样本学习性能不佳。本文提出了一种空输入提示方法，用于校准预训练语言模型中编码的固有偏差。与以往主要致力于社会公平的固有偏差修正方法不同，我们的目标是在增强语言模型在下游零/少样本学习任务中的性能的同时，强调固有偏差校准的效率。具体来说，我们利用从GPT-4生成的一组自动选取的无意义输入来提示预训练语言模型以探测固有偏差。利用偏差反映的概率分布，我们提出了一个分布差异损失用于偏差校准，其中我们仅更新语言模型的偏差参数（总参数的0.1%）以朝向相等的概率分布。",
    "tldr": "本研究提出了一种空输入提示方法，用于校准预训练语言模型中的固有偏差，从而提升零/少样本学习的性能。",
    "en_tdlr": "This study introduces a null-input prompting method to calibrate intrinsic bias in pre-trained language models, improving the performance of zero/few-shot learning."
}