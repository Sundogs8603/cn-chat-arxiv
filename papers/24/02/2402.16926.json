{
    "title": "On the (In)feasibility of ML Backdoor Detection as an Hypothesis Testing Problem",
    "abstract": "arXiv:2402.16926v1 Announce Type: cross  Abstract: We introduce a formal statistical definition for the problem of backdoor detection in machine learning systems and use it to analyze the feasibility of such problems, providing evidence for the utility and applicability of our definition. The main contributions of this work are an impossibility result and an achievability result for backdoor detection. We show a no-free-lunch theorem, proving that universal (adversary-unaware) backdoor detection is impossible, except for very small alphabet sizes. Thus, we argue, that backdoor detection methods need to be either explicitly, or implicitly adversary-aware. However, our work does not imply that backdoor detection cannot work in specific scenarios, as evidenced by successful backdoor detection methods in the scientific literature. Furthermore, we connect our definition to the probably approximately correct (PAC) learnability of the out-of-distribution detection problem.",
    "link": "https://arxiv.org/abs/2402.16926",
    "context": "Title: On the (In)feasibility of ML Backdoor Detection as an Hypothesis Testing Problem\nAbstract: arXiv:2402.16926v1 Announce Type: cross  Abstract: We introduce a formal statistical definition for the problem of backdoor detection in machine learning systems and use it to analyze the feasibility of such problems, providing evidence for the utility and applicability of our definition. The main contributions of this work are an impossibility result and an achievability result for backdoor detection. We show a no-free-lunch theorem, proving that universal (adversary-unaware) backdoor detection is impossible, except for very small alphabet sizes. Thus, we argue, that backdoor detection methods need to be either explicitly, or implicitly adversary-aware. However, our work does not imply that backdoor detection cannot work in specific scenarios, as evidenced by successful backdoor detection methods in the scientific literature. Furthermore, we connect our definition to the probably approximately correct (PAC) learnability of the out-of-distribution detection problem.",
    "path": "papers/24/02/2402.16926.json",
    "total_tokens": 870,
    "translated_title": "机器学习后门检测的可行性问题作为假设检验问题的探讨",
    "translated_abstract": "我们提出了一种正式的统计学定义，用于分析机器学习系统中的后门检测问题的可行性，并使用它来分析这些问题的可行性，提供了对我们定义的实用性和适用性的证据。这项工作的主要贡献是对后门检测的不可能性结果和可实现性结果。我们展示了一个没有免费午餐定理，证明了通用（对敌方不知情）后门检测是不可能的，除非Alphabet大小非常小。因此，我们认为，后门检测方法需要明确地或隐式地考虑敌对因素。然而，我们的工作并不意味着后门检测在特定场景下不能起作用，因为科学文献中成功的后门检测方法证明了这一点。此外，我们将我们的定义与大概近似正确（PAC）学习与外分布检测问题联系起来。",
    "tldr": "提出了机器学习系统中后门检测问题的正式统计定义，并得出了后门检测的不可能性与可实现性结果，指出了通用后门检测的局限性，强调后门检测方法需要考虑敌对因素。",
    "en_tdlr": "This paper introduces a formal statistical definition for backdoor detection in machine learning systems, presents results on its infeasibility and achievability, shows the limitations of universal backdoor detection, and emphasizes the importance of considering adversary factors in backdoor detection methods."
}