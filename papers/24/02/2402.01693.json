{
    "title": "Quality of Answers of Generative Large Language Models vs Peer Patients for Interpreting Lab Test Results for Lay Patients: Evaluation Study",
    "abstract": "Lab results are often confusing and hard to understand. Large language models (LLMs) such as ChatGPT have opened a promising avenue for patients to get their questions answered. We aim to assess the feasibility of using LLMs to generate relevant, accurate, helpful, and unharmful responses to lab test-related questions asked by patients and to identify potential issues that can be mitigated with augmentation approaches. We first collected lab test results related question and answer data from Yahoo! Answers and selected 53 QA pairs for this study. Using the LangChain framework and ChatGPT web portal, we generated responses to the 53 questions from four LLMs including GPT-4, Meta LLaMA 2, MedAlpaca, and ORCA_mini. We first assessed the similarity of their answers using standard QA similarity-based evaluation metrics including ROUGE, BLEU, METEOR, BERTScore. We also utilized an LLM-based evaluator to judge whether a target model has higher quality in terms of relevance, correctness, helpf",
    "link": "https://arxiv.org/abs/2402.01693",
    "context": "Title: Quality of Answers of Generative Large Language Models vs Peer Patients for Interpreting Lab Test Results for Lay Patients: Evaluation Study\nAbstract: Lab results are often confusing and hard to understand. Large language models (LLMs) such as ChatGPT have opened a promising avenue for patients to get their questions answered. We aim to assess the feasibility of using LLMs to generate relevant, accurate, helpful, and unharmful responses to lab test-related questions asked by patients and to identify potential issues that can be mitigated with augmentation approaches. We first collected lab test results related question and answer data from Yahoo! Answers and selected 53 QA pairs for this study. Using the LangChain framework and ChatGPT web portal, we generated responses to the 53 questions from four LLMs including GPT-4, Meta LLaMA 2, MedAlpaca, and ORCA_mini. We first assessed the similarity of their answers using standard QA similarity-based evaluation metrics including ROUGE, BLEU, METEOR, BERTScore. We also utilized an LLM-based evaluator to judge whether a target model has higher quality in terms of relevance, correctness, helpf",
    "path": "papers/24/02/2402.01693.json",
    "total_tokens": 1021,
    "translated_title": "大型语言生成模型与人类患者相比，对非专业患者解释实验室测试结果的回答质量的评估研究",
    "translated_abstract": "实验室检测结果常常令人困惑和难以理解。大型语言生成模型（LLMs），如ChatGPT，为患者提供了获取问题答案的有前景的途径。我们的目标是评估使用LLMs回答患者有关实验室测试问题的相关、准确、有帮助并且无害的回答的可行性，以及识别可以通过增强方法来缓解的潜在问题。我们首先从Yahoo! Answers收集了与实验室测试结果相关的问题和答案数据，并选择了53个问答对进行本研究。使用LangChain框架和ChatGPT互联网门户，我们从四个LLMs（包括GPT-4、Meta LLaMA 2、MedAlpaca和ORCA_mini）生成了对这53个问题的回答。我们首先使用标准的问答相似度评估指标（包括ROUGE、BLEU、METEOR和BERTScore）评估了它们回答的相似性。我们还利用基于LLMs的评估器判断目标模型在相关性、正确性和有帮助性方面的质量是否更高。",
    "tldr": "本研究评估了使用大型语言生成模型（LLMs）与人类患者相比，解答非专业患者关于实验室测试结果的问题的回答质量。评估结果表明LLMs在相关性、正确性和有帮助性方面具有一定潜力，但还存在潜在问题需要改进。",
    "en_tdlr": "This study evaluates the quality of answers provided by generative large language models (LLMs) compared to peer patients in interpreting lab test results for lay patients. The results suggest that LLMs have potential in terms of relevance, correctness, and helpfulness, but there are still potential issues that need to be addressed."
}