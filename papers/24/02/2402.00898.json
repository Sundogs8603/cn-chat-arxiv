{
    "title": "An Early Categorization of Prompt Injection Attacks on Large Language Models",
    "abstract": "Large language models and AI chatbots have been at the forefront of democratizing artificial intelligence. However, the releases of ChatGPT and other similar tools have been followed by growing concerns regarding the difficulty of controlling large language models and their outputs. Currently, we are witnessing a cat-and-mouse game where users attempt to misuse the models with a novel attack called prompt injections. In contrast, the developers attempt to discover the vulnerabilities and block the attacks simultaneously. In this paper, we provide an overview of these emergent threats and present a categorization of prompt injections, which can guide future research on prompt injections and act as a checklist of vulnerabilities in the development of LLM interfaces. Moreover, based on previous literature and our own empirical research, we discuss the implications of prompt injections to LLM end users, developers, and researchers.",
    "link": "https://rss.arxiv.org/abs/2402.00898",
    "context": "Title: An Early Categorization of Prompt Injection Attacks on Large Language Models\nAbstract: Large language models and AI chatbots have been at the forefront of democratizing artificial intelligence. However, the releases of ChatGPT and other similar tools have been followed by growing concerns regarding the difficulty of controlling large language models and their outputs. Currently, we are witnessing a cat-and-mouse game where users attempt to misuse the models with a novel attack called prompt injections. In contrast, the developers attempt to discover the vulnerabilities and block the attacks simultaneously. In this paper, we provide an overview of these emergent threats and present a categorization of prompt injections, which can guide future research on prompt injections and act as a checklist of vulnerabilities in the development of LLM interfaces. Moreover, based on previous literature and our own empirical research, we discuss the implications of prompt injections to LLM end users, developers, and researchers.",
    "path": "papers/24/02/2402.00898.json",
    "total_tokens": 804,
    "translated_title": "大规模语言模型上的提示注入攻击的早期分类",
    "translated_abstract": "大规模语言模型和AI聊天机器人一直是民主化人工智能的前沿。然而，ChatGPT和其他类似工具的发布后，人们对于控制大规模语言模型及其输出的难度越来越担忧。目前，我们正在目睹一场捉迷藏的游戏，用户试图利用这些模型进行一种称为提示注入的新型攻击，而开发人员则试图同时发现漏洞并阻止这些攻击。在本文中，我们概述了这些新兴威胁，并提出了提示注入的分类，这可以指导未来在提示注入上的研究，并作为LLM界面开发中漏洞的检查清单。此外，基于先前的文献和我们自己的实证研究，我们讨论了提示注入对LLM最终用户、开发人员和研究人员的影响。",
    "tldr": "本文旨在提供对大规模语言模型上的提示注入攻击的早期分类，并讨论了这些攻击对LLM最终用户、开发人员和研究人员的影响。",
    "en_tdlr": "This paper provides an early categorization of prompt injection attacks on large language models and discusses the implications of these attacks on LLM end users, developers, and researchers."
}