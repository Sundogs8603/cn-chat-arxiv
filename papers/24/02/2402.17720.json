{
    "title": "The SMART approach to instance-optimal online learning",
    "abstract": "arXiv:2402.17720v1 Announce Type: new  Abstract: We devise an online learning algorithm -- titled Switching via Monotone Adapted Regret Traces (SMART) -- that adapts to the data and achieves regret that is instance optimal, i.e., simultaneously competitive on every input sequence compared to the performance of the follow-the-leader (FTL) policy and the worst case guarantee of any other input policy. We show that the regret of the SMART policy on any input sequence is within a multiplicative factor $e/(e-1) \\approx 1.58$ of the smaller of: 1) the regret obtained by FTL on the sequence, and 2) the upper bound on regret guaranteed by the given worst-case policy. This implies a strictly stronger guarantee than typical `best-of-both-worlds' bounds as the guarantee holds for every input sequence regardless of how it is generated. SMART is simple to implement as it begins by playing FTL and switches at most once during the time horizon to the worst-case algorithm. Our approach and results fol",
    "link": "https://arxiv.org/abs/2402.17720",
    "context": "Title: The SMART approach to instance-optimal online learning\nAbstract: arXiv:2402.17720v1 Announce Type: new  Abstract: We devise an online learning algorithm -- titled Switching via Monotone Adapted Regret Traces (SMART) -- that adapts to the data and achieves regret that is instance optimal, i.e., simultaneously competitive on every input sequence compared to the performance of the follow-the-leader (FTL) policy and the worst case guarantee of any other input policy. We show that the regret of the SMART policy on any input sequence is within a multiplicative factor $e/(e-1) \\approx 1.58$ of the smaller of: 1) the regret obtained by FTL on the sequence, and 2) the upper bound on regret guaranteed by the given worst-case policy. This implies a strictly stronger guarantee than typical `best-of-both-worlds' bounds as the guarantee holds for every input sequence regardless of how it is generated. SMART is simple to implement as it begins by playing FTL and switches at most once during the time horizon to the worst-case algorithm. Our approach and results fol",
    "path": "papers/24/02/2402.17720.json",
    "total_tokens": 903,
    "translated_title": "SMART算法在实例最优在线学习中的应用",
    "translated_abstract": "我们设计了一种在线学习算法 - Switching via Monotone Adapted Regret Traces (SMART) - 该算法能够适应数据并实现实例最优的遗憾，即相对于随机跟随者（FTL）策略的性能以及任何其他输入策略的最坏情况保证而言，在每个输入序列上具有竞争力。我们证明了SMART策略对任何输入序列的遗憾都在一个倍乘因子$e/(e-1) \\approx 1.58$之内，这个倍乘因子是FTL策略在该序列上获得的遗憾和由给定的最坏情况策略保证的遗憾上限中较小值的倍数。这意味着我们提供的保证比典型的“两全其美”的界限要强大，因为该保证适用于每个输入序列，无论它是如何生成的。SMART算法易于实施，因为它从FTL开始，并且在时间范围内至多切换一次到最坏情况算法。",
    "tldr": "SMART算法在实现实例最优在线学习中取得了重要突破，具有比传统“两全其美”界限更强大的保证，能够在每个输入序列上实现竞争性表现。"
}