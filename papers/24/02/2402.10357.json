{
    "title": "Efficient Sampling on Riemannian Manifolds via Langevin MCMC",
    "abstract": "arXiv:2402.10357v1 Announce Type: cross  Abstract: We study the task of efficiently sampling from a Gibbs distribution $d \\pi^* = e^{-h} d {vol}_g$ over a Riemannian manifold $M$ via (geometric) Langevin MCMC; this algorithm involves computing exponential maps in random Gaussian directions and is efficiently implementable in practice. The key to our analysis of Langevin MCMC is a bound on the discretization error of the geometric Euler-Murayama scheme, assuming $\\nabla h$ is Lipschitz and $M$ has bounded sectional curvature. Our error bound matches the error of Euclidean Euler-Murayama in terms of its stepsize dependence. Combined with a contraction guarantee for the geometric Langevin Diffusion under Kendall-Cranston coupling, we prove that the Langevin MCMC iterates lie within $\\epsilon$-Wasserstein distance of $\\pi^*$ after $\\tilde{O}(\\epsilon^{-2})$ steps, which matches the iteration complexity for Euclidean Langevin MCMC. Our results apply in general settings where $h$ can be nonc",
    "link": "https://arxiv.org/abs/2402.10357",
    "context": "Title: Efficient Sampling on Riemannian Manifolds via Langevin MCMC\nAbstract: arXiv:2402.10357v1 Announce Type: cross  Abstract: We study the task of efficiently sampling from a Gibbs distribution $d \\pi^* = e^{-h} d {vol}_g$ over a Riemannian manifold $M$ via (geometric) Langevin MCMC; this algorithm involves computing exponential maps in random Gaussian directions and is efficiently implementable in practice. The key to our analysis of Langevin MCMC is a bound on the discretization error of the geometric Euler-Murayama scheme, assuming $\\nabla h$ is Lipschitz and $M$ has bounded sectional curvature. Our error bound matches the error of Euclidean Euler-Murayama in terms of its stepsize dependence. Combined with a contraction guarantee for the geometric Langevin Diffusion under Kendall-Cranston coupling, we prove that the Langevin MCMC iterates lie within $\\epsilon$-Wasserstein distance of $\\pi^*$ after $\\tilde{O}(\\epsilon^{-2})$ steps, which matches the iteration complexity for Euclidean Langevin MCMC. Our results apply in general settings where $h$ can be nonc",
    "path": "papers/24/02/2402.10357.json",
    "total_tokens": 987,
    "translated_title": "通过Langevin MCMC在黎曼流形上高效采样",
    "translated_abstract": "我们研究了通过（几何）Langevin MCMC在黎曼流形$M$上高效地从Gibbs分布$d \\pi^* = e^{-h} d {vol}_g$中采样的任务；该算法涉及在随机高斯方向上计算指数映射，在实践中可以高效实现。我们对Langevin MCMC的分析的关键在于对几何Euler-Murayama方案的离散化误差做出的界限，假设$\\nabla h$是Lipschitz的，且$M$具有有界的曲率截面。我们的误差界限与欧几里得Euler-Murayama在步长依赖性方面的误差相匹配。结合Kendall-Cranston耦合下对几何Langevin扩散的收缩保证，我们证明Langevin MCMC迭代在经过$\\tilde{O}(\\epsilon^{-2})$步后与$\\pi^*$之间的$\\epsilon$-Wasserstein距离内，这与欧几里得Langevin MCMC的迭代复杂度相匹配。我们的结果适用于一般设置，其中$h$可以是非凸的。",
    "tldr": "通过Langevin MCMC在黎曼流形上高效采样，并证明了在特定条件下迭代步数为$\\tilde{O}(\\epsilon^{-2})$时，Langevin MCMC的迭代会与目标分布在$\\epsilon$-Wasserstein距离内。",
    "en_tdlr": "Efficient sampling on Riemannian manifolds via Langevin MCMC with iteration complexity $\\tilde{O}(\\epsilon^{-2})$, ensuring iterations lie within $\\epsilon$-Wasserstein distance of the target distribution."
}