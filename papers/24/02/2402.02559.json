{
    "title": "NavHint: Vision and Language Navigation Agent with a Hint Generator",
    "abstract": "Existing work on vision and language navigation mainly relies on navigation-related losses to establish the connection between vision and language modalities, neglecting aspects of helping the navigation agent build a deep understanding of the visual environment. In our work, we provide indirect supervision to the navigation agent through a hint generator that provides detailed visual descriptions. The hint generator assists the navigation agent in developing a global understanding of the visual environment. It directs the agent's attention toward related navigation details, including the relevant sub-instruction, potential challenges in recognition and ambiguities in grounding, and the targeted viewpoint description. To train the hint generator, we construct a synthetic dataset based on landmarks in the instructions and visible and distinctive objects in the visual environment. We evaluate our method on the R2R and R4R datasets and achieve state-of-the-art on several metrics. The expe",
    "link": "https://arxiv.org/abs/2402.02559",
    "context": "Title: NavHint: Vision and Language Navigation Agent with a Hint Generator\nAbstract: Existing work on vision and language navigation mainly relies on navigation-related losses to establish the connection between vision and language modalities, neglecting aspects of helping the navigation agent build a deep understanding of the visual environment. In our work, we provide indirect supervision to the navigation agent through a hint generator that provides detailed visual descriptions. The hint generator assists the navigation agent in developing a global understanding of the visual environment. It directs the agent's attention toward related navigation details, including the relevant sub-instruction, potential challenges in recognition and ambiguities in grounding, and the targeted viewpoint description. To train the hint generator, we construct a synthetic dataset based on landmarks in the instructions and visible and distinctive objects in the visual environment. We evaluate our method on the R2R and R4R datasets and achieve state-of-the-art on several metrics. The expe",
    "path": "papers/24/02/2402.02559.json",
    "total_tokens": 866,
    "translated_title": "NavHint: 具有提示生成器的视觉和语言导航代理",
    "translated_abstract": "现有的关于视觉和语言导航的工作主要依赖于与导航相关的损失，以建立视觉和语言模态之间的连接，忽略了帮助导航代理建立对视觉环境的深入理解的方面。在我们的工作中，我们通过一个提示生成器为导航代理提供间接监督，提供详细的视觉描述。提示生成器帮助导航代理发展对视觉环境的整体理解。它引导代理注意相关的导航细节，包括相关的子指令、识别中的潜在挑战和基于地面的歧义，以及目标视点描述。为了训练提示生成器，我们基于指令中的地标和视觉环境中可见且有区别的对象构建了一个合成数据集。我们在R2R和R4R数据集上评估了我们的方法，并在几个指标上取得了最先进的成果。",
    "tldr": "本论文提出了一种名为NavHint的视觉和语言导航代理，通过一个提示生成器为导航代理提供间接监督，帮助其对视觉环境进行整体理解。该方法在R2R和R4R数据集上取得了state-of-the-art的表现。",
    "en_tdlr": "This paper proposes a vision and language navigation agent called NavHint, which utilizes a hint generator to provide indirect supervision and assist the agent in developing a global understanding of the visual environment. The method achieves state-of-the-art performance on the R2R and R4R datasets."
}