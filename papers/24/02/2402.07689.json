{
    "title": "OrderBkd: Textual backdoor attack through repositioning",
    "abstract": "The use of third-party datasets and pre-trained machine learning models poses a threat to NLP systems due to possibility of hidden backdoor attacks. Existing attacks involve poisoning the data samples such as insertion of tokens or sentence paraphrasing, which either alter the semantics of the original texts or can be detected. Our main difference from the previous work is that we use the reposition of a two words in a sentence as a trigger. By designing and applying specific part-of-speech (POS) based rules for selecting these tokens, we maintain high attack success rate on SST-2 and AG classification datasets while outperforming existing attacks in terms of perplexity and semantic similarity to the clean samples. In addition, we show the robustness of our attack to the ONION defense method. All the code and data for the paper can be obtained at https://github.com/alekseevskaia/OrderBkd.",
    "link": "https://arxiv.org/abs/2402.07689",
    "context": "Title: OrderBkd: Textual backdoor attack through repositioning\nAbstract: The use of third-party datasets and pre-trained machine learning models poses a threat to NLP systems due to possibility of hidden backdoor attacks. Existing attacks involve poisoning the data samples such as insertion of tokens or sentence paraphrasing, which either alter the semantics of the original texts or can be detected. Our main difference from the previous work is that we use the reposition of a two words in a sentence as a trigger. By designing and applying specific part-of-speech (POS) based rules for selecting these tokens, we maintain high attack success rate on SST-2 and AG classification datasets while outperforming existing attacks in terms of perplexity and semantic similarity to the clean samples. In addition, we show the robustness of our attack to the ONION defense method. All the code and data for the paper can be obtained at https://github.com/alekseevskaia/OrderBkd.",
    "path": "papers/24/02/2402.07689.json",
    "total_tokens": 863,
    "translated_title": "OrderBkd: 通过重新定位进行的文本后门攻击",
    "translated_abstract": "使用第三方数据集和预训练的机器学习模型对NLP系统构成威胁，可能隐藏后门攻击。现有的攻击方式包括插入标记或句子重述等污染数据样本，这要么改变了原始文本的语义，要么可以被检测出来。我们与以往工作的主要区别在于，我们使用重新定位句子中的两个单词作为触发器。通过设计并应用基于词性的规则来选择这些标记，我们在SST-2和AG分类数据集上保持了高攻击成功率，同时在困惑度和与干净样本的语义相似性方面优于现有攻击方法。此外，我们展示了我们的攻击对ONION防御方法的鲁棒性。论文中的所有代码和数据可在https://github.com/alekseevskaia/OrderBkd获取。",
    "tldr": "本论文提出了一种通过重新定位句子中的两个单词实施文本后门攻击的方法，与已有的攻击方式相比，在攻击成功率、困惑度和与干净样本的语义相似性方面表现更好，并且对ONION防御方法具有鲁棒性。",
    "en_tdlr": "This paper proposes a method of carrying out textual backdoor attacks by repositioning two words in a sentence, which outperforms existing attacks in terms of attack success rate, perplexity, and semantic similarity to clean samples, and exhibits robustness against the ONION defense method."
}