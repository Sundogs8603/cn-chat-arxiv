{
    "title": "Enhancing Large Language Model Performance To Answer Questions and Extract Information More Accurately",
    "abstract": "Large Language Models (LLMs) generate responses to questions; however, their effectiveness is often hindered by sub-optimal quality of answers and occasional failures to provide accurate responses to questions. To address these challenges, a fine-tuning process is employed, involving feedback and examples to refine models. The objective is to enhance AI models through continuous feedback loops, utilizing metrics such as cosine similarity, LLM evaluation and Rouge-L scores to evaluate the models. Leveraging LLMs like GPT-3.5, GPT4ALL, and LLaMA2, and Claude, this approach is benchmarked on financial datasets, including the FinanceBench and RAG Instruct Benchmark Tester Dataset, illustrating the necessity of fine-tuning. The results showcase the capability of fine-tuned models to surpass the accuracy of zero-shot LLMs, providing superior question and answering capabilities. Notably, the combination of fine-tuning the LLM with a process known as Retrieval Augmented Generation (RAG) proves",
    "link": "https://arxiv.org/abs/2402.01722",
    "context": "Title: Enhancing Large Language Model Performance To Answer Questions and Extract Information More Accurately\nAbstract: Large Language Models (LLMs) generate responses to questions; however, their effectiveness is often hindered by sub-optimal quality of answers and occasional failures to provide accurate responses to questions. To address these challenges, a fine-tuning process is employed, involving feedback and examples to refine models. The objective is to enhance AI models through continuous feedback loops, utilizing metrics such as cosine similarity, LLM evaluation and Rouge-L scores to evaluate the models. Leveraging LLMs like GPT-3.5, GPT4ALL, and LLaMA2, and Claude, this approach is benchmarked on financial datasets, including the FinanceBench and RAG Instruct Benchmark Tester Dataset, illustrating the necessity of fine-tuning. The results showcase the capability of fine-tuned models to surpass the accuracy of zero-shot LLMs, providing superior question and answering capabilities. Notably, the combination of fine-tuning the LLM with a process known as Retrieval Augmented Generation (RAG) proves",
    "path": "papers/24/02/2402.01722.json",
    "total_tokens": 994,
    "translated_title": "提升大型语言模型的性能，以更准确地回答问题和提取信息",
    "translated_abstract": "大型语言模型（LLMs）生成问题的回答，然而它们的有效性常常受到答案质量的不佳和偶尔无法准确回答问题的影响。为了应对这些挑战，采用了一种精调过程，利用反馈和示例来优化模型。优化的目标是通过持续的反馈循环和利用余弦相似度、LLM评估和Rouge-L得分等指标来提升AI模型的性能。利用像GPT-3.5、GPT4ALL、LLaMA2和Claude这样的LLMs，并在包括FinanceBench和RAG Instruct Benchmark Tester Dataset在内的金融数据集上进行基准测试，展示了精调的必要性。结果表明，经过精调的模型能够超越零-shot LLMs的准确性，提供卓越的问答能力。值得注意的是，将LLM与一种名为RAG的检索增强生成过程相结合的方法证明了其有效性。",
    "tldr": "通过使用反馈和示例的精调过程，结合余弦相似度、LLM评估和Rouge-L得分等指标，可以提升大型语言模型（LLMs）在回答问题和提取信息方面的准确性。与零-shot LLMs相比，经过精调的模型展示了出色的问答能力，并且通过结合RAG过程进一步提高了其效果。",
    "en_tdlr": "By employing a fine-tuning process with feedback and examples, along with metrics like cosine similarity, LLM evaluation, and Rouge-L scores, the performance of large language models (LLMs) in answering questions and extracting information can be enhanced. Fine-tuned models surpass the accuracy of zero-shot LLMs, showcasing excellent question-answering capabilities. Furthermore, combining LLMs with the Retrieval Augmented Generation (RAG) process further improves their effectiveness."
}