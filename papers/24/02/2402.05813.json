{
    "title": "Selective Forgetting: Advancing Machine Unlearning Techniques and Evaluation in Language Models",
    "abstract": "The aim of this study is to investigate Machine Unlearning (MU), a burgeoning field focused on addressing concerns related to neural models inadvertently retaining personal or sensitive data. Here, a novel approach is introduced to achieve precise and selective forgetting within language models. Unlike previous methodologies that adopt completely opposing training objectives, this approach aims to mitigate adverse effects on language model performance, particularly in generation tasks. Furthermore, two innovative evaluation metrics are proposed: Sensitive Information Extraction Likelihood (S-EL) and Sensitive Information Memory Accuracy (S-MA), designed to gauge the effectiveness of sensitive information elimination. To reinforce the forgetting framework, an effective method for annotating sensitive scopes is presented, involving both online and offline strategies. The online selection mechanism leverages language probability scores to ensure computational efficiency, while the offline",
    "link": "https://arxiv.org/abs/2402.05813",
    "context": "Title: Selective Forgetting: Advancing Machine Unlearning Techniques and Evaluation in Language Models\nAbstract: The aim of this study is to investigate Machine Unlearning (MU), a burgeoning field focused on addressing concerns related to neural models inadvertently retaining personal or sensitive data. Here, a novel approach is introduced to achieve precise and selective forgetting within language models. Unlike previous methodologies that adopt completely opposing training objectives, this approach aims to mitigate adverse effects on language model performance, particularly in generation tasks. Furthermore, two innovative evaluation metrics are proposed: Sensitive Information Extraction Likelihood (S-EL) and Sensitive Information Memory Accuracy (S-MA), designed to gauge the effectiveness of sensitive information elimination. To reinforce the forgetting framework, an effective method for annotating sensitive scopes is presented, involving both online and offline strategies. The online selection mechanism leverages language probability scores to ensure computational efficiency, while the offline",
    "path": "papers/24/02/2402.05813.json",
    "total_tokens": 925,
    "translated_title": "选择性遗忘：推进语言模型中的机器遗忘技术和评估",
    "translated_abstract": "本研究旨在研究机器遗忘（MU），这是一个致力于解决神经模型意外保留个人或敏感数据的问题的新兴领域。在这里，引入了一种新方法，实现精确和选择性遗忘语言模型中的信息。与以往完全相反的训练目标的方法不同，这种方法旨在减轻对语言模型性能的负面影响，特别是在生成任务中。此外，提出了两个创新的评估指标：敏感信息提取可能性（S-EL）和敏感信息存储准确性（S-MA），旨在衡量敏感信息消除的有效性。为了加强遗忘框架，提出了一种有效的标注敏感范围的方法，涵盖了在线和离线策略。在线选择机制利用语言概率得分确保计算效率，而离线策略则利用基于距离的过滤器。",
    "tldr": "本研究提出了一种新方法，在语言模型中实现了精确和选择性的遗忘，以解决神经模型意外保留个人或敏感数据的问题。此外，还提出了两个创新的评估指标，旨在衡量敏感信息消除的效果。为了强化遗忘框架，还提出了一种有效的标注敏感范围的方法。",
    "en_tdlr": "This study introduces a novel method for precise and selective forgetting in language models to address the issue of inadvertently retaining personal or sensitive data. It also proposes innovative evaluation metrics to gauge the effectiveness of sensitive information elimination. Additionally, an effective method for annotating sensitive scopes is presented to reinforce the forgetting framework."
}