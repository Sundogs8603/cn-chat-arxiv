{
    "title": "Mysterious Projections: Multimodal LLMs Gain Domain-Specific Visual Capabilities Without Richer Cross-Modal Projections",
    "abstract": "arXiv:2402.16832v1 Announce Type: new  Abstract: Multimodal large language models (MLLMs) like LLaVA and GPT-4(V) enable general-purpose conversations about images with the language modality. As off-the-shelf MLLMs may have limited capabilities on images from domains like dermatology and agriculture, they must be fine-tuned to unlock domain-specific applications. The prevalent architecture of current open-source MLLMs comprises two major modules: an image-language (cross-modal) projection network and a large language model. It is desirable to understand the roles of these two modules in modeling domain-specific visual attributes to inform the design of future models and streamline the interpretability efforts on the current models. To this end, via experiments on 4 datasets and under 2 fine-tuning settings, we find that as the MLLM is fine-tuned, it indeed gains domain-specific visual capabilities, but the updates do not lead to the projection extracting relevant domain-specific visual",
    "link": "https://arxiv.org/abs/2402.16832",
    "context": "Title: Mysterious Projections: Multimodal LLMs Gain Domain-Specific Visual Capabilities Without Richer Cross-Modal Projections\nAbstract: arXiv:2402.16832v1 Announce Type: new  Abstract: Multimodal large language models (MLLMs) like LLaVA and GPT-4(V) enable general-purpose conversations about images with the language modality. As off-the-shelf MLLMs may have limited capabilities on images from domains like dermatology and agriculture, they must be fine-tuned to unlock domain-specific applications. The prevalent architecture of current open-source MLLMs comprises two major modules: an image-language (cross-modal) projection network and a large language model. It is desirable to understand the roles of these two modules in modeling domain-specific visual attributes to inform the design of future models and streamline the interpretability efforts on the current models. To this end, via experiments on 4 datasets and under 2 fine-tuning settings, we find that as the MLLM is fine-tuned, it indeed gains domain-specific visual capabilities, but the updates do not lead to the projection extracting relevant domain-specific visual",
    "path": "papers/24/02/2402.16832.json",
    "total_tokens": 763,
    "translated_title": "神秘的投影：多模态LLMs在没有更丰富的跨模态投影的情况下获得特定领域的视觉能力",
    "translated_abstract": "多模态大型语言模型（MLLMs）如LLaVA和GPT-4(V)使得可以进行关于图像的通用对话。然而，现成的MLLMs可能在诸如皮肤病学和农业等领域的图像上具有有限的能力，因此必须进行微调以解锁特定领域的应用。通过对4个数据集进行实验，在两种微调设置下，我们发现随着MLLM的微调，它确实获得了特定领域的视觉能力，但这些更新并没有导致投影提取相关的领域特定视觉属性。",
    "tldr": "MLLMs通过微调获得了特定领域的视觉能力，但投影并未提取相关的领域特定视觉属性。",
    "en_tdlr": "MLLMs gain domain-specific visual capabilities through fine-tuning, but the projection does not extract relevant domain-specific visual attributes."
}