{
    "title": "RAMP: Boosting Adversarial Robustness Against Multiple $l_p$ Perturbations",
    "abstract": "There is considerable work on improving robustness against adversarial attacks bounded by a single $l_p$ norm using adversarial training (AT). However, the multiple-norm robustness (union accuracy) of AT models is still low. We observe that simultaneously obtaining good union and clean accuracy is hard since there are tradeoffs between robustness against multiple $l_p$ perturbations, and accuracy/robustness/efficiency. By analyzing the tradeoffs from the lens of distribution shifts, we identify the key tradeoff pair among $l_p$ attacks to boost efficiency and design a logit pairing loss to improve the union accuracy. Next, we connect natural training with AT via gradient projection, to find and incorporate useful information from natural training into AT, which moderates the accuracy/robustness tradeoff. Combining our contributions, we propose a framework called \\textbf{RAMP}, to boost the robustness against multiple $l_p$ perturbations. We show \\textbf{RAMP} can be easily adapted for ",
    "link": "https://arxiv.org/abs/2402.06827",
    "context": "Title: RAMP: Boosting Adversarial Robustness Against Multiple $l_p$ Perturbations\nAbstract: There is considerable work on improving robustness against adversarial attacks bounded by a single $l_p$ norm using adversarial training (AT). However, the multiple-norm robustness (union accuracy) of AT models is still low. We observe that simultaneously obtaining good union and clean accuracy is hard since there are tradeoffs between robustness against multiple $l_p$ perturbations, and accuracy/robustness/efficiency. By analyzing the tradeoffs from the lens of distribution shifts, we identify the key tradeoff pair among $l_p$ attacks to boost efficiency and design a logit pairing loss to improve the union accuracy. Next, we connect natural training with AT via gradient projection, to find and incorporate useful information from natural training into AT, which moderates the accuracy/robustness tradeoff. Combining our contributions, we propose a framework called \\textbf{RAMP}, to boost the robustness against multiple $l_p$ perturbations. We show \\textbf{RAMP} can be easily adapted for ",
    "path": "papers/24/02/2402.06827.json",
    "total_tokens": 1077,
    "translated_title": "RAMP：增强对多个$l_p$扰动的对抗鲁棒性",
    "translated_abstract": "在提高对单个$l_p$范数受限的对抗攻击的鲁棒性方面，已经有相当多的工作在使用对抗训练（AT）进行研究。然而，AT模型的多范数鲁棒性（共同准确性）仍然较低。我们观察到，同时获得良好的共同准确性和清洁准确性是困难的，因为在多个$l_p$扰动之间存在鲁棒性、准确性/鲁棒性/效率之间的权衡。通过从分布转变的角度分析这些权衡，我们确定了$l_p$攻击之间的关键权衡对，以提高效率并设计了一个逻辑配对损失来提高共同准确性。接下来，我们通过梯度投影将自然训练与AT相连接，以从自然训练中找到并整合有用的信息到AT中，从而调和准确性/鲁棒性的权衡。结合我们的贡献，我们提出了一个名为\\textbf{RAMP}的框架，来提高对多个$l_p$扰动的鲁棒性。我们展示了\\textbf{RAMP}可以很容易地适应...",
    "tldr": "该论文提出了一种名为RAMP的框架，旨在增强对多个$l_p$扰动的对抗鲁棒性。通过分析不同$l_p$攻击之间的权衡关系，并设计逻辑配对损失来提高准确性和鲁棒性的平衡。同时，通过将自然训练与对抗训练相结合，整合有用信息以调和准确性和鲁棒性的权衡。",
    "en_tdlr": "This paper proposes a framework called RAMP to boost adversarial robustness against multiple $l_p$ perturbations. It analyzes the tradeoffs between different $l_p$ attacks and designs a logit pairing loss to improve the balance between accuracy and robustness. Additionally, it combines natural training with adversarial training to integrate useful information and moderate the tradeoff between accuracy and robustness."
}