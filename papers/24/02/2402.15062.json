{
    "title": "Gotcha! Don't trick me with unanswerable questions! Self-aligning Large Language Models for Responding to Unknown Questions",
    "abstract": "arXiv:2402.15062v1 Announce Type: new  Abstract: Despite the remarkable abilities of Large Language Models (LLMs) to answer questions, they often display a considerable level of overconfidence even when the question does not have a definitive answer. To avoid providing hallucinated answers to these unknown questions, existing studies typically investigate approaches to refusing to answer these questions. In this work, we propose a novel and scalable self-alignment method to utilize the LLM itself to enhance its response-ability to different types of unknown questions, being capable of not only refusing to answer but also providing explanation to the unanswerability of unknown questions. Specifically, the Self-Align method first employ a two-stage class-aware self-augmentation approach to generate a large amount of unknown question-response data. Then we conduct disparity-driven self-curation to select qualified data for fine-tuning the LLM itself for aligning the responses to unknown q",
    "link": "https://arxiv.org/abs/2402.15062",
    "context": "Title: Gotcha! Don't trick me with unanswerable questions! Self-aligning Large Language Models for Responding to Unknown Questions\nAbstract: arXiv:2402.15062v1 Announce Type: new  Abstract: Despite the remarkable abilities of Large Language Models (LLMs) to answer questions, they often display a considerable level of overconfidence even when the question does not have a definitive answer. To avoid providing hallucinated answers to these unknown questions, existing studies typically investigate approaches to refusing to answer these questions. In this work, we propose a novel and scalable self-alignment method to utilize the LLM itself to enhance its response-ability to different types of unknown questions, being capable of not only refusing to answer but also providing explanation to the unanswerability of unknown questions. Specifically, the Self-Align method first employ a two-stage class-aware self-augmentation approach to generate a large amount of unknown question-response data. Then we conduct disparity-driven self-curation to select qualified data for fine-tuning the LLM itself for aligning the responses to unknown q",
    "path": "papers/24/02/2402.15062.json",
    "total_tokens": 833,
    "translated_title": "别耍花招！大型语言模型自我调整以回答未知问题",
    "translated_abstract": "尽管大型语言模型（LLMs）具有出色的回答问题能力，但它们在问题没有明确答案时往往表现出相当程度的自信过度。为了避免向这些未知问题提供虚构答案，现有研究通常探讨拒绝回答这些问题的方法。在这项工作中，我们提出了一种新颖且可扩展的自我调整方法，利用LLM本身来增强其对不同类型未知问题的回应能力，不仅能够拒绝回答，还能够解释未知问题无法回答的原因。具体来说，Self-Align方法首先采用两阶段类感知自我增强方法生成大量未知问题-回应数据。然后，我们进行差异驱动的自我整理，选择合格数据对LLM本身进行微调，以调整对未知问题的响应。",
    "tldr": "提出了一种自我调整方法，利用大型语言模型增强回答未知问题的能力，包括拒绝回答并解释未知问题无法回答的原因。",
    "en_tdlr": "Proposed a self-aligning method to enhance the ability of Large Language Models in responding to unknown questions by not only refusing to answer but also providing explanation for unanswerable questions."
}