{
    "title": "Parameter Efficient Finetuning for Speech Emotion Recognition and Domain Adaptation",
    "abstract": "arXiv:2402.11747v1 Announce Type: cross  Abstract: Foundation models have shown superior performance for speech emotion recognition (SER). However, given the limited data in emotion corpora, finetuning all parameters of large pre-trained models for SER can be both resource-intensive and susceptible to overfitting. This paper investigates parameter-efficient finetuning (PEFT) for SER. Various PEFT adaptors are systematically studied for both classification of discrete emotion categories and prediction of dimensional emotional attributes. The results demonstrate that the combination of PEFT methods surpasses full finetuning with a significant reduction in the number of trainable parameters. Furthermore, a two-stage adaptation strategy is proposed to adapt models trained on acted emotion data, which is more readily available, to make the model more adept at capturing natural emotional expressions. Both intra- and cross-corpus experiments validate the efficacy of the proposed approach in e",
    "link": "https://arxiv.org/abs/2402.11747",
    "context": "Title: Parameter Efficient Finetuning for Speech Emotion Recognition and Domain Adaptation\nAbstract: arXiv:2402.11747v1 Announce Type: cross  Abstract: Foundation models have shown superior performance for speech emotion recognition (SER). However, given the limited data in emotion corpora, finetuning all parameters of large pre-trained models for SER can be both resource-intensive and susceptible to overfitting. This paper investigates parameter-efficient finetuning (PEFT) for SER. Various PEFT adaptors are systematically studied for both classification of discrete emotion categories and prediction of dimensional emotional attributes. The results demonstrate that the combination of PEFT methods surpasses full finetuning with a significant reduction in the number of trainable parameters. Furthermore, a two-stage adaptation strategy is proposed to adapt models trained on acted emotion data, which is more readily available, to make the model more adept at capturing natural emotional expressions. Both intra- and cross-corpus experiments validate the efficacy of the proposed approach in e",
    "path": "papers/24/02/2402.11747.json",
    "total_tokens": 924,
    "translated_title": "语音情绪识别和领域适应的参数高效微调",
    "translated_abstract": "基础模型在语音情绪识别（SER）方面表现出卓越的性能。然而，鉴于情绪语料库中的数据有限，对大型预训练模型的所有参数进行微调既耗费资源又容易过拟合。本文研究了用于SER的参数高效微调（PEFT）。系统研究了各种PEFT适配器，旨在对离散情绪类别的分类和情绪属性的维度预测进行研究。结果表明，PEFT方法的组合超越了具有可训练参数数量显著减少的完整微调。此外，提出了一个两阶段适应策略，以适应在场景情绪数据上训练的模型，这种数据更易获得，使模型更擅长捕捉自然情感表达。内部和跨语料库实验验证了所提方法的有效性。",
    "tldr": "本文研究了用于语音情绪识别的参数高效微调方法，提出了各种PEFT适配器并展示了其在分类离散情绪类别和预测情绪属性方面的有效性，同时通过减少可训练参数数量超越了完整微调。还提出了两阶段适应策略以提高模型对自然情感表达的捕捉能力。",
    "en_tdlr": "This paper investigates parameter-efficient finetuning for speech emotion recognition (SER), proposes various PEFT adaptors showing effectiveness in classifying discrete emotion categories and predicting emotional attributes with a significant reduction in trainable parameters compared to full finetuning. Additionally, a two-stage adaptation strategy is introduced to enhance the model's capability in capturing natural emotional expressions."
}