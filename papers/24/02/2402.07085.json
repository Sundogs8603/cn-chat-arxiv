{
    "title": "Speech Rhythm-Based Speaker Embeddings Extraction from Phonemes and Phoneme Duration for Multi-Speaker Speech Synthesis",
    "abstract": "This paper proposes a speech rhythm-based method for speaker embeddings to model phoneme duration using a few utterances by the target speaker. Speech rhythm is one of the essential factors among speaker characteristics, along with acoustic features such as F0, for reproducing individual utterances in speech synthesis. A novel feature of the proposed method is the rhythm-based embeddings extracted from phonemes and their durations, which are known to be related to speaking rhythm. They are extracted with a speaker identification model similar to the conventional spectral feature-based one. We conducted three experiments, speaker embeddings generation, speech synthesis with generated embeddings, and embedding space analysis, to evaluate the performance. The proposed method demonstrated a moderate speaker identification performance (15.2% EER), even with only phonemes and their duration information. The objective and subjective evaluation results demonstrated that the proposed method can",
    "link": "https://arxiv.org/abs/2402.07085",
    "context": "Title: Speech Rhythm-Based Speaker Embeddings Extraction from Phonemes and Phoneme Duration for Multi-Speaker Speech Synthesis\nAbstract: This paper proposes a speech rhythm-based method for speaker embeddings to model phoneme duration using a few utterances by the target speaker. Speech rhythm is one of the essential factors among speaker characteristics, along with acoustic features such as F0, for reproducing individual utterances in speech synthesis. A novel feature of the proposed method is the rhythm-based embeddings extracted from phonemes and their durations, which are known to be related to speaking rhythm. They are extracted with a speaker identification model similar to the conventional spectral feature-based one. We conducted three experiments, speaker embeddings generation, speech synthesis with generated embeddings, and embedding space analysis, to evaluate the performance. The proposed method demonstrated a moderate speaker identification performance (15.2% EER), even with only phonemes and their duration information. The objective and subjective evaluation results demonstrated that the proposed method can",
    "path": "papers/24/02/2402.07085.json",
    "total_tokens": 891,
    "translated_title": "基于语音韵律的多说话人语音合成中从音素和音素持续时间中提取说话人嵌入的方法",
    "translated_abstract": "本文提出了一种基于语音韵律的方法，用于从目标说话人的少量句子中建模音素持续时间，从而提取说话人嵌入。语音韵律是与说话人特征相关的重要因素之一，与基频等声学特征一起用于在语音合成中重现单个句子。所提出方法的一个新特点是基于韵律的嵌入，从已知与说话韵律相关的音素及其持续时间中提取，类似于传统的基于频谱特征的说话人识别模型。我们进行了三个实验，包括生成说话人嵌入、使用生成的嵌入进行语音合成以及嵌入空间分析，以评估该方法的性能。结果表明，即使只使用音素及其持续时间信息，所提出的方法也展现了较为适中的说话人识别性能（15.2% EER）。客观和主观评估结果表明，所提出的方法能够实现有效的多说话人语音合成。",
    "tldr": "本文提出了一种基于语音韵律的方法，通过从音素和音素持续时间中提取说话人嵌入，模拟目标说话人的个体发音特征。实验证明，该方法可以实现有效的多说话人语音合成。",
    "en_tdlr": "This paper proposes a speech rhythm-based method to extract speaker embeddings from phonemes and phoneme duration, achieving effective multi-speaker speech synthesis."
}