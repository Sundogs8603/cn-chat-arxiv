{
    "title": "Leveraging Approximate Model-based Shielding for Probabilistic Safety Guarantees in Continuous Environments",
    "abstract": "Shielding is a popular technique for achieving safe reinforcement learning (RL). However, classical shielding approaches come with quite restrictive assumptions making them difficult to deploy in complex environments, particularly those with continuous state or action spaces. In this paper we extend the more versatile approximate model-based shielding (AMBS) framework to the continuous setting. In particular we use Safety Gym as our test-bed, allowing for a more direct comparison of AMBS with popular constrained RL algorithms. We also provide strong probabilistic safety guarantees for the continuous setting. In addition, we propose two novel penalty techniques that directly modify the policy gradient, which empirically provide more stable convergence in our experiments.",
    "link": "https://arxiv.org/abs/2402.00816",
    "context": "Title: Leveraging Approximate Model-based Shielding for Probabilistic Safety Guarantees in Continuous Environments\nAbstract: Shielding is a popular technique for achieving safe reinforcement learning (RL). However, classical shielding approaches come with quite restrictive assumptions making them difficult to deploy in complex environments, particularly those with continuous state or action spaces. In this paper we extend the more versatile approximate model-based shielding (AMBS) framework to the continuous setting. In particular we use Safety Gym as our test-bed, allowing for a more direct comparison of AMBS with popular constrained RL algorithms. We also provide strong probabilistic safety guarantees for the continuous setting. In addition, we propose two novel penalty techniques that directly modify the policy gradient, which empirically provide more stable convergence in our experiments.",
    "path": "papers/24/02/2402.00816.json",
    "total_tokens": 768,
    "translated_title": "在连续环境中利用近似基于模型的屏蔽技术实现概率安全保证",
    "translated_abstract": "屏蔽技术是实现安全增强学习的一种流行技术。然而，传统的屏蔽方法存在相当严格的假设，使其难以在复杂环境中部署，特别是在具有连续状态或行动空间的环境中。本文将更通用的近似基于模型的屏蔽（AMBS）框架扩展到连续环境中。我们使用Safety Gym作为我们的测试平台，可以更直接地将AMBS与流行的约束强化学习算法进行比较。我们还为连续环境提供了强大的概率安全保证。此外，我们提出了两种新颖的惩罚技术，直接修改策略梯度，在我们的实验中实现了更稳定的收敛。",
    "tldr": "本文提出了在连续环境中利用近似基于模型的屏蔽技术实现概率安全保证的方法，并通过与约束强化学习算法的对比实验证明了其通用性和稳定性。",
    "en_tdlr": "This paper proposes a method to leverage approximate model-based shielding for probabilistic safety guarantees in continuous environments, and demonstrates its generality and stability through comparison with constrained reinforcement learning algorithms."
}