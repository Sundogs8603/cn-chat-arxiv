{
    "title": "Are Large Language Models Good Prompt Optimizers?",
    "abstract": "LLM-based Automatic Prompt Optimization, which typically utilizes LLMs as Prompt Optimizers to self-reflect and refine prompts, has shown promising performance in recent studies. Despite the success, the underlying mechanism of this approach remains unexplored, and the true effectiveness of LLMs as Prompt Optimizers requires further validation. In this work, we conducted a comprehensive study to uncover the actual mechanism of LLM-based Prompt Optimization. Our findings reveal that the LLM optimizers struggle to identify the true causes of errors during reflection, tending to be biased by their own prior knowledge rather than genuinely reflecting on the errors. Furthermore, even when the reflection is semantically valid, the LLM optimizers often fail to generate appropriate prompts for the target models with a single prompt refinement step, partly due to the unpredictable behaviors of the target models. Based on the observations, we introduce a new \"Automatic Behavior Optimization\" par",
    "link": "https://arxiv.org/abs/2402.02101",
    "context": "Title: Are Large Language Models Good Prompt Optimizers?\nAbstract: LLM-based Automatic Prompt Optimization, which typically utilizes LLMs as Prompt Optimizers to self-reflect and refine prompts, has shown promising performance in recent studies. Despite the success, the underlying mechanism of this approach remains unexplored, and the true effectiveness of LLMs as Prompt Optimizers requires further validation. In this work, we conducted a comprehensive study to uncover the actual mechanism of LLM-based Prompt Optimization. Our findings reveal that the LLM optimizers struggle to identify the true causes of errors during reflection, tending to be biased by their own prior knowledge rather than genuinely reflecting on the errors. Furthermore, even when the reflection is semantically valid, the LLM optimizers often fail to generate appropriate prompts for the target models with a single prompt refinement step, partly due to the unpredictable behaviors of the target models. Based on the observations, we introduce a new \"Automatic Behavior Optimization\" par",
    "path": "papers/24/02/2402.02101.json",
    "total_tokens": 884,
    "translated_title": "大型语言模型是好的提示优化器吗？",
    "translated_abstract": "近期的研究表明，以大型语言模型（LLM）作为提示优化器进行自我反馈和优化提示在性能上取得了令人期待的结果。尽管成功，但这种方法的底层机制尚未被探索，而LLM作为提示优化器的真正有效性需要进一步验证。本文进行了一项全面的研究，揭示了基于LLM的提示优化的实际机制。我们的研究发现，LLM优化器在反思过程中往往难以准确识别错误的真正原因，而更多地受到自身先前知识的偏见。此外，即使反思在语义上是有效的，LLM优化器也经常无法通过单一的优化步骤为目标模型生成合适的提示，部分原因是目标模型的行为是不可预测的。根据观察结果，我们提出了一种新的“自动行为优化”方法。",
    "tldr": "这项研究揭示了以大型语言模型（LLM）作为提示优化器的实际机制。研究发现LLM优化器往往受到自身先前知识的偏见，难以准确识别错误的真正原因，并且在生成合适的提示方面面临挑战。",
    "en_tdlr": "This study uncovers the actual mechanism of using large language models (LLMs) as prompt optimizers. The findings reveal that LLM optimizers tend to be biased by their own prior knowledge, struggle to identify the true causes of errors, and face challenges in generating appropriate prompts."
}