{
    "title": "Real-time Low-latency Music Source Separation using Hybrid Spectrogram-TasNet",
    "abstract": "arXiv:2402.17701v1 Announce Type: cross  Abstract: There have been significant advances in deep learning for music demixing in recent years. However, there has been little attention given to how these neural networks can be adapted for real-time low-latency applications, which could be helpful for hearing aids, remixing audio streams and live shows. In this paper, we investigate the various challenges involved in adapting current demixing models in the literature for this use case. Subsequently, inspired by the Hybrid Demucs architecture, we propose the Hybrid Spectrogram Time-domain Audio Separation Network HS-TasNet, which utilises the advantages of spectral and waveform domains. For a latency of 23 ms, the HS-TasNet obtains an overall signal-to-distortion ratio (SDR) of 4.65 on the MusDB test set, and increases to 5.55 with additional training data. These results demonstrate the potential of efficient demixing for real-time low-latency music applications.",
    "link": "https://arxiv.org/abs/2402.17701",
    "context": "Title: Real-time Low-latency Music Source Separation using Hybrid Spectrogram-TasNet\nAbstract: arXiv:2402.17701v1 Announce Type: cross  Abstract: There have been significant advances in deep learning for music demixing in recent years. However, there has been little attention given to how these neural networks can be adapted for real-time low-latency applications, which could be helpful for hearing aids, remixing audio streams and live shows. In this paper, we investigate the various challenges involved in adapting current demixing models in the literature for this use case. Subsequently, inspired by the Hybrid Demucs architecture, we propose the Hybrid Spectrogram Time-domain Audio Separation Network HS-TasNet, which utilises the advantages of spectral and waveform domains. For a latency of 23 ms, the HS-TasNet obtains an overall signal-to-distortion ratio (SDR) of 4.65 on the MusDB test set, and increases to 5.55 with additional training data. These results demonstrate the potential of efficient demixing for real-time low-latency music applications.",
    "path": "papers/24/02/2402.17701.json",
    "total_tokens": 882,
    "translated_title": "使用混合谱图-TasNet进行实时低延迟音乐源分离",
    "translated_abstract": "近年来，深度学习在音乐解混方面取得了显著进展。然而，对于如何调整这些神经网络以适用于实时低延迟应用几乎没有得到关注，这对助听器、混音音频流和现场表演可能很有帮助。本文研究了将当前文献中的解混模型调整为这种用例所涉及的各种挑战。随后，受混合Demucs架构启发，我们提出了混合谱图时域音频分离网络HS-TasNet，充分利用了频谱和波形域的优势。在23毫秒的延迟下，HS-TasNet在MusDB测试集上获得了4.65的总信号-失真比（SDR），并在额外的训练数据下增加到5.55。这些结果表明了实时低延迟音乐应用中高效解混的潜力。",
    "tldr": "提出了一种混合谱图时域音频分离网络（HS-TasNet），用于实现实时低延迟音乐源分离，在MusDB测试集上达到了较高的信号-失真比。",
    "en_tdlr": "Proposed a Hybrid Spectrogram Time-domain Audio Separation Network (HS-TasNet) for real-time low-latency music source separation, achieving high Signal-to-Distortion Ratio on the MusDB test set."
}