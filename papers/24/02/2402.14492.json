{
    "title": "INSTRAUG: Automatic Instruction Augmentation for Multimodal Instruction Fine-tuning",
    "abstract": "arXiv:2402.14492v1 Announce Type: cross  Abstract: Fine-tuning large language models (LLMs) on multi-task instruction-following data has been proven to be a powerful learning paradigm for improving their zero-shot capabilities on new tasks. Recent works about high-quality instruction-following data generation and selection require amounts of human labor to conceive model-understandable instructions for the given tasks and carefully filter the LLM-generated data. In this work, we introduce an automatic instruction augmentation method named INSTRAUG in multimodal tasks. It starts from a handful of basic and straightforward meta instructions but can expand an instruction-following dataset by 30 times. Results on two popular multimodal instructionfollowing benchmarks MULTIINSTRUCT and InstructBLIP show that INSTRAUG can significantly improve the alignment of multimodal large language models (MLLMs) across 12 multimodal tasks, which is even equivalent to the benefits of scaling up training ",
    "link": "https://arxiv.org/abs/2402.14492",
    "context": "Title: INSTRAUG: Automatic Instruction Augmentation for Multimodal Instruction Fine-tuning\nAbstract: arXiv:2402.14492v1 Announce Type: cross  Abstract: Fine-tuning large language models (LLMs) on multi-task instruction-following data has been proven to be a powerful learning paradigm for improving their zero-shot capabilities on new tasks. Recent works about high-quality instruction-following data generation and selection require amounts of human labor to conceive model-understandable instructions for the given tasks and carefully filter the LLM-generated data. In this work, we introduce an automatic instruction augmentation method named INSTRAUG in multimodal tasks. It starts from a handful of basic and straightforward meta instructions but can expand an instruction-following dataset by 30 times. Results on two popular multimodal instructionfollowing benchmarks MULTIINSTRUCT and InstructBLIP show that INSTRAUG can significantly improve the alignment of multimodal large language models (MLLMs) across 12 multimodal tasks, which is even equivalent to the benefits of scaling up training ",
    "path": "papers/24/02/2402.14492.json",
    "total_tokens": 839,
    "translated_title": "INSTRAUG：用于多模指令微调的自动指令增强",
    "translated_abstract": "将大型语言模型（LLMs）在多任务指令跟随数据上进行微调已被证明是一种强大的学习范式，可以提高它们对新任务的零样本能力。最近关于高质量指令跟随数据生成和选择的工作需要大量人力，以为给定任务构思模型可理解的指令，并谨慎过滤LLM生成的数据。在这项工作中，我们引入了一种名为INSTRAUG的多模任务自动指令增强方法。它从一些基本和简单的元指令开始，但能将一个指令跟随数据集扩大30倍。在两个流行的多模指令跟随基准测试集MULTIINSTRUCT和InstructBLIP上的结果显示，INSTRAUG可以显著改善跨12个多模任务的多模大型语言模型（MLLMs）的对齐，甚至相当于增加训练规模的好处。",
    "tldr": "INSTRAUG是一种自动指令增强方法，可以在多模任务中显著改善多模大型语言模型的对齐，相当于增加训练规模的好处。",
    "en_tdlr": "INSTRAUG is an automatic instruction augmentation method that can significantly improve the alignment of multimodal large language models in multimodal tasks, equivalent to the benefits of scaling up training."
}