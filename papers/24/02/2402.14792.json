{
    "title": "Consolidating Attention Features for Multi-view Image Editing",
    "abstract": "arXiv:2402.14792v1 Announce Type: cross  Abstract: Large-scale text-to-image models enable a wide range of image editing techniques, using text prompts or even spatial controls. However, applying these editing methods to multi-view images depicting a single scene leads to 3D-inconsistent results. In this work, we focus on spatial control-based geometric manipulations and introduce a method to consolidate the editing process across various views. We build on two insights: (1) maintaining consistent features throughout the generative process helps attain consistency in multi-view editing, and (2) the queries in self-attention layers significantly influence the image structure. Hence, we propose to improve the geometric consistency of the edited images by enforcing the consistency of the queries. To do so, we introduce QNeRF, a neural radiance field trained on the internal query features of the edited images. Once trained, QNeRF can render 3D-consistent queries, which are then softly inje",
    "link": "https://arxiv.org/abs/2402.14792",
    "context": "Title: Consolidating Attention Features for Multi-view Image Editing\nAbstract: arXiv:2402.14792v1 Announce Type: cross  Abstract: Large-scale text-to-image models enable a wide range of image editing techniques, using text prompts or even spatial controls. However, applying these editing methods to multi-view images depicting a single scene leads to 3D-inconsistent results. In this work, we focus on spatial control-based geometric manipulations and introduce a method to consolidate the editing process across various views. We build on two insights: (1) maintaining consistent features throughout the generative process helps attain consistency in multi-view editing, and (2) the queries in self-attention layers significantly influence the image structure. Hence, we propose to improve the geometric consistency of the edited images by enforcing the consistency of the queries. To do so, we introduce QNeRF, a neural radiance field trained on the internal query features of the edited images. Once trained, QNeRF can render 3D-consistent queries, which are then softly inje",
    "path": "papers/24/02/2402.14792.json",
    "total_tokens": 832,
    "translated_title": "合并注意力特征以进行多视图图像编辑",
    "translated_abstract": "大规模文本到图像模型实现了广泛的图像编辑技术，使用文本提示甚至空间控制。然而，将这些编辑方法应用于描绘单个场景的多视图图像会导致3D不一致的结果。本文关注基于空间控制的几何操作，并介绍了一种在各个视图上 consolitdate 编辑过程的方法。我们建立在两个观点基础上: (1) 在生成过程中保持一致的特征有助于实现多视图编辑的一致性，(2) 注意力层中的查询显著影响图像结构。因此，我们提出通过强化查询的一致性来提高编辑图像的几何一致性。为此，我们引入了 QNeRF，这是一个基于编辑图像的内部查询特征训练的神经辐射场。一旦训练完成，QNeRF 可以呈现3D一致的查询，然后在软件中进行注入",
    "tldr": "通过维护一致的特征并强化查询的一致性，我们提出了QNeRF方法，以实现多视图图像编辑的几何一致性。",
    "en_tdlr": "We propose the QNeRF method, which maintains consistent features and enforces query consistency to achieve geometric consistency in multi-view image editing."
}