{
    "title": "Lifelong Event Detection with Embedding Space Separation and Compaction",
    "abstract": "arXiv:2404.02507v1 Announce Type: new  Abstract: To mitigate forgetting, existing lifelong event detection methods typically maintain a memory module and replay the stored memory data during the learning of a new task. However, the simple combination of memory data and new-task samples can still result in substantial forgetting of previously acquired knowledge, which may occur due to the potential overlap between the feature distribution of new data and the previously learned embedding space. Moreover, the model suffers from overfitting on the few memory samples rather than effectively remembering learned patterns. To address the challenges of forgetting and overfitting, we propose a novel method based on embedding space separation and compaction. Our method alleviates forgetting of previously learned tasks by forcing the feature distribution of new data away from the previous embedding space. It also mitigates overfitting by a memory calibration mechanism that encourages memory data t",
    "link": "https://arxiv.org/abs/2404.02507",
    "context": "Title: Lifelong Event Detection with Embedding Space Separation and Compaction\nAbstract: arXiv:2404.02507v1 Announce Type: new  Abstract: To mitigate forgetting, existing lifelong event detection methods typically maintain a memory module and replay the stored memory data during the learning of a new task. However, the simple combination of memory data and new-task samples can still result in substantial forgetting of previously acquired knowledge, which may occur due to the potential overlap between the feature distribution of new data and the previously learned embedding space. Moreover, the model suffers from overfitting on the few memory samples rather than effectively remembering learned patterns. To address the challenges of forgetting and overfitting, we propose a novel method based on embedding space separation and compaction. Our method alleviates forgetting of previously learned tasks by forcing the feature distribution of new data away from the previous embedding space. It also mitigates overfitting by a memory calibration mechanism that encourages memory data t",
    "path": "papers/24/04/2404.02507.json",
    "total_tokens": 803,
    "translated_title": "具有嵌入空间分离和压缩的终身事件检测",
    "translated_abstract": "为了减轻遗忘，现有的终身事件检测方法通常维护一个记忆模块，并在学习新任务时重播存储的记忆数据。然而，记忆数据和新任务样本的简单结合仍可能导致先前获得的知识大量遗忘，这可能是由于新数据的特征分布与先前学习的嵌入空间之间的潜在重叠所导致的。此外，模型更容易对少量记忆样本过拟合，而不是有效记忆学到的模式。为了解决遗忘和过拟合的挑战，我们提出了一种基于嵌入空间分离和压缩的新方法。我们的方法通过强制新数据的特征分布远离先前的嵌入空间来减轻先前学习任务的遗忘。它还通过记忆校准机制来缓解过拟合",
    "tldr": "通过嵌入空间分离和压缩，新方法减轻了先前学习任务的遗忘，并缓解了过拟合问题",
    "en_tdlr": "The new method alleviates forgetting of previously learned tasks and mitigates overfitting through embedding space separation and compaction."
}