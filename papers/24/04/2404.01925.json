{
    "title": "Improving Bird's Eye View Semantic Segmentation by Task Decomposition",
    "abstract": "arXiv:2404.01925v1 Announce Type: cross  Abstract: Semantic segmentation in bird's eye view (BEV) plays a crucial role in autonomous driving. Previous methods usually follow an end-to-end pipeline, directly predicting the BEV segmentation map from monocular RGB inputs. However, the challenge arises when the RGB inputs and BEV targets from distinct perspectives, making the direct point-to-point predicting hard to optimize. In this paper, we decompose the original BEV segmentation task into two stages, namely BEV map reconstruction and RGB-BEV feature alignment. In the first stage, we train a BEV autoencoder to reconstruct the BEV segmentation maps given corrupted noisy latent representation, which urges the decoder to learn fundamental knowledge of typical BEV patterns. The second stage involves mapping RGB input images into the BEV latent space of the first stage, directly optimizing the correlations between the two views at the feature level. Our approach simplifies the complexity of ",
    "link": "https://arxiv.org/abs/2404.01925",
    "context": "Title: Improving Bird's Eye View Semantic Segmentation by Task Decomposition\nAbstract: arXiv:2404.01925v1 Announce Type: cross  Abstract: Semantic segmentation in bird's eye view (BEV) plays a crucial role in autonomous driving. Previous methods usually follow an end-to-end pipeline, directly predicting the BEV segmentation map from monocular RGB inputs. However, the challenge arises when the RGB inputs and BEV targets from distinct perspectives, making the direct point-to-point predicting hard to optimize. In this paper, we decompose the original BEV segmentation task into two stages, namely BEV map reconstruction and RGB-BEV feature alignment. In the first stage, we train a BEV autoencoder to reconstruct the BEV segmentation maps given corrupted noisy latent representation, which urges the decoder to learn fundamental knowledge of typical BEV patterns. The second stage involves mapping RGB input images into the BEV latent space of the first stage, directly optimizing the correlations between the two views at the feature level. Our approach simplifies the complexity of ",
    "path": "papers/24/04/2404.01925.json",
    "total_tokens": 848,
    "translated_title": "通过任务分解来改进鸟瞰视图语义分割",
    "translated_abstract": "鸟瞰视图（BEV）中的语义分割在自动驾驶中扮演着关键角色。先前的方法通常遵循端到端的流程，直接从单眼RGB输入预测BEV分割地图。然而，当RGB输入和BEV目标来自不同视角时，直接点对点预测变得难以优化。本文将原始的BEV分割任务分解为两个阶段，即BEV地图重建和RGB-BEV特征对齐。在第一阶段，我们训练一个BEV自动编码器，以给定受损噪声潜在表示的方式重建BEV分割地图，从而促使解码器学习典型BEV模式的基本知识。第二阶段涉及将RGB输入图像映射到第一阶段的BEV潜在空间中，直接优化两个视图在特征级别上的相关性。我们的方法简化了端到端方法的复杂性。",
    "tldr": "该方法通过将鸟瞰视图语义分割任务分解为BEV地图重建和RGB-BEV特征对齐两个阶段，来优化自动驾驶中的语义分割任务。",
    "en_tdlr": "This approach optimizes semantic segmentation in autonomous driving by decomposing the task into two stages: BEV map reconstruction and RGB-BEV feature alignment."
}