{
    "title": "Can LLMs Master Math? Investigating Large Language Models on Math Stack Exchange",
    "abstract": "arXiv:2404.00344v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated exceptional capabilities in various natural language tasks, often achieving performances that surpass those of humans. Despite these advancements, the domain of mathematics presents a distinctive challenge, primarily due to its specialized structure and the precision it demands. In this study, we adopted a two-step approach for investigating the proficiency of LLMs in answering mathematical questions. First, we employ the most effective LLMs, as identified by their performance on math question-answer benchmarks, to generate answers to 78 questions from the Math Stack Exchange (MSE). Second, a case analysis is conducted on the LLM that showed the highest performance, focusing on the quality and accuracy of its answers through manual evaluation. We found that GPT-4 performs best (nDCG of 0.48 and P@10 of 0.37) amongst existing LLMs fine-tuned for answering mathematics questions and outperfor",
    "link": "https://arxiv.org/abs/2404.00344",
    "context": "Title: Can LLMs Master Math? Investigating Large Language Models on Math Stack Exchange\nAbstract: arXiv:2404.00344v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated exceptional capabilities in various natural language tasks, often achieving performances that surpass those of humans. Despite these advancements, the domain of mathematics presents a distinctive challenge, primarily due to its specialized structure and the precision it demands. In this study, we adopted a two-step approach for investigating the proficiency of LLMs in answering mathematical questions. First, we employ the most effective LLMs, as identified by their performance on math question-answer benchmarks, to generate answers to 78 questions from the Math Stack Exchange (MSE). Second, a case analysis is conducted on the LLM that showed the highest performance, focusing on the quality and accuracy of its answers through manual evaluation. We found that GPT-4 performs best (nDCG of 0.48 and P@10 of 0.37) amongst existing LLMs fine-tuned for answering mathematics questions and outperfor",
    "path": "papers/24/04/2404.00344.json",
    "total_tokens": 824,
    "translated_title": "LLMs能够掌握数学吗？在数学堆栈交换上研究大型语言模型",
    "translated_abstract": "大型语言模型（LLMs）在各种自然语言任务中展示出异常能力，通常表现出超越人类的性能。尽管取得了这些进展，数学领域提出了一种独特的挑战，主要是因为其专门的结构和所需的精度。本研究采用了两步方法来调查LLMs在回答数学问题方面的熟练程度。首先，我们采用在数学问题-答案基准测试中表现最佳的LLMs来回答Math Stack Exchange（MSE）中的78个问题。其次，对表现最佳的LLM进行案例分析，重点关注其答案的质量和准确性。我们发现，在为回答数学问题进行微调的现有LLMs中，GPT-4表现最佳（nDCG为0.48，P@10为0.37），在数学问题上表现优异。",
    "tldr": "LLMs在数学领域表现出色，其中GPT-4在Math Stack Exchange上回答数学问题的表现最佳。"
}