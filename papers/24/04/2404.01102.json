{
    "title": "Diffusion based Zero-shot Medical Image-to-Image Translation for Cross Modality Segmentation",
    "abstract": "arXiv:2404.01102v1 Announce Type: cross  Abstract: Cross-modality image segmentation aims to segment the target modalities using a method designed in the source modality. Deep generative models can translate the target modality images into the source modality, thus enabling cross-modality segmentation. However, a vast body of existing cross-modality image translation methods relies on supervised learning. In this work, we aim to address the challenge of zero-shot learning-based image translation tasks (extreme scenarios in the target modality is unseen in the training phase). To leverage generative learning for zero-shot cross-modality image segmentation, we propose a novel unsupervised image translation method. The framework learns to translate the unseen source image to the target modality for image segmentation by leveraging the inherent statistical consistency between different modalities for diffusion guidance. Our framework captures identical cross-modality features in the statis",
    "link": "https://arxiv.org/abs/2404.01102",
    "context": "Title: Diffusion based Zero-shot Medical Image-to-Image Translation for Cross Modality Segmentation\nAbstract: arXiv:2404.01102v1 Announce Type: cross  Abstract: Cross-modality image segmentation aims to segment the target modalities using a method designed in the source modality. Deep generative models can translate the target modality images into the source modality, thus enabling cross-modality segmentation. However, a vast body of existing cross-modality image translation methods relies on supervised learning. In this work, we aim to address the challenge of zero-shot learning-based image translation tasks (extreme scenarios in the target modality is unseen in the training phase). To leverage generative learning for zero-shot cross-modality image segmentation, we propose a novel unsupervised image translation method. The framework learns to translate the unseen source image to the target modality for image segmentation by leveraging the inherent statistical consistency between different modalities for diffusion guidance. Our framework captures identical cross-modality features in the statis",
    "path": "papers/24/04/2404.01102.json",
    "total_tokens": 819,
    "translated_title": "基于扩散的零样本医学图像到图像翻译用于跨模态分割",
    "translated_abstract": "交叉模态图像分割旨在使用在源模态中设计的方法对目标模态进行分割。深度生成模型可以将目标模态图像转换为源模态，从而实现跨模态分割。然而，现有大量交叉模态图像翻译方法依赖于监督学习。本工作旨在解决基于零样本学习的图像翻译任务的挑战（极端情况下目标模态在训练阶段未知）。为了利用生成学习进行零样本跨模态图像分割，我们提出了一种新颖的无监督图像翻译方法。该框架通过利用不同模态之间固有的统计一致性进行扩散引导，学习将未知源图像转换为目标模态以进行图像分割。我们的框架捕捉了相同的跨模态特征...",
    "tldr": "使用扩散引导的新型无监督图像翻译方法，解决了零样本跨模态图像分割任务中的挑战",
    "en_tdlr": "A novel unsupervised image translation method using diffusion guidance addresses the challenge of zero-shot cross-modality image segmentation tasks."
}