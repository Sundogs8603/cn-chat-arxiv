{
    "title": "Your Co-Workers Matter: Evaluating Collaborative Capabilities of Language Models in Blocks World",
    "abstract": "arXiv:2404.00246v1 Announce Type: cross  Abstract: Language agents that interact with the world on their own have great potential for automating digital tasks. While large language model (LLM) agents have made progress in understanding and executing tasks such as textual games and webpage control, many real-world tasks also require collaboration with humans or other LLMs in equal roles, which involves intent understanding, task coordination, and communication. To test LLM's ability to collaborate, we design a blocks-world environment, where two agents, each having unique goals and skills, build a target structure together. To complete the goals, they can act in the world and communicate in natural language. Under this environment, we design increasingly challenging settings to evaluate different collaboration perspectives, from independent to more complex, dependent tasks. We further adopt chain-of-thought prompts that include intermediate reasoning steps to model the partner's state a",
    "link": "https://arxiv.org/abs/2404.00246",
    "context": "Title: Your Co-Workers Matter: Evaluating Collaborative Capabilities of Language Models in Blocks World\nAbstract: arXiv:2404.00246v1 Announce Type: cross  Abstract: Language agents that interact with the world on their own have great potential for automating digital tasks. While large language model (LLM) agents have made progress in understanding and executing tasks such as textual games and webpage control, many real-world tasks also require collaboration with humans or other LLMs in equal roles, which involves intent understanding, task coordination, and communication. To test LLM's ability to collaborate, we design a blocks-world environment, where two agents, each having unique goals and skills, build a target structure together. To complete the goals, they can act in the world and communicate in natural language. Under this environment, we design increasingly challenging settings to evaluate different collaboration perspectives, from independent to more complex, dependent tasks. We further adopt chain-of-thought prompts that include intermediate reasoning steps to model the partner's state a",
    "path": "papers/24/04/2404.00246.json",
    "total_tokens": 863,
    "translated_title": "你的同事很重要：评估语言模型在方块世界中的协作能力",
    "translated_abstract": "与世界自行交互的语言代理在自动化数字任务方面具有巨大潜力。虽然大型语言模型代理在理解和执行文本游戏和网页控制等任务方面取得了进展，但许多现实任务也需要与人类或其他同等角色的LLM协作，这涉及意图理解、任务协调和沟通。为测试LLM协作能力，我们设计了一个方块世界环境，在这个环境中，两个代理，每个代理都有独特的目标和技能，一起建造一个目标结构。为实现目标，他们可以在世界中行动并用自然语言进行沟通。在这个环境下，我们设计了越来越具有挑战性的设置，以评估不同协作视角，从独立的到更复杂的依赖任务。我们进一步采用了中间推理步骤来建模合作伙伴的状态。",
    "tldr": "在一个方块世界环境中，论文评估了大型语言模型的协作能力，通过设计不断增加挑战性的设置来评估不同的协作视角，从独立到更复杂的依赖任务。"
}