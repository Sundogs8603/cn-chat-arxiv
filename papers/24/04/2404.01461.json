{
    "title": "Will the Real Linda Please Stand up...to Large Language Models? Examining the Representativeness Heuristic in LLMs",
    "abstract": "arXiv:2404.01461v1 Announce Type: new  Abstract: Although large language models (LLMs) have demonstrated remarkable proficiency in understanding text and generating human-like text, they may exhibit biases acquired from training data in doing so. Specifically, LLMs may be susceptible to a common cognitive trap in human decision-making called the representativeness heuristic. This is a concept in psychology that refers to judging the likelihood of an event based on how closely it resembles a well-known prototype or typical example versus considering broader facts or statistical evidence. This work investigates the impact of the representativeness heuristic on LLM reasoning. We created REHEAT (Representativeness Heuristic AI Testing), a dataset containing a series of problems spanning six common types of representativeness heuristics. Experiments reveal that four LLMs applied to REHEAT all exhibited representativeness heuristic biases. We further identify that the model's reasoning steps",
    "link": "https://arxiv.org/abs/2404.01461",
    "context": "Title: Will the Real Linda Please Stand up...to Large Language Models? Examining the Representativeness Heuristic in LLMs\nAbstract: arXiv:2404.01461v1 Announce Type: new  Abstract: Although large language models (LLMs) have demonstrated remarkable proficiency in understanding text and generating human-like text, they may exhibit biases acquired from training data in doing so. Specifically, LLMs may be susceptible to a common cognitive trap in human decision-making called the representativeness heuristic. This is a concept in psychology that refers to judging the likelihood of an event based on how closely it resembles a well-known prototype or typical example versus considering broader facts or statistical evidence. This work investigates the impact of the representativeness heuristic on LLM reasoning. We created REHEAT (Representativeness Heuristic AI Testing), a dataset containing a series of problems spanning six common types of representativeness heuristics. Experiments reveal that four LLMs applied to REHEAT all exhibited representativeness heuristic biases. We further identify that the model's reasoning steps",
    "path": "papers/24/04/2404.01461.json",
    "total_tokens": 829,
    "translated_title": "请真正的琳达站出来...面对大语言模型？在LLMs中审视代表性启发式",
    "translated_abstract": "尽管大型语言模型（LLMs）在理解文本和生成类似人类文本方面表现出色，但它们可能会展现出从训练数据中获得的偏见。具体而言，LLMs可能会容易受到人类决策中的一种常见认知陷阱影响，即代表性启发式。这是心理学中的一个概念，指的是根据事件与一个众所周知的原型或典型例子的相似程度来判断事件发生的可能性，而不考虑更广泛的事实或统计证据。本研究调查了代表性启发式对LLM推理的影响。我们创建了REHEAT（Representativeness Heuristic AI Testing），一个包含涵盖六种常见代表性启发式类型问题的数据集。实验显示，应用于REHEAT的四个LLMs都表现出代表性启发式偏见。我们进一步确定了模型的推理步骤",
    "tldr": "该研究调查了代表性启发式对大型语言模型推理的影响，并创建了专门的数据集进行实验验证",
    "en_tdlr": "This study examines the impact of the representativeness heuristic on large language model reasoning and creates a specific dataset for experimental validation."
}