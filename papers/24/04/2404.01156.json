{
    "title": "SyncMask: Synchronized Attentional Masking for Fashion-centric Vision-Language Pretraining",
    "abstract": "arXiv:2404.01156v1 Announce Type: cross  Abstract: Vision-language models (VLMs) have made significant strides in cross-modal understanding through large-scale paired datasets. However, in fashion domain, datasets often exhibit a disparity between the information conveyed in image and text. This issue stems from datasets containing multiple images of a single fashion item all paired with one text, leading to cases where some textual details are not visible in individual images. This mismatch, particularly when non-co-occurring elements are masked, undermines the training of conventional VLM objectives like Masked Language Modeling and Masked Image Modeling, thereby hindering the model's ability to accurately align fine-grained visual and textual features. Addressing this problem, we propose Synchronized attentional Masking (SyncMask), which generate masks that pinpoint the image patches and word tokens where the information co-occur in both image and text. This synchronization is accom",
    "link": "https://arxiv.org/abs/2404.01156",
    "context": "Title: SyncMask: Synchronized Attentional Masking for Fashion-centric Vision-Language Pretraining\nAbstract: arXiv:2404.01156v1 Announce Type: cross  Abstract: Vision-language models (VLMs) have made significant strides in cross-modal understanding through large-scale paired datasets. However, in fashion domain, datasets often exhibit a disparity between the information conveyed in image and text. This issue stems from datasets containing multiple images of a single fashion item all paired with one text, leading to cases where some textual details are not visible in individual images. This mismatch, particularly when non-co-occurring elements are masked, undermines the training of conventional VLM objectives like Masked Language Modeling and Masked Image Modeling, thereby hindering the model's ability to accurately align fine-grained visual and textual features. Addressing this problem, we propose Synchronized attentional Masking (SyncMask), which generate masks that pinpoint the image patches and word tokens where the information co-occur in both image and text. This synchronization is accom",
    "path": "papers/24/04/2404.01156.json",
    "total_tokens": 678,
    "translated_title": "SyncMask：面向时尚视觉语言预训练的同步注意力遮罩",
    "translated_abstract": "视觉语言模型（VLMs）通过大规模配对数据集在跨模态理解方面取得了重要进展。然而，在时尚领域，数据集中经常存在图像和文本传达信息之间的差异。我们提出了同步注意力遮罩（SyncMask），其生成的遮罩指示了图像块和单词标记在图像和文本中同时出现的位置。",
    "tldr": "提出了同步注意力遮罩（SyncMask），用于解决时尚领域图像和文本信息不匹配的问题，可以准确对齐细粒度的视觉和文本特征。",
    "en_tdlr": "Introduced SyncMask to address the mismatch between image and text information in the fashion domain, enabling accurate alignment of fine-grained visual and textual features."
}