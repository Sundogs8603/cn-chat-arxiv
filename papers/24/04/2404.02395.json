{
    "title": "Optimal Batch Allocation for Wireless Federated Learning",
    "abstract": "arXiv:2404.02395v1 Announce Type: new  Abstract: Federated learning aims to construct a global model that fits the dataset distributed across local devices without direct access to private data, leveraging communication between a server and the local devices. In the context of a practical communication scheme, we study the completion time required to achieve a target performance. Specifically, we analyze the number of iterations required for federated learning to reach a specific optimality gap from a minimum global loss. Subsequently, we characterize the time required for each iteration under two fundamental multiple access schemes: time-division multiple access (TDMA) and random access (RA). We propose a step-wise batch allocation, demonstrated to be optimal for TDMA-based federated learning systems. Additionally, we show that the non-zero batch gap between devices provided by the proposed step-wise batch allocation significantly reduces the completion time for RA-based learning syst",
    "link": "https://arxiv.org/abs/2404.02395",
    "context": "Title: Optimal Batch Allocation for Wireless Federated Learning\nAbstract: arXiv:2404.02395v1 Announce Type: new  Abstract: Federated learning aims to construct a global model that fits the dataset distributed across local devices without direct access to private data, leveraging communication between a server and the local devices. In the context of a practical communication scheme, we study the completion time required to achieve a target performance. Specifically, we analyze the number of iterations required for federated learning to reach a specific optimality gap from a minimum global loss. Subsequently, we characterize the time required for each iteration under two fundamental multiple access schemes: time-division multiple access (TDMA) and random access (RA). We propose a step-wise batch allocation, demonstrated to be optimal for TDMA-based federated learning systems. Additionally, we show that the non-zero batch gap between devices provided by the proposed step-wise batch allocation significantly reduces the completion time for RA-based learning syst",
    "path": "papers/24/04/2404.02395.json",
    "total_tokens": 889,
    "translated_title": "无线联邦学习的最佳批量分配",
    "translated_abstract": "联邦学习旨在构建一个适合分布在本地设备上的数据集的全局模型，而无需直接访问私有数据，利用服务器与本地设备之间的通信。在实际通信方案的背景下，我们研究了实现目标性能所需的完成时间。具体来说，我们分析了需要多少次迭代才能使联邦学习达到从最小全局损失到特定最优性差距的水平。随后，我们特征化了两种基本的多用户接入方案下每次迭代所需的时间：时分多址接入（TDMA）和随机接入（RA）。我们提出了一种分步批量分配方法，证明了对于基于TDMA的联邦学习系统而言是最佳的。另外，我们展示了由提出的分步批量分配方法提供的设备之间的非零批次差距显著降低了基于RA的学习系统的完成时间",
    "tldr": "分析了在无线联邦学习中实现特定优越性差距所需的迭代次数，并提出了适用于基于TDMA的系统的最佳批量分配方法。此外，还展示了提出的分步批量分配方法可以显著减少基于RA的学习系统的完成时间",
    "en_tdlr": "Analyzed the number of iterations needed to achieve a specific optimality gap in wireless federated learning and proposed an optimal batch allocation method for TDMA-based systems. Additionally, demonstrated that the proposed step-wise batch allocation can significantly reduce the completion time for RA-based learning systems."
}