{
    "title": "Efficient Prompting Methods for Large Language Models: A Survey",
    "abstract": "arXiv:2404.01077v1 Announce Type: new  Abstract: Prompting has become a mainstream paradigm for adapting large language models (LLMs) to specific natural language processing tasks. While this approach opens the door to in-context learning of LLMs, it brings the additional computational burden of model inference and human effort of manual-designed prompts, particularly when using lengthy and complex prompts to guide and control the behavior of LLMs. As a result, the LLM field has seen a remarkable surge in efficient prompting methods. In this paper, we present a comprehensive overview of these methods. At a high level, efficient prompting methods can broadly be categorized into two approaches: prompting with efficient computation and prompting with efficient design. The former involves various ways of compressing prompts, and the latter employs techniques for automatic prompt optimization. We present the basic concepts of prompting, review the advances for efficient prompting, and highl",
    "link": "https://arxiv.org/abs/2404.01077",
    "context": "Title: Efficient Prompting Methods for Large Language Models: A Survey\nAbstract: arXiv:2404.01077v1 Announce Type: new  Abstract: Prompting has become a mainstream paradigm for adapting large language models (LLMs) to specific natural language processing tasks. While this approach opens the door to in-context learning of LLMs, it brings the additional computational burden of model inference and human effort of manual-designed prompts, particularly when using lengthy and complex prompts to guide and control the behavior of LLMs. As a result, the LLM field has seen a remarkable surge in efficient prompting methods. In this paper, we present a comprehensive overview of these methods. At a high level, efficient prompting methods can broadly be categorized into two approaches: prompting with efficient computation and prompting with efficient design. The former involves various ways of compressing prompts, and the latter employs techniques for automatic prompt optimization. We present the basic concepts of prompting, review the advances for efficient prompting, and highl",
    "path": "papers/24/04/2404.01077.json",
    "total_tokens": 814,
    "translated_title": "大型语言模型的高效提示方法：一项调查",
    "translated_abstract": "提示已成为调整大型语言模型（LLMs）以适应特定自然语言处理任务的主流范式。尽管这种方法为LLMs的上下文学习打开了大门，但引入了额外的计算负担，即模型推理的计算负担和手动设计提示的人力劳动，特别是在使用冗长和复杂的提示来引导和控制LLMs的行为时。因此，LLM领域见证了高效提示方法的显著激增。在本文中，我们对这些方法进行了全面的概述。在较高的层面上，高效提示方法可以广泛分类为两种方式：具有高效计算的提示和具有高效设计的提示。前者涉及各种压缩提示的方法，后者采用自动提示优化技术。我们介绍了提示的基本概念，回顾了高效提示的进展，并突出显示出",
    "tldr": "提示已成为大型语言模型适应特定自然语言处理任务的主流范式，而高效提示方法在压缩提示和自动提示优化方面取得显著进展。",
    "en_tdlr": "Prompting has become a mainstream paradigm for adapting large language models to specific natural language processing tasks, and efficient prompting methods have made significant progress in compressing prompts and automatic prompt optimization."
}