{
    "title": "Multi-Granularity Guided Fusion-in-Decoder",
    "abstract": "arXiv:2404.02581v1 Announce Type: new  Abstract: In Open-domain Question Answering (ODQA), it is essential to discern relevant contexts as evidence and avoid spurious ones among retrieved results. The model architecture that uses concatenated multiple contexts in the decoding phase, i.e., Fusion-in-Decoder, demonstrates promising performance but generates incorrect outputs from seemingly plausible contexts. To address this problem, we propose the Multi-Granularity guided Fusion-in-Decoder (MGFiD), discerning evidence across multiple levels of granularity. Based on multi-task learning, MGFiD harmonizes passage re-ranking with sentence classification. It aggregates evident sentences into an anchor vector that instructs the decoder. Additionally, it improves decoding efficiency by reusing the results of passage re-ranking for passage pruning. Through our experiments, MGFiD outperforms existing models on the Natural Questions (NQ) and TriviaQA (TQA) datasets, highlighting the benefits of i",
    "link": "https://arxiv.org/abs/2404.02581",
    "context": "Title: Multi-Granularity Guided Fusion-in-Decoder\nAbstract: arXiv:2404.02581v1 Announce Type: new  Abstract: In Open-domain Question Answering (ODQA), it is essential to discern relevant contexts as evidence and avoid spurious ones among retrieved results. The model architecture that uses concatenated multiple contexts in the decoding phase, i.e., Fusion-in-Decoder, demonstrates promising performance but generates incorrect outputs from seemingly plausible contexts. To address this problem, we propose the Multi-Granularity guided Fusion-in-Decoder (MGFiD), discerning evidence across multiple levels of granularity. Based on multi-task learning, MGFiD harmonizes passage re-ranking with sentence classification. It aggregates evident sentences into an anchor vector that instructs the decoder. Additionally, it improves decoding efficiency by reusing the results of passage re-ranking for passage pruning. Through our experiments, MGFiD outperforms existing models on the Natural Questions (NQ) and TriviaQA (TQA) datasets, highlighting the benefits of i",
    "path": "papers/24/04/2404.02581.json",
    "total_tokens": 842,
    "translated_title": "多粒度引导的解码器融合",
    "translated_abstract": "在开放域问答中，识别相关上下文作为证据并避免在检索结果中出现虚假上下文至关重要。在解码阶段使用多个上下文进行串联的模型架构（即Fusion-in-Decoder）表现出有希望的性能，但会从看似合理的上下文中生成不正确的输出。为了解决这个问题，我们提出了多粒度引导的解码器融合（MGFiD），跨多个粒度辨别证据。基于多任务学习，MGFiD将段落重新排序与句子分类进行协调。它将明显的句子聚合到一个锚定向量中，指导解码器。此外，它通过重用段落重新排序的结果来提高解码效率进行段落修剪。通过实验证明，MGFiD在自然问答（NQ）和TriviaQA（TQA）数据集上优于现有模型，突显了其优点。",
    "tldr": "提出了多粒度引导的解码器融合（MGFiD），通过跨多个粒度辨别证据，并结合段落重新排序和句子分类，提高开放域问答中解码效率。",
    "en_tdlr": "Introduced Multi-Granularity guided Fusion-in-Decoder (MGFiD) that discerns evidence across multiple granularities, harmonizes passage re-ranking with sentence classification, and improves decoding efficiency in open-domain question answering."
}