{
    "title": "Upsample Guidance: Scale Up Diffusion Models without Training",
    "abstract": "arXiv:2404.01709v1 Announce Type: cross  Abstract: Diffusion models have demonstrated superior performance across various generative tasks including images, videos, and audio. However, they encounter difficulties in directly generating high-resolution samples. Previously proposed solutions to this issue involve modifying the architecture, further training, or partitioning the sampling process into multiple stages. These methods have the limitation of not being able to directly utilize pre-trained models as-is, requiring additional work. In this paper, we introduce upsample guidance, a technique that adapts pretrained diffusion model (e.g., $512^2$) to generate higher-resolution images (e.g., $1536^2$) by adding only a single term in the sampling process. Remarkably, this technique does not necessitate any additional training or relying on external models. We demonstrate that upsample guidance can be applied to various models, such as pixel-space, latent space, and video diffusion model",
    "link": "https://arxiv.org/abs/2404.01709",
    "context": "Title: Upsample Guidance: Scale Up Diffusion Models without Training\nAbstract: arXiv:2404.01709v1 Announce Type: cross  Abstract: Diffusion models have demonstrated superior performance across various generative tasks including images, videos, and audio. However, they encounter difficulties in directly generating high-resolution samples. Previously proposed solutions to this issue involve modifying the architecture, further training, or partitioning the sampling process into multiple stages. These methods have the limitation of not being able to directly utilize pre-trained models as-is, requiring additional work. In this paper, we introduce upsample guidance, a technique that adapts pretrained diffusion model (e.g., $512^2$) to generate higher-resolution images (e.g., $1536^2$) by adding only a single term in the sampling process. Remarkably, this technique does not necessitate any additional training or relying on external models. We demonstrate that upsample guidance can be applied to various models, such as pixel-space, latent space, and video diffusion model",
    "path": "papers/24/04/2404.01709.json",
    "total_tokens": 844,
    "translated_title": "Upsample Guidance: 不经过训练即可扩展扩散模型",
    "translated_abstract": "扩散模型在包括图像、视频和音频等各种生成任务中已经表现出卓越性能。然而，它们在直接生成高分辨率样本方面遇到困难。先前提出的解决方案包括修改架构、进一步训练或将采样过程划分为多个阶段。这些方法的局限性在于无法直接使用预训练模型，需要额外工作。在本文中，我们引入了上采样指导，这是一种技术，通过在采样过程中仅添加一个项，使预训练扩散模型（例如$512^2$）能够生成更高分辨率的图像（例如$1536^2$）。值得注意的是，这种技术不需要任何额外训练或依赖外部模型。我们展示了上采样指导可应用于各种模型，如像素空间、潜在空间和视频扩散模型。",
    "tldr": "提出了一种称为上采样指导的技术，能够适应预训练的扩散模型，实现更高分辨率图像的生成，无需额外训练或依赖外部模型。"
}