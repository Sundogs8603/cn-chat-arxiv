{
    "title": "UniMEEC: Towards Unified Multimodal Emotion Recognition and Emotion Cause",
    "abstract": "arXiv:2404.00403v1 Announce Type: new  Abstract: Multimodal emotion recognition in conversation (MERC) and multimodal emotion-cause pair extraction (MECPE) has recently garnered significant attention. Emotions are the expression of affect or feelings; responses to specific events, thoughts, or situations are known as emotion causes. Both are like two sides of a coin, collectively describing human behaviors and intents. However, most existing works treat MERC and MECPE as separate tasks, which may result in potential challenges in integrating emotion and cause in real-world applications. In this paper, we propose a Unified Multimodal Emotion recognition and Emotion-Cause analysis framework (UniMEEC) to explore the causality and complementarity between emotion and emotion cause. Concretely, UniMEEC reformulates the MERC and MECPE tasks as two mask prediction problems, enhancing the interaction between emotion and cause. Meanwhile, UniMEEC shares the prompt learning among modalities for p",
    "link": "https://arxiv.org/abs/2404.00403",
    "context": "Title: UniMEEC: Towards Unified Multimodal Emotion Recognition and Emotion Cause\nAbstract: arXiv:2404.00403v1 Announce Type: new  Abstract: Multimodal emotion recognition in conversation (MERC) and multimodal emotion-cause pair extraction (MECPE) has recently garnered significant attention. Emotions are the expression of affect or feelings; responses to specific events, thoughts, or situations are known as emotion causes. Both are like two sides of a coin, collectively describing human behaviors and intents. However, most existing works treat MERC and MECPE as separate tasks, which may result in potential challenges in integrating emotion and cause in real-world applications. In this paper, we propose a Unified Multimodal Emotion recognition and Emotion-Cause analysis framework (UniMEEC) to explore the causality and complementarity between emotion and emotion cause. Concretely, UniMEEC reformulates the MERC and MECPE tasks as two mask prediction problems, enhancing the interaction between emotion and cause. Meanwhile, UniMEEC shares the prompt learning among modalities for p",
    "path": "papers/24/04/2404.00403.json",
    "total_tokens": 910,
    "translated_title": "UniMEEC:走向统一的多模情绪识别与情绪因果",
    "translated_abstract": "最近，对话中的多模情绪识别（MERC）和多模情绪-原因对提取（MECPE）引起了广泛关注。情绪是情感或感受的表达；对特定事件、想法或情况的响应被称为情绪原因。它们如同一枚硬币的两面，共同描述了人类行为和意图。然而，大多数现有作品将MERC和MECPE视为独立任务，这可能导致在整合情绪和原因到现实应用中存在潜在挑战。在本文中，我们提出了一个统一的多模情绪识别和情绪-原因分析框架（UniMEEC），以探索情绪和情绪原因之间的因果关系和互补性。具体来说，UniMEEC将MERC和MECPE任务重新定义为两个掩码预测问题，增强了情绪和原因之间的交互作用。与此同时，UniMEEC在各模态之间共享迅速学习以促进",
    "tldr": "UniMEEC提出了一个统一的多模情绪识别和情绪-原因分析框架，将MERC和MECPE重新定义为两个掩码预测问题，以增强情绪和原因之间的交互作用。",
    "en_tdlr": "UniMEEC introduces a unified framework for multimodal emotion recognition and emotion-cause analysis, reformulating MERC and MECPE as two mask prediction problems to enhance the interaction between emotion and cause."
}