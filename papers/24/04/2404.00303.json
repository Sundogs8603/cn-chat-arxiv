{
    "title": "A Comprehensive Study on NLP Data Augmentation for Hate Speech Detection: Legacy Methods, BERT, and LLMs",
    "abstract": "arXiv:2404.00303v1 Announce Type: new  Abstract: The surge of interest in data augmentation within the realm of NLP has been driven by the need to address challenges posed by hate speech domains, the dynamic nature of social media vocabulary, and the demands for large-scale neural networks requiring extensive training data. However, the prevalent use of lexical substitution in data augmentation has raised concerns, as it may inadvertently alter the intended meaning, thereby impacting the efficacy of supervised machine learning models. In pursuit of suitable data augmentation methods, this study explores both established legacy approaches and contemporary practices such as Large Language Models (LLM), including GPT in Hate Speech detection. Additionally, we propose an optimized utilization of BERT-based encoder models with contextual cosine similarity filtration, exposing significant limitations in prior synonym substitution methods. Our comparative analysis encompasses five popular aug",
    "link": "https://arxiv.org/abs/2404.00303",
    "context": "Title: A Comprehensive Study on NLP Data Augmentation for Hate Speech Detection: Legacy Methods, BERT, and LLMs\nAbstract: arXiv:2404.00303v1 Announce Type: new  Abstract: The surge of interest in data augmentation within the realm of NLP has been driven by the need to address challenges posed by hate speech domains, the dynamic nature of social media vocabulary, and the demands for large-scale neural networks requiring extensive training data. However, the prevalent use of lexical substitution in data augmentation has raised concerns, as it may inadvertently alter the intended meaning, thereby impacting the efficacy of supervised machine learning models. In pursuit of suitable data augmentation methods, this study explores both established legacy approaches and contemporary practices such as Large Language Models (LLM), including GPT in Hate Speech detection. Additionally, we propose an optimized utilization of BERT-based encoder models with contextual cosine similarity filtration, exposing significant limitations in prior synonym substitution methods. Our comparative analysis encompasses five popular aug",
    "path": "papers/24/04/2404.00303.json",
    "total_tokens": 906,
    "translated_title": "针对仇恨言论检测的自然语言处理数据增强的综合研究：传统方法、BERT和LLM",
    "translated_abstract": "针对自然语言处理领域中数据增强引起的兴趣激增，驱动力来自于需要解决仇恨言论领域所带来的挑战、社交媒体词汇的动态性，以及大规模神经网络对大量训练数据的需求。然而，数据增强中普遍使用的词汇替换引发了关注，因为它可能无意中改变预期含义，从而影响监督机器学习模型的有效性。为寻求合适的数据增强方法，本研究探索了传统的传统方法和当代实践，如大型语言模型（LLM），包括GPT在仇恨言论检测中的应用。此外，我们提出了一种优化利用基于BERT的编码器模型，搭配上上文余弦相似性过滤，揭示了之前同义词替换方法的重大局限性。我们的比较分析涵盖了五种流行的增强方法。",
    "tldr": "本研究从传统方法到当代实践，探讨了适用于仇恨言论检测的数据增强方法，提出了优化利用BERT-based编码器模型的思路，并揭示了相较于之前的同义词替换方法存在的重要限制。",
    "en_tdlr": "This study investigates data augmentation methods for hate speech detection from traditional approaches to contemporary practices, proposes an optimized utilization of BERT-based encoder models, and highlights significant limitations compared to previous synonym substitution methods."
}