{
    "title": "Evaluating the Factuality of Large Language Models using Large-Scale Knowledge Graphs",
    "abstract": "arXiv:2404.00942v1 Announce Type: cross  Abstract: The advent of Large Language Models (LLMs) has significantly transformed the AI landscape, enhancing machine learning and AI capabilities. Factuality issue is a critical concern for LLMs, as they may generate factually incorrect responses. In this paper, we propose GraphEval to evaluate an LLM's performance using a substantially large test dataset. Specifically, the test dataset is retrieved from a large knowledge graph with more than 10 million facts without expensive human efforts. Unlike conventional methods that evaluate LLMs based on generated responses, GraphEval streamlines the evaluation process by creating a judge model to estimate the correctness of the answers given by the LLM. Our experiments demonstrate that the judge model's factuality assessment aligns closely with the correctness of the LLM's generated outputs, while also substantially reducing evaluation costs. Besides, our findings offer valuable insights into LLM per",
    "link": "https://arxiv.org/abs/2404.00942",
    "context": "Title: Evaluating the Factuality of Large Language Models using Large-Scale Knowledge Graphs\nAbstract: arXiv:2404.00942v1 Announce Type: cross  Abstract: The advent of Large Language Models (LLMs) has significantly transformed the AI landscape, enhancing machine learning and AI capabilities. Factuality issue is a critical concern for LLMs, as they may generate factually incorrect responses. In this paper, we propose GraphEval to evaluate an LLM's performance using a substantially large test dataset. Specifically, the test dataset is retrieved from a large knowledge graph with more than 10 million facts without expensive human efforts. Unlike conventional methods that evaluate LLMs based on generated responses, GraphEval streamlines the evaluation process by creating a judge model to estimate the correctness of the answers given by the LLM. Our experiments demonstrate that the judge model's factuality assessment aligns closely with the correctness of the LLM's generated outputs, while also substantially reducing evaluation costs. Besides, our findings offer valuable insights into LLM per",
    "path": "papers/24/04/2404.00942.json",
    "total_tokens": 822,
    "translated_title": "使用大规模知识图谱评估大型语言模型的事实性",
    "translated_abstract": "大型语言模型（LLMs）的出现显著改变了人工智能领域，增强了机器学习和人工智能的能力。事实性问题对LLMs来说是一个关键问题，因为它们可能生成事实不准确的响应。本文提出了GraphEval，通过大规模测试数据集对LLM的性能进行评估。具体而言，测试数据集是从拥有超过1000万个事实的大型知识图谱中检索而来，无需昂贵的人力成本。与基于生成响应评估LLMs的传统方法不同，GraphEval通过创建一个评估模型简化了评估过程，用于估计LLM给出的答案的正确性。我们的实验表明，评估模型的事实性评估与LLM生成的输出的正确性密切相关，同时显著降低了评估成本。此外，我们的发现为LLM的性能提供了宝贵的洞见。",
    "tldr": "使用大型知识图谱创建评估模型以检查大型语言模型在事实性上的表现，有效降低评估成本。",
    "en_tdlr": "Evaluating large language models on factuality using a judge model created from a massive knowledge graph significantly reduces evaluation costs and provides valuable insights."
}