{
    "title": "Robust Ensemble Person Re-Identification via Orthogonal Fusion with Occlusion Handling",
    "abstract": "arXiv:2404.00107v1 Announce Type: cross  Abstract: Occlusion remains one of the major challenges in person reidentification (ReID) as a result of the diversity of poses and the variation of appearances. Developing novel architectures to improve the robustness of occlusion-aware person Re-ID requires new insights, especially on low-resolution edge cameras. We propose a deep ensemble model that harnesses both CNN and Transformer architectures to generate robust feature representations. To achieve robust Re-ID without the need to manually label occluded regions, we propose to take an ensemble learning-based approach derived from the analogy between arbitrarily shaped occluded regions and robust feature representation. Using the orthogonality principle, our developed deep CNN model makes use of masked autoencoder (MAE) and global-local feature fusion for robust person identification. Furthermore, we present a part occlusion-aware transformer capable of learning feature space that is robust",
    "link": "https://arxiv.org/abs/2404.00107",
    "context": "Title: Robust Ensemble Person Re-Identification via Orthogonal Fusion with Occlusion Handling\nAbstract: arXiv:2404.00107v1 Announce Type: cross  Abstract: Occlusion remains one of the major challenges in person reidentification (ReID) as a result of the diversity of poses and the variation of appearances. Developing novel architectures to improve the robustness of occlusion-aware person Re-ID requires new insights, especially on low-resolution edge cameras. We propose a deep ensemble model that harnesses both CNN and Transformer architectures to generate robust feature representations. To achieve robust Re-ID without the need to manually label occluded regions, we propose to take an ensemble learning-based approach derived from the analogy between arbitrarily shaped occluded regions and robust feature representation. Using the orthogonality principle, our developed deep CNN model makes use of masked autoencoder (MAE) and global-local feature fusion for robust person identification. Furthermore, we present a part occlusion-aware transformer capable of learning feature space that is robust",
    "path": "papers/24/04/2404.00107.json",
    "total_tokens": 881,
    "translated_title": "通过具有遮挡处理的正交融合的强健集成人员识别",
    "translated_abstract": "遮挡仍然是人员再识别（ReID）中的一个主要挑战，这是由于姿势的多样性和外观的变化。为了改善具有遮挡感知的人员Re-ID的鲁棒性，需要开发新的架构，特别是在低分辨率边缘摄像头上。我们提出了一种深度集成模型，利用CNN和Transformer架构生成强大的特征表示。为了实现鲁棒的Re-ID，而无需手动标记被遮挡的区域，我们提出了一种基于集成学习的方法，从任意形状的被遮挡区域和鲁棒特征表示之间的类比中推导出。利用正交性原理，我们开发的深度CNN模型利用了掩蔽自编码器（MAE）和全局-局部特征融合来进行强大的人员识别。此外，我们提出了一个能够学习鲁棒特征空间的部分遮挡感知变压器。",
    "tldr": "提出了一种通过正交融合处理遮挡的强健集成人员识别模型，无需手动标记遮挡区域，利用CNN和Transformer架构生成鲁棒特征表示。",
    "en_tdlr": "Proposed a robust ensemble person re-identification model for occlusion handling using orthogonal fusion, without the need for manual labeling of occluded regions, leveraging CNN and Transformer architectures to generate robust feature representations."
}