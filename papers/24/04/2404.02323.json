{
    "title": "Toward Informal Language Processing: Knowledge of Slang in Large Language Models",
    "abstract": "arXiv:2404.02323v1 Announce Type: new  Abstract: Recent advancement in large language models (LLMs) has offered a strong potential for natural language systems to process informal language. A representative form of informal language is slang, used commonly in daily conversations and online social media. To date, slang has not been comprehensively evaluated in LLMs due partly to the absence of a carefully designed and publicly accessible benchmark. Using movie subtitles, we construct a dataset that supports evaluation on a diverse set of tasks pertaining to automatic processing of slang. For both evaluation and finetuning, we show the effectiveness of our dataset on two core applications: 1) slang detection, and 2) identification of regional and historical sources of slang from natural sentences. We also show how our dataset can be used to probe the output distributions of LLMs for interpretive insights. We find that while LLMs such as GPT-4 achieve good performance in a zero-shot setti",
    "link": "https://arxiv.org/abs/2404.02323",
    "context": "Title: Toward Informal Language Processing: Knowledge of Slang in Large Language Models\nAbstract: arXiv:2404.02323v1 Announce Type: new  Abstract: Recent advancement in large language models (LLMs) has offered a strong potential for natural language systems to process informal language. A representative form of informal language is slang, used commonly in daily conversations and online social media. To date, slang has not been comprehensively evaluated in LLMs due partly to the absence of a carefully designed and publicly accessible benchmark. Using movie subtitles, we construct a dataset that supports evaluation on a diverse set of tasks pertaining to automatic processing of slang. For both evaluation and finetuning, we show the effectiveness of our dataset on two core applications: 1) slang detection, and 2) identification of regional and historical sources of slang from natural sentences. We also show how our dataset can be used to probe the output distributions of LLMs for interpretive insights. We find that while LLMs such as GPT-4 achieve good performance in a zero-shot setti",
    "path": "papers/24/04/2404.02323.json",
    "total_tokens": 877,
    "translated_title": "迈向非正式语言处理：大型语言模型对俚语的认知",
    "translated_abstract": "大型语言模型（LLMs）的最新进展为自然语言系统处理非正式语言提供了强大潜力。非正式语言的一个代表形式是俚语，在日常对话和在线社交媒体中常用。迄今为止，由于缺乏一个精心设计且可公开访问的基准，俚语在LLMs中尚未得到全面评估。我们利用电影字幕构建了一个数据集，支持在涉及俚语自动处理的多样化任务上进行评估。我们展示了我们的数据集在两个核心应用中（俚语检测和识别自然语句中俚语的地区和历史来源）的评估和微调的有效性。我们还展示了如何使用我们的数据集来探测LLMs的输出分布以获得解释性洞见。我们发现，尽管 GPT-4 等LLMs 在零次尝试方面表现良好，但在俚语处理方面仍有改进的空间。",
    "tldr": "大型语言模型通过建立支持多任务评估的俚语数据集，有效实现了俚语检测和识别地区与历史俚语来源，并通过探索LLMs输出分布提供了解释性洞见。",
    "en_tdlr": "Large language models effectively detect and identify the origins of slang from different regions and historical periods by constructing a dataset supporting multi-task evaluation, while also providing interpretive insights through exploring the output distributions of LLMs."
}