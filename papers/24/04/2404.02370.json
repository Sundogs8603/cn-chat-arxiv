{
    "title": "Enhancing Human-Computer Interaction in Chest X-ray Analysis using Vision and Language Model with Eye Gaze Patterns",
    "abstract": "arXiv:2404.02370v1 Announce Type: cross  Abstract: Recent advancements in Computer Assisted Diagnosis have shown promising performance in medical imaging tasks, particularly in chest X-ray analysis. However, the interaction between these models and radiologists has been primarily limited to input images. This work proposes a novel approach to enhance human-computer interaction in chest X-ray analysis using Vision-Language Models (VLMs) enhanced with radiologists' attention by incorporating eye gaze data alongside textual prompts. Our approach leverages heatmaps generated from eye gaze data, overlaying them onto medical images to highlight areas of intense radiologist's focus during chest X-ray evaluation. We evaluate this methodology in tasks such as visual question answering, chest X-ray report automation, error detection, and differential diagnosis. Our results demonstrate the inclusion of eye gaze information significantly enhances the accuracy of chest X-ray analysis. Also, the imp",
    "link": "https://arxiv.org/abs/2404.02370",
    "context": "Title: Enhancing Human-Computer Interaction in Chest X-ray Analysis using Vision and Language Model with Eye Gaze Patterns\nAbstract: arXiv:2404.02370v1 Announce Type: cross  Abstract: Recent advancements in Computer Assisted Diagnosis have shown promising performance in medical imaging tasks, particularly in chest X-ray analysis. However, the interaction between these models and radiologists has been primarily limited to input images. This work proposes a novel approach to enhance human-computer interaction in chest X-ray analysis using Vision-Language Models (VLMs) enhanced with radiologists' attention by incorporating eye gaze data alongside textual prompts. Our approach leverages heatmaps generated from eye gaze data, overlaying them onto medical images to highlight areas of intense radiologist's focus during chest X-ray evaluation. We evaluate this methodology in tasks such as visual question answering, chest X-ray report automation, error detection, and differential diagnosis. Our results demonstrate the inclusion of eye gaze information significantly enhances the accuracy of chest X-ray analysis. Also, the imp",
    "path": "papers/24/04/2404.02370.json",
    "total_tokens": 911,
    "translated_title": "利用视觉和语言模型以及眼睛注视模式增强胸部X射线分析中的人机交互",
    "translated_abstract": "最近计算机辅助诊断的进展在医学影像任务中表现出良好的性能，特别是在胸部X射线分析方面。然而，这些模型与放射科医师之间的互动主要仅限于输入图像。本文提出了一种新方法，通过将眼动数据与文本提示结合在一起，利用增强了放射科医师的关注的视觉语言模型（VLMs）来增强胸部X射线分析中的人机交互。我们的方法利用从眼动数据生成的热图，将它们叠加到医学图像上，以突出放射科医师在胸部X射线评估过程中关注强度较高的区域。我们在视觉问题回答、胸部X射线报告自动化、错误检测和鉴别诊断等任务中评估了这种方法。我们的结果表明，包含眼动信息显著提高了胸部X射线分析的准确性。",
    "tldr": "通过结合眼动数据和文本提示，利用Vision-Language Models（VLMs）增强胸部X射线分析中的人机交互，提高了放射科医师的关注度，有效增强了胸部X射线分析的准确性。",
    "en_tdlr": "By combining eye gaze data and textual prompts, using Vision-Language Models (VLMs) enhances human-computer interaction in chest X-ray analysis, improves radiologists' focus, and significantly enhances the accuracy of chest X-ray analysis."
}