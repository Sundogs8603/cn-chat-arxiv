{
    "title": "Distributed Autonomous Swarm Formation for Dynamic Network Bridging",
    "abstract": "arXiv:2404.01557v1 Announce Type: cross  Abstract: Effective operation and seamless cooperation of robotic systems are a fundamental component of next-generation technologies and applications. In contexts such as disaster response, swarm operations require coordinated behavior and mobility control to be handled in a distributed manner, with the quality of the agents' actions heavily relying on the communication between them and the underlying network. In this paper, we formulate the problem of dynamic network bridging in a novel Decentralized Partially Observable Markov Decision Process (Dec-POMDP), where a swarm of agents cooperates to form a link between two distant moving targets. Furthermore, we propose a Multi-Agent Reinforcement Learning (MARL) approach for the problem based on Graph Convolutional Reinforcement Learning (DGN) which naturally applies to the networked, distributed nature of the task. The proposed method is evaluated in a simulated environment and compared to a cent",
    "link": "https://arxiv.org/abs/2404.01557",
    "context": "Title: Distributed Autonomous Swarm Formation for Dynamic Network Bridging\nAbstract: arXiv:2404.01557v1 Announce Type: cross  Abstract: Effective operation and seamless cooperation of robotic systems are a fundamental component of next-generation technologies and applications. In contexts such as disaster response, swarm operations require coordinated behavior and mobility control to be handled in a distributed manner, with the quality of the agents' actions heavily relying on the communication between them and the underlying network. In this paper, we formulate the problem of dynamic network bridging in a novel Decentralized Partially Observable Markov Decision Process (Dec-POMDP), where a swarm of agents cooperates to form a link between two distant moving targets. Furthermore, we propose a Multi-Agent Reinforcement Learning (MARL) approach for the problem based on Graph Convolutional Reinforcement Learning (DGN) which naturally applies to the networked, distributed nature of the task. The proposed method is evaluated in a simulated environment and compared to a cent",
    "path": "papers/24/04/2404.01557.json",
    "total_tokens": 872,
    "translated_title": "分布式自主群体形成动态网络桥接",
    "translated_abstract": "有效的机器人系统操作和无缝协作是下一代技术和应用的基本组成部分。在诸如灾难响应之类的情景中，群体操作需要协调的行为和移动控制以分布式方式处理，代理之间的通信以及底层网络质量对其行动的质量产生重大影响。本文针对动态网络桥接问题提出了一种新颖的分布式部分可观察马尔可夫决策过程（Dec-POMDP）方法，其中一群代理协作形成两个远距移动目标之间的连接。此外，我们提出了一种基于图卷积强化学习（DGN）的多智能体强化学习（MARL）方法，该方法自然适用于任务的网络化、分布式性质。所提出的方法在模拟环境中进行了评估，并与一个基于强化学习的中心化方法进行了比较。",
    "tldr": "提出了一种用于动态网络桥接的新颖分布式部分可观察马尔可夫决策过程（Dec-POMDP）方法，以及基于图卷积强化学习（DGN）的多智能体强化学习（MARL）方法。",
    "en_tdlr": "Proposed a novel Decentralized Partially Observable Markov Decision Process (Dec-POMDP) method for dynamic network bridging, along with a Multi-Agent Reinforcement Learning (MARL) approach based on Graph Convolutional Reinforcement Learning (DGN)."
}