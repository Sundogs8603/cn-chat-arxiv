{
    "title": "Computation and Communication Efficient Lightweighting Vertical Federated Learning",
    "abstract": "arXiv:2404.00466v1 Announce Type: new  Abstract: The exploration of computational and communication efficiency within Federated Learning (FL) has emerged as a prominent and crucial field of study. While most existing efforts to enhance these efficiencies have focused on Horizontal FL, the distinct processes and model structures of Vertical FL preclude the direct application of Horizontal FL-based techniques. In response, we introduce the concept of Lightweight Vertical Federated Learning (LVFL), targeting both computational and communication efficiencies. This approach involves separate lightweighting strategies for the feature model, to improve computational efficiency, and for feature embedding, to enhance communication efficiency. Moreover, we establish a convergence bound for our LVFL algorithm, which accounts for both communication and computational lightweighting ratios. Our evaluation of the algorithm on a image classification dataset reveals that LVFL significantly alleviates c",
    "link": "https://arxiv.org/abs/2404.00466",
    "context": "Title: Computation and Communication Efficient Lightweighting Vertical Federated Learning\nAbstract: arXiv:2404.00466v1 Announce Type: new  Abstract: The exploration of computational and communication efficiency within Federated Learning (FL) has emerged as a prominent and crucial field of study. While most existing efforts to enhance these efficiencies have focused on Horizontal FL, the distinct processes and model structures of Vertical FL preclude the direct application of Horizontal FL-based techniques. In response, we introduce the concept of Lightweight Vertical Federated Learning (LVFL), targeting both computational and communication efficiencies. This approach involves separate lightweighting strategies for the feature model, to improve computational efficiency, and for feature embedding, to enhance communication efficiency. Moreover, we establish a convergence bound for our LVFL algorithm, which accounts for both communication and computational lightweighting ratios. Our evaluation of the algorithm on a image classification dataset reveals that LVFL significantly alleviates c",
    "path": "papers/24/04/2404.00466.json",
    "total_tokens": 815,
    "translated_title": "计算和通信高效的轻量级纵向联邦学习",
    "translated_abstract": "在联邦学习（FL）中探索计算和通信效率已成为一个突出和关键的研究领域。尽管大多数现有的努力都集中在提高这些效率，但由于垂直FL的不同过程和模型结构，无法直接应用基于水平FL的技术。因此，我们引入了轻量级纵向联邦学习（LVFL）的概念，旨在提高计算和通信效率。这种方法涉及针对特征模型的单独轻量化策略，以提高计算效率，并针对特征嵌入进行轻量化，以增强通信效率。此外，我们为LVFL算法建立了收敛界限，考虑了通信和计算轻量化比率。我们在图像分类数据集上对该算法进行评估的结果表明，LVFL显著减轻了c",
    "tldr": "提出轻量级纵向联邦学习（LVFL）的概念，针对计算和通信效率采用分离的轻量化策略，建立了收敛界限，并在图像分类数据集上得到了验证",
    "en_tdlr": "Introducing Lightweight Vertical Federated Learning (LVFL) targeting both computational and communication efficiencies, establishing a convergence bound, and validating the approach on an image classification dataset."
}