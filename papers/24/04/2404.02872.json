{
    "title": "Integrating Explanations in Learning LTL Specifications from Demonstrations",
    "abstract": "arXiv:2404.02872v1 Announce Type: new  Abstract: This paper investigates whether recent advances in Large Language Models (LLMs) can assist in translating human explanations into a format that can robustly support learning Linear Temporal Logic (LTL) from demonstrations. Both LLMs and optimization-based methods can extract LTL specifications from demonstrations; however, they have distinct limitations. LLMs can quickly generate solutions and incorporate human explanations, but their lack of consistency and reliability hampers their applicability in safety-critical domains. On the other hand, optimization-based methods do provide formal guarantees but cannot process natural language explanations and face scalability challenges. We present a principled approach to combining LLMs and optimization-based methods to faithfully translate human explanations and demonstrations into LTL specifications. We have implemented a tool called Janaka based on our approach. Our experiments demonstrate th",
    "link": "https://arxiv.org/abs/2404.02872",
    "context": "Title: Integrating Explanations in Learning LTL Specifications from Demonstrations\nAbstract: arXiv:2404.02872v1 Announce Type: new  Abstract: This paper investigates whether recent advances in Large Language Models (LLMs) can assist in translating human explanations into a format that can robustly support learning Linear Temporal Logic (LTL) from demonstrations. Both LLMs and optimization-based methods can extract LTL specifications from demonstrations; however, they have distinct limitations. LLMs can quickly generate solutions and incorporate human explanations, but their lack of consistency and reliability hampers their applicability in safety-critical domains. On the other hand, optimization-based methods do provide formal guarantees but cannot process natural language explanations and face scalability challenges. We present a principled approach to combining LLMs and optimization-based methods to faithfully translate human explanations and demonstrations into LTL specifications. We have implemented a tool called Janaka based on our approach. Our experiments demonstrate th",
    "path": "papers/24/04/2404.02872.json",
    "total_tokens": 808,
    "translated_title": "整合解释在从演示中学习LTL规范中的应用",
    "translated_abstract": "本文研究最近大型语言模型（LLMs）的进展是否有助于将人类解释转化为能够稳健支持从演示中学习线性时间逻辑（LTL）的格式。LLMs和基于优化的方法都可以从演示中提取LTL规范；然而，它们存在着明显的局限性。LLMs可以快速生成解决方案并整合人类解释，但缺乏一致性和可靠性限制了它们在安全关键领域的适用性。另一方面，基于优化的方法可以提供形式化保证，但无法处理自然语言解释并面临可扩展性挑战。我们提出了一种有原则的方法，将LLMs和基于优化的方法相结合，忠实地将人类解释和演示转化为LTL规范。我们基于我们的方法实现了一个名为Janaka的工具。我们的实验证明",
    "tldr": "这项研究提出了一种整合大型语言模型和基于优化方法的方法，用于将人类解释和演示准确地转化为LTL规范。"
}