{
    "title": "On the Role of Summary Content Units in Text Summarization Evaluation",
    "abstract": "arXiv:2404.01701v1 Announce Type: new  Abstract: At the heart of the Pyramid evaluation method for text summarization lie human written summary content units (SCUs). These SCUs are concise sentences that decompose a summary into small facts. Such SCUs can be used to judge the quality of a candidate summary, possibly partially automated via natural language inference (NLI) systems. Interestingly, with the aim to fully automate the Pyramid evaluation, Zhang and Bansal (2021) show that SCUs can be approximated by automatically generated semantic role triplets (STUs). However, several questions currently lack answers, in particular: i) Are there other ways of approximating SCUs that can offer advantages? ii) Under which conditions are SCUs (or their approximations) offering the most value? In this work, we examine two novel strategies to approximate SCUs: generating SCU approximations from AMR meaning representations (SMUs) and from large language models (SGUs), respectively. We find that ",
    "link": "https://arxiv.org/abs/2404.01701",
    "context": "Title: On the Role of Summary Content Units in Text Summarization Evaluation\nAbstract: arXiv:2404.01701v1 Announce Type: new  Abstract: At the heart of the Pyramid evaluation method for text summarization lie human written summary content units (SCUs). These SCUs are concise sentences that decompose a summary into small facts. Such SCUs can be used to judge the quality of a candidate summary, possibly partially automated via natural language inference (NLI) systems. Interestingly, with the aim to fully automate the Pyramid evaluation, Zhang and Bansal (2021) show that SCUs can be approximated by automatically generated semantic role triplets (STUs). However, several questions currently lack answers, in particular: i) Are there other ways of approximating SCUs that can offer advantages? ii) Under which conditions are SCUs (or their approximations) offering the most value? In this work, we examine two novel strategies to approximate SCUs: generating SCU approximations from AMR meaning representations (SMUs) and from large language models (SGUs), respectively. We find that ",
    "path": "papers/24/04/2404.01701.json",
    "total_tokens": 868,
    "translated_title": "论文摘要中总结内容单元在文本摘要评估中的作用",
    "translated_abstract": "金字塔评估方法的核心是人类撰写的总结内容单元（SCUs）。这些SCUs是简洁的句子，将一个摘要分解为小事实。这些SCUs可以用来评判候选摘要的质量，可能通过自然语言推理（NLI）系统部分自动化。有趣的是，为了完全自动化金字塔评估，Zhang和Bansal（2021）表明SCUs可以通过自动生成的语义角色三元组（STUs）来近似。然而，目前还有一些问题没有答案，特别是：i）是否有其他逼近SCUs的方式能够提供优势？ii）在哪些条件下SCUs（或它们的近似）提供最大价值？在这项工作中，我们研究了两种新颖的策略来逼近SCUs：分别从AMR意义表示（SMUs）和大型语言模型（SGUs）生成SCU近似。我们发现",
    "tldr": "本研究探讨了两种新颖策略来逼近摘要内容单元（SCUs），分别是从AMR意义表示（SMUs）和大型语言模型（SGUs）生成SCU近似。",
    "en_tdlr": "This study examines two novel strategies to approximate Summary Content Units (SCUs) by generating SCU approximations from AMR meaning representations (SMUs) and large language models (SGUs)."
}