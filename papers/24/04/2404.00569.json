{
    "title": "CM-TTS: Enhancing Real Time Text-to-Speech Synthesis Efficiency through Weighted Samplers and Consistency Models",
    "abstract": "arXiv:2404.00569v1 Announce Type: cross  Abstract: Neural Text-to-Speech (TTS) systems find broad applications in voice assistants, e-learning, and audiobook creation. The pursuit of modern models, like Diffusion Models (DMs), holds promise for achieving high-fidelity, real-time speech synthesis. Yet, the efficiency of multi-step sampling in Diffusion Models presents challenges. Efforts have been made to integrate GANs with DMs, speeding up inference by approximating denoising distributions, but this introduces issues with model convergence due to adversarial training. To overcome this, we introduce CM-TTS, a novel architecture grounded in consistency models (CMs). Drawing inspiration from continuous-time diffusion models, CM-TTS achieves top-quality speech synthesis in fewer steps without adversarial training or pre-trained model dependencies. We further design weighted samplers to incorporate different sampling positions into model training with dynamic probabilities, ensuring unbias",
    "link": "https://arxiv.org/abs/2404.00569",
    "context": "Title: CM-TTS: Enhancing Real Time Text-to-Speech Synthesis Efficiency through Weighted Samplers and Consistency Models\nAbstract: arXiv:2404.00569v1 Announce Type: cross  Abstract: Neural Text-to-Speech (TTS) systems find broad applications in voice assistants, e-learning, and audiobook creation. The pursuit of modern models, like Diffusion Models (DMs), holds promise for achieving high-fidelity, real-time speech synthesis. Yet, the efficiency of multi-step sampling in Diffusion Models presents challenges. Efforts have been made to integrate GANs with DMs, speeding up inference by approximating denoising distributions, but this introduces issues with model convergence due to adversarial training. To overcome this, we introduce CM-TTS, a novel architecture grounded in consistency models (CMs). Drawing inspiration from continuous-time diffusion models, CM-TTS achieves top-quality speech synthesis in fewer steps without adversarial training or pre-trained model dependencies. We further design weighted samplers to incorporate different sampling positions into model training with dynamic probabilities, ensuring unbias",
    "path": "papers/24/04/2404.00569.json",
    "total_tokens": 897,
    "translated_title": "CM-TTS: 通过加权采样器和一致性模型提高实时文本转语音合成效率",
    "translated_abstract": "神经文本转语音（TTS）系统在语音助手、电子学习和有声读物制作等领域具有广泛应用。现代模型的追求，如扩散模型（DMs），有望实现高保真、实时的语音合成。然而，扩散模型中多步采样的效率存在挑战。已经做出努力将GANs与DMs集成在一起，通过逼近去噪分布加快推断速度，但这由于对抗训练导致模型收敛出现问题。为了克服这些问题，我们提出了CM-TTS，这是一种基于一致性模型（CMs）的新型体系结构。CM-TTS汲取了连续时间扩散模型的灵感，在较少步骤中实现了高质量的语音合成，而无需进行对抗训练或依赖预训练模型。我们进一步设计了加权采样器，以动态概率将不同采样位置纳入模型训练，确保不偏倚。",
    "tldr": "CM-TTS通过一致性模型和加权采样器实现了更高效的实时文本转语音合成，避免了对抗训练和预训练模型的依赖。"
}