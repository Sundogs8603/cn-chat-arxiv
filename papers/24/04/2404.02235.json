{
    "title": "Is Exploration All You Need? Effective Exploration Characteristics for Transfer in Reinforcement Learning",
    "abstract": "arXiv:2404.02235v1 Announce Type: cross  Abstract: In deep reinforcement learning (RL) research, there has been a concerted effort to design more efficient and productive exploration methods while solving sparse-reward problems. These exploration methods often share common principles (e.g., improving diversity) and implementation details (e.g., intrinsic reward). Prior work found that non-stationary Markov decision processes (MDPs) require exploration to efficiently adapt to changes in the environment with online transfer learning. However, the relationship between specific exploration characteristics and effective transfer learning in deep RL has not been characterized. In this work, we seek to understand the relationships between salient exploration characteristics and improved performance and efficiency in transfer learning. We test eleven popular exploration algorithms on a variety of transfer types -- or ``novelties'' -- to identify the characteristics that positively affect onlin",
    "link": "https://arxiv.org/abs/2404.02235",
    "context": "Title: Is Exploration All You Need? Effective Exploration Characteristics for Transfer in Reinforcement Learning\nAbstract: arXiv:2404.02235v1 Announce Type: cross  Abstract: In deep reinforcement learning (RL) research, there has been a concerted effort to design more efficient and productive exploration methods while solving sparse-reward problems. These exploration methods often share common principles (e.g., improving diversity) and implementation details (e.g., intrinsic reward). Prior work found that non-stationary Markov decision processes (MDPs) require exploration to efficiently adapt to changes in the environment with online transfer learning. However, the relationship between specific exploration characteristics and effective transfer learning in deep RL has not been characterized. In this work, we seek to understand the relationships between salient exploration characteristics and improved performance and efficiency in transfer learning. We test eleven popular exploration algorithms on a variety of transfer types -- or ``novelties'' -- to identify the characteristics that positively affect onlin",
    "path": "papers/24/04/2404.02235.json",
    "total_tokens": 842,
    "translated_title": "探索是您需要的全部内容吗？用于强化学习中转移的有效探索特征",
    "translated_abstract": "在深度强化学习（RL）研究中，人们正在努力设计更高效、更具生产力的探索方法，同时解决稀疏奖励问题。这些探索方法通常共享共同原则（例如改善多样性）和实现细节（例如内在奖励）。先前的研究发现，非静止马尔可夫决策过程（MDP）需要探索，以便有效地适应在线转移学习中环境的变化。然而，具体探索特征与在深度RL中的有效转移学习之间的关系尚未被表征。在这项工作中，我们试图理解显著探索特征与改进性能和效率在转移学习中的关系。我们测试了十一个流行的探索算法，针对各种转移类型进行测试，以确定那些积极影响在线",
    "tldr": "探索特征与深度强化学习中有效的转移学习的关系，尚未被明确表征。研究试图理解探索特征与改进性能和效率在转移学习中的关系",
    "en_tdlr": "The relationship between specific exploration characteristics and effective transfer learning in deep RL has not been characterized. The study aims to understand the relationships between salient exploration characteristics and improved performance and efficiency in transfer learning."
}