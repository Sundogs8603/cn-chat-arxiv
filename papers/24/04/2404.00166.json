{
    "title": "Uncovering Bias in Large Vision-Language Models with Counterfactuals",
    "abstract": "arXiv:2404.00166v1 Announce Type: cross  Abstract: With the advent of Large Language Models (LLMs) possessing increasingly impressive capabilities, a number of Large Vision-Language Models (LVLMs) have been proposed to augment LLMs with visual inputs. Such models condition generated text on both an input image and a text prompt, enabling a variety of use cases such as visual question answering and multimodal chat. While prior studies have examined the social biases contained in text generated by LLMs, this topic has been relatively unexplored in LVLMs. Examining social biases in LVLMs is particularly challenging due to the confounding contributions of bias induced by information contained across the text and visual modalities. To address this challenging problem, we conduct a large-scale study of text generated by different LVLMs under counterfactual changes to input images. Specifically, we present LVLMs with identical open-ended text prompts while conditioning on images from differen",
    "link": "https://arxiv.org/abs/2404.00166",
    "context": "Title: Uncovering Bias in Large Vision-Language Models with Counterfactuals\nAbstract: arXiv:2404.00166v1 Announce Type: cross  Abstract: With the advent of Large Language Models (LLMs) possessing increasingly impressive capabilities, a number of Large Vision-Language Models (LVLMs) have been proposed to augment LLMs with visual inputs. Such models condition generated text on both an input image and a text prompt, enabling a variety of use cases such as visual question answering and multimodal chat. While prior studies have examined the social biases contained in text generated by LLMs, this topic has been relatively unexplored in LVLMs. Examining social biases in LVLMs is particularly challenging due to the confounding contributions of bias induced by information contained across the text and visual modalities. To address this challenging problem, we conduct a large-scale study of text generated by different LVLMs under counterfactual changes to input images. Specifically, we present LVLMs with identical open-ended text prompts while conditioning on images from differen",
    "path": "papers/24/04/2404.00166.json",
    "total_tokens": 868,
    "translated_title": "通过反事实来揭示大规模视觉-语言模型中的偏见",
    "translated_abstract": "随着拥有越来越令人印象深刻能力的大型语言模型（LLMs）的出现，提出了许多大型视觉-语言模型（LVLMs）来利用视觉输入增强LLMs。这些模型在生成文本时同时条件于输入图像和文本提示，实现了各种用例，如视觉问答和多模态聊天。尽管先前的研究已经考察了LLMs生成的文本中包含的社会偏见，但在LVLMs中相对较少探讨了这个问题。由于文本和视觉模态中包含的信息引起的偏见相互交叉，检查LVLMs中的社会偏见尤其具有挑战性。为了解决这个具有挑战性的问题，我们对不同LVLMs生成的文本进行了大规模研究，通过对输入图像进行反事实变化。具体来说，我们向LVLMs呈现相同的开放式文本提示，同时在不同的图像条件下进行。",
    "tldr": "通过对输入图像进行反事实变化，我们对不同大规模视觉-语言模型生成的文本进行了研究，以揭示其中的社会偏见。",
    "en_tdlr": "We conduct a large-scale study of text generated by different Large Vision-Language Models (LVLMs) under counterfactual changes to input images to uncover social biases contained in the generated text."
}