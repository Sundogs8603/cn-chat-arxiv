{
    "title": "AILS-NTUA at SemEval-2024 Task 6: Efficient model tuning for hallucination detection and analysis",
    "abstract": "arXiv:2404.01210v1 Announce Type: new  Abstract: In this paper, we present our team's submissions for SemEval-2024 Task-6 - SHROOM, a Shared-task on Hallucinations and Related Observable Overgeneration Mistakes. The participants were asked to perform binary classification to identify cases of fluent overgeneration hallucinations. Our experimentation included fine-tuning a pre-trained model on hallucination detection and a Natural Language Inference (NLI) model. The most successful strategy involved creating an ensemble of these models, resulting in accuracy rates of 77.8% and 79.9% on model-agnostic and model-aware datasets respectively, outperforming the organizers' baseline and achieving notable results when contrasted with the top-performing results in the competition, which reported accuracies of 84.7% and 81.3% correspondingly.",
    "link": "https://arxiv.org/abs/2404.01210",
    "context": "Title: AILS-NTUA at SemEval-2024 Task 6: Efficient model tuning for hallucination detection and analysis\nAbstract: arXiv:2404.01210v1 Announce Type: new  Abstract: In this paper, we present our team's submissions for SemEval-2024 Task-6 - SHROOM, a Shared-task on Hallucinations and Related Observable Overgeneration Mistakes. The participants were asked to perform binary classification to identify cases of fluent overgeneration hallucinations. Our experimentation included fine-tuning a pre-trained model on hallucination detection and a Natural Language Inference (NLI) model. The most successful strategy involved creating an ensemble of these models, resulting in accuracy rates of 77.8% and 79.9% on model-agnostic and model-aware datasets respectively, outperforming the organizers' baseline and achieving notable results when contrasted with the top-performing results in the competition, which reported accuracies of 84.7% and 81.3% correspondingly.",
    "path": "papers/24/04/2404.01210.json",
    "total_tokens": 860,
    "translated_title": "AILS-NTUA参加SemEval-2024任务6：用于幻觉检测和分析的高效模型调优",
    "translated_abstract": "在本文中，我们介绍了我们团队针对SemEval-2024任务6 - SHROOM的提交内容，这是一个关于幻觉和相关可观测过度生成错误的共享任务。参与者被要求进行二元分类，以识别流利过度生成的幻觉案例。我们的实验包括对幻觉检测和自然语言推理（NLI）模型进行微调。最成功的策略涉及创建这些模型的集成，结果在模型不可知和模型感知数据集上的准确率分别为77.8％和79.9％，超过了组织者的基线，并在与竞赛中表现最佳的结果进行对比时取得显着成果，该竞赛报告的准确率分别为84.7％和81.3％。",
    "tldr": "该论文提出了一种高效的模型调优策略，通过将预训练模型和自然语言推理模型进行集成，成功在幻觉检测任务中取得了77.8%和79.9%的准确率，优于组织者的基线和竞赛中其他参赛者的表现。",
    "en_tdlr": "This paper presents an efficient model tuning strategy by integrating pre-trained and natural language inference models, achieving accuracy rates of 77.8% and 79.9% in hallucination detection task, outperforming the organizers' baseline and other competitors in the competition."
}