{
    "title": "Edinburgh Clinical NLP at SemEval-2024 Task 2: Fine-tune your model unless you have access to GPT-4",
    "abstract": "arXiv:2404.00484v1 Announce Type: new  Abstract: The NLI4CT task assesses Natural Language Inference systems in predicting whether hypotheses entail or contradict evidence from Clinical Trial Reports. In this study, we evaluate various Large Language Models (LLMs) with multiple strategies, including Chain-of-Thought, In-Context Learning, and Parameter-Efficient Fine-Tuning (PEFT). We propose a PEFT method to improve the consistency of LLMs by merging adapters that were fine-tuned separately using triplet and language modelling objectives. We found that merging the two PEFT adapters improves the F1 score (+0.0346) and consistency (+0.152) of the LLMs. However, our novel methods did not produce more accurate results than GPT-4 in terms of faithfulness and consistency. Averaging the three metrics, GPT-4 ranks joint-first in the competition with 0.8328. Finally, our contamination analysis with GPT-4 indicates that there was no test data leakage.",
    "link": "https://arxiv.org/abs/2404.00484",
    "context": "Title: Edinburgh Clinical NLP at SemEval-2024 Task 2: Fine-tune your model unless you have access to GPT-4\nAbstract: arXiv:2404.00484v1 Announce Type: new  Abstract: The NLI4CT task assesses Natural Language Inference systems in predicting whether hypotheses entail or contradict evidence from Clinical Trial Reports. In this study, we evaluate various Large Language Models (LLMs) with multiple strategies, including Chain-of-Thought, In-Context Learning, and Parameter-Efficient Fine-Tuning (PEFT). We propose a PEFT method to improve the consistency of LLMs by merging adapters that were fine-tuned separately using triplet and language modelling objectives. We found that merging the two PEFT adapters improves the F1 score (+0.0346) and consistency (+0.152) of the LLMs. However, our novel methods did not produce more accurate results than GPT-4 in terms of faithfulness and consistency. Averaging the three metrics, GPT-4 ranks joint-first in the competition with 0.8328. Finally, our contamination analysis with GPT-4 indicates that there was no test data leakage.",
    "path": "papers/24/04/2404.00484.json",
    "total_tokens": 954,
    "translated_title": "SemEval-2024任务2中的爱丁堡临床NLP：Fine-tune your model unless you have access to GPT-4",
    "translated_abstract": "NLI4CT任务评估自然语言推理系统在预测假设是否包含或与临床试验报告中的证据相矛盾方面的表现。本研究评估了多种大型语言模型（LLMs）并采用多种策略，包括思维链、上下文学习和参数高效微调（PEFT）。我们提出了一种PEFT方法，通过合并分别使用三元组和语言建模目标进行微调的适配器来提高LLMs的一致性。我们发现合并两个PEFT适配器可以提高LLMs的F1分数（+0.0346）和一致性（+0.152）。然而，我们的新方法未能产生比GPT-4更准确的结果，无论是在忠实度还是一致性方面。综合三个指标，GPT-4在竞赛中以0.8328的得分并列第一。最后，我们与GPT-4的污染分析显示没有测试数据泄露。",
    "tldr": "本研究提出了一种参数高效微调（PEFT）方法，通过合并分别使用三元组和语言建模目标进行微调的适配器来提高大型语言模型（LLMs）的一致性，但未能超越GPT-4在忠实度和一致性方面的准确性。"
}