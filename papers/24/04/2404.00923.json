{
    "title": "MM3DGS SLAM: Multi-modal 3D Gaussian Splatting for SLAM Using Vision, Depth, and Inertial Measurements",
    "abstract": "arXiv:2404.00923v1 Announce Type: cross  Abstract: Simultaneous localization and mapping is essential for position tracking and scene understanding. 3D Gaussian-based map representations enable photorealistic reconstruction and real-time rendering of scenes using multiple posed cameras. We show for the first time that using 3D Gaussians for map representation with unposed camera images and inertial measurements can enable accurate SLAM. Our method, MM3DGS, addresses the limitations of prior neural radiance field-based representations by enabling faster rendering, scale awareness, and improved trajectory tracking. Our framework enables keyframe-based mapping and tracking utilizing loss functions that incorporate relative pose transformations from pre-integrated inertial measurements, depth estimates, and measures of photometric rendering quality. We also release a multi-modal dataset, UT-MM, collected from a mobile robot equipped with a camera and an inertial measurement unit. Experimen",
    "link": "https://arxiv.org/abs/2404.00923",
    "context": "Title: MM3DGS SLAM: Multi-modal 3D Gaussian Splatting for SLAM Using Vision, Depth, and Inertial Measurements\nAbstract: arXiv:2404.00923v1 Announce Type: cross  Abstract: Simultaneous localization and mapping is essential for position tracking and scene understanding. 3D Gaussian-based map representations enable photorealistic reconstruction and real-time rendering of scenes using multiple posed cameras. We show for the first time that using 3D Gaussians for map representation with unposed camera images and inertial measurements can enable accurate SLAM. Our method, MM3DGS, addresses the limitations of prior neural radiance field-based representations by enabling faster rendering, scale awareness, and improved trajectory tracking. Our framework enables keyframe-based mapping and tracking utilizing loss functions that incorporate relative pose transformations from pre-integrated inertial measurements, depth estimates, and measures of photometric rendering quality. We also release a multi-modal dataset, UT-MM, collected from a mobile robot equipped with a camera and an inertial measurement unit. Experimen",
    "path": "papers/24/04/2404.00923.json",
    "total_tokens": 922,
    "translated_title": "MM3DGS SLAM: 利用视觉、深度和惯性测量的多模态3D高斯雨滴法SLAM",
    "translated_abstract": "同步定位与建图对于位置跟踪和场景理解至关重要。基于3D高斯的地图表示使得能够利用多姿态相机实现逼真重建和实时渲染场景。我们首次展示，利用3D高斯进行地图表示，并结合未定位相机图像和惯性测量，可以实现准确的SLAM。我们的方法MM3DGS通过实现更快的渲染、尺度感知和改进的轨迹跟踪，解决了先前基于神经辐射场的表示法的局限性。我们的框架实现了基于关键帧的建图和跟踪，利用包含相对姿态变换的损失函数，这些姿态变换来自预积分的惯性测量、深度估计和光度渲染质量的度量。我们还发布了一个多模态数据集UT-MM，该数据集由配备相机和惯性测量单元的移动机器人收集而成。",
    "tldr": "使用多模态3D高斯雨滴法SLAM可以结合未定位相机图像和惯性测量，实现准确的地图建立和轨迹跟踪，具有更快的渲染速度、尺度感知性和改进的轨迹追踪能力。",
    "en_tdlr": "MM3DGS SLAM utilizes multi-modal 3D Gaussian splatting with unposed camera images and inertial measurements for accurate map building and trajectory tracking, offering faster rendering, scale awareness, and improved trajectory tracking."
}