{
    "title": "AD4RL: Autonomous Driving Benchmarks for Offline Reinforcement Learning with Value-based Dataset",
    "abstract": "arXiv:2404.02429v1 Announce Type: cross  Abstract: Offline reinforcement learning has emerged as a promising technology by enhancing its practicality through the use of pre-collected large datasets. Despite its practical benefits, most algorithm development research in offline reinforcement learning still relies on game tasks with synthetic datasets. To address such limitations, this paper provides autonomous driving datasets and benchmarks for offline reinforcement learning research. We provide 19 datasets, including real-world human driver's datasets, and seven popular offline reinforcement learning algorithms in three realistic driving scenarios. We also provide a unified decision-making process model that can operate effectively across different scenarios, serving as a reference framework in algorithm design. Our research lays the groundwork for further collaborations in the community to explore practical aspects of existing reinforcement learning methods. Dataset and codes can be ",
    "link": "https://arxiv.org/abs/2404.02429",
    "context": "Title: AD4RL: Autonomous Driving Benchmarks for Offline Reinforcement Learning with Value-based Dataset\nAbstract: arXiv:2404.02429v1 Announce Type: cross  Abstract: Offline reinforcement learning has emerged as a promising technology by enhancing its practicality through the use of pre-collected large datasets. Despite its practical benefits, most algorithm development research in offline reinforcement learning still relies on game tasks with synthetic datasets. To address such limitations, this paper provides autonomous driving datasets and benchmarks for offline reinforcement learning research. We provide 19 datasets, including real-world human driver's datasets, and seven popular offline reinforcement learning algorithms in three realistic driving scenarios. We also provide a unified decision-making process model that can operate effectively across different scenarios, serving as a reference framework in algorithm design. Our research lays the groundwork for further collaborations in the community to explore practical aspects of existing reinforcement learning methods. Dataset and codes can be ",
    "path": "papers/24/04/2404.02429.json",
    "total_tokens": 906,
    "translated_title": "AD4RL：具有基于价值数据集的离线强化学习的自动驾驶基准测试",
    "translated_abstract": "离线强化学习通过利用预先收集的大型数据集，已成为一项具有潜力的技术。尽管离线强化学习的实际好处已被增强，但大多数离线强化学习的算法开发研究仍依赖于具有合成数据集的游戏任务。为了解决这些限制，本文提供了用于离线强化学习研究的自动驾驶数据集和基准测试。我们提供了19个数据集，包括真实世界人类驾驶员的数据集，以及三种实际驾驶场景中的七种流行的离线强化学习算法。我们还提供了一个统一的决策过程模型，可以在不同场景中有效运行，作为算法设计的参考框架。我们的研究为社区进一步探索现有强化学习方法的实际方面奠定了基础。",
    "tldr": "本文提供了用于离线强化学习研究的自动驾驶数据集和基准测试，包括真实世界人类驾驶员的数据集，以及七种离线强化学习算法在三种实际驾驶场景中的应用，并提供了一个统一决策模型作为算法设计的参考框架。",
    "en_tdlr": "This paper introduces autonomous driving datasets and benchmarks for offline reinforcement learning research, including real-world human driver's datasets, the application of seven popular offline reinforcement learning algorithms in three realistic driving scenarios, and a unified decision-making model as a reference framework for algorithm design."
}