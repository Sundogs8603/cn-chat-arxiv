{
    "title": "Predictive Performance Comparison of Decision Policies Under Confounding",
    "abstract": "arXiv:2404.00848v1 Announce Type: new  Abstract: Predictive models are often introduced to decision-making tasks under the rationale that they improve performance over an existing decision-making policy. However, it is challenging to compare predictive performance against an existing decision-making policy that is generally under-specified and dependent on unobservable factors. These sources of uncertainty are often addressed in practice by making strong assumptions about the data-generating mechanism. In this work, we propose a method to compare the predictive performance of decision policies under a variety of modern identification approaches from the causal inference and off-policy evaluation literatures (e.g., instrumental variable, marginal sensitivity model, proximal variable). Key to our method is the insight that there are regions of uncertainty that we can safely ignore in the policy comparison. We develop a practical approach for finite-sample estimation of regret intervals u",
    "link": "https://arxiv.org/abs/2404.00848",
    "context": "Title: Predictive Performance Comparison of Decision Policies Under Confounding\nAbstract: arXiv:2404.00848v1 Announce Type: new  Abstract: Predictive models are often introduced to decision-making tasks under the rationale that they improve performance over an existing decision-making policy. However, it is challenging to compare predictive performance against an existing decision-making policy that is generally under-specified and dependent on unobservable factors. These sources of uncertainty are often addressed in practice by making strong assumptions about the data-generating mechanism. In this work, we propose a method to compare the predictive performance of decision policies under a variety of modern identification approaches from the causal inference and off-policy evaluation literatures (e.g., instrumental variable, marginal sensitivity model, proximal variable). Key to our method is the insight that there are regions of uncertainty that we can safely ignore in the policy comparison. We develop a practical approach for finite-sample estimation of regret intervals u",
    "path": "papers/24/04/2404.00848.json",
    "total_tokens": 803,
    "translated_title": "决策政策在混杂情况下的预测性能比较",
    "translated_abstract": "预测模型通常被引入决策任务中，其基本理念是它们可以提升决策政策的性能。然而，与通常存在于未明确规定和依赖不可观测因素的现有决策政策相比较预测性能是具有挑战性的。这些不确定性来源通常在实践中被通过对数据生成机制进行强假设来处理。在这项研究中，我们提出了一种方法，来比较决策政策的预测性能，根据因果推断和离线评估文献中的各种现代识别方法进行评估（例如，工具变量，边际敏感性模型，近端变量）。我们的方法的关键是我们可以安全地忽略政策比较中的不确定性区域。我们开发了一种有限样本估计遗憾区间的实用方法。",
    "tldr": "提出了一种方法，通过现代识别方法比较决策政策的预测性能，关键在于可以安全忽略不确定性区域。"
}