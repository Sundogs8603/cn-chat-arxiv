{
    "title": "Token-Efficient Leverage Learning in Large Language Models",
    "abstract": "arXiv:2404.00914v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have excelled in various tasks but perform better in high-resource scenarios, which presents challenges in low-resource scenarios. Data scarcity and the inherent difficulty of adapting LLMs to specific tasks compound the challenge. To address the twin hurdles, we introduce \\textbf{Leverage Learning}. We present a streamlined implement of this methodology called Token-Efficient Leverage Learning (TELL). TELL showcases the potential of Leverage Learning, demonstrating effectiveness across various LLMs and low-resource tasks, ranging from $10^4$ to $10^6$ tokens. It reduces task data requirements by up to nearly an order of magnitude compared to conventional Supervised Fine-Tuning (SFT) while delivering competitive performance. With the same amount of task data, TELL leads in improving task performance compared to SFT. We discuss the mechanism of Leverage Learning, suggesting it aligns with quantization hypoth",
    "link": "https://arxiv.org/abs/2404.00914",
    "context": "Title: Token-Efficient Leverage Learning in Large Language Models\nAbstract: arXiv:2404.00914v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have excelled in various tasks but perform better in high-resource scenarios, which presents challenges in low-resource scenarios. Data scarcity and the inherent difficulty of adapting LLMs to specific tasks compound the challenge. To address the twin hurdles, we introduce \\textbf{Leverage Learning}. We present a streamlined implement of this methodology called Token-Efficient Leverage Learning (TELL). TELL showcases the potential of Leverage Learning, demonstrating effectiveness across various LLMs and low-resource tasks, ranging from $10^4$ to $10^6$ tokens. It reduces task data requirements by up to nearly an order of magnitude compared to conventional Supervised Fine-Tuning (SFT) while delivering competitive performance. With the same amount of task data, TELL leads in improving task performance compared to SFT. We discuss the mechanism of Leverage Learning, suggesting it aligns with quantization hypoth",
    "path": "papers/24/04/2404.00914.json",
    "total_tokens": 870,
    "translated_title": "大型语言模型中的高效令牌利用学习",
    "translated_abstract": "大型语言模型（LLMs）在各种任务中表现出色，但在高资源场景中表现更佳，这在低资源场景中存在挑战。数据稀缺和LLMs适应特定任务固有的困难加剧了这一挑战。为了解决这两大难题，我们引入了\\textbf{Leverage Learning}。我们提出了这一方法的简化实现，称为Token-Efficient Leverage Learning (TELL)。TELL展示了Leverage Learning的潜力，证明它在各种LLMs和低资源任务中的有效性，从$10^4$到$10^6$个令牌不等。与传统的监督微调（SFT）相比，它将任务数据需求降低了近一个数量级，同时提供竞争力的性能。在相同量的任务数据情况下，TELL在改善任务性能方面领先于SFT。我们讨论了Leverage Learning的机制，暗示其符合量化假设。",
    "tldr": "介绍了一种名为Token-Efficient Leverage Learning（TELL）的方法，在大型语言模型中展示了其降低任务数据需求、提高任务性能的潜力，为低资源任务带来了竞争性能。",
    "en_tdlr": "Introduced Token-Efficient Leverage Learning (TELL) method, showcasing its potential in reducing task data requirements and improving task performance in large language models, delivering competitive performance for low-resource tasks."
}