{
    "title": "Learning Intersections of Halfspaces with Distribution Shift: Improved Algorithms and SQ Lower Bounds",
    "abstract": "arXiv:2404.02364v1 Announce Type: cross  Abstract: Recent work of Klivans, Stavropoulos, and Vasilyan initiated the study of testable learning with distribution shift (TDS learning), where a learner is given labeled samples from training distribution $\\mathcal{D}$, unlabeled samples from test distribution $\\mathcal{D}'$, and the goal is to output a classifier with low error on $\\mathcal{D}'$ whenever the training samples pass a corresponding test. Their model deviates from all prior work in that no assumptions are made on $\\mathcal{D}'$. Instead, the test must accept (with high probability) when the marginals of the training and test distributions are equal.   Here we focus on the fundamental case of intersections of halfspaces with respect to Gaussian training distributions and prove a variety of new upper bounds including a $2^{(k/\\epsilon)^{O(1)}} \\mathsf{poly}(d)$-time algorithm for TDS learning intersections of $k$ homogeneous halfspaces to accuracy $\\epsilon$ (prior work achieved",
    "link": "https://arxiv.org/abs/2404.02364",
    "context": "Title: Learning Intersections of Halfspaces with Distribution Shift: Improved Algorithms and SQ Lower Bounds\nAbstract: arXiv:2404.02364v1 Announce Type: cross  Abstract: Recent work of Klivans, Stavropoulos, and Vasilyan initiated the study of testable learning with distribution shift (TDS learning), where a learner is given labeled samples from training distribution $\\mathcal{D}$, unlabeled samples from test distribution $\\mathcal{D}'$, and the goal is to output a classifier with low error on $\\mathcal{D}'$ whenever the training samples pass a corresponding test. Their model deviates from all prior work in that no assumptions are made on $\\mathcal{D}'$. Instead, the test must accept (with high probability) when the marginals of the training and test distributions are equal.   Here we focus on the fundamental case of intersections of halfspaces with respect to Gaussian training distributions and prove a variety of new upper bounds including a $2^{(k/\\epsilon)^{O(1)}} \\mathsf{poly}(d)$-time algorithm for TDS learning intersections of $k$ homogeneous halfspaces to accuracy $\\epsilon$ (prior work achieved",
    "path": "papers/24/04/2404.02364.json",
    "total_tokens": 878,
    "translated_title": "学习与分布偏移的半空间交集：改进算法和SQ下界",
    "translated_abstract": "Klivans、Stavropoulos和Vasilyan最近的工作引发了对具有分布偏移的可测试学习（TDS学习）的研究，其中学习者从训练分布$\\mathcal{D}$获得标记样本，从测试分布$\\mathcal{D}'$获得未标记样本，目标是在训练样本通过相应的测试时输出在$\\mathcal{D}'$上具有低误差的分类器。他们的模型不同于先前的所有工作，因为$\\mathcal{D}'$上没有假设。相反，当训练和测试分布的边际相等时，测试必须接受（以高概率）。",
    "tldr": "研究学习与分布偏移的交集问题，在基于高斯训练分布的情况下，证明了一系列新的上界，包括一种TDS学习$k$个齐次半空间交集达到精度$\\epsilon$的$2^{(k/\\epsilon)^{O(1)}} \\mathsf{poly}(d)$时间算法（在先前的工作中）。",
    "en_tdlr": "Studying intersections of halfspaces with distribution shift, new upper bounds are proven including a $2^{(k/\\epsilon)^{O(1)}} \\mathsf{poly}(d)$-time algorithm for TDS learning intersections of $k$ homogeneous halfspaces to accuracy $\\epsilon\" with respect to Gaussian training distributions."
}