{
    "title": "DIBS: Enhancing Dense Video Captioning with Unlabeled Videos via Pseudo Boundary Enrichment and Online Refinement",
    "abstract": "arXiv:2404.02755v1 Announce Type: cross  Abstract: We present Dive Into the BoundarieS (DIBS), a novel pretraining framework for dense video captioning (DVC), that elaborates on improving the quality of the generated event captions and their associated pseudo event boundaries from unlabeled videos. By leveraging the capabilities of diverse large language models (LLMs), we generate rich DVC-oriented caption candidates and optimize the corresponding pseudo boundaries under several meticulously designed objectives, considering diversity, event-centricity, temporal ordering, and coherence. Moreover, we further introduce a novel online boundary refinement strategy that iteratively improves the quality of pseudo boundaries during training. Comprehensive experiments have been conducted to examine the effectiveness of the proposed technique components. By leveraging a substantial amount of unlabeled video data, such as HowTo100M, we achieve a remarkable advancement on standard DVC datasets lik",
    "link": "https://arxiv.org/abs/2404.02755",
    "context": "Title: DIBS: Enhancing Dense Video Captioning with Unlabeled Videos via Pseudo Boundary Enrichment and Online Refinement\nAbstract: arXiv:2404.02755v1 Announce Type: cross  Abstract: We present Dive Into the BoundarieS (DIBS), a novel pretraining framework for dense video captioning (DVC), that elaborates on improving the quality of the generated event captions and their associated pseudo event boundaries from unlabeled videos. By leveraging the capabilities of diverse large language models (LLMs), we generate rich DVC-oriented caption candidates and optimize the corresponding pseudo boundaries under several meticulously designed objectives, considering diversity, event-centricity, temporal ordering, and coherence. Moreover, we further introduce a novel online boundary refinement strategy that iteratively improves the quality of pseudo boundaries during training. Comprehensive experiments have been conducted to examine the effectiveness of the proposed technique components. By leveraging a substantial amount of unlabeled video data, such as HowTo100M, we achieve a remarkable advancement on standard DVC datasets lik",
    "path": "papers/24/04/2404.02755.json",
    "total_tokens": 907,
    "translated_title": "通过伪边界丰富和在线细化提高无标注视频的密集视频字幕质量的 DIBS: 用未标的视频增强密集视频字幕",
    "translated_abstract": "我们提出了 Dive Into the BoundarieS (DIBS)，这是一种新颖的用于密集视频字幕（DVC）的预训练框架，详细阐述了如何从未标记的视频中提高生成的事件字幕及其关联伪事件边界的质量。通过利用不同大型语言模型（LLMs）的能力，我们生成丰富的面向DVC的字幕候选项，并根据几个精心设计的目标优化相应的伪边界，考虑到多样性、事件中心性、时间排序和连贯性。此外，我们还引入了一种新颖的在线边界细化策略，迭代地在训练过程中提高伪边界的质量。我们进行了全面的实验，来检验所提出技术组件的有效性。通过利用大量未标记的视频数据，如 HowTo100M，我们在标准的 DVC 数据集上实现了显著的进展。",
    "tldr": "DIBS是一种用于密集视频字幕（DVC）的预训练框架，通过优化生成的事件字幕和伪事件边界的质量，并引入在线边界细化策略，显著提高了在未标注视频上的效果。",
    "en_tdlr": "DIBS is a pretraining framework for dense video captioning (DVC) that enhances the quality of generated event captions and pseudo event boundaries, and introduces an online boundary refinement strategy, achieving significant improvement on unlabeled videos."
}