{
    "title": "OOSTraj: Out-of-Sight Trajectory Prediction With Vision-Positioning Denoising",
    "abstract": "arXiv:2404.02227v1 Announce Type: cross  Abstract: Trajectory prediction is fundamental in computer vision and autonomous driving, particularly for understanding pedestrian behavior and enabling proactive decision-making. Existing approaches in this field often assume precise and complete observational data, neglecting the challenges associated with out-of-view objects and the noise inherent in sensor data due to limited camera range, physical obstructions, and the absence of ground truth for denoised sensor data. Such oversights are critical safety concerns, as they can result in missing essential, non-visible objects. To bridge this gap, we present a novel method for out-of-sight trajectory prediction that leverages a vision-positioning technique. Our approach denoises noisy sensor observations in an unsupervised manner and precisely maps sensor-based trajectories of out-of-sight objects into visual trajectories. This method has demonstrated state-of-the-art performance in out-of-sig",
    "link": "https://arxiv.org/abs/2404.02227",
    "context": "Title: OOSTraj: Out-of-Sight Trajectory Prediction With Vision-Positioning Denoising\nAbstract: arXiv:2404.02227v1 Announce Type: cross  Abstract: Trajectory prediction is fundamental in computer vision and autonomous driving, particularly for understanding pedestrian behavior and enabling proactive decision-making. Existing approaches in this field often assume precise and complete observational data, neglecting the challenges associated with out-of-view objects and the noise inherent in sensor data due to limited camera range, physical obstructions, and the absence of ground truth for denoised sensor data. Such oversights are critical safety concerns, as they can result in missing essential, non-visible objects. To bridge this gap, we present a novel method for out-of-sight trajectory prediction that leverages a vision-positioning technique. Our approach denoises noisy sensor observations in an unsupervised manner and precisely maps sensor-based trajectories of out-of-sight objects into visual trajectories. This method has demonstrated state-of-the-art performance in out-of-sig",
    "path": "papers/24/04/2404.02227.json",
    "total_tokens": 861,
    "translated_title": "OOSTraj：利用视觉定位去噪的视界轨迹预测",
    "translated_abstract": "轨迹预测在计算机视觉和自动驾驶中是基础性的，特别是为了理解行人行为和实现积极决策。现有的方法往往假设精确完整的观测数据，忽视了与视野外物体和由于有限摄像头范围、物理障碍以及缺乏去噪传感器数据的真实数据相关的挑战。这样的偏见是关键的安全问题，因为这可能导致关键的非可见对象被忽略。为了弥补这一差距，我们提出了一种利用视觉定位技术进行视界轨迹预测的新方法。我们的方法以无监督方式去噪嘈杂的传感器观测，并将视野外物体的传感器轨迹精确映射到视觉轨迹中。这种方法在视野外轨迹预测方面展现了最先进的性能。",
    "tldr": "提出了一种利用视觉定位技术进行视界轨迹预测的新方法，可以有效地解决视野外物体和传感器数据噪声的挑战，达到了最先进的性能。",
    "en_tdlr": "Proposed a novel method for out-of-sight trajectory prediction leveraging vision-positioning technique that effectively addresses challenges of out-of-view objects and sensor data noise, achieving state-of-the-art performance."
}