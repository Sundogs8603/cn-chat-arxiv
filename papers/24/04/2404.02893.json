{
    "title": "ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline",
    "abstract": "arXiv:2404.02893v1 Announce Type: new  Abstract: Large language models (LLMs) have shown excellent mastering of human language, but still struggle in real-world applications that require mathematical problem-solving. While many strategies and datasets to enhance LLMs' mathematics are developed, it remains a challenge to simultaneously maintain and improve both language and mathematical capabilities in deployed LLM systems.In this work, we tailor the Self-Critique pipeline, which addresses the challenge in the feedback learning stage of LLM alignment. We first train a general Math-Critique model from the LLM itself to provide feedback signals. Then, we sequentially employ rejective fine-tuning and direct preference optimization over the LLM's own generations for data collection. Based on ChatGLM3-32B, we conduct a series of experiments on both academic and our newly created challenging dataset, MathUserEval. Results show that our pipeline significantly enhances the LLM's mathematical pr",
    "link": "https://arxiv.org/abs/2404.02893",
    "context": "Title: ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline\nAbstract: arXiv:2404.02893v1 Announce Type: new  Abstract: Large language models (LLMs) have shown excellent mastering of human language, but still struggle in real-world applications that require mathematical problem-solving. While many strategies and datasets to enhance LLMs' mathematics are developed, it remains a challenge to simultaneously maintain and improve both language and mathematical capabilities in deployed LLM systems.In this work, we tailor the Self-Critique pipeline, which addresses the challenge in the feedback learning stage of LLM alignment. We first train a general Math-Critique model from the LLM itself to provide feedback signals. Then, we sequentially employ rejective fine-tuning and direct preference optimization over the LLM's own generations for data collection. Based on ChatGLM3-32B, we conduct a series of experiments on both academic and our newly created challenging dataset, MathUserEval. Results show that our pipeline significantly enhances the LLM's mathematical pr",
    "path": "papers/24/04/2404.02893.json",
    "total_tokens": 840,
    "translated_title": "ChatGLM-Math:使用自我批判管道改进大型语言模型在数学问题解决中的表现",
    "translated_abstract": "大型语言模型(LLMs)在掌握人类语言方面表现出色，但在需要数学问题解决的现实应用中仍然面临困难。尽管已经开发了许多增强LLMs数学能力的策略和数据集，但同时在部署的LLM系统中保持和提高语言和数学能力仍然是一个挑战。在这项工作中，我们定制了Self-Critique管道，解决了LLM对齐的反馈学习阶段的挑战。我们首先训练一个通用的Math-Critique模型，从LLM本身提供反馈信号。然后，我们依次使用拒绝微调和直接偏好优化LLM自身生成的数据收集。基于ChatGLM3-32B，我们在学术领域和我们新创建的挑战性数据集MathUserEval上进行了一系列实验。结果显示我们的管道显著增强了LLM的数学能力。",
    "tldr": "ChatGLM-Math通过自我批判管道在大型语言模型中实现了数学问题解决能力的显著增强",
    "en_tdlr": "ChatGLM-Math significantly enhances the mathematical problem-solving capabilities in large language models through a self-critique pipeline."
}