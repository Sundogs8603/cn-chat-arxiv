{
    "title": "Nearly-tight Approximation Guarantees for the Improving Multi-Armed Bandits Problem",
    "abstract": "arXiv:2404.01198v1 Announce Type: new  Abstract: We give nearly-tight upper and lower bounds for the improving multi-armed bandits problem. An instance of this problem has $k$ arms, each of whose reward function is a concave and increasing function of the number of times that arm has been pulled so far. We show that for any randomized online algorithm, there exists an instance on which it must suffer at least an $\\Omega(\\sqrt{k})$ approximation factor relative to the optimal reward. We then provide a randomized online algorithm that guarantees an $O(\\sqrt{k})$ approximation factor, if it is told the maximum reward achievable by the optimal arm in advance. We then show how to remove this assumption at the cost of an extra $O(\\log k)$ approximation factor, achieving an overall $O(\\sqrt{k} \\log k)$ approximation relative to optimal.",
    "link": "https://arxiv.org/abs/2404.01198",
    "context": "Title: Nearly-tight Approximation Guarantees for the Improving Multi-Armed Bandits Problem\nAbstract: arXiv:2404.01198v1 Announce Type: new  Abstract: We give nearly-tight upper and lower bounds for the improving multi-armed bandits problem. An instance of this problem has $k$ arms, each of whose reward function is a concave and increasing function of the number of times that arm has been pulled so far. We show that for any randomized online algorithm, there exists an instance on which it must suffer at least an $\\Omega(\\sqrt{k})$ approximation factor relative to the optimal reward. We then provide a randomized online algorithm that guarantees an $O(\\sqrt{k})$ approximation factor, if it is told the maximum reward achievable by the optimal arm in advance. We then show how to remove this assumption at the cost of an extra $O(\\log k)$ approximation factor, achieving an overall $O(\\sqrt{k} \\log k)$ approximation relative to optimal.",
    "path": "papers/24/04/2404.01198.json",
    "total_tokens": 833,
    "translated_title": "对改进的多臂老虎机问题的近乎最紧密的逼近保证",
    "translated_abstract": "我们为改进的多臂老虎机问题提供了近乎最紧密的上界和下界。这个问题的一个实例有$k$个臂，每个臂的奖励函数都是一个凹函数，并且是一个与到目前为止拉动该臂的次数成增函数。我们证明了对于任何随机在线算法，都存在一个实例，使其相对于最优奖励必须至少承受一个$\\Omega(\\sqrt{k})$的近似因子。然后我们提供了一个随机在线算法，如果事先告知最优臂可实现的最大奖励，就可以保证一个$O(\\sqrt{k})$的近似因子。我们还展示了如何在额外付出$O(\\log k)$的近似因子的代价下，消除这个假设，实现相对于最优的总体$O(\\sqrt{k} \\log k)$的逼近。",
    "tldr": "对改进的多臂老虎机问题，我们给出了一个随机在线算法，可以在不了解最优臂最大奖励的情况下，以$O(\\sqrt{k} \\log k)$的逼近相对于最优。",
    "en_tdlr": "For the improving multi-armed bandits problem, we provide a randomized online algorithm that achieves an $O(\\sqrt{k} \\log k)$ approximation relative to optimal without knowing the maximum reward achievable by the optimal arm in advance."
}