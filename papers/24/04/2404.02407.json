{
    "title": "Decision Transformer as a Foundation Model for Partially Observable Continuous Control",
    "abstract": "arXiv:2404.02407v1 Announce Type: cross  Abstract: Closed-loop control of nonlinear dynamical systems with partial-state observability demands expert knowledge of a diverse, less standardized set of theoretical tools. Moreover, it requires a delicate integration of controller and estimator designs to achieve the desired system behavior. To establish a general controller synthesis framework, we explore the Decision Transformer (DT) architecture. Specifically, we first frame the control task as predicting the current optimal action based on past observations, actions, and rewards, eliminating the need for a separate estimator design. Then, we leverage the pre-trained language models, i.e., the Generative Pre-trained Transformer (GPT) series, to initialize DT and subsequently train it for control tasks using low-rank adaptation (LoRA). Our comprehensive experiments across five distinct control tasks, ranging from maneuvering aerospace systems to controlling partial differential equations ",
    "link": "https://arxiv.org/abs/2404.02407",
    "context": "Title: Decision Transformer as a Foundation Model for Partially Observable Continuous Control\nAbstract: arXiv:2404.02407v1 Announce Type: cross  Abstract: Closed-loop control of nonlinear dynamical systems with partial-state observability demands expert knowledge of a diverse, less standardized set of theoretical tools. Moreover, it requires a delicate integration of controller and estimator designs to achieve the desired system behavior. To establish a general controller synthesis framework, we explore the Decision Transformer (DT) architecture. Specifically, we first frame the control task as predicting the current optimal action based on past observations, actions, and rewards, eliminating the need for a separate estimator design. Then, we leverage the pre-trained language models, i.e., the Generative Pre-trained Transformer (GPT) series, to initialize DT and subsequently train it for control tasks using low-rank adaptation (LoRA). Our comprehensive experiments across five distinct control tasks, ranging from maneuvering aerospace systems to controlling partial differential equations ",
    "path": "papers/24/04/2404.02407.json",
    "total_tokens": 885,
    "translated_title": "决策Transformer作为部分可观测连续控制的基础模型",
    "translated_abstract": "面对具有部分状态可观测性的非线性动态系统的闭环控制需要专家对一组不太标准化的理论工具有深入了解，此外，它还需要控制器和估计器设计的精心融合以实现期望的系统行为。为建立一个通用的控制器合成框架，我们探索了决策Transformer（DT）架构。具体地，我们首先将控制任务框架化为基于过去的观察、动作和奖励预测当前最优动作，消除了对单独估计器设计的需求。然后，我们利用预训练的语言模型，即生成式预训练Transformer（GPT）系列，来初始化DT，并随后使用低秩适应（LoRA）对其进行控制任务训练。我们在五个不同的控制任务上进行了全面实验，涵盖航空航天系统的操纵到控制偏微分方程。",
    "tldr": "通过将控制任务作为基于过去观察、动作和奖励的当前最优动作预测来消除估计器设计需求，并利用生成式预训练Transformer系列初始化决策Transformer，然后使用低秩适应对其进行控制任务训练。",
    "en_tdlr": "The study eliminates the need for estimator design by framing the control task as predicting the current optimal action based on past observations, actions, and rewards, utilizing pre-trained language models to initialize the decision transformer, and training it for control tasks using low-rank adaptation."
}