{
    "title": "NLP Systems That Can't Tell Use from Mention Censor Counterspeech, but Teaching the Distinction Helps",
    "abstract": "arXiv:2404.01651v1 Announce Type: new  Abstract: The use of words to convey speaker's intent is traditionally distinguished from the `mention' of words for quoting what someone said, or pointing out properties of a word. Here we show that computationally modeling this use-mention distinction is crucial for dealing with counterspeech online. Counterspeech that refutes problematic content often mentions harmful language but is not harmful itself (e.g., calling a vaccine dangerous is not the same as expressing disapproval of someone for calling vaccines dangerous). We show that even recent language models fail at distinguishing use from mention, and that this failure propagates to two key downstream tasks: misinformation and hate speech detection, resulting in censorship of counterspeech. We introduce prompting mitigations that teach the use-mention distinction, and show they reduce these errors. Our work highlights the importance of the use-mention distinction for NLP and CSS and offers ",
    "link": "https://arxiv.org/abs/2404.01651",
    "context": "Title: NLP Systems That Can't Tell Use from Mention Censor Counterspeech, but Teaching the Distinction Helps\nAbstract: arXiv:2404.01651v1 Announce Type: new  Abstract: The use of words to convey speaker's intent is traditionally distinguished from the `mention' of words for quoting what someone said, or pointing out properties of a word. Here we show that computationally modeling this use-mention distinction is crucial for dealing with counterspeech online. Counterspeech that refutes problematic content often mentions harmful language but is not harmful itself (e.g., calling a vaccine dangerous is not the same as expressing disapproval of someone for calling vaccines dangerous). We show that even recent language models fail at distinguishing use from mention, and that this failure propagates to two key downstream tasks: misinformation and hate speech detection, resulting in censorship of counterspeech. We introduce prompting mitigations that teach the use-mention distinction, and show they reduce these errors. Our work highlights the importance of the use-mention distinction for NLP and CSS and offers ",
    "path": "papers/24/04/2404.01651.json",
    "total_tokens": 873,
    "translated_title": "无法区分使用和提及的自然语言处理系统会抑制抗议言论，而教导这个区分有助于改善",
    "translated_abstract": "传统上，使用词语传达说话者的意图与“提及”词语引述他人的话语或指出词语的属性是有所区别的。在这里我们展示，计算模拟这种使用-提及区别对于处理线上抗议言论至关重要。驳斥有问题内容的抗议言论通常提及有害语言但本身并不有害（例如，称疫苗危险并不等同于对某人表示反对称呼疫苗危险）。我们展示，即使是最近的语言模型也无法区分使用和提及，而这个失败会延伸到两个关键的下游任务：虚假信息和仇恨言论检测，导致对抗议言论的审查。我们引入提示缓解措施来教导使用-提及区别，并展示它们减少了这些错误。我们的工作突显了使用-提及区别对自然语言处理和CSS的重要性，并提供了…",
    "tldr": "NLP 系统无法区分使用和提及，对于处理在线抗议言论至关重要，教导这种区分有助于减少虚假信息和仇恨言论检测中的审查错误",
    "en_tdlr": "NLP systems' failure to distinguish between use and mention is crucial for handling online counterspeech, and teaching this distinction helps reduce censorship errors in misinformation and hate speech detection."
}