{
    "title": "Auditing Large Language Models for Enhanced Text-Based Stereotype Detection and Probing-Based Bias Evaluation",
    "abstract": "arXiv:2404.01768v1 Announce Type: cross  Abstract: Recent advancements in Large Language Models (LLMs) have significantly increased their presence in human-facing Artificial Intelligence (AI) applications. However, LLMs could reproduce and even exacerbate stereotypical outputs from training data. This work introduces the Multi-Grain Stereotype (MGS) dataset, encompassing 51,867 instances across gender, race, profession, religion, and stereotypical text, collected by fusing multiple previously publicly available stereotype detection datasets. We explore different machine learning approaches aimed at establishing baselines for stereotype detection, and fine-tune several language models of various architectures and model sizes, presenting in this work a series of stereotypes classifier models for English text trained on MGS. To understand whether our stereotype detectors capture relevant features (aligning with human common sense) we utilise a variety of explanainable AI tools, including ",
    "link": "https://arxiv.org/abs/2404.01768",
    "context": "Title: Auditing Large Language Models for Enhanced Text-Based Stereotype Detection and Probing-Based Bias Evaluation\nAbstract: arXiv:2404.01768v1 Announce Type: cross  Abstract: Recent advancements in Large Language Models (LLMs) have significantly increased their presence in human-facing Artificial Intelligence (AI) applications. However, LLMs could reproduce and even exacerbate stereotypical outputs from training data. This work introduces the Multi-Grain Stereotype (MGS) dataset, encompassing 51,867 instances across gender, race, profession, religion, and stereotypical text, collected by fusing multiple previously publicly available stereotype detection datasets. We explore different machine learning approaches aimed at establishing baselines for stereotype detection, and fine-tune several language models of various architectures and model sizes, presenting in this work a series of stereotypes classifier models for English text trained on MGS. To understand whether our stereotype detectors capture relevant features (aligning with human common sense) we utilise a variety of explanainable AI tools, including ",
    "path": "papers/24/04/2404.01768.json",
    "total_tokens": 901,
    "translated_title": "用于增强基于文本的陈规检测和基于探测的偏见评估的大规模语言模型审计",
    "translated_abstract": "大型语言模型（LLMs）的最新进展显著提高了它们在面向人类的人工智能（AI）应用中的影响力。然而，LLMs可能会复制甚至加剧自训练数据中的陈规输出。本研究介绍了Multi-Grain Stereotype（MGS）数据集，包括51,867个实例，涵盖性别、种族、职业、宗教和陈规文本，通过融合多个先前公开的陈规检测数据集收集而来。我们探索了旨在为陈规检测建立基线的不同机器学习方法，并微调了多种架构和模型大小的几个语言模型，本文展示了一系列基于MGS训练的英文文本的陈规分类器模型。为了了解我们的陈规检测器是否捕捉到与人类常识一致的相关特征，我们利用了各种可解释的AI工具，",
    "tldr": "该研究引入了Multi-Grain Stereotype（MGS）数据集，探索了不同的机器学习方法用于建立陈规检测的基线，并提出了一系列基于MGS数据训练的英文文本的陈规分类器模型。",
    "en_tdlr": "The study introduces the Multi-Grain Stereotype (MGS) dataset, explores different machine learning approaches for establishing baselines in stereotype detection, and presents a series of stereotype classifier models for English text trained on the MGS dataset."
}