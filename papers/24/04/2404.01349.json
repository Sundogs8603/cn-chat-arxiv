{
    "title": "Fairness in Large Language Models: A Taxonomic Survey",
    "abstract": "arXiv:2404.01349v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated remarkable success across various domains. However, despite their promising performance in numerous real-world applications, most of these algorithms lack fairness considerations. Consequently, they may lead to discriminatory outcomes against certain communities, particularly marginalized populations, prompting extensive study in fair LLMs. On the other hand, fairness in LLMs, in contrast to fairness in traditional machine learning, entails exclusive backgrounds, taxonomies, and fulfillment techniques. To this end, this survey presents a comprehensive overview of recent advances in the existing literature concerning fair LLMs. Specifically, a brief introduction to LLMs is provided, followed by an analysis of factors contributing to bias in LLMs. Additionally, the concept of fairness in LLMs is discussed categorically, summarizing metrics for evaluating bias in LLMs and existing algorithms ",
    "link": "https://arxiv.org/abs/2404.01349",
    "context": "Title: Fairness in Large Language Models: A Taxonomic Survey\nAbstract: arXiv:2404.01349v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated remarkable success across various domains. However, despite their promising performance in numerous real-world applications, most of these algorithms lack fairness considerations. Consequently, they may lead to discriminatory outcomes against certain communities, particularly marginalized populations, prompting extensive study in fair LLMs. On the other hand, fairness in LLMs, in contrast to fairness in traditional machine learning, entails exclusive backgrounds, taxonomies, and fulfillment techniques. To this end, this survey presents a comprehensive overview of recent advances in the existing literature concerning fair LLMs. Specifically, a brief introduction to LLMs is provided, followed by an analysis of factors contributing to bias in LLMs. Additionally, the concept of fairness in LLMs is discussed categorically, summarizing metrics for evaluating bias in LLMs and existing algorithms ",
    "path": "papers/24/04/2404.01349.json",
    "total_tokens": 811,
    "translated_title": "大型语言模型中的公平性：一个分类调查",
    "translated_abstract": "大型语言模型（LLMs）在各个领域展现了显著的成功。然而，尽管它们在许多实际应用中表现出色，大多数这些算法缺乏公平性考虑。因此，它们可能导致针对某些社区，特别是边缘化人群的歧视性结果，促使对公平的LLMs进行广泛研究。与传统机器学习中的公平相反，在LLMs中的公平性涉及独特的背景、分类法和实现技术。为此，该调查提供了关于公平LLMs的现有文献研究进展的全面概述。具体来说，提供了有关LLMs的简要介绍，接着分析了导致LLMs偏见的因素。此外，分类讨论了LLMs中的公平概念，总结了评估LLMs偏见的指标和现有算法。",
    "tldr": "该调查总结了大型语言模型中公平性的最新进展，包括对偏见因素的分析、公平度量和现有算法分类。",
    "en_tdlr": "This survey provides a comprehensive overview of recent advances in fairness in Large Language Models, including analysis of bias factors, fairness metrics, and categorization of existing algorithms."
}