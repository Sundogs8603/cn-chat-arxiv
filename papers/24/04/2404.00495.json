{
    "title": "Configurable Safety Tuning of Language Models with Synthetic Preference Data",
    "abstract": "arXiv:2404.00495v1 Announce Type: cross  Abstract: State-of-the-art language model fine-tuning techniques, such as Direct Preference Optimization (DPO), restrict user control by hard-coding predefined behaviors into the model. To address this, we propose a novel method, Configurable Safety Tuning (CST), that augments DPO using synthetic preference data to facilitate flexible safety configuration of LLMs at inference time. CST overcomes the constraints of vanilla DPO by introducing a system prompt specifying safety configurations, enabling LLM deployers to disable/enable safety preferences based on their need, just changing the system prompt. Our experimental evaluations indicate that CST successfully manages different safety configurations and retains the original functionality of LLMs, showing it is a robust method for configurable deployment. Data and models available at https://github.com/vicgalle/configurable-safety-tuning",
    "link": "https://arxiv.org/abs/2404.00495",
    "context": "Title: Configurable Safety Tuning of Language Models with Synthetic Preference Data\nAbstract: arXiv:2404.00495v1 Announce Type: cross  Abstract: State-of-the-art language model fine-tuning techniques, such as Direct Preference Optimization (DPO), restrict user control by hard-coding predefined behaviors into the model. To address this, we propose a novel method, Configurable Safety Tuning (CST), that augments DPO using synthetic preference data to facilitate flexible safety configuration of LLMs at inference time. CST overcomes the constraints of vanilla DPO by introducing a system prompt specifying safety configurations, enabling LLM deployers to disable/enable safety preferences based on their need, just changing the system prompt. Our experimental evaluations indicate that CST successfully manages different safety configurations and retains the original functionality of LLMs, showing it is a robust method for configurable deployment. Data and models available at https://github.com/vicgalle/configurable-safety-tuning",
    "path": "papers/24/04/2404.00495.json",
    "total_tokens": 845,
    "translated_title": "使用合成偏好数据对语言模型进行可配置安全调优",
    "translated_abstract": "最先进的语言模型微调技术，如直接偏好优化（DPO），通过将预定义行为硬编码到模型中，限制了用户的控制权。为了解决这个问题，我们提出了一种新颖的方法，Configurable Safety Tuning（CST），它利用合成偏好数据来增强DPO，以促进在推断时对LLMs进行灵活的安全配置。CST通过引入指定安全配置的系统提示，允许LLM部署者根据需要禁用/启用安全偏好，仅需更改系统提示。我们的实验评估表明，CST成功管理不同的安全配置，并保留了LLMs的原始功能，显示出它是一种适用于可配置部署的强大方法。",
    "tldr": "提出了一种名为Configurable Safety Tuning（CST）的新方法，通过使用合成偏好数据，在推断时实现对LLMs的灵活安全配置，允许用户根据需要禁用/启用安全偏好，且实验表明CST成功管理不同的安全配置并保留了原始功能，是一种适用于可配置部署的强大方法。",
    "en_tdlr": "Proposed a novel method called Configurable Safety Tuning (CST) that enables flexible safety configuration of LLMs at inference time using synthetic preference data, allowing users to disable/enable safety preferences based on their need. Experimental evaluations show that CST successfully manages different safety configurations and retains the original functionality, making it a robust method for configurable deployment."
}