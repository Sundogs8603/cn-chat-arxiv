{
    "title": "Condition-Aware Neural Network for Controlled Image Generation",
    "abstract": "arXiv:2404.01143v1 Announce Type: cross  Abstract: We present Condition-Aware Neural Network (CAN), a new method for adding control to image generative models. In parallel to prior conditional control methods, CAN controls the image generation process by dynamically manipulating the weight of the neural network. This is achieved by introducing a condition-aware weight generation module that generates conditional weight for convolution/linear layers based on the input condition. We test CAN on class-conditional image generation on ImageNet and text-to-image generation on COCO. CAN consistently delivers significant improvements for diffusion transformer models, including DiT and UViT. In particular, CAN combined with EfficientViT (CaT) achieves 2.78 FID on ImageNet 512x512, surpassing DiT-XL/2 while requiring 52x fewer MACs per sampling step.",
    "link": "https://arxiv.org/abs/2404.01143",
    "context": "Title: Condition-Aware Neural Network for Controlled Image Generation\nAbstract: arXiv:2404.01143v1 Announce Type: cross  Abstract: We present Condition-Aware Neural Network (CAN), a new method for adding control to image generative models. In parallel to prior conditional control methods, CAN controls the image generation process by dynamically manipulating the weight of the neural network. This is achieved by introducing a condition-aware weight generation module that generates conditional weight for convolution/linear layers based on the input condition. We test CAN on class-conditional image generation on ImageNet and text-to-image generation on COCO. CAN consistently delivers significant improvements for diffusion transformer models, including DiT and UViT. In particular, CAN combined with EfficientViT (CaT) achieves 2.78 FID on ImageNet 512x512, surpassing DiT-XL/2 while requiring 52x fewer MACs per sampling step.",
    "path": "papers/24/04/2404.01143.json",
    "total_tokens": 815,
    "translated_title": "条件感知神经网络用于可控图像生成",
    "translated_abstract": "我们提出了一种新的方法，称为条件感知神经网络（CAN），用于向图像生成模型添加控制。与先前的条件控制方法并行，CAN通过动态操纵神经网络的权重来控制图像生成过程。这是通过引入一个条件感知权重生成模块来实现的，根据输入条件为卷积/线性层生成有条件的权重。我们在ImageNet上对类别有条件的图像生成和在COCO上对文本到图像的生成进行了CAN测试。CAN始终为扩散变换器模型提供显着改进，包括DiT和UViT。特别是，CAN与EfficientViT（CaT）相结合，在ImageNet 512x512上实现了2.78 FID，超过了DiT-XL/2，同时每个采样步骤需要的MAC数量减少了52倍。",
    "tldr": "提出了一种条件感知神经网络（CAN）用于图像生成模型，通过动态调整神经网络的权重来控制图像生成过程，在ImageNet和COCO上测试表明，CAN与EfficientViT（CaT）相结合取得了显著的改进。",
    "en_tdlr": "Introduced Condition-Aware Neural Network (CAN) for image generative models, which controls the image generation process by dynamically manipulating the network weights. Testing on ImageNet and COCO shows significant improvements, especially when CAN is combined with EfficientViT (CaT)."
}