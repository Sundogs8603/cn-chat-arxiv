{
    "title": "Measuring Social Norms of Large Language Models",
    "abstract": "arXiv:2404.02491v1 Announce Type: cross  Abstract: We present a new challenge to examine whether large language models understand social norms. In contrast to existing datasets, our dataset requires a fundamental understanding of social norms to solve. Our dataset features the largest set of social norm skills, consisting of 402 skills and 12,383 questions covering a wide set of social norms ranging from opinions and arguments to culture and laws. We design our dataset according to the K-12 curriculum. This enables the direct comparison of the social understanding of large language models to humans, more specifically, elementary students. While prior work generates nearly random accuracy on our benchmark, recent large language models such as GPT3.5-Turbo and LLaMA2-Chat are able to improve the performance significantly, only slightly below human performance. We then propose a multi-agent framework based on large language models to improve the models' ability to understand social norms.",
    "link": "https://arxiv.org/abs/2404.02491",
    "context": "Title: Measuring Social Norms of Large Language Models\nAbstract: arXiv:2404.02491v1 Announce Type: cross  Abstract: We present a new challenge to examine whether large language models understand social norms. In contrast to existing datasets, our dataset requires a fundamental understanding of social norms to solve. Our dataset features the largest set of social norm skills, consisting of 402 skills and 12,383 questions covering a wide set of social norms ranging from opinions and arguments to culture and laws. We design our dataset according to the K-12 curriculum. This enables the direct comparison of the social understanding of large language models to humans, more specifically, elementary students. While prior work generates nearly random accuracy on our benchmark, recent large language models such as GPT3.5-Turbo and LLaMA2-Chat are able to improve the performance significantly, only slightly below human performance. We then propose a multi-agent framework based on large language models to improve the models' ability to understand social norms.",
    "path": "papers/24/04/2404.02491.json",
    "total_tokens": 892,
    "translated_title": "测量大型语言模型的社会规范",
    "translated_abstract": "我们提出了一个新的挑战，以检验大型语言模型是否理解社会规范。与现有数据集不同，我们的数据集要求具有解决社会规范的基本理解。我们的数据集包含最大的社会规范技能集，包括402项技能和12,383个问题，涵盖了从观点和论点到文化和法律等广泛的社会规范。我们根据K-12课程设计了我们的数据集。这使得可以直接将大型语言模型的社会理解能力与人类进行比较，更具体地说是与小学生进行比较。尽管先前的工作在我们的基准测试中产生几乎随机的准确度，但最近的大型语言模型（如GPT3.5-Turbo和LLaMA2-Chat）能够显著提高性能，仅略低于人类性能。然后，我们提出了一个基于大型语言模型的多代理框架，以提高模型理解社会规范的能力。",
    "tldr": "论文提出了一个挑战，测试大型语言模型对社会规范的理解，构建了一个数据集涵盖广泛的社会规范问题，通过多代理框架基于大型语言模型来提高模型对社会规范的理解能力。",
    "en_tdlr": "The paper introduces a challenge to test large language models' understanding of social norms, constructs a dataset covering a wide range of social norm questions, and proposes a multi-agent framework based on large language models to enhance the models' understanding of social norms."
}