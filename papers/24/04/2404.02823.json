{
    "title": "Conifer: Improving Complex Constrained Instruction-Following Ability of Large Language Models",
    "abstract": "arXiv:2404.02823v1 Announce Type: cross  Abstract: The ability of large language models (LLMs) to follow instructions is crucial to real-world applications. Despite recent advances, several studies have highlighted that LLMs struggle when faced with challenging instructions, especially those that include complex constraints, hindering their effectiveness in various tasks. To address this challenge, we introduce Conifer, a novel instruction tuning dataset, designed to enhance LLMs to follow multi-level instructions with complex constraints. Utilizing GPT-4, we curate the dataset by a series of LLM-driven refinement processes to ensure high quality. We also propose a progressive learning scheme that emphasizes an easy-to-hard progression, and learning from process feedback. Models trained with Conifer exhibit remarkable improvements in instruction-following abilities, especially for instructions with complex constraints. On several instruction-following benchmarks, our 7B model outperfor",
    "link": "https://arxiv.org/abs/2404.02823",
    "context": "Title: Conifer: Improving Complex Constrained Instruction-Following Ability of Large Language Models\nAbstract: arXiv:2404.02823v1 Announce Type: cross  Abstract: The ability of large language models (LLMs) to follow instructions is crucial to real-world applications. Despite recent advances, several studies have highlighted that LLMs struggle when faced with challenging instructions, especially those that include complex constraints, hindering their effectiveness in various tasks. To address this challenge, we introduce Conifer, a novel instruction tuning dataset, designed to enhance LLMs to follow multi-level instructions with complex constraints. Utilizing GPT-4, we curate the dataset by a series of LLM-driven refinement processes to ensure high quality. We also propose a progressive learning scheme that emphasizes an easy-to-hard progression, and learning from process feedback. Models trained with Conifer exhibit remarkable improvements in instruction-following abilities, especially for instructions with complex constraints. On several instruction-following benchmarks, our 7B model outperfor",
    "path": "papers/24/04/2404.02823.json",
    "total_tokens": 898,
    "translated_title": "Conifer: 提高大型语言模型复杂约束指令遵循能力",
    "translated_abstract": "大型语言模型(LLMs)遵循指令的能力对实际应用至关重要。尽管最近取得进展，但一些研究指出，LLMs在面对具有挑战性指令时存在困难，特别是包含复杂约束的指令，阻碍了它们在各种任务中的有效性。为解决这一挑战，我们引入了Conifer，这是一个新颖的指令调节数据集，旨在增强LLMs遵循具有复杂约束的多层指令。通过一系列LLM驱动的细化过程，我们利用GPT-4策划了这个数据集以确保高质量。我们还提出了一个强调易于难的渐进学习方案，并从过程反馈中学习。使用Conifer训练的模型在遵循指令能力方面表现出显著改善，特别是对于带有复杂约束的指令。在几个遵循指令的基准测试中，我们的7B模型表现优异",
    "tldr": "Conifer提出了一个新的指令调节数据集，通过LLMs驱动的细化过程，以及渐进学习方案，显著提高了大型语言模型遵循具有复杂约束的多层指令的能力",
    "en_tdlr": "Conifer introduces a novel instruction tuning dataset that significantly enhances the ability of large language models to follow multi-level instructions with complex constraints through LLMs-driven refinement processes and a progressive learning scheme."
}