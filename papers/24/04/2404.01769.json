{
    "title": "Unifying Qualitative and Quantitative Safety Verification of DNN-Controlled Systems",
    "abstract": "arXiv:2404.01769v1 Announce Type: new  Abstract: The rapid advance of deep reinforcement learning techniques enables the oversight of safety-critical systems through the utilization of Deep Neural Networks (DNNs). This underscores the pressing need to promptly establish certified safety guarantees for such DNN-controlled systems. Most of the existing verification approaches rely on qualitative approaches, predominantly employing reachability analysis. However, qualitative verification proves inadequate for DNN-controlled systems as their behaviors exhibit stochastic tendencies when operating in open and adversarial environments. In this paper, we propose a novel framework for unifying both qualitative and quantitative safety verification problems of DNN-controlled systems. This is achieved by formulating the verification tasks as the synthesis of valid neural barrier certificates (NBCs). Initially, the framework seeks to establish almost-sure safety guarantees through qualitative verif",
    "link": "https://arxiv.org/abs/2404.01769",
    "context": "Title: Unifying Qualitative and Quantitative Safety Verification of DNN-Controlled Systems\nAbstract: arXiv:2404.01769v1 Announce Type: new  Abstract: The rapid advance of deep reinforcement learning techniques enables the oversight of safety-critical systems through the utilization of Deep Neural Networks (DNNs). This underscores the pressing need to promptly establish certified safety guarantees for such DNN-controlled systems. Most of the existing verification approaches rely on qualitative approaches, predominantly employing reachability analysis. However, qualitative verification proves inadequate for DNN-controlled systems as their behaviors exhibit stochastic tendencies when operating in open and adversarial environments. In this paper, we propose a novel framework for unifying both qualitative and quantitative safety verification problems of DNN-controlled systems. This is achieved by formulating the verification tasks as the synthesis of valid neural barrier certificates (NBCs). Initially, the framework seeks to establish almost-sure safety guarantees through qualitative verif",
    "path": "papers/24/04/2404.01769.json",
    "total_tokens": 792,
    "translated_title": "统一DNN控制系统的定性和定量安全验证",
    "translated_abstract": "深度强化学习技术的快速发展使得可以通过利用深度神经网络(DNNs)监督安全关键系统，凸显了迅速建立这种DNN控制系统的认证安全保证的迫切需要。大多数现有的验证方法依赖于定性方法，主要采用可达性分析。然而，对于在开放和对抗环境中运行时其行为具有随机趋势的DNN控制系统而言，定性验证证明不足。本文提出了一个新的框架，用于统一DNN控制系统的定性和定量安全验证问题。这是通过将验证任务构建为有效神经障碍证书(NBCs)的综合来实现的。最初，该框架旨在通过定性验证建立几乎确定的安全保证",
    "tldr": "本文提出了一个新的框架，用于统一DNN控制系统的定性和定量安全验证问题，通过构建有效神经障碍证书(NBCs)来实现几乎确定的安全保证",
    "en_tdlr": "This paper proposes a novel framework for unifying the qualitative and quantitative safety verification problems of DNN-controlled systems by synthesizing valid Neural Barrier Certificates (NBCs) to establish almost-sure safety guarantees."
}