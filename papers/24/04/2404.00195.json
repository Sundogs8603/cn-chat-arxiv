{
    "title": "Multiple-policy Evaluation via Density Estimation",
    "abstract": "arXiv:2404.00195v1 Announce Type: cross  Abstract: In this work, we focus on the multiple-policy evaluation problem where we are given a set of $K$ target policies and the goal is to evaluate their performance (the expected total rewards) to an accuracy $\\epsilon$ with probability at least $1-\\delta$. We propose an algorithm named $\\mathrm{CAESAR}$ to address this problem. Our approach is based on computing an approximate optimal offline sampling distribution and using the data sampled from it to perform the simultaneous estimation of the policy values. $\\mathrm{CAESAR}$ consists of two phases. In the first one we produce coarse estimates of the vistation distributions of the target policies at a low order sample complexity rate that scales with $\\tilde{O}(\\frac{1}{\\epsilon})$. In the second phase, we approximate the optimal offline sampling distribution and compute the importance weighting ratios for all target policies by minimizing a step-wise quadratic loss function inspired by the",
    "link": "https://arxiv.org/abs/2404.00195",
    "context": "Title: Multiple-policy Evaluation via Density Estimation\nAbstract: arXiv:2404.00195v1 Announce Type: cross  Abstract: In this work, we focus on the multiple-policy evaluation problem where we are given a set of $K$ target policies and the goal is to evaluate their performance (the expected total rewards) to an accuracy $\\epsilon$ with probability at least $1-\\delta$. We propose an algorithm named $\\mathrm{CAESAR}$ to address this problem. Our approach is based on computing an approximate optimal offline sampling distribution and using the data sampled from it to perform the simultaneous estimation of the policy values. $\\mathrm{CAESAR}$ consists of two phases. In the first one we produce coarse estimates of the vistation distributions of the target policies at a low order sample complexity rate that scales with $\\tilde{O}(\\frac{1}{\\epsilon})$. In the second phase, we approximate the optimal offline sampling distribution and compute the importance weighting ratios for all target policies by minimizing a step-wise quadratic loss function inspired by the",
    "path": "papers/24/04/2404.00195.json",
    "total_tokens": 856,
    "translated_title": "通过密度估计进行多策略评估",
    "translated_abstract": "在这项工作中，我们专注于多策略评估问题，给定一组 $K$ 个目标策略，目标是以至少 $1-\\delta$ 的概率评估它们的性能（期望总奖励）达到精度 $\\epsilon$。我们提出了一种名为 $\\mathrm{CAESAR}$ 的算法来解决这个问题。我们的方法基于计算一个近似的最优离线采样分布，并利用从中采样的数据来同时估计策略价值。$\\mathrm{CAESAR}$ 包括两个阶段。在第一个阶段，我们以随着 $\\tilde{O}(\\frac{1}{\\epsilon})$ 缩放的低订单采样复杂性率产生目标策略的访问分布的粗略估计。在第二阶段，我们近似最优离线采样分布，并通过最小化一个逐步二次损失函数来计算所有目标策略的重要性权重比例。",
    "tldr": "该研究提出一种名为 $\\mathrm{CAESAR}$ 的算法，通过计算一个近似的最优离线采样分布，同时估计多个策略的价值，以解决多策略评估问题。",
    "en_tdlr": "The study introduces an algorithm named $\\mathrm{CAESAR}$ which addresses the multiple-policy evaluation problem by computing an approximate optimal offline sampling distribution for simultaneous estimation of policy values."
}