{
    "title": "What Can Transformer Learn with Varying Depth? Case Studies on Sequence Learning Tasks",
    "abstract": "arXiv:2404.01601v1 Announce Type: new  Abstract: We study the capabilities of the transformer architecture with varying depth. Specifically, we designed a novel set of sequence learning tasks to systematically evaluate and comprehend how the depth of transformer affects its ability to perform memorization, reasoning, generalization, and contextual generalization. We show a transformer with only one attention layer can excel in memorization but falls short in other tasks. Then, we show that exhibiting reasoning and generalization ability requires the transformer to have at least two attention layers, while context generalization ability may necessitate three attention layers. Additionally, we identify a class of simple operations that a single attention layer can execute, and show that the complex tasks can be approached as the combinations of these simple operations and thus can be resolved by stacking multiple attention layers. This sheds light on studying more practical and complex t",
    "link": "https://arxiv.org/abs/2404.01601",
    "context": "Title: What Can Transformer Learn with Varying Depth? Case Studies on Sequence Learning Tasks\nAbstract: arXiv:2404.01601v1 Announce Type: new  Abstract: We study the capabilities of the transformer architecture with varying depth. Specifically, we designed a novel set of sequence learning tasks to systematically evaluate and comprehend how the depth of transformer affects its ability to perform memorization, reasoning, generalization, and contextual generalization. We show a transformer with only one attention layer can excel in memorization but falls short in other tasks. Then, we show that exhibiting reasoning and generalization ability requires the transformer to have at least two attention layers, while context generalization ability may necessitate three attention layers. Additionally, we identify a class of simple operations that a single attention layer can execute, and show that the complex tasks can be approached as the combinations of these simple operations and thus can be resolved by stacking multiple attention layers. This sheds light on studying more practical and complex t",
    "path": "papers/24/04/2404.01601.json",
    "total_tokens": 855,
    "translated_title": "变深度Transformer能学到什么？序列学习任务的案例研究",
    "translated_abstract": "我们研究了具有不同深度的Transformer架构的能力。具体来说，我们设计了一组新颖的序列学习任务，系统评估和理解了Transformer的深度如何影响其进行记忆、推理、泛化和上下文泛化的能力。我们展示了只有一个注意力层的Transformer可以在记忆方面表现出色，但在其他任务方面表现不佳。接着，我们展示了展示推理和泛化能力需要Transformer至少具有两个注意力层，而上下文泛化能力可能需要三个注意力层。此外，我们确定了单个注意力层可以执行的一类简单操作，并展示了复杂任务可以作为这些简单操作的组合来处理，因此可以通过堆叠多个注意力层来解决。这为研究更实际和复杂的问题提供了启示。",
    "tldr": "Transformer的深度对其进行不同任务的影响进行了系统评估，研究发现推理和泛化需要至少两个注意力层，而上下文泛化可能需要三个注意力层。通过组合简单操作和堆叠多个注意力层，复杂任务可以得到解决。",
    "en_tdlr": "The study systematically evaluated the impact of varying depths of Transformer on different tasks, revealing that reasoning and generalization require at least two attention layers, while contextual generalization may need three attention layers. Complex tasks can be solved by combining simple operations and stacking multiple attention layers."
}