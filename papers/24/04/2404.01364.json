{
    "title": "Information Plane Analysis Visualization in Deep Learning via Transfer Entropy",
    "abstract": "arXiv:2404.01364v1 Announce Type: cross  Abstract: In a feedforward network, Transfer Entropy (TE) can be used to measure the influence that one layer has on another by quantifying the information transfer between them during training. According to the Information Bottleneck principle, a neural model's internal representation should compress the input data as much as possible while still retaining sufficient information about the output. Information Plane analysis is a visualization technique used to understand the trade-off between compression and information preservation in the context of the Information Bottleneck method by plotting the amount of information in the input data against the compressed representation. The claim that there is a causal link between information-theoretic compression and generalization, measured by mutual information, is plausible, but results from different studies are conflicting. In contrast to mutual information, TE can capture temporal relationships be",
    "link": "https://arxiv.org/abs/2404.01364",
    "context": "Title: Information Plane Analysis Visualization in Deep Learning via Transfer Entropy\nAbstract: arXiv:2404.01364v1 Announce Type: cross  Abstract: In a feedforward network, Transfer Entropy (TE) can be used to measure the influence that one layer has on another by quantifying the information transfer between them during training. According to the Information Bottleneck principle, a neural model's internal representation should compress the input data as much as possible while still retaining sufficient information about the output. Information Plane analysis is a visualization technique used to understand the trade-off between compression and information preservation in the context of the Information Bottleneck method by plotting the amount of information in the input data against the compressed representation. The claim that there is a causal link between information-theoretic compression and generalization, measured by mutual information, is plausible, but results from different studies are conflicting. In contrast to mutual information, TE can capture temporal relationships be",
    "path": "papers/24/04/2404.01364.json",
    "total_tokens": 780,
    "translated_title": "通过转移熵在深度学习中的信息平面分析可视化",
    "translated_abstract": "在前馈网络中，可以利用转移熵（TE）来衡量一层对另一层的影响，通过量化它们之间在训练期间的信息传递。根据信息瓶颈原理，神经模型的内部表示应尽可能压缩输入数据，同时仍保留足够的关于输出的信息。信息平面分析是一种可视化技术，用于通过绘制输入数据中的信息量与压缩表示之间的关系，来理解信息瓶颈方法中压缩和信息保留之间的权衡。声称信息论压缩和泛化之间存在因果联系，通过互信息来衡量是可信的，但不同研究的结果存在冲突。TE可以捕捉时间关系，与互信息相比，存在差异。",
    "tldr": "通过转移熵进行信息平面分析可视化揭示了信息瓶颈方法中压缩和信息保留的权衡，以及信息论压缩与泛化之间存在的关系。",
    "en_tdlr": "Information Plane analysis visualization using Transfer Entropy reveals the trade-off between compression and information preservation in the Information Bottleneck method, and the relationship between information-theoretic compression and generalization."
}