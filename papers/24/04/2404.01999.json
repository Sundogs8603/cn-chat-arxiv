{
    "title": "Emergence of Chemotactic Strategies with Multi-Agent Reinforcement Learning",
    "abstract": "arXiv:2404.01999v1 Announce Type: cross  Abstract: Reinforcement learning (RL) is a flexible and efficient method for programming micro-robots in complex environments. Here we investigate whether reinforcement learning can provide insights into biological systems when trained to perform chemotaxis. Namely, whether we can learn about how intelligent agents process given information in order to swim towards a target. We run simulations covering a range of agent shapes, sizes, and swim speeds to determine if the physical constraints on biological swimmers, namely Brownian motion, lead to regions where reinforcement learners' training fails. We find that the RL agents can perform chemotaxis as soon as it is physically possible and, in some cases, even before the active swimming overpowers the stochastic environment. We study the efficiency of the emergent policy and identify convergence in agent size and swim speeds. Finally, we study the strategy adopted by the reinforcement learning algo",
    "link": "https://arxiv.org/abs/2404.01999",
    "context": "Title: Emergence of Chemotactic Strategies with Multi-Agent Reinforcement Learning\nAbstract: arXiv:2404.01999v1 Announce Type: cross  Abstract: Reinforcement learning (RL) is a flexible and efficient method for programming micro-robots in complex environments. Here we investigate whether reinforcement learning can provide insights into biological systems when trained to perform chemotaxis. Namely, whether we can learn about how intelligent agents process given information in order to swim towards a target. We run simulations covering a range of agent shapes, sizes, and swim speeds to determine if the physical constraints on biological swimmers, namely Brownian motion, lead to regions where reinforcement learners' training fails. We find that the RL agents can perform chemotaxis as soon as it is physically possible and, in some cases, even before the active swimming overpowers the stochastic environment. We study the efficiency of the emergent policy and identify convergence in agent size and swim speeds. Finally, we study the strategy adopted by the reinforcement learning algo",
    "path": "papers/24/04/2404.01999.json",
    "total_tokens": 894,
    "translated_title": "利用多智能体强化学习实现趋化策略的出现",
    "translated_abstract": "强化学习（RL）是一种在复杂环境中为微型机器人编程的灵活高效的方法。本文探讨了当强化学习被训练执行趋化时，是否能向生物系统提供洞察。具体而言，我们探究了智能体如何处理信息以朝向目标游动。我们进行了一系列模拟实验，涵盖了各种智能体形状、大小和游泳速度，以确定生物游泳者的物理约束，即布朗运动，是否导致强化学习者的训练失败。我们发现RL智能体可以在物理可能性范围内执行趋化，并且在某些情况下，甚至在主动游动压倒随机环境之前就能执行趋化。我们研究了新兴政策的效率，并确定了智能体大小和游泳速度的收敛。最后，我们研究了强化学习算法采用的策略。",
    "tldr": "强化学习在趋化方面的应用研究表明，智能体能够根据布朗运动物理约束快速实现趋化，同时发现新兴策略的效率和智能体大小、游泳速度的收敛。",
    "en_tdlr": "The study on the application of reinforcement learning in chemotaxis demonstrates that agents can quickly achieve chemotaxis based on physical constraints like Brownian motion, while also revealing the efficiency of emergent policies and the convergence in agent size and swim speeds."
}