{
    "title": "Towards Realistic Scene Generation with LiDAR Diffusion Models",
    "abstract": "arXiv:2404.00815v1 Announce Type: cross  Abstract: Diffusion models (DMs) excel in photo-realistic image synthesis, but their adaptation to LiDAR scene generation poses a substantial hurdle. This is primarily because DMs operating in the point space struggle to preserve the curve-like patterns and 3D geometry of LiDAR scenes, which consumes much of their representation power. In this paper, we propose LiDAR Diffusion Models (LiDMs) to generate LiDAR-realistic scenes from a latent space tailored to capture the realism of LiDAR scenes by incorporating geometric priors into the learning pipeline. Our method targets three major desiderata: pattern realism, geometry realism, and object realism. Specifically, we introduce curve-wise compression to simulate real-world LiDAR patterns, point-wise coordinate supervision to learn scene geometry, and patch-wise encoding for a full 3D object context. With these three core designs, our method achieves competitive performance on unconditional LiDAR g",
    "link": "https://arxiv.org/abs/2404.00815",
    "context": "Title: Towards Realistic Scene Generation with LiDAR Diffusion Models\nAbstract: arXiv:2404.00815v1 Announce Type: cross  Abstract: Diffusion models (DMs) excel in photo-realistic image synthesis, but their adaptation to LiDAR scene generation poses a substantial hurdle. This is primarily because DMs operating in the point space struggle to preserve the curve-like patterns and 3D geometry of LiDAR scenes, which consumes much of their representation power. In this paper, we propose LiDAR Diffusion Models (LiDMs) to generate LiDAR-realistic scenes from a latent space tailored to capture the realism of LiDAR scenes by incorporating geometric priors into the learning pipeline. Our method targets three major desiderata: pattern realism, geometry realism, and object realism. Specifically, we introduce curve-wise compression to simulate real-world LiDAR patterns, point-wise coordinate supervision to learn scene geometry, and patch-wise encoding for a full 3D object context. With these three core designs, our method achieves competitive performance on unconditional LiDAR g",
    "path": "papers/24/04/2404.00815.json",
    "total_tokens": 682,
    "translated_title": "基于LiDAR扩散模型的逼真场景生成",
    "translated_abstract": "扩散模型在逼真图像合成方面表现出色，但是它们在适应LiDAR场景生成方面面临重大障碍。本文提出了LiDAR扩散模型（LiDMs），通过在学习流程中引入几何先验，从而生成具有LiDAR逼真效果的场景。",
    "tldr": "本文提出了LiDAR扩散模型（LiDMs），能够生成具有LiDAR逼真效果的场景，通过引入几何先验，实现了模式逼真、几何逼真和物体逼真。",
    "en_tdlr": "This paper introduces LiDAR Diffusion Models (LiDMs), which can generate LiDAR-realistic scenes by incorporating geometric priors, achieving pattern realism, geometry realism, and object realism."
}