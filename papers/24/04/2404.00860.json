{
    "title": "Lipsum-FT: Robust Fine-Tuning of Zero-Shot Models Using Random Text Guidance",
    "abstract": "arXiv:2404.00860v1 Announce Type: new  Abstract: Large-scale contrastive vision-language pre-trained models provide the zero-shot model achieving competitive performance across a range of image classification tasks without requiring training on downstream data. Recent works have confirmed that while additional fine-tuning of the zero-shot model on the reference data results in enhanced downstream performance, it compromises the model's robustness against distribution shifts. Our investigation begins by examining the conditions required to achieve the goals of robust fine-tuning, employing descriptions based on feature distortion theory and joint energy-based models. Subsequently, we propose a novel robust fine-tuning algorithm, Lipsum-FT, that effectively utilizes the language modeling aspect of the vision-language pre-trained models. Extensive experiments conducted on distribution shift scenarios in DomainNet and ImageNet confirm the superiority of our proposed Lipsum-FT approach over",
    "link": "https://arxiv.org/abs/2404.00860",
    "context": "Title: Lipsum-FT: Robust Fine-Tuning of Zero-Shot Models Using Random Text Guidance\nAbstract: arXiv:2404.00860v1 Announce Type: new  Abstract: Large-scale contrastive vision-language pre-trained models provide the zero-shot model achieving competitive performance across a range of image classification tasks without requiring training on downstream data. Recent works have confirmed that while additional fine-tuning of the zero-shot model on the reference data results in enhanced downstream performance, it compromises the model's robustness against distribution shifts. Our investigation begins by examining the conditions required to achieve the goals of robust fine-tuning, employing descriptions based on feature distortion theory and joint energy-based models. Subsequently, we propose a novel robust fine-tuning algorithm, Lipsum-FT, that effectively utilizes the language modeling aspect of the vision-language pre-trained models. Extensive experiments conducted on distribution shift scenarios in DomainNet and ImageNet confirm the superiority of our proposed Lipsum-FT approach over",
    "path": "papers/24/04/2404.00860.json",
    "total_tokens": 780,
    "translated_title": "Lipsum-FT: 使用随机文本引导进行零样本模型的稳健微调",
    "translated_abstract": "大规模对比视觉-语言预训练模型为零样本模型提供了在一系列图像分类任务上取得竞争性表现的能力，而无需在下游数据上进行训练。我们的调查从研究需要达到稳健微调目标的条件开始，采用了基于特征失真理论和联合能量模型的描述。随后，我们提出了一种新颖的稳健微调算法 Lipsum-FT，有效利用视觉-语言预训练模型的语言建模方面。在 DomainNet 和 ImageNet 上进行的分布转移场景的大量实验验证了我们提出的 Lipsum-FT 方法的优越性。",
    "tldr": "本研究提出了一种名为 Lipsum-FT 的算法，通过有效利用视觉-语言预训练模型的语言建模，实现了在分布转移场景下对零样本模型进行稳健微调，提高了下游任务的性能。",
    "en_tdlr": "This study introduces Lipsum-FT algorithm, which achieves robust fine-tuning of zero-shot models in distribution shift scenarios by effectively utilizing the language modeling aspect of vision-language pre-trained models, leading to enhanced downstream performance."
}