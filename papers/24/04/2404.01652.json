{
    "title": "Towards Better Generalization in Open-Domain Question Answering by Mitigating Context Memorization",
    "abstract": "arXiv:2404.01652v1 Announce Type: cross  Abstract: Open-domain Question Answering (OpenQA) aims at answering factual questions with an external large-scale knowledge corpus. However, real-world knowledge is not static; it updates and evolves continually. Such a dynamic characteristic of knowledge poses a vital challenge for these models, as the trained models need to constantly adapt to the latest information to make sure that the answers remain accurate. In addition, it is still unclear how well an OpenQA model can transfer to completely new knowledge domains. In this paper, we investigate the generalization performance of a retrieval-augmented QA model in two specific scenarios: 1) adapting to updated versions of the same knowledge corpus; 2) switching to completely different knowledge domains. We observe that the generalization challenges of OpenQA models stem from the reader's over-reliance on memorizing the knowledge from the external corpus, which hinders the model from generaliz",
    "link": "https://arxiv.org/abs/2404.01652",
    "context": "Title: Towards Better Generalization in Open-Domain Question Answering by Mitigating Context Memorization\nAbstract: arXiv:2404.01652v1 Announce Type: cross  Abstract: Open-domain Question Answering (OpenQA) aims at answering factual questions with an external large-scale knowledge corpus. However, real-world knowledge is not static; it updates and evolves continually. Such a dynamic characteristic of knowledge poses a vital challenge for these models, as the trained models need to constantly adapt to the latest information to make sure that the answers remain accurate. In addition, it is still unclear how well an OpenQA model can transfer to completely new knowledge domains. In this paper, we investigate the generalization performance of a retrieval-augmented QA model in two specific scenarios: 1) adapting to updated versions of the same knowledge corpus; 2) switching to completely different knowledge domains. We observe that the generalization challenges of OpenQA models stem from the reader's over-reliance on memorizing the knowledge from the external corpus, which hinders the model from generaliz",
    "path": "papers/24/04/2404.01652.json",
    "total_tokens": 882,
    "translated_title": "通过缓解上下文记忆实现开放域问答中更好的泛化",
    "translated_abstract": "开放域问答（OpenQA）旨在利用外部大规模知识语料库回答事实问题。然而，现实世界中的知识并非静态的；它不断更新和演变。这种知识的动态特性为这些模型带来了重要挑战，因为训练的模型需要不断适应最新信息，以确保答案保持准确。此外，目前尚不清楚开放域问答模型能够多好地转移到完全新的知识领域。本文研究了一个基于检索增强的QA模型在两种具体情景下的泛化性能：1）适应相同知识语料库的更新版本；2）转换到完全不同的知识领域。我们发现，开放域问答模型的泛化挑战源自阅读器过度依赖从外部语料库中记忆知识，从而阻碍了模型的泛化能力。",
    "tldr": "本文研究了在开放域问答中泛化性能的问题，发现挑战在于阅读器过度依赖记忆外部语料库的知识，限制了模型的泛化能力。",
    "en_tdlr": "This paper investigates the generalization performance in open-domain question answering, revealing that the challenge lies in the reader's over-reliance on memorizing knowledge from the external corpus, which hinders the model's generalization ability."
}