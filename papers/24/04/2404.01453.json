{
    "title": "Unveiling Divergent Inductive Biases of LLMs on Temporal Data",
    "abstract": "arXiv:2404.01453v1 Announce Type: cross  Abstract: Unraveling the intricate details of events in natural language necessitates a subtle understanding of temporal dynamics. Despite the adeptness of Large Language Models (LLMs) in discerning patterns and relationships from data, their inherent comprehension of temporal dynamics remains a formidable challenge. This research meticulously explores these intrinsic challenges within LLMs, with a specific emphasis on evaluating the performance of GPT-3.5 and GPT-4 models in the analysis of temporal data. Employing two distinct prompt types, namely Question Answering (QA) format and Textual Entailment (TE) format, our analysis probes into both implicit and explicit events. The findings underscore noteworthy trends, revealing disparities in the performance of GPT-3.5 and GPT-4. Notably, biases toward specific temporal relationships come to light, with GPT-3.5 demonstrating a preference for \"AFTER'' in the QA format for both implicit and explicit",
    "link": "https://arxiv.org/abs/2404.01453",
    "context": "Title: Unveiling Divergent Inductive Biases of LLMs on Temporal Data\nAbstract: arXiv:2404.01453v1 Announce Type: cross  Abstract: Unraveling the intricate details of events in natural language necessitates a subtle understanding of temporal dynamics. Despite the adeptness of Large Language Models (LLMs) in discerning patterns and relationships from data, their inherent comprehension of temporal dynamics remains a formidable challenge. This research meticulously explores these intrinsic challenges within LLMs, with a specific emphasis on evaluating the performance of GPT-3.5 and GPT-4 models in the analysis of temporal data. Employing two distinct prompt types, namely Question Answering (QA) format and Textual Entailment (TE) format, our analysis probes into both implicit and explicit events. The findings underscore noteworthy trends, revealing disparities in the performance of GPT-3.5 and GPT-4. Notably, biases toward specific temporal relationships come to light, with GPT-3.5 demonstrating a preference for \"AFTER'' in the QA format for both implicit and explicit",
    "path": "papers/24/04/2404.01453.json",
    "total_tokens": 902,
    "translated_title": "揭示LLMs在时间数据上的分歧归纳偏见",
    "translated_abstract": "揭示自然语言事件的微妙细节需要对时间动态进行微妙理解。尽管大型语言模型（LLMs）在从数据中辨别模式和关系方面表现得很熟练，但它们对时间动态的内在理解仍然是一个巨大挑战。本研究在LLMs中细致探索这些固有挑战，特别强调评估GPT-3.5和GPT-4模型在时间数据分析中的性能。通过采用问答（QA）格式和文本蕴涵（TE）格式两种不同的提示类型，我们的分析深入探究了隐式和显式事件。研究结果凸显了一些显著趋势，揭示了GPT-3.5和GPT-4性能上的差异。值得注意的是，倾向于特定时间关系的偏见浮出水面，其中在QA格式中，GPT-3.5在隐式和显式方面均表现出对\"AFTER\"的偏好。",
    "tldr": "本研究探索了LLMs在时间数据分析中的固有挑战，重点评估了GPT-3.5和GPT-4模型的性能，发现了它们在特定时间关系上存在偏向性。",
    "en_tdlr": "This study explores the inherent challenges of LLMs in analyzing temporal data, with a focus on evaluating the performance of GPT-3.5 and GPT-4 models, revealing biases towards specific temporal relationships."
}