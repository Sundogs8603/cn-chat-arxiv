{
    "title": "Modeling Output-Level Task Relatedness in Multi-Task Learning with Feedback Mechanism",
    "abstract": "arXiv:2404.00885v1 Announce Type: new  Abstract: Multi-task learning (MTL) is a paradigm that simultaneously learns multiple tasks by sharing information at different levels, enhancing the performance of each individual task. While previous research has primarily focused on feature-level or parameter-level task relatedness, and proposed various model architectures and learning algorithms to improve learning performance, we aim to explore output-level task relatedness. This approach introduces a posteriori information into the model, considering that different tasks may produce correlated outputs with mutual influences. We achieve this by incorporating a feedback mechanism into MTL models, where the output of one task serves as a hidden feature for another task, thereby transforming a static MTL model into a dynamic one. To ensure the training process converges, we introduce a convergence loss that measures the trend of a task's outputs during each iteration. Additionally, we propose a ",
    "link": "https://arxiv.org/abs/2404.00885",
    "context": "Title: Modeling Output-Level Task Relatedness in Multi-Task Learning with Feedback Mechanism\nAbstract: arXiv:2404.00885v1 Announce Type: new  Abstract: Multi-task learning (MTL) is a paradigm that simultaneously learns multiple tasks by sharing information at different levels, enhancing the performance of each individual task. While previous research has primarily focused on feature-level or parameter-level task relatedness, and proposed various model architectures and learning algorithms to improve learning performance, we aim to explore output-level task relatedness. This approach introduces a posteriori information into the model, considering that different tasks may produce correlated outputs with mutual influences. We achieve this by incorporating a feedback mechanism into MTL models, where the output of one task serves as a hidden feature for another task, thereby transforming a static MTL model into a dynamic one. To ensure the training process converges, we introduce a convergence loss that measures the trend of a task's outputs during each iteration. Additionally, we propose a ",
    "path": "papers/24/04/2404.00885.json",
    "total_tokens": 634,
    "translated_title": "用反馈机制建模多任务学习中的输出级任务相关性",
    "translated_abstract": "多任务学习（MTL）是一种通过在不同层次共享信息来同时学习多个任务的范式，增强每个单独任务的性能。我们旨在探索输出级任务相关性，通过将后验信息引入模型，考虑到不同任务可能产生相关的相互影响的输出。",
    "tldr": "在多任务学习中引入反馈机制，将一个任务的输出作为另一个任务的隐藏特征，使静态的多任务学习模型转变为动态模型。",
    "en_tdlr": "Introducing a feedback mechanism in multi-task learning, where the output of one task serves as a hidden feature for another task, transforming a static MTL model into a dynamic one."
}