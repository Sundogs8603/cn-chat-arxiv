{
    "title": "Memory-based Cross-modal Semantic Alignment Network for Radiology Report Generation",
    "abstract": "arXiv:2404.00588v1 Announce Type: cross  Abstract: Generating radiology reports automatically reduces the workload of radiologists and helps the diagnoses of specific diseases. Many existing methods take this task as modality transfer process. However, since the key information related to disease accounts for a small proportion in both image and report, it is hard for the model to learn the latent relation between the radiology image and its report, thus failing to generate fluent and accurate radiology reports. To tackle this problem, we propose a memory-based cross-modal semantic alignment model (MCSAM) following an encoder-decoder paradigm. MCSAM includes a well initialized long-term clinical memory bank to learn disease-related representations as well as prior knowledge for different modalities to retrieve and use the retrieved memory to perform feature consolidation. To ensure the semantic consistency of the retrieved cross modal prior knowledge, a cross-modal semantic alignment m",
    "link": "https://arxiv.org/abs/2404.00588",
    "context": "Title: Memory-based Cross-modal Semantic Alignment Network for Radiology Report Generation\nAbstract: arXiv:2404.00588v1 Announce Type: cross  Abstract: Generating radiology reports automatically reduces the workload of radiologists and helps the diagnoses of specific diseases. Many existing methods take this task as modality transfer process. However, since the key information related to disease accounts for a small proportion in both image and report, it is hard for the model to learn the latent relation between the radiology image and its report, thus failing to generate fluent and accurate radiology reports. To tackle this problem, we propose a memory-based cross-modal semantic alignment model (MCSAM) following an encoder-decoder paradigm. MCSAM includes a well initialized long-term clinical memory bank to learn disease-related representations as well as prior knowledge for different modalities to retrieve and use the retrieved memory to perform feature consolidation. To ensure the semantic consistency of the retrieved cross modal prior knowledge, a cross-modal semantic alignment m",
    "path": "papers/24/04/2404.00588.json",
    "total_tokens": 808,
    "translated_title": "基于记忆的交叉模态语义对齐网络用于放射学报告生成",
    "translated_abstract": "生成放射学报告可以自动减少放射科医生的工作量并有助于特定疾病的诊断。然而，由于涉及疾病的关键信息在图像和报告中所占比例很小，模型很难学习放射学图像和报告之间的潜在关系，从而无法生成流畅和准确的放射学报告。为了解决这个问题，我们提出了一种基于记忆的交叉模态语义对齐模型（MCSAM），采用编码-解码范式。MCSAM包括一个良好初始化的长期临床记忆库，用于学习与疾病相关的表示以及不同模态的先验知识，以检索并利用检索到的记忆来进行特征整合。为了确保检索到的跨模态先验知识的语义一致性，提出了一个跨模态语义对齐模",
    "tldr": "提出了一种基于记忆的交叉模态语义对齐网络用于减少工作量并生成准确放射学报告"
}