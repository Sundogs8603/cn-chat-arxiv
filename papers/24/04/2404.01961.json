{
    "title": "Team UTSA-NLP at SemEval 2024 Task 5: Prompt Ensembling for Argument Reasoning in Civil Procedures with GPT4",
    "abstract": "arXiv:2404.01961v1 Announce Type: new  Abstract: In this paper, we present our system for the SemEval Task 5, The Legal Argument Reasoning Task in Civil Procedure Challenge. Legal argument reasoning is an essential skill that all law students must master. Moreover, it is important to develop natural language processing solutions that can reason about a question given terse domain-specific contextual information. Our system explores a prompt-based solution using GPT4 to reason over legal arguments. We also evaluate an ensemble of prompting strategies, including chain-of-thought reasoning and in-context learning. Overall, our system results in a Macro F1 of .8095 on the validation dataset and .7315 (5th out of 21 teams) on the final test set. Code for this project is available at https://github.com/danschumac1/CivilPromptReasoningGPT4.",
    "link": "https://arxiv.org/abs/2404.01961",
    "context": "Title: Team UTSA-NLP at SemEval 2024 Task 5: Prompt Ensembling for Argument Reasoning in Civil Procedures with GPT4\nAbstract: arXiv:2404.01961v1 Announce Type: new  Abstract: In this paper, we present our system for the SemEval Task 5, The Legal Argument Reasoning Task in Civil Procedure Challenge. Legal argument reasoning is an essential skill that all law students must master. Moreover, it is important to develop natural language processing solutions that can reason about a question given terse domain-specific contextual information. Our system explores a prompt-based solution using GPT4 to reason over legal arguments. We also evaluate an ensemble of prompting strategies, including chain-of-thought reasoning and in-context learning. Overall, our system results in a Macro F1 of .8095 on the validation dataset and .7315 (5th out of 21 teams) on the final test set. Code for this project is available at https://github.com/danschumac1/CivilPromptReasoningGPT4.",
    "path": "papers/24/04/2404.01961.json",
    "total_tokens": 914,
    "translated_title": "Team UTSA-NLP在SemEval 2024任务5中的表现：基于GPT4的民事诉讼中的辩证推理的提示合成",
    "translated_abstract": "在本文中，我们介绍了我们针对SemEval任务5（民事诉讼中的法律辩证任务挑战）的系统。法律辩证推理是所有法学生都必须掌握的基本技能。此外，开发能够根据简洁的领域特定上下文信息推理问题的自然语言处理解决方案至关重要。我们的系统探索了使用GPT4进行基于提示的解决方案来推理法律论点。我们还评估了一系列提示策略的集合，包括思维链推理和上下文学习。总体而言，我们的系统在验证数据集上取得了Macro F1值为0.8095，在最终测试集上取得了0.7315（21个团队中排名第5）。此项目的代码可在https://github.com/danschumac1/CivilPromptReasoningGPT4 获取。",
    "tldr": "通过使用GPT4进行基于提示的解决方案，我们的系统在民事诉讼中的辩证推理方面取得了显著成果，包括思维链推理和上下文学习等提示策略的集成。在SemEval任务5中，我们获得了0.8095的Macro F1值，并在最终测试集中排名第5。",
    "en_tdlr": "Our system achieved significant results in argument reasoning in civil procedures by employing prompt-based solutions with GPT4, integrating prompting strategies including chain-of-thought reasoning and in-context learning. We obtained a Macro F1 score of 0.8095 in SemEval Task 5, ranking 5th in the final test set."
}