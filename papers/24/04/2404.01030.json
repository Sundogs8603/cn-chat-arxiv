{
    "title": "Survey of Bias In Text-to-Image Generation: Definition, Evaluation, and Mitigation",
    "abstract": "arXiv:2404.01030v1 Announce Type: cross  Abstract: The recent advancement of large and powerful models with Text-to-Image (T2I) generation abilities -- such as OpenAI's DALLE-3 and Google's Gemini -- enables users to generate high-quality images from textual prompts. However, it has become increasingly evident that even simple prompts could cause T2I models to exhibit conspicuous social bias in generated images. Such bias might lead to both allocational and representational harms in society, further marginalizing minority groups. Noting this problem, a large body of recent works has been dedicated to investigating different dimensions of bias in T2I systems. However, an extensive review of these studies is lacking, hindering a systematic understanding of current progress and research gaps. We present the first extensive survey on bias in T2I generative models. In this survey, we review prior studies on dimensions of bias: Gender, Skintone, and Geo-Culture. Specifically, we discuss how ",
    "link": "https://arxiv.org/abs/2404.01030",
    "context": "Title: Survey of Bias In Text-to-Image Generation: Definition, Evaluation, and Mitigation\nAbstract: arXiv:2404.01030v1 Announce Type: cross  Abstract: The recent advancement of large and powerful models with Text-to-Image (T2I) generation abilities -- such as OpenAI's DALLE-3 and Google's Gemini -- enables users to generate high-quality images from textual prompts. However, it has become increasingly evident that even simple prompts could cause T2I models to exhibit conspicuous social bias in generated images. Such bias might lead to both allocational and representational harms in society, further marginalizing minority groups. Noting this problem, a large body of recent works has been dedicated to investigating different dimensions of bias in T2I systems. However, an extensive review of these studies is lacking, hindering a systematic understanding of current progress and research gaps. We present the first extensive survey on bias in T2I generative models. In this survey, we review prior studies on dimensions of bias: Gender, Skintone, and Geo-Culture. Specifically, we discuss how ",
    "path": "papers/24/04/2404.01030.json",
    "total_tokens": 867,
    "translated_title": "文本到图像生成中的偏见调查：定义、评估和缓解",
    "translated_abstract": "最近强大的大型模型，如OpenAI的DALLE-3和Google的Gemini，使得用户能够从文本提示生成高质量图像。然而，即使是简单的提示也可能导致文本到图像模型在生成的图像中展现明显的社会偏见。这种偏见可能会导致社会中的分配和代表性伤害，进一步边缘化少数群体。鉴于这一问题，最近有大量研究致力于调查文本到图像系统中偏见的不同维度。然而，对这些研究的全面回顾仍然缺乏，阻碍了对当前进展和研究空白的系统性理解。我们提出了关于文本到图像生成模型中偏见的第一次广泛调查。在这项调查中，我们回顾了先前关于偏见维度的研究：性别、肤色和地域文化。",
    "tldr": "该调查综述了文本到图像生成中的偏见问题，重点讨论了性别、肤色和地域文化这些方面，旨在帮助理解当前进展和研究空白。",
    "en_tdlr": "This survey provides an extensive review of bias in text-to-image generation, focusing on gender, skintone, and geo-culture dimensions, aiming to facilitate understanding of current progress and research gaps."
}