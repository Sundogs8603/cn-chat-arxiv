{
    "title": "Privacy Re-identification Attacks on Tabular GANs",
    "abstract": "arXiv:2404.00696v1 Announce Type: cross  Abstract: Generative models are subject to overfitting and thus may potentially leak sensitive information from the training data. In this work. we investigate the privacy risks that can potentially arise from the use of generative adversarial networks (GANs) for creating tabular synthetic datasets. For the purpose, we analyse the effects of re-identification attacks on synthetic data, i.e., attacks which aim at selecting samples that are predicted to correspond to memorised training samples based on their proximity to the nearest synthetic records. We thus consider multiple settings where different attackers might have different access levels or knowledge of the generative model and predictive, and assess which information is potentially most useful for launching more successful re-identification attacks. In doing so we also consider the situation for which re-identification attacks are formulated as reconstruction attacks, i.e., the situation ",
    "link": "https://arxiv.org/abs/2404.00696",
    "context": "Title: Privacy Re-identification Attacks on Tabular GANs\nAbstract: arXiv:2404.00696v1 Announce Type: cross  Abstract: Generative models are subject to overfitting and thus may potentially leak sensitive information from the training data. In this work. we investigate the privacy risks that can potentially arise from the use of generative adversarial networks (GANs) for creating tabular synthetic datasets. For the purpose, we analyse the effects of re-identification attacks on synthetic data, i.e., attacks which aim at selecting samples that are predicted to correspond to memorised training samples based on their proximity to the nearest synthetic records. We thus consider multiple settings where different attackers might have different access levels or knowledge of the generative model and predictive, and assess which information is potentially most useful for launching more successful re-identification attacks. In doing so we also consider the situation for which re-identification attacks are formulated as reconstruction attacks, i.e., the situation ",
    "path": "papers/24/04/2404.00696.json",
    "total_tokens": 812,
    "translated_title": "针对表格生成对抗网络的隐私再识别攻击",
    "translated_abstract": "生成模型容易出现过拟合，因此可能潜在地泄露训练数据的敏感信息。本研究调查了使用生成对抗网络（GANs）生成表格合成数据时可能产生的隐私风险。我们分析了对合成数据进行再识别攻击的影响，即攻击旨在选择被预测与基于最接近合成记录的记忆训练样本对应的样本。我们考虑了多种不同攻击者可能具有不同访问级别或对生成模型和预测的知识，并评估哪些信息可能最有助于发动更成功的再识别攻击。在此过程中，我们还考虑了将再识别攻击制定为重建攻击的情形。",
    "tldr": "本研究调查了使用生成对抗网络（GANs）生成表格合成数据时可能产生的隐私风险，分析了对合成数据进行再识别攻击的影响以及信息对发动更成功的再识别攻击的潜在用处。",
    "en_tdlr": "This study investigates the privacy risks of using generative adversarial networks (GANs) to generate tabular synthetic datasets, analyzing the impact of re-identification attacks on synthetic data and assessing the potential usefulness of information for launching more successful re-identification attacks."
}