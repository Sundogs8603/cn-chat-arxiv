{
    "title": "Label-Agnostic Forgetting: A Supervision-Free Unlearning in Deep Models",
    "abstract": "arXiv:2404.00506v1 Announce Type: new  Abstract: Machine unlearning aims to remove information derived from forgotten data while preserving that of the remaining dataset in a well-trained model. With the increasing emphasis on data privacy, several approaches to machine unlearning have emerged. However, these methods typically rely on complete supervision throughout the unlearning process. Unfortunately, obtaining such supervision, whether for the forgetting or remaining data, can be impractical due to the substantial cost associated with annotating real-world datasets. This challenge prompts us to propose a supervision-free unlearning approach that operates without the need for labels during the unlearning process. Specifically, we introduce a variational approach to approximate the distribution of representations for the remaining data. Leveraging this approximation, we adapt the original model to eliminate information from the forgotten data at the representation level. To further a",
    "link": "https://arxiv.org/abs/2404.00506",
    "context": "Title: Label-Agnostic Forgetting: A Supervision-Free Unlearning in Deep Models\nAbstract: arXiv:2404.00506v1 Announce Type: new  Abstract: Machine unlearning aims to remove information derived from forgotten data while preserving that of the remaining dataset in a well-trained model. With the increasing emphasis on data privacy, several approaches to machine unlearning have emerged. However, these methods typically rely on complete supervision throughout the unlearning process. Unfortunately, obtaining such supervision, whether for the forgetting or remaining data, can be impractical due to the substantial cost associated with annotating real-world datasets. This challenge prompts us to propose a supervision-free unlearning approach that operates without the need for labels during the unlearning process. Specifically, we introduce a variational approach to approximate the distribution of representations for the remaining data. Leveraging this approximation, we adapt the original model to eliminate information from the forgotten data at the representation level. To further a",
    "path": "papers/24/04/2404.00506.json",
    "total_tokens": 773,
    "translated_title": "与标签无关的遗忘:深度模型中无监督的去学习",
    "translated_abstract": "机器去学习旨在从已遗忘数据中删除信息，同时保留训练良好的模型中剩余数据的信息。然而，现有的机器去学习方法通常依赖于整个去学习过程中的完全监督。不幸的是，由于标注真实世界数据集所需的巨大成本，获得这种监督可能实际上是不切实际的。这个挑战促使我们提出一种在去学习过程中无需标签的无监督去学习方法。具体地，我们引入一种变分方法来近似剩余数据的表示分布。利用这种近似，我们调整原始模型以在表示级别消除已遗忘数据中的信息。",
    "tldr": "该论文提出了一种无需标签的无监督去学习方法，通过引入变分方法并利用表示分布的近似，实现了在深度模型中消除已遗忘数据信息的目标。",
    "en_tdlr": "This paper presents a supervision-free unlearning approach by introducing a variational method and leveraging the approximation of representation distribution, achieving the goal of eliminating information from forgotten data in deep models."
}