{
    "title": "Removing Speaker Information from Speech Representation using Variable-Length Soft Pooling",
    "abstract": "arXiv:2404.00856v1 Announce Type: cross  Abstract: Recently, there have been efforts to encode the linguistic information of speech using a self-supervised framework for speech synthesis. However, predicting representations from surrounding representations can inadvertently entangle speaker information in the speech representation. This paper aims to remove speaker information by exploiting the structured nature of speech, composed of discrete units like phonemes with clear boundaries. A neural network predicts these boundaries, enabling variable-length pooling for event-based representation extraction instead of fixed-rate methods. The boundary predictor outputs a probability for the boundary between 0 and 1, making pooling soft. The model is trained to minimize the difference with the pooled representation of the data augmented by time-stretch and pitch-shift. To confirm that the learned representation includes contents information but is independent of speaker information, the model",
    "link": "https://arxiv.org/abs/2404.00856",
    "context": "Title: Removing Speaker Information from Speech Representation using Variable-Length Soft Pooling\nAbstract: arXiv:2404.00856v1 Announce Type: cross  Abstract: Recently, there have been efforts to encode the linguistic information of speech using a self-supervised framework for speech synthesis. However, predicting representations from surrounding representations can inadvertently entangle speaker information in the speech representation. This paper aims to remove speaker information by exploiting the structured nature of speech, composed of discrete units like phonemes with clear boundaries. A neural network predicts these boundaries, enabling variable-length pooling for event-based representation extraction instead of fixed-rate methods. The boundary predictor outputs a probability for the boundary between 0 and 1, making pooling soft. The model is trained to minimize the difference with the pooled representation of the data augmented by time-stretch and pitch-shift. To confirm that the learned representation includes contents information but is independent of speaker information, the model",
    "path": "papers/24/04/2404.00856.json",
    "total_tokens": 767,
    "translated_title": "使用可变长度软池化从语音表示中去除说话者信息",
    "translated_abstract": "最近，有一些研究致力于利用自监督框架对语音进行编码，以进行语音合成的语言信息。然而，从周围表示预测表示可能会在语音表示中不经意地缠结说话者信息。本文旨在通过利用语音的结构化特性来去除说话者信息，语音由具有清晰边界的离散单元(如音素)组成。神经网络预测这些边界，实现基于事件的表示提取的可变长度池化，而不是固定速率方法。边界预测器输出介于0和1之间的边界概率，使池化软化。模型训练以最小化数据增强的池化表示与时间拉伸和音高变换之间的差异。为了确认学到的表示包含内容信息但独立于说话者信息，模型...",
    "tldr": "该论文旨在利用神经网络预测语音中离散单元边界，实现可变长度池化，从而去除表示中的说话者信息。",
    "en_tdlr": "This paper aims to remove speaker information from speech representations by predicting boundaries of discrete units in speech with a neural network to enable variable-length pooling."
}