{
    "title": "Heterogeneous Contrastive Learning for Foundation Models and Beyond",
    "abstract": "arXiv:2404.00225v1 Announce Type: new  Abstract: In the era of big data and Artificial Intelligence, an emerging paradigm is to utilize contrastive self-supervised learning to model large-scale heterogeneous data. Many existing foundation models benefit from the generalization capability of contrastive self-supervised learning by learning compact and high-quality representations without relying on any label information. Amidst the explosive advancements in foundation models across multiple domains, including natural language processing and computer vision, a thorough survey on heterogeneous contrastive learning for the foundation model is urgently needed. In response, this survey critically evaluates the current landscape of heterogeneous contrastive learning for foundation models, highlighting the open challenges and future trends of contrastive learning. In particular, we first present how the recent advanced contrastive learning-based methods deal with view heterogeneity and how con",
    "link": "https://arxiv.org/abs/2404.00225",
    "context": "Title: Heterogeneous Contrastive Learning for Foundation Models and Beyond\nAbstract: arXiv:2404.00225v1 Announce Type: new  Abstract: In the era of big data and Artificial Intelligence, an emerging paradigm is to utilize contrastive self-supervised learning to model large-scale heterogeneous data. Many existing foundation models benefit from the generalization capability of contrastive self-supervised learning by learning compact and high-quality representations without relying on any label information. Amidst the explosive advancements in foundation models across multiple domains, including natural language processing and computer vision, a thorough survey on heterogeneous contrastive learning for the foundation model is urgently needed. In response, this survey critically evaluates the current landscape of heterogeneous contrastive learning for foundation models, highlighting the open challenges and future trends of contrastive learning. In particular, we first present how the recent advanced contrastive learning-based methods deal with view heterogeneity and how con",
    "path": "papers/24/04/2404.00225.json",
    "total_tokens": 750,
    "translated_title": "基于异构对比学习的基础模型及其发展",
    "translated_abstract": "在大数据和人工智能时代，利用对比自监督学习来建模大规模异构数据的新兴范式受到关注。许多现有的基础模型通过学习紧凑、高质量的表示形式而受益于对比自监督学习的泛化能力，而无需依赖任何标签信息。本调查对基础模型的异构对比学习的当前情况进行了批判性评估，突出了对比学习的挑战和未来趋势。特别是，我们首先介绍了最近提出的基于对比学习的高级方法如何处理视图的异构性，以及对比学习在基础模型中的作用。",
    "tldr": "对比自监督学习为基础模型提供了泛化能力，本调查对基于对比学习的异构学习方法进行了评估，突出了挑战和未来趋势。",
    "en_tdlr": "Contrastive self-supervised learning enhances the generalization capability of foundation models. This survey evaluates the heterogeneous learning methods based on contrastive learning, highlighting challenges and future trends."
}