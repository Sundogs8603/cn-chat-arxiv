{
    "title": "RQ-RAG: Learning to Refine Queries for Retrieval Augmented Generation",
    "abstract": "arXiv:2404.00610v1 Announce Type: new  Abstract: Large Language Models (LLMs) exhibit remarkable capabilities but are prone to generating inaccurate or hallucinatory responses. This limitation stems from their reliance on vast pretraining datasets, making them susceptible to errors in unseen scenarios. To tackle these challenges, Retrieval-Augmented Generation (RAG) addresses this by incorporating external, relevant documents into the response generation process, thus leveraging non-parametric knowledge alongside LLMs' in-context learning abilities. However, existing RAG implementations primarily focus on initial input for context retrieval, overlooking the nuances of ambiguous or complex queries that necessitate further clarification or decomposition for accurate responses. To this end, we propose learning to Refine Query for Retrieval Augmented Generation (RQ-RAG) in this paper, endeavoring to enhance the model by equipping it with capabilities for explicit rewriting, decomposition, ",
    "link": "https://arxiv.org/abs/2404.00610",
    "context": "Title: RQ-RAG: Learning to Refine Queries for Retrieval Augmented Generation\nAbstract: arXiv:2404.00610v1 Announce Type: new  Abstract: Large Language Models (LLMs) exhibit remarkable capabilities but are prone to generating inaccurate or hallucinatory responses. This limitation stems from their reliance on vast pretraining datasets, making them susceptible to errors in unseen scenarios. To tackle these challenges, Retrieval-Augmented Generation (RAG) addresses this by incorporating external, relevant documents into the response generation process, thus leveraging non-parametric knowledge alongside LLMs' in-context learning abilities. However, existing RAG implementations primarily focus on initial input for context retrieval, overlooking the nuances of ambiguous or complex queries that necessitate further clarification or decomposition for accurate responses. To this end, we propose learning to Refine Query for Retrieval Augmented Generation (RQ-RAG) in this paper, endeavoring to enhance the model by equipping it with capabilities for explicit rewriting, decomposition, ",
    "path": "papers/24/04/2404.00610.json",
    "total_tokens": 785,
    "translated_title": "RQ-RAG: 学习为检索增强生成细化查询",
    "translated_abstract": "大型语言模型(LLMs)展示出卓越的能力，但容易生成不准确或幻觉性的响应。Retrieval-Augmented Generation (RAG)通过将外部相关文档纳入响应生成过程中，从而利用非参数化知识和LLMs的上下文学习能力，来解决这些挑战。然而，现有的RAG实现主要关注于上下文检索的初始输入，忽视了需要进一步澄清或分解以获得准确响应的模糊或复杂查询的细微差别。因此，本文提出了学习为检索增强生成细化查询(RQ-RAG)，致力于通过赋予模型显式重写、分解能力来增强模型。",
    "tldr": "本论文提出了RQ-RAG，旨在为检索增强生成模型增加细化查询的能力，以便针对模糊或复杂查询进一步澄清或分解，从而提高生成准确度。"
}