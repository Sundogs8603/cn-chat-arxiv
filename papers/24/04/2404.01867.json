{
    "title": "Active Exploration in Bayesian Model-based Reinforcement Learning for Robot Manipulation",
    "abstract": "arXiv:2404.01867v1 Announce Type: cross  Abstract: Efficiently tackling multiple tasks within complex environment, such as those found in robot manipulation, remains an ongoing challenge in robotics and an opportunity for data-driven solutions, such as reinforcement learning (RL). Model-based RL, by building a dynamic model of the robot, enables data reuse and transfer learning between tasks with the same robot and similar environment. Furthermore, data gathering in robotics is expensive and we must rely on data efficient approaches such as model-based RL, where policy learning is mostly conducted on cheaper simulations based on the learned model. Therefore, the quality of the model is fundamental for the performance of the posterior tasks. In this work, we focus on improving the quality of the model and maintaining the data efficiency by performing active learning of the dynamic model during a preliminary exploration phase based on maximize information gathering. We employ Bayesian ne",
    "link": "https://arxiv.org/abs/2404.01867",
    "context": "Title: Active Exploration in Bayesian Model-based Reinforcement Learning for Robot Manipulation\nAbstract: arXiv:2404.01867v1 Announce Type: cross  Abstract: Efficiently tackling multiple tasks within complex environment, such as those found in robot manipulation, remains an ongoing challenge in robotics and an opportunity for data-driven solutions, such as reinforcement learning (RL). Model-based RL, by building a dynamic model of the robot, enables data reuse and transfer learning between tasks with the same robot and similar environment. Furthermore, data gathering in robotics is expensive and we must rely on data efficient approaches such as model-based RL, where policy learning is mostly conducted on cheaper simulations based on the learned model. Therefore, the quality of the model is fundamental for the performance of the posterior tasks. In this work, we focus on improving the quality of the model and maintaining the data efficiency by performing active learning of the dynamic model during a preliminary exploration phase based on maximize information gathering. We employ Bayesian ne",
    "path": "papers/24/04/2404.01867.json",
    "total_tokens": 808,
    "translated_title": "机器人操作中基于贝叶斯模型的强化学习中的主动探索",
    "translated_abstract": "有效解决机器人操作等复杂环境中的多个任务仍然是机器人技术中的一个持续挑战，也是数据驱动解决方案（如强化学习（RL））的一个机会。模型驱动的RL通过构建机器人的动态模型，实现数据重用和在具有相同机器人和类似环境的任务之间进行迁移学习。此外，机器人学中的数据收集成本很高，我们必须依赖数据高效的方法，如基于模型的RL，在基于学习模型的廉价仿真中进行大部分策略学习。因此，模型的质量对于后续任务的性能至关重要。在这项工作中，我们致力于通过在初始探索阶段执行动态模型的主动学习，基于最大化信息收集，以提高模型的质量并保持数据效率。",
    "tldr": "该论文提出了在机器人操作中基于贝叶斯模型的强化学习中通过主动探索改善模型质量和保持数据效率的方法。",
    "en_tdlr": "The paper proposes a method in Bayesian model-based reinforcement learning for robot manipulation that improves model quality and maintains data efficiency through active exploration."
}