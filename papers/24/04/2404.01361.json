{
    "title": "LLM Attributor: Interactive Visual Attribution for LLM Generation",
    "abstract": "arXiv:2404.01361v1 Announce Type: cross  Abstract: While large language models (LLMs) have shown remarkable capability to generate convincing text across diverse domains, concerns around its potential risks have highlighted the importance of understanding the rationale behind text generation. We present LLM Attributor, a Python library that provides interactive visualizations for training data attribution of an LLM's text generation. Our library offers a new way to quickly attribute an LLM's text generation to training data points to inspect model behaviors, enhance its trustworthiness, and compare model-generated text with user-provided text. We describe the visual and interactive design of our tool and highlight usage scenarios for LLaMA2 models fine-tuned with two different datasets: online articles about recent disasters and finance-related question-answer pairs. Thanks to LLM Attributor's broad support for computational notebooks, users can easily integrate it into their workflow ",
    "link": "https://arxiv.org/abs/2404.01361",
    "context": "Title: LLM Attributor: Interactive Visual Attribution for LLM Generation\nAbstract: arXiv:2404.01361v1 Announce Type: cross  Abstract: While large language models (LLMs) have shown remarkable capability to generate convincing text across diverse domains, concerns around its potential risks have highlighted the importance of understanding the rationale behind text generation. We present LLM Attributor, a Python library that provides interactive visualizations for training data attribution of an LLM's text generation. Our library offers a new way to quickly attribute an LLM's text generation to training data points to inspect model behaviors, enhance its trustworthiness, and compare model-generated text with user-provided text. We describe the visual and interactive design of our tool and highlight usage scenarios for LLaMA2 models fine-tuned with two different datasets: online articles about recent disasters and finance-related question-answer pairs. Thanks to LLM Attributor's broad support for computational notebooks, users can easily integrate it into their workflow ",
    "path": "papers/24/04/2404.01361.json",
    "total_tokens": 859,
    "translated_title": "LLM Attributor: 交互式可视化归因用于LLM生成",
    "translated_abstract": "虽然大型语言模型（LLMs）显示出在各个领域生成令人信服的文本的能力，但对其潜在风险的担忧凸显了了解文本生成背后原因的重要性。我们提出了LLM Attributor，一个提供LLM文本生成训练数据归因交互可视化的Python库。我们的库为快速将LLM的文本生成归因到训练数据点提供了一种新方式，以检查模型行为、增强其可信度，并将模型生成的文本与用户提供的文本进行比较。我们描述了工具的视觉和交互设计，并强调LLaMA2模型的使用场景，该模型通过两个不同数据集进行微调：关于最近灾难和金融相关问答对的在线文章。由于LLM Attributor对计算笔记本的广泛支持，用户可以轻松将其整合到他们的工作流程中。",
    "tldr": "LLM Attributor是一个Python库，提供了交互式可视化方式用于将LLM的文本生成结果归因到训练数据点，帮助用户检查模型行为、增强可信度，并与用户提供的文本进行比较。",
    "en_tdlr": "LLM Attributor is a Python library that offers interactive visualizations to attribute an LLM's text generation to training data points, assisting users in inspecting model behaviors, enhancing trustworthiness, and comparing with user-provided text."
}