{
    "title": "MESEN: Exploit Multimodal Data to Design Unimodal Human Activity Recognition with Few Labels",
    "abstract": "arXiv:2404.01958v1 Announce Type: new  Abstract: Human activity recognition (HAR) will be an essential function of various emerging applications. However, HAR typically encounters challenges related to modality limitations and label scarcity, leading to an application gap between current solutions and real-world requirements. In this work, we propose MESEN, a multimodal-empowered unimodal sensing framework, to utilize unlabeled multimodal data available during the HAR model design phase for unimodal HAR enhancement during the deployment phase. From a study on the impact of supervised multimodal fusion on unimodal feature extraction, MESEN is designed to feature a multi-task mechanism during the multimodal-aided pre-training stage. With the proposed mechanism integrating cross-modal feature contrastive learning and multimodal pseudo-classification aligning, MESEN exploits unlabeled multimodal data to extract effective unimodal features for each modality. Subsequently, MESEN can adapt to",
    "link": "https://arxiv.org/abs/2404.01958",
    "context": "Title: MESEN: Exploit Multimodal Data to Design Unimodal Human Activity Recognition with Few Labels\nAbstract: arXiv:2404.01958v1 Announce Type: new  Abstract: Human activity recognition (HAR) will be an essential function of various emerging applications. However, HAR typically encounters challenges related to modality limitations and label scarcity, leading to an application gap between current solutions and real-world requirements. In this work, we propose MESEN, a multimodal-empowered unimodal sensing framework, to utilize unlabeled multimodal data available during the HAR model design phase for unimodal HAR enhancement during the deployment phase. From a study on the impact of supervised multimodal fusion on unimodal feature extraction, MESEN is designed to feature a multi-task mechanism during the multimodal-aided pre-training stage. With the proposed mechanism integrating cross-modal feature contrastive learning and multimodal pseudo-classification aligning, MESEN exploits unlabeled multimodal data to extract effective unimodal features for each modality. Subsequently, MESEN can adapt to",
    "path": "papers/24/04/2404.01958.json",
    "total_tokens": 863,
    "translated_title": "利用多模态数据设计利用少量标签进行单模态人类活动识别的MESEN",
    "translated_abstract": "人类活动识别（HAR）将成为各种新兴应用的重要功能。然而，HAR通常面临与模态限制和标签稀缺相关的挑战，导致当前解决方案与真实世界需求之间存在应用差距。在本研究中，我们提出了MESEN，一个多模态增强的单模态传感框架，用于利用HAR模型设计阶段可用的未标记多模态数据，以在部署阶段加强单模态HAR。通过对监督多模态融合对单模态特征提取的影响的研究，MESEN在多模态辅助预训练阶段设计了一个多任务机制。通过整合跨模态特征对比学习和多模态伪分类对齐的建议机制，MESEN利用未标记的多模态数据提取出每种模态的有效单模态特征。随后，MESEN可以适应",
    "tldr": "提出了MESEN，一个利用未标记多模态数据设计单模态人类活动识别的框架，通过多任务机制和特征学习实现了有效的单模态特征提取。",
    "en_tdlr": "MESEN is proposed as a framework that utilizes unlabeled multimodal data to design unimodal human activity recognition, achieving effective unimodal feature extraction through a multi-task mechanism and feature learning."
}