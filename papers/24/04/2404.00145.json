{
    "title": "Verifying the Selected Completely at Random Assumption in Positive-Unlabeled Learning",
    "abstract": "arXiv:2404.00145v1 Announce Type: cross  Abstract: The goal of positive-unlabeled (PU) learning is to train a binary classifier on the basis of training data containing positive and unlabeled instances, where unlabeled observations can belong either to the positive class or to the negative class. Modeling PU data requires certain assumptions on the labeling mechanism that describes which positive observations are assigned a label. The simplest assumption, considered in early works, is SCAR (Selected Completely at Random Assumption), according to which the propensity score function, defined as the probability of assigning a label to a positive observation, is constant. On the other hand, a much more realistic assumption is SAR (Selected at Random), which states that the propensity function solely depends on the observed feature vector. SCAR-based algorithms are much simpler and computationally much faster compared to SAR-based algorithms, which usually require challenging estimation of ",
    "link": "https://arxiv.org/abs/2404.00145",
    "context": "Title: Verifying the Selected Completely at Random Assumption in Positive-Unlabeled Learning\nAbstract: arXiv:2404.00145v1 Announce Type: cross  Abstract: The goal of positive-unlabeled (PU) learning is to train a binary classifier on the basis of training data containing positive and unlabeled instances, where unlabeled observations can belong either to the positive class or to the negative class. Modeling PU data requires certain assumptions on the labeling mechanism that describes which positive observations are assigned a label. The simplest assumption, considered in early works, is SCAR (Selected Completely at Random Assumption), according to which the propensity score function, defined as the probability of assigning a label to a positive observation, is constant. On the other hand, a much more realistic assumption is SAR (Selected at Random), which states that the propensity function solely depends on the observed feature vector. SCAR-based algorithms are much simpler and computationally much faster compared to SAR-based algorithms, which usually require challenging estimation of ",
    "path": "papers/24/04/2404.00145.json",
    "total_tokens": 813,
    "translated_title": "在正-无监督学习中验证完全随机选择假设",
    "translated_abstract": "正-无监督学习的目标是在包含正例和未标记实例的训练数据基础上训练二元分类器，其中未标记观测可以属于正类或负类。建模正-无监督数据需要关于标签机制的一些假设，描述哪些正例被分配标签。早期研究中考虑的最简单假设是SCAR（完全随机选择假设），其概率分数函数定义为给正例分配标签的概率是常数。另一方面，一个更为现实的假设是SAR（随机选择），它表明概率函数仅依赖于观察到的特征向量。基于SCAR的算法比基于SAR的算法简单得多，并且在计算上更快，后者通常需要挑战性的估计。",
    "tldr": "在正-无监督学习中，研究了验证完全随机选择假设（SCAR）和更为现实的随机选择假设（SAR）对算法复杂性和速度的影响。"
}