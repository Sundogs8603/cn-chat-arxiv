{
    "title": "Decentralized Collaborative Learning Framework with External Privacy Leakage Analysis",
    "abstract": "arXiv:2404.01270v1 Announce Type: new  Abstract: This paper presents two methodological advancements in decentralized multi-task learning under privacy constraints, aiming to pave the way for future developments in next-generation Blockchain platforms. First, we expand the existing framework for collaborative dictionary learning (CollabDict), which has previously been limited to Gaussian mixture models, by incorporating deep variational autoencoders (VAEs) into the framework, with a particular focus on anomaly detection. We demonstrate that the VAE-based anomaly score function shares the same mathematical structure as the non-deep model, and provide comprehensive qualitative comparison. Second, considering the widespread use of \"pre-trained models,\" we provide a mathematical analysis on data privacy leakage when models trained with CollabDict are shared externally. We show that the CollabDict approach, when applied to Gaussian mixtures, adheres to a Renyi differential privacy criterion",
    "link": "https://arxiv.org/abs/2404.01270",
    "context": "Title: Decentralized Collaborative Learning Framework with External Privacy Leakage Analysis\nAbstract: arXiv:2404.01270v1 Announce Type: new  Abstract: This paper presents two methodological advancements in decentralized multi-task learning under privacy constraints, aiming to pave the way for future developments in next-generation Blockchain platforms. First, we expand the existing framework for collaborative dictionary learning (CollabDict), which has previously been limited to Gaussian mixture models, by incorporating deep variational autoencoders (VAEs) into the framework, with a particular focus on anomaly detection. We demonstrate that the VAE-based anomaly score function shares the same mathematical structure as the non-deep model, and provide comprehensive qualitative comparison. Second, considering the widespread use of \"pre-trained models,\" we provide a mathematical analysis on data privacy leakage when models trained with CollabDict are shared externally. We show that the CollabDict approach, when applied to Gaussian mixtures, adheres to a Renyi differential privacy criterion",
    "path": "papers/24/04/2404.01270.json",
    "total_tokens": 870,
    "translated_title": "具有外部隐私泄露分析的分散协作学习框架",
    "translated_abstract": "本文提出了在隐私约束条件下分散多任务学习中的两种方法论进展，旨在为未来下一代区块链平台的发展铺平道路。首先，我们将用于协作词典学习（CollabDict）的现有框架进行扩展，该框架先前仅限于高斯混合模型，通过将深度变分自动编码器（VAEs）纳入框架，特别关注异常检测。我们展示基于VAE的异常评分函数与非深度模型具有相同的数学结构，并提供全面的定性比较。其次，考虑到“预训练模型”广泛使用，我们对使用CollabDict训练的模型在外部共享时的数据隐私泄漏进行了数学分析。我们展示了当将CollabDict方法应用于高斯混合模型时，符合Renyi微分隐私标准。",
    "tldr": "本文提出了分散多任务学习中的两种方法论进展，一是在CollabDict框架中整合深度变分自动编码器用于异常检测，二是提供了使用CollabDict训练的模型在外部共享时数据隐私泄漏的数学分析。",
    "en_tdlr": "This paper presents two methodological advancements in decentralized multi-task learning under privacy constraints, expanding CollabDict framework with deep variational autoencoders for anomaly detection and providing mathematical analysis on data privacy leakage when sharing models trained with CollabDict externally."
}