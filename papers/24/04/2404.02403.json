{
    "title": "Benchmarking Large Language Models for Persian: A Preliminary Study Focusing on ChatGPT",
    "abstract": "arXiv:2404.02403v1 Announce Type: new  Abstract: This paper explores the efficacy of large language models (LLMs) for Persian. While ChatGPT and consequent LLMs have shown remarkable performance in English, their efficiency for more low-resource languages remains an open question. We present the first comprehensive benchmarking study of LLMs across diverse Persian language tasks. Our primary focus is on GPT-3.5-turbo, but we also include GPT-4 and OpenChat-3.5 to provide a more holistic evaluation. Our assessment encompasses a diverse set of tasks categorized into classic, reasoning, and knowledge-based domains. To enable a thorough comparison, we evaluate LLMs against existing task-specific fine-tuned models. Given the limited availability of Persian datasets for reasoning tasks, we introduce two new benchmarks: one based on elementary school math questions and another derived from the entrance exams for 7th and 10th grades. Our findings reveal that while LLMs, especially GPT-4, excel",
    "link": "https://arxiv.org/abs/2404.02403",
    "context": "Title: Benchmarking Large Language Models for Persian: A Preliminary Study Focusing on ChatGPT\nAbstract: arXiv:2404.02403v1 Announce Type: new  Abstract: This paper explores the efficacy of large language models (LLMs) for Persian. While ChatGPT and consequent LLMs have shown remarkable performance in English, their efficiency for more low-resource languages remains an open question. We present the first comprehensive benchmarking study of LLMs across diverse Persian language tasks. Our primary focus is on GPT-3.5-turbo, but we also include GPT-4 and OpenChat-3.5 to provide a more holistic evaluation. Our assessment encompasses a diverse set of tasks categorized into classic, reasoning, and knowledge-based domains. To enable a thorough comparison, we evaluate LLMs against existing task-specific fine-tuned models. Given the limited availability of Persian datasets for reasoning tasks, we introduce two new benchmarks: one based on elementary school math questions and another derived from the entrance exams for 7th and 10th grades. Our findings reveal that while LLMs, especially GPT-4, excel",
    "path": "papers/24/04/2404.02403.json",
    "total_tokens": 902,
    "translated_title": "评估波斯语大型语言模型：以 ChatGPT 为中心的初步研究",
    "translated_abstract": "本文探讨了大型语言模型（LLMs）在波斯语中的有效性。虽然ChatGPT和随后的LLMs在英语中表现出色，但它们在更低资源语言中的效率仍然是一个开放的问题。我们提出了对一系列波斯语任务进行全面基准测试研究的首次尝试。我们的主要关注点是在GPT-3.5-turbo上进行评估，但我们也包括了GPT-4和OpenChat-3.5以提供更全面的评估。我们的评估涵盖了一系列任务，包括经典、推理和基于知识的领域。为了进行深入比较，我们评估了LLMs与现有任务特定的微调模型的性能。考虑到推理任务波斯语数据集的有限性，我们引入了两个新的基准测试：一个基于小学数学问题，另一个源自第7和第10年级入学考试。我们的研究结果显示，LLMs，尤其是GPT-4，在推理任务表现出色。",
    "tldr": "评估了波斯语大型语言模型在不同任务上的表现，引入了推理任务方面的新基准测试，发现LLMs在推理任务中表现优异。",
    "en_tdlr": "Evaluated the performance of large language models for Persian across various tasks, introduced new benchmarks for reasoning tasks, and found that LLMs excel in reasoning tasks."
}