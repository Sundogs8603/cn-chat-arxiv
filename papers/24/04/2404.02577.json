{
    "title": "Solving a Real-World Optimization Problem Using Proximal Policy Optimization with Curriculum Learning and Reward Engineering",
    "abstract": "arXiv:2404.02577v1 Announce Type: new  Abstract: We present a proximal policy optimization (PPO) agent trained through curriculum learning (CL) principles and meticulous reward engineering to optimize a real-world high-throughput waste sorting facility. Our work addresses the challenge of effectively balancing the competing objectives of operational safety, volume optimization, and minimizing resource usage. A vanilla agent trained from scratch on these multiple criteria fails to solve the problem due to its inherent complexities. This problem is particularly difficult due to the environment's extremely delayed rewards with long time horizons and class (or action) imbalance, with important actions being infrequent in the optimal policy. This forces the agent to anticipate long-term action consequences and prioritize rare but rewarding behaviours, creating a non-trivial reinforcement learning task. Our five-stage CL approach tackles these challenges by gradually increasing the complexit",
    "link": "https://arxiv.org/abs/2404.02577",
    "context": "Title: Solving a Real-World Optimization Problem Using Proximal Policy Optimization with Curriculum Learning and Reward Engineering\nAbstract: arXiv:2404.02577v1 Announce Type: new  Abstract: We present a proximal policy optimization (PPO) agent trained through curriculum learning (CL) principles and meticulous reward engineering to optimize a real-world high-throughput waste sorting facility. Our work addresses the challenge of effectively balancing the competing objectives of operational safety, volume optimization, and minimizing resource usage. A vanilla agent trained from scratch on these multiple criteria fails to solve the problem due to its inherent complexities. This problem is particularly difficult due to the environment's extremely delayed rewards with long time horizons and class (or action) imbalance, with important actions being infrequent in the optimal policy. This forces the agent to anticipate long-term action consequences and prioritize rare but rewarding behaviours, creating a non-trivial reinforcement learning task. Our five-stage CL approach tackles these challenges by gradually increasing the complexit",
    "path": "papers/24/04/2404.02577.json",
    "total_tokens": 664,
    "translated_title": "使用课程学习和奖励工程的近端策略优化解决实际优化问题",
    "translated_abstract": "我们提出了一个通过课程学习原则和精心设计的奖励工程训练的近端策略优化（PPO）代理，来优化一个现实世界中的高吞吐量废物分类设施。我们的工作解决了有效平衡操作安全性、优化容量和最小化资源使用等竞争性目标的挑战。一个从头开始训练的基本代理在这些多重标准上失败解决问题，因为其固有复杂性。",
    "tldr": "使用课程学习和奖励工程的近端策略优化来解决实际问题。",
    "en_tdlr": "Solving a real-world problem using proximal policy optimization with curriculum learning and reward engineering."
}