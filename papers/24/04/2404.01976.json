{
    "title": "Joint-Task Regularization for Partially Labeled Multi-Task Learning",
    "abstract": "arXiv:2404.01976v1 Announce Type: cross  Abstract: Multi-task learning has become increasingly popular in the machine learning field, but its practicality is hindered by the need for large, labeled datasets. Most multi-task learning methods depend on fully labeled datasets wherein each input example is accompanied by ground-truth labels for all target tasks. Unfortunately, curating such datasets can be prohibitively expensive and impractical, especially for dense prediction tasks which require per-pixel labels for each image. With this in mind, we propose Joint-Task Regularization (JTR), an intuitive technique which leverages cross-task relations to simultaneously regularize all tasks in a single joint-task latent space to improve learning when data is not fully labeled for all tasks. JTR stands out from existing approaches in that it regularizes all tasks jointly rather than separately in pairs -- therefore, it achieves linear complexity relative to the number of tasks while previous ",
    "link": "https://arxiv.org/abs/2404.01976",
    "context": "Title: Joint-Task Regularization for Partially Labeled Multi-Task Learning\nAbstract: arXiv:2404.01976v1 Announce Type: cross  Abstract: Multi-task learning has become increasingly popular in the machine learning field, but its practicality is hindered by the need for large, labeled datasets. Most multi-task learning methods depend on fully labeled datasets wherein each input example is accompanied by ground-truth labels for all target tasks. Unfortunately, curating such datasets can be prohibitively expensive and impractical, especially for dense prediction tasks which require per-pixel labels for each image. With this in mind, we propose Joint-Task Regularization (JTR), an intuitive technique which leverages cross-task relations to simultaneously regularize all tasks in a single joint-task latent space to improve learning when data is not fully labeled for all tasks. JTR stands out from existing approaches in that it regularizes all tasks jointly rather than separately in pairs -- therefore, it achieves linear complexity relative to the number of tasks while previous ",
    "path": "papers/24/04/2404.01976.json",
    "total_tokens": 853,
    "translated_title": "联合任务正则化用于部分标记的多任务学习",
    "translated_abstract": "多任务学习在机器学习领域变得越来越流行，但其实用性受到需要大量标记数据集的限制。大多数多任务学习方法依赖完全标记的数据集，其中每个输入示例都附带所有目标任务的地面真相标签。不幸的是，筛选这样的数据集可能会因为昂贵且不切实际，尤其是对于需要每个图像的每个像素标签的密集预测任务。基于此，我们提出了联合任务正则化（JTR），这是一种直观的技术，利用跨任务关系在单个联合任务潜在空间中同时对所有任务进行正则化，以改善在数据未完全标记所有任务时的学习。JTR与现有方法有所不同之处在于它同时对所有任务进行正则化而不是分别对每对任务进行，因此实现了相对于任务数量的线性复杂度，而以前的方法没有做到这一点。",
    "tldr": "提出了一种联合任务正则化（JTR）技术，通过在单个联合任务潜在空间中同时对所有任务进行正则化，改善了当数据未完全标记所有任务时的学习。",
    "en_tdlr": "Introduced Joint-Task Regularization (JTR) technique, which leverages cross-task relations to simultaneously regularize all tasks in a single joint-task latent space to improve learning when data is not fully labeled for all tasks."
}