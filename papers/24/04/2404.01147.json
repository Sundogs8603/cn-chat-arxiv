{
    "title": "Do LLMs Find Human Answers To Fact-Driven Questions Perplexing? A Case Study on Reddit",
    "abstract": "arXiv:2404.01147v1 Announce Type: new  Abstract: Large language models (LLMs) have been shown to be proficient in correctly answering questions in the context of online discourse. However, the study of using LLMs to model human-like answers to fact-driven social media questions is still under-explored. In this work, we investigate how LLMs model the wide variety of human answers to fact-driven questions posed on several topic-specific Reddit communities, or subreddits. We collect and release a dataset of 409 fact-driven questions and 7,534 diverse, human-rated answers from 15 r/Ask{Topic} communities across 3 categories: profession, social identity, and geographic location. We find that LLMs are considerably better at modeling highly-rated human answers to such questions, as opposed to poorly-rated human answers. We present several directions for future research based on our initial findings.",
    "link": "https://arxiv.org/abs/2404.01147",
    "context": "Title: Do LLMs Find Human Answers To Fact-Driven Questions Perplexing? A Case Study on Reddit\nAbstract: arXiv:2404.01147v1 Announce Type: new  Abstract: Large language models (LLMs) have been shown to be proficient in correctly answering questions in the context of online discourse. However, the study of using LLMs to model human-like answers to fact-driven social media questions is still under-explored. In this work, we investigate how LLMs model the wide variety of human answers to fact-driven questions posed on several topic-specific Reddit communities, or subreddits. We collect and release a dataset of 409 fact-driven questions and 7,534 diverse, human-rated answers from 15 r/Ask{Topic} communities across 3 categories: profession, social identity, and geographic location. We find that LLMs are considerably better at modeling highly-rated human answers to such questions, as opposed to poorly-rated human answers. We present several directions for future research based on our initial findings.",
    "path": "papers/24/04/2404.01147.json",
    "total_tokens": 828,
    "translated_title": "LLM是否会对基于事实的问题的人类答案感到困惑？以Reddit为个案研究",
    "translated_abstract": "大型语言模型（LLMs）已被证明可以熟练地正确回答在线话语环境下的问题。然而，使用LLMs来模拟人类对基于事实的社交媒体问题的回答仍未被充分探讨。在本研究中，我们调查了LLMs如何模拟在几个专题性Reddit社区（或子社区）中提出的基于事实问题的各种人类答案。我们收集并公开了409个基于事实问题和来自15个r/Ask{Topic}社区的7,534个多样化的、经人类评分的答案的数据集，这些社区覆盖了3个类别：职业、社会身份和地理位置。我们发现LLMs在模拟高评分的人类答案方面要比模拟低评分的人类答案效果显著。我们基于我们的初步发现提出了几个未来研究的方向。",
    "tldr": "LLMs在模拟基于事实问题的社交媒体问题中人类答案时表现较好，为未来研究提供了方向。",
    "en_tdlr": "LLMs perform well in modeling human answers to fact-driven questions in social media, providing directions for future research."
}