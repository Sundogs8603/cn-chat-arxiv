{
    "title": "Unsupervised Learning of Effective Actions in Robotics",
    "abstract": "arXiv:2404.02728v1 Announce Type: cross  Abstract: Learning actions that are relevant to decision-making and can be executed effectively is a key problem in autonomous robotics. Current state-of-the-art action representations in robotics lack proper effect-driven learning of the robot's actions. Although successful in solving manipulation tasks, deep learning methods also lack this ability, in addition to their high cost in terms of memory or training data. In this paper, we propose an unsupervised algorithm to discretize a continuous motion space and generate \"action prototypes\", each producing different effects in the environment. After an exploration phase, the algorithm automatically builds a representation of the effects and groups motions into action prototypes, where motions more likely to produce an effect are represented more than those that lead to negligible changes. We evaluate our method on a simulated stair-climbing reinforcement learning task, and the preliminary results",
    "link": "https://arxiv.org/abs/2404.02728",
    "context": "Title: Unsupervised Learning of Effective Actions in Robotics\nAbstract: arXiv:2404.02728v1 Announce Type: cross  Abstract: Learning actions that are relevant to decision-making and can be executed effectively is a key problem in autonomous robotics. Current state-of-the-art action representations in robotics lack proper effect-driven learning of the robot's actions. Although successful in solving manipulation tasks, deep learning methods also lack this ability, in addition to their high cost in terms of memory or training data. In this paper, we propose an unsupervised algorithm to discretize a continuous motion space and generate \"action prototypes\", each producing different effects in the environment. After an exploration phase, the algorithm automatically builds a representation of the effects and groups motions into action prototypes, where motions more likely to produce an effect are represented more than those that lead to negligible changes. We evaluate our method on a simulated stair-climbing reinforcement learning task, and the preliminary results",
    "path": "papers/24/04/2404.02728.json",
    "total_tokens": 821,
    "translated_title": "机器人学中有效动作的无监督学习",
    "translated_abstract": "学习与决策相关且可以有效执行的动作是自主机器人中的关键问题。当前机器人学中最先进的动作表示缺乏对机器人动作的适当效果驱动学习。尽管深度学习方法在解决操纵任务方面取得成功，但它们也缺乏这种能力，而且在内存或训练数据方面成本高。在本文中，我们提出了一种无监督算法，用于对连续运动空间进行离散化，生成“动作原型”，每个原型在环境中产生不同的效果。在探索阶段之后，该算法会自动构建对效果的表示，并将动作分组为动作原型，其中更有可能产生效果的动作比导致可忽略变化的动作更多地表示。我们在模拟楼梯攀登强化学习任务上评估了我们的方法，初步结果表明...",
    "tldr": "该论文提出了一种无监督算法，通过在探索阶段将连续运动空间离散化, 自动生成“动作原型”, 从而实现机器人动作的效果驱动学习",
    "en_tdlr": "The paper presents an unsupervised algorithm that discretizes a continuous motion space, generates \"action prototypes\" during an exploration phase, and achieves effect-driven learning of robot actions."
}