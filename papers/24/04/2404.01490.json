{
    "title": "AAdaM at SemEval-2024 Task 1: Augmentation and Adaptation for Multilingual Semantic Textual Relatedness",
    "abstract": "arXiv:2404.01490v1 Announce Type: new  Abstract: This paper presents our system developed for the SemEval-2024 Task 1: Semantic Textual Relatedness for African and Asian Languages. The shared task aims at measuring the semantic textual relatedness between pairs of sentences, with a focus on a range of under-represented languages. In this work, we propose using machine translation for data augmentation to address the low-resource challenge of limited training data. Moreover, we apply task-adaptive pre-training on unlabeled task data to bridge the gap between pre-training and task adaptation. For model training, we investigate both full fine-tuning and adapter-based tuning, and adopt the adapter framework for effective zero-shot cross-lingual transfer. We achieve competitive results in the shared task: our system performs the best among all ranked teams in both subtask A (supervised learning) and subtask C (cross-lingual transfer).",
    "link": "https://arxiv.org/abs/2404.01490",
    "context": "Title: AAdaM at SemEval-2024 Task 1: Augmentation and Adaptation for Multilingual Semantic Textual Relatedness\nAbstract: arXiv:2404.01490v1 Announce Type: new  Abstract: This paper presents our system developed for the SemEval-2024 Task 1: Semantic Textual Relatedness for African and Asian Languages. The shared task aims at measuring the semantic textual relatedness between pairs of sentences, with a focus on a range of under-represented languages. In this work, we propose using machine translation for data augmentation to address the low-resource challenge of limited training data. Moreover, we apply task-adaptive pre-training on unlabeled task data to bridge the gap between pre-training and task adaptation. For model training, we investigate both full fine-tuning and adapter-based tuning, and adopt the adapter framework for effective zero-shot cross-lingual transfer. We achieve competitive results in the shared task: our system performs the best among all ranked teams in both subtask A (supervised learning) and subtask C (cross-lingual transfer).",
    "path": "papers/24/04/2404.01490.json",
    "total_tokens": 867,
    "translated_title": "AAdaM在SemEval-2024任务1中的表现：多语言语义文本相关性的增强与适应",
    "translated_abstract": "这篇论文介绍了我们为SemEval-2024任务1开发的系统：非洲和亚洲语言的语义文本相关性。该共享任务旨在衡量句子对之间的语义文本相关性，重点关注一系列代表性不足的语言。在这项工作中，我们提出利用机器翻译进行数据增强，以解决训练数据有限的低资源挑战。此外，我们将任务自适应预训练应用于未标记的任务数据，以弥合预训练和任务适应之间的差距。在模型训练方面，我们研究了完全微调和基于适配器的调整，并采用适配器框架实现了有效的零-shot跨语言转移。在共享任务中取得了竞争性结果：我们的系统在子任务A（监督学习）和子任务C（跨语言转移）中表现最佳，排名最高。",
    "tldr": "提出利用机器翻译进行数据增强以解决训练数据有限的挑战，应用任务自适应预训练和适配器框架实现了竞争性结果。",
    "en_tdlr": "Proposed using machine translation for data augmentation to address the challenge of limited training data, achieved competitive results by applying task-adaptive pre-training and adapter framework."
}