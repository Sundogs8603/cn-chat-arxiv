{
    "title": "On-the-fly Definition Augmentation of LLMs for Biomedical NER",
    "abstract": "arXiv:2404.00152v1 Announce Type: new  Abstract: Despite their general capabilities, LLMs still struggle on biomedical NER tasks, which are difficult due to the presence of specialized terminology and lack of training data. In this work we set out to improve LLM performance on biomedical NER in limited data settings via a new knowledge augmentation approach which incorporates definitions of relevant concepts on-the-fly. During this process, to provide a test bed for knowledge augmentation, we perform a comprehensive exploration of prompting strategies. Our experiments show that definition augmentation is useful for both open source and closed LLMs. For example, it leads to a relative improvement of 15\\% (on average) in GPT-4 performance (F1) across all (six) of our test datasets. We conduct extensive ablations and analyses to demonstrate that our performance improvements stem from adding relevant definitional knowledge. We find that careful prompting strategies also improve LLM perform",
    "link": "https://arxiv.org/abs/2404.00152",
    "context": "Title: On-the-fly Definition Augmentation of LLMs for Biomedical NER\nAbstract: arXiv:2404.00152v1 Announce Type: new  Abstract: Despite their general capabilities, LLMs still struggle on biomedical NER tasks, which are difficult due to the presence of specialized terminology and lack of training data. In this work we set out to improve LLM performance on biomedical NER in limited data settings via a new knowledge augmentation approach which incorporates definitions of relevant concepts on-the-fly. During this process, to provide a test bed for knowledge augmentation, we perform a comprehensive exploration of prompting strategies. Our experiments show that definition augmentation is useful for both open source and closed LLMs. For example, it leads to a relative improvement of 15\\% (on average) in GPT-4 performance (F1) across all (six) of our test datasets. We conduct extensive ablations and analyses to demonstrate that our performance improvements stem from adding relevant definitional knowledge. We find that careful prompting strategies also improve LLM perform",
    "path": "papers/24/04/2404.00152.json",
    "total_tokens": 860,
    "translated_title": "在线定义增强LLMs用于生物医学NER",
    "translated_abstract": "尽管LLMs具有一般的能力，但仍然在生物医学NER任务中遇到困难，这是由于存在专业术语和缺乏训练数据所致。在这项工作中，我们旨在通过一种新的知识增强方法，在有限数据设置下改善LLMs在生物医学NER上的性能，该方法通过实时合并相关概念的定义。在这个过程中，为了提供知识增强的测试场景，我们对提示策略进行了全面的探索。我们的实验证明，定义增强对于开源和封闭的LLMs都是有用的。例如，在我们所有（六个）测试数据集中，它导致了GPT-4性能（F1）平均相对提升了15\\%。我们进行了广泛的消融和分析，以证明我们的性能改进来源于添加相关的定义知识。我们发现谨慎的提示策略也提高了LLMs的性能。",
    "tldr": "通过实时合并相关概念的定义，本研究提出了一种新的知识增强方法以改善LLMs在生物医学NER任务中的性能，在测试数据设置下平均提高了15\\%的性能。",
    "en_tdlr": "This work proposes a novel knowledge augmentation approach to improve LLMs performance on biomedical NER tasks by incorporating definitions of relevant concepts on-the-fly, resulting in an average performance improvement of 15% in limited data settings."
}