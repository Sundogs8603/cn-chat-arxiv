{
    "title": "ADVREPAIR:Provable Repair of Adversarial Attack",
    "abstract": "arXiv:2404.01642v1 Announce Type: new  Abstract: Deep neural networks (DNNs) are increasingly deployed in safety-critical domains, but their vulnerability to adversarial attacks poses serious safety risks. Existing neuron-level methods using limited data lack efficacy in fixing adversaries due to the inherent complexity of adversarial attack mechanisms, while adversarial training, leveraging a large number of adversarial samples to enhance robustness, lacks provability. In this paper, we propose ADVREPAIR, a novel approach for provable repair of adversarial attacks using limited data. By utilizing formal verification, ADVREPAIR constructs patch modules that, when integrated with the original network, deliver provable and specialized repairs within the robustness neighborhood. Additionally, our approach incorporates a heuristic mechanism for assigning patch modules, allowing this defense against adversarial attacks to generalize to other inputs. ADVREPAIR demonstrates superior efficienc",
    "link": "https://arxiv.org/abs/2404.01642",
    "context": "Title: ADVREPAIR:Provable Repair of Adversarial Attack\nAbstract: arXiv:2404.01642v1 Announce Type: new  Abstract: Deep neural networks (DNNs) are increasingly deployed in safety-critical domains, but their vulnerability to adversarial attacks poses serious safety risks. Existing neuron-level methods using limited data lack efficacy in fixing adversaries due to the inherent complexity of adversarial attack mechanisms, while adversarial training, leveraging a large number of adversarial samples to enhance robustness, lacks provability. In this paper, we propose ADVREPAIR, a novel approach for provable repair of adversarial attacks using limited data. By utilizing formal verification, ADVREPAIR constructs patch modules that, when integrated with the original network, deliver provable and specialized repairs within the robustness neighborhood. Additionally, our approach incorporates a heuristic mechanism for assigning patch modules, allowing this defense against adversarial attacks to generalize to other inputs. ADVREPAIR demonstrates superior efficienc",
    "path": "papers/24/04/2404.01642.json",
    "total_tokens": 864,
    "translated_title": "ADVREPAIR：对抗攻击的可证修复",
    "translated_abstract": "深度神经网络(DNNs)在安全关键领域中的部署日益增加，但它们对抗性攻击的脆弱性构成严重的安全风险。现有的使用有限数据的神经元级方法在修复对手方面缺乏效力，因为对抗攻击机制的固有复杂性，而对抗训练，利用大量对抗样本增强鲁棒性，缺乏可证性。在本文中，我们提出了ADVREPAIR，一种利用有限数据进行对抗攻击的可证修复的新方法。通过利用形式验证，ADVREPAIR构建补丁模块，当与原始网络集成时，在稳健邻域内提供可证和专门的修复。此外，我们的方法还包括一种启发式机制来分配补丁模块，使得这种防御对抗攻击泛化到其他输入。ADVREPAIR展示了卓越的效率。",
    "tldr": "ADVREPAIR是一种利用有限数据进行对抗攻击的可证修复的新方法，通过形式验证构建补丁模块，在稳健邻域内提供可证和专门的修复，同时具有泛化到其他输入的防御能力。",
    "en_tdlr": "ADVREPAIR is a novel approach for provable repair of adversarial attacks using limited data, construct patch modules through formal verification to deliver provable and specialized repairs within the robustness neighborhood, with the defense capability to generalize to other inputs."
}