{
    "title": "GOV-REK: Governed Reward Engineering Kernels for Designing Robust Multi-Agent Reinforcement Learning Systems",
    "abstract": "arXiv:2404.01131v1 Announce Type: cross  Abstract: For multi-agent reinforcement learning systems (MARLS), the problem formulation generally involves investing massive reward engineering effort specific to a given problem. However, this effort often cannot be translated to other problems; worse, it gets wasted when system dynamics change drastically. This problem is further exacerbated in sparse reward scenarios, where a meaningful heuristic can assist in the policy convergence task. We propose GOVerned Reward Engineering Kernels (GOV-REK), which dynamically assign reward distributions to agents in MARLS during its learning stage. We also introduce governance kernels, which exploit the underlying structure in either state or joint action space for assigning meaningful agent reward distributions. During the agent learning stage, it iteratively explores different reward distribution configurations with a Hyperband-like algorithm to learn ideal agent reward models in a problem-agnostic ma",
    "link": "https://arxiv.org/abs/2404.01131",
    "context": "Title: GOV-REK: Governed Reward Engineering Kernels for Designing Robust Multi-Agent Reinforcement Learning Systems\nAbstract: arXiv:2404.01131v1 Announce Type: cross  Abstract: For multi-agent reinforcement learning systems (MARLS), the problem formulation generally involves investing massive reward engineering effort specific to a given problem. However, this effort often cannot be translated to other problems; worse, it gets wasted when system dynamics change drastically. This problem is further exacerbated in sparse reward scenarios, where a meaningful heuristic can assist in the policy convergence task. We propose GOVerned Reward Engineering Kernels (GOV-REK), which dynamically assign reward distributions to agents in MARLS during its learning stage. We also introduce governance kernels, which exploit the underlying structure in either state or joint action space for assigning meaningful agent reward distributions. During the agent learning stage, it iteratively explores different reward distribution configurations with a Hyperband-like algorithm to learn ideal agent reward models in a problem-agnostic ma",
    "path": "papers/24/04/2404.01131.json",
    "total_tokens": 874,
    "translated_title": "GOV-REK：用于设计鲁棒多智能体强化学习系统的受管奖励工程核",
    "translated_abstract": "对于多智能体强化学习系统（MARLS），问题的制定通常需要投入大量奖励工程工作，针对特定问题。然而，这种努力通常无法转化为其他问题；更糟糕的是，当系统动态发生 drastica 改变时，这种努力就会被浪费。在稀疏奖励场景中，有意义的启发式可以帮助策略收敛任务。我们提出了 GOVerned Reward Engineering Kernels (GOV-REK)，在 MARLS 的学习阶段动态地为代理分配奖励分布。我们还引入了治理内核，利用状态或联合行动空间中的基础结构来分配有意义的代理奖励分布。在代理学习阶段，它使用类似 Hyperband 的算法迭代地探索不同的奖励分布配置，以在问题-不可知 ma 中学习理想的代理奖励模型。",
    "tldr": "GOV-REK提出了一种动态为多智能体强化学习系统中的代理分配奖励分布的方法，并通过治理内核利用状态或联合行动空间的结构，以解决奖励工程努力无法转化的问题。",
    "en_tdlr": "GOV-REK proposes a method to dynamically assign reward distributions to agents in multi-agent reinforcement learning systems, utilizing governance kernels to address the issue of untranslatable reward engineering efforts."
}