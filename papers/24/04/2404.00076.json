{
    "title": "A Backdoor Approach with Inverted Labels Using Dirty Label-Flipping Attacks",
    "abstract": "arXiv:2404.00076v1 Announce Type: cross  Abstract: Audio-based machine learning systems frequently use public or third-party data, which might be inaccurate. This exposes deep neural network (DNN) models trained on such data to potential data poisoning attacks. In this type of assault, attackers can train the DNN model using poisoned data, potentially degrading its performance. Another type of data poisoning attack that is extremely relevant to our investigation is label flipping, in which the attacker manipulates the labels for a subset of data. It has been demonstrated that these assaults may drastically reduce system performance, even for attackers with minimal abilities. In this study, we propose a backdoor attack named 'DirtyFlipping', which uses dirty label techniques, \"label-on-label\", to input triggers (clapping) in the selected data patterns associated with the target class, thereby enabling a stealthy backdoor.",
    "link": "https://arxiv.org/abs/2404.00076",
    "context": "Title: A Backdoor Approach with Inverted Labels Using Dirty Label-Flipping Attacks\nAbstract: arXiv:2404.00076v1 Announce Type: cross  Abstract: Audio-based machine learning systems frequently use public or third-party data, which might be inaccurate. This exposes deep neural network (DNN) models trained on such data to potential data poisoning attacks. In this type of assault, attackers can train the DNN model using poisoned data, potentially degrading its performance. Another type of data poisoning attack that is extremely relevant to our investigation is label flipping, in which the attacker manipulates the labels for a subset of data. It has been demonstrated that these assaults may drastically reduce system performance, even for attackers with minimal abilities. In this study, we propose a backdoor attack named 'DirtyFlipping', which uses dirty label techniques, \"label-on-label\", to input triggers (clapping) in the selected data patterns associated with the target class, thereby enabling a stealthy backdoor.",
    "path": "papers/24/04/2404.00076.json",
    "total_tokens": 827,
    "translated_title": "使用倒置标签的后门方法：脏标签翻转攻击",
    "translated_abstract": "基于声音的机器学习系统经常使用公共或第三方数据，这可能是不准确的。这使得训练在这些数据上的深度神经网络（DNN）模型容易受到潜在的数据毒化攻击。在这种攻击类型中，攻击者可以使用毒化数据来训练DNN模型，可能会降低其性能。另一种对我们的研究非常相关的数据毒化攻击类型是标签翻转，攻击者在其中操纵数据子集的标签。已经证明，即使是能力有限的攻击者，这些攻击也可能极大地降低系统性能。在本研究中，我们提出了一种名为“DirtyFlipping”的后门攻击，使用脏标签技术，“标签对标签”，在与目标类别相关的选定数据模式中输入触发器（拍手），从而实现了隐蔽的后门。",
    "tldr": "提出了一种后门攻击方法，名为“DirtyFlipping”，利用脏标签技术在选定的数据模式中输入触发器，从而实现隐蔽的后门。",
    "en_tdlr": "Proposed a backdoor attack method named \"DirtyFlipping\", which utilizes dirty label techniques to input triggers in selected data patterns, enabling a stealthy backdoor."
}