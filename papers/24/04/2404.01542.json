{
    "title": "Predicting the Performance of Foundation Models via Agreement-on-the-Line",
    "abstract": "arXiv:2404.01542v1 Announce Type: new  Abstract: Estimating the out-of-distribution performance in regimes where labels are scarce is critical to safely deploy foundation models. Recently, it was shown that ensembles of neural networks observe the phenomena ``agreement-on-the-line'', which can be leveraged to reliably predict OOD performance without labels. However, in contrast to classical neural networks that are trained on in-distribution data from scratch for numerous epochs, foundation models undergo minimal finetuning from heavily pretrained weights, which may reduce the ensemble diversity needed to observe agreement-on-the-line. In our work, we demonstrate that when lightly finetuning multiple runs from a $\\textit{single}$ foundation model, the choice of randomness during training (linear head initialization, data ordering, and data subsetting) can lead to drastically different levels of agreement-on-the-line in the resulting ensemble. Surprisingly, only random head initializati",
    "link": "https://arxiv.org/abs/2404.01542",
    "context": "Title: Predicting the Performance of Foundation Models via Agreement-on-the-Line\nAbstract: arXiv:2404.01542v1 Announce Type: new  Abstract: Estimating the out-of-distribution performance in regimes where labels are scarce is critical to safely deploy foundation models. Recently, it was shown that ensembles of neural networks observe the phenomena ``agreement-on-the-line'', which can be leveraged to reliably predict OOD performance without labels. However, in contrast to classical neural networks that are trained on in-distribution data from scratch for numerous epochs, foundation models undergo minimal finetuning from heavily pretrained weights, which may reduce the ensemble diversity needed to observe agreement-on-the-line. In our work, we demonstrate that when lightly finetuning multiple runs from a $\\textit{single}$ foundation model, the choice of randomness during training (linear head initialization, data ordering, and data subsetting) can lead to drastically different levels of agreement-on-the-line in the resulting ensemble. Surprisingly, only random head initializati",
    "path": "papers/24/04/2404.01542.json",
    "total_tokens": 880,
    "translated_title": "通过线上的一致性预测基础模型的性能",
    "translated_abstract": "估计标签稀缺情况下的外部分布性能对于安全部署基础模型至关重要。最近，人们发现神经网络集合观察到“线上一致性”现象，可以利用它可靠地预测无标签的外部分布性能。然而，与在分布数据上从头开始训练多次轮数的传统神经网络相比，基础模型经历了从预训练权重中进行最小微调，这可能会减少观察到线上一致性所需的集合多样性。在我们的工作中，我们展示出当轻微微调整来自$\\textit{单个}$基础模型的多次运行时，训练期间的随机性选择（线性头初始化、数据排序和数据子集）可能导致不同程度的线上一致性的最终集合。令人惊讶的是，只有随机头初始化就能极大程度地影响集合中的一致性。ên初化就能使产生的集合中的一致性水平产生巨大差异。",
    "tldr": "本研究发现，通过对来自单个基础模型的多次运行进行轻微微调，可以通过训练期间的随机性选择来显著影响最终集合中的一致性。",
    "en_tdlr": "This study shows that lightly finetuning multiple runs from a single foundation model can significantly impact the agreement-on-the-line in the resulting ensemble through random choices during training."
}