{
    "title": "SHIELD: A regularization technique for eXplainable Artificial Intelligence",
    "abstract": "arXiv:2404.02611v1 Announce Type: new  Abstract: As Artificial Intelligence systems become integral across domains, the demand for explainability grows. While the effort by the scientific community is focused on obtaining a better explanation for the model, it is important not to ignore the potential of this explanation process to improve training as well. While existing efforts primarily focus on generating and evaluating explanations for black-box models, there remains a critical gap in directly enhancing models through these evaluations. This paper introduces SHIELD (Selective Hidden Input Evaluation for Learning Dynamics), a regularization technique for explainable artificial intelligence designed to improve model quality by concealing portions of input data and assessing the resulting discrepancy in predictions. In contrast to conventional approaches, SHIELD regularization seamlessly integrates into the objective function, enhancing model explainability while also improving perfor",
    "link": "https://arxiv.org/abs/2404.02611",
    "context": "Title: SHIELD: A regularization technique for eXplainable Artificial Intelligence\nAbstract: arXiv:2404.02611v1 Announce Type: new  Abstract: As Artificial Intelligence systems become integral across domains, the demand for explainability grows. While the effort by the scientific community is focused on obtaining a better explanation for the model, it is important not to ignore the potential of this explanation process to improve training as well. While existing efforts primarily focus on generating and evaluating explanations for black-box models, there remains a critical gap in directly enhancing models through these evaluations. This paper introduces SHIELD (Selective Hidden Input Evaluation for Learning Dynamics), a regularization technique for explainable artificial intelligence designed to improve model quality by concealing portions of input data and assessing the resulting discrepancy in predictions. In contrast to conventional approaches, SHIELD regularization seamlessly integrates into the objective function, enhancing model explainability while also improving perfor",
    "path": "papers/24/04/2404.02611.json",
    "total_tokens": 789,
    "translated_title": "SHIELD: 一种用于可解释人工智能的正则化技术",
    "translated_abstract": "随着人工智能系统在各个领域变得不可或缺，对可解释性的需求与日俱增。尽管科学界的努力主要集中在为模型获取更好的解释上，但重要的是不要忽视这个解释过程对改善训练的潜力。虽然现有的努力主要集中在为黑盒模型生成和评估解释上，但直接通过这些评估来增强模型仍存在关键差距。本文介绍了SHIELD（选择性隐藏输入评估学习动态），这是一种适用于可解释人工智能的正则化技术，旨在通过隐藏部分输入数据并评估预测结果的差异来改善模型质量。与传统方法相比，SHIELD正则化无缝集成到目标函数中，提高了模型的可解释性同时也改善了性能",
    "tldr": "SHIELD引入了一种正则化技术，通过隐藏部分输入数据并评估预测结果的差异，从而改善了可解释人工智能模型的质量。",
    "en_tdlr": "The SHIELD introduces a regularization technique to improve the quality of interpretable artificial intelligence models by concealing portions of input data and assessing the discrepancy in predictions."
}