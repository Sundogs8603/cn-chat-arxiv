{
    "title": "Injecting New Knowledge into Large Language Models via Supervised Fine-Tuning",
    "abstract": "arXiv:2404.00213v1 Announce Type: new  Abstract: In recent years, Large Language Models (LLMs) have shown remarkable performance in generating human-like text, proving to be a valuable asset across various applications. However, adapting these models to incorporate new, out-of-domain knowledge remains a challenge, particularly for facts and events that occur after the model's knowledge cutoff date. This paper investigates the effectiveness of Supervised Fine-Tuning (SFT) as a method for knowledge injection in LLMs, specifically focusing on the domain of recent sporting events. We compare different dataset generation strategies -- token-based and fact-based scaling -- to create training data that helps the model learn new information. Our experiments on GPT-4 demonstrate that while token-based scaling can lead to improvements in Q&A accuracy, it may not provide uniform coverage of new knowledge. Fact-based scaling, on the other hand, offers a more systematic approach to ensure even cove",
    "link": "https://arxiv.org/abs/2404.00213",
    "context": "Title: Injecting New Knowledge into Large Language Models via Supervised Fine-Tuning\nAbstract: arXiv:2404.00213v1 Announce Type: new  Abstract: In recent years, Large Language Models (LLMs) have shown remarkable performance in generating human-like text, proving to be a valuable asset across various applications. However, adapting these models to incorporate new, out-of-domain knowledge remains a challenge, particularly for facts and events that occur after the model's knowledge cutoff date. This paper investigates the effectiveness of Supervised Fine-Tuning (SFT) as a method for knowledge injection in LLMs, specifically focusing on the domain of recent sporting events. We compare different dataset generation strategies -- token-based and fact-based scaling -- to create training data that helps the model learn new information. Our experiments on GPT-4 demonstrate that while token-based scaling can lead to improvements in Q&A accuracy, it may not provide uniform coverage of new knowledge. Fact-based scaling, on the other hand, offers a more systematic approach to ensure even cove",
    "path": "papers/24/04/2404.00213.json",
    "total_tokens": 715,
    "translated_title": "通过监督微调将新知识注入大型语言模型",
    "translated_abstract": "近年来，大型语言模型（LLMs）在生成类似人类文本方面表现出色，被证明在各种应用中是一项宝贵的资产。然而，使这些模型适应并整合新的领域知识仍然是一项挑战，特别是针对模型知识截止日期之后发生的事实和事件。本文研究了监督微调（SFT）作为LLMs中注入知识的方法的有效性，特别关注了最近体育事件领域。",
    "tldr": "本论文研究了在大型语言模型中通过监督微调方法注入新知识的效果，特别关注了最近体育事件领域。",
    "en_tdlr": "This paper investigates the effectiveness of Supervised Fine-Tuning (SFT) as a method for knowledge injection in Large Language Models (LLMs), with a specific focus on the domain of recent sporting events."
}