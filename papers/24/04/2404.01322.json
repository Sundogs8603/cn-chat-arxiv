{
    "title": "A Review of Multi-Modal Large Language and Vision Models",
    "abstract": "arXiv:2404.01322v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have recently emerged as a focal point of research and application, driven by their unprecedented ability to understand and generate text with human-like quality. Even more recently, LLMs have been extended into multi-modal large language models (MM-LLMs) which extends their capabilities to deal with image, video and audio information, in addition to text. This opens up applications like text-to-video generation, image captioning, text-to-speech, and more and is achieved either by retro-fitting an LLM with multi-modal capabilities, or building a MM-LLM from scratch. This paper provides an extensive review of the current state of those LLMs with multi-modal capabilities as well as the very recent MM-LLMs. It covers the historical development of LLMs especially the advances enabled by transformer-based architectures like OpenAI's GPT series and Google's BERT, as well as the role of attention mechanisms in enh",
    "link": "https://arxiv.org/abs/2404.01322",
    "context": "Title: A Review of Multi-Modal Large Language and Vision Models\nAbstract: arXiv:2404.01322v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have recently emerged as a focal point of research and application, driven by their unprecedented ability to understand and generate text with human-like quality. Even more recently, LLMs have been extended into multi-modal large language models (MM-LLMs) which extends their capabilities to deal with image, video and audio information, in addition to text. This opens up applications like text-to-video generation, image captioning, text-to-speech, and more and is achieved either by retro-fitting an LLM with multi-modal capabilities, or building a MM-LLM from scratch. This paper provides an extensive review of the current state of those LLMs with multi-modal capabilities as well as the very recent MM-LLMs. It covers the historical development of LLMs especially the advances enabled by transformer-based architectures like OpenAI's GPT series and Google's BERT, as well as the role of attention mechanisms in enh",
    "path": "papers/24/04/2404.01322.json",
    "total_tokens": 823,
    "translated_title": "对多模态大型语言与视觉模型的综述",
    "translated_abstract": "大型语言模型（LLMs）最近成为研究和应用的焦点，其能够理解和生成具有类似于人类质量的文本，受到了推动。更近期，LLMs被扩展为多模态大型语言模型（MM-LLMs），将其能力扩展到处理图像、视频和音频信息，除了文本。这打开了诸如文本到视频生成、图像字幕、文本到语音等应用，并通过将LLM与多模态能力进行后期调整，或者从头开始构建MM-LLM来实现。本文全面回顾了具有多模态能力的当前LLMs以及最新的MM-LLMs的现状。它涵盖了LLMs的历史发展，特别是由transformer-based 架构如OpenAI的GPT系列和Google的BERT提供的进展，以及注意机制在增强中的作用",
    "tldr": "该论文对具有多模态能力的大型语言模型进行了综述，涵盖了LLMs的发展历程、transformer-based 架构的进展以及注意机制的作用"
}