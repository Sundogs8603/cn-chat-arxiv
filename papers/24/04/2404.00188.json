{
    "title": "DataAgent: Evaluating Large Language Models' Ability to Answer Zero-Shot, Natural Language Queries",
    "abstract": "arXiv:2404.00188v1 Announce Type: cross  Abstract: Conventional processes for analyzing datasets and extracting meaningful information are often time-consuming and laborious. Previous work has identified manual, repetitive coding and data collection as major obstacles that hinder data scientists from undertaking more nuanced labor and high-level projects. To combat this, we evaluated OpenAI's GPT-3.5 as a \"Language Data Scientist\" (LDS) that can extrapolate key findings, including correlations and basic information, from a given dataset. The model was tested on a diverse set of benchmark datasets to evaluate its performance across multiple standards, including data science code-generation based tasks involving libraries such as NumPy, Pandas, Scikit-Learn, and TensorFlow, and was broadly successful in correctly answering a given data science query related to the benchmark dataset. The LDS used various novel prompt engineering techniques to effectively answer a given question, including",
    "link": "https://arxiv.org/abs/2404.00188",
    "context": "Title: DataAgent: Evaluating Large Language Models' Ability to Answer Zero-Shot, Natural Language Queries\nAbstract: arXiv:2404.00188v1 Announce Type: cross  Abstract: Conventional processes for analyzing datasets and extracting meaningful information are often time-consuming and laborious. Previous work has identified manual, repetitive coding and data collection as major obstacles that hinder data scientists from undertaking more nuanced labor and high-level projects. To combat this, we evaluated OpenAI's GPT-3.5 as a \"Language Data Scientist\" (LDS) that can extrapolate key findings, including correlations and basic information, from a given dataset. The model was tested on a diverse set of benchmark datasets to evaluate its performance across multiple standards, including data science code-generation based tasks involving libraries such as NumPy, Pandas, Scikit-Learn, and TensorFlow, and was broadly successful in correctly answering a given data science query related to the benchmark dataset. The LDS used various novel prompt engineering techniques to effectively answer a given question, including",
    "path": "papers/24/04/2404.00188.json",
    "total_tokens": 798,
    "translated_title": "DataAgent: 评估大型语言模型回答零样本自然语言查询的能力",
    "translated_abstract": "传统的数据集分析和提取有意义信息的过程往往耗时且繁琐。以前的工作已经确定手动、重复性编码和数据收集是阻碍数据科学家从事更微妙的工作和高水平项目的主要障碍。为了解决这个问题，我们评估了 OpenAI 的 GPT-3.5 作为“语言数据科学家”（LDS），可以从给定数据集中推导出关键发现，包括相关性和基本信息。该模型在多个标准上表现良好，包括基于数据科学代码生成的任务，涉及NumPy、Pandas、Scikit-Learn 和 TensorFlow 等库，并在正确回答与基准数据集相关的给定数据科学查询方面取得了广泛成功。LDS 使用了各种新颖的提示工程技术来有效回答给定问题，包括",
    "tldr": "评估了 OpenAI 的 GPT-3.5 模型作为“语言数据科学家”，成功回答了与基准数据集相关的数据科学查询。",
    "en_tdlr": "Evaluated OpenAI's GPT-3.5 model as a \"Language Data Scientist\" and successfully answered data science queries related to benchmark datasets."
}