{
    "title": "Evaluating Text-to-Visual Generation with Image-to-Text Generation",
    "abstract": "arXiv:2404.01291v1 Announce Type: cross  Abstract: Despite significant progress in generative AI, comprehensive evaluation remains challenging because of the lack of effective metrics and standardized benchmarks. For instance, the widely-used CLIPScore measures the alignment between a (generated) image and text prompt, but it fails to produce reliable scores for complex prompts involving compositions of objects, attributes, and relations. One reason is that text encoders of CLIP can notoriously act as a \"bag of words\", conflating prompts such as \"the horse is eating the grass\" with \"the grass is eating the horse\". To address this, we introduce the VQAScore, which uses a visual-question-answering (VQA) model to produce an alignment score by computing the probability of a \"Yes\" answer to a simple \"Does this figure show '{text}'?\" question. Though simpler than prior art, VQAScore computed with off-the-shelf models produces state-of-the-art results across many (8) image-text alignment benc",
    "link": "https://arxiv.org/abs/2404.01291",
    "context": "Title: Evaluating Text-to-Visual Generation with Image-to-Text Generation\nAbstract: arXiv:2404.01291v1 Announce Type: cross  Abstract: Despite significant progress in generative AI, comprehensive evaluation remains challenging because of the lack of effective metrics and standardized benchmarks. For instance, the widely-used CLIPScore measures the alignment between a (generated) image and text prompt, but it fails to produce reliable scores for complex prompts involving compositions of objects, attributes, and relations. One reason is that text encoders of CLIP can notoriously act as a \"bag of words\", conflating prompts such as \"the horse is eating the grass\" with \"the grass is eating the horse\". To address this, we introduce the VQAScore, which uses a visual-question-answering (VQA) model to produce an alignment score by computing the probability of a \"Yes\" answer to a simple \"Does this figure show '{text}'?\" question. Though simpler than prior art, VQAScore computed with off-the-shelf models produces state-of-the-art results across many (8) image-text alignment benc",
    "path": "papers/24/04/2404.01291.json",
    "total_tokens": 748,
    "translated_title": "评估文本到图像生成与图像到文本生成",
    "translated_abstract": "尽管生成式人工智能取得了显著进展，但由于缺乏有效的度量标准和标准化基准，综合评估仍然具有挑战性。为了解决这个问题，我们引入了VQAScore，使用视觉问答（VQA）模型通过计算对简单的“这幅图表现出了'{文本}'吗？”问题的“是”答案的概率来生成对齐分数。尽管比先前的方法更简单，但使用现成模型计算的VQAScore在许多（8个）图像文本对齐基准上产生了最先进的结果。",
    "tldr": "引入VQAScore，利用视觉问答模型生成对齐分数，取得了在图像文本对齐基准上的最先进结果",
    "en_tdlr": "Introducing VQAScore and utilizing a visual-question-answering model to generate alignment scores, achieving state-of-the-art results in image-text alignment benchmarks."
}