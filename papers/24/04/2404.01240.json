{
    "title": "AURORA: Navigating UI Tarpits via Automated Neural Screen Understanding",
    "abstract": "arXiv:2404.01240v1 Announce Type: cross  Abstract: Nearly a decade of research in software engineering has focused on automating mobile app testing to help engineers in overcoming the unique challenges associated with the software platform. Much of this work has come in the form of Automated Input Generation tools (AIG tools) that dynamically explore app screens. However, such tools have repeatedly been demonstrated to achieve lower-than-expected code coverage - particularly on sophisticated proprietary apps. Prior work has illustrated that a primary cause of these coverage deficiencies is related to so-called tarpits, or complex screens that are difficult to navigate.   In this paper, we take a critical step toward enabling AIG tools to effectively navigate tarpits during app exploration through a new form of automated semantic screen understanding. We introduce AURORA, a technique that learns from the visual and textual patterns that exist in mobile app UIs to automatically detect co",
    "link": "https://arxiv.org/abs/2404.01240",
    "context": "Title: AURORA: Navigating UI Tarpits via Automated Neural Screen Understanding\nAbstract: arXiv:2404.01240v1 Announce Type: cross  Abstract: Nearly a decade of research in software engineering has focused on automating mobile app testing to help engineers in overcoming the unique challenges associated with the software platform. Much of this work has come in the form of Automated Input Generation tools (AIG tools) that dynamically explore app screens. However, such tools have repeatedly been demonstrated to achieve lower-than-expected code coverage - particularly on sophisticated proprietary apps. Prior work has illustrated that a primary cause of these coverage deficiencies is related to so-called tarpits, or complex screens that are difficult to navigate.   In this paper, we take a critical step toward enabling AIG tools to effectively navigate tarpits during app exploration through a new form of automated semantic screen understanding. We introduce AURORA, a technique that learns from the visual and textual patterns that exist in mobile app UIs to automatically detect co",
    "path": "papers/24/04/2404.01240.json",
    "total_tokens": 772,
    "translated_title": "AURORA: 通过自动化神经屏幕理解来导航UI“TarPits”",
    "translated_abstract": "在软件工程领域，近十年来的研究侧重于自动化移动应用程序测试，以帮助工程师克服软件平台所面临的独特挑战。这项工作主要以自动化输入生成工具(AIG工具)的形式出现，动态探索应用程序屏幕。然而，这些工具反复证明达到的代码覆盖率低于预期 - 尤其是在复杂的专有应用程序上。先前的研究表明，导致这些覆盖率不足的一个主要原因与所谓的“tarpits”有关，即复杂且难以导航的屏幕。",
    "tldr": "通过新形式的自动化语义屏幕理解，本文提出了一种名为AURORA的技术，旨在帮助AIG工具有效地导航应用程序探索过程中的“tarpits”。",
    "en_tdlr": "This paper introduces AURORA, a technique that aims to help AIG tools effectively navigate \"tarpits\" during app exploration through a new form of automated semantic screen understanding."
}