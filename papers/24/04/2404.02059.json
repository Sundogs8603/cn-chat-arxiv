{
    "title": "IISAN: Efficiently Adapting Multimodal Representation for Sequential Recommendation with Decoupled PEFT",
    "abstract": "arXiv:2404.02059v1 Announce Type: new  Abstract: Multimodal foundation models are transformative in sequential recommender systems, leveraging powerful representation learning capabilities. While Parameter-efficient Fine-tuning (PEFT) is commonly used to adapt foundation models for recommendation tasks, most research prioritizes parameter efficiency, often overlooking critical factors like GPU memory efficiency and training speed. Addressing this gap, our paper introduces IISAN (Intra- and Inter-modal Side Adapted Network for Multimodal Representation), a simple plug-and-play architecture using a Decoupled PEFT structure and exploiting both intra- and inter-modal adaptation.   IISAN matches the performance of full fine-tuning (FFT) and state-of-the-art PEFT. More importantly, it significantly reduces GPU memory usage - from 47GB to just 3GB for multimodal sequential recommendation tasks. Additionally, it accelerates training time per epoch from 443s to 22s compared to FFT. This is also",
    "link": "https://arxiv.org/abs/2404.02059",
    "context": "Title: IISAN: Efficiently Adapting Multimodal Representation for Sequential Recommendation with Decoupled PEFT\nAbstract: arXiv:2404.02059v1 Announce Type: new  Abstract: Multimodal foundation models are transformative in sequential recommender systems, leveraging powerful representation learning capabilities. While Parameter-efficient Fine-tuning (PEFT) is commonly used to adapt foundation models for recommendation tasks, most research prioritizes parameter efficiency, often overlooking critical factors like GPU memory efficiency and training speed. Addressing this gap, our paper introduces IISAN (Intra- and Inter-modal Side Adapted Network for Multimodal Representation), a simple plug-and-play architecture using a Decoupled PEFT structure and exploiting both intra- and inter-modal adaptation.   IISAN matches the performance of full fine-tuning (FFT) and state-of-the-art PEFT. More importantly, it significantly reduces GPU memory usage - from 47GB to just 3GB for multimodal sequential recommendation tasks. Additionally, it accelerates training time per epoch from 443s to 22s compared to FFT. This is also",
    "path": "papers/24/04/2404.02059.json",
    "total_tokens": 907,
    "translated_title": "IISAN：使用解耦PEFT有效地调整多模态表示以顺序推荐",
    "translated_abstract": "多模态基础模型在顺序推荐系统中具有转变性，利用强大的表示学习能力。虽然参数高效微调（PEFT）通常用于调整基础模型以进行推荐任务，但大多数研究优先考虑参数效率，通常忽略GPU内存效率和训练速度等关键因素。针对这一差距，本文引入了IISAN（多模态表示的内部和跨模态侧面适应网络），一个使用解耦PEFT结构并利用内部和跨模态适应的简单即插即用架构。IISAN与全微调（FFT）和最先进的PEFT的性能相匹配。更重要的是，它显著减少了GPU内存使用量 - 对于多模态顺序推荐任务，从47GB降低到仅3GB。此外，与FFT相比，它将每个时代的训练时间从443秒加速到22秒。",
    "tldr": "IISAN是一种简单的插拔架构，采用解耦PEFT结构，并利用内部和跨模态适应，与全微调和最先进的PEFT性能匹配，显著减少GPU内存使用量，并加速了训练时间。",
    "en_tdlr": "IISAN is a simple plug-and-play architecture utilizing a Decoupled PEFT structure and intra- and inter-modal adaptation, matching the performance of full fine-tuning (FFT) and state-of-the-art PEFT, significantly reducing GPU memory usage, and speeding up training time."
}