{
    "title": "Shortcuts Arising from Contrast: Effective and Covert Clean-Label Attacks in Prompt-Based Learning",
    "abstract": "arXiv:2404.00461v1 Announce Type: cross  Abstract: Prompt-based learning paradigm has demonstrated remarkable efficacy in enhancing the adaptability of pretrained language models (PLMs), particularly in few-shot scenarios. However, this learning paradigm has been shown to be vulnerable to backdoor attacks. The current clean-label attack, employing a specific prompt as a trigger, can achieve success without the need for external triggers and ensure correct labeling of poisoned samples, which is more stealthy compared to the poisoned-label attack, but on the other hand, it faces significant issues with false activations and poses greater challenges, necessitating a higher rate of poisoning. Using conventional negative data augmentation methods, we discovered that it is challenging to trade off between effectiveness and stealthiness in a clean-label setting. In addressing this issue, we are inspired by the notion that a backdoor acts as a shortcut and posit that this shortcut stems from t",
    "link": "https://arxiv.org/abs/2404.00461",
    "context": "Title: Shortcuts Arising from Contrast: Effective and Covert Clean-Label Attacks in Prompt-Based Learning\nAbstract: arXiv:2404.00461v1 Announce Type: cross  Abstract: Prompt-based learning paradigm has demonstrated remarkable efficacy in enhancing the adaptability of pretrained language models (PLMs), particularly in few-shot scenarios. However, this learning paradigm has been shown to be vulnerable to backdoor attacks. The current clean-label attack, employing a specific prompt as a trigger, can achieve success without the need for external triggers and ensure correct labeling of poisoned samples, which is more stealthy compared to the poisoned-label attack, but on the other hand, it faces significant issues with false activations and poses greater challenges, necessitating a higher rate of poisoning. Using conventional negative data augmentation methods, we discovered that it is challenging to trade off between effectiveness and stealthiness in a clean-label setting. In addressing this issue, we are inspired by the notion that a backdoor acts as a shortcut and posit that this shortcut stems from t",
    "path": "papers/24/04/2404.00461.json",
    "total_tokens": 877,
    "translated_title": "从对比中出现的快速方法：基于提示的学习中的有效和隐蔽干净标签攻击",
    "translated_abstract": "Prompt-based learning范式表现出卓越的效力，可以提升预训练语言模型（PLMs）在少样本情况下的适应能力。然而，这种学习范式已被证明容易受到后门攻击的影响。当前的干净标签攻击，利用特定提示作为触发器，可以在不需要外部触发器的情况下成功，并确保对有毒样本的正确标记，相比有毒标签攻击更具隐蔽性，但另一方面，它面临着严重的误激活问题，并提出了更大的挑战，需要更高比例的毒害。通过传统的负数据增强方法，我们发现在干净标签设置中在效力和隐蔽性之间取得平衡是具有挑战性的。在解决这一问题时，我们受到后门充当快捷方式的观念的启发，并假设这一快捷方式源于t。",
    "tldr": "基于提示的学习中的干净标签攻击通过特定提示作为触发器，实现成功的同时确保正确标记有毒样本，但仍面临误激活问题和挑战，需要更高比例的毒害。",
    "en_tdlr": "Clean-label attacks in prompt-based learning use prompts as triggers to successfully label poisoned samples, but face challenges with false activations and require higher poisoning rates."
}