{
    "title": "Are large language models superhuman chemists?",
    "abstract": "arXiv:2404.01475v1 Announce Type: cross  Abstract: Large language models (LLMs) have gained widespread interest due to their ability to process human language and perform tasks on which they have not been explicitly trained. This is relevant for the chemical sciences, which face the problem of small and diverse datasets that are frequently in the form of text. LLMs have shown promise in addressing these issues and are increasingly being harnessed to predict chemical properties, optimize reactions, and even design and conduct experiments autonomously. However, we still have only a very limited systematic understanding of the chemical reasoning capabilities of LLMs, which would be required to improve models and mitigate potential harms. Here, we introduce \"ChemBench,\" an automated framework designed to rigorously evaluate the chemical knowledge and reasoning abilities of state-of-the-art LLMs against the expertise of human chemists. We curated more than 7,000 question-answer pairs for a ",
    "link": "https://arxiv.org/abs/2404.01475",
    "context": "Title: Are large language models superhuman chemists?\nAbstract: arXiv:2404.01475v1 Announce Type: cross  Abstract: Large language models (LLMs) have gained widespread interest due to their ability to process human language and perform tasks on which they have not been explicitly trained. This is relevant for the chemical sciences, which face the problem of small and diverse datasets that are frequently in the form of text. LLMs have shown promise in addressing these issues and are increasingly being harnessed to predict chemical properties, optimize reactions, and even design and conduct experiments autonomously. However, we still have only a very limited systematic understanding of the chemical reasoning capabilities of LLMs, which would be required to improve models and mitigate potential harms. Here, we introduce \"ChemBench,\" an automated framework designed to rigorously evaluate the chemical knowledge and reasoning abilities of state-of-the-art LLMs against the expertise of human chemists. We curated more than 7,000 question-answer pairs for a ",
    "path": "papers/24/04/2404.01475.json",
    "total_tokens": 825,
    "translated_title": "大型语言模型是否是超人类化学家？",
    "translated_abstract": "大型语言模型（LLMs）因其处理人类语言并执行未经明确训练的任务的能力而引起了广泛关注。这对化学科学是相关的，因为化学面临着数据集小且多样的问题，这些数据集通常以文本形式呈现。 LLMs在解决这些问题方面表现出潜力，并且越来越多地被利用来预测化学性质，优化反应，甚至自主设计和进行实验。然而，我们对LLMs的化学推理能力仅有非常有限的系统性理解，这是改进模型和减轻潜在危害所必需的。在这里，我们介绍了“ChemBench”，这是一个自动化框架，旨在严格评估最先进的LLMs的化学知识和推理能力，以与人类化学家的专业知识相比较。",
    "tldr": "介绍了一个自动化框架“ChemBench”，旨在评估最先进的大型语言模型（LLMs）在化学知识和推理能力方面与人类化学家专业知识的对比。"
}