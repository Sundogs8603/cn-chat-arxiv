{
    "title": "Multi-Conditional Ranking with Large Language Models",
    "abstract": "arXiv:2404.00211v1 Announce Type: new  Abstract: Utilizing large language models (LLMs) to rank a set of items has become a common approach in recommendation and retrieval systems. Typically, these systems focus on ordering a substantial number of documents in a monotonic order based on a given query. However, real-world scenarios often present a different challenge: ranking a comparatively smaller set of items, but according to a variety of diverse and occasionally conflicting conditions. In this paper, we define and explore the task of multi-conditional ranking by introducing MCRank, a benchmark tailored for assessing multi-conditional ranking across various item types and conditions. Our analysis of LLMs using MCRank indicates a significant decrease in performance as the number and complexity of items and conditions grow. To overcome this limitation, we propose a novel decomposed reasoning method, consisting of EXtracting and Sorting the conditions, and then Iterativly Ranking the i",
    "link": "https://arxiv.org/abs/2404.00211",
    "context": "Title: Multi-Conditional Ranking with Large Language Models\nAbstract: arXiv:2404.00211v1 Announce Type: new  Abstract: Utilizing large language models (LLMs) to rank a set of items has become a common approach in recommendation and retrieval systems. Typically, these systems focus on ordering a substantial number of documents in a monotonic order based on a given query. However, real-world scenarios often present a different challenge: ranking a comparatively smaller set of items, but according to a variety of diverse and occasionally conflicting conditions. In this paper, we define and explore the task of multi-conditional ranking by introducing MCRank, a benchmark tailored for assessing multi-conditional ranking across various item types and conditions. Our analysis of LLMs using MCRank indicates a significant decrease in performance as the number and complexity of items and conditions grow. To overcome this limitation, we propose a novel decomposed reasoning method, consisting of EXtracting and Sorting the conditions, and then Iterativly Ranking the i",
    "path": "papers/24/04/2404.00211.json",
    "total_tokens": 703,
    "translated_title": "大型语言模型下的多条件排序",
    "translated_abstract": "利用大型语言模型(LLMs)对一组项目进行排序已成为推荐和检索系统中的常见方法。在这篇论文中，我们定义并探讨了多条件排序的任务，引入了一个名为MCRank的基准，旨在评估跨不同项目类型和条件进行多条件排序。我们使用MCRank对LLMs进行分析表明，随着项目和条件数量以及复杂性的增长，性能显著下降。为了克服这一限制，我们提出了一种新颖的分解推理方法，包括提取和排序条件，然后迭代地对条件进行排序。",
    "tldr": "该论文提出了一种新颖的分解推理方法(MCRank)，用于解决大型语言模型在多条件排序任务中性能下降的问题。",
    "en_tdlr": "This paper introduces a novel decomposed reasoning method (MCRank) to address the performance decrease of large language models in multi-conditional ranking tasks."
}