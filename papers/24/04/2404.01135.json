{
    "title": "Enhancing Reasoning Capacity of SLM using Cognitive Enhancement",
    "abstract": "arXiv:2404.01135v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have been applied to automate cyber security activities and processes including cyber investigation and digital forensics. However, the use of such models for cyber investigation and digital forensics should address accountability and security considerations. Accountability ensures models have the means to provide explainable reasonings and outcomes. This information can be extracted through explicit prompt requests. For security considerations, it is crucial to address privacy and confidentiality of the involved data during data processing as well. One approach to deal with this consideration is to have the data processed locally using a local instance of the model. Due to limitations of locally available resources, namely memory and GPU capacities, a Smaller Large Language Model (SLM) will typically be used. These SLMs have significantly fewer parameters compared to the LLMs. However, such size reductions",
    "link": "https://arxiv.org/abs/2404.01135",
    "context": "Title: Enhancing Reasoning Capacity of SLM using Cognitive Enhancement\nAbstract: arXiv:2404.01135v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have been applied to automate cyber security activities and processes including cyber investigation and digital forensics. However, the use of such models for cyber investigation and digital forensics should address accountability and security considerations. Accountability ensures models have the means to provide explainable reasonings and outcomes. This information can be extracted through explicit prompt requests. For security considerations, it is crucial to address privacy and confidentiality of the involved data during data processing as well. One approach to deal with this consideration is to have the data processed locally using a local instance of the model. Due to limitations of locally available resources, namely memory and GPU capacities, a Smaller Large Language Model (SLM) will typically be used. These SLMs have significantly fewer parameters compared to the LLMs. However, such size reductions",
    "path": "papers/24/04/2404.01135.json",
    "total_tokens": 805,
    "translated_title": "利用认知增强技术增强SLM的推理能力",
    "translated_abstract": "大语言模型(LLMs)已被应用于自动化网络安全活动和流程，包括网络调查和数字取证。然而，将这些模型用于网络调查和数字取证时，应该考虑问责制和安全性。问责制确保模型能够提供可解释的推理和结果。这些信息可以通过显式提示请求来提取。对于安全考虑，在数据处理过程中至关重要的是要解决所涉数据的隐私和保密性。一种处理这个考虑的方法是在本地使用模型的本地实例对数据进行处理。由于本地可用资源（主要是内存和GPU容量）的限制，通常会使用较小的大型语言模型(SLM)。这些SLM与LLMs相比，具有明显较少的参数。然而，这种大小缩减…",
    "tldr": "利用认知增强技术，本研究提出了一种在网络调查和数字取证中提高SLM推理能力的方法，其中通过处理本地数据并减少参数数量来满足安全性和数据隐私性需求。",
    "en_tdlr": "This study proposes a method to enhance the reasoning capacity of SLM in cyber investigation and digital forensics using cognitive enhancement, by processing data locally and reducing the number of parameters to meet security and data privacy requirements."
}