{
    "title": "Towards Large Language Model driven Reference-less Translation Evaluation for English and Indian Languages",
    "abstract": "arXiv:2404.02512v1 Announce Type: new  Abstract: With the primary focus on evaluating the effectiveness of large language models for automatic reference-less translation assessment, this work presents our experiments on mimicking human direct assessment to evaluate the quality of translations in English and Indian languages. We constructed a translation evaluation task where we performed zero-shot learning, in-context example-driven learning, and fine-tuning of large language models to provide a score out of 100, where 100 represents a perfect translation and 1 represents a poor translation. We compared the performance of our trained systems with existing methods such as COMET, BERT-Scorer, and LABSE, and found that the LLM-based evaluator (LLaMA-2-13B) achieves a comparable or higher overall correlation with human judgments for the considered Indian language pairs.",
    "link": "https://arxiv.org/abs/2404.02512",
    "context": "Title: Towards Large Language Model driven Reference-less Translation Evaluation for English and Indian Languages\nAbstract: arXiv:2404.02512v1 Announce Type: new  Abstract: With the primary focus on evaluating the effectiveness of large language models for automatic reference-less translation assessment, this work presents our experiments on mimicking human direct assessment to evaluate the quality of translations in English and Indian languages. We constructed a translation evaluation task where we performed zero-shot learning, in-context example-driven learning, and fine-tuning of large language models to provide a score out of 100, where 100 represents a perfect translation and 1 represents a poor translation. We compared the performance of our trained systems with existing methods such as COMET, BERT-Scorer, and LABSE, and found that the LLM-based evaluator (LLaMA-2-13B) achieves a comparable or higher overall correlation with human judgments for the considered Indian language pairs.",
    "path": "papers/24/04/2404.02512.json",
    "total_tokens": 847,
    "translated_title": "面向英语和印度语的大型语言模型驱动的无参考翻译评估",
    "translated_abstract": "本文的主要重点是评估大型语言模型在自动无参考翻译评估中的有效性，我们展示了在评估英语和印度语翻译质量方面的实验。我们构建了一个翻译评估任务，通过零样本学习、示例驱动学习和对大型语言模型的微调来模拟人类直接评估，从而给出一个0到100的分数，其中100代表完美翻译，1代表翻译质量很差。我们将我们训练过的系统的性能与COMET、BERT-Scorer和LABSE等现有方法进行了比较，发现基于LLM的评估器（LLaMA-2-13B）在考虑的印度语言语种中实现了与人类判断相当或更高的整体相关性。",
    "tldr": "该研究旨在评估大型语言模型在无参考翻译评估中的有效性，通过零样本学习、示例驱动学习和微调来模拟人类直接评估，发现LLM-based评估器在印度语言对中获得了与人类判断相当或更高的整体相关性。",
    "en_tdlr": "This work aims to evaluate the effectiveness of large language models for automatic reference-less translation assessment, presenting experiments in English and Indian languages where the LLM-based evaluator achieves comparable or higher overall correlation with human judgments."
}