{
    "title": "Feature Splatting: Language-Driven Physics-Based Scene Synthesis and Editing",
    "abstract": "arXiv:2404.01223v1 Announce Type: cross  Abstract: Scene representations using 3D Gaussian primitives have produced excellent results in modeling the appearance of static and dynamic 3D scenes. Many graphics applications, however, demand the ability to manipulate both the appearance and the physical properties of objects. We introduce Feature Splatting, an approach that unifies physics-based dynamic scene synthesis with rich semantics from vision language foundation models that are grounded by natural language. Our first contribution is a way to distill high-quality, object-centric vision-language features into 3D Gaussians, that enables semi-automatic scene decomposition using text queries. Our second contribution is a way to synthesize physics-based dynamics from an otherwise static scene using a particle-based simulator, in which material properties are assigned automatically via text queries. We ablate key techniques used in this pipeline, to illustrate the challenge and opportunit",
    "link": "https://arxiv.org/abs/2404.01223",
    "context": "Title: Feature Splatting: Language-Driven Physics-Based Scene Synthesis and Editing\nAbstract: arXiv:2404.01223v1 Announce Type: cross  Abstract: Scene representations using 3D Gaussian primitives have produced excellent results in modeling the appearance of static and dynamic 3D scenes. Many graphics applications, however, demand the ability to manipulate both the appearance and the physical properties of objects. We introduce Feature Splatting, an approach that unifies physics-based dynamic scene synthesis with rich semantics from vision language foundation models that are grounded by natural language. Our first contribution is a way to distill high-quality, object-centric vision-language features into 3D Gaussians, that enables semi-automatic scene decomposition using text queries. Our second contribution is a way to synthesize physics-based dynamics from an otherwise static scene using a particle-based simulator, in which material properties are assigned automatically via text queries. We ablate key techniques used in this pipeline, to illustrate the challenge and opportunit",
    "path": "papers/24/04/2404.01223.json",
    "total_tokens": 866,
    "translated_title": "特征点切片：基于语言驱动的基于物理的场景合成和编辑",
    "translated_abstract": "使用3D高斯原语表示场景在建模静态和动态3D场景的外观方面取得了出色的结果。 然而，许多图形应用程序需要能够操纵对象的外观和物理特性。 我们介绍了一种称为Feature Splatting的方法，它将基于物理的动态场景合成与源于自然语言的丰富语义统一起来。 我们的第一个贡献是一种方法，可以将高质量的，以对象为中心的视觉语言特征提炼成3D高斯，从而利用文本查询实现半自动场景分解。 我们的第二个贡献是一种方法，通过基于粒子的模拟器从静态场景中合成基于物理的动态场景，在此过程中，材料属性通过文本查询自动分配。 我们剔除了在这个流程中使用的关键技术，以阐明挑战和机会。",
    "tldr": "该研究提出了一种名为Feature Splatting的方法，将基于物理的动态场景合成与源自视觉语言的丰富语义统一起来，实现了高质量的对象分解和基于文本查询的物理特性自动合成。",
    "en_tdlr": "This study introduces a method called Feature Splatting, which unifies physics-based dynamic scene synthesis with rich semantics from vision language, enabling high-quality object decomposition and automatic synthesis of physical properties based on text queries."
}