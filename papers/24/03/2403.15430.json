{
    "title": "Distilling Named Entity Recognition Models for Endangered Species from Large Language Models",
    "abstract": "arXiv:2403.15430v1 Announce Type: new  Abstract: Natural language processing (NLP) practitioners are leveraging large language models (LLM) to create structured datasets from semi-structured and unstructured data sources such as patents, papers, and theses, without having domain-specific knowledge. At the same time, ecological experts are searching for a variety of means to preserve biodiversity. To contribute to these efforts, we focused on endangered species and through in-context learning, we distilled knowledge from GPT-4. In effect, we created datasets for both named entity recognition (NER) and relation extraction (RE) via a two-stage process: 1) we generated synthetic data from GPT-4 of four classes of endangered species, 2) humans verified the factual accuracy of the synthetic data, resulting in gold data. Eventually, our novel dataset contains a total of 3.6K sentences, evenly divided between 1.8K NER and 1.8K RE sentences. The constructed dataset was then used to fine-tune bo",
    "link": "https://arxiv.org/abs/2403.15430",
    "context": "Title: Distilling Named Entity Recognition Models for Endangered Species from Large Language Models\nAbstract: arXiv:2403.15430v1 Announce Type: new  Abstract: Natural language processing (NLP) practitioners are leveraging large language models (LLM) to create structured datasets from semi-structured and unstructured data sources such as patents, papers, and theses, without having domain-specific knowledge. At the same time, ecological experts are searching for a variety of means to preserve biodiversity. To contribute to these efforts, we focused on endangered species and through in-context learning, we distilled knowledge from GPT-4. In effect, we created datasets for both named entity recognition (NER) and relation extraction (RE) via a two-stage process: 1) we generated synthetic data from GPT-4 of four classes of endangered species, 2) humans verified the factual accuracy of the synthetic data, resulting in gold data. Eventually, our novel dataset contains a total of 3.6K sentences, evenly divided between 1.8K NER and 1.8K RE sentences. The constructed dataset was then used to fine-tune bo",
    "path": "papers/24/03/2403.15430.json",
    "total_tokens": 847,
    "translated_title": "从大型语言模型中提炼濒危物种的命名实体识别模型",
    "translated_abstract": "自然语言处理（NLP）从业者正在利用大型语言模型（LLM）从专利、论文和论文等半结构化和非结构化数据源创建结构化数据集，而无需具备领域特定知识。与此同时，生态专家正在寻找各种手段来保护生物多样性。为了为这些努力做出贡献，我们专注于濒危物种，并通过上下文学习从GPT-4中提炼知识。实际上，我们通过两阶段过程创建了命名实体识别（NER）和关系抽取（RE）的数据集：1）我们从GPT-4中生成了四类濒危物种的合成数据，2）人类验证了合成数据的事实准确性，最终生成金标数据。最终，我们的新颖数据集包含共3.6K个句子，均分为1.8K个NER句子和1.8K个RE句子。构建的数据集随后用于对bo进行微调。",
    "tldr": "通过从GPT-4中提取知识，我们为濒危物种创建了命名实体识别和关系抽取的数据集，为保护生物多样性做出贡献。"
}