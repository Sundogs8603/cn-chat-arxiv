{
    "title": "Predictions from language models for multiple-choice tasks are not robust under variation of scoring methods",
    "abstract": "arXiv:2403.00998v1 Announce Type: new  Abstract: This paper systematically compares different methods of deriving item-level predictions of language models for multiple-choice tasks. It compares scoring methods for answer options based on free generation of responses, various probability-based scores, a Likert-scale style rating method, and embedding similarity. In a case study on pragmatic language interpretation, we find that LLM predictions are not robust under variation of method choice, both within a single LLM and across different LLMs. As this variability entails pronounced researcher degrees of freedom in reporting results, knowledge of the variability is crucial to secure robustness of results and research integrity.",
    "link": "https://arxiv.org/abs/2403.00998",
    "context": "Title: Predictions from language models for multiple-choice tasks are not robust under variation of scoring methods\nAbstract: arXiv:2403.00998v1 Announce Type: new  Abstract: This paper systematically compares different methods of deriving item-level predictions of language models for multiple-choice tasks. It compares scoring methods for answer options based on free generation of responses, various probability-based scores, a Likert-scale style rating method, and embedding similarity. In a case study on pragmatic language interpretation, we find that LLM predictions are not robust under variation of method choice, both within a single LLM and across different LLMs. As this variability entails pronounced researcher degrees of freedom in reporting results, knowledge of the variability is crucial to secure robustness of results and research integrity.",
    "path": "papers/24/03/2403.00998.json",
    "total_tokens": 763,
    "translated_title": "语言模型在多项选择任务中的预测结果在评分方法变化下不稳健",
    "translated_abstract": "本文系统地比较了不同的方法，用于从语言模型中推导多项选择任务的项目级别预测。它比较了基于自由生成回答、各种基于概率的分数、类似Likert量表风格的评分方法和嵌入相似性的答案选项评分方法。在一个关于语用语言解释的案例研究中，我们发现LLM的预测在选择方法变化下既在单个LLM内部又在不同的LLM之间并不稳健。由于这种变异导致研究者在报告结果时具有显著的自由度，了解这种变异对于确保结果的稳健性和研究诚信至关重要。",
    "tldr": "本研究比较了不同方法对语言模型在多项选择任务中的项目级别预测的影响，发现LLM的预测结果在评分方法的变化下不稳健，这对确保结果的稳健性和研究诚信至关重要。",
    "en_tdlr": "This study systematically compares different methods of deriving item-level predictions of language models for multiple-choice tasks and finds that LLM predictions are not robust under variation of scoring methods, highlighting the importance of ensuring result robustness and research integrity."
}