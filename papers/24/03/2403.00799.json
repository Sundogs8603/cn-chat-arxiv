{
    "title": "An Empirical Study of Data Ability Boundary in LLMs' Math Reasoning",
    "abstract": "arXiv:2403.00799v1 Announce Type: cross  Abstract: Large language models (LLMs) are displaying emergent abilities for math reasoning tasks,and there is a growing attention on enhancing the ability of open-source LLMs through supervised fine-tuning (SFT).In this paper, we aim to explore a general data strategy for supervised data to help optimize and expand math reasoning ability.Firstly, we determine the ability boundary of reasoning paths augmentation by identifying these paths' minimal optimal set.Secondly, we validate that different abilities of the model can be cumulatively enhanced by Mix of Minimal Optimal Sets of corresponding types of data, while our models MMOS achieve SOTA performance on series base models under much lower construction costs.Besides, we point out GSM-HARD is not really hard and today's LLMs no longer lack numerical robustness.Also, we provide an Auto Problem Generator for robustness testing and educational applications.Our code and data are publicly available",
    "link": "https://arxiv.org/abs/2403.00799",
    "context": "Title: An Empirical Study of Data Ability Boundary in LLMs' Math Reasoning\nAbstract: arXiv:2403.00799v1 Announce Type: cross  Abstract: Large language models (LLMs) are displaying emergent abilities for math reasoning tasks,and there is a growing attention on enhancing the ability of open-source LLMs through supervised fine-tuning (SFT).In this paper, we aim to explore a general data strategy for supervised data to help optimize and expand math reasoning ability.Firstly, we determine the ability boundary of reasoning paths augmentation by identifying these paths' minimal optimal set.Secondly, we validate that different abilities of the model can be cumulatively enhanced by Mix of Minimal Optimal Sets of corresponding types of data, while our models MMOS achieve SOTA performance on series base models under much lower construction costs.Besides, we point out GSM-HARD is not really hard and today's LLMs no longer lack numerical robustness.Also, we provide an Auto Problem Generator for robustness testing and educational applications.Our code and data are publicly available",
    "path": "papers/24/03/2403.00799.json",
    "total_tokens": 873,
    "translated_title": "LLM在数学推理中数据能力边界的实证研究",
    "translated_abstract": "大型语言模型(LLMs)正在展示对数学推理任务的新兴能力，人们越来越关注通过监督微调（SFT）增强开源LLMs的能力。本文旨在探讨一个通用的监督数据策略，以帮助优化和拓展数学推理能力。首先，我们通过识别推理路径的最优路径集确定推理路径增强的能力边界。其次，我们验证模型不同能力可以通过相应类型数据的最小最优集混合来累积增强，而我们的模型MMOS在更低的构建成本下实现了系列基础模型的SOTA性能。此外，我们指出GSM-HARD并不真正困难，当今的LLMs不再缺乏数值稳健性。此外，我们提供一个用于稳健性测试和教育应用的自动问题生成器。我们的代码和数据可公开获取。",
    "tldr": "通过确定最优路径集，本研究拓展了LLMs在数学推理任务中的能力边界，提出了一种监督数据策略，通过混合不同类型数据的最小最优集来累积增强模型能力，并实现了SOTA性能。",
    "en_tdlr": "This study extends the ability boundary of LLMs in mathematical reasoning tasks by identifying optimal path sets, proposing a supervised data strategy that cumulatively enhances model capabilities by mixing minimum optimal sets of different data types, and achieves SOTA performance."
}