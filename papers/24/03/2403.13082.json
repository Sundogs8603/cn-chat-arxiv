{
    "title": "Pruning for Improved ADC Efficiency in Crossbar-based Analog In-memory Accelerators",
    "abstract": "arXiv:2403.13082v1 Announce Type: cross  Abstract: Deep learning has proved successful in many applications but suffers from high computational demands and requires custom accelerators for deployment. Crossbar-based analog in-memory architectures are attractive for acceleration of deep neural networks (DNN), due to their high data reuse and high efficiency enabled by combining storage and computation in memory. However, they require analog-to-digital converters (ADCs) to communicate crossbar outputs. ADCs consume a significant portion of energy and area of every crossbar processing unit, thus diminishing the potential efficiency benefits. Pruning is a well-studied technique to improve the efficiency of DNNs but requires modifications to be effective for crossbars. In this paper, we motivate crossbar-attuned pruning to target ADC-specific inefficiencies. This is achieved by identifying three key properties (dubbed D.U.B.) that induce sparsity that can be utilized to reduce ADC energy wi",
    "link": "https://arxiv.org/abs/2403.13082",
    "context": "Title: Pruning for Improved ADC Efficiency in Crossbar-based Analog In-memory Accelerators\nAbstract: arXiv:2403.13082v1 Announce Type: cross  Abstract: Deep learning has proved successful in many applications but suffers from high computational demands and requires custom accelerators for deployment. Crossbar-based analog in-memory architectures are attractive for acceleration of deep neural networks (DNN), due to their high data reuse and high efficiency enabled by combining storage and computation in memory. However, they require analog-to-digital converters (ADCs) to communicate crossbar outputs. ADCs consume a significant portion of energy and area of every crossbar processing unit, thus diminishing the potential efficiency benefits. Pruning is a well-studied technique to improve the efficiency of DNNs but requires modifications to be effective for crossbars. In this paper, we motivate crossbar-attuned pruning to target ADC-specific inefficiencies. This is achieved by identifying three key properties (dubbed D.U.B.) that induce sparsity that can be utilized to reduce ADC energy wi",
    "path": "papers/24/03/2403.13082.json",
    "total_tokens": 881,
    "translated_title": "在基于交叉栅栏的模拟内存加速器中剪枝以提高ADC效率",
    "translated_abstract": "深度学习在许多应用中取得了成功，但面临着高计算需求的问题，需要定制加速器进行部署。基于交叉栅栏的模拟内存架构因在内存中结合存储和计算而具有高数据重用和高效率，而成为加速深度神经网络（DNN）的吸引力所在。然而，它们需要模拟-数字转换器（ADC）来通信交叉栅栏输出。ADC消耗了每个交叉栅栏处理单元的大部分能量和面积，因此削弱了潜在的效率优势。剪枝是提高DNN效率的一个众所周知的技术，但需要进行修改才能对交叉栅有所作用。在本文中，我们提出了针对ADC特定效率低的交叉栅栏调整剪枝的动机。这通过识别会引起稀疏性的三个关键属性（称为D.U.B.）来实现，可以利用这些属性来降低ADC的能耗。",
    "tldr": "提出了一种针对基于交叉栅栏的模拟内存加速器中ADC特定效率低的剪枝方法，通过识别三个关键属性来降低ADC的能耗"
}