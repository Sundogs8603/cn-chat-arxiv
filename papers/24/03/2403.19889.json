{
    "title": "Towards a Robust Retrieval-Based Summarization System",
    "abstract": "arXiv:2403.19889v1 Announce Type: cross  Abstract: This paper describes an investigation of the robustness of large language models (LLMs) for retrieval augmented generation (RAG)-based summarization tasks. While LLMs provide summarization capabilities, their performance in complex, real-world scenarios remains under-explored. Our first contribution is LogicSumm, an innovative evaluation framework incorporating realistic scenarios to assess LLM robustness during RAG-based summarization. Based on limitations identified by LogiSumm, we then developed SummRAG, a comprehensive system to create training dialogues and fine-tune a model to enhance robustness within LogicSumm's scenarios. SummRAG is an example of our goal of defining structured methods to test the capabilities of an LLM, rather than addressing issues in a one-off fashion. Experimental results confirm the power of SummRAG, showcasing improved logical coherence and summarization quality. Data, corresponding model weights, and Py",
    "link": "https://arxiv.org/abs/2403.19889",
    "context": "Title: Towards a Robust Retrieval-Based Summarization System\nAbstract: arXiv:2403.19889v1 Announce Type: cross  Abstract: This paper describes an investigation of the robustness of large language models (LLMs) for retrieval augmented generation (RAG)-based summarization tasks. While LLMs provide summarization capabilities, their performance in complex, real-world scenarios remains under-explored. Our first contribution is LogicSumm, an innovative evaluation framework incorporating realistic scenarios to assess LLM robustness during RAG-based summarization. Based on limitations identified by LogiSumm, we then developed SummRAG, a comprehensive system to create training dialogues and fine-tune a model to enhance robustness within LogicSumm's scenarios. SummRAG is an example of our goal of defining structured methods to test the capabilities of an LLM, rather than addressing issues in a one-off fashion. Experimental results confirm the power of SummRAG, showcasing improved logical coherence and summarization quality. Data, corresponding model weights, and Py",
    "path": "papers/24/03/2403.19889.json",
    "total_tokens": 881,
    "translated_title": "朝向一个强大的基于检索的摘要系统",
    "translated_abstract": "本文描述了对大型语言模型（LLMs）在检索增强生成（RAG）-基础摘要任务中的健壮性进行的调查。虽然LLMs提供了摘要能力，但它们在复杂的实际场景中的表现仍未得到充分探讨。我们的第一个贡献是LogicSumm，这是一个创新的评估框架，结合了现实场景，用来评估LLMs在RAG基础摘要过程中的健壮性。根据LogicSumm识别出的局限性，我们开发了SummRAG，这是一个全面的系统，用于创建训练对话并微调模型，以增强在LogicSumm场景中的健壮性。SummRAG是我们定义结构化方法来测试LLM能力的目标的一个示例，而不是一劳永逸地解决问题。实验结果证实了SummRAG的强大，展示了逻辑连贯性和摘要质量的提升。",
    "tldr": "该论文对大型语言模型在检索增强生成-基础摘要任务中的健壮性进行了调查，并提出了一个创新的评估框架和一个全面的系统来增强模型在特定场景下的健壮性。",
    "en_tdlr": "This paper investigates the robustness of large language models for retrieval augmented generation-based summarization tasks, proposing an innovative evaluation framework and a comprehensive system to enhance the model's robustness in specific scenarios."
}