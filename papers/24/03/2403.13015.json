{
    "title": "HyperVQ: MLR-based Vector Quantization in Hyperbolic Space",
    "abstract": "arXiv:2403.13015v1 Announce Type: cross  Abstract: The success of models operating on tokenized data has led to an increased demand for effective tokenization methods, particularly when applied to vision or auditory tasks, which inherently involve non-discrete data. One of the most popular tokenization methods is Vector Quantization (VQ), a key component of several recent state-of-the-art methods across various domains. Typically, a VQ Variational Autoencoder (VQVAE) is trained to transform data to and from its tokenized representation. However, since the VQVAE is trained with a reconstruction objective, there is no constraint for the embeddings to be well disentangled, a crucial aspect for using them in discriminative tasks. Recently, several works have demonstrated the benefits of utilizing hyperbolic spaces for representation learning. Hyperbolic spaces induce compact latent representations due to their exponential volume growth and inherent ability to model hierarchical and structu",
    "link": "https://arxiv.org/abs/2403.13015",
    "context": "Title: HyperVQ: MLR-based Vector Quantization in Hyperbolic Space\nAbstract: arXiv:2403.13015v1 Announce Type: cross  Abstract: The success of models operating on tokenized data has led to an increased demand for effective tokenization methods, particularly when applied to vision or auditory tasks, which inherently involve non-discrete data. One of the most popular tokenization methods is Vector Quantization (VQ), a key component of several recent state-of-the-art methods across various domains. Typically, a VQ Variational Autoencoder (VQVAE) is trained to transform data to and from its tokenized representation. However, since the VQVAE is trained with a reconstruction objective, there is no constraint for the embeddings to be well disentangled, a crucial aspect for using them in discriminative tasks. Recently, several works have demonstrated the benefits of utilizing hyperbolic spaces for representation learning. Hyperbolic spaces induce compact latent representations due to their exponential volume growth and inherent ability to model hierarchical and structu",
    "path": "papers/24/03/2403.13015.json",
    "total_tokens": 884,
    "translated_title": "HyperVQ：基于MLR的超半平面空间向量量化",
    "translated_abstract": "论文在探讨基于tokenized数据的模型取得成功之后，对有效的tokenization方法的需求不断增加，尤其是在涉及非离散数据的视觉或听觉任务中。其中，最流行的tokenization方法之一是矢量量化（VQ），它是各个领域最新最先进方法的关键组件之一。通常，VQ变分自动编码器（VQVAE）被训练用于将数据转换到其经过tokenization的表示形式，然后再转换回去。然而，由于VQVAE是通过重构目标来训练的，对于嵌入是否被很好地分解为不同参数并没有约束，这对于将它们用于区分任务非常重要。最近，一些作品已经证明了利用超半平面空间进行表示学习的好处。超半平面空间由于其指数级体积增长和固有的建模分层和结图的能力，导致产生了紧凑的潜在表示形式。",
    "tldr": "论文提出了一种基于MLR的超半平面空间向量量化方法HyperVQ，结合了矢量量化和超半平面空间的优势，用于更好地学习数据的紧凑潜在表示形式。",
    "en_tdlr": "The paper introduces a MLR-based vector quantization method in hyperbolic space, HyperVQ, which combines the advantages of vector quantization and hyperbolic space for better learning compact latent representations of data."
}