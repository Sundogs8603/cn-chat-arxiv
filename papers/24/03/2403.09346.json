{
    "title": "AVIBench: Towards Evaluating the Robustness of Large Vision-Language Model on Adversarial Visual-Instructions",
    "abstract": "arXiv:2403.09346v1 Announce Type: cross  Abstract: Large Vision-Language Models (LVLMs) have shown significant progress in well responding to visual-instructions from users. However, these instructions, encompassing images and text, are susceptible to both intentional and inadvertent attacks. Despite the critical importance of LVLMs' robustness against such threats, current research in this area remains limited. To bridge this gap, we introduce AVIBench, a framework designed to analyze the robustness of LVLMs when facing various adversarial visual-instructions (AVIs), including four types of image-based AVIs, ten types of text-based AVIs, and nine types of content bias AVIs (such as gender, violence, cultural, and racial biases, among others). We generate 260K AVIs encompassing five categories of multimodal capabilities (nine tasks) and content bias. We then conduct a comprehensive evaluation involving 14 open-source LVLMs to assess their performance. AVIBench also serves as a convenie",
    "link": "https://arxiv.org/abs/2403.09346",
    "context": "Title: AVIBench: Towards Evaluating the Robustness of Large Vision-Language Model on Adversarial Visual-Instructions\nAbstract: arXiv:2403.09346v1 Announce Type: cross  Abstract: Large Vision-Language Models (LVLMs) have shown significant progress in well responding to visual-instructions from users. However, these instructions, encompassing images and text, are susceptible to both intentional and inadvertent attacks. Despite the critical importance of LVLMs' robustness against such threats, current research in this area remains limited. To bridge this gap, we introduce AVIBench, a framework designed to analyze the robustness of LVLMs when facing various adversarial visual-instructions (AVIs), including four types of image-based AVIs, ten types of text-based AVIs, and nine types of content bias AVIs (such as gender, violence, cultural, and racial biases, among others). We generate 260K AVIs encompassing five categories of multimodal capabilities (nine tasks) and content bias. We then conduct a comprehensive evaluation involving 14 open-source LVLMs to assess their performance. AVIBench also serves as a convenie",
    "path": "papers/24/03/2403.09346.json",
    "total_tokens": 941,
    "translated_title": "AVIBench：评估大型视觉-语言模型在对抗性视觉指导上的鲁棒性",
    "translated_abstract": "大型视觉-语言模型（LVLMs）在对用户的视觉指令作出良好响应方面取得了显著进展。然而，这些指令涵盖图像和文本，容易受到有意和无意攻击的影响。尽管LVLMs对抗此类威胁的鲁棒性至关重要，但当前该领域的研究仍然有限。为弥补这一差距，我们引入了AVIBench，一个旨在分析LVLMs在面对各种对抗性视觉指令（AVIs）时的鲁棒性的框架，包括四种基于图像的AVIs、十种基于文本的AVIs和九种内容偏见AVIs（如性别、暴力、文化和种族偏见等）。我们生成了26万个AVIs，涵盖五类多模态能力（九项任务）和内容偏见。然后，我们对包括14个开源LVLMs在内的模型进行全面评估以评估其性能。AVIBench还可作为一个便利的工具",
    "tldr": "AVIBench是一个框架，用于分析大型视觉-语言模型对抗各种形式的对抗性视觉指令的鲁棒性，包括图像和文本攻击以及内容偏见攻击。",
    "en_tdlr": "AVIBench is a framework designed to analyze the robustness of large vision-language models against various forms of adversarial visual-instructions, including image and text-based attacks as well as content bias attacks."
}