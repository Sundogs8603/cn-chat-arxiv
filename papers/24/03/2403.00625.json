{
    "title": "Bias Mitigation in Fine-tuning Pre-trained Models for Enhanced Fairness and Efficiency",
    "abstract": "arXiv:2403.00625v1 Announce Type: new  Abstract: Fine-tuning pre-trained models is a widely employed technique in numerous real-world applications. However, fine-tuning these models on new tasks can lead to unfair outcomes. This is due to the absence of generalization guarantees for fairness properties, regardless of whether the original pre-trained model was developed with fairness considerations. To tackle this issue, we introduce an efficient and robust fine-tuning framework specifically designed to mitigate biases in new tasks. Our empirical analysis shows that the parameters in the pre-trained model that affect predictions for different demographic groups are different, so based on this observation, we employ a transfer learning strategy that neutralizes the importance of these influential weights, determined using Fisher information across demographic groups. Additionally, we integrate this weight importance neutralization strategy with a matrix factorization technique, which pro",
    "link": "https://arxiv.org/abs/2403.00625",
    "context": "Title: Bias Mitigation in Fine-tuning Pre-trained Models for Enhanced Fairness and Efficiency\nAbstract: arXiv:2403.00625v1 Announce Type: new  Abstract: Fine-tuning pre-trained models is a widely employed technique in numerous real-world applications. However, fine-tuning these models on new tasks can lead to unfair outcomes. This is due to the absence of generalization guarantees for fairness properties, regardless of whether the original pre-trained model was developed with fairness considerations. To tackle this issue, we introduce an efficient and robust fine-tuning framework specifically designed to mitigate biases in new tasks. Our empirical analysis shows that the parameters in the pre-trained model that affect predictions for different demographic groups are different, so based on this observation, we employ a transfer learning strategy that neutralizes the importance of these influential weights, determined using Fisher information across demographic groups. Additionally, we integrate this weight importance neutralization strategy with a matrix factorization technique, which pro",
    "path": "papers/24/03/2403.00625.json",
    "total_tokens": 855,
    "translated_title": "在微调预训练模型以提升公平性和效率的偏见缓解方法",
    "translated_abstract": "细调预训练模型是许多现实世界应用中广泛采用的技术。然而，在新任务上微调这些模型可能导致不公平的结果。这是因为无论原始预训练模型是否考虑了公平性，都没有公平性属性的泛化保证。为了解决这个问题，我们引入了一种专门设计用于减轻新任务中偏见的高效且稳健的微调框架。我们的实证分析表明，影响不同人口群体预测的预训练模型中的参数是不同的，基于这一观察，我们采用一种转移学习策略，该策略通过使用跨人口群体之间的Fisher信息确定的这些有影响力的权重来中和这些有影响力的权重的重要性。此外，我们将这种权重重要性中和策略与矩阵因子分解技术结合起来。",
    "tldr": "该论文介绍了一种专门设计用于减轻新任务中偏见的高效且稳健的微调框架，通过中和对不同人口群体预测有影响力的权重，从而提升公平性和效率。",
    "en_tdlr": "This paper presents an efficient and robust fine-tuning framework specifically designed to mitigate biases in new tasks by neutralizing the influential weights for predicting different demographic groups, aiming to enhance fairness and efficiency."
}