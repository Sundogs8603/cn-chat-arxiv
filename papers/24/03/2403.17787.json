{
    "title": "Evaluating the Efficacy of Prompt-Engineered Large Multimodal Models Versus Fine-Tuned Vision Transformers in Image-Based Security Applications",
    "abstract": "arXiv:2403.17787v1 Announce Type: new  Abstract: The success of Large Language Models (LLMs) has led to a parallel rise in the development of Large Multimodal Models (LMMs), such as Gemini-pro, which have begun to transform a variety of applications. These sophisticated multimodal models are designed to interpret and analyze complex data, integrating both textual and visual information on a scale previously unattainable, opening new avenues for a range of applications. This paper investigates the applicability and effectiveness of prompt-engineered Gemini-pro LMMs versus fine-tuned Vision Transformer (ViT) models in addressing critical security challenges. We focus on two distinct tasks: a visually evident task of detecting simple triggers, such as small squares in images, indicative of potential backdoors, and a non-visually evident task of malware classification through visual representations. Our results highlight a significant divergence in performance, with Gemini-pro falling shor",
    "link": "https://arxiv.org/abs/2403.17787",
    "context": "Title: Evaluating the Efficacy of Prompt-Engineered Large Multimodal Models Versus Fine-Tuned Vision Transformers in Image-Based Security Applications\nAbstract: arXiv:2403.17787v1 Announce Type: new  Abstract: The success of Large Language Models (LLMs) has led to a parallel rise in the development of Large Multimodal Models (LMMs), such as Gemini-pro, which have begun to transform a variety of applications. These sophisticated multimodal models are designed to interpret and analyze complex data, integrating both textual and visual information on a scale previously unattainable, opening new avenues for a range of applications. This paper investigates the applicability and effectiveness of prompt-engineered Gemini-pro LMMs versus fine-tuned Vision Transformer (ViT) models in addressing critical security challenges. We focus on two distinct tasks: a visually evident task of detecting simple triggers, such as small squares in images, indicative of potential backdoors, and a non-visually evident task of malware classification through visual representations. Our results highlight a significant divergence in performance, with Gemini-pro falling shor",
    "path": "papers/24/03/2403.17787.json",
    "total_tokens": 884,
    "translated_title": "评估在基于图像的安全应用中，在即时工程过程中设计的大型多模型与微调视觉变换器的有效性",
    "translated_abstract": "大型语言模型（LLMs）的成功导致了大型多模态模型（LMMs）（如Gemini-pro）的发展，这些模型已经开始转变各种应用。这些复杂的多模态模型旨在解释和分析复杂数据，整合了以往难以实现的文本和视觉信息规模，为一系列应用开辟了新的途径。本文调查了在解决关键安全挑战方面，即时工程的Gemini-pro LMMs与微调视觉变换器（ViT）模型的适用性和有效性。我们专注于两个不同的任务：检测图像中的简单触发器（如方形小方块）以示潜在后门的在视觉上显而易见的任务，以及通过视觉表示进行恶意软件分类的在视觉上不明显的任务。我们的结果突显了性能上的显著差异，Gemini-pro表现不佳。",
    "tldr": "评估在基于图像的安全应用中，即时工程的Gemini-pro大型多模态模型与微调的Vision Transformer模型的有效性，并发现在关键安全挑战中表现出明显的性能差异。",
    "en_tdlr": "Evaluating the efficacy of prompt-engineered Gemini-pro LMMs versus fine-tuned Vision Transformer models in image-based security applications reveals a significant performance gap in addressing critical security challenges."
}