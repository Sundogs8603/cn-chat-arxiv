{
    "title": "LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation",
    "abstract": "arXiv:2403.01131v1 Announce Type: cross  Abstract: Recent research explores optimization using large language models (LLMs) by either iteratively seeking next-step solutions from LLMs or directly prompting LLMs for an optimizer. However, these approaches exhibit inherent limitations, including low operational efficiency, high sensitivity to prompt design, and a lack of domain-specific knowledge. We introduce LLaMoCo, the first instruction-tuning framework designed to adapt LLMs for solving optimization problems in a code-to-code manner. Specifically, we establish a comprehensive instruction set containing well-described problem prompts and effective optimization codes. We then develop a novel two-phase learning strategy that incorporates a contrastive learning-based warm-up procedure before the instruction-tuning phase to enhance the convergence behavior during model fine-tuning. The experiment results demonstrate that a CodeGen (350M) model fine-tuned by our LLaMoCo achieves superior ",
    "link": "https://arxiv.org/abs/2403.01131",
    "context": "Title: LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation\nAbstract: arXiv:2403.01131v1 Announce Type: cross  Abstract: Recent research explores optimization using large language models (LLMs) by either iteratively seeking next-step solutions from LLMs or directly prompting LLMs for an optimizer. However, these approaches exhibit inherent limitations, including low operational efficiency, high sensitivity to prompt design, and a lack of domain-specific knowledge. We introduce LLaMoCo, the first instruction-tuning framework designed to adapt LLMs for solving optimization problems in a code-to-code manner. Specifically, we establish a comprehensive instruction set containing well-described problem prompts and effective optimization codes. We then develop a novel two-phase learning strategy that incorporates a contrastive learning-based warm-up procedure before the instruction-tuning phase to enhance the convergence behavior during model fine-tuning. The experiment results demonstrate that a CodeGen (350M) model fine-tuned by our LLaMoCo achieves superior ",
    "path": "papers/24/03/2403.01131.json",
    "total_tokens": 870,
    "translated_title": "LLaMoCo：用于优化代码生成的大型语言模型指令调优",
    "translated_abstract": "最近的研究探讨了使用大型语言模型（LLMs）进行优化，方法包括从LLMs迭代地寻找下一步解决方案，或直接提示LLMs以获取优化器。然而，这些方法存在固有限制，包括操作效率低、对提示设计敏感度高以及缺乏领域特定知识。我们介绍了LLaMoCo，这是第一个旨在以代码对代码方式调整LLMs以解决优化问题的指令调优框架。具体地，我们建立了一个包含清晰描述的问题提示和有效优化代码的全面指令集。然后我们开发了一种新颖的两阶段学习策略，在指令调优阶段之前，该策略整合了基于对比学习的热身过程，以增强模型微调期间的收敛行为。实验结果表明，通过我们的LLaMoCo精调的CodeGen（350M）模型达到了卓越的性能。",
    "tldr": "LLaMoCo是第一个旨在以代码对代码方式调整LLMs以解决优化问题的指令调优框架，通过全面指令集和新颖的两阶段学习策略，实现了优越的性能。",
    "en_tdlr": "LLaMoCo is the first instruction-tuning framework designed to adapt LLMs for solving optimization problems in a code-to-code manner, achieving superior performance through a comprehensive instruction set and a novel two-phase learning strategy."
}