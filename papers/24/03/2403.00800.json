{
    "title": "Brain-Inspired Two-Stage Approach: Enhancing Mathematical Reasoning by Imitating Human Thought Processes",
    "abstract": "arXiv:2403.00800v1 Announce Type: cross  Abstract: Although large language models demonstrate emergent abilities in solving math word problems, there is a challenging task in complex multi-step mathematical reasoning tasks. To improve model performance on mathematical reasoning tasks, previous work has conducted supervised fine-tuning on open-source models by improving the quality and quantity of data. In this paper, we propose a novel approach, named Brain, to imitate human thought processes to enhance mathematical reasoning abilities, using the Frontal Lobe Model to generate plans, and then employing the Parietal Lobe Model to generate code and execute to obtain answers. First, we achieve SOTA performance in comparison with Code LLaMA 7B based models through this method. Secondly, we find that plans can be explicitly extracted from natural language, code, or formal language. Our code and data are publicly available at https://github.com/cyzhh/Brain.",
    "link": "https://arxiv.org/abs/2403.00800",
    "context": "Title: Brain-Inspired Two-Stage Approach: Enhancing Mathematical Reasoning by Imitating Human Thought Processes\nAbstract: arXiv:2403.00800v1 Announce Type: cross  Abstract: Although large language models demonstrate emergent abilities in solving math word problems, there is a challenging task in complex multi-step mathematical reasoning tasks. To improve model performance on mathematical reasoning tasks, previous work has conducted supervised fine-tuning on open-source models by improving the quality and quantity of data. In this paper, we propose a novel approach, named Brain, to imitate human thought processes to enhance mathematical reasoning abilities, using the Frontal Lobe Model to generate plans, and then employing the Parietal Lobe Model to generate code and execute to obtain answers. First, we achieve SOTA performance in comparison with Code LLaMA 7B based models through this method. Secondly, we find that plans can be explicitly extracted from natural language, code, or formal language. Our code and data are publicly available at https://github.com/cyzhh/Brain.",
    "path": "papers/24/03/2403.00800.json",
    "total_tokens": 845,
    "translated_title": "借鉴人类思维过程的脑启发两阶段方法：通过模仿人类思维过程增强数学推理能力",
    "translated_abstract": "虽然大型语言模型展示了在解决数学问题方面的新能力，但在复杂的多步数学推理任务中仍然存在挑战。为了提高模型在数学推理任务上的表现，先前的工作通过改进数据的质量和数量，在开源模型上进行了监督微调。在本文中，我们提出了一种名为Brain的新方法，通过使用前额叶模型生成计划，然后使用顶叶模型生成代码并执行以获得答案，来模仿人类思维过程以增强数学推理能力。首先，我们通过此方法与基于Code LLaMA 7B的模型相比实现了SOTA性能。其次，我们发现计划可以明确地从自然语言、代码或形式语言中提取出来。我们的代码和数据可以在https://github.com/cyzhh/Brain上公开获取。",
    "tldr": "通过模仿人类思维过程，在数学推理任务中提出的Brain方法实现了最先进的性能，并发现计划可以从自然语言、代码或形式语言中明确提取出来。",
    "en_tdlr": "The Brain method proposed in this paper, which imitates human thought processes, achieves state-of-the-art performance in mathematical reasoning tasks and demonstrates the explicit extraction of plans from natural language, code, or formal language."
}