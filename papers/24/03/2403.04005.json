{
    "title": "On the Efficient Marginalization of Probabilistic Sequence Models",
    "abstract": "arXiv:2403.04005v1 Announce Type: cross  Abstract: Real-world data often exhibits sequential dependence, across diverse domains such as human behavior, medicine, finance, and climate modeling. Probabilistic methods capture the inherent uncertainty associated with prediction in these contexts, with autoregressive models being especially prominent. This dissertation focuses on using autoregressive models to answer complex probabilistic queries that go beyond single-step prediction, such as the timing of future events or the likelihood of a specific event occurring before another. In particular, we develop a broad class of novel and efficient approximation techniques for marginalization in sequential models that are model-agnostic. These techniques rely solely on access to and sampling from next-step conditional distributions of a pre-trained autoregressive model, including both traditional parametric models as well as more recent neural autoregressive models. Specific approaches are pres",
    "link": "https://arxiv.org/abs/2403.04005",
    "context": "Title: On the Efficient Marginalization of Probabilistic Sequence Models\nAbstract: arXiv:2403.04005v1 Announce Type: cross  Abstract: Real-world data often exhibits sequential dependence, across diverse domains such as human behavior, medicine, finance, and climate modeling. Probabilistic methods capture the inherent uncertainty associated with prediction in these contexts, with autoregressive models being especially prominent. This dissertation focuses on using autoregressive models to answer complex probabilistic queries that go beyond single-step prediction, such as the timing of future events or the likelihood of a specific event occurring before another. In particular, we develop a broad class of novel and efficient approximation techniques for marginalization in sequential models that are model-agnostic. These techniques rely solely on access to and sampling from next-step conditional distributions of a pre-trained autoregressive model, including both traditional parametric models as well as more recent neural autoregressive models. Specific approaches are pres",
    "path": "papers/24/03/2403.04005.json",
    "total_tokens": 836,
    "translated_title": "关于概率序列模型边缘化的高效性",
    "translated_abstract": "现实世界中的数据经常表现出序列依赖性，涵盖人类行为、医学、金融和气候模拟等各个领域。概率方法捕捉了这些背景下预测相关的固有不确定性，其中自回归模型尤为突出。本论文着重于使用自回归模型回答超出单步预测范围的复杂概率查询，比如未来事件的时间安排或某一事件发生在另一事件之前的可能性。具体来说，我们开发了一系列新颖高效的逼近技术，用于序贯模型的边缘化，这些技术是模型无关的，仅依赖于预训练自回归模型的下一步条件分布的访问和采样，包括传统参数模型以及最新的神经自回归模型。",
    "tldr": "论文提出了一系列新颖高效的逼近技术，用于序贯模型的边缘化，这些技术是模型无关的，仅依赖于预训练自回归模型的下一步条件分布的访问和采样。",
    "en_tdlr": "The paper introduces a series of novel and efficient approximation techniques for marginalization in sequential models that are model-agnostic, relying solely on access to and sampling from next-step conditional distributions of a pre-trained autoregressive model."
}