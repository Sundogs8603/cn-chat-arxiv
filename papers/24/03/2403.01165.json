{
    "title": "STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient Fine-Tuning of Large Language Models",
    "abstract": "arXiv:2403.01165v1 Announce Type: cross  Abstract: Though Large Language Models (LLMs) have demonstrated the powerful capabilities of few-shot learning through prompting methods, supervised training is still necessary for complex reasoning tasks. Because of their extensive parameters and memory consumption, both Parameter-Efficient Fine-Tuning (PEFT) methods and Memory-Efficient Fine-Tuning methods have been proposed for LLMs. Nevertheless, the issue of large annotated data consumption, the aim of Data-Efficient Fine-Tuning, remains unexplored. One obvious way is to combine the PEFT method with active learning. However, the experimental results show that such a combination is not trivial and yields inferior results. Through probe experiments, such observation might be explained by two main reasons: uncertainty gap and poor model calibration. Therefore, in this paper, we propose a novel approach to effectively integrate uncertainty-based active learning and LoRA. Specifically, for the u",
    "link": "https://arxiv.org/abs/2403.01165",
    "context": "Title: STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient Fine-Tuning of Large Language Models\nAbstract: arXiv:2403.01165v1 Announce Type: cross  Abstract: Though Large Language Models (LLMs) have demonstrated the powerful capabilities of few-shot learning through prompting methods, supervised training is still necessary for complex reasoning tasks. Because of their extensive parameters and memory consumption, both Parameter-Efficient Fine-Tuning (PEFT) methods and Memory-Efficient Fine-Tuning methods have been proposed for LLMs. Nevertheless, the issue of large annotated data consumption, the aim of Data-Efficient Fine-Tuning, remains unexplored. One obvious way is to combine the PEFT method with active learning. However, the experimental results show that such a combination is not trivial and yields inferior results. Through probe experiments, such observation might be explained by two main reasons: uncertainty gap and poor model calibration. Therefore, in this paper, we propose a novel approach to effectively integrate uncertainty-based active learning and LoRA. Specifically, for the u",
    "path": "papers/24/03/2403.01165.json",
    "total_tokens": 827,
    "translated_title": "STAR: 使用动态主动学习约束LoRA，实现大型语言模型数据高效微调",
    "translated_abstract": "大型语言模型(LLMs)通过提示方法展示了少样本学习的强大能力，但对于复杂推理任务仍需监督训练。针对LLMs的参数众多和内存消耗大问题，分别提出了参数高效微调(PEFT)方法和内存高效微调方法。然而，数据高效微调旨在解决大量注释数据消耗的问题，却鲜有研究。一种明显的方式是将PEFT方法与主动学习相结合。然而，实验结果表明这种组合并非简单，并产生较差的结果。通过探针实验，这一观察结果可能由两个主要原因解释：不确定性差距和模型校准不佳。因此，在本文中，我们提出了一种新颖的方法，有效地将基于不确定性的主动学习和LoRA进行整合。",
    "tldr": "本论文提出了一种新颖的方法，有效地将基于不确定性的主动学习和LoRA相结合，以解决大型语言模型数据高效微调中遇到的问题。",
    "en_tdlr": "This paper proposes a novel approach to effectively integrate uncertainty-based active learning and LoRA to address the challenges in data-efficient fine-tuning of large language models."
}