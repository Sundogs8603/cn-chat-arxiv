{
    "title": "Is Translation All You Need? A Study on Solving Multilingual Tasks with Large Language Models",
    "abstract": "arXiv:2403.10258v1 Announce Type: new  Abstract: Large language models (LLMs) have demonstrated strong multilingual capabilities; yet, they are mostly English-centric due to the imbalanced training corpora. Existing works leverage this phenomenon to improve their multilingual performances on NLP tasks. In this work, we extend the evaluation from NLP tasks to real user queries. We find that even though translation into English can help improve the performance of multilingual NLP tasks for English-centric LLMs, it may not be optimal for all scenarios. For culture-related tasks that need deep language understanding, prompting in the native language proves to be more promising since it can capture the nuances related to culture and language. Therefore, we advocate for more efforts towards the development of strong multilingual LLMs instead of just English-centric LLMs.",
    "link": "https://arxiv.org/abs/2403.10258",
    "context": "Title: Is Translation All You Need? A Study on Solving Multilingual Tasks with Large Language Models\nAbstract: arXiv:2403.10258v1 Announce Type: new  Abstract: Large language models (LLMs) have demonstrated strong multilingual capabilities; yet, they are mostly English-centric due to the imbalanced training corpora. Existing works leverage this phenomenon to improve their multilingual performances on NLP tasks. In this work, we extend the evaluation from NLP tasks to real user queries. We find that even though translation into English can help improve the performance of multilingual NLP tasks for English-centric LLMs, it may not be optimal for all scenarios. For culture-related tasks that need deep language understanding, prompting in the native language proves to be more promising since it can capture the nuances related to culture and language. Therefore, we advocate for more efforts towards the development of strong multilingual LLMs instead of just English-centric LLMs.",
    "path": "papers/24/03/2403.10258.json",
    "total_tokens": 798,
    "translated_title": "翻译到底是你所需要的全部吗？使用大型语言模型解决多语言任务的研究",
    "translated_abstract": "大型语言模型（LLMs）展示了强大的多语言能力；然而，由于训练语料库不平衡，它们大多是以英语为中心的。现有研究利用这一现象来提高它们在自然语言处理任务上的多语言性能。在本研究中，我们将评估从自然语言处理任务扩展到真实用户查询。我们发现，尽管将文本翻译成英语可以帮助提高以英语为中心的LLMs在多语言自然语言处理任务中的性能，但并不一定适用于所有场景。对于需要深入理解语言的文化相关任务，以本地语言提示更为有前景，因为它可以捕捉与文化和语言相关的微妙之处。因此，我们主张着力发展强大的多语言LLMs，而不仅仅是以英语为中心的LLMs。",
    "tldr": "提出了通过本地语言提示来解决文化相关任务的方法，并呼吁发展强大的多语言LLMs。",
    "en_tdlr": "Propose a method to solve culture-related tasks by prompting in native language, and advocate for the development of strong multilingual LLMs."
}