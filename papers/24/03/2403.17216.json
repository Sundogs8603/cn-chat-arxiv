{
    "title": "Ontology Completion with Natural Language Inference and Concept Embeddings: An Analysis",
    "abstract": "arXiv:2403.17216v1 Announce Type: new  Abstract: We consider the problem of finding plausible knowledge that is missing from a given ontology, as a generalisation of the well-studied taxonomy expansion task. One line of work treats this task as a Natural Language Inference (NLI) problem, thus relying on the knowledge captured by language models to identify the missing knowledge. Another line of work uses concept embeddings to identify what different concepts have in common, taking inspiration from cognitive models for category based induction. These two approaches are intuitively complementary, but their effectiveness has not yet been compared. In this paper, we introduce a benchmark for evaluating ontology completion methods and thoroughly analyse the strengths and weaknesses of both approaches. We find that both approaches are indeed complementary, with hybrid strategies achieving the best overall results. We also find that the task is highly challenging for Large Language Models, ev",
    "link": "https://arxiv.org/abs/2403.17216",
    "context": "Title: Ontology Completion with Natural Language Inference and Concept Embeddings: An Analysis\nAbstract: arXiv:2403.17216v1 Announce Type: new  Abstract: We consider the problem of finding plausible knowledge that is missing from a given ontology, as a generalisation of the well-studied taxonomy expansion task. One line of work treats this task as a Natural Language Inference (NLI) problem, thus relying on the knowledge captured by language models to identify the missing knowledge. Another line of work uses concept embeddings to identify what different concepts have in common, taking inspiration from cognitive models for category based induction. These two approaches are intuitively complementary, but their effectiveness has not yet been compared. In this paper, we introduce a benchmark for evaluating ontology completion methods and thoroughly analyse the strengths and weaknesses of both approaches. We find that both approaches are indeed complementary, with hybrid strategies achieving the best overall results. We also find that the task is highly challenging for Large Language Models, ev",
    "path": "papers/24/03/2403.17216.json",
    "total_tokens": 840,
    "translated_title": "使用自然语言推理和概念嵌入进行本体补全：一项分析",
    "translated_abstract": "我们考虑了找到给定本体中缺失的合理知识的问题，作为对广泛研究的分类法扩展任务的概括。一种方法将这一任务视为自然语言推理（NLI）问题，依赖于语言模型捕获的知识来识别缺失的知识。另一种方法使用概念嵌入来确定不同概念之间的共同之处，受认知模型对基于类别归纳的启发。这两种方法在直觉上是互补的，但它们的有效性尚未进行比较。在这篇论文中，我们介绍了一个用于评估本体补全方法的基准，并彻底分析了这两种方法的优势和劣势。我们发现这两种方法确实是互补的，混合策略实现了最佳的整体结果。我们还发现这一任务对大型语言模型来说非常具有挑战性。",
    "tldr": "本文介绍了使用自然语言推理和概念嵌入进行本体补全的新方法，并发现这两种方法互补，混合策略取得最佳效果。",
    "en_tdlr": "The paper introduces a novel approach for ontology completion using natural language inference and concept embeddings, finding that the two methods are complementary and hybrid strategies achieve the best results."
}