{
    "title": "Towards Sustainable SecureML: Quantifying Carbon Footprint of Adversarial Machine Learning",
    "abstract": "arXiv:2403.19009v1 Announce Type: new  Abstract: The widespread adoption of machine learning (ML) across various industries has raised sustainability concerns due to its substantial energy usage and carbon emissions. This issue becomes more pressing in adversarial ML, which focuses on enhancing model security against different network-based attacks. Implementing defenses in ML systems often necessitates additional computational resources and network security measures, exacerbating their environmental impacts. In this paper, we pioneer the first investigation into adversarial ML's carbon footprint, providing empirical evidence connecting greater model robustness to higher emissions. Addressing the critical need to quantify this trade-off, we introduce the Robustness Carbon Trade-off Index (RCTI). This novel metric, inspired by economic elasticity principles, captures the sensitivity of carbon emissions to changes in adversarial robustness. We demonstrate the RCTI through an experiment i",
    "link": "https://arxiv.org/abs/2403.19009",
    "context": "Title: Towards Sustainable SecureML: Quantifying Carbon Footprint of Adversarial Machine Learning\nAbstract: arXiv:2403.19009v1 Announce Type: new  Abstract: The widespread adoption of machine learning (ML) across various industries has raised sustainability concerns due to its substantial energy usage and carbon emissions. This issue becomes more pressing in adversarial ML, which focuses on enhancing model security against different network-based attacks. Implementing defenses in ML systems often necessitates additional computational resources and network security measures, exacerbating their environmental impacts. In this paper, we pioneer the first investigation into adversarial ML's carbon footprint, providing empirical evidence connecting greater model robustness to higher emissions. Addressing the critical need to quantify this trade-off, we introduce the Robustness Carbon Trade-off Index (RCTI). This novel metric, inspired by economic elasticity principles, captures the sensitivity of carbon emissions to changes in adversarial robustness. We demonstrate the RCTI through an experiment i",
    "path": "papers/24/03/2403.19009.json",
    "total_tokens": 847,
    "translated_title": "迈向可持续的SecureML: 量化对抗机器学习的碳足迹",
    "translated_abstract": "机器学习(ML)在各行各业的广泛应用引起了可持续性担忧，因为其巨大的能源消耗和碳排放。在对抗性ML中，这一问题变得更加紧迫，因为它着重于增强模型对抗不同基于网络的攻击的安全性。在ML系统中实施防御通常需要额外的计算资源和网络安全措施，加剧了它们的环境影响。本文探讨了对抗性ML的碳足迹，提供实证证据将更大的模型稳健性与更高的排放联系起来。为了解决量化这种权衡的迫切需求，我们引入了Robustness Carbon Trade-off Index (RCTI)。这一新颖的度量指标受经济弹性原理启发，捕捉了碳排放对抗性稳健性变化的敏感性。",
    "tldr": "本文首次探究了对抗机器学习的碳足迹，并引入了Robustness Carbon Trade-off Index（RCTI），该指标捕捉了碳排放对抗性稳健性变化的敏感性。",
    "en_tdlr": "This paper pioneers an investigation into the carbon footprint of adversarial machine learning and introduces the Robustness Carbon Trade-off Index (RCTI) which captures the sensitivity of carbon emissions to changes in adversarial robustness."
}