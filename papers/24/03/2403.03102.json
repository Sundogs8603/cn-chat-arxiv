{
    "title": "\"In Dialogues We Learn\": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning",
    "abstract": "arXiv:2403.03102v1 Announce Type: cross  Abstract: Personalized dialogue systems have gained significant attention in recent years for their ability to generate responses in alignment with different personas. However, most existing approaches rely on pre-defined personal profiles, which are not only time-consuming and labor-intensive to create but also lack flexibility. We propose In-Dialogue Learning (IDL), a fine-tuning framework that enhances the ability of pre-trained large language models to leverage dialogue history to characterize persona for completing personalized dialogue generation tasks without pre-defined profiles. Our experiments on three datasets demonstrate that IDL brings substantial improvements, with BLEU and ROUGE scores increasing by up to 200% and 247%, respectively. Additionally, the results of human evaluations further validate the efficacy of our proposed method.",
    "link": "https://arxiv.org/abs/2403.03102",
    "context": "Title: \"In Dialogues We Learn\": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning\nAbstract: arXiv:2403.03102v1 Announce Type: cross  Abstract: Personalized dialogue systems have gained significant attention in recent years for their ability to generate responses in alignment with different personas. However, most existing approaches rely on pre-defined personal profiles, which are not only time-consuming and labor-intensive to create but also lack flexibility. We propose In-Dialogue Learning (IDL), a fine-tuning framework that enhances the ability of pre-trained large language models to leverage dialogue history to characterize persona for completing personalized dialogue generation tasks without pre-defined profiles. Our experiments on three datasets demonstrate that IDL brings substantial improvements, with BLEU and ROUGE scores increasing by up to 200% and 247%, respectively. Additionally, the results of human evaluations further validate the efficacy of our proposed method.",
    "path": "papers/24/03/2403.03102.json",
    "total_tokens": 764,
    "translated_title": "“在对话中学习”：通过对话中学习实现无需预定义个人资料的个性化对话",
    "translated_abstract": "个性化对话系统近年来备受关注，因其能够生成与不同人设一致的响应。然而，大多数现有方法依赖预定义的个人资料，这不仅耗时且劳动密集，还缺乏灵活性。我们提出了In-Dialogue Learning（IDL），一种微调框架，增强了预训练的大型语言模型利用对话历史来刻画个人设，以完成个性化对话生成任务，而无需预定义个人资料。我们在三个数据集上的实验表明，IDL带来了显著的改进，BLEU和ROUGE分数分别增加了高达200%和247%。此外，人工评估的结果进一步验证了我们提出方法的有效性。",
    "tldr": "提出了一种In-Dialogue Learning框架，通过对话历史刻画个人设来完成个性化对话生成任务，无需预定义个人资料，并在实验证明其显著改进对话生成性能。",
    "en_tdlr": "Introduced the In-Dialogue Learning framework to characterize personas based on dialogue history for personalized dialogue generation without pre-defined profiles, achieving significant performance improvements as validated in experiments."
}