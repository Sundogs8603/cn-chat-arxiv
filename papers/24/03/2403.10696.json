{
    "title": "On the low-shot transferability of [V]-Mamba",
    "abstract": "arXiv:2403.10696v1 Announce Type: cross  Abstract: The strength of modern large-scale neural networks lies in their ability to efficiently adapt to new tasks with few examples. Although extensive research has investigated the transferability of Vision Transformers (ViTs) to various downstream tasks under diverse constraints, this study shifts focus to explore the transfer learning potential of [V]-Mamba. We compare its performance with ViTs across different few-shot data budgets and efficient transfer methods. Our analysis yields three key insights into [V]-Mamba's few-shot transfer performance: (a) [V]-Mamba demonstrates superior or equivalent few-shot learning capabilities compared to ViTs when utilizing linear probing (LP) for transfer, (b) Conversely, [V]-Mamba exhibits weaker or similar few-shot learning performance compared to ViTs when employing visual prompting (VP) as the transfer method, and (c) We observe a weak positive correlation between the performance gap in transfer vi",
    "link": "https://arxiv.org/abs/2403.10696",
    "context": "Title: On the low-shot transferability of [V]-Mamba\nAbstract: arXiv:2403.10696v1 Announce Type: cross  Abstract: The strength of modern large-scale neural networks lies in their ability to efficiently adapt to new tasks with few examples. Although extensive research has investigated the transferability of Vision Transformers (ViTs) to various downstream tasks under diverse constraints, this study shifts focus to explore the transfer learning potential of [V]-Mamba. We compare its performance with ViTs across different few-shot data budgets and efficient transfer methods. Our analysis yields three key insights into [V]-Mamba's few-shot transfer performance: (a) [V]-Mamba demonstrates superior or equivalent few-shot learning capabilities compared to ViTs when utilizing linear probing (LP) for transfer, (b) Conversely, [V]-Mamba exhibits weaker or similar few-shot learning performance compared to ViTs when employing visual prompting (VP) as the transfer method, and (c) We observe a weak positive correlation between the performance gap in transfer vi",
    "path": "papers/24/03/2403.10696.json",
    "total_tokens": 886,
    "translated_title": "论[V]-Mamba的低样本迁移性",
    "translated_abstract": "现代大规模神经网络的优势在于它们能够有效地适应少量示例的新任务。尽管大量研究已经探讨了Vision Transformers（ViTs）在不同约束下用于各种下游任务的可迁移性，但本研究将重点转移到了[V]-Mamba的迁移学习潜力。我们比较了其在不同少样本数据预算和高效迁移方法下的性能。我们的分析得出了三个关于[V]-Mamba在少样本迁移性能方面的关键见解：(a) 在利用线性探查（LP）进行迁移时，[V]-Mamba相较于ViTs展现出了更优秀或等效的少样本学习能力，(b) 相反，当采用视觉提示（VP）作为迁移方法时，[V]-Mamba展示出较弱或类似于ViTs的少样本学习性能，(c) 我们观察到在迁移性能差距方面存在着微弱的正相关性",
    "tldr": "[V]-Mamba相对于ViTs在利用线性探查进行迁移时展现出更优秀或等效的少样本学习能力，但在采用视觉提示作为迁移方法时表现出较弱或类似的表现。"
}