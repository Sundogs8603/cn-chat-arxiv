{
    "title": "RiEMann: Near Real-Time SE(3)-Equivariant Robot Manipulation without Point Cloud Segmentation",
    "abstract": "arXiv:2403.19460v1 Announce Type: cross  Abstract: We present RiEMann, an end-to-end near Real-time SE(3)-Equivariant Robot Manipulation imitation learning framework from scene point cloud input. Compared to previous methods that rely on descriptor field matching, RiEMann directly predicts the target poses of objects for manipulation without any object segmentation. RiEMann learns a manipulation task from scratch with 5 to 10 demonstrations, generalizes to unseen SE(3) transformations and instances of target objects, resists visual interference of distracting objects, and follows the near real-time pose change of the target object. The scalable action space of RiEMann facilitates the addition of custom equivariant actions such as the direction of turning the faucet, which makes articulated object manipulation possible for RiEMann. In simulation and real-world 6-DOF robot manipulation experiments, we test RiEMann on 5 categories of manipulation tasks with a total of 25 variants and show",
    "link": "https://arxiv.org/abs/2403.19460",
    "context": "Title: RiEMann: Near Real-Time SE(3)-Equivariant Robot Manipulation without Point Cloud Segmentation\nAbstract: arXiv:2403.19460v1 Announce Type: cross  Abstract: We present RiEMann, an end-to-end near Real-time SE(3)-Equivariant Robot Manipulation imitation learning framework from scene point cloud input. Compared to previous methods that rely on descriptor field matching, RiEMann directly predicts the target poses of objects for manipulation without any object segmentation. RiEMann learns a manipulation task from scratch with 5 to 10 demonstrations, generalizes to unseen SE(3) transformations and instances of target objects, resists visual interference of distracting objects, and follows the near real-time pose change of the target object. The scalable action space of RiEMann facilitates the addition of custom equivariant actions such as the direction of turning the faucet, which makes articulated object manipulation possible for RiEMann. In simulation and real-world 6-DOF robot manipulation experiments, we test RiEMann on 5 categories of manipulation tasks with a total of 25 variants and show",
    "path": "papers/24/03/2403.19460.json",
    "total_tokens": 959,
    "translated_title": "RiEMann: 不需要点云分割的近实时 SE(3)等变机器人操作",
    "translated_abstract": "我们提出了RiEMann，一个端到端的近实时 SE(3)等变机器人操作模仿学习框架，从场景点云输入中学习。与先前依赖描述符匹配的方法不同，RiEMann直接预测对象的目标姿势进行操作，而无需进行任何对象分割。RiEMann可以从零开始学习一个操作任务，只需5到10个演示，可以泛化到看不见的SE(3)转换和目标对象的实例，抵抗干扰对象的视觉干扰，并遵循目标对象的近实时姿势变化。RiEMann的可伸缩动作空间有助于添加自定义等变动作，例如旋转水龙头的方向，这使得RiEMann可以进行关节对象操作。在模拟和现实世界的6自由度机器人操作实验中，我们测试了RiEMann 对 5类操纵任务的25种变体进行了测试。",
    "tldr": "RiEMann提出了一个近实时SE(3)等变机器人操作模仿学习框架，无需点云分割，可以从零开始学习操作任务，泛化到看不见的转换和目标对象实例，对抗视觉干扰，实时跟踪目标对象的姿势变化，同时具有可扩展的动作空间使得关节对象操作成为可能。",
    "en_tdlr": "RiEMann introduces a near real-time SE(3)-equivariant robot manipulation imitation learning framework that does not require point cloud segmentation, can learn manipulation tasks from scratch, generalize to unseen transformations and instances of target objects, resist visual interference, track the pose changes of target objects in near real-time, and has a scalable action space enabling articulated object manipulation."
}