{
    "title": "What Was Your Prompt? A Remote Keylogging Attack on AI Assistants",
    "abstract": "arXiv:2403.09751v1 Announce Type: cross  Abstract: AI assistants are becoming an integral part of society, used for asking advice or help in personal and confidential issues. In this paper, we unveil a novel side-channel that can be used to read encrypted responses from AI Assistants over the web: the token-length side-channel. We found that many vendors, including OpenAI and Microsoft, have this side-channel.   However, inferring the content of a response from a token-length sequence alone proves challenging. This is because tokens are akin to words, and responses can be several sentences long leading to millions of grammatically correct sentences. In this paper, we show how this can be overcome by (1) utilizing the power of a large language model (LLM) to translate these sequences, (2) providing the LLM with inter-sentence context to narrow the search space and (3) performing a known-plaintext attack by fine-tuning the model on the target model's writing style.   Using these methods,",
    "link": "https://arxiv.org/abs/2403.09751",
    "context": "Title: What Was Your Prompt? A Remote Keylogging Attack on AI Assistants\nAbstract: arXiv:2403.09751v1 Announce Type: cross  Abstract: AI assistants are becoming an integral part of society, used for asking advice or help in personal and confidential issues. In this paper, we unveil a novel side-channel that can be used to read encrypted responses from AI Assistants over the web: the token-length side-channel. We found that many vendors, including OpenAI and Microsoft, have this side-channel.   However, inferring the content of a response from a token-length sequence alone proves challenging. This is because tokens are akin to words, and responses can be several sentences long leading to millions of grammatically correct sentences. In this paper, we show how this can be overcome by (1) utilizing the power of a large language model (LLM) to translate these sequences, (2) providing the LLM with inter-sentence context to narrow the search space and (3) performing a known-plaintext attack by fine-tuning the model on the target model's writing style.   Using these methods,",
    "path": "papers/24/03/2403.09751.json",
    "total_tokens": 819,
    "translated_title": "你的提示是什么？一种针对AI助手的远程键盘记录攻击",
    "translated_abstract": "AI助手正逐渐成为社会的一个重要组成部分，用于寻求个人和机密问题的建议或帮助。本文揭示了一种新的旁路攻击，可用于通过网络读取AI助手的加密响应：令牌长度旁路。我们发现包括OpenAI和Microsoft在内的许多厂商受到这一旁路的影响。然而，仅从令牌长度序列推断响应内容却具有挑战性。这是因为令牌类似于单词，响应可以是几句话长，导致有成千上万个语法正确的句子。",
    "tldr": "本文揭示了一种可以用于读取AI助手加密响应的新型旁路攻击——令牌长度旁路，并展示了如何通过利用大型语言模型，提供句子间上下文并进行已知明文攻击来克服这一挑战。",
    "en_tdlr": "This paper unveils a novel side-channel attack, the token-length side-channel, for reading encrypted responses from AI assistants, and demonstrates how to overcome the challenge by utilizing a large language model, providing inter-sentence context, and performing a known-plaintext attack."
}