{
    "title": "Leveraging Linguistically Enhanced Embeddings for Open Information Extraction",
    "abstract": "arXiv:2403.13903v1 Announce Type: new  Abstract: Open Information Extraction (OIE) is a structured prediction (SP) task in Natural Language Processing (NLP) that aims to extract structured $n$-ary tuples - usually subject-relation-object triples - from free text. The word embeddings in the input text can be enhanced with linguistic features, usually Part-of-Speech (PoS) and Syntactic Dependency Parse (SynDP) labels. However, past enhancement techniques cannot leverage the power of pretrained language models (PLMs), which themselves have been hardly used for OIE. To bridge this gap, we are the first to leverage linguistic features with a Seq2Seq PLM for OIE. We do so by introducing two methods - Weighted Addition and Linearized Concatenation. Our work can give any neural OIE architecture the key performance boost from both PLMs and linguistic features in one go. In our settings, this shows wide improvements of up to 24.9%, 27.3% and 14.9% on Precision, Recall and F1 scores respectively ",
    "link": "https://arxiv.org/abs/2403.13903",
    "context": "Title: Leveraging Linguistically Enhanced Embeddings for Open Information Extraction\nAbstract: arXiv:2403.13903v1 Announce Type: new  Abstract: Open Information Extraction (OIE) is a structured prediction (SP) task in Natural Language Processing (NLP) that aims to extract structured $n$-ary tuples - usually subject-relation-object triples - from free text. The word embeddings in the input text can be enhanced with linguistic features, usually Part-of-Speech (PoS) and Syntactic Dependency Parse (SynDP) labels. However, past enhancement techniques cannot leverage the power of pretrained language models (PLMs), which themselves have been hardly used for OIE. To bridge this gap, we are the first to leverage linguistic features with a Seq2Seq PLM for OIE. We do so by introducing two methods - Weighted Addition and Linearized Concatenation. Our work can give any neural OIE architecture the key performance boost from both PLMs and linguistic features in one go. In our settings, this shows wide improvements of up to 24.9%, 27.3% and 14.9% on Precision, Recall and F1 scores respectively ",
    "path": "papers/24/03/2403.13903.json",
    "total_tokens": 895,
    "translated_title": "利用语言增强嵌入进行开放信息抽取",
    "translated_abstract": "开放信息抽取（OIE）是自然语言处理（NLP）中一项结构化预测（SP）任务，旨在从自由文本中提取结构化的$n$-元组，通常是主-谓-宾三元组。输入文本中的词嵌入可以通过语言特征（通常是词性（PoS）和句法依存解析（SynDP）标签）进行增强。然而，过去的增强技术无法利用预训练语言模型（PLM）的强大功能，而PLMs本身很少用于OIE。为了弥合这一差距，我们首次利用Seq2Seq PLM与语言特征进行OIE，通过引入加权相加和线性化连接两种方法。我们的工作可以使任何神经网络OIE架构一次性获得PLMs和语言特征的关键性能提升。在我们的设置中，这显示了对Precision、Recall和F1得分的广泛提高，分别达到24.9%、27.3%和14.9%。",
    "tldr": "首次利用Seq2Seq PLM与语言特征相结合，有效提高了神经网络OIE架构的性能，使其同时获益于预训练语言模型和语言特征。",
    "en_tdlr": "The paper introduces the combination of Seq2Seq PLM with linguistic features for the first time, effectively enhancing the performance of neural network OIE architecture, benefiting from both pretrained language models and linguistic features."
}