{
    "title": "An In-Depth Analysis of Data Reduction Methods for Sustainable Deep Learning",
    "abstract": "arXiv:2403.15150v1 Announce Type: new  Abstract: In recent years, Deep Learning has gained popularity for its ability to solve complex classification tasks, increasingly delivering better results thanks to the development of more accurate models, the availability of huge volumes of data and the improved computational capabilities of modern computers. However, these improvements in performance also bring efficiency problems, related to the storage of datasets and models, and to the waste of energy and time involved in both the training and inference processes. In this context, data reduction can help reduce energy consumption when training a deep learning model. In this paper, we present up to eight different methods to reduce the size of a tabular training dataset, and we develop a Python package to apply them. We also introduce a representativeness metric based on topology to measure how similar are the reduced datasets and the full training dataset. Additionally, we develop a methodo",
    "link": "https://arxiv.org/abs/2403.15150",
    "context": "Title: An In-Depth Analysis of Data Reduction Methods for Sustainable Deep Learning\nAbstract: arXiv:2403.15150v1 Announce Type: new  Abstract: In recent years, Deep Learning has gained popularity for its ability to solve complex classification tasks, increasingly delivering better results thanks to the development of more accurate models, the availability of huge volumes of data and the improved computational capabilities of modern computers. However, these improvements in performance also bring efficiency problems, related to the storage of datasets and models, and to the waste of energy and time involved in both the training and inference processes. In this context, data reduction can help reduce energy consumption when training a deep learning model. In this paper, we present up to eight different methods to reduce the size of a tabular training dataset, and we develop a Python package to apply them. We also introduce a representativeness metric based on topology to measure how similar are the reduced datasets and the full training dataset. Additionally, we develop a methodo",
    "path": "papers/24/03/2403.15150.json",
    "total_tokens": 833,
    "translated_title": "深度学习数据减少方法的深度分析",
    "translated_abstract": "近年来，深度学习因其解决复杂分类任务的能力而备受青睐，随着更精确模型的开发、海量数据的可用性以及现代计算机改进的计算能力，不断取得更好的结果。然而，这些性能的提升也带来了效率问题，涉及数据集和模型的存储，以及训练和推理过程中涉及的能源和时间浪费。在这种背景下，数据减少有助于在训练深度学习模型时减少能源消耗。本文介绍了八种不同的方法来减小表格训练数据集的大小，并开发了一个Python软件包来应用这些方法。我们还引入了一种基于拓扑的代表性度量，用以衡量减少的数据集和完整训练数据集之间的相似程度。",
    "tldr": "本文深度分析了深度学习数据减少方法对提升效率的作用，提出了多种减小训练数据集大小的方法，并开发了用于衡量数据集相似度的拓扑代表性度量。",
    "en_tdlr": "This paper provides an in-depth analysis of the impact of data reduction methods on enhancing efficiency in deep learning, introducing multiple approaches for reducing the size of training datasets and developing a topology-based representativeness metric to measure dataset similarity."
}