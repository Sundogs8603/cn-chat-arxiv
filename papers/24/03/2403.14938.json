{
    "title": "On Zero-Shot Counterspeech Generation by LLMs",
    "abstract": "arXiv:2403.14938v1 Announce Type: new  Abstract: With the emergence of numerous Large Language Models (LLM), the usage of such models in various Natural Language Processing (NLP) applications is increasing extensively. Counterspeech generation is one such key task where efforts are made to develop generative models by fine-tuning LLMs with hatespeech - counterspeech pairs, but none of these attempts explores the intrinsic properties of large language models in zero-shot settings. In this work, we present a comprehensive analysis of the performances of four LLMs namely GPT-2, DialoGPT, ChatGPT and FlanT5 in zero-shot settings for counterspeech generation, which is the first of its kind. For GPT-2 and DialoGPT, we further investigate the deviation in performance with respect to the sizes (small, medium, large) of the models. On the other hand, we propose three different prompting strategies for generating different types of counterspeech and analyse the impact of such strategies on the p",
    "link": "https://arxiv.org/abs/2403.14938",
    "context": "Title: On Zero-Shot Counterspeech Generation by LLMs\nAbstract: arXiv:2403.14938v1 Announce Type: new  Abstract: With the emergence of numerous Large Language Models (LLM), the usage of such models in various Natural Language Processing (NLP) applications is increasing extensively. Counterspeech generation is one such key task where efforts are made to develop generative models by fine-tuning LLMs with hatespeech - counterspeech pairs, but none of these attempts explores the intrinsic properties of large language models in zero-shot settings. In this work, we present a comprehensive analysis of the performances of four LLMs namely GPT-2, DialoGPT, ChatGPT and FlanT5 in zero-shot settings for counterspeech generation, which is the first of its kind. For GPT-2 and DialoGPT, we further investigate the deviation in performance with respect to the sizes (small, medium, large) of the models. On the other hand, we propose three different prompting strategies for generating different types of counterspeech and analyse the impact of such strategies on the p",
    "path": "papers/24/03/2403.14938.json",
    "total_tokens": 877,
    "translated_title": "关于LLM在零-shot 对抗性言论生成中的应用",
    "translated_abstract": "随着大量大型语言模型（LLM）的出现，这些模型在各种自然语言处理（NLP）应用中的使用量大幅增加。对抗性言论生成是一个重要任务，努力通过微调LLM与仇恨言论-对抗性言论对来发展生成模型，但这些尝试都没有探索大型语言模型在零-shot 设置中的内在特性。在这项工作中，我们对四个LLM（GPT-2、DialoGPT、ChatGPT和FlanT5）在零-shot 设置下用于对抗性言论生成的性能进行了全面分析，这是第一次。对于GPT-2和DialoGPT，我们进一步研究了随着模型大小（小、中、大）性能偏差。另一方面，我们提出了三种不同的提示策略，用于生成不同类型的对抗性言论，并分析了这些策略对性能的影响。",
    "tldr": "该研究首次在零-shot 设置下探索了四种LLM在对抗性言论生成任务中的表现，并提出了三种不同的提示策略，为生成不同类型的对抗性言论提供了全面分析。"
}