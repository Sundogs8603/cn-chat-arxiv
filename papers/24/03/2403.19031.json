{
    "title": "Evaluating Large Language Models for Health-Related Text Classification Tasks with Public Social Media Data",
    "abstract": "arXiv:2403.19031v1 Announce Type: cross  Abstract: Large language models (LLMs) have demonstrated remarkable success in NLP tasks. However, there is a paucity of studies that attempt to evaluate their performances on social media-based health-related natural language processing tasks, which have traditionally been difficult to achieve high scores in. We benchmarked one supervised classic machine learning model based on Support Vector Machines (SVMs), three supervised pretrained language models (PLMs) based on RoBERTa, BERTweet, and SocBERT, and two LLM based classifiers (GPT3.5 and GPT4), across 6 text classification tasks. We developed three approaches for leveraging LLMs for text classification: employing LLMs as zero-shot classifiers, us-ing LLMs as annotators to annotate training data for supervised classifiers, and utilizing LLMs with few-shot examples for augmentation of manually annotated data. Our comprehensive experiments demonstrate that employ-ing data augmentation using LLM",
    "link": "https://arxiv.org/abs/2403.19031",
    "context": "Title: Evaluating Large Language Models for Health-Related Text Classification Tasks with Public Social Media Data\nAbstract: arXiv:2403.19031v1 Announce Type: cross  Abstract: Large language models (LLMs) have demonstrated remarkable success in NLP tasks. However, there is a paucity of studies that attempt to evaluate their performances on social media-based health-related natural language processing tasks, which have traditionally been difficult to achieve high scores in. We benchmarked one supervised classic machine learning model based on Support Vector Machines (SVMs), three supervised pretrained language models (PLMs) based on RoBERTa, BERTweet, and SocBERT, and two LLM based classifiers (GPT3.5 and GPT4), across 6 text classification tasks. We developed three approaches for leveraging LLMs for text classification: employing LLMs as zero-shot classifiers, us-ing LLMs as annotators to annotate training data for supervised classifiers, and utilizing LLMs with few-shot examples for augmentation of manually annotated data. Our comprehensive experiments demonstrate that employ-ing data augmentation using LLM",
    "path": "papers/24/03/2403.19031.json",
    "total_tokens": 794,
    "translated_title": "使用公共社交媒体数据评估大型语言模型在健康相关文本分类任务中的表现",
    "translated_abstract": "大型语言模型（LLMs）在NLP任务中展现出卓越的成功。然而，几乎没有研究试图评估它们在基于社交媒体的健康相关自然语言处理任务中的表现，这些任务传统上很难获得高分。我们在6个文本分类任务上对一个基于支持向量机（SVMs）的监督经典机器学习模型，三个基于RoBERTa、BERTweet和SocBERT的监督预训练语言模型（PLMs），以及两个基于GPT3.5和GPT4的LLM分类器进行了基准测试。我们开发了三种利用LLMs进行文本分类的方法：将LLMs用作零次分类器，将LLMs用作注释器为监督分类器注释训练数据，以及利用LLMs进行少量示例来增加手动注释数据。我们全面的实验表明，利用LLMs进行数据增强可以...",
    "tldr": "综合实验表明，利用LLMs进行数据增强可以...",
    "en_tdlr": "Comprehensive experiments demonstrate that employing data augmentation using LLMs..."
}