{
    "title": "Harnessing Artificial Intelligence to Combat Online Hate: Exploring the Challenges and Opportunities of Large Language Models in Hate Speech Detection",
    "abstract": "arXiv:2403.08035v1 Announce Type: cross  Abstract: Large language models (LLMs) excel in many diverse applications beyond language generation, e.g., translation, summarization, and sentiment analysis. One intriguing application is in text classification. This becomes pertinent in the realm of identifying hateful or toxic speech -- a domain fraught with challenges and ethical dilemmas. In our study, we have two objectives: firstly, to offer a literature review revolving around LLMs as classifiers, emphasizing their role in detecting and classifying hateful or toxic content. Subsequently, we explore the efficacy of several LLMs in classifying hate speech: identifying which LLMs excel in this task as well as their underlying attributes and training. Providing insight into the factors that contribute to an LLM proficiency (or lack thereof) in discerning hateful content. By combining a comprehensive literature review with an empirical analysis, our paper strives to shed light on the capabil",
    "link": "https://arxiv.org/abs/2403.08035",
    "context": "Title: Harnessing Artificial Intelligence to Combat Online Hate: Exploring the Challenges and Opportunities of Large Language Models in Hate Speech Detection\nAbstract: arXiv:2403.08035v1 Announce Type: cross  Abstract: Large language models (LLMs) excel in many diverse applications beyond language generation, e.g., translation, summarization, and sentiment analysis. One intriguing application is in text classification. This becomes pertinent in the realm of identifying hateful or toxic speech -- a domain fraught with challenges and ethical dilemmas. In our study, we have two objectives: firstly, to offer a literature review revolving around LLMs as classifiers, emphasizing their role in detecting and classifying hateful or toxic content. Subsequently, we explore the efficacy of several LLMs in classifying hate speech: identifying which LLMs excel in this task as well as their underlying attributes and training. Providing insight into the factors that contribute to an LLM proficiency (or lack thereof) in discerning hateful content. By combining a comprehensive literature review with an empirical analysis, our paper strives to shed light on the capabil",
    "path": "papers/24/03/2403.08035.json",
    "total_tokens": 988,
    "translated_title": "利用人工智能打击网络仇恨：探讨大型语言模型在仇恨言论检测中的挑战和机遇",
    "translated_abstract": "大型语言模型（LLMs）在许多不同的应用中表现出色，除了语言生成，还包括翻译、摘要和情感分析等。一个引人注目的应用是文本分类。在识别令人憎恶或有毒言论的领域中，这变得至关重要，这是一个充满挑战和伦理困境的领域。在我们的研究中，我们有两个目标：首先，提供一个围绕LLMs作为分类器的文献综述，强调它们在检测和分类令人憎恶或有毒内容方面的作用。随后，我们探究了几种LLMs在分类仇恨言论方面的效力：识别哪些LLMs在这一任务中表现出色以及它们的基本属性和训练。借此洞察促成LLM在识别令人憎恶内容方面的优劣性所依赖的因素。通过结合全面的文献回顾和实证分析，我们的论文旨在解开这些大型语言模型在辨别令人憎恶内容方面的能力。",
    "tldr": "该论文围绕大型语言模型（LLMs）在检测和分类令人憎恶或有毒内容方面的作用展开文献综述和实证分析，旨在揭示LLM在识别令人憎恶内容方面的能力及其影响因素。",
    "en_tdlr": "This paper provides a literature review and empirical analysis on the role of Large Language Models (LLMs) in detecting and classifying hateful or toxic content, aiming to uncover the capabilities and influencing factors of LLMs in identifying hateful content."
}