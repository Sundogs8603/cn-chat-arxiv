{
    "title": "Counterfactual Fairness through Transforming Data Orthogonal to Bias",
    "abstract": "arXiv:2403.17852v1 Announce Type: new  Abstract: Machine learning models have shown exceptional prowess in solving complex issues across various domains. Nonetheless, these models can sometimes exhibit biased decision-making, leading to disparities in treatment across different groups. Despite the extensive research on fairness, the nuanced effects of multivariate and continuous sensitive variables on decision-making outcomes remain insufficiently studied. We introduce a novel data pre-processing algorithm, Orthogonal to Bias (OB), designed to remove the influence of a group of continuous sensitive variables, thereby facilitating counterfactual fairness in machine learning applications. Our approach is grounded in the assumption of a jointly normal distribution within a structural causal model (SCM), proving that counterfactual fairness can be achieved by ensuring the data is uncorrelated with sensitive variables. The OB algorithm is model-agnostic, catering to a wide array of machine ",
    "link": "https://arxiv.org/abs/2403.17852",
    "context": "Title: Counterfactual Fairness through Transforming Data Orthogonal to Bias\nAbstract: arXiv:2403.17852v1 Announce Type: new  Abstract: Machine learning models have shown exceptional prowess in solving complex issues across various domains. Nonetheless, these models can sometimes exhibit biased decision-making, leading to disparities in treatment across different groups. Despite the extensive research on fairness, the nuanced effects of multivariate and continuous sensitive variables on decision-making outcomes remain insufficiently studied. We introduce a novel data pre-processing algorithm, Orthogonal to Bias (OB), designed to remove the influence of a group of continuous sensitive variables, thereby facilitating counterfactual fairness in machine learning applications. Our approach is grounded in the assumption of a jointly normal distribution within a structural causal model (SCM), proving that counterfactual fairness can be achieved by ensuring the data is uncorrelated with sensitive variables. The OB algorithm is model-agnostic, catering to a wide array of machine ",
    "path": "papers/24/03/2403.17852.json",
    "total_tokens": 818,
    "translated_title": "通过将数据转化为与偏见正交的方式实现反事实公平性",
    "translated_abstract": "机器学习模型在解决各个领域的复杂问题中展现出了卓越的能力。然而，这些模型有时可能表现出有偏见的决策，导致不同群体之间的待遇不平等。尽管公平性方面的研究已经很广泛，但多元连续敏感变量对决策结果的微妙影响尚未得到充分研究。我们引入了一种新颖的数据预处理算法，即正交于偏见（OB），旨在消除连续敏感变量的影响，从而促进机器学习应用中的反事实公平性。我们的方法基于结构因果模型（SCM）中联合正态分布的假设，证明了通过确保数据与敏感变量不相关即可实现反事实公平性。OB算法与模型无关，适用于多种机器学习应用。",
    "tldr": "提出了一种新颖的数据预处理算法，正交于偏见（OB），通过确保数据与敏感变量不相关，实现机器学习应用中的反事实公平性。",
    "en_tdlr": "Proposed a novel data pre-processing algorithm, Orthogonal to Bias (OB), which achieves counterfactual fairness in machine learning applications by ensuring data is uncorrelated with sensitive variables."
}