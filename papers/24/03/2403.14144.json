{
    "title": "Understanding the Ranking Loss for Recommendation with Sparse User Feedback",
    "abstract": "arXiv:2403.14144v1 Announce Type: new  Abstract: Click-through rate (CTR) prediction holds significant importance in the realm of online advertising. While many existing approaches treat it as a binary classification problem and utilize binary cross entropy (BCE) as the optimization objective, recent advancements have indicated that combining BCE loss with ranking loss yields substantial performance improvements. However, the full efficacy of this combination loss remains incompletely understood. In this paper, we uncover a new challenge associated with BCE loss in scenarios with sparse positive feedback, such as CTR prediction: the gradient vanishing for negative samples. Subsequently, we introduce a novel perspective on the effectiveness of ranking loss in CTR prediction, highlighting its ability to generate larger gradients on negative samples, thereby mitigating their optimization issues and resulting in improved classification ability. Our perspective is supported by extensive the",
    "link": "https://arxiv.org/abs/2403.14144",
    "context": "Title: Understanding the Ranking Loss for Recommendation with Sparse User Feedback\nAbstract: arXiv:2403.14144v1 Announce Type: new  Abstract: Click-through rate (CTR) prediction holds significant importance in the realm of online advertising. While many existing approaches treat it as a binary classification problem and utilize binary cross entropy (BCE) as the optimization objective, recent advancements have indicated that combining BCE loss with ranking loss yields substantial performance improvements. However, the full efficacy of this combination loss remains incompletely understood. In this paper, we uncover a new challenge associated with BCE loss in scenarios with sparse positive feedback, such as CTR prediction: the gradient vanishing for negative samples. Subsequently, we introduce a novel perspective on the effectiveness of ranking loss in CTR prediction, highlighting its ability to generate larger gradients on negative samples, thereby mitigating their optimization issues and resulting in improved classification ability. Our perspective is supported by extensive the",
    "path": "papers/24/03/2403.14144.json",
    "total_tokens": 842,
    "translated_title": "了解带有稀疏用户反馈的推荐排序损失",
    "translated_abstract": "arXiv:2403.14144v1 公告类型: 新的 摘要: 在在线广告领域，点击率（CTR）预测具有重要意义。虽然许多现有方法将其视为二元分类问题，并利用二元交叉熵（BCE）作为优化目标，但最近的进展表明，将BCE损失与排序损失相结合可以显著提高性能。然而，这种组合损失的完整功效尚未完全理解。在本文中，我们揭示了在存在稀疏正反馈场景（如CTR预测）中与BCE损失相关的一个新挑战：负样本的梯度消失问题。随后，我们介绍了一个新的视角，强调了排序损失在CTR预测中的有效性，突出了它在负样本上生成更大的梯度，从而减轻了它们的优化问题，并导致了改善的分类能力。我们的观点得到了大量支持。",
    "tldr": "排序损失与二元交叉熵损失相结合可以提高点击率预测性能，特别是在稀疏正反馈情况下，通过生成更大的负样本梯度来改善分类能力。",
    "en_tdlr": "Combining ranking loss with binary cross entropy loss can enhance CTR prediction performance, especially in scenarios with sparse positive feedback, by generating larger gradients on negative samples to improve classification ability."
}