{
    "title": "Evolution Transformer: In-Context Evolutionary Optimization",
    "abstract": "arXiv:2403.02985v1 Announce Type: new  Abstract: Evolutionary optimization algorithms are often derived from loose biological analogies and struggle to leverage information obtained during the sequential course of optimization. An alternative promising approach is to leverage data and directly discover powerful optimization principles via meta-optimization. In this work, we follow such a paradigm and introduce Evolution Transformer, a causal Transformer architecture, which can flexibly characterize a family of Evolution Strategies. Given a trajectory of evaluations and search distribution statistics, Evolution Transformer outputs a performance-improving update to the search distribution. The architecture imposes a set of suitable inductive biases, i.e. the invariance of the distribution update to the order of population members within a generation and equivariance to the order of the search dimensions. We train the model weights using Evolutionary Algorithm Distillation, a technique fo",
    "link": "https://arxiv.org/abs/2403.02985",
    "context": "Title: Evolution Transformer: In-Context Evolutionary Optimization\nAbstract: arXiv:2403.02985v1 Announce Type: new  Abstract: Evolutionary optimization algorithms are often derived from loose biological analogies and struggle to leverage information obtained during the sequential course of optimization. An alternative promising approach is to leverage data and directly discover powerful optimization principles via meta-optimization. In this work, we follow such a paradigm and introduce Evolution Transformer, a causal Transformer architecture, which can flexibly characterize a family of Evolution Strategies. Given a trajectory of evaluations and search distribution statistics, Evolution Transformer outputs a performance-improving update to the search distribution. The architecture imposes a set of suitable inductive biases, i.e. the invariance of the distribution update to the order of population members within a generation and equivariance to the order of the search dimensions. We train the model weights using Evolutionary Algorithm Distillation, a technique fo",
    "path": "papers/24/03/2403.02985.json",
    "total_tokens": 731,
    "translated_title": "进化Transformer：上下文进化优化",
    "translated_abstract": "进化优化算法通常从宽泛的生物类比中衍生出来，在优化的连续过程中难以利用所获得的信息。另一种有前途的方法是利用数据，通过元优化直接发现强大的优化原则。在这项工作中，我们遵循这样的范式，引入了Evolution Transformer，一个因果Transformer架构，可以灵活地描述一类进化策略。给定评估轨迹和搜索分布统计数据，Evolution Transformer输出一个改进搜索分布的更新。该架构施加了一组适当的归纳偏差，即在一代中个体成员顺序不变的分布更新和对搜索维度顺序的等变性。我们使用进化算法蒸馏训练模型权重，这是一种技术。",
    "tldr": "提出了一种Evolution Transformer架构，可以通过元优化直接发现强大的优化原则，达到改进搜索分布的目的。",
    "en_tdlr": "Proposed Evolution Transformer architecture that directly discovers powerful optimization principles via meta-optimization to improve search distribution."
}