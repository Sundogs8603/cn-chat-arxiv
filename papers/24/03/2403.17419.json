{
    "title": "AI Safety: Necessary, but insufficient and possibly problematic",
    "abstract": "arXiv:2403.17419v1 Announce Type: new  Abstract: This article critically examines the recent hype around AI safety. We first start with noting the nature of the AI safety hype as being dominated by governments and corporations, and contrast it with other avenues within AI research on advancing social good. We consider what 'AI safety' actually means, and outline the dominant concepts that the digital footprint of AI safety aligns with. We posit that AI safety has a nuanced and uneasy relationship with transparency and other allied notions associated with societal good, indicating that it is an insufficient notion if the goal is that of societal good in a broad sense. We note that the AI safety debate has already influenced some regulatory efforts in AI, perhaps in not so desirable directions. We also share our concerns on how AI safety may normalize AI that advances structural harm through providing exploitative and harmful AI with a veneer of safety.",
    "link": "https://arxiv.org/abs/2403.17419",
    "context": "Title: AI Safety: Necessary, but insufficient and possibly problematic\nAbstract: arXiv:2403.17419v1 Announce Type: new  Abstract: This article critically examines the recent hype around AI safety. We first start with noting the nature of the AI safety hype as being dominated by governments and corporations, and contrast it with other avenues within AI research on advancing social good. We consider what 'AI safety' actually means, and outline the dominant concepts that the digital footprint of AI safety aligns with. We posit that AI safety has a nuanced and uneasy relationship with transparency and other allied notions associated with societal good, indicating that it is an insufficient notion if the goal is that of societal good in a broad sense. We note that the AI safety debate has already influenced some regulatory efforts in AI, perhaps in not so desirable directions. We also share our concerns on how AI safety may normalize AI that advances structural harm through providing exploitative and harmful AI with a veneer of safety.",
    "path": "papers/24/03/2403.17419.json",
    "total_tokens": 801,
    "translated_title": "AI安全性：必要，但不足和可能存在问题",
    "translated_abstract": "本文对近期围绕AI安全性的炒作进行了批判性审视。我们首先指出AI安全性炒作的性质是由政府和企业主导，并将其与AI研究中其他关于推进社会利益的途径进行对比。我们考虑了“AI安全性”实际上意味着什么，并概述了AI安全性数字足迹所符合的主流概念。我们认为AI安全性与透明度等与社会利益相关联的概念之间存在微妙且不稳定的关系，表明如果目标是广义上的社会利益，则它是一个不充分的概念。我们指出，AI安全性的讨论已经影响了一些AI监管努力，也许是朝着不太理想的方向。我们还分享了对AI安全性如何使通过给予剥削性和有害AI一层安全外衣来促使结构性伤害的AI合法化的担忧。",
    "tldr": "AI安全性炒作存在问题，可能会导致不利的监管努力并使有害AI合法化。"
}