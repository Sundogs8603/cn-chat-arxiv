{
    "title": "Efficient Prompt Tuning of Large Vision-Language Model for Fine-Grained Ship Classification",
    "abstract": "arXiv:2403.08271v1 Announce Type: cross  Abstract: Fine-grained ship classification in remote sensing (RS-FGSC) poses a significant challenge due to the high similarity between classes and the limited availability of labeled data, limiting the effectiveness of traditional supervised classification methods. Recent advancements in large pre-trained Vision-Language Models (VLMs) have demonstrated impressive capabilities in few-shot or zero-shot learning, particularly in understanding image content. This study delves into harnessing the potential of VLMs to enhance classification accuracy for unseen ship categories, which holds considerable significance in scenarios with restricted data due to cost or privacy constraints. Directly fine-tuning VLMs for RS-FGSC often encounters the challenge of overfitting the seen classes, resulting in suboptimal generalization to unseen classes, which highlights the difficulty in differentiating complex backgrounds and capturing distinct ship features. To ",
    "link": "https://arxiv.org/abs/2403.08271",
    "context": "Title: Efficient Prompt Tuning of Large Vision-Language Model for Fine-Grained Ship Classification\nAbstract: arXiv:2403.08271v1 Announce Type: cross  Abstract: Fine-grained ship classification in remote sensing (RS-FGSC) poses a significant challenge due to the high similarity between classes and the limited availability of labeled data, limiting the effectiveness of traditional supervised classification methods. Recent advancements in large pre-trained Vision-Language Models (VLMs) have demonstrated impressive capabilities in few-shot or zero-shot learning, particularly in understanding image content. This study delves into harnessing the potential of VLMs to enhance classification accuracy for unseen ship categories, which holds considerable significance in scenarios with restricted data due to cost or privacy constraints. Directly fine-tuning VLMs for RS-FGSC often encounters the challenge of overfitting the seen classes, resulting in suboptimal generalization to unseen classes, which highlights the difficulty in differentiating complex backgrounds and capturing distinct ship features. To ",
    "path": "papers/24/03/2403.08271.json",
    "total_tokens": 832,
    "translated_title": "用于细粒度船舶分类的大规模视觉-语言模型的高效提示调整",
    "translated_abstract": "遥感中的细粒度船舶分类 (RS-FGSC) 由于类别之间的高相似性以及有限的标记数据可用性而面临重大挑战，限制了传统监督分类方法的有效性。最近大规模预训练的视觉-语言模型 (VLMs) 在少样本或零样本学习中展现出令人印象深刻的能力，特别是在理解图像内容方面。本研究深入挖掘了VLMs的潜力，以提高未见船舶类别的分类准确性，在由于成本或隐私限制而数据受限的情况下具有重要意义。直接为RS-FGSC微调VLMs通常会遇到过拟合可见类的挑战，导致对未见类的泛化不佳，突出了区分复杂背景和捕捉独特船舶特征的困难。",
    "tldr": "本研究使用大规模预训练的视觉-语言模型，提出了一种高效的提示调整方法，以增强未见船舶类别的分类准确性。",
    "en_tdlr": "This study proposes an efficient prompt tuning method using large pre-trained Vision-Language Models to enhance the classification accuracy of unseen ship categories."
}