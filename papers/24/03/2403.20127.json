{
    "title": "The Impact of Prompts on Zero-Shot Detection of AI-Generated Text",
    "abstract": "arXiv:2403.20127v1 Announce Type: new  Abstract: In recent years, there have been significant advancements in the development of Large Language Models (LLMs). While their practical applications are now widespread, their potential for misuse, such as generating fake news and committing plagiarism, has posed significant concerns. To address this issue, detectors have been developed to evaluate whether a given text is human-generated or AI-generated. Among others, zero-shot detectors stand out as effective approaches that do not require additional training data and are often likelihood-based. In chat-based applications, users commonly input prompts and utilize the AI-generated texts. However, zero-shot detectors typically analyze these texts in isolation, neglecting the impact of the original prompts. It is conceivable that this approach may lead to a discrepancy in likelihood assessments between the text generation phase and the detection phase. So far, there remains an unverified gap co",
    "link": "https://arxiv.org/abs/2403.20127",
    "context": "Title: The Impact of Prompts on Zero-Shot Detection of AI-Generated Text\nAbstract: arXiv:2403.20127v1 Announce Type: new  Abstract: In recent years, there have been significant advancements in the development of Large Language Models (LLMs). While their practical applications are now widespread, their potential for misuse, such as generating fake news and committing plagiarism, has posed significant concerns. To address this issue, detectors have been developed to evaluate whether a given text is human-generated or AI-generated. Among others, zero-shot detectors stand out as effective approaches that do not require additional training data and are often likelihood-based. In chat-based applications, users commonly input prompts and utilize the AI-generated texts. However, zero-shot detectors typically analyze these texts in isolation, neglecting the impact of the original prompts. It is conceivable that this approach may lead to a discrepancy in likelihood assessments between the text generation phase and the detection phase. So far, there remains an unverified gap co",
    "path": "papers/24/03/2403.20127.json",
    "total_tokens": 819,
    "translated_title": "提示对AI生成文本的零样本检测的影响",
    "translated_abstract": "近年来，大型语言模型（LLMs）的发展取得了显著进展。虽然它们的实际应用现在已经广泛，但其被滥用的潜力，例如生成假新闻和犯下剽窃行为，引起了重大关注。为解决这一问题，已经开发了检测器来评估给定文本是人类生成还是AI生成的能力。在许多方法中，零样本检测器是一种有效的方法，它们无需额外的训练数据，通常基于可能性。在基于聊天的应用程序中，用户通常输入提示并利用AI生成的文本。然而，零样本检测器通常独立分析这些文本，忽略了原始提示的影响。可以想象，这种方法可能导致文本生成阶段和检测阶段的可能性评估之间存在差异。到目前为止，仍然有一个未经验证的差距。",
    "tldr": "零样本检测器通常独立分析AI生成文本，而忽略了原始提示的影响，可能导致在可能性评估中存在差异",
    "en_tdlr": "Zero-shot detectors typically analyze AI-generated text independently without considering the impact of the original prompts, which may lead to discrepancies in likelihood assessments."
}