{
    "title": "The Implicit Bias of Heterogeneity towards Invariance and Causality",
    "abstract": "arXiv:2403.01420v1 Announce Type: new  Abstract: It is observed empirically that the large language models (LLM), trained with a variant of regression loss using numerous corpus from the Internet, can unveil causal associations to some extent. This is contrary to the traditional wisdom that ``association is not causation'' and the paradigm of traditional causal inference in which prior causal knowledge should be carefully incorporated into the design of methods. It is a mystery why causality, in a higher layer of understanding, can emerge from the regression task that pursues associations. In this paper, we claim the emergence of causality from association-oriented training can be attributed to the coupling effects from the heterogeneity of the source data, stochasticity of training algorithms, and over-parameterization of the learning models. We illustrate such an intuition using a simple but insightful model that learns invariance, a quasi-causality, using regression loss. To be spec",
    "link": "https://arxiv.org/abs/2403.01420",
    "context": "Title: The Implicit Bias of Heterogeneity towards Invariance and Causality\nAbstract: arXiv:2403.01420v1 Announce Type: new  Abstract: It is observed empirically that the large language models (LLM), trained with a variant of regression loss using numerous corpus from the Internet, can unveil causal associations to some extent. This is contrary to the traditional wisdom that ``association is not causation'' and the paradigm of traditional causal inference in which prior causal knowledge should be carefully incorporated into the design of methods. It is a mystery why causality, in a higher layer of understanding, can emerge from the regression task that pursues associations. In this paper, we claim the emergence of causality from association-oriented training can be attributed to the coupling effects from the heterogeneity of the source data, stochasticity of training algorithms, and over-parameterization of the learning models. We illustrate such an intuition using a simple but insightful model that learns invariance, a quasi-causality, using regression loss. To be spec",
    "path": "papers/24/03/2403.01420.json",
    "total_tokens": 828,
    "translated_title": "异质性对不变性和因果关系的隐性偏差",
    "translated_abstract": "从经验上观察到，使用来自互联网的大量语料库训练的大型语言模型（LLM），使用一种变体回归损失，可以在一定程度上揭示因果关联。这与传统智慧“关联不是因果”以及传统因果推断范式相反，传统因果推断范式认为先前的因果知识应谨慎地纳入到方法设计中。令人困惑的是，为何在追求关联的回归任务中能够从更高层次的理解中出现因果性。本文声称从面向关联的训练中出现因果性可以归因于源数据的异质性、训练算法的随机性和学习模型的超参数化的耦合效应。我们使用一个简单但有见地的模型来阐释这样的直觉，该模型使用回归损失学习不变性，一种准因果关系。",
    "tldr": "异质性对于回归任务中出现因果性的贡献解释了为何大型语言模型能够从关联性训练中揭示因果关联。"
}