{
    "title": "An Improved Algorithm for Learning Drifting Discrete Distributions",
    "abstract": "arXiv:2403.05446v1 Announce Type: new  Abstract: We present a new adaptive algorithm for learning discrete distributions under distribution drift. In this setting, we observe a sequence of independent samples from a discrete distribution that is changing over time, and the goal is to estimate the current distribution. Since we have access to only a single sample for each time step, a good estimation requires a careful choice of the number of past samples to use. To use more samples, we must resort to samples further in the past, and we incur a drift error due to the bias introduced by the change in distribution. On the other hand, if we use a small number of past samples, we incur a large statistical error as the estimation has a high variance. We present a novel adaptive algorithm that can solve this trade-off without any prior knowledge of the drift. Unlike previous adaptive results, our algorithm characterizes the statistical error using data-dependent bounds. This technicality enab",
    "link": "https://arxiv.org/abs/2403.05446",
    "context": "Title: An Improved Algorithm for Learning Drifting Discrete Distributions\nAbstract: arXiv:2403.05446v1 Announce Type: new  Abstract: We present a new adaptive algorithm for learning discrete distributions under distribution drift. In this setting, we observe a sequence of independent samples from a discrete distribution that is changing over time, and the goal is to estimate the current distribution. Since we have access to only a single sample for each time step, a good estimation requires a careful choice of the number of past samples to use. To use more samples, we must resort to samples further in the past, and we incur a drift error due to the bias introduced by the change in distribution. On the other hand, if we use a small number of past samples, we incur a large statistical error as the estimation has a high variance. We present a novel adaptive algorithm that can solve this trade-off without any prior knowledge of the drift. Unlike previous adaptive results, our algorithm characterizes the statistical error using data-dependent bounds. This technicality enab",
    "path": "papers/24/03/2403.05446.json",
    "total_tokens": 858,
    "translated_title": "一种用于学习漂移离散分布的改进算法",
    "translated_abstract": "我们提出了一种新的自适应算法，用于在分布漂移情况下学习离散分布。在这种情况下，我们观察来自一个随时间变化的离散分布的独立样本序列，目标是估计当前分布。由于我们每个时间步只能访问一个样本，一个良好的估计需要谨慎选择要使用的过去样本的数量。为了使用更多样本，我们必须诉诸更早的样本，这会因为分布变化引入的偏差而产生漂移误差。另一方面，如果我们使用较少的过去样本，估计会有较高的方差，导致较大的统计误差。我们提出了一种新颖的自适应算法，可以解决这种权衡，而无需任何漂移的先验知识。与以前的自适应结果不同，我们的算法使用基于数据的界来表征统计误差。",
    "tldr": "提出了一种可以在分布漂移情况下学习离散分布的自适应算法，能够解决过去样本数量选择的权衡问题，并利用数据相关的界来表征统计误差。"
}