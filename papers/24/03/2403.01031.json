{
    "title": "Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks",
    "abstract": "arXiv:2403.01031v1 Announce Type: cross  Abstract: Multimodal large language models (MLLMs) have proven effective in a wide range of tasks requiring complex reasoning and linguistic comprehension. However, due to a lack of high-quality multimodal resources in languages other than English, success of MLLMs remains relatively limited to English-based settings. This poses significant challenges in developing comparable models for other languages, including even those with large speaker populations such as Arabic. To alleviate this challenge, we introduce a comprehensive family of Arabic MLLMs, dubbed \\textit{Peacock}, with strong vision and language capabilities. Through comprehensive qualitative and quantitative analysis, we demonstrate the solid performance of our models on various visual reasoning tasks and further show their emerging dialectal potential. Additionally, we introduce ~\\textit{Henna}, a new benchmark specifically designed for assessing MLLMs on aspects related to Arabic c",
    "link": "https://arxiv.org/abs/2403.01031",
    "context": "Title: Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks\nAbstract: arXiv:2403.01031v1 Announce Type: cross  Abstract: Multimodal large language models (MLLMs) have proven effective in a wide range of tasks requiring complex reasoning and linguistic comprehension. However, due to a lack of high-quality multimodal resources in languages other than English, success of MLLMs remains relatively limited to English-based settings. This poses significant challenges in developing comparable models for other languages, including even those with large speaker populations such as Arabic. To alleviate this challenge, we introduce a comprehensive family of Arabic MLLMs, dubbed \\textit{Peacock}, with strong vision and language capabilities. Through comprehensive qualitative and quantitative analysis, we demonstrate the solid performance of our models on various visual reasoning tasks and further show their emerging dialectal potential. Additionally, we introduce ~\\textit{Henna}, a new benchmark specifically designed for assessing MLLMs on aspects related to Arabic c",
    "path": "papers/24/03/2403.01031.json",
    "total_tokens": 895,
    "translated_title": "孔雀：一系列阿拉伯多模式大语言模型及基准",
    "translated_abstract": "多模式大语言模型（MLLMs）在需要复杂推理和语言理解的各种任务中已被证明有效。然而，由于除英语以外的其他语言缺乏高质量的多模式资源，MLLMs的成功仍然相对局限于英语环境。这给开发其他语言的可比较模型带来了重大挑战，甚至包括那些拥有庞大说话人口的语言，如阿拉伯语。为了缓解这一挑战，我们引入了一套综合的阿拉伯MLLMs系列，称为\\textit{Peacock}，具有强大的视觉和语言能力。通过全面的定性和定量分析，我们展示了我们的模型在各种视觉推理任务上的出色性能，并进一步展示了它们不断出现的方言潜力。此外，我们还介绍了一个名为\\textit{Henna}的新基准，专门用于评估MLLM在与阿拉伯语相关的方面。",
    "tldr": "介绍了一系列阿拉伯多模式大语言模型Peacock，展示了其在视觉推理任务上的出色性能和不断出现的方言潜力，并提出了一个用于评估阿拉伯语相关方面的新基准Henna",
    "en_tdlr": "Introducing a family of Arabic multimodal large language models called Peacock, showcasing their excellent performance on visual reasoning tasks and emerging dialectal potential, along with the introduction of a new benchmark named Henna for evaluating aspects related to Arabic."
}