{
    "title": "Distributionally Generative Augmentation for Fair Facial Attribute Classification",
    "abstract": "arXiv:2403.06606v1 Announce Type: cross  Abstract: Facial Attribute Classification (FAC) holds substantial promise in widespread applications. However, FAC models trained by traditional methodologies can be unfair by exhibiting accuracy inconsistencies across varied data subpopulations. This unfairness is largely attributed to bias in data, where some spurious attributes (e.g., Male) statistically correlate with the target attribute (e.g., Smiling). Most of existing fairness-aware methods rely on the labels of spurious attributes, which may be unavailable in practice. This work proposes a novel, generation-based two-stage framework to train a fair FAC model on biased data without additional annotation. Initially, we identify the potential spurious attributes based on generative models. Notably, it enhances interpretability by explicitly showing the spurious attributes in image space. Following this, for each image, we first edit the spurious attributes with a random degree sampled from",
    "link": "https://arxiv.org/abs/2403.06606",
    "context": "Title: Distributionally Generative Augmentation for Fair Facial Attribute Classification\nAbstract: arXiv:2403.06606v1 Announce Type: cross  Abstract: Facial Attribute Classification (FAC) holds substantial promise in widespread applications. However, FAC models trained by traditional methodologies can be unfair by exhibiting accuracy inconsistencies across varied data subpopulations. This unfairness is largely attributed to bias in data, where some spurious attributes (e.g., Male) statistically correlate with the target attribute (e.g., Smiling). Most of existing fairness-aware methods rely on the labels of spurious attributes, which may be unavailable in practice. This work proposes a novel, generation-based two-stage framework to train a fair FAC model on biased data without additional annotation. Initially, we identify the potential spurious attributes based on generative models. Notably, it enhances interpretability by explicitly showing the spurious attributes in image space. Following this, for each image, we first edit the spurious attributes with a random degree sampled from",
    "path": "papers/24/03/2403.06606.json",
    "total_tokens": 889,
    "translated_title": "分布生成增强公平面部属性分类",
    "translated_abstract": "面部属性分类（FAC）在广泛的应用中具有重要的潜力。然而，传统方法训练的FAC模型可能存在不公平性，因为在不同的数据子群体中展示准确性不一致。这种不公平性主要归因于数据中的偏见，其中一些虚假属性（例如，男性）在统计上与目标属性（例如，微笑）相关。大多数现有的注重公平性的方法依赖于虚假属性的标签，但这在实践中可能无法获得。本文提出了一种新颖的基于生成的两阶段框架，用于在带有偏见的数据上训练公平的FAC模型，而无需额外注释。首先，我们基于生成模型识别潜在的虚假属性。值得注意的是，通过明确展示图像空间中的虚假属性，它增强了可解释性。随后，对于每个图像，我们首先编辑虚假属性，随机抽样一定程度，",
    "tldr": "该论文提出了一种新颖的分布生成增强方法，用于在偏见数据上训练公平的面部属性分类模型，无需额外标注虚假属性，通过生成模型识别潜在的虚假属性，并在图像空间中显示，以提高模型可解释性。",
    "en_tdlr": "This paper presents a novel distributionally generative augmentation method for training fair facial attribute classification models on biased data without additional annotation, identifying potential spurious attributes through generative models and showing them in image space to enhance interpretability."
}