{
    "title": "Improving Sequence-to-Sequence Models for Abstractive Text Summarization Using Meta Heuristic Approaches",
    "abstract": "arXiv:2403.16247v1 Announce Type: new  Abstract: As human society transitions into the information age, reduction in our attention span is a contingency, and people who spend time reading lengthy news articles are decreasing rapidly and the need for succinct information is higher than ever before. Therefore, it is essential to provide a quick overview of important news by concisely summarizing the top news article and the most intuitive headline. When humans try to make summaries, they extract the essential information from the source and add useful phrases and grammatical annotations from the original extract. Humans have a unique ability to create abstractions. However, automatic summarization is a complicated problem to solve. The use of sequence-to-sequence (seq2seq) models for neural abstractive text summarization has been ascending as far as prevalence. Numerous innovative strategies have been proposed to develop the current seq2seq models further, permitting them to handle diffe",
    "link": "https://arxiv.org/abs/2403.16247",
    "context": "Title: Improving Sequence-to-Sequence Models for Abstractive Text Summarization Using Meta Heuristic Approaches\nAbstract: arXiv:2403.16247v1 Announce Type: new  Abstract: As human society transitions into the information age, reduction in our attention span is a contingency, and people who spend time reading lengthy news articles are decreasing rapidly and the need for succinct information is higher than ever before. Therefore, it is essential to provide a quick overview of important news by concisely summarizing the top news article and the most intuitive headline. When humans try to make summaries, they extract the essential information from the source and add useful phrases and grammatical annotations from the original extract. Humans have a unique ability to create abstractions. However, automatic summarization is a complicated problem to solve. The use of sequence-to-sequence (seq2seq) models for neural abstractive text summarization has been ascending as far as prevalence. Numerous innovative strategies have been proposed to develop the current seq2seq models further, permitting them to handle diffe",
    "path": "papers/24/03/2403.16247.json",
    "total_tokens": 806,
    "translated_title": "使用元启发方法改进序列到序列模型，用于抽象文本摘要",
    "translated_abstract": "随着人类社会过渡到信息时代，我们注意力的减少是一个必然趋势，花时间阅读冗长新闻文章的人群正在迅速减少，而对简洁信息的需求比以往任何时候都更高。因此，通过简洁地总结顶级新闻文章和最直观的标题，提供重要新闻的快速概述是至关重要的。人类在尝试进行摘要时，会从来源中提取基本信息，并从原始提取中添加有用短语和语法注释。人类有创建抽象的独特能力。然而，自动摘要是一个复杂的问题。对于神经抽象文本摘要，使用序列到序列（seq2seq）模型的应用程度不断增加。已经提出了许多创新策略来进一步发展当前的seq2seq模型，使其能够处理差异",
    "tldr": "改进使用元启发方法的序列到序列模型，以提高抽象文本摘要的准确性和有效性",
    "en_tdlr": "Improving sequence-to-sequence models with meta heuristic approaches to enhance the accuracy and effectiveness of abstractive text summarization."
}