{
    "title": "Attention-aware semantic relevance predicting Chinese sentence reading",
    "abstract": "arXiv:2403.18542v1 Announce Type: new  Abstract: In recent years, several influential computational models and metrics have been proposed to predict how humans comprehend and process sentence. One particularly promising approach is contextual semantic similarity. Inspired by the attention algorithm in Transformer and human memory mechanisms, this study proposes an ``attention-aware'' approach for computing contextual semantic relevance. This new approach takes into account the different contributions of contextual parts and the expectation effect, allowing it to incorporate contextual information fully. The attention-aware approach also facilitates the simulation of existing reading models and evaluate them. The resulting ``attention-aware'' metrics of semantic relevance can more accurately predict fixation durations in Chinese reading tasks recorded in an eye-tracking corpus than those calculated by existing approaches. The study's findings further provide strong support for the prese",
    "link": "https://arxiv.org/abs/2403.18542",
    "context": "Title: Attention-aware semantic relevance predicting Chinese sentence reading\nAbstract: arXiv:2403.18542v1 Announce Type: new  Abstract: In recent years, several influential computational models and metrics have been proposed to predict how humans comprehend and process sentence. One particularly promising approach is contextual semantic similarity. Inspired by the attention algorithm in Transformer and human memory mechanisms, this study proposes an ``attention-aware'' approach for computing contextual semantic relevance. This new approach takes into account the different contributions of contextual parts and the expectation effect, allowing it to incorporate contextual information fully. The attention-aware approach also facilitates the simulation of existing reading models and evaluate them. The resulting ``attention-aware'' metrics of semantic relevance can more accurately predict fixation durations in Chinese reading tasks recorded in an eye-tracking corpus than those calculated by existing approaches. The study's findings further provide strong support for the prese",
    "path": "papers/24/03/2403.18542.json",
    "total_tokens": 748,
    "translated_title": "关注语境语义相关性预测中文句子阅读",
    "translated_abstract": "近年来，已经提出了几种有影响力的计算模型和度量标准，用于预测人类如何理解和处理句子。本研究受Transformer中的注意力算法和人类记忆机制启发，提出了一种“关注语境”的方法来计算语境语义相关性。这种新方法考虑了语境部分的不同贡献和期望效应，使其能够充分整合语境信息。关注语境方法还有助于模拟现有的阅读模型并对其进行评估。最终得到的“关注语境”语义相关性度量标准比现有方法更准确地预测了记录在眼动追踪语料库中的中文阅读任务中凝视持续时间。该研究的发现进一步为现有的研究提供了有力支持。",
    "tldr": "提出了一种基于“关注语境”的方法，可以更准确地预测中文阅读任务中的凝视持续时间。",
    "en_tdlr": "Proposed an \"attention-aware\" approach that can more accurately predict fixation durations in Chinese reading tasks."
}