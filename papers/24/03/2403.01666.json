{
    "title": "Improving Adversarial Energy-Based Model via Diffusion Process",
    "abstract": "arXiv:2403.01666v1 Announce Type: new  Abstract: Generative models have shown strong generation ability while efficient likelihood estimation is less explored. Energy-based models~(EBMs) define a flexible energy function to parameterize unnormalized densities efficiently but are notorious for being difficult to train. Adversarial EBMs introduce a generator to form a minimax training game to avoid expensive MCMC sampling used in traditional EBMs, but a noticeable gap between adversarial EBMs and other strong generative models still exists. Inspired by diffusion-based models, we embedded EBMs into each denoising step to split a long-generated process into several smaller steps. Besides, we employ a symmetric Jeffrey divergence and introduce a variational posterior distribution for the generator's training to address the main challenges that exist in adversarial EBMs. Our experiments show significant improvement in generation compared to existing adversarial EBMs, while also providing a u",
    "link": "https://arxiv.org/abs/2403.01666",
    "context": "Title: Improving Adversarial Energy-Based Model via Diffusion Process\nAbstract: arXiv:2403.01666v1 Announce Type: new  Abstract: Generative models have shown strong generation ability while efficient likelihood estimation is less explored. Energy-based models~(EBMs) define a flexible energy function to parameterize unnormalized densities efficiently but are notorious for being difficult to train. Adversarial EBMs introduce a generator to form a minimax training game to avoid expensive MCMC sampling used in traditional EBMs, but a noticeable gap between adversarial EBMs and other strong generative models still exists. Inspired by diffusion-based models, we embedded EBMs into each denoising step to split a long-generated process into several smaller steps. Besides, we employ a symmetric Jeffrey divergence and introduce a variational posterior distribution for the generator's training to address the main challenges that exist in adversarial EBMs. Our experiments show significant improvement in generation compared to existing adversarial EBMs, while also providing a u",
    "path": "papers/24/03/2403.01666.json",
    "total_tokens": 839,
    "translated_title": "通过扩散过程改进对抗能量模型",
    "translated_abstract": "生成模型展示了强大的生成能力，而高效的似然度估计却鲜为人知。基于能量的模型（EBMs）定义了一个灵活的能量函数，以有效地参数化未标准化的密度，但训练难度很大。对抗性的EBMs引入了一个生成器形成一个极小极大训练游戏，以避免传统EBMs中使用昂贵的MCMC采样，但对抗性的EBMs与其他强大的生成模型之间仍然存在明显差距。受扩散模型的启发，我们将EBMs嵌入到每个去噪步骤中，将一个长生成过程分成几个较小的步骤。此外，我们使用对称的Jeffrey散度并引入一个变分后验分布来训练生成器，以解决对抗性EBMs中存在的主要挑战。我们的实验结果显示，与现有的对抗性EBMs相比，在生成方面取得了显著的改进，同时提供了一个u",
    "tldr": "通过将EBMs嵌入到扩散步骤中并引入变分后验分布，有效改进了对抗性能量模型的生成能力。",
    "en_tdlr": "The generation ability of adversarial energy-based models has been significantly improved by embedding EBMs into diffusion steps and introducing a variational posterior distribution."
}