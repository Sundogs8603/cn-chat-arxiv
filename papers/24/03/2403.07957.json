{
    "title": "Efficient Post-Training Augmentation for Adaptive Inference in Heterogeneous and Distributed IoT Environments",
    "abstract": "arXiv:2403.07957v1 Announce Type: cross  Abstract: Early Exit Neural Networks (EENNs) present a solution to enhance the efficiency of neural network deployments. However, creating EENNs is challenging and requires specialized domain knowledge, due to the large amount of additional design choices. To address this issue, we propose an automated augmentation flow that focuses on converting an existing model into an EENN. It performs all required design decisions for the deployment to heterogeneous or distributed hardware targets: Our framework constructs the EENN architecture, maps its subgraphs to the hardware targets, and configures its decision mechanism. To the best of our knowledge, it is the first framework that is able to perform all of these steps.   We evaluated our approach on a collection of Internet-of-Things and standard image classification use cases. For a speech command detection task, our solution was able to reduce the mean operations per inference by 59.67%. For an ECG ",
    "link": "https://arxiv.org/abs/2403.07957",
    "context": "Title: Efficient Post-Training Augmentation for Adaptive Inference in Heterogeneous and Distributed IoT Environments\nAbstract: arXiv:2403.07957v1 Announce Type: cross  Abstract: Early Exit Neural Networks (EENNs) present a solution to enhance the efficiency of neural network deployments. However, creating EENNs is challenging and requires specialized domain knowledge, due to the large amount of additional design choices. To address this issue, we propose an automated augmentation flow that focuses on converting an existing model into an EENN. It performs all required design decisions for the deployment to heterogeneous or distributed hardware targets: Our framework constructs the EENN architecture, maps its subgraphs to the hardware targets, and configures its decision mechanism. To the best of our knowledge, it is the first framework that is able to perform all of these steps.   We evaluated our approach on a collection of Internet-of-Things and standard image classification use cases. For a speech command detection task, our solution was able to reduce the mean operations per inference by 59.67%. For an ECG ",
    "path": "papers/24/03/2403.07957.json",
    "total_tokens": 878,
    "translated_title": "高效的后训练增强方法用于异构和分布式物联网环境中的自适应推断",
    "translated_abstract": "早期退出神经网络（EENN）提出了一种增强神经网络部署效率的解决方案。然而，创建EENN具有挑战性，并且需要专业领域知识，由于大量额外的设计选择。为了解决这个问题，我们提出了一种自动增强流程，专注于将现有模型转换为EENN。它执行了部署到异构或分布式硬件目标所需的所有设计决策：我们的框架构建了EENN架构，将其子图映射到硬件目标，并配置了其决策机制。据我们所知，这是第一个能够执行所有这些步骤的框架。我们在一系列物联网和标准图像分类用例上评估了我们的方法。对于语音命令检测任务，我们的解决方案能够将每次推断的平均操作减少了59.67%。",
    "tldr": "提出了一种自动增强流程，能够将现有模型转换为早期退出神经网络（EENN），提高神经网络部署效率，实现了在物联网和图像分类用例上显著减少推断操作的效果。",
    "en_tdlr": "Proposed an automated augmentation flow to convert an existing model into Early Exit Neural Networks (EENNs) for enhanced efficiency of neural network deployments, achieving a significant reduction in inference operations in IoT and image classification use cases."
}