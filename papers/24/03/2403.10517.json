{
    "title": "VideoAgent: Long-form Video Understanding with Large Language Model as Agent",
    "abstract": "arXiv:2403.10517v1 Announce Type: cross  Abstract: Long-form video understanding represents a significant challenge within computer vision, demanding a model capable of reasoning over long multi-modal sequences. Motivated by the human cognitive process for long-form video understanding, we emphasize interactive reasoning and planning over the ability to process lengthy visual inputs. We introduce a novel agent-based system, VideoAgent, that employs a large language model as a central agent to iteratively identify and compile crucial information to answer a question, with vision-language foundation models serving as tools to translate and retrieve visual information. Evaluated on the challenging EgoSchema and NExT-QA benchmarks, VideoAgent achieves 54.1% and 71.3% zero-shot accuracy with only 8.4 and 8.2 frames used on average. These results demonstrate superior effectiveness and efficiency of our method over the current state-of-the-art methods, highlighting the potential of agent-base",
    "link": "https://arxiv.org/abs/2403.10517",
    "context": "Title: VideoAgent: Long-form Video Understanding with Large Language Model as Agent\nAbstract: arXiv:2403.10517v1 Announce Type: cross  Abstract: Long-form video understanding represents a significant challenge within computer vision, demanding a model capable of reasoning over long multi-modal sequences. Motivated by the human cognitive process for long-form video understanding, we emphasize interactive reasoning and planning over the ability to process lengthy visual inputs. We introduce a novel agent-based system, VideoAgent, that employs a large language model as a central agent to iteratively identify and compile crucial information to answer a question, with vision-language foundation models serving as tools to translate and retrieve visual information. Evaluated on the challenging EgoSchema and NExT-QA benchmarks, VideoAgent achieves 54.1% and 71.3% zero-shot accuracy with only 8.4 and 8.2 frames used on average. These results demonstrate superior effectiveness and efficiency of our method over the current state-of-the-art methods, highlighting the potential of agent-base",
    "path": "papers/24/03/2403.10517.json",
    "total_tokens": 858,
    "translated_title": "基于大型语言模型的视频代理：长视频理解",
    "translated_abstract": "长视频理解在计算机视觉中代表着一个重大挑战，需要一个能够推理长时间多模态序列的模型。受人类认知长视频过程的启发，我们强调互动推理和计划，而不是处理长篇视觉输入的能力。我们引入了一个新颖的基于代理的系统VideoAgent，它采用大型语言模型作为中央代理，迭代地识别和整理关键信息以回答问题，视觉语言基础模型作为工具来翻译和检索视觉信息。在具有挑战性的EgoSchema和NExT-QA基准测试中，VideoAgent在平均仅使用8.4和8.2帧的情况下分别实现了54.1%和71.3%的零-shot准确率。这些结果展示了我们方法相对于当前最先进方法的卓越效果和效率，突出了代理模型的潜力。",
    "tldr": "提出了一种新颖的基于代理的系统VideoAgent，利用大型语言模型作为中央代理，采用互动推理和计划来处理长视频理解问题，在挑战性基准测试中表现出卓越的效果和效率。",
    "en_tdlr": "Introduced a novel agent-based system VideoAgent that utilizes a large language model as the central agent for interactive reasoning and planning in long-form video understanding, achieving superior effectiveness and efficiency in challenging benchmarks."
}