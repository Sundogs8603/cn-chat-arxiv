{
    "title": "Birbal: An efficient 7B instruct-model fine-tuned with curated datasets",
    "abstract": "arXiv:2403.02247v1 Announce Type: new  Abstract: LLMOps incur significant costs due to hardware requirements, hindering their widespread accessibility. Additionally, a lack of transparency in model training methods and data contributes to the majority of models being non-reproducible. To tackle these challenges, the LLM Efficiency Challenge was introduced at NeurIPS Workshop, aiming to adapt foundation models on a diverse set of tasks via fine-tuning on a single GPU (RTX 4090 or A100 with 40GB) within a 24-hour timeframe. In this system description paper, we introduce Birbal, our Mistral-7B based winning model, fine-tuned on a single RTX 4090 for 16 hours. Birbal's success lies in curating high-quality instructions covering diverse tasks, resulting in a 35% performance improvement over second-best Qwen-14B based submission.",
    "link": "https://arxiv.org/abs/2403.02247",
    "context": "Title: Birbal: An efficient 7B instruct-model fine-tuned with curated datasets\nAbstract: arXiv:2403.02247v1 Announce Type: new  Abstract: LLMOps incur significant costs due to hardware requirements, hindering their widespread accessibility. Additionally, a lack of transparency in model training methods and data contributes to the majority of models being non-reproducible. To tackle these challenges, the LLM Efficiency Challenge was introduced at NeurIPS Workshop, aiming to adapt foundation models on a diverse set of tasks via fine-tuning on a single GPU (RTX 4090 or A100 with 40GB) within a 24-hour timeframe. In this system description paper, we introduce Birbal, our Mistral-7B based winning model, fine-tuned on a single RTX 4090 for 16 hours. Birbal's success lies in curating high-quality instructions covering diverse tasks, resulting in a 35% performance improvement over second-best Qwen-14B based submission.",
    "path": "papers/24/03/2403.02247.json",
    "total_tokens": 804,
    "translated_title": "Birbal: 一种使用精心策划的数据集进行微调的高效7B指令模型",
    "translated_abstract": "LLMOps由于硬件需求而产生重大成本，限制了它们的广泛可及性。此外，模型训练方法和数据缺乏透明度导致大多数模型无法重现。为了解决这些挑战，NeurIPS Workshop推出了LLM Efficiency Challenge，旨在通过在单个GPU（RTX 4090或带有40GB的A100）上在24小时内进行微调以适应各种任务。在这篇系统描述论文中，我们介绍了Birbal，我们基于Mistral-7B模型进行微调的获胜模型，微调时间为16小时。Birbal的成功在于整理了覆盖各种任务的高质量指令，使其性能比第二名Qwen-14B基于提交的性能提高了35%。",
    "tldr": "Birbal是一个基于Mistral-7B模型的高效模型，通过在单个RTX 4090上进行16小时微调，成功地整理了高质量指令，使性能提高了35%。"
}