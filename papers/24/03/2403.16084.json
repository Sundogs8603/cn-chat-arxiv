{
    "title": "Argument Quality Assessment in the Age of Instruction-Following Large Language Models",
    "abstract": "arXiv:2403.16084v1 Announce Type: new  Abstract: The computational treatment of arguments on controversial issues has been subject to extensive NLP research, due to its envisioned impact on opinion formation, decision making, writing education, and the like. A critical task in any such application is the assessment of an argument's quality - but it is also particularly challenging. In this position paper, we start from a brief survey of argument quality research, where we identify the diversity of quality notions and the subjectiveness of their perception as the main hurdles towards substantial progress on argument quality assessment. We argue that the capabilities of instruction-following large language models (LLMs) to leverage knowledge across contexts enable a much more reliable assessment. Rather than just fine-tuning LLMs towards leaderboard chasing on assessment tasks, they need to be instructed systematically with argumentation theories and scenarios as well as with ways to sol",
    "link": "https://arxiv.org/abs/2403.16084",
    "context": "Title: Argument Quality Assessment in the Age of Instruction-Following Large Language Models\nAbstract: arXiv:2403.16084v1 Announce Type: new  Abstract: The computational treatment of arguments on controversial issues has been subject to extensive NLP research, due to its envisioned impact on opinion formation, decision making, writing education, and the like. A critical task in any such application is the assessment of an argument's quality - but it is also particularly challenging. In this position paper, we start from a brief survey of argument quality research, where we identify the diversity of quality notions and the subjectiveness of their perception as the main hurdles towards substantial progress on argument quality assessment. We argue that the capabilities of instruction-following large language models (LLMs) to leverage knowledge across contexts enable a much more reliable assessment. Rather than just fine-tuning LLMs towards leaderboard chasing on assessment tasks, they need to be instructed systematically with argumentation theories and scenarios as well as with ways to sol",
    "path": "papers/24/03/2403.16084.json",
    "total_tokens": 809,
    "translated_title": "在指导式大型语言模型时代的论证质量评估",
    "translated_abstract": "争议问题上的论证在NLP研究中受到广泛关注，由于其对观点形成、决策制定、写作教育等方面的潜在影响。在任何此类应用中，一个关键任务是评估论证的质量，但这也是一个特别具有挑战性的任务。本文从对论证质量研究的简要调查开始，我们确定质量概念的多样性和其感知的主观性是实现论证质量评估实质性进展的主要障碍。我们认为，指导式大型语言模型（LLMs）利用跨上下文的知识能力，能够实现更可靠的评估。它们不仅需要将LLMs微调为评估任务的领先者，还需要系统地用论证理论和情景以及解决问题的方式对其进行指导。",
    "tldr": "论文讨论了在指导式大型语言模型时代，如何通过引入论证理论和情景，使其能够更可靠地评估争议问题中的论证质量。",
    "en_tdlr": "The paper discusses how to introduce argumentation theories and scenarios to guide instruction-following large language models towards more reliable assessment of argument quality in the era of large language models."
}