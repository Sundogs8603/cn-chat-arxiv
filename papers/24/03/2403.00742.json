{
    "title": "Dialect prejudice predicts AI decisions about people's character, employability, and criminality",
    "abstract": "arXiv:2403.00742v1 Announce Type: cross  Abstract: Hundreds of millions of people now interact with language models, with uses ranging from serving as a writing aid to informing hiring decisions. Yet these language models are known to perpetuate systematic racial prejudices, making their judgments biased in problematic ways about groups like African Americans. While prior research has focused on overt racism in language models, social scientists have argued that racism with a more subtle character has developed over time. It is unknown whether this covert racism manifests in language models. Here, we demonstrate that language models embody covert racism in the form of dialect prejudice: we extend research showing that Americans hold raciolinguistic stereotypes about speakers of African American English and find that language models have the same prejudice, exhibiting covert stereotypes that are more negative than any human stereotypes about African Americans ever experimentally recorde",
    "link": "https://arxiv.org/abs/2403.00742",
    "context": "Title: Dialect prejudice predicts AI decisions about people's character, employability, and criminality\nAbstract: arXiv:2403.00742v1 Announce Type: cross  Abstract: Hundreds of millions of people now interact with language models, with uses ranging from serving as a writing aid to informing hiring decisions. Yet these language models are known to perpetuate systematic racial prejudices, making their judgments biased in problematic ways about groups like African Americans. While prior research has focused on overt racism in language models, social scientists have argued that racism with a more subtle character has developed over time. It is unknown whether this covert racism manifests in language models. Here, we demonstrate that language models embody covert racism in the form of dialect prejudice: we extend research showing that Americans hold raciolinguistic stereotypes about speakers of African American English and find that language models have the same prejudice, exhibiting covert stereotypes that are more negative than any human stereotypes about African Americans ever experimentally recorde",
    "path": "papers/24/03/2403.00742.json",
    "total_tokens": 757,
    "translated_title": "方言偏见预测人工智能对人物性格、就业能力和犯罪倾向的决策",
    "translated_abstract": "数亿人现在与语言模型互动，其用途从作为写作辅助到影响招聘决策。然而，已知这些语言模型会传播系统性种族偏见，使它们对像非洲裔美国人这样的群体做出有问题的偏见判断。本文展示了语言模型体现了一种潜在的种族文化偏见，即方言偏见：我们扩展了关于美国人对非裔美国英语说话者持有种族语言刻板印象的研究，并发现语言模型也有同样的偏见，表现出潜在的刻板印象，这种刻板印象比实验中记录的任何人类关于非裔美国人的刻板印象都更为负面。",
    "tldr": "语言模型对非裔美国英语说话者持有负面的潜在刻板印象，展现了方言偏见。",
    "en_tdlr": "Language models exhibit negative covert stereotypes towards African American English speakers, demonstrating dialect prejudice."
}