{
    "title": "Measuring Bias in a Ranked List using Term-based Representations",
    "abstract": "arXiv:2403.05975v1 Announce Type: new  Abstract: In most recent studies, gender bias in document ranking is evaluated with the NFaiRR metric, which measures bias in a ranked list based on an aggregation over the unbiasedness scores of each ranked document. This perspective in measuring the bias of a ranked list has a key limitation: individual documents of a ranked list might be biased while the ranked list as a whole balances the groups' representations. To address this issue, we propose a novel metric called TExFAIR (term exposure-based fairness), which is based on two new extensions to a generic fairness evaluation framework, attention-weighted ranking fairness (AWRF). TExFAIR assesses fairness based on the term-based representation of groups in a ranked list: (i) an explicit definition of associating documents to groups based on probabilistic term-level associations, and (ii) a rank-biased discounting factor (RBDF) for counting non-representative documents towards the measurement o",
    "link": "https://arxiv.org/abs/2403.05975",
    "context": "Title: Measuring Bias in a Ranked List using Term-based Representations\nAbstract: arXiv:2403.05975v1 Announce Type: new  Abstract: In most recent studies, gender bias in document ranking is evaluated with the NFaiRR metric, which measures bias in a ranked list based on an aggregation over the unbiasedness scores of each ranked document. This perspective in measuring the bias of a ranked list has a key limitation: individual documents of a ranked list might be biased while the ranked list as a whole balances the groups' representations. To address this issue, we propose a novel metric called TExFAIR (term exposure-based fairness), which is based on two new extensions to a generic fairness evaluation framework, attention-weighted ranking fairness (AWRF). TExFAIR assesses fairness based on the term-based representation of groups in a ranked list: (i) an explicit definition of associating documents to groups based on probabilistic term-level associations, and (ii) a rank-biased discounting factor (RBDF) for counting non-representative documents towards the measurement o",
    "path": "papers/24/03/2403.05975.json",
    "total_tokens": 890,
    "translated_title": "使用基于术语表示的方法评估排名列表中的偏见",
    "translated_abstract": "在最近的研究中，性别偏见在文档排名中使用NFaiRR指标进行评估，该指标根据每个排名文档的无偏分数的聚合来衡量排名列表中的偏见。然而，这种衡量排名列表偏见的观点存在一个重要局限性：排名列表中的个别文档可能存在偏见，而整个排名列表却能平衡各个群体的表示。为了解决这个问题，我们提出了一种称为TExFAIR（基于术语曝光的公平性）的新指标，它基于通用公平性评估框架——注意力加权排名公平性（AWRF）的两个新扩展。TExFAIR根据排名列表中群体的基于术语的表示来评估公平性：（i）通过基于概率术语级关联来明确地将文档与群体关联起来的定义，以及（ii）用于计算对衡量产生偏差的因素的排名偏差折扣因子（RBDF）。",
    "tldr": "本文提出了一种新的指标TExFAIR，基于术语表示群体在排名列表中的公平性，通过两个新的扩展来解决现有偏见度量方法的局限性。",
    "en_tdlr": "This paper introduces a novel metric TExFAIR, which assesses fairness in a ranked list based on the term-based representation of groups, addressing the limitations of current bias measurement methods with two new extensions."
}