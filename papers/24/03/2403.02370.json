{
    "title": "adaptMLLM: Fine-Tuning Multilingual Language Models on Low-Resource Languages with Integrated LLM Playgrounds",
    "abstract": "arXiv:2403.02370v1 Announce Type: cross  Abstract: The advent of Multilingual Language Models (MLLMs) and Large Language Models has spawned innovation in many areas of natural language processing. Despite the exciting potential of this technology, its impact on developing high-quality Machine Translation (MT) outputs for low-resource languages remains relatively under-explored. Furthermore, an open-source application, dedicated to both fine-tuning MLLMs and managing the complete MT workflow for low-resources languages, remains unavailable. We aim to address these imbalances through the development of adaptMLLM, which streamlines all processes involved in the fine-tuning of MLLMs for MT. This open-source application is tailored for developers, translators, and users who are engaged in MT. An intuitive interface allows for easy customisation of hyperparameters, and the application offers a range of metrics for model evaluation and the capability to deploy models as a translation service ",
    "link": "https://arxiv.org/abs/2403.02370",
    "context": "Title: adaptMLLM: Fine-Tuning Multilingual Language Models on Low-Resource Languages with Integrated LLM Playgrounds\nAbstract: arXiv:2403.02370v1 Announce Type: cross  Abstract: The advent of Multilingual Language Models (MLLMs) and Large Language Models has spawned innovation in many areas of natural language processing. Despite the exciting potential of this technology, its impact on developing high-quality Machine Translation (MT) outputs for low-resource languages remains relatively under-explored. Furthermore, an open-source application, dedicated to both fine-tuning MLLMs and managing the complete MT workflow for low-resources languages, remains unavailable. We aim to address these imbalances through the development of adaptMLLM, which streamlines all processes involved in the fine-tuning of MLLMs for MT. This open-source application is tailored for developers, translators, and users who are engaged in MT. An intuitive interface allows for easy customisation of hyperparameters, and the application offers a range of metrics for model evaluation and the capability to deploy models as a translation service ",
    "path": "papers/24/03/2403.02370.json",
    "total_tokens": 853,
    "translated_title": "adaptMLLM：在低资源语言上用集成LLM游乐场对多语言语言模型进行微调",
    "translated_abstract": "Multilingual Language Models (MLLMs)和Large Language Models的出现，在自然语言处理的许多领域引发了创新。尽管这项技术具有令人兴奋的潜力，但其对低资源语言开发高质量的机器翻译（MT）输出的影响相对较少探讨。此外，尚未推出一个开源应用程序，专门用于对MLLM进行微调，并管理低资源语言的完整MT工作流程。我们旨在通过开发adaptMLLM来解决这些不平衡，该应用程序简化了用于MT的MLLM微调的所有流程。这个开源应用程序专门为从事MT的开发人员、翻译人员和用户量身定制。直观的界面允许轻松地自定义超参数，该应用程序提供一系列用于模型评估的指标，并具有部署模型作为翻译服务的能力。",
    "tldr": "该论文介绍了adaptMLLM，一个旨在解决低资源语言机器翻译问题的开源应用程序，该应用程序简化了对多语言语言模型进行微调的所有流程。",
    "en_tdlr": "This paper introduces adaptMLLM, an open-source application designed to address the issue of machine translation for low-resource languages, streamlining all processes involved in fine-tuning multilingual language models."
}