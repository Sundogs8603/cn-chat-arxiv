{
    "title": "Non-autoregressive Sequence-to-Sequence Vision-Language Models",
    "abstract": "arXiv:2403.02249v1 Announce Type: cross  Abstract: Sequence-to-sequence vision-language models are showing promise, but their applicability is limited by their inference latency due to their autoregressive way of generating predictions. We propose a parallel decoding sequence-to-sequence vision-language model, trained with a Query-CTC loss, that marginalizes over multiple inference paths in the decoder. This allows us to model the joint distribution of tokens, rather than restricting to conditional distribution as in an autoregressive model. The resulting model, NARVL, achieves performance on-par with its state-of-the-art autoregressive counterpart, but is faster at inference time, reducing from the linear complexity associated with the sequential generation of tokens to a paradigm of constant time joint inference.",
    "link": "https://arxiv.org/abs/2403.02249",
    "context": "Title: Non-autoregressive Sequence-to-Sequence Vision-Language Models\nAbstract: arXiv:2403.02249v1 Announce Type: cross  Abstract: Sequence-to-sequence vision-language models are showing promise, but their applicability is limited by their inference latency due to their autoregressive way of generating predictions. We propose a parallel decoding sequence-to-sequence vision-language model, trained with a Query-CTC loss, that marginalizes over multiple inference paths in the decoder. This allows us to model the joint distribution of tokens, rather than restricting to conditional distribution as in an autoregressive model. The resulting model, NARVL, achieves performance on-par with its state-of-the-art autoregressive counterpart, but is faster at inference time, reducing from the linear complexity associated with the sequential generation of tokens to a paradigm of constant time joint inference.",
    "path": "papers/24/03/2403.02249.json",
    "total_tokens": 755,
    "translated_title": "非自回归序列到序列视觉语言模型",
    "translated_abstract": "序列到序列的视觉语言模型表现出了潜力，但由于它们生成预测的自回归方式，它们的推理延迟限制了它们的适用性。我们提出了一个并行解码的序列到序列视觉语言模型，使用Query-CTC损失进行训练，在解码器中边际化多个推理路径。这使我们能够对标记的联合分布进行建模，而不像自回归模型那样限制在条件分布上。结果模型NARVL在推理时间上达到了与最新自回归对应物相当的性能，但更快，从与顺序生成标记相关的线性复杂度减少到常量时间联合推理的范式。",
    "tldr": "提出了一种非自回归序列到序列视觉语言模型，通过在解码器中边际化多个推理路径的方式，实现了对标记的联合分布建模，从而在保持性能的同时加快了推理速度。",
    "en_tdlr": "Proposed a non-autoregressive sequence-to-sequence vision-language model that marginalizes over multiple inference paths in the decoder to model the joint distribution of tokens, achieving faster inference speed while maintaining performance."
}