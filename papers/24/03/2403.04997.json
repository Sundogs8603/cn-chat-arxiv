{
    "title": "DiffChat: Learning to Chat with Text-to-Image Synthesis Models for Interactive Image Creation",
    "abstract": "arXiv:2403.04997v1 Announce Type: new  Abstract: We present DiffChat, a novel method to align Large Language Models (LLMs) to \"chat\" with prompt-as-input Text-to-Image Synthesis (TIS) models (e.g., Stable Diffusion) for interactive image creation. Given a raw prompt/image and a user-specified instruction, DiffChat can effectively make appropriate modifications and generate the target prompt, which can be leveraged to create the target image of high quality. To achieve this, we first collect an instruction-following prompt engineering dataset named InstructPE for the supervised training of DiffChat. Next, we propose a reinforcement learning framework with the feedback of three core criteria for image creation, i.e., aesthetics, user preference, and content integrity. It involves an action-space dynamic modification technique to obtain more relevant positive samples and harder negative samples during the off-policy sampling. Content integrity is also introduced into the value estimation ",
    "link": "https://arxiv.org/abs/2403.04997",
    "context": "Title: DiffChat: Learning to Chat with Text-to-Image Synthesis Models for Interactive Image Creation\nAbstract: arXiv:2403.04997v1 Announce Type: new  Abstract: We present DiffChat, a novel method to align Large Language Models (LLMs) to \"chat\" with prompt-as-input Text-to-Image Synthesis (TIS) models (e.g., Stable Diffusion) for interactive image creation. Given a raw prompt/image and a user-specified instruction, DiffChat can effectively make appropriate modifications and generate the target prompt, which can be leveraged to create the target image of high quality. To achieve this, we first collect an instruction-following prompt engineering dataset named InstructPE for the supervised training of DiffChat. Next, we propose a reinforcement learning framework with the feedback of three core criteria for image creation, i.e., aesthetics, user preference, and content integrity. It involves an action-space dynamic modification technique to obtain more relevant positive samples and harder negative samples during the off-policy sampling. Content integrity is also introduced into the value estimation ",
    "path": "papers/24/03/2403.04997.json",
    "total_tokens": 864,
    "translated_title": "DiffChat: 学习使用文本到图像合成模型进行互动图像创作的聊天",
    "translated_abstract": "我们提出了DiffChat，一种新颖的方法，通过使大型语言模型（LLMs）与以提示为输入的文本到图像合成（TIS）模型（例如稳定扩散）对齐，来\"聊天\"以进行互动图像创作。给定原始提示/图像和用户指定的指令，DiffChat 可以有效地进行适当修改并生成目标提示，这可用于创建高质量的目标图像。为实现此目标，我们首先收集了一个名为InstructPE的指令遵循提示工程数据集，用于 DiffChat 的监督训练。接下来，我们提出了一个基于强化学习的框架，利用三个核心标准（美学、用户喜好和内容完整性）的反馈来进行图像创作。该框架涉及一个动态修改技术来获得更相关的正样本和更难的负样本，以实现脱机采样。内容完整性还被引入到值估计中。",
    "tldr": "DiffChat 是一种新方法，通过对齐大型语言模型与文本到图像合成模型，实现了在互动图像创作中进行聊天并生成高质量图像的目标。",
    "en_tdlr": "DiffChat is a new method that aligns large language models with text-to-image synthesis models to chat for interactive image creation and generate high-quality images."
}