{
    "title": "Can Small Language Models be Good Reasoners for Sequential Recommendation?",
    "abstract": "arXiv:2403.04260v1 Announce Type: cross  Abstract: Large language models (LLMs) open up new horizons for sequential recommendations, owing to their remarkable language comprehension and generation capabilities. However, there are still numerous challenges that should be addressed to successfully implement sequential recommendations empowered by LLMs. Firstly, user behavior patterns are often complex, and relying solely on one-step reasoning from LLMs may lead to incorrect or task-irrelevant responses. Secondly, the prohibitively resource requirements of LLM (e.g., ChatGPT-175B) are overwhelmingly high and impractical for real sequential recommender systems. In this paper, we propose a novel Step-by-step knowLedge dIstillation fraMework for recommendation (SLIM), paving a promising path for sequential recommenders to enjoy the exceptional reasoning capabilities of LLMs in a \"slim\" (i.e., resource-efficient) manner. We introduce CoT prompting based on user behavior sequences for the larg",
    "link": "https://arxiv.org/abs/2403.04260",
    "context": "Title: Can Small Language Models be Good Reasoners for Sequential Recommendation?\nAbstract: arXiv:2403.04260v1 Announce Type: cross  Abstract: Large language models (LLMs) open up new horizons for sequential recommendations, owing to their remarkable language comprehension and generation capabilities. However, there are still numerous challenges that should be addressed to successfully implement sequential recommendations empowered by LLMs. Firstly, user behavior patterns are often complex, and relying solely on one-step reasoning from LLMs may lead to incorrect or task-irrelevant responses. Secondly, the prohibitively resource requirements of LLM (e.g., ChatGPT-175B) are overwhelmingly high and impractical for real sequential recommender systems. In this paper, we propose a novel Step-by-step knowLedge dIstillation fraMework for recommendation (SLIM), paving a promising path for sequential recommenders to enjoy the exceptional reasoning capabilities of LLMs in a \"slim\" (i.e., resource-efficient) manner. We introduce CoT prompting based on user behavior sequences for the larg",
    "path": "papers/24/03/2403.04260.json",
    "total_tokens": 884,
    "translated_title": "小型语言模型能成为顺序推荐系统的良好推理者吗？",
    "translated_abstract": "大型语言模型（LLMs）由于其出色的语言理解和生成能力，为顺序推荐开拓了新的领域。然而，要成功实现由LLMs赋能的顺序推荐还有许多挑战需要解决。首先，用户行为模式通常复杂，仅仅依靠LLMs的一步推理可能会导致错误或与任务无关的响应。其次，LLMs（例如ChatGPT-175B）极高的资源需求是难以承受且在实际顺序推荐系统中不切实际的。本文提出了一个新颖的逐步知识提取框架用于推荐（SLIM），为顺序推荐器以“瘦”（即资源高效）的方式享受LLMs出色的推理能力铺平了一条有前途的道路。我们引入基于用户行为序列的CoT提示来实现更好的推荐。",
    "tldr": "提出了逐步知识提取框架（SLIM），为顺序推荐系统解决了大型语言模型（LLMs）高资源需求的难题，使其能以资源高效的方式享受LLMs的出色推理能力。",
    "en_tdlr": "Introduced a Step-by-step knowLedge dIstillation fraMework for recommendation (SLIM) to address the challenge of high resource requirements of Large Language Models (LLMs) in sequential recommendation systems, enabling them to leverage the exceptional reasoning capabilities of LLMs in a resource-efficient manner."
}