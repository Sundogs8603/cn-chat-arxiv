{
    "title": "Closing the Visual Sim-to-Real Gap with Object-Composable NeRFs",
    "abstract": "arXiv:2403.04114v1 Announce Type: cross  Abstract: Deep learning methods for perception are the cornerstone of many robotic systems. Despite their potential for impressive performance, obtaining real-world training data is expensive, and can be impractically difficult for some tasks. Sim-to-real transfer with domain randomization offers a potential workaround, but often requires extensive manual tuning and results in models that are brittle to distribution shift between sim and real. In this work, we introduce Composable Object Volume NeRF (COV-NeRF), an object-composable NeRF model that is the centerpiece of a real-to-sim pipeline for synthesizing training data targeted to scenes and objects from the real world. COV-NeRF extracts objects from real images and composes them into new scenes, generating photorealistic renderings and many types of 2D and 3D supervision, including depth maps, segmentation masks, and meshes. We show that COV-NeRF matches the rendering quality of modern NeRF ",
    "link": "https://arxiv.org/abs/2403.04114",
    "context": "Title: Closing the Visual Sim-to-Real Gap with Object-Composable NeRFs\nAbstract: arXiv:2403.04114v1 Announce Type: cross  Abstract: Deep learning methods for perception are the cornerstone of many robotic systems. Despite their potential for impressive performance, obtaining real-world training data is expensive, and can be impractically difficult for some tasks. Sim-to-real transfer with domain randomization offers a potential workaround, but often requires extensive manual tuning and results in models that are brittle to distribution shift between sim and real. In this work, we introduce Composable Object Volume NeRF (COV-NeRF), an object-composable NeRF model that is the centerpiece of a real-to-sim pipeline for synthesizing training data targeted to scenes and objects from the real world. COV-NeRF extracts objects from real images and composes them into new scenes, generating photorealistic renderings and many types of 2D and 3D supervision, including depth maps, segmentation masks, and meshes. We show that COV-NeRF matches the rendering quality of modern NeRF ",
    "path": "papers/24/03/2403.04114.json",
    "total_tokens": 955,
    "translated_title": "用可组合物体的神经辅助射线体逼真地缩小视觉从虚拟到实际的差距",
    "translated_abstract": "感知的深度学习方法是许多机器人系统的基石。尽管这些方法具有令人印象深刻的性能潜力，但获取真实世界的训练数据成本高，对于一些任务可能难以实际操作。通过领域随机化进行从虚拟到实际的转移提供了一个潜在的解决方法，但往往需要大量手动调整，并导致模型对于虚拟和真实之间的分布变化很脆弱。在这项工作中，我们介绍了可组合对象体积神经辅助射线体（COV-NeRF），这是一个以真实到虚拟管道为中心的物体可组合的NeRF模型，用于合成面向来自真实世界的场景和对象的训练数据。COV-NeRF从真实图像中提取对象，并将它们合成为新场景，生成逼真的渲染以及多种类型的2D和3D监督，包括深度图，分割遮罩和网格。我们展示COV-NeRF与现代NeRF的渲染质量相匹配",
    "tldr": "COV-NeRF是一种新型的神经辅助射线体模型，可以从真实图像中提取对象并合成新场景，有效地解决了视觉从虚拟到实际中的数据匹配问题。",
    "en_tdlr": "COV-NeRF is a novel NeRF model that extracts objects from real images and composes them into new scenes, effectively addressing the data matching issue in bridging the visual gap from simulation to reality."
}