{
    "title": "The First to Know: How Token Distributions Reveal Hidden Knowledge in Large Vision-Language Models?",
    "abstract": "arXiv:2403.09037v1 Announce Type: cross  Abstract: Large vision-language models (LVLMs), designed to interpret and respond to human instructions, occasionally generate hallucinated or harmful content due to inappropriate instructions. This study uses linear probing to shed light on the hidden knowledge at the output layer of LVLMs. We demonstrate that the logit distributions of the first tokens contain sufficient information to determine whether to respond to the instructions, including recognizing unanswerable visual questions, defending against multi-modal jailbreaking attack, and identifying deceptive questions. Such hidden knowledge is gradually lost in logits of subsequent tokens during response generation. Then, we illustrate a simple decoding strategy at the generation of the first token, effectively improving the generated content. In experiments, we find a few interesting insights: First, the CLIP model already contains a strong signal for solving these tasks, indicating poten",
    "link": "https://arxiv.org/abs/2403.09037",
    "context": "Title: The First to Know: How Token Distributions Reveal Hidden Knowledge in Large Vision-Language Models?\nAbstract: arXiv:2403.09037v1 Announce Type: cross  Abstract: Large vision-language models (LVLMs), designed to interpret and respond to human instructions, occasionally generate hallucinated or harmful content due to inappropriate instructions. This study uses linear probing to shed light on the hidden knowledge at the output layer of LVLMs. We demonstrate that the logit distributions of the first tokens contain sufficient information to determine whether to respond to the instructions, including recognizing unanswerable visual questions, defending against multi-modal jailbreaking attack, and identifying deceptive questions. Such hidden knowledge is gradually lost in logits of subsequent tokens during response generation. Then, we illustrate a simple decoding strategy at the generation of the first token, effectively improving the generated content. In experiments, we find a few interesting insights: First, the CLIP model already contains a strong signal for solving these tasks, indicating poten",
    "path": "papers/24/03/2403.09037.json",
    "total_tokens": 925,
    "translated_title": "第一个知道：令牌分布如何揭示大型视觉语言模型中的隐藏知识？",
    "translated_abstract": "大型视觉语言模型（LVLMs）旨在解释和响应人类指令，但由于不当指令而偶尔生成幻觉或有害内容。本研究使用线性探测来揭示LVLMs输出层的隐藏知识。我们证明了首个令牌的logit分布包含足够信息，可以确定是否应对指令作出响应，包括识别无法回答的视觉问题、防范多模态越狱攻击以及识别欺骗性问题。这种隐藏知识在响应生成过程中随后令牌的logit逐渐丢失。然后，我们演示了一种简单的解码策略在生成第一个令牌时，有效改善生成的内容。在实验中，我们发现了一些有趣的见解：首先，CLIP模型已经包含解决这些任务的强烈信号，表明潜力",
    "tldr": "本研究利用线性探测揭示了大型视觉语言模型的隐藏知识，发现首个令牌的logit分布包含足够信息，可以识别无法回答的视觉问题、防范多模态越狱攻击以及识别欺骗性问题，并提出了一个简单的解码策略以有效改善生成内容。"
}