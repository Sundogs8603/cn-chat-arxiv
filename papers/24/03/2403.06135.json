{
    "title": "MACE: Mass Concept Erasure in Diffusion Models",
    "abstract": "arXiv:2403.06135v1 Announce Type: cross  Abstract: The rapid expansion of large-scale text-to-image diffusion models has raised growing concerns regarding their potential misuse in creating harmful or misleading content. In this paper, we introduce MACE, a finetuning framework for the task of mass concept erasure. This task aims to prevent models from generating images that embody unwanted concepts when prompted. Existing concept erasure methods are typically restricted to handling fewer than five concepts simultaneously and struggle to find a balance between erasing concept synonyms (generality) and maintaining unrelated concepts (specificity). In contrast, MACE differs by successfully scaling the erasure scope up to 100 concepts and by achieving an effective balance between generality and specificity. This is achieved by leveraging closed-form cross-attention refinement along with LoRA finetuning, collectively eliminating the information of undesirable concepts. Furthermore, MACE int",
    "link": "https://arxiv.org/abs/2403.06135",
    "context": "Title: MACE: Mass Concept Erasure in Diffusion Models\nAbstract: arXiv:2403.06135v1 Announce Type: cross  Abstract: The rapid expansion of large-scale text-to-image diffusion models has raised growing concerns regarding their potential misuse in creating harmful or misleading content. In this paper, we introduce MACE, a finetuning framework for the task of mass concept erasure. This task aims to prevent models from generating images that embody unwanted concepts when prompted. Existing concept erasure methods are typically restricted to handling fewer than five concepts simultaneously and struggle to find a balance between erasing concept synonyms (generality) and maintaining unrelated concepts (specificity). In contrast, MACE differs by successfully scaling the erasure scope up to 100 concepts and by achieving an effective balance between generality and specificity. This is achieved by leveraging closed-form cross-attention refinement along with LoRA finetuning, collectively eliminating the information of undesirable concepts. Furthermore, MACE int",
    "path": "papers/24/03/2403.06135.json",
    "total_tokens": 854,
    "translated_title": "MACE：扩散模型中的大规模概念消除",
    "translated_abstract": "大规模文本到图像扩散模型的快速扩展引起了人们对其在创建有害或误导性内容方面潜在误用的担忧。本文介绍了一种名为MACE的微调框架，用于大规模概念消除任务。该任务旨在防止模型在提示时生成具有不希望概念的图像。现有的概念消除方法通常受限于同时处理少于五个概念，并且在消除概念的同时难以找到消除概念同义词（泛化性）和保持不相关概念（特异性）之间的平衡。相比之下，MACE通过成功将消除范围扩展到100个概念，并在泛化性和特异性之间取得有效平衡而不同。这是通过利用闭环交叉注意力细化以及LoRA微调来实现的，共同消除了不良概念的信息。此外，MACE还...",
    "tldr": "MACE通过成功将概念消除的范围扩展到100个概念，并在泛化性和特异性之间取得有效平衡，从而防止大规模文本到图像扩散模型生成不良或误导性图像。",
    "en_tdlr": "MACE successfully scales the concept erasure scope up to 100 concepts, achieving an effective balance between generality and specificity to prevent large-scale text-to-image diffusion models from generating harmful or misleading images."
}