{
    "title": "All Artificial, Less Intelligence: GenAI through the Lens of Formal Verification",
    "abstract": "arXiv:2403.16750v1 Announce Type: new  Abstract: Modern hardware designs have grown increasingly efficient and complex. However, they are often susceptible to Common Weakness Enumerations (CWEs). This paper is focused on the formal verification of CWEs in a dataset of hardware designs written in SystemVerilog from Regenerative Artificial Intelligence (AI) powered by Large Language Models (LLMs). We applied formal verification to categorize each hardware design as vulnerable or CWE-free. This dataset was generated by 4 different LLMs and features a unique set of designs for each of the 10 CWEs we target in our paper. We have associated the identified vulnerabilities with CWE numbers for a dataset of 60,000 generated SystemVerilog Register Transfer Level (RTL) code. It was also found that most LLMs are not aware of any hardware CWEs; hence they are usually not considered when generating the hardware code. Our study reveals that approximately 60% of the hardware designs generated by LLMs ",
    "link": "https://arxiv.org/abs/2403.16750",
    "context": "Title: All Artificial, Less Intelligence: GenAI through the Lens of Formal Verification\nAbstract: arXiv:2403.16750v1 Announce Type: new  Abstract: Modern hardware designs have grown increasingly efficient and complex. However, they are often susceptible to Common Weakness Enumerations (CWEs). This paper is focused on the formal verification of CWEs in a dataset of hardware designs written in SystemVerilog from Regenerative Artificial Intelligence (AI) powered by Large Language Models (LLMs). We applied formal verification to categorize each hardware design as vulnerable or CWE-free. This dataset was generated by 4 different LLMs and features a unique set of designs for each of the 10 CWEs we target in our paper. We have associated the identified vulnerabilities with CWE numbers for a dataset of 60,000 generated SystemVerilog Register Transfer Level (RTL) code. It was also found that most LLMs are not aware of any hardware CWEs; hence they are usually not considered when generating the hardware code. Our study reveals that approximately 60% of the hardware designs generated by LLMs ",
    "path": "papers/24/03/2403.16750.json",
    "total_tokens": 925,
    "translated_title": "人工总算不那么智能：从形式验证的角度看GenAI",
    "translated_abstract": "现代硬件设计变得越来越高效和复杂。然而，它们常常容易受到常见弱点枚举（CWEs）的影响。本文关注的是在由大型语言模型（LLMs）赋能的再生人工智能（AI）中，对一组用SystemVerilog编写的硬件设计中CWEs的形式验证。我们应用形式验证来将每个硬件设计分类为易受攻击或无CWE。这个数据集是由4个不同的LLMs生成的，为我们论文中针对的10种CWE中的每一种特性设计了一组独特的设计。我们将识别出的漏洞与CWE编号关联，用于60,000个生成的SystemVerilog寄存器传输级（RTL）代码的数据集。研究还发现，大多数LLMs并不知道任何硬件CWEs；因此，它们通常在生成硬件代码时不予考虑。我们的研究显示，大约60%由LLMs生成的硬件设计存在漏洞。",
    "tldr": "本文研究了再生人工智能中硬件设计中CWEs的形式验证，发现大多数大型语言模型在生成硬件代码时并未考虑硬件CWEs，导致大约60%的硬件设计存在漏洞。",
    "en_tdlr": "This paper focuses on the formal verification of Common Weakness Enumerations (CWEs) in hardware designs powered by Large Language Models (LLMs), revealing that most LLMs do not consider hardware CWEs when generating hardware code, leading to approximately 60% of the designs containing vulnerabilities."
}