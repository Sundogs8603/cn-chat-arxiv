{
    "title": "Improving Adversarial Data Collection by Supporting Annotators: Lessons from GAHD, a German Hate Speech Dataset",
    "abstract": "arXiv:2403.19559v1 Announce Type: new  Abstract: Hate speech detection models are only as good as the data they are trained on. Datasets sourced from social media suffer from systematic gaps and biases, leading to unreliable models with simplistic decision boundaries. Adversarial datasets, collected by exploiting model weaknesses, promise to fix this problem. However, adversarial data collection can be slow and costly, and individual annotators have limited creativity. In this paper, we introduce GAHD, a new German Adversarial Hate speech Dataset comprising ca.\\ 11k examples. During data collection, we explore new strategies for supporting annotators, to create more diverse adversarial examples more efficiently and provide a manual analysis of annotator disagreements for each strategy. Our experiments show that the resulting dataset is challenging even for state-of-the-art hate speech detection models, and that training on GAHD clearly improves model robustness. Further, we find that m",
    "link": "https://arxiv.org/abs/2403.19559",
    "context": "Title: Improving Adversarial Data Collection by Supporting Annotators: Lessons from GAHD, a German Hate Speech Dataset\nAbstract: arXiv:2403.19559v1 Announce Type: new  Abstract: Hate speech detection models are only as good as the data they are trained on. Datasets sourced from social media suffer from systematic gaps and biases, leading to unreliable models with simplistic decision boundaries. Adversarial datasets, collected by exploiting model weaknesses, promise to fix this problem. However, adversarial data collection can be slow and costly, and individual annotators have limited creativity. In this paper, we introduce GAHD, a new German Adversarial Hate speech Dataset comprising ca.\\ 11k examples. During data collection, we explore new strategies for supporting annotators, to create more diverse adversarial examples more efficiently and provide a manual analysis of annotator disagreements for each strategy. Our experiments show that the resulting dataset is challenging even for state-of-the-art hate speech detection models, and that training on GAHD clearly improves model robustness. Further, we find that m",
    "path": "papers/24/03/2403.19559.json",
    "total_tokens": 917,
    "translated_title": "支持标注者以改进对抗数据收集：来自GAHD的教训，一个德语仇恨言论数据集",
    "translated_abstract": "厌恶言论检测模型的表现取决于它们所训练的数据。从社交媒体获取的数据集存在系统性缺陷和偏见，导致模型具有简单的决策边界。通过利用模型的弱点收集的对抗性数据集承诺解决这一问题。然而，对抗数据集的收集可能缓慢且昂贵，而个体标注者的创造力有限。在本文中，我们介绍了GAHD，一个新的德语对抗性仇恨言论数据集，包含约11k个示例。在数据收集过程中，我们探索了支持标注者的新策略，以更有效地创建更多样化的对抗性示例，并为每种策略提供了标注者意见分歧的手动分析。我们的实验表明，由此产生的数据集即使对于最先进的仇恨言论检测模型也具有挑战性，并且在GAHD上的训练显然提高了模型的鲁棒性。",
    "tldr": "通过支持标注者，提出新策略来创建更多样化的对抗性示例，引入GAHD德语对抗性仇恨言论数据集，表明训练模型使用GAHD可以显著提高模型的鲁棒性。",
    "en_tdlr": "By supporting annotators with new strategies to create more diverse adversarial examples, introducing the GAHD German Adversarial Hate speech Dataset shows training models on GAHD significantly improves model robustness."
}