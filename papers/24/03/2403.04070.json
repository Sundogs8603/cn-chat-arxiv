{
    "title": "Improving Adversarial Training using Vulnerability-Aware Perturbation Budget",
    "abstract": "arXiv:2403.04070v1 Announce Type: cross  Abstract: Adversarial Training (AT) effectively improves the robustness of Deep Neural Networks (DNNs) to adversarial attacks. Generally, AT involves training DNN models with adversarial examples obtained within a pre-defined, fixed perturbation bound. Notably, individual natural examples from which these adversarial examples are crafted exhibit varying degrees of intrinsic vulnerabilities, and as such, crafting adversarial examples with fixed perturbation radius for all instances may not sufficiently unleash the potency of AT. Motivated by this observation, we propose two simple, computationally cheap vulnerability-aware reweighting functions for assigning perturbation bounds to adversarial examples used for AT, named Margin-Weighted Perturbation Budget (MWPB) and Standard-Deviation-Weighted Perturbation Budget (SDWPB). The proposed methods assign perturbation radii to individual adversarial samples based on the vulnerability of their correspon",
    "link": "https://arxiv.org/abs/2403.04070",
    "context": "Title: Improving Adversarial Training using Vulnerability-Aware Perturbation Budget\nAbstract: arXiv:2403.04070v1 Announce Type: cross  Abstract: Adversarial Training (AT) effectively improves the robustness of Deep Neural Networks (DNNs) to adversarial attacks. Generally, AT involves training DNN models with adversarial examples obtained within a pre-defined, fixed perturbation bound. Notably, individual natural examples from which these adversarial examples are crafted exhibit varying degrees of intrinsic vulnerabilities, and as such, crafting adversarial examples with fixed perturbation radius for all instances may not sufficiently unleash the potency of AT. Motivated by this observation, we propose two simple, computationally cheap vulnerability-aware reweighting functions for assigning perturbation bounds to adversarial examples used for AT, named Margin-Weighted Perturbation Budget (MWPB) and Standard-Deviation-Weighted Perturbation Budget (SDWPB). The proposed methods assign perturbation radii to individual adversarial samples based on the vulnerability of their correspon",
    "path": "papers/24/03/2403.04070.json",
    "total_tokens": 868,
    "translated_title": "利用脆弱性感知扰动预算改进对抗训练",
    "translated_abstract": "对抗训练(Adversarial Training, AT)有效地提高了深度神经网络(DNNs)对敌对攻击的鲁棒性。通常，AT涉及使用在预定义、固定扰动界限内获取的对抗示例来训练DNN模型。值得注意的是，用于制作这些对抗示例的个别自然示例展示出不同程度的固有脆弱性，因此，为所有实例设定固定扰动半径来制作对抗示例可能不足以充分发挥AT的有效性。受到这一观察的启发，我们提出了两种简单、计算廉价的基于脆弱性感知的重新加权函数，用于为用于AT的对抗示例分配扰动界限，分别命名为边际加权扰动预算（MWPB）和标准差加权扰动预算（SDWPB）。所提出的方法根据其对应脆弱性为单个对抗样本分配扰动半径。",
    "tldr": "提出了两种基于脆弱性感知的重新加权函数，用于为对抗训练中的对抗示例分配扰动界限，从而提高了对抗训练的有效性。",
    "en_tdlr": "Two vulnerability-aware reweighting functions are proposed to assign perturbation bounds to adversarial examples in adversarial training, thus improving the effectiveness of adversarial training."
}