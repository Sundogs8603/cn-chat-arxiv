{
    "title": "Large Language Models Are State-of-the-Art Evaluator for Grammatical Error Correction",
    "abstract": "arXiv:2403.17540v1 Announce Type: new  Abstract: Large Language Models (LLMs) have been reported to outperform existing automatic evaluation metrics in some tasks, such as text summarization and machine translation. However, there has been a lack of research on LLMs as evaluators in grammatical error correction (GEC). In this study, we investigate the performance of LLMs in GEC evaluation by employing prompts designed to incorporate various evaluation criteria inspired by previous research. Our extensive experimental results demonstrate that GPT-4 achieved Kendall's rank correlation of 0.662 with human judgments, surpassing all existing methods. Furthermore, in recent GEC evaluations, we have underscored the significance of the LLMs scale and particularly emphasized the importance of fluency among evaluation criteria.",
    "link": "https://arxiv.org/abs/2403.17540",
    "context": "Title: Large Language Models Are State-of-the-Art Evaluator for Grammatical Error Correction\nAbstract: arXiv:2403.17540v1 Announce Type: new  Abstract: Large Language Models (LLMs) have been reported to outperform existing automatic evaluation metrics in some tasks, such as text summarization and machine translation. However, there has been a lack of research on LLMs as evaluators in grammatical error correction (GEC). In this study, we investigate the performance of LLMs in GEC evaluation by employing prompts designed to incorporate various evaluation criteria inspired by previous research. Our extensive experimental results demonstrate that GPT-4 achieved Kendall's rank correlation of 0.662 with human judgments, surpassing all existing methods. Furthermore, in recent GEC evaluations, we have underscored the significance of the LLMs scale and particularly emphasized the importance of fluency among evaluation criteria.",
    "path": "papers/24/03/2403.17540.json",
    "total_tokens": 767,
    "translated_title": "大型语言模型是语法错误校正的最先进评估器",
    "translated_abstract": "大型语言模型（LLMs）据报道在某些任务中胜过现有的自动评估指标，比如文本总结和机器翻译。但是，关于LLMs在语法错误校正（GEC）中作为评估器的研究还不足。本研究通过采用设计的提示来整合先前研究启发的各种评估标准，调查了LLMs在GEC评估中的表现。我们的广泛实验结果表明，GPT-4在与人类判断之间达到了0.662的Kendall等级相关性，超过了所有现有方法。此外，在最近的GEC评估中，我们强调了LLMs规模的重要性，特别强调了流畅度在评估标准中的重要性。",
    "tldr": "大型语言模型GPT-4在语法错误校正评估中表现优异，与人类判断有很高的相关性，凸显了在评估标准中流畅度的重要性。",
    "en_tdlr": "The large language model GPT-4 performs exceptionally well in grammatical error correction evaluation, showing high correlation with human judgments and highlighting the importance of fluency in evaluation criteria."
}