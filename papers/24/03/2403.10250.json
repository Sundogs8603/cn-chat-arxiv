{
    "title": "Interpretable Machine Learning for Survival Analysis",
    "abstract": "arXiv:2403.10250v1 Announce Type: cross  Abstract: With the spread and rapid advancement of black box machine learning models, the field of interpretable machine learning (IML) or explainable artificial intelligence (XAI) has become increasingly important over the last decade. This is particularly relevant for survival analysis, where the adoption of IML techniques promotes transparency, accountability and fairness in sensitive areas, such as clinical decision making processes, the development of targeted therapies, interventions or in other medical or healthcare related contexts. More specifically, explainability can uncover a survival model's potential biases and limitations and provide more mathematically sound ways to understand how and which features are influential for prediction or constitute risk factors. However, the lack of readily available IML methods may have deterred medical practitioners and policy makers in public health from leveraging the full potential of machine lea",
    "link": "https://arxiv.org/abs/2403.10250",
    "context": "Title: Interpretable Machine Learning for Survival Analysis\nAbstract: arXiv:2403.10250v1 Announce Type: cross  Abstract: With the spread and rapid advancement of black box machine learning models, the field of interpretable machine learning (IML) or explainable artificial intelligence (XAI) has become increasingly important over the last decade. This is particularly relevant for survival analysis, where the adoption of IML techniques promotes transparency, accountability and fairness in sensitive areas, such as clinical decision making processes, the development of targeted therapies, interventions or in other medical or healthcare related contexts. More specifically, explainability can uncover a survival model's potential biases and limitations and provide more mathematically sound ways to understand how and which features are influential for prediction or constitute risk factors. However, the lack of readily available IML methods may have deterred medical practitioners and policy makers in public health from leveraging the full potential of machine lea",
    "path": "papers/24/03/2403.10250.json",
    "total_tokens": 850,
    "translated_title": "可解释的机器学习用于生存分析",
    "translated_abstract": "随着黑盒机器学习模型的传播和快速进步，可解释的机器学习（IML）领域或可解释的人工智能（XAI）在过去十年中变得越来越重要。 这在生存分析领域尤为重要，其中采用IML技术促进了透明度、问责制和公平性，特别是在临床决策过程、有针对性疗法的开发、干预或其他医学或与医疗保健相关的环境中。 具体来说，可解释性可以揭示生存模型的潜在偏见和局限性，并提供更符合数学原理的方法来理解哪些特征对预测有影响或构成风险因素。 然而，缺乏即时可用的IML方法可能已经阻碍了医学从业者和公共卫生政策制定者充分利用机器学习的潜力。",
    "tldr": "可解释的机器学习在生存分析中的应用促进了透明度和公平性，揭示了模型的潜在偏见和限制，并提供了更符合数学原理的特征影响和风险因素预测方法。",
    "en_tdlr": "Interpretable machine learning applied in survival analysis promotes transparency and fairness, uncovering potential biases and limitations of the model, and providing more mathematically sound methods for predicting feature influences and risk factors."
}