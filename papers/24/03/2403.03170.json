{
    "title": "SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection",
    "abstract": "arXiv:2403.03170v1 Announce Type: cross  Abstract: Misinformation is a prevalent societal issue due to its potential high risks. Out-of-context (OOC) misinformation, where authentic images are repurposed with false text, is one of the easiest and most effective ways to mislead audiences. Current methods focus on assessing image-text consistency but lack convincing explanations for their judgments, which is essential for debunking misinformation. While Multimodal Large Language Models (MLLMs) have rich knowledge and innate capability for visual reasoning and explanation generation, they still lack sophistication in understanding and discovering the subtle crossmodal differences. In this paper, we introduce SNIFFER, a novel multimodal large language model specifically engineered for OOC misinformation detection and explanation. SNIFFER employs two-stage instruction tuning on InstructBLIP. The first stage refines the model's concept alignment of generic objects with news-domain entities a",
    "link": "https://arxiv.org/abs/2403.03170",
    "context": "Title: SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection\nAbstract: arXiv:2403.03170v1 Announce Type: cross  Abstract: Misinformation is a prevalent societal issue due to its potential high risks. Out-of-context (OOC) misinformation, where authentic images are repurposed with false text, is one of the easiest and most effective ways to mislead audiences. Current methods focus on assessing image-text consistency but lack convincing explanations for their judgments, which is essential for debunking misinformation. While Multimodal Large Language Models (MLLMs) have rich knowledge and innate capability for visual reasoning and explanation generation, they still lack sophistication in understanding and discovering the subtle crossmodal differences. In this paper, we introduce SNIFFER, a novel multimodal large language model specifically engineered for OOC misinformation detection and explanation. SNIFFER employs two-stage instruction tuning on InstructBLIP. The first stage refines the model's concept alignment of generic objects with news-domain entities a",
    "path": "papers/24/03/2403.03170.json",
    "total_tokens": 877,
    "translated_title": "SNIFFER: 可解释的跨文本信息误传检测的多模大语言模型",
    "translated_abstract": "虚假信息是一个普遍的社会问题，由于潜在的高风险。超出上下文（OOC）的误传，即真实图像被伪造的文本再利用，是误导观众的最简单和最有效的方法之一。当前的方法侧重于评估图像-文本一致性，但缺乏说服力的解释来支持他们的判断，这对于揭示误传至关重要。虽然多模大语言模型（MLLMs）具有丰富的知识和内在的视觉推理和解释生成能力，但它们仍然缺乏理解和发现微妙的跨模态差异的复杂性。在本文中，我们介绍了SNIFFER，这是一种专门为OOC误传检测和解释而设计的新颖的多模大语言模型。SNIFFER在InstructBLIP上采用了两阶段的指导微调。第一阶段通过新闻领域实体与通用对象的模型概念对齐，",
    "tldr": "SNIFFER是一种专门为超出上下文误传检测和解释而设计的新型多模大语言模型，通过两阶段指导微调，在解释生成方面取得了突破。",
    "en_tdlr": "SNIFFER is a novel multimodal large language model specifically engineered for out-of-context misinformation detection and explanation, making breakthroughs in explanation generation through two-stage instruction tuning."
}