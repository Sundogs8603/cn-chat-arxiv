{
    "title": "Semantically Enriched Cross-Lingual Sentence Embeddings for Crisis-related Social Media Texts",
    "abstract": "arXiv:2403.16614v1 Announce Type: new  Abstract: Tasks such as semantic search and clustering on crisis-related social media texts enhance our comprehension of crisis discourse, aiding decision-making and targeted interventions. Pre-trained language models have advanced performance in crisis informatics, but their contextual embeddings lack semantic meaningfulness. Although the CrisisTransformers family includes a sentence encoder to address the semanticity issue, it remains monolingual, processing only English texts. Furthermore, employing separate models for different languages leads to embeddings in distinct vector spaces, introducing challenges when comparing semantic similarities between multi-lingual texts. Therefore, we propose multi-lingual sentence encoders (CT-XLMR-SE and CT-mBERT-SE) that embed crisis-related social media texts for over 50 languages, such that texts with similar meanings are in close proximity within the same vector space, irrespective of language diversity.",
    "link": "https://arxiv.org/abs/2403.16614",
    "context": "Title: Semantically Enriched Cross-Lingual Sentence Embeddings for Crisis-related Social Media Texts\nAbstract: arXiv:2403.16614v1 Announce Type: new  Abstract: Tasks such as semantic search and clustering on crisis-related social media texts enhance our comprehension of crisis discourse, aiding decision-making and targeted interventions. Pre-trained language models have advanced performance in crisis informatics, but their contextual embeddings lack semantic meaningfulness. Although the CrisisTransformers family includes a sentence encoder to address the semanticity issue, it remains monolingual, processing only English texts. Furthermore, employing separate models for different languages leads to embeddings in distinct vector spaces, introducing challenges when comparing semantic similarities between multi-lingual texts. Therefore, we propose multi-lingual sentence encoders (CT-XLMR-SE and CT-mBERT-SE) that embed crisis-related social media texts for over 50 languages, such that texts with similar meanings are in close proximity within the same vector space, irrespective of language diversity.",
    "path": "papers/24/03/2403.16614.json",
    "total_tokens": 908,
    "translated_title": "为危机相关社交媒体文本增加语义内容的跨语言句子嵌入",
    "translated_abstract": "诸如危机相关社交媒体文本的语义搜索和聚类等任务提高了我们对危机话语的理解，有助于决策制定和有针对性的干预。预先训练的语言模型在危机信息学中取得了良好的表现，但它们的上下文嵌入缺乏语义意义。尽管CrisisTransformers系列包括一个句子编码器来解决语义问题，但它仍然是单语的，仅处理英语文本。此外，为不同语言使用单独的模型会导致嵌入到不同向量空间中，当比较多语言文本之间的语义相似性时会引入挑战。因此，我们提出了多语言句子编码器（CT-XLMR-SE和CT-mBERT-SE），为50多种语言的危机相关社交媒体文本嵌入，使具有相似含义的文本在相同的向量空间内靠近，无论语言多样性如何。",
    "tldr": "提出了多语言句子编码器（CT-XLMR-SE和CT-mBERT-SE），可为50多种语言的危机相关社交媒体文本嵌入语义内容，使具有相似含义的文本在同一向量空间内接近，无论语言差异。",
    "en_tdlr": "Introduced multilingual sentence encoders (CT-XLMR-SE and CT-mBERT-SE) that embed crisis-related social media texts for over 50 languages, ensuring texts with similar meanings are in close proximity within the same vector space, regardless of language diversity."
}