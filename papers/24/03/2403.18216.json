{
    "title": "Minimax Optimal Fair Classification with Bounded Demographic Disparity",
    "abstract": "arXiv:2403.18216v1 Announce Type: cross  Abstract: Mitigating the disparate impact of statistical machine learning methods is crucial for ensuring fairness. While extensive research aims to reduce disparity, the effect of using a \\emph{finite dataset} -- as opposed to the entire population -- remains unclear. This paper explores the statistical foundations of fair binary classification with two protected groups, focusing on controlling demographic disparity, defined as the difference in acceptance rates between the groups. Although fairness may come at the cost of accuracy even with infinite data, we show that using a finite sample incurs additional costs due to the need to estimate group-specific acceptance thresholds. We study the minimax optimal classification error while constraining demographic disparity to a user-specified threshold. To quantify the impact of fairness constraints, we introduce a novel measure called \\emph{fairness-aware excess risk} and derive a minimax lower bou",
    "link": "https://arxiv.org/abs/2403.18216",
    "context": "Title: Minimax Optimal Fair Classification with Bounded Demographic Disparity\nAbstract: arXiv:2403.18216v1 Announce Type: cross  Abstract: Mitigating the disparate impact of statistical machine learning methods is crucial for ensuring fairness. While extensive research aims to reduce disparity, the effect of using a \\emph{finite dataset} -- as opposed to the entire population -- remains unclear. This paper explores the statistical foundations of fair binary classification with two protected groups, focusing on controlling demographic disparity, defined as the difference in acceptance rates between the groups. Although fairness may come at the cost of accuracy even with infinite data, we show that using a finite sample incurs additional costs due to the need to estimate group-specific acceptance thresholds. We study the minimax optimal classification error while constraining demographic disparity to a user-specified threshold. To quantify the impact of fairness constraints, we introduce a novel measure called \\emph{fairness-aware excess risk} and derive a minimax lower bou",
    "path": "papers/24/03/2403.18216.json",
    "total_tokens": 847,
    "translated_title": "具有有界人口差异的极小极小公平分类",
    "translated_abstract": "缓解统计机器学习方法的不公平影响对确保公平至关重要。尽管大量研究旨在减少差异，但使用\\emph{有限数据集}的效果 -- 而不是整个人口 -- 仍不清楚。本文探讨了具有两个受保护群体的公平二元分类的统计基础，重点是控制人口差异，即群体之间的接受率差异。尽管即使有无限数据，公平可能会以准确性为代价，但我们表明使用有限样本会由于需要估计特定于群体的接受阈值而产生额外成本。我们研究了再将人口差异限制到用户指定阈值时的极小极小最优分类错误。为了量化公平约束的影响，我们引入了一种称为\\emph{公平感知超额风险}的新颖度量，并推导了一个极小极小下界。",
    "tldr": "本文研究了在公平二元分类中控制人口差异的统计基础，提出了极小极小最优分类错误限制人口差异到用户指定阈值的方法。",
    "en_tdlr": "This paper explores the statistical foundations of fair binary classification with two protected groups, focusing on controlling demographic disparity, and introduces a method of minimizing optimal classification error while constraining demographic disparity to a user-specified threshold."
}