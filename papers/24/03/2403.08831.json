{
    "title": "Majority-of-Three: The Simplest Optimal Learner?",
    "abstract": "arXiv:2403.08831v1 Announce Type: cross  Abstract: Developing an optimal PAC learning algorithm in the realizable setting, where empirical risk minimization (ERM) is suboptimal, was a major open problem in learning theory for decades. The problem was finally resolved by Hanneke a few years ago. Unfortunately, Hanneke's algorithm is quite complex as it returns the majority vote of many ERM classifiers that are trained on carefully selected subsets of the data. It is thus a natural goal to determine the simplest algorithm that is optimal. In this work we study the arguably simplest algorithm that could be optimal: returning the majority vote of three ERM classifiers. We show that this algorithm achieves the optimal in-expectation bound on its error which is provably unattainable by a single ERM classifier. Furthermore, we prove a near-optimal high-probability bound on this algorithm's error. We conjecture that a better analysis will prove that this algorithm is in fact optimal in the hig",
    "link": "https://arxiv.org/abs/2403.08831",
    "context": "Title: Majority-of-Three: The Simplest Optimal Learner?\nAbstract: arXiv:2403.08831v1 Announce Type: cross  Abstract: Developing an optimal PAC learning algorithm in the realizable setting, where empirical risk minimization (ERM) is suboptimal, was a major open problem in learning theory for decades. The problem was finally resolved by Hanneke a few years ago. Unfortunately, Hanneke's algorithm is quite complex as it returns the majority vote of many ERM classifiers that are trained on carefully selected subsets of the data. It is thus a natural goal to determine the simplest algorithm that is optimal. In this work we study the arguably simplest algorithm that could be optimal: returning the majority vote of three ERM classifiers. We show that this algorithm achieves the optimal in-expectation bound on its error which is provably unattainable by a single ERM classifier. Furthermore, we prove a near-optimal high-probability bound on this algorithm's error. We conjecture that a better analysis will prove that this algorithm is in fact optimal in the hig",
    "path": "papers/24/03/2403.08831.json",
    "total_tokens": 848,
    "translated_title": "多数三者：最简单的最优学习器？",
    "translated_abstract": "在实现数据设置下发展最佳的PAC学习算法是学习理论中几十年来的一个重大开放性问题，其中经验风险最小化（ERM）是次优的。几年前，Hanneke终于解决了这个问题。不幸的是，Hanneke的算法相当复杂，因为它返回许多经过精心选择的数据子集上训练的ERM分类器的多数投票。因此，最自然的目标是确定最简单的最优算法。在这项工作中，我们研究了可能最优的最简单算法：返回三个ERM分类器的多数投票。我们展示了这个算法实现了其错误的期望最优边界，这显然是单个ERM分类器无法达到的。此外，我们证明了该算法错误的近乎最优概率边界。我们推测更好的分析将证明这个算法实际上在高",
    "tldr": "该论文研究了可能最优的最简单算法：返回三个ERM分类器的多数投票，证明其实现了错误的期望最优边界，并得出近乎最优概率边界。",
    "en_tdlr": "This paper studies the possibly simplest optimal algorithm of returning the majority vote of three ERM classifiers, demonstrating its achievement of the optimal in-expectation bound on error and providing a near-optimal high-probability bound."
}