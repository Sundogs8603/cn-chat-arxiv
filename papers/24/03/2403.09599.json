{
    "title": "Logical Discrete Graphical Models Must Supplement Large Language Models for Information Synthesis",
    "abstract": "arXiv:2403.09599v1 Announce Type: new  Abstract: Given the emergent reasoning abilities of large language models, information retrieval is becoming more complex. Rather than just retrieve a document, modern information retrieval systems advertise that they can synthesize an answer based on potentially many different documents, conflicting data sources, and using reasoning. We review recent literature and argue that the large language model has crucial flaws that prevent it from on its own ever constituting general intelligence, or answering general information synthesis requests. This review shows that the following are problems for large language models: hallucinations, complex reasoning, planning under uncertainty, and complex calculations. We outline how logical discrete graphical models can solve all of these problems, and outline a method of training a logical discrete model from unlabeled text.",
    "link": "https://arxiv.org/abs/2403.09599",
    "context": "Title: Logical Discrete Graphical Models Must Supplement Large Language Models for Information Synthesis\nAbstract: arXiv:2403.09599v1 Announce Type: new  Abstract: Given the emergent reasoning abilities of large language models, information retrieval is becoming more complex. Rather than just retrieve a document, modern information retrieval systems advertise that they can synthesize an answer based on potentially many different documents, conflicting data sources, and using reasoning. We review recent literature and argue that the large language model has crucial flaws that prevent it from on its own ever constituting general intelligence, or answering general information synthesis requests. This review shows that the following are problems for large language models: hallucinations, complex reasoning, planning under uncertainty, and complex calculations. We outline how logical discrete graphical models can solve all of these problems, and outline a method of training a logical discrete model from unlabeled text.",
    "path": "papers/24/03/2403.09599.json",
    "total_tokens": 781,
    "translated_title": "逻辑离散图形模型必须为信息综合补充大语言模型",
    "translated_abstract": "鉴于大型语言模型的新兴推理能力，信息检索变得更加复杂。现代信息检索系统宣称他们可以基于潜在的多个不同文档、冲突的数据来源和推理来综合生成答案，而不仅仅是检索文档。我们审查了最近的文献，并认为大型语言模型有关键缺陷，使其不可能独立构成通用智能，或回答一般信息综合请求。这项审查显示大语言模型存在以下问题：幻觉、复杂推理、不确定性下的规划和复杂计算。我们概述了逻辑离散图形模型如何解决所有这些问题，并概述了从无标签文本训练逻辑离散模型的方法。",
    "tldr": "逻辑离散图形模型被认为是大型语言模型无法解决的问题的解决方案，能够解决幻觉、复杂推理、不确定性下的规划和复杂计算等问题。"
}