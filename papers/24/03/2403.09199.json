{
    "title": "Customizing Segmentation Foundation Model via Prompt Learning for Instance Segmentation",
    "abstract": "arXiv:2403.09199v1 Announce Type: cross  Abstract: Recently, foundation models trained on massive datasets to adapt to a wide range of domains have attracted considerable attention and are actively being explored within the computer vision community. Among these, the Segment Anything Model (SAM) stands out for its remarkable progress in generalizability and flexibility for image segmentation tasks, achieved through prompt-based object mask generation. However, despite its strength, SAM faces two key limitations when applied to customized instance segmentation that segments specific objects or those in unique environments not typically present in the training data: 1) the ambiguity inherent in input prompts and 2) the necessity for extensive additional training to achieve optimal segmentation. To address these challenges, we propose a novel method, customized instance segmentation via prompt learning tailored to SAM. Our method involves a prompt learning module (PLM), which adjusts inpu",
    "link": "https://arxiv.org/abs/2403.09199",
    "context": "Title: Customizing Segmentation Foundation Model via Prompt Learning for Instance Segmentation\nAbstract: arXiv:2403.09199v1 Announce Type: cross  Abstract: Recently, foundation models trained on massive datasets to adapt to a wide range of domains have attracted considerable attention and are actively being explored within the computer vision community. Among these, the Segment Anything Model (SAM) stands out for its remarkable progress in generalizability and flexibility for image segmentation tasks, achieved through prompt-based object mask generation. However, despite its strength, SAM faces two key limitations when applied to customized instance segmentation that segments specific objects or those in unique environments not typically present in the training data: 1) the ambiguity inherent in input prompts and 2) the necessity for extensive additional training to achieve optimal segmentation. To address these challenges, we propose a novel method, customized instance segmentation via prompt learning tailored to SAM. Our method involves a prompt learning module (PLM), which adjusts inpu",
    "path": "papers/24/03/2403.09199.json",
    "total_tokens": 849,
    "translated_title": "通过提示学习定制化分割基础模型进行实例分割",
    "translated_abstract": "最近，通过大规模数据集训练的基础模型吸引了相当多的关注，并在计算机视觉领域得到积极探讨。在这些模型中，Segment Anything Model (SAM)因其在图像分割任务中的泛化能力和灵活性而脱颖而出，通过基于提示的对象掩模生成取得了显著进展。然而，尽管SAM具有这些优势，在应用于定制化实例分割时（对特定对象或在训练数据中通常不存在的独特环境中进行分割），SAM面临两个关键限制：1）输入提示中固有的模糊性，2）为实现最佳分割需要大量额外训练。为解决这些挑战，我们提出了一种新颖的方法，即通过提示学习定制化实例分割，针对SAM进行了定制。我们的方法包含一个提示学习模块（PLM），可以调整输入。",
    "tldr": "提出了一种针对Segment Anything Model (SAM)的新颖方法，通过提示学习定制化实例分割，解决了在应用于定制化实例分割时面临的输入提示模糊性和额外训练需求的挑战",
    "en_tdlr": "Introduces a novel method tailored to Segment Anything Model (SAM), which addresses the challenges of input prompt ambiguity and the need for additional training when applied to customized instance segmentation."
}