{
    "title": "Alpaca against Vicuna: Using LLMs to Uncover Memorization of LLMs",
    "abstract": "arXiv:2403.04801v1 Announce Type: new  Abstract: In this paper, we introduce a black-box prompt optimization method that uses an attacker LLM agent to uncover higher levels of memorization in a victim agent, compared to what is revealed by prompting the target model with the training data directly, which is the dominant approach of quantifying memorization in LLMs. We use an iterative rejection-sampling optimization process to find instruction-based prompts with two main characteristics: (1) minimal overlap with the training data to avoid presenting the solution directly to the model, and (2) maximal overlap between the victim model's output and the training data, aiming to induce the victim to spit out training data. We observe that our instruction-based prompts generate outputs with 23.7% higher overlap with training data compared to the baseline prefix-suffix measurements. Our findings show that (1) instruction-tuned models can expose pre-training data as much as their base-models, ",
    "link": "https://arxiv.org/abs/2403.04801",
    "context": "Title: Alpaca against Vicuna: Using LLMs to Uncover Memorization of LLMs\nAbstract: arXiv:2403.04801v1 Announce Type: new  Abstract: In this paper, we introduce a black-box prompt optimization method that uses an attacker LLM agent to uncover higher levels of memorization in a victim agent, compared to what is revealed by prompting the target model with the training data directly, which is the dominant approach of quantifying memorization in LLMs. We use an iterative rejection-sampling optimization process to find instruction-based prompts with two main characteristics: (1) minimal overlap with the training data to avoid presenting the solution directly to the model, and (2) maximal overlap between the victim model's output and the training data, aiming to induce the victim to spit out training data. We observe that our instruction-based prompts generate outputs with 23.7% higher overlap with training data compared to the baseline prefix-suffix measurements. Our findings show that (1) instruction-tuned models can expose pre-training data as much as their base-models, ",
    "path": "papers/24/03/2403.04801.json",
    "total_tokens": 883,
    "translated_title": "Alpaca对抗Vicuna：使用LLMs揭示LLMs的记忆化",
    "translated_abstract": "在本文中，我们介绍了一种黑盒提示优化方法，该方法利用攻击者LLM代理来揭示受害代理中更高级别的记忆化，与直接用训练数据提示目标模型相比，这是量化LLMs记忆化的主导方法。我们使用迭代的拒绝抽样优化过程来找到基于指令的提示，具有两个主要特征：(1)与训练数据最小重叠，以避免直接向模型呈现解决方案，以及(2)受害模型输出与训练数据的最大重叠，旨在诱使受害者吐出训练数据。我们观察到，我们基于指令的提示生成的输出与训练数据重叠程度比基线前缀后缀测量高出23.7％。我们的发现表明，(1)经过指令调整的模型可以暴露与他们的基本模型一样多的预训练数据。",
    "tldr": "使用LLM代理进行黑盒提示优化方法，揭示了受害代理中更高级别的记忆化，相比直接用训练数据提示目标模型，这种方法更有效，能更好地量化LLMs的记忆化。"
}