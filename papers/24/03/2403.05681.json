{
    "title": "DP-TabICL: In-Context Learning with Differentially Private Tabular Data",
    "abstract": "arXiv:2403.05681v1 Announce Type: cross  Abstract: In-context learning (ICL) enables large language models (LLMs) to adapt to new tasks by conditioning on demonstrations of question-answer pairs and it has been shown to have comparable performance to costly model retraining and fine-tuning. Recently, ICL has been extended to allow tabular data to be used as demonstration examples by serializing individual records into natural language formats. However, it has been shown that LLMs can leak information contained in prompts, and since tabular data often contain sensitive information, understanding how to protect the underlying tabular data used in ICL is a critical area of research. This work serves as an initial investigation into how to use differential privacy (DP) -- the long-established gold standard for data privacy and anonymization -- to protect tabular data used in ICL. Specifically, we investigate the application of DP mechanisms for private tabular ICL via data privatization pr",
    "link": "https://arxiv.org/abs/2403.05681",
    "context": "Title: DP-TabICL: In-Context Learning with Differentially Private Tabular Data\nAbstract: arXiv:2403.05681v1 Announce Type: cross  Abstract: In-context learning (ICL) enables large language models (LLMs) to adapt to new tasks by conditioning on demonstrations of question-answer pairs and it has been shown to have comparable performance to costly model retraining and fine-tuning. Recently, ICL has been extended to allow tabular data to be used as demonstration examples by serializing individual records into natural language formats. However, it has been shown that LLMs can leak information contained in prompts, and since tabular data often contain sensitive information, understanding how to protect the underlying tabular data used in ICL is a critical area of research. This work serves as an initial investigation into how to use differential privacy (DP) -- the long-established gold standard for data privacy and anonymization -- to protect tabular data used in ICL. Specifically, we investigate the application of DP mechanisms for private tabular ICL via data privatization pr",
    "path": "papers/24/03/2403.05681.json",
    "total_tokens": 816,
    "translated_title": "使用不同ially Private Tabular Data进行环境中学习的DP-TabICL",
    "translated_abstract": "In-context learning (ICL)使得大型语言模型（LLM）通过在问题-答案对的示范条件下适应新任务，并且它已经表现出与昂贵的模型重新训练和微调相媲美的性能。最近，ICL已被扩展，允许使用表格数据作为示范示例，方法是将单个记录串行化为自然语言格式。然而，已经表明LLM可能会泄露提示中包含的信息，而且由于表格数据通常包含敏感信息，因此了解如何保护ICL中使用的基础表格数据是一个重要的研究领域。本文作为对如何使用差分隐私（DP）进行初始探索的研究--差分隐私是数据隐私和匿名化的长期金标准--以保护ICL中使用的表格数据。具体而言，我们研究了通过数据私有化机制在私有表格ICL中应用DP机制。",
    "tldr": "研究了如何使用差分隐私来保护在环境中学习中使用的表格数据。",
    "en_tdlr": "Investigated how to use differential privacy to protect tabular data used in in-context learning."
}