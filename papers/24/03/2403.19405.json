{
    "title": "Tabular Learning: Encoding for Entity and Context Embeddings",
    "abstract": "arXiv:2403.19405v1 Announce Type: cross  Abstract: Examining the effect of different encoding techniques on entity and context embeddings, the goal of this work is to challenge commonly used Ordinal encoding for tabular learning. Applying different preprocessing methods and network architectures over several datasets resulted in a benchmark on how the encoders influence the learning outcome of the networks. By keeping the test, validation and training data consistent, results have shown that ordinal encoding is not the most suited encoder for categorical data in terms of preprocessing the data and thereafter, classifying the target variable correctly. A better outcome was achieved, encoding the features based on string similarities by computing a similarity matrix as input for the network. This is the case for both, entity and context embeddings, where the transformer architecture showed improved performance for Ordinal and Similarity encoding with regard to multi-label classification ",
    "link": "https://arxiv.org/abs/2403.19405",
    "context": "Title: Tabular Learning: Encoding for Entity and Context Embeddings\nAbstract: arXiv:2403.19405v1 Announce Type: cross  Abstract: Examining the effect of different encoding techniques on entity and context embeddings, the goal of this work is to challenge commonly used Ordinal encoding for tabular learning. Applying different preprocessing methods and network architectures over several datasets resulted in a benchmark on how the encoders influence the learning outcome of the networks. By keeping the test, validation and training data consistent, results have shown that ordinal encoding is not the most suited encoder for categorical data in terms of preprocessing the data and thereafter, classifying the target variable correctly. A better outcome was achieved, encoding the features based on string similarities by computing a similarity matrix as input for the network. This is the case for both, entity and context embeddings, where the transformer architecture showed improved performance for Ordinal and Similarity encoding with regard to multi-label classification ",
    "path": "papers/24/03/2403.19405.json",
    "total_tokens": 765,
    "translated_title": "表格学习：实体和上下文嵌入的编码",
    "translated_abstract": "本文研究了不同编码技术对实体和上下文嵌入的影响，旨在挑战常用的序数编码在表格学习中的应用。通过在多个数据集上应用不同的预处理方法和网络架构，对编码器如何影响网络学习结果进行了评估。通过保持测试、验证和训练数据的一致性，结果表明，对于分类数据，序数编码并不是最合适的编码器，无法正确预处理数据并分类目标变量。通过基于字符串相似性对特征进行编码，计算相似性矩阵作为网络输入，取得了更好的结果。这适用于实体和上下文嵌入，在多标签分类中，变换器架构在序数编码和相似性编码方面表现出更好的性能。",
    "tldr": "挑战常用的序数编码，提出基于字符串相似性编码的表格学习方法，取得了更好的分类效果和性能提升。",
    "en_tdlr": "Challenging the commonly used ordinal encoding, this work proposes a tabular learning approach based on string similarity encoding, achieving better classification results and performance enhancements."
}