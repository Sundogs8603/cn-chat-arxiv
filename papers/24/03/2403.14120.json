{
    "title": "Advancing IIoT with Over-the-Air Federated Learning: The Role of Iterative Magnitude Pruning",
    "abstract": "arXiv:2403.14120v1 Announce Type: cross  Abstract: The industrial Internet of Things (IIoT) under Industry 4.0 heralds an era of interconnected smart devices where data-driven insights and machine learning (ML) fuse to revolutionize manufacturing. A noteworthy development in IIoT is the integration of federated learning (FL), which addresses data privacy and security among devices. FL enables edge sensors, also known as peripheral intelligence units (PIUs) to learn and adapt using their data locally, without explicit sharing of confidential data, to facilitate a collaborative yet confidential learning process. However, the lower memory footprint and computational power of PIUs inherently require deep neural network (DNN) models that have a very compact size. Model compression techniques such as pruning can be used to reduce the size of DNN models by removing unnecessary connections that have little impact on the model's performance, thus making the models more suitable for the limited ",
    "link": "https://arxiv.org/abs/2403.14120",
    "context": "Title: Advancing IIoT with Over-the-Air Federated Learning: The Role of Iterative Magnitude Pruning\nAbstract: arXiv:2403.14120v1 Announce Type: cross  Abstract: The industrial Internet of Things (IIoT) under Industry 4.0 heralds an era of interconnected smart devices where data-driven insights and machine learning (ML) fuse to revolutionize manufacturing. A noteworthy development in IIoT is the integration of federated learning (FL), which addresses data privacy and security among devices. FL enables edge sensors, also known as peripheral intelligence units (PIUs) to learn and adapt using their data locally, without explicit sharing of confidential data, to facilitate a collaborative yet confidential learning process. However, the lower memory footprint and computational power of PIUs inherently require deep neural network (DNN) models that have a very compact size. Model compression techniques such as pruning can be used to reduce the size of DNN models by removing unnecessary connections that have little impact on the model's performance, thus making the models more suitable for the limited ",
    "path": "papers/24/03/2403.14120.json",
    "total_tokens": 887,
    "translated_title": "用迭代幅值剪枝推进工业物联网的联邦学习",
    "translated_abstract": "工业物联网（IIoT）在工业4.0的背景下迎来了一种互联的智能设备时代，数据驱动的见解和机器学习（ML）融合，彻底改变了制造业。 IIoT中一个值得关注的发展是联邦学习（FL）的整合，该技术解决了设备之间数据隐私和安全性的问题。 FL使边缘传感器（也称为外围智能单元（PIUs））能够使用本地数据进行学习和适应，无需显式共享机密数据，从而促进协作但机密的学习过程。然而，PIUs较低的内存占用和计算能力固有地需要具有非常紫紧凑尺寸的深度神经网络（DNN）模型。剪枝等模型压缩技术可用于通过移除对模型性能影响较小的不必要连接来减小DNN模型的大小，从而使模型更适合有限的环境。",
    "tldr": "联邦学习在工业物联网中的应用促进了机器学习和数据隐私，本文提出了一种用于提升PIUs性能的迭代幅值剪枝技术。",
    "en_tdlr": "The integration of federated learning in the Industrial Internet of Things advances machine learning and data privacy, proposing an iterative magnitude pruning technique to enhance the performance of peripheral intelligence units (PIUs)."
}