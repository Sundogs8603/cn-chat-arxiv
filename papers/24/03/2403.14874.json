{
    "title": "WeatherProof: Leveraging Language Guidance for Semantic Segmentation in Adverse Weather",
    "abstract": "arXiv:2403.14874v1 Announce Type: cross  Abstract: We propose a method to infer semantic segmentation maps from images captured under adverse weather conditions. We begin by examining existing models on images degraded by weather conditions such as rain, fog, or snow, and found that they exhibit a large performance drop as compared to those captured under clear weather. To control for changes in scene structures, we propose WeatherProof, the first semantic segmentation dataset with accurate clear and adverse weather image pairs that share an underlying scene. Through this dataset, we analyze the error modes in existing models and found that they were sensitive to the highly complex combination of different weather effects induced on the image during capture. To improve robustness, we propose a way to use language as guidance by identifying contributions of adverse weather conditions and injecting that as \"side information\". Models trained using our language guidance exhibit performance",
    "link": "https://arxiv.org/abs/2403.14874",
    "context": "Title: WeatherProof: Leveraging Language Guidance for Semantic Segmentation in Adverse Weather\nAbstract: arXiv:2403.14874v1 Announce Type: cross  Abstract: We propose a method to infer semantic segmentation maps from images captured under adverse weather conditions. We begin by examining existing models on images degraded by weather conditions such as rain, fog, or snow, and found that they exhibit a large performance drop as compared to those captured under clear weather. To control for changes in scene structures, we propose WeatherProof, the first semantic segmentation dataset with accurate clear and adverse weather image pairs that share an underlying scene. Through this dataset, we analyze the error modes in existing models and found that they were sensitive to the highly complex combination of different weather effects induced on the image during capture. To improve robustness, we propose a way to use language as guidance by identifying contributions of adverse weather conditions and injecting that as \"side information\". Models trained using our language guidance exhibit performance",
    "path": "papers/24/03/2403.14874.json",
    "total_tokens": 833,
    "translated_title": "WeatherProof:借助语言指导在恶劣天气条件下进行语义分割",
    "translated_abstract": "我们提出了一种方法来推断在恶劣天气条件下拍摄的图像的语义分割图。我们首先检查了针对受天气条件（如雨、雾或雪）影响而降级的图像的现有模型，发现它们与在晴朗天气下拍摄的图像相比性能大幅下降。为了控制场景结构的变化，我们提出了WeatherProof，这是第一个具有准确的晴朗和恶劣天气图像对的语义分割数据集，它们共享相同的场景。通过这个数据集，我们分析了现有模型的错误模式，发现它们对在拍摄过程中施加在图像上的不同天气效应的高度复杂组合敏感。为了提高鲁棒性，我们提出了一种使用语言作为指导的方式，通过识别恶劣天气条件的影响并将其注入为“辅助信息”。使用我们的语言指导训练的模型表现",
    "tldr": "该论文提出了一种在恶劣天气条件下进行语义分割的方法，通过引入语言指导以提高模型的鲁棒性。",
    "en_tdlr": "This paper introduces a method for semantic segmentation under adverse weather conditions, improving model robustness by incorporating language guidance."
}