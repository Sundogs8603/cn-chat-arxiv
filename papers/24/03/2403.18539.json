{
    "title": "Safe and Robust Reinforcement-Learning: Principles and Practice",
    "abstract": "arXiv:2403.18539v1 Announce Type: new  Abstract: Reinforcement Learning (RL) has shown remarkable success in solving relatively complex tasks, yet the deployment of RL systems in real-world scenarios poses significant challenges related to safety and robustness. This paper aims to identify and further understand those challenges thorough the exploration of the main dimensions of the safe and robust RL landscape, encompassing algorithmic, ethical, and practical considerations. We conduct a comprehensive review of methodologies and open problems that summarizes the efforts in recent years to address the inherent risks associated with RL applications.   After discussing and proposing definitions for both safe and robust RL, the paper categorizes existing research works into different algorithmic approaches that enhance the safety and robustness of RL agents. We examine techniques such as uncertainty estimation, optimisation methodologies, exploration-exploitation trade-offs, and adversari",
    "link": "https://arxiv.org/abs/2403.18539",
    "context": "Title: Safe and Robust Reinforcement-Learning: Principles and Practice\nAbstract: arXiv:2403.18539v1 Announce Type: new  Abstract: Reinforcement Learning (RL) has shown remarkable success in solving relatively complex tasks, yet the deployment of RL systems in real-world scenarios poses significant challenges related to safety and robustness. This paper aims to identify and further understand those challenges thorough the exploration of the main dimensions of the safe and robust RL landscape, encompassing algorithmic, ethical, and practical considerations. We conduct a comprehensive review of methodologies and open problems that summarizes the efforts in recent years to address the inherent risks associated with RL applications.   After discussing and proposing definitions for both safe and robust RL, the paper categorizes existing research works into different algorithmic approaches that enhance the safety and robustness of RL agents. We examine techniques such as uncertainty estimation, optimisation methodologies, exploration-exploitation trade-offs, and adversari",
    "path": "papers/24/03/2403.18539.json",
    "total_tokens": 850,
    "translated_title": "安全稳健的强化学习: 原则与实践",
    "translated_abstract": "强化学习（RL）在解决相对复杂的任务方面取得了显著成功，然而在实际场景中部署RL系统面临与安全和稳健性有关的重大挑战。本文旨在通过探索安全和稳健RL领域的主要维度，涵盖算法、伦理和实际考虑因素，识别并进一步理解这些挑战。我们对近年来致力于解决与RL应用相关固有风险的方法和开放问题进行了全面审查。在讨论并提出安全和稳健RL的定义后，本文将现有研究工作归类为不同的算法方法，以增强RL代理的安全性和稳健性。我们考察了诸如不确定性估计、优化方法学、探索和利用的权衡以及对抗性等技术。",
    "tldr": "本文通过对安全和稳健RL领域的探索，识别并进一步理解了在实际场景中部署RL系统面临的重大挑战，提出了不同算法方法的综合评述以增强RL代理的安全性和稳健性。",
    "en_tdlr": "This paper identifies and further understands the significant challenges faced in deploying RL systems in real-world scenarios through exploration of the safe and robust RL landscape, and provides a comprehensive review of different algorithmic approaches to enhance the safety and robustness of RL agents."
}