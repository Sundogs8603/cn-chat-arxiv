{
    "title": "Parametric PDE Control with Deep Reinforcement Learning and Differentiable L0-Sparse Polynomial Policies",
    "abstract": "arXiv:2403.15267v1 Announce Type: new  Abstract: Optimal control of parametric partial differential equations (PDEs) is crucial in many applications in engineering and science. In recent years, the progress in scientific machine learning has opened up new frontiers for the control of parametric PDEs. In particular, deep reinforcement learning (DRL) has the potential to solve high-dimensional and complex control problems in a large variety of applications. Most DRL methods rely on deep neural network (DNN) control policies. However, for many dynamical systems, DNN-based control policies tend to be over-parametrized, which means they need large amounts of training data, show limited robustness, and lack interpretability. In this work, we leverage dictionary learning and differentiable L$_0$ regularization to learn sparse, robust, and interpretable control policies for parametric PDEs. Our sparse policy architecture is agnostic to the DRL method and can be used in different policy-gradien",
    "link": "https://arxiv.org/abs/2403.15267",
    "context": "Title: Parametric PDE Control with Deep Reinforcement Learning and Differentiable L0-Sparse Polynomial Policies\nAbstract: arXiv:2403.15267v1 Announce Type: new  Abstract: Optimal control of parametric partial differential equations (PDEs) is crucial in many applications in engineering and science. In recent years, the progress in scientific machine learning has opened up new frontiers for the control of parametric PDEs. In particular, deep reinforcement learning (DRL) has the potential to solve high-dimensional and complex control problems in a large variety of applications. Most DRL methods rely on deep neural network (DNN) control policies. However, for many dynamical systems, DNN-based control policies tend to be over-parametrized, which means they need large amounts of training data, show limited robustness, and lack interpretability. In this work, we leverage dictionary learning and differentiable L$_0$ regularization to learn sparse, robust, and interpretable control policies for parametric PDEs. Our sparse policy architecture is agnostic to the DRL method and can be used in different policy-gradien",
    "path": "papers/24/03/2403.15267.json",
    "total_tokens": 755,
    "translated_title": "使用深度强化学习和可微分L0稀疏多项式策略的参数PDE控制",
    "translated_abstract": "参数偏微分方程（PDE）的最优控制在工程和科学的许多应用中至关重要。近年来，科学机器学习的进展为参数PDE的控制开辟了新的前沿。特别是，深度强化学习（DRL）有望解决各种应用中的高维复杂控制问题。在这项工作中，我们利用字典学习和可微分L$_0$正则化来学习稀疏、鲁棒和可解释的参数PDE控制策略。",
    "tldr": "使用字典学习和可微分L$_0$正则化方法，本文提出了一种稀疏、鲁棒、可解释的控制策略，适用于参数PDE系统。",
    "en_tdlr": "This paper introduces a sparse, robust, and interpretable control strategy for parametric PDEs by utilizing dictionary learning and differentiable L$_0$ regularization."
}