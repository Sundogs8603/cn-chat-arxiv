{
    "title": "AlloyBERT: Alloy Property Prediction with Large Language Models",
    "abstract": "arXiv:2403.19783v1 Announce Type: cross  Abstract: The pursuit of novel alloys tailored to specific requirements poses significant challenges for researchers in the field. This underscores the importance of developing predictive techniques for essential physical properties of alloys based on their chemical composition and processing parameters. This study introduces AlloyBERT, a transformer encoder-based model designed to predict properties such as elastic modulus and yield strength of alloys using textual inputs. Leveraging the pre-trained RoBERTa encoder model as its foundation, AlloyBERT employs self-attention mechanisms to establish meaningful relationships between words, enabling it to interpret human-readable input and predict target alloy properties. By combining a tokenizer trained on our textual data and a RoBERTa encoder pre-trained and fine-tuned for this specific task, we achieved a mean squared error (MSE) of 0.00015 on the Multi Principal Elemental Alloys (MPEA) data set ",
    "link": "https://arxiv.org/abs/2403.19783",
    "context": "Title: AlloyBERT: Alloy Property Prediction with Large Language Models\nAbstract: arXiv:2403.19783v1 Announce Type: cross  Abstract: The pursuit of novel alloys tailored to specific requirements poses significant challenges for researchers in the field. This underscores the importance of developing predictive techniques for essential physical properties of alloys based on their chemical composition and processing parameters. This study introduces AlloyBERT, a transformer encoder-based model designed to predict properties such as elastic modulus and yield strength of alloys using textual inputs. Leveraging the pre-trained RoBERTa encoder model as its foundation, AlloyBERT employs self-attention mechanisms to establish meaningful relationships between words, enabling it to interpret human-readable input and predict target alloy properties. By combining a tokenizer trained on our textual data and a RoBERTa encoder pre-trained and fine-tuned for this specific task, we achieved a mean squared error (MSE) of 0.00015 on the Multi Principal Elemental Alloys (MPEA) data set ",
    "path": "papers/24/03/2403.19783.json",
    "total_tokens": 689,
    "translated_title": "使用大型语言模型的合金性能预测：AlloyBERT",
    "translated_abstract": "通过化学成分和处理参数，基于大型语言模型设计AlloyBERT模型来预测合金的弹性模量和屈服强度等性能，该模型利用预训练的RoBERTa编码器模型作为基础，通过自注意机制建立单词之间的有意义关系，从而解释可读的输入并预测合金性能。",
    "tldr": "AlloyBERT是一种基于Transformer编码器的模型，利用文本输入预测合金的弹性模量和屈服强度，结合预训练的RoBERTa编码器和训练有素的分词器，实现了在MPEA数据集上的低均方误差。",
    "en_tdlr": "AlloyBERT is a transformer encoder-based model that predicts properties such as elastic modulus and yield strength of alloys using textual inputs, achieving low mean squared error on the MPEA dataset by combining pre-trained RoBERTa encoder and trained tokenizer."
}