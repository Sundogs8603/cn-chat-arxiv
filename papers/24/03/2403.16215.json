{
    "title": "Systematic construction of continuous-time neural networks for linear dynamical systems",
    "abstract": "arXiv:2403.16215v1 Announce Type: new  Abstract: Discovering a suitable neural network architecture for modeling complex dynamical systems poses a formidable challenge, often involving extensive trial and error and navigation through a high-dimensional hyper-parameter space. In this paper, we discuss a systematic approach to constructing neural architectures for modeling a subclass of dynamical systems, namely, Linear Time-Invariant (LTI) systems. We use a variant of continuous-time neural networks in which the output of each neuron evolves continuously as a solution of a first-order or second-order Ordinary Differential Equation (ODE). Instead of deriving the network architecture and parameters from data, we propose a gradient-free algorithm to compute sparse architecture and network parameters directly from the given LTI system, leveraging its properties. We bring forth a novel neural architecture paradigm featuring horizontal hidden layers and provide insights into why employing con",
    "link": "https://arxiv.org/abs/2403.16215",
    "context": "Title: Systematic construction of continuous-time neural networks for linear dynamical systems\nAbstract: arXiv:2403.16215v1 Announce Type: new  Abstract: Discovering a suitable neural network architecture for modeling complex dynamical systems poses a formidable challenge, often involving extensive trial and error and navigation through a high-dimensional hyper-parameter space. In this paper, we discuss a systematic approach to constructing neural architectures for modeling a subclass of dynamical systems, namely, Linear Time-Invariant (LTI) systems. We use a variant of continuous-time neural networks in which the output of each neuron evolves continuously as a solution of a first-order or second-order Ordinary Differential Equation (ODE). Instead of deriving the network architecture and parameters from data, we propose a gradient-free algorithm to compute sparse architecture and network parameters directly from the given LTI system, leveraging its properties. We bring forth a novel neural architecture paradigm featuring horizontal hidden layers and provide insights into why employing con",
    "path": "papers/24/03/2403.16215.json",
    "total_tokens": 848,
    "translated_title": "连续时间神经网络系统化构建用于线性动力系统",
    "translated_abstract": "arXiv:2403.16215v1 公告类型：新摘要：发现适合模拟复杂动力系统的神经网络架构往往是一个艰巨的挑战，通常涉及大量的试错和在高维超参数空间中导航。在本文中，我们讨论了一种系统化构建神经网络架构的方法，用于模拟一类动力系统，即线性定常(LTI)系统。我们使用连续时间神经网络的变体，其中每个神经元的输出连续地演化为一阶或二阶常微分方程的解。我们提出了一个无梯度算法，直接从给定的LTI系统中计算稀疏的网络架构和网络参数，利用其特性，而不是从数据中推导网络架构和参数。我们提出了一个具有水平隐藏层的新型神经网络架构范式，并阐明了为什么使用con",
    "tldr": "提出了一种系统化构建神经网络架构的方法，用于模拟线性定常系统，并提出了一种无梯度算法，直接从给定的系统中计算稀疏的网络架构和参数，具有水平隐藏层的新型神经网络架构范式",
    "en_tdlr": "A systematic approach is proposed to construct neural network architectures for modeling linear time-invariant systems, with a gradient-free algorithm to compute sparse architecture and parameters directly from the given system, introducing a novel neural architecture paradigm featuring horizontal hidden layers."
}