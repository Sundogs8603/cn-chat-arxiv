{
    "title": "ODE Discovery for Longitudinal Heterogeneous Treatment Effects Inference",
    "abstract": "arXiv:2403.10766v1 Announce Type: new  Abstract: Inferring unbiased treatment effects has received widespread attention in the machine learning community. In recent years, our community has proposed numerous solutions in standard settings, high-dimensional treatment settings, and even longitudinal settings. While very diverse, the solution has mostly relied on neural networks for inference and simultaneous correction of assignment bias. New approaches typically build on top of previous approaches by proposing new (or refined) architectures and learning algorithms. However, the end result -- a neural-network-based inference machine -- remains unchallenged. In this paper, we introduce a different type of solution in the longitudinal setting: a closed-form ordinary differential equation (ODE). While we still rely on continuous optimization to learn an ODE, the resulting inference machine is no longer a neural network. Doing so yields several advantages such as interpretability, irregular ",
    "link": "https://arxiv.org/abs/2403.10766",
    "context": "Title: ODE Discovery for Longitudinal Heterogeneous Treatment Effects Inference\nAbstract: arXiv:2403.10766v1 Announce Type: new  Abstract: Inferring unbiased treatment effects has received widespread attention in the machine learning community. In recent years, our community has proposed numerous solutions in standard settings, high-dimensional treatment settings, and even longitudinal settings. While very diverse, the solution has mostly relied on neural networks for inference and simultaneous correction of assignment bias. New approaches typically build on top of previous approaches by proposing new (or refined) architectures and learning algorithms. However, the end result -- a neural-network-based inference machine -- remains unchallenged. In this paper, we introduce a different type of solution in the longitudinal setting: a closed-form ordinary differential equation (ODE). While we still rely on continuous optimization to learn an ODE, the resulting inference machine is no longer a neural network. Doing so yields several advantages such as interpretability, irregular ",
    "path": "papers/24/03/2403.10766.json",
    "total_tokens": 828,
    "translated_title": "横向异质性处理效应推断的ODE发现",
    "translated_abstract": "在机器学习社区中，推断无偏处理效应已经受到广泛关注。近年来，我们的社区针对标准设置、高维处理设置甚至纵向设置提出了许多解决方案。虽然解决方案非常多样化，但大多仍然依赖于神经网络进行推断和同时纠正分配偏差。新方法通常是在之前的方法基础上提出新的（或改进的）架构和学习算法。然而，最终结果——基于神经网络的推断机器——尚未受到挑战。在本文中，我们在纵向设置中引入了一种不同类型的解决方案：一个封闭形式的常微分方程（ODE）。虽然我们仍然依赖于连续优化来学习ODE，但得到的推断机器不再是神经网络。这样做带来了几个优势，比如可解释性，不规则性。",
    "tldr": "本文提出了一种在纵向设置中使用封闭形式常微分方程（ODE）的解决方案，相较于传统的神经网络推断，具有更好的可解释性和不规则性。"
}