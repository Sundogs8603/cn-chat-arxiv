{
    "title": "Theoretical Insights for Diffusion Guidance: A Case Study for Gaussian Mixture Models",
    "abstract": "arXiv:2403.01639v1 Announce Type: new  Abstract: Diffusion models benefit from instillation of task-specific information into the score function to steer the sample generation towards desired properties. Such information is coined as guidance. For example, in text-to-image synthesis, text input is encoded as guidance to generate semantically aligned images. Proper guidance inputs are closely tied to the performance of diffusion models. A common observation is that strong guidance promotes a tight alignment to the task-specific information, while reducing the diversity of the generated samples. In this paper, we provide the first theoretical study towards understanding the influence of guidance on diffusion models in the context of Gaussian mixture models. Under mild conditions, we prove that incorporating diffusion guidance not only boosts classification confidence but also diminishes distribution diversity, leading to a reduction in the differential entropy of the output distribution.",
    "link": "https://arxiv.org/abs/2403.01639",
    "context": "Title: Theoretical Insights for Diffusion Guidance: A Case Study for Gaussian Mixture Models\nAbstract: arXiv:2403.01639v1 Announce Type: new  Abstract: Diffusion models benefit from instillation of task-specific information into the score function to steer the sample generation towards desired properties. Such information is coined as guidance. For example, in text-to-image synthesis, text input is encoded as guidance to generate semantically aligned images. Proper guidance inputs are closely tied to the performance of diffusion models. A common observation is that strong guidance promotes a tight alignment to the task-specific information, while reducing the diversity of the generated samples. In this paper, we provide the first theoretical study towards understanding the influence of guidance on diffusion models in the context of Gaussian mixture models. Under mild conditions, we prove that incorporating diffusion guidance not only boosts classification confidence but also diminishes distribution diversity, leading to a reduction in the differential entropy of the output distribution.",
    "path": "papers/24/03/2403.01639.json",
    "total_tokens": 795,
    "translated_title": "Gaussian Mixture Models的扩散指导的理论洞见",
    "translated_abstract": "扩散模型受益于将特定任务信息注入评分函数以引导样本生成朝向所需属性。这种信息被称为指导。例如，在文本到图像合成中，文本输入被编码为指导以生成语义对齐的图像。适当的指导输入与扩散模型的性能密切相关。一个常见的观察是，强有力的指导促进了与任务特定信息的紧密对齐，同时减少了生成样本的多样性。本文首次在高斯混合模型背景下提供了对理解指导对扩散模型影响的理论研究。在温和的条件下，我们证明了将扩散指导纳入不仅提升了分类置信度，而且减少了分布多样性，导致输出分布的差异熵减少。",
    "tldr": "本文首次在高斯混合模型背景下进行理论研究，证明了将扩散指导纳入不仅提升了分类置信度，而且减少了分布多样性。",
    "en_tdlr": "This paper provides the first theoretical study on the influence of guidance on diffusion models in the context of Gaussian mixture models, showing that incorporating diffusion guidance boosts classification confidence and diminishes distribution diversity."
}