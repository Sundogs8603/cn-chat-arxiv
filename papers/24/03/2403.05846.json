{
    "title": "Diffusion Lens: Interpreting Text Encoders in Text-to-Image Pipelines",
    "abstract": "arXiv:2403.05846v1 Announce Type: cross  Abstract: Text-to-image diffusion models (T2I) use a latent representation of a text prompt to guide the image generation process. However, the process by which the encoder produces the text representation is unknown. We propose the Diffusion Lens, a method for analyzing the text encoder of T2I models by generating images from its intermediate representations. Using the Diffusion Lens, we perform an extensive analysis of two recent T2I models. Exploring compound prompts, we find that complex scenes describing multiple objects are composed progressively and more slowly compared to simple scenes; Exploring knowledge retrieval, we find that representation of uncommon concepts requires further computation compared to common concepts, and that knowledge retrieval is gradual across layers. Overall, our findings provide valuable insights into the text encoder component in T2I pipelines.",
    "link": "https://arxiv.org/abs/2403.05846",
    "context": "Title: Diffusion Lens: Interpreting Text Encoders in Text-to-Image Pipelines\nAbstract: arXiv:2403.05846v1 Announce Type: cross  Abstract: Text-to-image diffusion models (T2I) use a latent representation of a text prompt to guide the image generation process. However, the process by which the encoder produces the text representation is unknown. We propose the Diffusion Lens, a method for analyzing the text encoder of T2I models by generating images from its intermediate representations. Using the Diffusion Lens, we perform an extensive analysis of two recent T2I models. Exploring compound prompts, we find that complex scenes describing multiple objects are composed progressively and more slowly compared to simple scenes; Exploring knowledge retrieval, we find that representation of uncommon concepts requires further computation compared to common concepts, and that knowledge retrieval is gradual across layers. Overall, our findings provide valuable insights into the text encoder component in T2I pipelines.",
    "path": "papers/24/03/2403.05846.json",
    "total_tokens": 843,
    "translated_title": "扩散镜头：解释文本编码器在文本到图像管道中的作用",
    "translated_abstract": "arXiv:2403.05846v1 通告类型：跨 存在文本到图像扩散模型（T2I）使用文本提示的潜在表示来引导图像生成过程。然而，编码器产生文本表示的过程是未知的。我们提出了扩散镜头，一种分析 T2I 模型文本编码器的方法，通过生成其中间表示的图像。使用扩散镜头，我们对两个最近的 T2I 模型进行了广泛分析。在探索复合提示时，我们发现描述多个对象的复杂场景相对于简单场景是逐步且较慢地构建的；在探索知识检索时，我们发现表示不常见概念需要比常见概念更多的计算，并且知识检索在层之间是渐进的。总体而言，我们的发现为 T2I 管道中的文本编码器组件提供了宝贵的见解。",
    "tldr": "提出了一种分析文本到图像模型中文本编码器的方法，并通过生成中间表示的图像来深入研究，揭示了在复合提示和知识检索方面的一些重要发现。"
}