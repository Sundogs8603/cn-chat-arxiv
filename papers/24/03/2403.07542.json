{
    "title": "A Survey of Vision Transformers in Autonomous Driving: Current Trends and Future Directions",
    "abstract": "arXiv:2403.07542v1 Announce Type: cross  Abstract: This survey explores the adaptation of visual transformer models in Autonomous Driving, a transition inspired by their success in Natural Language Processing. Surpassing traditional Recurrent Neural Networks in tasks like sequential image processing and outperforming Convolutional Neural Networks in global context capture, as evidenced in complex scene recognition, Transformers are gaining traction in computer vision. These capabilities are crucial in Autonomous Driving for real-time, dynamic visual scene processing. Our survey provides a comprehensive overview of Vision Transformer applications in Autonomous Driving, focusing on foundational concepts such as self-attention, multi-head attention, and encoder-decoder architecture. We cover applications in object detection, segmentation, pedestrian detection, lane detection, and more, comparing their architectural merits and limitations. The survey concludes with future research directio",
    "link": "https://arxiv.org/abs/2403.07542",
    "context": "Title: A Survey of Vision Transformers in Autonomous Driving: Current Trends and Future Directions\nAbstract: arXiv:2403.07542v1 Announce Type: cross  Abstract: This survey explores the adaptation of visual transformer models in Autonomous Driving, a transition inspired by their success in Natural Language Processing. Surpassing traditional Recurrent Neural Networks in tasks like sequential image processing and outperforming Convolutional Neural Networks in global context capture, as evidenced in complex scene recognition, Transformers are gaining traction in computer vision. These capabilities are crucial in Autonomous Driving for real-time, dynamic visual scene processing. Our survey provides a comprehensive overview of Vision Transformer applications in Autonomous Driving, focusing on foundational concepts such as self-attention, multi-head attention, and encoder-decoder architecture. We cover applications in object detection, segmentation, pedestrian detection, lane detection, and more, comparing their architectural merits and limitations. The survey concludes with future research directio",
    "path": "papers/24/03/2403.07542.json",
    "total_tokens": 833,
    "translated_title": "自动驾驶中视觉Transformer的调研：当前趋势与未来发展方向",
    "translated_abstract": "这项调研探讨了在自动驾驶中采用视觉Transformer模型的适应性，这是受到它们在自然语言处理中取得成功的启发。Transformer模型在连续图像处理等任务中超越了传统的循环神经网络，并在全局上下文捕捉方面表现出色，如在复杂场景识别中表现优异，因此在计算机视觉领域中得到了认可。这些能力在自动驾驶中的实时、动态视觉场景处理中至关重要。我们的调研全面概述了自动驾驶中视觉Transformer的应用，重点关注自注意力、多头注意力和编码器-解码器架构等基础概念。我们涵盖了目标检测、分割、行人检测、车道检测等各种应用，比较它们的架构优点和局限性。调研最后探讨了未来的研究方向。",
    "tldr": "视觉Transformer模型在自动驾驶中的成功应用表明其在全局上下文捕捉方面的优势，对于实时、动态视觉场景处理具有关键意义。",
    "en_tdlr": "The successful application of Vision Transformers in autonomous driving demonstrates their advantage in capturing global context, which is crucial for real-time, dynamic visual scene processing."
}