{
    "title": "pyvene: A Library for Understanding and Improving PyTorch Models via Interventions",
    "abstract": "arXiv:2403.07809v1 Announce Type: cross  Abstract: Interventions on model-internal states are fundamental operations in many areas of AI, including model editing, steering, robustness, and interpretability. To facilitate such research, we introduce $\\textbf{pyvene}$, an open-source Python library that supports customizable interventions on a range of different PyTorch modules. $\\textbf{pyvene}$ supports complex intervention schemes with an intuitive configuration format, and its interventions can be static or include trainable parameters. We show how $\\textbf{pyvene}$ provides a unified and extensible framework for performing interventions on neural models and sharing the intervened upon models with others. We illustrate the power of the library via interpretability analyses using causal abstraction and knowledge localization. We publish our library through Python Package Index (PyPI) and provide code, documentation, and tutorials at https://github.com/stanfordnlp/pyvene.",
    "link": "https://arxiv.org/abs/2403.07809",
    "context": "Title: pyvene: A Library for Understanding and Improving PyTorch Models via Interventions\nAbstract: arXiv:2403.07809v1 Announce Type: cross  Abstract: Interventions on model-internal states are fundamental operations in many areas of AI, including model editing, steering, robustness, and interpretability. To facilitate such research, we introduce $\\textbf{pyvene}$, an open-source Python library that supports customizable interventions on a range of different PyTorch modules. $\\textbf{pyvene}$ supports complex intervention schemes with an intuitive configuration format, and its interventions can be static or include trainable parameters. We show how $\\textbf{pyvene}$ provides a unified and extensible framework for performing interventions on neural models and sharing the intervened upon models with others. We illustrate the power of the library via interpretability analyses using causal abstraction and knowledge localization. We publish our library through Python Package Index (PyPI) and provide code, documentation, and tutorials at https://github.com/stanfordnlp/pyvene.",
    "path": "papers/24/03/2403.07809.json",
    "total_tokens": 846,
    "translated_title": "pyvene: 通过干预来理解和改进PyTorch模型的库",
    "translated_abstract": "模型内部状态的干预是人工智能许多领域的基本操作，包括模型编辑、控制、稳健性和可解释性。为了促进这方面的研究，我们介绍了pyvene，一个开源的Python库，支持在各种不同PyTorch模块上进行可定制的干预。Pyvene支持复杂的干预方案，具有直观的配置格式，并且其干预可以是静态的或包含可训练参数。我们展示了pyvene如何提供一个统一和可扩展的框架，用于对神经模型进行干预并与他人共享经过干预的模型。我们通过因果抽象和知识定位的可解释性分析展示了该库的能力。我们通过Python Package Index（PyPI）发布了我们的库，并在https://github.com/stanfordnlp/pyvene 提供了代码、文档和教程。",
    "tldr": "pyvene是一个开源Python库，支持在PyTorch模型上进行可定制的干预，提供统一和可扩展的框架，用于解释神经模型并与他人分享经过干预的模型。",
    "en_tdlr": "pyvene is an open-source Python library that supports customizable interventions on PyTorch models, providing a unified and extensible framework for interpreting neural models and sharing intervened models with others."
}