{
    "title": "Multi-Agent Reinforcement Learning with a Hierarchy of Reward Machines",
    "abstract": "arXiv:2403.07005v1 Announce Type: new  Abstract: In this paper, we study the cooperative Multi-Agent Reinforcement Learning (MARL) problems using Reward Machines (RMs) to specify the reward functions such that the prior knowledge of high-level events in a task can be leveraged to facilitate the learning efficiency. Unlike the existing work that RMs have been incorporated into MARL for task decomposition and policy learning in relatively simple domains or with an assumption of independencies among the agents, we present Multi-Agent Reinforcement Learning with a Hierarchy of RMs (MAHRM) that is capable of dealing with more complex scenarios when the events among agents can occur concurrently and the agents are highly interdependent.   MAHRM exploits the relationship of high-level events to decompose a task into a hierarchy of simpler subtasks that are assigned to a small group of agents, so as to reduce the overall computational complexity.   Experimental results in three cooperative MAR",
    "link": "https://arxiv.org/abs/2403.07005",
    "context": "Title: Multi-Agent Reinforcement Learning with a Hierarchy of Reward Machines\nAbstract: arXiv:2403.07005v1 Announce Type: new  Abstract: In this paper, we study the cooperative Multi-Agent Reinforcement Learning (MARL) problems using Reward Machines (RMs) to specify the reward functions such that the prior knowledge of high-level events in a task can be leveraged to facilitate the learning efficiency. Unlike the existing work that RMs have been incorporated into MARL for task decomposition and policy learning in relatively simple domains or with an assumption of independencies among the agents, we present Multi-Agent Reinforcement Learning with a Hierarchy of RMs (MAHRM) that is capable of dealing with more complex scenarios when the events among agents can occur concurrently and the agents are highly interdependent.   MAHRM exploits the relationship of high-level events to decompose a task into a hierarchy of simpler subtasks that are assigned to a small group of agents, so as to reduce the overall computational complexity.   Experimental results in three cooperative MAR",
    "path": "papers/24/03/2403.07005.json",
    "total_tokens": 729,
    "translated_title": "具有奖励机器层次结构的多智能体强化学习",
    "translated_abstract": "在本文中，我们研究了利用奖励机器（RMs）来指定奖励函数，并通过这种方式利用任务中高级事件的先验知识来促进学习效率的合作式多智能体强化学习（MARL）问题。我们提出了具有层次结构奖励机器的多智能体强化学习（MAHRM），能够处理更复杂的场景，其中智能体之间的事件可以同时发生且互相依赖。",
    "tldr": "提出了具有层次结构奖励机器的多智能体强化学习（MAHRM），可以处理更复杂的情况，将任务分解为简单子任务的层次结构，以减少计算复杂性。",
    "en_tdlr": "Introduced Multi-Agent Reinforcement Learning with a Hierarchy of Reward Machines (MAHRM) capable of handling more complex scenarios by decomposing tasks into a hierarchy of simpler subtasks to reduce computational complexity."
}