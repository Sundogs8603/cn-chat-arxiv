{
    "title": "Training Unbiased Diffusion Models From Biased Dataset",
    "abstract": "arXiv:2403.01189v1 Announce Type: new  Abstract: With significant advancements in diffusion models, addressing the potential risks of dataset bias becomes increasingly important. Since generated outputs directly suffer from dataset bias, mitigating latent bias becomes a key factor in improving sample quality and proportion. This paper proposes time-dependent importance reweighting to mitigate the bias for the diffusion models. We demonstrate that the time-dependent density ratio becomes more precise than previous approaches, thereby minimizing error propagation in generative learning. While directly applying it to score-matching is intractable, we discover that using the time-dependent density ratio both for reweighting and score correction can lead to a tractable form of the objective function to regenerate the unbiased data density. Furthermore, we theoretically establish a connection with traditional score-matching, and we demonstrate its convergence to an unbiased distribution. The",
    "link": "https://arxiv.org/abs/2403.01189",
    "context": "Title: Training Unbiased Diffusion Models From Biased Dataset\nAbstract: arXiv:2403.01189v1 Announce Type: new  Abstract: With significant advancements in diffusion models, addressing the potential risks of dataset bias becomes increasingly important. Since generated outputs directly suffer from dataset bias, mitigating latent bias becomes a key factor in improving sample quality and proportion. This paper proposes time-dependent importance reweighting to mitigate the bias for the diffusion models. We demonstrate that the time-dependent density ratio becomes more precise than previous approaches, thereby minimizing error propagation in generative learning. While directly applying it to score-matching is intractable, we discover that using the time-dependent density ratio both for reweighting and score correction can lead to a tractable form of the objective function to regenerate the unbiased data density. Furthermore, we theoretically establish a connection with traditional score-matching, and we demonstrate its convergence to an unbiased distribution. The",
    "path": "papers/24/03/2403.01189.json",
    "total_tokens": 834,
    "translated_title": "从偏倚数据集中训练无偏扩散模型",
    "translated_abstract": "随着扩散模型的重大进展，解决数据集偏差的潜在风险变得越来越重要。由于生成的输出直接受到数据集偏差的影响，减轻潜在偏差成为改善样本质量和比例的关键因素。本文提出了一种基于时间的重要性重赋权方法来减轻扩散模型的偏差。我们证明了时间依赖密度比比以前的方法更精确，从而最小化了生成学习中的误差传播。虽然直接将其应用于得分匹配是不可行的，但我们发现使用时间依赖密度比既进行重新赋权又进行得分校正可以导致一种可解的目标函数形式，来重新生成无偏数据密度。此外，我们在理论上建立了与传统得分匹配的联系，并证明了它收敛到一个无偏分布。",
    "tldr": "提出了一种基于时间的重要性重赋权方法，以减轻扩散模型的偏差，并通过时间依赖密度比实现更准确的重赋权，从而最小化生成学习中的误差传播。"
}