{
    "title": "Efficient Information Extraction in Few-Shot Relation Classification through Contrastive Representation Learning",
    "abstract": "arXiv:2403.16543v1 Announce Type: cross  Abstract: Differentiating relationships between entity pairs with limited labeled instances poses a significant challenge in few-shot relation classification. Representations of textual data extract rich information spanning the domain, entities, and relations. In this paper, we introduce a novel approach to enhance information extraction combining multiple sentence representations and contrastive learning. While representations in relation classification are commonly extracted using entity marker tokens, we argue that substantial information within the internal model representations remains untapped. To address this, we propose aligning multiple sentence representations, such as the [CLS] token, the [MASK] token used in prompting, and entity marker tokens. Our method employs contrastive learning to extract complementary discriminative information from these individual representations. This is particularly relevant in low-resource settings where",
    "link": "https://arxiv.org/abs/2403.16543",
    "context": "Title: Efficient Information Extraction in Few-Shot Relation Classification through Contrastive Representation Learning\nAbstract: arXiv:2403.16543v1 Announce Type: cross  Abstract: Differentiating relationships between entity pairs with limited labeled instances poses a significant challenge in few-shot relation classification. Representations of textual data extract rich information spanning the domain, entities, and relations. In this paper, we introduce a novel approach to enhance information extraction combining multiple sentence representations and contrastive learning. While representations in relation classification are commonly extracted using entity marker tokens, we argue that substantial information within the internal model representations remains untapped. To address this, we propose aligning multiple sentence representations, such as the [CLS] token, the [MASK] token used in prompting, and entity marker tokens. Our method employs contrastive learning to extract complementary discriminative information from these individual representations. This is particularly relevant in low-resource settings where",
    "path": "papers/24/03/2403.16543.json",
    "total_tokens": 744,
    "translated_title": "通过对比表示学习提高少样本关系分类中的高效信息提取",
    "translated_abstract": "有限标记实例下的关系分类中区分实体对之间的关系构成少样本关系分类中的重大挑战。文本数据的表示提取了跨领域、实体和关系的丰富信息。在本文中，我们介绍了一种结合多个句子表示和对比学习以增强信息提取的新方法。尽管关系分类中通常使用实体标记令牌提取表示，但我们认为模型内部表示中存在大量未被利用的信息。为了解决这一问题，我们提出了对齐多个句子表示的方法，如[CLS]令牌、提示中使用的[MASK]令牌和实体标记令牌。我们的方法利用对比学习从这些个体表示中提取互补的判别信息。这在低资源环境中特别相关，其中",
    "tldr": "通过对比学习从多个句子表示中提取互补的判别信息，提高少样本关系分类中的信息提取效率",
    "en_tdlr": "Improving information extraction efficiency in few-shot relation classification through contrastive learning from multiple sentence representations."
}