{
    "title": "Robustifying and Boosting Training-Free Neural Architecture Search",
    "abstract": "arXiv:2403.07591v1 Announce Type: new  Abstract: Neural architecture search (NAS) has become a key component of AutoML and a standard tool to automate the design of deep neural networks. Recently, training-free NAS as an emerging paradigm has successfully reduced the search costs of standard training-based NAS by estimating the true architecture performance with only training-free metrics. Nevertheless, the estimation ability of these metrics typically varies across different tasks, making it challenging to achieve robust and consistently good search performance on diverse tasks with only a single training-free metric. Meanwhile, the estimation gap between training-free metrics and the true architecture performances limits training-free NAS to achieve superior performance. To address these challenges, we propose the robustifying and boosting training-free NAS (RoBoT) algorithm which (a) employs the optimized combination of existing training-free metrics explored from Bayesian optimizat",
    "link": "https://arxiv.org/abs/2403.07591",
    "context": "Title: Robustifying and Boosting Training-Free Neural Architecture Search\nAbstract: arXiv:2403.07591v1 Announce Type: new  Abstract: Neural architecture search (NAS) has become a key component of AutoML and a standard tool to automate the design of deep neural networks. Recently, training-free NAS as an emerging paradigm has successfully reduced the search costs of standard training-based NAS by estimating the true architecture performance with only training-free metrics. Nevertheless, the estimation ability of these metrics typically varies across different tasks, making it challenging to achieve robust and consistently good search performance on diverse tasks with only a single training-free metric. Meanwhile, the estimation gap between training-free metrics and the true architecture performances limits training-free NAS to achieve superior performance. To address these challenges, we propose the robustifying and boosting training-free NAS (RoBoT) algorithm which (a) employs the optimized combination of existing training-free metrics explored from Bayesian optimizat",
    "path": "papers/24/03/2403.07591.json",
    "total_tokens": 797,
    "translated_title": "强化和增强无训练神经架构搜索",
    "translated_abstract": "神经架构搜索（NAS）已成为AutoML的关键组件和自动设计深度神经网络的标准工具。最近，作为新兴范式的无训练NAS通过仅使用无训练指标估计真实架构性能，成功降低了标准基于训练NAS的搜索成本。然而，这些指标的估计能力通常在不同任务间变化，使得仅使用单一无训练指标在多样任务上实现稳健和一致良好的搜索性能具有挑战性。与此同时，无训练指标与真实架构性能之间的估计差距限制了无训练NAS实现卓越性能。为解决这些挑战，我们提出了强化和增强无训练NAS（RoBoT）算法，该算法（a）利用从贝叶斯优化中探索出的现有无训练指标的优化组合",
    "tldr": "提出了RoBoT算法，旨在解决无训练神经架构搜索中指标估计不准确和性能限制的问题",
    "en_tdlr": "Proposed the RoBoT algorithm to address the issues of inaccurate metric estimation and performance limitations in training-free neural architecture search."
}