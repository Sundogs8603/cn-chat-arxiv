{
    "title": "Uncertainty Quantification for cross-subject Motor Imagery classification",
    "abstract": "arXiv:2403.09228v1 Announce Type: new  Abstract: Uncertainty Quantification aims to determine when the prediction from a Machine Learning model is likely to be wrong. Computer Vision research has explored methods for determining epistemic uncertainty (also known as model uncertainty), which should correspond with generalisation error. These methods theoretically allow to predict misclassifications due to inter-subject variability. We applied a variety of Uncertainty Quantification methods to predict misclassifications for a Motor Imagery Brain Computer Interface. Deep Ensembles performed best, both in terms of classification performance and cross-subject Uncertainty Quantification performance. However, we found that standard CNNs with Softmax output performed better than some of the more advanced methods.",
    "link": "https://arxiv.org/abs/2403.09228",
    "context": "Title: Uncertainty Quantification for cross-subject Motor Imagery classification\nAbstract: arXiv:2403.09228v1 Announce Type: new  Abstract: Uncertainty Quantification aims to determine when the prediction from a Machine Learning model is likely to be wrong. Computer Vision research has explored methods for determining epistemic uncertainty (also known as model uncertainty), which should correspond with generalisation error. These methods theoretically allow to predict misclassifications due to inter-subject variability. We applied a variety of Uncertainty Quantification methods to predict misclassifications for a Motor Imagery Brain Computer Interface. Deep Ensembles performed best, both in terms of classification performance and cross-subject Uncertainty Quantification performance. However, we found that standard CNNs with Softmax output performed better than some of the more advanced methods.",
    "path": "papers/24/03/2403.09228.json",
    "total_tokens": 737,
    "translated_title": "跨受试者运动想象分类的不确定性量化",
    "translated_abstract": "不确定性量化旨在确定机器学习模型的预测何时可能出错。计算机视觉研究探索了确定认知不确定性（也称为模型不确定性）的方法，这应与泛化误差相对应。这些方法理论上可用于预测由受试者间变异性引起的错分。我们应用了各种不确定性量化方法来预测脑机接口中的错分。深度集成在分类性能和跨受试者不确定性量化性能方面表现最好。然而，我们发现具有Softmax输出的标准CNN优于一些更先进的方法。",
    "tldr": "本研究针对跨受试者的运动想象分类，引入不确定性量化方法，验证了深度集成在分类性能和跨受试者不确定性量化性能上的优越表现，同时发现标准CNN方法在某些情况下表现更好。",
    "en_tdlr": "This study introduces Uncertainty Quantification methods for cross-subject motor imagery classification, demonstrates the superior performance of Deep Ensembles in both classification and cross-subject uncertainty quantification, while also finding that standard CNNs outperformed some advanced methods in certain scenarios."
}