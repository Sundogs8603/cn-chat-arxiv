{
    "title": "Re2LLM: Reflective Reinforcement Large Language Model for Session-based Recommendation",
    "abstract": "arXiv:2403.16427v1 Announce Type: new  Abstract: Large Language Models (LLMs) are emerging as promising approaches to enhance session-based recommendation (SBR), where both prompt-based and fine-tuning-based methods have been widely investigated to align LLMs with SBR.   However, the former methods struggle with optimal prompts to elicit the correct reasoning of LLMs due to the lack of task-specific feedback, leading to unsatisfactory recommendations.   Although the latter methods attempt to fine-tune LLMs with domain-specific knowledge, they face limitations such as high computational costs and reliance on open-source backbones.   To address such issues, we propose a \\underline{Re}flective \\underline{Re}inforcement \\underline{L}arge \\underline{L}anguage \\underline{M}odel (Re2LLM) for SBR, guiding LLMs to focus on specialized knowledge essential for more accurate recommendations effectively and efficiently.   In particular, we first design the Reflective Exploration Module to effective",
    "link": "https://arxiv.org/abs/2403.16427",
    "context": "Title: Re2LLM: Reflective Reinforcement Large Language Model for Session-based Recommendation\nAbstract: arXiv:2403.16427v1 Announce Type: new  Abstract: Large Language Models (LLMs) are emerging as promising approaches to enhance session-based recommendation (SBR), where both prompt-based and fine-tuning-based methods have been widely investigated to align LLMs with SBR.   However, the former methods struggle with optimal prompts to elicit the correct reasoning of LLMs due to the lack of task-specific feedback, leading to unsatisfactory recommendations.   Although the latter methods attempt to fine-tune LLMs with domain-specific knowledge, they face limitations such as high computational costs and reliance on open-source backbones.   To address such issues, we propose a \\underline{Re}flective \\underline{Re}inforcement \\underline{L}arge \\underline{L}anguage \\underline{M}odel (Re2LLM) for SBR, guiding LLMs to focus on specialized knowledge essential for more accurate recommendations effectively and efficiently.   In particular, we first design the Reflective Exploration Module to effective",
    "path": "papers/24/03/2403.16427.json",
    "total_tokens": 851,
    "translated_title": "Re2LLM: 反射式强化大型语言模型用于基于会话的推荐",
    "translated_abstract": "大型语言模型(LLMs)正日益被看作是增强基于会话推荐(SBR)的有前途的方法，其中已广泛研究了基于提示和微调的方法，以使LLMs与SBR对齐。然而，前者因缺乏任务特定反馈而难以找到引导LLMs正确推理的最佳提示，导致推荐结果不佳。尽管后者试图用领域特定知识微调LLMs，但它们面临诸如高计算成本和依赖开源骨干的限制。为解决这些问题，我们提出了一种用于SBR的反射式强化大型语言模型(Re2LLM)，引导LLMs专注于更准确推荐所需的专业知识，实现有效和高效。具体来说，我们首先设计了反射式探索模块",
    "tldr": "Re2LLM是为基于会话的推荐提出的反射式强化大型语言模型，引导LLMs专注于更准确推荐所需的专业知识，实现有效和高效。",
    "en_tdlr": "Re2LLM is a reflective reinforcement large language model proposed for session-based recommendation, guiding LLMs to focus on specialized knowledge essential for more accurate recommendations effectively and efficiently."
}