{
    "title": "Physics-informed RL for Maximal Safety Probability Estimation",
    "abstract": "arXiv:2403.16391v1 Announce Type: cross  Abstract: Accurate risk quantification and reachability analysis are crucial for safe control and learning, but sampling from rare events, risky states, or long-term trajectories can be prohibitively costly. Motivated by this, we study how to estimate the long-term safety probability of maximally safe actions without sufficient coverage of samples from risky states and long-term trajectories. The use of maximal safety probability in control and learning is expected to avoid conservative behaviors due to over-approximation of risk. Here, we first show that long-term safety probability, which is multiplicative in time, can be converted into additive costs and be solved using standard reinforcement learning methods. We then derive this probability as solutions of partial differential equations (PDEs) and propose Physics-Informed Reinforcement Learning (PIRL) algorithm. The proposed method can learn using sparse rewards because the physics constrain",
    "link": "https://arxiv.org/abs/2403.16391",
    "context": "Title: Physics-informed RL for Maximal Safety Probability Estimation\nAbstract: arXiv:2403.16391v1 Announce Type: cross  Abstract: Accurate risk quantification and reachability analysis are crucial for safe control and learning, but sampling from rare events, risky states, or long-term trajectories can be prohibitively costly. Motivated by this, we study how to estimate the long-term safety probability of maximally safe actions without sufficient coverage of samples from risky states and long-term trajectories. The use of maximal safety probability in control and learning is expected to avoid conservative behaviors due to over-approximation of risk. Here, we first show that long-term safety probability, which is multiplicative in time, can be converted into additive costs and be solved using standard reinforcement learning methods. We then derive this probability as solutions of partial differential equations (PDEs) and propose Physics-Informed Reinforcement Learning (PIRL) algorithm. The proposed method can learn using sparse rewards because the physics constrain",
    "path": "papers/24/03/2403.16391.json",
    "total_tokens": 824,
    "translated_title": "物理信息强化强化学习用于最大安全概率估计",
    "translated_abstract": "精确的风险量化和可达性分析对于安全控制和学习至关重要，但从稀有事件、风险状态或长期轨迹中采样可能成本过高。我们研究了如何在没有足够覆盖来自风险状态和长期轨迹的样本的情况下估计最大安全行动的长期安全概率。在控制和学习中使用最大安全概率预计可以避免由于风险过度逼近而导致的保守行为。我们首先展示了长期安全概率可以转化为加法成本并且可以使用标准强化学习方法来解决。然后我们将这个概率推导为偏微分方程（PDE）的解，并提出了物理信息强化学习（PIRL）算法。所提出的方法可以使用稀疏奖励进行学习，因为物理约束。",
    "tldr": "利用物理信息强化学习算法可以估计最大安全行动的长期安全概率，避免风险过度逼近导致的保守行为"
}