{
    "title": "A Multimodal Intermediate Fusion Network with Manifold Learning for Stress Detection",
    "abstract": "arXiv:2403.08077v1 Announce Type: cross  Abstract: Multimodal deep learning methods capture synergistic features from multiple modalities and have the potential to improve accuracy for stress detection compared to unimodal methods. However, this accuracy gain typically comes from high computational cost due to the high-dimensional feature spaces, especially for intermediate fusion. Dimensionality reduction is one way to optimize multimodal learning by simplifying data and making the features more amenable to processing and analysis, thereby reducing computational complexity. This paper introduces an intermediate multimodal fusion network with manifold learning-based dimensionality reduction. The multimodal network generates independent representations from biometric signals and facial landmarks through 1D-CNN and 2D-CNN. Finally, these features are fused and fed to another 1D-CNN layer, followed by a fully connected dense layer. We compared various dimensionality reduction techniques f",
    "link": "https://arxiv.org/abs/2403.08077",
    "context": "Title: A Multimodal Intermediate Fusion Network with Manifold Learning for Stress Detection\nAbstract: arXiv:2403.08077v1 Announce Type: cross  Abstract: Multimodal deep learning methods capture synergistic features from multiple modalities and have the potential to improve accuracy for stress detection compared to unimodal methods. However, this accuracy gain typically comes from high computational cost due to the high-dimensional feature spaces, especially for intermediate fusion. Dimensionality reduction is one way to optimize multimodal learning by simplifying data and making the features more amenable to processing and analysis, thereby reducing computational complexity. This paper introduces an intermediate multimodal fusion network with manifold learning-based dimensionality reduction. The multimodal network generates independent representations from biometric signals and facial landmarks through 1D-CNN and 2D-CNN. Finally, these features are fused and fed to another 1D-CNN layer, followed by a fully connected dense layer. We compared various dimensionality reduction techniques f",
    "path": "papers/24/03/2403.08077.json",
    "total_tokens": 874,
    "translated_title": "一种具有流形学习的多模态中间融合网络用于压力检测",
    "translated_abstract": "多模态深度学习方法从多个模态中捕获协同特征，并且与单模态方法相比，具有提高压力检测准确性的潜力。然而，这种准确性提升通常来自于高计算成本，原因是高维特征空间，尤其对于中间融合。降维是优化多模态学习的一种方式，通过简化数据并使特征更易于处理和分析，从而降低计算复杂性。本文介绍了一种具有基于流形学习的维度降低的中间多模态融合网络。多模态网络通过1D-CNN和2D-CNN从生物特征信号和面部标记生成独立表示。最后，这些特征被融合并馈送给另一个1D-CNN层，然后是一个全连接的稠密层。我们比较了各种维度减少技术。",
    "tldr": "该论文提出了一种具有流形学习的中间多模态融合网络，从多个模态中捕获协同特征，并通过维度降低优化多模态学习，提高压力检测准确性，同时减少计算复杂性。",
    "en_tdlr": "This paper introduces an intermediate multimodal fusion network with manifold learning-based dimensionality reduction, capturing synergistic features from multiple modalities, optimizing multimodal learning through dimensionality reduction, enhancing stress detection accuracy, while reducing computational complexity."
}