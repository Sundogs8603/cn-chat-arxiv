{
    "title": "DP-Dueling: Learning from Preference Feedback without Compromising User Privacy",
    "abstract": "arXiv:2403.15045v1 Announce Type: new  Abstract: We consider the well-studied dueling bandit problem, where a learner aims to identify near-optimal actions using pairwise comparisons, under the constraint of differential privacy. We consider a general class of utility-based preference matrices for large (potentially unbounded) decision spaces and give the first differentially private dueling bandit algorithm for active learning with user preferences. Our proposed algorithms are computationally efficient with near-optimal performance, both in terms of the private and non-private regret bound. More precisely, we show that when the decision space is of finite size $K$, our proposed algorithm yields order optimal $O\\Big(\\sum_{i = 2}^K\\log\\frac{KT}{\\Delta_i} + \\frac{K}{\\epsilon}\\Big)$ regret bound for pure $\\epsilon$-DP, where $\\Delta_i$ denotes the suboptimality gap of the $i$-th arm. We also present a matching lower bound analysis which proves the optimality of our algorithms. Finally, we",
    "link": "https://arxiv.org/abs/2403.15045",
    "context": "Title: DP-Dueling: Learning from Preference Feedback without Compromising User Privacy\nAbstract: arXiv:2403.15045v1 Announce Type: new  Abstract: We consider the well-studied dueling bandit problem, where a learner aims to identify near-optimal actions using pairwise comparisons, under the constraint of differential privacy. We consider a general class of utility-based preference matrices for large (potentially unbounded) decision spaces and give the first differentially private dueling bandit algorithm for active learning with user preferences. Our proposed algorithms are computationally efficient with near-optimal performance, both in terms of the private and non-private regret bound. More precisely, we show that when the decision space is of finite size $K$, our proposed algorithm yields order optimal $O\\Big(\\sum_{i = 2}^K\\log\\frac{KT}{\\Delta_i} + \\frac{K}{\\epsilon}\\Big)$ regret bound for pure $\\epsilon$-DP, where $\\Delta_i$ denotes the suboptimality gap of the $i$-th arm. We also present a matching lower bound analysis which proves the optimality of our algorithms. Finally, we",
    "path": "papers/24/03/2403.15045.json",
    "total_tokens": 938,
    "translated_title": "DP-Dueling: 在不损害用户隐私的情况下从偏好反馈中学习",
    "translated_abstract": "我们考虑了广泛研究的对抗式双臂老虎机问题，其中学习者旨在使用成对比较来识别近似最优动作，同时受到差分隐私的约束。我们考虑了大型（可能是无界的）决策空间的基于效用的偏好矩阵的一般类，并为带有用户偏好的主动学习提供了第一个差分私密对抗式双臂老虎机算法。我们提出的算法在计算效率方面表现出色，并在私密和非私密遗憾上都接近最优性能。更确切地说，当决策空间是有限大小$K$时，我们提出的算法为纯$\\epsilon$-DP产生了顺序最优$O\\Big(\\sum_{i = 2}^K\\log\\frac{KT}{\\Delta_i} + \\frac{K}{\\epsilon}\\Big)$遗憾上界，其中$\\Delta_i$表示第$i$个臂的次优差距。我们还提供了一致的下界分析，证明了我们算法的最优性。",
    "tldr": "提出了第一个针对带用户偏好的主动学习的差分私密对抗式双臂老虎机算法，并在计算效率方面表现优异，同时具有接近最优的私密和非私密遗憾上界。",
    "en_tdlr": "Proposed the first differentially private dueling bandit algorithm for active learning with user preferences, which is computationally efficient with near-optimal performance in terms of private and non-private regret bound."
}