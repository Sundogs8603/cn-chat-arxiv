{
    "title": "Learning Generalizable Feature Fields for Mobile Manipulation",
    "abstract": "arXiv:2403.07563v1 Announce Type: cross  Abstract: An open problem in mobile manipulation is how to represent objects and scenes in a unified manner, so that robots can use it both for navigating in the environment and manipulating objects. The latter requires capturing intricate geometry while understanding fine-grained semantics, whereas the former involves capturing the complexity inherit to an expansive physical scale. In this work, we present GeFF (Generalizable Feature Fields), a scene-level generalizable neural feature field that acts as a unified representation for both navigation and manipulation that performs in real-time. To do so, we treat generative novel view synthesis as a pre-training task, and then align the resulting rich scene priors with natural language via CLIP feature distillation. We demonstrate the effectiveness of this approach by deploying GeFF on a quadrupedal robot equipped with a manipulator. We evaluate GeFF's ability to generalize to open-set objects as ",
    "link": "https://arxiv.org/abs/2403.07563",
    "context": "Title: Learning Generalizable Feature Fields for Mobile Manipulation\nAbstract: arXiv:2403.07563v1 Announce Type: cross  Abstract: An open problem in mobile manipulation is how to represent objects and scenes in a unified manner, so that robots can use it both for navigating in the environment and manipulating objects. The latter requires capturing intricate geometry while understanding fine-grained semantics, whereas the former involves capturing the complexity inherit to an expansive physical scale. In this work, we present GeFF (Generalizable Feature Fields), a scene-level generalizable neural feature field that acts as a unified representation for both navigation and manipulation that performs in real-time. To do so, we treat generative novel view synthesis as a pre-training task, and then align the resulting rich scene priors with natural language via CLIP feature distillation. We demonstrate the effectiveness of this approach by deploying GeFF on a quadrupedal robot equipped with a manipulator. We evaluate GeFF's ability to generalize to open-set objects as ",
    "path": "papers/24/03/2403.07563.json",
    "total_tokens": 691,
    "translated_title": "学习移动操作的通用特征场",
    "translated_abstract": "移动操作中的一个悬而未决的问题是如何以统一的方式表示物体和场景，使得机器人可以同时用于在环境中导航和操作物体。本工作提出了GeFF（通用特征场），这是一个场景级的通用神经特征场，作为导航和操作的统一表示，可以实时执行。为此，我们将生成新视图合成视为一个预训练任务，然后通过CLIP特征提炼将生成的丰富场景先验与自然语言对齐。",
    "tldr": "提出了GeFF（通用特征场），作为导航和操作的统一表示，可以实时执行，通过将生成的丰富场景先验与自然语言对齐来提高效果。",
    "en_tdlr": "Introduced GeFF as a unified representation for navigation and manipulation, capable of real-time execution, by aligning rich scene priors with natural language."
}