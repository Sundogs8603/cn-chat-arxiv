{
    "title": "CTSM: Combining Trait and State Emotions for Empathetic Response Model",
    "abstract": "arXiv:2403.15516v1 Announce Type: cross  Abstract: Empathetic response generation endeavors to empower dialogue systems to perceive speakers' emotions and generate empathetic responses accordingly. Psychological research demonstrates that emotion, as an essential factor in empathy, encompasses trait emotions, which are static and context-independent, and state emotions, which are dynamic and context-dependent. However, previous studies treat them in isolation, leading to insufficient emotional perception of the context, and subsequently, less effective empathetic expression. To address this problem, we propose Combining Trait and State emotions for Empathetic Response Model (CTSM). Specifically, to sufficiently perceive emotions in dialogue, we first construct and encode trait and state emotion embeddings, and then we further enhance emotional perception capability through an emotion guidance module that guides emotion representation. In addition, we propose a cross-contrastive learnin",
    "link": "https://arxiv.org/abs/2403.15516",
    "context": "Title: CTSM: Combining Trait and State Emotions for Empathetic Response Model\nAbstract: arXiv:2403.15516v1 Announce Type: cross  Abstract: Empathetic response generation endeavors to empower dialogue systems to perceive speakers' emotions and generate empathetic responses accordingly. Psychological research demonstrates that emotion, as an essential factor in empathy, encompasses trait emotions, which are static and context-independent, and state emotions, which are dynamic and context-dependent. However, previous studies treat them in isolation, leading to insufficient emotional perception of the context, and subsequently, less effective empathetic expression. To address this problem, we propose Combining Trait and State emotions for Empathetic Response Model (CTSM). Specifically, to sufficiently perceive emotions in dialogue, we first construct and encode trait and state emotion embeddings, and then we further enhance emotional perception capability through an emotion guidance module that guides emotion representation. In addition, we propose a cross-contrastive learnin",
    "path": "papers/24/03/2403.15516.json",
    "total_tokens": 823,
    "translated_title": "CTSM：将特质和状态情绪相结合的共情响应模型",
    "translated_abstract": "共情性响应生成旨在赋予对话系统感知说话者情绪并相应生成共情性回应的能力。心理研究表明，作为共情的一个重要因素，情绪包括特质情绪（静态且与环境无关）和状态情绪（动态且与环境相关）。然而，先前的研究将它们单独处理，导致对情境情绪的感知不足，进而影响了有效的共情表达。为解决这一问题，我们提出了将特质和状态情绪相结合的共情响应模型（CTSM）。具体来说，为了充分感知对话中的情绪，我们首先构建和编码特质和状态情绪嵌入，然后通过一个情绪引导模块进一步增强情绪感知能力，该模块指导情绪表达。此外，我们提出了一种交叉对比学习。",
    "tldr": "CTSM模型结合特质和状态情绪，通过构建和编码情绪嵌入以及引入情绪引导模块，解决了先前处理情绪感知不足的问题。",
    "en_tdlr": "The CTSM model combines trait and state emotions, addressing the issue of insufficient emotional perception by constructing and encoding emotion embeddings, and introducing an emotion guidance module."
}