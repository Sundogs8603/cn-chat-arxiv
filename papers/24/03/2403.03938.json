{
    "title": "GUIDE: Guidance-based Incremental Learning with Diffusion Models",
    "abstract": "arXiv:2403.03938v1 Announce Type: new  Abstract: We introduce GUIDE, a novel continual learning approach that directs diffusion models to rehearse samples at risk of being forgotten. Existing generative strategies combat catastrophic forgetting by randomly sampling rehearsal examples from a generative model. Such an approach contradicts buffer-based approaches where sampling strategy plays an important role. We propose to bridge this gap by integrating diffusion models with classifier guidance techniques to produce rehearsal examples specifically targeting information forgotten by a continuously trained model. This approach enables the generation of samples from preceding task distributions, which are more likely to be misclassified in the context of recently encountered classes. Our experimental results show that GUIDE significantly reduces catastrophic forgetting, outperforming conventional random sampling approaches and surpassing recent state-of-the-art methods in continual learnin",
    "link": "https://arxiv.org/abs/2403.03938",
    "context": "Title: GUIDE: Guidance-based Incremental Learning with Diffusion Models\nAbstract: arXiv:2403.03938v1 Announce Type: new  Abstract: We introduce GUIDE, a novel continual learning approach that directs diffusion models to rehearse samples at risk of being forgotten. Existing generative strategies combat catastrophic forgetting by randomly sampling rehearsal examples from a generative model. Such an approach contradicts buffer-based approaches where sampling strategy plays an important role. We propose to bridge this gap by integrating diffusion models with classifier guidance techniques to produce rehearsal examples specifically targeting information forgotten by a continuously trained model. This approach enables the generation of samples from preceding task distributions, which are more likely to be misclassified in the context of recently encountered classes. Our experimental results show that GUIDE significantly reduces catastrophic forgetting, outperforming conventional random sampling approaches and surpassing recent state-of-the-art methods in continual learnin",
    "path": "papers/24/03/2403.03938.json",
    "total_tokens": 807,
    "translated_title": "GUIDE：基于引导的扩散模型增量学习",
    "translated_abstract": "我们引入了GUIDE，一种新颖的持续学习方法，该方法指导扩散模型对有被遗忘风险的样本进行复习。现有的生成策略通过从生成模型中随机抽取复习样本来对抗灾难性遗忘。这种方法与基于缓冲区的方法相矛盾，其中采样策略起着重要作用。我们提出通过将扩散模型与分类器引导技术相结合，产生专门针对持续训练模型遗忘信息的复习示例，以弥合这一差距。这种方法使得能够从先前任务分布中生成样本，这些样本在最近遇到的类别情境下更有可能被误分类。我们的实验结果表明，GUIDE显著减少了灾难性遗忘，优于传统的随机抽样方法，并在持续学习方面超过了最近的先进方法。",
    "tldr": "GUIDE利用扩散模型和分类器引导技术，针对持续训练模型遗忘的信息产生复习示例，显著减少了灾难性遗忘。"
}