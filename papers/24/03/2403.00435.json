{
    "title": "Hierarchical Indexing for Retrieval-Augmented Opinion Summarization",
    "abstract": "arXiv:2403.00435v1 Announce Type: new  Abstract: We propose a method for unsupervised abstractive opinion summarization, that combines the attributability and scalability of extractive approaches with the coherence and fluency of Large Language Models (LLMs). Our method, HIRO, learns an index structure that maps sentences to a path through a semantically organized discrete hierarchy. At inference time, we populate the index and use it to identify and retrieve clusters of sentences containing popular opinions from input reviews. Then, we use a pretrained LLM to generate a readable summary that is grounded in these extracted evidential clusters. The modularity of our approach allows us to evaluate its efficacy at each stage. We show that HIRO learns an encoding space that is more semantically structured than prior work, and generates summaries that are more representative of the opinions in the input reviews. Human evaluation confirms that HIRO generates more coherent, detailed and accur",
    "link": "https://arxiv.org/abs/2403.00435",
    "context": "Title: Hierarchical Indexing for Retrieval-Augmented Opinion Summarization\nAbstract: arXiv:2403.00435v1 Announce Type: new  Abstract: We propose a method for unsupervised abstractive opinion summarization, that combines the attributability and scalability of extractive approaches with the coherence and fluency of Large Language Models (LLMs). Our method, HIRO, learns an index structure that maps sentences to a path through a semantically organized discrete hierarchy. At inference time, we populate the index and use it to identify and retrieve clusters of sentences containing popular opinions from input reviews. Then, we use a pretrained LLM to generate a readable summary that is grounded in these extracted evidential clusters. The modularity of our approach allows us to evaluate its efficacy at each stage. We show that HIRO learns an encoding space that is more semantically structured than prior work, and generates summaries that are more representative of the opinions in the input reviews. Human evaluation confirms that HIRO generates more coherent, detailed and accur",
    "path": "papers/24/03/2403.00435.json",
    "total_tokens": 887,
    "translated_title": "用于检索增强意见摘要的分层索引",
    "translated_abstract": "我们提出了一种用于无监督抽象意见摘要的方法，结合了抽取方法的可归因性和可扩展性以及大型语言模型(LLMs)的连贯性和流畅性。我们的方法，HIRO，学习了一个将句子映射到通过语义组织的离散层次结构路径的索引结构。在推断时，我们填充索引并使用它来识别和检索包含输入评论中流行意见的句子簇。然后，我们使用一个预训练的LLM生成一个基于这些提取的证据簇的可读摘要。我们的方法的模块化性允许我们在每个阶段评估其有效性。我们展示了HIRO学习了比先前工作更具语义结构的编码空间，并生成了更符合输入评论中意见的摘要。人类评估证实，HIRO生成的摘要更连贯、详细和准确。",
    "tldr": "HIRO 是一种用于无监督抽象意见摘要的方法，通过学习索引结构来提取输入评论中流行意见的句子簇，并利用预训练的大型语言模型生成相关的摘要，得到更具语义结构的编码空间和更具代表性的摘要。"
}