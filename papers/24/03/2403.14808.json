{
    "title": "A Collection of Pragmatic-Similarity Judgments over Spoken Dialog Utterances",
    "abstract": "arXiv:2403.14808v1 Announce Type: new  Abstract: Automatic measures of similarity between utterances are invaluable for training speech synthesizers, evaluating machine translation, and assessing learner productions. While there exist measures for semantic similarity and prosodic similarity, there are as yet none for pragmatic similarity. To enable the training of such measures, we developed the first collection of human judgments of pragmatic similarity between utterance pairs. Each pair consisting of an utterance extracted from a recorded dialog and a re-enactment of that utterance. Re-enactments were done under various conditions designed to create a variety of degrees of similarity. Each pair was rated on a continuous scale by 6 to 9 judges. The average inter-judge correlation was as high as 0.72 for English and 0.66 for Spanish. We make this data available at https://github.com/divettemarco/PragSim .",
    "link": "https://arxiv.org/abs/2403.14808",
    "context": "Title: A Collection of Pragmatic-Similarity Judgments over Spoken Dialog Utterances\nAbstract: arXiv:2403.14808v1 Announce Type: new  Abstract: Automatic measures of similarity between utterances are invaluable for training speech synthesizers, evaluating machine translation, and assessing learner productions. While there exist measures for semantic similarity and prosodic similarity, there are as yet none for pragmatic similarity. To enable the training of such measures, we developed the first collection of human judgments of pragmatic similarity between utterance pairs. Each pair consisting of an utterance extracted from a recorded dialog and a re-enactment of that utterance. Re-enactments were done under various conditions designed to create a variety of degrees of similarity. Each pair was rated on a continuous scale by 6 to 9 judges. The average inter-judge correlation was as high as 0.72 for English and 0.66 for Spanish. We make this data available at https://github.com/divettemarco/PragSim .",
    "path": "papers/24/03/2403.14808.json",
    "total_tokens": 806,
    "translated_title": "一组关于口语对话话语的实用相似度判断集合",
    "translated_abstract": "自动测量话语之间相似度的方法对于训练语音合成器、评估机器翻译以及评估学习者的产出非常宝贵。尽管已经存在语义相似度和韵律相似度的测量方法，但目前尚无关于语用相似度的方法。为了训练这样的测量方法，我们开发了第一个人类判断口语对话话语之间语用相似度的集合。每对话语包括一段来自录音对话的话语和该话语的再现。再现是在设计了各种条件以创建不同程度相似度的情况下完成的。每对话语由6到9位评委在连续尺度上评分。英语的评委间平均相关性高达0.72，而西班牙语为0.66。我们在https://github.com/divettemarco/PragSim 上提供了这些数据。",
    "tldr": "开发了第一个人类判断口语对话话语之间语用相似度的集合，通过评分表明了不同程度相似度的差异。"
}