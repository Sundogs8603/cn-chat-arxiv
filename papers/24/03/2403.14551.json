{
    "title": "Lexicon-Level Contrastive Visual-Grounding Improves Language Modeling",
    "abstract": "arXiv:2403.14551v1 Announce Type: cross  Abstract: Today's most accurate language models are trained on orders of magnitude more language data than human language learners receive - but with no supervision from other sensory modalities that play a crucial role in human learning. Can we make LMs' representations and predictions more accurate (and more human-like) with more ecologically plausible supervision? This paper describes LexiContrastive Grounding (LCG), a grounded language learning procedure that leverages visual supervision to improve textual representations. LexiContrastive Grounding combines a next token prediction strategy with a contrastive visual grounding objective, focusing on early-layer representations that encode lexical information. Across multiple word-learning and sentence-understanding benchmarks, LexiContrastive Grounding not only outperforms standard language-only models in learning efficiency, but also improves upon vision-and-language learning procedures inclu",
    "link": "https://arxiv.org/abs/2403.14551",
    "context": "Title: Lexicon-Level Contrastive Visual-Grounding Improves Language Modeling\nAbstract: arXiv:2403.14551v1 Announce Type: cross  Abstract: Today's most accurate language models are trained on orders of magnitude more language data than human language learners receive - but with no supervision from other sensory modalities that play a crucial role in human learning. Can we make LMs' representations and predictions more accurate (and more human-like) with more ecologically plausible supervision? This paper describes LexiContrastive Grounding (LCG), a grounded language learning procedure that leverages visual supervision to improve textual representations. LexiContrastive Grounding combines a next token prediction strategy with a contrastive visual grounding objective, focusing on early-layer representations that encode lexical information. Across multiple word-learning and sentence-understanding benchmarks, LexiContrastive Grounding not only outperforms standard language-only models in learning efficiency, but also improves upon vision-and-language learning procedures inclu",
    "path": "papers/24/03/2403.14551.json",
    "total_tokens": 825,
    "translated_title": "词汇级对比视觉基础改进语言建模",
    "translated_abstract": "今天最准确的语言模型是在比人类语言学习者接收到的语言数据量多得多的情况下训练的，但并没有来自在人类学习中起关键作用的其他感官模式的监督。本文描述了LexiContrastive Grounding (LCG)，一种利用视觉监督来改进文本表征的基于地面语言学习程序。LexiContrastive Grounding将下一个标记预测策略与对比视觉基础目标结合起来，重点放在编码词汇信息的早期层表示上。在多个单词学习和句子理解基准测试中，LexiContrastive Grounding不仅在学习效率上优于标准语言模型，而且在视觉与语言学习程序方面取得了进步。",
    "tldr": "这项研究介绍了LexiContrastive Grounding (LCG)，它结合了视觉监督和文本表示改进策略，在多个单词学习和句子理解基准测试中表现出比标准语言模型更高的学习效率和进步。",
    "en_tdlr": "This paper introduces LexiContrastive Grounding (LCG), which combines visual supervision and text representation improvement strategies, demonstrating higher learning efficiency and advancements in multiple word-learning and sentence-understanding benchmarks compared to standard language models."
}