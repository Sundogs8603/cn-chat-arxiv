{
    "title": "Different Tokenization Schemes Lead to Comparable Performance in Spanish Number Agreement",
    "abstract": "arXiv:2403.13754v1 Announce Type: new  Abstract: The relationship between language model tokenization and performance is an open area of research. Here, we investigate how different tokenization schemes impact number agreement in Spanish plurals. We find that morphologically-aligned tokenization performs similarly to other tokenization schemes, even when induced artificially for words that would not be tokenized that way during training. We then present exploratory analyses demonstrating that language model embeddings for different plural tokenizations have similar distributions along the embedding space axis that maximally distinguishes singular and plural nouns. Our results suggest that morphologically-aligned tokenization is a viable tokenization approach, and existing models already generalize some morphological patterns to new items. However, our results indicate that morphological tokenization is not strictly required for performance.",
    "link": "https://arxiv.org/abs/2403.13754",
    "context": "Title: Different Tokenization Schemes Lead to Comparable Performance in Spanish Number Agreement\nAbstract: arXiv:2403.13754v1 Announce Type: new  Abstract: The relationship between language model tokenization and performance is an open area of research. Here, we investigate how different tokenization schemes impact number agreement in Spanish plurals. We find that morphologically-aligned tokenization performs similarly to other tokenization schemes, even when induced artificially for words that would not be tokenized that way during training. We then present exploratory analyses demonstrating that language model embeddings for different plural tokenizations have similar distributions along the embedding space axis that maximally distinguishes singular and plural nouns. Our results suggest that morphologically-aligned tokenization is a viable tokenization approach, and existing models already generalize some morphological patterns to new items. However, our results indicate that morphological tokenization is not strictly required for performance.",
    "path": "papers/24/03/2403.13754.json",
    "total_tokens": 804,
    "translated_title": "不同的分词方案在西班牙语数词一致性中表现相似",
    "translated_abstract": "语言模型的分词和性能之间的关系是一个开放的研究领域。本文调查了不同分词方案对西班牙语复数一致性的影响。我们发现，在词形对齐的分词方案下，性能与其他分词方案类似，即使对于训练过程中不会以这种方式分词的词进行人工诱导。我们还展示了探索性分析结果，表明不同复数分词的语言模型嵌入在最大区分单数名词和复数名词的嵌入空间轴上具有相似的分布。我们的结果表明，词形对齐的分词是一种可行的分词方法，而现有模型已经将某些词形模式推广到新项目。然而，我们的结果表明，形态分词并非对性能绝对必要。",
    "tldr": "不同的分词方案在西班牙语数词一致性中表现相似，结果表明词形对齐的分词是一种可行的分词方法，但并非对性能绝对必要。",
    "en_tdlr": "Different tokenization schemes lead to comparable performance in Spanish number agreement, suggesting that morphologically-aligned tokenization is a viable tokenization approach, but not strictly required for performance."
}