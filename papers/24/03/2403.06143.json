{
    "title": "Fluent: Round-efficient Secure Aggregation for Private Federated Learning",
    "abstract": "arXiv:2403.06143v1 Announce Type: cross  Abstract: Federated learning (FL) facilitates collaborative training of machine learning models among a large number of clients while safeguarding the privacy of their local datasets. However, FL remains susceptible to vulnerabilities such as privacy inference and inversion attacks. Single-server secure aggregation schemes were proposed to address these threats. Nonetheless, they encounter practical constraints due to their round and communication complexities. This work introduces Fluent, a round and communication-efficient secure aggregation scheme for private FL. Fluent has several improvements compared to state-of-the-art solutions like Bell et al. (CCS 2020) and Ma et al. (SP 2023): (1) it eliminates frequent handshakes and secret sharing operations by efficiently reusing the shares across multiple training iterations without leaking any private information; (2) it accomplishes both the consistency check and gradient unmasking in one logica",
    "link": "https://arxiv.org/abs/2403.06143",
    "context": "Title: Fluent: Round-efficient Secure Aggregation for Private Federated Learning\nAbstract: arXiv:2403.06143v1 Announce Type: cross  Abstract: Federated learning (FL) facilitates collaborative training of machine learning models among a large number of clients while safeguarding the privacy of their local datasets. However, FL remains susceptible to vulnerabilities such as privacy inference and inversion attacks. Single-server secure aggregation schemes were proposed to address these threats. Nonetheless, they encounter practical constraints due to their round and communication complexities. This work introduces Fluent, a round and communication-efficient secure aggregation scheme for private FL. Fluent has several improvements compared to state-of-the-art solutions like Bell et al. (CCS 2020) and Ma et al. (SP 2023): (1) it eliminates frequent handshakes and secret sharing operations by efficiently reusing the shares across multiple training iterations without leaking any private information; (2) it accomplishes both the consistency check and gradient unmasking in one logica",
    "path": "papers/24/03/2403.06143.json",
    "total_tokens": 729,
    "translated_title": "流畅：面向私人联邦学习的轮次高效安全聚合",
    "translated_abstract": "面向私人联邦学习的流畅(Fluent)介绍了一种轮次和通信高效的安全聚合方案。与Bell等人（CCS 2020）和Ma等人（SP 2023）的最新解决方案相比，Fluent在几个方面有所改进：(1)通过在多个训练迭代之间高效地重用份额而不泄露任何私人信息，消除了频繁的握手和秘密共享操作；(2)在一个逻辑操作中完成了一致性检查和梯度解码。",
    "tldr": "Fluent提出了一种面向私人联邦学习的轮次和通信高效的安全聚合方案，相比现有解决方案有两个重要改进。",
    "en_tdlr": "Fluent introduces a round and communication-efficient secure aggregation scheme for private federated learning, with improvements including eliminating frequent handshakes and secret sharing operations by efficiently reusing shares across multiple iterations, and accomplishing consistency check and gradient unmasking in one logical operation."
}