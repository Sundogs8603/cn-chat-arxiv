{
    "title": "SQL-Encoder: Improving NL2SQL In-Context Learning Through a Context-Aware Encoder",
    "abstract": "arXiv:2403.16204v1 Announce Type: new  Abstract: Detecting structural similarity between queries is essential for selecting examples in in-context learning models. However, assessing structural similarity based solely on the natural language expressions of queries, without considering SQL queries, presents a significant challenge. This paper explores the significance of this similarity metric and proposes a model for accurately estimating it. To achieve this, we leverage a dataset comprising 170k question pairs, meticulously curated to train a similarity prediction model. Our comprehensive evaluation demonstrates that the proposed model adeptly captures the structural similarity between questions, as evidenced by improvements in Kendall-Tau distance and precision@k metrics. Notably, our model outperforms strong competitive embedding models from OpenAI and Cohere. Furthermore, compared to these competitive models, our proposed encoder enhances the downstream performance of NL2SQL models",
    "link": "https://arxiv.org/abs/2403.16204",
    "context": "Title: SQL-Encoder: Improving NL2SQL In-Context Learning Through a Context-Aware Encoder\nAbstract: arXiv:2403.16204v1 Announce Type: new  Abstract: Detecting structural similarity between queries is essential for selecting examples in in-context learning models. However, assessing structural similarity based solely on the natural language expressions of queries, without considering SQL queries, presents a significant challenge. This paper explores the significance of this similarity metric and proposes a model for accurately estimating it. To achieve this, we leverage a dataset comprising 170k question pairs, meticulously curated to train a similarity prediction model. Our comprehensive evaluation demonstrates that the proposed model adeptly captures the structural similarity between questions, as evidenced by improvements in Kendall-Tau distance and precision@k metrics. Notably, our model outperforms strong competitive embedding models from OpenAI and Cohere. Furthermore, compared to these competitive models, our proposed encoder enhances the downstream performance of NL2SQL models",
    "path": "papers/24/03/2403.16204.json",
    "total_tokens": 904,
    "translated_title": "SQL-Encoder: 通过上下文感知编码器改进NL2SQL的上下文学习",
    "translated_abstract": "检测查询之间的结构相似性对于在上下文学习模型中选择示例至关重要。然而，仅基于查询的自然语言表达来评估结构相似性，而不考虑SQL查询，会带来显著的挑战。本文探讨了这种相似度度量的重要性，并提出了一个准确估计它的模型。为了实现这一目标，我们利用了一个包含17万个问题对的数据集，经过精心策划，用于训练一个相似性预测模型。我们的综合评估表明，所提出的模型巧妙地捕捉到了问题之间的结构相似性，这体现在Kendall-Tau距离和precision@k指标的改善上。值得注意的是，我们的模型优于OpenAI和Cohere的竞争性嵌入模型。此外，与这些竞争性模型相比，我们提出的编码器提升了NL2SQL模型的下游性能。",
    "tldr": "本文研究了通过上下文感知编码器改进NL2SQL模型中上下文学习的方法，并提出了一个准确估计查询相似性的模型，通过170k个问题对数据集进行训练，能够优于其他竞争模型，提升NL2SQL模型的性能。",
    "en_tdlr": "This paper explores a method to improve NL2SQL models through a context-aware encoder, proposing a model for accurately estimating query similarity by training on a dataset of 170k question pairs, outperforming other competitive models and enhancing the performance of NL2SQL models."
}