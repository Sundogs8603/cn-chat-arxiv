{
    "title": "GSNeRF: Generalizable Semantic Neural Radiance Fields with Enhanced 3D Scene Understanding",
    "abstract": "arXiv:2403.03608v1 Announce Type: cross  Abstract: Utilizing multi-view inputs to synthesize novel-view images, Neural Radiance Fields (NeRF) have emerged as a popular research topic in 3D vision. In this work, we introduce a Generalizable Semantic Neural Radiance Field (GSNeRF), which uniquely takes image semantics into the synthesis process so that both novel view images and the associated semantic maps can be produced for unseen scenes. Our GSNeRF is composed of two stages: Semantic Geo-Reasoning and Depth-Guided Visual rendering. The former is able to observe multi-view image inputs to extract semantic and geometry features from a scene. Guided by the resulting image geometry information, the latter performs both image and semantic rendering with improved performances. Our experiments not only confirm that GSNeRF performs favorably against prior works on both novel-view image and semantic segmentation synthesis but the effectiveness of our sampling strategy for visual rendering is ",
    "link": "https://arxiv.org/abs/2403.03608",
    "context": "Title: GSNeRF: Generalizable Semantic Neural Radiance Fields with Enhanced 3D Scene Understanding\nAbstract: arXiv:2403.03608v1 Announce Type: cross  Abstract: Utilizing multi-view inputs to synthesize novel-view images, Neural Radiance Fields (NeRF) have emerged as a popular research topic in 3D vision. In this work, we introduce a Generalizable Semantic Neural Radiance Field (GSNeRF), which uniquely takes image semantics into the synthesis process so that both novel view images and the associated semantic maps can be produced for unseen scenes. Our GSNeRF is composed of two stages: Semantic Geo-Reasoning and Depth-Guided Visual rendering. The former is able to observe multi-view image inputs to extract semantic and geometry features from a scene. Guided by the resulting image geometry information, the latter performs both image and semantic rendering with improved performances. Our experiments not only confirm that GSNeRF performs favorably against prior works on both novel-view image and semantic segmentation synthesis but the effectiveness of our sampling strategy for visual rendering is ",
    "path": "papers/24/03/2403.03608.json",
    "total_tokens": 795,
    "translated_title": "GSNeRF: 增强了3D场景理解的通用语义神经辐射场",
    "translated_abstract": "在这项工作中，我们引入了一种通用的语义神经辐射场（GSNeRF），它独特地将图像语义纳入合成过程，因此可以为未知场景生成新视图图像和相关的语义地图。我们的GSNeRF由两个阶段组成：语义地理推理和深度引导可视渲染。前者能够观察多视图图像输入，从场景中提取语义和几何特征。在后者的指导下，根据生成的图像几何信息，进行了具有改进性能的图像和语义渲染。我们的实验证实了GSNeRF在新视图图像和语义分割合成方面优于先前工作，并且证明了我们的采样策略对于可视渲染的有效性。",
    "tldr": "GSNeRF通过引入图像语义，实现了对未知场景的新视图图像和相关语义地图的生成，并在图像和语义渲染方面取得了改进性能。",
    "en_tdlr": "GSNeRF generates novel-view images and associated semantic maps for unseen scenes by incorporating image semantics, showing improved performance in image and semantic rendering."
}