{
    "title": "Diversity-Aware Agnostic Ensemble of Sharpness Minimizers",
    "abstract": "arXiv:2403.13204v1 Announce Type: new  Abstract: There has long been plenty of theoretical and empirical evidence supporting the success of ensemble learning. Deep ensembles in particular take advantage of training randomness and expressivity of individual neural networks to gain prediction diversity, ultimately leading to better generalization, robustness and uncertainty estimation. In respect of generalization, it is found that pursuing wider local minima result in models being more robust to shifts between training and testing sets. A natural research question arises out of these two approaches as to whether a boost in generalization ability can be achieved if ensemble learning and loss sharpness minimization are integrated. Our work investigates this connection and proposes DASH - a learning algorithm that promotes diversity and flatness within deep ensembles. More concretely, DASH encourages base learners to move divergently towards low-loss regions of minimal sharpness. We provid",
    "link": "https://arxiv.org/abs/2403.13204",
    "context": "Title: Diversity-Aware Agnostic Ensemble of Sharpness Minimizers\nAbstract: arXiv:2403.13204v1 Announce Type: new  Abstract: There has long been plenty of theoretical and empirical evidence supporting the success of ensemble learning. Deep ensembles in particular take advantage of training randomness and expressivity of individual neural networks to gain prediction diversity, ultimately leading to better generalization, robustness and uncertainty estimation. In respect of generalization, it is found that pursuing wider local minima result in models being more robust to shifts between training and testing sets. A natural research question arises out of these two approaches as to whether a boost in generalization ability can be achieved if ensemble learning and loss sharpness minimization are integrated. Our work investigates this connection and proposes DASH - a learning algorithm that promotes diversity and flatness within deep ensembles. More concretely, DASH encourages base learners to move divergently towards low-loss regions of minimal sharpness. We provid",
    "path": "papers/24/03/2403.13204.json",
    "total_tokens": 848,
    "translated_title": "多样性感知的无偏小人集成",
    "translated_abstract": "长期以来，有大量理论和经验证据支持集成学习的成功。特别是深度集成利用训练中的随机性和单个神经网络的表现力，获得预测多样性，从而最终实现更好的泛化、鲁棒性和不确定性估计。在泛化方面，发现追求更广泛的局部最小值会导致模型对训练和测试集之间的转变更加鲁棒。基于这两种方法，一个自然的研究问题是，如果集成学习和损失锐度最小化相结合，是否可以实现泛化能力的提升。我们的工作研究了这种联系，并提出了一种促进深度集成内多样性和平坦性的学习算法——DASH。更具体地说，DASH鼓励基础学习器向最小锐度区域的低损失区域发散移动。",
    "tldr": "提出了一种促进深度集成内多样性和平坦性的学习算法DASH，通过鼓励基础学习器向最小锐度区域的低损失区域发散移动来提高泛化能力。"
}