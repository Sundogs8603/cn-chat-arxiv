{
    "title": "EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents",
    "abstract": "arXiv:2403.12014v1 Announce Type: cross  Abstract: Recent SOTA approaches for embodied learning via interaction directly employ large language models (LLMs) as agents to determine the next steps in an environment. Due to their world knowledge and reasoning capabilities, LLM agents achieve stronger performance than previous smaller agents based on reinforcement learning (RL); however, frequently calling LLMs is slow and expensive. Instead of directly employing LLMs as agents, can we use LLMs' reasoning capabilities to adaptively create training environments to help smaller embodied RL agents learn useful skills that they are weak at? We propose EnvGen, a novel framework to address this question. First, we prompt an LLM to generate training environments that allow agents to quickly learn different tasks in parallel. Concretely, the LLM is given the task description and simulator objectives that the agents should learn and is then asked to generate a set of environment configurations (e.g",
    "link": "https://arxiv.org/abs/2403.12014",
    "context": "Title: EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents\nAbstract: arXiv:2403.12014v1 Announce Type: cross  Abstract: Recent SOTA approaches for embodied learning via interaction directly employ large language models (LLMs) as agents to determine the next steps in an environment. Due to their world knowledge and reasoning capabilities, LLM agents achieve stronger performance than previous smaller agents based on reinforcement learning (RL); however, frequently calling LLMs is slow and expensive. Instead of directly employing LLMs as agents, can we use LLMs' reasoning capabilities to adaptively create training environments to help smaller embodied RL agents learn useful skills that they are weak at? We propose EnvGen, a novel framework to address this question. First, we prompt an LLM to generate training environments that allow agents to quickly learn different tasks in parallel. Concretely, the LLM is given the task description and simulator objectives that the agents should learn and is then asked to generate a set of environment configurations (e.g",
    "path": "papers/24/03/2403.12014.json",
    "total_tokens": 771,
    "translated_title": "EnvGen: 通过LLMs生成和调整环境以训练具身体的代理",
    "translated_abstract": "最近有关通过互动进行具身体学习的最新方法直接采用大型语言模型（LLMs）作为代理，以确定环境中的下一步。LLM代理由于其世界知识和推理能力，比基于强化学习（RL）的以往较小的代理表现更强；但频繁调用LLMs速度慢且昂贵。我们提出EnvGen，一个处理这个问题的新框架。首先，我们提示一个LLM生成训练环境，使代理可以快速并行学习不同任务。具体而言，LLM获得任务描述和模拟器目标，然后被要求生成一组环境配置。",
    "tldr": "EnvGen提出了一种新的框架，利用LLMs的推理能力自适应创建训练环境，帮助小型具身体RL代理在弱点方面学习有用技能。"
}