{
    "title": "IterAlign: Iterative Constitutional Alignment of Large Language Models",
    "abstract": "arXiv:2403.18341v1 Announce Type: new  Abstract: With the rapid development of large language models (LLMs), aligning LLMs with human values and societal norms to ensure their reliability and safety has become crucial. Reinforcement learning with human feedback (RLHF) and Constitutional AI (CAI) have been proposed for LLM alignment. However, these methods require either heavy human annotations or explicitly pre-defined constitutions, which are labor-intensive and resource-consuming. To overcome these drawbacks, we study constitution-based LLM alignment and propose a data-driven constitution discovery and self-alignment framework called IterAlign. IterAlign leverages red teaming to unveil the weaknesses of an LLM and automatically discovers new constitutions using a stronger LLM. These constitutions are then used to guide self-correction of the base LLM. Such a constitution discovery pipeline can be run iteratively and automatically to discover new constitutions that specifically target",
    "link": "https://arxiv.org/abs/2403.18341",
    "context": "Title: IterAlign: Iterative Constitutional Alignment of Large Language Models\nAbstract: arXiv:2403.18341v1 Announce Type: new  Abstract: With the rapid development of large language models (LLMs), aligning LLMs with human values and societal norms to ensure their reliability and safety has become crucial. Reinforcement learning with human feedback (RLHF) and Constitutional AI (CAI) have been proposed for LLM alignment. However, these methods require either heavy human annotations or explicitly pre-defined constitutions, which are labor-intensive and resource-consuming. To overcome these drawbacks, we study constitution-based LLM alignment and propose a data-driven constitution discovery and self-alignment framework called IterAlign. IterAlign leverages red teaming to unveil the weaknesses of an LLM and automatically discovers new constitutions using a stronger LLM. These constitutions are then used to guide self-correction of the base LLM. Such a constitution discovery pipeline can be run iteratively and automatically to discover new constitutions that specifically target",
    "path": "papers/24/03/2403.18341.json",
    "total_tokens": 878,
    "translated_title": "IterAlign: 大型语言模型的迭代式宪法对齐",
    "translated_abstract": "随着大型语言模型（LLMs）的快速发展，将LLMs与人类价值观和社会规范对齐以确保其可靠性和安全性变得至关重要。强化学习与人类反馈（RLHF）和宪法AI（CAI）已被提出用于LLM对齐。然而，这些方法要求大量的人类注释或明确预定义的宪法，这些都是劳动密集型和资源消耗型的。为了克服这些缺点，我们研究了基于宪法的LLM对齐，并提出了一种名为IterAlign的数据驱动宪法发现和自对齐框架。IterAlign利用红队测试揭示LLM的弱点，并使用更强大的LLM自动发现新的宪法。然后，这些宪法被用来指导基于LLM的自校正。这种宪法发现流程可以迭代自动运行，以发现针对特定LLMs的新宪法。",
    "tldr": "提出了IterAlign，是一种数据驱动的宪法发现和自对齐框架，通过红队测试发现LLM的弱点，并使用更强大的LLM自动发现新的宪法，从而指导LLM的自校正。",
    "en_tdlr": "Introducing IterAlign, a data-driven framework for constitution discovery and self-alignment, which leverages red team testing to reveal weaknesses of LLMs and automatically discovers new constitutions using stronger LLMs to guide self-correction."
}