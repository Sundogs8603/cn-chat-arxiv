{
    "title": "Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression",
    "abstract": "arXiv:2403.15447v1 Announce Type: cross  Abstract: Compressing high-capability Large Language Models (LLMs) has emerged as a favored strategy for resource-efficient inferences. While state-of-the-art (SoTA) compression methods boast impressive advancements in preserving benign task performance, the potential risks of compression in terms of safety and trustworthiness have been largely neglected. This study conducts the first, thorough evaluation of three (3) leading LLMs using five (5) SoTA compression techniques across eight (8) trustworthiness dimensions. Our experiments highlight the intricate interplay between compression and trustworthiness, revealing some interesting patterns. We find that quantization is currently a more effective approach than pruning in achieving efficiency and trustworthiness simultaneously. For instance, a 4-bit quantized model retains the trustworthiness of its original counterpart, but model pruning significantly degrades trustworthiness, even at 50% spars",
    "link": "https://arxiv.org/abs/2403.15447",
    "context": "Title: Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression\nAbstract: arXiv:2403.15447v1 Announce Type: cross  Abstract: Compressing high-capability Large Language Models (LLMs) has emerged as a favored strategy for resource-efficient inferences. While state-of-the-art (SoTA) compression methods boast impressive advancements in preserving benign task performance, the potential risks of compression in terms of safety and trustworthiness have been largely neglected. This study conducts the first, thorough evaluation of three (3) leading LLMs using five (5) SoTA compression techniques across eight (8) trustworthiness dimensions. Our experiments highlight the intricate interplay between compression and trustworthiness, revealing some interesting patterns. We find that quantization is currently a more effective approach than pruning in achieving efficiency and trustworthiness simultaneously. For instance, a 4-bit quantized model retains the trustworthiness of its original counterpart, but model pruning significantly degrades trustworthiness, even at 50% spars",
    "path": "papers/24/03/2403.15447.json",
    "total_tokens": 843,
    "translated_title": "解码压缩的信任：审视在压缩下高效LLMs的可信度",
    "translated_abstract": "将高性能的大型语言模型（LLMs）压缩已经成为一种资源高效推断的首选策略。尽管最先进的压缩方法在保留良性任务性能方面取得了令人印象深刻的进展，但压缩在安全性和可信度方面的潜在风险在很大程度上被忽视。这项研究对使用五种最先进压缩技术评估三种领先LLMs的可信度维度进行了首次彻底评估。我们的实验突出了压缩与可信度之间复杂的相互作用，揭示了一些有趣的模式。我们发现，目前量化比剪枝更有效地同时实现效率和可信度。例如，4位量化模型保留了其原始对应物的可信度，但模型剪枝显著降低了可信度，即使在50%的稀疏度下。",
    "tldr": "量化目前比剪枝更有效，可以同时实现效率和可信度，但剪枝会显著降低模型的可信度",
    "en_tdlr": "Quantization is currently more effective than pruning in achieving efficiency and trustworthiness simultaneously, but pruning significantly degrades the trustworthiness of the model"
}