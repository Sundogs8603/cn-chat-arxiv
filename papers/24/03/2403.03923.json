{
    "title": "Did Translation Models Get More Robust Without Anyone Even Noticing?",
    "abstract": "arXiv:2403.03923v1 Announce Type: new  Abstract: Neural machine translation (MT) models achieve strong results across a variety of settings, but it is widely believed that they are highly sensitive to \"noisy\" inputs, such as spelling errors, abbreviations, and other formatting issues. In this paper, we revisit this insight in light of recent multilingual MT models and large language models (LLMs) applied to machine translation. Somewhat surprisingly, we show through controlled experiments that these models are far more robust to many kinds of noise than previous models, even when they perform similarly on clean data. This is notable because, even though LLMs have more parameters and more complex training processes than past models, none of the open ones we consider use any techniques specifically designed to encourage robustness. Next, we show that similar trends hold for social media translation experiments -- LLMs are more robust to social media text. We include an analysis of the ci",
    "link": "https://arxiv.org/abs/2403.03923",
    "context": "Title: Did Translation Models Get More Robust Without Anyone Even Noticing?\nAbstract: arXiv:2403.03923v1 Announce Type: new  Abstract: Neural machine translation (MT) models achieve strong results across a variety of settings, but it is widely believed that they are highly sensitive to \"noisy\" inputs, such as spelling errors, abbreviations, and other formatting issues. In this paper, we revisit this insight in light of recent multilingual MT models and large language models (LLMs) applied to machine translation. Somewhat surprisingly, we show through controlled experiments that these models are far more robust to many kinds of noise than previous models, even when they perform similarly on clean data. This is notable because, even though LLMs have more parameters and more complex training processes than past models, none of the open ones we consider use any techniques specifically designed to encourage robustness. Next, we show that similar trends hold for social media translation experiments -- LLMs are more robust to social media text. We include an analysis of the ci",
    "path": "papers/24/03/2403.03923.json",
    "total_tokens": 940,
    "translated_title": "翻译模型是否在无人发觉的情况下变得更加稳健了？",
    "translated_abstract": "神经机器翻译（MT）模型在各种场景中取得了强大的结果，但普遍认为它们对\"嘈杂\"输入（如拼写错误、缩写和其他格式问题）非常敏感。本文针对最近的多语言MT模型和应用于机器翻译的大型语言模型（LLMs），重新审视这一观点。有些令人惊讶的是，我们通过受控实验表明，这些模型对许多种噪声比先前的模型更加稳健，即使在干净数据上表现类似。这很引人注目，因为尽管LLMs拥有比过去模型更多的参数和更复杂的训练过程，我们考虑的开源模型中没有一个使用任何专门设计的鼓励稳健性的技术。接下来，我们展示类似的趋势也适用于社交媒体翻译实验——LLMs对社交媒体文本更加稳健。我们还包括了一项关于......",
    "tldr": "最近的研究表明，新的多语言机器翻译模型和大型语言模型在面对各种噪声输入时比先前的模型更加稳健，尽管它们的参数更多、训练过程更复杂，并且没有采用特定设计用于增强稳健性的技术。",
    "en_tdlr": "Recent studies have shown that new multilingual machine translation models and large language models are more robust to various noisy inputs compared to previous models, despite having more parameters, complex training processes, and not utilizing specific techniques designed to enhance robustness."
}