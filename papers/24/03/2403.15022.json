{
    "title": "Insights into the Lottery Ticket Hypothesis and the Iterative Magnitude Pruning",
    "abstract": "arXiv:2403.15022v1 Announce Type: new  Abstract: Lottery ticket hypothesis for deep neural networks emphasizes the importance of initialization used to re-train the sparser networks obtained using the iterative magnitude pruning process. An explanation for why the specific initialization proposed by the lottery ticket hypothesis tends to work better in terms of generalization (and training) performance has been lacking. Moreover, the underlying principles in iterative magnitude pruning, like the pruning of smaller magnitude weights and the role of the iterative process, lack full understanding and explanation. In this work, we attempt to provide insights into these phenomena by empirically studying the volume/geometry and loss landscape characteristics of the solutions obtained at various stages of the iterative magnitude pruning process.",
    "link": "https://arxiv.org/abs/2403.15022",
    "context": "Title: Insights into the Lottery Ticket Hypothesis and the Iterative Magnitude Pruning\nAbstract: arXiv:2403.15022v1 Announce Type: new  Abstract: Lottery ticket hypothesis for deep neural networks emphasizes the importance of initialization used to re-train the sparser networks obtained using the iterative magnitude pruning process. An explanation for why the specific initialization proposed by the lottery ticket hypothesis tends to work better in terms of generalization (and training) performance has been lacking. Moreover, the underlying principles in iterative magnitude pruning, like the pruning of smaller magnitude weights and the role of the iterative process, lack full understanding and explanation. In this work, we attempt to provide insights into these phenomena by empirically studying the volume/geometry and loss landscape characteristics of the solutions obtained at various stages of the iterative magnitude pruning process.",
    "path": "papers/24/03/2403.15022.json",
    "total_tokens": 830,
    "translated_title": "走势彩票假设和迭代幅度剪枝的洞见",
    "translated_abstract": "arXiv:2403.15022v1 公告类型：新摘要：深度神经网络的走势彩票假设强调了重新训练利用迭代幅度剪枝过程获得的更稀疏网络时所使用的初始化的重要性。至今尚缺乏关于走势彩票假设中提出的特定初始化为何更有利于泛化（和训练）性能的解释。此外，迭代幅度剪枝中的基本原理，如剪枝较小幅度权重和迭代过程的作用，尚缺乏完全理解和解释。在本研究中，我们尝试通过对在迭代幅度剪枝过程的各个阶段获得的解决方案的体积/几何和损失景观特征进行经验研究，以洞察这些现象。",
    "tldr": "通过对迭代幅度剪枝过程中不同阶段获得的解决方案的体积/几何和损失景观特征进行经验研究，我们试图洞察走势彩票假设和迭代幅度剪枝中的现象。",
    "en_tdlr": "We attempt to provide insights into phenomena related to the Lottery Ticket Hypothesis and Iterative Magnitude Pruning by empirically studying the volume/geometry and loss landscape characteristics of solutions obtained at various stages of the iterative magnitude pruning process."
}