{
    "title": "Autoregressive Score Generation for Multi-trait Essay Scoring",
    "abstract": "arXiv:2403.08332v1 Announce Type: cross  Abstract: Recently, encoder-only pre-trained models such as BERT have been successfully applied in automated essay scoring (AES) to predict a single overall score. However, studies have yet to explore these models in multi-trait AES, possibly due to the inefficiency of replicating BERT-based models for each trait. Breaking away from the existing sole use of encoder, we propose an autoregressive prediction of multi-trait scores (ArTS), incorporating a decoding process by leveraging the pre-trained T5. Unlike prior regression or classification methods, we redefine AES as a score-generation task, allowing a single model to predict multiple scores. During decoding, the subsequent trait prediction can benefit by conditioning on the preceding trait scores. Experimental results proved the efficacy of ArTS, showing over 5% average improvements in both prompts and traits.",
    "link": "https://arxiv.org/abs/2403.08332",
    "context": "Title: Autoregressive Score Generation for Multi-trait Essay Scoring\nAbstract: arXiv:2403.08332v1 Announce Type: cross  Abstract: Recently, encoder-only pre-trained models such as BERT have been successfully applied in automated essay scoring (AES) to predict a single overall score. However, studies have yet to explore these models in multi-trait AES, possibly due to the inefficiency of replicating BERT-based models for each trait. Breaking away from the existing sole use of encoder, we propose an autoregressive prediction of multi-trait scores (ArTS), incorporating a decoding process by leveraging the pre-trained T5. Unlike prior regression or classification methods, we redefine AES as a score-generation task, allowing a single model to predict multiple scores. During decoding, the subsequent trait prediction can benefit by conditioning on the preceding trait scores. Experimental results proved the efficacy of ArTS, showing over 5% average improvements in both prompts and traits.",
    "path": "papers/24/03/2403.08332.json",
    "total_tokens": 775,
    "translated_title": "自回归得分生成用于多特征作文评分",
    "translated_abstract": "最近，仅编码器预训练模型如BERT已成功应用于自动作文评分（AES）中，用于预测单一整体分数。然而，研究尚未探索这些模型在多特征AES中的应用，可能是由于为每个特征复制基于BERT的模型的效率低下。我们突破了现有仅使用编码器的模型，提出了一种自回归预测多特征分数（ArTS）的方法，通过利用预先训练的T5来结合一个解码过程。与先前的回归或分类方法不同，我们重新定义AES为一个得分生成任务，允许单个模型预测多个分数。在解码过程中，随后的特征预测可以通过在先前的特征分数上进行条件化而受益。实验结果证明了ArTS的有效性，显示了在提示和特征方面平均提高5%以上。",
    "tldr": "提出一种自回归预测多特征分数的方法（ArTS），通过利用预先训练的T5来结合解码过程，实现了自动作文评分中多分数预测的效果。"
}