{
    "title": "CatCode: A Comprehensive Evaluation Framework for LLMs On the Mixture of Code and Text",
    "abstract": "arXiv:2403.01784v1 Announce Type: new  Abstract: Large language models (LLMs) such as ChatGPT are increasingly proficient in understanding and generating a mixture of code and text. Evaluation based on such $\\textit{mixture}$ can lead to a more comprehensive understanding of the models' abilities in solving coding problems. However, in this context, current evaluation methods are either limited in task coverage or lack standardization. To address this issue, we propose using category theory as a framework for evaluation. Specifically, morphisms within a code category can represent code debugging and transformation, functors between two categories represent code translation, and functors between a code category and a natural language category represent code generation, explanation, and reproduction. We present an automatic evaluation framework called $\\textbf{CatCode}$ ($\\textbf{Cat}$egory $\\textbf{Code}$) that can comprehensively assess the coding abilities of LLMs, including ChatGPT, ",
    "link": "https://arxiv.org/abs/2403.01784",
    "context": "Title: CatCode: A Comprehensive Evaluation Framework for LLMs On the Mixture of Code and Text\nAbstract: arXiv:2403.01784v1 Announce Type: new  Abstract: Large language models (LLMs) such as ChatGPT are increasingly proficient in understanding and generating a mixture of code and text. Evaluation based on such $\\textit{mixture}$ can lead to a more comprehensive understanding of the models' abilities in solving coding problems. However, in this context, current evaluation methods are either limited in task coverage or lack standardization. To address this issue, we propose using category theory as a framework for evaluation. Specifically, morphisms within a code category can represent code debugging and transformation, functors between two categories represent code translation, and functors between a code category and a natural language category represent code generation, explanation, and reproduction. We present an automatic evaluation framework called $\\textbf{CatCode}$ ($\\textbf{Cat}$egory $\\textbf{Code}$) that can comprehensively assess the coding abilities of LLMs, including ChatGPT, ",
    "path": "papers/24/03/2403.01784.json",
    "total_tokens": 801,
    "translated_title": "CatCode：一种用于LLMs在代码和文本混合方面的全面评估框架",
    "translated_abstract": "大型语言模型（LLMs）如ChatGPT在理解和生成代码和文本混合方面越来越精通。基于这种混合的评估可以更全面地了解模型在解决编程问题时的能力。为了解决当前评估方法在任务覆盖范围上的限制或缺乏标准化的问题，我们提出使用范畴论作为评估框架。具体而言，代码范畴中的态射可以表示代码调试和转换，两个范畴之间的函子表示代码翻译，代码范畴和自然语言范畴之间的函子表示代码生成、解释和再现。我们提出了一个名为CatCode（Category Code）的自动评估框架，可以全面评估LLMs（包括ChatGPT）的编码能力。",
    "tldr": "CatCode提出了一种基于范畴论的评估框架，可以全面评估LLMs在解决编程问题时的编码能力。",
    "en_tdlr": "CatCode proposes an evaluation framework based on category theory that comprehensively assesses the coding abilities of LLMs in solving coding problems."
}