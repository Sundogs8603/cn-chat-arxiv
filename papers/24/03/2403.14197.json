{
    "title": "Context Quality Matters in Training Fusion-in-Decoder for Extractive Open-Domain Question Answering",
    "abstract": "arXiv:2403.14197v1 Announce Type: new  Abstract: Retrieval-augmented generation models augment knowledge encoded in a language model by providing additional relevant external knowledge (context) during generation. Although it has been shown that the quantity and quality of context impact the performance of retrieval-augmented generation models during inference, limited research explores how these characteristics affect model training. This paper explores how context quantity and quality during model training affect the performance of Fusion-in-Decoder (FiD), the state-of-the-art retrieval-augmented generation model, in extractive open-domain question answering tasks. Experimental results suggest that FiD models overfit to context quality during training and show suboptimal performance when evaluated on different context quality. Through the experimental results, we also reveal FiD models trained with different context quality have different cross-attention distribution patterns. Specif",
    "link": "https://arxiv.org/abs/2403.14197",
    "context": "Title: Context Quality Matters in Training Fusion-in-Decoder for Extractive Open-Domain Question Answering\nAbstract: arXiv:2403.14197v1 Announce Type: new  Abstract: Retrieval-augmented generation models augment knowledge encoded in a language model by providing additional relevant external knowledge (context) during generation. Although it has been shown that the quantity and quality of context impact the performance of retrieval-augmented generation models during inference, limited research explores how these characteristics affect model training. This paper explores how context quantity and quality during model training affect the performance of Fusion-in-Decoder (FiD), the state-of-the-art retrieval-augmented generation model, in extractive open-domain question answering tasks. Experimental results suggest that FiD models overfit to context quality during training and show suboptimal performance when evaluated on different context quality. Through the experimental results, we also reveal FiD models trained with different context quality have different cross-attention distribution patterns. Specif",
    "path": "papers/24/03/2403.14197.json",
    "total_tokens": 916,
    "translated_title": "在提取式开放域问答中，训练解码器中的融合技术时，上下文质量很重要",
    "translated_abstract": "检索增强生成模型通过在生成过程中提供额外相关的外部知识（上下文）来增强语言模型中编码的知识。尽管已经显示出上下文的数量和质量会影响检索增强生成模型在推断过程中的性能，但有限的研究探讨了这些特征如何影响模型训练。本文探讨了模型训练过程中上下文数量和质量如何影响融合解码器（FiD）在提取式开放域问答任务中的性能，FiD是目前的检索增强生成模型。实验结果表明，FiD模型在训练过程中过拟合到上下文质量，并在不同上下文质量的评估中表现出亚优性能。通过实验结果，我们还揭示了使用不同上下文质量训练的FiD模型具有不同的交叉注意力分布模式。",
    "tldr": "论文探讨了在训练 Fusion-in-Decoder（FiD）时上下文数量和质量对提取式开放域问答任务性能的影响，实验结果表明FiD模型在训练过程中可能会过拟合到上下文质量，导致在不同质量上下文评估时表现出亚优性能。",
    "en_tdlr": "This paper investigates how the quantity and quality of context during training affect the performance of Fusion-in-Decoder (FiD) in extractive open-domain question answering tasks, with experimental results suggesting potential overfitting to context quality and suboptimal performance on evaluations with different context qualities."
}