{
    "title": "PPS-QMIX: Periodically Parameter Sharing for Accelerating Convergence of Multi-Agent Reinforcement Learning",
    "abstract": "arXiv:2403.02635v1 Announce Type: new  Abstract: Training for multi-agent reinforcement learning(MARL) is a time-consuming process caused by distribution shift of each agent. One drawback is that strategy of each agent in MARL is independent but actually in cooperation. Thus, a vertical issue in multi-agent reinforcement learning is how to efficiently accelerate training process. To address this problem, current research has leveraged a centralized function(CF) across multiple agents to learn contribution of the team reward for each agent. However, CF based methods introduce joint error from other agents in estimation of value network. In so doing, inspired by federated learning, we propose three simple novel approaches called Average Periodically Parameter Sharing(A-PPS), Reward-Scalability Periodically Parameter Sharing(RS-PPS) and Partial Personalized Periodically Parameter Sharing(PP-PPS) mechanism to accelerate training of MARL. Agents share Q-value network periodically during the",
    "link": "https://arxiv.org/abs/2403.02635",
    "context": "Title: PPS-QMIX: Periodically Parameter Sharing for Accelerating Convergence of Multi-Agent Reinforcement Learning\nAbstract: arXiv:2403.02635v1 Announce Type: new  Abstract: Training for multi-agent reinforcement learning(MARL) is a time-consuming process caused by distribution shift of each agent. One drawback is that strategy of each agent in MARL is independent but actually in cooperation. Thus, a vertical issue in multi-agent reinforcement learning is how to efficiently accelerate training process. To address this problem, current research has leveraged a centralized function(CF) across multiple agents to learn contribution of the team reward for each agent. However, CF based methods introduce joint error from other agents in estimation of value network. In so doing, inspired by federated learning, we propose three simple novel approaches called Average Periodically Parameter Sharing(A-PPS), Reward-Scalability Periodically Parameter Sharing(RS-PPS) and Partial Personalized Periodically Parameter Sharing(PP-PPS) mechanism to accelerate training of MARL. Agents share Q-value network periodically during the",
    "path": "papers/24/03/2403.02635.json",
    "total_tokens": 927,
    "translated_title": "PPS-QMIX: 周期参数共享用于加速多智体强化学习的收敛",
    "translated_abstract": "训练多智体强化学习（MARL）是一个耗时的过程，因为每个智体的分布偏移导致的。一个缺点是MARL中每个智体的策略是独立的，实际上是合作的。因此，多智体强化学习领域的一个重要问题是如何有效加速训练过程。为了解决这个问题，当前研究利用跨多智体的中心化功能（CF）来学习每个智体团队奖励的贡献。然而，基于CF的方法会在值网络估计中引入其他智体的联合误差。受到联邦学习的启发，我们提出了三种简单的新方法，即平均周期参数共享（A-PPS）、奖励可伸缩性周期参数共享（RS-PPS）和部分个性化周期参数共享（PP-PPS）机制来加速MARL训练。智体在训练过程中周期性地共享Q值网络。",
    "tldr": "提出了三种简单的新方法来加速多智体强化学习训练过程，即平均周期参数共享（A-PPS）、奖励可伸缩性周期参数共享（RS-PPS）和部分个性化周期参数共享（PP-PPS）机制。",
    "en_tdlr": "Proposed three simple novel approaches to accelerate the training process of multi-agent reinforcement learning: Average Periodically Parameter Sharing (A-PPS), Reward-Scalability Periodically Parameter Sharing (RS-PPS), and Partial Personalized Periodically Parameter Sharing (PP-PPS) mechanisms."
}