{
    "title": "Chained Information-Theoretic bounds and Tight Regret Rate for Linear Bandit Problems",
    "abstract": "arXiv:2403.03361v1 Announce Type: cross  Abstract: This paper studies the Bayesian regret of a variant of the Thompson-Sampling algorithm for bandit problems. It builds upon the information-theoretic framework of [Russo and Van Roy, 2015] and, more specifically, on the rate-distortion analysis from [Dong and Van Roy, 2020], where they proved a bound with regret rate of $O(d\\sqrt{T \\log(T)})$ for the $d$-dimensional linear bandit setting. We focus on bandit problems with a metric action space and, using a chaining argument, we establish new bounds that depend on the metric entropy of the action space for a variant of Thompson-Sampling.   Under suitable continuity assumption of the rewards, our bound offers a tight rate of $O(d\\sqrt{T})$ for $d$-dimensional linear bandit problems.",
    "link": "https://arxiv.org/abs/2403.03361",
    "context": "Title: Chained Information-Theoretic bounds and Tight Regret Rate for Linear Bandit Problems\nAbstract: arXiv:2403.03361v1 Announce Type: cross  Abstract: This paper studies the Bayesian regret of a variant of the Thompson-Sampling algorithm for bandit problems. It builds upon the information-theoretic framework of [Russo and Van Roy, 2015] and, more specifically, on the rate-distortion analysis from [Dong and Van Roy, 2020], where they proved a bound with regret rate of $O(d\\sqrt{T \\log(T)})$ for the $d$-dimensional linear bandit setting. We focus on bandit problems with a metric action space and, using a chaining argument, we establish new bounds that depend on the metric entropy of the action space for a variant of Thompson-Sampling.   Under suitable continuity assumption of the rewards, our bound offers a tight rate of $O(d\\sqrt{T})$ for $d$-dimensional linear bandit problems.",
    "path": "papers/24/03/2403.03361.json",
    "total_tokens": 850,
    "translated_title": "链式信息论界限和线性赌博问题的严格遗憾率",
    "translated_abstract": "本文研究了一种Thompson-Sampling算法变体在赌博问题中的贝叶斯遗憾。它基于[Russo and Van Roy，2015]的信息论框架，更具体地，基于[Dong and Van Roy，2020]的率-失真分析，在那里他们证明了$d$维线性赌博设置的遗憾率为$O(d\\sqrt{T \\log(T)})$的界限。我们专注于具有度量动作空间的赌博问题，并使用链接论证建立了依赖于动作空间度量熵的新界限，针对Thompson-Sampling的一个变体。在奖励的适当连续性假设下，我们的界限为$d$维线性赌博问题提供了$O(d\\sqrt{T})$的严格率。",
    "tldr": "本文研究了线性赌博问题中Thompson-Sampling算法变体的贝叶斯遗憾，通过使用链接论证建立了具有度量动作空间的新界限，为$d$维线性赌博问题提供了$O(d\\sqrt{T})$的严格率。",
    "en_tdlr": "This paper investigates the Bayesian regret of a variant of Thompson-Sampling algorithm for linear bandit problems, establishing new bounds that depend on the metric entropy of the action space, offering a tight rate of $O(d\\sqrt{T})$ for $d$-dimensional linear bandit problems."
}