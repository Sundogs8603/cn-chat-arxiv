{
    "title": "STREAM: Spatio-TempoRal Evaluation and Analysis Metric for Video Generative Models",
    "abstract": "arXiv:2403.09669v1 Announce Type: cross  Abstract: Image generative models have made significant progress in generating realistic and diverse images, supported by comprehensive guidance from various evaluation metrics. However, current video generative models struggle to generate even short video clips, with limited tools that provide insights for improvements. Current video evaluation metrics are simple adaptations of image metrics by switching the embeddings with video embedding networks, which may underestimate the unique characteristics of video. Our analysis reveals that the widely used Frechet Video Distance (FVD) has a stronger emphasis on the spatial aspect than the temporal naturalness of video and is inherently constrained by the input size of the embedding networks used, limiting it to 16 frames. Additionally, it demonstrates considerable instability and diverges from human evaluations. To address the limitations, we propose STREAM, a new video evaluation metric uniquely des",
    "link": "https://arxiv.org/abs/2403.09669",
    "context": "Title: STREAM: Spatio-TempoRal Evaluation and Analysis Metric for Video Generative Models\nAbstract: arXiv:2403.09669v1 Announce Type: cross  Abstract: Image generative models have made significant progress in generating realistic and diverse images, supported by comprehensive guidance from various evaluation metrics. However, current video generative models struggle to generate even short video clips, with limited tools that provide insights for improvements. Current video evaluation metrics are simple adaptations of image metrics by switching the embeddings with video embedding networks, which may underestimate the unique characteristics of video. Our analysis reveals that the widely used Frechet Video Distance (FVD) has a stronger emphasis on the spatial aspect than the temporal naturalness of video and is inherently constrained by the input size of the embedding networks used, limiting it to 16 frames. Additionally, it demonstrates considerable instability and diverges from human evaluations. To address the limitations, we propose STREAM, a new video evaluation metric uniquely des",
    "path": "papers/24/03/2403.09669.json",
    "total_tokens": 800,
    "translated_title": "STREAM：用于视频生成模型的时空评估和分析度量",
    "translated_abstract": "图像生成模型在生成逼真多样的图像方面取得了显著进展，得益于各种评估度量的全面指导。然而，当前的视频生成模型在生成短视频片段时仍然存在困难，缺乏提供改进见解的工具。目前的视频评估度量方法是通过将嵌入视频嵌入网络来简单调整图像度量方法而得到的，这可能低估了视频的独特特性。我们的分析表明，广泛使用的Frechet Video Distance (FVD) 在空间方面的重视程度要大于视频的时间自然性，且受到所使用的嵌入网络输入大小的限制，仅限于16帧视频。此外，它表现出相当大的不稳定性，并与人类评估存在差异。为了解决这些限制，我们提出了STREAM，一种新的视频评估度量方法，独特地设计以解决当前视频生成模型评估的挑战。",
    "tldr": "提出了STREAM，一种新的视频评估度量方法，弥补了当前视频生成模型评估中对于时空特性的不足"
}