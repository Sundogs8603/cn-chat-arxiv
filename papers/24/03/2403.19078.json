{
    "title": "MVEB: Self-Supervised Learning with Multi-View Entropy Bottleneck",
    "abstract": "arXiv:2403.19078v1 Announce Type: cross  Abstract: Self-supervised learning aims to learn representation that can be effectively generalized to downstream tasks. Many self-supervised approaches regard two views of an image as both the input and the self-supervised signals, assuming that either view contains the same task-relevant information and the shared information is (approximately) sufficient for predicting downstream tasks. Recent studies show that discarding superfluous information not shared between the views can improve generalization. Hence, the ideal representation is sufficient for downstream tasks and contains minimal superfluous information, termed minimal sufficient representation. One can learn this representation by maximizing the mutual information between the representation and the supervised view while eliminating superfluous information. Nevertheless, the computation of mutual information is notoriously intractable. In this work, we propose an objective termed mult",
    "link": "https://arxiv.org/abs/2403.19078",
    "context": "Title: MVEB: Self-Supervised Learning with Multi-View Entropy Bottleneck\nAbstract: arXiv:2403.19078v1 Announce Type: cross  Abstract: Self-supervised learning aims to learn representation that can be effectively generalized to downstream tasks. Many self-supervised approaches regard two views of an image as both the input and the self-supervised signals, assuming that either view contains the same task-relevant information and the shared information is (approximately) sufficient for predicting downstream tasks. Recent studies show that discarding superfluous information not shared between the views can improve generalization. Hence, the ideal representation is sufficient for downstream tasks and contains minimal superfluous information, termed minimal sufficient representation. One can learn this representation by maximizing the mutual information between the representation and the supervised view while eliminating superfluous information. Nevertheless, the computation of mutual information is notoriously intractable. In this work, we propose an objective termed mult",
    "path": "papers/24/03/2403.19078.json",
    "total_tokens": 800,
    "translated_title": "MVEB：具有多视图熵瓶颈的自监督学习",
    "translated_abstract": "自监督学习旨在学习能够有效推广到下游任务的表示。许多自监督方法将图像的两个视图视为输入和自监督信号，假定任一视图都包含相同的与任务相关信息，并且共享信息（大致）足以预测下游任务。最近的研究表明，舍弃视图之间不共享的多余信息可以改善泛化能力。因此，理想的表示对下游任务是足够的，并且包含最少的多余信息，称为最小足够表示。一个可以通过最大化表示和监督视图之间的互信息并消除多余信息来学习这种表示。然而，互信息的计算因为困难而臭名昭着。在本工作中，我们提出一种称为多视图熵瓶颈的目标。",
    "tldr": "该工作提出了一种名为MVEB的方法，通过消除图像视图之间不共享的多余信息，实现了最小足够表示的学习，并解决了互信息计算困难的问题。",
    "en_tdlr": "This work introduces a method named MVEB, which achieves learning of minimal sufficient representation by eliminating superfluous information not shared between image views and addresses the challenge of computing mutual information."
}