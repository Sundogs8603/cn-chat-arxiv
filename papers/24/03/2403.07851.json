{
    "title": "12 mJ per Class On-Device Online Few-Shot Class-Incremental Learning",
    "abstract": "arXiv:2403.07851v1 Announce Type: new  Abstract: Few-Shot Class-Incremental Learning (FSCIL) enables machine learning systems to expand their inference capabilities to new classes using only a few labeled examples, without forgetting the previously learned classes. Classical backpropagation-based learning and its variants are often unsuitable for battery-powered, memory-constrained systems at the extreme edge. In this work, we introduce Online Few-Shot Class-Incremental Learning (O-FSCIL), based on a lightweight model consisting of a pretrained and metalearned feature extractor and an expandable explicit memory storing the class prototypes. The architecture is pretrained with a novel feature orthogonality regularization and metalearned with a multi-margin loss. For learning a new class, our approach extends the explicit memory with novel class prototypes, while the remaining architecture is kept frozen. This allows learning previously unseen classes based on only a few examples with on",
    "link": "https://arxiv.org/abs/2403.07851",
    "context": "Title: 12 mJ per Class On-Device Online Few-Shot Class-Incremental Learning\nAbstract: arXiv:2403.07851v1 Announce Type: new  Abstract: Few-Shot Class-Incremental Learning (FSCIL) enables machine learning systems to expand their inference capabilities to new classes using only a few labeled examples, without forgetting the previously learned classes. Classical backpropagation-based learning and its variants are often unsuitable for battery-powered, memory-constrained systems at the extreme edge. In this work, we introduce Online Few-Shot Class-Incremental Learning (O-FSCIL), based on a lightweight model consisting of a pretrained and metalearned feature extractor and an expandable explicit memory storing the class prototypes. The architecture is pretrained with a novel feature orthogonality regularization and metalearned with a multi-margin loss. For learning a new class, our approach extends the explicit memory with novel class prototypes, while the remaining architecture is kept frozen. This allows learning previously unseen classes based on only a few examples with on",
    "path": "papers/24/03/2403.07851.json",
    "total_tokens": 845,
    "translated_title": "设备上每类12毫焦的在线少样本类增量学习",
    "translated_abstract": "《少样本类增量学习（FSCIL）》使机器学习系统仅使用少量已标记的示例即可扩展其对新类的推理能力，而不会忘记先前学习过的类。本文介绍了一种基于轻量级模型的《在线少样本类增量学习（O-FSCIL）》，该模型由预训练和元学习的特征提取器以及存储类原型的可扩展显式内存组成。该架构使用一种新颖的特征正交正则化进行预训练，并通过多边界损失进行元学习。对于学习新类，我们的方法通过新的类原型扩展显式内存，同时保持其余架构冻结。这样可以基于仅仅少量示例学习以前未见过的类。",
    "tldr": "该论文提出了基于轻量级模型的在线少样本类增量学习（O-FSCIL），使用特征正交正则化和多边界损失进行预训练和元学习，在设备上实现每类12毫焦的学习能力。",
    "en_tdlr": "The paper introduces On-Device Online Few-Shot Class-Incremental Learning (O-FSCIL) based on a lightweight model, achieving a learning capability of 12 mJ per class using feature orthogonality regularization and multi-margin loss for pretraining and metalearning."
}