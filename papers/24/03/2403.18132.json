{
    "title": "Recommendation of data-free class-incremental learning algorithms by simulating future data",
    "abstract": "arXiv:2403.18132v1 Announce Type: cross  Abstract: Class-incremental learning deals with sequential data streams composed of batches of classes. Various algorithms have been proposed to address the challenging case where samples from past classes cannot be stored. However, selecting an appropriate algorithm for a user-defined setting is an open problem, as the relative performance of these algorithms depends on the incremental settings. To solve this problem, we introduce an algorithm recommendation method that simulates the future data stream. Given an initial set of classes, it leverages generative models to simulate future classes from the same visual domain. We evaluate recent algorithms on the simulated stream and recommend the one which performs best in the user-defined incremental setting. We illustrate the effectiveness of our method on three large datasets using six algorithms and six incremental settings. Our method outperforms competitive baselines, and performance is close ",
    "link": "https://arxiv.org/abs/2403.18132",
    "context": "Title: Recommendation of data-free class-incremental learning algorithms by simulating future data\nAbstract: arXiv:2403.18132v1 Announce Type: cross  Abstract: Class-incremental learning deals with sequential data streams composed of batches of classes. Various algorithms have been proposed to address the challenging case where samples from past classes cannot be stored. However, selecting an appropriate algorithm for a user-defined setting is an open problem, as the relative performance of these algorithms depends on the incremental settings. To solve this problem, we introduce an algorithm recommendation method that simulates the future data stream. Given an initial set of classes, it leverages generative models to simulate future classes from the same visual domain. We evaluate recent algorithms on the simulated stream and recommend the one which performs best in the user-defined incremental setting. We illustrate the effectiveness of our method on three large datasets using six algorithms and six incremental settings. Our method outperforms competitive baselines, and performance is close ",
    "path": "papers/24/03/2403.18132.json",
    "total_tokens": 783,
    "translated_title": "通过模拟未来数据推荐无数据的类递增学习算法",
    "translated_abstract": "类递增学习处理由类别批次组成的顺序数据流。已经提出了各种算法来解决从无法存储过去类别的样本的具有挑战性的情况。然而，为用户定义的设置选择适当的算法是一个未解之谜，因为这些算法的相对性能取决于递增设置。为了解决这个问题，我们引入了一种模拟未来数据流的算法推荐方法。给定一个初始类别集合，它利用生成模型从相同的视觉域模拟未来类别。我们在模拟流上评估了最近的算法，并推荐在用户定义的递增设置中表现最佳的算法。我们使用六种算法和六个递增设置，在三个大型数据集上展示了我们方法的有效性。我们的方法胜过了竞争基线，并且性能接近",
    "tldr": "通过模拟未来数据流，推荐无数据的类递增学习算法，实验结果表明方法胜过竞争基线",
    "en_tdlr": "Recommending data-free class-incremental learning algorithms by simulating future data streams, experimental results show the method outperforms competitive baselines."
}