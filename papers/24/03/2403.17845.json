{
    "title": "TractOracle: towards an anatomically-informed reward function for RL-based tractography",
    "abstract": "arXiv:2403.17845v1 Announce Type: new  Abstract: Reinforcement learning (RL)-based tractography is a competitive alternative to machine learning and classical tractography algorithms due to its high anatomical accuracy obtained without the need for any annotated data. However, the reward functions so far used to train RL agents do not encapsulate anatomical knowledge which causes agents to generate spurious false positives tracts. In this paper, we propose a new RL tractography system, TractOracle, which relies on a reward network trained for streamline classification. This network is used both as a reward function during training as well as a mean for stopping the tracking process early and thus reduce the number of false positive streamlines. This makes our system a unique method that evaluates and reconstructs WM streamlines at the same time. We report an improvement of true positive ratios by almost 20\\% and a reduction of 3x of false positive ratios on one dataset and an increase ",
    "link": "https://arxiv.org/abs/2403.17845",
    "context": "Title: TractOracle: towards an anatomically-informed reward function for RL-based tractography\nAbstract: arXiv:2403.17845v1 Announce Type: new  Abstract: Reinforcement learning (RL)-based tractography is a competitive alternative to machine learning and classical tractography algorithms due to its high anatomical accuracy obtained without the need for any annotated data. However, the reward functions so far used to train RL agents do not encapsulate anatomical knowledge which causes agents to generate spurious false positives tracts. In this paper, we propose a new RL tractography system, TractOracle, which relies on a reward network trained for streamline classification. This network is used both as a reward function during training as well as a mean for stopping the tracking process early and thus reduce the number of false positive streamlines. This makes our system a unique method that evaluates and reconstructs WM streamlines at the same time. We report an improvement of true positive ratios by almost 20\\% and a reduction of 3x of false positive ratios on one dataset and an increase ",
    "path": "papers/24/03/2403.17845.json",
    "total_tokens": 884,
    "translated_title": "TractOracle: 为基于RL的纤维束追踪提供一个解剖学知识驱动的奖励函数",
    "translated_abstract": "强化学习（RL）基于的纤维束追踪是一种竞争性的替代方案，能够以较高的解剖学准确性进行操作，而无需任何注释数据。然而，迄今为止用于训练RL代理的奖励功能并不包含解剖知识，这导致代理生成虚假阳性的纤维束。在本文中，我们提出了一个新的RL纤维束追踪系统，TractOracle，它依赖于一个用于分类的追踪网络训练的奖励网络。该网络在训练过程中既用作奖励函数，又用作早期停止追踪过程的手段，从而减少虚假阳性纤维束的数量。这使得我们的系统成为一种同时评估和重建WM纤维束的独特方法。我们在一个数据集上报告了真阳性比率几乎提高了20\\%，假阳性比率减少了3倍。",
    "tldr": "TractOracle 提出了一种新的RL纤维束追踪系统，通过基于解剖学知识的奖励函数提高了真阳性比率并降低了虚假阳性比率",
    "en_tdlr": "TractOracle proposes a new RL tractography system that improves true positive rates and reduces false positive rates by using an anatomically-informed reward function."
}