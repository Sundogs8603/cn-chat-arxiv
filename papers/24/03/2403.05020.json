{
    "title": "Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs",
    "abstract": "arXiv:2403.05020v1 Announce Type: cross  Abstract: Recent advances in large language models (LLM) have enabled richer social simulations, allowing for the study of various social phenomena with LLM-based agents. However, most work has used an omniscient perspective on these simulations (e.g., single LLM to generate all interlocutors), which is fundamentally at odds with the non-omniscient, information asymmetric interactions that humans have. To examine these differences, we develop an evaluation framework to simulate social interactions with LLMs in various settings (omniscient, non-omniscient). Our experiments show that interlocutors simulated omnisciently are much more successful at accomplishing social goals compared to non-omniscient agents, despite the latter being the more realistic setting. Furthermore, we demonstrate that learning from omniscient simulations improves the apparent naturalness of interactions but scarcely enhances goal achievement in cooperative scenarios. Our f",
    "link": "https://arxiv.org/abs/2403.05020",
    "context": "Title: Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs\nAbstract: arXiv:2403.05020v1 Announce Type: cross  Abstract: Recent advances in large language models (LLM) have enabled richer social simulations, allowing for the study of various social phenomena with LLM-based agents. However, most work has used an omniscient perspective on these simulations (e.g., single LLM to generate all interlocutors), which is fundamentally at odds with the non-omniscient, information asymmetric interactions that humans have. To examine these differences, we develop an evaluation framework to simulate social interactions with LLMs in various settings (omniscient, non-omniscient). Our experiments show that interlocutors simulated omnisciently are much more successful at accomplishing social goals compared to non-omniscient agents, despite the latter being the more realistic setting. Furthermore, we demonstrate that learning from omniscient simulations improves the apparent naturalness of interactions but scarcely enhances goal achievement in cooperative scenarios. Our f",
    "path": "papers/24/03/2403.05020.json",
    "total_tokens": 804,
    "translated_title": "模拟社交互动成功性的误导性：以LLMs为例",
    "translated_abstract": "最近大型语言模型（LLM）的进展使得社交模拟更加丰富，能够使用基于LLM的代理人研究各种社交现象。然而，大多数工作在这些模拟中采用了一种全知的透视（例如，单个LLM生成所有交谈者），这与人类具有的非全知、信息不对称的互动根本不符。为了研究这些差异，我们开发了一个评估框架，在各种设定（全知、非全知）中使用LLMs模拟社交互动。我们的实验表明，通过全知方式模拟的交谈者在实现社交目标方面比非全知代理人更成功，尽管后者更符合现实设置。此外，我们表明从全知模拟中学习可以改善交互的自然性，但在合作场景中几乎不能增强目标实现。",
    "tldr": "研究发现，使用LLMs进行社交互动的全知模拟比非全知模拟更容易实现社交目标，尽管非全知模拟更接近实际情况。"
}