{
    "title": "Efficient High-Resolution Time Series Classification via Attention Kronecker Decomposition",
    "abstract": "arXiv:2403.04882v1 Announce Type: new  Abstract: The high-resolution time series classification problem is essential due to the increasing availability of detailed temporal data in various domains. To tackle this challenge effectively, it is imperative that the state-of-the-art attention model is scalable to accommodate the growing sequence lengths typically encountered in high-resolution time series data, while also demonstrating robustness in handling the inherent noise prevalent in such datasets. To address this, we propose to hierarchically encode the long time series into multiple levels based on the interaction ranges. By capturing relationships at different levels, we can build more robust, expressive, and efficient models that are capable of capturing both short-term fluctuations and long-term trends in the data. We then propose a new time series transformer backbone (KronTime) by introducing Kronecker-decomposed attention to process such multi-level time series, which sequenti",
    "link": "https://arxiv.org/abs/2403.04882",
    "context": "Title: Efficient High-Resolution Time Series Classification via Attention Kronecker Decomposition\nAbstract: arXiv:2403.04882v1 Announce Type: new  Abstract: The high-resolution time series classification problem is essential due to the increasing availability of detailed temporal data in various domains. To tackle this challenge effectively, it is imperative that the state-of-the-art attention model is scalable to accommodate the growing sequence lengths typically encountered in high-resolution time series data, while also demonstrating robustness in handling the inherent noise prevalent in such datasets. To address this, we propose to hierarchically encode the long time series into multiple levels based on the interaction ranges. By capturing relationships at different levels, we can build more robust, expressive, and efficient models that are capable of capturing both short-term fluctuations and long-term trends in the data. We then propose a new time series transformer backbone (KronTime) by introducing Kronecker-decomposed attention to process such multi-level time series, which sequenti",
    "path": "papers/24/03/2403.04882.json",
    "total_tokens": 778,
    "translated_title": "通过注意力 Kronecker 分解实现高分辨率时间序列分类的高效性",
    "translated_abstract": "高分辨率时间序列分类问题由于各个领域中详细时间数据不断增加而变得至关重要。为了有效应对这一挑战，关键在于当前最先进的注意力模型能够在高分辨率时间序列数据中处理逐渐增长的序列长度，并且展现出在处理这类数据中普遍存在的噪声时的鲁棒性。为了解决这一问题，我们建议根据交互范围将长时间序列分层编码为多个层级。通过在不同层级捕获关系，我们可以构建更加鲁棒、表达丰富和高效的模型，能够捕捉数据中的短期波动和长期趋势。然后，我们提出了一种新的时间序列变换器骨干（KronTime），通过引入 Kronecker 分解的注意力来处理这种多层次时间序列。",
    "tldr": "通过引入Kronecker分解的注意力， Hierarchical attention-based Kronecker-decomposition for high-resolution time series classification.",
    "en_tdlr": "Hierarchical attention-based Kronecker-decomposition for high-resolution time series classification by introducing Kronecker-decomposed attention."
}