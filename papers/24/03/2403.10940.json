{
    "title": "ViSaRL: Visual Reinforcement Learning Guided by Human Saliency",
    "abstract": "arXiv:2403.10940v1 Announce Type: cross  Abstract: Training robots to perform complex control tasks from high-dimensional pixel input using reinforcement learning (RL) is sample-inefficient, because image observations are comprised primarily of task-irrelevant information. By contrast, humans are able to visually attend to task-relevant objects and areas. Based on this insight, we introduce Visual Saliency-Guided Reinforcement Learning (ViSaRL). Using ViSaRL to learn visual representations significantly improves the success rate, sample efficiency, and generalization of an RL agent on diverse tasks including DeepMind Control benchmark, robot manipulation in simulation and on a real robot. We present approaches for incorporating saliency into both CNN and Transformer-based encoders. We show that visual representations learned using ViSaRL are robust to various sources of visual perturbations including perceptual noise and scene variations. ViSaRL nearly doubles success rate on the real-",
    "link": "https://arxiv.org/abs/2403.10940",
    "context": "Title: ViSaRL: Visual Reinforcement Learning Guided by Human Saliency\nAbstract: arXiv:2403.10940v1 Announce Type: cross  Abstract: Training robots to perform complex control tasks from high-dimensional pixel input using reinforcement learning (RL) is sample-inefficient, because image observations are comprised primarily of task-irrelevant information. By contrast, humans are able to visually attend to task-relevant objects and areas. Based on this insight, we introduce Visual Saliency-Guided Reinforcement Learning (ViSaRL). Using ViSaRL to learn visual representations significantly improves the success rate, sample efficiency, and generalization of an RL agent on diverse tasks including DeepMind Control benchmark, robot manipulation in simulation and on a real robot. We present approaches for incorporating saliency into both CNN and Transformer-based encoders. We show that visual representations learned using ViSaRL are robust to various sources of visual perturbations including perceptual noise and scene variations. ViSaRL nearly doubles success rate on the real-",
    "path": "papers/24/03/2403.10940.json",
    "total_tokens": 887,
    "translated_title": "ViSaRL：受人类显著性引导的视觉强化学习",
    "translated_abstract": "使用强化学习（RL）从高维像素输入培训机器人执行复杂控制任务在样本效率上是低效的，因为图像观察主要由与任务无关的信息组成。相比之下，人类能够在视觉上关注与任务相关的对象和区域。基于这一观察，我们引入了受视觉显著性引导的强化学习（ViSaRL）。使用ViSaRL学习视觉表示显着提高了RL代理在不同任务上，包括DeepMind控制基准、仿真中的机器人操作和真实机器人上的成功率、样本效率和泛化性能。我们提出了将显著性整合到基于CNN和Transformer的编码器中的方法。我们展示使用ViSaRL学习的视觉表示对各种视觉扰动，包括感知噪声和场景变化，都具有鲁棒性。ViSaRL在真实环境中成功率几乎翻了一番。",
    "tldr": "ViSaRL提出了Visual Saliency-Guided Reinforcement Learning（受视觉显著性引导的强化学习）方法，通过学习视觉表示来显著提高RL代理在不同任务上的成功率、样本效率和泛化性能。",
    "en_tdlr": "ViSaRL introduces Visual Saliency-Guided Reinforcement Learning, which significantly enhances the success rate, sample efficiency, and generalization of RL agents on diverse tasks by learning visual representations."
}