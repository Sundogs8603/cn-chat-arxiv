{
    "title": "ACLSum: A New Dataset for Aspect-based Summarization of Scientific Publications",
    "abstract": "arXiv:2403.05303v1 Announce Type: new  Abstract: Extensive efforts in the past have been directed toward the development of summarization datasets. However, a predominant number of these resources have been (semi)-automatically generated, typically through web data crawling, resulting in subpar resources for training and evaluating summarization systems, a quality compromise that is arguably due to the substantial costs associated with generating ground-truth summaries, particularly for diverse languages and specialized domains. To address this issue, we present ACLSum, a novel summarization dataset carefully crafted and evaluated by domain experts. In contrast to previous datasets, ACLSum facilitates multi-aspect summarization of scientific papers, covering challenges, approaches, and outcomes in depth. Through extensive experiments, we evaluate the quality of our resource and the performance of models based on pretrained language models and state-of-the-art large language models (LLM",
    "link": "https://arxiv.org/abs/2403.05303",
    "context": "Title: ACLSum: A New Dataset for Aspect-based Summarization of Scientific Publications\nAbstract: arXiv:2403.05303v1 Announce Type: new  Abstract: Extensive efforts in the past have been directed toward the development of summarization datasets. However, a predominant number of these resources have been (semi)-automatically generated, typically through web data crawling, resulting in subpar resources for training and evaluating summarization systems, a quality compromise that is arguably due to the substantial costs associated with generating ground-truth summaries, particularly for diverse languages and specialized domains. To address this issue, we present ACLSum, a novel summarization dataset carefully crafted and evaluated by domain experts. In contrast to previous datasets, ACLSum facilitates multi-aspect summarization of scientific papers, covering challenges, approaches, and outcomes in depth. Through extensive experiments, we evaluate the quality of our resource and the performance of models based on pretrained language models and state-of-the-art large language models (LLM",
    "path": "papers/24/03/2403.05303.json",
    "total_tokens": 806,
    "translated_title": "ACLSum：一种新的用于科学出版物基于方面的摘要的数据集",
    "translated_abstract": "过去，人们已经付出了大量努力来开发摘要数据集。然而，大部分资源是(半)自动生成的，通常是通过网络数据爬取得到的，导致了用于训练和评估摘要系统的资源质量不佳，这可能是由于生成基准摘要的高昂成本，尤其是针对多种语言和专业领域。为解决这一问题，我们提出了ACLSum，这是一个由领域专家精心制作和评估的新型摘要数据集。与以往的数据集不同，ACLSum支持对科学论文进行多方面摘要，深入涵盖挑战、方法和结果。通过大量实验，我们评估了我们的资源质量以及基于预训练语言模型和最先进的大型语言模型(LLM)的模型性能。",
    "tldr": "ACLSum是一个由领域专家精心制作和评估的新型摘要数据集，支持对科学论文进行多方面摘要，深入涵盖挑战、方法和结果。",
    "en_tdlr": "ACLSum is a novel summarization dataset carefully crafted and evaluated by domain experts, facilitating multi-aspect summarization of scientific papers, covering challenges, approaches, and outcomes in depth."
}