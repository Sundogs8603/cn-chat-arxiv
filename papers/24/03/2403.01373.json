{
    "title": "Evaluating and Mitigating Number Hallucinations in Large Vision-Language Models: A Consistency Perspective",
    "abstract": "arXiv:2403.01373v1 Announce Type: new  Abstract: Large vision language models have demonstrated remarkable efficacy in addressing challenges related to both textual and visual content. Nevertheless, these models are susceptible to various hallucinations. In this paper, we focus on a new form of hallucination, specifically termed as number hallucination, which denotes instances where models fail to accurately identify the quantity of objects in an image. We establish a dataset and employ evaluation metrics to assess number hallucination, revealing a pronounced prevalence of this issue across mainstream large vision language models (LVLMs). Additionally, we delve into a thorough analysis of number hallucination, examining inner and outer inconsistency problem from two related perspectives. We assert that this inconsistency is one cause of number hallucination and propose a consistency training method as a means to alleviate such hallucination, which achieves an average improvement of 8\\%",
    "link": "https://arxiv.org/abs/2403.01373",
    "context": "Title: Evaluating and Mitigating Number Hallucinations in Large Vision-Language Models: A Consistency Perspective\nAbstract: arXiv:2403.01373v1 Announce Type: new  Abstract: Large vision language models have demonstrated remarkable efficacy in addressing challenges related to both textual and visual content. Nevertheless, these models are susceptible to various hallucinations. In this paper, we focus on a new form of hallucination, specifically termed as number hallucination, which denotes instances where models fail to accurately identify the quantity of objects in an image. We establish a dataset and employ evaluation metrics to assess number hallucination, revealing a pronounced prevalence of this issue across mainstream large vision language models (LVLMs). Additionally, we delve into a thorough analysis of number hallucination, examining inner and outer inconsistency problem from two related perspectives. We assert that this inconsistency is one cause of number hallucination and propose a consistency training method as a means to alleviate such hallucination, which achieves an average improvement of 8\\%",
    "path": "papers/24/03/2403.01373.json",
    "total_tokens": 817,
    "translated_title": "评估和减少大规模视觉语言模型中的数字幻觉：一种一致性视角",
    "translated_abstract": "大型视觉语言模型已经展示出在处理文本和视觉内容相关挑战方面的显著功效。然而，这些模型容易出现各种幻觉。本文关注一种新形式的幻觉，称为数字幻觉，指的是模型未能准确识别图像中物体的数量的情况。我们建立了一个数据集，并采用评估指标评估数字幻觉，揭示了这一问题在主流大型视觉语言模型(LVLMs)中的明显普遍性。此外，我们从两个相关视角深入分析了数字幻觉，考察了内在和外在的不一致问题。我们认为这种不一致性是数字幻觉的一个原因，并提出了一种一致性训练方法作为减轻此类幻觉的手段，该方法取得了8%的平均改进。",
    "tldr": "本文评估了大型视觉语言模型中的数字幻觉问题，并提出一种一致性训练方法，可使数字幻觉得到显著改善",
    "en_tdlr": "This paper evaluates number hallucinations in large vision-language models and proposes a consistency training method to significantly improve the issue."
}