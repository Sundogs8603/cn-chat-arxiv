{
    "title": "Exploring Continual Learning of Compositional Generalization in NLI",
    "abstract": "arXiv:2403.04400v1 Announce Type: new  Abstract: Compositional Natural Language Inference has been explored to assess the true abilities of neural models to perform NLI. Yet, current evaluations assume models to have full access to all primitive inferences in advance, in contrast to humans that continuously acquire inference knowledge. In this paper, we introduce the Continual Compositional Generalization in Inference (C2Gen NLI) challenge, where a model continuously acquires knowledge of constituting primitive inference tasks as a basis for compositional inferences. We explore how continual learning affects compositional generalization in NLI, by designing a continual learning setup for compositional NLI inference tasks. Our experiments demonstrate that models fail to compositionally generalize in a continual scenario. To address this problem, we first benchmark various continual learning algorithms and verify their efficacy. We then further analyze C2Gen, focusing on how to order pri",
    "link": "https://arxiv.org/abs/2403.04400",
    "context": "Title: Exploring Continual Learning of Compositional Generalization in NLI\nAbstract: arXiv:2403.04400v1 Announce Type: new  Abstract: Compositional Natural Language Inference has been explored to assess the true abilities of neural models to perform NLI. Yet, current evaluations assume models to have full access to all primitive inferences in advance, in contrast to humans that continuously acquire inference knowledge. In this paper, we introduce the Continual Compositional Generalization in Inference (C2Gen NLI) challenge, where a model continuously acquires knowledge of constituting primitive inference tasks as a basis for compositional inferences. We explore how continual learning affects compositional generalization in NLI, by designing a continual learning setup for compositional NLI inference tasks. Our experiments demonstrate that models fail to compositionally generalize in a continual scenario. To address this problem, we first benchmark various continual learning algorithms and verify their efficacy. We then further analyze C2Gen, focusing on how to order pri",
    "path": "papers/24/03/2403.04400.json",
    "total_tokens": 862,
    "translated_title": "在自然语言推理中探索组合泛化的不间断学习",
    "translated_abstract": "组合自然语言推理已被用来评估神经模型执行NLI的真实能力。然而，当前的评估假设模型事先完全访问所有原始推理，与人类不断获得推理知识的方式相反。在本文中，我们介绍了推理中的连续组合泛化（C2Gen NLI）挑战，其中模型持续获取构成原始推理任务的知识作为组合推理的基础。我们研究了不断学习如何影响NLI中的组合泛化，通过为组合NLI推理任务设计了一个不断学习设置。我们的实验表明，模型在不断学习的情况下无法组合泛化。为了解决这个问题，我们首先对各种不断学习算法进行基准测试并验证它们的功效。然后，我们进一步分析了C2Gen，重点关注如何排序",
    "tldr": "本文介绍了连续组合泛化挑战，探讨了模型如何持续获取原始推理任务的知识并进行组合推理，研究了不断学习对NLI中组合泛化的影响，并提出了解决方案。",
    "en_tdlr": "This paper introduces the C2Gen NLI challenge, explores how models continuously acquire knowledge of primitive inference tasks for compositional inferences, investigates the impact of continual learning on compositional generalization in NLI, and proposes solutions."
}