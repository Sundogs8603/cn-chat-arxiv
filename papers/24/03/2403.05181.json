{
    "title": "Adversarial Sparse Teacher: Defense Against Distillation-Based Model Stealing Attacks Using Adversarial Examples",
    "abstract": "arXiv:2403.05181v1 Announce Type: new  Abstract: Knowledge Distillation (KD) facilitates the transfer of discriminative capabilities from an advanced teacher model to a simpler student model, ensuring performance enhancement without compromising accuracy. It is also exploited for model stealing attacks, where adversaries use KD to mimic the functionality of a teacher model. Recent developments in this domain have been influenced by the Stingy Teacher model, which provided empirical analysis showing that sparse outputs can significantly degrade the performance of student models. Addressing the risk of intellectual property leakage, our work introduces an approach to train a teacher model that inherently protects its logits, influenced by the Nasty Teacher concept. Differing from existing methods, we incorporate sparse outputs of adversarial examples with standard training data to strengthen the teacher's defense against student distillation. Our approach carefully reduces the relative e",
    "link": "https://arxiv.org/abs/2403.05181",
    "context": "Title: Adversarial Sparse Teacher: Defense Against Distillation-Based Model Stealing Attacks Using Adversarial Examples\nAbstract: arXiv:2403.05181v1 Announce Type: new  Abstract: Knowledge Distillation (KD) facilitates the transfer of discriminative capabilities from an advanced teacher model to a simpler student model, ensuring performance enhancement without compromising accuracy. It is also exploited for model stealing attacks, where adversaries use KD to mimic the functionality of a teacher model. Recent developments in this domain have been influenced by the Stingy Teacher model, which provided empirical analysis showing that sparse outputs can significantly degrade the performance of student models. Addressing the risk of intellectual property leakage, our work introduces an approach to train a teacher model that inherently protects its logits, influenced by the Nasty Teacher concept. Differing from existing methods, we incorporate sparse outputs of adversarial examples with standard training data to strengthen the teacher's defense against student distillation. Our approach carefully reduces the relative e",
    "path": "papers/24/03/2403.05181.json",
    "total_tokens": 883,
    "translated_title": "Adversarial Sparse Teacher: 对抗敌对示例，防御用对抗示例进行的基于蒸馏的模型窃取攻击",
    "translated_abstract": "知识蒸馏（KD）促进了将高级教师模型的区分能力转移到更简单的学生模型，确保提高性能而不影响准确性。它也被用于模型窃取攻击，其中对手使用KD来模仿教师模型的功能。最近在该领域的发展受到了吝啬教师模型的影响，该模型通过实证分析表明稀疏输出可以显著降低学生模型的性能。为了解决知识产权泄露的风险，我们的工作引入了一种训练教师模型的方法，该方法从根本上保护其logits，受“恶毒教师”理念的影响。与现有方法不同，我们将对抗示例的稀疏输出与标准训练数据结合起来，以加强教师对学生蒸馏的防御。我们的方法巧妙地减少了相对的e",
    "tldr": "本文提出了一种训练教师模型的方法，通过引入敌对示例的稀疏输出，并与标准训练数据结合使用，来加强教师模型对学生蒸馏的防御。",
    "en_tdlr": "This paper presents an approach to train a teacher model by incorporating sparse outputs of adversarial examples with standard training data to strengthen the teacher's defense against student distillation."
}