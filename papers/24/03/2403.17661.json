{
    "title": "Language Models for Text Classification: Is In-Context Learning Enough?",
    "abstract": "arXiv:2403.17661v1 Announce Type: cross  Abstract: Recent foundational language models have shown state-of-the-art performance in many NLP tasks in zero- and few-shot settings. An advantage of these models over more standard approaches based on fine-tuning is the ability to understand instructions written in natural language (prompts), which helps them generalise better to different tasks and domains without the need for specific training data. This makes them suitable for addressing text classification problems for domains with limited amounts of annotated instances. However, existing research is limited in scale and lacks understanding of how text generation models combined with prompting techniques compare to more established methods for text classification such as fine-tuning masked language models. In this paper, we address this research gap by performing a large-scale evaluation study for 16 text classification datasets covering binary, multiclass, and multilabel problems. In par",
    "link": "https://arxiv.org/abs/2403.17661",
    "context": "Title: Language Models for Text Classification: Is In-Context Learning Enough?\nAbstract: arXiv:2403.17661v1 Announce Type: cross  Abstract: Recent foundational language models have shown state-of-the-art performance in many NLP tasks in zero- and few-shot settings. An advantage of these models over more standard approaches based on fine-tuning is the ability to understand instructions written in natural language (prompts), which helps them generalise better to different tasks and domains without the need for specific training data. This makes them suitable for addressing text classification problems for domains with limited amounts of annotated instances. However, existing research is limited in scale and lacks understanding of how text generation models combined with prompting techniques compare to more established methods for text classification such as fine-tuning masked language models. In this paper, we address this research gap by performing a large-scale evaluation study for 16 text classification datasets covering binary, multiclass, and multilabel problems. In par",
    "path": "papers/24/03/2403.17661.json",
    "total_tokens": 836,
    "translated_title": "文本分类的语言模型：仅仅上下文学习就足够了吗？",
    "translated_abstract": "最近的基础语言模型在零次和少次标记设置中展示了在许多自然语言处理任务中的最先进性能。这些模型相对于基于微调的更标准的方法的优势在于能够理解用自然语言编写的指令（提示），这有助于它们更好地推广到不同的任务和领域，而无需特定的训练数据。这使它们适合解决具有有限标注实例数量的领域的文本分类问题。但是，现有研究在规模上有限，并缺乏对文本生成模型与提示技术相结合与更传统的文本分类方法（如微调掩码语言模型）的比较的理解。在本文中，我们通过对涵盖二元、多类和多标签问题的16个文本分类数据集进行大规模评估研究来填补这一研究空白。",
    "tldr": "本研究通过对16个文本分类数据集的大规模评估研究，填补了现有研究缺乏对文本生成模型与提示技术与更传统的文本分类方法之间比较的理解。"
}