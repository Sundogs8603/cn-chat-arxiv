{
    "title": "Quality-Diversity Actor-Critic: Learning High-Performing and Diverse Behaviors via Value and Successor Features Critics",
    "abstract": "arXiv:2403.09930v1 Announce Type: cross  Abstract: A key aspect of intelligence is the ability to demonstrate a broad spectrum of behaviors for adapting to unexpected situations. Over the past decade, advancements in deep reinforcement learning have led to groundbreaking achievements to solve complex continuous control tasks. However, most approaches return only one solution specialized for a specific problem. We introduce Quality-Diversity Actor-Critic (QDAC), an off-policy actor-critic deep reinforcement learning algorithm that leverages a value function critic and a successor features critic to learn high-performing and diverse behaviors. In this framework, the actor optimizes an objective that seamlessly unifies both critics using constrained optimization to (1) maximize return, while (2) executing diverse skills. Compared with other Quality-Diversity methods, QDAC achieves significantly higher performance and more diverse behaviors on six challenging continuous control locomotion ",
    "link": "https://arxiv.org/abs/2403.09930",
    "context": "Title: Quality-Diversity Actor-Critic: Learning High-Performing and Diverse Behaviors via Value and Successor Features Critics\nAbstract: arXiv:2403.09930v1 Announce Type: cross  Abstract: A key aspect of intelligence is the ability to demonstrate a broad spectrum of behaviors for adapting to unexpected situations. Over the past decade, advancements in deep reinforcement learning have led to groundbreaking achievements to solve complex continuous control tasks. However, most approaches return only one solution specialized for a specific problem. We introduce Quality-Diversity Actor-Critic (QDAC), an off-policy actor-critic deep reinforcement learning algorithm that leverages a value function critic and a successor features critic to learn high-performing and diverse behaviors. In this framework, the actor optimizes an objective that seamlessly unifies both critics using constrained optimization to (1) maximize return, while (2) executing diverse skills. Compared with other Quality-Diversity methods, QDAC achieves significantly higher performance and more diverse behaviors on six challenging continuous control locomotion ",
    "path": "papers/24/03/2403.09930.json",
    "total_tokens": 855,
    "translated_title": "质量多样性演员-评论家：通过值和继承特征评论家学习高性能和多样性行为",
    "translated_abstract": "智能的一个关键方面是表现出适应意外情况的广泛行为谱。过去十年，深度强化学习的进步取得了突破性成就，用于解决复杂的连续控制任务。然而，大多数方法只返回一个专门针对特定问题的解决方案。我们引入了质量多样性演员-评论家（QDAC），这是一种基于离策略演员-评论家深度强化学习算法，利用价值函数评论家和继承特征评论家学习高性能和多样性行为。在这个框架中，演员通过受限优化来最大化回报并执行多样性技能的客观函数，无缝统一了两个评论家。与其他质量多样性方法相比，QDAC在六个具有挑战性的连续控制运动任务上实现了显着更高的性能和更多样性的行为。",
    "tldr": "QDAC是一种基于离策略演员-评论家深度强化学习算法，通过价值函数评论家和继承特征评论家学习高性能和多样性行为。",
    "en_tdlr": "QDAC is an off-policy actor-critic deep reinforcement learning algorithm that leverages a value function critic and a successor features critic to learn high-performing and diverse behaviors."
}