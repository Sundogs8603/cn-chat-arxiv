{
    "title": "Wildest Dreams: Reproducible Research in Privacy-preserving Neural Network Training",
    "abstract": "arXiv:2403.03592v1 Announce Type: cross  Abstract: Machine Learning (ML), addresses a multitude of complex issues in multiple disciplines, including social sciences, finance, and medical research. ML models require substantial computing power and are only as powerful as the data utilized. Due to high computational cost of ML methods, data scientists frequently use Machine Learning-as-a-Service (MLaaS) to outsource computation to external servers. However, when working with private information, like financial data or health records, outsourcing the computation might result in privacy issues. Recent advances in Privacy-Preserving Techniques (PPTs) have enabled ML training and inference over protected data through the use of Privacy-Preserving Machine Learning (PPML). However, these techniques are still at a preliminary stage and their application in real-world situations is demanding. In order to comprehend discrepancy between theoretical research suggestions and actual applications, thi",
    "link": "https://arxiv.org/abs/2403.03592",
    "context": "Title: Wildest Dreams: Reproducible Research in Privacy-preserving Neural Network Training\nAbstract: arXiv:2403.03592v1 Announce Type: cross  Abstract: Machine Learning (ML), addresses a multitude of complex issues in multiple disciplines, including social sciences, finance, and medical research. ML models require substantial computing power and are only as powerful as the data utilized. Due to high computational cost of ML methods, data scientists frequently use Machine Learning-as-a-Service (MLaaS) to outsource computation to external servers. However, when working with private information, like financial data or health records, outsourcing the computation might result in privacy issues. Recent advances in Privacy-Preserving Techniques (PPTs) have enabled ML training and inference over protected data through the use of Privacy-Preserving Machine Learning (PPML). However, these techniques are still at a preliminary stage and their application in real-world situations is demanding. In order to comprehend discrepancy between theoretical research suggestions and actual applications, thi",
    "path": "papers/24/03/2403.03592.json",
    "total_tokens": 810,
    "translated_title": "Wildest Dreams: 隐私保护神经网络训练中可复现的研究",
    "translated_abstract": "机器学习（ML）涉及多个学科的复杂问题，包括社会科学、金融和医学研究。ML模型需要大量计算资源，其强大程度取决于所使用的数据。由于ML方法的高计算成本，数据科学家经常使用机器学习即服务（MLaaS）将计算外包给外部服务器。然而，当处理私人信息（如财务数据或健康记录）时，将计算外包可能会导致隐私问题。隐私保护技术（PPTs）的最新进展通过隐私保护机器学习（PPML）使得可以在受保护数据上进行ML训练和推断。然而，这些技术仍处于初步阶段，它们在实际情况中的应用要求较高。为了理解理论研究建议与实际应用之间的差异，",
    "tldr": "隐私保护技术的最新进展使得可以在受保护数据上进行机器学习训练和推断，但在实际应用中仍面临挑战。"
}