{
    "title": "Forest Inspection Dataset for Aerial Semantic Segmentation and Depth Estimation",
    "abstract": "arXiv:2403.06621v1 Announce Type: cross  Abstract: Humans use UAVs to monitor changes in forest environments since they are lightweight and provide a large variety of surveillance data. However, their information does not present enough details for understanding the scene which is needed to assess the degree of deforestation. Deep learning algorithms must be trained on large amounts of data to output accurate interpretations, but ground truth recordings of annotated forest imagery are not available. To solve this problem, we introduce a new large aerial dataset for forest inspection which contains both real-world and virtual recordings of natural environments, with densely annotated semantic segmentation labels and depth maps, taken in different illumination conditions, at various altitudes and recording angles. We test the performance of two multi-scale neural networks for solving the semantic segmentation task (HRNet and PointFlow network), studying the impact of the various acquisit",
    "link": "https://arxiv.org/abs/2403.06621",
    "context": "Title: Forest Inspection Dataset for Aerial Semantic Segmentation and Depth Estimation\nAbstract: arXiv:2403.06621v1 Announce Type: cross  Abstract: Humans use UAVs to monitor changes in forest environments since they are lightweight and provide a large variety of surveillance data. However, their information does not present enough details for understanding the scene which is needed to assess the degree of deforestation. Deep learning algorithms must be trained on large amounts of data to output accurate interpretations, but ground truth recordings of annotated forest imagery are not available. To solve this problem, we introduce a new large aerial dataset for forest inspection which contains both real-world and virtual recordings of natural environments, with densely annotated semantic segmentation labels and depth maps, taken in different illumination conditions, at various altitudes and recording angles. We test the performance of two multi-scale neural networks for solving the semantic segmentation task (HRNet and PointFlow network), studying the impact of the various acquisit",
    "path": "papers/24/03/2403.06621.json",
    "total_tokens": 809,
    "translated_title": "针对航空语义分割和深度估计的森林巡检数据集",
    "translated_abstract": "人类使用无人机来监测森林环境的变化，因为它们重量轻，提供了大量的监视数据。然而，它们的信息并不足以展示足够的细节，这对于评估森林砍伐程度是必要的。为了解决这个问题，我们引入了一个新的大型航空数据集，其中包含自然环境的真实和虚拟录影，具有密集注释的语义分割标签和深度地图，拍摄于不同的照明条件，不同高度和记录角度。我们测试了两个多尺度神经网络解决语义分割任务的性能（HRNet和PointFlow网络），研究了各种获取方式的影响。",
    "tldr": "引入了一个新的大型航空数据集，包含了自然环境的真实和虚拟录像，使用密集注释的语义分割标签和深度地图，在不同条件下拍摄，用于训练深度学习算法解决森林巡检问题。",
    "en_tdlr": "Introducing a new large aerial dataset with real-world and virtual recordings of natural environments, densely annotated with semantic segmentation labels and depth maps, taken in different illumination conditions, for training deep learning algorithms to solve forest inspection tasks."
}