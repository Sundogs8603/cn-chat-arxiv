{
    "title": "EthioLLM: Multilingual Large Language Models for Ethiopian Languages with Task Evaluation",
    "abstract": "arXiv:2403.13737v1 Announce Type: new  Abstract: Large language models (LLMs) have gained popularity recently due to their outstanding performance in various downstream Natural Language Processing (NLP) tasks. However, low-resource languages are still lagging behind current state-of-the-art (SOTA) developments in the field of NLP due to insufficient resources to train LLMs. Ethiopian languages exhibit remarkable linguistic diversity, encompassing a wide array of scripts, and are imbued with profound religious and cultural significance. This paper introduces EthioLLM -- multilingual large language models for five Ethiopian languages (Amharic, Ge'ez, Afan Oromo, Somali, and Tigrinya) and English, and Ethiobenchmark -- a new benchmark dataset for various downstream NLP tasks. We evaluate the performance of these models across five downstream NLP tasks. We open-source our multilingual language models, new benchmark datasets for various downstream tasks, and task-specific fine-tuned languag",
    "link": "https://arxiv.org/abs/2403.13737",
    "context": "Title: EthioLLM: Multilingual Large Language Models for Ethiopian Languages with Task Evaluation\nAbstract: arXiv:2403.13737v1 Announce Type: new  Abstract: Large language models (LLMs) have gained popularity recently due to their outstanding performance in various downstream Natural Language Processing (NLP) tasks. However, low-resource languages are still lagging behind current state-of-the-art (SOTA) developments in the field of NLP due to insufficient resources to train LLMs. Ethiopian languages exhibit remarkable linguistic diversity, encompassing a wide array of scripts, and are imbued with profound religious and cultural significance. This paper introduces EthioLLM -- multilingual large language models for five Ethiopian languages (Amharic, Ge'ez, Afan Oromo, Somali, and Tigrinya) and English, and Ethiobenchmark -- a new benchmark dataset for various downstream NLP tasks. We evaluate the performance of these models across five downstream NLP tasks. We open-source our multilingual language models, new benchmark datasets for various downstream tasks, and task-specific fine-tuned languag",
    "path": "papers/24/03/2403.13737.json",
    "total_tokens": 974,
    "translated_title": "EthioLLM：用于埃塞俄比亚语言的多语言大型语言模型及任务评估",
    "translated_abstract": "大型语言模型（LLMs）近来因其在各种下游自然语言处理（NLP）任务中的出色表现而备受青睐。然而，由于训练LLMs的资源不足，低资源语言仍落后于NLP领域的最新发展。埃塞俄比亚语言拥有显著的语言多样性，包括广泛的文字系统，并富有深远的宗教和文化意义。本文介绍了EthioLLM - 五种埃塞俄比亚语言（阿姆哈拉语、盖伊兹语、阿方奥罗莫语、索马里语和提格里尼亚语）和英语的多语言大型语言模型，以及Ethiobenchmark - 用于各种下游NLP任务的新基准数据集。我们评估了这些模型在五个下游NLP任务中的性能。我们开源我们的多语言语言模型、各种下游任务的新基准数据集和任务特定的精调语言",
    "tldr": "EthioLLM为埃塞俄比亚五种语言（阿姆哈拉语、盖伊兹语、阿方奥罗莫语、索马里语和提格里尼亚语）以及英语引入了多语言大型语言模型，并提出了一个新的基准数据集Ethiobenchmark，为各种下游自然语言处理任务评估了这些模型的性能。",
    "en_tdlr": "EthioLLM introduces multilingual large language models for five Ethiopian languages (Amharic, Ge'ez, Afan Oromo, Somali, and Tigrinya) and English, along with a new benchmark dataset EthioBenchmark, evaluating the models' performance across various downstream NLP tasks."
}