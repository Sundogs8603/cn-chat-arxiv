{
    "title": "MedCLIP-SAM: Bridging Text and Image Towards Universal Medical Image Segmentation",
    "abstract": "arXiv:2403.20253v1 Announce Type: cross  Abstract: Medical image segmentation of anatomical structures and pathology is crucial in modern clinical diagnosis, disease study, and treatment planning. To date, great progress has been made in deep learning-based segmentation techniques, but most methods still lack data efficiency, generalizability, and interactability. Consequently, the development of new, precise segmentation methods that demand fewer labeled datasets is of utmost importance in medical image analysis. Recently, the emergence of foundation models, such as CLIP and Segment-Anything-Model (SAM), with comprehensive cross-domain representation opened the door for interactive and universal image segmentation. However, exploration of these models for data-efficient medical image segmentation is still limited, but is highly necessary. In this paper, we propose a novel framework, called MedCLIP-SAM that combines CLIP and SAM models to generate segmentation of clinical scans using t",
    "link": "https://arxiv.org/abs/2403.20253",
    "context": "Title: MedCLIP-SAM: Bridging Text and Image Towards Universal Medical Image Segmentation\nAbstract: arXiv:2403.20253v1 Announce Type: cross  Abstract: Medical image segmentation of anatomical structures and pathology is crucial in modern clinical diagnosis, disease study, and treatment planning. To date, great progress has been made in deep learning-based segmentation techniques, but most methods still lack data efficiency, generalizability, and interactability. Consequently, the development of new, precise segmentation methods that demand fewer labeled datasets is of utmost importance in medical image analysis. Recently, the emergence of foundation models, such as CLIP and Segment-Anything-Model (SAM), with comprehensive cross-domain representation opened the door for interactive and universal image segmentation. However, exploration of these models for data-efficient medical image segmentation is still limited, but is highly necessary. In this paper, we propose a novel framework, called MedCLIP-SAM that combines CLIP and SAM models to generate segmentation of clinical scans using t",
    "path": "papers/24/03/2403.20253.json",
    "total_tokens": 643,
    "translated_title": "MedCLIP-SAM：将文本和图像进行桥接，实现通用医学图像分割",
    "translated_abstract": "医学图像中解剖结构和病变的分割在现代临床诊断、疾病研究和治疗规划中至关重要。本文提出了一个新颖的框架，称为MedCLIP-SAM，结合了CLIP和SAM模型，以生成使用少量标记数据的临床扫描的分割。",
    "tldr": "提出了MedCLIP-SAM框架，结合了CLIP和SAM模型，实现使用少量标记数据的临床图像分割",
    "en_tdlr": "Introduced the MedCLIP-SAM framework, which combines CLIP and SAM models to achieve clinical image segmentation with fewer labeled datasets."
}