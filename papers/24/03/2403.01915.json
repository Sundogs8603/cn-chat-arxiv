{
    "title": "xT: Nested Tokenization for Larger Context in Large Images",
    "abstract": "arXiv:2403.01915v1 Announce Type: cross  Abstract: Modern computer vision pipelines handle large images in one of two sub-optimal ways: down-sampling or cropping. These two methods incur significant losses in the amount of information and context present in an image. There are many downstream applications in which global context matters as much as high frequency details, such as in real-world satellite imagery; in such cases researchers have to make the uncomfortable choice of which information to discard. We introduce xT, a simple framework for vision transformers which effectively aggregates global context with local details and can model large images end-to-end on contemporary GPUs. We select a set of benchmark datasets across classic vision tasks which accurately reflect a vision model's ability to understand truly large images and incorporate fine details over large scales and assess our method's improvement on them. By introducing a nested tokenization scheme for large images in ",
    "link": "https://arxiv.org/abs/2403.01915",
    "context": "Title: xT: Nested Tokenization for Larger Context in Large Images\nAbstract: arXiv:2403.01915v1 Announce Type: cross  Abstract: Modern computer vision pipelines handle large images in one of two sub-optimal ways: down-sampling or cropping. These two methods incur significant losses in the amount of information and context present in an image. There are many downstream applications in which global context matters as much as high frequency details, such as in real-world satellite imagery; in such cases researchers have to make the uncomfortable choice of which information to discard. We introduce xT, a simple framework for vision transformers which effectively aggregates global context with local details and can model large images end-to-end on contemporary GPUs. We select a set of benchmark datasets across classic vision tasks which accurately reflect a vision model's ability to understand truly large images and incorporate fine details over large scales and assess our method's improvement on them. By introducing a nested tokenization scheme for large images in ",
    "path": "papers/24/03/2403.01915.json",
    "total_tokens": 860,
    "translated_title": "xT：用于大图像中更大上下文的嵌套标记化",
    "translated_abstract": "现代计算机视觉流水线以两种次优方式处理大图像：下采样或裁剪。这两种方法导致图像中信息和背景的丢失。在许多下游应用中，全局背景的重要性与高频细节一样，例如在现实世界的卫星图像中；在这种情况下，研究人员必须做出舍弃哪些信息的困扰选择。我们介绍了xT，这是一个简单的视觉Transformer框架，可以有效地聚合全局背景和局部细节，并可以在当代GPU上端对端地对大图像进行建模。我们选择了一组跨经典视觉任务的基准数据集，这些任务准确地反映了视觉模型理解真正大型图像并在大范围内融合细节的能力，并评估了我们的方法在其上的改进。通过引入针对大图像的嵌套标记化方案",
    "tldr": "xT为视觉Transformer引入了嵌套标记化方案，有效地聚合了全局背景和局部细节，使其能够在现代GPU上端到端地建模大图像，并在经典视觉任务数据集上展示了改进。",
    "en_tdlr": "xT introduces a nested tokenization scheme for vision transformers, effectively aggregating global context with local details to model large images end-to-end on contemporary GPUs, and demonstrates improvements on benchmark datasets across classic vision tasks."
}