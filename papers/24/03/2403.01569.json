{
    "title": "Kick Back & Relax++: Scaling Beyond Ground-Truth Depth with SlowTV & CribsTV",
    "abstract": "arXiv:2403.01569v1 Announce Type: cross  Abstract: Self-supervised learning is the key to unlocking generic computer vision systems. By eliminating the reliance on ground-truth annotations, it allows scaling to much larger data quantities. Unfortunately, self-supervised monocular depth estimation (SS-MDE) has been limited by the absence of diverse training data. Existing datasets have focused exclusively on urban driving in densely populated cities, resulting in models that fail to generalize beyond this domain.   To address these limitations, this paper proposes two novel datasets: SlowTV and CribsTV. These are large-scale datasets curated from publicly available YouTube videos, containing a total of 2M training frames. They offer an incredibly diverse set of environments, ranging from snowy forests to coastal roads, luxury mansions and even underwater coral reefs. We leverage these datasets to tackle the challenging task of zero-shot generalization, outperforming every existing SS-MD",
    "link": "https://arxiv.org/abs/2403.01569",
    "context": "Title: Kick Back & Relax++: Scaling Beyond Ground-Truth Depth with SlowTV & CribsTV\nAbstract: arXiv:2403.01569v1 Announce Type: cross  Abstract: Self-supervised learning is the key to unlocking generic computer vision systems. By eliminating the reliance on ground-truth annotations, it allows scaling to much larger data quantities. Unfortunately, self-supervised monocular depth estimation (SS-MDE) has been limited by the absence of diverse training data. Existing datasets have focused exclusively on urban driving in densely populated cities, resulting in models that fail to generalize beyond this domain.   To address these limitations, this paper proposes two novel datasets: SlowTV and CribsTV. These are large-scale datasets curated from publicly available YouTube videos, containing a total of 2M training frames. They offer an incredibly diverse set of environments, ranging from snowy forests to coastal roads, luxury mansions and even underwater coral reefs. We leverage these datasets to tackle the challenging task of zero-shot generalization, outperforming every existing SS-MD",
    "path": "papers/24/03/2403.01569.json",
    "total_tokens": 891,
    "translated_title": "放松并放松++：通过SlowTV和CribsTV超越地面真实深度的扩展",
    "translated_abstract": "自监督学习是解锁通用计算机视觉系统的关键。通过消除对地面真实注释的依赖，它允许扩展到更大数量的数据。然而，自监督单目深度估计（SS-MDE）受到多样化训练数据缺乏的限制。现有数据集仅关注于密集人口城市中的城市驾驶，导致模型无法推广到此领域之外。为了解决这些限制，本文提出了两个新颖的数据集：SlowTV和CribsTV。这些是从公开的YouTube视频中精心策划的大规模数据集，包含总共2M训练帧。它们提供了一个非常多样化的环境集，从多雪的森林到沿海道路，豪华豪宅，甚至水下珊瑚礁。我们利用这些数据集来解决零-shot泛化的挑战性任务，胜过每个现有的SS-MD",
    "tldr": "本文提出了两个新颖的数据集SlowTV和CribsTV，通过这些数据集，成功解决了自监督单目深度估计（SS-MDE）存在的多样化训练数据不足问题，实现了零-shot泛化的任务。",
    "en_tdlr": "This paper introduces two novel datasets, SlowTV and CribsTV, which address the lack of diverse training data in self-supervised monocular depth estimation (SS-MDE) and achieve zero-shot generalization task."
}