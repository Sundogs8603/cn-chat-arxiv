{
    "title": "Domain-Agnostic Mutual Prompting for Unsupervised Domain Adaptation",
    "abstract": "arXiv:2403.02899v1 Announce Type: new  Abstract: Conventional Unsupervised Domain Adaptation (UDA) strives to minimize distribution discrepancy between domains, which neglects to harness rich semantics from data and struggles to handle complex domain shifts. A promising technique is to leverage the knowledge of large-scale pre-trained vision-language models for more guided adaptation. Despite some endeavors, current methods often learn textual prompts to embed domain semantics for source and target domains separately and perform classification within each domain, limiting cross-domain knowledge transfer. Moreover, prompting only the language branch lacks flexibility to adapt both modalities dynamically. To bridge this gap, we propose Domain-Agnostic Mutual Prompting (DAMP) to exploit domain-invariant semantics by mutually aligning visual and textual embeddings. Specifically, the image contextual information is utilized to prompt the language branch in a domain-agnostic and instance-con",
    "link": "https://arxiv.org/abs/2403.02899",
    "context": "Title: Domain-Agnostic Mutual Prompting for Unsupervised Domain Adaptation\nAbstract: arXiv:2403.02899v1 Announce Type: new  Abstract: Conventional Unsupervised Domain Adaptation (UDA) strives to minimize distribution discrepancy between domains, which neglects to harness rich semantics from data and struggles to handle complex domain shifts. A promising technique is to leverage the knowledge of large-scale pre-trained vision-language models for more guided adaptation. Despite some endeavors, current methods often learn textual prompts to embed domain semantics for source and target domains separately and perform classification within each domain, limiting cross-domain knowledge transfer. Moreover, prompting only the language branch lacks flexibility to adapt both modalities dynamically. To bridge this gap, we propose Domain-Agnostic Mutual Prompting (DAMP) to exploit domain-invariant semantics by mutually aligning visual and textual embeddings. Specifically, the image contextual information is utilized to prompt the language branch in a domain-agnostic and instance-con",
    "path": "papers/24/03/2403.02899.json",
    "total_tokens": 851,
    "translated_title": "针对无监督领域自适应的领域无关互相提示",
    "translated_abstract": "传统的无监督领域自适应（UDA）致力于最小化不同领域之间的分布差异，忽略了从数据中获取丰富语义并且难以处理复杂的领域转变。一种有前途的技术是利用大规模预训练的视觉-语言模型的知识来进行更有指导性的自适应。尽管一些尝试，但目前的方法通常学习文本提示将领域语义嵌入源领域和目标领域分别进行分类，限制了跨领域知识传递。此外，仅提示语言分支缺乏动态适应两种模态的灵活性。为了弥合这一差距，我们提出了一种领域无关互相提示（DAMP）方法，通过互相对齐视觉和文本嵌入来利用领域不变语义。",
    "tldr": "提出了领域无关互相提示（DAMP）方法，通过互相对齐视觉和文本嵌入来利用领域不变语义，弥合了传统无监督领域自适应方法的局限性。",
    "en_tdlr": "Introduced Domain-Agnostic Mutual Prompting (DAMP) method, which utilizes domain-invariant semantics by mutually aligning visual and textual embeddings, bridging the limitations of conventional unsupervised domain adaptation methods."
}