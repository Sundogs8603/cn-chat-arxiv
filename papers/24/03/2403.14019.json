{
    "title": "Searching Search Spaces: Meta-evolving a Geometric Encoding for Neural Networks",
    "abstract": "arXiv:2403.14019v1 Announce Type: cross  Abstract: In evolutionary policy search, neural networks are usually represented using a direct mapping: each gene encodes one network weight. Indirect encoding methods, where each gene can encode for multiple weights, shorten the genome to reduce the dimensions of the search space and better exploit permutations and symmetries. The Geometric Encoding for Neural network Evolution (GENE) introduced an indirect encoding where the weight of a connection is computed as the (pseudo-)distance between the two linked neurons, leading to a genome size growing linearly with the number of genes instead of quadratically in direct encoding. However GENE still relies on hand-crafted distance functions with no prior optimization. Here we show that better performing distance functions can be found for GENE using Cartesian Genetic Programming (CGP) in a meta-evolution approach, hence optimizing the encoding to create a search space that is easier to exploit. We ",
    "link": "https://arxiv.org/abs/2403.14019",
    "context": "Title: Searching Search Spaces: Meta-evolving a Geometric Encoding for Neural Networks\nAbstract: arXiv:2403.14019v1 Announce Type: cross  Abstract: In evolutionary policy search, neural networks are usually represented using a direct mapping: each gene encodes one network weight. Indirect encoding methods, where each gene can encode for multiple weights, shorten the genome to reduce the dimensions of the search space and better exploit permutations and symmetries. The Geometric Encoding for Neural network Evolution (GENE) introduced an indirect encoding where the weight of a connection is computed as the (pseudo-)distance between the two linked neurons, leading to a genome size growing linearly with the number of genes instead of quadratically in direct encoding. However GENE still relies on hand-crafted distance functions with no prior optimization. Here we show that better performing distance functions can be found for GENE using Cartesian Genetic Programming (CGP) in a meta-evolution approach, hence optimizing the encoding to create a search space that is easier to exploit. We ",
    "path": "papers/24/03/2403.14019.json",
    "total_tokens": 846,
    "translated_title": "搜索搜索空间：元演变神经网络的几何编码",
    "translated_abstract": "在进化策略搜索中，神经网络通常使用直接映射来表示：每个基因编码一个网络权重。间接编码方法，其中每个基因可以编码多个权重，将基因组缩短以减少搜索空间的维数，并更好地利用排列和对称性。神经网络Evolution的几何编码（GENE）引入了一种间接编码方法，其中连接的权重被计算为两个连接神经元之间的（伪）距离，使基因组大小随着基因数量线性增长，而不是在直接编码中呈二次增长。然而，GENE仍然依赖于手工设计的距离函数，并没有进行优化。在这里，我们展示了可以使用笛卡尔遗传规划（CGP）找到更好的性能距离函数，从而在元演化方法中优化GENE的编码，从而创建一个更容易利用的搜索空间。",
    "tldr": "通过使用笛卡尔遗传规划（CGP）的元演化方法，优化了神经网络Evolution的几何编码（GENE）, 找到更有效的距离函数，创建一个更易于利用的搜索空间。",
    "en_tdlr": "Through meta-evolution approach using Cartesian Genetic Programming (CGP), the geometric encoding for Neural network Evolution (GENE) was optimized with better distance functions, resulting in a more exploitable search space."
}