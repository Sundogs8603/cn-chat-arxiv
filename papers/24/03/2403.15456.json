{
    "title": "WoLF: Large Language Model Framework for CXR Understanding",
    "abstract": "arXiv:2403.15456v1 Announce Type: new  Abstract: Significant methodological strides have been made toward Chest X-ray (CXR) understanding via modern vision-language models (VLMs), demonstrating impressive Visual Question Answering (VQA) and CXR report generation abilities. However, existing CXR understanding frameworks still possess several procedural caveats. (1) Previous methods solely use CXR reports, which are insufficient for comprehensive Visual Question Answering (VQA), especially when additional health-related data like medication history and prior diagnoses are needed. (2) Previous methods use raw CXR reports, which are often arbitrarily structured. While modern language models can understand various text formats, restructuring reports for clearer, organized anatomy-based information could enhance their usefulness. (3) Current evaluation methods for CXR-VQA primarily emphasize linguistic correctness, lacking the capability to offer nuanced assessments of the generated answers.",
    "link": "https://arxiv.org/abs/2403.15456",
    "context": "Title: WoLF: Large Language Model Framework for CXR Understanding\nAbstract: arXiv:2403.15456v1 Announce Type: new  Abstract: Significant methodological strides have been made toward Chest X-ray (CXR) understanding via modern vision-language models (VLMs), demonstrating impressive Visual Question Answering (VQA) and CXR report generation abilities. However, existing CXR understanding frameworks still possess several procedural caveats. (1) Previous methods solely use CXR reports, which are insufficient for comprehensive Visual Question Answering (VQA), especially when additional health-related data like medication history and prior diagnoses are needed. (2) Previous methods use raw CXR reports, which are often arbitrarily structured. While modern language models can understand various text formats, restructuring reports for clearer, organized anatomy-based information could enhance their usefulness. (3) Current evaluation methods for CXR-VQA primarily emphasize linguistic correctness, lacking the capability to offer nuanced assessments of the generated answers.",
    "path": "papers/24/03/2403.15456.json",
    "total_tokens": 860,
    "translated_title": "WoLF: 用于胸部X线图理解的大型语言模型框架",
    "translated_abstract": "通过现代视觉语言模型(VLMs)取得了对胸部X线图(CXR)理解方面的显着方法进展，展示了令人印象深刻的视觉问答(VQA)和CXR报告生成能力。然而，现有的CXR理解框架仍存在几个程序上的缺陷。(1)以往的方法仅使用CXR报告，这对于全面的视觉问答(VQA)来说是不够的，特别是当需要额外的健康相关数据如用药历史和先前的诊断时。(2)以往的方法使用未经处理的CXR报告，这些报告往往结构随意。虽然现代语言模型可以理解各种文本格式，但为了提供更清晰、有组织的基于解剖学的信息，重构报告可能会增强它们的实用性。(3)目前用于CXR-VQA的评估方法主要强调语言正确性，缺乏对生成答案的微妙评估能力。",
    "tldr": "WoLF框架提出了对于CXR的全面理解的改进，包括使用额外的健康相关数据、重构报告以提供更有组织的信息、以及改进生成答案的细致评估。",
    "en_tdlr": "WoLF framework proposes enhancements for comprehensive understanding of CXR, including utilizing additional health-related data, restructuring reports for more organized information, and improving nuanced evaluation of generated answers."
}