{
    "title": "Collaborative AI Teaming in Unknown Environments via Active Goal Deduction",
    "abstract": "arXiv:2403.15341v1 Announce Type: new  Abstract: With the advancements of artificial intelligence (AI), we're seeing more scenarios that require AI to work closely with other agents, whose goals and strategies might not be known beforehand. However, existing approaches for training collaborative agents often require defined and known reward signals and cannot address the problem of teaming with unknown agents that often have latent objectives/rewards. In response to this challenge, we propose teaming with unknown agents framework, which leverages kernel density Bayesian inverse learning method for active goal deduction and utilizes pre-trained, goal-conditioned policies to enable zero-shot policy adaptation. We prove that unbiased reward estimates in our framework are sufficient for optimal teaming with unknown agents. We further evaluate the framework of redesigned multi-agent particle and StarCraft II micromanagement environments with diverse unknown agents of different behaviors/rew",
    "link": "https://arxiv.org/abs/2403.15341",
    "context": "Title: Collaborative AI Teaming in Unknown Environments via Active Goal Deduction\nAbstract: arXiv:2403.15341v1 Announce Type: new  Abstract: With the advancements of artificial intelligence (AI), we're seeing more scenarios that require AI to work closely with other agents, whose goals and strategies might not be known beforehand. However, existing approaches for training collaborative agents often require defined and known reward signals and cannot address the problem of teaming with unknown agents that often have latent objectives/rewards. In response to this challenge, we propose teaming with unknown agents framework, which leverages kernel density Bayesian inverse learning method for active goal deduction and utilizes pre-trained, goal-conditioned policies to enable zero-shot policy adaptation. We prove that unbiased reward estimates in our framework are sufficient for optimal teaming with unknown agents. We further evaluate the framework of redesigned multi-agent particle and StarCraft II micromanagement environments with diverse unknown agents of different behaviors/rew",
    "path": "papers/24/03/2403.15341.json",
    "total_tokens": 872,
    "translated_title": "通过积极目标演绎在未知环境中进行协作人工智能团队",
    "translated_abstract": "随着人工智能（AI）的进步，我们看到越来越多需要AI与其他代理人密切合作的情境，这些代理人的目标和策略可能事先未知。然而，现有的训练协作代理的方法通常需要预先定义和已知的奖励信号，并且无法解决与经常具有潜在目标/奖励的未知代理人进行团队合作的问题。为了应对这一挑战，我们提出了与未知代理人合作的框架，该框架利用核密度贝叶斯逆学习方法进行积极目标推断，并利用预训练的、以目标为条件的策略实现零射击策略适应。我们证明了在我们的框架中无偏奖励估计对于与未知代理人进行最佳团队合作是足够的。我们进一步评估了在重新设计的多智能体粒子和星际争霸II微管理环境中与不同行为/奖励的多样未知代理人进行团队合作的框架",
    "tldr": "通过积极目标推断，利用预训练的策略，实现零射击策略适应，对未知代理人进行最佳团队合作。"
}