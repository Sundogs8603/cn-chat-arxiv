{
    "title": "Hypothesis-Driven Deep Learning for Out of Distribution Detection",
    "abstract": "arXiv:2403.14058v1 Announce Type: new  Abstract: Predictions of opaque black-box systems are frequently deployed in high-stakes applications such as healthcare. For such applications, it is crucial to assess how models handle samples beyond the domain of training data. While several metrics and tests exist to detect out-of-distribution (OoD) data from in-distribution (InD) data to a deep neural network (DNN), their performance varies significantly across datasets, models, and tasks, which limits their practical use. In this paper, we propose a hypothesis-driven approach to quantify whether a new sample is InD or OoD. Given a trained DNN and some input, we first feed the input through the DNN and compute an ensemble of OoD metrics, which we term latent responses. We then formulate the OoD detection problem as a hypothesis test between latent responses of different groups, and use permutation-based resampling to infer the significance of the observed latent responses under a null hypothe",
    "link": "https://arxiv.org/abs/2403.14058",
    "context": "Title: Hypothesis-Driven Deep Learning for Out of Distribution Detection\nAbstract: arXiv:2403.14058v1 Announce Type: new  Abstract: Predictions of opaque black-box systems are frequently deployed in high-stakes applications such as healthcare. For such applications, it is crucial to assess how models handle samples beyond the domain of training data. While several metrics and tests exist to detect out-of-distribution (OoD) data from in-distribution (InD) data to a deep neural network (DNN), their performance varies significantly across datasets, models, and tasks, which limits their practical use. In this paper, we propose a hypothesis-driven approach to quantify whether a new sample is InD or OoD. Given a trained DNN and some input, we first feed the input through the DNN and compute an ensemble of OoD metrics, which we term latent responses. We then formulate the OoD detection problem as a hypothesis test between latent responses of different groups, and use permutation-based resampling to infer the significance of the observed latent responses under a null hypothe",
    "path": "papers/24/03/2403.14058.json",
    "total_tokens": 897,
    "translated_title": "基于假设的深度学习用于外域检测",
    "translated_abstract": "不透明黑盒系统的预测经常用于诸如医疗保健等高风险应用中。对于这类应用，评估模型处理超出训练数据域的样本的方式至关重要。虽然存在几种度量和测试来检测深度神经网络（DNN）中的超出分布（OoD）数据和分布内（InD）数据，但它们的性能在数据集、模型和任务之间存在显著差异，这限制了它们的实际应用。在本文中，我们提出了一种基于假设的方法来量化新样本是InD还是OoD。给定一个训练过的DNN和一些输入，我们首先通过DNN馈送输入并计算一组OoD度量，称为潜在响应。然后，我们将OoD检测问题表述为潜在响应之间的假设检验，并使用基于排列的重新采样来推断在零假设下观察到的潜在响应的显著性。",
    "tldr": "本论文提出了一种基于假设的深度学习方法，用于量化新样本是否属于内部分布或外部分布，在高风险应用中如医疗保健领域具有重要意义。",
    "en_tdlr": "This paper introduces a hypothesis-driven deep learning approach to quantify whether a new sample belongs to in-distribution or out-of-distribution, which is crucial for high-stakes applications such as healthcare."
}