{
    "title": "LAMP: A Language Model on the Map",
    "abstract": "arXiv:2403.09059v1 Announce Type: new  Abstract: Large Language Models (LLMs) are poised to play an increasingly important role in our lives, providing assistance across a wide array of tasks. In the geospatial domain, LLMs have demonstrated the ability to answer generic questions, such as identifying a country's capital; nonetheless, their utility is hindered when it comes to answering fine-grained questions about specific places, such as grocery stores or restaurants, which constitute essential aspects of people's everyday lives. This is mainly because the places in our cities haven't been systematically fed into LLMs, so as to understand and memorize them. This study introduces a novel framework for fine-tuning a pre-trained model on city-specific data, to enable it to provide accurate recommendations, while minimizing hallucinations. We share our model, LAMP, and the data used to train it. We conduct experiments to analyze its ability to correctly retrieving spatial objects, and co",
    "link": "https://arxiv.org/abs/2403.09059",
    "context": "Title: LAMP: A Language Model on the Map\nAbstract: arXiv:2403.09059v1 Announce Type: new  Abstract: Large Language Models (LLMs) are poised to play an increasingly important role in our lives, providing assistance across a wide array of tasks. In the geospatial domain, LLMs have demonstrated the ability to answer generic questions, such as identifying a country's capital; nonetheless, their utility is hindered when it comes to answering fine-grained questions about specific places, such as grocery stores or restaurants, which constitute essential aspects of people's everyday lives. This is mainly because the places in our cities haven't been systematically fed into LLMs, so as to understand and memorize them. This study introduces a novel framework for fine-tuning a pre-trained model on city-specific data, to enable it to provide accurate recommendations, while minimizing hallucinations. We share our model, LAMP, and the data used to train it. We conduct experiments to analyze its ability to correctly retrieving spatial objects, and co",
    "path": "papers/24/03/2403.09059.json",
    "total_tokens": 857,
    "translated_title": "LAMP：地图上的语言模型",
    "translated_abstract": "大型语言模型（LLMs）在我们的生活中扮演着越来越重要的角色，为我们在各种任务中提供帮助。在地理空间领域，LLMs已经展示出能够回答一般性问题的能力，比如识别一个国家的首都；然而，当涉及回答关于特定地点的细粒度问题时，比如杂货店或餐馆，这些构成了人们日常生活中重要的方面时，它们的效用受到阻碍。这主要是因为我们城市中的地点尚未被系统地输入到LLMs中，以便于理解和记忆它们。该研究引入了一个新颖的框架，用于在城市特定数据上微调预训练模型，从而使其能够提供准确的建议，同时最小化幻觉。我们分享我们的模型LAMP和用于训练它的数据。我们进行实验分析其正确检索空间对象的能力。",
    "tldr": "该研究引入了一个新颖的框架，用于在城市特定数据上微调预训练模型，使其能够为人们提供准确的推荐，同时最小化幻觉。",
    "en_tdlr": "The study introduces a novel framework for fine-tuning a pre-trained model on city-specific data, enabling it to provide accurate recommendations for people while minimizing hallucinations."
}