{
    "title": "Towards Multimodal Video Paragraph Captioning Models Robust to Missing Modality",
    "abstract": "arXiv:2403.19221v1 Announce Type: cross  Abstract: Video paragraph captioning (VPC) involves generating detailed narratives for long videos, utilizing supportive modalities such as speech and event boundaries. However, the existing models are constrained by the assumption of constant availability of a single auxiliary modality, which is impractical given the diversity and unpredictable nature of real-world scenarios. To this end, we propose a Missing-Resistant framework MR-VPC that effectively harnesses all available auxiliary inputs and maintains resilience even in the absence of certain modalities. Under this framework, we propose the Multimodal VPC (MVPC) architecture integrating video, speech, and event boundary inputs in a unified manner to process various auxiliary inputs. Moreover, to fortify the model against incomplete data, we introduce DropAM, a data augmentation strategy that randomly omits auxiliary inputs, paired with DistillAM, a regularization target that distills knowl",
    "link": "https://arxiv.org/abs/2403.19221",
    "context": "Title: Towards Multimodal Video Paragraph Captioning Models Robust to Missing Modality\nAbstract: arXiv:2403.19221v1 Announce Type: cross  Abstract: Video paragraph captioning (VPC) involves generating detailed narratives for long videos, utilizing supportive modalities such as speech and event boundaries. However, the existing models are constrained by the assumption of constant availability of a single auxiliary modality, which is impractical given the diversity and unpredictable nature of real-world scenarios. To this end, we propose a Missing-Resistant framework MR-VPC that effectively harnesses all available auxiliary inputs and maintains resilience even in the absence of certain modalities. Under this framework, we propose the Multimodal VPC (MVPC) architecture integrating video, speech, and event boundary inputs in a unified manner to process various auxiliary inputs. Moreover, to fortify the model against incomplete data, we introduce DropAM, a data augmentation strategy that randomly omits auxiliary inputs, paired with DistillAM, a regularization target that distills knowl",
    "path": "papers/24/03/2403.19221.json",
    "total_tokens": 944,
    "translated_title": "朝着对缺失模态具有鲁棒性的多模态视频段落字幕生成模型",
    "translated_abstract": "视频段落字幕生成（VPC）涉及为长视频生成详细的叙述，利用支持性模态，如语音和事件边界。然而，现有模型受制于一个假设，即单一辅助模态的恒定可用性，这在真实场景的多样性和不可预测性下是不切实际的。为此，我们提出了一个具有 Missing-Resistant 框架 MR-VPC，该框架有效地利用所有可用的辅助输入，并且即使某些模态缺失也能保持韧性。在该框架下，我们提出了融合视频、语音和事件边界输入的多模态 VPC（MVPC）架构，以统一方式处理各种辅助输入。此外，为了加强模型对不完整数据的鲁棒性，我们引入了 DropAM，一种随机省略辅助输入的数据增强策略，结合 DistillAM，一种用于提炼知识的正则化目标。",
    "tldr": "提出了一种具有 Missing-Resistant 框架的多模态视频段落字幕生成模型，能够有效整合各种可用的辅助输入，在缺失某些模态的情况下仍能保持韧性，并引入了随机省略辅助输入的数据增强策略以及用于提炼知识的正则化目标。",
    "en_tdlr": "Proposed a multimodal video paragraph captioning model with a Missing-Resistant framework that effectively integrates various available auxiliary inputs, maintaining resilience even in the absence of certain modalities, and introduced a data augmentation strategy of randomly omitting auxiliary inputs paired with a regularization target for knowledge distillation."
}