{
    "title": "Chain-of-Action: Faithful and Multimodal Question Answering through Large Language Models",
    "abstract": "arXiv:2403.17359v1 Announce Type: new  Abstract: We present a Chain-of-Action (CoA) framework for multimodal and retrieval-augmented Question-Answering (QA). Compared to the literature, CoA overcomes two major challenges of current QA applications: (i) unfaithful hallucination that is inconsistent with real-time or domain facts and (ii) weak reasoning performance over compositional information. Our key contribution is a novel reasoning-retrieval mechanism that decomposes a complex question into a reasoning chain via systematic prompting and pre-designed actions. Methodologically, we propose three types of domain-adaptable `Plug-and-Play' actions for retrieving real-time information from heterogeneous sources. We also propose a multi-reference faith score (MRFS) to verify and resolve conflicts in the answers. Empirically, we exploit both public benchmarks and a Web3 case study to demonstrate the capability of CoA over other methods.",
    "link": "https://arxiv.org/abs/2403.17359",
    "context": "Title: Chain-of-Action: Faithful and Multimodal Question Answering through Large Language Models\nAbstract: arXiv:2403.17359v1 Announce Type: new  Abstract: We present a Chain-of-Action (CoA) framework for multimodal and retrieval-augmented Question-Answering (QA). Compared to the literature, CoA overcomes two major challenges of current QA applications: (i) unfaithful hallucination that is inconsistent with real-time or domain facts and (ii) weak reasoning performance over compositional information. Our key contribution is a novel reasoning-retrieval mechanism that decomposes a complex question into a reasoning chain via systematic prompting and pre-designed actions. Methodologically, we propose three types of domain-adaptable `Plug-and-Play' actions for retrieving real-time information from heterogeneous sources. We also propose a multi-reference faith score (MRFS) to verify and resolve conflicts in the answers. Empirically, we exploit both public benchmarks and a Web3 case study to demonstrate the capability of CoA over other methods.",
    "path": "papers/24/03/2403.17359.json",
    "total_tokens": 849,
    "translated_title": "Chain-of-Action：通过大型语言模型实现忠实和多模态问答",
    "translated_abstract": "我们提出了一个称为Chain-of-Action (CoA)的框架，用于多模态和检索增强问答(QA)。与现有文献相比，CoA克服了当前QA应用的两个主要挑战：(i) 与实时或领域事实不一致的不忠实幻觉，以及(ii) 对组合信息的弱推理性能。我们的主要贡献是一种新颖的推理-检索机制，通过系统提示和预设计的动作将复杂问题分解为推理链。在方法上，我们提出了三种领域适应性的“即插即用”操作，用于从异构源检索实时信息。我们还提出了一个多参考忠实分数（MRFS）来验证和解决答案中的冲突。在经验上，我们利用公共基准和一个Web3案例研究来展示CoA相比其他方法的能力。",
    "tldr": "提出了Chain-of-Action (CoA)框架，通过新颖的推理-检索机制和多参考忠实分数解决了当前QA应用中的不忠实幻觉和弱推理性能问题",
    "en_tdlr": "Proposed the Chain-of-Action (CoA) framework to address the issues of unfaithful hallucination and weak reasoning performance in current QA applications through a novel reasoning-retrieval mechanism and multi-reference faith score."
}