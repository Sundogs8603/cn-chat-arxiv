{
    "title": "Self-Refinement of Language Models from External Proxy Metrics Feedback",
    "abstract": "arXiv:2403.00827v1 Announce Type: cross  Abstract: It is often desirable for Large Language Models (LLMs) to capture multiple objectives when providing a response. In document-grounded response generation, for example, agent responses are expected to be relevant to a user's query while also being grounded in a given document. In this paper, we introduce Proxy Metric-based Self-Refinement (ProMiSe), which enables an LLM to refine its own initial response along key dimensions of quality guided by external metrics feedback, yielding an overall better final response. ProMiSe leverages feedback on response quality through principle-specific proxy metrics, and iteratively refines its response one principle at a time. We apply ProMiSe to open source language models Flan-T5-XXL and Llama-2-13B-Chat, to evaluate its performance on document-grounded question answering datasets, MultiDoc2Dial and QuAC, demonstrating that self-refinement improves response quality. We further show that fine-tuning ",
    "link": "https://arxiv.org/abs/2403.00827",
    "context": "Title: Self-Refinement of Language Models from External Proxy Metrics Feedback\nAbstract: arXiv:2403.00827v1 Announce Type: cross  Abstract: It is often desirable for Large Language Models (LLMs) to capture multiple objectives when providing a response. In document-grounded response generation, for example, agent responses are expected to be relevant to a user's query while also being grounded in a given document. In this paper, we introduce Proxy Metric-based Self-Refinement (ProMiSe), which enables an LLM to refine its own initial response along key dimensions of quality guided by external metrics feedback, yielding an overall better final response. ProMiSe leverages feedback on response quality through principle-specific proxy metrics, and iteratively refines its response one principle at a time. We apply ProMiSe to open source language models Flan-T5-XXL and Llama-2-13B-Chat, to evaluate its performance on document-grounded question answering datasets, MultiDoc2Dial and QuAC, demonstrating that self-refinement improves response quality. We further show that fine-tuning ",
    "path": "papers/24/03/2403.00827.json",
    "total_tokens": 704,
    "translated_title": "来自外部代理指标反馈的语言模型自我完善",
    "translated_abstract": "在文档为基础的响应生成中，期望代理响应不仅与用户的查询相关，还与给定的文档相关。本文引入了基于代理指标的自我完善（ProMiSe），使得大型语言模型能够沿着外部指标反馈引导的质量关键维度优化其初始响应，从而产生更好的最终响应。",
    "tldr": "本文提出了Proxy Metric-based Self-Refinement (ProMiSe)方法，通过外部指标反馈指导语言模型在质量关键维度上进行自我完善，从而改进响应质量。",
    "en_tdlr": "This paper introduces Proxy Metric-based Self-Refinement (ProMiSe) method, enabling a language model to refine its initial response along key dimensions of quality guided by external metrics feedback, resulting in improved response quality."
}