{
    "title": "How much data do you need? Part 2: Predicting DL class specific training dataset sizes",
    "abstract": "arXiv:2403.06311v1 Announce Type: new  Abstract: This paper targets the question of predicting machine learning classification model performance, when taking into account the number of training examples per class and not just the overall number of training examples. This leads to the a combinatorial question, which combinations of number of training examples per class should be considered, given a fixed overall training dataset size. In order to solve this question, an algorithm is suggested which is motivated from special cases of space filling design of experiments. The resulting data are modeled using models like powerlaw curves and similar models, extended like generalized linear models i.e. by replacing the overall training dataset size by a parametrized linear combination of the number of training examples per label class. The proposed algorithm has been applied on the CIFAR10 and the EMNIST datasets.",
    "link": "https://arxiv.org/abs/2403.06311",
    "context": "Title: How much data do you need? Part 2: Predicting DL class specific training dataset sizes\nAbstract: arXiv:2403.06311v1 Announce Type: new  Abstract: This paper targets the question of predicting machine learning classification model performance, when taking into account the number of training examples per class and not just the overall number of training examples. This leads to the a combinatorial question, which combinations of number of training examples per class should be considered, given a fixed overall training dataset size. In order to solve this question, an algorithm is suggested which is motivated from special cases of space filling design of experiments. The resulting data are modeled using models like powerlaw curves and similar models, extended like generalized linear models i.e. by replacing the overall training dataset size by a parametrized linear combination of the number of training examples per label class. The proposed algorithm has been applied on the CIFAR10 and the EMNIST datasets.",
    "path": "papers/24/03/2403.06311.json",
    "total_tokens": 834,
    "translated_title": "你需要多少数据？第二部分：预测深度学习类特定训练数据集大小",
    "translated_abstract": "本文旨在研究在考虑每个类别的训练样本数量而不仅仅是总体训练样本数量时，预测机器学习分类模型性能的问题。这带来了一个组合问题，即在给定固定总体训练数据集大小的情况下，应考虑哪些每个类的训练样本数量组合。为了解决这个问题，提出了一种算法，该算法受到实验设计中的空间填满设计的特殊情况的启发。生成的数据使用诸如幂律曲线和类似模型、扩展的广义线性模型等模型来进行建模，即通过将总体训练数据集大小替换为给定标签类别的训练样本数量的参数化线性组合。该算法已应用于CIFAR10和EMNIST数据集。",
    "tldr": "通过考虑每个类别的训练样本数量，而不仅仅是总体训练样本数量，来预测机器学习分类模型性能，并提出了一种基于空间填充设计的算法，可以对 CIFAR10 和 EMNIST 数据集进行应用。"
}