{
    "title": "Optimistic Verifiable Training by Controlling Hardware Nondeterminism",
    "abstract": "arXiv:2403.09603v1 Announce Type: cross  Abstract: The increasing compute demands of AI systems has led to the emergence of services that train models on behalf of clients lacking necessary resources. However, ensuring correctness of training and guarding against potential training-time attacks, such as data poisoning, poses challenges. Existing works on verifiable training largely fall into two classes: proof-based systems, which struggle to scale due to requiring cryptographic techniques, and \"optimistic\" methods that consider a trusted third-party auditor who replicates the training process. A key challenge with the latter is that hardware nondeterminism between GPU types during training prevents an auditor from replicating the training process exactly, and such schemes are therefore non-robust. We propose a method that combines training in a higher precision than the target model, rounding after intermediate computation steps, and storing rounding decisions based on an adaptive thr",
    "link": "https://arxiv.org/abs/2403.09603",
    "context": "Title: Optimistic Verifiable Training by Controlling Hardware Nondeterminism\nAbstract: arXiv:2403.09603v1 Announce Type: cross  Abstract: The increasing compute demands of AI systems has led to the emergence of services that train models on behalf of clients lacking necessary resources. However, ensuring correctness of training and guarding against potential training-time attacks, such as data poisoning, poses challenges. Existing works on verifiable training largely fall into two classes: proof-based systems, which struggle to scale due to requiring cryptographic techniques, and \"optimistic\" methods that consider a trusted third-party auditor who replicates the training process. A key challenge with the latter is that hardware nondeterminism between GPU types during training prevents an auditor from replicating the training process exactly, and such schemes are therefore non-robust. We propose a method that combines training in a higher precision than the target model, rounding after intermediate computation steps, and storing rounding decisions based on an adaptive thr",
    "path": "papers/24/03/2403.09603.json",
    "total_tokens": 869,
    "translated_title": "控制硬件非确定性进行乐观可验证训练",
    "translated_abstract": "AI系统日益增加的计算需求导致了为缺乏必要资源的客户进行模型训练的服务的出现。然而，确保训练的正确性并防范潜在的训练时攻击，例如数据毒化，都带来了挑战。现有的关于可验证训练的工作主要分为两类：基于证明的系统，由于需要加密技术而难以扩展，以及考虑到一个可信第三方审计员复制训练过程的“乐观”方法。 后者的一个关键挑战是，在训练期间GPU类型之间的硬件非确定性阻止审计员精确复制训练过程，因此这样的方案不够健壮。我们提出了一种方法，将训练在比目标模型更高的精度下进行，中间计算步骤后四舍五入，基于自适应阈值存储四舍五入决策。",
    "tldr": "提出了一种方法，结合了在比目标模型更高精度下进行训练、在中间计算步骤后进行四舍五入，并基于自适应阈值存储四舍五入决策，以应对硬件非确定性对训练过程的影响。",
    "en_tdlr": "Proposed a method that combines training in a higher precision than the target model, rounding after intermediate computation steps, and storing rounding decisions based on an adaptive threshold to address the impact of hardware nondeterminism on the training process."
}