{
    "title": "The NeurIPS 2023 Machine Learning for Audio Workshop: Affective Audio Benchmarks and Novel Data",
    "abstract": "arXiv:2403.14048v1 Announce Type: cross  Abstract: The NeurIPS 2023 Machine Learning for Audio Workshop brings together machine learning (ML) experts from various audio domains. There are several valuable audio-driven ML tasks, from speech emotion recognition to audio event detection, but the community is sparse compared to other ML areas, e.g., computer vision or natural language processing. A major limitation with audio is the available data; with audio being a time-dependent modality, high-quality data collection is time-consuming and costly, making it challenging for academic groups to apply their often state-of-the-art strategies to a larger, more generalizable dataset. In this short white paper, to encourage researchers with limited access to large-datasets, the organizers first outline several open-source datasets that are available to the community, and for the duration of the workshop are making several propriety datasets available. Namely, three vocal datasets, Hume-Prosody, ",
    "link": "https://arxiv.org/abs/2403.14048",
    "context": "Title: The NeurIPS 2023 Machine Learning for Audio Workshop: Affective Audio Benchmarks and Novel Data\nAbstract: arXiv:2403.14048v1 Announce Type: cross  Abstract: The NeurIPS 2023 Machine Learning for Audio Workshop brings together machine learning (ML) experts from various audio domains. There are several valuable audio-driven ML tasks, from speech emotion recognition to audio event detection, but the community is sparse compared to other ML areas, e.g., computer vision or natural language processing. A major limitation with audio is the available data; with audio being a time-dependent modality, high-quality data collection is time-consuming and costly, making it challenging for academic groups to apply their often state-of-the-art strategies to a larger, more generalizable dataset. In this short white paper, to encourage researchers with limited access to large-datasets, the organizers first outline several open-source datasets that are available to the community, and for the duration of the workshop are making several propriety datasets available. Namely, three vocal datasets, Hume-Prosody, ",
    "path": "papers/24/03/2403.14048.json",
    "total_tokens": 890,
    "translated_title": "NeurIPS 2023音频机器学习研讨会：情感音频基准和新数据",
    "translated_abstract": "NeurIPS 2023音频机器学习研讨会汇集了来自各种音频领域的机器学习（ML）专家。 文章指出，有许多有价值的音频驱动的ML任务，从语音情感识别到音频事件检测，但相比于其他ML领域（如计算机视觉或自然语言处理），音频社区相对较少。 其中一个主要限制是可用的数据； 由于音频是一种时间相关的模态，高质量的数据收集耗时且昂贵，这使得学术团体难以将他们的最先进策略应用于一个更大，更具普遍性的数据集。 为鼓励那些获取大型数据集困难的研究人员，研讨会组织者首先概述了几个可供社区使用的开源数据集，并在研讨会期间提供了几个专有数据集。 具体来说，包括三个发声数据集，Hume-Prosody，",
    "tldr": "NeurIPS 2023音频机器学习研讨会聚集了音频领域的机器学习专家，为解决音频数据获取困难的问题，提供了多个开源数据集和专有数据集。"
}