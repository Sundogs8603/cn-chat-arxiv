{
    "title": "Cross-lingual Contextualized Phrase Retrieval",
    "abstract": "arXiv:2403.16820v1 Announce Type: new  Abstract: Phrase-level dense retrieval has shown many appealing characteristics in downstream NLP tasks by leveraging the fine-grained information that phrases offer. In our work, we propose a new task formulation of dense retrieval, cross-lingual contextualized phrase retrieval, which aims to augment cross-lingual applications by addressing polysemy using context information. However, the lack of specific training data and models are the primary challenges to achieve our goal. As a result, we extract pairs of cross-lingual phrases using word alignment information automatically induced from parallel sentences. Subsequently, we train our Cross-lingual Contextualized Phrase Retriever (CCPR) using contrastive learning, which encourages the hidden representations of phrases with similar contexts and semantics to align closely. Comprehensive experiments on both the cross-lingual phrase retrieval task and a downstream task, i.e, machine translation, dem",
    "link": "https://arxiv.org/abs/2403.16820",
    "context": "Title: Cross-lingual Contextualized Phrase Retrieval\nAbstract: arXiv:2403.16820v1 Announce Type: new  Abstract: Phrase-level dense retrieval has shown many appealing characteristics in downstream NLP tasks by leveraging the fine-grained information that phrases offer. In our work, we propose a new task formulation of dense retrieval, cross-lingual contextualized phrase retrieval, which aims to augment cross-lingual applications by addressing polysemy using context information. However, the lack of specific training data and models are the primary challenges to achieve our goal. As a result, we extract pairs of cross-lingual phrases using word alignment information automatically induced from parallel sentences. Subsequently, we train our Cross-lingual Contextualized Phrase Retriever (CCPR) using contrastive learning, which encourages the hidden representations of phrases with similar contexts and semantics to align closely. Comprehensive experiments on both the cross-lingual phrase retrieval task and a downstream task, i.e, machine translation, dem",
    "path": "papers/24/03/2403.16820.json",
    "total_tokens": 838,
    "translated_title": "跨语言上下文化短语检索",
    "translated_abstract": "短语级密集检索通过利用短语提供的细粒度信息，在下游自然语言处理任务中展现出许多吸引人的特征。在我们的工作中，我们提出了一种新的密集检索任务形式，即跨语言上下文化短语检索，旨在通过使用上下文信息来增强解决多义性的跨语言应用。然而，缺乏特定的训练数据和模型是实现我们目标的主要挑战。因此，我们利用从平行句子中自动诱导的单词对齐信息提取跨语言短语对。随后，我们使用对比学习训练我们的跨语言上下文化短语检索器（CCPR），该对比学习鼓励具有相似上下文和语义的短语的隐藏表示紧密对齐。我们对跨语言短语检索任务和一个下游任务，即机器翻译，进行了全面的实验。",
    "tldr": "该研究提出了跨语言上下文化短语检索任务，并通过利用对比学习来解决多义性，从而增强了跨语言应用的性能。",
    "en_tdlr": "This paper introduces the task of cross-lingual contextualized phrase retrieval and enhances cross-lingual applications performance by leveraging contrastive learning to address polysemy."
}