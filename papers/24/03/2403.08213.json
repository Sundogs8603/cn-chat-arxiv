{
    "title": "Can Large Language Models Identify Authorship?",
    "abstract": "arXiv:2403.08213v1 Announce Type: new  Abstract: The ability to accurately identify authorship is crucial for verifying content authenticity and mitigating misinformation. Large Language Models (LLMs) have demonstrated exceptional capacity for reasoning and problem-solving. However, their potential in authorship analysis, encompassing authorship verification and attribution, remains underexplored. This paper conducts a comprehensive evaluation of LLMs in these critical tasks. Traditional studies have depended on hand-crafted stylistic features, whereas state-of-the-art approaches leverage text embeddings from pre-trained language models. These methods, which typically require fine-tuning on labeled data, often suffer from performance degradation in cross-domain applications and provide limited explainability. This work seeks to address three research questions: (1) Can LLMs perform zero-shot, end-to-end authorship verification effectively? (2) Are LLMs capable of accurately attributing",
    "link": "https://arxiv.org/abs/2403.08213",
    "context": "Title: Can Large Language Models Identify Authorship?\nAbstract: arXiv:2403.08213v1 Announce Type: new  Abstract: The ability to accurately identify authorship is crucial for verifying content authenticity and mitigating misinformation. Large Language Models (LLMs) have demonstrated exceptional capacity for reasoning and problem-solving. However, their potential in authorship analysis, encompassing authorship verification and attribution, remains underexplored. This paper conducts a comprehensive evaluation of LLMs in these critical tasks. Traditional studies have depended on hand-crafted stylistic features, whereas state-of-the-art approaches leverage text embeddings from pre-trained language models. These methods, which typically require fine-tuning on labeled data, often suffer from performance degradation in cross-domain applications and provide limited explainability. This work seeks to address three research questions: (1) Can LLMs perform zero-shot, end-to-end authorship verification effectively? (2) Are LLMs capable of accurately attributing",
    "path": "papers/24/03/2403.08213.json",
    "total_tokens": 814,
    "translated_title": "大型语言模型能否识别作者身份？",
    "translated_abstract": "精准识别作者身份对验证内容真实性和减少误导信息至关重要。 大型语言模型（LLMs）展示了出色的推理和问题解决能力。然而，它们在作者分析（包括作者验证和归属）方面的潜力仍未得到充分探索。 本文对LLMs在这些关键任务中进行了全面评估。 传统研究依赖于手工制作的文体特征，而最先进的方法利用预先训练的语言模型中的文本嵌入。 这些方法通常需要在标记数据上进行微调，然而在跨领域应用中往往表现出性能下降，并提供有限的可解释性。 本文旨在回答三个研究问题：（1）LLMs能否有效执行零样本、端到端的作者验证？（2）LLMs能否准确进行作者身份归属？",
    "tldr": "大型语言模型在作者识别方面的潜力尚未得到充分探索，本文通过全面评估解决了LLMs在作者验证和归属中的三个关键研究问题。",
    "en_tdlr": "This paper comprehensively evaluates the potential of Large Language Models in authorship analysis and addresses three key research questions in authorship verification and attribution."
}