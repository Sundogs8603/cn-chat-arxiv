{
    "title": "STARFlow: Spatial Temporal Feature Re-embedding with Attentive Learning for Real-world Scene Flow",
    "abstract": "arXiv:2403.07032v1 Announce Type: cross  Abstract: Scene flow prediction is a crucial underlying task in understanding dynamic scenes as it offers fundamental motion information. However, contemporary scene flow methods encounter three major challenges. Firstly, flow estimation solely based on local receptive fields lacks long-dependency matching of point pairs. To address this issue, we propose global attentive flow embedding to match all-to-all point pairs in both feature space and Euclidean space, providing global initialization before local refinement. Secondly, there are deformations existing in non-rigid objects after warping, which leads to variations in the spatiotemporal relation between the consecutive frames. For a more precise estimation of residual flow, a spatial temporal feature re-embedding module is devised to acquire the sequence features after deformation. Furthermore, previous methods perform poor generalization due to the significant domain gap between the synthesi",
    "link": "https://arxiv.org/abs/2403.07032",
    "context": "Title: STARFlow: Spatial Temporal Feature Re-embedding with Attentive Learning for Real-world Scene Flow\nAbstract: arXiv:2403.07032v1 Announce Type: cross  Abstract: Scene flow prediction is a crucial underlying task in understanding dynamic scenes as it offers fundamental motion information. However, contemporary scene flow methods encounter three major challenges. Firstly, flow estimation solely based on local receptive fields lacks long-dependency matching of point pairs. To address this issue, we propose global attentive flow embedding to match all-to-all point pairs in both feature space and Euclidean space, providing global initialization before local refinement. Secondly, there are deformations existing in non-rigid objects after warping, which leads to variations in the spatiotemporal relation between the consecutive frames. For a more precise estimation of residual flow, a spatial temporal feature re-embedding module is devised to acquire the sequence features after deformation. Furthermore, previous methods perform poor generalization due to the significant domain gap between the synthesi",
    "path": "papers/24/03/2403.07032.json",
    "total_tokens": 853,
    "translated_title": "STARFlow: 具有注意力学习的空间时间特征重新嵌入用于现实世界的场景流",
    "translated_abstract": "场景流预测是理解动态场景中的关键任务，因为它提供了基本的运动信息。然而，当代场景流方法面临三大挑战。首先，仅基于局部感受野的流估计缺乏点对的长依赖匹配。为了解决这个问题，我们提出了全局注意力流嵌入，以匹配特征空间和欧几里得空间中的所有点对，提供局部细化之前的全局初始化。其次，在变形后存在非刚性物体的变形，导致连续帧之间的时空关系变化。为了更精确地估计残余流，设计了一个空间时间特征重新嵌入模块，以在变形后获取序列特征。此外，由于合成数据和真实数据之间的显著域差异，先前的方法表现出较差的泛化能力。",
    "tldr": "提出了一种全局注意力流嵌入和空间时间特征重新嵌入模块相结合的方法，用于解决现实世界场景流预测中的局部依赖匹配和非刚性物体变形的挑战。"
}