{
    "title": "Debatrix: Multi-dimensinal Debate Judge with Iterative Chronological Analysis Based on LLM",
    "abstract": "arXiv:2403.08010v1 Announce Type: new  Abstract: How can we construct an automated debate judge to evaluate an extensive, vibrant, multi-turn debate? This task is challenging, as judging a debate involves grappling with lengthy texts, intricate argument relationships, and multi-dimensional assessments. At the same time, current research mainly focuses on short dialogues, rarely touching upon the evaluation of an entire debate. In this paper, by leveraging Large Language Models (LLMs), we propose Debatrix, which makes the analysis and assessment of multi-turn debates more aligned with majority preferences. Specifically, Debatrix features a vertical, iterative chronological analysis and a horizontal, multi-dimensional evaluation collaboration. To align with real-world debate scenarios, we introduced the PanelBench benchmark, comparing our system's performance to actual debate outcomes. The findings indicate a notable enhancement over directly using LLMs for debate evaluation. Source code",
    "link": "https://arxiv.org/abs/2403.08010",
    "context": "Title: Debatrix: Multi-dimensinal Debate Judge with Iterative Chronological Analysis Based on LLM\nAbstract: arXiv:2403.08010v1 Announce Type: new  Abstract: How can we construct an automated debate judge to evaluate an extensive, vibrant, multi-turn debate? This task is challenging, as judging a debate involves grappling with lengthy texts, intricate argument relationships, and multi-dimensional assessments. At the same time, current research mainly focuses on short dialogues, rarely touching upon the evaluation of an entire debate. In this paper, by leveraging Large Language Models (LLMs), we propose Debatrix, which makes the analysis and assessment of multi-turn debates more aligned with majority preferences. Specifically, Debatrix features a vertical, iterative chronological analysis and a horizontal, multi-dimensional evaluation collaboration. To align with real-world debate scenarios, we introduced the PanelBench benchmark, comparing our system's performance to actual debate outcomes. The findings indicate a notable enhancement over directly using LLMs for debate evaluation. Source code",
    "path": "papers/24/03/2403.08010.json",
    "total_tokens": 863,
    "translated_title": "Debatrix:基于LLM的多维辩论评判系统与迭代时间序列分析",
    "translated_abstract": "如何构建一个自动化辩论评判系统来评估一场广泛、充满活力的多轮辩论？这一任务具有挑战性，因为评判辩论涉及处理冗长文本、复杂的论点关系和多维度评估。当前的研究主要集中在短对话，很少涉及对整场辩论的评估。在本文中，通过利用大型语言模型（LLMs），我们提出了Debatrix，使得多轮辩论的分析和评估更符合大多数人的偏好。具体而言，Debatrix具有垂直的、迭代式的时间序列分析和水平的、多维度的评估协作。为了与现实世界的辩论场景保持一致，我们引入了PanelBench基准，将我们系统的性能与实际辩论结果进行比较。研究结果显示，相较于直接使用LLMs进行辩论评估，我们的系统表现出显著的增强效果。",
    "tldr": "提出了Debatrix系统，利用LLMs进行多轮辩论的分析和评估，性能显著优于直接使用LLMs，实现了对整场辩论的评估。",
    "en_tdlr": "Introduced Debatrix system, utilizing LLMs for analysis and evaluation of multi-turn debates, showing significant improvement over direct use of LLMs and achieving evaluation of entire debate."
}