{
    "title": "DPPA: Pruning Method for Large Language Model to Model Merging",
    "abstract": "arXiv:2403.02799v1 Announce Type: cross  Abstract: Model merging is to combine fine-tuned models derived from multiple domains, with the intent of enhancing the model's proficiency across various domains. The principal concern is the resolution of parameter conflicts. A substantial amount of existing research remedy this issue during the merging stage, with the latest study focusing on resolving this issue throughout the pruning stage. The DARE approach has exhibited promising outcomes when applied to a simplistic fine-tuned model. However, the efficacy of this method tends to wane when employed on complex fine-tuned models that show a significant parameter bias relative to the baseline model. In this paper, we introduce a dual-stage method termed Dynamic Pruning Partition Amplification (DPPA), devised to tackle the challenge of merging complex fine-tuned models. Initially, we introduce Dynamically Pruning (DP), an improved approach based on magnitude pruning, which aim is to enhance p",
    "link": "https://arxiv.org/abs/2403.02799",
    "context": "Title: DPPA: Pruning Method for Large Language Model to Model Merging\nAbstract: arXiv:2403.02799v1 Announce Type: cross  Abstract: Model merging is to combine fine-tuned models derived from multiple domains, with the intent of enhancing the model's proficiency across various domains. The principal concern is the resolution of parameter conflicts. A substantial amount of existing research remedy this issue during the merging stage, with the latest study focusing on resolving this issue throughout the pruning stage. The DARE approach has exhibited promising outcomes when applied to a simplistic fine-tuned model. However, the efficacy of this method tends to wane when employed on complex fine-tuned models that show a significant parameter bias relative to the baseline model. In this paper, we introduce a dual-stage method termed Dynamic Pruning Partition Amplification (DPPA), devised to tackle the challenge of merging complex fine-tuned models. Initially, we introduce Dynamically Pruning (DP), an improved approach based on magnitude pruning, which aim is to enhance p",
    "path": "papers/24/03/2403.02799.json",
    "total_tokens": 828,
    "translated_title": "DPPA：用于大型语言模型的修剪方法以进行模型合并",
    "translated_abstract": "模型合并是将从多个领域衍生出的微调模型相结合，旨在增强模型在各个领域的熟练度。主要关注点是解决参数冲突。现有大量研究已解决了合并阶段的这个问题，最新研究集中在通过修剪阶段来解决这个问题。DARE方法在应用于简单微调模型时表现出有希望的结果。然而，当用于显示与基线模型相比存在显著参数偏差的复杂微调模型时，该方法的有效性往往会减弱。本文介绍了一种名为动态修剪分区增强（DPPA）的双阶段方法，旨在解决合并复杂微调模型的挑战。首先，我们介绍了动态修剪（DP），这是一种基于量剪枝的改进方法，其目的是增强p",
    "tldr": "提出了一种名为动态修剪分区增强（DPPA）的双阶段方法，用于解决合并复杂微调模型的挑战。",
    "en_tdlr": "Introduced a dual-stage method called Dynamic Pruning Partition Amplification (DPPA) to address the challenge of merging complex fine-tuned models."
}