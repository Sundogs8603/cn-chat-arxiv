{
    "title": "InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents",
    "abstract": "arXiv:2403.02691v1 Announce Type: new  Abstract: Recent work has embodied LLMs as agents, allowing them to access tools, perform actions, and interact with external content (e.g., emails or websites). However, external content introduces the risk of indirect prompt injection (IPI) attacks, where malicious instructions are embedded within the content processed by LLMs, aiming to manipulate these agents into executing detrimental actions against users. Given the potentially severe consequences of such attacks, establishing benchmarks to assess and mitigate these risks is imperative.   In this work, we introduce InjecAgent, a benchmark designed to assess the vulnerability of tool-integrated LLM agents to IPI attacks. InjecAgent comprises 1,054 test cases covering 17 different user tools and 62 attacker tools. We categorize attack intentions into two primary types: direct harm to users and exfiltration of private data. We evaluate 30 different LLM agents and show that agents are vulnerable",
    "link": "https://arxiv.org/abs/2403.02691",
    "context": "Title: InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents\nAbstract: arXiv:2403.02691v1 Announce Type: new  Abstract: Recent work has embodied LLMs as agents, allowing them to access tools, perform actions, and interact with external content (e.g., emails or websites). However, external content introduces the risk of indirect prompt injection (IPI) attacks, where malicious instructions are embedded within the content processed by LLMs, aiming to manipulate these agents into executing detrimental actions against users. Given the potentially severe consequences of such attacks, establishing benchmarks to assess and mitigate these risks is imperative.   In this work, we introduce InjecAgent, a benchmark designed to assess the vulnerability of tool-integrated LLM agents to IPI attacks. InjecAgent comprises 1,054 test cases covering 17 different user tools and 62 attacker tools. We categorize attack intentions into two primary types: direct harm to users and exfiltration of private data. We evaluate 30 different LLM agents and show that agents are vulnerable",
    "path": "papers/24/03/2403.02691.json",
    "total_tokens": 915,
    "translated_title": "InjecAgent：基于工具集成的大型语言模型Agent中的间接提示注入基准测试",
    "translated_abstract": "最近的工作将LLMs作为代理体现出来，使它们能够访问工具，执行操作，并与外部内容（例如，电子邮件或网站）进行交互。然而，外部内容引入了间接提示注入（IPI）攻击的风险，恶意指令被嵌入LLMs处理的内容中，旨在操纵这些代理执行对用户有害的操作。考虑到这类攻击的潜在严重后果，建立用于评估和减轻这些风险的基准测试至关重要。在这项工作中，我们介绍了InjecAgent，这是一个旨在评估工具集成的LLM代理对IPI攻击的脆弱性的基准测试。InjecAgent包括1,054个测试用例，涵盖17种不同的用户工具和62种攻击者工具。我们将攻击意图分为两种主要类型：对用户造成直接伤害和窃取私人数据。我们评估了30种不同的LLM代理，并表明这些代理是脆弱的。",
    "tldr": "本研究引入了InjecAgent基准测试，用于评估工具集成的大型语言模型代理对间接提示注入攻击的脆弱性，通过评估30种LLM代理，发现这些代理存在漏洞",
    "en_tdlr": "This work introduces the InjecAgent benchmark to assess the vulnerability of tool-integrated large language model agents to indirect prompt injection attacks, evaluating 30 different LLM agents and revealing their vulnerabilities."
}