{
    "title": "Rotary Position Embedding for Vision Transformer",
    "abstract": "arXiv:2403.13298v1 Announce Type: cross  Abstract: Rotary Position Embedding (RoPE) performs remarkably on language models, especially for length extrapolation of Transformers. However, the impacts of RoPE on computer vision domains have been underexplored, even though RoPE appears capable of enhancing Vision Transformer (ViT) performance in a way similar to the language domain. This study provides a comprehensive analysis of RoPE when applied to ViTs, utilizing practical implementations of RoPE for 2D vision data. The analysis reveals that RoPE demonstrates impressive extrapolation performance, i.e., maintaining precision while increasing image resolution at inference. It eventually leads to performance improvement for ImageNet-1k, COCO detection, and ADE-20k segmentation. We believe this study provides thorough guidelines to apply RoPE into ViT, promising improved backbone performance with minimal extra computational overhead. Our code and pre-trained models are available at https://",
    "link": "https://arxiv.org/abs/2403.13298",
    "context": "Title: Rotary Position Embedding for Vision Transformer\nAbstract: arXiv:2403.13298v1 Announce Type: cross  Abstract: Rotary Position Embedding (RoPE) performs remarkably on language models, especially for length extrapolation of Transformers. However, the impacts of RoPE on computer vision domains have been underexplored, even though RoPE appears capable of enhancing Vision Transformer (ViT) performance in a way similar to the language domain. This study provides a comprehensive analysis of RoPE when applied to ViTs, utilizing practical implementations of RoPE for 2D vision data. The analysis reveals that RoPE demonstrates impressive extrapolation performance, i.e., maintaining precision while increasing image resolution at inference. It eventually leads to performance improvement for ImageNet-1k, COCO detection, and ADE-20k segmentation. We believe this study provides thorough guidelines to apply RoPE into ViT, promising improved backbone performance with minimal extra computational overhead. Our code and pre-trained models are available at https://",
    "path": "papers/24/03/2403.13298.json",
    "total_tokens": 845,
    "translated_title": "视觉变压器的旋转位置嵌入",
    "translated_abstract": "旋转位置嵌入（RoPE）在语言模型上表现出色，特别适用于Transformer的长度外推。然而，RoPE对计算机视觉领域的影响尚未被充分探讨，尽管RoPE似乎能够像语言领域一样增强视觉变压器（ViT）的性能。本研究对将RoPE应用于ViT时进行了全面分析，利用RoPE在2D视觉数据上的实际实现。分析显示，RoPE展示出令人印象深刻的外推性能，即在推断时在增加图像分辨率的同时保持精度。最终导致了ImageNet-1k、COCO检测和ADE-20k分割的性能提升。我们相信本研究提供了将RoPE应用于ViT的详尽指导，承诺通过最小的额外计算开销提高骨干性能。我们的代码和预训练模型可在网址https://找到。",
    "tldr": "RoPE在视觉变压器中展现出令人印象深刻的外推性能，提高了ImageNet-1k、COCO检测和ADE-20k分割的性能。",
    "en_tdlr": "RoPE demonstrates impressive extrapolation performance in Vision Transformer, leading to performance improvement in ImageNet-1k, COCO detection, and ADE-20k segmentation."
}