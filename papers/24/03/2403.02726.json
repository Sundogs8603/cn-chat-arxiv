{
    "title": "Bias in Generative AI",
    "abstract": "arXiv:2403.02726v1 Announce Type: cross  Abstract: This study analyzed images generated by three popular generative artificial intelligence (AI) tools - Midjourney, Stable Diffusion, and DALLE 2 - representing various occupations to investigate potential bias in AI generators. Our analysis revealed two overarching areas of concern in these AI generators, including (1) systematic gender and racial biases, and (2) subtle biases in facial expressions and appearances. Firstly, we found that all three AI generators exhibited bias against women and African Americans. Moreover, we found that the evident gender and racial biases uncovered in our analysis were even more pronounced than the status quo when compared to labor force statistics or Google images, intensifying the harmful biases we are actively striving to rectify in our society. Secondly, our study uncovered more nuanced prejudices in the portrayal of emotions and appearances. For example, women were depicted as younger with more smi",
    "link": "https://arxiv.org/abs/2403.02726",
    "context": "Title: Bias in Generative AI\nAbstract: arXiv:2403.02726v1 Announce Type: cross  Abstract: This study analyzed images generated by three popular generative artificial intelligence (AI) tools - Midjourney, Stable Diffusion, and DALLE 2 - representing various occupations to investigate potential bias in AI generators. Our analysis revealed two overarching areas of concern in these AI generators, including (1) systematic gender and racial biases, and (2) subtle biases in facial expressions and appearances. Firstly, we found that all three AI generators exhibited bias against women and African Americans. Moreover, we found that the evident gender and racial biases uncovered in our analysis were even more pronounced than the status quo when compared to labor force statistics or Google images, intensifying the harmful biases we are actively striving to rectify in our society. Secondly, our study uncovered more nuanced prejudices in the portrayal of emotions and appearances. For example, women were depicted as younger with more smi",
    "path": "papers/24/03/2403.02726.json",
    "total_tokens": 814,
    "translated_title": "生成AI中的偏见",
    "translated_abstract": "本研究分析了三种流行的生成人工智能（AI）工具（Midjourney，Stable Diffusion和DALLE 2）生成的代表各种职业的图像，以调查AI生成器中潜在的偏见。我们的分析揭示了这些AI生成器存在的两个主要关注领域，包括（1）系统性的性别和种族偏见，以及（2）对面部表情和外表的微妙偏见。首先，我们发现这三种AI生成器都存在对女性和非裔美国人的偏见。此外，我们发现，我们分析中揭示的明显的性别和种族偏见，与劳动力统计数据或Google图像相比，甚至更加显著，加剧了社会中我们正在积极努力纠正的有害偏见。其次，我们的研究揭示了在表现情绪和外表方面更加微妙的偏见。例如，女性被描绘为年轻且更多地微笑。",
    "tldr": "本研究揭示了生成AI工具中存在的系统性性别和种族偏见，以及对面部表情和外表的微妙偏见。",
    "en_tdlr": "This study revealed systematic gender and racial biases in generative AI tools, as well as subtle biases in facial expressions and appearances."
}