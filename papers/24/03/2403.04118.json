{
    "title": "Globally Stable Neural Imitation Policies",
    "abstract": "arXiv:2403.04118v1 Announce Type: cross  Abstract: Imitation learning presents an effective approach to alleviate the resource-intensive and time-consuming nature of policy learning from scratch in the solution space. Even though the resulting policy can mimic expert demonstrations reliably, it often lacks predictability in unexplored regions of the state-space, giving rise to significant safety concerns in the face of perturbations. To address these challenges, we introduce the Stable Neural Dynamical System (SNDS), an imitation learning regime which produces a policy with formal stability guarantees. We deploy a neural policy architecture that facilitates the representation of stability based on Lyapunov theorem, and jointly train the policy and its corresponding Lyapunov candidate to ensure global stability. We validate our approach by conducting extensive experiments in simulation and successfully deploying the trained policies on a real-world manipulator arm. The experimental resu",
    "link": "https://arxiv.org/abs/2403.04118",
    "context": "Title: Globally Stable Neural Imitation Policies\nAbstract: arXiv:2403.04118v1 Announce Type: cross  Abstract: Imitation learning presents an effective approach to alleviate the resource-intensive and time-consuming nature of policy learning from scratch in the solution space. Even though the resulting policy can mimic expert demonstrations reliably, it often lacks predictability in unexplored regions of the state-space, giving rise to significant safety concerns in the face of perturbations. To address these challenges, we introduce the Stable Neural Dynamical System (SNDS), an imitation learning regime which produces a policy with formal stability guarantees. We deploy a neural policy architecture that facilitates the representation of stability based on Lyapunov theorem, and jointly train the policy and its corresponding Lyapunov candidate to ensure global stability. We validate our approach by conducting extensive experiments in simulation and successfully deploying the trained policies on a real-world manipulator arm. The experimental resu",
    "path": "papers/24/03/2403.04118.json",
    "total_tokens": 889,
    "translated_title": "全局稳定的神经仿真政策",
    "translated_abstract": "仿真学习提供了一种有效的方法，可以缓解从头开始在解决空间中学习政策的资源密集和耗时的特性。尽管结果政策可以可靠地模仿专家演示，但在状态空间的未探索区域中常常缺乏可预测性，这给在面对扰动时带来了重大安全问题。为了解决这些挑战，我们引入了稳定神经动力系统（SNDS），一种生成具有正式稳定性保证的政策的仿真学习制度。我们使用神经政策架构，促进基于李亚普诺夫定理的稳定性表示，并联合训练政策及其相应的李亚普诺夫候选者，以确保全局稳定性。我们通过在仿真中进行大量实验来验证我们的方法，并成功将经过训练的政策部署到现实世界的机械手臂上。实验结果表明，我们的SNDS方法相比现有方法具有更好的全局稳定性和鲁棒性。",
    "tldr": "提出了稳定神经动力系统（SNDS）的仿真学习制度，可生成具有正式稳定性保证的政策，并通过联合训练政策和其对应的李亚普诺夫候选者确保全局稳定性。",
    "en_tdlr": "Introducing the Stable Neural Dynamical System (SNDS) for imitation learning, generating policies with formal stability guarantees by jointly training the policy and its corresponding Lyapunov candidate to ensure global stability."
}