{
    "title": "Gender Bias in Large Language Models across Multiple Languages",
    "abstract": "arXiv:2403.00277v1 Announce Type: new  Abstract: With the growing deployment of large language models (LLMs) across various applications, assessing the influence of gender biases embedded in LLMs becomes crucial. The topic of gender bias within the realm of natural language processing (NLP) has gained considerable focus, particularly in the context of English. Nonetheless, the investigation of gender bias in languages other than English is still relatively under-explored and insufficiently analyzed. In this work, We examine gender bias in LLMs-generated outputs for different languages. We use three measurements: 1) gender bias in selecting descriptive words given the gender-related context. 2) gender bias in selecting gender-related pronouns (she/he) given the descriptive words. 3) gender bias in the topics of LLM-generated dialogues. We investigate the outputs of the GPT series of LLMs in various languages using our three measurement methods. Our findings revealed significant gender b",
    "link": "https://arxiv.org/abs/2403.00277",
    "context": "Title: Gender Bias in Large Language Models across Multiple Languages\nAbstract: arXiv:2403.00277v1 Announce Type: new  Abstract: With the growing deployment of large language models (LLMs) across various applications, assessing the influence of gender biases embedded in LLMs becomes crucial. The topic of gender bias within the realm of natural language processing (NLP) has gained considerable focus, particularly in the context of English. Nonetheless, the investigation of gender bias in languages other than English is still relatively under-explored and insufficiently analyzed. In this work, We examine gender bias in LLMs-generated outputs for different languages. We use three measurements: 1) gender bias in selecting descriptive words given the gender-related context. 2) gender bias in selecting gender-related pronouns (she/he) given the descriptive words. 3) gender bias in the topics of LLM-generated dialogues. We investigate the outputs of the GPT series of LLMs in various languages using our three measurement methods. Our findings revealed significant gender b",
    "path": "papers/24/03/2403.00277.json",
    "total_tokens": 857,
    "translated_title": "多语种大型语言模型中的性别偏见",
    "translated_abstract": "随着大型语言模型(LLMs)在各种应用中的不断部署，评估LLMs中嵌入的性别偏见的影响变得至关重要。自然语言处理（NLP）领域中的性别偏见主题已经受到相当关注，特别是在英语环境下。然而，对于非英语语言中的性别偏见的调查仍然相对较少且分析不足。在本研究中，我们研究不同语言的LLMs生成的输出中的性别偏见。我们使用三种测量方法：1）在给定性别相关上下文的情况下选择描述性词汇时的性别偏见。2）在给定描述性词汇的情况下选择性别相关代词（她/他）时的性别偏见。3）在LLM生成的对话主题中的性别偏见。我们使用我们的三种测量方法研究了各语种中GPT系列LLMs的输出。我们的研究结果显示了显著的性别偏见。",
    "tldr": "本研究调查了不同语种中大型语言模型生成的输出中的性别偏见，使用了三种测量方法，结果显示存在显著的性别偏见。",
    "en_tdlr": "This study examines gender bias in outputs generated by large language models in different languages using three measurement methods, revealing significant gender bias."
}