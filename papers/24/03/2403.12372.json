{
    "title": "Learning Transferable Time Series Classifier with Cross-Domain Pre-training from Language Model",
    "abstract": "arXiv:2403.12372v1 Announce Type: new  Abstract: Advancements in self-supervised pre-training (SSL) have significantly advanced the field of learning transferable time series representations, which can be very useful in enhancing the downstream task. Despite being effective, most existing works struggle to achieve cross-domain SSL pre-training, missing valuable opportunities to integrate patterns and features from different domains. The main challenge lies in the significant differences in the characteristics of time-series data across different domains, such as variations in the number of channels and temporal resolution scales. To address this challenge, we propose CrossTimeNet, a novel cross-domain SSL learning framework to learn transferable knowledge from various domains to largely benefit the target downstream task. One of the key characteristics of CrossTimeNet is the newly designed time series tokenization module, which could effectively convert the raw time series into a seque",
    "link": "https://arxiv.org/abs/2403.12372",
    "context": "Title: Learning Transferable Time Series Classifier with Cross-Domain Pre-training from Language Model\nAbstract: arXiv:2403.12372v1 Announce Type: new  Abstract: Advancements in self-supervised pre-training (SSL) have significantly advanced the field of learning transferable time series representations, which can be very useful in enhancing the downstream task. Despite being effective, most existing works struggle to achieve cross-domain SSL pre-training, missing valuable opportunities to integrate patterns and features from different domains. The main challenge lies in the significant differences in the characteristics of time-series data across different domains, such as variations in the number of channels and temporal resolution scales. To address this challenge, we propose CrossTimeNet, a novel cross-domain SSL learning framework to learn transferable knowledge from various domains to largely benefit the target downstream task. One of the key characteristics of CrossTimeNet is the newly designed time series tokenization module, which could effectively convert the raw time series into a seque",
    "path": "papers/24/03/2403.12372.json",
    "total_tokens": 753,
    "translated_title": "使用语言模型的跨领域预训练学习可传递的时间序列分类器",
    "translated_abstract": "自监督预训练（SSL）的进展显著推动了可传递的时间序列表示领域的发展，这对于增强下游任务非常有用。尽管有效，但大多数现有工作在跨领域SSL预训练方面存在困难，错过了集成不同领域模式和特征的宝贵机会。我们提出了CrossTimeNet，这是一个新颖的跨领域SSL学习框架，旨在从各种领域学习可传递的知识，从而大大增强目标下游任务的效果。",
    "tldr": "提出了CrossTimeNet，一个新颖的跨领域自监督预训练学习框架，旨在解决不同领域时间序列数据特性差异带来的挑战，并能有效转换原始时间序列数据。",
    "en_tdlr": "Introduced CrossTimeNet, a novel cross-domain self-supervised pre-training framework aimed at addressing the challenges posed by differences in time-series data characteristics across domains and effectively converting raw time series data."
}