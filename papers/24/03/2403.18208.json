{
    "title": "An Evolutionary Network Architecture Search Framework with Adaptive Multimodal Fusion for Hand Gesture Recognition",
    "abstract": "arXiv:2403.18208v1 Announce Type: cross  Abstract: Hand gesture recognition (HGR) based on multimodal data has attracted considerable attention owing to its great potential in applications. Various manually designed multimodal deep networks have performed well in multimodal HGR (MHGR), but most of existing algorithms require a lot of expert experience and time-consuming manual trials. To address these issues, we propose an evolutionary network architecture search framework with the adaptive multimodel fusion (AMF-ENAS). Specifically, we design an encoding space that simultaneously considers fusion positions and ratios of the multimodal data, allowing for the automatic construction of multimodal networks with different architectures through decoding. Additionally, we consider three input streams corresponding to intra-modal surface electromyography (sEMG), intra-modal accelerometer (ACC), and inter-modal sEMG-ACC. To automatically adapt to various datasets, the ENAS framework is designe",
    "link": "https://arxiv.org/abs/2403.18208",
    "context": "Title: An Evolutionary Network Architecture Search Framework with Adaptive Multimodal Fusion for Hand Gesture Recognition\nAbstract: arXiv:2403.18208v1 Announce Type: cross  Abstract: Hand gesture recognition (HGR) based on multimodal data has attracted considerable attention owing to its great potential in applications. Various manually designed multimodal deep networks have performed well in multimodal HGR (MHGR), but most of existing algorithms require a lot of expert experience and time-consuming manual trials. To address these issues, we propose an evolutionary network architecture search framework with the adaptive multimodel fusion (AMF-ENAS). Specifically, we design an encoding space that simultaneously considers fusion positions and ratios of the multimodal data, allowing for the automatic construction of multimodal networks with different architectures through decoding. Additionally, we consider three input streams corresponding to intra-modal surface electromyography (sEMG), intra-modal accelerometer (ACC), and inter-modal sEMG-ACC. To automatically adapt to various datasets, the ENAS framework is designe",
    "path": "papers/24/03/2403.18208.json",
    "total_tokens": 844,
    "translated_title": "一种具有自适应多模态融合的演化网络架构搜索框架用于手势识别",
    "translated_abstract": "基于多模态数据的手势识别(HGR)因其在应用中的巨大潜力而引起了广泛关注。各种手动设计的多模态深度网络在多模态HGR（MHGR）中表现良好，但大多数现有算法需要大量专家经验和耗时的手动试验。为了解决这些问题，我们提出了一个具有自适应多模态融合的演化网络架构搜索框架(AMF-ENAS)。具体地，我们设计了一个编码空间，同时考虑了多模态数据的融合位置和比例，允许通过解码自动构建具有不同架构的多模态网络。此外，我们考虑了对应于单模态表面肌电图(sEMG)、单模态加速度计(ACC)和跨模态(sEMG-ACC)的三个输入流。为了自动适应各种数据集，ENAS框架被设计为",
    "tldr": "提出了一种演化网络架构搜索框架，具有自适应多模态融合，可以自动构建不同架构的多模态网络，并考虑了来自不同输入流的数据。"
}