{
    "title": "VoxGenesis: Unsupervised Discovery of Latent Speaker Manifold for Speech Synthesis",
    "abstract": "arXiv:2403.00529v1 Announce Type: cross  Abstract: Achieving nuanced and accurate emulation of human voice has been a longstanding goal in artificial intelligence. Although significant progress has been made in recent years, the mainstream of speech synthesis models still relies on supervised speaker modeling and explicit reference utterances. However, there are many aspects of human voice, such as emotion, intonation, and speaking style, for which it is hard to obtain accurate labels. In this paper, we propose VoxGenesis, a novel unsupervised speech synthesis framework that can discover a latent speaker manifold and meaningful voice editing directions without supervision. VoxGenesis is conceptually simple. Instead of mapping speech features to waveforms deterministically, VoxGenesis transforms a Gaussian distribution into speech distributions conditioned and aligned by semantic tokens. This forces the model to learn a speaker distribution disentangled from the semantic content. During",
    "link": "https://arxiv.org/abs/2403.00529",
    "context": "Title: VoxGenesis: Unsupervised Discovery of Latent Speaker Manifold for Speech Synthesis\nAbstract: arXiv:2403.00529v1 Announce Type: cross  Abstract: Achieving nuanced and accurate emulation of human voice has been a longstanding goal in artificial intelligence. Although significant progress has been made in recent years, the mainstream of speech synthesis models still relies on supervised speaker modeling and explicit reference utterances. However, there are many aspects of human voice, such as emotion, intonation, and speaking style, for which it is hard to obtain accurate labels. In this paper, we propose VoxGenesis, a novel unsupervised speech synthesis framework that can discover a latent speaker manifold and meaningful voice editing directions without supervision. VoxGenesis is conceptually simple. Instead of mapping speech features to waveforms deterministically, VoxGenesis transforms a Gaussian distribution into speech distributions conditioned and aligned by semantic tokens. This forces the model to learn a speaker distribution disentangled from the semantic content. During",
    "path": "papers/24/03/2403.00529.json",
    "total_tokens": 890,
    "translated_title": "VoxGenesis: 无监督发现潜在说话者流形用于语音合成",
    "translated_abstract": "arXiv:2403.00529v1 公告类型: 跨越 摘要: 在人工智能中，实现对人声的微妙和精准模拟一直是一个长期目标。尽管近年取得了重大进展，但当前主流的语音合成模型仍然依赖于监督式说话者建模和明确的参考语句。然而，人声有许多方面，例如情感、语调和说话风格，很难获得准确的标签。本文提出了 VoxGenesis，一种新颖的无监督语音合成框架，可以在没有监督的情况下发现潜在说话者流形和有意义的语音编辑方向。VoxGenesis 在概念上很简单。它不是将语音特征确定地映射到波形，而是将高斯分布转换为由语义标记条件和对准的语音分布。这迫使模型学习一个与语义内容解耦的说话者分布。",
    "tldr": "VoxGenesis是一个无监督语音合成框架，可以在没有监督的情况下发现潜在说话者流形和有意义的语音编辑方向，为解决情感、语调和说话风格等难以获取准确标签的人声特征提供了新方法。"
}