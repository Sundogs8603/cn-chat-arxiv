{
    "title": "SOTOPIA-$\\pi$: Interactive Learning of Socially Intelligent Language Agents",
    "abstract": "arXiv:2403.08715v1 Announce Type: new  Abstract: Humans learn social skills through both imitation and social interaction. This social learning process is largely understudied by existing research on building language agents. Motivated by this gap, we propose an interactive learning method, SOTOPIA-$\\pi$, improving the social intelligence of language agents. This method leverages behavior cloning and self-reinforcement training on filtered social interaction data according to large language model (LLM) ratings. We show that our training method allows a 7B LLM to reach the social goal completion ability of an expert model (GPT-4-based agent), while improving the safety of language agents and maintaining general QA ability on the MMLU benchmark. We also find that this training paradigm uncovers some difficulties in LLM-based evaluation of social intelligence: LLM-based evaluators overestimate the abilities of the language agents trained specifically for social interaction.",
    "link": "https://arxiv.org/abs/2403.08715",
    "context": "Title: SOTOPIA-$\\pi$: Interactive Learning of Socially Intelligent Language Agents\nAbstract: arXiv:2403.08715v1 Announce Type: new  Abstract: Humans learn social skills through both imitation and social interaction. This social learning process is largely understudied by existing research on building language agents. Motivated by this gap, we propose an interactive learning method, SOTOPIA-$\\pi$, improving the social intelligence of language agents. This method leverages behavior cloning and self-reinforcement training on filtered social interaction data according to large language model (LLM) ratings. We show that our training method allows a 7B LLM to reach the social goal completion ability of an expert model (GPT-4-based agent), while improving the safety of language agents and maintaining general QA ability on the MMLU benchmark. We also find that this training paradigm uncovers some difficulties in LLM-based evaluation of social intelligence: LLM-based evaluators overestimate the abilities of the language agents trained specifically for social interaction.",
    "path": "papers/24/03/2403.08715.json",
    "total_tokens": 891,
    "translated_title": "SOTOPIA-$\\pi$: 交互式学习社交智能语言代理",
    "translated_abstract": "人类通过模仿和社交互动来学习社交技能。现有研究在构建语言代理方面很少涉及这种社交学习过程。受到这一空白的启发，我们提出了一种交互式学习方法SOTOPIA-$\\pi$，改进了语言代理的社交智能。该方法利用行为克隆和自我强化训练，根据大型语言模型(LLM)评分对经过筛选的社交互动数据进行训练。我们证明了我们的训练方法使一个7B的LLM达到了专家模型(GPT-4-based agent)的社交目标完成能力，同时提高了语言代理的安全性，并在MMLU基准上保持了通用的问答能力。我们还发现，这种训练范式揭示了LLM评估社交智能的一些困难：基于LLM的评估者高估了专门针对社交互动训练的语言代理的能力。",
    "tldr": "提出了一种交互式学习方法SOTOPIA-$\\pi$，该方法利用行为克隆和自我强化训练，改进了语言代理的社交智能，使其达到了专家模型的水平，并提高了安全性。"
}