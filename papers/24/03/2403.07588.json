{
    "title": "Visual Privacy Auditing with Diffusion Models",
    "abstract": "arXiv:2403.07588v1 Announce Type: new  Abstract: Image reconstruction attacks on machine learning models pose a significant risk to privacy by potentially leaking sensitive information. Although defending against such attacks using differential privacy (DP) has proven effective, determining appropriate DP parameters remains challenging. Current formal guarantees on data reconstruction success suffer from overly theoretical assumptions regarding adversary knowledge about the target data, particularly in the image domain. In this work, we empirically investigate this discrepancy and find that the practicality of these assumptions strongly depends on the domain shift between the data prior and the reconstruction target. We propose a reconstruction attack based on diffusion models (DMs) that assumes adversary access to real-world image priors and assess its implications on privacy leakage under DP-SGD. We show that (1) real-world data priors significantly influence reconstruction success, ",
    "link": "https://arxiv.org/abs/2403.07588",
    "context": "Title: Visual Privacy Auditing with Diffusion Models\nAbstract: arXiv:2403.07588v1 Announce Type: new  Abstract: Image reconstruction attacks on machine learning models pose a significant risk to privacy by potentially leaking sensitive information. Although defending against such attacks using differential privacy (DP) has proven effective, determining appropriate DP parameters remains challenging. Current formal guarantees on data reconstruction success suffer from overly theoretical assumptions regarding adversary knowledge about the target data, particularly in the image domain. In this work, we empirically investigate this discrepancy and find that the practicality of these assumptions strongly depends on the domain shift between the data prior and the reconstruction target. We propose a reconstruction attack based on diffusion models (DMs) that assumes adversary access to real-world image priors and assess its implications on privacy leakage under DP-SGD. We show that (1) real-world data priors significantly influence reconstruction success, ",
    "path": "papers/24/03/2403.07588.json",
    "total_tokens": 842,
    "translated_title": "基于扩散模型的视觉隐私审计",
    "translated_abstract": "arXiv:2403.07588v1 声明类型: 新的 摘要: 对机器学习模型的图像重建攻击可能会导致泄露敏感信息，从而对隐私构成重大风险。虽然使用差分隐私(DP)来抵御此类攻击已被证明是有效的，但确定适当的DP参数仍然具有挑战性。当前对数据重建成功的形式化保证受到了关于对手对目标数据的了解的过于理论化的假设的影响，特别是在图像领域。在这项工作中，我们通过实证调查这一差异，并发现这些假设的实际性在很大程度上取决于数据先验和重建目标之间的域转移。我们提出了一种基于扩散模型(DMs)的重建攻击，假设对手可以访问真实世界的图像先验，并评估其对在DP-SGD下的隐私泄露的影响。我们展示了(1)真实世界的数据先验显著影响重建成功，",
    "tldr": "在这项研究中，通过使用扩散模型进行重建攻击，作者发现在DP-SGD下，真实世界的数据先验对于重建成功具有显著影响。",
    "en_tdlr": "The authors found that real-world data priors significantly influence reconstruction success under DP-SGD by using diffusion models for reconstruction attacks."
}