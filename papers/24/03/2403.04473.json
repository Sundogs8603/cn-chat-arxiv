{
    "title": "TextMonkey: An OCR-Free Large Multimodal Model for Understanding Document",
    "abstract": "arXiv:2403.04473v1 Announce Type: cross  Abstract: We present TextMonkey, a large multimodal model (LMM) tailored for text-centric tasks, including document question answering (DocVQA) and scene text analysis. Our approach introduces enhancement across several dimensions: by adopting Shifted Window Attention with zero-initialization, we achieve cross-window connectivity at higher input resolutions and stabilize early training; We hypothesize that images may contain redundant tokens, and by using similarity to filter out significant tokens, we can not only streamline the token length but also enhance the model's performance. Moreover, by expanding our model's capabilities to encompass text spotting and grounding, and incorporating positional information into responses, we enhance interpretability and minimize hallucinations. Additionally, TextMonkey can be finetuned to gain the ability to comprehend commands for clicking screenshots. Overall, our method notably boosts performance across",
    "link": "https://arxiv.org/abs/2403.04473",
    "context": "Title: TextMonkey: An OCR-Free Large Multimodal Model for Understanding Document\nAbstract: arXiv:2403.04473v1 Announce Type: cross  Abstract: We present TextMonkey, a large multimodal model (LMM) tailored for text-centric tasks, including document question answering (DocVQA) and scene text analysis. Our approach introduces enhancement across several dimensions: by adopting Shifted Window Attention with zero-initialization, we achieve cross-window connectivity at higher input resolutions and stabilize early training; We hypothesize that images may contain redundant tokens, and by using similarity to filter out significant tokens, we can not only streamline the token length but also enhance the model's performance. Moreover, by expanding our model's capabilities to encompass text spotting and grounding, and incorporating positional information into responses, we enhance interpretability and minimize hallucinations. Additionally, TextMonkey can be finetuned to gain the ability to comprehend commands for clicking screenshots. Overall, our method notably boosts performance across",
    "path": "papers/24/03/2403.04473.json",
    "total_tokens": 829,
    "translated_title": "TextMonkey：一种无需OCR的大型多模态模型，用于理解文档",
    "translated_abstract": "我们提出了TextMonkey，一个专为文本中心任务定制的大型多模态模型（LMM），包括文档问答（DocVQA）和场景文本分析。我们的方法在多个方面进行了改进：通过采用零初始化的Shifted Window Attention，我们实现了更高输入分辨率的跨窗口连接并稳定了早期训练；我们假设图像可能包含冗余标记，通过使用相似性来筛选出重要标记，我们不仅可以优化标记长度，还可以提升模型性能。此外，通过扩展我们模型的能力以涵盖文本定位和定位，并将位置信息纳入响应中，我们提高了可解释性并减少了幻觉。此外，TextMonkey 可以微调以获得理解点击截图命令的能力。总体来看，我们的方法显著提高了性能。",
    "tldr": "该论文提出了一种针对文本中心任务的大型多模态模型，通过引入零初始化的Shifted Window Attention、相似性筛选标记等方式对模型进行增强，同时拓展了模型的能力以提高性能。",
    "en_tdlr": "This paper introduces a large multimodal model tailored for text-centric tasks, with enhancements such as zero-initialization Shifted Window Attention and token filtering based on similarity, as well as expanded capabilities for improved performance."
}