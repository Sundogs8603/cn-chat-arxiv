{
    "title": "MMIDR: Teaching Large Language Model to Interpret Multimodal Misinformation via Knowledge Distillation",
    "abstract": "arXiv:2403.14171v1 Announce Type: new  Abstract: Automatic detection of multimodal misinformation has gained a widespread attention recently. However, the potential of powerful Large Language Models (LLMs) for multimodal misinformation detection remains underexplored. Besides, how to teach LLMs to interpret multimodal misinformation in cost-effective and accessible way is still an open question. To address that, we propose MMIDR, a framework designed to teach LLMs in providing fluent and high-quality textual explanations for their decision-making process of multimodal misinformation. To convert multimodal misinformation into an appropriate instruction-following format, we present a data augmentation perspective and pipeline. This pipeline consists of a visual information processing module and an evidence retrieval module. Subsequently, we prompt the proprietary LLMs with processed contents to extract rationales for interpreting the authenticity of multimodal misinformation. Furthermore",
    "link": "https://arxiv.org/abs/2403.14171",
    "context": "Title: MMIDR: Teaching Large Language Model to Interpret Multimodal Misinformation via Knowledge Distillation\nAbstract: arXiv:2403.14171v1 Announce Type: new  Abstract: Automatic detection of multimodal misinformation has gained a widespread attention recently. However, the potential of powerful Large Language Models (LLMs) for multimodal misinformation detection remains underexplored. Besides, how to teach LLMs to interpret multimodal misinformation in cost-effective and accessible way is still an open question. To address that, we propose MMIDR, a framework designed to teach LLMs in providing fluent and high-quality textual explanations for their decision-making process of multimodal misinformation. To convert multimodal misinformation into an appropriate instruction-following format, we present a data augmentation perspective and pipeline. This pipeline consists of a visual information processing module and an evidence retrieval module. Subsequently, we prompt the proprietary LLMs with processed contents to extract rationales for interpreting the authenticity of multimodal misinformation. Furthermore",
    "path": "papers/24/03/2403.14171.json",
    "total_tokens": 819,
    "translated_title": "通过知识蒸馏教授大型语言模型解释多模态虚假信息",
    "translated_abstract": "最近，多模态虚假信息的自动检测引起了广泛关注。然而，强大的大型语言模型（LLMs）在多模态虚假信息检测方面的潜力仍未得到充分发掘。此外，如何以成本效益和易于访问的方式教导LLMs解释多模态虚假信息仍然是一个悬而未决的问题。为了解决这个问题，我们提出了MMIDR，这是一个旨在教导LLMs为其多模态虚假信息决策过程提供流畅和高质量文本解释的框架。为了将多模态虚假信息转化为适当的指令执行格式，我们提出了一个数据增强视角和管道。该管道包括一个视觉信息处理模块和一个证据检索模块。随后，我们使用处理过的内容提示专有的LLMs为解释多模态虚假信息的真实性提取原因。",
    "tldr": "提出了MMIDR框架，用于教导大型语言模型提供解释其多模态虚假信息决策过程的文本解释。",
    "en_tdlr": "Introduced MMIDR framework to teach large language models in providing textual explanations for their decision-making process of multimodal misinformation."
}