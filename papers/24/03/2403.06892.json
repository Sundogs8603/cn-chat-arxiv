{
    "title": "Real-time Transformer-based Open-Vocabulary Detection with Efficient Fusion Head",
    "abstract": "arXiv:2403.06892v1 Announce Type: cross  Abstract: End-to-end transformer-based detectors (DETRs) have shown exceptional performance in both closed-set and open-vocabulary object detection (OVD) tasks through the integration of language modalities. However, their demanding computational requirements have hindered their practical application in real-time object detection (OD) scenarios. In this paper, we scrutinize the limitations of two leading models in the OVDEval benchmark, OmDet and Grounding-DINO, and introduce OmDet-Turbo. This novel transformer-based real-time OVD model features an innovative Efficient Fusion Head (EFH) module designed to alleviate the bottlenecks observed in OmDet and Grounding-DINO. Notably, OmDet-Turbo-Base achieves a 100.2 frames per second (FPS) with TensorRT and language cache techniques applied. Notably, in zero-shot scenarios on COCO and LVIS datasets, OmDet-Turbo achieves performance levels nearly on par with current state-of-the-art supervised models. ",
    "link": "https://arxiv.org/abs/2403.06892",
    "context": "Title: Real-time Transformer-based Open-Vocabulary Detection with Efficient Fusion Head\nAbstract: arXiv:2403.06892v1 Announce Type: cross  Abstract: End-to-end transformer-based detectors (DETRs) have shown exceptional performance in both closed-set and open-vocabulary object detection (OVD) tasks through the integration of language modalities. However, their demanding computational requirements have hindered their practical application in real-time object detection (OD) scenarios. In this paper, we scrutinize the limitations of two leading models in the OVDEval benchmark, OmDet and Grounding-DINO, and introduce OmDet-Turbo. This novel transformer-based real-time OVD model features an innovative Efficient Fusion Head (EFH) module designed to alleviate the bottlenecks observed in OmDet and Grounding-DINO. Notably, OmDet-Turbo-Base achieves a 100.2 frames per second (FPS) with TensorRT and language cache techniques applied. Notably, in zero-shot scenarios on COCO and LVIS datasets, OmDet-Turbo achieves performance levels nearly on par with current state-of-the-art supervised models. ",
    "path": "papers/24/03/2403.06892.json",
    "total_tokens": 901,
    "translated_title": "基于实时变压器的高效融合头开词汇检测",
    "translated_abstract": "基于端到端变压器的检测器（DETRs）通过整合语言模态，在封闭集和开词汇目标检测（OVD）任务中表现出色，但其高要求的计算需求阻碍了它们在实时目标检测（OD）场景中的实际应用。本文审查了OVDEval基准测试中两个领先模型OmDet和Grounding-DINO的限制，并引入了OmDet-Turbo。这种新颖的基于变压器的实时OVD模型具有创新的高效融合头（EFH）模块，旨在缓解OmDet和Grounding-DINO中观察到的瓶颈。值得注意的是，OmDet-Turbo-Base在应用TensorRT和语言缓存技术后实现了100.2帧每秒（FPS）。值得注意的是，在COCO和LVIS数据集的零样本场景中，OmDet-Turbo的性能几乎与当前最先进的监督模型持平。",
    "tldr": "本文提出了一种新颖的基于实时变压器的开词汇检测模型OmDet-Turbo，具有高效融合头模块，在实验中取得了与最先进监督模型几乎持平的性能水平。",
    "en_tdlr": "This paper introduces a novel real-time Transformer-based open-vocabulary detection model OmDet-Turbo with an efficient fusion head module, achieving performance levels nearly on par with current state-of-the-art supervised models in experiments."
}