{
    "title": "From Instructions to Constraints: Language Model Alignment with Automatic Constraint Verification",
    "abstract": "arXiv:2403.06326v1 Announce Type: cross  Abstract: User alignment is crucial for adapting general-purpose language models (LMs) to downstream tasks, but human annotations are often not available for all types of instructions, especially those with customized constraints. We observe that user instructions typically contain constraints. While assessing response quality in terms of the whole instruction is often costly, efficiently evaluating the satisfaction rate of constraints is feasible. We investigate common constraints in NLP tasks, categorize them into three classes based on the types of their arguments, and propose a unified framework, ACT (Aligning to ConsTraints), to automatically produce supervision signals for user alignment with constraints. Specifically, ACT uses constraint verifiers, which are typically easy to implement in practice, to compute constraint satisfaction rate (CSR) of each response. It samples multiple responses for each prompt and collect preference labels ba",
    "link": "https://arxiv.org/abs/2403.06326",
    "context": "Title: From Instructions to Constraints: Language Model Alignment with Automatic Constraint Verification\nAbstract: arXiv:2403.06326v1 Announce Type: cross  Abstract: User alignment is crucial for adapting general-purpose language models (LMs) to downstream tasks, but human annotations are often not available for all types of instructions, especially those with customized constraints. We observe that user instructions typically contain constraints. While assessing response quality in terms of the whole instruction is often costly, efficiently evaluating the satisfaction rate of constraints is feasible. We investigate common constraints in NLP tasks, categorize them into three classes based on the types of their arguments, and propose a unified framework, ACT (Aligning to ConsTraints), to automatically produce supervision signals for user alignment with constraints. Specifically, ACT uses constraint verifiers, which are typically easy to implement in practice, to compute constraint satisfaction rate (CSR) of each response. It samples multiple responses for each prompt and collect preference labels ba",
    "path": "papers/24/03/2403.06326.json",
    "total_tokens": 790,
    "translated_title": "从指令到约束：语言模型对齐与自动约束验证",
    "translated_abstract": "用户对齐对于将通用语言模型（LMs）调整为下游任务至关重要，但通常无法为所有类型的指令提供人类注释，特别是具有定制约束的指令。我们观察到用户指令通常包含约束条件。虽然评估整个指令的响应质量通常成本高昂，但高效地评估约束条件的满意率是可行的。我们研究了NLP任务中的常见约束条件，将它们基于其参数类型分类为三类，并提出了一个统一框架，ACT（Aligning to ConsTraints），用于自动为带约束用户对齐生成监督信号。具体而言，ACT使用约束验证器，这些验证器在实践中通常易于实现，来计算每个响应的约束满意率（CSR）。它为每个提示取样多个响应并收集偏好标签。",
    "tldr": "提出了ACT框架，通过约束验证器自动计算每个响应的约束满意率，实现语言模型对齐与自动约束验证。",
    "en_tdlr": "Introduced the ACT framework to automatically compute the constraint satisfaction rate of each response using constraint verifiers, achieving language model alignment with automatic constraint verification."
}