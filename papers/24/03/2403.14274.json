{
    "title": "Multi-role Consensus through LLMs Discussions for Vulnerability Detection",
    "abstract": "arXiv:2403.14274v1 Announce Type: cross  Abstract: Recent advancements in large language models (LLMs) have highlighted the potential for vulnerability detection, a crucial component of software quality assurance. Despite this progress, most studies have been limited to the perspective of a single role, usually testers, lacking diverse viewpoints from different roles in a typical software development life-cycle, including both developers and testers. To this end, this paper introduces an approach to employ LLMs to act as different roles to simulate real-life code review process, engaging in discussions towards a consensus on the existence and classification of vulnerabilities in the code. Preliminary evaluation of the proposed approach indicates a 4.73% increase in the precision rate, 58.9% increase in the recall rate, and a 28.1% increase in the F1 score.",
    "link": "https://arxiv.org/abs/2403.14274",
    "context": "Title: Multi-role Consensus through LLMs Discussions for Vulnerability Detection\nAbstract: arXiv:2403.14274v1 Announce Type: cross  Abstract: Recent advancements in large language models (LLMs) have highlighted the potential for vulnerability detection, a crucial component of software quality assurance. Despite this progress, most studies have been limited to the perspective of a single role, usually testers, lacking diverse viewpoints from different roles in a typical software development life-cycle, including both developers and testers. To this end, this paper introduces an approach to employ LLMs to act as different roles to simulate real-life code review process, engaging in discussions towards a consensus on the existence and classification of vulnerabilities in the code. Preliminary evaluation of the proposed approach indicates a 4.73% increase in the precision rate, 58.9% increase in the recall rate, and a 28.1% increase in the F1 score.",
    "path": "papers/24/03/2403.14274.json",
    "total_tokens": 795,
    "translated_title": "通过LLMs讨论实现漏洞检测的多角共识",
    "translated_abstract": "最近大型语言模型（LLMs）的发展突显了漏洞检测的潜力，这是软件质量保证的关键组成部分。然而，大多数研究仅限于单一角色的视角，通常是测试人员，缺乏典型软件开发生命周期中不同角色的多元观点，包括开发人员和测试人员。为此，本文介绍了一种利用LLMs扮演不同角色的方法，模拟现实代码审查过程，进行讨论以达成关于代码中漏洞存在和分类的共识。所提出方法的初步评估显示，精确率增加了4.73％，召回率增加了58.9％，F1分数增加了28.1％。",
    "tldr": "本论文提出了一种利用LLMs模拟不同角色进行讨论，以达成对代码中漏洞存在和分类的共识的方法，并在初步评估中实现了精确率、召回率和F1分数的明显提升。",
    "en_tdlr": "This paper introduces an approach to employ LLMs to simulate different roles in discussions towards a consensus on the existence and classification of vulnerabilities in the code, with preliminary evaluation showing significant improvements in precision rate, recall rate, and F1 score."
}