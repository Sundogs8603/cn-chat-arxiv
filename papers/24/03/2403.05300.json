{
    "title": "Unity by Diversity: Improved Representation Learning in Multimodal VAEs",
    "abstract": "arXiv:2403.05300v1 Announce Type: cross  Abstract: Variational Autoencoders for multimodal data hold promise for many tasks in data analysis, such as representation learning, conditional generation, and imputation. Current architectures either share the encoder output, decoder input, or both across modalities to learn a shared representation. Such architectures impose hard constraints on the model. In this work, we show that a better latent representation can be obtained by replacing these hard constraints with a soft constraint. We propose a new mixture-of-experts prior, softly guiding each modality's latent representation towards a shared aggregate posterior. This approach results in a superior latent representation and allows each encoding to preserve information from its uncompressed original features better. In extensive experiments on multiple benchmark datasets and a challenging real-world neuroscience data set, we show improved learned latent representations and imputation of m",
    "link": "https://arxiv.org/abs/2403.05300",
    "context": "Title: Unity by Diversity: Improved Representation Learning in Multimodal VAEs\nAbstract: arXiv:2403.05300v1 Announce Type: cross  Abstract: Variational Autoencoders for multimodal data hold promise for many tasks in data analysis, such as representation learning, conditional generation, and imputation. Current architectures either share the encoder output, decoder input, or both across modalities to learn a shared representation. Such architectures impose hard constraints on the model. In this work, we show that a better latent representation can be obtained by replacing these hard constraints with a soft constraint. We propose a new mixture-of-experts prior, softly guiding each modality's latent representation towards a shared aggregate posterior. This approach results in a superior latent representation and allows each encoding to preserve information from its uncompressed original features better. In extensive experiments on multiple benchmark datasets and a challenging real-world neuroscience data set, we show improved learned latent representations and imputation of m",
    "path": "papers/24/03/2403.05300.json",
    "total_tokens": 797,
    "translated_title": "多模态VAEs中的统一多样性：改进的表示学习",
    "translated_abstract": "多模态数据的变分自编码器在数据分析的许多任务中表现出潜力，如表示学习、有条件生成和填补。目前的架构要么跨模态共享编码器输出、解码器输入，要么两者都要学习共享表示。这样的架构对模型施加了严格约束。在这项工作中，我们展示了通过用软约束取代这些硬约束可以获得更好的潜在表示。我们提出了一种新的专家混合先验，软性地引导每个模态的潜在表示朝着共享的后验。这种方法导致了优秀的潜在表示，并允许每个编码保留来自其未压缩原始特征更好的信息。通过对多个基准数据集和一个具有挑战性的现实世界神经科学数据集进行的广泛实验，我们展示了改进的学习潜在表示和填补。",
    "tldr": "通过软约束取代硬约束，提出了一种新的专家混合先验，改善了多模态VAEs中的表示学习。",
    "en_tdlr": "Proposed a new mixture-of-experts prior by replacing hard constraints with soft constraints, improving representation learning in multimodal VAEs."
}