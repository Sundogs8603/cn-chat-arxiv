{
    "title": "PathoTune: Adapting Visual Foundation Model to Pathological Specialists",
    "abstract": "arXiv:2403.16497v1 Announce Type: cross  Abstract: As natural image understanding moves towards the pretrain-finetune era, research in pathology imaging is concurrently evolving. Despite the predominant focus on pretraining pathological foundation models, how to adapt foundation models to downstream tasks is little explored. For downstream adaptation, we propose the existence of two domain gaps, i.e., the Foundation-Task Gap and the Task-Instance Gap. To mitigate these gaps, we introduce PathoTune, a framework designed to efficiently adapt pathological or even visual foundation models to pathology-specific tasks via multi-modal prompt tuning. The proposed framework leverages Task-specific Visual Prompts and Task-specific Textual Prompts to identify task-relevant features, along with Instance-specific Visual Prompts for encoding single pathological image features. Results across multiple datasets at both patch-level and WSI-level demonstrate its superior performance over single-modality",
    "link": "https://arxiv.org/abs/2403.16497",
    "context": "Title: PathoTune: Adapting Visual Foundation Model to Pathological Specialists\nAbstract: arXiv:2403.16497v1 Announce Type: cross  Abstract: As natural image understanding moves towards the pretrain-finetune era, research in pathology imaging is concurrently evolving. Despite the predominant focus on pretraining pathological foundation models, how to adapt foundation models to downstream tasks is little explored. For downstream adaptation, we propose the existence of two domain gaps, i.e., the Foundation-Task Gap and the Task-Instance Gap. To mitigate these gaps, we introduce PathoTune, a framework designed to efficiently adapt pathological or even visual foundation models to pathology-specific tasks via multi-modal prompt tuning. The proposed framework leverages Task-specific Visual Prompts and Task-specific Textual Prompts to identify task-relevant features, along with Instance-specific Visual Prompts for encoding single pathological image features. Results across multiple datasets at both patch-level and WSI-level demonstrate its superior performance over single-modality",
    "path": "papers/24/03/2403.16497.json",
    "total_tokens": 870,
    "translated_title": "PathoTune: 将视觉基础模型调整至病理专家",
    "translated_abstract": "在自然图像理解走向预训练微调的时代的同时，病理影像的研究也在不断发展。尽管主要关注预训练病理基础模型，但如何将基础模型调整到下游任务中却鲜有研究。为了下游调整，我们提出存在两个域差距，即基础-任务差距和任务-实例差距。为了缓解这些差距，我们引入了 PathoTune，这是一个旨在通过多模态提示微调，高效地将病理甚至视觉基础模型调整到病理特定任务的框架。所提出的框架利用任务特定的视觉提示和任务特定的文本提示来识别任务相关特征，以及实例特定的视觉提示来编码单个病理图像特征。在多个数据集上以补丁级别和WSI级别的结果表明，其性能优于单模态。",
    "tldr": "PathoTune提出了一个框架，能够通过多模态提示微调，将病理甚至视觉基础模型高效地调整到病理特定任务，从而缓解基础-任务差距和任务-实例差距。",
    "en_tdlr": "PathoTune proposes a framework that efficiently adapts pathological or visual foundation models to pathology-specific tasks via multi-modal prompt tuning, mitigating the Foundation-Task Gap and the Task-Instance Gap."
}