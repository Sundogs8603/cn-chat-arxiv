{
    "title": "Isotropic3D: Image-to-3D Generation Based on a Single CLIP Embedding",
    "abstract": "arXiv:2403.10395v1 Announce Type: cross  Abstract: Encouraged by the growing availability of pre-trained 2D diffusion models, image-to-3D generation by leveraging Score Distillation Sampling (SDS) is making remarkable progress. Most existing methods combine novel-view lifting from 2D diffusion models which usually take the reference image as a condition while applying hard L2 image supervision at the reference view. Yet heavily adhering to the image is prone to corrupting the inductive knowledge of the 2D diffusion model leading to flat or distorted 3D generation frequently. In this work, we reexamine image-to-3D in a novel perspective and present Isotropic3D, an image-to-3D generation pipeline that takes only an image CLIP embedding as input. Isotropic3D allows the optimization to be isotropic w.r.t. the azimuth angle by solely resting on the SDS loss. The core of our framework lies in a two-stage diffusion model fine-tuning. Firstly, we fine-tune a text-to-3D diffusion model by subst",
    "link": "https://arxiv.org/abs/2403.10395",
    "context": "Title: Isotropic3D: Image-to-3D Generation Based on a Single CLIP Embedding\nAbstract: arXiv:2403.10395v1 Announce Type: cross  Abstract: Encouraged by the growing availability of pre-trained 2D diffusion models, image-to-3D generation by leveraging Score Distillation Sampling (SDS) is making remarkable progress. Most existing methods combine novel-view lifting from 2D diffusion models which usually take the reference image as a condition while applying hard L2 image supervision at the reference view. Yet heavily adhering to the image is prone to corrupting the inductive knowledge of the 2D diffusion model leading to flat or distorted 3D generation frequently. In this work, we reexamine image-to-3D in a novel perspective and present Isotropic3D, an image-to-3D generation pipeline that takes only an image CLIP embedding as input. Isotropic3D allows the optimization to be isotropic w.r.t. the azimuth angle by solely resting on the SDS loss. The core of our framework lies in a two-stage diffusion model fine-tuning. Firstly, we fine-tune a text-to-3D diffusion model by subst",
    "path": "papers/24/03/2403.10395.json",
    "total_tokens": 943,
    "translated_title": "Isotropic3D：基于单个CLIP嵌入的图像到3D生成",
    "translated_abstract": "鼓舞于越来越多预训练的2D扩散模型的可用性，通过利用分数蒸馏采样（SDS）进行图像到3D生成正在取得显著进展。大多数现有方法将新视角提升到2D扩散模型，通常以参考图像作为条件，同时在参考视图上应用严格的L2图像监督。然而过分依赖图像容易破坏2D扩散模型的归纳知识，经常导致生成平坦或扭曲的3D。在这项工作中，我们以一种新颖的角度重新审视图像到3D，并呈现Isotropic3D，一个仅以图像CLIP嵌入作为输入的图像到3D生成流水线。Isotropic3D允许优化相对于方位角是各向同性，因为仅依赖于SDS损失。我们框架的核心在于两阶段扩散模型微调。首先，我们通过替换 fine-tune了一个文本到3D扩散模型",
    "tldr": "Isotropic3D是一个图像到3D生成的新方法，通过仅使用图像CLIP嵌入作为输入，让优化相对于方位角是各向同性，避免过分依赖图像导致生成的扁平或扭曲。"
}