{
    "title": "M2DA: Multi-Modal Fusion Transformer Incorporating Driver Attention for Autonomous Driving",
    "abstract": "arXiv:2403.12552v1 Announce Type: cross  Abstract: End-to-end autonomous driving has witnessed remarkable progress. However, the extensive deployment of autonomous vehicles has yet to be realized, primarily due to 1) inefficient multi-modal environment perception: how to integrate data from multi-modal sensors more efficiently; 2) non-human-like scene understanding: how to effectively locate and predict critical risky agents in traffic scenarios like an experienced driver. To overcome these challenges, in this paper, we propose a Multi-Modal fusion transformer incorporating Driver Attention (M2DA) for autonomous driving. To better fuse multi-modal data and achieve higher alignment between different modalities, a novel Lidar-Vision-Attention-based Fusion (LVAFusion) module is proposed. By incorporating driver attention, we empower the human-like scene understanding ability to autonomous vehicles to identify crucial areas within complex scenarios precisely and ensure safety. We conduct e",
    "link": "https://arxiv.org/abs/2403.12552",
    "context": "Title: M2DA: Multi-Modal Fusion Transformer Incorporating Driver Attention for Autonomous Driving\nAbstract: arXiv:2403.12552v1 Announce Type: cross  Abstract: End-to-end autonomous driving has witnessed remarkable progress. However, the extensive deployment of autonomous vehicles has yet to be realized, primarily due to 1) inefficient multi-modal environment perception: how to integrate data from multi-modal sensors more efficiently; 2) non-human-like scene understanding: how to effectively locate and predict critical risky agents in traffic scenarios like an experienced driver. To overcome these challenges, in this paper, we propose a Multi-Modal fusion transformer incorporating Driver Attention (M2DA) for autonomous driving. To better fuse multi-modal data and achieve higher alignment between different modalities, a novel Lidar-Vision-Attention-based Fusion (LVAFusion) module is proposed. By incorporating driver attention, we empower the human-like scene understanding ability to autonomous vehicles to identify crucial areas within complex scenarios precisely and ensure safety. We conduct e",
    "path": "papers/24/03/2403.12552.json",
    "total_tokens": 899,
    "translated_title": "M2DA: 融合驾驶员注意力的多模态融合变压器用于自动驾驶",
    "translated_abstract": "自动驾驶的端到端模式取得了显著进展。然而，由于1) 多模态环境感知低效：如何更有效地集成来自多模态传感器的数据；2) 非人类般的场景理解：如何有效地在交通场景中定位和预测关键的风险代理人，像有经验的驾驶员。为了克服这些挑战，在本文中，我们提出了一种融合驾驶员注意力的多模态融合变压器 (M2DA) 用于自动驾驶。为了更好地融合多模态数据并实现不同模态之间更高的对齐性，我们提出了一种基于激光雷达-视觉-注意力融合 (LVAFusion) 模块。通过引入驾驶员注意力，我们赋予了自动驾驶汽车类似人类的场景理解能力，能够精确识别复杂场景中的关键区域，并确保安全。",
    "tldr": "提出了一种融合驾驶员注意力的多模态融合变压器(M2DA)用于自动驾驶，通过引入LVAFusion模块和驾驶员注意力，实现了更高的数据融合效率和人类化的场景理解能力。",
    "en_tdlr": "Proposed a multi-modal fusion transformer (M2DA) incorporating driver attention for autonomous driving, achieving higher data fusion efficiency and human-like scene understanding ability by introducing LVAFusion module and driver attention."
}