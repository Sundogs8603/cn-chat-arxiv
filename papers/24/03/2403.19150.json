{
    "title": "Towards Understanding Dual BN In Hybrid Adversarial Training",
    "abstract": "arXiv:2403.19150v1 Announce Type: cross  Abstract: There is a growing concern about applying batch normalization (BN) in adversarial training (AT), especially when the model is trained on both adversarial samples and clean samples (termed Hybrid-AT). With the assumption that adversarial and clean samples are from two different domains, a common practice in prior works is to adopt Dual BN, where BN and BN are used for adversarial and clean branches, respectively. A popular belief for motivating Dual BN is that estimating normalization statistics of this mixture distribution is challenging and thus disentangling it for normalization achieves stronger robustness. In contrast to this belief, we reveal that disentangling statistics plays a less role than disentangling affine parameters in model training. This finding aligns with prior work (Rebuffi et al., 2023), and we build upon their research for further investigations. We demonstrate that the domain gap between adversarial and clean sam",
    "link": "https://arxiv.org/abs/2403.19150",
    "context": "Title: Towards Understanding Dual BN In Hybrid Adversarial Training\nAbstract: arXiv:2403.19150v1 Announce Type: cross  Abstract: There is a growing concern about applying batch normalization (BN) in adversarial training (AT), especially when the model is trained on both adversarial samples and clean samples (termed Hybrid-AT). With the assumption that adversarial and clean samples are from two different domains, a common practice in prior works is to adopt Dual BN, where BN and BN are used for adversarial and clean branches, respectively. A popular belief for motivating Dual BN is that estimating normalization statistics of this mixture distribution is challenging and thus disentangling it for normalization achieves stronger robustness. In contrast to this belief, we reveal that disentangling statistics plays a less role than disentangling affine parameters in model training. This finding aligns with prior work (Rebuffi et al., 2023), and we build upon their research for further investigations. We demonstrate that the domain gap between adversarial and clean sam",
    "path": "papers/24/03/2403.19150.json",
    "total_tokens": 850,
    "translated_title": "探索混合对抗训练中的双重批量归一化模型",
    "translated_abstract": "有关在对抗训练（AT）中应用批量归一化（BN）的关注日益增长，尤其是当模型同时在对抗样本和干净样本上进行训练（称为混合-AT）时。一个先前研究常见的做法是假设对抗样本和干净样本来自两个不同的领域，采用双重BN，分别用于对抗分支和干净分支。激励双重BN的一种流行观念是，估计这种混合分布的规范化统计数据是具有挑战性的，因此为规范化而将其分开可以实现更强的鲁棒性。与这一观念相反，我们发现，在模型训练中，分离统计数据的作用比分离仿射参数的作用较小。这一发现与先前的研究（Rebuffi等人，2023）一致，我们在其研究的基础上进行进一步的探讨。",
    "tldr": "在混合对抗训练中，分离仿射参数比分离统计数据在模型训练中发挥更重要的作用。",
    "en_tdlr": "Separating affine parameters plays a more important role than separating statistical data in model training within Hybrid Adversarial Training."
}