{
    "title": "Accelerating Federated Learning by Selecting Beneficial Herd of Local Gradients",
    "abstract": "arXiv:2403.16557v1 Announce Type: new  Abstract: Federated Learning (FL) is a distributed machine learning framework in communication network systems. However, the systems' Non-Independent and Identically Distributed (Non-IID) data negatively affect the convergence efficiency of the global model, since only a subset of these data samples are beneficial for model convergence. In pursuit of this subset, a reliable approach involves determining a measure of validity to rank the samples within the dataset. In this paper, We propose the BHerd strategy which selects a beneficial herd of local gradients to accelerate the convergence of the FL model. Specifically, we map the distribution of the local dataset to the local gradients and use the Herding strategy to obtain a permutation of the set of gradients, where the more advanced gradients in the permutation are closer to the average of the set of gradients. These top portion of the gradients will be selected and sent to the server for global",
    "link": "https://arxiv.org/abs/2403.16557",
    "context": "Title: Accelerating Federated Learning by Selecting Beneficial Herd of Local Gradients\nAbstract: arXiv:2403.16557v1 Announce Type: new  Abstract: Federated Learning (FL) is a distributed machine learning framework in communication network systems. However, the systems' Non-Independent and Identically Distributed (Non-IID) data negatively affect the convergence efficiency of the global model, since only a subset of these data samples are beneficial for model convergence. In pursuit of this subset, a reliable approach involves determining a measure of validity to rank the samples within the dataset. In this paper, We propose the BHerd strategy which selects a beneficial herd of local gradients to accelerate the convergence of the FL model. Specifically, we map the distribution of the local dataset to the local gradients and use the Herding strategy to obtain a permutation of the set of gradients, where the more advanced gradients in the permutation are closer to the average of the set of gradients. These top portion of the gradients will be selected and sent to the server for global",
    "path": "papers/24/03/2403.16557.json",
    "total_tokens": 800,
    "translated_title": "通过选择有益的局部梯度加速联邦学习",
    "translated_abstract": "联邦学习（FL）是一种在通信网络系统中进行分布式机器学习的框架。然而，系统中的非独立同分布（Non-IID）数据对全局模型的收敛效率产生负面影响，因为只有这些数据样本的一个子集对模型收敛是有益的。为了寻找这个子集，一种可靠的方法是确定一个度量的有效性来对数据集中的样本进行排序。在本文中，我们提出了BHerd策略，该策略选择有益的局部梯度来加速FL模型的收敛。具体地，我们将局部数据集的分布映射到局部梯度上，并使用探羊策略获取梯度集合的排列，排列中较为先进的梯度靠近梯度集合的平均值。这些排在前面的梯度将被选中发送到服务器进行全局更新。",
    "tldr": "提出了BHerd策略，通过选择有益的局部梯度加速联邦学习模型的收敛效率",
    "en_tdlr": "Introduced the BHerd strategy to accelerate the convergence efficiency of federated learning models by selecting beneficial local gradients."
}