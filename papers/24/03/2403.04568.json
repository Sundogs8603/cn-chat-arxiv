{
    "title": "Improved Algorithm for Adversarial Linear Mixture MDPs with Bandit Feedback and Unknown Transition",
    "abstract": "arXiv:2403.04568v1 Announce Type: new  Abstract: We study reinforcement learning with linear function approximation, unknown transition, and adversarial losses in the bandit feedback setting. Specifically, we focus on linear mixture MDPs whose transition kernel is a linear mixture model. We propose a new algorithm that attains an $\\widetilde{O}(d\\sqrt{HS^3K} + \\sqrt{HSAK})$ regret with high probability, where $d$ is the dimension of feature mappings, $S$ is the size of state space, $A$ is the size of action space, $H$ is the episode length and $K$ is the number of episodes. Our result strictly improves the previous best-known $\\widetilde{O}(dS^2 \\sqrt{K} + \\sqrt{HSAK})$ result in Zhao et al. (2023a) since $H \\leq S$ holds by the layered MDP structure. Our advancements are primarily attributed to (i) a new least square estimator for the transition parameter that leverages the visit information of all states, as opposed to only one state in prior work, and (ii) a new self-normalized conc",
    "link": "https://arxiv.org/abs/2403.04568",
    "context": "Title: Improved Algorithm for Adversarial Linear Mixture MDPs with Bandit Feedback and Unknown Transition\nAbstract: arXiv:2403.04568v1 Announce Type: new  Abstract: We study reinforcement learning with linear function approximation, unknown transition, and adversarial losses in the bandit feedback setting. Specifically, we focus on linear mixture MDPs whose transition kernel is a linear mixture model. We propose a new algorithm that attains an $\\widetilde{O}(d\\sqrt{HS^3K} + \\sqrt{HSAK})$ regret with high probability, where $d$ is the dimension of feature mappings, $S$ is the size of state space, $A$ is the size of action space, $H$ is the episode length and $K$ is the number of episodes. Our result strictly improves the previous best-known $\\widetilde{O}(dS^2 \\sqrt{K} + \\sqrt{HSAK})$ result in Zhao et al. (2023a) since $H \\leq S$ holds by the layered MDP structure. Our advancements are primarily attributed to (i) a new least square estimator for the transition parameter that leverages the visit information of all states, as opposed to only one state in prior work, and (ii) a new self-normalized conc",
    "path": "papers/24/03/2403.04568.json",
    "total_tokens": 960,
    "translated_title": "改进的算法用于带有匪夷所思反馈和未知转移的敌对线性混合MDPs",
    "translated_abstract": "我们研究具有线性函数逼近、未知转移和在匪夷所思反馈设置中的敌对损失的强化学习。具体而言，我们专注于转移核为线性混合模型的线性混合MDPs。我们提出了一种新算法，该算法在高概率下达到了$\\widetilde{O}(d\\sqrt{HS^3K} + \\sqrt{HSAK})$的遗憾值，其中$d$是特征映射的维度，$S$是状态空间的大小，$A$是动作空间的大小，$H$是每集长度，$K$是集数。我们的结果严格改进了Zhao等人(2023a)中已知的最佳$\\widetilde{O}(dS^2 \\sqrt{K} + \\sqrt{HSAK})$结果，因为$H \\leq S$由层次MDP结构成立。我们的进展主要归因于(i)一种新的最小二乘估计器，用于转移参数，利用了所有状态的访问信息，而不像以前的工作只用一个状态，以及(ii)一种新的self-normalized分。。",
    "tldr": "通过引入新的最小二乘估计器和self-normalized技术，我们提出了一个新算法，显著改进了线性混合MDPs中的遗憾上界。",
    "en_tdlr": "By introducing a new least square estimator and self-normalized technique, we propose a new algorithm that significantly improves the upper bound on regret in linear mixture MDPs."
}