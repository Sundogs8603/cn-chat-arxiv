{
    "title": "STRUM-LLM: Attributed and Structured Contrastive Summarization",
    "abstract": "arXiv:2403.19710v1 Announce Type: cross  Abstract: Users often struggle with decision-making between two options (A vs B), as it usually requires time-consuming research across multiple web pages. We propose STRUM-LLM that addresses this challenge by generating attributed, structured, and helpful contrastive summaries that highlight key differences between the two options. STRUM-LLM identifies helpful contrast: the specific attributes along which the two options differ significantly and which are most likely to influence the user's decision. Our technique is domain-agnostic, and does not require any human-labeled data or fixed attribute list as supervision. STRUM-LLM attributes all extractions back to the input sources along with textual evidence, and it does not have a limit on the length of input sources that it can process. STRUM-LLM Distilled has 100x more throughput than the models with comparable performance while being 10x smaller. In this paper, we provide extensive evaluations",
    "link": "https://arxiv.org/abs/2403.19710",
    "context": "Title: STRUM-LLM: Attributed and Structured Contrastive Summarization\nAbstract: arXiv:2403.19710v1 Announce Type: cross  Abstract: Users often struggle with decision-making between two options (A vs B), as it usually requires time-consuming research across multiple web pages. We propose STRUM-LLM that addresses this challenge by generating attributed, structured, and helpful contrastive summaries that highlight key differences between the two options. STRUM-LLM identifies helpful contrast: the specific attributes along which the two options differ significantly and which are most likely to influence the user's decision. Our technique is domain-agnostic, and does not require any human-labeled data or fixed attribute list as supervision. STRUM-LLM attributes all extractions back to the input sources along with textual evidence, and it does not have a limit on the length of input sources that it can process. STRUM-LLM Distilled has 100x more throughput than the models with comparable performance while being 10x smaller. In this paper, we provide extensive evaluations",
    "path": "papers/24/03/2403.19710.json",
    "total_tokens": 883,
    "translated_title": "STRUM-LLM: 属性化和结构化对比摘要",
    "translated_abstract": "用户经常在两个选项（A vs B）之间做决策时感到困难，因为这通常需要在多个网页上进行耗时的研究。我们提出了STRUM-LLM，通过生成带属性、结构化和有帮助的对比摘要，突出两个选项之间的关键差异，来解决这一挑战。STRUM-LLM识别了有帮助的对比：两个选项在哪些特定属性上有显著差异，以及最有可能影响用户决策。我们的技术是与领域无关的，并不需要任何人工标记的数据或固定属性列表作为监督。STRUM-LLM将所有提取的内容属性化，以及文本证据，且不限制其处理的输入来源的长度。STRUM-LLM Distilled的吞吐量比具有相似性能的模型高100倍，同时体积小10倍。在本文中，我们进行了广泛的评估。",
    "tldr": "STRUM-LLM提出了一种生成属性化、结构化和有帮助的对比摘要的方法，识别并突出两个选项之间的关键差异，不需要人工标记的数据或固定属性列表，具有高吞吐量和小体积。",
    "en_tdlr": "STRUM-LLM proposes a method to generate attributed, structured, and helpful contrastive summaries that highlight key differences between two options, without requiring human-labeled data or fixed attribute list, with high throughput and small size."
}