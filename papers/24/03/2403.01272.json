{
    "title": "Can a Confident Prior Replace a Cold Posterior?",
    "abstract": "arXiv:2403.01272v1 Announce Type: new  Abstract: Benchmark datasets used for image classification tend to have very low levels of label noise. When Bayesian neural networks are trained on these datasets, they often underfit, misrepresenting the aleatoric uncertainty of the data. A common solution is to cool the posterior, which improves fit to the training data but is challenging to interpret from a Bayesian perspective. We explore whether posterior tempering can be replaced by a confidence-inducing prior distribution. First, we introduce a \"DirClip\" prior that is practical to sample and nearly matches the performance of a cold posterior. Second, we introduce a \"confidence prior\" that directly approximates a cold likelihood in the limit of decreasing temperature but cannot be easily sampled. Lastly, we provide several general insights into confidence-inducing priors, such as when they might diverge and how fine-tuning can mitigate numerical instability.",
    "link": "https://arxiv.org/abs/2403.01272",
    "context": "Title: Can a Confident Prior Replace a Cold Posterior?\nAbstract: arXiv:2403.01272v1 Announce Type: new  Abstract: Benchmark datasets used for image classification tend to have very low levels of label noise. When Bayesian neural networks are trained on these datasets, they often underfit, misrepresenting the aleatoric uncertainty of the data. A common solution is to cool the posterior, which improves fit to the training data but is challenging to interpret from a Bayesian perspective. We explore whether posterior tempering can be replaced by a confidence-inducing prior distribution. First, we introduce a \"DirClip\" prior that is practical to sample and nearly matches the performance of a cold posterior. Second, we introduce a \"confidence prior\" that directly approximates a cold likelihood in the limit of decreasing temperature but cannot be easily sampled. Lastly, we provide several general insights into confidence-inducing priors, such as when they might diverge and how fine-tuning can mitigate numerical instability.",
    "path": "papers/24/03/2403.01272.json",
    "total_tokens": 859,
    "translated_title": "可以用自信先验替代冷却后验吗？",
    "translated_abstract": "用于图像分类的基准数据集往往具有非常低的标签噪声水平。当贝叶斯神经网络在这些数据集上训练时，它们经常欠拟合，错误地表示数据的随机不确定性。一种常见的解决方案是调整后验概率，这样可以改善对训练数据的拟合，但从贝叶斯角度解释起来具有挑战性。我们探讨了后验调整是否可以被一种提高信心的先验分布替代。首先，我们引入了一个实用的采样“DirClip”先验，并且几乎与冷却后验的性能相匹配。其次，我们引入了一个“信心先验”，它在温度趋于零时直接近似于冷布局，但不能轻松抽样。最后，我们提供了一些关于提高信心的先验的一般见解，例如何时可能出现分歧以及如何通过微调来缓解数值不稳定性。",
    "tldr": "探讨了将后验调整替换为增加信心的先验分布的可行性，引入了实用的“DirClip”先验和“信心先验”，提供了对信心先验的一般见解。"
}