{
    "title": "Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation",
    "abstract": "arXiv:2403.02951v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have emerged as a powerful tool in advancing the Text-to-SQL task, significantly outperforming traditional methods. Nevertheless, as a nascent research field, there is still no consensus on the optimal prompt templates and design frameworks. Additionally, existing benchmarks inadequately explore the performance of LLMs across the various sub-tasks of the Text-to-SQL process, which hinders the assessment of LLMs' cognitive capabilities and the optimization of LLM-based solutions.To address the aforementioned issues, we firstly construct a new dataset designed to mitigate the risk of overfitting in LLMs. Then we formulate five evaluation tasks to comprehensively assess the performance of diverse methods across various LLMs throughout the Text-to-SQL process.Our study highlights the performance disparities among LLMs and proposes optimal in-context learning solutions tailored to each task. These findings offer",
    "link": "https://arxiv.org/abs/2403.02951",
    "context": "Title: Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation\nAbstract: arXiv:2403.02951v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have emerged as a powerful tool in advancing the Text-to-SQL task, significantly outperforming traditional methods. Nevertheless, as a nascent research field, there is still no consensus on the optimal prompt templates and design frameworks. Additionally, existing benchmarks inadequately explore the performance of LLMs across the various sub-tasks of the Text-to-SQL process, which hinders the assessment of LLMs' cognitive capabilities and the optimization of LLM-based solutions.To address the aforementioned issues, we firstly construct a new dataset designed to mitigate the risk of overfitting in LLMs. Then we formulate five evaluation tasks to comprehensively assess the performance of diverse methods across various LLMs throughout the Text-to-SQL process.Our study highlights the performance disparities among LLMs and proposes optimal in-context learning solutions tailored to each task. These findings offer",
    "path": "papers/24/03/2403.02951.json",
    "total_tokens": 872,
    "translated_title": "评估大型语言模型的文本生成SQL能力：全面评估",
    "translated_abstract": "大型语言模型（LLMs）已经成为推动文本生成SQL任务的强大工具，明显优于传统方法。然而，作为一个新兴的研究领域，对于最佳提示模板和设计框架仍然没有达成共识。",
    "tldr": "大型语言模型在文本生成SQL任务中表现出色，但对于最佳提示模板和设计框架仍无共识，新数据集和评估任务有助于全面评估各种方法的表现，并提出了优化解决方案。",
    "en_tdlr": "Large Language Models excel in the Text-to-SQL task, yet consensus on optimal prompt templates and design frameworks is lacking. New dataset and evaluation tasks aid in comprehensive assessment of diverse methods' performance and propose optimal solutions."
}