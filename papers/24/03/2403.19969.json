{
    "title": "Separate, Dynamic and Differentiable (SMART) Pruner for Block/Output Channel Pruning on Computer Vision Tasks",
    "abstract": "arXiv:2403.19969v1 Announce Type: cross  Abstract: Deep Neural Network (DNN) pruning has emerged as a key strategy to reduce model size, improve inference latency, and lower power consumption on DNN accelerators. Among various pruning techniques, block and output channel pruning have shown significant potential in accelerating hardware performance. However, their accuracy often requires further improvement. In response to this challenge, we introduce a separate, dynamic and differentiable (SMART) pruner. This pruner stands out by utilizing a separate, learnable probability mask for weight importance ranking, employing a differentiable Top k operator to achieve target sparsity, and leveraging a dynamic temperature parameter trick to escape from non-sparse local minima. In our experiments, the SMART pruner consistently demonstrated its superiority over existing pruning methods across a wide range of tasks and models on block and output channel pruning. Additionally, we extend our testing",
    "link": "https://arxiv.org/abs/2403.19969",
    "context": "Title: Separate, Dynamic and Differentiable (SMART) Pruner for Block/Output Channel Pruning on Computer Vision Tasks\nAbstract: arXiv:2403.19969v1 Announce Type: cross  Abstract: Deep Neural Network (DNN) pruning has emerged as a key strategy to reduce model size, improve inference latency, and lower power consumption on DNN accelerators. Among various pruning techniques, block and output channel pruning have shown significant potential in accelerating hardware performance. However, their accuracy often requires further improvement. In response to this challenge, we introduce a separate, dynamic and differentiable (SMART) pruner. This pruner stands out by utilizing a separate, learnable probability mask for weight importance ranking, employing a differentiable Top k operator to achieve target sparsity, and leveraging a dynamic temperature parameter trick to escape from non-sparse local minima. In our experiments, the SMART pruner consistently demonstrated its superiority over existing pruning methods across a wide range of tasks and models on block and output channel pruning. Additionally, we extend our testing",
    "path": "papers/24/03/2403.19969.json",
    "total_tokens": 862,
    "translated_title": "用于计算机视觉任务的分离、动态和可微（SMART）剪枝器",
    "translated_abstract": "深度神经网络（DNN）剪枝已被视为减小模型大小、改善推理延迟以及降低DNN加速器功耗的关键策略。在各种剪枝技术中，块和输出通道剪枝在加速硬件性能方面展现出了显著潜力。然而，它们的准确性通常需要进一步改进。为了应对这一挑战，我们介绍了一种名为分离、动态和可微（SMART）剪枝器。该剪枝器利用一个独立的、可学习的概率掩码进行权重重要性排序，采用可微的Top k运算符来实现目标稀疏性，并利用动态温度参数技巧来逃离非稀疏局部极小值。在我们的实验中，SMART剪枝器在块和输出通道剪枝的各种任务和模型上一直表现出优越性。",
    "tldr": "SMART剪枝器引入了独立的、可学习的概率掩码、可微的Top k运算符和动态温度参数技巧，在块和输出通道剪枝任务中显示出优越性。",
    "en_tdlr": "The SMART pruner introduces independent, learnable probability mask, differentiable Top k operator, and dynamic temperature parameter trick, demonstrating superiority in block and output channel pruning tasks."
}