{
    "title": "KorMedMCQA: Multi-Choice Question Answering Benchmark for Korean Healthcare Professional Licensing Examinations",
    "abstract": "arXiv:2403.01469v1 Announce Type: new  Abstract: We introduce KorMedMCQA, the first Korean multiple-choice question answering (MCQA) benchmark derived from Korean healthcare professional licensing examinations, covering from the year 2012 to year 2023. This dataset consists of a selection of questions from the license examinations for doctors, nurses, and pharmacists, featuring a diverse array of subjects. We conduct baseline experiments on various large language models, including proprietary/open-source, multilingual/Korean-additional pretrained, and clinical context pretrained models, highlighting the potential for further enhancements. We make our data publicly available on HuggingFace and provide a evaluation script via LM-Harness, inviting further exploration and advancement in Korean healthcare environments.",
    "link": "https://arxiv.org/abs/2403.01469",
    "context": "Title: KorMedMCQA: Multi-Choice Question Answering Benchmark for Korean Healthcare Professional Licensing Examinations\nAbstract: arXiv:2403.01469v1 Announce Type: new  Abstract: We introduce KorMedMCQA, the first Korean multiple-choice question answering (MCQA) benchmark derived from Korean healthcare professional licensing examinations, covering from the year 2012 to year 2023. This dataset consists of a selection of questions from the license examinations for doctors, nurses, and pharmacists, featuring a diverse array of subjects. We conduct baseline experiments on various large language models, including proprietary/open-source, multilingual/Korean-additional pretrained, and clinical context pretrained models, highlighting the potential for further enhancements. We make our data publicly available on HuggingFace and provide a evaluation script via LM-Harness, inviting further exploration and advancement in Korean healthcare environments.",
    "path": "papers/24/03/2403.01469.json",
    "total_tokens": 836,
    "translated_title": "KorMedMCQA: 韩国医疗专业执业考试的多项选择题问答基准",
    "translated_abstract": "我们介绍了KorMedMCQA，这是首个源自韩国医疗专业执业考试的韩语多项选择题问答（MCQA）基准，涵盖了从2012年到2023年的考试内容。该数据集包括医生、护士和药剂师执照考试中的一部分问题，涵盖多种学科。我们对各种大型语言模型进行了基线实验，包括专有/开源、多语言/韩语附加预训练和临床背景预训练模型，突显了进一步增强潜力。我们在HuggingFace上公开了我们的数据，并通过LM-Harness提供了一个评估脚本，邀请在韩国医疗环境中进行进一步探索和发展。",
    "tldr": "KorMedMCQA是首个从韩国医疗专业执业考试中衍生的多项选择题问答基准，提供了多种大型语言模型的基线实验结果，并在HuggingFace上公开了数据，为韩国医疗环境中的进一步研究和发展提供了可能性。"
}