{
    "title": "SineNet: Learning Temporal Dynamics in Time-Dependent Partial Differential Equations",
    "abstract": "arXiv:2403.19507v1 Announce Type: new  Abstract: We consider using deep neural networks to solve time-dependent partial differential equations (PDEs), where multi-scale processing is crucial for modeling complex, time-evolving dynamics. While the U-Net architecture with skip connections is commonly used by prior studies to enable multi-scale processing, our analysis shows that the need for features to evolve across layers results in temporally misaligned features in skip connections, which limits the model's performance. To address this limitation, we propose SineNet, consisting of multiple sequentially connected U-shaped network blocks, referred to as waves. In SineNet, high-resolution features are evolved progressively through multiple stages, thereby reducing the amount of misalignment within each stage. We furthermore analyze the role of skip connections in enabling both parallel and sequential processing of multi-scale information. Our method is rigorously tested on multiple PDE d",
    "link": "https://arxiv.org/abs/2403.19507",
    "context": "Title: SineNet: Learning Temporal Dynamics in Time-Dependent Partial Differential Equations\nAbstract: arXiv:2403.19507v1 Announce Type: new  Abstract: We consider using deep neural networks to solve time-dependent partial differential equations (PDEs), where multi-scale processing is crucial for modeling complex, time-evolving dynamics. While the U-Net architecture with skip connections is commonly used by prior studies to enable multi-scale processing, our analysis shows that the need for features to evolve across layers results in temporally misaligned features in skip connections, which limits the model's performance. To address this limitation, we propose SineNet, consisting of multiple sequentially connected U-shaped network blocks, referred to as waves. In SineNet, high-resolution features are evolved progressively through multiple stages, thereby reducing the amount of misalignment within each stage. We furthermore analyze the role of skip connections in enabling both parallel and sequential processing of multi-scale information. Our method is rigorously tested on multiple PDE d",
    "path": "papers/24/03/2403.19507.json",
    "total_tokens": 815,
    "translated_title": "SineNet：学习时间依赖偏微分方程的时间动力学",
    "translated_abstract": "我们考虑使用深度神经网络来解决时间依赖偏微分方程（PDE），其中多尺度处理对于建模复杂的时间演变动态至关重要。虽然先前的研究通常使用具有跳跃连接的U-Net架构来实现多尺度处理，但我们的分析显示，特征需要跨层演变导致跳跃连接中存在时间错位的特征，从而限制了模型的性能。为了解决这一局限，我们提出了SineNet，由多个依次连接的U形网络块组成，称为波。在SineNet中，高分辨率特征通过多个阶段逐渐演变，从而减少每个阶段内的错位量。我们进一步分析了跳跃连接在实现多尺度信息的并行和连续处理中的作用。我们的方法在多个PDE上经过严格测试。",
    "tldr": "SineNet提出了一种通过多个依次连接的U-shaped网络块（波）在解决时间依赖偏微分方程时减少错位特征的方法",
    "en_tdlr": "SineNet proposes a method to reduce misaligned features in solving time-dependent PDEs by using multiple sequentially connected U-shaped network blocks (waves)."
}