{
    "title": "A Survey of Explainable Knowledge Tracing",
    "abstract": "arXiv:2403.07279v1 Announce Type: new  Abstract: With the long term accumulation of high quality educational data, artificial intelligence has shown excellent performance in knowledge tracing. However, due to the lack of interpretability and transparency of some algorithms, this approach will result in reduced stakeholder trust and a decreased acceptance of intelligent decisions. Therefore, algorithms need to achieve high accuracy, and users need to understand the internal operating mechanism and provide reliable explanations for decisions. This paper thoroughly analyzes the interpretability of KT algorithms. First, the concepts and common methods of explainable artificial intelligence and knowledge tracing are introduced. Next, explainable knowledge tracing models are classified into two categories: transparent models and black box models. Then, the interpretable methods used are reviewed from three stages: ante hoc interpretable methods, post hoc interpretable methods, and other dime",
    "link": "https://arxiv.org/abs/2403.07279",
    "context": "Title: A Survey of Explainable Knowledge Tracing\nAbstract: arXiv:2403.07279v1 Announce Type: new  Abstract: With the long term accumulation of high quality educational data, artificial intelligence has shown excellent performance in knowledge tracing. However, due to the lack of interpretability and transparency of some algorithms, this approach will result in reduced stakeholder trust and a decreased acceptance of intelligent decisions. Therefore, algorithms need to achieve high accuracy, and users need to understand the internal operating mechanism and provide reliable explanations for decisions. This paper thoroughly analyzes the interpretability of KT algorithms. First, the concepts and common methods of explainable artificial intelligence and knowledge tracing are introduced. Next, explainable knowledge tracing models are classified into two categories: transparent models and black box models. Then, the interpretable methods used are reviewed from three stages: ante hoc interpretable methods, post hoc interpretable methods, and other dime",
    "path": "papers/24/03/2403.07279.json",
    "total_tokens": 784,
    "translated_title": "对可解释知识追踪的调查",
    "translated_abstract": "随着高质量教育数据的长期积累，人工智能在知识追踪中表现出色。然而，由于一些算法缺乏解释性和透明性，这种方法会导致利益相关者的信任降低，智能决策的接受度降低。因此，算法需要达到高准确性，用户需要了解内部操作机制并为决策提供可靠解释。本文对可解释性KT算法进行了彻底分析。首先介绍了可解释人工智能和知识追踪的概念和常见方法。然后，将可解释知识追踪模型分为两类：透明模型和黑盒模型。接着，从“ante hoc可解释性方法”、“post hoc可解释性方法”和其他维度审查了可解释性方法。",
    "tldr": "对知识追踪算法进行了解释性分析，提出了可解释知识追踪模型分为透明模型和黑盒模型，探讨了不同阶段的解释性方法。",
    "en_tdlr": "An analysis of explainable knowledge tracing algorithms, categorizing them into transparent and black box models, and reviewing interpretable methods across different stages."
}