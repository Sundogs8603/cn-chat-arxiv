{
    "title": "Fourier or Wavelet bases as counterpart self-attention in spikformer for efficient visual classification",
    "abstract": "arXiv:2403.18228v1 Announce Type: cross  Abstract: Energy-efficient spikformer has been proposed by integrating the biologically plausible spiking neural network (SNN) and artificial Transformer, whereby the Spiking Self-Attention (SSA) is used to achieve both higher accuracy and lower computational cost. However, it seems that self-attention is not always necessary, especially in sparse spike-form calculation manners. In this paper, we innovatively replace vanilla SSA (using dynamic bases calculating from Query and Key) with spike-form Fourier Transform, Wavelet Transform, and their combinations (using fixed triangular or wavelets bases), based on a key hypothesis that both of them use a set of basis functions for information transformation. Hence, the Fourier-or-Wavelet-based spikformer (FWformer) is proposed and verified in visual classification tasks, including both static image and event-based video datasets. The FWformer can achieve comparable or even higher accuracies ($0.4\\%$-$",
    "link": "https://arxiv.org/abs/2403.18228",
    "context": "Title: Fourier or Wavelet bases as counterpart self-attention in spikformer for efficient visual classification\nAbstract: arXiv:2403.18228v1 Announce Type: cross  Abstract: Energy-efficient spikformer has been proposed by integrating the biologically plausible spiking neural network (SNN) and artificial Transformer, whereby the Spiking Self-Attention (SSA) is used to achieve both higher accuracy and lower computational cost. However, it seems that self-attention is not always necessary, especially in sparse spike-form calculation manners. In this paper, we innovatively replace vanilla SSA (using dynamic bases calculating from Query and Key) with spike-form Fourier Transform, Wavelet Transform, and their combinations (using fixed triangular or wavelets bases), based on a key hypothesis that both of them use a set of basis functions for information transformation. Hence, the Fourier-or-Wavelet-based spikformer (FWformer) is proposed and verified in visual classification tasks, including both static image and event-based video datasets. The FWformer can achieve comparable or even higher accuracies ($0.4\\%$-$",
    "path": "papers/24/03/2403.18228.json",
    "total_tokens": 876,
    "translated_title": "傅立叶或小波基作为Spikformer中高效视觉分类的自注意力对应物",
    "translated_abstract": "能效高的Spikformer通过将生物合理的脉冲神经网络（SNN）和人工Transformer集成提出，其中使用脉冲自注意力（SSA）既可提高准确率又可降低计算成本。然而，在稀疏脉冲形式计算方式中，自注意力并非总是必要的。本文创新性地将传统SSA（使用来自查询和键的动态基函数计算）替换为脉冲形式的傅立叶变换、小波变换以及它们的组合（使用固定的三角形或小波基函数），基于一个关键假设，即它们都使用一组基函数进行信息变换。因此，提出了基于傅立叶或小波的Spikformer（FWformer），并在视觉分类任务中进行了验证，包括静态图像和基于事件的视频数据集。FWformer在准确率方面能够达到可比甚至更高的水平（0.4%-$",
    "tldr": "本文提出了在Spikformer中使用傅立叶或小波基代替传统的自注意力机制，提出的FWformer在视觉分类任务中表现出可比甚至更高的准确率。",
    "en_tdlr": "This paper proposes replacing the traditional self-attention mechanism with Fourier or Wavelet bases in Spikformer, and the proposed FWformer achieves comparable or even higher accuracies in visual classification tasks."
}