{
    "title": "Grammatical vs Spelling Error Correction: An Investigation into the Responsiveness of Transformer-based Language Models using BART and MarianMT",
    "abstract": "arXiv:2403.16655v1 Announce Type: new  Abstract: Text continues to remain a relevant form of representation for information. Text documents are created either in digital native platforms or through the conversion of other media files such as images and speech. While the digital native text is invariably obtained through physical or virtual keyboards, technologies such as OCR and speech recognition are utilized to transform the images and speech signals into text content. All these variety of mechanisms of text generation also introduce errors into the captured text.   This project aims at analyzing different kinds of error that occurs in text documents. The work employs two of the advanced deep neural network-based language models, namely, BART and MarianMT, to rectify the anomalies present in the text. Transfer learning of these models with available dataset is performed to finetune their capacity for error correction. A comparative study is conducted to investigate the effectiveness ",
    "link": "https://arxiv.org/abs/2403.16655",
    "context": "Title: Grammatical vs Spelling Error Correction: An Investigation into the Responsiveness of Transformer-based Language Models using BART and MarianMT\nAbstract: arXiv:2403.16655v1 Announce Type: new  Abstract: Text continues to remain a relevant form of representation for information. Text documents are created either in digital native platforms or through the conversion of other media files such as images and speech. While the digital native text is invariably obtained through physical or virtual keyboards, technologies such as OCR and speech recognition are utilized to transform the images and speech signals into text content. All these variety of mechanisms of text generation also introduce errors into the captured text.   This project aims at analyzing different kinds of error that occurs in text documents. The work employs two of the advanced deep neural network-based language models, namely, BART and MarianMT, to rectify the anomalies present in the text. Transfer learning of these models with available dataset is performed to finetune their capacity for error correction. A comparative study is conducted to investigate the effectiveness ",
    "path": "papers/24/03/2403.16655.json",
    "total_tokens": 819,
    "translated_title": "语法错误与拼写错误更正：利用BART和MarianMT探究基于Transformer的语言模型的响应性",
    "translated_abstract": "Text 仍然是信息表示的一个相关形式。文本文档是在数字原生平台中创建的，或通过将其他媒体文件（如图像和语音）转换而来。虽然数字原生文本通常是通过实体或虚拟键盘获得的，但也利用OCR和语音识别技术将图像和语音信号转换为文本内容。所有这些文本生成机制都会引入错误到所捕获的文本中。该项目旨在分析文本文档中出现的不同类型错误。该工作采用两种先进的基于深度神经网络的语言模型，即BART和MarianMT，来纠正文本中存在的异常。对这些模型进行可用数据集的迁移学习，以微调它们的纠错能力。进行了一项比较研究来调查其有效性。",
    "tldr": "该研究利用BART和MarianMT两种先进的深度神经网络语言模型，对文本中的错误进行修正，并通过比较研究探究它们的有效性",
    "en_tdlr": "This study utilizes BART and MarianMT, two advanced deep neural network-based language models, to correct errors in text and investigates their effectiveness through comparative study."
}