{
    "title": "StyleChat: Learning Recitation-Augmented Memory in LLMs for Stylized Dialogue Generation",
    "abstract": "arXiv:2403.11439v1 Announce Type: new  Abstract: Large Language Models (LLMs) demonstrate superior performance in generative scenarios and have attracted widespread attention. Among them, stylized dialogue generation is essential in the context of LLMs for building intelligent and engaging dialogue agent. However the ability of LLMs is data-driven and limited by data bias, leading to poor performance on specific tasks. In particular, stylized dialogue generation suffers from a severe lack of supervised data. Furthermore, although many prompt-based methods have been proposed to accomplish specific tasks, their performance in complex real-world scenarios involving a wide variety of dialog styles further enhancement. In this work, we first introduce a stylized dialogue dataset StyleEval with 38 styles by leveraging the generative power of LLMs comprehensively, which has been carefully constructed with rigorous human-led quality control. Based on this, we propose the stylized dialogue fram",
    "link": "https://arxiv.org/abs/2403.11439",
    "context": "Title: StyleChat: Learning Recitation-Augmented Memory in LLMs for Stylized Dialogue Generation\nAbstract: arXiv:2403.11439v1 Announce Type: new  Abstract: Large Language Models (LLMs) demonstrate superior performance in generative scenarios and have attracted widespread attention. Among them, stylized dialogue generation is essential in the context of LLMs for building intelligent and engaging dialogue agent. However the ability of LLMs is data-driven and limited by data bias, leading to poor performance on specific tasks. In particular, stylized dialogue generation suffers from a severe lack of supervised data. Furthermore, although many prompt-based methods have been proposed to accomplish specific tasks, their performance in complex real-world scenarios involving a wide variety of dialog styles further enhancement. In this work, we first introduce a stylized dialogue dataset StyleEval with 38 styles by leveraging the generative power of LLMs comprehensively, which has been carefully constructed with rigorous human-led quality control. Based on this, we propose the stylized dialogue fram",
    "path": "papers/24/03/2403.11439.json",
    "total_tokens": 847,
    "translated_title": "StyleChat: 在LLMs中学习复述增强记忆以进行风格化对话生成",
    "translated_abstract": "大型语言模型(LLMs)在生成场景中展现出卓越的性能，并受到广泛关注。其中，在LLMs环境中进行风格化对话生成对于构建智能且引人入胜的对话代理至关重要。然而，LLMs的能力是数据驱动的，并受数据偏差限制，导致在特定任务上表现不佳。特别是，风格化对话生成面临着严重的监督数据不足问题。此外，虽然提出了许多基于提示的方法来完成特定任务，但在涉及各种对话风格的复杂现实场景中的性能需要进一步提升。在这项工作中，我们首次引入一个包含38种风格的风格化对话数据集StyleEval，充分利用LLMs的生成能力，经过严格的人为质量控制精心构建。基于此，我们提出了风格化对话框架",
    "tldr": "该论文介绍了一个包含38种风格的风格化对话数据集StyleEval，并提出了一种风格化对话框架，以增强LLMs在风格化对话生成中的性能。"
}