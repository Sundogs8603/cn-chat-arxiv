{
    "title": "Differentiable Information Bottleneck for Deterministic Multi-view Clustering",
    "abstract": "arXiv:2403.15681v1 Announce Type: cross  Abstract: In recent several years, the information bottleneck (IB) principle provides an information-theoretic framework for deep multi-view clustering (MVC) by compressing multi-view observations while preserving the relevant information of multiple views. Although existing IB-based deep MVC methods have achieved huge success, they rely on variational approximation and distribution assumption to estimate the lower bound of mutual information, which is a notoriously hard and impractical problem in high-dimensional multi-view spaces. In this work, we propose a new differentiable information bottleneck (DIB) method, which provides a deterministic and analytical MVC solution by fitting the mutual information without the necessity of variational approximation. Specifically, we first propose to directly fit the mutual information of high-dimensional spaces by leveraging normalized kernel Gram matrix, which does not require any auxiliary neural estima",
    "link": "https://arxiv.org/abs/2403.15681",
    "context": "Title: Differentiable Information Bottleneck for Deterministic Multi-view Clustering\nAbstract: arXiv:2403.15681v1 Announce Type: cross  Abstract: In recent several years, the information bottleneck (IB) principle provides an information-theoretic framework for deep multi-view clustering (MVC) by compressing multi-view observations while preserving the relevant information of multiple views. Although existing IB-based deep MVC methods have achieved huge success, they rely on variational approximation and distribution assumption to estimate the lower bound of mutual information, which is a notoriously hard and impractical problem in high-dimensional multi-view spaces. In this work, we propose a new differentiable information bottleneck (DIB) method, which provides a deterministic and analytical MVC solution by fitting the mutual information without the necessity of variational approximation. Specifically, we first propose to directly fit the mutual information of high-dimensional spaces by leveraging normalized kernel Gram matrix, which does not require any auxiliary neural estima",
    "path": "papers/24/03/2403.15681.json",
    "total_tokens": 733,
    "translated_title": "可微分信息瓶颈在确定性多视角聚类中的应用",
    "translated_abstract": "最近几年，信息瓶颈（IB）原理为深度多视角聚类（MVC）提供了信息理论框架，通过压缩多视角观察数据来保留多视角相关信息。本文提出了一种新的可微分信息瓶颈（DIB）方法，通过拟合相互信息而不需要变分逼近，提供了一种确定性和分析性的MVC解决方案。具体地，我们首先提出通过利用归一化核格拉姆矩阵直接拟合高维空间的相互信息，而无需任何辅助神经估计。",
    "tldr": "提出了一种新的可微分信息瓶颈（DIB）方法，用于确定性多视角聚类，可以通过拟合相互信息来提供分析性解决方案，避免了变分逼近的需要。",
    "en_tdlr": "Introduced a new differentiable information bottleneck (DIB) method for deterministic multi-view clustering, which provides an analytical solution by fitting mutual information, avoiding the need for variational approximation."
}