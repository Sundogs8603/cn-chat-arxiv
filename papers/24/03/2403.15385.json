{
    "title": "LATTE3D: Large-scale Amortized Text-To-Enhanced3D Synthesis",
    "abstract": "arXiv:2403.15385v1 Announce Type: cross  Abstract: Recent text-to-3D generation approaches produce impressive 3D results but require time-consuming optimization that can take up to an hour per prompt. Amortized methods like ATT3D optimize multiple prompts simultaneously to improve efficiency, enabling fast text-to-3D synthesis. However, they cannot capture high-frequency geometry and texture details and struggle to scale to large prompt sets, so they generalize poorly. We introduce LATTE3D, addressing these limitations to achieve fast, high-quality generation on a significantly larger prompt set. Key to our method is 1) building a scalable architecture and 2) leveraging 3D data during optimization through 3D-aware diffusion priors, shape regularization, and model initialization to achieve robustness to diverse and complex training prompts. LATTE3D amortizes both neural field and textured surface generation to produce highly detailed textured meshes in a single forward pass. LATTE3D gen",
    "link": "https://arxiv.org/abs/2403.15385",
    "context": "Title: LATTE3D: Large-scale Amortized Text-To-Enhanced3D Synthesis\nAbstract: arXiv:2403.15385v1 Announce Type: cross  Abstract: Recent text-to-3D generation approaches produce impressive 3D results but require time-consuming optimization that can take up to an hour per prompt. Amortized methods like ATT3D optimize multiple prompts simultaneously to improve efficiency, enabling fast text-to-3D synthesis. However, they cannot capture high-frequency geometry and texture details and struggle to scale to large prompt sets, so they generalize poorly. We introduce LATTE3D, addressing these limitations to achieve fast, high-quality generation on a significantly larger prompt set. Key to our method is 1) building a scalable architecture and 2) leveraging 3D data during optimization through 3D-aware diffusion priors, shape regularization, and model initialization to achieve robustness to diverse and complex training prompts. LATTE3D amortizes both neural field and textured surface generation to produce highly detailed textured meshes in a single forward pass. LATTE3D gen",
    "path": "papers/24/03/2403.15385.json",
    "total_tokens": 886,
    "translated_title": "LATTE3D: 大规模摊还式文本增强3D合成",
    "translated_abstract": "最近的文本到3D生成方法产生了令人印象深刻的3D结果，但需要耗时的优化，每个提示可能需要长达一小时。像ATT3D这样的摊还方法同时优化多个提示，以提高效率，实现快速的文本到3D合成。然而，它们无法捕捉高频几何和纹理细节，并且很难扩展到大型提示集，因此泛化能力较差。我们引入了LATTE3D，解决了这些限制，实现在显著更大的提示集上进行快速、高质量的生成。我们的方法的关键之处在于 1)构建可扩展的架构和 2)利用3D数据在优化过程中通过3D感知扩散先验、形状正则化和模型初始化，以实现对不同和复杂训练提示的稳健性。LATTE3D摊还了神经场和纹理表面的生成，能在单次前向传递中产生高度详细的纹理网格。",
    "tldr": "LATTE3D通过构建可扩展的架构、利用3D数据并采用摊还方法，在显著更大的提示集上实现快速、高质量的文本增强3D合成。"
}