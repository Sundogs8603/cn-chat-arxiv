{
    "title": "ECToNAS: Evolutionary Cross-Topology Neural Architecture Search",
    "abstract": "arXiv:2403.05123v1 Announce Type: new  Abstract: We present ECToNAS, a cost-efficient evolutionary cross-topology neural architecture search algorithm that does not require any pre-trained meta controllers. Our framework is able to select suitable network architectures for different tasks and hyperparameter settings, independently performing cross-topology optimisation where required. It is a hybrid approach that fuses training and topology optimisation together into one lightweight, resource-friendly process. We demonstrate the validity and power of this approach with six standard data sets (CIFAR-10, CIFAR-100, EuroSAT, Fashion MNIST, MNIST, SVHN), showcasing the algorithm's ability to not only optimise the topology within an architectural type, but also to dynamically add and remove convolutional cells when and where required, thus crossing boundaries between different network types. This enables researchers without a background in machine learning to make use of appropriate model t",
    "link": "https://arxiv.org/abs/2403.05123",
    "context": "Title: ECToNAS: Evolutionary Cross-Topology Neural Architecture Search\nAbstract: arXiv:2403.05123v1 Announce Type: new  Abstract: We present ECToNAS, a cost-efficient evolutionary cross-topology neural architecture search algorithm that does not require any pre-trained meta controllers. Our framework is able to select suitable network architectures for different tasks and hyperparameter settings, independently performing cross-topology optimisation where required. It is a hybrid approach that fuses training and topology optimisation together into one lightweight, resource-friendly process. We demonstrate the validity and power of this approach with six standard data sets (CIFAR-10, CIFAR-100, EuroSAT, Fashion MNIST, MNIST, SVHN), showcasing the algorithm's ability to not only optimise the topology within an architectural type, but also to dynamically add and remove convolutional cells when and where required, thus crossing boundaries between different network types. This enables researchers without a background in machine learning to make use of appropriate model t",
    "path": "papers/24/03/2403.05123.json",
    "total_tokens": 928,
    "translated_title": "ECToNAS: 进化跨拓扑神经架构搜索",
    "translated_abstract": "我们提出了ECToNAS，这是一种成本高效的进化跨拓扑神经架构搜索算法，不需要任何预训练的元控制器。我们的框架能够独立地为不同任务和超参数设置选择合适的网络架构，并在需要时执行跨拓扑优化。这是一种混合方法，将训练和拓扑优化合并为一个轻量级、资源友好的过程。我们通过六个标准数据集（CIFAR-10、CIFAR-100、EuroSAT、Fashion MNIST、MNIST、SVHN）展示了这种方法的有效性和能力，展示了该算法不仅能优化架构类型内的拓扑，还能根据需要动态添加和移除卷积单元，从而跨越不同网络类型之间的边界。这使得那些没有机器学习背景的研究人员能够利用适当的模型。",
    "tldr": "ECToNAS是一种成本高效的进化跨拓扑神经架构搜索算法，不需要预训练的元控制器，能够在不同任务和超参数设置下自主选择合适的网络架构，实现跨拓扑优化，动态添加和移除卷积单元，为没有机器学习背景的研究人员提供了利用适当模型的可能性。",
    "en_tdlr": "ECToNAS is a cost-efficient evolutionary cross-topology neural architecture search algorithm that does not require pre-trained meta controllers, independently selects suitable network architectures for different tasks and hyperparameter settings, performs cross-topology optimization, dynamically adds and removes convolutional cells, providing the possibility for researchers without a background in machine learning to use appropriate models."
}