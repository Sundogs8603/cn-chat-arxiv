{
    "title": "Evaluating Fair Feature Selection in Machine Learning for Healthcare",
    "abstract": "arXiv:2403.19165v1 Announce Type: new  Abstract: With the universal adoption of machine learning in healthcare, the potential for the automation of societal biases to further exacerbate health disparities poses a significant risk. We explore algorithmic fairness from the perspective of feature selection. Traditional feature selection methods identify features for better decision making by removing resource-intensive, correlated, or non-relevant features but overlook how these factors may differ across subgroups. To counter these issues, we evaluate a fair feature selection method that considers equal importance to all demographic groups. We jointly considered a fairness metric and an error metric within the feature selection process to ensure a balance between minimizing both bias and global classification error. We tested our approach on three publicly available healthcare datasets. On all three datasets, we observed improvements in fairness metrics coupled with a minimal degradation ",
    "link": "https://arxiv.org/abs/2403.19165",
    "context": "Title: Evaluating Fair Feature Selection in Machine Learning for Healthcare\nAbstract: arXiv:2403.19165v1 Announce Type: new  Abstract: With the universal adoption of machine learning in healthcare, the potential for the automation of societal biases to further exacerbate health disparities poses a significant risk. We explore algorithmic fairness from the perspective of feature selection. Traditional feature selection methods identify features for better decision making by removing resource-intensive, correlated, or non-relevant features but overlook how these factors may differ across subgroups. To counter these issues, we evaluate a fair feature selection method that considers equal importance to all demographic groups. We jointly considered a fairness metric and an error metric within the feature selection process to ensure a balance between minimizing both bias and global classification error. We tested our approach on three publicly available healthcare datasets. On all three datasets, we observed improvements in fairness metrics coupled with a minimal degradation ",
    "path": "papers/24/03/2403.19165.json",
    "total_tokens": 853,
    "translated_title": "在医疗保健领域评估机器学习中的公平特征选择",
    "translated_abstract": "随着机器学习在医疗保健领域的普及，自动化社会偏见进一步加剧健康差距的潜力构成了重大风险。我们从特征选择的角度探讨算法公平性。传统的特征选择方法通过去除资源密集、相关或不相关的特征来识别用于更好决策的特征，但忽略了这些因素在不同子群体中可能存在的差异。为了应对这些问题，我们评估了一种考虑对所有人口统计群体均等重要性的公平特征选择方法。我们在特征选择过程中同时考虑了公平性度量和错误度量，以确保在最大程度减少偏见和全局分类错误之间实现平衡。我们在三个公开可用的医疗保健数据集上测试了我们的方法。在所有三个数据集上，我们观察到公平性指标得到改善，同时分类错误仅有轻微下降。",
    "tldr": "通过考虑对所有人口统计群体均等重要性的公平特征选择方法，在医疗保健领域评估算法公平性，确保在减少偏见和全局分类错误之间实现平衡。",
    "en_tdlr": "Evaluating algorithmic fairness in healthcare by considering a fair feature selection method that assigns equal importance to all demographic groups, balancing the reduction of bias and global classification error."
}