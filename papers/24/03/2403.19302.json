{
    "title": "Generate then Retrieve: Conversational Response Retrieval Using LLMs as Answer and Query Generators",
    "abstract": "arXiv:2403.19302v1 Announce Type: new  Abstract: CIS is a prominent area in IR that focuses on developing interactive knowledge assistants. These systems must adeptly comprehend the user's information requirements within the conversational context and retrieve the relevant information. To this aim, the existing approaches model the user's information needs with one query called rewritten query and use this query for passage retrieval. In this paper, we propose three different methods for generating multiple queries to enhance the retrieval. In these methods, we leverage the capabilities of large language models (LLMs) in understanding the user's information need and generating an appropriate response, to generate multiple queries. We implement and evaluate the proposed models utilizing various LLMs including GPT-4 and Llama-2 chat in zero-shot and few-shot settings. In addition, we propose a new benchmark for TREC iKAT based on gpt 3.5 judgments. Our experiments reveal the effectivenes",
    "link": "https://arxiv.org/abs/2403.19302",
    "context": "Title: Generate then Retrieve: Conversational Response Retrieval Using LLMs as Answer and Query Generators\nAbstract: arXiv:2403.19302v1 Announce Type: new  Abstract: CIS is a prominent area in IR that focuses on developing interactive knowledge assistants. These systems must adeptly comprehend the user's information requirements within the conversational context and retrieve the relevant information. To this aim, the existing approaches model the user's information needs with one query called rewritten query and use this query for passage retrieval. In this paper, we propose three different methods for generating multiple queries to enhance the retrieval. In these methods, we leverage the capabilities of large language models (LLMs) in understanding the user's information need and generating an appropriate response, to generate multiple queries. We implement and evaluate the proposed models utilizing various LLMs including GPT-4 and Llama-2 chat in zero-shot and few-shot settings. In addition, we propose a new benchmark for TREC iKAT based on gpt 3.5 judgments. Our experiments reveal the effectivenes",
    "path": "papers/24/03/2403.19302.json",
    "total_tokens": 847,
    "translated_title": "生成然后检索：使用LLM作为答案和查询生成器的对话响应检索",
    "translated_abstract": "CIS是信息检索中的一个重要领域，专注于开发交互式知识助手。这些系统必须能够熟练地理解用户在对话环境中的信息需求，并检索相关信息。为实现这一目标，现有方法使用一个称为重写查询的查询来建模用户的信息需求，并将此查询用于段落检索。在本文中，我们提出了三种用于生成多个查询以增强检索的不同方法。在这些方法中，我们利用大型语言模型（LLMs）的能力来理解用户的信息需求和生成适当的响应，以生成多个查询。我们实现并评估了提出的模型，利用包括GPT-4和Llama-2在零-shot和少-shot设置中的各种LLMs。此外，我们基于gpt 3.5的判断提出了一个针对TREC iKAT的新基准。我们的实验揭示了效果",
    "tldr": "本文提出了一种利用大型语言模型生成多个查询以增强对话响应检索的方法，并基于不同LLMs实现评估，同时还提出了一个新的TREC iKAT基准。",
    "en_tdlr": "This paper presents a method of using large language models to generate multiple queries to enhance conversational response retrieval, evaluated with different LLMs, and introduces a new benchmark for TREC iKAT."
}