{
    "title": "Adversarially Robust Deepfake Detection via Adversarial Feature Similarity Learning",
    "abstract": "arXiv:2403.08806v1 Announce Type: cross  Abstract: Deepfake technology has raised concerns about the authenticity of digital content, necessitating the development of effective detection methods. However, the widespread availability of deepfakes has given rise to a new challenge in the form of adversarial attacks. Adversaries can manipulate deepfake videos with small, imperceptible perturbations that can deceive the detection models into producing incorrect outputs. To tackle this critical issue, we introduce Adversarial Feature Similarity Learning (AFSL), which integrates three fundamental deep feature learning paradigms. By optimizing the similarity between samples and weight vectors, our approach aims to distinguish between real and fake instances. Additionally, we aim to maximize the similarity between both adversarially perturbed examples and unperturbed examples, regardless of their real or fake nature. Moreover, we introduce a regularization technique that maximizes the dissimil",
    "link": "https://arxiv.org/abs/2403.08806",
    "context": "Title: Adversarially Robust Deepfake Detection via Adversarial Feature Similarity Learning\nAbstract: arXiv:2403.08806v1 Announce Type: cross  Abstract: Deepfake technology has raised concerns about the authenticity of digital content, necessitating the development of effective detection methods. However, the widespread availability of deepfakes has given rise to a new challenge in the form of adversarial attacks. Adversaries can manipulate deepfake videos with small, imperceptible perturbations that can deceive the detection models into producing incorrect outputs. To tackle this critical issue, we introduce Adversarial Feature Similarity Learning (AFSL), which integrates three fundamental deep feature learning paradigms. By optimizing the similarity between samples and weight vectors, our approach aims to distinguish between real and fake instances. Additionally, we aim to maximize the similarity between both adversarially perturbed examples and unperturbed examples, regardless of their real or fake nature. Moreover, we introduce a regularization technique that maximizes the dissimil",
    "path": "papers/24/03/2403.08806.json",
    "total_tokens": 844,
    "translated_title": "通过对抗特征相似性学习来提升对抗性强的Deepfake检测",
    "translated_abstract": "Deepfake技术引发了对数字内容真实性的担忧，迫切需要开发有效的检测方法。然而，广泛传播的Deepfake技术也带来了对抗性攻击的新挑战，对手可以通过微小的、察觉不到的扰动来操纵Deepfake视频，欺骗检测模型产生错误输出。为了解决这一关键问题，我们引入了Adversarial Feature Similarity Learning（AFSL），该方法将三种基本的深度特征学习范式整合在一起。通过优化样本和权重向量之间的相似性，我们的方法旨在区分真实和虚假实例。此外，我们旨在最大化对抗性扰动示例和未经扰动示例之间的相似性，而不管它们是真实的还是虚假的。此外，我们引入了一种正则化技术，其最大化了",
    "tldr": "通过对抗特征相似性学习来提升对抗性强的Deepfake检测，以区分真假实例并最大化对抗性扰动和未扰动示例之间的相似性。",
    "en_tdlr": "Enhancing adversarially robust deepfake detection through adversarial feature similarity learning to distinguish real and fake instances and maximize the similarity between adversarially perturbed and unperturbed examples."
}