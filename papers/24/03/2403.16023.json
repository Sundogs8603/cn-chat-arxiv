{
    "title": "RPMArt: Towards Robust Perception and Manipulation for Articulated Objects",
    "abstract": "arXiv:2403.16023v1 Announce Type: cross  Abstract: Articulated objects are commonly found in daily life. It is essential that robots can exhibit robust perception and manipulation skills for articulated objects in real-world robotic applications. However, existing methods for articulated objects insufficiently address noise in point clouds and struggle to bridge the gap between simulation and reality, thus limiting the practical deployment in real-world scenarios. To tackle these challenges, we propose a framework towards Robust Perception and Manipulation for Articulated Objects (RPMArt), which learns to estimate the articulation parameters and manipulate the articulation part from the noisy point cloud. Our primary contribution is a Robust Articulation Network (RoArtNet) that is able to predict both joint parameters and affordable points robustly by local feature learning and point tuple voting. Moreover, we introduce an articulation-aware classification scheme to enhance its ability",
    "link": "https://arxiv.org/abs/2403.16023",
    "context": "Title: RPMArt: Towards Robust Perception and Manipulation for Articulated Objects\nAbstract: arXiv:2403.16023v1 Announce Type: cross  Abstract: Articulated objects are commonly found in daily life. It is essential that robots can exhibit robust perception and manipulation skills for articulated objects in real-world robotic applications. However, existing methods for articulated objects insufficiently address noise in point clouds and struggle to bridge the gap between simulation and reality, thus limiting the practical deployment in real-world scenarios. To tackle these challenges, we propose a framework towards Robust Perception and Manipulation for Articulated Objects (RPMArt), which learns to estimate the articulation parameters and manipulate the articulation part from the noisy point cloud. Our primary contribution is a Robust Articulation Network (RoArtNet) that is able to predict both joint parameters and affordable points robustly by local feature learning and point tuple voting. Moreover, we introduce an articulation-aware classification scheme to enhance its ability",
    "path": "papers/24/03/2403.16023.json",
    "total_tokens": 824,
    "translated_title": "RPMArt：面向关节对象的健壮感知和操作",
    "translated_abstract": "关节对象在日常生活中很常见。对于真实世界的机器人应用来说，机器人能够表现出对关节对象的健壮感知和操作技能是至关重要的。然而，现有的关节对象方法不够解决点云中的噪声问题，难以弥合模拟与现实之间的差距，从而限制了在真实场景中的实际部署。为了解决这些挑战，我们提出了一个面向关节对象的健壮感知和操作的框架（RPMArt），该框架学习如何从嘈杂的点云中估计关节参数并操作关节部分。我们的主要贡献是一个健壮关节网络（RoArtNet），通过局部特征学习和点元组投票能够稳健地预测关节参数和可信点。此外，我们引入了一个关节感知分类方案来增强其能力。",
    "tldr": "提出了面向关节对象的健壮感知和操作框架RPMArt，主要贡献是能够稳健地预测关节参数和可信点的RoArtNet。",
    "en_tdlr": "Proposed a framework RPMArt for robust perception and manipulation for articulated objects, with the primary contribution being RoArtNet's ability to robustly predict joint parameters and reliable points."
}