{
    "title": "Inf2Guard: An Information-Theoretic Framework for Learning Privacy-Preserving Representations against Inference Attacks",
    "abstract": "arXiv:2403.02116v1 Announce Type: new  Abstract: Machine learning (ML) is vulnerable to inference (e.g., membership inference, property inference, and data reconstruction) attacks that aim to infer the private information of training data or dataset. Existing defenses are only designed for one specific type of attack and sacrifice significant utility or are soon broken by adaptive attacks. We address these limitations by proposing an information-theoretic defense framework, called Inf2Guard, against the three major types of inference attacks. Our framework, inspired by the success of representation learning, posits that learning shared representations not only saves time/costs but also benefits numerous downstream tasks. Generally, Inf2Guard involves two mutual information objectives, for privacy protection and utility preservation, respectively. Inf2Guard exhibits many merits: it facilitates the design of customized objectives against the specific inference attack; it provides a gener",
    "link": "https://arxiv.org/abs/2403.02116",
    "context": "Title: Inf2Guard: An Information-Theoretic Framework for Learning Privacy-Preserving Representations against Inference Attacks\nAbstract: arXiv:2403.02116v1 Announce Type: new  Abstract: Machine learning (ML) is vulnerable to inference (e.g., membership inference, property inference, and data reconstruction) attacks that aim to infer the private information of training data or dataset. Existing defenses are only designed for one specific type of attack and sacrifice significant utility or are soon broken by adaptive attacks. We address these limitations by proposing an information-theoretic defense framework, called Inf2Guard, against the three major types of inference attacks. Our framework, inspired by the success of representation learning, posits that learning shared representations not only saves time/costs but also benefits numerous downstream tasks. Generally, Inf2Guard involves two mutual information objectives, for privacy protection and utility preservation, respectively. Inf2Guard exhibits many merits: it facilitates the design of customized objectives against the specific inference attack; it provides a gener",
    "path": "papers/24/03/2403.02116.json",
    "total_tokens": 863,
    "translated_title": "Inf2Guard：一种信息论框架，用于学习防止推断攻击的隐私保护表示",
    "translated_abstract": "机器学习（ML）容易受到推断攻击（例如成员推断、属性推断和数据重构等）的威胁，这些攻击旨在推断训练数据或数据集的私人信息。现有的防御措施只针对一种特定类型的攻击设计，且会牺牲较大的效用，或很快被自适应攻击击破。我们提出了一种信息论防御框架，名为Inf2Guard，用于抵御三种主要类型的推断攻击。我们的框架受到表示学习成功的启发，认为学习共享表示不仅节省时间/成本，而且有益于许多下游任务。一般来说，Inf2Guard包括两个相互信息目标，分别用于隐私保护和效用保留。Inf2Guard具有许多优点：它促进了针对特定推断攻击的定制目标的设计；它提供了一种通用的...",
    "tldr": "Inf2Guard提出了一种信息论防御框架，应对三种主要类型的推断攻击，其中包括两个相互信息目标，分别用于隐私保护和效用保留。"
}