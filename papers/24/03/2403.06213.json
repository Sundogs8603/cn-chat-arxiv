{
    "title": "$V_kD:$ Improving Knowledge Distillation using Orthogonal Projections",
    "abstract": "arXiv:2403.06213v1 Announce Type: cross  Abstract: Knowledge distillation is an effective method for training small and efficient deep learning models. However, the efficacy of a single method can degenerate when transferring to other tasks, modalities, or even other architectures. To address this limitation, we propose a novel constrained feature distillation method. This method is derived from a small set of core principles, which results in two emerging components: an orthogonal projection and a task-specific normalisation. Equipped with both of these components, our transformer models can outperform all previous methods on ImageNet and reach up to a 4.4% relative improvement over the previous state-of-the-art methods. To further demonstrate the generality of our method, we apply it to object detection and image generation, whereby we obtain consistent and substantial performance improvements over state-of-the-art. Code and models are publicly available: https://github.com/roymiles/",
    "link": "https://arxiv.org/abs/2403.06213",
    "context": "Title: $V_kD:$ Improving Knowledge Distillation using Orthogonal Projections\nAbstract: arXiv:2403.06213v1 Announce Type: cross  Abstract: Knowledge distillation is an effective method for training small and efficient deep learning models. However, the efficacy of a single method can degenerate when transferring to other tasks, modalities, or even other architectures. To address this limitation, we propose a novel constrained feature distillation method. This method is derived from a small set of core principles, which results in two emerging components: an orthogonal projection and a task-specific normalisation. Equipped with both of these components, our transformer models can outperform all previous methods on ImageNet and reach up to a 4.4% relative improvement over the previous state-of-the-art methods. To further demonstrate the generality of our method, we apply it to object detection and image generation, whereby we obtain consistent and substantial performance improvements over state-of-the-art. Code and models are publicly available: https://github.com/roymiles/",
    "path": "papers/24/03/2403.06213.json",
    "total_tokens": 799,
    "translated_title": "$V_kD：使用正交投影改进知识蒸馏",
    "translated_abstract": "知识蒸馏是一种训练小型高效深度学习模型的有效方法。本文提出一种新颖的约束特征蒸馏方法，以解决单一方法在转移到其他任务、模态或架构时的有效性降低的问题。该方法源于一小组核心原则，包括正交投影和任务特定的归一化，通过这两个组件，我们的Transformer模型在ImageNet上表现优异，相对于之前的最先进方法取得了高达4.4%的相对改进。我们进一步将该方法应用于目标检测和图像生成，得到了持续和显著的性能改进。代码和模型公开可用：https://github.com/roymiles/",
    "tldr": "提出一种约束特征蒸馏方法，通过使用正交投影和任务特定的归一化，能够在ImageNet上实现高达4.4%的相对改进，并在目标检测和图像生成任务中取得显著性能提升",
    "en_tdlr": "Propose a constrained feature distillation method, which utilizes orthogonal projection and task-specific normalization, achieving up to a 4.4% relative improvement on ImageNet and substantial performance gains in object detection and image generation."
}