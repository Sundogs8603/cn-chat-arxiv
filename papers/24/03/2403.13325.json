{
    "title": "Harnessing Large Language Models for Text-Rich Sequential Recommendation",
    "abstract": "arXiv:2403.13325v1 Announce Type: new  Abstract: Recent advances in Large Language Models (LLMs) have been changing the paradigm of Recommender Systems (RS). However, when items in the recommendation scenarios contain rich textual information, such as product descriptions in online shopping or news headlines on social media, LLMs require longer texts to comprehensively depict the historical user behavior sequence. This poses significant challenges to LLM-based recommenders, such as over-length limitations, extensive time and space overheads, and suboptimal model performance. To this end, in this paper, we design a novel framework for harnessing Large Language Models for Text-Rich Sequential Recommendation (LLM-TRSR). Specifically, we first propose to segment the user historical behaviors and subsequently employ an LLM-based summarizer for summarizing these user behavior blocks. Particularly, drawing inspiration from the successful application of Convolutional Neural Networks (CNN) and ",
    "link": "https://arxiv.org/abs/2403.13325",
    "context": "Title: Harnessing Large Language Models for Text-Rich Sequential Recommendation\nAbstract: arXiv:2403.13325v1 Announce Type: new  Abstract: Recent advances in Large Language Models (LLMs) have been changing the paradigm of Recommender Systems (RS). However, when items in the recommendation scenarios contain rich textual information, such as product descriptions in online shopping or news headlines on social media, LLMs require longer texts to comprehensively depict the historical user behavior sequence. This poses significant challenges to LLM-based recommenders, such as over-length limitations, extensive time and space overheads, and suboptimal model performance. To this end, in this paper, we design a novel framework for harnessing Large Language Models for Text-Rich Sequential Recommendation (LLM-TRSR). Specifically, we first propose to segment the user historical behaviors and subsequently employ an LLM-based summarizer for summarizing these user behavior blocks. Particularly, drawing inspiration from the successful application of Convolutional Neural Networks (CNN) and ",
    "path": "papers/24/03/2403.13325.json",
    "total_tokens": 870,
    "translated_title": "利用大型语言模型进行文本丰富的顺序推荐",
    "translated_abstract": "近年来，大型语言模型（LLMs）的最新进展已经改变了推荐系统（RS）的范式。然而，当推荐场景中的物品包含丰富的文本信息，例如在线购物中的产品描述或社交媒体上的新闻标题时，LLMs需要更长的文本才能全面描述历史用户行为序列。这给基于LLM的推荐系统带来了重大挑战，例如长度限制、庞大的时间和空间开销以及子优化的模型性能。为此，在本文中，我们设计了一个新颖的框架，用于利用大型语言模型进行文本丰富的顺序推荐（LLM-TRSR）。具体而言，我们首先提出对用户历史行为进行分段，随后采用基于LLM的摘要工具对这些用户行为块进行总结。特别地，借鉴卷积神经网络（CNN）在成功应用中的灵感",
    "tldr": "利用大型语言模型，设计了一种新框架用于文本丰富的顺序推荐，通过对用户历史行为分段并采用LLM摘要工具进行总结，从而解决推荐系统中长文本信息带来的挑战",
    "en_tdlr": "A novel framework leveraging Large Language Models has been designed for text-rich sequential recommendation, addressing the challenges posed by longer textual information in recommender systems through segmenting user historical behaviors and using LLM summarizer."
}