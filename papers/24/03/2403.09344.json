{
    "title": "SketchINR: A First Look into Sketches as Implicit Neural Representations",
    "abstract": "arXiv:2403.09344v1 Announce Type: cross  Abstract: We propose SketchINR, to advance the representation of vector sketches with implicit neural models. A variable length vector sketch is compressed into a latent space of fixed dimension that implicitly encodes the underlying shape as a function of time and strokes. The learned function predicts the $xy$ point coordinates in a sketch at each time and stroke. Despite its simplicity, SketchINR outperforms existing representations at multiple tasks: (i) Encoding an entire sketch dataset into a fixed size latent vector, SketchINR gives $60\\times$ and $10\\times$ data compression over raster and vector sketches, respectively. (ii) SketchINR's auto-decoder provides a much higher-fidelity representation than other learned vector sketch representations, and is uniquely able to scale to complex vector sketches such as FS-COCO. (iii) SketchINR supports parallelisation that can decode/render $\\sim$$100\\times$ faster than other learned vector represe",
    "link": "https://arxiv.org/abs/2403.09344",
    "context": "Title: SketchINR: A First Look into Sketches as Implicit Neural Representations\nAbstract: arXiv:2403.09344v1 Announce Type: cross  Abstract: We propose SketchINR, to advance the representation of vector sketches with implicit neural models. A variable length vector sketch is compressed into a latent space of fixed dimension that implicitly encodes the underlying shape as a function of time and strokes. The learned function predicts the $xy$ point coordinates in a sketch at each time and stroke. Despite its simplicity, SketchINR outperforms existing representations at multiple tasks: (i) Encoding an entire sketch dataset into a fixed size latent vector, SketchINR gives $60\\times$ and $10\\times$ data compression over raster and vector sketches, respectively. (ii) SketchINR's auto-decoder provides a much higher-fidelity representation than other learned vector sketch representations, and is uniquely able to scale to complex vector sketches such as FS-COCO. (iii) SketchINR supports parallelisation that can decode/render $\\sim$$100\\times$ faster than other learned vector represe",
    "path": "papers/24/03/2403.09344.json",
    "total_tokens": 931,
    "translated_title": "SketchINR：将素描作为隐式神经表示的初探",
    "translated_abstract": "我们提出了SketchINR，旨在通过隐式神经模型推进矢量素描的表示。可变长度的矢量素描被压缩到固定维度的潜在空间中，隐式地将基础形状编码为时间和笔画的函数。学习的函数在每个时间和笔画上预测素描中的$ xy $点坐标。尽管简单，SketchINR在多个任务上优于现有表示：（i）将整个素描数据集编码为固定大小的潜在矢量时，SketchINR相比光栅和矢量素描，分别提供了$60\\times$和$10\\times$的数据压缩。 （ii）SketchINR的自动解码器提供比其他学习的矢量素描表示更高保真度的表示，并且能够独特地适应复杂的矢量素描，如FS-COCO。 （iii）SketchINR支持可以比其他学习的矢量表示解码/渲染快约约$\\sim$$100\\times$的并行化。",
    "tldr": "SketchINR将矢量素描压缩到固定维度的潜在空间中，通过隐式神经模型编码素描的形状，并在多个任务上表现优异，包括数据压缩、高保真度的表示以及快速解码渲染。",
    "en_tdlr": "SketchINR compresses vector sketches into a fixed-dimensional latent space, encodes the shape implicitly with neural models, and outperforms existing representations in tasks like data compression, high-fidelity representation, and fast decoding/rendering."
}