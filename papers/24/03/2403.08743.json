{
    "title": "Steering LLMs Towards Unbiased Responses: A Causality-Guided Debiasing Framework",
    "abstract": "arXiv:2403.08743v1 Announce Type: cross  Abstract: Large language models (LLMs) can easily generate biased and discriminative responses. As LLMs tap into consequential decision-making (e.g., hiring and healthcare), it is of crucial importance to develop strategies to mitigate these biases. This paper focuses on social bias, tackling the association between demographic information and LLM outputs. We propose a causality-guided debiasing framework that utilizes causal understandings of (1) the data-generating process of the training corpus fed to LLMs, and (2) the internal reasoning process of LLM inference, to guide the design of prompts for debiasing LLM outputs through selection mechanisms. Our framework unifies existing de-biasing prompting approaches such as inhibitive instructions and in-context contrastive examples, and sheds light on new ways of debiasing by encouraging bias-free reasoning. Our strong empirical performance on real-world datasets demonstrates that our framework pr",
    "link": "https://arxiv.org/abs/2403.08743",
    "context": "Title: Steering LLMs Towards Unbiased Responses: A Causality-Guided Debiasing Framework\nAbstract: arXiv:2403.08743v1 Announce Type: cross  Abstract: Large language models (LLMs) can easily generate biased and discriminative responses. As LLMs tap into consequential decision-making (e.g., hiring and healthcare), it is of crucial importance to develop strategies to mitigate these biases. This paper focuses on social bias, tackling the association between demographic information and LLM outputs. We propose a causality-guided debiasing framework that utilizes causal understandings of (1) the data-generating process of the training corpus fed to LLMs, and (2) the internal reasoning process of LLM inference, to guide the design of prompts for debiasing LLM outputs through selection mechanisms. Our framework unifies existing de-biasing prompting approaches such as inhibitive instructions and in-context contrastive examples, and sheds light on new ways of debiasing by encouraging bias-free reasoning. Our strong empirical performance on real-world datasets demonstrates that our framework pr",
    "path": "papers/24/03/2403.08743.json",
    "total_tokens": 854,
    "translated_title": "将LLMs引导到无偏响应：基于因果关系的去偏倾框架",
    "translated_abstract": "大型语言模型（LLMs）很容易产生偏见和歧视性的响应。由于LLMs涉及到重要的决策制定（例如招聘和医疗保健），开发减轻这些偏见的策略至关重要。本文侧重于社会偏见，解决了人口统计信息与LLM输出之间的关联。我们提出了一种基于因果关系的去偏倾框架，利用对LLMs输入的训练语料库的数据生成过程以及LLM推理的内部推理过程的因果理解，通过选择机制指导去偏倾LLM输出的提示设计。我们的框架统一了现有的去偏指示方法，如抑制指令和上下文对比例子，并通过鼓励无偏推理的方法，启示了新的去偏倾方式。我们在真实数据集上的强大实证表现表明，我们的框架可以",
    "tldr": "本文提出了一种基于因果关系的去偏倾框架，通过选择机制指导设计提示来减少大型语言模型(LLMs)产生的社会偏见。",
    "en_tdlr": "This paper introduces a causality-guided debiasing framework that mitigates social bias in large language models (LLMs) by guiding the design of prompts through selection mechanisms."
}