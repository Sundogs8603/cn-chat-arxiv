{
    "title": "Reliable, Adaptable, and Attributable Language Models with Retrieval",
    "abstract": "arXiv:2403.03187v1 Announce Type: cross  Abstract: Parametric language models (LMs), which are trained on vast amounts of web data, exhibit remarkable flexibility and capability. However, they still face practical challenges such as hallucinations, difficulty in adapting to new data distributions, and a lack of verifiability. In this position paper, we advocate for retrieval-augmented LMs to replace parametric LMs as the next generation of LMs. By incorporating large-scale datastores during inference, retrieval-augmented LMs can be more reliable, adaptable, and attributable. Despite their potential, retrieval-augmented LMs have yet to be widely adopted due to several obstacles: specifically, current retrieval-augmented LMs struggle to leverage helpful text beyond knowledge-intensive tasks such as question answering, have limited interaction between retrieval and LM components, and lack the infrastructure for scaling. To address these, we propose a roadmap for developing general-purpose",
    "link": "https://arxiv.org/abs/2403.03187",
    "context": "Title: Reliable, Adaptable, and Attributable Language Models with Retrieval\nAbstract: arXiv:2403.03187v1 Announce Type: cross  Abstract: Parametric language models (LMs), which are trained on vast amounts of web data, exhibit remarkable flexibility and capability. However, they still face practical challenges such as hallucinations, difficulty in adapting to new data distributions, and a lack of verifiability. In this position paper, we advocate for retrieval-augmented LMs to replace parametric LMs as the next generation of LMs. By incorporating large-scale datastores during inference, retrieval-augmented LMs can be more reliable, adaptable, and attributable. Despite their potential, retrieval-augmented LMs have yet to be widely adopted due to several obstacles: specifically, current retrieval-augmented LMs struggle to leverage helpful text beyond knowledge-intensive tasks such as question answering, have limited interaction between retrieval and LM components, and lack the infrastructure for scaling. To address these, we propose a roadmap for developing general-purpose",
    "path": "papers/24/03/2403.03187.json",
    "total_tokens": 739,
    "translated_title": "具有检索功能的可靠、适应性强且可追溯的语言模型",
    "translated_abstract": "参数化语言模型（LMs）在海量网络数据上训练，表现出卓越的灵活性和能力。然而，它们仍然面临着幻觉、难以适应新数据分布和缺乏可验证性等实际挑战。在这篇立场论文中，我们主张用具备检索功能的LMs取代参数化LMs作为下一代LMs。通过在推理过程中整合大规模数据存储，具有检索功能的LMs可以更加可靠、适应性更强、可追溯。",
    "tldr": "持续面临挑战的参数化语言模型LMs，作者主张使用具有检索功能的LMs作为下一代LMs，以提高可靠性、适应性和可追溯性。",
    "en_tdlr": "Advocating for the adoption of retrieval-augmented LMs as the next generation of LMs to address challenges faced by parametric LMs, enhancing reliability, adaptability, and traceability."
}