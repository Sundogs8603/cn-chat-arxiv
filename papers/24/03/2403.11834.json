{
    "title": "Towards Understanding the Relationship between In-context Learning and Compositional Generalization",
    "abstract": "arXiv:2403.11834v1 Announce Type: new  Abstract: According to the principle of compositional generalization, the meaning of a complex expression can be understood as a function of the meaning of its parts and of how they are combined. This principle is crucial for human language processing and also, arguably, for NLP models in the face of out-of-distribution data. However, many neural network models, including Transformers, have been shown to struggle with compositional generalization. In this paper, we hypothesize that forcing models to in-context learn can provide an inductive bias to promote compositional generalization. To test this hypothesis, we train a causal Transformer in a setting that renders ordinary learning very difficult: we present it with different orderings of the training instance and shuffle instance labels. This corresponds to training the model on all possible few-shot learning problems attainable from the dataset. The model can solve the task, however, by utilizi",
    "link": "https://arxiv.org/abs/2403.11834",
    "context": "Title: Towards Understanding the Relationship between In-context Learning and Compositional Generalization\nAbstract: arXiv:2403.11834v1 Announce Type: new  Abstract: According to the principle of compositional generalization, the meaning of a complex expression can be understood as a function of the meaning of its parts and of how they are combined. This principle is crucial for human language processing and also, arguably, for NLP models in the face of out-of-distribution data. However, many neural network models, including Transformers, have been shown to struggle with compositional generalization. In this paper, we hypothesize that forcing models to in-context learn can provide an inductive bias to promote compositional generalization. To test this hypothesis, we train a causal Transformer in a setting that renders ordinary learning very difficult: we present it with different orderings of the training instance and shuffle instance labels. This corresponds to training the model on all possible few-shot learning problems attainable from the dataset. The model can solve the task, however, by utilizi",
    "path": "papers/24/03/2403.11834.json",
    "total_tokens": 779,
    "translated_title": "探索上下文学习与构成概括之间的关系",
    "translated_abstract": "根据构成概括原则，复杂表达的含义可以理解为其部分含义及它们如何组合的函数。这一原则对于人类语言处理至关重要，同时，可以说对于面对超出分布数据的NLP模型也是重要的。然而，许多神经网络模型，包括Transformer，在构成概括方面表现不佳。本文假设强制模型进行上下文学习可以提供归纳偏见以促进构成概括。为了验证这一假设，我们在一个使普通学习非常困难的环境中训练了一个因果Transformer：我们向其提供不同排序的训练实例并洗牌实例标签。这相当于在数据集中训练模型解决所有可能的少样本学习问题。模型可以解决任务，然而，通过利用",
    "tldr": "强制模型进行上下文学习可能有助于促进神经网络模型的构成概括能力",
    "en_tdlr": "Forcing models to learn in context may help promote the compositional generalization ability of neural network models."
}