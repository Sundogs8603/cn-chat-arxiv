{
    "title": "Improving Text-to-Image Consistency via Automatic Prompt Optimization",
    "abstract": "arXiv:2403.17804v1 Announce Type: cross  Abstract: Impressive advances in text-to-image (T2I) generative models have yielded a plethora of high performing models which are able to generate aesthetically appealing, photorealistic images. Despite the progress, these models still struggle to produce images that are consistent with the input prompt, oftentimes failing to capture object quantities, relations and attributes properly. Existing solutions to improve prompt-image consistency suffer from the following challenges: (1) they oftentimes require model fine-tuning, (2) they only focus on nearby prompt samples, and (3) they are affected by unfavorable trade-offs among image quality, representation diversity, and prompt-image consistency. In this paper, we address these challenges and introduce a T2I optimization-by-prompting framework, OPT2I, which leverages a large language model (LLM) to improve prompt-image consistency in T2I models. Our framework starts from a user prompt and iterat",
    "link": "https://arxiv.org/abs/2403.17804",
    "context": "Title: Improving Text-to-Image Consistency via Automatic Prompt Optimization\nAbstract: arXiv:2403.17804v1 Announce Type: cross  Abstract: Impressive advances in text-to-image (T2I) generative models have yielded a plethora of high performing models which are able to generate aesthetically appealing, photorealistic images. Despite the progress, these models still struggle to produce images that are consistent with the input prompt, oftentimes failing to capture object quantities, relations and attributes properly. Existing solutions to improve prompt-image consistency suffer from the following challenges: (1) they oftentimes require model fine-tuning, (2) they only focus on nearby prompt samples, and (3) they are affected by unfavorable trade-offs among image quality, representation diversity, and prompt-image consistency. In this paper, we address these challenges and introduce a T2I optimization-by-prompting framework, OPT2I, which leverages a large language model (LLM) to improve prompt-image consistency in T2I models. Our framework starts from a user prompt and iterat",
    "path": "papers/24/03/2403.17804.json",
    "total_tokens": 880,
    "translated_title": "通过自动提示优化改进文本到图像的一致性",
    "translated_abstract": "arXiv:2403.17804v1 公告类型: 交叉 摘要: 文本到图像（T2I）生成模型取得了令人印象深刻的进展，产生了大量性能优越的模型，能够生成审美吸引人、逼真的图像。尽管取得了进展，这些模型仍然难以生成与输入提示一致的图像，常常无法正确捕捉物体数量、关系和属性。现有的解决方案改进提示-图像一致性面临以下挑战：（1）它们常常需要对模型进行微调，（2）它们仅关注附近的提示样本，（3）它们受到图像质量、表示多样性和提示-图像一致性之间不利权衡的影响。本文中，我们解决了这些挑战，并引入了一种 T2I 通过提示优化的框架 OPT2I，利用大型语言模型（LLM）改进 T2I 模型中的提示-图像一致性。我们的框架从用户提示开始，不断迭代。",
    "tldr": "本文提出了一个 T2I 优化通过提示的框架 OPT2I，利用大型语言模型（LLM）来改进 T2I 模型中的提示-图像一致性。",
    "en_tdlr": "This paper introduces a framework OPT2I for optimizing T2I models through prompts, leveraging a large language model (LLM) to improve the prompt-image consistency."
}