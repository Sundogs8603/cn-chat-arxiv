{
    "title": "CRM: Single Image to 3D Textured Mesh with Convolutional Reconstruction Model",
    "abstract": "arXiv:2403.05034v1 Announce Type: cross  Abstract: Feed-forward 3D generative models like the Large Reconstruction Model (LRM) have demonstrated exceptional generation speed. However, the transformer-based methods do not leverage the geometric priors of the triplane component in their architecture, often leading to sub-optimal quality given the limited size of 3D data and slow training. In this work, we present the Convolutional Reconstruction Model (CRM), a high-fidelity feed-forward single image-to-3D generative model. Recognizing the limitations posed by sparse 3D data, we highlight the necessity of integrating geometric priors into network design. CRM builds on the key observation that the visualization of triplane exhibits spatial correspondence of six orthographic images. First, it generates six orthographic view images from a single input image, then feeds these images into a convolutional U-Net, leveraging its strong pixel-level alignment capabilities and significant bandwidth ",
    "link": "https://arxiv.org/abs/2403.05034",
    "context": "Title: CRM: Single Image to 3D Textured Mesh with Convolutional Reconstruction Model\nAbstract: arXiv:2403.05034v1 Announce Type: cross  Abstract: Feed-forward 3D generative models like the Large Reconstruction Model (LRM) have demonstrated exceptional generation speed. However, the transformer-based methods do not leverage the geometric priors of the triplane component in their architecture, often leading to sub-optimal quality given the limited size of 3D data and slow training. In this work, we present the Convolutional Reconstruction Model (CRM), a high-fidelity feed-forward single image-to-3D generative model. Recognizing the limitations posed by sparse 3D data, we highlight the necessity of integrating geometric priors into network design. CRM builds on the key observation that the visualization of triplane exhibits spatial correspondence of six orthographic images. First, it generates six orthographic view images from a single input image, then feeds these images into a convolutional U-Net, leveraging its strong pixel-level alignment capabilities and significant bandwidth ",
    "path": "papers/24/03/2403.05034.json",
    "total_tokens": 940,
    "translated_title": "CRM：使用卷积重建模型将单张图像转换为3D纹理网格",
    "translated_abstract": "arXiv:2403.05034v1 公告类型：跨领域 摘要：像大型重建模型（LRM）这样的前馈3D生成模型已经展示出极高的生成速度。然而，基于Transformer的方法没有利用其架构中三平面组件的几何先验，常常导致由于3D数据量有限和训练速度慢而达不到最佳质量。在这项工作中，我们提出了卷积重建模型（CRM），一个高保真度的前馈单图像到3D生成模型。认识到稀疏3D数据带来的限制，我们强调了将几何先验整合到网络设计中的必要性。CRM建立在以下关键观察的基础上，即三平面的可视化展示了六个正交图像的空间对应关系。首先，它从单个输入图像生成六个正交视图图像，然后将这些图像馈入卷积U-Net，利用其强大的像素级对齐能力和显著的带宽。",
    "tldr": "CRM提出了一种高保真度的前馈单图像到3D生成模型，通过将三平面的几何先验整合到网络设计中，实现了从单个输入图像生成六个正交视图图像，然后利用卷积U-Net进行处理，从而提高了生成质量和速度。"
}