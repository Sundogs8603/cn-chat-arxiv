{
    "title": "An Analysis of Human Alignment of Latent Diffusion Models",
    "abstract": "arXiv:2403.08469v1 Announce Type: new  Abstract: Diffusion models, trained on large amounts of data, showed remarkable performance for image synthesis. They have high error consistency with humans and low texture bias when used for classification. Furthermore, prior work demonstrated the decomposability of their bottleneck layer representations into semantic directions. In this work, we analyze how well such representations are aligned to human responses on a triplet odd-one-out task. We find that despite the aforementioned observations: I) The representational alignment with humans is comparable to that of models trained only on ImageNet-1k. II) The most aligned layers of the denoiser U-Net are intermediate layers and not the bottleneck. III) Text conditioning greatly improves alignment at high noise levels, hinting at the importance of abstract textual information, especially in the early stage of generation.",
    "link": "https://arxiv.org/abs/2403.08469",
    "context": "Title: An Analysis of Human Alignment of Latent Diffusion Models\nAbstract: arXiv:2403.08469v1 Announce Type: new  Abstract: Diffusion models, trained on large amounts of data, showed remarkable performance for image synthesis. They have high error consistency with humans and low texture bias when used for classification. Furthermore, prior work demonstrated the decomposability of their bottleneck layer representations into semantic directions. In this work, we analyze how well such representations are aligned to human responses on a triplet odd-one-out task. We find that despite the aforementioned observations: I) The representational alignment with humans is comparable to that of models trained only on ImageNet-1k. II) The most aligned layers of the denoiser U-Net are intermediate layers and not the bottleneck. III) Text conditioning greatly improves alignment at high noise levels, hinting at the importance of abstract textual information, especially in the early stage of generation.",
    "path": "papers/24/03/2403.08469.json",
    "total_tokens": 871,
    "translated_title": "人类对潜在扩散模型的排列分析",
    "translated_abstract": "潜在扩散模型在大量数据训练下，展现出在图像合成方面出色的性能。当用于分类时，它们与人类有高误差一致性和低纹理偏差。此外，先前的工作证明了它们的瓶颈层表示可以分解为语义方向。在这项研究中，我们分析了这些表示与人类在三元奇一奇任务上对齐的情况。我们发现，尽管前述观察到：I）与人类的表示对齐性与仅在ImageNet-1k上训练的模型相媲美。II）去噪U-Net的最对齐层是中间层而不是瓶颈。III）文本调节为高噪声水平提高了对齐性，暗示着抽象文本信息的重要性，尤其是在生成的早期阶段。",
    "tldr": "分析了潜在扩散模型的排列对人类响应的对齐情况，并发现模型的对齐性与ImageNet-1k相当，去噪U-Net的最对齐层是中间层而不是瓶颈，并且文本调节在高噪声水平下提高了对齐性。",
    "en_tdlr": "An analysis of the alignment of latent diffusion models with human responses revealed comparable alignment to ImageNet-1k, the most aligned layers of the denoiser U-Net were found to be intermediate layers rather than the bottleneck, and text conditioning improved alignment at high noise levels."
}