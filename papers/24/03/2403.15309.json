{
    "title": "Controlled Training Data Generation with Diffusion Models",
    "abstract": "arXiv:2403.15309v1 Announce Type: cross  Abstract: In this work, we present a method to control a text-to-image generative model to produce training data specifically \"useful\" for supervised learning. Unlike previous works that employ an open-loop approach and pre-define prompts to generate new data using either a language model or human expertise, we develop an automated closed-loop system which involves two feedback mechanisms. The first mechanism uses feedback from a given supervised model and finds adversarial prompts that result in image generations that maximize the model loss. While these adversarial prompts result in diverse data informed by the model, they are not informed of the target distribution, which can be inefficient. Therefore, we introduce the second feedback mechanism that guides the generation process towards a certain target distribution. We call the method combining these two mechanisms Guided Adversarial Prompts. We perform our evaluations on different tasks, da",
    "link": "https://arxiv.org/abs/2403.15309",
    "context": "Title: Controlled Training Data Generation with Diffusion Models\nAbstract: arXiv:2403.15309v1 Announce Type: cross  Abstract: In this work, we present a method to control a text-to-image generative model to produce training data specifically \"useful\" for supervised learning. Unlike previous works that employ an open-loop approach and pre-define prompts to generate new data using either a language model or human expertise, we develop an automated closed-loop system which involves two feedback mechanisms. The first mechanism uses feedback from a given supervised model and finds adversarial prompts that result in image generations that maximize the model loss. While these adversarial prompts result in diverse data informed by the model, they are not informed of the target distribution, which can be inefficient. Therefore, we introduce the second feedback mechanism that guides the generation process towards a certain target distribution. We call the method combining these two mechanisms Guided Adversarial Prompts. We perform our evaluations on different tasks, da",
    "path": "papers/24/03/2403.15309.json",
    "total_tokens": 841,
    "translated_title": "使用扩散模型生成控制训练数据",
    "translated_abstract": "在这项工作中，我们提出了一种方法，可以控制文本到图像生成模型以生成训练数据，专门用于监督学习。与之前那些采用开环方法并预先定义提示词来使用语言模型或人类专业知识生成新数据的作品不同，我们开发了一种自动闭环系统，其中包括两个反馈机制。第一个机制使用来自给定监督模型的反馈，并找到导致图像生成最大化模型损失的对抗提示词。虽然这些对抗提示词导致了经过模型训练的多样化数据生成，但它们并不知道目标分布，这可能效率低下。因此，我们引入第二个反馈机制，将生成过程引导到特定目标分布。我们称将这两个机制结合起来的方法为引导对抗提示词。我们在不同任务上进行评估。",
    "tldr": "提出了一种使用扩散模型生成控制训练数据的方法，通过两个反馈机制，一方面使用监督模型反馈找到对抗性提示词实现图像生成，另一方面通过引导使生成过程朝向特定目标分布。"
}