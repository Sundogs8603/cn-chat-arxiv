{
    "title": "Pencil: Private and Extensible Collaborative Learning without the Non-Colluding Assumption",
    "abstract": "arXiv:2403.11166v1 Announce Type: cross  Abstract: The escalating focus on data privacy poses significant challenges for collaborative neural network training, where data ownership and model training/deployment responsibilities reside with distinct entities. Our community has made substantial contributions to addressing this challenge, proposing various approaches such as federated learning (FL) and privacy-preserving machine learning based on cryptographic constructs like homomorphic encryption (HE) and secure multiparty computation (MPC). However, FL completely overlooks model privacy, and HE has limited extensibility (confined to only one data provider). While the state-of-the-art MPC frameworks provide reasonable throughput and simultaneously ensure model/data privacy, they rely on a critical non-colluding assumption on the computing servers, and relaxing this assumption is still an open problem.   In this paper, we present Pencil, the first private training framework for collabora",
    "link": "https://arxiv.org/abs/2403.11166",
    "context": "Title: Pencil: Private and Extensible Collaborative Learning without the Non-Colluding Assumption\nAbstract: arXiv:2403.11166v1 Announce Type: cross  Abstract: The escalating focus on data privacy poses significant challenges for collaborative neural network training, where data ownership and model training/deployment responsibilities reside with distinct entities. Our community has made substantial contributions to addressing this challenge, proposing various approaches such as federated learning (FL) and privacy-preserving machine learning based on cryptographic constructs like homomorphic encryption (HE) and secure multiparty computation (MPC). However, FL completely overlooks model privacy, and HE has limited extensibility (confined to only one data provider). While the state-of-the-art MPC frameworks provide reasonable throughput and simultaneously ensure model/data privacy, they rely on a critical non-colluding assumption on the computing servers, and relaxing this assumption is still an open problem.   In this paper, we present Pencil, the first private training framework for collabora",
    "path": "papers/24/03/2403.11166.json",
    "total_tokens": 864,
    "translated_title": "铅笔：无需非共谋假设的私密可扩展协作学习",
    "translated_abstract": "随着对数据隐私的关注不断提升，协作神经网络训练面临着重大挑战，其中数据所有权以及模型训练/部署责任分属于不同实体。我们的社区在解决这一挑战方面做出了重大贡献，提出了各种方法，如联合学习（FL）和基于同态加密（HE）和安全多方计算（MPC）等密码构造的隐私保护机器学习。然而，FL完全忽视了模型隐私，HE的可扩展性有限（仅限于一家数据提供者）。尽管最先进的MPC框架提供了合理的吞吐量并同时确保了模型/数据隐私，但它们依赖于在计算服务器上假设的关键非共谋假设，放松这一假设仍然是一个未解之谜。在本文中，我们提出了Pencil，这是第一个用于协作训练的私密训练框架。",
    "tldr": "Pencil是第一个解决协作神经网络训练数据隐私挑战的框架，兼顾模型和数据隐私，不依赖非共谋假设。",
    "en_tdlr": "Pencil is the first framework to address the challenge of data privacy in collaborative neural network training, considering both model and data privacy without relying on the non-colluding assumption."
}