{
    "title": "Detecting Concrete Visual Tokens for Multimodal Machine Translation",
    "abstract": "arXiv:2403.03075v1 Announce Type: new  Abstract: The challenge of visual grounding and masking in multimodal machine translation (MMT) systems has encouraged varying approaches to the detection and selection of visually-grounded text tokens for masking. We introduce new methods for detection of visually and contextually relevant (concrete) tokens from source sentences, including detection with natural language processing (NLP), detection with object detection, and a joint detection-verification technique. We also introduce new methods for selection of detected tokens, including shortest $n$ tokens, longest $n$ tokens, and all detected concrete tokens. We utilize the GRAM MMT architecture to train models against synthetically collated multimodal datasets of source images with masked sentences, showing performance improvements and improved usage of visual context during translation tasks over the baseline model.",
    "link": "https://arxiv.org/abs/2403.03075",
    "context": "Title: Detecting Concrete Visual Tokens for Multimodal Machine Translation\nAbstract: arXiv:2403.03075v1 Announce Type: new  Abstract: The challenge of visual grounding and masking in multimodal machine translation (MMT) systems has encouraged varying approaches to the detection and selection of visually-grounded text tokens for masking. We introduce new methods for detection of visually and contextually relevant (concrete) tokens from source sentences, including detection with natural language processing (NLP), detection with object detection, and a joint detection-verification technique. We also introduce new methods for selection of detected tokens, including shortest $n$ tokens, longest $n$ tokens, and all detected concrete tokens. We utilize the GRAM MMT architecture to train models against synthetically collated multimodal datasets of source images with masked sentences, showing performance improvements and improved usage of visual context during translation tasks over the baseline model.",
    "path": "papers/24/03/2403.03075.json",
    "total_tokens": 825,
    "translated_title": "检测具体视觉令牌以进行多模态机器翻译",
    "translated_abstract": "在多模态机器翻译（MMT）系统中，视觉基础和遮蔽的挑战促使了对检测和选择用于遮蔽的视觉基础文本令牌的不同方法。我们介绍了用于从源句中检测视觉上和语境上相关（具体）令牌的新方法，包括自然语言处理（NLP）检测，物体检测检测和联合检测-验证技术。我们还介绍了用于选择检测到的令牌的新方法，包括最短$n$ 个令牌、最长$n$ 个令牌以及所有检测到的具体令牌。我们利用GRAM MMT 架构针对合成整理的多模态数据集即源图像与遮蔽句子进行模型训练，表现出相比基准模型的性能改进和在翻译任务中对视觉上下文的更好利用。",
    "tldr": "提出新方法用于检测和选择在多模态机器翻译中具体的视觉相关令牌，通过这些方法，在翻译任务中实现了性能的改进和更好的视觉上下文利用",
    "en_tdlr": "Introducing new methods for detecting and selecting visually concrete tokens in multimodal machine translation led to performance improvements and enhanced utilization of visual context in translation tasks."
}