{
    "title": "Scalable Learning of Item Response Theory Models",
    "abstract": "arXiv:2403.00680v1 Announce Type: new  Abstract: Item Response Theory (IRT) models aim to assess latent abilities of $n$ examinees along with latent difficulty characteristics of $m$ test items from categorical data that indicates the quality of their corresponding answers. Classical psychometric assessments are based on a relatively small number of examinees and items, say a class of $200$ students solving an exam comprising $10$ problems. More recent global large scale assessments such as PISA, or internet studies, may lead to significantly increased numbers of participants. Additionally, in the context of Machine Learning where algorithms take the role of examinees and data analysis problems take the role of items, both $n$ and $m$ may become very large, challenging the efficiency and scalability of computations. To learn the latent variables in IRT models from large data, we leverage the similarity of these models to logistic regression, which can be approximated accurately using s",
    "link": "https://arxiv.org/abs/2403.00680",
    "context": "Title: Scalable Learning of Item Response Theory Models\nAbstract: arXiv:2403.00680v1 Announce Type: new  Abstract: Item Response Theory (IRT) models aim to assess latent abilities of $n$ examinees along with latent difficulty characteristics of $m$ test items from categorical data that indicates the quality of their corresponding answers. Classical psychometric assessments are based on a relatively small number of examinees and items, say a class of $200$ students solving an exam comprising $10$ problems. More recent global large scale assessments such as PISA, or internet studies, may lead to significantly increased numbers of participants. Additionally, in the context of Machine Learning where algorithms take the role of examinees and data analysis problems take the role of items, both $n$ and $m$ may become very large, challenging the efficiency and scalability of computations. To learn the latent variables in IRT models from large data, we leverage the similarity of these models to logistic regression, which can be approximated accurately using s",
    "path": "papers/24/03/2403.00680.json",
    "total_tokens": 857,
    "translated_title": "可扩展的项目反应理论模型学习",
    "translated_abstract": "项目反应理论（IRT）模型旨在评估 $n$ 名考生的潜在能力以及 $m$ 个测验项目的隐含难度特征，这些项目是从表明其对应答案质量的分类数据中得出的。传统的心理测量评估基于相对较少的考生和项目，例如一个由 $200$ 名学生解决包含 $10$ 道题目的考试的班级。而近年来的全球大规模评估，如PISA，或互联网研究，可能导致参与者数量显著增加。此外，在机器学习领域，算法扮演考生角色，数据分析问题扮演项目角色，$n$ 和 $m$ 都可能变得非常大，挑战计算的效率和可伸缩性。为了从大数据中学习IRT模型中的潜在变量，我们利用这些模型与逻辑回归之间的相似性，后者可以使用s准确地近似。",
    "tldr": "该论文提出了一种从大数据中学习项目反应理论模型中的潜在变量的方法，利用这些模型与逻辑回归之间的相似性来提高计算的效率和可伸缩性。"
}