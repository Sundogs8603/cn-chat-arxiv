{
    "title": "Parallel Algorithms for Exact Enumeration of Deep Neural Network Activation Regions",
    "abstract": "arXiv:2403.00860v1 Announce Type: cross  Abstract: A feedforward neural network using rectified linear units constructs a mapping from inputs to outputs by partitioning its input space into a set of convex regions where points within a region share a single affine transformation. In order to understand how neural networks work, when and why they fail, and how they compare to biological intelligence, we need to understand the organization and formation of these regions. Step one is to design and implement algorithms for exact region enumeration in networks beyond toy examples.   In this work, we present parallel algorithms for exact enumeration in deep (and shallow) neural networks. Our work has three main contributions: (1) we present a novel algorithm framework and parallel algorithms for region enumeration; (2) we implement one of our algorithms on a variety of network architectures and experimentally show how the number of regions dictates runtime; and (3) we show, using our algorit",
    "link": "https://arxiv.org/abs/2403.00860",
    "context": "Title: Parallel Algorithms for Exact Enumeration of Deep Neural Network Activation Regions\nAbstract: arXiv:2403.00860v1 Announce Type: cross  Abstract: A feedforward neural network using rectified linear units constructs a mapping from inputs to outputs by partitioning its input space into a set of convex regions where points within a region share a single affine transformation. In order to understand how neural networks work, when and why they fail, and how they compare to biological intelligence, we need to understand the organization and formation of these regions. Step one is to design and implement algorithms for exact region enumeration in networks beyond toy examples.   In this work, we present parallel algorithms for exact enumeration in deep (and shallow) neural networks. Our work has three main contributions: (1) we present a novel algorithm framework and parallel algorithms for region enumeration; (2) we implement one of our algorithms on a variety of network architectures and experimentally show how the number of regions dictates runtime; and (3) we show, using our algorit",
    "path": "papers/24/03/2403.00860.json",
    "total_tokens": 754,
    "translated_title": "深度神经网络激活区域的精确枚举并行算法",
    "translated_abstract": "一种使用修正线性单元的前馈神经网络通过将其输入空间划分为一组凸区域来构建从输入到输出的映射，区域内的点共享单一仿射变换。为了理解神经网络的工作原理、失败原因以及与生物智能的比较，我们需要理解这些区域的组织和形成。本文介绍了精确枚举深度（和浅层）神经网络的并行算法。",
    "tldr": "本研究提出了深度（和浅层）神经网络中精确枚举的并行算法，主要贡献包括新颖的算法框架和并行算法，实现了其中一种算法在多种网络架构上，并实验证明区域数量对运行时间的影响。",
    "en_tdlr": "This work introduces parallel algorithms for exact enumeration in deep (and shallow) neural networks, with main contributions including a novel algorithm framework and parallel algorithms, implementation on various network architectures, and experimental demonstration of how the number of regions affects runtime."
}