{
    "title": "DreamMotion: Space-Time Self-Similarity Score Distillation for Zero-Shot Video Editing",
    "abstract": "arXiv:2403.12002v1 Announce Type: cross  Abstract: Text-driven diffusion-based video editing presents a unique challenge not encountered in image editing literature: establishing real-world motion. Unlike existing video editing approaches, here we focus on score distillation sampling to circumvent the standard reverse diffusion process and initiate optimization from videos that already exhibit natural motion. Our analysis reveals that while video score distillation can effectively introduce new content indicated by target text, it can also cause significant structure and motion deviation. To counteract this, we propose to match space-time self-similarities of the original video and the edited video during the score distillation. Thanks to the use of score distillation, our approach is model-agnostic, which can be applied for both cascaded and non-cascaded video diffusion frameworks. Through extensive comparisons with leading methods, our approach demonstrates its superiority in alterin",
    "link": "https://arxiv.org/abs/2403.12002",
    "context": "Title: DreamMotion: Space-Time Self-Similarity Score Distillation for Zero-Shot Video Editing\nAbstract: arXiv:2403.12002v1 Announce Type: cross  Abstract: Text-driven diffusion-based video editing presents a unique challenge not encountered in image editing literature: establishing real-world motion. Unlike existing video editing approaches, here we focus on score distillation sampling to circumvent the standard reverse diffusion process and initiate optimization from videos that already exhibit natural motion. Our analysis reveals that while video score distillation can effectively introduce new content indicated by target text, it can also cause significant structure and motion deviation. To counteract this, we propose to match space-time self-similarities of the original video and the edited video during the score distillation. Thanks to the use of score distillation, our approach is model-agnostic, which can be applied for both cascaded and non-cascaded video diffusion frameworks. Through extensive comparisons with leading methods, our approach demonstrates its superiority in alterin",
    "path": "papers/24/03/2403.12002.json",
    "total_tokens": 880,
    "translated_title": "DreamMotion：用于零样本视频编辑的时空自相似性分数蒸馏",
    "translated_abstract": "arXiv:2403.12002v1 公告类型：跨领域 摘要：基于文本驱动的扩散式视频编辑在图像编辑文献中显现了一项独特挑战：建立真实世界运动。与现有的视频编辑方法不同，我们在这里专注于分数蒸馏采样，以规避标准的反向扩散过程，并从已展现自然运动的视频中启动优化。我们的分析表明，虽然视频分数蒸馏可以有效地引入目标文本指示的新内容，但也可能导致显著的结构和运动偏差。为了抵消这一点，我们提出在分数蒸馏过程中匹配原始视频和编辑视频的时空自相似性。由于使用了分数蒸馏，我们的方法与模型无关，可应用于级联和非级联视频扩散框架。通过与领先方法的广泛比较，我们的方法展示了在视频编辑中的卓越优势。",
    "tldr": "该方法提出了一种用于零样本视频编辑的新方法，通过匹配原始视频和编辑视频的时空自相似性，在分数蒸馏过程中解决了新内容引入时可能出现的结构和运动偏差问题。",
    "en_tdlr": "This paper introduces a novel method for zero-shot video editing that addresses the potential structure and motion deviations when introducing new content by matching the space-time self-similarities between the original and edited videos during score distillation."
}