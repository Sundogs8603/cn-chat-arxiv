{
    "title": "Enhancing Data Quality in Federated Fine-Tuning of Foundation Models",
    "abstract": "arXiv:2403.04529v1 Announce Type: cross  Abstract: In the current landscape of foundation model training, there is a significant reliance on public domain data, which is nearing exhaustion according to recent research. To further scale up, it is crucial to incorporate collaboration among multiple specialized and high-quality private domain data sources. However, the challenge of training models locally without sharing private data presents numerous obstacles in data quality control. To tackle this issue, we propose a data quality control pipeline for federated fine-tuning of foundation models. This pipeline computes scores reflecting the quality of training data and determines a global threshold for a unified standard, aiming for improved global performance. Our experiments show that the proposed quality control pipeline facilitates the effectiveness and reliability of the model training, leading to better performance.",
    "link": "https://arxiv.org/abs/2403.04529",
    "context": "Title: Enhancing Data Quality in Federated Fine-Tuning of Foundation Models\nAbstract: arXiv:2403.04529v1 Announce Type: cross  Abstract: In the current landscape of foundation model training, there is a significant reliance on public domain data, which is nearing exhaustion according to recent research. To further scale up, it is crucial to incorporate collaboration among multiple specialized and high-quality private domain data sources. However, the challenge of training models locally without sharing private data presents numerous obstacles in data quality control. To tackle this issue, we propose a data quality control pipeline for federated fine-tuning of foundation models. This pipeline computes scores reflecting the quality of training data and determines a global threshold for a unified standard, aiming for improved global performance. Our experiments show that the proposed quality control pipeline facilitates the effectiveness and reliability of the model training, leading to better performance.",
    "path": "papers/24/03/2403.04529.json",
    "total_tokens": 764,
    "translated_title": "在联邦微调基础模型中提升数据质量",
    "translated_abstract": "基础模型训练的当前情景中，存在着对公共领域数据的显著依赖，而根据最近的研究，这些数据已接近枯竭。为了进一步扩大规模，将多个专业化和高质量的私有领域数据源进行协作是至关重要的。然而，在不共享私有数据的情况下地方性训练模型所面临的数据质量控制问题是具有挑战性的。为了解决这一问题，我们提出了一个用于联邦微调基础模型的数据质量控制管道。该管道计算反映训练数据质量的分数，并确定一个全局阈值以实现统一标准，旨在提高全局性能。我们的实验表明，所提出的质量控制管道促进了模型训练的有效性和可靠性，从而带来更好的性能。",
    "tldr": "提出了一个用于联邦微调基础模型的数据质量控制管道，可以提高全局性能。",
    "en_tdlr": "Proposed a data quality control pipeline for federated fine-tuning of foundation models to improve global performance."
}