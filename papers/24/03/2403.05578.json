{
    "title": "Chaining text-to-image and large language model: A novel approach for generating personalized e-commerce banners",
    "abstract": "arXiv:2403.05578v1 Announce Type: cross  Abstract: Text-to-image models such as stable diffusion have opened a plethora of opportunities for generating art. Recent literature has surveyed the use of text-to-image models for enhancing the work of many creative artists. Many e-commerce platforms employ a manual process to generate the banners, which is time-consuming and has limitations of scalability. In this work, we demonstrate the use of text-to-image models for generating personalized web banners with dynamic content for online shoppers based on their interactions. The novelty in this approach lies in converting users' interaction data to meaningful prompts without human intervention. To this end, we utilize a large language model (LLM) to systematically extract a tuple of attributes from item meta-information. The attributes are then passed to a text-to-image model via prompt engineering to generate images for the banner. Our results show that the proposed approach can create high-",
    "link": "https://arxiv.org/abs/2403.05578",
    "context": "Title: Chaining text-to-image and large language model: A novel approach for generating personalized e-commerce banners\nAbstract: arXiv:2403.05578v1 Announce Type: cross  Abstract: Text-to-image models such as stable diffusion have opened a plethora of opportunities for generating art. Recent literature has surveyed the use of text-to-image models for enhancing the work of many creative artists. Many e-commerce platforms employ a manual process to generate the banners, which is time-consuming and has limitations of scalability. In this work, we demonstrate the use of text-to-image models for generating personalized web banners with dynamic content for online shoppers based on their interactions. The novelty in this approach lies in converting users' interaction data to meaningful prompts without human intervention. To this end, we utilize a large language model (LLM) to systematically extract a tuple of attributes from item meta-information. The attributes are then passed to a text-to-image model via prompt engineering to generate images for the banner. Our results show that the proposed approach can create high-",
    "path": "papers/24/03/2403.05578.json",
    "total_tokens": 873,
    "translated_title": "将文本到图像和大型语言模型串联：生成个性化电子商务横幅的新方法",
    "translated_abstract": "arXiv:2403.05578v1 公告类型：交叉摘要：稳定扩散等文本到图像模型为生成艺术作品开辟了大量机会。最近的文献调查了文本到图像模型在增强许多创意艺术家工作中的应用。许多电子商务平台采用手动流程生成横幅，这是耗时的且存在可扩展性的局限性。在这项工作中，我们展示了利用文本到图像模型根据在线购物者的互动生成具有动态内容的个性化网页横幅的用途。此方法的新颖之处在于在没有人为干预的情况下将用户互动数据转换为有意义的提示。为此，我们利用大型语言模型（LLM）系统地从项目元信息中提取属性元组。然后通过提示工程将这些属性传递给文本到图像模型，以生成横幅的图像。我们的结果表明，所提出的方法可以创建高-",
    "tldr": "本研究提出了一种新方法，利用文本到图像模型和大型语言模型生成个性化网页横幅，根据用户互动动态内容，并且无需人工干预。",
    "en_tdlr": "This study presents a novel approach using text-to-image models and large language models to generate personalized web banners based on user interactions with dynamic content, without the need for manual intervention."
}