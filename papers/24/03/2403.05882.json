{
    "title": "DiffRed: Dimensionality Reduction guided by stable rank",
    "abstract": "arXiv:2403.05882v1 Announce Type: new  Abstract: In this work, we propose a novel dimensionality reduction technique, DiffRed, which first projects the data matrix, A, along first $k_1$ principal components and the residual matrix $A^{*}$ (left after subtracting its $k_1$-rank approximation) along $k_2$ Gaussian random vectors. We evaluate M1, the distortion of mean-squared pair-wise distance, and Stress, the normalized value of RMS of distortion of the pairwise distances. We rigorously prove that DiffRed achieves a general upper bound of $O\\left(\\sqrt{\\frac{1-p}{k_2}}\\right)$ on Stress and $O\\left(\\frac{(1-p)}{\\sqrt{k_2*\\rho(A^{*})}}\\right)$ on M1 where $p$ is the fraction of variance explained by the first $k_1$ principal components and $\\rho(A^{*})$ is the stable rank of $A^{*}$. These bounds are tighter than the currently known results for Random maps. Our extensive experiments on a variety of real-world datasets demonstrate that DiffRed achieves near zero M1 and much lower values ",
    "link": "https://arxiv.org/abs/2403.05882",
    "context": "Title: DiffRed: Dimensionality Reduction guided by stable rank\nAbstract: arXiv:2403.05882v1 Announce Type: new  Abstract: In this work, we propose a novel dimensionality reduction technique, DiffRed, which first projects the data matrix, A, along first $k_1$ principal components and the residual matrix $A^{*}$ (left after subtracting its $k_1$-rank approximation) along $k_2$ Gaussian random vectors. We evaluate M1, the distortion of mean-squared pair-wise distance, and Stress, the normalized value of RMS of distortion of the pairwise distances. We rigorously prove that DiffRed achieves a general upper bound of $O\\left(\\sqrt{\\frac{1-p}{k_2}}\\right)$ on Stress and $O\\left(\\frac{(1-p)}{\\sqrt{k_2*\\rho(A^{*})}}\\right)$ on M1 where $p$ is the fraction of variance explained by the first $k_1$ principal components and $\\rho(A^{*})$ is the stable rank of $A^{*}$. These bounds are tighter than the currently known results for Random maps. Our extensive experiments on a variety of real-world datasets demonstrate that DiffRed achieves near zero M1 and much lower values ",
    "path": "papers/24/03/2403.05882.json",
    "total_tokens": 971,
    "translated_title": "DiffRed: 由稳定秩引导的降维",
    "translated_abstract": "在这项工作中，我们提出了一种新颖的降维技术 DiffRed，该技术首先沿着前 $k_1$ 个主成分投影数据矩阵 A，然后将剩余矩阵 $A^{*}$（减去其 $k_1$-秩近似后剩余的部分）沿着 $k_2$ 个高斯随机向量进行投影。我们评估了 M1，即均方对距离失真，以及 Stress，即对成对距离失真的均方根值的归一化值。我们严格证明 DiffRed 在 Stress 上取得了 $O\\left(\\sqrt{\\frac{1-p}{k_2}}\\right)$ 的一般上界，在 M1 上取得了 $O\\left(\\frac{(1-p)}{\\sqrt{k_2*\\rho(A^{*})}}\\right)$ 的一般上界，其中$p$ 是由前 $k_1$ 个主成分解释的方差分数，$\\rho(A^{*})$ 是 $A^{*}$ 的稳定秩。这些上界比目前已知的随机映射结果更紧密。我们在各种真实世界数据集上进行了大量实验证明，DiffRed 实现了接近零的 M1 和更低的值。",
    "tldr": "DiffRed 提出了一种由稳定秩引导的降维方法，证明了在 Stress 和 M1 上取得了较紧密的上界，并通过实验证明在多种真实世界数据集上取得了良好效果。",
    "en_tdlr": "DiffRed introduces a dimensionality reduction technique guided by stable rank, proving tighter upper bounds on Stress and M1 and demonstrating effectiveness on various real-world datasets through experiments."
}