{
    "title": "Machine learning-based system reliability analysis with Gaussian Process Regression",
    "abstract": "arXiv:2403.11125v1 Announce Type: cross  Abstract: Machine learning-based reliability analysis methods have shown great advancements for their computational efficiency and accuracy. Recently, many efficient learning strategies have been proposed to enhance the computational performance. However, few of them explores the theoretical optimal learning strategy. In this article, we propose several theorems that facilitates such exploration. Specifically, cases that considering and neglecting the correlations among the candidate design samples are well elaborated. Moreover, we prove that the well-known U learning function can be reformulated to the optimal learning function for the case neglecting the Kriging correlation. In addition, the theoretical optimal learning strategy for sequential multiple training samples enrichment is also mathematically explored through the Bayesian estimate with the corresponding lost functions. Simulation results show that the optimal learning strategy consid",
    "link": "https://arxiv.org/abs/2403.11125",
    "context": "Title: Machine learning-based system reliability analysis with Gaussian Process Regression\nAbstract: arXiv:2403.11125v1 Announce Type: cross  Abstract: Machine learning-based reliability analysis methods have shown great advancements for their computational efficiency and accuracy. Recently, many efficient learning strategies have been proposed to enhance the computational performance. However, few of them explores the theoretical optimal learning strategy. In this article, we propose several theorems that facilitates such exploration. Specifically, cases that considering and neglecting the correlations among the candidate design samples are well elaborated. Moreover, we prove that the well-known U learning function can be reformulated to the optimal learning function for the case neglecting the Kriging correlation. In addition, the theoretical optimal learning strategy for sequential multiple training samples enrichment is also mathematically explored through the Bayesian estimate with the corresponding lost functions. Simulation results show that the optimal learning strategy consid",
    "path": "papers/24/03/2403.11125.json",
    "total_tokens": 883,
    "translated_title": "基于高斯过程回归的机器学习系统可靠性分析",
    "translated_abstract": "arXiv:2403.11125v1 公告类型: 交叉 摘要: 基于机器学习的可靠性分析方法在计算效率和准确性方面取得了巨大进展。最近，已经提出许多有效的学习策略来增强计算性能。然而，其中很少有人探讨了理论上的最优学习策略。在这篇文章中，我们提出了几个定理来促进这种探索。具体来说，详细阐述了考虑和忽略候选设计样本之间相关性的情况。此外，我们证明了众所周知的 U 学习函数可以重新制定为在忽略 Kriging 相关性的情况下的最优学习函数。此外，还通过带有相应损失函数的贝叶斯估计数学上探讨了顺序多个训练样本增益的理论上最优学习策略。模拟结果表明最优学习策略……",
    "tldr": "本文提出了基于高斯过程回归的机器学习系统可靠性分析方法，并通过几个定理探讨了最优学习策略，包括考虑和忽略样本之间的相关性以及顺序多个训练样本增益的理论最优策略。"
}