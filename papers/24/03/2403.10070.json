{
    "title": "A Structure-Preserving Kernel Method for Learning Hamiltonian Systems",
    "abstract": "arXiv:2403.10070v1 Announce Type: cross  Abstract: A structure-preserving kernel ridge regression method is presented that allows the recovery of potentially high-dimensional and nonlinear Hamiltonian functions out of datasets made of noisy observations of Hamiltonian vector fields. The method proposes a closed-form solution that yields excellent numerical performances that surpass other techniques proposed in the literature in this setup. From the methodological point of view, the paper extends kernel regression methods to problems in which loss functions involving linear functions of gradients are required and, in particular, a differential reproducing property and a Representer Theorem are proved in this context. The relation between the structure-preserving kernel estimator and the Gaussian posterior mean estimator is analyzed. A full error analysis is conducted that provides convergence rates using fixed and adaptive regularization parameters. The good performance of the proposed ",
    "link": "https://arxiv.org/abs/2403.10070",
    "context": "Title: A Structure-Preserving Kernel Method for Learning Hamiltonian Systems\nAbstract: arXiv:2403.10070v1 Announce Type: cross  Abstract: A structure-preserving kernel ridge regression method is presented that allows the recovery of potentially high-dimensional and nonlinear Hamiltonian functions out of datasets made of noisy observations of Hamiltonian vector fields. The method proposes a closed-form solution that yields excellent numerical performances that surpass other techniques proposed in the literature in this setup. From the methodological point of view, the paper extends kernel regression methods to problems in which loss functions involving linear functions of gradients are required and, in particular, a differential reproducing property and a Representer Theorem are proved in this context. The relation between the structure-preserving kernel estimator and the Gaussian posterior mean estimator is analyzed. A full error analysis is conducted that provides convergence rates using fixed and adaptive regularization parameters. The good performance of the proposed ",
    "path": "papers/24/03/2403.10070.json",
    "total_tokens": 776,
    "translated_title": "用于学习哈密顿系统的保结构核方法",
    "translated_abstract": "提出了一种保结构的核岭回归方法，允许从包含哈密顿向量场的噪声观测数据集中恢复潜在的高维非线性哈密顿函数。该方法提出了一个闭式解，在这一设置中表现出优秀的数值性能，超越了文献中提出的其他技术。从方法论的角度看，该论文扩展了核回归方法，解决需要包含梯度线性函数的损失函数的问题，特别地，在这一背景下证明了微分再现属性和表示定理。分析了保结构核估计器和高斯后验均值估计器之间的关系。进行了完整的误差分析，提供使用固定和自适应正则化参数的收敛速度。所提出方法的优良性能得到了确认。",
    "tldr": "提出了一种保结构的核岭回归方法，可以从噪声观测数据中恢复哈密顿函数，拓展了核回归方法，并具有出色的数值性能和收敛速度。",
    "en_tdlr": "Proposed a structure-preserving kernel ridge regression method for recovering Hamiltonian functions from noisy observations, extending kernel regression methods with excellent numerical performance and convergence rates."
}