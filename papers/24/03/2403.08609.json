{
    "title": "On the Convergence of Locally Adaptive and Scalable Diffusion-Based Sampling Methods for Deep Bayesian Neural Network Posteriors",
    "abstract": "arXiv:2403.08609v1 Announce Type: new  Abstract: Achieving robust uncertainty quantification for deep neural networks represents an important requirement in many real-world applications of deep learning such as medical imaging where it is necessary to assess the reliability of a neural network's prediction. Bayesian neural networks are a promising approach for modeling uncertainties in deep neural networks. Unfortunately, generating samples from the posterior distribution of neural networks is a major challenge. One significant advance in that direction would be the incorporation of adaptive step sizes, similar to modern neural network optimizers, into Monte Carlo Markov chain sampling algorithms without significantly increasing computational demand. Over the past years, several papers have introduced sampling algorithms with claims that they achieve this property. However, do they indeed converge to the correct distribution? In this paper, we demonstrate that these methods can have a ",
    "link": "https://arxiv.org/abs/2403.08609",
    "context": "Title: On the Convergence of Locally Adaptive and Scalable Diffusion-Based Sampling Methods for Deep Bayesian Neural Network Posteriors\nAbstract: arXiv:2403.08609v1 Announce Type: new  Abstract: Achieving robust uncertainty quantification for deep neural networks represents an important requirement in many real-world applications of deep learning such as medical imaging where it is necessary to assess the reliability of a neural network's prediction. Bayesian neural networks are a promising approach for modeling uncertainties in deep neural networks. Unfortunately, generating samples from the posterior distribution of neural networks is a major challenge. One significant advance in that direction would be the incorporation of adaptive step sizes, similar to modern neural network optimizers, into Monte Carlo Markov chain sampling algorithms without significantly increasing computational demand. Over the past years, several papers have introduced sampling algorithms with claims that they achieve this property. However, do they indeed converge to the correct distribution? In this paper, we demonstrate that these methods can have a ",
    "path": "papers/24/03/2403.08609.json",
    "total_tokens": 839,
    "translated_title": "深度贝叶斯神经网络后验的局部自适应和可扩展扩散采样方法的收敛问题",
    "translated_abstract": "实现深度神经网络的鲁棒不确定性量化在许多深度学习的实际应用中具有重要意义，如医学成像中需要评估神经网络预测的可靠性。贝叶斯神经网络是对深度神经网络中不确定性建模的一种有前途的方法。然而，从神经网络后验分布中生成样本是一个主要挑战。朝着这个方向的一个重要进展将是将类似于现代神经网络优化器的自适应步长纳入马尔可夫链蒙特卡罗采样算法，而不会显著增加计算需求。过去几年中，一些论文提出了具有实现这一属性的采样算法。然而，它们是否确实收敛到正确的分布呢？在本文中，我们证明了这些方法可以达到这一目标。",
    "tldr": "本文研究如何将自适应步长引入蒙特卡罗采样算法，以实现从神经网络后验分布中生成样本，并证明了这些方法可以收敛到正确的分布。"
}