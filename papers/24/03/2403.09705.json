{
    "title": "A Novel Nuanced Conversation Evaluation Framework for Large Language Models in Mental Health",
    "abstract": "arXiv:2403.09705v1 Announce Type: cross  Abstract: Understanding the conversation abilities of Large Language Models (LLMs) can help lead to its more cautious and appropriate deployment. This is especially important for safety-critical domains like mental health, where someone's life may depend on the exact wording of a response to an urgent question. In this paper, we propose a novel framework for evaluating the nuanced conversation abilities of LLMs. Within it, we develop a series of quantitative metrics developed from literature on using psychotherapy conversation analysis literature. While we ensure that our framework and metrics are transferable by researchers to relevant adjacent domains, we apply them to the mental health field. We use our framework to evaluate several popular frontier LLMs, including some GPT and Llama models, through a verified mental health dataset. Our results show that GPT4 Turbo can perform significantly more similarly to verified therapists than other sel",
    "link": "https://arxiv.org/abs/2403.09705",
    "context": "Title: A Novel Nuanced Conversation Evaluation Framework for Large Language Models in Mental Health\nAbstract: arXiv:2403.09705v1 Announce Type: cross  Abstract: Understanding the conversation abilities of Large Language Models (LLMs) can help lead to its more cautious and appropriate deployment. This is especially important for safety-critical domains like mental health, where someone's life may depend on the exact wording of a response to an urgent question. In this paper, we propose a novel framework for evaluating the nuanced conversation abilities of LLMs. Within it, we develop a series of quantitative metrics developed from literature on using psychotherapy conversation analysis literature. While we ensure that our framework and metrics are transferable by researchers to relevant adjacent domains, we apply them to the mental health field. We use our framework to evaluate several popular frontier LLMs, including some GPT and Llama models, through a verified mental health dataset. Our results show that GPT4 Turbo can perform significantly more similarly to verified therapists than other sel",
    "path": "papers/24/03/2403.09705.json",
    "total_tokens": 867,
    "translated_title": "一种针对大型语言模型在心理健康领域的新颖细致对话评估框架",
    "translated_abstract": "了解大型语言模型（LLMs）的对话能力可以帮助其更谨慎和适当地部署，对于像心理健康这样的安全关键领域尤为重要，其中某人的生命可能取决于对紧急问题回复的确切措辞。本文提出了一种评估LLMs微妙对话能力的新型框架。在其中，我们从心理治疗对话分析文献中发展了一系列定量指标。虽然我们确保我们的框架和指标可供研究人员转移到相关邻域，我们将它们应用到心理健康领域。我们使用我们的框架通过验证的心理健康数据集评估了几种流行的前沿LLMs模型，包括一些GPT和Llama模型。我们的结果显示，GPT4 Turbo在表现上与已验证的治疗师相比与其他模型更为相似。",
    "tldr": "提出了一种用于评估大型语言模型在心理健康领域微妙对话能力的新框架，并展示GPT4 Turbo可以与已验证的治疗师表现出更相似的结果。",
    "en_tdlr": "Proposed a new framework for evaluating the nuanced conversation abilities of large language models in mental health field and demonstrated that GPT4 Turbo can perform more similarly to verified therapists."
}