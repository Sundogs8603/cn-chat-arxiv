{
    "title": "Defending Against Data Reconstruction Attacks in Federated Learning: An Information Theory Approach",
    "abstract": "arXiv:2403.01268v1 Announce Type: new  Abstract: Federated Learning (FL) trains a black-box and high-dimensional model among different clients by exchanging parameters instead of direct data sharing, which mitigates the privacy leak incurred by machine learning. However, FL still suffers from membership inference attacks (MIA) or data reconstruction attacks (DRA). In particular, an attacker can extract the information from local datasets by constructing DRA, which cannot be effectively throttled by existing techniques, e.g., Differential Privacy (DP).   In this paper, we aim to ensure a strong privacy guarantee for FL under DRA. We prove that reconstruction errors under DRA are constrained by the information acquired by an attacker, which means that constraining the transmitted information can effectively throttle DRA. To quantify the information leakage incurred by FL, we establish a channel model, which depends on the upper bound of joint mutual information between the local dataset ",
    "link": "https://arxiv.org/abs/2403.01268",
    "context": "Title: Defending Against Data Reconstruction Attacks in Federated Learning: An Information Theory Approach\nAbstract: arXiv:2403.01268v1 Announce Type: new  Abstract: Federated Learning (FL) trains a black-box and high-dimensional model among different clients by exchanging parameters instead of direct data sharing, which mitigates the privacy leak incurred by machine learning. However, FL still suffers from membership inference attacks (MIA) or data reconstruction attacks (DRA). In particular, an attacker can extract the information from local datasets by constructing DRA, which cannot be effectively throttled by existing techniques, e.g., Differential Privacy (DP).   In this paper, we aim to ensure a strong privacy guarantee for FL under DRA. We prove that reconstruction errors under DRA are constrained by the information acquired by an attacker, which means that constraining the transmitted information can effectively throttle DRA. To quantify the information leakage incurred by FL, we establish a channel model, which depends on the upper bound of joint mutual information between the local dataset ",
    "path": "papers/24/03/2403.01268.json",
    "total_tokens": 695,
    "translated_title": "防御联邦学习中的数据重构攻击：一种信息论方法",
    "translated_abstract": "联邦学习通过交换参数而非直接共享数据，在不同客户端之间训练一个黑匣子和高维模型，从而减少了由机器学习带来的隐私泄露。然而，联邦学习仍然容易受到成员推断攻击（MIA）或数据重构攻击（DRA）的影响。具体而言，攻击者可以通过构建DRA从本地数据集中提取信息，现有技术（如差分隐私）无法有效地阻止这种攻击。",
    "tldr": "该论文通过一种信息论方法，旨在保证联邦学习在面临数据重构攻击时具有强大的隐私保证。",
    "en_tdlr": "This paper proposes an information theory approach to provide strong privacy guarantee for Federated Learning against data reconstruction attacks."
}