{
    "title": "SemRoDe: Macro Adversarial Training to Learn Representations That are Robust to Word-Level Attacks",
    "abstract": "arXiv:2403.18423v1 Announce Type: new  Abstract: Language models (LMs) are indispensable tools for natural language processing tasks, but their vulnerability to adversarial attacks remains a concern. While current research has explored adversarial training techniques, their improvements to defend against word-level attacks have been limited. In this work, we propose a novel approach called Semantic Robust Defence (SemRoDe), a Macro Adversarial Training strategy to enhance the robustness of LMs. Drawing inspiration from recent studies in the image domain, we investigate and later confirm that in a discrete data setting such as language, adversarial samples generated via word substitutions do indeed belong to an adversarial domain exhibiting a high Wasserstein distance from the base domain. Our method learns a robust representation that bridges these two domains. We hypothesize that if samples were not projected into an adversarial domain, but instead to a domain with minimal shift, it w",
    "link": "https://arxiv.org/abs/2403.18423",
    "context": "Title: SemRoDe: Macro Adversarial Training to Learn Representations That are Robust to Word-Level Attacks\nAbstract: arXiv:2403.18423v1 Announce Type: new  Abstract: Language models (LMs) are indispensable tools for natural language processing tasks, but their vulnerability to adversarial attacks remains a concern. While current research has explored adversarial training techniques, their improvements to defend against word-level attacks have been limited. In this work, we propose a novel approach called Semantic Robust Defence (SemRoDe), a Macro Adversarial Training strategy to enhance the robustness of LMs. Drawing inspiration from recent studies in the image domain, we investigate and later confirm that in a discrete data setting such as language, adversarial samples generated via word substitutions do indeed belong to an adversarial domain exhibiting a high Wasserstein distance from the base domain. Our method learns a robust representation that bridges these two domains. We hypothesize that if samples were not projected into an adversarial domain, but instead to a domain with minimal shift, it w",
    "path": "papers/24/03/2403.18423.json",
    "total_tokens": 953,
    "translated_title": "SemRoDe: 宏观对抗训练以学习对单词级攻击具有鲁棒性的表示",
    "translated_abstract": "语言模型（LMs）是自然语言处理任务中不可或缺的工具，但它们对对抗攻击的脆弱性仍然令人担忧。尽管当前的研究已经探索了对抗训练技术，但其在防御单词级攻击方面的改进仍然有限。在这项工作中，我们提出了一种名为语义鲁棒防御（SemRoDe）的新方法，这是一种宏观对抗训练策略，旨在增强LMs的鲁棒性。受到图像领域最近研究的启发，我们探讨并确认在像语言这样的离散数据设置中，通过单词替换生成的对抗样本确实属于一个展现与基本域具有高Wasserstein距离的对抗领域。我们的方法学习了一个能够连接这两个领域的鲁棒表示。我们假设如果样本被投影到一个非对抗领域，而是投影到一个具有最小偏移的领域，那么可能会...",
    "tldr": "提出了一种称为Semantic Robust Defence (SemRoDe)的新方法，通过宏观对抗训练策略增强了语言模型（LMs）的鲁棒性，学习了能够连接对抗领域和基本领域的鲁棒表示。",
    "en_tdlr": "Introduced a novel method called Semantic Robust Defence (SemRoDe), which enhances the robustness of language models (LMs) through macro adversarial training strategy, learning a robust representation that bridges adversarial and base domains."
}