{
    "title": "Japanese-English Sentence Translation Exercises Dataset for Automatic Grading",
    "abstract": "arXiv:2403.03396v1 Announce Type: new  Abstract: This paper proposes the task of automatic assessment of Sentence Translation Exercises (STEs), that have been used in the early stage of L2 language learning. We formalize the task as grading student responses for each rubric criterion pre-specified by the educators. We then create a dataset for STE between Japanese and English including 21 questions, along with a total of 3, 498 student responses (167 on average). The answer responses were collected from students and crowd workers. Using this dataset, we demonstrate the performance of baselines including finetuned BERT and GPT models with few-shot in-context learning. Experimental results show that the baseline model with finetuned BERT was able to classify correct responses with approximately 90% in F1, but only less than 80% for incorrect responses. Furthermore, the GPT models with few-shot learning show poorer results than finetuned BERT, indicating that our newly proposed task prese",
    "link": "https://arxiv.org/abs/2403.03396",
    "context": "Title: Japanese-English Sentence Translation Exercises Dataset for Automatic Grading\nAbstract: arXiv:2403.03396v1 Announce Type: new  Abstract: This paper proposes the task of automatic assessment of Sentence Translation Exercises (STEs), that have been used in the early stage of L2 language learning. We formalize the task as grading student responses for each rubric criterion pre-specified by the educators. We then create a dataset for STE between Japanese and English including 21 questions, along with a total of 3, 498 student responses (167 on average). The answer responses were collected from students and crowd workers. Using this dataset, we demonstrate the performance of baselines including finetuned BERT and GPT models with few-shot in-context learning. Experimental results show that the baseline model with finetuned BERT was able to classify correct responses with approximately 90% in F1, but only less than 80% for incorrect responses. Furthermore, the GPT models with few-shot learning show poorer results than finetuned BERT, indicating that our newly proposed task prese",
    "path": "papers/24/03/2403.03396.json",
    "total_tokens": 863,
    "translated_title": "用于自动评分的日英句子翻译练习数据集",
    "translated_abstract": "本文提出了自动评估句子翻译练习（STEs）的任务，这在第二语言学习的早期阶段被使用。我们将这项任务形式化为为每个由教育工作者预先指定的评分标准对学生回答进行评分的任务。我们创建了一个包含21个问题的日英STE数据集，以及共3,498个学生回答（平均167个）。回答数据来自学生和众包工作者。利用这个数据集，我们展示了包括微调的BERT和具有少量远程上下文学习的GPT模型在内的基线性能。实验结果表明，具有微调BERT的基线模型能够以约90%的F1值分类正确回答，但对于错误回答仅不到80%。此外，具有少量远程上下文学习的GPT模型显示出比微调的BERT更差的结果，表明我们新提出的任务",
    "tldr": "本文提出了用于自动评估句子翻译练习的任务，并创建了日英STE数据集，实验结果表明微调的BERT模型能够以约90%的F1值分类正确回答",
    "en_tdlr": "This paper introduces a task for automatic assessment of Sentence Translation Exercises and creates a dataset for Japanese-English STE, with experimental results showing that the finetuned BERT model can classify correct responses with approximately 90% in F1"
}