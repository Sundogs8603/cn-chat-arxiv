{
    "title": "On Latency Predictors for Neural Architecture Search",
    "abstract": "arXiv:2403.02446v1 Announce Type: new  Abstract: Efficient deployment of neural networks (NN) requires the co-optimization of accuracy and latency. For example, hardware-aware neural architecture search has been used to automatically find NN architectures that satisfy a latency constraint on a specific hardware device. Central to these search algorithms is a prediction model that is designed to provide a hardware latency estimate for a candidate NN architecture. Recent research has shown that the sample efficiency of these predictive models can be greatly improved through pre-training on some \\textit{training} devices with many samples, and then transferring the predictor on the \\textit{test} (target) device. Transfer learning and meta-learning methods have been used for this, but often exhibit significant performance variability. Additionally, the evaluation of existing latency predictors has been largely done on hand-crafted training/test device sets, making it difficult to ascertain",
    "link": "https://arxiv.org/abs/2403.02446",
    "context": "Title: On Latency Predictors for Neural Architecture Search\nAbstract: arXiv:2403.02446v1 Announce Type: new  Abstract: Efficient deployment of neural networks (NN) requires the co-optimization of accuracy and latency. For example, hardware-aware neural architecture search has been used to automatically find NN architectures that satisfy a latency constraint on a specific hardware device. Central to these search algorithms is a prediction model that is designed to provide a hardware latency estimate for a candidate NN architecture. Recent research has shown that the sample efficiency of these predictive models can be greatly improved through pre-training on some \\textit{training} devices with many samples, and then transferring the predictor on the \\textit{test} (target) device. Transfer learning and meta-learning methods have been used for this, but often exhibit significant performance variability. Additionally, the evaluation of existing latency predictors has been largely done on hand-crafted training/test device sets, making it difficult to ascertain",
    "path": "papers/24/03/2403.02446.json",
    "total_tokens": 795,
    "translated_title": "关于神经架构搜索的延迟预测器",
    "translated_abstract": "高效部署神经网络（NN）需要同时优化准确性和延迟。例如，硬件感知神经架构搜索已被用于自动找到满足特定硬件设备上延迟约束的NN架构。这些搜索算法的核心是一个旨在为候选NN架构提供硬件延迟估计的预测模型。最近的研究表明，通过在一些\\textit{训练}设备上进行大量样本的预训练，然后将预测器转移到\\textit{测试}（目标）设备上，这些预测模型的样本效率可以极大地提高。迁移学习和元学习方法已被用于此，但往往表现出显著的性能变异性。此外，现有延迟预测器的评估主要是在手工定制的训练/测试设备集上进行的，这使得难以确定",
    "tldr": "通过在训练设备上进行预训练，并将预测器转移到测试设备上，可以显著提高预测模型的样本效率。"
}