{
    "title": "Automatic design optimization of preference-based subjective evaluation with online learning in crowdsourcing environment",
    "abstract": "arXiv:2403.06100v1 Announce Type: cross  Abstract: A preference-based subjective evaluation is a key method for evaluating generative media reliably. However, its huge combinations of pairs prohibit it from being applied to large-scale evaluation using crowdsourcing. To address this issue, we propose an automatic optimization method for preference-based subjective evaluation in terms of pair combination selections and allocation of evaluation volumes with online learning in a crowdsourcing environment. We use a preference-based online learning method based on a sorting algorithm to identify the total order of evaluation targets with minimum sample volumes. Our online learning algorithm supports parallel and asynchronous execution under fixed-budget conditions required for crowdsourcing. Our experiment on preference-based subjective evaluation of synthetic speech shows that our method successfully optimizes the test by reducing pair combinations from 351 to 83 and allocating optimal eva",
    "link": "https://arxiv.org/abs/2403.06100",
    "context": "Title: Automatic design optimization of preference-based subjective evaluation with online learning in crowdsourcing environment\nAbstract: arXiv:2403.06100v1 Announce Type: cross  Abstract: A preference-based subjective evaluation is a key method for evaluating generative media reliably. However, its huge combinations of pairs prohibit it from being applied to large-scale evaluation using crowdsourcing. To address this issue, we propose an automatic optimization method for preference-based subjective evaluation in terms of pair combination selections and allocation of evaluation volumes with online learning in a crowdsourcing environment. We use a preference-based online learning method based on a sorting algorithm to identify the total order of evaluation targets with minimum sample volumes. Our online learning algorithm supports parallel and asynchronous execution under fixed-budget conditions required for crowdsourcing. Our experiment on preference-based subjective evaluation of synthetic speech shows that our method successfully optimizes the test by reducing pair combinations from 351 to 83 and allocating optimal eva",
    "path": "papers/24/03/2403.06100.json",
    "total_tokens": 793,
    "translated_title": "在众包环境中利用在线学习进行基于喜好的主观评估设计优化",
    "translated_abstract": "基于喜好的主观评估是评价生成式媒体可靠性的关键方法。然而，其庞大的配对组合使得它无法应用于利用众包进行大规模评估。为了解决这个问题，我们提出了一种用于在众包环境中进行基于喜好的主观评估的自动优化方法，该方法涉及对配对组合选择和评估量分配的在线学习。我们使用基于排序算法的基于喜好的在线学习方法来识别具有最小样本量的评估目标的完全顺序。我们的在线学习算法支持在众包所需的固定预算条件下的并行和异步执行。我们对合成语音的基于喜好的主观评估实验证明了我们的方法成功通过将配对组合从351减少到83并分配最优评估。",
    "tldr": "在众包环境中，我们提出了一种自动优化方法，利用在线学习对配对组合和评估量进行优化，实现基于喜好的主观评估的设计优化。",
    "en_tdlr": "We propose an automatic optimization method in crowdsourcing environment using online learning to optimize pair combinations and evaluation volumes for preference-based subjective evaluation design."
}