{
    "title": "DOCTR: Disentangled Object-Centric Transformer for Point Scene Understanding",
    "abstract": "arXiv:2403.16431v1 Announce Type: cross  Abstract: Point scene understanding is a challenging task to process real-world scene point cloud, which aims at segmenting each object, estimating its pose, and reconstructing its mesh simultaneously. Recent state-of-the-art method first segments each object and then processes them independently with multiple stages for the different sub-tasks. This leads to a complex pipeline to optimize and makes it hard to leverage the relationship constraints between multiple objects. In this work, we propose a novel Disentangled Object-Centric TRansformer (DOCTR) that explores object-centric representation to facilitate learning with multiple objects for the multiple sub-tasks in a unified manner. Each object is represented as a query, and a Transformer decoder is adapted to iteratively optimize all the queries involving their relationship. In particular, we introduce a semantic-geometry disentangled query (SGDQ) design that enables the query features to a",
    "link": "https://arxiv.org/abs/2403.16431",
    "context": "Title: DOCTR: Disentangled Object-Centric Transformer for Point Scene Understanding\nAbstract: arXiv:2403.16431v1 Announce Type: cross  Abstract: Point scene understanding is a challenging task to process real-world scene point cloud, which aims at segmenting each object, estimating its pose, and reconstructing its mesh simultaneously. Recent state-of-the-art method first segments each object and then processes them independently with multiple stages for the different sub-tasks. This leads to a complex pipeline to optimize and makes it hard to leverage the relationship constraints between multiple objects. In this work, we propose a novel Disentangled Object-Centric TRansformer (DOCTR) that explores object-centric representation to facilitate learning with multiple objects for the multiple sub-tasks in a unified manner. Each object is represented as a query, and a Transformer decoder is adapted to iteratively optimize all the queries involving their relationship. In particular, we introduce a semantic-geometry disentangled query (SGDQ) design that enables the query features to a",
    "path": "papers/24/03/2403.16431.json",
    "total_tokens": 845,
    "translated_title": "DOCTR：点场景理解的解耦对象中心Transformer",
    "translated_abstract": "点场景理解是处理现实世界场景点云的一项具有挑战性的任务，旨在同时对每个对象进行分割，估计其姿态并重新构建其网格。最近的最先进方法首先分割每个对象，然后使用多个阶段分别处理不同的子任务。这导致了一个复杂的流水线优化，并使得难以利用多个对象之间的关系约束。在这项工作中，我们提出了一种新颖的Disentangled Object-Centric TRansformer (DOCTR)，它探索了对象中心表示，以便以统一的方式便利多个对象学习多个子任务。每个对象被表示为一个查询，一个Transformer解码器被调整为迭代地优化涉及它们之间关系的所有查询。特别地，我们引入了一种语义几何解耦查询（SGDQ）设计，使查询特征能够",
    "tldr": "提出了一种新颖的Disentangled Object-Centric Transformer (DOCTR)，旨在以统一的方式便利多个对象学习点场景理解的多个子任务，并引入了语义-几何解耦查询设计来优化对象之间的关系。",
    "en_tdlr": "Proposed a novel Disentangled Object-Centric Transformer (DOCTR) aiming to facilitate learning with multiple objects for various sub-tasks in point scene understanding in a unified manner, and introduced a semantic-geometry disentangled query design to optimize the relationships between objects."
}