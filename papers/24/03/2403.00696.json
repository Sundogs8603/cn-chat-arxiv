{
    "title": "Self-Consistent Decoding for More Factual Open Responses",
    "abstract": "arXiv:2403.00696v1 Announce Type: new  Abstract: Self-consistency has emerged as a powerful method for improving the accuracy of short answers generated by large language models. As previously defined, it only concerns the accuracy of a final answer parsed from generated text. In this work, we extend the idea to open response generation, by integrating voting into the decoding method. Each output sentence is selected from among multiple samples, conditioning on the previous selections, based on a simple token overlap score. We compare this \"Sample & Select\" method to greedy decoding, beam search, nucleus sampling, and the recently introduced hallucination avoiding decoders of DoLA, P-CRR, and S-CRR. We show that Sample & Select improves factuality by a 30% relative margin against these decoders in NLI-based evaluation on the subsets of CNN/DM and XSum used in the FRANK benchmark, while maintaining comparable ROUGE-1 F1 scores against reference summaries. We collect human verifications ",
    "link": "https://arxiv.org/abs/2403.00696",
    "context": "Title: Self-Consistent Decoding for More Factual Open Responses\nAbstract: arXiv:2403.00696v1 Announce Type: new  Abstract: Self-consistency has emerged as a powerful method for improving the accuracy of short answers generated by large language models. As previously defined, it only concerns the accuracy of a final answer parsed from generated text. In this work, we extend the idea to open response generation, by integrating voting into the decoding method. Each output sentence is selected from among multiple samples, conditioning on the previous selections, based on a simple token overlap score. We compare this \"Sample & Select\" method to greedy decoding, beam search, nucleus sampling, and the recently introduced hallucination avoiding decoders of DoLA, P-CRR, and S-CRR. We show that Sample & Select improves factuality by a 30% relative margin against these decoders in NLI-based evaluation on the subsets of CNN/DM and XSum used in the FRANK benchmark, while maintaining comparable ROUGE-1 F1 scores against reference summaries. We collect human verifications ",
    "path": "papers/24/03/2403.00696.json",
    "total_tokens": 841,
    "translated_title": "自洽解码以获得更真实的开放响应",
    "translated_abstract": "自洽性已经成为提高大型语言模型生成准确短答案能力的强大方法。在以前的定义中，它只关注从生成文本中解析出的最终答案的准确性。本文将这一思想扩展到开放响应生成，通过在解码方法中整合投票来实现。每个输出句子是从多个样本中选择的，基于简单的令牌重叠得分，并且条件是先前的选择。我们将这种“样本与选择”方法与贪婪解码、束搜索、核采样以及DoLA、P-CRR和S-CRR等最近引入的避免产生幻觉的解码器进行比较。我们展示了“样本与选择”方法在基于NLI的评估中比这些解码器在CNN/DM和XSum子集上提高了30%的真实性，在维持与参考摘要相当的ROUGE-1 F1分数的同时。我们进行了人类验证。",
    "tldr": "将自洽解码方法扩展到开放响应生成，通过整合投票，并在NLI评估中展示了“样本与选择”方法相对于其他解码器可以提高30%的真实性。",
    "en_tdlr": "Extending self-consistent decoding to open response generation, integrating voting, and demonstrating a 30% factual improvement over other decoders in NLI evaluation."
}