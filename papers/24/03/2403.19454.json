{
    "title": "JDocQA: Japanese Document Question Answering Dataset for Generative Language Models",
    "abstract": "arXiv:2403.19454v1 Announce Type: new  Abstract: Document question answering is a task of question answering on given documents such as reports, slides, pamphlets, and websites, and it is a truly demanding task as paper and electronic forms of documents are so common in our society. This is known as a quite challenging task because it requires not only text understanding but also understanding of figures and tables, and hence visual question answering (VQA) methods are often examined in addition to textual approaches. We introduce Japanese Document Question Answering (JDocQA), a large-scale document-based QA dataset, essentially requiring both visual and textual information to answer questions, which comprises 5,504 documents in PDF format and annotated 11,600 question-and-answer instances in Japanese. Each QA instance includes references to the document pages and bounding boxes for the answer clues. We incorporate multiple categories of questions and unanswerable questions from the do",
    "link": "https://arxiv.org/abs/2403.19454",
    "context": "Title: JDocQA: Japanese Document Question Answering Dataset for Generative Language Models\nAbstract: arXiv:2403.19454v1 Announce Type: new  Abstract: Document question answering is a task of question answering on given documents such as reports, slides, pamphlets, and websites, and it is a truly demanding task as paper and electronic forms of documents are so common in our society. This is known as a quite challenging task because it requires not only text understanding but also understanding of figures and tables, and hence visual question answering (VQA) methods are often examined in addition to textual approaches. We introduce Japanese Document Question Answering (JDocQA), a large-scale document-based QA dataset, essentially requiring both visual and textual information to answer questions, which comprises 5,504 documents in PDF format and annotated 11,600 question-and-answer instances in Japanese. Each QA instance includes references to the document pages and bounding boxes for the answer clues. We incorporate multiple categories of questions and unanswerable questions from the do",
    "path": "papers/24/03/2403.19454.json",
    "total_tokens": 847,
    "translated_title": "JDocQA：用于生成语言模型的日语文档问答数据集",
    "translated_abstract": "arXiv:2403.19454v1 公告类型: 新的 摘要: 文档问答是针对给定文档（如报告、幻灯片、小册子和网站）的问答任务，这是一项非常具有挑战性的任务，因为纸质和电子形式的文档在我们的社会中非常普遍。 这是一个非常具有挑战性的任务，因为它不仅需要理解文本，还需要理解图表，因此除了文本方法之外，通常还会研究视觉问答（VQA）方法。 我们推出了《日语文档问答》（JDocQA），这是一个大规模的基于文档的问答数据集，基本上需要同时使用视觉和文本信息来回答问题，其中包括5,504个PDF格式的文档和11,600个日语问答实例。 每个问答实例都包括对文档页的引用和答案提示的边界框。",
    "tldr": "JDocQA是一个大规模的基于文档的问答数据集，要求结合视觉和文本信息回答问题，包括5,504个文档和11,600个问答实例。",
    "en_tdlr": "JDocQA is a large-scale document-based QA dataset that requires combining visual and textual information to answer questions, including 5,504 documents and 11,600 QA instances."
}