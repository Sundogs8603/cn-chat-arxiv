{
    "title": "HALC: Object Hallucination Reduction via Adaptive Focal-Contrast Decoding",
    "abstract": "arXiv:2403.00425v1 Announce Type: cross  Abstract: While large vision-language models (LVLMs) have demonstrated impressive capabilities in interpreting multi-modal contexts, they invariably suffer from object hallucinations (OH). We introduce HALC, a novel decoding algorithm designed to mitigate OH in LVLMs. HALC leverages distinct fine-grained optimal visual information in vision-language tasks and operates on both local and global contexts simultaneously. Specifically, HALC integrates a robust auto-focal grounding mechanism (locally) to correct hallucinated tokens on the fly, and a specialized beam search algorithm (globally) to significantly reduce OH while preserving text generation quality. Additionally, HALC can be integrated into any LVLMs as a plug-and-play module without extra training. Extensive experimental studies demonstrate the effectiveness of HALC in reducing OH, outperforming state-of-the-arts across four benchmarks.",
    "link": "https://arxiv.org/abs/2403.00425",
    "context": "Title: HALC: Object Hallucination Reduction via Adaptive Focal-Contrast Decoding\nAbstract: arXiv:2403.00425v1 Announce Type: cross  Abstract: While large vision-language models (LVLMs) have demonstrated impressive capabilities in interpreting multi-modal contexts, they invariably suffer from object hallucinations (OH). We introduce HALC, a novel decoding algorithm designed to mitigate OH in LVLMs. HALC leverages distinct fine-grained optimal visual information in vision-language tasks and operates on both local and global contexts simultaneously. Specifically, HALC integrates a robust auto-focal grounding mechanism (locally) to correct hallucinated tokens on the fly, and a specialized beam search algorithm (globally) to significantly reduce OH while preserving text generation quality. Additionally, HALC can be integrated into any LVLMs as a plug-and-play module without extra training. Extensive experimental studies demonstrate the effectiveness of HALC in reducing OH, outperforming state-of-the-arts across four benchmarks.",
    "path": "papers/24/03/2403.00425.json",
    "total_tokens": 924,
    "translated_title": "通过自适应焦点对比解码减少对象幻觉：HALC",
    "translated_abstract": "在解释多模态环境方面，大型视觉-语言模型（LVLMs）展现了令人印象深刻的能力，但它们不可避免地会受到对象幻觉（OH）的困扰。我们介绍了HALC，这是一种新颖的解码算法，旨在减少LVLMs中的OH。HALC利用视觉-语言任务中独特的细粒度最佳视觉信息，并同时在局部和全局上操作。具体来说，HALC集成了一个强大的自动聚焦基准机制（局部），在运行时纠正产生幻觉的标记，以及一种专门的波束搜索算法（全局），以显着减少OH，同时保持文本生成质量。此外，HALC可以作为即插即用模块集成到任何LVLMs中，无需额外训练。大量实验研究证明了HALC在减少OH方面的有效性，优于四个基准测试中的现有技术。",
    "tldr": "HALC是一种旨在减少大型视觉-语言模型中对象幻觉的新颖解码算法，通过局部的自动聚焦基准机制和全局的波束搜索算法，成功减少OH而保持文本生成质量，同时可以作为即插即用模块集成到任何LVLMs中。",
    "en_tdlr": "HALC is a novel decoding algorithm designed to reduce object hallucinations in large vision-language models, which successfully reduces OH while preserving text generation quality through a local auto-focal grounding mechanism and a global beam search algorithm, and can be integrated as a plug-and-play module into any LVLMs."
}