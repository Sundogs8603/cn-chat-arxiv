{
    "title": "Latxa: An Open Language Model and Evaluation Suite for Basque",
    "abstract": "arXiv:2403.20266v1 Announce Type: cross  Abstract: We introduce Latxa, a family of large language models for Basque ranging from 7 to 70 billion parameters. Latxa is based on Llama 2, which we continue pretraining on a new Basque corpus comprising 4.3M documents and 4.2B tokens. Addressing the scarcity of high-quality benchmarks for Basque, we further introduce 4 multiple choice evaluation datasets: EusProficiency, comprising 5,169 questions from official language proficiency exams; EusReading, comprising 352 reading comprehension questions; EusTrivia, comprising 1,715 trivia questions from 5 knowledge areas; and EusExams, comprising 16,774 questions from public examinations. In our extensive evaluation, Latxa outperforms all previous open models we compare to by a large margin. In addition, it is competitive with GPT-4 Turbo in language proficiency and understanding, despite lagging behind in reading comprehension and knowledge-intensive tasks. Both the Latxa family of models, as well",
    "link": "https://arxiv.org/abs/2403.20266",
    "context": "Title: Latxa: An Open Language Model and Evaluation Suite for Basque\nAbstract: arXiv:2403.20266v1 Announce Type: cross  Abstract: We introduce Latxa, a family of large language models for Basque ranging from 7 to 70 billion parameters. Latxa is based on Llama 2, which we continue pretraining on a new Basque corpus comprising 4.3M documents and 4.2B tokens. Addressing the scarcity of high-quality benchmarks for Basque, we further introduce 4 multiple choice evaluation datasets: EusProficiency, comprising 5,169 questions from official language proficiency exams; EusReading, comprising 352 reading comprehension questions; EusTrivia, comprising 1,715 trivia questions from 5 knowledge areas; and EusExams, comprising 16,774 questions from public examinations. In our extensive evaluation, Latxa outperforms all previous open models we compare to by a large margin. In addition, it is competitive with GPT-4 Turbo in language proficiency and understanding, despite lagging behind in reading comprehension and knowledge-intensive tasks. Both the Latxa family of models, as well",
    "path": "papers/24/03/2403.20266.json",
    "total_tokens": 946,
    "translated_title": "Latxa: 一种用于巴斯克语的开放语言模型和评估套件",
    "translated_abstract": "我们介绍了Latxa，这是一个基于Llama 2的大型巴斯克语言模型系列，参数范围从7到700亿。Latxa基于新的巴斯克语语料库预训练，包括430万个文档和42亿个标记。针对巴斯克语高质量基准的稀缺性，我们进一步提出了4个多项选择评估数据集：EusProficiency，包括来自官方语言能力考试的5169个问题；EusReading，包括352个阅读理解问题；EusTrivia，包括来自5个知识领域的1715个琐事问题；以及EusExams，包括来自公共考试的16774个问题。在我们的广泛评估中，Latxa在与我们比较的所有先前开放模型中表现出色。此外，尽管在阅读理解和知识密集型任务方面落后，但在语言熟练度和理解能力方面，它与GPT-4 Turbo具有竞争力。Latxa模型系列，以及",
    "tldr": "Latxa是一种用于巴斯克语的大型语言模型系列，在语言熟练度和理解能力方面表现出色，优于所有以前的开放模型，并具有多个评估数据集，填补了巴斯克语高质量基准的不足。",
    "en_tdlr": "Latxa is a family of large language models for Basque, outperforming previous models in language proficiency and understanding, with multiple evaluation datasets addressing the scarcity of high-quality benchmarks for Basque."
}