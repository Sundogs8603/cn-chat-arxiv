{
    "title": "Last Iterate Convergence of Incremental Methods and Applications in Continual Learning",
    "abstract": "arXiv:2403.06873v1 Announce Type: cross  Abstract: Incremental gradient methods and incremental proximal methods are a fundamental class of optimization algorithms used for solving finite sum problems, broadly studied in the literature. Yet, when it comes to their convergence guarantees, nonasymptotic (first-order or proximal) oracle complexity bounds have been obtained fairly recently, almost exclusively applying to the average iterate. Motivated by applications in continual learning, we obtain the first convergence guarantees for the last iterate of both incremental gradient and incremental proximal methods, in general convex smooth (for both) and convex Lipschitz (for the proximal variants) settings. Our oracle complexity bounds for the last iterate nearly match (i.e., match up to a square-root-log or a log factor) the best known oracle complexity bounds for the average iterate, for both classes of methods. We further obtain generalizations of our results to weighted averaging of th",
    "link": "https://arxiv.org/abs/2403.06873",
    "context": "Title: Last Iterate Convergence of Incremental Methods and Applications in Continual Learning\nAbstract: arXiv:2403.06873v1 Announce Type: cross  Abstract: Incremental gradient methods and incremental proximal methods are a fundamental class of optimization algorithms used for solving finite sum problems, broadly studied in the literature. Yet, when it comes to their convergence guarantees, nonasymptotic (first-order or proximal) oracle complexity bounds have been obtained fairly recently, almost exclusively applying to the average iterate. Motivated by applications in continual learning, we obtain the first convergence guarantees for the last iterate of both incremental gradient and incremental proximal methods, in general convex smooth (for both) and convex Lipschitz (for the proximal variants) settings. Our oracle complexity bounds for the last iterate nearly match (i.e., match up to a square-root-log or a log factor) the best known oracle complexity bounds for the average iterate, for both classes of methods. We further obtain generalizations of our results to weighted averaging of th",
    "path": "papers/24/03/2403.06873.json",
    "total_tokens": 873,
    "translated_title": "增量方法的最后迭代收敛性及在继续学习中的应用",
    "translated_abstract": "增量梯度方法和增量近端方法是一类基本的优化算法，用于解决广泛研究的有限和问题。然而，就收敛性保证而言，非渐进（一阶或近端）的预期复杂性界限最近才得到，并且几乎仅适用于平均迭代。受继续学习应用的启发，我们获得了对一般凸平滑（两者）和凸Lipschitz（对于近端变种）设置中增量梯度和增量近端方法的最后迭代的首个收敛保证。我们对最后迭代的预期复杂性界限几乎与最佳已知的平均迭代的预期复杂性界限相匹配（即匹配至平方根对数或对数因子），对两类方法均适用。我们进一步将我们的结果推广到加权平均的情况。",
    "tldr": "针对继续学习应用，本研究首次获得了增量梯度和增量近端方法最后迭代的收敛保证，且其预期复杂度界限几乎与已知最佳平均迭代的界限相匹配。"
}