{
    "title": "Unveiling the Generalization Power of Fine-Tuned Large Language Models",
    "abstract": "arXiv:2403.09162v1 Announce Type: new  Abstract: While Large Language Models (LLMs) have demonstrated exceptional multitasking abilities, fine-tuning these models on downstream, domain-specific datasets is often necessary to yield superior performance on test sets compared to their counterparts without fine-tuning. However, the comprehensive effects of fine-tuning on the LLMs' generalization ability are not fully understood. This paper delves into the differences between original, unmodified LLMs and their fine-tuned variants. Our primary investigation centers on whether fine-tuning affects the generalization ability intrinsic to LLMs. To elaborate on this, we conduct extensive experiments across five distinct language tasks on various datasets. Our main findings reveal that models fine-tuned on generation and classification tasks exhibit dissimilar behaviors in generalizing to different domains and tasks. Intriguingly, we observe that integrating the in-context learning strategy durin",
    "link": "https://arxiv.org/abs/2403.09162",
    "context": "Title: Unveiling the Generalization Power of Fine-Tuned Large Language Models\nAbstract: arXiv:2403.09162v1 Announce Type: new  Abstract: While Large Language Models (LLMs) have demonstrated exceptional multitasking abilities, fine-tuning these models on downstream, domain-specific datasets is often necessary to yield superior performance on test sets compared to their counterparts without fine-tuning. However, the comprehensive effects of fine-tuning on the LLMs' generalization ability are not fully understood. This paper delves into the differences between original, unmodified LLMs and their fine-tuned variants. Our primary investigation centers on whether fine-tuning affects the generalization ability intrinsic to LLMs. To elaborate on this, we conduct extensive experiments across five distinct language tasks on various datasets. Our main findings reveal that models fine-tuned on generation and classification tasks exhibit dissimilar behaviors in generalizing to different domains and tasks. Intriguingly, we observe that integrating the in-context learning strategy durin",
    "path": "papers/24/03/2403.09162.json",
    "total_tokens": 891,
    "translated_title": "揭示经过微调的大型语言模型的泛化能力",
    "translated_abstract": "虽然大型语言模型（LLMs）展示了出色的多任务能力，但通常需要在下游的领域特定数据集上对这些模型进行微调，以在测试集上获得比未经微调的模型更优越的性能。然而，关于微调对LLMs泛化能力的全面影响尚不完全了解。本文深入探讨了原始、未修改的LLMs与经过微调变体之间的差异。我们的主要研究重点在于微调是否会影响内在于LLMs的泛化能力。为了阐明这一点，我们在不同数据集上对五个不同语言任务进行了广泛实验。我们的主要发现表明，在生成和分类任务上进行微调的模型在泛化到不同领域和任务时表现出不同行为。有趣的是，我们发现在上下文学习策略的引入的情况下，对于某些具体任务的微调可以提高LLMs的泛化能力。",
    "tldr": "本文研究了经过微调的大型语言模型的泛化能力，发现在生成和分类任务上进行微调的模型在泛化到不同领域和任务时表现出不同行为，引入上下文学习策略可以提高模型的泛化能力。",
    "en_tdlr": "This paper explores the generalization power of fine-tuned large language models, finding that models fine-tuned on generation and classification tasks exhibit different behaviors in generalizing to different domains and tasks, and introducing in-context learning strategy can improve the model's generalization ability."
}