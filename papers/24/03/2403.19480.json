{
    "title": "$H$-Consistency Guarantees for Regression",
    "abstract": "arXiv:2403.19480v1 Announce Type: new  Abstract: We present a detailed study of $H$-consistency bounds for regression. We first present new theorems that generalize the tools previously given to establish $H$-consistency bounds. This generalization proves essential for analyzing $H$-consistency bounds specific to regression. Next, we prove a series of novel $H$-consistency bounds for surrogate loss functions of the squared loss, under the assumption of a symmetric distribution and a bounded hypothesis set. This includes positive results for the Huber loss, all $\\ell_p$ losses, $p \\geq 1$, the squared $\\epsilon$-insensitive loss, as well as a negative result for the $\\epsilon$-insensitive loss used in squared Support Vector Regression (SVR). We further leverage our analysis of $H$-consistency for regression and derive principled surrogate losses for adversarial regression (Section 5). This readily establishes novel algorithms for adversarial regression, for which we report favorable exp",
    "link": "https://arxiv.org/abs/2403.19480",
    "context": "Title: $H$-Consistency Guarantees for Regression\nAbstract: arXiv:2403.19480v1 Announce Type: new  Abstract: We present a detailed study of $H$-consistency bounds for regression. We first present new theorems that generalize the tools previously given to establish $H$-consistency bounds. This generalization proves essential for analyzing $H$-consistency bounds specific to regression. Next, we prove a series of novel $H$-consistency bounds for surrogate loss functions of the squared loss, under the assumption of a symmetric distribution and a bounded hypothesis set. This includes positive results for the Huber loss, all $\\ell_p$ losses, $p \\geq 1$, the squared $\\epsilon$-insensitive loss, as well as a negative result for the $\\epsilon$-insensitive loss used in squared Support Vector Regression (SVR). We further leverage our analysis of $H$-consistency for regression and derive principled surrogate losses for adversarial regression (Section 5). This readily establishes novel algorithms for adversarial regression, for which we report favorable exp",
    "path": "papers/24/03/2403.19480.json",
    "total_tokens": 923,
    "translated_title": "回归问题中的$H$一致性保证",
    "translated_abstract": "我们对回归问题中的$H$一致性界进行了详细研究。我们首先提出了一些新的定理，这些定理推广了先前用于建立$H$一致性界的工具。这种概括对于分析针对回归问题特定的$H$一致性界至关重要。接下来，我们在对称分布和有界假设集的条件下，证明了一系列关于平方损失的新颖$H$一致性界，包括Huber损失、所有$\\ell_p$损失（$p \\geq 1$）、平方$\\epsilon$-不敏感损失的正结果，以及对于在平方支持向量回归（SVR）中使用的$\\epsilon$-不敏感损失的负结果。我们进一步利用对回归问题中$H$一致性的分析，并提出了针对对抗回归的有原则的代理损失（第5节）。这为对抗性回归建立了新颖的算法，我们报告了有利的实验结果。",
    "tldr": "提出了通用的$H$一致性界工具来分析回归问题，并针对平方损失推导出一系列新颖的$H$一致性界；基于对$H$一致性的分析，为对抗性回归提供了有原则的代理损失。",
    "en_tdlr": "Presented general $H$-consistency bounds tools for regression analysis and derived a series of novel $H$-consistency bounds for squared loss; Provided principled surrogate losses for adversarial regression based on the analysis of $H$-consistency."
}