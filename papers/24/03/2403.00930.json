{
    "title": "Scale-free Adversarial Reinforcement Learning",
    "abstract": "arXiv:2403.00930v1 Announce Type: cross  Abstract: This paper initiates the study of scale-free learning in Markov Decision Processes (MDPs), where the scale of rewards/losses is unknown to the learner. We design a generic algorithmic framework, \\underline{S}cale \\underline{C}lipping \\underline{B}ound (\\texttt{SCB}), and instantiate this framework in both the adversarial Multi-armed Bandit (MAB) setting and the adversarial MDP setting. Through this framework, we achieve the first minimax optimal expected regret bound and the first high-probability regret bound in scale-free adversarial MABs, resolving an open problem raised in \\cite{hadiji2023adaptation}. On adversarial MDPs, our framework also give birth to the first scale-free RL algorithm with a $\\tilde{\\mathcal{O}}(\\sqrt{T})$ high-probability regret guarantee.",
    "link": "https://arxiv.org/abs/2403.00930",
    "context": "Title: Scale-free Adversarial Reinforcement Learning\nAbstract: arXiv:2403.00930v1 Announce Type: cross  Abstract: This paper initiates the study of scale-free learning in Markov Decision Processes (MDPs), where the scale of rewards/losses is unknown to the learner. We design a generic algorithmic framework, \\underline{S}cale \\underline{C}lipping \\underline{B}ound (\\texttt{SCB}), and instantiate this framework in both the adversarial Multi-armed Bandit (MAB) setting and the adversarial MDP setting. Through this framework, we achieve the first minimax optimal expected regret bound and the first high-probability regret bound in scale-free adversarial MABs, resolving an open problem raised in \\cite{hadiji2023adaptation}. On adversarial MDPs, our framework also give birth to the first scale-free RL algorithm with a $\\tilde{\\mathcal{O}}(\\sqrt{T})$ high-probability regret guarantee.",
    "path": "papers/24/03/2403.00930.json",
    "total_tokens": 803,
    "translated_title": "无尺度对抗性强化学习",
    "translated_abstract": "本文首次研究了马尔可夫决策过程（MDPs）中的无尺度学习，其奖励/损失的尺度为学习者所不知。我们设计了一个通用的算法框架，\\underline{S}cale \\underline{C}lipping \\underline{B}ound（\\texttt{SCB}），并将这一框架实例化到对抗性多臂赌博机（MAB）设置和对抗性MDP设置中。通过这个框架，在无尺度对抗性MABs中，我们实现了第一个最小值最优期望遗憾界和第一个高概率遗憾界，解决了\\cite{hadiji2023adaptation}中提出的一个开放问题。在对抗性MDPs中，我们的框架还诞生了第一个带有$\\tilde{\\mathcal{O}}(\\sqrt{T})$高概率遗憾保证的无尺度RL算法。",
    "tldr": "本文在马尔可夫决策过程中提出了首个无尺度对抗性学习算法框架SCB，在对抗性多臂赌博机和MDP设置中取得了关键突破。"
}