{
    "title": "Re-Simulation-based Self-Supervised Learning for Pre-Training Foundation Models",
    "abstract": "arXiv:2403.07066v1 Announce Type: cross  Abstract: Self-Supervised Learning (SSL) is at the core of training modern large machine learning models, providing a scheme for learning powerful representations that can be used in a variety of downstream tasks. However, SSL strategies must be adapted to the type of training data and downstream tasks required. We propose RS3L, a novel simulation-based SSL strategy that employs a method of re-simulation to drive data augmentation for contrastive learning. By intervening in the middle of the simulation process and re-running simulation components downstream of the intervention, we generate multiple realizations of an event, thus producing a set of augmentations covering all physics-driven variations available in the simulator. Using experiments from high-energy physics, we explore how this strategy may enable the development of a foundation model; we show how R3SL pre-training enables powerful performance in downstream tasks such as discriminati",
    "link": "https://arxiv.org/abs/2403.07066",
    "context": "Title: Re-Simulation-based Self-Supervised Learning for Pre-Training Foundation Models\nAbstract: arXiv:2403.07066v1 Announce Type: cross  Abstract: Self-Supervised Learning (SSL) is at the core of training modern large machine learning models, providing a scheme for learning powerful representations that can be used in a variety of downstream tasks. However, SSL strategies must be adapted to the type of training data and downstream tasks required. We propose RS3L, a novel simulation-based SSL strategy that employs a method of re-simulation to drive data augmentation for contrastive learning. By intervening in the middle of the simulation process and re-running simulation components downstream of the intervention, we generate multiple realizations of an event, thus producing a set of augmentations covering all physics-driven variations available in the simulator. Using experiments from high-energy physics, we explore how this strategy may enable the development of a foundation model; we show how R3SL pre-training enables powerful performance in downstream tasks such as discriminati",
    "path": "papers/24/03/2403.07066.json",
    "total_tokens": 887,
    "translated_title": "基于重新模拟的自监督学习用于预训练基础模型",
    "translated_abstract": "自监督学习（SSL）是训练现代大型机器学习模型的核心，提供了一种学习强大表示的方案，可用于各种下游任务。然而，SSL策略必须适应所需的训练数据类型和下游任务。我们提出了RS3L，一种新颖的基于模拟的SSL策略，采用重新模拟的方法来驱动对比学习的数据增强。通过介入模拟过程的中间并重新运行介入之后的模拟组件，我们生成一个事件的多个实现，从而产生一组涵盖模拟器中所有物理驱动变化的增强。通过使用高能物理实验，我们探讨了这种策略如何促进基础模型的发展；我们展示了R3SL预训练如何在下游任务中实现强大的性能，例如区分任务。",
    "tldr": "提出了一种新颖的基于重新模拟的自监督学习策略RS3L，通过介入模拟过程并重新模拟事件实现，生成一组涵盖所有物理驱动变化的数据增强，从而促进基础模型的发展，并展示了预训练R3SL在下游任务中表现出强大性能。",
    "en_tdlr": "Proposed a novel simulation-based SSL strategy RS3L that intervenes in the simulation process to generate multiple data augmentations covering all physics-driven variations, enabling the development of foundation models and demonstrating powerful performance in downstream tasks through pre-training R3SL."
}