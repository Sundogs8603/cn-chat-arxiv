{
    "title": "Harnessing Multi-Role Capabilities of Large Language Models for Open-Domain Question Answering",
    "abstract": "arXiv:2403.05217v1 Announce Type: cross  Abstract: Open-domain question answering (ODQA) has emerged as a pivotal research spotlight in information systems. Existing methods follow two main paradigms to collect evidence: (1) The \\textit{retrieve-then-read} paradigm retrieves pertinent documents from an external corpus; and (2) the \\textit{generate-then-read} paradigm employs large language models (LLMs) to generate relevant documents. However, neither can fully address multifaceted requirements for evidence. To this end, we propose LLMQA, a generalized framework that formulates the ODQA process into three basic steps: query expansion, document selection, and answer generation, combining the superiority of both retrieval-based and generation-based evidence. Since LLMs exhibit their excellent capabilities to accomplish various tasks, we instruct LLMs to play multiple roles as generators, rerankers, and evaluators within our framework, integrating them to collaborate in the ODQA process. ",
    "link": "https://arxiv.org/abs/2403.05217",
    "context": "Title: Harnessing Multi-Role Capabilities of Large Language Models for Open-Domain Question Answering\nAbstract: arXiv:2403.05217v1 Announce Type: cross  Abstract: Open-domain question answering (ODQA) has emerged as a pivotal research spotlight in information systems. Existing methods follow two main paradigms to collect evidence: (1) The \\textit{retrieve-then-read} paradigm retrieves pertinent documents from an external corpus; and (2) the \\textit{generate-then-read} paradigm employs large language models (LLMs) to generate relevant documents. However, neither can fully address multifaceted requirements for evidence. To this end, we propose LLMQA, a generalized framework that formulates the ODQA process into three basic steps: query expansion, document selection, and answer generation, combining the superiority of both retrieval-based and generation-based evidence. Since LLMs exhibit their excellent capabilities to accomplish various tasks, we instruct LLMs to play multiple roles as generators, rerankers, and evaluators within our framework, integrating them to collaborate in the ODQA process. ",
    "path": "papers/24/03/2403.05217.json",
    "total_tokens": 875,
    "translated_title": "利用大型语言模型的多角色能力进行开放领域问答",
    "translated_abstract": "开放领域问答（ODQA）已经成为信息系统中的一个关键研究焦点。现有方法主要遵循两种范式来收集证据：（1）\\textit{检索-然后阅读}范式从外部语料库中检索相关文档；和（2）\\textit{生成-然后阅读}范式使用大型语言模型（LLMs）生成相关文档。然而，这两种方法都不能完全满足证据的多方面要求。因此，我们提出了LLMQA，一个通用框架，将ODQA过程分为三个基本步骤：查询扩展，文档选择和答案生成，结合了检索和生成证据的优势。由于LLMs展示了其出色的能力来完成各种任务，我们指导LLMs在我们的框架内扮演生成器、重新排序器和评估器等多种角色，使它们融合在ODQA过程中协作。",
    "tldr": "提出了LLMQA框架，利用大型语言模型在开放领域问答中扮演生成器、重新排序器和评估器等多重角色，结合了检索和生成证据的优势。",
    "en_tdlr": "Introduced the LLMQA framework that leverages the multi-role capabilities of large language models to act as generators, rerankers, and evaluators in open-domain question answering, combining the strengths of retrieval and generation-based evidence."
}