{
    "title": "Causal Prompting: Debiasing Large Language Model Prompting based on Front-Door Adjustment",
    "abstract": "arXiv:2403.02738v1 Announce Type: new  Abstract: Despite the significant achievements of existing prompting methods such as in-context learning and chain-of-thought for large language models (LLMs), they still face challenges of various biases. Traditional debiasing methods primarily focus on the model training stage, including data augmentation-based and reweight-based approaches, with the limitations of addressing the complex biases of LLMs. To address such limitations, the causal relationship behind the prompting methods is uncovered using a structural causal model, and a novel causal prompting method based on front-door adjustment is proposed to effectively mitigate the bias of LLMs. In specific, causal intervention is implemented by designing the prompts without accessing the parameters and logits of LLMs.The chain-of-thoughts generated by LLMs are employed as the mediator variable and the causal effect between the input prompt and the output answers is calculated through front-do",
    "link": "https://arxiv.org/abs/2403.02738",
    "context": "Title: Causal Prompting: Debiasing Large Language Model Prompting based on Front-Door Adjustment\nAbstract: arXiv:2403.02738v1 Announce Type: new  Abstract: Despite the significant achievements of existing prompting methods such as in-context learning and chain-of-thought for large language models (LLMs), they still face challenges of various biases. Traditional debiasing methods primarily focus on the model training stage, including data augmentation-based and reweight-based approaches, with the limitations of addressing the complex biases of LLMs. To address such limitations, the causal relationship behind the prompting methods is uncovered using a structural causal model, and a novel causal prompting method based on front-door adjustment is proposed to effectively mitigate the bias of LLMs. In specific, causal intervention is implemented by designing the prompts without accessing the parameters and logits of LLMs.The chain-of-thoughts generated by LLMs are employed as the mediator variable and the causal effect between the input prompt and the output answers is calculated through front-do",
    "path": "papers/24/03/2403.02738.json",
    "total_tokens": 712,
    "translated_title": "因果引导：基于前门调整的大型语言模型启发式去偏方法",
    "translated_abstract": "尽管现有的诸如上下文学习和思维链等大型语言模型（LLMs）启发式方法取得了显著成就，但它们仍然面临各种偏见挑战。本文揭示了启发式方法背后的因果关系，并提出了一种基于前门调整的新型因果引导方法，以有效减轻LLMs的偏见。具体而言，通过设计提示而无需访问LLMs的参数和logit来实施因果干预。由LLMs生成的思维链被用作中介变量，通过前门计算输入提示与输出答案之间的因果效应。",
    "tldr": "提出了一种新型因果引导方法，通过前门调整有效减轻大型语言模型的偏见。",
    "en_tdlr": "A novel causal prompting method based on front-door adjustment is proposed to effectively mitigate the bias of large language models (LLMs)."
}