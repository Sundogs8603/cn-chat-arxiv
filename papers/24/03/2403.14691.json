{
    "title": "Large Language Models and User Trust: Focus on Healthcare",
    "abstract": "arXiv:2403.14691v1 Announce Type: cross  Abstract: This paper explores the evolving relationship between clinician trust in LLMs, the transformation of data sources from predominantly human-generated to AI-generated content, and the subsequent impact on the precision of LLMs and clinician competence. One of the primary concerns identified is the potential feedback loop that arises as LLMs become more reliant on their outputs for learning, which may lead to a degradation in output quality and a reduction in clinician skills due to decreased engagement with fundamental diagnostic processes. While theoretical at this stage, this feedback loop poses a significant challenge as the integration of LLMs in healthcare deepens, emphasizing the need for proactive dialogue and strategic measures to ensure the safe and effective use of LLM technology. Moreover, we delve into the potential risks associated with LLMs' self-referential learning loops and the deskilling of healthcare professionals. The",
    "link": "https://arxiv.org/abs/2403.14691",
    "context": "Title: Large Language Models and User Trust: Focus on Healthcare\nAbstract: arXiv:2403.14691v1 Announce Type: cross  Abstract: This paper explores the evolving relationship between clinician trust in LLMs, the transformation of data sources from predominantly human-generated to AI-generated content, and the subsequent impact on the precision of LLMs and clinician competence. One of the primary concerns identified is the potential feedback loop that arises as LLMs become more reliant on their outputs for learning, which may lead to a degradation in output quality and a reduction in clinician skills due to decreased engagement with fundamental diagnostic processes. While theoretical at this stage, this feedback loop poses a significant challenge as the integration of LLMs in healthcare deepens, emphasizing the need for proactive dialogue and strategic measures to ensure the safe and effective use of LLM technology. Moreover, we delve into the potential risks associated with LLMs' self-referential learning loops and the deskilling of healthcare professionals. The",
    "path": "papers/24/03/2403.14691.json",
    "total_tokens": 947,
    "translated_title": "大型语言模型和用户信任：以医疗为重点",
    "translated_abstract": "本文探讨了临床医生对LLMs的信任、数据来源从主要是人类生成到人工智能生成内容的转变，以及随之而来对LLMs精确性和临床医师能力的影响之间的不断发展的关系。其中一个主要问题是随着LLMs在学习过程中越来越依赖它们的输出，可能会导致输出质量下降，并导致临床医师技能减少，因为他们与基本诊断过程的参与减少。尽管目前还处于理论阶段，但这种反馈循环构成了一个重大挑战，因为LLMs在医疗保健中的整合加深，强调了需要积极对话和战略措施，以确保LLM技术的安全有效使用。此外，我们深入探讨了与LLMs自我参考学习循环以及医疗保健专业人员技能下降相关的潜在风险。",
    "tldr": "本文探讨了临床医生对LLMs的信任、数据来源从主要是人类生成到人工智能生成内容的转变，以及随之而来对LLMs精确性和临床医师能力的影响之间的不断发展的关系，强调了LLMs在医疗保健中的整合加深可能带来的挑战和风险。",
    "en_tdlr": "This paper explores the evolving relationship between clinician trust in LLMs, the transformation of data sources from predominantly human-generated to AI-generated content, and the subsequent impact on the precision of LLMs and clinician competence, emphasizing the potential challenges and risks as LLMs are more deeply integrated into healthcare."
}