{
    "title": "On the Consideration of AI Openness: Can Good Intent Be Abused?",
    "abstract": "arXiv:2403.06537v1 Announce Type: new  Abstract: Openness is critical for the advancement of science. In particular, recent rapid progress in AI has been made possible only by various open-source models, datasets, and libraries. However, this openness also means that technologies can be freely used for socially harmful purposes. Can open-source models or datasets be used for malicious purposes? If so, how easy is it to adapt technology for such goals? Here, we conduct a case study in the legal domain, a realm where individual decisions can have profound social consequences. To this end, we build EVE, a dataset consisting of 200 examples of questions and corresponding answers about criminal activities based on 200 Korean precedents. We found that a widely accepted open-source LLM, which initially refuses to answer unethical questions, can be easily tuned with EVE to provide unethical and informative answers about criminal activities. This implies that although open-source technologies c",
    "link": "https://arxiv.org/abs/2403.06537",
    "context": "Title: On the Consideration of AI Openness: Can Good Intent Be Abused?\nAbstract: arXiv:2403.06537v1 Announce Type: new  Abstract: Openness is critical for the advancement of science. In particular, recent rapid progress in AI has been made possible only by various open-source models, datasets, and libraries. However, this openness also means that technologies can be freely used for socially harmful purposes. Can open-source models or datasets be used for malicious purposes? If so, how easy is it to adapt technology for such goals? Here, we conduct a case study in the legal domain, a realm where individual decisions can have profound social consequences. To this end, we build EVE, a dataset consisting of 200 examples of questions and corresponding answers about criminal activities based on 200 Korean precedents. We found that a widely accepted open-source LLM, which initially refuses to answer unethical questions, can be easily tuned with EVE to provide unethical and informative answers about criminal activities. This implies that although open-source technologies c",
    "path": "papers/24/03/2403.06537.json",
    "total_tokens": 906,
    "translated_title": "对AI开放性的考量: 善意能否被滥用？",
    "translated_abstract": "开放性对科学的进展至关重要。特别是，最近人工智能的快速进展仅可能通过各种开源模型、数据集和库。然而，这种开放性也意味着技术可以被自由地用于社会有害目的。开源模型或数据集可以被用于恶意目的吗？如果是这样，那么技术被用于这些目的会有多容易？本文在法律领域进行了一个案例研究，这是一个个人决策可能产生深远社会后果的领域。为此，我们构建了EVE数据集，包含了200个关于犯罪活动的问题和对应答案，基于200个韩国先例。我们发现一个广泛认可的开源LLM，最初拒绝回答不道德问题，可以很容易地通过EVE进行调整，提供关于犯罪活动的不道德且具有信息性的答案。这意味着，尽管开源技术能够促进科学技术进步，但同时也带来了滥用风险。",
    "tldr": "开源技术虽然促进了科技进步，但也存在滥用风险，研究发现开源语言模型可以被调整用于提供有关犯罪活动的不道德且具有信息性的答案。",
    "en_tdlr": "Although open-source technologies facilitate technological advancements, they also pose risks for misuse, as the study found that open-source language models can be adapted to provide unethical and informative answers about criminal activities."
}