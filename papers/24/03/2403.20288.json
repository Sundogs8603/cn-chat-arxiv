{
    "title": "Can LLMs Correct Physicians, Yet? Investigating Effective Interaction Methods in the Medical Domain",
    "abstract": "arXiv:2403.20288v1 Announce Type: cross  Abstract: We explore the potential of Large Language Models (LLMs) to assist and potentially correct physicians in medical decision-making tasks. We evaluate several LLMs, including Meditron, Llama2, and Mistral, to analyze the ability of these models to interact effectively with physicians across different scenarios. We consider questions from PubMedQA and several tasks, ranging from binary (yes/no) responses to long answer generation, where the answer of the model is produced after an interaction with a physician. Our findings suggest that prompt design significantly influences the downstream accuracy of LLMs and that LLMs can provide valuable feedback to physicians, challenging incorrect diagnoses and contributing to more accurate decision-making. For example, when the physician is accurate 38% of the time, Mistral can produce the correct answer, improving accuracy up to 74% depending on the prompt being used, while Llama2 and Meditron models",
    "link": "https://arxiv.org/abs/2403.20288",
    "context": "Title: Can LLMs Correct Physicians, Yet? Investigating Effective Interaction Methods in the Medical Domain\nAbstract: arXiv:2403.20288v1 Announce Type: cross  Abstract: We explore the potential of Large Language Models (LLMs) to assist and potentially correct physicians in medical decision-making tasks. We evaluate several LLMs, including Meditron, Llama2, and Mistral, to analyze the ability of these models to interact effectively with physicians across different scenarios. We consider questions from PubMedQA and several tasks, ranging from binary (yes/no) responses to long answer generation, where the answer of the model is produced after an interaction with a physician. Our findings suggest that prompt design significantly influences the downstream accuracy of LLMs and that LLMs can provide valuable feedback to physicians, challenging incorrect diagnoses and contributing to more accurate decision-making. For example, when the physician is accurate 38% of the time, Mistral can produce the correct answer, improving accuracy up to 74% depending on the prompt being used, while Llama2 and Meditron models",
    "path": "papers/24/03/2403.20288.json",
    "total_tokens": 847,
    "translated_title": "LLM能够在医学领域中纠正医生吗？研究有效的交互方法",
    "translated_abstract": "我们探讨了大型语言模型（LLMs）在协助并可能纠正医生进行医疗决策任务方面的潜力。我们评估了几种LLMs，包括Meditron、Llama2和Mistral，分析这些模型在不同情景下与医生有效交互的能力。我们考虑了来自PubMedQA的问题和几项任务，从二元（是/否）回答到长答案生成，其中模型的答案是在与医生交互后产生的。我们的研究结果表明，提示设计显著影响了LLMs的下游准确性，并且LLMs可以为医生提供有价值的反馈，挑战不正确的诊断，促进更准确的决策。例如，当医生准确率为38%时，Mistral可以给出正确答案，根据所使用的提示，将准确性提高到74%，而Llama2和Meditron模型也能提供类似的改进。",
    "tldr": "LLMs在医学决策中提供重要反馈，可以挑战不正确的诊断，促进更准确的决策。",
    "en_tdlr": "LLMs provide valuable feedback in medical decision-making, challenging incorrect diagnoses and facilitating more accurate decisions."
}