{
    "title": "Exploring the Impact of Dataset Bias on Dataset Distillation",
    "abstract": "arXiv:2403.16028v1 Announce Type: cross  Abstract: Dataset Distillation (DD) is a promising technique to synthesize a smaller dataset that preserves essential information from the original dataset. This synthetic dataset can serve as a substitute for the original large-scale one, and help alleviate the training workload. However, current DD methods typically operate under the assumption that the dataset is unbiased, overlooking potential bias issues within the dataset itself. To fill in this blank, we systematically investigate the influence of dataset bias on DD. To the best of our knowledge, this is the first exploration in the DD domain. Given that there are no suitable biased datasets for DD, we first construct two biased datasets, CMNIST-DD and CCIFAR10-DD, to establish a foundation for subsequent analysis. Then we utilize existing DD methods to generate synthetic datasets on CMNIST-DD and CCIFAR10-DD, and evaluate their performance following the standard process. Experiments demo",
    "link": "https://arxiv.org/abs/2403.16028",
    "context": "Title: Exploring the Impact of Dataset Bias on Dataset Distillation\nAbstract: arXiv:2403.16028v1 Announce Type: cross  Abstract: Dataset Distillation (DD) is a promising technique to synthesize a smaller dataset that preserves essential information from the original dataset. This synthetic dataset can serve as a substitute for the original large-scale one, and help alleviate the training workload. However, current DD methods typically operate under the assumption that the dataset is unbiased, overlooking potential bias issues within the dataset itself. To fill in this blank, we systematically investigate the influence of dataset bias on DD. To the best of our knowledge, this is the first exploration in the DD domain. Given that there are no suitable biased datasets for DD, we first construct two biased datasets, CMNIST-DD and CCIFAR10-DD, to establish a foundation for subsequent analysis. Then we utilize existing DD methods to generate synthetic datasets on CMNIST-DD and CCIFAR10-DD, and evaluate their performance following the standard process. Experiments demo",
    "path": "papers/24/03/2403.16028.json",
    "total_tokens": 837,
    "translated_title": "探究数据集偏差对数据集精简的影响",
    "translated_abstract": "数据集精简（DD）是一种有前途的技术，用于合成一个保留原始数据集中基本信息的较小数据集。这个合成数据集可以作为原始大规模数据集的替代品，并有助于减轻训练负担。然而，当前的DD方法通常在假设数据集不具有偏见的情况下运作，忽视了数据集本身可能存在的潜在偏见问题。为了填补这一空白，我们系统地调查了数据集偏差对DD的影响。据我们所知，这是DD领域的首次探索。鉴于目前没有适用于DD的偏见数据集，我们首先构建了两个偏见数据集，CMNIST-DD和CCIFAR10-DD，为随后的分析奠定基础。然后我们利用现有的DD方法在CMNIST-DD和CCIFAR10-DD上生成合成数据集，并按照标准流程评估它们的性能。",
    "tldr": "针对数据集精简中的数据集偏差问题，我们进行了首次系统调查与探索，构建并评估了两个偏见数据集，为未来研究提供了基础。",
    "en_tdlr": "In the context of dataset distillation, we conducted the first systematic investigation on dataset bias, constructing and evaluating biased datasets, laying the foundation for future research."
}