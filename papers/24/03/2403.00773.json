{
    "title": "Misconduct in Post-Selections and Deep Learning",
    "abstract": "arXiv:2403.00773v1 Announce Type: new  Abstract: This is a theoretical paper on \"Deep Learning\" misconduct in particular and Post-Selection in general. As far as the author knows, the first peer-reviewed papers on Deep Learning misconduct are [32], [37], [36]. Regardless of learning modes, e.g., supervised, reinforcement, adversarial, and evolutional, almost all machine learning methods (except for a few methods that train a sole system) are rooted in the same misconduct -- cheating and hiding -- (1) cheating in the absence of a test and (2) hiding bad-looking data. It was reasoned in [32], [37], [36] that authors must report at least the average error of all trained networks, good and bad, on the validation set (called general cross-validation in this paper). Better, report also five percentage positions of ranked errors. From the new analysis here, we can see that the hidden culprit is Post-Selection. This is also true for Post-Selection on hand-tuned or searched hyperparameters, bec",
    "link": "https://arxiv.org/abs/2403.00773",
    "context": "Title: Misconduct in Post-Selections and Deep Learning\nAbstract: arXiv:2403.00773v1 Announce Type: new  Abstract: This is a theoretical paper on \"Deep Learning\" misconduct in particular and Post-Selection in general. As far as the author knows, the first peer-reviewed papers on Deep Learning misconduct are [32], [37], [36]. Regardless of learning modes, e.g., supervised, reinforcement, adversarial, and evolutional, almost all machine learning methods (except for a few methods that train a sole system) are rooted in the same misconduct -- cheating and hiding -- (1) cheating in the absence of a test and (2) hiding bad-looking data. It was reasoned in [32], [37], [36] that authors must report at least the average error of all trained networks, good and bad, on the validation set (called general cross-validation in this paper). Better, report also five percentage positions of ranked errors. From the new analysis here, we can see that the hidden culprit is Post-Selection. This is also true for Post-Selection on hand-tuned or searched hyperparameters, bec",
    "path": "papers/24/03/2403.00773.json",
    "total_tokens": 830,
    "translated_title": "后选择和深度学习中的不端行为",
    "translated_abstract": "这是关于“深度学习”特别是一般后选择中不端行为的理论论文。作者所知，关于深度学习不端行为的第一篇同行评审论文是[32]，[37]和[36]。无论学习模式是监督，强化，对抗还是进化，几乎所有机器学习方法（除了少数训练单一系统的方法）都根源于同样的不端行为-作弊和隐藏-（1）在没有测试的情况下作弊以及（2）隐藏外观不佳的数据。在[32]，[37]，[36]中推理，作者必须至少报告所有已训练网络在验证集上的平均误差（本文中称为通用交叉验证）。最好还报告排名误差的五个百分比位置。从这里的新分析中，我们可以看到隐藏的罪魁祸首是后选择。对手动调整或搜索超参数的后选择也是如此。",
    "tldr": "该论文讨论了深度学习和后选择中的不端行为，并提出了对于解决这一问题的新观点。",
    "en_tdlr": "The paper discusses misconduct in deep learning and post-selection, introducing new insights for addressing these issues."
}