{
    "title": "Linguistic Structure Induction from Language Models",
    "abstract": "arXiv:2403.09714v1 Announce Type: cross  Abstract: Linear sequences of words are implicitly represented in our brains by hierarchical structures that organize the composition of words in sentences. Linguists formalize different frameworks to model this hierarchy; two of the most common syntactic frameworks are Constituency and Dependency. Constituency represents sentences as nested groups of phrases, while dependency represents a sentence by assigning relations between its words. Recently, the pursuit of intelligent machines has produced Language Models (LMs) capable of solving many language tasks with a human-level performance. Many studies now question whether LMs implicitly represent syntactic hierarchies. This thesis focuses on producing constituency and dependency structures from LMs in an unsupervised setting. I review the critical methods in this field and highlight a line of work that utilizes a numerical representation for binary constituency trees (Syntactic Distance). I pres",
    "link": "https://arxiv.org/abs/2403.09714",
    "context": "Title: Linguistic Structure Induction from Language Models\nAbstract: arXiv:2403.09714v1 Announce Type: cross  Abstract: Linear sequences of words are implicitly represented in our brains by hierarchical structures that organize the composition of words in sentences. Linguists formalize different frameworks to model this hierarchy; two of the most common syntactic frameworks are Constituency and Dependency. Constituency represents sentences as nested groups of phrases, while dependency represents a sentence by assigning relations between its words. Recently, the pursuit of intelligent machines has produced Language Models (LMs) capable of solving many language tasks with a human-level performance. Many studies now question whether LMs implicitly represent syntactic hierarchies. This thesis focuses on producing constituency and dependency structures from LMs in an unsupervised setting. I review the critical methods in this field and highlight a line of work that utilizes a numerical representation for binary constituency trees (Syntactic Distance). I pres",
    "path": "papers/24/03/2403.09714.json",
    "total_tokens": 828,
    "translated_title": "从语言模型中诱导语言结构",
    "translated_abstract": "我们大脑中隐式地通过分层结构来组织单词在句子中的组成，而这些结构形成了单词的线性序列。语言学家们形式化了不同的框架来模拟这种层次结构；其中最常见的两种句法框架是短语结构和依存结构。短语结构将句子表示为短语的嵌套组，而依存结构通过为单词之间分配关系来表示句子。最近，对智能机器的追求产生了能够以人类水平完成许多语言任务的语言模型（LMs）。许多研究现在质疑LMs是否隐式地表示句法层次结构。本论文集中于在非监督设置中从LMs中生成短语结构和依存结构。我回顾了该领域的关键方法并重点介绍了一项利用二元短语结构树的数值表示（语法距离）的工作线。",
    "tldr": "该论文研究从语言模型中以非监督方式生成句法结构的方法，其中介绍了一种利用数值表示短语树的新方法。",
    "en_tdlr": "This paper investigates methods for generating syntactic structures from language models in an unsupervised manner, introducing a new approach using numerical representation of phrase trees."
}