{
    "title": "A Knowledge Plug-and-Play Test Bed for Open-domain Dialogue Generation",
    "abstract": "arXiv:2403.03496v1 Announce Type: new  Abstract: Knowledge-based, open-domain dialogue generation aims to build chit-chat systems that talk to humans using mined support knowledge. Many types and sources of knowledge have previously been shown to be useful as support knowledge. Even in the era of large language models, response generation grounded in knowledge retrieved from additional up-to-date sources remains a practically important approach. While prior work using single-source knowledge has shown a clear positive correlation between the performances of knowledge selection and response generation, there are no existing multi-source datasets for evaluating support knowledge retrieval. Further, prior work has assumed that the knowledge sources available at test time are the same as during training. This unrealistic assumption unnecessarily handicaps models, as new knowledge sources can become available after a model is trained. In this paper, we present a high-quality benchmark named",
    "link": "https://arxiv.org/abs/2403.03496",
    "context": "Title: A Knowledge Plug-and-Play Test Bed for Open-domain Dialogue Generation\nAbstract: arXiv:2403.03496v1 Announce Type: new  Abstract: Knowledge-based, open-domain dialogue generation aims to build chit-chat systems that talk to humans using mined support knowledge. Many types and sources of knowledge have previously been shown to be useful as support knowledge. Even in the era of large language models, response generation grounded in knowledge retrieved from additional up-to-date sources remains a practically important approach. While prior work using single-source knowledge has shown a clear positive correlation between the performances of knowledge selection and response generation, there are no existing multi-source datasets for evaluating support knowledge retrieval. Further, prior work has assumed that the knowledge sources available at test time are the same as during training. This unrealistic assumption unnecessarily handicaps models, as new knowledge sources can become available after a model is trained. In this paper, we present a high-quality benchmark named",
    "path": "papers/24/03/2403.03496.json",
    "total_tokens": 658,
    "translated_title": "一个用于开放领域对话生成的知识即插即用测试平台",
    "translated_abstract": "基于知识的开放领域对话生成旨在构建可以利用挖掘的支持知识与人类交谈的闲聊系统。先前已经展示了许多种类型和来源的知识作为支持知识是有用的。即使在大语言模型时代，基于从额外最新源检索的知识进行回应生成仍然是一种实际重要的方法。本文提出了一个高质量的基准测试",
    "tldr": "本文提出了一个新的高质量基准测试，用于评估支持知识检索，在开放领域对话生成中引入新的知识源",
    "en_tdlr": "This paper introduces a new high-quality benchmark for evaluating support knowledge retrieval and introducing new sources of knowledge in open-domain dialogue generation."
}