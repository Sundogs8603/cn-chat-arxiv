{
    "title": "TableLLM: Enabling Tabular Data Manipulation by LLMs in Real Office Usage Scenarios",
    "abstract": "arXiv:2403.19318v1 Announce Type: new  Abstract: We introduce TableLLM, a robust large language model (LLM) with 13 billion parameters, purpose-built for proficiently handling tabular data manipulation tasks, whether they are embedded within documents or spreadsheets, catering to real-world office scenarios. We propose a distant supervision method for training, which comprises a reasoning process extension strategy, aiding in training LLMs to understand reasoning patterns more effectively as well as a cross-way validation strategy, ensuring the quality of the automatically generated data. To evaluate the performance of TableLLM, we have crafted a benchmark tailored to address both document and spreadsheet formats as well as constructed a well-organized evaluation pipeline capable of handling both scenarios. Thorough evaluations underscore the advantages of TableLLM when compared to various existing general-purpose and tabular data-focused LLMs. We have publicly released the model check",
    "link": "https://arxiv.org/abs/2403.19318",
    "context": "Title: TableLLM: Enabling Tabular Data Manipulation by LLMs in Real Office Usage Scenarios\nAbstract: arXiv:2403.19318v1 Announce Type: new  Abstract: We introduce TableLLM, a robust large language model (LLM) with 13 billion parameters, purpose-built for proficiently handling tabular data manipulation tasks, whether they are embedded within documents or spreadsheets, catering to real-world office scenarios. We propose a distant supervision method for training, which comprises a reasoning process extension strategy, aiding in training LLMs to understand reasoning patterns more effectively as well as a cross-way validation strategy, ensuring the quality of the automatically generated data. To evaluate the performance of TableLLM, we have crafted a benchmark tailored to address both document and spreadsheet formats as well as constructed a well-organized evaluation pipeline capable of handling both scenarios. Thorough evaluations underscore the advantages of TableLLM when compared to various existing general-purpose and tabular data-focused LLMs. We have publicly released the model check",
    "path": "papers/24/03/2403.19318.json",
    "total_tokens": 889,
    "translated_title": "TableLLM：在实际办公使用场景中实现LLMs对表格数据进行处理的能力",
    "translated_abstract": "我们介绍了TableLLM，这是一个拥有130亿参数的强大大语言模型（LLM），专门用于熟练处理表格数据操作任务，无论其嵌入在文档还是电子表格中，以满足真实办公场景需求。我们提出了一种远程监督方法进行训练，其中包括一种推理过程扩展策略，有助于训练LLMs更有效地理解推理模式，以及一种交叉验证策略，确保自动生成数据的质量。为了评估TableLLM的性能，我们构建了一个旨在解决文档和电子表格格式的基准测试，并构建了一个能够处理两种场景的组织良好的评估管线。彻底的评估凸显了TableLLM相对于各种现有通用和专注于表格数据的LLMs的优势。我们已公开发布了该模型。",
    "tldr": "TableLLM是一个拥有130亿参数的强大大语言模型，专门用于熟练处理表格数据操作任务，通过远程监督方法和交叉验证策略，TableLLM相对于其他现有的通用和表格数据专注的LLMs具有明显优势。",
    "en_tdlr": "TableLLM is a powerful large language model with 13 billion parameters, specifically designed for proficiently handling tabular data manipulation tasks. Through distant supervision training and cross-way validation strategy, TableLLM demonstrates significant advantages over other existing general-purpose and tabular data-focused LLMs."
}