{
    "title": "Improving Learnt Local MAPF Policies with Heuristic Search",
    "abstract": "arXiv:2403.20300v1 Announce Type: cross  Abstract: Multi-agent path finding (MAPF) is the problem of finding collision-free paths for a team of agents to reach their goal locations. State-of-the-art classical MAPF solvers typically employ heuristic search to find solutions for hundreds of agents but are typically centralized and can struggle to scale when run with short timeouts. Machine learning (ML) approaches that learn policies for each agent are appealing as these could enable decentralized systems and scale well while maintaining good solution quality. Current ML approaches to MAPF have proposed methods that have started to scratch the surface of this potential. However, state-of-the-art ML approaches produce \"local\" policies that only plan for a single timestep and have poor success rates and scalability. Our main idea is that we can improve a ML local policy by using heuristic search methods on the output probability distribution to resolve deadlocks and enable full horizon pla",
    "link": "https://arxiv.org/abs/2403.20300",
    "context": "Title: Improving Learnt Local MAPF Policies with Heuristic Search\nAbstract: arXiv:2403.20300v1 Announce Type: cross  Abstract: Multi-agent path finding (MAPF) is the problem of finding collision-free paths for a team of agents to reach their goal locations. State-of-the-art classical MAPF solvers typically employ heuristic search to find solutions for hundreds of agents but are typically centralized and can struggle to scale when run with short timeouts. Machine learning (ML) approaches that learn policies for each agent are appealing as these could enable decentralized systems and scale well while maintaining good solution quality. Current ML approaches to MAPF have proposed methods that have started to scratch the surface of this potential. However, state-of-the-art ML approaches produce \"local\" policies that only plan for a single timestep and have poor success rates and scalability. Our main idea is that we can improve a ML local policy by using heuristic search methods on the output probability distribution to resolve deadlocks and enable full horizon pla",
    "path": "papers/24/03/2403.20300.json",
    "total_tokens": 853,
    "translated_title": "用启发式搜索改进学到的局部MAPF策略",
    "translated_abstract": "多智能体路径规划（MAPF）是在团队智能体到达目标位置时找到无碰撞路径的问题。目前最先进的经典MAPF求解器通常采用启发式搜索来找到数百个智能体的解决方案，但通常是集中式的，并且在短时间内运行时很难扩展。学习每个智能体策略的机器学习（ML）方法很有吸引力，因为这些方法可以实现去中心化系统并且在保持良好解决方案质量的同时可以很好地扩展。当前关于MAPF的ML方法提出了一些方法，已经开始探讨这一潜力。然而，最先进的ML方法生成“局部”策略，仅计划单个时间步，并且成功率和可扩展性较差。我们的主要想法是，通过使用启发式搜索方法处理输出概率分布，我们可以改进ML局部策略以解决死锁并启用完整时间跨度的规划。",
    "tldr": "我们提出了通过在输出概率分布上使用启发式搜索方法来改进ML局部策略，以解决死锁并启用完整时间跨度规划的主要想法",
    "en_tdlr": "Our main idea is to improve a ML local policy by using heuristic search methods on the output probability distribution to resolve deadlocks and enable full horizon planning."
}