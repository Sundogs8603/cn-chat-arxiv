{
    "title": "ParFormer: Vision Transformer Baseline with Parallel Local Global Token Mixer and Convolution Attention Patch Embedding",
    "abstract": "arXiv:2403.15004v1 Announce Type: cross  Abstract: This work presents ParFormer as an enhanced transformer architecture that allows the incorporation of different token mixers into a single stage, hence improving feature extraction capabilities. Integrating both local and global data allows for precise representation of short- and long-range spatial relationships without the need for computationally intensive methods such as shifting windows. Along with the parallel token mixer encoder, We offer the Convolutional Attention Patch Embedding (CAPE) as an enhancement of standard patch embedding to improve token mixer extraction with a convolutional attention module. Our comprehensive evaluation demonstrates that our ParFormer outperforms CNN-based and state-of-the-art transformer-based architectures in image classification and several complex tasks such as object recognition. The proposed CAPE has been demonstrated to benefit the overall MetaFormer architecture, even while utilizing the Id",
    "link": "https://arxiv.org/abs/2403.15004",
    "context": "Title: ParFormer: Vision Transformer Baseline with Parallel Local Global Token Mixer and Convolution Attention Patch Embedding\nAbstract: arXiv:2403.15004v1 Announce Type: cross  Abstract: This work presents ParFormer as an enhanced transformer architecture that allows the incorporation of different token mixers into a single stage, hence improving feature extraction capabilities. Integrating both local and global data allows for precise representation of short- and long-range spatial relationships without the need for computationally intensive methods such as shifting windows. Along with the parallel token mixer encoder, We offer the Convolutional Attention Patch Embedding (CAPE) as an enhancement of standard patch embedding to improve token mixer extraction with a convolutional attention module. Our comprehensive evaluation demonstrates that our ParFormer outperforms CNN-based and state-of-the-art transformer-based architectures in image classification and several complex tasks such as object recognition. The proposed CAPE has been demonstrated to benefit the overall MetaFormer architecture, even while utilizing the Id",
    "path": "papers/24/03/2403.15004.json",
    "total_tokens": 837,
    "translated_title": "ParFormer：具有并行局部全局标记混合器和卷积注意力补丁嵌入的视觉Transformer基线",
    "translated_abstract": "本文提出了ParFormer作为一种增强型Transformer架构，允许将不同的标记混合器整合到单个阶段中，从而提高特征提取能力。同时整合本地和全局数据，实现对短程和长程空间关系的精确表示，而无需像平移窗口这样需要大量计算的方法。除了并行标记混合器编码器外，我们提供了卷积注意力补丁嵌入(CAPE)，作为标准补丁嵌入的增强，通过卷积注意力模块改进标记混合器提取。我们的全面评估表明，我们的ParFormer在图像分类和物体识别等多个复杂任务中优于基于CNN和最先进的基于Transformer的架构。所提出的CAPE已被证明有益于整体MetaFormer架构，即使使用Id。",
    "tldr": "ParFormer提出了并行局部全局标记混合器和卷积注意力补丁嵌入，优化了特征提取能力，在图像分类和对象识别等任务中表现优于CNN和最先进的Transformer架构。",
    "en_tdlr": "ParFormer proposes parallel local global token mixer and convolution attention patch embedding, enhancing feature extraction capabilities and outperforming CNN-based and state-of-the-art transformer-based architectures in tasks such as image classification and object recognition."
}