{
    "title": "iScore: Visual Analytics for Interpreting How Language Models Automatically Score Summaries",
    "abstract": "arXiv:2403.04760v1 Announce Type: cross  Abstract: The recent explosion in popularity of large language models (LLMs) has inspired learning engineers to incorporate them into adaptive educational tools that automatically score summary writing. Understanding and evaluating LLMs is vital before deploying them in critical learning environments, yet their unprecedented size and expanding number of parameters inhibits transparency and impedes trust when they underperform. Through a collaborative user-centered design process with several learning engineers building and deploying summary scoring LLMs, we characterized fundamental design challenges and goals around interpreting their models, including aggregating large text inputs, tracking score provenance, and scaling LLM interpretability methods. To address their concerns, we developed iScore, an interactive visual analytics tool for learning engineers to upload, score, and compare multiple summaries simultaneously. Tightly integrated views",
    "link": "https://arxiv.org/abs/2403.04760",
    "context": "Title: iScore: Visual Analytics for Interpreting How Language Models Automatically Score Summaries\nAbstract: arXiv:2403.04760v1 Announce Type: cross  Abstract: The recent explosion in popularity of large language models (LLMs) has inspired learning engineers to incorporate them into adaptive educational tools that automatically score summary writing. Understanding and evaluating LLMs is vital before deploying them in critical learning environments, yet their unprecedented size and expanding number of parameters inhibits transparency and impedes trust when they underperform. Through a collaborative user-centered design process with several learning engineers building and deploying summary scoring LLMs, we characterized fundamental design challenges and goals around interpreting their models, including aggregating large text inputs, tracking score provenance, and scaling LLM interpretability methods. To address their concerns, we developed iScore, an interactive visual analytics tool for learning engineers to upload, score, and compare multiple summaries simultaneously. Tightly integrated views",
    "path": "papers/24/03/2403.04760.json",
    "total_tokens": 825,
    "translated_title": "iScore: 用于解释语言模型如何自动评分摘要的可视化分析",
    "translated_abstract": "近年来，大型语言模型（LLMs）的普及急剧增长，激发了学习工程师将它们纳入自适应教育工具中，用于自动评分摘要写作。在将它们部署到关键学习环境之前，了解和评估LLMs至关重要，然而它们数量庞大的参数和日益增加的规模阻碍了透明度，当它们表现不佳时还会影响信任。通过与多位构建和部署摘要评分LLMs的学习工程师展开协作的用户中心设计过程，我们界定了解释其模型的基本设计挑战和目标，包括整合大量文本输入、跟踪得分来源以及扩展LLM可解释性方法。为了解决他们的关切，我们开发了iScore，一款互动式可视化分析工具，供学习工程师同时上传、评分和比较多个摘要。与此同时紧密集成的视图",
    "tldr": "设计了iScore工具，通过用户中心设计过程解决了大型语言模型在自动评分摘要中的透明度和信任问题",
    "en_tdlr": "Developed iScore tool to address transparency and trust issues of large language models in automatically scoring summaries through a user-centered design process."
}