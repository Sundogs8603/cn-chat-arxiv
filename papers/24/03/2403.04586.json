{
    "title": "Learning Agility Adaptation for Flight in Clutter",
    "abstract": "arXiv:2403.04586v1 Announce Type: cross  Abstract: Animals learn to adapt agility of their movements to their capabilities and the environment they operate in. Mobile robots should also demonstrate this ability to combine agility and safety. The aim of this work is to endow flight vehicles with the ability of agility adaptation in prior unknown and partially observable cluttered environments. We propose a hierarchical learning and planning framework where we utilize both trial and error to comprehensively learn an agility policy with the vehicle's observation as the input, and well-established methods of model-based trajectory generation. Technically, we use online model-free reinforcement learning and a pre-training-fine-tuning reward scheme to obtain the deployable policy. The statistical results in simulation demonstrate the advantages of our method over the constant agility baselines and an alternative method in terms of flight efficiency and safety. In particular, the policy leads",
    "link": "https://arxiv.org/abs/2403.04586",
    "context": "Title: Learning Agility Adaptation for Flight in Clutter\nAbstract: arXiv:2403.04586v1 Announce Type: cross  Abstract: Animals learn to adapt agility of their movements to their capabilities and the environment they operate in. Mobile robots should also demonstrate this ability to combine agility and safety. The aim of this work is to endow flight vehicles with the ability of agility adaptation in prior unknown and partially observable cluttered environments. We propose a hierarchical learning and planning framework where we utilize both trial and error to comprehensively learn an agility policy with the vehicle's observation as the input, and well-established methods of model-based trajectory generation. Technically, we use online model-free reinforcement learning and a pre-training-fine-tuning reward scheme to obtain the deployable policy. The statistical results in simulation demonstrate the advantages of our method over the constant agility baselines and an alternative method in terms of flight efficiency and safety. In particular, the policy leads",
    "path": "papers/24/03/2403.04586.json",
    "total_tokens": 932,
    "translated_title": "在杂乱环境中学习飞行敏捷性调整",
    "translated_abstract": "动物学习适应其运动能力和操作环境的敏捷性。移动机器人也应展示这种能力，将敏捷性和安全性结合起来。本文旨在赋予飞行器在未知且部分可观测的杂乱环境中适应敏捷性的能力。我们提出了一种分层学习和规划框架，结合试错学习和基于模型的轨迹生成方法来全面学习敏捷性策略。我们使用在线无模型强化学习和预训练微调奖励方案来获得可部署的策略。在仿真中的统计结果显示，相较于恒定敏捷性基线和另一种替代方法，我们的方法在飞行效率和安全性方面具有优势。特别是，该策略导致",
    "tldr": "本文旨在使飞行器在未知且部分可观测的杂乱环境中具有敏捷性调整能力，提出了一种利用分层学习和规划框架的方法，通过在线无模型强化学习和预训练微调奖励方案获得可部署的策略，在仿真中显示出比恒定敏捷性基线和另一种替代方法更优越的飞行效率和安全性。",
    "en_tdlr": "This paper aims to endow flight vehicles with the ability of agility adaptation in prior unknown and partially observable cluttered environments. It proposes a method utilizing a hierarchical learning and planning framework, obtaining deployable policy through online model-free reinforcement learning and pre-training-fine-tuning reward scheme, showing advantages over constant agility baselines and an alternative method in flight efficiency and safety in simulations."
}