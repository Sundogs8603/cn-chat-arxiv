{
    "title": "Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases",
    "abstract": "arXiv:2403.16396v1 Announce Type: new  Abstract: Definition bias is a negative phenomenon that can mislead models. Definition bias in information extraction appears not only across datasets from different domains but also within datasets sharing the same domain. We identify two types of definition bias in IE: bias among information extraction datasets and bias between information extraction datasets and instruction tuning datasets. To systematically investigate definition bias, we conduct three probing experiments to quantitatively analyze it and discover the limitations of unified information extraction and large language models in solving definition bias. To mitigate definition bias in information extraction, we propose a multi-stage framework consisting of definition bias measurement, bias-aware fine-tuning, and task-specific bias mitigation. Experimental results demonstrate the effectiveness of our framework in addressing definition bias. Resources of this paper can be found at htt",
    "link": "https://arxiv.org/abs/2403.16396",
    "context": "Title: Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases\nAbstract: arXiv:2403.16396v1 Announce Type: new  Abstract: Definition bias is a negative phenomenon that can mislead models. Definition bias in information extraction appears not only across datasets from different domains but also within datasets sharing the same domain. We identify two types of definition bias in IE: bias among information extraction datasets and bias between information extraction datasets and instruction tuning datasets. To systematically investigate definition bias, we conduct three probing experiments to quantitatively analyze it and discover the limitations of unified information extraction and large language models in solving definition bias. To mitigate definition bias in information extraction, we propose a multi-stage framework consisting of definition bias measurement, bias-aware fine-tuning, and task-specific bias mitigation. Experimental results demonstrate the effectiveness of our framework in addressing definition bias. Resources of this paper can be found at htt",
    "path": "papers/24/03/2403.16396.json",
    "total_tokens": 820,
    "translated_title": "是否存在适用于所有情况的信息抽取一体化模型？重新审视任务定义偏见",
    "translated_abstract": "定义偏见是一种负面现象，可能会误导模型。信息抽取中的定义偏见不仅存在于来自不同领域的数据集之间，还存在于分享相同领域的数据集内部。本文确定了信息抽取中的两种定义偏见类型：在信息抽取数据集之间的偏见，以及在信息抽取数据集与指导调优数据集之间的偏见。为了系统地研究定义偏见，我们进行了三项探究性实验来定量分析它，并发现统一信息抽取和大型语言模型在解决定义偏见方面的局限性。为了减轻信息抽取中的定义偏见，我们提出了一个由定义偏见测量、偏见感知微调和任务特定偏见缓解组成的多阶段框架。实验结果表明我们的框架在应对定义偏见方面的有效性。本文资源可在htt找到",
    "tldr": "重新审视信息抽取中的任务定义偏见现象，提出了一个多阶段框架来衡量、感知和缓解这种偏见，实验证明该框架有效性。",
    "en_tdlr": "Addressing the task definition biases in information extraction, a multi-stage framework is proposed to measure, perceive, and mitigate biases, with experimental validation of its effectiveness."
}