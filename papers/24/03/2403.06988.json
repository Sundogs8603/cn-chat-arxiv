{
    "title": "Guiding LLMs The Right Way: Fast, Non-Invasive Constrained Generation",
    "abstract": "arXiv:2403.06988v1 Announce Type: cross  Abstract: To ensure that text generated by large language models (LLMs) is in an expected format, constrained decoding proposes to enforce strict formal language constraints during generation. However, as we show in this work, not only do such methods incur performance overhead during generation, but many of them also significantly impair task accuracy, if they do not correctly align the underlying LLM sub-word vocabularies with external constraints. To address this, we present a novel decoding algorithm, DOMINO, that can enforce constraints in a fully subword-aligned fashion, while leveraging pre-computation and speculative decoding to achieve virtually no overhead and in some cases even almost 2$\\times$ speedup over unconstrained decoding -- thereby outperforming existing approaches by a wide margin.",
    "link": "https://arxiv.org/abs/2403.06988",
    "context": "Title: Guiding LLMs The Right Way: Fast, Non-Invasive Constrained Generation\nAbstract: arXiv:2403.06988v1 Announce Type: cross  Abstract: To ensure that text generated by large language models (LLMs) is in an expected format, constrained decoding proposes to enforce strict formal language constraints during generation. However, as we show in this work, not only do such methods incur performance overhead during generation, but many of them also significantly impair task accuracy, if they do not correctly align the underlying LLM sub-word vocabularies with external constraints. To address this, we present a novel decoding algorithm, DOMINO, that can enforce constraints in a fully subword-aligned fashion, while leveraging pre-computation and speculative decoding to achieve virtually no overhead and in some cases even almost 2$\\times$ speedup over unconstrained decoding -- thereby outperforming existing approaches by a wide margin.",
    "path": "papers/24/03/2403.06988.json",
    "total_tokens": 813,
    "translated_title": "引导LLM走向正确之路：快速、非侵入式受限生成",
    "translated_abstract": "为了确保大型语言模型（LLMs）生成的文本符合预期格式，受限解码提出在生成过程中强制执行严格的形式语言约束。然而，正如我们在这项工作中所展示的，这类方法不仅在生成过程中产生性能开销，而且许多方法如果没有正确地将LLM子词词汇与外部约束对齐，则还会显著损害任务准确性。为了解决这个问题，我们提出了一种新颖的解码算法DOMINO，可以以完全基于子词对齐的方式强制执行约束，同时利用预计算和推测解码来实现几乎零开销，有时甚至比不受限制的解码快近2倍，从而远远超过现有方法的表现。",
    "tldr": "提出了一种新颖的解码算法DOMINO，在生成文本过程中以完全基于子词对齐的方式强制执行约束，几乎没有性能开销并有时甚至实现近2倍速度提升，远远优于现有方法。",
    "en_tdlr": "Introduced a novel decoding algorithm DOMINO that enforces constraints in a fully subword-aligned fashion during text generation, with virtually no performance overhead and in some cases even achieving nearly 2x speedup, outperforming existing methods by a wide margin."
}