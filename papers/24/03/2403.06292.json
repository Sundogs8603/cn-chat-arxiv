{
    "title": "Transformer based Multitask Learning for Image Captioning and Object Detection",
    "abstract": "arXiv:2403.06292v1 Announce Type: cross  Abstract: In several real-world scenarios like autonomous navigation and mobility, to obtain a better visual understanding of the surroundings, image captioning and object detection play a crucial role. This work introduces a novel multitask learning framework that combines image captioning and object detection into a joint model. We propose TICOD, Transformer-based Image Captioning and Object detection model for jointly training both tasks by combining the losses obtained from image captioning and object detection networks. By leveraging joint training, the model benefits from the complementary information shared between the two tasks, leading to improved performance for image captioning. Our approach utilizes a transformer-based architecture that enables end-to-end network integration for image captioning and object detection and performs both tasks jointly. We evaluate the effectiveness of our approach through comprehensive experiments on the",
    "link": "https://arxiv.org/abs/2403.06292",
    "context": "Title: Transformer based Multitask Learning for Image Captioning and Object Detection\nAbstract: arXiv:2403.06292v1 Announce Type: cross  Abstract: In several real-world scenarios like autonomous navigation and mobility, to obtain a better visual understanding of the surroundings, image captioning and object detection play a crucial role. This work introduces a novel multitask learning framework that combines image captioning and object detection into a joint model. We propose TICOD, Transformer-based Image Captioning and Object detection model for jointly training both tasks by combining the losses obtained from image captioning and object detection networks. By leveraging joint training, the model benefits from the complementary information shared between the two tasks, leading to improved performance for image captioning. Our approach utilizes a transformer-based architecture that enables end-to-end network integration for image captioning and object detection and performs both tasks jointly. We evaluate the effectiveness of our approach through comprehensive experiments on the",
    "path": "papers/24/03/2403.06292.json",
    "total_tokens": 822,
    "translated_title": "基于Transformer的多任务学习用于图像字幕生成和物体检测",
    "translated_abstract": "在像自主导航和移动性这样的几个实际场景中，为了更好地理解周围环境，图像字幕生成和物体检测发挥着关键作用。本研究引入了一种新颖的多任务学习框架，将图像字幕生成和物体检测结合成一个联合模型。我们提出了TICOD，一种基于Transformer的图像字幕生成和物体检测模型，通过结合图像字幕生成和物体检测网络获得的损失来同时训练两个任务。通过利用联合训练，该模型受益于两个任务之间共享的互补信息，从而提高了图像字幕生成的性能。我们的方法利用了基于Transformer的架构，实现了图像字幕生成和物体检测的端到端网络集成，并联合执行两个任务。我们通过全面实验评估了我们方法的有效性。",
    "tldr": "提出了一种结合图像字幕生成和物体检测的Transformer多任务学习框架，通过联合训练实现两个任务之间信息的互补共享，从而提高了图像字幕生成的性能。",
    "en_tdlr": "Introduced a Transformer-based multitask learning framework that combines image captioning and object detection, leveraging joint training to improve image captioning performance through complementary information sharing between tasks."
}