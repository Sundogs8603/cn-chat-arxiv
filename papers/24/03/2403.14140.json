{
    "title": "Learning Decomposable and Debiased Representations via Attribute-Centric Information Bottlenecks",
    "abstract": "arXiv:2403.14140v1 Announce Type: cross  Abstract: Biased attributes, spuriously correlated with target labels in a dataset, can problematically lead to neural networks that learn improper shortcuts for classifications and limit their capabilities for out-of-distribution (OOD) generalization. Although many debiasing approaches have been proposed to ensure correct predictions from biased datasets, few studies have considered learning latent embedding consisting of intrinsic and biased attributes that contribute to improved performance and explain how the model pays attention to attributes. In this paper, we propose a novel debiasing framework, Debiasing Global Workspace, introducing attention-based information bottlenecks for learning compositional representations of attributes without defining specific bias types. Based on our observation that learning shape-centric representation helps robust performance on OOD datasets, we adopt those abilities to learn robust and generalizable repre",
    "link": "https://arxiv.org/abs/2403.14140",
    "context": "Title: Learning Decomposable and Debiased Representations via Attribute-Centric Information Bottlenecks\nAbstract: arXiv:2403.14140v1 Announce Type: cross  Abstract: Biased attributes, spuriously correlated with target labels in a dataset, can problematically lead to neural networks that learn improper shortcuts for classifications and limit their capabilities for out-of-distribution (OOD) generalization. Although many debiasing approaches have been proposed to ensure correct predictions from biased datasets, few studies have considered learning latent embedding consisting of intrinsic and biased attributes that contribute to improved performance and explain how the model pays attention to attributes. In this paper, we propose a novel debiasing framework, Debiasing Global Workspace, introducing attention-based information bottlenecks for learning compositional representations of attributes without defining specific bias types. Based on our observation that learning shape-centric representation helps robust performance on OOD datasets, we adopt those abilities to learn robust and generalizable repre",
    "path": "papers/24/03/2403.14140.json",
    "total_tokens": 657,
    "translated_title": "通过属性中心信息瓶颈学习可分解且无偏见的表示形式",
    "translated_abstract": "有偏见的属性在数据集中与目标标签呈现虚假相关，可能导致神经网络学习不当的分类快捷方式，并且限制它们在超出分布的泛化方面的能力。本文提出了一个新颖的去偏见框架，引入基于注意力的信息瓶颈，用于学习属性的组合表示，而无需定义特定的偏见类型。",
    "tldr": "提出了一种新颖的去偏见框架，引入基于注意力的信息瓶颈，用于学习属性的组合表示，而无需定义特定的偏见类型",
    "en_tdlr": "Introducing a novel debiasing framework with attention-based information bottlenecks for learning compositional representations of attributes without defining specific bias types."
}