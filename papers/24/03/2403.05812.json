{
    "title": "Algorithmic progress in language models",
    "abstract": "arXiv:2403.05812v1 Announce Type: cross  Abstract: We investigate the rate at which algorithms for pre-training language models have improved since the advent of deep learning. Using a dataset of over 200 language model evaluations on Wikitext and Penn Treebank spanning 2012-2023, we find that the compute required to reach a set performance threshold has halved approximately every 8 months, with a 95% confidence interval of around 5 to 14 months, substantially faster than hardware gains per Moore's Law. We estimate augmented scaling laws, which enable us to quantify algorithmic progress and determine the relative contributions of scaling models versus innovations in training algorithms. Despite the rapid pace of algorithmic progress and the development of new architectures such as the transformer, our analysis reveals that the increase in compute made an even larger contribution to overall performance improvements over this time period. Though limited by noisy benchmark data, our analy",
    "link": "https://arxiv.org/abs/2403.05812",
    "context": "Title: Algorithmic progress in language models\nAbstract: arXiv:2403.05812v1 Announce Type: cross  Abstract: We investigate the rate at which algorithms for pre-training language models have improved since the advent of deep learning. Using a dataset of over 200 language model evaluations on Wikitext and Penn Treebank spanning 2012-2023, we find that the compute required to reach a set performance threshold has halved approximately every 8 months, with a 95% confidence interval of around 5 to 14 months, substantially faster than hardware gains per Moore's Law. We estimate augmented scaling laws, which enable us to quantify algorithmic progress and determine the relative contributions of scaling models versus innovations in training algorithms. Despite the rapid pace of algorithmic progress and the development of new architectures such as the transformer, our analysis reveals that the increase in compute made an even larger contribution to overall performance improvements over this time period. Though limited by noisy benchmark data, our analy",
    "path": "papers/24/03/2403.05812.json",
    "total_tokens": 895,
    "translated_title": "语言模型中算法进展的研究",
    "translated_abstract": "我们调查了自深度学习问世以来，用于预训练语言模型的算法改善速度。使用跨越2012年至2023年的Wikitext和Penn Treebank上的200多个语言模型评估数据集，我们发现达到一定性能阈值所需的计算时间大约每8个月减半，95%的置信区间约为5至14个月，远远快于摩尔定律的硬件增益。我们估计了增强扩展规律，这使我们能够量化算法进展，并确定模型扩展与训练算法创新的相对贡献。尽管算法进展速度快，且出现新的架构如Transformer，但我们的分析显示在这段时间内，计算能力的增加对整体性能改善的贡献更大。尽管受到嘈杂的基准数据的限制，我们的分析表明算法的进展对语言模型的性能的增长有显著影响。",
    "tldr": "研究发现，语言模型预训练算法每8个月几乎减半一次所需的计算需求，大大快于摩尔定律的硬件增益，尽管算法进展速度快，但计算能力的增加对整体性能改善的贡献更大。",
    "en_tdlr": "The study found that the compute required for pre-training language models halves approximately every 8 months, much faster than hardware gains per Moore's Law. Despite rapid algorithmic progress, the increase in compute made a larger contribution to overall performance improvements."
}