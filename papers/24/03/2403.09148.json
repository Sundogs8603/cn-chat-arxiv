{
    "title": "Evaluating LLMs for Gender Disparities in Notable Persons",
    "abstract": "arXiv:2403.09148v1 Announce Type: new  Abstract: This study examines the use of Large Language Models (LLMs) for retrieving factual information, addressing concerns over their propensity to produce factually incorrect \"hallucinated\" responses or to altogether decline to even answer prompt at all. Specifically, it investigates the presence of gender-based biases in LLMs' responses to factual inquiries. This paper takes a multi-pronged approach to evaluating GPT models by evaluating fairness across multiple dimensions of recall, hallucinations and declinations. Our findings reveal discernible gender disparities in the responses generated by GPT-3.5. While advancements in GPT-4 have led to improvements in performance, they have not fully eradicated these gender disparities, notably in instances where responses are declined. The study further explores the origins of these disparities by examining the influence of gender associations in prompts and the homogeneity in the responses.",
    "link": "https://arxiv.org/abs/2403.09148",
    "context": "Title: Evaluating LLMs for Gender Disparities in Notable Persons\nAbstract: arXiv:2403.09148v1 Announce Type: new  Abstract: This study examines the use of Large Language Models (LLMs) for retrieving factual information, addressing concerns over their propensity to produce factually incorrect \"hallucinated\" responses or to altogether decline to even answer prompt at all. Specifically, it investigates the presence of gender-based biases in LLMs' responses to factual inquiries. This paper takes a multi-pronged approach to evaluating GPT models by evaluating fairness across multiple dimensions of recall, hallucinations and declinations. Our findings reveal discernible gender disparities in the responses generated by GPT-3.5. While advancements in GPT-4 have led to improvements in performance, they have not fully eradicated these gender disparities, notably in instances where responses are declined. The study further explores the origins of these disparities by examining the influence of gender associations in prompts and the homogeneity in the responses.",
    "path": "papers/24/03/2403.09148.json",
    "total_tokens": 829,
    "translated_title": "评估用于显著人物的LLMs中的性别差距",
    "translated_abstract": "本研究探讨了大型语言模型（LLMs）用于检索事实信息的使用，解决了它们产生事实不准确的“幻觉”回复或完全拒绝甚至回答提示的倾向。具体来说，它调查了LLMs对事实查询的回应中存在的基于性别的偏见。这篇论文通过评估GPT模型在召回、幻觉和拒绝等多个维度上的公平性来采用多管齐下的方法。我们的研究发现GPT-3.5生成的回应中存在明显的性别差距。虽然GPT-4的进展提升了性能，但在回应被拒绝的情况下，这些性别差距并未完全消除。研究进一步探讨了这些差距的起源，通过检查提示中的性别关联和回应中的同质性。",
    "tldr": "评估大型语言模型在显著人物中存在的性别差距，并发现GPT-4在性能上有所改进，但问题尚未完全解决",
    "en_tdlr": "Evaluating gender disparities in Large Language Models (LLMs) for notable persons, finding improvements in performance with GPT-4 but the issues have not been fully resolved."
}