{
    "title": "TT-BLIP: Enhancing Fake News Detection Using BLIP and Tri-Transformer",
    "abstract": "arXiv:2403.12481v1 Announce Type: new  Abstract: Detecting fake news has received a lot of attention. Many previous methods concatenate independently encoded unimodal data, ignoring the benefits of integrated multimodal information. Also, the absence of specialized feature extraction for text and images further limits these methods. This paper introduces an end-to-end model called TT-BLIP that applies the bootstrapping language-image pretraining for unified vision-language understanding and generation (BLIP) for three types of information: BERT and BLIP\\textsubscript{Txt} for text, ResNet and BLIP\\textsubscript{Img} for images, and bidirectional BLIP encoders for multimodal information. The Multimodal Tri-Transformer fuses tri-modal features using three types of multi-head attention mechanisms, ensuring integrated modalities for enhanced representations and improved multimodal data analysis. The experiments are performed using two fake news datasets, Weibo and Gossipcop. The results in",
    "link": "https://arxiv.org/abs/2403.12481",
    "context": "Title: TT-BLIP: Enhancing Fake News Detection Using BLIP and Tri-Transformer\nAbstract: arXiv:2403.12481v1 Announce Type: new  Abstract: Detecting fake news has received a lot of attention. Many previous methods concatenate independently encoded unimodal data, ignoring the benefits of integrated multimodal information. Also, the absence of specialized feature extraction for text and images further limits these methods. This paper introduces an end-to-end model called TT-BLIP that applies the bootstrapping language-image pretraining for unified vision-language understanding and generation (BLIP) for three types of information: BERT and BLIP\\textsubscript{Txt} for text, ResNet and BLIP\\textsubscript{Img} for images, and bidirectional BLIP encoders for multimodal information. The Multimodal Tri-Transformer fuses tri-modal features using three types of multi-head attention mechanisms, ensuring integrated modalities for enhanced representations and improved multimodal data analysis. The experiments are performed using two fake news datasets, Weibo and Gossipcop. The results in",
    "path": "papers/24/03/2403.12481.json",
    "total_tokens": 905,
    "translated_title": "TT-BLIP：使用BLIP和Tri-Transformer增强假新闻检测",
    "translated_abstract": "arXiv:2403.12481v1 公告类型：新   摘要：检测假新闻受到了极大关注。许多先前的方法将独立编码的单模态数据进行串联，忽略了综合多模态信息的好处。此外，对于文本和图像缺乏专门的特征提取进一步限制了这些方法。本文介绍了一种名为TT-BLIP的端到端模型，该模型对三种类型的信息应用了引导式语言-图像预训练用于统一的视觉-语言理解和生成（BLIP）：BERT 和 BLIP\\textsubscript{Txt} 用于文本，ResNet 和 BLIP\\textsubscript{Img} 用于图像，以及用于多模态信息的双向 BLIP 编码器。多模态三角变换器使用三种类型的多头注意机制融合三模态特征，确保了增强表示和改进的多模态数据分析。实验使用了两个假新闻数据集，微博和Gossipcop。 结果表明，",
    "tldr": "TT-BLIP模型通过使用BLIP和Tri-Transformer技术，结合文本和图像的多模态信息提取，采用Multimodal Tri-Transformer融合特征，实现了增强的综合表征和改进的多模态数据分析。",
    "en_tdlr": "The TT-BLIP model enhances fake news detection by integrating multimodal information of text and images through BLIP and Tri-Transformer techniques, utilizing Multimodal Tri-Transformer to fuse features for improved representations and enhanced multimodal data analysis."
}