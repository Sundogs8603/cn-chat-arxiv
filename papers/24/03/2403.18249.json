{
    "title": "Exploring the Deceptive Power of LLM-Generated Fake News: A Study of Real-World Detection Challenges",
    "abstract": "arXiv:2403.18249v1 Announce Type: new  Abstract: Recent advancements in Large Language Models (LLMs) have enabled the creation of fake news, particularly in complex fields like healthcare. Studies highlight the gap in the deceptive power of LLM-generated fake news with and without human assistance, yet the potential of prompting techniques has not been fully explored. Thus, this work aims to determine whether prompting strategies can effectively narrow this gap. Current LLM-based fake news attacks require human intervention for information gathering and often miss details and fail to maintain context consistency. Therefore, to better understand threat tactics, we propose a strong fake news attack method called conditional Variational-autoencoder-Like Prompt (VLPrompt). Unlike current methods, VLPrompt eliminates the need for additional data collection while maintaining contextual coherence and preserving the intricacies of the original text. To propel future research on detecting VLPro",
    "link": "https://arxiv.org/abs/2403.18249",
    "context": "Title: Exploring the Deceptive Power of LLM-Generated Fake News: A Study of Real-World Detection Challenges\nAbstract: arXiv:2403.18249v1 Announce Type: new  Abstract: Recent advancements in Large Language Models (LLMs) have enabled the creation of fake news, particularly in complex fields like healthcare. Studies highlight the gap in the deceptive power of LLM-generated fake news with and without human assistance, yet the potential of prompting techniques has not been fully explored. Thus, this work aims to determine whether prompting strategies can effectively narrow this gap. Current LLM-based fake news attacks require human intervention for information gathering and often miss details and fail to maintain context consistency. Therefore, to better understand threat tactics, we propose a strong fake news attack method called conditional Variational-autoencoder-Like Prompt (VLPrompt). Unlike current methods, VLPrompt eliminates the need for additional data collection while maintaining contextual coherence and preserving the intricacies of the original text. To propel future research on detecting VLPro",
    "path": "papers/24/03/2403.18249.json",
    "total_tokens": 940,
    "translated_title": "探索LLM生成的虚假新闻的欺骗力：对现实世界检测挑战的研究",
    "translated_abstract": "最近，大型语言模型（LLMs）的进展使得在复杂领域如医疗保健领域尤为可能创造虚假新闻成为可能。研究突显了LLM生成的虚假新闻在有无人类辅助的情况下的欺骗力差距，但对于激励技术的潜力尚未完全探索。因此，本研究旨在确定激励策略是否能有效地缩小这一差距。当前基于LLM的虚假新闻攻击需要人类干预进行信息收集，通常会忽略细节并且无法保持上下文一致性。因此，为了更好地理解威胁策略，我们提出了一种称为条件变分自动编码器式提示（VLPrompt）的强假新闻攻击方法。与当前方法不同，VLPrompt消除了对额外数据收集的需求，同时保持了语境的连贯性并保留了原始文本的复杂性。",
    "tldr": "本研究提出了一种强假新闻攻击方法VLPrompt，通过消除对额外数据收集的需求，同时保持语境一致性和原始文本的复杂性，可以更好地缩小LLM生成虚假新闻的欺骗力差距。",
    "en_tdlr": "This study introduces a strong fake news attack method called VLPrompt, which effectively narrows the deceptive power gap in LLM-generated fake news by eliminating the need for additional data collection while maintaining contextual coherence and preserving the intricacies of the original text."
}