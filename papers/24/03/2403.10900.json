{
    "title": "BEnQA: A Question Answering and Reasoning Benchmark for Bengali and English",
    "abstract": "arXiv:2403.10900v1 Announce Type: new  Abstract: In this study, we introduce BEnQA, a dataset comprising parallel Bengali and English exam questions for middle and high school levels in Bangladesh. Our dataset consists of approximately 5K questions covering several subjects in science with different types of questions, including factual, application, and reasoning-based questions. We benchmark several Large Language Models (LLMs) with our parallel dataset and observe a notable performance disparity between the models in Bengali and English. We also investigate some prompting methods, and find that Chain-of-Thought prompting is beneficial mostly on reasoning questions, but not so much on factual ones. We also find that appending English translation helps to answer questions in Bengali. Our findings point to promising future research directions for improving the performance of LLMs in Bengali and more generally in low-resource languages.",
    "link": "https://arxiv.org/abs/2403.10900",
    "context": "Title: BEnQA: A Question Answering and Reasoning Benchmark for Bengali and English\nAbstract: arXiv:2403.10900v1 Announce Type: new  Abstract: In this study, we introduce BEnQA, a dataset comprising parallel Bengali and English exam questions for middle and high school levels in Bangladesh. Our dataset consists of approximately 5K questions covering several subjects in science with different types of questions, including factual, application, and reasoning-based questions. We benchmark several Large Language Models (LLMs) with our parallel dataset and observe a notable performance disparity between the models in Bengali and English. We also investigate some prompting methods, and find that Chain-of-Thought prompting is beneficial mostly on reasoning questions, but not so much on factual ones. We also find that appending English translation helps to answer questions in Bengali. Our findings point to promising future research directions for improving the performance of LLMs in Bengali and more generally in low-resource languages.",
    "path": "papers/24/03/2403.10900.json",
    "total_tokens": 918,
    "translated_title": "BEnQA: 孟加拉语和英语的问题回答和推理基准测试",
    "translated_abstract": "在这项研究中，我们介绍了BEnQA，这是一个包含孟加拉语和英语并行考试问题的数据集，主要涵盖孟加拉国中学和高中水平的题目。我们的数据集包含大约5,000道问题，涵盖了科学中的多个学科，包括事实性、应用性和基于推理的问题。我们使用我们的并行数据集对几个大型语言模型（LLMs）进行基准测试，并观察到模型在孟加拉语和英语中表现出明显的性能差异。我们还研究了一些提示方法，并发现对于基于推理的问题来说，“Chain-of-Thought”提示方法在某种程度上是有益的，但对于事实性问题则没有那么有帮助。我们还发现，在回答孟加拉语问题时，附加英语翻译有助于回答问题。我们的发现指出了未来改进LLMs在孟加拉语和更普遍地在资源匮乏语言中性能的有希望的研究方向。",
    "tldr": "BEnQA介绍了一项包含孟加拉语和英语考试问题的数据集，并发现大型语言模型在孟加拉语和英语问题中表现有明显差异，同时发现Chain-of-Thought提示对推理问题有益，附加英语翻译有助于解答孟加拉语问题。",
    "en_tdlr": "BEnQA introduces a dataset with Bengali and English exam questions, reveals significant performance differences of Large Language Models between Bengali and English questions, finds Chain-of-Thought prompting beneficial for reasoning questions, and shows adding English translation helps answering Bengali questions."
}