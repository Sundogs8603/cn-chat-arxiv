{
    "title": "Role of Locality and Weight Sharing in Image-Based Tasks: A Sample Complexity Separation between CNNs, LCNs, and FCNs",
    "abstract": "arXiv:2403.15707v1 Announce Type: cross  Abstract: Vision tasks are characterized by the properties of locality and translation invariance. The superior performance of convolutional neural networks (CNNs) on these tasks is widely attributed to the inductive bias of locality and weight sharing baked into their architecture. Existing attempts to quantify the statistical benefits of these biases in CNNs over locally connected convolutional neural networks (LCNs) and fully connected neural networks (FCNs) fall into one of the following categories: either they disregard the optimizer and only provide uniform convergence upper bounds with no separating lower bounds, or they consider simplistic tasks that do not truly mirror the locality and translation invariance as found in real-world vision tasks. To address these deficiencies, we introduce the Dynamic Signal Distribution (DSD) classification task that models an image as consisting of $k$ patches, each of dimension $d$, and the label is de",
    "link": "https://arxiv.org/abs/2403.15707",
    "context": "Title: Role of Locality and Weight Sharing in Image-Based Tasks: A Sample Complexity Separation between CNNs, LCNs, and FCNs\nAbstract: arXiv:2403.15707v1 Announce Type: cross  Abstract: Vision tasks are characterized by the properties of locality and translation invariance. The superior performance of convolutional neural networks (CNNs) on these tasks is widely attributed to the inductive bias of locality and weight sharing baked into their architecture. Existing attempts to quantify the statistical benefits of these biases in CNNs over locally connected convolutional neural networks (LCNs) and fully connected neural networks (FCNs) fall into one of the following categories: either they disregard the optimizer and only provide uniform convergence upper bounds with no separating lower bounds, or they consider simplistic tasks that do not truly mirror the locality and translation invariance as found in real-world vision tasks. To address these deficiencies, we introduce the Dynamic Signal Distribution (DSD) classification task that models an image as consisting of $k$ patches, each of dimension $d$, and the label is de",
    "path": "papers/24/03/2403.15707.json",
    "total_tokens": 888,
    "translated_title": "地域性和权重共享在基于图像的任务中的作用：CNN、LCN和FCN之间的样本复杂性分离",
    "translated_abstract": "视觉任务的特点是地域性和平移不变性。卷积神经网络（CNNs）在这些任务上表现出色，这在很大程度上归因于其架构中固有的地域性和权重共享的归纳偏差。现有的试图量化这些偏差在CNNs上相对于局部连接的卷积神经网络（LCNs）和全连接神经网络（FCNs）的统计优势的尝试可以归为以下几类：要么它们忽视优化器，仅提供具有统一收敛上界但没有分隔下界的统计收敛性，要么考虑到不真实地反映现实世界视觉任务中的地域性和平移不变性的简单任务。为了解决这些不足，我们介绍了动态信号分布（DSD）分类任务，它将图像建模为包含$k$个尺寸为$d$的补丁，标签是de",
    "tldr": "介绍了新的Dynamic Signal Distribution (DSD)分类任务，模拟图像由$k$个维度为$d$的补丁组成，以解决CNNs相对于LCNs和FCNs的统计优势问题",
    "en_tdlr": "Introduced a new Dynamic Signal Distribution (DSD) classification task that models an image as consisting of $k$ patches, each of dimension $d$, to address the statistical advantages of CNNs over LCNs and FCNs."
}