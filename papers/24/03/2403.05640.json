{
    "title": "Generating Hard-Negative Out-of-Scope Data with ChatGPT for Intent Classification",
    "abstract": "arXiv:2403.05640v1 Announce Type: new  Abstract: Intent classifiers must be able to distinguish when a user's utterance does not belong to any supported intent to avoid producing incorrect and unrelated system responses. Although out-of-scope (OOS) detection for intent classifiers has been studied, previous work has not yet studied changes in classifier performance against hard-negative out-of-scope utterances (i.e., inputs that share common features with in-scope data, but are actually out-of-scope). We present an automated technique to generate hard-negative OOS data using ChatGPT. We use our technique to build five new hard-negative OOS datasets, and evaluate each against three benchmark intent classifiers. We show that classifiers struggle to correctly identify hard-negative OOS utterances more than general OOS utterances. Finally, we show that incorporating hard-negative OOS data for training improves model robustness when detecting hard-negative OOS data and general OOS data. Our",
    "link": "https://arxiv.org/abs/2403.05640",
    "context": "Title: Generating Hard-Negative Out-of-Scope Data with ChatGPT for Intent Classification\nAbstract: arXiv:2403.05640v1 Announce Type: new  Abstract: Intent classifiers must be able to distinguish when a user's utterance does not belong to any supported intent to avoid producing incorrect and unrelated system responses. Although out-of-scope (OOS) detection for intent classifiers has been studied, previous work has not yet studied changes in classifier performance against hard-negative out-of-scope utterances (i.e., inputs that share common features with in-scope data, but are actually out-of-scope). We present an automated technique to generate hard-negative OOS data using ChatGPT. We use our technique to build five new hard-negative OOS datasets, and evaluate each against three benchmark intent classifiers. We show that classifiers struggle to correctly identify hard-negative OOS utterances more than general OOS utterances. Finally, we show that incorporating hard-negative OOS data for training improves model robustness when detecting hard-negative OOS data and general OOS data. Our",
    "path": "papers/24/03/2403.05640.json",
    "total_tokens": 924,
    "translated_title": "使用ChatGPT生成难负样本数据以供意图分类使用",
    "translated_abstract": "意图分类器必须能够区分用户的话语是否属于任何支持的意图，以避免产生不正确和无关的系统响应。 尽管已经研究了意图分类器的超范围（OOS）检测，但先前的工作尚未研究分类器性能对抗难负样本超范围话语（即，具有与范围内数据共同特征，但实际上超范围）的变化。 我们提出了一种使用ChatGPT生成难负样本OOS数据的自动化技术。 我们使用我们的技术构建了五个新的难负样本OOS数据集，并针对三个基准意图分类器对每个数据集进行评估。 我们展示了分类器在正确识别难负样本OOS话语方面的困难程度超过了一般的OOS话语。 最后，我们展示了在训练中结合难负样本OOS数据可以提高模型对难负样本OOS数据和一般OOS数据的鲁棒性。",
    "tldr": "使用ChatGPT生成难负样本OOS数据，提出了新的难负样本OOS数据集，表明分类器在识别难负样本OOS数据方面存在困难，同时显示在训练中加入难负样本OOS数据可以提高模型的鲁棒性",
    "en_tdlr": "Generating hard-negative OOS data with ChatGPT, creating new hard-negative OOS datasets, demonstrating classifier's difficulty in recognizing hard-negative OOS data, and showing improvement in model robustness by incorporating hard-negative OOS data in training."
}