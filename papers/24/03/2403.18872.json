{
    "title": "Targeted Visualization of the Backbone of Encoder LLMs",
    "abstract": "arXiv:2403.18872v1 Announce Type: cross  Abstract: Attention based Large Language Models (LLMs) are the state-of-the-art in natural language processing (NLP). The two most common architectures are encoders such as BERT, and decoders like the GPT models. Despite the success of encoder models, on which we focus in this work, they also bear several risks, including issues with bias or their susceptibility for adversarial attacks, signifying the necessity for explainable AI to detect such issues. While there does exist various local explainability methods focusing on the prediction of single inputs, global methods based on dimensionality reduction for classification inspection, which have emerged in other domains and that go further than just using t-SNE in the embedding space, are not widely spread in NLP.   To reduce this gap, we investigate the application of DeepView, a method for visualizing a part of the decision function together with a data set in two dimensions, to the NLP domain.",
    "link": "https://arxiv.org/abs/2403.18872",
    "context": "Title: Targeted Visualization of the Backbone of Encoder LLMs\nAbstract: arXiv:2403.18872v1 Announce Type: cross  Abstract: Attention based Large Language Models (LLMs) are the state-of-the-art in natural language processing (NLP). The two most common architectures are encoders such as BERT, and decoders like the GPT models. Despite the success of encoder models, on which we focus in this work, they also bear several risks, including issues with bias or their susceptibility for adversarial attacks, signifying the necessity for explainable AI to detect such issues. While there does exist various local explainability methods focusing on the prediction of single inputs, global methods based on dimensionality reduction for classification inspection, which have emerged in other domains and that go further than just using t-SNE in the embedding space, are not widely spread in NLP.   To reduce this gap, we investigate the application of DeepView, a method for visualizing a part of the decision function together with a data set in two dimensions, to the NLP domain.",
    "path": "papers/24/03/2403.18872.json",
    "total_tokens": 827,
    "translated_title": "编码器LLMs骨干的定向可视化",
    "translated_abstract": "基于注意力机制的大型语言模型(LLMs)是自然语言处理(NLP)中的最新技术。其中最常见的两种架构是编码器，如BERT，和解码器，如GPT模型。尽管编码器模型取得了成功，但它们也存在一些风险，包括偏见问题或易受对抗性攻击的影响，这表明了需要可解释的AI来检测这些问题。虽然目前存在各种关注预测单个输入的局部可解释性方法，但基于降维的用于分类检查的全局方法，并且在其他领域出现并超越仅在嵌入空间中使用t-SNE的方法，在NLP中并不十分广泛传播。为了缩小这一差距，我们研究了DeepView方法在NLP领域的应用，该方法用于在二维中可视化决策函数的一部分以及数据集。",
    "tldr": "本文研究了将DeepView方法应用于自然语言处理领域，以减少编码器模型存在的风险并解释模型决策过程。",
    "en_tdlr": "This paper investigates the application of DeepView method in the NLP domain to mitigate risks associated with encoder models and explain the model decision process."
}