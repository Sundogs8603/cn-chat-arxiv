{
    "title": "Reproducibility and Geometric Intrinsic Dimensionality: An Investigation on Graph Neural Network Research",
    "abstract": "arXiv:2403.08438v1 Announce Type: cross  Abstract: Difficulties in replication and reproducibility of empirical evidences in machine learning research have become a prominent topic in recent years. Ensuring that machine learning research results are sound and reliable requires reproducibility, which verifies the reliability of research findings using the same code and data. This promotes open and accessible research, robust experimental workflows, and the rapid integration of new findings. Evaluating the degree to which research publications support these different aspects of reproducibility is one goal of the present work. For this we introduce an ontology of reproducibility in machine learning and apply it to methods for graph neural networks. Building on these efforts we turn towards another critical challenge in machine learning, namely the curse of dimensionality, which poses challenges in data collection, representation, and analysis, making it harder to find representative data ",
    "link": "https://arxiv.org/abs/2403.08438",
    "context": "Title: Reproducibility and Geometric Intrinsic Dimensionality: An Investigation on Graph Neural Network Research\nAbstract: arXiv:2403.08438v1 Announce Type: cross  Abstract: Difficulties in replication and reproducibility of empirical evidences in machine learning research have become a prominent topic in recent years. Ensuring that machine learning research results are sound and reliable requires reproducibility, which verifies the reliability of research findings using the same code and data. This promotes open and accessible research, robust experimental workflows, and the rapid integration of new findings. Evaluating the degree to which research publications support these different aspects of reproducibility is one goal of the present work. For this we introduce an ontology of reproducibility in machine learning and apply it to methods for graph neural networks. Building on these efforts we turn towards another critical challenge in machine learning, namely the curse of dimensionality, which poses challenges in data collection, representation, and analysis, making it harder to find representative data ",
    "path": "papers/24/03/2403.08438.json",
    "total_tokens": 858,
    "translated_title": "再现性和几何内在维度性：对图神经网络研究的调查",
    "translated_abstract": "机器学习研究中复制和可再现性的困难近年来成为一个突出的话题。确保机器学习研究结果的可靠性需要可再现性，通过使用相同的代码和数据验证研究结果的可靠性。这促进了开放和可访问的研究、稳健的实验工作流程以及新发现的快速整合。评估研究出版物支持再现性的程度是本文的一个目标。为此，我们引入了一个机器学习中的再现性本体论，并将其应用于图神经网络的方法。在这些努力的基础上，我们转向机器学习中的另一个关键挑战，即维度诅咒，它在数据收集、表示和分析方面带来挑战，使得更难找到代表性数据。",
    "tldr": "本文研究了图神经网络研究中的再现性和几何内在维度性问题，并引入机器学习中的再现性本体论，以及探讨了维度诅咒对数据收集、表示和分析的挑战。",
    "en_tdlr": "This paper investigates reproducibility and geometric intrinsic dimensionality in graph neural network research, introduces an ontology of reproducibility in machine learning, and discusses the challenges posed by the curse of dimensionality on data collection, representation, and analysis in machine learning."
}