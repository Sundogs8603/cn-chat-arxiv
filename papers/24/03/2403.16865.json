{
    "title": "Encoding of lexical tone in self-supervised models of spoken language",
    "abstract": "arXiv:2403.16865v1 Announce Type: new  Abstract: Interpretability research has shown that self-supervised Spoken Language Models (SLMs) encode a wide variety of features in human speech from the acoustic, phonetic, phonological, syntactic and semantic levels, to speaker characteristics. The bulk of prior research on representations of phonology has focused on segmental features such as phonemes; the encoding of suprasegmental phonology (such as tone and stress patterns) in SLMs is not yet well understood. Tone is a suprasegmental feature that is present in more than half of the world's languages. This paper aims to analyze the tone encoding capabilities of SLMs, using Mandarin and Vietnamese as case studies. We show that SLMs encode lexical tone to a significant degree even when they are trained on data from non-tonal languages. We further find that SLMs behave similarly to native and non-native human participants in tone and consonant perception studies, but they do not follow the sam",
    "link": "https://arxiv.org/abs/2403.16865",
    "context": "Title: Encoding of lexical tone in self-supervised models of spoken language\nAbstract: arXiv:2403.16865v1 Announce Type: new  Abstract: Interpretability research has shown that self-supervised Spoken Language Models (SLMs) encode a wide variety of features in human speech from the acoustic, phonetic, phonological, syntactic and semantic levels, to speaker characteristics. The bulk of prior research on representations of phonology has focused on segmental features such as phonemes; the encoding of suprasegmental phonology (such as tone and stress patterns) in SLMs is not yet well understood. Tone is a suprasegmental feature that is present in more than half of the world's languages. This paper aims to analyze the tone encoding capabilities of SLMs, using Mandarin and Vietnamese as case studies. We show that SLMs encode lexical tone to a significant degree even when they are trained on data from non-tonal languages. We further find that SLMs behave similarly to native and non-native human participants in tone and consonant perception studies, but they do not follow the sam",
    "path": "papers/24/03/2403.16865.json",
    "total_tokens": 910,
    "translated_title": "口语语言自监督模型中的词汇音调编码",
    "translated_abstract": "解释性研究表明，自监督口语语言模型（SLMs）从声学、语音、音韵、句法和语义层面到说话者特征中编码了人类语音中的各种特征。以前关于音韵学表示的大部分研究都集中在诸如音素等部分特征上；SLMs中对音韵音系（如声调和重音模式）的编码尚未被充分理解。声调是一种存在于世界上半数以上语言中的音系特征。本文旨在分析SLMs的声调编码能力，以普通话和越南语作为案例研究。我们展示了SLMs在训练于非音调语言数据时也明显编码了词汇音调。我们进一步发现，SLMs在声调和辅音感知研究中的表现与本族和非本族的人类参与者类似，但它们不遵循相同的模式。",
    "tldr": "本文研究分析了口语语言自监督模型对声调的编码能力，使用普通话和越南语作为案例研究，并发现SLMs在训练于非音调语言数据时也保持着显著的词汇音调编码能力。",
    "en_tdlr": "This paper analyzes the tone encoding capabilities of self-supervised Spoken Language Models (SLMs), using Mandarin and Vietnamese as case studies, and finds that SLMs encode lexical tone significantly even when trained on data from non-tonal languages."
}