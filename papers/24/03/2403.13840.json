{
    "title": "Whose Side Are You On? Investigating the Political Stance of Large Language Models",
    "abstract": "arXiv:2403.13840v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have gained significant popularity for their application in various everyday tasks such as text generation, summarization, and information retrieval. As the widespread adoption of LLMs continues to surge, it becomes increasingly crucial to ensure that these models yield responses that are politically impartial, with the aim of preventing information bubbles, upholding fairness in representation, and mitigating confirmation bias. In this paper, we propose a quantitative framework and pipeline designed to systematically investigate the political orientation of LLMs. Our investigation delves into the political alignment of LLMs across a spectrum of eight polarizing topics, spanning from abortion to LGBTQ issues. Across topics, the results indicate that LLMs exhibit a tendency to provide responses that closely align with liberal or left-leaning perspectives rather than conservative or right-leaning ones when us",
    "link": "https://arxiv.org/abs/2403.13840",
    "context": "Title: Whose Side Are You On? Investigating the Political Stance of Large Language Models\nAbstract: arXiv:2403.13840v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have gained significant popularity for their application in various everyday tasks such as text generation, summarization, and information retrieval. As the widespread adoption of LLMs continues to surge, it becomes increasingly crucial to ensure that these models yield responses that are politically impartial, with the aim of preventing information bubbles, upholding fairness in representation, and mitigating confirmation bias. In this paper, we propose a quantitative framework and pipeline designed to systematically investigate the political orientation of LLMs. Our investigation delves into the political alignment of LLMs across a spectrum of eight polarizing topics, spanning from abortion to LGBTQ issues. Across topics, the results indicate that LLMs exhibit a tendency to provide responses that closely align with liberal or left-leaning perspectives rather than conservative or right-leaning ones when us",
    "path": "papers/24/03/2403.13840.json",
    "total_tokens": 817,
    "translated_title": "你站在哪一边？调查大型语言模型的政治立场",
    "translated_abstract": "大型语言模型（LLMs）因其在文本生成、摘要和信息检索等日常任务中的应用而备受欢迎。随着LLMs的广泛应用不断增长，确保这些模型产生政治中立的回应变得越来越重要，旨在避免信息泡沫，维护代表公平，并减轻确认偏见。本文提出了一个定量框架和流程，旨在系统地调查LLMs的政治取向。我们的调查深入探讨LLMs在八个极化话题的政治取向，从堕胎到LGBTQ问题跨越。结果表明，在各个话题上，LLMs倾向于提供与自由主义或左倾观点更为接近的回应，而不是与保守主义或右倾观点更为接近的回应。",
    "tldr": "本研究提出了一个定量框架和流程，系统调查大型语言模型的政治取向，结果显示这些模型倾向于提供与自由主义或左倾观点更为接近的回应。",
    "en_tdlr": "This study introduces a quantitative framework and pipeline to systematically investigate the political orientation of Large Language Models (LLMs), revealing a tendency for these models to provide responses that align more closely with liberal or left-leaning perspectives."
}