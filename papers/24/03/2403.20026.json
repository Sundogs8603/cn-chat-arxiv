{
    "title": "FSMR: A Feature Swapping Multi-modal Reasoning Approach with Joint Textual and Visual Clues",
    "abstract": "arXiv:2403.20026v1 Announce Type: cross  Abstract: Multi-modal reasoning plays a vital role in bridging the gap between textual and visual information, enabling a deeper understanding of the context. This paper presents the Feature Swapping Multi-modal Reasoning (FSMR) model, designed to enhance multi-modal reasoning through feature swapping. FSMR leverages a pre-trained visual-language model as an encoder, accommodating both text and image inputs for effective feature representation from both modalities. It introduces a unique feature swapping module, enabling the exchange of features between identified objects in images and corresponding vocabulary words in text, thereby enhancing the model's comprehension of the interplay between images and text. To further bolster its multi-modal alignment capabilities, FSMR incorporates a multi-modal cross-attention mechanism, facilitating the joint modeling of textual and visual information. During training, we employ image-text matching and cros",
    "link": "https://arxiv.org/abs/2403.20026",
    "context": "Title: FSMR: A Feature Swapping Multi-modal Reasoning Approach with Joint Textual and Visual Clues\nAbstract: arXiv:2403.20026v1 Announce Type: cross  Abstract: Multi-modal reasoning plays a vital role in bridging the gap between textual and visual information, enabling a deeper understanding of the context. This paper presents the Feature Swapping Multi-modal Reasoning (FSMR) model, designed to enhance multi-modal reasoning through feature swapping. FSMR leverages a pre-trained visual-language model as an encoder, accommodating both text and image inputs for effective feature representation from both modalities. It introduces a unique feature swapping module, enabling the exchange of features between identified objects in images and corresponding vocabulary words in text, thereby enhancing the model's comprehension of the interplay between images and text. To further bolster its multi-modal alignment capabilities, FSMR incorporates a multi-modal cross-attention mechanism, facilitating the joint modeling of textual and visual information. During training, we employ image-text matching and cros",
    "path": "papers/24/03/2403.20026.json",
    "total_tokens": 899,
    "translated_title": "FSMR：具有联合文本和视觉线索的特征交换多模态推理方法",
    "translated_abstract": "多模态推理在弥合文本和视觉信息之间的差距，实现对上下文的更深入理解方面起着至关重要的作用。本文提出了特征交换多模态推理（FSMR）模型，旨在通过特征交换增强多模态推理。FSMR利用预训练的视觉语言模型作为编码器，接纳文本和图像输入，有效地表征两种模态的特征。它引入了一个独特的特征交换模块，实现了图像中识别的对象和文本中对应词汇之间特征的交换，从而增强模型对图像和文本之间相互作用的理解。为了进一步加强其多模态对齐能力，FSMR融合了多模态交叉注意机制，促进了文本和视觉信息的联合建模。",
    "tldr": "这项研究提出了一种新的特征交换多模态推理（FSMR）模型，通过特征交换增强多模态推理，包括利用预训练的视觉-语言模型和独特的特征交换模块，以及融合多模态交叉注意机制来促进文本和图像信息的联合建模。",
    "en_tdlr": "This paper introduces a new Feature Swapping Multi-modal Reasoning (FSMR) model, which enhances multi-modal reasoning through feature swapping, including leveraging a pre-trained visual-language model, a unique feature swapping module, and incorporating a multi-modal cross-attention mechanism for joint modeling of textual and visual information."
}