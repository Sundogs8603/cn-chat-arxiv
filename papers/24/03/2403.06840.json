{
    "title": "RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback",
    "abstract": "arXiv:2403.06840v1 Announce Type: cross  Abstract: Large language models (LLMs) demonstrate exceptional performance in numerous tasks but still heavily rely on knowledge stored in their parameters. Moreover, updating this knowledge incurs high training costs. Retrieval-augmented generation (RAG) methods address this issue by integrating external knowledge. The model can answer questions it couldn't previously by retrieving knowledge relevant to the query. This approach improves performance in certain scenarios for specific tasks. However, if irrelevant texts are retrieved, it may impair model performance. In this paper, we propose Retrieval Augmented Iterative Self-Feedback (RA-ISF), a framework that iteratively decomposes tasks and processes them in three submodules to enhance the model's problem-solving capabilities. Experiments show that our method outperforms existing benchmarks, performing well on models like GPT3.5, Llama2, significantly enhancing factual reasoning capabilities a",
    "link": "https://arxiv.org/abs/2403.06840",
    "context": "Title: RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback\nAbstract: arXiv:2403.06840v1 Announce Type: cross  Abstract: Large language models (LLMs) demonstrate exceptional performance in numerous tasks but still heavily rely on knowledge stored in their parameters. Moreover, updating this knowledge incurs high training costs. Retrieval-augmented generation (RAG) methods address this issue by integrating external knowledge. The model can answer questions it couldn't previously by retrieving knowledge relevant to the query. This approach improves performance in certain scenarios for specific tasks. However, if irrelevant texts are retrieved, it may impair model performance. In this paper, we propose Retrieval Augmented Iterative Self-Feedback (RA-ISF), a framework that iteratively decomposes tasks and processes them in three submodules to enhance the model's problem-solving capabilities. Experiments show that our method outperforms existing benchmarks, performing well on models like GPT3.5, Llama2, significantly enhancing factual reasoning capabilities a",
    "path": "papers/24/03/2403.06840.json",
    "total_tokens": 782,
    "translated_title": "RA-ISF: 通过迭代自反馈学习检索增强以回答和理解",
    "translated_abstract": "大型语言模型(LLMs)在许多任务中表现出色，但仍然严重依赖存储在其参数中的知识。检索增强生成(RAG)方法通过整合外部知识来解决这一问题。模型可以通过检索与查询相关的知识来回答以前无法回答的问题。本文提出了检索增强迭代自反馈(RA-ISF)框架，通过三个子模块迭代分解任务并处理它们，以增强模型的问题解决能力。实验证明，我们的方法优于现有基准，在诸如GPT3.5、Llama2之类的模型上表现良好，显著增强了事实推理能力。",
    "tldr": "通过迭代自反馈的检索增强方法在指定任务的特定场景中提高模型性能，优于现有基准模型，显著增强了事实推理能力。"
}