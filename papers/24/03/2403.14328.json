{
    "title": "Distilling Reinforcement Learning Policies for Interpretable Robot Locomotion: Gradient Boosting Machines and Symbolic Regression",
    "abstract": "arXiv:2403.14328v1 Announce Type: cross  Abstract: Recent advancements in reinforcement learning (RL) have led to remarkable achievements in robot locomotion capabilities. However, the complexity and ``black-box'' nature of neural network-based RL policies hinder their interpretability and broader acceptance, particularly in applications demanding high levels of safety and reliability. This paper introduces a novel approach to distill neural RL policies into more interpretable forms using Gradient Boosting Machines (GBMs), Explainable Boosting Machines (EBMs) and Symbolic Regression. By leveraging the inherent interpretability of generalized additive models, decision trees, and analytical expressions, we transform opaque neural network policies into more transparent ``glass-box'' models. We train expert neural network policies using RL and subsequently distill them into (i) GBMs, (ii) EBMs, and (iii) symbolic policies. To address the inherent distribution shift challenge of behavioral ",
    "link": "https://arxiv.org/abs/2403.14328",
    "context": "Title: Distilling Reinforcement Learning Policies for Interpretable Robot Locomotion: Gradient Boosting Machines and Symbolic Regression\nAbstract: arXiv:2403.14328v1 Announce Type: cross  Abstract: Recent advancements in reinforcement learning (RL) have led to remarkable achievements in robot locomotion capabilities. However, the complexity and ``black-box'' nature of neural network-based RL policies hinder their interpretability and broader acceptance, particularly in applications demanding high levels of safety and reliability. This paper introduces a novel approach to distill neural RL policies into more interpretable forms using Gradient Boosting Machines (GBMs), Explainable Boosting Machines (EBMs) and Symbolic Regression. By leveraging the inherent interpretability of generalized additive models, decision trees, and analytical expressions, we transform opaque neural network policies into more transparent ``glass-box'' models. We train expert neural network policies using RL and subsequently distill them into (i) GBMs, (ii) EBMs, and (iii) symbolic policies. To address the inherent distribution shift challenge of behavioral ",
    "path": "papers/24/03/2403.14328.json",
    "total_tokens": 898,
    "translated_title": "将强化学习策略提炼为可解释的机器人运动：梯度提升机和符号回归",
    "translated_abstract": "最近强化学习（RL）的发展使机器人运动能力取得了显著进展。然而，基于神经网络的RL策略的复杂性和“黑匣子”特性阻碍了它们的可解释性和更广泛的接受度，特别是在要求高水平安全性和可靠性的应用中。本文引入了一种将神经RL策略提炼为更可解释形式的新方法，使用梯度提升机（GBMs）、可解释提升机（EBMs）和符号回归。通过利用广义加法模型、决策树和分析表达式的固有可解释性，我们将不透明的神经网络策略转化为更透明的“玻璃箱”模型。我们使用RL训练专家神经网络策略，然后将它们提炼为(i) GBMs、(ii) EBMs和(iii)符号策略。为了解决行为分布转移挑战",
    "tldr": "通过梯度提升机和符号回归等技术，将神经网络的强化学习策略转化为更可解释的形式，提高了机器人运动策略的透明度和可理解性。",
    "en_tdlr": "By leveraging techniques such as Gradient Boosting Machines and Symbolic Regression, this paper transforms neural network reinforcement learning policies into more interpretable forms, enhancing the transparency and interpretability of robot locomotion strategies."
}