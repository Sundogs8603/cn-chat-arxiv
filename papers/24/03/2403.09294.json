{
    "title": "Anatomical Structure-Guided Medical Vision-Language Pre-training",
    "abstract": "arXiv:2403.09294v1 Announce Type: cross  Abstract: Learning medical visual representations through vision-language pre-training has reached remarkable progress. Despite the promising performance, it still faces challenges, i.e., local alignment lacks interpretability and clinical relevance, and the insufficient internal and external representation learning of image-report pairs. To address these issues, we propose an Anatomical Structure-Guided (ASG) framework. Specifically, we parse raw reports into triplets , and fully utilize each element as supervision to enhance representation learning. For anatomical region, we design an automatic anatomical region-sentence alignment paradigm in collaboration with radiologists, considering them as the minimum semantic units to explore fine-grained local alignment. For finding and existence, we regard them as image tags, applying an image-tag recognition decoder to associate image features with their respective tags within each sample and construc",
    "link": "https://arxiv.org/abs/2403.09294",
    "context": "Title: Anatomical Structure-Guided Medical Vision-Language Pre-training\nAbstract: arXiv:2403.09294v1 Announce Type: cross  Abstract: Learning medical visual representations through vision-language pre-training has reached remarkable progress. Despite the promising performance, it still faces challenges, i.e., local alignment lacks interpretability and clinical relevance, and the insufficient internal and external representation learning of image-report pairs. To address these issues, we propose an Anatomical Structure-Guided (ASG) framework. Specifically, we parse raw reports into triplets , and fully utilize each element as supervision to enhance representation learning. For anatomical region, we design an automatic anatomical region-sentence alignment paradigm in collaboration with radiologists, considering them as the minimum semantic units to explore fine-grained local alignment. For finding and existence, we regard them as image tags, applying an image-tag recognition decoder to associate image features with their respective tags within each sample and construc",
    "path": "papers/24/03/2403.09294.json",
    "total_tokens": 894,
    "translated_title": "解剖结构引导的医学视觉-语言预训练",
    "translated_abstract": "通过视觉-语言预训练学习医学视觉表示已取得显著进展。尽管表现出有希望的性能，但仍面临挑战，即局部对齐缺乏可解释性和临床相关性，以及图像-报告对的内部和外部表示学习不足。为了解决这些问题，我们提出了一种解剖结构引导的（ASG）框架。具体来说，我们将原始报告解析为三元组，并充分利用每个元素作为监督来增强表示学习。对于解剖区域，我们设计了一种与放射科医师合作的自动解剖区域-句子对齐范例，将其视为最小语义单元来探索细粒度局部对齐。对于查找和存在性，我们将其视为图像标签，应用图像标签识别解码器，在每个样本内将图像特征与其相应标签关联起来，构建。",
    "tldr": "该研究提出了一种解剖结构引导的医学视觉-语言预训练框架，通过将原始报告解析为三元组并利用每个元素作为监督来增强表示学习，解决了局部对齐和图像-报告对表示学习中的挑战。",
    "en_tdlr": "This study proposes an Anatomical Structure-Guided medical vision-language pre-training framework to enhance representation learning by parsing raw reports into triplets and addressing challenges in local alignment and image-report pair representation learning."
}