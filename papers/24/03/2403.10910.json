{
    "title": "Graph Regularized NMF with L20-norm for Unsupervised Feature Learning",
    "abstract": "arXiv:2403.10910v1 Announce Type: new  Abstract: Nonnegative Matrix Factorization (NMF) is a widely applied technique in the fields of machine learning and data mining. Graph Regularized Non-negative Matrix Factorization (GNMF) is an extension of NMF that incorporates graph regularization constraints. GNMF has demonstrated exceptional performance in clustering and dimensionality reduction, effectively discovering inherent low-dimensional structures embedded within high-dimensional spaces. However, the sensitivity of GNMF to noise limits its stability and robustness in practical applications. In order to enhance feature sparsity and mitigate the impact of noise while mining row sparsity patterns in the data for effective feature selection, we introduce the $\\ell_{2,0}$-norm constraint as the sparsity constraints for GNMF. We propose an unsupervised feature learning framework based on GNMF\\_$\\ell_{20}$ and devise an algorithm based on PALM and its accelerated version to address this prob",
    "link": "https://arxiv.org/abs/2403.10910",
    "context": "Title: Graph Regularized NMF with L20-norm for Unsupervised Feature Learning\nAbstract: arXiv:2403.10910v1 Announce Type: new  Abstract: Nonnegative Matrix Factorization (NMF) is a widely applied technique in the fields of machine learning and data mining. Graph Regularized Non-negative Matrix Factorization (GNMF) is an extension of NMF that incorporates graph regularization constraints. GNMF has demonstrated exceptional performance in clustering and dimensionality reduction, effectively discovering inherent low-dimensional structures embedded within high-dimensional spaces. However, the sensitivity of GNMF to noise limits its stability and robustness in practical applications. In order to enhance feature sparsity and mitigate the impact of noise while mining row sparsity patterns in the data for effective feature selection, we introduce the $\\ell_{2,0}$-norm constraint as the sparsity constraints for GNMF. We propose an unsupervised feature learning framework based on GNMF\\_$\\ell_{20}$ and devise an algorithm based on PALM and its accelerated version to address this prob",
    "path": "papers/24/03/2403.10910.json",
    "total_tokens": 863,
    "translated_title": "具有L20范数的图正则化NMF用于无监督特征学习",
    "translated_abstract": "非负矩阵分解（NMF）是机器学习和数据挖掘领域广泛应用的技术。图正则化非负矩阵分解（GNMF）是NMF的一种扩展，它包含了图正则化约束。GNMF在聚类和降维方面表现出色，有效地发现了嵌入高维空间中的内在低维结构。然而，GNMF对噪声的敏感性限制了它在实际应用中的稳定性和鲁棒性。为了增强特征的稀疏性并减轻噪声对其影响，同时在数据中挖掘行稀疏模式以进行有效的特征选择，我们将L20范数约束引入作为GNMF的稀疏约束。我们提出了一种基于GNMF\\_$\\ell_{20}$的无监督特征学习框架，并设计了基于PALM及其加速版本的算法来解决这个问题。",
    "tldr": "引入L20范数约束的图正则化NMF用于无监督特征学习，旨在增强特征稀疏性和减轻噪声影响。",
    "en_tdlr": "Introducing the L20-norm constraint into the graph regularized NMF for unsupervised feature learning aims to enhance feature sparsity and mitigate the impact of noise."
}