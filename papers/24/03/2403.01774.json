{
    "title": "WebCiteS: Attributed Query-Focused Summarization on Chinese Web Search Results with Citations",
    "abstract": "arXiv:2403.01774v1 Announce Type: new  Abstract: Enhancing the attribution in large language models (LLMs) is a crucial task. One feasible approach is to enable LLMs to cite external sources that support their generations. However, existing datasets and evaluation methods in this domain still exhibit notable limitations. In this work, we formulate the task of attributed query-focused summarization (AQFS) and present WebCiteS, a Chinese dataset featuring 7k human-annotated summaries with citations. WebCiteS derives from real-world user queries and web search results, offering a valuable resource for model training and evaluation. Prior works in attribution evaluation do not differentiate between groundedness errors and citation errors. They also fall short in automatically verifying sentences that draw partial support from multiple sources. We tackle these issues by developing detailed metrics and enabling the automatic evaluator to decompose the sentences into sub-claims for fine-grain",
    "link": "https://arxiv.org/abs/2403.01774",
    "context": "Title: WebCiteS: Attributed Query-Focused Summarization on Chinese Web Search Results with Citations\nAbstract: arXiv:2403.01774v1 Announce Type: new  Abstract: Enhancing the attribution in large language models (LLMs) is a crucial task. One feasible approach is to enable LLMs to cite external sources that support their generations. However, existing datasets and evaluation methods in this domain still exhibit notable limitations. In this work, we formulate the task of attributed query-focused summarization (AQFS) and present WebCiteS, a Chinese dataset featuring 7k human-annotated summaries with citations. WebCiteS derives from real-world user queries and web search results, offering a valuable resource for model training and evaluation. Prior works in attribution evaluation do not differentiate between groundedness errors and citation errors. They also fall short in automatically verifying sentences that draw partial support from multiple sources. We tackle these issues by developing detailed metrics and enabling the automatic evaluator to decompose the sentences into sub-claims for fine-grain",
    "path": "papers/24/03/2403.01774.json",
    "total_tokens": 848,
    "translated_title": "WebCiteS: 在中国网页搜索结果上进行带引文的查询焦点摘要",
    "translated_abstract": "arXiv:2403.01774v1 声明类型：新摘要：增强大型语言模型（LLMs）中的归因是一项关键任务。一个可行的方法是使LLMs能够引用支持其生成的外部来源。然而，该领域现有数据集和评估方法仍存在明显限制。在这项工作中，我们制定了带引文的查询焦点摘要（AQFS）任务，并提出了WebCiteS，这是一个包含7k人工注释摘要及引文的中文数据集。WebCiteS源自现实用户查询和网页搜索结果，为模型训练和评估提供了宝贵资源。之前关于归因评估的工作未能区分基于事实错误和引文错误。他们亦未能自动验证那些部分依赖多个来源的句子。我们通过开发详细的度量标准并使自动评估器能够将句子分解为子主张以解决这些问题。",
    "tldr": "WebCiteS提出了一个带引文的查询焦点摘要任务，并发布了包含7k人工注释摘要及引文的中文数据集，以处理归因中存在的问题。",
    "en_tdlr": "WebCiteS introduces the task of attributed query-focused summarization and releases a Chinese dataset with 7k human-annotated summaries with citations to address issues in attribution."
}