{
    "title": "Dial-insight: Fine-tuning Large Language Models with High-Quality Domain-Specific Data Preventing Capability Collapse",
    "abstract": "arXiv:2403.09167v1 Announce Type: new  Abstract: The efficacy of large language models (LLMs) is heavily dependent on the quality of the underlying data, particularly within specialized domains. A common challenge when fine-tuning LLMs for domain-specific applications is the potential degradation of the model's generalization capabilities. To address these issues, we propose a two-stage approach for the construction of production prompts designed to yield high-quality data. This method involves the generation of a diverse array of prompts that encompass a broad spectrum of tasks and exhibit a rich variety of expressions. Furthermore, we introduce a cost-effective, multi-dimensional quality assessment framework to ensure the integrity of the generated labeling data. Utilizing a dataset comprised of service provider and customer interactions from the real estate sector, we demonstrate a positive correlation between data quality and model performance. Notably, our findings indicate that t",
    "link": "https://arxiv.org/abs/2403.09167",
    "context": "Title: Dial-insight: Fine-tuning Large Language Models with High-Quality Domain-Specific Data Preventing Capability Collapse\nAbstract: arXiv:2403.09167v1 Announce Type: new  Abstract: The efficacy of large language models (LLMs) is heavily dependent on the quality of the underlying data, particularly within specialized domains. A common challenge when fine-tuning LLMs for domain-specific applications is the potential degradation of the model's generalization capabilities. To address these issues, we propose a two-stage approach for the construction of production prompts designed to yield high-quality data. This method involves the generation of a diverse array of prompts that encompass a broad spectrum of tasks and exhibit a rich variety of expressions. Furthermore, we introduce a cost-effective, multi-dimensional quality assessment framework to ensure the integrity of the generated labeling data. Utilizing a dataset comprised of service provider and customer interactions from the real estate sector, we demonstrate a positive correlation between data quality and model performance. Notably, our findings indicate that t",
    "path": "papers/24/03/2403.09167.json",
    "total_tokens": 845,
    "translated_title": "Dial-insight: 使用高质量领域特定数据对大型语言模型进行微调，避免能力崩溃",
    "translated_abstract": "大型语言模型（LLMs）的有效性严重依赖于基础数据的质量，特别是在专业领域内。在为特定领域应用对LLMs进行微调时经常面临的挑战是模型泛化能力的潜在退化。为了解决这些问题，我们提出了一个两阶段的方法来构建旨在产生高质量数据的生产提示。该方法涉及生成涵盖各种任务和展现丰富表达形式的多样提示。此外，我们引入了一种经济高效的、多维质量评估框架，以确保生成的标注数据的完整性。利用来自房地产行业的服务提供商和客户互动组成的数据集，我们证明了数据质量与模型性能之间存在正向相关性。值得注意的是，我们的研究结果表明",
    "tldr": "通过提出具有多样提示和多维质量评估框架的两阶段方法，可以在避免模型泛化能力下降的情况下，使用高质量领域特定数据对大型语言模型进行微调。",
    "en_tdlr": "The paper proposes a two-stage approach with diverse prompts and multidimensional quality assessment framework to fine-tune large language models with high-quality domain-specific data, preventing capability collapse."
}