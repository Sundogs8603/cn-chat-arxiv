{
    "title": "Denoising Table-Text Retrieval for Open-Domain Question Answering",
    "abstract": "arXiv:2403.17611v1 Announce Type: cross  Abstract: In table-text open-domain question answering, a retriever system retrieves relevant evidence from tables and text to answer questions. Previous studies in table-text open-domain question answering have two common challenges: firstly, their retrievers can be affected by false-positive labels in training datasets; secondly, they may struggle to provide appropriate evidence for questions that require reasoning across the table. To address these issues, we propose Denoised Table-Text Retriever (DoTTeR). Our approach involves utilizing a denoised training dataset with fewer false positive labels by discarding instances with lower question-relevance scores measured through a false positive detection model. Subsequently, we integrate table-level ranking information into the retriever to assist in finding evidence for questions that demand reasoning across the table. To encode this ranking information, we fine-tune a rank-aware column encoder ",
    "link": "https://arxiv.org/abs/2403.17611",
    "context": "Title: Denoising Table-Text Retrieval for Open-Domain Question Answering\nAbstract: arXiv:2403.17611v1 Announce Type: cross  Abstract: In table-text open-domain question answering, a retriever system retrieves relevant evidence from tables and text to answer questions. Previous studies in table-text open-domain question answering have two common challenges: firstly, their retrievers can be affected by false-positive labels in training datasets; secondly, they may struggle to provide appropriate evidence for questions that require reasoning across the table. To address these issues, we propose Denoised Table-Text Retriever (DoTTeR). Our approach involves utilizing a denoised training dataset with fewer false positive labels by discarding instances with lower question-relevance scores measured through a false positive detection model. Subsequently, we integrate table-level ranking information into the retriever to assist in finding evidence for questions that demand reasoning across the table. To encode this ranking information, we fine-tune a rank-aware column encoder ",
    "path": "papers/24/03/2403.17611.json",
    "total_tokens": 890,
    "translated_title": "对开放领域问答的去噪表格-文本检索",
    "translated_abstract": "在表格-文本开放领域问答中，检索系统从表格和文本中检索相关证据以回答问题。之前在表格-文本开放领域问答中的研究存在两个常见挑战：首先，它们的检索器可能受到训练数据集中的假正标签影响；其次，它们可能难以为需要跨表格推理的问题提供适当的证据。为了解决这些问题，我们提出了去噪表格-文本检索器（DoTTeR）。我们的方法包括利用一个去噪的训练数据集，通过舍弃通过假正检测模型测量的较低问题相关性得分的示例来减少假正标签。随后，我们将表级排名信息整合到检索器中，以帮助找到需要跨表格推理的问题的证据。为了编码此排名信息，我们对一个排名感知的列编码器进行微调。",
    "tldr": "本文提出了一种Denosied Table-Text Retriever（DoTTeR）方法，通过利用去噪训练数据集和整合表级排名信息，解决了表格-文本开放领域问答中存在的假正标签影响和跨表格推理问题的挑战。",
    "en_tdlr": "This paper introduces a Denoised Table-Text Retriever (DoTTeR) method to address the challenges of false positive labels and reasoning across tables in table-text open-domain question answering by utilizing denoised training dataset and integrating table-level ranking information."
}