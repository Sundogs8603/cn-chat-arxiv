{
    "title": "MedPromptX: Grounded Multimodal Prompting for Chest X-ray Diagnosis",
    "abstract": "arXiv:2403.15585v1 Announce Type: cross  Abstract: Chest X-ray images are commonly used for predicting acute and chronic cardiopulmonary conditions, but efforts to integrate them with structured clinical data face challenges due to incomplete electronic health records (EHR). This paper introduces \\textbf{MedPromptX}, the first model to integrate multimodal large language models (MLLMs), few-shot prompting (FP) and visual grounding (VG) to combine imagery with EHR data for chest X-ray diagnosis. A pre-trained MLLM is utilized to complement the missing EHR information, providing a comprehensive understanding of patients' medical history. Additionally, FP reduces the necessity for extensive training of MLLMs while effectively tackling the issue of hallucination. Nevertheless, the process of determining the optimal number of few-shot examples and selecting high-quality candidates can be burdensome, yet it profoundly influences model performance. Hence, we propose a new technique that dynam",
    "link": "https://arxiv.org/abs/2403.15585",
    "context": "Title: MedPromptX: Grounded Multimodal Prompting for Chest X-ray Diagnosis\nAbstract: arXiv:2403.15585v1 Announce Type: cross  Abstract: Chest X-ray images are commonly used for predicting acute and chronic cardiopulmonary conditions, but efforts to integrate them with structured clinical data face challenges due to incomplete electronic health records (EHR). This paper introduces \\textbf{MedPromptX}, the first model to integrate multimodal large language models (MLLMs), few-shot prompting (FP) and visual grounding (VG) to combine imagery with EHR data for chest X-ray diagnosis. A pre-trained MLLM is utilized to complement the missing EHR information, providing a comprehensive understanding of patients' medical history. Additionally, FP reduces the necessity for extensive training of MLLMs while effectively tackling the issue of hallucination. Nevertheless, the process of determining the optimal number of few-shot examples and selecting high-quality candidates can be burdensome, yet it profoundly influences model performance. Hence, we propose a new technique that dynam",
    "path": "papers/24/03/2403.15585.json",
    "total_tokens": 943,
    "translated_title": "MedPromptX：基于现实的多模态提示用于胸部X线诊断",
    "translated_abstract": "胸部X线图像通常用于预测急性和慢性心肺疾病，但是将它们与结构化临床数据整合的努力面临着因电子健康记录（EHR）不完整而带来的挑战。本文引入了MedPromptX，这是第一个将多模态大型语言模型（MLLMs）、少样本提示（FP）和视觉基础（VG）相结合，将图像与EHR数据用于胸部X线诊断的模型。预训练的MLLM被用来补充缺失的EHR信息，提供对患者病史的全面理解。此外，少样本提示减少了对MLLM的大量训练的必要性，同时有效解决了幻觉问题。然而，确定最佳少样本示例的过程和选择高质量候选者可能过于繁琐，但它对模型性能产生着深远影响。因此，我们提出了一种新技术来动态地...",
    "tldr": "MedPromptX是第一个将多模态大型语言模型、少样本提示和视觉基础相结合，用于胸部X线诊断的模型，通过补充缺失的EHR信息，有效解决了幻觉问题，但选择最佳少样本示例和高质量候选者仍有待解决。",
    "en_tdlr": "MedPromptX is the first model to integrate multimodal large language models, few-shot prompting, and visual grounding for chest X-ray diagnosis, providing a comprehensive understanding of patients' medical history by complementing missing EHR information and effectively addressing the issue of hallucination, although the process of determining the optimal few-shot examples and selecting high-quality candidates remains a challenge."
}