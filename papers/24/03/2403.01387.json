{
    "title": "A Comprehensive Survey of Federated Transfer Learning: Challenges, Methods and Applications",
    "abstract": "arXiv:2403.01387v1 Announce Type: new  Abstract: Federated learning (FL) is a novel distributed machine learning paradigm that enables participants to collaboratively train a centralized model with privacy preservation by eliminating the requirement of data sharing. In practice, FL often involves multiple participants and requires the third party to aggregate global information to guide the update of the target participant. Therefore, many FL methods do not work well due to the training and test data of each participant may not be sampled from the same feature space and the same underlying distribution. Meanwhile, the differences in their local devices (system heterogeneity), the continuous influx of online data (incremental data), and labeled data scarcity may further influence the performance of these methods. To solve this problem, federated transfer learning (FTL), which integrates transfer learning (TL) into FL, has attracted the attention of numerous researchers. However, since F",
    "link": "https://arxiv.org/abs/2403.01387",
    "context": "Title: A Comprehensive Survey of Federated Transfer Learning: Challenges, Methods and Applications\nAbstract: arXiv:2403.01387v1 Announce Type: new  Abstract: Federated learning (FL) is a novel distributed machine learning paradigm that enables participants to collaboratively train a centralized model with privacy preservation by eliminating the requirement of data sharing. In practice, FL often involves multiple participants and requires the third party to aggregate global information to guide the update of the target participant. Therefore, many FL methods do not work well due to the training and test data of each participant may not be sampled from the same feature space and the same underlying distribution. Meanwhile, the differences in their local devices (system heterogeneity), the continuous influx of online data (incremental data), and labeled data scarcity may further influence the performance of these methods. To solve this problem, federated transfer learning (FTL), which integrates transfer learning (TL) into FL, has attracted the attention of numerous researchers. However, since F",
    "path": "papers/24/03/2403.01387.json",
    "total_tokens": 876,
    "translated_title": "《联邦迁移学习综述：挑战、方法与应用》",
    "translated_abstract": "arXiv:2403.01387v1 公告类型：新摘要：联邦学习（FL）是一种新颖的分布式机器学习范例，通过消除数据共享的要求，使参与者能够共同训练一个带有隐私保护的集中模型。在实践中，FL通常涉及多个参与者，并且需要第三方聚合全局信息以指导目标参与者的更新。因此，由于每个参与者的训练和测试数据可能不是从相同的特征空间和相同的基础分布中抽样得来，很多FL方法往往效果不佳。同时，他们本地设备的差异（系统异构性）、在线数据的持续涌入（增量数据）和标记数据的稀缺可能进一步影响这些方法的性能。为了解决这个问题，将迁移学习（TL）集成到FL中的联邦迁移学习（FTL）引起了许多研究人员的关注。",
    "tldr": "联邦学习是一种分布式机器学习范例，联邦迁移学习则将迁移学习引入联邦学习中，以解决不同参与者数据特征空间和分布的差异所带来的挑战。"
}