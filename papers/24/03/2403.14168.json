{
    "title": "M$^3$AV: A Multimodal, Multigenre, and Multipurpose Audio-Visual Academic Lecture Dataset",
    "abstract": "arXiv:2403.14168v1 Announce Type: new  Abstract: Publishing open-source academic video recordings is an emergent and prevalent approach to sharing knowledge online. Such videos carry rich multimodal information including speech, the facial and body movements of the speakers, as well as the texts and pictures in the slides and possibly even the papers. Although multiple academic video datasets have been constructed and released, few of them support both multimodal content recognition and understanding tasks, which is partially due to the lack of high-quality human annotations. In this paper, we propose a novel multimodal, multigenre, and multipurpose audio-visual academic lecture dataset (M$^3$AV), which has almost 367 hours of videos from five sources covering computer science, mathematics, and medical and biology topics. With high-quality human annotations of the spoken and written words, in particular high-valued name entities, the dataset can be used for multiple audio-visual recogn",
    "link": "https://arxiv.org/abs/2403.14168",
    "context": "Title: M$^3$AV: A Multimodal, Multigenre, and Multipurpose Audio-Visual Academic Lecture Dataset\nAbstract: arXiv:2403.14168v1 Announce Type: new  Abstract: Publishing open-source academic video recordings is an emergent and prevalent approach to sharing knowledge online. Such videos carry rich multimodal information including speech, the facial and body movements of the speakers, as well as the texts and pictures in the slides and possibly even the papers. Although multiple academic video datasets have been constructed and released, few of them support both multimodal content recognition and understanding tasks, which is partially due to the lack of high-quality human annotations. In this paper, we propose a novel multimodal, multigenre, and multipurpose audio-visual academic lecture dataset (M$^3$AV), which has almost 367 hours of videos from five sources covering computer science, mathematics, and medical and biology topics. With high-quality human annotations of the spoken and written words, in particular high-valued name entities, the dataset can be used for multiple audio-visual recogn",
    "path": "papers/24/03/2403.14168.json",
    "total_tokens": 885,
    "translated_title": "M$^3$AV：一种多模态、多体裁和多用途的音视频学术讲座数据集",
    "translated_abstract": "arXiv:2403.14168v1 公告类型：新摘要：发布开源学术视频录像是在线分享知识的一种新兴和普遍方法。这些视频包含丰富的多模态信息，包括演讲者的语音、面部和身体动作，以及幻灯片中的文本和图片，甚至可能包括论文内容。尽管已构建和发布了多个学术视频数据集，但很少有数据集支持多模态内容识别和理解任务，部分原因是缺乏高质量的人工注释。在本文中，我们提出了一种新颖的多模态、多体裁和多用途的音视频学术讲座数据集(M$^3$AV)，该数据集包括来自五个来源的近367小时的视频，涵盖计算机科学、数学以及医学和生物学等主题。通过对言语和书面文字（尤其是高价值名称实体）的高质量人工注释，该数据集可用于多种音视频识别",
    "tldr": "提出了一种新颖的M$^3$AV音视频学术讲座数据集，包含多模态、多体裁和高质量人工注释，可用于多种音视频识别任务",
    "en_tdlr": "Introduced a novel M$^3$AV audio-visual academic lecture dataset with multimodal, multigenre features and high-quality human annotations, suitable for various audio-visual recognition tasks."
}