{
    "title": "Trustworthy Automated Driving through Qualitative Scene Understanding and Explanations",
    "abstract": "arXiv:2403.09668v1 Announce Type: cross  Abstract: We present the Qualitative Explainable Graph (QXG): a unified symbolic and qualitative representation for scene understanding in urban mobility. QXG enables the interpretation of an automated vehicle's environment using sensor data and machine learning models. It leverages spatio-temporal graphs and qualitative constraints to extract scene semantics from raw sensor inputs, such as LiDAR and camera data, offering an intelligible scene model. Crucially, QXG can be incrementally constructed in real-time, making it a versatile tool for in-vehicle explanations and real-time decision-making across various sensor types. Our research showcases the transformative potential of QXG, particularly in the context of automated driving, where it elucidates decision rationales by linking the graph with vehicle actions. These explanations serve diverse purposes, from informing passengers and alerting vulnerable road users (VRUs) to enabling post-analysi",
    "link": "https://arxiv.org/abs/2403.09668",
    "context": "Title: Trustworthy Automated Driving through Qualitative Scene Understanding and Explanations\nAbstract: arXiv:2403.09668v1 Announce Type: cross  Abstract: We present the Qualitative Explainable Graph (QXG): a unified symbolic and qualitative representation for scene understanding in urban mobility. QXG enables the interpretation of an automated vehicle's environment using sensor data and machine learning models. It leverages spatio-temporal graphs and qualitative constraints to extract scene semantics from raw sensor inputs, such as LiDAR and camera data, offering an intelligible scene model. Crucially, QXG can be incrementally constructed in real-time, making it a versatile tool for in-vehicle explanations and real-time decision-making across various sensor types. Our research showcases the transformative potential of QXG, particularly in the context of automated driving, where it elucidates decision rationales by linking the graph with vehicle actions. These explanations serve diverse purposes, from informing passengers and alerting vulnerable road users (VRUs) to enabling post-analysi",
    "path": "papers/24/03/2403.09668.json",
    "total_tokens": 843,
    "translated_title": "通过定性场景理解和解释实现可信自动驾驶",
    "translated_abstract": "我们提出了定性可解释图（QXG）：一种统一的符号和定性表示，用于城市移动中的场景理解。QXG利用时空图和定性约束从原始传感器输入（如LiDAR和摄像头数据）中提取场景语义，提供了可解释的场景模型。关键的是，QXG可以在实时中进行增量构建，使其成为一种多功能工具，可用于车内解释和各种传感器类型的实时决策。我们的研究展示了QXG的变革潜力，特别是在自动驾驶领域，它通过将图与车辆动作联系起来，阐明了决策原理。这些解释服务于多种目的，从向乘客提供信息到警示弱势道路使用者（VRUs），再到实现事后分析。",
    "tldr": "我们提出了定性可解释图（QXG），通过将时空图和定性约束应用于传感器数据，能够实现在自动驾驶过程中对场景进行理解和解释，为实时决策提供可靠的场景模型。",
    "en_tdlr": "We propose the Qualitative Explainable Graph (QXG) that uses spatio-temporal graphs and qualitative constraints on sensor data to enable qualitative scene understanding and explanations in automated driving, providing a reliable scene model for real-time decision-making."
}