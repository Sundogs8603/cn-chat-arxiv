{
    "title": "Improving the Validity of Automatically Generated Feedback via Reinforcement Learning",
    "abstract": "arXiv:2403.01304v1 Announce Type: new  Abstract: Automatically generating feedback via large language models (LLMs) in intelligent tutoring systems and online learning platforms has the potential to improve the learning outcomes of many students. However, both feedback generation and evaluation are challenging: feedback content has to be valid especially in subjects like math, which requires models to understand the problem, the solution, and where the student's error lies. Feedback also has to be pedagogically valid to reflect effective tutoring strategies, such as explaining possible misconceptions and encouraging the student, among other desirable features. In this work, we address both problems of automatically generating and evaluating feedback while considering both correctness and alignment. First, we propose a rubric for evaluating math feedback and show that GPT-4 is able to effectively use it to annotate human-written and LLM-generated feedback. Second, we propose a framework",
    "link": "https://arxiv.org/abs/2403.01304",
    "context": "Title: Improving the Validity of Automatically Generated Feedback via Reinforcement Learning\nAbstract: arXiv:2403.01304v1 Announce Type: new  Abstract: Automatically generating feedback via large language models (LLMs) in intelligent tutoring systems and online learning platforms has the potential to improve the learning outcomes of many students. However, both feedback generation and evaluation are challenging: feedback content has to be valid especially in subjects like math, which requires models to understand the problem, the solution, and where the student's error lies. Feedback also has to be pedagogically valid to reflect effective tutoring strategies, such as explaining possible misconceptions and encouraging the student, among other desirable features. In this work, we address both problems of automatically generating and evaluating feedback while considering both correctness and alignment. First, we propose a rubric for evaluating math feedback and show that GPT-4 is able to effectively use it to annotate human-written and LLM-generated feedback. Second, we propose a framework",
    "path": "papers/24/03/2403.01304.json",
    "total_tokens": 652,
    "translated_title": "通过强化学习提高自动生成反馈的有效性",
    "translated_abstract": "在智能辅导系统和在线学习平台中，通过大型语言模型（LLMs）自动生成反馈具有改善许多学生学习成果的潜力。本研究解决了自动生成和评估反馈的问题，同时考虑了正确性和一致性。",
    "tldr": "本研究通过提出评估数学反馈的评分标准，展示了GPT-4能够有效地使用它来注释人工编写的和LLM生成的反馈，从而改进了自动生成反馈的有效性和可靠性。",
    "en_tdlr": "This study improves the validity and reliability of automatically generated feedback by proposing a rubric for evaluating math feedback and demonstrating GPT-4's effective use in annotating human-written and LLM-generated feedback."
}