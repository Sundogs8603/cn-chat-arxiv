{
    "title": "Trust AI Regulation? Discerning users are vital to build trust and effective AI regulation",
    "abstract": "arXiv:2403.09510v1 Announce Type: new  Abstract: There is general agreement that some form of regulation is necessary both for AI creators to be incentivised to develop trustworthy systems, and for users to actually trust those systems. But there is much debate about what form these regulations should take and how they should be implemented. Most work in this area has been qualitative, and has not been able to make formal predictions. Here, we propose that evolutionary game theory can be used to quantitatively model the dilemmas faced by users, AI creators, and regulators, and provide insights into the possible effects of different regulatory regimes. We show that creating trustworthy AI and user trust requires regulators to be incentivised to regulate effectively. We demonstrate the effectiveness of two mechanisms that can achieve this. The first is where governments can recognise and reward regulators that do a good job. In that case, if the AI system is not too risky for users then ",
    "link": "https://arxiv.org/abs/2403.09510",
    "context": "Title: Trust AI Regulation? Discerning users are vital to build trust and effective AI regulation\nAbstract: arXiv:2403.09510v1 Announce Type: new  Abstract: There is general agreement that some form of regulation is necessary both for AI creators to be incentivised to develop trustworthy systems, and for users to actually trust those systems. But there is much debate about what form these regulations should take and how they should be implemented. Most work in this area has been qualitative, and has not been able to make formal predictions. Here, we propose that evolutionary game theory can be used to quantitatively model the dilemmas faced by users, AI creators, and regulators, and provide insights into the possible effects of different regulatory regimes. We show that creating trustworthy AI and user trust requires regulators to be incentivised to regulate effectively. We demonstrate the effectiveness of two mechanisms that can achieve this. The first is where governments can recognise and reward regulators that do a good job. In that case, if the AI system is not too risky for users then ",
    "path": "papers/24/03/2403.09510.json",
    "total_tokens": 875,
    "translated_title": "AI监管信任? 辨识用户对于建立信任和有效的AI监管至关重要",
    "translated_abstract": "有普遍共识认为，AI创作者需要受到某种形式的监管以开发值得信赖的系统，用户也需要真正相信这些系统。然而，关于这些监管应该采取什么形式以及如何实施它们存在很大争议。在这一领域的大部分工作是定性的，并且不能进行正式预测。在这里，我们提出演化博弈论可以用于量化模拟用户、AI创作者和监管者面临的困境，并为不同监管制度可能产生的影响提供见解。我们展示了创建值得信赖的AI和用户信任需要监管者受到有效监管的激励。我们证明了可以实现这一点的两种机制的有效性。第一种机制是政府可以认可并奖励做好工作的监管者。在这种情况下，如果AI系统对用户来说不太风险。",
    "tldr": "通过演化博弈论量化模拟用户、AI创作者和监管者面临的困境，提出政府认可和奖励监管者可以激励有效监管的机制，帮助建立值得信赖的AI和用户信任。",
    "en_tdlr": "By quantitatively modeling the dilemmas faced by users, AI creators, and regulators using evolutionary game theory, proposing the mechanism of government recognition and reward for regulators to incentivize effective regulation, helps build trustworthy AI and user trust."
}