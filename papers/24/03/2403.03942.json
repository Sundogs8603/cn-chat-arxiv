{
    "title": "The Heuristic Core: Understanding Subnetwork Generalization in Pretrained Language Models",
    "abstract": "arXiv:2403.03942v1 Announce Type: new  Abstract: Prior work has found that pretrained language models (LMs) fine-tuned with different random seeds can achieve similar in-domain performance but generalize differently on tests of syntactic generalization. In this work, we show that, even within a single model, we can find multiple subnetworks that perform similarly in-domain, but generalize vastly differently. To better understand these phenomena, we investigate if they can be understood in terms of \"competing subnetworks\": the model initially represents a variety of distinct algorithms, corresponding to different subnetworks, and generalization occurs when it ultimately converges to one. This explanation has been used to account for generalization in simple algorithmic tasks. Instead of finding competing subnetworks, we find that all subnetworks -- whether they generalize or not -- share a set of attention heads, which we refer to as the heuristic core. Further analysis suggests that th",
    "link": "https://arxiv.org/abs/2403.03942",
    "context": "Title: The Heuristic Core: Understanding Subnetwork Generalization in Pretrained Language Models\nAbstract: arXiv:2403.03942v1 Announce Type: new  Abstract: Prior work has found that pretrained language models (LMs) fine-tuned with different random seeds can achieve similar in-domain performance but generalize differently on tests of syntactic generalization. In this work, we show that, even within a single model, we can find multiple subnetworks that perform similarly in-domain, but generalize vastly differently. To better understand these phenomena, we investigate if they can be understood in terms of \"competing subnetworks\": the model initially represents a variety of distinct algorithms, corresponding to different subnetworks, and generalization occurs when it ultimately converges to one. This explanation has been used to account for generalization in simple algorithmic tasks. Instead of finding competing subnetworks, we find that all subnetworks -- whether they generalize or not -- share a set of attention heads, which we refer to as the heuristic core. Further analysis suggests that th",
    "path": "papers/24/03/2403.03942.json",
    "total_tokens": 859,
    "translated_title": "《启发式核心：理解预训练语言模型中的子网络泛化》",
    "translated_abstract": "先前的研究发现，经过不同随机种子微调的预训练语言模型（LMs）可以实现类似的领域内性能，但在句法泛化测试中泛化不同。在这项工作中，我们展示出即使在单一模型内部，我们也可以找到执行类似领域内操作但泛化差异巨大的多个子网络。为了更好地理解这些现象，我们调查是否可以用“竞争性子网络”来理解它们：模型最初表示各种不同算法，对应于不同的子网络，当最终收敛到其中一个时泛化发生。这一解释已被用于解释简单算法任务中的泛化。我们发现，并非找到竞争性子网络，而是所有子网络 -- 无论它们是否泛化 -- 都共享一组注意力头，我们将其称为启发式核心。进一步分析表明，它可能是造成不同子网络泛化的原因。",
    "tldr": "在预训练语言模型中，发现所有子网络都共享一个注意力头集合，被称为启发式核心，这可能是造成子网络泛化差异的原因。"
}