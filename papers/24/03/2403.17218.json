{
    "title": "A Comprehensive Study of the Capabilities of Large Language Models for Vulnerability Detection",
    "abstract": "arXiv:2403.17218v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated great potential for code generation and other software engineering tasks. Vulnerability detection is of crucial importance to maintaining the security, integrity, and trustworthiness of software systems. Precise vulnerability detection requires reasoning about the code, making it a good case study for exploring the limits of LLMs' reasoning capabilities. Although recent work has applied LLMs to vulnerability detection using generic prompting techniques, their full capabilities for this task and the types of errors they make when explaining identified vulnerabilities remain unclear.   In this paper, we surveyed eleven LLMs that are state-of-the-art in code generation and commonly used as coding assistants, and evaluated their capabilities for vulnerability detection. We systematically searched for the best-performing prompts, incorporating techniques such as in-context learning and chain-of",
    "link": "https://arxiv.org/abs/2403.17218",
    "context": "Title: A Comprehensive Study of the Capabilities of Large Language Models for Vulnerability Detection\nAbstract: arXiv:2403.17218v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated great potential for code generation and other software engineering tasks. Vulnerability detection is of crucial importance to maintaining the security, integrity, and trustworthiness of software systems. Precise vulnerability detection requires reasoning about the code, making it a good case study for exploring the limits of LLMs' reasoning capabilities. Although recent work has applied LLMs to vulnerability detection using generic prompting techniques, their full capabilities for this task and the types of errors they make when explaining identified vulnerabilities remain unclear.   In this paper, we surveyed eleven LLMs that are state-of-the-art in code generation and commonly used as coding assistants, and evaluated their capabilities for vulnerability detection. We systematically searched for the best-performing prompts, incorporating techniques such as in-context learning and chain-of",
    "path": "papers/24/03/2403.17218.json",
    "total_tokens": 858,
    "translated_title": "大型语言模型在漏洞检测方面的能力综合研究",
    "translated_abstract": "大型语言模型（LLMs）已经展现出在代码生成和其他软件工程任务方面具有巨大潜力。漏洞检测对于维护软件系统的安全、完整性和可信度至关重要。精确的漏洞检测需要对代码进行推理，这使得它成为探索LLMs推理能力极限的良好案例研究。尽管最近的研究已经利用通用提示技术将LLMs应用于漏洞检测，但它们在这一任务中的完整能力以及在解释确定的漏洞时所犯的错误类型仍不清楚。在本文中，我们调查了十一种领先的在代码生成方面处于最前沿且通常用作编码助手的LLMs，并评估了它们在漏洞检测方面的能力。我们系统地搜索了效果最佳的提示，结合了诸如上下文学习和链式学习等技术。",
    "tldr": "本研究调查了十一种领先的大型语言模型在漏洞检测中的能力，并评估了它们的性能，为探索LLMs推理能力的极限提供了重要案例研究。",
    "en_tdlr": "This study investigated the capabilities of eleven state-of-the-art large language models in vulnerability detection, providing an important case study for exploring the limits of LLMs' reasoning abilities."
}