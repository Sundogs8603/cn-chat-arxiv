{
    "title": "Investigating grammatical abstraction in language models using few-shot learning of novel noun gender",
    "abstract": "arXiv:2403.10338v1 Announce Type: new  Abstract: Humans can learn a new word and infer its grammatical properties from very few examples. They have an abstract notion of linguistic properties like grammatical gender and agreement rules that can be applied to novel syntactic contexts and words. Drawing inspiration from psycholinguistics, we conduct a noun learning experiment to assess whether an LSTM and a decoder-only transformer can achieve human-like abstraction of grammatical gender in French. Language models were tasked with learning the gender of a novel noun embedding from a few examples in one grammatical agreement context and predicting agreement in another, unseen context. We find that both language models effectively generalise novel noun gender from one to two learning examples and apply the learnt gender across agreement contexts, albeit with a bias for the masculine gender category. Importantly, the few-shot updates were only applied to the embedding layers, demonstrating ",
    "link": "https://arxiv.org/abs/2403.10338",
    "context": "Title: Investigating grammatical abstraction in language models using few-shot learning of novel noun gender\nAbstract: arXiv:2403.10338v1 Announce Type: new  Abstract: Humans can learn a new word and infer its grammatical properties from very few examples. They have an abstract notion of linguistic properties like grammatical gender and agreement rules that can be applied to novel syntactic contexts and words. Drawing inspiration from psycholinguistics, we conduct a noun learning experiment to assess whether an LSTM and a decoder-only transformer can achieve human-like abstraction of grammatical gender in French. Language models were tasked with learning the gender of a novel noun embedding from a few examples in one grammatical agreement context and predicting agreement in another, unseen context. We find that both language models effectively generalise novel noun gender from one to two learning examples and apply the learnt gender across agreement contexts, albeit with a bias for the masculine gender category. Importantly, the few-shot updates were only applied to the embedding layers, demonstrating ",
    "path": "papers/24/03/2403.10338.json",
    "total_tokens": 851,
    "translated_title": "使用少样本学习探究语言模型中的语法抽象性：新名词性别的学习",
    "translated_abstract": "人类可以从很少的例子中学习一个新单词，并推断其语法属性。他们对像语法性别和一致规则这样的语言属性具有抽象概念，可以应用到新的句法上下文和词语中。我们从心理语言学中汲取灵感，进行了一个名词学习实验，评估LSTM和仅解码器变压器是否可以实现对法语中的语法性别的类似人类的抽象。语言模型的任务是从几个例子中学习一个新名词嵌入的性别，并在另一个未见上下文中预测一致。我们发现，两种语言模型在一个语法一致上下文中能有效地将新名词的性别概括到一个到两个学习示例，并把所学的性别应用到一致上下文，尽管有对阳性性别类别的偏见。重要的是，少样本更新仅应用于嵌入层，证明了...",
    "tldr": "语言模型可以通过很少的例子学习新名词的性别，并在不同的一致上下文中应用所学性别，虽然有对阳性性别类别的偏见",
    "en_tdlr": "Language models can learn the gender of a new noun from few examples and apply it across different agreement contexts, although with a bias towards the masculine gender category."
}