{
    "title": "Self-Supervised Multi-Frame Neural Scene Flow",
    "abstract": "arXiv:2403.16116v1 Announce Type: cross  Abstract: Neural Scene Flow Prior (NSFP) and Fast Neural Scene Flow (FNSF) have shown remarkable adaptability in the context of large out-of-distribution autonomous driving. Despite their success, the underlying reasons for their astonishing generalization capabilities remain unclear. Our research addresses this gap by examining the generalization capabilities of NSFP through the lens of uniform stability, revealing that its performance is inversely proportional to the number of input point clouds. This finding sheds light on NSFP's effectiveness in handling large-scale point cloud scene flow estimation tasks. Motivated by such theoretical insights, we further explore the improvement of scene flow estimation by leveraging historical point clouds across multiple frames, which inherently increases the number of point clouds. Consequently, we propose a simple and effective method for multi-frame point cloud scene flow estimation, along with a theor",
    "link": "https://arxiv.org/abs/2403.16116",
    "context": "Title: Self-Supervised Multi-Frame Neural Scene Flow\nAbstract: arXiv:2403.16116v1 Announce Type: cross  Abstract: Neural Scene Flow Prior (NSFP) and Fast Neural Scene Flow (FNSF) have shown remarkable adaptability in the context of large out-of-distribution autonomous driving. Despite their success, the underlying reasons for their astonishing generalization capabilities remain unclear. Our research addresses this gap by examining the generalization capabilities of NSFP through the lens of uniform stability, revealing that its performance is inversely proportional to the number of input point clouds. This finding sheds light on NSFP's effectiveness in handling large-scale point cloud scene flow estimation tasks. Motivated by such theoretical insights, we further explore the improvement of scene flow estimation by leveraging historical point clouds across multiple frames, which inherently increases the number of point clouds. Consequently, we propose a simple and effective method for multi-frame point cloud scene flow estimation, along with a theor",
    "path": "papers/24/03/2403.16116.json",
    "total_tokens": 765,
    "translated_title": "自监督多帧神经场景流",
    "translated_abstract": "Neural Scene Flow Prior (NSFP)和Fast Neural Scene Flow (FNSF)在大规模场景中具有出色的自适应性，但是它们的泛化能力的基础原因尚不清楚。我们的研究通过统一稳定性的视角来审视NSFP的泛化能力，揭示其性能与输入点云数量呈反比关系。这一发现揭示了NSFP在处理大规模点云场景流估计任务中的有效性。受这些理论洞察的启发，我们进一步通过利用多帧历史点云来改进场景流估计，从而增加了点云的数量。因此，我们提出了一种简单而有效的多帧点云场景流估计方法。",
    "tldr": "通过研究表明，Neural Scene Flow Prior (NSFP)的性能与输入点云的数量呈反比关系，因此我们提出了一种简单而有效的多帧点云场景流估计方法。",
    "en_tdlr": "Our research reveals that the performance of Neural Scene Flow Prior (NSFP) is inversely proportional to the number of input point clouds, leading to the proposal of a simple and effective method for multi-frame point cloud scene flow estimation."
}