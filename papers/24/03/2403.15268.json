{
    "title": "Imagination Augmented Generation: Learning to Imagine Richer Context for Question Answering over Large Language Models",
    "abstract": "arXiv:2403.15268v1 Announce Type: new  Abstract: Retrieval-Augmented-Generation and Gener-ation-Augmented-Generation have been proposed to enhance the knowledge required for question answering over Large Language Models (LLMs). However, the former depends on external resources, and both require incorporating the explicit documents into the context, which results in longer contexts that lead to more resource consumption. Recent works indicate that LLMs have modeled rich knowledge, albeit not effectively triggered or activated. Inspired by this, we propose a novel knowledge-augmented framework, Imagination-Augmented-Generation (IAG), which simulates the human capacity to compensate for knowledge deficits while answering questions solely through imagination, without relying on external resources. Guided by IAG, we propose an imagine richer context method for question answering (IMcQA), which obtains richer context through the following two modules: explicit imagination by generating a sho",
    "link": "https://arxiv.org/abs/2403.15268",
    "context": "Title: Imagination Augmented Generation: Learning to Imagine Richer Context for Question Answering over Large Language Models\nAbstract: arXiv:2403.15268v1 Announce Type: new  Abstract: Retrieval-Augmented-Generation and Gener-ation-Augmented-Generation have been proposed to enhance the knowledge required for question answering over Large Language Models (LLMs). However, the former depends on external resources, and both require incorporating the explicit documents into the context, which results in longer contexts that lead to more resource consumption. Recent works indicate that LLMs have modeled rich knowledge, albeit not effectively triggered or activated. Inspired by this, we propose a novel knowledge-augmented framework, Imagination-Augmented-Generation (IAG), which simulates the human capacity to compensate for knowledge deficits while answering questions solely through imagination, without relying on external resources. Guided by IAG, we propose an imagine richer context method for question answering (IMcQA), which obtains richer context through the following two modules: explicit imagination by generating a sho",
    "path": "papers/24/03/2403.15268.json",
    "total_tokens": 955,
    "translated_title": "想象增强生成：学习想象更丰富的背景来进行大型语言模型问题回答",
    "translated_abstract": "检索增强生成和生成增强生成已被提出来增强大型语言模型（LLMs）上的问题回答所需的知识。然而，前者依赖于外部资源，而且两者都需要将显式文档合并到上下文中，导致更长的上下文，从而消耗更多资源。最近的研究表明，LLMs已经建模了丰富的知识，尽管没有被有效地触发或激活。在此启发下，我们提出了一种新颖的知识增强框架，即想象增强生成（IAG），它模拟了人类通过想象力在仅凭想象回答问题时弥补知识缺陷的能力，而不依赖外部资源。在IAG的指导下，我们提出了一种用于问题回答的想象更丰富背景的方法（IMcQA），通过以下两个模块获得更丰富的背景：通过生成简单的想象实现显式想象",
    "tldr": "提出了一种新颖的知识增强框架，即想象增强生成（IAG），通过想象力，而非依赖外部资源，来补充大型语言模型中可能存在的知识缺陷，并提出了一种想象更丰富背景的方法（IMcQA）来解决问题回答中的挑战。"
}