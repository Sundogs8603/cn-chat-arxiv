{
    "title": "Sample size planning for conditional counterfactual mean estimation with a K-armed randomized experiment",
    "abstract": "arXiv:2403.04039v1 Announce Type: new  Abstract: We cover how to determine a sufficiently large sample size for a $K$-armed randomized experiment in order to estimate conditional counterfactual expectations in data-driven subgroups. The sub-groups can be output by any feature space partitioning algorithm, including as defined by binning users having similar predictive scores or as defined by a learned policy tree. After carefully specifying the inference target, a minimum confidence level, and a maximum margin of error, the key is to turn the original goal into a simultaneous inference problem where the recommended sample size to offset an increased possibility of estimation error is directly related to the number of inferences to be conducted. Given a fixed sample size budget, our result allows us to invert the question to one about the feasible number of treatment arms or partition complexity (e.g. number of decision tree leaves). Using policy trees to learn sub-groups, we evaluate o",
    "link": "https://arxiv.org/abs/2403.04039",
    "context": "Title: Sample size planning for conditional counterfactual mean estimation with a K-armed randomized experiment\nAbstract: arXiv:2403.04039v1 Announce Type: new  Abstract: We cover how to determine a sufficiently large sample size for a $K$-armed randomized experiment in order to estimate conditional counterfactual expectations in data-driven subgroups. The sub-groups can be output by any feature space partitioning algorithm, including as defined by binning users having similar predictive scores or as defined by a learned policy tree. After carefully specifying the inference target, a minimum confidence level, and a maximum margin of error, the key is to turn the original goal into a simultaneous inference problem where the recommended sample size to offset an increased possibility of estimation error is directly related to the number of inferences to be conducted. Given a fixed sample size budget, our result allows us to invert the question to one about the feasible number of treatment arms or partition complexity (e.g. number of decision tree leaves). Using policy trees to learn sub-groups, we evaluate o",
    "path": "papers/24/03/2403.04039.json",
    "total_tokens": 916,
    "translated_title": "用于条件反事实均值估计的样本规模规划: 一个K臂随机实验",
    "translated_abstract": "我们讨论如何确定足够大的样本规模，以估计数据驱动子组中的条件反事实期望，该子组可以由任何特征空间划分算法输出，包括根据预测分数相似的用户进行分组或根据学习的策略树进行分组。在仔细规定推断目标、最小置信水平和最大误差边际后，关键是将原始目标转化为一个同时推断问题，推荐的样本大小以抵消估计误差的增加可能性直接与要进行的推断数量相关。在给定固定样本规模预算的情况下，我们的结果使我们能够将问题反转为关于可行治疗手臂数量或分区复杂性（例如，决策树叶子数量）的问题。使用策略树学习子组，我们评估...",
    "tldr": "论文讨论了如何确定足够大的样本规模，以在数据驱动的子组中估计条件反事实期望，通过将原始目标转化为同时推断问题来解决估计误差增加的可能性，并且允许在固定的样本大小预算下逆转问题以确定可行的治疗手臂数量或分区复杂性。",
    "en_tdlr": "The paper discusses how to determine a sufficiently large sample size to estimate conditional counterfactual expectations in data-driven subgroups, by turning the original goal into a simultaneous inference problem to address the increased possibility of estimation error, allowing the inversion of the question to determine the feasible number of treatment arms or partition complexity under a fixed sample size budget."
}