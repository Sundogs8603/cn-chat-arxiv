{
    "title": "EXPLORER: Exploration-guided Reasoning for Textual Reinforcement Learning",
    "abstract": "arXiv:2403.10692v1 Announce Type: cross  Abstract: Text-based games (TBGs) have emerged as an important collection of NLP tasks, requiring reinforcement learning (RL) agents to combine natural language understanding with reasoning. A key challenge for agents attempting to solve such tasks is to generalize across multiple games and demonstrate good performance on both seen and unseen objects. Purely deep-RL-based approaches may perform well on seen objects; however, they fail to showcase the same performance on unseen objects. Commonsense-infused deep-RL agents may work better on unseen data; unfortunately, their policies are often not interpretable or easily transferable. To tackle these issues, in this paper, we present EXPLORER which is an exploration-guided reasoning agent for textual reinforcement learning. EXPLORER is neurosymbolic in nature, as it relies on a neural module for exploration and a symbolic module for exploitation. It can also learn generalized symbolic policies and ",
    "link": "https://arxiv.org/abs/2403.10692",
    "context": "Title: EXPLORER: Exploration-guided Reasoning for Textual Reinforcement Learning\nAbstract: arXiv:2403.10692v1 Announce Type: cross  Abstract: Text-based games (TBGs) have emerged as an important collection of NLP tasks, requiring reinforcement learning (RL) agents to combine natural language understanding with reasoning. A key challenge for agents attempting to solve such tasks is to generalize across multiple games and demonstrate good performance on both seen and unseen objects. Purely deep-RL-based approaches may perform well on seen objects; however, they fail to showcase the same performance on unseen objects. Commonsense-infused deep-RL agents may work better on unseen data; unfortunately, their policies are often not interpretable or easily transferable. To tackle these issues, in this paper, we present EXPLORER which is an exploration-guided reasoning agent for textual reinforcement learning. EXPLORER is neurosymbolic in nature, as it relies on a neural module for exploration and a symbolic module for exploitation. It can also learn generalized symbolic policies and ",
    "path": "papers/24/03/2403.10692.json",
    "total_tokens": 708,
    "translated_title": "EXPLORER：探索引导的文本强化学习",
    "translated_abstract": "文本游戏（TBGs）已经成为自然语言处理任务的一个重要集合，要求强化学习（RL）代理结合自然语言理解和推理。本文提出了一种名为EXPLORER的探索引导推理代理，用于文本强化学习，旨在解决智能体在多个游戏中泛化并在已知和未知对象上表现良好的关键挑战。",
    "tldr": "提出了一种名为EXPLORER的探索引导推理代理，用于文本强化学习，能够解决智能体在多个游戏中泛化并在已知和未知对象上表现良好的关键挑战。",
    "en_tdlr": "Proposed a exploration-guided reasoning agent named EXPLORER for textual reinforcement learning to address the key challenge of agents generalizing across multiple games and performing well on both seen and unseen objects."
}