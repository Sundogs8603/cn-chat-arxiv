{
    "title": "Adversarial Fine-tuning of Compressed Neural Networks for Joint Improvement of Robustness and Efficiency",
    "abstract": "arXiv:2403.09441v1 Announce Type: new  Abstract: As deep learning (DL) models are increasingly being integrated into our everyday lives, ensuring their safety by making them robust against adversarial attacks has become increasingly critical. DL models have been found to be susceptible to adversarial attacks which can be achieved by introducing small, targeted perturbations to disrupt the input data. Adversarial training has been presented as a mitigation strategy which can result in more robust models. This adversarial robustness comes with additional computational costs required to design adversarial attacks during training. The two objectives -- adversarial robustness and computational efficiency -- then appear to be in conflict of each other. In this work, we explore the effects of two different model compression methods -- structured weight pruning and quantization -- on adversarial robustness. We specifically explore the effects of fine-tuning on compressed models, and present th",
    "link": "https://arxiv.org/abs/2403.09441",
    "context": "Title: Adversarial Fine-tuning of Compressed Neural Networks for Joint Improvement of Robustness and Efficiency\nAbstract: arXiv:2403.09441v1 Announce Type: new  Abstract: As deep learning (DL) models are increasingly being integrated into our everyday lives, ensuring their safety by making them robust against adversarial attacks has become increasingly critical. DL models have been found to be susceptible to adversarial attacks which can be achieved by introducing small, targeted perturbations to disrupt the input data. Adversarial training has been presented as a mitigation strategy which can result in more robust models. This adversarial robustness comes with additional computational costs required to design adversarial attacks during training. The two objectives -- adversarial robustness and computational efficiency -- then appear to be in conflict of each other. In this work, we explore the effects of two different model compression methods -- structured weight pruning and quantization -- on adversarial robustness. We specifically explore the effects of fine-tuning on compressed models, and present th",
    "path": "papers/24/03/2403.09441.json",
    "total_tokens": 705,
    "translated_title": "对压缩神经网络进行对抗微调，共同提高鲁棒性和效率",
    "translated_abstract": "随着深度学习（DL）模型越来越多地融入我们的日常生活中，确保它们的安全性，使其对抗对抗性攻击具有鲁棒性变得越来越关键。我们在这项研究中探讨了两种不同的模型压缩方法 -- 结构化权重剪枝和量化对抗鲁棒性的影响。我们特别研究了对压缩模型进行微调的效果，并提出了一种同时提高鲁棒性和效率的方法。",
    "tldr": "本研究探讨了对压缩神经网络进行对抗微调对提高鲁棒性和效率的影响。",
    "en_tdlr": "This study investigates the impact of adversarial fine-tuning of compressed neural networks on improving robustness and efficiency."
}