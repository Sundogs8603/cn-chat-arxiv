{
    "title": "The Fusion of Deep Reinforcement Learning and Edge Computing for Real-time Monitoring and Control Optimization in IoT Environments",
    "abstract": "arXiv:2403.07923v1 Announce Type: cross  Abstract: In response to the demand for real-time performance and control quality in industrial Internet of Things (IoT) environments, this paper proposes an optimization control system based on deep reinforcement learning and edge computing. The system leverages cloud-edge collaboration, deploys lightweight policy networks at the edge, predicts system states, and outputs controls at a high frequency, enabling monitoring and optimization of industrial objectives. Additionally, a dynamic resource allocation mechanism is designed to ensure rational scheduling of edge computing resources, achieving global optimization. Results demonstrate that this approach reduces cloud-edge communication latency, accelerates response to abnormal situations, reduces system failure rates, extends average equipment operating time, and saves costs for manual maintenance and replacement. This ensures real-time and stable control.",
    "link": "https://arxiv.org/abs/2403.07923",
    "context": "Title: The Fusion of Deep Reinforcement Learning and Edge Computing for Real-time Monitoring and Control Optimization in IoT Environments\nAbstract: arXiv:2403.07923v1 Announce Type: cross  Abstract: In response to the demand for real-time performance and control quality in industrial Internet of Things (IoT) environments, this paper proposes an optimization control system based on deep reinforcement learning and edge computing. The system leverages cloud-edge collaboration, deploys lightweight policy networks at the edge, predicts system states, and outputs controls at a high frequency, enabling monitoring and optimization of industrial objectives. Additionally, a dynamic resource allocation mechanism is designed to ensure rational scheduling of edge computing resources, achieving global optimization. Results demonstrate that this approach reduces cloud-edge communication latency, accelerates response to abnormal situations, reduces system failure rates, extends average equipment operating time, and saves costs for manual maintenance and replacement. This ensures real-time and stable control.",
    "path": "papers/24/03/2403.07923.json",
    "total_tokens": 824,
    "translated_title": "深度强化学习与边缘计算在物联网环境中的实时监控与控制优化融合",
    "translated_abstract": "针对工业物联网环境中对实时性能和控制质量的需求，本文提出了基于深度强化学习和边缘计算的优化控制系统。该系统利用云边协同，部署轻量级策略网络在边缘，预测系统状态，并以高频率输出控制，实现工业目标的监控和优化。此外，设计了动态资源分配机制，以确保边缘计算资源的合理调度，实现全局优化。结果表明，该方法减少了云边通信延迟，加快了对异常情况的响应，降低了系统故障率，延长了设备平均运行时间，并节省了手动维护和更换成本。这确保了实时和稳定的控制。",
    "tldr": "本文提出了一种基于深度强化学习和边缘计算的优化控制系统，通过云边协同和动态资源分配实现工业目标的监控和优化，显著提升了系统性能，并节省了成本。",
    "en_tdlr": "This paper proposes an optimization control system based on deep reinforcement learning and edge computing, which significantly improves system performance and saves costs by leveraging cloud-edge collaboration and dynamic resource allocation for monitoring and optimizing industrial objectives."
}