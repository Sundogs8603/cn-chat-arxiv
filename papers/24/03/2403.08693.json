{
    "title": "Do Language Models Care About Text Quality? Evaluating Web-Crawled Corpora Across 11 Languages",
    "abstract": "arXiv:2403.08693v1 Announce Type: new  Abstract: Large, curated, web-crawled corpora play a vital role in training language models (LMs). They form the lion's share of the training data in virtually all recent LMs, such as the well-known GPT, LLaMA and XLM-RoBERTa models. However, despite this importance, relatively little attention has been given to the quality of these corpora. In this paper, we compare four of the currently most relevant large, web-crawled corpora (CC100, MaCoCu, mC4 and OSCAR) across eleven lower-resourced European languages. Our approach is two-fold: first, we perform an intrinsic evaluation by performing a human evaluation of the quality of samples taken from different corpora; then, we assess the practical impact of the qualitative differences by training specific LMs on each of the corpora and evaluating their performance on downstream tasks. We find that there are clear differences in quality of the corpora, with MaCoCu and OSCAR obtaining the best results. Ho",
    "link": "https://arxiv.org/abs/2403.08693",
    "context": "Title: Do Language Models Care About Text Quality? Evaluating Web-Crawled Corpora Across 11 Languages\nAbstract: arXiv:2403.08693v1 Announce Type: new  Abstract: Large, curated, web-crawled corpora play a vital role in training language models (LMs). They form the lion's share of the training data in virtually all recent LMs, such as the well-known GPT, LLaMA and XLM-RoBERTa models. However, despite this importance, relatively little attention has been given to the quality of these corpora. In this paper, we compare four of the currently most relevant large, web-crawled corpora (CC100, MaCoCu, mC4 and OSCAR) across eleven lower-resourced European languages. Our approach is two-fold: first, we perform an intrinsic evaluation by performing a human evaluation of the quality of samples taken from different corpora; then, we assess the practical impact of the qualitative differences by training specific LMs on each of the corpora and evaluating their performance on downstream tasks. We find that there are clear differences in quality of the corpora, with MaCoCu and OSCAR obtaining the best results. Ho",
    "path": "papers/24/03/2403.08693.json",
    "total_tokens": 896,
    "translated_title": "语言模型在意文本质量吗? 评估跨11种语言的网页抓取语料库",
    "translated_abstract": "大型、策划、网页抓取的语料库在训练语言模型（LMs）中起着至关重要的作用。它们构成了几乎所有最近LMs训练数据的主要部分，如广为人知的GPT、LLaMA和XLM-RoBERTa模型。然而，尽管这一重要性，对这些语料库的质量关注相对较少。在本文中，我们比较了目前最相关的四个大型、网页抓取的语料库（CC100、MaCoCu、mC4和OSCAR）跨11种欧洲低资源语言。我们的方法是双重的：首先，我们通过对来自不同语料库的样本进行人工评估来进行内在评估；然后，我们评估了质量差异的实际影响，通过在每个语料库上训练特定的LMs，并评估它们在下游任务上的表现。我们发现语料库的质量存在明显差异，MaCoCu和OSCAR取得了最佳结果。",
    "tldr": "本文评估了跨11种语言的大型网页抓取语料库的质量差异，并发现MaCoCu和OSCAR的表现最好。",
    "en_tdlr": "This paper evaluates the quality differences of large web-crawled corpora across 11 languages and finds that MaCoCu and OSCAR perform the best."
}