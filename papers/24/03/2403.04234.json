{
    "title": "Fundamental limits of Non-Linear Low-Rank Matrix Estimation",
    "abstract": "arXiv:2403.04234v1 Announce Type: cross  Abstract: We consider the task of estimating a low-rank matrix from non-linear and noisy observations. We prove a strong universality result showing that Bayes-optimal performances are characterized by an equivalent Gaussian model with an effective prior, whose parameters are entirely determined by an expansion of the non-linear function. In particular, we show that to reconstruct the signal accurately, one requires a signal-to-noise ratio growing as $N^{\\frac 12 (1-1/k_F)}$, where $k_F$ is the first non-zero Fisher information coefficient of the function. We provide asymptotic characterization for the minimal achievable mean squared error (MMSE) and an approximate message-passing algorithm that reaches the MMSE under conditions analogous to the linear version of the problem. We also provide asymptotic errors achieved by methods such as principal component analysis combined with Bayesian denoising, and compare them with Bayes-optimal MMSE.",
    "link": "https://arxiv.org/abs/2403.04234",
    "context": "Title: Fundamental limits of Non-Linear Low-Rank Matrix Estimation\nAbstract: arXiv:2403.04234v1 Announce Type: cross  Abstract: We consider the task of estimating a low-rank matrix from non-linear and noisy observations. We prove a strong universality result showing that Bayes-optimal performances are characterized by an equivalent Gaussian model with an effective prior, whose parameters are entirely determined by an expansion of the non-linear function. In particular, we show that to reconstruct the signal accurately, one requires a signal-to-noise ratio growing as $N^{\\frac 12 (1-1/k_F)}$, where $k_F$ is the first non-zero Fisher information coefficient of the function. We provide asymptotic characterization for the minimal achievable mean squared error (MMSE) and an approximate message-passing algorithm that reaches the MMSE under conditions analogous to the linear version of the problem. We also provide asymptotic errors achieved by methods such as principal component analysis combined with Bayesian denoising, and compare them with Bayes-optimal MMSE.",
    "path": "papers/24/03/2403.04234.json",
    "total_tokens": 893,
    "translated_title": "非线性低秩矩阵估计的基本限制",
    "translated_abstract": "我们考虑从非线性和嘈杂观测中估计低秩矩阵的任务。我们证明了一个强大的普适性结果，表明贝叶斯最优表现由一个等效高斯模型和一个有效先验所决定，其参数完全由非线性函数的展开确定。具体而言，我们表明为了准确重构信号，信噪比需要增长为$N^{\\frac 12 (1-1/k_F)}$，其中$k_F$是函数的第一个非零费舍尔信息系数。我们提供了最小可达均方误差（MMSE）的渐近特征化和一种近似传递消息算法，该算法在类似于问题的线性版本的情况下达到了MMSE。我们还提供了通过方法例如主成分分析结合贝叶斯降噪实现的渐近误差，并将它们与贝叶斯最优MMSE进行比较。",
    "tldr": "证明了贝叶斯最优性能由等效高斯模型和有效先验确定，信号重构需要增长的信噪比条件，并提供了针对非线性低秩矩阵估计问题的渐近误差特征化和近似传递消息算法。",
    "en_tdlr": "The paper proves that Bayes-optimal performances are determined by an equivalent Gaussian model with an effective prior, signal reconstruction requires a growth in signal-to-noise ratio, provides asymptotic characterization for minimal achievable mean squared error and an approximate message-passing algorithm for nonlinear low-rank matrix estimation."
}