{
    "title": "Differentially Private Knowledge Distillation via Synthetic Text Generation",
    "abstract": "arXiv:2403.00932v1 Announce Type: cross  Abstract: Large Language models (LLMs) are achieving state-of-the-art performance in many different downstream tasks. However, the increasing urgency of data privacy requires LLMs to train with Differential Privacy (DP) on private data. Concurrently it is also necessary to compress LLMs for real-life deployments on resource-constrained devices or latency-sensitive applications. Differential privacy and model compression generally must trade off utility loss to achieve their objectives. Moreover, concurrently achieving both can result in even more utility loss. To this end, we propose a novel differentially private knowledge distillation algorithm that exploits synthetic data generated by a differentially private LLM. The knowledge of a teacher model is transferred onto the student in two ways: one way from the synthetic data itself, the hard labels, and the other way by the output distribution of the teacher model evaluated on the synthetic data",
    "link": "https://arxiv.org/abs/2403.00932",
    "context": "Title: Differentially Private Knowledge Distillation via Synthetic Text Generation\nAbstract: arXiv:2403.00932v1 Announce Type: cross  Abstract: Large Language models (LLMs) are achieving state-of-the-art performance in many different downstream tasks. However, the increasing urgency of data privacy requires LLMs to train with Differential Privacy (DP) on private data. Concurrently it is also necessary to compress LLMs for real-life deployments on resource-constrained devices or latency-sensitive applications. Differential privacy and model compression generally must trade off utility loss to achieve their objectives. Moreover, concurrently achieving both can result in even more utility loss. To this end, we propose a novel differentially private knowledge distillation algorithm that exploits synthetic data generated by a differentially private LLM. The knowledge of a teacher model is transferred onto the student in two ways: one way from the synthetic data itself, the hard labels, and the other way by the output distribution of the teacher model evaluated on the synthetic data",
    "path": "papers/24/03/2403.00932.json",
    "total_tokens": 781,
    "translated_title": "通过合成文本生成的差分私密知识蒸馏",
    "translated_abstract": "大型语言模型(LLMs)在许多不同的下游任务中实现了最先进的性能。然而，数据隐私的增加紧迫性要求LLMs在私有数据上使用差分隐私(DP)进行训练。同时，还需要压缩LLMs以在资源受限的设备或延迟敏感的应用中进行真实部署。差分隐私和模型压缩通常必须在实现其目标的过程中权衡效用损失。此外，同时实现这两者可能导致更多的效用损失。为此，我们提出了一种新颖的差分私密知识蒸馏算法，该算法利用了由差分私密LLM生成的合成数据。教师模型的知识以两种方式转移到学生模型上：一种是来自合成数据本身的硬标签，另一种是通过在合成数据上评估的教师模型的输出分布。",
    "tldr": "提出一种利用合成数据进行知识蒸馏的差分私密算法",
    "en_tdlr": "A differentially private knowledge distillation algorithm is proposed that utilizes synthetic data for knowledge distillation."
}