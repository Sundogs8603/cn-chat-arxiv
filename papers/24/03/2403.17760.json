{
    "title": "Constructions Are So Difficult That Even Large Language Models Get Them Right for the Wrong Reasons",
    "abstract": "arXiv:2403.17760v1 Announce Type: new  Abstract: In this paper, we make a contribution that can be understood from two perspectives: from an NLP perspective, we introduce a small challenge dataset for NLI with large lexical overlap, which minimises the possibility of models discerning entailment solely based on token distinctions, and show that GPT-4 and Llama 2 fail it with strong bias. We then create further challenging sub-tasks in an effort to explain this failure. From a Computational Linguistics perspective, we identify a group of constructions with three classes of adjectives which cannot be distinguished by surface features. This enables us to probe for LLM's understanding of these constructions in various ways, and we find that they fail in a variety of ways to distinguish between them, suggesting that they don't adequately represent their meaning or capture the lexical properties of phrasal heads.",
    "link": "https://arxiv.org/abs/2403.17760",
    "context": "Title: Constructions Are So Difficult That Even Large Language Models Get Them Right for the Wrong Reasons\nAbstract: arXiv:2403.17760v1 Announce Type: new  Abstract: In this paper, we make a contribution that can be understood from two perspectives: from an NLP perspective, we introduce a small challenge dataset for NLI with large lexical overlap, which minimises the possibility of models discerning entailment solely based on token distinctions, and show that GPT-4 and Llama 2 fail it with strong bias. We then create further challenging sub-tasks in an effort to explain this failure. From a Computational Linguistics perspective, we identify a group of constructions with three classes of adjectives which cannot be distinguished by surface features. This enables us to probe for LLM's understanding of these constructions in various ways, and we find that they fail in a variety of ways to distinguish between them, suggesting that they don't adequately represent their meaning or capture the lexical properties of phrasal heads.",
    "path": "papers/24/03/2403.17760.json",
    "total_tokens": 843,
    "translated_title": "施工如此困难，以至于即使大型语言模型也因错误原因而正确",
    "translated_abstract": "在本文中，我们做出了两方面理解的贡献：从自然语言处理的角度看，我们引入了一个具有大量词汇重叠的NLI挑战数据集，最大程度地减少了模型仅基于标记区别来区分蕴涵的可能性，并展示了GPT-4和Llama 2以强烈的偏见失败。然后，我们进一步创建了具有挑战性的子任务，以解释这种失败。从计算语言学的角度看，我们确定了一个包含三类形容词的结构组，这些形容词无法通过表面特征来区分。这使我们能够以各种方式探究LLM对这些结构的理解，并发现它们在各种方式上都无法区分它们，表明它们不足以代表它们的含义或捕捉短语头的词汇属性。",
    "tldr": "本文引入了一个具有大量词汇重叠的NLI挑战数据集，探讨了大型语言模型在处理特定结构时出现的失败现象，揭示了它们在区分特定结构时的不足之处。",
    "en_tdlr": "This paper introduces a challenging NLI dataset with large lexical overlap, investigates the failures of large language models when dealing with specific structures, and reveals their shortcomings in distinguishing between these structures."
}