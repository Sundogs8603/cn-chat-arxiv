{
    "title": "Learning to Find Missing Video Frames with Synthetic Data Augmentation: A General Framework and Application in Generating Thermal Images Using RGB Cameras",
    "abstract": "arXiv:2403.00196v1 Announce Type: cross  Abstract: Advanced Driver Assistance Systems (ADAS) in intelligent vehicles rely on accurate driver perception within the vehicle cabin, often leveraging a combination of sensing modalities. However, these modalities operate at varying rates, posing challenges for real-time, comprehensive driver state monitoring. This paper addresses the issue of missing data due to sensor frame rate mismatches, introducing a generative model approach to create synthetic yet realistic thermal imagery. We propose using conditional generative adversarial networks (cGANs), specifically comparing the pix2pix and CycleGAN architectures. Experimental results demonstrate that pix2pix outperforms CycleGAN, and utilizing multi-view input styles, especially stacked views, enhances the accuracy of thermal image generation. Moreover, the study evaluates the model's generalizability across different subjects, revealing the importance of individualized training for optimal pe",
    "link": "https://arxiv.org/abs/2403.00196",
    "context": "Title: Learning to Find Missing Video Frames with Synthetic Data Augmentation: A General Framework and Application in Generating Thermal Images Using RGB Cameras\nAbstract: arXiv:2403.00196v1 Announce Type: cross  Abstract: Advanced Driver Assistance Systems (ADAS) in intelligent vehicles rely on accurate driver perception within the vehicle cabin, often leveraging a combination of sensing modalities. However, these modalities operate at varying rates, posing challenges for real-time, comprehensive driver state monitoring. This paper addresses the issue of missing data due to sensor frame rate mismatches, introducing a generative model approach to create synthetic yet realistic thermal imagery. We propose using conditional generative adversarial networks (cGANs), specifically comparing the pix2pix and CycleGAN architectures. Experimental results demonstrate that pix2pix outperforms CycleGAN, and utilizing multi-view input styles, especially stacked views, enhances the accuracy of thermal image generation. Moreover, the study evaluates the model's generalizability across different subjects, revealing the importance of individualized training for optimal pe",
    "path": "papers/24/03/2403.00196.json",
    "total_tokens": 940,
    "translated_title": "利用合成数据增强学习找到缺失视频帧：一个通用框架及在使用RGB摄像头生成热成像中的应用",
    "translated_abstract": "高级驾驶辅助系统（ADAS）在智能车辆中依赖于车辆车厢内的准确驾驶员感知，通常利用各种传感模式的结合。然而，这些模式以不同的速率操作，对于实时、全面的驾驶员状态监测提出了挑战。本文解决了由于传感器帧率不匹配导致数据缺失的问题，引入了一种生成模型方法来创建合成但逼真的热成像。我们提出使用有条件的生成对抗网络（cGANs），具体比较了pix2pix和CycleGAN架构。实验结果表明pix2pix优于CycleGAN，并且利用多视角输入风格，特别是堆叠视图，增强了热图像生成的准确性。此外，该研究评估了模型在不同主体之间的泛化能力，揭示了个性化训练对于最佳性能的重要性。",
    "tldr": "通过引入生成模型的方法解决了由于传感器帧率不匹配而导致数据缺失的问题，利用有条件的生成对抗网络（cGANs）中的pix2pix架构比CycleGAN表现更好，多视角输入风格特别是堆叠视图可以增强热图像生成的准确性",
    "en_tdlr": "The paper introduces a generative model approach to address missing data due to sensor frame rate mismatches, showcasing the superiority of using the pix2pix architecture within conditional generative adversarial networks (cGANs) over CycleGAN. Utilizing multi-view input styles, especially stacked views, enhances the accuracy of thermal image generation."
}