{
    "title": "Neuron-centric Hebbian Learning",
    "abstract": "arXiv:2403.12076v1 Announce Type: cross  Abstract: One of the most striking capabilities behind the learning mechanisms of the brain is the adaptation, through structural and functional plasticity, of its synapses. While synapses have the fundamental role of transmitting information across the brain, several studies show that it is the neuron activations that produce changes on synapses. Yet, most plasticity models devised for artificial Neural Networks (NNs), e.g., the ABCD rule, focus on synapses, rather than neurons, therefore optimizing synaptic-specific Hebbian parameters. This approach, however, increases the complexity of the optimization process since each synapse is associated to multiple Hebbian parameters. To overcome this limitation, we propose a novel plasticity model, called Neuron-centric Hebbian Learning (NcHL), where optimization focuses on neuron- rather than synaptic-specific Hebbian parameters. Compared to the ABCD rule, NcHL reduces the parameters from $5W$ to $5N$",
    "link": "https://arxiv.org/abs/2403.12076",
    "context": "Title: Neuron-centric Hebbian Learning\nAbstract: arXiv:2403.12076v1 Announce Type: cross  Abstract: One of the most striking capabilities behind the learning mechanisms of the brain is the adaptation, through structural and functional plasticity, of its synapses. While synapses have the fundamental role of transmitting information across the brain, several studies show that it is the neuron activations that produce changes on synapses. Yet, most plasticity models devised for artificial Neural Networks (NNs), e.g., the ABCD rule, focus on synapses, rather than neurons, therefore optimizing synaptic-specific Hebbian parameters. This approach, however, increases the complexity of the optimization process since each synapse is associated to multiple Hebbian parameters. To overcome this limitation, we propose a novel plasticity model, called Neuron-centric Hebbian Learning (NcHL), where optimization focuses on neuron- rather than synaptic-specific Hebbian parameters. Compared to the ABCD rule, NcHL reduces the parameters from $5W$ to $5N$",
    "path": "papers/24/03/2403.12076.json",
    "total_tokens": 851,
    "translated_title": "神经元中心的赫布学习",
    "translated_abstract": "大脑学习机制背后最引人注目的能力之一是通过结构和功能可塑性调整其突触。尽管突触在传递信息到整个大脑中起着基本作用，但几项研究表明，是神经元的激活产生了对突触的改变。然而，大多数为人工神经网络（NNs）设计的可塑性模型，如ABCD规则，侧重于突触而不是神经元，因此优化突触特定的赫布参数。然而，这种方法增加了优化过程的复杂性，因为每个突触都与多个赫布参数相关联。为了克服这一限制，我们提出了一种新颖的可塑性模型，称为神经元中心的赫布学习（NcHL），其优化侧重于神经元而不是突触特定的赫布参数。与ABCD规则相比，NcHL将参数减少从$5W$到$5N$。",
    "tldr": "提出了一种新的神经元中心的赫布学习模型，相较于传统的ABCD规则，将参数减少了从$5W$到$5N$。",
    "en_tdlr": "Introduced a novel Neuron-centric Hebbian Learning model that reduces the parameters from $5W$ to $5N compared to the traditional ABCD rule."
}