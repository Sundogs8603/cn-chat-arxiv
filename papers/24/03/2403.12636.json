{
    "title": "A Practical Guide to Statistical Distances for Evaluating Generative Models in Science",
    "abstract": "arXiv:2403.12636v1 Announce Type: new  Abstract: Generative models are invaluable in many fields of science because of their ability to capture high-dimensional and complicated distributions, such as photo-realistic images, protein structures, and connectomes. How do we evaluate the samples these models generate? This work aims to provide an accessible entry point to understanding popular notions of statistical distances, requiring only foundational knowledge in mathematics and statistics. We focus on four commonly used notions of statistical distances representing different methodologies: Using low-dimensional projections (Sliced-Wasserstein; SW), obtaining a distance using classifiers (Classifier Two-Sample Tests; C2ST), using embeddings through kernels (Maximum Mean Discrepancy; MMD), or neural networks (Fr\\'echet Inception Distance; FID). We highlight the intuition behind each distance and explain their merits, scalability, complexity, and pitfalls. To demonstrate how these distanc",
    "link": "https://arxiv.org/abs/2403.12636",
    "context": "Title: A Practical Guide to Statistical Distances for Evaluating Generative Models in Science\nAbstract: arXiv:2403.12636v1 Announce Type: new  Abstract: Generative models are invaluable in many fields of science because of their ability to capture high-dimensional and complicated distributions, such as photo-realistic images, protein structures, and connectomes. How do we evaluate the samples these models generate? This work aims to provide an accessible entry point to understanding popular notions of statistical distances, requiring only foundational knowledge in mathematics and statistics. We focus on four commonly used notions of statistical distances representing different methodologies: Using low-dimensional projections (Sliced-Wasserstein; SW), obtaining a distance using classifiers (Classifier Two-Sample Tests; C2ST), using embeddings through kernels (Maximum Mean Discrepancy; MMD), or neural networks (Fr\\'echet Inception Distance; FID). We highlight the intuition behind each distance and explain their merits, scalability, complexity, and pitfalls. To demonstrate how these distanc",
    "path": "papers/24/03/2403.12636.json",
    "total_tokens": 813,
    "translated_title": "用于科学中评估生成模型的统计距离的实用指南",
    "translated_abstract": "生成模型在许多科学领域中是非常宝贵的，因为它们能够捕捉高维和复杂的分布，例如逼真的图像、蛋白质结构和连接组。本研究旨在为理解流行的统计距离概念提供一个易于理解的入口点，只需要数学和统计学的基础知识。我们专注于代表不同方法论的四种常用统计距离概念：使用低维投影（Sliced-Wasserstein; SW)、使用分类器获取距离（Classifier Two-Sample Tests; C2ST)、通过核进行嵌入（Maximum Mean Discrepancy; MMD) 或神经网络（Fr\\'echet Inception Distance; FID)。我们强调每个距离背后的直觉，并解释它们的优点、可伸缩性、复杂性和缺陷。",
    "tldr": "本文提供了一种实用指南，介绍了四种常用统计距离的概念，以帮助评估生成模型，无需高深的数学和统计知识。"
}