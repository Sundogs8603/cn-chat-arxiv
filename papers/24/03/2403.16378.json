{
    "title": "Play to Your Strengths: Collaborative Intelligence of Conventional Recommender Models and Large Language Models",
    "abstract": "arXiv:2403.16378v1 Announce Type: new  Abstract: The rise of large language models (LLMs) has opened new opportunities in Recommender Systems (RSs) by enhancing user behavior modeling and content understanding. However, current approaches that integrate LLMs into RSs solely utilize either LLM or conventional recommender model (CRM) to generate final recommendations, without considering which data segments LLM or CRM excel in. To fill in this gap, we conduct experiments on MovieLens-1M and Amazon-Books datasets, and compare the performance of a representative CRM (DCNv2) and an LLM (LLaMA2-7B) on various groups of data samples. Our findings reveal that LLMs excel in data segments where CRMs exhibit lower confidence and precision, while samples where CRM excels are relatively challenging for LLM, requiring substantial training data and a long training time for comparable performance. This suggests potential synergies in the combination between LLM and CRM. Motivated by these insights, we",
    "link": "https://arxiv.org/abs/2403.16378",
    "context": "Title: Play to Your Strengths: Collaborative Intelligence of Conventional Recommender Models and Large Language Models\nAbstract: arXiv:2403.16378v1 Announce Type: new  Abstract: The rise of large language models (LLMs) has opened new opportunities in Recommender Systems (RSs) by enhancing user behavior modeling and content understanding. However, current approaches that integrate LLMs into RSs solely utilize either LLM or conventional recommender model (CRM) to generate final recommendations, without considering which data segments LLM or CRM excel in. To fill in this gap, we conduct experiments on MovieLens-1M and Amazon-Books datasets, and compare the performance of a representative CRM (DCNv2) and an LLM (LLaMA2-7B) on various groups of data samples. Our findings reveal that LLMs excel in data segments where CRMs exhibit lower confidence and precision, while samples where CRM excels are relatively challenging for LLM, requiring substantial training data and a long training time for comparable performance. This suggests potential synergies in the combination between LLM and CRM. Motivated by these insights, we",
    "path": "papers/24/03/2403.16378.json",
    "total_tokens": 910,
    "translated_title": "利用各自优势：传统推荐模型和大型语言模型的协作智能",
    "translated_abstract": "大型语言模型（LLMs）的崛起为推荐系统（RSs）带来了新的机遇，通过增强用户行为建模和内容理解。然而，当前将LLMs整合到RSs的方法仅仅利用LLM或传统推荐模型(CRM)来生成最终推荐，而没有考虑LLM或CRM在哪些数据段表现优秀。为了填补这一空白，我们在MovieLens-1M和Amazon-Books数据集上进行了实验，比较了代表性CRM（DCNv2）和一个LLM（LLaMA2-7B）在各种数据样本组上的性能。我们发现LLMs在CRM表现信心和精确性较低的数据段表现优异，而CRM表现优异的样本对LLM而言相对具有挑战性，需要大量训练数据和较长的训练时间才能获得可比较的性能。这表明LLM和CRM之间存在潜在的协同作用。受到这些见解的启发，我们...",
    "tldr": "LLMs在CRM表现信心和精确性较低的数据段表现优异，而CRM表现优异的样本对LLM而言相对具有挑战性，这表明LLM和CRM之间存在潜在的协同作用。",
    "en_tdlr": "LLMs excel in data segments where CRMs exhibit lower confidence and precision, while samples where CRM excels are relatively challenging for LLM, suggesting potential synergies in the combination between LLM and CRM."
}