{
    "title": "How Reliable is Your Simulator? Analysis on the Limitations of Current LLM-based User Simulators for Conversational Recommendation",
    "abstract": "arXiv:2403.16416v1 Announce Type: new  Abstract: Conversational Recommender System (CRS) interacts with users through natural language to understand their preferences and provide personalized recommendations in real-time. CRS has demonstrated significant potential, prompting researchers to address the development of more realistic and reliable user simulators as a key focus. Recently, the capabilities of Large Language Models (LLMs) have attracted a lot of attention in various fields. Simultaneously, efforts are underway to construct user simulators based on LLMs. While these works showcase innovation, they also come with certain limitations that require attention. In this work, we aim to analyze the limitations of using LLMs in constructing user simulators for CRS, to guide future research. To achieve this goal, we conduct analytical validation on the notable work, iEvaLM. Through multiple experiments on two widely-used datasets in the field of conversational recommendation, we highli",
    "link": "https://arxiv.org/abs/2403.16416",
    "context": "Title: How Reliable is Your Simulator? Analysis on the Limitations of Current LLM-based User Simulators for Conversational Recommendation\nAbstract: arXiv:2403.16416v1 Announce Type: new  Abstract: Conversational Recommender System (CRS) interacts with users through natural language to understand their preferences and provide personalized recommendations in real-time. CRS has demonstrated significant potential, prompting researchers to address the development of more realistic and reliable user simulators as a key focus. Recently, the capabilities of Large Language Models (LLMs) have attracted a lot of attention in various fields. Simultaneously, efforts are underway to construct user simulators based on LLMs. While these works showcase innovation, they also come with certain limitations that require attention. In this work, we aim to analyze the limitations of using LLMs in constructing user simulators for CRS, to guide future research. To achieve this goal, we conduct analytical validation on the notable work, iEvaLM. Through multiple experiments on two widely-used datasets in the field of conversational recommendation, we highli",
    "path": "papers/24/03/2403.16416.json",
    "total_tokens": 844,
    "translated_title": "您的模拟器有多可靠? 对当前基于LLM的用户对话推荐系统模拟器局限性的分析",
    "translated_abstract": "arXiv:2403.16416v1 公告类型: 新 抽象: 对话推荐系统（CRS）通过自然语言与用户交互，了解他们的偏好并实时提供个性化推荐。CRS已展示出显著潜力，促使研究人员将发展更现实和可靠的用户模拟器作为重点。最近，大型语言模型（LLMs）的能力在各个领域受到了广泛关注。与此同时，正在努力基于LLMs构建用户模拟器。虽然这些工作展现了创新，但也存在一定的局限性需要关注。在这项工作中，我们旨在分析使用LLMs构建CRS用户模拟器的局限性，以指导未来研究。为实现这一目标，我们对知名工作iEvaLM进行了分析验证。通过在对话推荐领域中两个广泛使用的数据集上进行多次实验，我们突显了",
    "tldr": "通过对LLMs构建CRS用户模拟器的局限性进行分析，为指导未来研究提供了重要见解。"
}