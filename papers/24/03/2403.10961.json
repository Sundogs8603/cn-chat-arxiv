{
    "title": "Energy-Based Models with Applications to Speech and Language Processing",
    "abstract": "arXiv:2403.10961v1 Announce Type: cross  Abstract: Energy-Based Models (EBMs) are an important class of probabilistic models, also known as random fields and undirected graphical models. EBMs are un-normalized and thus radically different from other popular self-normalized probabilistic models such as hidden Markov models (HMMs), autoregressive models, generative adversarial nets (GANs) and variational auto-encoders (VAEs). Over the past years, EBMs have attracted increasing interest not only from the core machine learning community, but also from application domains such as speech, vision, natural language processing (NLP) and so on, due to significant theoretical and algorithmic progress. The sequential nature of speech and language also presents special challenges and needs a different treatment from processing fix-dimensional data (e.g., images). Therefore, the purpose of this monograph is to present a systematic introduction to energy-based models, including both algorithmic progr",
    "link": "https://arxiv.org/abs/2403.10961",
    "context": "Title: Energy-Based Models with Applications to Speech and Language Processing\nAbstract: arXiv:2403.10961v1 Announce Type: cross  Abstract: Energy-Based Models (EBMs) are an important class of probabilistic models, also known as random fields and undirected graphical models. EBMs are un-normalized and thus radically different from other popular self-normalized probabilistic models such as hidden Markov models (HMMs), autoregressive models, generative adversarial nets (GANs) and variational auto-encoders (VAEs). Over the past years, EBMs have attracted increasing interest not only from the core machine learning community, but also from application domains such as speech, vision, natural language processing (NLP) and so on, due to significant theoretical and algorithmic progress. The sequential nature of speech and language also presents special challenges and needs a different treatment from processing fix-dimensional data (e.g., images). Therefore, the purpose of this monograph is to present a systematic introduction to energy-based models, including both algorithmic progr",
    "path": "papers/24/03/2403.10961.json",
    "total_tokens": 852,
    "translated_title": "基于能量的模型及其在语音和语言处理中的应用",
    "translated_abstract": "基于能量的模型（EBMs）是一类重要的概率模型，也称为随机场和无向图模型。EBMs是非规范化的，因此与其他流行的自归一化概率模型（如隐马尔可夫模型（HMMs）、自回归模型、生成对抗网络（GANs）和变分自编码器（VAEs））有根本的不同。近年来，由于重要的理论和算法进展，EBMs不仅吸引了核心机器学习社区的越来越多关注，还吸引了应用领域（如语音、视觉、自然语言处理（NLP）等）的兴趣。语音和语言的顺序性质也提供了特殊挑战，需要与处理固定维度数据（例如图像）有所不同的处理方法。因此，本专著旨在系统介绍基于能量的模型，包括算法进展。",
    "tldr": "基于能量的模型（EBMs）是一类重要的概率模型，在语音和语言处理等领域吸引了越来越多的关注，因其显著的理论和算法进展。",
    "en_tdlr": "Energy-Based Models (EBMs) are an important class of probabilistic models that have attracted increasing interest in areas such as speech and language processing due to significant theoretical and algorithmic progress."
}