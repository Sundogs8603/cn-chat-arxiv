{
    "title": "Towards a World-English Language Model for On-Device Virtual Assistants",
    "abstract": "arXiv:2403.18783v1 Announce Type: new  Abstract: Neural Network Language Models (NNLMs) for Virtual Assistants (VAs) are generally language-, region-, and in some cases, device-dependent, which increases the effort to scale and maintain them. Combining NNLMs for one or more of the categories is one way to improve scalability. In this work, we combine regional variants of English to build a ``World English'' NNLM for on-device VAs. In particular, we investigate the application of adapter bottlenecks to model dialect-specific characteristics in our existing production NNLMs {and enhance the multi-dialect baselines}. We find that adapter modules are more effective in modeling dialects than specializing entire sub-networks. Based on this insight and leveraging the design of our production models, we introduce a new architecture for World English NNLM that meets the accuracy, latency, and memory constraints of our single-dialect models.",
    "link": "https://arxiv.org/abs/2403.18783",
    "context": "Title: Towards a World-English Language Model for On-Device Virtual Assistants\nAbstract: arXiv:2403.18783v1 Announce Type: new  Abstract: Neural Network Language Models (NNLMs) for Virtual Assistants (VAs) are generally language-, region-, and in some cases, device-dependent, which increases the effort to scale and maintain them. Combining NNLMs for one or more of the categories is one way to improve scalability. In this work, we combine regional variants of English to build a ``World English'' NNLM for on-device VAs. In particular, we investigate the application of adapter bottlenecks to model dialect-specific characteristics in our existing production NNLMs {and enhance the multi-dialect baselines}. We find that adapter modules are more effective in modeling dialects than specializing entire sub-networks. Based on this insight and leveraging the design of our production models, we introduce a new architecture for World English NNLM that meets the accuracy, latency, and memory constraints of our single-dialect models.",
    "path": "papers/24/03/2403.18783.json",
    "total_tokens": 886,
    "translated_title": "为设备上的虚拟助手打造世界英语语言模型",
    "translated_abstract": "虚拟助手（VAs）的神经网络语言模型（NNLMs）通常是基于语言、地区，有时甚至还有设备的依赖性，这增加了扩展和维护的工作量。将NNLMs组合用于一个或多个类别是改善扩展性的一种方式。在这项工作中，我们结合区域性英语变体构建了一个“世界英语”NNLM，用于设备上的VAs。特别是，我们研究了适配器瓶颈的应用，以模拟我们现有生产NNLMS中的特定方言特征{并增强多方言基线}。我们发现适配器模块在模拟方言方面比专门化整个子网络更有效。基于这一见解，并利用我们生产模型的设计，我们介绍了一个新的世界英语NNLM架构，符合我们单方言模型的准确性、延迟和内存约束。",
    "tldr": "该论文提出了为设备上的虚拟助手打造世界英语语言模型的方法，通过结合英语的区域变体，采用适配器瓶颈来模拟特定方言特征，实现了准确性、延迟和内存方面的性能平衡。",
    "en_tdlr": "This paper presents a method for creating a World English language model for on-device virtual assistants, utilizing adapter bottlenecks to simulate dialect-specific characteristics and achieving a balance between accuracy, latency, and memory constraints."
}