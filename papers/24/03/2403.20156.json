{
    "title": "CAESAR: Enhancing Federated RL in Heterogeneous MDPs through Convergence-Aware Sampling with Screening",
    "abstract": "arXiv:2403.20156v1 Announce Type: cross  Abstract: In this study, we delve into Federated Reinforcement Learning (FedRL) in the context of value-based agents operating across diverse Markov Decision Processes (MDPs). Existing FedRL methods typically aggregate agents' learning by averaging the value functions across them to improve their performance. However, this aggregation strategy is suboptimal in heterogeneous environments where agents converge to diverse optimal value functions. To address this problem, we introduce the Convergence-AwarE SAmpling with scReening (CAESAR) aggregation scheme designed to enhance the learning of individual agents across varied MDPs. CAESAR is an aggregation strategy used by the server that combines convergence-aware sampling with a screening mechanism. By exploiting the fact that agents learning in identical MDPs are converging to the same optimal value function, CAESAR enables the selective assimilation of knowledge from more proficient counterparts, ",
    "link": "https://arxiv.org/abs/2403.20156",
    "context": "Title: CAESAR: Enhancing Federated RL in Heterogeneous MDPs through Convergence-Aware Sampling with Screening\nAbstract: arXiv:2403.20156v1 Announce Type: cross  Abstract: In this study, we delve into Federated Reinforcement Learning (FedRL) in the context of value-based agents operating across diverse Markov Decision Processes (MDPs). Existing FedRL methods typically aggregate agents' learning by averaging the value functions across them to improve their performance. However, this aggregation strategy is suboptimal in heterogeneous environments where agents converge to diverse optimal value functions. To address this problem, we introduce the Convergence-AwarE SAmpling with scReening (CAESAR) aggregation scheme designed to enhance the learning of individual agents across varied MDPs. CAESAR is an aggregation strategy used by the server that combines convergence-aware sampling with a screening mechanism. By exploiting the fact that agents learning in identical MDPs are converging to the same optimal value function, CAESAR enables the selective assimilation of knowledge from more proficient counterparts, ",
    "path": "papers/24/03/2403.20156.json",
    "total_tokens": 833,
    "translated_title": "在异构MDPs中通过收敛感知采样与筛选增强联邦强化学习的CAESAR算法",
    "translated_abstract": "本研究探讨了在值为基础代理在不同马尔可夫决策过程（MDPs）之间运行时的联邦强化学习（FedRL）。现有的FedRL方法通常通过对代理的值函数进行平均来改善它们的表现。然而，在异构环境中，这种聚合策略在代理收敛到不同的最优值函数时是次优的。为了解决这个问题，我们引入了设计用于增强个体代理跨各种MDPs学习的Convergence-AwarE SAmpling with scReening（CAESAR）聚合方案。CAESAR是服务器使用的一种聚合策略，结合了收敛感知采样和筛选机制。通过利用学习相同MDP中代理收敛到相同最优值函数的事实，CAESAR使得能够从更熟练的同行那里有选择地吸收知识。",
    "tldr": "CAESAR算法通过结合收敛感知采样和筛选机制，有效增强了个体代理在不同MDPs上的学习。",
    "en_tdlr": "CAESAR algorithm enhances individual agents' learning across different MDPs by combining convergence-aware sampling with a screening mechanism."
}