{
    "title": "Leveraging Counterfactual Paths for Contrastive Explanations of POMDP Policies",
    "abstract": "arXiv:2403.19760v1 Announce Type: new  Abstract: As humans come to rely on autonomous systems more, ensuring the transparency of such systems is important to their continued adoption. Explainable Artificial Intelligence (XAI) aims to reduce confusion and foster trust in systems by providing explanations of agent behavior. Partially observable Markov decision processes (POMDPs) provide a flexible framework capable of reasoning over transition and state uncertainty, while also being amenable to explanation. This work investigates the use of user-provided counterfactuals to generate contrastive explanations of POMDP policies. Feature expectations are used as a means of contrasting the performance of these policies. We demonstrate our approach in a Search and Rescue (SAR) setting. We analyze and discuss the associated challenges through two case studies.",
    "link": "https://arxiv.org/abs/2403.19760",
    "context": "Title: Leveraging Counterfactual Paths for Contrastive Explanations of POMDP Policies\nAbstract: arXiv:2403.19760v1 Announce Type: new  Abstract: As humans come to rely on autonomous systems more, ensuring the transparency of such systems is important to their continued adoption. Explainable Artificial Intelligence (XAI) aims to reduce confusion and foster trust in systems by providing explanations of agent behavior. Partially observable Markov decision processes (POMDPs) provide a flexible framework capable of reasoning over transition and state uncertainty, while also being amenable to explanation. This work investigates the use of user-provided counterfactuals to generate contrastive explanations of POMDP policies. Feature expectations are used as a means of contrasting the performance of these policies. We demonstrate our approach in a Search and Rescue (SAR) setting. We analyze and discuss the associated challenges through two case studies.",
    "path": "papers/24/03/2403.19760.json",
    "total_tokens": 811,
    "translated_title": "利用反事实路径解释POMDP策略的对照性",
    "translated_abstract": "随着人类越来越依赖自主系统，确保这些系统的透明性对于它们持续被采纳而言至关重要。可解释人工智能（XAI）旨在通过提供对代理行为的解释来减少困惑，培养人们对系统的信任。部分可观察马尔可夫决策过程（POMDPs）提供了一个能够推理转变和状态不确定性的灵活框架，同时也适合解释。这项工作研究了使用用户提供的反事实来生成POMDP策略的对照性解释。特征期望被用作对比这些策略的性能的手段。我们在搜索与救援（SAR）环境中演示了我们的方法。通过两个案例研究，我们分析和讨论了相关的挑战。",
    "tldr": "本研究利用用户提供的反事实路径来生成对照性解释POMDP策略，并通过分析Search and Rescue（SAR）环境中的案例研究来讨论与之相关的挑战。",
    "en_tdlr": "This study leverages user-provided counterfactual paths to generate contrastive explanations of POMDP policies and discusses the associated challenges through case studies in a Search and Rescue (SAR) setting."
}