{
    "title": "Word Importance Explains How Prompts Affect Language Model Outputs",
    "abstract": "arXiv:2403.03028v1 Announce Type: new  Abstract: The emergence of large language models (LLMs) has revolutionized numerous applications across industries. However, their \"black box\" nature often hinders the understanding of how they make specific decisions, raising concerns about their transparency, reliability, and ethical use. This study presents a method to improve the explainability of LLMs by varying individual words in prompts to uncover their statistical impact on the model outputs. This approach, inspired by permutation importance for tabular data, masks each word in the system prompt and evaluates its effect on the outputs based on the available text scores aggregated over multiple user inputs. Unlike classical attention, word importance measures the impact of prompt words on arbitrarily-defined text scores, which enables decomposing the importance of words into the specific measures of interest--including bias, reading level, verbosity, etc. This procedure also enables measur",
    "link": "https://arxiv.org/abs/2403.03028",
    "context": "Title: Word Importance Explains How Prompts Affect Language Model Outputs\nAbstract: arXiv:2403.03028v1 Announce Type: new  Abstract: The emergence of large language models (LLMs) has revolutionized numerous applications across industries. However, their \"black box\" nature often hinders the understanding of how they make specific decisions, raising concerns about their transparency, reliability, and ethical use. This study presents a method to improve the explainability of LLMs by varying individual words in prompts to uncover their statistical impact on the model outputs. This approach, inspired by permutation importance for tabular data, masks each word in the system prompt and evaluates its effect on the outputs based on the available text scores aggregated over multiple user inputs. Unlike classical attention, word importance measures the impact of prompt words on arbitrarily-defined text scores, which enables decomposing the importance of words into the specific measures of interest--including bias, reading level, verbosity, etc. This procedure also enables measur",
    "path": "papers/24/03/2403.03028.json",
    "total_tokens": 845,
    "translated_title": "单词重要性解释了提示如何影响语言模型输出",
    "translated_abstract": "大型语言模型（LLMs）的出现彻底改变了各行各业的许多应用。然而，它们的“黑盒”性质常常阻碍了我们对其如何做出具体决策的理解，引发了人们对其透明性、可靠性和道德使用的担忧。本研究提出了一种方法，通过改变提示中的单词来提高LLMs的可解释性，以揭示其在模型输出上的统计影响。该方法受表格数据的排列重要性启发，屏蔽系统提示中的每个单词，并根据可用文本分数在多个用户输入上进行聚合来评估其对输出的影响。与传统注意力不同，单词重要性衡量提示中单词对任意定义的文本分数的影响，从而能够将单词的重要性分解为具体的感兴趣的度量-- 包括偏见、阅读水平、冗余等。此程序还使测量",
    "tldr": "通过改变提示中的单词，本研究提出了一种方法来解释大型语言模型（LLMs）的工作原理，从而揭示其对模型输出的影响。"
}