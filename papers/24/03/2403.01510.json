{
    "title": "End-to-End Human Instance Matting",
    "abstract": "arXiv:2403.01510v1 Announce Type: cross  Abstract: Human instance matting aims to estimate an alpha matte for each human instance in an image, which is extremely challenging and has rarely been studied so far. Despite some efforts to use instance segmentation to generate a trimap for each instance and apply trimap-based matting methods, the resulting alpha mattes are often inaccurate due to inaccurate segmentation. In addition, this approach is computationally inefficient due to multiple executions of the matting method. To address these problems, this paper proposes a novel End-to-End Human Instance Matting (E2E-HIM) framework for simultaneous multiple instance matting in a more efficient manner. Specifically, a general perception network first extracts image features and decodes instance contexts into latent codes. Then, a united guidance network exploits spatial attention and semantics embedding to generate united semantics guidance, which encodes the locations and semantic correspo",
    "link": "https://arxiv.org/abs/2403.01510",
    "context": "Title: End-to-End Human Instance Matting\nAbstract: arXiv:2403.01510v1 Announce Type: cross  Abstract: Human instance matting aims to estimate an alpha matte for each human instance in an image, which is extremely challenging and has rarely been studied so far. Despite some efforts to use instance segmentation to generate a trimap for each instance and apply trimap-based matting methods, the resulting alpha mattes are often inaccurate due to inaccurate segmentation. In addition, this approach is computationally inefficient due to multiple executions of the matting method. To address these problems, this paper proposes a novel End-to-End Human Instance Matting (E2E-HIM) framework for simultaneous multiple instance matting in a more efficient manner. Specifically, a general perception network first extracts image features and decodes instance contexts into latent codes. Then, a united guidance network exploits spatial attention and semantics embedding to generate united semantics guidance, which encodes the locations and semantic correspo",
    "path": "papers/24/03/2403.01510.json",
    "total_tokens": 705,
    "translated_title": "一种端到端的人体实例抠图方法",
    "translated_abstract": "人体实例抠图旨在为图像中的每个人体实例估计一个alpha深度图，这是极具挑战性的，目前很少有研究。本文提出了一种新颖的端到端人体实例抠图（E2E-HIM）框架，以更高效的方式同时进行多个实例的抠图。具体来说，一个通用感知网络首先提取图像特征并将实例上下文解码为潜在编码。然后，一个统一引导网络利用空间注意力和语义嵌入生成统一的语义引导，其中编码了位置和语义对应关系。",
    "tldr": "提出了一种端到端的人体实例抠图框架，通过通用感知网络和统一引导网络实现高效的多实例抠图。",
    "en_tdlr": "Propose an end-to-end human instance matting framework for efficient multiple instance matting using a general perception network and a united guidance network."
}