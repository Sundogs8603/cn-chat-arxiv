{
    "title": "Don't Blame the Data, Blame the Model: Understanding Noise and Bias When Learning from Subjective Annotations",
    "abstract": "arXiv:2403.04085v1 Announce Type: new  Abstract: Researchers have raised awareness about the harms of aggregating labels especially in subjective tasks that naturally contain disagreements among human annotators. In this work we show that models that are only provided aggregated labels show low confidence on high-disagreement data instances. While previous studies consider such instances as mislabeled, we argue that the reason the high-disagreement text instances have been hard-to-learn is that the conventional aggregated models underperform in extracting useful signals from subjective tasks. Inspired by recent studies demonstrating the effectiveness of learning from raw annotations, we investigate classifying using Multiple Ground Truth (Multi-GT) approaches. Our experiments show an improvement of confidence for the high-disagreement instances.",
    "link": "https://arxiv.org/abs/2403.04085",
    "context": "Title: Don't Blame the Data, Blame the Model: Understanding Noise and Bias When Learning from Subjective Annotations\nAbstract: arXiv:2403.04085v1 Announce Type: new  Abstract: Researchers have raised awareness about the harms of aggregating labels especially in subjective tasks that naturally contain disagreements among human annotators. In this work we show that models that are only provided aggregated labels show low confidence on high-disagreement data instances. While previous studies consider such instances as mislabeled, we argue that the reason the high-disagreement text instances have been hard-to-learn is that the conventional aggregated models underperform in extracting useful signals from subjective tasks. Inspired by recent studies demonstrating the effectiveness of learning from raw annotations, we investigate classifying using Multiple Ground Truth (Multi-GT) approaches. Our experiments show an improvement of confidence for the high-disagreement instances.",
    "path": "papers/24/03/2403.04085.json",
    "total_tokens": 787,
    "translated_title": "不要责怪数据，而要责怪模型：理解从主观标注学习时的噪音和偏差",
    "translated_abstract": "研究人员提高了对在自然含有人类注释者之间分歧的主观任务中聚合标签的伤害的认识。在这项工作中，我们表明，仅提供聚合标签的模型在高分歧数据实例上表现出低置信度。虽然先前的研究将这种情况视为错误标记，但我们认为高分歧文本实例难以学习的原因是传统的聚合模型在从主观任务中提取有用信号方面表现不佳。受最近研究表明从原始注释中学习的有效性的启发，我们调查使用多个地面实况（Multi-GT）方法进行分类。我们的实验证明了对高分歧实例的置信度提高。",
    "tldr": "该论文研究了从主观标注学习时，模型对高分歧数据实例表现低置信度的原因，并提出了使用多地面实况方法进行分类以提高对这些实例的置信度。",
    "en_tdlr": "This paper investigates the reasons behind models showing low confidence on high-disagreement data instances in subjective annotation tasks, and proposes classifying using Multiple Ground Truth (Multi-GT) approaches to improve confidence for these instances."
}