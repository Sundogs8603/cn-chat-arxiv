{
    "title": "ChatGPT Rates Natural Language Explanation Quality Like Humans: But on Which Scales?",
    "abstract": "arXiv:2403.17368v1 Announce Type: cross  Abstract: As AI becomes more integral in our lives, the need for transparency and responsibility grows. While natural language explanations (NLEs) are vital for clarifying the reasoning behind AI decisions, evaluating them through human judgments is complex and resource-intensive due to subjectivity and the need for fine-grained ratings. This study explores the alignment between ChatGPT and human assessments across multiple scales (i.e., binary, ternary, and 7-Likert scale). We sample 300 data instances from three NLE datasets and collect 900 human annotations for both informativeness and clarity scores as the text quality measurement. We further conduct paired comparison experiments under different ranges of subjectivity scores, where the baseline comes from 8,346 human annotations. Our results show that ChatGPT aligns better with humans in more coarse-grained scales. Also, paired comparisons and dynamic prompting (i.e., providing semantically ",
    "link": "https://arxiv.org/abs/2403.17368",
    "context": "Title: ChatGPT Rates Natural Language Explanation Quality Like Humans: But on Which Scales?\nAbstract: arXiv:2403.17368v1 Announce Type: cross  Abstract: As AI becomes more integral in our lives, the need for transparency and responsibility grows. While natural language explanations (NLEs) are vital for clarifying the reasoning behind AI decisions, evaluating them through human judgments is complex and resource-intensive due to subjectivity and the need for fine-grained ratings. This study explores the alignment between ChatGPT and human assessments across multiple scales (i.e., binary, ternary, and 7-Likert scale). We sample 300 data instances from three NLE datasets and collect 900 human annotations for both informativeness and clarity scores as the text quality measurement. We further conduct paired comparison experiments under different ranges of subjectivity scores, where the baseline comes from 8,346 human annotations. Our results show that ChatGPT aligns better with humans in more coarse-grained scales. Also, paired comparisons and dynamic prompting (i.e., providing semantically ",
    "path": "papers/24/03/2403.17368.json",
    "total_tokens": 889,
    "translated_title": "ChatGPT将自然语言解释质量评级定为与人类相似：但是基于哪些标准？",
    "translated_abstract": "随着人工智能在我们的生活中变得越来越重要，透明度和责任性的需求也在增长。虽然自然语言解释（NLEs）对澄清人工智能决策背后的推理至关重要，但通过人类判断对其进行评估由于主观性和对细粒度评分的需求而变得复杂且资源密集。本研究探讨了ChatGPT与人类评估之间在多个尺度（即二元、三元和7-Likert尺度）上的一致性。我们从三个NLE数据集中抽取300个数据实例，并为信息量和清晰度两个文本质量度量收集了900个人类注释。我们进一步在不同主观评分范围下进行了成对比较实验，其中基线来自8,346个人类注释。我们的结果显示，在更粗粒度的尺度上，ChatGPT与人类更加一致。此外，成对比较和动态提示（即提供语义上）",
    "tldr": "本研究探索了ChatGPT在不同尺度下与人类评估之间的一致性，并发现在较粗粒度的尺度上，ChatGPT与人类更加一致。",
    "en_tdlr": "This study explores the alignment between ChatGPT and human assessments across different scales, finding that ChatGPT aligns better with humans on more coarse-grained scales."
}