{
    "title": "Multi-perspective Improvement of Knowledge Graph Completion with Large Language Models",
    "abstract": "arXiv:2403.01972v1 Announce Type: new  Abstract: Knowledge graph completion (KGC) is a widely used method to tackle incompleteness in knowledge graphs (KGs) by making predictions for missing links. Description-based KGC leverages pre-trained language models to learn entity and relation representations with their names or descriptions, which shows promising results. However, the performance of description-based KGC is still limited by the quality of text and the incomplete structure, as it lacks sufficient entity descriptions and relies solely on relation names, leading to sub-optimal results. To address this issue, we propose MPIKGC, a general framework to compensate for the deficiency of contextualized knowledge and improve KGC by querying large language models (LLMs) from various perspectives, which involves leveraging the reasoning, explanation, and summarization capabilities of LLMs to expand entity descriptions, understand relations, and extract structures, respectively. We conduc",
    "link": "https://arxiv.org/abs/2403.01972",
    "context": "Title: Multi-perspective Improvement of Knowledge Graph Completion with Large Language Models\nAbstract: arXiv:2403.01972v1 Announce Type: new  Abstract: Knowledge graph completion (KGC) is a widely used method to tackle incompleteness in knowledge graphs (KGs) by making predictions for missing links. Description-based KGC leverages pre-trained language models to learn entity and relation representations with their names or descriptions, which shows promising results. However, the performance of description-based KGC is still limited by the quality of text and the incomplete structure, as it lacks sufficient entity descriptions and relies solely on relation names, leading to sub-optimal results. To address this issue, we propose MPIKGC, a general framework to compensate for the deficiency of contextualized knowledge and improve KGC by querying large language models (LLMs) from various perspectives, which involves leveraging the reasoning, explanation, and summarization capabilities of LLMs to expand entity descriptions, understand relations, and extract structures, respectively. We conduc",
    "path": "papers/24/03/2403.01972.json",
    "total_tokens": 852,
    "translated_title": "利用大型语言模型多角度改进知识图谱补全",
    "translated_abstract": "知识图谱补全（KGC）是一种广泛使用的方法，可以通过为缺失的链接进行预测来解决知识图谱（KGs）的不完整性。基于描述的KGC利用预训练的语言模型学习实体和关系的表示形式，呈现出令人期待的结果。然而，基于描述的KGC的性能仍然受文本质量和不完整结构的限制，因为它缺乏足够的实体描述，并且仅依赖于关系名称，导致结果次优。为了解决这个问题，我们提出了MPIKGC，这是一个通用框架，通过从各种角度查询大型语言模型（LLMs）来补偿上下文化知识的不足，从而提高KGC，其中涉及利用LLMs的推理、解释和总结能力来扩展实体描述，理解关系和提取结构。",
    "tldr": "提出了MPIKGC框架，通过从多个角度利用大型语言模型来改善知识图谱补全，扩展实体描述、理解关系和提取结构，弥补了结构不完整和文本质量限制带来的问题",
    "en_tdlr": "Introduced MPIKGC framework that improves knowledge graph completion by leveraging large language models from multiple perspectives to expand entity descriptions, understand relations, and extract structures, addressing limitations from incomplete structure and text quality."
}