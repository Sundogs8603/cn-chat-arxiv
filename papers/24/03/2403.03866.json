{
    "title": "KIWI: A Dataset of Knowledge-Intensive Writing Instructions for Answering Research Questions",
    "abstract": "arXiv:2403.03866v1 Announce Type: new  Abstract: Large language models (LLMs) adapted to follow user instructions are now widely deployed as conversational agents. In this work, we examine one increasingly common instruction-following task: providing writing assistance to compose a long-form answer. To evaluate the capabilities of current LLMs on this task, we construct KIWI, a dataset of knowledge-intensive writing instructions in the scientific domain. Given a research question, an initial model-generated answer and a set of relevant papers, an expert annotator iteratively issues instructions for the model to revise and improve its answer. We collect 1,260 interaction turns from 234 interaction sessions with three state-of-the-art LLMs. Each turn includes a user instruction, a model response, and a human evaluation of the model response. Through a detailed analysis of the collected responses, we find that all models struggle to incorporate new information into an existing answer, and",
    "link": "https://arxiv.org/abs/2403.03866",
    "context": "Title: KIWI: A Dataset of Knowledge-Intensive Writing Instructions for Answering Research Questions\nAbstract: arXiv:2403.03866v1 Announce Type: new  Abstract: Large language models (LLMs) adapted to follow user instructions are now widely deployed as conversational agents. In this work, we examine one increasingly common instruction-following task: providing writing assistance to compose a long-form answer. To evaluate the capabilities of current LLMs on this task, we construct KIWI, a dataset of knowledge-intensive writing instructions in the scientific domain. Given a research question, an initial model-generated answer and a set of relevant papers, an expert annotator iteratively issues instructions for the model to revise and improve its answer. We collect 1,260 interaction turns from 234 interaction sessions with three state-of-the-art LLMs. Each turn includes a user instruction, a model response, and a human evaluation of the model response. Through a detailed analysis of the collected responses, we find that all models struggle to incorporate new information into an existing answer, and",
    "path": "papers/24/03/2403.03866.json",
    "total_tokens": 898,
    "translated_title": "KIWI：用于回答研究问题的知识密集型写作指南数据集",
    "translated_abstract": "arXiv:2403.03866v1 公告类型：新的 摘要：大型语言模型（LLMs）已经被调整以遵循用户指令，并广泛部署为会话代理。在这项工作中，我们研究了一个越来越常见的指令跟随任务：提供写作帮助以撰写长篇答案。为了评估当前LLMs在这项任务上的能力，我们构建了一个在科学领域中包含知识密集型写作指南的数据集KIWI。给定一个研究问题，一个初始模型生成的答案和一组相关论文，一个专家注释者会迭代地发布指导模型修订和改进答案的指令。我们从与三个最先进的LLMs的234个交互会话中收集了1,260个交互轮次。每个轮次包括用户指令、模型回应和对模型回应的人工评估。通过对收集到的回应进行详细分析，我们发现所有模型都难以将新信息整合到现有答案中，",
    "tldr": "该论文介绍了一个名为KIWI的数据集，用于评估大型语言模型在提供科学写作帮助时的能力，发现这些模型在整合新信息到现有答案中存在困难。",
    "en_tdlr": "This paper presents a dataset named KIWI for evaluating the ability of large language models in providing scientific writing assistance, revealing their difficulty in incorporating new information into existing answers."
}