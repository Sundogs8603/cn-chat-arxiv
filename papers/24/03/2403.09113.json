{
    "title": "AutoLoRA: Automatically Tuning Matrix Ranks in Low-Rank Adaptation Based on Meta Learning",
    "abstract": "arXiv:2403.09113v1 Announce Type: cross  Abstract: Large-scale pretraining followed by task-specific finetuning has achieved great success in various NLP tasks. Since finetuning all parameters of large pretrained models poses substantial computational and memory challenges, several efficient finetuning methods have been developed. Among them, low-rank adaptation (LoRA), which finetunes low-rank incremental update matrices on top of frozen pretrained weights, has proven particularly effective. Nonetheless, LoRA's uniform rank assignment across all layers, along with its reliance on an exhaustive search to find the best rank, leads to high computation costs and suboptimal finetuning performance. To address these limitations, we introduce AutoLoRA, a meta learning based framework for automatically identifying the optimal rank of each LoRA layer. AutoLoRA associates each rank-1 matrix in a low-rank update matrix with a selection variable, which determines whether the rank-1 matrix should b",
    "link": "https://arxiv.org/abs/2403.09113",
    "context": "Title: AutoLoRA: Automatically Tuning Matrix Ranks in Low-Rank Adaptation Based on Meta Learning\nAbstract: arXiv:2403.09113v1 Announce Type: cross  Abstract: Large-scale pretraining followed by task-specific finetuning has achieved great success in various NLP tasks. Since finetuning all parameters of large pretrained models poses substantial computational and memory challenges, several efficient finetuning methods have been developed. Among them, low-rank adaptation (LoRA), which finetunes low-rank incremental update matrices on top of frozen pretrained weights, has proven particularly effective. Nonetheless, LoRA's uniform rank assignment across all layers, along with its reliance on an exhaustive search to find the best rank, leads to high computation costs and suboptimal finetuning performance. To address these limitations, we introduce AutoLoRA, a meta learning based framework for automatically identifying the optimal rank of each LoRA layer. AutoLoRA associates each rank-1 matrix in a low-rank update matrix with a selection variable, which determines whether the rank-1 matrix should b",
    "path": "papers/24/03/2403.09113.json",
    "total_tokens": 900,
    "translated_title": "AutoLoRA：基于元学习的自动调整矩阵秩在低秩适应中的应用",
    "translated_abstract": "大规模预训练之后进行任务特定微调在各种自然语言处理任务中取得了巨大成功。然而，对于大型预训练模型的所有参数进行微调存在着巨大的计算和内存挑战，因此研发了几种高效的微调方法。其中，低秩适应（LoRA）通过在冻结的预训练权重之上微调低秩增量更新矩阵，被证明特别有效。然而，LoRA在所有层中均匀分配秩，并且依赖于穷举搜索来找到最佳秩，导致了高计算成本和微调性能不佳。为了解决这些限制，我们引入了AutoLoRA，这是一个基于元学习的框架，用于自动识别每个LoRA层的最佳秩。AutoLoRA将低秩更新矩阵中的每个秩为1的矩阵与选择变量相关联，该变量决定了秩为1的矩阵是否应该被...",
    "tldr": "AutoLoRA提出了一个基于元学习的框架，自动识别每个LoRA层的最佳秩，以解决LoRA中秩分配和秩搜索的问题，进而提高微调性能。",
    "en_tdlr": "AutoLoRA introduces a meta learning-based framework to automatically identify the optimal rank for each LoRA layer, addressing the issues of rank assignment and search in LoRA to enhance the finetuning performance."
}