{
    "title": "Language Guided Exploration for RL Agents in Text Environments",
    "abstract": "arXiv:2403.03141v1 Announce Type: new  Abstract: Real-world sequential decision making is characterized by sparse rewards and large decision spaces, posing significant difficulty for experiential learning systems like $\\textit{tabula rasa}$ reinforcement learning (RL) agents. Large Language Models (LLMs), with a wealth of world knowledge, can help RL agents learn quickly and adapt to distribution shifts. In this work, we introduce Language Guided Exploration (LGE) framework, which uses a pre-trained language model (called GUIDE ) to provide decision-level guidance to an RL agent (called EXPLORER). We observe that on ScienceWorld (Wang et al.,2022), a challenging text environment, LGE outperforms vanilla RL agents significantly and also outperforms other sophisticated methods like Behaviour Cloning and Text Decision Transformer.",
    "link": "https://arxiv.org/abs/2403.03141",
    "context": "Title: Language Guided Exploration for RL Agents in Text Environments\nAbstract: arXiv:2403.03141v1 Announce Type: new  Abstract: Real-world sequential decision making is characterized by sparse rewards and large decision spaces, posing significant difficulty for experiential learning systems like $\\textit{tabula rasa}$ reinforcement learning (RL) agents. Large Language Models (LLMs), with a wealth of world knowledge, can help RL agents learn quickly and adapt to distribution shifts. In this work, we introduce Language Guided Exploration (LGE) framework, which uses a pre-trained language model (called GUIDE ) to provide decision-level guidance to an RL agent (called EXPLORER). We observe that on ScienceWorld (Wang et al.,2022), a challenging text environment, LGE outperforms vanilla RL agents significantly and also outperforms other sophisticated methods like Behaviour Cloning and Text Decision Transformer.",
    "path": "papers/24/03/2403.03141.json",
    "total_tokens": 847,
    "translated_title": "文本环境中RL代理的语言引导探索",
    "translated_abstract": "实际世界中的序贯决策以稀疏奖励和庞大的决策空间为特征，这对tabula rasa强化学习（RL）代理等经验学习系统提出了重要困难。具有丰富世界知识的大型语言模型（LLMs）可以帮助RL代理快速学习并适应分布变化。在这项工作中，我们引入了语言指导探索（LGE）框架，该框架使用一个预先训练的语言模型（称为GUIDE）为RL代理（称为EXPLORER）提供决策级别的指导。我们观察到，在ScienceWorld（Wang等人，2022年）这一具有挑战性的文本环境中，LGE显著优于普通RL代理，并且优于行为克隆和文本决策Transformer等其他复杂方法。",
    "tldr": "引入了语言引导探索（LGE）框架，利用大型语言模型（LLM）为RL代理提供决策级别的引导，相比于普通RL代理和其他复杂方法，在具有挑战性的文本环境中取得了显著的优势。",
    "en_tdlr": "Introduced the Language Guided Exploration (LGE) framework, which utilizes a Large Language Model (LLM) to provide decision-level guidance for RL agents, outperforming vanilla RL agents and other sophisticated methods significantly in challenging text environments."
}