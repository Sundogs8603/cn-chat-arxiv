{
    "title": "TopicDiff: A Topic-enriched Diffusion Approach for Multimodal Conversational Emotion Detection",
    "abstract": "arXiv:2403.04789v1 Announce Type: cross  Abstract: Multimodal Conversational Emotion (MCE) detection, generally spanning across the acoustic, vision and language modalities, has attracted increasing interest in the multimedia community. Previous studies predominantly focus on learning contextual information in conversations with only a few considering the topic information in single language modality, while always neglecting the acoustic and vision topic information. On this basis, we propose a model-agnostic Topic-enriched Diffusion (TopicDiff) approach for capturing multimodal topic information in MCE tasks. Particularly, we integrate the diffusion model into neural topic model to alleviate the diversity deficiency problem of neural topic model in capturing topic information. Detailed evaluations demonstrate the significant improvements of TopicDiff over the state-of-the-art MCE baselines, justifying the importance of multimodal topic information to MCE and the effectiveness of Topic",
    "link": "https://arxiv.org/abs/2403.04789",
    "context": "Title: TopicDiff: A Topic-enriched Diffusion Approach for Multimodal Conversational Emotion Detection\nAbstract: arXiv:2403.04789v1 Announce Type: cross  Abstract: Multimodal Conversational Emotion (MCE) detection, generally spanning across the acoustic, vision and language modalities, has attracted increasing interest in the multimedia community. Previous studies predominantly focus on learning contextual information in conversations with only a few considering the topic information in single language modality, while always neglecting the acoustic and vision topic information. On this basis, we propose a model-agnostic Topic-enriched Diffusion (TopicDiff) approach for capturing multimodal topic information in MCE tasks. Particularly, we integrate the diffusion model into neural topic model to alleviate the diversity deficiency problem of neural topic model in capturing topic information. Detailed evaluations demonstrate the significant improvements of TopicDiff over the state-of-the-art MCE baselines, justifying the importance of multimodal topic information to MCE and the effectiveness of Topic",
    "path": "papers/24/03/2403.04789.json",
    "total_tokens": 886,
    "translated_title": "TopicDiff：一种用于多模态会话情感检测的主题丰富扩散方法",
    "translated_abstract": "多模态会话情感（MCE）检测通常跨越声学、视觉和语言模态，吸引了多媒体社区日益增加的兴趣。先前的研究主要集中在学习对话中的语境信息，只有少数考虑单一语言模态中的主题信息，而总是忽视声学和视觉主题信息。在此基础上，我们提出了一个模型不可知的Topic-enriched Diffusion（TopicDiff）方法，用于捕获MCE任务中的多模态主题信息。特别是，我们将扩散模型集成到神经主题模型中，以缓解神经主题模型在捕获主题信息方面的多样性不足问题。详细的评估表明，TopicDiff相对于最先进的MCE基线取得了显著改进，证明了多模态主题信息对MCE的重要性以及TopicDiff的有效性。",
    "tldr": "提出了一种TopicDiff方法，用于捕获多模态会话情感检测任务中的主题信息，通过将扩散模型集成到神经主题模型中，解决了神经主题模型在捕获主题信息方面的多样性不足问题，并相对于现有MCE基线取得了显著改进",
    "en_tdlr": "Proposed a TopicDiff approach for capturing topic information in multimodal conversational emotion detection tasks, which integrates the diffusion model into neural topic model to address the diversity deficiency problem and achieves significant improvements over existing MCE baselines."
}