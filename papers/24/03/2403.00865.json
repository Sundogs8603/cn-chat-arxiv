{
    "title": "Fast and Efficient Local Search for Genetic Programming Based Loss Function Learning",
    "abstract": "arXiv:2403.00865v1 Announce Type: cross  Abstract: In this paper, we develop upon the topic of loss function learning, an emergent meta-learning paradigm that aims to learn loss functions that significantly improve the performance of the models trained under them. Specifically, we propose a new meta-learning framework for task and model-agnostic loss function learning via a hybrid search approach. The framework first uses genetic programming to find a set of symbolic loss functions. Second, the set of learned loss functions is subsequently parameterized and optimized via unrolled differentiation. The versatility and performance of the proposed framework are empirically validated on a diverse set of supervised learning tasks. Results show that the learned loss functions bring improved convergence, sample efficiency, and inference performance on tabulated, computer vision, and natural language processing problems, using a variety of task-specific neural network architectures.",
    "link": "https://arxiv.org/abs/2403.00865",
    "context": "Title: Fast and Efficient Local Search for Genetic Programming Based Loss Function Learning\nAbstract: arXiv:2403.00865v1 Announce Type: cross  Abstract: In this paper, we develop upon the topic of loss function learning, an emergent meta-learning paradigm that aims to learn loss functions that significantly improve the performance of the models trained under them. Specifically, we propose a new meta-learning framework for task and model-agnostic loss function learning via a hybrid search approach. The framework first uses genetic programming to find a set of symbolic loss functions. Second, the set of learned loss functions is subsequently parameterized and optimized via unrolled differentiation. The versatility and performance of the proposed framework are empirically validated on a diverse set of supervised learning tasks. Results show that the learned loss functions bring improved convergence, sample efficiency, and inference performance on tabulated, computer vision, and natural language processing problems, using a variety of task-specific neural network architectures.",
    "path": "papers/24/03/2403.00865.json",
    "total_tokens": 839,
    "translated_title": "基于遗传编程的损失函数学习的快速高效局部搜索",
    "translated_abstract": "在本文中，我们深入探讨了损失函数学习的话题，这是一种新兴的元学习范式，旨在学习能显著改善经过其训练的模型性能的损失函数。具体来说，我们提出了一种新的元学习框架，通过混合搜索方法实现了任务和模型无关的损失函数学习。该框架首先使用遗传编程找到一组符号损失函数。其次，学习到的损失函数集合随后通过展开的微分进行参数化和优化。所提出的框架的多样性和性能经过实证验证，用于各种监督学习任务。实验结果表明，学习到的损失函数在表格、计算机视觉和自然语言处理问题上带来了改善的收敛性、样本效率和推理性能，使用各种特定任务的神经网络架构。",
    "tldr": "提出了一种新的基于遗传编程的元学习框架，通过局部搜索方法实现了任务和模型无关的损失函数学习，实验证实了该框架在各种监督学习任务上的多样性和性能。"
}