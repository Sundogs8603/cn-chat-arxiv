{
    "title": "Generalising Multi-Agent Cooperation through Task-Agnostic Communication",
    "abstract": "arXiv:2403.06750v1 Announce Type: cross  Abstract: Existing communication methods for multi-agent reinforcement learning (MARL) in cooperative multi-robot problems are almost exclusively task-specific, training new communication strategies for each unique task. We address this inefficiency by introducing a communication strategy applicable to any task within a given environment. We pre-train the communication strategy without task-specific reward guidance in a self-supervised manner using a set autoencoder. Our objective is to learn a fixed-size latent Markov state from a variable number of agent observations. Under mild assumptions, we prove that policies using our latent representations are guaranteed to converge, and upper bound the value error introduced by our Markov state approximation. Our method enables seamless adaptation to novel tasks without fine-tuning the communication strategy, gracefully supports scaling to more agents than present during training, and detects out-of-di",
    "link": "https://arxiv.org/abs/2403.06750",
    "context": "Title: Generalising Multi-Agent Cooperation through Task-Agnostic Communication\nAbstract: arXiv:2403.06750v1 Announce Type: cross  Abstract: Existing communication methods for multi-agent reinforcement learning (MARL) in cooperative multi-robot problems are almost exclusively task-specific, training new communication strategies for each unique task. We address this inefficiency by introducing a communication strategy applicable to any task within a given environment. We pre-train the communication strategy without task-specific reward guidance in a self-supervised manner using a set autoencoder. Our objective is to learn a fixed-size latent Markov state from a variable number of agent observations. Under mild assumptions, we prove that policies using our latent representations are guaranteed to converge, and upper bound the value error introduced by our Markov state approximation. Our method enables seamless adaptation to novel tasks without fine-tuning the communication strategy, gracefully supports scaling to more agents than present during training, and detects out-of-di",
    "path": "papers/24/03/2403.06750.json",
    "total_tokens": 821,
    "translated_title": "通过任务无关的通信来泛化多Agent合作",
    "translated_abstract": "现有的合作多机器人问题中的多Agent强化学习（MARL）的通信方法几乎完全是特定于任务的，为每个独特的任务训练新的通信策略。我们通过引入一种适用于给定环境中任何任务的通信策略来解决这种低效问题。我们自监督地使用一组自动编码器预先训练通信策略，而不需要特定于任务的奖励指导。我们的目标是从可变数量的Agent观测中学习固定大小的潜在马尔可夫状态。在温和的假设下，我们证明使用我们的潜在表示的策略保证收敛，并对由我们的马尔可夫状态近似引入的值误差上界进行限制。我们的方法实现了对新任务的无缝适应，无需微调通信策略，优雅地支持比训练期间更多Agent，以及检测范",
    "tldr": "通过预先训练的任务无关通信策略，在合作多机器人问题中实现了无需微调的任务泛化，支持更多Agent数量的扩展，并保证了收敛性。",
    "en_tdlr": "Task-agnostic communication strategy pre-training in cooperative multi-robot problems enables task generalization without fine-tuning, supports scaling to more agents, and guarantees convergence."
}