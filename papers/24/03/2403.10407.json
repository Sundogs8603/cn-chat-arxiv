{
    "title": "A Thorough Comparison of Cross-Encoders and LLMs for Reranking SPLADE",
    "abstract": "arXiv:2403.10407v1 Announce Type: new  Abstract: We present a comparative study between cross-encoder and LLMs rerankers in the context of re-ranking effective SPLADE retrievers. We conduct a large evaluation on TREC Deep Learning datasets and out-of-domain datasets such as BEIR and LoTTE. In the first set of experiments, we show how cross-encoder rerankers are hard to distinguish when it comes to re-rerank SPLADE on MS MARCO. Observations shift in the out-of-domain scenario, where both the type of model and the number of documents to re-rank have an impact on effectiveness. Then, we focus on listwise rerankers based on Large Language Models -- especially GPT-4. While GPT-4 demonstrates impressive (zero-shot) performance, we show that traditional cross-encoders remain very competitive. Overall, our findings aim to to provide a more nuanced perspective on the recent excitement surrounding LLM-based re-rankers -- by positioning them as another factor to consider in balancing effectivenes",
    "link": "https://arxiv.org/abs/2403.10407",
    "context": "Title: A Thorough Comparison of Cross-Encoders and LLMs for Reranking SPLADE\nAbstract: arXiv:2403.10407v1 Announce Type: new  Abstract: We present a comparative study between cross-encoder and LLMs rerankers in the context of re-ranking effective SPLADE retrievers. We conduct a large evaluation on TREC Deep Learning datasets and out-of-domain datasets such as BEIR and LoTTE. In the first set of experiments, we show how cross-encoder rerankers are hard to distinguish when it comes to re-rerank SPLADE on MS MARCO. Observations shift in the out-of-domain scenario, where both the type of model and the number of documents to re-rank have an impact on effectiveness. Then, we focus on listwise rerankers based on Large Language Models -- especially GPT-4. While GPT-4 demonstrates impressive (zero-shot) performance, we show that traditional cross-encoders remain very competitive. Overall, our findings aim to to provide a more nuanced perspective on the recent excitement surrounding LLM-based re-rankers -- by positioning them as another factor to consider in balancing effectivenes",
    "path": "papers/24/03/2403.10407.json",
    "total_tokens": 985,
    "translated_title": "跨编码器和LLMs在重新排序SPLADE中的彻底比较",
    "translated_abstract": "我们在重新排序有效的SPLADE检索器的背景下，介绍了跨编码器和LLMs重新排序器之间的比较性研究。我们对TREC深度学习数据集和BEIR、LoTTE等领域外数据集进行了大量评估。在第一组实验中，我们展示了在重新排序SPLADE在MS MARCO上时，跨编码器重新排序器是难以区分的。观察结果在领域外情况下发生了变化，模型类型和重新排序文档数量对效果产生影响。然后，我们专注于基于大型语言模型的列表式重新排序器，特别是GPT-4。虽然GPT-4展示了令人印象深刻的（零样本）性能，但我们表明传统的跨编码器仍然非常具有竞争力。总体而言，我们的研究结果旨在提供对围绕LLM-based重新排序器最近的兴奋情绪更细致的观点，将它们定位为在平衡效果时需要考虑的另一个因素。",
    "tldr": "本文比较了跨编码器和LLMs在重新排序SPLADE中的表现，发现在MS MARCO上，两者难以区分，但在领域外情况下，模型类型和重新排序文档数量对效果有影响，同时GPT-4表现出色，但传统跨编码器仍然具有竞争力。",
    "en_tdlr": "This paper compares the performance of cross-encoders and LLMs in reranking SPLADE, finding that they are hard to distinguish on MS MARCO but model type and number of documents impact effectiveness in out-of-domain scenarios, with GPT-4 showing impressive performance while traditional cross-encoders remain competitive."
}