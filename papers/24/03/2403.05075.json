{
    "title": "Benchmarking Large Language Models for Molecule Prediction Tasks",
    "abstract": "arXiv:2403.05075v1 Announce Type: new  Abstract: Large Language Models (LLMs) stand at the forefront of a number of Natural Language Processing (NLP) tasks. Despite the widespread adoption of LLMs in NLP, much of their potential in broader fields remains largely unexplored, and significant limitations persist in their design and implementation. Notably, LLMs struggle with structured data, such as graphs, and often falter when tasked with answering domain-specific questions requiring deep expertise, such as those in biology and chemistry. In this paper, we explore a fundamental question: Can LLMs effectively handle molecule prediction tasks? Rather than pursuing top-tier performance, our goal is to assess how LLMs can contribute to diverse molecule tasks. We identify several classification and regression prediction tasks across six standard molecule datasets. Subsequently, we carefully design a set of prompts to query LLMs on these tasks and compare their performance with existing Machi",
    "link": "https://arxiv.org/abs/2403.05075",
    "context": "Title: Benchmarking Large Language Models for Molecule Prediction Tasks\nAbstract: arXiv:2403.05075v1 Announce Type: new  Abstract: Large Language Models (LLMs) stand at the forefront of a number of Natural Language Processing (NLP) tasks. Despite the widespread adoption of LLMs in NLP, much of their potential in broader fields remains largely unexplored, and significant limitations persist in their design and implementation. Notably, LLMs struggle with structured data, such as graphs, and often falter when tasked with answering domain-specific questions requiring deep expertise, such as those in biology and chemistry. In this paper, we explore a fundamental question: Can LLMs effectively handle molecule prediction tasks? Rather than pursuing top-tier performance, our goal is to assess how LLMs can contribute to diverse molecule tasks. We identify several classification and regression prediction tasks across six standard molecule datasets. Subsequently, we carefully design a set of prompts to query LLMs on these tasks and compare their performance with existing Machi",
    "path": "papers/24/03/2403.05075.json",
    "total_tokens": 700,
    "translated_title": "用于分子预测任务的大型语言模型基准测试",
    "translated_abstract": "大型语言模型（LLMs）处于许多自然语言处理（NLP）任务的前沿。尽管LLMs在NLP中被广泛采用，但它们在更广泛领域的潜力仍然未被充分探索，其设计和实施存在显著限制。作者在本文中探讨了一个基本问题：LLMs能否有效处理分子预测任务？与追求最高水平性能不同，作者的目标是评估LLMs在不同的分子任务中的贡献。",
    "tldr": "本文探讨了大型语言模型在处理分子预测任务方面的潜力和限制，并评估了它们在多样化分子任务中的表现。",
    "en_tdlr": "The paper investigates the potential and limitations of large language models in handling molecule prediction tasks, evaluating their performance in diverse molecule tasks."
}