{
    "title": "SM4Depth: Seamless Monocular Metric Depth Estimation across Multiple Cameras and Scenes by One Model",
    "abstract": "arXiv:2403.08556v1 Announce Type: cross  Abstract: The generalization of monocular metric depth estimation (MMDE) has been a longstanding challenge. Recent methods made progress by combining relative and metric depth or aligning input image focal length. However, they are still beset by challenges in camera, scene, and data levels: (1) Sensitivity to different cameras; (2) Inconsistent accuracy across scenes; (3) Reliance on massive training data. This paper proposes SM4Depth, a seamless MMDE method, to address all the issues above within a single network. First, we reveal that a consistent field of view (FOV) is the key to resolve ``metric ambiguity'' across cameras, which guides us to propose a more straightforward preprocessing unit. Second, to achieve consistently high accuracy across scenes, we explicitly model the metric scale determination as discretizing the depth interval into bins and propose variation-based unnormalized depth bins. This method bridges the depth gap of divers",
    "link": "https://arxiv.org/abs/2403.08556",
    "context": "Title: SM4Depth: Seamless Monocular Metric Depth Estimation across Multiple Cameras and Scenes by One Model\nAbstract: arXiv:2403.08556v1 Announce Type: cross  Abstract: The generalization of monocular metric depth estimation (MMDE) has been a longstanding challenge. Recent methods made progress by combining relative and metric depth or aligning input image focal length. However, they are still beset by challenges in camera, scene, and data levels: (1) Sensitivity to different cameras; (2) Inconsistent accuracy across scenes; (3) Reliance on massive training data. This paper proposes SM4Depth, a seamless MMDE method, to address all the issues above within a single network. First, we reveal that a consistent field of view (FOV) is the key to resolve ``metric ambiguity'' across cameras, which guides us to propose a more straightforward preprocessing unit. Second, to achieve consistently high accuracy across scenes, we explicitly model the metric scale determination as discretizing the depth interval into bins and propose variation-based unnormalized depth bins. This method bridges the depth gap of divers",
    "path": "papers/24/03/2403.08556.json",
    "total_tokens": 786,
    "translated_title": "SM4Depth: 一种通过单一模型实现跨多摄像头和场景的无缝单目度量深度估计",
    "translated_abstract": "单目度量深度估计（MMDE）的泛化一直是一个长期存在的挑战。最近的方法通过结合相对深度和度量深度或对齐输入图像焦距取得了进展。然而，它们仍然面临着在相机、场景和数据级别上的挑战：（1）对不同摄像头的敏感性；（2）在不同场景中精度不一致；（3）依赖大规模训练数据。本文提出了一种无缝的MMDE方法SM4Depth，以在单个网络内解决上述所有问题。",
    "tldr": "SM4Depth通过一种新的预处理单元和深度间隔离散化的方法，解决了单目度量深度估计中的相机敏感性、场景精度不一致和数据依赖性等问题。",
    "en_tdlr": "SM4Depth addresses the challenges in monocular metric depth estimation, such as camera sensitivity, inconsistent accuracy across scenes, and reliance on massive training data, by introducing a novel preprocessing unit and discretizing depth interval."
}