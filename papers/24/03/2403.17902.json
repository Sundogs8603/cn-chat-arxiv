{
    "title": "Serpent: Scalable and Efficient Image Restoration via Multi-scale Structured State Space Models",
    "abstract": "arXiv:2403.17902v1 Announce Type: cross  Abstract: The landscape of computational building blocks of efficient image restoration architectures is dominated by a combination of convolutional processing and various attention mechanisms. However, convolutional filters are inherently local and therefore struggle at modeling long-range dependencies in images. On the other hand, attention excels at capturing global interactions between arbitrary image regions, however at a quadratic cost in image dimension. In this work, we propose Serpent, an architecture that leverages recent advances in state space models (SSMs) in its core computational block. SSMs, originally introduced for sequence modeling, can maintain a global receptive field with a favorable linear scaling in input size. Our preliminary results demonstrate that Serpent can achieve reconstruction quality on par with state-of-the-art techniques, while requiring orders of magnitude less compute (up to $150$ fold reduction in FLOPS) an",
    "link": "https://arxiv.org/abs/2403.17902",
    "context": "Title: Serpent: Scalable and Efficient Image Restoration via Multi-scale Structured State Space Models\nAbstract: arXiv:2403.17902v1 Announce Type: cross  Abstract: The landscape of computational building blocks of efficient image restoration architectures is dominated by a combination of convolutional processing and various attention mechanisms. However, convolutional filters are inherently local and therefore struggle at modeling long-range dependencies in images. On the other hand, attention excels at capturing global interactions between arbitrary image regions, however at a quadratic cost in image dimension. In this work, we propose Serpent, an architecture that leverages recent advances in state space models (SSMs) in its core computational block. SSMs, originally introduced for sequence modeling, can maintain a global receptive field with a favorable linear scaling in input size. Our preliminary results demonstrate that Serpent can achieve reconstruction quality on par with state-of-the-art techniques, while requiring orders of magnitude less compute (up to $150$ fold reduction in FLOPS) an",
    "path": "papers/24/03/2403.17902.json",
    "total_tokens": 875,
    "translated_title": "Serpent：通过多尺度结构化状态空间模型实现可扩展高效的图像恢复",
    "translated_abstract": "有效图像恢复架构的计算建筑块领域，主要由卷积处理和各种注意机制的组合所主导。然而，卷积滤波器本质上是局部的，因此在建模图像的长距离依赖性方面存在困难。另一方面，注意机制擅长捕获任意图像区域之间的全局相互作用，但对图像尺寸的二次成本较高。在这项工作中，我们提出了Serpent，这是一种利用最近在状态空间模型（SSMs）方面的进展作为其核心计算模块的架构。SSMs最初用于序列建模，可以通过有利的输入尺寸的线性缩放来维持全局感受野。我们的初步结果表明，Serpent可以实现与最先进技术相当的重建质量，同时需要数量级的计算量较少（在FLOPS上高达150倍的减少）。",
    "tldr": "Serpent提出了一种新的图像恢复架构，利用状态空间模型在全局感受野和计算效率之间取得平衡，实现了与最先进技术相当的重建质量，但计算量减少了数个数量级。",
    "en_tdlr": "Serpent introduces a novel image restoration architecture balancing global receptive field and computational efficiency through state space models, achieving reconstruction quality on par with state-of-the-art techniques but with orders of magnitude less compute."
}