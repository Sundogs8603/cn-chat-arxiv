{
    "title": "Elephants Never Forget: Testing Language Models for Memorization of Tabular Data",
    "abstract": "arXiv:2403.06644v1 Announce Type: cross  Abstract: While many have shown how Large Language Models (LLMs) can be applied to a diverse set of tasks, the critical issues of data contamination and memorization are often glossed over. In this work, we address this concern for tabular data. Starting with simple qualitative tests for whether an LLM knows the names and values of features, we introduce a variety of different techniques to assess the degrees of contamination, including statistical tests for conditional distribution modeling and four tests that identify memorization. Our investigation reveals that LLMs are pre-trained on many popular tabular datasets. This exposure can lead to invalid performance evaluation on downstream tasks because the LLMs have, in effect, been fit to the test set. Interestingly, we also identify a regime where the language model reproduces important statistics of the data, but fails to reproduce the dataset verbatim. On these datasets, although seen during ",
    "link": "https://arxiv.org/abs/2403.06644",
    "context": "Title: Elephants Never Forget: Testing Language Models for Memorization of Tabular Data\nAbstract: arXiv:2403.06644v1 Announce Type: cross  Abstract: While many have shown how Large Language Models (LLMs) can be applied to a diverse set of tasks, the critical issues of data contamination and memorization are often glossed over. In this work, we address this concern for tabular data. Starting with simple qualitative tests for whether an LLM knows the names and values of features, we introduce a variety of different techniques to assess the degrees of contamination, including statistical tests for conditional distribution modeling and four tests that identify memorization. Our investigation reveals that LLMs are pre-trained on many popular tabular datasets. This exposure can lead to invalid performance evaluation on downstream tasks because the LLMs have, in effect, been fit to the test set. Interestingly, we also identify a regime where the language model reproduces important statistics of the data, but fails to reproduce the dataset verbatim. On these datasets, although seen during ",
    "path": "papers/24/03/2403.06644.json",
    "total_tokens": 894,
    "translated_title": "大象永远不会忘记：测试语言模型对表格数据的记忆能力",
    "translated_abstract": "虽然许多人已经展示了大型语言模型（LLMs）如何应用于各种任务，但数据污染和记忆化的关键问题往往被忽视。在这项工作中，我们针对表格数据解决了这一问题。我们从简单的定性测试开始，测试LLM是否知道特征的名称和值，引入了各种不同的技术来评估污染程度，包括用于条件分布建模的统计测试和四个识别记忆化的测试。我们的调查发现，LLMs在许多流行的表格数据集上进行了预训练。这种暴露可能导致在下游任务上无效的性能评估，因为LLMs实际上已经适应了测试集。有趣的是，我们还确定了一种情况，在这种情况下，语言模型可以复制数据的重要统计信息，但无法逐字复制数据集。在这些数据集上，尽管见过...",
    "tldr": "本研究针对表格数据探讨了大型语言模型（LLMs）存在的数据污染和记忆化问题，发现LLMs在许多常见的表格数据集上进行了预训练，可能导致在下游任务中对性能评估的无效性。",
    "en_tdlr": "This study addresses the issues of data contamination and memorization in Large Language Models (LLMs) for tabular data, revealing that LLMs are pre-trained on popular tabular datasets, which may lead to invalid performance evaluation on downstream tasks."
}