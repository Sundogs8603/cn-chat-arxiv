{
    "title": "SpeechColab Leaderboard: An Open-Source Platform for Automatic Speech Recognition Evaluation",
    "abstract": "arXiv:2403.08196v1 Announce Type: new  Abstract: In the wake of the surging tide of deep learning over the past decade, Automatic Speech Recognition (ASR) has garnered substantial attention, leading to the emergence of numerous publicly accessible ASR systems that are actively being integrated into our daily lives. Nonetheless, the impartial and replicable evaluation of these ASR systems encounters challenges due to various crucial subtleties. In this paper we introduce the SpeechColab Leaderboard, a general-purpose, open-source platform designed for ASR evaluation. With this platform: (i) We report a comprehensive benchmark, unveiling the current state-of-the-art panorama for ASR systems, covering both open-source models and industrial commercial services. (ii) We quantize how distinct nuances in the scoring pipeline influence the final benchmark outcomes. These include nuances related to capitalization, punctuation, interjection, contraction, synonym usage, compound words, etc. These",
    "link": "https://arxiv.org/abs/2403.08196",
    "context": "Title: SpeechColab Leaderboard: An Open-Source Platform for Automatic Speech Recognition Evaluation\nAbstract: arXiv:2403.08196v1 Announce Type: new  Abstract: In the wake of the surging tide of deep learning over the past decade, Automatic Speech Recognition (ASR) has garnered substantial attention, leading to the emergence of numerous publicly accessible ASR systems that are actively being integrated into our daily lives. Nonetheless, the impartial and replicable evaluation of these ASR systems encounters challenges due to various crucial subtleties. In this paper we introduce the SpeechColab Leaderboard, a general-purpose, open-source platform designed for ASR evaluation. With this platform: (i) We report a comprehensive benchmark, unveiling the current state-of-the-art panorama for ASR systems, covering both open-source models and industrial commercial services. (ii) We quantize how distinct nuances in the scoring pipeline influence the final benchmark outcomes. These include nuances related to capitalization, punctuation, interjection, contraction, synonym usage, compound words, etc. These",
    "path": "papers/24/03/2403.08196.json",
    "total_tokens": 908,
    "translated_title": "SpeechColab排行榜：用于自动语音识别评估的开源平台",
    "translated_abstract": "随着过去十年深度学习浪潮的涌现，自动语音识别（ASR）引起了相当大的关注，导致了许多可公开访问的ASR系统的出现，这些系统正在积极地融入我们的日常生活中。然而，这些ASR系统的公正和可复制评估面临着由于各种关键微妙之处而带来的挑战。本文介绍了SpeechColab排行榜，这是一个通用的开源平台，专为ASR评估而设计。借助这个平台：(i)我们报告了一项全面的基准测试，揭示了ASR系统的最新技术现状，涵盖了开源模型和工业商业服务。 (ii)我们量化了得分管道中不同细微之处对最终基准测试结果的影响。这些包括与大写、标点、插入语、缩略语、同义词使用、复合词等相关的微妙之处。",
    "tldr": "介绍了SpeechColab Leaderboard，一个用于ASR评估的开源平台，提供全面的基准测试，揭示了ASR系统的最新技术现状，并量化了得分管道中不同细微之处对最终基准测试结果的影响。",
    "en_tdlr": "Introducing the SpeechColab Leaderboard, an open-source platform for ASR evaluation, providing a comprehensive benchmark revealing the current state-of-the-art in ASR systems, and quantifying the impact of different nuances in the scoring pipeline on the final benchmark outcomes."
}