{
    "title": "Time Series Compression using Quaternion Valued Neural Networks and Quaternion Backpropagation",
    "abstract": "arXiv:2403.11722v1 Announce Type: new  Abstract: We propose a novel quaternionic time-series compression methodology where we divide a long time-series into segments of data, extract the min, max, mean and standard deviation of these chunks as representative features and encapsulate them in a quaternion, yielding a quaternion valued time-series. This time-series is processed using quaternion valued neural network layers, where we aim to preserve the relation between these features through the usage of the Hamilton product. To train this quaternion neural network, we derive quaternion backpropagation employing the GHR calculus, which is required for a valid product and chain rule in quaternion space. Furthermore, we investigate the connection between the derived update rules and automatic differentiation. We apply our proposed compression method on the Tennessee Eastman Dataset, where we perform fault classification using the compressed data in two settings: a fully supervised one and i",
    "link": "https://arxiv.org/abs/2403.11722",
    "context": "Title: Time Series Compression using Quaternion Valued Neural Networks and Quaternion Backpropagation\nAbstract: arXiv:2403.11722v1 Announce Type: new  Abstract: We propose a novel quaternionic time-series compression methodology where we divide a long time-series into segments of data, extract the min, max, mean and standard deviation of these chunks as representative features and encapsulate them in a quaternion, yielding a quaternion valued time-series. This time-series is processed using quaternion valued neural network layers, where we aim to preserve the relation between these features through the usage of the Hamilton product. To train this quaternion neural network, we derive quaternion backpropagation employing the GHR calculus, which is required for a valid product and chain rule in quaternion space. Furthermore, we investigate the connection between the derived update rules and automatic differentiation. We apply our proposed compression method on the Tennessee Eastman Dataset, where we perform fault classification using the compressed data in two settings: a fully supervised one and i",
    "path": "papers/24/03/2403.11722.json",
    "total_tokens": 821,
    "translated_title": "使用四元值神经网络和四元反向传播进行时间序列压缩",
    "translated_abstract": "我们提出了一种新颖的四元数时间序列压缩方法，将长时间序列划分为数据段，提取这些块的最小值、最大值、均值和标准差作为代表性特征，并将它们封装在四元数中，得到一个四元数值时间序列。这个时间序列使用四元数值神经网络层进行处理，我们旨在通过使用哈密顿积来保留这些特征之间的关系。为了训练这个四元数神经网络，我们推导出使用GHR微积分的四元数反向传播，这对于四元数空间中的有效乘积和链规则是必需的。此外，我们研究了推导更新规则与自动微分之间的联系。我们将我们提出的压缩方法应用于Tennessee Eastman数据集，在两个设置中使用压缩数据进行故障分类：一个完全监督的设置和另一个半监督的设置。",
    "tldr": "提出了一种使用四元值神经网络和四元反向传播进行时间序列压缩的方法，在保留特征之间关系的同时在故障分类中展现出潜力。",
    "en_tdlr": "Proposed a method for time series compression using quaternion valued neural networks and quaternion backpropagation, showing potential in fault classification while preserving relations between features."
}