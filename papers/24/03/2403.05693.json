{
    "title": "Shielded Deep Reinforcement Learning for Complex Spacecraft Tasking",
    "abstract": "arXiv:2403.05693v1 Announce Type: new  Abstract: Autonomous spacecraft control via Shielded Deep Reinforcement Learning (SDRL) has become a rapidly growing research area. However, the construction of shields and the definition of tasking remains informal, resulting in policies with no guarantees on safety and ambiguous goals for the RL agent. In this paper, we first explore the use of formal languages, namely Linear Temporal Logic (LTL), to formalize spacecraft tasks and safety requirements. We then define a manner in which to construct a reward function from a co-safe LTL specification automatically for effective training in SDRL framework. We also investigate methods for constructing a shield from a safe LTL specification for spacecraft applications and propose three designs that provide probabilistic guarantees. We show how these shields interact with different policies and the flexibility of the reward structure through several experiments.",
    "link": "https://arxiv.org/abs/2403.05693",
    "context": "Title: Shielded Deep Reinforcement Learning for Complex Spacecraft Tasking\nAbstract: arXiv:2403.05693v1 Announce Type: new  Abstract: Autonomous spacecraft control via Shielded Deep Reinforcement Learning (SDRL) has become a rapidly growing research area. However, the construction of shields and the definition of tasking remains informal, resulting in policies with no guarantees on safety and ambiguous goals for the RL agent. In this paper, we first explore the use of formal languages, namely Linear Temporal Logic (LTL), to formalize spacecraft tasks and safety requirements. We then define a manner in which to construct a reward function from a co-safe LTL specification automatically for effective training in SDRL framework. We also investigate methods for constructing a shield from a safe LTL specification for spacecraft applications and propose three designs that provide probabilistic guarantees. We show how these shields interact with different policies and the flexibility of the reward structure through several experiments.",
    "path": "papers/24/03/2403.05693.json",
    "total_tokens": 912,
    "translated_title": "复杂航天器任务的屏蔽深度强化学习",
    "translated_abstract": "自主航天器控制通过屏蔽深度强化学习（SDRL）已成为快速增长的研究领域。然而，目前对屏蔽的构建和任务的定义仍不够正式，导致策略无法保证安全并给RL代理设定了模棱两可的目标。本文首先探讨了使用形式语言，即线性时态逻辑（LTL），来形式化航天器任务和安全要求。然后定义了一种自动从co-safe LTL规范构建奖励函数以有效训练SDRL框架的方式。我们还研究了为航天器应用从安全LTL规范构建屏蔽的方法，并提出了三种可以提供概率保证的设计。通过几个实验展示了这些屏蔽与不同策略的互动以及奖励结构的灵活性。",
    "tldr": "本文基于线性时态逻辑（LTL）形式化了航天器任务和安全要求，并提出了自动构建奖励函数以实现有效训练的方法。同时探讨了从安全LTL规范构建航天器屏蔽的方法，提出了三种可以提供概率保证的设计，并通过实验展示了这些屏蔽与不同策略的互动和奖励结构的灵活性。",
    "en_tdlr": "This paper formalizes spacecraft tasks and safety requirements using Linear Temporal Logic (LTL), proposes automatic reward function construction for effective training, investigates shield construction from safe LTL specification for spacecraft applications with three probabilistic designs, and demonstrates shield interactions with policies and reward structure flexibility through experiments."
}