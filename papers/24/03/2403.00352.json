{
    "title": "Revisiting Disentanglement in Downstream Tasks: A Study on Its Necessity for Abstract Visual Reasoning",
    "abstract": "arXiv:2403.00352v1 Announce Type: cross  Abstract: In representation learning, a disentangled representation is highly desirable as it encodes generative factors of data in a separable and compact pattern. Researchers have advocated leveraging disentangled representations to complete downstream tasks with encouraging empirical evidence. This paper further investigates the necessity of disentangled representation in downstream applications. Specifically, we show that dimension-wise disentangled representations are unnecessary on a fundamental downstream task, abstract visual reasoning. We provide extensive empirical evidence against the necessity of disentanglement, covering multiple datasets, representation learning methods, and downstream network architectures. Furthermore, our findings suggest that the informativeness of representations is a better indicator of downstream performance than disentanglement. Finally, the positive correlation between informativeness and disentanglement e",
    "link": "https://arxiv.org/abs/2403.00352",
    "context": "Title: Revisiting Disentanglement in Downstream Tasks: A Study on Its Necessity for Abstract Visual Reasoning\nAbstract: arXiv:2403.00352v1 Announce Type: cross  Abstract: In representation learning, a disentangled representation is highly desirable as it encodes generative factors of data in a separable and compact pattern. Researchers have advocated leveraging disentangled representations to complete downstream tasks with encouraging empirical evidence. This paper further investigates the necessity of disentangled representation in downstream applications. Specifically, we show that dimension-wise disentangled representations are unnecessary on a fundamental downstream task, abstract visual reasoning. We provide extensive empirical evidence against the necessity of disentanglement, covering multiple datasets, representation learning methods, and downstream network architectures. Furthermore, our findings suggest that the informativeness of representations is a better indicator of downstream performance than disentanglement. Finally, the positive correlation between informativeness and disentanglement e",
    "path": "papers/24/03/2403.00352.json",
    "total_tokens": 794,
    "translated_title": "重新审视下游任务中的解缠：对抽象视觉推理必要性的研究",
    "translated_abstract": "在表示学习中，解缠表示尤为理想，因为它以可分离且紧凑的模式编码数据的生成因子。研究人员倡导利用解缠表示完成下游任务，并提供了令人鼓舞的实证证据。本文进一步探讨了解缠表示在下游应用中的必要性。具体而言，我们展示了在基本的下游任务——抽象视觉推理中，基于维度的解缠表示是不必要的。我们提供了大量的实证证据，反驳了解缠的必要性，涵盖了多个数据集、表示学习方法和下游网络架构。此外，我们的发现表明，表示信息量的丰富程度是下游性能的更好指标，而不是解缠。最后，我们的研究还发现，表示信息量与解缠之间存在积极的相关性。",
    "tldr": "解缠表示对抽象视觉推理这一基本下游任务是不必要的，表示信息量的丰富程度更能影响下游性能。"
}