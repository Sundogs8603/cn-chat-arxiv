{
    "title": "Graph Unlearning with Efficient Partial Retraining",
    "abstract": "arXiv:2403.07353v1 Announce Type: new  Abstract: Graph Neural Networks (GNNs) have achieved remarkable success in various real-world applications. However, GNNs may be trained on undesirable graph data, which can degrade their performance and reliability. To enable trained GNNs to efficiently unlearn unwanted data, a desirable solution is retraining-based graph unlearning, which partitions the training graph into subgraphs and trains sub-models on them, allowing fast unlearning through partial retraining. However, the graph partition process causes information loss in the training graph, resulting in the low model utility of sub-GNN models. In this paper, we propose GraphRevoker, a novel graph unlearning framework that better maintains the model utility of unlearnable GNNs. Specifically, we preserve the graph property with graph property-aware sharding and effectively aggregate the sub-GNN models for prediction with graph contrastive sub-model aggregation. We conduct extensive experime",
    "link": "https://arxiv.org/abs/2403.07353",
    "context": "Title: Graph Unlearning with Efficient Partial Retraining\nAbstract: arXiv:2403.07353v1 Announce Type: new  Abstract: Graph Neural Networks (GNNs) have achieved remarkable success in various real-world applications. However, GNNs may be trained on undesirable graph data, which can degrade their performance and reliability. To enable trained GNNs to efficiently unlearn unwanted data, a desirable solution is retraining-based graph unlearning, which partitions the training graph into subgraphs and trains sub-models on them, allowing fast unlearning through partial retraining. However, the graph partition process causes information loss in the training graph, resulting in the low model utility of sub-GNN models. In this paper, we propose GraphRevoker, a novel graph unlearning framework that better maintains the model utility of unlearnable GNNs. Specifically, we preserve the graph property with graph property-aware sharding and effectively aggregate the sub-GNN models for prediction with graph contrastive sub-model aggregation. We conduct extensive experime",
    "path": "papers/24/03/2403.07353.json",
    "total_tokens": 771,
    "translated_title": "具有高效部分重新训练的图去除方法",
    "translated_abstract": "图神经网络（GNNs）在各种现实世界应用中取得了显著成功。然而，GNNs 可能会在不良的图数据上进行训练，这可能会降低它们的性能和可靠性。为了让已经训练过的GNNs能够有效地去除不需要的数据，一种理想的解决方案是基于重新训练的图去除方法，该方法将训练图分成子图，并在其上训练子模型，从而通过部分重新训练实现快速去除。然而，图分区过程会导致训练图中的信息丢失，从而导致子GNN模型的模型效用较低。",
    "tldr": "提出了一种新颖的图去除框架GraphRevoker，通过图属性感知划分和图对比子模型聚合，更好地保持了不可训练GNNs的模型效用。",
    "en_tdlr": "Introducing GraphRevoker, a novel framework for graph unlearning that better preserves the model utility of unlearnable GNNs through graph property-aware sharding and graph contrastive sub-model aggregation."
}