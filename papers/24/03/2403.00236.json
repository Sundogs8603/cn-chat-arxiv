{
    "title": "Benchmarking zero-shot stance detection with FlanT5-XXL: Insights from training data, prompting, and decoding strategies into its near-SoTA performance",
    "abstract": "arXiv:2403.00236v1 Announce Type: cross  Abstract: We investigate the performance of LLM-based zero-shot stance detection on tweets. Using FlanT5-XXL, an instruction-tuned open-source LLM, with the SemEval 2016 Tasks 6A, 6B, and P-Stance datasets, we study the performance and its variations under different prompts and decoding strategies, as well as the potential biases of the model. We show that the zero-shot approach can match or outperform state-of-the-art benchmarks, including fine-tuned models. We provide various insights into its performance including the sensitivity to instructions and prompts, the decoding strategies, the perplexity of the prompts, and to negations and oppositions present in prompts. Finally, we ensure that the LLM has not been trained on test datasets, and identify a positivity bias which may partially explain the performance differences across decoding strategie",
    "link": "https://arxiv.org/abs/2403.00236",
    "context": "Title: Benchmarking zero-shot stance detection with FlanT5-XXL: Insights from training data, prompting, and decoding strategies into its near-SoTA performance\nAbstract: arXiv:2403.00236v1 Announce Type: cross  Abstract: We investigate the performance of LLM-based zero-shot stance detection on tweets. Using FlanT5-XXL, an instruction-tuned open-source LLM, with the SemEval 2016 Tasks 6A, 6B, and P-Stance datasets, we study the performance and its variations under different prompts and decoding strategies, as well as the potential biases of the model. We show that the zero-shot approach can match or outperform state-of-the-art benchmarks, including fine-tuned models. We provide various insights into its performance including the sensitivity to instructions and prompts, the decoding strategies, the perplexity of the prompts, and to negations and oppositions present in prompts. Finally, we ensure that the LLM has not been trained on test datasets, and identify a positivity bias which may partially explain the performance differences across decoding strategie",
    "path": "papers/24/03/2403.00236.json",
    "total_tokens": 914,
    "translated_title": "使用FlanT5-XXL进行零-shot立场检测的基准测试：从训练数据、提示和解码策略中探讨其接近SOTA的表现",
    "translated_abstract": "我们研究了基于LLM的零-shot立场检测在推特上的表现。使用FlanT5-XXL，一个经过调整指令的开源LLM，在SemEval 2016任务6A、6B和P-Stance数据集上，我们研究了在不同提示和解码策略下的表现及其变化，以及模型的潜在偏见。我们展示零-shot方法可以匹敌甚至胜过最先进的基准测试，包括微调模型。我们提供了对其表现的各种见解，包括对指令和提示的敏感性，解码策略，提示的困惑度，以及提示中存在的否定和反对。最后，我们确保LLM没有在测试数据集上进行训练，并确定了一种可能部分解释解码策略之间表现差异的积极偏见。",
    "tldr": "通过使用FlanT5-XXL和SemEval 2016数据集，研究了零-shot立场检测在推特上的性能表现及其对提示和解码策略的敏感性，揭示了其能够匹敌或超越最先进基准测试的能力，并识别了其中的潜在偏见。"
}