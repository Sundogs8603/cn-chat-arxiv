{
    "title": "Just another copy and paste? Comparing the security vulnerabilities of ChatGPT generated code and StackOverflow answers",
    "abstract": "arXiv:2403.15600v1 Announce Type: cross  Abstract: Sonatype's 2023 report found that 97% of developers and security leads integrate generative Artificial Intelligence (AI), particularly Large Language Models (LLMs), into their development process. Concerns about the security implications of this trend have been raised. Developers are now weighing the benefits and risks of LLMs against other relied-upon information sources, such as StackOverflow (SO), requiring empirical data to inform their choice. In this work, our goal is to raise software developers awareness of the security implications when selecting code snippets by empirically comparing the vulnerabilities of ChatGPT and StackOverflow. To achieve this, we used an existing Java dataset from SO with security-related questions and answers. Then, we asked ChatGPT the same SO questions, gathering the generated code for comparison. After curating the dataset, we analyzed the number and types of Common Weakness Enumeration (CWE) vulner",
    "link": "https://arxiv.org/abs/2403.15600",
    "context": "Title: Just another copy and paste? Comparing the security vulnerabilities of ChatGPT generated code and StackOverflow answers\nAbstract: arXiv:2403.15600v1 Announce Type: cross  Abstract: Sonatype's 2023 report found that 97% of developers and security leads integrate generative Artificial Intelligence (AI), particularly Large Language Models (LLMs), into their development process. Concerns about the security implications of this trend have been raised. Developers are now weighing the benefits and risks of LLMs against other relied-upon information sources, such as StackOverflow (SO), requiring empirical data to inform their choice. In this work, our goal is to raise software developers awareness of the security implications when selecting code snippets by empirically comparing the vulnerabilities of ChatGPT and StackOverflow. To achieve this, we used an existing Java dataset from SO with security-related questions and answers. Then, we asked ChatGPT the same SO questions, gathering the generated code for comparison. After curating the dataset, we analyzed the number and types of Common Weakness Enumeration (CWE) vulner",
    "path": "papers/24/03/2403.15600.json",
    "total_tokens": 872,
    "translated_title": "仅仅又是复制粘贴吗？比较ChatGPT生成代码和StackOverflow答案的安全漏洞",
    "translated_abstract": "arXiv：2403.15600v1 发布类型：跨  摘要：Sonatype的2023年报告发现，97%的开发人员和安全负责人将生成式人工智能（AI），特别是大型语言模型（LLMs），集成到他们的开发流程中。对这一趋势的安全影响引起了人们的担忧。开发人员现在正在权衡LLMs相对于其他可靠信息来源（如StackOverflow（SO））的好处和风险，需要实证数据来指导他们的选择。在这项工作中，我们的目标是通过实证比较ChatGPT和StackOverflow的漏洞，引起软件开发人员选择代码片段时的安全影响意识。为了实现这一目标，我们使用了来自SO的与安全相关问题和答案的现有Java数据集。然后，我们询问ChatGPT相同的SO问题，收集生成的代码进行比较。在整理数据集后，我们分析了Common Weakness Enumeration (CWE) 漏洞的数量和类型。",
    "tldr": "本研究通过实证比较ChatGPT生成的代码和StackOverflow答案，提高软件开发人员在选择代码片段时对安全漏洞的认识。",
    "en_tdlr": "This study raises awareness among software developers about the security implications when selecting code snippets by empirically comparing the vulnerabilities of ChatGPT generated code and StackOverflow answers."
}