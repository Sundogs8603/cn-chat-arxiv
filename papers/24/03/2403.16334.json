{
    "title": "Graphs Generalization under Distribution Shifts",
    "abstract": "arXiv:2403.16334v1 Announce Type: cross  Abstract: Traditional machine learning methods heavily rely on the independent and identically distribution assumption, which imposes limitations when the test distribution deviates from the training distribution. To address this crucial issue, out-of-distribution (OOD) generalization, which aims to achieve satisfactory generalization performance when faced with unknown distribution shifts, has made a significant process. However, the OOD method for graph-structured data currently lacks clarity and remains relatively unexplored due to two primary challenges. Firstly, distribution shifts on graphs often occur simultaneously on node attributes and graph topology. Secondly, capturing invariant information amidst diverse distribution shifts proves to be a formidable challenge. To overcome these obstacles, in this paper, we introduce a novel framework, namely Graph Learning Invariant Domain genERation (GLIDER). The goal is to (1) diversify variations",
    "link": "https://arxiv.org/abs/2403.16334",
    "context": "Title: Graphs Generalization under Distribution Shifts\nAbstract: arXiv:2403.16334v1 Announce Type: cross  Abstract: Traditional machine learning methods heavily rely on the independent and identically distribution assumption, which imposes limitations when the test distribution deviates from the training distribution. To address this crucial issue, out-of-distribution (OOD) generalization, which aims to achieve satisfactory generalization performance when faced with unknown distribution shifts, has made a significant process. However, the OOD method for graph-structured data currently lacks clarity and remains relatively unexplored due to two primary challenges. Firstly, distribution shifts on graphs often occur simultaneously on node attributes and graph topology. Secondly, capturing invariant information amidst diverse distribution shifts proves to be a formidable challenge. To overcome these obstacles, in this paper, we introduce a novel framework, namely Graph Learning Invariant Domain genERation (GLIDER). The goal is to (1) diversify variations",
    "path": "papers/24/03/2403.16334.json",
    "total_tokens": 778,
    "translated_title": "图在分布转移下的泛化",
    "translated_abstract": "传统的机器学习方法严重依赖于独立同分布的假设，当测试分布与训练分布有所偏离时会受到限制。为了解决这一关键问题，针对已知分布转移而达到令人满意的泛化性能。然而，目前针对图结构数据的分布外泛化方法存在缺乏明晰性且尚未得到充分探索，主要由于两个主要挑战。首先，图中的分布转移通常同时发生在节点属性和图拓扑上。其次，在各种分布转移中捕获不变信息被证明是一个极具挑战性的问题。为了克服这些障碍，本文提出了一种全新的框架，即图学习不变域生成（GLIDER）。其目标是(1)多样化变化",
    "tldr": "本文介绍了一种名为GLIDER的新框架，旨在解决图结构数据中分布转移带来的挑战，并实现泛化性能优越。",
    "en_tdlr": "This paper introduces a novel framework called GLIDER to address the challenges of distribution shifts in graph-structured data and achieve superior generalization performance."
}