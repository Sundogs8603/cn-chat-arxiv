{
    "title": "Characterization of Large Language Model Development in the Datacenter",
    "abstract": "arXiv:2403.07648v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have presented impressive performance across several transformative tasks. However, it is non-trivial to efficiently utilize large-scale cluster resources to develop LLMs, often riddled with numerous challenges such as frequent hardware failures, intricate parallelization strategies, and imbalanced resource utilization. In this paper, we present an in-depth characterization study of a six-month LLM development workload trace collected from our GPU datacenter Acme. Specifically, we investigate discrepancies between LLMs and prior task-specific Deep Learning (DL) workloads, explore resource utilization patterns, and identify the impact of various job failures. Our analysis summarizes hurdles we encountered and uncovers potential opportunities to optimize systems tailored for LLMs. Furthermore, we introduce our system efforts: (1) fault-tolerant pretraining, which enhances fault tolerance through LLM-involved ",
    "link": "https://arxiv.org/abs/2403.07648",
    "context": "Title: Characterization of Large Language Model Development in the Datacenter\nAbstract: arXiv:2403.07648v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have presented impressive performance across several transformative tasks. However, it is non-trivial to efficiently utilize large-scale cluster resources to develop LLMs, often riddled with numerous challenges such as frequent hardware failures, intricate parallelization strategies, and imbalanced resource utilization. In this paper, we present an in-depth characterization study of a six-month LLM development workload trace collected from our GPU datacenter Acme. Specifically, we investigate discrepancies between LLMs and prior task-specific Deep Learning (DL) workloads, explore resource utilization patterns, and identify the impact of various job failures. Our analysis summarizes hurdles we encountered and uncovers potential opportunities to optimize systems tailored for LLMs. Furthermore, we introduce our system efforts: (1) fault-tolerant pretraining, which enhances fault tolerance through LLM-involved ",
    "path": "papers/24/03/2403.07648.json",
    "total_tokens": 894,
    "translated_title": "大型语言模型在数据中心开发的特征化研究",
    "translated_abstract": "大型语言模型（LLMs）在多个革命性任务上展现出了令人印象深刻的性能。然而，要有效利用大规模集群资源来开发LLMs并非易事，经常面临诸多挑战，如频繁的硬件故障、复杂的并行化策略和资源利用不平衡。本文对我们的GPU数据中心Acme中收集的为期六个月的LLM开发工作负载跟踪进行了深入的特征化研究。具体地，我们调查了LLMs与先前任务特定的深度学习（DL）工作负载之间的差异，探索了资源利用模式，并确定了各种作业故障的影响。我们的分析总结了我们遇到的障碍，并发现了优化专为LLMs定制的系统的潜在机会。此外，我们介绍了我们的系统努力：（1）容错预训练，通过LLM参与来增强容错能力。",
    "tldr": "本研究对大型语言模型的开发工作负载进行了深入特征化研究，发现了与先前任务特定深度学习工作负载的差异，探索了资源利用模式，并提出了优化系统以适应LLMs的潜在机会。"
}