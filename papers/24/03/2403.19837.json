{
    "title": "Concept-based Analysis of Neural Networks via Vision-Language Models",
    "abstract": "arXiv:2403.19837v1 Announce Type: cross  Abstract: Formal analysis of vision-based deep neural networks (DNNs) is highly desirable but it is very challenging due to the difficulty of expressing formal specifications for vision tasks and the lack of efficient verification procedures. In this paper, we propose to leverage emerging multimodal, vision-language, foundation models (VLMs) as a lens through which we can reason about vision models. VLMs have been trained on a large body of images accompanied by their textual description, and are thus implicitly aware of high-level, human-understandable concepts describing the images. We describe a logical specification language $\\texttt{Con}_{\\texttt{spec}}$ designed to facilitate writing specifications in terms of these concepts. To define and formally check $\\texttt{Con}_{\\texttt{spec}}$ specifications, we leverage a VLM, which provides a means to encode and efficiently check natural-language properties of vision models. We demonstrate our te",
    "link": "https://arxiv.org/abs/2403.19837",
    "context": "Title: Concept-based Analysis of Neural Networks via Vision-Language Models\nAbstract: arXiv:2403.19837v1 Announce Type: cross  Abstract: Formal analysis of vision-based deep neural networks (DNNs) is highly desirable but it is very challenging due to the difficulty of expressing formal specifications for vision tasks and the lack of efficient verification procedures. In this paper, we propose to leverage emerging multimodal, vision-language, foundation models (VLMs) as a lens through which we can reason about vision models. VLMs have been trained on a large body of images accompanied by their textual description, and are thus implicitly aware of high-level, human-understandable concepts describing the images. We describe a logical specification language $\\texttt{Con}_{\\texttt{spec}}$ designed to facilitate writing specifications in terms of these concepts. To define and formally check $\\texttt{Con}_{\\texttt{spec}}$ specifications, we leverage a VLM, which provides a means to encode and efficiently check natural-language properties of vision models. We demonstrate our te",
    "path": "papers/24/03/2403.19837.json",
    "total_tokens": 841,
    "translated_title": "通过视觉语言模型对神经网络进行基于概念的分析",
    "translated_abstract": "视觉深度神经网络（DNNs）的形式化分析非常可取，但由于难以表达视觉任务的形式化规范以及缺乏高效的验证程序，这是非常具有挑战性的。在本文中，我们提出利用新兴的多模态、视觉语言、基础模型（VLMs）作为一种通过其可以推理视觉模型的透镜。VLMs已经在大量图像及其文本描述上进行了训练，因此隐式地了解描述这些图像的高层次、人类可理解的概念。我们描述了一种名为$\\texttt{Con}_{\\texttt{spec}}$的逻辑规范语言，旨在便于按照这些概念编写规范。为了定义和形式化检查$\\texttt{Con}_{\\texttt{spec}}$规范，我们利用了一个VLM，它提供了一种编码和高效检查视觉模型的自然语言属性的方法。我们展示了我们的te",
    "tldr": "本文提出利用视觉语言模型作为透镜，通过其隐含的高层次概念来进行对视觉模型的分析。",
    "en_tdlr": "This paper proposes leveraging vision-language models as a lens to analyze vision models based on their implicitly understanding high-level concepts."
}