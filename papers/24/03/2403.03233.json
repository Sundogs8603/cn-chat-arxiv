{
    "title": "From Displacements to Distributions: A Machine-Learning Enabled Framework for Quantifying Uncertainties in Parameters of Computational Models",
    "abstract": "arXiv:2403.03233v1 Announce Type: cross  Abstract: This work presents novel extensions for combining two frameworks for quantifying both aleatoric (i.e., irreducible) and epistemic (i.e., reducible) sources of uncertainties in the modeling of engineered systems. The data-consistent (DC) framework poses an inverse problem and solution for quantifying aleatoric uncertainties in terms of pullback and push-forward measures for a given Quantity of Interest (QoI) map. Unfortunately, a pre-specified QoI map is not always available a priori to the collection of data associated with system outputs. The data themselves are often polluted with measurement errors (i.e., epistemic uncertainties), which complicates the process of specifying a useful QoI. The Learning Uncertain Quantities (LUQ) framework defines a formal three-step machine-learning enabled process for transforming noisy datasets into samples of a learned QoI map to enable DC-based inversion. We develop a robust filtering step in LUQ ",
    "link": "https://arxiv.org/abs/2403.03233",
    "context": "Title: From Displacements to Distributions: A Machine-Learning Enabled Framework for Quantifying Uncertainties in Parameters of Computational Models\nAbstract: arXiv:2403.03233v1 Announce Type: cross  Abstract: This work presents novel extensions for combining two frameworks for quantifying both aleatoric (i.e., irreducible) and epistemic (i.e., reducible) sources of uncertainties in the modeling of engineered systems. The data-consistent (DC) framework poses an inverse problem and solution for quantifying aleatoric uncertainties in terms of pullback and push-forward measures for a given Quantity of Interest (QoI) map. Unfortunately, a pre-specified QoI map is not always available a priori to the collection of data associated with system outputs. The data themselves are often polluted with measurement errors (i.e., epistemic uncertainties), which complicates the process of specifying a useful QoI. The Learning Uncertain Quantities (LUQ) framework defines a formal three-step machine-learning enabled process for transforming noisy datasets into samples of a learned QoI map to enable DC-based inversion. We develop a robust filtering step in LUQ ",
    "path": "papers/24/03/2403.03233.json",
    "total_tokens": 929,
    "translated_title": "从位移到分布：一种用于量化计算模型参数不确定性的机器学习框架",
    "translated_abstract": "这项工作提出了结合两种框架的新扩展，用于量化工程系统建模中的混合不确定性源，即aleatoric（即不可减少的）和epistemic（即可减少的）。数据一致性（DC）框架提出了一个逆问题和解决方案，以量化以给定量化兴趣图定的回拉和推进测度的aleatoric不确定性。不幸的是，预先指定的兴趣数量映射并不总是在与系统输出相关的数据收集之前是可用的。数据本身经常受到测量误差（即epistemic不确定性）的污染，这使得指定一个有用的兴趣数量映射的过程变得复杂。学习不确定量（LUQ）框架定义了一个正式的三步机器学习启用过程，用于将嘈杂数据集转化为学习到的兴趣的映射样本，以启用基于DC的反演。我们在LUQ中开发了一个强大的过滤步骤。",
    "tldr": "该论文提出了一种机器学习框架，可以量化计算模型参数不确定性的两种来源，通过结合数据一致性和学习不确定量框架，可以有效处理测量误差和兴趣数量映射问题"
}