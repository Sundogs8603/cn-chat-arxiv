{
    "title": "Evaluating Explanatory Capabilities of Machine Learning Models in Medical Diagnostics: A Human-in-the-Loop Approach",
    "abstract": "arXiv:2403.19820v1 Announce Type: cross  Abstract: This paper presents a comprehensive study on the evaluation of explanatory capabilities of machine learning models, with a focus on Decision Trees, Random Forest and XGBoost models using a pancreatic cancer dataset. We use Human-in-the-Loop related techniques and medical guidelines as a source of domain knowledge to establish the importance of the different features that are relevant to establish a pancreatic cancer treatment. These features are not only used as a dimensionality reduction approach for the machine learning models, but also as way to evaluate the explainability capabilities of the different models using agnostic and non-agnostic explainability techniques. To facilitate interpretation of explanatory results, we propose the use of similarity measures such as the Weighted Jaccard Similarity coefficient. The goal is to not only select the best performing model but also the one that can best explain its conclusions and aligns",
    "link": "https://arxiv.org/abs/2403.19820",
    "context": "Title: Evaluating Explanatory Capabilities of Machine Learning Models in Medical Diagnostics: A Human-in-the-Loop Approach\nAbstract: arXiv:2403.19820v1 Announce Type: cross  Abstract: This paper presents a comprehensive study on the evaluation of explanatory capabilities of machine learning models, with a focus on Decision Trees, Random Forest and XGBoost models using a pancreatic cancer dataset. We use Human-in-the-Loop related techniques and medical guidelines as a source of domain knowledge to establish the importance of the different features that are relevant to establish a pancreatic cancer treatment. These features are not only used as a dimensionality reduction approach for the machine learning models, but also as way to evaluate the explainability capabilities of the different models using agnostic and non-agnostic explainability techniques. To facilitate interpretation of explanatory results, we propose the use of similarity measures such as the Weighted Jaccard Similarity coefficient. The goal is to not only select the best performing model but also the one that can best explain its conclusions and aligns",
    "path": "papers/24/03/2403.19820.json",
    "total_tokens": 869,
    "translated_title": "评估医疗诊断中机器学习模型的解释能力：一种人机协作方法",
    "translated_abstract": "本文针对决策树、随机森林和XGBoost模型在胰腺癌数据集上的解释能力进行了全面研究。我们利用人机协作技术和医学指南作为领域知识来源，以确定与制定胰腺癌治疗相关的不同特征的重要性。这些特征不仅用作机器学习模型的降维方法，还用作评估不同模型的可解释性能力的方式，使用无知和非无知的解释性技术。为了便于解释结果的解释，我们提出使用诸如加权杰卡相似系数之类的相似度衡量。我们的目标不仅是选择性能最佳的模型，还要选择能够最好解释其结论并与之保持一致的模型。",
    "tldr": "通过人机协作方法，评估医疗诊断中机器学习模型的解释能力，提出了使用医学指南和特征重要性确定胰腺癌治疗关键特征的方法，同时探索了使用相似度衡量的解释结果的方法。",
    "en_tdlr": "By employing a human-in-the-loop approach, this study evaluates the explanatory capabilities of machine learning models in medical diagnostics, proposes the method of using medical guidelines and feature importance to determine key features for pancreatic cancer treatment, and explores the approach of interpreting results using similarity measures."
}