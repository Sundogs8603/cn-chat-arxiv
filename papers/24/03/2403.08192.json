{
    "title": "MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension",
    "abstract": "arXiv:2403.08192v1 Announce Type: new  Abstract: Large language models are playing an increasingly significant role in molecular research, yet existing models often generate erroneous information, posing challenges to accurate molecular comprehension. Traditional evaluation metrics for generated content fail to assess a model's accuracy in molecular understanding. To rectify the absence of factual evaluation, we present MoleculeQA, a novel question answering (QA) dataset which possesses 62K QA pairs over 23K molecules. Each QA pair, composed of a manual question, a positive option and three negative options, has consistent semantics with a molecular description from authoritative molecular corpus. MoleculeQA is not only the first benchmark for molecular factual bias evaluation but also the largest QA dataset for molecular research. A comprehensive evaluation on MoleculeQA for existing molecular LLMs exposes their deficiencies in specific areas and pinpoints several particularly crucial",
    "link": "https://arxiv.org/abs/2403.08192",
    "context": "Title: MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension\nAbstract: arXiv:2403.08192v1 Announce Type: new  Abstract: Large language models are playing an increasingly significant role in molecular research, yet existing models often generate erroneous information, posing challenges to accurate molecular comprehension. Traditional evaluation metrics for generated content fail to assess a model's accuracy in molecular understanding. To rectify the absence of factual evaluation, we present MoleculeQA, a novel question answering (QA) dataset which possesses 62K QA pairs over 23K molecules. Each QA pair, composed of a manual question, a positive option and three negative options, has consistent semantics with a molecular description from authoritative molecular corpus. MoleculeQA is not only the first benchmark for molecular factual bias evaluation but also the largest QA dataset for molecular research. A comprehensive evaluation on MoleculeQA for existing molecular LLMs exposes their deficiencies in specific areas and pinpoints several particularly crucial",
    "path": "papers/24/03/2403.08192.json",
    "total_tokens": 850,
    "translated_title": "MoleculeQA: 一个用于评估分子理解中事实准确性的数据集",
    "translated_abstract": "大型语言模型在分子研究中发挥越来越重要的作用，然而现有模型通常生成错误信息，给准确的分子理解带来挑战。传统的生成内容评估指标无法评估模型在分子理解中的准确性。为了纠正事实评估的缺失，我们提出了MoleculeQA，这是一个新颖的问题回答（QA）数据集，其中包含了23K个分子的62K个QA对。每个QA对由一个手动问题、一个正选项和三个负选项组成，并且与权威分子语料库中的分子描述具有一致的语义。MoleculeQA不仅是用于分子事实偏见评估的第一个基准，也是用于分子研究的最大QA数据集。对现有分子LLMs在MoleculeQA上进行的全面评估揭示了它们在特定领域的不足之处，并指出了一些特别关键的问题。",
    "tldr": "MoleculeQA是一个用于评估分子理解中事实准确性的数据集，具有62K个QA对，是第一个分子事实偏见评估的基准，也是最大的分子研究QA数据集。",
    "en_tdlr": "MoleculeQA is a dataset for evaluating factual accuracy in molecular comprehension, with 62K QA pairs, serving as the first benchmark for molecular factual bias evaluation and the largest QA dataset for molecular research."
}