{
    "title": "Exploring Chinese Humor Generation: A Study on Two-Part Allegorical Sayings",
    "abstract": "arXiv:2403.10781v1 Announce Type: cross  Abstract: Humor, a culturally nuanced aspect of human language, poses challenges for computational understanding and generation, especially in Chinese humor, which remains relatively unexplored in the NLP community. This paper investigates the capability of state-of-the-art language models to comprehend and generate Chinese humor, specifically focusing on training them to create allegorical sayings. We employ two prominent training methods: fine-tuning a medium-sized language model and prompting a large one. Our novel fine-tuning approach incorporates fused Pinyin embeddings to consider homophones and employs contrastive learning with synthetic hard negatives to distinguish humor elements. Human-annotated results show that these models can generate humorous allegorical sayings, with prompting proving to be a practical and effective method. However, there is still room for improvement in generating allegorical sayings that match human creativity.",
    "link": "https://arxiv.org/abs/2403.10781",
    "context": "Title: Exploring Chinese Humor Generation: A Study on Two-Part Allegorical Sayings\nAbstract: arXiv:2403.10781v1 Announce Type: cross  Abstract: Humor, a culturally nuanced aspect of human language, poses challenges for computational understanding and generation, especially in Chinese humor, which remains relatively unexplored in the NLP community. This paper investigates the capability of state-of-the-art language models to comprehend and generate Chinese humor, specifically focusing on training them to create allegorical sayings. We employ two prominent training methods: fine-tuning a medium-sized language model and prompting a large one. Our novel fine-tuning approach incorporates fused Pinyin embeddings to consider homophones and employs contrastive learning with synthetic hard negatives to distinguish humor elements. Human-annotated results show that these models can generate humorous allegorical sayings, with prompting proving to be a practical and effective method. However, there is still room for improvement in generating allegorical sayings that match human creativity.",
    "path": "papers/24/03/2403.10781.json",
    "total_tokens": 924,
    "translated_title": "探索中国幽默生成：关于两句典故谚语的研究",
    "translated_abstract": "幽默是人类语言中富有文化内涵的一个方面，对于计算机理解和生成而言具有挑战性，尤其是在相对未被自然语言处理社区探索的中国幽默领域。本文研究了最先进语言模型在理解和生成中国幽默方面的能力，特别聚焦于训练它们创造典故谚语。我们采用了两种显著的训练方法：调整一个中等规模的语言模型和提示一个大型模型。我们的新颖调整方法融合了拼音嵌入以考虑同音异义词，并采用对比学习与合成困难性负例以区分幽默元素。人类注释的结果显示这些模型能够生成幽默的典故谚语，提示法证明是一个实用且有效的方法。然而，在生成与人类创造力匹配的典故谚语方面仍有改进空间。",
    "tldr": "本文研究了如何利用最先进的语言模型来理解和生成中国幽默，特别是关于训练模型生成典故谚语。他们采用新颖的fine-tuning方法，包含融合拼音嵌入和对比学习，从而成功生成幽默性典故谚语。",
    "en_tdlr": "This paper explores the capability of state-of-the-art language models in comprehending and generating Chinese humor, specifically focusing on training them to create allegorical sayings. Their novel fine-tuning approach, incorporating fused Pinyin embeddings and contrastive learning, successfully generates humorous allegorical sayings."
}