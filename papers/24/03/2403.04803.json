{
    "title": "Enhancing Security in Federated Learning through Adaptive Consensus-Based Model Update Validation",
    "abstract": "arXiv:2403.04803v1 Announce Type: cross  Abstract: This paper introduces an advanced approach for fortifying Federated Learning (FL) systems against label-flipping attacks. We propose a simplified consensus-based verification process integrated with an adaptive thresholding mechanism. This dynamic thresholding is designed to adjust based on the evolving landscape of model updates, offering a refined layer of anomaly detection that aligns with the real-time needs of distributed learning environments. Our method necessitates a majority consensus among participating clients to validate updates, ensuring that only vetted and consensual modifications are applied to the global model. The efficacy of our approach is validated through experiments on two benchmark datasets in deep learning, CIFAR-10 and MNIST. Our results indicate a significant mitigation of label-flipping attacks, bolstering the FL system's resilience. This method transcends conventional techniques that depend on anomaly detec",
    "link": "https://arxiv.org/abs/2403.04803",
    "context": "Title: Enhancing Security in Federated Learning through Adaptive Consensus-Based Model Update Validation\nAbstract: arXiv:2403.04803v1 Announce Type: cross  Abstract: This paper introduces an advanced approach for fortifying Federated Learning (FL) systems against label-flipping attacks. We propose a simplified consensus-based verification process integrated with an adaptive thresholding mechanism. This dynamic thresholding is designed to adjust based on the evolving landscape of model updates, offering a refined layer of anomaly detection that aligns with the real-time needs of distributed learning environments. Our method necessitates a majority consensus among participating clients to validate updates, ensuring that only vetted and consensual modifications are applied to the global model. The efficacy of our approach is validated through experiments on two benchmark datasets in deep learning, CIFAR-10 and MNIST. Our results indicate a significant mitigation of label-flipping attacks, bolstering the FL system's resilience. This method transcends conventional techniques that depend on anomaly detec",
    "path": "papers/24/03/2403.04803.json",
    "total_tokens": 833,
    "translated_title": "通过自适应共识验证模型更新，增强联邦学习的安全性",
    "translated_abstract": "本文介绍了一种先进的方法，用于加强联邦学习（FL）系统抵御标签翻转攻击。我们提出了一个简化的基于共识的验证流程，结合自适应阈值机制。这种动态阈值设计旨在根据模型更新的发展情况进行调整，提供了一个精细的异常检测层，与分布式学习环境的实时需求保持一致。我们的方法需要参与客户之间达成多数共识才能验证更新，确保只有经过审查和共识的修改才应用于全局模型。我们通过在深度学习的两个基准数据集CIFAR-10和MNIST上进行实验验证了我们方法的有效性。我们的结果表明，标签翻转攻击得到了显著减轻，增强了FL系统的弹性。这种方法超越了依赖异常检测的传统技术。",
    "tldr": "通过自适应阈值机制和共识验证流程，增强了联邦学习系统对标签翻转攻击的安全性，有效减轻了攻击并提升系统的弹性。",
    "en_tdlr": "Enhanced security in Federated Learning against label-flipping attacks by introducing adaptive thresholding and consensus-based validation process, mitigating attacks significantly and enhancing system resilience."
}