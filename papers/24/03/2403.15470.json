{
    "title": "Vi-Mistral-X: Building a Vietnamese Language Model with Advanced Continual Pre-training",
    "abstract": "arXiv:2403.15470v1 Announce Type: new  Abstract: The advancement of Large Language Models (LLMs) has significantly transformed the field of natural language processing, although the focus on English-centric models has created a noticeable research gap for specific languages, including Vietnamese. To address this issue, this paper presents vi-mistral-x, an innovative Large Language Model designed expressly for the Vietnamese language. It utilizes a unique method of continual pre-training, based on the Mistral architecture, which incorporates grouped-query attention and sliding window attention techniques. This model, vi-Mistral-X, marks a significant step forward in improving the understanding and generation of the Vietnamese language. It introduces an additional phase of continual pre-training, specifically adapted for Vietnamese, enhancing the model's capability in understanding complex language nuances and generating accurate, context-aware Vietnamese text. Through comprehensive test",
    "link": "https://arxiv.org/abs/2403.15470",
    "context": "Title: Vi-Mistral-X: Building a Vietnamese Language Model with Advanced Continual Pre-training\nAbstract: arXiv:2403.15470v1 Announce Type: new  Abstract: The advancement of Large Language Models (LLMs) has significantly transformed the field of natural language processing, although the focus on English-centric models has created a noticeable research gap for specific languages, including Vietnamese. To address this issue, this paper presents vi-mistral-x, an innovative Large Language Model designed expressly for the Vietnamese language. It utilizes a unique method of continual pre-training, based on the Mistral architecture, which incorporates grouped-query attention and sliding window attention techniques. This model, vi-Mistral-X, marks a significant step forward in improving the understanding and generation of the Vietnamese language. It introduces an additional phase of continual pre-training, specifically adapted for Vietnamese, enhancing the model's capability in understanding complex language nuances and generating accurate, context-aware Vietnamese text. Through comprehensive test",
    "path": "papers/24/03/2403.15470.json",
    "total_tokens": 864,
    "translated_title": "使用先进的持续预训练构建越南语言模型 Vi-Mistral-X",
    "translated_abstract": "大型语言模型（LLM）的进步显著改变了自然语言处理领域，尽管专注于英语中心模型导致了一些特定语言（包括越南语）的研究空白。为解决这一问题，本文介绍了vi-mistral-x，这是一个专为越南语设计的创新大型语言模型。它利用了基于 Mistral 架构的一种独特的持续预训练方法，其中包括分组查询注意力和滑动窗口注意力技术。该模型 vi-Mistral-X 在改进对越南语言的理解和生成方面迈出了重要一步。它引入了一个专门针对越南语的额外持续预训练阶段，增强了模型在理解复杂语言细微差别和生成准确、上下文感知的越南语文本方面的能力。通过全面的测试",
    "tldr": "该论文介绍了 vi-Mistral-X，一个专为越南语设计的创新大型语言模型，采用了持续预训练方法，并引入了针对越南语的额外预训练阶段，大大提高了其对越南语的理解和生成能力。"
}