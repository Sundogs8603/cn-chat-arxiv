{
    "title": "DEE: Dual-stage Explainable Evaluation Method for Text Generation",
    "abstract": "arXiv:2403.11509v1 Announce Type: new  Abstract: Automatic methods for evaluating machine-generated texts hold significant importance due to the expanding applications of generative systems. Conventional methods tend to grapple with a lack of explainability, issuing a solitary numerical score to signify the assessment outcome. Recent advancements have sought to mitigate this limitation by incorporating large language models (LLMs) to offer more detailed error analyses, yet their applicability remains constrained, particularly in industrial contexts where comprehensive error coverage and swift detection are paramount. To alleviate these challenges, we introduce DEE, a Dual-stage Explainable Evaluation method for estimating the quality of text generation. Built upon Llama 2, DEE follows a dual-stage principle guided by stage-specific instructions to perform efficient identification of errors in generated texts in the initial stage and subsequently delves into providing comprehensive diag",
    "link": "https://arxiv.org/abs/2403.11509",
    "context": "Title: DEE: Dual-stage Explainable Evaluation Method for Text Generation\nAbstract: arXiv:2403.11509v1 Announce Type: new  Abstract: Automatic methods for evaluating machine-generated texts hold significant importance due to the expanding applications of generative systems. Conventional methods tend to grapple with a lack of explainability, issuing a solitary numerical score to signify the assessment outcome. Recent advancements have sought to mitigate this limitation by incorporating large language models (LLMs) to offer more detailed error analyses, yet their applicability remains constrained, particularly in industrial contexts where comprehensive error coverage and swift detection are paramount. To alleviate these challenges, we introduce DEE, a Dual-stage Explainable Evaluation method for estimating the quality of text generation. Built upon Llama 2, DEE follows a dual-stage principle guided by stage-specific instructions to perform efficient identification of errors in generated texts in the initial stage and subsequently delves into providing comprehensive diag",
    "path": "papers/24/03/2403.11509.json",
    "total_tokens": 758,
    "translated_title": "DEE: 文本生成的双阶段可解释评估方法",
    "translated_abstract": "自动评估机器生成的文本的方法对于生成系统的应用日益广泛具有重要意义。传统方法往往很难解释性，发出一个孤立的数字评分来表示评估结果。最近的进展试图通过引入大型语言模型（LLMs）来提供更详细的错误分析来缓解这一局限，然而它们的适用性仍受限制，尤其是在全面覆盖错误和快速检测至关重要的工业背景下。为了解决这些挑战，我们介绍了DEE，一个用于评估文本生成质量的双阶段可解释评估方法。基于Llama 2构建的DEE遵循一个双阶段原则，根据各阶段的指导进行高效识别初始阶段生成文本中的错误，并随后着手提供全面的诊断。",
    "tldr": "介绍了DEE，一个双阶段可解释评估方法，用于评估文本生成质量。",
    "en_tdlr": "Introduced DEE, a dual-stage explainable evaluation method for assessing the quality of text generation."
}