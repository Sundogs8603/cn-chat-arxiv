{
    "title": "Neural Image Compression with Text-guided Encoding for both Pixel-level and Perceptual Fidelity",
    "abstract": "arXiv:2403.02944v1 Announce Type: cross  Abstract: Recent advances in text-guided image compression have shown great potential to enhance the perceptual quality of reconstructed images. These methods, however, tend to have significantly degraded pixel-wise fidelity, limiting their practicality. To fill this gap, we develop a new text-guided image compression algorithm that achieves both high perceptual and pixel-wise fidelity. In particular, we propose a compression framework that leverages text information mainly by text-adaptive encoding and training with joint image-text loss. By doing so, we avoid decoding based on text-guided generative models -- known for high generative diversity -- and effectively utilize the semantic information of text at a global level. Experimental results on various datasets show that our method can achieve high pixel-level and perceptual quality, with either human- or machine-generated captions. In particular, our method outperforms all baselines in terms",
    "link": "https://arxiv.org/abs/2403.02944",
    "context": "Title: Neural Image Compression with Text-guided Encoding for both Pixel-level and Perceptual Fidelity\nAbstract: arXiv:2403.02944v1 Announce Type: cross  Abstract: Recent advances in text-guided image compression have shown great potential to enhance the perceptual quality of reconstructed images. These methods, however, tend to have significantly degraded pixel-wise fidelity, limiting their practicality. To fill this gap, we develop a new text-guided image compression algorithm that achieves both high perceptual and pixel-wise fidelity. In particular, we propose a compression framework that leverages text information mainly by text-adaptive encoding and training with joint image-text loss. By doing so, we avoid decoding based on text-guided generative models -- known for high generative diversity -- and effectively utilize the semantic information of text at a global level. Experimental results on various datasets show that our method can achieve high pixel-level and perceptual quality, with either human- or machine-generated captions. In particular, our method outperforms all baselines in terms",
    "path": "papers/24/03/2403.02944.json",
    "total_tokens": 905,
    "translated_title": "用文本引导编码的神经图像压缩技术实现像素级和感知准确度的双重提升",
    "translated_abstract": "最近在文本引导图像压缩方面取得的进展显示出了提高重建图像感知质量的巨大潜力。然而，这些方法往往会导致像素级准确度明显降低，限制了它们的实用性。为了填补这一差距，我们开发了一种新的文本引导图像压缩算法，实现了高感知和像素级准确度。具体来说，我们提出了一种压缩框架，主要通过文本自适应编码和联合图像-文本损失训练来利用文本信息。这样一来，我们避免了基于文本引导生成模型进行解码的问题，这些模型以高生成多样性而闻名，并有效利用了文本的语义信息。在各种数据集上的实验结果表明，我们的方法可以实现高像素级和感知质量，无论是人类生成的标题还是机器生成的标题。特别是，我们的方法在所有基线模型中表现最佳。",
    "tldr": "该论文提出了一种新的文本引导图像压缩算法，实现了高感知和像素级准确度，并通过文本自适应编码和联合图像-文本损失训练，避免了像素级准确度下降的问题。",
    "en_tdlr": "This paper presents a novel text-guided image compression algorithm that achieves high perceptual and pixel-level fidelity, avoiding pixel-wise fidelity degradation through text-adaptive encoding and training with joint image-text loss."
}