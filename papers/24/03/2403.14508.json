{
    "title": "Constrained Reinforcement Learning with Smoothed Log Barrier Function",
    "abstract": "arXiv:2403.14508v1 Announce Type: cross  Abstract: Reinforcement Learning (RL) has been widely applied to many control tasks and substantially improved the performances compared to conventional control methods in many domains where the reward function is well defined. However, for many real-world problems, it is often more convenient to formulate optimization problems in terms of rewards and constraints simultaneously. Optimizing such constrained problems via reward shaping can be difficult as it requires tedious manual tuning of reward functions with several interacting terms. Recent formulations which include constraints mostly require a pre-training phase, which often needs human expertise to collect data or assumes having a sub-optimal policy readily available. We propose a new constrained RL method called CSAC-LB (Constrained Soft Actor-Critic with Log Barrier Function), which achieves competitive performance without any pre-training by applying a linear smoothed log barrier funct",
    "link": "https://arxiv.org/abs/2403.14508",
    "context": "Title: Constrained Reinforcement Learning with Smoothed Log Barrier Function\nAbstract: arXiv:2403.14508v1 Announce Type: cross  Abstract: Reinforcement Learning (RL) has been widely applied to many control tasks and substantially improved the performances compared to conventional control methods in many domains where the reward function is well defined. However, for many real-world problems, it is often more convenient to formulate optimization problems in terms of rewards and constraints simultaneously. Optimizing such constrained problems via reward shaping can be difficult as it requires tedious manual tuning of reward functions with several interacting terms. Recent formulations which include constraints mostly require a pre-training phase, which often needs human expertise to collect data or assumes having a sub-optimal policy readily available. We propose a new constrained RL method called CSAC-LB (Constrained Soft Actor-Critic with Log Barrier Function), which achieves competitive performance without any pre-training by applying a linear smoothed log barrier funct",
    "path": "papers/24/03/2403.14508.json",
    "total_tokens": 830,
    "translated_title": "带有平滑对数障碍函数的约束加强学习",
    "translated_abstract": "强化学习（RL）已广泛应用于许多控制任务，并在许多领域的性能上与传统控制方法相比有了显著提高，其中奖励函数是很好定义的。然而，对于许多现实世界的问题，以奖励和约束同时制定优化问题通常更为方便。通过奖励塑造来优化这些受限问题可能会很困难，因为需要对带有几个交互项的奖励函数进行繁琐的手动调整。最近包含约束的公式在多数情况下需要预训练阶段，这通常需要人类专业知识来收集数据或假定有一个待用的次优策略。我们提出了一种名为CSAC-LB（带有对数障碍函数的约束软演员-评论家）的新型约束RL方法，通过应用线性平滑对数障碍函数，该方法实现了竞争性能，而不需要任何预训练。",
    "tldr": "提出了一种新的约束强化学习方法CSAC-LB，通过应用线性平滑对数障碍函数，实现了竞争性能，无需任何预训练",
    "en_tdlr": "Introduced a new constrained reinforcement learning method CSAC-LB, which achieves competitive performance without any pre-training by applying a linear smoothed log barrier function."
}