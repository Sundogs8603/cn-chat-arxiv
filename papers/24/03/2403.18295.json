{
    "title": "Dual Instruction Tuning with Large Language Models for Mathematical Reasoning",
    "abstract": "arXiv:2403.18295v1 Announce Type: new  Abstract: Recent advancements highlight the success of instruction tuning with large language models (LLMs) utilizing Chain-of-Thought (CoT) data for mathematical reasoning tasks. Despite the fine-tuned LLMs, challenges persist, such as incorrect, missing, and redundant steps in CoT generation leading to inaccuracies in answer predictions. To alleviate this problem, we propose a dual instruction tuning strategy to meticulously model mathematical reasoning from both forward and reverse directions. This involves introducing the Intermediate Reasoning State Prediction task (forward reasoning) and the Instruction Reconstruction task (reverse reasoning) to enhance the LLMs' understanding and execution of instructions. Training instances for these tasks are constructed based on existing mathematical instruction tuning datasets. Subsequently, LLMs undergo multi-task fine-tuning using both existing mathematical instructions and the newly created data. Com",
    "link": "https://arxiv.org/abs/2403.18295",
    "context": "Title: Dual Instruction Tuning with Large Language Models for Mathematical Reasoning\nAbstract: arXiv:2403.18295v1 Announce Type: new  Abstract: Recent advancements highlight the success of instruction tuning with large language models (LLMs) utilizing Chain-of-Thought (CoT) data for mathematical reasoning tasks. Despite the fine-tuned LLMs, challenges persist, such as incorrect, missing, and redundant steps in CoT generation leading to inaccuracies in answer predictions. To alleviate this problem, we propose a dual instruction tuning strategy to meticulously model mathematical reasoning from both forward and reverse directions. This involves introducing the Intermediate Reasoning State Prediction task (forward reasoning) and the Instruction Reconstruction task (reverse reasoning) to enhance the LLMs' understanding and execution of instructions. Training instances for these tasks are constructed based on existing mathematical instruction tuning datasets. Subsequently, LLMs undergo multi-task fine-tuning using both existing mathematical instructions and the newly created data. Com",
    "path": "papers/24/03/2403.18295.json",
    "total_tokens": 812,
    "translated_title": "大型语言模型对数学推理的双重指令调整",
    "translated_abstract": "最近的进展突显了利用大型语言模型（LLMs）在数学推理任务中利用CoT数据进行指令调整的成功。尽管进行了精细调整的LLMs，在CoT生成中仍存在错误、缺失和多余的步骤，导致答案预测不准确。为了缓解这一问题，我们提出了一种双重指令调整策略，以从前向和后向两个方向精密建模数学推理。这涉及引入中间推理状态预测任务（前向推理）和指令重构任务（后向推理），以增强LLMs对指令的理解和执行。这些任务的训练实例是基于现有的数学指令调整数据集构建的。随后，LLMs经过多任务微调，同时使用现有的数学指令和新创建的数据。",
    "tldr": "提出了双重指令调整策略，通过引入中间推理状态预测任务和指令重构任务，从前向和后向两个方向精密建模数学推理，以增强LLMs对指令的理解和执行。"
}