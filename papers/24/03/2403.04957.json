{
    "title": "Automatic and Universal Prompt Injection Attacks against Large Language Models",
    "abstract": "arXiv:2403.04957v1 Announce Type: new  Abstract: Large Language Models (LLMs) excel in processing and generating human language, powered by their ability to interpret and follow instructions. However, their capabilities can be exploited through prompt injection attacks. These attacks manipulate LLM-integrated applications into producing responses aligned with the attacker's injected content, deviating from the user's actual requests. The substantial risks posed by these attacks underscore the need for a thorough understanding of the threats. Yet, research in this area faces challenges due to the lack of a unified goal for such attacks and their reliance on manually crafted prompts, complicating comprehensive assessments of prompt injection robustness. We introduce a unified framework for understanding the objectives of prompt injection attacks and present an automated gradient-based method for generating highly effective and universal prompt injection data, even in the face of defensiv",
    "link": "https://arxiv.org/abs/2403.04957",
    "context": "Title: Automatic and Universal Prompt Injection Attacks against Large Language Models\nAbstract: arXiv:2403.04957v1 Announce Type: new  Abstract: Large Language Models (LLMs) excel in processing and generating human language, powered by their ability to interpret and follow instructions. However, their capabilities can be exploited through prompt injection attacks. These attacks manipulate LLM-integrated applications into producing responses aligned with the attacker's injected content, deviating from the user's actual requests. The substantial risks posed by these attacks underscore the need for a thorough understanding of the threats. Yet, research in this area faces challenges due to the lack of a unified goal for such attacks and their reliance on manually crafted prompts, complicating comprehensive assessments of prompt injection robustness. We introduce a unified framework for understanding the objectives of prompt injection attacks and present an automated gradient-based method for generating highly effective and universal prompt injection data, even in the face of defensiv",
    "path": "papers/24/03/2403.04957.json",
    "total_tokens": 815,
    "translated_title": "大型语言模型的自动和通用提示注入攻击",
    "translated_abstract": "大型语言模型（LLM）擅长处理和生成人类语言，其能力源于解释和遵循指令的能力。然而，这些能力可以通过提示注入攻击来利用。这些攻击会操纵LLM集成应用程序以产生与攻击者注入内容一致的响应，偏离用户的实际请求。这些攻击带来的重大风险凸显了对威胁的深入理解的必要性。然而，这一领域的研究面临挑战，因为这些攻击缺乏统一的目标，并且依赖手工制作的提示，使得对提示注入鲁棒性的全面评估变得复杂。我们引入了一个统一框架，以理解提示注入攻击的目标，并提出了一种基于梯度的自动方法，用于生成高效且通用的提示注入数据，即使面对防御措施也能如此。",
    "tldr": "引入了一个统一框架，用于理解提示注入攻击的目标，并提出了一种自动梯度方法，用于生成高效和通用的提示注入数据。"
}