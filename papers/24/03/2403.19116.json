{
    "title": "MFORT-QA: Multi-hop Few-shot Open Rich Table Question Answering",
    "abstract": "arXiv:2403.19116v1 Announce Type: cross  Abstract: In today's fast-paced industry, professionals face the challenge of summarizing a large number of documents and extracting vital information from them on a daily basis. These metrics are frequently hidden away in tables and/or their nested hyperlinks. To address this challenge, the approach of Table Question Answering (QA) has been developed to extract the relevant information. However, traditional Table QA training tasks that provide a table and an answer(s) from a gold cell coordinate(s) for a question may not always ensure extracting the accurate answer(s). Recent advancements in Large Language Models (LLMs) have opened up new possibilities for extracting information from tabular data using prompts. In this paper, we introduce the Multi-hop Few-shot Open Rich Table QA (MFORT-QA) approach, which consists of two major steps. The first step involves Few-Shot Learning (FSL), where relevant tables and associated contexts of hyperlinks ar",
    "link": "https://arxiv.org/abs/2403.19116",
    "context": "Title: MFORT-QA: Multi-hop Few-shot Open Rich Table Question Answering\nAbstract: arXiv:2403.19116v1 Announce Type: cross  Abstract: In today's fast-paced industry, professionals face the challenge of summarizing a large number of documents and extracting vital information from them on a daily basis. These metrics are frequently hidden away in tables and/or their nested hyperlinks. To address this challenge, the approach of Table Question Answering (QA) has been developed to extract the relevant information. However, traditional Table QA training tasks that provide a table and an answer(s) from a gold cell coordinate(s) for a question may not always ensure extracting the accurate answer(s). Recent advancements in Large Language Models (LLMs) have opened up new possibilities for extracting information from tabular data using prompts. In this paper, we introduce the Multi-hop Few-shot Open Rich Table QA (MFORT-QA) approach, which consists of two major steps. The first step involves Few-Shot Learning (FSL), where relevant tables and associated contexts of hyperlinks ar",
    "path": "papers/24/03/2403.19116.json",
    "total_tokens": 792,
    "translated_title": "MFORT-QA: 多跳少样本开放式丰富表格问答",
    "translated_abstract": "在当今快节奏的行业中，专业人士每天面临着总结大量文档并从中提取关键信息的挑战。这些度量经常隐藏在表格和/或其嵌套的超链接中。为了应对这一挑战，开发了表格问答（QA）方法来提取相关信息。然而，传统的表格QA训练任务并不总是能确保提取准确答案，这些任务会向问题提供一个表格和一个或多个来自黄金单元格坐标的答案。近期大语言模型（LLM）的进展为使用提示从表格数据中提取信息开辟了新的可能性。本文介绍了Multi-hop Few-shot Open Rich Table QA（MFORT-QA）方法，该方法包括两个主要步骤。",
    "tldr": "本文介绍了MFORT-QA方法，通过Few-Shot Learning和大语言模型，实现了在表格数据中进行多跳少样本的开放式丰富问答。",
    "en_tdlr": "This paper introduces the MFORT-QA approach, which utilizes Few-Shot Learning and Large Language Models to achieve multi-hop few-shot open rich table question answering in tabular data."
}