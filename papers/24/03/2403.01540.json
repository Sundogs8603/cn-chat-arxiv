{
    "title": "Quantized Hierarchical Federated Learning: A Robust Approach to Statistical Heterogeneity",
    "abstract": "arXiv:2403.01540v1 Announce Type: new  Abstract: This paper presents a novel hierarchical federated learning algorithm within multiple sets that incorporates quantization for communication-efficiency and demonstrates resilience to statistical heterogeneity. Unlike conventional hierarchical federated learning algorithms, our approach combines gradient aggregation in intra-set iterations with model aggregation in inter-set iterations. We offer a comprehensive analytical framework to evaluate its optimality gap and convergence rate, comparing these aspects with those of conventional algorithms. Additionally, we develop a problem formulation to derive optimal system parameters in a closed-form solution. Our findings reveal that our algorithm consistently achieves high learning accuracy over a range of parameters and significantly outperforms other hierarchical algorithms, particularly in scenarios with heterogeneous data distributions.",
    "link": "https://arxiv.org/abs/2403.01540",
    "context": "Title: Quantized Hierarchical Federated Learning: A Robust Approach to Statistical Heterogeneity\nAbstract: arXiv:2403.01540v1 Announce Type: new  Abstract: This paper presents a novel hierarchical federated learning algorithm within multiple sets that incorporates quantization for communication-efficiency and demonstrates resilience to statistical heterogeneity. Unlike conventional hierarchical federated learning algorithms, our approach combines gradient aggregation in intra-set iterations with model aggregation in inter-set iterations. We offer a comprehensive analytical framework to evaluate its optimality gap and convergence rate, comparing these aspects with those of conventional algorithms. Additionally, we develop a problem formulation to derive optimal system parameters in a closed-form solution. Our findings reveal that our algorithm consistently achieves high learning accuracy over a range of parameters and significantly outperforms other hierarchical algorithms, particularly in scenarios with heterogeneous data distributions.",
    "path": "papers/24/03/2403.01540.json",
    "total_tokens": 766,
    "translated_title": "分层量化联邦学习：统计异质性的一种强大方法",
    "translated_abstract": "本文介绍了一种新颖的分层联邦学习算法，该算法在多个集合中结合了量化以提高通信效率，并展示了对于统计异质性的弹性。与传统的分层联邦学习算法不同，我们的方法在集合内迭代中结合了梯度聚合和集合间迭代中的模型聚合。我们提供了一个全面的分析框架来评估其最优性差距和收敛速度，将这些方面与传统算法进行了比较。此外，我们开发了一个问题表述，以导出封闭形式的最优系统参数解。我们的研究结果表明，我们的算法在一系列参数上始终实现高学习精度，并且在具有异构数据分布的场景中明显优于其他分层算法。",
    "tldr": "该算法结合了分层联邦学习中的梯度聚合和模型聚合，通过量化提高通信效率，表现出对统计异质性的鲁棒性。",
    "en_tdlr": "The algorithm combines gradient aggregation and model aggregation in hierarchical federated learning, improves communication efficiency through quantization, and demonstrates resilience to statistical heterogeneity."
}