{
    "title": "Kernel Alignment for Unsupervised Feature Selection via Matrix Factorization",
    "abstract": "arXiv:2403.14688v1 Announce Type: new  Abstract: By removing irrelevant and redundant features, feature selection aims to find a good representation of the original features. With the prevalence of unlabeled data, unsupervised feature selection has been proven effective in alleviating the so-called curse of dimensionality. Most existing matrix factorization-based unsupervised feature selection methods are built upon subspace learning, but they have limitations in capturing nonlinear structural information among features. It is well-known that kernel techniques can capture nonlinear structural information. In this paper, we construct a model by integrating kernel functions and kernel alignment, which can be equivalently characterized as a matrix factorization problem. However, such an extension raises another issue: the algorithm performance heavily depends on the choice of kernel, which is often unknown a priori. Therefore, we further propose a multiple kernel-based learning method. By",
    "link": "https://arxiv.org/abs/2403.14688",
    "context": "Title: Kernel Alignment for Unsupervised Feature Selection via Matrix Factorization\nAbstract: arXiv:2403.14688v1 Announce Type: new  Abstract: By removing irrelevant and redundant features, feature selection aims to find a good representation of the original features. With the prevalence of unlabeled data, unsupervised feature selection has been proven effective in alleviating the so-called curse of dimensionality. Most existing matrix factorization-based unsupervised feature selection methods are built upon subspace learning, but they have limitations in capturing nonlinear structural information among features. It is well-known that kernel techniques can capture nonlinear structural information. In this paper, we construct a model by integrating kernel functions and kernel alignment, which can be equivalently characterized as a matrix factorization problem. However, such an extension raises another issue: the algorithm performance heavily depends on the choice of kernel, which is often unknown a priori. Therefore, we further propose a multiple kernel-based learning method. By",
    "path": "papers/24/03/2403.14688.json",
    "total_tokens": 801,
    "translated_title": "通过矩阵分解实现无监督特征选择的核对齐方法",
    "translated_abstract": "通过消除无关和冗余特征，特征选择旨在找到原始特征的良好表示。随着无标记数据的普及，无监督特征选择已被证明在缓解所谓的维度灾难中是有效的。大多数现有基于矩阵分解的无监督特征选择方法建立在子空间学习之上，但在捕获特征之间的非线性结构信息方面存在局限性。众所周知，核技术可以捕获非线性结构信息。在本文中，我们通过集成核函数和核对齐构建了一个模型，这等效地可以被表征为一个矩阵分解问题。然而，这种扩展引发了另一个问题：算法性能严重依赖于核的选择，而这通常是未知的。因此，我们进一步提出了一种基于多核学习的方法。",
    "tldr": "该论文提出了一种通过整合核函数和核对齐实现无监督特征选择的方法，并进一步提出了基于多核学习的方法。",
    "en_tdlr": "The paper proposes a method for unsupervised feature selection by integrating kernel functions and kernel alignment, and further presents a multiple kernel-based learning approach."
}