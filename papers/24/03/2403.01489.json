{
    "title": "Regeneration Based Training-free Attribution of Fake Images Generated by Text-to-Image Generative Models",
    "abstract": "arXiv:2403.01489v1 Announce Type: cross  Abstract: Text-to-image generative models have recently garnered significant attention due to their ability to generate images based on prompt descriptions. While these models have shown promising performance, concerns have been raised regarding the potential misuse of the generated fake images. In response to this, we have presented a simple yet effective training-free method to attribute fake images generated by text-to-image models to their source models. Given a test image to be attributed, we first inverse the textual prompt of the image, and then put the reconstructed prompt into different candidate models to regenerate candidate fake images. By calculating and ranking the similarity of the test image and the candidate images, we can determine the source of the image. This attribution allows model owners to be held accountable for any misuse of their models. Note that our approach does not limit the number of candidate text-to-image genera",
    "link": "https://arxiv.org/abs/2403.01489",
    "context": "Title: Regeneration Based Training-free Attribution of Fake Images Generated by Text-to-Image Generative Models\nAbstract: arXiv:2403.01489v1 Announce Type: cross  Abstract: Text-to-image generative models have recently garnered significant attention due to their ability to generate images based on prompt descriptions. While these models have shown promising performance, concerns have been raised regarding the potential misuse of the generated fake images. In response to this, we have presented a simple yet effective training-free method to attribute fake images generated by text-to-image models to their source models. Given a test image to be attributed, we first inverse the textual prompt of the image, and then put the reconstructed prompt into different candidate models to regenerate candidate fake images. By calculating and ranking the similarity of the test image and the candidate images, we can determine the source of the image. This attribution allows model owners to be held accountable for any misuse of their models. Note that our approach does not limit the number of candidate text-to-image genera",
    "path": "papers/24/03/2403.01489.json",
    "total_tokens": 833,
    "translated_title": "基于重建的无需训练的文本到图像生成模型生成的假图像溯源方法",
    "translated_abstract": "文本到图像生成模型最近引起了人们的广泛关注，因为它们能够基于描述生成图像。虽然这些模型表现出色，但人们对生成的假图像可能被滥用提出了担忧。为了应对这一问题，我们提出了一种简单而有效的无需训练的方法，用于将由文本到图像模型生成的假图像归因于其来源模型。给定一个待归因的测试图像，首先我们反向重建图像的文本提示，然后将重建的提示放入不同的候选模型中以再现候选假图像。通过计算和排名测试图像与候选图像之间的相似性，我们可以确定图像的来源。这种溯源方法可以让模型所有者对其模型的任何滥用负责。需要注意的是，我们的方法不限制候选文本到图像生成模型的数量。",
    "tldr": "提出了一种基于重建的无需训练的方法，用于将由文本到图像生成模型生成的假图像归因于其来源模型，从而让模型所有者对模型的任何滥用负责。"
}