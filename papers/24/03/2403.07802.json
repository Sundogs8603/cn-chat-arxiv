{
    "title": "Boosting keyword spotting through on-device learnable user speech characteristics",
    "abstract": "arXiv:2403.07802v1 Announce Type: cross  Abstract: Keyword spotting systems for always-on TinyML-constrained applications require on-site tuning to boost the accuracy of offline trained classifiers when deployed in unseen inference conditions. Adapting to the speech peculiarities of target users requires many in-domain samples, often unavailable in real-world scenarios. Furthermore, current on-device learning techniques rely on computationally intensive and memory-hungry backbone update schemes, unfit for always-on, battery-powered devices. In this work, we propose a novel on-device learning architecture, composed of a pretrained backbone and a user-aware embedding learning the user's speech characteristics. The so-generated features are fused and used to classify the input utterance. For domain shifts generated by unseen speakers, we measure error rate reductions of up to 19% from 30.1% to 24.3% based on the 35-class problem of the Google Speech Commands dataset, through the inexpensi",
    "link": "https://arxiv.org/abs/2403.07802",
    "context": "Title: Boosting keyword spotting through on-device learnable user speech characteristics\nAbstract: arXiv:2403.07802v1 Announce Type: cross  Abstract: Keyword spotting systems for always-on TinyML-constrained applications require on-site tuning to boost the accuracy of offline trained classifiers when deployed in unseen inference conditions. Adapting to the speech peculiarities of target users requires many in-domain samples, often unavailable in real-world scenarios. Furthermore, current on-device learning techniques rely on computationally intensive and memory-hungry backbone update schemes, unfit for always-on, battery-powered devices. In this work, we propose a novel on-device learning architecture, composed of a pretrained backbone and a user-aware embedding learning the user's speech characteristics. The so-generated features are fused and used to classify the input utterance. For domain shifts generated by unseen speakers, we measure error rate reductions of up to 19% from 30.1% to 24.3% based on the 35-class problem of the Google Speech Commands dataset, through the inexpensi",
    "path": "papers/24/03/2403.07802.json",
    "total_tokens": 867,
    "translated_title": "通过设备本地可学习的用户语音特征增强关键词识别",
    "translated_abstract": "TinyML受限应用的关键词识别系统需要现场调整，以提高离线训练分类器在未知推理条件下部署时的准确性。适应目标用户的语音特点需要大量领域内样本，通常在现实场景中不可用。此外，当前的设备本地学习技术依赖于计算密集型和内存消耗极大的骨干更新方案，不适用于始终开启、使用电池供电的设备。在这项工作中，我们提出了一种新颖的设备本地学习架构，由预训练骨干和学习用户语音特征的用户感知嵌入组成。生成的特征被融合并用于对输入的话语进行分类。针对由未知讲话者引起的领域转移，我们在Google Speech Commands数据集的35类问题上测得错误率降低高达19%，从30.1%降至24.3%。",
    "tldr": "提出一种新颖的设备本地学习架构，通过学习用户语音特征来增强关键词识别系统，在35类问题的Google Speech Commands数据集中实现了高达19%的错误率降低。",
    "en_tdlr": "Introducing a novel on-device learning architecture to enhance keyword spotting systems through learning user speech characteristics, achieving error rate reductions up to 19% on the 35-class problem of the Google Speech Commands dataset."
}