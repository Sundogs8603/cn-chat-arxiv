{
    "title": "Cross Domain Policy Transfer with Effect Cycle-Consistency",
    "abstract": "arXiv:2403.02018v1 Announce Type: cross  Abstract: Training a robotic policy from scratch using deep reinforcement learning methods can be prohibitively expensive due to sample inefficiency. To address this challenge, transferring policies trained in the source domain to the target domain becomes an attractive paradigm. Previous research has typically focused on domains with similar state and action spaces but differing in other aspects. In this paper, our primary focus lies in domains with different state and action spaces, which has broader practical implications, i.e. transfer the policy from robot A to robot B. Unlike prior methods that rely on paired data, we propose a novel approach for learning the mapping functions between state and action spaces across domains using unpaired data. We propose effect cycle consistency, which aligns the effects of transitions across two domains through a symmetrical optimization structure for learning these mapping functions. Once the mapping fun",
    "link": "https://arxiv.org/abs/2403.02018",
    "context": "Title: Cross Domain Policy Transfer with Effect Cycle-Consistency\nAbstract: arXiv:2403.02018v1 Announce Type: cross  Abstract: Training a robotic policy from scratch using deep reinforcement learning methods can be prohibitively expensive due to sample inefficiency. To address this challenge, transferring policies trained in the source domain to the target domain becomes an attractive paradigm. Previous research has typically focused on domains with similar state and action spaces but differing in other aspects. In this paper, our primary focus lies in domains with different state and action spaces, which has broader practical implications, i.e. transfer the policy from robot A to robot B. Unlike prior methods that rely on paired data, we propose a novel approach for learning the mapping functions between state and action spaces across domains using unpaired data. We propose effect cycle consistency, which aligns the effects of transitions across two domains through a symmetrical optimization structure for learning these mapping functions. Once the mapping fun",
    "path": "papers/24/03/2403.02018.json",
    "total_tokens": 817,
    "translated_title": "跨域策略转移与效果循环一致性",
    "translated_abstract": "使用深度强化学习方法从头开始训练机器人策略可能因为样本效率低而成本过高。为了解决这一挑战，将在源域中训练的策略转移到目标域变得具有吸引力。先前的研究通常集中在状态和动作空间相似但在其他方面不同的域上。本文的主要重点在于具有不同状态和动作空间的领域，这具有更广泛的实际意义，即从机器人A转移到机器人B的策略转移。与依赖配对数据的先前方法不同，我们提出了一种新颖的方法，使用未配对数据学习跨领域状态和动作空间之间的映射函数。我们提出了效果循环一致性，通过对称优化结构来对两个领域之间的过渡效果进行对齐，从而学习这些映射函数。一旦映射完成",
    "tldr": "提出了一种新颖的方法，通过使用未配对数据学习两个领域之间的状态和动作空间映射函数，实现了跨域策略转移。",
    "en_tdlr": "Introduced a novel approach to transfer policies across domains by learning mapping functions between state and action spaces using unpaired data."
}