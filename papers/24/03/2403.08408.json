{
    "title": "Reduced Jeffries-Matusita distance: A Novel Loss Function to Improve Generalization Performance of Deep Classification Models",
    "abstract": "arXiv:2403.08408v1 Announce Type: new  Abstract: The generalization performance of deep neural networks in classification tasks is a major concern in machine learning research. Despite widespread techniques used to diminish the over-fitting issue such as data augmentation, pseudo-labeling, regularization, and ensemble learning, this performance still needs to be enhanced with other approaches. In recent years, it has been theoretically demonstrated that the loss function characteristics i.e. its Lipschitzness and maximum value affect the generalization performance of deep neural networks which can be utilized as a guidance to propose novel distance measures. In this paper, by analyzing the aforementioned characteristics, we introduce a distance called Reduced Jeffries-Matusita as a loss function for training deep classification models to reduce the over-fitting issue. In our experiments, we evaluate the new loss function in two different problems: image classification in computer visio",
    "link": "https://arxiv.org/abs/2403.08408",
    "context": "Title: Reduced Jeffries-Matusita distance: A Novel Loss Function to Improve Generalization Performance of Deep Classification Models\nAbstract: arXiv:2403.08408v1 Announce Type: new  Abstract: The generalization performance of deep neural networks in classification tasks is a major concern in machine learning research. Despite widespread techniques used to diminish the over-fitting issue such as data augmentation, pseudo-labeling, regularization, and ensemble learning, this performance still needs to be enhanced with other approaches. In recent years, it has been theoretically demonstrated that the loss function characteristics i.e. its Lipschitzness and maximum value affect the generalization performance of deep neural networks which can be utilized as a guidance to propose novel distance measures. In this paper, by analyzing the aforementioned characteristics, we introduce a distance called Reduced Jeffries-Matusita as a loss function for training deep classification models to reduce the over-fitting issue. In our experiments, we evaluate the new loss function in two different problems: image classification in computer visio",
    "path": "papers/24/03/2403.08408.json",
    "total_tokens": 800,
    "translated_title": "减小Jeffries-Matusita距离：提高深度分类模型泛化性能的新型损失函数",
    "translated_abstract": "深度神经网络在分类任务中的泛化性能是机器学习研究中的一个主要关注点。尽管广泛采用诸如数据增强、伪标记、正则化和集成学习等技术来减少过拟合问题，但仍需要通过其他方法来提高性能。近年来，已在理论上证明损失函数特性，如其Lipschitz性和最大值，影响深度神经网络的泛化性能，这可以被用作提出新的距离度量的指导。本文通过分析上述特性，引入了一种称为减小Jeffries-Matusita距离的距离作为深度分类模型训练的损失函数，以减少过拟合问题。在实验中，我们在两个不同问题中评估了新的损失函数：计算机视觉中的图像分类。",
    "tldr": "提出了一种减小Jeffries-Matusita距离的损失函数，用于训练深度分类模型以减少过拟合问题。",
    "en_tdlr": "Introducing a loss function called Reduced Jeffries-Matusita distance to train deep classification models for reducing over-fitting issue."
}