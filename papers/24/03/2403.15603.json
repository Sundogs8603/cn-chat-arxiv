{
    "title": "Forward Learning for Gradient-based Black-box Saliency Map Generation",
    "abstract": "arXiv:2403.15603v1 Announce Type: cross  Abstract: Gradient-based saliency maps are widely used to explain deep neural network decisions. However, as models become deeper and more black-box, such as in closed-source APIs like ChatGPT, computing gradients become challenging, hindering conventional explanation methods. In this work, we introduce a novel unified framework for estimating gradients in black-box settings and generating saliency maps to interpret model decisions. We employ the likelihood ratio method to estimate output-to-input gradients and utilize them for saliency map generation. Additionally, we propose blockwise computation techniques to enhance estimation accuracy. Extensive experiments in black-box settings validate the effectiveness of our method, demonstrating accurate gradient estimation and explainability of generated saliency maps. Furthermore, we showcase the scalability of our approach by applying it to explain GPT-Vision, revealing the continued relevance of gr",
    "link": "https://arxiv.org/abs/2403.15603",
    "context": "Title: Forward Learning for Gradient-based Black-box Saliency Map Generation\nAbstract: arXiv:2403.15603v1 Announce Type: cross  Abstract: Gradient-based saliency maps are widely used to explain deep neural network decisions. However, as models become deeper and more black-box, such as in closed-source APIs like ChatGPT, computing gradients become challenging, hindering conventional explanation methods. In this work, we introduce a novel unified framework for estimating gradients in black-box settings and generating saliency maps to interpret model decisions. We employ the likelihood ratio method to estimate output-to-input gradients and utilize them for saliency map generation. Additionally, we propose blockwise computation techniques to enhance estimation accuracy. Extensive experiments in black-box settings validate the effectiveness of our method, demonstrating accurate gradient estimation and explainability of generated saliency maps. Furthermore, we showcase the scalability of our approach by applying it to explain GPT-Vision, revealing the continued relevance of gr",
    "path": "papers/24/03/2403.15603.json",
    "total_tokens": 905,
    "translated_title": "基于前向学习的基于梯度的黑盒显著图生成",
    "translated_abstract": "梯度-based显著图被广泛用于解释深度神经网络决策。然而，随着模型变得更深和更黑盒，如在闭源API（如ChatGPT）中，计算梯度变得具有挑战性，阻碍传统解释方法。在这项工作中，我们引入了一个新颖的统一框架，用于在黑盒设置中估计梯度并生成显著图来解释模型决策。我们采用似然比方法来估计输出到输入的梯度，并将其用于显著图生成。此外，我们提出了分块计算技术来增强估计准确性。在黑盒设置中进行的大量实验证实了我们方法的有效性，展示了准确的梯度估计和生成显著图的解释性。此外，我们通过应用它来解释GPT-Vision展示了我们方法的可扩展性，揭示了梯度相关性的持续影响。",
    "tldr": "提出了一种新颖的统一框架，在黑盒设置中估计梯度并生成显著图解释模型决策，通过Likelihood Ratio方法估计输出到输入的梯度，并应用分块计算技术提高估计准确性，实验证实有效性和可扩展性。",
    "en_tdlr": "A novel unified framework is proposed to estimate gradients and generate saliency maps to interpret model decisions in black-box settings, utilizing the Likelihood Ratio method for output-to-input gradient estimation and introducing blockwise computation techniques for enhanced accuracy, with extensive experiments validating effectiveness and scalability."
}