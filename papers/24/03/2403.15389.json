{
    "title": "DiffusionMTL: Learning Multi-Task Denoising Diffusion Model from Partially Annotated Data",
    "abstract": "arXiv:2403.15389v1 Announce Type: cross  Abstract: Recently, there has been an increased interest in the practical problem of learning multiple dense scene understanding tasks from partially annotated data, where each training sample is only labeled for a subset of the tasks. The missing of task labels in training leads to low-quality and noisy predictions, as can be observed from state-of-the-art methods. To tackle this issue, we reformulate the partially-labeled multi-task dense prediction as a pixel-level denoising problem, and propose a novel multi-task denoising diffusion framework coined as DiffusionMTL. It designs a joint diffusion and denoising paradigm to model a potential noisy distribution in the task prediction or feature maps and generate rectified outputs for different tasks. To exploit multi-task consistency in denoising, we further introduce a Multi-Task Conditioning strategy, which can implicitly utilize the complementary nature of the tasks to help learn the unlabeled",
    "link": "https://arxiv.org/abs/2403.15389",
    "context": "Title: DiffusionMTL: Learning Multi-Task Denoising Diffusion Model from Partially Annotated Data\nAbstract: arXiv:2403.15389v1 Announce Type: cross  Abstract: Recently, there has been an increased interest in the practical problem of learning multiple dense scene understanding tasks from partially annotated data, where each training sample is only labeled for a subset of the tasks. The missing of task labels in training leads to low-quality and noisy predictions, as can be observed from state-of-the-art methods. To tackle this issue, we reformulate the partially-labeled multi-task dense prediction as a pixel-level denoising problem, and propose a novel multi-task denoising diffusion framework coined as DiffusionMTL. It designs a joint diffusion and denoising paradigm to model a potential noisy distribution in the task prediction or feature maps and generate rectified outputs for different tasks. To exploit multi-task consistency in denoising, we further introduce a Multi-Task Conditioning strategy, which can implicitly utilize the complementary nature of the tasks to help learn the unlabeled",
    "path": "papers/24/03/2403.15389.json",
    "total_tokens": 890,
    "translated_title": "DiffusionMTL: 从部分标注数据中学习多任务去噪扩散模型",
    "translated_abstract": "最近，对从部分标注数据中学习多个密集场景理解任务的实际问题越来越感兴趣，其中每个训练样本仅针对一部分任务进行标记。在训练中缺少任务标签会导致低质量和嘈杂的预测，这可以从最先进方法中观察到。为了解决这个问题，我们将部分标记的多任务密集预测重新构建为像素级去噪问题，并提出了一个被称为DiffusionMTL的新型多任务去噪扩散框架。它设计了一个联合扩散和去噪范式，以模拟任务预测或特征图中的潜在噪声分布，并为不同任务生成校正输出。为了利用去噪中的多任务一致性，我们进一步引入了一个多任务条件策略，它可以隐式利用任务的互补性来帮助学习未标记",
    "tldr": "DiffusionMTL 提出了一个新型多任务去噪扩散框架，通过联合扩散和去噪来改善部分标注数据中的多任务密集场景理解，进一步引入了多任务条件策略来利用任务的互补性。",
    "en_tdlr": "DiffusionMTL proposes a novel multi-task denoising diffusion framework to improve learning multiple dense scene understanding tasks from partially annotated data, further introducing a Multi-Task Conditioning strategy to leverage the complementary nature of the tasks."
}