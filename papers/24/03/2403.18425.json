{
    "title": "U-Sketch: An Efficient Approach for Sketch to Image Diffusion Models",
    "abstract": "arXiv:2403.18425v1 Announce Type: cross  Abstract: Diffusion models have demonstrated remarkable performance in text-to-image synthesis, producing realistic and high resolution images that faithfully adhere to the corresponding text-prompts. Despite their great success, they still fall behind in sketch-to-image synthesis tasks, where in addition to text-prompts, the spatial layout of the generated images has to closely follow the outlines of certain reference sketches. Employing an MLP latent edge predictor to guide the spatial layout of the synthesized image by predicting edge maps at each denoising step has been recently proposed. Despite yielding promising results, the pixel-wise operation of the MLP does not take into account the spatial layout as a whole, and demands numerous denoising iterations to produce satisfactory images, leading to time inefficiency. To this end, we introduce U-Sketch, a framework featuring a U-Net type latent edge predictor, which is capable of efficiently",
    "link": "https://arxiv.org/abs/2403.18425",
    "context": "Title: U-Sketch: An Efficient Approach for Sketch to Image Diffusion Models\nAbstract: arXiv:2403.18425v1 Announce Type: cross  Abstract: Diffusion models have demonstrated remarkable performance in text-to-image synthesis, producing realistic and high resolution images that faithfully adhere to the corresponding text-prompts. Despite their great success, they still fall behind in sketch-to-image synthesis tasks, where in addition to text-prompts, the spatial layout of the generated images has to closely follow the outlines of certain reference sketches. Employing an MLP latent edge predictor to guide the spatial layout of the synthesized image by predicting edge maps at each denoising step has been recently proposed. Despite yielding promising results, the pixel-wise operation of the MLP does not take into account the spatial layout as a whole, and demands numerous denoising iterations to produce satisfactory images, leading to time inefficiency. To this end, we introduce U-Sketch, a framework featuring a U-Net type latent edge predictor, which is capable of efficiently",
    "path": "papers/24/03/2403.18425.json",
    "total_tokens": 848,
    "translated_title": "U-Sketch: 一种用于草图到图像扩散模型的高效方法",
    "translated_abstract": "扩散模型在文本到图像合成中表现出色，产生了符合相应文本提示的逼真高分辨率图像。尽管取得了巨大成功，但在草图到图像合成任务中仍有所欠缺，生成图像的空间布局不仅要遵循文本提示，还必须紧密跟随某些参考草图的轮廓。最近提出了使用MLP潜在边缘预测器来引导合成图像的空间布局，通过在每个去噪步骤预测边缘地图。尽管取得了有希望的结果，但MLP的逐像素操作并未将空间布局作为整体考虑进来，需要大量去噪迭代才能生成令人满意的图像，导致时间效率低下。因此，我们引入了U-Sketch，这是一个引入了U-Net类型潜在边缘预测器的框架，能够高效地",
    "tldr": "引入了U-Sketch框架，具有U-Net类型的潜在边缘预测器，能够有效地改进草图到图像扩散模型的空间布局生成。",
    "en_tdlr": "Introduced U-Sketch framework with a U-Net type latent edge predictor to efficiently enhance the spatial layout generation in sketch to image diffusion models."
}