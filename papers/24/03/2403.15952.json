{
    "title": "IllusionVQA: A Challenging Optical Illusion Dataset for Vision Language Models",
    "abstract": "arXiv:2403.15952v1 Announce Type: cross  Abstract: The advent of Vision Language Models (VLM) has allowed researchers to investigate the visual understanding of a neural network using natural language. Beyond object classification and detection, VLMs are capable of visual comprehension and common-sense reasoning. This naturally led to the question: How do VLMs respond when the image itself is inherently unreasonable? To this end, we present IllusionVQA: a diverse dataset of challenging optical illusions and hard-to-interpret scenes to test the capability of VLMs in two distinct multiple-choice VQA tasks - comprehension and soft localization. GPT4V, the best-performing VLM, achieves 62.99% accuracy (4-shot) on the comprehension task and 49.7% on the localization task (4-shot and Chain-of-Thought). Human evaluation reveals that humans achieve 91.03% and 100% accuracy in comprehension and localization. We discover that In-Context Learning (ICL) and Chain-of-Thought reasoning substantially",
    "link": "https://arxiv.org/abs/2403.15952",
    "context": "Title: IllusionVQA: A Challenging Optical Illusion Dataset for Vision Language Models\nAbstract: arXiv:2403.15952v1 Announce Type: cross  Abstract: The advent of Vision Language Models (VLM) has allowed researchers to investigate the visual understanding of a neural network using natural language. Beyond object classification and detection, VLMs are capable of visual comprehension and common-sense reasoning. This naturally led to the question: How do VLMs respond when the image itself is inherently unreasonable? To this end, we present IllusionVQA: a diverse dataset of challenging optical illusions and hard-to-interpret scenes to test the capability of VLMs in two distinct multiple-choice VQA tasks - comprehension and soft localization. GPT4V, the best-performing VLM, achieves 62.99% accuracy (4-shot) on the comprehension task and 49.7% on the localization task (4-shot and Chain-of-Thought). Human evaluation reveals that humans achieve 91.03% and 100% accuracy in comprehension and localization. We discover that In-Context Learning (ICL) and Chain-of-Thought reasoning substantially",
    "path": "papers/24/03/2403.15952.json",
    "total_tokens": 930,
    "translated_title": "IllusionVQA：一个挑战视觉语言模型的错觉数据集",
    "translated_abstract": "视觉语言模型（VLM）的出现使研究人员能够使用自然语言调查神经网络的视觉理解。 VLM不仅能够进行对象分类和检测，还能够进行视觉理解和常识推理。 这自然而然地引出了一个问题：当图像本身是不合理的时，VLM会如何回应？ 为此，我们提出了IllusionVQA：一个包含具有挑战性的光学错觉和难以解释的场景的多样数据集，以测试VLM在两种不同的多选VQA任务 - 理解和软定位的能力。 表现最佳的VLM GPT4V在理解任务（4-shot）上实现了62.99％的准确率，在定位任务（4-shot和Chain-of-Thought）上实现了49.7％的准确率。 人类评估表明，人类在理解和定位方面的准确率分别为91.03％和100％。 我们发现，在上下文学习（ICL）和Chain-of-Thought推理方面有很大帮助。",
    "tldr": "提出了IllusionVQA数据集，用于测试视觉语言模型在错觉和难解场景下的表现，研究发现在理解任务和定位任务上，表现最佳的VLM为GPT4V，而人类表现更胜一筹。"
}