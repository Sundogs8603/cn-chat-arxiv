{
    "title": "Constrained Reinforcement Learning for Adaptive Controller Synchronization in Distributed SDN",
    "abstract": "arXiv:2403.08775v1 Announce Type: cross  Abstract: In software-defined networking (SDN), the implementation of distributed SDN controllers, with each controller responsible for managing a specific sub-network or domain, plays a critical role in achieving a balance between centralized control, scalability, reliability, and network efficiency. These controllers must be synchronized to maintain a logically centralized view of the entire network. While there are various approaches for synchronizing distributed SDN controllers, most tend to prioritize goals such as optimization of communication latency or load balancing, often neglecting to address both the aspects simultaneously. This limitation becomes particularly significant when considering applications like Augmented and Virtual Reality (AR/VR), which demand constrained network latencies and substantial computational resources. Additionally, many existing studies in this field predominantly rely on value-based reinforcement learning (",
    "link": "https://arxiv.org/abs/2403.08775",
    "context": "Title: Constrained Reinforcement Learning for Adaptive Controller Synchronization in Distributed SDN\nAbstract: arXiv:2403.08775v1 Announce Type: cross  Abstract: In software-defined networking (SDN), the implementation of distributed SDN controllers, with each controller responsible for managing a specific sub-network or domain, plays a critical role in achieving a balance between centralized control, scalability, reliability, and network efficiency. These controllers must be synchronized to maintain a logically centralized view of the entire network. While there are various approaches for synchronizing distributed SDN controllers, most tend to prioritize goals such as optimization of communication latency or load balancing, often neglecting to address both the aspects simultaneously. This limitation becomes particularly significant when considering applications like Augmented and Virtual Reality (AR/VR), which demand constrained network latencies and substantial computational resources. Additionally, many existing studies in this field predominantly rely on value-based reinforcement learning (",
    "path": "papers/24/03/2403.08775.json",
    "total_tokens": 866,
    "translated_title": "基于约束的强化学习用于分布式SDN中的自适应控制器同步",
    "translated_abstract": "在软件定义网络(SDN)中，分布式SDN控制器的实现起着至关重要的作用，每个控制器负责管理特定的子网络或域，以在集中化控制、可伸缩性、可靠性和网络效率之间实现平衡。这些控制器必须同步以保持对整个网络的逻辑集中视图。尽管有各种方法可以用于同步分布式SDN控制器，但大多数倾向于优先考虑诸如优化通信延迟或负载平衡等目标，通常忽视同时解决这两个方面。在考虑诸如增强现实和虚拟现实（AR/VR）等需求受到限制的网络延迟和大量计算资源的应用时，这种限制尤为显著。此外，许多现有研究在这一领域主要依赖基于值的强化学习",
    "tldr": "该论文提出了一种基于约束的强化学习方法，在分布式SDN中实现自适应控制器同步，以解决优化通信延迟和负载平衡之间的平衡问题，特别适用于对网络延迟和计算资源要求严格的应用。",
    "en_tdlr": "This paper proposes a constrained reinforcement learning approach to achieve adaptive controller synchronization in distributed SDN, striking a balance between optimizing communication latency and load balancing, especially suitable for applications with strict requirements on network latency and computational resources."
}