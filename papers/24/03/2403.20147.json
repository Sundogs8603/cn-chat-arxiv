{
    "title": "IndiBias: A Benchmark Dataset to Measure Social Biases in Language Models for Indian Context",
    "abstract": "arXiv:2403.20147v1 Announce Type: new  Abstract: The pervasive influence of social biases in language data has sparked the need for benchmark datasets that capture and evaluate these biases in Large Language Models (LLMs). Existing efforts predominantly focus on English language and the Western context, leaving a void for a reliable dataset that encapsulates India's unique socio-cultural nuances. To bridge this gap, we introduce IndiBias, a comprehensive benchmarking dataset designed specifically for evaluating social biases in the Indian context. We filter and translate the existing CrowS-Pairs dataset to create a benchmark dataset suited to the Indian context in Hindi language. Additionally, we leverage LLMs including ChatGPT and InstructGPT to augment our dataset with diverse societal biases and stereotypes prevalent in India. The included bias dimensions encompass gender, religion, caste, age, region, physical appearance, and occupation. We also build a resource to address intersec",
    "link": "https://arxiv.org/abs/2403.20147",
    "context": "Title: IndiBias: A Benchmark Dataset to Measure Social Biases in Language Models for Indian Context\nAbstract: arXiv:2403.20147v1 Announce Type: new  Abstract: The pervasive influence of social biases in language data has sparked the need for benchmark datasets that capture and evaluate these biases in Large Language Models (LLMs). Existing efforts predominantly focus on English language and the Western context, leaving a void for a reliable dataset that encapsulates India's unique socio-cultural nuances. To bridge this gap, we introduce IndiBias, a comprehensive benchmarking dataset designed specifically for evaluating social biases in the Indian context. We filter and translate the existing CrowS-Pairs dataset to create a benchmark dataset suited to the Indian context in Hindi language. Additionally, we leverage LLMs including ChatGPT and InstructGPT to augment our dataset with diverse societal biases and stereotypes prevalent in India. The included bias dimensions encompass gender, religion, caste, age, region, physical appearance, and occupation. We also build a resource to address intersec",
    "path": "papers/24/03/2403.20147.json",
    "total_tokens": 913,
    "translated_title": "IndiBias：一个用于衡量印度语境下语言模型社会偏见的基准数据集",
    "translated_abstract": "在语言数据中普遍存在的社会偏见影响引发了对捕捉和评估大型语言模型（LLMs）中这些偏见的基准数据集的需求。现有工作主要集中在英语和西方背景，缺乏一个可靠的数据集，能够体现印度独特的社会文化细微差别。为了弥补这一空白，我们引入了IndiBias，这是一个专门设计用于评估印度语境中社会偏见的全面基准数据集。我们过滤和翻译现有的CrowS-Pairs数据集，创建了一个适合印度语境中使用的基准数据集，使用印地语。此外，我们利用包括ChatGPT和InstructGPT在内的LLMs，以印度流行的各种社会偏见和刻板印象增强我们的数据集。包含的偏见维度涵盖性别、宗教、种姓、年龄、地区、外貌和职业。我们还建立了一个资源来解决交叉",
    "tldr": "IndiBias是一个为评估印度语境中社会偏见而设计的综合基准数据集，通过过滤和翻译现有数据集以及利用不同LLMs的方法，涵盖了印度中流行的各种社会偏见维度。",
    "en_tdlr": "IndiBias is a comprehensive benchmark dataset designed to evaluate social biases in the Indian context, covering various dimensions of societal biases prevalent in India through filtering and translating existing datasets and leveraging different LLMs."
}