{
    "title": "OpenEval: Benchmarking Chinese LLMs across Capability, Alignment and Safety",
    "abstract": "arXiv:2403.12316v1 Announce Type: new  Abstract: The rapid development of Chinese large language models (LLMs) poses big challenges for efficient LLM evaluation. While current initiatives have introduced new benchmarks or evaluation platforms for assessing Chinese LLMs, many of these focus primarily on capabilities, usually overlooking potential alignment and safety issues. To address this gap, we introduce OpenEval, an evaluation testbed that benchmarks Chinese LLMs across capability, alignment and safety. For capability assessment, we include 12 benchmark datasets to evaluate Chinese LLMs from 4 sub-dimensions: NLP tasks, disciplinary knowledge, commonsense reasoning and mathematical reasoning. For alignment assessment, OpenEval contains 7 datasets that examines the bias, offensiveness and illegalness in the outputs yielded by Chinese LLMs. To evaluate safety, especially anticipated risks (e.g., power-seeking, self-awareness) of advanced LLMs, we include 6 datasets. In addition to th",
    "link": "https://arxiv.org/abs/2403.12316",
    "context": "Title: OpenEval: Benchmarking Chinese LLMs across Capability, Alignment and Safety\nAbstract: arXiv:2403.12316v1 Announce Type: new  Abstract: The rapid development of Chinese large language models (LLMs) poses big challenges for efficient LLM evaluation. While current initiatives have introduced new benchmarks or evaluation platforms for assessing Chinese LLMs, many of these focus primarily on capabilities, usually overlooking potential alignment and safety issues. To address this gap, we introduce OpenEval, an evaluation testbed that benchmarks Chinese LLMs across capability, alignment and safety. For capability assessment, we include 12 benchmark datasets to evaluate Chinese LLMs from 4 sub-dimensions: NLP tasks, disciplinary knowledge, commonsense reasoning and mathematical reasoning. For alignment assessment, OpenEval contains 7 datasets that examines the bias, offensiveness and illegalness in the outputs yielded by Chinese LLMs. To evaluate safety, especially anticipated risks (e.g., power-seeking, self-awareness) of advanced LLMs, we include 6 datasets. In addition to th",
    "path": "papers/24/03/2403.12316.json",
    "total_tokens": 923,
    "translated_title": "OpenEval：在能力、对齐性和安全性方面对中文LLM进行基准测试",
    "translated_abstract": "arXiv:2403.12316v1 公告类型：新的 摘要：中文大型语言模型（LLMs）的快速发展为高效的LLM评估带来了巨大挑战。尽管当前的举措已经推出了新的基准测试或评估平台，用于评估中文LLMs，但其中许多主要关注能力，通常忽视了潜在的对齐性和安全问题。为了填补这一空白，我们引入了OpenEval，一个评估测试平台，以在能力、对齐性和安全性方面对中文LLMs进行基准测试。对于能力评估，我们包括12个基准数据集，以从4个子维度评估中文LLMs：自然语言处理任务、学科知识、常识推理和数学推理。对于对齐性评估，OpenEval包含7个数据集，检查中文LLMs产生的输出中的偏见、冒犯性和违法性。为了评估安全性，特别是高级LLMs的预期风险（如寻求权力、自我意识等），我们包括6个数据集。",
    "tldr": "OpenEval引入了一个评估测试平台，通过对中文LLMs进行基准测试，涵盖了能力、对齐性和安全性，填补了现有基准测试忽视对齐性和安全问题的空白。",
    "en_tdlr": "OpenEval introduces an evaluation testbed that benchmarks Chinese LLMs across capability, alignment, and safety, filling the gap in existing benchmarks by addressing alignment and safety issues."
}