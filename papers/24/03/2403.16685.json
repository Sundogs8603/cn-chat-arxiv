{
    "title": "ToXCL: A Unified Framework for Toxic Speech Detection and Explanation",
    "abstract": "arXiv:2403.16685v1 Announce Type: new  Abstract: The proliferation of online toxic speech is a pertinent problem posing threats to demographic groups. While explicit toxic speech contains offensive lexical signals, implicit one consists of coded or indirect language. Therefore, it is crucial for models not only to detect implicit toxic speech but also to explain its toxicity. This draws a unique need for unified frameworks that can effectively detect and explain implicit toxic speech. Prior works mainly formulated the task of toxic speech detection and explanation as a text generation problem. Nonetheless, models trained using this strategy can be prone to suffer from the consequent error propagation problem. Moreover, our experiments reveal that the detection results of such models are much lower than those that focus only on the detection task. To bridge these gaps, we introduce ToXCL, a unified framework for the detection and explanation of implicit toxic speech. Our model consists ",
    "link": "https://arxiv.org/abs/2403.16685",
    "context": "Title: ToXCL: A Unified Framework for Toxic Speech Detection and Explanation\nAbstract: arXiv:2403.16685v1 Announce Type: new  Abstract: The proliferation of online toxic speech is a pertinent problem posing threats to demographic groups. While explicit toxic speech contains offensive lexical signals, implicit one consists of coded or indirect language. Therefore, it is crucial for models not only to detect implicit toxic speech but also to explain its toxicity. This draws a unique need for unified frameworks that can effectively detect and explain implicit toxic speech. Prior works mainly formulated the task of toxic speech detection and explanation as a text generation problem. Nonetheless, models trained using this strategy can be prone to suffer from the consequent error propagation problem. Moreover, our experiments reveal that the detection results of such models are much lower than those that focus only on the detection task. To bridge these gaps, we introduce ToXCL, a unified framework for the detection and explanation of implicit toxic speech. Our model consists ",
    "path": "papers/24/03/2403.16685.json",
    "total_tokens": 827,
    "translated_title": "ToXCL：毒性言论检测和解释的统一框架",
    "translated_abstract": "线上毒性言论的蔓延是一个令人关注的问题，对人群构成威胁。明显的毒性言论包含冒犯性词汇信号，隐性的言论则包含编码或间接语言。因此，模型不仅需要检测隐性毒性言论，还需要解释其毒性。这导致了对有效检测和解释隐性毒性言论的统一框架的独特需求。先前的工作主要将毒性言论的检测和解释任务制定为文本生成问题。然而，使用这种策略训练的模型可能容易受到后续错误传播问题的影响。此外，我们的实验表明，这种模型的检测结果远低于那些仅专注于检测任务的模型。为了弥补这些差距，我们引入了ToXCL，一个用于检测和解释隐性毒性言论的统一框架。",
    "tldr": "ToXCL是一个统一框架，旨在检测和解释隐性毒性言论，解决了传统模型在检测和解释任务中可能遇到的问题。",
    "en_tdlr": "ToXCL is a unified framework aimed at detecting and explaining implicit toxic speech, addressing potential issues with traditional models in detection and explanation tasks."
}