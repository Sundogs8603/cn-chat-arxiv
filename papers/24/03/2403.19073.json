{
    "title": "Dataflow-Aware PIM-Enabled Manycore Architecture for Deep Learning Workloads",
    "abstract": "arXiv:2403.19073v1 Announce Type: cross  Abstract: Processing-in-memory (PIM) has emerged as an enabler for the energy-efficient and high-performance acceleration of deep learning (DL) workloads. Resistive random-access memory (ReRAM) is one of the most promising technologies to implement PIM. However, as the complexity of Deep convolutional neural networks (DNNs) grows, we need to design a manycore architecture with multiple ReRAM-based processing elements (PEs) on a single chip. Existing PIM-based architectures mostly focus on computation while ignoring the role of communication. ReRAM-based tiled manycore architectures often involve many Processing Elements (PEs), which need to be interconnected via an efficient on-chip communication infrastructure. Simply allocating more resources (ReRAMs) to speed up only computation is ineffective if the communication infrastructure cannot keep up with it. In this paper, we highlight the design principles of a dataflow-aware PIM-enabled manycore ",
    "link": "https://arxiv.org/abs/2403.19073",
    "context": "Title: Dataflow-Aware PIM-Enabled Manycore Architecture for Deep Learning Workloads\nAbstract: arXiv:2403.19073v1 Announce Type: cross  Abstract: Processing-in-memory (PIM) has emerged as an enabler for the energy-efficient and high-performance acceleration of deep learning (DL) workloads. Resistive random-access memory (ReRAM) is one of the most promising technologies to implement PIM. However, as the complexity of Deep convolutional neural networks (DNNs) grows, we need to design a manycore architecture with multiple ReRAM-based processing elements (PEs) on a single chip. Existing PIM-based architectures mostly focus on computation while ignoring the role of communication. ReRAM-based tiled manycore architectures often involve many Processing Elements (PEs), which need to be interconnected via an efficient on-chip communication infrastructure. Simply allocating more resources (ReRAMs) to speed up only computation is ineffective if the communication infrastructure cannot keep up with it. In this paper, we highlight the design principles of a dataflow-aware PIM-enabled manycore ",
    "path": "papers/24/03/2403.19073.json",
    "total_tokens": 797,
    "translated_title": "面向数据流的用于深度学习工作负载的PIM启用的多核体系结构",
    "translated_abstract": "Processing-in-memory (PIM)已经成为深度学习(DL)工作负载的能效高性能加速的推动因素。阻变随机存取存储器(ReRAM)是实现PIM的最有前途的技术之一。然而，随着深度卷积神经网络(DNNs)的复杂度增加，我们需要设计一个多核体系结构，在单片上有多个基于ReRAM的处理元素(PEs)。现有的基于PIM的体系结构主要关注计算，而忽视通信的作用。ReRAM为基础的切片式多核体系结构通常涉及许多处理元素(PEs)，这些元素需要通过高效的片上通信基础设施相互连接。如果通信基础设施无法跟得上，简单地分配更多资源(ReRAMs)来加速计算是无效的。",
    "tldr": "设计了一种面向数据流的PIM启用的多核体系结构以加速深度学习工作负载",
    "en_tdlr": "Proposed a dataflow-aware PIM-enabled manycore architecture to accelerate deep learning workloads."
}