{
    "title": "Segment Any Object Model (SAOM): Real-to-Simulation Fine-Tuning Strategy for Multi-Class Multi-Instance Segmentation",
    "abstract": "arXiv:2403.10780v1 Announce Type: cross  Abstract: Multi-class multi-instance segmentation is the task of identifying masks for multiple object classes and multiple instances of the same class within an image. The foundational Segment Anything Model (SAM) is designed for promptable multi-class multi-instance segmentation but tends to output part or sub-part masks in the \"everything\" mode for various real-world applications. Whole object segmentation masks play a crucial role for indoor scene understanding, especially in robotics applications. We propose a new domain invariant Real-to-Simulation (Real-Sim) fine-tuning strategy for SAM. We use object images and ground truth data collected from Ai2Thor simulator during fine-tuning (real-to-sim). To allow our Segment Any Object Model (SAOM) to work in the \"everything\" mode, we propose the novel nearest neighbour assignment method, updating point embeddings for each ground-truth mask. SAOM is evaluated on our own dataset collected from Ai2T",
    "link": "https://arxiv.org/abs/2403.10780",
    "context": "Title: Segment Any Object Model (SAOM): Real-to-Simulation Fine-Tuning Strategy for Multi-Class Multi-Instance Segmentation\nAbstract: arXiv:2403.10780v1 Announce Type: cross  Abstract: Multi-class multi-instance segmentation is the task of identifying masks for multiple object classes and multiple instances of the same class within an image. The foundational Segment Anything Model (SAM) is designed for promptable multi-class multi-instance segmentation but tends to output part or sub-part masks in the \"everything\" mode for various real-world applications. Whole object segmentation masks play a crucial role for indoor scene understanding, especially in robotics applications. We propose a new domain invariant Real-to-Simulation (Real-Sim) fine-tuning strategy for SAM. We use object images and ground truth data collected from Ai2Thor simulator during fine-tuning (real-to-sim). To allow our Segment Any Object Model (SAOM) to work in the \"everything\" mode, we propose the novel nearest neighbour assignment method, updating point embeddings for each ground-truth mask. SAOM is evaluated on our own dataset collected from Ai2T",
    "path": "papers/24/03/2403.10780.json",
    "total_tokens": 908,
    "translated_title": "物体任意模型（SAOM）：用于多类多实例分割的实际到仿真微调策略",
    "translated_abstract": "多类多实例分割是识别图像中多个对象类别和同一类别的多个实例的任务。基础的“Segment Anything Model”（SAM）专门设计用于多类多实例分割，但在各种真实世界应用中往往会以“一切”模式输出部分或子部分掩模。整体物体分割掩模在室内场景理解中发挥着至关重要的作用，尤其在机器人应用中。我们提出了一种新的域不变的Real-to-Simulation（Real-Sim）微调策略用于SAM。我们在微调（真实到仿真）期间使用从Ai2Thor模拟器收集的物体图像和地面真实数据。为了允许我们的Segment Any Object Model（SAOM）在“一切”模式下工作，我们提出了一种新颖的最近邻分配方法，更新每个地面真实掩模的点嵌入。SAOM在我们从Ai2T收集的自己的数据集上进行了评估。",
    "tldr": "提出了一种新颖的域不变的Real-to-Simulation微调策略，以实现多类多实例分割中Segment Any Object Model（SAOM）的“一切”模式工作，并在室内场景理解中发挥关键作用。",
    "en_tdlr": "Introduced a novel domain invariant Real-to-Simulation fine-tuning strategy to enable the \"everything\" mode operation of Segment Any Object Model (SAOM) for multi-class multi-instance segmentation, playing a crucial role in indoor scene understanding."
}