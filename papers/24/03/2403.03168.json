{
    "title": "Learning Explicitly Conditioned Sparsifying Transforms",
    "abstract": "arXiv:2403.03168v1 Announce Type: cross  Abstract: Sparsifying transforms became in the last decades widely known tools for finding structured sparse representations of signals in certain transform domains. Despite the popularity of classical transforms such as DCT and Wavelet, learning optimal transforms that guarantee good representations of data into the sparse domain has been recently analyzed in a series of papers. Typically, the conditioning number and representation ability are complementary key features of learning square transforms that may not be explicitly controlled in a given optimization model. Unlike the existing approaches from the literature, in our paper, we consider a new sparsifying transform model that enforces explicit control over the data representation quality and the condition number of the learned transforms. We confirm through numerical experiments that our model presents better numerical behavior than the state-of-the-art.",
    "link": "https://arxiv.org/abs/2403.03168",
    "context": "Title: Learning Explicitly Conditioned Sparsifying Transforms\nAbstract: arXiv:2403.03168v1 Announce Type: cross  Abstract: Sparsifying transforms became in the last decades widely known tools for finding structured sparse representations of signals in certain transform domains. Despite the popularity of classical transforms such as DCT and Wavelet, learning optimal transforms that guarantee good representations of data into the sparse domain has been recently analyzed in a series of papers. Typically, the conditioning number and representation ability are complementary key features of learning square transforms that may not be explicitly controlled in a given optimization model. Unlike the existing approaches from the literature, in our paper, we consider a new sparsifying transform model that enforces explicit control over the data representation quality and the condition number of the learned transforms. We confirm through numerical experiments that our model presents better numerical behavior than the state-of-the-art.",
    "path": "papers/24/03/2403.03168.json",
    "total_tokens": 796,
    "translated_title": "学习显式条件化稀疏变换",
    "translated_abstract": "在过去的几十年里，稀疏化变换已经成为一种广为人知的工具，用于在某些变换域中找到信号的结构稀疏表示。尽管像DCT和小波这样的经典变换很受欢迎，但最近在一系列论文中已经分析了学习保证数据在稀疏域中具有良好表示的最优变换。学习方块变换的条件数和表示能力通常是互补的关键特征，可能在给定的优化模型中不能明确控制。与现有文献中的方法不同，在我们的论文中，我们考虑了一种新的稀疏变换模型，该模型强制在学习变换的数据表示质量和条件数上进行显式控制。我们通过数值实验确认，我们的模型比最先进的模型具有更好的数值行为。",
    "tldr": "该论文提出了一种新的稀疏变换模型，通过显式控制数据表示质量和条件数，有效地学习保证数据在稀疏域中具有良好表示的优化变换。"
}