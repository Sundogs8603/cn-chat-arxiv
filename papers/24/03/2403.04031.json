{
    "title": "Can Large Language Models do Analytical Reasoning?",
    "abstract": "arXiv:2403.04031v1 Announce Type: cross  Abstract: This paper explores the cutting-edge Large Language Model with analytical reasoning on sports. Our analytical reasoning embodies the tasks of letting large language models count how many points each team scores in a quarter in the NBA and NFL games. Our major discoveries are in two folds. Firstly, we find among all the models we employed, GPT-4 stands out in effectiveness, followed by Claude-2.1, with GPT-3.5, Gemini-Pro, and Llama-2-70b lagging behind. Specifically, we compare three different prompting techniques and a divide-and-conquer approach, we find that the latter was the most effective. Our divide-and-conquer approach breaks down play-by-play data into smaller, more manageable segments, solves each piece individually, and then aggregates them together. Besides the divide-and-conquer approach, we also explore the Chain of Thought (CoT) strategy, which markedly improves outcomes for certain models, notably GPT-4 and Claude-2.1, ",
    "link": "https://arxiv.org/abs/2403.04031",
    "context": "Title: Can Large Language Models do Analytical Reasoning?\nAbstract: arXiv:2403.04031v1 Announce Type: cross  Abstract: This paper explores the cutting-edge Large Language Model with analytical reasoning on sports. Our analytical reasoning embodies the tasks of letting large language models count how many points each team scores in a quarter in the NBA and NFL games. Our major discoveries are in two folds. Firstly, we find among all the models we employed, GPT-4 stands out in effectiveness, followed by Claude-2.1, with GPT-3.5, Gemini-Pro, and Llama-2-70b lagging behind. Specifically, we compare three different prompting techniques and a divide-and-conquer approach, we find that the latter was the most effective. Our divide-and-conquer approach breaks down play-by-play data into smaller, more manageable segments, solves each piece individually, and then aggregates them together. Besides the divide-and-conquer approach, we also explore the Chain of Thought (CoT) strategy, which markedly improves outcomes for certain models, notably GPT-4 and Claude-2.1, ",
    "path": "papers/24/03/2403.04031.json",
    "total_tokens": 902,
    "translated_title": "大型语言模型能进行分析推理吗？",
    "translated_abstract": "这篇论文探讨了应用于体育领域的前沿大型语言模型进行分析推理。我们使用大型语言模型来计算NBA和NFL比赛中每支球队在一个季度中得分的任务。我们的主要发现有两个方面。首先，我们发现在我们使用的所有模型中，GPT-4在效果上表现最为突出，其次是Claude-2.1，而GPT-3.5、Gemini-Pro和Llama-2-70b效果稍逊。具体来说，我们比较了三种不同的提示技术和分治法，发现后者效果最好。我们的分治法将逐步数据细分为更小、更易处理的片段，分别解决每个片段，然后将它们合并在一起。除了分治法，我们还探讨了一种名为Chain of Thought（CoT）策略，显著改善了某些模型的结果，尤其是GPT-4和Claude-2.1。",
    "tldr": "本研究探索了大型语言模型在体育领域的分析推理能力，发现在处理NBA和NFL比赛得分任务时，GPT-4和Claude-2.1表现最佳，采用分治法进行数据处理效果最好。",
    "en_tdlr": "This study investigates the analytical reasoning capability of large language models in the sports domain, revealing that GPT-4 and Claude-2.1 perform best in handling tasks related to scoring in NBA and NFL games, with the divide-and-conquer approach proving to be the most effective."
}