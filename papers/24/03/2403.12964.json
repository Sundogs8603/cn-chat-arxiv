{
    "title": "Negative Yields Positive: Unified Dual-Path Adapter for Vision-Language Models",
    "abstract": "arXiv:2403.12964v1 Announce Type: cross  Abstract: Recently, large-scale pre-trained Vision-Language Models (VLMs) have demonstrated great potential in learning open-world visual representations, and exhibit remarkable performance across a wide range of downstream tasks through efficient fine-tuning. In this work, we innovatively introduce the concept of dual learning into fine-tuning VLMs, i.e., we not only learn what an image is, but also what an image isn't. Building on this concept, we introduce a novel DualAdapter approach to enable dual-path adaptation of VLMs from both positive and negative perspectives with only limited annotated samples. In the inference stage, our DualAdapter performs unified predictions by simultaneously conducting complementary positive selection and negative exclusion across target classes, thereby enhancing the overall recognition accuracy of VLMs in downstream tasks. Our extensive experimental results across 15 datasets validate that the proposed DualAda",
    "link": "https://arxiv.org/abs/2403.12964",
    "context": "Title: Negative Yields Positive: Unified Dual-Path Adapter for Vision-Language Models\nAbstract: arXiv:2403.12964v1 Announce Type: cross  Abstract: Recently, large-scale pre-trained Vision-Language Models (VLMs) have demonstrated great potential in learning open-world visual representations, and exhibit remarkable performance across a wide range of downstream tasks through efficient fine-tuning. In this work, we innovatively introduce the concept of dual learning into fine-tuning VLMs, i.e., we not only learn what an image is, but also what an image isn't. Building on this concept, we introduce a novel DualAdapter approach to enable dual-path adaptation of VLMs from both positive and negative perspectives with only limited annotated samples. In the inference stage, our DualAdapter performs unified predictions by simultaneously conducting complementary positive selection and negative exclusion across target classes, thereby enhancing the overall recognition accuracy of VLMs in downstream tasks. Our extensive experimental results across 15 datasets validate that the proposed DualAda",
    "path": "papers/24/03/2403.12964.json",
    "total_tokens": 885,
    "translated_title": "负得正：用于视觉语言模型的统一双路径适配器",
    "translated_abstract": "最近，大规模预训练的视觉-语言模型（VLMs）展示了学习开放世界视觉表示方面的巨大潜力，并通过高效微调在各种下游任务中展现出卓越性能。在这项工作中，我们创新地将双学习概念引入微调VLMs中，即我们不仅学习图像是什么，还学习图像不是什么。基于这一概念，我们提出了一种新颖的DualAdapter方法，使VLMs能够从正面和负面两方面进行双路径适配，仅使用有限的注释样本。在推理阶段，我们的DualAdapter通过针对目标类别同时进行补充正向选择和负向排除，实现了统一预测，从而提高了VLMs在下游任务中的整体识别准确性。我们广泛的实验结果跨越15个数据集，验证了所提出的DualAda",
    "tldr": "本研究在视觉-语言模型的微调中引入了双学习概念，提出了DualAdapter方法，通过正面和负面两方面的双路径适配，同时进行补充正向选择和负向排除，从而提高了在下游任务中的整体识别准确性。",
    "en_tdlr": "This study introduces the concept of dual learning into fine-tuning Vision-Language Models (VLMs) and presents a DualAdapter approach for dual-path adaptation from both positive and negative perspectives, enhancing the overall recognition accuracy in downstream tasks."
}