{
    "title": "Comparing effectiveness of regularization methods on text classification: Simple and complex model in data shortage situation",
    "abstract": "arXiv:2403.00825v1 Announce Type: new  Abstract: Text classification is the task of assigning a document to a predefined class. However, it is expensive to acquire enough labeled documents or to label them. In this paper, we study the regularization methods' effects on various classification models when only a few labeled data are available. We compare a simple word embedding-based model, which is simple but effective, with complex models (CNN and BiLSTM). In supervised learning, adversarial training can further regularize the model. When an unlabeled dataset is available, we can regularize the model using semi-supervised learning methods such as the Pi model and virtual adversarial training. We evaluate the regularization effects on four text classification datasets (AG news, DBpedia, Yahoo! Answers, Yelp Polarity), using only 0.1% to 0.5% of the original labeled training documents. The simple model performs relatively well in fully supervised learning, but with the help of adversaria",
    "link": "https://arxiv.org/abs/2403.00825",
    "context": "Title: Comparing effectiveness of regularization methods on text classification: Simple and complex model in data shortage situation\nAbstract: arXiv:2403.00825v1 Announce Type: new  Abstract: Text classification is the task of assigning a document to a predefined class. However, it is expensive to acquire enough labeled documents or to label them. In this paper, we study the regularization methods' effects on various classification models when only a few labeled data are available. We compare a simple word embedding-based model, which is simple but effective, with complex models (CNN and BiLSTM). In supervised learning, adversarial training can further regularize the model. When an unlabeled dataset is available, we can regularize the model using semi-supervised learning methods such as the Pi model and virtual adversarial training. We evaluate the regularization effects on four text classification datasets (AG news, DBpedia, Yahoo! Answers, Yelp Polarity), using only 0.1% to 0.5% of the original labeled training documents. The simple model performs relatively well in fully supervised learning, but with the help of adversaria",
    "path": "papers/24/03/2403.00825.json",
    "total_tokens": 937,
    "translated_title": "在数据短缺情况下比较正则化方法在文本分类中的有效性：简单和复杂模型的比较",
    "translated_abstract": "文本分类是将文档分配到预定义类别的任务。然而，获取足够标记的文档或对其进行标记是昂贵的。本文研究了当只有少量带标签数据可用时，正则化方法对各种分类模型的影响。我们将简单而有效的基于词嵌入的模型与复杂模型（CNN和BiLSTM）进行比较。在监督学习中，对抗训练可以进一步对模型进行正则化。当有一个未标记数据集可用时，我们可以使用半监督学习方法（如Pi模型和虚拟对抗训练）对模型进行正则化。我们仅使用原始标记训练文档的0.1%至0.5%来评估四个文本分类数据集（AG新闻、DBpedia、Yahoo! Answers、Yelp Polarity）上的正则化效果。简单模型在完全监督学习中表现相对良好，但在对抗性训练的帮助下",
    "tldr": "本文比较了当只有少量带标签数据可用时，简单的词嵌入模型与复杂模型（CNN和BiLSTM）在文本分类中的正则化效果，并探讨了对抗训练和半监督学习方法在提高模型性能方面的作用。",
    "en_tdlr": "This paper compares the regularization effects of simple word embedding model and complex models (CNN and BiLSTM) in text classification when only a few labeled data are available, and discusses the impact of adversarial training and semi-supervised learning methods on improving model performance."
}