{
    "title": "Interpretable Machine Learning for Weather and Climate Prediction: A Survey",
    "abstract": "arXiv:2403.18864v1 Announce Type: cross  Abstract: Advanced machine learning models have recently achieved high predictive accuracy for weather and climate prediction. However, these complex models often lack inherent transparency and interpretability, acting as \"black boxes\" that impede user trust and hinder further model improvements. As such, interpretable machine learning techniques have become crucial in enhancing the credibility and utility of weather and climate modeling. In this survey, we review current interpretable machine learning approaches applied to meteorological predictions. We categorize methods into two major paradigms: 1) Post-hoc interpretability techniques that explain pre-trained models, such as perturbation-based, game theory based, and gradient-based attribution methods. 2) Designing inherently interpretable models from scratch using architectures like tree ensembles and explainable neural networks. We summarize how each technique provides insights into the pre",
    "link": "https://arxiv.org/abs/2403.18864",
    "context": "Title: Interpretable Machine Learning for Weather and Climate Prediction: A Survey\nAbstract: arXiv:2403.18864v1 Announce Type: cross  Abstract: Advanced machine learning models have recently achieved high predictive accuracy for weather and climate prediction. However, these complex models often lack inherent transparency and interpretability, acting as \"black boxes\" that impede user trust and hinder further model improvements. As such, interpretable machine learning techniques have become crucial in enhancing the credibility and utility of weather and climate modeling. In this survey, we review current interpretable machine learning approaches applied to meteorological predictions. We categorize methods into two major paradigms: 1) Post-hoc interpretability techniques that explain pre-trained models, such as perturbation-based, game theory based, and gradient-based attribution methods. 2) Designing inherently interpretable models from scratch using architectures like tree ensembles and explainable neural networks. We summarize how each technique provides insights into the pre",
    "path": "papers/24/03/2403.18864.json",
    "total_tokens": 858,
    "translated_title": "可解释的机器学习用于天气和气候预测：一项调查",
    "translated_abstract": "最近，先进的机器学习模型在天气和气候预测方面取得了高预测准确性。然而，这些复杂模型通常缺乏固有的透明度和可解释性，表现为“黑匣子”，阻碍了用户信任，也限制了进一步的模型改进。因此，可解释的机器学习技术在增强天气和气候建模的可信度和实用性方面变得至关重要。在本调查中，我们审查了应用于气象预测的当前可解释的机器学习方法。我们将方法分类为两个主要范例：1）后验可解释性技术，解释预训练模型的方法，如基于扰动、基于博弈论和基于梯度的归因方法。2）从头开始设计固有可解释模型的方法，使用树集成和可解释神经网络等架构。我们总结了每种技术如何提供对预测模型内部的见解。",
    "tldr": "可解释的机器学习技术对于增强天气和气候建模的可信度和实用性至关重要，包括后验可解释性技术和从头设计的固有可解释模型。",
    "en_tdlr": "Interpretable machine learning techniques are crucial for enhancing the credibility and utility of weather and climate modeling, including post-hoc interpretability techniques and inherently interpretable model designs."
}