{
    "title": "DPP-Based Adversarial Prompt Searching for Lanugage Models",
    "abstract": "arXiv:2403.00292v1 Announce Type: new  Abstract: Language models risk generating mindless and offensive content, which hinders their safe deployment. Therefore, it is crucial to discover and modify potential toxic outputs of pre-trained language models before deployment. In this work, we elicit toxic content by automatically searching for a prompt that directs pre-trained language models towards the generation of a specific target output. The problem is challenging due to the discrete nature of textual data and the considerable computational resources required for a single forward pass of the language model. To combat these challenges, we introduce Auto-regressive Selective Replacement Ascent (ASRA), a discrete optimization algorithm that selects prompts based on both quality and similarity with determinantal point process (DPP). Experimental results on six different pre-trained language models demonstrate the efficacy of ASRA for eliciting toxic content. Furthermore, our analysis reve",
    "link": "https://arxiv.org/abs/2403.00292",
    "context": "Title: DPP-Based Adversarial Prompt Searching for Lanugage Models\nAbstract: arXiv:2403.00292v1 Announce Type: new  Abstract: Language models risk generating mindless and offensive content, which hinders their safe deployment. Therefore, it is crucial to discover and modify potential toxic outputs of pre-trained language models before deployment. In this work, we elicit toxic content by automatically searching for a prompt that directs pre-trained language models towards the generation of a specific target output. The problem is challenging due to the discrete nature of textual data and the considerable computational resources required for a single forward pass of the language model. To combat these challenges, we introduce Auto-regressive Selective Replacement Ascent (ASRA), a discrete optimization algorithm that selects prompts based on both quality and similarity with determinantal point process (DPP). Experimental results on six different pre-trained language models demonstrate the efficacy of ASRA for eliciting toxic content. Furthermore, our analysis reve",
    "path": "papers/24/03/2403.00292.json",
    "total_tokens": 785,
    "translated_title": "基于DPP的对抗性提示搜索用于语言模型",
    "translated_abstract": "语言模型存在生成毫无意义和冒犯性内容的风险，这妨碍了它们的安全部署。因此，在部署之前发现并修改预训练语言模型潜在的有毒输出是至关重要的。本研究中，我们通过自动搜索提示来引导预训练语言模型生成特定目标输出的有毒内容。该问题具有挑战性，因为文本数据的离散性以及针对语言模型的单次前向传递所需的大量计算资源。为了应对这些挑战，我们提出了自回归选择替代上升（ASRA）算法，这是一种基于确定性点过程（DPP）的选择提示的离散优化算法。对六种不同预训练语言模型的实验结果表明，ASRA对引发有毒内容具有很好的效果。",
    "tldr": "通过Auto-regressive Selective Replacement Ascent (ASRA)算法，我们成功引导预训练语言模型生成有毒内容，具有很好的效果。",
    "en_tdlr": "Leveraging Auto-regressive Selective Replacement Ascent (ASRA) algorithm, we effectively guide pre-trained language models to generate toxic content."
}