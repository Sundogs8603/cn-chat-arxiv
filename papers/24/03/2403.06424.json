{
    "title": "Bridging Domains with Approximately Shared Features",
    "abstract": "arXiv:2403.06424v1 Announce Type: cross  Abstract: Multi-source domain adaptation aims to reduce performance degradation when applying machine learning models to unseen domains. A fundamental challenge is devising the optimal strategy for feature selection. Existing literature is somewhat paradoxical: some advocate for learning invariant features from source domains, while others favor more diverse features. To address the challenge, we propose a statistical framework that distinguishes the utilities of features based on the variance of their correlation to label $y$ across domains. Under our framework, we design and analyze a learning procedure consisting of learning approximately shared feature representation from source tasks and fine-tuning it on the target task. Our theoretical analysis necessitates the importance of learning approximately shared features instead of only the strictly invariant features and yields an improved population risk compared to previous results on both sou",
    "link": "https://arxiv.org/abs/2403.06424",
    "context": "Title: Bridging Domains with Approximately Shared Features\nAbstract: arXiv:2403.06424v1 Announce Type: cross  Abstract: Multi-source domain adaptation aims to reduce performance degradation when applying machine learning models to unseen domains. A fundamental challenge is devising the optimal strategy for feature selection. Existing literature is somewhat paradoxical: some advocate for learning invariant features from source domains, while others favor more diverse features. To address the challenge, we propose a statistical framework that distinguishes the utilities of features based on the variance of their correlation to label $y$ across domains. Under our framework, we design and analyze a learning procedure consisting of learning approximately shared feature representation from source tasks and fine-tuning it on the target task. Our theoretical analysis necessitates the importance of learning approximately shared features instead of only the strictly invariant features and yields an improved population risk compared to previous results on both sou",
    "path": "papers/24/03/2403.06424.json",
    "total_tokens": 870,
    "translated_title": "通过大致共享特征来实现领域之间的桥梁",
    "translated_abstract": "多源领域适应旨在在将机器学习模型应用于未知领域时降低性能下降。一个基本挑战是设计特征选择的最佳策略。现有文献在某种程度上存在悖论：有些人主张从源领域学习不变特征，而另一些人则更青睐多样化特征。为了解决这一挑战，我们提出了一个统计框架，根据它们与标签 $y$ 的相关性的方差来区分特征的效用。在我们的框架下，我们设计和分析了一个学习过程，该过程由从源任务学习到的大致共享特征表示，并在目标任务上进行微调。我们的理论分析需要学习大致共享特征的重要性，而不仅仅是严格不变的特征，并且相对于以前关于源领域适应性的结果而言，产生了改进的总体风险。",
    "tldr": "提出了一种统计框架，根据特征与标签的相关性方差来区分特征的效用，并设计了一种学习过程，从源任务学习到大致共享的特征表示，并在目标任务上进行微调，以优化总体风险。"
}