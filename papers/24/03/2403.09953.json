{
    "title": "Online GNN Evaluation Under Test-time Graph Distribution Shifts",
    "abstract": "arXiv:2403.09953v1 Announce Type: new  Abstract: Evaluating the performance of a well-trained GNN model on real-world graphs is a pivotal step for reliable GNN online deployment and serving. Due to a lack of test node labels and unknown potential training-test graph data distribution shifts, conventional model evaluation encounters limitations in calculating performance metrics (e.g., test error) and measuring graph data-level discrepancies, particularly when the training graph used for developing GNNs remains unobserved during test time. In this paper, we study a new research problem, online GNN evaluation, which aims to provide valuable insights into the well-trained GNNs's ability to effectively generalize to real-world unlabeled graphs under the test-time graph distribution shifts. Concretely, we develop an effective learning behavior discrepancy score, dubbed LeBeD, to estimate the test-time generalization errors of well-trained GNN models. Through a novel GNN re-training strategy",
    "link": "https://arxiv.org/abs/2403.09953",
    "context": "Title: Online GNN Evaluation Under Test-time Graph Distribution Shifts\nAbstract: arXiv:2403.09953v1 Announce Type: new  Abstract: Evaluating the performance of a well-trained GNN model on real-world graphs is a pivotal step for reliable GNN online deployment and serving. Due to a lack of test node labels and unknown potential training-test graph data distribution shifts, conventional model evaluation encounters limitations in calculating performance metrics (e.g., test error) and measuring graph data-level discrepancies, particularly when the training graph used for developing GNNs remains unobserved during test time. In this paper, we study a new research problem, online GNN evaluation, which aims to provide valuable insights into the well-trained GNNs's ability to effectively generalize to real-world unlabeled graphs under the test-time graph distribution shifts. Concretely, we develop an effective learning behavior discrepancy score, dubbed LeBeD, to estimate the test-time generalization errors of well-trained GNN models. Through a novel GNN re-training strategy",
    "path": "papers/24/03/2403.09953.json",
    "total_tokens": 839,
    "translated_title": "在测试时间图分布转移下的在线GNN评估",
    "translated_abstract": "评估一个经过充分训练的GNN模型在真实世界图上的表现是可靠的GNN在线部署和服务的关键步骤。由于缺乏测试节点标签和未知潜在的训练-测试图数据分布转移，传统模型评估在计算性能指标（如测试错误）和测量图数据级别差异方面存在局限性，特别是在测试时所使用的训练图仍未被观察到。本文研究了一个新的研究问题，即在线GNN评估，旨在为经过充分训练的GNN在测试时间图分布转移下有效推广到真实世界无标签图提供宝贵见解。具体来说，我们开发了一种有效的学习行为差异评分，称为LeBeD，来估计经过充分训练的GNN模型的测试时间泛化错误。通过一种新颖的GNN重新训练策略",
    "tldr": "在线GNN评估研究了如何在测试时间图分布转移的情况下，衡量经过充分训练的GNN模型对真实世界无标签图的泛化能力。",
    "en_tdlr": "The study on online GNN evaluation investigates how well-trained GNN models generalize to real-world unlabeled graphs under test-time graph distribution shifts."
}