{
    "title": "Uncovering Selective State Space Model's Capabilities in Lifelong Sequential Recommendation",
    "abstract": "arXiv:2403.16371v1 Announce Type: new  Abstract: Sequential Recommenders have been widely applied in various online services, aiming to model users' dynamic interests from their sequential interactions. With users increasingly engaging with online platforms, vast amounts of lifelong user behavioral sequences have been generated. However, existing sequential recommender models often struggle to handle such lifelong sequences. The primary challenges stem from computational complexity and the ability to capture long-range dependencies within the sequence. Recently, a state space model featuring a selective mechanism (i.e., Mamba) has emerged. In this work, we investigate the performance of Mamba for lifelong sequential recommendation (i.e., length>=2k). More specifically, we leverage the Mamba block to model lifelong user sequences selectively. We conduct extensive experiments to evaluate the performance of representative sequential recommendation models in the setting of lifelong sequenc",
    "link": "https://arxiv.org/abs/2403.16371",
    "context": "Title: Uncovering Selective State Space Model's Capabilities in Lifelong Sequential Recommendation\nAbstract: arXiv:2403.16371v1 Announce Type: new  Abstract: Sequential Recommenders have been widely applied in various online services, aiming to model users' dynamic interests from their sequential interactions. With users increasingly engaging with online platforms, vast amounts of lifelong user behavioral sequences have been generated. However, existing sequential recommender models often struggle to handle such lifelong sequences. The primary challenges stem from computational complexity and the ability to capture long-range dependencies within the sequence. Recently, a state space model featuring a selective mechanism (i.e., Mamba) has emerged. In this work, we investigate the performance of Mamba for lifelong sequential recommendation (i.e., length>=2k). More specifically, we leverage the Mamba block to model lifelong user sequences selectively. We conduct extensive experiments to evaluate the performance of representative sequential recommendation models in the setting of lifelong sequenc",
    "path": "papers/24/03/2403.16371.json",
    "total_tokens": 825,
    "translated_title": "在终身序列推荐中揭示有选择性的状态空间模型的能力",
    "translated_abstract": "顺序推荐系统已广泛应用于各种在线服务中，旨在从用户的顺序交互中模拟他们的动态兴趣。随着用户越来越多地参与在线平台，生成了大量的终身用户行为序列。然而，现有的顺序推荐模型通常很难处理这样的终身序列。主要挑战源于计算复杂性和捕获序列中长距离依赖的能力。最近，一种具有选择机制（即Mamba）的状态空间模型开始出现。本文研究了Mamba在终身序列推荐（即长度>=2k）中的性能。具体来说，我们利用Mamba块有选择地模拟终身用户序列。我们进行了大量实验，评估了代表性顺序推荐模型在终身序列设置中的性能。",
    "tldr": "研究人员调查了具有选择机制的Mamba在终身序列推荐中的性能，通过有选择地利用Mamba块来模拟用户终身序列，以解决现有模型难以处理终身序列的挑战。",
    "en_tdlr": "Researchers investigated the performance of Mamba with a selective mechanism in lifelong sequential recommendation, utilizing Mamba blocks selectively to model lifelong user sequences and address the challenges faced by existing models in handling lifelong sequences."
}