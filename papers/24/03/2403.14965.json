{
    "title": "Comprehensive Evaluation and Insights into the Use of Large Language Models in the Automation of Behavior-Driven Development Acceptance Test Formulation",
    "abstract": "arXiv:2403.14965v1 Announce Type: cross  Abstract: Behavior-driven development (BDD) is an Agile testing methodology fostering collaboration among developers, QA analysts, and stakeholders. In this manuscript, we propose a novel approach to enhance BDD practices using large language models (LLMs) to automate acceptance test generation. Our study uses zero and few-shot prompts to evaluate LLMs such as GPT-3.5, GPT-4, Llama-2-13B, and PaLM-2. The paper presents a detailed methodology that includes the dataset, prompt techniques, LLMs, and the evaluation process. The results demonstrate that GPT-3.5 and GPT-4 generate error-free BDD acceptance tests with better performance. The few-shot prompt technique highlights its ability to provide higher accuracy by incorporating examples for in-context learning. Furthermore, the study examines syntax errors, validation accuracy, and comparative analysis of LLMs, revealing their effectiveness in enhancing BDD practices. However, our study acknowledg",
    "link": "https://arxiv.org/abs/2403.14965",
    "context": "Title: Comprehensive Evaluation and Insights into the Use of Large Language Models in the Automation of Behavior-Driven Development Acceptance Test Formulation\nAbstract: arXiv:2403.14965v1 Announce Type: cross  Abstract: Behavior-driven development (BDD) is an Agile testing methodology fostering collaboration among developers, QA analysts, and stakeholders. In this manuscript, we propose a novel approach to enhance BDD practices using large language models (LLMs) to automate acceptance test generation. Our study uses zero and few-shot prompts to evaluate LLMs such as GPT-3.5, GPT-4, Llama-2-13B, and PaLM-2. The paper presents a detailed methodology that includes the dataset, prompt techniques, LLMs, and the evaluation process. The results demonstrate that GPT-3.5 and GPT-4 generate error-free BDD acceptance tests with better performance. The few-shot prompt technique highlights its ability to provide higher accuracy by incorporating examples for in-context learning. Furthermore, the study examines syntax errors, validation accuracy, and comparative analysis of LLMs, revealing their effectiveness in enhancing BDD practices. However, our study acknowledg",
    "path": "papers/24/03/2403.14965.json",
    "total_tokens": 919,
    "translated_title": "大型语言模型在自动化行为驱动开发验收测试生成中的全面评估和见解",
    "translated_abstract": "行为驱动开发（BDD）是一种促进开发人员、QA分析员和利益相关者合作的敏捷测试方法论。在本文中，我们提出了一种新颖的方法来利用大型语言模型（LLMs）来增强BDD实践，从而自动化验收测试生成。我们的研究使用零和少量提示来评估诸如GPT-3.5、GPT-4、Llama-2-13B和PaLM-2等LLMs。该论文提出了一个包括数据集、提示技术、LLMs和评估过程的详细方法论。结果表明，GPT-3.5和GPT-4生成无错误的BDD验收测试，表现更佳。少量提示技术突显了通过纳入示例进行上下文学习来提供更高准确性的能力。此外，该研究还检查了语法错误、验证准确性以及LLMs的比较分析，揭示了它们在增强BDD实践中的有效性。",
    "tldr": "本文提出了一种利用大型语言模型自动化生成BDD验收测试的新方法，并通过使用GPT-3.5和GPT-4等模型，展示了其在提高准确性和增强BDD实践方面的有效性。",
    "en_tdlr": "This paper presents a novel approach to automate the generation of BDD acceptance tests using large language models, demonstrating the effectiveness in improving accuracy and enhancing BDD practices with models such as GPT-3.5 and GPT-4."
}