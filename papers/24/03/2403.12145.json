{
    "title": "Syn-QA2: Evaluating False Assumptions in Long-tail Questions with Synthetic QA Datasets",
    "abstract": "arXiv:2403.12145v1 Announce Type: new  Abstract: Sensitivity to false assumptions (or false premises) in information-seeking questions is critical for robust question-answering (QA) systems. Recent work has shown that false assumptions in naturally occurring questions pose challenges to current models, with low performance on both generative QA and simple detection tasks (Kim et al. 2023). However, the focus of existing work on naturally occurring questions leads to a gap in the analysis of model behavior on the long tail of the distribution of possible questions. To this end, we introduce Syn-(QA)$^2$, a set of two synthetically generated QA datasets: one generated using perturbed relations from Wikidata, and the other by perturbing HotpotQA (Yang et al. 2018). Our findings from evaluating a range of large language models are threefold: (1) false assumptions in QA are challenging, echoing the findings of prior work, (2) the binary detection task is challenging even compared to the dif",
    "link": "https://arxiv.org/abs/2403.12145",
    "context": "Title: Syn-QA2: Evaluating False Assumptions in Long-tail Questions with Synthetic QA Datasets\nAbstract: arXiv:2403.12145v1 Announce Type: new  Abstract: Sensitivity to false assumptions (or false premises) in information-seeking questions is critical for robust question-answering (QA) systems. Recent work has shown that false assumptions in naturally occurring questions pose challenges to current models, with low performance on both generative QA and simple detection tasks (Kim et al. 2023). However, the focus of existing work on naturally occurring questions leads to a gap in the analysis of model behavior on the long tail of the distribution of possible questions. To this end, we introduce Syn-(QA)$^2$, a set of two synthetically generated QA datasets: one generated using perturbed relations from Wikidata, and the other by perturbing HotpotQA (Yang et al. 2018). Our findings from evaluating a range of large language models are threefold: (1) false assumptions in QA are challenging, echoing the findings of prior work, (2) the binary detection task is challenging even compared to the dif",
    "path": "papers/24/03/2403.12145.json",
    "total_tokens": 828,
    "translated_title": "Syn-QA2: 使用合成QA数据集评估长尾问题中的错误假设",
    "translated_abstract": "最近的研究表明，信息检索问题中的错误假设(或错误前提)对于稳健的问答(QA)系统至关重要。然而，现有研究集中在自然发生的问题上，存在关于模型在可能问题分布的长尾上的行为分析的空白。因此，我们引入了Syn-(QA)$^2$，一个包含两个合成生成的QA数据集：一个是使用来自Wikidata的扰动关系生成的，另一个是通过扰动HotpotQA生成的。我们从评估一系列大型语言模型中得出的发现有三个：(1) QA中的错误假设是具有挑战性的，呼应了先前工作的发现，(2) 与不可区分任务相比，二元检测任务更具挑战性.",
    "tldr": "通过合成QA数据集Syn-(QA)$^2$的引入，作者发现在长尾问题上的错误假设对大型语言模型来说是具有挑战性的，尤其是在二元检测任务方面。",
    "en_tdlr": "By introducing the synthetic QA datasets Syn-(QA)$^2$, the authors found that false assumptions in long-tail questions pose challenges to large language models, particularly in the binary detection task."
}