{
    "title": "generAItor: Tree-in-the-Loop Text Generation for Language Model Explainability and Adaptation",
    "abstract": "arXiv:2403.07627v1 Announce Type: cross  Abstract: Large language models (LLMs) are widely deployed in various downstream tasks, e.g., auto-completion, aided writing, or chat-based text generation. However, the considered output candidates of the underlying search algorithm are under-explored and under-explained. We tackle this shortcoming by proposing a tree-in-the-loop approach, where a visual representation of the beam search tree is the central component for analyzing, explaining, and adapting the generated outputs. To support these tasks, we present generAItor, a visual analytics technique, augmenting the central beam search tree with various task-specific widgets, providing targeted visualizations and interaction possibilities. Our approach allows interactions on multiple levels and offers an iterative pipeline that encompasses generating, exploring, and comparing output candidates, as well as fine-tuning the model based on adapted data. Our case study shows that our tool generat",
    "link": "https://arxiv.org/abs/2403.07627",
    "context": "Title: generAItor: Tree-in-the-Loop Text Generation for Language Model Explainability and Adaptation\nAbstract: arXiv:2403.07627v1 Announce Type: cross  Abstract: Large language models (LLMs) are widely deployed in various downstream tasks, e.g., auto-completion, aided writing, or chat-based text generation. However, the considered output candidates of the underlying search algorithm are under-explored and under-explained. We tackle this shortcoming by proposing a tree-in-the-loop approach, where a visual representation of the beam search tree is the central component for analyzing, explaining, and adapting the generated outputs. To support these tasks, we present generAItor, a visual analytics technique, augmenting the central beam search tree with various task-specific widgets, providing targeted visualizations and interaction possibilities. Our approach allows interactions on multiple levels and offers an iterative pipeline that encompasses generating, exploring, and comparing output candidates, as well as fine-tuning the model based on adapted data. Our case study shows that our tool generat",
    "path": "papers/24/03/2403.07627.json",
    "total_tokens": 836,
    "translated_title": "generAItor: 树-环路文本生成用于语言模型的可解释性和适应性",
    "translated_abstract": "大语言模型（LLMs）广泛部署在各种下游任务中，例如自动完成、辅助写作或基于对话的文本生成。然而，搜索算法的输出候选结果被较少探索和解释。我们通过提出一种树-环路方法来解决这一不足，其中束搜索树的可视化表示是分析、解释和调整生成的输出的核心组件。为支持这些任务，我们提出了generAItor，一种视觉分析技术，将中心束搜索树与各种特定于任务的小部件相结合，提供有针对性的可视化和交互可能性。我们的方法允许在多个层面进行交互，并提供一个迭代流程，包括生成、探索和比较输出的候选结果，以及根据适应数据微调模型。我们的案例研究表明我们的工具 generat",
    "tldr": "提出了一种树-环路方法，通过将束搜索树与各种小部件相结合，提供了可视化和交互可能性，从而分析、解释和调整生成的输出。",
    "en_tdlr": "Introducing a tree-in-the-loop approach that combines the beam search tree with task-specific widgets to provide visualizations and interaction possibilities, aiding in the analysis, explanation, and adaptation of generated outputs."
}