{
    "title": "Zero-Shot Multi-task Hallucination Detection",
    "abstract": "arXiv:2403.12244v1 Announce Type: new  Abstract: In recent studies, the extensive utilization of large language models has underscored the importance of robust evaluation methodologies for assessing text generation quality and relevance to specific tasks. This has revealed a prevalent issue known as hallucination, an emergent condition in the model where generated text lacks faithfulness to the source and deviates from the evaluation criteria. In this study, we formally define hallucination and propose a framework for its quantitative detection in a zero-shot setting, leveraging our definition and the assumption that model outputs entail task and sample specific inputs. In detecting hallucinations, our solution achieves an accuracy of 0.78 in a model-aware setting and 0.61 in a model-agnostic setting. Notably, our solution maintains computational efficiency, requiring far less computational resources than other SOTA approaches, aligning with the trend towards lightweight and compressed",
    "link": "https://arxiv.org/abs/2403.12244",
    "context": "Title: Zero-Shot Multi-task Hallucination Detection\nAbstract: arXiv:2403.12244v1 Announce Type: new  Abstract: In recent studies, the extensive utilization of large language models has underscored the importance of robust evaluation methodologies for assessing text generation quality and relevance to specific tasks. This has revealed a prevalent issue known as hallucination, an emergent condition in the model where generated text lacks faithfulness to the source and deviates from the evaluation criteria. In this study, we formally define hallucination and propose a framework for its quantitative detection in a zero-shot setting, leveraging our definition and the assumption that model outputs entail task and sample specific inputs. In detecting hallucinations, our solution achieves an accuracy of 0.78 in a model-aware setting and 0.61 in a model-agnostic setting. Notably, our solution maintains computational efficiency, requiring far less computational resources than other SOTA approaches, aligning with the trend towards lightweight and compressed",
    "path": "papers/24/03/2403.12244.json",
    "total_tokens": 836,
    "translated_title": "零样本多任务幻觉检测",
    "translated_abstract": "在最近的研究中，大型语言模型的广泛利用突显了评估文本生成质量和与特定任务相关性的稳健方法的重要性。这揭示了一个普遍的问题，即幻觉，这是模型中的一种紧急情况，生成的文本与来源缺乏忠实度，并且偏离了评估标准。在这项研究中，我们正式定义了幻觉，并提出了一个框架，用于在零样本设置下定量检测幻觉，利用我们的定义和假设，即模型输出包含与任务和样本特定输入有关的信息。在检测幻觉时，我们的解决方案在模型感知设置中实现了0.78的准确度，在模型无关设置下实现了0.61的准确度。值得注意的是，我们的解决方案保持了计算效率，需要比其他SOTA方法少得多的计算资源，与轻量级和压缩的趋势保持一致。",
    "tldr": "提出了一个在零样本设置下定量检测幻觉的框架，并在模型感知设置下实现了0.78的准确度，同时保持了计算效率。",
    "en_tdlr": "Proposed a framework for quantitatively detecting hallucination in a zero-shot setting, achieving an accuracy of 0.78 in a model-aware setting, while maintaining computational efficiency."
}