{
    "title": "Learning using granularity statistical invariants for classification",
    "abstract": "arXiv:2403.20122v1 Announce Type: new  Abstract: Learning using statistical invariants (LUSI) is a new learning paradigm, which adopts weak convergence mechanism, and can be applied to a wider range of classification problems. However, the computation cost of invariant matrices in LUSI is high for large-scale datasets during training. To settle this issue, this paper introduces a granularity statistical invariant for LUSI, and develops a new learning paradigm called learning using granularity statistical invariants (LUGSI). LUGSI employs both strong and weak convergence mechanisms, taking a perspective of minimizing expected risk. As far as we know, it is the first time to construct granularity statistical invariants. Compared to LUSI, the introduction of this new statistical invariant brings two advantages. Firstly, it enhances the structural information of the data. Secondly, LUGSI transforms a large invariant matrix into a smaller one by maximizing the distance between classes, achi",
    "link": "https://arxiv.org/abs/2403.20122",
    "context": "Title: Learning using granularity statistical invariants for classification\nAbstract: arXiv:2403.20122v1 Announce Type: new  Abstract: Learning using statistical invariants (LUSI) is a new learning paradigm, which adopts weak convergence mechanism, and can be applied to a wider range of classification problems. However, the computation cost of invariant matrices in LUSI is high for large-scale datasets during training. To settle this issue, this paper introduces a granularity statistical invariant for LUSI, and develops a new learning paradigm called learning using granularity statistical invariants (LUGSI). LUGSI employs both strong and weak convergence mechanisms, taking a perspective of minimizing expected risk. As far as we know, it is the first time to construct granularity statistical invariants. Compared to LUSI, the introduction of this new statistical invariant brings two advantages. Firstly, it enhances the structural information of the data. Secondly, LUGSI transforms a large invariant matrix into a smaller one by maximizing the distance between classes, achi",
    "path": "papers/24/03/2403.20122.json",
    "total_tokens": 891,
    "translated_title": "使用粒度统计不变量进行分类的学习",
    "translated_abstract": "arXiv:2403.20122v1 公告类型：新摘要：学习使用统计不变量（Learning using statistical invariants，LUSI）是一种新的学习范式，采用了弱收敛机制，可以应用于更广泛的分类问题。然而，LUSI中不变矩阵的计算成本在训练过程中对于大规模数据集来说过高。为解决这一问题，本文引入了一种粒度统计不变量用于LUSI，并开发了一种名为学习使用粒度统计不变量（Learning using granularity statistical invariants，LUGSI）的新学习范式。LUGSI同时采用了强和弱收敛机制，以最小化预期风险的视角。据我们所知，这是第一次构建粒度统计不变量。与LUSI相比，引入这种新的统计不变量带来两个优势。首先，它增强了数据的结构信息。其次，LUGSI通过最大化类别之间的距离，将大的不变性矩阵转化为小矩阵，达到了降维的效果。",
    "tldr": "LUGSI是第一次引入粒度统计不变量，相较于LUSI，它通过强弱两种收敛机制并最小化预期风险，提高了数据结构信息并成功降维。",
    "en_tdlr": "LUGSI is the first to introduce granularity statistical invariants, which enhances structural information and achieves dimensionality reduction by employing both strong and weak convergence mechanisms to minimize expected risk compared to LUSI."
}