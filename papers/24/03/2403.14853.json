{
    "title": "iSpLib: A Library for Accelerating Graph Neural Networks using Auto-tuned Sparse Operations",
    "abstract": "arXiv:2403.14853v1 Announce Type: new  Abstract: Core computations in Graph Neural Network (GNN) training and inference are often mapped to sparse matrix operations such as sparse-dense matrix multiplication (SpMM). These sparse operations are harder to optimize by manual tuning because their performance depends significantly on the sparsity of input graphs, GNN models, and computing platforms. To address this challenge, we present iSpLib, a PyTorch-based C++ library equipped with auto-tuned sparse operations. iSpLib expedites GNN training with a cache-enabled backpropagation that stores intermediate matrices in local caches. The library offers a user-friendly Python plug-in that allows users to take advantage of our optimized PyTorch operations out-of-the-box for any existing linear algebra-based PyTorch implementation of popular GNNs (Graph Convolution Network, GraphSAGE, Graph Inference Network, etc.) with only two lines of additional code. We demonstrate that iSpLib obtains up to 2",
    "link": "https://arxiv.org/abs/2403.14853",
    "context": "Title: iSpLib: A Library for Accelerating Graph Neural Networks using Auto-tuned Sparse Operations\nAbstract: arXiv:2403.14853v1 Announce Type: new  Abstract: Core computations in Graph Neural Network (GNN) training and inference are often mapped to sparse matrix operations such as sparse-dense matrix multiplication (SpMM). These sparse operations are harder to optimize by manual tuning because their performance depends significantly on the sparsity of input graphs, GNN models, and computing platforms. To address this challenge, we present iSpLib, a PyTorch-based C++ library equipped with auto-tuned sparse operations. iSpLib expedites GNN training with a cache-enabled backpropagation that stores intermediate matrices in local caches. The library offers a user-friendly Python plug-in that allows users to take advantage of our optimized PyTorch operations out-of-the-box for any existing linear algebra-based PyTorch implementation of popular GNNs (Graph Convolution Network, GraphSAGE, Graph Inference Network, etc.) with only two lines of additional code. We demonstrate that iSpLib obtains up to 2",
    "path": "papers/24/03/2403.14853.json",
    "total_tokens": 930,
    "translated_title": "iSpLib：使用自动调优稀疏操作加速图神经网络的库",
    "translated_abstract": "图神经网络（GNN）训练和推断中的核心计算通常被映射到稀疏矩阵运算，如稀疏-稠密矩阵乘法（SpMM）。这些稀疏操作很难通过手动调优进行优化，因为它们的性能在很大程度上取决于输入图的稀疏性、GNN模型和计算平台。为解决这一挑战，我们提出了iSpLib，一个基于PyTorch的C++库，配备了自动调优的稀疏操作。iSpLib通过具有缓存功能的反向传播加快了GNN训练，该反向传播将中间矩阵存储在本地缓存中。该库提供了一个用户友好的Python插件，允许用户利用我们优化过的PyTorch操作，仅需两行额外代码即可直接在任何现有基于线性代数的PyTorch实现的流行GNN（图卷积网络、GraphSAGE、图推理网络等）中使用。我们展示了iSpLib在不同数据集上的训练加速，最大可达2倍。",
    "tldr": "iSpLib是一个基于PyTorch的C++库，提供了自动调优的稀疏操作，加速了图神经网络的训练，并通过缓存优化和用户友好的Python插件实现了简便的操作。",
    "en_tdlr": "iSpLib is a PyTorch-based C++ library with auto-tuned sparse operations that accelerates the training of Graph Neural Networks, providing cache optimization and a user-friendly Python plugin for ease of use."
}