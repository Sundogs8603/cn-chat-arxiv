{
    "title": "Balancing Fairness and Accuracy in Data-Restricted Binary Classification",
    "abstract": "arXiv:2403.07724v1 Announce Type: cross  Abstract: Applications that deal with sensitive information may have restrictions placed on the data available to a machine learning (ML) classifier. For example, in some applications, a classifier may not have direct access to sensitive attributes, affecting its ability to produce accurate and fair decisions. This paper proposes a framework that models the trade-off between accuracy and fairness under four practical scenarios that dictate the type of data available for analysis. Prior works examine this trade-off by analyzing the outputs of a scoring function that has been trained to implicitly learn the underlying distribution of the feature vector, class label, and sensitive attribute of a dataset. In contrast, our framework directly analyzes the behavior of the optimal Bayesian classifier on this underlying distribution by constructing a discrete approximation it from the dataset itself. This approach enables us to formulate multiple convex ",
    "link": "https://arxiv.org/abs/2403.07724",
    "context": "Title: Balancing Fairness and Accuracy in Data-Restricted Binary Classification\nAbstract: arXiv:2403.07724v1 Announce Type: cross  Abstract: Applications that deal with sensitive information may have restrictions placed on the data available to a machine learning (ML) classifier. For example, in some applications, a classifier may not have direct access to sensitive attributes, affecting its ability to produce accurate and fair decisions. This paper proposes a framework that models the trade-off between accuracy and fairness under four practical scenarios that dictate the type of data available for analysis. Prior works examine this trade-off by analyzing the outputs of a scoring function that has been trained to implicitly learn the underlying distribution of the feature vector, class label, and sensitive attribute of a dataset. In contrast, our framework directly analyzes the behavior of the optimal Bayesian classifier on this underlying distribution by constructing a discrete approximation it from the dataset itself. This approach enables us to formulate multiple convex ",
    "path": "papers/24/03/2403.07724.json",
    "total_tokens": 747,
    "translated_title": "在数据限制的二分类中平衡公平性和准确性",
    "translated_abstract": "处理敏感信息的应用可能对机器学习（ML）分类器可用数据设置限制。本文提出一个框架，模拟准确性和公平性之间的权衡，在四种实际情景下探讨可用于分析的数据类型。与先前研究通过分析经训练以隐式学习数据集的特征向量、类别标签和敏感属性的潜在分布的评分函数的输出来考虑这种权衡不同，我们的框架直接通过从数据集本身构建的离散近似来分析最优贝叶斯分类器在这个潜在分布上的行为。这种方法使我们能够制定多个凸优化问题，以更好地平衡准确性和公平性。",
    "tldr": "研究提出了一个框架，直接分析最优贝叶斯分类器在数据限制的情况下的行为，以平衡准确性和公平性。",
    "en_tdlr": "This paper proposes a framework that directly analyzes the behavior of the optimal Bayesian classifier under data restrictions to balance accuracy and fairness."
}