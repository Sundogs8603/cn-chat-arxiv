{
    "title": "What Sketch Explainability Really Means for Downstream Tasks",
    "abstract": "arXiv:2403.09480v1 Announce Type: cross  Abstract: In this paper, we explore the unique modality of sketch for explainability, emphasising the profound impact of human strokes compared to conventional pixel-oriented studies. Beyond explanations of network behavior, we discern the genuine implications of explainability across diverse downstream sketch-related tasks. We propose a lightweight and portable explainability solution -- a seamless plugin that integrates effortlessly with any pre-trained model, eliminating the need for re-training. Demonstrating its adaptability, we present four applications: highly studied retrieval and generation, and completely novel assisted drawing and sketch adversarial attacks. The centrepiece to our solution is a stroke-level attribution map that takes different forms when linked with downstream tasks. By addressing the inherent non-differentiability of rasterisation, we enable explanations at both coarse stroke level (SLA) and partial stroke level (P-S",
    "link": "https://arxiv.org/abs/2403.09480",
    "context": "Title: What Sketch Explainability Really Means for Downstream Tasks\nAbstract: arXiv:2403.09480v1 Announce Type: cross  Abstract: In this paper, we explore the unique modality of sketch for explainability, emphasising the profound impact of human strokes compared to conventional pixel-oriented studies. Beyond explanations of network behavior, we discern the genuine implications of explainability across diverse downstream sketch-related tasks. We propose a lightweight and portable explainability solution -- a seamless plugin that integrates effortlessly with any pre-trained model, eliminating the need for re-training. Demonstrating its adaptability, we present four applications: highly studied retrieval and generation, and completely novel assisted drawing and sketch adversarial attacks. The centrepiece to our solution is a stroke-level attribution map that takes different forms when linked with downstream tasks. By addressing the inherent non-differentiability of rasterisation, we enable explanations at both coarse stroke level (SLA) and partial stroke level (P-S",
    "path": "papers/24/03/2403.09480.json",
    "total_tokens": 868,
    "translated_title": "Sketch解释在下游任务中的实际含义",
    "translated_abstract": "在本文中，我们探讨了涵盖草图解释性的独特模态，强调人类笔触相对于传统基于像素的研究所产生的深远影响。除了解释网络行为之外，我们还辨别了解释性在不同下游与草图相关任务中的真正含义。我们提出了一种轻量且便携的解释性解决方案——一个无缝插件，能够轻松与任何预训练模型集成，消除了重新训练的需要。为了展示其适应性，我们提出了四个应用：广受关注的检索和生成，以及全新的辅助绘图和草图对抗攻击。我们解决方案的核心是一种笔触级别的归因地图，在与下游任务链接时呈现不同形式。通过解决光栅化的固有不可微性，我们实现了在粗略笔触级别（SLA）和部分笔触级别（P-S）进行解释的能力。",
    "tldr": "本文探讨了草图解释的独特性，提出了适用于各种下游任务的解释性解决方案，包括四个应用领域：检索、生成、辅助绘图以及草图对抗攻击。",
    "en_tdlr": "This paper explores the uniqueness of sketch explainability and proposes an interpretable solution for various downstream tasks, including retrieval, generation, assisted drawing, and sketch adversarial attacks."
}