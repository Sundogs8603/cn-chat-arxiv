{
    "title": "A Question on the Explainability of Large Language Models and the Word-Level Univariate First-Order Plausibility Assumption",
    "abstract": "arXiv:2403.10275v1 Announce Type: cross  Abstract: The explanations of large language models have recently been shown to be sensitive to the randomness used for their training, creating a need to characterize this sensitivity. In this paper, we propose a characterization that questions the possibility to provide simple and informative explanations for such models. To this end, we give statistical definitions for the explanations' signal, noise and signal-to-noise ratio. We highlight that, in a typical case study where word-level univariate explanations are analyzed with first-order statistical tools, the explanations of simple feature-based models carry more signal and less noise than those of transformer ones. We then discuss the possibility to improve these results with alternative definitions of signal and noise that would capture more complex explanations and analysis methods, while also questioning the tradeoff with their plausibility for readers.",
    "link": "https://arxiv.org/abs/2403.10275",
    "context": "Title: A Question on the Explainability of Large Language Models and the Word-Level Univariate First-Order Plausibility Assumption\nAbstract: arXiv:2403.10275v1 Announce Type: cross  Abstract: The explanations of large language models have recently been shown to be sensitive to the randomness used for their training, creating a need to characterize this sensitivity. In this paper, we propose a characterization that questions the possibility to provide simple and informative explanations for such models. To this end, we give statistical definitions for the explanations' signal, noise and signal-to-noise ratio. We highlight that, in a typical case study where word-level univariate explanations are analyzed with first-order statistical tools, the explanations of simple feature-based models carry more signal and less noise than those of transformer ones. We then discuss the possibility to improve these results with alternative definitions of signal and noise that would capture more complex explanations and analysis methods, while also questioning the tradeoff with their plausibility for readers.",
    "path": "papers/24/03/2403.10275.json",
    "total_tokens": 819,
    "translated_title": "关于大型语言模型的可解释性问题和基于词级单变量一阶概率假设的研究",
    "translated_abstract": "最近研究表明，大型语言模型的解释对其训练中使用的随机性很敏感，因此需要对这种敏感性进行表征。本文提出了一个挑战为这些模型提供简单和信息丰富解释的表征方法。为此，我们为解释的信号、噪声和信噪比给出了统计定义。我们强调，在一个典型案例研究中，使用一阶统计工具分析基于单一特征的模型解释时，简单特征模型的解释传递更多信号并且噪声更少。然后，我们讨论了通过替代信号和噪声的定义来改进这些结果的可能性，这种方法可以捕捉更复杂的解释和分析方法，同时也质疑了与读者可信度之间的权衡。",
    "tldr": "本文提出了一个方法来挑战为大型语言模型提供简单而丰富解释的可能性，研究发现使用基于特征的模型在信号传递方面效果更好。",
    "en_tdlr": "This paper proposes a method to challenge the possibility of providing simple and informative explanations for large language models, finding that feature-based models perform better in signal transmission."
}