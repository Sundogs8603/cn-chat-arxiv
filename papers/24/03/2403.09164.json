{
    "title": "Exploring the Comprehension of ChatGPT in Traditional Chinese Medicine Knowledge",
    "abstract": "arXiv:2403.09164v1 Announce Type: new  Abstract: No previous work has studied the performance of Large Language Models (LLMs) in the context of Traditional Chinese Medicine (TCM), an essential and distinct branch of medical knowledge with a rich history. To bridge this gap, we present a TCM question dataset named TCM-QA, which comprises three question types: single choice, multiple choice, and true or false, to examine the LLM's capacity for knowledge recall and comprehensive reasoning within the TCM domain. In our study, we evaluate two settings of the LLM, zero-shot and few-shot settings, while concurrently discussing the differences between English and Chinese prompts. Our results indicate that ChatGPT performs best in true or false questions, achieving the highest precision of 0.688 while scoring the lowest precision is 0.241 in multiple-choice questions. Furthermore, we observed that Chinese prompts outperformed English prompts in our evaluations. Additionally, we assess the quali",
    "link": "https://arxiv.org/abs/2403.09164",
    "context": "Title: Exploring the Comprehension of ChatGPT in Traditional Chinese Medicine Knowledge\nAbstract: arXiv:2403.09164v1 Announce Type: new  Abstract: No previous work has studied the performance of Large Language Models (LLMs) in the context of Traditional Chinese Medicine (TCM), an essential and distinct branch of medical knowledge with a rich history. To bridge this gap, we present a TCM question dataset named TCM-QA, which comprises three question types: single choice, multiple choice, and true or false, to examine the LLM's capacity for knowledge recall and comprehensive reasoning within the TCM domain. In our study, we evaluate two settings of the LLM, zero-shot and few-shot settings, while concurrently discussing the differences between English and Chinese prompts. Our results indicate that ChatGPT performs best in true or false questions, achieving the highest precision of 0.688 while scoring the lowest precision is 0.241 in multiple-choice questions. Furthermore, we observed that Chinese prompts outperformed English prompts in our evaluations. Additionally, we assess the quali",
    "path": "papers/24/03/2403.09164.json",
    "total_tokens": 867,
    "translated_title": "探究ChatGPT在中医知识理解中的应用",
    "translated_abstract": "尚无先前的研究关注大语言模型（LLMs）在传统中医学（TCM）领域中的性能，这是一门具有丰富历史的重要而独特的医学知识分支。为弥补这一空白，我们提出了一个名为TCM-QA的中医问题数据集，包括三种问题类型：单项选择、多项选择和判断题，以检验LLM在TCM领域内知识回忆和全面推理的能力。在我们的研究中，我们评估了LLM的两种设置，即零次和少次设置，同时讨论了英文和中文提示之间的差异。我们的结果表明，ChatGPT在判断题中表现最佳，精确度最高达到0.688，而在多项选择问题中得分最低的精确度为0.241。此外，我们观察到在我们的评估中，中文提示表现优于英文提示。",
    "tldr": "探索了ChatGPT在中医知识理解中的应用，提出了TCM-QA数据集，评估了LLM的性能，并发现在判断题中表现最佳，中文提示优于英文提示。",
    "en_tdlr": "Explored the application of ChatGPT in understanding traditional Chinese medicine knowledge, introduced TCM-QA dataset, evaluated the performance of LLM, and found that it performed best in true or false questions with Chinese prompts outperforming English prompts."
}