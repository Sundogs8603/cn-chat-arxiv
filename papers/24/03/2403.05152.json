{
    "title": "Towards a Psychology of Machines: Large Language Models Predict Human Memory",
    "abstract": "arXiv:2403.05152v1 Announce Type: cross  Abstract: Large language models (LLMs) are demonstrating remarkable capabilities across various tasks despite lacking a foundation in human cognition. This raises the question: can these models, beyond simply mimicking human language patterns, offer insights into the mechanisms underlying human cognition? This study explores the ability of ChatGPT to predict human performance in a language-based memory task. Building upon theories of text comprehension, we hypothesize that recognizing ambiguous sentences (e.g., \"Because Bill drinks wine is never kept in the house\") is facilitated by preceding them with contextually relevant information. Participants, both human and ChatGPT, were presented with pairs of sentences. The second sentence was always a garden-path sentence designed to be inherently ambiguous, while the first sentence either provided a fitting (e.g., \"Bill has chronic alcoholism\") or an unfitting context (e.g., \"Bill likes to play golf\"",
    "link": "https://arxiv.org/abs/2403.05152",
    "context": "Title: Towards a Psychology of Machines: Large Language Models Predict Human Memory\nAbstract: arXiv:2403.05152v1 Announce Type: cross  Abstract: Large language models (LLMs) are demonstrating remarkable capabilities across various tasks despite lacking a foundation in human cognition. This raises the question: can these models, beyond simply mimicking human language patterns, offer insights into the mechanisms underlying human cognition? This study explores the ability of ChatGPT to predict human performance in a language-based memory task. Building upon theories of text comprehension, we hypothesize that recognizing ambiguous sentences (e.g., \"Because Bill drinks wine is never kept in the house\") is facilitated by preceding them with contextually relevant information. Participants, both human and ChatGPT, were presented with pairs of sentences. The second sentence was always a garden-path sentence designed to be inherently ambiguous, while the first sentence either provided a fitting (e.g., \"Bill has chronic alcoholism\") or an unfitting context (e.g., \"Bill likes to play golf\"",
    "path": "papers/24/03/2403.05152.json",
    "total_tokens": 877,
    "translated_title": "朝向机器心理学：大型语言模型预测人类记忆",
    "translated_abstract": "大型语言模型（LLMs）在各种任务中展示出了非凡的能力，尽管缺乏人类认知基础。这引发了一个问题：除了简单模仿人类语言模式，这些模型能否提供关于人类认知机制的洞见？本研究探讨了ChatGPT在预测基于语言的记忆任务中人类表现的能力。基于文本理解理论，我们假设识别模棱两可的句子（例如，“因为比尔喝酒，所以酒从未留在房子里”）在前面提供与上下文相关信息的情况下会得到促进。参与者，无论是人类还是ChatGPT，都被呈现成对的句子。第二个句子总是一个旨在固有地模棱两可的花园路径句，而第一个句子则提供了合适的（例如，“比尔患有慢性酒精中毒”）或不合适的上下文（例如，“比尔喜欢打高尔夫”）。",
    "tldr": "这项研究探索了大型语言模型在预测基于语言的记忆任务中的表现，并通过其对模棱两可句子的处理能力增进了对人类认知机制的理解。"
}