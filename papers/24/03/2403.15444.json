{
    "title": "A Survey of IMU Based Cross-Modal Transfer Learning in Human Activity Recognition",
    "abstract": "arXiv:2403.15444v1 Announce Type: cross  Abstract: Despite living in a multi-sensory world, most AI models are limited to textual and visual understanding of human motion and behavior. In fact, full situational awareness of human motion could best be understood through a combination of sensors. In this survey we investigate how knowledge can be transferred and utilized amongst modalities for Human Activity/Action Recognition (HAR), i.e. cross-modality transfer learning. We motivate the importance and potential of IMU data and its applicability in cross-modality learning as well as the importance of studying the HAR problem. We categorize HAR related tasks by time and abstractness and then compare various types of multimodal HAR datasets. We also distinguish and expound on many related but inconsistently used terms in the literature, such as transfer learning, domain adaptation, representation learning, sensor fusion, and multimodal learning, and describe how cross-modal learning fits w",
    "link": "https://arxiv.org/abs/2403.15444",
    "context": "Title: A Survey of IMU Based Cross-Modal Transfer Learning in Human Activity Recognition\nAbstract: arXiv:2403.15444v1 Announce Type: cross  Abstract: Despite living in a multi-sensory world, most AI models are limited to textual and visual understanding of human motion and behavior. In fact, full situational awareness of human motion could best be understood through a combination of sensors. In this survey we investigate how knowledge can be transferred and utilized amongst modalities for Human Activity/Action Recognition (HAR), i.e. cross-modality transfer learning. We motivate the importance and potential of IMU data and its applicability in cross-modality learning as well as the importance of studying the HAR problem. We categorize HAR related tasks by time and abstractness and then compare various types of multimodal HAR datasets. We also distinguish and expound on many related but inconsistently used terms in the literature, such as transfer learning, domain adaptation, representation learning, sensor fusion, and multimodal learning, and describe how cross-modal learning fits w",
    "path": "papers/24/03/2403.15444.json",
    "total_tokens": 908,
    "translated_title": "基于IMU的跨模态迁移学习在人类活动识别中的调查",
    "translated_abstract": "尽管生活在一个多感知世界中，大多数人工智能模型仍然局限于对人体运动和行为的文本和视觉理解。事实上，对人类运动的完整情境意识最好是通过传感器的组合来理解。在本调查中，我们研究了如何在人类活动/动作识别（HAR）中跨模态迁移学习中传递和利用知识。我们阐述了IMU数据及其在跨模态学习中的适用性的重要性和潜力，以及研究HAR问题的重要性。我们通过时间和抽象性将HAR相关任务进行了分类，然后比较了各种类型的多模态HAR数据集。我们还区分和详细阐述了文献中许多相关但不一致使用的术语，如迁移学习、域自适应、表示学习、传感器融合和多模态学习，并描述了跨模态学习如何适应。",
    "tldr": "本篇论文调查了如何在人类活动/动作识别中实现跨模态迁移学习，探讨了IMU数据在此领域中的潜在应用，对HAR问题进行了重要性探讨，并比较了不同类型的多模态HAR数据集。",
    "en_tdlr": "This paper investigates how to achieve cross-modal transfer learning in human activity/action recognition, explores the potential applications of IMU data in this field, discusses the importance of the HAR problem, and compares different types of multimodal HAR datasets."
}