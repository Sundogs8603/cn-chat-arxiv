{
    "title": "Should We Fear Large Language Models? A Structural Analysis of the Human Reasoning System for Elucidating LLM Capabilities and Risks Through the Lens of Heidegger's Philosophy",
    "abstract": "arXiv:2403.03288v1 Announce Type: new  Abstract: In the rapidly evolving field of Large Language Models (LLMs), there is a critical need to thoroughly analyze their capabilities and risks. Central to our investigation are two novel elements. Firstly, it is the innovative parallels between the statistical patterns of word relationships within LLMs and Martin Heidegger's concepts of \"ready-to-hand\" and \"present-at-hand,\" which encapsulate the utilitarian and scientific altitudes humans employ in interacting with the world. This comparison lays the groundwork for positioning LLMs as the digital counterpart to the Faculty of Verbal Knowledge, shedding light on their capacity to emulate certain facets of human reasoning. Secondly, a structural analysis of human reasoning, viewed through Heidegger's notion of truth as \"unconcealment\" is conducted This foundational principle enables us to map out the inputs and outputs of the reasoning system and divide reasoning into four distinct categories",
    "link": "https://arxiv.org/abs/2403.03288",
    "context": "Title: Should We Fear Large Language Models? A Structural Analysis of the Human Reasoning System for Elucidating LLM Capabilities and Risks Through the Lens of Heidegger's Philosophy\nAbstract: arXiv:2403.03288v1 Announce Type: new  Abstract: In the rapidly evolving field of Large Language Models (LLMs), there is a critical need to thoroughly analyze their capabilities and risks. Central to our investigation are two novel elements. Firstly, it is the innovative parallels between the statistical patterns of word relationships within LLMs and Martin Heidegger's concepts of \"ready-to-hand\" and \"present-at-hand,\" which encapsulate the utilitarian and scientific altitudes humans employ in interacting with the world. This comparison lays the groundwork for positioning LLMs as the digital counterpart to the Faculty of Verbal Knowledge, shedding light on their capacity to emulate certain facets of human reasoning. Secondly, a structural analysis of human reasoning, viewed through Heidegger's notion of truth as \"unconcealment\" is conducted This foundational principle enables us to map out the inputs and outputs of the reasoning system and divide reasoning into four distinct categories",
    "path": "papers/24/03/2403.03288.json",
    "total_tokens": 925,
    "translated_title": "我们应该担心大型语言模型吗？通过海德格尔哲学视角阐明LLM的能力和风险的人类推理系统的结构分析",
    "translated_abstract": "在快速发展的大型语言模型（LLMs）领域，有必要彻底分析它们的能力和风险。我们研究的核心是两个创新元素。首先，是LLMs中单词关系的统计模式与马丁·海德格尔的\"就绪\"和\"现存\"概念之间的创新类比，它概括了人类与世界互动中使用的实用和科学态度。这种比较奠定了将LLMs定位为数字化对应人类知识能力的基础，揭示了它们模拟人类推理某些方面的能力。其次，通过海德格尔将真理理解为\"揭示\"的概念对人类推理进行结构分析。这一基础原则使我们能够绘制推理系统的输入和输出，并将推理划分为四个不同类别。",
    "tldr": "本研究通过比较LLMs中的统计模式与海德格尔哲学概念，探讨了LLMs作为知识能力数字化对应和人类推理模拟的能力，并通过海德格尔的真理概念对人类推理进行结构性分析。",
    "en_tdlr": "This study examines the parallels between statistical patterns in LLMs and Heidegger's philosophy, discussing LLMs as digital counterparts to human knowledge and their ability to simulate human reasoning, alongside a structural analysis of human reasoning based on Heidegger's concept of truth."
}