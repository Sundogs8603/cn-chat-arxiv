{
    "title": "Projected Gradient Descent for Spectral Compressed Sensing via Symmetric Hankel Factorization",
    "abstract": "arXiv:2403.09031v1 Announce Type: new  Abstract: Current spectral compressed sensing methods via Hankel matrix completion employ symmetric factorization to demonstrate the low-rank property of the Hankel matrix. However, previous non-convex gradient methods only utilize asymmetric factorization to achieve spectral compressed sensing. In this paper, we propose a novel nonconvex projected gradient descent method for spectral compressed sensing via symmetric factorization named Symmetric Hankel Projected Gradient Descent (SHGD), which updates only one matrix and avoids a balancing regularization term. SHGD reduces about half of the computation and storage costs compared to the prior gradient method based on asymmetric factorization. {Besides, the symmetric factorization employed in our work is completely novel to the prior low-rank factorization model, introducing a new factorization ambiguity under complex orthogonal transformation}. Novel distance metrics are designed for our factorizat",
    "link": "https://arxiv.org/abs/2403.09031",
    "context": "Title: Projected Gradient Descent for Spectral Compressed Sensing via Symmetric Hankel Factorization\nAbstract: arXiv:2403.09031v1 Announce Type: new  Abstract: Current spectral compressed sensing methods via Hankel matrix completion employ symmetric factorization to demonstrate the low-rank property of the Hankel matrix. However, previous non-convex gradient methods only utilize asymmetric factorization to achieve spectral compressed sensing. In this paper, we propose a novel nonconvex projected gradient descent method for spectral compressed sensing via symmetric factorization named Symmetric Hankel Projected Gradient Descent (SHGD), which updates only one matrix and avoids a balancing regularization term. SHGD reduces about half of the computation and storage costs compared to the prior gradient method based on asymmetric factorization. {Besides, the symmetric factorization employed in our work is completely novel to the prior low-rank factorization model, introducing a new factorization ambiguity under complex orthogonal transformation}. Novel distance metrics are designed for our factorizat",
    "path": "papers/24/03/2403.09031.json",
    "total_tokens": 849,
    "translated_title": "基于对称 Hankel 因子分解的谱压缩感知的投影梯度下降",
    "translated_abstract": "当前谱压缩感知方法通过 Hankel 矩阵完成采用对称因子分解来展示 Hankel 矩阵的低秩性质。然而，先前的非凸梯度方法只利用不对称因子分解来实现谱压缩感知。在本文中，我们提出了一种新颖的投影梯度下降方法，通过对称因子分解进行谱压缩感知，名为对称 Hankel 投影梯度下降（SHGD），它仅更新一个矩阵并避免了平衡正则化项。与基于不对称因子分解的先前梯度方法相比，SHGD减少了大约一半的计算和存储成本。此外，我们工作中使用的对称因子分解与先前的低秩分解模型完全不同，引入了在复正交变换下的新因子分解歧义。我们为我们的分解设计了新颖的距离度量。",
    "tldr": "提出了一种新的投影梯度下降方法（SHGD），通过对称因子分解进行谱压缩感知，减少了计算和存储成本，引入了新的因子分解歧义。",
    "en_tdlr": "Introduced a novel projected gradient descent method (SHGD) for spectral compressed sensing via symmetric factorization, reducing computational and storage costs and introducing a new factorization ambiguity."
}