{
    "title": "Reading Subtext: Evaluating Large Language Models on Short Story Summarization with Writers",
    "abstract": "arXiv:2403.01061v1 Announce Type: new  Abstract: We evaluate recent Large language Models (LLMs) on the challenging task of summarizing short stories, which can be lengthy, and include nuanced subtext or scrambled timelines. Importantly, we work directly with authors to ensure that the stories have not been shared online (and therefore are unseen by the models), and to obtain informed evaluations of summary quality using judgments from the authors themselves. Through quantitative and qualitative analysis grounded in narrative theory, we compare GPT-4, Claude-2.1, and LLama-2-70B. We find that all three models make faithfulness mistakes in over 50% of summaries and struggle to interpret difficult subtext. However, at their best, the models can provide thoughtful thematic analysis of stories. We additionally demonstrate that LLM judgments of summary quality do not match the feedback from the writers.",
    "link": "https://arxiv.org/abs/2403.01061",
    "context": "Title: Reading Subtext: Evaluating Large Language Models on Short Story Summarization with Writers\nAbstract: arXiv:2403.01061v1 Announce Type: new  Abstract: We evaluate recent Large language Models (LLMs) on the challenging task of summarizing short stories, which can be lengthy, and include nuanced subtext or scrambled timelines. Importantly, we work directly with authors to ensure that the stories have not been shared online (and therefore are unseen by the models), and to obtain informed evaluations of summary quality using judgments from the authors themselves. Through quantitative and qualitative analysis grounded in narrative theory, we compare GPT-4, Claude-2.1, and LLama-2-70B. We find that all three models make faithfulness mistakes in over 50% of summaries and struggle to interpret difficult subtext. However, at their best, the models can provide thoughtful thematic analysis of stories. We additionally demonstrate that LLM judgments of summary quality do not match the feedback from the writers.",
    "path": "papers/24/03/2403.01061.json",
    "total_tokens": 859,
    "translated_title": "阅读潜台词：在短篇小说摘要上评估大型语言模型与作者合作",
    "translated_abstract": "我们评估了最近的大型语言模型（LLMs）在摘要长篇文学作品这一具有挑战性的任务上的表现，这些作品可能长度较长，并包含微妙的潜台词或错综复杂的时间线。重要的是，我们直接与作者合作，确保这些作品尚未在网络上分享过（因此对这些模型是未知的），并获得作者本人对摘要质量的明确评价。通过基于叙事理论的定量和定性分析，我们比较了GPT-4、Claude-2.1和LLama-2-70B。我们发现这三个模型在50%以上的摘要中会出现忠实性错误，并且难以解释难以理解的潜台词。然而，在最佳状态下，这些模型可以对故事进行有深度的主题分析。此外，我们还展示了LLMs对摘要质量的判断与作家的反馈不一致。",
    "tldr": "评估大型语言模型在短篇小说摘要上的表现，发现它们在忠实性和解释潜台词方面存在挑战，但在进行主题分析时表现出思考深度。"
}