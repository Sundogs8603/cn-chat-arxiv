{
    "title": "Laplacian-guided Entropy Model in Neural Codec with Blur-dissipated Synthesis",
    "abstract": "arXiv:2403.16258v1 Announce Type: cross  Abstract: While replacing Gaussian decoders with a conditional diffusion model enhances the perceptual quality of reconstructions in neural image compression, their lack of inductive bias for image data restricts their ability to achieve state-of-the-art perceptual levels. To address this limitation, we adopt a non-isotropic diffusion model at the decoder side. This model imposes an inductive bias aimed at distinguishing between frequency contents, thereby facilitating the generation of high-quality images. Moreover, our framework is equipped with a novel entropy model that accurately models the probability distribution of latent representation by exploiting spatio-channel correlations in latent space, while accelerating the entropy decoding step. This channel-wise entropy model leverages both local and global spatial contexts within each channel chunk. The global spatial context is built upon the Transformer, which is specifically designed for ",
    "link": "https://arxiv.org/abs/2403.16258",
    "context": "Title: Laplacian-guided Entropy Model in Neural Codec with Blur-dissipated Synthesis\nAbstract: arXiv:2403.16258v1 Announce Type: cross  Abstract: While replacing Gaussian decoders with a conditional diffusion model enhances the perceptual quality of reconstructions in neural image compression, their lack of inductive bias for image data restricts their ability to achieve state-of-the-art perceptual levels. To address this limitation, we adopt a non-isotropic diffusion model at the decoder side. This model imposes an inductive bias aimed at distinguishing between frequency contents, thereby facilitating the generation of high-quality images. Moreover, our framework is equipped with a novel entropy model that accurately models the probability distribution of latent representation by exploiting spatio-channel correlations in latent space, while accelerating the entropy decoding step. This channel-wise entropy model leverages both local and global spatial contexts within each channel chunk. The global spatial context is built upon the Transformer, which is specifically designed for ",
    "path": "papers/24/03/2403.16258.json",
    "total_tokens": 840,
    "translated_title": "在模糊扩散合成中的拉普拉斯引导熵模型神经编解码器中",
    "translated_abstract": "将高斯解码器替换为条件扩散模型可以增强神经图像压缩中重建图像的感知质量，但它们对图像数据缺乏归纳偏差，限制了它们实现最先进感知水平的能力。为解决这一限制，我们在解码器端采用了非各向同性扩散模型。该模型施加了一种旨在区分频率内容的归纳偏差，从而促进高质量图像的生成。此外，我们的框架配备了一种新颖的熵模型，通过利用潜在空间中的空间通道相关性准确建模潜在表征的概率分布，同时加速熵解码步骤。这种通道级熵模型利用每个通道块内的本地和全局空间上下文。全局空间上下文是建立在专门设计用于……",
    "tldr": "采用非各向同性扩散模型和新颖的熵模型在神经图像压缩中，以区分频率内容并加速熵解码步骤，提高生成高质量图像的能力。",
    "en_tdlr": "Enhancing the generation of high-quality images in neural image compression by adopting a non-isotropic diffusion model and a novel entropy model to distinguish frequency contents and accelerate the entropy decoding step."
}