{
    "title": "Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering",
    "abstract": "arXiv:2403.01390v1 Announce Type: new  Abstract: Knowledge Graph Question Answering (KGQA) methods seek to answer Natural Language questions using the relational information stored in Knowledge Graphs (KGs). With the recent advancements of Large Language Models (LLMs) and their remarkable reasoning abilities, there is a growing trend to leverage them for KGQA. However, existing methodologies have only focused on answering factual questions, e.g., \"In which city was Silvio Berlusconi's first wife born?\", leaving questions involving commonsense reasoning that real-world users may pose more often, e.g., \"Do I need separate visas to see the Venus of Willendorf and attend the Olympics this summer?\" unaddressed. In this work, we first observe that existing LLM-based methods for KGQA struggle with hallucination on such questions, especially on queries targeting long-tail entities (e.g., non-mainstream and recent entities), thus hindering their applicability in real-world applications especial",
    "link": "https://arxiv.org/abs/2403.01390",
    "context": "Title: Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering\nAbstract: arXiv:2403.01390v1 Announce Type: new  Abstract: Knowledge Graph Question Answering (KGQA) methods seek to answer Natural Language questions using the relational information stored in Knowledge Graphs (KGs). With the recent advancements of Large Language Models (LLMs) and their remarkable reasoning abilities, there is a growing trend to leverage them for KGQA. However, existing methodologies have only focused on answering factual questions, e.g., \"In which city was Silvio Berlusconi's first wife born?\", leaving questions involving commonsense reasoning that real-world users may pose more often, e.g., \"Do I need separate visas to see the Venus of Willendorf and attend the Olympics this summer?\" unaddressed. In this work, we first observe that existing LLM-based methods for KGQA struggle with hallucination on such questions, especially on queries targeting long-tail entities (e.g., non-mainstream and recent entities), thus hindering their applicability in real-world applications especial",
    "path": "papers/24/03/2403.01390.json",
    "total_tokens": 849,
    "translated_title": "正当且充分：可验证的常识知识图问题回答中的大型语言模型",
    "translated_abstract": "知识图问题回答（KGQA）方法旨在利用知识图中存储的关系信息来回答自然语言问题。随着大型语言模型（LLMs）的最新进展及其出色的推理能力，利用它们进行KGQA的趋势日益增长。然而，现有方法仅专注于回答事实性问题，例如“Silvio Berlusconi的第一任妻子出生在哪座城市？”，而忽略了涉及常识推理的问题，这是现实世界用户可能更经常提出的，例如“我需要单独的签证才能看到威伦多夫的维纳斯并参加今年夏天的奥运会吗？”。在这项工作中，我们首先观察到，现有基于LLM的KGQA方法在处理这类问题时难以产生真实的答案，尤其是对针对长尾实体的查询（例如非主流和最近的实体），从而阻碍了它们在现实世界应用中的可应用性。",
    "tldr": "LLM-based KGQA methods struggle with hallucination on commonsense reasoning questions, hindering their applicability in real-world applications.",
    "en_tdlr": "LLM-based KGQA methods struggle with hallucination on commonsense reasoning questions, hindering their applicability in real-world applications."
}