{
    "title": "Speeding Up Path Planning via Reinforcement Learning in MCTS for Automated Parking",
    "abstract": "arXiv:2403.17234v1 Announce Type: new  Abstract: In this paper, we address a method that integrates reinforcement learning into the Monte Carlo tree search to boost online path planning under fully observable environments for automated parking tasks. Sampling-based planning methods under high-dimensional space can be computationally expensive and time-consuming. State evaluation methods are useful by leveraging the prior knowledge into the search steps, making the process faster in a real-time system. Given the fact that automated parking tasks are often executed under complex environments, a solid but lightweight heuristic guidance is challenging to compose in a traditional analytical way. To overcome this limitation, we propose a reinforcement learning pipeline with a Monte Carlo tree search under the path planning framework. By iteratively learning the value of a state and the best action among samples from its previous cycle's outcomes, we are able to model a value estimator and a ",
    "link": "https://arxiv.org/abs/2403.17234",
    "context": "Title: Speeding Up Path Planning via Reinforcement Learning in MCTS for Automated Parking\nAbstract: arXiv:2403.17234v1 Announce Type: new  Abstract: In this paper, we address a method that integrates reinforcement learning into the Monte Carlo tree search to boost online path planning under fully observable environments for automated parking tasks. Sampling-based planning methods under high-dimensional space can be computationally expensive and time-consuming. State evaluation methods are useful by leveraging the prior knowledge into the search steps, making the process faster in a real-time system. Given the fact that automated parking tasks are often executed under complex environments, a solid but lightweight heuristic guidance is challenging to compose in a traditional analytical way. To overcome this limitation, we propose a reinforcement learning pipeline with a Monte Carlo tree search under the path planning framework. By iteratively learning the value of a state and the best action among samples from its previous cycle's outcomes, we are able to model a value estimator and a ",
    "path": "papers/24/03/2403.17234.json",
    "total_tokens": 830,
    "translated_title": "在自动停车中通过强化学习在MCTS中加速路径规划",
    "translated_abstract": "本文针对一种方法进行了讨论，该方法将强化学习整合到蒙特卡洛树搜索中，以提升在全可观测环境下进行自动停车任务的在线路径规划。在高维空间下基于采样的规划方法可能具有计算开销大、耗时长的特点。状态评估方法通过将先验知识应用于搜索步骤中，使实时系统中的过程更快速。鉴于自动停车任务通常在复杂环境中执行，传统分析方式难以构建坚实但轻量级的启发式指导。为了克服这一局限性，我们提出了在路径规划框架下具有蒙特卡洛树搜索的强化学习流水线。通过迭代地学习状态的价值以及最佳动作，在前一个周期结果的样本中选择最佳动作，我们能够建模一个值估计器以及一个...",
    "tldr": "本文提出了一种将强化学习与蒙特卡洛树搜索集成的方法，用于自动停车任务中的在线路径规划，旨在加速路径规划过程，提高效率。",
    "en_tdlr": "This paper introduces a method that integrates reinforcement learning with Monte Carlo tree search for online path planning in automated parking, aiming to speed up the planning process and improve efficiency."
}