{
    "title": "Synthetic Privileged Information Enhances Medical Image Representation Learning",
    "abstract": "arXiv:2403.05220v1 Announce Type: cross  Abstract: Multimodal self-supervised representation learning has consistently proven to be a highly effective method in medical image analysis, offering strong task performance and producing biologically informed insights. However, these methods heavily rely on large, paired datasets, which is prohibitive for their use in scenarios where paired data does not exist, or there is only a small amount available. In contrast, image generation methods can work well on very small datasets, and can find mappings between unpaired datasets, meaning an effectively unlimited amount of paired synthetic data can be generated. In this work, we demonstrate that representation learning can be significantly improved by synthetically generating paired information, both compared to training on either single-modality (up to 4.4x error reduction) or authentic multi-modal paired datasets (up to 5.6x error reduction).",
    "link": "https://arxiv.org/abs/2403.05220",
    "context": "Title: Synthetic Privileged Information Enhances Medical Image Representation Learning\nAbstract: arXiv:2403.05220v1 Announce Type: cross  Abstract: Multimodal self-supervised representation learning has consistently proven to be a highly effective method in medical image analysis, offering strong task performance and producing biologically informed insights. However, these methods heavily rely on large, paired datasets, which is prohibitive for their use in scenarios where paired data does not exist, or there is only a small amount available. In contrast, image generation methods can work well on very small datasets, and can find mappings between unpaired datasets, meaning an effectively unlimited amount of paired synthetic data can be generated. In this work, we demonstrate that representation learning can be significantly improved by synthetically generating paired information, both compared to training on either single-modality (up to 4.4x error reduction) or authentic multi-modal paired datasets (up to 5.6x error reduction).",
    "path": "papers/24/03/2403.05220.json",
    "total_tokens": 809,
    "translated_title": "合成特权信息增强医学图像表示学习",
    "translated_abstract": "多模态自监督表示学习一直被证明是医学图像分析中一种非常有效的方法，提供了强大的任务性能并产生了生物学相关的见解。然而，这些方法严重依赖于大规模配对数据集，这在不存在配对数据或只有少量可用的情况下是不切实际的。相比之下，图像生成方法可以在非常小的数据集上很好地工作，并且可以找到未配对数据集之间的映射，这意味着可以生成有效无限量的配对合成数据。在这项工作中，我们展示了通过合成生成配对信息可以显著改善表示学习，与单模态训练（误差减小达到4.4倍）或真实多模态配对数据集进行训练（误差减小达到5.6倍）相比。",
    "tldr": "合成生成的配对信息显著改善了医学图像表示学习，相比于单模态训练或真实多模态配对数据集，误差减小分别达到4.4倍和5.6倍",
    "en_tdlr": "Synthetic generation of paired information significantly improves medical image representation learning, with error reductions up to 4.4x compared to single-modality training and up to 5.6x compared to authentic multi-modal paired datasets."
}