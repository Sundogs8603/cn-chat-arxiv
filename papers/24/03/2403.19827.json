{
    "title": "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs",
    "abstract": "arXiv:2403.19827v1 Announce Type: new  Abstract: Language models learn rare syntactic phenomena, but it has been argued that they rely on rote memorization, as opposed to grammatical generalization. Training on a corpus of human-scale in size (100M words), we iteratively trained transformer language models on systematically manipulated corpora and then evaluated their learning of a particular rare grammatical phenomenon: the English Article+Adjective+Numeral+Noun (AANN) construction (``a beautiful five days''). We first compared how well this construction was learned on the default corpus relative to a counterfactual corpus in which the AANN sentences were removed. AANNs were still learned better than systematically perturbed variants of the construction. Using additional counterfactual corpora, we suggest that this learning occurs through generalization from related constructions (e.g., ``a few days''). An additional experiment showed that this learning is enhanced when there is more ",
    "link": "https://arxiv.org/abs/2403.19827",
    "context": "Title: Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs\nAbstract: arXiv:2403.19827v1 Announce Type: new  Abstract: Language models learn rare syntactic phenomena, but it has been argued that they rely on rote memorization, as opposed to grammatical generalization. Training on a corpus of human-scale in size (100M words), we iteratively trained transformer language models on systematically manipulated corpora and then evaluated their learning of a particular rare grammatical phenomenon: the English Article+Adjective+Numeral+Noun (AANN) construction (``a beautiful five days''). We first compared how well this construction was learned on the default corpus relative to a counterfactual corpus in which the AANN sentences were removed. AANNs were still learned better than systematically perturbed variants of the construction. Using additional counterfactual corpora, we suggest that this learning occurs through generalization from related constructions (e.g., ``a few days''). An additional experiment showed that this learning is enhanced when there is more ",
    "path": "papers/24/03/2403.19827.json",
    "total_tokens": 691,
    "translated_title": "语言模型从不常见的现象中学习：缺失AANN的情况",
    "translated_abstract": "语言模型学习罕见的句法现象，但有人认为它们依赖于死记硬背，而不是语法概括。我们在规模为人类规模的语料库（1亿字）上进行训练，迭代训练变压器语言模型，然后评估它们对特定罕见语法现象的学习：英语的冠词+形容词+数字+名词（AANN）结构（“a beautiful five days”）。",
    "tldr": "语言模型通过从相关结构（例如“a few days”）进行泛化学习，能够更好地学习AANN结构。"
}