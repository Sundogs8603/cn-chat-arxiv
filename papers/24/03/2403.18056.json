{
    "title": "Self-Clustering Hierarchical Multi-Agent Reinforcement Learning with Extensible Cooperation Graph",
    "abstract": "arXiv:2403.18056v1 Announce Type: new  Abstract: Multi-Agent Reinforcement Learning (MARL) has been successful in solving many cooperative challenges. However, classic non-hierarchical MARL algorithms still cannot address various complex multi-agent problems that require hierarchical cooperative behaviors. The cooperative knowledge and policies learned in non-hierarchical algorithms are implicit and not interpretable, thereby restricting the integration of existing knowledge. This paper proposes a novel hierarchical MARL model called Hierarchical Cooperation Graph Learning (HCGL) for solving general multi-agent problems. HCGL has three components: a dynamic Extensible Cooperation Graph (ECG) for achieving self-clustering cooperation; a group of graph operators for adjusting the topology of ECG; and an MARL optimizer for training these graph operators. HCGL's key distinction from other MARL models is that the behaviors of agents are guided by the topology of ECG instead of policy neural",
    "link": "https://arxiv.org/abs/2403.18056",
    "context": "Title: Self-Clustering Hierarchical Multi-Agent Reinforcement Learning with Extensible Cooperation Graph\nAbstract: arXiv:2403.18056v1 Announce Type: new  Abstract: Multi-Agent Reinforcement Learning (MARL) has been successful in solving many cooperative challenges. However, classic non-hierarchical MARL algorithms still cannot address various complex multi-agent problems that require hierarchical cooperative behaviors. The cooperative knowledge and policies learned in non-hierarchical algorithms are implicit and not interpretable, thereby restricting the integration of existing knowledge. This paper proposes a novel hierarchical MARL model called Hierarchical Cooperation Graph Learning (HCGL) for solving general multi-agent problems. HCGL has three components: a dynamic Extensible Cooperation Graph (ECG) for achieving self-clustering cooperation; a group of graph operators for adjusting the topology of ECG; and an MARL optimizer for training these graph operators. HCGL's key distinction from other MARL models is that the behaviors of agents are guided by the topology of ECG instead of policy neural",
    "path": "papers/24/03/2403.18056.json",
    "total_tokens": 870,
    "translated_title": "具有可扩展合作图的自主分层多智能体强化学习",
    "translated_abstract": "多智能体强化学习（MARL）在解决许多合作挑战方面取得了成功。然而，经典的非分层MARL算法仍然无法解决需要分层合作行为的各种复杂多智能体问题。非分层算法学习的合作知识和策略是隐式的，不易解释，从而限制了现有知识的整合。本文提出了一种解决一般多智能体问题的新型分层MARL模型，名为Hierarchical Cooperation Graph Learning（HCGL）。HCGL有三个组成部分：用于实现自我聚类合作的动态可扩展合作图（ECG）；一组用于调整ECG拓扑结构的图操作器；以及用于训练这些图操作器的MARL优化器。HCGL与其他MARL模型的主要区别在于，代理的行为受ECG拓扑结构的引导，而不是策略神经网络。",
    "tldr": "本论文提出了一种名为Hierarchical Cooperation Graph Learning（HCGL）的新型分层MARL模型，其中代理的行为受可扩展合作图（ECG）的拓扑结构引导，解决了一般多智能体问题。",
    "en_tdlr": "This paper introduces a novel hierarchical MARL model called Hierarchical Cooperation Graph Learning (HCGL), where the behaviors of agents are guided by the topology of Extensible Cooperation Graph (ECG), addressing general multi-agent problems."
}