{
    "title": "Validating and Exploring Large Geographic Corpora",
    "abstract": "arXiv:2403.08198v1 Announce Type: new  Abstract: This paper investigates the impact of corpus creation decisions on large multi-lingual geographic web corpora. Beginning with a 427 billion word corpus derived from the Common Crawl, three methods are used to improve the quality of sub-corpora representing specific language-country pairs like New Zealand English: (i) the agreement of independent language identification systems, (ii) hash-based deduplication, and (iii) location-specific outlier detection. The impact of each of these steps is then evaluated at the language level and the country level by using corpus similarity measures to compare each resulting corpus with baseline data sets. The goal is to understand the impact of upstream data cleaning decisions on downstream corpora with a specific focus on under-represented languages and populations. The evaluation shows that the validity of sub-corpora is improved with each stage of cleaning but that this improvement is unevenly distr",
    "link": "https://arxiv.org/abs/2403.08198",
    "context": "Title: Validating and Exploring Large Geographic Corpora\nAbstract: arXiv:2403.08198v1 Announce Type: new  Abstract: This paper investigates the impact of corpus creation decisions on large multi-lingual geographic web corpora. Beginning with a 427 billion word corpus derived from the Common Crawl, three methods are used to improve the quality of sub-corpora representing specific language-country pairs like New Zealand English: (i) the agreement of independent language identification systems, (ii) hash-based deduplication, and (iii) location-specific outlier detection. The impact of each of these steps is then evaluated at the language level and the country level by using corpus similarity measures to compare each resulting corpus with baseline data sets. The goal is to understand the impact of upstream data cleaning decisions on downstream corpora with a specific focus on under-represented languages and populations. The evaluation shows that the validity of sub-corpora is improved with each stage of cleaning but that this improvement is unevenly distr",
    "path": "papers/24/03/2403.08198.json",
    "total_tokens": 876,
    "translated_title": "验证和探索大规模地理语料库",
    "translated_abstract": "这篇论文研究了语料库创建决策对大规模多语言地理网络语料库的影响。从Common Crawl获得的4270亿词语语料开始，使用三种方法来提高代表特定语言-国家对如新西兰英语的子语料库的质量：(i) 独立语言识别系统的一致性，(ii) 基于哈希的重复数据删除，以及(iii) 特定地点的异常值检测。然后通过使用语料相似性度量来将每个生成的语料库与基线数据集比较，评估了每个步骤对语言级别和国家级别的影响。旨在了解上游数据清洗决策对下游语料库的影响，特别关注未被充分代表的语言和人口。评估表明，随着每个清理阶段的进行，子语料库的有效性得到改善，但这种改善是不均匀的。",
    "tldr": "本文研究了在大规模地理多语言网络语料库中的语料库创建决策对质量的影响，通过改进数据清洗方法来提高特定语言-国家子语料库的有效性，并重点关注未充分代表的语言和人口群体。",
    "en_tdlr": "This paper investigates the impact of corpus creation decisions on large multi-lingual geographic web corpora, improving the quality of specific language-country sub-corpora through enhanced data cleaning methods, with a focus on under-represented languages and populations."
}