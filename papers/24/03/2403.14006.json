{
    "title": "On Prompt Sensitivity of ChatGPT in Affective Computing",
    "abstract": "arXiv:2403.14006v1 Announce Type: cross  Abstract: Recent studies have demonstrated the emerging capabilities of foundation models like ChatGPT in several fields, including affective computing. However, accessing these emerging capabilities is facilitated through prompt engineering. Despite the existence of some prompting techniques, the field is still rapidly evolving and many prompting ideas still require investigation. In this work, we introduce a method to evaluate and investigate the sensitivity of the performance of foundation models based on different prompts or generation parameters. We perform our evaluation on ChatGPT within the scope of affective computing on three major problems, namely sentiment analysis, toxicity detection, and sarcasm detection. First, we carry out a sensitivity analysis on pivotal parameters in auto-regressive text generation, specifically the temperature parameter $T$ and the top-$p$ parameter in Nucleus sampling, dictating how conservative or creative",
    "link": "https://arxiv.org/abs/2403.14006",
    "context": "Title: On Prompt Sensitivity of ChatGPT in Affective Computing\nAbstract: arXiv:2403.14006v1 Announce Type: cross  Abstract: Recent studies have demonstrated the emerging capabilities of foundation models like ChatGPT in several fields, including affective computing. However, accessing these emerging capabilities is facilitated through prompt engineering. Despite the existence of some prompting techniques, the field is still rapidly evolving and many prompting ideas still require investigation. In this work, we introduce a method to evaluate and investigate the sensitivity of the performance of foundation models based on different prompts or generation parameters. We perform our evaluation on ChatGPT within the scope of affective computing on three major problems, namely sentiment analysis, toxicity detection, and sarcasm detection. First, we carry out a sensitivity analysis on pivotal parameters in auto-regressive text generation, specifically the temperature parameter $T$ and the top-$p$ parameter in Nucleus sampling, dictating how conservative or creative",
    "path": "papers/24/03/2403.14006.json",
    "total_tokens": 846,
    "translated_title": "论ChatGPT在情感计算中的提示敏感性",
    "translated_abstract": "最近的研究已经展示了像ChatGPT这样的基础模型在多个领域，包括情感计算中的新兴能力。然而，访问这些新兴能力是通过提示工程来实现的。尽管存在一些提示技术，但该领域仍在迅速发展，许多提示想法仍需要调查。在这项工作中，我们介绍了一种方法，用于评估并调查基于不同提示或生成参数的基础模型性能的敏感性。我们在情感计算范围内针对ChatGPT执行我们的评估，解决了三个主要问题，即情绪分析、毒性检测和讽刺检测。首先，我们对自回归文本生成中的关键参数进行了敏感性分析，特别是温度参数$T$和Nucleus抽样中的top-$p$参数，指导着保守或创造性",
    "tldr": "该研究介绍了一个用于评估基础模型性能敏感性的方法，针对ChatGPT在情感计算中的提示敏感性进行了研究和评估，涵盖情绪分析、毒性检测和讽刺检测。",
    "en_tdlr": "This study introduces a method to evaluate the sensitivity of foundation models’ performance based on different prompts, specifically focusing on ChatGPT in affective computing, covering sentiment analysis, toxicity detection, and sarcasm detection."
}