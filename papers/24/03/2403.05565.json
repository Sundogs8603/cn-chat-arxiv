{
    "title": "OpenHEXAI: An Open-Source Framework for Human-Centered Evaluation of Explainable Machine Learning",
    "abstract": "arXiv:2403.05565v1 Announce Type: cross  Abstract: Recently, there has been a surge of explainable AI (XAI) methods driven by the need for understanding machine learning model behaviors in high-stakes scenarios. However, properly evaluating the effectiveness of the XAI methods inevitably requires the involvement of human subjects, and conducting human-centered benchmarks is challenging in a number of ways: designing and implementing user studies is complex; numerous design choices in the design space of user study lead to problems of reproducibility; and running user studies can be challenging and even daunting for machine learning researchers. To address these challenges, this paper presents OpenHEXAI, an open-source framework for human-centered evaluation of XAI methods. OpenHEXAI features (1) a collection of diverse benchmark datasets, pre-trained models, and post hoc explanation methods; (2) an easy-to-use web application for user study; (3) comprehensive evaluation metrics for the",
    "link": "https://arxiv.org/abs/2403.05565",
    "context": "Title: OpenHEXAI: An Open-Source Framework for Human-Centered Evaluation of Explainable Machine Learning\nAbstract: arXiv:2403.05565v1 Announce Type: cross  Abstract: Recently, there has been a surge of explainable AI (XAI) methods driven by the need for understanding machine learning model behaviors in high-stakes scenarios. However, properly evaluating the effectiveness of the XAI methods inevitably requires the involvement of human subjects, and conducting human-centered benchmarks is challenging in a number of ways: designing and implementing user studies is complex; numerous design choices in the design space of user study lead to problems of reproducibility; and running user studies can be challenging and even daunting for machine learning researchers. To address these challenges, this paper presents OpenHEXAI, an open-source framework for human-centered evaluation of XAI methods. OpenHEXAI features (1) a collection of diverse benchmark datasets, pre-trained models, and post hoc explanation methods; (2) an easy-to-use web application for user study; (3) comprehensive evaluation metrics for the",
    "path": "papers/24/03/2403.05565.json",
    "total_tokens": 881,
    "translated_title": "OpenHEXAI：一个用于可解释机器学习人类中心评估的开源框架",
    "translated_abstract": "最近，由于需要理解高风险情景下的机器学习模型行为，解释型人工智能（XAI）方法大幅增多。然而，适当评估XAI方法的有效性不可避免地需要人类主体的参与，并且进行人类中心基准测试在许多方面都具有挑战性：设计和实施用户研究是复杂的；在设计空间中的众多设计选择导致可重复性问题；进行用户研究可能对机器学习研究人员来说是具有挑战性甚至令人望而生畏的。为解决这些挑战，本文提出了OpenHEXAI，一个用于XAI方法的人类中心评估的开源框架。OpenHEXAI具有（1）一系列不同基准数据集、预训练模型和事后解释方法；（2）用于用户研究的易于使用的Web应用程序；（3）全面的评估指标。",
    "tldr": "OpenHEXAI是一个用于人类中心评估可解释机器学习的开源框架，拥有多元化基准数据集、易于使用的用户研究Web应用程序和全面的评估指标。",
    "en_tdlr": "OpenHEXAI is an open-source framework for human-centered evaluation of explainable machine learning, featuring diverse benchmark datasets, an easy-to-use web application for user studies, and comprehensive evaluation metrics."
}