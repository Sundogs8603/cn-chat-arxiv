{
    "title": "Shifted Interpolation for Differential Privacy",
    "abstract": "arXiv:2403.00278v1 Announce Type: new  Abstract: Noisy gradient descent and its variants are the predominant algorithms for differentially private machine learning. It is a fundamental question to quantify their privacy leakage, yet tight characterizations remain open even in the foundational setting of convex losses. This paper improves over previous analyses by establishing (and refining) the \"privacy amplification by iteration\" phenomenon in the unifying framework of $f$-differential privacy--which tightly captures all aspects of the privacy loss and immediately implies tighter privacy accounting in other notions of differential privacy, e.g., $(\\varepsilon,\\delta)$-DP and Renyi DP. Our key technical insight is the construction of shifted interpolated processes that unravel the popular shifted-divergences argument, enabling generalizations beyond divergence-based relaxations of DP. Notably, this leads to the first exact privacy analysis in the foundational setting of strongly convex",
    "link": "https://arxiv.org/abs/2403.00278",
    "context": "Title: Shifted Interpolation for Differential Privacy\nAbstract: arXiv:2403.00278v1 Announce Type: new  Abstract: Noisy gradient descent and its variants are the predominant algorithms for differentially private machine learning. It is a fundamental question to quantify their privacy leakage, yet tight characterizations remain open even in the foundational setting of convex losses. This paper improves over previous analyses by establishing (and refining) the \"privacy amplification by iteration\" phenomenon in the unifying framework of $f$-differential privacy--which tightly captures all aspects of the privacy loss and immediately implies tighter privacy accounting in other notions of differential privacy, e.g., $(\\varepsilon,\\delta)$-DP and Renyi DP. Our key technical insight is the construction of shifted interpolated processes that unravel the popular shifted-divergences argument, enabling generalizations beyond divergence-based relaxations of DP. Notably, this leads to the first exact privacy analysis in the foundational setting of strongly convex",
    "path": "papers/24/03/2403.00278.json",
    "total_tokens": 860,
    "translated_title": "差分隐私的平移插值",
    "translated_abstract": "喧嚣的梯度下降及其变种是差分隐私机器学习中主导的算法。量化它们的隐私泄漏是一个基本问题，然而即使在凸损失的基础设置中，紧致的表征仍然是开放的。本文通过在$f$-差分隐私的统一框架下建立（和改进）“通过迭代实现隐私放大”现象，提高了先前分析的水平--这种方法紧紧捕捉了隐私损失的所有方面，并立即获得了其他差分隐私概念（如$(\\varepsilon,\\delta)$-DP和Renyi DP）更紧密的隐私核算。我们的关键技术见解是构建了揭示了流行的平移散度论证的平移插值过程，使得超越基于散度的差分隐私放宽的泛化成为可能。值得注意的是，这导致了在强凸基础设置中的第一个精确隐私分析。",
    "tldr": "本文在统一框架下建立了“通过迭代实现隐私放大”现象，提高了先前分析的水平，并由此获得了其他差分隐私概念更紧密的隐私核算。",
    "en_tdlr": "This paper establishes the \"privacy amplification by iteration\" phenomenon in the unifying framework of $f$-differential privacy, improving previous analyses and leading to tighter privacy accounting in other differential privacy notions."
}