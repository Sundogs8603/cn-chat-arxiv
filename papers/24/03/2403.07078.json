{
    "title": "Improving deep learning with prior knowledge and cognitive models: A survey on enhancing explainability, adversarial robustness and zero-shot learning",
    "abstract": "arXiv:2403.07078v1 Announce Type: cross  Abstract: We review current and emerging knowledge-informed and brain-inspired cognitive systems for realizing adversarial defenses, eXplainable Artificial Intelligence (XAI), and zero-shot or few-short learning. Data-driven deep learning models have achieved remarkable performance and demonstrated capabilities surpassing human experts in many applications. Yet, their inability to exploit domain knowledge leads to serious performance limitations in practical applications. In particular, deep learning systems are exposed to adversarial attacks, which can trick them into making glaringly incorrect decisions. Moreover, complex data-driven models typically lack interpretability or explainability, i.e., their decisions cannot be understood by human subjects. Furthermore, models are usually trained on standard datasets with a closed-world assumption. Hence, they struggle to generalize to unseen cases during inference in practical open-world environmen",
    "link": "https://arxiv.org/abs/2403.07078",
    "context": "Title: Improving deep learning with prior knowledge and cognitive models: A survey on enhancing explainability, adversarial robustness and zero-shot learning\nAbstract: arXiv:2403.07078v1 Announce Type: cross  Abstract: We review current and emerging knowledge-informed and brain-inspired cognitive systems for realizing adversarial defenses, eXplainable Artificial Intelligence (XAI), and zero-shot or few-short learning. Data-driven deep learning models have achieved remarkable performance and demonstrated capabilities surpassing human experts in many applications. Yet, their inability to exploit domain knowledge leads to serious performance limitations in practical applications. In particular, deep learning systems are exposed to adversarial attacks, which can trick them into making glaringly incorrect decisions. Moreover, complex data-driven models typically lack interpretability or explainability, i.e., their decisions cannot be understood by human subjects. Furthermore, models are usually trained on standard datasets with a closed-world assumption. Hence, they struggle to generalize to unseen cases during inference in practical open-world environmen",
    "path": "papers/24/03/2403.07078.json",
    "total_tokens": 979,
    "translated_title": "借助先验知识和认知模型改善深度学习：增强可解释性、对抗鲁棒性和零样本学习的调查",
    "translated_abstract": "我们审查了当前和新兴的知识驱动和脑启发的认知系统，用于实现对抗性防御、可解释的人工智能（XAI）以及零样本或少样本学习。数据驱动的深度学习模型在许多应用中取得了显著的性能，并展示了超越人类专家的能力。然而，它们由于无法利用领域知识而在实际应用中存在严重性能限制。特别是，深度学习系统容易受到对抗性攻击，这可能导致它们做出明显错误的决定。此外，复杂的数据驱动模型通常缺乏解释性，即它们的决策无法被人类主体理解。此外，模型通常是在标准数据集上训练的，具有封闭世界的假设。因此，在实际的开放环境中进行推理时，它们很难推广到未见案例。",
    "tldr": "本文调查了如何借助先验知识和认知模型来改善深度学习，以提升对抗防御、可解释性人工智能（XAI）和零样本学习，弥补现有深度学习模型在领域知识利用、对抗性攻击防御、解释性以及在开放环境推理中的性能限制。",
    "en_tdlr": "This paper surveys how to improve deep learning with prior knowledge and cognitive models to enhance adversarial defense, explainable artificial intelligence (XAI), and zero-shot learning, addressing the performance limitations of current deep learning models in utilizing domain knowledge, defending against adversarial attacks, interpretability, and inference in open-world environments."
}