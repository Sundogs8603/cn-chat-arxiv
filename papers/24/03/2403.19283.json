{
    "title": "Ungrammatical-syntax-based In-context Example Selection for Grammatical Error Correction",
    "abstract": "arXiv:2403.19283v1 Announce Type: new  Abstract: In the era of large language models (LLMs), in-context learning (ICL) stands out as an effective prompting strategy that explores LLMs' potency across various tasks. However, applying LLMs to grammatical error correction (GEC) is still a challenging task. In this paper, we propose a novel ungrammatical-syntax-based in-context example selection strategy for GEC. Specifically, we measure similarity of sentences based on their syntactic structures with diverse algorithms, and identify optimal ICL examples sharing the most similar ill-formed syntax to the test input. Additionally, we carry out a two-stage process to further improve the quality of selection results. On benchmark English GEC datasets, empirical results show that our proposed ungrammatical-syntax-based strategies outperform commonly-used word-matching or semantics-based methods with multiple LLMs. This indicates that for a syntax-oriented task like GEC, paying more attention to",
    "link": "https://arxiv.org/abs/2403.19283",
    "context": "Title: Ungrammatical-syntax-based In-context Example Selection for Grammatical Error Correction\nAbstract: arXiv:2403.19283v1 Announce Type: new  Abstract: In the era of large language models (LLMs), in-context learning (ICL) stands out as an effective prompting strategy that explores LLMs' potency across various tasks. However, applying LLMs to grammatical error correction (GEC) is still a challenging task. In this paper, we propose a novel ungrammatical-syntax-based in-context example selection strategy for GEC. Specifically, we measure similarity of sentences based on their syntactic structures with diverse algorithms, and identify optimal ICL examples sharing the most similar ill-formed syntax to the test input. Additionally, we carry out a two-stage process to further improve the quality of selection results. On benchmark English GEC datasets, empirical results show that our proposed ungrammatical-syntax-based strategies outperform commonly-used word-matching or semantics-based methods with multiple LLMs. This indicates that for a syntax-oriented task like GEC, paying more attention to",
    "path": "papers/24/03/2403.19283.json",
    "total_tokens": 890,
    "translated_title": "基于不合语法句法的上下文示例选择用于语法错误校正",
    "translated_abstract": "在大语言模型(LLMs)时代，上下文学习(ICL)作为一种有效的提示策略，探索LLMs在各种任务中的能力。然而，将LLMs应用于语法错误校正(GEC)仍然是一项具有挑战性的任务。在本文中，我们提出了一种新颖的基于不合语法句法的上下文示例选择策略用于GEC。具体而言，我们基于各种算法测量句子的相似性，并识别出与测试输入具有最相似不合格式句法的最佳ICL示例。此外，我们进行了一个两阶段流程，以进一步提高选择结果的质量。在基准英语GEC数据集上，实证结果表明我们提出的基于不合语法句法的策略比常用的基于单词匹配或语义的方法与多个LLMs表现更好。这表明对于像GEC这样的句法定向任务，更多关注语法是值得的。",
    "tldr": "在本文中，我们提出了一种基于不合语法句法的上下文示例选择策略，用于在语法错误校正中提高性能，并在基准英语GEC数据集上取得了比常用方法更好的表现。",
    "en_tdlr": "In this paper, we propose a novel ungrammatical-syntax-based in-context example selection strategy for grammatical error correction (GEC) to improve performance, demonstrating better results than commonly-used methods on benchmark English GEC datasets."
}