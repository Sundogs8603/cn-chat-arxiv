{
    "title": "Discrete Semantic Tokenization for Deep CTR Prediction",
    "abstract": "arXiv:2403.08206v1 Announce Type: new  Abstract: Incorporating item content information into click-through rate (CTR) prediction models remains a challenge, especially with the time and space constraints of industrial scenarios. The content-encoding paradigm, which integrates user and item encoders directly into CTR models, prioritizes space over time. In contrast, the embedding-based paradigm transforms item and user semantics into latent embeddings and then caches them, prioritizes space over time. In this paper, we introduce a new semantic-token paradigm and propose a discrete semantic tokenization approach, namely UIST, for user and item representation. UIST facilitates swift training and inference while maintaining a conservative memory footprint. Specifically, UIST quantizes dense embedding vectors into discrete tokens with shorter lengths and employs a hierarchical mixture inference module to weigh the contribution of each user--item token pair. Our experimental results on news ",
    "link": "https://arxiv.org/abs/2403.08206",
    "context": "Title: Discrete Semantic Tokenization for Deep CTR Prediction\nAbstract: arXiv:2403.08206v1 Announce Type: new  Abstract: Incorporating item content information into click-through rate (CTR) prediction models remains a challenge, especially with the time and space constraints of industrial scenarios. The content-encoding paradigm, which integrates user and item encoders directly into CTR models, prioritizes space over time. In contrast, the embedding-based paradigm transforms item and user semantics into latent embeddings and then caches them, prioritizes space over time. In this paper, we introduce a new semantic-token paradigm and propose a discrete semantic tokenization approach, namely UIST, for user and item representation. UIST facilitates swift training and inference while maintaining a conservative memory footprint. Specifically, UIST quantizes dense embedding vectors into discrete tokens with shorter lengths and employs a hierarchical mixture inference module to weigh the contribution of each user--item token pair. Our experimental results on news ",
    "path": "papers/24/03/2403.08206.json",
    "total_tokens": 897,
    "translated_title": "用于深度CTR预测的离散语义标记化",
    "translated_abstract": "将项目内容信息整合到点击率（CTR）预测模型中仍然是一个挑战，尤其是在工业场景下的时间和空间约束下。传统的内容编码范式将用户和项目编码器直接整合到CTR模型中，优先考虑空间而非时间。相反，基于嵌入的范式将项目和用户语义转换为潜在嵌入，然后对其进行缓存，优先考虑空间而非时间。本文介绍了一种新型的语义标记范式，并提出了一种用于用户和项目表示的离散语义标记化方法，即UIST。UIST实现了快速的训练和推断，同时保持了保守的内存占用。具体而言，UIST将密集嵌入向量量化为较短的离散标记，并采用分层混合推断模块来衡量每个用户-项目标记对的贡献。我们在新闻数据集上的实验结果表明，UIST在提高效率的同时降低了内存消耗。",
    "tldr": "提出了一种新型的语义标记范式并引入离散语义标记化方法UIST，用于用户和项目表示，旨在将项目内容信息整合到点击率（CTR）预测模型中，实现快速训练和推断，并在保持内存占用的同时提高效率。",
    "en_tdlr": "Introduced a new semantic-token paradigm and proposed a discrete semantic tokenization approach UIST for user and item representation, aiming to incorporate item content information into click-through rate (CTR) prediction models, enabling swift training and inference while maintaining a conservative memory footprint."
}