{
    "title": "Preventing Catastrophic Forgetting through Memory Networks in Continuous Detection",
    "abstract": "arXiv:2403.14797v1 Announce Type: cross  Abstract: Modern pre-trained architectures struggle to retain previous information while undergoing continuous fine-tuning on new tasks. Despite notable progress in continual classification, systems designed for complex vision tasks such as detection or segmentation still struggle to attain satisfactory performance. In this work, we introduce a memory-based detection transformer architecture to adapt a pre-trained DETR-style detector to new tasks while preserving knowledge from previous tasks. We propose a novel localized query function for efficient information retrieval from memory units, aiming to minimize forgetting. Furthermore, we identify a fundamental challenge in continual detection referred to as background relegation. This arises when object categories from earlier tasks reappear in future tasks, potentially without labels, leading them to be implicitly treated as background. This is an inevitable issue in continual detection or segme",
    "link": "https://arxiv.org/abs/2403.14797",
    "context": "Title: Preventing Catastrophic Forgetting through Memory Networks in Continuous Detection\nAbstract: arXiv:2403.14797v1 Announce Type: cross  Abstract: Modern pre-trained architectures struggle to retain previous information while undergoing continuous fine-tuning on new tasks. Despite notable progress in continual classification, systems designed for complex vision tasks such as detection or segmentation still struggle to attain satisfactory performance. In this work, we introduce a memory-based detection transformer architecture to adapt a pre-trained DETR-style detector to new tasks while preserving knowledge from previous tasks. We propose a novel localized query function for efficient information retrieval from memory units, aiming to minimize forgetting. Furthermore, we identify a fundamental challenge in continual detection referred to as background relegation. This arises when object categories from earlier tasks reappear in future tasks, potentially without labels, leading them to be implicitly treated as background. This is an inevitable issue in continual detection or segme",
    "path": "papers/24/03/2403.14797.json",
    "total_tokens": 832,
    "translated_title": "通过记忆网络在连续检测中防止灾难性遗忘",
    "translated_abstract": "现代预训练架构在持续对新任务进行微调时很难保留先前的信息。尽管在持续分类方面取得了显著进展，但针对复杂视觉任务（如检测或分割）设计的系统仍然难以获得满意的性能。在这项工作中，我们引入了一种基于记忆的检测变压器架构，以使预训练的DETR风格检测器适应新任务，同时保留先前任务的知识。我们提出了一种新颖的局部查询函数，用于有效地从记忆单元中检索信息，旨在最小化遗忘。此外，我们确定了持续检测中一个称为背景贬低的基本挑战。当来自先前任务的对象类别在未来任务中重新出现时，可能没有标签，导致它们被隐式视为背景。这是持续检测或分割中不可避免的问题。",
    "tldr": "通过引入记忆网络和局部查询函数，这项工作致力于在连续检测中防止灾难性遗忘，并解决了持续检测中的背景贬低问题。"
}