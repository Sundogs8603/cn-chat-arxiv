{
    "title": "FairRAG: Fair Human Generation via Fair Retrieval Augmentation",
    "abstract": "arXiv:2403.19964v1 Announce Type: cross  Abstract: Existing text-to-image generative models reflect or even amplify societal biases ingrained in their training data. This is especially concerning for human image generation where models are biased against certain demographic groups. Existing attempts to rectify this issue are hindered by the inherent limitations of the pre-trained models and fail to substantially improve demographic diversity. In this work, we introduce Fair Retrieval Augmented Generation (FairRAG), a novel framework that conditions pre-trained generative models on reference images retrieved from an external image database to improve fairness in human generation. FairRAG enables conditioning through a lightweight linear module that projects reference images into the textual space. To enhance fairness, FairRAG applies simple-yet-effective debiasing strategies, providing images from diverse demographic groups during the generative process. Extensive experiments demonstrat",
    "link": "https://arxiv.org/abs/2403.19964",
    "context": "Title: FairRAG: Fair Human Generation via Fair Retrieval Augmentation\nAbstract: arXiv:2403.19964v1 Announce Type: cross  Abstract: Existing text-to-image generative models reflect or even amplify societal biases ingrained in their training data. This is especially concerning for human image generation where models are biased against certain demographic groups. Existing attempts to rectify this issue are hindered by the inherent limitations of the pre-trained models and fail to substantially improve demographic diversity. In this work, we introduce Fair Retrieval Augmented Generation (FairRAG), a novel framework that conditions pre-trained generative models on reference images retrieved from an external image database to improve fairness in human generation. FairRAG enables conditioning through a lightweight linear module that projects reference images into the textual space. To enhance fairness, FairRAG applies simple-yet-effective debiasing strategies, providing images from diverse demographic groups during the generative process. Extensive experiments demonstrat",
    "path": "papers/24/03/2403.19964.json",
    "total_tokens": 836,
    "translated_title": "FairRAG: 公平人类生成的公平检索增强",
    "translated_abstract": "存在的文本到图像生成模型反映甚至放大了其训练数据中根深蒂固的社会偏见。这对人类图像生成尤为令人担忧，因为模型偏向某些人口统计组。现有的纠正此问题的尝试受到预训练模型固有限制的影响，并未能在根本上改善人口多样性。在这项工作中，我们引入了公平检索增强生成（FairRAG），这是一个新颖的框架，通过在来自外部图像数据库的参考图像上进行条件化来提高人类生成中的公平性。FairRAG通过一个轻量级线性模块实现条件化，将参考图像投射到文本空间中。为了增强公平性，FairRAG应用了简单而有效的去偏方法，在生成过程中提供来自不同人口统计组的图像。大量实验展示",
    "tldr": "FairRAG框架通过在外部图像数据库检索到的参考图像来提高人类生成中的公平性，并应用简单但有效的去偏策略，从而为生成过程提供来自不同人口统计组的图像。"
}