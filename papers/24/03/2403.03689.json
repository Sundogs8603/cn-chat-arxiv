{
    "title": "General2Specialized LLMs Translation for E-commerce",
    "abstract": "arXiv:2403.03689v1 Announce Type: cross  Abstract: Existing Neural Machine Translation (NMT) models mainly handle translation in the general domain, while overlooking domains with special writing formulas, such as e-commerce and legal documents. Taking e-commerce as an example, the texts usually include amounts of domain-related words and have more grammar problems, which leads to inferior performances of current NMT methods. To address these problems, we collect two domain-related resources, including a set of term pairs (aligned Chinese-English bilingual terms) and a parallel corpus annotated for the e-commerce domain. Furthermore, we propose a two-step fine-tuning paradigm (named G2ST) with self-contrastive semantic enhancement to transfer one general NMT model to the specialized NMT model for e-commerce. The paradigm can be used for the NMT models based on Large language models (LLMs). Extensive evaluations on real e-commerce titles demonstrate the superior translation quality and ",
    "link": "https://arxiv.org/abs/2403.03689",
    "context": "Title: General2Specialized LLMs Translation for E-commerce\nAbstract: arXiv:2403.03689v1 Announce Type: cross  Abstract: Existing Neural Machine Translation (NMT) models mainly handle translation in the general domain, while overlooking domains with special writing formulas, such as e-commerce and legal documents. Taking e-commerce as an example, the texts usually include amounts of domain-related words and have more grammar problems, which leads to inferior performances of current NMT methods. To address these problems, we collect two domain-related resources, including a set of term pairs (aligned Chinese-English bilingual terms) and a parallel corpus annotated for the e-commerce domain. Furthermore, we propose a two-step fine-tuning paradigm (named G2ST) with self-contrastive semantic enhancement to transfer one general NMT model to the specialized NMT model for e-commerce. The paradigm can be used for the NMT models based on Large language models (LLMs). Extensive evaluations on real e-commerce titles demonstrate the superior translation quality and ",
    "path": "papers/24/03/2403.03689.json",
    "total_tokens": 873,
    "translated_title": "通用到专业的电子商务LLMs翻译",
    "translated_abstract": "现有的神经机器翻译（NMT）模型主要处理通用领域的翻译，忽略了具有特殊写作公式的领域，比如电子商务和法律文件。以电子商务为例，文本通常包含大量领域相关词汇，并且存在更多的语法问题，这导致当前NMT方法的性能较差。为解决这些问题，我们收集了两个与领域相关的资源，包括一组术语对（对齐的中英双语术语）和一个针对电子商务领域进行注释的平行语料库。此外，我们提出了一个两步微调范式（名为G2ST），其中包括自对比语义增强，以将一个通用NMT模型转换为专门用于电子商务的NMT模型。该范式适用于基于大型语言模型（LLMs）的NMT模型。对真实电子商务标题的广泛评估表明了卓越的翻译质量。",
    "tldr": "提出了一个名为G2ST的两步微调范式，通过自对比语义增强将通用NMT模型转换为专门用于电子商务的NMT模型，以提高翻译质量。",
    "en_tdlr": "Introduced a two-step fine-tuning paradigm called G2ST, which transfers a general NMT model to a specialized NMT model for e-commerce through self-contrastive semantic enhancement to improve translation quality."
}