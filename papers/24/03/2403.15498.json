{
    "title": "Emergent World Models and Latent Variable Estimation in Chess-Playing Language Models",
    "abstract": "arXiv:2403.15498v1 Announce Type: cross  Abstract: Language models have shown unprecedented capabilities, sparking debate over the source of their performance. Is it merely the outcome of learning syntactic patterns and surface level statistics, or do they extract semantics and a world model from the text? Prior work by Li et al. investigated this by training a GPT model on synthetic, randomly generated Othello games and found that the model learned an internal representation of the board state. We extend this work into the more complex domain of chess, training on real games and investigating our model's internal representations using linear probes and contrastive activations. The model is given no a priori knowledge of the game and is solely trained on next character prediction, yet we find evidence of internal representations of board state. We validate these internal representations by using them to make interventions on the model's activations and edit its internal board state. Un",
    "link": "https://arxiv.org/abs/2403.15498",
    "context": "Title: Emergent World Models and Latent Variable Estimation in Chess-Playing Language Models\nAbstract: arXiv:2403.15498v1 Announce Type: cross  Abstract: Language models have shown unprecedented capabilities, sparking debate over the source of their performance. Is it merely the outcome of learning syntactic patterns and surface level statistics, or do they extract semantics and a world model from the text? Prior work by Li et al. investigated this by training a GPT model on synthetic, randomly generated Othello games and found that the model learned an internal representation of the board state. We extend this work into the more complex domain of chess, training on real games and investigating our model's internal representations using linear probes and contrastive activations. The model is given no a priori knowledge of the game and is solely trained on next character prediction, yet we find evidence of internal representations of board state. We validate these internal representations by using them to make interventions on the model's activations and edit its internal board state. Un",
    "path": "papers/24/03/2403.15498.json",
    "total_tokens": 723,
    "translated_title": "棋类语言模型中的新颖世界模型和潜变量估计",
    "translated_abstract": "语言模型展现了前所未有的能力，引发了关于其性能来源的讨论。是仅仅学习句法模式和表面统计结果，还是从文本中提取语义和世界模型？我们在象棋这个更复杂的领域扩展了之前的工作，通过在真实游戏中训练模型，使用线性探测和对比激活来研究模型的内部表示。尽管模型没有先验的游戏知识，仅仅通过下一个字符预测进行训练，我们发现了关于棋盘状态的内部表示的证据。",
    "tldr": "棋类语言模型在没有先验知识的情况下，通过下一个字符预测训练，仍能学习出内部表示的棋盘状态"
}