{
    "title": "Distill2Explain: Differentiable decision trees for explainable reinforcement learning in energy application controllers",
    "abstract": "arXiv:2403.11907v1 Announce Type: cross  Abstract: Demand-side flexibility is gaining importance as a crucial element in the energy transition process. Accounting for about 25% of final energy consumption globally, the residential sector is an important (potential) source of energy flexibility. However, unlocking this flexibility requires developing a control framework that (1) easily scales across different houses, (2) is easy to maintain, and (3) is simple to understand for end-users. A potential control framework for such a task is data-driven control, specifically model-free reinforcement learning (RL). Such RL-based controllers learn a good control policy by interacting with their environment, learning purely based on data and with minimal human intervention. Yet, they lack explainability, which hampers user acceptance. Moreover, limited hardware capabilities of residential assets forms a hurdle (e.g., using deep neural networks). To overcome both those challenges, we propose a no",
    "link": "https://arxiv.org/abs/2403.11907",
    "context": "Title: Distill2Explain: Differentiable decision trees for explainable reinforcement learning in energy application controllers\nAbstract: arXiv:2403.11907v1 Announce Type: cross  Abstract: Demand-side flexibility is gaining importance as a crucial element in the energy transition process. Accounting for about 25% of final energy consumption globally, the residential sector is an important (potential) source of energy flexibility. However, unlocking this flexibility requires developing a control framework that (1) easily scales across different houses, (2) is easy to maintain, and (3) is simple to understand for end-users. A potential control framework for such a task is data-driven control, specifically model-free reinforcement learning (RL). Such RL-based controllers learn a good control policy by interacting with their environment, learning purely based on data and with minimal human intervention. Yet, they lack explainability, which hampers user acceptance. Moreover, limited hardware capabilities of residential assets forms a hurdle (e.g., using deep neural networks). To overcome both those challenges, we propose a no",
    "path": "papers/24/03/2403.11907.json",
    "total_tokens": 909,
    "translated_title": "Distill2Explain: 可解释强化学习在能源应用控制器中的可微分决策树",
    "translated_abstract": "需求侧灵活性作为能源过渡进程中的关键要素日益重要。作为全球最终能源消耗的约25％，住宅部门是一个重要的（潜在的）能源灵活性来源。然而，发掘这种灵活性需要开发一个控制框架，该框架在不同房屋之间容易扩展，易于维护，并且对终端用户简单易懂。针对这一任务的潜在控制框架是数据驱动控制，特别是无模型强化学习（RL）。这种基于RL的控制器通过与环境交互学习良好的控制策略，完全基于数据学习，并且人类干预最小。然而，它们缺乏可解释性，这妨碍了用户接受。此外，住宅资产的有限硬件能力构成了阻碍（例如使用深度神经网络）。为了克服这两个挑战，我们提出了一种...",
    "tldr": "可解释性强化学习在能源应用控制器中的创新是通过提出可微分决策树来解决数据驱动控制中的可解释性和住宅资产硬件能力受限等挑战。",
    "en_tdlr": "The innovation of explainable reinforcement learning in energy application controllers is to address challenges such as explainability in data-driven control and limited hardware capabilities of residential assets by proposing differentiable decision trees."
}