{
    "title": "ModaLink: Unifying Modalities for Efficient Image-to-PointCloud Place Recognition",
    "abstract": "arXiv:2403.18762v1 Announce Type: cross  Abstract: Place recognition is an important task for robots and autonomous cars to localize themselves and close loops in pre-built maps. While single-modal sensor-based methods have shown satisfactory performance, cross-modal place recognition that retrieving images from a point-cloud database remains a challenging problem. Current cross-modal methods transform images into 3D points using depth estimation for modality conversion, which are usually computationally intensive and need expensive labeled data for depth supervision. In this work, we introduce a fast and lightweight framework to encode images and point clouds into place-distinctive descriptors. We propose an effective Field of View (FoV) transformation module to convert point clouds into an analogous modality as images. This module eliminates the necessity for depth estimation and helps subsequent modules achieve real-time performance. We further design a non-negative factorization-ba",
    "link": "https://arxiv.org/abs/2403.18762",
    "context": "Title: ModaLink: Unifying Modalities for Efficient Image-to-PointCloud Place Recognition\nAbstract: arXiv:2403.18762v1 Announce Type: cross  Abstract: Place recognition is an important task for robots and autonomous cars to localize themselves and close loops in pre-built maps. While single-modal sensor-based methods have shown satisfactory performance, cross-modal place recognition that retrieving images from a point-cloud database remains a challenging problem. Current cross-modal methods transform images into 3D points using depth estimation for modality conversion, which are usually computationally intensive and need expensive labeled data for depth supervision. In this work, we introduce a fast and lightweight framework to encode images and point clouds into place-distinctive descriptors. We propose an effective Field of View (FoV) transformation module to convert point clouds into an analogous modality as images. This module eliminates the necessity for depth estimation and helps subsequent modules achieve real-time performance. We further design a non-negative factorization-ba",
    "path": "papers/24/03/2403.18762.json",
    "total_tokens": 848,
    "translated_title": "ModaLink：统一模态以实现高效的图像到点云地点识别",
    "translated_abstract": "场所识别对于机器人和自动驾驶汽车来定位自身并关闭在预先构建的地图中的循环是一个重要的任务。而单模态传感器方法已经显示出令人满意的性能，而检索图像的交叉模态地点识别仍然是一个具有挑战性的问题。当前的交叉模态方法将图像转换为3D点使用深度估计进行模态转换，这通常计算密集且需要昂贵的标记数据进行深度监督。在这项工作中，我们介绍了一个快速且轻量级的框架，将图像和点云编码为地点特征描述符。我们提出了一个有效的视场（FoV）转换模块，将点云转换为与图像类似的模态。该模块消除了深度估计的必要性，并帮助后续模块实现实时性能。",
    "tldr": "提出了一个快速轻量级的框架，将图像和点云编码为地点特征描述符，并设计了一种有效的Field of View（FoV）转换模块来消除深度估计的必要性，从而实现了实时性能。",
    "en_tdlr": "Introduced a fast and lightweight framework to encode images and point clouds into place-distinctive descriptors, and designed an effective Field of View (FoV) transformation module to eliminate the necessity for depth estimation, achieving real-time performance."
}