{
    "title": "Self-Supervised Interpretable Sensorimotor Learning via Latent Functional Modularity",
    "abstract": "arXiv:2403.18947v1 Announce Type: new  Abstract: We introduce MoNet, a novel method that combines end-to-end learning with modular network architectures for self-supervised and interpretable sensorimotor learning. MoNet is composed of three functionally distinct neural modules: Perception, Planning, and Control. Leveraging its inherent modularity through a cognition-guided contrastive loss function, MoNet efficiently learns task-specific decision-making processes in latent space, without requiring task-level supervision. Moreover, our method incorporates an online post-hoc explainability approach, which enhances the interpretability of the end-to-end inferences without a trade-off in sensorimotor performance. In real-world indoor environments, MoNet demonstrates effective visual autonomous navigation, surpassing baseline models by 11% to 47% in task specificity analysis. We further delve into the interpretability of our network through the post-hoc analysis of perceptual saliency maps ",
    "link": "https://arxiv.org/abs/2403.18947",
    "context": "Title: Self-Supervised Interpretable Sensorimotor Learning via Latent Functional Modularity\nAbstract: arXiv:2403.18947v1 Announce Type: new  Abstract: We introduce MoNet, a novel method that combines end-to-end learning with modular network architectures for self-supervised and interpretable sensorimotor learning. MoNet is composed of three functionally distinct neural modules: Perception, Planning, and Control. Leveraging its inherent modularity through a cognition-guided contrastive loss function, MoNet efficiently learns task-specific decision-making processes in latent space, without requiring task-level supervision. Moreover, our method incorporates an online post-hoc explainability approach, which enhances the interpretability of the end-to-end inferences without a trade-off in sensorimotor performance. In real-world indoor environments, MoNet demonstrates effective visual autonomous navigation, surpassing baseline models by 11% to 47% in task specificity analysis. We further delve into the interpretability of our network through the post-hoc analysis of perceptual saliency maps ",
    "path": "papers/24/03/2403.18947.json",
    "total_tokens": 906,
    "translated_title": "自监督可解释的感知动作学习通过潜在功能模块性",
    "translated_abstract": "我们介绍了MoNet，这是一种将端到端学习与模块化网络架构相结合的新方法，用于自监督和可解释的感知动作学习。MoNet由三个功能上不同的神经模块组成：感知、规划和控制。通过认知引导的对比损失函数，MoNet有效地在潜在空间中学习特定任务的决策过程，而不需要任务级别的监督。此外，我们的方法还融入了一种在线事后解释方法，增强了端到端推断的可解释性，而不影响感知动作性能。在现实世界的室内环境中，MoNet展示了有效的视觉自主导航，在任务特异性分析中超越了基线模型11%至47%。我们进一步通过感知显著性地图的事后分析探讨了我们网络的可解释性。",
    "tldr": "MoNet是一种结合端到端学习和模块化网络架构的方法，通过认知引导的对比损失函数，在潜在空间中高效学习任务特定的决策过程，而无需任务级别的监督，同时提高端到端推断的可解释性，实现了在实际环境中的有效视觉自主导航。",
    "en_tdlr": "MoNet is a method that combines end-to-end learning with modular network architectures, efficiently learns task-specific decision-making processes in latent space through cognition-guided contrastive loss function without task-level supervision, enhances interpretability of end-to-end inferences, and achieves effective visual autonomous navigation in real-world environments."
}