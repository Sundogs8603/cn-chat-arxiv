{
    "title": "Rethinking of Encoder-based Warm-start Methods in Hyperparameter Optimization",
    "abstract": "arXiv:2403.04720v1 Announce Type: new  Abstract: Effectively representing heterogeneous tabular datasets for meta-learning remains an open problem. Previous approaches rely on predefined meta-features, for example, statistical measures or landmarkers. Encoder-based models, such as Dataset2Vec, allow us to extract significant meta-features automatically without human intervention. This research introduces a novel encoder-based representation of tabular datasets implemented within the liltab package available on GitHub https://github.com/azoz01/liltab. Our package is based on an established model for heterogeneous tabular data proposed in [Iwata and Kumagai, 2020]. The proposed approach employs a different model for encoding feature relationships, generating alternative representations compared to existing methods like Dataset2Vec. Both of them leverage the fundamental assumption of dataset similarity learning. In this work, we evaluate Dataset2Vec and liltab on two common meta-tasks - r",
    "link": "https://arxiv.org/abs/2403.04720",
    "context": "Title: Rethinking of Encoder-based Warm-start Methods in Hyperparameter Optimization\nAbstract: arXiv:2403.04720v1 Announce Type: new  Abstract: Effectively representing heterogeneous tabular datasets for meta-learning remains an open problem. Previous approaches rely on predefined meta-features, for example, statistical measures or landmarkers. Encoder-based models, such as Dataset2Vec, allow us to extract significant meta-features automatically without human intervention. This research introduces a novel encoder-based representation of tabular datasets implemented within the liltab package available on GitHub https://github.com/azoz01/liltab. Our package is based on an established model for heterogeneous tabular data proposed in [Iwata and Kumagai, 2020]. The proposed approach employs a different model for encoding feature relationships, generating alternative representations compared to existing methods like Dataset2Vec. Both of them leverage the fundamental assumption of dataset similarity learning. In this work, we evaluate Dataset2Vec and liltab on two common meta-tasks - r",
    "path": "papers/24/03/2403.04720.json",
    "total_tokens": 841,
    "translated_title": "在超参数优化中重新思考基于编码器的热启动方法",
    "translated_abstract": "有效地表示异质性表格数据集以用于元学习仍然是一个未解决的问题。以往的方法依赖于预定义的元特征，例如，统计量或标志点。基于编码器的模型，如Dataset2Vec，使我们能够在无人干预的情况下自动提取重要的元特征。本研究介绍了一个新颖的基于编码器的表格数据集表示，实现在liltab包中，该包可在GitHub上找到https://github.com/azoz01/liltab。我们的包基于[Iwata and Kumagai, 2020]提出的一个用于异质表格数据的已建立模型。所提出的方法采用一种不同于现有方法如Dataset2Vec 的编码特征关系的模型，生成与现有方法不同的替代表示。它们都利用了数据集相似性学习的基本假设。在这项工作中，我们在两个常见的元任务上评价了Dataset2Vec和liltab",
    "tldr": "提出了一种新的基于编码器的表格数据集表示方法，与现有方法不同，能够自动提取重要的元特征，同时在两个常见的元任务上进行了评估"
}