{
    "title": "Complexity Matters: Dynamics of Feature Learning in the Presence of Spurious Correlations",
    "abstract": "arXiv:2403.03375v1 Announce Type: new  Abstract: Existing research often posits spurious features as \"easier\" to learn than core features in neural network optimization, but the impact of their relative simplicity remains under-explored. Moreover they mainly focus on the end performance intead of the learning dynamics of feature learning. In this paper, we propose a theoretical framework and associated synthetic dataset grounded in boolean function analysis which allows for fine-grained control on the relative complexity (compared to core features) and correlation strength (with respect to the label) of spurious features to study the dynamics of feature learning under spurious correlation. Our setup uncovers several interesting phenomenon: (1) stronger spurious correlations or simpler spurious features slow down the rate of learning for the core features, (2) learning phases of spurious features and core features are not always separable, (3) spurious features are not forgotten even af",
    "link": "https://arxiv.org/abs/2403.03375",
    "context": "Title: Complexity Matters: Dynamics of Feature Learning in the Presence of Spurious Correlations\nAbstract: arXiv:2403.03375v1 Announce Type: new  Abstract: Existing research often posits spurious features as \"easier\" to learn than core features in neural network optimization, but the impact of their relative simplicity remains under-explored. Moreover they mainly focus on the end performance intead of the learning dynamics of feature learning. In this paper, we propose a theoretical framework and associated synthetic dataset grounded in boolean function analysis which allows for fine-grained control on the relative complexity (compared to core features) and correlation strength (with respect to the label) of spurious features to study the dynamics of feature learning under spurious correlation. Our setup uncovers several interesting phenomenon: (1) stronger spurious correlations or simpler spurious features slow down the rate of learning for the core features, (2) learning phases of spurious features and core features are not always separable, (3) spurious features are not forgotten even af",
    "path": "papers/24/03/2403.03375.json",
    "total_tokens": 1008,
    "translated_title": "复杂性至关重要：在存在虚假相关性的情况下特征学习的动态",
    "translated_abstract": "现有研究经常将虚假特征定义为在神经网络优化中“更容易”学习的内容，但它们相对简单性的影响仍未被充分探讨。此外，他们主要关注的是最终性能，而不是特征学习的学习动态。在本文中，我们提出了一个理论框架和相关的基于布尔函数分析的合成数据集，允许对虚假特征的相对复杂性（与核心特征相比）和相关性强度（相对于标签）进行细致控制，以研究在虚假相关性下特征学习的动态。我们的设置揭示了几个有趣的现象：（1）更强的虚假相关性或更简单的虚假特征会减慢核心特征的学习速度，（2）虚假特征和核心特征的学习阶段并非总是可以被分开，（3）虚假特征即使在一段时间之后也不会被遗忘。",
    "tldr": "在本文中，通过提出一个基于布尔函数分析的合成数据集，研究了在虚假相关性条件下特征学习动态，发现了虚假相关性或虚假特征的强度会影响核心特征学习速度，虚假特征和核心特征的学习阶段不总是可分开，并且虚假特征即使在一段时间后也不会被遗忘。",
    "en_tdlr": "This paper investigates the dynamics of feature learning under spurious correlations by proposing a synthetic dataset based on boolean function analysis, revealing that the strength of spurious correlations or features can affect the learning speed of core features, the learning phases of spurious and core features are not always separable, and spurious features are not forgotten even after a period of time."
}