{
    "title": "Answerability in Retrieval-Augmented Open-Domain Question Answering",
    "abstract": "arXiv:2403.01461v1 Announce Type: new  Abstract: The performance of Open-Domain Question Answering (ODQA) retrieval systems can exhibit sub-optimal behavior, providing text excerpts with varying degrees of irrelevance. Unfortunately, many existing ODQA datasets lack examples specifically targeting the identification of irrelevant text excerpts. Previous attempts to address this gap have relied on a simplistic approach of pairing questions with random text excerpts. This paper aims to investigate the effectiveness of models trained using this randomized strategy, uncovering an important limitation in their ability to generalize to irrelevant text excerpts with high semantic overlap. As a result, we observed a substantial decrease in predictive accuracy, from 98% to 1%. To address this limitation, we discovered an efficient approach for training models to recognize such excerpts. By leveraging unanswerable pairs from the SQuAD 2.0 dataset, our models achieve a nearly perfect (~100%) accu",
    "link": "https://arxiv.org/abs/2403.01461",
    "context": "Title: Answerability in Retrieval-Augmented Open-Domain Question Answering\nAbstract: arXiv:2403.01461v1 Announce Type: new  Abstract: The performance of Open-Domain Question Answering (ODQA) retrieval systems can exhibit sub-optimal behavior, providing text excerpts with varying degrees of irrelevance. Unfortunately, many existing ODQA datasets lack examples specifically targeting the identification of irrelevant text excerpts. Previous attempts to address this gap have relied on a simplistic approach of pairing questions with random text excerpts. This paper aims to investigate the effectiveness of models trained using this randomized strategy, uncovering an important limitation in their ability to generalize to irrelevant text excerpts with high semantic overlap. As a result, we observed a substantial decrease in predictive accuracy, from 98% to 1%. To address this limitation, we discovered an efficient approach for training models to recognize such excerpts. By leveraging unanswerable pairs from the SQuAD 2.0 dataset, our models achieve a nearly perfect (~100%) accu",
    "path": "papers/24/03/2403.01461.json",
    "total_tokens": 909,
    "translated_title": "检索增强开放域问答中的可回答性研究",
    "translated_abstract": "开放域问答检索系统的性能可能表现出次优行为，提供具有不同程度无关性的文本摘录。不幸的是，许多现有的开放域问答数据集缺乏专门针对识别无关文本摘录的示例。先前的尝试致力于解决这一差距问题，但依赖于将问题与随机文本摘录配对的简单方法。本文旨在探讨使用这种随机化策略训练模型的效果，揭示其在泛化到具有高语义重叠的无关文本摘录方面存在重要局限性。结果，我们观察到预测准确性显著下降，从98%下降到1%。为解决这一限制，我们发现了一种有效的训练模型识别此类摘录的方法。通过利用来自SQuAD 2.0数据集的不可回答问题对，我们的模型实现了近乎完美的(~100%)准确率。",
    "tldr": "本论文研究了在开放域问答中检索系统的可回答性问题，揭示了使用随机化策略训练模型在泛化到具有高语义重叠的无关文本摘录方面的重要局限性，并提出了一种有效的训练模型的方法。",
    "en_tdlr": "This paper investigates answerability in retrieval systems of open-domain question answering, highlighting the important limitation of using a randomized strategy to train models in generalizing to irrelevant text excerpts with high semantic overlap, and proposes an effective method for training models."
}