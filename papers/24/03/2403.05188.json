{
    "title": "CommitBench: A Benchmark for Commit Message Generation",
    "abstract": "arXiv:2403.05188v1 Announce Type: new  Abstract: Writing commit messages is a tedious daily task for many software developers, and often remains neglected. Automating this task has the potential to save time while ensuring that messages are informative. A high-quality dataset and an objective benchmark are vital preconditions for solid research and evaluation towards this goal. We show that existing datasets exhibit various problems, such as the quality of the commit selection, small sample sizes, duplicates, privacy issues, and missing licenses for redistribution. This can lead to unusable models and skewed evaluations, where inferior models achieve higher evaluation scores due to biases in the data. We compile a new large-scale dataset, CommitBench, adopting best practices for dataset creation. We sample commits from diverse projects with licenses that permit redistribution and apply our filtering and dataset enhancements to improve the quality of generated commit messages. We use Co",
    "link": "https://arxiv.org/abs/2403.05188",
    "context": "Title: CommitBench: A Benchmark for Commit Message Generation\nAbstract: arXiv:2403.05188v1 Announce Type: new  Abstract: Writing commit messages is a tedious daily task for many software developers, and often remains neglected. Automating this task has the potential to save time while ensuring that messages are informative. A high-quality dataset and an objective benchmark are vital preconditions for solid research and evaluation towards this goal. We show that existing datasets exhibit various problems, such as the quality of the commit selection, small sample sizes, duplicates, privacy issues, and missing licenses for redistribution. This can lead to unusable models and skewed evaluations, where inferior models achieve higher evaluation scores due to biases in the data. We compile a new large-scale dataset, CommitBench, adopting best practices for dataset creation. We sample commits from diverse projects with licenses that permit redistribution and apply our filtering and dataset enhancements to improve the quality of generated commit messages. We use Co",
    "path": "papers/24/03/2403.05188.json",
    "total_tokens": 803,
    "translated_title": "CommitBench：用于提交信息生成的基准测试",
    "translated_abstract": "写提交信息对许多软件开发人员来说是一项乏味的日常任务，经常被忽视。自动化此任务有潜力节省时间，同时确保信息具有信息量。高质量的数据集和客观的基准测试是朝着这一目标进行坚实研究和评估的重要先决条件。我们发现现有数据集存在各种问题，例如提交选择的质量、样本量小、重复、隐私问题以及没有授权进行再分发。这可能导致无法使用的模型和偏倚的评估，次优模型由于数据中的偏见而获得更高的评估分数。我们编制了一个新的大规模数据集CommitBench，采用了数据集创建的最佳实践。我们从许可允许再分发的各种项目中抽样提交，并应用我们的过滤和数据集增强措施以提高生成的提交信息的质量。",
    "tldr": "提出了一个名为CommitBench的新大规模数据集，采用最佳实践进行数据集创建，解决了现有数据集存在的问题，以改善生成的提交信息的质量。"
}