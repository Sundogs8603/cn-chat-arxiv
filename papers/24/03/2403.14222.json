{
    "title": "Large-Scale Label Interpretation Learning for Few-Shot Named Entity Recognition",
    "abstract": "arXiv:2403.14222v1 Announce Type: new  Abstract: Few-shot named entity recognition (NER) detects named entities within text using only a few annotated examples. One promising line of research is to leverage natural language descriptions of each entity type: the common label PER might, for example, be verbalized as ''person entity.'' In an initial label interpretation learning phase, the model learns to interpret such verbalized descriptions of entity types. In a subsequent few-shot tagset extension phase, this model is then given a description of a previously unseen entity type (such as ''music album'') and optionally a few training examples to perform few-shot NER for this type. In this paper, we systematically explore the impact of a strong semantic prior to interpret verbalizations of new entity types by massively scaling up the number and granularity of entity types used for label interpretation learning. To this end, we leverage an entity linking benchmark to create a dataset with",
    "link": "https://arxiv.org/abs/2403.14222",
    "context": "Title: Large-Scale Label Interpretation Learning for Few-Shot Named Entity Recognition\nAbstract: arXiv:2403.14222v1 Announce Type: new  Abstract: Few-shot named entity recognition (NER) detects named entities within text using only a few annotated examples. One promising line of research is to leverage natural language descriptions of each entity type: the common label PER might, for example, be verbalized as ''person entity.'' In an initial label interpretation learning phase, the model learns to interpret such verbalized descriptions of entity types. In a subsequent few-shot tagset extension phase, this model is then given a description of a previously unseen entity type (such as ''music album'') and optionally a few training examples to perform few-shot NER for this type. In this paper, we systematically explore the impact of a strong semantic prior to interpret verbalizations of new entity types by massively scaling up the number and granularity of entity types used for label interpretation learning. To this end, we leverage an entity linking benchmark to create a dataset with",
    "path": "papers/24/03/2403.14222.json",
    "total_tokens": 796,
    "translated_title": "大规模标签解释学习用于少样本命名实体识别",
    "translated_abstract": "少样本命名实体识别（NER）仅使用少量注释示例在文本中检测命名实体。 一种有前途的研究方向是利用每种实体类型的自然语言描述：例如，常见标签PER可能被表达为“人物实体”。 在初始标签解释学习阶段，模型学习解释这些实体类型的文本化描述。 在随后的少样本标签集扩展阶段，该模型然后给出先前未见实体类型的描述（例如“音乐专辑”）以及可选的少量训练示例，执行该类型的少样本NER。 在本文中，我们系统地探讨了强语义先验对于通过大规模扩展用于标签解释学习的实体类型数量和粒度的影响。 为此，我们利用实体链接基准来创建一个数据集...",
    "tldr": "通过大规模扩展实体类型数量和粒度，研究了强语义先验对于解释实体类型文本化描述的影响。",
    "en_tdlr": "Investigated the impact of a strong semantic prior on interpreting verbalized descriptions of entity types by massively scaling up the number and granularity of entity types used for label interpretation learning."
}