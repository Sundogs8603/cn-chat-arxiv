{
    "title": "Loop Improvement: An Efficient Approach for Extracting Shared Features from Heterogeneous Data without Central Server",
    "abstract": "arXiv:2403.14371v1 Announce Type: cross  Abstract: In federated learning, data heterogeneity significantly impacts performance. A typical solution involves segregating these parameters into shared and personalized components, a concept also relevant in multi-task learning. Addressing this, we propose \"Loop Improvement\" (LI), a novel method enhancing this separation and feature extraction without necessitating a central server or data interchange among participants. Our experiments reveal LI's superiority in several aspects: In personalized federated learning environments, LI consistently outperforms the advanced FedALA algorithm in accuracy across diverse scenarios. Additionally, LI's feature extractor closely matches the performance achieved when aggregating data from all clients. In global model contexts, employing LI with stacked personalized layers and an additional network also yields comparable results to combined client data scenarios. Furthermore, LI's adaptability extends to m",
    "link": "https://arxiv.org/abs/2403.14371",
    "context": "Title: Loop Improvement: An Efficient Approach for Extracting Shared Features from Heterogeneous Data without Central Server\nAbstract: arXiv:2403.14371v1 Announce Type: cross  Abstract: In federated learning, data heterogeneity significantly impacts performance. A typical solution involves segregating these parameters into shared and personalized components, a concept also relevant in multi-task learning. Addressing this, we propose \"Loop Improvement\" (LI), a novel method enhancing this separation and feature extraction without necessitating a central server or data interchange among participants. Our experiments reveal LI's superiority in several aspects: In personalized federated learning environments, LI consistently outperforms the advanced FedALA algorithm in accuracy across diverse scenarios. Additionally, LI's feature extractor closely matches the performance achieved when aggregating data from all clients. In global model contexts, employing LI with stacked personalized layers and an additional network also yields comparable results to combined client data scenarios. Furthermore, LI's adaptability extends to m",
    "path": "papers/24/03/2403.14371.json",
    "total_tokens": 865,
    "translated_title": "循环改进：一种从异构数据中提取共享特征的高效方法，无需中央服务器",
    "translated_abstract": "在联邦学习中，数据的异质性显著影响性能。一种典型的解决方案是将这些参数分为共享和个性化组件，这个概念在多任务学习中也很重要。针对这一问题，我们提出了“循环改进”（LI），这是一种新颖的方法，增强了这种分离和特征提取，而不需要中央服务器或参与者之间的数据交换。我们的实验显示，在个性化联邦学习环境中，LI在准确性方面始终优于先进的FedALA算法，适用于各种情况。此外，LI的特征提取器与聚合所有客户端数据时实现的性能相匹配。在全局模型环境中，使用具有堆叠个性化层和额外网络的LI也产生了与合并客户端数据场景相当的结果。此外，LI的适应能力延展到...",
    "tldr": "循环改进（LI）是一种无需中央服务器或数据交换的新颖方法，可提高数据异质性下的特征提取效率，表现优越于先进算法FedALA，并可应用于个性化联邦学习和全局模型环境。",
    "en_tdlr": "Loop Improvement (LI) is a novel method that enhances feature extraction efficiency under data heterogeneity without requiring a central server or data exchange, outperforming the advanced FedALA algorithm and applicable to personalized federated learning and global model contexts."
}