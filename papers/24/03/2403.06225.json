{
    "title": "MoST: Motion Style Transformer between Diverse Action Contents",
    "abstract": "arXiv:2403.06225v1 Announce Type: cross  Abstract: While existing motion style transfer methods are effective between two motions with identical content, their performance significantly diminishes when transferring style between motions with different contents. This challenge lies in the lack of clear separation between content and style of a motion. To tackle this challenge, we propose a novel motion style transformer that effectively disentangles style from content and generates a plausible motion with transferred style from a source motion. Our distinctive approach to achieving the goal of disentanglement is twofold: (1) a new architecture for motion style transformer with 'part-attentive style modulator across body parts' and 'Siamese encoders that encode style and content features separately'; (2) style disentanglement loss. Our method outperforms existing methods and demonstrates exceptionally high quality, particularly in motion pairs with different contents, without the need fo",
    "link": "https://arxiv.org/abs/2403.06225",
    "context": "Title: MoST: Motion Style Transformer between Diverse Action Contents\nAbstract: arXiv:2403.06225v1 Announce Type: cross  Abstract: While existing motion style transfer methods are effective between two motions with identical content, their performance significantly diminishes when transferring style between motions with different contents. This challenge lies in the lack of clear separation between content and style of a motion. To tackle this challenge, we propose a novel motion style transformer that effectively disentangles style from content and generates a plausible motion with transferred style from a source motion. Our distinctive approach to achieving the goal of disentanglement is twofold: (1) a new architecture for motion style transformer with 'part-attentive style modulator across body parts' and 'Siamese encoders that encode style and content features separately'; (2) style disentanglement loss. Our method outperforms existing methods and demonstrates exceptionally high quality, particularly in motion pairs with different contents, without the need fo",
    "path": "papers/24/03/2403.06225.json",
    "total_tokens": 842,
    "translated_title": "MoST: 在多样动作内容之间进行运动风格转换的动作风格转换器",
    "translated_abstract": "尽管现有的动作风格转移方法在相同内容的两个动作之间是有效的，但当在不同内容的动作之间转移风格时，它们的表现显著下降。这一挑战在于动作的内容和风格之间缺乏明确的分离。为了应对这一挑战，我们提出了一种新颖的动作风格转换器，有效地将风格与内容分离，并从源动作生成具有转移风格的合理动作。我们实现分离目标的独特方法具有双重性：(1) 带有“部分关注风格调制器跨身体部位”和“编码器编码风格和内容特征分开”的动作风格转换器的新架构；(2) 风格分离损失。我们的方法优于现有方法，并表现出异常高的质量，特别是在具有不同内容的动作对中，无需...",
    "tldr": "MoST提出了一种新颖的动作风格转换器，能够有效地将风格与内容分离，在转移风格时表现出色，并在不同内容的动作对中展现出卓越的质量。",
    "en_tdlr": "MoST proposed a novel motion style transformer that effectively disentangles style from content, performs well in transferring style, and demonstrates exceptional quality in motion pairs with different contents."
}