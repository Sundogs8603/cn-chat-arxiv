{
    "title": "Enhanced Event-Based Video Reconstruction with Motion Compensation",
    "abstract": "arXiv:2403.11961v1 Announce Type: cross  Abstract: Deep neural networks for event-based video reconstruction often suffer from a lack of interpretability and have high memory demands. A lightweight network called CISTA-LSTC has recently been introduced showing that high-quality reconstruction can be achieved through the systematic design of its architecture. However, its modelling assumption that input signals and output reconstructed frame share the same sparse representation neglects the displacement caused by motion. To address this, we propose warping the input intensity frames and sparse codes to enhance reconstruction quality. A CISTA-Flow network is constructed by integrating a flow network with CISTA-LSTC for motion compensation. The system relies solely on events, in which predicted flow aids in reconstruction and then reconstructed frames are used to facilitate flow estimation. We also introduce an iterative training framework for this combined system. Results demonstrate tha",
    "link": "https://arxiv.org/abs/2403.11961",
    "context": "Title: Enhanced Event-Based Video Reconstruction with Motion Compensation\nAbstract: arXiv:2403.11961v1 Announce Type: cross  Abstract: Deep neural networks for event-based video reconstruction often suffer from a lack of interpretability and have high memory demands. A lightweight network called CISTA-LSTC has recently been introduced showing that high-quality reconstruction can be achieved through the systematic design of its architecture. However, its modelling assumption that input signals and output reconstructed frame share the same sparse representation neglects the displacement caused by motion. To address this, we propose warping the input intensity frames and sparse codes to enhance reconstruction quality. A CISTA-Flow network is constructed by integrating a flow network with CISTA-LSTC for motion compensation. The system relies solely on events, in which predicted flow aids in reconstruction and then reconstructed frames are used to facilitate flow estimation. We also introduce an iterative training framework for this combined system. Results demonstrate tha",
    "path": "papers/24/03/2403.11961.json",
    "total_tokens": 805,
    "translated_title": "通过运动补偿增强事件驱动视频重建",
    "translated_abstract": "深度神经网络用于事件驱动视频重建通常缺乏可解释性，并且具有高内存需求。最近引入了一种轻量级网络CISTA-LSTC，表明通过系统设计其架构可以实现高质量的重建。然而，其建模假设输入信号和输出重建帧共享相同的稀疏表示，忽视了运动导致的位移。为了解决这一问题，我们提出对输入强度帧和稀疏编码进行变换以增强重建质量。通过将流网络与CISTA-LSTC集成，构建了一个CISTA-Flow网络用于运动补偿。系统仅依赖事件，其中预测的流有助于重建，然后重建的帧用于促进流估计。我们还为该组合系统引入了一个迭代训练框架。结果表明",
    "tldr": "通过运动补偿来增强重建质量，提出将输入帧和稀疏编码进行变换，并将流网络与CISTA-LSTC集成，形成CISTA-Flow网络，使系统仅依赖事件。"
}