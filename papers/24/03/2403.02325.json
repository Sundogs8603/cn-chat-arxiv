{
    "title": "Contrastive Region Guidance: Improving Grounding in Vision-Language Models without Training",
    "abstract": "arXiv:2403.02325v1 Announce Type: cross  Abstract: Highlighting particularly relevant regions of an image can improve the performance of vision-language models (VLMs) on various vision-language (VL) tasks by guiding the model to attend more closely to these regions of interest. For example, VLMs can be given a \"visual prompt\", where visual markers such as bounding boxes delineate key image regions. However, current VLMs that can incorporate visual guidance are either proprietary and expensive or require costly training on curated data that includes visual prompts. We introduce Contrastive Region Guidance (CRG), a training-free guidance method that enables open-source VLMs to respond to visual prompts. CRG contrasts model outputs produced with and without visual prompts, factoring out biases revealed by the model when answering without the information required to produce a correct answer (i.e., the model's prior). CRG achieves substantial improvements in a wide variety of VL tasks: When",
    "link": "https://arxiv.org/abs/2403.02325",
    "context": "Title: Contrastive Region Guidance: Improving Grounding in Vision-Language Models without Training\nAbstract: arXiv:2403.02325v1 Announce Type: cross  Abstract: Highlighting particularly relevant regions of an image can improve the performance of vision-language models (VLMs) on various vision-language (VL) tasks by guiding the model to attend more closely to these regions of interest. For example, VLMs can be given a \"visual prompt\", where visual markers such as bounding boxes delineate key image regions. However, current VLMs that can incorporate visual guidance are either proprietary and expensive or require costly training on curated data that includes visual prompts. We introduce Contrastive Region Guidance (CRG), a training-free guidance method that enables open-source VLMs to respond to visual prompts. CRG contrasts model outputs produced with and without visual prompts, factoring out biases revealed by the model when answering without the information required to produce a correct answer (i.e., the model's prior). CRG achieves substantial improvements in a wide variety of VL tasks: When",
    "path": "papers/24/03/2403.02325.json",
    "total_tokens": 702,
    "translated_title": "对比区域引导：在视觉-语言模型中提高定位准确性而无需训练",
    "translated_abstract": "通过突出图像中特别相关的区域，可以改善视觉-语言模型（VLMs）在各种视觉-语言（VL）任务上的性能，引导模型更密切地关注这些感兴趣的区域。我们引入了对比区域引导（CRG），这是一种无需训练的引导方法，可以使开源的VLMs响应视觉提示，并在各种VL任务中取得显著改进。",
    "tldr": "引入了对比区域引导（CRG）方法，实现了在视觉-语言模型中无需训练即可使模型响应视觉提示并取得显著改进。",
    "en_tdlr": "Introduced Contrastive Region Guidance (CRG), enabling vision-language models to respond to visual prompts without training and achieving substantial improvements."
}