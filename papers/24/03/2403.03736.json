{
    "title": "Unifying Generation and Compression: Ultra-low bitrate Image Coding Via Multi-stage Transformer",
    "abstract": "arXiv:2403.03736v1 Announce Type: cross  Abstract: Recent progress in generative compression technology has significantly improved the perceptual quality of compressed data. However, these advancements primarily focus on producing high-frequency details, often overlooking the ability of generative models to capture the prior distribution of image content, thus impeding further bitrate reduction in extreme compression scenarios (<0.05 bpp). Motivated by the capabilities of predictive language models for lossless compression, this paper introduces a novel Unified Image Generation-Compression (UIGC) paradigm, merging the processes of generation and compression. A key feature of the UIGC framework is the adoption of vector-quantized (VQ) image models for tokenization, alongside a multi-stage transformer designed to exploit spatial contextual information for modeling the prior distribution. As such, the dual-purpose framework effectively utilizes the learned prior for entropy estimation and",
    "link": "https://arxiv.org/abs/2403.03736",
    "context": "Title: Unifying Generation and Compression: Ultra-low bitrate Image Coding Via Multi-stage Transformer\nAbstract: arXiv:2403.03736v1 Announce Type: cross  Abstract: Recent progress in generative compression technology has significantly improved the perceptual quality of compressed data. However, these advancements primarily focus on producing high-frequency details, often overlooking the ability of generative models to capture the prior distribution of image content, thus impeding further bitrate reduction in extreme compression scenarios (<0.05 bpp). Motivated by the capabilities of predictive language models for lossless compression, this paper introduces a novel Unified Image Generation-Compression (UIGC) paradigm, merging the processes of generation and compression. A key feature of the UIGC framework is the adoption of vector-quantized (VQ) image models for tokenization, alongside a multi-stage transformer designed to exploit spatial contextual information for modeling the prior distribution. As such, the dual-purpose framework effectively utilizes the learned prior for entropy estimation and",
    "path": "papers/24/03/2403.03736.json",
    "total_tokens": 856,
    "translated_title": "通过多阶段Transformer实现统一生成和压缩：超低比特率图像编码",
    "translated_abstract": "近年来生成式压缩技术的进展显著提高了压缩数据的感知质量。然而，这些进展主要集中在产生高频细节，往往忽视了生成模型捕捉图像内容先验分布的能力，从而阻碍了在极端压缩场景（<0.05 bpp）中进一步降低比特率。在预测性语言模型对无损压缩的能力的启发下，本文引入了一种新颖的统一图像生成-压缩（UIGC）范式，将生成和压缩的过程结合在一起。UIGC框架的一个关键特征是采用向量量化（VQ）图像模型进行标记化，以及一个多阶段Transformer，旨在利用空间上下文信息来建模先验分布。因此，这种双重用途的框架有效地利用了学习到的先验进行熵估计。",
    "tldr": "通过引入统一图像生成-压缩（UIGC）范式，本文提出了一种新的多阶段Transformer框架，结合了生成和压缩的过程，以有效利用学习到的先验进行熵估计。",
    "en_tdlr": "This paper introduces a novel Unified Image Generation-Compression (UIGC) paradigm, merging the processes of generation and compression with a multi-stage transformer framework to effectively utilize the learned prior for entropy estimation."
}