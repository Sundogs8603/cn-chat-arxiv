{
    "title": "Meaningful Learning: Advancing Abstract Reasoning in Large Language Models via Generic Fact Guidance",
    "abstract": "arXiv:2403.09085v1 Announce Type: cross  Abstract: Large language models (LLMs) have developed impressive performance and strong explainability across various reasoning scenarios, marking a significant stride towards mimicking human-like intelligence. Despite this, when tasked with simple questions supported by a generic fact, LLMs often fail to provide consistent and precise answers, indicating a deficiency in abstract reasoning abilities. This has sparked a vigorous debate about whether LLMs are genuinely reasoning or merely memorizing. In light of this, we design a preliminary study to quantify and delve into the abstract reasoning abilities of existing LLMs. Our findings reveal a substantial discrepancy between their general reasoning and abstract reasoning performances. To relieve this problem, we tailor an abstract reasoning dataset (AbsR) together with a meaningful learning paradigm to teach LLMs how to leverage generic facts for reasoning purposes. The results show that our app",
    "link": "https://arxiv.org/abs/2403.09085",
    "context": "Title: Meaningful Learning: Advancing Abstract Reasoning in Large Language Models via Generic Fact Guidance\nAbstract: arXiv:2403.09085v1 Announce Type: cross  Abstract: Large language models (LLMs) have developed impressive performance and strong explainability across various reasoning scenarios, marking a significant stride towards mimicking human-like intelligence. Despite this, when tasked with simple questions supported by a generic fact, LLMs often fail to provide consistent and precise answers, indicating a deficiency in abstract reasoning abilities. This has sparked a vigorous debate about whether LLMs are genuinely reasoning or merely memorizing. In light of this, we design a preliminary study to quantify and delve into the abstract reasoning abilities of existing LLMs. Our findings reveal a substantial discrepancy between their general reasoning and abstract reasoning performances. To relieve this problem, we tailor an abstract reasoning dataset (AbsR) together with a meaningful learning paradigm to teach LLMs how to leverage generic facts for reasoning purposes. The results show that our app",
    "path": "papers/24/03/2403.09085.json",
    "total_tokens": 888,
    "translated_title": "有意义学习：通过通用事实引导推进大型语言模型的抽象推理",
    "translated_abstract": "大型语言模型（LLMs）在各种推理场景中取得了令人印象深刻的性能和强大的可解释性，标志着朝着模拟人类智能迈出了重要的一步。然而，当面对由通用事实支持的简单问题时，LLMs经常未能提供一致和准确的答案，表明其存在抽象推理能力的不足。这引发了关于LLMs到底是在真正推理还是仅仅在记忆的激烈争论。鉴此，我们设计了一个初步研究来量化并深入探讨现有LLMs的抽象推理能力。我们的研究发现显示出它们的一般推理和抽象推理表现之间存在实质性差异。为了缓解这一问题，我们为大型语言模型定制了一个抽象推理数据集（AbsR），结合有意义的学习范式，教会LLMs如何利用通用事实进行推理。结果表明我们的方法能够显着改善LLMs在抽象推理中的表现。",
    "tldr": "设计了一个抽象推理数据集和有意义学习范式，教导大型语言模型如何利用通用事实进行推理，有效提升了抽象推理能力。"
}