{
    "title": "Mechanics of Next Token Prediction with Self-Attention",
    "abstract": "arXiv:2403.08081v1 Announce Type: cross  Abstract: Transformer-based language models are trained on large datasets to predict the next token given an input sequence. Despite this simple training objective, they have led to revolutionary advances in natural language processing. Underlying this success is the self-attention mechanism. In this work, we ask: $\\textit{What}$ $\\textit{does}$ $\\textit{a}$ $\\textit{single}$ $\\textit{self-attention}$ $\\textit{layer}$ $\\textit{learn}$ $\\textit{from}$ $\\textit{next-token}$ $\\textit{prediction?}$ We show that training self-attention with gradient descent learns an automaton which generates the next token in two distinct steps: $\\textbf{(1)}$ $\\textbf{Hard}$ $\\textbf{retrieval:}$ Given input sequence, self-attention precisely selects the $\\textit{high-priority}$ $\\textit{input}$ $\\textit{tokens}$ associated with the last input token. $\\textbf{(2)}$ $\\textbf{Soft}$ $\\textbf{composition:}$ It then creates a convex combination of the high-priority tok",
    "link": "https://arxiv.org/abs/2403.08081",
    "context": "Title: Mechanics of Next Token Prediction with Self-Attention\nAbstract: arXiv:2403.08081v1 Announce Type: cross  Abstract: Transformer-based language models are trained on large datasets to predict the next token given an input sequence. Despite this simple training objective, they have led to revolutionary advances in natural language processing. Underlying this success is the self-attention mechanism. In this work, we ask: $\\textit{What}$ $\\textit{does}$ $\\textit{a}$ $\\textit{single}$ $\\textit{self-attention}$ $\\textit{layer}$ $\\textit{learn}$ $\\textit{from}$ $\\textit{next-token}$ $\\textit{prediction?}$ We show that training self-attention with gradient descent learns an automaton which generates the next token in two distinct steps: $\\textbf{(1)}$ $\\textbf{Hard}$ $\\textbf{retrieval:}$ Given input sequence, self-attention precisely selects the $\\textit{high-priority}$ $\\textit{input}$ $\\textit{tokens}$ associated with the last input token. $\\textbf{(2)}$ $\\textbf{Soft}$ $\\textbf{composition:}$ It then creates a convex combination of the high-priority tok",
    "path": "papers/24/03/2403.08081.json",
    "total_tokens": 846,
    "translated_title": "具有自注意力机制的下一个标记预测的力学",
    "translated_abstract": "基于Transformer的语言模型在大型数据集上训练，以预测给定输入序列的下一个标记。尽管训练目标简单，但它们已经在自然语言处理领域取得了革命性进展。这一成功的基础是自注意力机制。在这项研究中，我们提出了一个问题：一个单独的自注意力层从下一个标记预测中学到了什么？我们展示：通过梯度下降训练自注意力学习到一个自动机，该自动机通过两个不同的步骤生成下一个标记：(1) 硬检索：在给定输入序列的情况下，自注意力精确选择与上一个输入标记相关的高优先级输入标记。(2) 软组合：然后，它创建高优先级标记的凸组合。",
    "tldr": "通过梯度下降训练自注意力学习到一个自动机，在下一个标记预测中生成标记的两个不同步骤是：硬检索和软组合。",
    "en_tdlr": "Training self-attention with gradient descent learns an automaton which generates the next token in two distinct steps: Hard retrieval and Soft composition."
}