{
    "title": "Soften to Defend: Towards Adversarial Robustness via Self-Guided Label Refinement",
    "abstract": "arXiv:2403.09101v1 Announce Type: new  Abstract: Adversarial training (AT) is currently one of the most effective ways to obtain the robustness of deep neural networks against adversarial attacks. However, most AT methods suffer from robust overfitting, i.e., a significant generalization gap in adversarial robustness between the training and testing curves. In this paper, we first identify a connection between robust overfitting and the excessive memorization of noisy labels in AT from a view of gradient norm. As such label noise is mainly caused by a distribution mismatch and improper label assignments, we are motivated to propose a label refinement approach for AT. Specifically, our Self-Guided Label Refinement first self-refines a more accurate and informative label distribution from over-confident hard labels, and then it calibrates the training by dynamically incorporating knowledge from self-distilled models into the current model and thus requiring no external teachers. Empirica",
    "link": "https://arxiv.org/abs/2403.09101",
    "context": "Title: Soften to Defend: Towards Adversarial Robustness via Self-Guided Label Refinement\nAbstract: arXiv:2403.09101v1 Announce Type: new  Abstract: Adversarial training (AT) is currently one of the most effective ways to obtain the robustness of deep neural networks against adversarial attacks. However, most AT methods suffer from robust overfitting, i.e., a significant generalization gap in adversarial robustness between the training and testing curves. In this paper, we first identify a connection between robust overfitting and the excessive memorization of noisy labels in AT from a view of gradient norm. As such label noise is mainly caused by a distribution mismatch and improper label assignments, we are motivated to propose a label refinement approach for AT. Specifically, our Self-Guided Label Refinement first self-refines a more accurate and informative label distribution from over-confident hard labels, and then it calibrates the training by dynamically incorporating knowledge from self-distilled models into the current model and thus requiring no external teachers. Empirica",
    "path": "papers/24/03/2403.09101.json",
    "total_tokens": 922,
    "translated_title": "软化以保卫：通过自导标签细化实现对抗鲁棒性",
    "translated_abstract": "对抗训练（AT）目前是获得深度神经网络对抗攻击鲁棒性的最有效方法之一。然而，大多数AT方法遭受鲁棒过拟合，即在训练和测试曲线之间存在显著的对抗鲁棒性泛化差距。本文首次从梯度范数的角度识别了鲁棒过拟合与AT中嘈杂标签过度记忆之间的联系。鉴于此类标签噪声主要是由分布不匹配和不恰当的标签分配导致的，我们提出了一种用于AT的标签细化方法。具体来说，我们的自导标签细化首先从过于自信的硬标签中自我细化出更准确和信息丰富的标签分布，然后通过动态将自我蒸馏模型的知识纳入当前模型从而无需外部教师来校准训练。",
    "tldr": "本文提出了一种自导标签细化方法，通过在对抗训练中自我细化更准确和信息丰富的标签分布，并动态将自我蒸馏模型的知识纳入当前模型来消除对抗鲁棒性的过拟合问题。",
    "en_tdlr": "This paper proposes a self-guided label refinement approach that refines a more accurate and informative label distribution from over-confident hard labels in adversarial training, and dynamically incorporates knowledge from self-distilled models into the current model to eliminate robust overfitting in adversarial robustness."
}