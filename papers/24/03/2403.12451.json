{
    "title": "INSIGHT: End-to-End Neuro-Symbolic Visual Reinforcement Learning with Language Explanations",
    "abstract": "arXiv:2403.12451v1 Announce Type: new  Abstract: Neuro-symbolic reinforcement learning (NS-RL) has emerged as a promising paradigm for explainable decision-making, characterized by the interpretability of symbolic policies. For tasks with visual observations, NS-RL entails structured representations for states, but previous algorithms are unable to refine the structured states with reward signals due to a lack of efficiency. Accessibility is also an issue, as extensive domain knowledge is required to interpret current symbolic policies. In this paper, we present a framework that is capable of learning structured states and symbolic policies simultaneously, whose key idea is to overcome the efficiency bottleneck by distilling vision foundation models into a scalable perception module. Moreover, we design a pipeline that uses large language models to generate concise and readable language explanations for policies and decisions. In experiments on nine Atari tasks, our approach demonstrat",
    "link": "https://arxiv.org/abs/2403.12451",
    "context": "Title: INSIGHT: End-to-End Neuro-Symbolic Visual Reinforcement Learning with Language Explanations\nAbstract: arXiv:2403.12451v1 Announce Type: new  Abstract: Neuro-symbolic reinforcement learning (NS-RL) has emerged as a promising paradigm for explainable decision-making, characterized by the interpretability of symbolic policies. For tasks with visual observations, NS-RL entails structured representations for states, but previous algorithms are unable to refine the structured states with reward signals due to a lack of efficiency. Accessibility is also an issue, as extensive domain knowledge is required to interpret current symbolic policies. In this paper, we present a framework that is capable of learning structured states and symbolic policies simultaneously, whose key idea is to overcome the efficiency bottleneck by distilling vision foundation models into a scalable perception module. Moreover, we design a pipeline that uses large language models to generate concise and readable language explanations for policies and decisions. In experiments on nine Atari tasks, our approach demonstrat",
    "path": "papers/24/03/2403.12451.json",
    "total_tokens": 882,
    "translated_title": "INSIGHT: 带有语言解释的端到端神经符号视觉强化学习",
    "translated_abstract": "神经符号强化学习（NS-RL）已成为可解释决策制定的有希望的范式，其特点是符号策略的可解释性。对于具有视觉观测的任务，NS-RL涉及对状态进行结构化表示，但由于缺乏效率，先前的算法无法利用奖励信号来细化结构化状态。可访问性也是一个问题，因为需要广泛的领域知识来解释当前的符号策略。在本文中，我们提出了一个能够同时学习结构化状态和符号策略的框架，其关键思想是通过将视觉基础模型提炼成可扩展的感知模块，克服效率瓶颈。此外，我们设计了一个流水线，利用大的语言模型为政策和决策生成简洁易读的语言解释。在九个Atari任务的实验中，我们的方法表现出...",
    "tldr": "本文提出了一种可以同时学习结构化状态和符号策略的框架，通过将视觉基础模型提炼成可扩展的感知模块来克服效率瓶颈，并利用大的语言模型生成简洁易读的语言解释。"
}