{
    "title": "LLMCRIT: Teaching Large Language Models to Use Criteria",
    "abstract": "arXiv:2403.01069v1 Announce Type: new  Abstract: Humans follow criteria when they execute tasks, and these criteria are directly used to assess the quality of task completion. Therefore, having models learn to use criteria to provide feedback can help humans or models to perform tasks better. However, existing research in this field tends to consider only a limited set of criteria or quality assessment aspects. To fill this gap, we propose a general framework that enables large language models (LLMs) to use comprehensive criteria for a task in delivering natural language feedback on task execution. In particular, we present a model-in-the-loop framework that semi-automatically derives criteria from collected guidelines for different writing tasks and constructs in-context demonstrations for each criterion. We choose three tasks from real-world scenarios to operationalize this idea: paper introduction writing, Python code writing, and Reddit post writing, and evaluate our feedback gener",
    "link": "https://arxiv.org/abs/2403.01069",
    "context": "Title: LLMCRIT: Teaching Large Language Models to Use Criteria\nAbstract: arXiv:2403.01069v1 Announce Type: new  Abstract: Humans follow criteria when they execute tasks, and these criteria are directly used to assess the quality of task completion. Therefore, having models learn to use criteria to provide feedback can help humans or models to perform tasks better. However, existing research in this field tends to consider only a limited set of criteria or quality assessment aspects. To fill this gap, we propose a general framework that enables large language models (LLMs) to use comprehensive criteria for a task in delivering natural language feedback on task execution. In particular, we present a model-in-the-loop framework that semi-automatically derives criteria from collected guidelines for different writing tasks and constructs in-context demonstrations for each criterion. We choose three tasks from real-world scenarios to operationalize this idea: paper introduction writing, Python code writing, and Reddit post writing, and evaluate our feedback gener",
    "path": "papers/24/03/2403.01069.json",
    "total_tokens": 826,
    "translated_title": "LLMCRIT:教授大型语言模型使用标准",
    "translated_abstract": "人类在执行任务时遵循标准，这些标准直接用于评估任务完成的质量。因此，使模型学习使用标准提供反馈可以帮助人类或模型更好地执行任务。然而，现有研究往往只考虑有限的标准或质量评估方面。为了填补这一空白，我们提出了一个通用框架，使大型语言模型（LLMs）能够在完成任务时使用全面的标准提供自然语言反馈。具体来说，我们提出了一个模型-环路框架，从收集的不同写作任务指南中半自动地提取标准，并为每个标准构建上下文演示。我们选择了来自现实场景的三个任务来实现这一想法：论文引言写作、Python代码编写和Reddit帖子撰写，并评估我们的反馈生成。",
    "tldr": "提出了一个通用框架，使大型语言模型能够使用全面标准为任务提供自然语言反馈，并在论文引言写作、Python代码编写和Reddit帖子撰写等任务中进行了实证评估。"
}