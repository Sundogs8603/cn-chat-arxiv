{
    "title": "Demystifying Deep Reinforcement Learning-Based Autonomous Vehicle Decision-Making",
    "abstract": "arXiv:2403.11432v1 Announce Type: cross  Abstract: With the advent of universal function approximators in the domain of reinforcement learning, the number of practical applications leveraging deep reinforcement learning (DRL) has exploded. Decision-making in automated driving tasks has emerged as a chief application among them, taking the sensor data or the higher-order kinematic variables as the input and providing a discrete choice or continuous control output. However, the black-box nature of the models presents an overwhelming limitation that restricts the real-world deployment of DRL in autonomous vehicles (AVs). Therefore, in this research work, we focus on the interpretability of an attention-based DRL framework. We use a continuous proximal policy optimization-based DRL algorithm as the baseline model and add a multi-head attention framework in an open-source AV simulation environment. We provide some analytical techniques for discussing the interpretability of the trained mode",
    "link": "https://arxiv.org/abs/2403.11432",
    "context": "Title: Demystifying Deep Reinforcement Learning-Based Autonomous Vehicle Decision-Making\nAbstract: arXiv:2403.11432v1 Announce Type: cross  Abstract: With the advent of universal function approximators in the domain of reinforcement learning, the number of practical applications leveraging deep reinforcement learning (DRL) has exploded. Decision-making in automated driving tasks has emerged as a chief application among them, taking the sensor data or the higher-order kinematic variables as the input and providing a discrete choice or continuous control output. However, the black-box nature of the models presents an overwhelming limitation that restricts the real-world deployment of DRL in autonomous vehicles (AVs). Therefore, in this research work, we focus on the interpretability of an attention-based DRL framework. We use a continuous proximal policy optimization-based DRL algorithm as the baseline model and add a multi-head attention framework in an open-source AV simulation environment. We provide some analytical techniques for discussing the interpretability of the trained mode",
    "path": "papers/24/03/2403.11432.json",
    "total_tokens": 834,
    "translated_title": "深度强化学习驱动的自主车辆决策的揭秘",
    "translated_abstract": "随着强化学习领域中通用函数逼近器的出现，利用深度强化学习（DRL）的实际应用数量激增。自动驾驶任务中的决策制定已成为其中一项主要应用，将传感器数据或高阶运动学变量作为输入，并提供离散选择或连续控制输出。然而，模型的黑盒特性限制了DRL在自主车辆中的实际部署。因此，在这项研究工作中，我们关注基于注意力的DRL框架的可解释性。我们在开源AV仿真环境中使用了基于连续近端策略优化的DRL算法作为基线模型，并添加了一个多头注意力框架。我们提供了一些分析技术来讨论训练模型的可解释性。",
    "tldr": "本研究致力于研究基于注意力的DRL框架的可解释性，在自主车辆决策中，通过在开源AV仿真环境中添加多头注意力框架，提高了模型的解释性。",
    "en_tdlr": "This research focuses on the interpretability of an attention-based DRL framework in autonomous vehicle decision-making, enhancing the interpretability of the model by adding a multi-head attention framework in an open-source AV simulation environment."
}