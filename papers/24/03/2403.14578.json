{
    "title": "RAmBLA: A Framework for Evaluating the Reliability of LLMs as Assistants in the Biomedical Domain",
    "abstract": "arXiv:2403.14578v1 Announce Type: new  Abstract: Large Language Models (LLMs) increasingly support applications in a wide range of domains, some with potential high societal impact such as biomedicine, yet their reliability in realistic use cases is under-researched. In this work we introduce the Reliability AssesMent for Biomedical LLM Assistants (RAmBLA) framework and evaluate whether four state-of-the-art foundation LLMs can serve as reliable assistants in the biomedical domain. We identify prompt robustness, high recall, and a lack of hallucinations as necessary criteria for this use case. We design shortform tasks and tasks requiring LLM freeform responses mimicking real-world user interactions. We evaluate LLM performance using semantic similarity with a ground truth response, through an evaluator LLM.",
    "link": "https://arxiv.org/abs/2403.14578",
    "context": "Title: RAmBLA: A Framework for Evaluating the Reliability of LLMs as Assistants in the Biomedical Domain\nAbstract: arXiv:2403.14578v1 Announce Type: new  Abstract: Large Language Models (LLMs) increasingly support applications in a wide range of domains, some with potential high societal impact such as biomedicine, yet their reliability in realistic use cases is under-researched. In this work we introduce the Reliability AssesMent for Biomedical LLM Assistants (RAmBLA) framework and evaluate whether four state-of-the-art foundation LLMs can serve as reliable assistants in the biomedical domain. We identify prompt robustness, high recall, and a lack of hallucinations as necessary criteria for this use case. We design shortform tasks and tasks requiring LLM freeform responses mimicking real-world user interactions. We evaluate LLM performance using semantic similarity with a ground truth response, through an evaluator LLM.",
    "path": "papers/24/03/2403.14578.json",
    "total_tokens": 877,
    "translated_title": "RAmBLA：评估LLMs在生物医学领域中作为助手的可靠性的框架",
    "translated_abstract": "大型语言模型(LLMs)越来越多地支持各种领域的应用，其中一些潜在影响社会的领域，如生物医学，然而它们在现实用例中的可靠性尚未得到充分研究。在这项工作中，我们引入了用于评估生物医学LLM助手可靠性的RAmBLA框架，并评估四个最先进的基础LLMs是否可以作为生物医学领域的可靠助手。我们确定提示的健壮性、高召回率和缺乏幻觉是这种用例的必要标准。我们设计了模拟真实用户交互的短表单任务和需要LLM自由形式回答的任务。我们使用一个评估者LLM通过与真实响应的语义相似性来评估LLM的性能。",
    "tldr": "该研究引入了RAmBLA框架，评估四个最先进的基础LLMs在生物医学领域是否可以作为可靠助手，在任务设计和性能评估中强调了提示的健壮性、高召回率和缺乏幻觉的重要性。",
    "en_tdlr": "The study introduces the RAmBLA framework and evaluates whether four state-of-the-art foundation LLMs can serve as reliable assistants in the biomedical domain, emphasizing the importance of prompt robustness, high recall, and a lack of hallucinations in task design and performance evaluation."
}