{
    "title": "Scene-LLM: Extending Language Model for 3D Visual Understanding and Reasoning",
    "abstract": "arXiv:2403.11401v1 Announce Type: cross  Abstract: This paper introduces Scene-LLM, a 3D-visual-language model that enhances embodied agents' abilities in interactive 3D indoor environments by integrating the reasoning strengths of Large Language Models (LLMs). Scene-LLM adopts a hybrid 3D visual feature representation, that incorporates dense spatial information and supports scene state updates. The model employs a projection layer to efficiently project these features in the pre-trained textual embedding space, enabling effective interpretation of 3D visual information. Unique to our approach is the integration of both scene-level and ego-centric 3D information. This combination is pivotal for interactive planning, where scene-level data supports global planning and ego-centric data is important for localization. Notably, we use ego-centric 3D frame features for feature alignment, an efficient technique that enhances the model's ability to align features of small objects within the s",
    "link": "https://arxiv.org/abs/2403.11401",
    "context": "Title: Scene-LLM: Extending Language Model for 3D Visual Understanding and Reasoning\nAbstract: arXiv:2403.11401v1 Announce Type: cross  Abstract: This paper introduces Scene-LLM, a 3D-visual-language model that enhances embodied agents' abilities in interactive 3D indoor environments by integrating the reasoning strengths of Large Language Models (LLMs). Scene-LLM adopts a hybrid 3D visual feature representation, that incorporates dense spatial information and supports scene state updates. The model employs a projection layer to efficiently project these features in the pre-trained textual embedding space, enabling effective interpretation of 3D visual information. Unique to our approach is the integration of both scene-level and ego-centric 3D information. This combination is pivotal for interactive planning, where scene-level data supports global planning and ego-centric data is important for localization. Notably, we use ego-centric 3D frame features for feature alignment, an efficient technique that enhances the model's ability to align features of small objects within the s",
    "path": "papers/24/03/2403.11401.json",
    "total_tokens": 882,
    "translated_title": "Scene-LLM：扩展用于3D视觉理解和推理的语言模型",
    "translated_abstract": "本文介绍了Scene-LLM，这是一种3D视觉语言模型，通过整合大型语言模型（LLMs）的推理优势，增强了在交互式3D室内环境中具身体存在的代理者能力。Scene-LLM采用了混合的3D视觉特征表示，包括了密集的空间信息，并支持场景状态的更新。该模型使用投影层将这些特征高效地投影到预训练的文本嵌入空间中，从而有效解释3D视觉信息。我们方法的独特之处在于整合了场景级和以自我为中心的3D信息。这种组合对于交互式规划至关重要，其中场景级数据支持全局规划，以自我为中心的数据对于定位至关重要。值得注意的是，我们使用以自我为中心的3D帧特征进行特征对齐，这是一种增强模型对小物体特征对齐能力的有效技术。",
    "tldr": "本文介绍了Scene-LLM，一种3D视觉语言模型，通过整合大型语言模型（LLMs）的推理优势，增强了在交互式3D室内环境中具身体存在的代理者能力。"
}