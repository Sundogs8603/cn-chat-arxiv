{
    "title": "SPEAR:Exact Gradient Inversion of Batches in Federated Learning",
    "abstract": "arXiv:2403.03945v1 Announce Type: new  Abstract: Federated learning is a popular framework for collaborative machine learning where multiple clients only share gradient updates on their local data with the server and not the actual data. Unfortunately, it was recently shown that gradient inversion attacks can reconstruct this data from these shared gradients. Existing attacks enable exact reconstruction only for a batch size of $b=1$ in the important honest-but-curious setting, with larger batches permitting only approximate reconstruction. In this work, we propose \\emph{the first algorithm reconstructing whole batches with $b >1$ exactly}. This approach combines mathematical insights into the explicit low-rank structure of gradients with a sampling-based algorithm. Crucially, we leverage ReLU-induced gradient sparsity to precisely filter out large numbers of incorrect samples, making a final reconstruction step tractable. We provide an efficient GPU implementation for fully connected ",
    "link": "https://arxiv.org/abs/2403.03945",
    "context": "Title: SPEAR:Exact Gradient Inversion of Batches in Federated Learning\nAbstract: arXiv:2403.03945v1 Announce Type: new  Abstract: Federated learning is a popular framework for collaborative machine learning where multiple clients only share gradient updates on their local data with the server and not the actual data. Unfortunately, it was recently shown that gradient inversion attacks can reconstruct this data from these shared gradients. Existing attacks enable exact reconstruction only for a batch size of $b=1$ in the important honest-but-curious setting, with larger batches permitting only approximate reconstruction. In this work, we propose \\emph{the first algorithm reconstructing whole batches with $b >1$ exactly}. This approach combines mathematical insights into the explicit low-rank structure of gradients with a sampling-based algorithm. Crucially, we leverage ReLU-induced gradient sparsity to precisely filter out large numbers of incorrect samples, making a final reconstruction step tractable. We provide an efficient GPU implementation for fully connected ",
    "path": "papers/24/03/2403.03945.json",
    "total_tokens": 836,
    "translated_title": "SPEAR：联邦学习中批量精确梯度反演",
    "translated_abstract": "联邦学习是一种流行的协作机器学习框架，在这个框架中，多个客户端仅与服务器共享他们本地数据的梯度更新，而不是实际数据。不幸的是，最近发现梯度反演攻击可以从这些共享的梯度中重构出数据。现有的攻击只能在重要的诚实但好奇设置中对批量大小为$b=1$的数据进行精确重构，对于更大的批量只能进行近似重构。在这项工作中，我们提出了\\emph{第一个准确重建批量$b >1$的算法}。这种方法结合了对梯度显式低秩结构的数学见解和基于采样的算法。关键的是，我们利用ReLU诱导的梯度稀疏性，精确地过滤掉大量错误的样本，使最终的重建步骤可行。我们为全连接提供了高效的GPU实现",
    "tldr": "该论文提出了第一个能够精确重构批量$b >1$的算法，在联邦学习中解决了梯度反演攻击的问题。",
    "en_tdlr": "The paper proposes the first algorithm that can reconstruct whole batches with $b >1$ exactly, addressing the issue of gradient inversion attacks in federated learning."
}