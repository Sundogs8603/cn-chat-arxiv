{
    "title": "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
    "abstract": "arXiv:2403.03599v1 Announce Type: new  Abstract: Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (CIT) mechanism (Code available at https://github.com/BUPT-GAMMA/CITGNN), which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving th",
    "link": "https://arxiv.org/abs/2403.03599",
    "context": "Title: Learning Invariant Representations of Graph Neural Networks via Cluster Generalization\nAbstract: arXiv:2403.03599v1 Announce Type: new  Abstract: Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (CIT) mechanism (Code available at https://github.com/BUPT-GAMMA/CITGNN), which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving th",
    "path": "papers/24/03/2403.03599.json",
    "total_tokens": 827,
    "translated_title": "通过集群泛化学习图神经网络的不变表示",
    "translated_abstract": "图神经网络(GNNs)在建模图结构数据中变得越来越流行，因为它们能够通过聚合局部结构信息来学习节点表示。然而，人们普遍认为测试图的结构可能不同于训练图的结构，导致了结构转移。在本文中，我们实验性地发现，当结构转移发生时，GNNs的性能显著下降，这表明学习的模型可能偏向于特定的结构模式。为了解决这一挑战，我们提出了Cluster Information Transfer (CIT) 机制（代码可在https://github.com/BUPT-GAMMA/CITGNN找到），该机制可以为GNNs学习不变表示，从而提高它们对具有结构转移的各种未知测试图的泛化能力。CIT 机制通过将不同的集群信息与节点结合在一起，同时保留了节点之间的关系。",
    "tldr": "该论文提出了一种Cluster Information Transfer (CIT) 机制，可以为图神经网络学习不变表示，从而提高对具有结构转移的各种未知测试图的泛化能力。",
    "en_tdlr": "The paper introduces a Cluster Information Transfer (CIT) mechanism that can learn invariant representations for Graph Neural Networks, thereby improving their generalization ability to various and unknown test graphs with structure shift."
}