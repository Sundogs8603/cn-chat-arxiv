{
    "title": "Ask Your Distribution Shift if Pre-Training is Right for You",
    "abstract": "arXiv:2403.00194v1 Announce Type: new  Abstract: Pre-training is a widely used approach to develop models that are robust to distribution shifts. However, in practice, its effectiveness varies: fine-tuning a pre-trained model improves robustness significantly in some cases but not at all in others (compared to training from scratch). In this work, we seek to characterize the failure modes that pre-training can and cannot address. In particular, we focus on two possible failure modes of models under distribution shift: poor extrapolation (e.g., they cannot generalize to a different domain) and biases in the training data (e.g., they rely on spurious features). Our study suggests that, as a rule of thumb, pre-training can help mitigate poor extrapolation but not dataset biases. After providing theoretical motivation and empirical evidence for this finding, we explore two of its implications for developing robust models: (1) pre-training and interventions designed to prevent exploiting bi",
    "link": "https://arxiv.org/abs/2403.00194",
    "context": "Title: Ask Your Distribution Shift if Pre-Training is Right for You\nAbstract: arXiv:2403.00194v1 Announce Type: new  Abstract: Pre-training is a widely used approach to develop models that are robust to distribution shifts. However, in practice, its effectiveness varies: fine-tuning a pre-trained model improves robustness significantly in some cases but not at all in others (compared to training from scratch). In this work, we seek to characterize the failure modes that pre-training can and cannot address. In particular, we focus on two possible failure modes of models under distribution shift: poor extrapolation (e.g., they cannot generalize to a different domain) and biases in the training data (e.g., they rely on spurious features). Our study suggests that, as a rule of thumb, pre-training can help mitigate poor extrapolation but not dataset biases. After providing theoretical motivation and empirical evidence for this finding, we explore two of its implications for developing robust models: (1) pre-training and interventions designed to prevent exploiting bi",
    "path": "papers/24/03/2403.00194.json",
    "total_tokens": 857,
    "translated_title": "询问您的分布转移是否适合进行预训练",
    "translated_abstract": "预训练是一种广泛使用的方法，用于开发对分布转移具有鲁棒性的模型。然而，在实践中，其有效性因情况而异：在某些情况下，微调预训练模型可以显著改善鲁棒性，但在其他情况下则完全不同（与从头开始训练相比）。在这项工作中，我们试图描述预训练可以和不能解决的失败模式。特别是，我们关注模型在分布转移下可能出现的两种失败模式：较差的外推（例如，它们无法推广到不同领域）和训练数据中的偏见（例如，它们依赖于虚假特征）。我们的研究表明，作为一个经验准则，预训练可以帮助缓解较差的外推，但不能缓解数据集偏见。在提供了这一发现的理论动机和实证证据后，我们探讨了开发鲁棒模型的两个潜在含义：（1）预训练和旨在防止利用偏见的干预措施。",
    "tldr": "预训练有助于缓解较差的外推，但对数据集偏见无济于事。",
    "en_tdlr": "Pre-training helps mitigate poor extrapolation but is ineffective against dataset biases."
}