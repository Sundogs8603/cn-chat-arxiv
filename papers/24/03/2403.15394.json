{
    "title": "\"Model Cards for Model Reporting\" in 2024: Reclassifying Category of Ethical Considerations in Terms of Trustworthiness and Risk Management",
    "abstract": "arXiv:2403.15394v1 Announce Type: cross  Abstract: In 2019, the paper entitled \"Model Cards for Model Reporting\" introduced a new tool for documenting model performance and encouraged the practice of transparent reporting for a defined list of categories. One of the categories detailed in that paper is ethical considerations, which includes the subcategories of data, human life, mitigations, risks and harms, and use cases. We propose to reclassify this category in the original model card due to the recent maturing of the field known as trustworthy AI, a term which analyzes whether the algorithmic properties of the model indicate that the AI system is deserving of trust from its stakeholders. In our examination of trustworthy AI, we highlight three respected organizations - the European Commission's High-Level Expert Group on AI, the OECD, and the U.S.-based NIST - that have written guidelines on various aspects of trustworthy AI. These recent publications converge on numerous character",
    "link": "https://arxiv.org/abs/2403.15394",
    "context": "Title: \"Model Cards for Model Reporting\" in 2024: Reclassifying Category of Ethical Considerations in Terms of Trustworthiness and Risk Management\nAbstract: arXiv:2403.15394v1 Announce Type: cross  Abstract: In 2019, the paper entitled \"Model Cards for Model Reporting\" introduced a new tool for documenting model performance and encouraged the practice of transparent reporting for a defined list of categories. One of the categories detailed in that paper is ethical considerations, which includes the subcategories of data, human life, mitigations, risks and harms, and use cases. We propose to reclassify this category in the original model card due to the recent maturing of the field known as trustworthy AI, a term which analyzes whether the algorithmic properties of the model indicate that the AI system is deserving of trust from its stakeholders. In our examination of trustworthy AI, we highlight three respected organizations - the European Commission's High-Level Expert Group on AI, the OECD, and the U.S.-based NIST - that have written guidelines on various aspects of trustworthy AI. These recent publications converge on numerous character",
    "path": "papers/24/03/2403.15394.json",
    "total_tokens": 910,
    "translated_title": "2024年《模型报告的模型卡》：以可信度和风险管理重新分类道德考虑的类别",
    "translated_abstract": "2019年，题为《模型报告的模型卡》的论文介绍了一种新的工具，用于记录模型性能，并鼓励透明报告练习，针对一系列明确定义的类别。该论文中详细介绍的一个类别是道德考虑，其中包括数据、人类生命、缓解措施、风险和危害以及用例等子类别。我们提议重新分类原始模型卡中的这一类别，这是因为最近成熟的领域称为可信度人工智能，该术语分析算法属性是否表明AI系统值得受到利益相关者的信任。在我们对可信度人工智能的研究中，我们强调了三个备受尊重的组织——欧盟委员会AI高级专家组、经济合作与发展组织和美国国家标准与技术研究所——他们就可信度人工智能的各个方面撰写了准则。这些最近的出版物汇聚了许多共同点。",
    "tldr": "将模型报告中的道德考虑类别重新分类为可信度和风险管理类别，针对可信度AI领域的最新发展提出了新的观点。",
    "en_tdlr": "Reclassifying the category of ethical considerations in model reporting as trustworthiness and risk management, proposing new insights based on recent advancements in the field of trustworthy AI."
}