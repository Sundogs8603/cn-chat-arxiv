{
    "title": "Restoring Ancient Ideograph: A Multimodal Multitask Neural Network Approach",
    "abstract": "arXiv:2403.06682v1 Announce Type: new  Abstract: Cultural heritage serves as the enduring record of human thought and history. Despite significant efforts dedicated to the preservation of cultural relics, many ancient artefacts have been ravaged irreversibly by natural deterioration and human actions. Deep learning technology has emerged as a valuable tool for restoring various kinds of cultural heritages, including ancient text restoration. Previous research has approached ancient text restoration from either visual or textual perspectives, often overlooking the potential of synergizing multimodal information. This paper proposes a novel Multimodal Multitask Restoring Model (MMRM) to restore ancient texts, particularly emphasising the ideograph. This model combines context understanding with residual visual information from damaged ancient artefacts, enabling it to predict damaged characters and generate restored images simultaneously. We tested the MMRM model through experiments cond",
    "link": "https://arxiv.org/abs/2403.06682",
    "context": "Title: Restoring Ancient Ideograph: A Multimodal Multitask Neural Network Approach\nAbstract: arXiv:2403.06682v1 Announce Type: new  Abstract: Cultural heritage serves as the enduring record of human thought and history. Despite significant efforts dedicated to the preservation of cultural relics, many ancient artefacts have been ravaged irreversibly by natural deterioration and human actions. Deep learning technology has emerged as a valuable tool for restoring various kinds of cultural heritages, including ancient text restoration. Previous research has approached ancient text restoration from either visual or textual perspectives, often overlooking the potential of synergizing multimodal information. This paper proposes a novel Multimodal Multitask Restoring Model (MMRM) to restore ancient texts, particularly emphasising the ideograph. This model combines context understanding with residual visual information from damaged ancient artefacts, enabling it to predict damaged characters and generate restored images simultaneously. We tested the MMRM model through experiments cond",
    "path": "papers/24/03/2403.06682.json",
    "total_tokens": 856,
    "translated_title": "恢复古代表意字符: 一种多模态多任务神经网络方法",
    "translated_abstract": "文化遗产作为人类思想和历史的永恒记录。尽管已经付出了大量努力来保护文化遗产，但许多古代文物已经被自然退化和人为行为不可逆地破坏。深度学习技术已经成为恢复各种文化遗产，包括古代文本恢复的有价值工具。以往的研究通常从视觉或文本角度探讨古代文本的恢复，往往忽视了多模态信息相互配合的潜力。本文提出了一种新颖的多模态多任务恢复模型（MMRM）来恢复古代文本，特别强调表意字符。该模型将从受损古代文物中的上下文理解与残留的视觉信息相结合，使其能够同时预测受损字符并生成恢复图像。我们通过实验测试了MMRM模型",
    "tldr": "提出一种多模态多任务恢复模型（MMRM）来恢复古代文本，特别强调表意字符，结合上下文理解和残留的视觉信息来预测受损字符并生成恢复图像。",
    "en_tdlr": "Introducing a novel Multimodal Multitask Restoring Model (MMRM) to restore ancient texts, particularly emphasizing ideographs, by combining context understanding and residual visual information to predict damaged characters and generate restored images."
}