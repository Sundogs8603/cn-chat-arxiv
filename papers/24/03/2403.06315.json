{
    "title": "A Study on Domain Generalization for Failure Detection through Human Reactions in HRI",
    "abstract": "arXiv:2403.06315v1 Announce Type: cross  Abstract: Machine learning models are commonly tested in-distribution (same dataset); performance almost always drops in out-of-distribution settings. For HRI research, the goal is often to develop generalized models. This makes domain generalization - retaining performance in different settings - a critical issue. In this study, we present a concise analysis of domain generalization in failure detection models trained on human facial expressions. Using two distinct datasets of humans reacting to videos where error occurs, one from a controlled lab setting and another collected online, we trained deep learning models on each dataset. When testing these models on the alternate dataset, we observed a significant performance drop. We reflect on the causes for the observed model behavior and leave recommendations. This work emphasizes the need for HRI research focusing on improving model robustness and real-life applicability.",
    "link": "https://arxiv.org/abs/2403.06315",
    "context": "Title: A Study on Domain Generalization for Failure Detection through Human Reactions in HRI\nAbstract: arXiv:2403.06315v1 Announce Type: cross  Abstract: Machine learning models are commonly tested in-distribution (same dataset); performance almost always drops in out-of-distribution settings. For HRI research, the goal is often to develop generalized models. This makes domain generalization - retaining performance in different settings - a critical issue. In this study, we present a concise analysis of domain generalization in failure detection models trained on human facial expressions. Using two distinct datasets of humans reacting to videos where error occurs, one from a controlled lab setting and another collected online, we trained deep learning models on each dataset. When testing these models on the alternate dataset, we observed a significant performance drop. We reflect on the causes for the observed model behavior and leave recommendations. This work emphasizes the need for HRI research focusing on improving model robustness and real-life applicability.",
    "path": "papers/24/03/2403.06315.json",
    "total_tokens": 927,
    "translated_title": "通过人类反应研究人机交互中的领域泛化用于故障检测",
    "translated_abstract": "机器学习模型通常在分布内（相同数据集）进行测试；性能几乎总是在分布外设置下降。对于HRI研究，目标往往是开发广义模型。这使得领域泛化 - 在不同设置中保持性能 - 成为一个关键问题。在这项研究中，我们对在人类面部表情上训练的故障检测模型中的领域泛化进行了简明分析。我们使用两个不同的数据集，包括一个来自受控实验室环境的数据集和另一个在线收集的数据集，这些数据集展示了人类对发生错误的视频作出的反应。我们在每个数据集上训练了深度学习模型。当在交替数据集上测试这些模型时，我们观察到了显著的性能下降。我们反思了观察到的模型行为的原因并提出建议。这项工作强调了HRI研究需要关注改进模型的稳健性和实际适用性的需求。",
    "tldr": "该研究通过分析使用人类面部表情训练的故障检测模型中的领域泛化，并发现在不同数据集上性能显著下降。对于HRI研究，这强调了改进模型稳健性和实际适用性的重要性。",
    "en_tdlr": "This study analyzes domain generalization in failure detection models trained on human facial expressions and finds a significant performance drop on different datasets. For HRI research, it emphasizes the importance of improving model robustness and real-life applicability."
}