{
    "title": "Evaluating the Explainability of Neural Rankers",
    "abstract": "arXiv:2403.01981v1 Announce Type: new  Abstract: Information retrieval models have witnessed a paradigm shift from unsupervised statistical approaches to feature-based supervised approaches to completely data-driven ones that make use of the pre-training of large language models. While the increasing complexity of the search models have been able to demonstrate improvements in effectiveness (measured in terms of relevance of top-retrieved results), a question worthy of a thorough inspection is - \"how explainable are these models?\", which is what this paper aims to evaluate. In particular, we propose a common evaluation platform to systematically evaluate the explainability of any ranking model (the explanation algorithm being identical for all the models that are to be evaluated). In our proposed framework, each model, in addition to returning a ranked list of documents, also requires to return a list of explanation units or rationales for each document. This meta-information from each",
    "link": "https://arxiv.org/abs/2403.01981",
    "context": "Title: Evaluating the Explainability of Neural Rankers\nAbstract: arXiv:2403.01981v1 Announce Type: new  Abstract: Information retrieval models have witnessed a paradigm shift from unsupervised statistical approaches to feature-based supervised approaches to completely data-driven ones that make use of the pre-training of large language models. While the increasing complexity of the search models have been able to demonstrate improvements in effectiveness (measured in terms of relevance of top-retrieved results), a question worthy of a thorough inspection is - \"how explainable are these models?\", which is what this paper aims to evaluate. In particular, we propose a common evaluation platform to systematically evaluate the explainability of any ranking model (the explanation algorithm being identical for all the models that are to be evaluated). In our proposed framework, each model, in addition to returning a ranked list of documents, also requires to return a list of explanation units or rationales for each document. This meta-information from each",
    "path": "papers/24/03/2403.01981.json",
    "total_tokens": 805,
    "translated_title": "评估神经排序器的可解释性",
    "translated_abstract": "信息检索模型已经经历了从无监督统计方法到基于特征的监督方法，再到完全数据驱动的利用大型语言模型预训练的范式转变。虽然搜索模型的增加复杂性已经能够展示在效果方面的改进（以检索结果的相关性为衡量标准），但一个值得彻底检查的问题是 - \"这些模型的可解释性有多高？\"，这就是本文的评估目标。具体而言，我们提出了一个共同的评估平台，系统地评估任何排序模型的可解释性（说明算法对于所有待评估模型都是相同的）。在我们提出的框架中，每个模型除了返回一个排名的文档列表之外，还需要返回每个文档的解释单元或解释理由的列表。",
    "tldr": "本文旨在评估神经排序器的可解释性，提出了一个共同的评估平台，要求每个模型除了返回排名的文档列表外，还需返回每个文档的解释单元或解释理由列表。",
    "en_tdlr": "This paper aims to evaluate the explainability of neural rankers by proposing a common evaluation platform that requires each model to return a list of explanation units or rationales for each document in addition to the ranked list of documents."
}