{
    "title": "Feature Alignment: Rethinking Efficient Active Learning via Proxy in the Context of Pre-trained Models",
    "abstract": "arXiv:2403.01101v1 Announce Type: cross  Abstract: Fine-tuning the pre-trained model with active learning holds promise for reducing annotation costs. However, this combination introduces significant computational costs, particularly with the growing scale of pre-trained models. Recent research has proposed proxy-based active learning, which pre-computes features to reduce computational costs. Yet, this approach often incurs a significant loss in active learning performance, which may even outweigh the computational cost savings. In this paper, we argue the performance drop stems not only from pre-computed features' inability to distinguish between categories of labeled samples, resulting in the selection of redundant samples but also from the tendency to compromise valuable pre-trained information when fine-tuning with samples selected through the proxy model. To address this issue, we propose a novel method called aligned selection via proxy to update pre-computed features while sele",
    "link": "https://arxiv.org/abs/2403.01101",
    "context": "Title: Feature Alignment: Rethinking Efficient Active Learning via Proxy in the Context of Pre-trained Models\nAbstract: arXiv:2403.01101v1 Announce Type: cross  Abstract: Fine-tuning the pre-trained model with active learning holds promise for reducing annotation costs. However, this combination introduces significant computational costs, particularly with the growing scale of pre-trained models. Recent research has proposed proxy-based active learning, which pre-computes features to reduce computational costs. Yet, this approach often incurs a significant loss in active learning performance, which may even outweigh the computational cost savings. In this paper, we argue the performance drop stems not only from pre-computed features' inability to distinguish between categories of labeled samples, resulting in the selection of redundant samples but also from the tendency to compromise valuable pre-trained information when fine-tuning with samples selected through the proxy model. To address this issue, we propose a novel method called aligned selection via proxy to update pre-computed features while sele",
    "path": "papers/24/03/2403.01101.json",
    "total_tokens": 711,
    "translated_title": "特征对齐：在预训练模型背景下通过代理思考高效主动学习",
    "translated_abstract": "使用主动学习对预训练模型进行微调有望降低注释成本。然而，这种组合引入了显著的计算成本，尤其是随着预训练模型规模的增长。最近的研究提出了基于代理的主动学习，它预先计算特征以减少计算成本。然而，这种方法通常会在主动学习性能上造成重大损失，甚至可能超过计算成本节约。",
    "tldr": "通过代理进行特征对齐，以解决预先计算特征无法区分标记样本类别和避免通过代理模型选择样本时牺牲宝贵预训练信息的问题。"
}