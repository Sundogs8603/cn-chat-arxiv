{
    "title": "WaterJudge: Quality-Detection Trade-off when Watermarking Large Language Models",
    "abstract": "arXiv:2403.19548v1 Announce Type: new  Abstract: Watermarking generative-AI systems, such as LLMs, has gained considerable interest, driven by their enhanced capabilities across a wide range of tasks. Although current approaches have demonstrated that small, context-dependent shifts in the word distributions can be used to apply and detect watermarks, there has been little work in analyzing the impact that these perturbations have on the quality of generated texts. Balancing high detectability with minimal performance degradation is crucial in terms of selecting the appropriate watermarking setting; therefore this paper proposes a simple analysis framework where comparative assessment, a flexible NLG evaluation framework, is used to assess the quality degradation caused by a particular watermark setting. We demonstrate that our framework provides easy visualization of the quality-detection trade-off of watermark settings, enabling a simple solution to find an LLM watermark operating po",
    "link": "https://arxiv.org/abs/2403.19548",
    "context": "Title: WaterJudge: Quality-Detection Trade-off when Watermarking Large Language Models\nAbstract: arXiv:2403.19548v1 Announce Type: new  Abstract: Watermarking generative-AI systems, such as LLMs, has gained considerable interest, driven by their enhanced capabilities across a wide range of tasks. Although current approaches have demonstrated that small, context-dependent shifts in the word distributions can be used to apply and detect watermarks, there has been little work in analyzing the impact that these perturbations have on the quality of generated texts. Balancing high detectability with minimal performance degradation is crucial in terms of selecting the appropriate watermarking setting; therefore this paper proposes a simple analysis framework where comparative assessment, a flexible NLG evaluation framework, is used to assess the quality degradation caused by a particular watermark setting. We demonstrate that our framework provides easy visualization of the quality-detection trade-off of watermark settings, enabling a simple solution to find an LLM watermark operating po",
    "path": "papers/24/03/2403.19548.json",
    "total_tokens": 832,
    "translated_title": "WaterJudge: 在给大型语言模型设置水印时质量检测的权衡问题",
    "translated_abstract": "给如LLMs这样的生成式AI系统设置水印已经引起了相当大的兴趣，这种兴趣是因为它们在广泛任务中的增强能力。尽管当前的方法已经证明，可以利用在词分布中的小的、上下文相关的变化来应用和检测水印，但对这些扰动对生成文本质量的影响还没有太多的研究。在选择适当的水印设置方面，平衡高可检测性和最小性能降级至关重要；因此，本文提出了一个简单的分析框架，其中使用比较评估、一个灵活的NLG评估框架，来评估特定水印设置造成的质量退化。我们展示了我们的框架可以轻松可视化水印设置的质量-检测权衡，从而为找到一个LLM水印操作点提供了一个简单的解决方案。",
    "tldr": "提出了一个简单的分析框架，利用比较评估和灵活的NLG评估框架来评估特定水印设置对生成文本质量造成的影响。"
}