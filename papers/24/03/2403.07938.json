{
    "title": "Text-to-Audio Generation Synchronized with Videos",
    "abstract": "arXiv:2403.07938v1 Announce Type: cross  Abstract: In recent times, the focus on text-to-audio (TTA) generation has intensified, as researchers strive to synthesize audio from textual descriptions. However, most existing methods, though leveraging latent diffusion models to learn the correlation between audio and text embeddings, fall short when it comes to maintaining a seamless synchronization between the produced audio and its video. This often results in discernible audio-visual mismatches. To bridge this gap, we introduce a groundbreaking benchmark for Text-to-Audio generation that aligns with Videos, named T2AV-Bench. This benchmark distinguishes itself with three novel metrics dedicated to evaluating visual alignment and temporal consistency. To complement this, we also present a simple yet effective video-aligned TTA generation model, namely T2AV. Moving beyond traditional methods, T2AV refines the latent diffusion approach by integrating visual-aligned text embeddings as its c",
    "link": "https://arxiv.org/abs/2403.07938",
    "context": "Title: Text-to-Audio Generation Synchronized with Videos\nAbstract: arXiv:2403.07938v1 Announce Type: cross  Abstract: In recent times, the focus on text-to-audio (TTA) generation has intensified, as researchers strive to synthesize audio from textual descriptions. However, most existing methods, though leveraging latent diffusion models to learn the correlation between audio and text embeddings, fall short when it comes to maintaining a seamless synchronization between the produced audio and its video. This often results in discernible audio-visual mismatches. To bridge this gap, we introduce a groundbreaking benchmark for Text-to-Audio generation that aligns with Videos, named T2AV-Bench. This benchmark distinguishes itself with three novel metrics dedicated to evaluating visual alignment and temporal consistency. To complement this, we also present a simple yet effective video-aligned TTA generation model, namely T2AV. Moving beyond traditional methods, T2AV refines the latent diffusion approach by integrating visual-aligned text embeddings as its c",
    "path": "papers/24/03/2403.07938.json",
    "total_tokens": 863,
    "translated_title": "文本到音频生成与视频同步",
    "translated_abstract": "最近，人们对文本到音频（TTA）生成的关注日益加强，研究人员努力从文本描述中合成音频。然而，大多数现有方法虽然利用潜在扩散模型来学习音频和文本嵌入之间的关系，但在保持生成的音频与其视频之间无缝同步方面表现不佳。这经常导致可察觉的音频-视觉不匹配。为填补这一空白，我们引入了一个与视频对齐的文本到音频生成的开创性基准，名为T2AV-Bench。该基准通过三个专门用于评估视觉对齐和时间一致性的新颖指标而脱颖而出。为了补充这一点，我们还提出了一个简单而有效的视频对齐TTA生成模型，即T2AV。超越传统方法，T2AV通过将视觉对齐文本嵌入集成为其c",
    "tldr": "介绍了一个新的与视频对齐的文本到音频生成基准T2AV-Bench，以及一种简单而有效的视频对齐TTA生成模型T2AV，改进了传统方法，并融合了视觉对齐文本嵌入。",
    "en_tdlr": "Introducing a new benchmark T2AV-Bench for text-to-audio generation synchronized with videos, along with a simple yet effective video-aligned TTA generation model T2AV that enhances traditional methods by integrating visual-aligned text embeddings."
}