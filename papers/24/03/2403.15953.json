{
    "title": "Understanding The Effectiveness of Lossy Compression in Machine Learning Training Sets",
    "abstract": "arXiv:2403.15953v1 Announce Type: cross  Abstract: Learning and Artificial Intelligence (ML/AI) techniques have become increasingly prevalent in high performance computing (HPC). However, these methods depend on vast volumes of floating point data for training and validation which need methods to share the data on a wide area network (WAN) or to transfer it from edge devices to data centers. Data compression can be a solution to these problems, but an in-depth understanding of how lossy compression affects model quality is needed. Prior work largely considers a single application or compression method. We designed a systematic methodology for evaluating data reduction techniques for ML/AI, and we use it to perform a very comprehensive evaluation with 17 data reduction methods on 7 ML/AI applications to show modern lossy compression methods can achieve a 50-100x compression ratio improvement for a 1% or less loss in quality. We identify critical insights that guide the future use and de",
    "link": "https://arxiv.org/abs/2403.15953",
    "context": "Title: Understanding The Effectiveness of Lossy Compression in Machine Learning Training Sets\nAbstract: arXiv:2403.15953v1 Announce Type: cross  Abstract: Learning and Artificial Intelligence (ML/AI) techniques have become increasingly prevalent in high performance computing (HPC). However, these methods depend on vast volumes of floating point data for training and validation which need methods to share the data on a wide area network (WAN) or to transfer it from edge devices to data centers. Data compression can be a solution to these problems, but an in-depth understanding of how lossy compression affects model quality is needed. Prior work largely considers a single application or compression method. We designed a systematic methodology for evaluating data reduction techniques for ML/AI, and we use it to perform a very comprehensive evaluation with 17 data reduction methods on 7 ML/AI applications to show modern lossy compression methods can achieve a 50-100x compression ratio improvement for a 1% or less loss in quality. We identify critical insights that guide the future use and de",
    "path": "papers/24/03/2403.15953.json",
    "total_tokens": 827,
    "translated_title": "了解损失压缩在机器学习训练集中的有效性",
    "translated_abstract": "学习和人工智能（ML/AI）技术在高性能计算（HPC）中变得日益普及。然而，这些方法依赖于大量的浮点数据用于训练和验证，需要方法在广域网络（WAN）上共享数据或将其从边缘设备传输到数据中心。数据压缩可以解决这些问题，但需要深入了解损失压缩如何影响模型质量。我们设计了评估ML/AI数据减少技术的系统方法，并使用它对17种数据减少方法在7个ML/AI应用程序上进行了非常全面的评估，表明现代的损失压缩方法可以实现50-100倍的压缩比改善，质量损失在1%以下。我们提出了关键见解，指导未来的使用和de",
    "tldr": "深入探究损失压缩对模型质量的影响，发现现代损失压缩方法可以在保证质量损失在1%以下的情况下实现50-100倍的压缩比提升。",
    "en_tdlr": "Investigating the impact of lossy compression on model quality, revealing that modern lossy compression methods can achieve a 50-100x compression ratio improvement while maintaining quality loss below 1%."
}