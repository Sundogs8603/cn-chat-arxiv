{
    "title": "FENICE: Factuality Evaluation of summarization based on Natural language Inference and Claim Extraction",
    "abstract": "arXiv:2403.02270v1 Announce Type: new  Abstract: Recent advancements in text summarization, particularly with the advent of Large Language Models (LLMs), have shown remarkable performance. However, a notable challenge persists as a substantial number of automatically-generated summaries exhibit factual inconsistencies, such as hallucinations. In response to this issue, various approaches for the evaluation of consistency for summarization have emerged. Yet, these newly-introduced metrics face several limitations, including lack of interpretability, focus on short document summaries (e.g., news articles), and computational impracticality, especially for LLM-based metrics. To address these shortcomings, we propose Factuality Evaluation of summarization based on Natural language Inference and Claim Extraction (FENICE), a more interpretable and efficient factuality-oriented metric. FENICE leverages an NLI-based alignment between information in the source document and a set of atomic facts,",
    "link": "https://arxiv.org/abs/2403.02270",
    "context": "Title: FENICE: Factuality Evaluation of summarization based on Natural language Inference and Claim Extraction\nAbstract: arXiv:2403.02270v1 Announce Type: new  Abstract: Recent advancements in text summarization, particularly with the advent of Large Language Models (LLMs), have shown remarkable performance. However, a notable challenge persists as a substantial number of automatically-generated summaries exhibit factual inconsistencies, such as hallucinations. In response to this issue, various approaches for the evaluation of consistency for summarization have emerged. Yet, these newly-introduced metrics face several limitations, including lack of interpretability, focus on short document summaries (e.g., news articles), and computational impracticality, especially for LLM-based metrics. To address these shortcomings, we propose Factuality Evaluation of summarization based on Natural language Inference and Claim Extraction (FENICE), a more interpretable and efficient factuality-oriented metric. FENICE leverages an NLI-based alignment between information in the source document and a set of atomic facts,",
    "path": "papers/24/03/2403.02270.json",
    "total_tokens": 825,
    "translated_title": "基于自然语言推理和主张提取的摘要可信度评估",
    "translated_abstract": "最近在文本摘要方面取得的进展，尤其是随着大型语言模型（LLMs）的出现，已经表现出显著的性能。然而，一个显著的挑战仍然存在，即大量自动生成的摘要呈现事实不一致，比如幻觉。针对这一问题，出现了各种用于评估摘要一致性的方法。然而，这些新引入的度量标准面临着一些限制，包括缺乏可解释性，专注于短文档摘要（例如新闻文章）以及计算上的不可行性，特别是对于基于LLM的度量标准。为了解决这些缺点，我们提出了基于自然语言推理和主张提取的摘要可信度评估（FENICE），这是一种更具解释性和有效性的可信度导向度量。",
    "tldr": "提出了一种基于自然语言推理和主张提取的摘要可信度评估指标 FENICE，解决了自动生成摘要中存在的事实不一致性问题。",
    "en_tdlr": "Introducing FENICE, a factuality evaluation metric for summarization based on natural language inference and claim extraction, addressing the issue of factual inconsistencies in automatically generated summaries."
}