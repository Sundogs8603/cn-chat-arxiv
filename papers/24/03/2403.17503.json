{
    "title": "DS-AL: A Dual-Stream Analytic Learning for Exemplar-Free Class-Incremental Learning",
    "abstract": "arXiv:2403.17503v1 Announce Type: new  Abstract: Class-incremental learning (CIL) under an exemplar-free constraint has presented a significant challenge. Existing methods adhering to this constraint are prone to catastrophic forgetting, far more so than replay-based techniques that retain access to past samples. In this paper, to solve the exemplar-free CIL problem, we propose a Dual-Stream Analytic Learning (DS-AL) approach. The DS-AL contains a main stream offering an analytical (i.e., closed-form) linear solution, and a compensation stream improving the inherent under-fitting limitation due to adopting linear mapping. The main stream redefines the CIL problem into a Concatenated Recursive Least Squares (C-RLS) task, allowing an equivalence between the CIL and its joint-learning counterpart. The compensation stream is governed by a Dual-Activation Compensation (DAC) module. This module re-activates the embedding with a different activation function from the main stream one, and seek",
    "link": "https://arxiv.org/abs/2403.17503",
    "context": "Title: DS-AL: A Dual-Stream Analytic Learning for Exemplar-Free Class-Incremental Learning\nAbstract: arXiv:2403.17503v1 Announce Type: new  Abstract: Class-incremental learning (CIL) under an exemplar-free constraint has presented a significant challenge. Existing methods adhering to this constraint are prone to catastrophic forgetting, far more so than replay-based techniques that retain access to past samples. In this paper, to solve the exemplar-free CIL problem, we propose a Dual-Stream Analytic Learning (DS-AL) approach. The DS-AL contains a main stream offering an analytical (i.e., closed-form) linear solution, and a compensation stream improving the inherent under-fitting limitation due to adopting linear mapping. The main stream redefines the CIL problem into a Concatenated Recursive Least Squares (C-RLS) task, allowing an equivalence between the CIL and its joint-learning counterpart. The compensation stream is governed by a Dual-Activation Compensation (DAC) module. This module re-activates the embedding with a different activation function from the main stream one, and seek",
    "path": "papers/24/03/2403.17503.json",
    "total_tokens": 870,
    "translated_title": "DS-AL：一种面向无样本类增量学习的双流分析学习",
    "translated_abstract": "在无样本约束条件下的类增量学习(CIL)提出了重大挑战。现有的遵循此约束条件的方法往往比保留对过去样本访问权的回放技术更容易出现灾难性遗忘。为了解决无样本CIL问题，本文提出了一种双流分析学习(DS-AL)方法。DS-AL包含一个主流提供分析（即闭式）线性解决方案，以及一个改善由于采用线性映射而固有的欠拟合限制的补偿流。主流将CIL问题重新定义为一个连接递归最小二乘(C-RLS)任务，从而实现了CIL及其联合学习对应任务之间的等价性。补偿流由双激活补偿(DAC)模块控制。该模块使用不同于主流的激活函数重新激活嵌入，并寻找...",
    "tldr": "DS-AL提出了一种双流分析学习方法，通过主流和补偿流相结合，重新定义CIL问题，有效解决了无样本约束条件下的类增量学习问题。"
}