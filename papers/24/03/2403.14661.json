{
    "title": "Towards Modeling Learner Performance with Large Language Models",
    "abstract": "arXiv:2403.14661v1 Announce Type: cross  Abstract: Recent work exploring the capabilities of pre-trained large language models (LLMs) has demonstrated their ability to act as general pattern machines by completing complex token sequences representing a wide array of tasks, including time-series prediction and robot control. This paper investigates whether the pattern recognition and sequence modeling capabilities of LLMs can be extended to the domain of knowledge tracing, a critical component in the development of intelligent tutoring systems (ITSs) that tailor educational experiences by predicting learner performance over time. In an empirical evaluation across multiple real-world datasets, we compare two approaches to using LLMs for this task, zero-shot prompting and model fine-tuning, with existing, non-LLM approaches to knowledge tracing. While LLM-based approaches do not achieve state-of-the-art performance, fine-tuned LLMs surpass the performance of naive baseline models and perf",
    "link": "https://arxiv.org/abs/2403.14661",
    "context": "Title: Towards Modeling Learner Performance with Large Language Models\nAbstract: arXiv:2403.14661v1 Announce Type: cross  Abstract: Recent work exploring the capabilities of pre-trained large language models (LLMs) has demonstrated their ability to act as general pattern machines by completing complex token sequences representing a wide array of tasks, including time-series prediction and robot control. This paper investigates whether the pattern recognition and sequence modeling capabilities of LLMs can be extended to the domain of knowledge tracing, a critical component in the development of intelligent tutoring systems (ITSs) that tailor educational experiences by predicting learner performance over time. In an empirical evaluation across multiple real-world datasets, we compare two approaches to using LLMs for this task, zero-shot prompting and model fine-tuning, with existing, non-LLM approaches to knowledge tracing. While LLM-based approaches do not achieve state-of-the-art performance, fine-tuned LLMs surpass the performance of naive baseline models and perf",
    "path": "papers/24/03/2403.14661.json",
    "total_tokens": 860,
    "translated_title": "基于大型语言模型的学习者表现建模研究",
    "translated_abstract": "最近关于预训练大型语言模型（LLMs）能力的研究表明它们能够充当一般模式机器，通过完成代表各种任务的复杂令牌序列，包括时间序列预测和机器人控制。本文研究了LLMs的模式识别和序列建模能力是否能够扩展到知识追踪领域，这在智能辅导系统（ITSs）的发展中是一个关键组成部分，通过预测学习者随时间的表现来个性化教育体验。在多个真实世界数据集上进行了经验性评估，我们比较了使用LLMs进行此任务的两种方法，零-shot提示和模型微调，以及现有的非LLM方法。虽然基于LLMs的方法没有达到最先进的性能，但经过微调的LLMs超过了天真的基线模型的表现。",
    "tldr": "本文研究了预训练大型语言模型（LLMs）在知识追踪领域的应用，通过比较零-shot提示和模型微调两种方法，提出了LLMs在智能辅导系统中预测学习者表现的潜力。",
    "en_tdlr": "This paper investigates the application of pre-trained large language models (LLMs) in knowledge tracing, comparing zero-shot prompting and model fine-tuning approaches, highlighting the potential of LLMs in predicting learner performance in intelligent tutoring systems."
}