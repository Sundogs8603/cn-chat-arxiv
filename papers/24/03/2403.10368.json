{
    "title": "Conformal Predictions for Probabilistically Robust Scalable Machine Learning Classification",
    "abstract": "arXiv:2403.10368v1 Announce Type: cross  Abstract: Conformal predictions make it possible to define reliable and robust learning algorithms. But they are essentially a method for evaluating whether an algorithm is good enough to be used in practice. To define a reliable learning framework for classification from the very beginning of its design, the concept of scalable classifier was introduced to generalize the concept of classical classifier by linking it to statistical order theory and probabilistic learning theory. In this paper, we analyze the similarities between scalable classifiers and conformal predictions by introducing a new definition of a score function and defining a special set of input variables, the conformal safety set, which can identify patterns in the input space that satisfy the error coverage guarantee, i.e., that the probability of observing the wrong (possibly unsafe) label for points belonging to this set is bounded by a predefined $\\varepsilon$ error level. W",
    "link": "https://arxiv.org/abs/2403.10368",
    "context": "Title: Conformal Predictions for Probabilistically Robust Scalable Machine Learning Classification\nAbstract: arXiv:2403.10368v1 Announce Type: cross  Abstract: Conformal predictions make it possible to define reliable and robust learning algorithms. But they are essentially a method for evaluating whether an algorithm is good enough to be used in practice. To define a reliable learning framework for classification from the very beginning of its design, the concept of scalable classifier was introduced to generalize the concept of classical classifier by linking it to statistical order theory and probabilistic learning theory. In this paper, we analyze the similarities between scalable classifiers and conformal predictions by introducing a new definition of a score function and defining a special set of input variables, the conformal safety set, which can identify patterns in the input space that satisfy the error coverage guarantee, i.e., that the probability of observing the wrong (possibly unsafe) label for points belonging to this set is bounded by a predefined $\\varepsilon$ error level. W",
    "path": "papers/24/03/2403.10368.json",
    "total_tokens": 793,
    "translated_title": "面向概率鲁棒可扩展机器学习分类的适应性预测",
    "translated_abstract": "适应性预测可以定义可靠且稳健的学习算法，从设计初期就为分类定义了可靠的学习框架，通过将可扩展分类器的概念与统计排序理论和概率学习理论联系起来。本文通过引入得分函数的新定义和定义一组特殊的输入变量，即适应性安全集，来分析可扩展分类器和适应性预测之间的相似之处，该安全集能够识别在输入空间中满足误差覆盖保证的模式，即对于属于该集合的点观察到错误（可能不安全）标签的概率受到预定义的$\\varepsilon$错误水平的限制。",
    "tldr": "通过引入得分函数和定义适应性安全集，将可扩展分类器和适应性预测相结合，定义了一种可靠的学习框架，能够在设计初期就为分类提供稳健的算法。",
    "en_tdlr": "By introducing a score function and defining a conformal safety set, the combination of scalable classifiers and conformal predictions defines a reliable learning framework that provides robust algorithms for classification from the early stages of design."
}