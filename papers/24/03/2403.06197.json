{
    "title": "DrFuse: Learning Disentangled Representation for Clinical Multi-Modal Fusion with Missing Modality and Modal Inconsistency",
    "abstract": "arXiv:2403.06197v1 Announce Type: cross  Abstract: The combination of electronic health records (EHR) and medical images is crucial for clinicians in making diagnoses and forecasting prognosis. Strategically fusing these two data modalities has great potential to improve the accuracy of machine learning models in clinical prediction tasks. However, the asynchronous and complementary nature of EHR and medical images presents unique challenges. Missing modalities due to clinical and administrative factors are inevitable in practice, and the significance of each data modality varies depending on the patient and the prediction target, resulting in inconsistent predictions and suboptimal model performance. To address these challenges, we propose DrFuse to achieve effective clinical multi-modal fusion. It tackles the missing modality issue by disentangling the features shared across modalities and those unique within each modality. Furthermore, we address the modal inconsistency issue via a ",
    "link": "https://arxiv.org/abs/2403.06197",
    "context": "Title: DrFuse: Learning Disentangled Representation for Clinical Multi-Modal Fusion with Missing Modality and Modal Inconsistency\nAbstract: arXiv:2403.06197v1 Announce Type: cross  Abstract: The combination of electronic health records (EHR) and medical images is crucial for clinicians in making diagnoses and forecasting prognosis. Strategically fusing these two data modalities has great potential to improve the accuracy of machine learning models in clinical prediction tasks. However, the asynchronous and complementary nature of EHR and medical images presents unique challenges. Missing modalities due to clinical and administrative factors are inevitable in practice, and the significance of each data modality varies depending on the patient and the prediction target, resulting in inconsistent predictions and suboptimal model performance. To address these challenges, we propose DrFuse to achieve effective clinical multi-modal fusion. It tackles the missing modality issue by disentangling the features shared across modalities and those unique within each modality. Furthermore, we address the modal inconsistency issue via a ",
    "path": "papers/24/03/2403.06197.json",
    "total_tokens": 836,
    "translated_title": "DrFuse：学习面向临床多模态融合的解耦表示，解决缺失模态和模态不一致性问题",
    "translated_abstract": "电子健康记录（EHR）和医学图像的组合对临床医生在诊断和预测预后方面至关重要。战略性地融合这两种数据模态有巨大潜力改善临床预测任务中机器学习模型的准确性。然而，EHR和医学图像的异步和互补性特质带来独特挑战。由于临床和行政因素，缺失模态在实践中是不可避免的，而每种数据模态的重要性取决于患者和预测目标，导致预测不一致和模型性能次优。为解决这些挑战，我们提出DrFuse来实现有效的临床多模态融合。它通过解耦共享模态内和独特模态内的特征来解决缺失模态问题。此外，通过一种方法，我们解决了模态不一致性问题。",
    "tldr": "DrFuse通过解耦数据特征解决了临床多模态融合中的缺失模态和模态不一致性问题。",
    "en_tdlr": "DrFuse addresses missing modality and modal inconsistency issues in clinical multi-modal fusion by disentangling data features."
}