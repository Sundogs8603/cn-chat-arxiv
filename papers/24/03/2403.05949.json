{
    "title": "General surgery vision transformer: A video pre-trained foundation model for general surgery",
    "abstract": "arXiv:2403.05949v1 Announce Type: cross  Abstract: The absence of openly accessible data and specialized foundation models is a major barrier for computational research in surgery. Toward this, (i) we open-source the largest dataset of general surgery videos to-date, consisting of 680 hours of surgical videos, including data from robotic and laparoscopic techniques across 28 procedures; (ii) we propose a technique for video pre-training a general surgery vision transformer (GSViT) on surgical videos based on forward video prediction that can run in real-time for surgical applications, toward which we open-source the code and weights of GSViT; (iii) we also release code and weights for procedure-specific fine-tuned versions of GSViT across 10 procedures; (iv) we demonstrate the performance of GSViT on the Cholec80 phase annotation task, displaying improved performance over state-of-the-art single frame predictors.",
    "link": "https://arxiv.org/abs/2403.05949",
    "context": "Title: General surgery vision transformer: A video pre-trained foundation model for general surgery\nAbstract: arXiv:2403.05949v1 Announce Type: cross  Abstract: The absence of openly accessible data and specialized foundation models is a major barrier for computational research in surgery. Toward this, (i) we open-source the largest dataset of general surgery videos to-date, consisting of 680 hours of surgical videos, including data from robotic and laparoscopic techniques across 28 procedures; (ii) we propose a technique for video pre-training a general surgery vision transformer (GSViT) on surgical videos based on forward video prediction that can run in real-time for surgical applications, toward which we open-source the code and weights of GSViT; (iii) we also release code and weights for procedure-specific fine-tuned versions of GSViT across 10 procedures; (iv) we demonstrate the performance of GSViT on the Cholec80 phase annotation task, displaying improved performance over state-of-the-art single frame predictors.",
    "path": "papers/24/03/2403.05949.json",
    "total_tokens": 816,
    "translated_title": "通用外科视觉变换器：用于通用外科的视频预训练基础模型",
    "translated_abstract": "缺乏开放获取的数据和专门的基础模型是外科计算研究的主要障碍。为此，我们开源迄今为止最大的通用外科视频数据集，包括来自28种手术技术的680小时手术视频数据；我们提出了一种基于前向视频预测的通用外科视觉变换器（GSViT）视频预训练技术，可实时运行用于外科应用，我们还开源了GSViT的代码和权重；我们还发布了针对10种手术程序的特定程序微调版本的GSViT的代码和权重；我们展示了GSViT在Cholec80阶段注释任务上的性能，显示出优于最先进的单帧预测器的性能。",
    "tldr": "该论文开源了迄今为止最大的通用外科视频数据集，提出了用于外科应用的视频预训练通用外科视觉变换器（GSViT）技术，并展示了其在Cholec80阶段注释任务上的优越性能。",
    "en_tdlr": "The paper open-sourced the largest dataset of general surgery videos to-date, proposed a video pre-training technique for a general surgery vision transformer (GSViT) for surgical applications, and demonstrated its superior performance on the Cholec80 phase annotation task."
}