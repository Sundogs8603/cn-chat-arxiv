{
    "title": "Introducing User Feedback-based Counterfactual Explanations (UFCE)",
    "abstract": "arXiv:2403.00011v1 Announce Type: cross  Abstract: Machine learning models are widely used in real-world applications. However, their complexity makes it often challenging to interpret the rationale behind their decisions. Counterfactual explanations (CEs) have emerged as a viable solution for generating comprehensible explanations in eXplainable Artificial Intelligence (XAI). CE provides actionable information to users on how to achieve the desired outcome with minimal modifications to the input. However, current CE algorithms usually operate within the entire feature space when optimizing changes to turn over an undesired outcome, overlooking the identification of key contributors to the outcome and disregarding the practicality of the suggested changes. In this study, we introduce a novel methodology, that is named as user feedback-based counterfactual explanation (UFCE), which addresses these limitations and aims to bolster confidence in the provided explanations. UFCE allows for t",
    "link": "https://arxiv.org/abs/2403.00011",
    "context": "Title: Introducing User Feedback-based Counterfactual Explanations (UFCE)\nAbstract: arXiv:2403.00011v1 Announce Type: cross  Abstract: Machine learning models are widely used in real-world applications. However, their complexity makes it often challenging to interpret the rationale behind their decisions. Counterfactual explanations (CEs) have emerged as a viable solution for generating comprehensible explanations in eXplainable Artificial Intelligence (XAI). CE provides actionable information to users on how to achieve the desired outcome with minimal modifications to the input. However, current CE algorithms usually operate within the entire feature space when optimizing changes to turn over an undesired outcome, overlooking the identification of key contributors to the outcome and disregarding the practicality of the suggested changes. In this study, we introduce a novel methodology, that is named as user feedback-based counterfactual explanation (UFCE), which addresses these limitations and aims to bolster confidence in the provided explanations. UFCE allows for t",
    "path": "papers/24/03/2403.00011.json",
    "total_tokens": 837,
    "translated_title": "引入基于用户反馈的反事实解释（UFCE）",
    "translated_abstract": "机器学习模型在实际应用中被广泛使用。然而，它们的复杂性常常使得解释其决策背后的原因成为具有挑战性的任务。反事实解释（CEs）已经成为可行的解决方案，用于在可解释的人工智能（XAI）中生成可理解的解释。CE提供给用户关于如何通过最小的输入修改实现所期望的结果的可操作信息。然而，当前的CE算法通常在优化变化以避免不期望的结果时在整个特征空间内运行，忽视了对结果的主要贡献者的识别，并忽视了建议变化的实际可行性。在这项研究中，我们介绍了一种新的方法，被命名为基于用户反馈的反事实解释（UFCE），该方法解决了这些限制，并旨在增强对所提供解释的信心。UFCE允许t",
    "tldr": "本研究引入了一种名为基于用户反馈的反事实解释（UFCE）的新方法，旨在解决当前反事实解释算法的局限性，并增强提供的解释的可信度。"
}