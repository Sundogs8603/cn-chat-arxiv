{
    "title": "Re-Search for The Truth: Multi-round Retrieval-augmented Large Language Models are Strong Fake News Detectors",
    "abstract": "arXiv:2403.09747v1 Announce Type: cross  Abstract: The proliferation of fake news has had far-reaching implications on politics, the economy, and society at large. While Fake news detection methods have been employed to mitigate this issue, they primarily depend on two essential elements: the quality and relevance of the evidence, and the effectiveness of the verdict prediction mechanism. Traditional methods, which often source information from static repositories like Wikipedia, are limited by outdated or incomplete data, particularly for emerging or rare claims. Large Language Models (LLMs), known for their remarkable reasoning and generative capabilities, introduce a new frontier for fake news detection. However, like traditional methods, LLM-based solutions also grapple with the limitations of stale and long-tail knowledge. Additionally, retrieval-enhanced LLMs frequently struggle with issues such as low-quality evidence retrieval and context length constraints. To address these ch",
    "link": "https://arxiv.org/abs/2403.09747",
    "context": "Title: Re-Search for The Truth: Multi-round Retrieval-augmented Large Language Models are Strong Fake News Detectors\nAbstract: arXiv:2403.09747v1 Announce Type: cross  Abstract: The proliferation of fake news has had far-reaching implications on politics, the economy, and society at large. While Fake news detection methods have been employed to mitigate this issue, they primarily depend on two essential elements: the quality and relevance of the evidence, and the effectiveness of the verdict prediction mechanism. Traditional methods, which often source information from static repositories like Wikipedia, are limited by outdated or incomplete data, particularly for emerging or rare claims. Large Language Models (LLMs), known for their remarkable reasoning and generative capabilities, introduce a new frontier for fake news detection. However, like traditional methods, LLM-based solutions also grapple with the limitations of stale and long-tail knowledge. Additionally, retrieval-enhanced LLMs frequently struggle with issues such as low-quality evidence retrieval and context length constraints. To address these ch",
    "path": "papers/24/03/2403.09747.json",
    "total_tokens": 841,
    "translated_title": "重新探寻真相：多轮检索增强的大型语言模型是强大的假新闻检测器",
    "translated_abstract": "假新闻的泛滥对政治、经济和社会带来了深远的影响。尽管已经采用了假新闻检测方法来缓解这一问题，但它们主要依赖于两个基本要素：证据的质量和相关性，以及预测机制的有效性。传统方法通常从维基百科等静态知识库中获取信息，但受限于过时或不完整的数据，尤其是对于新兴或罕见的要求。以其卓越的推理和生成能力而闻名的大型语言模型(LLMs)为假新闻检测引入了一个新的领域。然而，与传统方法一样，基于LLM的解决方案也会面临过时和长尾知识的限制。此外，检索增强的LLMs经常遇到低质量证据检索和上下文长度限制等问题。为了解决这些问题",
    "tldr": "大型语言模型在假新闻检测中引入新的前沿，但仍需克服解决过时知识和低质量证据检索等问题",
    "en_tdlr": "Large Language Models introduce a new frontier for fake news detection, but still need to overcome issues such as outdated knowledge and low-quality evidence retrieval."
}