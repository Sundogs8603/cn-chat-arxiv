{
    "title": "Acquiring Diverse Skills using Curriculum Reinforcement Learning with Mixture of Experts",
    "abstract": "arXiv:2403.06966v1 Announce Type: new  Abstract: Reinforcement learning (RL) is a powerful approach for acquiring a good-performing policy. However, learning diverse skills is challenging in RL due to the commonly used Gaussian policy parameterization. We propose \\textbf{Di}verse \\textbf{Skil}l \\textbf{L}earning (Di-SkilL), an RL method for learning diverse skills using Mixture of Experts, where each expert formalizes a skill as a contextual motion primitive. Di-SkilL optimizes each expert and its associate context distribution to a maximum entropy objective that incentivizes learning diverse skills in similar contexts. The per-expert context distribution enables automatic curricula learning, allowing each expert to focus on its best-performing sub-region of the context space. To overcome hard discontinuities and multi-modalities without any prior knowledge of the environment's unknown context probability space, we leverage energy-based models to represent the per-expert context distri",
    "link": "https://arxiv.org/abs/2403.06966",
    "context": "Title: Acquiring Diverse Skills using Curriculum Reinforcement Learning with Mixture of Experts\nAbstract: arXiv:2403.06966v1 Announce Type: new  Abstract: Reinforcement learning (RL) is a powerful approach for acquiring a good-performing policy. However, learning diverse skills is challenging in RL due to the commonly used Gaussian policy parameterization. We propose \\textbf{Di}verse \\textbf{Skil}l \\textbf{L}earning (Di-SkilL), an RL method for learning diverse skills using Mixture of Experts, where each expert formalizes a skill as a contextual motion primitive. Di-SkilL optimizes each expert and its associate context distribution to a maximum entropy objective that incentivizes learning diverse skills in similar contexts. The per-expert context distribution enables automatic curricula learning, allowing each expert to focus on its best-performing sub-region of the context space. To overcome hard discontinuities and multi-modalities without any prior knowledge of the environment's unknown context probability space, we leverage energy-based models to represent the per-expert context distri",
    "path": "papers/24/03/2403.06966.json",
    "total_tokens": 841,
    "translated_title": "使用专家混合的课程强化学习获取多样技能",
    "translated_abstract": "强化学习是获取良好表现策略的强大方法，然而，由于常用的高斯策略参数化，RL中学习多样技能具有挑战性。我们提出了一种名为Di-SkilL的RL方法，用于使用专家混合学习多样技能，其中每个专家将技能形式化为一种上下文运动原语。Di-SkilL优化每个专家及其相关上下文分布以达到最大熵目标，激励在相似上下文中学习多样技能。每个专家的上下文分布使得自动课程学习成为可能，使每个专家能够专注于其在上下文空间的最佳表现子区域。为了克服在没有任何关于环境未知上下文概率空间的先验知识的情况下的硬性不连续性和多模态性，我们利用基于能量的模型来表示每个专家的上下文分布。",
    "tldr": "使用Mixture of Experts的Di-SkilL方法通过优化每个专家和其相关上下文分布，实现了在相似上下文中学习多样技能的目标。"
}