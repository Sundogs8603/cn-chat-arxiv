{
    "title": "Magic Markup: Maintaining Document-External Markup with an LLM",
    "abstract": "arXiv:2403.03481v1 Announce Type: new  Abstract: Text documents, including programs, typically have human-readable semantic structure. Historically, programmatic access to these semantics has required explicit in-document tagging. Especially in systems where the text has an execution semantics, this means it is an opt-in feature that is hard to support properly. Today, language models offer a new method: metadata can be bound to entities in changing text using a model's human-like understanding of semantics, with no requirements on the document structure. This method expands the applications of document annotation, a fundamental operation in program writing, debugging, maintenance, and presentation. We contribute a system that employs an intelligent agent to re-tag modified programs, enabling rich annotations to automatically follow code as it evolves. We also contribute a formal problem definition, an empirical synthetic benchmark suite, and our benchmark generator. Our system achieve",
    "link": "https://arxiv.org/abs/2403.03481",
    "context": "Title: Magic Markup: Maintaining Document-External Markup with an LLM\nAbstract: arXiv:2403.03481v1 Announce Type: new  Abstract: Text documents, including programs, typically have human-readable semantic structure. Historically, programmatic access to these semantics has required explicit in-document tagging. Especially in systems where the text has an execution semantics, this means it is an opt-in feature that is hard to support properly. Today, language models offer a new method: metadata can be bound to entities in changing text using a model's human-like understanding of semantics, with no requirements on the document structure. This method expands the applications of document annotation, a fundamental operation in program writing, debugging, maintenance, and presentation. We contribute a system that employs an intelligent agent to re-tag modified programs, enabling rich annotations to automatically follow code as it evolves. We also contribute a formal problem definition, an empirical synthetic benchmark suite, and our benchmark generator. Our system achieve",
    "path": "papers/24/03/2403.03481.json",
    "total_tokens": 830,
    "translated_title": "魔法标记：使用LLM维护文档外部标记",
    "translated_abstract": "文本文档，包括程序，通常具有人类可读的语义结构。历史上，对这些语义的程序化访问需要显式的文档内标记。特别是在文本具有执行语义的系统中，这意味着这是一个难以正确支持的自愿功能。现今，语言模型提供了一种新方法：可以使用模型对语义的人类化理解将元数据绑定到变化的文本实体，而不需要文档结构的要求。该方法扩展了文档注释的应用，这是程序编写、调试、维护和展示中的基本操作。我们提出了一种系统，利用智能代理对修改后的程序重新进行标记，使得丰富的注释可以随着代码演进而自动跟随。我们还贡献了一个正式的问题定义，一个经验合成基准套件，以及我们的基准生成器。",
    "tldr": "使用LLM模型，我们提出了一种新方法，将元数据绑定到文本实体，扩展了文档注释的应用，实现了对修改后程序的自动重新标记，并提供了正式问题定义和基准套件。",
    "en_tdlr": "By utilizing LLM model, we introduce a new method to bind metadata to text entities, expand the applications of document annotation, enable automatic re-tagging of modified programs, and provide a formal problem definition and benchmark suite."
}