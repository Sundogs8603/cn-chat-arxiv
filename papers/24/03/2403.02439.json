{
    "title": "Root Causing Prediction Anomalies Using Explainable AI",
    "abstract": "arXiv:2403.02439v1 Announce Type: cross  Abstract: This paper presents a novel application of explainable AI (XAI) for root-causing performance degradation in machine learning models that learn continuously from user engagement data. In such systems a single feature corruption can cause cascading feature, label and concept drifts. We have successfully applied this technique to improve the reliability of models used in personalized advertising. Performance degradation in such systems manifest as prediction anomalies in the models. These models are typically trained continuously using features that are produced by hundreds of real time data processing pipelines or derived from other upstream models. A failure in any of these pipelines or an instability in any of the upstream models can cause feature corruption, causing the model's predicted output to deviate from the actual output and the training data to become corrupted. The causal relationship between the features and the predicted ou",
    "link": "https://arxiv.org/abs/2403.02439",
    "context": "Title: Root Causing Prediction Anomalies Using Explainable AI\nAbstract: arXiv:2403.02439v1 Announce Type: cross  Abstract: This paper presents a novel application of explainable AI (XAI) for root-causing performance degradation in machine learning models that learn continuously from user engagement data. In such systems a single feature corruption can cause cascading feature, label and concept drifts. We have successfully applied this technique to improve the reliability of models used in personalized advertising. Performance degradation in such systems manifest as prediction anomalies in the models. These models are typically trained continuously using features that are produced by hundreds of real time data processing pipelines or derived from other upstream models. A failure in any of these pipelines or an instability in any of the upstream models can cause feature corruption, causing the model's predicted output to deviate from the actual output and the training data to become corrupted. The causal relationship between the features and the predicted ou",
    "path": "papers/24/03/2403.02439.json",
    "total_tokens": 672,
    "translated_title": "使用可解释人工智能 (XAI) 分析预测异常根本原因",
    "translated_abstract": "本文介绍了可解释人工智能（XAI）在根因分析机器学习模型性能下降中的创新应用，该模型不断从用户参与数据中学习。在这些系统中，单个特征损坏可能导致级联特征、标签和概念漂移。我们已成功将这一技术应用于提高个性化广告中使用的模型的可靠性。在这种系统中，性能下降表现为模型中的预测异常。",
    "tldr": "本文介绍了在根本上解决个性化广告中模型性能下降问题的方法，通过解释人工智能技术分析预测异常。",
    "en_tdlr": "This paper introduces a method to fundamentally address performance degradation in models used for personalized advertising by analyzing prediction anomalies using explainable artificial intelligence technology."
}