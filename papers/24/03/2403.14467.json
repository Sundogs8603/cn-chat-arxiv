{
    "title": "Recourse for reclamation: Chatting with generative language models",
    "abstract": "arXiv:2403.14467v1 Announce Type: cross  Abstract: Researchers and developers increasingly rely on toxicity scoring to moderate generative language model outputs, in settings such as customer service, information retrieval, and content generation. However, toxicity scoring may render pertinent information inaccessible, rigidify or \"value-lock\" cultural norms, and prevent language reclamation processes, particularly for marginalized people. In this work, we extend the concept of algorithmic recourse to generative language models: we provide users a novel mechanism to achieve their desired prediction by dynamically setting thresholds for toxicity filtering. Users thereby exercise increased agency relative to interactions with the baseline system. A pilot study ($n = 30$) supports the potential of our proposed recourse mechanism, indicating improvements in usability compared to fixed-threshold toxicity-filtering of model outputs. Future work should explore the intersection of toxicity sco",
    "link": "https://arxiv.org/abs/2403.14467",
    "context": "Title: Recourse for reclamation: Chatting with generative language models\nAbstract: arXiv:2403.14467v1 Announce Type: cross  Abstract: Researchers and developers increasingly rely on toxicity scoring to moderate generative language model outputs, in settings such as customer service, information retrieval, and content generation. However, toxicity scoring may render pertinent information inaccessible, rigidify or \"value-lock\" cultural norms, and prevent language reclamation processes, particularly for marginalized people. In this work, we extend the concept of algorithmic recourse to generative language models: we provide users a novel mechanism to achieve their desired prediction by dynamically setting thresholds for toxicity filtering. Users thereby exercise increased agency relative to interactions with the baseline system. A pilot study ($n = 30$) supports the potential of our proposed recourse mechanism, indicating improvements in usability compared to fixed-threshold toxicity-filtering of model outputs. Future work should explore the intersection of toxicity sco",
    "path": "papers/24/03/2403.14467.json",
    "total_tokens": 866,
    "translated_title": "重新索取的权利：与生成式语言模型对话",
    "translated_abstract": "研究人员和开发者越来越多地依赖毒性评分来调节生成式语言模型的输出，在客户服务、信息检索和内容生成等场景中。然而，毒性评分可能使相关信息无法访问，使文化规范僵化或“价值锁定”，阻碍语言重新索取过程，特别是对边缘化群体。在这项工作中，我们将算法性索赔的概念延伸到生成式语言模型：我们为用户提供一种新颖机制，通过动态设置毒性过滤的阈值，使用户能够实现他们所期望的预测。用户因此相对于与基线系统的交互，可以行使更多的代理权。一项试点研究($n=30$)支持我们提出的索赔机制的潜力，表明与固定阈值毒性过滤模型输出相比，在可用性方面有所改进。未来的工作应该探索毒性评分与语言重新索取之间的交叉点。",
    "tldr": "这项工作将算法性索赔的概念延伸到生成式语言模型，为用户提供动态设置毒性过滤阈值的新机制，使他们能够实现他们期望的预测，从而增加他们的代理权。"
}