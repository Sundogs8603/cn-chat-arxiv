{
    "title": "Randomized Principal Component Analysis for Hyperspectral Image Classification",
    "abstract": "arXiv:2403.09117v1 Announce Type: cross  Abstract: The high-dimensional feature space of the hyperspectral imagery poses major challenges to the processing and analysis of the hyperspectral data sets. In such a case, dimensionality reduction is necessary to decrease the computational complexity. The random projections open up new ways of dimensionality reduction, especially for large data sets. In this paper, the principal component analysis (PCA) and randomized principal component analysis (R-PCA) for the classification of hyperspectral images using support vector machines (SVM) and light gradient boosting machines (LightGBM) have been investigated. In this experimental research, the number of features was reduced to 20 and 30 for classification of two hyperspectral datasets (Indian Pines and Pavia University). The experimental results demonstrated that PCA outperformed R-PCA for SVM for both datasets, but received close accuracy values for LightGBM. The highest classification accurac",
    "link": "https://arxiv.org/abs/2403.09117",
    "context": "Title: Randomized Principal Component Analysis for Hyperspectral Image Classification\nAbstract: arXiv:2403.09117v1 Announce Type: cross  Abstract: The high-dimensional feature space of the hyperspectral imagery poses major challenges to the processing and analysis of the hyperspectral data sets. In such a case, dimensionality reduction is necessary to decrease the computational complexity. The random projections open up new ways of dimensionality reduction, especially for large data sets. In this paper, the principal component analysis (PCA) and randomized principal component analysis (R-PCA) for the classification of hyperspectral images using support vector machines (SVM) and light gradient boosting machines (LightGBM) have been investigated. In this experimental research, the number of features was reduced to 20 and 30 for classification of two hyperspectral datasets (Indian Pines and Pavia University). The experimental results demonstrated that PCA outperformed R-PCA for SVM for both datasets, but received close accuracy values for LightGBM. The highest classification accurac",
    "path": "papers/24/03/2403.09117.json",
    "total_tokens": 876,
    "translated_title": "针对高光谱图像分类的随机主成分分析",
    "translated_abstract": "高光谱图像的高维特征空间给高光谱数据集的处理和分析带来了重大挑战。在这种情况下，降维是必要的以减小计算复杂性。随机投影为降低维度提供了新的途径，尤其适用于大数据集。本文探讨了使用支持向量机（SVM）和轻量级梯度提升机（LightGBM）对高光谱图像进行分类的主成分分析（PCA）和随机主成分分析（R-PCA）。在这项实验研究中，将特征数减少到20和30以进行两个高光谱数据集（Indian Pines和Pavia University）的分类。实验结果表明，对于两个数据集，PCA在SVM方面优于R-PCA，但在LightGBM方面获得了接近的准确度数值。",
    "tldr": "本研究探讨了针对高光谱图像分类的主成分分析（PCA）和随机主成分分析（R-PCA），实验证明PCA在支持向量机（SVM）方面优于R-PCA，但在轻量级梯度提升机（LightGBM）方面表现接近准确度数值。",
    "en_tdlr": "This study investigates principal component analysis (PCA) and randomized principal component analysis (R-PCA) for hyperspectral image classification, with experimental results showing that PCA outperforms R-PCA for support vector machines (SVM) but achieves similar accuracy values for LightGBM."
}