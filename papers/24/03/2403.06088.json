{
    "title": "Towards In-Vehicle Multi-Task Facial Attribute Recognition: Investigating Synthetic Data and Vision Foundation Models",
    "abstract": "arXiv:2403.06088v1 Announce Type: cross  Abstract: In the burgeoning field of intelligent transportation systems, enhancing vehicle-driver interaction through facial attribute recognition, such as facial expression, eye gaze, age, etc., is of paramount importance for safety, personalization, and overall user experience. However, the scarcity of comprehensive large-scale, real-world datasets poses a significant challenge for training robust multi-task models. Existing literature often overlooks the potential of synthetic datasets and the comparative efficacy of state-of-the-art vision foundation models in such constrained settings. This paper addresses these gaps by investigating the utility of synthetic datasets for training complex multi-task models that recognize facial attributes of passengers of a vehicle, such as gaze plane, age, and facial expression. Utilizing transfer learning techniques with both pre-trained Vision Transformer (ViT) and Residual Network (ResNet) models, we exp",
    "link": "https://arxiv.org/abs/2403.06088",
    "context": "Title: Towards In-Vehicle Multi-Task Facial Attribute Recognition: Investigating Synthetic Data and Vision Foundation Models\nAbstract: arXiv:2403.06088v1 Announce Type: cross  Abstract: In the burgeoning field of intelligent transportation systems, enhancing vehicle-driver interaction through facial attribute recognition, such as facial expression, eye gaze, age, etc., is of paramount importance for safety, personalization, and overall user experience. However, the scarcity of comprehensive large-scale, real-world datasets poses a significant challenge for training robust multi-task models. Existing literature often overlooks the potential of synthetic datasets and the comparative efficacy of state-of-the-art vision foundation models in such constrained settings. This paper addresses these gaps by investigating the utility of synthetic datasets for training complex multi-task models that recognize facial attributes of passengers of a vehicle, such as gaze plane, age, and facial expression. Utilizing transfer learning techniques with both pre-trained Vision Transformer (ViT) and Residual Network (ResNet) models, we exp",
    "path": "papers/24/03/2403.06088.json",
    "total_tokens": 840,
    "translated_title": "面向车载多任务面部属性识别：研究合成数据和视觉基础模型",
    "translated_abstract": "在智能交通系统蓬勃发展的领域中，通过面部属性识别（如面部表情、眼神、年龄等）增强车辆驾驶员的交互对于安全、个性化和整体用户体验至关重要。然而，缺乏全面大规模的真实世界数据集对训练稳健的多任务模型构成了重大挑战。现有文献通常忽视了合成数据集的潜力以及在这种受限环境中最先进的视觉基础模型的比较功效。本文通过研究合成数据集的实用性来训练识别车辆乘客的面部属性（如眼神方向、年龄和面部表情）的复杂多任务模型，并利用预训练的Vision Transformer（ViT）和残差网络（ResNet）模型的迁移学习技术来填补这些空白。",
    "tldr": "本文通过研究合成数据集的实用性和不同视觉基础模型在车载多任务面部属性识别中的效果，填补了现有文献中的空白。",
    "en_tdlr": "This paper fills the gaps in existing literature by investigating the utility of synthetic datasets and the comparative efficacy of different vision foundation models in in-vehicle multi-task facial attribute recognition."
}