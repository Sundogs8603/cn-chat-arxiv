{
    "title": "An Alternative Graphical Lasso Algorithm for Precision Matrices",
    "abstract": "arXiv:2403.12357v1 Announce Type: cross  Abstract: The Graphical Lasso (GLasso) algorithm is fast and widely used for estimating sparse precision matrices (Friedman et al., 2008). Its central role in the literature of high-dimensional covariance estimation rivals that of Lasso regression for sparse estimation of the mean vector. Some mysteries regarding its optimization target, convergence, positive-definiteness and performance have been unearthed, resolved and presented in Mazumder and Hastie (2011), leading to a new/improved (dual-primal) DP-GLasso. Using a new and slightly different reparametriztion of the last column of a precision matrix we show that the regularized normal log-likelihood naturally decouples into a sum of two easy to minimize convex functions one of which is a Lasso regression problem. This decomposition is the key in developing a transparent, simple iterative block coordinate descent algorithm for computing the GLasso updates with performance comparable to DP-GLas",
    "link": "https://arxiv.org/abs/2403.12357",
    "context": "Title: An Alternative Graphical Lasso Algorithm for Precision Matrices\nAbstract: arXiv:2403.12357v1 Announce Type: cross  Abstract: The Graphical Lasso (GLasso) algorithm is fast and widely used for estimating sparse precision matrices (Friedman et al., 2008). Its central role in the literature of high-dimensional covariance estimation rivals that of Lasso regression for sparse estimation of the mean vector. Some mysteries regarding its optimization target, convergence, positive-definiteness and performance have been unearthed, resolved and presented in Mazumder and Hastie (2011), leading to a new/improved (dual-primal) DP-GLasso. Using a new and slightly different reparametriztion of the last column of a precision matrix we show that the regularized normal log-likelihood naturally decouples into a sum of two easy to minimize convex functions one of which is a Lasso regression problem. This decomposition is the key in developing a transparent, simple iterative block coordinate descent algorithm for computing the GLasso updates with performance comparable to DP-GLas",
    "path": "papers/24/03/2403.12357.json",
    "total_tokens": 807,
    "translated_title": "一种用于精准矩阵的替代图形Lasso算法",
    "translated_abstract": "Graphical Lasso (GLasso)算法是一种快速且广泛用于估计稀疏精准矩阵的方法。本文通过使用新的并略微不同的精准矩阵最后一列的重新参数化，展示了正则化正态对数似然自然地分解成两个易于最小化的凸函数之和，其中之一是Lasso回归问题。这种分解是开发透明、简单的迭代块坐标下降算法的关键，用于计算GLasso更新，其性能与DP-GLas相当。",
    "tldr": "通过重新参数化精准矩阵最后一列，将正则化正态对数似然分解为两个易于最小化的凸函数，其中一个是Lasso回归问题，从而开发了一种简单的块坐标下降算法来计算GLasso更新，性能可与DP-GLas相媲美。",
    "en_tdlr": "By reparametrizing the last column of the precision matrix, the regularized normal log-likelihood naturally decomposes into two easy-to-minimize convex functions, one of which is a Lasso regression problem, leading to the development of a simple block coordinate descent algorithm for computing GLasso updates with performance comparable to DP-GLas."
}