{
    "title": "Towards Trustworthy Automated Driving through Qualitative Scene Understanding and Explanations",
    "abstract": "arXiv:2403.16908v1 Announce Type: new  Abstract: Understanding driving scenes and communicating automated vehicle decisions are key requirements for trustworthy automated driving. In this article, we introduce the Qualitative Explainable Graph (QXG), which is a unified symbolic and qualitative representation for scene understanding in urban mobility. The QXG enables interpreting an automated vehicle's environment using sensor data and machine learning models. It utilizes spatio-temporal graphs and qualitative constraints to extract scene semantics from raw sensor inputs, such as LiDAR and camera data, offering an interpretable scene model. A QXG can be incrementally constructed in real-time, making it a versatile tool for in-vehicle explanations across various sensor types. Our research showcases the potential of QXG, particularly in the context of automated driving, where it can rationalize decisions by linking the graph with observed actions. These explanations can serve diverse purp",
    "link": "https://arxiv.org/abs/2403.16908",
    "context": "Title: Towards Trustworthy Automated Driving through Qualitative Scene Understanding and Explanations\nAbstract: arXiv:2403.16908v1 Announce Type: new  Abstract: Understanding driving scenes and communicating automated vehicle decisions are key requirements for trustworthy automated driving. In this article, we introduce the Qualitative Explainable Graph (QXG), which is a unified symbolic and qualitative representation for scene understanding in urban mobility. The QXG enables interpreting an automated vehicle's environment using sensor data and machine learning models. It utilizes spatio-temporal graphs and qualitative constraints to extract scene semantics from raw sensor inputs, such as LiDAR and camera data, offering an interpretable scene model. A QXG can be incrementally constructed in real-time, making it a versatile tool for in-vehicle explanations across various sensor types. Our research showcases the potential of QXG, particularly in the context of automated driving, where it can rationalize decisions by linking the graph with observed actions. These explanations can serve diverse purp",
    "path": "papers/24/03/2403.16908.json",
    "total_tokens": 793,
    "translated_title": "通过定性场景理解和解释实现可信自动驾驶",
    "translated_abstract": "理解驾驶场景并传达自动驾驶车辆决策是可信自动驾驶的关键要求。本文介绍了定性可解释图（QXG），这是一种用于城市移动中场景理解的统一符号和定性表示。QXG利用时空图和定性约束从原始传感器输入（如LiDAR和摄像头数据）中提取场景语义，提供可解释的场景模型。QXG可以实时增量构建，成为一种适用于车载解释的多种传感器类型的多功能工具。我们的研究展示了QXG在自动驾驶领域的潜力，它可以通过将图形与观察到的行为联系起来来理解决策。这些解释可以用于多种目的。",
    "tldr": "QXG是一种统一符号和定性表示，利用时空图和定性约束从原始传感器输入中提取场景语义，为自动驾驶提供可信的场景理解和解释。",
    "en_tdlr": "QXG is a unified symbolic and qualitative representation that extracts scene semantics from raw sensor inputs using spatio-temporal graphs and qualitative constraints, providing trustworthy scene understanding and explanations for automated driving."
}