{
    "title": "Hierarchical Open-Vocabulary 3D Scene Graphs for Language-Grounded Robot Navigation",
    "abstract": "arXiv:2403.17846v1 Announce Type: cross  Abstract: Recent open-vocabulary robot mapping methods enrich dense geometric maps with pre-trained visual-language features. While these maps allow for the prediction of point-wise saliency maps when queried for a certain language concept, large-scale environments and abstract queries beyond the object level still pose a considerable hurdle, ultimately limiting language-grounded robotic navigation. In this work, we present HOV-SG, a hierarchical open-vocabulary 3D scene graph mapping approach for language-grounded robot navigation. Leveraging open-vocabulary vision foundation models, we first obtain state-of-the-art open-vocabulary segment-level maps in 3D and subsequently construct a 3D scene graph hierarchy consisting of floor, room, and object concepts, each enriched with open-vocabulary features. Our approach is able to represent multi-story buildings and allows robotic traversal of those using a cross-floor Voronoi graph. HOV-SG is evaluat",
    "link": "https://arxiv.org/abs/2403.17846",
    "context": "Title: Hierarchical Open-Vocabulary 3D Scene Graphs for Language-Grounded Robot Navigation\nAbstract: arXiv:2403.17846v1 Announce Type: cross  Abstract: Recent open-vocabulary robot mapping methods enrich dense geometric maps with pre-trained visual-language features. While these maps allow for the prediction of point-wise saliency maps when queried for a certain language concept, large-scale environments and abstract queries beyond the object level still pose a considerable hurdle, ultimately limiting language-grounded robotic navigation. In this work, we present HOV-SG, a hierarchical open-vocabulary 3D scene graph mapping approach for language-grounded robot navigation. Leveraging open-vocabulary vision foundation models, we first obtain state-of-the-art open-vocabulary segment-level maps in 3D and subsequently construct a 3D scene graph hierarchy consisting of floor, room, and object concepts, each enriched with open-vocabulary features. Our approach is able to represent multi-story buildings and allows robotic traversal of those using a cross-floor Voronoi graph. HOV-SG is evaluat",
    "path": "papers/24/03/2403.17846.json",
    "total_tokens": 874,
    "translated_title": "基于语言驱动的机器人导航的分层开放词汇3D场景图",
    "translated_abstract": "最近的开放词汇机器人映射方法利用预先训练的视觉-语言特征丰富了密集几何地图。虽然这些地图允许在查询某种语言概念时预测逐点显著性地图，但大规模环境和超出对象级别的抽象查询仍然是一个相当大的障碍，最终限制了基于语言的机器人导航。在这项工作中，我们提出了HOV-SG，一种用于语言驱动的机器人导航的分层开放词汇3D场景图映射方法。通过利用开放词汇视觉基础模型，我们首先在3D空间中获得了最先进的开放词汇分段级地图，然后构建了由地板、房间和对象概念组成的3D场景图层次结构，每个都包含开放性词汇特征。我们的方法能够表示多层建筑，并且允许机器人使用跨层Voronoi图穿越这些建筑。HOV-SG进行了评估。",
    "tldr": "提出了一种用于语言驱动的机器人导航的分层开放词汇3D场景图映射方法，可以有效代表多层建筑并允许机器人在其中穿行。"
}