{
    "title": "Development of a Reliable and Accessible Caregiving Language Model (CaLM)",
    "abstract": "arXiv:2403.06857v1 Announce Type: new  Abstract: Unlike professional caregivers, family caregivers often assume this role without formal preparation or training. Because of this, there is an urgent need to enhance the capacity of family caregivers to provide quality care. Large language models can potentially be used as a foundation technology for supporting caregivers as educational tools or as adjunct to care. This study aimed to develop a reliable Caregiving Language Model (CaLM) by using FMs and a caregiving knowledge base, develop an accessible CaLM using a small FM that requires fewer computing resources, and evaluate the performance of the model compared to a large FM. We developed CaLM using the Retrieval Augmented Generation (RAG) framework combined with FM fine-tuning for improving the quality of FM answers by grounding the model on a caregiving knowledge base. We used two small FMs as candidates for the FM of CaLM (LLaMA-2 and Falcon with 7B parameters) and larger FM GPT-3.5",
    "link": "https://arxiv.org/abs/2403.06857",
    "context": "Title: Development of a Reliable and Accessible Caregiving Language Model (CaLM)\nAbstract: arXiv:2403.06857v1 Announce Type: new  Abstract: Unlike professional caregivers, family caregivers often assume this role without formal preparation or training. Because of this, there is an urgent need to enhance the capacity of family caregivers to provide quality care. Large language models can potentially be used as a foundation technology for supporting caregivers as educational tools or as adjunct to care. This study aimed to develop a reliable Caregiving Language Model (CaLM) by using FMs and a caregiving knowledge base, develop an accessible CaLM using a small FM that requires fewer computing resources, and evaluate the performance of the model compared to a large FM. We developed CaLM using the Retrieval Augmented Generation (RAG) framework combined with FM fine-tuning for improving the quality of FM answers by grounding the model on a caregiving knowledge base. We used two small FMs as candidates for the FM of CaLM (LLaMA-2 and Falcon with 7B parameters) and larger FM GPT-3.5",
    "path": "papers/24/03/2403.06857.json",
    "total_tokens": 898,
    "translated_title": "开发一种可靠且易获取的护理语言模型（CaLM）",
    "translated_abstract": "与专业护理人员不同，家庭护理人员通常在没有正式准备或培训的情况下承担这一角色。因此，迫切需要增强家庭护理人员提供优质护理的能力。大型语言模型可以作为支持护理人员的教育工具或护理的辅助技术的基础技术。本研究旨在通过使用FM和护理知识库开发可靠的护理语言模型（CaLM），使用需要更少计算资源的小FM开发易获取的CaLM，并评估模型相对于大型FM的性能。我们使用检索增强生成（RAG）框架结合FM微调开发CaLM，以通过将模型基于护理知识库来提高FM答案的质量。我们选择两个小FM作为CaLM的FM候选者（LLaMA-2和参数为7B的Falcon），以及更大的FM GPT-3.5。",
    "tldr": "该研究旨在开发一种可靠的护理语言模型（CaLM），使用FM和护理知识库，通过RAG框架和FM微调提高FM答案质量，以支持家庭护理人员提供优质护理。",
    "en_tdlr": "The study aimed to develop a reliable Caregiving Language Model (CaLM) using FM and a caregiving knowledge base, enhancing FM answer quality through the RAG framework and FM fine-tuning to support family caregivers in providing quality care."
}