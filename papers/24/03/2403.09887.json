{
    "title": "Sabi\\'a-2: A New Generation of Portuguese Large Language Models",
    "abstract": "arXiv:2403.09887v1 Announce Type: cross  Abstract: We introduce Sabi\\'a-2, a family of large language models trained on Portuguese texts. The models are evaluated on a diverse range of exams, including entry-level tests for Brazilian universities, professional certification exams, and graduate-level exams for various disciplines such as accounting, economics, engineering, law and medicine. Our results reveal that our best model so far, Sabi\\'a-2 Medium, matches or surpasses GPT-4's performance in 23 out of 64 exams and outperforms GPT-3.5 in 58 out of 64 exams. Notably, specialization has a significant impact on a model's performance without the need to increase its size, allowing us to offer Sabi\\'a-2 Medium at a price per token that is 10 times cheaper than GPT-4. Finally, we identified that math and coding are key abilities that need improvement.",
    "link": "https://arxiv.org/abs/2403.09887",
    "context": "Title: Sabi\\'a-2: A New Generation of Portuguese Large Language Models\nAbstract: arXiv:2403.09887v1 Announce Type: cross  Abstract: We introduce Sabi\\'a-2, a family of large language models trained on Portuguese texts. The models are evaluated on a diverse range of exams, including entry-level tests for Brazilian universities, professional certification exams, and graduate-level exams for various disciplines such as accounting, economics, engineering, law and medicine. Our results reveal that our best model so far, Sabi\\'a-2 Medium, matches or surpasses GPT-4's performance in 23 out of 64 exams and outperforms GPT-3.5 in 58 out of 64 exams. Notably, specialization has a significant impact on a model's performance without the need to increase its size, allowing us to offer Sabi\\'a-2 Medium at a price per token that is 10 times cheaper than GPT-4. Finally, we identified that math and coding are key abilities that need improvement.",
    "path": "papers/24/03/2403.09887.json",
    "total_tokens": 951,
    "translated_title": "Sabi\\'a-2:一代新的葡萄牙大型语言模型",
    "translated_abstract": "我们介绍了Sabi'a-2，这是一族在葡萄牙文本上训练的大型语言模型。这些模型在多个考试中进行了评估，包括巴西大学的入学考试、专业认证考试以及各种学科（如会计、经济学、工程学、法律和医学）的研究生入学考试。我们的结果显示，到目前为止我们最优秀的模型Sabi'a-2 Medium，在64场考试中有23场与GPT-4的表现相匹敌或超越，并且在64场考试中有58场超过了GPT-3.5。值得注意的是，专业化对模型的性能有显著影响，无需增大模型尺寸，我们可以提供Sabi'a-2 Medium，每个记号的价格比GPT-4便宜10倍。最后，我们发现数学和编码是需要改进的关键能力。",
    "tldr": "Sabi'a-2是一代新的葡萄牙大型语言模型，其中的Sabi'a-2 Medium模型在多个考试中的表现超越了GPT-4，且在大多数考试中超过了GPT-3.5，同时专业化对模型的性能有显著影响，可在无需增大模型尺寸的情况下以比GPT-4便宜10倍的价格提供。",
    "en_tdlr": "Sabi'a-2 is a new generation of Portuguese large language models, with the Sabi'a-2 Medium model outperforming GPT-4 in multiple exams and surpassing GPT-3.5 in most exams. Specialization significantly impacts the model's performance without the need for size increase, allowing for a 10 times cheaper price per token compared to GPT-4."
}