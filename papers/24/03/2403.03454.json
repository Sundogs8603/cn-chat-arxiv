{
    "title": "Learning Constrained Optimization with Deep Augmented Lagrangian Methods",
    "abstract": "arXiv:2403.03454v1 Announce Type: new  Abstract: Learning to Optimize (LtO) is a problem setting in which a machine learning (ML) model is trained to emulate a constrained optimization solver. Learning to produce optimal and feasible solutions subject to complex constraints is a difficult task, but is often made possible by restricting the input space to a limited distribution of related problems. Most LtO methods focus on directly learning solutions to the primal problem, and applying correction schemes or loss function penalties to encourage feasibility. This paper proposes an alternative approach, in which the ML model is trained instead to predict dual solution estimates directly, from which primal estimates are constructed to form dual-feasible solution pairs. This enables an end-to-end training scheme is which the dual objective is maximized as a loss function, and solution estimates iterate toward primal feasibility, emulating a Dual Ascent method. First it is shown that the poo",
    "link": "https://arxiv.org/abs/2403.03454",
    "context": "Title: Learning Constrained Optimization with Deep Augmented Lagrangian Methods\nAbstract: arXiv:2403.03454v1 Announce Type: new  Abstract: Learning to Optimize (LtO) is a problem setting in which a machine learning (ML) model is trained to emulate a constrained optimization solver. Learning to produce optimal and feasible solutions subject to complex constraints is a difficult task, but is often made possible by restricting the input space to a limited distribution of related problems. Most LtO methods focus on directly learning solutions to the primal problem, and applying correction schemes or loss function penalties to encourage feasibility. This paper proposes an alternative approach, in which the ML model is trained instead to predict dual solution estimates directly, from which primal estimates are constructed to form dual-feasible solution pairs. This enables an end-to-end training scheme is which the dual objective is maximized as a loss function, and solution estimates iterate toward primal feasibility, emulating a Dual Ascent method. First it is shown that the poo",
    "path": "papers/24/03/2403.03454.json",
    "total_tokens": 888,
    "translated_title": "使用深度增广拉格朗日方法学习受限制优化",
    "translated_abstract": "学习优化（LtO）是一个问题设置，在此设置中，一个机器学习（ML）模型被训练成模拟一个受限制优化求解器。学习产生最优和符合复杂约束的解决方案是一项困难的任务，但通常可以通过将输入空间限制为一组相关问题的分布来实现。大多数LtO方法侧重于直接学习原始问题的解决方案，并应用校正方案或损失函数惩罚来鼓励可行性。本文提出了一种替代方法，即训练ML模型直接预测对偶解估计，从而构建原始估计以形成对偶可行解对。这使得能够进行端到端训练方案，在这种方案中对偶目标被最大化作为损失函数，解决方案估计向原始可行性迭代，模拟对偶上升方法。",
    "tldr": "本文提出了一种使用深度增广拉格朗日方法的学习受限制优化的方法，通过训练机器学习模型直接预测对偶解估计，并构建原始估计，从而实现对偶可行解对，同时迭代向原始可行性，模拟对偶上升方法。",
    "en_tdlr": "This paper introduces a method for learning constrained optimization with deep augmented Lagrangian methods, where a machine learning model is trained to predict dual solution estimates directly, constructing primal estimates to form dual-feasible solution pairs, iterating towards primal feasibility, emulating Dual Ascent method."
}