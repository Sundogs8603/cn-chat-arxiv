{
    "title": "SUDO: a framework for evaluating clinical artificial intelligence systems without ground-truth annotations",
    "abstract": "arXiv:2403.17011v1 Announce Type: cross  Abstract: A clinical artificial intelligence (AI) system is often validated on a held-out set of data which it has not been exposed to before (e.g., data from a different hospital with a distinct electronic health record system). This evaluation process is meant to mimic the deployment of an AI system on data in the wild; those which are currently unseen by the system yet are expected to be encountered in a clinical setting. However, when data in the wild differ from the held-out set of data, a phenomenon referred to as distribution shift, and lack ground-truth annotations, it becomes unclear the extent to which AI-based findings can be trusted on data in the wild. Here, we introduce SUDO, a framework for evaluating AI systems without ground-truth annotations. SUDO assigns temporary labels to data points in the wild and directly uses them to train distinct models, with the highest performing model indicative of the most likely label. Through exp",
    "link": "https://arxiv.org/abs/2403.17011",
    "context": "Title: SUDO: a framework for evaluating clinical artificial intelligence systems without ground-truth annotations\nAbstract: arXiv:2403.17011v1 Announce Type: cross  Abstract: A clinical artificial intelligence (AI) system is often validated on a held-out set of data which it has not been exposed to before (e.g., data from a different hospital with a distinct electronic health record system). This evaluation process is meant to mimic the deployment of an AI system on data in the wild; those which are currently unseen by the system yet are expected to be encountered in a clinical setting. However, when data in the wild differ from the held-out set of data, a phenomenon referred to as distribution shift, and lack ground-truth annotations, it becomes unclear the extent to which AI-based findings can be trusted on data in the wild. Here, we introduce SUDO, a framework for evaluating AI systems without ground-truth annotations. SUDO assigns temporary labels to data points in the wild and directly uses them to train distinct models, with the highest performing model indicative of the most likely label. Through exp",
    "path": "papers/24/03/2403.17011.json",
    "total_tokens": 846,
    "translated_title": "SUDO：一种无需真实标注评估临床人工智能系统的框架",
    "translated_abstract": "临床人工智能（AI）系统通常在一个未曝光过的数据集上进行验证（例如来自具有不同电子健康记录系统的不同医院的数据）。这种评估过程旨在模拟将AI系统部署在未被系统见过但在临床环境中预计会遇到的数据上；然而，当实际数据与未曝光的数据集不同时，即分布转移现象，并且缺乏真实标注时，不清楚基于AI的发现在实际数据上能否受信任。在这里，我们介绍SUDO，一种用于评估无需真实标注的AI系统的框架。SUDO为实际数据点分配临时标签，并直接使用这些标签训练不同模型，表现最优的模型表明最可能的标签。",
    "tldr": "SUDO框架允许在缺乏真实标注的情况下评估AI系统，通过为实际数据点分配临时标签并直接使用它们训练模型来解决分布转移问题，从而提高对临床数据的可信度。",
    "en_tdlr": "SUDO framework allows evaluation of AI systems without ground-truth annotations by assigning temporary labels to real-world data points and training models directly, addressing the distribution shift issue to enhance trust in clinical data."
}