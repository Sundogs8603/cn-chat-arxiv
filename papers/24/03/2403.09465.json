{
    "title": "Outlier Robust Multivariate Polynomial Regression",
    "abstract": "arXiv:2403.09465v1 Announce Type: cross  Abstract: We study the problem of robust multivariate polynomial regression: let $p\\colon\\mathbb{R}^n\\to\\mathbb{R}$ be an unknown $n$-variate polynomial of degree at most $d$ in each variable. We are given as input a set of random samples $(\\mathbf{x}_i,y_i) \\in [-1,1]^n \\times \\mathbb{R}$ that are noisy versions of $(\\mathbf{x}_i,p(\\mathbf{x}_i))$. More precisely, each $\\mathbf{x}_i$ is sampled independently from some distribution $\\chi$ on $[-1,1]^n$, and for each $i$ independently, $y_i$ is arbitrary (i.e., an outlier) with probability at most $\\rho < 1/2$, and otherwise satisfies $|y_i-p(\\mathbf{x}_i)|\\leq\\sigma$. The goal is to output a polynomial $\\hat{p}$, of degree at most $d$ in each variable, within an $\\ell_\\infty$-distance of at most $O(\\sigma)$ from $p$.   Kane, Karmalkar, and Price [FOCS'17] solved this problem for $n=1$. We generalize their results to the $n$-variate setting, showing an algorithm that achieves a sample complexity ",
    "link": "https://arxiv.org/abs/2403.09465",
    "context": "Title: Outlier Robust Multivariate Polynomial Regression\nAbstract: arXiv:2403.09465v1 Announce Type: cross  Abstract: We study the problem of robust multivariate polynomial regression: let $p\\colon\\mathbb{R}^n\\to\\mathbb{R}$ be an unknown $n$-variate polynomial of degree at most $d$ in each variable. We are given as input a set of random samples $(\\mathbf{x}_i,y_i) \\in [-1,1]^n \\times \\mathbb{R}$ that are noisy versions of $(\\mathbf{x}_i,p(\\mathbf{x}_i))$. More precisely, each $\\mathbf{x}_i$ is sampled independently from some distribution $\\chi$ on $[-1,1]^n$, and for each $i$ independently, $y_i$ is arbitrary (i.e., an outlier) with probability at most $\\rho < 1/2$, and otherwise satisfies $|y_i-p(\\mathbf{x}_i)|\\leq\\sigma$. The goal is to output a polynomial $\\hat{p}$, of degree at most $d$ in each variable, within an $\\ell_\\infty$-distance of at most $O(\\sigma)$ from $p$.   Kane, Karmalkar, and Price [FOCS'17] solved this problem for $n=1$. We generalize their results to the $n$-variate setting, showing an algorithm that achieves a sample complexity ",
    "path": "papers/24/03/2403.09465.json",
    "total_tokens": 930,
    "translated_title": "异常值鲁棒的多元多项式回归",
    "translated_abstract": "我们研究了异常值鲁棒的多元多项式回归问题：设$p\\colon\\mathbb{R}^n\\to\\mathbb{R}$是一个未知的在每个变量上至多为$d$次的$n$元多项式。给定一组随机样本$(\\mathbf{x}_i,y_i) \\in [-1,1]^n \\times \\mathbb{R}$，它们是$(\\mathbf{x}_i,p(\\mathbf{x}_i))$的带噪声版本。更具体地，每个$\\mathbf{x}_i$独立地从$[-1,1]^n$上的某个分布$\\chi$中采样，对每个$i$，$y_i$以概率至多$\\rho < 1/2$是任意的（即异常值），否则满足$|y_i-p(\\mathbf{x}_i)|\\leq\\sigma$。目标是输出一个多元多项式$\\hat{p}$，在每个变量上至多为$d$次，在$\\ell_\\infty$范数下与$p$的距离至多为$O(\\sigma)$。",
    "tldr": "将一维的解法推广到多维，提出了一种在多元多项式回归中对异常值具有鲁棒性的算法。",
    "en_tdlr": "Generalizing the one-dimensional solution to multivariate case, an algorithm for robust handling of outliers in multivariate polynomial regression is proposed."
}