{
    "title": "A Channel-ensemble Approach: Unbiased and Low-variance Pseudo-labels is Critical for Semi-supervised Classification",
    "abstract": "arXiv:2403.18407v1 Announce Type: cross  Abstract: Semi-supervised learning (SSL) is a practical challenge in computer vision. Pseudo-label (PL) methods, e.g., FixMatch and FreeMatch, obtain the State Of The Art (SOTA) performances in SSL. These approaches employ a threshold-to-pseudo-label (T2L) process to generate PLs by truncating the confidence scores of unlabeled data predicted by the self-training method. However, self-trained models typically yield biased and high-variance predictions, especially in the scenarios when a little labeled data are supplied. To address this issue, we propose a lightweight channel-based ensemble method to effectively consolidate multiple inferior PLs into the theoretically guaranteed unbiased and low-variance one. Importantly, our approach can be readily extended to any SSL framework, such as FixMatch or FreeMatch. Experimental results demonstrate that our method significantly outperforms state-of-the-art techniques on CIFAR10/100 in terms of effectiv",
    "link": "https://arxiv.org/abs/2403.18407",
    "context": "Title: A Channel-ensemble Approach: Unbiased and Low-variance Pseudo-labels is Critical for Semi-supervised Classification\nAbstract: arXiv:2403.18407v1 Announce Type: cross  Abstract: Semi-supervised learning (SSL) is a practical challenge in computer vision. Pseudo-label (PL) methods, e.g., FixMatch and FreeMatch, obtain the State Of The Art (SOTA) performances in SSL. These approaches employ a threshold-to-pseudo-label (T2L) process to generate PLs by truncating the confidence scores of unlabeled data predicted by the self-training method. However, self-trained models typically yield biased and high-variance predictions, especially in the scenarios when a little labeled data are supplied. To address this issue, we propose a lightweight channel-based ensemble method to effectively consolidate multiple inferior PLs into the theoretically guaranteed unbiased and low-variance one. Importantly, our approach can be readily extended to any SSL framework, such as FixMatch or FreeMatch. Experimental results demonstrate that our method significantly outperforms state-of-the-art techniques on CIFAR10/100 in terms of effectiv",
    "path": "papers/24/03/2403.18407.json",
    "total_tokens": 934,
    "translated_title": "一种通道集成方法：无偏差和低方差的伪标签对半监督分类至关重要",
    "translated_abstract": "半监督学习（SSL）在计算机视觉中是一个实际挑战。伪标签（PL）方法，例如FixMatch和FreeMatch，在SSL中获得了现有技术的最佳性能。这些方法利用阈值到伪标签（T2L）处理通过截断自我训练方法预测的无标签数据的置信度得到PL。然而，自我训练模型通常会产生有偏差和高方差的预测，特别是在提供少量标记数据的情况下。为了解决这个问题，我们提出了一种轻量级基于通道的集成方法，将多个较差的伪标签有效地合并为理论上保证的无偏差和低方差的伪标签。重要的是，我们的方法可以轻松扩展到任何SSL框架，例如FixMatch或FreeMatch。实验结果表明，我们的方法在CIFAR10/100的效果方面显著优于现有技术。",
    "tldr": "通过提出一种轻量级基于通道的集成方法，将多个较差的伪标签有效地合并为理论上保证的无偏差和低方差的一个伪标签，解决半监督学习中自我训练模型产生的有偏差和高方差预测问题。",
    "en_tdlr": "By proposing a lightweight channel-based ensemble method to effectively consolidate multiple inferior pseudo-labels into a theoretically guaranteed unbiased and low-variance one, we address the biased and high-variance predictions issue of self-trained models in semi-supervised learning."
}