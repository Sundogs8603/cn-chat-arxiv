{
    "title": "Optimization on a Finer Scale: Bounded Local Subgradient Variation Perspective",
    "abstract": "arXiv:2403.16317v1 Announce Type: cross  Abstract: We initiate the study of nonsmooth optimization problems under bounded local subgradient variation, which postulates bounded difference between (sub)gradients in small local regions around points, in either average or maximum sense. The resulting class of objective functions encapsulates the classes of objective functions traditionally studied in optimization, which are defined based on either Lipschitz continuity of the objective or H\\\"{o}lder/Lipschitz continuity of its gradient. Further, the defined class contains functions that are neither Lipschitz continuous nor have a H\\\"{o}lder continuous gradient. When restricted to the traditional classes of optimization problems, the parameters defining the studied classes lead to more fine-grained complexity bounds, recovering traditional oracle complexity bounds in the worst case but generally leading to lower oracle complexity for functions that are not ``worst case.'' Some highlights of ",
    "link": "https://arxiv.org/abs/2403.16317",
    "context": "Title: Optimization on a Finer Scale: Bounded Local Subgradient Variation Perspective\nAbstract: arXiv:2403.16317v1 Announce Type: cross  Abstract: We initiate the study of nonsmooth optimization problems under bounded local subgradient variation, which postulates bounded difference between (sub)gradients in small local regions around points, in either average or maximum sense. The resulting class of objective functions encapsulates the classes of objective functions traditionally studied in optimization, which are defined based on either Lipschitz continuity of the objective or H\\\"{o}lder/Lipschitz continuity of its gradient. Further, the defined class contains functions that are neither Lipschitz continuous nor have a H\\\"{o}lder continuous gradient. When restricted to the traditional classes of optimization problems, the parameters defining the studied classes lead to more fine-grained complexity bounds, recovering traditional oracle complexity bounds in the worst case but generally leading to lower oracle complexity for functions that are not ``worst case.'' Some highlights of ",
    "path": "papers/24/03/2403.16317.json",
    "total_tokens": 869,
    "translated_title": "在更细粒度上的优化：有界局部次梯度变化的视角",
    "translated_abstract": "我们在有界局部次梯度变化的条件下开始研究非光滑优化问题，它假设在点附近的小区域内，(次)梯度之间存在有限的差异，可以用平均或最大方式求值。由此产生的目标函数类包括传统优化中传统研究的目标函数类，这些类根据目标函数的Lipschitz连续性或其梯度的H\\\"{o}lder/Lipschitz连续性定义。此外，该定义类包含那些既不是Lipschitz连续的也没有H\\\"{o}lder连续梯度的函数。当限制在传统优化问题类时，定义研究类的参数导致更加精细的复杂性界限，在最坏情况下恢复传统的oracle复杂度界限，但一般情况下会导致那些不是“最坏情况”的函数具有较低的oracle 复杂性。",
    "tldr": "该研究在有界局部次梯度变化的条件下研究非光滑优化问题，提出的目标函数类能帮助更好理解传统优化问题的复杂性，并在一般情况下降低oracle复杂度。",
    "en_tdlr": "This research studies nonsmooth optimization problems under bounded local subgradient variation, proposing a class of objective functions to better understand the complexity of traditional optimization problems and generally reduce oracle complexity."
}