{
    "title": "Caveat Lector: Large Language Models in Legal Practice",
    "abstract": "arXiv:2403.09163v1 Announce Type: new  Abstract: The current fascination with large language models, or LLMs, derives from the fact that many users lack the expertise to evaluate the quality of the generated text. LLMs may therefore appear more capable than they actually are. The dangerous combination of fluency and superficial plausibility leads to the temptation to trust the generated text and creates the risk of overreliance. Who would not trust perfect legalese? Relying recent findings in both technical and legal scholarship, this Article counterbalances the overly optimistic predictions as to the role of LLMs in legal practice. Integrating LLMs into legal workstreams without a better comprehension of their limitations, will create inefficiencies if not outright risks. Notwithstanding their unprecedented ability to generate text, LLMs do not understand text. Without the ability to understand meaning, LLMs will remain unable to use language, to acquire knowledge and to perform compl",
    "link": "https://arxiv.org/abs/2403.09163",
    "context": "Title: Caveat Lector: Large Language Models in Legal Practice\nAbstract: arXiv:2403.09163v1 Announce Type: new  Abstract: The current fascination with large language models, or LLMs, derives from the fact that many users lack the expertise to evaluate the quality of the generated text. LLMs may therefore appear more capable than they actually are. The dangerous combination of fluency and superficial plausibility leads to the temptation to trust the generated text and creates the risk of overreliance. Who would not trust perfect legalese? Relying recent findings in both technical and legal scholarship, this Article counterbalances the overly optimistic predictions as to the role of LLMs in legal practice. Integrating LLMs into legal workstreams without a better comprehension of their limitations, will create inefficiencies if not outright risks. Notwithstanding their unprecedented ability to generate text, LLMs do not understand text. Without the ability to understand meaning, LLMs will remain unable to use language, to acquire knowledge and to perform compl",
    "path": "papers/24/03/2403.09163.json",
    "total_tokens": 819,
    "translated_title": "Caveat Lector：在法律实践中使用大型语言模型",
    "translated_abstract": "当前对大型语言模型（LLMs）的着迷源于许多用户缺乏评估生成文本质量的专业知识。因此，LLMs可能看起来比它们实际上更有能力。流畅性和表面合理性的危险组合导致人们倾向于相信生成的文本，并产生过度依赖的风险。谁不会相信完美的法律用语呢？本文基于最近在技术和法律学术界的发现，对LLMs在法律实践中的作用进行了过分乐观的预测进行了平衡。在没有更好理解其局限性的情况下将LLMs整合到法律工作流程中，将会产生低效甚至直接的风险。尽管它们能够生成文本，但LLMs并不理解文本。没有理解意义的能力，LLMs将无法使用语言，获取知识并执行...",
    "tldr": "LLMs在法律实践中的作用被过分乐观地预测，不理解文本内容会导致依赖风险。",
    "en_tdlr": "The role of LLMs in legal practice is overly optimistically predicted, the lack of understanding of text content leads to reliance risks."
}