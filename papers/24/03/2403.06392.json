{
    "title": "Towards Robust Out-of-Distribution Generalization Bounds via Sharpness",
    "abstract": "arXiv:2403.06392v1 Announce Type: new  Abstract: Generalizing to out-of-distribution (OOD) data or unseen domain, termed OOD generalization, still lacks appropriate theoretical guarantees. Canonical OOD bounds focus on different distance measurements between source and target domains but fail to consider the optimization property of the learned model. As empirically shown in recent work, the sharpness of learned minima influences OOD generalization. To bridge this gap between optimization and OOD generalization, we study the effect of sharpness on how a model tolerates data change in domain shift which is usually captured by \"robustness\" in generalization. In this paper, we give a rigorous connection between sharpness and robustness, which gives better OOD guarantees for robust algorithms. It also provides a theoretical backing for \"flat minima leads to better OOD generalization\". Overall, we propose a sharpness-based OOD generalization bound by taking robustness into consideration, re",
    "link": "https://arxiv.org/abs/2403.06392",
    "context": "Title: Towards Robust Out-of-Distribution Generalization Bounds via Sharpness\nAbstract: arXiv:2403.06392v1 Announce Type: new  Abstract: Generalizing to out-of-distribution (OOD) data or unseen domain, termed OOD generalization, still lacks appropriate theoretical guarantees. Canonical OOD bounds focus on different distance measurements between source and target domains but fail to consider the optimization property of the learned model. As empirically shown in recent work, the sharpness of learned minima influences OOD generalization. To bridge this gap between optimization and OOD generalization, we study the effect of sharpness on how a model tolerates data change in domain shift which is usually captured by \"robustness\" in generalization. In this paper, we give a rigorous connection between sharpness and robustness, which gives better OOD guarantees for robust algorithms. It also provides a theoretical backing for \"flat minima leads to better OOD generalization\". Overall, we propose a sharpness-based OOD generalization bound by taking robustness into consideration, re",
    "path": "papers/24/03/2403.06392.json",
    "total_tokens": 906,
    "translated_title": "通过尖锐度实现健壮的出域泛化界限",
    "translated_abstract": "对于对于领域之外（OOD）数据或未见过的领域进行泛化，即OOD泛化，仍然缺乏适当的理论保证。传统的OOD界限关注源领域和目标领域之间的不同距离测量，但未考虑学习模型的优化特性。我们研究了学习的极小值的尖锐度对模型在领域转移中承受数据变化的影响，这通常由泛化中的\"鲁棒性\"来捕获。本文提出了尖锐度和鲁棒性之间的严格联系，为鲁棒算法提供了更好的OOD保证。论文提供了\"平坦极小值导致更好的OOD泛化\"的理论支持。总体而言，我们通过考虑鲁棒性提出了基于尖锐度的OOD泛化界限。",
    "tldr": "本文研究了学习的极小值的尖锐度如何影响模型对领域转移中数据变化的容忍度，并建立了尖锐度和鲁棒性之间的严格联系，提出了基于尖锐度的OOD泛化界限，为鲁棒算法提供了更好的OOD保证。"
}