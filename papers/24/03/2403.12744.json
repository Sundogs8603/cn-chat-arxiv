{
    "title": "Instructing Large Language Models to Identify and Ignore Irrelevant Conditions",
    "abstract": "arXiv:2403.12744v1 Announce Type: new  Abstract: Math word problem (MWP) solving requires generating a reasoning path based on a given problem description that often contains irrelevant conditions. Existing chain-of-thought (CoT) prompting methods elicited multi-step reasoning abilities of large language models (LLMs) to solve MWPs. However, they were seriously confused by the irrelevant conditions, resulting in low accuracy. In this paper, we propose a novel approach named I$^3$C that instructs LLMs to identify and ignore irrelevant conditions. It identifies a set of irrelevant condition candidates that have a weak semantic relevance with the question. Then it prompts LLMs to verify the irrelevant conditions. Lastly it instructs the LLMs with the verification on relevant and irrelevant conditions to avoid confusion and improve reasoning paths. Moreover, we propose to select (problem, reasoning paths) pairs as demonstrations to enhance I$^3$C with few-shot reasoning. We develop I$^3$C-",
    "link": "https://arxiv.org/abs/2403.12744",
    "context": "Title: Instructing Large Language Models to Identify and Ignore Irrelevant Conditions\nAbstract: arXiv:2403.12744v1 Announce Type: new  Abstract: Math word problem (MWP) solving requires generating a reasoning path based on a given problem description that often contains irrelevant conditions. Existing chain-of-thought (CoT) prompting methods elicited multi-step reasoning abilities of large language models (LLMs) to solve MWPs. However, they were seriously confused by the irrelevant conditions, resulting in low accuracy. In this paper, we propose a novel approach named I$^3$C that instructs LLMs to identify and ignore irrelevant conditions. It identifies a set of irrelevant condition candidates that have a weak semantic relevance with the question. Then it prompts LLMs to verify the irrelevant conditions. Lastly it instructs the LLMs with the verification on relevant and irrelevant conditions to avoid confusion and improve reasoning paths. Moreover, we propose to select (problem, reasoning paths) pairs as demonstrations to enhance I$^3$C with few-shot reasoning. We develop I$^3$C-",
    "path": "papers/24/03/2403.12744.json",
    "total_tokens": 808,
    "translated_title": "指导大型语言模型识别和忽略不相关条件",
    "translated_abstract": "数学问题解决需要根据给定的问题描述生成推理路径，而这个描述通常包含不相关的条件。现有的“chain-of-thought”(CoT)提示方法引出了大型语言模型(LLMs)的多步推理能力来解决数学问题。然而，它们常常被不相关的条件严重困扰，导致准确性不高。在这篇论文中，我们提出了一种名为I$^3$C的新方法，指导LLMs识别和忽略不相关条件。它确定了一组与问题的语义关联较弱的不相关条件候选集。然后提示LLMs验证不相关条件。最后，通过关于相关和不相关条件的验证指导LLMs，避免混淆并提高推理路径。此外，我们建议选择(问题，推理路径)对作为示范，以增强I$^3$C的少样本推理。",
    "tldr": "提出了一种新方法 I$^3$C，指导大型语言模型识别和忽略不相关条件，并通过少样本推理加以增强。",
    "en_tdlr": "Introducing a novel approach I$^3$C to instruct large language models to identify and ignore irrelevant conditions, enhanced with few-shot reasoning."
}