{
    "title": "E2F-Net: Eyes-to-Face Inpainting via StyleGAN Latent Space",
    "abstract": "arXiv:2403.12197v1 Announce Type: cross  Abstract: Face inpainting, the technique of restoring missing or damaged regions in facial images, is pivotal for applications like face recognition in occluded scenarios and image analysis with poor-quality captures. This process not only needs to produce realistic visuals but also preserve individual identity characteristics. The aim of this paper is to inpaint a face given periocular region (eyes-to-face) through a proposed new Generative Adversarial Network (GAN)-based model called Eyes-to-Face Network (E2F-Net). The proposed approach extracts identity and non-identity features from the periocular region using two dedicated encoders have been used. The extracted features are then mapped to the latent space of a pre-trained StyleGAN generator to benefit from its state-of-the-art performance and its rich, diverse and expressive latent space without any additional training. We further improve the StyleGAN output to find the optimal code in the ",
    "link": "https://arxiv.org/abs/2403.12197",
    "context": "Title: E2F-Net: Eyes-to-Face Inpainting via StyleGAN Latent Space\nAbstract: arXiv:2403.12197v1 Announce Type: cross  Abstract: Face inpainting, the technique of restoring missing or damaged regions in facial images, is pivotal for applications like face recognition in occluded scenarios and image analysis with poor-quality captures. This process not only needs to produce realistic visuals but also preserve individual identity characteristics. The aim of this paper is to inpaint a face given periocular region (eyes-to-face) through a proposed new Generative Adversarial Network (GAN)-based model called Eyes-to-Face Network (E2F-Net). The proposed approach extracts identity and non-identity features from the periocular region using two dedicated encoders have been used. The extracted features are then mapped to the latent space of a pre-trained StyleGAN generator to benefit from its state-of-the-art performance and its rich, diverse and expressive latent space without any additional training. We further improve the StyleGAN output to find the optimal code in the ",
    "path": "papers/24/03/2403.12197.json",
    "total_tokens": 745,
    "translated_title": "E2F-Net: 通过StyleGAN潜空间进行眼睛到脸部修复的工作",
    "translated_abstract": "人脸修复是一种技术，用于恢复缺失或受损的面部图像区域，在遮挡情景下的人脸识别和质量差的图像分析等应用中至关重要。本文的目的是通过一种新的基于生成对抗网络（GAN）模型，即Eyes-to-Face Network（E2F-Net），修复给定的眼部区域并完成人脸修复。",
    "tldr": "本文提出了一种基于GAN的模型，E2F-Net，通过显著提取眼部区域的身份和非身份特征，并将其映射到预训练的StyleGAN生成器的潜空间，实现了眼睛到脸部的修复。",
    "en_tdlr": "The paper introduces a GAN-based model, E2F-Net, which significantly extracts identity and non-identity features from the periocular region and maps them to the latent space of a pre-trained StyleGAN generator, achieving eyes-to-face inpainting."
}