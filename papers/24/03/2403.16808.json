{
    "title": "Navigating the EU AI Act: A Methodological Approach to Compliance for Safety-critical Products",
    "abstract": "arXiv:2403.16808v1 Announce Type: new  Abstract: In December 2023, the European Parliament provisionally agreed on the EU AI Act. This unprecedented regulatory framework for AI systems lays out guidelines to ensure the safety, legality, and trustworthiness of AI products. This paper presents a methodology for interpreting the EU AI Act requirements for high-risk AI systems by leveraging product quality models. We first propose an extended product quality model for AI systems, incorporating attributes relevant to the Act not covered by current quality models. We map the Act requirements to relevant quality attributes with the goal of refining them into measurable characteristics. We then propose a contract-based approach to derive technical requirements at the stakeholder level. This facilitates the development and assessment of AI systems that not only adhere to established quality standards, but also comply with the regulatory requirements outlined in the Act for high-risk (including ",
    "link": "https://arxiv.org/abs/2403.16808",
    "context": "Title: Navigating the EU AI Act: A Methodological Approach to Compliance for Safety-critical Products\nAbstract: arXiv:2403.16808v1 Announce Type: new  Abstract: In December 2023, the European Parliament provisionally agreed on the EU AI Act. This unprecedented regulatory framework for AI systems lays out guidelines to ensure the safety, legality, and trustworthiness of AI products. This paper presents a methodology for interpreting the EU AI Act requirements for high-risk AI systems by leveraging product quality models. We first propose an extended product quality model for AI systems, incorporating attributes relevant to the Act not covered by current quality models. We map the Act requirements to relevant quality attributes with the goal of refining them into measurable characteristics. We then propose a contract-based approach to derive technical requirements at the stakeholder level. This facilitates the development and assessment of AI systems that not only adhere to established quality standards, but also comply with the regulatory requirements outlined in the Act for high-risk (including ",
    "path": "papers/24/03/2403.16808.json",
    "total_tokens": 801,
    "translated_title": "理解欧盟AI法案: 合规安全关键产品的方法论途径",
    "translated_abstract": "2023年12月，欧洲议会暂时同意了欧盟AI法案。这一前所未有的AI系统监管框架制定了确保AI产品安全、合法和值得信赖的指导方针。本文提出了一种方法，通过利用产品质量模型来解释高风险AI系统在欧盟AI法案下的要求。我们首先提出了一个扩展的AI系统产品质量模型，将法案中未涵盖的相关属性纳入考虑。我们将法案要求与相关质量属性进行映射，目的是将其细化为可衡量的特征。然后，我们提出了一种基于合同的方法，从利益相关者层面推导技术要求。这有助于开发和评估不仅符合已建立质量标准，而且符合法案中针对高风险（包括",
    "tldr": "通过利用产品质量模型和合同法方法，本文提出了一种解释欧盟AI法案对高风险AI系统要求的方法论途径。"
}