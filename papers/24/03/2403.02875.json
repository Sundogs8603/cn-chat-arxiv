{
    "title": "Enhancing Conceptual Understanding in Multimodal Contrastive Learning through Hard Negative Samples",
    "abstract": "arXiv:2403.02875v1 Announce Type: cross  Abstract: Current multimodal models leveraging contrastive learning often face limitations in developing fine-grained conceptual understanding. This is due to random negative samples during pretraining, causing almost exclusively very dissimilar concepts to be compared in the loss function. Consequently, the models struggle with fine-grained semantic differences. To address this problem, we introduce a novel pretraining method incorporating synthetic hard negative text examples. The hard negatives permute terms corresponding to visual concepts, leading to a more fine-grained visual and textual concept alignment. Further, we introduce InpaintCOCO, a new challenging dataset for assessing the fine-grained alignment of colors, objects, and sizes in vision-language models. We created the dataset using generative inpainting from COCO images by changing the visual concepts so that the images no longer match their original captions. Our results show sig",
    "link": "https://arxiv.org/abs/2403.02875",
    "context": "Title: Enhancing Conceptual Understanding in Multimodal Contrastive Learning through Hard Negative Samples\nAbstract: arXiv:2403.02875v1 Announce Type: cross  Abstract: Current multimodal models leveraging contrastive learning often face limitations in developing fine-grained conceptual understanding. This is due to random negative samples during pretraining, causing almost exclusively very dissimilar concepts to be compared in the loss function. Consequently, the models struggle with fine-grained semantic differences. To address this problem, we introduce a novel pretraining method incorporating synthetic hard negative text examples. The hard negatives permute terms corresponding to visual concepts, leading to a more fine-grained visual and textual concept alignment. Further, we introduce InpaintCOCO, a new challenging dataset for assessing the fine-grained alignment of colors, objects, and sizes in vision-language models. We created the dataset using generative inpainting from COCO images by changing the visual concepts so that the images no longer match their original captions. Our results show sig",
    "path": "papers/24/03/2403.02875.json",
    "total_tokens": 872,
    "translated_title": "通过硬负样本增强多模态对比学习中的概念理解",
    "translated_abstract": "当前利用对比学习的多模态模型在发展精细的概念理解方面通常存在一些限制。在预训练过程中，由于随机负样本，导致几乎只有非常不同的概念进行损失函数比较。因此，模型在处理细粒度语义差异时遇到困难。为了解决这个问题，我们引入了一种新颖的预训练方法，结合了合成的硬负文本示例。这些硬负样本对应于视觉概念的排列，导致更精细的视觉和文本概念对齐。此外，我们引入了InpaintCOCO，一个用于评估视觉-语言模型中颜色、对象和大小细粒度对齐的新挑战性数据集。我们使用从COCO图像生成的信息填充来创建数据集，通过改变视觉概念，使图像不再与其原始标题匹配。我们的结果显示...",
    "tldr": "提出了一种通过硬负样本改进多模态对比学习中概念理解的方法，并引入了一个评估视觉-语言模型中颜色、对象和大小细粒度对齐的新数据集。",
    "en_tdlr": "Proposed a method to enhance conceptual understanding in multimodal contrastive learning through hard negative samples and introduced a new dataset for evaluating fine-grained alignment of colors, objects, and sizes in vision-language models."
}