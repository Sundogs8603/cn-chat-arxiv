{
    "title": "German also Hallucinates! Inconsistency Detection in News Summaries with the Absinth Dataset",
    "abstract": "arXiv:2403.03750v1 Announce Type: cross  Abstract: The advent of Large Language Models (LLMs) has led to remarkable progress on a wide range of natural language processing tasks. Despite the advances, these large-sized models still suffer from hallucinating information in their output, which poses a major issue in automatic text summarization, as we must guarantee that the generated summary is consistent with the content of the source document. Previous research addresses the challenging task of detecting hallucinations in the output (i.e. inconsistency detection) in order to evaluate the faithfulness of the generated summaries. However, these works primarily focus on English and recent multilingual approaches lack German data. This work presents absinth, a manually annotated dataset for hallucination detection in German news summarization and explores the capabilities of novel open-source LLMs on this task in both fine-tuning and in-context learning settings. We open-source and releas",
    "link": "https://arxiv.org/abs/2403.03750",
    "context": "Title: German also Hallucinates! Inconsistency Detection in News Summaries with the Absinth Dataset\nAbstract: arXiv:2403.03750v1 Announce Type: cross  Abstract: The advent of Large Language Models (LLMs) has led to remarkable progress on a wide range of natural language processing tasks. Despite the advances, these large-sized models still suffer from hallucinating information in their output, which poses a major issue in automatic text summarization, as we must guarantee that the generated summary is consistent with the content of the source document. Previous research addresses the challenging task of detecting hallucinations in the output (i.e. inconsistency detection) in order to evaluate the faithfulness of the generated summaries. However, these works primarily focus on English and recent multilingual approaches lack German data. This work presents absinth, a manually annotated dataset for hallucination detection in German news summarization and explores the capabilities of novel open-source LLMs on this task in both fine-tuning and in-context learning settings. We open-source and releas",
    "path": "papers/24/03/2403.03750.json",
    "total_tokens": 735,
    "translated_title": "德语也产生幻觉！使用Absinth数据集检测新闻摘要中的不一致性",
    "translated_abstract": "大型语言模型（LLMs）的出现在自然语言处理任务中取得了显著进展，然而，这些大型模型仍然存在产生信息幻觉的问题，这在自动文本摘要中至关重要。先前的研究主要集中在英语上，并且最近的多语言方法缺乏德语数据。本文提出了absinth，一个用于德语新闻摘要中幻觉检测的手动注释数据集，并探讨了新型开源LLMs在这一任务上的能力，包括微调和上下文学习设置。我们开源并发布了这个数据集。",
    "tldr": "本文提出了一个用于德语新闻摘要中幻觉检测的数据集absinth，探讨了LLMs在该任务中的应用。"
}