{
    "title": "uaMix-MAE: Efficient Tuning of Pretrained Audio Transformers with Unsupervised Audio Mixtures",
    "abstract": "arXiv:2403.09579v1 Announce Type: cross  Abstract: Masked Autoencoders (MAEs) learn rich low-level representations from unlabeled data but require substantial labeled data to effectively adapt to downstream tasks. Conversely, Instance Discrimination (ID) emphasizes high-level semantics, offering a potential solution to alleviate annotation requirements in MAEs. Although combining these two approaches can address downstream tasks with limited labeled data, naively integrating ID into MAEs leads to extended training times and high computational costs. To address this challenge, we introduce uaMix-MAE, an efficient ID tuning strategy that leverages unsupervised audio mixtures. Utilizing contrastive tuning, uaMix-MAE aligns the representations of pretrained MAEs, thereby facilitating effective adaptation to task-specific semantics. To optimize the model with small amounts of unlabeled data, we propose an audio mixing technique that manipulates audio samples in both input and virtual label ",
    "link": "https://arxiv.org/abs/2403.09579",
    "context": "Title: uaMix-MAE: Efficient Tuning of Pretrained Audio Transformers with Unsupervised Audio Mixtures\nAbstract: arXiv:2403.09579v1 Announce Type: cross  Abstract: Masked Autoencoders (MAEs) learn rich low-level representations from unlabeled data but require substantial labeled data to effectively adapt to downstream tasks. Conversely, Instance Discrimination (ID) emphasizes high-level semantics, offering a potential solution to alleviate annotation requirements in MAEs. Although combining these two approaches can address downstream tasks with limited labeled data, naively integrating ID into MAEs leads to extended training times and high computational costs. To address this challenge, we introduce uaMix-MAE, an efficient ID tuning strategy that leverages unsupervised audio mixtures. Utilizing contrastive tuning, uaMix-MAE aligns the representations of pretrained MAEs, thereby facilitating effective adaptation to task-specific semantics. To optimize the model with small amounts of unlabeled data, we propose an audio mixing technique that manipulates audio samples in both input and virtual label ",
    "path": "papers/24/03/2403.09579.json",
    "total_tokens": 792,
    "translated_title": "uaMix-MAE: 使用无监督音频混合高效调整预训练音频Transformer",
    "translated_abstract": "掩码自编码器（MAEs）能够从无标注数据中学习丰富的低级表示，但需要大量有标注数据才能有效地适应下游任务。而实例区分（ID）则强调高级语义，为减轻MAEs中的注释需求提供了潜在解决方案。本文介绍了一种称为uaMix-MAE的高效ID调整策略，利用无监督音频混合。通过对比调整，uaMix-MAE使预训练MAEs的表示对齐，从而促进有效地适应特定任务语义。为了在小量无标注数据优化模型，我们提出了一种音频混合技术，可以在输入和虚拟标签中操作音频样本。",
    "tldr": "uaMix-MAE提出了一种高效的ID调整策略，利用无监督音频混合对预训练的MAEs进行对比调整，从而有效地适应特定任务语义。",
    "en_tdlr": "uaMix-MAE introduces an efficient ID tuning strategy that leverages unsupervised audio mixtures to align the representations of pretrained MAEs for effective adaptation to task-specific semantics."
}