{
    "title": "Towards a Framework for Evaluating Explanations in Automated Fact Verification",
    "abstract": "arXiv:2403.20322v1 Announce Type: new  Abstract: As deep neural models in NLP become more complex, and as a consequence opaque, the necessity to interpret them becomes greater. A burgeoning interest has emerged in rationalizing explanations to provide short and coherent justifications for predictions. In this position paper, we advocate for a formal framework for key concepts and properties about rationalizing explanations to support their evaluation systematically. We also outline one such formal framework, tailored to rationalizing explanations of increasingly complex structures, from free-form explanations to deductive explanations, to argumentative explanations (with the richest structure). Focusing on the automated fact verification task, we provide illustrations of the use and usefulness of our formalization for evaluating explanations, tailored to their varying structures.",
    "link": "https://arxiv.org/abs/2403.20322",
    "context": "Title: Towards a Framework for Evaluating Explanations in Automated Fact Verification\nAbstract: arXiv:2403.20322v1 Announce Type: new  Abstract: As deep neural models in NLP become more complex, and as a consequence opaque, the necessity to interpret them becomes greater. A burgeoning interest has emerged in rationalizing explanations to provide short and coherent justifications for predictions. In this position paper, we advocate for a formal framework for key concepts and properties about rationalizing explanations to support their evaluation systematically. We also outline one such formal framework, tailored to rationalizing explanations of increasingly complex structures, from free-form explanations to deductive explanations, to argumentative explanations (with the richest structure). Focusing on the automated fact verification task, we provide illustrations of the use and usefulness of our formalization for evaluating explanations, tailored to their varying structures.",
    "path": "papers/24/03/2403.20322.json",
    "total_tokens": 780,
    "translated_title": "在自动事实验证中评估解释的框架",
    "translated_abstract": "随着自然语言处理中的深度神经模型变得越来越复杂，也因此变得不透明，解释它们的必要性变得更为重要。越来越多的人对理性化解释产生了兴趣，以提供对预测的简短和连贯的理由。在这篇立场论文中，我们倡导一个形式化框架，用于关于理性化解释的关键概念和属性，以支持系统地评估它们。我们还概述了一个这样的形式化框架，定制于越来越复杂结构的理性化解释，从自由形式的解释到演绎性解释，再到具有最丰富结构的论证性解释。我们聚焦于自动事实验证任务，提供了使用我们的形式化评估解释的示例及其实用性，针对不同结构做出了定制。",
    "tldr": "倡导并提出了一个形式化框架，用于系统评估理性化解释，针对自动事实验证任务中不同结构的解释提供了一套评估方法",
    "en_tdlr": "Advocating for a formal framework for systematically evaluating rationalizing explanations, tailored to different structures of explanations in the task of automated fact verification."
}