{
    "title": "Generalized Multi-Source Inference for Text Conditioned Music Diffusion Models",
    "abstract": "arXiv:2403.11706v1 Announce Type: cross  Abstract: Multi-Source Diffusion Models (MSDM) allow for compositional musical generation tasks: generating a set of coherent sources, creating accompaniments, and performing source separation. Despite their versatility, they require estimating the joint distribution over the sources, necessitating pre-separated musical data, which is rarely available, and fixing the number and type of sources at training time. This paper generalizes MSDM to arbitrary time-domain diffusion models conditioned on text embeddings. These models do not require separated data as they are trained on mixtures, can parameterize an arbitrary number of sources, and allow for rich semantic control. We propose an inference procedure enabling the coherent generation of sources and accompaniments. Additionally, we adapt the Dirac separator of MSDM to perform source separation. We experiment with diffusion models trained on Slakh2100 and MTG-Jamendo, showcasing competitive gene",
    "link": "https://arxiv.org/abs/2403.11706",
    "context": "Title: Generalized Multi-Source Inference for Text Conditioned Music Diffusion Models\nAbstract: arXiv:2403.11706v1 Announce Type: cross  Abstract: Multi-Source Diffusion Models (MSDM) allow for compositional musical generation tasks: generating a set of coherent sources, creating accompaniments, and performing source separation. Despite their versatility, they require estimating the joint distribution over the sources, necessitating pre-separated musical data, which is rarely available, and fixing the number and type of sources at training time. This paper generalizes MSDM to arbitrary time-domain diffusion models conditioned on text embeddings. These models do not require separated data as they are trained on mixtures, can parameterize an arbitrary number of sources, and allow for rich semantic control. We propose an inference procedure enabling the coherent generation of sources and accompaniments. Additionally, we adapt the Dirac separator of MSDM to perform source separation. We experiment with diffusion models trained on Slakh2100 and MTG-Jamendo, showcasing competitive gene",
    "path": "papers/24/03/2403.11706.json",
    "total_tokens": 790,
    "translated_title": "通用文本条件音乐扩散模型的多源推断",
    "translated_abstract": "多源扩散模型（MSDM）用于音乐生成任务：生成一组连贯的源，创建伴奏以及执行源分离。本文将MSDM推广到条件于文本嵌入的任意时间域扩散模型。这些模型不需要分离的数据，可以对任意数量的源进行参数化，并允许丰富的语义控制。我们提出了一种推理过程，可以实现源和伴奏的连贯生成。此外，我们调整了MSDM的Dirac分隔器以执行源分离。我们实验了在Slakh2100和MTG-Jamendo上训练的扩散模型，展示了有竞争力的性能。",
    "tldr": "本文将多源扩散模型（MSDM）推广到任意时间域扩散模型，并引入文本嵌入条件，实现了不需要分离数据训练，可以参数化任意数量源，并实现丰富语义控制的音乐生成模型。",
    "en_tdlr": "This paper generalizes Multi-Source Diffusion Models (MSDM) to arbitrary time-domain diffusion models conditioned on text embeddings, enabling training without separated data, parameterization of arbitrary number of sources, and rich semantic control in music generation."
}