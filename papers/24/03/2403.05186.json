{
    "title": "ROUGE-K: Do Your Summaries Have Keywords?",
    "abstract": "arXiv:2403.05186v1 Announce Type: new  Abstract: Keywords, that is, content-relevant words in summaries play an important role in efficient information conveyance, making it critical to assess if system-generated summaries contain such informative words during evaluation. However, existing evaluation metrics for extreme summarization models do not pay explicit attention to keywords in summaries, leaving developers ignorant of their presence. To address this issue, we present a keyword-oriented evaluation metric, dubbed ROUGE-K, which provides a quantitative answer to the question of -- \\textit{How well do summaries include keywords?} Through the lens of this keyword-aware metric, we surprisingly find that a current strong baseline model often misses essential information in their summaries. Our analysis reveals that human annotators indeed find the summaries with more keywords to be more relevant to the source documents. This is an important yet previously overlooked aspect in evaluati",
    "link": "https://arxiv.org/abs/2403.05186",
    "context": "Title: ROUGE-K: Do Your Summaries Have Keywords?\nAbstract: arXiv:2403.05186v1 Announce Type: new  Abstract: Keywords, that is, content-relevant words in summaries play an important role in efficient information conveyance, making it critical to assess if system-generated summaries contain such informative words during evaluation. However, existing evaluation metrics for extreme summarization models do not pay explicit attention to keywords in summaries, leaving developers ignorant of their presence. To address this issue, we present a keyword-oriented evaluation metric, dubbed ROUGE-K, which provides a quantitative answer to the question of -- \\textit{How well do summaries include keywords?} Through the lens of this keyword-aware metric, we surprisingly find that a current strong baseline model often misses essential information in their summaries. Our analysis reveals that human annotators indeed find the summaries with more keywords to be more relevant to the source documents. This is an important yet previously overlooked aspect in evaluati",
    "path": "papers/24/03/2403.05186.json",
    "total_tokens": 872,
    "translated_title": "ROUGE-K：您的摘要包含关键词吗？",
    "translated_abstract": "关键词，在摘要中指的是与内容相关的关键词，在有效传达信息方面起着重要作用，因此在评估中检查系统生成的摘要是否包含这些信息性关键词至关重要。然而，现有极端摘要模型的评估指标并未明确关注摘要中的关键词，使开发人员对其是否存在毫无所知。为解决这一问题，我们提出了一种关键词导向的评估指标，称为ROUGE-K，它提供了一个定量答案来回答关于“摘要中关键词包含得如何”的问题。通过这一关键词感知度指标的视角，我们惊讶地发现目前的强基线模型经常在摘要中漏掉关键信息。我们的分析揭示，人类注释员确实发现包含更多关键词的摘要与源文件更相关。这是评估中一个重要但之前被忽视的方面。",
    "tldr": "ROUGE-K是一种关键词导向的评估指标，通过量化回答摘要是否包含关键词这一问题，研究发现当前强基线模型在摘要中经常遗漏关键信息，人类注释员觉得包含更多关键词的摘要更相关。",
    "en_tdlr": "ROUGE-K is a keyword-oriented evaluation metric that quantitatively answers the question of whether summaries contain keywords. The study found that the current strong baseline model often misses essential information in summaries, and human annotators perceive summaries with more keywords as more relevant."
}