{
    "title": "Contextual Moral Value Alignment Through Context-Based Aggregation",
    "abstract": "arXiv:2403.12805v1 Announce Type: new  Abstract: Developing value-aligned AI agents is a complex undertaking and an ongoing challenge in the field of AI. Specifically within the domain of Large Language Models (LLMs), the capability to consolidate multiple independently trained dialogue agents, each aligned with a distinct moral value, into a unified system that can adapt to and be aligned with multiple moral values is of paramount importance. In this paper, we propose a system that does contextual moral value alignment based on contextual aggregation. Here, aggregation is defined as the process of integrating a subset of LLM responses that are best suited to respond to a user input, taking into account features extracted from the user's input. The proposed system shows better results in term of alignment to human value compared to the state of the art.",
    "link": "https://arxiv.org/abs/2403.12805",
    "context": "Title: Contextual Moral Value Alignment Through Context-Based Aggregation\nAbstract: arXiv:2403.12805v1 Announce Type: new  Abstract: Developing value-aligned AI agents is a complex undertaking and an ongoing challenge in the field of AI. Specifically within the domain of Large Language Models (LLMs), the capability to consolidate multiple independently trained dialogue agents, each aligned with a distinct moral value, into a unified system that can adapt to and be aligned with multiple moral values is of paramount importance. In this paper, we propose a system that does contextual moral value alignment based on contextual aggregation. Here, aggregation is defined as the process of integrating a subset of LLM responses that are best suited to respond to a user input, taking into account features extracted from the user's input. The proposed system shows better results in term of alignment to human value compared to the state of the art.",
    "path": "papers/24/03/2403.12805.json",
    "total_tokens": 735,
    "translated_title": "基于上下文的聚合实现情境道德价值对齐",
    "translated_abstract": "开发价值对齐的人工智能代理是人工智能领域一个复杂而持续挑战。特别是在大型语言模型（LLMs）领域，将多个独立训练的对话代理整合为一个统一系统，使其能够适应并与多个道德价值对齐，具有至关重要的意义。本文提出了一个基于情境聚合的情境道德价值对齐系统。在该系统中，聚合被定义为整合适合回复用户输入的LLM响应子集的过程，考虑了从用户输入中提取出的特征。所提出的系统在与人类价值对齐方面取得了比现有技术更好的结果。",
    "tldr": "提出了一个基于情境聚合的情境道德价值对齐系统，相比现有技术，在与人类价值对齐方面表现更好。",
    "en_tdlr": "Proposed a system for contextual moral value alignment based on contextual aggregation, showing better alignment to human value compared to the state of the art."
}