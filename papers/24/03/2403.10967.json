{
    "title": "Dreaming of Many Worlds: Learning Contextual World Models Aids Zero-Shot Generalization",
    "abstract": "arXiv:2403.10967v1 Announce Type: cross  Abstract: Zero-shot generalization (ZSG) to unseen dynamics is a major challenge for creating generally capable embodied agents. To address the broader challenge, we start with the simpler setting of contextual reinforcement learning (cRL), assuming observability of the context values that parameterize the variation in the system's dynamics, such as the mass or dimensions of a robot, without making further simplifying assumptions about the observability of the Markovian state. Toward the goal of ZSG to unseen variation in context, we propose the contextual recurrent state-space model (cRSSM), which introduces changes to the world model of the Dreamer (v3) (Hafner et al., 2023). This allows the world model to incorporate context for inferring latent Markovian states from the observations and modeling the latent dynamics. Our experiments show that such systematic incorporation of the context improves the ZSG of the policies trained on the ``dreams",
    "link": "https://arxiv.org/abs/2403.10967",
    "context": "Title: Dreaming of Many Worlds: Learning Contextual World Models Aids Zero-Shot Generalization\nAbstract: arXiv:2403.10967v1 Announce Type: cross  Abstract: Zero-shot generalization (ZSG) to unseen dynamics is a major challenge for creating generally capable embodied agents. To address the broader challenge, we start with the simpler setting of contextual reinforcement learning (cRL), assuming observability of the context values that parameterize the variation in the system's dynamics, such as the mass or dimensions of a robot, without making further simplifying assumptions about the observability of the Markovian state. Toward the goal of ZSG to unseen variation in context, we propose the contextual recurrent state-space model (cRSSM), which introduces changes to the world model of the Dreamer (v3) (Hafner et al., 2023). This allows the world model to incorporate context for inferring latent Markovian states from the observations and modeling the latent dynamics. Our experiments show that such systematic incorporation of the context improves the ZSG of the policies trained on the ``dreams",
    "path": "papers/24/03/2403.10967.json",
    "total_tokens": 863,
    "translated_title": "梦想中的许多世界：学习上下文世界模型有助于零样点泛化",
    "translated_abstract": "零样点泛化（Zero-shot generalization，ZSG）到未见过的动态对于创建具有普遍能力的体系代理是一个重大挑战。为了解决更广泛的挑战，我们从上下文强化学习（contextual reinforcement learning，cRL）的简单设置开始，假设可观察到参数化系统动态变化的上下文值，如机器人的质量或尺寸，而不对马尔可夫状态的可观察性做进一步简化假设。为了实现对未知上下文变化的ZSG目标，我们提出了上下文循环状态空间模型（contextual recurrent state-space model，cRSSM），它对Dreamer（v3）（Hafner等人，2023年）的世界模型进行了修改，使得世界模型可以融入上下文以从观察中推断潜在的马尔可夫状态并建模潜在动态。我们的实验表明，这种系统性地将上下文纳入其中提高了在“梦境”训练的策略的ZSG能力。",
    "tldr": "学习上下文世界模型有助于提高在未知上下文下的零样点泛化能力。",
    "en_tdlr": "Learning contextual world models improves zero-shot generalization in unknown contexts."
}