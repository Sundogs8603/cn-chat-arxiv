{
    "title": "SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with Auto-Generated Data",
    "abstract": "arXiv:2403.06952v1 Announce Type: cross  Abstract: Recent text-to-image (T2I) generation models have demonstrated impressive capabilities in creating images from text descriptions. However, these T2I generation models often fall short of generating images that precisely match the details of the text inputs, such as incorrect spatial relationship or missing objects. In this paper, we introduce SELMA: Skill-Specific Expert Learning and Merging with Auto-Generated Data, a novel paradigm to improve the faithfulness of T2I models by fine-tuning models on automatically generated, multi-skill image-text datasets, with skill-specific expert learning and merging. First, SELMA leverages an LLM's in-context learning capability to generate multiple datasets of text prompts that can teach different skills, and then generates the images with a T2I model based on the prompts. Next, SELMA adapts the T2I model to the new skills by learning multiple single-skill LoRA (low-rank adaptation) experts follow",
    "link": "https://arxiv.org/abs/2403.06952",
    "context": "Title: SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with Auto-Generated Data\nAbstract: arXiv:2403.06952v1 Announce Type: cross  Abstract: Recent text-to-image (T2I) generation models have demonstrated impressive capabilities in creating images from text descriptions. However, these T2I generation models often fall short of generating images that precisely match the details of the text inputs, such as incorrect spatial relationship or missing objects. In this paper, we introduce SELMA: Skill-Specific Expert Learning and Merging with Auto-Generated Data, a novel paradigm to improve the faithfulness of T2I models by fine-tuning models on automatically generated, multi-skill image-text datasets, with skill-specific expert learning and merging. First, SELMA leverages an LLM's in-context learning capability to generate multiple datasets of text prompts that can teach different skills, and then generates the images with a T2I model based on the prompts. Next, SELMA adapts the T2I model to the new skills by learning multiple single-skill LoRA (low-rank adaptation) experts follow",
    "path": "papers/24/03/2403.06952.json",
    "total_tokens": 863,
    "translated_title": "SELMA：学习和合并具有自动生成数据的技能特定文本到图像专家",
    "translated_abstract": "最近，文本到图像（T2I）生成模型展示了从文本描述中创建图像的令人印象深刻的能力。然而，这些T2I生成模型在生成精确匹配文本输入细节的图像方面经常表现不佳，比如不正确的空间关系或缺失对象。在本文中，我们介绍了SELMA：具有自动生成数据的技能特定专家学习和合并，这是一种改进T2I模型忠实度的新范式，通过在自动生成的多技能图像文本数据集上微调模型，并进行技能特定专家学习和合并。首先，SELMA利用LLM的环境学习能力生成多个文本提示数据集，可以教授不同的技能，然后基于提示使用T2I模型生成图像。接下来，SELMA通过学习多个单技能的LoRA（低秩调整）专家调整T2I模型到新技能。",
    "tldr": "SELMA提出了一种新范式，通过在自动生成的多技能图像文本数据集上微调模型，并进行技能特定专家学习和合并，从而改进T2I模型的忠实度。",
    "en_tdlr": "SELMA introduces a novel paradigm to improve the faithfulness of T2I models by fine-tuning models on automatically generated, multi-skill image-text datasets, with skill-specific expert learning and merging."
}