{
    "title": "A Moral Imperative: The Need for Continual Superalignment of Large Language Models",
    "abstract": "arXiv:2403.14683v1 Announce Type: cross  Abstract: This paper examines the challenges associated with achieving life-long superalignment in AI systems, particularly large language models (LLMs). Superalignment is a theoretical framework that aspires to ensure that superintelligent AI systems act in accordance with human values and goals. Despite its promising vision, we argue that achieving superalignment requires substantial changes in the current LLM architectures due to their inherent limitations in comprehending and adapting to the dynamic nature of these human ethics and evolving global scenarios. We dissect the challenges of encoding an ever-changing spectrum of human values into LLMs, highlighting the discrepancies between static AI models and the dynamic nature of human societies. To illustrate these challenges, we analyze two distinct examples: one demonstrates a qualitative shift in human values, while the other presents a quantifiable change. Through these examples, we illus",
    "link": "https://arxiv.org/abs/2403.14683",
    "context": "Title: A Moral Imperative: The Need for Continual Superalignment of Large Language Models\nAbstract: arXiv:2403.14683v1 Announce Type: cross  Abstract: This paper examines the challenges associated with achieving life-long superalignment in AI systems, particularly large language models (LLMs). Superalignment is a theoretical framework that aspires to ensure that superintelligent AI systems act in accordance with human values and goals. Despite its promising vision, we argue that achieving superalignment requires substantial changes in the current LLM architectures due to their inherent limitations in comprehending and adapting to the dynamic nature of these human ethics and evolving global scenarios. We dissect the challenges of encoding an ever-changing spectrum of human values into LLMs, highlighting the discrepancies between static AI models and the dynamic nature of human societies. To illustrate these challenges, we analyze two distinct examples: one demonstrates a qualitative shift in human values, while the other presents a quantifiable change. Through these examples, we illus",
    "path": "papers/24/03/2403.14683.json",
    "total_tokens": 856,
    "translated_title": "一项道义使命：对大型语言模型持续超对齐的需求",
    "translated_abstract": "这篇论文探讨了在人工智能系统中实现终身超对齐的挑战，尤其是在大型语言模型（LLMs）中。超对齐是一个理论框架，旨在确保超智能人工智能系统符合人类的价值观和目标。尽管其展望令人振奋，我们认为实现超对齐需要对当前LLM架构进行重大变革，因为它们在理解和适应人类道德的动态性和不断发展的全球情景方面固有的局限性。我们剖析了将不断变化的人类价值观谱系编码到LLMs中的挑战，突出了静态人工智能模型与人类社会动态性之间的差异。为了说明这些挑战，我们分析了两个不同的示例：一个展示了人类价值观的定性转变，另一个呈现了可量化的变化。通过这些示例，我们说明…",
    "tldr": "实现终身超对齐需要对当前大型语言模型架构进行重大变革，以解决其在理解和适应动态人类道德和不断发展的全球情景方面的局限性。"
}