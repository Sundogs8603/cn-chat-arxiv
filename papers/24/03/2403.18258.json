{
    "title": "Enhancing Generative Class Incremental Learning Performance with Model Forgetting Approach",
    "abstract": "arXiv:2403.18258v1 Announce Type: cross  Abstract: This study presents a novel approach to Generative Class Incremental Learning (GCIL) by introducing the forgetting mechanism, aimed at dynamically managing class information for better adaptation to streaming data. GCIL is one of the hot topics in the field of computer vision, and this is considered one of the crucial tasks in society, specifically the continual learning of generative models. The ability to forget is a crucial brain function that facilitates continual learning by selectively discarding less relevant information for humans. However, in the field of machine learning models, the concept of intentionally forgetting has not been extensively investigated. In this study we aim to bridge this gap by incorporating the forgetting mechanisms into GCIL, thereby examining their impact on the models' ability to learn in continual learning. Through our experiments, we have found that integrating the forgetting mechanisms significantl",
    "link": "https://arxiv.org/abs/2403.18258",
    "context": "Title: Enhancing Generative Class Incremental Learning Performance with Model Forgetting Approach\nAbstract: arXiv:2403.18258v1 Announce Type: cross  Abstract: This study presents a novel approach to Generative Class Incremental Learning (GCIL) by introducing the forgetting mechanism, aimed at dynamically managing class information for better adaptation to streaming data. GCIL is one of the hot topics in the field of computer vision, and this is considered one of the crucial tasks in society, specifically the continual learning of generative models. The ability to forget is a crucial brain function that facilitates continual learning by selectively discarding less relevant information for humans. However, in the field of machine learning models, the concept of intentionally forgetting has not been extensively investigated. In this study we aim to bridge this gap by incorporating the forgetting mechanisms into GCIL, thereby examining their impact on the models' ability to learn in continual learning. Through our experiments, we have found that integrating the forgetting mechanisms significantl",
    "path": "papers/24/03/2403.18258.json",
    "total_tokens": 791,
    "translated_title": "用遗忘机制方法提升生成式类增量学习性能",
    "translated_abstract": "这项研究介绍了一种新颖的方法，通过引入遗忘机制来增强生成式类增量学习（GCIL），旨在动态管理类信息，以更好地适应数据流。 GCIL 是计算机视觉领域的热门话题之一，被认为是社会中至关重要的任务之一，特别是生成模型的持续学习。 遗忘是一种关键的大脑功能，通过选择性地丢弃对人类不太相关的信息，有助于持续学习。 然而，在机器学习模型领域，故意忘记的概念尚未得到广泛研究。 在本研究中，我们旨在通过将遗忘机制纳入GCIL中来弥合这一差距，从而检验它们对模型在持续学习中学习能力的影响。 通过我们的实验，我们发现整合遗忘机制显着",
    "tldr": "本研究通过引入遗忘机制提升生成式类增量学习性能。",
    "en_tdlr": "This study enhances generative class incremental learning performance by introducing a forgetting mechanism."
}