{
    "title": "Partially Blinded Unlearning: Class Unlearning for Deep Networks a Bayesian Perspective",
    "abstract": "arXiv:2403.16246v1 Announce Type: new  Abstract: In order to adhere to regulatory standards governing individual data privacy and safety, machine learning models must systematically eliminate information derived from specific subsets of a user's training data that can no longer be utilized. The emerging discipline of Machine Unlearning has arisen as a pivotal area of research, facilitating the process of selectively discarding information designated to specific sets or classes of data from a pre-trained model, thereby eliminating the necessity for extensive retraining from scratch. The principal aim of this study is to formulate a methodology tailored for the purposeful elimination of information linked to a specific class of data from a pre-trained classification network. This intentional removal is crafted to degrade the model's performance specifically concerning the unlearned data class while concurrently minimizing any detrimental impacts on the model's performance in other classe",
    "link": "https://arxiv.org/abs/2403.16246",
    "context": "Title: Partially Blinded Unlearning: Class Unlearning for Deep Networks a Bayesian Perspective\nAbstract: arXiv:2403.16246v1 Announce Type: new  Abstract: In order to adhere to regulatory standards governing individual data privacy and safety, machine learning models must systematically eliminate information derived from specific subsets of a user's training data that can no longer be utilized. The emerging discipline of Machine Unlearning has arisen as a pivotal area of research, facilitating the process of selectively discarding information designated to specific sets or classes of data from a pre-trained model, thereby eliminating the necessity for extensive retraining from scratch. The principal aim of this study is to formulate a methodology tailored for the purposeful elimination of information linked to a specific class of data from a pre-trained classification network. This intentional removal is crafted to degrade the model's performance specifically concerning the unlearned data class while concurrently minimizing any detrimental impacts on the model's performance in other classe",
    "path": "papers/24/03/2403.16246.json",
    "total_tokens": 822,
    "translated_title": "部分遮蔽的遗忘: 一种贝叶斯视角下的深度网络类别遗忘",
    "translated_abstract": "为了遵守监管个人数据隐私和安全的标准，机器学习模型必须系统地消除从用户训练数据的特定子集导出的无法再利用的信息。机器遗忘这一新兴学科已成为一个重要的研究领域，促进了有选择性地丢弃预训练模型中指定给特定数据集或类别的信息的过程，从而消除了必须从头开始进行广泛重新训练的必要性。本研究的主要目的是制定一种针对从预训练分类网络中特定类别的数据中目的性消除信息的方法论。这种有意的去除旨在降低模型对未学习数据类别的性能，同时最小化对模型在其他类别中性能的任何不利影响。",
    "tldr": "该研究提出了一种针对预训练分类网络中特定类别数据的目的性消除方法，以降低模型对未学习数据类别的性能影响，同时最小化其他类别性能的不利影响。",
    "en_tdlr": "This study introduces a methodology for purposefully eliminating information from specific class data in pre-trained classification networks to reduce the impact on the performance of unlearned data classes while minimizing adverse effects on performance in other classes."
}