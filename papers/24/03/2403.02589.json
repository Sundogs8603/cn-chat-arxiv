{
    "title": "MUSIC: Accelerated Convergence for Distributed Optimization With Inexact and Exact Methods",
    "abstract": "arXiv:2403.02589v1 Announce Type: cross  Abstract: Gradient-type distributed optimization methods have blossomed into one of the most important tools for solving a minimization learning task over a networked agent system. However, only one gradient update per iteration is difficult to achieve a substantive acceleration of convergence. In this paper, we propose an accelerated framework named as MUSIC allowing each agent to perform multiple local updates and a single combination in each iteration. More importantly, we equip inexact and exact distributed optimization methods into this framework, thereby developing two new algorithms that exhibit accelerated linear convergence and high communication efficiency. Our rigorous convergence analysis reveals the sources of steady-state errors arising from inexact policies and offers effective solutions. Numerical results based on synthetic and real datasets demonstrate both our theoretical motivations and analysis, as well as performance advanta",
    "link": "https://arxiv.org/abs/2403.02589",
    "context": "Title: MUSIC: Accelerated Convergence for Distributed Optimization With Inexact and Exact Methods\nAbstract: arXiv:2403.02589v1 Announce Type: cross  Abstract: Gradient-type distributed optimization methods have blossomed into one of the most important tools for solving a minimization learning task over a networked agent system. However, only one gradient update per iteration is difficult to achieve a substantive acceleration of convergence. In this paper, we propose an accelerated framework named as MUSIC allowing each agent to perform multiple local updates and a single combination in each iteration. More importantly, we equip inexact and exact distributed optimization methods into this framework, thereby developing two new algorithms that exhibit accelerated linear convergence and high communication efficiency. Our rigorous convergence analysis reveals the sources of steady-state errors arising from inexact policies and offers effective solutions. Numerical results based on synthetic and real datasets demonstrate both our theoretical motivations and analysis, as well as performance advanta",
    "path": "papers/24/03/2403.02589.json",
    "total_tokens": 828,
    "translated_title": "MUSIC: 具有不精确和精确方法的分布式优化加速收敛",
    "translated_abstract": "梯度型分布式优化方法已经成为解决网络化代理系统上的最小化学习任务的最重要工具之一。然而，每次迭代只能实现一个梯度更新，难以实现收敛加速。在本文中，我们提出了一个名为MUSIC的加速框架，允许每个代理执行多个本地更新和每个迭代中的单个组合。更重要的是，我们将不精确和精确的分布式优化方法装备到这个框架中，因此开发出两种新算法，表现出加速的线性收敛和高通信效率。我们的严格收敛分析揭示了由不精确策略引起的稳态误差的来源，并提供了有效的解决方案。基于合成和真实数据集的数值结果展示了我们的理论动机和分析，以及性能优势。",
    "tldr": "提出了一个名为MUSIC的加速框架，允许每个代理执行多个本地更新和每个迭代中的单个组合，同时将不精确和精确的分布式优化方法结合，实现了加速的线性收敛和高通信效率。",
    "en_tdlr": "Introduced an accelerated framework called MUSIC that allows each agent to perform multiple local updates and a single combination in each iteration, while integrating inexact and exact distributed optimization methods to achieve accelerated linear convergence and high communication efficiency."
}