{
    "title": "Reinforcement Learning with Options",
    "abstract": "arXiv:2403.10855v1 Announce Type: new  Abstract: The current thesis aims to explore the reinforcement learning field and build on existing methods to produce improved ones to tackle the problem of learning in high-dimensional and complex environments. It addresses such goals by decomposing learning tasks in a hierarchical fashion known as Hierarchical Reinforcement Learning.   We start in the first chapter by getting familiar with the Markov Decision Process framework and presenting some of its recent techniques that the following chapters use. We then proceed to build our Hierarchical Policy learning as an answer to the limitations of a single primitive policy. The hierarchy is composed of a manager agent at the top and employee agents at the lower level.   In the last chapter, which is the core of this thesis, we attempt to learn lower-level elements of the hierarchy independently of the manager level in what is known as the \"Eigenoption\". Based on the graph structure of the environm",
    "link": "https://arxiv.org/abs/2403.10855",
    "context": "Title: Reinforcement Learning with Options\nAbstract: arXiv:2403.10855v1 Announce Type: new  Abstract: The current thesis aims to explore the reinforcement learning field and build on existing methods to produce improved ones to tackle the problem of learning in high-dimensional and complex environments. It addresses such goals by decomposing learning tasks in a hierarchical fashion known as Hierarchical Reinforcement Learning.   We start in the first chapter by getting familiar with the Markov Decision Process framework and presenting some of its recent techniques that the following chapters use. We then proceed to build our Hierarchical Policy learning as an answer to the limitations of a single primitive policy. The hierarchy is composed of a manager agent at the top and employee agents at the lower level.   In the last chapter, which is the core of this thesis, we attempt to learn lower-level elements of the hierarchy independently of the manager level in what is known as the \"Eigenoption\". Based on the graph structure of the environm",
    "path": "papers/24/03/2403.10855.json",
    "total_tokens": 776,
    "translated_title": "使用选项的强化学习",
    "translated_abstract": "这篇论文旨在探索强化学习领域，并建立在现有方法的基础上，提出改进的方法来解决在高维复杂环境中学习的问题。它通过以分层方式分解学习任务，即分层强化学习，来实现这些目标。第一章我们熟悉马尔可夫决策过程框架，并展示一些最近的技术。之后，我们构建了分层策略学习，以应对单个基本策略的局限性。这个层次结构由顶层的管理代理和底层的员工代理组成。在最后一章，也是本论文的核心部分，我们尝试独立于管理级别学习层次结构的低层元素，即所谓的“Eigenoption”。基于环境的图结构。",
    "tldr": "本论文提出了使用选项的分层强化学习方法，通过构建Hierarchical Policy learning来解决高维复杂环境中学习的问题。"
}