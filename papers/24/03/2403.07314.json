{
    "title": "Customizable Avatars with Dynamic Facial Action Coded Expressions (CADyFACE) for Improved User Engagement",
    "abstract": "arXiv:2403.07314v1 Announce Type: cross  Abstract: Customizable 3D avatar-based facial expression stimuli may improve user engagement in behavioral biomarker discovery and therapeutic intervention for autism, Alzheimer's disease, facial palsy, and more. However, there is a lack of customizable avatar-based stimuli with Facial Action Coding System (FACS) action unit (AU) labels. Therefore, this study focuses on (1) FACS-labeled, customizable avatar-based expression stimuli for maintaining subjects' engagement, (2) learning-based measurements that quantify subjects' facial responses to such stimuli, and (3) validation of constructs represented by stimulus-measurement pairs. We propose Customizable Avatars with Dynamic Facial Action Coded Expressions (CADyFACE) labeled with AUs by a certified FACS expert. To measure subjects' AUs in response to CADyFACE, we propose a novel Beta-guided Correlation and Multi-task Expression learning neural network (BeCoME-Net) for multi-label AU detection. ",
    "link": "https://arxiv.org/abs/2403.07314",
    "context": "Title: Customizable Avatars with Dynamic Facial Action Coded Expressions (CADyFACE) for Improved User Engagement\nAbstract: arXiv:2403.07314v1 Announce Type: cross  Abstract: Customizable 3D avatar-based facial expression stimuli may improve user engagement in behavioral biomarker discovery and therapeutic intervention for autism, Alzheimer's disease, facial palsy, and more. However, there is a lack of customizable avatar-based stimuli with Facial Action Coding System (FACS) action unit (AU) labels. Therefore, this study focuses on (1) FACS-labeled, customizable avatar-based expression stimuli for maintaining subjects' engagement, (2) learning-based measurements that quantify subjects' facial responses to such stimuli, and (3) validation of constructs represented by stimulus-measurement pairs. We propose Customizable Avatars with Dynamic Facial Action Coded Expressions (CADyFACE) labeled with AUs by a certified FACS expert. To measure subjects' AUs in response to CADyFACE, we propose a novel Beta-guided Correlation and Multi-task Expression learning neural network (BeCoME-Net) for multi-label AU detection. ",
    "path": "papers/24/03/2403.07314.json",
    "total_tokens": 929,
    "translated_title": "可定制化头像的动态面部表情编码表达（CADyFACE）以提升用户参与度",
    "translated_abstract": "定制化的3D头像为基础的面部表情刺激可能提高用户在行为生物标志物发现和自闭症、阿尔茨海默病、面瘫等疾病治疗干预中的参与度。然而，缺乏具有面部动作编码系统（FACS）动作单元（AU）标签的可定制化头像刺激。因此，本研究侧重于（1）具有FACS标记的可定制化头像表达刺激，以维持受试者的参与度，（2）基于学习的测量，量化受试者对此类刺激的面部反应，以及（3）验证由刺激-测量对表示的构造。我们提出了由获得FACS专家认证的AU标记的Customizable Avatars with Dynamic Facial Action Coded Expressions（CADyFACE）。为了测量受试者对CADyFACE的AU的反应，我们提出了一种新颖的Beta引导相关和多任务表达学习神经网络（BeCoME-Net）用于多标签AU检测。",
    "tldr": "该研究提出了一种定制化头像系统CADyFACE，通过FACS标记的动态面部表情，以及一种新颖的神经网络BeCoME-Net来量化用户对刺激的面部反应。",
    "en_tdlr": "The study introduces a customizable avatar system CADyFACE with dynamically coded facial expressions labeled by FACS, along with a novel neural network BeCoME-Net for quantifying users' facial responses to stimuli."
}