{
    "title": "ChatUIE: Exploring Chat-based Unified Information Extraction using Large Language Models",
    "abstract": "arXiv:2403.05132v1 Announce Type: cross  Abstract: Recent advancements in large language models have shown impressive performance in general chat. However, their domain-specific capabilities, particularly in information extraction, have certain limitations. Extracting structured information from natural language that deviates from known schemas or instructions has proven challenging for previous prompt-based methods. This motivated us to explore domain-specific modeling in chat-based language models as a solution for extracting structured information from natural language. In this paper, we present ChatUIE, an innovative unified information extraction framework built upon ChatGLM. Simultaneously, reinforcement learning is employed to improve and align various tasks that involve confusing and limited samples. Furthermore, we integrate generation constraints to address the issue of generating elements that are not present in the input. Our experimental results demonstrate that ChatUIE ca",
    "link": "https://arxiv.org/abs/2403.05132",
    "context": "Title: ChatUIE: Exploring Chat-based Unified Information Extraction using Large Language Models\nAbstract: arXiv:2403.05132v1 Announce Type: cross  Abstract: Recent advancements in large language models have shown impressive performance in general chat. However, their domain-specific capabilities, particularly in information extraction, have certain limitations. Extracting structured information from natural language that deviates from known schemas or instructions has proven challenging for previous prompt-based methods. This motivated us to explore domain-specific modeling in chat-based language models as a solution for extracting structured information from natural language. In this paper, we present ChatUIE, an innovative unified information extraction framework built upon ChatGLM. Simultaneously, reinforcement learning is employed to improve and align various tasks that involve confusing and limited samples. Furthermore, we integrate generation constraints to address the issue of generating elements that are not present in the input. Our experimental results demonstrate that ChatUIE ca",
    "path": "papers/24/03/2403.05132.json",
    "total_tokens": 805,
    "translated_title": "ChatUIE：利用大型语言模型探索基于聊天的统一信息提取",
    "translated_abstract": "最近大型语言模型的发展在一般的聊天中展现出令人印象深刻的性能。然而，它们在特定领域的能力，特别是在信息提取方面，存在一定的局限性。从偏离已知模式或指令的自然语言中提取结构化信息对于之前基于提示的方法来说是具有挑战性的。这促使我们探索聊天型语言模型中的领域特定建模作为从自然语言中提取结构化信息的解决方案。在本文中，我们提出了ChatUIE，这是一个基于ChatGLM构建的创新的统一信息提取框架。同时，采用强化学习来改进和对齐涉及混乱和有限样本的各种任务。此外，我们整合了生成约束来解决在输入中不存在的元素生成的问题。我们的实验结果表明ChatUIE能够...",
    "tldr": "ChatUIE利用大型语言模型探索基于聊天的统一信息提取，通过强化学习和生成约束提高对自然语言中结构化信息的提取能力。"
}