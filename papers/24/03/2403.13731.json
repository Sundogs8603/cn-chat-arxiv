{
    "title": "Emotion Recognition Using Transformers with Masked Learning",
    "abstract": "arXiv:2403.13731v2 Announce Type: replace-cross  Abstract: In recent years, deep learning has achieved innovative advancements in various fields, including the analysis of human emotions and behaviors. Initiatives such as the Affective Behavior Analysis in-the-wild (ABAW) competition have been particularly instrumental in driving research in this area by providing diverse and challenging datasets that enable precise evaluation of complex emotional states. This study leverages the Vision Transformer (ViT) and Transformer models to focus on the estimation of Valence-Arousal (VA), which signifies the positivity and intensity of emotions, recognition of various facial expressions, and detection of Action Units (AU) representing fundamental muscle movements. This approach transcends traditional Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) based methods, proposing a new Transformer-based framework that maximizes the understanding of temporal and spatial features. Th",
    "link": "https://arxiv.org/abs/2403.13731",
    "context": "Title: Emotion Recognition Using Transformers with Masked Learning\nAbstract: arXiv:2403.13731v2 Announce Type: replace-cross  Abstract: In recent years, deep learning has achieved innovative advancements in various fields, including the analysis of human emotions and behaviors. Initiatives such as the Affective Behavior Analysis in-the-wild (ABAW) competition have been particularly instrumental in driving research in this area by providing diverse and challenging datasets that enable precise evaluation of complex emotional states. This study leverages the Vision Transformer (ViT) and Transformer models to focus on the estimation of Valence-Arousal (VA), which signifies the positivity and intensity of emotions, recognition of various facial expressions, and detection of Action Units (AU) representing fundamental muscle movements. This approach transcends traditional Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) based methods, proposing a new Transformer-based framework that maximizes the understanding of temporal and spatial features. Th",
    "path": "papers/24/03/2403.13731.json",
    "total_tokens": 835,
    "translated_title": "使用掩模学习的Transformer进行情绪识别",
    "translated_abstract": "在近年来，深度学习在各个领域取得了创新性进展，其中包括对人类情绪和行为的分析。诸如野外情感行为分析（ABAW）竞赛等倡议尤其在推动这一领域的研究方面发挥了重要作用，通过提供多样且具有挑战性的数据集，能够精确评估复杂情绪状态。本研究利用了Vision Transformer（ViT）和Transformer模型，专注于对情绪的积极性和强度（Valence-Arousal），各种面部表情的识别以及代表基本肌肉运动的动作单元（AU）的检测。这种方法超越了传统的卷积神经网络（CNNs）和长短期记忆（LSTM）方法，提出了一种基于Transformer的全新框架，最大化了对时空特征的理解。",
    "tldr": "本研究提出了一种使用Transformer进行情绪识别的新框架，专注于Valence-Arousal估计、面部表情识别和动作单元检测，并最大化了对时空特征的理解。"
}