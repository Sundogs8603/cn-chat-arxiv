{
    "title": "FairRR: Pre-Processing for Group Fairness through Randomized Response",
    "abstract": "arXiv:2403.07780v1 Announce Type: cross  Abstract: The increasing usage of machine learning models in consequential decision-making processes has spurred research into the fairness of these systems. While significant work has been done to study group fairness in the in-processing and post-processing setting, there has been little that theoretically connects these results to the pre-processing domain. This paper proposes that achieving group fairness in downstream models can be formulated as finding the optimal design matrix in which to modify a response variable in a Randomized Response framework. We show that measures of group fairness can be directly controlled for with optimal model utility, proposing a pre-processing algorithm called FairRR that yields excellent downstream model utility and fairness.",
    "link": "https://arxiv.org/abs/2403.07780",
    "context": "Title: FairRR: Pre-Processing for Group Fairness through Randomized Response\nAbstract: arXiv:2403.07780v1 Announce Type: cross  Abstract: The increasing usage of machine learning models in consequential decision-making processes has spurred research into the fairness of these systems. While significant work has been done to study group fairness in the in-processing and post-processing setting, there has been little that theoretically connects these results to the pre-processing domain. This paper proposes that achieving group fairness in downstream models can be formulated as finding the optimal design matrix in which to modify a response variable in a Randomized Response framework. We show that measures of group fairness can be directly controlled for with optimal model utility, proposing a pre-processing algorithm called FairRR that yields excellent downstream model utility and fairness.",
    "path": "papers/24/03/2403.07780.json",
    "total_tokens": 767,
    "translated_title": "公平RR：通过随机响应实现群体公平的预处理",
    "translated_abstract": "机器学习模型在重要决策过程中的使用日益增多，这促使人们开始研究这些系统的公平性。虽然在处理过程和后处理设置中已经进行了大量工作来研究群体公平性，但很少有研究能够从理论上将这些结果与预处理领域连接起来。本文提出，实现下游模型中的群体公平性可以被形式化为在随机响应框架中修改响应变量的最优设计矩阵。我们展示了群体公平性的度量可以通过最优模型效用直接控制，提出了一种称为FairRR的预处理算法，该算法产生出色的下游模型效用和公平性。",
    "tldr": "本文提出了一种名为FairRR的预处理算法，通过在随机响应框架中修改响应变量的最优设计矩阵，直接控制群体公平性的度量，从而产生出色的下游模型效用和公平性。",
    "en_tdlr": "This paper proposes a pre-processing algorithm called FairRR, which modifies the response variable in a Randomized Response framework to achieve group fairness in downstream models with optimal design matrix, directly controlling the measures of group fairness to yield excellent downstream model utility and fairness."
}