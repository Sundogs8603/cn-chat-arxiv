{
    "title": "EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba",
    "abstract": "arXiv:2403.09977v1 Announce Type: cross  Abstract: Prior efforts in light-weight model development mainly centered on CNN and Transformer-based designs yet faced persistent challenges. CNNs adept at local feature extraction compromise resolution while Transformers offer global reach but escalate computational demands $\\mathcal{O}(N^2)$. This ongoing trade-off between accuracy and efficiency remains a significant hurdle. Recently, state space models (SSMs), such as Mamba, have shown outstanding performance and competitiveness in various tasks such as language modeling and computer vision, while reducing the time complexity of global information extraction to $\\mathcal{O}(N)$. Inspired by this, this work proposes to explore the potential of visual state space models in light-weight model design and introduce a novel efficient model variant dubbed EfficientVMamba. Concretely, our EfficientVMamba integrates a atrous-based selective scan approach by efficient skip sampling, constituting bui",
    "link": "https://arxiv.org/abs/2403.09977",
    "context": "Title: EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba\nAbstract: arXiv:2403.09977v1 Announce Type: cross  Abstract: Prior efforts in light-weight model development mainly centered on CNN and Transformer-based designs yet faced persistent challenges. CNNs adept at local feature extraction compromise resolution while Transformers offer global reach but escalate computational demands $\\mathcal{O}(N^2)$. This ongoing trade-off between accuracy and efficiency remains a significant hurdle. Recently, state space models (SSMs), such as Mamba, have shown outstanding performance and competitiveness in various tasks such as language modeling and computer vision, while reducing the time complexity of global information extraction to $\\mathcal{O}(N)$. Inspired by this, this work proposes to explore the potential of visual state space models in light-weight model design and introduce a novel efficient model variant dubbed EfficientVMamba. Concretely, our EfficientVMamba integrates a atrous-based selective scan approach by efficient skip sampling, constituting bui",
    "path": "papers/24/03/2403.09977.json",
    "total_tokens": 856,
    "translated_title": "EfficientVMamba: 一种专为轻量级视觉Mamba设计的Atrous选择扫描方法",
    "translated_abstract": "先前轻量级模型开发的努力主要集中在基于CNN和Transformer的设计上，但仍面临持续挑战。CNN在局部特征提取方面擅长，但会损害分辨率，而Transformers提供全局范围，但会增加计算需求$\\mathcal{O}(N^2)$。准确性和效率之间的这种持续权衡仍然是一个重大障碍。最近，状态空间模型（SSMs），如Mamba，在语言建模和计算机视觉等各种任务中表现出色并具有竞争力，同时将全局信息提取的时间复杂度降低到$\\mathcal{O}(N)$。在此启发下，本文提出探索视觉状态空间模型在轻量级模型设计中的潜力，并引入了一种名为EfficientVMamba的全新高效模型变体。具体而言，我们的EfficientVMamba通过高效的跳跃采样集成了基于atrous的选择扫描方法。",
    "tldr": "EfficientVMamba是一种新颖的高效模型变体，通过atrous-based selective scan方法实现了轻量级模型设计，克服了准确性和效率之间的权衡挑战。",
    "en_tdlr": "EfficientVMamba is a novel efficient model variant that achieves light-weight model design through an atrous-based selective scan approach, overcoming the trade-off challenge between accuracy and efficiency."
}