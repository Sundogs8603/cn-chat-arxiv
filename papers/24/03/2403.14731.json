{
    "title": "Reversible Jump Attack to Textual Classifiers with Modification Reduction",
    "abstract": "arXiv:2403.14731v1 Announce Type: cross  Abstract: Recent studies on adversarial examples expose vulnerabilities of natural language processing (NLP) models. Existing techniques for generating adversarial examples are typically driven by deterministic hierarchical rules that are agnostic to the optimal adversarial examples, a strategy that often results in adversarial samples with a suboptimal balance between magnitudes of changes and attack successes. To this end, in this research we propose two algorithms, Reversible Jump Attack (RJA) and Metropolis-Hasting Modification Reduction (MMR), to generate highly effective adversarial examples and to improve the imperceptibility of the examples, respectively. RJA utilizes a novel randomization mechanism to enlarge the search space and efficiently adapts to a number of perturbed words for adversarial examples. With these generated adversarial examples, MMR applies the Metropolis-Hasting sampler to enhance the imperceptibility of adversarial e",
    "link": "https://arxiv.org/abs/2403.14731",
    "context": "Title: Reversible Jump Attack to Textual Classifiers with Modification Reduction\nAbstract: arXiv:2403.14731v1 Announce Type: cross  Abstract: Recent studies on adversarial examples expose vulnerabilities of natural language processing (NLP) models. Existing techniques for generating adversarial examples are typically driven by deterministic hierarchical rules that are agnostic to the optimal adversarial examples, a strategy that often results in adversarial samples with a suboptimal balance between magnitudes of changes and attack successes. To this end, in this research we propose two algorithms, Reversible Jump Attack (RJA) and Metropolis-Hasting Modification Reduction (MMR), to generate highly effective adversarial examples and to improve the imperceptibility of the examples, respectively. RJA utilizes a novel randomization mechanism to enlarge the search space and efficiently adapts to a number of perturbed words for adversarial examples. With these generated adversarial examples, MMR applies the Metropolis-Hasting sampler to enhance the imperceptibility of adversarial e",
    "path": "papers/24/03/2403.14731.json",
    "total_tokens": 783,
    "translated_title": "可逆跳动攻击对文本分类器的修改缩减",
    "translated_abstract": "最近的对抗样本研究揭示了自然语言处理（NLP）模型的漏洞。现有生成对抗样本的技术通常由确定性的层次规则驱动，这些规则对最优对抗样本毫不关心，通常导致对抗样本在变化幅度和攻击成功之间存在次优平衡。在此研究中，我们提出了两种算法，可逆跳动攻击（RJA）和Metropolis-Hasting修改缩减（MMR），用于生成高度有效的对抗示例并分别改善示例的不可察觉性。RJA利用新颖的随机化机制来扩大搜索空间，有效适应对抗样本中的多个扰动词汇。利用生成的对抗示例，MMR应用Metropolis-Hasting采样器以增强对抗示例的不可察觉性。",
    "tldr": "提出了两种算法，可逆跳动攻击（RJA）和Metropolis-Hasting修改缩减（MMR），用于生成高度有效的对抗示例，并分别改善示例的不可察觉性。"
}