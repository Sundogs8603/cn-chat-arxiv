{
    "title": "Uncertainty-Aware Explanations Through Probabilistic Self-Explainable Neural Networks",
    "abstract": "arXiv:2403.13740v1 Announce Type: new  Abstract: The lack of transparency of Deep Neural Networks continues to be a limitation that severely undermines their reliability and usage in high-stakes applications. Promising approaches to overcome such limitations are Prototype-Based Self-Explainable Neural Networks (PSENNs), whose predictions rely on the similarity between the input at hand and a set of prototypical representations of the output classes, offering therefore a deep, yet transparent-by-design, architecture. So far, such models have been designed by considering pointwise estimates for the prototypes, which remain fixed after the learning phase of the model. In this paper, we introduce a probabilistic reformulation of PSENNs, called Prob-PSENN, which replaces point estimates for the prototypes with probability distributions over their values. This provides not only a more flexible framework for an end-to-end learning of prototypes, but can also capture the explanatory uncertaint",
    "link": "https://arxiv.org/abs/2403.13740",
    "context": "Title: Uncertainty-Aware Explanations Through Probabilistic Self-Explainable Neural Networks\nAbstract: arXiv:2403.13740v1 Announce Type: new  Abstract: The lack of transparency of Deep Neural Networks continues to be a limitation that severely undermines their reliability and usage in high-stakes applications. Promising approaches to overcome such limitations are Prototype-Based Self-Explainable Neural Networks (PSENNs), whose predictions rely on the similarity between the input at hand and a set of prototypical representations of the output classes, offering therefore a deep, yet transparent-by-design, architecture. So far, such models have been designed by considering pointwise estimates for the prototypes, which remain fixed after the learning phase of the model. In this paper, we introduce a probabilistic reformulation of PSENNs, called Prob-PSENN, which replaces point estimates for the prototypes with probability distributions over their values. This provides not only a more flexible framework for an end-to-end learning of prototypes, but can also capture the explanatory uncertaint",
    "path": "papers/24/03/2403.13740.json",
    "total_tokens": 673,
    "translated_title": "通过概率自解释神经网络实现对不确定性的认知",
    "translated_abstract": "深度神经网络的不透明性持续限制其可靠性和在高风险应用中的使用。本文介绍了概率自解释神经网络（Prob-PSENN），采用概率分布代替原型的点估计，提供了一种更灵活的原型端到端学习框架。",
    "tldr": "本文引入了概率自解释神经网络（Prob-PSENN），通过概率分布取代点估计，实现了更灵活的原型学习，提供了实用的对不确定性的解释。",
    "en_tdlr": "This paper introduces Probabilistic Self-Explainable Neural Networks (Prob-PSENN) which utilize probability distributions instead of point estimates for prototypes, offering a more flexible framework for prototype learning and practical explanations of uncertainties."
}