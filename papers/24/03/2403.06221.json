{
    "title": "TRAD: Enhancing LLM Agents with Step-Wise Thought Retrieval and Aligned Decision",
    "abstract": "arXiv:2403.06221v1 Announce Type: new  Abstract: Numerous large language model (LLM) agents have been built for different tasks like web navigation and online shopping due to LLM's wide knowledge and text-understanding ability. Among these works, many of them utilize in-context examples to achieve generalization without the need for fine-tuning, while few of them have considered the problem of how to select and effectively utilize these examples. Recently, methods based on trajectory-level retrieval with task meta-data and using trajectories as in-context examples have been proposed to improve the agent's overall performance in some sequential decision making tasks. However, these methods can be problematic due to plausible examples retrieved without task-specific state transition dynamics and long input with plenty of irrelevant context. In this paper, we propose a novel framework (TRAD) to address these issues. TRAD first conducts Thought Retrieval, achieving step-level demonstration",
    "link": "https://arxiv.org/abs/2403.06221",
    "context": "Title: TRAD: Enhancing LLM Agents with Step-Wise Thought Retrieval and Aligned Decision\nAbstract: arXiv:2403.06221v1 Announce Type: new  Abstract: Numerous large language model (LLM) agents have been built for different tasks like web navigation and online shopping due to LLM's wide knowledge and text-understanding ability. Among these works, many of them utilize in-context examples to achieve generalization without the need for fine-tuning, while few of them have considered the problem of how to select and effectively utilize these examples. Recently, methods based on trajectory-level retrieval with task meta-data and using trajectories as in-context examples have been proposed to improve the agent's overall performance in some sequential decision making tasks. However, these methods can be problematic due to plausible examples retrieved without task-specific state transition dynamics and long input with plenty of irrelevant context. In this paper, we propose a novel framework (TRAD) to address these issues. TRAD first conducts Thought Retrieval, achieving step-level demonstration",
    "path": "papers/24/03/2403.06221.json",
    "total_tokens": 807,
    "translated_title": "用步骤式思维检索和对齐决策增强LLM代理",
    "translated_abstract": "许多大型语言模型（LLM）代理已经被构建用于不同任务，如网络导航和在线购物，这是因为LLM具有广泛的知识和文本理解能力。在这些研究中，许多利用上下文示例来实现泛化，而无需微调，但少数考虑了如何选择和有效利用这些示例的问题。最近，基于轨迹级检索和使用轨迹作为上下文示例的方法已经提出，以提高代理在一些顺序决策任务中的整体性能。然而，这些方法可能存在问题，因为检索出的可信示例缺乏特定于任务的状态转移动态，且输入长且包含大量无关上下文。在本文中，我们提出了一个新框架（TRAD）来解决这些问题。TRAD首先进行思维检索，实现步骤级演示。",
    "tldr": "提出了TRAD框架，通过步骤式思维检索和对齐决策解决了利用上下文示例时可能出现的问题。",
    "en_tdlr": "Introducing the TRAD framework to address issues with utilizing contextual examples through step-wise thought retrieval and aligned decision-making."
}