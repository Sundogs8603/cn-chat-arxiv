{
    "title": "Fill-and-Spill: Deep Reinforcement Learning Policy Gradient Methods for Reservoir Operation Decision and Control",
    "abstract": "arXiv:2403.04195v1 Announce Type: new  Abstract: Changes in demand, various hydrological inputs, and environmental stressors are among the issues that water managers and policymakers face on a regular basis. These concerns have sparked interest in applying different techniques to determine reservoir operation policy decisions. As the resolution of the analysis increases, it becomes more difficult to effectively represent a real-world system using traditional methods such as Dynamic Programming (DP) and Stochastic Dynamic Programming (SDP) for determining the best reservoir operation policy. One of the challenges is the \"curse of dimensionality,\" which means the number of samples needed to estimate an arbitrary function with a given level of accuracy grows exponentially with respect to the number of input variables (i.e., dimensionality) of the function. Deep Reinforcement Learning (DRL) is an intelligent approach to overcome the curses of stochastic optimization problems for reservoir ",
    "link": "https://arxiv.org/abs/2403.04195",
    "context": "Title: Fill-and-Spill: Deep Reinforcement Learning Policy Gradient Methods for Reservoir Operation Decision and Control\nAbstract: arXiv:2403.04195v1 Announce Type: new  Abstract: Changes in demand, various hydrological inputs, and environmental stressors are among the issues that water managers and policymakers face on a regular basis. These concerns have sparked interest in applying different techniques to determine reservoir operation policy decisions. As the resolution of the analysis increases, it becomes more difficult to effectively represent a real-world system using traditional methods such as Dynamic Programming (DP) and Stochastic Dynamic Programming (SDP) for determining the best reservoir operation policy. One of the challenges is the \"curse of dimensionality,\" which means the number of samples needed to estimate an arbitrary function with a given level of accuracy grows exponentially with respect to the number of input variables (i.e., dimensionality) of the function. Deep Reinforcement Learning (DRL) is an intelligent approach to overcome the curses of stochastic optimization problems for reservoir ",
    "path": "papers/24/03/2403.04195.json",
    "total_tokens": 860,
    "translated_title": "《装填与溢出：用于水库运行决策与控制的深度强化学习策略梯度方法》",
    "translated_abstract": "需求变化、各种水文输入和环境压力是水资源管理者和决策者经常面临的问题之一。 这些问题引起人们对应用不同技术来确定水库运行政策决策的兴趣。 随着分析的分辨率提高，使用传统方法如动态规划（DP）和随机动态规划（SDP）来确定最佳水库运行政策越来越困难，因为这些方法难以有效地表示真实世界系统。 其中一个挑战是“维度诅咒”，这意味着估计具有给定精度水平任意函数所需的样本数量随着函数的输入变量数量（即维数）呈指数级增长。 深度强化学习（DRL）是一种智能方法，可以克服水库随机优化问题的诅咒。",
    "tldr": "深度强化学习方法应用于水库运行决策与控制，克服了动态规划和随机动态规划在高分辨率下面临的挑战，解决了“维度诅咒”问题。",
    "en_tdlr": "Deep reinforcement learning methods applied to reservoir operation decision and control have overcome the challenges faced by dynamic programming and stochastic dynamic programming at high resolutions, addressing the \"curse of dimensionality.\""
}