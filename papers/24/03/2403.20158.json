{
    "title": "ChatGPT v.s. Media Bias: A Comparative Study of GPT-3.5 and Fine-tuned Language Models",
    "abstract": "arXiv:2403.20158v1 Announce Type: cross  Abstract: In our rapidly evolving digital sphere, the ability to discern media bias becomes crucial as it can shape public sentiment and influence pivotal decisions. The advent of large language models (LLMs), such as ChatGPT, noted for their broad utility in various natural language processing (NLP) tasks, invites exploration of their efficacy in media bias detection. Can ChatGPT detect media bias? This study seeks to answer this question by leveraging the Media Bias Identification Benchmark (MBIB) to assess ChatGPT's competency in distinguishing six categories of media bias, juxtaposed against fine-tuned models such as BART, ConvBERT, and GPT-2. The findings present a dichotomy: ChatGPT performs at par with fine-tuned models in detecting hate speech and text-level context bias, yet faces difficulties with subtler elements of other bias detections, namely, fake news, racial, gender, and cognitive biases.",
    "link": "https://arxiv.org/abs/2403.20158",
    "context": "Title: ChatGPT v.s. Media Bias: A Comparative Study of GPT-3.5 and Fine-tuned Language Models\nAbstract: arXiv:2403.20158v1 Announce Type: cross  Abstract: In our rapidly evolving digital sphere, the ability to discern media bias becomes crucial as it can shape public sentiment and influence pivotal decisions. The advent of large language models (LLMs), such as ChatGPT, noted for their broad utility in various natural language processing (NLP) tasks, invites exploration of their efficacy in media bias detection. Can ChatGPT detect media bias? This study seeks to answer this question by leveraging the Media Bias Identification Benchmark (MBIB) to assess ChatGPT's competency in distinguishing six categories of media bias, juxtaposed against fine-tuned models such as BART, ConvBERT, and GPT-2. The findings present a dichotomy: ChatGPT performs at par with fine-tuned models in detecting hate speech and text-level context bias, yet faces difficulties with subtler elements of other bias detections, namely, fake news, racial, gender, and cognitive biases.",
    "path": "papers/24/03/2403.20158.json",
    "total_tokens": 978,
    "translated_title": "ChatGPT与媒体偏见：GPT-3.5和Fine-tuned语言模型的比较研究",
    "translated_abstract": "在我们快速发展的数字领域中，辨别媒体偏见的能力变得至关重要，因为它可以塑造公众情绪并影响关键决策。大型语言模型（LLMs），如ChatGPT，在各种自然语言处理（NLP）任务中具有广泛实用性，引发了对它们在媒体偏见检测中有效性的探究。ChatGPT能否检测媒体偏见？本研究旨在通过利用媒体偏见识别基准（MBIB）来评估ChatGPT在区分六种媒体偏见方面的能力，与Fine-tuned模型（如BART、ConvBERT和GPT-2）进行对比。研究结果呈现了一种二分法：ChatGPT在检测仇恨言论和文本级上下文偏见方面与Fine-tuned模型表现一致，但在其他偏见检测的更微妙要素上，即虚假新闻、种族、性别和认知偏见方面则面临困难。",
    "tldr": "研究比较了ChatGPT与Fine-tuned语言模型在检测媒体偏见方面的表现，发现ChatGPT在检测仇恨言论和文本级上下文偏见方面表现一致，但在检测虚假新闻、种族、性别和认知偏见方面则存在困难。",
    "en_tdlr": "This study compares the performance of ChatGPT with fine-tuned language models in detecting media bias, finding that ChatGPT performs similarly to fine-tuned models in detecting hate speech and text-level context bias, but faces challenges in detecting fake news, racial, gender, and cognitive biases."
}