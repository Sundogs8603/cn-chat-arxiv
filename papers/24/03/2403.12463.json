{
    "title": "Reinforcement learning based local path planning for mobile robot",
    "abstract": "arXiv:2403.12463v1 Announce Type: cross  Abstract: Different methods are used for a mobile robot to go to a specific target location. These methods work in different ways for online and offline scenarios. In the offline scenario, an environment map is created once, and fixed path planning is made on this map to reach the target. Path planning algorithms such as A* and RRT (Rapidly-Exploring Random Tree) are the examples of offline methods. The most obvious situation here is the need to re-plan the path for changing conditions of the loaded map. On the other hand, in the online scenario, the robot moves dynamically to a given target without using a map by using the perceived data coming from the sensors. Approaches such as SFM (Social Force Model) are used in online systems. However, these methods suffer from the requirement of a lot of dynamic sensing data. Thus, it can be said that the need for re-planning and mapping in offline systems and various system design requirements in online",
    "link": "https://arxiv.org/abs/2403.12463",
    "context": "Title: Reinforcement learning based local path planning for mobile robot\nAbstract: arXiv:2403.12463v1 Announce Type: cross  Abstract: Different methods are used for a mobile robot to go to a specific target location. These methods work in different ways for online and offline scenarios. In the offline scenario, an environment map is created once, and fixed path planning is made on this map to reach the target. Path planning algorithms such as A* and RRT (Rapidly-Exploring Random Tree) are the examples of offline methods. The most obvious situation here is the need to re-plan the path for changing conditions of the loaded map. On the other hand, in the online scenario, the robot moves dynamically to a given target without using a map by using the perceived data coming from the sensors. Approaches such as SFM (Social Force Model) are used in online systems. However, these methods suffer from the requirement of a lot of dynamic sensing data. Thus, it can be said that the need for re-planning and mapping in offline systems and various system design requirements in online",
    "path": "papers/24/03/2403.12463.json",
    "total_tokens": 798,
    "translated_title": "基于强化学习的移动机器人局部路径规划",
    "translated_abstract": "不同的方法被用来让移动机器人到达特定目标位置。这些方法在在线和离线场景中以不同方式工作。在离线场景中，环境地图被创建一次，然后在该地图上进行固定路径规划以到达目标。A*和RRT（Rapidly-Exploring Random Tree）等路径规划算法是离线方法的例子。另一方面，在在线场景中，机器人通过使用传感器传输的感知数据动态移动到给定目标，而不使用地图。在线系统中使用的方法，如SFM（Social Force Model），要求大量动态感应数据。因此，可以说在离线系统中需要重新规划和映射，而在线系统中存在各种系统设计要求。",
    "tldr": "该论文基于强化学习提出了一种新的移动机器人局部路径规划方法，克服了离线系统中重新规划和映射的需求以及在线系统中动态感应数据要求的问题。",
    "en_tdlr": "This paper proposes a new local path planning method for mobile robots based on reinforcement learning, overcoming the need for re-planning and mapping in offline systems and the requirement for dynamic sensing data in online systems."
}