{
    "title": "TAMS: Translation-Assisted Morphological Segmentation",
    "abstract": "arXiv:2403.14840v1 Announce Type: new  Abstract: Canonical morphological segmentation is the process of analyzing words into the standard (aka underlying) forms of their constituent morphemes. This is a core task in language documentation, and NLP systems have the potential to dramatically speed up this process. But in typical language documentation settings, training data for canonical morpheme segmentation is scarce, making it difficult to train high quality models. However, translation data is often much more abundant, and, in this work, we present a method that attempts to leverage this data in the canonical segmentation task. We propose a character-level sequence-to-sequence model that incorporates representations of translations obtained from pretrained high-resource monolingual language models as an additional signal. Our model outperforms the baseline in a super-low resource setting but yields mixed results on training splits with more data. While further work is needed to make",
    "link": "https://arxiv.org/abs/2403.14840",
    "context": "Title: TAMS: Translation-Assisted Morphological Segmentation\nAbstract: arXiv:2403.14840v1 Announce Type: new  Abstract: Canonical morphological segmentation is the process of analyzing words into the standard (aka underlying) forms of their constituent morphemes. This is a core task in language documentation, and NLP systems have the potential to dramatically speed up this process. But in typical language documentation settings, training data for canonical morpheme segmentation is scarce, making it difficult to train high quality models. However, translation data is often much more abundant, and, in this work, we present a method that attempts to leverage this data in the canonical segmentation task. We propose a character-level sequence-to-sequence model that incorporates representations of translations obtained from pretrained high-resource monolingual language models as an additional signal. Our model outperforms the baseline in a super-low resource setting but yields mixed results on training splits with more data. While further work is needed to make",
    "path": "papers/24/03/2403.14840.json",
    "total_tokens": 864,
    "translated_title": "TAMS: 翻译辅助的形态分割",
    "translated_abstract": "规范形态分割是将单词分析为其构成形态素的标准（也称为底层）形式的过程。这是语言文档编制中的核心任务，NLP 系统有望显著加快这一处理过程。在典型的语言文档编制环境中，规范形态分割的训练数据稀缺，这使得难以训练出高质量的模型。然而，翻译数据通常更为丰富，在这项工作中，我们提出了一种尝试利用这些数据的方法来进行规范分割任务。我们提出了一个字符级序列到序列模型，该模型将来自预先训练的高资源单语言模型的翻译表示作为额外信号。我们的模型在超低资源设置中优于基线，但在具有更多数据的训练分割上产生了不同的结果。需要进一步工作才能使",
    "tldr": "这项工作提出了一种利用翻译数据辅助形态分割任务的方法，通过使用字符级序列到序列模型，以及预先训练的高资源单语言模型的翻译表示，实现在低资源环境下超越基线模型。",
    "en_tdlr": "This work presents a method that leverages translation data to assist in morphological segmentation by utilizing a character-level sequence-to-sequence model and translation representations from pretrained high-resource monolingual language models, achieving improvements over baseline models in low-resource settings."
}