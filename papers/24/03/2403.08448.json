{
    "title": "Actor-Critic Physics-informed Neural Lyapunov Control",
    "abstract": "arXiv:2403.08448v1 Announce Type: new  Abstract: Designing control policies for stabilization tasks with provable guarantees is a long-standing problem in nonlinear control. A crucial performance metric is the size of the resulting region of attraction, which essentially serves as a robustness \"margin\" of the closed-loop system against uncertainties. In this paper, we propose a new method to train a stabilizing neural network controller along with its corresponding Lyapunov certificate, aiming to maximize the resulting region of attraction while respecting the actuation constraints. Crucial to our approach is the use of Zubov's Partial Differential Equation (PDE), which precisely characterizes the true region of attraction of a given control policy. Our framework follows an actor-critic pattern where we alternate between improving the control policy (actor) and learning a Zubov function (critic). Finally, we compute the largest certifiable region of attraction by invoking an SMT solver",
    "link": "https://arxiv.org/abs/2403.08448",
    "context": "Title: Actor-Critic Physics-informed Neural Lyapunov Control\nAbstract: arXiv:2403.08448v1 Announce Type: new  Abstract: Designing control policies for stabilization tasks with provable guarantees is a long-standing problem in nonlinear control. A crucial performance metric is the size of the resulting region of attraction, which essentially serves as a robustness \"margin\" of the closed-loop system against uncertainties. In this paper, we propose a new method to train a stabilizing neural network controller along with its corresponding Lyapunov certificate, aiming to maximize the resulting region of attraction while respecting the actuation constraints. Crucial to our approach is the use of Zubov's Partial Differential Equation (PDE), which precisely characterizes the true region of attraction of a given control policy. Our framework follows an actor-critic pattern where we alternate between improving the control policy (actor) and learning a Zubov function (critic). Finally, we compute the largest certifiable region of attraction by invoking an SMT solver",
    "path": "papers/24/03/2403.08448.json",
    "total_tokens": 888,
    "translated_title": "《基于演员评论者物理信息神经李雅普诺夫控制》",
    "translated_abstract": "设计具有可证保证的稳定化任务控制策略是非线性控制中的一个长期问题。关键的性能指标是产生区域吸引力的大小，这基本上充当了封闭环系统对不确定性的弹性“边界”。本文提出了一种新方法，用于训练一个稳定的神经网络控制器以及其对应的李雅普诺夫证书，旨在最大化产生的区域吸引力，同时尊重激励约束。我们方法的关键之处在于使用祖博夫的偏微分方程（PDE），该方程精确地表征了给定控制策略的真实区域吸引力。我们的框架遵循演员评论者模式，我们在改进控制策略（演员）和学习祖博夫函数（评论者）之间交替进行。最后，我们通过调用SMT求解器计算出最大的可证区域吸引力。",
    "tldr": "提出了一种新方法，通过使用祖博夫的偏微分方程（PDE）来训练神经网络控制器，以及对应的李雅普诺夫证书，以最大化区域吸引力，并尊重激励约束。",
    "en_tdlr": "A novel method is proposed to train a neural network controller with its corresponding Lyapunov certificate using Zubov's Partial Differential Equation (PDE) to maximize the region of attraction and satisfy actuation constraints."
}