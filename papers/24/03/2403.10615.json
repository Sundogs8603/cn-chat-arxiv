{
    "title": "LightIt: Illumination Modeling and Control for Diffusion Models",
    "abstract": "arXiv:2403.10615v1 Announce Type: cross  Abstract: We introduce LightIt, a method for explicit illumination control for image generation. Recent generative methods lack lighting control, which is crucial to numerous artistic aspects of image generation such as setting the overall mood or cinematic appearance. To overcome these limitations, we propose to condition the generation on shading and normal maps. We model the lighting with single bounce shading, which includes cast shadows. We first train a shading estimation module to generate a dataset of real-world images and shading pairs. Then, we train a control network using the estimated shading and normals as input. Our method demonstrates high-quality image generation and lighting control in numerous scenes. Additionally, we use our generated dataset to train an identity-preserving relighting model, conditioned on an image and a target shading. Our method is the first that enables the generation of images with controllable, consisten",
    "link": "https://arxiv.org/abs/2403.10615",
    "context": "Title: LightIt: Illumination Modeling and Control for Diffusion Models\nAbstract: arXiv:2403.10615v1 Announce Type: cross  Abstract: We introduce LightIt, a method for explicit illumination control for image generation. Recent generative methods lack lighting control, which is crucial to numerous artistic aspects of image generation such as setting the overall mood or cinematic appearance. To overcome these limitations, we propose to condition the generation on shading and normal maps. We model the lighting with single bounce shading, which includes cast shadows. We first train a shading estimation module to generate a dataset of real-world images and shading pairs. Then, we train a control network using the estimated shading and normals as input. Our method demonstrates high-quality image generation and lighting control in numerous scenes. Additionally, we use our generated dataset to train an identity-preserving relighting model, conditioned on an image and a target shading. Our method is the first that enables the generation of images with controllable, consisten",
    "path": "papers/24/03/2403.10615.json",
    "total_tokens": 845,
    "translated_title": "LightIt：扩散模型的照明建模与控制",
    "translated_abstract": "我们介绍了LightIt，这是一种用于图像生成的显式照明控制方法。最近的生成方法缺乏照明控制，而这对于图像生成的许多艺术方面至关重要，比如设置整体情绪或电影外观。为了克服这些限制，我们提出在生成过程中以遮蔽和法线图为条件。我们使用单次反射遮蔽来建模照明，包括投射阴影。我们首先训练一个遮蔽估计模块来生成真实世界图像和遮蔽对的数据集。然后，我们使用估计的遮蔽和法线作为输入训练控制网络。我们的方法展示了在许多场景中高质量的图像生成和照明控制。此外，我们使用我们生成的数据集来训练一个保持身份的重照模型，以图像和目标遮蔽为条件。我们的方法是第一个能够生成具有可控、一致性的图像的方法。",
    "tldr": "LightIt提出了一种用于图像生成的显式照明控制方法，通过条件生成来实现对图像生成的照明控制，同时训练了一个身份保持的重照模型。",
    "en_tdlr": "LightIt proposes an explicit illumination control method for image generation, achieving lighting control through conditional generation and training an identity-preserving relighting model."
}