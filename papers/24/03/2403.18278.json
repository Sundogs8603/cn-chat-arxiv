{
    "title": "Identification and Uses of Deep Learning Backbones via Pattern Mining",
    "abstract": "arXiv:2403.18278v1 Announce Type: new  Abstract: Deep learning is extensively used in many areas of data mining as a black-box method with impressive results. However, understanding the core mechanism of how deep learning makes predictions is a relatively understudied problem. Here we explore the notion of identifying a backbone of deep learning for a given group of instances. A group here can be instances of the same class or even misclassified instances of the same class. We view each instance for a given group as activating a subset of neurons and attempt to find a subgraph of neurons associated with a given concept/group. We formulate this problem as a set cover style problem and show it is intractable and presents a highly constrained integer linear programming (ILP) formulation. As an alternative, we explore a coverage-based heuristic approach related to pattern mining, and show it converges to a Pareto equilibrium point of the ILP formulation. Experimentally we explore these bac",
    "link": "https://arxiv.org/abs/2403.18278",
    "context": "Title: Identification and Uses of Deep Learning Backbones via Pattern Mining\nAbstract: arXiv:2403.18278v1 Announce Type: new  Abstract: Deep learning is extensively used in many areas of data mining as a black-box method with impressive results. However, understanding the core mechanism of how deep learning makes predictions is a relatively understudied problem. Here we explore the notion of identifying a backbone of deep learning for a given group of instances. A group here can be instances of the same class or even misclassified instances of the same class. We view each instance for a given group as activating a subset of neurons and attempt to find a subgraph of neurons associated with a given concept/group. We formulate this problem as a set cover style problem and show it is intractable and presents a highly constrained integer linear programming (ILP) formulation. As an alternative, we explore a coverage-based heuristic approach related to pattern mining, and show it converges to a Pareto equilibrium point of the ILP formulation. Experimentally we explore these bac",
    "path": "papers/24/03/2403.18278.json",
    "total_tokens": 958,
    "translated_title": "通过模式挖掘识别和使用深度学习骨干",
    "translated_abstract": "arXiv:2403.18278v1 公告类型: 新摘要: 深度学习作为一种黑盒方法在许多数据挖掘领域被广泛使用，并取得了令人印象深刻的结果。然而，理解深度学习如何进行预测的核心机制是一个相对少被研究的问题。本文探讨了为给定组实例识别深度学习的骨干的概念。这里的“组”可以是同一类别的实例，甚至是同一类别的误分类实例。我们将给定组的每个实例视为激活一组神经元，并尝试找到与给定概念/组相关联的神经元子图。我们将这个问题定义为集合覆盖风格问题，并展示了它是不可解的，并提出了高度受限的整数线性规划（ILP）公式。作为替代，我们探讨了一种基于覆盖率的启发式方法，与模式挖掘相关，并展示了它收敛到ILP公式的帕累托均衡点。在实验中，我们探索了这些背景",
    "tldr": "通过模式挖掘识别和使用深度学习骨干，研究了深度学习如何进行预测的核心机制，提出了集合覆盖风格问题和相关的启发式方法，并表明其收敛到ILP公式的帕累托均衡点。",
    "en_tdlr": "The paper identifies and utilizes deep learning backbones through pattern mining, explores the core mechanism of deep learning predictions, presents a set cover style problem and its related heuristic approach, showing convergence to a Pareto equilibrium point of the ILP formulation."
}