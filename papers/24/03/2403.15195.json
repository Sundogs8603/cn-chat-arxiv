{
    "title": "FSD-Inference: Fully Serverless Distributed Inference with Scalable Cloud Communication",
    "abstract": "arXiv:2403.15195v1 Announce Type: cross  Abstract: Serverless computing offers attractive scalability, elasticity and cost-effectiveness. However, constraints on memory, CPU and function runtime have hindered its adoption for data-intensive applications and machine learning (ML) workloads. Traditional 'server-ful' platforms enable distributed computation via fast networks and well-established inter-process communication (IPC) mechanisms such as MPI and shared memory. In the absence of such solutions in the serverless domain, parallel computation with significant IPC requirements is challenging. We present FSD-Inference, the first fully serverless and highly scalable system for distributed ML inference. We explore potential communication channels, in conjunction with Function-as-a-Service (FaaS) compute, to design a state-of-the-art solution for distributed ML within the context of serverless data-intensive computing. We introduce novel fully serverless communication schemes for ML infe",
    "link": "https://arxiv.org/abs/2403.15195",
    "context": "Title: FSD-Inference: Fully Serverless Distributed Inference with Scalable Cloud Communication\nAbstract: arXiv:2403.15195v1 Announce Type: cross  Abstract: Serverless computing offers attractive scalability, elasticity and cost-effectiveness. However, constraints on memory, CPU and function runtime have hindered its adoption for data-intensive applications and machine learning (ML) workloads. Traditional 'server-ful' platforms enable distributed computation via fast networks and well-established inter-process communication (IPC) mechanisms such as MPI and shared memory. In the absence of such solutions in the serverless domain, parallel computation with significant IPC requirements is challenging. We present FSD-Inference, the first fully serverless and highly scalable system for distributed ML inference. We explore potential communication channels, in conjunction with Function-as-a-Service (FaaS) compute, to design a state-of-the-art solution for distributed ML within the context of serverless data-intensive computing. We introduce novel fully serverless communication schemes for ML infe",
    "path": "papers/24/03/2403.15195.json",
    "total_tokens": 839,
    "translated_title": "FSD-Inference: 具有可扩展云通信的完全无服务器分布式推断",
    "translated_abstract": "arXiv:2403.15195v1 公告类型:跨领域 抽象: 无服务器计算提供了具有吸引力的可伸缩性、弹性和成本效益。然而，对内存、CPU和函数运行时间的限制阻碍了其在数据密集型应用和机器学习（ML）工作负载中的应用。传统的“全服务器”平台通过快速网络和已建立良好的进程间通信（IPC）机制（如MPI和共享内存）实现了分布式计算。在无服务器领域缺乏此类解决方案的情况下，具有重要IPC要求的并行计算具有挑战性。我们提出FSD-Inference，这是第一个完全无服务器且高度可扩展的分布式ML推断系统。我们探讨潜在的通信渠道，与函数即服务（FaaS）计算相结合，为无服务器数据密集型计算环境中的分布式ML设计了一流的解决方案。我们引入了用于ML推断的全新无服务器通信方案。",
    "tldr": "FSD-Inference是第一个完全无服务器且高度可扩展的分布式ML推断系统，引入了全新的无服务器通信方案。",
    "en_tdlr": "FSD-Inference is the first fully serverless and highly scalable system for distributed ML inference, introducing novel fully serverless communication schemes."
}