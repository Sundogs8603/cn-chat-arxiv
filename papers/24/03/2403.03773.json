{
    "title": "Verified Training for Counterfactual Explanation Robustness under Data Shift",
    "abstract": "arXiv:2403.03773v1 Announce Type: new  Abstract: Counterfactual explanations (CEs) enhance the interpretability of machine learning models by describing what changes to an input are necessary to change its prediction to a desired class. These explanations are commonly used to guide users' actions, e.g., by describing how a user whose loan application was denied can be approved for a loan in the future. Existing approaches generate CEs by focusing on a single, fixed model, and do not provide any formal guarantees on the CEs' future validity. When models are updated periodically to account for data shift, if the generated CEs are not robust to the shifts, users' actions may no longer have the desired impacts on their predictions. This paper introduces VeriTraCER, an approach that jointly trains a classifier and an explainer to explicitly consider the robustness of the generated CEs to small model shifts. VeriTraCER optimizes over a carefully designed loss function that ensures the verifi",
    "link": "https://arxiv.org/abs/2403.03773",
    "context": "Title: Verified Training for Counterfactual Explanation Robustness under Data Shift\nAbstract: arXiv:2403.03773v1 Announce Type: new  Abstract: Counterfactual explanations (CEs) enhance the interpretability of machine learning models by describing what changes to an input are necessary to change its prediction to a desired class. These explanations are commonly used to guide users' actions, e.g., by describing how a user whose loan application was denied can be approved for a loan in the future. Existing approaches generate CEs by focusing on a single, fixed model, and do not provide any formal guarantees on the CEs' future validity. When models are updated periodically to account for data shift, if the generated CEs are not robust to the shifts, users' actions may no longer have the desired impacts on their predictions. This paper introduces VeriTraCER, an approach that jointly trains a classifier and an explainer to explicitly consider the robustness of the generated CEs to small model shifts. VeriTraCER optimizes over a carefully designed loss function that ensures the verifi",
    "path": "papers/24/03/2403.03773.json",
    "total_tokens": 841,
    "translated_title": "针对数据偏移下反事实解释健壮性的验证训练",
    "translated_abstract": "反事实解释（CEs）通过描述对输入的哪些更改是必要的，以将其预测改变为所需类别，提高了机器学习模型的可解释性。这些解释通常用于指导用户的行动，例如，通过描述一个贷款申请被拒绝的用户如何在未来可以获批贷款。现有方法通过专注于单个固定模型生成CEs，并未对CEs的未来有效性提供任何正式保证。当模型定期更新以考虑数据偏移时，如果生成的CEs对偏移不具有健壮性，用户的行动可能不再对其预测产生期望的影响。本文介绍了VeriTraCER，一种联合训练分类器和解释器的方法，明确考虑生成的CEs对小型模型偏移的健壮性。VeriTraCER通过一个精心设计的损失函数进行优化，确保验证",
    "tldr": "本文引入了VeriTraCER，一种联合训练分类器和解释器的方法，以显式考虑生成的CEs对小型模型偏移的健壮性。",
    "en_tdlr": "This paper introduces VeriTraCER, an approach that jointly trains a classifier and an explainer to explicitly consider the robustness of the generated CEs to small model shifts."
}