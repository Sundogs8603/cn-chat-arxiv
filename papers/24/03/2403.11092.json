{
    "title": "Lost in Translation? Translation Errors and Challenges for Fair Assessment of Text-to-Image Models on Multilingual Concepts",
    "abstract": "arXiv:2403.11092v1 Announce Type: cross  Abstract: Benchmarks of the multilingual capabilities of text-to-image (T2I) models compare generated images prompted in a test language to an expected image distribution over a concept set. One such benchmark, \"Conceptual Coverage Across Languages\" (CoCo-CroLa), assesses the tangible noun inventory of T2I models by prompting them to generate pictures from a concept list translated to seven languages and comparing the output image populations. Unfortunately, we find that this benchmark contains translation errors of varying severity in Spanish, Japanese, and Chinese. We provide corrections for these errors and analyze how impactful they are on the utility and validity of CoCo-CroLa as a benchmark. We reassess multiple baseline T2I models with the revisions, compare the outputs elicited under the new translations to those conditioned on the old, and show that a correction's impactfulness on the image-domain benchmark results can be predicted in t",
    "link": "https://arxiv.org/abs/2403.11092",
    "context": "Title: Lost in Translation? Translation Errors and Challenges for Fair Assessment of Text-to-Image Models on Multilingual Concepts\nAbstract: arXiv:2403.11092v1 Announce Type: cross  Abstract: Benchmarks of the multilingual capabilities of text-to-image (T2I) models compare generated images prompted in a test language to an expected image distribution over a concept set. One such benchmark, \"Conceptual Coverage Across Languages\" (CoCo-CroLa), assesses the tangible noun inventory of T2I models by prompting them to generate pictures from a concept list translated to seven languages and comparing the output image populations. Unfortunately, we find that this benchmark contains translation errors of varying severity in Spanish, Japanese, and Chinese. We provide corrections for these errors and analyze how impactful they are on the utility and validity of CoCo-CroLa as a benchmark. We reassess multiple baseline T2I models with the revisions, compare the outputs elicited under the new translations to those conditioned on the old, and show that a correction's impactfulness on the image-domain benchmark results can be predicted in t",
    "path": "papers/24/03/2403.11092.json",
    "total_tokens": 835,
    "translated_title": "翻译困境？跨语言概念上对文本到图像模型公平评估的翻译错误与挑战",
    "translated_abstract": "通过将概念列表翻译成七种语言，将刺激生成的图像与预期的图像分布进行比较，评估了文本到图像（T2I）模型的多语言能力基准。不幸的是，我们发现这个基准在西班牙语、日语和中文中存在不同严重程度的翻译错误。我们提供了这些错误的更正，并分析了它们对CoCo-CroLa作为基准的效用和有效性的影响。我们通过修订后重新评估了多个基线T2I模型，比较了在新翻译下引发的输出与在旧翻译下引发的输出，并展示了修正对图像领域基准结果的影响程度是可以预测的。",
    "tldr": "本研究发现在一个文本到图像模型基准中存在西班牙语、日语和中文中不同程度的翻译错误，提供了纠正，并分析了对基准性能的影响。",
    "en_tdlr": "This study identifies translation errors of varying severity in Spanish, Japanese, and Chinese within a benchmark for text-to-image models, provides corrections, and analyzes their impact on benchmark performance."
}