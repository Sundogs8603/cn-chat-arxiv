{
    "title": "Prompt Selection and Augmentation for Few Examples Code Generation in Large Language Model and its Application in Robotics Control",
    "abstract": "arXiv:2403.12999v1 Announce Type: cross  Abstract: Few-shot prompting and step-by-step reasoning have enhanced the capabilities of Large Language Models (LLMs) in tackling complex tasks including code generation. In this paper, we introduce a prompt selection and augmentation algorithm aimed at improving mathematical reasoning and robot arm operations. Our approach incorporates a multi-stage example augmentation scheme combined with an example selection scheme. This algorithm improves LLM performance by selecting a set of examples that increase diversity, minimize redundancy, and increase relevance to the question. When combined with the Program-of-Thought prompting, our algorithm demonstrates an improvement in performance on the GSM8K and SVAMP benchmarks, with increases of 0.3% and 1.1% respectively. Furthermore, in simulated tabletop environments, our algorithm surpasses the Code-as-Policies approach by achieving a 3.4% increase in successful task completions and a decrease of over ",
    "link": "https://arxiv.org/abs/2403.12999",
    "context": "Title: Prompt Selection and Augmentation for Few Examples Code Generation in Large Language Model and its Application in Robotics Control\nAbstract: arXiv:2403.12999v1 Announce Type: cross  Abstract: Few-shot prompting and step-by-step reasoning have enhanced the capabilities of Large Language Models (LLMs) in tackling complex tasks including code generation. In this paper, we introduce a prompt selection and augmentation algorithm aimed at improving mathematical reasoning and robot arm operations. Our approach incorporates a multi-stage example augmentation scheme combined with an example selection scheme. This algorithm improves LLM performance by selecting a set of examples that increase diversity, minimize redundancy, and increase relevance to the question. When combined with the Program-of-Thought prompting, our algorithm demonstrates an improvement in performance on the GSM8K and SVAMP benchmarks, with increases of 0.3% and 1.1% respectively. Furthermore, in simulated tabletop environments, our algorithm surpasses the Code-as-Policies approach by achieving a 3.4% increase in successful task completions and a decrease of over ",
    "path": "papers/24/03/2403.12999.json",
    "total_tokens": 807,
    "translated_title": "大型语言模型中的少样本代码生成中的提示选择和增强以及其在机器人控制中的应用",
    "translated_abstract": "少样本提示和逐步推理已经增强了大型语言模型（LLMs）在处理包括代码生成在内的复杂任务的能力。在本文中，我们介绍了一个旨在改善数学推理和机器人臂操作的提示选择和增强算法。我们的方法结合了多阶段示例增强方案和示例选择方案。该算法通过选择一组增加多样性、最小化冗余并增加与问题相关性的示例来提高LLM性能。当与“思维编程”提示结合使用时，我们的算法在GSM8K和SVAMP基准测试中表现出性能改进，分别增加了0.3%和1.1%。此外，在模拟桌面环境中，我们的算法通过实现成功任务完成率提高了3.4%，并且成功完成任务的时间减少了。",
    "tldr": "本文介绍了一个提示选择和增强算法，通过优化示例选择和增强，提高了大型语言模型在代码生成和机器人控制方面的性能。",
    "en_tdlr": "This paper introduces a prompt selection and augmentation algorithm that enhances the performance of Large Language Models in code generation and robotics control by optimizing example selection and augmentation."
}