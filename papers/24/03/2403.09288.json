{
    "title": "Adversarial Training with OCR Modality Perturbation for Scene-Text Visual Question Answering",
    "abstract": "arXiv:2403.09288v1 Announce Type: cross  Abstract: Scene-Text Visual Question Answering (ST-VQA) aims to understand scene text in images and answer questions related to the text content. Most existing methods heavily rely on the accuracy of Optical Character Recognition (OCR) systems, and aggressive fine-tuning based on limited spatial location information and erroneous OCR text information often leads to inevitable overfitting. In this paper, we propose a multimodal adversarial training architecture with spatial awareness capabilities. Specifically, we introduce an Adversarial OCR Enhancement (AOE) module, which leverages adversarial training in the embedding space of OCR modality to enhance fault-tolerant representation of OCR texts, thereby reducing noise caused by OCR errors. Simultaneously, We add a Spatial-Aware Self-Attention (SASA) mechanism to help the model better capture the spatial relationships among OCR tokens. Various experiments demonstrate that our method achieves sign",
    "link": "https://arxiv.org/abs/2403.09288",
    "context": "Title: Adversarial Training with OCR Modality Perturbation for Scene-Text Visual Question Answering\nAbstract: arXiv:2403.09288v1 Announce Type: cross  Abstract: Scene-Text Visual Question Answering (ST-VQA) aims to understand scene text in images and answer questions related to the text content. Most existing methods heavily rely on the accuracy of Optical Character Recognition (OCR) systems, and aggressive fine-tuning based on limited spatial location information and erroneous OCR text information often leads to inevitable overfitting. In this paper, we propose a multimodal adversarial training architecture with spatial awareness capabilities. Specifically, we introduce an Adversarial OCR Enhancement (AOE) module, which leverages adversarial training in the embedding space of OCR modality to enhance fault-tolerant representation of OCR texts, thereby reducing noise caused by OCR errors. Simultaneously, We add a Spatial-Aware Self-Attention (SASA) mechanism to help the model better capture the spatial relationships among OCR tokens. Various experiments demonstrate that our method achieves sign",
    "path": "papers/24/03/2403.09288.json",
    "total_tokens": 832,
    "translated_title": "具有OCR模态扰动的对抗训练用于场景文本视觉问答",
    "translated_abstract": "Scene-Text Visual Question Answering（ST-VQA）旨在理解图像中的场景文本并回答与文本内容相关的问题。本文提出了一种具有空间感知能力的多模态对抗训练架构。具体来说，我们引入了一个Adversarial OCR Enhancement（AOE）模块，在OCR模态的嵌入空间中利用对抗训练来增强OCR文本的容错表示，从而减少OCR错误引起的噪音。同时，我们添加了一个空间感知自注意力（SASA）机制，帮助模型更好地捕捉OCR标记之间的空间关系。各种实验表明，我们的方法取得了显著的成果。",
    "tldr": "该论文提出了一种具有空间感知能力的多模态对抗训练架构，通过Adversarial OCR Enhancement（AOE）模块和空间感知自注意力（SASA）机制，可以增强OCR文本的容错性，并帮助模型更好地捕捉OCR标记之间的空间关系。",
    "en_tdlr": "The paper presents a multimodal adversarial training architecture with spatial awareness capabilities, leveraging Adversarial OCR Enhancement (AOE) module and Spatial-Aware Self-Attention (SASA) mechanism to enhance fault-tolerant representation of OCR texts and capture spatial relationships among OCR tokens more effectively."
}