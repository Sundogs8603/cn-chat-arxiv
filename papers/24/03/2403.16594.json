{
    "title": "EDUE: Expert Disagreement-Guided One-Pass Uncertainty Estimation for Medical Image Segmentation",
    "abstract": "arXiv:2403.16594v1 Announce Type: cross  Abstract: Deploying deep learning (DL) models in medical applications relies on predictive performance and other critical factors, such as conveying trustworthy predictive uncertainty. Uncertainty estimation (UE) methods provide potential solutions for evaluating prediction reliability and improving the model confidence calibration. Despite increasing interest in UE, challenges persist, such as the need for explicit methods to capture aleatoric uncertainty and align uncertainty estimates with real-life disagreements among domain experts. This paper proposes an Expert Disagreement-Guided Uncertainty Estimation (EDUE) for medical image segmentation. By leveraging variability in ground-truth annotations from multiple raters, we guide the model during training and incorporate random sampling-based strategies to enhance calibration confidence. Our method achieves 55% and 23% improvement in correlation on average with expert disagreements at the image",
    "link": "https://arxiv.org/abs/2403.16594",
    "context": "Title: EDUE: Expert Disagreement-Guided One-Pass Uncertainty Estimation for Medical Image Segmentation\nAbstract: arXiv:2403.16594v1 Announce Type: cross  Abstract: Deploying deep learning (DL) models in medical applications relies on predictive performance and other critical factors, such as conveying trustworthy predictive uncertainty. Uncertainty estimation (UE) methods provide potential solutions for evaluating prediction reliability and improving the model confidence calibration. Despite increasing interest in UE, challenges persist, such as the need for explicit methods to capture aleatoric uncertainty and align uncertainty estimates with real-life disagreements among domain experts. This paper proposes an Expert Disagreement-Guided Uncertainty Estimation (EDUE) for medical image segmentation. By leveraging variability in ground-truth annotations from multiple raters, we guide the model during training and incorporate random sampling-based strategies to enhance calibration confidence. Our method achieves 55% and 23% improvement in correlation on average with expert disagreements at the image",
    "path": "papers/24/03/2403.16594.json",
    "total_tokens": 927,
    "translated_title": "EDUE:专家分歧引导的一次过不确定性估计用于医学图像分割",
    "translated_abstract": "在医学应用中部署深度学习模型依赖于预测性能和其他重要因素，如传达可信的预测不确定性。不确定性估计（UE）方法为评估预测可靠性和提高模型置信度校准提供可能的解决方案。尽管对UE的兴趣日益增加，但仍存在挑战，如需要明确捕获适当不确定性的方法，并将不确定性估计与领域专家之间的现实分歧进行对齐。本文提出了一种专家分歧引导的不确定性估计（EDUE）方法，用于医学图像分割。通过利用来自多个评分者的地面实况注释中的变异性，我们在训练过程中引导模型，并结合基于随机抽样的策略，以增强校准信心。我们的方法在与图像专家分歧平均相关性方面实现了55%和23%的改进。",
    "tldr": "提出了一种专家分歧引导的不确定性估计（EDUE）方法，用于医学图像分割，在训练过程中通过地面实况注释的变异性来引导模型，并采用随机抽样策略以提高校准信心，实现了平均55%和23%的相关性改进。",
    "en_tdlr": "Proposed an Expert Disagreement-Guided Uncertainty Estimation (EDUE) method for medical image segmentation, guiding the model during training by leveraging variability in ground-truth annotations from multiple raters and incorporating random sampling-based strategies to enhance calibration confidence, resulting in an average improvement of 55% and 23% in correlation with expert disagreements."
}