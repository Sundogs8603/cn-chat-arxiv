{
    "title": "Privacy-preserving Fine-tuning of Large Language Models through Flatness",
    "abstract": "arXiv:2403.04124v1 Announce Type: new  Abstract: The privacy concerns associated with the use of Large Language Models (LLMs) have grown recently with the development of LLMs such as ChatGPT. Differential Privacy (DP) techniques are explored in existing work to mitigate their privacy risks at the cost of generalization degradation. Our paper reveals that the flatness of DP-trained models' loss landscape plays an essential role in the trade-off between their privacy and generalization. We further propose a holistic framework to enforce appropriate weight flatness, which substantially improves model generalization with competitive privacy preservation. It innovates from three coarse-to-grained levels, including perturbation-aware min-max optimization on model weights within a layer, flatness-guided sparse prefix-tuning on weights across layers, and weight knowledge distillation between DP \\& non-DP weights copies. Comprehensive experiments of both black-box and white-box scenarios are co",
    "link": "https://arxiv.org/abs/2403.04124",
    "context": "Title: Privacy-preserving Fine-tuning of Large Language Models through Flatness\nAbstract: arXiv:2403.04124v1 Announce Type: new  Abstract: The privacy concerns associated with the use of Large Language Models (LLMs) have grown recently with the development of LLMs such as ChatGPT. Differential Privacy (DP) techniques are explored in existing work to mitigate their privacy risks at the cost of generalization degradation. Our paper reveals that the flatness of DP-trained models' loss landscape plays an essential role in the trade-off between their privacy and generalization. We further propose a holistic framework to enforce appropriate weight flatness, which substantially improves model generalization with competitive privacy preservation. It innovates from three coarse-to-grained levels, including perturbation-aware min-max optimization on model weights within a layer, flatness-guided sparse prefix-tuning on weights across layers, and weight knowledge distillation between DP \\& non-DP weights copies. Comprehensive experiments of both black-box and white-box scenarios are co",
    "path": "papers/24/03/2403.04124.json",
    "total_tokens": 950,
    "translated_title": "通过平坦性实现对大型语言模型的隐私保护微调",
    "translated_abstract": "最近随着诸如ChatGPT之类的大型语言模型（LLMs）的发展，与使用LLMs相关的隐私问题日益增加。现有工作探索了使用差分隐私（DP）技术来减轻其隐私风险的方法，但以泛化降级为代价。我们的论文揭示了DP训练模型的损失景观的平坦性在它们的隐私和泛化之间的权衡中起着至关重要的作用。我们进一步提出了一个全面的框架来强制实施适当的权重平坦化，这大大提高了模型的泛化能力，并具有竞争性的隐私保护。它从三个粗到精的层次进行创新，包括对层内模型权重进行扰动感知的最小-最大优化、跨层权重进行平坦引导的稀疏前缀微调，以及在DP和非DP权重副本之间进行权重知识蒸馏。全面的黑盒和白盒场景实验。",
    "tldr": "论文揭示了DP训练模型的损失景观的平坦性在隐私和泛化之间的权衡中起着关键作用，并提出了一种全面的框架，通过强制实施适当的权重平坦化来显著提高模型的泛化能力，同时保留竞争性的隐私保护。"
}