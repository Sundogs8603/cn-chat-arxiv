{
    "title": "Coupled generator decomposition for fusion of electro- and magnetoencephalography data",
    "abstract": "arXiv:2403.15409v1 Announce Type: cross  Abstract: Data fusion modeling can identify common features across diverse data sources while accounting for source-specific variability. Here we introduce the concept of a \\textit{coupled generator decomposition} and demonstrate how it generalizes sparse principal component analysis (SPCA) for data fusion. Leveraging data from a multisubject, multimodal (electro- and magnetoencephalography (EEG and MEG)) neuroimaging experiment, we demonstrate the efficacy of the framework in identifying common features in response to face perception stimuli, while accommodating modality- and subject-specific variability. Through split-half cross-validation of EEG/MEG trials, we investigate the optimal model order and regularization strengths for models of varying complexity, comparing these to a group-level model assuming shared brain responses to stimuli. Our findings reveal altered $\\sim170ms$ fusiform face area activation for scrambled faces, as opposed to ",
    "link": "https://arxiv.org/abs/2403.15409",
    "context": "Title: Coupled generator decomposition for fusion of electro- and magnetoencephalography data\nAbstract: arXiv:2403.15409v1 Announce Type: cross  Abstract: Data fusion modeling can identify common features across diverse data sources while accounting for source-specific variability. Here we introduce the concept of a \\textit{coupled generator decomposition} and demonstrate how it generalizes sparse principal component analysis (SPCA) for data fusion. Leveraging data from a multisubject, multimodal (electro- and magnetoencephalography (EEG and MEG)) neuroimaging experiment, we demonstrate the efficacy of the framework in identifying common features in response to face perception stimuli, while accommodating modality- and subject-specific variability. Through split-half cross-validation of EEG/MEG trials, we investigate the optimal model order and regularization strengths for models of varying complexity, comparing these to a group-level model assuming shared brain responses to stimuli. Our findings reveal altered $\\sim170ms$ fusiform face area activation for scrambled faces, as opposed to ",
    "path": "papers/24/03/2403.15409.json",
    "total_tokens": 918,
    "translated_title": "耦合发生器分解用于融合脑电图和脑磁图数据",
    "translated_abstract": "数据融合建模可以识别跨不同数据源的共同特征，同时考虑源特异性变异。在这里，我们介绍了\\textit{耦合发生器分解}的概念，展示了它如何推广了数据融合的稀疏主成分分析（SPCA）。通过利用多个受试者、多模态（脑电图和脑磁图（EEG和MEG））神经影像实验的数据，我们展示了该框架在识别对面部知觉刺激的共同特征方面的效果，同时考虑了模态和受试者特异性变异。通过脑电图/脑磁图试验的拆分交叉验证，我们研究了不同复杂性模型的最佳模型顺序和正则化强度，将其与假设对刺激有共享脑反应的群体水平模型进行比较。我们的发现显示，与混乱的面孔相比，约$\\sim170ms$颞下回面区激活发生了改变。",
    "tldr": "介绍了耦合发生器分解的概念，推广了稀疏主成分分析（SPCA），并通过脑电图和脑磁图数据的融合实验展示了其在识别共同特征的有效性。"
}