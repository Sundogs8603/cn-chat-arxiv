{
    "title": "Regulating Large Language Models: A Roundtable Report",
    "abstract": "arXiv:2403.15397v1 Announce Type: cross  Abstract: On July 20, 2023, a group of 27 scholars and digital rights advocates with expertise in law, computer science, political science, and other disciplines gathered for the Large Language Models, Law and Policy Roundtable, co-hosted by the NYU School of Law's Information Law Institute and the Center for Democracy & Technology. The roundtable convened to discuss how law and policy can help address some of the larger societal problems posed by large language models (LLMs). The discussion focused on three policy topic areas in particular:   1. Truthfulness: What risks do LLMs pose in terms of generating mis- and disinformation? How can these risks be mitigated from a technical and/or regulatory perspective?   2. Privacy: What are the biggest privacy risks involved in the creation, deployment, and use of LLMs? How can these risks be mitigated from a technical and/or regulatory perspective?   3. Market concentration: What threats do LLMs pose c",
    "link": "https://arxiv.org/abs/2403.15397",
    "context": "Title: Regulating Large Language Models: A Roundtable Report\nAbstract: arXiv:2403.15397v1 Announce Type: cross  Abstract: On July 20, 2023, a group of 27 scholars and digital rights advocates with expertise in law, computer science, political science, and other disciplines gathered for the Large Language Models, Law and Policy Roundtable, co-hosted by the NYU School of Law's Information Law Institute and the Center for Democracy & Technology. The roundtable convened to discuss how law and policy can help address some of the larger societal problems posed by large language models (LLMs). The discussion focused on three policy topic areas in particular:   1. Truthfulness: What risks do LLMs pose in terms of generating mis- and disinformation? How can these risks be mitigated from a technical and/or regulatory perspective?   2. Privacy: What are the biggest privacy risks involved in the creation, deployment, and use of LLMs? How can these risks be mitigated from a technical and/or regulatory perspective?   3. Market concentration: What threats do LLMs pose c",
    "path": "papers/24/03/2403.15397.json",
    "total_tokens": 886,
    "translated_title": "管控大型语言模型：圆桌报告",
    "translated_abstract": "在2023年7月20日，一群具有法律、计算机科学、政治科学等专业知识的27名学者和数字权利倡导者聚集在纽约大学法学院信息法律研究所和民主与科技中心联合举办的大型语言模型、法律和政策圆桌会议上。圆桌会议旨在讨论法律和政策如何帮助解决大型语言模型（LLMs）带来的一些较大社会问题。讨论主要集中在三个政策领域：1.真实性：LLMs在生成误信息和假信息方面存在哪些风险？从技术和/或监管的角度如何减轻这些风险？2.隐私：在创建、部署和使用LLMs过程中涉及哪些最大的隐私风险？如何从技术和/或监管的角度减轻这些风险？3.市场集中：LLMs带来了哪些市场集中的威胁？",
    "tldr": "圆桌会议探讨了如何通过法律和政策来解决大型语言模型可能带来的真实性、隐私和市场集中等方面的重要社会问题。",
    "en_tdlr": "The roundtable discussed how to address significant societal issues posed by large language models in terms of truthfulness, privacy, and market concentration through law and policy."
}