{
    "title": "Block-wise LoRA: Revisiting Fine-grained LoRA for Effective Personalization and Stylization in Text-to-Image Generation",
    "abstract": "arXiv:2403.07500v1 Announce Type: cross  Abstract: The objective of personalization and stylization in text-to-image is to instruct a pre-trained diffusion model to analyze new concepts introduced by users and incorporate them into expected styles. Recently, parameter-efficient fine-tuning (PEFT) approaches have been widely adopted to address this task and have greatly propelled the development of this field. Despite their popularity, existing efficient fine-tuning methods still struggle to achieve effective personalization and stylization in T2I generation. To address this issue, we propose block-wise Low-Rank Adaptation (LoRA) to perform fine-grained fine-tuning for different blocks of SD, which can generate images faithful to input prompts and target identity and also with desired style. Extensive experiments demonstrate the effectiveness of the proposed method.",
    "link": "https://arxiv.org/abs/2403.07500",
    "context": "Title: Block-wise LoRA: Revisiting Fine-grained LoRA for Effective Personalization and Stylization in Text-to-Image Generation\nAbstract: arXiv:2403.07500v1 Announce Type: cross  Abstract: The objective of personalization and stylization in text-to-image is to instruct a pre-trained diffusion model to analyze new concepts introduced by users and incorporate them into expected styles. Recently, parameter-efficient fine-tuning (PEFT) approaches have been widely adopted to address this task and have greatly propelled the development of this field. Despite their popularity, existing efficient fine-tuning methods still struggle to achieve effective personalization and stylization in T2I generation. To address this issue, we propose block-wise Low-Rank Adaptation (LoRA) to perform fine-grained fine-tuning for different blocks of SD, which can generate images faithful to input prompts and target identity and also with desired style. Extensive experiments demonstrate the effectiveness of the proposed method.",
    "path": "papers/24/03/2403.07500.json",
    "total_tokens": 782,
    "translated_title": "分块LoRA：重新审视文本到图像生成中的细粒度LoRA以实现有效的个性化和风格化",
    "translated_abstract": "个性化和风格化在文本到图像中的目标是指导一个预训练扩散模型分析用户引入的新概念，并将其融入到预期的风格中。 最近，广泛采用了参数高效微调（PEFT）方法来解决这一任务，并极大推动了该领域的发展。 尽管它们很受欢迎，现有的高效微调方法仍然难以实现文本到图像生成中的有效个性化和风格化。 为了解决这个问题，我们提出了分块低秩适应（LoRA）以对SD的不同块执行细粒度微调，可以生成忠实于输入提示和目标身份且具有所需样式的图像。 大量实验证明了所提方法的有效性。",
    "tldr": "提出了分块低秩适应（LoRA）方法，在文本到图像生成中实现了有效的个性化和风格化细粒度微调。"
}