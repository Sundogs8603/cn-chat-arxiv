{
    "title": "Gujarati-English Code-Switching Speech Recognition using ensemble prediction of spoken language",
    "abstract": "arXiv:2403.08011v1 Announce Type: cross  Abstract: An important and difficult task in code-switched speech recognition is to recognize the language, as lots of words in two languages can sound similar, especially in some accents. We focus on improving performance of end-to-end Automatic Speech Recognition models by conditioning transformer layers on language ID of words and character in the output in an per layer supervised manner. To this end, we propose two methods of introducing language specific parameters and explainability in the multi-head attention mechanism, and implement a Temporal Loss that helps maintain continuity in input alignment. Despite being unable to reduce WER significantly, our method shows promise in predicting the correct language from just spoken data. We introduce regularization in the language prediction by dropping LID in the sequence, which helps align long repeated output sequences.",
    "link": "https://arxiv.org/abs/2403.08011",
    "context": "Title: Gujarati-English Code-Switching Speech Recognition using ensemble prediction of spoken language\nAbstract: arXiv:2403.08011v1 Announce Type: cross  Abstract: An important and difficult task in code-switched speech recognition is to recognize the language, as lots of words in two languages can sound similar, especially in some accents. We focus on improving performance of end-to-end Automatic Speech Recognition models by conditioning transformer layers on language ID of words and character in the output in an per layer supervised manner. To this end, we propose two methods of introducing language specific parameters and explainability in the multi-head attention mechanism, and implement a Temporal Loss that helps maintain continuity in input alignment. Despite being unable to reduce WER significantly, our method shows promise in predicting the correct language from just spoken data. We introduce regularization in the language prediction by dropping LID in the sequence, which helps align long repeated output sequences.",
    "path": "papers/24/03/2403.08011.json",
    "total_tokens": 828,
    "translated_title": "使用集成预测口语言识别的古吉拉特语-英语混合语音识别",
    "translated_abstract": "混合语音识别中一个重要且困难的任务是识别语言，因为两种语言中的许多词在某些口音下听起来相似。我们专注于通过在输出中以每层有监督的方式对单词和字符的语言ID条件化变压器层，以改善端到端自动语音识别模型的性能。为此，我们提出了两种引入语言特定参数和可解释性到多头注意力机制的方法，并实施了一个有助于保持输入对齐连续性的时间损失。尽管无法显著降低词错误率（WER），我们的方法展现了在仅仅通过口语数据预测正确语言的潜力。我们通过在序列中删除LID引入了语言预测的正则化，有助于对齐长重复的输出序列。",
    "tldr": "通过在输出中以每层有监督的方式对单词和字符的语言ID条件化变压器层，该方法虽然未能显著降低词错误率，但展现了在仅仅通过口语数据预测正确语言的潜力。"
}