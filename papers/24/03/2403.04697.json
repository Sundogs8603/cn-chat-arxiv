{
    "title": "AUFormer: Vision Transformers are Parameter-Efficient Facial Action Unit Detectors",
    "abstract": "arXiv:2403.04697v1 Announce Type: cross  Abstract: Facial Action Units (AU) is a vital concept in the realm of affective computing, and AU detection has always been a hot research topic. Existing methods suffer from overfitting issues due to the utilization of a large number of learnable parameters on scarce AU-annotated datasets or heavy reliance on substantial additional relevant data. Parameter-Efficient Transfer Learning (PETL) provides a promising paradigm to address these challenges, whereas its existing methods lack design for AU characteristics. Therefore, we innovatively investigate PETL paradigm to AU detection, introducing AUFormer and proposing a novel Mixture-of-Knowledge Expert (MoKE) collaboration mechanism. An individual MoKE specific to a certain AU with minimal learnable parameters first integrates personalized multi-scale and correlation knowledge. Then the MoKE collaborates with other MoKEs in the expert group to obtain aggregated information and inject it into the ",
    "link": "https://arxiv.org/abs/2403.04697",
    "context": "Title: AUFormer: Vision Transformers are Parameter-Efficient Facial Action Unit Detectors\nAbstract: arXiv:2403.04697v1 Announce Type: cross  Abstract: Facial Action Units (AU) is a vital concept in the realm of affective computing, and AU detection has always been a hot research topic. Existing methods suffer from overfitting issues due to the utilization of a large number of learnable parameters on scarce AU-annotated datasets or heavy reliance on substantial additional relevant data. Parameter-Efficient Transfer Learning (PETL) provides a promising paradigm to address these challenges, whereas its existing methods lack design for AU characteristics. Therefore, we innovatively investigate PETL paradigm to AU detection, introducing AUFormer and proposing a novel Mixture-of-Knowledge Expert (MoKE) collaboration mechanism. An individual MoKE specific to a certain AU with minimal learnable parameters first integrates personalized multi-scale and correlation knowledge. Then the MoKE collaborates with other MoKEs in the expert group to obtain aggregated information and inject it into the ",
    "path": "papers/24/03/2403.04697.json",
    "total_tokens": 859,
    "translated_title": "AUFormer: 视觉Transformer是参数高效的面部动作单位检测器",
    "translated_abstract": "面部动作单位（AU）在情感计算领域是一个重要概念，AU检测一直是一个热门的研究课题。现有方法由于在稀缺的AU注释数据集上利用大量可学习参数或过度依赖大量额外相关数据而存在过拟合问题。参数高效迁移学习（PETL）提供了一个有希望解决这些挑战的范式，然而其现有方法缺乏针对AU特征的设计。因此，我们创新性地将PETL范式应用于AU检测，引入AUFormer并提出了一种新颖的知识混合专家（MoKE）协作机制。一个特定于某个AU并具有最少可学习参数的MoKE首先集成个性化的多尺度和相关知识。然后MoKE与专家组中的其他MoKE合作，获取聚合信息并将其注入到...",
    "tldr": "AUFormer提出了一种参数高效的面部动作单位检测方法，引入了新颖的知识混合专家协作机制，解决了传统方法在稀缺数据集或过度依赖额外数据导致的过拟合问题。",
    "en_tdlr": "AUFormer proposes a parameter-efficient method for facial action unit detection, introducing a novel Mixture-of-Knowledge Expert collaboration mechanism to address overfitting issues caused by sparse datasets or heavy reliance on additional data in traditional methods."
}