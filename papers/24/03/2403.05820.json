{
    "title": "An Audio-textual Diffusion Model For Converting Speech Signals Into Ultrasound Tongue Imaging Data",
    "abstract": "arXiv:2403.05820v1 Announce Type: cross  Abstract: Acoustic-to-articulatory inversion (AAI) is to convert audio into articulator movements, such as ultrasound tongue imaging (UTI) data. An issue of existing AAI methods is only using the personalized acoustic information to derive the general patterns of tongue motions, and thus the quality of generated UTI data is limited. To address this issue, this paper proposes an audio-textual diffusion model for the UTI data generation task. In this model, the inherent acoustic characteristics of individuals related to the tongue motion details are encoded by using wav2vec 2.0, while the ASR transcriptions related to the universality of tongue motions are encoded by using BERT. UTI data are then generated by using a diffusion module. Experimental results showed that the proposed diffusion model could generate high-quality UTI data with clear tongue contour that is crucial for the linguistic analysis and clinical assessment. The project can be fou",
    "link": "https://arxiv.org/abs/2403.05820",
    "context": "Title: An Audio-textual Diffusion Model For Converting Speech Signals Into Ultrasound Tongue Imaging Data\nAbstract: arXiv:2403.05820v1 Announce Type: cross  Abstract: Acoustic-to-articulatory inversion (AAI) is to convert audio into articulator movements, such as ultrasound tongue imaging (UTI) data. An issue of existing AAI methods is only using the personalized acoustic information to derive the general patterns of tongue motions, and thus the quality of generated UTI data is limited. To address this issue, this paper proposes an audio-textual diffusion model for the UTI data generation task. In this model, the inherent acoustic characteristics of individuals related to the tongue motion details are encoded by using wav2vec 2.0, while the ASR transcriptions related to the universality of tongue motions are encoded by using BERT. UTI data are then generated by using a diffusion module. Experimental results showed that the proposed diffusion model could generate high-quality UTI data with clear tongue contour that is crucial for the linguistic analysis and clinical assessment. The project can be fou",
    "path": "papers/24/03/2403.05820.json",
    "total_tokens": 833,
    "translated_title": "一种音频文本扩散模型用于将语音信号转换为超声舌头成像数据",
    "translated_abstract": "声音到语音逆变换（AAI）旨在将音频转换为发音器官运动，如超声舌头成像（UTI）数据。现有AAI方法的一个问题是仅使用个性化音频信息来推导舌头运动的一般模式，因此生成的UTI数据质量有限。为解决这一问题，本文提出了一种用于UTI数据生成任务的音频文本扩散模型。在该模型中，使用wav2vec 2.0对个体相关的舌头运动细节进行编码，而使用BERT对与舌头运动普遍性相关的ASR转录进行编码。然后通过扩散模块生成UTI数据。实验结果表明，所提出的扩散模型能够生成具有清晰舌头轮廓的高质量UTI数据，这对语言分析和临床评估至关重要。",
    "tldr": "提出一种音频文本扩散模型，通过编码个体特征和通用模式，生成高质量超声舌头成像数据，用于语言分析和临床评估。",
    "en_tdlr": "Introducing an audio-textual diffusion model that generates high-quality ultrasound tongue imaging data by encoding individual characteristics and universal patterns, crucial for linguistic analysis and clinical assessment."
}