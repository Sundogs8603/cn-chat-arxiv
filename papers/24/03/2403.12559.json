{
    "title": "Confidence Self-Calibration for Multi-Label Class-Incremental Learning",
    "abstract": "arXiv:2403.12559v1 Announce Type: cross  Abstract: The partial label challenge in Multi-Label Class-Incremental Learning (MLCIL) arises when only the new classes are labeled during training, while past and future labels remain unavailable. This issue leads to a proliferation of false-positive errors due to erroneously high confidence multi-label predictions, exacerbating catastrophic forgetting within the disjoint label space. In this paper, we aim to refine multi-label confidence calibration in MLCIL and propose a Confidence Self-Calibration (CSC) approach. Firstly, for label relationship calibration, we introduce a class-incremental graph convolutional network that bridges the isolated label spaces by constructing learnable, dynamically extended label relationship graph. Then, for confidence calibration, we present a max-entropy regularization for each multi-label increment, facilitating confidence self-calibration through the penalization of over-confident output distributions. Our ",
    "link": "https://arxiv.org/abs/2403.12559",
    "context": "Title: Confidence Self-Calibration for Multi-Label Class-Incremental Learning\nAbstract: arXiv:2403.12559v1 Announce Type: cross  Abstract: The partial label challenge in Multi-Label Class-Incremental Learning (MLCIL) arises when only the new classes are labeled during training, while past and future labels remain unavailable. This issue leads to a proliferation of false-positive errors due to erroneously high confidence multi-label predictions, exacerbating catastrophic forgetting within the disjoint label space. In this paper, we aim to refine multi-label confidence calibration in MLCIL and propose a Confidence Self-Calibration (CSC) approach. Firstly, for label relationship calibration, we introduce a class-incremental graph convolutional network that bridges the isolated label spaces by constructing learnable, dynamically extended label relationship graph. Then, for confidence calibration, we present a max-entropy regularization for each multi-label increment, facilitating confidence self-calibration through the penalization of over-confident output distributions. Our ",
    "path": "papers/24/03/2403.12559.json",
    "total_tokens": 856,
    "translated_title": "多标签类增量学习的信心自校准",
    "translated_abstract": "多标签类增量学习（MLCIL）中的部分标签挑战是在训练期间只有新类别被标记，而过去和未来标签仍然不可用。这个问题会导致由于错误地高置信度多标签预测而出现大量误报错误，加剧了在不同标签空间内的灾难性遗忘。在本文中，我们旨在在MLCIL中改进多标签信心校准，并提出了一种信心自校准（CSC）方法。首先，为了标签关系校准，我们引入一个类增量图卷积网络，通过构建可学习的、动态扩展的标签关系图来连接孤立的标签空间。然后，为了信心校准，我们针对每个多标签增量提出了一种最大熵正则化，通过对过于自信的输出分布进行惩罚，促进了信心的自校准。",
    "tldr": "本文提出了一种针对多标签类增量学习中的信心自校准问题的方法，通过引入图卷积网络和最大熵正则化，改善了多标签信心校准，减少了过度自信的误报错误。",
    "en_tdlr": "This paper proposes an approach to confidence self-calibration for multi-label class-incremental learning, which improves multi-label confidence calibration and reduces false-positive errors caused by over-confident predictions by introducing graph convolutional network and max-entropy regularization."
}