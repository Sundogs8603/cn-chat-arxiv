{
    "title": "DeepSeek-VL: Towards Real-World Vision-Language Understanding",
    "abstract": "arXiv:2403.05525v1 Announce Type: new  Abstract: We present DeepSeek-VL, an open-source Vision-Language (VL) Model designed for real-world vision and language understanding applications. Our approach is structured around three key dimensions:   We strive to ensure our data is diverse, scalable, and extensively covers real-world scenarios including web screenshots, PDFs, OCR, charts, and knowledge-based content, aiming for a comprehensive representation of practical contexts. Further, we create a use case taxonomy from real user scenarios and construct an instruction tuning dataset accordingly. The fine-tuning with this dataset substantially improves the model's user experience in practical applications. Considering efficiency and the demands of most real-world scenarios, DeepSeek-VL incorporates a hybrid vision encoder that efficiently processes high-resolution images (1024 x 1024), while maintaining a relatively low computational overhead. This design choice ensures the model's abilit",
    "link": "https://arxiv.org/abs/2403.05525",
    "context": "Title: DeepSeek-VL: Towards Real-World Vision-Language Understanding\nAbstract: arXiv:2403.05525v1 Announce Type: new  Abstract: We present DeepSeek-VL, an open-source Vision-Language (VL) Model designed for real-world vision and language understanding applications. Our approach is structured around three key dimensions:   We strive to ensure our data is diverse, scalable, and extensively covers real-world scenarios including web screenshots, PDFs, OCR, charts, and knowledge-based content, aiming for a comprehensive representation of practical contexts. Further, we create a use case taxonomy from real user scenarios and construct an instruction tuning dataset accordingly. The fine-tuning with this dataset substantially improves the model's user experience in practical applications. Considering efficiency and the demands of most real-world scenarios, DeepSeek-VL incorporates a hybrid vision encoder that efficiently processes high-resolution images (1024 x 1024), while maintaining a relatively low computational overhead. This design choice ensures the model's abilit",
    "path": "papers/24/03/2403.05525.json",
    "total_tokens": 822,
    "translated_title": "DeepSeek-VL:走向真实世界的视觉语言理解",
    "translated_abstract": "我们提出DeepSeek-VL，一个面向真实世界视觉和语言理解应用的开源视觉-语言（VL）模型。我们的方法围绕三个关键维度展开：确保数据多样化、可扩展性强，并广泛涵盖包括网络截图、PDF、OCR、图表和基于知识的内容在内的真实场景，以全面表征实际环境。此外，我们从真实用户场景创建了用例分类法，并相应构建了指导调整数据集。通过这个数据集的微调，大大提高了模型在实际应用中的用户体验。考虑到效率和大多数真实场景的需求，DeepSeek-VL整合了一个混合视觉编码器，能够高效处理高分辨率图像（1024 x 1024），同时保持相对较低的计算开销。这种设计选择确保了模型的能力",
    "tldr": "DeepSeek-VL是一个面向真实世界的视觉语言理解模型，通过多样化数据、真实场景覆盖和高效编码器的设计，大大提高了在实际应用中的用户体验",
    "en_tdlr": "DeepSeek-VL is a vision-language model designed for real-world applications, it significantly improves user experience in practical scenarios through diverse data, comprehensive coverage of real-world contexts, and an efficient encoder."
}