{
    "title": "PEEB: Part-based Image Classifiers with an Explainable and Editable Language Bottleneck",
    "abstract": "arXiv:2403.05297v1 Announce Type: cross  Abstract: CLIP-based classifiers rely on the prompt containing a {class name} that is known to the text encoder. That is, CLIP performs poorly on new classes or the classes whose names rarely appear on the Internet (e.g., scientific names of birds). For fine-grained classification, we propose PEEB - an explainable and editable classifier to (1) express the class name into a set of pre-defined text descriptors that describe the visual parts of that class; and (2) match the embeddings of the detected parts to their textual descriptors in each class to compute a logit score for classification. In a zero-shot setting where the class names are unknown, PEEB outperforms CLIP by a large margin (~10x in accuracy). Compared to part-based classifiers, PEEB is not only the state-of-the-art on the supervised-learning setting (88.80% accuracy) but also the first to enable users to edit the class definitions to form a new classifier without retraining. Compar",
    "link": "https://arxiv.org/abs/2403.05297",
    "context": "Title: PEEB: Part-based Image Classifiers with an Explainable and Editable Language Bottleneck\nAbstract: arXiv:2403.05297v1 Announce Type: cross  Abstract: CLIP-based classifiers rely on the prompt containing a {class name} that is known to the text encoder. That is, CLIP performs poorly on new classes or the classes whose names rarely appear on the Internet (e.g., scientific names of birds). For fine-grained classification, we propose PEEB - an explainable and editable classifier to (1) express the class name into a set of pre-defined text descriptors that describe the visual parts of that class; and (2) match the embeddings of the detected parts to their textual descriptors in each class to compute a logit score for classification. In a zero-shot setting where the class names are unknown, PEEB outperforms CLIP by a large margin (~10x in accuracy). Compared to part-based classifiers, PEEB is not only the state-of-the-art on the supervised-learning setting (88.80% accuracy) but also the first to enable users to edit the class definitions to form a new classifier without retraining. Compar",
    "path": "papers/24/03/2403.05297.json",
    "total_tokens": 975,
    "translated_title": "PEEB：具有可解释和可编辑语言瓶颈的基于部分的图像分类器",
    "translated_abstract": "基于CLIP的分类器依赖于包含{text encoder已知的类名称}的提示。也就是说，CLIP在新类别或其名称很少在互联网上出现的类别（例如鸟类的学名）上表现不佳。针对细粒度分类，我们提出了PEEB - 一种可解释和可编辑的分类器，用于（1）将类别名称表达为一组预定义的描述视觉部分的文本描述符；和（2）将检测到的部分的嵌入与每个类别中的文本描述符进行匹配，以计算用于分类的逻辑分数。在一个零样本设置中，其中类别名称是未知的，PEEB在准确性上大幅优于CLIP（约为10倍）。与基于部分的分类器相比，PEEB不仅在监督学习设置上是最先进的（88.80%准确率），而且还是第一个能够让用户编辑类定义以形成新的分类器而无需重新训练的分类器。",
    "tldr": "PEEB是一种基于部分的图像分类器，通过将类别名称转换为描述视觉部分的文本描述符，并将检测到的部分的嵌入与文本描述符匹配，从而在零样本设置中表现出色，并且不仅在监督学习中表现出色，而且还首次实现用户编辑类定义形成新分类器无需重新训练。",
    "en_tdlr": "PEEB is a part-based image classifier that converts class names into textual descriptors describing visual parts, matches embeddings of detected parts with textual descriptors to achieve superior performance in zero-shot setting, and is not only state-of-the-art in supervised learning but also the first to allow users to edit class definitions for a new classifier without retraining."
}