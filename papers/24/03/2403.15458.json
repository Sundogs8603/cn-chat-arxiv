{
    "title": "Fine-Tuning Pre-trained Language Models to Detect In-Game Trash Talks",
    "abstract": "arXiv:2403.15458v1 Announce Type: new  Abstract: Common problems in playing online mobile and computer games were related to toxic behavior and abusive communication among players. Based on different reports and studies, the study also discusses the impact of online hate speech and toxicity on players' in-game performance and overall well-being. This study investigates the capability of pre-trained language models to classify or detect trash talk or toxic in-game messages The study employs and evaluates the performance of pre-trained BERT and GPT language models in detecting toxicity within in-game chats. Using publicly available APIs, in-game chat data from DOTA 2 game matches were collected, processed, reviewed, and labeled as non-toxic, mild (toxicity), and toxic. The study was able to collect around two thousand in-game chats to train and test BERT (Base-uncased), BERT (Large-uncased), and GPT-3 models. Based on the three models' state-of-the-art performance, this study concludes p",
    "link": "https://arxiv.org/abs/2403.15458",
    "context": "Title: Fine-Tuning Pre-trained Language Models to Detect In-Game Trash Talks\nAbstract: arXiv:2403.15458v1 Announce Type: new  Abstract: Common problems in playing online mobile and computer games were related to toxic behavior and abusive communication among players. Based on different reports and studies, the study also discusses the impact of online hate speech and toxicity on players' in-game performance and overall well-being. This study investigates the capability of pre-trained language models to classify or detect trash talk or toxic in-game messages The study employs and evaluates the performance of pre-trained BERT and GPT language models in detecting toxicity within in-game chats. Using publicly available APIs, in-game chat data from DOTA 2 game matches were collected, processed, reviewed, and labeled as non-toxic, mild (toxicity), and toxic. The study was able to collect around two thousand in-game chats to train and test BERT (Base-uncased), BERT (Large-uncased), and GPT-3 models. Based on the three models' state-of-the-art performance, this study concludes p",
    "path": "papers/24/03/2403.15458.json",
    "total_tokens": 921,
    "translated_title": "调整预训练语言模型以检测游戏内垃圾话",
    "translated_abstract": "玩在线手机和电脑游戏时常见的问题与玩家之间的有毒行为和滥用沟通有关。基于不同的报告和研究，本研究还讨论了在线仇恨言论和毒性对玩家游戏表现和整体幸福感的影响。本研究调查了预训练语言模型对分类或检测游戏内垃圾话或有毒信息的能力。研究采用并评估了预训练的BERT和GPT语言模型在检测游戏内聊天中的毒性方面的表现。利用公开可用的API，收集了来自DOTA 2游戏对战的游戏内聊天数据，经过处理、审查和标记为非毒性、轻微（毒性）和有毒。该研究能够收集约两千个游戏内聊天以训练和测试BERT（Base-uncased）、BERT（Large-uncased）和GPT-3模型。基于这三种模型的最先进表现，本研究得出结论",
    "tldr": "本研究调查了预训练语言模型在检测游戏内垃圾话和毒性信息方面的能力，使用BERT和GPT模型在DOTA 2游戏对战的聊天数据上进行评估。",
    "en_tdlr": "This study investigates the capability of pre-trained language models to classify or detect trash talk or toxic in-game messages using BERT and GPT models in DOTA 2 game matches."
}