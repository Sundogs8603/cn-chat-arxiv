{
    "title": "Towards Generalizable and Interpretable Motion Prediction: A Deep Variational Bayes Approach",
    "abstract": "arXiv:2403.06086v1 Announce Type: new  Abstract: Estimating the potential behavior of the surrounding human-driven vehicles is crucial for the safety of autonomous vehicles in a mixed traffic flow. Recent state-of-the-art achieved accurate prediction using deep neural networks. However, these end-to-end models are usually black boxes with weak interpretability and generalizability. This paper proposes the Goal-based Neural Variational Agent (GNeVA), an interpretable generative model for motion prediction with robust generalizability to out-of-distribution cases. For interpretability, the model achieves target-driven motion prediction by estimating the spatial distribution of long-term destinations with a variational mixture of Gaussians. We identify a causal structure among maps and agents' histories and derive a variational posterior to enhance generalizability. Experiments on motion prediction datasets validate that the fitted model can be interpretable and generalizable and can achi",
    "link": "https://arxiv.org/abs/2403.06086",
    "context": "Title: Towards Generalizable and Interpretable Motion Prediction: A Deep Variational Bayes Approach\nAbstract: arXiv:2403.06086v1 Announce Type: new  Abstract: Estimating the potential behavior of the surrounding human-driven vehicles is crucial for the safety of autonomous vehicles in a mixed traffic flow. Recent state-of-the-art achieved accurate prediction using deep neural networks. However, these end-to-end models are usually black boxes with weak interpretability and generalizability. This paper proposes the Goal-based Neural Variational Agent (GNeVA), an interpretable generative model for motion prediction with robust generalizability to out-of-distribution cases. For interpretability, the model achieves target-driven motion prediction by estimating the spatial distribution of long-term destinations with a variational mixture of Gaussians. We identify a causal structure among maps and agents' histories and derive a variational posterior to enhance generalizability. Experiments on motion prediction datasets validate that the fitted model can be interpretable and generalizable and can achi",
    "path": "papers/24/03/2403.06086.json",
    "total_tokens": 907,
    "translated_title": "通向可泛化和可解释的运动预测：一种深度变分贝叶斯方法",
    "translated_abstract": "arXiv:2403.06086v1 公告类型:新 摘要:估计周围人驾驶车辆的潜在行为对自动驾驶车辆在混合交通流中的安全至关重要。最近的最先进技术利用深度神经网络实现了准确的预测。然而，这些端到端模型通常是黑箱，解释性和泛化能力弱。本文提出了基于目标的神经变分代理（GNeVA），一种可解释的生成模型，用于具有鲁棒泛化能力以处理分布之外情况的运动预测。为了可解释性，该模型通过估算长期目的地的空间分布来实现目标驱动的运动预测，采用高斯变分混合。我们识别地图和代理历史之间的因果结构，并推导变分后验以增强泛化能力。在运动预测数据集上的实验证明，拟合的模型既可解释又具有泛化能力，并可实现",
    "tldr": "本论文提出了一种Goal-based Neural Variational Agent (GNeVA)模型，通过变分高斯混合估算长期目的地的空间分布，实现了目标驱动的运动预测，具有强大的泛化能力和解释性。",
    "en_tdlr": "This paper introduces a Goal-based Neural Variational Agent (GNeVA) model, which achieves target-driven motion prediction by estimating the spatial distribution of long-term destinations using variational Gaussian mixture, demonstrating robust generalizability and interpretability."
}