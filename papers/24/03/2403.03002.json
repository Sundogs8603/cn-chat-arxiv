{
    "title": "Mem-elements based Neuromorphic Hardware for Neural Network Application",
    "abstract": "arXiv:2403.03002v1 Announce Type: cross  Abstract: The thesis investigates the utilization of memristive and memcapacitive crossbar arrays in low-power machine learning accelerators, offering a comprehensive co-design framework for deep neural networks (DNN). The model, implemented through a hybrid Python and PyTorch approach, accounts for various non-idealities, achieving exceptional training accuracies of 90.02% and 91.03% for the CIFAR-10 dataset with memristive and memcapacitive crossbar arrays on an 8-layer VGG network. Additionally, the thesis introduces a novel approach to emulate meminductor devices using Operational Transconductance Amplifiers (OTA) and capacitors, showcasing adjustable behavior. Transistor-level simulations in 180 nm CMOS technology, operating at 60 MHz, demonstrate the proposed meminductor emulator's viability with a power consumption of 0.337 mW. The design is further validated in neuromorphic circuits and CNN accelerators, achieving training and testing ac",
    "link": "https://arxiv.org/abs/2403.03002",
    "context": "Title: Mem-elements based Neuromorphic Hardware for Neural Network Application\nAbstract: arXiv:2403.03002v1 Announce Type: cross  Abstract: The thesis investigates the utilization of memristive and memcapacitive crossbar arrays in low-power machine learning accelerators, offering a comprehensive co-design framework for deep neural networks (DNN). The model, implemented through a hybrid Python and PyTorch approach, accounts for various non-idealities, achieving exceptional training accuracies of 90.02% and 91.03% for the CIFAR-10 dataset with memristive and memcapacitive crossbar arrays on an 8-layer VGG network. Additionally, the thesis introduces a novel approach to emulate meminductor devices using Operational Transconductance Amplifiers (OTA) and capacitors, showcasing adjustable behavior. Transistor-level simulations in 180 nm CMOS technology, operating at 60 MHz, demonstrate the proposed meminductor emulator's viability with a power consumption of 0.337 mW. The design is further validated in neuromorphic circuits and CNN accelerators, achieving training and testing ac",
    "path": "papers/24/03/2403.03002.json",
    "total_tokens": 939,
    "translated_title": "基于Mem元件的神经形态硬件在神经网络应用中的应用",
    "translated_abstract": "这篇论文研究了在低功耗机器学习加速器中利用记忆电阻和记忆电容交叉阵列，提供了一个全面的深度神经网络（DNN）协同设计框架。该模型采用混合Python和PyTorch方法实现，考虑了各种非理想因素，在8层VGG网络上，使用记忆电阻和记忆电容交叉阵列对CIFAR-10数据集实现了出色的训练准确度，分别为90.02%和91.03%。此外，论文引入了一种使用运算跨导放大器（OTA）和电容器来模拟meminductor器件的新方法，展示了可调行为。在180纳米CMOS技术的晶体管级模拟中，以60 MHz运行，验证了提出的meminductor模拟器具有0.337 mW功耗的可行性。该设计进一步在神经形态电路和CNN加速器中验证，取得了训练和测试准确性。",
    "tldr": "这项研究提出了利用记忆元件交叉阵列设计低功耗机器学习加速器的方法，并且成功实现了在CIFAR-10数据集上使用memristive和memcapacitive交叉阵列在8层VGG网络上实现出色训练准确度。",
    "en_tdlr": "This research introduces a method for designing low-power machine learning accelerators using mem-elements crossbar arrays, and successfully achieves outstanding training accuracy on the CIFAR-10 dataset with memristive and memcapacitive crossbar arrays on an 8-layer VGG network."
}