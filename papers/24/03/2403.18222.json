{
    "title": "Uncertainty-Aware Deployment of Pre-trained Language-Conditioned Imitation Learning Policies",
    "abstract": "arXiv:2403.18222v1 Announce Type: cross  Abstract: Large-scale robotic policies trained on data from diverse tasks and robotic platforms hold great promise for enabling general-purpose robots; however, reliable generalization to new environment conditions remains a major challenge. Toward addressing this challenge, we propose a novel approach for uncertainty-aware deployment of pre-trained language-conditioned imitation learning agents. Specifically, we use temperature scaling to calibrate these models and exploit the calibrated model to make uncertainty-aware decisions by aggregating the local information of candidate actions. We implement our approach in simulation using three such pre-trained models, and showcase its potential to significantly enhance task completion rates. The accompanying code is accessible at the link: https://github.com/BobWu1998/uncertainty_quant_all.git",
    "link": "https://arxiv.org/abs/2403.18222",
    "context": "Title: Uncertainty-Aware Deployment of Pre-trained Language-Conditioned Imitation Learning Policies\nAbstract: arXiv:2403.18222v1 Announce Type: cross  Abstract: Large-scale robotic policies trained on data from diverse tasks and robotic platforms hold great promise for enabling general-purpose robots; however, reliable generalization to new environment conditions remains a major challenge. Toward addressing this challenge, we propose a novel approach for uncertainty-aware deployment of pre-trained language-conditioned imitation learning agents. Specifically, we use temperature scaling to calibrate these models and exploit the calibrated model to make uncertainty-aware decisions by aggregating the local information of candidate actions. We implement our approach in simulation using three such pre-trained models, and showcase its potential to significantly enhance task completion rates. The accompanying code is accessible at the link: https://github.com/BobWu1998/uncertainty_quant_all.git",
    "path": "papers/24/03/2403.18222.json",
    "total_tokens": 816,
    "translated_title": "预训练语言条件模仿学习策略的不确定性感知部署",
    "translated_abstract": "大规模机器人策略在来自不同任务和机器人平台的数据上训练，为实现通用机器人带来很大希望；然而，可靠地泛化到新的环境条件仍然是一个主要挑战。为解决这一挑战，我们提出了一种新颖的方法，用于不确定性感知的预训练语言条件模仿学习代理的部署。具体来说，我们使用温度缩放来校准这些模型，并利用校准的模型通过聚合候选动作的本地信息来做出不确定性感知决策。我们在仿真环境中使用三个这样的预训练模型来实现我们的方法，并展示其潜力显著提升任务完成率。附带的代码可以在以下链接找到：https://github.com/BobWu1998/uncertainty_quant_all.git",
    "tldr": "提出一种不确定性感知的预训练语言条件模仿学习代理的部署方法，通过温度缩放和本地信息聚合做出不确定性感知决策，显著提升任务完成率。",
    "en_tdlr": "Introducing an uncertainty-aware deployment method for pre-trained language-conditioned imitation learning agents, utilizing temperature scaling and local information aggregation for uncertainty-aware decision-making, leading to significantly improved task completion rates."
}