{
    "title": "Probabilistic Circuits with Constraints via Convex Optimization",
    "abstract": "arXiv:2403.13125v1 Announce Type: new  Abstract: This work addresses integrating probabilistic propositional logic constraints into the distribution encoded by a probabilistic circuit (PC). PCs are a class of tractable models that allow efficient computations (such as conditional and marginal probabilities) while achieving state-of-the-art performance in some domains. The proposed approach takes both a PC and constraints as inputs, and outputs a new PC that satisfies the constraints. This is done efficiently via convex optimization without the need to retrain the entire model. Empirical evaluations indicate that the combination of constraints and PCs can have multiple use cases, including the improvement of model performance under scarce or incomplete data, as well as the enforcement of machine learning fairness measures into the model without compromising model fitness. We believe that these ideas will open possibilities for multiple other applications involving the combination of log",
    "link": "https://arxiv.org/abs/2403.13125",
    "context": "Title: Probabilistic Circuits with Constraints via Convex Optimization\nAbstract: arXiv:2403.13125v1 Announce Type: new  Abstract: This work addresses integrating probabilistic propositional logic constraints into the distribution encoded by a probabilistic circuit (PC). PCs are a class of tractable models that allow efficient computations (such as conditional and marginal probabilities) while achieving state-of-the-art performance in some domains. The proposed approach takes both a PC and constraints as inputs, and outputs a new PC that satisfies the constraints. This is done efficiently via convex optimization without the need to retrain the entire model. Empirical evaluations indicate that the combination of constraints and PCs can have multiple use cases, including the improvement of model performance under scarce or incomplete data, as well as the enforcement of machine learning fairness measures into the model without compromising model fitness. We believe that these ideas will open possibilities for multiple other applications involving the combination of log",
    "path": "papers/24/03/2403.13125.json",
    "total_tokens": 850,
    "translated_title": "通过凸优化实现带约束的概率电路",
    "translated_abstract": "这项工作解决了将概率命题逻辑约束集成到由概率电路（PC）编码的分布中的问题。PC是一类可计算的模型，允许进行高效计算（如条件概率和边缘概率），同时在某些领域实现了最先进的性能。所提出的方法将PC和约束作为输入，并输出满足约束的新PC。这通过凸优化有效地完成，无需重新训练整个模型。实证评估表明，约束和PC的组合可以具有多种用途，包括在稀疏或不完整数据下改进模型性能，以及在不影响模型适应度的情况下将机器学习公平性措施纳入模型中。我们相信这些想法将为涉及将对数结合的多个其他应用开辟可能性。",
    "tldr": "该论文提出了一种通过凸优化有效地将概率命题逻辑约束集成到概率电路中的方法，这可以在不需重新训练整个模型的情况下实现，这种组合可以改善模型在稀疏或不完整数据下的性能，并实现机器学习公平性措施。",
    "en_tdlr": "This paper presents an approach to efficiently integrate probabilistic propositional logic constraints into probabilistic circuits via convex optimization, allowing for the improvement of model performance under scarce or incomplete data without the need for retraining the entire model, while also enabling the enforcement of machine learning fairness measures."
}