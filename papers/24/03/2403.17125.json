{
    "title": "The Strong Pull of Prior Knowledge in Large Language Models and Its Impact on Emotion Recognition",
    "abstract": "arXiv:2403.17125v1 Announce Type: cross  Abstract: In-context Learning (ICL) has emerged as a powerful paradigm for performing natural language tasks with Large Language Models (LLM) without updating the models' parameters, in contrast to the traditional gradient-based finetuning. The promise of ICL is that the LLM can adapt to perform the present task at a competitive or state-of-the-art level at a fraction of the cost. The ability of LLMs to perform tasks in this few-shot manner relies on their background knowledge of the task (or task priors). However, recent work has found that, unlike traditional learning, LLMs are unable to fully integrate information from demonstrations that contrast task priors. This can lead to performance saturation at suboptimal levels, especially for subjective tasks such as emotion recognition, where the mapping from text to emotions can differ widely due to variability in human annotations. In this work, we design experiments and propose measurements to e",
    "link": "https://arxiv.org/abs/2403.17125",
    "context": "Title: The Strong Pull of Prior Knowledge in Large Language Models and Its Impact on Emotion Recognition\nAbstract: arXiv:2403.17125v1 Announce Type: cross  Abstract: In-context Learning (ICL) has emerged as a powerful paradigm for performing natural language tasks with Large Language Models (LLM) without updating the models' parameters, in contrast to the traditional gradient-based finetuning. The promise of ICL is that the LLM can adapt to perform the present task at a competitive or state-of-the-art level at a fraction of the cost. The ability of LLMs to perform tasks in this few-shot manner relies on their background knowledge of the task (or task priors). However, recent work has found that, unlike traditional learning, LLMs are unable to fully integrate information from demonstrations that contrast task priors. This can lead to performance saturation at suboptimal levels, especially for subjective tasks such as emotion recognition, where the mapping from text to emotions can differ widely due to variability in human annotations. In this work, we design experiments and propose measurements to e",
    "path": "papers/24/03/2403.17125.json",
    "total_tokens": 875,
    "translated_title": "大型语言模型中先验知识的强大作用及其对情绪识别的影响",
    "translated_abstract": "In-context Learning (ICL)作为一种强大的范式浮现出来，可以在大型语言模型（LLM）上执行自然语言任务，而无需更新模型的参数，与传统的基于梯度的微调相反。 ICL的承诺是，LLM可以适应执行当前任务，并以竞争力或最新水平的一小部分成本。 LLM以这种少样本的方式执行任务的能力依赖于它们对任务的背景知识（或任务先验知识）。然而，最近的研究发现，与传统学习不同，LLM无法完全整合与任务先验知识相矛盾的演示信息。 这可能导致表现达到次优水平，特别是对于主观任务（如情绪识别），其中文本到情绪的映射可能因人类注释的变异性而大不相同。 在这项工作中，我们设计实验并提出了测量方法",
    "tldr": "大型语言模型在执行任务时依赖背景知识（先验知识），但无法完全整合与任务先验知识相矛盾的信息，影响了情绪识别等主观任务的表现水平。",
    "en_tdlr": "Large language models rely on background knowledge (prior knowledge) to perform tasks but are unable to fully integrate information that contradicts task priors, impacting performance levels in subjective tasks such as emotion recognition."
}