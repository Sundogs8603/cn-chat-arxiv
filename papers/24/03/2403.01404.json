{
    "title": "What Is Missing in Multilingual Visual Reasoning and How to Fix It",
    "abstract": "arXiv:2403.01404v1 Announce Type: new  Abstract: NLP models today strive for supporting multiple languages and modalities, improving accessibility for diverse users. In this paper, we evaluate their multilingual, multimodal capabilities by testing on a visual reasoning task. We observe that proprietary systems like GPT-4V obtain the best performance on this task now, but open models lag in comparison. Surprisingly, GPT-4V exhibits similar performance between English and other languages, indicating the potential for equitable system development across languages. Our analysis on model failures reveals three key aspects that make this task challenging: multilinguality, complex reasoning, and multimodality. To address these challenges, we propose three targeted interventions including a translate-test approach to tackle multilinguality, a visual programming approach to break down complex reasoning, and a novel method that leverages image captioning to address multimodality. Our interventio",
    "link": "https://arxiv.org/abs/2403.01404",
    "context": "Title: What Is Missing in Multilingual Visual Reasoning and How to Fix It\nAbstract: arXiv:2403.01404v1 Announce Type: new  Abstract: NLP models today strive for supporting multiple languages and modalities, improving accessibility for diverse users. In this paper, we evaluate their multilingual, multimodal capabilities by testing on a visual reasoning task. We observe that proprietary systems like GPT-4V obtain the best performance on this task now, but open models lag in comparison. Surprisingly, GPT-4V exhibits similar performance between English and other languages, indicating the potential for equitable system development across languages. Our analysis on model failures reveals three key aspects that make this task challenging: multilinguality, complex reasoning, and multimodality. To address these challenges, we propose three targeted interventions including a translate-test approach to tackle multilinguality, a visual programming approach to break down complex reasoning, and a novel method that leverages image captioning to address multimodality. Our interventio",
    "path": "papers/24/03/2403.01404.json",
    "total_tokens": 891,
    "translated_title": "多语言视觉推理中的缺失及修复方法",
    "translated_abstract": "NLP模型今天在支持多语言和多模态方面取得了进展，提高了对各种用户的可访问性。本文通过在一个视觉推理任务上的测试来评估它们的多语言，多模态能力。我们观察到像GPT-4V这样的专有系统现在在该任务上表现最佳，但与开放模型相比存在差距。令人惊讶的是，GPT-4V在英语和其他语言之间表现出类似的性能，表明在不同语言之间开发公平的系统具有潜力。我们对模型失败进行的分析揭示了使这一任务具有挑战性的三个关键方面：多语言性，复杂推理和多模态性。为了解决这些挑战，我们提出了三种有针对性的干预措施，包括一种翻译-测试方法来解决多语言性，一种视觉编程方法来分解复杂推理，以及一种利用图像字幕生成来解决多模态性的新方法。",
    "tldr": "本文通过在视觉推理任务上的测试，发现了多语言视觉推理中存在的挑战，并提出了针对性的干预措施，包括翻译-测试方法，视觉编程方法和图像字幕生成方法。",
    "en_tdlr": "This paper evaluates multilingual and multimodal capabilities of NLP models on a visual reasoning task, identifying challenges in multilingual visual reasoning and proposing targeted interventions including translate-test approach, visual programming, and image captioning method."
}