{
    "title": "Self-Supervised Learning for Time Series: Contrastive or Generative?",
    "abstract": "arXiv:2403.09809v1 Announce Type: cross  Abstract: Self-supervised learning (SSL) has recently emerged as a powerful approach to learning representations from large-scale unlabeled data, showing promising results in time series analysis. The self-supervised representation learning can be categorized into two mainstream: contrastive and generative. In this paper, we will present a comprehensive comparative study between contrastive and generative methods in time series. We first introduce the basic frameworks for contrastive and generative SSL, respectively, and discuss how to obtain the supervision signal that guides the model optimization. We then implement classical algorithms (SimCLR vs. MAE) for each type and conduct a comparative analysis in fair settings. Our results provide insights into the strengths and weaknesses of each approach and offer practical recommendations for choosing suitable SSL methods. We also discuss the implications of our findings for the broader field of rep",
    "link": "https://arxiv.org/abs/2403.09809",
    "context": "Title: Self-Supervised Learning for Time Series: Contrastive or Generative?\nAbstract: arXiv:2403.09809v1 Announce Type: cross  Abstract: Self-supervised learning (SSL) has recently emerged as a powerful approach to learning representations from large-scale unlabeled data, showing promising results in time series analysis. The self-supervised representation learning can be categorized into two mainstream: contrastive and generative. In this paper, we will present a comprehensive comparative study between contrastive and generative methods in time series. We first introduce the basic frameworks for contrastive and generative SSL, respectively, and discuss how to obtain the supervision signal that guides the model optimization. We then implement classical algorithms (SimCLR vs. MAE) for each type and conduct a comparative analysis in fair settings. Our results provide insights into the strengths and weaknesses of each approach and offer practical recommendations for choosing suitable SSL methods. We also discuss the implications of our findings for the broader field of rep",
    "path": "papers/24/03/2403.09809.json",
    "total_tokens": 827,
    "translated_title": "自监督学习用于时间序列：对比或生成？",
    "translated_abstract": "自监督学习（SSL）最近已经被证明是一种从大规模未标记数据中学习表示的强大方法，在时间序列分析中表现出有希望的结果。自监督表示学习可以分为两个主流：对比和生成。在本文中，我们将对时间序列中的对比和生成方法进行全面的比较研究。首先，我们分别介绍了对比和生成SSL的基本框架，并讨论了如何获得指导模型优化的监督信号。然后，我们分别为每种类型实现了经典算法（SimCLR vs. MAE），并在公平设置下进行了比较分析。我们的结果提供了对每种方法的优势和劣势的深入洞察，并为选择合适的SSL方法提供了实用建议。我们还讨论了我们的发现对更广泛的表示学习领域的影响。",
    "tldr": "本文对时间序列中的对比和生成自监督学习方法进行了全面比较研究，提供了各种方法的优势和劣势洞察，并为选择合适的SSL方法提供了实用建议。",
    "en_tdlr": "This paper presents a comprehensive comparative study between contrastive and generative self-supervised learning methods in time series, providing insights into the strengths and weaknesses of each approach and offering practical recommendations for choosing suitable SSL methods."
}