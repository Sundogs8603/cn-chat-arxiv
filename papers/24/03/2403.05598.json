{
    "title": "Privacy Amplification for the Gaussian Mechanism via Bounded Support",
    "abstract": "arXiv:2403.05598v1 Announce Type: cross  Abstract: Data-dependent privacy accounting frameworks such as per-instance differential privacy (pDP) and Fisher information loss (FIL) confer fine-grained privacy guarantees for individuals in a fixed training dataset. These guarantees can be desirable compared to vanilla DP in real world settings as they tightly upper-bound the privacy leakage for a $\\textit{specific}$ individual in an $\\textit{actual}$ dataset, rather than considering worst-case datasets. While these frameworks are beginning to gain popularity, to date, there is a lack of private mechanisms that can fully leverage advantages of data-dependent accounting. To bridge this gap, we propose simple modifications of the Gaussian mechanism with bounded support, showing that they amplify privacy guarantees under data-dependent accounting. Experiments on model training with DP-SGD show that using bounded support Gaussian mechanisms can provide a reduction of the pDP bound $\\epsilon$ by",
    "link": "https://arxiv.org/abs/2403.05598",
    "context": "Title: Privacy Amplification for the Gaussian Mechanism via Bounded Support\nAbstract: arXiv:2403.05598v1 Announce Type: cross  Abstract: Data-dependent privacy accounting frameworks such as per-instance differential privacy (pDP) and Fisher information loss (FIL) confer fine-grained privacy guarantees for individuals in a fixed training dataset. These guarantees can be desirable compared to vanilla DP in real world settings as they tightly upper-bound the privacy leakage for a $\\textit{specific}$ individual in an $\\textit{actual}$ dataset, rather than considering worst-case datasets. While these frameworks are beginning to gain popularity, to date, there is a lack of private mechanisms that can fully leverage advantages of data-dependent accounting. To bridge this gap, we propose simple modifications of the Gaussian mechanism with bounded support, showing that they amplify privacy guarantees under data-dependent accounting. Experiments on model training with DP-SGD show that using bounded support Gaussian mechanisms can provide a reduction of the pDP bound $\\epsilon$ by",
    "path": "papers/24/03/2403.05598.json",
    "total_tokens": 837,
    "translated_title": "通过有界支持的高斯机制实现隐私增强",
    "translated_abstract": "arXiv：2403.05598v1 公布类型：跨领域 摘要：数据相关的隐私核算框架，如每实例差分隐私（pDP）和费舍尔信息损失（FIL），为固定训练数据集中的个体提供细粒度的隐私保证。与传统的差分隐私相比，这些保证在现实世界的环境中可能更为理想，因为它们严格地上界约束了$\\textit{实际}$数据集中$\\textit{特定}$个体的隐私泄露，而不是考虑最坏情况的数据集。尽管这些框架开始受到欢迎，但迄今为止，缺乏可以充分利用数据相关核算优势的私人机制。为了填补这一空白，我们提出了对有界支持的高斯机制进行简单修改，证明它们在数据相关核算下增强了隐私保证。通过对DP-SGD模型训练的实验表明，使用有界支持高斯机制可以降低pDP界限$\\epsilon$。",
    "tldr": "通过有界支持的高斯机制的简单修改，可以在数据相关核算下增强隐私保证",
    "en_tdlr": "The paper proposes simple modifications of the Gaussian mechanism with bounded support to amplify privacy guarantees under data-dependent accounting."
}