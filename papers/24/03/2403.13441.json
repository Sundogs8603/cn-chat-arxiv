{
    "title": "Robustness Verifcation in Neural Networks",
    "abstract": "arXiv:2403.13441v1 Announce Type: cross  Abstract: In this paper we investigate formal verification problems for Neural Network computations. Of central importance will be various robustness and minimization problems such as: Given symbolic specifications of allowed inputs and outputs in form of Linear Programming instances, one question is whether there do exist valid inputs such that the network computes a valid output? And does this property hold for all valid inputs? Do two given networks compute the same function? Is there a smaller network computing the same function?   The complexity of these questions have been investigated recently from a practical point of view and approximated by heuristic algorithms. We complement these achievements by giving a theoretical framework that enables us to interchange security and efficiency questions in neural networks and analyze their computational complexities. We show that the problems are conquerable in a semi-linear setting, meaning that ",
    "link": "https://arxiv.org/abs/2403.13441",
    "context": "Title: Robustness Verifcation in Neural Networks\nAbstract: arXiv:2403.13441v1 Announce Type: cross  Abstract: In this paper we investigate formal verification problems for Neural Network computations. Of central importance will be various robustness and minimization problems such as: Given symbolic specifications of allowed inputs and outputs in form of Linear Programming instances, one question is whether there do exist valid inputs such that the network computes a valid output? And does this property hold for all valid inputs? Do two given networks compute the same function? Is there a smaller network computing the same function?   The complexity of these questions have been investigated recently from a practical point of view and approximated by heuristic algorithms. We complement these achievements by giving a theoretical framework that enables us to interchange security and efficiency questions in neural networks and analyze their computational complexities. We show that the problems are conquerable in a semi-linear setting, meaning that ",
    "path": "papers/24/03/2403.13441.json",
    "total_tokens": 773,
    "translated_title": "神经网络中的鲁棒性验证",
    "translated_abstract": "在本文中，我们研究了神经网络计算的形式化验证问题。其中的重要问题包括鲁棒性和最小化问题，例如在线性规划实例的符号输入和输出规范性的基础上，是否存在有效的输入使得网络计算出有效的输出？这个性质是否对所有有效的输入都成立？两个给定的网络是否计算出相同的函数？是否存在一个更小的网络来计算相同的函数？这些问题的复杂性最近从实用角度进行了研究，并通过启发式算法进行了近似。我们通过提供一个理论框架来补充这些成果，该框架使我们能够在神经网络中交换安全性和效率性问题，并分析它们的计算复杂性。我们证明了这些问题在半线性设置下是可以克服的，也就是说...",
    "tldr": "本文研究了神经网络中的鲁棒性验证问题，提出了一个理论框架来解决安全性和效率性问题，并分析了它们的计算复杂性。",
    "en_tdlr": "This paper investigates robustness verification problems in neural networks, proposes a theoretical framework to address security and efficiency concerns, and analyzes their computational complexities."
}