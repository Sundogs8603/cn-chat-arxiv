{
    "title": "Visually Guided Generative Text-Layout Pre-training for Document Intelligence",
    "abstract": "arXiv:2403.16516v1 Announce Type: new  Abstract: Prior study shows that pre-training techniques can boost the performance of visual document understanding (VDU), which typically requires models to gain abilities to perceive and reason both document texts and layouts (e.g., locations of texts and table-cells). To this end, we propose visually guided generative text-layout pre-training, named ViTLP. Given a document image, the model optimizes hierarchical language and layout modeling objectives to generate the interleaved text and layout sequence. In addition, to address the limitation of processing long documents by Transformers, we introduce a straightforward yet effective multi-segment generative pre-training scheme, facilitating ViTLP to process word-intensive documents of any length. ViTLP can function as a native OCR model to localize and recognize texts of document images. Besides, ViTLP can be effectively applied to various downstream VDU tasks. Extensive experiments show that Vi",
    "link": "https://arxiv.org/abs/2403.16516",
    "context": "Title: Visually Guided Generative Text-Layout Pre-training for Document Intelligence\nAbstract: arXiv:2403.16516v1 Announce Type: new  Abstract: Prior study shows that pre-training techniques can boost the performance of visual document understanding (VDU), which typically requires models to gain abilities to perceive and reason both document texts and layouts (e.g., locations of texts and table-cells). To this end, we propose visually guided generative text-layout pre-training, named ViTLP. Given a document image, the model optimizes hierarchical language and layout modeling objectives to generate the interleaved text and layout sequence. In addition, to address the limitation of processing long documents by Transformers, we introduce a straightforward yet effective multi-segment generative pre-training scheme, facilitating ViTLP to process word-intensive documents of any length. ViTLP can function as a native OCR model to localize and recognize texts of document images. Besides, ViTLP can be effectively applied to various downstream VDU tasks. Extensive experiments show that Vi",
    "path": "papers/24/03/2403.16516.json",
    "total_tokens": 849,
    "translated_title": "可视引导的生成式文本布局预训练用于文档智能",
    "translated_abstract": "先前的研究表明，预训练技术可以提升视觉文档理解（VDU）的性能，通常需要模型获得感知和推理文档文本和布局（例如文本和表格单元的位置）的能力。为此，我们提出了一种名为ViTLP的可视引导的生成文本布局预训练技术。给定一个文档图像，该模型优化分层语言和布局建模目标，以生成交错的文本和布局序列。此外，为了解决Transformers处理长文档的局限性，我们引入了一种简单而有效的多段生成式预训练方案，使ViTLP能够处理任意长度的词汇密集型文档。ViTLP可以作为本地OCR模型，用于定位和识别文档图像中的文本。此外，ViTLP可以有效应用于各种下游VDU任务。大量实验证明ViTLP可以...",
    "tldr": "提出了一种名为ViTLP的可视引导的生成文本布局预训练技术，能够处理任意长度的词汇密集型文档，并且可以作为OCR模型用于文本定位和识别。",
    "en_tdlr": "Propose a visually guided generative text-layout pre-training technique named ViTLP, capable of processing word-intensive documents of any length and serving as an OCR model for text localization and recognition."
}