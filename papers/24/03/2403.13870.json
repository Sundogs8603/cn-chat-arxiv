{
    "title": "ExMap: Leveraging Explainability Heatmaps for Unsupervised Group Robustness to Spurious Correlations",
    "abstract": "arXiv:2403.13870v1 Announce Type: cross  Abstract: Group robustness strategies aim to mitigate learned biases in deep learning models that arise from spurious correlations present in their training datasets. However, most existing methods rely on the access to the label distribution of the groups, which is time-consuming and expensive to obtain. As a result, unsupervised group robustness strategies are sought. Based on the insight that a trained model's classification strategies can be inferred accurately based on explainability heatmaps, we introduce ExMap, an unsupervised two stage mechanism designed to enhance group robustness in traditional classifiers. ExMap utilizes a clustering module to infer pseudo-labels based on a model's explainability heatmaps, which are then used during training in lieu of actual labels. Our empirical studies validate the efficacy of ExMap - We demonstrate that it bridges the performance gap with its supervised counterparts and outperforms existing partia",
    "link": "https://arxiv.org/abs/2403.13870",
    "context": "Title: ExMap: Leveraging Explainability Heatmaps for Unsupervised Group Robustness to Spurious Correlations\nAbstract: arXiv:2403.13870v1 Announce Type: cross  Abstract: Group robustness strategies aim to mitigate learned biases in deep learning models that arise from spurious correlations present in their training datasets. However, most existing methods rely on the access to the label distribution of the groups, which is time-consuming and expensive to obtain. As a result, unsupervised group robustness strategies are sought. Based on the insight that a trained model's classification strategies can be inferred accurately based on explainability heatmaps, we introduce ExMap, an unsupervised two stage mechanism designed to enhance group robustness in traditional classifiers. ExMap utilizes a clustering module to infer pseudo-labels based on a model's explainability heatmaps, which are then used during training in lieu of actual labels. Our empirical studies validate the efficacy of ExMap - We demonstrate that it bridges the performance gap with its supervised counterparts and outperforms existing partia",
    "path": "papers/24/03/2403.13870.json",
    "total_tokens": 930,
    "translated_title": "ExMap：利用可解释性热图实现对虚假相关性的无监督群体鲁棒性",
    "translated_abstract": "arXiv:2403.13870v1 公告类型：交叉 组鲁棒性策略旨在减轻深度学习模型中由训练数据集中存在的虚假相关性产生的学习偏差。然而，大多数现有方法依赖于对群体标签分布的访问，这是耗时且昂贵的。因此，人们寻求无监督的群体鲁棒性策略。基于这样一种看法：可以根据可解释性热图准确推断训练模型的分类策略，我们引入了ExMap，这是一种设计用于增强传统分类器中群体鲁棒性的无监督两阶段机制。ExMap利用聚类模块根据模型的可解释性热图推断伪标签，然后在训练过程中使用这些伪标签代替实际标签。我们的实证研究验证了ExMap的有效性-我们展示它能够弥合与监督对应方法之间的性能差距，并优于现有的部分",
    "tldr": "ExMap 是一种无监督群体鲁棒性策略，利用可解释性热图推断模型的分类策略，通过聚类模块推断伪标签来增强传统分类器的鲁棒性。"
}