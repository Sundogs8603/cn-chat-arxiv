{
    "title": "Improving Diffusion Models's Data-Corruption Resistance using Scheduled Pseudo-Huber Loss",
    "abstract": "arXiv:2403.16728v1 Announce Type: new  Abstract: Diffusion models are known to be vulnerable to outliers in training data. In this paper we study an alternative diffusion loss function, which can preserve the high quality of generated data like the original squared $L_{2}$ loss while at the same time being robust to outliers. We propose to use pseudo-Huber loss function with a time-dependent parameter to allow for the trade-off between robustness on the most vulnerable early reverse-diffusion steps and fine details restoration on the final steps. We show that pseudo-Huber loss with the time-dependent parameter exhibits better performance on corrupted datasets in both image and audio domains. In addition, the loss function we propose can potentially help diffusion models to resist dataset corruption while not requiring data filtering or purification compared to conventional training algorithms.",
    "link": "https://arxiv.org/abs/2403.16728",
    "context": "Title: Improving Diffusion Models's Data-Corruption Resistance using Scheduled Pseudo-Huber Loss\nAbstract: arXiv:2403.16728v1 Announce Type: new  Abstract: Diffusion models are known to be vulnerable to outliers in training data. In this paper we study an alternative diffusion loss function, which can preserve the high quality of generated data like the original squared $L_{2}$ loss while at the same time being robust to outliers. We propose to use pseudo-Huber loss function with a time-dependent parameter to allow for the trade-off between robustness on the most vulnerable early reverse-diffusion steps and fine details restoration on the final steps. We show that pseudo-Huber loss with the time-dependent parameter exhibits better performance on corrupted datasets in both image and audio domains. In addition, the loss function we propose can potentially help diffusion models to resist dataset corruption while not requiring data filtering or purification compared to conventional training algorithms.",
    "path": "papers/24/03/2403.16728.json",
    "total_tokens": 806,
    "translated_title": "使用定时伪Huber损失改进扩散模型的数据破坏抵抗力",
    "translated_abstract": "扩散模型因训练数据中的异常值而脆弱。本文研究了一种替代扩散损失函数，该函数可以在保留高质量生成数据的同时，具有鲁棒性以抵抗异常值。我们建议使用带有时间相关参数的伪Huber损失函数，以在最脆弱的早期逆扩散步骤中实现鲁棒性和最终步骤中细节恢复之间的权衡。我们展示了具有时间相关参数的伪Huber损失在图像和音频领域的损坏数据集上表现更好。此外，我们提出的损失函数可以帮助扩散模型抵抗数据集破坏，而与传统训练算法相比，不需要数据过滤或净化。",
    "tldr": "使用定时伪Huber损失函数改进扩散模型的数据破坏抵抗力，可在保留高质量生成数据的同时提供鲁棒性，并在损坏数据集上展现更好性能。"
}