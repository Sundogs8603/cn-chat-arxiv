{
    "title": "Towards Independence Criterion in Machine Unlearning of Features and Labels",
    "abstract": "arXiv:2403.08124v1 Announce Type: cross  Abstract: This work delves into the complexities of machine unlearning in the face of distributional shifts, particularly focusing on the challenges posed by non-uniform feature and label removal. With the advent of regulations like the GDPR emphasizing data privacy and the right to be forgotten, machine learning models face the daunting task of unlearning sensitive information without compromising their integrity or performance. Our research introduces a novel approach that leverages influence functions and principles of distributional independence to address these challenges. By proposing a comprehensive framework for machine unlearning, we aim to ensure privacy protection while maintaining model performance and adaptability across varying distributions. Our method not only facilitates efficient data removal but also dynamically adjusts the model to preserve its generalization capabilities. Through extensive experimentation, we demonstrate the",
    "link": "https://arxiv.org/abs/2403.08124",
    "context": "Title: Towards Independence Criterion in Machine Unlearning of Features and Labels\nAbstract: arXiv:2403.08124v1 Announce Type: cross  Abstract: This work delves into the complexities of machine unlearning in the face of distributional shifts, particularly focusing on the challenges posed by non-uniform feature and label removal. With the advent of regulations like the GDPR emphasizing data privacy and the right to be forgotten, machine learning models face the daunting task of unlearning sensitive information without compromising their integrity or performance. Our research introduces a novel approach that leverages influence functions and principles of distributional independence to address these challenges. By proposing a comprehensive framework for machine unlearning, we aim to ensure privacy protection while maintaining model performance and adaptability across varying distributions. Our method not only facilitates efficient data removal but also dynamically adjusts the model to preserve its generalization capabilities. Through extensive experimentation, we demonstrate the",
    "path": "papers/24/03/2403.08124.json",
    "total_tokens": 813,
    "translated_title": "在机器特征和标签的遗忘中朝向独立准则",
    "translated_abstract": "这项工作深入探讨了面临分布转移时的机器遗忘复杂性，特别关注非均匀特征和标签删除所带来的挑战。随着GDPR等法规强调数据隐私和被遗忘的权利，机器学习模型面临着遗忘敏感信息而不损害其完整性或性能的艰巨任务。我们的研究引入了一种利用影响函数和分布独立原则来应对这些挑战的新方法。通过提出一个全面的机器遗忘框架，我们旨在确保隐私保护，同时在不同分布下保持模型性能和适应性。我们的方法不仅有助于高效地删除数据，还动态调整模型以保持其泛化能力。通过大量实验，我们证明了",
    "tldr": "提出了一种利用影响函数和分布独立原则的新方法，以应对机器遗忘中非均匀特征和标签删除的挑战，保护隐私同时保持模型性能和适应性",
    "en_tdlr": "Introduced a novel approach leveraging influence functions and principles of distributional independence to address the challenges of non-uniform feature and label removal in machine unlearning, aiming to ensure privacy protection while maintaining model performance and adaptability across varying distributions."
}