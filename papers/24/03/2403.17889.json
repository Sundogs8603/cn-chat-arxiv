{
    "title": "Large scale paired antibody language models",
    "abstract": "arXiv:2403.17889v1 Announce Type: cross  Abstract: Antibodies are proteins produced by the immune system that can identify and neutralise a wide variety of antigens with high specificity and affinity, and constitute the most successful class of biotherapeutics. With the advent of next-generation sequencing, billions of antibody sequences have been collected in recent years, though their application in the design of better therapeutics has been constrained by the sheer volume and complexity of the data. To address this challenge, we present IgBert and IgT5, the best performing antibody-specific language models developed to date which can consistently handle both paired and unpaired variable region sequences as input. These models are trained comprehensively using the more than two billion unpaired sequences and two million paired sequences of light and heavy chains present in the Observed Antibody Space dataset. We show that our models outperform existing antibody and protein language m",
    "link": "https://arxiv.org/abs/2403.17889",
    "context": "Title: Large scale paired antibody language models\nAbstract: arXiv:2403.17889v1 Announce Type: cross  Abstract: Antibodies are proteins produced by the immune system that can identify and neutralise a wide variety of antigens with high specificity and affinity, and constitute the most successful class of biotherapeutics. With the advent of next-generation sequencing, billions of antibody sequences have been collected in recent years, though their application in the design of better therapeutics has been constrained by the sheer volume and complexity of the data. To address this challenge, we present IgBert and IgT5, the best performing antibody-specific language models developed to date which can consistently handle both paired and unpaired variable region sequences as input. These models are trained comprehensively using the more than two billion unpaired sequences and two million paired sequences of light and heavy chains present in the Observed Antibody Space dataset. We show that our models outperform existing antibody and protein language m",
    "path": "papers/24/03/2403.17889.json",
    "total_tokens": 861,
    "translated_title": "大规模配对抗体语言模型",
    "translated_abstract": "抗体是免疫系统产生的蛋白质，可以识别和中和各种抗原，具有高特异性和亲和力，并构成最成功的生物治疗类别。 随着下一代测序技术的出现，近年来已收集了数十亿个抗体序列，尽管这些序列在设计更好的治疗方案中的应用受到数据量和复杂性的限制。 为了解决这一挑战，我们提出了迄今开发的表现最佳的抗体特定语言模型IgBert和IgT5，这两个模型可以持续处理作为输入的配对和无配对可变区序列。 这些模型全面地使用了“观测到的抗体空间”数据集中的超过20亿个无配对序列和两百万个轻链和重链的配对序列进行培训。 我们展示了我们的模型胜过现有的抗体和蛋白质语言模型。",
    "tldr": "IgBert和IgT5是迄今为止发展的最佳表现的抗体特定语言模型，可以处理配对和无配对可变区序列，并在训练中使用了超过20亿个无配对序列和两百万个配对序列。",
    "en_tdlr": "IgBert and IgT5 are the best performing antibody-specific language models developed to date, capable of handling both paired and unpaired variable region sequences, trained comprehensively using more than two billion unpaired sequences and two million paired sequences."
}