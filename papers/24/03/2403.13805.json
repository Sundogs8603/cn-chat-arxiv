{
    "title": "RAR: Retrieving And Ranking Augmented MLLMs for Visual Recognition",
    "abstract": "arXiv:2403.13805v1 Announce Type: cross  Abstract: CLIP (Contrastive Language-Image Pre-training) uses contrastive learning from noise image-text pairs to excel at recognizing a wide array of candidates, yet its focus on broad associations hinders the precision in distinguishing subtle differences among fine-grained items. Conversely, Multimodal Large Language Models (MLLMs) excel at classifying fine-grained categories, thanks to their substantial knowledge from pre-training on web-level corpora. However, the performance of MLLMs declines with an increase in category numbers, primarily due to growing complexity and constraints of limited context window size. To synergize the strengths of both approaches and enhance the few-shot/zero-shot recognition abilities for datasets characterized by extensive and fine-grained vocabularies, this paper introduces RAR, a Retrieving And Ranking augmented method for MLLMs. We initially establish a multi-modal retriever based on CLIP to create and stor",
    "link": "https://arxiv.org/abs/2403.13805",
    "context": "Title: RAR: Retrieving And Ranking Augmented MLLMs for Visual Recognition\nAbstract: arXiv:2403.13805v1 Announce Type: cross  Abstract: CLIP (Contrastive Language-Image Pre-training) uses contrastive learning from noise image-text pairs to excel at recognizing a wide array of candidates, yet its focus on broad associations hinders the precision in distinguishing subtle differences among fine-grained items. Conversely, Multimodal Large Language Models (MLLMs) excel at classifying fine-grained categories, thanks to their substantial knowledge from pre-training on web-level corpora. However, the performance of MLLMs declines with an increase in category numbers, primarily due to growing complexity and constraints of limited context window size. To synergize the strengths of both approaches and enhance the few-shot/zero-shot recognition abilities for datasets characterized by extensive and fine-grained vocabularies, this paper introduces RAR, a Retrieving And Ranking augmented method for MLLMs. We initially establish a multi-modal retriever based on CLIP to create and stor",
    "path": "papers/24/03/2403.13805.json",
    "total_tokens": 924,
    "translated_title": "RAR：用于视觉识别的检索和排名增强MLLMs",
    "translated_abstract": "arXiv:2403.13805v1 通告类型：交叉摘要：CLIP（对比语言-图像预训练）利用从噪声图像文本对中的对比学习，在识别各种候选项方面表现出色，但其对广泛关联的关注降低了在区分细粒度项目中微妙差异的精度。相反，多模态大型语言模型（MLLMs）在分类细粒度类别方面表现出色，这归功于它们在基于网络的语料库上的预训练所具有的大量知识。然而，由于类别数量的增加，MLLMs的性能下降，主要是由于不断增加的复杂性和有限上下文窗口大小的限制。为了协同两种方法的优势，并增强针对具有广泛和细粒度词汇特征的数据集的少样本/零样本识别能力，本文介绍了RAR，一种用于MLLMs的检索和排名增强方法。我们最初建立了一个基于CLIP的多模态检索器，用于创建和存储",
    "tldr": "该论文介绍了RAR方法，通过结合CLIP和MLLMs的优势，增强了少样本/零样本识别能力，特别适用于具有广泛和细粒度词汇特征的数据集。",
    "en_tdlr": "This paper introduces RAR, a method that synergizes the strengths of CLIP and MLLMs to enhance few-shot/zero-shot recognition abilities, especially for datasets characterized by extensive and fine-grained vocabularies."
}