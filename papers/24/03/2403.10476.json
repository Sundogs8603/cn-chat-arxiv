{
    "title": "Approximate Nullspace Augmented Finetuning for Robust Vision Transformers",
    "abstract": "arXiv:2403.10476v1 Announce Type: cross  Abstract: Enhancing the robustness of deep learning models, particularly in the realm of vision transformers (ViTs), is crucial for their real-world deployment. In this work, we provide a finetuning approach to enhance the robustness of vision transformers inspired by the concept of nullspace from linear algebra. Our investigation centers on whether a vision transformer can exhibit resilience to input variations akin to the nullspace property in linear mappings, implying that perturbations sampled from this nullspace do not influence the model's output when added to the input. Firstly, we show that for many pretrained ViTs, a non-trivial nullspace exists due to the presence of the patch embedding layer. Secondly, as nullspace is a concept associated with linear algebra, we demonstrate that it is possible to synthesize approximate nullspace elements for the non-linear blocks of ViTs employing an optimisation strategy. Finally, we propose a fine-t",
    "link": "https://arxiv.org/abs/2403.10476",
    "context": "Title: Approximate Nullspace Augmented Finetuning for Robust Vision Transformers\nAbstract: arXiv:2403.10476v1 Announce Type: cross  Abstract: Enhancing the robustness of deep learning models, particularly in the realm of vision transformers (ViTs), is crucial for their real-world deployment. In this work, we provide a finetuning approach to enhance the robustness of vision transformers inspired by the concept of nullspace from linear algebra. Our investigation centers on whether a vision transformer can exhibit resilience to input variations akin to the nullspace property in linear mappings, implying that perturbations sampled from this nullspace do not influence the model's output when added to the input. Firstly, we show that for many pretrained ViTs, a non-trivial nullspace exists due to the presence of the patch embedding layer. Secondly, as nullspace is a concept associated with linear algebra, we demonstrate that it is possible to synthesize approximate nullspace elements for the non-linear blocks of ViTs employing an optimisation strategy. Finally, we propose a fine-t",
    "path": "papers/24/03/2403.10476.json",
    "total_tokens": 906,
    "translated_title": "增强鲁棒性的近似零空间增强微调方法用于视觉变换器",
    "translated_abstract": "增强深度学习模型的鲁棒性，特别是在视觉变换器（ViTs）领域中，对于它们在现实世界中的部署至关重要。在这项工作中，我们提供了一种启发自线性代数中零空间概念的视觉变换器鲁棒性增强微调方法。我们的研究集中在一个问题上，即视觉变换器是否可以展现出类似于线性映射中的零空间属性的输入变化韧性，这意味着从该零空间中采样的扰动添加到输入时不会影响模型的输出。首先，我们展示了对于许多预训练的ViTs，存在一个非平凡的零空间，这是由于存在修补嵌入层。其次，由于零空间是与线性代数相关的概念，我们表明可以利用优化策略为ViTs的非线性块合成近似零空间元素。最后，我们提出了一种细致的方法",
    "tldr": "本研究提出了一种启发自线性代数零空间概念的视觉变换器鲁棒性增强微调方法，通过合成近似零空间元素来提高模型的鲁棒性。"
}