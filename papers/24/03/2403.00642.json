{
    "title": "Rethinking The Uniformity Metric in Self-Supervised Learning",
    "abstract": "arXiv:2403.00642v1 Announce Type: cross  Abstract: Uniformity plays a crucial role in the assessment of learned representations, contributing to a deeper comprehension of self-supervised learning. The seminal work by \\citet{Wang2020UnderstandingCR} introduced a uniformity metric that quantitatively measures the collapse degree of learned representations. Directly optimizing this metric together with alignment proves to be effective in preventing constant collapse. However, we present both theoretical and empirical evidence revealing that this metric lacks sensitivity to dimensional collapse, highlighting its limitations. To address this limitation and design a more effective uniformity metric, this paper identifies five fundamental properties, some of which the existing uniformity metric fails to meet. We subsequently introduce a novel uniformity metric that satisfies all of these desiderata and exhibits sensitivity to dimensional collapse. When applied as an auxiliary loss in various ",
    "link": "https://arxiv.org/abs/2403.00642",
    "context": "Title: Rethinking The Uniformity Metric in Self-Supervised Learning\nAbstract: arXiv:2403.00642v1 Announce Type: cross  Abstract: Uniformity plays a crucial role in the assessment of learned representations, contributing to a deeper comprehension of self-supervised learning. The seminal work by \\citet{Wang2020UnderstandingCR} introduced a uniformity metric that quantitatively measures the collapse degree of learned representations. Directly optimizing this metric together with alignment proves to be effective in preventing constant collapse. However, we present both theoretical and empirical evidence revealing that this metric lacks sensitivity to dimensional collapse, highlighting its limitations. To address this limitation and design a more effective uniformity metric, this paper identifies five fundamental properties, some of which the existing uniformity metric fails to meet. We subsequently introduce a novel uniformity metric that satisfies all of these desiderata and exhibits sensitivity to dimensional collapse. When applied as an auxiliary loss in various ",
    "path": "papers/24/03/2403.00642.json",
    "total_tokens": 812,
    "translated_title": "重新审视自监督学习中的均匀性度量",
    "translated_abstract": "均匀性在评估学习表示方面起着至关重要的作用，有助于更深入理解自监督学习。之前的一项开创性工作引入了一个均匀性度量，定量衡量学习表示的崩溃程度。直接优化这一度量与对齐一起，被证明能够有效地防止不断崩溃。然而，我们提出理论和实证证据表明这一度量缺乏对维度崩溃的敏感性，凸显了其局限性。为了解决这一局限性并设计一个更有效的均匀性度量，本文确定了五个基本性质，其中现有的均匀性度量未能满足其中的一些。我们随后引入了一个新的均匀性度量，满足所有这些期望，并且对维度崩溃具有敏感性。",
    "tldr": "通过识别并满足现有均匀性度量未能达标的五个基本性质，本文引入了一个对维度崩溃敏感的新均匀性度量。",
    "en_tdlr": "By identifying and satisfying five fundamental properties that the existing uniformity metric fails to meet, this paper introduces a new uniformity metric that is sensitive to dimensional collapse."
}