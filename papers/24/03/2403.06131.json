{
    "title": "FedPIT: Towards Privacy-preserving and Few-shot Federated Instruction Tuning",
    "abstract": "arXiv:2403.06131v1 Announce Type: cross  Abstract: Instruction tuning has proven essential for enhancing the performance of large language models (LLMs) in generating human-aligned responses. However, collecting diverse, high-quality instruction data for tuning poses challenges, particularly in privacy-sensitive domains. Federated instruction tuning (FedIT) has emerged as a solution, leveraging federated learning from multiple data owners while preserving privacy. Yet, it faces challenges due to limited instruction data and vulnerabilities to training data extraction attacks. To address these issues, we propose a novel federated algorithm, FedPIT, which utilizes LLMs' in-context learning capability to self-generate task-specific synthetic data for training autonomously. Our method employs parameter-isolated training to maintain global parameters trained on synthetic data and local parameters trained on augmented local data, effectively thwarting data extraction attacks. Extensive exper",
    "link": "https://arxiv.org/abs/2403.06131",
    "context": "Title: FedPIT: Towards Privacy-preserving and Few-shot Federated Instruction Tuning\nAbstract: arXiv:2403.06131v1 Announce Type: cross  Abstract: Instruction tuning has proven essential for enhancing the performance of large language models (LLMs) in generating human-aligned responses. However, collecting diverse, high-quality instruction data for tuning poses challenges, particularly in privacy-sensitive domains. Federated instruction tuning (FedIT) has emerged as a solution, leveraging federated learning from multiple data owners while preserving privacy. Yet, it faces challenges due to limited instruction data and vulnerabilities to training data extraction attacks. To address these issues, we propose a novel federated algorithm, FedPIT, which utilizes LLMs' in-context learning capability to self-generate task-specific synthetic data for training autonomously. Our method employs parameter-isolated training to maintain global parameters trained on synthetic data and local parameters trained on augmented local data, effectively thwarting data extraction attacks. Extensive exper",
    "path": "papers/24/03/2403.06131.json",
    "total_tokens": 874,
    "translated_title": "FedPIT：面向隐私保护和少样本联邦指令调整",
    "translated_abstract": "指令调整对于增强大型语言模型（LLMs）在生成与人类对齐的响应方面的性能已被证明至关重要。然而，在调整过程中收集多样化、高质量的指令数据存在挑战，特别是在涉及隐私的领域。联邦指令调整（FedIT）已成为一种解决方案，利用来自多个数据所有者的联邦学习，同时保护隐私。然而，由于指令数据有限以及容易受到训练数据提取攻击的脆弱性，它面临挑战。为解决这些问题，我们提出了一种新颖的联邦算法，FedPIT，它利用LLMs的上下文学习能力自动生成用于训练的特定任务合成数据。我们的方法采用参数隔离训练来维护在合成数据上训练的全局参数和在增强本地数据上训练的本地参数，有效地防止数据提取攻击。",
    "tldr": "提出一种新颖的联邦算法FedPIT，通过利用LLMs的上下文学习能力自动生成任务特定的合成数据进行训练，采用参数隔离训练来防止数据提取攻击。",
    "en_tdlr": "Proposed a novel federated algorithm FedPIT that utilizes LLMs' in-context learning capability to self-generate task-specific synthetic data for training, employing parameter-isolated training to thwart data extraction attacks."
}