{
    "title": "Reducing self-supervised learning complexity improves weakly-supervised classification performance in computational pathology",
    "abstract": "arXiv:2403.04558v1 Announce Type: cross  Abstract: Deep Learning models have been successfully utilized to extract clinically actionable insights from routinely available histology data. Generally, these models require annotations performed by clinicians, which are scarce and costly to generate. The emergence of self-supervised learning (SSL) methods remove this barrier, allowing for large-scale analyses on non-annotated data. However, recent SSL approaches apply increasingly expansive model architectures and larger datasets, causing the rapid escalation of data volumes, hardware prerequisites, and overall expenses, limiting access to these resources to few institutions. Therefore, we investigated the complexity of contrastive SSL in computational pathology in relation to classification performance with the utilization of consumer-grade hardware. Specifically, we analyzed the effects of adaptations in data volume, architecture, and algorithms on downstream clas- sification tasks, empha",
    "link": "https://arxiv.org/abs/2403.04558",
    "context": "Title: Reducing self-supervised learning complexity improves weakly-supervised classification performance in computational pathology\nAbstract: arXiv:2403.04558v1 Announce Type: cross  Abstract: Deep Learning models have been successfully utilized to extract clinically actionable insights from routinely available histology data. Generally, these models require annotations performed by clinicians, which are scarce and costly to generate. The emergence of self-supervised learning (SSL) methods remove this barrier, allowing for large-scale analyses on non-annotated data. However, recent SSL approaches apply increasingly expansive model architectures and larger datasets, causing the rapid escalation of data volumes, hardware prerequisites, and overall expenses, limiting access to these resources to few institutions. Therefore, we investigated the complexity of contrastive SSL in computational pathology in relation to classification performance with the utilization of consumer-grade hardware. Specifically, we analyzed the effects of adaptations in data volume, architecture, and algorithms on downstream clas- sification tasks, empha",
    "path": "papers/24/03/2403.04558.json",
    "total_tokens": 807,
    "translated_title": "减少自监督学习复杂性改善计算病理学中的弱监督分类性能",
    "translated_abstract": "深度学习模型已成功应用于从常规可用的组织学数据中提取临床可操作见解。通常，这些模型需要临床医生进行的标注，这种标注稀缺且昂贵。自监督学习（SSL）方法的出现消除了这一障碍，允许对非标注数据进行大规模分析。然而，最近的SSL方法采用日益庞大的模型架构和更大的数据集，导致数据量迅速增加，硬件要求和整体成本增加，使得很少机构能够获得这些资源。因此，我们研究了对比自监督学习在计算病理学中的复杂性与分类性能之间的关系，利用消费级硬件。具体而言，我们分析了数据量、架构和算法的调整对下游分类任务的影响。",
    "tldr": "本研究探讨了在计算病理学中减少对比自监督学习复杂性对分类性能的改善，通过利用消费级硬件。",
    "en_tdlr": "This study investigates the improvement of classification performance by reducing the complexity of contrastive self-supervised learning in computational pathology, utilizing consumer-grade hardware."
}