{
    "title": "Zero-shot cross-modal transfer of Reinforcement Learning policies through a Global Workspace",
    "abstract": "arXiv:2403.04588v1 Announce Type: new  Abstract: Humans perceive the world through multiple senses, enabling them to create a comprehensive representation of their surroundings and to generalize information across domains. For instance, when a textual description of a scene is given, humans can mentally visualize it. In fields like robotics and Reinforcement Learning (RL), agents can also access information about the environment through multiple sensors; yet redundancy and complementarity between sensors is difficult to exploit as a source of robustness (e.g. against sensor failure) or generalization (e.g. transfer across domains). Prior research demonstrated that a robust and flexible multimodal representation can be efficiently constructed based on the cognitive science notion of a 'Global Workspace': a unique representation trained to combine information across modalities, and to broadcast its signal back to each modality. Here, we explore whether such a brain-inspired multimodal re",
    "link": "https://arxiv.org/abs/2403.04588",
    "context": "Title: Zero-shot cross-modal transfer of Reinforcement Learning policies through a Global Workspace\nAbstract: arXiv:2403.04588v1 Announce Type: new  Abstract: Humans perceive the world through multiple senses, enabling them to create a comprehensive representation of their surroundings and to generalize information across domains. For instance, when a textual description of a scene is given, humans can mentally visualize it. In fields like robotics and Reinforcement Learning (RL), agents can also access information about the environment through multiple sensors; yet redundancy and complementarity between sensors is difficult to exploit as a source of robustness (e.g. against sensor failure) or generalization (e.g. transfer across domains). Prior research demonstrated that a robust and flexible multimodal representation can be efficiently constructed based on the cognitive science notion of a 'Global Workspace': a unique representation trained to combine information across modalities, and to broadcast its signal back to each modality. Here, we explore whether such a brain-inspired multimodal re",
    "path": "papers/24/03/2403.04588.json",
    "total_tokens": 666,
    "translated_title": "通过全球工作空间实现零射击跨模态转移的强化学习策略",
    "translated_abstract": "人类通过多种感官感知世界，使他们能够综合地表达周围环境，并且能够在不同领域之间泛化信息。本文探讨了通过“全局工作空间”的认知科学概念来构建强大而灵活的多模态表示，以及在机器人和强化学习领域中将其应用于跨模态转移的有效性。",
    "tldr": "本研究探索了利用全球工作空间来构建多模态表示，以实现零射击跨模态转移的强化学习策略。",
    "en_tdlr": "This study explores using a Global Workspace to construct multimodal representations for achieving zero-shot cross-modal transfer of Reinforcement Learning policies."
}