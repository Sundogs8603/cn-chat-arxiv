{
    "title": "A comparison of Human, GPT-3.5, and GPT-4 Performance in a University-Level Coding Course",
    "abstract": "arXiv:2403.16977v1 Announce Type: new  Abstract: This study evaluates the performance of ChatGPT variants, GPT-3.5 and GPT-4, both with and without prompt engineering, against solely student work and a mixed category containing both student and GPT-4 contributions in university-level physics coding assignments using the Python language. Comparing 50 student submissions to 50 AI-generated submissions across different categories, and marked blindly by three independent markers, we amassed $n = 300$ data points. Students averaged 91.9% (SE:0.4), surpassing the highest performing AI submission category, GPT-4 with prompt engineering, which scored 81.1% (SE:0.8) - a statistically significant difference (p = $2.482 \\times 10^{-10}$). Prompt engineering significantly improved scores for both GPT-4 (p = $1.661 \\times 10^{-4}$) and GPT-3.5 (p = $4.967 \\times 10^{-9}$). Additionally, the blinded markers were tasked with guessing the authorship of the submissions on a four-point Likert scale from",
    "link": "https://arxiv.org/abs/2403.16977",
    "context": "Title: A comparison of Human, GPT-3.5, and GPT-4 Performance in a University-Level Coding Course\nAbstract: arXiv:2403.16977v1 Announce Type: new  Abstract: This study evaluates the performance of ChatGPT variants, GPT-3.5 and GPT-4, both with and without prompt engineering, against solely student work and a mixed category containing both student and GPT-4 contributions in university-level physics coding assignments using the Python language. Comparing 50 student submissions to 50 AI-generated submissions across different categories, and marked blindly by three independent markers, we amassed $n = 300$ data points. Students averaged 91.9% (SE:0.4), surpassing the highest performing AI submission category, GPT-4 with prompt engineering, which scored 81.1% (SE:0.8) - a statistically significant difference (p = $2.482 \\times 10^{-10}$). Prompt engineering significantly improved scores for both GPT-4 (p = $1.661 \\times 10^{-4}$) and GPT-3.5 (p = $4.967 \\times 10^{-9}$). Additionally, the blinded markers were tasked with guessing the authorship of the submissions on a four-point Likert scale from",
    "path": "papers/24/03/2403.16977.json",
    "total_tokens": 993,
    "translated_title": "人类、GPT-3.5和GPT-4在大学级编程课程中表现的比较",
    "translated_abstract": "本研究评估了使用Python语言在大学级物理编程作业中，ChatGPT变种GPT-3.5和GPT-4的表现，包括是否进行提示工程，与仅学生作品和同时包含学生和GPT-4贡献的混合类别的对比。通过50份学生提交和50份不同类别的AI生成的提交的评比，由三名独立评分者进行盲目评分，我们总计了300个数据点。学生平均得分为91.9% (标准误:0.4)，超过了得分为81.1% (标准误:0.8)的表现最好的AI提交类别GPT-4+提示工程，这是一个显著差异 (p = $2.482 \\times 10^{-10}$)。提示工程显著提高了GPT-4 (p = $1.661 \\times 10^{-4}$)和GPT-3.5 (p = $4.967 \\times 10^{-9}$)的得分。此外，盲目评分者被要求使用四点李克特量表猜测提交作品的作者身份。",
    "tldr": "本研究比较了人类、GPT-3.5和GPT-4在大学级编程课程中的表现，结果显示学生的平均得分明显高于AI提交，同时提示工程显著提高了GPT-4和GPT-3.5的得分。"
}