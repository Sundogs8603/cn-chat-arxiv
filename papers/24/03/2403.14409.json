{
    "title": "Locating and Mitigating Gender Bias in Large Language Models",
    "abstract": "arXiv:2403.14409v1 Announce Type: cross  Abstract: Large language models(LLM) are pre-trained on extensive corpora to learn facts and human cognition which contain human preferences. However, this process can inadvertently lead to these models acquiring biases and stereotypes prevalent in society. Prior research has typically tackled the issue of bias through a one-dimensional perspective, concentrating either on locating or mitigating it. This limited perspective has created obstacles in facilitating research on bias to synergistically complement and progressively build upon one another. In this study, we integrate the processes of locating and mitigating bias within a unified framework. Initially, we use causal mediation analysis to trace the causal effects of different components' activation within a large language model. Building on this, we propose the LSDM (Least Square Debias Method), a knowledge-editing based method for mitigating gender bias in occupational pronouns, and compa",
    "link": "https://arxiv.org/abs/2403.14409",
    "context": "Title: Locating and Mitigating Gender Bias in Large Language Models\nAbstract: arXiv:2403.14409v1 Announce Type: cross  Abstract: Large language models(LLM) are pre-trained on extensive corpora to learn facts and human cognition which contain human preferences. However, this process can inadvertently lead to these models acquiring biases and stereotypes prevalent in society. Prior research has typically tackled the issue of bias through a one-dimensional perspective, concentrating either on locating or mitigating it. This limited perspective has created obstacles in facilitating research on bias to synergistically complement and progressively build upon one another. In this study, we integrate the processes of locating and mitigating bias within a unified framework. Initially, we use causal mediation analysis to trace the causal effects of different components' activation within a large language model. Building on this, we propose the LSDM (Least Square Debias Method), a knowledge-editing based method for mitigating gender bias in occupational pronouns, and compa",
    "path": "papers/24/03/2403.14409.json",
    "total_tokens": 929,
    "translated_title": "定位和减轻大型语言模型中的性别偏见",
    "translated_abstract": "大型语言模型（LLM）在广泛语料库上进行预训练，学习事实和人类认知，其中包含人类偏好。然而，这个过程可能无意中导致这些模型获得社会中普遍存在的偏见和刻板印象。先前的研究通常通过单一视角处理偏见问题，集中于定位或减轻偏见。这种有限的视角在促进偏见研究方面造成了障碍，无法协同互补并逐步积累经验。在这项研究中，我们将定位和减轻偏见的过程融入一个统一框架内。首先，我们使用因果中介分析来跟踪大型语言模型中不同组件激活的因果效应。在此基础上，我们提出LSDM（最小二乘减偏方法），这是一种基于知识编辑的方法，用于减轻职业代词中的性别偏见，和比较",
    "tldr": "本研究提出了一种将定位和减轻偏见过程融入统一框架的方法，通过因果中介分析追踪大型语言模型中不同组件激活的因果效应，并提出了一种用于减轻职业代词中性别偏见的基于知识编辑的LSDM方法。",
    "en_tdlr": "This study proposes a method that integrates the processes of locating and mitigating bias within a unified framework, tracking the causal effects of different components' activation within a large language model through causal mediation analysis, and introduces the LSDM method, a knowledge-editing based approach for mitigating gender bias in occupational pronouns."
}