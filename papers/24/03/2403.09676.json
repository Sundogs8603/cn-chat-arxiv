{
    "title": "Unmasking the Shadows of AI: Investigating Deceptive Capabilities in Large Language Models",
    "abstract": "arXiv:2403.09676v1 Announce Type: cross  Abstract: This research critically navigates the intricate landscape of AI deception, concentrating on deceptive behaviours of Large Language Models (LLMs). My objective is to elucidate this issue, examine the discourse surrounding it, and subsequently delve into its categorization and ramifications. The essay initiates with an evaluation of the AI Safety Summit 2023 (ASS) and introduction of LLMs, emphasising multidimensional biases that underlie their deceptive behaviours.The literature review covers four types of deception categorised: Strategic deception, Imitation, Sycophancy, and Unfaithful Reasoning, along with the social implications and risks they entail. Lastly, I take an evaluative stance on various aspects related to navigating the persistent challenges of the deceptive AI. This encompasses considerations of international collaborative governance, the reconfigured engagement of individuals with AI, proposal of practical adjustments, ",
    "link": "https://arxiv.org/abs/2403.09676",
    "context": "Title: Unmasking the Shadows of AI: Investigating Deceptive Capabilities in Large Language Models\nAbstract: arXiv:2403.09676v1 Announce Type: cross  Abstract: This research critically navigates the intricate landscape of AI deception, concentrating on deceptive behaviours of Large Language Models (LLMs). My objective is to elucidate this issue, examine the discourse surrounding it, and subsequently delve into its categorization and ramifications. The essay initiates with an evaluation of the AI Safety Summit 2023 (ASS) and introduction of LLMs, emphasising multidimensional biases that underlie their deceptive behaviours.The literature review covers four types of deception categorised: Strategic deception, Imitation, Sycophancy, and Unfaithful Reasoning, along with the social implications and risks they entail. Lastly, I take an evaluative stance on various aspects related to navigating the persistent challenges of the deceptive AI. This encompasses considerations of international collaborative governance, the reconfigured engagement of individuals with AI, proposal of practical adjustments, ",
    "path": "papers/24/03/2403.09676.json",
    "total_tokens": 841,
    "translated_title": "揭开AI的阴影：探究大型语言模型的欺骗能力",
    "translated_abstract": "这项研究对人工智能欺骗的复杂领域进行了批判性导航，集中研究了大型语言模型（LLMs）的欺骗行为。作者的目标是阐明这一问题，审视围绕它的讨论，随后深入其分类和后果。文章从评估2033年AI安全峰会（ASS），以及LLMs的介绍开始，强调了潜在导致它们欺骗行为的多维偏见。文献综述涵盖了四种分类的欺骗：战略欺骗、模仿、谄媚和不忠推理，以及它们所带来的社会影响和风险。最后，作者对与应对欺骗AI的持久挑战相关的各个方面采取了评估立场。这包括考虑国际协作治理、个人与AI重新构建的互动，提出实际调整的建议。",
    "tldr": "该研究探讨了大型语言模型的欺骗行为并分类讨论其引发的社会影响和风险。",
    "en_tdlr": "This research investigates deceptive behaviors of Large Language Models (LLMs) and categorizes their social implications and risks."
}