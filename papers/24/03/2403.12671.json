{
    "title": "Enhancing Security of AI-Based Code Synthesis with GitHub Copilot via Cheap and Efficient Prompt-Engineering",
    "abstract": "arXiv:2403.12671v1 Announce Type: cross  Abstract: AI assistants for coding are on the rise. However one of the reasons developers and companies avoid harnessing their full potential is the questionable security of the generated code. This paper first reviews the current state-of-the-art and identifies areas for improvement on this issue. Then, we propose a systematic approach based on prompt-altering methods to achieve better code security of (even proprietary black-box) AI-based code generators such as GitHub Copilot, while minimizing the complexity of the application from the user point-of-view, the computational resources, and operational costs. In sum, we propose and evaluate three prompt altering methods: (1) scenario-specific, (2) iterative, and (3) general clause, while we discuss their combination. Contrary to the audit of code security, the latter two of the proposed methods require no expert knowledge from the user. We assess the effectiveness of the proposed methods on the ",
    "link": "https://arxiv.org/abs/2403.12671",
    "context": "Title: Enhancing Security of AI-Based Code Synthesis with GitHub Copilot via Cheap and Efficient Prompt-Engineering\nAbstract: arXiv:2403.12671v1 Announce Type: cross  Abstract: AI assistants for coding are on the rise. However one of the reasons developers and companies avoid harnessing their full potential is the questionable security of the generated code. This paper first reviews the current state-of-the-art and identifies areas for improvement on this issue. Then, we propose a systematic approach based on prompt-altering methods to achieve better code security of (even proprietary black-box) AI-based code generators such as GitHub Copilot, while minimizing the complexity of the application from the user point-of-view, the computational resources, and operational costs. In sum, we propose and evaluate three prompt altering methods: (1) scenario-specific, (2) iterative, and (3) general clause, while we discuss their combination. Contrary to the audit of code security, the latter two of the proposed methods require no expert knowledge from the user. We assess the effectiveness of the proposed methods on the ",
    "path": "papers/24/03/2403.12671.json",
    "total_tokens": 837,
    "translated_title": "通过廉价高效的提示工程增强 GitHub Copilot 的 AI 代码合成安全性",
    "translated_abstract": "编程的 AI 助手正在兴起。然而，开发人员和公司避免充分利用它们的一个原因是生成代码的安全性存疑。本文首先回顾了当前的最先进技术，并确定了需要改进的领域。然后，我们提出了一种基于提示改变方法的系统方法，以实现更好的代码安全性，即使是针对专有黑盒的 AI 代码生成器，如 GitHub Copilot，同时尽量减少用户角度、计算资源和运营成本的复杂性。总之，我们提出并评估了三种提示改变方法：（1）特定场景的，（2）迭代的，和（3）通用的从句，同时讨论它们的组合。与对代码安全性的审计相反，最后两种所提出的方法不需要用户具备专业知识。我们评估了所提出方法在...",
    "tldr": "提出了通过提示工程方法增强 GitHub Copilot 的 AI 代码合成安全性，其中包括三种提示改变方法：特定场景的、迭代的和通用的从句，同时讨论它们的组合。",
    "en_tdlr": "Proposed to enhance the security of AI-based code synthesis with GitHub Copilot through prompt-engineering, including three prompt altering methods: scenario-specific, iterative, and general clause, while discussing their combination."
}