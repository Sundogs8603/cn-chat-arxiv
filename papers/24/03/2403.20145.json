{
    "title": "Fine-tuning Large Language Models for Automated Diagnostic Screening Summaries",
    "abstract": "arXiv:2403.20145v1 Announce Type: new  Abstract: Improving mental health support in developing countries is a pressing need. One potential solution is the development of scalable, automated systems to conduct diagnostic screenings, which could help alleviate the burden on mental health professionals. In this work, we evaluate several state-of-the-art Large Language Models (LLMs), with and without fine-tuning, on our custom dataset for generating concise summaries from mental state examinations. We rigorously evaluate four different models for summary generation using established ROUGE metrics and input from human evaluators. The results highlight that our top-performing fine-tuned model outperforms existing models, achieving ROUGE-1 and ROUGE-L values of 0.810 and 0.764, respectively. Furthermore, we assessed the fine-tuned model's generalizability on a publicly available D4 dataset, and the outcomes were promising, indicating its potential applicability beyond our custom dataset.",
    "link": "https://arxiv.org/abs/2403.20145",
    "context": "Title: Fine-tuning Large Language Models for Automated Diagnostic Screening Summaries\nAbstract: arXiv:2403.20145v1 Announce Type: new  Abstract: Improving mental health support in developing countries is a pressing need. One potential solution is the development of scalable, automated systems to conduct diagnostic screenings, which could help alleviate the burden on mental health professionals. In this work, we evaluate several state-of-the-art Large Language Models (LLMs), with and without fine-tuning, on our custom dataset for generating concise summaries from mental state examinations. We rigorously evaluate four different models for summary generation using established ROUGE metrics and input from human evaluators. The results highlight that our top-performing fine-tuned model outperforms existing models, achieving ROUGE-1 and ROUGE-L values of 0.810 and 0.764, respectively. Furthermore, we assessed the fine-tuned model's generalizability on a publicly available D4 dataset, and the outcomes were promising, indicating its potential applicability beyond our custom dataset.",
    "path": "papers/24/03/2403.20145.json",
    "total_tokens": 867,
    "translated_title": "为自动诊断筛查总结优化大型语言模型的研究",
    "translated_abstract": "在发展中国家改善心理健康支持是一个紧迫的需求。一种潜在的解决方案是开发可扩展的自动系统进行诊断筛查，这有助于减轻心理健康专业人员的负担。本研究评估了几种最先进的大型语言模型（LLMs）在自定义数据集上进行了微调和未微调，用于从心理状态检查中生成简明摘要。我们使用已建立的ROUGE指标和人类评估者的输入，对四种不同的摘要生成模型进行了严格评估。结果表明，我们表现最佳的经过微调的模型胜过现有模型，分别实现了0.810和0.764的ROUGE-1和ROUGE-L值。此外，我们对微调模型在公开可用的D4数据集上的泛化能力进行了评估，结果令人鼓舞，表明其潜在适用性超出我们的自定义数据集。",
    "tldr": "该研究通过评估大型语言模型在自定义数据集上的微调和未微调，发现经过微调的模型胜过现有模型，在生成摘要方面取得了显著的进展。"
}