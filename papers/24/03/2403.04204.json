{
    "title": "On the Essence and Prospect: An Investigation of Alignment Approaches for Big Models",
    "abstract": "arXiv:2403.04204v1 Announce Type: new  Abstract: Big models have achieved revolutionary breakthroughs in the field of AI, but they might also pose potential concerns. Addressing such concerns, alignment technologies were introduced to make these models conform to human preferences and values. Despite considerable advancements in the past year, various challenges lie in establishing the optimal alignment strategy, such as data cost and scalable oversight, and how to align remains an open question. In this survey paper, we comprehensively investigate value alignment approaches. We first unpack the historical context of alignment tracing back to the 1920s (where it comes from), then delve into the mathematical essence of alignment (what it is), shedding light on the inherent challenges. Following this foundation, we provide a detailed examination of existing alignment methods, which fall into three categories: Reinforcement Learning, Supervised Fine-Tuning, and In-context Learning, and de",
    "link": "https://arxiv.org/abs/2403.04204",
    "context": "Title: On the Essence and Prospect: An Investigation of Alignment Approaches for Big Models\nAbstract: arXiv:2403.04204v1 Announce Type: new  Abstract: Big models have achieved revolutionary breakthroughs in the field of AI, but they might also pose potential concerns. Addressing such concerns, alignment technologies were introduced to make these models conform to human preferences and values. Despite considerable advancements in the past year, various challenges lie in establishing the optimal alignment strategy, such as data cost and scalable oversight, and how to align remains an open question. In this survey paper, we comprehensively investigate value alignment approaches. We first unpack the historical context of alignment tracing back to the 1920s (where it comes from), then delve into the mathematical essence of alignment (what it is), shedding light on the inherent challenges. Following this foundation, we provide a detailed examination of existing alignment methods, which fall into three categories: Reinforcement Learning, Supervised Fine-Tuning, and In-context Learning, and de",
    "path": "papers/24/03/2403.04204.json",
    "total_tokens": 876,
    "translated_title": "对于大型模型对齐方法的探究：本质与前景",
    "translated_abstract": "大型模型在人工智能领域取得了革命性突破，但也可能带来潜在的问题。为解决这些问题，引入了对齐技术，使这些模型符合人类的偏好和价值观。尽管在过去一年取得了相当大的进展，但建立最佳对齐策略仍面临诸多挑战，如数据成本和可扩展性监督。如何进行对齐仍然是一个开放的问题。在这篇调查论文中，我们全面调查了价值对齐方法。我们首先揭示了对齐的历史背景，追溯到20世纪20年代（它的起源），然后深入探讨了对齐的数学本质（它是什么），阐明了其中固有的挑战。在奠定了这个基础后，我们对现有的对齐方法进行了详细考察，这些方法可以分为三类：强化学习、监督微调和上下文学习。",
    "tldr": "调查了大型模型价值对齐方法，揭示历史背景和数学本质，详细讨论了强化学习、监督微调和上下文学习等对齐方法。",
    "en_tdlr": "Investigated alignment approaches for big models, exploring historical context and mathematical essence, discussing in detail reinforcement learning, supervised fine-tuning, and in-context learning methods."
}