{
    "title": "OSSCAR: One-Shot Structured Pruning in Vision and Language Models with Combinatorial Optimization",
    "abstract": "arXiv:2403.12983v1 Announce Type: cross  Abstract: Structured pruning is a promising approach for reducing the inference costs of large vision and language models. By removing carefully chosen structures, e.g., neurons or attention heads, the improvements from this approach can be realized on standard deep learning hardware. In this work, we focus on structured pruning in the one-shot (post-training) setting, which does not require model retraining after pruning. We propose a novel combinatorial optimization framework for this problem, based on a layer-wise reconstruction objective and a careful reformulation that allows for scalable optimization. Moreover, we design a new local combinatorial optimization algorithm, which exploits low-rank updates for efficient local search. Our framework is time and memory-efficient and considerably improves upon state-of-the-art one-shot methods on vision models (e.g., ResNet50, MobileNet) and language models (e.g., OPT-1.3B -- OPT-30B). For language",
    "link": "https://arxiv.org/abs/2403.12983",
    "context": "Title: OSSCAR: One-Shot Structured Pruning in Vision and Language Models with Combinatorial Optimization\nAbstract: arXiv:2403.12983v1 Announce Type: cross  Abstract: Structured pruning is a promising approach for reducing the inference costs of large vision and language models. By removing carefully chosen structures, e.g., neurons or attention heads, the improvements from this approach can be realized on standard deep learning hardware. In this work, we focus on structured pruning in the one-shot (post-training) setting, which does not require model retraining after pruning. We propose a novel combinatorial optimization framework for this problem, based on a layer-wise reconstruction objective and a careful reformulation that allows for scalable optimization. Moreover, we design a new local combinatorial optimization algorithm, which exploits low-rank updates for efficient local search. Our framework is time and memory-efficient and considerably improves upon state-of-the-art one-shot methods on vision models (e.g., ResNet50, MobileNet) and language models (e.g., OPT-1.3B -- OPT-30B). For language",
    "path": "papers/24/03/2403.12983.json",
    "total_tokens": 853,
    "translated_title": "OSSCAR：视觉和语言模型中的一次性结构修剪与组合优化",
    "translated_abstract": "结构修剪是减少大型视觉和语言模型推理成本的一种有前景的方法。通过精心选择结构，例如神经元或注意力头，可以在标准深度学习硬件上实现该方法的改进。在这项工作中，我们专注于一次性（训练后）设置中的结构修剪，这不需要修剪后重新训练模型。我们为这个问题提出了一个基于层次重构目标和仔细重新制定的新型组合优化框架，使得优化可扩展。此外，我们设计了一种新的本地组合优化算法，利用低秩更新进行高效的局部搜索。我们的框架在时间和内存效率上都得到了改善，并且在视觉模型（例如ResNet50、MobileNet）和语言模型（例如OPT-1.3B至OPT-30B）上明显优于最先进的一次性方法。",
    "tldr": "本文提出了一种基于组合优化的新型框架，针对一次性结构修剪问题，无需模型重新训练，在视觉和语言模型上取得了显著改进。",
    "en_tdlr": "This paper presents a novel framework based on combinatorial optimization for one-shot structured pruning, achieving significant improvements on vision and language models without the need for model retraining."
}