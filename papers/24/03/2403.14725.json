{
    "title": "Jailbreaking is Best Solved by Definition",
    "abstract": "arXiv:2403.14725v1 Announce Type: cross  Abstract: The rise of \"jailbreak\" attacks on language models has led to a flurry of defenses aimed at preventing the output of undesirable responses. In this work, we critically examine the two stages of the defense pipeline: (i) the definition of what constitutes unsafe outputs, and (ii) the enforcement of the definition via methods such as input processing or fine-tuning. We cast severe doubt on the efficacy of existing enforcement mechanisms by showing that they fail to defend even for a simple definition of unsafe outputs--outputs that contain the word \"purple\". In contrast, post-processing outputs is perfectly robust for such a definition. Drawing on our results, we present our position that the real challenge in defending jailbreaks lies in obtaining a good definition of unsafe responses: without a good definition, no enforcement strategy can succeed, but with a good definition, output processing already serves as a robust baseline albeit ",
    "link": "https://arxiv.org/abs/2403.14725",
    "context": "Title: Jailbreaking is Best Solved by Definition\nAbstract: arXiv:2403.14725v1 Announce Type: cross  Abstract: The rise of \"jailbreak\" attacks on language models has led to a flurry of defenses aimed at preventing the output of undesirable responses. In this work, we critically examine the two stages of the defense pipeline: (i) the definition of what constitutes unsafe outputs, and (ii) the enforcement of the definition via methods such as input processing or fine-tuning. We cast severe doubt on the efficacy of existing enforcement mechanisms by showing that they fail to defend even for a simple definition of unsafe outputs--outputs that contain the word \"purple\". In contrast, post-processing outputs is perfectly robust for such a definition. Drawing on our results, we present our position that the real challenge in defending jailbreaks lies in obtaining a good definition of unsafe responses: without a good definition, no enforcement strategy can succeed, but with a good definition, output processing already serves as a robust baseline albeit ",
    "path": "papers/24/03/2403.14725.json",
    "total_tokens": 810,
    "translated_title": "Jailbreaking的最佳解决方案是通过定义",
    "translated_abstract": "语言模型上\"越狱\"攻击的增多引发了大量防御工作，旨在防止产生不良回应。在这项工作中，我们批判性地审视了防御管道的两个阶段：（i）定义何为不安全输出，和（ii）通过输入处理或微调等方法来执行该定义。我们严重怀疑现有的执行机制的有效性，通过展示它们即使对于简单的不安全输出定义--包含单词\"purple\"的输出也无法防御。相比之下，对输出进行后处理对于这样的定义是完全健壮的。基于我们的结果，我们提出我们的观点，即在防御越狱攻击中真正的挑战在于得到一个良好的不安全响应定义：没有良好的定义，任何执行策略都无法成功，但有了良好的定义，输出处理已经作为一个强大的基线。",
    "tldr": "语言模型中\"越狱\"攻击的关键是通过定义好的不安全响应来进行防御，而不是依赖于执行策略。",
    "en_tdlr": "The key to defending against \"jailbreak\" attacks on language models lies in defining unsafe responses effectively rather than relying on enforcement strategies."
}