{
    "title": "Mol-AIR: Molecular Reinforcement Learning with Adaptive Intrinsic Rewards for Goal-directed Molecular Generation",
    "abstract": "arXiv:2403.20109v1 Announce Type: cross  Abstract: Optimizing techniques for discovering molecular structures with desired properties is crucial in artificial intelligence(AI)-based drug discovery. Combining deep generative models with reinforcement learning has emerged as an effective strategy for generating molecules with specific properties. Despite its potential, this approach is ineffective in exploring the vast chemical space and optimizing particular chemical properties. To overcome these limitations, we present Mol-AIR, a reinforcement learning-based framework using adaptive intrinsic rewards for effective goal-directed molecular generation. Mol-AIR leverages the strengths of both history-based and learning-based intrinsic rewards by exploiting random distillation network and counting-based strategies. In benchmark tests, Mol-AIR demonstrates superior performance over existing approaches in generating molecules with desired properties without any prior knowledge, including pena",
    "link": "https://arxiv.org/abs/2403.20109",
    "context": "Title: Mol-AIR: Molecular Reinforcement Learning with Adaptive Intrinsic Rewards for Goal-directed Molecular Generation\nAbstract: arXiv:2403.20109v1 Announce Type: cross  Abstract: Optimizing techniques for discovering molecular structures with desired properties is crucial in artificial intelligence(AI)-based drug discovery. Combining deep generative models with reinforcement learning has emerged as an effective strategy for generating molecules with specific properties. Despite its potential, this approach is ineffective in exploring the vast chemical space and optimizing particular chemical properties. To overcome these limitations, we present Mol-AIR, a reinforcement learning-based framework using adaptive intrinsic rewards for effective goal-directed molecular generation. Mol-AIR leverages the strengths of both history-based and learning-based intrinsic rewards by exploiting random distillation network and counting-based strategies. In benchmark tests, Mol-AIR demonstrates superior performance over existing approaches in generating molecules with desired properties without any prior knowledge, including pena",
    "path": "papers/24/03/2403.20109.json",
    "total_tokens": 855,
    "translated_title": "Mol-AIR：使用自适应内在奖励的分子强化学习用于目标导向的分子生成",
    "translated_abstract": "优化发现具有期望性质的分子结构的技术在基于人工智能(AI)的药物发现中至关重要。将深度生成模型与强化学习相结合已经成为生成具有特定性质的分子的有效策略。尽管具有潜力，但这种方法在探索庞大的化学空间和优化特定化学性质方面效果不佳。为了克服这些局限性，我们提出了Mol-AIR，这是一个基于强化学习的框架，使用自适应内在奖励进行有效的目标导向分子生成。Mol-AIR利用基于历史的和基于学习的内在奖励的优势，通过利用随机蒸馏网络和基于计数的策略。在基准测试中，Mol-AIR展现了超出现有方法的性能，在生成具有期望性质的分子方面，无需任何先验知识，包括pena",
    "tldr": "Mol-AIR 提出了使用自适应内在奖励的分子强化学习框架，通过利用历史和学习的内在奖励优势，在生成具有期望性质的分子方面表现出卓越性能。",
    "en_tdlr": "Mol-AIR introduces a molecular reinforcement learning framework with adaptive intrinsic rewards, leveraging the strengths of both history-based and learning-based intrinsic rewards to demonstrate superior performance in generating molecules with desired properties."
}