{
    "title": "Using Generative Text Models to Create Qualitative Codebooks for Student Evaluations of Teaching",
    "abstract": "arXiv:2403.11984v1 Announce Type: cross  Abstract: Feedback is a critical aspect of improvement. Unfortunately, when there is a lot of feedback from multiple sources, it can be difficult to distill the information into actionable insights. Consider student evaluations of teaching (SETs), which are important sources of feedback for educators. They can give instructors insights into what worked during a semester. A collection of SETs can also be useful to administrators as signals for courses or entire programs. However, on a large scale as in high-enrollment courses or administrative records over several years, the volume of SETs can render them difficult to analyze. In this paper, we discuss a novel method for analyzing SETs using natural language processing (NLP) and large language models (LLMs). We demonstrate the method by applying it to a corpus of 5,000 SETs from a large public university. We show that the method can be used to extract, embed, cluster, and summarize the SETs to id",
    "link": "https://arxiv.org/abs/2403.11984",
    "context": "Title: Using Generative Text Models to Create Qualitative Codebooks for Student Evaluations of Teaching\nAbstract: arXiv:2403.11984v1 Announce Type: cross  Abstract: Feedback is a critical aspect of improvement. Unfortunately, when there is a lot of feedback from multiple sources, it can be difficult to distill the information into actionable insights. Consider student evaluations of teaching (SETs), which are important sources of feedback for educators. They can give instructors insights into what worked during a semester. A collection of SETs can also be useful to administrators as signals for courses or entire programs. However, on a large scale as in high-enrollment courses or administrative records over several years, the volume of SETs can render them difficult to analyze. In this paper, we discuss a novel method for analyzing SETs using natural language processing (NLP) and large language models (LLMs). We demonstrate the method by applying it to a corpus of 5,000 SETs from a large public university. We show that the method can be used to extract, embed, cluster, and summarize the SETs to id",
    "path": "papers/24/03/2403.11984.json",
    "total_tokens": 702,
    "translated_title": "使用生成文本模型为教学评估创建定性代码手册",
    "translated_abstract": "反馈是改进的关键方面。然而，当有来自多个来源的大量反馈时，将信息提炼成可操作的见解可能会很困难。本文讨论了一种使用自然语言处理（NLP）和大型语言模型（LLMs）分析教学评估（SETs）的新方法。我们通过将其应用于一所大型公立大学的5000个SETs语料库来演示该方法。",
    "tldr": "本文介绍了一种使用自然语言处理和大型语言模型分析教学评估的新方法，可以从大量反馈中提取、嵌入、聚类和总结SETs。",
    "en_tdlr": "This paper presents a novel method using natural language processing and large language models to analyze student evaluations of teaching, extracting, embedding, clustering, and summarizing SETs from a large volume of feedback."
}