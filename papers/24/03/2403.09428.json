{
    "title": "Borrowing Treasures from Neighbors: In-Context Learning for Multimodal Learning with Missing Modalities and Data Scarcity",
    "abstract": "arXiv:2403.09428v1 Announce Type: new  Abstract: Multimodal machine learning with missing modalities is an increasingly relevant challenge arising in various applications such as healthcare. This paper extends the current research into missing modalities to the low-data regime, i.e., a downstream task has both missing modalities and limited sample size issues. This problem setting is particularly challenging and also practical as it is often expensive to get full-modality data and sufficient annotated training samples. We propose to use retrieval-augmented in-context learning to address these two crucial issues by unleashing the potential of a transformer's in-context learning ability. Diverging from existing methods, which primarily belong to the parametric paradigm and often require sufficient training samples, our work exploits the value of the available full-modality data, offering a novel perspective on resolving the challenge. The proposed data-dependent framework exhibits a high",
    "link": "https://arxiv.org/abs/2403.09428",
    "context": "Title: Borrowing Treasures from Neighbors: In-Context Learning for Multimodal Learning with Missing Modalities and Data Scarcity\nAbstract: arXiv:2403.09428v1 Announce Type: new  Abstract: Multimodal machine learning with missing modalities is an increasingly relevant challenge arising in various applications such as healthcare. This paper extends the current research into missing modalities to the low-data regime, i.e., a downstream task has both missing modalities and limited sample size issues. This problem setting is particularly challenging and also practical as it is often expensive to get full-modality data and sufficient annotated training samples. We propose to use retrieval-augmented in-context learning to address these two crucial issues by unleashing the potential of a transformer's in-context learning ability. Diverging from existing methods, which primarily belong to the parametric paradigm and often require sufficient training samples, our work exploits the value of the available full-modality data, offering a novel perspective on resolving the challenge. The proposed data-dependent framework exhibits a high",
    "path": "papers/24/03/2403.09428.json",
    "total_tokens": 749,
    "translated_title": "与邻居借宝：用于多模态学习的上下文学习，解决缺失模态和数据稀缺问题",
    "translated_abstract": "缺失模态的多模态机器学习是一个越来越相关的挑战，在各种应用中如医疗保健。本文将现有关于缺失模态的研究拓展到低数据情境，即一个下游任务既存在缺失模态又存在样本数量有限的问题。我们建议使用检索增强的上下文学习来解决这两个关键问题，释放变压器在上下文学习能力方面的潜力。与现有方法不同，我们的工作利用现有的全模态数据的价值，提供了解决挑战的新视角。",
    "tldr": "本文提出了一种检索增强的上下文学习框架，旨在解决多模态学习中缺失模态和数据稀缺问题。",
    "en_tdlr": "This paper introduces a retrieval-augmented in-context learning framework to address the challenge of missing modalities and data scarcity in multimodal learning."
}