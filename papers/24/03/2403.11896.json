{
    "title": "Investigating Markers and Drivers of Gender Bias in Machine Translations",
    "abstract": "arXiv:2403.11896v1 Announce Type: new  Abstract: Implicit gender bias in Large Language Models (LLMs) is a well-documented problem, and implications of gender introduced into automatic translations can perpetuate real-world biases. However, some LLMs use heuristics or post-processing to mask such bias, making investigation difficult. Here, we examine bias in LLMss via back-translation, using the DeepL translation API to investigate the bias evinced when repeatedly translating a set of 56 Software Engineering tasks used in a previous study. Each statement starts with 'she', and is translated first into a 'genderless' intermediate language then back into English; we then examine pronoun- choice in the back-translated texts. We expand prior research in the following ways: (1) by comparing results across five intermediate languages, namely Finnish, Indonesian, Estonian, Turkish and Hungarian; (2) by proposing a novel metric for assessing the variation in gender implied in the repeated tran",
    "link": "https://arxiv.org/abs/2403.11896",
    "context": "Title: Investigating Markers and Drivers of Gender Bias in Machine Translations\nAbstract: arXiv:2403.11896v1 Announce Type: new  Abstract: Implicit gender bias in Large Language Models (LLMs) is a well-documented problem, and implications of gender introduced into automatic translations can perpetuate real-world biases. However, some LLMs use heuristics or post-processing to mask such bias, making investigation difficult. Here, we examine bias in LLMss via back-translation, using the DeepL translation API to investigate the bias evinced when repeatedly translating a set of 56 Software Engineering tasks used in a previous study. Each statement starts with 'she', and is translated first into a 'genderless' intermediate language then back into English; we then examine pronoun- choice in the back-translated texts. We expand prior research in the following ways: (1) by comparing results across five intermediate languages, namely Finnish, Indonesian, Estonian, Turkish and Hungarian; (2) by proposing a novel metric for assessing the variation in gender implied in the repeated tran",
    "path": "papers/24/03/2403.11896.json",
    "total_tokens": 898,
    "translated_title": "调查机器翻译中性别偏见的标记和驱动因素",
    "translated_abstract": "大语言模型（LLMs）中的隐含性别偏见是一个有充分文献支持的问题，通过自动翻译引入性别可能会延续现实世界的偏见。有些LLMs使用启发式或后处理来掩盖这种偏见，使调查变得困难。本文通过反向翻译来研究LLMs中的偏见，使用DeepL翻译API来调查重复翻译一组56个先前研究中使用的软件工程任务时所展现的偏见。每个陈述以 'she' 开始，并首先翻译为一个 '无性别' 中间语言，然后再翻译回英语；然后我们检查了反向翻译文本中的代词选择。我们通过以下方式扩展了先前的研究：（1）比较了五种中间语言（芬兰语、印度尼西亚语、爱沙尼亚语、土耳其语和匈牙利语）的结果；（2）提出了用于评估重复翻译中所暗示的性别变化的新度量标准。",
    "tldr": "通过使用反向翻译技术，比较五种中间语言的结果，并提出新的指标评估翻译中隐含的性别偏见变化。",
    "en_tdlr": "Comparing results across five intermediate languages using back-translation, and proposing a novel metric to assess variation in gender implied in translations."
}