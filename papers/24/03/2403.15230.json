{
    "title": "An Exploratory Investigation into Code License Infringements in Large Language Model Training Datasets",
    "abstract": "arXiv:2403.15230v1 Announce Type: cross  Abstract: Does the training of large language models potentially infringe upon code licenses? Furthermore, are there any datasets available that can be safely used for training these models without violating such licenses? In our study, we assess the current trends in the field and the importance of incorporating code into the training of large language models. Additionally, we examine publicly available datasets to see whether these models can be trained on them without the risk of legal issues in the future. To accomplish this, we compiled a list of 53 large language models trained on file-level code. We then extracted their datasets and analyzed how much they overlap with a dataset we created, consisting exclusively of strong copyleft code.   Our analysis revealed that every dataset we examined contained license inconsistencies, despite being selected based on their associated repository licenses. We analyzed a total of 514 million code files",
    "link": "https://arxiv.org/abs/2403.15230",
    "context": "Title: An Exploratory Investigation into Code License Infringements in Large Language Model Training Datasets\nAbstract: arXiv:2403.15230v1 Announce Type: cross  Abstract: Does the training of large language models potentially infringe upon code licenses? Furthermore, are there any datasets available that can be safely used for training these models without violating such licenses? In our study, we assess the current trends in the field and the importance of incorporating code into the training of large language models. Additionally, we examine publicly available datasets to see whether these models can be trained on them without the risk of legal issues in the future. To accomplish this, we compiled a list of 53 large language models trained on file-level code. We then extracted their datasets and analyzed how much they overlap with a dataset we created, consisting exclusively of strong copyleft code.   Our analysis revealed that every dataset we examined contained license inconsistencies, despite being selected based on their associated repository licenses. We analyzed a total of 514 million code files",
    "path": "papers/24/03/2403.15230.json",
    "total_tokens": 826,
    "translated_title": "在大型语言模型训练数据集中对代码许可侵权的初步调查",
    "translated_abstract": "arXiv:2403.15230v1 公告类型: 跨领域 摘要: 训练大型语言模型是否潜在侵犯代码许可？此外，是否有可用于训练这些模型而不违反这些许可的数据集？在我们的研究中，我们评估了该领域的当前趋势以及将代码纳入大型语言模型训练的重要性。此外，我们检查了公开可用的数据集，以查看是否可以在这些数据集上训练这些模型而不会面临未来的法律问题。为了实现这一目标，我们编制了一个包含53个基于文件级代码训练的大型语言模型的列表。然后我们提取了它们的数据集，并分析了它们与我们创建的数据集重叠的程度，后者仅包含强制共享代码。",
    "tldr": "该研究调查了大型语言模型训练数据集中的代码许可侵权问题，发现每个数据集都存在许可不一致性，尽管它们是基于相关代码仓库许可证来选择的。"
}