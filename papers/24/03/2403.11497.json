{
    "title": "Do CLIPs Always Generalize Better than ImageNet Models?",
    "abstract": "arXiv:2403.11497v1 Announce Type: cross  Abstract: Large vision language models, such as CLIPs, have revolutionized modern machine learning. CLIPs have demonstrated great generalizability under distribution shifts, supported by an increasing body of literature. However, the evaluation datasets for CLIPs are variations primarily designed for ImageNet benchmarks, which may not fully reflect the extent to which CLIPs, e.g., pre-trained on LAION, robust to spurious correlations. To bridge the gap, we collect a real-world dataset called CounterAnimal that contains realistic spurious features found in animal photos. CounterAnimal consists of a) the common group: comprising animals on common backgrounds, and b) the counter group: including animals on unusual backgrounds. The performance drops from the common to counter groups quantify the reliance of models on spurious features (i.e., backgrounds) to predict the animals. We find that CLIPs trained on either LAION or the OpenAI data exhibit no",
    "link": "https://arxiv.org/abs/2403.11497",
    "context": "Title: Do CLIPs Always Generalize Better than ImageNet Models?\nAbstract: arXiv:2403.11497v1 Announce Type: cross  Abstract: Large vision language models, such as CLIPs, have revolutionized modern machine learning. CLIPs have demonstrated great generalizability under distribution shifts, supported by an increasing body of literature. However, the evaluation datasets for CLIPs are variations primarily designed for ImageNet benchmarks, which may not fully reflect the extent to which CLIPs, e.g., pre-trained on LAION, robust to spurious correlations. To bridge the gap, we collect a real-world dataset called CounterAnimal that contains realistic spurious features found in animal photos. CounterAnimal consists of a) the common group: comprising animals on common backgrounds, and b) the counter group: including animals on unusual backgrounds. The performance drops from the common to counter groups quantify the reliance of models on spurious features (i.e., backgrounds) to predict the animals. We find that CLIPs trained on either LAION or the OpenAI data exhibit no",
    "path": "papers/24/03/2403.11497.json",
    "total_tokens": 851,
    "translated_title": "CLIP总是比ImageNet模型泛化更好吗？",
    "translated_abstract": "大型视觉语言模型，例如CLIP，已经彻底改变了现代机器学习。CLIP展示了在分布转移下的良好泛化能力，得到了越来越多的文献支持。然而，CLIP的评估数据集主要是为ImageNet基准而设计的变种，可能不能完全反映CLIP在LAION等上进行预训练时对虚假相关性的稳健性。为了弥补这一差距，我们收集了一个真实世界数据集，名为CounterAnimal，其中包含动物照片中发现的现实虚假特征。CounterAnimal包括a）常见组：包括常见背景的动物，并且 b) 对照组：包括在不寻常背景下的动物。从常见组到对照组的性能下降量化了模型对虚假特征（即背景）预测动物的依赖性。我们发现，在LAION或OpenAI数据上进行训练的CLIP即没有",
    "tldr": "CLIP模型在面对分布转移时表现出良好的泛化能力，作者设计了CounterAnimal数据集来探究模型对虚假特征的依赖性。",
    "en_tdlr": "CLIP models demonstrate good generalization ability under distribution shifts, and the authors introduce the CounterAnimal dataset to investigate the models' reliance on spurious features."
}