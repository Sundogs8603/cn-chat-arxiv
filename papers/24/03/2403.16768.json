{
    "title": "DeepKnowledge: Generalisation-Driven Deep Learning Testing",
    "abstract": "arXiv:2403.16768v1 Announce Type: cross  Abstract: Despite their unprecedented success, DNNs are notoriously fragile to small shifts in data distribution, demanding effective testing techniques that can assess their dependability. Despite recent advances in DNN testing, there is a lack of systematic testing approaches that assess the DNN's capability to generalise and operate comparably beyond data in their training distribution. We address this gap with DeepKnowledge, a systematic testing methodology for DNN-based systems founded on the theory of knowledge generalisation, which aims to enhance DNN robustness and reduce the residual risk of 'black box' models. Conforming to this theory, DeepKnowledge posits that core computational DNN units, termed Transfer Knowledge neurons, can generalise under domain shift. DeepKnowledge provides an objective confidence measurement on testing activities of DNN given data distribution shifts and uses this information to instrument a generalisation-in",
    "link": "https://arxiv.org/abs/2403.16768",
    "context": "Title: DeepKnowledge: Generalisation-Driven Deep Learning Testing\nAbstract: arXiv:2403.16768v1 Announce Type: cross  Abstract: Despite their unprecedented success, DNNs are notoriously fragile to small shifts in data distribution, demanding effective testing techniques that can assess their dependability. Despite recent advances in DNN testing, there is a lack of systematic testing approaches that assess the DNN's capability to generalise and operate comparably beyond data in their training distribution. We address this gap with DeepKnowledge, a systematic testing methodology for DNN-based systems founded on the theory of knowledge generalisation, which aims to enhance DNN robustness and reduce the residual risk of 'black box' models. Conforming to this theory, DeepKnowledge posits that core computational DNN units, termed Transfer Knowledge neurons, can generalise under domain shift. DeepKnowledge provides an objective confidence measurement on testing activities of DNN given data distribution shifts and uses this information to instrument a generalisation-in",
    "path": "papers/24/03/2403.16768.json",
    "total_tokens": 840,
    "translated_title": "DeepKnowledge: 基于泛化驱动的深度学习测试",
    "translated_abstract": "尽管深度神经网络取得了前所未有的成功，但它们对数据分布的微小变化极为脆弱，这要求有效的测试技术来评估它们的可靠性。尽管近年来在深度神经网络测试方面取得了进展，但缺乏系统化的测试方法来评估深度神经网络在训练分布之外的数据上泛化和运行的能力。我们通过DeepKnowledge来解决这一问题，这是一种基于知识泛化理论的深度神经网络系统测试方法，旨在增强深度神经网络的稳健性，并减少“黑匣子”模型的剩余风险。根据这一理论，DeepKnowledge认为核心计算DNN单元，称为转移知识神经元，在域变化下可以泛化。DeepKnowledge提供了一种客观的信心度量，用于评估给定数据分布变化的DNN测试活动，并利用这些信息来推动泛化。",
    "tldr": "DeepKnowledge提出了一种基于知识泛化理论的深度学习系统测试方法，旨在提高DNN的稳健性并减少黑匣子模型的风险。",
    "en_tdlr": "DeepKnowledge proposes a deep learning system testing method based on the theory of knowledge generalization, aiming to improve DNN robustness and reduce the risk of black box models."
}