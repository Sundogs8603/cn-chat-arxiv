{
    "title": "DESIRE-ME: Domain-Enhanced Supervised Information REtrieval using Mixture-of-Experts",
    "abstract": "arXiv:2403.13468v1 Announce Type: new  Abstract: Open-domain question answering requires retrieval systems able to cope with the diverse and varied nature of questions, providing accurate answers across a broad spectrum of query types and topics. To deal with such topic heterogeneity through a unique model, we propose DESIRE-ME, a neural information retrieval model that leverages the Mixture-of-Experts framework to combine multiple specialized neural models. We rely on Wikipedia data to train an effective neural gating mechanism that classifies the incoming query and that weighs the predictions of the different domain-specific experts correspondingly. This allows DESIRE-ME to specialize adaptively in multiple domains. Through extensive experiments on publicly available datasets, we show that our proposal can effectively generalize domain-enhanced neural models. DESIRE-ME excels in handling open-domain questions adaptively, boosting by up to 12% in NDCG@10 and 22% in P@1, the underlying",
    "link": "https://arxiv.org/abs/2403.13468",
    "context": "Title: DESIRE-ME: Domain-Enhanced Supervised Information REtrieval using Mixture-of-Experts\nAbstract: arXiv:2403.13468v1 Announce Type: new  Abstract: Open-domain question answering requires retrieval systems able to cope with the diverse and varied nature of questions, providing accurate answers across a broad spectrum of query types and topics. To deal with such topic heterogeneity through a unique model, we propose DESIRE-ME, a neural information retrieval model that leverages the Mixture-of-Experts framework to combine multiple specialized neural models. We rely on Wikipedia data to train an effective neural gating mechanism that classifies the incoming query and that weighs the predictions of the different domain-specific experts correspondingly. This allows DESIRE-ME to specialize adaptively in multiple domains. Through extensive experiments on publicly available datasets, we show that our proposal can effectively generalize domain-enhanced neural models. DESIRE-ME excels in handling open-domain questions adaptively, boosting by up to 12% in NDCG@10 and 22% in P@1, the underlying",
    "path": "papers/24/03/2403.13468.json",
    "total_tokens": 935,
    "translated_title": "DESIRE-ME：使用专家混合模型的增强领域监督信息检索",
    "translated_abstract": "开放领域问题回答需要检索系统能够处理多样化和变化多样的问题，提供准确的答案涵盖广泛的查询类型和主题。为了通过一个独特的模型处理这种主题异质性，我们提出了DESIRE-ME，这是一个神经信息检索模型，利用专家混合框架结合多个专业神经模型。我们依赖于维基百科数据来训练一个有效的神经门控机制，对传入查询进行分类，并相应地加权不同领域专家的预测。这使得DESIRE-ME能够自适应地在多个领域中专门化。通过对公开可用数据集的大量实验，我们展示了我们的提议能够有效地概括领域增强的神经模型。DESIRE-ME在自适应处理开放领域问题方面表现出色，能将NDCG@10提高高达12%，P@1提高高达22%。",
    "tldr": "DESIRE-ME是一个神经信息检索模型，利用专家混合框架结合多个专业神经模型，通过训练神经门控机制对不同领域的专家预测进行加权，能够自适应地在多个领域中专门化，并在处理开放领域问题中表现出色。",
    "en_tdlr": "DESIRE-ME is a neural information retrieval model that leverages the Mixture-of-Experts framework to combine multiple specialized neural models. It trains an effective neural gating mechanism based on Wikipedia data to classify and weigh domain-specific expert predictions, allowing adaptive specialization across multiple domains, excelling in handling open-domain questions."
}