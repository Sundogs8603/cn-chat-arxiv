{
    "title": "Metaphor Understanding Challenge Dataset for LLMs",
    "abstract": "arXiv:2403.11810v1 Announce Type: new  Abstract: Metaphors in natural language are a reflection of fundamental cognitive processes such as analogical reasoning and categorisation, and are deeply rooted in everyday communication. Metaphor understanding is therefore an essential task for large language models (LLMs). We release the Metaphor Understanding Challenge Dataset (MUNCH), designed to evaluate the metaphor understanding capabilities of LLMs. The dataset provides over 10k paraphrases for sentences containing metaphor use, as well as 1.5k instances containing inapt paraphrases. The inapt paraphrases were carefully selected to serve as control to determine whether the model indeed performs full metaphor interpretation or rather resorts to lexical similarity. All apt and inapt paraphrases were manually annotated. The metaphorical sentences cover natural metaphor uses across 4 genres (academic, news, fiction, and conversation), and they exhibit different levels of novelty. Experiments",
    "link": "https://arxiv.org/abs/2403.11810",
    "context": "Title: Metaphor Understanding Challenge Dataset for LLMs\nAbstract: arXiv:2403.11810v1 Announce Type: new  Abstract: Metaphors in natural language are a reflection of fundamental cognitive processes such as analogical reasoning and categorisation, and are deeply rooted in everyday communication. Metaphor understanding is therefore an essential task for large language models (LLMs). We release the Metaphor Understanding Challenge Dataset (MUNCH), designed to evaluate the metaphor understanding capabilities of LLMs. The dataset provides over 10k paraphrases for sentences containing metaphor use, as well as 1.5k instances containing inapt paraphrases. The inapt paraphrases were carefully selected to serve as control to determine whether the model indeed performs full metaphor interpretation or rather resorts to lexical similarity. All apt and inapt paraphrases were manually annotated. The metaphorical sentences cover natural metaphor uses across 4 genres (academic, news, fiction, and conversation), and they exhibit different levels of novelty. Experiments",
    "path": "papers/24/03/2403.11810.json",
    "total_tokens": 934,
    "translated_title": "大语言模型的隐喻理解挑战数据集",
    "translated_abstract": "自然语言中的隐喻是基本认知过程（如类比推理和分类）的反映，并深深根植于日常交流。因此，隐喻理解对于大语言模型（LLMs）来说是一项重要任务。我们发布了隐喻理解挑战数据集（MUNCH），旨在评估LLMs的隐喻理解能力。该数据集提供了包含隐喻用法的句子的超过10k个释义，以及包含1.5k个不恰当释义的实例。这些不恰当释义经过精心挑选，旨在作为控制来确定模型是否确实进行全面的隐喻解释，还是仅仅依赖词汇相似性。所有恰当和不恰当的释义都经过手动注释。这些隐喻句涵盖了4种流派（学术、新闻、小说和对话）中的自然隐喻用法，并展示不同程度的新颖性。",
    "tldr": "该研究发布了一个旨在评估大语言模型（LLMs）隐喻理解能力的数据集，包含超过10k个隐喻句的释义以及1.5k个不恰当释义实例，为研究人员提供了有效的工具来检验模型是否真正实现全面隐喻解释而非仅依赖词汇相似性。",
    "en_tdlr": "The study introduces a dataset designed to evaluate the metaphor understanding capabilities of large language models (LLMs), providing over 10k paraphrases for sentences containing metaphors and 1.5k instances of inappropriate paraphrases, offering researchers a tool to examine if models truly achieve full metaphor interpretation rather than relying on lexical similarity."
}