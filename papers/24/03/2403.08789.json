{
    "title": "Bridging Human Concepts and Computer Vision for Explainable Face Verification",
    "abstract": "arXiv:2403.08789v1 Announce Type: cross  Abstract: With Artificial Intelligence (AI) influencing the decision-making process of sensitive applications such as Face Verification, it is fundamental to ensure the transparency, fairness, and accountability of decisions. Although Explainable Artificial Intelligence (XAI) techniques exist to clarify AI decisions, it is equally important to provide interpretability of these decisions to humans. In this paper, we present an approach to combine computer and human vision to increase the explanation's interpretability of a face verification algorithm. In particular, we are inspired by the human perceptual process to understand how machines perceive face's human-semantic areas during face comparison tasks. We use Mediapipe, which provides a segmentation technique that identifies distinct human-semantic facial regions, enabling the machine's perception analysis. Additionally, we adapted two model-agnostic algorithms to provide human-interpretable i",
    "link": "https://arxiv.org/abs/2403.08789",
    "context": "Title: Bridging Human Concepts and Computer Vision for Explainable Face Verification\nAbstract: arXiv:2403.08789v1 Announce Type: cross  Abstract: With Artificial Intelligence (AI) influencing the decision-making process of sensitive applications such as Face Verification, it is fundamental to ensure the transparency, fairness, and accountability of decisions. Although Explainable Artificial Intelligence (XAI) techniques exist to clarify AI decisions, it is equally important to provide interpretability of these decisions to humans. In this paper, we present an approach to combine computer and human vision to increase the explanation's interpretability of a face verification algorithm. In particular, we are inspired by the human perceptual process to understand how machines perceive face's human-semantic areas during face comparison tasks. We use Mediapipe, which provides a segmentation technique that identifies distinct human-semantic facial regions, enabling the machine's perception analysis. Additionally, we adapted two model-agnostic algorithms to provide human-interpretable i",
    "path": "papers/24/03/2403.08789.json",
    "total_tokens": 784,
    "translated_title": "将人类概念与计算机视觉相结合，实现可解释的人脸验证",
    "translated_abstract": "人工智能(AI)影响了敏感应用程序(如人脸验证)的决策过程，因此确保决策的透明性、公平性和问责制非常重要。尽管存在可解释的人工智能(XAI)技术用于澄清AI决策，但同样重要的是为人类提供这些决策的可解释性。本文提出了一种方法，结合计算机和人类视觉，增加了人脸验证算法解释的可解释性。具体而言，我们受到人类感知过程的启发，以了解机器在人脸比较任务期间如何感知人类语义区域。我们使用Mediapipe提供的分割技术，可以识别出不同的人类语义面部区域，从而实现机器的感知分析。此外，我们还调整了两种模型不可知算法，以提供人类可解释性",
    "tldr": "本文通过结合计算机和人类视觉的方法，提高了人脸验证算法解释的可解释性"
}