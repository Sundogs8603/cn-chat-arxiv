{
    "title": "Semantic Map-based Generation of Navigation Instructions",
    "abstract": "arXiv:2403.19603v1 Announce Type: cross  Abstract: We are interested in the generation of navigation instructions, either in their own right or as training material for robotic navigation task. In this paper, we propose a new approach to navigation instruction generation by framing the problem as an image captioning task using semantic maps as visual input. Conventional approaches employ a sequence of panorama images to generate navigation instructions. Semantic maps abstract away from visual details and fuse the information in multiple panorama images into a single top-down representation, thereby reducing computational complexity to process the input. We present a benchmark dataset for instruction generation using semantic maps, propose an initial model and ask human subjects to manually assess the quality of generated instructions. Our initial investigations show promise in using semantic maps for instruction generation instead of a sequence of panorama images, but there is vast sco",
    "link": "https://arxiv.org/abs/2403.19603",
    "context": "Title: Semantic Map-based Generation of Navigation Instructions\nAbstract: arXiv:2403.19603v1 Announce Type: cross  Abstract: We are interested in the generation of navigation instructions, either in their own right or as training material for robotic navigation task. In this paper, we propose a new approach to navigation instruction generation by framing the problem as an image captioning task using semantic maps as visual input. Conventional approaches employ a sequence of panorama images to generate navigation instructions. Semantic maps abstract away from visual details and fuse the information in multiple panorama images into a single top-down representation, thereby reducing computational complexity to process the input. We present a benchmark dataset for instruction generation using semantic maps, propose an initial model and ask human subjects to manually assess the quality of generated instructions. Our initial investigations show promise in using semantic maps for instruction generation instead of a sequence of panorama images, but there is vast sco",
    "path": "papers/24/03/2403.19603.json",
    "total_tokens": 789,
    "translated_title": "基于语义地图的导航说明生成",
    "translated_abstract": "我们对导航说明的生成很感兴趣，无论是作为自身存在的文本还是作为机器人导航任务的训练材料。在本文中，我们提出了一种新的导航说明生成方法，将问题构建为使用语义地图作为视觉输入的图像字幕任务。传统方法采用一系列全景图像来生成导航说明。语义地图将视觉细节抽象出来，将多个全景图像中的信息融合到单个自上而下的表示中，从而降低了处理输入的计算复杂性。我们提供了一个使用语义地图生成说明的基准数据集，提出了一个初始模型，并请人工主观评估生成说明的质量。我们的初步调查显示，使用语义地图生成说明而不是一系列全景图像具有潜力，但研究范围仍然广阔。",
    "tldr": "通过使用语义地图作为视觉输入，我们提出了一种新的导航说明生成方法，将问题构建为图像字幕任务，有望降低生成指令的计算复杂性。",
    "en_tdlr": "We propose a new approach to navigation instruction generation by framing the problem as an image captioning task using semantic maps as visual input, which shows promise in reducing the computational complexity of generating instructions."
}