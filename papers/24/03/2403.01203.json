{
    "title": "Pseudo-Label Calibration Semi-supervised Multi-Modal Entity Alignment",
    "abstract": "arXiv:2403.01203v1 Announce Type: cross  Abstract: Multi-modal entity alignment (MMEA) aims to identify equivalent entities between two multi-modal knowledge graphs for integration. Unfortunately, prior arts have attempted to improve the interaction and fusion of multi-modal information, which have overlooked the influence of modal-specific noise and the usage of labeled and unlabeled data in semi-supervised settings. In this work, we introduce a Pseudo-label Calibration Multi-modal Entity Alignment (PCMEA) in a semi-supervised way. Specifically, in order to generate holistic entity representations, we first devise various embedding modules and attention mechanisms to extract visual, structural, relational, and attribute features. Different from the prior direct fusion methods, we next propose to exploit mutual information maximization to filter the modal-specific noise and to augment modal-invariant commonality. Then, we combine pseudo-label calibration with momentum-based contrastive",
    "link": "https://arxiv.org/abs/2403.01203",
    "context": "Title: Pseudo-Label Calibration Semi-supervised Multi-Modal Entity Alignment\nAbstract: arXiv:2403.01203v1 Announce Type: cross  Abstract: Multi-modal entity alignment (MMEA) aims to identify equivalent entities between two multi-modal knowledge graphs for integration. Unfortunately, prior arts have attempted to improve the interaction and fusion of multi-modal information, which have overlooked the influence of modal-specific noise and the usage of labeled and unlabeled data in semi-supervised settings. In this work, we introduce a Pseudo-label Calibration Multi-modal Entity Alignment (PCMEA) in a semi-supervised way. Specifically, in order to generate holistic entity representations, we first devise various embedding modules and attention mechanisms to extract visual, structural, relational, and attribute features. Different from the prior direct fusion methods, we next propose to exploit mutual information maximization to filter the modal-specific noise and to augment modal-invariant commonality. Then, we combine pseudo-label calibration with momentum-based contrastive",
    "path": "papers/24/03/2403.01203.json",
    "total_tokens": 828,
    "translated_title": "伪标签校准半监督多模态实体对齐",
    "translated_abstract": "多模态实体对齐(MMEA)旨在识别两个多模态知识图之间的等价实体，以进行整合。不幸的是，之前的研究试图改进多模态信息的交互和融合，却忽视了模态特定噪音在半监督设置中标记和未标记数据的影响。在这项工作中，我们介绍了一种半监督的伪标签校准多模态实体对齐(PCMEA)方法。具体来说，为了生成全面的实体表示，我们首先设计了各种嵌入模块和注意机制来提取视觉、结构、关系和属性特征。接着，我们提出利用互信息最大化来过滤模态特定噪音并增强模态不变性共性。然后，我们将伪标签校准与基于动量的对比融合方法结合起来。",
    "tldr": "本研究提出了一种伪标签校准的半监督多模态实体对齐方法，通过引入互信息最大化来过滤模态特定噪音，增强模态不变性共性。",
    "en_tdlr": "This work presents a pseudo-label calibration semi-supervised multi-modal entity alignment method that filters modality-specific noise and enhances modal-invariant commonality by introducing mutual information maximization."
}