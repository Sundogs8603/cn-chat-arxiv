{
    "title": "Understanding and Mitigating Human-Labelling Errors in Supervised Contrastive Learning",
    "abstract": "arXiv:2403.06289v1 Announce Type: cross  Abstract: Human-annotated vision datasets inevitably contain a fraction of human mislabelled examples. While the detrimental effects of such mislabelling on supervised learning are well-researched, their influence on Supervised Contrastive Learning (SCL) remains largely unexplored. In this paper, we show that human-labelling errors not only differ significantly from synthetic label errors, but also pose unique challenges in SCL, different to those in traditional supervised learning methods. Specifically, our results indicate they adversely impact the learning process in the ~99% of cases when they occur as false positive samples. Existing noise-mitigating methods primarily focus on synthetic label errors and tackle the unrealistic setting of very high synthetic noise rates (40-80%), but they often underperform on common image datasets due to overfitting. To address this issue, we introduce a novel SCL objective with robustness to human-labelling",
    "link": "https://arxiv.org/abs/2403.06289",
    "context": "Title: Understanding and Mitigating Human-Labelling Errors in Supervised Contrastive Learning\nAbstract: arXiv:2403.06289v1 Announce Type: cross  Abstract: Human-annotated vision datasets inevitably contain a fraction of human mislabelled examples. While the detrimental effects of such mislabelling on supervised learning are well-researched, their influence on Supervised Contrastive Learning (SCL) remains largely unexplored. In this paper, we show that human-labelling errors not only differ significantly from synthetic label errors, but also pose unique challenges in SCL, different to those in traditional supervised learning methods. Specifically, our results indicate they adversely impact the learning process in the ~99% of cases when they occur as false positive samples. Existing noise-mitigating methods primarily focus on synthetic label errors and tackle the unrealistic setting of very high synthetic noise rates (40-80%), but they often underperform on common image datasets due to overfitting. To address this issue, we introduce a novel SCL objective with robustness to human-labelling",
    "path": "papers/24/03/2403.06289.json",
    "total_tokens": 969,
    "translated_title": "理解和减轻监督对比学习中的人工标注误差",
    "translated_abstract": "通过arXiv:2403.06289v1公开的交叉类型的文摘可以得知，人工标注的视觉数据集中不可避免地包含一部分人工标注错误的示例。尽管这类标注错误对于监督学习的负面影响已经得到深入研究，但它们对监督对比学习（SCL）的影响仍然是相对未知的。本文表明，人工标注错误不仅与合成标签错误显著不同，而且在SCL中构成独特挑战，与传统监督学习方法中的挑战有所不同。具体而言，我们的研究结果表明，当它们作为误报样本出现时，它们会对学习过程造成大约99%的负面影响。已有的噪声缓解方法主要侧重于合成标签错误，并处理非常高合成噪声率（40-80%）的不切实际设置，但由于过度拟合，它们在普通图像数据集上的表现往往较差。为了解决这个问题，我们引入了一种新颖的对抗人工标注鲁棒性的SCL目标。",
    "tldr": "本文揭示了人工标注误差不仅与合成标签错误有显著不同，而且在监督对比学习中构成了独特挑战，提出了一种新颖的对抗人工标注误差的SCL目标。",
    "en_tdlr": "This paper reveals that human-labelling errors not only differ significantly from synthetic label errors, but also pose unique challenges in Supervised Contrastive Learning, introducing a novel objective for addressing human-labelling errors robustly."
}