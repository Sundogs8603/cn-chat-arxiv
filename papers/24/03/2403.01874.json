{
    "title": "A Survey on Evaluation of Out-of-Distribution Generalization",
    "abstract": "arXiv:2403.01874v1 Announce Type: new  Abstract: Machine learning models, while progressively advanced, rely heavily on the IID assumption, which is often unfulfilled in practice due to inevitable distribution shifts. This renders them susceptible and untrustworthy for deployment in risk-sensitive applications. Such a significant problem has consequently spawned various branches of works dedicated to developing algorithms capable of Out-of-Distribution (OOD) generalization. Despite these efforts, much less attention has been paid to the evaluation of OOD generalization, which is also a complex and fundamental problem. Its goal is not only to assess whether a model's OOD generalization capability is strong or not, but also to evaluate where a model generalizes well or poorly. This entails characterizing the types of distribution shifts that a model can effectively address, and identifying the safe and risky input regions given a model. This paper serves as the first effort to conduct a ",
    "link": "https://arxiv.org/abs/2403.01874",
    "context": "Title: A Survey on Evaluation of Out-of-Distribution Generalization\nAbstract: arXiv:2403.01874v1 Announce Type: new  Abstract: Machine learning models, while progressively advanced, rely heavily on the IID assumption, which is often unfulfilled in practice due to inevitable distribution shifts. This renders them susceptible and untrustworthy for deployment in risk-sensitive applications. Such a significant problem has consequently spawned various branches of works dedicated to developing algorithms capable of Out-of-Distribution (OOD) generalization. Despite these efforts, much less attention has been paid to the evaluation of OOD generalization, which is also a complex and fundamental problem. Its goal is not only to assess whether a model's OOD generalization capability is strong or not, but also to evaluate where a model generalizes well or poorly. This entails characterizing the types of distribution shifts that a model can effectively address, and identifying the safe and risky input regions given a model. This paper serves as the first effort to conduct a ",
    "path": "papers/24/03/2403.01874.json",
    "total_tokens": 821,
    "translated_title": "对外分布泛化评估的调查",
    "translated_abstract": "机器学习模型虽然越来越先进，但严重依赖IID假设，而由于不可避免的分布转换，在实践中往往无法满足此假设。这使得它们在风险敏感应用的部署中容易受到影响并且不可信。这种重要问题因此衍生出各种致力于开发能够进行外部分布（OOD）泛化的算法的分支。尽管有这些努力，但对OOD泛化的评估却受到的关注较少，这也是一个复杂且基本的问题。其目标不仅在于评估模型的OOD泛化能力是否强大，还要评估模型泛化良好或不佳之处。这涉及描述模型能够有效解决的分布转换类型，并确定给定模型的安全和风险输入区域。这篇论文是首次努力进行的",
    "tldr": "该论文是针对外部分布泛化评估进行的首次努力，重点在于评估模型的OOD泛化能力以及泛化的表现好坏。",
    "en_tdlr": "This paper is the first effort to address the evaluation of Out-of-Distribution generalization, focusing on assessing the model's OOD generalization capability and performance."
}