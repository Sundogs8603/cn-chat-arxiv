{
    "title": "Learning User Embeddings from Human Gaze for Personalised Saliency Prediction",
    "abstract": "arXiv:2403.13653v2 Announce Type: replace-cross  Abstract: Reusable embeddings of user behaviour have shown significant performance improvements for the personalised saliency prediction task. However, prior works require explicit user characteristics and preferences as input, which are often difficult to obtain. We present a novel method to extract user embeddings from pairs of natural images and corresponding saliency maps generated from a small amount of user-specific eye tracking data. At the core of our method is a Siamese convolutional neural encoder that learns the user embeddings by contrasting the image and personal saliency map pairs of different users. Evaluations on two public saliency datasets show that the generated embeddings have high discriminative power, are effective at refining universal saliency maps to the individual users, and generalise well across users and images. Finally, based on our model's ability to encode individual user characteristics, our work points t",
    "link": "https://arxiv.org/abs/2403.13653",
    "context": "Title: Learning User Embeddings from Human Gaze for Personalised Saliency Prediction\nAbstract: arXiv:2403.13653v2 Announce Type: replace-cross  Abstract: Reusable embeddings of user behaviour have shown significant performance improvements for the personalised saliency prediction task. However, prior works require explicit user characteristics and preferences as input, which are often difficult to obtain. We present a novel method to extract user embeddings from pairs of natural images and corresponding saliency maps generated from a small amount of user-specific eye tracking data. At the core of our method is a Siamese convolutional neural encoder that learns the user embeddings by contrasting the image and personal saliency map pairs of different users. Evaluations on two public saliency datasets show that the generated embeddings have high discriminative power, are effective at refining universal saliency maps to the individual users, and generalise well across users and images. Finally, based on our model's ability to encode individual user characteristics, our work points t",
    "path": "papers/24/03/2403.13653.json",
    "total_tokens": 823,
    "translated_title": "从人类凝视中学习用户嵌入以个性化显著性预测",
    "translated_abstract": "用户行为的可重用嵌入已经显示出对个性化显著性预测任务具有显著的性能提升。然而，先前的工作需要明确的用户特征和偏好作为输入，这通常很难获得。我们提出了一种新颖的方法，从少量用户特定的眼动数据生成的自然图像和相应显著性地图对中提取用户嵌入。我们的方法的核心是一个Siamese卷积神经编码器，通过对比不同用户的图像和个人显著性地图对来学习用户嵌入。在两个公共显著性数据集上的评估表明，生成的嵌入具有很高的区分能力，有效地将通用显著性地图优化到个人用户层面，并且在用户和图像之间具有良好的泛化能力。最后，基于我们模型对个人用户特征的编码能力，我们的工作指出",
    "tldr": "通过眼动数据提取用户嵌入，可以有效个性化显著性预测任务，并且具有良好的泛化能力。",
    "en_tdlr": "Extracting user embeddings from eye tracking data can effectively personalize saliency prediction and generalize well across users and images."
}