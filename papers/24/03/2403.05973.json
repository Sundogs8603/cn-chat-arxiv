{
    "title": "Calibrating Large Language Models Using Their Generations Only",
    "abstract": "arXiv:2403.05973v1 Announce Type: cross  Abstract: As large language models (LLMs) are increasingly deployed in user-facing applications, building trust and maintaining safety by accurately quantifying a model's confidence in its prediction becomes even more important. However, finding effective ways to calibrate LLMs - especially when the only interface to the models is their generated text - remains a challenge. We propose APRICOT (auxiliary prediction of confidence targets): A method to set confidence targets and train an additional model that predicts an LLM's confidence based on its textual input and output alone. This approach has several advantages: It is conceptually simple, does not require access to the target model beyond its output, does not interfere with the language generation, and has a multitude of potential usages, for instance by verbalizing the predicted confidence or adjusting the given answer based on the confidence. We show how our approach performs competitively",
    "link": "https://arxiv.org/abs/2403.05973",
    "context": "Title: Calibrating Large Language Models Using Their Generations Only\nAbstract: arXiv:2403.05973v1 Announce Type: cross  Abstract: As large language models (LLMs) are increasingly deployed in user-facing applications, building trust and maintaining safety by accurately quantifying a model's confidence in its prediction becomes even more important. However, finding effective ways to calibrate LLMs - especially when the only interface to the models is their generated text - remains a challenge. We propose APRICOT (auxiliary prediction of confidence targets): A method to set confidence targets and train an additional model that predicts an LLM's confidence based on its textual input and output alone. This approach has several advantages: It is conceptually simple, does not require access to the target model beyond its output, does not interfere with the language generation, and has a multitude of potential usages, for instance by verbalizing the predicted confidence or adjusting the given answer based on the confidence. We show how our approach performs competitively",
    "path": "papers/24/03/2403.05973.json",
    "total_tokens": 822,
    "translated_title": "仅使用生成来校准大型语言模型",
    "translated_abstract": "随着大型语言模型（LLMs）越来越多地部署在面向用户的应用程序中，通过准确量化模型对其预测的信心来建立信任并保持安全性变得更加重要。然而，找到有效的方法来校准LLMs - 尤其是当与模型的唯一接口是它们生成的文本时 - 仍然是一个挑战。我们提出了APRICOT（辅助预测置信目标）：一种通过仅使用其文本输入和输出来设置置信目标并训练一个额外模型来预测LLM置信度的方法。这种方法有几个优点：概念上简单，不需要访问目标模型超出其输出，不干扰语言生成，并且有多种潜在用途，例如通过言语化预测的置信度或根据置信度调整给定的答案。我们展示了我们的方法如何具有竞争性能。",
    "tldr": "使用APRICOT方法，通过仅使用大型语言模型的文本输入和输出来设置置信目标并训练额外模型，从而实现大型语言模型的校准。",
    "en_tdlr": "With the APRICOT method, the calibration of large language models is achieved by setting confidence targets and training an additional model using only the textual input and output of the models."
}