{
    "title": "The Solution for the ICCV 2023 1st Scientific Figure Captioning Challenge",
    "abstract": "arXiv:2403.17342v1 Announce Type: cross  Abstract: In this paper, we propose a solution for improving the quality of captions generated for figures in papers. We adopt the approach of summarizing the textual content in the paper to generate image captions. Throughout our study, we encounter discrepancies in the OCR information provided in the official dataset. To rectify this, we employ the PaddleOCR toolkit to extract OCR information from all images. Moreover, we observe that certain textual content in the official paper pertains to images that are not relevant for captioning, thereby introducing noise during caption generation. To mitigate this issue, we leverage LLaMA to extract image-specific information by querying the textual content based on image mentions, effectively filtering out extraneous information. Additionally, we recognize a discrepancy between the primary use of maximum likelihood estimation during text generation and the evaluation metrics such as ROUGE employed to a",
    "link": "https://arxiv.org/abs/2403.17342",
    "context": "Title: The Solution for the ICCV 2023 1st Scientific Figure Captioning Challenge\nAbstract: arXiv:2403.17342v1 Announce Type: cross  Abstract: In this paper, we propose a solution for improving the quality of captions generated for figures in papers. We adopt the approach of summarizing the textual content in the paper to generate image captions. Throughout our study, we encounter discrepancies in the OCR information provided in the official dataset. To rectify this, we employ the PaddleOCR toolkit to extract OCR information from all images. Moreover, we observe that certain textual content in the official paper pertains to images that are not relevant for captioning, thereby introducing noise during caption generation. To mitigate this issue, we leverage LLaMA to extract image-specific information by querying the textual content based on image mentions, effectively filtering out extraneous information. Additionally, we recognize a discrepancy between the primary use of maximum likelihood estimation during text generation and the evaluation metrics such as ROUGE employed to a",
    "path": "papers/24/03/2403.17342.json",
    "total_tokens": 801,
    "translated_title": "ICCV 2023第一个科学图像字幕挑战的解决方案",
    "translated_abstract": "在本文中，我们提出了一种解决方案，用于改善论文中生成的图像标题的质量。我们采用总结论文中的文本内容生成图像标题的方法。在我们的研究过程中，我们发现官方数据集中提供的OCR信息存在差异。为了纠正这一问题，我们使用PaddleOCR工具包从所有图像中提取OCR信息。此外，我们观察到官方文件中的某些文本内容与不适合进行标题处理的图像相关，从而在生成标题过程中引入噪音。为了减轻这一问题，我们利用LLaMA根据图像提及查询文本内容来提取特定于图像的信息，有效地过滤掉多余信息。此外，我们认识到在文本生成过程中主要使用最大似然估计及用于评估的指标（如ROUGE）之间存在差异。",
    "tldr": "我们提出了一种根据论文内容生成图像标题的解决方案，并通过使用PaddleOCR和LLaMA工具包解决了OCR信息和信息过滤方面的问题。",
    "en_tdlr": "We propose a solution for generating image captions based on textual content in papers, addressing OCR information discrepancies and noise reduction using PaddleOCR and LLaMA."
}