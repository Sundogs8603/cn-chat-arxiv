{
    "title": "Let's Focus on Neuron: Neuron-Level Supervised Fine-tuning for Large Language Model",
    "abstract": "arXiv:2403.11621v1 Announce Type: new  Abstract: Large Language Models (LLMs) are composed of neurons that exhibit various behaviors and roles, which become increasingly diversified as models scale. Recent studies have revealed that not all neurons are active across different datasets, and this sparsity correlates positively with the task-specific ability, leading to advancements in model pruning and training efficiency. Traditional fine-tuning methods engage all parameters of LLMs, which is computationally expensive and may not be necessary. In contrast, Parameter-Efficient Fine-Tuning (PEFT) approaches aim to minimize the number of trainable parameters, yet they still operate at a relatively macro scale (e.g., layer-level). We introduce Neuron-Level Fine-Tuning (NeFT), a novel approach that refines the granularity of parameter training down to the individual neuron, enabling more precise and computationally efficient model updates. The experimental results show that NeFT not only exc",
    "link": "https://arxiv.org/abs/2403.11621",
    "context": "Title: Let's Focus on Neuron: Neuron-Level Supervised Fine-tuning for Large Language Model\nAbstract: arXiv:2403.11621v1 Announce Type: new  Abstract: Large Language Models (LLMs) are composed of neurons that exhibit various behaviors and roles, which become increasingly diversified as models scale. Recent studies have revealed that not all neurons are active across different datasets, and this sparsity correlates positively with the task-specific ability, leading to advancements in model pruning and training efficiency. Traditional fine-tuning methods engage all parameters of LLMs, which is computationally expensive and may not be necessary. In contrast, Parameter-Efficient Fine-Tuning (PEFT) approaches aim to minimize the number of trainable parameters, yet they still operate at a relatively macro scale (e.g., layer-level). We introduce Neuron-Level Fine-Tuning (NeFT), a novel approach that refines the granularity of parameter training down to the individual neuron, enabling more precise and computationally efficient model updates. The experimental results show that NeFT not only exc",
    "path": "papers/24/03/2403.11621.json",
    "total_tokens": 859,
    "translated_title": "让我们关注神经元：大型语言模型的神经元级监督微调",
    "translated_abstract": "大型语言模型（LLMs）由展示各种行为和角色的神经元组成，在模型扩展的同时表现出越来越多样化的特性。最近的研究揭示了并非所有神经元在不同数据集中都活跃，而这种稀疏性与任务特定能力呈正相关，从而推动了模型剪枝和训练效率的发展。传统的微调方法涉及LLMs的所有参数，这在计算上是昂贵的且可能并非必要的。相比之下，参数高效微调（PEFT）方法旨在最小化可训练参数的数量，但它们仍在相对宏观的尺度上操作（例如，层级）。我们引入了神经元级微调（NeFT），这是一种将参数训练的粒度细化到个体神经元的新方法，从而实现更精确和计算高效的模型更新。实验结果表明，NeFT不仅能在几乎相同精度下显著减少可训练参数，还能在模型更新方面 更有效。",
    "tldr": "NeFT是一种神经元级微调的新方法，可以精确和计算高效地更新大型语言模型。",
    "en_tdlr": "NeFT is a novel approach for neuron-level fine-tuning, which enables precise and computationally efficient model updates for large language models."
}