{
    "title": "LOCR: Location-Guided Transformer for Optical Character Recognition",
    "abstract": "arXiv:2403.02127v1 Announce Type: cross  Abstract: Academic documents are packed with texts, equations, tables, and figures, requiring comprehensive understanding for accurate Optical Character Recognition (OCR). While end-to-end OCR methods offer improved accuracy over layout-based approaches, they often grapple with significant repetition issues, especially with complex layouts in Out-Of-Domain (OOD) documents.To tackle this issue, we propose LOCR, a model that integrates location guiding into the transformer architecture during autoregression. We train the model on a dataset comprising over 77M text-location pairs from 125K academic document pages, including bounding boxes for words, tables and mathematical symbols. LOCR adeptly handles various formatting elements and generates content in Markdown language. It outperforms all existing methods in our test set constructed from arXiv, as measured by edit distance, BLEU, METEOR and F-measure.LOCR also reduces repetition frequency from 4",
    "link": "https://arxiv.org/abs/2403.02127",
    "context": "Title: LOCR: Location-Guided Transformer for Optical Character Recognition\nAbstract: arXiv:2403.02127v1 Announce Type: cross  Abstract: Academic documents are packed with texts, equations, tables, and figures, requiring comprehensive understanding for accurate Optical Character Recognition (OCR). While end-to-end OCR methods offer improved accuracy over layout-based approaches, they often grapple with significant repetition issues, especially with complex layouts in Out-Of-Domain (OOD) documents.To tackle this issue, we propose LOCR, a model that integrates location guiding into the transformer architecture during autoregression. We train the model on a dataset comprising over 77M text-location pairs from 125K academic document pages, including bounding boxes for words, tables and mathematical symbols. LOCR adeptly handles various formatting elements and generates content in Markdown language. It outperforms all existing methods in our test set constructed from arXiv, as measured by edit distance, BLEU, METEOR and F-measure.LOCR also reduces repetition frequency from 4",
    "path": "papers/24/03/2403.02127.json",
    "total_tokens": 858,
    "translated_title": "LOCR：面向光学字符识别的位置引导Transformer",
    "translated_abstract": "学术文档充斥着文本、方程式、表格和图形，需要全面理解才能准确进行光学字符识别（OCR）。尽管端到端OCR方法在准确性上优于基于布局的方法，但它们通常在处理重复性问题时遇到困难，特别是在“领域外”（OOD）文档中的复杂布局。为了解决这一问题，我们提出了LOCR，一种将位置引导整合到变压器架构中的模型。我们在一个包含来自125K个学术文档页面的超过7700万个文本-位置对的数据集上训练模型，包括单词、表格和数学符号的边界框。LOCR能熟练处理各种格式元素并以Markdown语言生成内容。在我们从arXiv构建的测试集中，衡量方式为编辑距离、BLEU、METEOR和F-measure，LOCR优于所有现有方法。LOCR还将重复频率从4",
    "tldr": "LOCR是一种面向光学字符识别的模型，通过在自回归过程中在transformer架构中集成位置引导，能够有效处理学术文档中的重复问题，并在测试集上表现出色。",
    "en_tdlr": "LOCR is a model for optical character recognition that integrates location guiding into the transformer architecture during autoregression, effectively tackling repetition issues in academic documents and outperforming existing methods on the test set."
}