{
    "title": "GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning",
    "abstract": "arXiv:2403.14410v1 Announce Type: cross  Abstract: Deep neural networks often exhibit sub-optimal performance under covariate and category shifts. Source-Free Domain Adaptation (SFDA) presents a promising solution to this dilemma, yet most SFDA approaches are restricted to closed-set scenarios. In this paper, we explore Source-Free Universal Domain Adaptation (SF-UniDA) aiming to accurately classify \"known\" data belonging to common categories and segregate them from target-private \"unknown\" data. We propose a novel Global and Local Clustering (GLC) technique, which comprises an adaptive one-vs-all global clustering algorithm to discern between target classes, complemented by a local k-NN clustering strategy to mitigate negative transfer. Despite the effectiveness, the inherent closed-set source architecture leads to uniform treatment of \"unknown\" data, impeding the identification of distinct \"unknown\" categories. To address this, we evolve GLC to GLC++, integrating a contrastive affini",
    "link": "https://arxiv.org/abs/2403.14410",
    "context": "Title: GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning\nAbstract: arXiv:2403.14410v1 Announce Type: cross  Abstract: Deep neural networks often exhibit sub-optimal performance under covariate and category shifts. Source-Free Domain Adaptation (SFDA) presents a promising solution to this dilemma, yet most SFDA approaches are restricted to closed-set scenarios. In this paper, we explore Source-Free Universal Domain Adaptation (SF-UniDA) aiming to accurately classify \"known\" data belonging to common categories and segregate them from target-private \"unknown\" data. We propose a novel Global and Local Clustering (GLC) technique, which comprises an adaptive one-vs-all global clustering algorithm to discern between target classes, complemented by a local k-NN clustering strategy to mitigate negative transfer. Despite the effectiveness, the inherent closed-set source architecture leads to uniform treatment of \"unknown\" data, impeding the identification of distinct \"unknown\" categories. To address this, we evolve GLC to GLC++, integrating a contrastive affini",
    "path": "papers/24/03/2403.14410.json",
    "total_tokens": 901,
    "translated_title": "GLC++: 全局局部聚类和对比关联学习的无源通用域自适应",
    "translated_abstract": "深度神经网络经常在协变量和类别转移下表现出次优性能。无源域自适应（SFDA）为这一困境提供了一个有希望的解决方案，然而大多数SFDA方法局限于封闭集场景。在本文中，我们探讨了旨在准确分类属于常见类别的“已知”数据并将其与目标专有“未知”数据隔离开来的无源通用域自适应（SF-UniDA）。我们提出了一种新颖的全球和局部聚类（GLC）技术，其中包括自适应的一对全局聚类算法来区分目标类别，辅以本地k-NN聚类策略以减轻负面转移。尽管有效，但固有的封闭源架构导致对“未知”数据的统一处理，阻碍了对不同“未知”类别的识别。为了解决这个问题，我们将GLC发展到GLC++，整合了对比亲和性。",
    "tldr": "该论文提出了GLC++方法，通过全局和局部聚类以及对比关联学习实现了无源通用域自适应，能够准确分类已知数据并将其从未知数据中分离。",
    "en_tdlr": "This paper introduces GLC++, a method that achieves source-free universal domain adaptation through global and local clustering, as well as contrastive affinity learning, enabling accurate classification of known data and segregation from unknown data."
}