{
    "title": "Removing Undesirable Concepts in Text-to-Image Generative Models with Learnable Prompts",
    "abstract": "arXiv:2403.12326v1 Announce Type: new  Abstract: Generative models have demonstrated remarkable potential in generating visually impressive content from textual descriptions. However, training these models on unfiltered internet data poses the risk of learning and subsequently propagating undesirable concepts, such as copyrighted or unethical content. In this paper, we propose a novel method to remove undesirable concepts from text-to-image generative models by incorporating a learnable prompt into the cross-attention module. This learnable prompt acts as additional memory to transfer the knowledge of undesirable concepts into it and reduce the dependency of these concepts on the model parameters and corresponding textual inputs. Because of this knowledge transfer into the prompt, erasing these undesirable concepts is more stable and has minimal negative impact on other concepts. We demonstrate the effectiveness of our method on the Stable Diffusion model, showcasing its superiority ov",
    "link": "https://arxiv.org/abs/2403.12326",
    "context": "Title: Removing Undesirable Concepts in Text-to-Image Generative Models with Learnable Prompts\nAbstract: arXiv:2403.12326v1 Announce Type: new  Abstract: Generative models have demonstrated remarkable potential in generating visually impressive content from textual descriptions. However, training these models on unfiltered internet data poses the risk of learning and subsequently propagating undesirable concepts, such as copyrighted or unethical content. In this paper, we propose a novel method to remove undesirable concepts from text-to-image generative models by incorporating a learnable prompt into the cross-attention module. This learnable prompt acts as additional memory to transfer the knowledge of undesirable concepts into it and reduce the dependency of these concepts on the model parameters and corresponding textual inputs. Because of this knowledge transfer into the prompt, erasing these undesirable concepts is more stable and has minimal negative impact on other concepts. We demonstrate the effectiveness of our method on the Stable Diffusion model, showcasing its superiority ov",
    "path": "papers/24/03/2403.12326.json",
    "total_tokens": 839,
    "translated_title": "使用可学习提示从文本到图像生成模型中去除不良概念",
    "translated_abstract": "生成模型已经展示出在从文本描述中生成视觉上令人印象深刻的内容方面具有显著潜力。然而，在未经筛选的互联网数据上训练这些模型存在学习和随后传播不良概念（如受版权保护或不道德内容）的风险。在本文中，我们提出了一种新方法，通过将可学习提示结合到交叉注意力模块中，从文本到图像生成模型中去除不良概念。这可学习提示充当附加内存，将不良概念的知识转移到其中，并减少这些概念对模型参数和相应文本输入的依赖。由于这种知识转移到提示中，消除这些不良概念更加稳定，并对其他概念影响最小。我们在稳定扩散模型上展示了我们方法的有效性，展示了其优势。",
    "tldr": "通过引入可学习提示到交叉注意力模块中，本文提出了一种新方法，用于从文本到图像生成模型中去除不良概念，实现了对模型效果的提升。",
    "en_tdlr": "A novel method is proposed to remove undesirable concepts from text-to-image generative models by incorporating a learnable prompt into the cross-attention module, which improves the model performance."
}