{
    "title": "ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation",
    "abstract": "arXiv:2403.18807v1 Announce Type: cross  Abstract: In the absence of parallax cues, a learning-based single image depth estimation (SIDE) model relies heavily on shading and contextual cues in the image. While this simplicity is attractive, it is necessary to train such models on large and varied datasets, which are difficult to capture. It has been shown that using embeddings from pre-trained foundational models, such as CLIP, improves zero shot transfer in several applications. Taking inspiration from this, in our paper we explore the use of global image priors generated from a pre-trained ViT model to provide more detailed contextual information. We argue that the embedding vector from a ViT model, pre-trained on a large dataset, captures greater relevant information for SIDE than the usual route of generating pseudo image captions, followed by CLIP based text embeddings. Based on this idea, we propose a new SIDE model using a diffusion backbone which is conditioned on ViT embedding",
    "link": "https://arxiv.org/abs/2403.18807",
    "context": "Title: ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation\nAbstract: arXiv:2403.18807v1 Announce Type: cross  Abstract: In the absence of parallax cues, a learning-based single image depth estimation (SIDE) model relies heavily on shading and contextual cues in the image. While this simplicity is attractive, it is necessary to train such models on large and varied datasets, which are difficult to capture. It has been shown that using embeddings from pre-trained foundational models, such as CLIP, improves zero shot transfer in several applications. Taking inspiration from this, in our paper we explore the use of global image priors generated from a pre-trained ViT model to provide more detailed contextual information. We argue that the embedding vector from a ViT model, pre-trained on a large dataset, captures greater relevant information for SIDE than the usual route of generating pseudo image captions, followed by CLIP based text embeddings. Based on this idea, we propose a new SIDE model using a diffusion backbone which is conditioned on ViT embedding",
    "path": "papers/24/03/2403.18807.json",
    "total_tokens": 755,
    "translated_title": "ECoDepth: 有效调整扩散模型以用于单目深度估计",
    "translated_abstract": "在缺乏视差线索的情况下，基于学习的单图深度估计（SIDE）模型严重依赖图像中的阴影和上下文线索。我们从已有研究的启发中探讨使用从预训练的ViT模型生成的全局图像先验，以提供更详细的上下文信息。基于这一想法，我们提出了一种新的使用扩散骨干的SIDE模型，其受到ViT嵌入的条件约束。",
    "tldr": "通过使用预训练的ViT模型生成的全局图像先验，为单图深度估计模型提供更详细的上下文信息，并提出了一种新的使用扩散骨干且受ViT嵌入条件约束的深度估计模型。",
    "en_tdlr": "By utilizing global image priors generated from a pre-trained ViT model to provide more detailed contextual information for single image depth estimation (SIDE) models, a new depth estimation model using diffusion backbone conditioned on ViT embedding is proposed."
}