{
    "title": "BaCon: Boosting Imbalanced Semi-supervised Learning via Balanced Feature-Level Contrastive Learning",
    "abstract": "arXiv:2403.12986v1 Announce Type: cross  Abstract: Semi-supervised Learning (SSL) reduces the need for extensive annotations in deep learning, but the more realistic challenge of imbalanced data distribution in SSL remains largely unexplored. In Class Imbalanced Semi-supervised Learning (CISSL), the bias introduced by unreliable pseudo-labels can be exacerbated by imbalanced data distributions. Most existing methods address this issue at instance-level through reweighting or resampling, but the performance is heavily limited by their reliance on biased backbone representation. Some other methods do perform feature-level adjustments like feature blending but might introduce unfavorable noise. In this paper, we discuss the bonus of a more balanced feature distribution for the CISSL problem, and further propose a Balanced Feature-Level Contrastive Learning method (BaCon). Our method directly regularizes the distribution of instances' representations in a well-designed contrastive manner. ",
    "link": "https://arxiv.org/abs/2403.12986",
    "context": "Title: BaCon: Boosting Imbalanced Semi-supervised Learning via Balanced Feature-Level Contrastive Learning\nAbstract: arXiv:2403.12986v1 Announce Type: cross  Abstract: Semi-supervised Learning (SSL) reduces the need for extensive annotations in deep learning, but the more realistic challenge of imbalanced data distribution in SSL remains largely unexplored. In Class Imbalanced Semi-supervised Learning (CISSL), the bias introduced by unreliable pseudo-labels can be exacerbated by imbalanced data distributions. Most existing methods address this issue at instance-level through reweighting or resampling, but the performance is heavily limited by their reliance on biased backbone representation. Some other methods do perform feature-level adjustments like feature blending but might introduce unfavorable noise. In this paper, we discuss the bonus of a more balanced feature distribution for the CISSL problem, and further propose a Balanced Feature-Level Contrastive Learning method (BaCon). Our method directly regularizes the distribution of instances' representations in a well-designed contrastive manner. ",
    "path": "papers/24/03/2403.12986.json",
    "total_tokens": 846,
    "translated_title": "BaCon：通过平衡特征级对比学习增强不平衡半监督学习",
    "translated_abstract": "半监督学习减少了深度学习中对大量标注的需求，但是半监督学习中更现实的挑战——数据分布不平衡的问题仍然较少被探讨。在类别不平衡的半监督学习(CISSL)中，不平衡数据分布可能会加剧由不可靠伪标签引入的偏见。大多数现有方法通过重新加权或重采样来解决这一问题，但由于它们依赖于有偏的骨干表示，其性能受到严重限制。一些其他方法确实进行了特征级调整，比如特征融合，但可能引入不利的噪声。本文讨论了更平衡的特征分布对CISSL问题的好处，并进一步提出了一种平衡特征级对比学习方法(BaCon)。我们的方法通过一种精心设计的对比方式直接规范了实例表示的分布。",
    "tldr": "BaCon通过平衡特征级对比学习方法直接规范了实例表示的分布，在解决不平衡的半监督学习中具有重要意义。",
    "en_tdlr": "BaCon proposes a Balanced Feature-Level Contrastive Learning method to directly regularize the distribution of instances' representations, which is significant for addressing imbalanced semi-supervised learning."
}