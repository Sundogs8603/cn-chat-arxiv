{
    "title": "Flickr30K-CFQ: A Compact and Fragmented Query Dataset for Text-image Retrieval",
    "abstract": "arXiv:2403.13317v1 Announce Type: new  Abstract: With the explosive growth of multi-modal information on the Internet, unimodal search cannot satisfy the requirement of Internet applications. Text-image retrieval research is needed to realize high-quality and efficient retrieval between different modalities. Existing text-image retrieval research is mostly based on general vision-language datasets (e.g. MS-COCO, Flickr30K), in which the query utterance is rigid and unnatural (i.e. verbosity and formality). To overcome the shortcoming, we construct a new Compact and Fragmented Query challenge dataset (named Flickr30K-CFQ) to model text-image retrieval task considering multiple query content and style, including compact and fine-grained entity-relation corpus. We propose a novel query-enhanced text-image retrieval method using prompt engineering based on LLM. Experiments show that our proposed Flickr30-CFQ reveals the insufficiency of existing vision-language datasets in realistic text-i",
    "link": "https://arxiv.org/abs/2403.13317",
    "context": "Title: Flickr30K-CFQ: A Compact and Fragmented Query Dataset for Text-image Retrieval\nAbstract: arXiv:2403.13317v1 Announce Type: new  Abstract: With the explosive growth of multi-modal information on the Internet, unimodal search cannot satisfy the requirement of Internet applications. Text-image retrieval research is needed to realize high-quality and efficient retrieval between different modalities. Existing text-image retrieval research is mostly based on general vision-language datasets (e.g. MS-COCO, Flickr30K), in which the query utterance is rigid and unnatural (i.e. verbosity and formality). To overcome the shortcoming, we construct a new Compact and Fragmented Query challenge dataset (named Flickr30K-CFQ) to model text-image retrieval task considering multiple query content and style, including compact and fine-grained entity-relation corpus. We propose a novel query-enhanced text-image retrieval method using prompt engineering based on LLM. Experiments show that our proposed Flickr30-CFQ reveals the insufficiency of existing vision-language datasets in realistic text-i",
    "path": "papers/24/03/2403.13317.json",
    "total_tokens": 901,
    "translated_title": "Flickr30K-CFQ：用于文本图像检索的紧凑碎片化查询数据集",
    "translated_abstract": "随着互联网上多模态信息的爆炸性增长，单模态搜索无法满足互联网应用的需求。需要进行文本图像检索研究，实现不同模态之间高质量高效的检索。现有的文本图像检索研究大多基于通用的视觉-语言数据集（如MS-COCO、Flickr30K），其中查询话语刻板而不自然（即冗长和过于正式）。为了克服这一缺点，我们构建了一个新的紧凑碎片化查询挑战数据集（名为Flickr30K-CFQ），以建模考虑多个查询内容和风格的文本图像检索任务，包括紧凑和细粒度的实体关系语料库。我们提出了一种基于LLM的新型查询增强文本图像检索方法。实验证明，我们提出的Flickr30-CFQ揭示了现有视觉-语言数据集在现实文本图像检索任务中的不足之处。",
    "tldr": "提出了一个新的紧凑碎片化查询挑战数据集（Flickr30K-CFQ），模拟考虑多个查询内容和风格的文本图像检索任务，并提出了一种基于LLM的查询增强文本图像检索方法。",
    "en_tdlr": "Introduced a new Compact and Fragmented Query challenge dataset (Flickr30K-CFQ) to model text-image retrieval task considering multiple query content and style, and proposed a query-enhanced text-image retrieval method based on LLM."
}