{
    "title": "Telecom Language Models: Must They Be Large?",
    "abstract": "arXiv:2403.04666v1 Announce Type: new  Abstract: The increasing interest in Large Language Models (LLMs) within the telecommunications sector underscores their potential to revolutionize operational efficiency. However, the deployment of these sophisticated models is often hampered by their substantial size and computational demands, raising concerns about their viability in resource-constrained environments. Addressing this challenge, recent advancements have seen the emergence of small language models that surprisingly exhibit performance comparable to their larger counterparts in many tasks, such as coding and common-sense reasoning. Phi-2, a compact yet powerful model, exemplifies this new wave of efficient small language models. This paper conducts a comprehensive evaluation of Phi-2's intrinsic understanding of the telecommunications domain. Recognizing the scale-related limitations, we enhance Phi-2's capabilities through a Retrieval-Augmented Generation approach, meticulously i",
    "link": "https://arxiv.org/abs/2403.04666",
    "context": "Title: Telecom Language Models: Must They Be Large?\nAbstract: arXiv:2403.04666v1 Announce Type: new  Abstract: The increasing interest in Large Language Models (LLMs) within the telecommunications sector underscores their potential to revolutionize operational efficiency. However, the deployment of these sophisticated models is often hampered by their substantial size and computational demands, raising concerns about their viability in resource-constrained environments. Addressing this challenge, recent advancements have seen the emergence of small language models that surprisingly exhibit performance comparable to their larger counterparts in many tasks, such as coding and common-sense reasoning. Phi-2, a compact yet powerful model, exemplifies this new wave of efficient small language models. This paper conducts a comprehensive evaluation of Phi-2's intrinsic understanding of the telecommunications domain. Recognizing the scale-related limitations, we enhance Phi-2's capabilities through a Retrieval-Augmented Generation approach, meticulously i",
    "path": "papers/24/03/2403.04666.json",
    "total_tokens": 809,
    "translated_title": "电信语言模型：它们必须庞大吗？",
    "translated_abstract": "电信部门对庞大语言模型（LLMs）的日益关注凸显了它们在改变运营效率方面的潜力。然而，部署这些复杂模型往往受到其巨大体积和计算需求的影响，引发了对它们在资源受限环境中可行性的担忧。为了解决这一挑战，最近的进展出现了一批小型语言模型，令人惊讶的是它们在许多任务中表现与其较大对应物相当，比如编码和常识推理。Phi-2是一种紧凑但功能强大的模型，它体现了这一系列高效小型语言模型的新浪潮。本文对Phi-2在电信领域内在本质上的理解进行了全面评估。鉴于规模相关限制，我们通过检索增强生成方法，精心增强了Phi-2的能力。",
    "tldr": "小型语言模型Phi-2在电信领域展示出与大型对应模型相媲美的性能，通过检索增强生成方法提升了其能力。",
    "en_tdlr": "The small language model Phi-2 demonstrates comparable performance to its larger counterparts in the telecommunications domain, and its capabilities are enhanced through a retrieval-augmented generation approach."
}