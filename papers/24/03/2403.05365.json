{
    "title": "The Impact of Quantization on the Robustness of Transformer-based Text Classifiers",
    "abstract": "arXiv:2403.05365v1 Announce Type: new  Abstract: Transformer-based models have made remarkable advancements in various NLP areas. Nevertheless, these models often exhibit vulnerabilities when confronted with adversarial attacks. In this paper, we explore the effect of quantization on the robustness of Transformer-based models. Quantization usually involves mapping a high-precision real number to a lower-precision value, aiming at reducing the size of the model at hand. To the best of our knowledge, this work is the first application of quantization on the robustness of NLP models. In our experiments, we evaluate the impact of quantization on BERT and DistilBERT models in text classification using SST-2, Emotion, and MR datasets. We also evaluate the performance of these models against TextFooler, PWWS, and PSO adversarial attacks. Our findings show that quantization significantly improves (by an average of 18.68%) the adversarial accuracy of the models. Furthermore, we compare the effe",
    "link": "https://arxiv.org/abs/2403.05365",
    "context": "Title: The Impact of Quantization on the Robustness of Transformer-based Text Classifiers\nAbstract: arXiv:2403.05365v1 Announce Type: new  Abstract: Transformer-based models have made remarkable advancements in various NLP areas. Nevertheless, these models often exhibit vulnerabilities when confronted with adversarial attacks. In this paper, we explore the effect of quantization on the robustness of Transformer-based models. Quantization usually involves mapping a high-precision real number to a lower-precision value, aiming at reducing the size of the model at hand. To the best of our knowledge, this work is the first application of quantization on the robustness of NLP models. In our experiments, we evaluate the impact of quantization on BERT and DistilBERT models in text classification using SST-2, Emotion, and MR datasets. We also evaluate the performance of these models against TextFooler, PWWS, and PSO adversarial attacks. Our findings show that quantization significantly improves (by an average of 18.68%) the adversarial accuracy of the models. Furthermore, we compare the effe",
    "path": "papers/24/03/2403.05365.json",
    "total_tokens": 849,
    "translated_title": "量化对基于Transformer的文本分类器鲁棒性的影响",
    "translated_abstract": "Transformer-based模型在各种自然语言处理领域取得了显著的进展。然而，这些模型在面对对抗性攻击时往往表现出脆弱性。本文探讨了量化对Transformer-based模型鲁棒性的影响。量化通常涉及将高精度实数映射到较低精度的值，旨在减少所涉模型的大小。据我们所知，这项工作是首次将量化应用于NLP模型的鲁棒性。在实验中，我们评估了在文本分类中对BERT和DistilBERT模型应用量化的影响，使用了SST-2、Emotion和MR数据集。我们还评估了这些模型在面对TextFooler、PWWS和PSO对抗性攻击时的表现。我们的研究结果显示，量化显著提高了模型的对抗准确性（平均提升了18.68%）。此外，我们比较了...",
    "tldr": "量化可以显著提高Transformer-based文本分类器在面对对抗攻击时的鲁棒性表现，平均提升了18.68%。"
}