{
    "title": "On the Effectiveness of Distillation in Mitigating Backdoors in Pre-trained Encoder",
    "abstract": "arXiv:2403.03846v1 Announce Type: new  Abstract: In this paper, we study a defense against poisoned encoders in SSL called distillation, which is a defense used in supervised learning originally. Distillation aims to distill knowledge from a given model (a.k.a the teacher net) and transfer it to another (a.k.a the student net). Now, we use it to distill benign knowledge from poisoned pre-trained encoders and transfer it to a new encoder, resulting in a clean pre-trained encoder. In particular, we conduct an empirical study on the effectiveness and performance of distillation against poisoned encoders. Using two state-of-the-art backdoor attacks against pre-trained image encoders and four commonly used image classification datasets, our experimental results show that distillation can reduce attack success rate from 80.87% to 27.51% while suffering a 6.35% loss in accuracy. Moreover, we investigate the impact of three core components of distillation on performance: teacher net, student n",
    "link": "https://arxiv.org/abs/2403.03846",
    "context": "Title: On the Effectiveness of Distillation in Mitigating Backdoors in Pre-trained Encoder\nAbstract: arXiv:2403.03846v1 Announce Type: new  Abstract: In this paper, we study a defense against poisoned encoders in SSL called distillation, which is a defense used in supervised learning originally. Distillation aims to distill knowledge from a given model (a.k.a the teacher net) and transfer it to another (a.k.a the student net). Now, we use it to distill benign knowledge from poisoned pre-trained encoders and transfer it to a new encoder, resulting in a clean pre-trained encoder. In particular, we conduct an empirical study on the effectiveness and performance of distillation against poisoned encoders. Using two state-of-the-art backdoor attacks against pre-trained image encoders and four commonly used image classification datasets, our experimental results show that distillation can reduce attack success rate from 80.87% to 27.51% while suffering a 6.35% loss in accuracy. Moreover, we investigate the impact of three core components of distillation on performance: teacher net, student n",
    "path": "papers/24/03/2403.03846.json",
    "total_tokens": 961,
    "translated_title": "在缓解预训练编码器中后门问题中蒸馏的有效性研究",
    "translated_abstract": "在本文中，我们研究了一种用于SSL中防御受污染编码器的方法，叫做蒸馏，这个方法最初是用于监督学习中的防御机制。蒸馏旨在从给定模型（称为教师网络）中提炼知识，并将其传递给另一个模型（称为学生网络）。我们现在使用它从受污染的预训练编码器中提炼良性知识，并将其传递给一个新编码器，从而得到一个干净的预训练编码器。具体来说，我们对蒸馏对抗受污染编码器的有效性和性能进行了实证研究。我们使用了两种最先进的针对预训练图像编码器的后门攻击方法和四个常用的图像分类数据集，实验结果表明，蒸馏可以将攻击成功率从80.87%降低到27.51%，而准确率下降了6.35%。此外，我们研究了蒸馏的三个核心组件对性能的影响：教师网络、学生网络和",
    "tldr": "研究了如何利用蒸馏从受污染的预训练编码器中提取良性知识，将其传递给新编码器，成功降低攻击成功率，并探讨了蒸馏的核心组件对性能的影响。",
    "en_tdlr": "Investigated the extraction of benign knowledge from poisoned pre-trained encoders using distillation to reduce attack success rate and explored the impact of core components of distillation on performance."
}