{
    "title": "LoMOE: Localized Multi-Object Editing via Multi-Diffusion",
    "abstract": "arXiv:2403.00437v1 Announce Type: cross  Abstract: Recent developments in the field of diffusion models have demonstrated an exceptional capacity to generate high-quality prompt-conditioned image edits. Nevertheless, previous approaches have primarily relied on textual prompts for image editing, which tend to be less effective when making precise edits to specific objects or fine-grained regions within a scene containing single/multiple objects. We introduce a novel framework for zero-shot localized multi-object editing through a multi-diffusion process to overcome this challenge. This framework empowers users to perform various operations on objects within an image, such as adding, replacing, or editing $\\textbf{many}$ objects in a complex scene $\\textbf{in one pass}$. Our approach leverages foreground masks and corresponding simple text prompts that exert localized influences on the target regions resulting in high-fidelity image editing. A combination of cross-attention and backgrou",
    "link": "https://arxiv.org/abs/2403.00437",
    "context": "Title: LoMOE: Localized Multi-Object Editing via Multi-Diffusion\nAbstract: arXiv:2403.00437v1 Announce Type: cross  Abstract: Recent developments in the field of diffusion models have demonstrated an exceptional capacity to generate high-quality prompt-conditioned image edits. Nevertheless, previous approaches have primarily relied on textual prompts for image editing, which tend to be less effective when making precise edits to specific objects or fine-grained regions within a scene containing single/multiple objects. We introduce a novel framework for zero-shot localized multi-object editing through a multi-diffusion process to overcome this challenge. This framework empowers users to perform various operations on objects within an image, such as adding, replacing, or editing $\\textbf{many}$ objects in a complex scene $\\textbf{in one pass}$. Our approach leverages foreground masks and corresponding simple text prompts that exert localized influences on the target regions resulting in high-fidelity image editing. A combination of cross-attention and backgrou",
    "path": "papers/24/03/2403.00437.json",
    "total_tokens": 782,
    "translated_title": "LoMOE: 通过多扩散实现局部多对象编辑",
    "translated_abstract": "扩散模型领域的最新发展展示了生成高质量基于提示条件的图像编辑的卓越能力。然而，先前的方法主要依赖于文本提示进行图像编辑，当对场景中包含单个/多个对象的特定对象或细粒度区域进行精确编辑时往往不太有效。我们引入了一种新颖的框架，通过多扩散过程实现零样本局部多对象编辑，以克服这一挑战。该框架赋予用户在图像中对对象执行各种操作的能力，例如在一个复杂场景中一次性添加、替换或编辑$\\textbf{多}$对象。我们的方法利用前景 mask 和对应的简单文本提示对目标区域施加局部影响，实现高保真度图像编辑。通过跨注意力和背景",
    "tldr": "通过多扩散过程实现零样本局部多对象编辑，赋予用户在图像中一次性添加、替换或编辑多对象的能力。",
    "en_tdlr": "Zero-shot localized multi-object editing through multi-diffusion process empowers users to add, replace, or edit multiple objects in an image in one pass."
}