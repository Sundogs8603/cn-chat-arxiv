{
    "title": "An Analytic Solution to Covariance Propagation in Neural Networks",
    "abstract": "arXiv:2403.16163v1 Announce Type: cross  Abstract: Uncertainty quantification of neural networks is critical to measuring the reliability and robustness of deep learning systems. However, this often involves costly or inaccurate sampling methods and approximations. This paper presents a sample-free moment propagation technique that propagates mean vectors and covariance matrices across a network to accurately characterize the input-output distributions of neural networks. A key enabler of our technique is an analytic solution for the covariance of random variables passed through nonlinear activation functions, such as Heaviside, ReLU, and GELU. The wide applicability and merits of the proposed technique are shown in experiments analyzing the input-output distributions of trained neural networks and training Bayesian neural networks.",
    "link": "https://arxiv.org/abs/2403.16163",
    "context": "Title: An Analytic Solution to Covariance Propagation in Neural Networks\nAbstract: arXiv:2403.16163v1 Announce Type: cross  Abstract: Uncertainty quantification of neural networks is critical to measuring the reliability and robustness of deep learning systems. However, this often involves costly or inaccurate sampling methods and approximations. This paper presents a sample-free moment propagation technique that propagates mean vectors and covariance matrices across a network to accurately characterize the input-output distributions of neural networks. A key enabler of our technique is an analytic solution for the covariance of random variables passed through nonlinear activation functions, such as Heaviside, ReLU, and GELU. The wide applicability and merits of the proposed technique are shown in experiments analyzing the input-output distributions of trained neural networks and training Bayesian neural networks.",
    "path": "papers/24/03/2403.16163.json",
    "total_tokens": 779,
    "translated_title": "神经网络中协方差传播的解析解",
    "translated_abstract": "神经网络的不确定性量化对于衡量深度学习系统的可靠性和鲁棒性至关重要。然而，这通常涉及昂贵或不准确的采样方法和近似。本文提出了一种无需样本的矩传播技术，通过网络传播均值向量和协方差矩阵，准确表征神经网络的输入输出分布。我们的技术的一个关键优势是为通过非线性激活函数（如Heaviside、ReLU和GELU）传递的随机变量的协方差提供了解析解。通过分析经过训练的神经网络的输入输出分布以及训练贝叶斯神经网络的实验，展示了所提出技术的广泛适用性和优点。",
    "tldr": "该论文提出了一种无需样本的矩传播技术，能够准确表征神经网络的输入输出分布，其关键创新在于提供了通过非线性激活函数传递的随机变量协方差的解析解。",
    "en_tdlr": "This paper introduces a sample-free moment propagation technique that accurately characterizes the input-output distributions of neural networks, with a key innovation being the analytic solution provided for the covariance of random variables passed through nonlinear activation functions."
}