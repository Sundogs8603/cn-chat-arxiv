{
    "title": "RL-MSA: a Reinforcement Learning-based Multi-line bus Scheduling Approach",
    "abstract": "arXiv:2403.06466v1 Announce Type: cross  Abstract: Multiple Line Bus Scheduling Problem (MLBSP) is vital to save operational cost of bus company and guarantee service quality for passengers. Existing approaches typically generate a bus scheduling scheme in an offline manner and then schedule buses according to the scheme. In practice, uncertain events such as traffic congestion occur frequently, which may make the pre-determined bus scheduling scheme infeasible. In this paper, MLBSP is modeled as a Markov Decision Process (MDP). A Reinforcement Learning-based Multi-line bus Scheduling Approach (RL-MSA) is proposed for bus scheduling at both the offline and online phases. At the offline phase, deadhead decision is integrated into bus selection decision for the first time to simplify the learning problem. At the online phase, deadhead decision is made through a time window mechanism based on the policy learned at the offline phase. We develop several new and useful state features includi",
    "link": "https://arxiv.org/abs/2403.06466",
    "context": "Title: RL-MSA: a Reinforcement Learning-based Multi-line bus Scheduling Approach\nAbstract: arXiv:2403.06466v1 Announce Type: cross  Abstract: Multiple Line Bus Scheduling Problem (MLBSP) is vital to save operational cost of bus company and guarantee service quality for passengers. Existing approaches typically generate a bus scheduling scheme in an offline manner and then schedule buses according to the scheme. In practice, uncertain events such as traffic congestion occur frequently, which may make the pre-determined bus scheduling scheme infeasible. In this paper, MLBSP is modeled as a Markov Decision Process (MDP). A Reinforcement Learning-based Multi-line bus Scheduling Approach (RL-MSA) is proposed for bus scheduling at both the offline and online phases. At the offline phase, deadhead decision is integrated into bus selection decision for the first time to simplify the learning problem. At the online phase, deadhead decision is made through a time window mechanism based on the policy learned at the offline phase. We develop several new and useful state features includi",
    "path": "papers/24/03/2403.06466.json",
    "total_tokens": 928,
    "translated_title": "RL-MSA：基于强化学习的多线路公交车调度方法",
    "translated_abstract": "多线路公交车调度问题（MLBSP）对于节省公交公司运营成本和保证乘客服务质量至关重要。现有方法通常以离线方式生成公交车调度方案，然后根据该方案安排公交车。然而在实践中，诸如交通拥堵之类的不确定事件经常发生，这可能使事先确定的公交车调度方案变得不可行。本文将MLBSP建模为马尔科夫决策过程（MDP）。提出了一种基于强化学习的多线路公交车调度方法（RL-MSA），用于在离线和在线阶段进行公交车调度。在离线阶段，将直行车决策整合到首次出现的公交车选择决策中，以简化学习问题。在在线阶段，通过基于离线阶段学会的策略进行直行车决策，采用时间窗口机制。我们开发了几个新的有用状态特征包括",
    "tldr": "RL-MSA提出了一种基于强化学习的多线路公交车调度方法，将多线路公交车调度问题建模为MDP，首次在离线阶段将直行车决策整合入公交车选择决策，有效简化学习问题，在线阶段通过时间窗口机制进行直行车决策。",
    "en_tdlr": "RL-MSA proposes a Reinforcement Learning-based approach for multi-line bus scheduling, modeling the problem as MDP, integrating deadhead decision into bus selection decision at offline phase for the first time to simplify learning problem, and making deadhead decision at online phase through a time window mechanism."
}