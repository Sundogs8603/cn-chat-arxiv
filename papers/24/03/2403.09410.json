{
    "title": "XCoOp: Explainable Prompt Learning for Computer-Aided Diagnosis via Concept-guided Context Optimization",
    "abstract": "arXiv:2403.09410v1 Announce Type: cross  Abstract: Utilizing potent representations of the large vision-language models (VLMs) to accomplish various downstream tasks has attracted increasing attention. Within this research field, soft prompt learning has become a representative approach for efficiently adapting VLMs such as CLIP, to tasks like image classification. However, most existing prompt learning methods learn text tokens that are unexplainable, which cannot satisfy the stringent interpretability requirements of Explainable Artificial Intelligence (XAI) in high-stakes scenarios like healthcare. To address this issue, we propose a novel explainable prompt learning framework that leverages medical knowledge by aligning the semantics of images, learnable prompts, and clinical concept-driven prompts at multiple granularities. Moreover, our framework addresses the lack of valuable concept annotations by eliciting knowledge from large language models and offers both visual and textual",
    "link": "https://arxiv.org/abs/2403.09410",
    "context": "Title: XCoOp: Explainable Prompt Learning for Computer-Aided Diagnosis via Concept-guided Context Optimization\nAbstract: arXiv:2403.09410v1 Announce Type: cross  Abstract: Utilizing potent representations of the large vision-language models (VLMs) to accomplish various downstream tasks has attracted increasing attention. Within this research field, soft prompt learning has become a representative approach for efficiently adapting VLMs such as CLIP, to tasks like image classification. However, most existing prompt learning methods learn text tokens that are unexplainable, which cannot satisfy the stringent interpretability requirements of Explainable Artificial Intelligence (XAI) in high-stakes scenarios like healthcare. To address this issue, we propose a novel explainable prompt learning framework that leverages medical knowledge by aligning the semantics of images, learnable prompts, and clinical concept-driven prompts at multiple granularities. Moreover, our framework addresses the lack of valuable concept annotations by eliciting knowledge from large language models and offers both visual and textual",
    "path": "papers/24/03/2403.09410.json",
    "total_tokens": 880,
    "translated_title": "XCoOp：通过概念引导的上下文优化为计算机辅助诊断提供可解释的提示学习",
    "translated_abstract": "利用大视觉-语言模型（VLMs）强大的表示来完成各种下游任务已经引起了越来越多的关注。在这一研究领域中，软提示学习已经成为一种代表性方法，用于高效地适应VLMs，例如CLIP，以执行诸如图像分类之类的任务。然而，大多数现有的提示学习方法学习的文本标记是无法解释的，这不能满足像医疗保健等高风险场景中解释人工智能（XAI）的严格可解释性要求。为了解决这一问题，我们提出了一种新颖的可解释的提示学习框架，通过在多个粒度上对齐图像、可学习提示和临床概念驱动提示的语义，利用医学知识。此外，我们的框架通过从大型语言模型中获取知识来解决缺乏有价值的概念注释的问题，并提供了视觉和文本上",
    "tldr": "提出了一种新颖的可解释的提示学习框架，通过对齐图像、可学习提示和临床概念驱动提示的语义，利用医学知识。",
    "en_tdlr": "Proposed a novel explainable prompt learning framework that leverages medical knowledge by aligning the semantics of images, learnable prompts, and clinical concept-driven prompts at multiple granularities."
}