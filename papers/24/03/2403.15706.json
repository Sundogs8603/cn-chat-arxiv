{
    "title": "G-ACIL: Analytic Learning for Exemplar-Free Generalized Class Incremental Learning",
    "abstract": "arXiv:2403.15706v1 Announce Type: new  Abstract: Class incremental learning (CIL) trains a network on sequential tasks with separated categories but suffers from catastrophic forgetting, where models quickly lose previously learned knowledge when acquiring new tasks. The generalized CIL (GCIL) aims to address the CIL problem in a more real-world scenario, where incoming data have mixed data categories and unknown sample size distribution, leading to intensified forgetting. Existing attempts for the GCIL either have poor performance, or invade data privacy by saving historical exemplars. To address this, in this paper, we propose an exemplar-free generalized analytic class incremental learning (G-ACIL). The G-ACIL adopts analytic learning (a gradient-free training technique), and delivers an analytical solution (i.e., closed-form) to the GCIL scenario. This solution is derived via decomposing the incoming data into exposed and unexposed classes, allowing an equivalence between the incre",
    "link": "https://arxiv.org/abs/2403.15706",
    "context": "Title: G-ACIL: Analytic Learning for Exemplar-Free Generalized Class Incremental Learning\nAbstract: arXiv:2403.15706v1 Announce Type: new  Abstract: Class incremental learning (CIL) trains a network on sequential tasks with separated categories but suffers from catastrophic forgetting, where models quickly lose previously learned knowledge when acquiring new tasks. The generalized CIL (GCIL) aims to address the CIL problem in a more real-world scenario, where incoming data have mixed data categories and unknown sample size distribution, leading to intensified forgetting. Existing attempts for the GCIL either have poor performance, or invade data privacy by saving historical exemplars. To address this, in this paper, we propose an exemplar-free generalized analytic class incremental learning (G-ACIL). The G-ACIL adopts analytic learning (a gradient-free training technique), and delivers an analytical solution (i.e., closed-form) to the GCIL scenario. This solution is derived via decomposing the incoming data into exposed and unexposed classes, allowing an equivalence between the incre",
    "path": "papers/24/03/2403.15706.json",
    "total_tokens": 900,
    "translated_title": "G-ACIL：面向非范例化的广义类增量学习的分析学习",
    "translated_abstract": "分类增量学习(CIL)在顺序任务上训练网络，每个任务有不同的类别，但存在灾难性遗忘问题，当学习新任务时快速遗忘先前学到的知识。广义CIL(GCIL)旨在解决更接近现实情景下的CIL问题，即新数据具有混合数据类别和未知样本分布大小，导致遗忘加剧。现有的针对GCIL的尝试要么性能不佳，要么通过保存历史范例侵犯数据隐私。为了解决这个问题，本文提出了一种面向非范例化的广义分析类增量学习(G-ACIL)。G-ACIL采用分析学习(一种无梯度训练技术)，并为GCIL情景提供分析解(即闭合形式)。该解决方案通过将传入数据分解为暴露类和未暴露类，实现了增长类之间的等效性。",
    "tldr": "在这项研究中，我们提出了一种面向非范例化的广义分析类增量学习，通过采用分析学习并提供了对GCIL情景的分析解决方案，有效地解决了模型快速遗忘和数据隐私侵犯问题。",
    "en_tdlr": "In this study, we propose an exemplar-free generalized analytic class incremental learning approach, which tackles the issues of rapid forgetting and data privacy infringement by employing analytic learning and providing an analytical solution for the GCIL scenario."
}