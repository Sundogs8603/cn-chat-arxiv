{
    "title": "Enhancing Multi-Hop Knowledge Graph Reasoning through Reward Shaping Techniques",
    "abstract": "arXiv:2403.05801v1 Announce Type: new  Abstract: In the realm of computational knowledge representation, Knowledge Graph Reasoning (KG-R) stands at the forefront of facilitating sophisticated inferential capabilities across multifarious domains. The quintessence of this research elucidates the employment of reinforcement learning (RL) strategies, notably the REINFORCE algorithm, to navigate the intricacies inherent in multi-hop KG-R. This investigation critically addresses the prevalent challenges introduced by the inherent incompleteness of Knowledge Graphs (KGs), which frequently results in erroneous inferential outcomes, manifesting as both false negatives and misleading positives. By partitioning the Unified Medical Language System (UMLS) benchmark dataset into rich and sparse subsets, we investigate the efficacy of pre-trained BERT embeddings and Prompt Learning methodologies to refine the reward shaping process. This approach not only enhances the precision of multi-hop KG-R but ",
    "link": "https://arxiv.org/abs/2403.05801",
    "context": "Title: Enhancing Multi-Hop Knowledge Graph Reasoning through Reward Shaping Techniques\nAbstract: arXiv:2403.05801v1 Announce Type: new  Abstract: In the realm of computational knowledge representation, Knowledge Graph Reasoning (KG-R) stands at the forefront of facilitating sophisticated inferential capabilities across multifarious domains. The quintessence of this research elucidates the employment of reinforcement learning (RL) strategies, notably the REINFORCE algorithm, to navigate the intricacies inherent in multi-hop KG-R. This investigation critically addresses the prevalent challenges introduced by the inherent incompleteness of Knowledge Graphs (KGs), which frequently results in erroneous inferential outcomes, manifesting as both false negatives and misleading positives. By partitioning the Unified Medical Language System (UMLS) benchmark dataset into rich and sparse subsets, we investigate the efficacy of pre-trained BERT embeddings and Prompt Learning methodologies to refine the reward shaping process. This approach not only enhances the precision of multi-hop KG-R but ",
    "path": "papers/24/03/2403.05801.json",
    "total_tokens": 766,
    "translated_title": "通过奖励塑造技术增强多跳知识图推理",
    "translated_abstract": "在计算知识表示领域，知识图推理（KG-R）处于促进各个领域之间复杂推理能力的前沿。本研究的要点在于阐明了利用强化学习（RL）策略，特别是REINFORCE算法，来解决多跳KG-R中固有复杂性的方法。通过将统一医学语言系统（UMLS）基准数据集分为丰富和稀疏子集，我们研究了预训练的BERT嵌入和提示学习方法对改进奖励塑造过程的有效性。这种方法不仅提高了多跳KG-R的精度，还...",
    "tldr": "通过奖励塑造技术和预训练的BERT嵌入以及提示学习方法，本研究在多跳知识图推理中处理知识图的固有不完整性，提高了精度。"
}