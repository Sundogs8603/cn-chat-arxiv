{
    "title": "Hessian-Free Laplace in Bayesian Deep Learning",
    "abstract": "arXiv:2403.10671v1 Announce Type: cross  Abstract: The Laplace approximation (LA) of the Bayesian posterior is a Gaussian distribution centered at the maximum a posteriori estimate. Its appeal in Bayesian deep learning stems from the ability to quantify uncertainty post-hoc (i.e., after standard network parameter optimization), the ease of sampling from the approximate posterior, and the analytic form of model evidence. However, an important computational bottleneck of LA is the necessary step of calculating and inverting the Hessian matrix of the log posterior. The Hessian may be approximated in a variety of ways, with quality varying with a number of factors including the network, dataset, and inference task. In this paper, we propose an alternative framework that sidesteps Hessian calculation and inversion. The Hessian-free Laplace (HFL) approximation uses curvature of both the log posterior and network prediction to estimate its variance. Only two point estimates are needed: the st",
    "link": "https://arxiv.org/abs/2403.10671",
    "context": "Title: Hessian-Free Laplace in Bayesian Deep Learning\nAbstract: arXiv:2403.10671v1 Announce Type: cross  Abstract: The Laplace approximation (LA) of the Bayesian posterior is a Gaussian distribution centered at the maximum a posteriori estimate. Its appeal in Bayesian deep learning stems from the ability to quantify uncertainty post-hoc (i.e., after standard network parameter optimization), the ease of sampling from the approximate posterior, and the analytic form of model evidence. However, an important computational bottleneck of LA is the necessary step of calculating and inverting the Hessian matrix of the log posterior. The Hessian may be approximated in a variety of ways, with quality varying with a number of factors including the network, dataset, and inference task. In this paper, we propose an alternative framework that sidesteps Hessian calculation and inversion. The Hessian-free Laplace (HFL) approximation uses curvature of both the log posterior and network prediction to estimate its variance. Only two point estimates are needed: the st",
    "path": "papers/24/03/2403.10671.json",
    "total_tokens": 813,
    "translated_title": "Bayesian深度学习中的无Hessian-Laplace",
    "translated_abstract": "贝叶斯后验的Laplace近似（LA）是以最大后验估计为中心的高斯分布。它在贝叶斯深度学习中的吸引力源于能够在标准网络参数优化之后量化不确定性（即事后），从近似后验中抽样的便利性以及模型证据的解析形式。然而，LA的一个重要计算瓶颈是必须计算和求逆对数后验的Hessian矩阵。Hessian可以以多种方式近似，质量与网络、数据集和推断任务等多个因素有关。在本文中，我们提出了一个绕过Hessian计算和求逆的替代框架。无Hessian-Laplace（HFL）近似使用对数后验和网络预测的曲率来估计其方差。只需要两个点估计：最大后验估计和等价的曲率方向。",
    "tldr": "提出了一种无Hessian计算和求逆的Hessian-Free Laplace近似框架，通过对数后验和网络预测的曲率来估计后验的方差。",
    "en_tdlr": "Introduced a Hessian-Free Laplace approximation framework that avoids Hessian calculation and inversion, estimating the variance of the posterior using the curvature of the log posterior and network prediction."
}