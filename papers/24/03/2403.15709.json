{
    "title": "Contact-aware Human Motion Generation from Textual Descriptions",
    "abstract": "arXiv:2403.15709v1 Announce Type: cross  Abstract: This paper addresses the problem of generating 3D interactive human motion from text. Given a textual description depicting the actions of different body parts in contact with objects, we synthesize sequences of 3D body poses that are visually natural and physically plausible. Yet, this task poses a significant challenge due to the inadequate consideration of interactions by physical contacts in both motion and textual descriptions, leading to unnatural and implausible sequences. To tackle this challenge, we create a novel dataset named RICH-CAT, representing ``Contact-Aware Texts'' constructed from the RICH dataset. RICH-CAT comprises high-quality motion, accurate human-object contact labels, and detailed textual descriptions, encompassing over 8,500 motion-text pairs across 26 indoor/outdoor actions. Leveraging RICH-CAT, we propose a novel approach named CATMO for text-driven interactive human motion synthesis that explicitly integra",
    "link": "https://arxiv.org/abs/2403.15709",
    "context": "Title: Contact-aware Human Motion Generation from Textual Descriptions\nAbstract: arXiv:2403.15709v1 Announce Type: cross  Abstract: This paper addresses the problem of generating 3D interactive human motion from text. Given a textual description depicting the actions of different body parts in contact with objects, we synthesize sequences of 3D body poses that are visually natural and physically plausible. Yet, this task poses a significant challenge due to the inadequate consideration of interactions by physical contacts in both motion and textual descriptions, leading to unnatural and implausible sequences. To tackle this challenge, we create a novel dataset named RICH-CAT, representing ``Contact-Aware Texts'' constructed from the RICH dataset. RICH-CAT comprises high-quality motion, accurate human-object contact labels, and detailed textual descriptions, encompassing over 8,500 motion-text pairs across 26 indoor/outdoor actions. Leveraging RICH-CAT, we propose a novel approach named CATMO for text-driven interactive human motion synthesis that explicitly integra",
    "path": "papers/24/03/2403.15709.json",
    "total_tokens": 832,
    "translated_title": "从文本描述生成考虑接触的人体动作",
    "translated_abstract": "本文解决了从文本生成3D交互式人体动作的问题。给定描述了不同身体部位接触物体动作的文本描述，我们综合生成视觉自然且物理合理的3D人体姿势序列。然而，这个任务存在一个重要挑战，即在动作和文本描述中对物理接触的互动考虑不足，导致序列不自然且不合理。为了解决这一挑战，我们创建了一个名为RICH-CAT的新数据集，表示从RICH数据集构建的“考虑接触”的文本。RICH-CAT包括高质量动作、准确的人-物接触标签和详细的文本描述，涵盖了26种室内/室外动作的8500多对动作-文本配对。利用RICH-CAT，我们提出了一种名为CATMO的新方法，用于文本驱动的交互式人体动作合成，明确整合了物理接触的信息。",
    "tldr": "本研究提出了一种新的方法CATMO，通过整合物理接触信息，从文本描述中生成视觉自然且物理合理的3D人体动作。",
    "en_tdlr": "This paper proposes a novel approach CATMO that generates visually natural and physically plausible 3D human motions from textual descriptions by integrating physical contact information."
}