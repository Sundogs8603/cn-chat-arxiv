{
    "title": "Embedded Named Entity Recognition using Probing Classifiers",
    "abstract": "arXiv:2403.11747v1 Announce Type: new  Abstract: Extracting semantic information from generated text is a useful tool for applications such as automated fact checking or retrieval augmented generation. Currently, this requires either separate models during inference, which increases computational cost, or destructive fine-tuning of the language model. Instead, we propose directly embedding information extraction capabilities into pre-trained language models using probing classifiers, enabling efficient simultaneous text generation and information extraction. For this, we introduce an approach called EMBER and show that it enables named entity recognition in decoder-only language models without fine-tuning them and while incurring minimal additional computational cost at inference time. Specifically, our experiments using GPT-2 show that EMBER maintains high token generation rates during streaming text generation, with only a negligible decrease in speed of around 1% compared to a 43.64",
    "link": "https://arxiv.org/abs/2403.11747",
    "context": "Title: Embedded Named Entity Recognition using Probing Classifiers\nAbstract: arXiv:2403.11747v1 Announce Type: new  Abstract: Extracting semantic information from generated text is a useful tool for applications such as automated fact checking or retrieval augmented generation. Currently, this requires either separate models during inference, which increases computational cost, or destructive fine-tuning of the language model. Instead, we propose directly embedding information extraction capabilities into pre-trained language models using probing classifiers, enabling efficient simultaneous text generation and information extraction. For this, we introduce an approach called EMBER and show that it enables named entity recognition in decoder-only language models without fine-tuning them and while incurring minimal additional computational cost at inference time. Specifically, our experiments using GPT-2 show that EMBER maintains high token generation rates during streaming text generation, with only a negligible decrease in speed of around 1% compared to a 43.64",
    "path": "papers/24/03/2403.11747.json",
    "total_tokens": 836,
    "translated_title": "使用探测分类器的嵌入式命名实体识别",
    "translated_abstract": "从生成的文本中提取语义信息是自动事实检查或检索增强生成等应用的有用工具。目前，这要求在推理过程中使用单独的模型，这会增加计算成本，或对语言模型进行破坏性微调。相反，我们提出直接将信息提取功能嵌入预训练的语言模型中，使用探测分类器，从而实现高效的同时文本生成和信息提取。为此，我们介绍了一种名为EMBER的方法，并展示它使解码器-only语言模型能够在不微调的情况下进行命名实体识别，并且在推理过程中附加的计算成本极小。具体来说，我们使用GPT-2进行的实验表明，EMBER在流文本生成过程中保持高令牌生成速率，与43.64%相比，其速度仅略微下降约1%。",
    "tldr": "提出一种名为EMBER的方法，通过使用探测分类器将信息提取能力直接嵌入预训练语言模型中，实现了高效的同时文本生成和信息提取，使得解码器-only语言模型能够在不微调的情况下进行命名实体识别。",
    "en_tdlr": "Introducing a method called EMBER that embeds information extraction capabilities into pre-trained language models using probing classifiers, enabling efficient simultaneous text generation and information extraction, allowing decoder-only language models to perform named entity recognition without fine-tuning."
}