{
    "title": "Moments of Clarity: Streamlining Latent Spaces in Machine Learning using Moment Pooling",
    "abstract": "arXiv:2403.08854v1 Announce Type: cross  Abstract: Many machine learning applications involve learning a latent representation of data, which is often high-dimensional and difficult to directly interpret. In this work, we propose \"Moment Pooling\", a natural extension of Deep Sets networks which drastically decrease latent space dimensionality of these networks while maintaining or even improving performance. Moment Pooling generalizes the summation in Deep Sets to arbitrary multivariate moments, which enables the model to achieve a much higher effective latent dimensionality for a fixed latent dimension. We demonstrate Moment Pooling on the collider physics task of quark/gluon jet classification by extending Energy Flow Networks (EFNs) to Moment EFNs. We find that Moment EFNs with latent dimensions as small as 1 perform similarly to ordinary EFNs with higher latent dimension. This small latent dimension allows for the internal representation to be directly visualized and interpreted, w",
    "link": "https://arxiv.org/abs/2403.08854",
    "context": "Title: Moments of Clarity: Streamlining Latent Spaces in Machine Learning using Moment Pooling\nAbstract: arXiv:2403.08854v1 Announce Type: cross  Abstract: Many machine learning applications involve learning a latent representation of data, which is often high-dimensional and difficult to directly interpret. In this work, we propose \"Moment Pooling\", a natural extension of Deep Sets networks which drastically decrease latent space dimensionality of these networks while maintaining or even improving performance. Moment Pooling generalizes the summation in Deep Sets to arbitrary multivariate moments, which enables the model to achieve a much higher effective latent dimensionality for a fixed latent dimension. We demonstrate Moment Pooling on the collider physics task of quark/gluon jet classification by extending Energy Flow Networks (EFNs) to Moment EFNs. We find that Moment EFNs with latent dimensions as small as 1 perform similarly to ordinary EFNs with higher latent dimension. This small latent dimension allows for the internal representation to be directly visualized and interpreted, w",
    "path": "papers/24/03/2403.08854.json",
    "total_tokens": 910,
    "translated_title": "清晰瞬间：使用Moment Pooling简化机器学习中的潜在空间",
    "translated_abstract": "许多机器学习应用涉及学习数据的潜在表示，通常是高维且难以直接解释。在这项工作中，我们提出了“Moment Pooling”，这是Deep Sets网络的一个自然延伸，可大幅减少这些网络的潜在空间维度，同时维持甚至提高性能。Moment Pooling将Deep Sets中的求和泛化为任意的多变量矩，使模型能够在固定的潜在维度下实现更高的有效潜在维度。我们将Moment Pooling应用于夸克/胶子喷注分类的对撞机物理任务，通过将Energy Flow Networks（EFNs）扩展为Moment EFNs。我们发现，具有小至1的潜在维度的Moment EFNs表现与具有较高潜在维度的普通EFNs类似。这种小潜在维度使内部表示可以直接可视化和解释。",
    "tldr": "提出了一种称为Moment Pooling的新方法，通过将Deep Sets中的求和泛化为任意的多变量矩，显著降低机器学习网络的潜在空间维度，在固定的潜在维度下实现更高的有效潜在维度，从而可以直接可视化和解释内部表示。",
    "en_tdlr": "Proposed a new method called Moment Pooling, which generalizes the summation in Deep Sets to arbitrary multivariate moments, significantly reducing the latent space dimensionality of machine learning networks, achieving a higher effective latent dimensionality for a fixed latent dimension, allowing for direct visualization and interpretation of the internal representation."
}