{
    "title": "Counterfactual Image Editing",
    "abstract": "arXiv:2403.09683v1 Announce Type: cross  Abstract: Counterfactual image editing is an important task in generative AI, which asks how an image would look if certain features were different. The current literature on the topic focuses primarily on changing individual features while remaining silent about the causal relationships between these features, as present in the real world. In this paper, we formalize the counterfactual image editing task using formal language, modeling the causal relationships between latent generative factors and images through a special type of model called augmented structural causal models (ASCMs). Second, we show two fundamental impossibility results: (1) counterfactual editing is impossible from i.i.d. image samples and their corresponding labels alone; (2) even when the causal relationships between the latent generative factors and images are available, no guarantees regarding the output of the model can be provided. Third, we propose a relaxation for th",
    "link": "https://arxiv.org/abs/2403.09683",
    "context": "Title: Counterfactual Image Editing\nAbstract: arXiv:2403.09683v1 Announce Type: cross  Abstract: Counterfactual image editing is an important task in generative AI, which asks how an image would look if certain features were different. The current literature on the topic focuses primarily on changing individual features while remaining silent about the causal relationships between these features, as present in the real world. In this paper, we formalize the counterfactual image editing task using formal language, modeling the causal relationships between latent generative factors and images through a special type of model called augmented structural causal models (ASCMs). Second, we show two fundamental impossibility results: (1) counterfactual editing is impossible from i.i.d. image samples and their corresponding labels alone; (2) even when the causal relationships between the latent generative factors and images are available, no guarantees regarding the output of the model can be provided. Third, we propose a relaxation for th",
    "path": "papers/24/03/2403.09683.json",
    "total_tokens": 869,
    "translated_title": "对事实图像编辑",
    "translated_abstract": "对事实图像编辑是生成人工智能中的一项重要任务，它询问了如果某些特征不同，图像将会呈现怎样的外观。目前关于这个话题的文献主要集中在改变单个特征上，却不谈论这些特征之间的因果关系，而这是真实世界中所存在的。本文使用形式语言对对事实图像编辑任务加以形式化，并通过一种称为增强结构因果模型（ASCMs）的特殊模型来对潜在生成因素与图像之间的因果关系进行建模。其次，我们展示了两个基本的不可能结果：（1）仅仅依靠i.i.d.图像样本及其对应标签是不可能进行对事实编辑的；（2）即使潜在生成因素与图像之间的因果关系是可用的，也无法保证模型输出的结果。第三，我们为这一问题提出了一种放松的解决方案。",
    "tldr": "本文提出了对事实图像编辑的形式化方法，展示了基于i.i.d.图像样本和标签进行对事实编辑的不可能性，并指出即使知晓潜在生成因素与图像之间的因果关系，也无法提供关于模型输出结果的任何保证。",
    "en_tdlr": "This paper formalizes the task of counterfactual image editing, demonstrates the impossibility of counterfactual editing based on i.i.d. image samples and labels, and highlights the lack of guarantees on model output even when causal relationships between latent generative factors and images are known."
}