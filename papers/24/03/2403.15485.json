{
    "title": "MOGAM: A Multimodal Object-oriented Graph Attention Model for Depression Detection",
    "abstract": "arXiv:2403.15485v1 Announce Type: cross  Abstract: Early detection plays a crucial role in the treatment of depression. Therefore, numerous studies have focused on social media platforms, where individuals express their emotions, aiming to achieve early detection of depression. However, the majority of existing approaches often rely on specific features, leading to limited scalability across different types of social media datasets, such as text, images, or videos. To overcome this limitation, we introduce a Multimodal Object-Oriented Graph Attention Model (MOGAM), which can be applied to diverse types of data, offering a more scalable and versatile solution. Furthermore, to ensure that our model can capture authentic symptoms of depression, we only include vlogs from users with a clinical diagnosis. To leverage the diverse features of vlogs, we adopt a multimodal approach and collect additional metadata such as the title, description, and duration of the vlogs. To effectively aggregat",
    "link": "https://arxiv.org/abs/2403.15485",
    "context": "Title: MOGAM: A Multimodal Object-oriented Graph Attention Model for Depression Detection\nAbstract: arXiv:2403.15485v1 Announce Type: cross  Abstract: Early detection plays a crucial role in the treatment of depression. Therefore, numerous studies have focused on social media platforms, where individuals express their emotions, aiming to achieve early detection of depression. However, the majority of existing approaches often rely on specific features, leading to limited scalability across different types of social media datasets, such as text, images, or videos. To overcome this limitation, we introduce a Multimodal Object-Oriented Graph Attention Model (MOGAM), which can be applied to diverse types of data, offering a more scalable and versatile solution. Furthermore, to ensure that our model can capture authentic symptoms of depression, we only include vlogs from users with a clinical diagnosis. To leverage the diverse features of vlogs, we adopt a multimodal approach and collect additional metadata such as the title, description, and duration of the vlogs. To effectively aggregat",
    "path": "papers/24/03/2403.15485.json",
    "total_tokens": 892,
    "translated_title": "MOGAM：一种用于抑郁症检测的多模态面向对象图注意模型",
    "translated_abstract": "早期检测在抑郁症治疗中起着至关重要的作用。因此，许多研究关注社交媒体平台，个体在该平台表达情绪，旨在实现抑郁症的早期检测。然而，现有方法主要依赖特定特征，导致在不同类型的社交媒体数据集（如文本、图像或视频）上的可扩展性有限。为克服这一限制，我们引入了一种多模态面向对象图注意模型（MOGAM），可应用于各种数据类型，提供更具可伸缩性和多功能性的解决方案。此外，为确保我们的模型能够捕捉抑郁症的真实症状，我们仅收集了具有临床诊断的用户的视频日志。为了利用视频日志的多样特征，我们采用多模态方法，并收集额外的元数据，如视频日志的标题、描述和持续时间。为了有效地聚合",
    "tldr": "MOGAM模型是为了克服现有抑郁症检测方法在不同社交媒体数据类型上的限制而提出，通过多模态数据的综合应用，实现了更具可扩展性和多功能性的解决方案。",
    "en_tdlr": "MOGAM model is proposed to overcome the limitations of existing depression detection methods across different types of social media data by leveraging multimodal data, offering a more scalable and versatile solution."
}