{
    "title": "Reinforcement Learning Jazz Improvisation: When Music Meets Game Theory",
    "abstract": "arXiv:2403.03224v1 Announce Type: cross  Abstract: Live performances of music are always charming, with the unpredictability of improvisation due to the dynamic between musicians and interactions with the audience. Jazz improvisation is a particularly noteworthy example for further investigation from a theoretical perspective. Here, we introduce a novel mathematical game theory model for jazz improvisation, providing a framework for studying music theory and improvisational methodologies. We use computational modeling, mainly reinforcement learning, to explore diverse stochastic improvisational strategies and their paired performance on improvisation. We find that the most effective strategy pair is a strategy that reacts to the most recent payoff (Stepwise Changes) with a reinforcement learning strategy limited to notes in the given chord (Chord-Following Reinforcement Learning). Conversely, a strategy that reacts to the partner's last note and attempts to harmonize with it (Harmony P",
    "link": "https://arxiv.org/abs/2403.03224",
    "context": "Title: Reinforcement Learning Jazz Improvisation: When Music Meets Game Theory\nAbstract: arXiv:2403.03224v1 Announce Type: cross  Abstract: Live performances of music are always charming, with the unpredictability of improvisation due to the dynamic between musicians and interactions with the audience. Jazz improvisation is a particularly noteworthy example for further investigation from a theoretical perspective. Here, we introduce a novel mathematical game theory model for jazz improvisation, providing a framework for studying music theory and improvisational methodologies. We use computational modeling, mainly reinforcement learning, to explore diverse stochastic improvisational strategies and their paired performance on improvisation. We find that the most effective strategy pair is a strategy that reacts to the most recent payoff (Stepwise Changes) with a reinforcement learning strategy limited to notes in the given chord (Chord-Following Reinforcement Learning). Conversely, a strategy that reacts to the partner's last note and attempts to harmonize with it (Harmony P",
    "path": "papers/24/03/2403.03224.json",
    "total_tokens": 931,
    "translated_title": "强化学习爵士即兴演奏：音乐遇上博弈论",
    "translated_abstract": "音乐的现场表演总是迷人的，即兴演奏的不可预测性是由于音乐家之间的动态关系和与观众的互动。爵士即兴演奏是一个特别值得从理论视角进一步研究的例子。本文引入了一个新颖的数学博弈论模型来研究爵士即兴演奏，为研究音乐理论和即兴演奏方法学提供了一个框架。我们使用计算建模，主要是强化学习，来探索不同的随机即兴策略及其在即兴演奏中的配对表现。我们发现，最有效的策略对是一种对最近收益作出反应的策略（逐步改变），配合强化学习策略，其仅限于给定和弦中的音符（和弦跟随强化学习）。相反，一种对伙伴的上一个音符作出反应，并试图与之和谐的策略（和谐P",
    "tldr": "介绍了一个新颖的数学博弈论模型用于研究爵士即兴演奏，探索不同的随机即兴策略和其在即兴演奏中的配对表现，发现最有效的策略对是逐步改变和和弦跟随强化学习。",
    "en_tdlr": "Introduces a novel mathematical game theory model for jazz improvisation, explores various stochastic improvisational strategies and their paired performance, finding that the most effective strategy pair consists of Stepwise Changes and Chord-Following Reinforcement Learning."
}