{
    "title": "Crimson: Empowering Strategic Reasoning in Cybersecurity through Large Language Models",
    "abstract": "arXiv:2403.00878v1 Announce Type: cross  Abstract: We introduces Crimson, a system that enhances the strategic reasoning capabilities of Large Language Models (LLMs) within the realm of cybersecurity. By correlating CVEs with MITRE ATT&CK techniques, Crimson advances threat anticipation and strategic defense efforts. Our approach includes defining and evaluating cybersecurity strategic tasks, alongside implementing a comprehensive human-in-the-loop data-synthetic workflow to develop the CVE-to-ATT&CK Mapping (CVEM) dataset. We further enhance LLMs' reasoning abilities through a novel Retrieval-Aware Training (RAT) process and its refined iteration, RAT-R.   Our findings demonstrate that an LLM fine-tuned with our techniques, possessing 7 billion parameters, approaches the performance level of GPT-4, showing markedly lower rates of hallucination and errors, and surpassing other models in strategic reasoning tasks. Moreover, domain-specific fine-tuning of embedding models significantly i",
    "link": "https://arxiv.org/abs/2403.00878",
    "context": "Title: Crimson: Empowering Strategic Reasoning in Cybersecurity through Large Language Models\nAbstract: arXiv:2403.00878v1 Announce Type: cross  Abstract: We introduces Crimson, a system that enhances the strategic reasoning capabilities of Large Language Models (LLMs) within the realm of cybersecurity. By correlating CVEs with MITRE ATT&CK techniques, Crimson advances threat anticipation and strategic defense efforts. Our approach includes defining and evaluating cybersecurity strategic tasks, alongside implementing a comprehensive human-in-the-loop data-synthetic workflow to develop the CVE-to-ATT&CK Mapping (CVEM) dataset. We further enhance LLMs' reasoning abilities through a novel Retrieval-Aware Training (RAT) process and its refined iteration, RAT-R.   Our findings demonstrate that an LLM fine-tuned with our techniques, possessing 7 billion parameters, approaches the performance level of GPT-4, showing markedly lower rates of hallucination and errors, and surpassing other models in strategic reasoning tasks. Moreover, domain-specific fine-tuning of embedding models significantly i",
    "path": "papers/24/03/2403.00878.json",
    "total_tokens": 861,
    "translated_title": "Crimson: 通过大型语言模型增强网络安全领域的战略推理能力",
    "translated_abstract": "我们介绍了Crimson，这是一个系统，通过将CVE与MITRE ATT&CK技术相关联，增强了大型语言模型（LLMs）在网络安全领域的战略推理能力。我们的方法包括定义和评估网络安全战略任务，以及实施全面的人机协作数据合成工作流程，以开发CVE到ATT&CK映射（CVEM）数据集。我们通过一种新颖的“检索感知训练”（RAT）过程及其改进的迭代RAT-R进一步提高了LLMs的推理能力。我们的研究结果表明，通过我们的技术对具有70亿参数的LLM进行微调，性能接近GPT-4，显示出幻觉和错误率明显降低，并在战略推理任务中超越其他模型。此外，对嵌入模型进行领域特定微调显著地提高了",
    "tldr": "Crimson系统通过将CVE与MITRE ATT&CK技术相关联，提升了大型语言模型在网络安全中的战略推理能力，实现了接近GPT-4性能水平，且在战略推理任务中表现优异。"
}