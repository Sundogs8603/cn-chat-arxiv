{
    "title": "Early Period of Training Impacts Out-of-Distribution Generalization",
    "abstract": "arXiv:2403.15210v1 Announce Type: new  Abstract: Prior research has found that differences in the early period of neural network training significantly impact the performance of in-distribution (ID) tasks. However, neural networks are often sensitive to out-of-distribution (OOD) data, making them less reliable in downstream applications. Yet, the impact of the early training period on OOD generalization remains understudied due to its complexity and lack of effective analytical methodologies. In this work, we investigate the relationship between learning dynamics and OOD generalization during the early period of neural network training. We utilize the trace of Fisher Information and sharpness, with a focus on gradual unfreezing (i.e. progressively unfreezing parameters during training) as the methodology for investigation. Through a series of empirical experiments, we show that 1) selecting the number of trainable parameters at different times during training, i.e. realized by gradual ",
    "link": "https://arxiv.org/abs/2403.15210",
    "context": "Title: Early Period of Training Impacts Out-of-Distribution Generalization\nAbstract: arXiv:2403.15210v1 Announce Type: new  Abstract: Prior research has found that differences in the early period of neural network training significantly impact the performance of in-distribution (ID) tasks. However, neural networks are often sensitive to out-of-distribution (OOD) data, making them less reliable in downstream applications. Yet, the impact of the early training period on OOD generalization remains understudied due to its complexity and lack of effective analytical methodologies. In this work, we investigate the relationship between learning dynamics and OOD generalization during the early period of neural network training. We utilize the trace of Fisher Information and sharpness, with a focus on gradual unfreezing (i.e. progressively unfreezing parameters during training) as the methodology for investigation. Through a series of empirical experiments, we show that 1) selecting the number of trainable parameters at different times during training, i.e. realized by gradual ",
    "path": "papers/24/03/2403.15210.json",
    "total_tokens": 854,
    "translated_title": "训练早期影响超出分布泛化",
    "translated_abstract": "先前的研究发现神经网络训练的早期阶段的差异显著影响分布内（ID）任务的表现。然而，神经网络往往对超出分布（OOD）数据敏感，在下游应用中变得不太可靠。然而，由于其复杂性和缺乏有效的分析方法，早期训练阶段对OOD泛化的影响仍未得到充分研究。在这项工作中，我们研究了学习动态和神经网络训练早期阶段的OOD泛化之间的关系。我们利用Fisher信息的痕迹和锐利度，重点关注渐进解冻（即在训练过程中逐渐解冻参数）作为研究方法。通过一系列实证实验，我们展示了1）在训练过程中选择不同时间点的可训练参数数量，即逐渐解冻的实现方式",
    "tldr": "神经网络训练早期阶段的影响对超出分布泛化进行了研究，通过探究学习动态和用于调查的渐进解冻方法，揭示了其重要性。",
    "en_tdlr": "This work investigates the impact of the early period of neural network training on out-of-distribution generalization, revealing its significance through exploring the learning dynamics and utilizing gradual unfreezing for investigation."
}