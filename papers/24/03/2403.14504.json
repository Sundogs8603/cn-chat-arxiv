{
    "title": "Soft Learning Probabilistic Circuits",
    "abstract": "arXiv:2403.14504v1 Announce Type: cross  Abstract: Probabilistic Circuits (PCs) are prominent tractable probabilistic models, allowing for a range of exact inferences. This paper focuses on the main algorithm for training PCs, LearnSPN, a gold standard due to its efficiency, performance, and ease of use, in particular for tabular data. We show that LearnSPN is a greedy likelihood maximizer under mild assumptions. While inferences in PCs may use the entire circuit structure for processing queries, LearnSPN applies a hard method for learning them, propagating at each sum node a data point through one and only one of the children/edges as in a hard clustering process. We propose a new learning procedure named SoftLearn, that induces a PC using a soft clustering process. We investigate the effect of this learning-inference compatibility in PCs. Our experiments show that SoftLearn outperforms LearnSPN in many situations, yielding better likelihoods and arguably better samples. We also analy",
    "link": "https://arxiv.org/abs/2403.14504",
    "context": "Title: Soft Learning Probabilistic Circuits\nAbstract: arXiv:2403.14504v1 Announce Type: cross  Abstract: Probabilistic Circuits (PCs) are prominent tractable probabilistic models, allowing for a range of exact inferences. This paper focuses on the main algorithm for training PCs, LearnSPN, a gold standard due to its efficiency, performance, and ease of use, in particular for tabular data. We show that LearnSPN is a greedy likelihood maximizer under mild assumptions. While inferences in PCs may use the entire circuit structure for processing queries, LearnSPN applies a hard method for learning them, propagating at each sum node a data point through one and only one of the children/edges as in a hard clustering process. We propose a new learning procedure named SoftLearn, that induces a PC using a soft clustering process. We investigate the effect of this learning-inference compatibility in PCs. Our experiments show that SoftLearn outperforms LearnSPN in many situations, yielding better likelihoods and arguably better samples. We also analy",
    "path": "papers/24/03/2403.14504.json",
    "total_tokens": 868,
    "translated_title": "软学习概率电路",
    "translated_abstract": "概率电路（PCs)是杰出的可计算概率模型，允许进行一系列准确推理。该论文专注于主要的 PC 训练算法 LearnSPN，由于其效率、性能和易用性而成为金标准，特别适用于表格数据。我们表明在温和假设下，LearnSPN 是一种贪心似然最大化器。虽然在 PC 中，推理可以利用整个电路结构来处理查询，但 LearnSPN 应用了一种硬方法来学习它们，通过在每个求和节点上通过一个而仅一个子/边的数据点进行传播，就像在一个硬聚类过程中一样。我们提出了一种名为 SoftLearn 的新学习程序，它通过软聚类过程诱导出一个 PC。我们调查了这种学习-推理兼容性在 PC 中的影响。我们的实验表明，SoftLearn 在许多情况下优于 LearnSPN，产生更好的似然值，可能还产生更好的样本。",
    "tldr": "该论文提出了一种新的学习过程 SoftLearn，通过软聚类过程诱导出一个 PC，相较于传统的 LearnSPN，在许多情况下表现更好，产生更好的似然值和样本。",
    "en_tdlr": "This paper introduces a new learning process SoftLearn, which induces a PC through a soft clustering process, outperforming traditional LearnSPN in many cases by producing better likelihoods and samples."
}