{
    "title": "LMStyle Benchmark: Evaluating Text Style Transfer for Chatbots",
    "abstract": "arXiv:2403.08943v1 Announce Type: new  Abstract: Since the breakthrough of ChatGPT, large language models (LLMs) have garnered significant attention in the research community. With the development of LLMs, the question of text style transfer for conversational models has emerged as a natural extension, where chatbots may possess their own styles or even characters. However, standard evaluation metrics have not yet been established for this new settings. This paper aims to address this issue by proposing the LMStyle Benchmark, a novel evaluation framework applicable to chat-style text style transfer (C-TST), that can measure the quality of style transfer for LLMs in an automated and scalable manner. In addition to conventional style strength metrics, LMStyle Benchmark further considers a novel aspect of metrics called appropriateness, a high-level metrics take account of coherence, fluency and other implicit factors without the aid of reference samples. Our experiments demonstrate that ",
    "link": "https://arxiv.org/abs/2403.08943",
    "context": "Title: LMStyle Benchmark: Evaluating Text Style Transfer for Chatbots\nAbstract: arXiv:2403.08943v1 Announce Type: new  Abstract: Since the breakthrough of ChatGPT, large language models (LLMs) have garnered significant attention in the research community. With the development of LLMs, the question of text style transfer for conversational models has emerged as a natural extension, where chatbots may possess their own styles or even characters. However, standard evaluation metrics have not yet been established for this new settings. This paper aims to address this issue by proposing the LMStyle Benchmark, a novel evaluation framework applicable to chat-style text style transfer (C-TST), that can measure the quality of style transfer for LLMs in an automated and scalable manner. In addition to conventional style strength metrics, LMStyle Benchmark further considers a novel aspect of metrics called appropriateness, a high-level metrics take account of coherence, fluency and other implicit factors without the aid of reference samples. Our experiments demonstrate that ",
    "path": "papers/24/03/2403.08943.json",
    "total_tokens": 882,
    "translated_title": "LMStyle基准：评估用于聊天机器人的文本风格转移",
    "translated_abstract": "自ChatGPT突破以来，大型语言模型(LLMs)在研究界引起了极大关注。随着LLMs的发展，文本风格转移对话模型的问题已成为自然延伸，其中聊天机器人可能拥有自己的风格甚至特色。然而，针对这种新设置尚未建立标准评估指标。本文旨在通过提出LMStyle基准来解决这一问题，这是一个新颖的评估框架，适用于聊天风格文本风格转移(C-TST)，可自动化和可扩展地衡量LLMs的风格转移质量。除了传统的风格强度指标外，LMStyle基准还考虑了一个称为适当性的新颖度量方面，一个高水平指标，考虑了连贯性、流畅性和其他隐含因素，无需参考样本的帮助。我们的实验表明",
    "tldr": "该论文提出了LMStyle基准，针对聊天机器人的文本风格转移进行评估，不仅可以自动化和可扩展地衡量LLMs的风格转移质量，还考虑了适当性这一新颖度量方面。",
    "en_tdlr": "This paper introduces the LMStyle Benchmark for evaluating text style transfer for chatbots, which not only measures the quality of style transfer for LLMs in an automated and scalable manner, but also considers a novel aspect of appropriateness metrics."
}