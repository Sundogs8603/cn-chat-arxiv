{
    "title": "TRELM: Towards Robust and Efficient Pre-training for Knowledge-Enhanced Language Models",
    "abstract": "arXiv:2403.11203v1 Announce Type: new  Abstract: KEPLMs are pre-trained models that utilize external knowledge to enhance language understanding. Previous language models facilitated knowledge acquisition by incorporating knowledge-related pre-training tasks learned from relation triples in knowledge graphs. However, these models do not prioritize learning embeddings for entity-related tokens. Moreover, updating the entire set of parameters in KEPLMs is computationally demanding. This paper introduces TRELM, a Robust and Efficient Pre-training framework for Knowledge-Enhanced Language Models. We observe that entities in text corpora usually follow the long-tail distribution, where the representations of some entities are suboptimally optimized and hinder the pre-training process for KEPLMs. To tackle this, we employ a robust approach to inject knowledge triples and employ a knowledge-augmented memory bank to capture valuable information. Furthermore, updating a small subset of neurons ",
    "link": "https://arxiv.org/abs/2403.11203",
    "context": "Title: TRELM: Towards Robust and Efficient Pre-training for Knowledge-Enhanced Language Models\nAbstract: arXiv:2403.11203v1 Announce Type: new  Abstract: KEPLMs are pre-trained models that utilize external knowledge to enhance language understanding. Previous language models facilitated knowledge acquisition by incorporating knowledge-related pre-training tasks learned from relation triples in knowledge graphs. However, these models do not prioritize learning embeddings for entity-related tokens. Moreover, updating the entire set of parameters in KEPLMs is computationally demanding. This paper introduces TRELM, a Robust and Efficient Pre-training framework for Knowledge-Enhanced Language Models. We observe that entities in text corpora usually follow the long-tail distribution, where the representations of some entities are suboptimally optimized and hinder the pre-training process for KEPLMs. To tackle this, we employ a robust approach to inject knowledge triples and employ a knowledge-augmented memory bank to capture valuable information. Furthermore, updating a small subset of neurons ",
    "path": "papers/24/03/2403.11203.json",
    "total_tokens": 883,
    "translated_title": "TRELM: 面向知识增强语言模型的稳健高效预训练",
    "translated_abstract": "KEPLM是利用外部知识增强语言理解的预训练模型。之前的语言模型通过在知识图谱中学习关系三元组来促进知识获取。然而，这些模型并未优先学习与实体相关的令牌的嵌入。此外，更新KEPLM中的全部参数在计算上是费时的。本文介绍了TRELM，一种面向知识增强语言模型的稳健高效预训练框架。我们观察到文本语料库中的实体通常遵循长尾分布，一些实体的表示未经优化，妨碍了KEPLM的预训练过程。为了解决这个问题，我们采用了一种稳健方法来注入知识三元组，并采用了知识增强的存储库来捕获有价值的信息。此外，只更新小部分神经元",
    "tldr": "本文介绍了TRELM，一种面向知识增强语言模型的稳健高效预训练框架，通过采用稳健方法注入知识三元组和知识增强的存储库来解决实体表示优化不足和预训练过程的问题。",
    "en_tdlr": "This paper introduces TRELM, a robust and efficient pre-training framework for knowledge-enhanced language models, tackling the issues of suboptimal entity representations and pre-training process by employing a robust approach to inject knowledge triples and a knowledge-augmented memory bank."
}