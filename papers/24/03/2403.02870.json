{
    "title": "Precise Extraction of Deep Learning Models via Side-Channel Attacks on Edge/Endpoint Devices",
    "abstract": "arXiv:2403.02870v1 Announce Type: new  Abstract: With growing popularity, deep learning (DL) models are becoming larger-scale, and only the companies with vast training datasets and immense computing power can manage their business serving such large models. Most of those DL models are proprietary to the companies who thus strive to keep their private models safe from the model extraction attack (MEA), whose aim is to steal the model by training surrogate models. Nowadays, companies are inclined to offload the models from central servers to edge/endpoint devices. As revealed in the latest studies, adversaries exploit this opportunity as new attack vectors to launch side-channel attack (SCA) on the device running victim model and obtain various pieces of the model information, such as the model architecture (MA) and image dimension (ID). Our work provides a comprehensive understanding of such a relationship for the first time and would benefit future MEA studies in both offensive and de",
    "link": "https://arxiv.org/abs/2403.02870",
    "context": "Title: Precise Extraction of Deep Learning Models via Side-Channel Attacks on Edge/Endpoint Devices\nAbstract: arXiv:2403.02870v1 Announce Type: new  Abstract: With growing popularity, deep learning (DL) models are becoming larger-scale, and only the companies with vast training datasets and immense computing power can manage their business serving such large models. Most of those DL models are proprietary to the companies who thus strive to keep their private models safe from the model extraction attack (MEA), whose aim is to steal the model by training surrogate models. Nowadays, companies are inclined to offload the models from central servers to edge/endpoint devices. As revealed in the latest studies, adversaries exploit this opportunity as new attack vectors to launch side-channel attack (SCA) on the device running victim model and obtain various pieces of the model information, such as the model architecture (MA) and image dimension (ID). Our work provides a comprehensive understanding of such a relationship for the first time and would benefit future MEA studies in both offensive and de",
    "path": "papers/24/03/2403.02870.json",
    "total_tokens": 902,
    "translated_title": "通过边缘/端点设备的侧信道攻击精确提取深度学习模型",
    "translated_abstract": "随着深度学习（DL）模型日益普及，模型规模越来越大，只有拥有庞大训练数据集和巨大计算能力的公司才能应对业务需求的这些大型模型。大多数DL模型是公司专有的，因此这些公司努力保护他们的私有模型，以免受到模型提取攻击（MEA）的侵害，该攻击目的是通过训练代理模型来窃取模型。如今，公司倾向于将模型从中央服务器转移到边缘/端点设备。正如最新研究揭示的那样，攻击者利用这一机会作为启动侧信道攻击（SCA）的新攻击向量，针对运行受害模型的设备发动攻击，获取模型信息的各种要点，例如模型架构（MA）和图像维度（ID）。我们的工作首次全面理解了这种关系，将有助于未来MEA研究在进攻和防御方面取得进展。",
    "tldr": "该研究揭示了对深度学习模型进行精确提取的新型攻击方法，通过边缘/端点设备的侧信道攻击可以获取模型架构和图像维度等重要信息。"
}