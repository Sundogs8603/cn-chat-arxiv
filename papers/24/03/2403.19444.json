{
    "title": "Transparent and Clinically Interpretable AI for Lung Cancer Detection in Chest X-Rays",
    "abstract": "arXiv:2403.19444v1 Announce Type: new  Abstract: The rapidly advancing field of Explainable Artificial Intelligence (XAI) aims to tackle the issue of trust regarding the use of complex black-box deep learning models in real-world applications. Existing post-hoc XAI techniques have recently been shown to have poor performance on medical data, producing unreliable explanations which are infeasible for clinical use. To address this, we propose an ante-hoc approach based on concept bottleneck models which introduces for the first time clinical concepts into the classification pipeline, allowing the user valuable insight into the decision-making process. On a large public dataset of chest X-rays and associated medical reports, we focus on the binary classification task of lung cancer detection. Our approach yields improved classification performance in lung cancer detection when compared to baseline deep learning models (F1 > 0.9), while also generating clinically relevant and more reliable",
    "link": "https://arxiv.org/abs/2403.19444",
    "context": "Title: Transparent and Clinically Interpretable AI for Lung Cancer Detection in Chest X-Rays\nAbstract: arXiv:2403.19444v1 Announce Type: new  Abstract: The rapidly advancing field of Explainable Artificial Intelligence (XAI) aims to tackle the issue of trust regarding the use of complex black-box deep learning models in real-world applications. Existing post-hoc XAI techniques have recently been shown to have poor performance on medical data, producing unreliable explanations which are infeasible for clinical use. To address this, we propose an ante-hoc approach based on concept bottleneck models which introduces for the first time clinical concepts into the classification pipeline, allowing the user valuable insight into the decision-making process. On a large public dataset of chest X-rays and associated medical reports, we focus on the binary classification task of lung cancer detection. Our approach yields improved classification performance in lung cancer detection when compared to baseline deep learning models (F1 > 0.9), while also generating clinically relevant and more reliable",
    "path": "papers/24/03/2403.19444.json",
    "total_tokens": 920,
    "translated_title": "透明且临床可解释的人工智能用于胸部X射线肺癌检测",
    "translated_abstract": "arXiv:2403.19444v1 公告类型：新 简要摘要：透明人工智能（XAI）领域正在迅速发展，旨在解决复杂黑匣子深度学习模型在现实应用中的信任问题。现有的事后XAI技术最近已被证明在医疗数据上表现不佳，产生不可靠的解释，不适合临床使用。为解决这一问题，我们提出了一种基于概念瓶颈模型的ante-hoc方法，首次将临床概念引入分类管道，使用户可以深入了解决策过程。在一个大型公共数据集上，我们聚焦于胸部X射线和相关医疗报告的二元分类任务，即肺癌的检测。与基准深度学习模型相比，我们的方法在肺癌检测中获得了更好的分类性能（F1 > 0.9），同时生成了临床相关且更可靠的解释。",
    "tldr": "使用概念瓶颈模型的ante-hoc方法将临床概念引入到分类管道中，提供了肺癌检测决策过程中的有价值见解，相较于基线深度学习模型实现了更好的分类性能（F1 > 0.9）。",
    "en_tdlr": "An ante-hoc approach based on concept bottleneck models introduces clinical concepts into the classification pipeline, providing valuable insights into the decision-making process for lung cancer detection and outperforming baseline deep learning models with improved classification performance (F1 > 0.9)."
}