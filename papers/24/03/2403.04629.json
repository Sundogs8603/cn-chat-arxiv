{
    "title": "Explaining Bayesian Optimization by Shapley Values Facilitates Human-AI Collaboration",
    "abstract": "arXiv:2403.04629v1 Announce Type: cross  Abstract: Bayesian optimization (BO) with Gaussian processes (GP) has become an indispensable algorithm for black box optimization problems. Not without a dash of irony, BO is often considered a black box itself, lacking ways to provide reasons as to why certain parameters are proposed to be evaluated. This is particularly relevant in human-in-the-loop applications of BO, such as in robotics. We address this issue by proposing ShapleyBO, a framework for interpreting BO's proposals by game-theoretic Shapley values.They quantify each parameter's contribution to BO's acquisition function. Exploiting the linearity of Shapley values, we are further able to identify how strongly each parameter drives BO's exploration and exploitation for additive acquisition functions like the confidence bound. We also show that ShapleyBO can disentangle the contributions to exploration into those that explore aleatoric and epistemic uncertainty. Moreover, our method ",
    "link": "https://arxiv.org/abs/2403.04629",
    "context": "Title: Explaining Bayesian Optimization by Shapley Values Facilitates Human-AI Collaboration\nAbstract: arXiv:2403.04629v1 Announce Type: cross  Abstract: Bayesian optimization (BO) with Gaussian processes (GP) has become an indispensable algorithm for black box optimization problems. Not without a dash of irony, BO is often considered a black box itself, lacking ways to provide reasons as to why certain parameters are proposed to be evaluated. This is particularly relevant in human-in-the-loop applications of BO, such as in robotics. We address this issue by proposing ShapleyBO, a framework for interpreting BO's proposals by game-theoretic Shapley values.They quantify each parameter's contribution to BO's acquisition function. Exploiting the linearity of Shapley values, we are further able to identify how strongly each parameter drives BO's exploration and exploitation for additive acquisition functions like the confidence bound. We also show that ShapleyBO can disentangle the contributions to exploration into those that explore aleatoric and epistemic uncertainty. Moreover, our method ",
    "path": "papers/24/03/2403.04629.json",
    "total_tokens": 835,
    "translated_title": "用Shapley值解释贝叶斯优化促进人工智能与人类协作",
    "translated_abstract": "贝叶斯优化（BO）与高斯过程（GP）已成为解决黑匣子优化问题的不可或缺的算法。然而，BO本身也常常被认为是一个黑匣子，缺乏提供为何提议评估某些参数的理由的方法。我们通过提出ShapleyBO来解决这个问题，这是一个用博弈论Shapley值解释BO提议的框架。它量化了每个参数对BO的收获函数的贡献。利用Shapley值的线性性，我们能够进一步确定每个参数对于像置信边界这样的加法收获函数推动BO的探索和开发的强度。我们还展示了ShapleyBO能够解决探索对于勘探aleatoric和认识epistemic不确定性的贡献。",
    "tldr": "提出了ShapleyBO框架，用Shapley值解释贝叶斯优化提议，量化每个参数对于优化过程的贡献，并能够区分不同类型的不确定性探索贡献。",
    "en_tdlr": "Introducing the ShapleyBO framework to interpret Bayesian optimization proposals with Shapley values, quantifying contributions of each parameter to the optimization process and distinguishing contributions of different types of uncertainty exploration."
}