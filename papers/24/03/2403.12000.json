{
    "title": "Notochord: a Flexible Probabilistic Model for Real-Time MIDI Performance",
    "abstract": "arXiv:2403.12000v1 Announce Type: cross  Abstract: Deep learning-based probabilistic models of musical data are producing increasingly realistic results and promise to enter creative workflows of many kinds. Yet they have been little-studied in a performance setting, where the results of user actions typically ought to feel instantaneous. To enable such study, we designed Notochord, a deep probabilistic model for sequences of structured events, and trained an instance of it on the Lakh MIDI dataset. Our probabilistic formulation allows interpretable interventions at a sub-event level, which enables one model to act as a backbone for diverse interactive musical functions including steerable generation, harmonization, machine improvisation, and likelihood-based interfaces. Notochord can generate polyphonic and multi-track MIDI, and respond to inputs with latency below ten milliseconds. Training code, model checkpoints and interactive examples are provided as open source software.",
    "link": "https://arxiv.org/abs/2403.12000",
    "context": "Title: Notochord: a Flexible Probabilistic Model for Real-Time MIDI Performance\nAbstract: arXiv:2403.12000v1 Announce Type: cross  Abstract: Deep learning-based probabilistic models of musical data are producing increasingly realistic results and promise to enter creative workflows of many kinds. Yet they have been little-studied in a performance setting, where the results of user actions typically ought to feel instantaneous. To enable such study, we designed Notochord, a deep probabilistic model for sequences of structured events, and trained an instance of it on the Lakh MIDI dataset. Our probabilistic formulation allows interpretable interventions at a sub-event level, which enables one model to act as a backbone for diverse interactive musical functions including steerable generation, harmonization, machine improvisation, and likelihood-based interfaces. Notochord can generate polyphonic and multi-track MIDI, and respond to inputs with latency below ten milliseconds. Training code, model checkpoints and interactive examples are provided as open source software.",
    "path": "papers/24/03/2403.12000.json",
    "total_tokens": 848,
    "translated_title": "Notochord：一种用于实时MIDI表演的灵活概率模型",
    "translated_abstract": "音乐数据基于深度学习的概率模型产生了越来越逼真的结果，并有望进入各种创作工作流程中。然而，在表演环境中对其实际效果进行研究还很少，用户行为的结果通常应该即时感知。为了促进这样的研究，我们设计了Notochord，这是一个用于结构化事件序列的深度概率模型，并在Lakh MIDI数据集上对其进行了训练。我们的概率形式允许在子事件级别进行可解释的干预，这使得一个模型可以作为多样交互音乐功能的基础，包括可操控的生成、和声、机器即兴和基于可能性的界面。Notochord可以生成多音轨MIDI并在十毫秒以下的延迟内响应输入。我们提供了训练代码，模型检查点和交互示例作为开源软件。",
    "tldr": "Notochord是一种灵活概率模型，能够在实时MIDI表演中生成多音轨MIDI并以低于10毫秒的延迟响应输入，支持多种交互音乐功能。",
    "en_tdlr": "Notochord is a flexible probabilistic model that can generate multi-track MIDI in real-time MIDI performance with a latency below 10 milliseconds, supporting various interactive musical functions."
}