{
    "title": "Depending on yourself when you should: Mentoring LLM with RL agents to become the master in cybersecurity games",
    "abstract": "arXiv:2403.17674v1 Announce Type: cross  Abstract: Integrating LLM and reinforcement learning (RL) agent effectively to achieve complementary performance is critical in high stake tasks like cybersecurity operations. In this study, we introduce SecurityBot, a LLM agent mentored by pre-trained RL agents, to support cybersecurity operations. In particularly, the LLM agent is supported with a profile module to generated behavior guidelines, a memory module to accumulate local experiences, a reflection module to re-evaluate choices, and an action module to reduce action space. Additionally, it adopts the collaboration mechanism to take suggestions from pre-trained RL agents, including a cursor for dynamic suggestion taken, an aggregator for multiple mentors' suggestions ranking and a caller for proactive suggestion asking. Building on the CybORG experiment framework, our experiences show that SecurityBot demonstrates significant performance improvement compared with LLM or RL standalone, a",
    "link": "https://arxiv.org/abs/2403.17674",
    "context": "Title: Depending on yourself when you should: Mentoring LLM with RL agents to become the master in cybersecurity games\nAbstract: arXiv:2403.17674v1 Announce Type: cross  Abstract: Integrating LLM and reinforcement learning (RL) agent effectively to achieve complementary performance is critical in high stake tasks like cybersecurity operations. In this study, we introduce SecurityBot, a LLM agent mentored by pre-trained RL agents, to support cybersecurity operations. In particularly, the LLM agent is supported with a profile module to generated behavior guidelines, a memory module to accumulate local experiences, a reflection module to re-evaluate choices, and an action module to reduce action space. Additionally, it adopts the collaboration mechanism to take suggestions from pre-trained RL agents, including a cursor for dynamic suggestion taken, an aggregator for multiple mentors' suggestions ranking and a caller for proactive suggestion asking. Building on the CybORG experiment framework, our experiences show that SecurityBot demonstrates significant performance improvement compared with LLM or RL standalone, a",
    "path": "papers/24/03/2403.17674.json",
    "total_tokens": 847,
    "translated_title": "在网络安全游戏中依靠自己的时候：通过强化学习代理指导LLM成为专家",
    "translated_abstract": "将LLM（生命周期长、记忆持续、自我评估的）与强化学习（RL）代理有效结合，以实现在网络安全等高风险任务中的协同性能至关重要。在本研究中，我们介绍了SecurityBot，这是一个由预训练RL代理指导的LLM代理，用于支持网络安全操作。该LLM代理具有概要模块以生成行为指南、记忆模块以累积本地经验、反思模块以重新评估选择，以及行动模块以减少行动空间。此外，它采用协作机制从预训练RL代理获得建议，包括用于动态建议的光标、用于多个导师建议排名的聚合器和用于主动建议请求的呼叫器。基于CybORG实验框架，我们的经验表明，与独立的LLM或RL相比，SecurityBot表现出显著的性能改进。",
    "tldr": "将预训练的强化学习代理指导的LLM代理SecurityBot用于网络安全操作，实现显著性能改进。",
    "en_tdlr": "Using pre-trained reinforcement learning agents to mentor the LLM agent, SecurityBot, results in significant performance improvements in cybersecurity operations compared to standalone LLM or RL agents."
}