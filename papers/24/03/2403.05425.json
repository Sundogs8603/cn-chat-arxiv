{
    "title": "An Adaptive Dimension Reduction Estimation Method for High-dimensional Bayesian Optimization",
    "abstract": "arXiv:2403.05425v1 Announce Type: new  Abstract: Bayesian optimization (BO) has shown impressive results in a variety of applications within low-to-moderate dimensional Euclidean spaces. However, extending BO to high-dimensional settings remains a significant challenge. We address this challenge by proposing a two-step optimization framework. Initially, we identify the effective dimension reduction (EDR) subspace for the objective function using the minimum average variance estimation (MAVE) method. Subsequently, we construct a Gaussian process model within this EDR subspace and optimize it using the expected improvement criterion. Our algorithm offers the flexibility to operate these steps either concurrently or in sequence. In the sequential approach, we meticulously balance the exploration-exploitation trade-off by distributing the sampling budget between subspace estimation and function optimization, and the convergence rate of our algorithm in high-dimensional contexts has been es",
    "link": "https://arxiv.org/abs/2403.05425",
    "context": "Title: An Adaptive Dimension Reduction Estimation Method for High-dimensional Bayesian Optimization\nAbstract: arXiv:2403.05425v1 Announce Type: new  Abstract: Bayesian optimization (BO) has shown impressive results in a variety of applications within low-to-moderate dimensional Euclidean spaces. However, extending BO to high-dimensional settings remains a significant challenge. We address this challenge by proposing a two-step optimization framework. Initially, we identify the effective dimension reduction (EDR) subspace for the objective function using the minimum average variance estimation (MAVE) method. Subsequently, we construct a Gaussian process model within this EDR subspace and optimize it using the expected improvement criterion. Our algorithm offers the flexibility to operate these steps either concurrently or in sequence. In the sequential approach, we meticulously balance the exploration-exploitation trade-off by distributing the sampling budget between subspace estimation and function optimization, and the convergence rate of our algorithm in high-dimensional contexts has been es",
    "path": "papers/24/03/2403.05425.json",
    "total_tokens": 885,
    "translated_title": "一种用于高维贝叶斯优化的自适应降维估计方法",
    "translated_abstract": "贝叶斯优化在低到中维欧几里得空间的各种应用中展现出了令人印象深刻的结果。然而，将贝叶斯优化扩展到高维设置仍然是一个重大挑战。我们通过提出一个两步优化框架来解决这一挑战。首先，我们使用最小平均方差估计（MAVE）方法识别目标函数的有效降维（EDR）子空间。随后，我们在该EDR子空间内构建一个高斯过程模型，并使用预期改进准则进行优化。我们的算法能够灵活地同时或顺序地执行这些步骤。在顺序方法中，我们通过在子空间估计和函数优化之间分配采样预算来仔细平衡探索利用的权衡，我们的算法在高维环境中的收敛速度已经得到改善。",
    "tldr": "提出一种两步优化框架，通过最小平均方差估计方法识别目标函数的有效降维子空间，然后在该子空间内构建高斯过程模型并进行优化，能够平衡探索与利用的权衡，提高在高维环境中的收敛速度",
    "en_tdlr": "Propose a two-step optimization framework by identifying the effective dimension reduction subspace for the objective function using the MAVE method, constructing a Gaussian process model within this subspace, balancing the exploration-exploitation trade-off, and improving the convergence rate in high-dimensional contexts."
}