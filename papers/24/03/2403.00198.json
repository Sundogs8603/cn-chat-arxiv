{
    "title": "AXOLOTL: Fairness through Assisted Self-Debiasing of Large Language Model Outputs",
    "abstract": "arXiv:2403.00198v1 Announce Type: cross  Abstract: Pre-trained Large Language Models (LLMs) have significantly advanced natural language processing capabilities but are susceptible to biases present in their training data, leading to unfair outcomes in various applications. While numerous strategies have been proposed to mitigate bias, they often require extensive computational resources and may compromise model performance. In this work, we introduce AXOLOTL, a novel post-processing framework, which operates agnostically across tasks and models, leveraging public APIs to interact with LLMs without direct access to internal parameters. Through a three-step process resembling zero-shot learning, AXOLOTL identifies biases, proposes resolutions, and guides the model to self-debias its outputs. This approach minimizes computational costs and preserves model performance, making AXOLOTL a promising tool for debiasing LLM outputs with broad applicability and ease of use.",
    "link": "https://arxiv.org/abs/2403.00198",
    "context": "Title: AXOLOTL: Fairness through Assisted Self-Debiasing of Large Language Model Outputs\nAbstract: arXiv:2403.00198v1 Announce Type: cross  Abstract: Pre-trained Large Language Models (LLMs) have significantly advanced natural language processing capabilities but are susceptible to biases present in their training data, leading to unfair outcomes in various applications. While numerous strategies have been proposed to mitigate bias, they often require extensive computational resources and may compromise model performance. In this work, we introduce AXOLOTL, a novel post-processing framework, which operates agnostically across tasks and models, leveraging public APIs to interact with LLMs without direct access to internal parameters. Through a three-step process resembling zero-shot learning, AXOLOTL identifies biases, proposes resolutions, and guides the model to self-debias its outputs. This approach minimizes computational costs and preserves model performance, making AXOLOTL a promising tool for debiasing LLM outputs with broad applicability and ease of use.",
    "path": "papers/24/03/2403.00198.json",
    "total_tokens": 874,
    "translated_title": "AXOLOTL：通过辅助自我去偏见大型语言模型输出实现公平性",
    "translated_abstract": "预训练的大型语言模型（LLMs）极大地推动了自然语言处理能力，但容易受其训练数据中存在的偏见影响，导致在各种应用中出现不公平结果。尽管已经提出了许多策略来减轻偏见，但它们通常需要大量计算资源，可能会损害模型性能。在这项工作中，我们介绍了AXOLOTL，这是一个新颖的后处理框架，能够独立于任务和模型运行，在不直接访问内部参数的情况下利用公共API与LLMs交互。通过类似零样本学习的三步过程，AXOLOTL识别偏见，提出解决方案，并指导模型自我去偏见其输出。这种方法最小化了计算成本，并保持了模型性能，使AXOLOTL成为一个具有广泛适用性和易用性的去偏见LLM输出的有前景工具。",
    "tldr": "AXOLOTL是一个新颖的后处理框架，通过零样本学习的三步过程，识别和解决偏见，指导模型自我去偏见其输出，从而实现公平性并保持模型性能。",
    "en_tdlr": "AXOLOTL is a novel post-processing framework that identifies and resolves biases through a three-step process resembling zero-shot learning, guiding the model to self-debias its outputs to achieve fairness while preserving model performance."
}