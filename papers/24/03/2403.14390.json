{
    "title": "From Large to Tiny: Distilling and Refining Mathematical Expertise for Math Word Problems with Weakly Supervision",
    "abstract": "arXiv:2403.14390v1 Announce Type: new  Abstract: Addressing the challenge of high annotation costs in solving Math Word Problems (MWPs) through full supervision with intermediate equations, recent works have proposed weakly supervised task settings that rely solely on the final answer as a supervised signal. Existing leading approaches typically employ various search techniques to infer intermediate equations, but cannot ensure their semantic consistency with natural language descriptions. The rise of Large Language Models (LLMs) like ChatGPT has opened up new possibilities for addressing MWPs directly. However, the computational demands of LLMs make them less than ideal for use in settings where resources are tight. In light of these challenges, we introduce an innovative two-stage framework that adeptly transfers mathematical Expertise from large to tiny language models. In \\emph{Distillation Stage}, we propose a series of extraction processes that satisfy the properties of MWPs to d",
    "link": "https://arxiv.org/abs/2403.14390",
    "context": "Title: From Large to Tiny: Distilling and Refining Mathematical Expertise for Math Word Problems with Weakly Supervision\nAbstract: arXiv:2403.14390v1 Announce Type: new  Abstract: Addressing the challenge of high annotation costs in solving Math Word Problems (MWPs) through full supervision with intermediate equations, recent works have proposed weakly supervised task settings that rely solely on the final answer as a supervised signal. Existing leading approaches typically employ various search techniques to infer intermediate equations, but cannot ensure their semantic consistency with natural language descriptions. The rise of Large Language Models (LLMs) like ChatGPT has opened up new possibilities for addressing MWPs directly. However, the computational demands of LLMs make them less than ideal for use in settings where resources are tight. In light of these challenges, we introduce an innovative two-stage framework that adeptly transfers mathematical Expertise from large to tiny language models. In \\emph{Distillation Stage}, we propose a series of extraction processes that satisfy the properties of MWPs to d",
    "path": "papers/24/03/2403.14390.json",
    "total_tokens": 819,
    "translated_title": "从大到小：利用弱监督对数学问题进行知识提炼和优化",
    "translated_abstract": "解决数学问题中高昂注释成本的挑战，通过使用中间方程式进行全面监督的最近研究提出了依赖最终答案作为监督信号的弱监督任务设置。现有的主导方法通常采用各种搜索技术来推断中间方程式，但无法保证其与自然语言描述的语义一致性。大型语言模型（LLM）如ChatGPT的崛起为直接解决数学问题打开了新的可能性。然而，LLMs的计算要求使它们在资源紧张的环境中使用时并不理想。鉴于这些挑战，我们引入了一种创新的两阶段框架，巧妙地将数学专业知识从大型语言模型转移到小型语言模型。在\\emph{蒸馏阶段}中，我们提出了一系列满足MWP属性的提取过程",
    "tldr": "提出了一种创新的两阶段框架，巧妙地将数学专业知识从大型语言模型转移到小型语言模型",
    "en_tdlr": "Introduced an innovative two-stage framework that adeptly transfers mathematical expertise from large to tiny language models."
}