{
    "title": "A Framework for Cost-Effective and Self-Adaptive LLM Shaking and Recovery Mechanism",
    "abstract": "arXiv:2403.07283v1 Announce Type: cross  Abstract: As Large Language Models (LLMs) gain great success in real-world applications, an increasing number of users are seeking to develop and deploy their customized LLMs through cloud services. Nonetheless, in some specific domains, there are still concerns regarding cost and trade-offs between privacy issues and accuracy. In this study, we introduce a cost-effective and self-adaptive LLM shaking tuning and recovery mechanism, named CypherTalk. With carefully designed horizontal and vertical shaking operators, we can achieve comparable accuracy results with SOTA privacy-preserving LLM schemes using Cryptography-based or Differential Privacy-based methods. Experiments also show that with the CypherTalk framework, users can achieve reliable accuracy when using optimized shaking operator settings. To our best knowledge, this is the first work that considers cost, and trade-off between model utility and privacy in LLM scenarios.",
    "link": "https://arxiv.org/abs/2403.07283",
    "context": "Title: A Framework for Cost-Effective and Self-Adaptive LLM Shaking and Recovery Mechanism\nAbstract: arXiv:2403.07283v1 Announce Type: cross  Abstract: As Large Language Models (LLMs) gain great success in real-world applications, an increasing number of users are seeking to develop and deploy their customized LLMs through cloud services. Nonetheless, in some specific domains, there are still concerns regarding cost and trade-offs between privacy issues and accuracy. In this study, we introduce a cost-effective and self-adaptive LLM shaking tuning and recovery mechanism, named CypherTalk. With carefully designed horizontal and vertical shaking operators, we can achieve comparable accuracy results with SOTA privacy-preserving LLM schemes using Cryptography-based or Differential Privacy-based methods. Experiments also show that with the CypherTalk framework, users can achieve reliable accuracy when using optimized shaking operator settings. To our best knowledge, this is the first work that considers cost, and trade-off between model utility and privacy in LLM scenarios.",
    "path": "papers/24/03/2403.07283.json",
    "total_tokens": 854,
    "translated_title": "一种成本效益和自适应的LLM摇晃和恢复机制框架",
    "translated_abstract": "随着大型语言模型（LLMs）在真实应用中取得巨大成功，越来越多的用户希望通过云服务开发和部署他们定制的LLMs。然而，在一些特定领域，人们仍然关注成本、隐私问题和准确性之间的权衡。本研究引入了一种名为CypherTalk的成本效益和自适应LLM摇晃调整和恢复机制，通过精心设计的水平和垂直摇晃操作符，我们能够实现与基于密码学或差分隐私方法的LLM隐私保护方案相当的准确性结果。实验证明，使用CypherTalk框架，用户可以在使用优化摇晃操作符设置时实现可靠的准确性。据我们所知，这是首个考虑在LLM场景中成本、模型效用和隐私之间权衡的工作。",
    "tldr": "介绍了一种名为CypherTalk的成本效益和自适应的LLM摇晃调整和恢复机制，通过优化摇晃操作符设置，实现了在成本、模型效用和隐私之间权衡的结果。"
}