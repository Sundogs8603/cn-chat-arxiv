{
    "title": "Chart-based Reasoning: Transferring Capabilities from LLMs to VLMs",
    "abstract": "arXiv:2403.12596v1 Announce Type: new  Abstract: Vision-language models (VLMs) are achieving increasingly strong performance on multimodal tasks. However, reasoning capabilities remain limited particularly for smaller VLMs, while those of large-language models (LLMs) have seen numerous improvements. We propose a technique to transfer capabilities from LLMs to VLMs. On the recently introduced ChartQA, our method obtains state-of-the-art performance when applied on the PaLI3-5B VLM by \\citet{chen2023pali3}, while also enabling much better performance on PlotQA and FigureQA.   We first improve the chart representation by continuing the pre-training stage using an improved version of the chart-to-table translation task by \\citet{liu2023deplot}. We then propose constructing a 20x larger dataset than the original training set. To improve general reasoning capabilities and improve numerical operations, we synthesize reasoning traces using the table representation of charts. Lastly, our model ",
    "link": "https://arxiv.org/abs/2403.12596",
    "context": "Title: Chart-based Reasoning: Transferring Capabilities from LLMs to VLMs\nAbstract: arXiv:2403.12596v1 Announce Type: new  Abstract: Vision-language models (VLMs) are achieving increasingly strong performance on multimodal tasks. However, reasoning capabilities remain limited particularly for smaller VLMs, while those of large-language models (LLMs) have seen numerous improvements. We propose a technique to transfer capabilities from LLMs to VLMs. On the recently introduced ChartQA, our method obtains state-of-the-art performance when applied on the PaLI3-5B VLM by \\citet{chen2023pali3}, while also enabling much better performance on PlotQA and FigureQA.   We first improve the chart representation by continuing the pre-training stage using an improved version of the chart-to-table translation task by \\citet{liu2023deplot}. We then propose constructing a 20x larger dataset than the original training set. To improve general reasoning capabilities and improve numerical operations, we synthesize reasoning traces using the table representation of charts. Lastly, our model ",
    "path": "papers/24/03/2403.12596.json",
    "total_tokens": 765,
    "translated_title": "基于图表的推理：将LLMs的能力转移到VLMs中",
    "translated_abstract": "arXiv:2403.12596v1 公告类型：新 抽象：视觉语言模型（VLMs）在多模态任务上取得了越来越强的性能。然而，尤其是对于较小的VLMs，推理能力仍然有限，而大型语言模型（LLMs）的能力已经取得了许多改进。我们提出了一种将LLMs的能力转移到VLMs的技术。在最近引入的ChartQA上，我们的方法在应用于\\citet{chen2023pali3}的PaLI3-5B VLM时获得了最先进的性能，同时也使PlotQA和FigureQA的性能大大提高。",
    "tldr": "提出了一种将大型语言模型（LLMs）的能力转移到视觉语言模型（VLMs）的技术，在多个任务上取得了最先进的性能。",
    "en_tdlr": "Propose a technique to transfer capabilities from large-language models (LLMs) to vision-language models (VLMs) and achieve state-of-the-art performance on multiple tasks."
}