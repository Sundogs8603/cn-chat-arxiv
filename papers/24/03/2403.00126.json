{
    "title": "FAC$^2$E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition",
    "abstract": "arXiv:2403.00126v1 Announce Type: new  Abstract: Large language models (LLMs) are primarily evaluated by overall performance on various text understanding and generation tasks. However, such a paradigm fails to comprehensively differentiate the fine-grained language and cognitive skills, rendering the lack of sufficient interpretation to LLMs' capabilities. In this paper, we present FAC$^2$E, a framework for Fine-grAined and Cognition-grounded LLMs' Capability Evaluation. Specifically, we formulate LLMs' evaluation in a multi-dimensional and explainable manner by dissociating the language-related capabilities and the cognition-related ones. Besides, through extracting the intermediate reasoning from LLMs, we further break down the process of applying a specific capability into three sub-steps: recalling relevant knowledge, utilizing knowledge, and solving problems. Finally, FAC$^2$E evaluates each sub-step of each fine-grained capability, providing a two-faceted diagnosis for LLMs. Uti",
    "link": "https://arxiv.org/abs/2403.00126",
    "context": "Title: FAC$^2$E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition\nAbstract: arXiv:2403.00126v1 Announce Type: new  Abstract: Large language models (LLMs) are primarily evaluated by overall performance on various text understanding and generation tasks. However, such a paradigm fails to comprehensively differentiate the fine-grained language and cognitive skills, rendering the lack of sufficient interpretation to LLMs' capabilities. In this paper, we present FAC$^2$E, a framework for Fine-grAined and Cognition-grounded LLMs' Capability Evaluation. Specifically, we formulate LLMs' evaluation in a multi-dimensional and explainable manner by dissociating the language-related capabilities and the cognition-related ones. Besides, through extracting the intermediate reasoning from LLMs, we further break down the process of applying a specific capability into three sub-steps: recalling relevant knowledge, utilizing knowledge, and solving problems. Finally, FAC$^2$E evaluates each sub-step of each fine-grained capability, providing a two-faceted diagnosis for LLMs. Uti",
    "path": "papers/24/03/2403.00126.json",
    "total_tokens": 906,
    "translated_title": "FAC$^2$E: 通过分离语言和认知来更好地理解大型语言模型的能力",
    "translated_abstract": "大型语言模型（LLMs）主要通过在各种文本理解和生成任务上的整体性能进行评估。然而，这种范式未能全面区分细粒度的语言和认知技能，导致对LLMs能力的解释不足。本文提出了FAC$^2$E，一种用于细粒度和基于认知的LLMs能力评估的框架。具体而言，我们通过分离与语言相关的能力和认知相关的能力，以多维和可解释的方式来制定LLMs的评估。此外，通过从LLMs中提取中间推理，我们进一步将应用特定能力的过程分解为三个子步骤：回忆相关知识、利用知识和解决问题。最后，FAC$^2$E评估每个细粒度能力的每个子步骤，为LLMs提供了双重诊断。",
    "tldr": "FAC$^2$E框架通过分离语言和认知能力，提供了多维和可解释的评估方式，并将LLMs应用能力分解为回忆知识、利用知识和解决问题三个子步骤，从而为LLMs提供了双重诊断。",
    "en_tdlr": "FAC$^2$E framework offers a multidimensional and interpretable evaluation by dissociating language and cognition abilities, breaking down LLMs' application capabilities into three sub-steps of recalling knowledge, utilizing knowledge, and problem-solving, providing a dual diagnosis for LLMs."
}