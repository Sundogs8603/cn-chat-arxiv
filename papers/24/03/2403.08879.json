{
    "title": "Multi-Objective Optimization Using Adaptive Distributed Reinforcement Learning",
    "abstract": "arXiv:2403.08879v1 Announce Type: cross  Abstract: The Intelligent Transportation System (ITS) environment is known to be dynamic and distributed, where participants (vehicle users, operators, etc.) have multiple, changing and possibly conflicting objectives. Although Reinforcement Learning (RL) algorithms are commonly applied to optimize ITS applications such as resource management and offloading, most RL algorithms focus on single objectives. In many situations, converting a multi-objective problem into a single-objective one is impossible, intractable or insufficient, making such RL algorithms inapplicable. We propose a multi-objective, multi-agent reinforcement learning (MARL) algorithm with high learning efficiency and low computational requirements, which automatically triggers adaptive few-shot learning in a dynamic, distributed and noisy environment with sparse and delayed reward. We test our algorithm in an ITS environment with edge cloud computing. Empirical results show that",
    "link": "https://arxiv.org/abs/2403.08879",
    "context": "Title: Multi-Objective Optimization Using Adaptive Distributed Reinforcement Learning\nAbstract: arXiv:2403.08879v1 Announce Type: cross  Abstract: The Intelligent Transportation System (ITS) environment is known to be dynamic and distributed, where participants (vehicle users, operators, etc.) have multiple, changing and possibly conflicting objectives. Although Reinforcement Learning (RL) algorithms are commonly applied to optimize ITS applications such as resource management and offloading, most RL algorithms focus on single objectives. In many situations, converting a multi-objective problem into a single-objective one is impossible, intractable or insufficient, making such RL algorithms inapplicable. We propose a multi-objective, multi-agent reinforcement learning (MARL) algorithm with high learning efficiency and low computational requirements, which automatically triggers adaptive few-shot learning in a dynamic, distributed and noisy environment with sparse and delayed reward. We test our algorithm in an ITS environment with edge cloud computing. Empirical results show that",
    "path": "papers/24/03/2403.08879.json",
    "total_tokens": 813,
    "translated_title": "使用自适应分布式强化学习进行多目标优化",
    "translated_abstract": "智能交通系统（ITS）环境被认为是动态和分布式的，参与者（车辆用户，运营商等）具有多个、不断变化且可能相互冲突的目标。虽然强化学习（RL）算法通常用于优化ITS应用，如资源管理和卸载，但大多数RL算法专注于单一目标。在许多情况下，将多目标问题转化为单一目标是不可能的、棘手的或不足的，这使得这种RL算法不适用。我们提出了一种具有高学习效率和低计算要求的多目标多代理强化学习（MARL）算法，该算法在动态、分布式和嘈杂的环境中自动触发自适应的少样本学习，并具有稀疏和延迟奖励。我们在具有边缘云计算的ITS环境中测试了我们的算法。实证结果表明",
    "tldr": "提出了一种在智能交通系统环境下进行多目标、多智能体强化学习的算法，具有高学习效率和低计算要求。",
    "en_tdlr": "Proposed a multi-objective, multi-agent reinforcement learning algorithm in the Intelligent Transportation System (ITS) environment with high learning efficiency and low computational requirements."
}