{
    "title": "Fast and Simple Explainability for Point Cloud Networks",
    "abstract": "arXiv:2403.07706v1 Announce Type: cross  Abstract: We propose a fast and simple explainable AI (XAI) method for point cloud data. It computes pointwise importance with respect to a trained network downstream task. This allows better understanding of the network properties, which is imperative for safety-critical applications. In addition to debugging and visualization, our low computational complexity facilitates online feedback to the network at inference. This can be used to reduce uncertainty and to increase robustness. In this work, we introduce \\emph{Feature Based Interpretability} (FBI), where we compute the features' norm, per point, before the bottleneck. We analyze the use of gradients and post- and pre-bottleneck strategies, showing pre-bottleneck is preferred, in terms of smoothness and ranking. We obtain at least three orders of magnitude speedup, compared to current XAI methods, thus, scalable for big point clouds or large-scale architectures. Our approach achieves SOTA re",
    "link": "https://arxiv.org/abs/2403.07706",
    "context": "Title: Fast and Simple Explainability for Point Cloud Networks\nAbstract: arXiv:2403.07706v1 Announce Type: cross  Abstract: We propose a fast and simple explainable AI (XAI) method for point cloud data. It computes pointwise importance with respect to a trained network downstream task. This allows better understanding of the network properties, which is imperative for safety-critical applications. In addition to debugging and visualization, our low computational complexity facilitates online feedback to the network at inference. This can be used to reduce uncertainty and to increase robustness. In this work, we introduce \\emph{Feature Based Interpretability} (FBI), where we compute the features' norm, per point, before the bottleneck. We analyze the use of gradients and post- and pre-bottleneck strategies, showing pre-bottleneck is preferred, in terms of smoothness and ranking. We obtain at least three orders of magnitude speedup, compared to current XAI methods, thus, scalable for big point clouds or large-scale architectures. Our approach achieves SOTA re",
    "path": "papers/24/03/2403.07706.json",
    "total_tokens": 911,
    "translated_title": "点云网络的快速简单可解释性",
    "translated_abstract": "我们提出了一种针对点云数据的快速简单可解释的人工智能（XAI）方法。它计算了相对于已经训练好的网络下游任务的每个点的重要性。这有助于更好地理解网络的特性，对于安全关键应用至关重要。除了调试和可视化之外，我们的低计算复杂度有助于在线反馈到网络进行推断。这可以用于减少不确定性并提高鲁棒性。在这项工作中，我们引入了“基于特征的解释”（FBI），在瓶颈层之前计算每个点的特征范数。我们分析了梯度的使用以及后瓶颈和前瓶颈策略，结果显示前瓶颈更受青睐，从平滑度和排名角度来看。与当前的XAI方法相比，我们实现了至少三个数量级的速度提升，因此适用于大型点云或大规模架构。我们的方法实现了SOTA水平。",
    "tldr": "该方法提出了一种基于特征的解释（FBI）方法，通过计算每个点在瓶颈层之前的特征范数，实现了与当前XAI方法至少三个数量级的速度提升，适用于大型点云或大规模架构。",
    "en_tdlr": "The proposed method introduces a Feature Based Interpretability (FBI) approach, which computes the feature norm per point before the bottleneck, achieving at least three orders of magnitude speedup compared to current XAI methods, making it suitable for large point clouds or large-scale architectures."
}