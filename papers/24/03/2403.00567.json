{
    "title": "Flatten Long-Range Loss Landscapes for Cross-Domain Few-Shot Learning",
    "abstract": "arXiv:2403.00567v1 Announce Type: cross  Abstract: Cross-domain few-shot learning (CDFSL) aims to acquire knowledge from limited training data in the target domain by leveraging prior knowledge transferred from source domains with abundant training samples. CDFSL faces challenges in transferring knowledge across dissimilar domains and fine-tuning models with limited training data. To address these challenges, we initially extend the analysis of loss landscapes from the parameter space to the representation space, which allows us to simultaneously interpret the transferring and fine-tuning difficulties of CDFSL models. We observe that sharp minima in the loss landscapes of the representation space result in representations that are hard to transfer and fine-tune. Moreover, existing flatness-based methods have limited generalization ability due to their short-range flatness. To enhance the transferability and facilitate fine-tuning, we introduce a simple yet effective approach to achieve",
    "link": "https://arxiv.org/abs/2403.00567",
    "context": "Title: Flatten Long-Range Loss Landscapes for Cross-Domain Few-Shot Learning\nAbstract: arXiv:2403.00567v1 Announce Type: cross  Abstract: Cross-domain few-shot learning (CDFSL) aims to acquire knowledge from limited training data in the target domain by leveraging prior knowledge transferred from source domains with abundant training samples. CDFSL faces challenges in transferring knowledge across dissimilar domains and fine-tuning models with limited training data. To address these challenges, we initially extend the analysis of loss landscapes from the parameter space to the representation space, which allows us to simultaneously interpret the transferring and fine-tuning difficulties of CDFSL models. We observe that sharp minima in the loss landscapes of the representation space result in representations that are hard to transfer and fine-tune. Moreover, existing flatness-based methods have limited generalization ability due to their short-range flatness. To enhance the transferability and facilitate fine-tuning, we introduce a simple yet effective approach to achieve",
    "path": "papers/24/03/2403.00567.json",
    "total_tokens": 842,
    "translated_title": "摊平长程丢失景观，用于跨领域少样本学习",
    "translated_abstract": "跨领域少样本学习（CDFSL）旨在通过利用源域的丰富训练样本转移先前知识，以从目标域的有限训练数据中获取知识。本文针对CDFSL在跨不同领域传输知识和在有限训练数据下微调模型方面面临的挑战，将分析损失景观从参数空间扩展到表示空间，从而允许我们同时解释CDFSL模型的传输和微调困难。我们观察到表示空间损失景观中的尖锐极小值导致难以转移和微调的表示。此外，现有基于平坦性的方法由于其短程平坦性而具有有限的泛化能力。为增强可转移性并促进微调，我们引入了一种简单而有效的方法",
    "tldr": "将分析损失景观从参数空间扩展到表示空间，观察到尖锐极小值导致难以转移和微调的表示，引入一种简单而有效的方法以增强可转移性和促进微调。"
}