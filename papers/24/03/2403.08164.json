{
    "title": "EM-TTS: Efficiently Trained Low-Resource Mongolian Lightweight Text-to-Speech",
    "abstract": "arXiv:2403.08164v1 Announce Type: cross  Abstract: Recently, deep learning-based Text-to-Speech (TTS) systems have achieved high-quality speech synthesis results. Recurrent neural networks have become a standard modeling technique for sequential data in TTS systems and are widely used. However, training a TTS model which includes RNN components requires powerful GPU performance and takes a long time. In contrast, CNN-based sequence synthesis techniques can significantly reduce the parameters and training time of a TTS model while guaranteeing a certain performance due to their high parallelism, which alleviate these economic costs of training. In this paper, we propose a lightweight TTS system based on deep convolutional neural networks, which is a two-stage training end-to-end TTS model and does not employ any recurrent units. Our model consists of two stages: Text2Spectrum and SSRN. The former is used to encode phonemes into a coarse mel spectrogram and the latter is used to synthesi",
    "link": "https://arxiv.org/abs/2403.08164",
    "context": "Title: EM-TTS: Efficiently Trained Low-Resource Mongolian Lightweight Text-to-Speech\nAbstract: arXiv:2403.08164v1 Announce Type: cross  Abstract: Recently, deep learning-based Text-to-Speech (TTS) systems have achieved high-quality speech synthesis results. Recurrent neural networks have become a standard modeling technique for sequential data in TTS systems and are widely used. However, training a TTS model which includes RNN components requires powerful GPU performance and takes a long time. In contrast, CNN-based sequence synthesis techniques can significantly reduce the parameters and training time of a TTS model while guaranteeing a certain performance due to their high parallelism, which alleviate these economic costs of training. In this paper, we propose a lightweight TTS system based on deep convolutional neural networks, which is a two-stage training end-to-end TTS model and does not employ any recurrent units. Our model consists of two stages: Text2Spectrum and SSRN. The former is used to encode phonemes into a coarse mel spectrogram and the latter is used to synthesi",
    "path": "papers/24/03/2403.08164.json",
    "total_tokens": 872,
    "translated_title": "EM-TTS：高效训练的低资源蒙古语轻量级文本转语音系统",
    "translated_abstract": "最近，基于深度学习的文本转语音（TTS）系统取得了高质量的语音合成结果。递归神经网络已成为TTS系统中序列数据的标准建模技术，并被广泛使用。然而，训练包含RNN组件的TTS模型需要强大的GPU性能并且时间长。相反，基于CNN的序列合成技术可以显著减少TTS模型的参数和训练时间，同时由于其高并行性，可以保证一定的性能，从而减轻这些训练的经济成本。本文提出了一种基于深度卷积神经网络的轻量级TTS系统，这是一个两阶段训练的端到端TTS模型，不使用任何递归单元。我们的模型包括两个阶段：Text2Spectrum 和 SSRN。前者用于将音素编码为粗糙的梅尔频谱图，后者用于合成。",
    "tldr": "提出了一种基于深度卷积神经网络的轻量级TTS系统，采用两阶段训练而非递归单元，可以显著减少训练时间和经济成本",
    "en_tdlr": "Proposed a lightweight TTS system based on deep convolutional neural networks, trained in two stages without recurrent units, to significantly reduce training time and economic costs."
}