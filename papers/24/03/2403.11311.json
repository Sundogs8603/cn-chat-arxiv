{
    "title": "Mixture-of-Prompt-Experts for Multi-modal Semantic Understanding",
    "abstract": "arXiv:2403.11311v1 Announce Type: new  Abstract: Deep multimodal semantic understanding that goes beyond the mere superficial content relation mining has received increasing attention in the realm of artificial intelligence. The challenges of collecting and annotating high-quality multi-modal data have underscored the significance of few-shot learning. In this paper, we focus on two critical tasks under this context: few-shot multi-modal sarcasm detection (MSD) and multi-modal sentiment analysis (MSA). To address them, we propose Mixture-of-Prompt-Experts with Block-Aware Prompt Fusion (MoPE-BAF), a novel multi-modal soft prompt framework based on the unified vision-language model (VLM). Specifically, we design three experts of soft prompts: a text prompt and an image prompt that extract modality-specific features to enrich the single-modal representation, and a unified prompt to assist multi-modal interaction. Additionally, we reorganize Transformer layers into several blocks and intr",
    "link": "https://arxiv.org/abs/2403.11311",
    "context": "Title: Mixture-of-Prompt-Experts for Multi-modal Semantic Understanding\nAbstract: arXiv:2403.11311v1 Announce Type: new  Abstract: Deep multimodal semantic understanding that goes beyond the mere superficial content relation mining has received increasing attention in the realm of artificial intelligence. The challenges of collecting and annotating high-quality multi-modal data have underscored the significance of few-shot learning. In this paper, we focus on two critical tasks under this context: few-shot multi-modal sarcasm detection (MSD) and multi-modal sentiment analysis (MSA). To address them, we propose Mixture-of-Prompt-Experts with Block-Aware Prompt Fusion (MoPE-BAF), a novel multi-modal soft prompt framework based on the unified vision-language model (VLM). Specifically, we design three experts of soft prompts: a text prompt and an image prompt that extract modality-specific features to enrich the single-modal representation, and a unified prompt to assist multi-modal interaction. Additionally, we reorganize Transformer layers into several blocks and intr",
    "path": "papers/24/03/2403.11311.json",
    "total_tokens": 903,
    "translated_title": "混合提示专家用于多模态语义理解",
    "translated_abstract": "arXiv:2403.11311v1 公告类型:新 抽象:在人工智能领域，深度多模态语义理解受到越来越多的关注，超越了单纯的表面内容关系挖掘。收集和注释高质量的多模态数据的挑战凸显了少样本学习的重要性。本文关注这一背景下的两个关键任务: 少样本多模态讽刺检测（MSD）和多模态情感分析（MSA）。为了解决这些问题，我们提出了基于统一视觉-语言模型（VLM）的一种新型多模态软提示框架Mixture-of-Prompt-Experts with Block-Aware Prompt Fusion（MoPE-BAF）。具体来说，我们设计了三个软提示专家: 一个文本提示和一个图像提示，用于提取特定于模态的特征以丰富单模态表示，以及一个统一提示以协助多模态交互。此外，我们将Transformer层重新组织为几个块，并实现了...",
    "tldr": "提出了一种新型多模态软提示框架MoPE-BAF，用于解决少样本学习下的多模态讽刺检测和情感分析问题，通过三个软提示专家和块感知提示融合，实现了模态特征提取和多模态交互。",
    "en_tdlr": "Introducing a novel multi-modal soft prompt framework MoPE-BAF to tackle few-shot learning for multi-modal sarcasm detection and sentiment analysis, facilitating modality-specific feature extraction and multi-modal interaction through three prompt experts and block-aware prompt fusion."
}