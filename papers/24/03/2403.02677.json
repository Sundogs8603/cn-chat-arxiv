{
    "title": "Finetuned Multimodal Language Models Are High-Quality Image-Text Data Filters",
    "abstract": "arXiv:2403.02677v1 Announce Type: cross  Abstract: We propose a novel framework for filtering image-text data by leveraging fine-tuned Multimodal Language Models (MLMs). Our approach outperforms predominant filtering methods (e.g., CLIPScore) via integrating the recent advances in MLMs. We design four distinct yet complementary metrics to holistically measure the quality of image-text data. A new pipeline is established to construct high-quality instruction data for fine-tuning MLMs as data filters. Comparing with CLIPScore, our MLM filters produce more precise and comprehensive scores that directly improve the quality of filtered data and boost the performance of pre-trained models. We achieve significant improvements over CLIPScore on popular foundation models (i.e., CLIP and BLIP2) and various downstream tasks. Our MLM filter can generalize to different models and tasks, and be used as a drop-in replacement for CLIPScore. An additional ablation study is provided to verify our design",
    "link": "https://arxiv.org/abs/2403.02677",
    "context": "Title: Finetuned Multimodal Language Models Are High-Quality Image-Text Data Filters\nAbstract: arXiv:2403.02677v1 Announce Type: cross  Abstract: We propose a novel framework for filtering image-text data by leveraging fine-tuned Multimodal Language Models (MLMs). Our approach outperforms predominant filtering methods (e.g., CLIPScore) via integrating the recent advances in MLMs. We design four distinct yet complementary metrics to holistically measure the quality of image-text data. A new pipeline is established to construct high-quality instruction data for fine-tuning MLMs as data filters. Comparing with CLIPScore, our MLM filters produce more precise and comprehensive scores that directly improve the quality of filtered data and boost the performance of pre-trained models. We achieve significant improvements over CLIPScore on popular foundation models (i.e., CLIP and BLIP2) and various downstream tasks. Our MLM filter can generalize to different models and tasks, and be used as a drop-in replacement for CLIPScore. An additional ablation study is provided to verify our design",
    "path": "papers/24/03/2403.02677.json",
    "total_tokens": 887,
    "translated_title": "细调多模态语言模型是高质量的图像文本数据过滤器",
    "translated_abstract": "我们提出了一种通过利用经过良好调整的多模态语言模型（MLM）来过滤图像文本数据的新框架。我们的方法通过整合MLMs的最新进展胜过主流过滤方法（例如CLIPScore）。我们设计了四个独特而互补的指标来全面衡量图像文本数据的质量。我们建立了一个新的流程来构建高质量的指导数据，用于细调MLMs作为数据过滤器。与CLIPScore相比，我们的MLM过滤器产生更精确、更全面的分数，直接提高了过滤数据的质量，并提升了预训练模型的性能。我们在流行的基础模型（即CLIP和BLIP2）和各种下游任务上显著优于CLIPScore。我们的MLM过滤器可以推广到不同的模型和任务，并可以作为CLIPScore的即插即用替代品。提供了额外的消融研究来验证我们的设计。",
    "tldr": "通过细调多模态语言模型，我们提出了一种新框架，能够更准确、更全面地过滤图像文本数据，从而提高数据质量和预训练模型的性能。",
    "en_tdlr": "We propose a novel framework for filtering image-text data by leveraging fine-tuned Multimodal Language Models (MLMs), which outperforms predominant methods by providing more accurate and comprehensive data filtering to enhance data quality and model performance."
}