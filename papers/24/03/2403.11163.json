{
    "title": "A Selective Review on Statistical Methods for Massive Data Computation: Distributed Computing, Subsampling, and Minibatch Techniques",
    "abstract": "arXiv:2403.11163v1 Announce Type: cross  Abstract: This paper presents a selective review of statistical computation methods for massive data analysis. A huge amount of statistical methods for massive data computation have been rapidly developed in the past decades. In this work, we focus on three categories of statistical computation methods: (1) distributed computing, (2) subsampling methods, and (3) minibatch gradient techniques. The first class of literature is about distributed computing and focuses on the situation, where the dataset size is too huge to be comfortably handled by one single computer. In this case, a distributed computation system with multiple computers has to be utilized. The second class of literature is about subsampling methods and concerns about the situation, where the sample size of dataset is small enough to be placed on one single computer but too large to be easily processed by its memory as a whole. The last class of literature studies those minibatch g",
    "link": "https://arxiv.org/abs/2403.11163",
    "context": "Title: A Selective Review on Statistical Methods for Massive Data Computation: Distributed Computing, Subsampling, and Minibatch Techniques\nAbstract: arXiv:2403.11163v1 Announce Type: cross  Abstract: This paper presents a selective review of statistical computation methods for massive data analysis. A huge amount of statistical methods for massive data computation have been rapidly developed in the past decades. In this work, we focus on three categories of statistical computation methods: (1) distributed computing, (2) subsampling methods, and (3) minibatch gradient techniques. The first class of literature is about distributed computing and focuses on the situation, where the dataset size is too huge to be comfortably handled by one single computer. In this case, a distributed computation system with multiple computers has to be utilized. The second class of literature is about subsampling methods and concerns about the situation, where the sample size of dataset is small enough to be placed on one single computer but too large to be easily processed by its memory as a whole. The last class of literature studies those minibatch g",
    "path": "papers/24/03/2403.11163.json",
    "total_tokens": 843,
    "translated_title": "面向大规模数据计算的统计方法选择性综述：分布式计算、子采样和小批量技术",
    "translated_abstract": "本文提供了对大规模数据分析的统计计算方法进行选择性综述。过去几十年中，已经迅速发展了大量用于大规模数据计算的统计方法。在本工作中，我们着重研究了三类统计计算方法：（1）分布式计算，（2）子采样方法，和（3）小批量梯度技术。第一类文献关于分布式计算，重点是在数据集太大无法被单台计算机轻松处理的情况下。在这种情况下，必须使用一个具有多台计算机的分布式计算系统。第二类文献关于子采样方法，关注的是样本数据集的大小足够小，可以放在一台计算机上，但太大以至于无法整体处理其内存。最后一类文献研究了小批量梯度方法...",
    "tldr": "该论文选择性综述了大规模数据计算的统计方法，主要集中在分布式计算、子采样以及小批量梯度技术这三类统计计算方法。",
    "en_tdlr": "This paper presents a selective review of statistical computation methods for massive data analysis, focusing on distributed computing, subsampling methods, and minibatch gradient techniques."
}