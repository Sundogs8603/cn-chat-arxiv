{
    "title": "DuDoUniNeXt: Dual-domain unified hybrid model for single and multi-contrast undersampled MRI reconstruction",
    "abstract": "arXiv:2403.05256v1 Announce Type: cross  Abstract: Multi-contrast (MC) Magnetic Resonance Imaging (MRI) reconstruction aims to incorporate a reference image of auxiliary modality to guide the reconstruction process of the target modality. Known MC reconstruction methods perform well with a fully sampled reference image, but usually exhibit inferior performance, compared to single-contrast (SC) methods, when the reference image is missing or of low quality. To address this issue, we propose DuDoUniNeXt, a unified dual-domain MRI reconstruction network that can accommodate to scenarios involving absent, low-quality, and high-quality reference images. DuDoUniNeXt adopts a hybrid backbone that combines CNN and ViT, enabling specific adjustment of image domain and k-space reconstruction. Specifically, an adaptive coarse-to-fine feature fusion module (AdaC2F) is devised to dynamically process the information from reference images of varying qualities. Besides, a partially shared shallow feat",
    "link": "https://arxiv.org/abs/2403.05256",
    "context": "Title: DuDoUniNeXt: Dual-domain unified hybrid model for single and multi-contrast undersampled MRI reconstruction\nAbstract: arXiv:2403.05256v1 Announce Type: cross  Abstract: Multi-contrast (MC) Magnetic Resonance Imaging (MRI) reconstruction aims to incorporate a reference image of auxiliary modality to guide the reconstruction process of the target modality. Known MC reconstruction methods perform well with a fully sampled reference image, but usually exhibit inferior performance, compared to single-contrast (SC) methods, when the reference image is missing or of low quality. To address this issue, we propose DuDoUniNeXt, a unified dual-domain MRI reconstruction network that can accommodate to scenarios involving absent, low-quality, and high-quality reference images. DuDoUniNeXt adopts a hybrid backbone that combines CNN and ViT, enabling specific adjustment of image domain and k-space reconstruction. Specifically, an adaptive coarse-to-fine feature fusion module (AdaC2F) is devised to dynamically process the information from reference images of varying qualities. Besides, a partially shared shallow feat",
    "path": "papers/24/03/2403.05256.json",
    "total_tokens": 887,
    "translated_title": "DuDoUniNeXt：用于单和多对比度欠采样MRI重建的双域统一混合模型",
    "translated_abstract": "多对比度（MC）磁共振成像（MRI）重建旨在将辅助模态的参考图像纳入目标模态的重建过程中。已知的MC重建方法在有完全采样的参考图像时表现良好，但通常在参考图像缺失或质量低下时，与单对比度（SC）方法相比表现较差。为解决这一问题，我们提出了DuDoUniNeXt，一个统一的双域MRI重建网络，可适应涉及缺失、质量低和质量高的参考图像的各种场景。DuDoUniNeXt采用了一个结合了CNN和ViT的混合主干，实现了对图像域和k-空间重建的特定调整。具体来说，设计了一种自适应粗到细特征融合模块（AdaC2F），动态处理不同质量参考图像的信息。此外，还有一个部分共享的浅层特征",
    "tldr": "提出了DuDoUniNeXt，一个统一的双域MRI重建网络，能适应不同质量的参考图像，解决了在缺少或低质量参考图像时性能不佳的问题"
}