{
    "title": "PURPLE: Making a Large Language Model a Better SQL Writer",
    "abstract": "arXiv:2403.20014v1 Announce Type: cross  Abstract: Large Language Model (LLM) techniques play an increasingly important role in Natural Language to SQL (NL2SQL) translation. LLMs trained by extensive corpora have strong natural language understanding and basic SQL generation abilities without additional tuning specific to NL2SQL tasks. Existing LLMs-based NL2SQL approaches try to improve the translation by enhancing the LLMs with an emphasis on user intention understanding. However, LLMs sometimes fail to generate appropriate SQL due to their lack of knowledge in organizing complex logical operator composition. A promising method is to input the LLMs with demonstrations, which include known NL2SQL translations from various databases. LLMs can learn to organize operator compositions from the input demonstrations for the given task. In this paper, we propose PURPLE (Pre-trained models Utilized to Retrieve Prompts for Logical Enhancement), which improves accuracy by retrieving demonstrati",
    "link": "https://arxiv.org/abs/2403.20014",
    "context": "Title: PURPLE: Making a Large Language Model a Better SQL Writer\nAbstract: arXiv:2403.20014v1 Announce Type: cross  Abstract: Large Language Model (LLM) techniques play an increasingly important role in Natural Language to SQL (NL2SQL) translation. LLMs trained by extensive corpora have strong natural language understanding and basic SQL generation abilities without additional tuning specific to NL2SQL tasks. Existing LLMs-based NL2SQL approaches try to improve the translation by enhancing the LLMs with an emphasis on user intention understanding. However, LLMs sometimes fail to generate appropriate SQL due to their lack of knowledge in organizing complex logical operator composition. A promising method is to input the LLMs with demonstrations, which include known NL2SQL translations from various databases. LLMs can learn to organize operator compositions from the input demonstrations for the given task. In this paper, we propose PURPLE (Pre-trained models Utilized to Retrieve Prompts for Logical Enhancement), which improves accuracy by retrieving demonstrati",
    "path": "papers/24/03/2403.20014.json",
    "total_tokens": 790,
    "translated_title": "PURPLE: 让大型语言模型成为更好的SQL编写器",
    "translated_abstract": "大型语言模型（LLM）技术在自然语言到SQL（NL2SQL）翻译中起着越来越重要的作用。通过大规模语料库训练的LLMs具有强大的自然语言理解和基本SQL生成能力，无需针对NL2SQL任务进行额外调整。现有基于LLMs的NL2SQL方法试图通过强调用户意图理解来提高翻译效果。然而，由于缺乏在组织复杂的逻辑运算符组合方面的知识，LLMs有时会生成不合适的SQL。一种有希望的方法是向LLMs输入演示，其中包括来自各种数据库的已知NL2SQL翻译。LLMs可以从输入演示中学习如何为给定任务组织运算符组合。在本文中，我们提出了PURPLE（Pre-trained models Utilized to Retrieve Prompts for Logical Enhancement），通过检索演示来提高准确性。",
    "tldr": "提出了PURPLE模型，通过检索演示来提高大型语言模型在SQL生成中的准确性",
    "en_tdlr": "Proposed PURPLE model improves the accuracy of large language models in SQL generation by retrieving demonstrations."
}