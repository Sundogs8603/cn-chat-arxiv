{
    "title": "Cross-domain and Cross-dimension Learning for Image-to-Graph Transformers",
    "abstract": "arXiv:2403.06601v1 Announce Type: cross  Abstract: Direct image-to-graph transformation is a challenging task that solves object detection and relationship prediction in a single model. Due to the complexity of this task, large training datasets are rare in many domains, which makes the training of large networks challenging. This data sparsity necessitates the establishment of pre-training strategies akin to the state-of-the-art in computer vision. In this work, we introduce a set of methods enabling cross-domain and cross-dimension transfer learning for image-to-graph transformers. We propose (1) a regularized edge sampling loss for sampling the optimal number of object relationships (edges) across domains, (2) a domain adaptation framework for image-to-graph transformers that aligns features from different domains, and (3) a simple projection function that allows us to pretrain 3D transformers on 2D input data. We demonstrate our method's utility in cross-domain and cross-dimension ",
    "link": "https://arxiv.org/abs/2403.06601",
    "context": "Title: Cross-domain and Cross-dimension Learning for Image-to-Graph Transformers\nAbstract: arXiv:2403.06601v1 Announce Type: cross  Abstract: Direct image-to-graph transformation is a challenging task that solves object detection and relationship prediction in a single model. Due to the complexity of this task, large training datasets are rare in many domains, which makes the training of large networks challenging. This data sparsity necessitates the establishment of pre-training strategies akin to the state-of-the-art in computer vision. In this work, we introduce a set of methods enabling cross-domain and cross-dimension transfer learning for image-to-graph transformers. We propose (1) a regularized edge sampling loss for sampling the optimal number of object relationships (edges) across domains, (2) a domain adaptation framework for image-to-graph transformers that aligns features from different domains, and (3) a simple projection function that allows us to pretrain 3D transformers on 2D input data. We demonstrate our method's utility in cross-domain and cross-dimension ",
    "path": "papers/24/03/2403.06601.json",
    "total_tokens": 952,
    "translated_title": "图像到图形变换中的跨域和跨维度学习",
    "translated_abstract": "直接的图像到图形转换是一个具有挑战性的任务，它在单个模型中解决了目标检测和关系预测。由于这个任务的复杂性，在许多领域中很难找到大型训练数据集，这使得训练大型网络具有挑战性。这种数据稀疏性需要建立类似于计算机视觉中最先进技术的预训练策略。在这项工作中，我们引入了一套方法，实现了图像到图形转换器的跨域和跨维度迁移学习。我们提出了(1) 正则化边缘采样损失，用于在不同领域中采样最佳数量的目标关系(边缘)，(2) 一种图像到图形转换器的领域自适应框架，可以对齐不同领域的特征，和(3) 一种简单的投影函数，使我们能够在二维输入数据上预训练三维转换器。我们展示了我们的方法在跨域和跨维度下的实用性。",
    "tldr": "该论文提出了一种用于图像到图形转换器的跨域和跨维度迁移学习方法，包括正则化边缘采样损失、领域自适应框架和简单的投影函数，可以解决数据稀缺性问题，并在实验中展示了其实用性。",
    "en_tdlr": "This paper introduces a method for cross-domain and cross-dimension transfer learning for image-to-graph transformers, including regularized edge sampling loss, domain adaptation framework, and simple projection function to address data sparsity, with demonstrated utility in experiments."
}