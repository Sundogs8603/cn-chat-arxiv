{
    "title": "Enhancing LLM Factual Accuracy with RAG to Counter Hallucinations: A Case Study on Domain-Specific Queries in Private Knowledge-Bases",
    "abstract": "arXiv:2403.10446v1 Announce Type: new  Abstract: We proposed an end-to-end system design towards utilizing Retrieval Augmented Generation (RAG) to improve the factual accuracy of Large Language Models (LLMs) for domain-specific and time-sensitive queries related to private knowledge-bases. Our system integrates RAG pipeline with upstream datasets processing and downstream performance evaluation. Addressing the challenge of LLM hallucinations, we finetune models with a curated dataset which originates from CMU's extensive resources and annotated with the teacher model. Our experiments demonstrate the system's effectiveness in generating more accurate answers to domain-specific and time-sensitive inquiries. The results also revealed the limitations of fine-tuning LLMs with small-scale and skewed datasets. This research highlights the potential of RAG systems in augmenting LLMs with external datasets for improved performance in knowledge-intensive tasks. Our code and models are available ",
    "link": "https://arxiv.org/abs/2403.10446",
    "context": "Title: Enhancing LLM Factual Accuracy with RAG to Counter Hallucinations: A Case Study on Domain-Specific Queries in Private Knowledge-Bases\nAbstract: arXiv:2403.10446v1 Announce Type: new  Abstract: We proposed an end-to-end system design towards utilizing Retrieval Augmented Generation (RAG) to improve the factual accuracy of Large Language Models (LLMs) for domain-specific and time-sensitive queries related to private knowledge-bases. Our system integrates RAG pipeline with upstream datasets processing and downstream performance evaluation. Addressing the challenge of LLM hallucinations, we finetune models with a curated dataset which originates from CMU's extensive resources and annotated with the teacher model. Our experiments demonstrate the system's effectiveness in generating more accurate answers to domain-specific and time-sensitive inquiries. The results also revealed the limitations of fine-tuning LLMs with small-scale and skewed datasets. This research highlights the potential of RAG systems in augmenting LLMs with external datasets for improved performance in knowledge-intensive tasks. Our code and models are available ",
    "path": "papers/24/03/2403.10446.json",
    "total_tokens": 846,
    "translated_title": "利用RAG增强LLM事实准确性以消除幻觉：私人知识库中特定领域查询的案例研究",
    "translated_abstract": "我们提出了一个端到端系统设计，利用检索增强生成（RAG）来提高大型语言模型（LLMs）对私人知识库中与特定领域和时效查询相关的事实准确性。我们的系统将RAG管道与上游数据集处理和下游性能评估整合在一起。解决LLM幻觉的挑战，我们用源自CMU广泛资源并用教师模型注释的筛选数据集对模型进行微调。我们的实验表明该系统在生成更准确的特定领域和时效查询答案方面的有效性。结果还揭示了使用小规模和倾斜数据集微调LLMs的局限性。这项研究突显了RAG系统在增强LLMs与外部数据集以改进知识密集型任务性能方面的潜力。我们的代码和模型可供使用。",
    "tldr": "利用RAG系统增强LLMs，提高其对私人知识库中特定领域和时效查询的事实准确性，尤其在使用外部数据集方面表现出潜力。",
    "en_tdlr": "Enhancing LLMs with RAG to improve factual accuracy for domain-specific and time-sensitive queries in private knowledge-bases shows potential, especially when leveraging external datasets."
}