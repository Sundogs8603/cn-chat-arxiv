{
    "title": "LLM-Oriented Retrieval Tuner",
    "abstract": "arXiv:2403.01999v1 Announce Type: new  Abstract: Dense Retrieval (DR) is now considered as a promising tool to enhance the memorization capacity of Large Language Models (LLM) such as GPT3 and GPT-4 by incorporating external memories. However, due to the paradigm discrepancy between text generation of LLM and DR, it is still an open challenge to integrate the retrieval and generation tasks in a shared LLM. In this paper, we propose an efficient LLM-Oriented Retrieval Tuner, namely LMORT, which decouples DR capacity from base LLM and non-invasively coordinates the optimally aligned and uniform layers of the LLM towards a unified DR space, achieving an efficient and effective DR without tuning the LLM itself. The extensive experiments on six BEIR datasets show that our approach could achieve competitive zero-shot retrieval performance compared to a range of strong DR models while maintaining the generation ability of LLM.",
    "link": "https://arxiv.org/abs/2403.01999",
    "context": "Title: LLM-Oriented Retrieval Tuner\nAbstract: arXiv:2403.01999v1 Announce Type: new  Abstract: Dense Retrieval (DR) is now considered as a promising tool to enhance the memorization capacity of Large Language Models (LLM) such as GPT3 and GPT-4 by incorporating external memories. However, due to the paradigm discrepancy between text generation of LLM and DR, it is still an open challenge to integrate the retrieval and generation tasks in a shared LLM. In this paper, we propose an efficient LLM-Oriented Retrieval Tuner, namely LMORT, which decouples DR capacity from base LLM and non-invasively coordinates the optimally aligned and uniform layers of the LLM towards a unified DR space, achieving an efficient and effective DR without tuning the LLM itself. The extensive experiments on six BEIR datasets show that our approach could achieve competitive zero-shot retrieval performance compared to a range of strong DR models while maintaining the generation ability of LLM.",
    "path": "papers/24/03/2403.01999.json",
    "total_tokens": 842,
    "translated_title": "LLM-Oriented Retrieval Tuner",
    "translated_abstract": "密集检索（DR）现在被认为是增强大型语言模型（LLM）如GPT3和GPT-4记忆能力的一种有希望的工具，通过融入外部记忆。然而，由于LLM的文本生成和DR之间的范式差异，将检索和生成任务整合到一个共享的LLM中仍然是一个未解决的挑战。本文提出了一种高效的LLM定向检索调节器，即LMORT，它能够将DR容量与基础LLM解耦，并通过非侵入性地协调LLM的优化对齐和统一层向统一的DR空间，实现了有效和高效的DR，而无需调整LLM本身。在六个BEIR数据集上进行的大量实验证明，我们的方法在保持LLM生成能力的同时，能够实现与一系列强大DR模型相比具有竞争力的零-shot检索性能。",
    "tldr": "通过LMORT，作者提出了一种高效的LLM定向检索调节器，可以实现有效的密集检索，与其他强大的DR模型相比具有竞争力的零-shot检索性能，并保持LLM的生成能力。"
}