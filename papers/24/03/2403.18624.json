{
    "title": "Vulnerability Detection with Code Language Models: How Far Are We?",
    "abstract": "arXiv:2403.18624v1 Announce Type: cross  Abstract: In the context of the rising interest in code language models (code LMs) and vulnerability detection, we study the effectiveness of code LMs for detecting vulnerabilities. Our analysis reveals significant shortcomings in existing vulnerability datasets, including poor data quality, low label accuracy, and high duplication rates, leading to unreliable model performance in realistic vulnerability detection scenarios. Additionally, the evaluation methods used with these datasets are not representative of real-world vulnerability detection.   To address these challenges, we introduce PrimeVul, a new dataset for training and evaluating code LMs for vulnerability detection. PrimeVul incorporates a novel set of data labeling techniques that achieve comparable label accuracy to human-verified benchmarks while significantly expanding the dataset. It also implements a rigorous data de-duplication and chronological data splitting strategy to miti",
    "link": "https://arxiv.org/abs/2403.18624",
    "context": "Title: Vulnerability Detection with Code Language Models: How Far Are We?\nAbstract: arXiv:2403.18624v1 Announce Type: cross  Abstract: In the context of the rising interest in code language models (code LMs) and vulnerability detection, we study the effectiveness of code LMs for detecting vulnerabilities. Our analysis reveals significant shortcomings in existing vulnerability datasets, including poor data quality, low label accuracy, and high duplication rates, leading to unreliable model performance in realistic vulnerability detection scenarios. Additionally, the evaluation methods used with these datasets are not representative of real-world vulnerability detection.   To address these challenges, we introduce PrimeVul, a new dataset for training and evaluating code LMs for vulnerability detection. PrimeVul incorporates a novel set of data labeling techniques that achieve comparable label accuracy to human-verified benchmarks while significantly expanding the dataset. It also implements a rigorous data de-duplication and chronological data splitting strategy to miti",
    "path": "papers/24/03/2403.18624.json",
    "total_tokens": 735,
    "translated_title": "使用代码语言模型进行漏洞检测：我们离目标有多远？",
    "translated_abstract": "在代码语言模型（code LMs）和漏洞检测备受关注的背景下，我们研究了代码语言模型用于检测漏洞的有效性。我们的分析揭示了现有漏洞数据集存在的重大缺陷，包括数据质量低、标签准确性差以及高重复率，导致在现实漏洞检测场景中模型性能不可靠。此外，这些数据集使用的评估方法也不能代表真实世界的漏洞检测情景。",
    "tldr": "我们提出了一个新的数据集PrimeVul，用于训练和评估代码语言模型进行漏洞检测，通过引入一套新颖的数据标记技术，实现了与人工验证基准相当的标签准确性，显著扩大了数据集。",
    "en_tdlr": "We introduce PrimeVul, a new dataset for training and evaluating code language models for vulnerability detection with novel data labeling techniques to achieve comparable label accuracy to human-verified benchmarks and significantly expand the dataset."
}