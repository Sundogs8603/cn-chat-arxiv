{
    "title": "InstaSynth: Opportunities and Challenges in Generating Synthetic Instagram Data with ChatGPT for Sponsored Content Detection",
    "abstract": "arXiv:2403.15214v1 Announce Type: cross  Abstract: Large Language Models (LLMs) raise concerns about lowering the cost of generating texts that could be used for unethical or illegal purposes, especially on social media. This paper investigates the promise of such models to help enforce legal requirements related to the disclosure of sponsored content online. We investigate the use of LLMs for generating synthetic Instagram captions with two objectives: The first objective (fidelity) is to produce realistic synthetic datasets. For this, we implement content-level and network-level metrics to assess whether synthetic captions are realistic. The second objective (utility) is to create synthetic data that is useful for sponsored content detection. For this, we evaluate the effectiveness of the generated synthetic data for training classifiers to identify undisclosed advertisements on Instagram. Our investigations show that the objectives of fidelity and utility may conflict and that promp",
    "link": "https://arxiv.org/abs/2403.15214",
    "context": "Title: InstaSynth: Opportunities and Challenges in Generating Synthetic Instagram Data with ChatGPT for Sponsored Content Detection\nAbstract: arXiv:2403.15214v1 Announce Type: cross  Abstract: Large Language Models (LLMs) raise concerns about lowering the cost of generating texts that could be used for unethical or illegal purposes, especially on social media. This paper investigates the promise of such models to help enforce legal requirements related to the disclosure of sponsored content online. We investigate the use of LLMs for generating synthetic Instagram captions with two objectives: The first objective (fidelity) is to produce realistic synthetic datasets. For this, we implement content-level and network-level metrics to assess whether synthetic captions are realistic. The second objective (utility) is to create synthetic data that is useful for sponsored content detection. For this, we evaluate the effectiveness of the generated synthetic data for training classifiers to identify undisclosed advertisements on Instagram. Our investigations show that the objectives of fidelity and utility may conflict and that promp",
    "path": "papers/24/03/2403.15214.json",
    "total_tokens": 836,
    "translated_title": "InstaSynth：使用ChatGPT为赞助内容检测生成合成Instagram数据的机遇和挑战",
    "translated_abstract": "大型语言模型（LLMs）引发了有关降低生成可能被用于不道德或非法目的的文本成本的担忧，尤其是在社交媒体上。本文调查了这些模型帮助强制执行与在线披露赞助内容相关的法律要求的潜力。我们研究了使用LLMs生成合成Instagram标题的两个目标：第一个目标（保真度）是产生逼真的合成数据集。为此，我们实施了内容级和网络级指标来评估合成标题是否真实。第二个目标（实用性）是创建对赞助内容检测有用的合成数据。为此，我们评估了所生成合成数据用于训练分类器以识别Instagram上未公开广告的效果。我们的调查表明，保真度和实用性的目标可能存在冲突。",
    "tldr": "本文研究了使用大型语言模型帮助强制执行在线披露赞助内容相关法律要求的潜力，探讨了使用LLMs生成合成Instagram标题的保真度和实用性目标可能存在冲突。",
    "en_tdlr": "This paper investigates the potential of using large language models to enforce legal requirements related to disclosing sponsored content online, exploring the potential conflict between fidelity and utility objectives when generating synthetic Instagram captions with LLMS."
}