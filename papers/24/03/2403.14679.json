{
    "title": "Continual Learning by Three-Phase Consolidation",
    "abstract": "arXiv:2403.14679v1 Announce Type: new  Abstract: TPC (Three-Phase Consolidation) is here introduced as a simple but effective approach to continually learn new classes (and/or instances of known classes) while controlling forgetting of previous knowledge. Each experience (a.k.a. task) is learned in three phases characterized by different rules and learning dynamics, aimed at removing the class-bias problem (due to class unbalancing) and limiting gradient-based corrections to prevent forgetting of underrepresented classes. Several experiments on complex datasets demonstrate its accuracy and efficiency advantages over competitive existing approaches. The algorithm and all the results presented in this paper are fully reproducible thanks to its publication on the Avalanche open framework for continual learning.",
    "link": "https://arxiv.org/abs/2403.14679",
    "context": "Title: Continual Learning by Three-Phase Consolidation\nAbstract: arXiv:2403.14679v1 Announce Type: new  Abstract: TPC (Three-Phase Consolidation) is here introduced as a simple but effective approach to continually learn new classes (and/or instances of known classes) while controlling forgetting of previous knowledge. Each experience (a.k.a. task) is learned in three phases characterized by different rules and learning dynamics, aimed at removing the class-bias problem (due to class unbalancing) and limiting gradient-based corrections to prevent forgetting of underrepresented classes. Several experiments on complex datasets demonstrate its accuracy and efficiency advantages over competitive existing approaches. The algorithm and all the results presented in this paper are fully reproducible thanks to its publication on the Avalanche open framework for continual learning.",
    "path": "papers/24/03/2403.14679.json",
    "total_tokens": 765,
    "translated_title": "三阶段巩固的持续学习",
    "translated_abstract": "TPC (Three-Phase Consolidation)被引入作为一种简单但有效的方法，用于在控制遗忘先前知识的同时持续学习新类别（和/或已知类别的实例）。每个经验（也称为任务）都通过具有不同规则和学习动态的三个阶段来学习，旨在消除由于类别不平衡而导致的类别偏差问题，并限制基于梯度的校正，以防止遗忘少数类。复杂数据集上的多个实验证明了它在准确性和效率上优于现有竞争方法的优势。由于其发布在持续学习的Avalanche开放框架上，本文展示的算法和所有结果均可以完全可复制。",
    "tldr": "通过三阶段巩固的持续学习方法，旨在解决类别不平衡问题，限制梯度校正避免遗忘少数类，并在复杂数据集上展示了其准确性和效率优势。",
    "en_tdlr": "The paper introduces Three-Phase Consolidation (TPC) as a simple yet effective approach for continual learning, addressing the class-bias issue, limiting gradient-based corrections to prevent forgetting of underrepresented classes, and demonstrating accuracy and efficiency advantages on complex datasets."
}