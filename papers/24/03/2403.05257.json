{
    "title": "Cross-lingual Transfer or Machine Translation? On Data Augmentation for Monolingual Semantic Textual Similarity",
    "abstract": "arXiv:2403.05257v1 Announce Type: new  Abstract: Learning better sentence embeddings leads to improved performance for natural language understanding tasks including semantic textual similarity (STS) and natural language inference (NLI). As prior studies leverage large-scale labeled NLI datasets for fine-tuning masked language models to yield sentence embeddings, task performance for languages other than English is often left behind. In this study, we directly compared two data augmentation techniques as potential solutions for monolingual STS: (a) cross-lingual transfer that exploits English resources alone as training data to yield non-English sentence embeddings as zero-shot inference, and (b) machine translation that coverts English data into pseudo non-English training data in advance. In our experiments on monolingual STS in Japanese and Korean, we find that the two data techniques yield performance on par. Rather, we find a superiority of the Wikipedia domain over the NLI domain",
    "link": "https://arxiv.org/abs/2403.05257",
    "context": "Title: Cross-lingual Transfer or Machine Translation? On Data Augmentation for Monolingual Semantic Textual Similarity\nAbstract: arXiv:2403.05257v1 Announce Type: new  Abstract: Learning better sentence embeddings leads to improved performance for natural language understanding tasks including semantic textual similarity (STS) and natural language inference (NLI). As prior studies leverage large-scale labeled NLI datasets for fine-tuning masked language models to yield sentence embeddings, task performance for languages other than English is often left behind. In this study, we directly compared two data augmentation techniques as potential solutions for monolingual STS: (a) cross-lingual transfer that exploits English resources alone as training data to yield non-English sentence embeddings as zero-shot inference, and (b) machine translation that coverts English data into pseudo non-English training data in advance. In our experiments on monolingual STS in Japanese and Korean, we find that the two data techniques yield performance on par. Rather, we find a superiority of the Wikipedia domain over the NLI domain",
    "path": "papers/24/03/2403.05257.json",
    "total_tokens": 812,
    "translated_title": "跨语言转移还是机器翻译？关于单语义文本相似性的数据增强",
    "translated_abstract": "学习更好的句子嵌入将提高自然语言理解任务的性能，包括语义文本相似性（STS）和自然语言推理（NLI）。在本研究中，我们直接比较了作为单语STS潜在解决方案的两种数据增强技术：（a）利用仅英语资源作为训练数据以生成非英语句子嵌入作为零短推理的跨语言转移，以及（b）将英语数据提前转换为伪非英语训练数据的机器翻译。在我们在日语和韩语的单语STS实验中，我们发现这两种数据技术表现相当。相反，我们发现维基百科领域优于NLI领域",
    "tldr": "该研究对比了跨语言转移和机器翻译两种数据增强技术在单语义文本相似性中的表现，并发现维基百科领域优于NLI领域。",
    "en_tdlr": "This study compared cross-lingual transfer and machine translation for data augmentation in monolingual semantic textual similarity, finding the superiority of Wikipedia domain over NLI domain."
}