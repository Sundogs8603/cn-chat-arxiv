{
    "title": "Stochastic Gradient Langevin Unlearning",
    "abstract": "arXiv:2403.17105v1 Announce Type: new  Abstract: ``The right to be forgotten'' ensured by laws for user data privacy becomes increasingly important. Machine unlearning aims to efficiently remove the effect of certain data points on the trained model parameters so that it can be approximately the same as if one retrains the model from scratch. This work proposes stochastic gradient Langevin unlearning, the first unlearning framework based on noisy stochastic gradient descent (SGD) with privacy guarantees for approximate unlearning problems under convexity assumption. Our results show that mini-batch gradient updates provide a superior privacy-complexity trade-off compared to the full-batch counterpart. There are numerous algorithmic benefits of our unlearning approach, including complexity saving compared to retraining, and supporting sequential and batch unlearning. To examine the privacy-utility-complexity trade-off of our method, we conduct experiments on benchmark datasets compared ",
    "link": "https://arxiv.org/abs/2403.17105",
    "context": "Title: Stochastic Gradient Langevin Unlearning\nAbstract: arXiv:2403.17105v1 Announce Type: new  Abstract: ``The right to be forgotten'' ensured by laws for user data privacy becomes increasingly important. Machine unlearning aims to efficiently remove the effect of certain data points on the trained model parameters so that it can be approximately the same as if one retrains the model from scratch. This work proposes stochastic gradient Langevin unlearning, the first unlearning framework based on noisy stochastic gradient descent (SGD) with privacy guarantees for approximate unlearning problems under convexity assumption. Our results show that mini-batch gradient updates provide a superior privacy-complexity trade-off compared to the full-batch counterpart. There are numerous algorithmic benefits of our unlearning approach, including complexity saving compared to retraining, and supporting sequential and batch unlearning. To examine the privacy-utility-complexity trade-off of our method, we conduct experiments on benchmark datasets compared ",
    "path": "papers/24/03/2403.17105.json",
    "total_tokens": 865,
    "translated_title": "随机梯度 Langevin 反遗忘",
    "translated_abstract": "“被遗忘的权利”是用户数据隐私的法律所确保的越来越重要。机器反遗忘旨在高效地消除已训练模型参数上某些数据点的影响，使其近似于从头开始重新训练模型。本研究提出了随机梯度 Langevin 反遗忘，这是第一个基于带有隐私保障的噪声随机梯度下降（SGD）的反遗忘框架，适用于凸性假设下的近似反遗忘问题。我们的结果表明，与全批次对应方法相比，小批次梯度更新在隐私复杂度权衡方面提供了更好的性能。我们的反遗忘方法具有诸多算法优势，包括与重新训练相比的复杂度节省，以及支持顺序和批量反遗忘。为了检验我们方法的隐私-效用-复杂度权衡，我们在基准数据集上进行了实验比较。",
    "tldr": "本工作提出了随机梯度 Langevin 反遗忘方法，为近似反遗忘问题提供了隐私保障，并展示了小批次梯度更新相较于全批次的优越性能。"
}