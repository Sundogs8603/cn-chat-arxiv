{
    "title": "AcceleratedLiNGAM: Learning Causal DAGs at the speed of GPUs",
    "abstract": "arXiv:2403.03772v1 Announce Type: new  Abstract: Existing causal discovery methods based on combinatorial optimization or search are slow, prohibiting their application on large-scale datasets. In response, more recent methods attempt to address this limitation by formulating causal discovery as structure learning with continuous optimization but such approaches thus far provide no statistical guarantees. In this paper, we show that by efficiently parallelizing existing causal discovery methods, we can in fact scale them to thousands of dimensions, making them practical for substantially larger-scale problems. In particular, we parallelize the LiNGAM method, which is quadratic in the number of variables, obtaining up to a 32-fold speed-up on benchmark datasets when compared with existing sequential implementations. Specifically, we focus on the causal ordering subprocedure in DirectLiNGAM and implement GPU kernels to accelerate it. This allows us to apply DirectLiNGAM to causal inferen",
    "link": "https://arxiv.org/abs/2403.03772",
    "context": "Title: AcceleratedLiNGAM: Learning Causal DAGs at the speed of GPUs\nAbstract: arXiv:2403.03772v1 Announce Type: new  Abstract: Existing causal discovery methods based on combinatorial optimization or search are slow, prohibiting their application on large-scale datasets. In response, more recent methods attempt to address this limitation by formulating causal discovery as structure learning with continuous optimization but such approaches thus far provide no statistical guarantees. In this paper, we show that by efficiently parallelizing existing causal discovery methods, we can in fact scale them to thousands of dimensions, making them practical for substantially larger-scale problems. In particular, we parallelize the LiNGAM method, which is quadratic in the number of variables, obtaining up to a 32-fold speed-up on benchmark datasets when compared with existing sequential implementations. Specifically, we focus on the causal ordering subprocedure in DirectLiNGAM and implement GPU kernels to accelerate it. This allows us to apply DirectLiNGAM to causal inferen",
    "path": "papers/24/03/2403.03772.json",
    "total_tokens": 814,
    "translated_title": "加速LiNGAM: 以GPU速度学习因果DAGs",
    "translated_abstract": "现有基于组合优化或搜索的因果发现方法速度较慢，限制了它们在大规模数据集上的应用。最近的一些方法尝试通过连续优化的结构学习来解决这一限制，但迄今为止这些方法并未提供统计保证。本文通过有效地并行化现有的因果发现方法，展示我们实际上可以将它们扩展到数千个维度，使其在规模更大的问题上变得实用。具体而言，我们对LiNGAM方法进行了并行化，这种方法与变量数量成二次关系，与现有的顺序实现相比，我们在基准数据集上获得了多达32倍的加速。特别是，我们专注于DirectLiNGAM中的因果排序子过程，并实现了GPU核心以加速它。这使我们能够将DirectLiNGAM应用于因果推断。",
    "tldr": "通过有效地并行化现有的因果发现方法，本研究实现了对数千个维度的扩展，特别是将LiNGAM方法并行化，获得了多达32倍的加速。",
    "en_tdlr": "By efficiently parallelizing existing causal discovery methods, this study achieves scalability to thousands of dimensions, particularly through parallelizing the LiNGAM method for up to a 32-fold speed-up."
}