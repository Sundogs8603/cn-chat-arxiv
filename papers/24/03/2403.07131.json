{
    "title": "Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot Task Allocation",
    "abstract": "arXiv:2403.07131v1 Announce Type: new  Abstract: Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and efficient decision-making, which is often achieved using heuristics-aided methods such as genetic algorithms, auction-based methods, and bipartite graph matching methods. These methods often assume a form that lends better explainability compared to an end-to-end (learnt) neural network based policy for MRTA. However, deriving suitable heuristics can be tedious, risky and in some cases impractical if problems are too complex. This raises the question: can these heuristics be learned? To this end, this paper particularly develops a Graph Reinforcement Learning (GRL) framework to learn the heuristics or incentives for a bipartite graph matching approach to MRTA. Specifically a Capsule Attention policy model is used to learn how to weight task/robot pairings (edges) in the bipartite graph that connects the set of tasks to the set of robots. The original capsule att",
    "link": "https://arxiv.org/abs/2403.07131",
    "context": "Title: Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot Task Allocation\nAbstract: arXiv:2403.07131v1 Announce Type: new  Abstract: Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and efficient decision-making, which is often achieved using heuristics-aided methods such as genetic algorithms, auction-based methods, and bipartite graph matching methods. These methods often assume a form that lends better explainability compared to an end-to-end (learnt) neural network based policy for MRTA. However, deriving suitable heuristics can be tedious, risky and in some cases impractical if problems are too complex. This raises the question: can these heuristics be learned? To this end, this paper particularly develops a Graph Reinforcement Learning (GRL) framework to learn the heuristics or incentives for a bipartite graph matching approach to MRTA. Specifically a Capsule Attention policy model is used to learn how to weight task/robot pairings (edges) in the bipartite graph that connects the set of tasks to the set of robots. The original capsule att",
    "path": "papers/24/03/2403.07131.json",
    "total_tokens": 917,
    "translated_title": "带有学习激励函数的大图匹配用于多机器人任务分配",
    "translated_abstract": "大多数现实世界的多机器人任务分配（MRTA）问题需要快速高效的决策制定，通常通过使用启发式辅助方法（如遗传算法、基于拍卖的方法和二部图匹配方法）来实现。这些方法通常具有更好的可解释性形式，相比于MRTA的端到端（学习）神经网络政策。然而，获取适当的启发式方法可能很繁琐、风险较高，并且在某些情况下如果问题过于复杂可能不切实际。这就引发了一个问题：这些启发式方法能否被学习？为此，本文特别开发了一个图强化学习（GRL）框架，用于学习二部图匹配方法MRTA中的启发式或激励。具体地，使用了胶囊注意力策略模型来学习如何为连接任务集和机器人集的二部图中的任务/机器人配对（边）进行加权。",
    "tldr": "本文提出了一种带有学习激励函数的大图匹配方法，用于多机器人任务分配，通过开发图强化学习框架，学习二部图匹配方法MRTA中的启发式或激励。"
}