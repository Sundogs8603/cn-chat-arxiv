{
    "title": "Boundary Matters: A Bi-Level Active Finetuning Framework",
    "abstract": "arXiv:2403.10069v1 Announce Type: cross  Abstract: The pretraining-finetuning paradigm has gained widespread adoption in vision tasks and other fields, yet it faces the significant challenge of high sample annotation costs. To mitigate this, the concept of active finetuning has emerged, aiming to select the most appropriate samples for model finetuning within a limited budget. Traditional active learning methods often struggle in this setting due to their inherent bias in batch selection. Furthermore, the recent active finetuning approach has primarily concentrated on aligning the distribution of selected subsets with the overall data pool, focusing solely on diversity. In this paper, we propose a Bi-Level Active Finetuning framework to select the samples for annotation in one shot, which includes two stages: core sample selection for diversity, and boundary sample selection for uncertainty. The process begins with the identification of pseudo-class centers, followed by an innovative d",
    "link": "https://arxiv.org/abs/2403.10069",
    "context": "Title: Boundary Matters: A Bi-Level Active Finetuning Framework\nAbstract: arXiv:2403.10069v1 Announce Type: cross  Abstract: The pretraining-finetuning paradigm has gained widespread adoption in vision tasks and other fields, yet it faces the significant challenge of high sample annotation costs. To mitigate this, the concept of active finetuning has emerged, aiming to select the most appropriate samples for model finetuning within a limited budget. Traditional active learning methods often struggle in this setting due to their inherent bias in batch selection. Furthermore, the recent active finetuning approach has primarily concentrated on aligning the distribution of selected subsets with the overall data pool, focusing solely on diversity. In this paper, we propose a Bi-Level Active Finetuning framework to select the samples for annotation in one shot, which includes two stages: core sample selection for diversity, and boundary sample selection for uncertainty. The process begins with the identification of pseudo-class centers, followed by an innovative d",
    "path": "papers/24/03/2403.10069.json",
    "total_tokens": 811,
    "translated_title": "边界问题：一个双层主动微调框架",
    "translated_abstract": "预训练-微调范式在视觉任务和其他领域已经得到广泛采用，但面临高样本注释成本的重要挑战。为了减轻这一挑战，出现了主动微调的概念，旨在在有限预算内选择模型微调的最合适样本。传统的主动学习方法在这种设置下往往面临批量选择中的固有偏见。此外，最近的主动微调方法主要集中在使所选择的子集分布与整体数据池一致，仅关注多样性。在本文中，我们提出了一个双层主动微调框架，在一次选择过程中选择注释样本，包括两个阶段：用于多样性的核心样本选择和用于不确定性的边界样本选择。该过程从识别伪类中心开始，然后进行创新性的d",
    "tldr": "提出了一个双层主动微调框架，旨在通过一次选择过程来选择注释样本，其中包括核心样本选择以确保多样性和边界样本选择以处理不确定性。",
    "en_tdlr": "Introduced a bi-level active finetuning framework to select annotated samples in one shot, including core sample selection for diversity and boundary sample selection for uncertainty."
}