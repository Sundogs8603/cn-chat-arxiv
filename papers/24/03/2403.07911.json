{
    "title": "Standing on FURM ground -- A framework for evaluating Fair, Useful, and Reliable AI Models in healthcare systems",
    "abstract": "arXiv:2403.07911v1 Announce Type: cross  Abstract: The impact of using artificial intelligence (AI) to guide patient care or operational processes is an interplay of the AI model's output, the decision-making protocol based on that output, and the capacity of the stakeholders involved to take the necessary subsequent action. Estimating the effects of this interplay before deployment, and studying it in real time afterwards, are essential to bridge the chasm between AI model development and achievable benefit. To accomplish this, the Data Science team at Stanford Health Care has developed a mechanism to identify fair, useful and reliable AI models (FURM) by conducting an ethical review to identify potential value mismatches, simulations to estimate usefulness, financial projections to assess sustainability, as well as analyses to determine IT feasibility, design a deployment strategy, and recommend a prospective monitoring and evaluation plan. We report on FURM assessments done to evalu",
    "link": "https://arxiv.org/abs/2403.07911",
    "context": "Title: Standing on FURM ground -- A framework for evaluating Fair, Useful, and Reliable AI Models in healthcare systems\nAbstract: arXiv:2403.07911v1 Announce Type: cross  Abstract: The impact of using artificial intelligence (AI) to guide patient care or operational processes is an interplay of the AI model's output, the decision-making protocol based on that output, and the capacity of the stakeholders involved to take the necessary subsequent action. Estimating the effects of this interplay before deployment, and studying it in real time afterwards, are essential to bridge the chasm between AI model development and achievable benefit. To accomplish this, the Data Science team at Stanford Health Care has developed a mechanism to identify fair, useful and reliable AI models (FURM) by conducting an ethical review to identify potential value mismatches, simulations to estimate usefulness, financial projections to assess sustainability, as well as analyses to determine IT feasibility, design a deployment strategy, and recommend a prospective monitoring and evaluation plan. We report on FURM assessments done to evalu",
    "path": "papers/24/03/2403.07911.json",
    "total_tokens": 866,
    "translated_title": "站在FURM基础上-评估医疗系统中公平、有用和可靠AI模型的框架",
    "translated_abstract": "使用人工智能（AI）指导患者护理或操作流程的影响取决于AI模型的输出、基于该输出的决策协议以及相关利益相关者采取必要后续行动的能力。在部署前估计这种相互作用的影响，并在部署后实时研究它，对于弥合AI模型开发与可实现利益之间的鸿沟至关重要。为了实现这一点，斯坦福医疗保健的数据科学团队开发了一种机制，通过进行伦理审查以识别潜在的价值不匹配、仿真估算有用性、财务预测评估可持续性，以及分析确定IT可行性、设计部署策略，并建议前瞻性监测和评估计划来识别公平、有用和可靠的AI模型（FURM）。我们报告了对FURM评估进行的评估。",
    "tldr": "开发了一种机制来评估医疗系统中的公平、有用和可靠AI模型，弥合AI模型开发与实际受益之间的鸿沟。",
    "en_tdlr": "A mechanism has been developed to evaluate fair, useful, and reliable AI models in healthcare systems, bridging the gap between AI model development and achievable benefits."
}