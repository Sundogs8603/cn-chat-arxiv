{
    "title": "ProCQA: A Large-scale Community-based Programming Question Answering Dataset for Code Search",
    "abstract": "arXiv:2403.16702v1 Announce Type: new  Abstract: Retrieval-based code question answering seeks to match user queries in natural language to relevant code snippets. Previous approaches typically rely on pretraining models using crafted bi-modal and uni-modal datasets to align text and code representations. In this paper, we introduce ProCQA, a large-scale programming question answering dataset extracted from the StackOverflow community, offering naturally structured mixed-modal QA pairs. To validate its effectiveness, we propose a modality-agnostic contrastive pre-training approach to improve the alignment of text and code representations of current code language models. Compared to previous models that primarily employ bimodal and unimodal pairs extracted from CodeSearchNet for pre-training, our model exhibits significant performance improvements across a wide range of code retrieval benchmarks.",
    "link": "https://arxiv.org/abs/2403.16702",
    "context": "Title: ProCQA: A Large-scale Community-based Programming Question Answering Dataset for Code Search\nAbstract: arXiv:2403.16702v1 Announce Type: new  Abstract: Retrieval-based code question answering seeks to match user queries in natural language to relevant code snippets. Previous approaches typically rely on pretraining models using crafted bi-modal and uni-modal datasets to align text and code representations. In this paper, we introduce ProCQA, a large-scale programming question answering dataset extracted from the StackOverflow community, offering naturally structured mixed-modal QA pairs. To validate its effectiveness, we propose a modality-agnostic contrastive pre-training approach to improve the alignment of text and code representations of current code language models. Compared to previous models that primarily employ bimodal and unimodal pairs extracted from CodeSearchNet for pre-training, our model exhibits significant performance improvements across a wide range of code retrieval benchmarks.",
    "path": "papers/24/03/2403.16702.json",
    "total_tokens": 814,
    "translated_title": "ProCQA：一个用于代码搜索的大规模基于社区的编程问题回答数据集",
    "translated_abstract": "检索式代码问答旨在将用户在自然语言中的查询与相关代码片段匹配。先前的方法通常依赖于使用精心设计的双模态和单模态数据集进行预训练模型，以对齐文本和代码表示。在本文中，我们介绍了ProCQA，这是一个从StackOverflow社区中提取的大规模编程问题回答数据集，提供自然结构化的混合模态问答对。为了验证其有效性，我们提出了一种模态不可知的对比训练方法，以改善当前代码语言模型的文本和代码表示的对齐。与先前主要使用从CodeSearchNet中提取的双模态和单模态对进行预训练的模型相比，我们的模型在广泛的代码检索基准上表现出显著的性能改进。",
    "tldr": "ProCQA数据集是从StackOverflow社区提取的，为编程问题回答提供了自然结构化的混合模态问答对，并引入了一种模态-不可知的对比预训练方法，显著提高了代码语言模型的性能。",
    "en_tdlr": "The ProCQA dataset, extracted from the StackOverflow community, provides naturally structured mixed-modal QA pairs for programming question answering, and introduces a modality-agnostic contrastive pre-training approach that significantly improves the performance of code language models."
}