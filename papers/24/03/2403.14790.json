{
    "title": "Latent Diffusion Models for Attribute-Preserving Image Anonymization",
    "abstract": "arXiv:2403.14790v1 Announce Type: cross  Abstract: Generative techniques for image anonymization have great potential to generate datasets that protect the privacy of those depicted in the images, while achieving high data fidelity and utility. Existing methods have focused extensively on preserving facial attributes, but failed to embrace a more comprehensive perspective that considers the scene and background into the anonymization process. This paper presents, to the best of our knowledge, the first approach to image anonymization based on Latent Diffusion Models (LDMs). Every element of a scene is maintained to convey the same meaning, yet manipulated in a way that makes re-identification difficult. We propose two LDMs for this purpose: CAMOUFLaGE-Base exploits a combination of pre-trained ControlNets, and a new controlling mechanism designed to increase the distance between the real and anonymized images. CAMOFULaGE-Light is based on the Adapter technique, coupled with an encoding",
    "link": "https://arxiv.org/abs/2403.14790",
    "context": "Title: Latent Diffusion Models for Attribute-Preserving Image Anonymization\nAbstract: arXiv:2403.14790v1 Announce Type: cross  Abstract: Generative techniques for image anonymization have great potential to generate datasets that protect the privacy of those depicted in the images, while achieving high data fidelity and utility. Existing methods have focused extensively on preserving facial attributes, but failed to embrace a more comprehensive perspective that considers the scene and background into the anonymization process. This paper presents, to the best of our knowledge, the first approach to image anonymization based on Latent Diffusion Models (LDMs). Every element of a scene is maintained to convey the same meaning, yet manipulated in a way that makes re-identification difficult. We propose two LDMs for this purpose: CAMOUFLaGE-Base exploits a combination of pre-trained ControlNets, and a new controlling mechanism designed to increase the distance between the real and anonymized images. CAMOFULaGE-Light is based on the Adapter technique, coupled with an encoding",
    "path": "papers/24/03/2403.14790.json",
    "total_tokens": 884,
    "translated_title": "基于潜在扩散模型进行属性保留图像匿名化",
    "translated_abstract": "图像匿名化的生成技术对于生成能够保护图像中被描述个体隐私的数据集具有巨大潜力，同时实现高数据保真度和实用性。现有方法在保留面部属性方面进行了大量研究，但未能采纳更全面的视角，考虑在匿名化过程中将场景和背景纳入考虑。本文提出了一种基于潜在扩散模型（LDMs）的图像匿名化方法，据我们所知，这是首个采用这种方法的研究。场景的每一个元素都被保留以传达相同的意义，但以一种使重新识别变得困难的方式进行操纵。我们针对此目的提出了两种LDMs：CAMOUFLaGE-Base利用预训练的ControlNets的组合，以及一种旨在增加实际图像和匿名化图像之间距离的新控制机制。CAMOFULaGE-Light基于Adapter技术，并配备了一种编码",
    "tldr": "这项研究提出了基于潜在扩散模型的图像匿名化方法，通过保留场景中的每个元素传达相同意义，但使得重新识别变得困难。",
    "en_tdlr": "This study introduces an image anonymization method based on Latent Diffusion Models, which maintains every element in a scene to convey the same meaning but makes re-identification difficult."
}