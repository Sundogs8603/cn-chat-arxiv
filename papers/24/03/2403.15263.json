{
    "title": "Federated Bayesian Deep Learning: The Application of Statistical Aggregation Methods to Bayesian Models",
    "abstract": "arXiv:2403.15263v1 Announce Type: new  Abstract: Federated learning (FL) is an approach to training machine learning models that takes advantage of multiple distributed datasets while maintaining data privacy and reducing communication costs associated with sharing local datasets. Aggregation strategies have been developed to pool or fuse the weights and biases of distributed deterministic models; however, modern deterministic deep learning (DL) models are often poorly calibrated and lack the ability to communicate a measure of epistemic uncertainty in prediction, which is desirable for remote sensing platforms and safety-critical applications. Conversely, Bayesian DL models are often well calibrated and capable of quantifying and communicating a measure of epistemic uncertainty along with a competitive prediction accuracy. Unfortunately, because the weights and biases in Bayesian DL models are defined by a probability distribution, simple application of the aggregation methods associa",
    "link": "https://arxiv.org/abs/2403.15263",
    "context": "Title: Federated Bayesian Deep Learning: The Application of Statistical Aggregation Methods to Bayesian Models\nAbstract: arXiv:2403.15263v1 Announce Type: new  Abstract: Federated learning (FL) is an approach to training machine learning models that takes advantage of multiple distributed datasets while maintaining data privacy and reducing communication costs associated with sharing local datasets. Aggregation strategies have been developed to pool or fuse the weights and biases of distributed deterministic models; however, modern deterministic deep learning (DL) models are often poorly calibrated and lack the ability to communicate a measure of epistemic uncertainty in prediction, which is desirable for remote sensing platforms and safety-critical applications. Conversely, Bayesian DL models are often well calibrated and capable of quantifying and communicating a measure of epistemic uncertainty along with a competitive prediction accuracy. Unfortunately, because the weights and biases in Bayesian DL models are defined by a probability distribution, simple application of the aggregation methods associa",
    "path": "papers/24/03/2403.15263.json",
    "total_tokens": 825,
    "translated_title": "联邦贝叶斯深度学习：统计聚合方法应用于贝叶斯模型",
    "translated_abstract": "联邦学习(FL)是一种训练机器学习模型的方法，利用多个分布式数据集，同时保持数据隐私和减少与共享本地数据集相关的通信成本。已经开发了聚合策略，用于整合或融合分布式确定性模型的权重和偏差；然而，现代确定性深度学习（DL）模型通常校准不佳，缺乏在预测中传达一种认识不确定性的能力，这对遥感平台和安全关键应用是理想的。相反，贝叶斯DL模型通常校准良好，能够量化和传达一种认识不确定性的能力以及具有竞争力的预测准确性。不幸的是，因为贝叶斯DL模型中的权重和偏差由概率分布定义，所以简单应用聚合方法是困难的。",
    "tldr": "该论文研究了联邦贝叶斯深度学习的方法，旨在解决在现代深度学习模型中传达认识不确定性的挑战。",
    "en_tdlr": "This paper explores the method of federated Bayesian deep learning to address the challenge of conveying epistemic uncertainty in modern deep learning models."
}