{
    "title": "CLIP the Bias: How Useful is Balancing Data in Multimodal Learning?",
    "abstract": "arXiv:2403.04547v1 Announce Type: cross  Abstract: We study the effectiveness of data-balancing for mitigating biases in contrastive language-image pretraining (CLIP), identifying areas of strength and limitation. First, we reaffirm prior conclusions that CLIP models can inadvertently absorb societal stereotypes. To counter this, we present a novel algorithm, called Multi-Modal Moment Matching (M4), designed to reduce both representation and association biases (i.e. in first- and second-order statistics) in multimodal data. We use M4 to conduct an in-depth analysis taking into account various factors, such as the model, representation, and data size. Our study also explores the dynamic nature of how CLIP learns and unlearns biases. In particular, we find that fine-tuning is effective in countering representation biases, though its impact diminishes for association biases. Also, data balancing has a mixed impact on quality: it tends to improve classification but can hurt retrieval. Inte",
    "link": "https://arxiv.org/abs/2403.04547",
    "context": "Title: CLIP the Bias: How Useful is Balancing Data in Multimodal Learning?\nAbstract: arXiv:2403.04547v1 Announce Type: cross  Abstract: We study the effectiveness of data-balancing for mitigating biases in contrastive language-image pretraining (CLIP), identifying areas of strength and limitation. First, we reaffirm prior conclusions that CLIP models can inadvertently absorb societal stereotypes. To counter this, we present a novel algorithm, called Multi-Modal Moment Matching (M4), designed to reduce both representation and association biases (i.e. in first- and second-order statistics) in multimodal data. We use M4 to conduct an in-depth analysis taking into account various factors, such as the model, representation, and data size. Our study also explores the dynamic nature of how CLIP learns and unlearns biases. In particular, we find that fine-tuning is effective in countering representation biases, though its impact diminishes for association biases. Also, data balancing has a mixed impact on quality: it tends to improve classification but can hurt retrieval. Inte",
    "path": "papers/24/03/2403.04547.json",
    "total_tokens": 852,
    "translated_title": "CLIP去偏见：在多模态学习中平衡数据有多大用处？",
    "translated_abstract": "我们研究了数据平衡对于减轻对比语言-图像预训练（CLIP）中的偏见的有效性，确定了其优势和局限性。首先，我们重申了以前的结论，即CLIP模型可能会无意中吸收社会刻板印象。为了应对这一问题，我们提出了一种新的算法，称为多模态时刻匹配（M4），旨在减少多模态数据中的表示和关联偏见（即一阶和二阶统计）。我们使用M4进行了深入分析，考虑了模型、表示和数据大小等各种因素。我们的研究还探讨了CLIP学习和消除偏见的动态特性。特别是，我们发现微调可以有效地抵制表示偏见，但对关联偏见的影响逐渐减弱。此外，数据平衡对质量有着复杂的影响：它倾向于改善分类，但可能会损害检索。",
    "tldr": "数据平衡在对比语言-图像预训练（CLIP）中可以部分改善偏见问题，然而会对质量产生复杂影响。",
    "en_tdlr": "Balancing data in contrastive language-image pretraining (CLIP) can partially improve bias issues but has complex effects on quality."
}