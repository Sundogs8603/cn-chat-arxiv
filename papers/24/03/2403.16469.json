{
    "title": "Learning from Reduced Labels for Long-Tailed Data",
    "abstract": "arXiv:2403.16469v1 Announce Type: new  Abstract: Long-tailed data is prevalent in real-world classification tasks and heavily relies on supervised information, which makes the annotation process exceptionally labor-intensive and time-consuming. Unfortunately, despite being a common approach to mitigate labeling costs, existing weakly supervised learning methods struggle to adequately preserve supervised information for tail samples, resulting in a decline in accuracy for the tail classes. To alleviate this problem, we introduce a novel weakly supervised labeling setting called Reduced Label. The proposed labeling setting not only avoids the decline of supervised information for the tail samples, but also decreases the labeling costs associated with long-tailed data. Additionally, we propose an straightforward and highly efficient unbiased framework with strong theoretical guarantees to learn from these Reduced Labels. Extensive experiments conducted on benchmark datasets including Imag",
    "link": "https://arxiv.org/abs/2403.16469",
    "context": "Title: Learning from Reduced Labels for Long-Tailed Data\nAbstract: arXiv:2403.16469v1 Announce Type: new  Abstract: Long-tailed data is prevalent in real-world classification tasks and heavily relies on supervised information, which makes the annotation process exceptionally labor-intensive and time-consuming. Unfortunately, despite being a common approach to mitigate labeling costs, existing weakly supervised learning methods struggle to adequately preserve supervised information for tail samples, resulting in a decline in accuracy for the tail classes. To alleviate this problem, we introduce a novel weakly supervised labeling setting called Reduced Label. The proposed labeling setting not only avoids the decline of supervised information for the tail samples, but also decreases the labeling costs associated with long-tailed data. Additionally, we propose an straightforward and highly efficient unbiased framework with strong theoretical guarantees to learn from these Reduced Labels. Extensive experiments conducted on benchmark datasets including Imag",
    "path": "papers/24/03/2403.16469.json",
    "total_tokens": 805,
    "translated_title": "学习从减少标签的长尾数据中",
    "translated_abstract": "长尾数据在现实世界的分类任务中普遍存在，并且严重依赖监督信息，这使得注释过程异常耗时且费力。然而，尽管减少标注成本是缓解标签成本的常见方法，但现有的弱监督学习方法很难充分保留尾部样本的监督信息，导致尾部类别的准确率下降。为了缓解这一问题，我们提出了一种名为Reduced Label的新型弱监督标签设置。所提出的标签设置不仅避免了尾部样本的监督信息下降，还减少了与长尾数据相关的标签成本。此外，我们提出了一个简单直观且高效的无偏框架，具有强大的理论保证，可以从这些Reduced Labels中学习。在包括Imag在内的基准数据集上进行了广泛的实验",
    "tldr": "提出了一种名为Reduced Label的新型弱监督标签设置，能够高效地学习长尾数据，避免了尾部样本监督信息的下降，降低了标签成本",
    "en_tdlr": "Introducing a novel weakly supervised labeling setting called Reduced Label that efficiently learns from long-tailed data, avoids decline in supervised information for tail samples, and reduces labeling costs."
}