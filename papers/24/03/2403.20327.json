{
    "title": "Gecko: Versatile Text Embeddings Distilled from Large Language Models",
    "abstract": "arXiv:2403.20327v1 Announce Type: new  Abstract: We present Gecko, a compact and versatile text embedding model. Gecko achieves strong retrieval performance by leveraging a key idea: distilling knowledge from large language models (LLMs) into a retriever. Our two-step distillation process begins with generating diverse, synthetic paired data using an LLM. Next, we further refine the data quality by retrieving a set of candidate passages for each query, and relabeling the positive and hard negative passages using the same LLM. The effectiveness of our approach is demonstrated by the compactness of the Gecko. On the Massive Text Embedding Benchmark (MTEB), Gecko with 256 embedding dimensions outperforms all existing entries with 768 embedding size. Gecko with 768 embedding dimensions achieves an average score of 66.31, competing with 7x larger models and 5x higher dimensional embeddings.",
    "link": "https://arxiv.org/abs/2403.20327",
    "context": "Title: Gecko: Versatile Text Embeddings Distilled from Large Language Models\nAbstract: arXiv:2403.20327v1 Announce Type: new  Abstract: We present Gecko, a compact and versatile text embedding model. Gecko achieves strong retrieval performance by leveraging a key idea: distilling knowledge from large language models (LLMs) into a retriever. Our two-step distillation process begins with generating diverse, synthetic paired data using an LLM. Next, we further refine the data quality by retrieving a set of candidate passages for each query, and relabeling the positive and hard negative passages using the same LLM. The effectiveness of our approach is demonstrated by the compactness of the Gecko. On the Massive Text Embedding Benchmark (MTEB), Gecko with 256 embedding dimensions outperforms all existing entries with 768 embedding size. Gecko with 768 embedding dimensions achieves an average score of 66.31, competing with 7x larger models and 5x higher dimensional embeddings.",
    "path": "papers/24/03/2403.20327.json",
    "total_tokens": 856,
    "translated_title": "由大型语言模型提炼出的多功能文本嵌入式模型Gecko",
    "translated_abstract": "我们提出了Gecko，一种紧凑而多功能的文本嵌入式模型。Gecko通过利用一个关键思想实现了强大的检索性能：将大型语言模型(LLMs)中的知识提炼为检索器。我们的两步提炼过程首先涉及使用LLM生成多样化合成的配对数据。接下来，我们通过为每个查询检索一组候选段落，并使用相同的LLM重新标记正面和困难的负面段落，进一步提高数据质量。Gecko模型的紧凑性展示了我们方法的有效性。在大规模文本嵌入式基准测试(MTEB)上，具有256嵌入维度的Gecko的表现优于所有现有的768嵌入尺寸的条目。具有768嵌入维度的Gecko实现了平均得分66.31，与7倍大的模型和5倍高维嵌入相竞争。",
    "tldr": "Gecko是一种紧凑而多功能的文本嵌入式模型，通过提炼大型语言模型中的知识为检索器，在性能上表现出色，并在Massive Text Embedding Benchmark上超越了现有的所有条目。",
    "en_tdlr": "Gecko is a compact and versatile text embedding model that distills knowledge from large language models into a retriever, achieving strong retrieval performance and outperforming all existing entries on the Massive Text Embedding Benchmark."
}