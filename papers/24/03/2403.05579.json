{
    "title": "Cultural Bias in Explainable AI Research: A Systematic Analysis",
    "abstract": "arXiv:2403.05579v1 Announce Type: cross  Abstract: For synergistic interactions between humans and artificial intelligence (AI) systems, AI outputs often need to be explainable to people. Explainable AI (XAI) systems are commonly tested in human user studies. However, whether XAI researchers consider potential cultural differences in human explanatory needs remains unexplored. We highlight psychological research that found significant differences in human explanations between many people from Western, commonly individualist countries and people from non-Western, often collectivist countries. We argue that XAI research currently overlooks these variations and that many popular XAI designs implicitly and problematically assume that Western explanatory needs are shared cross-culturally. Additionally, we systematically reviewed over 200 XAI user studies and found that most studies did not consider relevant cultural variations, sampled only Western populations, but drew conclusions about hu",
    "link": "https://arxiv.org/abs/2403.05579",
    "context": "Title: Cultural Bias in Explainable AI Research: A Systematic Analysis\nAbstract: arXiv:2403.05579v1 Announce Type: cross  Abstract: For synergistic interactions between humans and artificial intelligence (AI) systems, AI outputs often need to be explainable to people. Explainable AI (XAI) systems are commonly tested in human user studies. However, whether XAI researchers consider potential cultural differences in human explanatory needs remains unexplored. We highlight psychological research that found significant differences in human explanations between many people from Western, commonly individualist countries and people from non-Western, often collectivist countries. We argue that XAI research currently overlooks these variations and that many popular XAI designs implicitly and problematically assume that Western explanatory needs are shared cross-culturally. Additionally, we systematically reviewed over 200 XAI user studies and found that most studies did not consider relevant cultural variations, sampled only Western populations, but drew conclusions about hu",
    "path": "papers/24/03/2403.05579.json",
    "total_tokens": 823,
    "translated_title": "Explainable AI研究中的文化偏见：一项系统性分析",
    "translated_abstract": "为了使人类和人工智能（AI）系统之间的协同作用更加有效，人工智能的输出通常需要向人类解释。可解释的人工智能（XAI）系统通常在人类用户研究中进行测试。然而，XAI研究人员是否考虑了人类解释需求中的文化差异仍未被探讨。我们强调了一项心理研究发现，普遍来自西方个人主义国家的人们和经常来自非西方集体主义国家的人们在解释上存在明显差异。我们认为，XAI研究目前忽视了这些差异，并且许多流行的XAI设计隐含地且问题地假设西方的解释需求在跨文化中是共享的。此外，我们系统性地审查了超过200个XAI用户研究，发现大多数研究未考虑相关的文化变化，只对西方人口进行了取样，但对人类的结论取得的是关于人类整体的。",
    "tldr": "XAI研究普遍忽视了潜在的文化差异，过于假设西方解释需求在全球通用。",
    "en_tdlr": "XAI research commonly overlooks potential cultural differences, overly assuming that Western explanatory needs are universally shared."
}