{
    "title": "FIMBA: Evaluating the Robustness of AI in Genomics via Feature Importance Adversarial Attacks. (arXiv:2401.10657v1 [cs.LG])",
    "abstract": "With the steady rise of the use of AI in bio-technical applications and the widespread adoption of genomics sequencing, an increasing amount of AI-based algorithms and tools is entering the research and production stage affecting critical decision-making streams like drug discovery and clinical outcomes. This paper demonstrates the vulnerability of AI models often utilized downstream tasks on recognized public genomics datasets. We undermine model robustness by deploying an attack that focuses on input transformation while mimicking the real data and confusing the model decision-making, ultimately yielding a pronounced deterioration in model performance. Further, we enhance our approach by generating poisoned data using a variational autoencoder-based model. Our empirical findings unequivocally demonstrate a decline in model performance, underscored by diminished accuracy and an upswing in false positives and false negatives. Furthermore, we analyze the resulting adversarial samples vi",
    "link": "http://arxiv.org/abs/2401.10657",
    "context": "Title: FIMBA: Evaluating the Robustness of AI in Genomics via Feature Importance Adversarial Attacks. (arXiv:2401.10657v1 [cs.LG])\nAbstract: With the steady rise of the use of AI in bio-technical applications and the widespread adoption of genomics sequencing, an increasing amount of AI-based algorithms and tools is entering the research and production stage affecting critical decision-making streams like drug discovery and clinical outcomes. This paper demonstrates the vulnerability of AI models often utilized downstream tasks on recognized public genomics datasets. We undermine model robustness by deploying an attack that focuses on input transformation while mimicking the real data and confusing the model decision-making, ultimately yielding a pronounced deterioration in model performance. Further, we enhance our approach by generating poisoned data using a variational autoencoder-based model. Our empirical findings unequivocally demonstrate a decline in model performance, underscored by diminished accuracy and an upswing in false positives and false negatives. Furthermore, we analyze the resulting adversarial samples vi",
    "path": "papers/24/01/2401.10657.json",
    "total_tokens": 920,
    "translated_title": "FIMBA:通过特征重要性对抗攻击评估基因组学中人工智能的鲁棒性",
    "translated_abstract": "随着人工智能在生物技术应用中的不断增长和基因组测序的广泛采用，越来越多基于人工智能的算法和工具进入研究和生产阶段，影响着药物发现和临床结果等重要决策流程。本文通过在公认的基因组学数据集上进行模型对抗攻击，展示了人工智能模型在下游任务中的脆弱性。我们通过采用模拟真实数据并混淆模型决策的输入转换攻击，从而大幅度降低了模型的性能。此外，我们通过使用变分自动编码器模型来生成有毒数据来增强我们的攻击方法。实验结果明确表明模型性能下降，准确率降低，假阳性和假阴性增加。此外，我们还分析了生成的对抗样本。",
    "tldr": "本文通过对抗攻击展示了基因组学中人工智能模型的脆弱性，同时提出了一种基于输入转换的攻击方法和使用变分自动编码器模型生成有毒数据的增强方法。实验结果表明模型性能下降，准确率降低，假阳性和假阴性增加。",
    "en_tdlr": "This paper demonstrates the vulnerability of AI models in genomics through adversarial attacks, and proposes an attack method based on input transformation and an enhancement method using a variational autoencoder model to generate poisoned data. The experimental results show a decline in model performance, decreased accuracy, and an increase in false positives and false negatives."
}