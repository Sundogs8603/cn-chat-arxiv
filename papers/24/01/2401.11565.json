{
    "title": "Thompson Sampling for Stochastic Bandits with Noisy Contexts: An Information-Theoretic Regret Analysis. (arXiv:2401.11565v1 [cs.LG])",
    "abstract": "We explore a stochastic contextual linear bandit problem where the agent observes a noisy, corrupted version of the true context through a noise channel with an unknown noise parameter. Our objective is to design an action policy that can approximate\" that of an oracle, which has access to the reward model, the channel parameter, and the predictive distribution of the true context from the observed noisy context. In a Bayesian framework, we introduce a Thompson sampling algorithm for Gaussian bandits with Gaussian context noise. Adopting an information-theoretic analysis, we demonstrate the Bayesian regret of our algorithm concerning the oracle's action policy. We also extend this problem to a scenario where the agent observes the true context with some delay after receiving the reward and show that delayed true contexts lead to lower Bayesian regret. Finally, we empirically demonstrate the performance of the proposed algorithms against baselines.",
    "link": "http://arxiv.org/abs/2401.11565",
    "context": "Title: Thompson Sampling for Stochastic Bandits with Noisy Contexts: An Information-Theoretic Regret Analysis. (arXiv:2401.11565v1 [cs.LG])\nAbstract: We explore a stochastic contextual linear bandit problem where the agent observes a noisy, corrupted version of the true context through a noise channel with an unknown noise parameter. Our objective is to design an action policy that can approximate\" that of an oracle, which has access to the reward model, the channel parameter, and the predictive distribution of the true context from the observed noisy context. In a Bayesian framework, we introduce a Thompson sampling algorithm for Gaussian bandits with Gaussian context noise. Adopting an information-theoretic analysis, we demonstrate the Bayesian regret of our algorithm concerning the oracle's action policy. We also extend this problem to a scenario where the agent observes the true context with some delay after receiving the reward and show that delayed true contexts lead to lower Bayesian regret. Finally, we empirically demonstrate the performance of the proposed algorithms against baselines.",
    "path": "papers/24/01/2401.11565.json",
    "total_tokens": 951,
    "translated_title": "Thompson采样用于具有噪音上下文的随机赌臂问题的信息论性后悔分析",
    "translated_abstract": "我们研究了一种随机上下文线性赌臂问题，其中代理通过一个未知噪声参数的噪声信道观察到真实上下文的噪声，我们的目标是设计一个动作策略，可以近似于具有奖励模型、噪声参数和从观察到的噪声上下文中真实上下文的预测分布的oracle的动作策略。在贝叶斯框架下，我们引入了一种针对具有高斯上下文噪声的高斯赌臂的Thompson采样算法。采用信息论分析，我们证明了我们的算法相对于oracle的动作策略的贝叶斯后悔。我们还将这个问题扩展到了代理在接收到奖励后延迟观察到真实上下文的情况，并展示了延迟真实上下文导致更低的贝叶斯后悔。最后，我们通过与基线算法的比较实证地展示了所提出算法的性能。",
    "tldr": "本文研究了具有噪音上下文的随机赌臂问题，并提出了一种Thompson采样算法，通过贝叶斯框架进行分析，证明了算法的贝叶斯后悔，并扩展了问题到延迟观察真实上下文的情况，并实证了算法的性能。",
    "en_tdlr": "This paper explores the problem of stochastic contextual linear bandits with noisy contexts and proposes a Thompson sampling algorithm. Using a Bayesian framework, the algorithm's Bayesian regret is analyzed and the problem is extended to delayed observation of true contexts, with empirical performance evaluation provided."
}