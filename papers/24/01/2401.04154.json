{
    "title": "Efficient Selective Audio Masked Multimodal Bottleneck Transformer for Audio-Video Classification. (arXiv:2401.04154v1 [cs.CV])",
    "abstract": "Audio and video are two most common modalities in the mainstream media platforms, e.g., YouTube. To learn from multimodal videos effectively, in this work, we propose a novel audio-video recognition approach termed audio video Transformer, AVT, leveraging the effective spatio-temporal representation by the video Transformer to improve action recognition accuracy. For multimodal fusion, simply concatenating multimodal tokens in a cross-modal Transformer requires large computational and memory resources, instead we reduce the cross-modality complexity through an audio-video bottleneck Transformer. To improve the learning efficiency of multimodal Transformer, we integrate self-supervised objectives, i.e., audio-video contrastive learning, audio-video matching, and masked audio and video learning, into AVT training, which maps diverse audio and video representations into a common multimodal representation space. We further propose a masked audio segment loss to learn semantic audio activit",
    "link": "http://arxiv.org/abs/2401.04154",
    "context": "Title: Efficient Selective Audio Masked Multimodal Bottleneck Transformer for Audio-Video Classification. (arXiv:2401.04154v1 [cs.CV])\nAbstract: Audio and video are two most common modalities in the mainstream media platforms, e.g., YouTube. To learn from multimodal videos effectively, in this work, we propose a novel audio-video recognition approach termed audio video Transformer, AVT, leveraging the effective spatio-temporal representation by the video Transformer to improve action recognition accuracy. For multimodal fusion, simply concatenating multimodal tokens in a cross-modal Transformer requires large computational and memory resources, instead we reduce the cross-modality complexity through an audio-video bottleneck Transformer. To improve the learning efficiency of multimodal Transformer, we integrate self-supervised objectives, i.e., audio-video contrastive learning, audio-video matching, and masked audio and video learning, into AVT training, which maps diverse audio and video representations into a common multimodal representation space. We further propose a masked audio segment loss to learn semantic audio activit",
    "path": "papers/24/01/2401.04154.json",
    "total_tokens": 886,
    "translated_title": "高效选择性音频掩蔽多模态瓶颈Transformer用于音视频分类",
    "translated_abstract": "音频和视频是主流媒体平台（如YouTube）中最常见的两种形式。为了有效地从多模态视频中学习，本文提出了一种新的音视频识别方法，称为音视频Transformer（AVT），利用视频Transformer的有效时空表示来提高动作识别的准确性。为了进行多模态融合，简单地通过跨模态Transformer连接多模态令牌会占用大量计算和内存资源，因此我们通过音视频瓶颈Transformer降低了跨模态复杂性。为了提高多模态Transformer的学习效率，我们将自监督目标（即音视频对比学习、音视频匹配和音视频遮蔽学习）整合到AVT训练中，将多样的音频和视频表示映射到一个通用的多模态表示空间中。我们还提出了一个音频片段遮蔽损失来学习语义音频活动。",
    "tldr": "这项研究提出了一种高效选择性音频掩蔽多模态瓶颈Transformer用于音视频分类，通过音视频Transformer提取时空表示并结合自监督目标进行训练，实现了有效的多模态学习和语义音频活动的学习。",
    "en_tdlr": "This research introduces an efficient selective audio masked multimodal bottleneck Transformer for audio-video classification. It improves action recognition accuracy by leveraging effective spatio-temporal representation from the video Transformer. By integrating self-supervised objectives and using a masked audio segment loss, it achieves efficient multimodal learning and semantic audio activity."
}