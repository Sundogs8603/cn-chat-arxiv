{
    "title": "How the Advent of Ubiquitous Large Language Models both Stymie and Turbocharge Dynamic Adversarial Question Generation. (arXiv:2401.11185v1 [cs.CL])",
    "abstract": "Dynamic adversarial question generation, where humans write examples to stump a model, aims to create examples that are realistic and informative. However, the advent of large language models (LLMs) has been a double-edged sword for human authors: more people are interested in seeing and pushing the limits of these models, but because the models are so much stronger an opponent, they are harder to defeat. To understand how these models impact adversarial question writing process, we enrich the writing guidance with LLMs and retrieval models for the authors to reason why their questions are not adversarial. While authors could create interesting, challenging adversarial questions, they sometimes resort to tricks that result in poor questions that are ambiguous, subjective, or confusing not just to a computer but also to humans. To address these issues, we propose new metrics and incentives for eliciting good, challenging questions and present a new dataset of adversarially authored ques",
    "link": "http://arxiv.org/abs/2401.11185",
    "context": "Title: How the Advent of Ubiquitous Large Language Models both Stymie and Turbocharge Dynamic Adversarial Question Generation. (arXiv:2401.11185v1 [cs.CL])\nAbstract: Dynamic adversarial question generation, where humans write examples to stump a model, aims to create examples that are realistic and informative. However, the advent of large language models (LLMs) has been a double-edged sword for human authors: more people are interested in seeing and pushing the limits of these models, but because the models are so much stronger an opponent, they are harder to defeat. To understand how these models impact adversarial question writing process, we enrich the writing guidance with LLMs and retrieval models for the authors to reason why their questions are not adversarial. While authors could create interesting, challenging adversarial questions, they sometimes resort to tricks that result in poor questions that are ambiguous, subjective, or confusing not just to a computer but also to humans. To address these issues, we propose new metrics and incentives for eliciting good, challenging questions and present a new dataset of adversarially authored ques",
    "path": "papers/24/01/2401.11185.json",
    "total_tokens": 953,
    "translated_title": "万物普及的大型语言模型的出现既阻碍又推动了动态对抗性问题生成",
    "translated_abstract": "动态对抗性问题生成旨在生成既真实又有信息的示例来困扰模型，然而，大型语言模型（LLMs）的出现对人类作者来说是一把双刃剑：更多人对这些模型感兴趣并推动其极限，但由于模型对手更强大，难以击败。为了了解这些模型对对抗性问题编写过程的影响，我们为作者提供了LLMs和检索模型的写作指导，以理解为什么他们的问题不具备对抗性。虽然作者可以创建有趣且具有挑战性的对抗性问题，但他们有时会采用诡计导致问题质量变差，这些问题不仅对计算机而且对人类也是模糊、主观或混乱的。为了解决这些问题，我们提出了精心设计的度量标准和激励机制来引发好的、具有挑战性的问题，并提出了一个新的对抗性问题数据集。",
    "tldr": "万物普及的大型语言模型的出现既推动了动态对抗性问题生成的发展，又阻碍了其进展。为了解决这个问题，我们为作者提供了LLMs和检索模型的写作指导，提出了新的度量标准和激励机制，并创建了一个新的对抗性问题数据集。",
    "en_tdlr": "The advent of ubiquitous large language models has both propelled and hindered the progress of dynamic adversarial question generation. To address this, we provide authors with guidance using LLMs and retrieval models, propose new metrics and incentives, and present a new dataset."
}