{
    "title": "GT-PCA: Effective and Interpretable Dimensionality Reduction with General Transform-Invariant Principal Component Analysis. (arXiv:2401.15623v1 [stat.ML])",
    "abstract": "Data analysis often requires methods that are invariant with respect to specific transformations, such as rotations in case of images or shifts in case of images and time series. While principal component analysis (PCA) is a widely-used dimension reduction technique, it lacks robustness with respect to these transformations. Modern alternatives, such as autoencoders, can be invariant with respect to specific transformations but are generally not interpretable. We introduce General Transform-Invariant Principal Component Analysis (GT-PCA) as an effective and interpretable alternative to PCA and autoencoders. We propose a neural network that efficiently estimates the components and show that GT-PCA significantly outperforms alternative methods in experiments based on synthetic and real data.",
    "link": "http://arxiv.org/abs/2401.15623",
    "context": "Title: GT-PCA: Effective and Interpretable Dimensionality Reduction with General Transform-Invariant Principal Component Analysis. (arXiv:2401.15623v1 [stat.ML])\nAbstract: Data analysis often requires methods that are invariant with respect to specific transformations, such as rotations in case of images or shifts in case of images and time series. While principal component analysis (PCA) is a widely-used dimension reduction technique, it lacks robustness with respect to these transformations. Modern alternatives, such as autoencoders, can be invariant with respect to specific transformations but are generally not interpretable. We introduce General Transform-Invariant Principal Component Analysis (GT-PCA) as an effective and interpretable alternative to PCA and autoencoders. We propose a neural network that efficiently estimates the components and show that GT-PCA significantly outperforms alternative methods in experiments based on synthetic and real data.",
    "path": "papers/24/01/2401.15623.json",
    "total_tokens": 726,
    "translated_title": "GT-PCA：具有普适变换不变性的主成分分析的高效和可解释的降维方法",
    "translated_abstract": "数据分析通常需要与特定转换不变的方法，例如针对图像的旋转或图像和时间序列的移动。虽然主成分分析（PCA）是一种广泛使用的降维技术，但在这些转换方面缺乏鲁棒性。现代替代方法，如自动编码器，可以与特定转换不变，但通常不可解释。我们介绍了一种名为GT-PCA的普适变换不变的主成分分析方法，作为PCA和自动编码器的高效可解释替代方法。我们提出了一个神经网络，有效估计各个成分，并在基于合成和真实数据的实验中证明GT-PCA明显优于其他方法。",
    "tldr": "GT-PCA是一种高效且可解释的主成分分析的降维方法，与具体转换不变，能显著优于其他方法。",
    "en_tdlr": "GT-PCA is an efficient and interpretable dimensionality reduction method that is invariant with respect to specific transformations and significantly outperforms alternative methods."
}