{
    "title": "A least distance estimator for a multivariate regression model using deep neural networks. (arXiv:2401.03123v1 [stat.ME])",
    "abstract": "We propose a deep neural network (DNN) based least distance (LD) estimator (DNN-LD) for a multivariate regression problem, addressing the limitations of the conventional methods. Due to the flexibility of a DNN structure, both linear and nonlinear conditional mean functions can be easily modeled, and a multivariate regression model can be realized by simply adding extra nodes at the output layer. The proposed method is more efficient in capturing the dependency structure among responses than the least squares loss, and robust to outliers. In addition, we consider $L_1$-type penalization for variable selection, crucial in analyzing high-dimensional data. Namely, we propose what we call (A)GDNN-LD estimator that enjoys variable selection and model estimation simultaneously, by applying the (adaptive) group Lasso penalty to weight parameters in the DNN structure. For the computation, we propose a quadratic smoothing approximation method to facilitate optimizing the non-smooth objective fu",
    "link": "http://arxiv.org/abs/2401.03123",
    "context": "Title: A least distance estimator for a multivariate regression model using deep neural networks. (arXiv:2401.03123v1 [stat.ME])\nAbstract: We propose a deep neural network (DNN) based least distance (LD) estimator (DNN-LD) for a multivariate regression problem, addressing the limitations of the conventional methods. Due to the flexibility of a DNN structure, both linear and nonlinear conditional mean functions can be easily modeled, and a multivariate regression model can be realized by simply adding extra nodes at the output layer. The proposed method is more efficient in capturing the dependency structure among responses than the least squares loss, and robust to outliers. In addition, we consider $L_1$-type penalization for variable selection, crucial in analyzing high-dimensional data. Namely, we propose what we call (A)GDNN-LD estimator that enjoys variable selection and model estimation simultaneously, by applying the (adaptive) group Lasso penalty to weight parameters in the DNN structure. For the computation, we propose a quadratic smoothing approximation method to facilitate optimizing the non-smooth objective fu",
    "path": "papers/24/01/2401.03123.json",
    "total_tokens": 946,
    "translated_title": "一种使用深度神经网络的多元回归模型最小距离估计器",
    "translated_abstract": "我们提出了一种基于深度神经网络(DNN)的最小距离(LD)估计器(DNN-LD)用于多元回归问题，解决了传统方法的局限性。由于DNN结构的灵活性，可以轻松建模线性和非线性条件均值函数，并且只需在输出层添加额外节点即可实现多元回归模型。该方法比最小二乘损失更有效地捕捉响应之间的依赖结构，并且对异常值具有鲁棒性。此外，我们考虑到变量选择在分析高维数据中的关键性，引入了L1型惩罚。具体而言，我们提出了我们称之为(A)GDNN-LD估计器，通过将(自适应)分组Lasso惩罚应用于DNN结构中的权重参数，同时实现了变量选择和模型估计。为了进行计算，我们提出了一种二次平滑近似方法，以便优化非光滑的目标函数。",
    "tldr": "我们提出了一种基于深度神经网络的最小距离估计器，用于多元回归问题，可以灵活建模线性和非线性条件均值函数，并具有更好的捕捉依赖关系和鲁棒性，同时考虑了变量选择在分析高维数据中的重要性。",
    "en_tdlr": "We propose a deep neural network (DNN) based least distance (LD) estimator (DNN-LD) for a multivariate regression problem, which allows for flexible modeling of linear and nonlinear conditional mean functions, capturing dependencies and robustness, and considering the importance of variable selection in analyzing high-dimensional data."
}