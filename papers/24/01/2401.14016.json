{
    "title": "Towards Uncertainty-Aware Language Agent. (arXiv:2401.14016v1 [cs.CL])",
    "abstract": "While Language Agents have achieved promising success by placing Large Language Models at the core of a more versatile design that dynamically interacts with the external world, the existing approaches neglect the notion of uncertainty during these interactions. We present the Uncertainty-Aware Language Agent (UALA), a framework that orchestrates the interaction between the agent and the external world using uncertainty quantification. Compared with other well-known counterparts like ReAct, our extensive experiments across 3 representative tasks (HotpotQA, StrategyQA, MMLU) and various LLM sizes demonstrates that UALA brings a significant improvement of performance, while having a substantially lower reliance on the external world (i.e., reduced number of tool calls and tokens). Our analyses provide various insights including the great potential of UALA compared with agent fine-tuning, and underscoring the unreliably of verbalised confidence of LLMs as a proxy for uncertainty.",
    "link": "http://arxiv.org/abs/2401.14016",
    "context": "Title: Towards Uncertainty-Aware Language Agent. (arXiv:2401.14016v1 [cs.CL])\nAbstract: While Language Agents have achieved promising success by placing Large Language Models at the core of a more versatile design that dynamically interacts with the external world, the existing approaches neglect the notion of uncertainty during these interactions. We present the Uncertainty-Aware Language Agent (UALA), a framework that orchestrates the interaction between the agent and the external world using uncertainty quantification. Compared with other well-known counterparts like ReAct, our extensive experiments across 3 representative tasks (HotpotQA, StrategyQA, MMLU) and various LLM sizes demonstrates that UALA brings a significant improvement of performance, while having a substantially lower reliance on the external world (i.e., reduced number of tool calls and tokens). Our analyses provide various insights including the great potential of UALA compared with agent fine-tuning, and underscoring the unreliably of verbalised confidence of LLMs as a proxy for uncertainty.",
    "path": "papers/24/01/2401.14016.json",
    "total_tokens": 903,
    "translated_title": "面向不确定性感知的语言智能体",
    "translated_abstract": "虽然语言智能体通过将大型语言模型置于更多功能的设计核心以及与外部世界的动态交互中取得了令人期待的成功，但现有方法在这些交互过程中忽视了不确定性的概念。我们提出了一种称为不确定性感知的语言智能体（UALA）的框架，该框架使用不确定性量化来编排代理和外部世界之间的交互。与其他知名对手（如ReAct）相比，我们在3个代表性任务（HotpotQA，StrategyQA，MMLU）和各种LLM尺寸上进行了广泛的实验，结果表明UALA在性能方面有显著的改进，同时对外部世界的依赖性显著降低（即，减少了工具调用和标记数）。我们的分析提供了各种见解，包括与代理微调相比，UALA的巨大潜力，并强调在语言模型的口头置信度作为不确定性的代理时的不可靠性。",
    "tldr": "UALA是一个使用不确定性量化来进行代理和外部世界交互的框架，相比于其他方法，它在多个任务和语言模型尺寸下表现出显著的性能改进，并且在对外部世界的依赖性方面更低。",
    "en_tdlr": "UALA is a framework that uses uncertainty quantification to facilitate the interaction between the agent and the external world. Compared to other approaches, it shows significant performance improvement across multiple tasks and language model sizes, while having lower reliance on the external world."
}