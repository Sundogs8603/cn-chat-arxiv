{
    "title": "Bag of Tricks to Boost Adversarial Transferability. (arXiv:2401.08734v1 [cs.CV])",
    "abstract": "Deep neural networks are widely known to be vulnerable to adversarial examples. However, vanilla adversarial examples generated under the white-box setting often exhibit low transferability across different models. Since adversarial transferability poses more severe threats to practical applications, various approaches have been proposed for better transferability, including gradient-based, input transformation-based, and model-related attacks, \\etc. In this work, we find that several tiny changes in the existing adversarial attacks can significantly affect the attack performance, \\eg, the number of iterations and step size. Based on careful studies of existing adversarial attacks, we propose a bag of tricks to enhance adversarial transferability, including momentum initialization, scheduled step size, dual example, spectral-based input transformation, and several ensemble strategies. Extensive experiments on the ImageNet dataset validate the high effectiveness of our proposed tricks a",
    "link": "http://arxiv.org/abs/2401.08734",
    "context": "Title: Bag of Tricks to Boost Adversarial Transferability. (arXiv:2401.08734v1 [cs.CV])\nAbstract: Deep neural networks are widely known to be vulnerable to adversarial examples. However, vanilla adversarial examples generated under the white-box setting often exhibit low transferability across different models. Since adversarial transferability poses more severe threats to practical applications, various approaches have been proposed for better transferability, including gradient-based, input transformation-based, and model-related attacks, \\etc. In this work, we find that several tiny changes in the existing adversarial attacks can significantly affect the attack performance, \\eg, the number of iterations and step size. Based on careful studies of existing adversarial attacks, we propose a bag of tricks to enhance adversarial transferability, including momentum initialization, scheduled step size, dual example, spectral-based input transformation, and several ensemble strategies. Extensive experiments on the ImageNet dataset validate the high effectiveness of our proposed tricks a",
    "path": "papers/24/01/2401.08734.json",
    "total_tokens": 847,
    "translated_title": "提高对抗转移能力的一系列技巧",
    "translated_abstract": "深度神经网络广为人知的是对抗性样本的脆弱性。然而，在白盒设置下生成的纯粹对抗性样本在不同模型间的传递能力通常较低。由于对抗性转移对实际应用造成更严重的威胁，因此已提出了各种方法来改善转移能力，包括基于梯度、基于输入转换和基于模型的攻击等。在这项工作中，我们发现现有对抗性攻击中的几个微小改变可以显著影响攻击性能，例如迭代次数和步长。基于对现有的对抗性攻击进行仔细研究，我们提出了一系列技巧来增强对抗性转移能力，包括动量初始化、定期调整步长、对抗示例、基于谱的输入转换以及几种集成策略。在ImageNet数据集上进行的大量实验证实了我们提出的技巧的高效性。",
    "tldr": "本文通过对现有对抗性攻击的研究，提出了一系列技巧来增强对抗性转移能力，并在ImageNet数据集上进行了大量实验证实了其高效性。"
}