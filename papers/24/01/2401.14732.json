{
    "title": "Residual Quantization with Implicit Neural Codebooks. (arXiv:2401.14732v1 [cs.LG])",
    "abstract": "Vector quantization is a fundamental operation for data compression and vector search. To obtain high accuracy, multi-codebook methods increase the rate by representing each vector using codewords across multiple codebooks. Residual quantization (RQ) is one such method, which increases accuracy by iteratively quantizing the error of the previous step. The error distribution is dependent on previously selected codewords. This dependency is, however, not accounted for in conventional RQ as it uses a generic codebook per quantization step. In this paper, we propose QINCo, a neural RQ variant which predicts specialized codebooks per vector using a neural network that is conditioned on the approximation of the vector from previous steps. Experiments show that QINCo outperforms state-of-the-art methods by a large margin on several datasets and code sizes. For example, QINCo achieves better nearest-neighbor search accuracy using 12 bytes codes than other methods using 16 bytes on the BigANN a",
    "link": "http://arxiv.org/abs/2401.14732",
    "context": "Title: Residual Quantization with Implicit Neural Codebooks. (arXiv:2401.14732v1 [cs.LG])\nAbstract: Vector quantization is a fundamental operation for data compression and vector search. To obtain high accuracy, multi-codebook methods increase the rate by representing each vector using codewords across multiple codebooks. Residual quantization (RQ) is one such method, which increases accuracy by iteratively quantizing the error of the previous step. The error distribution is dependent on previously selected codewords. This dependency is, however, not accounted for in conventional RQ as it uses a generic codebook per quantization step. In this paper, we propose QINCo, a neural RQ variant which predicts specialized codebooks per vector using a neural network that is conditioned on the approximation of the vector from previous steps. Experiments show that QINCo outperforms state-of-the-art methods by a large margin on several datasets and code sizes. For example, QINCo achieves better nearest-neighbor search accuracy using 12 bytes codes than other methods using 16 bytes on the BigANN a",
    "path": "papers/24/01/2401.14732.json",
    "total_tokens": 860,
    "translated_title": "隐式神经码书的残余量化方法",
    "translated_abstract": "矢量量化是数据压缩和矢量搜索的基本操作。为了获得高准确性，多码书方法通过使用多个码书中的码字来表示每个矢量来增加速率。残余量化（RQ）是一种方法，通过迭代量化上一步的误差来提高准确性。然而，误差分布依赖于先前选择的码字，在传统RQ中未对此进行考虑，因为它在每个量化步骤中使用通用码书。在本文中，我们提出了QINCo，一种神经网络残余量化变体，它使用神经网络来预测每个矢量的专门码书，条件是先前步骤的向量近似。实验证明，在多个数据集和码书大小上，QINCo的性能优于现有方法很多。例如，QINCo使用12字节的码字在BigANN上比使用16字节的其他方法实现更好的最近邻搜索准确性。",
    "tldr": "本文提出了QINCo，一种神经网络残余量化变体，通过预测每个矢量的专门码书，提高了准确性，并在多个数据集和码书大小上优于现有方法。"
}