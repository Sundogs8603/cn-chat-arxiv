{
    "title": "A Reliable Knowledge Processing Framework for Combustion Science using Foundation Models. (arXiv:2401.00544v2 [cs.AI] UPDATED)",
    "abstract": "This research explores the integration of large language models (LLMs) into scientific data assimilation, focusing on combustion science as a case study. Leveraging foundational models integrated with Retrieval-Augmented Generation (RAG) framework, the study introduces an approach to process diverse combustion research data, spanning experimental studies, simulations, and literature. The multifaceted nature of combustion research emphasizes the critical role of knowledge processing in navigating and extracting valuable information from a vast and diverse pool of sources. The developed approach minimizes computational and economic expenses while optimizing data privacy and accuracy. It incorporates prompt engineering and offline open-source LLMs, offering user autonomy in selecting base models. The study provides a thorough examination of text segmentation strategies, conducts comparative studies between LLMs, and explores various optimized prompts to demonstrate the effectiveness of th",
    "link": "http://arxiv.org/abs/2401.00544",
    "context": "Title: A Reliable Knowledge Processing Framework for Combustion Science using Foundation Models. (arXiv:2401.00544v2 [cs.AI] UPDATED)\nAbstract: This research explores the integration of large language models (LLMs) into scientific data assimilation, focusing on combustion science as a case study. Leveraging foundational models integrated with Retrieval-Augmented Generation (RAG) framework, the study introduces an approach to process diverse combustion research data, spanning experimental studies, simulations, and literature. The multifaceted nature of combustion research emphasizes the critical role of knowledge processing in navigating and extracting valuable information from a vast and diverse pool of sources. The developed approach minimizes computational and economic expenses while optimizing data privacy and accuracy. It incorporates prompt engineering and offline open-source LLMs, offering user autonomy in selecting base models. The study provides a thorough examination of text segmentation strategies, conducts comparative studies between LLMs, and explores various optimized prompts to demonstrate the effectiveness of th",
    "path": "papers/24/01/2401.00544.json",
    "total_tokens": 924,
    "translated_title": "火燃科学中使用基础模型的可靠知识处理框架",
    "translated_abstract": "本研究探讨将大型语言模型（LLMs）整合到科学数据融合中，以燃烧科学为案例研究。通过整合基础模型与检索增强生成（RAG）框架，本研究介绍了一种处理多样化燃烧研究数据的方法，涵盖实验研究、模拟和文献等方面。燃烧研究的多方面性强调了知识处理在从丰富的、多样化的信息来源中导航和提取有价值信息中的关键作用。所开发的方法在优化数据隐私和准确性的同时，最大限度地减少了计算和经济开销。它包括提示工程和离线开源LLMs，为用户选择基础模型提供了自主性。本研究对文本分割策略进行了全面的研究，进行了LLMs之间的比较研究，并探索了各种优化的提示方式，以证明其有效性。",
    "tldr": "本研究介绍了一种可靠的知识处理框架，将大型语言模型整合到燃烧科学中。该框架通过使用基础模型和RAG框架，处理多样化的燃烧研究数据，最大限度地减少计算和经济开销，同时优化数据隐私和准确性。",
    "en_tdlr": "This research presents a reliable knowledge processing framework that integrates large language models into combustion science. It effectively processes diverse combustion research data, minimizing computational and economic expenses while optimizing data privacy and accuracy."
}