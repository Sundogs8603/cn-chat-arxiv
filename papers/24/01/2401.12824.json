{
    "title": "MAPPING: Debiasing Graph Neural Networks for Fair Node Classification with Limited Sensitive Information Leakage. (arXiv:2401.12824v1 [cs.LG])",
    "abstract": "Despite remarkable success in diverse web-based applications, Graph Neural Networks(GNNs) inherit and further exacerbate historical discrimination and social stereotypes, which critically hinder their deployments in high-stake domains such as online clinical diagnosis, financial crediting, etc. However, current fairness research that primarily craft on i.i.d data, cannot be trivially replicated to non-i.i.d. graph structures with topological dependence among samples. Existing fair graph learning typically favors pairwise constraints to achieve fairness but fails to cast off dimensional limitations and generalize them into multiple sensitive attributes; besides, most studies focus on in-processing techniques to enforce and calibrate fairness, constructing a model-agnostic debiasing GNN framework at the pre-processing stage to prevent downstream misuses and improve training reliability is still largely under-explored. Furthermore, previous work on GNNs tend to enhance either fairness or ",
    "link": "http://arxiv.org/abs/2401.12824",
    "context": "Title: MAPPING: Debiasing Graph Neural Networks for Fair Node Classification with Limited Sensitive Information Leakage. (arXiv:2401.12824v1 [cs.LG])\nAbstract: Despite remarkable success in diverse web-based applications, Graph Neural Networks(GNNs) inherit and further exacerbate historical discrimination and social stereotypes, which critically hinder their deployments in high-stake domains such as online clinical diagnosis, financial crediting, etc. However, current fairness research that primarily craft on i.i.d data, cannot be trivially replicated to non-i.i.d. graph structures with topological dependence among samples. Existing fair graph learning typically favors pairwise constraints to achieve fairness but fails to cast off dimensional limitations and generalize them into multiple sensitive attributes; besides, most studies focus on in-processing techniques to enforce and calibrate fairness, constructing a model-agnostic debiasing GNN framework at the pre-processing stage to prevent downstream misuses and improve training reliability is still largely under-explored. Furthermore, previous work on GNNs tend to enhance either fairness or ",
    "path": "papers/24/01/2401.12824.json",
    "total_tokens": 984,
    "translated_title": "MAPPING: 使用有限敏感信息泄露的去偏置图神经网络进行公平节点分类",
    "translated_abstract": "尽管在各种基于网络的应用中取得了显著的成功，但图神经网络（GNN）继承并进一步加剧了历史上的偏见和社会刻板印象，这严重阻碍了它们在在线临床诊断、金融信贷等高风险领域的部署。然而，当前的公平性研究主要集中在独立同分布数据上，并不能简单地复制到具有拓扑依赖的非独立同分布图结构中。现有的公平图学习通常偏好于使用成对约束来实现公平性，但无法克服维度限制并将其推广到多个敏感属性；此外，大多数研究集中在处理技术上来强制并调整公平性，在预处理阶段构建一个模型无关的去偏置GNN框架，以防止下游误用并提高训练的可靠性在先前的工作中，GNN往往倾向于增强公平性或增加预测性能，因此在二者之间进行全面权衡仍然是一个挑战。",
    "tldr": "本文提出了一种使用有限敏感信息泄露的去偏置图神经网络进行公平节点分类的方法，该方法克服了非独立同分布图结构中的拓扑依赖问题，并构建了一个模型无关的去偏置框架，以防止下游误用并提高训练的可靠性。",
    "en_tdlr": "This paper proposes a method for fair node classification using debiased graph neural networks with limited sensitive information leakage. It overcomes the issue of topological dependence in non-i.i.d. graph structures and constructs a model-agnostic debiasing framework to prevent downstream misuses and improve training reliability."
}