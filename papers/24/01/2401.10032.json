{
    "title": "FreGrad: Lightweight and Fast Frequency-aware Diffusion Vocoder. (arXiv:2401.10032v1 [eess.AS])",
    "abstract": "The goal of this paper is to generate realistic audio with a lightweight and fast diffusion-based vocoder, named FreGrad. Our framework consists of the following three key components: (1) We employ discrete wavelet transform that decomposes a complicated waveform into sub-band wavelets, which helps FreGrad to operate on a simple and concise feature space, (2) We design a frequency-aware dilated convolution that elevates frequency awareness, resulting in generating speech with accurate frequency information, and (3) We introduce a bag of tricks that boosts the generation quality of the proposed model. In our experiments, FreGrad achieves 3.7 times faster training time and 2.2 times faster inference speed compared to our baseline while reducing the model size by 0.6 times (only 1.78M parameters) without sacrificing the output quality. Audio samples are available at: https://mm.kaist.ac.kr/projects/FreGrad.",
    "link": "http://arxiv.org/abs/2401.10032",
    "context": "Title: FreGrad: Lightweight and Fast Frequency-aware Diffusion Vocoder. (arXiv:2401.10032v1 [eess.AS])\nAbstract: The goal of this paper is to generate realistic audio with a lightweight and fast diffusion-based vocoder, named FreGrad. Our framework consists of the following three key components: (1) We employ discrete wavelet transform that decomposes a complicated waveform into sub-band wavelets, which helps FreGrad to operate on a simple and concise feature space, (2) We design a frequency-aware dilated convolution that elevates frequency awareness, resulting in generating speech with accurate frequency information, and (3) We introduce a bag of tricks that boosts the generation quality of the proposed model. In our experiments, FreGrad achieves 3.7 times faster training time and 2.2 times faster inference speed compared to our baseline while reducing the model size by 0.6 times (only 1.78M parameters) without sacrificing the output quality. Audio samples are available at: https://mm.kaist.ac.kr/projects/FreGrad.",
    "path": "papers/24/01/2401.10032.json",
    "total_tokens": 960,
    "translated_title": "FreGrad: 轻量级和快速的频率感知扩散声码器",
    "translated_abstract": "本文的目标是使用一种轻量级和快速的基于扩散的声码器FreGrad生成逼真的音频。我们的框架包括以下三个关键组件：（1）我们使用离散小波变换将复杂的波形分解为子带小波，这有助于FreGrad在简单而简洁的特征空间上操作，（2）我们设计了一种频率感知的扩张卷积来提升频率感知能力，从而生成具有准确频率信息的语音，（3）我们引入了一些技巧来提高所提模型的生成质量。在实验中，FreGrad相比基准模型的训练速度快了3.7倍，推断速度快了2.2倍，同时模型的大小减小了0.6倍（仅1.78M参数），而不降低输出质量。音频样本可在以下链接中获得：https://mm.kaist.ac.kr/projects/FreGrad。",
    "tldr": "本文介绍了一种轻量级和快速的频率感知扩散声码器FreGrad，通过离散小波变换、频率感知的扩张卷积和技巧等关键组件，实现了高质量音频的生成。在实验中，FreGrad相比基准模型训练速度快3.7倍，推断速度快2.2倍，模型大小减小0.6倍，而输出质量不受影响。",
    "en_tdlr": "This paper presents FreGrad, a lightweight and fast frequency-aware diffusion vocoder, which generates realistic audio using key components such as discrete wavelet transform, frequency-aware dilated convolution, and bag of tricks. In experiments, FreGrad achieves significantly faster training and inference speeds, along with reduced model size, without sacrificing output quality."
}