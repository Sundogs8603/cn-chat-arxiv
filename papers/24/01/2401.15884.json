{
    "title": "Corrective Retrieval Augmented Generation",
    "abstract": "arXiv:2401.15884v2 Announce Type: replace  Abstract: Large language models (LLMs) inevitably exhibit hallucinations since the accuracy of generated texts cannot be secured solely by the parametric knowledge they encapsulate. Although retrieval-augmented generation (RAG) is a practicable complement to LLMs, it relies heavily on the relevance of retrieved documents, raising concerns about how the model behaves if retrieval goes wrong. To this end, we propose the Corrective Retrieval Augmented Generation (CRAG) to improve the robustness of generation. Specifically, a lightweight retrieval evaluator is designed to assess the overall quality of retrieved documents for a query, returning a confidence degree based on which different knowledge retrieval actions can be triggered. Since retrieval from static and limited corpora can only return sub-optimal documents, large-scale web searches are utilized as an extension for augmenting the retrieval results. Besides, a decompose-then-recompose alg",
    "link": "https://arxiv.org/abs/2401.15884",
    "context": "Title: Corrective Retrieval Augmented Generation\nAbstract: arXiv:2401.15884v2 Announce Type: replace  Abstract: Large language models (LLMs) inevitably exhibit hallucinations since the accuracy of generated texts cannot be secured solely by the parametric knowledge they encapsulate. Although retrieval-augmented generation (RAG) is a practicable complement to LLMs, it relies heavily on the relevance of retrieved documents, raising concerns about how the model behaves if retrieval goes wrong. To this end, we propose the Corrective Retrieval Augmented Generation (CRAG) to improve the robustness of generation. Specifically, a lightweight retrieval evaluator is designed to assess the overall quality of retrieved documents for a query, returning a confidence degree based on which different knowledge retrieval actions can be triggered. Since retrieval from static and limited corpora can only return sub-optimal documents, large-scale web searches are utilized as an extension for augmenting the retrieval results. Besides, a decompose-then-recompose alg",
    "path": "papers/24/01/2401.15884.json",
    "total_tokens": 814,
    "translated_title": "纠正检索增强生成",
    "translated_abstract": "大型语言模型（LLMs）不可避免地出现幻觉，因为生成的文本准确性不能仅通过它们封装的参数化知识来保证。尽管检索增强生成（RAG）是对LLMs的可行补充，但它严重依赖于检索文档的相关性，引发了如果检索出现问题模型将如何行为的担忧。为此，我们提出了纠正检索增强生成（CRAG）来提高生成的鲁棒性。具体地，设计了一个轻量级的检索评估器，用于评估为查询检索的文档的整体质量，根据返回的置信度触发不同的知识检索操作。由于从静态和有限的语料库中检索只能返回次优文档，因此利用大规模网络搜索作为扩展来增强检索结果。此外，还有一个分解-重组算法。",
    "tldr": "提出了纠正检索增强生成（CRAG）来改善生成模型的鲁棒性，通过设计轻量级检索评估器和利用大规模网络搜索扩展检索结果。",
    "en_tdlr": "Proposed Corrective Retrieval Augmented Generation (CRAG) to enhance the robustness of generation models by introducing a lightweight retrieval evaluator and utilizing large-scale web searches to augment retrieval results."
}