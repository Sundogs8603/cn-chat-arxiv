{
    "title": "Investigating Data Contamination for Pre-training Language Models. (arXiv:2401.06059v1 [cs.CL])",
    "abstract": "Language models pre-trained on web-scale corpora demonstrate impressive capabilities on diverse downstream tasks. However, there is increasing concern whether such capabilities might arise from evaluation datasets being included in the pre-training corpus -- a phenomenon known as \\textit{data contamination} -- in a manner that artificially increases performance. There has been little understanding of how this potential contamination might influence LMs' performance on downstream tasks. In this paper, we explore the impact of data contamination at the pre-training stage by pre-training a series of GPT-2 models \\textit{from scratch}. We highlight the effect of both text contamination (\\textit{i.e.}\\ input text of the evaluation samples) and ground-truth contamination (\\textit{i.e.}\\ the prompts asked on the input and the desired outputs) from evaluation data. We also investigate the effects of repeating contamination for various downstream tasks. Additionally, we examine the prevailing n",
    "link": "http://arxiv.org/abs/2401.06059",
    "context": "Title: Investigating Data Contamination for Pre-training Language Models. (arXiv:2401.06059v1 [cs.CL])\nAbstract: Language models pre-trained on web-scale corpora demonstrate impressive capabilities on diverse downstream tasks. However, there is increasing concern whether such capabilities might arise from evaluation datasets being included in the pre-training corpus -- a phenomenon known as \\textit{data contamination} -- in a manner that artificially increases performance. There has been little understanding of how this potential contamination might influence LMs' performance on downstream tasks. In this paper, we explore the impact of data contamination at the pre-training stage by pre-training a series of GPT-2 models \\textit{from scratch}. We highlight the effect of both text contamination (\\textit{i.e.}\\ input text of the evaluation samples) and ground-truth contamination (\\textit{i.e.}\\ the prompts asked on the input and the desired outputs) from evaluation data. We also investigate the effects of repeating contamination for various downstream tasks. Additionally, we examine the prevailing n",
    "path": "papers/24/01/2401.06059.json",
    "total_tokens": 824,
    "translated_title": "研究预训练语言模型的数据污染",
    "translated_abstract": "在大规模网络语料库上预训练的语言模型在各种下游任务上展示出令人印象深刻的能力。然而，越来越担心这种能力是否是由于评估数据集被包含在预训练语料库中导致的，这种现象被称为“数据污染”，从而在人工提高性能。目前对这种潜在污染如何影响语言模型在下游任务上的性能缺乏了解。本文通过从头开始预训练一系列GPT-2模型，探讨了在预训练阶段数据污染的影响。我们强调了来自评估数据的文本污染（即输入文本的评估样本）和基准污染（即输入中的提示和期望输出）的影响。我们还研究了在各种下游任务中重复污染的影响。此外，我们还调查了普遍存在的n",
    "tldr": "这项研究调查了预训练语言模型中的数据污染问题，以及该污染对下游任务性能的影响。",
    "en_tdlr": "This study investigates the issue of data contamination in pre-training language models and the impact of this contamination on downstream task performance."
}