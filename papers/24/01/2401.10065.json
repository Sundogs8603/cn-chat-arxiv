{
    "title": "Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs. (arXiv:2401.10065v1 [cs.CL])",
    "abstract": "Reasoning is a fundamental component for achieving language understanding. Among the multiple types of reasoning, conditional reasoning, the ability to draw different conclusions depending on some condition, has been understudied in large language models (LLMs). Recent prompting methods, such as chain of thought, have significantly improved LLMs on reasoning tasks. Nevertheless, there is still little understanding of what triggers reasoning abilities in LLMs. We hypothesize that code prompts can trigger conditional reasoning in LLMs trained on text and code. We propose a chain of prompts that transforms a natural language problem into code and prompts the LLM with the generated code. Our experiments find that code prompts exhibit a performance boost between 2.6 and 7.7 points on GPT 3.5 across multiple datasets requiring conditional reasoning. We then conduct experiments to discover how code prompts elicit conditional reasoning abilities and through which features. We observe that prom",
    "link": "http://arxiv.org/abs/2401.10065",
    "context": "Title: Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs. (arXiv:2401.10065v1 [cs.CL])\nAbstract: Reasoning is a fundamental component for achieving language understanding. Among the multiple types of reasoning, conditional reasoning, the ability to draw different conclusions depending on some condition, has been understudied in large language models (LLMs). Recent prompting methods, such as chain of thought, have significantly improved LLMs on reasoning tasks. Nevertheless, there is still little understanding of what triggers reasoning abilities in LLMs. We hypothesize that code prompts can trigger conditional reasoning in LLMs trained on text and code. We propose a chain of prompts that transforms a natural language problem into code and prompts the LLM with the generated code. Our experiments find that code prompts exhibit a performance boost between 2.6 and 7.7 points on GPT 3.5 across multiple datasets requiring conditional reasoning. We then conduct experiments to discover how code prompts elicit conditional reasoning abilities and through which features. We observe that prom",
    "path": "papers/24/01/2401.10065.json",
    "total_tokens": 885,
    "translated_title": "代码提示在文本+代码LLMs中引发了条件推理能力",
    "translated_abstract": "推理是实现语言理解的基本组成部分。在多种推理类型中，条件推理是一种在某些条件下得出不同结论的能力，在大型语言模型（LLMs）中一直没有得到充分研究。最近的提示方法，如思维链，显著改进了在推理任务上的LLMs性能。然而，我们对于什么触发了LLMs中的推理能力仍然知之甚少。我们假设代码提示能够触发在文本和代码上训练的LLMs中的条件推理。我们提出了一系列的提示，将自然语言问题转化为代码，并用生成的代码提示LLMs。我们的实验发现，在需要条件推理的多个数据集上，代码提示使得GPT 3.5的性能提升了2.6到7.7个百分点。接着，我们进行了实验，探索了代码提示如何引发条件推理能力以及通过哪些特征进行。我们观察到，提示的形式和内容对于引发条件推理能力起到了重要作用。",
    "tldr": "本论文研究了在大型语言模型（LLMs）中触发条件推理能力的方法，通过使用代码提示将自然语言问题转化为代码，从而在多个数据集上实现了显著的性能提升。"
}