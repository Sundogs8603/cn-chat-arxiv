{
    "title": "TechGPT-2.0: A large language model project to solve the task of knowledge graph construction. (arXiv:2401.04507v1 [cs.CL])",
    "abstract": "Large language models have exhibited robust performance across diverse natural language processing tasks. This report introduces TechGPT-2.0, a project designed to enhance the capabilities of large language models specifically in knowledge graph construction tasks, including named entity recognition (NER) and relationship triple extraction (RTE) tasks in NLP applications. Additionally, it serves as a LLM accessible for research within the Chinese open-source model community. We offer two 7B large language model weights and a QLoRA weight specialized for processing lengthy texts.Notably, TechGPT-2.0 is trained on Huawei's Ascend server. Inheriting all functionalities from TechGPT-1.0, it exhibits robust text processing capabilities, particularly in the domains of medicine and law. Furthermore, we introduce new capabilities to the model, enabling it to process texts in various domains such as geographical areas, transportation, organizations, literary works, biology, natural sciences, as",
    "link": "http://arxiv.org/abs/2401.04507",
    "context": "Title: TechGPT-2.0: A large language model project to solve the task of knowledge graph construction. (arXiv:2401.04507v1 [cs.CL])\nAbstract: Large language models have exhibited robust performance across diverse natural language processing tasks. This report introduces TechGPT-2.0, a project designed to enhance the capabilities of large language models specifically in knowledge graph construction tasks, including named entity recognition (NER) and relationship triple extraction (RTE) tasks in NLP applications. Additionally, it serves as a LLM accessible for research within the Chinese open-source model community. We offer two 7B large language model weights and a QLoRA weight specialized for processing lengthy texts.Notably, TechGPT-2.0 is trained on Huawei's Ascend server. Inheriting all functionalities from TechGPT-1.0, it exhibits robust text processing capabilities, particularly in the domains of medicine and law. Furthermore, we introduce new capabilities to the model, enabling it to process texts in various domains such as geographical areas, transportation, organizations, literary works, biology, natural sciences, as",
    "path": "papers/24/01/2401.04507.json",
    "total_tokens": 884,
    "translated_title": "TechGPT-2.0:一个解决知识图谱构建任务的大型语言模型项目",
    "translated_abstract": "大型语言模型在各种自然语言处理任务中都展现出了强大的性能。本报告介绍了TechGPT-2.0，这是一个项目，旨在增强大型语言模型在知识图谱构建任务中的能力，包括命名实体识别（NER）和关系三元组提取（RTE）。此外，它还作为一个面向中国开源模型社区的LLM可访问研究。我们提供了两个7B大型语言模型的权重和一个专门用于处理长文本的QLoRA权重。值得注意的是，TechGPT-2.0是在华为的Ascend服务器上训练的。继承了TechGPT-1.0的所有功能，它展现出了强大的文本处理能力，特别是在医学和法律领域。此外，我们还为模型引入了新的功能，使其能够处理各个领域的文本，如地理区域、交通、组织机构、文学作品、生物学和自然科学等。",
    "tldr": "TechGPT-2.0是一个解决知识图谱构建任务的大型语言模型项目，具有强大的文本处理能力和多个领域的应用能力。",
    "en_tdlr": "TechGPT-2.0 is a large language model project designed to solve the task of knowledge graph construction. It exhibits robust text processing capabilities and application abilities in various domains."
}