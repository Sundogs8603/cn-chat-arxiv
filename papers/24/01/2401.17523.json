{
    "title": "Game-Theoretic Unlearnable Example Generator",
    "abstract": "Unlearnable example attacks are data poisoning attacks aiming to degrade the clean test accuracy of deep learning by adding imperceptible perturbations to the training samples, which can be formulated as a bi-level optimization problem. However, directly solving this optimization problem is intractable for deep neural networks. In this paper, we investigate unlearnable example attacks from a game-theoretic perspective, by formulating the attack as a nonzero sum Stackelberg game. First, the existence of game equilibria is proved under the normal setting and the adversarial training setting. It is shown that the game equilibrium gives the most powerful poison attack in that the victim has the lowest test accuracy among all networks within the same hypothesis space, when certain loss functions are used. Second, we propose a novel attack method, called the Game Unlearnable Example (GUE), which has three main gradients. (1) The poisons are obtained by directly solving the equilibrium of the",
    "link": "https://arxiv.org/abs/2401.17523",
    "context": "Title: Game-Theoretic Unlearnable Example Generator\nAbstract: Unlearnable example attacks are data poisoning attacks aiming to degrade the clean test accuracy of deep learning by adding imperceptible perturbations to the training samples, which can be formulated as a bi-level optimization problem. However, directly solving this optimization problem is intractable for deep neural networks. In this paper, we investigate unlearnable example attacks from a game-theoretic perspective, by formulating the attack as a nonzero sum Stackelberg game. First, the existence of game equilibria is proved under the normal setting and the adversarial training setting. It is shown that the game equilibrium gives the most powerful poison attack in that the victim has the lowest test accuracy among all networks within the same hypothesis space, when certain loss functions are used. Second, we propose a novel attack method, called the Game Unlearnable Example (GUE), which has three main gradients. (1) The poisons are obtained by directly solving the equilibrium of the",
    "path": "papers/24/01/2401.17523.json",
    "total_tokens": 869,
    "translated_title": "游戏论域不可学习示例生成器",
    "translated_abstract": "不可学习示例攻击是一种数据毒化攻击，旨在通过向训练样本添加微不可察觉的扰动，降低深度学习的干净测试准确性，这可以被定义为一个二层优化问题。然而，直接解决这个优化问题对于深度神经网络来说是难以处理的。在本文中，我们从博弈论的角度对不可学习示例攻击进行了研究，将攻击形式化为一个非零和Stackelberg博弈。首先，在正常设置和对抗训练设置下证明了博弈均衡的存在性。结果表明，在使用特定损失函数时，博弈均衡给出了最强大的毒攻击，即在相同假设空间内，受害者的测试准确率最低。其次，我们提出了一种新的攻击方法，称为游戏论域不可学习示例（GUE），它主要包括三个梯度。（1）通过直接求解均衡获得毒攻击。",
    "tldr": "本论文研究了从游戏论域的角度来进行不可学习示例攻击的方法。研究发现，博弈均衡给出了最强大的毒攻击，并提出了一种名为游戏论域不可学习示例（GUE）的新攻击方法。"
}