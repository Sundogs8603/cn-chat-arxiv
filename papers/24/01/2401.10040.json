{
    "title": "Large Language Models for Scientific Information Extraction: An Empirical Study for Virology. (arXiv:2401.10040v1 [cs.CL])",
    "abstract": "In this paper, we champion the use of structured and semantic content representation of discourse-based scholarly communication, inspired by tools like Wikipedia infoboxes or structured Amazon product descriptions. These representations provide users with a concise overview, aiding scientists in navigating the dense academic landscape. Our novel automated approach leverages the robust text generation capabilities of LLMs to produce structured scholarly contribution summaries, offering both a practical solution and insights into LLMs' emergent abilities.  For LLMs, the prime focus is on improving their general intelligence as conversational agents. We argue that these models can also be applied effectively in information extraction (IE), specifically in complex IE tasks within terse domains like Science. This paradigm shift replaces the traditional modular, pipelined machine learning approach with a simpler objective expressed through instructions. Our results show that finetuned FLAN-T",
    "link": "http://arxiv.org/abs/2401.10040",
    "context": "Title: Large Language Models for Scientific Information Extraction: An Empirical Study for Virology. (arXiv:2401.10040v1 [cs.CL])\nAbstract: In this paper, we champion the use of structured and semantic content representation of discourse-based scholarly communication, inspired by tools like Wikipedia infoboxes or structured Amazon product descriptions. These representations provide users with a concise overview, aiding scientists in navigating the dense academic landscape. Our novel automated approach leverages the robust text generation capabilities of LLMs to produce structured scholarly contribution summaries, offering both a practical solution and insights into LLMs' emergent abilities.  For LLMs, the prime focus is on improving their general intelligence as conversational agents. We argue that these models can also be applied effectively in information extraction (IE), specifically in complex IE tasks within terse domains like Science. This paradigm shift replaces the traditional modular, pipelined machine learning approach with a simpler objective expressed through instructions. Our results show that finetuned FLAN-T",
    "path": "papers/24/01/2401.10040.json",
    "total_tokens": 915,
    "translated_title": "大型语言模型在科学信息提取中的应用：一项针对病毒学的实证研究",
    "translated_abstract": "本文倡导使用结构化和语义内容表示来进行基于学术交流的学术论文，受到维基百科信息框或结构化的亚马逊产品描述等工具的启发。这些表示形式提供了简洁的概述，帮助科学家在浓厚的学术环境中进行导航。我们的新颖自动化方法利用LLM的强大文本生成能力，产生结构化的学术贡献摘要，既提供了实际解决方案，也揭示了LLM紧迫的能力。对于LLM，主要关注的是改善其作为对话代理的通用智能。我们认为这些模型也可以在信息提取（IE）中有效应用，特别是在科学等领域的复杂IE任务中。这种范式转变用一系列指令代替了传统的模块化、流水线式的机器学习方法，简化了目标。我们的结果表明，通过微调的FLAN-T模型可以取得良好效果。",
    "tldr": "使用大型语言模型进行结构化的科学信息提取，在病毒学领域进行了实证研究，结果表明这种方法可以提供简洁的学术贡献摘要，对科学家进行导航和解决LLM的紧迫能力。"
}