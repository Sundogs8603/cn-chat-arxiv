{
    "title": "Unveiling the Tapestry of Automated Essay Scoring: A Comprehensive Investigation of Accuracy, Fairness, and Generalizability. (arXiv:2401.05655v1 [cs.CL])",
    "abstract": "Automatic Essay Scoring (AES) is a well-established educational pursuit that employs machine learning to evaluate student-authored essays. While much effort has been made in this area, current research primarily focuses on either (i) boosting the predictive accuracy of an AES model for a specific prompt (i.e., developing prompt-specific models), which often heavily relies on the use of the labeled data from the same target prompt; or (ii) assessing the applicability of AES models developed on non-target prompts to the intended target prompt (i.e., developing the AES models in a cross-prompt setting). Given the inherent bias in machine learning and its potential impact on marginalized groups, it is imperative to investigate whether such bias exists in current AES methods and, if identified, how it intervenes with an AES model's accuracy and generalizability. Thus, our study aimed to uncover the intricate relationship between an AES model's accuracy, fairness, and generalizability, contr",
    "link": "http://arxiv.org/abs/2401.05655",
    "context": "Title: Unveiling the Tapestry of Automated Essay Scoring: A Comprehensive Investigation of Accuracy, Fairness, and Generalizability. (arXiv:2401.05655v1 [cs.CL])\nAbstract: Automatic Essay Scoring (AES) is a well-established educational pursuit that employs machine learning to evaluate student-authored essays. While much effort has been made in this area, current research primarily focuses on either (i) boosting the predictive accuracy of an AES model for a specific prompt (i.e., developing prompt-specific models), which often heavily relies on the use of the labeled data from the same target prompt; or (ii) assessing the applicability of AES models developed on non-target prompts to the intended target prompt (i.e., developing the AES models in a cross-prompt setting). Given the inherent bias in machine learning and its potential impact on marginalized groups, it is imperative to investigate whether such bias exists in current AES methods and, if identified, how it intervenes with an AES model's accuracy and generalizability. Thus, our study aimed to uncover the intricate relationship between an AES model's accuracy, fairness, and generalizability, contr",
    "path": "papers/24/01/2401.05655.json",
    "total_tokens": 897,
    "translated_title": "自动化文章评分的权威调查：准确性、公平性和泛化性的全面研究",
    "translated_abstract": "自动文章评分（AES）是一项成熟的教育任务，采用机器学习来评估学生撰写的文章。尽管在这个领域已经做出了许多努力，但目前的研究主要集中在（i）提高AES模型对特定提示的预测准确性方面（即开发特定提示的模型），这往往严重依赖于来自相同目标提示的标注数据的使用；或者（ii）评估非目标提示上开发的AES模型在预期目标提示上的适用性方面（即在交叉提示环境中开发AES模型）。鉴于机器学习的固有偏见及其对边缘化群体的潜在影响，有必要调查当前AES方法是否存在这种偏见，并在确定后了解其如何干扰AES模型的准确性和泛化性。因此，我们的研究旨在揭示AES模型的准确性、公平性和泛化性之间的复杂关系。",
    "tldr": "这项研究旨在全面调查自动化文章评分的准确性、公平性和泛化性，以揭示其与机器学习中的偏见之间的关系。",
    "en_tdlr": "This study investigates the accuracy, fairness, and generalizability of automated essay scoring, aiming to uncover the relationship between these factors and the biases in machine learning."
}