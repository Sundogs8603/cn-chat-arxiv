{
    "title": "Comprehensive OOD Detection Improvements. (arXiv:2401.10176v1 [cs.LG])",
    "abstract": "As machine learning becomes increasingly prevalent in impactful decisions, recognizing when inference data is outside the model's expected input distribution is paramount for giving context to predictions. Out-of-distribution (OOD) detection methods have been created for this task. Such methods can be split into representation-based or logit-based methods from whether they respectively utilize the model's embeddings or predictions for OOD detection. In contrast to most papers which solely focus on one such group, we address both. We employ dimensionality reduction on feature embeddings in representation-based methods for both time speedups and improved performance. Additionally, we propose DICE-COL, a modification of the popular logit-based method Directed Sparsification (DICE) that resolves an unnoticed flaw. We demonstrate the effectiveness of our methods on the OpenOODv1.5 benchmark framework, where they significantly improve performance and set state-of-the-art results.",
    "link": "http://arxiv.org/abs/2401.10176",
    "context": "Title: Comprehensive OOD Detection Improvements. (arXiv:2401.10176v1 [cs.LG])\nAbstract: As machine learning becomes increasingly prevalent in impactful decisions, recognizing when inference data is outside the model's expected input distribution is paramount for giving context to predictions. Out-of-distribution (OOD) detection methods have been created for this task. Such methods can be split into representation-based or logit-based methods from whether they respectively utilize the model's embeddings or predictions for OOD detection. In contrast to most papers which solely focus on one such group, we address both. We employ dimensionality reduction on feature embeddings in representation-based methods for both time speedups and improved performance. Additionally, we propose DICE-COL, a modification of the popular logit-based method Directed Sparsification (DICE) that resolves an unnoticed flaw. We demonstrate the effectiveness of our methods on the OpenOODv1.5 benchmark framework, where they significantly improve performance and set state-of-the-art results.",
    "path": "papers/24/01/2401.10176.json",
    "total_tokens": 875,
    "translated_title": "综合性的OOD检测改进",
    "translated_abstract": "随着机器学习在重大决策中的日益普及，识别推理数据是否超出模型预期的输入分布对于给出预测的背景是至关重要的。为此，我们提出了一种分为基于表示和基于逻辑的方法的OOD检测方法。与大多数论文只关注其中一组不同，我们同时解决了两个方法。我们在基于表示的方法中对特征嵌入进行降维，以提高时间性能和性能。此外，我们提出了DICE-COL，这是一种改进了流行的基于逻辑的方法Directed Sparsification (DICE)的方法，解决了一个未被注意到的缺陷。我们在OpenOODv1.5基准框架上展示了我们方法的有效性，结果表明它们显著提高了性能并获得了最新的结果。",
    "tldr": "本文提出了一种综合性的OOD检测方法，包括基于表示和基于逻辑的方法。其中，在基于表示的方法中，通过降维改进了性能，在基于逻辑的方法中，通过解决一个未被注意到的缺陷提高了性能。在基准测试中，这些方法表现出卓越的性能，并取得了最新的结果。"
}