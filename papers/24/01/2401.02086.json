{
    "title": "View-based Explanations for Graph Neural Networks. (arXiv:2401.02086v1 [cs.LG])",
    "abstract": "Generating explanations for graph neural networks (GNNs) has been studied to understand their behavior in analytical tasks such as graph classification. Existing approaches aim to understand the overall results of GNNs rather than providing explanations for specific class labels of interest, and may return explanation structures that are hard to access, nor directly queryable.  We propose GVEX, a novel paradigm that generates Graph Views for EXplanation. (1) We design a two-tier explanation structure called explanation views. An explanation view consists of a set of graph patterns and a set of induced explanation subgraphs. Given a database G of multiple graphs and a specific class label l assigned by a GNN-based classifier M, it concisely describes the fraction of G that best explains why l is assigned by M. (2) We propose quality measures and formulate an optimization problem to compute optimal explanation views for GNN explanation. We show that the problem is $\\Sigma^2_P$-hard. (3) ",
    "link": "http://arxiv.org/abs/2401.02086",
    "context": "Title: View-based Explanations for Graph Neural Networks. (arXiv:2401.02086v1 [cs.LG])\nAbstract: Generating explanations for graph neural networks (GNNs) has been studied to understand their behavior in analytical tasks such as graph classification. Existing approaches aim to understand the overall results of GNNs rather than providing explanations for specific class labels of interest, and may return explanation structures that are hard to access, nor directly queryable.  We propose GVEX, a novel paradigm that generates Graph Views for EXplanation. (1) We design a two-tier explanation structure called explanation views. An explanation view consists of a set of graph patterns and a set of induced explanation subgraphs. Given a database G of multiple graphs and a specific class label l assigned by a GNN-based classifier M, it concisely describes the fraction of G that best explains why l is assigned by M. (2) We propose quality measures and formulate an optimization problem to compute optimal explanation views for GNN explanation. We show that the problem is $\\Sigma^2_P$-hard. (3) ",
    "path": "papers/24/01/2401.02086.json",
    "total_tokens": 830,
    "translated_title": "基于视图的图神经网络解释",
    "translated_abstract": "研究生成图神经网络(GNNs)的解释，以了解它们在图分类等分析任务中的行为。现有的方法旨在理解GNNs的整体结果，而不是针对特定类别的解释，并且可能返回难以访问或直接查询的解释结构。我们提出了一种新颖的范式GVEX，用于生成图解释的图视图。我们设计了一种两层的解释结构，称为解释视图。解释视图包括一组图模式和一组诱发的解释子图。给定一个包含多个图和由基于GNN的分类器M分配的特定类别标签l的数据库G，它简洁地描述了最好解释为什么l由M分配的G的分数。我们提出了质量度量方法，并制定了一个优化问题来计算GNN解释的最佳解释视图。我们证明了该问题是Σ^2_P难的。",
    "tldr": "这篇论文提出了一种基于视图的解释方法来解释图神经网络(GNNs)的行为，通过生成解释视图和图模式来解释特定类别的结果。",
    "en_tdlr": "This paper proposes a view-based explanation approach to interpret the behavior of graph neural networks(GNNs), by generating explanation views and graph patterns to explain the results of specific class labels."
}