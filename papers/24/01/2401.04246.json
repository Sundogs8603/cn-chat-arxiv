{
    "title": "Scalable Normalizing Flows Enable Boltzmann Generators for Macromolecules. (arXiv:2401.04246v1 [cs.LG])",
    "abstract": "The Boltzmann distribution of a protein provides a roadmap to all of its functional states. Normalizing flows are a promising tool for modeling this distribution, but current methods are intractable for typical pharmacological targets; they become computationally intractable due to the size of the system, heterogeneity of intra-molecular potential energy, and long-range interactions. To remedy these issues, we present a novel flow architecture that utilizes split channels and gated attention to efficiently learn the conformational distribution of proteins defined by internal coordinates. We show that by utilizing a 2-Wasserstein loss, one can smooth the transition from maximum likelihood training to energy-based training, enabling the training of Boltzmann Generators for macromolecules. We evaluate our model and training strategy on villin headpiece HP35(nle-nle), a 35-residue subdomain, and protein G, a 56-residue protein. We demonstrate that standard architectures and training strate",
    "link": "http://arxiv.org/abs/2401.04246",
    "context": "Title: Scalable Normalizing Flows Enable Boltzmann Generators for Macromolecules. (arXiv:2401.04246v1 [cs.LG])\nAbstract: The Boltzmann distribution of a protein provides a roadmap to all of its functional states. Normalizing flows are a promising tool for modeling this distribution, but current methods are intractable for typical pharmacological targets; they become computationally intractable due to the size of the system, heterogeneity of intra-molecular potential energy, and long-range interactions. To remedy these issues, we present a novel flow architecture that utilizes split channels and gated attention to efficiently learn the conformational distribution of proteins defined by internal coordinates. We show that by utilizing a 2-Wasserstein loss, one can smooth the transition from maximum likelihood training to energy-based training, enabling the training of Boltzmann Generators for macromolecules. We evaluate our model and training strategy on villin headpiece HP35(nle-nle), a 35-residue subdomain, and protein G, a 56-residue protein. We demonstrate that standard architectures and training strate",
    "path": "papers/24/01/2401.04246.json",
    "total_tokens": 933,
    "translated_title": "可扩展的归一化流使得玻尔兹曼发生器能够模拟大分子物质",
    "translated_abstract": "蛋白质的玻尔兹曼分布为其所有功能状态提供了一个路线图。归一化流是模拟这种分布的一种有前途的工具，但是当前的方法对于典型的药物靶标来说是不可解的；由于系统的大小、分子内部势能的异质性和远程相互作用的存在，它们在计算上是不可解的。为了解决这些问题，我们提出了一种新颖的流体架构，利用分裂通道和门控注意力来高效地学习由内部坐标定义的蛋白质的构象分布。我们展示了通过利用2-Wasserstein损失，可以平滑地从最大似然训练过渡到基于能量的训练，从而实现大分子的玻尔兹曼发生器的训练。我们在HP35(nle-nle)维林头部片段和蛋白质G中评估了我们的模型和训练策略。我们证明了标准的架构和训练策略无法处理这些问题。",
    "tldr": "提出了一种新颖的流体架构来高效地学习蛋白质的构象分布，并通过利用2-Wasserstein损失平滑地实现了大分子的玻尔兹曼发生器的训练。",
    "en_tdlr": "A novel flow architecture is proposed to efficiently learn the conformational distribution of proteins, enabling the training of Boltzmann Generators for macromolecules by utilizing a 2-Wasserstein loss."
}