{
    "title": "A Robbins--Monro Sequence That Can Exploit Prior Information For Faster Convergence. (arXiv:2401.03206v1 [cs.LG])",
    "abstract": "We propose a new method to improve the convergence speed of the Robbins-Monro algorithm by introducing prior information about the target point into the Robbins-Monro iteration. We achieve the incorporation of prior information without the need of a -- potentially wrong -- regression model, which would also entail additional constraints. We show that this prior-information Robbins-Monro sequence is convergent for a wide range of prior distributions, even wrong ones, such as Gaussian, weighted sum of Gaussians, e.g., in a kernel density estimate, as well as bounded arbitrary distribution functions greater than zero. We furthermore analyse the sequence numerically to understand its performance and the influence of parameters. The results demonstrate that the prior-information Robbins-Monro sequence converges faster than the standard one, especially during the first steps, which are particularly important for applications where the number of function measurements is limited, and when the ",
    "link": "http://arxiv.org/abs/2401.03206",
    "context": "Title: A Robbins--Monro Sequence That Can Exploit Prior Information For Faster Convergence. (arXiv:2401.03206v1 [cs.LG])\nAbstract: We propose a new method to improve the convergence speed of the Robbins-Monro algorithm by introducing prior information about the target point into the Robbins-Monro iteration. We achieve the incorporation of prior information without the need of a -- potentially wrong -- regression model, which would also entail additional constraints. We show that this prior-information Robbins-Monro sequence is convergent for a wide range of prior distributions, even wrong ones, such as Gaussian, weighted sum of Gaussians, e.g., in a kernel density estimate, as well as bounded arbitrary distribution functions greater than zero. We furthermore analyse the sequence numerically to understand its performance and the influence of parameters. The results demonstrate that the prior-information Robbins-Monro sequence converges faster than the standard one, especially during the first steps, which are particularly important for applications where the number of function measurements is limited, and when the ",
    "path": "papers/24/01/2401.03206.json",
    "total_tokens": 777,
    "translated_title": "一种可以利用先验信息加快收敛速度的Robbins-Monro序列",
    "translated_abstract": "我们提出了一种新方法，通过将目标点的先验信息引入Robbins-Monro迭代来改善收敛速度。我们实现了不需要回归模型的先验信息的融合，这也会带来额外的约束。我们证明了这种先验信息的Robbins-Monro序列对于广泛的先验分布都是收敛的，即使是错误的先验分布，如高斯分布、高斯分布的加权和（例如在核密度估计中），以及大于零的有界任意分布函数。我们还通过数值分析来了解序列的性能和参数的影响。结果表明，先验信息的Robbins-Monro序列比标准序列收敛更快，特别是在前几步，这对于测量函数数目有限和误差较大的应用特别重要。",
    "tldr": "提出了一种新的方法，通过引入先验信息，改进了Robbins-Monro算法的收敛速度。结果表明，先验信息的Robbins-Monro序列比标准序列收敛更快，特别是在前几步。"
}