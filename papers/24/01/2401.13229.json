{
    "title": "From Random to Informed Data Selection: A Diversity-Based Approach to Optimize Human Annotation and Few-Shot Learning. (arXiv:2401.13229v1 [cs.CL])",
    "abstract": "A major challenge in Natural Language Processing is obtaining annotated data for supervised learning. An option is the use of crowdsourcing platforms for data annotation. However, crowdsourcing introduces issues related to the annotator's experience, consistency, and biases. An alternative is to use zero-shot methods, which in turn have limitations compared to their few-shot or fully supervised counterparts. Recent advancements driven by large language models show potential, but struggle to adapt to specialized domains with severely limited data. The most common approaches therefore involve the human itself randomly annotating a set of datapoints to build initial datasets. But randomly sampling data to be annotated is often inefficient as it ignores the characteristics of the data and the specific needs of the model. The situation worsens when working with imbalanced datasets, as random sampling tends to heavily bias towards the majority classes, leading to excessive annotated data. To",
    "link": "http://arxiv.org/abs/2401.13229",
    "context": "Title: From Random to Informed Data Selection: A Diversity-Based Approach to Optimize Human Annotation and Few-Shot Learning. (arXiv:2401.13229v1 [cs.CL])\nAbstract: A major challenge in Natural Language Processing is obtaining annotated data for supervised learning. An option is the use of crowdsourcing platforms for data annotation. However, crowdsourcing introduces issues related to the annotator's experience, consistency, and biases. An alternative is to use zero-shot methods, which in turn have limitations compared to their few-shot or fully supervised counterparts. Recent advancements driven by large language models show potential, but struggle to adapt to specialized domains with severely limited data. The most common approaches therefore involve the human itself randomly annotating a set of datapoints to build initial datasets. But randomly sampling data to be annotated is often inefficient as it ignores the characteristics of the data and the specific needs of the model. The situation worsens when working with imbalanced datasets, as random sampling tends to heavily bias towards the majority classes, leading to excessive annotated data. To",
    "path": "papers/24/01/2401.13229.json",
    "total_tokens": 899,
    "translated_title": "从随机到有信息选择数据：基于多样性的方法优化人类注释和少样本学习",
    "translated_abstract": "自然语言处理中的一个主要挑战是获取用于监督学习的注释数据。一种选择是使用众包平台进行数据注释。然而，众包引入了与注释者的经验、一致性和偏见相关的问题。另一种选择是使用零样本方法，但与少样本或完全监督的方法相比，零样本方法有其局限性。最近由大型语言模型推动的最新进展显示出潜力，但在数据严重受限的专业领域中，它们往往难以适应。因此，最常见的方法是人类随机注释一组数据点来构建初始数据集。然而，随机抽样数据进行注释通常效率低下，因为它忽视了数据的特征和模型的特定需求。当处理不平衡数据集时，情况更加糟糕，因为随机抽样倾向于严重偏向多数类别，导致过多的注释数据。",
    "tldr": "该论文介绍了一种基于多样性的方法，从而优化人类注释和少样本学习。传统的随机选择数据方法忽视了数据的特征和模型的需求，而该方法将考虑这些因素，以提高数据选择的效率。",
    "en_tdlr": "This paper presents a diversity-based approach to optimize human annotation and few-shot learning. The traditional random data selection method ignores the characteristics of the data and the specific needs of the model, while this approach takes these factors into consideration to improve the efficiency of data selection."
}