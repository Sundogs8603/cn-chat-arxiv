{
    "title": "Text Embedding Inversion Security for Multilingual Language Models",
    "abstract": "arXiv:2401.12192v2 Announce Type: replace-cross  Abstract: Textual data is often represented as realnumbered embeddings in NLP, particularly with the popularity of large language models (LLMs) and Embeddings as a Service (EaaS). However, storing sensitive information as embeddings can be vulnerable to security breaches, as research shows that text can be reconstructed from embeddings, even without knowledge of the underlying model. While defence mechanisms have been explored, these are exclusively focused on English, leaving other languages vulnerable to attacks. This work explores LLM security through multilingual embedding inversion. We define the problem of black-box multilingual and cross-lingual inversion attacks, and thoroughly explore their potential implications. Our findings suggest that multilingual LLMs may be more vulnerable to inversion attacks, in part because English based defences may be ineffective. To alleviate this, we propose a simple masking defense effective for b",
    "link": "https://arxiv.org/abs/2401.12192",
    "context": "Title: Text Embedding Inversion Security for Multilingual Language Models\nAbstract: arXiv:2401.12192v2 Announce Type: replace-cross  Abstract: Textual data is often represented as realnumbered embeddings in NLP, particularly with the popularity of large language models (LLMs) and Embeddings as a Service (EaaS). However, storing sensitive information as embeddings can be vulnerable to security breaches, as research shows that text can be reconstructed from embeddings, even without knowledge of the underlying model. While defence mechanisms have been explored, these are exclusively focused on English, leaving other languages vulnerable to attacks. This work explores LLM security through multilingual embedding inversion. We define the problem of black-box multilingual and cross-lingual inversion attacks, and thoroughly explore their potential implications. Our findings suggest that multilingual LLMs may be more vulnerable to inversion attacks, in part because English based defences may be ineffective. To alleviate this, we propose a simple masking defense effective for b",
    "path": "papers/24/01/2401.12192.json",
    "total_tokens": 874,
    "translated_title": "多语言语言模型的文本嵌入反向安全性",
    "translated_abstract": "在自然语言处理中，文本数据通常以实数嵌入表示，尤其是随着大型语言模型（LLMs）和嵌入式服务（EaaS）的流行。然而，将敏感信息存储为嵌入可能容易受到安全漏洞的影响，因为研究表明，即使不知道底层模型的情况下，文本也可以从嵌入中重构。尽管已经探讨了防御机制，但这些机制专注于英语，使其他语言容易受到攻击。本文通过多语言嵌入逆转探讨了LLM安全性。我们定义了黑盒多语言和跨语言逆转攻击的问题，并深入探讨了它们可能的影响。我们的研究结果表明，多语言LLMs可能更容易受到逆转攻击的影响，部分原因是基于英语的防御可能无效。为了缓解这一问题，我们提出了一种简单的掩蔽防御方法，对b有效。",
    "tldr": "该研究探讨了多语言语言模型的文本嵌入逆转安全性问题，发现多语言模型更容易受到逆转攻击的影响，并提出了简单的掩蔽防御方法。",
    "en_tdlr": "This study investigates the security of text embedding inversion for multilingual language models, finding them more vulnerable to inversion attacks and proposing a simple masking defense."
}