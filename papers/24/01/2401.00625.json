{
    "title": "Beyond Efficiency: A Systematic Survey of Resource-Efficient Large Language Models. (arXiv:2401.00625v2 [cs.LG] UPDATED)",
    "abstract": "The burgeoning field of Large Language Models (LLMs), exemplified by sophisticated models like OpenAI's ChatGPT, represents a significant advancement in artificial intelligence. These models, however, bring forth substantial challenges in the high consumption of computational, memory, energy, and financial resources, especially in environments with limited resource capabilities. This survey aims to systematically address these challenges by reviewing a broad spectrum of techniques designed to enhance the resource efficiency of LLMs. We categorize methods based on their optimization focus: computational, memory, energy, financial, and network resources and their applicability across various stages of an LLM's lifecycle, including architecture design, pretraining, finetuning, and system design. Additionally, the survey introduces a nuanced categorization of resource efficiency techniques by their specific resource types, which uncovers the intricate relationships and mappings between var",
    "link": "http://arxiv.org/abs/2401.00625",
    "context": "Title: Beyond Efficiency: A Systematic Survey of Resource-Efficient Large Language Models. (arXiv:2401.00625v2 [cs.LG] UPDATED)\nAbstract: The burgeoning field of Large Language Models (LLMs), exemplified by sophisticated models like OpenAI's ChatGPT, represents a significant advancement in artificial intelligence. These models, however, bring forth substantial challenges in the high consumption of computational, memory, energy, and financial resources, especially in environments with limited resource capabilities. This survey aims to systematically address these challenges by reviewing a broad spectrum of techniques designed to enhance the resource efficiency of LLMs. We categorize methods based on their optimization focus: computational, memory, energy, financial, and network resources and their applicability across various stages of an LLM's lifecycle, including architecture design, pretraining, finetuning, and system design. Additionally, the survey introduces a nuanced categorization of resource efficiency techniques by their specific resource types, which uncovers the intricate relationships and mappings between var",
    "path": "papers/24/01/2401.00625.json",
    "total_tokens": 889,
    "translated_title": "超越效率：资源高效的大型语言模型的系统调研",
    "translated_abstract": "大型语言模型（LLMs）领域的迅猛发展代表了人工智能领域的一个重要进步，这些模型，如OpenAI的ChatGPT，带来了计算、内存、能量和财务资源高消耗等重大挑战，尤其是在资源有限的环境中。本调研旨在系统地解决这些挑战，并审查了一系列旨在增强LLMs资源效率的技术。我们根据优化重点对方法进行分类：计算、内存、能量、财务和网络资源，以及它们在LLM生命周期的各个阶段（包括架构设计、预训练、微调和系统设计）中的适用性。此外，该调研通过特定资源类型引入了细致的资源效率技术分类，揭示了不同资源之间的复杂关系和映射。",
    "tldr": "本调研系统地解决了大型语言模型的资源效率挑战，介绍了各种优化方法和技术，包括计算、内存、能量、财务和网络资源的优化，在LLM的生命周期的各个阶段都具有应用价值，同时提出了细致的资源效率技术分类。",
    "en_tdlr": "This survey systematically addresses the resource efficiency challenges of large language models (LLMs) and introduces various optimization methods and techniques for computational, memory, energy, financial, and network resources. It highlights the applicability of these techniques across different stages of an LLM's lifecycle and presents a nuanced categorization of resource efficiency techniques."
}