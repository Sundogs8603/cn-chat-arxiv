{
    "title": "Scissorhands: Scrub Data Influence via Connection Sensitivity in Networks. (arXiv:2401.06187v1 [cs.LG])",
    "abstract": "Machine unlearning has become a pivotal task to erase the influence of data from a trained model. It adheres to recent data regulation standards and enhances the privacy and security of machine learning applications. Most existing machine unlearning methods perform well, however, they typically necessitate access to the entirety of the remaining data, which might not be feasible in certain scenarios. In this work, we present a new machine unlearning approach Scissorhands, which operates effectively with only a subset of the training data. Initially, Scissorhands identifies the most pertinent parameters in the given model relative to the forgetting data via connection sensitivity. This process involves reinitializing the most influential top-$k$ percent of these parameters, resulting in a trimmed model for erasing the influence of the forgetting data. Subsequently, Scissorhands retrains the trimmed model through a min-max optimization process, seeking parameters that preserve informatio",
    "link": "http://arxiv.org/abs/2401.06187",
    "context": "Title: Scissorhands: Scrub Data Influence via Connection Sensitivity in Networks. (arXiv:2401.06187v1 [cs.LG])\nAbstract: Machine unlearning has become a pivotal task to erase the influence of data from a trained model. It adheres to recent data regulation standards and enhances the privacy and security of machine learning applications. Most existing machine unlearning methods perform well, however, they typically necessitate access to the entirety of the remaining data, which might not be feasible in certain scenarios. In this work, we present a new machine unlearning approach Scissorhands, which operates effectively with only a subset of the training data. Initially, Scissorhands identifies the most pertinent parameters in the given model relative to the forgetting data via connection sensitivity. This process involves reinitializing the most influential top-$k$ percent of these parameters, resulting in a trimmed model for erasing the influence of the forgetting data. Subsequently, Scissorhands retrains the trimmed model through a min-max optimization process, seeking parameters that preserve informatio",
    "path": "papers/24/01/2401.06187.json",
    "total_tokens": 852,
    "translated_title": "Scissorhands: 通过网络连接敏感性在数据影响中进行数据擦除",
    "translated_abstract": "机器取消学习已成为一项重要任务，旨在擦除训练模型中的数据影响。它符合最新的数据监管标准，增强了机器学习应用的隐私和安全性。大多数现有的机器取消学习方法表现良好，但通常需要访问其余数据的全部内容，在某些情况下可能不可行。在这项工作中，我们提出了一种新的机器取消学习方法“Scissorhands”，它只使用训练数据的子集来有效运行。初始阶段，Scissorhands通过连接敏感性在给定模型中识别与遗忘数据相关的最相关参数。该过程通过重新初始化这些参数中具有最大影响力的前k%的最相关参数，从而产生一个用于擦除遗忘数据影响的修剪模型。随后，Scissorhands通过最小-最大优化过程对修剪的模型进行再训练，寻找保留信息的参数。",
    "tldr": "Scissorhands 是一种新的机器取消学习方法，通过连接敏感性识别与遗忘数据相关的最相关参数，并通过重新训练修剪的模型来擦除数据影响。",
    "en_tdlr": "Scissorhands is a new machine unlearning approach that identifies the most relevant parameters associated with the forgetting data using connection sensitivity and erases the data influence by retraining the trimmed model."
}