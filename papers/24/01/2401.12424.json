{
    "title": "DALex: Lexicase-like Selection via Diverse Aggregation. (arXiv:2401.12424v1 [cs.NE])",
    "abstract": "Lexicase selection has been shown to provide advantages over other selection algorithms in several areas of evolutionary computation and machine learning. In its standard form, lexicase selection filters a population or other collection based on randomly ordered training cases that are considered one at a time. This iterated filtering process can be time-consuming, particularly in settings with large numbers of training cases. In this paper, we propose a new method that is nearly equivalent to lexicase selection in terms of the individuals that it selects, but which does so significantly more quickly. The new method, called DALex (for Diversely Aggregated Lexicase), selects the best individual with respect to a weighted sum of training case errors, where the weights are randomly sampled. This allows us to formulate the core computation required for selection as matrix multiplication instead of recursive loops of comparisons, which in turn allows us to take advantage of optimized and pa",
    "link": "http://arxiv.org/abs/2401.12424",
    "context": "Title: DALex: Lexicase-like Selection via Diverse Aggregation. (arXiv:2401.12424v1 [cs.NE])\nAbstract: Lexicase selection has been shown to provide advantages over other selection algorithms in several areas of evolutionary computation and machine learning. In its standard form, lexicase selection filters a population or other collection based on randomly ordered training cases that are considered one at a time. This iterated filtering process can be time-consuming, particularly in settings with large numbers of training cases. In this paper, we propose a new method that is nearly equivalent to lexicase selection in terms of the individuals that it selects, but which does so significantly more quickly. The new method, called DALex (for Diversely Aggregated Lexicase), selects the best individual with respect to a weighted sum of training case errors, where the weights are randomly sampled. This allows us to formulate the core computation required for selection as matrix multiplication instead of recursive loops of comparisons, which in turn allows us to take advantage of optimized and pa",
    "path": "papers/24/01/2401.12424.json",
    "total_tokens": 842,
    "translated_title": "DALex: 通过多样聚合实现类似词法选择的选择算法",
    "translated_abstract": "在进化计算和机器学习的多个领域中，词法选择被证明相比其他选择算法具有优势。词法选择在其标准形式下，根据随机顺序的训练案例进行逐一考虑，并基于此过程对种群或其他集合进行筛选。然而，这个逐步筛选的过程可能会耗时，尤其是在具有大量训练案例的情况下。本文提出了一种新的方法DALex（即多样聚合词法选择），该方法在选择个体方面与词法选择几乎等效，但速度更快。DALex方法根据加权训练案例误差的和选择最佳个体，其中权重是随机采样的。这使得我们可以将选择所需的核心计算形式化为矩阵乘法，而不是递归循环比较，从而可以利用优化和并行化的计算。",
    "tldr": "本文提出了一种新的选择算法DALex，它通过加权训练案例误差的和来选择最佳个体，相比标准的词法选择更快速。",
    "en_tdlr": "This paper proposes a new selection algorithm called DALex, which selects the best individual by aggregating the weighted sum of training case errors, resulting in faster selection compared to standard lexicase selection."
}