{
    "title": "Full Bayesian Significance Testing for Neural Networks. (arXiv:2401.13335v1 [stat.ML])",
    "abstract": "Significance testing aims to determine whether a proposition about the population distribution is the truth or not given observations. However, traditional significance testing often needs to derive the distribution of the testing statistic, failing to deal with complex nonlinear relationships. In this paper, we propose to conduct Full Bayesian Significance Testing for neural networks, called \\textit{n}FBST, to overcome the limitation in relationship characterization of traditional approaches. A Bayesian neural network is utilized to fit the nonlinear and multi-dimensional relationships with small errors and avoid hard theoretical derivation by computing the evidence value. Besides, \\textit{n}FBST can test not only global significance but also local and instance-wise significance, which previous testing methods don't focus on. Moreover, \\textit{n}FBST is a general framework that can be extended based on the measures selected, such as Grad-\\textit{n}FBST, LRP-\\textit{n}FBST, DeepLIFT-\\t",
    "link": "http://arxiv.org/abs/2401.13335",
    "context": "Title: Full Bayesian Significance Testing for Neural Networks. (arXiv:2401.13335v1 [stat.ML])\nAbstract: Significance testing aims to determine whether a proposition about the population distribution is the truth or not given observations. However, traditional significance testing often needs to derive the distribution of the testing statistic, failing to deal with complex nonlinear relationships. In this paper, we propose to conduct Full Bayesian Significance Testing for neural networks, called \\textit{n}FBST, to overcome the limitation in relationship characterization of traditional approaches. A Bayesian neural network is utilized to fit the nonlinear and multi-dimensional relationships with small errors and avoid hard theoretical derivation by computing the evidence value. Besides, \\textit{n}FBST can test not only global significance but also local and instance-wise significance, which previous testing methods don't focus on. Moreover, \\textit{n}FBST is a general framework that can be extended based on the measures selected, such as Grad-\\textit{n}FBST, LRP-\\textit{n}FBST, DeepLIFT-\\t",
    "path": "papers/24/01/2401.13335.json",
    "total_tokens": 906,
    "translated_title": "全贝叶斯神经网络显著性检验",
    "translated_abstract": "显著性检验旨在确定给定观测结果，关于总体分布的命题是否为真。然而，传统的显著性检验通常需要推导出检验统计量的分布，无法处理复杂的非线性关系。本文提出了一种用于神经网络的全贝叶斯显著性检验方法，称为nFBST，旨在克服传统方法在关系表征方面的局限性。利用贝叶斯神经网络拟合非线性和多维关系，并通过计算证据值而不是进行繁琐的理论推导来避免错误。此外，nFBST还可以测试全局、局部和实例级的显著性，这是之前的检验方法所不关注的。此外，nFBST是一个通用框架，可以根据所选的度量进行扩展，如Grad-nFBST，LRP-nFBST，DeepLIFT-nFBST。",
    "tldr": "该论文提出了一种全贝叶斯神经网络显著性检验方法（nFBST），通过利用贝叶斯神经网络拟合非线性和多维关系，并计算证据值来替代传统方法中的理论推导，该方法能够测试全局、局部和实例级的显著性。",
    "en_tdlr": "This paper proposes a Full Bayesian Significance Testing method (nFBST) for neural networks, which fits the nonlinear and multi-dimensional relationships using a Bayesian neural network and computes evidence values instead of relying on theoretical derivations. The nFBST method can test for global, local, and instance-wise significance."
}