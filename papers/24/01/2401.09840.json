{
    "title": "FREED++: Improving RL Agents for Fragment-Based Molecule Generation by Thorough Reproduction. (arXiv:2401.09840v1 [q-bio.BM])",
    "abstract": "A rational design of new therapeutic drugs aims to find a molecular structure with desired biological functionality, e.g., an ability to activate or suppress a specific protein via binding to it. Molecular docking is a common technique for evaluating protein-molecule interactions. Recently, Reinforcement Learning (RL) has emerged as a promising approach to generating molecules with the docking score (DS) as a reward. In this work, we reproduce, scrutinize and improve the recent RL model for molecule generation called FREED (arXiv:2110.01219). Extensive evaluation of the proposed method reveals several limitations and challenges despite the outstanding results reported for three target proteins. Our contributions include fixing numerous implementation bugs and simplifying the model while increasing its quality, significantly extending experiments, and conducting an accurate comparison with current state-of-the-art methods for protein-conditioned molecule generation. We show that the res",
    "link": "http://arxiv.org/abs/2401.09840",
    "context": "Title: FREED++: Improving RL Agents for Fragment-Based Molecule Generation by Thorough Reproduction. (arXiv:2401.09840v1 [q-bio.BM])\nAbstract: A rational design of new therapeutic drugs aims to find a molecular structure with desired biological functionality, e.g., an ability to activate or suppress a specific protein via binding to it. Molecular docking is a common technique for evaluating protein-molecule interactions. Recently, Reinforcement Learning (RL) has emerged as a promising approach to generating molecules with the docking score (DS) as a reward. In this work, we reproduce, scrutinize and improve the recent RL model for molecule generation called FREED (arXiv:2110.01219). Extensive evaluation of the proposed method reveals several limitations and challenges despite the outstanding results reported for three target proteins. Our contributions include fixing numerous implementation bugs and simplifying the model while increasing its quality, significantly extending experiments, and conducting an accurate comparison with current state-of-the-art methods for protein-conditioned molecule generation. We show that the res",
    "path": "papers/24/01/2401.09840.json",
    "total_tokens": 884,
    "translated_title": "FREED++:通过彻底的复制改善基于片段的分子生成的RL代理",
    "translated_abstract": "新型治疗药物的理性设计旨在找到具有所需生物功能的分子结构，例如，通过与特定蛋白质结合来激活或抑制它。分子对接是评估蛋白质-分子相互作用的常见技术。最近，强化学习（RL）已经成为一种有希望的方法，通过对接评分（DS）作为奖励来生成分子。在这项工作中，我们复制、审查和改进了最近用于分子生成的RL模型FREED（arXiv：2110.01219）。对所提出方法的广泛评估揭示了一些局限性和挑战，尽管对三个目标蛋白质报告了杰出的结果。我们的贡献包括修复了许多实现错误，简化了模型并提高了其质量，大大扩展了实验范围，并与当前最先进的蛋白质条件下分子生成方法进行了准确比较。我们展示了该方法的鲁棒性和高效性",
    "tldr": "本研究改进了名为FREED的RL模型，通过复制、审查和简化，使其在蛋白质条件下的分子生成中具有更好的质量和性能",
    "en_tdlr": "This study improves the RL model called FREED for protein-conditioned molecule generation by reproducing, scrutinizing, and simplifying it, achieving better quality and performance."
}