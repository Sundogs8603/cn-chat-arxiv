{
    "title": "Reinforcement Learning Interventions on Boundedly Rational Human Agents in Frictionful Tasks. (arXiv:2401.14923v1 [cs.AI])",
    "abstract": "Many important behavior changes are frictionful; they require individuals to expend effort over a long period with little immediate gratification. Here, an artificial intelligence (AI) agent can provide personalized interventions to help individuals stick to their goals. In these settings, the AI agent must personalize rapidly (before the individual disengages) and interpretably, to help us understand the behavioral interventions. In this paper, we introduce Behavior Model Reinforcement Learning (BMRL), a framework in which an AI agent intervenes on the parameters of a Markov Decision Process (MDP) belonging to a boundedly rational human agent. Our formulation of the human decision-maker as a planning agent allows us to attribute undesirable human policies (ones that do not lead to the goal) to their maladapted MDP parameters, such as an extremely low discount factor. Furthermore, we propose a class of tractable human models that captures fundamental behaviors in frictionful tasks. Int",
    "link": "http://arxiv.org/abs/2401.14923",
    "context": "Title: Reinforcement Learning Interventions on Boundedly Rational Human Agents in Frictionful Tasks. (arXiv:2401.14923v1 [cs.AI])\nAbstract: Many important behavior changes are frictionful; they require individuals to expend effort over a long period with little immediate gratification. Here, an artificial intelligence (AI) agent can provide personalized interventions to help individuals stick to their goals. In these settings, the AI agent must personalize rapidly (before the individual disengages) and interpretably, to help us understand the behavioral interventions. In this paper, we introduce Behavior Model Reinforcement Learning (BMRL), a framework in which an AI agent intervenes on the parameters of a Markov Decision Process (MDP) belonging to a boundedly rational human agent. Our formulation of the human decision-maker as a planning agent allows us to attribute undesirable human policies (ones that do not lead to the goal) to their maladapted MDP parameters, such as an extremely low discount factor. Furthermore, we propose a class of tractable human models that captures fundamental behaviors in frictionful tasks. Int",
    "path": "papers/24/01/2401.14923.json",
    "total_tokens": 933,
    "translated_title": "在有限理性人类代理在摩擦任务中进行强化学习干预",
    "translated_abstract": "许多重要的行为变化是具有摩擦的；它们要求个体长期付出努力，但没有即时的满足。在这种情况下，人工智能（AI）代理可以提供个性化的干预，帮助个体坚持自己的目标。在这些设置中，AI代理必须快速个性化（在个体失去兴趣之前）并具有解释性，以帮助我们理解行为干预。在本文中，我们引入了行为模型强化学习（BMRL）框架，其中AI代理对属于有限理性人类代理的马尔可夫决策过程（MDP）的参数进行干预。我们将人类决策者的形式化为一个规划代理，这样我们就能够将不理想的人类策略（不会达到目标的策略）归因于其不适应的MDP参数，比如极低的折扣因子。此外，我们提出了一类可解释的人类模型，捕捉了摩擦任务中的基本行为。",
    "tldr": "本论文介绍了行为模型强化学习（BMRL）框架，在摩擦性任务中，AI代理对有限理性人类代理的参数进行干预，通过对人类策略进行解释，帮助理解行为干预。",
    "en_tdlr": "This paper introduces the Behavior Model Reinforcement Learning (BMRL) framework, which intervenes on the parameters of a bounded rational human agent in frictionful tasks. It helps understand behavioral interventions by interpreting human policies and personalizing them."
}