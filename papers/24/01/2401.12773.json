{
    "title": "Generative AI Triggers Welfare-Reducing Decisions in Humans. (arXiv:2401.12773v1 [econ.GN])",
    "abstract": "Generative artificial intelligence (AI) is poised to reshape the way individuals communicate and interact. While this form of AI has the potential to efficiently make numerous human decisions, there is limited understanding of how individuals respond to its use in social interaction. In particular, it remains unclear how individuals engage with algorithms when the interaction entails consequences for other people. Here, we report the results of a large-scale pre-registered online experiment (N = 3,552) indicating diminished fairness, trust, trustworthiness, cooperation, and coordination by human players in economic twoplayer games, when the decision of the interaction partner is taken over by ChatGPT. On the contrary, we observe no adverse welfare effects when individuals are uncertain about whether they are interacting with a human or generative AI. Therefore, the promotion of AI transparency, often suggested as a solution to mitigate the negative impacts of generative AI on society, ",
    "link": "http://arxiv.org/abs/2401.12773",
    "context": "Title: Generative AI Triggers Welfare-Reducing Decisions in Humans. (arXiv:2401.12773v1 [econ.GN])\nAbstract: Generative artificial intelligence (AI) is poised to reshape the way individuals communicate and interact. While this form of AI has the potential to efficiently make numerous human decisions, there is limited understanding of how individuals respond to its use in social interaction. In particular, it remains unclear how individuals engage with algorithms when the interaction entails consequences for other people. Here, we report the results of a large-scale pre-registered online experiment (N = 3,552) indicating diminished fairness, trust, trustworthiness, cooperation, and coordination by human players in economic twoplayer games, when the decision of the interaction partner is taken over by ChatGPT. On the contrary, we observe no adverse welfare effects when individuals are uncertain about whether they are interacting with a human or generative AI. Therefore, the promotion of AI transparency, often suggested as a solution to mitigate the negative impacts of generative AI on society, ",
    "path": "papers/24/01/2401.12773.json",
    "total_tokens": 910,
    "translated_title": "生成式人工智能触发人类的削减福利决策",
    "translated_abstract": "生成式人工智能有望重塑个人的沟通和互动方式。虽然这种形式的人工智能有能力高效地做出许多人类决策，但人们对其在社交互动中的使用方式了解有限。特别是，人们如何与算法进行交互时，其决策对他人产生后果尚不清楚。在这里，我们报告了一项大规模的预先注册在线实验（N = 3,552）的结果，表明当决策的互动伙伴由ChatGPT接管时，人类玩家在经济二人游戏中表现出的公平性、信任、值得信赖、合作和协调能力下降。相反，在不确定是否与人类或生成式人工智能进行互动时，我们观察到没有不利的福利影响。因此，人工智能透明度的提高，通常被认为是缓解生成式人工智能对社会负面影响的解决方案。",
    "tldr": "生成式人工智能在社交互动中将决策交给算法会对人类的公平性、信任、合作和协调能力产生负面影响，但当人们不确定是否与人类或生成式人工智能进行互动时，不会对福利产生不利影响。"
}