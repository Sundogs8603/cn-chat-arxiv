{
    "title": "Arabic Tweet Act: A Weighted Ensemble Pre-Trained Transformer Model for Classifying Arabic Speech Acts on Twitter",
    "abstract": "Speech acts are a speakers actions when performing an utterance within a conversation, such as asking, recommending, greeting, or thanking someone, expressing a thought, or making a suggestion. Understanding speech acts helps interpret the intended meaning and actions behind a speakers or writers words. This paper proposes a Twitter dialectal Arabic speech act classification approach based on a transformer deep learning neural network. Twitter and social media, are becoming more and more integrated into daily life. As a result, they have evolved into a vital source of information that represents the views and attitudes of their users. We proposed a BERT based weighted ensemble learning approach to integrate the advantages of various BERT models in dialectal Arabic speech acts classification. We compared the proposed model against several variants of Arabic BERT models and sequence-based models. We developed a dialectal Arabic tweet act dataset by annotating a subset of a large existing",
    "link": "https://arxiv.org/abs/2401.17373",
    "context": "Title: Arabic Tweet Act: A Weighted Ensemble Pre-Trained Transformer Model for Classifying Arabic Speech Acts on Twitter\nAbstract: Speech acts are a speakers actions when performing an utterance within a conversation, such as asking, recommending, greeting, or thanking someone, expressing a thought, or making a suggestion. Understanding speech acts helps interpret the intended meaning and actions behind a speakers or writers words. This paper proposes a Twitter dialectal Arabic speech act classification approach based on a transformer deep learning neural network. Twitter and social media, are becoming more and more integrated into daily life. As a result, they have evolved into a vital source of information that represents the views and attitudes of their users. We proposed a BERT based weighted ensemble learning approach to integrate the advantages of various BERT models in dialectal Arabic speech acts classification. We compared the proposed model against several variants of Arabic BERT models and sequence-based models. We developed a dialectal Arabic tweet act dataset by annotating a subset of a large existing",
    "path": "papers/24/01/2401.17373.json",
    "total_tokens": 880,
    "translated_title": "阿拉伯推文行为：基于加权集成预训练Transformer模型的阿拉伯语推特语言行为分类",
    "translated_abstract": "语言行为是说话者在对话中表达意思时的行为，例如询问、推荐、问候、道谢、表达想法或提出建议。理解语言行为有助于解释说话者或作者言语背后的意图和行为。本文提出了一种基于Transformer深度学习神经网络的阿拉伯语推特语言行为分类方法。推特和社交媒体越来越融入日常生活。因此，它们已经演变成了表达用户观点和态度的重要信息来源。我们提出了一种基于BERT的加权集成学习方法，以整合方言阿拉伯语语言行为分类中各种BERT模型的优势。我们将所提出的模型与几个阿拉伯BERT模型和基于序列的模型进行了比较。通过对现有大型数据集的子集进行注释，我们开发了一个方言阿拉伯推特行为数据集。",
    "tldr": "本文提出了一种用于阿拉伯语推特语言行为分类的加权集成预训练Transformer模型。通过整合不同的BERT模型，我们实现了对阿拉伯方言的精确分类，为理解用户观点和态度提供了有力的工具。",
    "en_tdlr": "This paper proposes a weighted ensemble pre-trained transformer model for classifying Arabic speech acts on Twitter. By integrating different BERT models, the proposed approach achieves accurate classification of Arabic dialects, providing a powerful tool for understanding user views and attitudes."
}