{
    "title": "Fast Registration of Photorealistic Avatars for VR Facial Animation. (arXiv:2401.11002v1 [cs.CV])",
    "abstract": "Virtual Reality (VR) bares promise of social interactions that can feel more immersive than other media. Key to this is the ability to accurately animate a photorealistic avatar of one's likeness while wearing a VR headset. Although high quality registration of person-specific avatars to headset-mounted camera (HMC) images is possible in an offline setting, the performance of generic realtime models are significantly degraded. Online registration is also challenging due to oblique camera views and differences in modality. In this work, we first show that the domain gap between the avatar and headset-camera images is one of the primary sources of difficulty, where a transformer-based architecture achieves high accuracy on domain-consistent data, but degrades when the domain-gap is re-introduced. Building on this finding, we develop a system design that decouples the problem into two parts: 1) an iterative refinement module that takes in-domain inputs, and 2) a generic avatar-guided imag",
    "link": "http://arxiv.org/abs/2401.11002",
    "context": "Title: Fast Registration of Photorealistic Avatars for VR Facial Animation. (arXiv:2401.11002v1 [cs.CV])\nAbstract: Virtual Reality (VR) bares promise of social interactions that can feel more immersive than other media. Key to this is the ability to accurately animate a photorealistic avatar of one's likeness while wearing a VR headset. Although high quality registration of person-specific avatars to headset-mounted camera (HMC) images is possible in an offline setting, the performance of generic realtime models are significantly degraded. Online registration is also challenging due to oblique camera views and differences in modality. In this work, we first show that the domain gap between the avatar and headset-camera images is one of the primary sources of difficulty, where a transformer-based architecture achieves high accuracy on domain-consistent data, but degrades when the domain-gap is re-introduced. Building on this finding, we develop a system design that decouples the problem into two parts: 1) an iterative refinement module that takes in-domain inputs, and 2) a generic avatar-guided imag",
    "path": "papers/24/01/2401.11002.json",
    "total_tokens": 896,
    "translated_title": "快速注册逼真的虚拟现实头像用于面部动画",
    "translated_abstract": "虚拟现实（VR）在社交互动方面拥有更具沉浸感的潜力。其中一个关键是能够在佩戴VR头显的情况下准确地模拟一个逼真的头像。虽然在离线环境中可以实现对特定个人头像进行高质量注册，并进行动画生成，但通用实时模型的性能明显下降。在线注册也面临诸多挑战，包括倾斜的摄像机视角和不同的模态。在这项工作中，我们首先表明头像与头显相机图像之间的领域差距是困难的主要源泉之一，基于转换器的架构在领域一致的数据上实现了高准确性，在引入领域差距后性能下降。基于此发现，我们提出了一个系统设计，将问题分解为两个部分：1）一个迭代细化模块，接收领域内输入，和2）一个通用的头像引导图像生成模块",
    "tldr": "本论文针对虚拟现实头像注册和面部动画问题，发现头像和头显相机图像之间的领域差距是主要难点，并提出了一个系统设计来解决这个问题。",
    "en_tdlr": "This paper addresses the challenge of registering virtual reality avatars and animating facial expressions, identifying the domain gap between the avatar and headset-camera images as a primary difficulty, and proposing a system design to overcome it."
}