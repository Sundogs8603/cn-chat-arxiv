{
    "title": "LongAlign: A Recipe for Long Context Alignment of Large Language Models",
    "abstract": "Extending large language models to effectively handle long contexts requires instruction fine-tuning on input sequences of similar length. To address this, we present LongAlign -- a recipe of the instruction data, training, and evaluation for long context alignment. First, we construct a long instruction-following dataset using Self-Instruct. To ensure the data diversity, it covers a broad range of tasks from various long context sources. Second, we adopt the packing and sorted batching strategies to speed up supervised fine-tuning on data with varied length distributions. Additionally, we develop a loss weighting method to balance the contribution to the loss across different sequences during packing training. Third, we introduce the LongBench-Chat benchmark for evaluating instruction-following capabilities on queries of 10k-100k in length. Experiments show that LongAlign outperforms existing recipes for LLMs in long context tasks by up to 30\\%, while also maintaining their proficienc",
    "link": "https://arxiv.org/abs/2401.18058",
    "context": "Title: LongAlign: A Recipe for Long Context Alignment of Large Language Models\nAbstract: Extending large language models to effectively handle long contexts requires instruction fine-tuning on input sequences of similar length. To address this, we present LongAlign -- a recipe of the instruction data, training, and evaluation for long context alignment. First, we construct a long instruction-following dataset using Self-Instruct. To ensure the data diversity, it covers a broad range of tasks from various long context sources. Second, we adopt the packing and sorted batching strategies to speed up supervised fine-tuning on data with varied length distributions. Additionally, we develop a loss weighting method to balance the contribution to the loss across different sequences during packing training. Third, we introduce the LongBench-Chat benchmark for evaluating instruction-following capabilities on queries of 10k-100k in length. Experiments show that LongAlign outperforms existing recipes for LLMs in long context tasks by up to 30\\%, while also maintaining their proficienc",
    "path": "papers/24/01/2401.18058.json",
    "total_tokens": 887,
    "translated_title": "LongAlign：大型语言模型的长上下文对齐方法",
    "translated_abstract": "将大型语言模型扩展到有效处理长上下文的能力需要对相似长度的输入序列进行指导微调。为了解决这个问题，我们提出了LongAlign - 一种用于长上下文对齐的指导数据、训练和评估方法。首先，我们使用自我指导方法构建长指令跟随数据集。为了确保数据多样性，它涵盖了来自不同长上下文来源的广泛任务。其次，我们采用打包和排序批处理策略，加速在具有不同长度分布的数据上的受监督微调。此外，我们还开发了一种损失加权方法，在打包训练过程中平衡损失对不同序列的贡献。第三，我们引入了LongBench-Chat基准，用于评估10k-100k长度的查询的指令跟随能力。实验结果表明，LongAlign在长上下文任务中比现有的LLMs方法的性能提高了多达30\\%，同时也保持了其熟练性。",
    "tldr": "LongAlign是一种用于大型语言模型的长上下文对齐的方法，通过指导微调和使用打包、排序和损失加权策略，它在长上下文任务中表现优异，相比现有的方法提高了多达30\\%的性能。",
    "en_tdlr": "LongAlign is a method for long context alignment of large language models. By utilizing instruction fine-tuning and employing packing, sorting, and loss weighting strategies, it outperforms existing methods in long context tasks by up to 30\\%."
}