{
    "title": "Federated Multi-View Synthesizing for Metaverse. (arXiv:2401.00859v1 [eess.IV])",
    "abstract": "The metaverse is expected to provide immersive entertainment, education, and business applications. However, virtual reality (VR) transmission over wireless networks is data- and computation-intensive, making it critical to introduce novel solutions that meet stringent quality-of-service requirements. With recent advances in edge intelligence and deep learning, we have developed a novel multi-view synthesizing framework that can efficiently provide computation, storage, and communication resources for wireless content delivery in the metaverse. We propose a three-dimensional (3D)-aware generative model that uses collections of single-view images. These single-view images are transmitted to a group of users with overlapping fields of view, which avoids massive content transmission compared to transmitting tiles or whole 3D models. We then present a federated learning approach to guarantee an efficient learning process. The training performance can be improved by characterizing the verti",
    "link": "http://arxiv.org/abs/2401.00859",
    "context": "Title: Federated Multi-View Synthesizing for Metaverse. (arXiv:2401.00859v1 [eess.IV])\nAbstract: The metaverse is expected to provide immersive entertainment, education, and business applications. However, virtual reality (VR) transmission over wireless networks is data- and computation-intensive, making it critical to introduce novel solutions that meet stringent quality-of-service requirements. With recent advances in edge intelligence and deep learning, we have developed a novel multi-view synthesizing framework that can efficiently provide computation, storage, and communication resources for wireless content delivery in the metaverse. We propose a three-dimensional (3D)-aware generative model that uses collections of single-view images. These single-view images are transmitted to a group of users with overlapping fields of view, which avoids massive content transmission compared to transmitting tiles or whole 3D models. We then present a federated learning approach to guarantee an efficient learning process. The training performance can be improved by characterizing the verti",
    "path": "papers/24/01/2401.00859.json",
    "total_tokens": 871,
    "translated_title": "为元宇宙进行联合多视角合成",
    "translated_abstract": "元宇宙预计能提供沉浸式的娱乐、教育和商业应用。然而，虚拟现实（VR）在无线网络上的传输需要大量的数据和计算资源，因此需要引入满足严格的服务质量要求的新解决方案。通过边缘智能和深度学习的最新进展，我们开发了一种新的多视角合成框架，可以为元宇宙中的无线内容传递提供高效的计算、存储和通信资源。我们提出了一个三维感知的生成模型，利用单视角图像集合。这些单视角图像被传输给一组具有重叠视野的用户，相比传输瓦片或整个三维模型，可以避免大量的内容传输。然后，我们提出了一种联合学习方法，以保证高效的学习过程。通过表征垂直方向上的特征，可以提高训练性能。",
    "tldr": "本论文提出了一种用于元宇宙的联合多视角合成框架，通过三维感知的生成模型和联合学习方法，实现了高效的无线内容传递，满足元宇宙中严格的服务质量要求。",
    "en_tdlr": "This paper proposes a federated multi-view synthesizing framework for the metaverse, which efficiently delivers wireless content by utilizing a 3D-aware generative model and a federated learning approach, meeting the stringent quality-of-service requirements in the metaverse."
}