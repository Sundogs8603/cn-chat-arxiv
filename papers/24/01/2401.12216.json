{
    "title": "Mitigating Covariate Shift in Misspecified Regression with Applications to Reinforcement Learning. (arXiv:2401.12216v1 [stat.ML])",
    "abstract": "A pervasive phenomenon in machine learning applications is distribution shift, where training and deployment conditions for a machine learning model differ. As distribution shift typically results in a degradation in performance, much attention has been devoted to algorithmic interventions that mitigate these detrimental effects. In this paper, we study the effect of distribution shift in the presence of model misspecification, specifically focusing on $L_{\\infty}$-misspecified regression and adversarial covariate shift, where the regression target remains fixed while the covariate distribution changes arbitrarily. We show that empirical risk minimization, or standard least squares regression, can result in undesirable misspecification amplification where the error due to misspecification is amplified by the density ratio between the training and testing distributions. As our main result, we develop a new algorithm -- inspired by robust optimization techniques -- that avoids this undes",
    "link": "http://arxiv.org/abs/2401.12216",
    "context": "Title: Mitigating Covariate Shift in Misspecified Regression with Applications to Reinforcement Learning. (arXiv:2401.12216v1 [stat.ML])\nAbstract: A pervasive phenomenon in machine learning applications is distribution shift, where training and deployment conditions for a machine learning model differ. As distribution shift typically results in a degradation in performance, much attention has been devoted to algorithmic interventions that mitigate these detrimental effects. In this paper, we study the effect of distribution shift in the presence of model misspecification, specifically focusing on $L_{\\infty}$-misspecified regression and adversarial covariate shift, where the regression target remains fixed while the covariate distribution changes arbitrarily. We show that empirical risk minimization, or standard least squares regression, can result in undesirable misspecification amplification where the error due to misspecification is amplified by the density ratio between the training and testing distributions. As our main result, we develop a new algorithm -- inspired by robust optimization techniques -- that avoids this undes",
    "path": "papers/24/01/2401.12216.json",
    "total_tokens": 832,
    "translated_title": "用于减轻分布转变的错误回归的方法及在强化学习中的应用",
    "translated_abstract": "机器学习应用中普遍存在的一个现象是分布转变，指的是训练和部署条件之间的差异。由于分布转变通常导致性能下降，因此人们一直致力于算法干预以减轻这些不利影响。在本文中，我们研究了在模型规范错误的情况下分布转变的影响，具体关注L∞-错误回归和对抗性协变量转变，其中回归目标保持不变，而协变量分布任意变化。我们发现经验风险最小化或标准最小二乘回归可能导致不可取的错误放大，其中由于规范错误而产生的误差被训练和测试分布之间的密度比放大。作为我们的主要结果，我们提出了一种新的算法——受鲁棒优化技术启发——以避免这种不可取的错误放大现象。",
    "tldr": "本文研究了在模型规范错误的条件下，由于分布转变导致的错误放大问题，并提出了一种新的算法来解决这个问题。",
    "en_tdlr": "This paper investigates the issue of error amplification due to distribution shift in misspecified regression and proposes a new algorithm to mitigate this problem."
}