{
    "title": "Contracting with a Learning Agent. (arXiv:2401.16198v1 [cs.GT])",
    "abstract": "Many real-life contractual relations differ completely from the clean, static model at the heart of principal-agent theory. Typically, they involve repeated strategic interactions of the principal and agent, taking place under uncertainty and over time. While appealing in theory, players seldom use complex dynamic strategies in practice, often preferring to circumvent complexity and approach uncertainty through learning. We initiate the study of repeated contracts with a learning agent, focusing on agents who achieve no-regret outcomes.  Optimizing against a no-regret agent is a known open problem in general games; we achieve an optimal solution to this problem for a canonical contract setting, in which the agent's choice among multiple actions leads to success/failure. The solution has a surprisingly simple structure: for some $\\alpha > 0$, initially offer the agent a linear contract with scalar $\\alpha$, then switch to offering a linear contract with scalar $0$. This switch causes th",
    "link": "http://arxiv.org/abs/2401.16198",
    "context": "Title: Contracting with a Learning Agent. (arXiv:2401.16198v1 [cs.GT])\nAbstract: Many real-life contractual relations differ completely from the clean, static model at the heart of principal-agent theory. Typically, they involve repeated strategic interactions of the principal and agent, taking place under uncertainty and over time. While appealing in theory, players seldom use complex dynamic strategies in practice, often preferring to circumvent complexity and approach uncertainty through learning. We initiate the study of repeated contracts with a learning agent, focusing on agents who achieve no-regret outcomes.  Optimizing against a no-regret agent is a known open problem in general games; we achieve an optimal solution to this problem for a canonical contract setting, in which the agent's choice among multiple actions leads to success/failure. The solution has a surprisingly simple structure: for some $\\alpha > 0$, initially offer the agent a linear contract with scalar $\\alpha$, then switch to offering a linear contract with scalar $0$. This switch causes th",
    "path": "papers/24/01/2401.16198.json",
    "total_tokens": 868,
    "translated_title": "同学习代理人进行合同订立",
    "translated_abstract": "许多现实生活中的合同关系与基本的委托代理理论存在明显差异。通常，它们涉及到委托人和代理人在不确定性和时间的条件下进行重复的策略性互动。虽然从理论上讲很吸引人，但在实践中，玩家很少使用复杂的动态策略，通常更喜欢通过学习来应对不确定性和复杂性。我们开始研究与学习代理人进行重复合同的问题，重点关注达到无悔结果的代理人。在一般博弈中优化对抗无悔代理人是一个已知的开放问题;我们针对一个经典的合同设置问题实现了对这个问题的最优解，其中代理人在多个选择动作中选择会导致成功/失败。解决方案具有出人意料的简单结构：对于一些$\\alpha > 0$，最初以标量$\\alpha$提供线性合同，然后切换到以标量$0$提供线性合同。这个转换引发了...",
    "tldr": "本研究主要针对与学习代理人进行重复合同的问题，关注代理人达到无悔结果的情况。我们在一个经典的合同设置下找到了最优解。解决方案采用了简单的结构：最初以一个线性合同开始，然后切换到另一个线性合同。"
}