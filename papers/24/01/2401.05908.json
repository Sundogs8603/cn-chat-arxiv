{
    "title": "EpilepsyLLM: Domain-Specific Large Language Model Fine-tuned with Epilepsy Medical Knowledge. (arXiv:2401.05908v1 [cs.CL])",
    "abstract": "With large training datasets and massive amounts of computing sources, large language models (LLMs) achieve remarkable performance in comprehensive and generative ability. Based on those powerful LLMs, the model fine-tuned with domain-specific datasets posseses more specialized knowledge and thus is more practical like medical LLMs. However, the existing fine-tuned medical LLMs are limited to general medical knowledge with English language. For disease-specific problems, the model's response is inaccurate and sometimes even completely irrelevant, especially when using a language other than English. In this work, we focus on the particular disease of Epilepsy with Japanese language and introduce a customized LLM termed as EpilepsyLLM. Our model is trained from the pre-trained LLM by fine-tuning technique using datasets from the epilepsy domain. The datasets contain knowledge of basic information about disease, common treatment methods and drugs, and important notes in life and work. The",
    "link": "http://arxiv.org/abs/2401.05908",
    "context": "Title: EpilepsyLLM: Domain-Specific Large Language Model Fine-tuned with Epilepsy Medical Knowledge. (arXiv:2401.05908v1 [cs.CL])\nAbstract: With large training datasets and massive amounts of computing sources, large language models (LLMs) achieve remarkable performance in comprehensive and generative ability. Based on those powerful LLMs, the model fine-tuned with domain-specific datasets posseses more specialized knowledge and thus is more practical like medical LLMs. However, the existing fine-tuned medical LLMs are limited to general medical knowledge with English language. For disease-specific problems, the model's response is inaccurate and sometimes even completely irrelevant, especially when using a language other than English. In this work, we focus on the particular disease of Epilepsy with Japanese language and introduce a customized LLM termed as EpilepsyLLM. Our model is trained from the pre-trained LLM by fine-tuning technique using datasets from the epilepsy domain. The datasets contain knowledge of basic information about disease, common treatment methods and drugs, and important notes in life and work. The",
    "path": "papers/24/01/2401.05908.json",
    "total_tokens": 987,
    "translated_title": "EpilepsyLLM: 使用癫痫医学知识进行领域特定的大型语言模型微调",
    "translated_abstract": "大型语言模型（LLMs）凭借庞大的训练数据集和大量的计算资源，在综合和生成能力方面取得了显著的性能。基于这些强大的LLMs，通过领域特定的数据集进行微调，模型拥有更专业的知识，因此更实用，比如医学LLMs。然而，现有的经过微调的医学LLMs仅限于通用的英文医学知识。对于特定疾病的问题，模型的响应是不准确的，有时甚至完全不相关，特别是在使用非英文语言时。在本研究中，我们专注于使用日语进行癫痫疾病的研究，并引入了一种定制的LLM，称为EpilepsyLLM。我们的模型使用来自癫痫领域的数据集通过微调技术从预训练的LLM进行训练，其中包含有关疾病基本信息、常见治疗方法和药物以及生活和工作中的重要注意事项的知识。",
    "tldr": "本研究提出了一种用于癫痫疾病的定制化大型语言模型EpilepsyLLM，通过微调预训练的LLM并使用癫痫领域的数据集进行训练。通过该模型，可以更准确地回答与癫痫相关的问题，尤其适用于使用日语进行研究。",
    "en_tdlr": "This paper introduces a customized large language model called EpilepsyLLM for the disease of Epilepsy, trained by fine-tuning a pre-trained LLM with datasets from the epilepsy domain. The model provides more accurate responses to epilepsy-related questions, especially in the context of Japanese language research."
}