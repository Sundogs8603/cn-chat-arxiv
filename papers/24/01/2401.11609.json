{
    "title": "Graph Edits for Counterfactual Explanations: A comparative study",
    "abstract": "arXiv:2401.11609v2 Announce Type: replace-cross  Abstract: Counterfactuals have been established as a popular explainability technique which leverages a set of minimal edits to alter the prediction of a classifier. When considering conceptual counterfactuals on images, the edits requested should correspond to salient concepts present in the input data. At the same time, conceptual distances are defined by knowledge graphs, ensuring the optimality of conceptual edits. In this work, we extend previous endeavors on graph edits as counterfactual explanations by conducting a comparative study which encompasses both supervised and unsupervised Graph Neural Network (GNN) approaches. To this end, we pose the following significant research question: should we represent input data as graphs, which is the optimal GNN approach in terms of performance and time efficiency to generate minimal and meaningful counterfactual explanations for black-box image classifiers?",
    "link": "https://arxiv.org/abs/2401.11609",
    "context": "Title: Graph Edits for Counterfactual Explanations: A comparative study\nAbstract: arXiv:2401.11609v2 Announce Type: replace-cross  Abstract: Counterfactuals have been established as a popular explainability technique which leverages a set of minimal edits to alter the prediction of a classifier. When considering conceptual counterfactuals on images, the edits requested should correspond to salient concepts present in the input data. At the same time, conceptual distances are defined by knowledge graphs, ensuring the optimality of conceptual edits. In this work, we extend previous endeavors on graph edits as counterfactual explanations by conducting a comparative study which encompasses both supervised and unsupervised Graph Neural Network (GNN) approaches. To this end, we pose the following significant research question: should we represent input data as graphs, which is the optimal GNN approach in terms of performance and time efficiency to generate minimal and meaningful counterfactual explanations for black-box image classifiers?",
    "path": "papers/24/01/2401.11609.json",
    "total_tokens": 855,
    "translated_title": "图编辑用于反事实解释：一项比较研究",
    "translated_abstract": "反事实已被确立为一种流行的可解释性技术，利用一组最小的编辑来改变分类器的预测。在考虑图像上的概念反事实时，请求的编辑应对应输入数据中存在的显著概念。同时，概念距离由知识图谱定义，确保概念编辑的最优性。在这项工作中，我们通过进行比较研究扩展了以图编辑为反事实解释的先前努力，在这项研究中涵盖了监督和无监督的图神经网络（GNN）方法。到此为止，我们提出了以下重要的研究问题：我们应该将输入数据表示为图形，这是生成黑箱图像分类器的最小和有意义的反事实解释在性能和时间效率方面最佳的GNN方法吗？",
    "tldr": "研究通过比较监督和无监督的图神经网络方法，扩展了图编辑作为反事实解释的先前努力，探讨了将输入数据表示为图形对于生成黑箱图像分类器最小且有意义的反事实解释的性能和时间效率最佳的方法。"
}