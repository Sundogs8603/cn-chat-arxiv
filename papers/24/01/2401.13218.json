{
    "title": "ULTRA: Unleash LLMs' Potential for Event Argument Extraction through Hierarchical Modeling and Pair-wise Refinement. (arXiv:2401.13218v1 [cs.CL])",
    "abstract": "Structural extraction of events within discourse is critical since it avails a deeper understanding of communication patterns and behavior trends. Event argument extraction (EAE), at the core of event-centric understanding, is the task of identifying role-specific text spans (i.e., arguments) for a given event. Document-level EAE (DocEAE) focuses on arguments that are scattered across an entire document. In this work, we explore the capabilities of open source Large Language Models (LLMs), i.e., Flan-UL2, for the DocEAE task. To this end, we propose ULTRA, a hierarchical framework that extracts event arguments more cost-effectively -- the method needs as few as 50 annotations and doesn't require hitting costly API endpoints. Further, it alleviates the positional bias issue intrinsic to LLMs. ULTRA first sequentially reads text chunks of a document to generate a candidate argument set, upon which ULTRA learns to drop non-pertinent candidates through self-refinement. We further introduce",
    "link": "http://arxiv.org/abs/2401.13218",
    "context": "Title: ULTRA: Unleash LLMs' Potential for Event Argument Extraction through Hierarchical Modeling and Pair-wise Refinement. (arXiv:2401.13218v1 [cs.CL])\nAbstract: Structural extraction of events within discourse is critical since it avails a deeper understanding of communication patterns and behavior trends. Event argument extraction (EAE), at the core of event-centric understanding, is the task of identifying role-specific text spans (i.e., arguments) for a given event. Document-level EAE (DocEAE) focuses on arguments that are scattered across an entire document. In this work, we explore the capabilities of open source Large Language Models (LLMs), i.e., Flan-UL2, for the DocEAE task. To this end, we propose ULTRA, a hierarchical framework that extracts event arguments more cost-effectively -- the method needs as few as 50 annotations and doesn't require hitting costly API endpoints. Further, it alleviates the positional bias issue intrinsic to LLMs. ULTRA first sequentially reads text chunks of a document to generate a candidate argument set, upon which ULTRA learns to drop non-pertinent candidates through self-refinement. We further introduce",
    "path": "papers/24/01/2401.13218.json",
    "total_tokens": 909,
    "translated_title": "ULTRA:通过层级建模和逐对优化释放LLMs在事件论证提取中的潜力",
    "translated_abstract": "将事件在话语中进行结构化提取是至关重要的，因为它可以更深入地理解交流模式和行为趋势。事件论证提取（EAE）是事件中心理解的核心任务，其任务是为给定事件识别特定角色的文本范围（即论证）。文档级EAE（DocEAE）侧重于散布在整个文档中的论证。在这项工作中，我们探索了开源的大型语言模型（LLMs，例如Flan-UL2）在DocEAE任务中的能力。为此，我们提出了ULTRA，一种层级框架，通过更加经济高效地提取事件论证，从而在方法中只需要少于50个注释，并且不需要访问昂贵的API端点。此外，它缓解了LLMs固有的位置偏差问题。ULTRA首先顺序阅读文档的文本块以生成候选论证集合，随后通过自我优化学习放弃非相关的候选。我们进一步介绍了...",
    "tldr": "ULTRA是一种层级框架，利用大型语言模型在事件论证提取中进行经济高效的处理，通过自我优化和候选论证集合的生成，解决了位置偏差问题。",
    "en_tdlr": "ULTRA is a hierarchical framework that utilizes large language models for cost-effective event argument extraction, addressing the positional bias issue through self-refinement and candidate argument set generation."
}