{
    "title": "Towards Trustable Language Models: Investigating Information Quality of Large Language Models. (arXiv:2401.13086v1 [cs.CL])",
    "abstract": "Large language models (LLM) are generating information at a rapid pace, requiring users to increasingly rely and trust the data. Despite remarkable advances of LLM, Information generated by LLM is not completely trustworthy, due to challenges in information quality. Specifically, integrity of Information quality decreases due to unreliable, biased, tokenization during pre-training of LLM. Moreover, due to decreased information quality issues, has led towards hallucination, fabricated information. Unreliable information can lead towards flawed decisions in businesses, which impacts economic activity. In this work, we introduce novel mathematical information quality evaluation of LLM, we furthermore analyze and highlight information quality challenges, scaling laws to systematically scale language models.",
    "link": "http://arxiv.org/abs/2401.13086",
    "context": "Title: Towards Trustable Language Models: Investigating Information Quality of Large Language Models. (arXiv:2401.13086v1 [cs.CL])\nAbstract: Large language models (LLM) are generating information at a rapid pace, requiring users to increasingly rely and trust the data. Despite remarkable advances of LLM, Information generated by LLM is not completely trustworthy, due to challenges in information quality. Specifically, integrity of Information quality decreases due to unreliable, biased, tokenization during pre-training of LLM. Moreover, due to decreased information quality issues, has led towards hallucination, fabricated information. Unreliable information can lead towards flawed decisions in businesses, which impacts economic activity. In this work, we introduce novel mathematical information quality evaluation of LLM, we furthermore analyze and highlight information quality challenges, scaling laws to systematically scale language models.",
    "path": "papers/24/01/2401.13086.json",
    "total_tokens": 796,
    "translated_title": "向可信赖的语言模型迈进：探究大规模语言模型的信息质量",
    "translated_abstract": "大规模语言模型（LLM）正在迅速生成大量信息，用户越来越依赖和信任这些数据。尽管LLM取得了显著进展，但由于信息质量的挑战，LLM生成的信息并不完全可信。具体而言，LLM在预训练过程中的标记化不可靠、存在偏见，导致信息质量的完整性下降。此外，由于信息质量下降的问题，LLM可能会产生幻觉、捏造信息。不可靠的信息可能导致企业做出错误决策，影响经济活动。在这项工作中，我们引入了LLM的新颖数学信息质量评估方法，进一步分析和突出了信息质量挑战，以系统地扩展语言模型。",
    "tldr": "这项研究探讨了大规模语言模型的信息质量问题，发现标记化不可靠、偏见以及信息质量下降可能导致幻觉、捏造信息，从而对企业决策产生错误影响。"
}