{
    "title": "A Big Data Architecture for Early Identification and Categorization of Dark Web Sites. (arXiv:2401.13320v1 [cs.DC])",
    "abstract": "The dark web has become notorious for its association with illicit activities and there is a growing need for systems to automate the monitoring of this space. This paper proposes an end-to-end scalable architecture for the early identification of new Tor sites and the daily analysis of their content. The solution is built using an Open Source Big Data stack for data serving with Kubernetes, Kafka, Kubeflow, and MinIO, continuously discovering onion addresses in different sources (threat intelligence, code repositories, web-Tor gateways, and Tor repositories), downloading the HTML from Tor and deduplicating the content using MinHash LSH, and categorizing with the BERTopic modeling (SBERT embedding, UMAP dimensionality reduction, HDBSCAN document clustering and c-TF-IDF topic keywords). In 93 days, the system identified 80,049 onion services and characterized 90% of them, addressing the challenge of Tor volatility. A disproportionate amount of repeated content is found, with only 6.1% u",
    "link": "http://arxiv.org/abs/2401.13320",
    "context": "Title: A Big Data Architecture for Early Identification and Categorization of Dark Web Sites. (arXiv:2401.13320v1 [cs.DC])\nAbstract: The dark web has become notorious for its association with illicit activities and there is a growing need for systems to automate the monitoring of this space. This paper proposes an end-to-end scalable architecture for the early identification of new Tor sites and the daily analysis of their content. The solution is built using an Open Source Big Data stack for data serving with Kubernetes, Kafka, Kubeflow, and MinIO, continuously discovering onion addresses in different sources (threat intelligence, code repositories, web-Tor gateways, and Tor repositories), downloading the HTML from Tor and deduplicating the content using MinHash LSH, and categorizing with the BERTopic modeling (SBERT embedding, UMAP dimensionality reduction, HDBSCAN document clustering and c-TF-IDF topic keywords). In 93 days, the system identified 80,049 onion services and characterized 90% of them, addressing the challenge of Tor volatility. A disproportionate amount of repeated content is found, with only 6.1% u",
    "path": "papers/24/01/2401.13320.json",
    "total_tokens": 956,
    "translated_title": "一个用于早期识别和分类暗网站的大数据架构",
    "translated_abstract": "暗网因其与非法活动的关联而臭名昭著，需要系统自动监测这一领域。本文提出了一个端到端可扩展的架构，用于早期识别新的Tor网站和对其内容进行日常分析。该解决方案使用开源的大数据技术栈，包括Kubernetes、Kafka、Kubeflow和MinIO，不断从不同来源（威胁情报、代码仓库、Web-Tor网关和Tor仓库）发现洋葱地址，从Tor下载HTML，并使用MinHash LSH进行内容去重，通过BERTopic建模（SBERT嵌入、UMAP降维、HDBSCAN文档聚类和c-TF-IDF主题关键词）进行分类。在93天内，该系统识别了80,049个洋葱服务，并对其中90%进行了表征，解决了Tor的不稳定性挑战。发现了大量重复内容，仅占6.1%。",
    "tldr": "本文提出了一个用于早期识别和分类暗网站的大数据架构。该架构利用开源技术实现了从多个来源发现洋葱地址、下载HTML并进行内容去重和分类的功能，并成功应对了Tor的不稳定性挑战。在93天内，系统识别了80,049个洋葱服务，并对90%进行了表征。",
    "en_tdlr": "This paper presents a big data architecture for early identification and categorization of dark web sites. The architecture utilizes open source technologies to discover onion addresses from various sources, download HTML, deduplicate content, and perform categorization, effectively addressing the challenge of Tor's volatility. In 93 days, the system identified 80,049 onion services and characterized 90% of them."
}