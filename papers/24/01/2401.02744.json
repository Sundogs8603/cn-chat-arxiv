{
    "title": "MAMI: Multi-Attentional Mutual-Information for Long Sequence Neuron Captioning. (arXiv:2401.02744v1 [cs.AI])",
    "abstract": "Neuron labeling is an approach to visualize the behaviour and respond of a certain neuron to a certain pattern that activates the neuron. Neuron labeling extract information about the features captured by certain neurons in a deep neural network, one of which uses the encoder-decoder image captioning approach. The encoder used can be a pretrained CNN-based model and the decoder is an RNN-based model for text generation. Previous work, namely MILAN (Mutual Information-guided Linguistic Annotation of Neuron), has tried to visualize the neuron behaviour using modified Show, Attend, and Tell (SAT) model in the encoder, and LSTM added with Bahdanau attention in the decoder. MILAN can show great result on short sequence neuron captioning, but it does not show great result on long sequence neuron captioning, so in this work, we would like to improve the performance of MILAN even more by utilizing different kind of attention mechanism and additionally adding several attention result into one, ",
    "link": "http://arxiv.org/abs/2401.02744",
    "context": "Title: MAMI: Multi-Attentional Mutual-Information for Long Sequence Neuron Captioning. (arXiv:2401.02744v1 [cs.AI])\nAbstract: Neuron labeling is an approach to visualize the behaviour and respond of a certain neuron to a certain pattern that activates the neuron. Neuron labeling extract information about the features captured by certain neurons in a deep neural network, one of which uses the encoder-decoder image captioning approach. The encoder used can be a pretrained CNN-based model and the decoder is an RNN-based model for text generation. Previous work, namely MILAN (Mutual Information-guided Linguistic Annotation of Neuron), has tried to visualize the neuron behaviour using modified Show, Attend, and Tell (SAT) model in the encoder, and LSTM added with Bahdanau attention in the decoder. MILAN can show great result on short sequence neuron captioning, but it does not show great result on long sequence neuron captioning, so in this work, we would like to improve the performance of MILAN even more by utilizing different kind of attention mechanism and additionally adding several attention result into one, ",
    "path": "papers/24/01/2401.02744.json",
    "total_tokens": 883,
    "translated_title": "MAMI: 多注意力互信息用于长序列神经元字幕生成",
    "translated_abstract": "神经元标记是一种可视化特定神经元对激活该神经元的模式的行为和反应的方法。神经元标记提取了深度神经网络中某些神经元捕获的特征信息，其中之一使用了编码器-解码器图像字幕生成方法。编码器可以是预训练的基于CNN的模型，解码器是基于RNN的模型用于文本生成。之前的工作，即MILAN（Mutual Information-guided Linguistic Annotation of Neuron），尝试使用修改后的Show, Attend, and Tell（SAT）模型进行神经元行为的可视化，在编码器中使用LSTM与Bahdanau注意力。MILAN在短序列神经元字幕生成方面表现出色，但在长序列神经元字幕生成方面表现不佳，因此在本文中，我们希望通过利用不同类型的注意力机制并额外添加若干注意力结果来进一步提升MILAN的性能。",
    "tldr": "本文提出了MAMI方法，利用多注意力互信息用于长序列神经元字幕生成，并通过不同类型的注意机制和多个注意力结果的汇聚进一步提升了MILAN方法的性能。"
}