{
    "title": "AboutMe: Using Self-Descriptions in Webpages to Document the Effects of English Pretraining Data Filters. (arXiv:2401.06408v1 [cs.CL])",
    "abstract": "Large language models' (LLMs) abilities are drawn from their pretraining data, and model development begins with data curation. However, decisions around what data is retained or removed during this initial stage is under-scrutinized. In our work, we ground web text, which is a popular pretraining data source, to its social and geographic contexts. We create a new dataset of 10.3 million self-descriptions of website creators, and extract information about who they are and where they are from: their topical interests, social roles, and geographic affiliations. Then, we conduct the first study investigating how ten \"quality\" and English language identification (langID) filters affect webpages that vary along these social dimensions. Our experiments illuminate a range of implicit preferences in data curation: we show that some quality classifiers act like topical domain filters, and langID can overlook English content from some regions of the world. Overall, we hope that our work will enc",
    "link": "http://arxiv.org/abs/2401.06408",
    "context": "Title: AboutMe: Using Self-Descriptions in Webpages to Document the Effects of English Pretraining Data Filters. (arXiv:2401.06408v1 [cs.CL])\nAbstract: Large language models' (LLMs) abilities are drawn from their pretraining data, and model development begins with data curation. However, decisions around what data is retained or removed during this initial stage is under-scrutinized. In our work, we ground web text, which is a popular pretraining data source, to its social and geographic contexts. We create a new dataset of 10.3 million self-descriptions of website creators, and extract information about who they are and where they are from: their topical interests, social roles, and geographic affiliations. Then, we conduct the first study investigating how ten \"quality\" and English language identification (langID) filters affect webpages that vary along these social dimensions. Our experiments illuminate a range of implicit preferences in data curation: we show that some quality classifiers act like topical domain filters, and langID can overlook English content from some regions of the world. Overall, we hope that our work will enc",
    "path": "papers/24/01/2401.06408.json",
    "total_tokens": 1061,
    "translated_title": "关于我：使用自我描述的网页来记录英语预训练数据过滤器的影响",
    "translated_abstract": "大型语言模型（LLM）的能力来源于它们的预训练数据，模型的开发始于数据的筛选。然而，在这个初步阶段决定保留哪些数据或移除哪些数据的决策常常没有被充分审查。在我们的工作中，我们将网页文本与其社交和地理背景联系起来。我们创建了一个新的数据集，包含1030万个网页创建者的自我描述，并提取了关于他们的个人信息以及他们来自哪里的信息：他们的兴趣领域、社交角色和地理归属。然后，我们进行了第一项研究，调查了十个“质量”和英语语言识别（langID）过滤器对这些社交维度变化的网页的影响。我们的实验揭示了数据筛选中一系列隐含的偏好：我们展示出一些质量分类器的作用类似于主题领域过滤器，而langID可能会忽视世界某些地区的英语内容。总体而言，我们希望我们的工作能够提供对数据筛选中隐含偏好的洞察，以促进更公正和全面的模型开发。",
    "tldr": "这项研究调查了十个质量和语言识别过滤器对不同社交维度变化的网页的影响。实验发现在数据筛选过程中存在隐含的偏好，一些质量分类器类似于主题过滤器，而语言识别可能会忽视某些地区的英语内容。我们的研究为促进更公正和全面的模型开发提供了洞察。",
    "en_tdlr": "This study investigates the effects of ten quality and language identification filters on webpages that vary along social dimensions. The experiments reveal implicit preferences in data curation, showing that some quality classifiers act as topical domain filters and language identification may overlook English content from certain regions. The insights from our research aim to facilitate fair and comprehensive model development."
}