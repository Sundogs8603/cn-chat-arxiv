{
    "title": "Beyond Reference-Based Metrics: Analyzing Behaviors of Open LLMs on Data-to-Text Generation. (arXiv:2401.10186v1 [cs.CL])",
    "abstract": "We investigate to which extent open large language models (LLMs) can generate coherent and relevant text from structured data. To prevent bias from benchmarks leaked into LLM training data, we collect Quintd-1: an ad-hoc benchmark for five data-to-text (D2T) generation tasks, consisting of structured data records in standard formats gathered from public APIs. We leverage reference-free evaluation metrics and LLMs' in-context learning capabilities, allowing us to test the models with no human-written references. Our evaluation focuses on annotating semantic accuracy errors on token-level, combining human annotators and a metric based on GPT-4. Our systematic examination of the models' behavior across domains and tasks suggests that state-of-the-art open LLMs with 7B parameters can generate fluent and coherent text from various standard data formats in zero-shot settings. However, we also show that semantic accuracy of the outputs remains a major issue: on our benchmark, 80% of outputs o",
    "link": "http://arxiv.org/abs/2401.10186",
    "context": "Title: Beyond Reference-Based Metrics: Analyzing Behaviors of Open LLMs on Data-to-Text Generation. (arXiv:2401.10186v1 [cs.CL])\nAbstract: We investigate to which extent open large language models (LLMs) can generate coherent and relevant text from structured data. To prevent bias from benchmarks leaked into LLM training data, we collect Quintd-1: an ad-hoc benchmark for five data-to-text (D2T) generation tasks, consisting of structured data records in standard formats gathered from public APIs. We leverage reference-free evaluation metrics and LLMs' in-context learning capabilities, allowing us to test the models with no human-written references. Our evaluation focuses on annotating semantic accuracy errors on token-level, combining human annotators and a metric based on GPT-4. Our systematic examination of the models' behavior across domains and tasks suggests that state-of-the-art open LLMs with 7B parameters can generate fluent and coherent text from various standard data formats in zero-shot settings. However, we also show that semantic accuracy of the outputs remains a major issue: on our benchmark, 80% of outputs o",
    "path": "papers/24/01/2401.10186.json",
    "total_tokens": 911,
    "translated_title": "超越基于参考指标：分析开放式LLM在数据到文本生成上的行为",
    "translated_abstract": "我们调查开放式大型语言模型(LLMs)在从结构化数据生成连贯和相关文本方面的程度。为了防止基准泄露到LLM训练数据中的偏差，我们收集了Quintd-1:一个为5个数据到文本(D2T)生成任务设计的专门基准，该任务包括从公共API中收集的标准格式的结构化数据记录。我们利用无参考评估指标和LLMs的上下文学习能力，使我们能够在没有人工写作参考资料的情况下测试模型。我们的评估重点是在token级别上对语义准确性错误进行注释，结合人类标注者和基于GPT-4的指标。我们系统地研究了模型在不同领域和任务中的行为，发现7B参数的最先进开放式LLMs可以在零-shot设置中从各种标准数据格式中生成流畅和连贯的文本。然而，我们也表明输出的语义准确性仍然是一个重大问题：在我们的基准上，80%的输出存在语义准确性错误。",
    "tldr": "开放式大型语言模型在零-shot设置下能够从各种标准数据格式中生成流畅和连贯的文本，但是输出的语义准确性仍然是一个重要问题。"
}