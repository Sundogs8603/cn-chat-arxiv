{
    "title": "Evaluation of General Large Language Models in Contextually Assessing Semantic Concepts Extracted from Adult Critical Care Electronic Health Record Notes. (arXiv:2401.13588v1 [cs.CL])",
    "abstract": "The field of healthcare has increasingly turned its focus towards Large Language Models (LLMs) due to their remarkable performance. However, their performance in actual clinical applications has been underexplored. Traditional evaluations based on question-answering tasks don't fully capture the nuanced contexts. This gap highlights the need for more in-depth and practical assessments of LLMs in real-world healthcare settings. Objective: We sought to evaluate the performance of LLMs in the complex clinical context of adult critical care medicine using systematic and comprehensible analytic methods, including clinician annotation and adjudication. Methods: We investigated the performance of three general LLMs in understanding and processing real-world clinical notes. Concepts from 150 clinical notes were identified by MetaMap and then labeled by 9 clinicians. Each LLM's proficiency was evaluated by identifying the temporality and negation of these concepts using different prompts for an",
    "link": "http://arxiv.org/abs/2401.13588",
    "context": "Title: Evaluation of General Large Language Models in Contextually Assessing Semantic Concepts Extracted from Adult Critical Care Electronic Health Record Notes. (arXiv:2401.13588v1 [cs.CL])\nAbstract: The field of healthcare has increasingly turned its focus towards Large Language Models (LLMs) due to their remarkable performance. However, their performance in actual clinical applications has been underexplored. Traditional evaluations based on question-answering tasks don't fully capture the nuanced contexts. This gap highlights the need for more in-depth and practical assessments of LLMs in real-world healthcare settings. Objective: We sought to evaluate the performance of LLMs in the complex clinical context of adult critical care medicine using systematic and comprehensible analytic methods, including clinician annotation and adjudication. Methods: We investigated the performance of three general LLMs in understanding and processing real-world clinical notes. Concepts from 150 clinical notes were identified by MetaMap and then labeled by 9 clinicians. Each LLM's proficiency was evaluated by identifying the temporality and negation of these concepts using different prompts for an",
    "path": "papers/24/01/2401.13588.json",
    "total_tokens": 833,
    "translated_title": "评估大型语言模型在从成人重症护理电子病历中提取语义概念的背景下的应用",
    "translated_abstract": "鉴于大型语言模型（LLMs）的出色表现，该研究将焦点转向了医疗健康领域。然而，它们在实际临床应用中的表现尚未得到充分探讨。传统的问答任务评估不能完全捕捉到复杂的上下文信息。这种差距凸显了在实际医疗领域中对LLMs进行更深入和实用的评估的需求。该研究旨在使用系统化和易于理解的分析方法，包括临床医生注释和裁定，评估LLMs在成人重症护理医学复杂环境中的表现。",
    "tldr": "在实际医疗领域中对大型语言模型（LLMs）进行更深入和实用的评估是必要的，该研究旨在评估LLMs在成人重症护理医学复杂环境中的表现。",
    "en_tdlr": "It is necessary to evaluate Large Language Models (LLMs) in real-world healthcare settings. This study aims to evaluate the performance of LLMs in the complex clinical context of adult critical care medicine."
}