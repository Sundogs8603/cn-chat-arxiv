{
    "title": "LLMs as On-demand Customizable Service. (arXiv:2401.16577v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable language understanding and generation capabilities. However, training, deploying, and accessing these models pose notable challenges, including resource-intensive demands, extended training durations, and scalability issues. To address these issues, we introduce a concept of hierarchical, distributed LLM architecture that aims at enhancing the accessibility and deployability of LLMs across heterogeneous computing platforms, including general-purpose computers (e.g., laptops) and IoT-style devices (e.g., embedded systems). By introducing a \"layered\" approach, the proposed architecture enables on-demand accessibility to LLMs as a customizable service. This approach also ensures optimal trade-offs between the available computational resources and the user's application needs. We envision that the concept of hierarchical LLM will empower extensive, crowd-sourced user bases to harness the capabilities of LLMs, thereby fostering advan",
    "link": "http://arxiv.org/abs/2401.16577",
    "context": "Title: LLMs as On-demand Customizable Service. (arXiv:2401.16577v1 [cs.CL])\nAbstract: Large Language Models (LLMs) have demonstrated remarkable language understanding and generation capabilities. However, training, deploying, and accessing these models pose notable challenges, including resource-intensive demands, extended training durations, and scalability issues. To address these issues, we introduce a concept of hierarchical, distributed LLM architecture that aims at enhancing the accessibility and deployability of LLMs across heterogeneous computing platforms, including general-purpose computers (e.g., laptops) and IoT-style devices (e.g., embedded systems). By introducing a \"layered\" approach, the proposed architecture enables on-demand accessibility to LLMs as a customizable service. This approach also ensures optimal trade-offs between the available computational resources and the user's application needs. We envision that the concept of hierarchical LLM will empower extensive, crowd-sourced user bases to harness the capabilities of LLMs, thereby fostering advan",
    "path": "papers/24/01/2401.16577.json",
    "total_tokens": 901,
    "translated_title": "LLM作为按需可定制的服务",
    "translated_abstract": "大型语言模型（LLMs）展示了卓越的语言理解和生成能力。然而，训练、部署和访问这些模型都存在显著的挑战，包括资源密集需求、长时间训练和可扩展性问题。为了解决这些问题，我们引入了一个分层、分布式的LLM架构概念，旨在增强LLMs在异构计算平台上的可访问性和可部署性，包括通用计算机（如笔记本电脑）和物联网设备（如嵌入式系统）。通过引入\"分层\"方法，所提出的架构使LLMs可以按需访问，作为可定制的服务。这种方法还可以确保可用计算资源和用户应用需求之间的最佳权衡。我们预见到，分层LLM的概念将赋予广泛的众包用户基础利用LLM的能力，从而促进技术进步。",
    "tldr": "提出了一种分层、分布式的LLM架构概念，通过在通用计算机和物联网设备上提供按需访问的可定制服务，解决了LLMs训练、部署和访问过程中的挑战，并能够实现资源和应用需求的最佳平衡。",
    "en_tdlr": "A hierarchical, distributed LLM architecture has been proposed to address the challenges in training, deploying, and accessing LLMs. By providing on-demand accessibility as a customizable service on general-purpose computers and IoT-style devices, it enables optimal trade-offs between computational resources and application needs, empowering extensive user bases to harness the capabilities of LLMs and fostering technological advancements."
}