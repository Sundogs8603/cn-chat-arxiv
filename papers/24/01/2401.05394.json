{
    "title": "Iterative Regularization with k-Support Norm: an Important Complement to Sparse Recovery. (arXiv:2401.05394v1 [eess.SP])",
    "abstract": "Sparse recovery is ubiquitous in machine learning and signal processing. Due to the NP-hard nature of sparse recovery, existing methods are known to suffer either from restrictive (or even unknown) applicability conditions, or high computational cost. Recently, iterative regularization methods have emerged as a promising fast approach because they can achieve sparse recovery in one pass through early stopping, rather than the tedious grid-search used in the traditional methods. However, most of those iterative methods are based on the $\\ell_1$ norm which requires restrictive applicability conditions and could fail in many cases. Therefore, achieving sparse recovery with iterative regularization methods under a wider range of conditions has yet to be further explored. To address this issue, we propose a novel iterative regularization algorithm, IRKSN, based on the $k$-support norm regularizer rather than the $\\ell_1$ norm. We provide conditions for sparse recovery with IRKSN, and compar",
    "link": "http://arxiv.org/abs/2401.05394",
    "context": "Title: Iterative Regularization with k-Support Norm: an Important Complement to Sparse Recovery. (arXiv:2401.05394v1 [eess.SP])\nAbstract: Sparse recovery is ubiquitous in machine learning and signal processing. Due to the NP-hard nature of sparse recovery, existing methods are known to suffer either from restrictive (or even unknown) applicability conditions, or high computational cost. Recently, iterative regularization methods have emerged as a promising fast approach because they can achieve sparse recovery in one pass through early stopping, rather than the tedious grid-search used in the traditional methods. However, most of those iterative methods are based on the $\\ell_1$ norm which requires restrictive applicability conditions and could fail in many cases. Therefore, achieving sparse recovery with iterative regularization methods under a wider range of conditions has yet to be further explored. To address this issue, we propose a novel iterative regularization algorithm, IRKSN, based on the $k$-support norm regularizer rather than the $\\ell_1$ norm. We provide conditions for sparse recovery with IRKSN, and compar",
    "path": "papers/24/01/2401.05394.json",
    "total_tokens": 915,
    "translated_title": "迭代正则化与k支撑范数：稀疏恢复的重要补充",
    "translated_abstract": "稀疏恢复在机器学习和信号处理中无处不在。由于稀疏恢复的NP困难性质，现有方法通常要么受限于适用条件（甚至未知），要么计算成本高。最近，迭代正则化方法作为一种快速方法出现，因为它们可以通过提前停止一次通过来实现稀疏恢复，而不是传统方法中繁琐的网格搜索。然而，大多数这些迭代方法都基于$\\ell_1$范数，需要受限的适用条件，并且在许多情况下可能会失败。因此，迭代正则化方法在更广泛的条件下实现稀疏恢复仍需进一步探索。为了解决这个问题，我们提出了一种新的迭代正则化算法IRKSN，它基于$k$支撑范数正则化而不是$\\ell_1$范数。我们提供了使用IRKSN进行稀疏恢复的条件，并进行了比较。",
    "tldr": "该论文介绍了一种新的迭代正则化算法IRKSN，它通过使用$k$支撑范数正则化实现稀疏恢复，并提供了条件。这是对基于$\\ell_1$范数的迭代方法的一种重要补充。",
    "en_tdlr": "This paper introduces a new iterative regularization algorithm, IRKSN, which achieves sparse recovery by using the k-support norm regularizer and provides conditions. It is an important complement to iterative methods based on the l1 norm."
}