{
    "title": "Migrating Birds Optimization-Based Feature Selection for Text Classification. (arXiv:2401.10270v1 [cs.NE])",
    "abstract": "This research introduces a novel approach, MBO-NB, that leverages Migrating Birds Optimization (MBO) coupled with Naive Bayes as an internal classifier to address feature selection challenges in text classification having large number of features. Focusing on computational efficiency, we preprocess raw data using the Information Gain algorithm, strategically reducing the feature count from an average of 62221 to 2089. Our experiments demonstrate MBO-NB's superior effectiveness in feature reduction compared to other existing techniques, emphasizing an increased classification accuracy. The successful integration of Naive Bayes within MBO presents a well-rounded solution. In individual comparisons with Particle Swarm Optimization (PSO), MBO-NB consistently outperforms by an average of 6.9% across four setups. This research offers valuable insights into enhancing feature selection methods, providing a scalable and effective solution for text classification",
    "link": "http://arxiv.org/abs/2401.10270",
    "context": "Title: Migrating Birds Optimization-Based Feature Selection for Text Classification. (arXiv:2401.10270v1 [cs.NE])\nAbstract: This research introduces a novel approach, MBO-NB, that leverages Migrating Birds Optimization (MBO) coupled with Naive Bayes as an internal classifier to address feature selection challenges in text classification having large number of features. Focusing on computational efficiency, we preprocess raw data using the Information Gain algorithm, strategically reducing the feature count from an average of 62221 to 2089. Our experiments demonstrate MBO-NB's superior effectiveness in feature reduction compared to other existing techniques, emphasizing an increased classification accuracy. The successful integration of Naive Bayes within MBO presents a well-rounded solution. In individual comparisons with Particle Swarm Optimization (PSO), MBO-NB consistently outperforms by an average of 6.9% across four setups. This research offers valuable insights into enhancing feature selection methods, providing a scalable and effective solution for text classification",
    "path": "papers/24/01/2401.10270.json",
    "total_tokens": 965,
    "translated_title": "基于迁徙鸟优化的文本分类特征选择研究",
    "translated_abstract": "本研究引入了一种新颖的方法，MBO-NB，在处理具有大量特征的文本分类中利用迁徙鸟优化（MBO）与朴素贝叶斯作为内部分类器来解决特征选择挑战。我们通过使用信息增益算法对原始数据进行预处理，从平均62221个特征降低到2089个，以便提高计算效率。实验证明，与其他现有技术相比，MBO-NB在特征减少方面具有效果，并强调了分类准确性的提高。朴素贝叶斯嵌入MBO中的成功整合提供了一个全面的解决方案。在与粒子群优化（PSO）进行个体对比时，MBO-NB在四种设置中平均表现优于6.9％。本研究为增强特征选择方法提供了有价值的见解，为文本分类提供了可扩展和有效的解决方案。",
    "tldr": "本文提出了一种基于迁徙鸟优化的特征选择方法，通过结合朴素贝叶斯作为内部分类器，解决了文本分类中特征选择的挑战。实验结果表明，与其他方法相比，该方法在特征减少和分类准确性方面具有明显优势。研究还提供了有关增强特征选择方法的宝贵见解，为文本分类提供了可扩展和有效的解决方案。"
}