{
    "title": "Decentralized Gossip Mutual Learning (GML) for automatic head and neck tumor segmentation. (arXiv:2401.06180v1 [eess.IV])",
    "abstract": "Federated learning (FL) has emerged as a promising strategy for collaboratively training complicated machine learning models from different medical centers without the need of data sharing. However, the traditional FL relies on a central server to orchestrate the global model training among clients. This makes it vulnerable to the failure of the model server. Meanwhile, the model trained based on the global data property may not yield the best performance on the local data of a particular site due to the variations of data characteristics among them. To address these limitations, we proposed Gossip Mutual Learning(GML), a decentralized collaborative learning framework that employs Gossip Protocol for direct peer-to-peer communication and encourages each site to optimize its local model by leveraging useful information from peers through mutual learning. On the task of tumor segmentation on PET/CT images using HECKTOR21 dataset with 223 cases from five clinical sites, we demonstrated GM",
    "link": "http://arxiv.org/abs/2401.06180",
    "context": "Title: Decentralized Gossip Mutual Learning (GML) for automatic head and neck tumor segmentation. (arXiv:2401.06180v1 [eess.IV])\nAbstract: Federated learning (FL) has emerged as a promising strategy for collaboratively training complicated machine learning models from different medical centers without the need of data sharing. However, the traditional FL relies on a central server to orchestrate the global model training among clients. This makes it vulnerable to the failure of the model server. Meanwhile, the model trained based on the global data property may not yield the best performance on the local data of a particular site due to the variations of data characteristics among them. To address these limitations, we proposed Gossip Mutual Learning(GML), a decentralized collaborative learning framework that employs Gossip Protocol for direct peer-to-peer communication and encourages each site to optimize its local model by leveraging useful information from peers through mutual learning. On the task of tumor segmentation on PET/CT images using HECKTOR21 dataset with 223 cases from five clinical sites, we demonstrated GM",
    "path": "papers/24/01/2401.06180.json",
    "total_tokens": 923,
    "translated_title": "分布式传闻互惠学习（GML）用于头颈肿瘤自动分割",
    "translated_abstract": "联邦学习（FL）已经被证明是一种有前途的策略，可以在不共享数据的情况下，从不同的医疗中心合作训练复杂的机器学习模型。然而，传统的FL依赖于一个中央服务器来协调客户端之间的全局模型训练，这使得它容易受到模型服务器故障的影响。同时，基于全局数据属性训练的模型可能无法在特定站点的本地数据上获得最佳性能，原因是数据特征之间的变化。为了解决这些限制，我们提出了Gossip Mutual Learning（GML），这是一个分散的协作学习框架，它使用传闻协议进行直接的点对点通信，并通过互惠学习从对等方那里利用有用的信息来优化每个站点的本地模型。在使用HECKTOR21数据集的PET/CT图像上的肿瘤分割任务中，我们证明了GML的有效性。",
    "tldr": "GML是一种使用传闻协议进行直接点对点通信的分散协作学习框架，在医疗图像分割任务中取得了较好的效果，避免了传统联邦学习中中心服务器的故障和局部数据特征变化的问题。"
}