{
    "title": "Decoding AI's Nudge: A Unified Framework to Predict Human Behavior in AI-assisted Decision Making. (arXiv:2401.05840v1 [cs.HC])",
    "abstract": "With the rapid development of AI-based decision aids, different forms of AI assistance have been increasingly integrated into the human decision making processes. To best support humans in decision making, it is essential to quantitatively understand how diverse forms of AI assistance influence humans' decision making behavior. To this end, much of the current research focuses on the end-to-end prediction of human behavior using ``black-box'' models, often lacking interpretations of the nuanced ways in which AI assistance impacts the human decision making process. Meanwhile, methods that prioritize the interpretability of human behavior predictions are often tailored for one specific form of AI assistance, making adaptations to other forms of assistance difficult. In this paper, we propose a computational framework that can provide an interpretable characterization of the influence of different forms of AI assistance on decision makers in AI-assisted decision making. By conceptualizing",
    "link": "http://arxiv.org/abs/2401.05840",
    "context": "Title: Decoding AI's Nudge: A Unified Framework to Predict Human Behavior in AI-assisted Decision Making. (arXiv:2401.05840v1 [cs.HC])\nAbstract: With the rapid development of AI-based decision aids, different forms of AI assistance have been increasingly integrated into the human decision making processes. To best support humans in decision making, it is essential to quantitatively understand how diverse forms of AI assistance influence humans' decision making behavior. To this end, much of the current research focuses on the end-to-end prediction of human behavior using ``black-box'' models, often lacking interpretations of the nuanced ways in which AI assistance impacts the human decision making process. Meanwhile, methods that prioritize the interpretability of human behavior predictions are often tailored for one specific form of AI assistance, making adaptations to other forms of assistance difficult. In this paper, we propose a computational framework that can provide an interpretable characterization of the influence of different forms of AI assistance on decision makers in AI-assisted decision making. By conceptualizing",
    "path": "papers/24/01/2401.05840.json",
    "total_tokens": 850,
    "translated_title": "解码AI的助推：预测AI辅助决策中人类行为的统一框架",
    "translated_abstract": "随着基于AI的决策辅助工具的快速发展，不同形式的AI辅助越来越多地融入到人类决策过程中。为了最好地支持人类在决策过程中，必须定量地了解不同形式的AI辅助如何影响人类的决策行为。为此，当前的研究主要集中在使用“黑盒子”模型进行人类行为的端到端预测，常常缺乏对AI辅助对人类决策过程产生微妙影响的解释。与此同时，优先考虑人类行为预测解释性的方法常常只针对某一特定形式的AI辅助进行调整，难以适应其他形式的辅助。在本文中，我们提出了一个计算框架，可以对不同形式的AI辅助对决策者在AI辅助决策中的影响进行解释性描述。",
    "tldr": "本文提出了一个计算框架，可以对不同形式的AI辅助对决策者在AI辅助决策中的影响进行解释性描述。",
    "en_tdlr": "This paper proposes a computational framework that provides an interpretable characterization of the influence of different forms of AI assistance on decision makers in AI-assisted decision making."
}