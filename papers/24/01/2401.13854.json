{
    "title": "Embedding Attack Project (Work Report). (arXiv:2401.13854v1 [cs.LG])",
    "abstract": "This report summarizes all the MIA experiments (Membership Inference Attacks) of the Embedding Attack Project, including threat models, experimental setup, experimental results, findings and discussion. Current results cover the evaluation of two main MIA strategies (loss-based and embedding-based MIAs) on 6 AI models ranging from Computer Vision to Language Modelling. There are two ongoing experiments on MIA defense and neighborhood-comparison embedding attacks. These are ongoing projects.  The current work on MIA and PIA can be summarized into six conclusions: (1) Amount of overfitting is directly proportional to model's vulnerability; (2) early embedding layers in the model are less susceptible to privacy leaks; (3) Deeper model layers contain more membership information; (4) Models are more vulnerable to MIA if both embeddings and corresponding training labels are compromised; (5) it is possible to use pseudo-labels to increase the MIA success; and (6) although MIA and PIA success ",
    "link": "http://arxiv.org/abs/2401.13854",
    "context": "Title: Embedding Attack Project (Work Report). (arXiv:2401.13854v1 [cs.LG])\nAbstract: This report summarizes all the MIA experiments (Membership Inference Attacks) of the Embedding Attack Project, including threat models, experimental setup, experimental results, findings and discussion. Current results cover the evaluation of two main MIA strategies (loss-based and embedding-based MIAs) on 6 AI models ranging from Computer Vision to Language Modelling. There are two ongoing experiments on MIA defense and neighborhood-comparison embedding attacks. These are ongoing projects.  The current work on MIA and PIA can be summarized into six conclusions: (1) Amount of overfitting is directly proportional to model's vulnerability; (2) early embedding layers in the model are less susceptible to privacy leaks; (3) Deeper model layers contain more membership information; (4) Models are more vulnerable to MIA if both embeddings and corresponding training labels are compromised; (5) it is possible to use pseudo-labels to increase the MIA success; and (6) although MIA and PIA success ",
    "path": "papers/24/01/2401.13854.json",
    "total_tokens": 1125,
    "translated_title": "嵌入式攻击项目（工作报告）",
    "translated_abstract": "该报告总结了嵌入式攻击项目的全部MIA实验（成员推断攻击），包括威胁模型、实验设置、实验结果、发现和讨论。目前的结果涵盖了对从计算机视觉到语言建模的6个人工智能模型上评估两种主要MIA策略（基于损失和嵌入的MIA）。关于MIA防御和邻近比较嵌入攻击还有两个正在进行的实验。这些都是正在进行中的项目。目前关于MIA和PIA的工作可以总结为六个结论：（1）过拟合程度与模型的易受攻击性成正比；（2）模型中的早期嵌入层更不容易受到隐私泄漏的影响；（3）更深层的模型层包含更多的成员信息；（4）如果嵌入和对应的训练标签都被泄露，模型对MIA更脆弱；（5）可以使用伪标签来增加MIA的成功率；（6）尽管MIA和PIA的成功率存在差异",
    "tldr": "Embedding Attack Project的工作报告总结了嵌入式攻击项目的MIA实验，发现了以下六个结论：（1）过拟合程度与模型的易受攻击性成正比；（2）模型中的早期嵌入层更不容易受到隐私泄漏的影响；（3）更深层的模型层包含更多的成员信息；（4）如果嵌入和对应的训练标签都被泄露，模型对MIA更脆弱；（5）可以使用伪标签来增加MIA的成功率；（6）尽管MIA和PIA的成功率存在差异",
    "en_tdlr": "The work report of the Embedding Attack Project summarizes the MIA experiments and reveals six conclusions: (1) The level of overfitting is directly proportional to the vulnerability of the model; (2) Early embedding layers in the model are less susceptible to privacy leaks; (3) Deeper model layers contain more membership information; (4) Models are more vulnerable to MIA if both embeddings and corresponding training labels are compromised; (5) It is possible to use pseudo-labels to increase the success rate of MIA; (6) Despite the differences in success rates between MIA and PIA."
}