{
    "title": "Utilizing Neural Transducers for Two-Stage Text-to-Speech via Semantic Token Prediction. (arXiv:2401.01498v1 [eess.AS])",
    "abstract": "We propose a novel text-to-speech (TTS) framework centered around a neural transducer. Our approach divides the whole TTS pipeline into semantic-level sequence-to-sequence (seq2seq) modeling and fine-grained acoustic modeling stages, utilizing discrete semantic tokens obtained from wav2vec2.0 embeddings. For a robust and efficient alignment modeling, we employ a neural transducer named token transducer for the semantic token prediction, benefiting from its hard monotonic alignment constraints. Subsequently, a non-autoregressive (NAR) speech generator efficiently synthesizes waveforms from these semantic tokens. Additionally, a reference speech controls temporal dynamics and acoustic conditions at each stage. This decoupled framework reduces the training complexity of TTS while allowing each stage to focus on semantic and acoustic modeling. Our experimental results on zero-shot adaptive TTS demonstrate that our model surpasses the baseline in terms of speech quality and speaker similari",
    "link": "http://arxiv.org/abs/2401.01498",
    "context": "Title: Utilizing Neural Transducers for Two-Stage Text-to-Speech via Semantic Token Prediction. (arXiv:2401.01498v1 [eess.AS])\nAbstract: We propose a novel text-to-speech (TTS) framework centered around a neural transducer. Our approach divides the whole TTS pipeline into semantic-level sequence-to-sequence (seq2seq) modeling and fine-grained acoustic modeling stages, utilizing discrete semantic tokens obtained from wav2vec2.0 embeddings. For a robust and efficient alignment modeling, we employ a neural transducer named token transducer for the semantic token prediction, benefiting from its hard monotonic alignment constraints. Subsequently, a non-autoregressive (NAR) speech generator efficiently synthesizes waveforms from these semantic tokens. Additionally, a reference speech controls temporal dynamics and acoustic conditions at each stage. This decoupled framework reduces the training complexity of TTS while allowing each stage to focus on semantic and acoustic modeling. Our experimental results on zero-shot adaptive TTS demonstrate that our model surpasses the baseline in terms of speech quality and speaker similari",
    "path": "papers/24/01/2401.01498.json",
    "total_tokens": 972,
    "translated_title": "利用神经转导器进行两阶段文本到语音转换的语义标记预测",
    "translated_abstract": "我们提出了一个新颖的文本到语音（TTS）框架，它以神经转导器为核心。我们的方法将整个TTS流程划分为语义级别的序列到序列(seq2seq)建模和细粒度的声学建模阶段，利用从wav2vec2.0嵌入中获取的离散语义标记。为了实现稳健高效的对齐建模，我们使用了一个名为语义标记转导器的神经转导器来进行语义标记预测，从中获得了硬单调对齐约束的益处。随后，一个非自回归(NAR)语音生成器从这些语义标记有效地合成波形。另外，参考语音在每个阶段控制着时间动态和声学条件。这种解耦的框架减少了TTS的训练复杂性，同时允许每个阶段专注于语义和声学建模。我们在零-shot自适应TTS上的实验结果表明，我们的模型在语音质量和说话者相似度方面超越了基线模型。",
    "tldr": "利用神经转导器实现了一个两阶段的文本到语音转换框架，通过语义标记预测实现了稳健高效的对齐建模，并通过非自回归语音生成器合成语音波形。该框架在语音质量和说话者相似度方面超过了基线模型。",
    "en_tdlr": "A two-stage text-to-speech framework utilizing neural transducers is proposed, which achieves robust alignment modeling through semantic token prediction and synthesizes speech waveforms efficiently using a non-autoregressive speech generator. The framework outperforms the baseline model in terms of speech quality and speaker similarity."
}