{
    "title": "Global-Liar: Factuality of LLMs over Time and Geographic Regions",
    "abstract": "The increasing reliance on AI-driven solutions, particularly Large Language Models (LLMs) like the GPT series, for information retrieval highlights the critical need for their factuality and fairness, especially amidst the rampant spread of misinformation and disinformation online. Our study evaluates the factual accuracy, stability, and biases in widely adopted GPT models, including GPT-3.5 and GPT-4, contributing to reliability and integrity of AI-mediated information dissemination.   We introduce 'Global-Liar,' a dataset uniquely balanced in terms of geographic and temporal representation, facilitating a more nuanced evaluation of LLM biases. Our analysis reveals that newer iterations of GPT models do not always equate to improved performance. Notably, the GPT-4 version from March demonstrates higher factual accuracy than its subsequent June release. Furthermore, a concerning bias is observed, privileging statements from the Global North over the Global South, thus potentially exace",
    "link": "https://arxiv.org/abs/2401.17839",
    "context": "Title: Global-Liar: Factuality of LLMs over Time and Geographic Regions\nAbstract: The increasing reliance on AI-driven solutions, particularly Large Language Models (LLMs) like the GPT series, for information retrieval highlights the critical need for their factuality and fairness, especially amidst the rampant spread of misinformation and disinformation online. Our study evaluates the factual accuracy, stability, and biases in widely adopted GPT models, including GPT-3.5 and GPT-4, contributing to reliability and integrity of AI-mediated information dissemination.   We introduce 'Global-Liar,' a dataset uniquely balanced in terms of geographic and temporal representation, facilitating a more nuanced evaluation of LLM biases. Our analysis reveals that newer iterations of GPT models do not always equate to improved performance. Notably, the GPT-4 version from March demonstrates higher factual accuracy than its subsequent June release. Furthermore, a concerning bias is observed, privileging statements from the Global North over the Global South, thus potentially exace",
    "path": "papers/24/01/2401.17839.json",
    "total_tokens": 966,
    "translated_title": "全球说谎者：LLMs在时间和地理区域上的事实性",
    "translated_abstract": "越来越多地依赖于人工智能驱动的解决方案，特别是像GPT系列这样的大型语言模型（LLMs）在信息检索中的使用，突显了对它们的事实准确性和公正性的重要性，尤其是在网络上虚假信息和误导信息猖獗传播的背景下。我们的研究评估了广泛采用的GPT模型（包括GPT-3.5和GPT-4）的事实准确性、稳定性和偏见，以提高人工智能介导信息传播的可靠性和完整性。我们引入了一个独特平衡的数据集“全球说谎者”，其在地理和时间表征方面有助于更细致地评估LLM的偏见。我们的分析结果表明，较新的GPT模型并不总是意味着性能的提升。值得注意的是，3月发布的GPT-4版本显示出比其后续6月发布版本更高的事实准确性。此外，还观察到一个令人担忧的偏见，即对全球南方的陈述给予了特权，可能加剧了不平等。",
    "tldr": "本论文评估了GPT模型的事实准确性、稳定性和偏见，并引入了一个平衡数据集\"全球说谎者\"，结果显示较新的GPT模型并不总是意味着性能的提升，并且观察到一个全球南方陈述被偏袒的问题。",
    "en_tdlr": "This paper evaluates the factual accuracy, stability, and biases of GPT models, introduces a balanced dataset called \"Global-Liar,\" and reveals that newer GPT models do not always perform better. There is also a bias observed where statements from the Global South are privileged."
}