{
    "title": "A Deep Q-Learning based Smart Scheduling of EVs for Demand Response in Smart Grids. (arXiv:2401.02653v1 [cs.LG])",
    "abstract": "Economic and policy factors are driving the continuous increase in the adoption and usage of electrical vehicles (EVs). However, despite being a cleaner alternative to combustion engine vehicles, EVs have negative impacts on the lifespan of microgrid equipment and energy balance due to increased power demand and the timing of their usage. In our view grid management should leverage on EVs scheduling flexibility to support local network balancing through active participation in demand response programs. In this paper, we propose a model-free solution, leveraging Deep Q-Learning to schedule the charging and discharging activities of EVs within a microgrid to align with a target energy profile provided by the distribution system operator. We adapted the Bellman Equation to assess the value of a state based on specific rewards for EV scheduling actions and used a neural network to estimate Q-values for available actions and the epsilon-greedy algorithm to balance exploitation and explorati",
    "link": "http://arxiv.org/abs/2401.02653",
    "context": "Title: A Deep Q-Learning based Smart Scheduling of EVs for Demand Response in Smart Grids. (arXiv:2401.02653v1 [cs.LG])\nAbstract: Economic and policy factors are driving the continuous increase in the adoption and usage of electrical vehicles (EVs). However, despite being a cleaner alternative to combustion engine vehicles, EVs have negative impacts on the lifespan of microgrid equipment and energy balance due to increased power demand and the timing of their usage. In our view grid management should leverage on EVs scheduling flexibility to support local network balancing through active participation in demand response programs. In this paper, we propose a model-free solution, leveraging Deep Q-Learning to schedule the charging and discharging activities of EVs within a microgrid to align with a target energy profile provided by the distribution system operator. We adapted the Bellman Equation to assess the value of a state based on specific rewards for EV scheduling actions and used a neural network to estimate Q-values for available actions and the epsilon-greedy algorithm to balance exploitation and explorati",
    "path": "papers/24/01/2401.02653.json",
    "total_tokens": 922,
    "translated_title": "EV在智能电网中的需求响应智能调度的基于深度强化学习的研究",
    "translated_abstract": "经济和政策因素推动了电动车(EV)的不断增加和使用。然而，尽管EV是一种比燃油车更清洁的替代品，但由于电力需求增加和使用时间导致的负面影响，EV对微电网设备寿命和能源平衡产生了负面影响。在我们看来，电网管理应该利用EV的调度灵活性，通过积极参与需求响应计划来支持局部网络平衡。在本文中，我们提出了一种基于深度强化学习的无模型解决方案，用于将EV的充电和放电活动调度到微电网中，以与配电系统操作员提供的目标能量配置文件一致。我们改进了Bellman方程，通过特定的奖励评估状态的价值，使用神经网络估计可用动作的Q值，并使用epsilon-greedy算法平衡开发和探索。",
    "tldr": "本研究提出了一种基于深度强化学习的智能调度方法，用于解决电动车在智能电网中的需求响应问题。通过调度电动车的充放电活动，以与配电系统操作员提供的目标能量配置文件一致，可以实现局部网络的平衡和优化。"
}