{
    "title": "MAPLE: Multilingual Evaluation of Parameter Efficient Finetuning of Large Language Models",
    "abstract": "arXiv:2401.07598v2 Announce Type: replace  Abstract: Parameter Efficient Finetuning (PEFT) has emerged as a viable solution for improving the performance of Large Language Models (LLMs) without requiring massive resources and compute. Prior work on multilingual evaluation has shown that there is a large gap between the performance of LLMs on English and other languages. Further, there is also a large gap between the performance of smaller open-source models and larger LLMs. Finetuning can be an effective way to bridge this gap and make language models more equitable. In this work, we finetune the LLama-2-7B and Mistral-7B models on two synthetic multilingual instruction tuning datasets to determine its effect on model performance on six downstream tasks covering forty languages in all. Additionally, we experiment with various parameters, such as rank for low-rank adaptation and values of quantisation to determine their effects on downstream performance and find that higher rank and hig",
    "link": "https://arxiv.org/abs/2401.07598",
    "context": "Title: MAPLE: Multilingual Evaluation of Parameter Efficient Finetuning of Large Language Models\nAbstract: arXiv:2401.07598v2 Announce Type: replace  Abstract: Parameter Efficient Finetuning (PEFT) has emerged as a viable solution for improving the performance of Large Language Models (LLMs) without requiring massive resources and compute. Prior work on multilingual evaluation has shown that there is a large gap between the performance of LLMs on English and other languages. Further, there is also a large gap between the performance of smaller open-source models and larger LLMs. Finetuning can be an effective way to bridge this gap and make language models more equitable. In this work, we finetune the LLama-2-7B and Mistral-7B models on two synthetic multilingual instruction tuning datasets to determine its effect on model performance on six downstream tasks covering forty languages in all. Additionally, we experiment with various parameters, such as rank for low-rank adaptation and values of quantisation to determine their effects on downstream performance and find that higher rank and hig",
    "path": "papers/24/01/2401.07598.json",
    "total_tokens": 757,
    "translated_title": "MAPLE: 多语言参数高效微调大型语言模型的评估",
    "translated_abstract": "Parameter Efficient Finetuning (PEFT)已经成为改善大型语言模型（LLMs）性能的可行解决方案，而无需大量资源和计算。本文在两个合成多语言指令调整数据集上微调LLama-2-7B和Mistral-7B模型，以确定其对六个涵盖四十种语言的下游任务上模型性能的影响。此外，我们尝试不同的参数，例如用于低秩适应的秩和量化值，以确定它们对下游性能的影响，发现更高的秩和更高的hig",
    "tldr": "MAPLE通过在两个多语言指令调整数据集上对LLama-2-7B和Mistral-7B模型进行微调，在六项涵盖40种语言的下游任务中发现了微调对模型性能的影响。",
    "en_tdlr": "MAPLE investigates the impact of finetuning LLama-2-7B and Mistral-7B models on two synthetic multilingual instruction tuning datasets across six downstream tasks covering forty languages."
}