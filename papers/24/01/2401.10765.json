{
    "title": "Starlit: Privacy-Preserving Federated Learning to Enhance Financial Fraud Detection. (arXiv:2401.10765v1 [cs.LG])",
    "abstract": "Federated Learning (FL) is a data-minimization approach enabling collaborative model training across diverse clients with local data, avoiding direct data exchange. However, state-of-the-art FL solutions to identify fraudulent financial transactions exhibit a subset of the following limitations. They (1) lack a formal security definition and proof, (2) assume prior freezing of suspicious customers' accounts by financial institutions (limiting the solutions' adoption), (3) scale poorly, involving either $O(n^2)$ computationally expensive modular exponentiation (where $n$ is the total number of financial institutions) or highly inefficient fully homomorphic encryption, (4) assume the parties have already completed the identity alignment phase, hence excluding it from the implementation, performance evaluation, and security analysis, and (5) struggle to resist clients' dropouts. This work introduces Starlit, a novel scalable privacy-preserving FL mechanism that overcomes these limitations",
    "link": "http://arxiv.org/abs/2401.10765",
    "context": "Title: Starlit: Privacy-Preserving Federated Learning to Enhance Financial Fraud Detection. (arXiv:2401.10765v1 [cs.LG])\nAbstract: Federated Learning (FL) is a data-minimization approach enabling collaborative model training across diverse clients with local data, avoiding direct data exchange. However, state-of-the-art FL solutions to identify fraudulent financial transactions exhibit a subset of the following limitations. They (1) lack a formal security definition and proof, (2) assume prior freezing of suspicious customers' accounts by financial institutions (limiting the solutions' adoption), (3) scale poorly, involving either $O(n^2)$ computationally expensive modular exponentiation (where $n$ is the total number of financial institutions) or highly inefficient fully homomorphic encryption, (4) assume the parties have already completed the identity alignment phase, hence excluding it from the implementation, performance evaluation, and security analysis, and (5) struggle to resist clients' dropouts. This work introduces Starlit, a novel scalable privacy-preserving FL mechanism that overcomes these limitations",
    "path": "papers/24/01/2401.10765.json",
    "total_tokens": 943,
    "translated_title": "Starlit: 隐私保护的联邦学习以增强金融欺诈检测",
    "translated_abstract": "联邦学习（FL）是一种数据最小化方法，能够在具有本地数据的各个客户端之间进行协作模型训练，避免直接数据交换。然而，用于识别欺诈金融交易的最新FL解决方案存在以下一些限制：缺乏正式的安全定义和证明，假定金融机构事先冻结可疑客户的账户（限制了解决方案的采用），规模不断扩大，涉及$O(n^2)$的计算昂贵的模块指数运算（其中$n$是金融机构的总数）或者高效率低的完全同态加密，假设各方已经完成了身份对齐阶段，因此将其排除在实施、性能评估和安全分析之外，并且难以抵抗客户端的退出。本文引入了一种新颖的可扩展隐私保护FL机制——Starlit，克服了这些限制。",
    "tldr": "Starlit是一个新的可扩展隐私保护的联邦学习机制，解决了对于金融欺诈检测中的几个限制，包括缺乏正式的安全定义和证明、假定冻结账户、规模扩大、身份对齐阶段和难以抵抗客户端退出。",
    "en_tdlr": "Starlit is a novel scalable privacy-preserving federated learning mechanism that overcomes several limitations in financial fraud detection, including the lack of a formal security definition and proof, assuming account freezing, scalability issues, exclusion of the identity alignment phase, and resistance to client dropouts."
}