{
    "title": "Pixel to Elevation: Learning to Predict Elevation Maps at Long Range using Images for Autonomous Offroad Navigation",
    "abstract": "Understanding terrain topology at long-range is crucial for the success of off-road robotic missions, especially when navigating at high-speeds. LiDAR sensors, which are currently heavily relied upon for geometric mapping, provide sparse measurements when mapping at greater distances. To address this challenge, we present a novel learning-based approach capable of predicting terrain elevation maps at long-range using only onboard egocentric images in real-time. Our proposed method is comprised of three main elements. First, a transformer-based encoder is introduced that learns cross-view associations between the egocentric views and prior bird-eye-view elevation map predictions. Second, an orientation-aware positional encoding is proposed to incorporate the 3D vehicle pose information over complex unstructured terrain with multi-view visual image features. Lastly, a history-augmented learn-able map embedding is proposed to achieve better temporal consistency between elevation map predi",
    "link": "https://arxiv.org/abs/2401.17484",
    "context": "Title: Pixel to Elevation: Learning to Predict Elevation Maps at Long Range using Images for Autonomous Offroad Navigation\nAbstract: Understanding terrain topology at long-range is crucial for the success of off-road robotic missions, especially when navigating at high-speeds. LiDAR sensors, which are currently heavily relied upon for geometric mapping, provide sparse measurements when mapping at greater distances. To address this challenge, we present a novel learning-based approach capable of predicting terrain elevation maps at long-range using only onboard egocentric images in real-time. Our proposed method is comprised of three main elements. First, a transformer-based encoder is introduced that learns cross-view associations between the egocentric views and prior bird-eye-view elevation map predictions. Second, an orientation-aware positional encoding is proposed to incorporate the 3D vehicle pose information over complex unstructured terrain with multi-view visual image features. Lastly, a history-augmented learn-able map embedding is proposed to achieve better temporal consistency between elevation map predi",
    "path": "papers/24/01/2401.17484.json",
    "total_tokens": 1017,
    "translated_title": "像素到高程：使用图像学习预测自主越野导航中的长距离高程地图",
    "translated_abstract": "在离线机器人任务中，长距离理解地形拓扑对于成功至关重要，特别是在高速导航时。目前，几何映射主要依赖于LiDAR传感器，但在更远距离的映射时提供的测量数较少。为了解决这个挑战，我们提出了一种新颖的基于学习的方法，能够仅使用实时车载视角图像预测长距离地形高程地图。我们的方法由三个主要元素组成。首先，引入了一个基于transformer的编码器，该编码器学习车载视角图像与先前的鸟瞰图高程地图预测之间的跨视图关联。其次，提出了一种方向感知的位置编码，将3D车辆姿态信息与多视角视觉图像特征相结合，用于处理复杂的非结构化地形。最后，提出了一种历史增强的可学习地图嵌入，以实现高程地图预测之间的更好时序一致性。",
    "tldr": "本研究提出了一种学习方法，可以通过车载视角图像实时预测长距离地形高程地图。该方法包括transformer-based编码器、方向感知的位置编码和历史增强的可学习地图嵌入。通过学习视角图像与鸟瞰图高程地图之间的关联，结合车辆姿态信息和视觉图像特征，实现更好的地图预测时序一致性。",
    "en_tdlr": "This study proposes a learning-based approach to predict long-range terrain elevation maps in real-time using onboard egocentric images. The approach includes a transformer-based encoder, an orientation-aware positional encoding, and a history-augmented learnable map embedding. By learning the associations between egocentric views and bird-eye-view elevation map predictions, integrating vehicle pose information and visual image features, it achieves better temporal consistency in map predictions."
}