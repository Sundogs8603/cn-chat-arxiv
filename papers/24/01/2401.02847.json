{
    "title": "Generating Non-Stationary Textures using Self-Rectification. (arXiv:2401.02847v1 [cs.CV])",
    "abstract": "This paper addresses the challenge of example-based non-stationary texture synthesis. We introduce a novel twostep approach wherein users first modify a reference texture using standard image editing tools, yielding an initial rough target for the synthesis. Subsequently, our proposed method, termed \"self-rectification\", automatically refines this target into a coherent, seamless texture, while faithfully preserving the distinct visual characteristics of the reference exemplar. Our method leverages a pre-trained diffusion network, and uses self-attention mechanisms, to gradually align the synthesized texture with the reference, ensuring the retention of the structures in the provided target. Through experimental validation, our approach exhibits exceptional proficiency in handling non-stationary textures, demonstrating significant advancements in texture synthesis when compared to existing state-of-the-art techniques. Code is available at https://github.com/xiaorongjun000/Self-Rectific",
    "link": "http://arxiv.org/abs/2401.02847",
    "context": "Title: Generating Non-Stationary Textures using Self-Rectification. (arXiv:2401.02847v1 [cs.CV])\nAbstract: This paper addresses the challenge of example-based non-stationary texture synthesis. We introduce a novel twostep approach wherein users first modify a reference texture using standard image editing tools, yielding an initial rough target for the synthesis. Subsequently, our proposed method, termed \"self-rectification\", automatically refines this target into a coherent, seamless texture, while faithfully preserving the distinct visual characteristics of the reference exemplar. Our method leverages a pre-trained diffusion network, and uses self-attention mechanisms, to gradually align the synthesized texture with the reference, ensuring the retention of the structures in the provided target. Through experimental validation, our approach exhibits exceptional proficiency in handling non-stationary textures, demonstrating significant advancements in texture synthesis when compared to existing state-of-the-art techniques. Code is available at https://github.com/xiaorongjun000/Self-Rectific",
    "path": "papers/24/01/2401.02847.json",
    "total_tokens": 946,
    "translated_title": "使用自校正生成非平稳纹理",
    "translated_abstract": "本文解决了基于示例的非平稳纹理合成的挑战。我们提出了一种新的两步方法，用户可以使用标准图像编辑工具修改参考纹理，得到合成的初始目标。随后，我们提出的方法“自校正”自动将这个目标细化为一种连贯、无缝的纹理，同时忠实地保留了参考样本的独特视觉特征。我们的方法利用预训练扩散网络，并使用自注意机制，逐渐将合成纹理与参考对齐，确保保留所提供目标中的结构。通过实验证实，我们的方法在处理非平稳纹理方面表现出卓越的能力，相比现有的最先进技术，在纹理合成方面取得了显著的进展。代码可在https://github.com/xiaorongjun000/Self-Rectific下载。",
    "tldr": "本文提出了一种使用自校正来生成非平稳纹理的方法，通过使用预训练扩散网络和自注意机制，可以将用户修改的参考纹理细化为一种连贯、无缝的纹理，并保留参考样本的独特视觉特征。实验证实表明，该方法在处理非平稳纹理方面具有卓越的能力，相比现有技术在纹理合成方面取得了显著的进展。"
}