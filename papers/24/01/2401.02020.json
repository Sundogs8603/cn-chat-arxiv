{
    "title": "Spikformer V2: Join the High Accuracy Club on ImageNet with an SNN Ticket. (arXiv:2401.02020v1 [cs.NE])",
    "abstract": "Spiking Neural Networks (SNNs), known for their biologically plausible architecture, face the challenge of limited performance. The self-attention mechanism, which is the cornerstone of the high-performance Transformer and also a biologically inspired structure, is absent in existing SNNs. To this end, we explore the potential of leveraging both self-attention capability and biological properties of SNNs, and propose a novel Spiking Self-Attention (SSA) and Spiking Transformer (Spikformer). The SSA mechanism eliminates the need for softmax and captures the sparse visual feature employing spike-based Query, Key, and Value. This sparse computation without multiplication makes SSA efficient and energy-saving. Further, we develop a Spiking Convolutional Stem (SCS) with supplementary convolutional layers to enhance the architecture of Spikformer. The Spikformer enhanced with the SCS is referred to as Spikformer V2. To train larger and deeper Spikformer V2, we introduce a pioneering explorat",
    "link": "http://arxiv.org/abs/2401.02020",
    "context": "Title: Spikformer V2: Join the High Accuracy Club on ImageNet with an SNN Ticket. (arXiv:2401.02020v1 [cs.NE])\nAbstract: Spiking Neural Networks (SNNs), known for their biologically plausible architecture, face the challenge of limited performance. The self-attention mechanism, which is the cornerstone of the high-performance Transformer and also a biologically inspired structure, is absent in existing SNNs. To this end, we explore the potential of leveraging both self-attention capability and biological properties of SNNs, and propose a novel Spiking Self-Attention (SSA) and Spiking Transformer (Spikformer). The SSA mechanism eliminates the need for softmax and captures the sparse visual feature employing spike-based Query, Key, and Value. This sparse computation without multiplication makes SSA efficient and energy-saving. Further, we develop a Spiking Convolutional Stem (SCS) with supplementary convolutional layers to enhance the architecture of Spikformer. The Spikformer enhanced with the SCS is referred to as Spikformer V2. To train larger and deeper Spikformer V2, we introduce a pioneering explorat",
    "path": "papers/24/01/2401.02020.json",
    "total_tokens": 898,
    "translated_title": "Spikformer V2：通过SNN Ticket在ImageNet上实现高准确度",
    "translated_abstract": "脉冲神经网络（SNNs）因其生物学合理的结构而闻名，但其性能受到限制。基于生物启发结构的高性能Transformer中的自注意机制在现有的SNNs中缺失。为此，我们探索了利用自注意能力和SNNs的生物特性的潜力，并提出了一种新颖的脉冲自注意（SSA）和脉冲Transformer（Spikformer）。SSA机制消除了对softmax的需求，并利用基于脉冲的查询、键和值捕获稀疏的视觉特征。这种无乘法的稀疏计算使得SSA高效且节能。此外，我们还开发了一种脉冲卷积干细胞（SCS）和补充卷积层来增强Spikformer的架构。加上SCS的Spikformer被称为Spikformer V2。为了训练更大更深的Spikformer V2，我们引入了一种开创性的探+",
    "tldr": "Spikformer V2是一种基于SNNs和自注意机制的脉冲神经网络，通过提出脉冲自注意机制和脉冲Transformer来实现高准确度的图像识别。",
    "en_tdlr": "Spikformer V2 is a spiking neural network based on SNNs and self-attention mechanism, which achieves high accuracy in image recognition by introducing spiking self-attention and spiking Transformer."
}