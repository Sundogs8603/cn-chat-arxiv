{
    "title": "End-to-End Anti-Backdoor Learning on Images and Time Series. (arXiv:2401.03215v1 [cs.LG])",
    "abstract": "Backdoor attacks present a substantial security concern for deep learning models, especially those utilized in applications critical to safety and security. These attacks manipulate model behavior by embedding a hidden trigger during the training phase, allowing unauthorized control over the model's output during inference time. Although numerous defenses exist for image classification models, there is a conspicuous absence of defenses tailored for time series data, as well as an end-to-end solution capable of training clean models on poisoned data. To address this gap, this paper builds upon Anti-Backdoor Learning (ABL) and introduces an innovative method, End-to-End Anti-Backdoor Learning (E2ABL), for robust training against backdoor attacks. Unlike the original ABL, which employs a two-stage training procedure, E2ABL accomplishes end-to-end training through an additional classification head linked to the shallow layers of a Deep Neural Network (DNN). This secondary head actively ide",
    "link": "http://arxiv.org/abs/2401.03215",
    "context": "Title: End-to-End Anti-Backdoor Learning on Images and Time Series. (arXiv:2401.03215v1 [cs.LG])\nAbstract: Backdoor attacks present a substantial security concern for deep learning models, especially those utilized in applications critical to safety and security. These attacks manipulate model behavior by embedding a hidden trigger during the training phase, allowing unauthorized control over the model's output during inference time. Although numerous defenses exist for image classification models, there is a conspicuous absence of defenses tailored for time series data, as well as an end-to-end solution capable of training clean models on poisoned data. To address this gap, this paper builds upon Anti-Backdoor Learning (ABL) and introduces an innovative method, End-to-End Anti-Backdoor Learning (E2ABL), for robust training against backdoor attacks. Unlike the original ABL, which employs a two-stage training procedure, E2ABL accomplishes end-to-end training through an additional classification head linked to the shallow layers of a Deep Neural Network (DNN). This secondary head actively ide",
    "path": "papers/24/01/2401.03215.json",
    "total_tokens": 1053,
    "translated_title": "图像和时间序列的端到端反后门学习",
    "translated_abstract": "后门攻击对深度学习模型构成了重大的安全威胁，尤其是那些用于安全和保密的关键应用程序中。这些攻击通过在训练阶段嵌入隐藏触发器来操纵模型的行为，在推断时允许对模型的输出进行未经授权的控制。尽管存在大量面向图像分类模型的防御策略，但鲜有针对时间序列数据的防御解决方案，也没有能够在受污染数据上进行干净模型训练的端到端解决方案。为了填补这一空白，本文在反后门学习（ABL）的基础上，引入了一种创新方法——端到端反后门学习（E2ABL），用于对抗后门攻击的鲁棒训练。与原始的ABL不同，E2ABL通过与深度神经网络（DNN）的浅层连接的附加分类头实现端到端训练。这个辅助头积极地探索深层特征空间中的干净样本和污染样本之间的边界。",
    "tldr": "本文提出了一种名为端到端反后门学习（E2ABL）的方法，该方法可以在图像和时间序列数据上进行鲁棒训练以对抗后门攻击。与传统的反后门学习（ABL）方法不同，E2ABL通过额外的分类头在深度神经网络（DNN）的浅层进行端到端训练，并有效地鉴别深层特征空间中干净样本和污染样本之间的边界。",
    "en_tdlr": "This paper proposes an innovative method called End-to-End Anti-Backdoor Learning (E2ABL) for robust training against backdoor attacks on both image and time series data. Unlike traditional Anti-Backdoor Learning (ABL) methods, E2ABL achieves end-to-end training through an additional classification head connected to the shallow layers of a Deep Neural Network (DNN), effectively identifying the boundary between clean and poisoned samples in the deep feature space."
}