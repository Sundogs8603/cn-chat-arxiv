{
    "title": "Revisiting Gradient Pruning: A Dual Realization for Defending against Gradient Attacks. (arXiv:2401.16687v1 [cs.CR])",
    "abstract": "Collaborative learning (CL) is a distributed learning framework that aims to protect user privacy by allowing users to jointly train a model by sharing their gradient updates only. However, gradient inversion attacks (GIAs), which recover users' training data from shared gradients, impose severe privacy threats to CL. Existing defense methods adopt different techniques, e.g., differential privacy, cryptography, and perturbation defenses, to defend against the GIAs. Nevertheless, all current defense methods suffer from a poor trade-off between privacy, utility, and efficiency. To mitigate the weaknesses of existing solutions, we propose a novel defense method, Dual Gradient Pruning (DGP), based on gradient pruning, which can improve communication efficiency while preserving the utility and privacy of CL. Specifically, DGP slightly changes gradient pruning with a stronger privacy guarantee. And DGP can also significantly improve communication efficiency with a theoretical analysis of its",
    "link": "http://arxiv.org/abs/2401.16687",
    "context": "Title: Revisiting Gradient Pruning: A Dual Realization for Defending against Gradient Attacks. (arXiv:2401.16687v1 [cs.CR])\nAbstract: Collaborative learning (CL) is a distributed learning framework that aims to protect user privacy by allowing users to jointly train a model by sharing their gradient updates only. However, gradient inversion attacks (GIAs), which recover users' training data from shared gradients, impose severe privacy threats to CL. Existing defense methods adopt different techniques, e.g., differential privacy, cryptography, and perturbation defenses, to defend against the GIAs. Nevertheless, all current defense methods suffer from a poor trade-off between privacy, utility, and efficiency. To mitigate the weaknesses of existing solutions, we propose a novel defense method, Dual Gradient Pruning (DGP), based on gradient pruning, which can improve communication efficiency while preserving the utility and privacy of CL. Specifically, DGP slightly changes gradient pruning with a stronger privacy guarantee. And DGP can also significantly improve communication efficiency with a theoretical analysis of its",
    "path": "papers/24/01/2401.16687.json",
    "total_tokens": 899,
    "translated_title": "重新审视梯度剪枝：一种用于抵御梯度攻击的双重实现",
    "translated_abstract": "协作学习是一种分布式学习框架，通过共享梯度更新训练模型，旨在保护用户隐私。然而，梯度反演攻击可以从共享的梯度中恢复用户的训练数据，对协作学习构成严重的隐私威胁。现有的防御方法采用不同的技术，如差分隐私、密码学和扰动防御，以抵御梯度反演攻击。然而，所有的现有防御方法在隐私、效用和效率之间存在较差的平衡。为了缓解现有解决方案的弱点，我们提出了一种新颖的防御方法，即双重梯度剪枝（DGP），基于梯度剪枝，它可以提高通信效率同时保持协作学习的效用和隐私。具体而言，DGP稍微改变了梯度剪枝，并提供了更强的隐私保证。同时，DGP还可以通过理论分析显著提高通信效率。",
    "tldr": "提出了一种基于梯度剪枝的防御方法，双重梯度剪枝（DGP），可以提高协作学习的通信效率同时保护隐私。",
    "en_tdlr": "A novel defense method called Dual Gradient Pruning (DGP), based on gradient pruning, is proposed to improve the communication efficiency and preserve privacy in collaborative learning."
}