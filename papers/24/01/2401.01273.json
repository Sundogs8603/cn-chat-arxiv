{
    "title": "Learning-based agricultural management in partially observable environments subject to climate variability. (arXiv:2401.01273v1 [cs.LG])",
    "abstract": "Agricultural management, with a particular focus on fertilization strategies, holds a central role in shaping crop yield, economic profitability, and environmental sustainability. While conventional guidelines offer valuable insights, their efficacy diminishes when confronted with extreme weather conditions, such as heatwaves and droughts. In this study, we introduce an innovative framework that integrates Deep Reinforcement Learning (DRL) with Recurrent Neural Networks (RNNs). Leveraging the Gym-DSSAT simulator, we train an intelligent agent to master optimal nitrogen fertilization management. Through a series of simulation experiments conducted on corn crops in Iowa, we compare Partially Observable Markov Decision Process (POMDP) models with Markov Decision Process (MDP) models. Our research underscores the advantages of utilizing sequential observations in developing more efficient nitrogen input policies. Additionally, we explore the impact of climate variability, particularly duri",
    "link": "http://arxiv.org/abs/2401.01273",
    "context": "Title: Learning-based agricultural management in partially observable environments subject to climate variability. (arXiv:2401.01273v1 [cs.LG])\nAbstract: Agricultural management, with a particular focus on fertilization strategies, holds a central role in shaping crop yield, economic profitability, and environmental sustainability. While conventional guidelines offer valuable insights, their efficacy diminishes when confronted with extreme weather conditions, such as heatwaves and droughts. In this study, we introduce an innovative framework that integrates Deep Reinforcement Learning (DRL) with Recurrent Neural Networks (RNNs). Leveraging the Gym-DSSAT simulator, we train an intelligent agent to master optimal nitrogen fertilization management. Through a series of simulation experiments conducted on corn crops in Iowa, we compare Partially Observable Markov Decision Process (POMDP) models with Markov Decision Process (MDP) models. Our research underscores the advantages of utilizing sequential observations in developing more efficient nitrogen input policies. Additionally, we explore the impact of climate variability, particularly duri",
    "path": "papers/24/01/2401.01273.json",
    "total_tokens": 983,
    "translated_title": "学习基于环境气候变异的部分可观测农业管理",
    "translated_abstract": "农业管理在塑造作物产量、经济可盈利性和环境可持续性方面扮演着重要角色，特别关注施肥策略。然而，当面对极端天气条件（如热浪和干旱）时，传统指导方针的有效性减弱。本研究引入了一种创新框架，将深度强化学习（DRL）与循环神经网络（RNNs）相结合。利用Gym-DSSAT模拟器，我们训练了一个智能agent来掌握最佳氮肥管理。通过在爱荷华州玉米农作物上进行一系列模拟实验，我们比较了部分可观测马尔科夫决策过程（POMDP）模型和马尔科夫决策过程（MDP）模型。我们的研究强调了利用序列观测来开发更高效的氮肥输入策略的优势。此外，我们还探讨了气候的变异性对农业管理的影响。",
    "tldr": "本研究引入了一种将深度强化学习与循环神经网络相结合的创新框架，利用Gym-DSSAT模拟器训练智能agent来掌握最佳氮肥管理策略。研究强调了利用序列观测开发更高效氮肥输入策略的优势，并探讨了气候变异对农业管理的影响。",
    "en_tdlr": "This study introduces an innovative framework that combines deep reinforcement learning with recurrent neural networks to train an intelligent agent for optimal nitrogen fertilization management. It emphasizes the advantages of utilizing sequential observations to develop more efficient nitrogen input policies and explores the impact of climate variability on agricultural management."
}