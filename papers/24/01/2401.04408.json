{
    "title": "Fine-Grained Embedding Dimension Optimization During Training for Recommender Systems. (arXiv:2401.04408v1 [cs.IR])",
    "abstract": "Huge embedding tables in modern Deep Learning Recommender Models (DLRM) require prohibitively large memory during training and inference. Aiming to reduce the memory footprint of training, this paper proposes FIne-grained In-Training Embedding Dimension optimization (FIITED). Given the observation that embedding vectors are not equally important, FIITED adjusts the dimension of each individual embedding vector continuously during training, assigning longer dimensions to more important embeddings while adapting to dynamic changes in data. A novel embedding storage system based on virtually-hashed physically-indexed hash tables is designed to efficiently implement the embedding dimension adjustment and effectively enable memory saving. Experiments on two industry models show that FIITED is able to reduce the size of embeddings by more than 65% while maintaining the trained model's quality, saving significantly more memory than a state-of-the-art in-training embedding pruning method. On p",
    "link": "http://arxiv.org/abs/2401.04408",
    "context": "Title: Fine-Grained Embedding Dimension Optimization During Training for Recommender Systems. (arXiv:2401.04408v1 [cs.IR])\nAbstract: Huge embedding tables in modern Deep Learning Recommender Models (DLRM) require prohibitively large memory during training and inference. Aiming to reduce the memory footprint of training, this paper proposes FIne-grained In-Training Embedding Dimension optimization (FIITED). Given the observation that embedding vectors are not equally important, FIITED adjusts the dimension of each individual embedding vector continuously during training, assigning longer dimensions to more important embeddings while adapting to dynamic changes in data. A novel embedding storage system based on virtually-hashed physically-indexed hash tables is designed to efficiently implement the embedding dimension adjustment and effectively enable memory saving. Experiments on two industry models show that FIITED is able to reduce the size of embeddings by more than 65% while maintaining the trained model's quality, saving significantly more memory than a state-of-the-art in-training embedding pruning method. On p",
    "path": "papers/24/01/2401.04408.json",
    "total_tokens": 939,
    "translated_title": "在推荐系统的训练过程中优化细粒度嵌入维度",
    "translated_abstract": "现代深度学习推荐模型中的大型嵌入表在训练和推断过程中需要过大的内存。为了减小训练时的内存占用，本文提出了一种细粒度嵌入维度优化方法 (FIITED)。根据嵌入向量的重要性不同，FIITED在训练过程中连续调整每个嵌入向量的维度，将更重要的嵌入向量分配更长的维度，并能够适应数据的动态变化。同时，本文设计了一种基于虚拟哈希的物理索引哈希表的嵌入存储系统，以实现嵌入维度的调整并有效地节省内存。对两个行业模型的实验表明，FIITED能够将嵌入的大小减小超过65%，同时保持训练模型的质量，比现有的一种在训练过程中进行嵌入修剪的方法节省更多内存。",
    "tldr": "本文提出了一种细粒度嵌入维度优化方法（FIITED），能够在推荐系统的训练过程中根据嵌入向量的重要性不断调整其维度，并设计了一种虚拟哈希索引哈希表的嵌入存储系统以有效节省内存。",
    "en_tdlr": "This paper proposes a fine-grained embedding dimension optimization method (FIITED) that continuously adjusts the dimension of each embedding vector based on its importance in the training process of recommender systems. It also designs a virtual-hashed physically-indexed hash table-based embedding storage system to efficiently save memory. Experimental results show that FIITED can significantly reduce the size of embeddings while maintaining the quality of the trained model."
}