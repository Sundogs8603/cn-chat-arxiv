{
    "title": "Cross-Speaker Encoding Network for Multi-Talker Speech Recognition. (arXiv:2401.04152v1 [cs.SD])",
    "abstract": "End-to-end multi-talker speech recognition has garnered great interest as an effective approach to directly transcribe overlapped speech from multiple speakers. Current methods typically adopt either 1) single-input multiple-output (SIMO) models with a branched encoder, or 2) single-input single-output (SISO) models based on attention-based encoder-decoder architecture with serialized output training (SOT). In this work, we propose a Cross-Speaker Encoding (CSE) network to address the limitations of SIMO models by aggregating cross-speaker representations. Furthermore, the CSE model is integrated with SOT to leverage both the advantages of SIMO and SISO while mitigating their drawbacks. To the best of our knowledge, this work represents an early effort to integrate SIMO and SISO for multi-talker speech recognition. Experiments on the two-speaker LibrispeechMix dataset show that the CES model reduces word error rate (WER) by 8% over the SIMO baseline. The CSE-SOT model reduces WER by 10",
    "link": "http://arxiv.org/abs/2401.04152",
    "context": "Title: Cross-Speaker Encoding Network for Multi-Talker Speech Recognition. (arXiv:2401.04152v1 [cs.SD])\nAbstract: End-to-end multi-talker speech recognition has garnered great interest as an effective approach to directly transcribe overlapped speech from multiple speakers. Current methods typically adopt either 1) single-input multiple-output (SIMO) models with a branched encoder, or 2) single-input single-output (SISO) models based on attention-based encoder-decoder architecture with serialized output training (SOT). In this work, we propose a Cross-Speaker Encoding (CSE) network to address the limitations of SIMO models by aggregating cross-speaker representations. Furthermore, the CSE model is integrated with SOT to leverage both the advantages of SIMO and SISO while mitigating their drawbacks. To the best of our knowledge, this work represents an early effort to integrate SIMO and SISO for multi-talker speech recognition. Experiments on the two-speaker LibrispeechMix dataset show that the CES model reduces word error rate (WER) by 8% over the SIMO baseline. The CSE-SOT model reduces WER by 10",
    "path": "papers/24/01/2401.04152.json",
    "total_tokens": 989,
    "translated_title": "跨说话人编码网络用于多说话人语音识别",
    "translated_abstract": "端到端的多说话人语音识别已经引起了极大的兴趣，作为一种直接转录多个说话人重叠语音的有效方法。目前的方法通常采用1）带有分支编码器的单输入多输出（SIMO）模型，或者2）基于注意力机制的编码器-解码器架构和序列化输出训练（SOT）的单输入单输出（SISO）模型。在这项工作中，我们提出了一种叫做Cross-Speaker Encoding（CSE）的网络来解决SIMO模型的局限性，通过聚合跨说话人表示。此外，CSE模型与SOT相结合，既发挥了SIMO和SISO的优势，又缓解了它们的缺点。据我们所知，该工作代表了将SIMO和SISO集成到多说话人语音识别中的早期工作。在两个说话人的LibrispeechMix数据集上进行的实验表明，CES模型相比于SIMO基准模型将词错误率（WER）降低了8%。CSE-SOT模型将WER降低了10%",
    "tldr": "本文提出了一种叫做Cross-Speaker Encoding（CSE）的网络，用于解决多说话人语音识别中的局限性，通过聚合跨说话人表示。通过与SOT结合，该模型在两个说话人的数据集上实验证明比SIMO基准模型的词错误率（WER）分别降低了8%和10%。",
    "en_tdlr": "This paper proposes a Cross-Speaker Encoding (CSE) network to address the limitations of multi-talker speech recognition by aggregating cross-speaker representations. By integrating with SOT, the model reduces word error rate (WER) by 8% and 10% on two-speaker datasets compared to the SIMO baseline."
}