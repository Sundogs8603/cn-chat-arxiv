{
    "title": "Sparse PCA with False Discovery Rate Controlled Variable Selection. (arXiv:2401.08375v1 [stat.ML])",
    "abstract": "Sparse principal component analysis (PCA) aims at mapping large dimensional data to a linear subspace of lower dimension. By imposing loading vectors to be sparse, it performs the double duty of dimension reduction and variable selection. Sparse PCA algorithms are usually expressed as a trade-off between explained variance and sparsity of the loading vectors (i.e., number of selected variables). As a high explained variance is not necessarily synonymous with relevant information, these methods are prone to select irrelevant variables. To overcome this issue, we propose an alternative formulation of sparse PCA driven by the false discovery rate (FDR). We then leverage the Terminating-Random Experiments (T-Rex) selector to automatically determine an FDR-controlled support of the loading vectors. A major advantage of the resulting T-Rex PCA is that no sparsity parameter tuning is required. Numerical experiments and a stock market data example demonstrate a significant performance improvem",
    "link": "http://arxiv.org/abs/2401.08375",
    "context": "Title: Sparse PCA with False Discovery Rate Controlled Variable Selection. (arXiv:2401.08375v1 [stat.ML])\nAbstract: Sparse principal component analysis (PCA) aims at mapping large dimensional data to a linear subspace of lower dimension. By imposing loading vectors to be sparse, it performs the double duty of dimension reduction and variable selection. Sparse PCA algorithms are usually expressed as a trade-off between explained variance and sparsity of the loading vectors (i.e., number of selected variables). As a high explained variance is not necessarily synonymous with relevant information, these methods are prone to select irrelevant variables. To overcome this issue, we propose an alternative formulation of sparse PCA driven by the false discovery rate (FDR). We then leverage the Terminating-Random Experiments (T-Rex) selector to automatically determine an FDR-controlled support of the loading vectors. A major advantage of the resulting T-Rex PCA is that no sparsity parameter tuning is required. Numerical experiments and a stock market data example demonstrate a significant performance improvem",
    "path": "papers/24/01/2401.08375.json",
    "total_tokens": 867,
    "translated_title": "通过可控的误发现率选择的稀疏PCA",
    "translated_abstract": "稀疏主成分分析（PCA）旨在将高维数据映射到较低维的线性子空间。通过使加载向量稀疏，它既可以实现降维又可以进行变量选择。稀疏PCA算法通常是在解释方差和加载向量稀疏性之间权衡，加载向量的稀疏性即选择的变量数量。由于高解释方差不一定代表相关信息，这些方法容易选择不相关的变量。为了克服这个问题，我们提出了一种以误发现率（FDR）为驱动的稀疏PCA的替代形式。然后，我们利用终止随机实验（T-Rex）选择器自动确定加载向量的FDR控制支撑。得到的T-Rex PCA的一大优势是不需要调整稀疏参数。数值实验和股票市场数据示例证明了性能的显著改善。",
    "tldr": "该论文提出了一种通过可控的误发现率（FDR）驱动的稀疏PCA方法，在不需要调整稀疏参数的情况下，实现了对加载向量的自动选择，从而解决了传统稀疏PCA方法容易选择不相关变量的问题。",
    "en_tdlr": "This paper proposes a sparse PCA method driven by the false discovery rate (FDR), which automatically selects loading vectors without the need for tuning sparsity parameters, addressing the issue of traditional sparse PCA methods selecting irrelevant variables."
}