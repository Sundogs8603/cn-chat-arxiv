{
    "title": "On the generalization capacity of neural networks during generic multimodal reasoning. (arXiv:2401.15030v1 [cs.LG])",
    "abstract": "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks structures). We found that across model architectures (e.g., RNNs, Transformers, Perceivers, etc.), models with multiple attention layers, or models that leveraged cross-attention mechanisms between input domains, fared better. Our positive results demonstrate that for multi",
    "link": "http://arxiv.org/abs/2401.15030",
    "context": "Title: On the generalization capacity of neural networks during generic multimodal reasoning. (arXiv:2401.15030v1 [cs.LG])\nAbstract: The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks structures). We found that across model architectures (e.g., RNNs, Transformers, Perceivers, etc.), models with multiple attention layers, or models that leveraged cross-attention mechanisms between input domains, fared better. Our positive results demonstrate that for multi",
    "path": "papers/24/01/2401.15030.json",
    "total_tokens": 854,
    "translated_title": "关于神经网络在通用多模态推理中的泛化能力的研究",
    "translated_abstract": "Transformer的出现导致了大型语言模型（LLM）的发展, 这些模型似乎展示了类似人类的能力。为了评估这类模型和其他基本的神经网络架构在多模态领域的一般性，我们评估和比较了它们在多模态泛化方面的能力。我们引入了一个多模态问答基准来评估三种特定类型的超出分布（OOD）泛化性能：分心泛化（在分心存在的情况下泛化），系统的组合泛化（对新的任务排列的泛化）和有益的组合泛化（对更复杂的任务结构进行泛化）。我们发现，在不同的模型架构上（如RNN，Transformer，Perceivers等），具有多个注意力层或者利用输入领域之间的交叉注意机制的模型更好。我们的积极结果表明，对于多模态泛化，模型架构是重要因素。",
    "tldr": "本研究评估了不同神经网络架构在多模态泛化方面的能力，并发现具有多个注意力层或利用交叉注意机制的模型表现更好。",
    "en_tdlr": "This study evaluates the capability of different neural network architectures in multimodal generalization, and found that models with multiple attention layers or utilizing cross-attention mechanisms perform better."
}