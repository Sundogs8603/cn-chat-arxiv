{
    "title": "Contrastive Perplexity for Controlled Generation: An Application in Detoxifying Large Language Models. (arXiv:2401.08491v2 [cs.CL] UPDATED)",
    "abstract": "The generation of undesirable and factually incorrect content of large language models poses a significant challenge and remains largely an unsolved issue. This paper studies the integration of a contrastive learning objective for fine-tuning LLMs for implicit knowledge editing and controlled text generation. Optimizing the training objective entails aligning text perplexities in a contrastive fashion. To facilitate training the model in a self-supervised fashion, we leverage an off-the-shelf LLM for training data generation. We showcase applicability in the domain of detoxification. Herein, the proposed approach leads to a significant decrease in the generation of toxic content while preserving general utility for downstream tasks such as commonsense reasoning and reading comprehension. The proposed approach is conceptually simple but empirically powerful.",
    "link": "http://arxiv.org/abs/2401.08491",
    "context": "Title: Contrastive Perplexity for Controlled Generation: An Application in Detoxifying Large Language Models. (arXiv:2401.08491v2 [cs.CL] UPDATED)\nAbstract: The generation of undesirable and factually incorrect content of large language models poses a significant challenge and remains largely an unsolved issue. This paper studies the integration of a contrastive learning objective for fine-tuning LLMs for implicit knowledge editing and controlled text generation. Optimizing the training objective entails aligning text perplexities in a contrastive fashion. To facilitate training the model in a self-supervised fashion, we leverage an off-the-shelf LLM for training data generation. We showcase applicability in the domain of detoxification. Herein, the proposed approach leads to a significant decrease in the generation of toxic content while preserving general utility for downstream tasks such as commonsense reasoning and reading comprehension. The proposed approach is conceptually simple but empirically powerful.",
    "path": "papers/24/01/2401.08491.json",
    "total_tokens": 801,
    "translated_title": "对比困惑度在受控生成中的应用：清洁大型语言模型",
    "translated_abstract": "大型语言模型产生不可取和事实不正确的内容在很大程度上是一个挑战和未解决的问题。本文研究了对比学习目标的集成，用于微调语言模型以进行隐式知识编辑和受控文本生成。通过对比方式优化训练目标，即对齐文本的困惑度。为了以自监督的方式训练模型，我们利用现成的语言模型来生成训练数据。我们展示了在清洁领域的适用性。在此过程中，所提出的方法显著减少了生成有害内容的数量，同时保留了对于常识推理和阅读理解等下游任务的实用性。所提出的方法在概念上简单但经验上强大。",
    "tldr": "这项研究研究了对比学习目标的集成到微调大型语言模型中，以解决其产生不可取内容的问题，并展示了在清洁领域中有效减少有害内容生成的方法。"
}