{
    "title": "Spiker+: a framework for the generation of efficient Spiking Neural Networks FPGA accelerators for inference at the edge. (arXiv:2401.01141v1 [cs.NE])",
    "abstract": "Including Artificial Neural Networks in embedded systems at the edge allows applications to exploit Artificial Intelligence capabilities directly within devices operating at the network periphery. This paper introduces Spiker+, a comprehensive framework for generating efficient, low-power, and low-area customized Spiking Neural Networks (SNN) accelerators on FPGA for inference at the edge. Spiker+ presents a configurable multi-layer hardware SNN, a library of highly efficient neuron architectures, and a design framework, enabling the development of complex neural network accelerators with few lines of Python code. Spiker+ is tested on two benchmark datasets, the MNIST and the Spiking Heidelberg Digits (SHD). On the MNIST, it demonstrates competitive performance compared to state-of-the-art SNN accelerators. It outperforms them in terms of resource allocation, with a requirement of 7,612 logic cells and 18 Block RAMs (BRAMs), which makes it fit in very small FPGA, and power consumption,",
    "link": "http://arxiv.org/abs/2401.01141",
    "context": "Title: Spiker+: a framework for the generation of efficient Spiking Neural Networks FPGA accelerators for inference at the edge. (arXiv:2401.01141v1 [cs.NE])\nAbstract: Including Artificial Neural Networks in embedded systems at the edge allows applications to exploit Artificial Intelligence capabilities directly within devices operating at the network periphery. This paper introduces Spiker+, a comprehensive framework for generating efficient, low-power, and low-area customized Spiking Neural Networks (SNN) accelerators on FPGA for inference at the edge. Spiker+ presents a configurable multi-layer hardware SNN, a library of highly efficient neuron architectures, and a design framework, enabling the development of complex neural network accelerators with few lines of Python code. Spiker+ is tested on two benchmark datasets, the MNIST and the Spiking Heidelberg Digits (SHD). On the MNIST, it demonstrates competitive performance compared to state-of-the-art SNN accelerators. It outperforms them in terms of resource allocation, with a requirement of 7,612 logic cells and 18 Block RAMs (BRAMs), which makes it fit in very small FPGA, and power consumption,",
    "path": "papers/24/01/2401.01141.json",
    "total_tokens": 870,
    "translated_title": "Spiker＋：一种用于在边缘进行推理的高效Spiking神经网络FPGA加速器生成框架",
    "translated_abstract": "在边缘嵌入式系统中包含人工神经网络可以使应用程序在网络边缘设备中直接利用人工智能能力。本文介绍了Spiker＋，这是一个用于在边缘进行推理的高效、低功耗、低面积的定制Spiking神经网络（SNN）FPGA加速器的综合框架。Spiker＋提供了可配置的多层硬件SNN、高效的神经元架构库以及一个设计框架，使得可以用少量Python代码开发复杂的神经网络加速器。Spiker＋在两个基准数据集MNIST和Spiking Heidelberg Digits（SHD）上进行了测试。在MNIST上，它表现出与最先进的SNN加速器相媲美的性能。它在资源分配方面优于它们，需要7612个逻辑单元和18个Block RAM（BRAM），可以适应非常小的FPGA，并且功耗较低。",
    "tldr": "Spiker+是一个在边缘进行推理的高效Spiking神经网络FPGA加速器生成框架，具有低资源消耗和低功耗的特点。"
}