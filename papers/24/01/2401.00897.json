{
    "title": "Masked Modeling for Self-supervised Representation Learning on Vision and Beyond. (arXiv:2401.00897v1 [cs.CV])",
    "abstract": "As the deep learning revolution marches on, self-supervised learning has garnered increasing attention in recent years thanks to its remarkable representation learning ability and the low dependence on labeled data. Among these varied self-supervised techniques, masked modeling has emerged as a distinctive approach that involves predicting parts of the original data that are proportionally masked during training. This paradigm enables deep models to learn robust representations and has demonstrated exceptional performance in the context of computer vision, natural language processing, and other modalities. In this survey, we present a comprehensive review of the masked modeling framework and its methodology. We elaborate on the details of techniques within masked modeling, including diverse masking strategies, recovering targets, network architectures, and more. Then, we systematically investigate its wide-ranging applications across domains. Furthermore, we also explore the commonalit",
    "link": "http://arxiv.org/abs/2401.00897",
    "context": "Title: Masked Modeling for Self-supervised Representation Learning on Vision and Beyond. (arXiv:2401.00897v1 [cs.CV])\nAbstract: As the deep learning revolution marches on, self-supervised learning has garnered increasing attention in recent years thanks to its remarkable representation learning ability and the low dependence on labeled data. Among these varied self-supervised techniques, masked modeling has emerged as a distinctive approach that involves predicting parts of the original data that are proportionally masked during training. This paradigm enables deep models to learn robust representations and has demonstrated exceptional performance in the context of computer vision, natural language processing, and other modalities. In this survey, we present a comprehensive review of the masked modeling framework and its methodology. We elaborate on the details of techniques within masked modeling, including diverse masking strategies, recovering targets, network architectures, and more. Then, we systematically investigate its wide-ranging applications across domains. Furthermore, we also explore the commonalit",
    "path": "papers/24/01/2401.00897.json",
    "total_tokens": 871,
    "translated_title": "自监督视觉学习中的蒙面建模",
    "translated_abstract": "随着深度学习的革命不断向前，自监督学习因其出色的表示学习能力和对标注数据的低依赖性而受到越来越多的关注。在这些多样的自监督技术中，蒙面建模已经成为一种独特的方法，其中在训练过程中相应比例的原始数据会被蒙面，模型需要预测出这些蒙面的部分。这种范式使深度模型能够学习到稳健的表示，并在计算机视觉、自然语言处理和其他领域展示出了出色的性能。在本调查中，我们对蒙面建模框架及其方法进行了全面的回顾，详细介绍了蒙面建模中的技术细节，包括多样的蒙面策略、恢复目标、网络架构等。然后，我们系统地调查了它在各个领域中的广泛应用。此外，我们还探讨了其共性。",
    "tldr": "蒙面建模是一种自监督学习方法，通过预测被蒙面部分实现深度模型学习稳健的表示，已在计算机视觉和自然语言处理等领域展现出卓越性能。",
    "en_tdlr": "Masked modeling is a self-supervised learning method that enables deep models to learn robust representations by predicting the masked parts of the data, and has demonstrated exceptional performance in computer vision and natural language processing."
}