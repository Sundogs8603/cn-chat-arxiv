{
    "title": "Assessing Large Language Models in Mechanical Engineering Education: A Study on Mechanics-Focused Conceptual Understanding. (arXiv:2401.12983v1 [cs.CL])",
    "abstract": "This study is a pioneering endeavor to investigate the capabilities of Large Language Models (LLMs) in addressing conceptual questions within the domain of mechanical engineering with a focus on mechanics. Our examination involves a manually crafted exam encompassing 126 multiple-choice questions, spanning various aspects of mechanics courses, including Fluid Mechanics, Mechanical Vibration, Engineering Statics and Dynamics, Mechanics of Materials, Theory of Elasticity, and Continuum Mechanics. Three LLMs, including ChatGPT (GPT-3.5), ChatGPT (GPT-4), and Claude (Claude-2.1), were subjected to evaluation against engineering faculties and students with or without mechanical engineering background. The findings reveal GPT-4's superior performance over the other two LLMs and human cohorts in answering questions across various mechanics topics, except for Continuum Mechanics. This signals the potential future improvements for GPT models in handling symbolic calculations and tensor analyses",
    "link": "http://arxiv.org/abs/2401.12983",
    "context": "Title: Assessing Large Language Models in Mechanical Engineering Education: A Study on Mechanics-Focused Conceptual Understanding. (arXiv:2401.12983v1 [cs.CL])\nAbstract: This study is a pioneering endeavor to investigate the capabilities of Large Language Models (LLMs) in addressing conceptual questions within the domain of mechanical engineering with a focus on mechanics. Our examination involves a manually crafted exam encompassing 126 multiple-choice questions, spanning various aspects of mechanics courses, including Fluid Mechanics, Mechanical Vibration, Engineering Statics and Dynamics, Mechanics of Materials, Theory of Elasticity, and Continuum Mechanics. Three LLMs, including ChatGPT (GPT-3.5), ChatGPT (GPT-4), and Claude (Claude-2.1), were subjected to evaluation against engineering faculties and students with or without mechanical engineering background. The findings reveal GPT-4's superior performance over the other two LLMs and human cohorts in answering questions across various mechanics topics, except for Continuum Mechanics. This signals the potential future improvements for GPT models in handling symbolic calculations and tensor analyses",
    "path": "papers/24/01/2401.12983.json",
    "total_tokens": 969,
    "translated_title": "在机械工程教育中评估大型语言模型：关于以力学为重点的概念理解的研究",
    "translated_abstract": "本研究是对大型语言模型（LLMs）在机械工程领域中解决概念性问题的能力进行的开创性研究，重点是力学。我们使用包含126个多项选择题的手工制作的考试来进行考察，涵盖了力学课程的各个方面，包括流体力学、机械振动、工程静力学和动力学、材料力学、弹性理论和连续介质力学。我们对三个LLM进行了评估，包括ChatGPT（GPT-3.5）、ChatGPT（GPT-4）和Claude（Claude-2.1），并将其与具有或没有机械工程背景的工程教职员和学生进行了比较。研究结果显示，在各种力学主题的问题回答方面，除了连续介质力学外，GPT-4的表现优于其他两个LLM和人类对照组。这表明GPT模型在处理符号计算和张量分析方面有潜在的未来改进空间。",
    "tldr": "本研究通过对三个大型语言模型（LLMs）在机械工程领域中解决概念性问题的能力进行评估，发现GPT-4在各个力学主题的问题回答方面表现优于其他两个模型和人类对照组，显示出潜在的未来改进空间。",
    "en_tdlr": "This study assesses the capabilities of Large Language Models (LLMs) in addressing conceptual questions in mechanical engineering and finds that GPT-4 outperforms other models and human cohorts in answering questions across various mechanics topics, indicating potential future improvements."
}