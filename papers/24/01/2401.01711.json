{
    "title": "Evaluating Large Language Models in Semantic Parsing for Conversational Question Answering over Knowledge Graphs. (arXiv:2401.01711v1 [cs.CL])",
    "abstract": "Conversational question answering systems often rely on semantic parsing to enable interactive information retrieval, which involves the generation of structured database queries from a natural language input. For information-seeking conversations about facts stored within a knowledge graph, dialogue utterances are transformed into graph queries in a process that is called knowledge-based conversational question answering. This paper evaluates the performance of large language models that have not been explicitly pre-trained on this task. Through a series of experiments on an extensive benchmark dataset, we compare models of varying sizes with different prompting techniques and identify common issue types in the generated output. Our results demonstrate that large language models are capable of generating graph queries from dialogues, with significant improvements achievable through few-shot prompting and fine-tuning techniques, especially for smaller models that exhibit lower zero-sho",
    "link": "http://arxiv.org/abs/2401.01711",
    "context": "Title: Evaluating Large Language Models in Semantic Parsing for Conversational Question Answering over Knowledge Graphs. (arXiv:2401.01711v1 [cs.CL])\nAbstract: Conversational question answering systems often rely on semantic parsing to enable interactive information retrieval, which involves the generation of structured database queries from a natural language input. For information-seeking conversations about facts stored within a knowledge graph, dialogue utterances are transformed into graph queries in a process that is called knowledge-based conversational question answering. This paper evaluates the performance of large language models that have not been explicitly pre-trained on this task. Through a series of experiments on an extensive benchmark dataset, we compare models of varying sizes with different prompting techniques and identify common issue types in the generated output. Our results demonstrate that large language models are capable of generating graph queries from dialogues, with significant improvements achievable through few-shot prompting and fine-tuning techniques, especially for smaller models that exhibit lower zero-sho",
    "path": "papers/24/01/2401.01711.json",
    "total_tokens": 787,
    "translated_title": "在语义解析中评估大型语言模型在基于知识图谱的对话问答中的应用",
    "translated_abstract": "会话式问答系统通常依赖语义解析来实现交互式信息检索，该过程涉及将自然语言输入转化为结构化数据库查询。对于知识图谱中存储的事实的信息检索对话，对话表达被转化为图查询的过程被称为基于知识的对话问答。本文评估了尚未明确在此任务上进行预训练的大型语言模型的性能。通过在广泛的基准数据集上进行一系列实验，我们比较了不同大小和提示技术的模型，并识别出生成输出中常见的问题类型。我们的结果表明，大型语言模型能够从对话中生成图查询，通过少量提示和微调技术可以显著提高性能，特别是对于展示较低零样本性能的较小模型。",
    "tldr": "本论文评估了尚未在知识图谱对话问答任务上进行预训练的大型语言模型的性能，并通过实验证明了这些模型在生成图查询方面的能力以及通过少量提示和微调技术可以显著改善其性能。"
}