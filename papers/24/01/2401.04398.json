{
    "title": "Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding. (arXiv:2401.04398v1 [cs.CL])",
    "abstract": "Table-based reasoning with large language models (LLMs) is a promising direction to tackle many table understanding tasks, such as table-based question answering and fact verification. Compared with generic reasoning, table-based reasoning requires the extraction of underlying semantics from both free-form questions and semi-structured tabular data. Chain-of-Thought and its similar approaches incorporate the reasoning chain in the form of textual context, but it is still an open question how to effectively leverage tabular data in the reasoning chain. We propose the Chain-of-Table framework, where tabular data is explicitly used in the reasoning chain as a proxy for intermediate thoughts. Specifically, we guide LLMs using in-context learning to iteratively generate operations and update the table to represent a tabular reasoning chain. LLMs can therefore dynamically plan the next operation based on the results of the previous ones. This continuous evolution of the table forms a chain, ",
    "link": "http://arxiv.org/abs/2401.04398",
    "context": "Title: Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding. (arXiv:2401.04398v1 [cs.CL])\nAbstract: Table-based reasoning with large language models (LLMs) is a promising direction to tackle many table understanding tasks, such as table-based question answering and fact verification. Compared with generic reasoning, table-based reasoning requires the extraction of underlying semantics from both free-form questions and semi-structured tabular data. Chain-of-Thought and its similar approaches incorporate the reasoning chain in the form of textual context, but it is still an open question how to effectively leverage tabular data in the reasoning chain. We propose the Chain-of-Table framework, where tabular data is explicitly used in the reasoning chain as a proxy for intermediate thoughts. Specifically, we guide LLMs using in-context learning to iteratively generate operations and update the table to represent a tabular reasoning chain. LLMs can therefore dynamically plan the next operation based on the results of the previous ones. This continuous evolution of the table forms a chain, ",
    "path": "papers/24/01/2401.04398.json",
    "total_tokens": 850,
    "translated_title": "Chain-of-Table: 在推理链中演化表格用于表格理解",
    "translated_abstract": "基于大型语言模型（LLMs）的表格推理是解决许多表格理解任务（如基于表格的问答和事实验证）的一种有前景的方法。与通常的推理相比，基于表格的推理需要从自由形式问题和半结构化表格数据中提取潜在语义。Chain-of-Thought及其类似方法将推理链以文本上下文的形式纳入其中，但如何有效利用表格数据在推理链中仍然是一个开放的问题。我们提出了Chain-of-Table框架，其中表格数据以作为中间思维的代理明确地用于推理链中。具体地，我们使用上下文学习指导LLMs来迭代生成操作并更新表格，以代表一个表格推理链。因此，LLMs可以根据之前操作的结果动态地规划下一个操作。这种表格的持续演化形成了一个链。",
    "tldr": "这篇论文提出了Chain-of-Table框架，通过在推理链中使用表格数据作为中间思维的代理，利用大型语言模型在表格理解任务中进行推理，实现了动态演化的表格推理链。"
}