{
    "title": "Unsupervised Multiple Domain Translation through Controlled Disentanglement in Variational Autoencoder. (arXiv:2401.09180v1 [cs.LG])",
    "abstract": "Unsupervised Multiple Domain Translation is the task of transforming data from one domain to other domains without having paired data to train the systems. Typically, methods based on Generative Adversarial Networks (GANs) are used to address this task. However, our proposal exclusively relies on a modified version of a Variational Autoencoder. This modification consists of the use of two latent variables disentangled in a controlled way by design. One of this latent variables is imposed to depend exclusively on the domain, while the other one must depend on the rest of the variability factors of the data. Additionally, the conditions imposed over the domain latent variable allow for better control and understanding of the latent space. We empirically demonstrate that our approach works on different vision datasets improving the performance of other well known methods. Finally, we prove that, indeed, one of the latent variables stores all the information related to the domain and the o",
    "link": "http://arxiv.org/abs/2401.09180",
    "context": "Title: Unsupervised Multiple Domain Translation through Controlled Disentanglement in Variational Autoencoder. (arXiv:2401.09180v1 [cs.LG])\nAbstract: Unsupervised Multiple Domain Translation is the task of transforming data from one domain to other domains without having paired data to train the systems. Typically, methods based on Generative Adversarial Networks (GANs) are used to address this task. However, our proposal exclusively relies on a modified version of a Variational Autoencoder. This modification consists of the use of two latent variables disentangled in a controlled way by design. One of this latent variables is imposed to depend exclusively on the domain, while the other one must depend on the rest of the variability factors of the data. Additionally, the conditions imposed over the domain latent variable allow for better control and understanding of the latent space. We empirically demonstrate that our approach works on different vision datasets improving the performance of other well known methods. Finally, we prove that, indeed, one of the latent variables stores all the information related to the domain and the o",
    "path": "papers/24/01/2401.09180.json",
    "total_tokens": 920,
    "translated_title": "通过可控的变分自编码器中的受控解缠来进行无监督多领域翻译",
    "translated_abstract": "无监督多领域翻译是将数据从一个领域转换到其他领域，而无需配对数据来训练系统的任务。通常，基于生成对抗网络（GAN）的方法被用来解决这个任务。然而，我们的提议完全依赖于修改过的变分自编码器。这种修改包括通过设计以控制方式解缠两个潜变量。其中一个潜变量被强制仅依赖于领域，而另一个潜变量必须依赖于数据的其他变化因素。此外，对于领域潜变量的条件限制可以更好地控制和理解潜空间。我们从实证上证明了我们的方法适用于不同的视觉数据集，提高了其他众所周知的方法的性能。最后，我们证明了实际上一个潜变量存储了与领域和其他变化因素有关的所有信息。",
    "tldr": "该论文提出了一种无监督多领域翻译的方法，通过修改后的变分自编码器实现了受控解缠的两个潜变量，其中一个仅与领域有关，另一个与数据的其他变化因素有关。实验证明该方法在不同的视觉数据集上提高了性能。",
    "en_tdlr": "This paper presents an approach for unsupervised multiple domain translation using a modified version of a Variational Autoencoder, which utilizes controlled disentanglement of two latent variables. The method performs well on various vision datasets and improves upon existing techniques."
}