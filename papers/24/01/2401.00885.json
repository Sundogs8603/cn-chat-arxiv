{
    "title": "Attractor reconstruction with reservoir computers: The effect of the reservoir's conditional Lyapunov exponents on faithful attractor reconstruction. (arXiv:2401.00885v1 [cs.LG])",
    "abstract": "Reservoir computing is a machine learning technique which has been shown to be able to replicate the chaotic attractor, including the fractal dimension and the entire Lyapunov spectrum, of the dynamical system on which it is trained. We quantitatively relate the generalized synchronization dynamics of a driven reservoir computer during the training stage to the performance of the autonomous reservoir computer at the attractor reconstruction task. We show that, for successful attractor reconstruction and Lyapunov exponent estimation, the largest conditional Lyapunov exponent of the driven reservoir must be significantly smaller (more negative) than the smallest (most negative) Lyapunov exponent of the true system. We find that the maximal conditional Lyapunov exponent of the reservoir depends strongly on the spectral radius of the reservoir adjacency matrix, and therefore, for attractor reconstruction and Lyapunov exponent estimation, small spectral radius reservoir computers perform be",
    "link": "http://arxiv.org/abs/2401.00885",
    "context": "Title: Attractor reconstruction with reservoir computers: The effect of the reservoir's conditional Lyapunov exponents on faithful attractor reconstruction. (arXiv:2401.00885v1 [cs.LG])\nAbstract: Reservoir computing is a machine learning technique which has been shown to be able to replicate the chaotic attractor, including the fractal dimension and the entire Lyapunov spectrum, of the dynamical system on which it is trained. We quantitatively relate the generalized synchronization dynamics of a driven reservoir computer during the training stage to the performance of the autonomous reservoir computer at the attractor reconstruction task. We show that, for successful attractor reconstruction and Lyapunov exponent estimation, the largest conditional Lyapunov exponent of the driven reservoir must be significantly smaller (more negative) than the smallest (most negative) Lyapunov exponent of the true system. We find that the maximal conditional Lyapunov exponent of the reservoir depends strongly on the spectral radius of the reservoir adjacency matrix, and therefore, for attractor reconstruction and Lyapunov exponent estimation, small spectral radius reservoir computers perform be",
    "path": "papers/24/01/2401.00885.json",
    "total_tokens": 912,
    "translated_title": "使用储层计算进行吸引子重建：储层的条件Lyapunov指数对忠实吸引子重建的影响",
    "translated_abstract": "储层计算是一种机器学习技术，已被证明能够复制动力系统的混沌吸引子，包括分形维度和整个Lyapunov谱。我们定量地将驱动式储层计算的广义同步动力学与自主式储层计算在吸引子重建任务上的性能相关联。我们发现，为了成功进行吸引子重建和Lyapunov指数估计，驱动式储层的最大条件Lyapunov指数必须显著小于真实系统的最小（最负）Lyapunov指数。我们发现，储层的最大条件Lyapunov指数强烈依赖于储层邻接矩阵的谱半径，因此，对于吸引子重建和Lyapunov指数估计，谱半径较小的储层计算表现更好。",
    "tldr": "该论文研究了储层计算在吸引子重建中的表现，发现驱动式储层的最大条件Lyapunov指数需要比真实系统的最小Lyapunov指数更小，储层的谱半径对吸引子重建起到重要作用。"
}