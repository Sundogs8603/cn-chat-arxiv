{
    "title": "Wake-Sleep Consolidated Learning. (arXiv:2401.08623v1 [cs.NE])",
    "abstract": "We propose Wake-Sleep Consolidated Learning (WSCL), a learning strategy leveraging Complementary Learning System theory and the wake-sleep phases of the human brain to improve the performance of deep neural networks for visual classification tasks in continual learning settings. Our method learns continually via the synchronization between distinct wake and sleep phases. During the wake phase, the model is exposed to sensory input and adapts its representations, ensuring stability through a dynamic parameter freezing mechanism and storing episodic memories in a short-term temporary memory (similarly to what happens in the hippocampus). During the sleep phase, the training process is split into NREM and REM stages. In the NREM stage, the model's synaptic weights are consolidated using replayed samples from the short-term and long-term memory and the synaptic plasticity mechanism is activated, strengthening important connections and weakening unimportant ones. In the REM stage, the model",
    "link": "http://arxiv.org/abs/2401.08623",
    "context": "Title: Wake-Sleep Consolidated Learning. (arXiv:2401.08623v1 [cs.NE])\nAbstract: We propose Wake-Sleep Consolidated Learning (WSCL), a learning strategy leveraging Complementary Learning System theory and the wake-sleep phases of the human brain to improve the performance of deep neural networks for visual classification tasks in continual learning settings. Our method learns continually via the synchronization between distinct wake and sleep phases. During the wake phase, the model is exposed to sensory input and adapts its representations, ensuring stability through a dynamic parameter freezing mechanism and storing episodic memories in a short-term temporary memory (similarly to what happens in the hippocampus). During the sleep phase, the training process is split into NREM and REM stages. In the NREM stage, the model's synaptic weights are consolidated using replayed samples from the short-term and long-term memory and the synaptic plasticity mechanism is activated, strengthening important connections and weakening unimportant ones. In the REM stage, the model",
    "path": "papers/24/01/2401.08623.json",
    "total_tokens": 1039,
    "translated_title": "Wake-Sleep Consolidated Learning（WSCL）的研究",
    "translated_abstract": "我们提出了 Wake-Sleep Consolidated Learning（WSCL）的学习策略，利用互补学习系统理论和人脑的觉醒-睡眠阶段来改进深度神经网络在连续学习设置中的视觉分类任务表现。我们的方法通过觉醒和睡眠阶段之间的同步学习来实现持续学习。在觉醒阶段，模型暴露于感官输入并调整其表示，通过动态参数冻结机制确保稳定性，并将情节记忆存储在短期临时记忆中（类似于海马体中的情况）。在睡眠阶段，训练过程分为NREM和REM阶段。在NREM阶段，模型的突触权重利用来自短期和长期记忆的回放样本进行巩固，并激活突触可塑性机制，强化重要连接并削弱不重要的连接。在REM阶段，模型...",
    "tldr": "Wake-Sleep Consolidated Learning（WSCL）是一种借鉴人脑觉醒-睡眠阶段的学习策略，用于改进深度神经网络在连续学习中的视觉分类任务。该方法通过觉醒和睡眠阶段之间的同步学习来实现持续学习，觉醒阶段中模型适应感官输入并利用动态参数冻结机制保持稳定，睡眠阶段根据NREM和REM阶段对模型的突触权重进行巩固和调整，强化重要连接并削弱不重要的连接。",
    "en_tdlr": "Wake-Sleep Consolidated Learning (WSCL) is a learning strategy inspired by the wake-sleep phases of the human brain to improve the performance of deep neural networks in visual classification tasks during continual learning. The method achieves continuous learning by synchronizing the wake and sleep phases, with the wake phase adapting the model to sensory input and the sleep phase consolidating and adjusting the synaptic weights based on NREM and REM stages, strengthening important connections and weakening unimportant ones."
}