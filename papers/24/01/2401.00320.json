{
    "title": "DXAI: Explaining Classification by Image Decomposition",
    "abstract": "arXiv:2401.00320v2 Announce Type: replace-cross  Abstract: We propose a new way to explain and to visualize neural network classification through a decomposition-based explainable AI (DXAI). Instead of providing an explanation heatmap, our method yields a decomposition of the image into class-agnostic and class-distinct parts, with respect to the data and chosen classifier. Following a fundamental signal processing paradigm of analysis and synthesis, the original image is the sum of the decomposed parts. We thus obtain a radically different way of explaining classification. The class-agnostic part ideally is composed of all image features which do not posses class information, where the class-distinct part is its complementary. This new visualization can be more helpful and informative in certain scenarios, especially when the attributes are dense, global and additive in nature, for instance, when colors or textures are essential for class distinction. Code is available at https://gith",
    "link": "https://arxiv.org/abs/2401.00320",
    "context": "Title: DXAI: Explaining Classification by Image Decomposition\nAbstract: arXiv:2401.00320v2 Announce Type: replace-cross  Abstract: We propose a new way to explain and to visualize neural network classification through a decomposition-based explainable AI (DXAI). Instead of providing an explanation heatmap, our method yields a decomposition of the image into class-agnostic and class-distinct parts, with respect to the data and chosen classifier. Following a fundamental signal processing paradigm of analysis and synthesis, the original image is the sum of the decomposed parts. We thus obtain a radically different way of explaining classification. The class-agnostic part ideally is composed of all image features which do not posses class information, where the class-distinct part is its complementary. This new visualization can be more helpful and informative in certain scenarios, especially when the attributes are dense, global and additive in nature, for instance, when colors or textures are essential for class distinction. Code is available at https://gith",
    "path": "papers/24/01/2401.00320.json",
    "total_tokens": 814,
    "translated_title": "DXAI：通过图像分解解释分类",
    "translated_abstract": "我们提出了一种通过基于分解的可解释AI（DXAI）来解释和可视化神经网络分类的新方法。我们的方法不是提供解释热图，而是将图像分解为与数据和所选分类器相关的类别不可知和类别明显部分。遵循分析和综合的基本信号处理范式，原始图像是分解部分的总和。因此，我们获得了一种根本不同的解释分类方式。类别不可知部分理想地由不具有类别信息的所有图像特征组成，而类别明显部分则是其补充。在某些情况下，尤其是当属性密集、全局且具有累积性质时，此新可视化可能更有帮助和信息性，例如，当颜色或纹理对于类别区分至关重要时。代码可在https://gith上找到",
    "tldr": "提出一种新的可解释AI方法DXAI，通过将图像分解为类别不可知和类别明显部分来解释和可视化神经网络分类，为解释分类提供了一种根本不同的方式",
    "en_tdlr": "Propose a novel explainable AI method, DXAI, which explains and visualizes neural network classification by decomposing the image into class-agnostic and class-distinct parts, offering a fundamentally different way of explaining classification."
}