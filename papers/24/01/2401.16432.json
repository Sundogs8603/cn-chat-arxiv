{
    "title": "Improving conversion rate prediction via self-supervised pre-training in online advertising. (arXiv:2401.16432v1 [cs.IR])",
    "abstract": "The task of predicting conversion rates (CVR) lies at the heart of online advertising systems aiming to optimize bids to meet advertiser performance requirements. Even with the recent rise of deep neural networks, these predictions are often made by factorization machines (FM), especially in commercial settings where inference latency is key. These models are trained using the logistic regression framework on labeled tabular data formed from past user activity that is relevant to the task at hand.  Many advertisers only care about click-attributed conversions. A major challenge in training models that predict conversions-given-clicks comes from data sparsity - clicks are rare, conversions attributed to clicks are even rarer. However, mitigating sparsity by adding conversions that are not click-attributed to the training set impairs model calibration. Since calibration is critical to achieving advertiser goals, this is infeasible.  In this work we use the well-known idea of self-supervi",
    "link": "http://arxiv.org/abs/2401.16432",
    "context": "Title: Improving conversion rate prediction via self-supervised pre-training in online advertising. (arXiv:2401.16432v1 [cs.IR])\nAbstract: The task of predicting conversion rates (CVR) lies at the heart of online advertising systems aiming to optimize bids to meet advertiser performance requirements. Even with the recent rise of deep neural networks, these predictions are often made by factorization machines (FM), especially in commercial settings where inference latency is key. These models are trained using the logistic regression framework on labeled tabular data formed from past user activity that is relevant to the task at hand.  Many advertisers only care about click-attributed conversions. A major challenge in training models that predict conversions-given-clicks comes from data sparsity - clicks are rare, conversions attributed to clicks are even rarer. However, mitigating sparsity by adding conversions that are not click-attributed to the training set impairs model calibration. Since calibration is critical to achieving advertiser goals, this is infeasible.  In this work we use the well-known idea of self-supervi",
    "path": "papers/24/01/2401.16432.json",
    "total_tokens": 914,
    "translated_title": "在在线广告中通过自监督预训练改进转化率预测",
    "translated_abstract": "预测转化率是在线广告系统中优化投标以满足广告主性能要求的关键任务。尽管深度神经网络的崛起，但这些预测通常由分解机（FM）进行，特别是在推理延迟至关重要的商业环境中。这些模型使用逻辑回归框架训练，利用与任务相关的过去用户活动形成的标记表格数据。许多广告主只关心被点击属性的转化。预测给定点击的转化模型训练的主要挑战来自数据稀疏性 - 点击很少，点击归因的转化更少。然而，在训练集中添加非点击归因的转化来减轻稀疏性会损坏模型的校准。由于校准对实现广告主目标至关重要，这是不可行的。在这项工作中，我们使用了自监督预训练的众所周知的思想来解决这个问题。",
    "tldr": "这项研究通过自监督预训练方法，改进了在线广告系统中的转化率预测。由于数据稀疏性的挑战，添加非点击归因的转化会损坏模型的校准，而自监督预训练能够解决这个问题。",
    "en_tdlr": "This research improves conversion rate prediction in online advertising systems by using self-supervised pre-training. Adding non-click-attributed conversions to solve data sparsity challenge impairs model calibration, but self-supervised pre-training addresses this issue."
}