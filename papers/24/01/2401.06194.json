{
    "title": "CrisisKAN: Knowledge-infused and Explainable Multimodal Attention Network for Crisis Event Classification. (arXiv:2401.06194v1 [cs.LG])",
    "abstract": "Pervasive use of social media has become the emerging source for real-time information (like images, text, or both) to identify various events. Despite the rapid growth of image and text-based event classification, the state-of-the-art (SOTA) models find it challenging to bridge the semantic gap between features of image and text modalities due to inconsistent encoding. Also, the black-box nature of models fails to explain the model's outcomes for building trust in high-stakes situations such as disasters, pandemic. Additionally, the word limit imposed on social media posts can potentially introduce bias towards specific events. To address these issues, we proposed CrisisKAN, a novel Knowledge-infused and Explainable Multimodal Attention Network that entails images and texts in conjunction with external knowledge from Wikipedia to classify crisis events. To enrich the context-specific understanding of textual information, we integrated Wikipedia knowledge using proposed wiki extraction",
    "link": "http://arxiv.org/abs/2401.06194",
    "context": "Title: CrisisKAN: Knowledge-infused and Explainable Multimodal Attention Network for Crisis Event Classification. (arXiv:2401.06194v1 [cs.LG])\nAbstract: Pervasive use of social media has become the emerging source for real-time information (like images, text, or both) to identify various events. Despite the rapid growth of image and text-based event classification, the state-of-the-art (SOTA) models find it challenging to bridge the semantic gap between features of image and text modalities due to inconsistent encoding. Also, the black-box nature of models fails to explain the model's outcomes for building trust in high-stakes situations such as disasters, pandemic. Additionally, the word limit imposed on social media posts can potentially introduce bias towards specific events. To address these issues, we proposed CrisisKAN, a novel Knowledge-infused and Explainable Multimodal Attention Network that entails images and texts in conjunction with external knowledge from Wikipedia to classify crisis events. To enrich the context-specific understanding of textual information, we integrated Wikipedia knowledge using proposed wiki extraction",
    "path": "papers/24/01/2401.06194.json",
    "total_tokens": 922,
    "translated_title": "CrisisKAN: 知识注入和可解释的多模态注意力网络用于危机事件分类",
    "translated_abstract": "广泛使用社交媒体已成为实时信息（如图像、文本或二者兼有）识别各种事件的新兴来源。尽管图像和文本的事件分类迅速发展，但最先进的模型仍然难以弥合由于不一致的编码导致的图像和文本模态之间的语义差距。此外，模型的黑匣子特性无法解释模型的结果，无法在灾难、大流行等高风险情况下建立信任。此外，社交媒体帖子的字数限制可能会对特定事件引入偏见。为了解决这些问题，我们提出了CrisisKAN，一种新颖的知识注入和可解释的多模态注意力网络，将图像和文本与维基百科的外部知识相结合，用于分类危机事件。为了丰富对文本信息的上下文特定理解，我们使用了提出的维基百科知识提取方法。",
    "tldr": "CrisisKAN是一种知识注入和可解释的多模态注意力网络，用于危机事件分类。它通过结合图像、文本和维基百科的外部知识来弥合图像和文本模态之间的语义差距，并解释模型的结果，以建立在高风险情况下的信任。",
    "en_tdlr": "CrisisKAN is a knowledge-infused and explainable multimodal attention network for crisis event classification. It bridges the semantic gap between image and text modalities by incorporating external knowledge from Wikipedia and explains the model's outcomes, thus building trust in high-stakes situations."
}