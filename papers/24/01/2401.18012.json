{
    "title": "Causal Coordinated Concurrent Reinforcement Learning",
    "abstract": "In this work, we propose a novel algorithmic framework for data sharing and coordinated exploration for the purpose of learning more data-efficient and better performing policies under a concurrent reinforcement learning (CRL) setting. In contrast to other work which make the assumption that all agents act under identical environments, we relax this restriction and instead consider the formulation where each agent acts within an environment which shares a global structure but also exhibits individual variations. Our algorithm leverages a causal inference algorithm in the form of Additive Noise Model - Mixture Model (ANM-MM) in extracting model parameters governing individual differentials via independence enforcement. We propose a new data sharing scheme based on a similarity measure of the extracted model parameters and demonstrate superior learning speeds on a set of autoregressive, pendulum and cart-pole swing-up tasks and finally, we show the effectiveness of diverse action selecti",
    "link": "https://arxiv.org/abs/2401.18012",
    "context": "Title: Causal Coordinated Concurrent Reinforcement Learning\nAbstract: In this work, we propose a novel algorithmic framework for data sharing and coordinated exploration for the purpose of learning more data-efficient and better performing policies under a concurrent reinforcement learning (CRL) setting. In contrast to other work which make the assumption that all agents act under identical environments, we relax this restriction and instead consider the formulation where each agent acts within an environment which shares a global structure but also exhibits individual variations. Our algorithm leverages a causal inference algorithm in the form of Additive Noise Model - Mixture Model (ANM-MM) in extracting model parameters governing individual differentials via independence enforcement. We propose a new data sharing scheme based on a similarity measure of the extracted model parameters and demonstrate superior learning speeds on a set of autoregressive, pendulum and cart-pole swing-up tasks and finally, we show the effectiveness of diverse action selecti",
    "path": "papers/24/01/2401.18012.json",
    "total_tokens": 901,
    "translated_title": "因果协同并发强化学习",
    "translated_abstract": "在这项工作中，我们提出了一种新颖的算法框架，用于数据共享和协同探索，以在并发强化学习（CRL）环境下学习更高效和表现更好的策略。与其他假设所有代理都在相同环境下行动的工作相比，我们放宽了这一限制，而是考虑每个代理在共享全局结构但也存在个体差异的环境中行动的情况。我们的算法利用了一个因果推断算法，即加性噪声模型 - 混合模型（ANM-MM），通过独立性强化提取控制个体差异的模型参数。我们提出了一种基于提取的模型参数相似性度量的数据共享方案，并在一组自回归、摆杆和倒立摆任务上展示了更快的学习速度，最后我们展示了多样化动作选择的有效性。",
    "tldr": "这项工作提出了一种用于并发强化学习的新算法框架，通过数据共享和协同探索来学习更高效和表现更好的策略。算法中利用因果推断算法提取控制个体差异的模型参数，并提出了一种基于相似性度量的数据共享方案，展示了更快的学习速度和多样化动作选择的有效性。",
    "en_tdlr": "This work presents a novel algorithmic framework for concurrent reinforcement learning, which learns more data-efficient and better performing policies through data sharing and coordinated exploration. The algorithm leverages a causal inference algorithm to extract model parameters governing individual differentials and proposes a data sharing scheme based on similarity measure. It demonstrates faster learning speeds and the effectiveness of diverse action selection."
}