{
    "title": "LongHealth: A Question Answering Benchmark with Long Clinical Documents. (arXiv:2401.14490v1 [cs.CL])",
    "abstract": "Background: Recent advancements in large language models (LLMs) offer potential benefits in healthcare, particularly in processing extensive patient records. However, existing benchmarks do not fully assess LLMs' capability in handling real-world, lengthy clinical data.  Methods: We present the LongHealth benchmark, comprising 20 detailed fictional patient cases across various diseases, with each case containing 5,090 to 6,754 words. The benchmark challenges LLMs with 400 multiple-choice questions in three categories: information extraction, negation, and sorting, challenging LLMs to extract and interpret information from large clinical documents.  Results: We evaluated nine open-source LLMs with a minimum of 16,000 tokens and also included OpenAI's proprietary and cost-efficient GPT-3.5 Turbo for comparison. The highest accuracy was observed for Mixtral-8x7B-Instruct-v0.1, particularly in tasks focused on information retrieval from single and multiple patient documents. However, all m",
    "link": "http://arxiv.org/abs/2401.14490",
    "context": "Title: LongHealth: A Question Answering Benchmark with Long Clinical Documents. (arXiv:2401.14490v1 [cs.CL])\nAbstract: Background: Recent advancements in large language models (LLMs) offer potential benefits in healthcare, particularly in processing extensive patient records. However, existing benchmarks do not fully assess LLMs' capability in handling real-world, lengthy clinical data.  Methods: We present the LongHealth benchmark, comprising 20 detailed fictional patient cases across various diseases, with each case containing 5,090 to 6,754 words. The benchmark challenges LLMs with 400 multiple-choice questions in three categories: information extraction, negation, and sorting, challenging LLMs to extract and interpret information from large clinical documents.  Results: We evaluated nine open-source LLMs with a minimum of 16,000 tokens and also included OpenAI's proprietary and cost-efficient GPT-3.5 Turbo for comparison. The highest accuracy was observed for Mixtral-8x7B-Instruct-v0.1, particularly in tasks focused on information retrieval from single and multiple patient documents. However, all m",
    "path": "papers/24/01/2401.14490.json",
    "total_tokens": 1000,
    "translated_title": "LongHealth:一份具有长篇临床文档的问答基准",
    "translated_abstract": "背景：最近大型语言模型（LLMs）的进展在医疗保健领域有潜在的好处，尤其是在处理大量的病患记录方面。然而，现有的基准未能充分评估LLMs在处理现实世界中的长篇临床数据方面的能力。方法：我们提出了LongHealth基准，包括20个详细的虚构病例，涵盖各种疾病，每个案例包含5090至6754个字。该基准通过三个类别的400个多项选择题，挑战LLMs从大型临床文档中提取并解释信息。结果：我们评估了九种开源LLMs，其中最少有16,000个标记，并且还包括了OpenAI的专有和成本效益的GPT-3.5 Turbo进行比较。 Mixtral-8x7B-Instruct-v0.1在从单个和多个病患文档中检索信息的任务中观察到最高的准确性。然而，所有的LLMs在处理有关否定和排序的任务时表现不佳。",
    "tldr": "LongHealth是一个具有长篇临床文档的问答基准，用于评估大型语言模型在处理真实世界中的长篇临床数据方面的能力。最高准确性观察在信息提取任务中，Mixtral-8x7B-Instruct-v0.1在从单个和多个病患文档中检索信息的任务中表现最好。"
}