{
    "title": "Contextual Feature Extraction Hierarchies Converge in Large Language Models and the Brain",
    "abstract": "Recent advancements in artificial intelligence have sparked interest in the parallels between large language models (LLMs) and human neural processing, particularly in language comprehension. While prior research has established similarities in the representation of LLMs and the brain, the underlying computational principles that cause this convergence, especially in the context of evolving LLMs, remain elusive. Here, we examined a diverse selection of high-performance LLMs with similar parameter sizes to investigate the factors contributing to their alignment with the brain's language processing mechanisms. We find that as LLMs achieve higher performance on benchmark tasks, they not only become more brain-like as measured by higher performance when predicting neural responses from LLM embeddings, but also their hierarchical feature extraction pathways map more closely onto the brain's while using fewer layers to do the same encoding. We also compare the feature extraction pathways of ",
    "link": "https://arxiv.org/abs/2401.17671",
    "context": "Title: Contextual Feature Extraction Hierarchies Converge in Large Language Models and the Brain\nAbstract: Recent advancements in artificial intelligence have sparked interest in the parallels between large language models (LLMs) and human neural processing, particularly in language comprehension. While prior research has established similarities in the representation of LLMs and the brain, the underlying computational principles that cause this convergence, especially in the context of evolving LLMs, remain elusive. Here, we examined a diverse selection of high-performance LLMs with similar parameter sizes to investigate the factors contributing to their alignment with the brain's language processing mechanisms. We find that as LLMs achieve higher performance on benchmark tasks, they not only become more brain-like as measured by higher performance when predicting neural responses from LLM embeddings, but also their hierarchical feature extraction pathways map more closely onto the brain's while using fewer layers to do the same encoding. We also compare the feature extraction pathways of ",
    "path": "papers/24/01/2401.17671.json",
    "total_tokens": 895,
    "translated_title": "在大型语言模型和大脑中，上下文特征提取层次收敛",
    "translated_abstract": "最近在人工智能方面的进展引发了对大型语言模型（LLM）和人类神经处理之间相似性的兴趣，特别是在语言理解方面。虽然之前的研究已经确定了LLM表示和大脑之间的相似之处，但在演化的LLM背景下引发这种收敛的潜在计算原理仍然不清楚。在这里，我们对一系列性能较高的LLM进行了研究，这些模型的参数大小相似，以探究导致其与大脑语言处理机制一致的因素。我们发现，当LLM在基准任务上达到更高的性能时，它们不仅在预测LLM嵌入的神经响应时表现出更高的类脑性能，而且它们的分层特征提取路径与大脑的映射更接近，并且使用更少的层次来进行相同的编码。",
    "tldr": "在研究中发现，随着大型语言模型在基准任务上的性能提高，模型不仅在预测神经响应时表现出更高的类脑性能，而且其分层特征提取路径与大脑的映射更接近，并且使用更少的层次来进行相同的编码。",
    "en_tdlr": "The study found that as large language models improve performance on benchmark tasks, they become more brain-like in predicting neural responses from model embeddings, and their hierarchical feature extraction pathways align more closely with those of the brain while using fewer layers for the same encoding."
}