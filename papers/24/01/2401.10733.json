{
    "title": "Dynamic Q&A of Clinical Documents with Large Language Models. (arXiv:2401.10733v1 [cs.IR])",
    "abstract": "Electronic health records (EHRs) house crucial patient data in clinical notes. As these notes grow in volume and complexity, manual extraction becomes challenging. This work introduces a natural language interface using large language models (LLMs) for dynamic question-answering on clinical notes. Our chatbot, powered by Langchain and transformer-based LLMs, allows users to query in natural language, receiving relevant answers from clinical notes. Experiments, utilizing various embedding models and advanced LLMs, show Wizard Vicuna's superior accuracy, albeit with high compute demands. Model optimization, including weight quantization, improves latency by approximately 48 times. Promising results indicate potential, yet challenges such as model hallucinations and limited diverse medical case evaluations remain. Addressing these gaps is crucial for unlocking the value in clinical notes and advancing AI-driven clinical decision-making.",
    "link": "http://arxiv.org/abs/2401.10733",
    "context": "Title: Dynamic Q&A of Clinical Documents with Large Language Models. (arXiv:2401.10733v1 [cs.IR])\nAbstract: Electronic health records (EHRs) house crucial patient data in clinical notes. As these notes grow in volume and complexity, manual extraction becomes challenging. This work introduces a natural language interface using large language models (LLMs) for dynamic question-answering on clinical notes. Our chatbot, powered by Langchain and transformer-based LLMs, allows users to query in natural language, receiving relevant answers from clinical notes. Experiments, utilizing various embedding models and advanced LLMs, show Wizard Vicuna's superior accuracy, albeit with high compute demands. Model optimization, including weight quantization, improves latency by approximately 48 times. Promising results indicate potential, yet challenges such as model hallucinations and limited diverse medical case evaluations remain. Addressing these gaps is crucial for unlocking the value in clinical notes and advancing AI-driven clinical decision-making.",
    "path": "papers/24/01/2401.10733.json",
    "total_tokens": 1091,
    "translated_title": "使用大型语言模型进行临床文档的动态问答",
    "translated_abstract": "电子健康记录（EHR）中收录了临床笔记中的重要患者数据。随着这些笔记数量和复杂度的增加，手动提取变得具有挑战性。本研究利用大型语言模型（LLMs）引入了一种自然语言接口，用于对临床笔记进行动态问答。我们的聊天机器人由Langchain和基于Transformer的LLMs驱动，允许用户用自然语言发出查询，并从临床笔记中获得相关答案。通过使用各种嵌入模型和先进的LLMs进行实验，结果表明Wizard Vicuna在准确性方面表现优异，尽管计算要求较高。模型优化，包括权重量化，将延迟提高了约48倍。有希望的结果显示了临床笔记中的价值潜力，但仍存在模型产生幻象和有限的多样化医疗案例评估等挑战。解决这些问题对于发掘临床笔记的价值和推动AI驱动的临床决策至关重要。",
    "tldr": "本研究介绍了一种使用大型语言模型进行临床文档动态问答的自然语言接口。通过Langchain和Transformer-based LLMs驱动的聊天机器人，用户可以用自然语言查询临床笔记并获得相关答案。实验结果显示Wizard Vicuna具有出色的准确性，但计算要求较高。模型优化方案提高了约48倍的延迟。然而，模型产生幻象和多样化医疗案例评估的限制仍然存在。解决这些挑战对于发掘临床笔记的价值和推进基于AI的临床决策至关重要。",
    "en_tdlr": "This work introduces a natural language interface using large language models (LLMs) for dynamic question-answering on clinical notes. The chatbot, powered by Langchain and transformer-based LLMs, allows users to query in natural language and receive relevant answers from clinical notes. The experiments show superior accuracy, albeit with high compute demands. Model optimization improves latency by approximately 48 times. Challenges such as model hallucinations and limited diverse medical case evaluations remain."
}