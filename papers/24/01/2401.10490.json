{
    "title": "Generalization Error Guaranteed Auto-Encoder-Based Nonlinear Model Reduction for Operator Learning. (arXiv:2401.10490v1 [cs.LG])",
    "abstract": "Many physical processes in science and engineering are naturally represented by operators between infinite-dimensional function spaces. The problem of operator learning, in this context, seeks to extract these physical processes from empirical data, which is challenging due to the infinite or high dimensionality of data. An integral component in addressing this challenge is model reduction, which reduces both the data dimensionality and problem size. In this paper, we utilize low-dimensional nonlinear structures in model reduction by investigating Auto-Encoder-based Neural Network (AENet). AENet first learns the latent variables of the input data and then learns the transformation from these latent variables to corresponding output data. Our numerical experiments validate the ability of AENet to accurately learn the solution operator of nonlinear partial differential equations. Furthermore, we establish a mathematical and statistical estimation theory that analyzes the generalization e",
    "link": "http://arxiv.org/abs/2401.10490",
    "context": "Title: Generalization Error Guaranteed Auto-Encoder-Based Nonlinear Model Reduction for Operator Learning. (arXiv:2401.10490v1 [cs.LG])\nAbstract: Many physical processes in science and engineering are naturally represented by operators between infinite-dimensional function spaces. The problem of operator learning, in this context, seeks to extract these physical processes from empirical data, which is challenging due to the infinite or high dimensionality of data. An integral component in addressing this challenge is model reduction, which reduces both the data dimensionality and problem size. In this paper, we utilize low-dimensional nonlinear structures in model reduction by investigating Auto-Encoder-based Neural Network (AENet). AENet first learns the latent variables of the input data and then learns the transformation from these latent variables to corresponding output data. Our numerical experiments validate the ability of AENet to accurately learn the solution operator of nonlinear partial differential equations. Furthermore, we establish a mathematical and statistical estimation theory that analyzes the generalization e",
    "path": "papers/24/01/2401.10490.json",
    "total_tokens": 848,
    "translated_title": "基于Auto-Encoder的非线性模型降维算法用于运算符学习的泛化误差保证",
    "translated_abstract": "在科学和工程中，许多物理过程可以自然地由无限维函数空间之间的运算符表示。在这个背景下，运算符学习的问题是从经验数据中提取这些物理过程，由于数据的无限或高维度，这是具有挑战性的。解决这个挑战的一个重要组成部分是模型降维，它可以减少数据的维度和问题的大小。在本文中，我们利用模型降维中的低维非线性结构，通过研究基于Auto-Encoder的神经网络(AENet)。AENet首先学习输入数据的潜变量，然后学习从这些潜变量到相应输出数据的转换。我们的数值实验验证了AENet准确学习非线性偏微分方程的解算符的能力。此外，我们建立了一个数学和统计估计理论，分析了泛化误差。",
    "tldr": "本文提出了一种基于Auto-Encoder的非线性模型降维算法，用于运算符学习，并且通过数值实验验证了其准确学习非线性偏微分方程的解算符的能力。",
    "en_tdlr": "This paper presents a nonlinear model reduction algorithm based on Auto-Encoder for operator learning, and validates its ability to accurately learn the solution operator of nonlinear partial differential equations through numerical experiments."
}