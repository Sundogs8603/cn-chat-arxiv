{
    "title": "Whose wife is it anyway? Assessing bias against same-gender relationships in machine translation. (arXiv:2401.04972v1 [cs.CL])",
    "abstract": "Machine translation often suffers from biased data and algorithms that can lead to unacceptable errors in system output. While bias in gender norms has been investigated, less is known about whether MT systems encode bias about social relationships, e.g. sentences such as \"the lawyer kissed her wife.\" We investigate the degree of bias against same-gender relationships in MT systems, using generated template sentences drawn from several noun-gender languages (e.g. Spanish). We find that three popular MT services consistently fail to accurately translate sentences concerning relationships between nouns of the same gender. The error rate varies considerably based on the context, e.g. same-gender sentences referencing high female-representation occupations are translated with lower accuracy. We provide this work as a case study in the evaluation of intrinsic bias in NLP systems, with respect to social relationships.",
    "link": "http://arxiv.org/abs/2401.04972",
    "context": "Title: Whose wife is it anyway? Assessing bias against same-gender relationships in machine translation. (arXiv:2401.04972v1 [cs.CL])\nAbstract: Machine translation often suffers from biased data and algorithms that can lead to unacceptable errors in system output. While bias in gender norms has been investigated, less is known about whether MT systems encode bias about social relationships, e.g. sentences such as \"the lawyer kissed her wife.\" We investigate the degree of bias against same-gender relationships in MT systems, using generated template sentences drawn from several noun-gender languages (e.g. Spanish). We find that three popular MT services consistently fail to accurately translate sentences concerning relationships between nouns of the same gender. The error rate varies considerably based on the context, e.g. same-gender sentences referencing high female-representation occupations are translated with lower accuracy. We provide this work as a case study in the evaluation of intrinsic bias in NLP systems, with respect to social relationships.",
    "path": "papers/24/01/2401.04972.json",
    "total_tokens": 986,
    "translated_title": "机器翻译中的同性关系偏见评估：它究竟是谁的妻子？",
    "translated_abstract": "机器翻译经常受到有偏见的数据和算法的困扰，这可能导致系统输出中的不可接受的错误。虽然对性别规范的偏见进行了调查研究，但对MT系统是否对社会关系编码偏见的情况了解较少，例如“律师吻了她的妻子”这样的句子。我们通过使用从几种名词性别语言（例如西班牙语）中抽取的生成模板句子，调查MT系统针对同性关系的偏见程度。我们发现三个受欢迎的MT服务在准确翻译涉及同性别名词之间关系的句子时一直存在问题。错误率根据上下文而变化很大，例如引用女性占比较高职业的同性句子的翻译准确度较低。我们提供这项工作作为研究NLP系统中固有偏见的案例研究，涉及社会关系方面的偏见评估。",
    "tldr": "本文研究了机器翻译系统对同性关系的偏见问题，发现三个受欢迎的MT服务在准确翻译涉及同性别名词之间关系的句子时存在较大的错误率，特别是在涉及女性职业的上下文中表现更差。这项工作为评估NLP系统中固有偏见提供了一个社会关系方面的案例研究。"
}