{
    "title": "Langevin Unlearning: A New Perspective of Noisy Gradient Descent for Machine Unlearning. (arXiv:2401.10371v1 [cs.LG])",
    "abstract": "Machine unlearning has raised significant interest with the adoption of laws ensuring the ``right to be forgotten''. Researchers have provided a probabilistic notion of approximate unlearning under a similar definition of Differential Privacy (DP), where privacy is defined as statistical indistinguishability to retraining from scratch. We propose Langevin unlearning, an unlearning framework based on noisy gradient descent with privacy guarantees for approximate unlearning problems. Langevin unlearning unifies the DP learning process and the privacy-certified unlearning process with many algorithmic benefits. These include approximate certified unlearning for non-convex problems, complexity saving compared to retraining, sequential and batch unlearning for multiple unlearning requests. We verify the practicality of Langevin unlearning by studying its privacy-utility-complexity trade-off via experiments on benchmark datasets, and also demonstrate its superiority against gradient-decent-p",
    "link": "http://arxiv.org/abs/2401.10371",
    "context": "Title: Langevin Unlearning: A New Perspective of Noisy Gradient Descent for Machine Unlearning. (arXiv:2401.10371v1 [cs.LG])\nAbstract: Machine unlearning has raised significant interest with the adoption of laws ensuring the ``right to be forgotten''. Researchers have provided a probabilistic notion of approximate unlearning under a similar definition of Differential Privacy (DP), where privacy is defined as statistical indistinguishability to retraining from scratch. We propose Langevin unlearning, an unlearning framework based on noisy gradient descent with privacy guarantees for approximate unlearning problems. Langevin unlearning unifies the DP learning process and the privacy-certified unlearning process with many algorithmic benefits. These include approximate certified unlearning for non-convex problems, complexity saving compared to retraining, sequential and batch unlearning for multiple unlearning requests. We verify the practicality of Langevin unlearning by studying its privacy-utility-complexity trade-off via experiments on benchmark datasets, and also demonstrate its superiority against gradient-decent-p",
    "path": "papers/24/01/2401.10371.json",
    "total_tokens": 857,
    "translated_title": "Langevin遗忘：噪声梯度下降的机器遗忘新视角",
    "translated_abstract": "随着采用确保“被遗忘权”的法律，机器遗忘引起了极大的兴趣。研究人员提供了一个概率性的近似遗忘定义，类似于差分隐私（DP）的定义，其中隐私被定义为对重新训练的统计不可区分性。我们提出了Langevin遗忘，这是一个基于噪声梯度下降的近似遗忘问题的隐私保证的遗忘框架。Langevin遗忘在算法上统一了DP学习过程和隐私认证的遗忘过程。其中包括非凸问题的近似认证遗忘，相对于重新训练的复杂度节省，以及用于多个遗忘请求的顺序和批量遗忘。我们通过在基准数据集上的实验验证了Langevin遗忘的实用性，并展示了它对梯度下降的优势。",
    "tldr": "Langevin遗忘是一种基于噪声梯度下降的遗忘框架，能够在近似遗忘问题中提供隐私保证，并且具有算法上的优势。",
    "en_tdlr": "Langevin Unlearning is a forgetting framework based on noisy gradient descent, which provides privacy guarantees for approximate forgetting problems and has algorithmic advantages."
}