{
    "title": "Data Attribution for Diffusion Models: Timestep-induced Bias in Influence Estimation. (arXiv:2401.09031v1 [cs.LG])",
    "abstract": "Data attribution methods trace model behavior back to its training dataset, offering an effective approach to better understand ``black-box'' neural networks. While prior research has established quantifiable links between model output and training data in diverse settings, interpreting diffusion model outputs in relation to training samples remains underexplored. In particular, diffusion models operate over a sequence of timesteps instead of instantaneous input-output relationships in previous contexts, posing a significant challenge to extend existing frameworks to diffusion models directly. Notably, we present Diffusion-TracIn that incorporates this temporal dynamics and observe that samples' loss gradient norms are highly dependent on timestep. This trend leads to a prominent bias in influence estimation, and is particularly noticeable for samples trained on large-norm-inducing timesteps, causing them to be generally influential. To mitigate this effect, we introduce Diffusion-ReTr",
    "link": "http://arxiv.org/abs/2401.09031",
    "context": "Title: Data Attribution for Diffusion Models: Timestep-induced Bias in Influence Estimation. (arXiv:2401.09031v1 [cs.LG])\nAbstract: Data attribution methods trace model behavior back to its training dataset, offering an effective approach to better understand ``black-box'' neural networks. While prior research has established quantifiable links between model output and training data in diverse settings, interpreting diffusion model outputs in relation to training samples remains underexplored. In particular, diffusion models operate over a sequence of timesteps instead of instantaneous input-output relationships in previous contexts, posing a significant challenge to extend existing frameworks to diffusion models directly. Notably, we present Diffusion-TracIn that incorporates this temporal dynamics and observe that samples' loss gradient norms are highly dependent on timestep. This trend leads to a prominent bias in influence estimation, and is particularly noticeable for samples trained on large-norm-inducing timesteps, causing them to be generally influential. To mitigate this effect, we introduce Diffusion-ReTr",
    "path": "papers/24/01/2401.09031.json",
    "total_tokens": 981,
    "translated_title": "数据归因对扩散模型的影响：时间步引起的对影响估计的偏差",
    "translated_abstract": "数据归因方法可以将模型行为追溯到其训练数据集，为理解“黑箱”神经网络提供了一种有效的方法。虽然先前的研究已经在各种情况下建立了模型输出与训练数据之间的可量化联系，但在与训练样本相关的扩散模型输出的解释方面仍然未被充分探索。特别是，扩散模型通过一系列时间步骤而不是之前的瞬时输入输出关系操作，对直接将现有框架扩展到扩散模型构成了重大挑战。值得注意的是，我们提出了Diffusion-TracIn，它包含了这种时间动力学，并观察到样本的损失梯度范数高度依赖于时间步骤。这种趋势导致影响估计中存在显著的偏差，对于在引发大范数时间步骤上训练的样本尤为明显，导致它们通常具有影响力。为了减轻这种影响，我们引入了Diffusion-ReTr方法。",
    "tldr": "本文研究了数据归因方法对扩散模型的影响，发现对于在引发大范数时间步骤上训练的样本，其损失梯度范数高度依赖于时间步骤，导致在影响估计中存在显著的偏差。为了解决这个问题，提出了Diffusion-ReTr方法。"
}