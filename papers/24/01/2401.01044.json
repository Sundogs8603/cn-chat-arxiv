{
    "title": "Auffusion: Leveraging the Power of Diffusion and Large Language Models for Text-to-Audio Generation. (arXiv:2401.01044v1 [cs.SD])",
    "abstract": "Recent advancements in diffusion models and large language models (LLMs) have significantly propelled the field of AIGC. Text-to-Audio (TTA), a burgeoning AIGC application designed to generate audio from natural language prompts, is attracting increasing attention. However, existing TTA studies often struggle with generation quality and text-audio alignment, especially for complex textual inputs. Drawing inspiration from state-of-the-art Text-to-Image (T2I) diffusion models, we introduce Auffusion, a TTA system adapting T2I model frameworks to TTA task, by effectively leveraging their inherent generative strengths and precise cross-modal alignment. Our objective and subjective evaluations demonstrate that Auffusion surpasses previous TTA approaches using limited data and computational resource. Furthermore, previous studies in T2I recognizes the significant impact of encoder choice on cross-modal alignment, like fine-grained details and object bindings, while similar evaluation is lack",
    "link": "http://arxiv.org/abs/2401.01044",
    "context": "Title: Auffusion: Leveraging the Power of Diffusion and Large Language Models for Text-to-Audio Generation. (arXiv:2401.01044v1 [cs.SD])\nAbstract: Recent advancements in diffusion models and large language models (LLMs) have significantly propelled the field of AIGC. Text-to-Audio (TTA), a burgeoning AIGC application designed to generate audio from natural language prompts, is attracting increasing attention. However, existing TTA studies often struggle with generation quality and text-audio alignment, especially for complex textual inputs. Drawing inspiration from state-of-the-art Text-to-Image (T2I) diffusion models, we introduce Auffusion, a TTA system adapting T2I model frameworks to TTA task, by effectively leveraging their inherent generative strengths and precise cross-modal alignment. Our objective and subjective evaluations demonstrate that Auffusion surpasses previous TTA approaches using limited data and computational resource. Furthermore, previous studies in T2I recognizes the significant impact of encoder choice on cross-modal alignment, like fine-grained details and object bindings, while similar evaluation is lack",
    "path": "papers/24/01/2401.01044.json",
    "total_tokens": 996,
    "translated_title": "Auffusion: 利用扩散和大型语言模型提升文本到音频生成的能力",
    "translated_abstract": "最近扩散模型和大型语言模型（LLM）的进展显著推动了AIGC领域的发展。文本到音频（TTA）作为一种新兴的AIGC应用，旨在从自然语言提示生成音频，引起了越来越多的关注。然而，现有的TTA研究往往在生成质量和文本-音频对齐方面存在困难，特别是对于复杂的文本输入。受到最先进的文本到图像（T2I）扩散模型的启发，我们介绍了Auffusion，一种将T2I模型框架适应TTA任务的系统，通过有效利用其固有的生成优势和精确的跨模态对齐能力。我们的客观和主观评估表明，Auffusion在使用有限的数据和计算资源时超越了之前的TTA方法。此外，之前的T2I研究认识到编码器选择对跨模态对齐的重要影响，例如细节和物体绑定，而类似的评估则缺乏。",
    "tldr": "这篇论文介绍了一种名为Auffusion的文本到音频生成系统，它利用扩散和大型语言模型，通过跨模态对齐的能力，提高了生成质量和文本-音频对齐。该系统在有限的数据和计算资源下胜过了之前的方法，并关注了编码器选择对跨模态对齐的重要性。"
}