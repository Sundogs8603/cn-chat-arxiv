{
    "title": "Balanced Multi-modal Federated Learning via Cross-Modal Infiltration. (arXiv:2401.00894v1 [cs.LG])",
    "abstract": "Federated learning (FL) underpins advancements in privacy-preserving distributed computing by collaboratively training neural networks without exposing clients' raw data. Current FL paradigms primarily focus on uni-modal data, while exploiting the knowledge from distributed multimodal data remains largely unexplored. Existing multimodal FL (MFL) solutions are mainly designed for statistical or modality heterogeneity from the input side, however, have yet to solve the fundamental issue,\"modality imbalance\", in distributed conditions, which can lead to inadequate information exploitation and heterogeneous knowledge aggregation on different modalities.In this paper, we propose a novel Cross-Modal Infiltration Federated Learning (FedCMI) framework that effectively alleviates modality imbalance and knowledge heterogeneity via knowledge transfer from the global dominant modality. To avoid the loss of information in the weak modality due to merely imitating the behavior of dominant modality, ",
    "link": "http://arxiv.org/abs/2401.00894",
    "context": "Title: Balanced Multi-modal Federated Learning via Cross-Modal Infiltration. (arXiv:2401.00894v1 [cs.LG])\nAbstract: Federated learning (FL) underpins advancements in privacy-preserving distributed computing by collaboratively training neural networks without exposing clients' raw data. Current FL paradigms primarily focus on uni-modal data, while exploiting the knowledge from distributed multimodal data remains largely unexplored. Existing multimodal FL (MFL) solutions are mainly designed for statistical or modality heterogeneity from the input side, however, have yet to solve the fundamental issue,\"modality imbalance\", in distributed conditions, which can lead to inadequate information exploitation and heterogeneous knowledge aggregation on different modalities.In this paper, we propose a novel Cross-Modal Infiltration Federated Learning (FedCMI) framework that effectively alleviates modality imbalance and knowledge heterogeneity via knowledge transfer from the global dominant modality. To avoid the loss of information in the weak modality due to merely imitating the behavior of dominant modality, ",
    "path": "papers/24/01/2401.00894.json",
    "total_tokens": 900,
    "translated_title": "通过跨模态渗透实现平衡多模态联邦学习",
    "translated_abstract": "联邦学习是隐私保护分布式计算的基础，通过协同训练神经网络而不暴露客户端的原始数据。当前的联邦学习主要关注单一模态数据，而对于分布式多模态数据的知识利用仍然未被充分探索。现有的多模态联邦学习解决方案主要针对输入端的统计或模态异质性，然而在分布式环境中尚未解决\"模态不平衡\"的根本问题，这可能导致对不同模态的信息利用不足和异质知识聚合。本文提出了一种新颖的跨模态渗透联邦学习（FedCMI）框架，通过从全局主导模态进行知识传递，有效缓解模态不平衡和知识异质性问题。为了避免仅仅模仿主导模态行为导致弱模态信息的丢失，我们提出了一种注意力机制来选择性地传递知识。",
    "tldr": "该论文提出了一种通过从全局主导模态进行知识传递的跨模态渗透联邦学习框架，有效解决了分布式环境中的模态不平衡和知识异质性问题。"
}