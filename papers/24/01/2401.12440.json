{
    "title": "Post-Training Embedding Alignment for Decoupling Enrollment and Runtime Speaker Recognition Models. (arXiv:2401.12440v1 [eess.AS])",
    "abstract": "Automated speaker identification (SID) is a crucial step for the personalization of a wide range of speech-enabled services. Typical SID systems use a symmetric enrollment-verification framework with a single model to derive embeddings both offline for voice profiles extracted from enrollment utterances, and online from runtime utterances. Due to the distinct circumstances of enrollment and runtime, such as different computation and latency constraints, several applications would benefit from an asymmetric enrollment-verification framework that uses different models for enrollment and runtime embedding generation. To support this asymmetric SID where each of the two models can be updated independently, we propose using a lightweight neural network to map the embeddings from the two independent models to a shared speaker embedding space. Our results show that this approach significantly outperforms cosine scoring in a shared speaker logit space for models that were trained with a contra",
    "link": "http://arxiv.org/abs/2401.12440",
    "context": "Title: Post-Training Embedding Alignment for Decoupling Enrollment and Runtime Speaker Recognition Models. (arXiv:2401.12440v1 [eess.AS])\nAbstract: Automated speaker identification (SID) is a crucial step for the personalization of a wide range of speech-enabled services. Typical SID systems use a symmetric enrollment-verification framework with a single model to derive embeddings both offline for voice profiles extracted from enrollment utterances, and online from runtime utterances. Due to the distinct circumstances of enrollment and runtime, such as different computation and latency constraints, several applications would benefit from an asymmetric enrollment-verification framework that uses different models for enrollment and runtime embedding generation. To support this asymmetric SID where each of the two models can be updated independently, we propose using a lightweight neural network to map the embeddings from the two independent models to a shared speaker embedding space. Our results show that this approach significantly outperforms cosine scoring in a shared speaker logit space for models that were trained with a contra",
    "path": "papers/24/01/2401.12440.json",
    "total_tokens": 887,
    "translated_title": "用于解耦注册和运行时说话人识别模型的后训练嵌入对齐",
    "translated_abstract": "自动说话人识别是个人化广泛语音服务的关键步骤。传统的说话人识别系统使用对称的注册-验证框架，在一个模型中从注册语音中离线提取嵌入，同时从运行时语音中在线提取嵌入。由于注册和运行时的不同情况，如计算和延迟约束的差异，一些应用程序会从采用不对称的注册-验证框架中获益，这种框架使用不同模型进行注册和运行时的嵌入生成。为了支持这种不对称的说话人识别，其中的两个模型可以独立更新，我们提出使用轻量级神经网络将两个独立模型的嵌入映射到共享的说话人嵌入空间。我们的结果表明，这种方法在共享说话人逻辑空间中显著优于余弦相似度计算，这些计算是使用反向训练的模型进行。",
    "tldr": "该论文提出了一种后训练嵌入对齐的方法，用于解决注册和运行时说话人识别模型耦合的问题。实验结果表明，这种方法在共享说话人嵌入空间中明显优于传统的余弦相似度计算方法。"
}