{
    "title": "Brave: Byzantine-Resilient and Privacy-Preserving Peer-to-Peer Federated Learning. (arXiv:2401.05562v1 [cs.LG])",
    "abstract": "Federated learning (FL) enables multiple participants to train a global machine learning model without sharing their private training data. Peer-to-peer (P2P) FL advances existing centralized FL paradigms by eliminating the server that aggregates local models from participants and then updates the global model. However, P2P FL is vulnerable to (i) honest-but-curious participants whose objective is to infer private training data of other participants, and (ii) Byzantine participants who can transmit arbitrarily manipulated local models to corrupt the learning process. P2P FL schemes that simultaneously guarantee Byzantine resilience and preserve privacy have been less studied. In this paper, we develop Brave, a protocol that ensures Byzantine Resilience And privacy-preserving property for P2P FL in the presence of both types of adversaries. We show that Brave preserves privacy by establishing that any honest-but-curious adversary cannot infer other participants' private data by observin",
    "link": "http://arxiv.org/abs/2401.05562",
    "context": "Title: Brave: Byzantine-Resilient and Privacy-Preserving Peer-to-Peer Federated Learning. (arXiv:2401.05562v1 [cs.LG])\nAbstract: Federated learning (FL) enables multiple participants to train a global machine learning model without sharing their private training data. Peer-to-peer (P2P) FL advances existing centralized FL paradigms by eliminating the server that aggregates local models from participants and then updates the global model. However, P2P FL is vulnerable to (i) honest-but-curious participants whose objective is to infer private training data of other participants, and (ii) Byzantine participants who can transmit arbitrarily manipulated local models to corrupt the learning process. P2P FL schemes that simultaneously guarantee Byzantine resilience and preserve privacy have been less studied. In this paper, we develop Brave, a protocol that ensures Byzantine Resilience And privacy-preserving property for P2P FL in the presence of both types of adversaries. We show that Brave preserves privacy by establishing that any honest-but-curious adversary cannot infer other participants' private data by observin",
    "path": "papers/24/01/2401.05562.json",
    "total_tokens": 938,
    "translated_title": "Brave：具有拜占庭容错和隐私保护的点对点联邦学习",
    "translated_abstract": "联邦学习使多个参与者在不共享个人训练数据的情况下训练全局机器学习模型。点对点联邦学习通过消除从参与者那里聚合本地模型并更新全局模型的服务器来推进现有的集中式联邦学习范式。然而，点对点联邦学习容易受到两种类型的对手的攻击：（i）对私有训练数据进行推断的真诚但好奇的参与者，以及（ii）能够传输任意操纵的本地模型来破坏学习过程的拜占庭参与者。同时保证拜占庭容错和隐私保护的点对点联邦学习方案研究较少。在本文中，我们开发了一种名为Brave的协议，该协议在两种类型的对手存在时确保点对点联邦学习的拜占庭容错和隐私保护属性。我们通过证明任何真诚但好奇的对手不能通过观察来推断其他参与者的私有数据，来展示Brave可以保护隐私。",
    "tldr": "本文开发了一种名为Brave的协议，具有拜占庭容错和隐私保护的点对点联邦学习，保护了参与者的隐私并防止对手破坏学习过程。"
}