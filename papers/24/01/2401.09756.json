{
    "title": "Explaining Drift using Shapley Values. (arXiv:2401.09756v1 [cs.LG])",
    "abstract": "Machine learning models often deteriorate in their performance when they are used to predict the outcomes over data on which they were not trained. These scenarios can often arise in real world when the distribution of data changes gradually or abruptly due to major events like a pandemic. There have been many attempts in machine learning research to come up with techniques that are resilient to such Concept drifts. However, there is no principled framework to identify the drivers behind the drift in model performance. In this paper, we propose a novel framework - DBShap that uses Shapley values to identify the main contributors of the drift and quantify their respective contributions. The proposed framework not only quantifies the importance of individual features in driving the drift but also includes the change in the underlying relation between the input and output as a possible driver. The explanation provided by DBShap can be used to understand the root cause behind the drift and",
    "link": "http://arxiv.org/abs/2401.09756",
    "context": "Title: Explaining Drift using Shapley Values. (arXiv:2401.09756v1 [cs.LG])\nAbstract: Machine learning models often deteriorate in their performance when they are used to predict the outcomes over data on which they were not trained. These scenarios can often arise in real world when the distribution of data changes gradually or abruptly due to major events like a pandemic. There have been many attempts in machine learning research to come up with techniques that are resilient to such Concept drifts. However, there is no principled framework to identify the drivers behind the drift in model performance. In this paper, we propose a novel framework - DBShap that uses Shapley values to identify the main contributors of the drift and quantify their respective contributions. The proposed framework not only quantifies the importance of individual features in driving the drift but also includes the change in the underlying relation between the input and output as a possible driver. The explanation provided by DBShap can be used to understand the root cause behind the drift and",
    "path": "papers/24/01/2401.09756.json",
    "total_tokens": 888,
    "translated_title": "使用Shapley值解释漂移",
    "translated_abstract": "当机器学习模型被用于预测其未训练数据的结果时，其性能常常会下降。这种情况在现实世界中经常发生，因为数据的分布会逐渐或突然地发生变化，或由于像大流行病这样的重大事件。在机器学习研究中，已经有许多尝试提出能够抵御这种概念漂移的技术。然而，没有一个原则性的框架来确定导致模型性能漂移的原因。在本文中，我们提出了一个新颖的框架-DBShap，它使用Shapley值来确定漂移的主要贡献者并量化他们的贡献。所提出的框架不仅量化了单个特征在驱动漂移方面的重要性，还包括了输入和输出之间底层关系的变化作为可能的驱动因素。DBShap所提供的解释可以用于理解漂移背后的根本原因。",
    "tldr": "本文提出了一个新的框架-DBShap，使用Shapley值来确定模型性能漂移的主要贡献者并量化他们的贡献。通过DBShap提供的解释，可以理解漂移背后的根本原因。",
    "en_tdlr": "This paper proposes a novel framework, DBShap, which uses Shapley values to identify the main contributors of model performance drift and quantify their contributions. The explanation provided by DBShap can be used to understand the root cause behind the drift."
}