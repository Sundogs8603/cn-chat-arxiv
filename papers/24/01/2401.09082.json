{
    "title": "What makes for a 'good' social actor? Using respect as a lens to evaluate interactions with language agents. (arXiv:2401.09082v1 [cs.CL])",
    "abstract": "With the growing popularity of dialogue agents based on large language models (LLMs), urgent attention has been drawn to finding ways to ensure their behaviour is ethical and appropriate. These are largely interpreted in terms of the 'HHH' criteria: making outputs more helpful and honest, and avoiding harmful (biased, toxic, or inaccurate) statements. Whilst this semantic focus is useful from the perspective of viewing LLM agents as mere mediums for information, it fails to account for pragmatic factors that can make the same utterance seem more or less offensive or tactless in different social situations. We propose an approach to ethics that is more centred on relational and situational factors, exploring what it means for a system, as a social actor, to treat an individual respectfully in a (series of) interaction(s). Our work anticipates a set of largely unexplored risks at the level of situated interaction, and offers practical suggestions to help LLM technologies behave as 'good'",
    "link": "http://arxiv.org/abs/2401.09082",
    "context": "Title: What makes for a 'good' social actor? Using respect as a lens to evaluate interactions with language agents. (arXiv:2401.09082v1 [cs.CL])\nAbstract: With the growing popularity of dialogue agents based on large language models (LLMs), urgent attention has been drawn to finding ways to ensure their behaviour is ethical and appropriate. These are largely interpreted in terms of the 'HHH' criteria: making outputs more helpful and honest, and avoiding harmful (biased, toxic, or inaccurate) statements. Whilst this semantic focus is useful from the perspective of viewing LLM agents as mere mediums for information, it fails to account for pragmatic factors that can make the same utterance seem more or less offensive or tactless in different social situations. We propose an approach to ethics that is more centred on relational and situational factors, exploring what it means for a system, as a social actor, to treat an individual respectfully in a (series of) interaction(s). Our work anticipates a set of largely unexplored risks at the level of situated interaction, and offers practical suggestions to help LLM technologies behave as 'good'",
    "path": "papers/24/01/2401.09082.json",
    "total_tokens": 927,
    "translated_title": "什么是“好”的社交行为者？以尊重为视角评估与语言代理的交互",
    "translated_abstract": "随着基于大型语言模型（LLM）的对话代理越来越受欢迎，如何确保它们的行为道德和适当性已经引起了紧急关注。从“HHH”标准的角度来看，这主要体现在让输出更有帮助和诚实，并避免有害（有偏见、有毒或不准确）的陈述。虽然这种语义焦点对于将LLM代理视为纯粹的信息媒介是有用的，但它未能考虑到在不同社交情境中，同样的话语可能会显得更或者更少冒犯或不得体的实际因素。我们提出了一种更加关注关系和情境因素的伦理方法，探讨作为社交行为者的系统如何在交互中以尊重的方式对待个体。我们的工作预见了在情境交互层面上一系列尚未被探索的风险，并提供了实用建议，以帮助LLM技术表现得“好”",
    "tldr": "本文研究以尊重为视角评估与语言代理的交互，提出了一种更加关注关系和情境因素的伦理方法，旨在帮助LLM技术表现得“好”",
    "en_tdlr": "This paper explores the evaluation of interactions with language agents from the perspective of respect and proposes an ethics approach that considers relational and situational factors, aiming to help LLM technologies behave ethically and appropriately."
}