{
    "title": "SERNet-Former: Semantic Segmentation by Efficient Residual Network with Attention-Boosting Gates and Attention-Fusion Networks",
    "abstract": "Improving the efficiency of state-of-the-art methods in semantic segmentation requires overcoming the increasing computational cost as well as issues such as fusing semantic information from global and local contexts. Based on the recent success and problems that convolutional neural networks (CNNs) encounter in semantic segmentation, this research proposes an encoder-decoder architecture with a unique efficient residual network. Attention-boosting gates (AbGs) and attention-boosting modules (AbMs) are deployed by aiming to fuse the feature-based semantic information with the global context of the efficient residual network in the encoder. Respectively, the decoder network is developed with the additional attention-fusion networks (AfNs) inspired by AbM. AfNs are designed to improve the efficiency in the one-to-one conversion of the semantic information by deploying additional convolution layers in the decoder part. Our network is tested on the challenging CamVid and Cityscapes dataset",
    "link": "https://arxiv.org/abs/2401.15741",
    "context": "Title: SERNet-Former: Semantic Segmentation by Efficient Residual Network with Attention-Boosting Gates and Attention-Fusion Networks\nAbstract: Improving the efficiency of state-of-the-art methods in semantic segmentation requires overcoming the increasing computational cost as well as issues such as fusing semantic information from global and local contexts. Based on the recent success and problems that convolutional neural networks (CNNs) encounter in semantic segmentation, this research proposes an encoder-decoder architecture with a unique efficient residual network. Attention-boosting gates (AbGs) and attention-boosting modules (AbMs) are deployed by aiming to fuse the feature-based semantic information with the global context of the efficient residual network in the encoder. Respectively, the decoder network is developed with the additional attention-fusion networks (AfNs) inspired by AbM. AfNs are designed to improve the efficiency in the one-to-one conversion of the semantic information by deploying additional convolution layers in the decoder part. Our network is tested on the challenging CamVid and Cityscapes dataset",
    "path": "papers/24/01/2401.15741.json",
    "total_tokens": 927,
    "translated_title": "SERNet-Former: 带有注意力增强门和注意力融合网络的高效剩余网络语义分割方法",
    "translated_abstract": "在语义分割领域，改善最先进方法的效率需要解决不断增长的计算成本以及从全局和局部上融合语义信息的问题。基于最近在语义分割中卷积神经网络（CNN）的成功和问题，本研究提出了一种带有独特高效剩余网络的编码器-解码器架构。通过引入注意力增强门（AbGs）和注意力增强模块（AbMs），目标是在编码器中将基于特征的语义信息与高效剩余网络的全局上下文相结合。同时，在解码器部分采用了受到AbM启发的额外注意力融合网络（AfNs）。AfNs旨在通过在解码器部分部署额外的卷积层，改善语义信息的逐一转换的效率。我们将网络在具有挑战性的CamVid和Cityscapes数据集上进行了测试。",
    "tldr": "这篇论文提出了一种名为SERNet-Former的高效剩余网络语义分割方法。它通过引入注意力增强门和注意力融合网络来改善语义分割方法的效率，并解决了从全局和局部上融合语义信息的问题。实验结果表明，该方法在挑战性的数据集上取得了良好的性能。",
    "en_tdlr": "This paper proposes a semantic segmentation method called SERNet-Former, which utilizes an efficient residual network and attention-boosting gates to improve the efficiency of state-of-the-art methods in semantic segmentation and addresses the fusion of semantic information from global and local contexts. Experimental results demonstrate the effectiveness of the proposed method on challenging datasets."
}