{
    "title": "Reliability and Interpretability in Science and Deep Learning",
    "abstract": "In recent years, the question of the reliability of Machine Learning (ML) methods has acquired significant importance, and the analysis of the associated uncertainties has motivated a growing amount of research. However, most of these studies have applied standard error analysis to ML models, and in particular Deep Neural Network (DNN) models, which represent a rather significant departure from standard scientific modelling. It is therefore necessary to integrate the standard error analysis with a deeper epistemological analysis of the possible differences between DNN models and standard scientific modelling and the possible implications of these differences in the assessment of reliability. This article offers several contributions. First, it emphasises the ubiquitous role of model assumptions (both in ML and traditional Science) against the illusion of theory-free science. Secondly, model assumptions are analysed from the point of view of their (epistemic) complexity, which is shown ",
    "link": "https://arxiv.org/abs/2401.07359",
    "context": "Title: Reliability and Interpretability in Science and Deep Learning\nAbstract: In recent years, the question of the reliability of Machine Learning (ML) methods has acquired significant importance, and the analysis of the associated uncertainties has motivated a growing amount of research. However, most of these studies have applied standard error analysis to ML models, and in particular Deep Neural Network (DNN) models, which represent a rather significant departure from standard scientific modelling. It is therefore necessary to integrate the standard error analysis with a deeper epistemological analysis of the possible differences between DNN models and standard scientific modelling and the possible implications of these differences in the assessment of reliability. This article offers several contributions. First, it emphasises the ubiquitous role of model assumptions (both in ML and traditional Science) against the illusion of theory-free science. Secondly, model assumptions are analysed from the point of view of their (epistemic) complexity, which is shown ",
    "path": "papers/24/01/2401.07359.json",
    "total_tokens": 859,
    "translated_title": "科学与深度学习中的可靠性和解释性",
    "translated_abstract": "近年来，机器学习（ML）方法的可靠性问题日益重要，并且与此相关的不确定性分析已经激发了大量的研究。然而，大部分研究都仅将标准错误分析应用于深度神经网络（DNN）模型，这在很大程度上与标准科学建模有所不同。因此，有必要将标准错误分析与对DNN模型与标准科学建模的可能差异以及这些差异在可靠性评估中可能产生的影响的更深层次的认识论分析相结合。本文提供了几个贡献。首先，强调了模型假设（在ML和传统科学中均存在）在无理论科学的错觉下的普遍作用。其次，从（认识论的）复杂性角度分析了模型假设，同时还展示了模型假设在可靠性评估中的作用。",
    "tldr": "这篇论文强调了科学与深度学习中模型假设的重要性，并提供了对模型假设认识论复杂性的分析，同时结合标准错误分析与深度神经网络模型的特点，来评估模型可靠性。",
    "en_tdlr": "This paper emphasizes the importance of model assumptions in science and deep learning and provides an analysis of the epistemological complexity of these assumptions. It integrates standard error analysis with the unique characteristics of deep neural network models to assess model reliability."
}