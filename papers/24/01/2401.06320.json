{
    "title": "Zero-shot Generative Large Language Models for Systematic Review Screening Automation. (arXiv:2401.06320v1 [cs.IR])",
    "abstract": "Systematic reviews are crucial for evidence-based medicine as they comprehensively analyse published research findings on specific questions. Conducting such reviews is often resource- and time-intensive, especially in the screening phase, where abstracts of publications are assessed for inclusion in a review. This study investigates the effectiveness of using zero-shot large language models~(LLMs) for automatic screening. We evaluate the effectiveness of eight different LLMs and investigate a calibration technique that uses a predefined recall threshold to determine whether a publication should be included in a systematic review. Our comprehensive evaluation using five standard test collections shows that instruction fine-tuning plays an important role in screening, that calibration renders LLMs practical for achieving a targeted recall, and that combining both with an ensemble of zero-shot models saves significant screening time compared to state-of-the-art approaches.",
    "link": "http://arxiv.org/abs/2401.06320",
    "context": "Title: Zero-shot Generative Large Language Models for Systematic Review Screening Automation. (arXiv:2401.06320v1 [cs.IR])\nAbstract: Systematic reviews are crucial for evidence-based medicine as they comprehensively analyse published research findings on specific questions. Conducting such reviews is often resource- and time-intensive, especially in the screening phase, where abstracts of publications are assessed for inclusion in a review. This study investigates the effectiveness of using zero-shot large language models~(LLMs) for automatic screening. We evaluate the effectiveness of eight different LLMs and investigate a calibration technique that uses a predefined recall threshold to determine whether a publication should be included in a systematic review. Our comprehensive evaluation using five standard test collections shows that instruction fine-tuning plays an important role in screening, that calibration renders LLMs practical for achieving a targeted recall, and that combining both with an ensemble of zero-shot models saves significant screening time compared to state-of-the-art approaches.",
    "path": "papers/24/01/2401.06320.json",
    "total_tokens": 884,
    "translated_title": "零样本生成式大型语言模型用于系统性综述筛选自动化",
    "translated_abstract": "系统性综述对于基于证据的医学非常重要，它们综合分析了特定问题的已发表研究结果。进行此类综述通常需要大量的资源和时间，特别是在筛选阶段，需要评估出版物摘要是否应包括在综述中。本研究调查了使用零样本大型语言模型（LLM）进行自动筛选的有效性。我们评估了八种不同的LLM的效果，并研究了一种使用预定义的召回阈值的校准技术，用于确定是否应将出版物包括在系统性综述中。我们的全面评估使用了五个标准测试集，结果显示指导微调在筛选中起到了重要作用，校准使LLMs在实现目标召回方面更实用，并且将这两者与零样本模型的集成相结合与现有技术相比节省了大量筛选时间。",
    "tldr": "本研究调查了使用零样本生成式大型语言模型进行系统性综述自动筛选的有效性，结果显示指导微调和校准技术在筛选中起到重要作用，并且与零样本模型的集成相结合可以显著节省筛选时间。"
}