{
    "title": "Prompt-RAG: Pioneering Vector Embedding-Free Retrieval-Augmented Generation in Niche Domains, Exemplified by Korean Medicine. (arXiv:2401.11246v1 [cs.CL])",
    "abstract": "We propose a natural language prompt-based retrieval augmented generation (Prompt-RAG), a novel approach to enhance the performance of generative large language models (LLMs) in niche domains. Conventional RAG methods mostly require vector embeddings, yet the suitability of generic LLM-based embedding representations for specialized domains remains uncertain. To explore and exemplify this point, we compared vector embeddings from Korean Medicine (KM) and Conventional Medicine (CM) documents, finding that KM document embeddings correlated more with token overlaps and less with human-assessed document relatedness, in contrast to CM embeddings. Prompt-RAG, distinct from conventional RAG models, operates without the need for embedding vectors. Its performance was assessed through a Question-Answering (QA) chatbot application, where responses were evaluated for relevance, readability, and informativeness. The results showed that Prompt-RAG outperformed existing models, including ChatGPT and",
    "link": "http://arxiv.org/abs/2401.11246",
    "context": "Title: Prompt-RAG: Pioneering Vector Embedding-Free Retrieval-Augmented Generation in Niche Domains, Exemplified by Korean Medicine. (arXiv:2401.11246v1 [cs.CL])\nAbstract: We propose a natural language prompt-based retrieval augmented generation (Prompt-RAG), a novel approach to enhance the performance of generative large language models (LLMs) in niche domains. Conventional RAG methods mostly require vector embeddings, yet the suitability of generic LLM-based embedding representations for specialized domains remains uncertain. To explore and exemplify this point, we compared vector embeddings from Korean Medicine (KM) and Conventional Medicine (CM) documents, finding that KM document embeddings correlated more with token overlaps and less with human-assessed document relatedness, in contrast to CM embeddings. Prompt-RAG, distinct from conventional RAG models, operates without the need for embedding vectors. Its performance was assessed through a Question-Answering (QA) chatbot application, where responses were evaluated for relevance, readability, and informativeness. The results showed that Prompt-RAG outperformed existing models, including ChatGPT and",
    "path": "papers/24/01/2401.11246.json",
    "total_tokens": 942,
    "translated_title": "Prompt-RAG: 在小众领域中的基于向量嵌入的检索增强生成的开创性研究，以韩医学为例",
    "translated_abstract": "我们提出了一种基于自然语言提示的检索增强生成（Prompt-RAG）的新方法，旨在增强大型语言模型（LLM）在小众领域中的性能。传统的RAG方法大多需要向量嵌入，然而通用的LLM基于嵌入表示对于专业领域的适用性仍然不确定。为了探索和举例说明这一点，我们比较了韩医学（KM）和传统医学（CM）文档的向量嵌入，发现KM文档的嵌入与标记重叠相关性更强，与人工评估的文档相关性较小，而CM文档则相反。Prompt-RAG与传统的RAG模型不同，它不需要嵌入向量。通过问答机器人应用程序对其性能进行了评估，其中回答的相关性、可读性和信息性进行了评估。结果表明，Prompt-RAG优于现有模型，包括ChatGPT和...",
    "tldr": "Prompt-RAG是一种在小众领域中增强了大型语言模型性能的新方法，与传统的RAG模型不同，它不需要使用嵌入向量。通过问答机器人应用程序的评估，结果表明Prompt-RAG优于现有模型，包括ChatGPT。",
    "en_tdlr": "Prompt-RAG is a novel approach that enhances the performance of large language models in niche domains without the need for embedding vectors. Evaluation results from a question-answering chatbot application show that Prompt-RAG outperforms existing models, including ChatGPT."
}