{
    "title": "Can AI Assistants Know What They Don't Know?. (arXiv:2401.13275v1 [cs.CL])",
    "abstract": "Recently, AI assistants based on large language models (LLMs) show surprising performance in many tasks, such as dialogue, solving math problems, writing code, and using tools. Although LLMs possess intensive world knowledge, they still make factual errors when facing some knowledge intensive tasks, like open-domain question answering. These untruthful responses from the AI assistant may cause significant risks in practical applications. We believe that an AI assistant's refusal to answer questions it does not know is a crucial method for reducing hallucinations and making the assistant truthful. Therefore, in this paper, we ask the question \"Can AI assistants know what they don't know and express them through natural language?\" To answer this question, we construct a model-specific \"I don't know\" (Idk) dataset for an assistant, which contains its known and unknown questions, based on existing open-domain question answering datasets. Then we align the assistant with its corresponding I",
    "link": "http://arxiv.org/abs/2401.13275",
    "context": "Title: Can AI Assistants Know What They Don't Know?. (arXiv:2401.13275v1 [cs.CL])\nAbstract: Recently, AI assistants based on large language models (LLMs) show surprising performance in many tasks, such as dialogue, solving math problems, writing code, and using tools. Although LLMs possess intensive world knowledge, they still make factual errors when facing some knowledge intensive tasks, like open-domain question answering. These untruthful responses from the AI assistant may cause significant risks in practical applications. We believe that an AI assistant's refusal to answer questions it does not know is a crucial method for reducing hallucinations and making the assistant truthful. Therefore, in this paper, we ask the question \"Can AI assistants know what they don't know and express them through natural language?\" To answer this question, we construct a model-specific \"I don't know\" (Idk) dataset for an assistant, which contains its known and unknown questions, based on existing open-domain question answering datasets. Then we align the assistant with its corresponding I",
    "path": "papers/24/01/2401.13275.json",
    "total_tokens": 901,
    "translated_title": "AI助手是否能知道自己不知道的事情?",
    "translated_abstract": "最近，基于大型语言模型（LLMs）的AI助手在对话、解决数学问题、编写代码和使用工具等许多任务中表现出令人惊讶的性能。尽管LLMs具有深入的世界知识，但在面对某些知识密集型任务（如开放领域问答）时仍然会出现事实错误。AI助手的这种不真实回答可能在实际应用中造成重大风险。我们认为，AI助手拒绝回答自己不知道的问题是减少幻觉和使助手真实的关键方法。因此，在本文中，我们提出问题“AI助手是否能知道自己不知道的事情，并通过自然语言表达出来？”为了回答这个问题，我们为助手构建了一个特定模型的“I don't know”(Idk)数据集，其中包含了已知和未知的问题，基于现有的开放领域问答数据集。然后我们将助手与其相应的Idk数据进行对齐。",
    "tldr": "本文研究了AI助手是否能知道自己不知道的事情，并通过自然语言表达出来的问题。为了回答这个问题，我们构建了一个特定模型的\"I don't know\"（Idk）数据集，并与AI助手进行对齐。",
    "en_tdlr": "This paper investigates whether AI assistants can know what they don't know and express it in natural language. To answer this question, a model-specific \"I don't know\" (Idk) dataset is constructed and aligned with the assistant."
}