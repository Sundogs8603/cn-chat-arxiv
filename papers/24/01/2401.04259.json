{
    "title": "MARG: Multi-Agent Review Generation for Scientific Papers. (arXiv:2401.04259v1 [cs.CL])",
    "abstract": "We study the ability of LLMs to generate feedback for scientific papers and develop MARG, a feedback generation approach using multiple LLM instances that engage in internal discussion. By distributing paper text across agents, MARG can consume the full text of papers beyond the input length limitations of the base LLM, and by specializing agents and incorporating sub-tasks tailored to different comment types (experiments, clarity, impact) it improves the helpfulness and specificity of feedback. In a user study, baseline methods using GPT-4 were rated as producing generic or very generic comments more than half the time, and only 1.7 comments per paper were rated as good overall in the best baseline. Our system substantially improves the ability of GPT-4 to generate specific and helpful feedback, reducing the rate of generic comments from 60% to 29% and generating 3.7 good comments per paper (a 2.2x improvement).",
    "link": "http://arxiv.org/abs/2401.04259",
    "context": "Title: MARG: Multi-Agent Review Generation for Scientific Papers. (arXiv:2401.04259v1 [cs.CL])\nAbstract: We study the ability of LLMs to generate feedback for scientific papers and develop MARG, a feedback generation approach using multiple LLM instances that engage in internal discussion. By distributing paper text across agents, MARG can consume the full text of papers beyond the input length limitations of the base LLM, and by specializing agents and incorporating sub-tasks tailored to different comment types (experiments, clarity, impact) it improves the helpfulness and specificity of feedback. In a user study, baseline methods using GPT-4 were rated as producing generic or very generic comments more than half the time, and only 1.7 comments per paper were rated as good overall in the best baseline. Our system substantially improves the ability of GPT-4 to generate specific and helpful feedback, reducing the rate of generic comments from 60% to 29% and generating 3.7 good comments per paper (a 2.2x improvement).",
    "path": "papers/24/01/2401.04259.json",
    "total_tokens": 840,
    "translated_title": "MARG：多智能体为科学论文生成评论的方法",
    "translated_abstract": "我们研究了语言模型（LLMs）生成科学论文反馈的能力，并开发了MARG，一种使用多个LLM实例进行内部讨论的反馈生成方法。通过将论文文本分配给智能体，MARG可以消化超出基本LLM输入长度限制的完整论文文本，并通过专门化智能体和结合适合不同评论类型的子任务（实验，清晰度，影响力），提高反馈的有用性和特定性。在一项用户研究中，使用GPT-4的基准方法的评论被评为超过一半时间产生的是普通或非常普通的评论，最佳基准方法中每篇论文只被评为1.7条整体上好的评论。我们的系统大大提高了GPT-4生成具体和有用反馈的能力，将普通评论的比例从60%降低到29%，每篇论文产生3.7条好的评论（提高了2.2倍）。",
    "tldr": "MARG是一种使用多智能体模型进行内部讨论的方法，通过分配不同的子任务提高了GPT-4生成具体和有用反馈的能力。",
    "en_tdlr": "MARG is an approach that utilizes multiple LLM instances for internal discussion, improving the ability of GPT-4 to generate specific and helpful feedback by distributing different sub-tasks."
}