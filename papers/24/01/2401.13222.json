{
    "title": "It's About Time: Incorporating Temporality in Retrieval Augmented Language Models. (arXiv:2401.13222v1 [cs.IR])",
    "abstract": "The web serves as a global repository of knowledge, used by billions of people to search for information. Ensuring that users receive the most relevant and up-to-date information, especially in the presence of multiple versions of web content from different time points remains a critical challenge for information retrieval. This challenge has recently been compounded by the increased use of question answering tools trained on Wikipedia or web content and powered by large language models (LLMs) \\citep{chatgpt} which have been found to make up information (or hallucinate), and in addition have been shown to struggle with the temporal dimensions of information. Even Retriever Augmented Language Models (RALMs) which incorporate a document database to reduce LLM hallucination are unable to handle temporal queries correctly. This leads to instances where RALMs respond to queries such as \"Who won the Wimbledon Championship?\", by retrieving document passages related to Wimbledon but without th",
    "link": "http://arxiv.org/abs/2401.13222",
    "context": "Title: It's About Time: Incorporating Temporality in Retrieval Augmented Language Models. (arXiv:2401.13222v1 [cs.IR])\nAbstract: The web serves as a global repository of knowledge, used by billions of people to search for information. Ensuring that users receive the most relevant and up-to-date information, especially in the presence of multiple versions of web content from different time points remains a critical challenge for information retrieval. This challenge has recently been compounded by the increased use of question answering tools trained on Wikipedia or web content and powered by large language models (LLMs) \\citep{chatgpt} which have been found to make up information (or hallucinate), and in addition have been shown to struggle with the temporal dimensions of information. Even Retriever Augmented Language Models (RALMs) which incorporate a document database to reduce LLM hallucination are unable to handle temporal queries correctly. This leads to instances where RALMs respond to queries such as \"Who won the Wimbledon Championship?\", by retrieving document passages related to Wimbledon but without th",
    "path": "papers/24/01/2401.13222.json",
    "total_tokens": 815,
    "translated_title": "关于时间的重要性：在检索增强语言模型中引入时间性",
    "translated_abstract": "网络作为全球的知识存储库，被数十亿人用于搜索信息。确保用户能够获得最相关和最新的信息是信息检索面临的关键挑战，尤其是在存在来自不同时间点的多个版本的网络内容的情况下。最近，这个挑战变得更加复杂，原因是对维基百科或网络内容进行训练的问答工具的增加使用，这些工具由大型语言模型（LLM）驱动，而这些模型被发现会虚构信息，且在处理时间信息方面存在困难。即使是引入文档数据库以减少LLM虚构的检索增强语言模型（RALM）也无法正确处理时间查询。这导致RALM在回答类似“谁赢得了温网冠军？”的查询时，只会检索与温网相关的文档内容，而不完整。",
    "tldr": "在大型语言模型中引入时间性是信息检索的关键挑战，目前的检索增强语言模型无法很好地处理时间查询。"
}