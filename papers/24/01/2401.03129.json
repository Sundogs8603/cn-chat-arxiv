{
    "title": "Examining Forgetting in Continual Pre-training of Aligned Large Language Models. (arXiv:2401.03129v1 [cs.CL])",
    "abstract": "Recent advances in Large Language Models (LLMs) have exhibited remarkable proficiency across various tasks. Given the potent applications of LLMs in numerous fields, there has been a surge in LLM development. In developing LLMs, a common practice involves continual pre-training on previously fine-tuned models. However, this can lead to catastrophic forgetting. In our work, we investigate the phenomenon of forgetting that occurs during continual pre-training on an existing fine-tuned LLM. We evaluate the impact of continuous pre-training on the fine-tuned LLM across various dimensions, including output format, knowledge, and reliability. Experiment results highlight the non-trivial challenge of addressing catastrophic forgetting during continual pre-training, especially the repetition issue.",
    "link": "http://arxiv.org/abs/2401.03129",
    "context": "Title: Examining Forgetting in Continual Pre-training of Aligned Large Language Models. (arXiv:2401.03129v1 [cs.CL])\nAbstract: Recent advances in Large Language Models (LLMs) have exhibited remarkable proficiency across various tasks. Given the potent applications of LLMs in numerous fields, there has been a surge in LLM development. In developing LLMs, a common practice involves continual pre-training on previously fine-tuned models. However, this can lead to catastrophic forgetting. In our work, we investigate the phenomenon of forgetting that occurs during continual pre-training on an existing fine-tuned LLM. We evaluate the impact of continuous pre-training on the fine-tuned LLM across various dimensions, including output format, knowledge, and reliability. Experiment results highlight the non-trivial challenge of addressing catastrophic forgetting during continual pre-training, especially the repetition issue.",
    "path": "papers/24/01/2401.03129.json",
    "total_tokens": 866,
    "translated_title": "在对齐大型语言模型的持续预训练中研究遗忘现象",
    "translated_abstract": "最近大型语言模型(LLMs)的先进研究在各种任务中展现了出色的能力。鉴于LLMs在很多领域中的重要应用，LLM的开发也有了显著增长。在开发LLMs时，一种常见做法是对先前微调模型进行连续的预训练。然而，这可能导致灾难性的遗忘。在我们的工作中，我们研究了在现有微调LLM的持续预训练过程中发生的遗忘现象。我们评估了持续预训练对微调LLM在输出格式、知识和可靠性等各个维度上的影响。实验结果突显了在持续预训练过程中解决灾难性遗忘的非平凡挑战，尤其是重复问题。",
    "tldr": "本文研究了在对齐大型语言模型的持续预训练过程中出现的遗忘现象，通过评估持续预训练对微调模型在输出格式、知识和可靠性等方面的影响，结果发现解决灾难性遗忘，尤其是重复问题，是一个非常具有挑战性的问题。",
    "en_tdlr": "This paper examines the phenomenon of forgetting that occurs during continual pre-training of aligned large language models. The impact of continuous pre-training on the fine-tuned models is evaluated across various dimensions, highlighting the challenge of addressing catastrophic forgetting, especially the repetition issue."
}