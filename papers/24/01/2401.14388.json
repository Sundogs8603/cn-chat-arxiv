{
    "title": "Smooth Ranking SVM via Cutting-Plane Method. (arXiv:2401.14388v1 [cs.LG])",
    "abstract": "The most popular classification algorithms are designed to maximize classification accuracy during training. However, this strategy may fail in the presence of class imbalance since it is possible to train models with high accuracy by overfitting to the majority class. On the other hand, the Area Under the Curve (AUC) is a widely used metric to compare classification performance of different algorithms when there is a class imbalance, and various approaches focusing on the direct optimization of this metric during training have been proposed. Among them, SVM-based formulations are especially popular as this formulation allows incorporating different regularization strategies easily. In this work, we develop a prototype learning approach that relies on cutting-plane method, similar to Ranking SVM, to maximize AUC. Our algorithm learns simpler models by iteratively introducing cutting planes, thus overfitting is prevented in an unconventional way. Furthermore, it penalizes the changes in",
    "link": "http://arxiv.org/abs/2401.14388",
    "context": "Title: Smooth Ranking SVM via Cutting-Plane Method. (arXiv:2401.14388v1 [cs.LG])\nAbstract: The most popular classification algorithms are designed to maximize classification accuracy during training. However, this strategy may fail in the presence of class imbalance since it is possible to train models with high accuracy by overfitting to the majority class. On the other hand, the Area Under the Curve (AUC) is a widely used metric to compare classification performance of different algorithms when there is a class imbalance, and various approaches focusing on the direct optimization of this metric during training have been proposed. Among them, SVM-based formulations are especially popular as this formulation allows incorporating different regularization strategies easily. In this work, we develop a prototype learning approach that relies on cutting-plane method, similar to Ranking SVM, to maximize AUC. Our algorithm learns simpler models by iteratively introducing cutting planes, thus overfitting is prevented in an unconventional way. Furthermore, it penalizes the changes in",
    "path": "papers/24/01/2401.14388.json",
    "total_tokens": 825,
    "translated_title": "利用割平面方法的平滑排名SVM",
    "translated_abstract": "最受欢迎的分类算法旨在在训练过程中最大化分类准确性。然而，在存在类别不平衡的情况下，这种策略可能会失败，因为可以通过对大多数类别过度拟合来训练高准确性的模型。另一方面，在存在类别不平衡的情况下，曲线下面积（AUC）是一种常用的度量方法，用来比较不同算法的分类性能，并且已经提出了许多专注于在训练过程中直接优化该度量的方法。其中，基于SVM的公式特别受欢迎，因为该公式可以轻松地结合不同的正则化策略。在这项工作中，我们开发了一种基于割平面方法的原型学习方法，类似于排名SVM，以最大化AUC。我们的算法通过迭代地引入割平面来学习更简单的模型，从而以非常规的方式防止过拟合。此外，它惩罚了模型的变化。",
    "tldr": "本论文提出了一种利用割平面方法的平滑排名SVM算法来最大化分类性能中的AUC指标。通过迭代引入割平面以防止过拟合，并惩罚模型的变化。"
}