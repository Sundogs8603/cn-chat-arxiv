{
    "title": "Stochastic Dynamic Power Dispatch with High Generalization and Few-Shot Adaption via Contextual Meta Graph Reinforcement Learning. (arXiv:2401.12235v1 [cs.LG])",
    "abstract": "Reinforcement learning is an emerging approaches to facilitate multi-stage sequential decision-making problems. This paper studies a real-time multi-stage stochastic power dispatch considering multivariate uncertainties. Current researches suffer from low generalization and practicality, that is, the learned dispatch policy can only handle a specific dispatch scenario, its performance degrades significantly if actual samples and training samples are inconsistent. To fill these gaps, a novel contextual meta graph reinforcement learning (Meta-GRL) for a highly generalized multi-stage optimal dispatch policy is proposed. Specifically, a more general contextual Markov decision process (MDP) and scalable graph representation are introduced to achieve a more generalized multi-stage stochastic power dispatch modeling. An upper meta-learner is proposed to encode context for different dispatch scenarios and learn how to achieve dispatch task identification while the lower policy learner learns ",
    "link": "http://arxiv.org/abs/2401.12235",
    "context": "Title: Stochastic Dynamic Power Dispatch with High Generalization and Few-Shot Adaption via Contextual Meta Graph Reinforcement Learning. (arXiv:2401.12235v1 [cs.LG])\nAbstract: Reinforcement learning is an emerging approaches to facilitate multi-stage sequential decision-making problems. This paper studies a real-time multi-stage stochastic power dispatch considering multivariate uncertainties. Current researches suffer from low generalization and practicality, that is, the learned dispatch policy can only handle a specific dispatch scenario, its performance degrades significantly if actual samples and training samples are inconsistent. To fill these gaps, a novel contextual meta graph reinforcement learning (Meta-GRL) for a highly generalized multi-stage optimal dispatch policy is proposed. Specifically, a more general contextual Markov decision process (MDP) and scalable graph representation are introduced to achieve a more generalized multi-stage stochastic power dispatch modeling. An upper meta-learner is proposed to encode context for different dispatch scenarios and learn how to achieve dispatch task identification while the lower policy learner learns ",
    "path": "papers/24/01/2401.12235.json",
    "total_tokens": 1014,
    "translated_title": "通过上下文元图强化学习，实现具有高泛化性和少样本适应性的随机动态电力分配",
    "translated_abstract": "强化学习是一种用于多阶段顺序决策问题的新兴方法。本文研究了考虑多变量不确定性的实时多阶段随机电力分配问题。目前的研究存在泛化性和实用性不高的问题，即学习到的分配策略只能处理特定情景下的分配问题，如果实际样本和训练样本不一致，性能会显著下降。为填补这些空白，提出了一种新颖的上下文元图强化学习（Meta-GRL）方法，用于实现高度泛化的多阶段最优分配策略。具体而言，引入了更一般化的上下文马尔可夫决策过程（MDP）和可扩展的图表示，以实现更一般化的多阶段随机电力分配建模。提出了一个上层元学习器，用于对不同的分配情景进行编码，并学习如何实现分配任务的识别，而下层策略学习器则学习具体的电力分配策略。",
    "tldr": "本文提出了一种通过上下文元图强化学习方法，实现具有高泛化性和少样本适应性的随机动态电力分配。通过引入更一般化的上下文MDP和可扩展的图表示，该方法能够处理多变量不确定性的实时多阶段随机电力分配问题，填补了现有研究的泛化性和实用性低的缺点。",
    "en_tdlr": "This paper proposes a novel contextual meta graph reinforcement learning (Meta-GRL) approach to achieve stochastic dynamic power dispatch with high generalization and few-shot adaption. By introducing a more generalized contextual Markov decision process and scalable graph representation, this method can handle real-time multi-stage power dispatch considering multivariate uncertainties, addressing the low generalization and practicality issues in current research."
}