{
    "title": "The Effect of Human v/s Synthetic Test Data and Round-tripping on Assessment of Sentiment Analysis Systems for Bias. (arXiv:2401.12985v1 [cs.CL])",
    "abstract": "Sentiment Analysis Systems (SASs) are data-driven Artificial Intelligence (AI) systems that output polarity and emotional intensity when given a piece of text as input. Like other AIs, SASs are also known to have unstable behavior when subjected to changes in data which can make it problematic to trust out of concerns like bias when AI works with humans and data has protected attributes like gender, race, and age. Recently, an approach was introduced to assess SASs in a blackbox setting without training data or code, and rating them for bias using synthetic English data. We augment it by introducing two human-generated chatbot datasets and also consider a round-trip setting of translating the data from one language to the same through an intermediate language. We find that these settings show SASs performance in a more realistic light. Specifically, we find that rating SASs on the chatbot data showed more bias compared to the synthetic data, and round-tripping using Spanish and Danish ",
    "link": "http://arxiv.org/abs/2401.12985",
    "context": "Title: The Effect of Human v/s Synthetic Test Data and Round-tripping on Assessment of Sentiment Analysis Systems for Bias. (arXiv:2401.12985v1 [cs.CL])\nAbstract: Sentiment Analysis Systems (SASs) are data-driven Artificial Intelligence (AI) systems that output polarity and emotional intensity when given a piece of text as input. Like other AIs, SASs are also known to have unstable behavior when subjected to changes in data which can make it problematic to trust out of concerns like bias when AI works with humans and data has protected attributes like gender, race, and age. Recently, an approach was introduced to assess SASs in a blackbox setting without training data or code, and rating them for bias using synthetic English data. We augment it by introducing two human-generated chatbot datasets and also consider a round-trip setting of translating the data from one language to the same through an intermediate language. We find that these settings show SASs performance in a more realistic light. Specifically, we find that rating SASs on the chatbot data showed more bias compared to the synthetic data, and round-tripping using Spanish and Danish ",
    "path": "papers/24/01/2401.12985.json",
    "total_tokens": 1002,
    "translated_title": "人类与合成测试数据以及往返测试对偏见分析系统评估的影响",
    "translated_abstract": "情感分析系统（SASs）是数据驱动的人工智能系统，当给定一段文本作为输入时，可以输出情感极性和情感强度。和其他人工智能一样，当SASs面临数据变化时，也会出现不稳定的行为，这可能会导致在AI与人类合作时出现问题，特别是涉及到保护属性（如性别、种族和年龄）的数据时，我们可能会对其存在偏见的信任感产生疑虑。最近，提出了一种在黑盒设置中评估SASs的方法，该方法无需训练数据或代码，并通过使用合成英文数据对其进行偏见评级。我们通过引入两个人工生成的聊天机器人数据集来扩展这个方法，并考虑了往返测试的设置，即通过一个中间语言将数据从一种语言翻译为相同语言。我们发现这些设置可以更真实地展示SASs的性能。具体来说，我们发现在聊天机器人数据上评估SASs显示出比合成数据更多的偏见，并且使用西班牙语和丹麦语进行往返测试。",
    "tldr": "本研究通过引入人工生成的聊天机器人数据集和考虑往返测试的设置，评估了情感分析系统（SASs）的偏见。结果显示，在聊天机器人数据上评估SASs显示出更多的偏见，而往返测试则更真实地展示了SASs的性能。",
    "en_tdlr": "This study examines bias in Sentiment Analysis Systems (SASs) by introducing human-generated chatbot datasets and considering round-tripping tests. The findings show that SASs exhibit more bias when evaluated on chatbot data compared to synthetic data, and round-tripping tests provide a more realistic assessment of SASs' performance."
}