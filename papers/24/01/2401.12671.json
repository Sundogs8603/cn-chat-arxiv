{
    "title": "Context Matters: Pushing the Boundaries of Open-Ended Answer Generation with Graph-Structured Knowledge Context. (arXiv:2401.12671v1 [cs.CL])",
    "abstract": "In the continuously advancing AI landscape, crafting context-rich and meaningful responses via Large Language Models (LLMs) is essential. Researchers are becoming more aware of the challenges that LLMs with fewer parameters encounter when trying to provide suitable answers to open-ended questions. To address these hurdles, the integration of cutting-edge strategies, augmentation of rich external domain knowledge to LLMs, offers significant improvements. This paper introduces a novel framework that combines graph-driven context retrieval in conjunction to knowledge graphs based enhancement, honing the proficiency of LLMs, especially in domain specific community question answering platforms like AskUbuntu, Unix, and ServerFault. We conduct experiments on various LLMs with different parameter sizes to evaluate their ability to ground knowledge and determine factual accuracy in answers to open-ended questions. Our methodology GraphContextGen consistently outperforms dominant text-based ret",
    "link": "http://arxiv.org/abs/2401.12671",
    "context": "Title: Context Matters: Pushing the Boundaries of Open-Ended Answer Generation with Graph-Structured Knowledge Context. (arXiv:2401.12671v1 [cs.CL])\nAbstract: In the continuously advancing AI landscape, crafting context-rich and meaningful responses via Large Language Models (LLMs) is essential. Researchers are becoming more aware of the challenges that LLMs with fewer parameters encounter when trying to provide suitable answers to open-ended questions. To address these hurdles, the integration of cutting-edge strategies, augmentation of rich external domain knowledge to LLMs, offers significant improvements. This paper introduces a novel framework that combines graph-driven context retrieval in conjunction to knowledge graphs based enhancement, honing the proficiency of LLMs, especially in domain specific community question answering platforms like AskUbuntu, Unix, and ServerFault. We conduct experiments on various LLMs with different parameter sizes to evaluate their ability to ground knowledge and determine factual accuracy in answers to open-ended questions. Our methodology GraphContextGen consistently outperforms dominant text-based ret",
    "path": "papers/24/01/2401.12671.json",
    "total_tokens": 906,
    "translated_title": "上下文的重要性：通过图结构化知识上下文推动开放式答案生成的边界",
    "translated_abstract": "在不断发展的人工智能领域中，通过大型语言模型（LLMs）来构建上下文丰富、有意义的回答至关重要。研究人员越来越意识到当LLMs的参数较少时，尝试提供合适答案给开放式问题时会遇到的挑战。为了解决这些障碍，将先进的策略与丰富的外部领域知识与LLMs相结合，可以显著提升答案的质量。本论文介绍了一种新颖的框架，将基于图的上下文检索与知识图结构增强相结合，提高了LLMs的能力，特别适用于特定领域的社区问答平台，如AskUbuntu、Unix和ServerFault。我们对不同参数大小的各种LLMs进行实验，评估它们在开放式问题的回答中的知识确定能力和事实准确性。我们的方法GraphContextGen在基于文本的现有方法上持续优于其他方法。",
    "tldr": "本论文介绍了一种结合图驱动的上下文检索和知识图结构增强的框架，通过提高LLMs的能力，尤其是在特定领域的社区问答平台上，更好地回答开放式问题。"
}