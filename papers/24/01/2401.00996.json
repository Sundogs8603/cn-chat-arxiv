{
    "title": "Safety and Performance, Why Not Both? Bi-Objective Optimized Model Compression against Heterogeneous Attacks Toward AI Software Deployment. (arXiv:2401.00996v1 [cs.AI])",
    "abstract": "The size of deep learning models in artificial intelligence (AI) software is increasing rapidly, hindering the large-scale deployment on resource-restricted devices (e.g., smartphones). To mitigate this issue, AI software compression plays a crucial role, which aims to compress model size while keeping high performance. However, the intrinsic defects in a big model may be inherited by the compressed one. Such defects may be easily leveraged by adversaries, since a compressed model is usually deployed in a large number of devices without adequate protection. In this article, we aim to address the safe model compression problem from the perspective of safety-performance co-optimization. Specifically, inspired by the test-driven development (TDD) paradigm in software engineering, we propose a test-driven sparse training framework called SafeCompress. By simulating the attack mechanism as safety testing, SafeCompress can automatically compress a big model to a small one following the dynam",
    "link": "http://arxiv.org/abs/2401.00996",
    "context": "Title: Safety and Performance, Why Not Both? Bi-Objective Optimized Model Compression against Heterogeneous Attacks Toward AI Software Deployment. (arXiv:2401.00996v1 [cs.AI])\nAbstract: The size of deep learning models in artificial intelligence (AI) software is increasing rapidly, hindering the large-scale deployment on resource-restricted devices (e.g., smartphones). To mitigate this issue, AI software compression plays a crucial role, which aims to compress model size while keeping high performance. However, the intrinsic defects in a big model may be inherited by the compressed one. Such defects may be easily leveraged by adversaries, since a compressed model is usually deployed in a large number of devices without adequate protection. In this article, we aim to address the safe model compression problem from the perspective of safety-performance co-optimization. Specifically, inspired by the test-driven development (TDD) paradigm in software engineering, we propose a test-driven sparse training framework called SafeCompress. By simulating the attack mechanism as safety testing, SafeCompress can automatically compress a big model to a small one following the dynam",
    "path": "papers/24/01/2401.00996.json",
    "total_tokens": 893,
    "translated_title": "安全与性能，为什么不两者兼得？针对人工智能软件部署的异构攻击的双目标优化模型压缩",
    "translated_abstract": "人工智能（AI）软件中深度学习模型的大小正在迅速增加，这对于资源受限的设备（如智能手机）的大规模部署构成了阻碍。为了解决这个问题，AI软件压缩发挥了关键作用，旨在在保持高性能的同时压缩模型大小。然而，大型模型中的固有缺陷可能会被压缩模型继承。由于压缩模型通常在大量设备上部署且没有足够的保护，这些缺陷可能易被对手利用。在本文中，我们从安全性能协调的角度解决了安全模型压缩问题。具体而言，受软件工程中测试驱动开发（TDD）范式的启发，我们提出了一个名为SafeCompress的测试驱动稀疏训练框架。通过将攻击机制模拟为安全测试，SafeCompress可以自动将大型模型压缩为小型模型。",
    "tldr": "本文提出了一个名为SafeCompress的测试驱动稀疏训练框架，用于解决人工智能软件中的安全模型压缩问题。",
    "en_tdlr": "This article proposes a test-driven sparse training framework called SafeCompress to address the issue of safe model compression in AI software."
}