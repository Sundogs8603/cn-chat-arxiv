{
    "title": "Binary Linear Tree Commitment-based Ownership Protection for Distributed Machine Learning. (arXiv:2401.05895v1 [cs.LG])",
    "abstract": "Distributed machine learning enables parallel training of extensive datasets by delegating computing tasks across multiple workers. Despite the cost reduction benefits of distributed machine learning, the dissemination of final model weights often leads to potential conflicts over model ownership as workers struggle to substantiate their involvement in the training computation. To address the above ownership issues and prevent accidental failures and malicious attacks, verifying the computational integrity and effectiveness of workers becomes particularly crucial in distributed machine learning. In this paper, we proposed a novel binary linear tree commitment-based ownership protection model to ensure computational integrity with limited overhead and concise proof. Due to the frequent updates of parameters during training, our commitment scheme introduces a maintainable tree structure to reduce the costs of updating proofs. Distinguished from SNARK-based verifiable computation, our mod",
    "link": "http://arxiv.org/abs/2401.05895",
    "context": "Title: Binary Linear Tree Commitment-based Ownership Protection for Distributed Machine Learning. (arXiv:2401.05895v1 [cs.LG])\nAbstract: Distributed machine learning enables parallel training of extensive datasets by delegating computing tasks across multiple workers. Despite the cost reduction benefits of distributed machine learning, the dissemination of final model weights often leads to potential conflicts over model ownership as workers struggle to substantiate their involvement in the training computation. To address the above ownership issues and prevent accidental failures and malicious attacks, verifying the computational integrity and effectiveness of workers becomes particularly crucial in distributed machine learning. In this paper, we proposed a novel binary linear tree commitment-based ownership protection model to ensure computational integrity with limited overhead and concise proof. Due to the frequent updates of parameters during training, our commitment scheme introduces a maintainable tree structure to reduce the costs of updating proofs. Distinguished from SNARK-based verifiable computation, our mod",
    "path": "papers/24/01/2401.05895.json",
    "total_tokens": 845,
    "translated_title": "基于二进制线性树提交的分布式机器学习所有权保护",
    "translated_abstract": "分布式机器学习通过将计算任务分配给多个工作节点，实现了对大规模数据集的并行训练。但是，最终模型权重的传播往往会导致模型所有权的潜在冲突，因为工作节点难以证明自己在训练计算中的参与度。为了解决上述所有权问题，并防止意外故障和恶意攻击，在分布式机器学习中验证工作节点的计算完整性和效果变得尤为重要。本文提出了一种新的基于二进制线性树提交的所有权保护模型，以确保计算的完整性，同时保证开销有限和证明简洁。由于训练过程中参数的频繁更新，我们的提交方案引入了可维护的树结构，降低了更新证明的成本。与基于SNARK的验证计算不同，我们的模型可以同时支持批量训练和在线训练。",
    "tldr": "本论文提出了一种基于二进制线性树提交的分布式机器学习所有权保护模型，通过验证计算的完整性和效果，解决了模型所有权的冲突问题，并降低了更新证明的成本。",
    "en_tdlr": "This paper proposes a binary linear tree commitment-based ownership protection model for distributed machine learning, which addresses the conflict over model ownership and reduces the cost of updating proofs by verifying the computational integrity and effectiveness."
}