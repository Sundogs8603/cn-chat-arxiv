{
    "title": "Enhancing Efficiency and Robustness in Support Vector Regression with HawkEye Loss. (arXiv:2401.16785v1 [cs.LG])",
    "abstract": "Support vector regression (SVR) has garnered significant popularity over the past two decades owing to its wide range of applications across various fields. Despite its versatility, SVR encounters challenges when confronted with outliers and noise, primarily due to the use of the $\\varepsilon$-insensitive loss function. To address this limitation, SVR with bounded loss functions has emerged as an appealing alternative, offering enhanced generalization performance and robustness. Notably, recent developments focus on designing bounded loss functions with smooth characteristics, facilitating the adoption of gradient-based optimization algorithms. However, it's crucial to highlight that these bounded and smooth loss functions do not possess an insensitive zone. In this paper, we address the aforementioned constraints by introducing a novel symmetric loss function named the HawkEye loss function. It is worth noting that the HawkEye loss function stands out as the first loss function in SVR",
    "link": "http://arxiv.org/abs/2401.16785",
    "context": "Title: Enhancing Efficiency and Robustness in Support Vector Regression with HawkEye Loss. (arXiv:2401.16785v1 [cs.LG])\nAbstract: Support vector regression (SVR) has garnered significant popularity over the past two decades owing to its wide range of applications across various fields. Despite its versatility, SVR encounters challenges when confronted with outliers and noise, primarily due to the use of the $\\varepsilon$-insensitive loss function. To address this limitation, SVR with bounded loss functions has emerged as an appealing alternative, offering enhanced generalization performance and robustness. Notably, recent developments focus on designing bounded loss functions with smooth characteristics, facilitating the adoption of gradient-based optimization algorithms. However, it's crucial to highlight that these bounded and smooth loss functions do not possess an insensitive zone. In this paper, we address the aforementioned constraints by introducing a novel symmetric loss function named the HawkEye loss function. It is worth noting that the HawkEye loss function stands out as the first loss function in SVR",
    "path": "papers/24/01/2401.16785.json",
    "total_tokens": 878,
    "translated_title": "通过HawkEye Loss在支持向量回归中提高效率和鲁棒性",
    "translated_abstract": "支持向量回归（SVR）由于其在各个领域的广泛应用而受到了显著的关注，在面对离群值和噪声时，SVR遇到了挑战，主要是由于使用了ε-insensitive损失函数。为了解决这个限制，具有有界损失函数的SVR已成为一种吸引人的替代方案，提供了增强的泛化性能和鲁棒性。值得注意的是，最近的研究关注于设计具有平滑特性的有界损失函数，促进了梯度优化算法的采用。然而，需要强调的是，这些有界和平滑的损失函数不具有一个不敏感的区域。在本文中，我们通过引入一种名为HawkEye损失函数的新的对称损失函数来解决上述约束。值得注意的是，HawkEye损失函数作为SVR中的第一个损失函数突出显示出来。",
    "tldr": "通过引入名为HawkEye损失函数的新的对称损失函数，本文解决了支持向量回归在处理离群值和噪声时遇到的挑战，并提供了增强的泛化性能和鲁棒性。"
}