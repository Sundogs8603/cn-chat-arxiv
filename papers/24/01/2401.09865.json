{
    "title": "Improving fine-grained understanding in image-text pre-training. (arXiv:2401.09865v1 [cs.CV])",
    "abstract": "We introduce SPARse Fine-grained Contrastive Alignment (SPARC), a simple method for pretraining more fine-grained multimodal representations from image-text pairs. Given that multiple image patches often correspond to single words, we propose to learn a grouping of image patches for every token in the caption. To achieve this, we use a sparse similarity metric between image patches and language tokens and compute for each token a language-grouped vision embedding as the weighted average of patches. The token and language-grouped vision embeddings are then contrasted through a fine-grained sequence-wise loss that only depends on individual samples and does not require other batch samples as negatives. This enables more detailed information to be learned in a computationally inexpensive manner. SPARC combines this fine-grained loss with a contrastive loss between global image and text embeddings to learn representations that simultaneously encode global and local information. We thorough",
    "link": "http://arxiv.org/abs/2401.09865",
    "context": "Title: Improving fine-grained understanding in image-text pre-training. (arXiv:2401.09865v1 [cs.CV])\nAbstract: We introduce SPARse Fine-grained Contrastive Alignment (SPARC), a simple method for pretraining more fine-grained multimodal representations from image-text pairs. Given that multiple image patches often correspond to single words, we propose to learn a grouping of image patches for every token in the caption. To achieve this, we use a sparse similarity metric between image patches and language tokens and compute for each token a language-grouped vision embedding as the weighted average of patches. The token and language-grouped vision embeddings are then contrasted through a fine-grained sequence-wise loss that only depends on individual samples and does not require other batch samples as negatives. This enables more detailed information to be learned in a computationally inexpensive manner. SPARC combines this fine-grained loss with a contrastive loss between global image and text embeddings to learn representations that simultaneously encode global and local information. We thorough",
    "path": "papers/24/01/2401.09865.json",
    "total_tokens": 936,
    "translated_title": "提高图像-文本预训练中细粒度理解的方法",
    "translated_abstract": "我们引入了一种名为SPARC的方法，用于从图像-文本对中预训练更细粒度的多模态表示。考虑到多个图像块通常对应于单个单词，我们提出为每个字幕令牌学习一组图像块的方法。为了实现这一点，我们使用了图像块和语言令牌之间的稀疏相似度度量，并计算出每个令牌的语言分组的视觉嵌入，作为图像块的加权平均值。然后，通过一种仅依赖于单个样本而不需要其他批次样本作为负样本的细粒度序列损失，对令牌和语言分组的视觉嵌入进行对比。这使得可以以较低的计算成本学习更详细的信息。SPARC将这种细粒度损失与全局图像和文本嵌入之间的对比损失相结合，以同时编码全局和局部信息的表示。",
    "tldr": "本研究引入了一种名为SPARC的方法，通过在图像-文本对中学习每个令牌的图像组合，以提高图像-文本预训练中的细粒度理解能力。SPARC方法结合了细粒度损失和对比损失，可以以较低的计算成本学习同时编码全局和局部信息的表示。",
    "en_tdlr": "This study introduces a method called SPARC, which improves fine-grained understanding in image-text pre-training by learning image grouping for each token in image-text pairs. SPARC combines fine-grained loss and contrastive loss to learn representations that encode both global and local information in a computationally efficient manner."
}