{
    "title": "Identifying and Analyzing Task-Encoding Tokens in Large Language Models",
    "abstract": "arXiv:2401.11323v2 Announce Type: replace  Abstract: In-context learning (ICL) has become an effective solution for few-shot learning in natural language processing. However, our understanding of ICL's working mechanisms is limited, specifically regarding how models learn to perform tasks from ICL demonstrations. For example, unexpectedly large changes in performance can arise from small changes in the prompt, leaving prompt design a largely empirical endeavour. In this paper, we investigate this problem by identifying and analyzing task-encoding tokens on whose representations the task performance depends. Using experiments that ablate the representations of different token types, we find that template and stopword tokens are the most prone to be task-encoding. In addition, we demonstrate experimentally that lexical meaning, repetition, and text formatting are the main distinguishing characteristics of these tokens. Our work sheds light on how large language models (LLMs) learn to per",
    "link": "https://arxiv.org/abs/2401.11323",
    "context": "Title: Identifying and Analyzing Task-Encoding Tokens in Large Language Models\nAbstract: arXiv:2401.11323v2 Announce Type: replace  Abstract: In-context learning (ICL) has become an effective solution for few-shot learning in natural language processing. However, our understanding of ICL's working mechanisms is limited, specifically regarding how models learn to perform tasks from ICL demonstrations. For example, unexpectedly large changes in performance can arise from small changes in the prompt, leaving prompt design a largely empirical endeavour. In this paper, we investigate this problem by identifying and analyzing task-encoding tokens on whose representations the task performance depends. Using experiments that ablate the representations of different token types, we find that template and stopword tokens are the most prone to be task-encoding. In addition, we demonstrate experimentally that lexical meaning, repetition, and text formatting are the main distinguishing characteristics of these tokens. Our work sheds light on how large language models (LLMs) learn to per",
    "path": "papers/24/01/2401.11323.json",
    "total_tokens": 686,
    "translated_title": "辨识并分析大型语言模型中的任务编码标记",
    "translated_abstract": "在上下文学习（ICL）已成为自然语言处理中少样本学习的有效解决方案。然而，我们对ICL的工作机制的理解有限，特别是模型如何从ICL演示中学习执行任务。本文通过识别和分析任务编码标记，调查了这个问题。我们发现，模板标记和停用词标记最容易成为任务编码标记。此外，我们实验证明，词汇意思、重复和文本格式是这些标记的主要区别特征。我们的工作揭示了大型语言模型（LLMs）学习的方式。",
    "tldr": "本文通过识别和分析任务编码标记，揭示了大型语言模型如何学习执行任务的方式。",
    "en_tdlr": "This paper reveals how large language models learn to perform tasks by identifying and analyzing task-encoding tokens."
}