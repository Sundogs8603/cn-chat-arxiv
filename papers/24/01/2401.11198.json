{
    "title": "A Deep Learning Approach for Selective Relevance Feedback. (arXiv:2401.11198v1 [cs.IR])",
    "abstract": "Pseudo-relevance feedback (PRF) can enhance average retrieval effectiveness over a sufficiently large number of queries. However, PRF often introduces a drift into the original information need, thus hurting the retrieval effectiveness of several queries. While a selective application of PRF can potentially alleviate this issue, previous approaches have largely relied on unsupervised or feature-based learning to determine whether a query should be expanded. In contrast, we revisit the problem of selective PRF from a deep learning perspective, presenting a model that is entirely data-driven and trained in an end-to-end manner. The proposed model leverages a transformer-based bi-encoder architecture. Additionally, to further improve retrieval effectiveness with this selective PRF approach, we make use of the model's confidence estimates to combine the information from the original and expanded queries. In our experiments, we apply this selective feedback on a number of different combinat",
    "link": "http://arxiv.org/abs/2401.11198",
    "context": "Title: A Deep Learning Approach for Selective Relevance Feedback. (arXiv:2401.11198v1 [cs.IR])\nAbstract: Pseudo-relevance feedback (PRF) can enhance average retrieval effectiveness over a sufficiently large number of queries. However, PRF often introduces a drift into the original information need, thus hurting the retrieval effectiveness of several queries. While a selective application of PRF can potentially alleviate this issue, previous approaches have largely relied on unsupervised or feature-based learning to determine whether a query should be expanded. In contrast, we revisit the problem of selective PRF from a deep learning perspective, presenting a model that is entirely data-driven and trained in an end-to-end manner. The proposed model leverages a transformer-based bi-encoder architecture. Additionally, to further improve retrieval effectiveness with this selective PRF approach, we make use of the model's confidence estimates to combine the information from the original and expanded queries. In our experiments, we apply this selective feedback on a number of different combinat",
    "path": "papers/24/01/2401.11198.json",
    "total_tokens": 723,
    "translated_title": "深度学习方法用于选择性相关反馈",
    "translated_abstract": "通过建立一个完全基于数据驱动训练的模型，本文从深度学习的角度重新思考了选择性伪相关反馈问题，并提出了一个基于transformer双编码器架构的模型。此外，为了进一步提高使用选择性伪相关反馈方法的检索效果，我们利用模型的置信度估计来结合原始和扩展的查询信息。在实验中，我们将此选择性反馈应用于多种不同的组合。",
    "tldr": "本文从深度学习的角度重新思考了选择性伪相关反馈问题，并提出了一个完全基于数据驱动训练的模型，通过利用置信度估计来结合原始和扩展的查询信息，从而进一步提高检索效果。",
    "en_tdlr": "This paper rethinks the problem of selective pseudo-relevance feedback from a deep learning perspective and proposes a fully data-driven model. By leveraging confidence estimates to combine the information from original and expanded queries, the retrieval effectiveness is further improved."
}