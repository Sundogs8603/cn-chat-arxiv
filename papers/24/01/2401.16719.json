{
    "title": "OptiState: State Estimation of Legged Robots using Gated Networks with Transformer-based Vision and Kalman Filtering. (arXiv:2401.16719v1 [cs.RO])",
    "abstract": "State estimation for legged robots is challenging due to their highly dynamic motion and limitations imposed by sensor accuracy. By integrating Kalman filtering, optimization, and learning-based modalities, we propose a hybrid solution that combines proprioception and exteroceptive information for estimating the state of the robot's trunk. Leveraging joint encoder and IMU measurements, our Kalman filter is enhanced through a single-rigid body model that incorporates ground reaction force control outputs from convex Model Predictive Control optimization. The estimation is further refined through Gated Recurrent Units, which also considers semantic insights and robot height from a Vision Transformer autoencoder applied on depth images. This framework not only furnishes accurate robot state estimates, including uncertainty evaluations, but can minimize the nonlinear errors that arise from sensor measurements and model simplifications through learning. The proposed methodology is evaluated",
    "link": "http://arxiv.org/abs/2401.16719",
    "context": "Title: OptiState: State Estimation of Legged Robots using Gated Networks with Transformer-based Vision and Kalman Filtering. (arXiv:2401.16719v1 [cs.RO])\nAbstract: State estimation for legged robots is challenging due to their highly dynamic motion and limitations imposed by sensor accuracy. By integrating Kalman filtering, optimization, and learning-based modalities, we propose a hybrid solution that combines proprioception and exteroceptive information for estimating the state of the robot's trunk. Leveraging joint encoder and IMU measurements, our Kalman filter is enhanced through a single-rigid body model that incorporates ground reaction force control outputs from convex Model Predictive Control optimization. The estimation is further refined through Gated Recurrent Units, which also considers semantic insights and robot height from a Vision Transformer autoencoder applied on depth images. This framework not only furnishes accurate robot state estimates, including uncertainty evaluations, but can minimize the nonlinear errors that arise from sensor measurements and model simplifications through learning. The proposed methodology is evaluated",
    "path": "papers/24/01/2401.16719.json",
    "total_tokens": 1088,
    "translated_title": "OptiState：基于门控网络、Transformer视觉和卡尔曼滤波的腿式机器人状态估计",
    "translated_abstract": "由于腿式机器人的高动态运动和传感器精度的局限性，腿式机器人的状态估计具有挑战性。通过整合卡尔曼滤波、优化和基于学习的模态，我们提出了一种混合解决方案，结合了本体感和外感信息，用于估计机器人主体的状态。借助关节编码器和IMU测量，我们的卡尔曼滤波器通过单刚体模型进行增强，该模型还结合了基于凸规划的模型预测控制优化的接地反力控制输出。通过门控循环单元进一步改进估计结果，该方法还考虑了从深度图像上应用视觉Transformer自编码器获得的语义洞察和机器人高度。该框架不仅提供准确的机器人状态估计，包括不确定性评估，还可以通过学习来减小传感器测量和模型简化引起的非线性误差。所提出的方法经过评估。",
    "tldr": "本研究提出了一种名为OptiState的腿式机器人状态估计方法，该方法通过整合Kalman滤波、优化和学习模式的混合解决方案，结合本体感和外感信息，以精确估计机器人主体的状态。该方法利用关节编码器、IMU测量和基于凸规划的模型预测控制优化，通过Gate循环单元和Vision Transformer自编码器改进了估计结果。研究结果表明，该方法能够提供准确的机器人状态估计，并减小传感器测量和模型简化引起的非线性误差。"
}