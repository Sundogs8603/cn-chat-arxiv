{
    "title": "Towards Understanding the Riemannian SGD and SVRG Flows on Wasserstein Probabilistic Space. (arXiv:2401.13530v1 [cs.LG])",
    "abstract": "Recently, optimization on the Riemannian manifold has provided new insights to the optimization community. In this regard, the manifold taken as the probability measure metric space equipped with the second-order Wasserstein distance is of particular interest, since optimization on it can be linked to practical sampling processes. In general, the oracle (continuous) optimization method on Wasserstein space is Riemannian gradient flow (i.e., Langevin dynamics when minimizing KL divergence). In this paper, we aim to enrich the continuous optimization methods in the Wasserstein space by extending the gradient flow into the stochastic gradient descent (SGD) flow and stochastic variance reduction gradient (SVRG) flow. The two flows on Euclidean space are standard stochastic optimization methods, while their Riemannian counterparts are not explored yet. By leveraging the structures in Wasserstein space, we construct a stochastic differential equation (SDE) to approximate the discrete dynamic",
    "link": "http://arxiv.org/abs/2401.13530",
    "context": "Title: Towards Understanding the Riemannian SGD and SVRG Flows on Wasserstein Probabilistic Space. (arXiv:2401.13530v1 [cs.LG])\nAbstract: Recently, optimization on the Riemannian manifold has provided new insights to the optimization community. In this regard, the manifold taken as the probability measure metric space equipped with the second-order Wasserstein distance is of particular interest, since optimization on it can be linked to practical sampling processes. In general, the oracle (continuous) optimization method on Wasserstein space is Riemannian gradient flow (i.e., Langevin dynamics when minimizing KL divergence). In this paper, we aim to enrich the continuous optimization methods in the Wasserstein space by extending the gradient flow into the stochastic gradient descent (SGD) flow and stochastic variance reduction gradient (SVRG) flow. The two flows on Euclidean space are standard stochastic optimization methods, while their Riemannian counterparts are not explored yet. By leveraging the structures in Wasserstein space, we construct a stochastic differential equation (SDE) to approximate the discrete dynamic",
    "path": "papers/24/01/2401.13530.json",
    "total_tokens": 882,
    "translated_title": "在Wasserstein概率空间上理解Riemannian SGD和SVRG流的研究",
    "translated_abstract": "最近，对于Riemannian流形上的优化研究为优化领域提供了新的见解。在这方面，概率测度度量空间作为流形，配备第二阶Wasserstein距离，尤其引人关注，因为在其上的优化可以与实际的采样过程相关联。一般来说，Wasserstein空间上的最优化方法是Riemannian梯度流（即，在最小化KL散度时的Langevin动力学）。在本文中，我们旨在通过将梯度流延展到随机梯度下降（SGD）流和随机方差减少梯度（SVRG）流，丰富Wasserstein空间中的连续优化方法。Euclidean空间上的这两种流是标准的随机优化方法，而它们在Riemannian空间中的对应方法尚未被探索。通过利用Wasserstein空间中的结构，我们构建了一个随机微分方程（SDE）来近似离散动态。",
    "tldr": "本文研究了在Wasserstein概率空间上的Riemannian SGD和SVRG流的优化方法，通过构建随机微分方程来丰富Wasserstein空间中的连续优化方法。",
    "en_tdlr": "This paper explores optimization methods of Riemannian SGD and SVRG flows on Wasserstein probabilistic space, enriching the continuous optimization methods by constructing a stochastic differential equation."
}