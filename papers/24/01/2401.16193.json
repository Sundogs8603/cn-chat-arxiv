{
    "title": "Contributing Dimension Structure of Deep Feature for Coreset Selection",
    "abstract": "arXiv:2401.16193v2 Announce Type: replace  Abstract: Coreset selection seeks to choose a subset of crucial training samples for efficient learning. It has gained traction in deep learning, particularly with the surge in training dataset sizes. Sample selection hinges on two main aspects: a sample's representation in enhancing performance and the role of sample diversity in averting overfitting. Existing methods typically measure both the representation and diversity of data based on similarity metrics, such as L2-norm. They have capably tackled representation via distribution matching guided by the similarities of features, gradients, or other information between data. However, the results of effectively diverse sample selection are mired in sub-optimality. This is because the similarity metrics usually simply aggregate dimension similarities without acknowledging disparities among the dimensions that significantly contribute to the final similarity. As a result, they fall short of ade",
    "link": "https://arxiv.org/abs/2401.16193",
    "context": "Title: Contributing Dimension Structure of Deep Feature for Coreset Selection\nAbstract: arXiv:2401.16193v2 Announce Type: replace  Abstract: Coreset selection seeks to choose a subset of crucial training samples for efficient learning. It has gained traction in deep learning, particularly with the surge in training dataset sizes. Sample selection hinges on two main aspects: a sample's representation in enhancing performance and the role of sample diversity in averting overfitting. Existing methods typically measure both the representation and diversity of data based on similarity metrics, such as L2-norm. They have capably tackled representation via distribution matching guided by the similarities of features, gradients, or other information between data. However, the results of effectively diverse sample selection are mired in sub-optimality. This is because the similarity metrics usually simply aggregate dimension similarities without acknowledging disparities among the dimensions that significantly contribute to the final similarity. As a result, they fall short of ade",
    "path": "papers/24/01/2401.16193.json",
    "total_tokens": 833,
    "translated_title": "为核心集选择贡献的深度特征维度结构",
    "translated_abstract": "核心集选择旨在为高效学习选择一组关键训练样本。随着训练数据集大小的激增，它在深度学习中日益受到关注。样本选择取决于两个主要方面：样本在提高性能方面的表示以及样本多样性在避免过拟合方面的作用。现有方法通常根据诸如L2范数之类的相似性度量来衡量数据的表示和多样性。它们通过特征、梯度或其他信息之间的相似性来引导分布匹配，有效地解决了表示问题。然而，有效多样性样本选择的结果却受困于次优性。这是因为相似性度量通常仅仅聚合维度相似性，而未意识到对于最终相似性贡献显著的维度之间的差异。因此，它们未能达到充分的效果。",
    "tldr": "现有核心集选择方法未能有效解决深度特征维度结构中维度之间差异对最终相似性的贡献，导致多样性样本选择的结果次优。",
    "en_tdlr": "Existing methods in coreset selection fail to effectively address the contributions of disparities among dimensions in deep feature structure to the final similarity, resulting in sub-optimal diverse sample selection."
}