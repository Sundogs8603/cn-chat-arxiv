{
    "title": "UNEX-RL: Reinforcing Long-Term Rewards in Multi-Stage Recommender Systems with UNidirectional EXecution. (arXiv:2401.06470v1 [cs.IR])",
    "abstract": "In recent years, there has been a growing interest in utilizing reinforcement learning (RL) to optimize long-term rewards in recommender systems. Since industrial recommender systems are typically designed as multi-stage systems, RL methods with a single agent face challenges when optimizing multiple stages simultaneously. The reason is that different stages have different observation spaces, and thus cannot be modeled by a single agent. To address this issue, we propose a novel UNidirectional-EXecution-based multi-agent Reinforcement Learning (UNEX-RL) framework to reinforce the long-term rewards in multi-stage recommender systems. We show that the unidirectional execution is a key feature of multi-stage recommender systems, bringing new challenges to the applications of multi-agent reinforcement learning (MARL), namely the observation dependency and the cascading effect. To tackle these challenges, we provide a cascading information chain (CIC) method to separate the independent obse",
    "link": "http://arxiv.org/abs/2401.06470",
    "context": "Title: UNEX-RL: Reinforcing Long-Term Rewards in Multi-Stage Recommender Systems with UNidirectional EXecution. (arXiv:2401.06470v1 [cs.IR])\nAbstract: In recent years, there has been a growing interest in utilizing reinforcement learning (RL) to optimize long-term rewards in recommender systems. Since industrial recommender systems are typically designed as multi-stage systems, RL methods with a single agent face challenges when optimizing multiple stages simultaneously. The reason is that different stages have different observation spaces, and thus cannot be modeled by a single agent. To address this issue, we propose a novel UNidirectional-EXecution-based multi-agent Reinforcement Learning (UNEX-RL) framework to reinforce the long-term rewards in multi-stage recommender systems. We show that the unidirectional execution is a key feature of multi-stage recommender systems, bringing new challenges to the applications of multi-agent reinforcement learning (MARL), namely the observation dependency and the cascading effect. To tackle these challenges, we provide a cascading information chain (CIC) method to separate the independent obse",
    "path": "papers/24/01/2401.06470.json",
    "total_tokens": 955,
    "translated_title": "UNEX-RL: 在多阶段推荐系统中通过单向执行加强长期奖励",
    "translated_abstract": "近年来，越来越多的人开始关注利用强化学习（RL）来优化推荐系统中的长期奖励。由于工业级的推荐系统通常是设计为多阶段系统，使用单个智能体的RL方法在同时优化多个阶段时面临挑战。原因是不同的阶段具有不同的观察空间，因此不能由单个智能体建模。为了解决这个问题，我们提出了一种新的基于UNidirectional-EXecution的多智能体强化学习框架（UNEX-RL），用于加强多阶段推荐系统中的长期奖励。我们展示了单向执行是多阶段推荐系统的一个关键特性，对多智能体强化学习（MARL）的应用带来了新的挑战，即观察依赖性和级联效应。为了解决这些挑战，我们提供了一种级联信息链（CIC）方法来分离独立的观察信息。",
    "tldr": "本论文提出了一种名为UNEX-RL的基于单向执行的多智能体强化学习框架，用于优化多阶段推荐系统中的长期奖励。该框架通过解决观察依赖性和级联效应的挑战，有效地提高了推荐系统的性能。",
    "en_tdlr": "This paper proposes a novel framework called UNEX-RL, which is based on unidirectional execution and multi-agent reinforcement learning, to optimize long-term rewards in multi-stage recommender systems. The framework addresses challenges such as observation dependency and cascading effect, and improves the performance of recommender systems."
}