{
    "title": "Propagation and Pitfalls: Reasoning-based Assessment of Knowledge Editing through Counterfactual Tasks",
    "abstract": "Current approaches of knowledge editing struggle to effectively propagate updates to interconnected facts. In this work, we delve into the barriers that hinder the appropriate propagation of updated knowledge within these models for accurate reasoning. To support our analysis, we introduce a novel reasoning-based benchmark -- ReCoE (Reasoning-based Counterfactual Editing dataset) -- which covers six common reasoning schemes in real world. We conduct a thorough analysis of existing knowledge editing techniques, including input augmentation, finetuning, and locate-and-edit. We found that all model editing methods show notably low performance on this dataset, especially in certain reasoning schemes. Our analysis over the chain-of-thought generation of edited models further uncover key reasons behind the inadequacy of existing knowledge editing methods from a reasoning standpoint, involving aspects on fact-wise editing, fact recall ability, and coherence in generation. We will make our ben",
    "link": "https://arxiv.org/abs/2401.17585",
    "context": "Title: Propagation and Pitfalls: Reasoning-based Assessment of Knowledge Editing through Counterfactual Tasks\nAbstract: Current approaches of knowledge editing struggle to effectively propagate updates to interconnected facts. In this work, we delve into the barriers that hinder the appropriate propagation of updated knowledge within these models for accurate reasoning. To support our analysis, we introduce a novel reasoning-based benchmark -- ReCoE (Reasoning-based Counterfactual Editing dataset) -- which covers six common reasoning schemes in real world. We conduct a thorough analysis of existing knowledge editing techniques, including input augmentation, finetuning, and locate-and-edit. We found that all model editing methods show notably low performance on this dataset, especially in certain reasoning schemes. Our analysis over the chain-of-thought generation of edited models further uncover key reasons behind the inadequacy of existing knowledge editing methods from a reasoning standpoint, involving aspects on fact-wise editing, fact recall ability, and coherence in generation. We will make our ben",
    "path": "papers/24/01/2401.17585.json",
    "total_tokens": 959,
    "translated_title": "传播与陷阱：通过反事实任务评估基于推理的知识编辑的困境",
    "translated_abstract": "当前的知识编辑方法在有效传播更新的相互关联事实方面面临困难。在这项工作中，我们深入探讨了阻碍准确推理模型中更新知识适当传播的障碍。为了支持我们的分析，我们引入了一种新颖的基于推理的基准——ReCoE（基于推理的反事实编辑数据集），涵盖了现实世界中的六种常见推理方案。我们对现有的知识编辑技术进行了全面分析，包括输入增强、微调和定位编辑。我们发现所有模型编辑方法在这个数据集上的表现都明显较低，尤其是在某些推理方案中。我们通过对编辑模型的思维链生成的分析，从推理的角度揭示了现有知识编辑方法不足的关键原因，包括对事实编辑、事实回忆能力以及生成的连贯性的方面。我们将公开我们的基准数据集和代码。",
    "tldr": "该论文针对现有的知识编辑方法在推理能力方面的限制，通过引入ReCoE数据集进行了深入分析。研究发现所有的模型编辑方法在该数据集上表现较差，尤其在特定的推理方案中。此外，通过对编辑模型思维链生成的分析，揭示了现有方法的不足之处，包括对事实编辑、事实回忆能力和连贯性的考量。"
}