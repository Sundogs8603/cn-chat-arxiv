{
    "title": "Improving Classification Performance With Human Feedback: Label a few, we label the rest. (arXiv:2401.09555v1 [cs.LG])",
    "abstract": "In the realm of artificial intelligence, where a vast majority of data is unstructured, obtaining substantial amounts of labeled data to train supervised machine learning models poses a significant challenge. To address this, we delve into few-shot and active learning, where are goal is to improve AI models with human feedback on a few labeled examples. This paper focuses on understanding how a continuous feedback loop can refine models, thereby enhancing their accuracy, recall, and precision through incremental human input. By employing Large Language Models (LLMs) such as GPT-3.5, BERT, and SetFit, we aim to analyze the efficacy of using a limited number of labeled examples to substantially improve model accuracy. We benchmark this approach on the Financial Phrasebank, Banking, Craigslist, Trec, Amazon Reviews datasets to prove that with just a few labeled examples, we are able to surpass the accuracy of zero shot large language models to provide enhanced text classification performa",
    "link": "http://arxiv.org/abs/2401.09555",
    "context": "Title: Improving Classification Performance With Human Feedback: Label a few, we label the rest. (arXiv:2401.09555v1 [cs.LG])\nAbstract: In the realm of artificial intelligence, where a vast majority of data is unstructured, obtaining substantial amounts of labeled data to train supervised machine learning models poses a significant challenge. To address this, we delve into few-shot and active learning, where are goal is to improve AI models with human feedback on a few labeled examples. This paper focuses on understanding how a continuous feedback loop can refine models, thereby enhancing their accuracy, recall, and precision through incremental human input. By employing Large Language Models (LLMs) such as GPT-3.5, BERT, and SetFit, we aim to analyze the efficacy of using a limited number of labeled examples to substantially improve model accuracy. We benchmark this approach on the Financial Phrasebank, Banking, Craigslist, Trec, Amazon Reviews datasets to prove that with just a few labeled examples, we are able to surpass the accuracy of zero shot large language models to provide enhanced text classification performa",
    "path": "papers/24/01/2401.09555.json",
    "total_tokens": 961,
    "translated_title": "通过人类反馈改进分类性能：标记一些，我们标记其余部分",
    "translated_abstract": "在人工智能领域，大部分数据是非结构化的，因此获取足够的有标签数据来训练监督式机器学习模型是一个重要挑战。为了解决这个问题，我们深入研究少样本学习和主动学习，即通过人类反馈来改进人工智能模型，仅使用一小部分有标签示例。本文着重于理解连续反馈循环如何改善模型，从而通过渐进式的人类参与提高模型的准确性、回归和精确度。通过使用大型语言模型（LLMs），如GPT-3.5、BERT和SetFit，我们旨在分析使用有限数量的有标签示例显著提高模型准确性的效果。我们在Financial Phrasebank、Banking、Craigslist、Trec和Amazon Reviews数据集上对此方法进行基准测试，证明仅使用少量有标签示例就能超越零样本大型语言模型的准确性，提供增强的文本分类性能。",
    "tldr": "本文探讨了通过人类反馈来改进分类模型性能的方法。使用少量有标签示例，通过连续反馈循环，我们能够显著提高模型的准确性。在多个数据集上进行评估，结果表明这种方法能够超越零样本大型语言模型，提供更强的文本分类性能。",
    "en_tdlr": "This paper explores a method to improve classification model performance through human feedback. By using a small number of labeled examples and employing a continuous feedback loop, we are able to significantly enhance the accuracy of the models. Evaluation on multiple datasets demonstrates that this approach can surpass zero-shot large language models and provide stronger text classification performance."
}