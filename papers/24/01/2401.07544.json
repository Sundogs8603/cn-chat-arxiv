{
    "title": "See the Unseen: Better Context-Consistent Knowledge-Editing by Noises. (arXiv:2401.07544v2 [cs.CL] UPDATED)",
    "abstract": "Knowledge-editing updates knowledge of large language models (LLMs) and contributes to the interpretability and application of LLMs. However, knowledge applying is context-consistent: LLMs can recall the same knowledge in different contexts. Existing works ignore this property and the editing lacks generalization. In this paper, we empirically find that the effects of different contexts upon LLMs in recalling the same knowledge follow a Gaussian-like distribution. We then sample Gaussian noises to simulate the effects of different contexts when updating LLMs. By such, we can make LLMs see the unseen contexts where the edited knowledge will be applied, therefore improving the editing generalization. Experimental results on three LLMs demonstrate the effectiveness of our methods and also distinguish our methods from the others of fine-tuning LLMs by noises.",
    "link": "http://arxiv.org/abs/2401.07544",
    "context": "Title: See the Unseen: Better Context-Consistent Knowledge-Editing by Noises. (arXiv:2401.07544v2 [cs.CL] UPDATED)\nAbstract: Knowledge-editing updates knowledge of large language models (LLMs) and contributes to the interpretability and application of LLMs. However, knowledge applying is context-consistent: LLMs can recall the same knowledge in different contexts. Existing works ignore this property and the editing lacks generalization. In this paper, we empirically find that the effects of different contexts upon LLMs in recalling the same knowledge follow a Gaussian-like distribution. We then sample Gaussian noises to simulate the effects of different contexts when updating LLMs. By such, we can make LLMs see the unseen contexts where the edited knowledge will be applied, therefore improving the editing generalization. Experimental results on three LLMs demonstrate the effectiveness of our methods and also distinguish our methods from the others of fine-tuning LLMs by noises.",
    "path": "papers/24/01/2401.07544.json",
    "total_tokens": 854,
    "translated_title": "看见未见：通过噪声实现更好的上下文一致性知识编辑",
    "translated_abstract": "知识编辑更新大型语言模型（LLM）的知识，并为LLM的可解释性和应用做出贡献。然而，知识应用是上下文一致的：LLM可以在不同上下文中回忆相同的知识。现有的工作忽视了这一属性，并且编辑缺乏普适性。本文通过实验证明，不同上下文对于LLM在回忆相同知识时的影响符合高斯分布。我们随后对高斯噪声进行采样，模拟在更新LLM时不同上下文的影响。通过这样的方式，我们可以使LLM看到将应用编辑后知识的未见上下文，从而改善编辑的推广性。对三个LLM的实验结果证明了我们方法的有效性，并且将我们的方法与通过噪声微调LLM的其他方法区分开来。",
    "tldr": "本文通过对不同上下文对大型语言模型的影响进行高斯噪声采样，实现了对知识编辑的上下文一致性进行更好的推广，提高了编辑的普适性。",
    "en_tdlr": "This paper improves the generalization of knowledge editing by sampling Gaussian noises to simulate the effects of different contexts on large language models (LLMs), allowing LLMs to see the unseen contexts where the edited knowledge will be applied. Experimental results demonstrate the effectiveness of this approach and distinguish it from other methods of fine-tuning LLMs with noises."
}