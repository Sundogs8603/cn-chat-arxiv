{
    "title": "An Optimal Transport Approach for Computing Adversarial Training Lower Bounds in Multiclass Classification. (arXiv:2401.09191v1 [cs.LG])",
    "abstract": "Despite the success of deep learning-based algorithms, it is widely known that neural networks may fail to be robust. A popular paradigm to enforce robustness is adversarial training (AT), however, this introduces many computational and theoretical difficulties. Recent works have developed a connection between AT in the multiclass classification setting and multimarginal optimal transport (MOT), unlocking a new set of tools to study this problem. In this paper, we leverage the MOT connection to propose computationally tractable numerical algorithms for computing universal lower bounds on the optimal adversarial risk and identifying optimal classifiers. We propose two main algorithms based on linear programming (LP) and entropic regularization (Sinkhorn). Our key insight is that one can harmlessly truncate the higher order interactions between classes, preventing the combinatorial run times typically encountered in MOT problems. We validate these results with experiments on MNIST and CI",
    "link": "http://arxiv.org/abs/2401.09191",
    "context": "Title: An Optimal Transport Approach for Computing Adversarial Training Lower Bounds in Multiclass Classification. (arXiv:2401.09191v1 [cs.LG])\nAbstract: Despite the success of deep learning-based algorithms, it is widely known that neural networks may fail to be robust. A popular paradigm to enforce robustness is adversarial training (AT), however, this introduces many computational and theoretical difficulties. Recent works have developed a connection between AT in the multiclass classification setting and multimarginal optimal transport (MOT), unlocking a new set of tools to study this problem. In this paper, we leverage the MOT connection to propose computationally tractable numerical algorithms for computing universal lower bounds on the optimal adversarial risk and identifying optimal classifiers. We propose two main algorithms based on linear programming (LP) and entropic regularization (Sinkhorn). Our key insight is that one can harmlessly truncate the higher order interactions between classes, preventing the combinatorial run times typically encountered in MOT problems. We validate these results with experiments on MNIST and CI",
    "path": "papers/24/01/2401.09191.json",
    "total_tokens": 917,
    "translated_title": "一个用于计算多类分类中对抗训练下界的最优输运方法",
    "translated_abstract": "尽管基于深度学习的算法取得了很大的成功，但广为人知的是神经网络可能缺乏鲁棒性。强制鲁棒性的流行范式是对抗训练（AT），然而，这引入了许多计算和理论上的困难。最近的研究在多类分类设置和多边际最优输运（MOT）之间建立了联系，为研究这个问题提供了一套新的工具。在本文中，我们利用MOT的连接，提出了计算上最简便可行的数值算法来计算最优对抗风险的普遍下界，并确定最优分类器。我们基于线性规划（LP）和熵正则化（Sinkhorn）提出了两个主要算法。我们的关键洞察是可以无害地截断类之间的高阶相互作用，从而避免了在MOT问题中通常遇到的组合运行时间。我们通过在MNIST和CI 上进行实验证实了这些结果",
    "tldr": "本文提出了一个用于计算多类分类中对抗训练下界的最优输运方法，并利用该方法提出了计算最优对抗风险下界和确定最优分类器的算法。通过截断类之间的高阶相互作用，避免了组合运行时间的问题。",
    "en_tdlr": "This paper proposes an optimal transport approach for computing adversarial training lower bounds in multiclass classification, and introduces algorithms to compute universal lower bounds on optimal adversarial risk and identify optimal classifiers. By truncating higher order interactions between classes, the computational complexity is mitigated."
}