{
    "title": "TAROT: A Hierarchical Framework with Multitask Co-Pretraining on Semi-Structured Data towards Effective Person-Job Fit. (arXiv:2401.07525v2 [cs.CL] UPDATED)",
    "abstract": "Person-job fit is an essential part of online recruitment platforms in serving various downstream applications like Job Search and Candidate Recommendation. Recently, pretrained large language models have further enhanced the effectiveness by leveraging richer textual information in user profiles and job descriptions apart from user behavior features and job metadata. However, the general domain-oriented design struggles to capture the unique structural information within user profiles and job descriptions, leading to a loss of latent semantic correlations. We propose TAROT, a hierarchical multitask co-pretraining framework, to better utilize structural and semantic information for informative text embeddings. TAROT targets semi-structured text in profiles and jobs, and it is co-pretained with multi-grained pretraining tasks to constrain the acquired semantic information at each level. Experiments on a real-world LinkedIn dataset show significant performance improvements, proving its e",
    "link": "http://arxiv.org/abs/2401.07525",
    "context": "Title: TAROT: A Hierarchical Framework with Multitask Co-Pretraining on Semi-Structured Data towards Effective Person-Job Fit. (arXiv:2401.07525v2 [cs.CL] UPDATED)\nAbstract: Person-job fit is an essential part of online recruitment platforms in serving various downstream applications like Job Search and Candidate Recommendation. Recently, pretrained large language models have further enhanced the effectiveness by leveraging richer textual information in user profiles and job descriptions apart from user behavior features and job metadata. However, the general domain-oriented design struggles to capture the unique structural information within user profiles and job descriptions, leading to a loss of latent semantic correlations. We propose TAROT, a hierarchical multitask co-pretraining framework, to better utilize structural and semantic information for informative text embeddings. TAROT targets semi-structured text in profiles and jobs, and it is co-pretained with multi-grained pretraining tasks to constrain the acquired semantic information at each level. Experiments on a real-world LinkedIn dataset show significant performance improvements, proving its e",
    "path": "papers/24/01/2401.07525.json",
    "total_tokens": 876,
    "translated_title": "TAROT：一种在半结构化数据上进行多任务预训练的层次框架，以实现有效的人-岗位匹配",
    "translated_abstract": "人-岗位匹配是在线招聘平台中的重要部分，可以用于各种下游应用，如职位搜索和候选人推荐。最近，预训练的大型语言模型通过利用用户简介和职位描述中的丰富文本信息以及用户行为特征和职位元数据，进一步增强了效果。然而，一般的面向领域的设计难以捕捉用户简介和职位描述中的独特结构信息，导致潜在语义相关性的丧失。我们提出了TAROT，一种层次化的多任务共同预训练框架，以更好地利用结构和语义信息进行信息性文本嵌入。TAROT针对简介和职位中的半结构化文本进行预训练，并通过多颗粒度的预训练任务来约束每个层次上获取的语义信息。在真实的LinkedIn数据集上的实验证明了显著的性能改进，验证了其有效性。",
    "tldr": "TAROT是一个层次化的多任务预训练框架，通过对半结构化数据进行预训练，结合多粒度的任务来提升人-岗位匹配的效果。",
    "en_tdlr": "TAROT is a hierarchical multitask co-pretraining framework that improves person-job fit by pretraining on semi-structured data and integrating multi-grained tasks."
}