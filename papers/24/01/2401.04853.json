{
    "title": "Entity Recognition from Colloquial Text. (arXiv:2401.04853v1 [cs.CL])",
    "abstract": "Extraction of concepts and entities of interest from non-formal texts such as social media posts and informal communication is an important capability for decision support systems in many domains, including healthcare, customer relationship management, and others. Despite the recent advances in training large language models for a variety of natural language processing tasks, the developed models and techniques have mainly focused on formal texts and do not perform as well on colloquial data, which is characterized by a number of distinct challenges. In our research, we focus on the healthcare domain and investigate the problem of symptom recognition from colloquial texts by designing and evaluating several training strategies for BERT-based model fine-tuning. These strategies are distinguished by the choice of the base model, the training corpora, and application of term perturbations in the training data. The best-performing models trained using these strategies outperform the state-",
    "link": "http://arxiv.org/abs/2401.04853",
    "context": "Title: Entity Recognition from Colloquial Text. (arXiv:2401.04853v1 [cs.CL])\nAbstract: Extraction of concepts and entities of interest from non-formal texts such as social media posts and informal communication is an important capability for decision support systems in many domains, including healthcare, customer relationship management, and others. Despite the recent advances in training large language models for a variety of natural language processing tasks, the developed models and techniques have mainly focused on formal texts and do not perform as well on colloquial data, which is characterized by a number of distinct challenges. In our research, we focus on the healthcare domain and investigate the problem of symptom recognition from colloquial texts by designing and evaluating several training strategies for BERT-based model fine-tuning. These strategies are distinguished by the choice of the base model, the training corpora, and application of term perturbations in the training data. The best-performing models trained using these strategies outperform the state-",
    "path": "papers/24/01/2401.04853.json",
    "total_tokens": 936,
    "translated_title": "从口语文本中进行实体识别",
    "translated_abstract": "从非正式文本（如社交媒体帖子和非正式交流）中提取概念和感兴趣的实体是决策支持系统在许多领域（包括医疗保健、客户关系管理等）中的重要能力。尽管近年来在训练大型语言模型以解决各种自然语言处理任务方面取得了进展，但这些模型和技术主要集中在正式文本上，在非正式数据上的表现较差，而非正式数据具有一些独特的挑战。在我们的研究中，我们关注医疗保健领域，并通过设计和评估BERT-based模型微调的几种训练策略，研究了从口语文本中识别症状的问题。这些策略通过选择基础模型、训练语料库以及在训练数据中应用术语扰动来区分。使用这些策略训练的最佳模型胜过了当前最先进的模型。",
    "tldr": "本论文研究了从非正式文本中进行实体识别的问题，特别关注医疗保健领域中从口语文本中识别症状的问题。通过设计和评估多个训练策略，使用BERT-based模型的微调，本研究找到了在非正式数据上表现较好的模型。",
    "en_tdlr": "This paper investigates entity recognition from non-formal text, with a specific focus on symptom recognition from colloquial texts in the healthcare domain. By designing and evaluating multiple training strategies using BERT-based model fine-tuning, the study identifies models that outperform current state-of-the-art approaches on colloquial data."
}