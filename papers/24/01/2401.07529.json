{
    "title": "MM-SAP: A Comprehensive Benchmark for Assessing Self-Awareness of Multimodal Large Language Models in Perception",
    "abstract": "arXiv:2401.07529v2 Announce Type: replace-cross  Abstract: Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated exceptional capabilities in visual perception and understanding. However, these models also suffer from hallucinations, which limit their reliability as AI systems. We believe that these hallucinations are partially due to the models' struggle with understanding what they can and cannot perceive from images, a capability we refer to as self-awareness in perception. Despite its importance, this aspect of MLLMs has been overlooked in prior studies. In this paper, we aim to define and evaluate the self-awareness of MLLMs in perception. To do this, we first introduce the knowledge quadrant in perception, which helps define what MLLMs know and do not know about images. Using this framework, we propose a novel benchmark, the Self-Awareness in Perception for MLLMs (MM-SAP), specifically designed to assess this capability. We apply MM-SAP to a variety of ",
    "link": "https://arxiv.org/abs/2401.07529",
    "context": "Title: MM-SAP: A Comprehensive Benchmark for Assessing Self-Awareness of Multimodal Large Language Models in Perception\nAbstract: arXiv:2401.07529v2 Announce Type: replace-cross  Abstract: Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated exceptional capabilities in visual perception and understanding. However, these models also suffer from hallucinations, which limit their reliability as AI systems. We believe that these hallucinations are partially due to the models' struggle with understanding what they can and cannot perceive from images, a capability we refer to as self-awareness in perception. Despite its importance, this aspect of MLLMs has been overlooked in prior studies. In this paper, we aim to define and evaluate the self-awareness of MLLMs in perception. To do this, we first introduce the knowledge quadrant in perception, which helps define what MLLMs know and do not know about images. Using this framework, we propose a novel benchmark, the Self-Awareness in Perception for MLLMs (MM-SAP), specifically designed to assess this capability. We apply MM-SAP to a variety of ",
    "path": "papers/24/01/2401.07529.json",
    "total_tokens": 904,
    "translated_title": "MM-SAP：用于评估多模态大型语言模型自我意识在感知中的全面基准",
    "translated_abstract": "多模态大型语言模型（MLLMs）近期的进展展示了其在视觉感知和理解方面出色的能力。然而，这些模型也存在幻觉问题，这限制了它们作为人工智能系统的可靠性。我们认为这些幻觉部分原因在于模型在理解从图像中能够和不能够感知的内容方面存在困难，这种能力我们称之为感知中的自我意识。尽管重要性重大，在先前的研究中却忽视了MLLMs的这个方面。本文旨在定义和评估MLLMs在感知中的自我意识。为此，我们首先引入了感知中的知识象限，这有助于定义MLLMs对图像了解和不了解的内容。利用这一框架，我们提出了一项新颖的基准，即专门设计用于评估这种能力的MLLMs感知中的自我意识基准（MM-SAP）。我们将MM-SAP应用于各种情况",
    "tldr": "本论文提出了一个新的基准MM-SAP，旨在评估多模态大型语言模型在感知中的自我意识能力，填补了先前研究中忽视的领域。",
    "en_tdlr": "This paper introduces a new benchmark MM-SAP, aiming to assess the self-awareness capability of multimodal large language models in perception, filling a gap in prior studies."
}