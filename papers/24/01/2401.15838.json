{
    "title": "Distributed Markov Chain Monte Carlo Sampling based on the Alternating Direction Method of Multipliers. (arXiv:2401.15838v1 [stat.ML])",
    "abstract": "Many machine learning applications require operating on a spatially distributed dataset. Despite technological advances, privacy considerations and communication constraints may prevent gathering the entire dataset in a central unit. In this paper, we propose a distributed sampling scheme based on the alternating direction method of multipliers, which is commonly used in the optimization literature due to its fast convergence. In contrast to distributed optimization, distributed sampling allows for uncertainty quantification in Bayesian inference tasks. We provide both theoretical guarantees of our algorithm's convergence and experimental evidence of its superiority to the state-of-the-art. For our theoretical results, we use convex optimization tools to establish a fundamental inequality on the generated local sample iterates. This inequality enables us to show convergence of the distribution associated with these iterates to the underlying target distribution in Wasserstein distance.",
    "link": "http://arxiv.org/abs/2401.15838",
    "context": "Title: Distributed Markov Chain Monte Carlo Sampling based on the Alternating Direction Method of Multipliers. (arXiv:2401.15838v1 [stat.ML])\nAbstract: Many machine learning applications require operating on a spatially distributed dataset. Despite technological advances, privacy considerations and communication constraints may prevent gathering the entire dataset in a central unit. In this paper, we propose a distributed sampling scheme based on the alternating direction method of multipliers, which is commonly used in the optimization literature due to its fast convergence. In contrast to distributed optimization, distributed sampling allows for uncertainty quantification in Bayesian inference tasks. We provide both theoretical guarantees of our algorithm's convergence and experimental evidence of its superiority to the state-of-the-art. For our theoretical results, we use convex optimization tools to establish a fundamental inequality on the generated local sample iterates. This inequality enables us to show convergence of the distribution associated with these iterates to the underlying target distribution in Wasserstein distance.",
    "path": "papers/24/01/2401.15838.json",
    "total_tokens": 849,
    "translated_title": "基于交替方向乘子法的分布式马尔可夫链蒙特卡罗抽样",
    "translated_abstract": "许多机器学习应用需要对空间分布的数据集进行操作。尽管技术进步，但隐私考虑和通信约束可能阻止将整个数据集收集到一个中心单位。在本文中，我们提出了一种基于交替方向乘子法的分布式抽样方案，该方法由于其快速收敛在优化文献中常被使用。与分布式优化相比，分布式抽样可以在贝叶斯推断任务中进行不确定性量化。我们提供了算法收敛的理论保证和实验数据证明其优于现有方法。在我们的理论结果中，我们使用凸优化工具建立了生成的本地样本迭代的基本不等式。这个不等式使我们能够证明与这些迭代相关的分布以Wasserstein距离收敛到潜在目标分布。",
    "tldr": "本文提出了一种基于交替方向乘子法的分布式抽样方案，能够在分布式环境中进行马尔可夫链蒙特卡罗抽样，从而实现贝叶斯推断任务中的不确定性量化。实验证明该方案优于现有方法。"
}