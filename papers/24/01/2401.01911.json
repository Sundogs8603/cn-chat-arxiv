{
    "title": "Backdoor Attack on Unpaired Medical Image-Text Foundation Models: A Pilot Study on MedCLIP. (arXiv:2401.01911v1 [cs.CV])",
    "abstract": "In recent years, foundation models (FMs) have solidified their role as cornerstone advancements in the deep learning domain. By extracting intricate patterns from vast datasets, these models consistently achieve state-of-the-art results across a spectrum of downstream tasks, all without necessitating extensive computational resources. Notably, MedCLIP, a vision-language contrastive learning-based medical FM, has been designed using unpaired image-text training. While the medical domain has often adopted unpaired training to amplify data, the exploration of potential security concerns linked to this approach hasn't kept pace with its practical usage. Notably, the augmentation capabilities inherent in unpaired training also indicate that minor label discrepancies can result in significant model deviations. In this study, we frame this label discrepancy as a backdoor attack problem. We further analyze its impact on medical FMs throughout the FM supply chain. Our evaluation primarily revol",
    "link": "http://arxiv.org/abs/2401.01911",
    "context": "Title: Backdoor Attack on Unpaired Medical Image-Text Foundation Models: A Pilot Study on MedCLIP. (arXiv:2401.01911v1 [cs.CV])\nAbstract: In recent years, foundation models (FMs) have solidified their role as cornerstone advancements in the deep learning domain. By extracting intricate patterns from vast datasets, these models consistently achieve state-of-the-art results across a spectrum of downstream tasks, all without necessitating extensive computational resources. Notably, MedCLIP, a vision-language contrastive learning-based medical FM, has been designed using unpaired image-text training. While the medical domain has often adopted unpaired training to amplify data, the exploration of potential security concerns linked to this approach hasn't kept pace with its practical usage. Notably, the augmentation capabilities inherent in unpaired training also indicate that minor label discrepancies can result in significant model deviations. In this study, we frame this label discrepancy as a backdoor attack problem. We further analyze its impact on medical FMs throughout the FM supply chain. Our evaluation primarily revol",
    "path": "papers/24/01/2401.01911.json",
    "total_tokens": 928,
    "translated_title": "对非配对的医学图像-文本基础模型的后门攻击：MedCLIP的试验研究",
    "translated_abstract": "在最近几年中，基础模型（FMs）在深度学习领域中已经确立了其作为基石性进展的角色。通过从大量数据集中提取复杂模式，这些模型始终在各种下游任务中实现最先进的结果，而又不需要大量的计算资源。值得注意的是，基于对比学习的视觉-语言对照学习医学FM MedCLIP采用了非配对的图像-文本训练。虽然医学领域经常采用非配对训练来增强数据，但与该方法相关的潜在安全问题的探索并未跟上其实际使用的步伐。值得注意的是，非配对训练中固有的增强能力也表明微小的标签差异可能导致重要的模型偏差。在本研究中，我们将这种标签差异框架化为后门攻击问题，并进一步分析其对整个FM供应链的影响。我们的评估主要围绕对医学FMs的研究。",
    "tldr": "该研究探讨了医学图像-文本基础模型中非配对训练引发的标签差异问题，并以此作为后门攻击的案例研究，分析了其对医学FM供应链的影响。",
    "en_tdlr": "This study examines the issue of label discrepancies in unpaired training of medical image-text foundation models and presents it as a case study for backdoor attacks, analyzing its impact on the medical FM supply chain."
}