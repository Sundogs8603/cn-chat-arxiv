{
    "title": "Explainable data-driven modeling via mixture of experts: towards effective blending of grey and black-box models. (arXiv:2401.17118v1 [cs.LG])",
    "abstract": "Traditional models grounded in first principles often struggle with accuracy as the system's complexity increases. Conversely, machine learning approaches, while powerful, face challenges in interpretability and in handling physical constraints. Efforts to combine these models often often stumble upon difficulties in finding a balance between accuracy and complexity. To address these issues, we propose a comprehensive framework based on a \"mixture of experts\" rationale. This approach enables the data-based fusion of diverse local models, leveraging the full potential of first-principle-based priors. Our solution allows independent training of experts, drawing on techniques from both machine learning and system identification, and it supports both collaborative and competitive learning paradigms. To enhance interpretability, we penalize abrupt variations in the expert's combination. Experimental results validate the effectiveness of our approach in producing an interpretable combination",
    "link": "http://arxiv.org/abs/2401.17118",
    "context": "Title: Explainable data-driven modeling via mixture of experts: towards effective blending of grey and black-box models. (arXiv:2401.17118v1 [cs.LG])\nAbstract: Traditional models grounded in first principles often struggle with accuracy as the system's complexity increases. Conversely, machine learning approaches, while powerful, face challenges in interpretability and in handling physical constraints. Efforts to combine these models often often stumble upon difficulties in finding a balance between accuracy and complexity. To address these issues, we propose a comprehensive framework based on a \"mixture of experts\" rationale. This approach enables the data-based fusion of diverse local models, leveraging the full potential of first-principle-based priors. Our solution allows independent training of experts, drawing on techniques from both machine learning and system identification, and it supports both collaborative and competitive learning paradigms. To enhance interpretability, we penalize abrupt variations in the expert's combination. Experimental results validate the effectiveness of our approach in producing an interpretable combination",
    "path": "papers/24/01/2401.17118.json",
    "total_tokens": 897,
    "translated_title": "通过专家混合实现可解释的数据驱动建模：实现灰盒和黑盒模型的有效融合",
    "translated_abstract": "随着系统的复杂性增加，传统的基于第一原理的模型常常在准确性上遇到困难。与此相反，机器学习方法虽然功能强大，但在可解释性和处理物理约束方面面临挑战。将这些模型结合起来的努力往往很难在准确性和复杂性之间找到平衡。为了解决这些问题，我们提出了一个基于“专家混合”原理的综合框架。这种方法可以对多样化的局部模型进行基于数据的融合，利用基于第一原理的先验知识的全部潜力。我们的解决方案允许专家的独立训练，借鉴了机器学习和系统识别的技术，并支持协作和竞争学习范式。为了增强可解释性，我们对专家的组合中的突变进行了惩罚。实验结果验证了我们的方法在生成可解释的组合方面的有效性。",
    "tldr": "这个论文提出了一种基于“专家混合”原理的综合框架，通过将灰盒和黑盒模型进行数据驱动的融合，实现了对复杂系统的准确建模，并提高了可解释性。"
}