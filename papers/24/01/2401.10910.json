{
    "title": "Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior. (arXiv:2401.10910v1 [q-bio.NC])",
    "abstract": "Recent advances in Large Language Models (LLMs) have shown impressive capabilities in various applications, yet LLMs face challenges such as limited context windows and difficulties in generalization. In this paper, we introduce a metacognition module for generative agents, enabling them to observe their own thought processes and actions. This metacognitive approach, designed to emulate System 1 and System 2 cognitive processes, allows agents to significantly enhance their performance by modifying their strategy. We tested the metacognition module on a variety of scenarios, including a situation where generative agents must survive a zombie apocalypse, and observe that our system outperform others, while agents adapt and improve their strategies to complete tasks over time.",
    "link": "http://arxiv.org/abs/2401.10910",
    "context": "Title: Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior. (arXiv:2401.10910v1 [q-bio.NC])\nAbstract: Recent advances in Large Language Models (LLMs) have shown impressive capabilities in various applications, yet LLMs face challenges such as limited context windows and difficulties in generalization. In this paper, we introduce a metacognition module for generative agents, enabling them to observe their own thought processes and actions. This metacognitive approach, designed to emulate System 1 and System 2 cognitive processes, allows agents to significantly enhance their performance by modifying their strategy. We tested the metacognition module on a variety of scenarios, including a situation where generative agents must survive a zombie apocalypse, and observe that our system outperform others, while agents adapt and improve their strategies to complete tasks over time.",
    "path": "papers/24/01/2401.10910.json",
    "total_tokens": 868,
    "translated_title": "元认知是你所需要的吗？在生成式智能体中使用内省以提高目标导向行为",
    "translated_abstract": "最近大型语言模型（LLMs）的进展在各种应用中展示了令人印象深刻的能力，然而LLMs面临着有限的上下文窗口和泛化困难等挑战。在本文中，我们引入了一个元认知模块用于生成式智能体，使其能够观察自己的思考过程和行动。这种元认知方法旨在模拟系统1和系统2的认知过程，使智能体能够通过修改策略显著提高性能。我们在各种场景下测试了元认知模块，包括生成式智能体必须在僵尸启示录中存活的情况，并观察到我们的系统在表现上超过其他系统，同时智能体能够随着时间适应和改进策略以完成任务。",
    "tldr": "本文介绍了一个使用内省的元认知模块，可以让生成式智能体观察自己的思考过程和行动，并通过修改策略来显著提高性能。通过在多种场景下测试，我们观察到该系统在与其他系统的比较中取得了优势，智能体能够适应和改进策略以完成任务。",
    "en_tdlr": "This paper introduces a metacognition module that allows generative agents to observe their own thought processes and actions, and significantly improve performance by modifying strategies. Testing in various scenarios, it outperforms other systems, with agents adapting and improving strategies to complete tasks over time."
}