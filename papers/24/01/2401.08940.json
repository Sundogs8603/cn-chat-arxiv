{
    "title": "CEL: A Continual Learning Model for Disease Outbreak Prediction by Leveraging Domain Adaptation via Elastic Weight Consolidation. (arXiv:2401.08940v1 [cs.LG])",
    "abstract": "Continual learning, the ability of a model to learn over time without forgetting previous knowledge and, therefore, be adaptive to new data, is paramount in dynamic fields such as disease outbreak prediction. Deep neural networks, i.e., LSTM, are prone to error due to catastrophic forgetting. This study introduces a novel CEL model for continual learning by leveraging domain adaptation via Elastic Weight Consolidation (EWC). This model aims to mitigate the catastrophic forgetting phenomenon in a domain incremental setting. The Fisher Information Matrix (FIM) is constructed with EWC to develop a regularization term that penalizes changes to important parameters, namely, the important previous knowledge. CEL's performance is evaluated on three distinct diseases, Influenza, Mpox, and Measles, with different metrics. The high R-squared values during evaluation and reevaluation outperform the other state-of-the-art models in several contexts, indicating that CEL adapts to incremental data w",
    "link": "http://arxiv.org/abs/2401.08940",
    "context": "Title: CEL: A Continual Learning Model for Disease Outbreak Prediction by Leveraging Domain Adaptation via Elastic Weight Consolidation. (arXiv:2401.08940v1 [cs.LG])\nAbstract: Continual learning, the ability of a model to learn over time without forgetting previous knowledge and, therefore, be adaptive to new data, is paramount in dynamic fields such as disease outbreak prediction. Deep neural networks, i.e., LSTM, are prone to error due to catastrophic forgetting. This study introduces a novel CEL model for continual learning by leveraging domain adaptation via Elastic Weight Consolidation (EWC). This model aims to mitigate the catastrophic forgetting phenomenon in a domain incremental setting. The Fisher Information Matrix (FIM) is constructed with EWC to develop a regularization term that penalizes changes to important parameters, namely, the important previous knowledge. CEL's performance is evaluated on three distinct diseases, Influenza, Mpox, and Measles, with different metrics. The high R-squared values during evaluation and reevaluation outperform the other state-of-the-art models in several contexts, indicating that CEL adapts to incremental data w",
    "path": "papers/24/01/2401.08940.json",
    "total_tokens": 975,
    "translated_title": "CEL：通过弹性权重整合利用领域自适应来进行疾病爆发预测的持续学习模型",
    "translated_abstract": "连续学习是模型在学习过程中不忘记之前知识并能适应新数据的能力，在疾病爆发预测等动态领域尤为重要。深度神经网络，如LSTM，由于灾难性遗忘而容易出错。本研究通过弹性权重整合（EWC）利用领域自适应引入了一种新颖的CEL模型进行持续学习。该模型旨在缓解领域增量设置中的灾难性遗忘现象。利用EWC构建Fisher信息矩阵（FIM）以开发出一个惩罚对重要参数即重要先前知识的改变的正则化项。在评估和重新评估中，CEL的性能使用不同指标在三种不同的疾病（流感，痘疹和麻疹）上得到了很高的R-squared值，胜过其他最先进的模型，在多个上下文中表明CEL对增量数据具有适应能力。",
    "tldr": "本研究提出了一种名为CEL的模型，通过利用领域自适应和弹性权重整合，实现了对疾病爆发预测的持续学习。该模型通过惩罚重要参数的改变来缓解灾难性遗忘现象，并在多个疾病上取得了比其他模型更好的性能。"
}