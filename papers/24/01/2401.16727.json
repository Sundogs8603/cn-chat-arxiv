{
    "title": "Recent Advances in Hate Speech Moderation: Multimodality and the Role of Large Models. (arXiv:2401.16727v1 [cs.CL])",
    "abstract": "In the evolving landscape of online communication, moderating hate speech (HS) presents an intricate challenge, compounded by the multimodal nature of digital content. This comprehensive survey delves into the recent strides in HS moderation, spotlighting the burgeoning role of large language models (LLMs) and large multimodal models (LMMs). Our exploration begins with a thorough analysis of current literature, revealing the nuanced interplay between textual, visual, and auditory elements in propagating HS. We uncover a notable trend towards integrating these modalities, primarily due to the complexity and subtlety with which HS is disseminated. A significant emphasis is placed on the advances facilitated by LLMs and LMMs, which have begun to redefine the boundaries of detection and moderation capabilities. We identify existing gaps in research, particularly in the context of underrepresented languages and cultures, and the need for solutions to handle low-resource settings. The survey",
    "link": "http://arxiv.org/abs/2401.16727",
    "context": "Title: Recent Advances in Hate Speech Moderation: Multimodality and the Role of Large Models. (arXiv:2401.16727v1 [cs.CL])\nAbstract: In the evolving landscape of online communication, moderating hate speech (HS) presents an intricate challenge, compounded by the multimodal nature of digital content. This comprehensive survey delves into the recent strides in HS moderation, spotlighting the burgeoning role of large language models (LLMs) and large multimodal models (LMMs). Our exploration begins with a thorough analysis of current literature, revealing the nuanced interplay between textual, visual, and auditory elements in propagating HS. We uncover a notable trend towards integrating these modalities, primarily due to the complexity and subtlety with which HS is disseminated. A significant emphasis is placed on the advances facilitated by LLMs and LMMs, which have begun to redefine the boundaries of detection and moderation capabilities. We identify existing gaps in research, particularly in the context of underrepresented languages and cultures, and the need for solutions to handle low-resource settings. The survey",
    "path": "papers/24/01/2401.16727.json",
    "total_tokens": 1018,
    "translated_title": "最近在仇恨言论审核方面的进展：多模态和大型模型的作用",
    "translated_abstract": "在网络交流的不断发展中，审核仇恨言论（HS）面临着复杂的挑战，这是由数字内容的多模态特性所带来的。这项综合调查深入研究了HS审核的最新进展，着重介绍了大型语言模型（LLMs）和大型多模态模型（LMMs）的崛起角色。我们的研究从对当前文献的全面分析开始，揭示了文本、视觉和听觉元素在传播HS中的微妙相互作用。我们发现了一个明显的趋势，即将这些模态整合在一起，主要是因为HS的传播具有复杂性和微妙性。对于由LLMs和LMMs带来的进展，我们特别强调了其对检测和审核能力边界的重新定义。我们确定了研究中存在的现有差距，特别是在少数语言和文化的背景下，以及在处理低资源环境中需要解决方案的需求。",
    "tldr": "这项综合调查总结了最近在仇恨言论审核方面的进展，重点介绍了大型语言模型和大型多模态模型的作用。研究发现了文本、视觉和听觉元素在传播仇恨言论中的微妙相互作用，并强调了大型模型对审核能力的重新定义。同时，研究还指出了在少数语言和文化背景下的研究差距和处理低资源环境的需求。",
    "en_tdlr": "This comprehensive survey summarizes recent advances in hate speech moderation, highlighting the role of large language models and large multimodal models. The study reveals the nuanced interplay between textual, visual, and auditory elements in propagating hate speech, emphasizing the redefinition of moderation capabilities enabled by large models. It also identifies gaps in research and the need for solutions in underrepresented languages and low-resource settings."
}