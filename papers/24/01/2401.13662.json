{
    "title": "The Definitive Guide to Policy Gradients in Deep Reinforcement Learning: Theory, Algorithms and Implementations. (arXiv:2401.13662v1 [cs.LG])",
    "abstract": "In recent years, various powerful policy gradient algorithms have been proposed in deep reinforcement learning. While all these algorithms build on the Policy Gradient Theorem, the specific design choices differ significantly across algorithms. We provide a holistic overview of on-policy policy gradient algorithms to facilitate the understanding of both their theoretical foundations and their practical implementations. In this overview, we include a detailed proof of the continuous version of the Policy Gradient Theorem, convergence results and a comprehensive discussion of practical algorithms. We compare the most prominent algorithms on continuous control environments and provide insights on the benefits of regularization. All code is available at https://github.com/Matt00n/PolicyGradientsJax.",
    "link": "http://arxiv.org/abs/2401.13662",
    "context": "Title: The Definitive Guide to Policy Gradients in Deep Reinforcement Learning: Theory, Algorithms and Implementations. (arXiv:2401.13662v1 [cs.LG])\nAbstract: In recent years, various powerful policy gradient algorithms have been proposed in deep reinforcement learning. While all these algorithms build on the Policy Gradient Theorem, the specific design choices differ significantly across algorithms. We provide a holistic overview of on-policy policy gradient algorithms to facilitate the understanding of both their theoretical foundations and their practical implementations. In this overview, we include a detailed proof of the continuous version of the Policy Gradient Theorem, convergence results and a comprehensive discussion of practical algorithms. We compare the most prominent algorithms on continuous control environments and provide insights on the benefits of regularization. All code is available at https://github.com/Matt00n/PolicyGradientsJax.",
    "path": "papers/24/01/2401.13662.json",
    "total_tokens": 790,
    "translated_title": "深度强化学习中策略梯度的终极指南：理论、算法和实现",
    "translated_abstract": "最近几年，在深度强化学习中提出了各种强大的策略梯度算法。虽然所有这些算法都建立在策略梯度定理的基础上，但具体的设计选择在算法之间有很大的差异。我们提供了一个整体的视角来概述在线策略梯度算法，以便理解它们的理论基础和实际实现。在这个概述中，我们包括了连续版本的策略梯度定理的详细证明、收敛结果和对实际算法的全面讨论。我们比较了连续控制环境中最重要的算法，并对正则化的益处提供了深入的见解。所有的代码都可以在https://github.com/Matt00n/PolicyGradientsJax获得。",
    "tldr": "本文提供了一个深度强化学习中策略梯度算法的综合指南，包括理论基础、实际实现和比较结果，并对正则化的益处进行了讨论。",
    "en_tdlr": "This paper provides a comprehensive guide to policy gradient algorithms in deep reinforcement learning, including theoretical foundations, practical implementations, and comparison results, with a discussion on the benefits of regularization."
}