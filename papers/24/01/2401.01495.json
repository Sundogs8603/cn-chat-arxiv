{
    "title": "A Two-Stage Multimodal Emotion Recognition Model Based on Graph Contrastive Learning. (arXiv:2401.01495v1 [cs.CL])",
    "abstract": "In terms of human-computer interaction, it is becoming more and more important to correctly understand the user's emotional state in a conversation, so the task of multimodal emotion recognition (MER) started to receive more attention. However, existing emotion classification methods usually perform classification only once. Sentences are likely to be misclassified in a single round of classification. Previous work usually ignores the similarities and differences between different morphological features in the fusion process. To address the above issues, we propose a two-stage emotion recognition model based on graph contrastive learning (TS-GCL). First, we encode the original dataset with different preprocessing modalities. Second, a graph contrastive learning (GCL) strategy is introduced for these three modal data with other structures to learn similarities and differences within and between modalities. Finally, we use MLP twice to achieve the final emotion classification. This stage",
    "link": "http://arxiv.org/abs/2401.01495",
    "context": "Title: A Two-Stage Multimodal Emotion Recognition Model Based on Graph Contrastive Learning. (arXiv:2401.01495v1 [cs.CL])\nAbstract: In terms of human-computer interaction, it is becoming more and more important to correctly understand the user's emotional state in a conversation, so the task of multimodal emotion recognition (MER) started to receive more attention. However, existing emotion classification methods usually perform classification only once. Sentences are likely to be misclassified in a single round of classification. Previous work usually ignores the similarities and differences between different morphological features in the fusion process. To address the above issues, we propose a two-stage emotion recognition model based on graph contrastive learning (TS-GCL). First, we encode the original dataset with different preprocessing modalities. Second, a graph contrastive learning (GCL) strategy is introduced for these three modal data with other structures to learn similarities and differences within and between modalities. Finally, we use MLP twice to achieve the final emotion classification. This stage",
    "path": "papers/24/01/2401.01495.json",
    "total_tokens": 916,
    "translated_title": "基于图形对比学习的两阶段多模态情绪识别模型",
    "translated_abstract": "在人机交互方面，正确理解用户在对话中的情绪状态变得越来越重要，因此多模态情绪识别（MER）的任务开始受到更多关注。然而，现有的情绪分类方法通常只进行一次分类，句子在单轮分类中很可能被错误分类。先前的工作通常忽略了融合过程中不同形态特征之间的相似性和差异性。为了解决上述问题，我们提出了一种基于图形对比学习的两阶段情绪识别模型（TS-GCL）。首先，我们使用不同的预处理模态对原始数据集进行编码。其次，引入了图形对比学习（GCL）策略，通过其他结构对这三个模态数据进行学习，以了解模态内部的相似性和差异性。最后，我们使用MLP两次进行最终的情绪分类。",
    "tldr": "该论文提出了一种基于图形对比学习的两阶段多模态情绪识别模型。首先，将原始数据集用不同预处理模态进行编码；然后，引入了图形对比学习策略，通过其他结构对不同模态数据进行学习，以了解模态内部的相似性和差异性；最后，使用MLP进行最终的情绪分类。",
    "en_tdlr": "This paper proposes a two-stage multimodal emotion recognition model based on graph contrastive learning. It encodes the original dataset with different preprocessing modalities, introduces a graph contrastive learning strategy to learn the similarities and differences within and between modalities, and uses MLP for final emotion classification."
}