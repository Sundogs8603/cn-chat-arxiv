{
    "title": "pix2gestalt: Amodal Segmentation by Synthesizing Wholes. (arXiv:2401.14398v1 [cs.CV])",
    "abstract": "We introduce pix2gestalt, a framework for zero-shot amodal segmentation, which learns to estimate the shape and appearance of whole objects that are only partially visible behind occlusions. By capitalizing on large-scale diffusion models and transferring their representations to this task, we learn a conditional diffusion model for reconstructing whole objects in challenging zero-shot cases, including examples that break natural and physical priors, such as art. As training data, we use a synthetically curated dataset containing occluded objects paired with their whole counterparts. Experiments show that our approach outperforms supervised baselines on established benchmarks. Our model can furthermore be used to significantly improve the performance of existing object recognition and 3D reconstruction methods in the presence of occlusions.",
    "link": "http://arxiv.org/abs/2401.14398",
    "context": "Title: pix2gestalt: Amodal Segmentation by Synthesizing Wholes. (arXiv:2401.14398v1 [cs.CV])\nAbstract: We introduce pix2gestalt, a framework for zero-shot amodal segmentation, which learns to estimate the shape and appearance of whole objects that are only partially visible behind occlusions. By capitalizing on large-scale diffusion models and transferring their representations to this task, we learn a conditional diffusion model for reconstructing whole objects in challenging zero-shot cases, including examples that break natural and physical priors, such as art. As training data, we use a synthetically curated dataset containing occluded objects paired with their whole counterparts. Experiments show that our approach outperforms supervised baselines on established benchmarks. Our model can furthermore be used to significantly improve the performance of existing object recognition and 3D reconstruction methods in the presence of occlusions.",
    "path": "papers/24/01/2401.14398.json",
    "total_tokens": 888,
    "translated_title": "pix2gestalt：通过合成整体进行非模态分割",
    "translated_abstract": "我们介绍了pix2gestalt，一个用于零样本非模态分割的框架，它学习估计部分被遮挡的整个对象的形状和外观。通过利用大规模扩散模型并将它们的表示迁移到这个任务上，我们学习了一个条件扩散模型，用于在具有挑战性的零样本情况下重建整个对象，包括违反自然和物理先验的艺术品等示例。作为训练数据，我们使用一个经过合成筛选的数据集，其中包含带有遮挡对象及其整个对象对应物的配对。实验证明，我们的方法在已建立的基准测试中优于有监督的基线方法。此外，在存在遮挡的情况下，我们的模型还可以显著提高现有对象识别和3D重建方法的性能。",
    "tldr": "pix2gestalt是一个用于零样本非模态分割的框架，能够学习估计被遮挡的整个对象的形状和外观，通过利用大规模扩散模型，学习条件扩散模型来重建整个对象，在多个基准测试中优于有监督的基线方法，同时可以显著提高在存在遮挡情况下的对象识别和3D重建方法的性能。",
    "en_tdlr": "pix2gestalt is a framework for zero-shot amodal segmentation that learns to estimate the shape and appearance of partially occluded whole objects. It outperforms supervised baselines on established benchmarks and significantly improves the performance of existing object recognition and 3D reconstruction methods in the presence of occlusions."
}