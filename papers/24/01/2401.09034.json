{
    "title": "UOEP: User-Oriented Exploration Policy for Enhancing Long-Term User Experiences in Recommender Systems. (arXiv:2401.09034v1 [cs.IR])",
    "abstract": "Reinforcement learning (RL) has gained traction for enhancing user long-term experiences in recommender systems by effectively exploring users' interests. However, modern recommender systems exhibit distinct user behavioral patterns among tens of millions of items, which increases the difficulty of exploration. For example, user behaviors with different activity levels require varying intensity of exploration, while previous studies often overlook this aspect and apply a uniform exploration strategy to all users, which ultimately hurts user experiences in the long run. To address these challenges, we propose User-Oriented Exploration Policy (UOEP), a novel approach facilitating fine-grained exploration among user groups. We first construct a distributional critic which allows policy optimization under varying quantile levels of cumulative reward feedbacks from users, representing user groups with varying activity levels. Guided by this critic, we devise a population of distinct actors ",
    "link": "http://arxiv.org/abs/2401.09034",
    "context": "Title: UOEP: User-Oriented Exploration Policy for Enhancing Long-Term User Experiences in Recommender Systems. (arXiv:2401.09034v1 [cs.IR])\nAbstract: Reinforcement learning (RL) has gained traction for enhancing user long-term experiences in recommender systems by effectively exploring users' interests. However, modern recommender systems exhibit distinct user behavioral patterns among tens of millions of items, which increases the difficulty of exploration. For example, user behaviors with different activity levels require varying intensity of exploration, while previous studies often overlook this aspect and apply a uniform exploration strategy to all users, which ultimately hurts user experiences in the long run. To address these challenges, we propose User-Oriented Exploration Policy (UOEP), a novel approach facilitating fine-grained exploration among user groups. We first construct a distributional critic which allows policy optimization under varying quantile levels of cumulative reward feedbacks from users, representing user groups with varying activity levels. Guided by this critic, we devise a population of distinct actors ",
    "path": "papers/24/01/2401.09034.json",
    "total_tokens": 875,
    "translated_title": "UOEP: 用户导向的探索策略以增强推荐系统中的长期用户体验",
    "translated_abstract": "强化学习（RL）已经在推荐系统中得到广泛应用，有效地探索用户的兴趣，以提升用户的长期体验。然而，现代推荐系统中存在着数千万个项目之间的不同用户行为模式，这增加了探索的难度。例如，不同活跃水平的用户行为需要不同强度的探索，而之前的研究往往忽视了这一方面，对所有用户应用统一的探索策略，最终损害了用户的长期体验。为了解决这些挑战，我们提出了用户导向的探索策略（UOEP），一种在用户群体中实现细粒度探索的新方法。我们首先构建了一个分布式评论家，它允许在不同的累积奖励反馈的分位数水平下进行策略优化，表示具有不同活动水平的用户群体。在这个评论家的指导下，我们设计了一组不同的演员。",
    "tldr": "UOEP是一种用户导向的探索策略，针对推荐系统中不同活跃水平的用户群体实现细粒度探索，以增强用户的长期体验。",
    "en_tdlr": "UOEP is a user-oriented exploration policy that enables fine-grained exploration among user groups with varying activity levels in recommender systems, aiming to enhance users' long-term experiences."
}