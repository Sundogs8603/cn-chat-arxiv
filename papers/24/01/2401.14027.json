{
    "title": "The Risk of Federated Learning to Skew Fine-Tuning Features and Underperform Out-of-Distribution Robustness. (arXiv:2401.14027v1 [cs.LG])",
    "abstract": "To tackle the scarcity and privacy issues associated with domain-specific datasets, the integration of federated learning in conjunction with fine-tuning has emerged as a practical solution. However, our findings reveal that federated learning has the risk of skewing fine-tuning features and compromising the out-of-distribution robustness of the model. By introducing three robustness indicators and conducting experiments across diverse robust datasets, we elucidate these phenomena by scrutinizing the diversity, transferability, and deviation within the model feature space. To mitigate the negative impact of federated learning on model robustness, we introduce GNP, a \\underline{G}eneral \\underline{N}oisy \\underline{P}rojection-based robust algorithm, ensuring no deterioration of accuracy on the target distribution. Specifically, the key strategy for enhancing model robustness entails the transfer of robustness from the pre-trained model to the fine-tuned model, coupled with adding a sma",
    "link": "http://arxiv.org/abs/2401.14027",
    "context": "Title: The Risk of Federated Learning to Skew Fine-Tuning Features and Underperform Out-of-Distribution Robustness. (arXiv:2401.14027v1 [cs.LG])\nAbstract: To tackle the scarcity and privacy issues associated with domain-specific datasets, the integration of federated learning in conjunction with fine-tuning has emerged as a practical solution. However, our findings reveal that federated learning has the risk of skewing fine-tuning features and compromising the out-of-distribution robustness of the model. By introducing three robustness indicators and conducting experiments across diverse robust datasets, we elucidate these phenomena by scrutinizing the diversity, transferability, and deviation within the model feature space. To mitigate the negative impact of federated learning on model robustness, we introduce GNP, a \\underline{G}eneral \\underline{N}oisy \\underline{P}rojection-based robust algorithm, ensuring no deterioration of accuracy on the target distribution. Specifically, the key strategy for enhancing model robustness entails the transfer of robustness from the pre-trained model to the fine-tuned model, coupled with adding a sma",
    "path": "papers/24/01/2401.14027.json",
    "total_tokens": 904,
    "translated_title": "面向领域特定数据稀缺性和隐私问题的联邦学习的风险：扭曲微调特征并降低抗分布鲁棒性的影响",
    "translated_abstract": "为了解决与领域特定数据集相关的稀缺性和隐私问题，联邦学习与微调的整合已经成为一种实际解决方案。然而，我们发现联邦学习存在扭曲微调特征和损害模型的抗分布鲁棒性的风险。通过引入三个鲁棒性指标并在不同的鲁棒数据集上进行实验证明，我们通过分析模型特征空间中的多样性、可转移性和偏离程度来阐明这些现象。为了减轻联邦学习对模型鲁棒性的负面影响，我们引入了GNP，一种基于\\textbf{G}eneral \\textbf{N}oisy \\textbf{P}rojection的鲁棒算法，确保在目标分布上准确性不会下降。具体来说，增强模型鲁棒性的关键策略是将鲁棒性从预训练模型转移到微调模型中，并结合添加一个小的...",
    "tldr": "联邦学习存在扭曲微调特征和损害模型抗分布鲁棒性的风险，为此我们引入了GNP算法来保证模型在目标分布上的准确性不会下降。"
}