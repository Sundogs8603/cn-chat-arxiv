{
    "title": "A comprehensive study on fidelity metrics for XAI. (arXiv:2401.10640v1 [cs.CV])",
    "abstract": "The use of eXplainable Artificial Intelligence (XAI) systems has introduced a set of challenges that need resolution. Herein, we focus on how to correctly select an XAI method, an open questions within the field. The inherent difficulty of this task is due to the lack of a ground truth. Several authors have proposed metrics to approximate the fidelity of different XAI methods. These metrics lack verification and have concerning disagreements. In this study, we proposed a novel methodology to verify fidelity metrics, using a well-known transparent model, namely a decision tree. This model allowed us to obtain explanations with perfect fidelity. Our proposal constitutes the first objective benchmark for these metrics, facilitating a comparison of existing proposals, and surpassing existing methods. We applied our benchmark to assess the existing fidelity metrics in two different experiments, each using public datasets comprising 52,000 images. The images from these datasets had a size a ",
    "link": "http://arxiv.org/abs/2401.10640",
    "context": "Title: A comprehensive study on fidelity metrics for XAI. (arXiv:2401.10640v1 [cs.CV])\nAbstract: The use of eXplainable Artificial Intelligence (XAI) systems has introduced a set of challenges that need resolution. Herein, we focus on how to correctly select an XAI method, an open questions within the field. The inherent difficulty of this task is due to the lack of a ground truth. Several authors have proposed metrics to approximate the fidelity of different XAI methods. These metrics lack verification and have concerning disagreements. In this study, we proposed a novel methodology to verify fidelity metrics, using a well-known transparent model, namely a decision tree. This model allowed us to obtain explanations with perfect fidelity. Our proposal constitutes the first objective benchmark for these metrics, facilitating a comparison of existing proposals, and surpassing existing methods. We applied our benchmark to assess the existing fidelity metrics in two different experiments, each using public datasets comprising 52,000 images. The images from these datasets had a size a ",
    "path": "papers/24/01/2401.10640.json",
    "total_tokens": 869,
    "translated_title": "XAI的忠诚度度量的综合研究",
    "translated_abstract": "可解释的人工智能(XAI)系统的使用引入了一系列需要解决的挑战。在此，我们重点研究如何正确选择XAI方法，这是该领域的一个开放问题。这个任务的困难在于缺乏标准答案。一些作者提出了度量不同XAI方法忠诚度的方法。这些度量缺乏验证，并存在有关的分歧。在本研究中，我们提出了一种新的方法来验证忠诚度度量，使用一个众所周知的透明模型，即决策树。这个模型使我们能够获得完美忠诚度的解释。我们的提议构成了这些度量的第一个客观基准，便于比较现有的提案，并超越现有的方法。我们将我们的基准应用于评估两个不同实验中现有的忠诚度度量，每个实验使用包含52,000张图片的公共数据集。这些数据集的图片大小为。",
    "tldr": "这项研究提出了一种验证可解释人工智能方法忠诚度的方法，并通过应用于两个不同实验中的现有度量进行了评估，成为这些度量的客观基准，超越了现有方法。"
}