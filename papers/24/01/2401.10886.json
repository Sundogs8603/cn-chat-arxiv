{
    "title": "SCENES: Subpixel Correspondence Estimation With Epipolar Supervision. (arXiv:2401.10886v1 [cs.CV])",
    "abstract": "Extracting point correspondences from two or more views of a scene is a fundamental computer vision problem with particular importance for relative camera pose estimation and structure-from-motion. Existing local feature matching approaches, trained with correspondence supervision on large-scale datasets, obtain highly-accurate matches on the test sets. However, they do not generalise well to new datasets with different characteristics to those they were trained on, unlike classic feature extractors. Instead, they require finetuning, which assumes that ground-truth correspondences or ground-truth camera poses and 3D structure are available. We relax this assumption by removing the requirement of 3D structure, e.g., depth maps or point clouds, and only require camera pose information, which can be obtained from odometry. We do so by replacing correspondence losses with epipolar losses, which encourage putative matches to lie on the associated epipolar line. While weaker than corresponde",
    "link": "http://arxiv.org/abs/2401.10886",
    "context": "Title: SCENES: Subpixel Correspondence Estimation With Epipolar Supervision. (arXiv:2401.10886v1 [cs.CV])\nAbstract: Extracting point correspondences from two or more views of a scene is a fundamental computer vision problem with particular importance for relative camera pose estimation and structure-from-motion. Existing local feature matching approaches, trained with correspondence supervision on large-scale datasets, obtain highly-accurate matches on the test sets. However, they do not generalise well to new datasets with different characteristics to those they were trained on, unlike classic feature extractors. Instead, they require finetuning, which assumes that ground-truth correspondences or ground-truth camera poses and 3D structure are available. We relax this assumption by removing the requirement of 3D structure, e.g., depth maps or point clouds, and only require camera pose information, which can be obtained from odometry. We do so by replacing correspondence losses with epipolar losses, which encourage putative matches to lie on the associated epipolar line. While weaker than corresponde",
    "path": "papers/24/01/2401.10886.json",
    "total_tokens": 885,
    "translated_title": "SCENES: 使用极线监督的亚像素对应关系估计",
    "translated_abstract": "从场景的两个或更多视角中提取点对应关系是一个基础的计算机视觉问题，特别重要的是相对相机姿态估计和结构运动。现有的基于局部特征匹配的方法，通过在大规模数据集上进行对应关系监督训练，能够在测试集上获得高度准确的匹配。然而，它们在不同特征的新数据集上往往无法很好地泛化，这与经典的特征提取器不同。相反，它们需要微调，假设可以获得地面实况对应关系或地面实况相机姿态和3D结构。我们通过取消对3D结构（如深度图或点云）的要求，只需要相机姿态信息（可以从里程计获得）来放松这个假设。我们通过将对应关系损失替换为极线损失来实现，极线损失鼓励假设匹配点位于相关的极线上。虽然它相对来说比对应关系较弱，但一定程度上可以在无需3D结构的情况下估计出相机的相对姿态。",
    "tldr": "SCENES提出了一种使用极线监督的亚像素对应关系估计方法，通过仅使用相机姿态信息而不需要3D结构，以放宽对数据集的特征要求。"
}