{
    "title": "MARIO: MAth Reasoning with code Interpreter Output -- A Reproducible Pipeline",
    "abstract": "arXiv:2401.08190v2 Announce Type: replace  Abstract: Large language models (LLMs) have seen considerable advancements in natural language understanding tasks, yet there remains a gap to bridge before attaining true artificial general intelligence, especially concerning shortcomings in mathematical reasoning capabilities. We postulate that the inherent nature of LLM training, which focuses on predicting probabilities of next token, presents challenges in effectively modeling mathematical reasoning that demands exact calculations, both from data-driven and theoretical standpoints. In this paper, we address this challenge by enriching the data landscape and introducing a novel math dataset, enhanced with a capability to utilize a Python code interpreter. This dataset is derived from GSM8K and MATH and has been further refined through a combination of GPT-4 annotations, human review, and self-training processes, where the errors in the original GSM8K training set have been fixed. Additiona",
    "link": "https://arxiv.org/abs/2401.08190",
    "context": "Title: MARIO: MAth Reasoning with code Interpreter Output -- A Reproducible Pipeline\nAbstract: arXiv:2401.08190v2 Announce Type: replace  Abstract: Large language models (LLMs) have seen considerable advancements in natural language understanding tasks, yet there remains a gap to bridge before attaining true artificial general intelligence, especially concerning shortcomings in mathematical reasoning capabilities. We postulate that the inherent nature of LLM training, which focuses on predicting probabilities of next token, presents challenges in effectively modeling mathematical reasoning that demands exact calculations, both from data-driven and theoretical standpoints. In this paper, we address this challenge by enriching the data landscape and introducing a novel math dataset, enhanced with a capability to utilize a Python code interpreter. This dataset is derived from GSM8K and MATH and has been further refined through a combination of GPT-4 annotations, human review, and self-training processes, where the errors in the original GSM8K training set have been fixed. Additiona",
    "path": "papers/24/01/2401.08190.json",
    "total_tokens": 661,
    "translated_title": "MARIO: 具有Python代码解释器的数学推理输出--可重复的流水线",
    "translated_abstract": "大型语言模型（LLMs）在自然语言理解任务中取得了相当大的进展，但在获得真正的人工通用智能方面仍然存在一些需要填补的差距，特别是在数学推理能力方面存在的缺陷。本文通过丰富数据景观和引入一种新颖的数学数据集来解决这一挑战，该数据集增加了使用Python代码解释器的能力。",
    "tldr": "本文通过引入具有Python代码解释器的数学数据集，解决了大型语言模型在数学推理能力方面的挑战。",
    "en_tdlr": "This paper addresses the challenge of mathematical reasoning capabilities in large language models by introducing a math dataset with a Python code interpreter."
}