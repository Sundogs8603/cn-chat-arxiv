{
    "title": "A Closer Look at AUROC and AUPRC under Class Imbalance. (arXiv:2401.06091v1 [cs.LG])",
    "abstract": "In machine learning (ML), a widespread adage is that the area under the precision-recall curve (AUPRC) is a superior metric for model comparison to the area under the receiver operating characteristic (AUROC) for binary classification tasks with class imbalance. This paper challenges this notion through novel mathematical analysis, illustrating that AUROC and AUPRC can be concisely related in probabilistic terms. We demonstrate that AUPRC, contrary to popular belief, is not superior in cases of class imbalance and might even be a harmful metric, given its inclination to unduly favor model improvements in subpopulations with more frequent positive labels. This bias can inadvertently heighten algorithmic disparities. Prompted by these insights, a thorough review of existing ML literature was conducted, utilizing large language models to analyze over 1.5 million papers from arXiv. Our investigation focused on the prevalence and substantiation of the purported AUPRC superiority. The result",
    "link": "http://arxiv.org/abs/2401.06091",
    "context": "Title: A Closer Look at AUROC and AUPRC under Class Imbalance. (arXiv:2401.06091v1 [cs.LG])\nAbstract: In machine learning (ML), a widespread adage is that the area under the precision-recall curve (AUPRC) is a superior metric for model comparison to the area under the receiver operating characteristic (AUROC) for binary classification tasks with class imbalance. This paper challenges this notion through novel mathematical analysis, illustrating that AUROC and AUPRC can be concisely related in probabilistic terms. We demonstrate that AUPRC, contrary to popular belief, is not superior in cases of class imbalance and might even be a harmful metric, given its inclination to unduly favor model improvements in subpopulations with more frequent positive labels. This bias can inadvertently heighten algorithmic disparities. Prompted by these insights, a thorough review of existing ML literature was conducted, utilizing large language models to analyze over 1.5 million papers from arXiv. Our investigation focused on the prevalence and substantiation of the purported AUPRC superiority. The result",
    "path": "papers/24/01/2401.06091.json",
    "total_tokens": 988,
    "translated_title": "AUROC和AUPRC在类不平衡下的深入研究",
    "translated_abstract": "在机器学习中，一个广泛的观点是，在二分类任务中，面积受限制的准确率曲线（AUPRC）比受试者工作特征曲线下的面积（AUROC）更好地用于模型比较，尤其是在存在类别不平衡的情况下。本文通过新颖的数学分析挑战了这一观点，并说明了AUROC和AUPRC可以以概率术语简洁地相关联。我们证明了AUPRC并不如人们普遍认为的在类别不平衡的情况下更优，甚至可能是一种有害的指标，因为它倾向于过分偏向于在正样本较为频繁的子群中改善模型。这种偏差可能会无意中增加算法的差异。在这些洞见的推动下，我们对现有的机器学习文献进行了彻底的回顾，并利用大型语言模型对arXiv上的150多万篇论文进行了分析。我们的调查重点是验证和证明声称的AUPRC优越性的普遍性。",
    "tldr": "通过数学分析，研究发现AUROC和AUPRC在类别不平衡情况下可以以概率术语简洁地相关联。相比于人们普遍认为的AUPRC优越性，结果表明AUPRC并不如人们预期的有优势，并且可能是一种有害的指标。研究还通过分析大量文献验证了这一结论。",
    "en_tdlr": "Through mathematical analysis, this study reveals a concise probabilistic relationship between AUROC and AUPRC under class imbalance. Contrary to popular belief, AUPRC is not superior and may even be a harmful metric. The conclusion is supported by an analysis of a large collection of literature."
}