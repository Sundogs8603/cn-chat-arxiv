{
    "title": "The Impact of Differential Feature Under-reporting on Algorithmic Fairness. (arXiv:2401.08788v1 [cs.LG])",
    "abstract": "Predictive risk models in the public sector are commonly developed using administrative data that is more complete for subpopulations that more greatly rely on public services. In the United States, for instance, information on health care utilization is routinely available to government agencies for individuals supported by Medicaid and Medicare, but not for the privately insured. Critiques of public sector algorithms have identified such differential feature under-reporting as a driver of disparities in algorithmic decision-making. Yet this form of data bias remains understudied from a technical viewpoint. While prior work has examined the fairness impacts of additive feature noise and features that are clearly marked as missing, the setting of data missingness absent indicators (i.e. differential feature under-reporting) has been lacking in research attention. In this work, we present an analytically tractable model of differential feature under-reporting which we then use to charac",
    "link": "http://arxiv.org/abs/2401.08788",
    "context": "Title: The Impact of Differential Feature Under-reporting on Algorithmic Fairness. (arXiv:2401.08788v1 [cs.LG])\nAbstract: Predictive risk models in the public sector are commonly developed using administrative data that is more complete for subpopulations that more greatly rely on public services. In the United States, for instance, information on health care utilization is routinely available to government agencies for individuals supported by Medicaid and Medicare, but not for the privately insured. Critiques of public sector algorithms have identified such differential feature under-reporting as a driver of disparities in algorithmic decision-making. Yet this form of data bias remains understudied from a technical viewpoint. While prior work has examined the fairness impacts of additive feature noise and features that are clearly marked as missing, the setting of data missingness absent indicators (i.e. differential feature under-reporting) has been lacking in research attention. In this work, we present an analytically tractable model of differential feature under-reporting which we then use to charac",
    "path": "papers/24/01/2401.08788.json",
    "total_tokens": 862,
    "translated_title": "差异特征未报告对算法公平性的影响",
    "translated_abstract": "公共部门的预测风险模型通常使用更完整的行政数据来开发，这些数据对于更大程度依赖公共服务的亚群体更为完整。例如，在美国，对于由医疗补助和医疗保险支持的个人，政府机构常常可以获得有关医疗保健利用的信息，但对于私人保险的人则没有。对公共部门算法的批评指出，差异特征未报告导致算法决策中的不公平。然而，这种数据偏见在技术视角下仍然研究不足。虽然以前的研究已经考察了添加特征噪声和明确标记为缺失的特征对公平性的影响，但缺失指标的数据缺失情况（即差异特征未报告）尚未得到研究的关注。在本研究中，我们提出了一个可分析的差异特征未报告模型，并将其应用于特征未报告对算法公平性的刻画。",
    "tldr": "本文研究了差异特征未报告对算法公平性的影响，并提出了一个可分析的模型进行刻画。",
    "en_tdlr": "This paper examines the impact of differential feature under-reporting on algorithmic fairness and presents an analytically tractable model to characterize it."
}