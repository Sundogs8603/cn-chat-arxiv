{
    "title": "Explaining Image Classifiers. (arXiv:2401.13752v1 [cs.AI])",
    "abstract": "We focus on explaining image classifiers, taking the work of Mothilal et al. [2021] (MMTS) as our point of departure. We observe that, although MMTS claim to be using the definition of explanation proposed by Halpern [2016], they do not quite do so. Roughly speaking, Halpern's definition has a necessity clause and a sufficiency clause. MMTS replace the necessity clause by a requirement that, as we show, implies it. Halpern's definition also allows agents to restrict the set of options considered. While these difference may seem minor, as we show, they can have a nontrivial impact on explanations. We also show that, essentially without change, Halpern's definition can handle two issues that have proved difficult for other approaches: explanations of absence (when, for example, an image classifier for tumors outputs \"no tumor\") and explanations of rare events (such as tumors).",
    "link": "http://arxiv.org/abs/2401.13752",
    "context": "Title: Explaining Image Classifiers. (arXiv:2401.13752v1 [cs.AI])\nAbstract: We focus on explaining image classifiers, taking the work of Mothilal et al. [2021] (MMTS) as our point of departure. We observe that, although MMTS claim to be using the definition of explanation proposed by Halpern [2016], they do not quite do so. Roughly speaking, Halpern's definition has a necessity clause and a sufficiency clause. MMTS replace the necessity clause by a requirement that, as we show, implies it. Halpern's definition also allows agents to restrict the set of options considered. While these difference may seem minor, as we show, they can have a nontrivial impact on explanations. We also show that, essentially without change, Halpern's definition can handle two issues that have proved difficult for other approaches: explanations of absence (when, for example, an image classifier for tumors outputs \"no tumor\") and explanations of rare events (such as tumors).",
    "path": "papers/24/01/2401.13752.json",
    "total_tokens": 946,
    "translated_title": "解释图像分类器（arXiv：2401.13752v1 [cs.AI]）",
    "translated_abstract": "我们的研究重点是解释图像分类器，以莫蒂拉尔等人[2021]（MMTS）的工作作为出发点。我们观察到，尽管MMTS声称使用Halpern [2016]提出的解释定义，但并非完全如此。粗略地说，Halpern的定义包含必要性和充分性两个条件。MMTS将必要性条款替换为我们展示的一个要求，并且暗含了必要性。Halpern的定义还允许代理人限制考虑的选项集。虽然这些差异可能看似微小，但如我们所示，它们对解释产生了重要影响。我们还展示了，几乎没有改变，Halpern的定义可以处理其他方法难以解决的两个问题：解释缺失（例如，图像分类器输出“无肿瘤”）和解释罕见事件（比如肿瘤）。",
    "tldr": "本论文研究了解释图像分类器的问题，并以Mothilal等人[2021]的工作为起点。论文指出Mothilal等人虽然声称使用Halpern [2016]提出的解释定义，但实际上有一定的偏差。论文还展示了Halpern的解释定义可以处理其他方法难以解决的缺失和罕见事件问题。",
    "en_tdlr": "This paper investigates the issue of explaining image classifiers, with a focus on the work of Mothilal et al. [2021] as a starting point. The paper points out that although Mothilal et al. claim to use Halpern's definition of explanation, there are some deviations. The paper also demonstrates that Halpern's definition can address the challenges of explaining absence and rare events that other methods struggle with."
}