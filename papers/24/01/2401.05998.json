{
    "title": "Combating Adversarial Attacks with Multi-Agent Debate. (arXiv:2401.05998v1 [cs.CL])",
    "abstract": "While state-of-the-art language models have achieved impressive results, they remain susceptible to inference-time adversarial attacks, such as adversarial prompts generated by red teams arXiv:2209.07858. One approach proposed to improve the general quality of language model generations is multi-agent debate, where language models self-evaluate through discussion and feedback arXiv:2305.14325. We implement multi-agent debate between current state-of-the-art language models and evaluate models' susceptibility to red team attacks in both single- and multi-agent settings. We find that multi-agent debate can reduce model toxicity when jailbroken or less capable models are forced to debate with non-jailbroken or more capable models. We also find marginal improvements through the general usage of multi-agent interactions. We further perform adversarial prompt content classification via embedding clustering, and analyze the susceptibility of different models to different types of attack topic",
    "link": "http://arxiv.org/abs/2401.05998",
    "context": "Title: Combating Adversarial Attacks with Multi-Agent Debate. (arXiv:2401.05998v1 [cs.CL])\nAbstract: While state-of-the-art language models have achieved impressive results, they remain susceptible to inference-time adversarial attacks, such as adversarial prompts generated by red teams arXiv:2209.07858. One approach proposed to improve the general quality of language model generations is multi-agent debate, where language models self-evaluate through discussion and feedback arXiv:2305.14325. We implement multi-agent debate between current state-of-the-art language models and evaluate models' susceptibility to red team attacks in both single- and multi-agent settings. We find that multi-agent debate can reduce model toxicity when jailbroken or less capable models are forced to debate with non-jailbroken or more capable models. We also find marginal improvements through the general usage of multi-agent interactions. We further perform adversarial prompt content classification via embedding clustering, and analyze the susceptibility of different models to different types of attack topic",
    "path": "papers/24/01/2401.05998.json",
    "total_tokens": 858,
    "translated_title": "使用多智能体辩论来对抗对抗性攻击",
    "translated_abstract": "虽然最先进的语言模型取得了令人印象深刻的成果，但它们仍然容易受到推理阶段的对抗性攻击，例如由红队生成的对抗性提示。为了提高语言模型生成的整体质量，提出了一种方法：多智能体辩论，其中语言模型通过讨论和反馈来自我评估。我们实施了最新的语言模型之间的多智能体辩论，并评估了模型在单一和多智能体环境中受到红队攻击的易受攻击性。我们发现，当越狱或能力较低的模型被迫与未越狱或能力更强的模型进行辩论时，多智能体辩论可以减少模型的有毒性。我们还通过嵌入聚类对对抗性提示内容进行分类，并分析了不同类型攻击主题对不同模型的易受攻击性。",
    "tldr": "使用多智能体辩论对抗对抗性攻击可以降低模型的有毒性，同时通过嵌入聚类对对抗性提示内容进行分类可以分析不同模型对不同类型攻击的易受攻击性。",
    "en_tdlr": "Combating adversarial attacks using multi-agent debate can reduce model toxicity, and analyzing the susceptibility of different models to different types of attacks through embedding clustering of adversarial prompt content."
}