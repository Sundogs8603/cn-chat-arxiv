{
    "title": "Digital Divides in Scene Recognition: Uncovering Socioeconomic Biases in Deep Learning Systems. (arXiv:2401.13097v1 [cs.CV])",
    "abstract": "Computer-based scene understanding has influenced fields ranging from urban planning to autonomous vehicle performance, yet little is known about how well these technologies work across social differences. We investigate the biases of deep convolutional neural networks (dCNNs) in scene classification, using nearly one million images from global and US sources, including user-submitted home photographs and Airbnb listings. We applied statistical models to quantify the impact of socioeconomic indicators such as family income, Human Development Index (HDI), and demographic factors from public data sources (CIA and US Census) on dCNN performance. Our analyses revealed significant socioeconomic bias, where pretrained dCNNs demonstrated lower classification accuracy, lower classification confidence, and a higher tendency to assign labels that could be offensive when applied to homes (e.g., \"ruin\", \"slum\"), especially in images from homes with lower socioeconomic status (SES). This trend is c",
    "link": "http://arxiv.org/abs/2401.13097",
    "context": "Title: Digital Divides in Scene Recognition: Uncovering Socioeconomic Biases in Deep Learning Systems. (arXiv:2401.13097v1 [cs.CV])\nAbstract: Computer-based scene understanding has influenced fields ranging from urban planning to autonomous vehicle performance, yet little is known about how well these technologies work across social differences. We investigate the biases of deep convolutional neural networks (dCNNs) in scene classification, using nearly one million images from global and US sources, including user-submitted home photographs and Airbnb listings. We applied statistical models to quantify the impact of socioeconomic indicators such as family income, Human Development Index (HDI), and demographic factors from public data sources (CIA and US Census) on dCNN performance. Our analyses revealed significant socioeconomic bias, where pretrained dCNNs demonstrated lower classification accuracy, lower classification confidence, and a higher tendency to assign labels that could be offensive when applied to homes (e.g., \"ruin\", \"slum\"), especially in images from homes with lower socioeconomic status (SES). This trend is c",
    "path": "papers/24/01/2401.13097.json",
    "total_tokens": 967,
    "translated_title": "场景识别中的数字鸿沟：揭示深度学习系统中的社会经济偏见",
    "translated_abstract": "基于计算机的场景理解影响了从城市规划到自动驾驶的领域，然而我们对这些技术在社会差异中的表现了解甚少。我们研究了深度卷积神经网络（dCNNs）在场景分类中的偏见，使用了来自全球和美国的近百万张图片，包括用户提交的家庭照片和Airbnb的房源照片。我们运用了统计模型，对家庭收入、人类发展指数（HDI）等社会经济指标以及公开数据来源（CIA和美国人口普查）的人口统计因素对dCNNs的表现影响进行了量化。我们的分析发现了显著的社会经济偏见，预训练的dCNNs表现出更低的分类准确度、更低的分类置信度，以及更高的倾向性在低社会经济地位的家庭（例如“废墟”，“贫民窟”）的图片中分配具有冒犯性的标签。这种趋势是持续的。",
    "tldr": "该研究研究了深度学习系统中的社会经济偏见对场景识别的影响，发现了预训练的卷积神经网络在低社会经济地位的家庭照片中显示出更低的分类准确度和分类置信度，并更容易分配具有冒犯性的标签。",
    "en_tdlr": "This study investigates the impact of socioeconomic biases in deep learning systems on scene recognition and reveals that pretrained convolutional neural networks demonstrate lower classification accuracy and confidence, as well as a higher tendency to assign offensive labels, especially in images from homes with lower socioeconomic status."
}