{
    "title": "MF-AED-AEC: Speech Emotion Recognition by Leveraging Multimodal Fusion, ASR Error Detection, and ASR Error Correction. (arXiv:2401.13260v1 [cs.CL])",
    "abstract": "The prevalent approach in speech emotion recognition (SER) involves integrating both audio and textual information to comprehensively identify the speaker's emotion, with the text generally obtained through automatic speech recognition (ASR). An essential issue of this approach is that ASR errors from the text modality can worsen the performance of SER. Previous studies have proposed using an auxiliary ASR error detection task to adaptively assign weights of each word in ASR hypotheses. However, this approach has limited improvement potential because it does not address the coherence of semantic information in the text. Additionally, the inherent heterogeneity of different modalities leads to distribution gaps between their representations, making their fusion challenging. Therefore, in this paper, we incorporate two auxiliary tasks, ASR error detection (AED) and ASR error correction (AEC), to enhance the semantic coherence of ASR text, and further introduce a novel multi-modal fusion ",
    "link": "http://arxiv.org/abs/2401.13260",
    "context": "Title: MF-AED-AEC: Speech Emotion Recognition by Leveraging Multimodal Fusion, ASR Error Detection, and ASR Error Correction. (arXiv:2401.13260v1 [cs.CL])\nAbstract: The prevalent approach in speech emotion recognition (SER) involves integrating both audio and textual information to comprehensively identify the speaker's emotion, with the text generally obtained through automatic speech recognition (ASR). An essential issue of this approach is that ASR errors from the text modality can worsen the performance of SER. Previous studies have proposed using an auxiliary ASR error detection task to adaptively assign weights of each word in ASR hypotheses. However, this approach has limited improvement potential because it does not address the coherence of semantic information in the text. Additionally, the inherent heterogeneity of different modalities leads to distribution gaps between their representations, making their fusion challenging. Therefore, in this paper, we incorporate two auxiliary tasks, ASR error detection (AED) and ASR error correction (AEC), to enhance the semantic coherence of ASR text, and further introduce a novel multi-modal fusion ",
    "path": "papers/24/01/2401.13260.json",
    "total_tokens": 908,
    "translated_title": "MF-AED-AEC: 通过融合多模态、ASR错误检测和ASR错误修正实现语音情感识别",
    "translated_abstract": "语音情感识别（SER）中普遍采用的方法是通过整合音频和文本信息来全面识别说话者的情感，其中文本通常通过自动语音识别（ASR）获取。这种方法的一个重要问题是，文本模态中的ASR错误会使SER的性能变差。之前的研究提出使用辅助的ASR错误检测任务来自适应地分配ASR假设中每个词的权重。然而，这种方法的改进潜力有限，因为它没有解决文本中语义信息的一致性。此外，不同模态之间的固有异质性导致它们表示之间的分布差异，使它们的融合具有挑战性。因此，在本文中，我们引入了两个辅助任务，ASR错误检测（AED）和ASR错误修正（AEC），以增强ASR文本的语义一致性，并进一步引入了一种新颖的多模态融合方法。",
    "tldr": "本文提出了一种名为MF-AED-AEC的方法，通过融合多模态、ASR错误检测和ASR错误修正，通过增强ASR文本的语义一致性来改进语音情感识别的性能。",
    "en_tdlr": "This paper proposes a method called MF-AED-AEC that improves the performance of speech emotion recognition by leveraging multimodal fusion, ASR error detection, and ASR error correction to enhance the semantic coherence of ASR text."
}