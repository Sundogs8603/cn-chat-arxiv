{
    "title": "CoMoSVC: Consistency Model-based Singing Voice Conversion. (arXiv:2401.01792v1 [eess.AS])",
    "abstract": "The diffusion-based Singing Voice Conversion (SVC) methods have achieved remarkable performances, producing natural audios with high similarity to the target timbre. However, the iterative sampling process results in slow inference speed, and acceleration thus becomes crucial. In this paper, we propose CoMoSVC, a consistency model-based SVC method, which aims to achieve both high-quality generation and high-speed sampling. A diffusion-based teacher model is first specially designed for SVC, and a student model is further distilled under self-consistency properties to achieve one-step sampling. Experiments on a single NVIDIA GTX4090 GPU reveal that although CoMoSVC has a significantly faster inference speed than the state-of-the-art (SOTA) diffusion-based SVC system, it still achieves comparable or superior conversion performance based on both subjective and objective metrics. Audio samples and codes are available at https://comosvc.github.io/.",
    "link": "http://arxiv.org/abs/2401.01792",
    "context": "Title: CoMoSVC: Consistency Model-based Singing Voice Conversion. (arXiv:2401.01792v1 [eess.AS])\nAbstract: The diffusion-based Singing Voice Conversion (SVC) methods have achieved remarkable performances, producing natural audios with high similarity to the target timbre. However, the iterative sampling process results in slow inference speed, and acceleration thus becomes crucial. In this paper, we propose CoMoSVC, a consistency model-based SVC method, which aims to achieve both high-quality generation and high-speed sampling. A diffusion-based teacher model is first specially designed for SVC, and a student model is further distilled under self-consistency properties to achieve one-step sampling. Experiments on a single NVIDIA GTX4090 GPU reveal that although CoMoSVC has a significantly faster inference speed than the state-of-the-art (SOTA) diffusion-based SVC system, it still achieves comparable or superior conversion performance based on both subjective and objective metrics. Audio samples and codes are available at https://comosvc.github.io/.",
    "path": "papers/24/01/2401.01792.json",
    "total_tokens": 944,
    "translated_title": "CoMoSVC: 基于一致性模型的唱歌声音转换",
    "translated_abstract": "基于扩散的唱歌声音转换（SVC）方法已经取得了显著的性能，产生了与目标音色相似度高的自然音频。然而，迭代采样过程导致推理速度慢，因此加速变得至关重要。在本文中，我们提出了基于一致性模型的CoMoSVC方法，旨在实现高质量生成和高速采样。首先，设计了针对SVC的基于扩散的教师模型，然后通过自一致性特性进一步提取学生模型，实现一步采样。在单个NVIDIA GTX4090 GPU上进行的实验证明，虽然CoMoSVC的推理速度比最先进的（SOTA）基于扩散的SVC系统要快得多，但在主观和客观指标上仍实现了可比或更优的转换性能。音频样本和代码可在网址https://comosvc.github.io/获取。",
    "tldr": "本文提出了一种基于一致性模型的唱歌声音转换方法。通过设计扩散教师模型和提取自一致性学生模型，该方法实现了高质量的声音生成和高速的采样，相比于最先进的扩散方法，具有更快的推理速度，并在主观和客观指标上实现了可比或更优的声音转换性能。",
    "en_tdlr": "This paper proposes a consistency model-based method for singing voice conversion. By designing a diffusion-based teacher model and extracting a self-consistency student model, the method achieves high-quality audio generation and fast sampling. It has a significantly faster inference speed compared to the state-of-the-art diffusion-based method and achieves comparable or superior conversion performance based on subjective and objective metrics."
}