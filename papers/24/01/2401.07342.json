{
    "title": "Who Said What? An Automated Approach to Analyzing Speech in Preschool Classrooms",
    "abstract": "arXiv:2401.07342v2 Announce Type: replace-cross  Abstract: Young children spend substantial portions of their waking hours in noisy preschool classrooms. In these environments, children's vocal interactions with teachers are critical contributors to their language outcomes, but manually transcribing these interactions is prohibitive. Using audio from child- and teacher-worn recorders, we propose an automated framework that uses open source software both to classify speakers (ALICE) and to transcribe their utterances (Whisper). We compare results from our framework to those from a human expert for 110 minutes of classroom recordings, including 85 minutes from child-word microphones (n=4 children) and 25 minutes from teacher-worn microphones (n=2 teachers). The overall proportion of agreement, that is, the proportion of correctly classified teacher and child utterances, was .76, with an error-corrected kappa of .50 and a weighted F1 of .76. The word error rate for both teacher and child ",
    "link": "https://arxiv.org/abs/2401.07342",
    "context": "Title: Who Said What? An Automated Approach to Analyzing Speech in Preschool Classrooms\nAbstract: arXiv:2401.07342v2 Announce Type: replace-cross  Abstract: Young children spend substantial portions of their waking hours in noisy preschool classrooms. In these environments, children's vocal interactions with teachers are critical contributors to their language outcomes, but manually transcribing these interactions is prohibitive. Using audio from child- and teacher-worn recorders, we propose an automated framework that uses open source software both to classify speakers (ALICE) and to transcribe their utterances (Whisper). We compare results from our framework to those from a human expert for 110 minutes of classroom recordings, including 85 minutes from child-word microphones (n=4 children) and 25 minutes from teacher-worn microphones (n=2 teachers). The overall proportion of agreement, that is, the proportion of correctly classified teacher and child utterances, was .76, with an error-corrected kappa of .50 and a weighted F1 of .76. The word error rate for both teacher and child ",
    "path": "papers/24/01/2401.07342.json",
    "total_tokens": 928,
    "translated_title": "谁说了什么？分析学前课堂言语的自动化方法",
    "translated_abstract": "年幼儿童在喧闹的学前课堂中度过大部分清醒时间。在这种环境中，孩子与教师之间的言语互动对他们的语言结果至关重要，但手动转录这些互动是困难的。本文提出了一个使用儿童和教师佩戴的录音设备录音的自动化框架，该框架使用开源软件对说话者进行分类（ALICE），并转录他们的话语（Whisper）。我们将框架的结果与人类专家对110分钟教室录音（包括来自儿童话筒的85分钟（4名儿童）和来自教师话筒的25分钟（2名教师））的结果进行了比较。总体一致比例，即正确分类的教师和儿童话语的比例为0.76，矫正的kappa为0.50，加权F1为0.76。教师和儿童的话语的词误率",
    "tldr": "提出了一个自动化框架，使用儿童和教师佩戴的录音设备记录言语，实现说话者分类和转录，与人类专家对比结果表明，框架整体准确率达到0.76，为学前教室言语分析提供了新思路"
}