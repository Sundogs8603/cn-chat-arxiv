{
    "title": "Fixed Point Diffusion Models. (arXiv:2401.08741v1 [cs.CV])",
    "abstract": "We introduce the Fixed Point Diffusion Model (FPDM), a novel approach to image generation that integrates the concept of fixed point solving into the framework of diffusion-based generative modeling. Our approach embeds an implicit fixed point solving layer into the denoising network of a diffusion model, transforming the diffusion process into a sequence of closely-related fixed point problems. Combined with a new stochastic training method, this approach significantly reduces model size, reduces memory usage, and accelerates training. Moreover, it enables the development of two new techniques to improve sampling efficiency: reallocating computation across timesteps and reusing fixed point solutions between timesteps. We conduct extensive experiments with state-of-the-art models on ImageNet, FFHQ, CelebA-HQ, and LSUN-Church, demonstrating substantial improvements in performance and efficiency. Compared to the state-of-the-art DiT model, FPDM contains 87% fewer parameters, consumes 60%",
    "link": "http://arxiv.org/abs/2401.08741",
    "context": "Title: Fixed Point Diffusion Models. (arXiv:2401.08741v1 [cs.CV])\nAbstract: We introduce the Fixed Point Diffusion Model (FPDM), a novel approach to image generation that integrates the concept of fixed point solving into the framework of diffusion-based generative modeling. Our approach embeds an implicit fixed point solving layer into the denoising network of a diffusion model, transforming the diffusion process into a sequence of closely-related fixed point problems. Combined with a new stochastic training method, this approach significantly reduces model size, reduces memory usage, and accelerates training. Moreover, it enables the development of two new techniques to improve sampling efficiency: reallocating computation across timesteps and reusing fixed point solutions between timesteps. We conduct extensive experiments with state-of-the-art models on ImageNet, FFHQ, CelebA-HQ, and LSUN-Church, demonstrating substantial improvements in performance and efficiency. Compared to the state-of-the-art DiT model, FPDM contains 87% fewer parameters, consumes 60%",
    "path": "papers/24/01/2401.08741.json",
    "total_tokens": 973,
    "translated_title": "固定点扩散模型",
    "translated_abstract": "我们引入了固定点扩散模型（FPDM），这是一种将固定点求解的概念融入基于扩散的生成模型框架的新方法。我们的方法将一个隐式的固定点求解层嵌入到扩散模型的去噪网络中，将扩散过程转化为一系列相关的固定点问题。结合一种新的随机训练方法，这种方法显著减少了模型大小，减小了内存使用量，并加快了训练速度。此外，它还能够开发出两种新的技术来提高采样效率：在时间步之间重新分配计算和重用固定点解。我们对ImageNet、FFHQ、CelebA-HQ和LSUN-Church等最先进的模型进行了大量实验，证明了性能和效率的显著改进。与最先进的DiT模型相比，FPDM参数减少了87%，内存消耗减少了60%。",
    "tldr": "固定点扩散模型（FPDM）是一种将固定点求解引入扩散生成模型框架的新方法，通过嵌入固定点求解层和采用新的训练方法，显著减小了模型大小、内存使用量并加快了训练速度，并且提出了两种新的技术来提高采样效率。实验证明，与现有模型相比，FPDM在性能和效率上有明显改进。",
    "en_tdlr": "Fixed Point Diffusion Model (FPDM) is a novel approach that integrates the concept of fixed point solving into the framework of diffusion-based generative modeling. By embedding an implicit fixed point solving layer and using a new training method, FPDM significantly reduces model size, memory usage, and training time, while introducing new techniques to improve sampling efficiency. Experimental results demonstrate substantial improvements in performance and efficiency compared to existing models."
}