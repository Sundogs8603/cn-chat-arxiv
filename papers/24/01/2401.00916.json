{
    "title": "Data Assimilation in Chaotic Systems Using Deep Reinforcement Learning. (arXiv:2401.00916v1 [math.DS])",
    "abstract": "Data assimilation (DA) plays a pivotal role in diverse applications, ranging from climate predictions and weather forecasts to trajectory planning for autonomous vehicles. A prime example is the widely used ensemble Kalman filter (EnKF), which relies on linear updates to minimize variance among the ensemble of forecast states. Recent advancements have seen the emergence of deep learning approaches in this domain, primarily within a supervised learning framework. However, the adaptability of such models to untrained scenarios remains a challenge. In this study, we introduce a novel DA strategy that utilizes reinforcement learning (RL) to apply state corrections using full or partial observations of the state variables. Our investigation focuses on demonstrating this approach to the chaotic Lorenz '63 system, where the agent's objective is to minimize the root-mean-squared error between the observations and corresponding forecast states. Consequently, the agent develops a correction stra",
    "link": "http://arxiv.org/abs/2401.00916",
    "context": "Title: Data Assimilation in Chaotic Systems Using Deep Reinforcement Learning. (arXiv:2401.00916v1 [math.DS])\nAbstract: Data assimilation (DA) plays a pivotal role in diverse applications, ranging from climate predictions and weather forecasts to trajectory planning for autonomous vehicles. A prime example is the widely used ensemble Kalman filter (EnKF), which relies on linear updates to minimize variance among the ensemble of forecast states. Recent advancements have seen the emergence of deep learning approaches in this domain, primarily within a supervised learning framework. However, the adaptability of such models to untrained scenarios remains a challenge. In this study, we introduce a novel DA strategy that utilizes reinforcement learning (RL) to apply state corrections using full or partial observations of the state variables. Our investigation focuses on demonstrating this approach to the chaotic Lorenz '63 system, where the agent's objective is to minimize the root-mean-squared error between the observations and corresponding forecast states. Consequently, the agent develops a correction stra",
    "path": "papers/24/01/2401.00916.json",
    "total_tokens": 850,
    "translated_title": "使用深度强化学习在混沌系统中进行数据同化",
    "translated_abstract": "数据同化在各种应用中起着关键作用，从气候预测和天气预报到自主车辆的轨迹规划。一个典型的例子是广泛使用的集合卡尔曼滤波器（EnKF），它依赖于线性更新来最小化预测状态集合的方差。最近的进展在这个领域中看到了深度学习方法的出现，主要是在有监督学习框架内。然而，这些模型在未经训练的情况下的适应性仍然是一个挑战。在本研究中，我们引入了一种新的数据同化策略，利用强化学习（RL）来使用完整或部分观测的状态变量进行状态校正。我们的研究重点是在混沌的Lorenz '63系统上展示这种方法，其中代理的目标是将观测和相应的预测状态之间的均方根误差最小化。因此，代理开发出了一种校正策略。",
    "tldr": "本文介绍了一种使用强化学习在混沌系统中进行数据同化的新策略。该方法通过使用完整或部分观测的状态变量进行状态校正，旨在最小化观测和预测状态之间的误差。"
}