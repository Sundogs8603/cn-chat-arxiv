{
    "title": "Sparse and Transferable Universal Singular Vectors Attack. (arXiv:2401.14031v1 [cs.LG])",
    "abstract": "The research in the field of adversarial attacks and models' vulnerability is one of the fundamental directions in modern machine learning. Recent studies reveal the vulnerability phenomenon, and understanding the mechanisms behind this is essential for improving neural network characteristics and interpretability. In this paper, we propose a novel sparse universal white-box adversarial attack. Our approach is based on truncated power iteration providing sparsity to $(p,q)$-singular vectors of the hidden layers of Jacobian matrices. Using the ImageNet benchmark validation subset, we analyze the proposed method in various settings, achieving results comparable to dense baselines with more than a 50% fooling rate while damaging only 5% of pixels and utilizing 256 samples for perturbation fitting. We also show that our algorithm admits higher attack magnitude without affecting the human ability to solve the task. Furthermore, we investigate that the constructed perturbations are highly tr",
    "link": "http://arxiv.org/abs/2401.14031",
    "context": "Title: Sparse and Transferable Universal Singular Vectors Attack. (arXiv:2401.14031v1 [cs.LG])\nAbstract: The research in the field of adversarial attacks and models' vulnerability is one of the fundamental directions in modern machine learning. Recent studies reveal the vulnerability phenomenon, and understanding the mechanisms behind this is essential for improving neural network characteristics and interpretability. In this paper, we propose a novel sparse universal white-box adversarial attack. Our approach is based on truncated power iteration providing sparsity to $(p,q)$-singular vectors of the hidden layers of Jacobian matrices. Using the ImageNet benchmark validation subset, we analyze the proposed method in various settings, achieving results comparable to dense baselines with more than a 50% fooling rate while damaging only 5% of pixels and utilizing 256 samples for perturbation fitting. We also show that our algorithm admits higher attack magnitude without affecting the human ability to solve the task. Furthermore, we investigate that the constructed perturbations are highly tr",
    "path": "papers/24/01/2401.14031.json",
    "total_tokens": 1034,
    "translated_title": "稀疏可传递的通用奇异向量攻击",
    "translated_abstract": "对抗攻击和模型的脆弱性研究是现代机器学习中的基本方向之一。最近的研究揭示了模型的脆弱性现象，了解其背后的机制对于改善神经网络的特性和可解释性至关重要。本文提出了一种新颖的稀疏通用白盒对抗攻击方法。我们的方法基于截断幂迭代，为雅可比矩阵的隐藏层的$(p,q)$-奇异向量提供稀疏性。在ImageNet基准验证子集上，我们在各种设置下分析了所提出的方法，实现了与密集基线相当的结果，愚弄率超过50%，但只破坏了5%的像素，并利用256个样本进行扰动拟合。我们还展示了我们的算法接受更高的攻击幅度，而不影响人类解决任务的能力。此外，我们还研究了构造的扰动是高度可传递的。",
    "tldr": "本文提出了一种稀疏可传递的通用奇异向量攻击方法，通过在隐藏层中利用截断幂迭代来获得稀疏的$(p,q)$-奇异向量。在ImageNet基准验证子集上的实验证明，该方法可以在仅破坏5%的像素和利用256个样本的情况下，达到与密集基线相当的愚弄率超过50%的结果。同时，该攻击方法不影响人类解决任务的能力，并且构造的扰动是高度可传递的。",
    "en_tdlr": "This paper proposes a sparse and transferable universal singular vectors attack that utilizes truncated power iteration to obtain sparse $(p,q)$-singular vectors in the hidden layers. Experimental results on the ImageNet benchmark subset show that the proposed method achieves comparable fooling rates of over 50% with only 5% pixel damage and utilizing 256 samples for perturbation fitting. Moreover, the attack does not affect human ability to solve the task and the constructed perturbations are highly transferable."
}