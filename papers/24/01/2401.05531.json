{
    "title": "VI-PANN: Harnessing Transfer Learning and Uncertainty-Aware Variational Inference for Improved Generalization in Audio Pattern Recognition. (arXiv:2401.05531v1 [cs.LG])",
    "abstract": "Transfer learning (TL) is an increasingly popular approach to training deep learning (DL) models that leverages the knowledge gained by training a foundation model on diverse, large-scale datasets for use on downstream tasks where less domain- or task-specific data is available. The literature is rich with TL techniques and applications; however, the bulk of the research makes use of deterministic DL models which are often uncalibrated and lack the ability to communicate a measure of epistemic (model) uncertainty in prediction. Unlike their deterministic counterparts, Bayesian DL (BDL) models are often well-calibrated, provide access to epistemic uncertainty for a prediction, and are capable of achieving competitive predictive performance. In this study, we propose variational inference pre-trained audio neural networks (VI-PANNs). VI-PANNs are a variational inference variant of the popular ResNet-54 architecture which are pre-trained on AudioSet, a large-scale audio event detection da",
    "link": "http://arxiv.org/abs/2401.05531",
    "context": "Title: VI-PANN: Harnessing Transfer Learning and Uncertainty-Aware Variational Inference for Improved Generalization in Audio Pattern Recognition. (arXiv:2401.05531v1 [cs.LG])\nAbstract: Transfer learning (TL) is an increasingly popular approach to training deep learning (DL) models that leverages the knowledge gained by training a foundation model on diverse, large-scale datasets for use on downstream tasks where less domain- or task-specific data is available. The literature is rich with TL techniques and applications; however, the bulk of the research makes use of deterministic DL models which are often uncalibrated and lack the ability to communicate a measure of epistemic (model) uncertainty in prediction. Unlike their deterministic counterparts, Bayesian DL (BDL) models are often well-calibrated, provide access to epistemic uncertainty for a prediction, and are capable of achieving competitive predictive performance. In this study, we propose variational inference pre-trained audio neural networks (VI-PANNs). VI-PANNs are a variational inference variant of the popular ResNet-54 architecture which are pre-trained on AudioSet, a large-scale audio event detection da",
    "path": "papers/24/01/2401.05531.json",
    "total_tokens": 890,
    "translated_title": "VI-PANN: 利用转移学习和不确定性感知变分推理来提高音频模式识别中的泛化性能",
    "translated_abstract": "转移学习是一种越来越流行的深度学习模型训练方法，利用在多样、大规模数据集上训练基础模型获取的知识，应用于在可用领域或任务特定数据较少的下游任务中。现有文献中有许多转移学习技术和应用，但大部分研究使用的是确定性的深度学习模型，这些模型通常不经校准，也无法提供预测的认知（模型）不确定度。与确定性模型相比，贝叶斯深度学习模型往往能够很好地进行校准，提供预测的认知不确定度，并具有竞争性的预测性能。本研究提出了变分推理预训练音频神经网络（VI-PANNs）。VI-PANNs是基于流行的ResNet-54架构的变分推理变体，其在大规模音频事件检测数据集AudioSet上进行了预训练。",
    "tldr": "本研究提出了VI-PANN，利用转移学习和不确定性感知变分推理方法，在音频模式识别中取得了改进的泛化性能。",
    "en_tdlr": "This paper introduces VI-PANN, which harnesses transfer learning and uncertainty-aware variational inference to improve generalization in audio pattern recognition."
}