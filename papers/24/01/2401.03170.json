{
    "title": "Preserving Silent Features for Domain Generalization. (arXiv:2401.03170v1 [cs.LG])",
    "abstract": "Domain generalization (DG) aims to improve the generalization ability of the model trained on several known training domains over unseen test domains. Previous work has shown that self-supervised contrastive pre-training improves the robustness of the model on downstream tasks. However, in this paper, we find that self-supervised models do not exhibit better generalization performance than supervised models pre-trained on the same dataset in the DG setting. We argue that this is owing to the fact that the richer intra-class discriminative features extracted by self-supervised contrastive learning, which we term silent features, are suppressed during supervised fine-tuning. These silent features are likely to contain features that are more generalizable on the test domain. In this work, we model and analyze this feature suppression phenomenon and theoretically prove that preserving silent features can achieve lower expected test domain risk under certain conditions. In light of this, we",
    "link": "http://arxiv.org/abs/2401.03170",
    "context": "Title: Preserving Silent Features for Domain Generalization. (arXiv:2401.03170v1 [cs.LG])\nAbstract: Domain generalization (DG) aims to improve the generalization ability of the model trained on several known training domains over unseen test domains. Previous work has shown that self-supervised contrastive pre-training improves the robustness of the model on downstream tasks. However, in this paper, we find that self-supervised models do not exhibit better generalization performance than supervised models pre-trained on the same dataset in the DG setting. We argue that this is owing to the fact that the richer intra-class discriminative features extracted by self-supervised contrastive learning, which we term silent features, are suppressed during supervised fine-tuning. These silent features are likely to contain features that are more generalizable on the test domain. In this work, we model and analyze this feature suppression phenomenon and theoretically prove that preserving silent features can achieve lower expected test domain risk under certain conditions. In light of this, we",
    "path": "papers/24/01/2401.03170.json",
    "total_tokens": 915,
    "translated_title": "保留静默特征用于领域泛化的研究",
    "translated_abstract": "领域泛化(DG)旨在提高模型在未知测试领域上的泛化能力，用已知的多个训练领域来训练模型。之前的研究表明，自监督对比预训练可以提高模型在下游任务上的鲁棒性。然而，在本文中，我们发现自监督模型在DG设置中并没有比在同一数据集上进行预训练的有监督模型展现出更好的泛化性能。我们认为这是由于自监督对比学习提取的更丰富的类内区分特征，即我们所称的静默特征，在有监督微调过程中被抑制了。这些静默特征很可能包含了更具泛化性的特征。在本研究中，我们对这种特征抑制现象进行建模和分析，并在一定条件下理论上证明保留静默特征可以实现更低的预期测试领域风险。",
    "tldr": "本研究发现，在领域泛化(DG)设置中，自监督模型不如有监督模型在泛化性能上表现得好。我们提出了静默特征的概念，认为保留这些静默特征可以降低测试领域风险。"
}