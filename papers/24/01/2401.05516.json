{
    "title": "FPRF: Feed-Forward Photorealistic Style Transfer of Large-Scale 3D Neural Radiance Fields. (arXiv:2401.05516v1 [cs.CV])",
    "abstract": "We present FPRF, a feed-forward photorealistic style transfer method for large-scale 3D neural radiance fields. FPRF stylizes large-scale 3D scenes with arbitrary, multiple style reference images without additional optimization while preserving multi-view appearance consistency. Prior arts required tedious per-style/-scene optimization and were limited to small-scale 3D scenes. FPRF efficiently stylizes large-scale 3D scenes by introducing a style-decomposed 3D neural radiance field, which inherits AdaIN's feed-forward stylization machinery, supporting arbitrary style reference images. Furthermore, FPRF supports multi-reference stylization with the semantic correspondence matching and local AdaIN, which adds diverse user control for 3D scene styles. FPRF also preserves multi-view consistency by applying semantic matching and style transfer processes directly onto queried features in 3D space. In experiments, we demonstrate that FPRF achieves favorable photorealistic quality 3D scene st",
    "link": "http://arxiv.org/abs/2401.05516",
    "context": "Title: FPRF: Feed-Forward Photorealistic Style Transfer of Large-Scale 3D Neural Radiance Fields. (arXiv:2401.05516v1 [cs.CV])\nAbstract: We present FPRF, a feed-forward photorealistic style transfer method for large-scale 3D neural radiance fields. FPRF stylizes large-scale 3D scenes with arbitrary, multiple style reference images without additional optimization while preserving multi-view appearance consistency. Prior arts required tedious per-style/-scene optimization and were limited to small-scale 3D scenes. FPRF efficiently stylizes large-scale 3D scenes by introducing a style-decomposed 3D neural radiance field, which inherits AdaIN's feed-forward stylization machinery, supporting arbitrary style reference images. Furthermore, FPRF supports multi-reference stylization with the semantic correspondence matching and local AdaIN, which adds diverse user control for 3D scene styles. FPRF also preserves multi-view consistency by applying semantic matching and style transfer processes directly onto queried features in 3D space. In experiments, we demonstrate that FPRF achieves favorable photorealistic quality 3D scene st",
    "path": "papers/24/01/2401.05516.json",
    "total_tokens": 966,
    "translated_title": "FPRF：大规模三维神经辐射场的前馈逼真风格迁移",
    "translated_abstract": "我们提出了FPRF，一种用于大规模三维神经辐射场的前馈逼真风格迁移方法。FPRF可以在不进行额外优化的情况下对大规模三维场景进行风格化，并保持多视角外观一致性。传统方法需要繁琐的每个风格/场景优化，并且局限于小规模三维场景。FPRF通过引入分解成风格的三维神经辐射场，高效地对大规模三维场景进行风格化，使用 AdaIN 的前馈风格化机制支持任意风格参考图像。此外，FPRF 还通过语义匹配和局部 AdaIN 支持多参考风格化，为三维场景风格提供了多样的用户控制。FPRF 还通过将语义匹配和风格迁移过程直接应用于3D空间中的查询特征来保持多视角一致性。在实验中，我们证明了FPRF具有较好的逼真的质量，能够对三维场景进行风格化。",
    "tldr": "FPRF是一种用于大规模三维神经辐射场的前馈逼真风格迁移方法，它实现了对大规模三维场景的高效风格化，并在保持多视角外观一致性的同时支持多风格参考图像和用户控制。",
    "en_tdlr": "FPRF is a feed-forward photorealistic style transfer method for large-scale 3D neural radiance fields, which efficiently stylizes large-scale 3D scenes and supports multiple style reference images and user control while preserving multi-view appearance consistency."
}