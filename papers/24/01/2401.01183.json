{
    "title": "Unifying Structured Data as Graph for Data-to-Text Pre-Training. (arXiv:2401.01183v1 [cs.CL])",
    "abstract": "Data-to-text (D2T) generation aims to transform structured data into natural language text. Data-to-text pre-training has proved to be powerful in enhancing D2T generation and yields impressive performances. However, previous pre-training methods either oversimplified structured data into a sequence without considering input structures or designed training objectives tailored for a specific data structure (e.g., table or knowledge graph). In this paper, we unify different types of structured data (i.e., table, key-value data, knowledge graph) into the graph format and cast different data-to-text generation tasks as graph-to-text generation. To effectively exploit the structural information of the input graph, we propose a structure-enhanced pre-training method for D2T generation by designing a structure-enhanced Transformer. Concretely, we devise a position matrix for the Transformer, encoding relative positional information of connected nodes in the input graph. In addition, we propos",
    "link": "http://arxiv.org/abs/2401.01183",
    "context": "Title: Unifying Structured Data as Graph for Data-to-Text Pre-Training. (arXiv:2401.01183v1 [cs.CL])\nAbstract: Data-to-text (D2T) generation aims to transform structured data into natural language text. Data-to-text pre-training has proved to be powerful in enhancing D2T generation and yields impressive performances. However, previous pre-training methods either oversimplified structured data into a sequence without considering input structures or designed training objectives tailored for a specific data structure (e.g., table or knowledge graph). In this paper, we unify different types of structured data (i.e., table, key-value data, knowledge graph) into the graph format and cast different data-to-text generation tasks as graph-to-text generation. To effectively exploit the structural information of the input graph, we propose a structure-enhanced pre-training method for D2T generation by designing a structure-enhanced Transformer. Concretely, we devise a position matrix for the Transformer, encoding relative positional information of connected nodes in the input graph. In addition, we propos",
    "path": "papers/24/01/2401.01183.json",
    "total_tokens": 939,
    "translated_title": "将结构化数据统一为图形以进行数据到文本预训练",
    "translated_abstract": "数据到文本（D2T）生成旨在将结构化数据转化为自然语言文本。数据到文本预训练已被证明在增强D2T生成并产生令人印象深刻的性能方面是有效的。然而，先前的预训练方法要么将结构化数据过度简化为一个序列，而不考虑输入的结构，要么设计用于特定数据结构（例如表格或知识图）的训练目标。在本文中，我们将不同类型的结构化数据（即，表格、键值数据、知识图）统一为图形格式，并将不同的数据到文本生成任务转化为图形到文本生成。为了有效利用输入图形的结构信息，我们提出了一种用于D2T生成的结构增强预训练方法，通过设计一种结构增强的Transformer。具体而言，我们为Transformer设计了一个位置矩阵，用于编码输入图形中相连节点的相对位置信息。此外，我们提出了一种基于图形结构的句法标签分类方法，用于有效结合句法信息和structure-enhanced特征。",
    "tldr": "本论文提出了一种将不同类型的结构化数据统一为图形格式，并将数据到文本生成任务转化为图形到文本生成的方法。为了更好地利用输入图形的结构信息，作者设计了一个结构增强的Transformer，并使用位置矩阵编码了相连节点的相对位置信息。"
}