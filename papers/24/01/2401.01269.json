{
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection. (arXiv:2401.01269v1 [cs.CR])",
    "abstract": "Despite the continued research and progress in building secure systems, Android applications continue to be ridden with vulnerabilities, necessitating effective detection methods. Current strategies involving static and dynamic analysis tools come with limitations like overwhelming number of false positives and limited scope of analysis which make either difficult to adopt. Over the past years, machine learning based approaches have been extensively explored for vulnerability detection, but its real-world applicability is constrained by data requirements and feature engineering challenges. Large Language Models (LLMs), with their vast parameters, have shown tremendous potential in understanding semnatics in human as well as programming languages. We dive into the efficacy of LLMs for detecting vulnerabilities in the context of Android security. We focus on building an AI-driven workflow to assist developers in identifying and rectifying vulnerabilities. Our experiments show that LLMs o",
    "link": "http://arxiv.org/abs/2401.01269",
    "context": "Title: LLbezpeky: Leveraging Large Language Models for Vulnerability Detection. (arXiv:2401.01269v1 [cs.CR])\nAbstract: Despite the continued research and progress in building secure systems, Android applications continue to be ridden with vulnerabilities, necessitating effective detection methods. Current strategies involving static and dynamic analysis tools come with limitations like overwhelming number of false positives and limited scope of analysis which make either difficult to adopt. Over the past years, machine learning based approaches have been extensively explored for vulnerability detection, but its real-world applicability is constrained by data requirements and feature engineering challenges. Large Language Models (LLMs), with their vast parameters, have shown tremendous potential in understanding semnatics in human as well as programming languages. We dive into the efficacy of LLMs for detecting vulnerabilities in the context of Android security. We focus on building an AI-driven workflow to assist developers in identifying and rectifying vulnerabilities. Our experiments show that LLMs o",
    "path": "papers/24/01/2401.01269.json",
    "total_tokens": 911,
    "translated_title": "LLbezpeky: 利用大型语言模型进行漏洞检测",
    "translated_abstract": "尽管在构建安全系统方面进行了持续的研究和进展，但安卓应用程序仍然存在漏洞，需要有效的检测方法。目前的静态和动态分析工具策略存在一些限制，如大量的误报和有限的分析范围，使得难以采用。在过去的几年中，基于机器学习的方法在漏洞检测方面得到了广泛探索，但其在实际应用中受到数据需求和特征工程挑战的限制。大型语言模型（LLMs）凭借其庞大的参数，在理解人类和编程语言中的语义方面展现出巨大潜力。我们深入研究了在安卓安全的背景下，LLMs用于检测漏洞的效果。我们的重点是构建一个基于人工智能的工作流程，帮助开发人员识别和修复漏洞。我们的实验结果表明，LLMs能够有效检测出漏洞。",
    "tldr": "LLbezpeky是一项利用大型语言模型进行漏洞检测的研究，研究发现LLMs在理解人类和编程语言中的语义方面展现出巨大潜力，并通过构建一个AI驱动的工作流程来帮助开发人员识别和修复漏洞。",
    "en_tdlr": "LLbezpeky is a study that leverages large language models for vulnerability detection, finding that LLMs show tremendous potential in understanding semantics in human and programming languages and assisting developers in identifying and rectifying vulnerabilities through an AI-driven workflow."
}