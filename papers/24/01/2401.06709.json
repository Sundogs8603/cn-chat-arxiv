{
    "title": "Reliability Analysis of Psychological Concept Extraction and Classification in User-penned Text. (arXiv:2401.06709v1 [cs.CL])",
    "abstract": "The social NLP research community witness a recent surge in the computational advancements of mental health analysis to build responsible AI models for a complex interplay between language use and self-perception. Such responsible AI models aid in quantifying the psychological concepts from user-penned texts on social media. On thinking beyond the low-level (classification) task, we advance the existing binary classification dataset, towards a higher-level task of reliability analysis through the lens of explanations, posing it as one of the safety measures. We annotate the LoST dataset to capture nuanced textual cues that suggest the presence of low self-esteem in the posts of Reddit users. We further state that the NLP models developed for determining the presence of low self-esteem, focus more on three types of textual cues: (i) Trigger: words that triggers mental disturbance, (ii) LoST indicators: text indicators emphasizing low self-esteem, and (iii) Consequences: words describing",
    "link": "http://arxiv.org/abs/2401.06709",
    "context": "Title: Reliability Analysis of Psychological Concept Extraction and Classification in User-penned Text. (arXiv:2401.06709v1 [cs.CL])\nAbstract: The social NLP research community witness a recent surge in the computational advancements of mental health analysis to build responsible AI models for a complex interplay between language use and self-perception. Such responsible AI models aid in quantifying the psychological concepts from user-penned texts on social media. On thinking beyond the low-level (classification) task, we advance the existing binary classification dataset, towards a higher-level task of reliability analysis through the lens of explanations, posing it as one of the safety measures. We annotate the LoST dataset to capture nuanced textual cues that suggest the presence of low self-esteem in the posts of Reddit users. We further state that the NLP models developed for determining the presence of low self-esteem, focus more on three types of textual cues: (i) Trigger: words that triggers mental disturbance, (ii) LoST indicators: text indicators emphasizing low self-esteem, and (iii) Consequences: words describing",
    "path": "papers/24/01/2401.06709.json",
    "total_tokens": 945,
    "translated_title": "在用户撰写的文本中心理概念提取和分类的可靠性分析",
    "translated_abstract": "社交NLP研究社区最近在心理健康分析的计算进展中见证了一波复杂的语言使用和自我感知之间相互作用的AI模型的建立。这些负责任的AI模型有助于从社交媒体上的用户撰写的文本中量化心理概念。在超越低级（分类）任务的基础上，我们将现有的二元分类数据集提升到更高级别的可靠性分析任务，通过解释的角度将之作为一种安全措施。我们注释了LoST数据集，以捕捉表明Reddit用户发帖中存在低自尊的微妙文本提示。我们进一步指出，用于确定低自尊存在的NLP模型更加关注三种类型的文本提示：（i）触发词：触发心理扰动的词汇，（ii）LoST指标：强调低自尊的文本指标，以及（iii）后果：描述情绪稳定性后果的词汇。",
    "tldr": "该论文研究了在用户撰写的文本中心理概念提取和分类的可靠性分析，并通过注解LoST数据集来捕捉表明低自尊存在的微妙文本提示。研究发现，NLP模型对触发词、LoST指标和后果这三类文本提示更加关注。",
    "en_tdlr": "This paper analyzes the reliability of psychological concept extraction and classification in user-penned text, and captures nuanced textual cues suggesting the presence of low self-esteem through annotation of the LoST dataset. The research finds that NLP models pay more attention to trigger words, LoST indicators, and consequences as textual cues."
}