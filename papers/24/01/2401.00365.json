{
    "title": "HQ-VAE: Hierarchical Discrete Representation Learning with Variational Bayes",
    "abstract": "arXiv:2401.00365v2 Announce Type: replace-cross  Abstract: Vector quantization (VQ) is a technique to deterministically learn features with discrete codebook representations. It is commonly performed with a variational autoencoding model, VQ-VAE, which can be further extended to hierarchical structures for making high-fidelity reconstructions. However, such hierarchical extensions of VQ-VAE often suffer from the codebook/layer collapse issue, where the codebook is not efficiently used to express the data, and hence degrades reconstruction accuracy. To mitigate this problem, we propose a novel unified framework to stochastically learn hierarchical discrete representation on the basis of the variational Bayes framework, called hierarchically quantized variational autoencoder (HQ-VAE). HQ-VAE naturally generalizes the hierarchical variants of VQ-VAE, such as VQ-VAE-2 and residual-quantized VAE (RQ-VAE), and provides them with a Bayesian training scheme. Our comprehensive experiments on im",
    "link": "https://arxiv.org/abs/2401.00365",
    "context": "Title: HQ-VAE: Hierarchical Discrete Representation Learning with Variational Bayes\nAbstract: arXiv:2401.00365v2 Announce Type: replace-cross  Abstract: Vector quantization (VQ) is a technique to deterministically learn features with discrete codebook representations. It is commonly performed with a variational autoencoding model, VQ-VAE, which can be further extended to hierarchical structures for making high-fidelity reconstructions. However, such hierarchical extensions of VQ-VAE often suffer from the codebook/layer collapse issue, where the codebook is not efficiently used to express the data, and hence degrades reconstruction accuracy. To mitigate this problem, we propose a novel unified framework to stochastically learn hierarchical discrete representation on the basis of the variational Bayes framework, called hierarchically quantized variational autoencoder (HQ-VAE). HQ-VAE naturally generalizes the hierarchical variants of VQ-VAE, such as VQ-VAE-2 and residual-quantized VAE (RQ-VAE), and provides them with a Bayesian training scheme. Our comprehensive experiments on im",
    "path": "papers/24/01/2401.00365.json",
    "total_tokens": 821,
    "translated_title": "HQ-VAE：具有变分贝叶斯的分层离散表示学习",
    "translated_abstract": "向量量化（VQ）是一种确定性学习具有离散码书表示的特征的技术。通常通过变分自动编码模型 VQ-VAE 来执行，可以进一步扩展到分层结构以进行高保真重建。然而，VQ-VAE 的这种分层扩展经常受到码书/层坍塌问题的困扰，其中码书未被有效地用来表达数据，从而降低重建精度。为了缓解这个问题，我们提出了一个新颖的统一框架，在变分贝叶斯框架的基础上随机学习分层离散表示，称为分层量化变分自动编码器（HQ-VAE）。",
    "tldr": "HQ-VAE提出了一种统一框架，利用变分贝叶斯在分层结构中随机学习离散表示，解决了传统VQ-VAE中的码书/层坍塌问题。",
    "en_tdlr": "HQ-VAE proposes a unified framework that stochastically learns discrete representations in hierarchical structures based on variational Bayes, addressing the codebook/layer collapse issue in traditional VQ-VAE."
}