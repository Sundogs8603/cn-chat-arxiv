{
    "title": "Salute the Classic: Revisiting Challenges of Machine Translation in the Age of Large Language Models. (arXiv:2401.08350v2 [cs.CL] UPDATED)",
    "abstract": "The evolution of Neural Machine Translation (NMT) has been significantly influenced by six core challenges (Koehn and Knowles, 2017), which have acted as benchmarks for progress in this field. This study revisits these challenges, offering insights into their ongoing relevance in the context of advanced Large Language Models (LLMs): domain mismatch, amount of parallel data, rare word prediction, translation of long sentences, attention model as word alignment, and sub-optimal beam search. Our empirical findings indicate that LLMs effectively lessen the reliance on parallel data for major languages in the pretraining phase. Additionally, the LLM-based translation system significantly enhances the translation of long sentences that contain approximately 80 words and shows the capability to translate documents of up to 512 words. However, despite these significant improvements, the challenges of domain mismatch and prediction of rare words persist. While the challenges of word alignment a",
    "link": "http://arxiv.org/abs/2401.08350",
    "context": "Title: Salute the Classic: Revisiting Challenges of Machine Translation in the Age of Large Language Models. (arXiv:2401.08350v2 [cs.CL] UPDATED)\nAbstract: The evolution of Neural Machine Translation (NMT) has been significantly influenced by six core challenges (Koehn and Knowles, 2017), which have acted as benchmarks for progress in this field. This study revisits these challenges, offering insights into their ongoing relevance in the context of advanced Large Language Models (LLMs): domain mismatch, amount of parallel data, rare word prediction, translation of long sentences, attention model as word alignment, and sub-optimal beam search. Our empirical findings indicate that LLMs effectively lessen the reliance on parallel data for major languages in the pretraining phase. Additionally, the LLM-based translation system significantly enhances the translation of long sentences that contain approximately 80 words and shows the capability to translate documents of up to 512 words. However, despite these significant improvements, the challenges of domain mismatch and prediction of rare words persist. While the challenges of word alignment a",
    "path": "papers/24/01/2401.08350.json",
    "total_tokens": 950,
    "translated_title": "向经典致敬：在大规模语言模型时代重新思考机器翻译的挑战",
    "translated_abstract": "神经机器翻译 (NMT) 的发展受到六个核心挑战的显著影响，这些挑战为这个领域的进展提供了基准。本研究重新审视了这些挑战，在先进大规模语言模型 (LLM) 的背景下，提供了对这些挑战持续相关性的深入见解。我们的实证研究表明，在预训练阶段，LLM能够有效减少对平行数据的依赖，特别是对于主要语言。此外，基于LLM的翻译系统显著提高了翻译约80个单词的长句子的质量，并且能够翻译长达512个单词的文档。然而，尽管取得了显著的改进，领域不匹配和罕见词预测仍然是挑战。在解决单词对齐和亚最优搜索的挑战方面，LLM仍存在改进的空间。",
    "tldr": "本文重新审视了机器翻译领域的六个核心挑战，并提供了对于大规模语言模型在这些挑战中所取得进展的实证发现。研究发现，大规模语言模型能够有效减少对平行数据的依赖，提高翻译质量并扩展翻译文档的长度范围。然而，领域不匹配和罕见词预测仍然是需要解决的问题。"
}