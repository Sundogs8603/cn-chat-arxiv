{
    "title": "Personalized Differential Privacy for Ridge Regression. (arXiv:2401.17127v1 [cs.LG])",
    "abstract": "The increased application of machine learning (ML) in sensitive domains requires protecting the training data through privacy frameworks, such as differential privacy (DP). DP requires to specify a uniform privacy level $\\varepsilon$ that expresses the maximum privacy loss that each data point in the entire dataset is willing to tolerate. Yet, in practice, different data points often have different privacy requirements. Having to set one uniform privacy level is usually too restrictive, often forcing a learner to guarantee the stringent privacy requirement, at a large cost to accuracy. To overcome this limitation, we introduce our novel Personalized-DP Output Perturbation method (PDP-OP) that enables to train Ridge regression models with individual per data point privacy levels. We provide rigorous privacy proofs for our PDP-OP as well as accuracy guarantees for the resulting model. This work is the first to provide such theoretical accuracy guarantees when it comes to personalized DP ",
    "link": "http://arxiv.org/abs/2401.17127",
    "context": "Title: Personalized Differential Privacy for Ridge Regression. (arXiv:2401.17127v1 [cs.LG])\nAbstract: The increased application of machine learning (ML) in sensitive domains requires protecting the training data through privacy frameworks, such as differential privacy (DP). DP requires to specify a uniform privacy level $\\varepsilon$ that expresses the maximum privacy loss that each data point in the entire dataset is willing to tolerate. Yet, in practice, different data points often have different privacy requirements. Having to set one uniform privacy level is usually too restrictive, often forcing a learner to guarantee the stringent privacy requirement, at a large cost to accuracy. To overcome this limitation, we introduce our novel Personalized-DP Output Perturbation method (PDP-OP) that enables to train Ridge regression models with individual per data point privacy levels. We provide rigorous privacy proofs for our PDP-OP as well as accuracy guarantees for the resulting model. This work is the first to provide such theoretical accuracy guarantees when it comes to personalized DP ",
    "path": "papers/24/01/2401.17127.json",
    "total_tokens": 876,
    "translated_title": "个性化差分隐私在Ridge回归中的应用",
    "translated_abstract": "在敏感领域中机器学习的应用增加，需要通过差分隐私等隐私框架保护训练数据。差分隐私要求指定一个统一的隐私水平ε，以表示每个数据点在整个数据集中愿意容忍的最大隐私损失。然而，在实践中，不同的数据点通常有不同的隐私需求。只设置一个统一的隐私水平通常过于限制，不允许学习器以大量的精度开销来保证严格的隐私要求。为了克服这个限制，我们引入了我们的个性化差分隐私输出扰动方法（PDP-OP），它可以训练具有每个数据点个性化隐私水平的Ridge回归模型。我们提供了对我们的PDP-OP的严格隐私证明以及生成模型的准确度保证。这项工作是首次在个性化差分隐私方面提供了这样的理论准确度保证。",
    "tldr": "该论文提出了一种个性化差分隐私输出扰动方法（PDP-OP），可以在Ridge回归中训练具有每个数据点个性化隐私水平的模型，并提供了相应的隐私证明和准确度保证。"
}