{
    "title": "Cooperative Multi-Agent Graph Bandits: UCB Algorithm and Regret Analysis. (arXiv:2401.10383v1 [cs.LG])",
    "abstract": "In this paper, we formulate the multi-agent graph bandit problem as a multi-agent extension of the graph bandit problem introduced by Zhang, Johansson, and Li [CISS 57, 1-6 (2023)]. In our formulation, $N$ cooperative agents travel on a connected graph $G$ with $K$ nodes. Upon arrival at each node, agents observe a random reward drawn from a node-dependent probability distribution. The reward of the system is modeled as a weighted sum of the rewards the agents observe, where the weights capture the decreasing marginal reward associated with multiple agents sampling the same node at the same time. We propose an Upper Confidence Bound (UCB)-based learning algorithm, Multi-G-UCB, and prove that its expected regret over $T$ steps is bounded by $O(N\\log(T)[\\sqrt{KT} + DK])$, where $D$ is the diameter of graph $G$. Lastly, we numerically test our algorithm by comparing it to alternative methods.",
    "link": "http://arxiv.org/abs/2401.10383",
    "context": "Title: Cooperative Multi-Agent Graph Bandits: UCB Algorithm and Regret Analysis. (arXiv:2401.10383v1 [cs.LG])\nAbstract: In this paper, we formulate the multi-agent graph bandit problem as a multi-agent extension of the graph bandit problem introduced by Zhang, Johansson, and Li [CISS 57, 1-6 (2023)]. In our formulation, $N$ cooperative agents travel on a connected graph $G$ with $K$ nodes. Upon arrival at each node, agents observe a random reward drawn from a node-dependent probability distribution. The reward of the system is modeled as a weighted sum of the rewards the agents observe, where the weights capture the decreasing marginal reward associated with multiple agents sampling the same node at the same time. We propose an Upper Confidence Bound (UCB)-based learning algorithm, Multi-G-UCB, and prove that its expected regret over $T$ steps is bounded by $O(N\\log(T)[\\sqrt{KT} + DK])$, where $D$ is the diameter of graph $G$. Lastly, we numerically test our algorithm by comparing it to alternative methods.",
    "path": "papers/24/01/2401.10383.json",
    "total_tokens": 871,
    "translated_title": "合作多智能体图形赌博机：UCB算法和遗憾分析",
    "translated_abstract": "本文将多智能体图形赌博机问题建模为Zhang、Johansson和Li在[CISS 57, 1-6 (2023)]中提出的图形赌博机问题的多智能体扩展。在我们的模型中，N个合作智能体在一个连通的图G上移动，图G有K个节点。抵达每个节点时，智能体观察到从一个与节点相关的概率分布中随机抽取的奖励。系统奖励被建模为智能体观测到的奖励的加权和，其中权重表达了多个智能体同时对同一节点进行采样的边际减少奖励。我们提出了一个基于上限置信区间（UCB）的学习算法，称为Multi-G-UCB，并证明了在T步内其期望遗憾被界定为$O(N\\log(T)[\\sqrt{KT} + DK])$，其中D是图G的直径。最后，我们通过与其他方法进行比较对算法进行了数值测试。",
    "tldr": "本文提出了一种解决多智能体图形赌博机问题的算法Multi-G-UCB，并通过数值实验验证了其有效性。",
    "en_tdlr": "We propose an algorithm, Multi-G-UCB, to solve the multi-agent graph bandit problem and validate its effectiveness through numerical experiments."
}