{
    "title": "Deep Dict: Deep Learning-based Lossy Time Series Compressor for IoT Data. (arXiv:2401.10396v1 [eess.SP])",
    "abstract": "We propose Deep Dict, a deep learning-based lossy time series compressor designed to achieve a high compression ratio while maintaining decompression error within a predefined range. Deep Dict incorporates two essential components: the Bernoulli transformer autoencoder (BTAE) and a distortion constraint. BTAE extracts Bernoulli representations from time series data, reducing the size of the representations compared to conventional autoencoders. The distortion constraint limits the prediction error of BTAE to the desired range. Moreover, in order to address the limitations of common regression losses such as L1/L2, we introduce a novel loss function called quantized entropy loss (QEL). QEL takes into account the specific characteristics of the problem, enhancing robustness to outliers and alleviating optimization challenges. Our evaluation of Deep Dict across ten diverse time series datasets from various domains reveals that Deep Dict outperforms state-of-the-art lossy compressors in te",
    "link": "http://arxiv.org/abs/2401.10396",
    "context": "Title: Deep Dict: Deep Learning-based Lossy Time Series Compressor for IoT Data. (arXiv:2401.10396v1 [eess.SP])\nAbstract: We propose Deep Dict, a deep learning-based lossy time series compressor designed to achieve a high compression ratio while maintaining decompression error within a predefined range. Deep Dict incorporates two essential components: the Bernoulli transformer autoencoder (BTAE) and a distortion constraint. BTAE extracts Bernoulli representations from time series data, reducing the size of the representations compared to conventional autoencoders. The distortion constraint limits the prediction error of BTAE to the desired range. Moreover, in order to address the limitations of common regression losses such as L1/L2, we introduce a novel loss function called quantized entropy loss (QEL). QEL takes into account the specific characteristics of the problem, enhancing robustness to outliers and alleviating optimization challenges. Our evaluation of Deep Dict across ten diverse time series datasets from various domains reveals that Deep Dict outperforms state-of-the-art lossy compressors in te",
    "path": "papers/24/01/2401.10396.json",
    "total_tokens": 1030,
    "translated_title": "深度字典: 基于深度学习的物联网数据的有损时间序列压缩器",
    "translated_abstract": "我们提出了深度字典，一种基于深度学习的有损时间序列压缩器，旨在实现高压缩比的同时保持解压缩误差在预定范围内。深度字典包括两个关键组件：伯努利变换自编码器（BTAE）和失真约束。BTAE从时间序列数据中提取伯努利表示，相对于传统自编码器，减小了表示的大小。失真约束限制了BTAE的预测误差在期望范围内。此外，为了解决常见回归损失（如L1/L2）的局限性，我们引入了一种称为量化熵损失（QEL）的新型损失函数。QEL考虑了问题的特定特性，增强了对异常值的鲁棒性，并减轻了优化挑战。我们对来自不同领域的10个多样化的时间序列数据集进行了深度字典的评估，结果显示深度字典在压缩率方面优于最先进的有损压缩器。",
    "tldr": "提出了一种深度学习-based的有损时间序列压缩器Deep Dict，通过引入伯努利变换自编码器（BTAE）和失真约束的方式，实现了高压缩比和保持预定范围内的解压缩误差，并通过引入量化熵损失（QEL）来提高鲁棒性。与最先进的有损压缩器相比，在多个时间序列数据集上表现更好。",
    "en_tdlr": "A deep learning-based lossy time series compressor called Deep Dict is proposed, which achieves a high compression ratio and maintains decompression error within a predefined range by incorporating the Bernoulli transformer autoencoder (BTAE) and a distortion constraint. The introduction of the novel loss function quantized entropy loss (QEL) improves robustness. Deep Dict outperforms state-of-the-art lossy compressors in multiple time series datasets."
}