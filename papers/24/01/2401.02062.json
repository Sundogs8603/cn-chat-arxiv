{
    "title": "U-Trustworthy Models.Reliability, Competence, and Confidence in Decision-Making. (arXiv:2401.02062v1 [stat.ML])",
    "abstract": "With growing concerns regarding bias and discrimination in predictive models, the AI community has increasingly focused on assessing AI system trustworthiness. Conventionally, trustworthy AI literature relies on the probabilistic framework and calibration as prerequisites for trustworthiness. In this work, we depart from this viewpoint by proposing a novel trust framework inspired by the philosophy literature on trust. We present a precise mathematical definition of trustworthiness, termed $\\mathcal{U}$-trustworthiness, specifically tailored for a subset of tasks aimed at maximizing a utility function. We argue that a model's $\\mathcal{U}$-trustworthiness is contingent upon its ability to maximize Bayes utility within this task subset. Our first set of results challenges the probabilistic framework by demonstrating its potential to favor less trustworthy models and introduce the risk of misleading trustworthiness assessments. Within the context of $\\mathcal{U}$-trustworthiness, we prov",
    "link": "http://arxiv.org/abs/2401.02062",
    "context": "Title: U-Trustworthy Models.Reliability, Competence, and Confidence in Decision-Making. (arXiv:2401.02062v1 [stat.ML])\nAbstract: With growing concerns regarding bias and discrimination in predictive models, the AI community has increasingly focused on assessing AI system trustworthiness. Conventionally, trustworthy AI literature relies on the probabilistic framework and calibration as prerequisites for trustworthiness. In this work, we depart from this viewpoint by proposing a novel trust framework inspired by the philosophy literature on trust. We present a precise mathematical definition of trustworthiness, termed $\\mathcal{U}$-trustworthiness, specifically tailored for a subset of tasks aimed at maximizing a utility function. We argue that a model's $\\mathcal{U}$-trustworthiness is contingent upon its ability to maximize Bayes utility within this task subset. Our first set of results challenges the probabilistic framework by demonstrating its potential to favor less trustworthy models and introduce the risk of misleading trustworthiness assessments. Within the context of $\\mathcal{U}$-trustworthiness, we prov",
    "path": "papers/24/01/2401.02062.json",
    "total_tokens": 957,
    "translated_title": "U-信任模型 - 决策中的可靠性、能力和信心",
    "translated_abstract": "随着对预测模型中偏见和歧视的担忧日益增长，人工智能社区越来越关注评估AI系统的信任性。传统上，信任的AI文献依赖于概率框架和校准作为信任的先决条件。在这项工作中，我们离开了这个观点，提出了一个受哲学文献中关于信任的启示的新的信任框架。我们提出了一个精确的数学定义，称为$\\mathcal{U}$-信任度，专门为最大化效用函数的任务子集量身定制。我们认为一个模型的$\\mathcal{U}$-信任度取决于它在这个任务子集中最大化贝叶斯效用的能力。我们的第一组结果挑战了概率框架，通过展示它可能偏向不太可信的模型，并引入误导性信任评估的风险。在$\\mathcal{U}$-信任度的背景下，我们提供了一些解决方案，以克服这些挑战，并提高模型的信任度估计。",
    "tldr": "提出了一种基于哲学文献的新的信任框架$\\mathcal{U}$-信任度，用于评估AI系统的信任性，该框架挑战了传统的概率框架，并提出了解决方案以克服偏见和误导性信任评估的风险。",
    "en_tdlr": "A novel trust framework $\\mathcal{U}$-trustworthiness is proposed to assess the trustworthiness of AI systems, challenging the conventional probabilistic framework and offering solutions to overcome the risks of bias and misleading trustworthiness assessments."
}