{
    "title": "Accelerating Black-Box Molecular Property Optimization by Adaptively Learning Sparse Subspaces. (arXiv:2401.01398v1 [q-bio.BM])",
    "abstract": "Molecular property optimization (MPO) problems are inherently challenging since they are formulated over discrete, unstructured spaces and the labeling process involves expensive simulations or experiments, which fundamentally limits the amount of available data. Bayesian optimization (BO) is a powerful and popular framework for efficient optimization of noisy, black-box objective functions (e.g., measured property values), thus is a potentially attractive framework for MPO. To apply BO to MPO problems, one must select a structured molecular representation that enables construction of a probabilistic surrogate model. Many molecular representations have been developed, however, they are all high-dimensional, which introduces important challenges in the BO process -- mainly because the curse of dimensionality makes it difficult to define and perform inference over a suitable class of surrogate models. This challenge has been recently addressed by learning a lower-dimensional encoding of ",
    "link": "http://arxiv.org/abs/2401.01398",
    "context": "Title: Accelerating Black-Box Molecular Property Optimization by Adaptively Learning Sparse Subspaces. (arXiv:2401.01398v1 [q-bio.BM])\nAbstract: Molecular property optimization (MPO) problems are inherently challenging since they are formulated over discrete, unstructured spaces and the labeling process involves expensive simulations or experiments, which fundamentally limits the amount of available data. Bayesian optimization (BO) is a powerful and popular framework for efficient optimization of noisy, black-box objective functions (e.g., measured property values), thus is a potentially attractive framework for MPO. To apply BO to MPO problems, one must select a structured molecular representation that enables construction of a probabilistic surrogate model. Many molecular representations have been developed, however, they are all high-dimensional, which introduces important challenges in the BO process -- mainly because the curse of dimensionality makes it difficult to define and perform inference over a suitable class of surrogate models. This challenge has been recently addressed by learning a lower-dimensional encoding of ",
    "path": "papers/24/01/2401.01398.json",
    "total_tokens": 857,
    "translated_title": "通过自适应学习稀疏子空间加速黑箱分子性质优化",
    "translated_abstract": "分子性质优化问题本质上具有挑战性，因为它们是在离散、非结构化空间上定义的，并且标记过程涉及昂贵的模拟或实验，这从根本上限制了可用数据的数量。贝叶斯优化是一种有效优化嘈杂的、黑箱目标函数（例如测量的性质值）的强大且流行的框架，因此对于分子性质优化而言是一个潜在的有吸引力的框架。要将贝叶斯优化应用于分子性质优化问题，必须选择一种结构化的分子表示方法，以便构建一个概率模型。许多分子表示方法已经被开发出来，然而它们都是高维的，这在贝叶斯优化过程中引入了重要的挑战，主要是因为维度的诅咒使得难以定义和执行适合的代理模型。最近通过学习更低维的编码来解决了这个挑战",
    "tldr": "通过自适应学习稀疏子空间加速黑箱分子性质优化的挑战已经通过学习更低维的编码得到解决",
    "en_tdlr": "The challenge of accelerating black-box molecular property optimization by adaptively learning sparse subspaces has been addressed by learning a lower-dimensional encoding."
}