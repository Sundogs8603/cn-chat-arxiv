{
    "title": "Functional Autoencoder for Smoothing and Representation Learning. (arXiv:2401.09499v1 [cs.LG])",
    "abstract": "A common pipeline in functional data analysis is to first convert the discretely observed data to smooth functions, and then represent the functions by a finite-dimensional vector of coefficients summarizing the information. Existing methods for data smoothing and dimensional reduction mainly focus on learning the linear mappings from the data space to the representation space, however, learning only the linear representations may not be sufficient. In this study, we propose to learn the nonlinear representations of functional data using neural network autoencoders designed to process data in the form it is usually collected without the need of preprocessing. We design the encoder to employ a projection layer computing the weighted inner product of the functional data and functional weights over the observed timestamp, and the decoder to apply a recovery layer that maps the finite-dimensional vector extracted from the functional data back to functional space using a set of predetermine",
    "link": "http://arxiv.org/abs/2401.09499",
    "context": "Title: Functional Autoencoder for Smoothing and Representation Learning. (arXiv:2401.09499v1 [cs.LG])\nAbstract: A common pipeline in functional data analysis is to first convert the discretely observed data to smooth functions, and then represent the functions by a finite-dimensional vector of coefficients summarizing the information. Existing methods for data smoothing and dimensional reduction mainly focus on learning the linear mappings from the data space to the representation space, however, learning only the linear representations may not be sufficient. In this study, we propose to learn the nonlinear representations of functional data using neural network autoencoders designed to process data in the form it is usually collected without the need of preprocessing. We design the encoder to employ a projection layer computing the weighted inner product of the functional data and functional weights over the observed timestamp, and the decoder to apply a recovery layer that maps the finite-dimensional vector extracted from the functional data back to functional space using a set of predetermine",
    "path": "papers/24/01/2401.09499.json",
    "total_tokens": 735,
    "translated_title": "功能自编码器用于平滑和表示学习",
    "translated_abstract": "功能数据分析中常用的流程是将离散观测数据转换为平滑函数，然后通过一个有限维度的系数向量来表示这些函数以总结信息。现有的数据平滑和降维方法主要集中在学习线性映射，但仅学习线性表示可能不足够。在本研究中，我们提出使用神经网络自编码器学习功能数据的非线性表示，而无需预处理。我们设计编码器采用投影层，计算功能数据和观察时间戳上的功能权重的加权内积，解码器应用恢复层，使用一组预先确定的有限维度向量将从功能数据中提取的向量映射回功能空间。",
    "tldr": "本研究提出了一种功能自编码器，用于学习功能数据的非线性表示，并避免了预处理的需要。",
    "en_tdlr": "This study proposes a functional autoencoder for learning nonlinear representations of functional data without the need for preprocessing. It aims to overcome the limitations of linear representations in data smoothing and dimensional reduction methods."
}