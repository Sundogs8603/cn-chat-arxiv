{
    "title": "CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs",
    "abstract": "arXiv:2401.11314v2 Announce Type: replace-cross  Abstract: Timely, personalized feedback is essential for students learning programming. LLM-powered tools like ChatGPT offer instant support, but reveal direct answers with code, which may hinder deep conceptual engagement. We developed CodeAid, an LLM-powered programming assistant delivering helpful, technically correct responses, without revealing code solutions. CodeAid answers conceptual questions, generates pseudo-code with line-by-line explanations, and annotates student's incorrect code with fix suggestions. We deployed CodeAid in a programming class of 700 students for a 12-week semester. A thematic analysis of 8,000 usages of CodeAid was performed, further enriched by weekly surveys, and 22 student interviews. We then interviewed eight programming educators to gain further insights. Our findings reveal four design considerations for future educational AI assistants: D1) exploiting AI's unique benefits; D2) simplifying query form",
    "link": "https://arxiv.org/abs/2401.11314",
    "context": "Title: CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs\nAbstract: arXiv:2401.11314v2 Announce Type: replace-cross  Abstract: Timely, personalized feedback is essential for students learning programming. LLM-powered tools like ChatGPT offer instant support, but reveal direct answers with code, which may hinder deep conceptual engagement. We developed CodeAid, an LLM-powered programming assistant delivering helpful, technically correct responses, without revealing code solutions. CodeAid answers conceptual questions, generates pseudo-code with line-by-line explanations, and annotates student's incorrect code with fix suggestions. We deployed CodeAid in a programming class of 700 students for a 12-week semester. A thematic analysis of 8,000 usages of CodeAid was performed, further enriched by weekly surveys, and 22 student interviews. We then interviewed eight programming educators to gain further insights. Our findings reveal four design considerations for future educational AI assistants: D1) exploiting AI's unique benefits; D2) simplifying query form",
    "path": "papers/24/01/2401.11314.json",
    "total_tokens": 961,
    "translated_title": "CodeAid: 对基于LLM的编程助手进行课堂部署的评估，平衡学生和教育者的需求",
    "translated_abstract": "科学的、个性化的反馈对于学习编程的学生至关重要。像ChatGPT这样基于LLM的工具提供即时支持，但呈现直接的代码答案，这可能妨碍深入的概念参与。我们开发了CodeAid，一个基于LLM的编程助手，提供有用的、技术上正确的回答，但不显示代码解决方案。CodeAid回答概念问题，生成带有逐行解释的伪代码，并为学生的错误代码加上修复建议。我们在一个包括700名学生的编程课程中部署了CodeAid，为期12周。我们进行了8000次CodeAid使用的主题分析，进一步结合每周调查和22次学生访谈。然后我们采访了八名编程教育者，以获得更多见解。我们的研究结果揭示了未来教育AI助手的四个设计考虑：D1)充分利用AI的独特优势；D2)简化查询形式。",
    "tldr": "通过开发CodeAid，一个基于LLM的编程助手，我们平衡了学生和教育者的需求，提供了有用的概念性回答而不暴露代码解决方案，在课堂环境中对其进行了评估和部署，并总结出四个未来教育AI助手的设计考虑。"
}