{
    "title": "Wasserstein Differential Privacy. (arXiv:2401.12436v1 [cs.LG])",
    "abstract": "Differential privacy (DP) has achieved remarkable results in the field of privacy-preserving machine learning. However, existing DP frameworks do not satisfy all the conditions for becoming metrics, which prevents them from deriving better basic private properties and leads to exaggerated values on privacy budgets. We propose Wasserstein differential privacy (WDP), an alternative DP framework to measure the risk of privacy leakage, which satisfies the properties of symmetry and triangle inequality. We show and prove that WDP has 13 excellent properties, which can be theoretical supports for the better performance of WDP than other DP frameworks. In addition, we derive a general privacy accounting method called Wasserstein accountant, which enables WDP to be applied in stochastic gradient descent (SGD) scenarios containing sub-sampling. Experiments on basic mechanisms, compositions and deep learning show that the privacy budgets obtained by Wasserstein accountant are relatively stable a",
    "link": "http://arxiv.org/abs/2401.12436",
    "context": "Title: Wasserstein Differential Privacy. (arXiv:2401.12436v1 [cs.LG])\nAbstract: Differential privacy (DP) has achieved remarkable results in the field of privacy-preserving machine learning. However, existing DP frameworks do not satisfy all the conditions for becoming metrics, which prevents them from deriving better basic private properties and leads to exaggerated values on privacy budgets. We propose Wasserstein differential privacy (WDP), an alternative DP framework to measure the risk of privacy leakage, which satisfies the properties of symmetry and triangle inequality. We show and prove that WDP has 13 excellent properties, which can be theoretical supports for the better performance of WDP than other DP frameworks. In addition, we derive a general privacy accounting method called Wasserstein accountant, which enables WDP to be applied in stochastic gradient descent (SGD) scenarios containing sub-sampling. Experiments on basic mechanisms, compositions and deep learning show that the privacy budgets obtained by Wasserstein accountant are relatively stable a",
    "path": "papers/24/01/2401.12436.json",
    "total_tokens": 828,
    "translated_title": "Wasserstein差分隐私",
    "translated_abstract": "差分隐私（DP）在隐私保护机器学习领域取得了显著的成果。然而，现有的DP框架并不满足成为度量的所有条件，这导致它们无法推导出更好的基本私有性质，并导致过高的隐私预算值。我们提出了Wasserstein差分隐私（WDP），这是一种用于测量隐私泄漏风险的替代DP框架，满足对称性和三角不等式性质。我们展示并证明WDP具有13个优秀性质，这些性质可以为WDP比其他DP框架表现更好提供理论支持。此外，我们推导出一种称为Wasserstein机制的通用隐私计算方法，使得WDP可以应用于包含子采样的随机梯度下降（SGD）场景。基本机制、组合和深度学习的实验证明，由Wasserstein机制得到的隐私预算相对稳定。",
    "tldr": "Wasserstein Differential Privacy是一种用于测量隐私泄漏风险的替代DP框架，满足对称性和三角不等式性质，并具有13个优秀性质。Wasserstein accountant是一种通用的隐私计算方法，可以稳定地获得隐私预算。"
}