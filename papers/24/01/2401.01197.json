{
    "title": "Uncertainty Resolution in Misinformation Detection. (arXiv:2401.01197v1 [cs.CL])",
    "abstract": "Misinformation poses a variety of risks, such as undermining public trust and distorting factual discourse. Large Language Models (LLMs) like GPT-4 have been shown effective in mitigating misinformation, particularly in handling statements where enough context is provided. However, they struggle to assess ambiguous or context-deficient statements accurately. This work introduces a new method to resolve uncertainty in such statements. We propose a framework to categorize missing information and publish category labels for the LIAR-New dataset, which is adaptable to cross-domain content with missing information. We then leverage this framework to generate effective user queries for missing context. Compared to baselines, our method improves the rate at which generated questions are answerable by the user by 38 percentage points and classification performance by over 10 percentage points macro F1. Thus, this approach may provide a valuable component for future misinformation mitigation pi",
    "link": "http://arxiv.org/abs/2401.01197",
    "context": "Title: Uncertainty Resolution in Misinformation Detection. (arXiv:2401.01197v1 [cs.CL])\nAbstract: Misinformation poses a variety of risks, such as undermining public trust and distorting factual discourse. Large Language Models (LLMs) like GPT-4 have been shown effective in mitigating misinformation, particularly in handling statements where enough context is provided. However, they struggle to assess ambiguous or context-deficient statements accurately. This work introduces a new method to resolve uncertainty in such statements. We propose a framework to categorize missing information and publish category labels for the LIAR-New dataset, which is adaptable to cross-domain content with missing information. We then leverage this framework to generate effective user queries for missing context. Compared to baselines, our method improves the rate at which generated questions are answerable by the user by 38 percentage points and classification performance by over 10 percentage points macro F1. Thus, this approach may provide a valuable component for future misinformation mitigation pi",
    "path": "papers/24/01/2401.01197.json",
    "total_tokens": 847,
    "translated_title": "误解信息检测中的不确定性解决方法",
    "translated_abstract": "误解信息存在各种风险，如破坏公众信任和扭曲事实言论。大型语言模型（LLMs）如GPT-4已被证明在减轻误解信息方面很有效，特别是在处理提供足够上下文的陈述时。然而，它们很难准确评估模糊或缺乏上下文的陈述。本文介绍了一种解决此类陈述中不确定性的新方法。我们提出了一个框架来对缺失信息进行分类，并为LIAR-New数据集提供类别标签，该数据集适用于具有缺失信息的跨域内容。然后，我们利用这个框架来生成缺失上下文的有效用户查询。与基线相比，我们的方法提高了用户可回答问题的比例38个百分点，并且分类性能提高了超过10个百分点的宏F1。因此，这种方法可能为未来的误解信息缓解提供有价值的组成部分。",
    "tldr": "该研究介绍了一种解决误解信息中不确定性的新方法，通过提出一个分类框架和生成有效的用户查询来解决缺失上下文的问题，提高了误解信息检测的性能。",
    "en_tdlr": "This study introduces a new method to resolve uncertainty in misinformation by proposing a categorization framework and generating effective user queries to handle missing context, improving the performance of misinformation detection."
}