{
    "title": "Meme-ingful Analysis: Enhanced Understanding of Cyberbullying in Memes Through Multimodal Explanations. (arXiv:2401.09899v1 [cs.CL])",
    "abstract": "Internet memes have gained significant influence in communicating political, psychological, and sociocultural ideas. While memes are often humorous, there has been a rise in the use of memes for trolling and cyberbullying. Although a wide variety of effective deep learning-based models have been developed for detecting offensive multimodal memes, only a few works have been done on explainability aspect. Recent laws like \"right to explanations\" of General Data Protection Regulation, have spurred research in developing interpretable models rather than only focusing on performance. Motivated by this, we introduce {\\em MultiBully-Ex}, the first benchmark dataset for multimodal explanation from code-mixed cyberbullying memes. Here, both visual and textual modalities are highlighted to explain why a given meme is cyberbullying. A Contrastive Language-Image Pretraining (CLIP) projection-based multimodal shared-private multitask approach has been proposed for visual and textual explanation of ",
    "link": "http://arxiv.org/abs/2401.09899",
    "context": "Title: Meme-ingful Analysis: Enhanced Understanding of Cyberbullying in Memes Through Multimodal Explanations. (arXiv:2401.09899v1 [cs.CL])\nAbstract: Internet memes have gained significant influence in communicating political, psychological, and sociocultural ideas. While memes are often humorous, there has been a rise in the use of memes for trolling and cyberbullying. Although a wide variety of effective deep learning-based models have been developed for detecting offensive multimodal memes, only a few works have been done on explainability aspect. Recent laws like \"right to explanations\" of General Data Protection Regulation, have spurred research in developing interpretable models rather than only focusing on performance. Motivated by this, we introduce {\\em MultiBully-Ex}, the first benchmark dataset for multimodal explanation from code-mixed cyberbullying memes. Here, both visual and textual modalities are highlighted to explain why a given meme is cyberbullying. A Contrastive Language-Image Pretraining (CLIP) projection-based multimodal shared-private multitask approach has been proposed for visual and textual explanation of ",
    "path": "papers/24/01/2401.09899.json",
    "total_tokens": 927,
    "translated_title": "有意义的模因分析：通过多模态解释提高对网络欺凌中的模因的理解",
    "translated_abstract": "互联网模因在传达政治、心理和社会文化观念方面具有重要影响力。虽然模因常常具有幽默的特点，但使用模因进行恶作剧和网络欺凌的现象正逐渐增加。虽然已经开发出了各种有效的基于深度学习的模型来检测冒犯性多模态模因，但在可解释性方面只有少数工作。类似于《通用数据保护条例》中的“解释权”，最近的相关法律已经推动了研究人员开发可解释的模型，而不仅仅关注性能。受此启发，我们引入了第一个用于多模态解释的代码混合网络欺凌模因基准数据集MultiBully-Ex。在这里，高亮显示了视觉和文本模态，以解释为什么给定的模因是网络欺凌行为。提出了基于对比语言-图像预训练（CLIP）投影的多模态共享-私有多任务方法，用于视觉和文本解释。",
    "tldr": "本研究提出了一个名为MultiBully-Ex的多模态解释的网络欺凌模因基准数据集，该数据集突出显示了视觉和文本模态，用于解释为什么给定的模因是网络欺凌行为。"
}