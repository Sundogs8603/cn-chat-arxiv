{
    "title": "Why is the User Interface a Dark Pattern? : Explainable Auto-Detection and its Analysis. (arXiv:2401.04119v1 [cs.HC])",
    "abstract": "Dark patterns are deceptive user interface designs for online services that make users behave in unintended ways. Dark patterns, such as privacy invasion, financial loss, and emotional distress, can harm users. These issues have been the subject of considerable debate in recent years. In this paper, we study interpretable dark pattern auto-detection, that is, why a particular user interface is detected as having dark patterns. First, we trained a model using transformer-based pre-trained language models, BERT, on a text-based dataset for the automatic detection of dark patterns in e-commerce. Then, we applied post-hoc explanation techniques, including local interpretable model agnostic explanation (LIME) and Shapley additive explanations (SHAP), to the trained model, which revealed which terms influence each prediction as a dark pattern. In addition, we extracted and analyzed terms that affected the dark patterns. Our findings may prevent users from being manipulated by dark patterns, ",
    "link": "http://arxiv.org/abs/2401.04119",
    "context": "Title: Why is the User Interface a Dark Pattern? : Explainable Auto-Detection and its Analysis. (arXiv:2401.04119v1 [cs.HC])\nAbstract: Dark patterns are deceptive user interface designs for online services that make users behave in unintended ways. Dark patterns, such as privacy invasion, financial loss, and emotional distress, can harm users. These issues have been the subject of considerable debate in recent years. In this paper, we study interpretable dark pattern auto-detection, that is, why a particular user interface is detected as having dark patterns. First, we trained a model using transformer-based pre-trained language models, BERT, on a text-based dataset for the automatic detection of dark patterns in e-commerce. Then, we applied post-hoc explanation techniques, including local interpretable model agnostic explanation (LIME) and Shapley additive explanations (SHAP), to the trained model, which revealed which terms influence each prediction as a dark pattern. In addition, we extracted and analyzed terms that affected the dark patterns. Our findings may prevent users from being manipulated by dark patterns, ",
    "path": "papers/24/01/2401.04119.json",
    "total_tokens": 891,
    "translated_title": "为什么用户界面是一种黑暗模式？：可解释的自动检测及其分析。",
    "translated_abstract": "黑暗模式是在线服务中误导用户行为的欺骗性用户界面设计。隐私侵犯、财务损失和情绪困扰等黑暗模式可能会对用户造成伤害。这些问题近年来一直是广泛讨论的话题。本文研究了可解释的黑暗模式自动检测，即为什么会将特定的用户界面检测为具有黑暗模式。首先，我们使用基于Transformer的预训练语言模型BERT对电子商务中的黑暗模式进行了文本数据集的自动检测模型训练。然后，我们应用了LIME和SHAP等后置解释技术对训练模型进行了解释，揭示了影响每个预测作为黑暗模式的术语。此外，我们还提取和分析了影响黑暗模式的术语。我们的研究结果可以帮助用户免受黑暗模式的操纵。",
    "tldr": "本研究通过使用BERT模型进行自动检测和LIME、SHAP等解释技术进行解释，揭示了黑暗模式中影响预测的关键术语，为用户提供防范黑暗模式的见解。",
    "en_tdlr": "This research utilizes BERT model for automatic detection and LIME, SHAP for explanation, revealing key terms that influence dark pattern predictions, providing insights for users to defend against dark patterns."
}