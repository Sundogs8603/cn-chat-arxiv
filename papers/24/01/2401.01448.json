{
    "title": "ProbMCL: Simple Probabilistic Contrastive Learning for Multi-label Visual Classification. (arXiv:2401.01448v1 [cs.CV])",
    "abstract": "Multi-label image classification presents a challenging task in many domains, including computer vision and medical imaging. Recent advancements have introduced graph-based and transformer-based methods to improve performance and capture label dependencies. However, these methods often include complex modules that entail heavy computation and lack interpretability. In this paper, we propose Probabilistic Multi-label Contrastive Learning (ProbMCL), a novel framework to address these challenges in multi-label image classification tasks. Our simple yet effective approach employs supervised contrastive learning, in which samples that share enough labels with an anchor image based on a decision threshold are introduced as a positive set. This structure captures label dependencies by pulling positive pair embeddings together and pushing away negative samples that fall below the threshold. We enhance representation learning by incorporating a mixture density network into contrastive learning ",
    "link": "http://arxiv.org/abs/2401.01448",
    "context": "Title: ProbMCL: Simple Probabilistic Contrastive Learning for Multi-label Visual Classification. (arXiv:2401.01448v1 [cs.CV])\nAbstract: Multi-label image classification presents a challenging task in many domains, including computer vision and medical imaging. Recent advancements have introduced graph-based and transformer-based methods to improve performance and capture label dependencies. However, these methods often include complex modules that entail heavy computation and lack interpretability. In this paper, we propose Probabilistic Multi-label Contrastive Learning (ProbMCL), a novel framework to address these challenges in multi-label image classification tasks. Our simple yet effective approach employs supervised contrastive learning, in which samples that share enough labels with an anchor image based on a decision threshold are introduced as a positive set. This structure captures label dependencies by pulling positive pair embeddings together and pushing away negative samples that fall below the threshold. We enhance representation learning by incorporating a mixture density network into contrastive learning ",
    "path": "papers/24/01/2401.01448.json",
    "total_tokens": 922,
    "translated_title": "ProbMCL: 简单的概率对比学习用于多标签视觉分类",
    "translated_abstract": "在计算机视觉和医学影像等许多领域中，多标签图像分类是一项具有挑战性的任务。最近的进展引入了基于图和变压器的方法来提高性能并捕捉标签之间的依赖关系。然而，这些方法通常包含复杂的模块，需要大量计算，并且缺乏可解释性。在本文中，我们提出了概率多标签对比学习（ProbMCL），这是一个新颖的框架，用于解决多标签图像分类任务中的这些挑战。我们提出了一个简单而有效的方法，采用了监督对比学习，根据决策阈值将与锚图像具有足够标签的样本引入正样本集。这种结构通过将正样本对的嵌入拉近，并推离低于阈值的负样本来捕捉标签之间的依赖关系。我们通过将混合密度网络融入对比学习中来增强表示学习。",
    "tldr": "ProbMCL是一个简单而有效的概率对比学习框架，用于解决多标签图像分类任务中的挑战。该方法通过采用监督对比学习和混合密度网络，在捕捉标签之间的依赖关系的同时，降低了复杂模块的计算需求和可解释性的不足。",
    "en_tdlr": "ProbMCL is a simple and effective probabilistic contrastive learning framework that addresses challenges in multi-label image classification. It captures label dependencies while reducing the computational complexity and lack of interpretability associated with complex modules by employing supervised contrastive learning and incorporating a mixture density network."
}