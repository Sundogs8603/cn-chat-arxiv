{
    "title": "Neuronal Temporal Filters as Normal Mode Extractors. (arXiv:2401.03248v1 [q-bio.NC])",
    "abstract": "To generate actions in the face of physiological delays, the brain must predict the future. Here we explore how prediction may lie at the core of brain function by considering a neuron predicting the future of a scalar time series input. Assuming that the dynamics of the lag vector (a vector composed of several consecutive elements of the time series) are locally linear, Normal Mode Decomposition decomposes the dynamics into independently evolving (eigen-)modes allowing for straightforward prediction. We propose that a neuron learns the top mode and projects its input onto the associated subspace. Under this interpretation, the temporal filter of a neuron corresponds to the left eigenvector of a generalized eigenvalue problem. We mathematically analyze the operation of such an algorithm on noisy observations of synthetic data generated by a linear system. Interestingly, the shape of the temporal filter varies with the signal-to-noise ratio (SNR): a noisy input yields a monophasic filte",
    "link": "http://arxiv.org/abs/2401.03248",
    "context": "Title: Neuronal Temporal Filters as Normal Mode Extractors. (arXiv:2401.03248v1 [q-bio.NC])\nAbstract: To generate actions in the face of physiological delays, the brain must predict the future. Here we explore how prediction may lie at the core of brain function by considering a neuron predicting the future of a scalar time series input. Assuming that the dynamics of the lag vector (a vector composed of several consecutive elements of the time series) are locally linear, Normal Mode Decomposition decomposes the dynamics into independently evolving (eigen-)modes allowing for straightforward prediction. We propose that a neuron learns the top mode and projects its input onto the associated subspace. Under this interpretation, the temporal filter of a neuron corresponds to the left eigenvector of a generalized eigenvalue problem. We mathematically analyze the operation of such an algorithm on noisy observations of synthetic data generated by a linear system. Interestingly, the shape of the temporal filter varies with the signal-to-noise ratio (SNR): a noisy input yields a monophasic filte",
    "path": "papers/24/01/2401.03248.json",
    "total_tokens": 940,
    "translated_title": "神经元时间滤波器作为正常模态提取器",
    "translated_abstract": "为了在生理延迟情况下产生行为，大脑必须预测未来。在这里，我们通过考虑一个神经元对标量时间序列输入的未来进行预测，探讨了预测可能是大脑功能的核心。假设滞后向量（由时间序列的若干连续元素组成的向量）的动力学是局部线性的，正常模态分解将动力学分解为相互独立演化的（特征）模态，从而实现简单的预测。我们提出，神经元学习顶层模态，并将其输入投影到相关子空间。根据这个解释，神经元的时间滤波器对应于广义特征值问题的左特征向量。我们在由线性系统生成的合成数据的噪声观测上对此算法的操作进行了数学分析。有趣的是，时间滤波器的形状随信噪比（SNR）而变化：嘈杂的输入产生一个单相滤波器。",
    "tldr": "本论文探讨了神经元如何通过预测时间序列的未来来生成行为。通过正常模态分解可以实现简单的预测，其中神经元通过学习顶层模态并将其输入投影到相关子空间。根据信噪比的不同，时间滤波器的形状会有所变化。"
}