{
    "title": "Model Editing Can Hurt General Abilities of Large Language Models. (arXiv:2401.04700v1 [cs.CL])",
    "abstract": "Recent advances in large language models (LLMs) have opened up new paradigms for accessing the knowledge stored in their parameters. One critical challenge that has emerged is the presence of hallucinations in LLM outputs due to false or outdated knowledge. Since retraining LLMs with updated information is resource-intensive, there has been a growing interest in model editing. However, many model editing methods, while effective in various scenarios, tend to overemphasize aspects such as efficacy, generalization, and locality in editing performance, often overlooking potential side effects on the general abilities of LLMs. In this paper, we raise concerns that the improvement of model factuality may come at the cost of a significant degradation of these general abilities, which is not conducive to the sustainable development of LLMs. Systematically, we analyze side effects by evaluating four popular editing methods on two LLMs across eight representative task categories. Extensive empi",
    "link": "http://arxiv.org/abs/2401.04700",
    "context": "Title: Model Editing Can Hurt General Abilities of Large Language Models. (arXiv:2401.04700v1 [cs.CL])\nAbstract: Recent advances in large language models (LLMs) have opened up new paradigms for accessing the knowledge stored in their parameters. One critical challenge that has emerged is the presence of hallucinations in LLM outputs due to false or outdated knowledge. Since retraining LLMs with updated information is resource-intensive, there has been a growing interest in model editing. However, many model editing methods, while effective in various scenarios, tend to overemphasize aspects such as efficacy, generalization, and locality in editing performance, often overlooking potential side effects on the general abilities of LLMs. In this paper, we raise concerns that the improvement of model factuality may come at the cost of a significant degradation of these general abilities, which is not conducive to the sustainable development of LLMs. Systematically, we analyze side effects by evaluating four popular editing methods on two LLMs across eight representative task categories. Extensive empi",
    "path": "papers/24/01/2401.04700.json",
    "total_tokens": 906,
    "translated_title": "模型编辑可能会损害大型语言模型的通用能力",
    "translated_abstract": "大型语言模型（LLM）的最新进展为我们获取其参数中存储的知识提供了新的范式。一个关键的挑战是LLM输出中存在错觉，这是由于错误或过时知识引起的。由于使用更新后的信息重新训练LLM需要大量资源，因此人们对模型编辑产生了越来越多的兴趣。然而，许多模型编辑方法在各种场景中很有效，但往往过于强调编辑性能的功效、泛化性和局部性，常常忽视了对LLM的通用能力可能产生的副作用。本文提出了改善模型的事实性可能会以相当大的通用能力下降为代价的担忧，这不符合LLM可持续发展的要求。我们通过评估四种常用的编辑方法在两个LLM上进行了系统分析副作用，并涵盖了八个代表性任务类别。",
    "tldr": "这项论文指出，模型编辑可能会改善模型的事实性，但会以降低模型的通用能力为代价。在这项研究中，作者通过评估四种编辑方法在两个大型语言模型上的表现，发现这些编辑方法往往忽视了对模型通用能力可能产生的负面影响。",
    "en_tdlr": "This paper highlights that model editing may improve the factual accuracy of large language models, but at the expense of their general abilities. Through evaluating four editing methods on two models, the authors find that these methods often overlook the potential negative effects on the models' general capabilities."
}