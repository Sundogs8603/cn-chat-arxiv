{
    "title": "Towards Efficient Diffusion-Based Image Editing with Instant Attention Masks. (arXiv:2401.07709v2 [cs.CV] UPDATED)",
    "abstract": "Diffusion-based Image Editing (DIE) is an emerging research hot-spot, which often applies a semantic mask to control the target area for diffusion-based editing. However, most existing solutions obtain these masks via manual operations or off-line processing, greatly reducing their efficiency. In this paper, we propose a novel and efficient image editing method for Text-to-Image (T2I) diffusion models, termed Instant Diffusion Editing(InstDiffEdit). In particular, InstDiffEdit aims to employ the cross-modal attention ability of existing diffusion models to achieve instant mask guidance during the diffusion steps. To reduce the noise of attention maps and realize the full automatics, we equip InstDiffEdit with a training-free refinement scheme to adaptively aggregate the attention distributions for the automatic yet accurate mask generation. Meanwhile, to supplement the existing evaluations of DIE, we propose a new benchmark called Editing-Mask to examine the mask accuracy and local edi",
    "link": "http://arxiv.org/abs/2401.07709",
    "context": "Title: Towards Efficient Diffusion-Based Image Editing with Instant Attention Masks. (arXiv:2401.07709v2 [cs.CV] UPDATED)\nAbstract: Diffusion-based Image Editing (DIE) is an emerging research hot-spot, which often applies a semantic mask to control the target area for diffusion-based editing. However, most existing solutions obtain these masks via manual operations or off-line processing, greatly reducing their efficiency. In this paper, we propose a novel and efficient image editing method for Text-to-Image (T2I) diffusion models, termed Instant Diffusion Editing(InstDiffEdit). In particular, InstDiffEdit aims to employ the cross-modal attention ability of existing diffusion models to achieve instant mask guidance during the diffusion steps. To reduce the noise of attention maps and realize the full automatics, we equip InstDiffEdit with a training-free refinement scheme to adaptively aggregate the attention distributions for the automatic yet accurate mask generation. Meanwhile, to supplement the existing evaluations of DIE, we propose a new benchmark called Editing-Mask to examine the mask accuracy and local edi",
    "path": "papers/24/01/2401.07709.json",
    "total_tokens": 946,
    "translated_title": "高效扩散式图像编辑与即时关注蒙版的研究",
    "translated_abstract": "扩散式图像编辑是一个新兴的研究热点，通常通过应用语义蒙版来控制编辑的目标区域。然而，现有的解决方案大多通过手动操作或离线处理来获取这些蒙版，大大降低了其效率。本文提出了一种针对文本到图像扩散模型的图像编辑方法，称为即时扩散编辑(InstDiffEdit)。InstDiffEdit旨在利用现有扩散模型的跨模态注意力能力，在扩散步骤中实现即时蒙版引导。为了减少注意力映射的噪声并实现全自动化，我们为InstDiffEdit配备了一种无需训练的细化方案，以自适应地聚合注意力分布，从而实现准确的蒙版生成。同时，为了补充现有的DIE评估，我们提出了一个名为Editing-Mask的新基准来检验蒙版准确性和局部编辑能力。",
    "tldr": "本文介绍了一种名为即时扩散编辑的图像编辑方法，该方法利用了现有的扩散模型的跨模态注意力能力，实现了即时的蒙版引导。通过采用无需训练的细化方案，该方法可以自适应地生成准确的蒙版，从而提高了扩散式图像编辑的效率。"
}