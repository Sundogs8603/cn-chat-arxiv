{
    "title": "Automated Root Causing of Cloud Incidents using In-Context Learning with GPT-4. (arXiv:2401.13810v1 [cs.CL])",
    "abstract": "Root Cause Analysis (RCA) plays a pivotal role in the incident diagnosis process for cloud services, requiring on-call engineers to identify the primary issues and implement corrective actions to prevent future recurrences. Improving the incident RCA process is vital for minimizing service downtime, customer impact and manual toil. Recent advances in artificial intelligence have introduced state-of-the-art Large Language Models (LLMs) like GPT-4, which have proven effective in tackling various AIOps problems, ranging from code authoring to incident management. Nonetheless, the GPT-4 model's immense size presents challenges when trying to fine-tune it on user data because of the significant GPU resource demand and the necessity for continuous model fine-tuning with the emergence of new data. To address the high cost of fine-tuning LLM, we propose an in-context learning approach for automated root causing, which eliminates the need for fine-tuning. We conduct extensive study over 100,000",
    "link": "http://arxiv.org/abs/2401.13810",
    "context": "Title: Automated Root Causing of Cloud Incidents using In-Context Learning with GPT-4. (arXiv:2401.13810v1 [cs.CL])\nAbstract: Root Cause Analysis (RCA) plays a pivotal role in the incident diagnosis process for cloud services, requiring on-call engineers to identify the primary issues and implement corrective actions to prevent future recurrences. Improving the incident RCA process is vital for minimizing service downtime, customer impact and manual toil. Recent advances in artificial intelligence have introduced state-of-the-art Large Language Models (LLMs) like GPT-4, which have proven effective in tackling various AIOps problems, ranging from code authoring to incident management. Nonetheless, the GPT-4 model's immense size presents challenges when trying to fine-tune it on user data because of the significant GPU resource demand and the necessity for continuous model fine-tuning with the emergence of new data. To address the high cost of fine-tuning LLM, we propose an in-context learning approach for automated root causing, which eliminates the need for fine-tuning. We conduct extensive study over 100,000",
    "path": "papers/24/01/2401.13810.json",
    "total_tokens": 944,
    "translated_title": "使用GPT-4进行上下文学习的自动化云故障溯源(arXiv:2401.13810v1 [cs.CL])",
    "translated_abstract": "根因分析（RCA）在云服务的故障诊断过程中起着至关重要的作用，需要值班工程师识别主要问题并实施纠正措施，以防止将来的复发。改进故障根因分析过程对于减少服务停机时间、客户影响和手动劳动至关重要。最近人工智能的进展引入了先进的大型语言模型（LLM），如GPT-4，在处理从代码撰写到故障管理等各种AIOps问题方面证明非常有效。然而，GPT-4模型巨大的尺寸在尝试在用户数据上进行微调时存在挑战，因为需要大量的GPU资源，并且随着新数据的出现需要持续进行模型微调。为了解决微调LLM的高成本问题，我们提出了一种基于上下文学习的自动故障溯源方法，它消除了对微调的需要。我们对10万个数据进行了广泛的研究。",
    "tldr": "这项研究提出了一种基于上下文学习的自动化云故障溯源方法，使用GPT-4模型，无需进行昂贵的微调操作，可以改进故障根因分析过程，降低服务停机时间、客户影响和手动劳动。"
}