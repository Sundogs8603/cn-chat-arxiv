{
    "title": "Towards Scalable and Robust Model Versioning. (arXiv:2401.09574v1 [cs.LG])",
    "abstract": "As the deployment of deep learning models continues to expand across industries, the threat of malicious incursions aimed at gaining access to these deployed models is on the rise. Should an attacker gain access to a deployed model, whether through server breaches, insider attacks, or model inversion techniques, they can then construct white-box adversarial attacks to manipulate the model's classification outcomes, thereby posing significant risks to organizations that rely on these models for critical tasks. Model owners need mechanisms to protect themselves against such losses without the necessity of acquiring fresh training data - a process that typically demands substantial investments in time and capital.  In this paper, we explore the feasibility of generating multiple versions of a model that possess different attack properties, without acquiring new training data or changing model architecture. The model owner can deploy one version at a time and replace a leaked version immed",
    "link": "http://arxiv.org/abs/2401.09574",
    "context": "Title: Towards Scalable and Robust Model Versioning. (arXiv:2401.09574v1 [cs.LG])\nAbstract: As the deployment of deep learning models continues to expand across industries, the threat of malicious incursions aimed at gaining access to these deployed models is on the rise. Should an attacker gain access to a deployed model, whether through server breaches, insider attacks, or model inversion techniques, they can then construct white-box adversarial attacks to manipulate the model's classification outcomes, thereby posing significant risks to organizations that rely on these models for critical tasks. Model owners need mechanisms to protect themselves against such losses without the necessity of acquiring fresh training data - a process that typically demands substantial investments in time and capital.  In this paper, we explore the feasibility of generating multiple versions of a model that possess different attack properties, without acquiring new training data or changing model architecture. The model owner can deploy one version at a time and replace a leaked version immed",
    "path": "papers/24/01/2401.09574.json",
    "total_tokens": 842,
    "translated_title": "实现可扩展和稳健的模型版本控制",
    "translated_abstract": "随着深度学习模型在各行各业的不断部署，针对这些部署模型进行恶意入侵的威胁也在增加。如果攻击者能够通过服务器入侵、内部攻击或模型反转技术获取部署模型的访问权限，他们可以构造白盒对抗攻击来操纵模型的分类结果，从而给依赖这些模型进行关键任务的组织带来重大风险。模型所有者需要一种机制来保护自己免受这种损失，而不需要获取新的训练数据，这通常需要大量的时间和资本投入。，在本文中，我们探讨了在不获取新的训练数据或更改模型架构的情况下，生成具有不同攻击属性的多个模型版本的可行性。模型所有者可以逐个部署版本并立即替换泄露的版本。",
    "tldr": "本文探讨了在不获取新的训练数据或更改模型架构的情况下，生成具有不同攻击属性的多个模型版本的可行性，以保护模型所有者免受恶意入侵带来的损失。"
}