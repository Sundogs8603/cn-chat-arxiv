{
    "title": "An ADRC-Incorporated Stochastic Gradient Descent Algorithm for Latent Factor Analysis. (arXiv:2401.07012v1 [cs.LG])",
    "abstract": "High-dimensional and incomplete (HDI) matrix contains many complex interactions between numerous nodes. A stochastic gradient descent (SGD)-based latent factor analysis (LFA) model is remarkably effective in extracting valuable information from an HDI matrix. However, such a model commonly encounters the problem of slow convergence because a standard SGD algorithm only considers the current learning error to compute the stochastic gradient without considering the historical and future state of the learning error. To address this critical issue, this paper innovatively proposes an ADRC-incorporated SGD (ADS) algorithm by refining the instance learning error by considering the historical and future state by following the principle of an ADRC controller. With it, an ADS-based LFA model is further achieved for fast and accurate latent factor analysis on an HDI matrix. Empirical studies on two HDI datasets demonstrate that the proposed model outperforms the state-of-the-art LFA models in te",
    "link": "http://arxiv.org/abs/2401.07012",
    "context": "Title: An ADRC-Incorporated Stochastic Gradient Descent Algorithm for Latent Factor Analysis. (arXiv:2401.07012v1 [cs.LG])\nAbstract: High-dimensional and incomplete (HDI) matrix contains many complex interactions between numerous nodes. A stochastic gradient descent (SGD)-based latent factor analysis (LFA) model is remarkably effective in extracting valuable information from an HDI matrix. However, such a model commonly encounters the problem of slow convergence because a standard SGD algorithm only considers the current learning error to compute the stochastic gradient without considering the historical and future state of the learning error. To address this critical issue, this paper innovatively proposes an ADRC-incorporated SGD (ADS) algorithm by refining the instance learning error by considering the historical and future state by following the principle of an ADRC controller. With it, an ADS-based LFA model is further achieved for fast and accurate latent factor analysis on an HDI matrix. Empirical studies on two HDI datasets demonstrate that the proposed model outperforms the state-of-the-art LFA models in te",
    "path": "papers/24/01/2401.07012.json",
    "total_tokens": 957,
    "translated_title": "一种将ADRC融入到随机梯度下降算法中的潜在因子分析方法",
    "translated_abstract": "高维和不完整的矩阵包含着许多复杂的节点间相互作用。基于随机梯度下降（SGD）的潜在因子分析（LFA）模型在从高维不完整的矩阵中提取有价值信息方面非常有效。然而，这样的模型通常会遇到收敛速度慢的问题，因为标准的SGD算法只考虑当前的学习误差来计算随机梯度，而不考虑学习误差的历史和未来状态。为了解决这个关键问题，本文创新性地提出了一种将ADRC融入到SGD算法中的ADS（ADRC-incorporated SGD）算法，通过考虑学习误差的历史和未来状态来改进实例的学习误差，遵循ADRC控制器的原则。基于此，进一步实现了一种基于ADS的LFA模型，用于在高维不完整的矩阵上进行快速准确的潜在因子分析。对两个高维不完整的数据集进行的实证研究表明，所提出的模型在技术性能上优于现有的LFA模型。",
    "tldr": "本文提出了一种将ADRC融入到随机梯度下降算法中的潜在因子分析方法，通过改进学习误差的计算方法，提高了模型的收敛速度和准确性。",
    "en_tdlr": "This paper proposes a method that incorporates ADRC into the stochastic gradient descent algorithm for latent factor analysis, improving the convergence speed and accuracy of the model by refining the computation of learning error."
}