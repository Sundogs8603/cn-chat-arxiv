{
    "title": "FedTabDiff: Federated Learning of Diffusion Probabilistic Models for Synthetic Mixed-Type Tabular Data Generation. (arXiv:2401.06263v1 [cs.LG])",
    "abstract": "Realistic synthetic tabular data generation encounters significant challenges in preserving privacy, especially when dealing with sensitive information in domains like finance and healthcare. In this paper, we introduce \\textit{Federated Tabular Diffusion} (FedTabDiff) for generating high-fidelity mixed-type tabular data without centralized access to the original tabular datasets. Leveraging the strengths of \\textit{Denoising Diffusion Probabilistic Models} (DDPMs), our approach addresses the inherent complexities in tabular data, such as mixed attribute types and implicit relationships. More critically, FedTabDiff realizes a decentralized learning scheme that permits multiple entities to collaboratively train a generative model while respecting data privacy and locality. We extend DDPMs into the federated setting for tabular data generation, which includes a synchronous update scheme and weighted averaging for effective model aggregation. Experimental evaluations on real-world financi",
    "link": "http://arxiv.org/abs/2401.06263",
    "context": "Title: FedTabDiff: Federated Learning of Diffusion Probabilistic Models for Synthetic Mixed-Type Tabular Data Generation. (arXiv:2401.06263v1 [cs.LG])\nAbstract: Realistic synthetic tabular data generation encounters significant challenges in preserving privacy, especially when dealing with sensitive information in domains like finance and healthcare. In this paper, we introduce \\textit{Federated Tabular Diffusion} (FedTabDiff) for generating high-fidelity mixed-type tabular data without centralized access to the original tabular datasets. Leveraging the strengths of \\textit{Denoising Diffusion Probabilistic Models} (DDPMs), our approach addresses the inherent complexities in tabular data, such as mixed attribute types and implicit relationships. More critically, FedTabDiff realizes a decentralized learning scheme that permits multiple entities to collaboratively train a generative model while respecting data privacy and locality. We extend DDPMs into the federated setting for tabular data generation, which includes a synchronous update scheme and weighted averaging for effective model aggregation. Experimental evaluations on real-world financi",
    "path": "papers/24/01/2401.06263.json",
    "total_tokens": 1016,
    "translated_title": "FedTabDiff: 用于合成混合类型表格数据生成的扩散概率模型的联邦学习",
    "translated_abstract": "在处理包含敏感信息的领域（如金融和医疗）的真实合成表格数据生成时，要保护隐私面临重大挑战。本文介绍了一种名为\"FedTabDiff\"的方法，用于生成高保真度的混合类型表格数据，而无需集中访问原始表格数据集。我们的方法利用了\"去噪扩散概率模型\"（DDPMs）的优势，解决了表格数据中的混合属性类型和隐含关系等固有复杂性。更重要的是，FedTabDiff实现了一种分散学习方案，允许多个实体在尊重数据隐私和本地性的同时共同训练生成模型。我们将DDPMs扩展到联邦学习环境中的表格数据生成，包括同步更新方案和加权平均以实现有效的模型聚合。在真实的金融数据集上进行了实验评估。",
    "tldr": "本文介绍了一种名为\"FedTabDiff\"的联邦学习方法，用于生成高保真度的混合类型表格数据，而无需集中访问原始表格数据集。该方法利用了\"去噪扩散概率模型\"（DDPMs）的优势，解决了表格数据中的混合属性类型和隐含关系等固有复杂性，并实现了分散学习方案来保护数据隐私和本地性。在真实的金融数据集上进行了实验评估。",
    "en_tdlr": "This paper introduces a federated learning method called FedTabDiff for generating high-fidelity mixed-type tabular data without centralized access to the original datasets. It leverages denoising diffusion probabilistic models (DDPMs) to address the complexities of mixed attribute types and implicit relationships in tabular data, while respecting data privacy and locality through a decentralized learning scheme. Experimental evaluations have been conducted on real-world financial datasets."
}