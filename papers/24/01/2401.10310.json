{
    "title": "Mathematical Algorithm Design for Deep Learning under Societal and Judicial Constraints: The Algorithmic Transparency Requirement. (arXiv:2401.10310v1 [cs.LG])",
    "abstract": "Deep learning still has drawbacks in terms of trustworthiness, which describes a comprehensible, fair, safe, and reliable method. To mitigate the potential risk of AI, clear obligations associated to trustworthiness have been proposed via regulatory guidelines, e.g., in the European AI Act. Therefore, a central question is to what extent trustworthy deep learning can be realized. Establishing the described properties constituting trustworthiness requires that the factors influencing an algorithmic computation can be retraced, i.e., the algorithmic implementation is transparent. Motivated by the observation that the current evolution of deep learning models necessitates a change in computing technology, we derive a mathematical framework which enables us to analyze whether a transparent implementation in a computing model is feasible. We exemplarily apply our trustworthiness framework to analyze deep learning approaches for inverse problems in digital and analog computing models represe",
    "link": "http://arxiv.org/abs/2401.10310",
    "context": "Title: Mathematical Algorithm Design for Deep Learning under Societal and Judicial Constraints: The Algorithmic Transparency Requirement. (arXiv:2401.10310v1 [cs.LG])\nAbstract: Deep learning still has drawbacks in terms of trustworthiness, which describes a comprehensible, fair, safe, and reliable method. To mitigate the potential risk of AI, clear obligations associated to trustworthiness have been proposed via regulatory guidelines, e.g., in the European AI Act. Therefore, a central question is to what extent trustworthy deep learning can be realized. Establishing the described properties constituting trustworthiness requires that the factors influencing an algorithmic computation can be retraced, i.e., the algorithmic implementation is transparent. Motivated by the observation that the current evolution of deep learning models necessitates a change in computing technology, we derive a mathematical framework which enables us to analyze whether a transparent implementation in a computing model is feasible. We exemplarily apply our trustworthiness framework to analyze deep learning approaches for inverse problems in digital and analog computing models represe",
    "path": "papers/24/01/2401.10310.json",
    "total_tokens": 875,
    "translated_title": "在社会和司法约束下对深度学习进行数学算法设计: 算法透明性要求",
    "translated_abstract": "深度学习在可信度方面仍然存在缺陷，这描述了一种可理解、公平、安全和可靠的方法。为了减轻人工智能的潜在风险，通过监管指南提出了与可信度相关的明确义务，例如,在欧洲AI法案中。因此，一个核心问题是可以实现多大程度上的可信度深度学习。建立构成可信度的描述性属性要求能够追溯影响算法计算的因素，即算法的实现是透明的。受当前深度学习模型演化需要改变计算技术的观察启发，我们得出一个数学框架，使我们能够分析在计算模型中是否有可能实现透明实施。我们应用我们的可信度框架来分析数字和模拟计算模型中逆问题的深度学习方法。",
    "tldr": "这篇论文探讨了在社会和司法约束下，对深度学习进行数学算法设计的挑战。研究者提出了算法透明性的要求，并使用数学框架来分析在计算模型中实现透明实施的可行性。",
    "en_tdlr": "This paper discusses the challenges of designing mathematical algorithms for deep learning under societal and judicial constraints. The researchers propose the requirement of algorithmic transparency and use a mathematical framework to analyze the feasibility of transparent implementation in computing models."
}