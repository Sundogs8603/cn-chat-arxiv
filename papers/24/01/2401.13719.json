{
    "title": "Inference Attacks Against Face Recognition Model without Classification Layers. (arXiv:2401.13719v1 [cs.CV])",
    "abstract": "Face recognition (FR) has been applied to nearly every aspect of daily life, but it is always accompanied by the underlying risk of leaking private information. At present, almost all attack models against FR rely heavily on the presence of a classification layer. However, in practice, the FR model can obtain complex features of the input via the model backbone, and then compare it with the target for inference, which does not explicitly involve the outputs of the classification layer adopting logit or other losses. In this work, we advocate a novel inference attack composed of two stages for practical FR models without a classification layer. The first stage is the membership inference attack. Specifically, We analyze the distances between the intermediate features and batch normalization (BN) parameters. The results indicate that this distance is a critical metric for membership inference. We thus design a simple but effective attack model that can determine whether a face image is f",
    "link": "http://arxiv.org/abs/2401.13719",
    "context": "Title: Inference Attacks Against Face Recognition Model without Classification Layers. (arXiv:2401.13719v1 [cs.CV])\nAbstract: Face recognition (FR) has been applied to nearly every aspect of daily life, but it is always accompanied by the underlying risk of leaking private information. At present, almost all attack models against FR rely heavily on the presence of a classification layer. However, in practice, the FR model can obtain complex features of the input via the model backbone, and then compare it with the target for inference, which does not explicitly involve the outputs of the classification layer adopting logit or other losses. In this work, we advocate a novel inference attack composed of two stages for practical FR models without a classification layer. The first stage is the membership inference attack. Specifically, We analyze the distances between the intermediate features and batch normalization (BN) parameters. The results indicate that this distance is a critical metric for membership inference. We thus design a simple but effective attack model that can determine whether a face image is f",
    "path": "papers/24/01/2401.13719.json",
    "total_tokens": 905,
    "translated_title": "不需要分类层的人脸识别模型的推理攻击",
    "translated_abstract": "人脸识别(FR)已经应用于日常生活的几乎所有方面，但它始终伴随着泄漏私人信息的潜在风险。目前，几乎所有对FR的攻击模型都严重依赖于分类层的存在。然而，在实践中，FR模型可以通过模型骨干获得输入的复杂特征，然后与目标进行推理比较，这与明确采用对数或其他损失的分类层的输出无关。在这项工作中，我们提出了一种针对没有分类层的实际FR模型的新型推理攻击，由两个阶段组成。第一阶段是成员推理攻击。具体而言，我们分析了中间特征和批归一化(BN)参数之间的距离。结果表明，这个距离是成员推理的关键指标。因此，我们设计了一个简单但有效的攻击模型，可以确定一个人脸图像是否属于模型的成员。",
    "tldr": "提出了一种针对没有分类层的实际人脸识别模型的新型推理攻击，通过分析中间特征与批归一化参数之间的距离，设计了一个简单但有效的攻击模型，可以确定一个人脸图像是否属于模型的成员。",
    "en_tdlr": "A novel inference attack is proposed against practical face recognition models without a classification layer. By analyzing the distances between intermediate features and batch normalization parameters, a simple yet effective attack model is designed to determine whether a face image belongs to the model's membership."
}