{
    "title": "Asymptotic Behavior of Adversarial Training Estimator under $\\ell_\\infty$-Perturbation. (arXiv:2401.15262v1 [math.ST])",
    "abstract": "Adversarial training has been proposed to hedge against adversarial attacks in machine learning and statistical models. This paper focuses on adversarial training under $\\ell_\\infty$-perturbation, which has recently attracted much research attention. The asymptotic behavior of the adversarial training estimator is investigated in the generalized linear model. The results imply that the limiting distribution of the adversarial training estimator under $\\ell_\\infty$-perturbation could put a positive probability mass at $0$ when the true parameter is $0$, providing a theoretical guarantee of the associated sparsity-recovery ability. Alternatively, a two-step procedure is proposed -adaptive adversarial training, which could further improve the performance of adversarial training under $\\ell_\\infty$-perturbation. Specifically, the proposed procedure could achieve asymptotic unbiasedness and variable-selection consistency. Numerical experiments are conducted to show the sparsity-recovery a",
    "link": "http://arxiv.org/abs/2401.15262",
    "context": "Title: Asymptotic Behavior of Adversarial Training Estimator under $\\ell_\\infty$-Perturbation. (arXiv:2401.15262v1 [math.ST])\nAbstract: Adversarial training has been proposed to hedge against adversarial attacks in machine learning and statistical models. This paper focuses on adversarial training under $\\ell_\\infty$-perturbation, which has recently attracted much research attention. The asymptotic behavior of the adversarial training estimator is investigated in the generalized linear model. The results imply that the limiting distribution of the adversarial training estimator under $\\ell_\\infty$-perturbation could put a positive probability mass at $0$ when the true parameter is $0$, providing a theoretical guarantee of the associated sparsity-recovery ability. Alternatively, a two-step procedure is proposed -adaptive adversarial training, which could further improve the performance of adversarial training under $\\ell_\\infty$-perturbation. Specifically, the proposed procedure could achieve asymptotic unbiasedness and variable-selection consistency. Numerical experiments are conducted to show the sparsity-recovery a",
    "path": "papers/24/01/2401.15262.json",
    "total_tokens": 976,
    "translated_title": "在$\\ell_\\infty$-扰动下对抗性训练估计器的渐近行为",
    "translated_abstract": "对抗性训练被提出来抵御机器学习和统计模型中的对抗性攻击。本文重点研究了在$\\ell_\\infty$-扰动下的对抗性训练，这个问题最近引起了很多研究的关注。在广义线性模型中研究了对抗性训练估计器的渐近行为。结果表明，当真实参数为0时，对抗性训练估计器在$\\ell_\\infty$-扰动下的极限分布可能在0处有一个正概率质量，为相关的稀疏性恢复能力提供了理论保证。此外，提出了一种两步过程——自适应对抗性训练，可以进一步提高在$\\ell_\\infty$-扰动下的对抗性训练的性能。具体而言，所提出的过程可以实现渐近无偏性和变量选择一致性。通过数值实验展示了稀疏性恢复的能力。",
    "tldr": "本文研究了在$\\ell_\\infty$-扰动下的对抗性训练，证明当真实参数为0时，对抗性训练估计器在该扰动下的极限分布可能在0处有一个正概率质量，提供了稀疏性恢复能力的理论保证，并提出了一种两步过程——自适应对抗性训练，可以进一步提高性能。",
    "en_tdlr": "This paper investigates the asymptotic behavior of the adversarial training estimator under $\\ell_\\infty$-perturbation and provides theoretical guarantees for the sparsity-recovery ability. A two-step procedure, adaptive adversarial training, is proposed to improve the performance further."
}