{
    "title": "Optimal Differentially Private PCA and Estimation for Spiked Covariance Matrices. (arXiv:2401.03820v1 [math.ST])",
    "abstract": "Estimating a covariance matrix and its associated principal components is a fundamental problem in contemporary statistics. While optimal estimation procedures have been developed with well-understood properties, the increasing demand for privacy preservation introduces new complexities to this classical problem. In this paper, we study optimal differentially private Principal Component Analysis (PCA) and covariance estimation within the spiked covariance model.  We precisely characterize the sensitivity of eigenvalues and eigenvectors under this model and establish the minimax rates of convergence for estimating both the principal components and covariance matrix. These rates hold up to logarithmic factors and encompass general Schatten norms, including spectral norm, Frobenius norm, and nuclear norm as special cases.  We introduce computationally efficient differentially private estimators and prove their minimax optimality, up to logarithmic factors. Additionally, matching minimax l",
    "link": "http://arxiv.org/abs/2401.03820",
    "context": "Title: Optimal Differentially Private PCA and Estimation for Spiked Covariance Matrices. (arXiv:2401.03820v1 [math.ST])\nAbstract: Estimating a covariance matrix and its associated principal components is a fundamental problem in contemporary statistics. While optimal estimation procedures have been developed with well-understood properties, the increasing demand for privacy preservation introduces new complexities to this classical problem. In this paper, we study optimal differentially private Principal Component Analysis (PCA) and covariance estimation within the spiked covariance model.  We precisely characterize the sensitivity of eigenvalues and eigenvectors under this model and establish the minimax rates of convergence for estimating both the principal components and covariance matrix. These rates hold up to logarithmic factors and encompass general Schatten norms, including spectral norm, Frobenius norm, and nuclear norm as special cases.  We introduce computationally efficient differentially private estimators and prove their minimax optimality, up to logarithmic factors. Additionally, matching minimax l",
    "path": "papers/24/01/2401.03820.json",
    "total_tokens": 885,
    "translated_title": "在带有尖峰协方差矩阵中的最优差分隐私主成分分析和估计",
    "translated_abstract": "在当代统计学中，估计协方差矩阵及其相关的主成分是一个基本问题。尽管已开发出具有良好性质的最优估计程序，但对隐私保护的增加需求给这个经典问题引入了新的复杂性。本文研究了在尖峰协方差模型中的最优差分隐私主成分分析（PCA）和协方差估计。我们精确地刻画了在该模型下特征值和特征向量的敏感性，并建立了估计主成分和协方差矩阵的最小最大收敛率。这些收敛率包括一般的Schatten范数，包括谱范数，Frobenius范数和核范数。我们引入了计算高效的差分隐私估计器，并证明它们的最小最大性，直到对数因子。另外，匹配的minimax最小最大率也得到了证明。",
    "tldr": "本文研究了在尖峰协方差模型中的最优差分隐私主成分分析和协方差估计问题，并提出了高效的差分隐私估计器，并证明了它们的最小最大性。",
    "en_tdlr": "This paper investigates optimal differentially private Principal Component Analysis (PCA) and covariance estimation in spiked covariance model. It introduces computationally efficient differentially private estimators and proves their minimax optimality."
}