{
    "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent",
    "abstract": "Large Language Model (LLM) agents significantly extend the capabilities of standalone LLMs, empowering them to interact with external tools (e.g., APIs, functions) and complete complex tasks in a self-directed fashion. The challenge of tool use demands that LLMs not only understand user queries and generate answers but also excel in task planning, memory management, tool invocation, and result summarization. While traditional approaches focus on training a single LLM with all these capabilities, performance limitations become apparent, particularly with smaller models. Moreover, the entire LLM may require retraining when tools are updated. To overcome these challenges, we propose a novel strategy that decomposes the aforementioned capabilities into a planner, caller, and summarizer. Each component is implemented by a single LLM that focuses on a specific capability and collaborates with other components to accomplish the task. This modular framework facilitates individual updates and t",
    "link": "https://arxiv.org/abs/2401.07324",
    "context": "Title: Small LLMs Are Weak Tool Learners: A Multi-LLM Agent\nAbstract: Large Language Model (LLM) agents significantly extend the capabilities of standalone LLMs, empowering them to interact with external tools (e.g., APIs, functions) and complete complex tasks in a self-directed fashion. The challenge of tool use demands that LLMs not only understand user queries and generate answers but also excel in task planning, memory management, tool invocation, and result summarization. While traditional approaches focus on training a single LLM with all these capabilities, performance limitations become apparent, particularly with smaller models. Moreover, the entire LLM may require retraining when tools are updated. To overcome these challenges, we propose a novel strategy that decomposes the aforementioned capabilities into a planner, caller, and summarizer. Each component is implemented by a single LLM that focuses on a specific capability and collaborates with other components to accomplish the task. This modular framework facilitates individual updates and t",
    "path": "papers/24/01/2401.07324.json",
    "total_tokens": 838,
    "translated_title": "小型LLMs是弱工具学习者：多LLM代理",
    "translated_abstract": "大型语言模型（LLM）代理大大扩展了独立LLMs的能力，使它们能够与外部工具（例如API，函数）进行交互，并自主完成复杂任务。工具使用的挑战要求LLMs不仅能理解用户查询并生成答案，还要在任务规划、记忆管理、工具调用和结果总结方面表现出色。传统方法集中于训练单个具备所有这些功能的LLM，但在小型模型上会出现性能限制的问题，此外，当工具更新时，整个LLM可能需要重新训练。为了克服这些挑战，我们提出了一种新的策略，将上述能力分解为计划器、调用器和总结器。每个组件由一个单独的LLM实现，专注于特定的能力，并与其他组件合作完成任务。这种模块化框架便于进行个体更新和...",
    "tldr": "本论文提出了一种新的策略，将大型语言模型代理（LLMs）的能力分解为计划器、调用器和总结器模块，以克服小型模型性能限制和工具更新的问题。",
    "en_tdlr": "This paper proposes a novel strategy to decompose the capabilities of Large Language Model (LLM) agents into planner, caller, and summarizer modules, overcoming performance limitations of small models and the need for retraining when tools are updated."
}