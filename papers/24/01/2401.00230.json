{
    "title": "Transformer Multivariate Forecasting: Less is More?",
    "abstract": "arXiv:2401.00230v2 Announce Type: replace-cross  Abstract: In the domain of multivariate forecasting, transformer models stand out as powerful apparatus, displaying exceptional capabilities in handling messy datasets from real-world contexts. However, the inherent complexity of these datasets, characterized by numerous variables and lengthy temporal sequences, poses challenges, including increased noise and extended model runtime. This paper focuses on reducing redundant information to elevate forecasting accuracy while optimizing runtime efficiency. We propose a novel transformer forecasting framework enhanced by Principal Component Analysis (PCA) to tackle this challenge. The framework is evaluated by five state-of-the-art (SOTA) models and four diverse real-world datasets. Our experimental results demonstrate the framework's ability to minimize prediction errors across all models and datasets while significantly reducing runtime. From the model perspective, one of the PCA-enhanced m",
    "link": "https://arxiv.org/abs/2401.00230",
    "context": "Title: Transformer Multivariate Forecasting: Less is More?\nAbstract: arXiv:2401.00230v2 Announce Type: replace-cross  Abstract: In the domain of multivariate forecasting, transformer models stand out as powerful apparatus, displaying exceptional capabilities in handling messy datasets from real-world contexts. However, the inherent complexity of these datasets, characterized by numerous variables and lengthy temporal sequences, poses challenges, including increased noise and extended model runtime. This paper focuses on reducing redundant information to elevate forecasting accuracy while optimizing runtime efficiency. We propose a novel transformer forecasting framework enhanced by Principal Component Analysis (PCA) to tackle this challenge. The framework is evaluated by five state-of-the-art (SOTA) models and four diverse real-world datasets. Our experimental results demonstrate the framework's ability to minimize prediction errors across all models and datasets while significantly reducing runtime. From the model perspective, one of the PCA-enhanced m",
    "path": "papers/24/01/2401.00230.json",
    "total_tokens": 774,
    "translated_title": "Transformer多元预测：少即是多？",
    "translated_abstract": "在多元预测领域，Transformer模型作为强大的工具脱颖而出，展现出在处理来自真实场景中杂乱数据集方面的异常能力。然而，这些数据集的固有复杂性，以众多变量和漫长时间序列为特征，带来挑战，包括增加的噪音和延长的模型运行时间。本文旨在通过减少冗余信息来提高预测精度，同时优化运行时间效率。我们提出了一种新颖的Transformer预测框架，通过主成分分析（PCA）来解决这一挑战。该框架通过五种最先进的模型和四个不同的真实数据集进行评估。我们的实验结果表明，该框架能够在所有模型和数据集上减少预测误差的能力，同时显著降低运行时间。",
    "tldr": "本文致力于通过引入主成分分析（PCA）来优化Transformer预测框架，以减少冗余信息并提高预测准确性和运行效率。",
    "en_tdlr": "This paper focuses on optimizing the Transformer forecasting framework by introducing Principal Component Analysis (PCA) to reduce redundant information and enhance forecasting accuracy and runtime efficiency."
}