{
    "title": "A Fast, Performant, Secure Distributed Training Framework For Large Language Model. (arXiv:2401.09796v1 [cs.LG])",
    "abstract": "The distributed (federated) LLM is an important method for co-training the domain-specific LLM using siloed data. However, maliciously stealing model parameters and data from the server or client side has become an urgent problem to be solved. In this paper, we propose a secure distributed LLM based on model slicing. In this case, we deploy the Trusted Execution Environment (TEE) on both the client and server side, and put the fine-tuned structure (LoRA or embedding of P-tuning v2) into the TEE. Then, secure communication is executed in the TEE and general environments through lightweight encryption. In order to further reduce the equipment cost as well as increase the model performance and accuracy, we propose a split fine-tuning scheme. In particular, we split the LLM by layers and place the latter layers in a server-side TEE (the client does not need a TEE). We then combine the proposed Sparsification Parameter Fine-tuning (SPF) with the LoRA part to improve the accuracy of the down",
    "link": "http://arxiv.org/abs/2401.09796",
    "context": "Title: A Fast, Performant, Secure Distributed Training Framework For Large Language Model. (arXiv:2401.09796v1 [cs.LG])\nAbstract: The distributed (federated) LLM is an important method for co-training the domain-specific LLM using siloed data. However, maliciously stealing model parameters and data from the server or client side has become an urgent problem to be solved. In this paper, we propose a secure distributed LLM based on model slicing. In this case, we deploy the Trusted Execution Environment (TEE) on both the client and server side, and put the fine-tuned structure (LoRA or embedding of P-tuning v2) into the TEE. Then, secure communication is executed in the TEE and general environments through lightweight encryption. In order to further reduce the equipment cost as well as increase the model performance and accuracy, we propose a split fine-tuning scheme. In particular, we split the LLM by layers and place the latter layers in a server-side TEE (the client does not need a TEE). We then combine the proposed Sparsification Parameter Fine-tuning (SPF) with the LoRA part to improve the accuracy of the down",
    "path": "papers/24/01/2401.09796.json",
    "total_tokens": 1034,
    "translated_title": "一种快速、高性能、安全的分布式训练框架用于大型语言模型",
    "translated_abstract": "分布式（联邦式）LLM是一种重要的方法，用于使用隔离数据共同训练领域特定的LLM。然而，恶意地从服务器或客户端窃取模型参数和数据已经成为一个迫切需要解决的问题。在本文中，我们提出了一种基于模型切片的安全分布式LLM。在这种情况下，我们在客户端和服务器端都部署了可信执行环境（TEE），并将微调的结构（LoRA或P-tuning v2的嵌入）放入TEE中。然后，通过轻量级加密，在TEE和通用环境中进行安全通信。为了进一步降低设备成本并提高模型性能和准确性，我们提出了一种分割微调方案。特别是，我们通过层次进行LLM的分割，将后面的层次放在服务器端TEE中（客户端不需要TEE）。然后，我们将提出的稀疏化参数微调（SPF）与LoRA部分相结合，以提高推断的准确性。",
    "tldr": "本文提出了一种基于模型切片的安全分布式语言模型训练框架。通过在客户端和服务器端部署可信执行环境（TEE）并使用轻量级加密进行安全通信，解决了恶意窃取模型参数和数据的问题。此外，采用分割微调和稀疏化参数微调的方法，在降低设备成本的同时提高了模型性能和准确性。",
    "en_tdlr": "This paper proposes a secure distributed training framework for large language models based on model slicing. By deploying Trusted Execution Environment (TEE) on both client and server side and using lightweight encryption for secure communication, the problem of maliciously stealing model parameters and data is addressed. Additionally, a split fine-tuning scheme and sparsification parameter fine-tuning are introduced to reduce equipment cost and improve model performance and accuracy."
}