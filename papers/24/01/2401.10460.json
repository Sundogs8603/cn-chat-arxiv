{
    "title": "Ultra-lightweight Neural Differential DSP Vocoder For High Quality Speech Synthesis. (arXiv:2401.10460v1 [cs.SD])",
    "abstract": "Neural vocoders model the raw audio waveform and synthesize high-quality audio, but even the highly efficient ones, like MB-MelGAN and LPCNet, fail to run real-time on a low-end device like a smartglass. A pure digital signal processing (DSP) based vocoder can be implemented via lightweight fast Fourier transforms (FFT), and therefore, is a magnitude faster than any neural vocoder. A DSP vocoder often gets a lower audio quality due to consuming over-smoothed acoustic model predictions of approximate representations for the vocal tract. In this paper, we propose an ultra-lightweight differential DSP (DDSP) vocoder that uses a jointly optimized acoustic model with a DSP vocoder, and learns without an extracted spectral feature for the vocal tract. The model achieves audio quality comparable to neural vocoders with a high average MOS of 4.36 while being efficient as a DSP vocoder. Our C++ implementation, without any hardware-specific optimization, is at 15 MFLOPS, surpasses MB-MelGAN by 3",
    "link": "http://arxiv.org/abs/2401.10460",
    "context": "Title: Ultra-lightweight Neural Differential DSP Vocoder For High Quality Speech Synthesis. (arXiv:2401.10460v1 [cs.SD])\nAbstract: Neural vocoders model the raw audio waveform and synthesize high-quality audio, but even the highly efficient ones, like MB-MelGAN and LPCNet, fail to run real-time on a low-end device like a smartglass. A pure digital signal processing (DSP) based vocoder can be implemented via lightweight fast Fourier transforms (FFT), and therefore, is a magnitude faster than any neural vocoder. A DSP vocoder often gets a lower audio quality due to consuming over-smoothed acoustic model predictions of approximate representations for the vocal tract. In this paper, we propose an ultra-lightweight differential DSP (DDSP) vocoder that uses a jointly optimized acoustic model with a DSP vocoder, and learns without an extracted spectral feature for the vocal tract. The model achieves audio quality comparable to neural vocoders with a high average MOS of 4.36 while being efficient as a DSP vocoder. Our C++ implementation, without any hardware-specific optimization, is at 15 MFLOPS, surpasses MB-MelGAN by 3",
    "path": "papers/24/01/2401.10460.json",
    "total_tokens": 974,
    "translated_title": "高质量语音合成的超轻型神经差分DSP声码器",
    "translated_abstract": "神经声码器模拟原始音频波形并合成高质量音频，但即使是高效率的声码器，如MB-MelGAN和LPCNet，也无法在低端设备（如智能眼镜）上实时运行。基于纯数字信号处理（DSP）的声码器可以通过轻量级的快速傅里叶变换（FFT）来实现，因此比任何神经声码器都快得多。DSP声码器通常由于使用过度平滑的声学模型预测和音道的近似表示而导致音频质量较低。在本文中，我们提出了一种超轻差分DSP声码器（DDSP声码器），它使用了经过联合优化的声学模型和DSP声码器，并且在不需要提取声道频谱特征的情况下进行训练。该模型在作为DSP声码器的同时，实现了与神经声码器相当的音频质量，平均MOS高达4.36。我们的C++实现，在没有任何硬件特定的优化情况下，达到了15 MFLOPS，超过MB-MelGAN 3个性能单位。",
    "tldr": "本文提出了一种超轻型差分DSP声码器，通过联合优化的声学模型和DSP声码器实现高质量的语音合成，而无需提取声道频谱特征。该模型在音频质量上接近神经声码器，且性能高效。",
    "en_tdlr": "This paper proposes an ultra-lightweight differential DSP vocoder that achieves high-quality speech synthesis by jointly optimizing an acoustic model with a DSP vocoder, without the need for extracted spectral features. The model achieves audio quality comparable to neural vocoders while being efficient in performance."
}