{
    "title": "Hierarchical Bias-Driven Stratification for Interpretable Causal Effect Estimation",
    "abstract": "Interpretability and transparency are essential for incorporating causal effect models from observational data into policy decision-making. They can provide trust for the model in the absence of ground truth labels to evaluate the accuracy of such models. To date, attempts at transparent causal effect estimation consist of applying post hoc explanation methods to black-box models, which are not interpretable. Here, we present BICauseTree: an interpretable balancing method that identifies clusters where natural experiments occur locally. Our approach builds on decision trees with a customized objective function to improve balancing and reduce treatment allocation bias. Consequently, it can additionally detect subgroups presenting positivity violations, exclude them, and provide a covariate-based definition of the target population we can infer from and generalize to. We evaluate the method's performance using synthetic and realistic datasets, explore its bias-interpretability tradeoff, ",
    "link": "https://arxiv.org/abs/2401.17737",
    "context": "Title: Hierarchical Bias-Driven Stratification for Interpretable Causal Effect Estimation\nAbstract: Interpretability and transparency are essential for incorporating causal effect models from observational data into policy decision-making. They can provide trust for the model in the absence of ground truth labels to evaluate the accuracy of such models. To date, attempts at transparent causal effect estimation consist of applying post hoc explanation methods to black-box models, which are not interpretable. Here, we present BICauseTree: an interpretable balancing method that identifies clusters where natural experiments occur locally. Our approach builds on decision trees with a customized objective function to improve balancing and reduce treatment allocation bias. Consequently, it can additionally detect subgroups presenting positivity violations, exclude them, and provide a covariate-based definition of the target population we can infer from and generalize to. We evaluate the method's performance using synthetic and realistic datasets, explore its bias-interpretability tradeoff, ",
    "path": "papers/24/01/2401.17737.json",
    "total_tokens": 856,
    "translated_title": "基于层级偏差驱动分层的可解释因果效应估计",
    "translated_abstract": "可解释性和透明性对于将观察数据中的因果效应模型纳入政策决策至关重要。它们可以在缺乏真实标签来评估这些模型准确性的情况下提供对模型的信任。到目前为止，透明的因果效应估计尝试包括将事后解释方法应用于不可解释的黑盒模型。在这里，我们提出了BICauseTree：一种可解释的平衡方法，用于识别局部发生自然实验的聚类。我们的方法基于带有自定义目标函数的决策树，以改进平衡和减少处理分配偏差。因此，它还可以检测出存在正性违规的子群体，排除它们，并提供基于协变量的目标人群定义，我们可以从中推断并推广。我们使用合成和真实数据集评估该方法的性能，并探索其偏差可解释性的权衡。",
    "tldr": "BICauseTree是一种基于层级偏差驱动分层的可解释因果效应估计方法，通过使用决策树进行平衡、减少偏差和确定目标人群定义，提供了可解释性和透明性。"
}