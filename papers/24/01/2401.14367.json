{
    "title": "Genie: Achieving Human Parity in Content-Grounded Datasets Generation. (arXiv:2401.14367v1 [cs.CL])",
    "abstract": "The lack of high-quality data for content-grounded generation tasks has been identified as a major obstacle to advancing these tasks. To address this gap, we propose Genie, a novel method for automatically generating high-quality content-grounded data. It consists of three stages: (a) Content Preparation, (b) Generation: creating task-specific examples from the content (e.g., question-answer pairs or summaries). (c) Filtering mechanism aiming to ensure the quality and faithfulness of the generated data. We showcase this methodology by generating three large-scale synthetic data, making wishes, for Long-Form Question-Answering (LFQA), summarization, and information extraction. In a human evaluation, our generated data was found to be natural and of high quality. Furthermore, we compare models trained on our data with models trained on human-written data -- ELI5 and ASQA for LFQA and CNN-DailyMail for Summarization. We show that our models are on par with or outperforming models trained ",
    "link": "http://arxiv.org/abs/2401.14367",
    "context": "Title: Genie: Achieving Human Parity in Content-Grounded Datasets Generation. (arXiv:2401.14367v1 [cs.CL])\nAbstract: The lack of high-quality data for content-grounded generation tasks has been identified as a major obstacle to advancing these tasks. To address this gap, we propose Genie, a novel method for automatically generating high-quality content-grounded data. It consists of three stages: (a) Content Preparation, (b) Generation: creating task-specific examples from the content (e.g., question-answer pairs or summaries). (c) Filtering mechanism aiming to ensure the quality and faithfulness of the generated data. We showcase this methodology by generating three large-scale synthetic data, making wishes, for Long-Form Question-Answering (LFQA), summarization, and information extraction. In a human evaluation, our generated data was found to be natural and of high quality. Furthermore, we compare models trained on our data with models trained on human-written data -- ELI5 and ASQA for LFQA and CNN-DailyMail for Summarization. We show that our models are on par with or outperforming models trained ",
    "path": "papers/24/01/2401.14367.json",
    "total_tokens": 944,
    "translated_title": "Genie：实现内容导向数据集生成的人类水平",
    "translated_abstract": "对于内容导向生成任务，缺乏高质量的数据被认为是推动这些任务发展的主要障碍。为了解决这个问题，我们提出了Genie，一种用于自动生成高质量内容导向数据的新方法。它包括三个阶段：（a）内容准备，（b）生成：从内容中创建特定任务的示例（例如问题-答案对或摘要），（c）过滤机制，旨在确保生成数据的质量和可信度。我们通过生成三个大规模的合成数据来展示这种方法：长型问题回答（LFQA）、摘要和信息提取。在人类评估中，我们生成的数据被发现是自然且高质量的。此外，我们将使用我们的数据训练的模型与使用人工编写的数据训练的模型进行比较 - 对于LFQA，我们与ELI5和ASQA进行比较，对于摘要，我们与CNN-DailyMail进行比较。我们表明，我们的模型与或超过使用人工数据训练的模型。",
    "tldr": "Genie是一个用于自动生成高质量内容导向数据的方法，通过三个阶段实现：内容准备、生成和过滤。在人类评估中，生成的数据被发现是自然且高质量的，并且通过与使用人工数据训练的模型比较，我们的模型表现相当或更好。",
    "en_tdlr": "Genie is a method for automatically generating high-quality content-grounded data, consisting of three stages: content preparation, generation, and filtering. The generated data was found to be natural and of high quality in human evaluations, and our models perform on par with or outperform models trained on human-written data."
}