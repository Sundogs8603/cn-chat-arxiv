{
    "title": "MedLM: Exploring Language Models for Medical Question Answering Systems",
    "abstract": "arXiv:2401.11389v2 Announce Type: replace-cross  Abstract: In the face of rapidly expanding online medical literature, automated systems for aggregating and summarizing information are becoming increasingly crucial for healthcare professionals and patients. Large Language Models (LLMs), with their advanced generative capabilities, have shown promise in various NLP tasks, and their potential in the healthcare domain, particularly for Closed-Book Generative QnA, is significant. However, the performance of these models in domain-specific tasks such as medical Q&A remains largely unexplored. This study aims to fill this gap by comparing the performance of general and medical-specific distilled LMs for medical Q&A. We aim to evaluate the effectiveness of fine-tuning domain-specific LMs and compare the performance of different families of Language Models. The study will address critical questions about these models' reliability, comparative performance, and effectiveness in the context of me",
    "link": "https://arxiv.org/abs/2401.11389",
    "context": "Title: MedLM: Exploring Language Models for Medical Question Answering Systems\nAbstract: arXiv:2401.11389v2 Announce Type: replace-cross  Abstract: In the face of rapidly expanding online medical literature, automated systems for aggregating and summarizing information are becoming increasingly crucial for healthcare professionals and patients. Large Language Models (LLMs), with their advanced generative capabilities, have shown promise in various NLP tasks, and their potential in the healthcare domain, particularly for Closed-Book Generative QnA, is significant. However, the performance of these models in domain-specific tasks such as medical Q&A remains largely unexplored. This study aims to fill this gap by comparing the performance of general and medical-specific distilled LMs for medical Q&A. We aim to evaluate the effectiveness of fine-tuning domain-specific LMs and compare the performance of different families of Language Models. The study will address critical questions about these models' reliability, comparative performance, and effectiveness in the context of me",
    "path": "papers/24/01/2401.11389.json",
    "total_tokens": 877,
    "translated_title": "MedLM: 探索用于医疗问答系统的语言模型",
    "translated_abstract": "面对迅速扩大的在线医学文献，自动化系统用于聚合和总结信息对于医疗保健专业人员和患者变得日益关键。大型语言模型（LLM）以其先进的生成能力在各种自然语言处理任务中显示出潜力，它们在医疗领域的潜力，特别是在封闭式生成问答方面，是显著的。然而，这些模型在医学问答等领域特定任务中的性能仍然较少被探索。本研究旨在通过比较通用和专门用于医学的精炼语言模型在医疗问答中的表现来填补这一空白。我们旨在评估微调领域特定语言模型的效果，并比较不同类型语言模型的性能。本研究将探讨这些模型的可靠性、比较性能和在医疗问答背景下的有效性等关键问题。",
    "tldr": "本研究比较了用于医疗问答的通用和医学特定的精炼语言模型的表现，以填补领域特定任务中这些模型性能的研究空白。",
    "en_tdlr": "This study compares the performance of general and medical-specific distilled language models for medical question answering to address the research gap in the performance of these models in domain-specific tasks."
}