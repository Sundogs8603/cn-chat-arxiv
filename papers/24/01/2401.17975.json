{
    "title": "Understanding polysemanticity in neural networks through coding theory",
    "abstract": "Despite substantial efforts, neural network interpretability remains an elusive goal, with previous research failing to provide succinct explanations of most single neurons' impact on the network output. This limitation is due to the polysemantic nature of most neurons, whereby a given neuron is involved in multiple unrelated network states, complicating the interpretation of that neuron. In this paper, we apply tools developed in neuroscience and information theory to propose both a novel practical approach to network interpretability and theoretical insights into polysemanticity and the density of codes. We infer levels of redundancy in the network's code by inspecting the eigenspectrum of the activation's covariance matrix. Furthermore, we show how random projections can reveal whether a network exhibits a smooth or non-differentiable code and hence how interpretable the code is. This same framework explains the advantages of polysemantic neurons to learning performance and explains",
    "link": "https://arxiv.org/abs/2401.17975",
    "context": "Title: Understanding polysemanticity in neural networks through coding theory\nAbstract: Despite substantial efforts, neural network interpretability remains an elusive goal, with previous research failing to provide succinct explanations of most single neurons' impact on the network output. This limitation is due to the polysemantic nature of most neurons, whereby a given neuron is involved in multiple unrelated network states, complicating the interpretation of that neuron. In this paper, we apply tools developed in neuroscience and information theory to propose both a novel practical approach to network interpretability and theoretical insights into polysemanticity and the density of codes. We infer levels of redundancy in the network's code by inspecting the eigenspectrum of the activation's covariance matrix. Furthermore, we show how random projections can reveal whether a network exhibits a smooth or non-differentiable code and hence how interpretable the code is. This same framework explains the advantages of polysemantic neurons to learning performance and explains",
    "path": "papers/24/01/2401.17975.json",
    "total_tokens": 838,
    "translated_title": "通过编码理论了解神经网络中的多语义性",
    "translated_abstract": "尽管付出了大量努力，神经网络可解释性仍然是一个难以捉摸的目标，以前的研究未能对大多数单个神经元对网络输出的影响提供简洁的解释。这个限制是由于大多数神经元的多语义性，即一个给定的神经元参与多个不相关的网络状态，使解释该神经元变得复杂。在本文中，我们应用神经科学和信息论中开发的工具，提出了一种新颖的网络可解释性实践方法，并对多语义性和编码密度提出了理论见解。我们通过检查激活的协方差矩阵的特征谱来推断网络代码的冗余水平。此外，我们展示了随机投影如何揭示网络是否具有平滑的或不可微的代码，从而解释了代码的可解释性。这个相同的框架解释了多语义神经元对学习性能的优势并解释了",
    "tldr": "通过应用编码理论和神经科学工具，本文提出了一种新颖的实践方法来理解神经网络中的多语义性，并对多语义神经元对学习性能的优势进行了解释。",
    "en_tdlr": "This paper proposes a novel practical approach using coding theory and neuroscience tools to understand the polysemanticity in neural networks, and provides insights into the advantages of polysemantic neurons to learning performance."
}