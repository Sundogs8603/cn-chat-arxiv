{
    "title": "TelME: Teacher-leading Multimodal Fusion Network for Emotion Recognition in Conversation. (arXiv:2401.12987v1 [cs.CL])",
    "abstract": "Emotion Recognition in Conversation (ERC) plays a crucial role in enabling dialogue systems to effectively respond to user requests. The emotions in a conversation can be identified by the representations from various modalities, such as audio, visual, and text. However, due to the weak contribution of non-verbal modalities to recognize emotions, multimodal ERC has always been considered a challenging task. In this paper, we propose Teacher-leading Multimodal fusion network for ERC (TelME). TelME incorporates cross-modal knowledge distillation to transfer information from a language model acting as the teacher to the non-verbal students, thereby optimizing the efficacy of the weak modalities. We then combine multimodal features using a shifting fusion approach in which student networks support the teacher. TelME achieves state-of-the-art performance in MELD, a multi-speaker conversation dataset for ERC. Finally, we demonstrate the effectiveness of our components through additional expe",
    "link": "http://arxiv.org/abs/2401.12987",
    "context": "Title: TelME: Teacher-leading Multimodal Fusion Network for Emotion Recognition in Conversation. (arXiv:2401.12987v1 [cs.CL])\nAbstract: Emotion Recognition in Conversation (ERC) plays a crucial role in enabling dialogue systems to effectively respond to user requests. The emotions in a conversation can be identified by the representations from various modalities, such as audio, visual, and text. However, due to the weak contribution of non-verbal modalities to recognize emotions, multimodal ERC has always been considered a challenging task. In this paper, we propose Teacher-leading Multimodal fusion network for ERC (TelME). TelME incorporates cross-modal knowledge distillation to transfer information from a language model acting as the teacher to the non-verbal students, thereby optimizing the efficacy of the weak modalities. We then combine multimodal features using a shifting fusion approach in which student networks support the teacher. TelME achieves state-of-the-art performance in MELD, a multi-speaker conversation dataset for ERC. Finally, we demonstrate the effectiveness of our components through additional expe",
    "path": "papers/24/01/2401.12987.json",
    "total_tokens": 896,
    "translated_title": "TelME：教师导向的多模融合网络用于对话中的情绪识别",
    "translated_abstract": "对话中的情绪识别在使对话系统能够有效回应用户请求方面起着至关重要的作用。对话中的情绪可以通过音频、视觉和文本等多种模态的表示进行识别。然而，由于非语言模态对识别情绪的贡献较弱，多模态情绪识别一直被认为是一项具有挑战性的任务。本文提出了一种用于对话中情绪识别的教师导向多模融合网络（TelME）。TelME通过跨模态知识蒸馏将信息从作为教师的语言模型传递给非语言的学生，从而优化了弱模态的效能。然后，我们采用一种移动融合方法将多模态特征组合起来，其中学生网络支持教师。TelME在MELD（一种用于对话情绪识别的多说话人数据集）上实现了最先进的性能。最后，我们通过额外的实验论证了我们组件的有效性。",
    "tldr": "TelME是一种教师导向的多模融合网络，通过跨模态知识蒸馏实现对话中情绪识别的优化，取得了在多说话人数据集MELD上的最先进性能。"
}