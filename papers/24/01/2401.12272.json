{
    "title": "Transfer Learning for Nonparametric Regression: Non-asymptotic Minimax Analysis and Adaptive Procedure. (arXiv:2401.12272v1 [stat.ML])",
    "abstract": "Transfer learning for nonparametric regression is considered. We first study the non-asymptotic minimax risk for this problem and develop a novel estimator called the confidence thresholding estimator, which is shown to achieve the minimax optimal risk up to a logarithmic factor. Our results demonstrate two unique phenomena in transfer learning: auto-smoothing and super-acceleration, which differentiate it from nonparametric regression in a traditional setting. We then propose a data-driven algorithm that adaptively achieves the minimax risk up to a logarithmic factor across a wide range of parameter spaces. Simulation studies are conducted to evaluate the numerical performance of the adaptive transfer learning algorithm, and a real-world example is provided to demonstrate the benefits of the proposed method.",
    "link": "http://arxiv.org/abs/2401.12272",
    "context": "Title: Transfer Learning for Nonparametric Regression: Non-asymptotic Minimax Analysis and Adaptive Procedure. (arXiv:2401.12272v1 [stat.ML])\nAbstract: Transfer learning for nonparametric regression is considered. We first study the non-asymptotic minimax risk for this problem and develop a novel estimator called the confidence thresholding estimator, which is shown to achieve the minimax optimal risk up to a logarithmic factor. Our results demonstrate two unique phenomena in transfer learning: auto-smoothing and super-acceleration, which differentiate it from nonparametric regression in a traditional setting. We then propose a data-driven algorithm that adaptively achieves the minimax risk up to a logarithmic factor across a wide range of parameter spaces. Simulation studies are conducted to evaluate the numerical performance of the adaptive transfer learning algorithm, and a real-world example is provided to demonstrate the benefits of the proposed method.",
    "path": "papers/24/01/2401.12272.json",
    "total_tokens": 930,
    "translated_title": "针对非参数回归的迁移学习：非渐近极小化分析和自适应过程",
    "translated_abstract": "本文研究了非参数回归的迁移学习问题。首先，我们研究了该问题的非渐近极小风险，并开发了一种新的估计器，称为置信阈值估计器，证明该估计器在一个对数因子的范围内实现了渐近极小的风险。我们的结果展示了迁移学习中的两个独特现象：自动平滑和超加速，这使其与传统设置中的非参数回归有所区别。然后，我们提出了一种数据驱动算法，通过自适应地在广泛的参数空间中实现了对数因子的渐近最小风险。通过仿真研究评估了自适应迁移学习算法的数值性能，并提供了一个真实世界的例子来展示该方法的好处。",
    "tldr": "本文研究了非参数回归的迁移学习问题，提出了一种新的置信阈值估计器来实现渐近最小风险，并发现了迁移学习中的两个独特现象：自动平滑和超加速。此外，我们还提出了一种数据驱动算法，可以适应广泛的参数空间，并在仿真研究和真实世界的例子中证明了该方法的优势。",
    "en_tdlr": "This paper investigates transfer learning for nonparametric regression, proposes a new confidence thresholding estimator to achieve asymptotic optimal risk, and discovers two unique phenomena: auto-smoothing and super-acceleration in transfer learning. Furthermore, a data-driven algorithm is introduced to adaptively achieve asymptotic minimum risk across a wide range of parameter spaces, and its effectiveness is demonstrated through simulation studies and a real-world example."
}