{
    "title": "Can overfitted deep neural networks in adversarial training generalize? -- An approximation viewpoint. (arXiv:2401.13624v1 [stat.ML])",
    "abstract": "Adversarial training is a widely used method to improve the robustness of deep neural networks (DNNs) over adversarial perturbations. However, it is empirically observed that adversarial training on over-parameterized networks often suffers from the \\textit{robust overfitting}: it can achieve almost zero adversarial training error while the robust generalization performance is not promising. In this paper, we provide a theoretical understanding of the question of whether overfitted DNNs in adversarial training can generalize from an approximation viewpoint. Specifically, our main results are summarized into three folds: i) For classification, we prove by construction the existence of infinitely many adversarial training classifiers on over-parameterized DNNs that obtain arbitrarily small adversarial training error (overfitting), whereas achieving good robust generalization error under certain conditions concerning the data quality, well separated, and perturbation level. ii) Linear ove",
    "link": "http://arxiv.org/abs/2401.13624",
    "context": "Title: Can overfitted deep neural networks in adversarial training generalize? -- An approximation viewpoint. (arXiv:2401.13624v1 [stat.ML])\nAbstract: Adversarial training is a widely used method to improve the robustness of deep neural networks (DNNs) over adversarial perturbations. However, it is empirically observed that adversarial training on over-parameterized networks often suffers from the \\textit{robust overfitting}: it can achieve almost zero adversarial training error while the robust generalization performance is not promising. In this paper, we provide a theoretical understanding of the question of whether overfitted DNNs in adversarial training can generalize from an approximation viewpoint. Specifically, our main results are summarized into three folds: i) For classification, we prove by construction the existence of infinitely many adversarial training classifiers on over-parameterized DNNs that obtain arbitrarily small adversarial training error (overfitting), whereas achieving good robust generalization error under certain conditions concerning the data quality, well separated, and perturbation level. ii) Linear ove",
    "path": "papers/24/01/2401.13624.json",
    "total_tokens": 934,
    "translated_title": "深度神经网络在对抗训练中的过拟合现象能否泛化？——一个近似视角",
    "translated_abstract": "对抗训练是一种广泛应用的方法，用于提高深度神经网络(DNNs)对对抗扰动的鲁棒性。然而，经验观察表明，在过参数化网络上进行对抗训练往往会遭受\"鲁棒性过拟合\"：它可以实现几乎零的对抗训练误差，而鲁棒泛化性能并不理想。本文从近似的角度提供了关于在对抗训练中过拟合的DNNs能否泛化的理论理解。具体而言，我们的主要结果总结为三个方面：i) 对于分类问题，我们证明了在过参数化的DNNs上可以构造出无限多个对抗训练分类器，其能够在满足一定条件下（涉及数据质量，良好分离和扰动程度）获得任意小的对抗训练误差（过拟合），同时在鲁棒泛化误差方面表现良好。ii) 线性超过拟合的DNNs也可以实现鲁棒泛化。iii) 我们通过数值实验验证了所提出的理论结果。",
    "tldr": "过拟合的深度神经网络在对抗训练中能够泛化，而且可以通过合适的条件获得良好的鲁棒泛化性能。",
    "en_tdlr": "Overfitted deep neural networks in adversarial training can generalize, and good robust generalization performance can be achieved with appropriate conditions."
}