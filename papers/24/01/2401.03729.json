{
    "title": "The Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Model Performance. (arXiv:2401.03729v2 [cs.CL] UPDATED)",
    "abstract": "Large Language Models (LLMs) are regularly being used to label data across many domains and for myriad tasks. By simply asking the LLM for an answer, or ``prompting,'' practitioners are able to use LLMs to quickly get a response for an arbitrary task. This prompting is done through a series of decisions by the practitioner, from simple wording of the prompt, to requesting the output in a certain data format, to jailbreaking in the case of prompts that address more sensitive topics. In this work, we ask: do variations in the way a prompt is constructed change the ultimate decision of the LLM? We answer this using a series of prompt variations across a variety of text classification tasks. We find that even the smallest of perturbations, such as adding a space at the end of a prompt, can cause the LLM to change its answer. Further, we find that requesting responses in XML and commonly used jailbreaks can have cataclysmic effects on the data labeled by LLMs.",
    "link": "http://arxiv.org/abs/2401.03729",
    "context": "Title: The Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Model Performance. (arXiv:2401.03729v2 [cs.CL] UPDATED)\nAbstract: Large Language Models (LLMs) are regularly being used to label data across many domains and for myriad tasks. By simply asking the LLM for an answer, or ``prompting,'' practitioners are able to use LLMs to quickly get a response for an arbitrary task. This prompting is done through a series of decisions by the practitioner, from simple wording of the prompt, to requesting the output in a certain data format, to jailbreaking in the case of prompts that address more sensitive topics. In this work, we ask: do variations in the way a prompt is constructed change the ultimate decision of the LLM? We answer this using a series of prompt variations across a variety of text classification tasks. We find that even the smallest of perturbations, such as adding a space at the end of a prompt, can cause the LLM to change its answer. Further, we find that requesting responses in XML and commonly used jailbreaks can have cataclysmic effects on the data labeled by LLMs.",
    "path": "papers/24/01/2401.03729.json",
    "total_tokens": 902,
    "translated_title": "改变提示的蝴蝶效应：微小的变化和越狱对大规模语言模型性能的影响",
    "translated_abstract": "大规模语言模型（LLMs）被广泛用于对多个领域和多个任务的数据进行标注。通过简单地向LLM提问或“提示”，实践者能够快速获得任意任务的响应。提示的构建方式是否变化会影响LLM的最终决策？我们通过对多种文本分类任务进行一系列提示变化来回答这个问题。我们发现，即使是最微小的扰动，比如在提示的末尾加一个空格，也可能导致LLM改变其答案。此外，我们发现在XML中请求响应和常用的越狱方式可能对由LLMs标记的数据产生灾难性影响。",
    "tldr": "本研究通过一系列提示变化探究改变提示的构建方式对大规模语言模型决策的影响，发现即使微小的改变，比如在提示末尾加一个空格，也可能导致模型的答案变化。同时，请求以XML格式返回和常用的越狱方式也可能对模型标记的数据产生灾难性影响。",
    "en_tdlr": "This study investigates the impact of altering prompts on large language models and finds that even small changes, such as adding a space at the end of a prompt, can cause the model to change its answer. Additionally, requesting responses in XML format and using commonly used jailbreaks can have catastrophic effects on the data labeled by the models."
}