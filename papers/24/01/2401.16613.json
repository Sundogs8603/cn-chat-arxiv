{
    "title": "Algebraic Complexity and Neurovariety of Linear Convolutional Networks. (arXiv:2401.16613v1 [math.AG])",
    "abstract": "In this paper, we study linear convolutional networks with one-dimensional filters and arbitrary strides. The neuromanifold of such a network is a semialgebraic set, represented by a space of polynomials admitting specific factorizations. Introducing a recursive algorithm, we generate polynomial equations whose common zero locus corresponds to the Zariski closure of the corresponding neuromanifold. Furthermore, we explore the algebraic complexity of training these networks employing tools from metric algebraic geometry. Our findings reveal that the number of all complex critical points in the optimization of such a network is equal to the generic Euclidean distance degree of a Segre variety. Notably, this count significantly surpasses the number of critical points encountered in the training of a fully connected linear network with the same number of parameters.",
    "link": "http://arxiv.org/abs/2401.16613",
    "context": "Title: Algebraic Complexity and Neurovariety of Linear Convolutional Networks. (arXiv:2401.16613v1 [math.AG])\nAbstract: In this paper, we study linear convolutional networks with one-dimensional filters and arbitrary strides. The neuromanifold of such a network is a semialgebraic set, represented by a space of polynomials admitting specific factorizations. Introducing a recursive algorithm, we generate polynomial equations whose common zero locus corresponds to the Zariski closure of the corresponding neuromanifold. Furthermore, we explore the algebraic complexity of training these networks employing tools from metric algebraic geometry. Our findings reveal that the number of all complex critical points in the optimization of such a network is equal to the generic Euclidean distance degree of a Segre variety. Notably, this count significantly surpasses the number of critical points encountered in the training of a fully connected linear network with the same number of parameters.",
    "path": "papers/24/01/2401.16613.json",
    "total_tokens": 781,
    "translated_title": "线性卷积网络的代数复杂度和神经多样性研究",
    "translated_abstract": "本文研究了具有一维滤波器和任意步幅的线性卷积网络。这种网络的神经流形是一个半代数集，由具有特定分解的多项式空间表示。通过引入递归算法，我们生成多项式方程，其共同零点对应于相应神经流形的Zariski闭包。此外，我们还利用度量代数几何的工具探索了训练这些网络的代数复杂度。我们的研究结果揭示，优化这种网络时所有复杂关键点的数量等于一个Segre簇的通用欧几里德距离度。值得注意的是，这个数量显著超过了使用相同参数个数训练完全连接的线性网络时遇到的关键点数量。",
    "tldr": "本文研究了具有一维滤波器和任意步幅的线性卷积网络的代数复杂度和神经多样性。通过引入递归算法和度量代数几何的工具，我们发现这些网络优化中的关键点数量显著超过了完全连接的线性网络。"
}