{
    "title": "LLMs for Relational Reasoning: How Far are We?. (arXiv:2401.09042v1 [cs.AI])",
    "abstract": "Large language models (LLMs) have revolutionized many areas (e.g. natural language processing, software engineering, etc.) by achieving state-of-the-art performance on extensive downstream tasks. Aiming to achieve robust and general artificial intelligence, there has been a surge of interest in investigating the reasoning ability of the LLMs. Whereas the textual and numerical reasoning benchmarks adopted by previous works are rather shallow and simple, it is hard to conclude that the LLMs possess strong reasoning ability by merely achieving positive results on these benchmarks. Recent efforts have demonstrated that the LLMs are poor at solving sequential decision-making problems that require common-sense planning by evaluating their performance on the reinforcement learning benchmarks. In this work, we conduct an in-depth assessment of several state-of-the-art LLMs' reasoning ability based on the inductive logic programming (ILP) benchmark, which is broadly recognized as a representati",
    "link": "http://arxiv.org/abs/2401.09042",
    "context": "Title: LLMs for Relational Reasoning: How Far are We?. (arXiv:2401.09042v1 [cs.AI])\nAbstract: Large language models (LLMs) have revolutionized many areas (e.g. natural language processing, software engineering, etc.) by achieving state-of-the-art performance on extensive downstream tasks. Aiming to achieve robust and general artificial intelligence, there has been a surge of interest in investigating the reasoning ability of the LLMs. Whereas the textual and numerical reasoning benchmarks adopted by previous works are rather shallow and simple, it is hard to conclude that the LLMs possess strong reasoning ability by merely achieving positive results on these benchmarks. Recent efforts have demonstrated that the LLMs are poor at solving sequential decision-making problems that require common-sense planning by evaluating their performance on the reinforcement learning benchmarks. In this work, we conduct an in-depth assessment of several state-of-the-art LLMs' reasoning ability based on the inductive logic programming (ILP) benchmark, which is broadly recognized as a representati",
    "path": "papers/24/01/2401.09042.json",
    "total_tokens": 911,
    "translated_title": "LLM对于关系推理的实现程度有多远？",
    "translated_abstract": "大型语言模型（LLM）通过在广泛的下游任务中取得了最先进的性能，从而革新了许多领域（例如自然语言处理、软件工程等）。为了实现强大且通用的人工智能，人们对LLM的推理能力产生了浓厚的兴趣。然而，先前研究采用的文本和数值推理基准测试相对浅显简单，仅仅通过在这些基准上取得积极结果难以得出LLM具有强大推理能力的结论。最近的研究努力通过在强化学习基准测试上评估LLM的性能，证明LLM在解决需要常识规划的顺序决策问题方面表现不佳。在本研究中，我们基于归纳逻辑编程（ILP）基准测试对几种最先进的LLM的推理能力进行了深入评估，这一基准测试被广泛认可为对推理能力的代表性评估。",
    "tldr": "本论文对多种最先进的LLM的推理能力进行了全面评估，发现它们在归纳逻辑编程基准测试上的表现欠佳，这挑战了它们在处理常识规划的顺序决策问题方面的能力。",
    "en_tdlr": "This paper provides a comprehensive assessment of the reasoning ability of several state-of-the-art LLMs and finds that they perform poorly on the inductive logic programming benchmark, challenging their capability in handling sequential decision-making problems requiring common-sense planning."
}