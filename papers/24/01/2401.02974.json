{
    "title": "Efficacy of Utilizing Large Language Models to Detect Public Threat Posted Online. (arXiv:2401.02974v1 [cs.CL])",
    "abstract": "This paper examines the efficacy of utilizing large language models (LLMs) to detect public threats posted online. Amid rising concerns over the spread of threatening rhetoric and advance notices of violence, automated content analysis techniques may aid in early identification and moderation. Custom data collection tools were developed to amass post titles from a popular Korean online community, comprising 500 non-threat examples and 20 threats. Various LLMs (GPT-3.5, GPT-4, PaLM) were prompted to classify individual posts as either \"threat\" or \"safe.\" Statistical analysis found all models demonstrated strong accuracy, passing chi-square goodness of fit tests for both threat and non-threat identification. GPT-4 performed best overall with 97.9% non-threat and 100% threat accuracy. Affordability analysis also showed PaLM API pricing as highly cost-efficient. The findings indicate LLMs can effectively augment human content moderation at scale to help mitigate emerging online risks. Howe",
    "link": "http://arxiv.org/abs/2401.02974",
    "context": "Title: Efficacy of Utilizing Large Language Models to Detect Public Threat Posted Online. (arXiv:2401.02974v1 [cs.CL])\nAbstract: This paper examines the efficacy of utilizing large language models (LLMs) to detect public threats posted online. Amid rising concerns over the spread of threatening rhetoric and advance notices of violence, automated content analysis techniques may aid in early identification and moderation. Custom data collection tools were developed to amass post titles from a popular Korean online community, comprising 500 non-threat examples and 20 threats. Various LLMs (GPT-3.5, GPT-4, PaLM) were prompted to classify individual posts as either \"threat\" or \"safe.\" Statistical analysis found all models demonstrated strong accuracy, passing chi-square goodness of fit tests for both threat and non-threat identification. GPT-4 performed best overall with 97.9% non-threat and 100% threat accuracy. Affordability analysis also showed PaLM API pricing as highly cost-efficient. The findings indicate LLMs can effectively augment human content moderation at scale to help mitigate emerging online risks. Howe",
    "path": "papers/24/01/2401.02974.json",
    "total_tokens": 1078,
    "translated_title": "利用大型语言模型检测在线公开威胁的效力",
    "translated_abstract": "本文研究了利用大型语言模型(LLMs)检测在线公开威胁的效力。在对威胁 retoric 的传播和暴力预告的增长越来越担忧的背景下，自动内容分析技术可以帮助早期发现和处理。我们开发了自定义的数据收集工具，从一个热门的韩国在线社区收集了500个非威胁示例和20个威胁示例的帖子标题。各种LLMs (GPT-3.5, GPT-4, PaLM) 被提示将单个帖子分类为\"威胁\"或\"安全\"。统计分析发现所有模型在威胁和非威胁识别方面表现出较高的准确性，通过卡方拟合度检验也得到了验证。GPT-4 的整体表现最好，非威胁精度达到了97.9%，威胁精度达到了100%。可行性分析还显示PaLM API的定价非常具有成本效益。研究结果显示，LLMs 在规模化环境中可以有效地增强人工内容审查，以帮助减轻新兴的在线风险。",
    "tldr": "本文研究了利用大型语言模型(LLMs)检测在线公开威胁的效力。通过实验发现，不同的LLMs在威胁和非威胁识别方面表现出较高的准确性，其中GPT-4的表现最佳。研究还发现PaLM API的定价非常具有成本效益。研究结果表明，LLMs可以有效地增强人工内容审查，帮助减轻新兴的在线风险。"
}