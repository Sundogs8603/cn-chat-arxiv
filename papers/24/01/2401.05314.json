{
    "title": "ANIM-400K: A Large-Scale Dataset for Automated End-To-End Dubbing of Video. (arXiv:2401.05314v1 [eess.AS])",
    "abstract": "The Internet's wealth of content, with up to 60% published in English, starkly contrasts the global population, where only 18.8% are English speakers, and just 5.1% consider it their native language, leading to disparities in online information access. Unfortunately, automated processes for dubbing of video - replacing the audio track of a video with a translated alternative remains a complex and challenging task due to pipelines, necessitating precise timing, facial movement synchronization, and prosody matching. While end-to-end dubbing offers a solution, data scarcity continues to impede the progress of both end-to-end and pipeline-based methods. In this work, we introduce Anim-400K, a comprehensive dataset of over 425K aligned animated video segments in Japanese and English supporting various video-related tasks, including automated dubbing, simultaneous translation, guided video summarization, and genre/theme/style classification. Our dataset is made publicly available for resea",
    "link": "http://arxiv.org/abs/2401.05314",
    "context": "Title: ANIM-400K: A Large-Scale Dataset for Automated End-To-End Dubbing of Video. (arXiv:2401.05314v1 [eess.AS])\nAbstract: The Internet's wealth of content, with up to 60% published in English, starkly contrasts the global population, where only 18.8% are English speakers, and just 5.1% consider it their native language, leading to disparities in online information access. Unfortunately, automated processes for dubbing of video - replacing the audio track of a video with a translated alternative remains a complex and challenging task due to pipelines, necessitating precise timing, facial movement synchronization, and prosody matching. While end-to-end dubbing offers a solution, data scarcity continues to impede the progress of both end-to-end and pipeline-based methods. In this work, we introduce Anim-400K, a comprehensive dataset of over 425K aligned animated video segments in Japanese and English supporting various video-related tasks, including automated dubbing, simultaneous translation, guided video summarization, and genre/theme/style classification. Our dataset is made publicly available for resea",
    "path": "papers/24/01/2401.05314.json",
    "total_tokens": 861,
    "translated_title": "ANIM-400K: 用于自动化视频配音的大规模数据集",
    "translated_abstract": "互联网上丰富的内容中，高达60％是用英语发布的，这与全球人口形成鲜明对比，全球只有18.8％是英语使用者，且只有5.1％将其视为母语，导致在线信息获取存在差异。不幸的是，使用替代翻译字幕替换视频的音轨仍然是一项复杂而具有挑战性的任务，需要精确的时序、面部运动同步和韵律匹配。虽然端对端配音提供了一种解决方案，但数据稀缺继续阻碍着端对端和基于流水线的方法的进展。在这项工作中，我们介绍了Anim-400K，这是一个包含超过425K个日语和英语对齐的动画视频片段的全面数据集，支持各种与视频相关的任务，包括自动化配音、同时翻译、导向视频摘要和类型/主题/风格分类。我们的数据集已公开提供给研究人员使用。",
    "tldr": "ANIM-400K是一个大规模的数据集，支持自动化视频配音和其他与视频相关的任务。它解决了语言差异和数据稀缺的问题，为研究人员提供了丰富的资源。"
}