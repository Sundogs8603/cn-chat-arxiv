{
    "title": "Personalized Reinforcement Learning with a Budget of Policies. (arXiv:2401.06514v1 [cs.LG])",
    "abstract": "Personalization in machine learning (ML) tailors models' decisions to the individual characteristics of users. While this approach has seen success in areas like recommender systems, its expansion into high-stakes fields such as healthcare and autonomous driving is hindered by the extensive regulatory approval processes involved. To address this challenge, we propose a novel framework termed represented Markov Decision Processes (r-MDPs) that is designed to balance the need for personalization with the regulatory constraints. In an r-MDP, we cater to a diverse user population, each with unique preferences, through interaction with a small set of representative policies. Our objective is twofold: efficiently match each user to an appropriate representative policy and simultaneously optimize these policies to maximize overall social welfare. We develop two deep reinforcement learning algorithms that efficiently solve r-MDPs. These algorithms draw inspiration from the principles of classi",
    "link": "http://arxiv.org/abs/2401.06514",
    "context": "Title: Personalized Reinforcement Learning with a Budget of Policies. (arXiv:2401.06514v1 [cs.LG])\nAbstract: Personalization in machine learning (ML) tailors models' decisions to the individual characteristics of users. While this approach has seen success in areas like recommender systems, its expansion into high-stakes fields such as healthcare and autonomous driving is hindered by the extensive regulatory approval processes involved. To address this challenge, we propose a novel framework termed represented Markov Decision Processes (r-MDPs) that is designed to balance the need for personalization with the regulatory constraints. In an r-MDP, we cater to a diverse user population, each with unique preferences, through interaction with a small set of representative policies. Our objective is twofold: efficiently match each user to an appropriate representative policy and simultaneously optimize these policies to maximize overall social welfare. We develop two deep reinforcement learning algorithms that efficiently solve r-MDPs. These algorithms draw inspiration from the principles of classi",
    "path": "papers/24/01/2401.06514.json",
    "total_tokens": 896,
    "translated_title": "个性化强化学习与策略预算",
    "translated_abstract": "个性化机器学习在根据用户个体特征调整模型决策方面取得了成功，但在涉及到健康和自动驾驶等高风险领域的扩展时，受到了复杂的监管审批流程的限制。为了解决这一挑战，我们提出了一种新的框架，称为表示的马尔可夫决策过程（r-MDPs），旨在平衡个性化需求和监管约束。在r-MDPs中，通过与一小组代表性策略的交互，我们为多样化的用户群体提供服务，每个用户都有独特的偏好。我们的目标是高效地将每个用户与适当的代表性策略进行匹配，并同时优化这些策略以最大化整体社会福利。我们开发了两种深度强化学习算法，可以高效地解决r-MDPs的问题。这些算法受到了经典强化学习原理的启发。",
    "tldr": "该论文提出了一种称为表示的马尔可夫决策过程（r-MDPs）的框架，通过与一小组代表性策略的交互，实现个性化强化学习，并同时在满足监管约束的情况下优化整体社会福利。",
    "en_tdlr": "This paper proposes a framework called represented Markov Decision Processes (r-MDPs) that enables personalized reinforcement learning by interacting with a small set of representative policies, and simultaneously optimizes overall social welfare while adhering to regulatory constraints."
}