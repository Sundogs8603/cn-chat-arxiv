{
    "title": "An Assessment on Comprehending Mental Health through Large Language Models. (arXiv:2401.04592v1 [cs.CL])",
    "abstract": "Mental health challenges pose considerable global burdens on individuals and communities. Recent data indicates that more than 20% of adults may encounter at least one mental disorder in their lifetime. On the one hand, the advancements in large language models have facilitated diverse applications, yet a significant research gap persists in understanding and enhancing the potential of large language models within the domain of mental health. On the other hand, across various applications, an outstanding question involves the capacity of large language models to comprehend expressions of human mental health conditions in natural language. This study presents an initial evaluation of large language models in addressing this gap. Due to this, we compare the performance of Llama-2 and ChatGPT with classical Machine as well as Deep learning models. Our results on the DAIC-WOZ dataset show that transformer-based models, like BERT or XLNet, outperform the large language models.",
    "link": "http://arxiv.org/abs/2401.04592",
    "context": "Title: An Assessment on Comprehending Mental Health through Large Language Models. (arXiv:2401.04592v1 [cs.CL])\nAbstract: Mental health challenges pose considerable global burdens on individuals and communities. Recent data indicates that more than 20% of adults may encounter at least one mental disorder in their lifetime. On the one hand, the advancements in large language models have facilitated diverse applications, yet a significant research gap persists in understanding and enhancing the potential of large language models within the domain of mental health. On the other hand, across various applications, an outstanding question involves the capacity of large language models to comprehend expressions of human mental health conditions in natural language. This study presents an initial evaluation of large language models in addressing this gap. Due to this, we compare the performance of Llama-2 and ChatGPT with classical Machine as well as Deep learning models. Our results on the DAIC-WOZ dataset show that transformer-based models, like BERT or XLNet, outperform the large language models.",
    "path": "papers/24/01/2401.04592.json",
    "total_tokens": 875,
    "translated_title": "通过大型语言模型了解心理健康的评估",
    "translated_abstract": "心理健康挑战对个人和社区造成了巨大的全球负担。最近的数据表明，超过20%的成年人在他们的一生中可能会遇到至少一种心理障碍。一方面，大型语言模型的进展为各种应用提供了便利，然而在心理健康领域，对大型语言模型的潜力的理解和提升仍存在重要的研究空白。另一方面，在各种应用中，一个重要的问题是大型语言模型对自然语言中人类心理健康状况表达的理解能力。本研究在解决这一空白的过程中进行了大型语言模型的初步评估。因此，我们将Llama-2和ChatGPT与传统的机器学习模型和深度学习模型进行了性能比较。我们在DAIC-WOZ数据集上的结果显示，基于Transformer的模型（如BERT或XLNet）的性能优于大型语言模型。",
    "tldr": "这项研究评估了大型语言模型在理解心理健康方面的潜力，结果显示基于Transformer的模型在表达人类心理健康状况方面的理解能力超过大型语言模型。",
    "en_tdlr": "This study assessed the potential of large language models in comprehending mental health, and found that transformer-based models outperformed large language models in understanding expressions of human mental health conditions."
}