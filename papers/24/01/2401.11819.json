{
    "title": "SuperCLUE-Math6: Graded Multi-Step Math Reasoning Benchmark for LLMs in Chinese",
    "abstract": "We introduce SuperCLUE-Math6(SC-Math6), a new benchmark dataset to evaluate the mathematical reasoning abilities of Chinese language models. SC-Math6 is designed as an upgraded Chinese version of the GSM8K dataset with enhanced difficulty, diversity, and application scope. It consists of over 2000 mathematical word problems requiring multi-step reasoning and providing natural language solutions. We propose an innovative scheme to quantify the reasoning capability of large models based on performance over problems with different reasoning steps. Experiments on 13 representative Chinese models demonstrate a clear stratification of reasoning levels, with top models like GPT-4 showing superior performance. SC-Math6 fills the gap in Chinese mathematical reasoning benchmarks and provides a comprehensive testbed to advance the intelligence of Chinese language models.",
    "link": "https://rss.arxiv.org/abs/2401.11819",
    "context": "Title: SuperCLUE-Math6: Graded Multi-Step Math Reasoning Benchmark for LLMs in Chinese\nAbstract: We introduce SuperCLUE-Math6(SC-Math6), a new benchmark dataset to evaluate the mathematical reasoning abilities of Chinese language models. SC-Math6 is designed as an upgraded Chinese version of the GSM8K dataset with enhanced difficulty, diversity, and application scope. It consists of over 2000 mathematical word problems requiring multi-step reasoning and providing natural language solutions. We propose an innovative scheme to quantify the reasoning capability of large models based on performance over problems with different reasoning steps. Experiments on 13 representative Chinese models demonstrate a clear stratification of reasoning levels, with top models like GPT-4 showing superior performance. SC-Math6 fills the gap in Chinese mathematical reasoning benchmarks and provides a comprehensive testbed to advance the intelligence of Chinese language models.",
    "path": "papers/24/01/2401.11819.json",
    "total_tokens": 980,
    "translated_title": "SuperCLUE-Math6：用于评估中文语言模型逻辑多步数学推理能力的分级基准数据集",
    "translated_abstract": "我们介绍了SuperCLUE-Math6（SC-Math6），这是一个新的基准数据集，用于评估中文语言模型的数学推理能力。SC-Math6是GSM8K数据集的升级版本，增加了难度、多样性和应用范围。它包含了2000多个需要多步推理并提供自然语言解决方案的数学问题。我们提出了一种创新的方法来量化大型模型的推理能力，基于不同推理步骤的问题表现。对13个代表性的中文模型的实验结果显示出明显的推理水平分层，顶级模型如GPT-4表现出优越的性能。SC-Math6填补了中文数学推理基准数据集的空白，并提供了一个全面的测试平台来推进中文语言模型的智能化。",
    "tldr": "SuperCLUE-Math6 是一个用于评估中文语言模型数学推理能力的分级数据集，通过增加难度、多样性和应用范围，提供了2000多个需要多步推理的数学问题，并采用创新方法来量化大型模型的推理能力。实验结果显示出明显的推理水平分层，顶级模型如GPT-4表现出优越的性能。SC-Math6填补了中文数学推理基准数据集的空白，并推进了中文语言模型的智能化。",
    "en_tdlr": "SuperCLUE-Math6 is a graded dataset designed to evaluate the mathematical reasoning abilities of Chinese language models. It enhances the difficulty, diversity, and application scope compared to previous datasets, consisting of over 2000 math word problems that require multi-step reasoning. The proposed innovative approach quantifies the reasoning capability of large models based on different reasoning steps. Experimental results show a clear stratification of reasoning levels among 13 representative Chinese models, with top models like GPT-4 demonstrating superior performance. SC-Math6 fills the gap in Chinese mathematical reasoning benchmarks and advances the intelligence of Chinese language models."
}