{
    "title": "Change Detection Between Optical Remote Sensing Imagery and Map Data via Segment Anything Model (SAM). (arXiv:2401.09019v1 [eess.IV])",
    "abstract": "Unsupervised multimodal change detection is pivotal for time-sensitive tasks and comprehensive multi-temporal Earth monitoring. In this study, we explore unsupervised multimodal change detection between two key remote sensing data sources: optical high-resolution imagery and OpenStreetMap (OSM) data. Specifically, we propose to utilize the vision foundation model Segmentation Anything Model (SAM), for addressing our task. Leveraging SAM's exceptional zero-shot transfer capability, high-quality segmentation maps of optical images can be obtained. Thus, we can directly compare these two heterogeneous data forms in the so-called segmentation domain. We then introduce two strategies for guiding SAM's segmentation process: the 'no-prompt' and 'box/mask prompt' methods. The two strategies are designed to detect land-cover changes in general scenarios and to identify new land-cover objects within existing backgrounds, respectively. Experimental results on three datasets indicate that the prop",
    "link": "http://arxiv.org/abs/2401.09019",
    "context": "Title: Change Detection Between Optical Remote Sensing Imagery and Map Data via Segment Anything Model (SAM). (arXiv:2401.09019v1 [eess.IV])\nAbstract: Unsupervised multimodal change detection is pivotal for time-sensitive tasks and comprehensive multi-temporal Earth monitoring. In this study, we explore unsupervised multimodal change detection between two key remote sensing data sources: optical high-resolution imagery and OpenStreetMap (OSM) data. Specifically, we propose to utilize the vision foundation model Segmentation Anything Model (SAM), for addressing our task. Leveraging SAM's exceptional zero-shot transfer capability, high-quality segmentation maps of optical images can be obtained. Thus, we can directly compare these two heterogeneous data forms in the so-called segmentation domain. We then introduce two strategies for guiding SAM's segmentation process: the 'no-prompt' and 'box/mask prompt' methods. The two strategies are designed to detect land-cover changes in general scenarios and to identify new land-cover objects within existing backgrounds, respectively. Experimental results on three datasets indicate that the prop",
    "path": "papers/24/01/2401.09019.json",
    "total_tokens": 1008,
    "translated_title": "通过分段任意模型（SAM）在光学遥感图像和地图数据之间进行变化检测",
    "translated_abstract": "无监督多模态变化检测对于时间敏感任务和全面的多时相地球监测至关重要。本研究探索了光学高分辨率图像和OpenStreetMap（OSM）数据之间的无监督多模态变化检测。具体而言，我们提出利用视觉基础模型-分段任意模型（SAM）来解决我们的任务。通过利用SAM的出色的零样本迁移能力，可以获得光学图像的高质量分割地图。因此，我们可以直接在所谓的分割域比较这两种异构数据形式。然后，我们引入了两种策略来指导SAM的分割过程：'无提示'和'框/蒙版提示'方法。这两种策略分别用于检测一般情况下的土地覆盖变化和识别现有背景中的新土地覆盖对象。三个数据集上的实验结果表明，所提出的方法在变化检测的准确性方面具有很好的性能。",
    "tldr": "本研究利用分段任意模型（SAM）实现了光学遥感图像和地图数据之间的无监督多模态变化检测。通过SAM的零样本迁移能力，可以获得高质量的光学图像分割地图，并且提出了两种策略来指导分割过程，从而在土地覆盖变化和新土地覆盖对象识别方面具有良好性能。",
    "en_tdlr": "This study presents unsupervised multimodal change detection between optical remote sensing imagery and map data using the Segment Anything Model (SAM). By leveraging SAM's zero-shot transfer capability, high-quality segmentation maps of optical images are obtained, and two strategies are introduced to guide the segmentation process for land-cover change detection and identification of new land-cover objects. Experimental results demonstrate the effectiveness of the proposed approach."
}