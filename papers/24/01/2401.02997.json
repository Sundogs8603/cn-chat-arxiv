{
    "title": "Blar-SQL: Faster, Stronger, Smaller NL2SQL. (arXiv:2401.02997v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) have gained considerable notoriety in the field of natural language to SQL tasks (NL2SQL). In this study, we show how task decomposition can greatly benefit LLMs in database understanding and query generation in order to answer human questions with an SQL query.  We fined-tuned open source models, specifically Llama-2 and Code Llama, by combining 2 different models each designated to focus on one of two tasks in order to leverage each model's core competency to further increase the accuracy of the final SQL query.  We propose a new framework to divide the schema into chunks in order to fit more information into a limited context. Our results are comparable with those obtained by GPT-4 at the same time being 135 times smaller, 90 times faster and more than 100 times cheaper than GPT-4.",
    "link": "http://arxiv.org/abs/2401.02997",
    "context": "Title: Blar-SQL: Faster, Stronger, Smaller NL2SQL. (arXiv:2401.02997v1 [cs.CL])\nAbstract: Large Language Models (LLMs) have gained considerable notoriety in the field of natural language to SQL tasks (NL2SQL). In this study, we show how task decomposition can greatly benefit LLMs in database understanding and query generation in order to answer human questions with an SQL query.  We fined-tuned open source models, specifically Llama-2 and Code Llama, by combining 2 different models each designated to focus on one of two tasks in order to leverage each model's core competency to further increase the accuracy of the final SQL query.  We propose a new framework to divide the schema into chunks in order to fit more information into a limited context. Our results are comparable with those obtained by GPT-4 at the same time being 135 times smaller, 90 times faster and more than 100 times cheaper than GPT-4.",
    "path": "papers/24/01/2401.02997.json",
    "total_tokens": 856,
    "translated_title": "Blar-SQL: 更快、更强、更小的NL2SQL",
    "translated_abstract": "大型语言模型（LLMs）在自然语言到SQL任务（NL2SQL）领域取得了可观的声誉。在本研究中，我们展示了如何通过任务分解来极大地改善LLMs在数据库理解和查询生成方面的能力，以便使用一个SQL查询来回答人类的问题。我们通过组合两个不同模型，分别专注于两个任务，对开源模型（特别是Llama-2和Code Llama）进行了精调，以利用每个模型的核心竞争力，进一步提高最终SQL查询的准确性。我们提出了一个新的框架来将模式划分为块，以将更多信息适应有限的上下文中。我们的结果与GPT-4获得的结果相当，同时比GPT-4更小135倍、更快90倍，并且比GPT-4便宜100倍以上。",
    "tldr": "该研究通过任务分解，提出了Blar-SQL框架，将两个不同的模型组合，分别专注于不同的任务，从而极大地提高了NL2SQL任务的准确性。该模型比GPT-4更小、更快、更便宜。",
    "en_tdlr": "This study proposes the Blar-SQL framework, which combines two models to improve the accuracy of NL2SQL tasks through task decomposition. The model is 135 times smaller, 90 times faster, and more than 100 times cheaper than GPT-4."
}