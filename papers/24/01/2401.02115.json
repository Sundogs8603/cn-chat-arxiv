{
    "title": "Using LLM to select the right SQL Query from candidates. (arXiv:2401.02115v1 [cs.CL])",
    "abstract": "Text-to-SQL models can generate a list of candidate SQL queries, and the best query is often in the candidate list, but not at the top of the list. An effective re-rank method can select the right SQL query from the candidate list and improve the model's performance. Previous studies on code generation automatically generate test cases and use them to re-rank candidate codes. However, automatic test case generation for text-to-SQL is an understudied field. We propose an automatic test case generation method that first generates a database and then uses LLMs to predict the ground truth, which is the expected execution results of the ground truth SQL query on this database. To reduce the difficulty for LLMs to predict, we conduct experiments to search for ways to generate easy databases for LLMs and design easy-to-understand prompts. Based on our test case generation method, we propose a re-rank method to select the right SQL query from the candidate list. Given a candidate list, our met",
    "link": "http://arxiv.org/abs/2401.02115",
    "context": "Title: Using LLM to select the right SQL Query from candidates. (arXiv:2401.02115v1 [cs.CL])\nAbstract: Text-to-SQL models can generate a list of candidate SQL queries, and the best query is often in the candidate list, but not at the top of the list. An effective re-rank method can select the right SQL query from the candidate list and improve the model's performance. Previous studies on code generation automatically generate test cases and use them to re-rank candidate codes. However, automatic test case generation for text-to-SQL is an understudied field. We propose an automatic test case generation method that first generates a database and then uses LLMs to predict the ground truth, which is the expected execution results of the ground truth SQL query on this database. To reduce the difficulty for LLMs to predict, we conduct experiments to search for ways to generate easy databases for LLMs and design easy-to-understand prompts. Based on our test case generation method, we propose a re-rank method to select the right SQL query from the candidate list. Given a candidate list, our met",
    "path": "papers/24/01/2401.02115.json",
    "total_tokens": 805,
    "translated_title": "使用LLM从候选项中选择正确的SQL查询",
    "translated_abstract": "文本到SQL模型可以生成一系列候选的SQL查询，而最佳查询往往不在候选列表的顶部。有效的重新排名方法可以从候选列表中选择正确的SQL查询，并提高模型的性能。之前的研究在代码生成方面通过生成测试用例来重新排名候选代码。然而，针对文本到SQL的自动测试用例生成是一个研究较少的领域。我们提出了一种自动测试用例生成的方法，首先生成一个数据库，然后使用LLM来预测真实结果，即期望结果执行真实的SQL查询在这个数据库上的结果。为了减少LLM的预测困难，我们进行了实验来寻找生成LLM易处理数据库的方法，并设计易理解的提示。基于我们的测试用例生成方法，我们提出了一种重新排名方法来从候选列表中选择正确的SQL查询。",
    "tldr": "本论文提出了一种使用LLM从候选项中选择正确的SQL查询的方法，并通过自动测试用例生成和重新排名来提高模型性能。",
    "en_tdlr": "This paper proposes a method to select the correct SQL query from candidates using LLM, and improves the model's performance through automatic test case generation and re-ranking."
}