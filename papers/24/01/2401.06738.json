{
    "title": "Noise-adaptive (Accelerated) Stochastic Heavy-Ball Momentum. (arXiv:2401.06738v1 [math.OC])",
    "abstract": "We analyze the convergence of stochastic heavy ball (SHB) momentum in the smooth, strongly-convex setting. Kidambi et al. (2018) show that SHB (with small mini-batches) cannot attain an accelerated rate of convergence even for quadratics, and conjecture that the practical gain of SHB is a by-product of mini-batching. We substantiate this claim by showing that SHB can obtain an accelerated rate when the mini-batch size is larger than some threshold. In particular, for strongly-convex quadratics with condition number $\\kappa$, we prove that SHB with the standard step-size and momentum parameters results in an $O\\left(\\exp(-\\frac{T}{\\sqrt{\\kappa}}) + \\sigma \\right)$ convergence rate, where $T$ is the number of iterations and $\\sigma^2$ is the variance in the stochastic gradients. To ensure convergence to the minimizer, we propose a multi-stage approach that results in a noise-adaptive $O\\left(\\exp\\left(-\\frac{T}{\\sqrt{\\kappa}} \\right) + \\frac{\\sigma}{T}\\right)$ rate. For general strongly-",
    "link": "http://arxiv.org/abs/2401.06738",
    "context": "Title: Noise-adaptive (Accelerated) Stochastic Heavy-Ball Momentum. (arXiv:2401.06738v1 [math.OC])\nAbstract: We analyze the convergence of stochastic heavy ball (SHB) momentum in the smooth, strongly-convex setting. Kidambi et al. (2018) show that SHB (with small mini-batches) cannot attain an accelerated rate of convergence even for quadratics, and conjecture that the practical gain of SHB is a by-product of mini-batching. We substantiate this claim by showing that SHB can obtain an accelerated rate when the mini-batch size is larger than some threshold. In particular, for strongly-convex quadratics with condition number $\\kappa$, we prove that SHB with the standard step-size and momentum parameters results in an $O\\left(\\exp(-\\frac{T}{\\sqrt{\\kappa}}) + \\sigma \\right)$ convergence rate, where $T$ is the number of iterations and $\\sigma^2$ is the variance in the stochastic gradients. To ensure convergence to the minimizer, we propose a multi-stage approach that results in a noise-adaptive $O\\left(\\exp\\left(-\\frac{T}{\\sqrt{\\kappa}} \\right) + \\frac{\\sigma}{T}\\right)$ rate. For general strongly-",
    "path": "papers/24/01/2401.06738.json",
    "total_tokens": 1063,
    "translated_title": "噪声自适应（加速）随机重力球动量",
    "translated_abstract": "我们分析了在光滑，强凸环境中随机重力球动量（SHB）的收敛性。Kidambi等人（2018）表明，对于二次函数，SHB（带有小批量）无法达到加速的收敛速度，并猜想SHB的实际收益是小批量的副产品。我们通过展示当批量大小大于一定阈值时，SHB可以获得加速的收敛速度来证实这一观点。特别地，对于条件数为$\\kappa$的强凸二次函数，我们证明了使用标准步长和动量参数的SHB具有$O\\left(\\exp(-\\frac{T}{\\sqrt{\\kappa}}) + \\sigma \\right)$的收敛速度，其中$T$为迭代次数，$\\sigma^2$为随机梯度的方差。为确保收敛到极小值，我们提出了一种多阶段方法，结果是噪声自适应的$O\\left(\\exp\\left(-\\frac{T}{\\sqrt{\\kappa}} \\right) + \\frac{\\sigma}{T}\\right)$速度。对于一般的强凸函数，我们在实验中展示了所提方法的有效性。",
    "tldr": "本研究分析了在光滑、强凸环境中随机重力球动量的收敛性，并证明了当批量大小大于某个阈值时，该方法可以实现加速收敛速度。针对强凸二次函数，我们建议了一种噪声自适应的多阶段方法，可以使收敛速度进一步提高。实验结果验证了该方法的有效性。",
    "en_tdlr": "This study analyzes the convergence of stochastic heavy ball momentum in the smooth, strongly-convex setting and proves that it can achieve accelerated convergence when the batch size exceeds a certain threshold. For strongly-convex quadratics, a noise-adaptive multi-stage approach is proposed to further improve the convergence rate. Experimental results validate the effectiveness of the proposed method."
}