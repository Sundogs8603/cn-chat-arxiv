{
    "title": "Cross-Modal Prototype based Multimodal Federated Learning under Severely Missing Modality. (arXiv:2401.13898v1 [cs.LG])",
    "abstract": "Multimodal federated learning (MFL) has emerged as a decentralized machine learning paradigm, allowing multiple clients with different modalities to collaborate on training a machine learning model across diverse data sources without sharing their private data. However, challenges, such as data heterogeneity and severely missing modalities, pose crucial hindrances to the robustness of MFL, significantly impacting the performance of global model. The absence of a modality introduces misalignment during the local training phase, stemming from zero-filling in the case of clients with missing modalities. Consequently, achieving robust generalization in global model becomes imperative, especially when dealing with clients that have incomplete data. In this paper, we propose Multimodal Federated Cross Prototype Learning (MFCPL), a novel approach for MFL under severely missing modalities by conducting the complete prototypes to provide diverse modality knowledge in modality-shared level with ",
    "link": "http://arxiv.org/abs/2401.13898",
    "context": "Title: Cross-Modal Prototype based Multimodal Federated Learning under Severely Missing Modality. (arXiv:2401.13898v1 [cs.LG])\nAbstract: Multimodal federated learning (MFL) has emerged as a decentralized machine learning paradigm, allowing multiple clients with different modalities to collaborate on training a machine learning model across diverse data sources without sharing their private data. However, challenges, such as data heterogeneity and severely missing modalities, pose crucial hindrances to the robustness of MFL, significantly impacting the performance of global model. The absence of a modality introduces misalignment during the local training phase, stemming from zero-filling in the case of clients with missing modalities. Consequently, achieving robust generalization in global model becomes imperative, especially when dealing with clients that have incomplete data. In this paper, we propose Multimodal Federated Cross Prototype Learning (MFCPL), a novel approach for MFL under severely missing modalities by conducting the complete prototypes to provide diverse modality knowledge in modality-shared level with ",
    "path": "papers/24/01/2401.13898.json",
    "total_tokens": 822,
    "translated_title": "跨模态原型基础的多模态联邦学习在严重缺失模态下的应用",
    "translated_abstract": "多模态联邦学习（MFL）作为一种去中心化的机器学习范例已经出现，它允许具有不同模态的多个客户端在不共享私人数据的情况下合作训练机器学习模型，跨多样的数据源。然而，数据异质性和严重缺失模态等挑战给MFL的稳健性带来重要阻碍，严重影响全局模型的性能。在本文中，我们提出了一种适用于严重缺失模态下的多模态联邦学习的新方法，即多模态联邦交叉原型学习（MFCPL），通过对模态共享级别进行完整的原型来提供多样的模态知识。",
    "tldr": "提出了一种适用于严重缺失模态的多模态联邦学习方法MFCPL，通过完整的原型提供多样的模态知识，解决了数据异质性和缺失模态带来的稳健性问题。",
    "en_tdlr": "A novel approach for multimodal federated learning under severely missing modalities, called MFCPL, is proposed to address data heterogeneity and robustness issues by using complete prototypes to provide diverse modality knowledge."
}