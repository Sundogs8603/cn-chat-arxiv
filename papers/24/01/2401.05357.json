{
    "title": "U-SWIM: Universal Selective Write-Verify for Computing-in-Memory Neural Accelerators. (arXiv:2401.05357v1 [cs.AR])",
    "abstract": "Architectures that incorporate Computing-in-Memory (CiM) using emerging non-volatile memory (NVM) devices have become strong contenders for deep neural network (DNN) acceleration due to their impressive energy efficiency. Yet, a significant challenge arises when using these emerging devices: they can show substantial variations during the weight-mapping process. This can severely impact DNN accuracy if not mitigated. A widely accepted remedy for imperfect weight mapping is the iterative write-verify approach, which involves verifying conductance values and adjusting devices if needed. In all existing publications, this procedure is applied to every individual device, resulting in a significant programming time overhead. In our research, we illustrate that only a small fraction of weights need this write-verify treatment for the corresponding devices and the DNN accuracy can be preserved, yielding a notable programming acceleration. Building on this, we introduce USWIM, a novel method b",
    "link": "http://arxiv.org/abs/2401.05357",
    "context": "Title: U-SWIM: Universal Selective Write-Verify for Computing-in-Memory Neural Accelerators. (arXiv:2401.05357v1 [cs.AR])\nAbstract: Architectures that incorporate Computing-in-Memory (CiM) using emerging non-volatile memory (NVM) devices have become strong contenders for deep neural network (DNN) acceleration due to their impressive energy efficiency. Yet, a significant challenge arises when using these emerging devices: they can show substantial variations during the weight-mapping process. This can severely impact DNN accuracy if not mitigated. A widely accepted remedy for imperfect weight mapping is the iterative write-verify approach, which involves verifying conductance values and adjusting devices if needed. In all existing publications, this procedure is applied to every individual device, resulting in a significant programming time overhead. In our research, we illustrate that only a small fraction of weights need this write-verify treatment for the corresponding devices and the DNN accuracy can be preserved, yielding a notable programming acceleration. Building on this, we introduce USWIM, a novel method b",
    "path": "papers/24/01/2401.05357.json",
    "total_tokens": 914,
    "translated_title": "U-SWIM: 通用选择性写入验证技术用于计算内存神经加速器",
    "translated_abstract": "通过使用新兴的非易失性内存(Non-Volatile Memory, NVM)设备来实现计算内存(Computing-in-Memory, CiM)的架构由于其惊人的能效而成为深度神经网络(DNN)加速的有力竞争者。然而，使用这些新兴设备时会面临一个重大挑战：在权重映射过程中会出现大的变化。如果不加以缓解，这会严重影响DNN的准确性。针对不完美的权重映射，一个被广泛接受的解决方法是迭代式写入验证方法，这涉及验证导纳值并在需要时调整设备。现有的所有发表作品都将此过程应用于每个单独的设备，导致显著的编程时间开销。在我们的研究中，我们证明只有一个小部分权重需要进行这种写入验证处理，可以保持相应设备和DNN的准确性，从而加快编程速度。基于此，我们介绍了一种新颖的方法 USWIM，",
    "tldr": "本文介绍了U-SWIM，一种用于计算内存神经加速器的通用选择性写入验证技术。通过只对少量权重进行写入验证处理，可以加快编程速度并保持DNN的准确性。",
    "en_tdlr": "This paper presents U-SWIM, a Universal Selective Write-Verify method for Computing-in-Memory Neural Accelerators. By applying write-verify treatment to only a small fraction of weights, it accelerates programming time while preserving DNN accuracy."
}