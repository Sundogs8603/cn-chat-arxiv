{
    "title": "Towards ASR Robust Spoken Language Understanding Through In-Context Learning With Word Confusion Networks. (arXiv:2401.02921v1 [cs.CL])",
    "abstract": "In the realm of spoken language understanding (SLU), numerous natural language understanding (NLU) methodologies have been adapted by supplying large language models (LLMs) with transcribed speech instead of conventional written text. In real-world scenarios, prior to input into an LLM, an automated speech recognition (ASR) system generates an output transcript hypothesis, where inherent errors can degrade subsequent SLU tasks. Here we introduce a method that utilizes the ASR system's lattice output instead of relying solely on the top hypothesis, aiming to encapsulate speech ambiguities and enhance SLU outcomes. Our in-context learning experiments, covering spoken question answering and intent classification, underline the LLM's resilience to noisy speech transcripts with the help of word confusion networks from lattices, bridging the SLU performance gap between using the top ASR hypothesis and an oracle upper bound. Additionally, we delve into the LLM's robustness to varying ASR perf",
    "link": "http://arxiv.org/abs/2401.02921",
    "context": "Title: Towards ASR Robust Spoken Language Understanding Through In-Context Learning With Word Confusion Networks. (arXiv:2401.02921v1 [cs.CL])\nAbstract: In the realm of spoken language understanding (SLU), numerous natural language understanding (NLU) methodologies have been adapted by supplying large language models (LLMs) with transcribed speech instead of conventional written text. In real-world scenarios, prior to input into an LLM, an automated speech recognition (ASR) system generates an output transcript hypothesis, where inherent errors can degrade subsequent SLU tasks. Here we introduce a method that utilizes the ASR system's lattice output instead of relying solely on the top hypothesis, aiming to encapsulate speech ambiguities and enhance SLU outcomes. Our in-context learning experiments, covering spoken question answering and intent classification, underline the LLM's resilience to noisy speech transcripts with the help of word confusion networks from lattices, bridging the SLU performance gap between using the top ASR hypothesis and an oracle upper bound. Additionally, we delve into the LLM's robustness to varying ASR perf",
    "path": "papers/24/01/2401.02921.json",
    "total_tokens": 931,
    "translated_title": "通过上下文学习与词混淆网实现ASR鲁棒的口语语言理解",
    "translated_abstract": "在口语语言理解领域，许多自然语言理解方法已经改进，将大型语言模型（LLM）与转录的语音进行了适配，而不是传统的书面文本。在现实场景中，自动语音识别（ASR）系统生成输出的转录假设，其中的错误会降低后续的SLU任务。我们提出了一种方法，利用ASR系统的lattice输出，而不仅仅依赖于顶部的假设，旨在包含语音模糊性并提升SLU的结果。我们进行了涵盖口语问答和意图分类的上下文学习实验，强调了LLM对嘈杂的语音转录的韧性，借助来自lattice的词混淆网络，弥合了使用顶部ASR假设和理想上限之间的SLU性能差距。此外，我们深入探讨了LLM对不同ASR性能的鲁棒性。",
    "tldr": "本研究介绍了一种通过利用ASR系统的lattice输出来提升口语语言理解鲁棒性的方法。实验结果表明，我们的方法可以弥合ASR假设和理想上限之间的性能差距，并提升在嘈杂语音转录下的SLU结果。",
    "en_tdlr": "This paper presents a method to enhance the robustness of spoken language understanding (SLU) by utilizing lattice outputs from an ASR system. The experiments show that this method can bridge the performance gap between ASR hypotheses and the ideal upper bound, improving the SLU results in noisy speech transcripts."
}