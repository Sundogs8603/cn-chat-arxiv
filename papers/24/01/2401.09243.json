{
    "title": "DiffClone: Enhanced Behaviour Cloning in Robotics with Diffusion-Driven Policy Learning. (arXiv:2401.09243v1 [cs.RO])",
    "abstract": "Robot learning tasks are extremely compute-intensive and hardware-specific. Thus the avenues of tackling these challenges, using a diverse dataset of offline demonstrations that can be used to train robot manipulation agents, is very appealing. The Train-Offline-Test-Online (TOTO) Benchmark provides a well-curated open-source dataset for offline training comprised mostly of expert data and also benchmark scores of the common offline-RL and behaviour cloning agents. In this paper, we introduce DiffClone, an offline algorithm of enhanced behaviour cloning agent with diffusion-based policy learning, and measured the efficacy of our method on real online physical robots at test time. This is also our official submission to the Train-Offline-Test-Online (TOTO) Benchmark Challenge organized at NeurIPS 2023. We experimented with both pre-trained visual representation and agent policies. In our experiments, we find that MOCO finetuned ResNet50 performs the best in comparison to other finetuned",
    "link": "http://arxiv.org/abs/2401.09243",
    "context": "Title: DiffClone: Enhanced Behaviour Cloning in Robotics with Diffusion-Driven Policy Learning. (arXiv:2401.09243v1 [cs.RO])\nAbstract: Robot learning tasks are extremely compute-intensive and hardware-specific. Thus the avenues of tackling these challenges, using a diverse dataset of offline demonstrations that can be used to train robot manipulation agents, is very appealing. The Train-Offline-Test-Online (TOTO) Benchmark provides a well-curated open-source dataset for offline training comprised mostly of expert data and also benchmark scores of the common offline-RL and behaviour cloning agents. In this paper, we introduce DiffClone, an offline algorithm of enhanced behaviour cloning agent with diffusion-based policy learning, and measured the efficacy of our method on real online physical robots at test time. This is also our official submission to the Train-Offline-Test-Online (TOTO) Benchmark Challenge organized at NeurIPS 2023. We experimented with both pre-trained visual representation and agent policies. In our experiments, we find that MOCO finetuned ResNet50 performs the best in comparison to other finetuned",
    "path": "papers/24/01/2401.09243.json",
    "total_tokens": 934,
    "translated_title": "DiffClone: 使用扩散驱动的策略学习增强机器人行为克隆",
    "translated_abstract": "机器人学习任务在计算上非常密集且硬件特定。因此，通过使用多样化的离线演示数据集来训练机器人操作代理，来应对这些挑战的方式非常吸引人。Train-Offline-Test-Online（TOTO）基准提供了一个经过精心策划的开源离线训练数据集，主要由专家数据组成，并提供了常见离线强化学习和行为克隆代理的基准分数。在本文中，我们介绍了DiffClone，一种增强行为克隆代理的离线算法，采用基于扩散的策略学习，并在测试时在真实的在线物理机器人上评估了我们的方法的有效性。同时，这也是我们在NeurIPS 2023举办的Train-Offline-Test-Online（TOTO）基准挑战赛中的官方提交。我们尝试了预训练的视觉表示和代理策略。在实验中，我们发现MOCO微调的ResNet50相比其他微调方法表现最好。",
    "tldr": "本文介绍了DiffClone，一种通过扩散驱动的策略学习增强行为克隆代理的离线算法。在真实的在线物理机器人上的实验表明，采用MOCO微调的ResNet50的效果最好。",
    "en_tdlr": "This paper presents DiffClone, an offline algorithm of enhanced behaviour cloning agent with diffusion-driven policy learning. Experiments on real online physical robots show that using MOCO finetuned ResNet50 performs the best."
}