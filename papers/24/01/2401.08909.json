{
    "title": "Characterising Gradients for Unsupervised Accuracy Estimation under Distribution Shift. (arXiv:2401.08909v1 [cs.LG])",
    "abstract": "Estimating test accuracy without access to the ground-truth test labels under varying test environments is a challenging, yet extremely important problem in the safe deployment of machine learning algorithms. Existing works rely on the information from either the outputs or the extracted features of neural networks to formulate an estimation score correlating with the ground-truth test accuracy. In this paper, we investigate--both empirically and theoretically--how the information provided by the gradients can be predictive of the ground-truth test accuracy even under a distribution shift. Specifically, we use the norm of classification-layer gradients, backpropagated from the cross-entropy loss after only one gradient step over test data. Our key idea is that the model should be adjusted with a higher magnitude of gradients when it does not generalize to the test dataset with a distribution shift. We provide theoretical insights highlighting the main ingredients of such an approach en",
    "link": "http://arxiv.org/abs/2401.08909",
    "context": "Title: Characterising Gradients for Unsupervised Accuracy Estimation under Distribution Shift. (arXiv:2401.08909v1 [cs.LG])\nAbstract: Estimating test accuracy without access to the ground-truth test labels under varying test environments is a challenging, yet extremely important problem in the safe deployment of machine learning algorithms. Existing works rely on the information from either the outputs or the extracted features of neural networks to formulate an estimation score correlating with the ground-truth test accuracy. In this paper, we investigate--both empirically and theoretically--how the information provided by the gradients can be predictive of the ground-truth test accuracy even under a distribution shift. Specifically, we use the norm of classification-layer gradients, backpropagated from the cross-entropy loss after only one gradient step over test data. Our key idea is that the model should be adjusted with a higher magnitude of gradients when it does not generalize to the test dataset with a distribution shift. We provide theoretical insights highlighting the main ingredients of such an approach en",
    "path": "papers/24/01/2401.08909.json",
    "total_tokens": 830,
    "translated_title": "无监督准确性估计下分布偏移的梯度特征化研究",
    "translated_abstract": "在变化的测试环境下，无法访问真实测试标签的情况下估计测试准确性是机器学习算法安全部署中一个具有挑战性但极其重要的问题。现有的方法依赖于神经网络的输出或提取特征的信息来建立与真实测试准确性相关的估计分数。本文通过实证和理论研究探讨了梯度信息如何在分布偏移下对真实测试准确性进行预测。具体而言，我们使用从经过一次梯度步长的交叉熵损失函数后反向传播的分类层梯度范数来进行研究。我们的关键思想是，在模型在分布偏移下无法泛化到测试数据集时，应当调整模型以获得更大的梯度范数。我们提供理论见解，突出了这种方法的主要要素。",
    "tldr": "本文研究了在分布偏移下，利用梯度信息对真实测试准确性进行预测的方法。通过分析分类层梯度范数，我们发现在无法泛化到测试数据集时，调整模型以获得更大的梯度范数是有效的。"
}