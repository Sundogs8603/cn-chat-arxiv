{
    "title": "ProLex: A Benchmark for Language Proficiency-oriented Lexical Substitution",
    "abstract": "Lexical Substitution discovers appropriate substitutes for a given target word in a context sentence. However, the task fails to consider substitutes that are of equal or higher proficiency than the target, an aspect that could be beneficial for language learners looking to improve their writing. To bridge this gap, we propose a new task, language proficiency-oriented lexical substitution. We also introduce ProLex, a novel benchmark designed to assess systems' ability to generate not only appropriate substitutes but also substitutes that demonstrate better language proficiency. Besides the benchmark, we propose models that can automatically perform the new task. We show that our best model, a Llama2-13B model fine-tuned with task-specific synthetic data, outperforms ChatGPT by an average of 3.2% in F-score and achieves comparable results with GPT-4 on ProLex.",
    "link": "https://arxiv.org/abs/2401.11356",
    "context": "Title: ProLex: A Benchmark for Language Proficiency-oriented Lexical Substitution\nAbstract: Lexical Substitution discovers appropriate substitutes for a given target word in a context sentence. However, the task fails to consider substitutes that are of equal or higher proficiency than the target, an aspect that could be beneficial for language learners looking to improve their writing. To bridge this gap, we propose a new task, language proficiency-oriented lexical substitution. We also introduce ProLex, a novel benchmark designed to assess systems' ability to generate not only appropriate substitutes but also substitutes that demonstrate better language proficiency. Besides the benchmark, we propose models that can automatically perform the new task. We show that our best model, a Llama2-13B model fine-tuned with task-specific synthetic data, outperforms ChatGPT by an average of 3.2% in F-score and achieves comparable results with GPT-4 on ProLex.",
    "path": "papers/24/01/2401.11356.json",
    "total_tokens": 919,
    "translated_title": "ProLex: 一种以语言熟练度为导向的词汇替换评估基准",
    "translated_abstract": "词汇替换是在上下文句子中为给定的目标词找到合适的替代词。然而，这个任务没有考虑到与目标词同等或更高熟练度的替代词，这对于希望提高写作水平的语言学习者来说可能是有益的。为了弥补这个差距，我们提出了一项新任务，即以语言熟练度为导向的词汇替换。我们还引入了ProLex，一个新颖的基准，旨在评估系统生成不仅合适的替代词还要表现出更好语言熟练度的能力。除了基准，我们提出了可以自动执行这个新任务的模型。我们证明了我们最好的模型，即使用任务特定合成数据微调的Llama2-13B模型，在F分数上平均优于ChatGPT 3.2％，并在ProLex上与GPT-4取得可比较的结果。",
    "tldr": "ProLex是一个以语言熟练度为导向的词汇替换的评估基准，旨在评估生成适当替代词和表现更好语言熟练度的系统能力。使用微调任务特定合成数据的Llama2-13B模型在F分数上优于ChatGPT 3.2%，与GPT-4在ProLex上表现相当。",
    "en_tdlr": "ProLex is a benchmark for language proficiency-oriented lexical substitution, evaluating systems' ability to generate appropriate substitutes and demonstrate better language proficiency. The Llama2-13B model fine-tuned with task-specific synthetic data outperforms ChatGPT by 3.2% in F-score and achieves comparable results with GPT-4 on ProLex."
}