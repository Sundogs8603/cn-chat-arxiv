{
    "title": "Neglected Hessian component explains mysteries in Sharpness regularization. (arXiv:2401.10809v1 [cs.LG])",
    "abstract": "Recent work has shown that methods like SAM which either explicitly or implicitly penalize second order information can improve generalization in deep learning. Seemingly similar methods like weight noise and gradient penalties often fail to provide such benefits. We show that these differences can be explained by the structure of the Hessian of the loss. First, we show that a common decomposition of the Hessian can be quantitatively interpreted as separating the feature exploitation from feature exploration. The feature exploration, which can be described by the Nonlinear Modeling Error matrix (NME), is commonly neglected in the literature since it vanishes at interpolation. Our work shows that the NME is in fact important as it can explain why gradient penalties are sensitive to the choice of activation function. Using this insight we design interventions to improve performance. We also provide evidence that challenges the long held equivalence of weight noise and gradient penalties.",
    "link": "http://arxiv.org/abs/2401.10809",
    "context": "Title: Neglected Hessian component explains mysteries in Sharpness regularization. (arXiv:2401.10809v1 [cs.LG])\nAbstract: Recent work has shown that methods like SAM which either explicitly or implicitly penalize second order information can improve generalization in deep learning. Seemingly similar methods like weight noise and gradient penalties often fail to provide such benefits. We show that these differences can be explained by the structure of the Hessian of the loss. First, we show that a common decomposition of the Hessian can be quantitatively interpreted as separating the feature exploitation from feature exploration. The feature exploration, which can be described by the Nonlinear Modeling Error matrix (NME), is commonly neglected in the literature since it vanishes at interpolation. Our work shows that the NME is in fact important as it can explain why gradient penalties are sensitive to the choice of activation function. Using this insight we design interventions to improve performance. We also provide evidence that challenges the long held equivalence of weight noise and gradient penalties.",
    "path": "papers/24/01/2401.10809.json",
    "total_tokens": 1132,
    "translated_title": "被忽视的黑塞 (Hessian) 组件解释了锐化正则化中的谜团",
    "translated_abstract": "最近的研究表明，像SAM这样明确或隐含地惩罚二阶信息的方法可以提高深度学习中的泛化性能。类似的方法，如权重噪声和梯度惩罚，经常无法提供这样的好处。我们展示了这些差异可以通过损失的黑塞矩阵的结构来解释。首先，我们展示了常用的黑塞矩阵的分解可以定量解释为将特征的开发和特征的探索分开。特征的探索可以通过非线性建模误差矩阵(NME)来描述，这在文献中通常被忽视，因为它在插值中消失。我们的工作表明，NME事实上很重要，因为它可以解释为什么梯度惩罚对激活函数的选择敏感。利用这一见解，我们设计了改进性能的干预措施。我们也提供了证据来挑战了长期以来权重噪声和梯度惩罚的等效性。",
    "tldr": "这篇论文研究了在深度学习中，明确或隐含地惩罚二阶信息可以提高泛化性能，而权重噪声和梯度惩罚则很少能带来这样的好处。作者通过对损失的黑塞矩阵的结构进行解释，提出了特征的开发和特征的探索之间的量化分离。同时，作者发现忽视的非线性建模误差矩阵 (NME) 实际上很重要，可以解释为什么梯度惩罚对激活函数的选择非常敏感。此外，作者通过设计干预措施来改进性能，并提供了证据挑战了以往的观点，认为权重噪声和梯度惩罚是等效的。",
    "en_tdlr": "This paper explores the role of penalizing second order information in improving generalization in deep learning, and argues that methods such as weight noise and gradient penalties often fail to provide such benefits due to the neglect of an important component in the Hessian matrix called Nonlinear Modeling Error (NME). The authors propose a quantitative interpretation of a common decomposition of the Hessian matrix, separating feature exploitation from feature exploration, and provide evidence challenging the long-held equivalence of weight noise and gradient penalties."
}