{
    "title": "Causal Layering via Conditional Entropy. (arXiv:2401.10495v1 [cs.LG])",
    "abstract": "Causal discovery aims to recover information about an unobserved causal graph from the observable data it generates. Layerings are orderings of the variables which place causes before effects. In this paper, we provide ways to recover layerings of a graph by accessing the data via a conditional entropy oracle, when distributions are discrete. Our algorithms work by repeatedly removing sources or sinks from the graph. Under appropriate assumptions and conditioning, we can separate the sources or sinks from the remainder of the nodes by comparing their conditional entropy to the unconditional entropy of their noise. Our algorithms are provably correct and run in worst-case quadratic time. The main assumptions are faithfulness and injective noise, and either known noise entropies or weakly monotonically increasing noise entropies along directed paths. In addition, we require one of either a very mild extension of faithfulness, or strictly monotonically increasing noise entropies, or expan",
    "link": "http://arxiv.org/abs/2401.10495",
    "context": "Title: Causal Layering via Conditional Entropy. (arXiv:2401.10495v1 [cs.LG])\nAbstract: Causal discovery aims to recover information about an unobserved causal graph from the observable data it generates. Layerings are orderings of the variables which place causes before effects. In this paper, we provide ways to recover layerings of a graph by accessing the data via a conditional entropy oracle, when distributions are discrete. Our algorithms work by repeatedly removing sources or sinks from the graph. Under appropriate assumptions and conditioning, we can separate the sources or sinks from the remainder of the nodes by comparing their conditional entropy to the unconditional entropy of their noise. Our algorithms are provably correct and run in worst-case quadratic time. The main assumptions are faithfulness and injective noise, and either known noise entropies or weakly monotonically increasing noise entropies along directed paths. In addition, we require one of either a very mild extension of faithfulness, or strictly monotonically increasing noise entropies, or expan",
    "path": "papers/24/01/2401.10495.json",
    "total_tokens": 921,
    "translated_title": "条件熵下的因果层析",
    "translated_abstract": "因果发现旨在从可观测到的数据中恢复关于未观测到的因果图的信息。层析是对变量进行排序，将因果放在效应之前。在本文中，我们提供了通过访问条件熵Oracle来恢复图层析的方法，当分布是离散的时候。我们的算法通过不断从图中删除源或汇点来工作。在适当的假设和条件下，我们可以通过比较它们的条件熵与噪声的无条件熵来将源或汇点与其余节点分离开来。我们的算法在最坏情况下的时间复杂度是二次的，并且经过证明是正确的。主要的假设是忠实性和单射噪声，以及已知噪声熵或沿着有向路径弱单调递增的噪声熵之一。此外，我们需要忠实性的一个非常温和的扩展，或者严格单调递增的噪声熵，或者扩展到无限值。",
    "tldr": "本文提出了一种通过条件熵Oracle来恢复图层析的方法，用于离散分布情况下的因果发现。算法通过比较节点的条件熵和噪声的无条件熵，通过删除源或汇点来实现节点的分离。算法具有可证明的正确性和二次时间复杂度。",
    "en_tdlr": "This paper proposes a method for recovering graph layerings via conditional entropy Oracle in the context of discrete distributions for causal discovery. The algorithm separates nodes by comparing their conditional entropy to the unconditional entropy of noise and removing sources or sinks. The algorithms are provably correct and have a worst-case quadratic time complexity."
}