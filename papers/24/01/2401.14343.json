{
    "title": "Class-attribute Priors: Adapting Optimization to Heterogeneity and Fairness Objective. (arXiv:2401.14343v1 [cs.LG])",
    "abstract": "Modern classification problems exhibit heterogeneities across individual classes: Each class may have unique attributes, such as sample size, label quality, or predictability (easy vs difficult), and variable importance at test-time. Without care, these heterogeneities impede the learning process, most notably, when optimizing fairness objectives. Confirming this, under a gaussian mixture setting, we show that the optimal SVM classifier for balanced accuracy needs to be adaptive to the class attributes. This motivates us to propose CAP: An effective and general method that generates a class-specific learning strategy (e.g. hyperparameter) based on the attributes of that class. This way, optimization process better adapts to heterogeneities. CAP leads to substantial improvements over the naive approach of assigning separate hyperparameters to each class. We instantiate CAP for loss function design and post-hoc logit adjustment, with emphasis on label-imbalanced problems. We show that CA",
    "link": "http://arxiv.org/abs/2401.14343",
    "context": "Title: Class-attribute Priors: Adapting Optimization to Heterogeneity and Fairness Objective. (arXiv:2401.14343v1 [cs.LG])\nAbstract: Modern classification problems exhibit heterogeneities across individual classes: Each class may have unique attributes, such as sample size, label quality, or predictability (easy vs difficult), and variable importance at test-time. Without care, these heterogeneities impede the learning process, most notably, when optimizing fairness objectives. Confirming this, under a gaussian mixture setting, we show that the optimal SVM classifier for balanced accuracy needs to be adaptive to the class attributes. This motivates us to propose CAP: An effective and general method that generates a class-specific learning strategy (e.g. hyperparameter) based on the attributes of that class. This way, optimization process better adapts to heterogeneities. CAP leads to substantial improvements over the naive approach of assigning separate hyperparameters to each class. We instantiate CAP for loss function design and post-hoc logit adjustment, with emphasis on label-imbalanced problems. We show that CA",
    "path": "papers/24/01/2401.14343.json",
    "total_tokens": 860,
    "translated_title": "类属性先验：将优化方法应用于异质性和公平目标",
    "translated_abstract": "现代分类问题在各个类别之间存在异质性：每个类别可能具有独特的属性，例如样本大小，标签质量或可预测性（易 vs 难），以及在测试时的变量重要性。如果不注意处理，这些异质性会阻碍学习过程，尤其是在优化公平目标时。在高斯混合模型设定下，我们证明了为了达到平衡准确度，最优的支持向量机分类器需要适应类别属性。这激发了我们提出了CAP：一种基于类别属性生成类别特定学习策略（例如超参数）的有效和通用方法。通过这种方式，优化过程更好地适应异质性。CAP相比于将不同的超参数分配给每个类别的朴素方法有显著改进。我们将CAP实例化为损失函数设计和事后对数调整，重点关注标签不平衡问题。",
    "tldr": "本研究提出了一种名称为CAP的方法，通过生成类别特定的学习策略来更好地适应异质性数据，并在损失函数设计和标签不平衡问题方面取得了显著改进。",
    "en_tdlr": "This paper proposes a method called CAP which adapts the optimization process to heterogeneity by generating class-specific learning strategies, leading to substantial improvements in loss function design and addressing label-imbalanced problems."
}