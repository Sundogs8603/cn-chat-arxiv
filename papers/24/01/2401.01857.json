{
    "title": "Optimal cross-learning for contextual bandits with unknown context distributions. (arXiv:2401.01857v1 [cs.LG])",
    "abstract": "We consider the problem of designing contextual bandit algorithms in the ``cross-learning'' setting of Balseiro et al., where the learner observes the loss for the action they play in all possible contexts, not just the context of the current round. We specifically consider the setting where losses are chosen adversarially and contexts are sampled i.i.d. from an unknown distribution. In this setting, we resolve an open problem of Balseiro et al. by providing an efficient algorithm with a nearly tight (up to logarithmic factors) regret bound of $\\widetilde{O}(\\sqrt{TK})$, independent of the number of contexts. As a consequence, we obtain the first nearly tight regret bounds for the problems of learning to bid in first-price auctions (under unknown value distributions) and sleeping bandits with a stochastic action set.  At the core of our algorithm is a novel technique for coordinating the execution of a learning algorithm over multiple epochs in such a way to remove correlations between",
    "link": "http://arxiv.org/abs/2401.01857",
    "context": "Title: Optimal cross-learning for contextual bandits with unknown context distributions. (arXiv:2401.01857v1 [cs.LG])\nAbstract: We consider the problem of designing contextual bandit algorithms in the ``cross-learning'' setting of Balseiro et al., where the learner observes the loss for the action they play in all possible contexts, not just the context of the current round. We specifically consider the setting where losses are chosen adversarially and contexts are sampled i.i.d. from an unknown distribution. In this setting, we resolve an open problem of Balseiro et al. by providing an efficient algorithm with a nearly tight (up to logarithmic factors) regret bound of $\\widetilde{O}(\\sqrt{TK})$, independent of the number of contexts. As a consequence, we obtain the first nearly tight regret bounds for the problems of learning to bid in first-price auctions (under unknown value distributions) and sleeping bandits with a stochastic action set.  At the core of our algorithm is a novel technique for coordinating the execution of a learning algorithm over multiple epochs in such a way to remove correlations between",
    "path": "papers/24/01/2401.01857.json",
    "total_tokens": 928,
    "translated_title": "未知上下文分布下上下文赌博最优交叉学习",
    "translated_abstract": "我们考虑在Balseiro等人的“交叉学习”设置中设计上下文赌博算法的问题，其中学习器观察到在所有可能的上下文中他们所选择的动作的损失，而不仅仅是当前回合的上下文。我们特别考虑在损失被对抗性地选择和上下文从未知分布独立同分布采样的情况下。在这个设置中，我们通过提供一个效率算法解决了Balseiro等人的一个开放问题，其遗憾界几乎达到紧致水平（对数因子），为$\\widetilde{O}(\\sqrt{TK})$，不依赖于上下文的数量。因此，我们首次获得了在未知值分布的一价拍卖中学习出几乎紧致的遗憾界和具有随机动作集的睡觉赌徒问题。",
    "tldr": "本文提出了一种针对“交叉学习”设置的上下文赌博算法，在未知上下文分布的情况下，通过协调多个时期内的学习算法的执行，实现了几乎紧致的遗憾界。此算法解决了学习在一价拍卖和睡觉赌徒问题中的应用难题。"
}