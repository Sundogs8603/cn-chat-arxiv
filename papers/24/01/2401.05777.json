{
    "title": "Probing Structured Semantics Understanding and Generation of Language Models via Question Answering. (arXiv:2401.05777v1 [cs.CL])",
    "abstract": "Recent advancement in the capabilities of large language models (LLMs) has triggered a new surge in LLMs' evaluation. Most recent evaluation works tends to evaluate the comprehensive ability of LLMs over series of tasks. However, the deep structure understanding of natural language is rarely explored. In this work, we examine the ability of LLMs to deal with structured semantics on the tasks of question answering with the help of the human-constructed formal language. Specifically, we implement the inter-conversion of natural and formal language through in-context learning of LLMs to verify their ability to understand and generate the structured logical forms. Extensive experiments with models of different sizes and in different formal languages show that today's state-of-the-art LLMs' understanding of the logical forms can approach human level overall, but there still are plenty of room in generating correct logical forms, which suggest that it is more effective to use LLMs to generat",
    "link": "http://arxiv.org/abs/2401.05777",
    "context": "Title: Probing Structured Semantics Understanding and Generation of Language Models via Question Answering. (arXiv:2401.05777v1 [cs.CL])\nAbstract: Recent advancement in the capabilities of large language models (LLMs) has triggered a new surge in LLMs' evaluation. Most recent evaluation works tends to evaluate the comprehensive ability of LLMs over series of tasks. However, the deep structure understanding of natural language is rarely explored. In this work, we examine the ability of LLMs to deal with structured semantics on the tasks of question answering with the help of the human-constructed formal language. Specifically, we implement the inter-conversion of natural and formal language through in-context learning of LLMs to verify their ability to understand and generate the structured logical forms. Extensive experiments with models of different sizes and in different formal languages show that today's state-of-the-art LLMs' understanding of the logical forms can approach human level overall, but there still are plenty of room in generating correct logical forms, which suggest that it is more effective to use LLMs to generat",
    "path": "papers/24/01/2401.05777.json",
    "total_tokens": 824,
    "translated_title": "通过问答探索语言模型对结构化语义理解和生成的探索",
    "translated_abstract": "最近大型语言模型（LLM）的能力的进步引发了对LLM评估的新浪潮。最近的评估工作倾向于评估LLM在一系列任务上的综合能力。然而，对自然语言的深入结构理解很少被探索。在这项工作中，我们通过人工构建的形式语言，研究LLM处理结构化语义的能力，在问答任务中进行相互转换的自然语言和形式语言，并通过LLM的上下文学习来验证其理解和生成结构化逻辑形式的能力。通过对不同大小和不同形式语言的模型进行广泛实验，结果显示现今最先进的LLM在理解逻辑形式方面的能力整体上可以达到人类水平，但在生成正确逻辑形式方面仍有很大的改进空间，这表明使用LLM生成逻辑形式更为有效。",
    "tldr": "本研究通过问答任务探索语言模型对结构化语义的理解和生成能力，结果显示现今的语言模型在理解逻辑形式方面已接近人类水平，但在生成正确逻辑形式方面仍需要改进。"
}