{
    "title": "MM-Interleaved: Interleaved Image-Text Generative Modeling via Multi-modal Feature Synchronizer. (arXiv:2401.10208v1 [cs.CV])",
    "abstract": "Developing generative models for interleaved image-text data has both research and practical value. It requires models to understand the interleaved sequences and subsequently generate images and text. However, existing attempts are limited by the issue that the fixed number of visual tokens cannot efficiently capture image details, which is particularly problematic in the multi-image scenarios. To address this, this paper presents MM-Interleaved, an end-to-end generative model for interleaved image-text data. It introduces a multi-scale and multi-image feature synchronizer module, allowing direct access to fine-grained image features in the previous context during the generation process. MM-Interleaved is end-to-end pre-trained on both paired and interleaved image-text corpora. It is further enhanced through a supervised fine-tuning phase, wherein the model improves its ability to follow complex multi-modal instructions. Experiments demonstrate the versatility of MM-Interleaved in rec",
    "link": "http://arxiv.org/abs/2401.10208",
    "context": "Title: MM-Interleaved: Interleaved Image-Text Generative Modeling via Multi-modal Feature Synchronizer. (arXiv:2401.10208v1 [cs.CV])\nAbstract: Developing generative models for interleaved image-text data has both research and practical value. It requires models to understand the interleaved sequences and subsequently generate images and text. However, existing attempts are limited by the issue that the fixed number of visual tokens cannot efficiently capture image details, which is particularly problematic in the multi-image scenarios. To address this, this paper presents MM-Interleaved, an end-to-end generative model for interleaved image-text data. It introduces a multi-scale and multi-image feature synchronizer module, allowing direct access to fine-grained image features in the previous context during the generation process. MM-Interleaved is end-to-end pre-trained on both paired and interleaved image-text corpora. It is further enhanced through a supervised fine-tuning phase, wherein the model improves its ability to follow complex multi-modal instructions. Experiments demonstrate the versatility of MM-Interleaved in rec",
    "path": "papers/24/01/2401.10208.json",
    "total_tokens": 950,
    "translated_title": "MM-交错的：通过多模式特征同步器进行交错图像-文本生成建模",
    "translated_abstract": "对于交错图像-文本数据的生成模型的开发具有研究和实际价值。它要求模型理解交错的序列，并随后生成图像和文本。然而，现有的尝试受到了固定数量的视觉标记不能有效捕捉图像细节的问题的限制，在多图像场景中，这一问题尤为严重。为了解决这个问题，本文提出了MM-交错，这是一个用于交错图像-文本数据的端到端生成模型。它引入了一个多尺度和多图像特征同步器模块，允许在生成过程中直接访问先前上下文中的细粒度图像特征。MM-交错在配对和交错图像-文本语料库上进行端到端预训练。它还通过一阶段的监督微调来进一步改善其遵循复杂多模态指令的能力。实验结果表明了MM-交错在图像修复、图像生成和文本描述生成等任务中的多功能性。",
    "tldr": "本文提出了MM-交错，这是一个用于交错图像-文本数据的生成模型。它通过引入多尺度和多图像特征同步器模块，解决了现有模型在捕捉图像细节方面的限制，并通过端到端预训练和监督微调相结合的方式提高了其生成能力。",
    "en_tdlr": "MM-Interleaved is a generative model for interleaved image-text data that addresses the limitation of capturing image details by introducing a multi-scale and multi-image feature synchronizer module. It is enhanced through end-to-end pre-training and supervised fine-tuning, improving its generation capability."
}