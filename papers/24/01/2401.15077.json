{
    "title": "EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty. (arXiv:2401.15077v1 [cs.LG])",
    "abstract": "Auto-regressive decoding makes the inference of Large Language Models (LLMs) time-consuming. We propose a simple framework, EAGLE (Extrapolation Algorithm for Greater Language-model Efficiency), for lossless acceleration. Unlike traditional speculative sampling methods, EAGLE operates the drafting process auto-regressively at the more regular (second-top-layer) feature level and addresses the sampling uncertainty issues in the next-feature prediction problems by integrating tokens from one time step ahead. The acceleration provided by EAGLE is lossless: it involves no fine-tuning of the target LLM, and the generated text maintains the same distribution as that of vanilla auto-regressive decoding. As of the submission of this paper, EAGLE is the fastest known framework within the speculative sampling family. On MT-bench, EAGLE is 3x faster than vanilla decoding, 2x faster than Lookahead, and 1.6x faster than Medusa. Using gpt-fast, EAGLE attains on average 160 tokens/s with LLaMA2-Chat ",
    "link": "http://arxiv.org/abs/2401.15077",
    "context": "Title: EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty. (arXiv:2401.15077v1 [cs.LG])\nAbstract: Auto-regressive decoding makes the inference of Large Language Models (LLMs) time-consuming. We propose a simple framework, EAGLE (Extrapolation Algorithm for Greater Language-model Efficiency), for lossless acceleration. Unlike traditional speculative sampling methods, EAGLE operates the drafting process auto-regressively at the more regular (second-top-layer) feature level and addresses the sampling uncertainty issues in the next-feature prediction problems by integrating tokens from one time step ahead. The acceleration provided by EAGLE is lossless: it involves no fine-tuning of the target LLM, and the generated text maintains the same distribution as that of vanilla auto-regressive decoding. As of the submission of this paper, EAGLE is the fastest known framework within the speculative sampling family. On MT-bench, EAGLE is 3x faster than vanilla decoding, 2x faster than Lookahead, and 1.6x faster than Medusa. Using gpt-fast, EAGLE attains on average 160 tokens/s with LLaMA2-Chat ",
    "path": "papers/24/01/2401.15077.json",
    "total_tokens": 911,
    "translated_title": "EAGLE: 推测采样需要重新思考特征不确定性",
    "translated_abstract": "自回归解码使得大型语言模型（LLMs）的推理变得耗时。我们提出了一个简单的框架，EAGLE（用于提高语言模型效率的外推算法），实现了无损加速。与传统的推测采样方法不同，EAGLE在更规律的（次顶层）特征层面上自回归进行编写，并通过整合提前一个时间步的标记来解决下一个特征预测问题中的采样不确定性。EAGLE所提供的加速是无损的：它不需要微调目标LLM，并且生成的文本与原始的自回归解码的分布相同。截至本文提交时，EAGLE是已知推测采样家族中速度最快的框架。在MT-bench上，EAGLE比原始解码快3倍，比Lookahead快2倍，比Medusa快1.6倍。使用gpt-fast，EAGLE平均每秒达到160个标记与LLaMA2-Chat搭配。",
    "tldr": "EAGLE是一个无损加速语言模型推理的框架，通过在次顶层特征层面上自回归推理，并解决采样不确定性问题，实现了比传统方法更快3倍的速度。",
    "en_tdlr": "EAGLE is a lossless acceleration framework for language model inference, which achieves 3x faster speed than traditional methods by perform auto-regressive decoding at the second-top-layer feature level and addressing the sampling uncertainty issue."
}