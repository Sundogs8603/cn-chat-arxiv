{
    "title": "GI-PIP: Do We Require Impractical Auxiliary Dataset for Gradient Inversion Attacks?. (arXiv:2401.11748v2 [cs.CR] UPDATED)",
    "abstract": "Deep gradient inversion attacks expose a serious threat to Federated Learning (FL) by accurately recovering private data from shared gradients. However, the state-of-the-art heavily relies on impractical assumptions to access excessive auxiliary data, which violates the basic data partitioning principle of FL. In this paper, a novel method, Gradient Inversion Attack using Practical Image Prior (GI-PIP), is proposed under a revised threat model. GI-PIP exploits anomaly detection models to capture the underlying distribution from fewer data, while GAN-based methods consume significant more data to synthesize images. The extracted distribution is then leveraged to regulate the attack process as Anomaly Score loss. Experimental results show that GI-PIP achieves a 16.12 dB PSNR recovery using only 3.8% data of ImageNet, while GAN-based methods necessitate over 70%. Moreover, GI-PIP exhibits superior capability on distribution generalization compared to GAN-based methods. Our approach signif",
    "link": "http://arxiv.org/abs/2401.11748",
    "context": "Title: GI-PIP: Do We Require Impractical Auxiliary Dataset for Gradient Inversion Attacks?. (arXiv:2401.11748v2 [cs.CR] UPDATED)\nAbstract: Deep gradient inversion attacks expose a serious threat to Federated Learning (FL) by accurately recovering private data from shared gradients. However, the state-of-the-art heavily relies on impractical assumptions to access excessive auxiliary data, which violates the basic data partitioning principle of FL. In this paper, a novel method, Gradient Inversion Attack using Practical Image Prior (GI-PIP), is proposed under a revised threat model. GI-PIP exploits anomaly detection models to capture the underlying distribution from fewer data, while GAN-based methods consume significant more data to synthesize images. The extracted distribution is then leveraged to regulate the attack process as Anomaly Score loss. Experimental results show that GI-PIP achieves a 16.12 dB PSNR recovery using only 3.8% data of ImageNet, while GAN-based methods necessitate over 70%. Moreover, GI-PIP exhibits superior capability on distribution generalization compared to GAN-based methods. Our approach signif",
    "path": "papers/24/01/2401.11748.json",
    "total_tokens": 966,
    "translated_title": "GI-PIP：梯度反转攻击是否需要不切实际的辅助数据集？",
    "translated_abstract": "深度梯度反转攻击通过准确地恢复共享梯度中的隐私数据，对联邦学习构成了严重威胁。然而，现有技术在访问过多的辅助数据方面依赖于不切实际的假设，这违反了联邦学习的基本数据分区原则。本文提出了一种新颖的方法，即使用实用图像先验的梯度反转攻击（GI-PIP），在经过修订的威胁模型下。GI-PIP利用异常检测模型从更少的数据中捕获底层分布，而基于GAN的方法需要消耗更多的数据来合成图像。然后，利用提取出的分布来调节攻击过程作为异常得分损失。实验结果表明，GI-PIP只使用了ImageNet数据的3.8%即可实现16.12 dB的PSNR恢复，而基于GAN的方法则需要超过70%的数据。此外，与基于GAN的方法相比，GI-PIP在分布泛化方面表现出更强大的能力。",
    "tldr": "本文提出了一种新颖的梯度反转攻击方法GI-PIP，不需要依赖不切实际的辅助数据集，通过利用异常检测模型从较少的数据中捕获底层分布，并能在图像恢复方面表现出优异的能力，同时在分布泛化方面也更强大。",
    "en_tdlr": "This paper proposes GI-PIP, a novel gradient inversion attack method that does not rely on impractical auxiliary datasets. It captures the underlying distribution from fewer data using anomaly detection models and exhibits superior capability in image recovery and distribution generalization."
}