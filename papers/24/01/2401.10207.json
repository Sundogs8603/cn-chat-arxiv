{
    "title": "Eclectic Rule Extraction for Explainability of Deep Neural Network based Intrusion Detection Systems. (arXiv:2401.10207v1 [cs.CR])",
    "abstract": "This paper addresses trust issues created from the ubiquity of black box algorithms and surrogate explainers in Explainable Intrusion Detection Systems (X-IDS). While Explainable Artificial Intelligence (XAI) aims to enhance transparency, black box surrogate explainers, such as Local Interpretable Model-Agnostic Explanation (LIME) and SHapley Additive exPlanation (SHAP), are difficult to trust. The black box nature of these surrogate explainers makes the process behind explanation generation opaque and difficult to understand. To avoid this problem, one can use transparent white box algorithms such as Rule Extraction (RE). There are three types of RE algorithms: pedagogical, decompositional, and eclectic. Pedagogical methods offer fast but untrustworthy white-box explanations, while decompositional RE provides trustworthy explanations with poor scalability. This work explores eclectic rule extraction, which strikes a balance between scalability and trustworthiness. By combining techniq",
    "link": "http://arxiv.org/abs/2401.10207",
    "context": "Title: Eclectic Rule Extraction for Explainability of Deep Neural Network based Intrusion Detection Systems. (arXiv:2401.10207v1 [cs.CR])\nAbstract: This paper addresses trust issues created from the ubiquity of black box algorithms and surrogate explainers in Explainable Intrusion Detection Systems (X-IDS). While Explainable Artificial Intelligence (XAI) aims to enhance transparency, black box surrogate explainers, such as Local Interpretable Model-Agnostic Explanation (LIME) and SHapley Additive exPlanation (SHAP), are difficult to trust. The black box nature of these surrogate explainers makes the process behind explanation generation opaque and difficult to understand. To avoid this problem, one can use transparent white box algorithms such as Rule Extraction (RE). There are three types of RE algorithms: pedagogical, decompositional, and eclectic. Pedagogical methods offer fast but untrustworthy white-box explanations, while decompositional RE provides trustworthy explanations with poor scalability. This work explores eclectic rule extraction, which strikes a balance between scalability and trustworthiness. By combining techniq",
    "path": "papers/24/01/2401.10207.json",
    "total_tokens": 887,
    "translated_title": "用于解释性深度神经网络入侵检测系统的折衷规则提取",
    "translated_abstract": "本文针对黑盒算法和代理解释器在可解释性入侵检测系统(X-IDS)中所引发的信任问题进行研究。虽然可解释的人工智能(XAI)旨在提高透明度，但黑盒代理解释器，如局部可解释的模型无关解释(LIME)和SHapley加法解释(SHAP)，很难信任。这些代理解释器的黑盒特性使得解释生成的过程不透明且难以理解。为了避免这个问题，可以使用透明的白盒算法，如规则提取(RE)。规则提取有三种类型的算法:教育、分解和折衷。教育方法提供快速但不可信赖的白盒解释，而分解规则提取提供了可信赖但可扩展性较差的解释。本研究探讨了折衷规则提取，它在可扩展性和可信赖性之间达到了平衡。通过综合不同的技术方法，",
    "tldr": "本文研究了用于解释性深度神经网络入侵检测系统的折衷规则提取，旨在解决黑盒解释器的不可信任问题。",
    "en_tdlr": "This paper explores eclectic rule extraction for explainability of deep neural network based intrusion detection systems, aiming to address the trust issues created by black box explainers."
}