{
    "title": "Benchmarking the Fairness of Image Upsampling Methods. (arXiv:2401.13555v1 [cs.CV])",
    "abstract": "Recent years have witnessed a rapid development of deep generative models for creating synthetic media, such as images and videos. While the practical applications of these models in everyday tasks are enticing, it is crucial to assess the inherent risks regarding their fairness. In this work, we introduce a comprehensive framework for benchmarking the performance and fairness of conditional generative models. We develop a set of metrics$\\unicode{x2013}$inspired by their supervised fairness counterparts$\\unicode{x2013}$to evaluate the models on their fairness and diversity. Focusing on the specific application of image upsampling, we create a benchmark covering a wide variety of modern upsampling methods. As part of the benchmark, we introduce UnfairFace, a subset of FairFace that replicates the racial distribution of common large-scale face datasets. Our empirical study highlights the importance of using an unbiased training set and reveals variations in how the algorithms respond to ",
    "link": "http://arxiv.org/abs/2401.13555",
    "context": "Title: Benchmarking the Fairness of Image Upsampling Methods. (arXiv:2401.13555v1 [cs.CV])\nAbstract: Recent years have witnessed a rapid development of deep generative models for creating synthetic media, such as images and videos. While the practical applications of these models in everyday tasks are enticing, it is crucial to assess the inherent risks regarding their fairness. In this work, we introduce a comprehensive framework for benchmarking the performance and fairness of conditional generative models. We develop a set of metrics$\\unicode{x2013}$inspired by their supervised fairness counterparts$\\unicode{x2013}$to evaluate the models on their fairness and diversity. Focusing on the specific application of image upsampling, we create a benchmark covering a wide variety of modern upsampling methods. As part of the benchmark, we introduce UnfairFace, a subset of FairFace that replicates the racial distribution of common large-scale face datasets. Our empirical study highlights the importance of using an unbiased training set and reveals variations in how the algorithms respond to ",
    "path": "papers/24/01/2401.13555.json",
    "total_tokens": 903,
    "translated_title": "图像上采样方法的公平性基准测试",
    "translated_abstract": "近年来，深度生成模型在创建合成媒体（如图像和视频）方面取得了快速发展。虽然这些模型在日常任务中的实际应用非常诱人，但评估其公平性相关的潜在风险至关重要。在这项工作中，我们引入了一个全面的框架，用于评估有条件生成模型的性能和公平性。我们开发了一套度量标准——受监督公平性的灵感来源——来评估模型的公平性和多样性。我们针对图像上采样这个特定应用，创建了一个涵盖各种现代上采样方法的基准测试。作为基准测试的一部分，我们引入了UnfairFace，这是FairFace的一个子集，复制了常见大规模人脸数据集的种族分布。我们的实证研究凸显了使用无偏训练集的重要性，并揭示了算法对该问题的响应变化。",
    "tldr": "这项工作提出了一个评估有条件生成模型性能和公平性的框架，并针对图像上采样应用创建了一个涵盖现代方法的基准测试。实证研究发现使用无偏训练集对结果至关重要，并揭示了不同算法对该问题的响应变化。",
    "en_tdlr": "This work introduces a framework for evaluating the performance and fairness of conditional generative models, focusing on image upsampling application. A comprehensive benchmark is created to cover modern methods, highlighting the importance of an unbiased training set and revealing variations in algorithm responses to the problem."
}