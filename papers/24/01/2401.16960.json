{
    "title": "Two Heads Are Better Than One: Integrating Knowledge from Knowledge Graphs and Large Language Models for Entity Alignment. (arXiv:2401.16960v1 [cs.CL])",
    "abstract": "Entity alignment, which is a prerequisite for creating a more comprehensive Knowledge Graph (KG), involves pinpointing equivalent entities across disparate KGs. Contemporary methods for entity alignment have predominantly utilized knowledge embedding models to procure entity embeddings that encapsulate various similarities-structural, relational, and attributive. These embeddings are then integrated through attention-based information fusion mechanisms. Despite this progress, effectively harnessing multifaceted information remains challenging due to inherent heterogeneity. Moreover, while Large Language Models (LLMs) have exhibited exceptional performance across diverse downstream tasks by implicitly capturing entity semantics, this implicit knowledge has yet to be exploited for entity alignment. In this study, we propose a Large Language Model-enhanced Entity Alignment framework (LLMEA), integrating structural knowledge from KGs with semantic knowledge from LLMs to enhance entity alig",
    "link": "http://arxiv.org/abs/2401.16960",
    "context": "Title: Two Heads Are Better Than One: Integrating Knowledge from Knowledge Graphs and Large Language Models for Entity Alignment. (arXiv:2401.16960v1 [cs.CL])\nAbstract: Entity alignment, which is a prerequisite for creating a more comprehensive Knowledge Graph (KG), involves pinpointing equivalent entities across disparate KGs. Contemporary methods for entity alignment have predominantly utilized knowledge embedding models to procure entity embeddings that encapsulate various similarities-structural, relational, and attributive. These embeddings are then integrated through attention-based information fusion mechanisms. Despite this progress, effectively harnessing multifaceted information remains challenging due to inherent heterogeneity. Moreover, while Large Language Models (LLMs) have exhibited exceptional performance across diverse downstream tasks by implicitly capturing entity semantics, this implicit knowledge has yet to be exploited for entity alignment. In this study, we propose a Large Language Model-enhanced Entity Alignment framework (LLMEA), integrating structural knowledge from KGs with semantic knowledge from LLMs to enhance entity alig",
    "path": "papers/24/01/2401.16960.json",
    "total_tokens": 898,
    "translated_title": "两个头胜于一: 为实体对齐整合知识图谱和大型语言模型的知识",
    "translated_abstract": "实体对齐是创建更全面的知识图谱的先决条件，涉及在不同的知识图谱中定位等价实体。目前的实体对齐方法主要利用知识嵌入模型获取包含各种相似性（结构、关系和属性）的实体嵌入。然后通过基于注意力的信息融合机制进行集成。尽管取得了一定的进展，但由于固有的异质性，有效利用多方面的信息仍然具有挑战性。此外，虽然大型语言模型（LLM）通过隐式捕捉实体语义，在各种下游任务上表现出色，但这种隐式知识尚未被用于实体对齐。在本研究中，我们提出了一个增强实体对齐的大型语言模型增强实体对齐框架（LLMEA），将知识图谱中的结构知识与LLM中的语义知识相结合，以增强实体对齐。",
    "tldr": "本研究提出了一种大型语言模型增强的实体对齐框架（LLMEA），将知识图谱中的结构知识与大型语言模型中的语义知识相结合，以提升实体对齐的效果。",
    "en_tdlr": "This study proposes a Large Language Model-enhanced Entity Alignment framework (LLMEA) that combines structural knowledge from Knowledge Graphs with semantic knowledge from Large Language Models (LLMs) to improve the effectiveness of entity alignment."
}