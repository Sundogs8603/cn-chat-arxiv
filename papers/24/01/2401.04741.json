{
    "title": "Masked AutoEncoder for Graph Clustering without Pre-defined Cluster Number k. (arXiv:2401.04741v1 [cs.LG])",
    "abstract": "Graph clustering algorithms with autoencoder structures have recently gained popularity due to their efficient performance and low training cost. However, for existing graph autoencoder clustering algorithms based on GCN or GAT, not only do they lack good generalization ability, but also the number of clusters clustered by such autoencoder models is difficult to determine automatically. To solve this problem, we propose a new framework called Graph Clustering with Masked Autoencoders (GCMA). It employs our designed fusion autoencoder based on the graph masking method for the fusion coding of graph. It introduces our improved density-based clustering algorithm as a second decoder while decoding with multi-target reconstruction. By decoding the mask embedding, our model can capture more generalized and comprehensive knowledge. The number of clusters and clustering results can be output end-to-end while improving the generalization ability. As a nonparametric class method, extensive exper",
    "link": "http://arxiv.org/abs/2401.04741",
    "context": "Title: Masked AutoEncoder for Graph Clustering without Pre-defined Cluster Number k. (arXiv:2401.04741v1 [cs.LG])\nAbstract: Graph clustering algorithms with autoencoder structures have recently gained popularity due to their efficient performance and low training cost. However, for existing graph autoencoder clustering algorithms based on GCN or GAT, not only do they lack good generalization ability, but also the number of clusters clustered by such autoencoder models is difficult to determine automatically. To solve this problem, we propose a new framework called Graph Clustering with Masked Autoencoders (GCMA). It employs our designed fusion autoencoder based on the graph masking method for the fusion coding of graph. It introduces our improved density-based clustering algorithm as a second decoder while decoding with multi-target reconstruction. By decoding the mask embedding, our model can capture more generalized and comprehensive knowledge. The number of clusters and clustering results can be output end-to-end while improving the generalization ability. As a nonparametric class method, extensive exper",
    "path": "papers/24/01/2401.04741.json",
    "total_tokens": 868,
    "translated_title": "无预定义聚类数k的图聚类的Masked AutoEncoder",
    "translated_abstract": "最近，基于自编码器结构的图聚类算法因其高效性能和低训练成本而受到广泛关注。然而，对于基于GCN或GAT的现有图自编码聚类算法，它们不仅缺乏良好的泛化能力，而且难以自动确定由此类自编码模型聚类的簇数。为了解决这个问题，我们提出了一种新的框架，称为Masked Autoencoders进行图聚类（GCMA）。它采用基于图屏蔽方法的融合自编码器进行图的融合编码。它引入我们改进的基于密度的聚类算法作为第二个解码器，在多目标重建时解码。通过解码掩码嵌入，我们的模型可以捕获更广义和全面的知识。在提高泛化能力的同时可以输出聚类数和聚类结果。作为一种非参数类方法，我们进行了大量的实验...",
    "tldr": "本论文提出了一种新的图聚类方法，通过加入掩码自编码器和改进的基于密度的聚类算法，能够在没有预定义的聚类数情况下实现高效的图聚类，并具有良好的泛化能力。",
    "en_tdlr": "This paper proposes a novel approach for graph clustering that achieves efficient clustering without pre-defined cluster number and has good generalization ability, by incorporating masked autoencoders and improved density-based clustering algorithm."
}