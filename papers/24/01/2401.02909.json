{
    "title": "Introducing Bode: A Fine-Tuned Large Language Model for Portuguese Prompt-Based Task. (arXiv:2401.02909v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) are increasingly bringing advances to Natural Language Processing. However, low-resource languages, those lacking extensive prominence in datasets for various NLP tasks, or where existing datasets are not as substantial, such as Portuguese, already obtain several benefits from LLMs, but not to the same extent. LLMs trained on multilingual datasets normally struggle to respond to prompts in Portuguese satisfactorily, presenting, for example, code switching in their responses. This work proposes a fine-tuned LLaMA 2-based model for Portuguese prompts named Bode in two versions: 7B and 13B. We evaluate the performance of this model in classification tasks using the zero-shot approach with in-context learning, and compare it with other LLMs. Our main contribution is to bring an LLM with satisfactory results in the Portuguese language, as well as to provide a model that is free for research or commercial purposes.",
    "link": "http://arxiv.org/abs/2401.02909",
    "context": "Title: Introducing Bode: A Fine-Tuned Large Language Model for Portuguese Prompt-Based Task. (arXiv:2401.02909v1 [cs.CL])\nAbstract: Large Language Models (LLMs) are increasingly bringing advances to Natural Language Processing. However, low-resource languages, those lacking extensive prominence in datasets for various NLP tasks, or where existing datasets are not as substantial, such as Portuguese, already obtain several benefits from LLMs, but not to the same extent. LLMs trained on multilingual datasets normally struggle to respond to prompts in Portuguese satisfactorily, presenting, for example, code switching in their responses. This work proposes a fine-tuned LLaMA 2-based model for Portuguese prompts named Bode in two versions: 7B and 13B. We evaluate the performance of this model in classification tasks using the zero-shot approach with in-context learning, and compare it with other LLMs. Our main contribution is to bring an LLM with satisfactory results in the Portuguese language, as well as to provide a model that is free for research or commercial purposes.",
    "path": "papers/24/01/2401.02909.json",
    "total_tokens": 907,
    "translated_title": "引入 Bode：针对基于葡萄牙语提示的任务的精调大型语言模型",
    "translated_abstract": "大型语言模型（LLM）越来越多地为自然语言处理带来了进展。然而，低资源语言，即在各种NLP任务的数据集中缺乏广泛关注或现有数据集不够充分的语言（如葡萄牙语），已经从LLM中获得了几个好处，但程度上不及其他语言。在多语言数据集上训练的LLM通常难以令人满意地回应葡萄牙语提示，例如，在回应中出现代码切换。本文提出了一种针对葡萄牙语提示的精调LLaMA 2模型，命名为Bode，分为7B和13B两个版本。我们使用零样本方法和上下文学习评估了该模型在分类任务中的性能，并将其与其他LLM进行了比较。我们的主要贡献是提供了一个在葡萄牙语中具有令人满意结果的LLM，并且可供研究或商业目的免费使用。",
    "tldr": "该论文介绍了一种精调的大型语言模型Bode，针对葡萄牙语提示的任务，该模型在分类任务中表现出令人满意的结果，并且可供免费用于研究或商业目的。",
    "en_tdlr": "This paper introduces a fine-tuned large language model called Bode for Portuguese prompt-based tasks. The model performs well in classification tasks and is available for free for research or commercial purposes."
}