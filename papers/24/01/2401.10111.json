{
    "title": "Marrying Adapters and Mixup to Efficiently Enhance the Adversarial Robustness of Pre-Trained Language Models for Text Classification. (arXiv:2401.10111v1 [cs.CL])",
    "abstract": "Existing works show that augmenting training data of neural networks using both clean and adversarial examples can enhance their generalizability under adversarial attacks. However, this training approach often leads to performance degradation on clean inputs. Additionally, it requires frequent re-training of the entire model to account for new attack types, resulting in significant and costly computations. Such limitations make adversarial training mechanisms less practical, particularly for complex Pre-trained Language Models (PLMs) with millions or even billions of parameters. To overcome these challenges while still harnessing the theoretical benefits of adversarial training, this study combines two concepts: (1) adapters, which enable parameter-efficient fine-tuning, and (2) Mixup, which train NNs via convex combinations of pairs data pairs. Intuitively, we propose to fine-tune PLMs through convex combinations of non-data pairs of fine-tuned adapters, one trained with clean and an",
    "link": "http://arxiv.org/abs/2401.10111",
    "context": "Title: Marrying Adapters and Mixup to Efficiently Enhance the Adversarial Robustness of Pre-Trained Language Models for Text Classification. (arXiv:2401.10111v1 [cs.CL])\nAbstract: Existing works show that augmenting training data of neural networks using both clean and adversarial examples can enhance their generalizability under adversarial attacks. However, this training approach often leads to performance degradation on clean inputs. Additionally, it requires frequent re-training of the entire model to account for new attack types, resulting in significant and costly computations. Such limitations make adversarial training mechanisms less practical, particularly for complex Pre-trained Language Models (PLMs) with millions or even billions of parameters. To overcome these challenges while still harnessing the theoretical benefits of adversarial training, this study combines two concepts: (1) adapters, which enable parameter-efficient fine-tuning, and (2) Mixup, which train NNs via convex combinations of pairs data pairs. Intuitively, we propose to fine-tune PLMs through convex combinations of non-data pairs of fine-tuned adapters, one trained with clean and an",
    "path": "papers/24/01/2401.10111.json",
    "total_tokens": 1016,
    "translated_title": "将适配器和Mixup相结合，以增强预训练语言模型在文本分类中的对抗鲁棒性",
    "translated_abstract": "现有的研究表明，使用干净和对抗性样本来增强神经网络的训练数据可以提高其在对抗攻击下的泛化能力。然而，这种训练方法往往会导致对清洁输入的性能下降。另外，它需要频繁地重新训练整个模型，以适应新的攻击类型，从而导致昂贵且计算量大的计算。这些限制使得对抗训练机制的实际应用变得不太实用，特别是对于具有数百万甚至数十亿参数的复杂预训练语言模型（PLMs）。为了克服这些挑战，同时利用对抗训练的理论益处，本研究将两个概念相结合：（1）适配器，可实现参数高效微调，和（2）Mixup，通过数据对的凸组合训练NNs。直观地说，我们建议通过非数据对的适配器的凸组合来微调PLMs，其中一个适配器使用干净的样本训练，另一个使用对抗性的样本训练。",
    "tldr": "本研究将适配器和Mixup相结合，以在不需要频繁重新训练整个模型的情况下增强预训练语言模型的对抗鲁棒性，通过使用适配器的凸组合和非数据对的训练，解决了对抗训练方法在性能下降和计算开销方面的限制。"
}