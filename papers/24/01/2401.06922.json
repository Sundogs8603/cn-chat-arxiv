{
    "title": "Open RAN LSTM Traffic Prediction and Slice Management using Deep Reinforcement Learning. (arXiv:2401.06922v1 [cs.LG])",
    "abstract": "With emerging applications such as autonomous driving, smart cities, and smart factories, network slicing has become an essential component of 5G and beyond networks as a means of catering to a service-aware network. However, managing different network slices while maintaining quality of services (QoS) is a challenge in a dynamic environment. To address this issue, this paper leverages the heterogeneous experiences of distributed units (DUs) in ORAN systems and introduces a novel approach to ORAN slicing xApp using distributed deep reinforcement learning (DDRL). Additionally, to enhance the decision-making performance of the RL agent, a prediction rApp based on long short-term memory (LSTM) is incorporated to provide additional information from the dynamic environment to the xApp. Simulation results demonstrate significant improvements in network performance, particularly in reducing QoS violations. This emphasizes the importance of using the prediction rApp and distributed actors' inf",
    "link": "http://arxiv.org/abs/2401.06922",
    "context": "Title: Open RAN LSTM Traffic Prediction and Slice Management using Deep Reinforcement Learning. (arXiv:2401.06922v1 [cs.LG])\nAbstract: With emerging applications such as autonomous driving, smart cities, and smart factories, network slicing has become an essential component of 5G and beyond networks as a means of catering to a service-aware network. However, managing different network slices while maintaining quality of services (QoS) is a challenge in a dynamic environment. To address this issue, this paper leverages the heterogeneous experiences of distributed units (DUs) in ORAN systems and introduces a novel approach to ORAN slicing xApp using distributed deep reinforcement learning (DDRL). Additionally, to enhance the decision-making performance of the RL agent, a prediction rApp based on long short-term memory (LSTM) is incorporated to provide additional information from the dynamic environment to the xApp. Simulation results demonstrate significant improvements in network performance, particularly in reducing QoS violations. This emphasizes the importance of using the prediction rApp and distributed actors' inf",
    "path": "papers/24/01/2401.06922.json",
    "total_tokens": 888,
    "translated_title": "使用深度强化学习进行Open RAN LSTM流量预测和切片管理",
    "translated_abstract": "随着自动驾驶、智慧城市和智能工厂等新兴应用的出现，网络切片成为5G及以上网络中满足面向服务的网络需求的关键组成部分。然而，在动态环境中管理不同的网络切片并保持服务质量(QoS)是一个挑战。为解决这个问题，本文利用ORAN系统中分布式单元(DUs)的异构经验，引入了一种使用分布式深度强化学习(DDRL)的ORAN切片xApp的新方法。此外，为了提高强化学习代理的决策性能，还引入了基于长短期记忆(LSTM)的预测rApp，从动态环境中提供额外信息给xApp。模拟结果表明网络性能有了显著的改进，尤其在降低QoS违规方面表现出色。这凸显了使用预测rApp和分布式actor的重要性。",
    "tldr": "本文提出了一种使用深度强化学习进行Open RAN LSTM流量预测和切片管理的方法，在保持服务质量的前提下，通过利用分布式单元的异构经验和预测模型的辅助信息，显著改善了网络性能。",
    "en_tdlr": "This paper proposes a method for Open RAN LSTM traffic prediction and slice management using deep reinforcement learning. By leveraging heterogeneous experiences of distributed units and incorporating a prediction model, the network performance is significantly improved while maintaining quality of services."
}