{
    "title": "The NPU-ASLP-LiAuto System Description for Visual Speech Recognition in CNVSRC 2023",
    "abstract": "arXiv:2401.06788v2 Announce Type: replace-cross  Abstract: This paper delineates the visual speech recognition (VSR) system introduced by the NPU-ASLP-LiAuto (Team 237) in the first Chinese Continuous Visual Speech Recognition Challenge (CNVSRC) 2023, engaging in the fixed and open tracks of Single-Speaker VSR Task, and the open track of Multi-Speaker VSR Task. In terms of data processing, we leverage the lip motion extractor from the baseline1 to produce multi-scale video data. Besides, various augmentation techniques are applied during training, encompassing speed perturbation, random rotation, horizontal flipping, and color transformation. The VSR model adopts an end-to-end architecture with joint CTC/attention loss, comprising a ResNet3D visual frontend, an E-Branchformer encoder, and a Transformer decoder. Experiments show that our system achieves 34.76% CER for the Single-Speaker Task and 41.06% CER for the Multi-Speaker Task after multi-system fusion, ranking first place in all ",
    "link": "https://arxiv.org/abs/2401.06788",
    "context": "Title: The NPU-ASLP-LiAuto System Description for Visual Speech Recognition in CNVSRC 2023\nAbstract: arXiv:2401.06788v2 Announce Type: replace-cross  Abstract: This paper delineates the visual speech recognition (VSR) system introduced by the NPU-ASLP-LiAuto (Team 237) in the first Chinese Continuous Visual Speech Recognition Challenge (CNVSRC) 2023, engaging in the fixed and open tracks of Single-Speaker VSR Task, and the open track of Multi-Speaker VSR Task. In terms of data processing, we leverage the lip motion extractor from the baseline1 to produce multi-scale video data. Besides, various augmentation techniques are applied during training, encompassing speed perturbation, random rotation, horizontal flipping, and color transformation. The VSR model adopts an end-to-end architecture with joint CTC/attention loss, comprising a ResNet3D visual frontend, an E-Branchformer encoder, and a Transformer decoder. Experiments show that our system achieves 34.76% CER for the Single-Speaker Task and 41.06% CER for the Multi-Speaker Task after multi-system fusion, ranking first place in all ",
    "path": "papers/24/01/2401.06788.json",
    "total_tokens": 938,
    "translated_title": "NPU-ASLP-LiAuto团队在CNVSRC 2023中视觉语音识别系统描述",
    "translated_abstract": "本文描述了NPU-ASLP-LiAuto（Team 237）在2023年第一届中国连续视觉语音识别挑战赛（CNVSRC）中推出的视觉语音识别（VSR）系统，参与了单说话者VSR任务的固定和开放轨迹，以及多说话者VSR任务的开放轨迹。在数据处理方面，我们利用基线1中的唇部运动提取器生成多尺度视频数据。此外，训练过程中应用了各种增强技术，包括速度扰动、随机旋转、水平翻转和颜色转换。VSR模型采用了端到端架构，联合CTC/注意力损失，包括ResNet3D视觉前端、E-Branchformer编码器和Transformer解码器。实验表明，我们的系统在多系统融合后实现了单说话者任务的34.76% CER和多说话者任务的41.06% CER，排名第一。",
    "tldr": "NPU-ASLP-LiAuto团队在2023年CNVSRC中提出了一种视觉语音识别系统，采用端到端架构和多样的数据处理和增强技术，取得了在单说话者和多说话者任务中的优异表现，排名第一。"
}