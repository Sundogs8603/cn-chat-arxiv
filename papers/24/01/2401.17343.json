{
    "title": "YTCommentQA: Video Question Answerability in Instructional Videos",
    "abstract": "Instructional videos provide detailed how-to guides for various tasks, with viewers often posing questions regarding the content. Addressing these questions is vital for comprehending the content, yet receiving immediate answers is difficult. While numerous computational models have been developed for Video Question Answering (Video QA) tasks, they are primarily trained on questions generated based on video content, aiming to produce answers from within the content. However, in real-world situations, users may pose questions that go beyond the video's informational boundaries, highlighting the necessity to determine if a video can provide the answer. Discerning whether a question can be answered by video content is challenging due to the multi-modal nature of videos, where visual and verbal information are intertwined. To bridge this gap, we present the YTCommentQA dataset, which contains naturally-generated questions from YouTube, categorized by their answerability and required modali",
    "link": "https://arxiv.org/abs/2401.17343",
    "context": "Title: YTCommentQA: Video Question Answerability in Instructional Videos\nAbstract: Instructional videos provide detailed how-to guides for various tasks, with viewers often posing questions regarding the content. Addressing these questions is vital for comprehending the content, yet receiving immediate answers is difficult. While numerous computational models have been developed for Video Question Answering (Video QA) tasks, they are primarily trained on questions generated based on video content, aiming to produce answers from within the content. However, in real-world situations, users may pose questions that go beyond the video's informational boundaries, highlighting the necessity to determine if a video can provide the answer. Discerning whether a question can be answered by video content is challenging due to the multi-modal nature of videos, where visual and verbal information are intertwined. To bridge this gap, we present the YTCommentQA dataset, which contains naturally-generated questions from YouTube, categorized by their answerability and required modali",
    "path": "papers/24/01/2401.17343.json",
    "total_tokens": 800,
    "translated_title": "YTCommentQA: 指导视频中的问题可回答性",
    "translated_abstract": "指导视频为各种任务提供了详细的如何操作指南，观众通常会就内容提出问题。解答这些问题对于理解内容至关重要，但是很难立即获得答案。目前已经开发了许多用于视频问题回答（Video QA）任务的计算模型，但它们主要是根据视频内容生成问题，旨在从内容中产生答案。然而，在现实世界的情况下，用户可能提出超出视频信息边界的问题，这突显出确定视频是否能提供答案的必要性。由于视频具有多模态性，视觉和口头信息交织在一起，因此判断一个问题是否可以通过视频内容回答是具有挑战性的。为了弥补这一差距，我们提出了YTCommentQA数据集，其中包含从YouTube生成的自然问题，根据其可回答性和所需模态进行了分类。",
    "tldr": "本研究提出了YTCommentQA数据集，通过收集来自YouTube的自然问题，分类其可回答性和所需模态，以解决指导视频中的问题可回答性问题。",
    "en_tdlr": "This paper presents the YTCommentQA dataset, which categorizes naturally-generated questions from YouTube based on their answerability and required modality, addressing the issue of question answerability in instructional videos."
}