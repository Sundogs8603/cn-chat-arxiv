{
    "title": "Mining experimental data from Materials Science literature with Large Language Models. (arXiv:2401.11052v1 [cs.CL])",
    "abstract": "This study is dedicated to evaluating the capabilities of advanced large language models (LLMs) such as GPT-3.5-Turbo, GPT-4, and GPT-4-Turbo in the extraction of structured information from scientific documents within the field of materials science. We introduce a novel methodology for the comparative analysis of intricate material expressions, emphasising the standardisation of chemical formulas to tackle the complexities inherent in materials science information assessment. To this end, we primarily focus on two critical tasks of information extraction: (i) a named entity recognition (NER) of studied materials and physical properties and (ii) a relation extraction (RE) between these entities. The performance of LLMs in executing these tasks is benchmarked against traditional models based on the BERT architecture and rule-based approaches. For NER, LLMs fail to outperform the baseline with zero-shot prompting and exhibit only limited improvement with few-shot prompting. However, for ",
    "link": "http://arxiv.org/abs/2401.11052",
    "context": "Title: Mining experimental data from Materials Science literature with Large Language Models. (arXiv:2401.11052v1 [cs.CL])\nAbstract: This study is dedicated to evaluating the capabilities of advanced large language models (LLMs) such as GPT-3.5-Turbo, GPT-4, and GPT-4-Turbo in the extraction of structured information from scientific documents within the field of materials science. We introduce a novel methodology for the comparative analysis of intricate material expressions, emphasising the standardisation of chemical formulas to tackle the complexities inherent in materials science information assessment. To this end, we primarily focus on two critical tasks of information extraction: (i) a named entity recognition (NER) of studied materials and physical properties and (ii) a relation extraction (RE) between these entities. The performance of LLMs in executing these tasks is benchmarked against traditional models based on the BERT architecture and rule-based approaches. For NER, LLMs fail to outperform the baseline with zero-shot prompting and exhibit only limited improvement with few-shot prompting. However, for ",
    "path": "papers/24/01/2401.11052.json",
    "total_tokens": 930,
    "translated_title": "使用大型语言模型从材料科学文献中挖掘实验数据",
    "translated_abstract": "本研究致力于评估先进的大型语言模型（LLMs），如GPT-3.5-Turbo、GPT-4和GPT-4-Turbo，在材料科学领域科学文档中提取结构化信息的能力。我们引入了一种新颖的方法，用于比较分析复杂的材料表达式，强调化学式的标准化，以解决材料科学信息评估中固有的复杂性。为此，我们主要关注信息提取的两个关键任务：（i）研究材料和物理性质的命名实体识别（NER）和（ii）这些实体之间的关系提取（RE）。LLMs在执行这些任务时的表现与基于BERT架构和基于规则的传统模型进行了基准测试。对于NER，LLMs在零-shot提示下无法超越基准线，并且仅在少数-shot提示下有少量改进。然而，对于...",
    "tldr": "本研究评估了使用大型语言模型从材料科学文献中提取结构化信息的能力，并引入了一种新颖的方法来处理材料科学信息的复杂性。在命名实体识别和关系提取任务上，LLMs与传统模型相比表现有限，但在少数-shot提示下有一定的改进。",
    "en_tdlr": "This study evaluates the capability of large language models (LLMs) in extracting structured information from materials science literature and introduces a novel approach to address the complexities involved. The LLMs perform moderately in named entity recognition and relation extraction tasks compared to traditional models, but show some improvement with few-shot prompting."
}