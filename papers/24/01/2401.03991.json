{
    "title": "Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark. (arXiv:2401.03991v1 [cs.AI] CROSS LISTED)",
    "abstract": "Artificial intelligence (AI) has made remarkable progress across various domains, with large language models like ChatGPT gaining substantial attention for their human-like text-generation capabilities. Despite these achievements, spatial reasoning remains a significant challenge for these models. Benchmarks like StepGame evaluate AI spatial reasoning, where ChatGPT has shown unsatisfactory performance. However, the presence of template errors in the benchmark has an impact on the evaluation results. Thus there is potential for ChatGPT to perform better if these template errors are addressed, leading to more accurate assessments of its spatial reasoning capabilities. In this study, we refine the StepGame benchmark, providing a more accurate dataset for model evaluation. We analyze GPT's spatial reasoning performance on the rectified benchmark, identifying proficiency in mapping natural language text to spatial relations but limitations in multi-hop reasoning. We provide a flawless solu",
    "link": "http://arxiv.org/abs/2401.03991",
    "context": "Title: Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark. (arXiv:2401.03991v1 [cs.AI] CROSS LISTED)\nAbstract: Artificial intelligence (AI) has made remarkable progress across various domains, with large language models like ChatGPT gaining substantial attention for their human-like text-generation capabilities. Despite these achievements, spatial reasoning remains a significant challenge for these models. Benchmarks like StepGame evaluate AI spatial reasoning, where ChatGPT has shown unsatisfactory performance. However, the presence of template errors in the benchmark has an impact on the evaluation results. Thus there is potential for ChatGPT to perform better if these template errors are addressed, leading to more accurate assessments of its spatial reasoning capabilities. In this study, we refine the StepGame benchmark, providing a more accurate dataset for model evaluation. We analyze GPT's spatial reasoning performance on the rectified benchmark, identifying proficiency in mapping natural language text to spatial relations but limitations in multi-hop reasoning. We provide a flawless solu",
    "path": "papers/24/01/2401.03991.json",
    "total_tokens": 936,
    "translated_title": "提升大型语言模型中的空间推理能力：通过StepGame基准的深入评估和增强",
    "translated_abstract": "人工智能在各个领域取得了显著进展，例如ChatGPT等大型语言模型因其类似人类的文本生成能力而受到了广泛关注。然而，这些模型在空间推理方面仍然存在一定挑战。StepGame等基准评估了人工智能的空间推理能力，ChatGPT在其中表现出了不尽人意的性能。然而，基准中存在的模板错误对评估结果有影响。因此，如果解决了这些模板错误，ChatGPT有潜力表现更好，从而获得对其空间推理能力更准确的评估。在本研究中，我们完善了StepGame基准，提供了更准确的数据集用于模型评估。我们分析了GPT在经过修正的基准上的空间推理性能，在将自然语言文本映射到空间关系方面表现优秀，但在多跳推理方面存在限制。我们提供了一个无缺陷的解决方案",
    "tldr": "本研究通过改进StepGame基准，提供了更准确的数据集用于评估语言模型在空间推理方面的能力。研究发现，当前的大型语言模型在将自然语言文本映射到空间关系方面表现优秀，但在多跳推理方面存在限制。",
    "en_tdlr": "This study refines the StepGame benchmark to evaluate the spatial reasoning capabilities of large language models. The study finds that current models excel at mapping natural language text to spatial relations but have limitations in multi-hop reasoning."
}