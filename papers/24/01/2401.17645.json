{
    "title": "ReSLLM: Large Language Models are Strong Resource Selectors for Federated Search",
    "abstract": "Federated search, which involves integrating results from multiple independent search engines, will become increasingly pivotal in the context of Retrieval-Augmented Generation pipelines empowering LLM-based applications such as chatbots. These systems often distribute queries among various search engines, ranging from specialized (e.g., PubMed) to general (e.g., Google), based on the nature of user utterances. A critical aspect of federated search is resource selection - the selection of appropriate resources prior to issuing the query to ensure high-quality and rapid responses, and contain costs associated with calling the external search engines. However, current SOTA resource selection methodologies primarily rely on feature-based learning approaches. These methods often involve the labour intensive and expensive creation of training labels for each resource. In contrast, LLMs have exhibited strong effectiveness as zero-shot methods across NLP and IR tasks. We hypothesise that in t",
    "link": "https://arxiv.org/abs/2401.17645",
    "context": "Title: ReSLLM: Large Language Models are Strong Resource Selectors for Federated Search\nAbstract: Federated search, which involves integrating results from multiple independent search engines, will become increasingly pivotal in the context of Retrieval-Augmented Generation pipelines empowering LLM-based applications such as chatbots. These systems often distribute queries among various search engines, ranging from specialized (e.g., PubMed) to general (e.g., Google), based on the nature of user utterances. A critical aspect of federated search is resource selection - the selection of appropriate resources prior to issuing the query to ensure high-quality and rapid responses, and contain costs associated with calling the external search engines. However, current SOTA resource selection methodologies primarily rely on feature-based learning approaches. These methods often involve the labour intensive and expensive creation of training labels for each resource. In contrast, LLMs have exhibited strong effectiveness as zero-shot methods across NLP and IR tasks. We hypothesise that in t",
    "path": "papers/24/01/2401.17645.json",
    "total_tokens": 808,
    "translated_title": "ReSLLM: 大型语言模型是联邦搜索强大的资源选择器",
    "translated_abstract": "联邦搜索是将多个独立搜索引擎的结果整合起来的过程，在增强检索生成流水线中具有越来越重要的作用，为聊天机器人等基于LLM的应用提供支持。这些系统通常根据用户的话语性质，将查询分发到各种搜索引擎中，从专门的（如PubMed）到通用的（如Google）。联邦搜索的一个关键方面是资源选择，即在发出查询之前选择适当的资源，以确保高质量和快速响应，并降低调用外部搜索引擎的成本。然而，当前的SOTA资源选择方法主要依赖于基于特征的学习方法。这些方法通常涉及人力密集和昂贵的训练标签的创建。相比之下，LLM在NLP和IR任务中表现出了强大的零-shot方法的效果。我们假设在这篇论文中...",
    "tldr": "大型语言模型在联邦搜索中展现出强大的资源选择能力，相比于传统的基于特征的学习方法具有更高的效果和更低的成本。",
    "en_tdlr": "Large language models demonstrate strong resource selection capabilities in federated search, offering higher effectiveness and lower cost compared to traditional feature-based learning approaches."
}