{
    "title": "Is K-fold cross validation the best model selection method for Machine Learning?. (arXiv:2401.16407v1 [stat.ML])",
    "abstract": "As a technique that can compactly represent complex patterns, machine learning has significant potential for predictive inference. K-fold cross-validation (CV) is the most common approach to ascertaining the likelihood that a machine learning outcome is generated by chance and frequently outperforms conventional hypothesis testing. This improvement uses measures directly obtained from machine learning classifications, such as accuracy, that do not have a parametric description. To approach a frequentist analysis within machine learning pipelines, a permutation test or simple statistics from data partitions (i.e. folds) can be added to estimate confidence intervals. Unfortunately, neither parametric nor non-parametric tests solve the inherent problems around partitioning small sample-size datasets and learning from heterogeneous data sources. The fact that machine learning strongly depends on the learning parameters and the distribution of data across folds recapitulates familiar diffic",
    "link": "http://arxiv.org/abs/2401.16407",
    "context": "Title: Is K-fold cross validation the best model selection method for Machine Learning?. (arXiv:2401.16407v1 [stat.ML])\nAbstract: As a technique that can compactly represent complex patterns, machine learning has significant potential for predictive inference. K-fold cross-validation (CV) is the most common approach to ascertaining the likelihood that a machine learning outcome is generated by chance and frequently outperforms conventional hypothesis testing. This improvement uses measures directly obtained from machine learning classifications, such as accuracy, that do not have a parametric description. To approach a frequentist analysis within machine learning pipelines, a permutation test or simple statistics from data partitions (i.e. folds) can be added to estimate confidence intervals. Unfortunately, neither parametric nor non-parametric tests solve the inherent problems around partitioning small sample-size datasets and learning from heterogeneous data sources. The fact that machine learning strongly depends on the learning parameters and the distribution of data across folds recapitulates familiar diffic",
    "path": "papers/24/01/2401.16407.json",
    "total_tokens": 805,
    "translated_title": "K折交叉验证是否是机器学习中最好的模型选择方法？",
    "translated_abstract": "机器学习作为一种能够紧凑表示复杂模式的技术，具有显著的预测推理潜力。K折交叉验证（CV）是确定机器学习结果是否是随机生成的最常用方法，并经常优于传统的假设检验。这种改进利用了直接从机器学习分类中获得的度量，比如准确性，这些度量没有参数描述。为了在机器学习流程中进行频率分析，可以添加排列测试或来自数据分区（即折叠）的简单统计量来估计置信区间。不幸的是，无论是参数化还是非参数化测试都无法解决围绕分割小样本数据集和来自异质数据源的学习固有问题。机器学习严重依赖学习参数和数据在折叠中的分布，这重新概括了熟悉的困难情况。",
    "tldr": "K折交叉验证在机器学习中是常用的模型选择方法，但在处理小样本数据集和异质数据源时存在困难。",
    "en_tdlr": "K-fold cross-validation is a commonly used model selection method in machine learning, but it faces difficulties when dealing with small sample-size datasets and heterogeneous data sources."
}