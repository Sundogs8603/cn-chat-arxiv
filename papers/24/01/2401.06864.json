{
    "title": "Deep Learning With DAGs. (arXiv:2401.06864v1 [stat.ML])",
    "abstract": "Social science theories often postulate causal relationships among a set of variables or events. Although directed acyclic graphs (DAGs) are increasingly used to represent these theories, their full potential has not yet been realized in practice. As non-parametric causal models, DAGs require no assumptions about the functional form of the hypothesized relationships. Nevertheless, to simplify the task of empirical evaluation, researchers tend to invoke such assumptions anyway, even though they are typically arbitrary and do not reflect any theoretical content or prior knowledge. Moreover, functional form assumptions can engender bias, whenever they fail to accurately capture the complexity of the causal system under investigation. In this article, we introduce causal-graphical normalizing flows (cGNFs), a novel approach to causal inference that leverages deep neural networks to empirically evaluate theories represented as DAGs. Unlike conventional approaches, cGNFs model the full joint",
    "link": "http://arxiv.org/abs/2401.06864",
    "context": "Title: Deep Learning With DAGs. (arXiv:2401.06864v1 [stat.ML])\nAbstract: Social science theories often postulate causal relationships among a set of variables or events. Although directed acyclic graphs (DAGs) are increasingly used to represent these theories, their full potential has not yet been realized in practice. As non-parametric causal models, DAGs require no assumptions about the functional form of the hypothesized relationships. Nevertheless, to simplify the task of empirical evaluation, researchers tend to invoke such assumptions anyway, even though they are typically arbitrary and do not reflect any theoretical content or prior knowledge. Moreover, functional form assumptions can engender bias, whenever they fail to accurately capture the complexity of the causal system under investigation. In this article, we introduce causal-graphical normalizing flows (cGNFs), a novel approach to causal inference that leverages deep neural networks to empirically evaluate theories represented as DAGs. Unlike conventional approaches, cGNFs model the full joint",
    "path": "papers/24/01/2401.06864.json",
    "total_tokens": 898,
    "translated_title": "使用DAGs的深度学习",
    "translated_abstract": "社会科学理论经常假设一组变量或事件之间存在因果关系。尽管有向无环图(DAGs)越来越多地被用来表示这些理论，但它们在实践中的全部潜力尚未得到实现。作为非参数因果模型，DAGs不需要关于假设关系的功能形式的任何假设。然而，为了简化实证评估的任务，研究人员倾向于无论如何激活这些假设，尽管它们通常是任意的，不反映任何理论内容或先前知识。此外，功能形式的假设可能导致偏见，因为它们未能准确捕捉研究中因果系统的复杂性。在本文中，我们介绍了一种名为因果图标准化流(cGNFs)的新方法，该方法利用深度神经网络来对表示为DAGs的理论进行实证评估。与传统方法不同，cGNFs模拟了全联合概率。",
    "tldr": "本文介绍了一种使用深度神经网络来对因果图进行实证评估的新方法。这种方法称为因果图标准化流(cGNFs)，通过使用DAGs表示理论，并避免功能形式的假设，来更准确地捕捉因果系统的复杂性。",
    "en_tdlr": "This paper introduces a novel approach, called causal-graphical normalizing flows (cGNFs), that uses deep neural networks to empirically evaluate causal diagrams represented as DAGs. It avoids making assumptions about the functional form of the relationships, allowing for a more accurate representation of the complexity of the causal system."
}