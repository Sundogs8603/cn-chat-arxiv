{
    "title": "Deep Anomaly Detection in Text. (arXiv:2401.02971v1 [cs.CL])",
    "abstract": "Deep anomaly detection methods have become increasingly popular in recent years, with methods like Stacked Autoencoders, Variational Autoencoders, and Generative Adversarial Networks greatly improving the state-of-the-art. Other methods rely on augmenting classical models (such as the One-Class Support Vector Machine), by learning an appropriate kernel function using Neural Networks. Recent developments in representation learning by self-supervision are proving to be very beneficial in the context of anomaly detection. Inspired by the advancements in anomaly detection using self-supervised learning in the field of computer vision, this thesis aims to develop a method for detecting anomalies by exploiting pretext tasks tailored for text corpora. This approach greatly improves the state-of-the-art on two datasets, 20Newsgroups, and AG News, for both semi-supervised and unsupervised anomaly detection, thus proving the potential for self-supervised anomaly detectors in the field of natural",
    "link": "http://arxiv.org/abs/2401.02971",
    "context": "Title: Deep Anomaly Detection in Text. (arXiv:2401.02971v1 [cs.CL])\nAbstract: Deep anomaly detection methods have become increasingly popular in recent years, with methods like Stacked Autoencoders, Variational Autoencoders, and Generative Adversarial Networks greatly improving the state-of-the-art. Other methods rely on augmenting classical models (such as the One-Class Support Vector Machine), by learning an appropriate kernel function using Neural Networks. Recent developments in representation learning by self-supervision are proving to be very beneficial in the context of anomaly detection. Inspired by the advancements in anomaly detection using self-supervised learning in the field of computer vision, this thesis aims to develop a method for detecting anomalies by exploiting pretext tasks tailored for text corpora. This approach greatly improves the state-of-the-art on two datasets, 20Newsgroups, and AG News, for both semi-supervised and unsupervised anomaly detection, thus proving the potential for self-supervised anomaly detectors in the field of natural",
    "path": "papers/24/01/2401.02971.json",
    "total_tokens": 869,
    "translated_title": "文本中的深度异常检测",
    "translated_abstract": "近年来，深度异常检测方法变得越来越受欢迎，诸如堆叠自动编码器、变分自动编码器和生成对抗网络等方法大大改进了最新技术。其他方法通过使用神经网络学习适当的核函数来增强经典模型（如单类支持向量机）。自我监督学习在异常检测领域中的代表线学习方面的最新发展证明在这一背景下非常有益。受计算机视觉领域中使用自我监督学习进行异常检测的进展启发，本论文旨在通过利用为文本语料库量身定制的预处理任务来开发一种检测异常的方法。这种方法在20Newsgroups和AG News两个数据集上大大改进了半监督和无监督的异常检测最新技术，从而证明了自我监督异常检测器在自然领域的潜力。",
    "tldr": "本研究旨在开发一种基于自我监督学习的方法，用于文本中的异常检测，通过利用预处理任务来提高最新技术，并在半监督和无监督的情况下对两个数据集进行了显著改进。",
    "en_tdlr": "This study aims to develop a method for anomaly detection in text by using self-supervised learning, which greatly improves the state-of-the-art by leveraging pretext tasks, and achieves significant advancements on two datasets in both semi-supervised and unsupervised scenarios."
}