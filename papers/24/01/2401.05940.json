{
    "title": "Mutation-based Consistency Testing for Evaluating the Code Understanding Capability of LLMs. (arXiv:2401.05940v1 [cs.SE])",
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in processing both natural and programming languages, which have enabled various applications in software engineering, such as requirement engineering, code generation, and software testing. However, existing code generation benchmarks do not necessarily assess the code understanding performance of LLMs, especially for the subtle inconsistencies that may arise between code and its semantics described in natural language.  In this paper, we propose a novel method to systematically assess the code understanding performance of LLMs, particularly focusing on subtle differences between code and its descriptions, by introducing code mutations to existing code generation datasets. Code mutations are small changes that alter the semantics of the original code, creating a mismatch with the natural language description. We apply different types of code mutations, such as operator replacement and statement deletion, to generate incon",
    "link": "http://arxiv.org/abs/2401.05940",
    "context": "Title: Mutation-based Consistency Testing for Evaluating the Code Understanding Capability of LLMs. (arXiv:2401.05940v1 [cs.SE])\nAbstract: Large Language Models (LLMs) have shown remarkable capabilities in processing both natural and programming languages, which have enabled various applications in software engineering, such as requirement engineering, code generation, and software testing. However, existing code generation benchmarks do not necessarily assess the code understanding performance of LLMs, especially for the subtle inconsistencies that may arise between code and its semantics described in natural language.  In this paper, we propose a novel method to systematically assess the code understanding performance of LLMs, particularly focusing on subtle differences between code and its descriptions, by introducing code mutations to existing code generation datasets. Code mutations are small changes that alter the semantics of the original code, creating a mismatch with the natural language description. We apply different types of code mutations, such as operator replacement and statement deletion, to generate incon",
    "path": "papers/24/01/2401.05940.json",
    "total_tokens": 847,
    "translated_title": "基于变异的一致性测试用于评估LLMs的代码理解能力",
    "translated_abstract": "大型语言模型（LLMs）在处理自然语言和编程语言方面显示出卓越的能力，为软件工程领域的需求工程、代码生成和软件测试等各种应用提供了可能。然而，现有的代码生成基准测试并不一定能够评估LLMs的代码理解性能，特别是对于代码和自然语言描述之间可能出现的微妙不一致性。在本文中，我们提出了一种新的方法来系统评估LLMs的代码理解性能，特别关注代码和描述之间的微小差异，通过引入代码变异到现有的代码生成数据集中。代码变异是对原始代码进行改动的小改变，会导致代码与自然语言描述不匹配。我们采用不同类型的代码变异，如操作符替换和语句删除，来生成不一致的代码数据。",
    "tldr": "本文提出了一种基于代码变异的方法，用于系统评估LLMs的代码理解能力，重点关注代码和描述之间的微妙差异。通过引入代码变异到现有的数据集中，我们可以生成不一致的代码数据，从而评估LLMs的代码理解性能。",
    "en_tdlr": "This paper proposes a mutation-based method to systematically assess the code understanding performance of LLMs, focusing on subtle differences between code and its descriptions. By introducing code mutations to existing datasets, incongruent code data can be generated to evaluate the code understanding capability of LLMs."
}