{
    "title": "Graph Guided Question Answer Generation for Procedural Question-Answering. (arXiv:2401.13594v1 [cs.CL])",
    "abstract": "In this paper, we focus on task-specific question answering (QA). To this end, we introduce a method for generating exhaustive and high-quality training data, which allows us to train compact (e.g., run on a mobile device), task-specific QA models that are competitive against GPT variants. The key technological enabler is a novel mechanism for automatic question-answer generation from procedural text which can ingest large amounts of textual instructions and produce exhaustive in-domain QA training data. While current QA data generation methods can produce well-formed and varied data, their non-exhaustive nature is sub-optimal for training a QA model. In contrast, we leverage the highly structured aspect of procedural text and represent each step and the overall flow of the procedure as graphs. We then condition on graph nodes to automatically generate QA pairs in an exhaustive and controllable manner. Comprehensive evaluations of our method show that: 1) small models trained with our ",
    "link": "http://arxiv.org/abs/2401.13594",
    "context": "Title: Graph Guided Question Answer Generation for Procedural Question-Answering. (arXiv:2401.13594v1 [cs.CL])\nAbstract: In this paper, we focus on task-specific question answering (QA). To this end, we introduce a method for generating exhaustive and high-quality training data, which allows us to train compact (e.g., run on a mobile device), task-specific QA models that are competitive against GPT variants. The key technological enabler is a novel mechanism for automatic question-answer generation from procedural text which can ingest large amounts of textual instructions and produce exhaustive in-domain QA training data. While current QA data generation methods can produce well-formed and varied data, their non-exhaustive nature is sub-optimal for training a QA model. In contrast, we leverage the highly structured aspect of procedural text and represent each step and the overall flow of the procedure as graphs. We then condition on graph nodes to automatically generate QA pairs in an exhaustive and controllable manner. Comprehensive evaluations of our method show that: 1) small models trained with our ",
    "path": "papers/24/01/2401.13594.json",
    "total_tokens": 932,
    "translated_title": "用于程序性问答的图形引导问题生成方法",
    "translated_abstract": "本文针对特定任务的问答(QA)问题进行研究，提出了一种生成详尽高质量训练数据的方法，使我们能够训练紧凑的、针对特定任务的QA模型，并与GPT变体模型竞争。关键的技术支持是一种从过程文本中自动生成问题-答案的新机制，它可以处理大量的文本指令，并产生详尽的领域内QA训练数据。目前的QA数据生成方法会产生形式良好且多样化的数据，但其非详尽性不利于训练QA模型。相反，我们利用过程性文本的高度结构化特性，将每个步骤和整个流程表示为图形，并以图节点为条件，自动以详尽和可控的方式生成QA对。对我们方法的全面评估表明：1) 使用我们的方法训练的小型模型能够达到竞争水平。",
    "tldr": "本文提出了一种生成详尽的高质量训练数据的方法，用于训练紧凑的、任务特定的QA模型，从而在特定问答任务中与GPT变体模型具有竞争力。这种方法利用过程性文本的结构化特性，通过将每个步骤和整个流程表示为图形，并以图节点为条件，在详尽和可控的方式下自动生成QA对。",
    "en_tdlr": "This paper proposes a method for generating exhaustively high-quality training data to train compact task-specific QA models that are competitive against GPT variants. The method leverages the structured aspect of procedural text, representing each step and the overall flow as graphs and generating QA pairs in an exhaustive and controllable manner."
}