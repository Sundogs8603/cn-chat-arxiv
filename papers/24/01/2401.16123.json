{
    "title": "Looking for a better fit? An Incremental Learning Multimodal Object Referencing Framework adapting to Individual Drivers",
    "abstract": "The rapid advancement of the automotive industry towards automated and semi-automated vehicles has rendered traditional methods of vehicle interaction, such as touch-based and voice command systems, inadequate for a widening range of non-driving related tasks, such as referencing objects outside of the vehicle. Consequently, research has shifted toward gestural input (e.g., hand, gaze, and head pose gestures) as a more suitable mode of interaction during driving. However, due to the dynamic nature of driving and individual variation, there are significant differences in drivers' gestural input performance. While, in theory, this inherent variability could be moderated by substantial data-driven machine learning models, prevalent methodologies lean towards constrained, single-instance trained models for object referencing. These models show a limited capacity to continuously adapt to the divergent behaviors of individual drivers and the variety of driving scenarios. To address this, we ",
    "link": "https://arxiv.org/abs/2401.16123",
    "context": "Title: Looking for a better fit? An Incremental Learning Multimodal Object Referencing Framework adapting to Individual Drivers\nAbstract: The rapid advancement of the automotive industry towards automated and semi-automated vehicles has rendered traditional methods of vehicle interaction, such as touch-based and voice command systems, inadequate for a widening range of non-driving related tasks, such as referencing objects outside of the vehicle. Consequently, research has shifted toward gestural input (e.g., hand, gaze, and head pose gestures) as a more suitable mode of interaction during driving. However, due to the dynamic nature of driving and individual variation, there are significant differences in drivers' gestural input performance. While, in theory, this inherent variability could be moderated by substantial data-driven machine learning models, prevalent methodologies lean towards constrained, single-instance trained models for object referencing. These models show a limited capacity to continuously adapt to the divergent behaviors of individual drivers and the variety of driving scenarios. To address this, we ",
    "path": "papers/24/01/2401.16123.json",
    "total_tokens": 911,
    "translated_title": "寻求更好的适应性？适应个体驾驶员的增量学习多模式目标引用框架",
    "translated_abstract": "汽车行业迅速向自动化和半自动化车辆发展，传统的车辆交互方法（如基于触摸和语音命令的系统）在越来越广泛的非驾驶相关任务（如引用车辆外部物体）中已经变得不合适。因此，研究转向姿势输入（如手势、视线和头部姿势手势）作为驾驶过程中更合适的交互方式。然而，由于驾驶的动态特性和个体差异，驾驶员的姿势输入性能存在显著差异。虽然理论上，这种固有的可变性可以通过大规模数据驱动的机器学习模型进行调节，但普遍的方法倾向于针对目标引用使用约束的单实例训练模型。这些模型在持续适应个体驾驶员的不同行为和各种驾驶场景方面显示出有限的能力。为了解决这个问题，我们提出了一种增量学习的多模式目标引用框架，可以适应个体驾驶员的变化行为和各种驾驶场景。",
    "tldr": "这项研究提出了一种增量学习的多模式目标引用框架，可以适应个体驾驶员的变化行为和各种驾驶场景。",
    "en_tdlr": "This research proposes an incremental learning multimodal object referencing framework that can adapt to the divergent behaviors of individual drivers and the variety of driving scenarios."
}