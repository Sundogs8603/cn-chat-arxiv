{
    "title": "A Robust Adversary Detection-Deactivation Method for Metaverse-oriented Collaborative Deep Learning. (arXiv:2401.01895v1 [cs.CR])",
    "abstract": "Metaverse is trending to create a digital circumstance that can transfer the real world to an online platform supported by large quantities of real-time interactions. Pre-trained Artificial Intelligence (AI) models are demonstrating their increasing capability in aiding the metaverse to achieve an excellent response with negligible delay, and nowadays, many large models are collaboratively trained by various participants in a manner named collaborative deep learning (CDL). However, several security weaknesses can threaten the safety of the CDL training process, which might result in fatal attacks to either the pre-trained large model or the local sensitive data sets possessed by an individual entity. In CDL, malicious participants can hide within the major innocent and silently uploads deceptive parameters to degenerate the model performance, or they can abuse the downloaded parameters to construct a Generative Adversarial Network (GAN) to acquire the private information of others ille",
    "link": "http://arxiv.org/abs/2401.01895",
    "context": "Title: A Robust Adversary Detection-Deactivation Method for Metaverse-oriented Collaborative Deep Learning. (arXiv:2401.01895v1 [cs.CR])\nAbstract: Metaverse is trending to create a digital circumstance that can transfer the real world to an online platform supported by large quantities of real-time interactions. Pre-trained Artificial Intelligence (AI) models are demonstrating their increasing capability in aiding the metaverse to achieve an excellent response with negligible delay, and nowadays, many large models are collaboratively trained by various participants in a manner named collaborative deep learning (CDL). However, several security weaknesses can threaten the safety of the CDL training process, which might result in fatal attacks to either the pre-trained large model or the local sensitive data sets possessed by an individual entity. In CDL, malicious participants can hide within the major innocent and silently uploads deceptive parameters to degenerate the model performance, or they can abuse the downloaded parameters to construct a Generative Adversarial Network (GAN) to acquire the private information of others ille",
    "path": "papers/24/01/2401.01895.json",
    "total_tokens": 885,
    "translated_title": "适用于元宇宙导向的协同深度学习的鲁棒性对抗检测和停用方法",
    "translated_abstract": "元宇宙正趋向于创建一个可以将现实世界转移到大量实时互动支持的在线平台上的数字情境。预训练的人工智能（AI）模型正在展示它们在帮助元宇宙实现优秀响应时的不断增强能力，而现在，许多大型模型都是通过多个参与者协同训练的，这种方式被称为协同深度学习（CDL）。然而，CDL训练过程中存在几个安全弱点，可能对预训练的大型模型或个体实体拥有的本地敏感数据集造成致命攻击。在CDL中，恶意参与者可以隐藏在主要无辜者中，并悄无声息地上传欺骗性参数以降低模型性能，或者他们可以滥用下载的参数构建生成对抗网络（GAN）以非法获取他人的私人信息。",
    "tldr": "本文提出了一种适用于元宇宙导向的协同深度学习的鲁棒性对抗检测和停用方法，用于解决CDL训练过程中的安全弱点，保护预训练的大型模型和本地敏感数据集。"
}