{
    "title": "Adaptive Differential Privacy in Federated Learning: A Priority-Based Approach. (arXiv:2401.02453v1 [cs.CR])",
    "abstract": "Federated learning (FL) as one of the novel branches of distributed machine learning (ML), develops global models through a private procedure without direct access to local datasets. However, access to model updates (e.g. gradient updates in deep neural networks) transferred between clients and servers can reveal sensitive information to adversaries. Differential privacy (DP) offers a framework that gives a privacy guarantee by adding certain amounts of noise to parameters. This approach, although being effective in terms of privacy, adversely affects model performance due to noise involvement. Hence, it is always needed to find a balance between noise injection and the sacrificed accuracy. To address this challenge, we propose adaptive noise addition in FL which decides the value of injected noise based on features' relative importance. Here, we first propose two effective methods for prioritizing features in deep neural network models and then perturb models' weights based on this in",
    "link": "http://arxiv.org/abs/2401.02453",
    "context": "Title: Adaptive Differential Privacy in Federated Learning: A Priority-Based Approach. (arXiv:2401.02453v1 [cs.CR])\nAbstract: Federated learning (FL) as one of the novel branches of distributed machine learning (ML), develops global models through a private procedure without direct access to local datasets. However, access to model updates (e.g. gradient updates in deep neural networks) transferred between clients and servers can reveal sensitive information to adversaries. Differential privacy (DP) offers a framework that gives a privacy guarantee by adding certain amounts of noise to parameters. This approach, although being effective in terms of privacy, adversely affects model performance due to noise involvement. Hence, it is always needed to find a balance between noise injection and the sacrificed accuracy. To address this challenge, we propose adaptive noise addition in FL which decides the value of injected noise based on features' relative importance. Here, we first propose two effective methods for prioritizing features in deep neural network models and then perturb models' weights based on this in",
    "path": "papers/24/01/2401.02453.json",
    "total_tokens": 892,
    "translated_title": "自适应差分隐私在联邦学习中的应用: 一种基于优先级的方法。",
    "translated_abstract": "作为分布式机器学习的新领域之一，联邦学习通过私有过程开发全局模型，而无需直接访问本地数据集。然而，客户端和服务器之间传输的模型更新（例如深度神经网络中的梯度更新）可能向对手泄露敏感信息。差分隐私通过向参数中添加一定量的噪声来提供隐私保证。尽管这种方法在隐私方面是有效的，但由于噪声的介入，会对模型性能产生负面影响。因此，必须在噪声注入和牺牲的准确性之间找到平衡。为了解决这个挑战，我们提出了在联邦学习中采用自适应噪声注入的方法，该方法根据特征的相对重要性决定注入噪声的值。我们首先提出了两种对深度神经网络模型中特征进行优先级排序的有效方法，然后基于此对模型的权重进行扰动。",
    "tldr": "这项研究提出了一种在联邦学习中使用自适应差分隐私的方法，通过根据特征的相对重要性来决定注入的噪声值，以平衡隐私和模型性能。",
    "en_tdlr": "This research proposes an approach to use adaptive differential privacy in federated learning, which decides the value of injected noise based on features' relative importance, in order to balance privacy and model performance."
}