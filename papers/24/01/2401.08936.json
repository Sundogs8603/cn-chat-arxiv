{
    "title": "DeLF: Designing Learning Environments with Foundation Models. (arXiv:2401.08936v1 [cs.AI])",
    "abstract": "Reinforcement learning (RL) offers a capable and intuitive structure for the fundamental sequential decision-making problem. Despite impressive breakthroughs, it can still be difficult to employ RL in practice in many simple applications. In this paper, we try to address this issue by introducing a method for designing the components of the RL environment for a given, user-intended application. We provide an initial formalization for the problem of RL component design, that concentrates on designing a good representation for observation and action space. We propose a method named DeLF: Designing Learning Environments with Foundation Models, that employs large language models to design and codify the user's intended learning scenario. By testing our method on four different learning environments, we demonstrate that DeLF can obtain executable environment codes for the corresponding RL problems.",
    "link": "http://arxiv.org/abs/2401.08936",
    "context": "Title: DeLF: Designing Learning Environments with Foundation Models. (arXiv:2401.08936v1 [cs.AI])\nAbstract: Reinforcement learning (RL) offers a capable and intuitive structure for the fundamental sequential decision-making problem. Despite impressive breakthroughs, it can still be difficult to employ RL in practice in many simple applications. In this paper, we try to address this issue by introducing a method for designing the components of the RL environment for a given, user-intended application. We provide an initial formalization for the problem of RL component design, that concentrates on designing a good representation for observation and action space. We propose a method named DeLF: Designing Learning Environments with Foundation Models, that employs large language models to design and codify the user's intended learning scenario. By testing our method on four different learning environments, we demonstrate that DeLF can obtain executable environment codes for the corresponding RL problems.",
    "path": "papers/24/01/2401.08936.json",
    "total_tokens": 807,
    "translated_title": "使用基础模型设计学习环境的 DeLF",
    "translated_abstract": "强化学习（RL）为基本的顺序决策问题提供了一种能力强大且直观的结构。尽管取得了令人瞩目的突破，但在许多简单应用中实际应用RL仍然很困难。在本文中，我们通过引入一种用于为给定的、用户预期的应用设计RL环境组件的方法来解决这个问题。我们提供了RL组件设计问题的初始形式化，重点是设计观察和动作空间的良好表示。我们提出了一种名为DeLF：使用基础模型设计学习环境的方法，该方法利用大型语言模型来设计和编码用户预期的学习场景。通过在四个不同的学习环境上测试我们的方法，我们证明了DeLF可以为相应的RL问题获得可执行的环境代码。",
    "tldr": "DeLF是一种利用大型语言模型设计学习环境的方法，可以解决在实践中应用强化学习的困难。通过测试，证明DeLF可以为不同的学习环境获得可执行的代码。",
    "en_tdlr": "DeLF is a method that utilizes large language models to design learning environments, addressing the challenges of applying reinforcement learning in practice. Through testing, it is shown that DeLF can obtain executable environment codes for different learning environments."
}