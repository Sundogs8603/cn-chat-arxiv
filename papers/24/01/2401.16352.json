{
    "title": "Adversarial Training on Purification (AToP): Advancing Both Robustness and Generalization",
    "abstract": "arXiv:2401.16352v2 Announce Type: replace-cross  Abstract: The deep neural networks are known to be vulnerable to well-designed adversarial attacks. The most successful defense technique based on adversarial training (AT) can achieve optimal robustness against particular attacks but cannot generalize well to unseen attacks. Another effective defense technique based on adversarial purification (AP) can enhance generalization but cannot achieve optimal robustness. Meanwhile, both methods share one common limitation on the degraded standard accuracy. To mitigate these issues, we propose a novel pipeline called Adversarial Training on Purification (AToP), which comprises two components: perturbation destruction by random transforms (RT) and purifier model fine-tuned (FT) by adversarial loss. RT is essential to avoid overlearning to known attacks resulting in the robustness generalization to unseen attacks and FT is essential for the improvement of robustness. To evaluate our method in an e",
    "link": "https://arxiv.org/abs/2401.16352",
    "context": "Title: Adversarial Training on Purification (AToP): Advancing Both Robustness and Generalization\nAbstract: arXiv:2401.16352v2 Announce Type: replace-cross  Abstract: The deep neural networks are known to be vulnerable to well-designed adversarial attacks. The most successful defense technique based on adversarial training (AT) can achieve optimal robustness against particular attacks but cannot generalize well to unseen attacks. Another effective defense technique based on adversarial purification (AP) can enhance generalization but cannot achieve optimal robustness. Meanwhile, both methods share one common limitation on the degraded standard accuracy. To mitigate these issues, we propose a novel pipeline called Adversarial Training on Purification (AToP), which comprises two components: perturbation destruction by random transforms (RT) and purifier model fine-tuned (FT) by adversarial loss. RT is essential to avoid overlearning to known attacks resulting in the robustness generalization to unseen attacks and FT is essential for the improvement of robustness. To evaluate our method in an e",
    "path": "papers/24/01/2401.16352.json",
    "total_tokens": 918,
    "translated_title": "对净化的对抗训练（AToP）：提升鲁棒性和泛化性能",
    "translated_abstract": "深度神经网络被认为易受设计精良的对抗攻击影响。基于对抗训练（AT）的最成功防御技术可以实现特定攻击下的最佳鲁棒性，但无法很好地泛化到未知攻击。基于对抗净化（AP）的另一有效防御技术可以增强泛化性能，但无法实现最佳鲁棒性。与此同时，这两种方法都存在一个共同的局限性，即标准准确性降级。为了缓解这些问题，我们提出了一种新的流程，称为对净化的对抗训练（AToP），包括两个组件：通过随机转换（RT）破坏扰动，以避免对已知攻击的过度学习，从而实现对未知攻击的鲁棒性泛化；以及通过对抗损失对净化器模型进行微调（FT），以提高鲁棒性。为了评估我们的方法，我们在一种...",
    "tldr": "提出了一种新的对净化的对抗训练（AToP）流程，通过随机转换的扰动破坏和通过对抗损失微调净化器模型，同时提升了鲁棒性和泛化性能。",
    "en_tdlr": "Introduced a new Adversarial Training on Purification (AToP) method, which enhances both robustness and generalization by perturbation destruction through random transforms and purifier model fine-tuning with adversarial loss."
}