{
    "title": "ConvConcatNet: a deep convolutional neural network to reconstruct mel spectrogram from the EEG. (arXiv:2401.04965v1 [eess.SP])",
    "abstract": "To investigate the processing of speech in the brain, simple linear models are commonly used to establish a relationship between brain signals and speech features. However, these linear models are ill-equipped to model a highly dynamic and complex non-linear system like the brain. Although non-linear methods with neural networks have been developed recently, reconstructing unseen stimuli from unseen subjects' EEG is still a highly challenging task. This work presents a novel method, ConvConcatNet, to reconstruct mel-specgrams from EEG, in which the deep convolution neural network and extensive concatenation operation were combined. With our ConvConcatNet model, the Pearson correlation between the reconstructed and the target mel-spectrogram can achieve 0.0420, which was ranked as No.1 in the Task 2 of the Auditory EEG Challenge. The codes and models to implement our work will be available on Github: https://github.com/xuxiran/ConvConcatNet",
    "link": "http://arxiv.org/abs/2401.04965",
    "context": "Title: ConvConcatNet: a deep convolutional neural network to reconstruct mel spectrogram from the EEG. (arXiv:2401.04965v1 [eess.SP])\nAbstract: To investigate the processing of speech in the brain, simple linear models are commonly used to establish a relationship between brain signals and speech features. However, these linear models are ill-equipped to model a highly dynamic and complex non-linear system like the brain. Although non-linear methods with neural networks have been developed recently, reconstructing unseen stimuli from unseen subjects' EEG is still a highly challenging task. This work presents a novel method, ConvConcatNet, to reconstruct mel-specgrams from EEG, in which the deep convolution neural network and extensive concatenation operation were combined. With our ConvConcatNet model, the Pearson correlation between the reconstructed and the target mel-spectrogram can achieve 0.0420, which was ranked as No.1 in the Task 2 of the Auditory EEG Challenge. The codes and models to implement our work will be available on Github: https://github.com/xuxiran/ConvConcatNet",
    "path": "papers/24/01/2401.04965.json",
    "total_tokens": 928,
    "translated_title": "ConvConcatNet: 一个用于从脑电图 (EEG) 重建 Mel 频谱的深度卷积神经网络",
    "translated_abstract": "为了研究大脑对语音的处理，通常使用简单的线性模型来建立脑信号和语音特征之间的关系。然而，这些线性模型不适用于模拟大脑这样高度动态和复杂的非线性系统。尽管最近已经开发出了使用神经网络的非线性方法，但从未见过的受试者的 EEG 中重建未知刺激仍然是一项极具挑战性的任务。本研究提出了一种新的方法 ConvConcatNet，通过结合深度卷积神经网络和广泛的串接操作，从 EEG 中重建 Mel 频谱。使用我们的 ConvConcatNet 模型，重建的 Mel 频谱与目标 Mel 频谱之间的皮尔逊相关系数可达到 0.0420，在听觉 EEG 挑战赛的任务2中排名第一。我们的代码和模型将在 Github 上提供：https://github.com/xuxiran/ConvConcatNet",
    "tldr": "本论文提出了一种名为ConvConcatNet的深度卷积神经网络方法，用于从EEG中重建Mel频谱，并在Auditory EEG Challenge的Task 2中取得了第一名，重建和目标Mel频谱之间的皮尔逊相关系数达到0.0420。"
}