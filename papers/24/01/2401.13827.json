{
    "title": "Traffic Learning and Proactive UAV Trajectory Planning for Data Uplink in Markovian IoT Models. (arXiv:2401.13827v1 [cs.LG])",
    "abstract": "The age of information (AoI) is used to measure the freshness of the data. In IoT networks, the traditional resource management schemes rely on a message exchange between the devices and the base station (BS) before communication which causes high AoI, high energy consumption, and low reliability. Unmanned aerial vehicles (UAVs) as flying BSs have many advantages in minimizing the AoI, energy-saving, and throughput improvement. In this paper, we present a novel learning-based framework that estimates the traffic arrival of IoT devices based on Markovian events. The learning proceeds to optimize the trajectory of multiple UAVs and their scheduling policy. First, the BS predicts the future traffic of the devices. We compare two traffic predictors: the forward algorithm (FA) and the long short-term memory (LSTM). Afterward, we propose a deep reinforcement learning (DRL) approach to optimize the optimal policy of each UAV. Finally, we manipulate the optimum reward function for the proposed",
    "link": "http://arxiv.org/abs/2401.13827",
    "context": "Title: Traffic Learning and Proactive UAV Trajectory Planning for Data Uplink in Markovian IoT Models. (arXiv:2401.13827v1 [cs.LG])\nAbstract: The age of information (AoI) is used to measure the freshness of the data. In IoT networks, the traditional resource management schemes rely on a message exchange between the devices and the base station (BS) before communication which causes high AoI, high energy consumption, and low reliability. Unmanned aerial vehicles (UAVs) as flying BSs have many advantages in minimizing the AoI, energy-saving, and throughput improvement. In this paper, we present a novel learning-based framework that estimates the traffic arrival of IoT devices based on Markovian events. The learning proceeds to optimize the trajectory of multiple UAVs and their scheduling policy. First, the BS predicts the future traffic of the devices. We compare two traffic predictors: the forward algorithm (FA) and the long short-term memory (LSTM). Afterward, we propose a deep reinforcement learning (DRL) approach to optimize the optimal policy of each UAV. Finally, we manipulate the optimum reward function for the proposed",
    "path": "papers/24/01/2401.13827.json",
    "total_tokens": 938,
    "translated_title": "用于马尔可夫物联网模型中数据上行的流量学习和主动无人机轨迹规划。",
    "translated_abstract": "信息时代(AoI)用于衡量数据的新鲜度。在物联网网络中，传统的资源管理方案依赖于设备和基站(BS)之间的消息交换，导致AoI高、能量消耗高且可靠性低。作为飞行基站的无人机(UAV)在减小AoI、节省能量和提高吞吐量方面具有许多优势。本文提出了一个基于学习的新框架，根据马尔科维事件估计物联网设备的流量到达情况。学习过程用于优化多个无人机的轨迹和调度策略。首先，BS预测设备未来的流量。我们比较了两种流量预测器：前向算法(FA)和长短期记忆(LSTM)。然后，我们提出了一种用于优化每个无人机最优策略的深度强化学习(DRL)方法。最后，我们针对提出的优化奖励函数进行了操作。",
    "tldr": "本文提出了一个新的学习框架，用于估计基于马尔可夫事件的物联网设备的流量情况，并优化多个无人机的轨迹和调度策略，以降低信息时代、节省能量和提高吞吐量。"
}