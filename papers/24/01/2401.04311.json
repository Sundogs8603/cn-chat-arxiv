{
    "title": "Private Truly-Everlasting Robust-Prediction. (arXiv:2401.04311v1 [cs.LG])",
    "abstract": "Private Everlasting Prediction (PEP), recently introduced by Naor et al. [2023], is a model for differentially private learning in which the learner never publicly releases a hypothesis. Instead, it provides black-box access to a \"prediction oracle\" that can predict the labels of an endless stream of unlabeled examples drawn from the underlying distribution. Importantly, PEP provides privacy both for the initial training set and for the endless stream of classification queries. We present two conceptual modifications to the definition of PEP, as well as new constructions exhibiting significant improvements over prior work. Specifically,  (1) Robustness: PEP only guarantees accuracy provided that all the classification queries are drawn from the correct underlying distribution. A few out-of-distribution queries might break the validity of the prediction oracle for future queries, even for future queries which are sampled from the correct distribution. We incorporate robustness against s",
    "link": "http://arxiv.org/abs/2401.04311",
    "context": "Title: Private Truly-Everlasting Robust-Prediction. (arXiv:2401.04311v1 [cs.LG])\nAbstract: Private Everlasting Prediction (PEP), recently introduced by Naor et al. [2023], is a model for differentially private learning in which the learner never publicly releases a hypothesis. Instead, it provides black-box access to a \"prediction oracle\" that can predict the labels of an endless stream of unlabeled examples drawn from the underlying distribution. Importantly, PEP provides privacy both for the initial training set and for the endless stream of classification queries. We present two conceptual modifications to the definition of PEP, as well as new constructions exhibiting significant improvements over prior work. Specifically,  (1) Robustness: PEP only guarantees accuracy provided that all the classification queries are drawn from the correct underlying distribution. A few out-of-distribution queries might break the validity of the prediction oracle for future queries, even for future queries which are sampled from the correct distribution. We incorporate robustness against s",
    "path": "papers/24/01/2401.04311.json",
    "total_tokens": 1006,
    "translated_title": "私人真正永恒的强大预测。",
    "translated_abstract": "私人永恒预测（PEP）是最近由Naor等人[2023]提出的不同ially private learning模型，其中学习者从不公开发布假设。相反，它提供对“预测oracle”的黑盒访问权限，该oracle可以预测从基础分布中抽取的无尽未标记示例的标签。重要的是，PEP可同时保护初始训练集和无尽分类查询的隐私。我们对PEP的定义进行了两个概念性改进，并展示了与之前的工作相比的显着改进的新构建。具体而言，（1）鲁棒性：PEP只在所有分类查询都是从正确的基础分布中抽取得到时才保证准确性。一些超出分布的查询可能会破坏未来查询的预测oracle的有效性， 即使这些查询是从正确的分布中抽样得到的。我们将鲁棒性与私人雅克比机制相结合，提供有保障的准确预测。",
    "tldr": "文章介绍了私人真正永恒的强大预测（PEP）模型，它通过提供对预测oracle的黑盒访问来实现不同ially private learning，保护了初始训练集和无尽分类查询的隐私。文章提出了对PEP定义的两个概念性改进，并展示了比以前的工作更好的新构建。具体而言，通过加入鲁棒性和私人雅克比机制，提供了可靠准确的预测。",
    "en_tdlr": "The paper introduces the Private Truly-Everlasting Robust-Prediction (PEP) model, which achieves differentially private learning by providing black-box access to a prediction oracle, protecting the privacy of both the initial training set and the endless stream of classification queries. The paper presents two conceptual modifications to the definition of PEP and showcases new constructions with significant improvements over prior work. Specifically, by incorporating robustness and the private Jacobian mechanism, reliable and accurate predictions are provided."
}