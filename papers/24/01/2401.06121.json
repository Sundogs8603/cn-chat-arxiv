{
    "title": "TOFU: A Task of Fictitious Unlearning for LLMs. (arXiv:2401.06121v1 [cs.LG])",
    "abstract": "Large language models trained on massive corpora of data from the web can memorize and reproduce sensitive or private data raising both legal and ethical concerns. Unlearning, or tuning models to forget information present in their training data, provides us with a way to protect private data after training. Although several methods exist for such unlearning, it is unclear to what extent they result in models equivalent to those where the data to be forgotten was never learned in the first place. To address this challenge, we present TOFU, a Task of Fictitious Unlearning, as a benchmark aimed at helping deepen our understanding of unlearning. We offer a dataset of 200 diverse synthetic author profiles, each consisting of 20 question-answer pairs, and a subset of these profiles called the forget set that serves as the target for unlearning. We compile a suite of metrics that work together to provide a holistic picture of unlearning efficacy. Finally, we provide a set of baseline results",
    "link": "http://arxiv.org/abs/2401.06121",
    "context": "Title: TOFU: A Task of Fictitious Unlearning for LLMs. (arXiv:2401.06121v1 [cs.LG])\nAbstract: Large language models trained on massive corpora of data from the web can memorize and reproduce sensitive or private data raising both legal and ethical concerns. Unlearning, or tuning models to forget information present in their training data, provides us with a way to protect private data after training. Although several methods exist for such unlearning, it is unclear to what extent they result in models equivalent to those where the data to be forgotten was never learned in the first place. To address this challenge, we present TOFU, a Task of Fictitious Unlearning, as a benchmark aimed at helping deepen our understanding of unlearning. We offer a dataset of 200 diverse synthetic author profiles, each consisting of 20 question-answer pairs, and a subset of these profiles called the forget set that serves as the target for unlearning. We compile a suite of metrics that work together to provide a holistic picture of unlearning efficacy. Finally, we provide a set of baseline results",
    "path": "papers/24/01/2401.06121.json",
    "total_tokens": 958,
    "translated_title": "TOFU: 一种用于LLM的虚拟遗忘任务",
    "translated_abstract": "大型语言模型在训练时可能会记忆和重现敏感或私密数据，引发法律和伦理上的关切。遗忘，或者调整模型以忘记训练数据中存在的信息，可以为我们提供一种在训练后保护私密数据的方式。尽管存在几种用于这种遗忘的方法，但尚不清楚它们在多大程度上会导致与从未学习过要被遗忘的数据的模型相等。为了解决这一挑战，我们提出了TOFU，一种虚拟遗忘任务，作为一个基准，旨在帮助我们加深对遗忘的理解。我们提供了一个由200个多样的合成作者配置文件组成的数据集，每个配置文件包含20个问答对，以及一个称为“遗忘集”的子集，作为遗忘的目标。我们编制了一套度量标准，共同提供了对遗忘效果的整体影响的完整画面。最后，我们提供了一组基准结果。",
    "tldr": "本研究提出了一种名为TOFU的虚拟遗忘任务，旨在帮助我们深入理解遗忘。通过提供一个包含200个合成作者配置文件的数据集以及一套综合度量标准，该研究探讨了遗忘方法的效果，并提供了一组基准结果。",
    "en_tdlr": "The study presents TOFU, a Task of Fictitious Unlearning, as a benchmark to deepen our understanding of unlearning. It provides a dataset of 200 diverse synthetic author profiles and a set of metrics to evaluate the efficacy of unlearning methods, along with baseline results."
}