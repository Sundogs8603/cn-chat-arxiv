{
    "title": "Attention and Autoencoder Hybrid Model for Unsupervised Online Anomaly Detection. (arXiv:2401.03322v1 [cs.LG])",
    "abstract": "This paper introduces a hybrid attention and autoencoder (AE) model for unsupervised online anomaly detection in time series. The autoencoder captures local structural patterns in short embeddings, while the attention model learns long-term features, facilitating parallel computing with positional encoding. Unique in its approach, our proposed hybrid model combines attention and autoencoder for the first time in time series anomaly detection. It employs an attention-based mechanism, akin to the deep transformer model, with key architectural modifications for predicting the next time step window in the autoencoder's latent space. The model utilizes a threshold from the validation dataset for anomaly detection and introduces an alternative method based on analyzing the first statistical moment of error, improving accuracy without dependence on a validation dataset. Evaluation on diverse real-world benchmark datasets and comparing with other well-established models, confirms the effective",
    "link": "http://arxiv.org/abs/2401.03322",
    "context": "Title: Attention and Autoencoder Hybrid Model for Unsupervised Online Anomaly Detection. (arXiv:2401.03322v1 [cs.LG])\nAbstract: This paper introduces a hybrid attention and autoencoder (AE) model for unsupervised online anomaly detection in time series. The autoencoder captures local structural patterns in short embeddings, while the attention model learns long-term features, facilitating parallel computing with positional encoding. Unique in its approach, our proposed hybrid model combines attention and autoencoder for the first time in time series anomaly detection. It employs an attention-based mechanism, akin to the deep transformer model, with key architectural modifications for predicting the next time step window in the autoencoder's latent space. The model utilizes a threshold from the validation dataset for anomaly detection and introduces an alternative method based on analyzing the first statistical moment of error, improving accuracy without dependence on a validation dataset. Evaluation on diverse real-world benchmark datasets and comparing with other well-established models, confirms the effective",
    "path": "papers/24/01/2401.03322.json",
    "total_tokens": 890,
    "translated_title": "基于注意力和自编码器的混合模型用于无监督在线异常检测",
    "translated_abstract": "本论文介绍了一种基于注意力和自编码器的混合模型，用于时间序列的无监督在线异常检测。自编码器捕捉短嵌入中的局部结构模式，而注意力模型学习长期特征，通过位置编码实现并行计算。在方法上独特的是，我们提出的混合模型首次在时间序列异常检测中结合了注意力和自编码器。它采用了类似深度变换器模型的注意力机制，并对自编码器的潜在空间中预测下一个时间步骤窗口进行了关键架构修改。该模型利用验证数据集中的阈值进行异常检测，并引入了一种基于分析误差的第一统计矩方法的替代方法，提高了准确性而不依赖于验证数据集。通过在多样的实际基准数据集上进行评估，并与其他广为认可的模型进行比较，证实了模型的有效性。",
    "tldr": "本文介绍了一种基于注意力和自编码器的混合模型，用于无监督的在线时间序列异常检测，通过结合注意力和自编码器，并在自编码器的潜在空间中预测下一个时间步骤窗口，提高了模型的准确性。"
}