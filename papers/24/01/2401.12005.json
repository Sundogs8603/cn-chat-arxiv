{
    "title": "ALMs: Authorial Language Models for Authorship Attribution",
    "abstract": "In this paper, we introduce an authorship attribution method called Authorial Language Models (ALMs) that involves identifying the most likely author of a questioned document based on the perplexity of the questioned document calculated for a set of causal language models fine-tuned on the writings of a set of candidate author. We benchmarked ALMs against state-of-art-systems using the CCAT50 dataset and the Blogs50 datasets. We find that ALMs achieves a macro-average accuracy score of 83.6% on Blogs50, outperforming all other methods, and 74.9% on CCAT50, matching the performance of the best method. To assess the performance of ALMs on shorter texts, we also conducted text ablation testing. We found that to reach a macro-average accuracy of 70%, ALMs needs 40 tokens on Blogs50 and 400 tokens on CCAT50, while to reach 60% ALMs requires 20 tokens on Blogs50 and 70 tokens on CCAT50.",
    "link": "https://arxiv.org/abs/2401.12005",
    "context": "Title: ALMs: Authorial Language Models for Authorship Attribution\nAbstract: In this paper, we introduce an authorship attribution method called Authorial Language Models (ALMs) that involves identifying the most likely author of a questioned document based on the perplexity of the questioned document calculated for a set of causal language models fine-tuned on the writings of a set of candidate author. We benchmarked ALMs against state-of-art-systems using the CCAT50 dataset and the Blogs50 datasets. We find that ALMs achieves a macro-average accuracy score of 83.6% on Blogs50, outperforming all other methods, and 74.9% on CCAT50, matching the performance of the best method. To assess the performance of ALMs on shorter texts, we also conducted text ablation testing. We found that to reach a macro-average accuracy of 70%, ALMs needs 40 tokens on Blogs50 and 400 tokens on CCAT50, while to reach 60% ALMs requires 20 tokens on Blogs50 and 70 tokens on CCAT50.",
    "path": "papers/24/01/2401.12005.json",
    "total_tokens": 933,
    "translated_title": "ALMs: 作者语言模型用于作者归属性",
    "translated_abstract": "在本文中，我们介绍了一种称为作者语言模型（ALMs）的作者归属方法，该方法通过计算基于一组被调整为候选作者的写作的因果语言模型的疑问文件的困惑度来确定最有可能的作者。我们使用CCAT50数据集和Blogs50数据集对ALMs进行了基准测试。我们发现，ALMs在Blogs50上取得了83.6%的宏平均准确率，超过了所有其他方法，而在CCAT50上取得了74.9%的宏平均准确率，与最好的方法相当。为了评估ALMs在较短文本上的性能，我们还进行了文本剥离测试。我们发现，为了达到70%的宏平均准确率，ALMs在Blogs50上需要40个令牌，在CCAT50上需要400个令牌，而为了达到60%，ALMs在Blogs50上需要20个令牌，在CCAT50上需要70个令牌。",
    "tldr": "本文介绍了一种名为作者语言模型（ALMs）的作者归属方法，通过计算疑问文件的困惑度来确定最有可能的作者。ALMs在Blogs50数据集上表现出色，在CCAT50数据集上与最好的方法相当。在较短文本上，ALMs需要较少的令牌来实现较高的准确率。"
}