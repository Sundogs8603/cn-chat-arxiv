{
    "title": "SNNLP: Energy-Efficient Natural Language Processing Using Spiking Neural Networks",
    "abstract": "As spiking neural networks receive more attention, we look toward applications of this computing paradigm in fields other than computer vision and signal processing. One major field, underexplored in the neuromorphic setting, is Natural Language Processing (NLP), where most state-of-the-art solutions still heavily rely on resource-consuming and power-hungry traditional deep learning architectures. Therefore, it is compelling to design NLP models for neuromorphic architectures due to their low energy requirements, with the additional benefit of a more human-brain-like operating model for processing information. However, one of the biggest issues with bringing NLP to the neuromorphic setting is in properly encoding text into a spike train so that it can be seamlessly handled by both current and future SNN architectures. In this paper, we compare various methods of encoding text as spikes and assess each method's performance in an associated SNN on a downstream NLP task, namely, sentiment",
    "link": "https://arxiv.org/abs/2401.17911",
    "context": "Title: SNNLP: Energy-Efficient Natural Language Processing Using Spiking Neural Networks\nAbstract: As spiking neural networks receive more attention, we look toward applications of this computing paradigm in fields other than computer vision and signal processing. One major field, underexplored in the neuromorphic setting, is Natural Language Processing (NLP), where most state-of-the-art solutions still heavily rely on resource-consuming and power-hungry traditional deep learning architectures. Therefore, it is compelling to design NLP models for neuromorphic architectures due to their low energy requirements, with the additional benefit of a more human-brain-like operating model for processing information. However, one of the biggest issues with bringing NLP to the neuromorphic setting is in properly encoding text into a spike train so that it can be seamlessly handled by both current and future SNN architectures. In this paper, we compare various methods of encoding text as spikes and assess each method's performance in an associated SNN on a downstream NLP task, namely, sentiment",
    "path": "papers/24/01/2401.17911.json",
    "total_tokens": 895,
    "translated_title": "SNNLP: 使用脉冲神经网络的高能效自然语言处理",
    "translated_abstract": "随着脉冲神经网络引起越来越多的关注，我们开始关注这种计算范式在计算机视觉和信号处理以外领域的应用。然而，在神经形态计算中，一个尚未充分研究的主要领域是自然语言处理（NLP），其中大多数最先进的解决方案仍然严重依赖资源消耗和耗电量较高的传统深度学习架构。因此，设计适用于神经形态架构的NLP模型具有引人注目的吸引力，因为它们具有较低的能量需求，并且在处理信息时具有更类似于人脑的操作模式的额外好处。然而，将NLP引入神经形态计算的最大问题之一在于如何将文本正确编码为脉冲序列，以便当前和未来的脉冲神经网络架构可以无缝处理。在本文章中，我们比较了不同的文本编码方法，并评估了每种方法在相关的脉冲神经网络上处理NLP任务（即情感分析）时的性能。",
    "tldr": "本论文研究了在自然语言处理领域中使用脉冲神经网络的高能效解决方案，并比较了不同的文本编码方法在相关任务中的性能。",
    "en_tdlr": "This paper investigates energy-efficient solutions in using spiking neural networks for natural language processing, and compares the performance of different text encoding methods in relevant tasks."
}