{
    "title": "Parametric Constraints for Bayesian Knowledge Tracing from First Principles. (arXiv:2401.09456v1 [cs.CY])",
    "abstract": "Bayesian Knowledge Tracing (BKT) is a probabilistic model of a learner's state of mastery corresponding to a knowledge component. It considers the learner's state of mastery as a \"hidden\" or latent binary variable and updates this state based on the observed correctness of the learner's response using parameters that represent transition probabilities between states. BKT is often represented as a Hidden Markov Model and the Expectation-Maximization (EM) algorithm is used to infer these parameters. However, this algorithm can suffer from several issues including producing multiple viable sets of parameters, settling into a local minima, producing degenerate parameter values, and a high computational cost during fitting. This paper takes a \"from first principles\" approach to deriving constraints that can be imposed on the BKT parameter space. Starting from the basic mathematical truths of probability and building up to the behaviors expected of the BKT parameters in real systems, this pa",
    "link": "http://arxiv.org/abs/2401.09456",
    "context": "Title: Parametric Constraints for Bayesian Knowledge Tracing from First Principles. (arXiv:2401.09456v1 [cs.CY])\nAbstract: Bayesian Knowledge Tracing (BKT) is a probabilistic model of a learner's state of mastery corresponding to a knowledge component. It considers the learner's state of mastery as a \"hidden\" or latent binary variable and updates this state based on the observed correctness of the learner's response using parameters that represent transition probabilities between states. BKT is often represented as a Hidden Markov Model and the Expectation-Maximization (EM) algorithm is used to infer these parameters. However, this algorithm can suffer from several issues including producing multiple viable sets of parameters, settling into a local minima, producing degenerate parameter values, and a high computational cost during fitting. This paper takes a \"from first principles\" approach to deriving constraints that can be imposed on the BKT parameter space. Starting from the basic mathematical truths of probability and building up to the behaviors expected of the BKT parameters in real systems, this pa",
    "path": "papers/24/01/2401.09456.json",
    "total_tokens": 829,
    "translated_title": "从一级原理出发的贝叶斯知识追踪的参数约束",
    "translated_abstract": "贝叶斯知识追踪(BKT)是一个学习者掌握状态的概率模型，对应一个知识组件。它将学习者的掌握状态视为一个“隐藏”的或潜在的二元变量，并根据学习者响应的正确性更新此状态，使用代表状态转换概率的参数。BKT通常被表示为一个隐藏马尔可夫模型，而期望最大化(EM)算法用于推断这些参数。然而，该算法可能面临多组可行的参数集、陷入局部最小值、产生退化的参数值以及拟合过程中的高计算成本等问题。本文采用“从一级原理”方法，推导出可以对BKT参数空间施加的约束。从概率的基本数学真理出发，逐步建立对于BKT参数在真实系统中所期望的行为。",
    "tldr": "本文从一级原理出发，推导出了可以在贝叶斯知识追踪的参数空间上施加的约束，解决了目前算法中存在的一系列问题。"
}