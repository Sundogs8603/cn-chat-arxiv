{
    "title": "PHOENIX: Open-Source Language Adaption for Direct Preference Optimization. (arXiv:2401.10580v1 [cs.CL])",
    "abstract": "Large language models have gained immense importance in recent years and have demonstrated outstanding results in solving various tasks. However, despite these achievements, many questions remain unanswered in the context of large language models. Besides the optimal use of the models for inference and the alignment of the results to the desired specifications, the transfer of models to other languages is still an underdeveloped area of research. The recent publication of models such as Llama-2 and Zephyr has provided new insights into architectural improvements and the use of human feedback. However, insights into adapting these techniques to other languages remain scarce. In this paper, we build on latest improvements and apply the Direct Preference Optimization(DPO) approach to the German language. The model is available at https://huggingface.co/DRXD1000/Phoenix.",
    "link": "http://arxiv.org/abs/2401.10580",
    "context": "Title: PHOENIX: Open-Source Language Adaption for Direct Preference Optimization. (arXiv:2401.10580v1 [cs.CL])\nAbstract: Large language models have gained immense importance in recent years and have demonstrated outstanding results in solving various tasks. However, despite these achievements, many questions remain unanswered in the context of large language models. Besides the optimal use of the models for inference and the alignment of the results to the desired specifications, the transfer of models to other languages is still an underdeveloped area of research. The recent publication of models such as Llama-2 and Zephyr has provided new insights into architectural improvements and the use of human feedback. However, insights into adapting these techniques to other languages remain scarce. In this paper, we build on latest improvements and apply the Direct Preference Optimization(DPO) approach to the German language. The model is available at https://huggingface.co/DRXD1000/Phoenix.",
    "path": "papers/24/01/2401.10580.json",
    "total_tokens": 773,
    "translated_title": "PHOENIX: 开源语言适应，用于直接偏好优化",
    "translated_abstract": "在最近几年中，大型语言模型变得非常重要，并在解决各种任务中展示出卓越的结果。然而，尽管取得了这些成就，但在大型语言模型的上下文中还有许多问题尚未解答。除了在推理中最佳使用模型和将结果与期望规范对齐之外，将模型转移到其他语言仍然是一个尚未开发完善的研究领域。最近发布的Llama-2和Zephyr等模型提供了关于架构改进和使用人类反馈的新见解。然而，关于如何将这些技术适配到其他语言的洞见仍然很少。在本文中，我们基于最新的改进，将直接偏好优化(DPO)方法应用到德语中。该模型可在https://huggingface.co/DRXD1000/Phoenix找到。",
    "tldr": "该论文介绍了一种开源的语言适应方法PHOENIX，用于直接优化偏好。研究构建在最新的改进基础上，并将直接偏好优化方法应用于德语。"
}