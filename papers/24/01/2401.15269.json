{
    "title": "Improving Medical Reasoning through Retrieval and Self-Reflection with Retrieval-Augmented Large Language Models. (arXiv:2401.15269v1 [cs.CL])",
    "abstract": "Recent proprietary large language models (LLMs), such as GPT-4, have achieved a milestone in tackling diverse challenges in the biomedical domain, ranging from multiple-choice questions to long-form generations. To address challenges that still cannot be handled with the encoded knowledge of LLMs, various retrieval-augmented generation (RAG) methods have been developed by searching documents from the knowledge corpus and appending them unconditionally or selectively to the input of LLMs for generation. However, when applying existing methods to different domain-specific problems, poor generalization becomes apparent, leading to fetching incorrect documents or making inaccurate judgments. In this paper, we introduce Self-BioRAG, a framework reliable for biomedical text that specializes in generating explanations, retrieving domain-specific documents, and self-reflecting generated responses. We utilize 84k filtered biomedical instruction sets to train Self-BioRAG that can assess its gene",
    "link": "http://arxiv.org/abs/2401.15269",
    "context": "Title: Improving Medical Reasoning through Retrieval and Self-Reflection with Retrieval-Augmented Large Language Models. (arXiv:2401.15269v1 [cs.CL])\nAbstract: Recent proprietary large language models (LLMs), such as GPT-4, have achieved a milestone in tackling diverse challenges in the biomedical domain, ranging from multiple-choice questions to long-form generations. To address challenges that still cannot be handled with the encoded knowledge of LLMs, various retrieval-augmented generation (RAG) methods have been developed by searching documents from the knowledge corpus and appending them unconditionally or selectively to the input of LLMs for generation. However, when applying existing methods to different domain-specific problems, poor generalization becomes apparent, leading to fetching incorrect documents or making inaccurate judgments. In this paper, we introduce Self-BioRAG, a framework reliable for biomedical text that specializes in generating explanations, retrieving domain-specific documents, and self-reflecting generated responses. We utilize 84k filtered biomedical instruction sets to train Self-BioRAG that can assess its gene",
    "path": "papers/24/01/2401.15269.json",
    "total_tokens": 910,
    "translated_title": "通过检索和自我反思改善医疗推理能力的检索增强型大型语言模型",
    "translated_abstract": "最近的专有大型语言模型（LLMs），例如GPT-4，在生物医学领域中解决了从多项选择题到长篇生成等多样化挑战的里程碑。为了解决LLMs编码知识无法处理的挑战，已经开发了各种检索增强生成（RAG）方法，通过从知识语料库中搜索文档并无条件或有选择地将其附加到LLMs的输入来进行生成。然而，将现有方法应用于不同领域特定问题时，出现了泛化能力差的问题，导致获取不正确的文档或做出不准确的判断。在本文中，我们介绍了一种可靠的医学文本框架Self-BioRAG，专门用于生成解释、检索领域特定文档和自我反思生成的响应。我们使用了84k个经过过滤的生物医学指令集来训练Self-BioRAG，它具备评估自己的基因",
    "tldr": "本论文介绍了一种名为Self-BioRAG的框架，通过使用检索和自我反思的方法，提高了医疗推理的能力。该框架专注于生成解释、检索领域特定文档以及对生成的响应进行自我反思。",
    "en_tdlr": "This paper introduces a framework called Self-BioRAG that improves medical reasoning through retrieval and self-reflection. The framework focuses on generating explanations, retrieving domain-specific documents, and self-reflecting on the generated responses."
}