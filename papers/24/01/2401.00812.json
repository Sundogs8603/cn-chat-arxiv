{
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents. (arXiv:2401.00812v2 [cs.CL] UPDATED)",
    "abstract": "The prominent large language models (LLMs) of today differ from past language models not only in size, but also in the fact that they are trained on a combination of natural language and formal language (code). As a medium between humans and computers, code translates high-level goals into executable steps, featuring standard syntax, logical consistency, abstraction, and modularity. In this survey, we present an overview of the various benefits of integrating code into LLMs' training data. Specifically, beyond enhancing LLMs in code generation, we observe that these unique properties of code help (i) unlock the reasoning ability of LLMs, enabling their applications to a range of more complex natural language tasks; (ii) steer LLMs to produce structured and precise intermediate steps, which can then be connected to external execution ends through function calls; and (iii) take advantage of code compilation and execution environment, which also provides diverse feedback for model improve",
    "link": "http://arxiv.org/abs/2401.00812",
    "context": "Title: If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents. (arXiv:2401.00812v2 [cs.CL] UPDATED)\nAbstract: The prominent large language models (LLMs) of today differ from past language models not only in size, but also in the fact that they are trained on a combination of natural language and formal language (code). As a medium between humans and computers, code translates high-level goals into executable steps, featuring standard syntax, logical consistency, abstraction, and modularity. In this survey, we present an overview of the various benefits of integrating code into LLMs' training data. Specifically, beyond enhancing LLMs in code generation, we observe that these unique properties of code help (i) unlock the reasoning ability of LLMs, enabling their applications to a range of more complex natural language tasks; (ii) steer LLMs to produce structured and precise intermediate steps, which can then be connected to external execution ends through function calls; and (iii) take advantage of code compilation and execution environment, which also provides diverse feedback for model improve",
    "path": "papers/24/01/2401.00812.json",
    "total_tokens": 938,
    "translated_title": "如果LLM是巫师，那么代码就是魔杖：关于代码如何使大规模语言模型成为智能代理的调查",
    "translated_abstract": "当今知名的大规模语言模型（LLMs）与过去的语言模型不仅在大小上有所不同，还在于它们在训练数据中结合了自然语言和形式语言（代码）。作为人类和计算机之间的中介，代码将高层次的目标转化为可执行的步骤，具有标准的语法、逻辑一致性、抽象和模块化。在本调查中，我们概述了将代码整合到LLMs的训练数据中的各种好处。具体而言，除了增强LLMs的代码生成能力外，我们观察到代码的这些独特属性有助于（i）激发LLMs的推理能力，使其能够应用于更复杂的自然语言任务；（ii）引导LLMs生成结构化和精确的中间步骤，然后通过函数调用与外部执行端连接起来；以及（iii）利用代码编译和执行环境，为模型改进提供多样化的反馈。",
    "tldr": "本调查研究探讨了在大规模语言模型中整合代码的好处，包括提升LLMs的代码生成能力、激发推理能力、生成结构化和精确的中间步骤，并利用代码的编译和执行环境来改善模型。"
}