{
    "title": "Improving Natural Language Understanding with Computation-Efficient Retrieval Representation Fusion. (arXiv:2401.02993v1 [cs.CL])",
    "abstract": "Retrieval-based augmentations that aim to incorporate knowledge from an external database into language models have achieved great success in various knowledge-intensive (KI) tasks, such as question-answering and text generation. However, integrating retrievals in non-knowledge-intensive (NKI) tasks, such as text classification, is still challenging. Existing works focus on concatenating retrievals to inputs as context to form the prompt-based inputs. Unfortunately, such methods require language models to have the capability to handle long texts. Besides, inferring such concatenated data would also consume a significant amount of computational resources.  To solve these challenges, we propose \\textbf{ReFusion} in this paper, a computation-efficient \\textbf{Re}trieval representation \\textbf{Fusion} with neural architecture search. The main idea is to directly fuse the retrieval representations into the language models. Specifically, we first propose an online retrieval module that retri",
    "link": "http://arxiv.org/abs/2401.02993",
    "context": "Title: Improving Natural Language Understanding with Computation-Efficient Retrieval Representation Fusion. (arXiv:2401.02993v1 [cs.CL])\nAbstract: Retrieval-based augmentations that aim to incorporate knowledge from an external database into language models have achieved great success in various knowledge-intensive (KI) tasks, such as question-answering and text generation. However, integrating retrievals in non-knowledge-intensive (NKI) tasks, such as text classification, is still challenging. Existing works focus on concatenating retrievals to inputs as context to form the prompt-based inputs. Unfortunately, such methods require language models to have the capability to handle long texts. Besides, inferring such concatenated data would also consume a significant amount of computational resources.  To solve these challenges, we propose \\textbf{ReFusion} in this paper, a computation-efficient \\textbf{Re}trieval representation \\textbf{Fusion} with neural architecture search. The main idea is to directly fuse the retrieval representations into the language models. Specifically, we first propose an online retrieval module that retri",
    "path": "papers/24/01/2401.02993.json",
    "total_tokens": 843,
    "translated_title": "使用计算高效的检索表示融合提高自然语言理解能力",
    "translated_abstract": "从外部数据库中获取知识并融入语言模型的检索增强方法在各种知识密集型任务（例如问答和文本生成）中取得了巨大成功。然而，在非知识密集型任务（例如文本分类）中集成检索仍然具有挑战性。现有的研究集中在将检索内容拼接到输入中形成提示性的输入。然而，这种方法要求语言模型具备处理长文本的能力。此外，推断这种拼接数据也会消耗大量的计算资源。为了解决这些问题，本文提出了一种计算高效的检索表示融合方法ReFusion，采用神经架构搜索。主要思想是直接将检索表示与语言模型进行融合。具体地，我们首先提出了一种在线检索模块，重新检索...",
    "tldr": "本文提出了一种计算高效的检索表示融合方法ReFusion，通过将检索表示直接融合到语言模型中，解决了将外部数据库的知识融入非知识密集型任务中的挑战。"
}