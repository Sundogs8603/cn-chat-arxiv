{
    "title": "Binary Feature Mask Optimization for Feature Selection. (arXiv:2401.12644v1 [cs.LG])",
    "abstract": "We investigate feature selection problem for generic machine learning (ML) models. We introduce a novel framework that selects features considering the predictions of the model. Our framework innovates by using a novel feature masking approach to eliminate the features during the selection process, instead of completely removing them from the dataset. This allows us to use the same ML model during feature selection, unlike other feature selection methods where we need to train the ML model again as the dataset has different dimensions on each iteration. We obtain the mask operator using the predictions of the ML model, which offers a comprehensive view on the subsets of the features essential for the predictive performance of the model. A variety of approaches exist in the feature selection literature. However, no study has introduced a training-free framework for a generic ML model to select features while considering the importance of the feature subsets as a whole, instead of focusi",
    "link": "http://arxiv.org/abs/2401.12644",
    "context": "Title: Binary Feature Mask Optimization for Feature Selection. (arXiv:2401.12644v1 [cs.LG])\nAbstract: We investigate feature selection problem for generic machine learning (ML) models. We introduce a novel framework that selects features considering the predictions of the model. Our framework innovates by using a novel feature masking approach to eliminate the features during the selection process, instead of completely removing them from the dataset. This allows us to use the same ML model during feature selection, unlike other feature selection methods where we need to train the ML model again as the dataset has different dimensions on each iteration. We obtain the mask operator using the predictions of the ML model, which offers a comprehensive view on the subsets of the features essential for the predictive performance of the model. A variety of approaches exist in the feature selection literature. However, no study has introduced a training-free framework for a generic ML model to select features while considering the importance of the feature subsets as a whole, instead of focusi",
    "path": "papers/24/01/2401.12644.json",
    "total_tokens": 946,
    "translated_title": "二进制特征屏蔽优化用于特征选择",
    "translated_abstract": "我们研究了通用机器学习模型的特征选择问题。我们引入了一种新颖的框架，该框架考虑了模型的预测结果来选择特征。我们的框架通过使用一种新颖的特征屏蔽方法，在特征选择过程中消除特征，而不是从数据集中完全移除它们。这使我们能够在特征选择过程中使用相同的机器学习模型，而不像其他特征选择方法那样需要在每次迭代中重新训练机器学习模型，因为数据集的维度不同。我们使用机器学习模型的预测结果来获取屏蔽操作符，这为模型的预测性能提供了对特征子集的全面观察。特征选择文献中存在各种方法。然而，没有研究引入一个针对通用机器学习模型的无需训练的框架，以整体考虑特征子集的重要性，而不是只关注单个特征的重要性。",
    "tldr": "这个论文提出了一种新颖的特征选择框架，通过使用特征屏蔽方法来消除特征，而不是从数据集中移除它们。这种方法不需要重新训练机器学习模型，可以综合考虑特征子集的重要性，为通用机器学习模型的特征选择问题提供了一种新的解决方案。",
    "en_tdlr": "This paper proposes a novel feature selection framework that eliminates features using a feature masking approach instead of completely removing them from the dataset. This method does not require retraining the machine learning model and provides a new solution to the feature selection problem for generic machine learning models by considering the importance of feature subsets."
}