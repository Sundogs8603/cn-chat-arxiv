{
    "title": "Few-Shot Causal Representation Learning for Out-of-Distribution Generalization on Heterogeneous Graphs",
    "abstract": "arXiv:2401.03597v2 Announce Type: replace  Abstract: Heterogeneous graph few-shot learning (HGFL) has been developed to address the label sparsity issue in heterogeneous graphs (HGs), which consist of various types of nodes and edges. The core concept of HGFL is to extract knowledge from rich-labeled classes in a source HG, transfer this knowledge to a target HG to facilitate learning new classes with few-labeled training data, and finally make predictions on unlabeled testing data. Existing methods typically assume that the source HG, training data, and testing data all share the same distribution. However, in practice, distribution shifts among these three types of data are inevitable due to two reasons: (1) the limited availability of the source HG that matches the target HG distribution, and (2) the unpredictable data generation mechanism of the target HG. Such distribution shifts result in ineffective knowledge transfer and poor learning performance in existing methods, thereby le",
    "link": "https://arxiv.org/abs/2401.03597",
    "context": "Title: Few-Shot Causal Representation Learning for Out-of-Distribution Generalization on Heterogeneous Graphs\nAbstract: arXiv:2401.03597v2 Announce Type: replace  Abstract: Heterogeneous graph few-shot learning (HGFL) has been developed to address the label sparsity issue in heterogeneous graphs (HGs), which consist of various types of nodes and edges. The core concept of HGFL is to extract knowledge from rich-labeled classes in a source HG, transfer this knowledge to a target HG to facilitate learning new classes with few-labeled training data, and finally make predictions on unlabeled testing data. Existing methods typically assume that the source HG, training data, and testing data all share the same distribution. However, in practice, distribution shifts among these three types of data are inevitable due to two reasons: (1) the limited availability of the source HG that matches the target HG distribution, and (2) the unpredictable data generation mechanism of the target HG. Such distribution shifts result in ineffective knowledge transfer and poor learning performance in existing methods, thereby le",
    "path": "papers/24/01/2401.03597.json",
    "total_tokens": 864,
    "translated_title": "少样本因果表示学习用于异构图的跨领域泛化",
    "translated_abstract": "异构图少样本学习（HGFL）已经被研发来解决异构图（HGs）中标签稀疏问题，其中包括各种类型的节点和边。HGFL的核心概念是从源HG中富标记类中提取知识，将这些知识转移到目标HG以促进学习新类别，使用少量标记的训练数据，并最终在未标记的测试数据上进行预测。现有方法通常假设源HG、训练数据和测试数据都共享相同的分布。然而，在实践中，这三种数据之间的分布转变是不可避免的，原因有两个：（1）源HG的有限可用性与目标HG分布匹配，以及（2）目标HG的不可预测数据生成机制。这种分布转变导致现有方法中知识传递无效和学习性能不佳。",
    "tldr": "该论文提出了一种少样本因果表示学习方法，用于在异构图上实现跨领域泛化，解决了源HG与目标HG分布不匹配导致的知识传递无效和学习性能不佳的问题。",
    "en_tdlr": "This paper proposes a few-shot causal representation learning method for achieving cross-domain generalization on heterogeneous graphs, addressing the issue of ineffective knowledge transfer and poor learning performance caused by mismatched distributions between the source HG and the target HG."
}