{
    "title": "Training Differentially Private Ad Prediction Models with Semi-Sensitive Features. (arXiv:2401.15246v1 [cs.LG])",
    "abstract": "Motivated by problems arising in digital advertising, we introduce the task of training differentially private (DP) machine learning models with semi-sensitive features. In this setting, a subset of the features is known to the attacker (and thus need not be protected) while the remaining features as well as the label are unknown to the attacker and should be protected by the DP guarantee. This task interpolates between training the model with full DP (where the label and all features should be protected) or with label DP (where all the features are considered known, and only the label should be protected). We present a new algorithm for training DP models with semi-sensitive features. Through an empirical evaluation on real ads datasets, we demonstrate that our algorithm surpasses in utility the baselines of (i) DP stochastic gradient descent (DP-SGD) run on all features (known and unknown), and (ii) a label DP algorithm run only on the known features (while discarding the unknown one",
    "link": "http://arxiv.org/abs/2401.15246",
    "context": "Title: Training Differentially Private Ad Prediction Models with Semi-Sensitive Features. (arXiv:2401.15246v1 [cs.LG])\nAbstract: Motivated by problems arising in digital advertising, we introduce the task of training differentially private (DP) machine learning models with semi-sensitive features. In this setting, a subset of the features is known to the attacker (and thus need not be protected) while the remaining features as well as the label are unknown to the attacker and should be protected by the DP guarantee. This task interpolates between training the model with full DP (where the label and all features should be protected) or with label DP (where all the features are considered known, and only the label should be protected). We present a new algorithm for training DP models with semi-sensitive features. Through an empirical evaluation on real ads datasets, we demonstrate that our algorithm surpasses in utility the baselines of (i) DP stochastic gradient descent (DP-SGD) run on all features (known and unknown), and (ii) a label DP algorithm run only on the known features (while discarding the unknown one",
    "path": "papers/24/01/2401.15246.json",
    "total_tokens": 903,
    "translated_title": "使用半敏感特征训练差分隐私广告预测模型",
    "translated_abstract": "我们以数字广告中出现的问题为出发点，介绍了使用半敏感特征训练差分隐私机器学习模型的任务。在这种情况下，攻击者已知一部分特征（因此无需保护），而剩余的特征以及标签对于攻击者来说是未知的，需要通过差分隐私保护。这个任务插值了使用全差分隐私（需要保护标签和所有特征）或标签差分隐私（所有特征被认为是已知的，只需保护标签）来训练模型。我们提出了一种新的算法来训练具有半敏感特征的差分隐私模型。通过对真实广告数据集的实证评估，我们证明了我们的算法在效用方面超过了（i）在所有特征上运行的差分隐私随机梯度下降（DP-SGD）基线和（ii）仅在已知特征上运行的标签差分隐私算法（而丢弃了未知的特征）。",
    "tldr": "我们介绍了一种新的算法，用于训练具有半敏感特征的差分隐私广告预测模型，并在真实广告数据集上证明了其优于传统方法的效果。"
}