{
    "title": "Singer Identity Representation Learning using Self-Supervised Techniques. (arXiv:2401.05064v1 [cs.SD])",
    "abstract": "Significant strides have been made in creating voice identity representations using speech data. However, the same level of progress has not been achieved for singing voices. To bridge this gap, we suggest a framework for training singer identity encoders to extract representations suitable for various singing-related tasks, such as singing voice similarity and synthesis. We explore different self-supervised learning techniques on a large collection of isolated vocal tracks and apply data augmentations during training to ensure that the representations are invariant to pitch and content variations. We evaluate the quality of the resulting representations on singer similarity and identification tasks across multiple datasets, with a particular emphasis on out-of-domain generalization. Our proposed framework produces high-quality embeddings that outperform both speaker verification and wav2vec 2.0 pre-trained baselines on singing voice while operating at 44.1 kHz. We release our code and",
    "link": "http://arxiv.org/abs/2401.05064",
    "context": "Title: Singer Identity Representation Learning using Self-Supervised Techniques. (arXiv:2401.05064v1 [cs.SD])\nAbstract: Significant strides have been made in creating voice identity representations using speech data. However, the same level of progress has not been achieved for singing voices. To bridge this gap, we suggest a framework for training singer identity encoders to extract representations suitable for various singing-related tasks, such as singing voice similarity and synthesis. We explore different self-supervised learning techniques on a large collection of isolated vocal tracks and apply data augmentations during training to ensure that the representations are invariant to pitch and content variations. We evaluate the quality of the resulting representations on singer similarity and identification tasks across multiple datasets, with a particular emphasis on out-of-domain generalization. Our proposed framework produces high-quality embeddings that outperform both speaker verification and wav2vec 2.0 pre-trained baselines on singing voice while operating at 44.1 kHz. We release our code and",
    "path": "papers/24/01/2401.05064.json",
    "total_tokens": 869,
    "translated_title": "使用自监督技术进行歌手身份表示学习",
    "translated_abstract": "在使用语音数据创建声音身份表示方面已经取得了重要进展。然而，对于唱歌声音，还没有取得同样的进展。为了弥补这一差距，我们提出了一个框架，用于训练歌手身份编码器，以提取适用于各种唱歌相关任务（如唱歌声音相似性和合成）的表示。我们在大量的独立音轨上探索了不同的自监督学习技术，并在训练期间应用数据增强，以确保表示对音高和内容变化不变。我们在多个数据集上评估了所得到表示的质量，特别注重领域外泛化能力。我们提出的框架在44.1 kHz条件下产生了高质量的嵌入，优于说话人验证和wav2vec 2.0预训练基线，并在唱歌声音上操作。我们发布了我们的代码和...",
    "tldr": "本论文提出了一个框架，通过使用自监督技术在大量的独立音轨上训练，以提取适用于唱歌相关任务的高质量歌手身份表示。实验证明，这些表示在多个数据集上优于现有的基线方法，并具备领域外泛化能力。"
}