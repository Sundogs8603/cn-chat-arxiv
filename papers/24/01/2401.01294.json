{
    "title": "Efficient Sparse Least Absolute Deviation Regression with Differential Privacy. (arXiv:2401.01294v1 [stat.ML])",
    "abstract": "In recent years, privacy-preserving machine learning algorithms have attracted increasing attention because of their important applications in many scientific fields. However, in the literature, most privacy-preserving algorithms demand learning objectives to be strongly convex and Lipschitz smooth, which thus cannot cover a wide class of robust loss functions (e.g., quantile/least absolute loss). In this work, we aim to develop a fast privacy-preserving learning solution for a sparse robust regression problem. Our learning loss consists of a robust least absolute loss and an $\\ell_1$ sparse penalty term. To fast solve the non-smooth loss under a given privacy budget, we develop a Fast Robust And Privacy-Preserving Estimation (FRAPPE) algorithm for least absolute deviation regression. Our algorithm achieves a fast estimation by reformulating the sparse LAD problem as a penalized least square estimation problem and adopts a three-stage noise injection to guarantee the $(\\epsilon,\\delta)",
    "link": "http://arxiv.org/abs/2401.01294",
    "context": "Title: Efficient Sparse Least Absolute Deviation Regression with Differential Privacy. (arXiv:2401.01294v1 [stat.ML])\nAbstract: In recent years, privacy-preserving machine learning algorithms have attracted increasing attention because of their important applications in many scientific fields. However, in the literature, most privacy-preserving algorithms demand learning objectives to be strongly convex and Lipschitz smooth, which thus cannot cover a wide class of robust loss functions (e.g., quantile/least absolute loss). In this work, we aim to develop a fast privacy-preserving learning solution for a sparse robust regression problem. Our learning loss consists of a robust least absolute loss and an $\\ell_1$ sparse penalty term. To fast solve the non-smooth loss under a given privacy budget, we develop a Fast Robust And Privacy-Preserving Estimation (FRAPPE) algorithm for least absolute deviation regression. Our algorithm achieves a fast estimation by reformulating the sparse LAD problem as a penalized least square estimation problem and adopts a three-stage noise injection to guarantee the $(\\epsilon,\\delta)",
    "path": "papers/24/01/2401.01294.json",
    "total_tokens": 994,
    "translated_title": "高效的稀疏最小绝对偏差回归与差分隐私",
    "translated_abstract": "最近几年来，隐私保护的机器学习算法因其在许多科学领域的重要应用而受到越来越多的关注。然而，在文献中，大多数隐私保护算法要求学习目标是强凸且Lipschitz平滑的，这不能涵盖广泛的鲁棒损失函数（例如，分位数/最小绝对损失）。在这项工作中，我们旨在为稀疏鲁棒回归问题开发一种快速的隐私保护学习解决方案。我们的学习损失包括一个鲁棒的最小绝对损失和一个l1稀疏惩罚项。为了在给定的隐私预算下快速解决非光滑损失，我们开发了一种快速鲁棒和隐私保护估计（FRAPPE）算法来进行最小绝对偏差回归。我们的算法通过将稀疏LAD问题重新表述为惩罚最小二乘估计问题，并采用三阶段噪声注入来保证（ε、δ）差分隐私保护。",
    "tldr": "本论文研究了稀疏最小绝对偏差回归问题中的隐私保护学习解决方案，通过开发一种快速的算法，将非光滑损失问题转化为惩罚最小二乘估计问题，并采用三阶段噪声注入来保证差分隐私保护。",
    "en_tdlr": "This paper investigates privacy-preserving learning solutions for sparse least absolute deviation regression problems. It develops a fast algorithm by reformulating the non-smooth loss problem as a penalized least square estimation problem and adopts a three-stage noise injection for differential privacy protection."
}