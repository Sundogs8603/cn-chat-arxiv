{
    "title": "Generative AI to Generate Test Data Generators",
    "abstract": "Generating fake data is an essential dimension of modern software testing, as demonstrated by the number and significance of data faking libraries. Yet, developers of faking libraries cannot keep up with the wide range of data to be generated for different natural languages and domains. In this paper, we assess the ability of generative AI for generating test data in different domains. We design three types of prompts for Large Language Models (LLMs), which perform test data generation tasks at different levels of integrability: 1) raw test data generation, 2) synthesizing programs in a specific language that generate useful test data, and 3) producing programs that use state-of-the-art faker libraries. We evaluate our approach by prompting LLMs to generate test data for 11 domains. The results show that LLMs can successfully generate realistic test data generators in a wide range of domains at all three levels of integrability.",
    "link": "https://arxiv.org/abs/2401.17626",
    "context": "Title: Generative AI to Generate Test Data Generators\nAbstract: Generating fake data is an essential dimension of modern software testing, as demonstrated by the number and significance of data faking libraries. Yet, developers of faking libraries cannot keep up with the wide range of data to be generated for different natural languages and domains. In this paper, we assess the ability of generative AI for generating test data in different domains. We design three types of prompts for Large Language Models (LLMs), which perform test data generation tasks at different levels of integrability: 1) raw test data generation, 2) synthesizing programs in a specific language that generate useful test data, and 3) producing programs that use state-of-the-art faker libraries. We evaluate our approach by prompting LLMs to generate test data for 11 domains. The results show that LLMs can successfully generate realistic test data generators in a wide range of domains at all three levels of integrability.",
    "path": "papers/24/01/2401.17626.json",
    "total_tokens": 769,
    "translated_title": "生成式人工智能生成测试数据生成器",
    "translated_abstract": "生成假数据是现代软件测试的重要维度之一，众多数据伪造库的数量和重要性证明了这一点。然而，伪造库的开发者无法满足不同自然语言和领域所需生成的广泛数据范围。本文评估了生成式人工智能在不同领域生成测试数据的能力。我们设计了三种类型的大型语言模型（LLMs）提示，它们在不同的集成级别上执行测试数据生成任务：1）原始测试数据生成，2）合成特定语言的程序以生成有用的测试数据，3）生成使用尖端伪造库的程序。我们通过提示LLMs为11个领域生成测试数据来评估我们的方法。结果表明，在所有三个集成级别上，LLMs能够成功地生成逼真的测试数据生成器。",
    "tldr": "本研究评估了生成式人工智能在不同领域生成测试数据的能力，并证明它能够在不同的集成级别上生成逼真的测试数据生成器。",
    "en_tdlr": "This paper evaluates the ability of generative AI to generate test data in different domains, and demonstrates its capability to generate realistic test data generators at different levels of integrability."
}