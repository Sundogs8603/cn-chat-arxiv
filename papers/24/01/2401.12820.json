{
    "title": "DatUS^2: Data-driven Unsupervised Semantic Segmentation with Pre-trained Self-supervised Vision Transformer. (arXiv:2401.12820v1 [cs.CV])",
    "abstract": "Successive proposals of several self-supervised training schemes continue to emerge, taking one step closer to developing a universal foundation model. In this process, the unsupervised downstream tasks are recognized as one of the evaluation methods to validate the quality of visual features learned with a self-supervised training scheme. However, unsupervised dense semantic segmentation has not been explored as a downstream task, which can utilize and evaluate the quality of semantic information introduced in patch-level feature representations during self-supervised training of a vision transformer. Therefore, this paper proposes a novel data-driven approach for unsupervised semantic segmentation (DatUS^2) as a downstream task. DatUS^2 generates semantically consistent and dense pseudo annotate segmentation masks for the unlabeled image dataset without using any visual-prior or synchronized data. We compare these pseudo-annotated segmentation masks with ground truth masks for evalua",
    "link": "http://arxiv.org/abs/2401.12820",
    "context": "Title: DatUS^2: Data-driven Unsupervised Semantic Segmentation with Pre-trained Self-supervised Vision Transformer. (arXiv:2401.12820v1 [cs.CV])\nAbstract: Successive proposals of several self-supervised training schemes continue to emerge, taking one step closer to developing a universal foundation model. In this process, the unsupervised downstream tasks are recognized as one of the evaluation methods to validate the quality of visual features learned with a self-supervised training scheme. However, unsupervised dense semantic segmentation has not been explored as a downstream task, which can utilize and evaluate the quality of semantic information introduced in patch-level feature representations during self-supervised training of a vision transformer. Therefore, this paper proposes a novel data-driven approach for unsupervised semantic segmentation (DatUS^2) as a downstream task. DatUS^2 generates semantically consistent and dense pseudo annotate segmentation masks for the unlabeled image dataset without using any visual-prior or synchronized data. We compare these pseudo-annotated segmentation masks with ground truth masks for evalua",
    "path": "papers/24/01/2401.12820.json",
    "total_tokens": 891,
    "translated_title": "DatUS^2: 使用预训练的自监督视觉Transformer进行数据驱动的无监督语义分割",
    "translated_abstract": "连续提出了几种自监督训练方案的建议，使得开发通用基础模型更近了一步。在这个过程中，无监督下游任务被认为是验证通过自监督训练方案学习到的视觉特征质量的方法之一。然而，尚未探索无监督的密集语义分割作为一种下游任务，它可以利用和评估自监督训练过程中引入的语义信息在补丁级特征表示中的质量。因此，本文提出了一种新颖的基于数据驱动的无监督语义分割方法（DatUS^2）作为一种下游任务。DatUS^2为未标记的图像数据集生成了语义一致且密集的伪标注分割掩模，而不使用任何视觉先验或同步数据。我们将这些伪标注分割掩模与真实掩模进行了比较以进行评估。",
    "tldr": "本文提出了一种新颖的数据驱动无监督语义分割方法（DatUS^2），通过自监督训练生成语义一致且密集的伪标注分割掩模，用于评估视觉特征质量。"
}