{
    "title": "On The Temporal Domain of Differential Equation Inspired Graph Neural Networks. (arXiv:2401.11074v1 [cs.LG])",
    "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable success in modeling complex relationships in graph-structured data. A recent innovation in this field is the family of Differential Equation-Inspired Graph Neural Networks (DE-GNNs), which leverage principles from continuous dynamical systems to model information flow on graphs with built-in properties such as feature smoothing or preservation. However, existing DE-GNNs rely on first or second-order temporal dependencies. In this paper, we propose a neural extension to those pre-defined temporal dependencies. We show that our model, called TDE-GNN, can capture a wide range of temporal dynamics that go beyond typical first or second-order methods, and provide use cases where existing temporal models are challenged. We demonstrate the benefit of learning the temporal dependencies using our method rather than using pre-defined temporal dynamics on several graph benchmarks.",
    "link": "http://arxiv.org/abs/2401.11074",
    "context": "Title: On The Temporal Domain of Differential Equation Inspired Graph Neural Networks. (arXiv:2401.11074v1 [cs.LG])\nAbstract: Graph Neural Networks (GNNs) have demonstrated remarkable success in modeling complex relationships in graph-structured data. A recent innovation in this field is the family of Differential Equation-Inspired Graph Neural Networks (DE-GNNs), which leverage principles from continuous dynamical systems to model information flow on graphs with built-in properties such as feature smoothing or preservation. However, existing DE-GNNs rely on first or second-order temporal dependencies. In this paper, we propose a neural extension to those pre-defined temporal dependencies. We show that our model, called TDE-GNN, can capture a wide range of temporal dynamics that go beyond typical first or second-order methods, and provide use cases where existing temporal models are challenged. We demonstrate the benefit of learning the temporal dependencies using our method rather than using pre-defined temporal dynamics on several graph benchmarks.",
    "path": "papers/24/01/2401.11074.json",
    "total_tokens": 900,
    "translated_title": "关于微分方程激发的图神经网络的时域问题研究",
    "translated_abstract": "图神经网络（GNNs）在建模图结构数据中的复杂关系方面取得了显著的成功。最近在这个领域的一个创新是微分方程激发的图神经网络（DE-GNNs），它利用连续动态系统的原理来模拟具有内置属性（如特征平滑或保留）的图上的信息流。然而，现有的DE-GNNs依赖于一阶或二阶时域相关性。本文提出了一个神经扩展来解决这些预定义的时域依赖问题。我们展示了我们的模型TDE-GNN能够捕捉到超过一阶或二阶方法的各种时域动态，并提供了现有时域模型无法解决的用例。我们通过在几个图基准测试上学习时域依赖性的益处来证明我们的方法相比于使用预定义时域动态的优势。",
    "tldr": "本文提出了一种名为TDE-GNN的模型，解决了现有微分方程激发的图神经网络中一阶或二阶时域相关性的限制。通过学习时域依赖性，我们的模型能够捕捉到更广泛的时域动态，并取得了在几个图基准测试上的优越表现。",
    "en_tdlr": "This paper introduces TDE-GNN, a model that overcomes the limitation of first or second-order temporal dependencies in existing DE-GNNs. By learning temporal dependencies, our model can capture a wider range of temporal dynamics and outperforms on several graph benchmarks."
}