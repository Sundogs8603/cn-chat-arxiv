{
    "title": "Are LLMs Robust for Spoken Dialogues?. (arXiv:2401.02297v1 [cs.CL])",
    "abstract": "Large Pre-Trained Language Models have demonstrated state-of-the-art performance in different downstream tasks, including dialogue state tracking and end-to-end response generation. Nevertheless, most of the publicly available datasets and benchmarks on task-oriented dialogues focus on written conversations. Consequently, the robustness of the developed models to spoken interactions is unknown. In this work, we have evaluated the performance of LLMs for spoken task-oriented dialogues on the DSTC11 test sets. Due to the lack of proper spoken dialogue datasets, we have automatically transcribed a development set of spoken dialogues with a state-of-the-art ASR engine. We have characterized the ASR-error types and their distributions and simulated these errors in a large dataset of dialogues. We report the intrinsic (perplexity) and extrinsic (human evaluation) performance of fine-tuned GPT-2 and T5 models in two subtasks of response generation and dialogue state tracking, respectively. Th",
    "link": "http://arxiv.org/abs/2401.02297",
    "context": "Title: Are LLMs Robust for Spoken Dialogues?. (arXiv:2401.02297v1 [cs.CL])\nAbstract: Large Pre-Trained Language Models have demonstrated state-of-the-art performance in different downstream tasks, including dialogue state tracking and end-to-end response generation. Nevertheless, most of the publicly available datasets and benchmarks on task-oriented dialogues focus on written conversations. Consequently, the robustness of the developed models to spoken interactions is unknown. In this work, we have evaluated the performance of LLMs for spoken task-oriented dialogues on the DSTC11 test sets. Due to the lack of proper spoken dialogue datasets, we have automatically transcribed a development set of spoken dialogues with a state-of-the-art ASR engine. We have characterized the ASR-error types and their distributions and simulated these errors in a large dataset of dialogues. We report the intrinsic (perplexity) and extrinsic (human evaluation) performance of fine-tuned GPT-2 and T5 models in two subtasks of response generation and dialogue state tracking, respectively. Th",
    "path": "papers/24/01/2401.02297.json",
    "total_tokens": 895,
    "translated_title": "对话型语言模型在口语对话中的鲁棒性研究",
    "translated_abstract": "大型预训练语言模型在对话状态跟踪和端到端回复生成等不同下游任务中展示了最先进的性能。然而，大多数公开可用的面向任务的对话数据集和基准都集中在书面对话上。因此，我们对开发的模型在口语交互中的鲁棒性进行了评估。由于缺乏适当的口语对话数据集，我们使用了最先进的自动语音识别引擎自动转录了一个口语对话的开发集。我们对ASR错误类型及其分布进行了特征化，并在大规模的对话数据集中模拟了这些错误。我们报告了GPT-2和T5模型在回复生成和对话状态跟踪两个子任务中的内在（困惑度）和外在（人工评估）性能。",
    "tldr": "本文评估了LLMs在口语任务导向对话中的性能，并报告了回复生成和对话状态跟踪两个子任务中的模型表现。由于缺乏适当的口语对话数据集，我们使用自动语音识别引擎转录了口语对话的开发集，并模拟了ASR错误以进行评估。"
}