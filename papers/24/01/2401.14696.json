{
    "title": "Asymptotic Midpoint Mixup for Margin Balancing and Moderate Broadening. (arXiv:2401.14696v1 [cs.LG])",
    "abstract": "In the feature space, the collapse between features invokes critical problems in representation learning by remaining the features undistinguished. Interpolation-based augmentation methods such as mixup have shown their effectiveness in relieving the collapse problem between different classes, called inter-class collapse. However, intra-class collapse raised in coarse-to-fine transfer learning has not been discussed in the augmentation approach. To address them, we propose a better feature augmentation method, asymptotic midpoint mixup. The method generates augmented features by interpolation but gradually moves them toward the midpoint of inter-class feature pairs. As a result, the method induces two effects: 1) balancing the margin for all classes and 2) only moderately broadening the margin until it holds maximal confidence. We empirically analyze the collapse effects by measuring alignment and uniformity with visualizing representations. Then, we validate the intra-class collapse e",
    "link": "http://arxiv.org/abs/2401.14696",
    "context": "Title: Asymptotic Midpoint Mixup for Margin Balancing and Moderate Broadening. (arXiv:2401.14696v1 [cs.LG])\nAbstract: In the feature space, the collapse between features invokes critical problems in representation learning by remaining the features undistinguished. Interpolation-based augmentation methods such as mixup have shown their effectiveness in relieving the collapse problem between different classes, called inter-class collapse. However, intra-class collapse raised in coarse-to-fine transfer learning has not been discussed in the augmentation approach. To address them, we propose a better feature augmentation method, asymptotic midpoint mixup. The method generates augmented features by interpolation but gradually moves them toward the midpoint of inter-class feature pairs. As a result, the method induces two effects: 1) balancing the margin for all classes and 2) only moderately broadening the margin until it holds maximal confidence. We empirically analyze the collapse effects by measuring alignment and uniformity with visualizing representations. Then, we validate the intra-class collapse e",
    "path": "papers/24/01/2401.14696.json",
    "total_tokens": 911,
    "translated_title": "渐进中点混合用于边距平衡和适度扩展的方法",
    "translated_abstract": "在特征空间中，特征之间的崩塌导致了表示学习中的一些关键问题，使得特征无法区分。基于插值的数据增强方法，如mixup，在减轻不同类别之间的崩塌问题上显示出了有效性，这被称为类间崩塌。然而，粗细转移学习中引起的类内崩塌并未在增强方法中讨论。为了解决这些问题，我们提出了一种更好的特征增强方法，即渐进中点混合。该方法通过插值生成增强特征，但将它们逐渐移动到类间特征对的中点。结果是，该方法产生了两个效果：1）平衡所有类别的边距，2）仅适度扩展边距，直到达到最大置信度。我们通过测量可视化表示的对齐性和均匀性来经验分析了崩塌效应。然后，我们验证了增强方法所带来的类内崩塌问题。",
    "tldr": "提出了渐进中点混合方法来解决粗细转移学习中的类内崩塌问题。该方法通过逐渐将增强特征移动至类间特征对的中点，实现了边距平衡以及适度扩展边距的效果。"
}