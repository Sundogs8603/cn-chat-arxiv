{
    "title": "MTAD: Tools and Benchmarks for Multivariate Time Series Anomaly Detection. (arXiv:2401.06175v1 [cs.SE])",
    "abstract": "Key Performance Indicators (KPIs) are essential time-series metrics for ensuring the reliability and stability of many software systems. They faithfully record runtime states to facilitate the understanding of anomalous system behaviors and provide informative clues for engineers to pinpoint the root causes. The unprecedented scale and complexity of modern software systems, however, make the volume of KPIs explode. Consequently, many traditional methods of KPI anomaly detection become impractical, which serves as a catalyst for the fast development of machine learning-based solutions in both academia and industry. However, there is currently a lack of rigorous comparison among these KPI anomaly detection methods, and re-implementation demands a non-trivial effort. Moreover, we observe that different works adopt independent evaluation processes with different metrics. Some of them may not fully reveal the capability of a model and some are creating an illusion of progress. To better und",
    "link": "http://arxiv.org/abs/2401.06175",
    "context": "Title: MTAD: Tools and Benchmarks for Multivariate Time Series Anomaly Detection. (arXiv:2401.06175v1 [cs.SE])\nAbstract: Key Performance Indicators (KPIs) are essential time-series metrics for ensuring the reliability and stability of many software systems. They faithfully record runtime states to facilitate the understanding of anomalous system behaviors and provide informative clues for engineers to pinpoint the root causes. The unprecedented scale and complexity of modern software systems, however, make the volume of KPIs explode. Consequently, many traditional methods of KPI anomaly detection become impractical, which serves as a catalyst for the fast development of machine learning-based solutions in both academia and industry. However, there is currently a lack of rigorous comparison among these KPI anomaly detection methods, and re-implementation demands a non-trivial effort. Moreover, we observe that different works adopt independent evaluation processes with different metrics. Some of them may not fully reveal the capability of a model and some are creating an illusion of progress. To better und",
    "path": "papers/24/01/2401.06175.json",
    "total_tokens": 860,
    "translated_title": "MTAD: 多元时间序列异常检测的工具和基准",
    "translated_abstract": "关键绩效指标是确保许多软件系统可靠性和稳定性的重要时间序列指标。它们忠实记录运行时状态，便于理解异常系统行为，并为工程师提供定位根本原因的有用线索。然而，现代软件系统的规模和复杂性前所未有，导致KPI数量激增。因此，许多传统的KPI异常检测方法变得不实用，这促使了学术界和工业界机器学习解决方案的快速发展。然而，目前缺乏对这些KPI异常检测方法的严格比较，并且重新实现需要付出相当大的工作量。此外，我们观察到不同的研究采用独立的评估过程和不同的指标。其中一些可能无法充分展示模型的能力，有些则产生了进展的错觉。为了更好地理解这个问题，我们提出了一套综合的多元时间序列异常检测工具和基准。",
    "tldr": "这篇论文提出了一套综合的多元时间序列异常检测工具和基准，解决了现有方法缺乏严格比较和重新实现困难的问题。",
    "en_tdlr": "This paper presents a comprehensive set of tools and benchmarks for multivariate time series anomaly detection, addressing the lack of rigorous comparison among existing methods and difficulties in re-implementation."
}