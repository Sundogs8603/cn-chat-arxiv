{
    "title": "Fast Adversarial Training against Textual Adversarial Attacks. (arXiv:2401.12461v1 [cs.CL])",
    "abstract": "Many adversarial defense methods have been proposed to enhance the adversarial robustness of natural language processing models. However, most of them introduce additional pre-set linguistic knowledge and assume that the synonym candidates used by attackers are accessible, which is an ideal assumption. We delve into adversarial training in the embedding space and propose a Fast Adversarial Training (FAT) method to improve the model robustness in the synonym-unaware scenario from the perspective of single-step perturbation generation and perturbation initialization. Based on the observation that the adversarial perturbations crafted by single-step and multi-step gradient ascent are similar, FAT uses single-step gradient ascent to craft adversarial examples in the embedding space to expedite the training process. Based on the observation that the perturbations generated on the identical training sample in successive epochs are similar, FAT fully utilizes historical information when initi",
    "link": "http://arxiv.org/abs/2401.12461",
    "context": "Title: Fast Adversarial Training against Textual Adversarial Attacks. (arXiv:2401.12461v1 [cs.CL])\nAbstract: Many adversarial defense methods have been proposed to enhance the adversarial robustness of natural language processing models. However, most of them introduce additional pre-set linguistic knowledge and assume that the synonym candidates used by attackers are accessible, which is an ideal assumption. We delve into adversarial training in the embedding space and propose a Fast Adversarial Training (FAT) method to improve the model robustness in the synonym-unaware scenario from the perspective of single-step perturbation generation and perturbation initialization. Based on the observation that the adversarial perturbations crafted by single-step and multi-step gradient ascent are similar, FAT uses single-step gradient ascent to craft adversarial examples in the embedding space to expedite the training process. Based on the observation that the perturbations generated on the identical training sample in successive epochs are similar, FAT fully utilizes historical information when initi",
    "path": "papers/24/01/2401.12461.json",
    "total_tokens": 913,
    "translated_title": "快速对抗训练与文本对抗攻击",
    "translated_abstract": "许多对抗性防御方法已被提出，以增强自然语言处理模型的对抗鲁棒性。然而，大多数方法引入了额外的预设语言知识，并假设攻击者使用的同义词候选词是可访问的，这是一个理想的假设。我们深入研究了嵌入空间中的对抗性训练，并从单步扰动生成和扰动初始化角度提出了一种快速对抗训练（FAT）方法，以改善在无同义词知识的情况下模型的鲁棒性。基于单步和多步梯度上升生成的对抗扰动相似的观察，FAT使用单步梯度上升在嵌入空间中生成对抗性示例，以加速训练过程。基于连续纪元中同一训练样本上生成的扰动相似的观察，FAT充分利用历史信息来初始化扰动。",
    "tldr": "本研究提出了一种快速对抗训练（FAT）方法，用于提高自然语言处理模型在无同义词知识的情况下的对抗鲁棒性。该方法通过单步梯度上升在嵌入空间中生成对抗性示例，以加速训练过程。"
}