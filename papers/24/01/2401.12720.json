{
    "title": "A Comprehensive View of the Biases of Toxicity and Sentiment Analysis Methods Towards Utterances with African American English Expressions. (arXiv:2401.12720v1 [cs.CL])",
    "abstract": "Language is a dynamic aspect of our culture that changes when expressed in different technologies/communities. Online social networks have enabled the diffusion and evolution of different dialects, including African American English (AAE). However, this increased usage is not without barriers. One particular barrier is how sentiment (Vader, TextBlob, and Flair) and toxicity (Google's Perspective and the open-source Detoxify) methods present biases towards utterances with AAE expressions. Consider Google's Perspective to understand bias. Here, an utterance such as ``All n*ggers deserve to die respectfully. The police murder us.'' it reaches a higher toxicity than ``African-Americans deserve to die respectfully. The police murder us.''. This score difference likely arises because the tool cannot understand the re-appropriation of the term ``n*gger''. One explanation for this bias is that AI models are trained on limited datasets, and using such a term in training data is more likely to a",
    "link": "http://arxiv.org/abs/2401.12720",
    "context": "Title: A Comprehensive View of the Biases of Toxicity and Sentiment Analysis Methods Towards Utterances with African American English Expressions. (arXiv:2401.12720v1 [cs.CL])\nAbstract: Language is a dynamic aspect of our culture that changes when expressed in different technologies/communities. Online social networks have enabled the diffusion and evolution of different dialects, including African American English (AAE). However, this increased usage is not without barriers. One particular barrier is how sentiment (Vader, TextBlob, and Flair) and toxicity (Google's Perspective and the open-source Detoxify) methods present biases towards utterances with AAE expressions. Consider Google's Perspective to understand bias. Here, an utterance such as ``All n*ggers deserve to die respectfully. The police murder us.'' it reaches a higher toxicity than ``African-Americans deserve to die respectfully. The police murder us.''. This score difference likely arises because the tool cannot understand the re-appropriation of the term ``n*gger''. One explanation for this bias is that AI models are trained on limited datasets, and using such a term in training data is more likely to a",
    "path": "papers/24/01/2401.12720.json",
    "total_tokens": 991,
    "translated_title": "对有着非洲裔美国英语表达的论述的毒性和情感分析方法的偏见的全面观察",
    "translated_abstract": "语言是我们文化的动态方面，不同的技术/社区中表达就会有所变化。在线社交网络使得不同方言，包括非洲裔美国英语（AAE）得以传播和演变。然而，这种增加的使用也存在障碍。其中一个障碍是情感（Vader，TextBlob和Flair）和毒性（谷歌的Perspective和开源的Detoxify）方法在对带有AAE表达的话语上呈现偏见。以谷歌的Perspective为例来理解偏见。在这里，像“所有黑鬼都应该受到尊重地死去。警察谋杀我们。”这样的话语比“非洲裔美国人应该受到尊重地死去。警察谋杀我们。”的毒性得分更高。这种得分差异很可能是因为该工具不能理解对“黑鬼”一词的再适应。对这种偏见的一个解释是，AI模型是基于有限的数据集进行训练的，使用这样的术语在训练数据中更有可能发生。",
    "tldr": "这项研究全面观察了情感和毒性分析方法对带有非洲裔美国英语表达的话语中的偏见。实验结果发现由于AI模型的训练数据有限，导致这些方法在对待对“黑鬼”一词的再适应时存在偏差。"
}