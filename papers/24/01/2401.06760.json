{
    "title": "Navigating the Metrics Maze: Reconciling Score Magnitudes and Accuracies. (arXiv:2401.06760v1 [cs.CL])",
    "abstract": "Ten years ago a single metric, BLEU, governed progress in machine translation research. For better or worse, there is no such consensus today, and consequently it is difficult for researchers to develop and retain the kinds of heuristic intuitions about metric deltas that drove earlier research and deployment decisions. This paper investigates the \"dynamic range\" of a number of modern metrics in an effort to provide a collective understanding of the meaning of differences in scores both within and among metrics; in other words, we ask what point difference X in metric Y is required between two systems for humans to notice? We conduct our evaluation on a new large dataset, ToShip23, using it to discover deltas at which metrics achieve system-level differences that are meaningful to humans, which we measure by pairwise system accuracy. We additionally show that this method of establishing delta-accuracy is more stable than the standard use of statistical p-values in regards to testset si",
    "link": "http://arxiv.org/abs/2401.06760",
    "context": "Title: Navigating the Metrics Maze: Reconciling Score Magnitudes and Accuracies. (arXiv:2401.06760v1 [cs.CL])\nAbstract: Ten years ago a single metric, BLEU, governed progress in machine translation research. For better or worse, there is no such consensus today, and consequently it is difficult for researchers to develop and retain the kinds of heuristic intuitions about metric deltas that drove earlier research and deployment decisions. This paper investigates the \"dynamic range\" of a number of modern metrics in an effort to provide a collective understanding of the meaning of differences in scores both within and among metrics; in other words, we ask what point difference X in metric Y is required between two systems for humans to notice? We conduct our evaluation on a new large dataset, ToShip23, using it to discover deltas at which metrics achieve system-level differences that are meaningful to humans, which we measure by pairwise system accuracy. We additionally show that this method of establishing delta-accuracy is more stable than the standard use of statistical p-values in regards to testset si",
    "path": "papers/24/01/2401.06760.json",
    "total_tokens": 873,
    "translated_title": "解决度量数值和准确性之间的迷宫：导航指标",
    "translated_abstract": "十年前，机器翻译研究中有一个单一的度量标准BLEU。如今，没有这样的共识，因此研究人员很难发展和保持之前推动研究和部署决策的那种启发性直觉。本文研究了一系列现代度量标准的“动态范围”，以提供对度量标准之间和内部得分差异的共同理解；换句话说，我们要问在度量标准Y中，两个系统需要有多大的得分差异X，人类才能注意到？我们使用一个新的大型数据集ToShip23进行评估，使用它发现度量标准达到人类感知水平的系统差异，我们通过成对系统准确性来衡量。此外，我们还表明与标准的统计p值在测试集上的稳定性相比，使用该方法建立差异准确性更为稳定。",
    "tldr": "本文研究了一系列现代度量标准的“动态范围”，以提供对度量标准之间和内部得分差异的共同理解，并通过人类感知水平的系统差异进行衡量。",
    "en_tdlr": "This paper investigates the \"dynamic range\" of a number of modern metrics in order to provide a collective understanding of the meaning of differences in scores both within and among metrics, and measures the system-level differences that are meaningful to humans."
}