{
    "title": "Sample-and-Bound for Non-Convex Optimization. (arXiv:2401.04812v1 [cs.AI])",
    "abstract": "Standard approaches for global optimization of non-convex functions, such as branch-and-bound, maintain partition trees to systematically prune the domain. The tree size grows exponentially in the number of dimensions. We propose new sampling-based methods for non-convex optimization that adapts Monte Carlo Tree Search (MCTS) to improve efficiency. Instead of the standard use of visitation count in Upper Confidence Bounds, we utilize numerical overapproximations of the objective as an uncertainty metric, and also take into account of sampled estimates of first-order and second-order information. The Monte Carlo tree in our approach avoids the usual fixed combinatorial patterns in growing the tree, and aggressively zooms into the promising regions, while still balancing exploration and exploitation. We evaluate the proposed algorithms on high-dimensional non-convex optimization benchmarks against competitive baselines and analyze the effects of the hyper parameters.",
    "link": "http://arxiv.org/abs/2401.04812",
    "context": "Title: Sample-and-Bound for Non-Convex Optimization. (arXiv:2401.04812v1 [cs.AI])\nAbstract: Standard approaches for global optimization of non-convex functions, such as branch-and-bound, maintain partition trees to systematically prune the domain. The tree size grows exponentially in the number of dimensions. We propose new sampling-based methods for non-convex optimization that adapts Monte Carlo Tree Search (MCTS) to improve efficiency. Instead of the standard use of visitation count in Upper Confidence Bounds, we utilize numerical overapproximations of the objective as an uncertainty metric, and also take into account of sampled estimates of first-order and second-order information. The Monte Carlo tree in our approach avoids the usual fixed combinatorial patterns in growing the tree, and aggressively zooms into the promising regions, while still balancing exploration and exploitation. We evaluate the proposed algorithms on high-dimensional non-convex optimization benchmarks against competitive baselines and analyze the effects of the hyper parameters.",
    "path": "papers/24/01/2401.04812.json",
    "total_tokens": 912,
    "translated_title": "采样与束缚用于非凸优化",
    "translated_abstract": "针对非凸函数的全局优化标准方法，如分支和束缚，维护可用于系统剪枝的分区树。树的大小随维度的增加而呈指数增长。我们提出了一种新的基于采样的非凸优化方法，它改进了蒙特卡罗树搜索(MCTS)的效率。我们不再使用标准的访问计数来作为不确定度指标，而是利用目标的数值上估计作为不确定度指标，并考虑采样估计的一阶和二阶信息。我们的方法中的蒙特卡罗树避免了通常固定组合模式的树生长，并积极地缩小到有希望的区域，同时平衡探索和开发。我们将提出的算法与竞争基线在高维非凸优化基准上进行评估，并分析超参数的影响。",
    "tldr": "本论文提出了一种基于采样的非凸优化方法，采用Monte Carlo Tree Search (MCTS)来提高效率，并利用数值上估计的不确定度指标和采样估计的一阶和二阶信息，避免固定组合模式的树生长，积极缩小到有希望的区域，同时平衡探索和开发。",
    "en_tdlr": "This paper proposes a sampling-based method for non-convex optimization, utilizing Monte Carlo Tree Search (MCTS) to improve efficiency. It uses numerical overapproximations as an uncertainty metric and incorporates first-order and second-order information from sampled estimates. The Monte Carlo tree avoids fixed combinatorial patterns and aggressively zooms into promising regions, while balancing exploration and exploitation."
}