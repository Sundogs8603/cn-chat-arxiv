{
    "title": "A large dataset curation and benchmark for drug target interaction",
    "abstract": "Bioactivity data plays a key role in drug discovery and repurposing. The resource-demanding nature of \\textit{in vitro} and \\textit{in vivo} experiments, as well as the recent advances in data-driven computational biochemistry research, highlight the importance of \\textit{in silico} drug target interaction (DTI) prediction approaches. While numerous large public bioactivity data sources exist, research in the field could benefit from better standardization of existing data resources. At present, different research works that share similar goals are often difficult to compare properly because of different choices of data sources and train/validation/test split strategies. Additionally, many works are based on small data subsets, leading to results and insights of possible limited validity. In this paper we propose a way to standardize and represent efficiently a very large dataset curated from multiple public sources, split the data into train, validation and test sets based on differen",
    "link": "https://arxiv.org/abs/2401.17174",
    "context": "Title: A large dataset curation and benchmark for drug target interaction\nAbstract: Bioactivity data plays a key role in drug discovery and repurposing. The resource-demanding nature of \\textit{in vitro} and \\textit{in vivo} experiments, as well as the recent advances in data-driven computational biochemistry research, highlight the importance of \\textit{in silico} drug target interaction (DTI) prediction approaches. While numerous large public bioactivity data sources exist, research in the field could benefit from better standardization of existing data resources. At present, different research works that share similar goals are often difficult to compare properly because of different choices of data sources and train/validation/test split strategies. Additionally, many works are based on small data subsets, leading to results and insights of possible limited validity. In this paper we propose a way to standardize and represent efficiently a very large dataset curated from multiple public sources, split the data into train, validation and test sets based on differen",
    "path": "papers/24/01/2401.17174.json",
    "total_tokens": 906,
    "translated_title": "一个用于药物靶标相互作用的大型数据集整理与基准测试",
    "translated_abstract": "生物活性数据在药物发现和重用中起着关键作用。因为\\textit{体外}和\\textit{体内}实验的资源需求大以及数据驱动的计算生物化学研究的最新进展，强调了\\textit{体内}药物靶标相互作用（DTI）预测方法的重要性。尽管存在许多大型公开生物活性数据源，但该领域的研究可以从对现有数据资源进行更好的标准化中受益。目前，不同研究工作往往难以正确比较，因为它们选择不同的数据源和训练/验证/测试集拆分策略。另外，许多工作基于小数据子集，导致可能具有有限有效性的结果和洞见。本文提出了一种方法来标准化和高效表示从多个公共资源中整理的非常大的数据集，并根据不同的选择将数据集划分为训练、验证和测试集。",
    "tldr": "本研究提出了一种通过整理和标准化多个公共资源的大型数据集，并采用不同的划分策略将数据集分为训练、验证和测试集的方法，以促进药物靶标相互作用的预测研究的标准化和比较。",
    "en_tdlr": "This paper proposes a method for curating and standardizing a large dataset from multiple public sources, and splitting it into training, validation, and test sets using different strategies, to facilitate the standardization and comparison of drug target interaction (DTI) prediction research."
}