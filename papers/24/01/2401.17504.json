{
    "title": "CaMU: Disentangling Causal Effects in Deep Model Unlearning",
    "abstract": "Machine unlearning requires removing the information of forgetting data while keeping the necessary information of remaining data. Despite recent advancements in this area, existing methodologies mainly focus on the effect of removing forgetting data without considering the negative impact this can have on the information of the remaining data, resulting in significant performance degradation after data removal. Although some methods try to repair the performance of remaining data after removal, the forgotten information can also return after repair. Such an issue is due to the intricate intertwining of the forgetting and remaining data. Without adequately differentiating the influence of these two kinds of data on the model, existing algorithms take the risk of either inadequate removal of the forgetting data or unnecessary loss of valuable information from the remaining data. To address this shortcoming, the present study undertakes a causal analysis of the unlearning and introduces ",
    "link": "https://arxiv.org/abs/2401.17504",
    "context": "Title: CaMU: Disentangling Causal Effects in Deep Model Unlearning\nAbstract: Machine unlearning requires removing the information of forgetting data while keeping the necessary information of remaining data. Despite recent advancements in this area, existing methodologies mainly focus on the effect of removing forgetting data without considering the negative impact this can have on the information of the remaining data, resulting in significant performance degradation after data removal. Although some methods try to repair the performance of remaining data after removal, the forgotten information can also return after repair. Such an issue is due to the intricate intertwining of the forgetting and remaining data. Without adequately differentiating the influence of these two kinds of data on the model, existing algorithms take the risk of either inadequate removal of the forgetting data or unnecessary loss of valuable information from the remaining data. To address this shortcoming, the present study undertakes a causal analysis of the unlearning and introduces ",
    "path": "papers/24/01/2401.17504.json",
    "total_tokens": 832,
    "translated_title": "CaMU：深度模型“遗忘”的因果效应解析",
    "translated_abstract": "机器“遗忘”需要在消除已遗忘数据的信息的同时，保留剩余数据的必要信息。尽管该领域近年来取得了一些进展，但现有的方法主要关注消除已遗忘数据的效果，而没有考虑到这可能对剩余数据的信息造成的负面影响，导致数据移除后显著性能下降。虽然一些方法尝试在移除后修复剩余数据的性能，但被遗忘的信息也可能在修复后再次出现。这个问题是由于“遗忘”和剩余数据的错综复杂的相互交织造成的。在充分区分这两类数据对模型的影响之前，现有的算法冒着要么不能充分消除已遗忘数据的风险，要么损失剩余数据的宝贵信息的风险。为了解决这个不足，本研究对“遗忘”进行了因果分析，并引入了一种新的方法。",
    "tldr": "本研究对深度模型的“遗忘”进行了因果分析，并提出了一种新的方法来解决移除已遗忘数据时对剩余数据信息损失的问题。",
    "en_tdlr": "This study provides a causal analysis of deep model \"unlearning\" and introduces a new method to address the issue of loss of information from the remaining data when removing forgotten data."
}