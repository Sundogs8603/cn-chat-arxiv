{
    "title": "UNSEE: Unsupervised Non-contrastive Sentence Embeddings. (arXiv:2401.15316v1 [cs.CL])",
    "abstract": "We present UNSEE: Unsupervised Non-Contrastive Sentence Embeddings, a novel approach that outperforms SimCSE in the Massive Text Embedding benchmark. Our exploration begins by addressing the challenge of representation collapse, a phenomenon observed when contrastive objectives in SimCSE are replaced with non-contrastive objectives. To counter this issue, we propose a straightforward solution known as the target network, effectively mitigating representation collapse. The introduction of the target network allows us to leverage non-contrastive objectives, maintaining training stability while achieving performance improvements comparable to contrastive objectives. Our method has achieved peak performance in non-contrastive sentence embeddings through meticulous fine-tuning and optimization. This comprehensive effort has yielded superior sentence representation models, showcasing the effectiveness of our approach.",
    "link": "http://arxiv.org/abs/2401.15316",
    "context": "Title: UNSEE: Unsupervised Non-contrastive Sentence Embeddings. (arXiv:2401.15316v1 [cs.CL])\nAbstract: We present UNSEE: Unsupervised Non-Contrastive Sentence Embeddings, a novel approach that outperforms SimCSE in the Massive Text Embedding benchmark. Our exploration begins by addressing the challenge of representation collapse, a phenomenon observed when contrastive objectives in SimCSE are replaced with non-contrastive objectives. To counter this issue, we propose a straightforward solution known as the target network, effectively mitigating representation collapse. The introduction of the target network allows us to leverage non-contrastive objectives, maintaining training stability while achieving performance improvements comparable to contrastive objectives. Our method has achieved peak performance in non-contrastive sentence embeddings through meticulous fine-tuning and optimization. This comprehensive effort has yielded superior sentence representation models, showcasing the effectiveness of our approach.",
    "path": "papers/24/01/2401.15316.json",
    "total_tokens": 773,
    "translated_title": "UNSEE: 无监督的非对比度句子嵌入",
    "translated_abstract": "我们提出了一种名为UNSEE（Unsupervised Non-Contrastive Sentence Embeddings）的新方法，在大规模文本嵌入基准测试中超越了SimCSE。我们首先解决了SimCSE中替换对比目标为非对比目标时出现的表示坍塌挑战。为了解决这个问题，我们提出了一种称为目标网络的简单解决方案，有效地缓解了表示坍塌。目标网络的引入使我们能够利用非对比目标，在保持训练稳定性的同时实现与对比目标相当的性能提升。通过精心调整和优化，我们的方法在非对比度句子嵌入上达到了巅峰性能。这一全面的努力产生了出色的句子表示模型，展示了我们方法的有效性。",
    "tldr": "UNSEE是一种无监督的非对比度句子嵌入方法，通过引入目标网络解决了表示坍塌问题，达到了与对比目标相当的性能提升。"
}