{
    "title": "DIALIGHT: Lightweight Multilingual Development and Evaluation of Task-Oriented Dialogue Systems with Large Language Models. (arXiv:2401.02208v1 [cs.CL])",
    "abstract": "We present DIALIGHT, a toolkit for developing and evaluating multilingual Task-Oriented Dialogue (ToD) systems which facilitates systematic evaluations and comparisons between ToD systems using fine-tuning of Pretrained Language Models (PLMs) and those utilising the zero-shot and in-context learning capabilities of Large Language Models (LLMs). In addition to automatic evaluation, this toolkit features (i) a secure, user-friendly web interface for fine-grained human evaluation at both local utterance level and global dialogue level, and (ii) a microservice-based backend, improving efficiency and scalability. Our evaluations reveal that while PLM fine-tuning leads to higher accuracy and coherence, LLM-based systems excel in producing diverse and likeable responses. However, we also identify significant challenges of LLMs in adherence to task-specific instructions and generating outputs in multiple languages, highlighting areas for future research. We hope this open-sourced toolkit will ",
    "link": "http://arxiv.org/abs/2401.02208",
    "context": "Title: DIALIGHT: Lightweight Multilingual Development and Evaluation of Task-Oriented Dialogue Systems with Large Language Models. (arXiv:2401.02208v1 [cs.CL])\nAbstract: We present DIALIGHT, a toolkit for developing and evaluating multilingual Task-Oriented Dialogue (ToD) systems which facilitates systematic evaluations and comparisons between ToD systems using fine-tuning of Pretrained Language Models (PLMs) and those utilising the zero-shot and in-context learning capabilities of Large Language Models (LLMs). In addition to automatic evaluation, this toolkit features (i) a secure, user-friendly web interface for fine-grained human evaluation at both local utterance level and global dialogue level, and (ii) a microservice-based backend, improving efficiency and scalability. Our evaluations reveal that while PLM fine-tuning leads to higher accuracy and coherence, LLM-based systems excel in producing diverse and likeable responses. However, we also identify significant challenges of LLMs in adherence to task-specific instructions and generating outputs in multiple languages, highlighting areas for future research. We hope this open-sourced toolkit will ",
    "path": "papers/24/01/2401.02208.json",
    "total_tokens": 1094,
    "translated_title": "DIALIGHT：轻量级多语言开发和评估以大语言模型为基础的面向任务对话系统",
    "translated_abstract": "我们提出了DIALIGHT，这是一个工具包，用于开发和评估多语言的面向任务的对话系统。它通过对预训练语言模型（PLM）进行微调和利用大型语言模型（LLM）的零-shot和上下文学习能力，使得系统评估和比较更加系统化。除了自动评估外，该工具包还具有（i）一个安全、用户友好的网络界面，用于在本地文本级和全局对话级进行细粒度的人工评估，以及（ii）基于微服务的后端，提高了效率和可扩展性。我们的评估结果表明，PLM微调可以提高准确性和连贯性，而基于LLM的系统在产生多样化和受欢迎的回复方面表现出色。然而，我们也发现LLM在遵循任务特定指令和生成多语言输出方面存在重要挑战，这为未来的研究指明了方向。我们希望这个开源工具包能够帮助研究人员更好地开发和评估任务导向的对话系统。",
    "tldr": "DIALIGHT是一个用于开发和评估多语言的面向任务的对话系统的工具包，通过对预训练语言模型进行微调和利用大型语言模型的零-shot和上下文学习能力，可以进行系统化的评估和比较。研究发现，PLM微调可以提高准确性和连贯性，而LLM系统在产生多样化和受欢迎的回复方面表现出色，但需要解决LLM在遵循任务特定指令和生成多语言输出方面的挑战。",
    "en_tdlr": "DIALIGHT is a toolkit for developing and evaluating multilingual Task-Oriented Dialogue (ToD) systems, enabling systematic evaluation and comparison through fine-tuning of Pretrained Language Models (PLMs) and the use of Large Language Models (LLMs) with zero-shot and in-context learning capabilities. The evaluations reveal that PLM fine-tuning improves accuracy and coherence, while LLM-based systems excel in producing diverse and likeable responses. However, challenges with adherence to task-specific instructions and generating outputs in multiple languages are identified."
}