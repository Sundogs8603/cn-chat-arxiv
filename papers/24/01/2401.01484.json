{
    "title": "Uncertainty Regularized Evidential Regression. (arXiv:2401.01484v1 [cs.LG])",
    "abstract": "The Evidential Regression Network (ERN) represents a novel approach that integrates deep learning with Dempster-Shafer's theory to predict a target and quantify the associated uncertainty. Guided by the underlying theory, specific activation functions must be employed to enforce non-negative values, which is a constraint that compromises model performance by limiting its ability to learn from all samples. This paper provides a theoretical analysis of this limitation and introduces an improvement to overcome it. Initially, we define the region where the models can't effectively learn from the samples. Following this, we thoroughly analyze the ERN and investigate this constraint. Leveraging the insights from our analysis, we address the limitation by introducing a novel regularization term that empowers the ERN to learn from the whole training set. Our extensive experiments substantiate our theoretical findings and demonstrate the effectiveness of the proposed solution.",
    "link": "http://arxiv.org/abs/2401.01484",
    "context": "Title: Uncertainty Regularized Evidential Regression. (arXiv:2401.01484v1 [cs.LG])\nAbstract: The Evidential Regression Network (ERN) represents a novel approach that integrates deep learning with Dempster-Shafer's theory to predict a target and quantify the associated uncertainty. Guided by the underlying theory, specific activation functions must be employed to enforce non-negative values, which is a constraint that compromises model performance by limiting its ability to learn from all samples. This paper provides a theoretical analysis of this limitation and introduces an improvement to overcome it. Initially, we define the region where the models can't effectively learn from the samples. Following this, we thoroughly analyze the ERN and investigate this constraint. Leveraging the insights from our analysis, we address the limitation by introducing a novel regularization term that empowers the ERN to learn from the whole training set. Our extensive experiments substantiate our theoretical findings and demonstrate the effectiveness of the proposed solution.",
    "path": "papers/24/01/2401.01484.json",
    "total_tokens": 814,
    "translated_title": "不确定性规范化的证据回归",
    "translated_abstract": "证据回归网络（ERN）是一种将深度学习与Dempster-Shafer理论相结合的新方法，用于预测目标并量化相关的不确定性。在底层理论的指导下，必须使用特定的激活函数来强制非负值，这种约束限制了模型从所有样本中学习的能力，从而危害了模型的性能。本文对这种限制进行了理论分析，并引入了一种改进方法来克服它。首先，我们定义了模型无法有效学习样本的区域。然后，我们对ERN进行了深入分析，研究了这个约束。基于我们分析的见解，通过引入一种新的正则化项，我们解决了这个限制，使ERN能够从整个训练集中学习。我们的广泛实验证实了我们的理论发现，并证明了所提出的解决方案的有效性。",
    "tldr": "本文研究了证据回归网络（ERN）中的模型性能限制问题，并提出了一种基于正则化的改进方法，使ERN能够从整个训练集中学习。",
    "en_tdlr": "This paper investigates the limitation of model performance in the Evidential Regression Network (ERN) and proposes an improvement based on regularization to enable the ERN to learn from the whole training set."
}