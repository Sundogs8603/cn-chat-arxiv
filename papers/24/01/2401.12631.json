{
    "title": "A Reply to Makelov et al. (2023)'s \"Interpretability Illusion\" Arguments. (arXiv:2401.12631v1 [cs.LG])",
    "abstract": "We respond to the recent paper by Makelov et al. (2023), which reviews subspace interchange intervention methods like distributed alignment search (DAS; Geiger et al. 2023) and claims that these methods potentially cause \"interpretability illusions\". We first review Makelov et al. (2023)'s technical notion of what an \"interpretability illusion\" is, and then we show that even intuitive and desirable explanations can qualify as illusions in this sense. As a result, their method of discovering \"illusions\" can reject explanations they consider \"non-illusory\". We then argue that the illusions Makelov et al. (2023) see in practice are artifacts of their training and evaluation paradigms. We close by emphasizing that, though we disagree with their core characterization, Makelov et al. (2023)'s examples and discussion have undoubtedly pushed the field of interpretability forward.",
    "link": "http://arxiv.org/abs/2401.12631",
    "context": "Title: A Reply to Makelov et al. (2023)'s \"Interpretability Illusion\" Arguments. (arXiv:2401.12631v1 [cs.LG])\nAbstract: We respond to the recent paper by Makelov et al. (2023), which reviews subspace interchange intervention methods like distributed alignment search (DAS; Geiger et al. 2023) and claims that these methods potentially cause \"interpretability illusions\". We first review Makelov et al. (2023)'s technical notion of what an \"interpretability illusion\" is, and then we show that even intuitive and desirable explanations can qualify as illusions in this sense. As a result, their method of discovering \"illusions\" can reject explanations they consider \"non-illusory\". We then argue that the illusions Makelov et al. (2023) see in practice are artifacts of their training and evaluation paradigms. We close by emphasizing that, though we disagree with their core characterization, Makelov et al. (2023)'s examples and discussion have undoubtedly pushed the field of interpretability forward.",
    "path": "papers/24/01/2401.12631.json",
    "total_tokens": 1022,
    "translated_title": "对Makelov等人(2023)的《可解释性错觉》论点的回应",
    "translated_abstract": "我们回应了Makelov等人(2023)的最新论文，该论文评述了诸如分布式对齐搜索(DAS; Geiger等人，2023)这样的子空间交换干预方法，并声称这些方法可能引起\"解释性错觉\"。我们首先回顾了Makelov等人(2023)对\"解释性错觉\"的技术概念，然后展示了即使直观和可取的解释在这个意义上也可能成为错觉。因此，他们发现\"错觉\"的方法可能会拒绝他们认为\"非错觉\"的解释。接着，我们认为Makelov等人(2023)在实践中看到的\"错觉\"是他们训练和评估范例的产物。最后，我们强调，尽管我们不同意他们的核心表述，但Makelov等人(2023)的例子和讨论无疑推动了可解释性领域的发展。",
    "tldr": "本文回应了Makelov等人(2023)的论文，该论文评述了子空间交换干预方法的\"解释性错觉\"问题。我们指出，所谓的\"解释性错觉\"可以包括直观和可取的解释，而Makelov等人(2023)发现的\"错觉\"是他们训练和评估范例的产物。尽管我们不同意他们的核心表述，但他们的例子和讨论推动了可解释性领域的发展。"
}