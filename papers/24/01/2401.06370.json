{
    "title": "Graph Relation Distillation for Efficient Biomedical Instance Segmentation. (arXiv:2401.06370v1 [cs.CV])",
    "abstract": "Instance-aware embeddings predicted by deep neural networks have revolutionized biomedical instance segmentation, but its resource requirements are substantial. Knowledge distillation offers a solution by transferring distilled knowledge from heavy teacher networks to lightweight yet high-performance student networks. However, existing knowledge distillation methods struggle to extract knowledge for distinguishing instances and overlook global relation information. To address these challenges, we propose a graph relation distillation approach for efficient biomedical instance segmentation, which considers three essential types of knowledge: instance-level features, instance relations, and pixel-level boundaries. We introduce two graph distillation schemes deployed at both the intra-image level and the inter-image level: instance graph distillation (IGD) and affinity graph distillation (AGD). IGD constructs a graph representing instance features and relations, transferring these two typ",
    "link": "http://arxiv.org/abs/2401.06370",
    "context": "Title: Graph Relation Distillation for Efficient Biomedical Instance Segmentation. (arXiv:2401.06370v1 [cs.CV])\nAbstract: Instance-aware embeddings predicted by deep neural networks have revolutionized biomedical instance segmentation, but its resource requirements are substantial. Knowledge distillation offers a solution by transferring distilled knowledge from heavy teacher networks to lightweight yet high-performance student networks. However, existing knowledge distillation methods struggle to extract knowledge for distinguishing instances and overlook global relation information. To address these challenges, we propose a graph relation distillation approach for efficient biomedical instance segmentation, which considers three essential types of knowledge: instance-level features, instance relations, and pixel-level boundaries. We introduce two graph distillation schemes deployed at both the intra-image level and the inter-image level: instance graph distillation (IGD) and affinity graph distillation (AGD). IGD constructs a graph representing instance features and relations, transferring these two typ",
    "path": "papers/24/01/2401.06370.json",
    "total_tokens": 902,
    "translated_title": "用于高效生物医学实例分割的图关系蒸馏",
    "translated_abstract": "由深度神经网络预测的实例感知嵌入已经在生物医学实例分割中引起了革命，但其资源需求巨大。知识蒸馏通过将来自重型教师网络的蒸馏知识转移给轻量级但高性能的学生网络，提供了一种解决方案。然而，现有的知识蒸馏方法在提取用于区分实例的知识和忽略全局关系信息方面存在困难。为了解决这些挑战，我们提出了一种用于高效生物医学实例分割的图关系蒸馏方法，它考虑了三种关键类型的知识：实例级特征、实例关系和像素级边界。我们引入了两种图蒸馏方案，分别部署在图像内部和图像间：实例图蒸馏（IGD）和亲和图蒸馏（AGD）。IGD构建了一个表示实例特征和关系的图，并将这两种类型的知识转移给学生网络。",
    "tldr": "本研究提出了一种用于高效生物医学实例分割的图关系蒸馏方法，通过考虑实例级特征、实例关系和像素级边界的知识，使用实例图蒸馏和亲和图蒸馏来解决资源需求巨大的问题。"
}