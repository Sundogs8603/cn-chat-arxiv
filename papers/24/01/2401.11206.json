{
    "title": "InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance. (arXiv:2401.11206v1 [cs.CL])",
    "abstract": "With the rapid development of large language models (LLMs), they are not only used as general-purpose AI assistants but are also customized through further fine-tuning to meet the requirements of different applications. A pivotal factor in the success of current LLMs is the alignment process. Current alignment methods, such as supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF), focus on training-time alignment and are often complex and cumbersome to implement. Therefore, we develop \\textbf{InferAligner}, a novel inference-time alignment method that utilizes cross-model guidance for harmlessness alignment. InferAligner utilizes safety steering vectors extracted from safety-aligned model to modify the activations of the target model when responding to harmful inputs, thereby guiding the target model to provide harmless responses. Experimental results show that our method can be very effectively applied to domain-specific models in finance, medicine, and ma",
    "link": "http://arxiv.org/abs/2401.11206",
    "context": "Title: InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance. (arXiv:2401.11206v1 [cs.CL])\nAbstract: With the rapid development of large language models (LLMs), they are not only used as general-purpose AI assistants but are also customized through further fine-tuning to meet the requirements of different applications. A pivotal factor in the success of current LLMs is the alignment process. Current alignment methods, such as supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF), focus on training-time alignment and are often complex and cumbersome to implement. Therefore, we develop \\textbf{InferAligner}, a novel inference-time alignment method that utilizes cross-model guidance for harmlessness alignment. InferAligner utilizes safety steering vectors extracted from safety-aligned model to modify the activations of the target model when responding to harmful inputs, thereby guiding the target model to provide harmless responses. Experimental results show that our method can be very effectively applied to domain-specific models in finance, medicine, and ma",
    "path": "papers/24/01/2401.11206.json",
    "total_tokens": 840,
    "translated_title": "InferAligner: 利用跨模型引导进行无害化推理时间对齐",
    "translated_abstract": "随着大型语言模型（LLM）的快速发展，它们不仅被用作通用AI助手，还通过进一步的微调定制以满足不同应用的要求。当前LLM成功的一个关键因素是对齐过程。当前的对齐方法，如有监督的微调（SFT）和从人类反馈中强化学习（RLHF），侧重于训练时间的对齐，往往复杂且难以实现。因此，我们开发了InferAligner，一种利用跨模型引导进行无害化对齐的新方法。InferAligner利用从安全对齐模型中提取的安全转向向量来修改目标模型在响应有害输入时的激活，从而引导目标模型提供无害响应。实验结果表明，我们的方法可以非常有效地应用于金融、医学和市场等领域特定模型中。",
    "tldr": "InferAligner是一种新颖的推理时间对齐方法，利用跨模型引导实现无害化对齐，可以有效地应用于领域特定模型中。"
}