{
    "title": "A Survey on Hardware Accelerators for Large Language Models. (arXiv:2401.09890v1 [cs.AR])",
    "abstract": "Large Language Models (LLMs) have emerged as powerful tools for natural language processing tasks, revolutionizing the field with their ability to understand and generate human-like text. As the demand for more sophisticated LLMs continues to grow, there is a pressing need to address the computational challenges associated with their scale and complexity. This paper presents a comprehensive survey on hardware accelerators designed to enhance the performance and energy efficiency of Large Language Models. By examining a diverse range of accelerators, including GPUs, FPGAs, and custom-designed architectures, we explore the landscape of hardware solutions tailored to meet the unique computational demands of LLMs. The survey encompasses an in-depth analysis of architecture, performance metrics, and energy efficiency considerations, providing valuable insights for researchers, engineers, and decision-makers aiming to optimize the deployment of LLMs in real-world applications.",
    "link": "http://arxiv.org/abs/2401.09890",
    "context": "Title: A Survey on Hardware Accelerators for Large Language Models. (arXiv:2401.09890v1 [cs.AR])\nAbstract: Large Language Models (LLMs) have emerged as powerful tools for natural language processing tasks, revolutionizing the field with their ability to understand and generate human-like text. As the demand for more sophisticated LLMs continues to grow, there is a pressing need to address the computational challenges associated with their scale and complexity. This paper presents a comprehensive survey on hardware accelerators designed to enhance the performance and energy efficiency of Large Language Models. By examining a diverse range of accelerators, including GPUs, FPGAs, and custom-designed architectures, we explore the landscape of hardware solutions tailored to meet the unique computational demands of LLMs. The survey encompasses an in-depth analysis of architecture, performance metrics, and energy efficiency considerations, providing valuable insights for researchers, engineers, and decision-makers aiming to optimize the deployment of LLMs in real-world applications.",
    "path": "papers/24/01/2401.09890.json",
    "total_tokens": 891,
    "translated_title": "关于大型语言模型的硬件加速器的调查",
    "translated_abstract": "大型语言模型（LLMs）已成为自然语言处理任务的强大工具，通过其理解和生成类似于人类文本的能力，它们正在为该领域带来革命性变革。随着对更复杂LLMs的需求不断增长，迫切需要解决与其规模和复杂性相关的计算挑战。本文针对提高大型语言模型性能和能量效率的硬件加速器进行了全面调查。通过对包括GPU、FPGA和定制架构在内的各种加速器进行研究，我们探索了旨在满足LLMs的独特计算需求的硬件解决方案的格局。本调查涵盖了对架构、性能指标和能量效率考虑的深入分析，为研究人员、工程师和决策者在实际应用中优化LLMs的部署提供了宝贵的见解。",
    "tldr": "这项论文调查了用于增强大型语言模型性能和能量效率的硬件加速器，并对多种加速器进行了深入分析，为研究人员、工程师和决策者在实际应用中优化大型语言模型的部署提供了宝贵的见解。",
    "en_tdlr": "This paper presents a comprehensive survey on hardware accelerators designed to enhance the performance and energy efficiency of Large Language Models. It explores the landscape of hardware solutions tailored to meet the unique computational demands of LLMs, and provides valuable insights for optimizing the deployment of LLMs in real-world applications."
}