{
    "title": "FedNS: A Fast Sketching Newton-Type Algorithm for Federated Learning. (arXiv:2401.02734v1 [cs.LG])",
    "abstract": "Recent Newton-type federated learning algorithms have demonstrated linear convergence with respect to the communication rounds. However, communicating Hessian matrices is often unfeasible due to their quadratic communication complexity. In this paper, we introduce a novel approach to tackle this issue while still achieving fast convergence rates. Our proposed method, named as Federated Newton Sketch methods (FedNS), approximates the centralized Newton's method by communicating the sketched square-root Hessian instead of the exact Hessian. To enhance communication efficiency, we reduce the sketch size to match the effective dimension of the Hessian matrix. We provide convergence analysis based on statistical learning for the federated Newton sketch approaches. Specifically, our approaches reach super-linear convergence rates w.r.t. the communication rounds for the first time. We validate the effectiveness of our algorithms through various experiments, which coincide with our theoretical",
    "link": "http://arxiv.org/abs/2401.02734",
    "context": "Title: FedNS: A Fast Sketching Newton-Type Algorithm for Federated Learning. (arXiv:2401.02734v1 [cs.LG])\nAbstract: Recent Newton-type federated learning algorithms have demonstrated linear convergence with respect to the communication rounds. However, communicating Hessian matrices is often unfeasible due to their quadratic communication complexity. In this paper, we introduce a novel approach to tackle this issue while still achieving fast convergence rates. Our proposed method, named as Federated Newton Sketch methods (FedNS), approximates the centralized Newton's method by communicating the sketched square-root Hessian instead of the exact Hessian. To enhance communication efficiency, we reduce the sketch size to match the effective dimension of the Hessian matrix. We provide convergence analysis based on statistical learning for the federated Newton sketch approaches. Specifically, our approaches reach super-linear convergence rates w.r.t. the communication rounds for the first time. We validate the effectiveness of our algorithms through various experiments, which coincide with our theoretical",
    "path": "papers/24/01/2401.02734.json",
    "total_tokens": 922,
    "translated_title": "FedNS:一种用于联邦学习的快速绘图牛顿型算法",
    "translated_abstract": "最近的牛顿型联邦学习算法已经证明具有与通信轮数成线性收敛。然而，由于其二次通信复杂性，通信海森矩阵通常不可行。在本文中，我们介绍了一种新的方法来解决这个问题，同时仍然实现快速收敛速率。我们提出的方法名为联邦牛顿绘图方法(FedNS)，通过传输草图化的平方根海森矩阵而不是精确的海森矩阵，来近似集中式牛顿方法。为了增强通信效率，我们将草图的大小缩小到与海森矩阵的有效维度相匹配。我们基于统计学习提供了联邦牛顿绘图方法的收敛性分析。具体而言，我们的方法首次在通信轮数的情况下达到了超线性的收敛速率。我们通过各种实验证实了我们算法的有效性，这与我们的理论相符。",
    "tldr": "本文提出了一种名为FedNS的快速绘图牛顿型算法，解决了牛顿型联邦学习算法在通信复杂度上的问题，通过传输草图化的平方根海森矩阵来近似集中式牛顿方法，实现了超线性的收敛速率。",
    "en_tdlr": "This paper presents a fast sketching Newton-type algorithm called FedNS, which addresses the issue of the quadratic communication complexity in Newton-type federated learning algorithms by approximating the centralized Newton's method using the sketched square-root Hessian. It achieves super-linear convergence rates for the first time."
}