{
    "title": "Ta'keed: The First Generative Fact-Checking System for Arabic Claims. (arXiv:2401.14067v1 [cs.CL])",
    "abstract": "This paper introduces Ta'keed, an explainable Arabic automatic fact-checking system. While existing research often focuses on classifying claims as \"True\" or \"False,\" there is a limited exploration of generating explanations for claim credibility, particularly in Arabic. Ta'keed addresses this gap by assessing claim truthfulness based on retrieved snippets, utilizing two main components: information retrieval and LLM-based claim verification. We compiled the ArFactEx, a testing gold-labelled dataset with manually justified references, to evaluate the system. The initial model achieved a promising F1 score of 0.72 in the classification task. Meanwhile, the system's generated explanations are compared with gold-standard explanations syntactically and semantically. The study recommends evaluating using semantic similarities, resulting in an average cosine similarity score of 0.76. Additionally, we explored the impact of varying snippet quantities on claim classification accuracy, revealin",
    "link": "http://arxiv.org/abs/2401.14067",
    "context": "Title: Ta'keed: The First Generative Fact-Checking System for Arabic Claims. (arXiv:2401.14067v1 [cs.CL])\nAbstract: This paper introduces Ta'keed, an explainable Arabic automatic fact-checking system. While existing research often focuses on classifying claims as \"True\" or \"False,\" there is a limited exploration of generating explanations for claim credibility, particularly in Arabic. Ta'keed addresses this gap by assessing claim truthfulness based on retrieved snippets, utilizing two main components: information retrieval and LLM-based claim verification. We compiled the ArFactEx, a testing gold-labelled dataset with manually justified references, to evaluate the system. The initial model achieved a promising F1 score of 0.72 in the classification task. Meanwhile, the system's generated explanations are compared with gold-standard explanations syntactically and semantically. The study recommends evaluating using semantic similarities, resulting in an average cosine similarity score of 0.76. Additionally, we explored the impact of varying snippet quantities on claim classification accuracy, revealin",
    "path": "papers/24/01/2401.14067.json",
    "total_tokens": 983,
    "translated_title": "Ta'keed: 首个用于阿拉伯语论断的生成式事实核查系统",
    "translated_abstract": "本文介绍了Ta'keed，一个可解释的阿拉伯语自动事实核查系统。现有研究通常将论断分类为“真”或“假”，但对于生成论断可信度的解释尤其在阿拉伯语领域的研究有限。Ta'keed通过基于检索片段的论断真实性评估来填补这一空白，利用信息检索和基于LLM的论断验证两个主要组件。我们编制了ArFactEx，一个带有手工证明参考的测试黄金标签数据集，用于评估该系统。初始模型在分类任务中取得了有希望的0.72的F1得分。与黄金标准解释在句法和语义上进行比较，系统生成的解释得到了推荐的语义相似性评估，平均余弦相似度分数为0.76。此外，我们还探讨了不同片段数量对论断分类准确性的影响，揭示....",
    "tldr": "Ta'keed是首个用于阿拉伯语论断的生成式事实核查系统，通过基于检索片段的论断真实性评估和LLM-based论断验证，解决了目前阿拉伯语领域缺乏生成解释论断可信度的研究。引入了一个测试黄金标签数据集，并分析了系统生成解释与黄金标准解释之间的语义相似性。研究还探讨了不同片段数量对论断分类准确性的影响。"
}