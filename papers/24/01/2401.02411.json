{
    "title": "What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs. (arXiv:2401.02411v1 [cs.CV])",
    "abstract": "3D-aware Generative Adversarial Networks (GANs) have shown remarkable progress in learning to generate multi-view-consistent images and 3D geometries of scenes from collections of 2D images via neural volume rendering. Yet, the significant memory and computational costs of dense sampling in volume rendering have forced 3D GANs to adopt patch-based training or employ low-resolution rendering with post-processing 2D super resolution, which sacrifices multiview consistency and the quality of resolved geometry. Consequently, 3D GANs have not yet been able to fully resolve the rich 3D geometry present in 2D images. In this work, we propose techniques to scale neural volume rendering to the much higher resolution of native 2D images, thereby resolving fine-grained 3D geometry with unprecedented detail. Our approach employs learning-based samplers for accelerating neural rendering for 3D GAN training using up to 5 times fewer depth samples. This enables us to explicitly \"render every pixel\" o",
    "link": "http://arxiv.org/abs/2401.02411",
    "context": "Title: What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs. (arXiv:2401.02411v1 [cs.CV])\nAbstract: 3D-aware Generative Adversarial Networks (GANs) have shown remarkable progress in learning to generate multi-view-consistent images and 3D geometries of scenes from collections of 2D images via neural volume rendering. Yet, the significant memory and computational costs of dense sampling in volume rendering have forced 3D GANs to adopt patch-based training or employ low-resolution rendering with post-processing 2D super resolution, which sacrifices multiview consistency and the quality of resolved geometry. Consequently, 3D GANs have not yet been able to fully resolve the rich 3D geometry present in 2D images. In this work, we propose techniques to scale neural volume rendering to the much higher resolution of native 2D images, thereby resolving fine-grained 3D geometry with unprecedented detail. Our approach employs learning-based samplers for accelerating neural rendering for 3D GAN training using up to 5 times fewer depth samples. This enables us to explicitly \"render every pixel\" o",
    "path": "papers/24/01/2401.02411.json",
    "total_tokens": 977,
    "translated_title": "你所见即所GAN: 在3D GAN中为高保真度几何图形渲染每个像素",
    "translated_abstract": "3D感知生成对抗网络(GANs)在通过神经体积渲染从2D图像集合中学习生成多视角一致的图像和场景3D几何图形方面取得了显著进展。然而，体积渲染中密集采样导致的显著内存和计算开销迫使3D GANs采用基于块的训练或采用低分辨率渲染与后处理的2D超分辨率，这损害了多视角一致性和解决几何图形的质量。因此，3D GANs尚不能完全解决2D图像中丰富的3D几何图形。在本文中，我们提出了将神经体积渲染扩展到本地2D图像更高分辨率的技术，因此能以前所未有的细节解决细粒度的3D几何图形。我们的方法使用基于学习的采样器来加速3D GAN训练中的神经渲染，使用更少的深度采样次数高达5倍。这使我们能够明确地“渲染每个像素”。",
    "tldr": "本文提出了将神经体积渲染扩展到本地2D图像更高分辨率的技术，以解决3D GANs无法解决2D图像中丰富的3D几何图形的问题。",
    "en_tdlr": "This paper proposes techniques to scale neural volume rendering to higher resolution 2D images in order to address the challenge of fully resolving rich 3D geometry in 2D images using 3D GANs."
}