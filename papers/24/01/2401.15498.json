{
    "title": "Do We Need Language-Specific Fact-Checking Models? The Case of Chinese",
    "abstract": "arXiv:2401.15498v2 Announce Type: replace  Abstract: This paper investigates the potential benefits of language-specific fact-checking models, focusing on the case of Chinese. We first demonstrate the limitations of translation-based methods and multilingual large language models (e.g., GPT-4), highlighting the need for language-specific systems. We further propose a Chinese fact-checking system that can better retrieve evidence from a document by incorporating context information. To better analyze token-level biases in different systems, we construct an adversarial dataset based on the CHEF dataset, where each instance has large word overlap with the original one but holds the opposite veracity label. Experimental results on the CHEF dataset and our adversarial dataset show that our proposed method outperforms translation-based methods and multilingual LLMs and is more robust toward biases, while there is still large room for improvement, emphasizing the importance of language-specif",
    "link": "https://arxiv.org/abs/2401.15498",
    "context": "Title: Do We Need Language-Specific Fact-Checking Models? The Case of Chinese\nAbstract: arXiv:2401.15498v2 Announce Type: replace  Abstract: This paper investigates the potential benefits of language-specific fact-checking models, focusing on the case of Chinese. We first demonstrate the limitations of translation-based methods and multilingual large language models (e.g., GPT-4), highlighting the need for language-specific systems. We further propose a Chinese fact-checking system that can better retrieve evidence from a document by incorporating context information. To better analyze token-level biases in different systems, we construct an adversarial dataset based on the CHEF dataset, where each instance has large word overlap with the original one but holds the opposite veracity label. Experimental results on the CHEF dataset and our adversarial dataset show that our proposed method outperforms translation-based methods and multilingual LLMs and is more robust toward biases, while there is still large room for improvement, emphasizing the importance of language-specif",
    "path": "papers/24/01/2401.15498.json",
    "total_tokens": 880,
    "translated_title": "我们是否需要语言特定的事实核查模型？以汉语为例",
    "translated_abstract": "本文研究了语言特定事实核查模型的潜在益处，重点关注汉语案例。我们首先展示了基于翻译方法和多语言大型语言模型（例如GPT-4）的局限性，突出了对语言特定系统的需求。我们进一步提出了一个汉语事实核查系统，通过整合上下文信息，可以更好地从文档中检索证据。为了更好地分析不同系统中的令牌级偏见，我们基于CHEF数据集构建了一个对抗数据集，其中每个实例与原始实例具有较大的词重叠，但具有相反的真实性标签。在CHEF数据集和我们的对抗数据集上的实验结果表明，我们提出的方法优于基于翻译的方法和多语言LLM，并且对偏见更加稳健，但仍有很大的改进空间，强调了语言特定性的重要性。",
    "tldr": "本文研究了语言特定事实核查模型的潜在益处，提出了一个汉语事实核查系统，并展示其优于翻译方法和多语言大型语言模型，同时对偏见更加稳健，强调了语言特定性的重要性。",
    "en_tdlr": "This paper investigates the potential benefits of language-specific fact-checking models, proposes a Chinese fact-checking system that outperforms translation-based methods and multilingual large language models, and emphasizes the importance of language specificity by being more robust towards biases."
}