{
    "title": "Central Limit Theorem for Two-Timescale Stochastic Approximation with Markovian Noise: Theory and Applications. (arXiv:2401.09339v1 [stat.ML])",
    "abstract": "Two-timescale stochastic approximation (TTSA) is among the most general frameworks for iterative stochastic algorithms. This includes well-known stochastic optimization methods such as SGD variants and those designed for bilevel or minimax problems, as well as reinforcement learning like the family of gradient-based temporal difference (GTD) algorithms. In this paper, we conduct an in-depth asymptotic analysis of TTSA under controlled Markovian noise via central limit theorem (CLT), uncovering the coupled dynamics of TTSA influenced by the underlying Markov chain, which has not been addressed by previous CLT results of TTSA only with Martingale difference noise. Building upon our CLT, we expand its application horizon of efficient sampling strategies from vanilla SGD to a wider TTSA context in distributed learning, thus broadening the scope of Hu et al. (2022). In addition, we leverage our CLT result to deduce the statistical properties of GTD algorithms with nonlinear function approxi",
    "link": "http://arxiv.org/abs/2401.09339",
    "context": "Title: Central Limit Theorem for Two-Timescale Stochastic Approximation with Markovian Noise: Theory and Applications. (arXiv:2401.09339v1 [stat.ML])\nAbstract: Two-timescale stochastic approximation (TTSA) is among the most general frameworks for iterative stochastic algorithms. This includes well-known stochastic optimization methods such as SGD variants and those designed for bilevel or minimax problems, as well as reinforcement learning like the family of gradient-based temporal difference (GTD) algorithms. In this paper, we conduct an in-depth asymptotic analysis of TTSA under controlled Markovian noise via central limit theorem (CLT), uncovering the coupled dynamics of TTSA influenced by the underlying Markov chain, which has not been addressed by previous CLT results of TTSA only with Martingale difference noise. Building upon our CLT, we expand its application horizon of efficient sampling strategies from vanilla SGD to a wider TTSA context in distributed learning, thus broadening the scope of Hu et al. (2022). In addition, we leverage our CLT result to deduce the statistical properties of GTD algorithms with nonlinear function approxi",
    "path": "papers/24/01/2401.09339.json",
    "total_tokens": 1039,
    "translated_title": "两时间尺度带马尔可夫噪声的随机逼近中心极限定理：理论和应用",
    "translated_abstract": "两时间尺度随机逼近（TTSA）是最通用的迭代随机算法框架之一。这包括了众所周知的随机优化方法，如SGD变种和用于双层或极小化问题的方法，以及类似梯度-based时序差异（GTD）算法的强化学习方法。本文通过中心极限定理（CLT）对带控制马尔可夫噪声的TTSA进行了深入的渐近分析，揭示了TTSA受底层马尔可夫链影响的耦合动力学，这在以前仅考虑鞅差异噪声的TTSA的CLT结果中没有得到解决。基于我们的CLT，我们将高效采样策略的应用范围从传统SGD扩展到了更广泛的TTSA背景下的分布式学习，从而扩大了胡等人（2022）的研究范围。此外，我们利用我们的CLT结果推导了具有非线性函数逼近的GTD算法的统计特性。",
    "tldr": "本文通过对两时间尺度随机逼近（TTSA）的广义分析，利用中心极限定理（CLT）揭示了TTSA受马尔可夫噪声影响的耦合动力学，从而拓展了传统SGD的高效采样策略在分布式学习中的应用范围，同时研究了具有非线性函数逼近的GTD算法的统计特性。",
    "en_tdlr": "This paper provides an in-depth asymptotic analysis of two-timescale stochastic approximation (TTSA) with controlled Markovian noise, revealing the coupled dynamics of TTSA influenced by the underlying Markov chain. It expands the application horizon of efficient sampling strategies from vanilla SGD to a wider TTSA context in distributed learning, and deduces the statistical properties of GTD algorithms with nonlinear function approximation."
}