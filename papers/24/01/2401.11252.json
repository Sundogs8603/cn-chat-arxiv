{
    "title": "Automated Fusion of Multimodal Electronic Health Records for Better Medical Predictions. (arXiv:2401.11252v1 [cs.LG])",
    "abstract": "The widespread adoption of Electronic Health Record (EHR) systems in healthcare institutes has generated vast amounts of medical data, offering significant opportunities for improving healthcare services through deep learning techniques. However, the complex and diverse modalities and feature structures in real-world EHR data pose great challenges for deep learning model design. To address the multi-modality challenge in EHR data, current approaches primarily rely on hand-crafted model architectures based on intuition and empirical experiences, leading to sub-optimal model architectures and limited performance. Therefore, to automate the process of model design for mining EHR data, we propose a novel neural architecture search (NAS) framework named AutoFM, which can automatically search for the optimal model architectures for encoding diverse input modalities and fusion strategies. We conduct thorough experiments on real-world multi-modal EHR data and prediction tasks, and the results ",
    "link": "http://arxiv.org/abs/2401.11252",
    "context": "Title: Automated Fusion of Multimodal Electronic Health Records for Better Medical Predictions. (arXiv:2401.11252v1 [cs.LG])\nAbstract: The widespread adoption of Electronic Health Record (EHR) systems in healthcare institutes has generated vast amounts of medical data, offering significant opportunities for improving healthcare services through deep learning techniques. However, the complex and diverse modalities and feature structures in real-world EHR data pose great challenges for deep learning model design. To address the multi-modality challenge in EHR data, current approaches primarily rely on hand-crafted model architectures based on intuition and empirical experiences, leading to sub-optimal model architectures and limited performance. Therefore, to automate the process of model design for mining EHR data, we propose a novel neural architecture search (NAS) framework named AutoFM, which can automatically search for the optimal model architectures for encoding diverse input modalities and fusion strategies. We conduct thorough experiments on real-world multi-modal EHR data and prediction tasks, and the results ",
    "path": "papers/24/01/2401.11252.json",
    "total_tokens": 935,
    "translated_title": "自动融合多模态电子健康记录以提升医疗预测准确性",
    "translated_abstract": "在医疗机构广泛采用电子健康记录（EHR）系统产生了大量医疗数据，为通过深度学习技术改进医疗服务提供了重要机会。然而，真实世界的EHR数据中复杂多样的模态和特征结构给深度学习模型设计带来了巨大挑战。为了解决EHR数据中的多模态问题，当前的方法主要依靠基于直觉和经验的手工模型架构，导致子优模型架构和有限性能。因此，为了自动化EHR数据挖掘模型设计的过程，我们提出了一种名为AutoFM的新颖神经架构搜索（NAS）框架，该框架能够自动搜索用于编码不同输入模态和融合策略的最佳模型架构。我们在真实的多模态EHR数据和预测任务上进行了全面的实验，实验证明了我们的方法的有效性和性能超越了传统方法。",
    "tldr": "该论文提出了一种自动融合多模态电子健康记录的神经架构搜索框架，用于改进医疗预测准确性。该框架可以自动搜索用于编码不同输入模态和融合策略的最佳模型架构，并在实验中取得了超越传统方法的效果。"
}