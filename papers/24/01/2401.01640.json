{
    "title": "Evaluating Fairness in Self-supervised and Supervised Models for Sequential Data. (arXiv:2401.01640v1 [cs.LG])",
    "abstract": "Self-supervised learning (SSL) has become the de facto training paradigm of large models where pre-training is followed by supervised fine-tuning using domain-specific data and labels. Hypothesizing that SSL models would learn more generic, hence less biased, representations, this study explores the impact of pre-training and fine-tuning strategies on fairness (i.e., performing equally on different demographic breakdowns). Motivated by human-centric applications on real-world timeseries data, we interpret inductive biases on the model, layer, and metric levels by systematically comparing SSL models to their supervised counterparts. Our findings demonstrate that SSL has the capacity to achieve performance on par with supervised methods while significantly enhancing fairness--exhibiting up to a 27% increase in fairness with a mere 1% loss in performance through self-supervision. Ultimately, this work underscores SSL's potential in human-centric computing, particularly high-stakes, data-s",
    "link": "http://arxiv.org/abs/2401.01640",
    "context": "Title: Evaluating Fairness in Self-supervised and Supervised Models for Sequential Data. (arXiv:2401.01640v1 [cs.LG])\nAbstract: Self-supervised learning (SSL) has become the de facto training paradigm of large models where pre-training is followed by supervised fine-tuning using domain-specific data and labels. Hypothesizing that SSL models would learn more generic, hence less biased, representations, this study explores the impact of pre-training and fine-tuning strategies on fairness (i.e., performing equally on different demographic breakdowns). Motivated by human-centric applications on real-world timeseries data, we interpret inductive biases on the model, layer, and metric levels by systematically comparing SSL models to their supervised counterparts. Our findings demonstrate that SSL has the capacity to achieve performance on par with supervised methods while significantly enhancing fairness--exhibiting up to a 27% increase in fairness with a mere 1% loss in performance through self-supervision. Ultimately, this work underscores SSL's potential in human-centric computing, particularly high-stakes, data-s",
    "path": "papers/24/01/2401.01640.json",
    "total_tokens": 936,
    "translated_title": "对于顺序数据中的自监督和监督模型进行公平性评估",
    "translated_abstract": "自监督学习（SSL）已成为大型模型的实际训练范式，其中预训练后跟随领域特定数据和标签的监督微调。本研究假设SSL模型会学习到更通用、因此更少有偏见的表示，探索预训练和微调策略对公平性（即在不同人口统计学分析中表现平等）的影响。在真实世界的时间序列数据上，受到以人为中心的应用的启发，我们通过系统比较SSL模型和相应的监督模型，从模型、层次和度量水平上解释归纳偏差。我们的研究结果表明，SSL能够实现与监督方法相当的性能，同时显著提高公平性，通过自监督学习可以在性能损失1%的情况下增加公平性高达27%。最终，这项工作强调了SSL在人为中心的计算中的潜力，特别是在高风险的数据情境中。",
    "tldr": "本研究通过比较自监督学习模型和监督学习模型在顺序数据上的表现发现，自监督学习模型能够实现与监督模型相当的性能，并显著提高公平性，这表明了其在人为中心的计算中的潜力。",
    "en_tdlr": "This study compares the performance of self-supervised learning models with supervised learning models on sequential data and finds that self-supervised learning models can achieve comparable performance to supervised models while significantly improving fairness, indicating their potential in human-centric computing."
}