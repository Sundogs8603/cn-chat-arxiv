{
    "title": "SwitchTab: Switched Autoencoders Are Effective Tabular Learners. (arXiv:2401.02013v1 [cs.LG])",
    "abstract": "Self-supervised representation learning methods have achieved significant success in computer vision and natural language processing, where data samples exhibit explicit spatial or semantic dependencies. However, applying these methods to tabular data is challenging due to the less pronounced dependencies among data samples. In this paper, we address this limitation by introducing SwitchTab, a novel self-supervised method specifically designed to capture latent dependencies in tabular data. SwitchTab leverages an asymmetric encoder-decoder framework to decouple mutual and salient features among data pairs, resulting in more representative embeddings. These embeddings, in turn, contribute to better decision boundaries and lead to improved results in downstream tasks. To validate the effectiveness of SwitchTab, we conduct extensive experiments across various domains involving tabular data. The results showcase superior performance in end-to-end prediction tasks with fine-tuning. Moreover",
    "link": "http://arxiv.org/abs/2401.02013",
    "context": "Title: SwitchTab: Switched Autoencoders Are Effective Tabular Learners. (arXiv:2401.02013v1 [cs.LG])\nAbstract: Self-supervised representation learning methods have achieved significant success in computer vision and natural language processing, where data samples exhibit explicit spatial or semantic dependencies. However, applying these methods to tabular data is challenging due to the less pronounced dependencies among data samples. In this paper, we address this limitation by introducing SwitchTab, a novel self-supervised method specifically designed to capture latent dependencies in tabular data. SwitchTab leverages an asymmetric encoder-decoder framework to decouple mutual and salient features among data pairs, resulting in more representative embeddings. These embeddings, in turn, contribute to better decision boundaries and lead to improved results in downstream tasks. To validate the effectiveness of SwitchTab, we conduct extensive experiments across various domains involving tabular data. The results showcase superior performance in end-to-end prediction tasks with fine-tuning. Moreover",
    "path": "papers/24/01/2401.02013.json",
    "total_tokens": 944,
    "translated_title": "SwitchTab: 切换式自编码器在表格学习中的有效性",
    "translated_abstract": "自监督表示学习方法在计算机视觉和自然语言处理中取得了显著的成功，其中数据样本呈现明确的空间或语义依赖关系。然而，将这些方法应用于表格数据是具有挑战性的，因为数据样本之间的依赖关系不太明显。本文通过引入SwitchTab，一种专门设计用于捕捉表格数据中的潜在依赖关系的新型自监督方法，来解决这一限制。SwitchTab利用一个非对称的编码器-解码器框架来解耦数据对中的互相关联和显著特征，从而产生更具代表性的嵌入。这些嵌入进而有助于更好的决策边界，并在下游任务中取得更好的结果。为了验证SwitchTab的有效性，我们在涉及表格数据的各个领域进行了大量实验。结果展示了在细调下端到端预测任务中表现出优越的性能。",
    "tldr": "SwitchTab是一种专门设计用于捕捉表格数据中潜在依赖关系的自监督方法。它引入了一个非对称的编码器-解码器框架来解耦数据对中的互相关联和显著特征，从而生成更具代表性的嵌入。在大量实验中，SwitchTab在细调下端到端预测任务中展现出了优越的性能。",
    "en_tdlr": "SwitchTab is a self-supervised method specifically designed to capture latent dependencies in tabular data. It leverages an asymmetric encoder-decoder framework to decouple mutual and salient features among data pairs, resulting in more representative embeddings. Extensive experiments showcase the superior performance of SwitchTab in end-to-end prediction tasks with fine-tuning."
}