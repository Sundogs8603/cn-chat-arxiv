{
    "title": "Ensembler: Combating model inversion attacks using model ensemble during collaborative inference. (arXiv:2401.10859v1 [cs.CR])",
    "abstract": "Deep learning models have exhibited remarkable performance across various domains. Nevertheless, the burgeoning model sizes compel edge devices to offload a significant portion of the inference process to the cloud. While this practice offers numerous advantages, it also raises critical concerns regarding user data privacy. In scenarios where the cloud server's trustworthiness is in question, the need for a practical and adaptable method to safeguard data privacy becomes imperative. In this paper, we introduce Ensembler, an extensible framework designed to substantially increase the difficulty of conducting model inversion attacks for adversarial parties. Ensembler leverages model ensembling on the adversarial server, running in parallel with existing approaches that introduce perturbations to sensitive data during colloborative inference. Our experiments demonstrate that when combined with even basic Gaussian noise, Ensembler can effectively shield images from reconstruction attacks, ",
    "link": "http://arxiv.org/abs/2401.10859",
    "context": "Title: Ensembler: Combating model inversion attacks using model ensemble during collaborative inference. (arXiv:2401.10859v1 [cs.CR])\nAbstract: Deep learning models have exhibited remarkable performance across various domains. Nevertheless, the burgeoning model sizes compel edge devices to offload a significant portion of the inference process to the cloud. While this practice offers numerous advantages, it also raises critical concerns regarding user data privacy. In scenarios where the cloud server's trustworthiness is in question, the need for a practical and adaptable method to safeguard data privacy becomes imperative. In this paper, we introduce Ensembler, an extensible framework designed to substantially increase the difficulty of conducting model inversion attacks for adversarial parties. Ensembler leverages model ensembling on the adversarial server, running in parallel with existing approaches that introduce perturbations to sensitive data during colloborative inference. Our experiments demonstrate that when combined with even basic Gaussian noise, Ensembler can effectively shield images from reconstruction attacks, ",
    "path": "papers/24/01/2401.10859.json",
    "total_tokens": 836,
    "translated_title": "Ensembler:使用模型集成在协作推理过程中防止模型反演攻击",
    "translated_abstract": "深度学习模型在各个领域展示出了卓越的性能。然而，庞大的模型大小促使边缘设备将推理过程的大部分转移到云端。虽然这种做法带来了许多优势，但也引发了关于用户数据隐私的重要问题。在云服务器的可信度受到质疑的情况下，保护数据隐私的实用和适应性方法变得至关重要。在本文中，我们介绍了Ensembler，这是一个可扩展的框架，旨在大大增加对抗方进行模型反演攻击的难度。Ensembler利用在对抗服务器上运行的模型组合，与现有的在协作推理过程中引入扰动到敏感数据的方法并行。我们的实验表明，即使与基本的高斯噪声相结合，Ensembler也可以有效地保护图像免受重建攻击。",
    "tldr": "Ensembler是一个防止模型反演攻击的可扩展框架，通过利用模型集成和引入扰动的方式，在协作推理过程中有效地保护数据隐私。",
    "en_tdlr": "Ensembler is an extensible framework that effectively protects data privacy during collaborative inference by using model ensemble and introducing perturbations to the sensitive data, thus preventing model inversion attacks."
}