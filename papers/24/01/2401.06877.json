{
    "title": "Promptly Predicting Structures: The Return of Inference",
    "abstract": "arXiv:2401.06877v2 Announce Type: replace  Abstract: Prompt-based methods have been used extensively across NLP to build zero- and few-shot label predictors. Many NLP tasks are naturally structured: that is, their outputs consist of multiple labels which constrain each other. Annotating data for such tasks can be cumbersome. Can the promise of the prompt-based paradigm be extended to such structured outputs? In this paper, we present a framework for constructing zero- and few-shot linguistic structure predictors. Our key insight is that we can use structural constraints -- and combinatorial inference derived from them -- to filter out inconsistent structures predicted by large language models. We instantiated this framework on two structured prediction tasks, and five datasets. Across all cases, our results show that enforcing consistency not only constructs structurally valid outputs, but also improves performance over the unconstrained variants.",
    "link": "https://arxiv.org/abs/2401.06877",
    "context": "Title: Promptly Predicting Structures: The Return of Inference\nAbstract: arXiv:2401.06877v2 Announce Type: replace  Abstract: Prompt-based methods have been used extensively across NLP to build zero- and few-shot label predictors. Many NLP tasks are naturally structured: that is, their outputs consist of multiple labels which constrain each other. Annotating data for such tasks can be cumbersome. Can the promise of the prompt-based paradigm be extended to such structured outputs? In this paper, we present a framework for constructing zero- and few-shot linguistic structure predictors. Our key insight is that we can use structural constraints -- and combinatorial inference derived from them -- to filter out inconsistent structures predicted by large language models. We instantiated this framework on two structured prediction tasks, and five datasets. Across all cases, our results show that enforcing consistency not only constructs structurally valid outputs, but also improves performance over the unconstrained variants.",
    "path": "papers/24/01/2401.06877.json",
    "total_tokens": 818,
    "translated_title": "及时预测结构：推理的回归",
    "translated_abstract": "在自然语言处理领域，基于提示的方法被广泛用于构建零样本和少样本标签预测器。许多自然语言处理任务具有结构特点：即它们的输出由多个相互约束的标签组成。为这类任务标注数据可能会很繁琐。本文探讨了基于提示的范式能否扩展到这种结构化输出任务？我们提出了一个构建零样本和少样本语言结构预测器的框架。我们的关键观点是，我们可以利用结构约束和从中得出的组合推理来过滤大型语言模型预测的不一致结构。我们在两个结构化预测任务和五个数据集上实例化了这个框架。结果表明，在所有情况下，强制实施一致性不仅构造了结构有效的输出，而且提高了性能，超过了不受约束的变体。",
    "tldr": "本文提出了一个框架，通过使用结构约束和由此衍生的组合推理，可以过滤大型语言模型预测的不一致结构，从而构建有效的结构化输出，并提高性能。"
}