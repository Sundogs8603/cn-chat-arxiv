{
    "title": "Accelerating superconductor discovery through tempered deep learning of the electron-phonon spectral function. (arXiv:2401.16611v1 [cond-mat.supr-con])",
    "abstract": "Integrating deep learning with the search for new electron-phonon superconductors represents a burgeoning field of research, where the primary challenge lies in the computational intensity of calculating the electron-phonon spectral function, $\\alpha^2F(\\omega)$, the essential ingredient of Midgal-Eliashberg theory of superconductivity. To overcome this challenge, we adopt a two-step approach. First, we compute $\\alpha^2F(\\omega)$ for 818 dynamically stable materials. We then train a deep-learning model to predict $\\alpha^2F(\\omega)$, using an unconventional training strategy to temper the model's overfitting, enhancing predictions. Specifically, we train a Bootstrapped Ensemble of Tempered Equivariant graph neural NETworks (BETE-NET), obtaining an MAE of 0.21, 45 K, and 43 K for the Eliashberg moments derived from $\\alpha^2F(\\omega)$: $\\lambda$, $\\omega_{\\log}$, and $\\omega_{2}$, respectively, yielding an MAE of 2.5 K for the critical temperature, $T_c$. Further, we incorporate domain",
    "link": "http://arxiv.org/abs/2401.16611",
    "context": "Title: Accelerating superconductor discovery through tempered deep learning of the electron-phonon spectral function. (arXiv:2401.16611v1 [cond-mat.supr-con])\nAbstract: Integrating deep learning with the search for new electron-phonon superconductors represents a burgeoning field of research, where the primary challenge lies in the computational intensity of calculating the electron-phonon spectral function, $\\alpha^2F(\\omega)$, the essential ingredient of Midgal-Eliashberg theory of superconductivity. To overcome this challenge, we adopt a two-step approach. First, we compute $\\alpha^2F(\\omega)$ for 818 dynamically stable materials. We then train a deep-learning model to predict $\\alpha^2F(\\omega)$, using an unconventional training strategy to temper the model's overfitting, enhancing predictions. Specifically, we train a Bootstrapped Ensemble of Tempered Equivariant graph neural NETworks (BETE-NET), obtaining an MAE of 0.21, 45 K, and 43 K for the Eliashberg moments derived from $\\alpha^2F(\\omega)$: $\\lambda$, $\\omega_{\\log}$, and $\\omega_{2}$, respectively, yielding an MAE of 2.5 K for the critical temperature, $T_c$. Further, we incorporate domain",
    "path": "papers/24/01/2401.16611.json",
    "total_tokens": 1009,
    "translated_title": "通过调控深度学习的电子声子谱函数来加速超导体发现",
    "translated_abstract": "将深度学习与寻找新的电子声子超导体结合起来，是一个蓬勃发展的研究领域，其中主要挑战在于计算电子声子谱函数$\\alpha^2F(\\omega)$的计算强度，这是 Midgal-Eliashberg 超导理论的基本因素。为了克服这个挑战，我们采用了一个两步方法。首先，我们对818个动态稳定的材料计算了$\\alpha^2F(\\omega)$。然后，我们采用一种非传统的训练策略，使用混合模型训练神经网络模型来预测$\\alpha^2F(\\omega)$，以调节模型的过度拟合，提高预测准确性。具体而言，我们使用 TEMNets（温度均衡下的 Bootstrapped Ensemble of Equivariant graph neural networks）模型进行训练，得到了来自$\\alpha^2F(\\omega)$的 Eliashberg 矩的 MAE，分别为0.21，45 K 和 43 K: $\\lambda$，$\\omega_{\\log}$ 和 $\\omega_{2}$，对应的临界温度$T_c$的 MAE 为2.5 K。此外，我们还将领域信息结合进来利用。",
    "tldr": "通过采用非传统的训练策略，结合调控深度学习模型，成功预测了电子声子谱函数，并得到了超导材料的关键参数，加速了超导体的发现。"
}