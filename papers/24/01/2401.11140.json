{
    "title": "Stability Plasticity Decoupled Fine-tuning For Few-shot end-to-end Object Detection. (arXiv:2401.11140v1 [cs.CV])",
    "abstract": "Few-shot object detection(FSOD) aims to design methods to adapt object detectors efficiently with only few annotated samples. Fine-tuning has been shown to be an effective and practical approach. However, previous works often take the classical base-novel two stage fine-tuning procedure but ignore the implicit stability-plasticity contradiction among different modules. Specifically, the random re-initialized classifiers need more plasticity to adapt to novel samples. The other modules inheriting pre-trained weights demand more stability to reserve their class-agnostic knowledge. Regular fine-tuning which couples the optimization of these two parts hurts the model generalization in FSOD scenarios. In this paper, we find that this problem is prominent in the end-to-end object detector Sparse R-CNN for its multi-classifier cascaded architecture. We propose to mitigate this contradiction by a new three-stage fine-tuning procedure by introducing an addtional plasticity classifier fine-tunin",
    "link": "http://arxiv.org/abs/2401.11140",
    "context": "Title: Stability Plasticity Decoupled Fine-tuning For Few-shot end-to-end Object Detection. (arXiv:2401.11140v1 [cs.CV])\nAbstract: Few-shot object detection(FSOD) aims to design methods to adapt object detectors efficiently with only few annotated samples. Fine-tuning has been shown to be an effective and practical approach. However, previous works often take the classical base-novel two stage fine-tuning procedure but ignore the implicit stability-plasticity contradiction among different modules. Specifically, the random re-initialized classifiers need more plasticity to adapt to novel samples. The other modules inheriting pre-trained weights demand more stability to reserve their class-agnostic knowledge. Regular fine-tuning which couples the optimization of these two parts hurts the model generalization in FSOD scenarios. In this paper, we find that this problem is prominent in the end-to-end object detector Sparse R-CNN for its multi-classifier cascaded architecture. We propose to mitigate this contradiction by a new three-stage fine-tuning procedure by introducing an addtional plasticity classifier fine-tunin",
    "path": "papers/24/01/2401.11140.json",
    "total_tokens": 899,
    "translated_title": "稳定与可塑性解耦的少样本端到端目标检测微调",
    "translated_abstract": "少样本目标检测（FSOD）旨在设计能够以尽可能少的标注样本高效适应目标检测器的方法。细调已被证明是一种有效且实用的方法。然而，以往的工作通常采用经典的基础-新颖两阶段微调过程，但忽略了不同模块之间的隐含稳定性-可塑性矛盾。具体而言，重新初始化的随机分类器需要更大的可塑性来适应新颖样本。继承预训练权重的其他模块需要更多的稳定性来保留其与类别无关的知识。常规微调将这两个部分的优化耦合在一起，在FSOD场景下损害了模型的泛化能力。在本文中，我们发现这个问题在端到端目标检测器Sparse R-CNN中尤为突出，因为它具有多分类器的级联结构。我们提出通过引入额外的可塑性分类器微调，采用新的三阶段微调过程来缓解这个矛盾。",
    "tldr": "本文提出了一个解耦稳定性和可塑性的新的三阶段微调过程，用于缓解少样本目标检测中的稳定性-可塑性矛盾问题。",
    "en_tdlr": "This paper proposes a new three-stage fine-tuning procedure that decouples stability and plasticity to mitigate the stability-plasticity contradiction in few-shot object detection."
}