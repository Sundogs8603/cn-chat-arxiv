{
    "title": "Unsupervised Object-Centric Learning from Multiple Unspecified Viewpoints. (arXiv:2401.01922v1 [cs.CV])",
    "abstract": "Visual scenes are extremely diverse, not only because there are infinite possible combinations of objects and backgrounds but also because the observations of the same scene may vary greatly with the change of viewpoints. When observing a multi-object visual scene from multiple viewpoints, humans can perceive the scene compositionally from each viewpoint while achieving the so-called ``object constancy'' across different viewpoints, even though the exact viewpoints are untold. This ability is essential for humans to identify the same object while moving and to learn from vision efficiently. It is intriguing to design models that have a similar ability. In this paper, we consider a novel problem of learning compositional scene representations from multiple unspecified (i.e., unknown and unrelated) viewpoints without using any supervision and propose a deep generative model which separates latent representations into a viewpoint-independent part and a viewpoint-dependent part to solve th",
    "link": "http://arxiv.org/abs/2401.01922",
    "context": "Title: Unsupervised Object-Centric Learning from Multiple Unspecified Viewpoints. (arXiv:2401.01922v1 [cs.CV])\nAbstract: Visual scenes are extremely diverse, not only because there are infinite possible combinations of objects and backgrounds but also because the observations of the same scene may vary greatly with the change of viewpoints. When observing a multi-object visual scene from multiple viewpoints, humans can perceive the scene compositionally from each viewpoint while achieving the so-called ``object constancy'' across different viewpoints, even though the exact viewpoints are untold. This ability is essential for humans to identify the same object while moving and to learn from vision efficiently. It is intriguing to design models that have a similar ability. In this paper, we consider a novel problem of learning compositional scene representations from multiple unspecified (i.e., unknown and unrelated) viewpoints without using any supervision and propose a deep generative model which separates latent representations into a viewpoint-independent part and a viewpoint-dependent part to solve th",
    "path": "papers/24/01/2401.01922.json",
    "total_tokens": 840,
    "translated_title": "从多个未指定视角进行无监督的物体中心学习",
    "translated_abstract": "视觉场景的多样性非常丰富，不仅因为对象和背景有无限可能的组合，而且因为同一场景的观察在视角变化时可能会有很大的差异。在观察多个视角的多物体视觉场景时，人类可以从每个视角对场景进行组合性感知，同时实现所谓的“对象恒常性”，尽管具体的视角是未知的。这种能力对于人类在移动过程中识别相同对象和高效学习视觉信息至关重要。设计具备类似能力的模型具有很大的吸引力。在本文中，我们考虑了一个新颖的问题，即在没有任何监督的情况下，从多个未指定的视角学习组合性场景表示，并提出了一个深度生成模型，将潜在表示分为与视角无关的部分和与视角相关的部分来解决这个问题。",
    "tldr": "本文提出了一个无监督的深度生成模型，用于从多个未指定的视角学习组合性场景表示。该模型能够将潜在表示分为与视角无关的部分和与视角相关的部分。"
}