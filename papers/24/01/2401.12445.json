{
    "title": "Session-level Normalization and Click-through Data Enhancement for Session-based Evaluation. (arXiv:2401.12445v1 [cs.IR])",
    "abstract": "Since a user usually has to issue a sequence of queries and examine multiple documents to resolve a complex information need in a search session, researchers have paid much attention to evaluating search systems at the session level rather than the single-query level. Most existing session-level metrics evaluate each query separately and then aggregate the query-level scores using a session-level weighting function. The assumptions behind these metrics are that all queries in the session should be involved, and their orders are fixed. However, if a search system could make the user satisfied with her first few queries, she may not need any subsequent queries. Besides, in most real-world search scenarios, due to a lack of explicit feedback from real users, we can only leverage some implicit feedback, such as users' clicks, as relevance labels for offline evaluation. Such implicit feedback might be different from the real relevance in a search session as some documents may be omitted in ",
    "link": "http://arxiv.org/abs/2401.12445",
    "context": "Title: Session-level Normalization and Click-through Data Enhancement for Session-based Evaluation. (arXiv:2401.12445v1 [cs.IR])\nAbstract: Since a user usually has to issue a sequence of queries and examine multiple documents to resolve a complex information need in a search session, researchers have paid much attention to evaluating search systems at the session level rather than the single-query level. Most existing session-level metrics evaluate each query separately and then aggregate the query-level scores using a session-level weighting function. The assumptions behind these metrics are that all queries in the session should be involved, and their orders are fixed. However, if a search system could make the user satisfied with her first few queries, she may not need any subsequent queries. Besides, in most real-world search scenarios, due to a lack of explicit feedback from real users, we can only leverage some implicit feedback, such as users' clicks, as relevance labels for offline evaluation. Such implicit feedback might be different from the real relevance in a search session as some documents may be omitted in ",
    "path": "papers/24/01/2401.12445.json",
    "total_tokens": 877,
    "translated_title": "会话级归一化和点击数据增强对于会话评估的应用",
    "translated_abstract": "鉴于用户通常需要发出一系列查询并检查多个文档以解决复杂的信息需求，研究人员更关注于会话级别而非单一查询级别上对搜索系统进行评估。现有的大多数会话级指标都是分别评估每个查询，然后使用会话级加权函数对查询级得分进行聚合。这些指标的假设是会话中的所有查询都应该参与其中，并且它们的顺序是固定的。然而，如果一个搜索系统可以通过用户的前几个查询使用户满意，那么她可能不需要任何后续查询了。此外，在大多数实际搜索场景中，由于缺乏真实用户的明确反馈，我们只能利用一些隐式反馈，如用户的点击，作为离线评估的相关性标签。这样的隐式反馈与搜索会话中的真实相关性可能有所不同，因为有些文档可能被忽略了。",
    "tldr": "本研究针对会话级别的搜索系统评估，提出了会话级归一化和点击数据增强的方法。传统方法中会话级指标的假设可能不符合实际情况，本文考虑了用户满意度和隐式反馈的影响。",
    "en_tdlr": "This study proposes session-level normalization and click-through data enhancement for session-based evaluation in search systems. It addresses the limitations of traditional session-level metrics and considers the impact of user satisfaction and implicit feedback."
}