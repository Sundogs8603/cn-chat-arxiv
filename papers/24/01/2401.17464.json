{
    "title": "Efficient Tool Use with Chain-of-Abstraction Reasoning",
    "abstract": "To achieve faithful reasoning that aligns with human expectations, large language models (LLMs) need to ground their reasoning to real-world knowledge (e.g., web facts, math and physical rules). Tools help LLMs access this external knowledge, but there remains challenges for fine-tuning LLM agents (e.g., Toolformer) to invoke tools in multi-step reasoning problems, where inter-connected tool calls require holistic and efficient tool usage planning.   In this work, we propose a new method for LLMs to better leverage tools in multi-step reasoning. Our method, Chain-of-Abstraction (CoA), trains LLMs to first decode reasoning chains with abstract placeholders, and then call domain tools to reify each reasoning chain by filling in specific knowledge. This planning with abstract chains enables LLMs to learn more general reasoning strategies, which are robust to shifts of domain knowledge (e.g., math results) relevant to different reasoning questions. It also allows LLMs to perform decoding a",
    "link": "https://arxiv.org/abs/2401.17464",
    "context": "Title: Efficient Tool Use with Chain-of-Abstraction Reasoning\nAbstract: To achieve faithful reasoning that aligns with human expectations, large language models (LLMs) need to ground their reasoning to real-world knowledge (e.g., web facts, math and physical rules). Tools help LLMs access this external knowledge, but there remains challenges for fine-tuning LLM agents (e.g., Toolformer) to invoke tools in multi-step reasoning problems, where inter-connected tool calls require holistic and efficient tool usage planning.   In this work, we propose a new method for LLMs to better leverage tools in multi-step reasoning. Our method, Chain-of-Abstraction (CoA), trains LLMs to first decode reasoning chains with abstract placeholders, and then call domain tools to reify each reasoning chain by filling in specific knowledge. This planning with abstract chains enables LLMs to learn more general reasoning strategies, which are robust to shifts of domain knowledge (e.g., math results) relevant to different reasoning questions. It also allows LLMs to perform decoding a",
    "path": "papers/24/01/2401.17464.json",
    "total_tokens": 884,
    "translated_title": "使用抽象链推理的高效工具使用",
    "translated_abstract": "为了实现与人类期望一致的准确推理，大型语言模型（LLM）需要将推理与现实世界的知识（例如网络事实、数学和物理规则）联系起来。工具可以帮助LLM获取这些外部知识，但是在多步推理问题中仍然存在挑战，即如何精细调整LLM代理（例如Toolformer）以调用工具，其中相互连接的工具调用需要整体化和高效的工具使用规划。在这项工作中，我们提出了一种新的方法，让LLM在多步推理中更好地利用工具。我们的方法是通过训练LLM首先用抽象占位符解码推理链，然后调用领域工具以填充具体知识来实现每个推理链。抽象链的规划使LLM能够学习更通用的推理策略，对于与不同推理问题相关的领域知识（例如数学结果）的变化具有鲁棒性。它还允许LLM执行解码操作",
    "tldr": "该方法通过让LLM首先解码抽象推理链，然后调用领域工具填充具体知识，使得LLM能够更好地利用工具进行多步推理，并且具有通用性和鲁棒性。",
    "en_tdlr": "This method enables LLMs to better leverage tools for multi-step reasoning by decoding abstract reasoning chains and calling domain tools to fill in specific knowledge, resulting in improved efficiency and generalizability."
}