{
    "title": "Large Language Models for Robotics: Opportunities, Challenges, and Perspectives. (arXiv:2401.04334v1 [cs.RO])",
    "abstract": "Large language models (LLMs) have undergone significant expansion and have been increasingly integrated across various domains. Notably, in the realm of robot task planning, LLMs harness their advanced reasoning and language comprehension capabilities to formulate precise and efficient action plans based on natural language instructions. However, for embodied tasks, where robots interact with complex environments, text-only LLMs often face challenges due to a lack of compatibility with robotic visual perception. This study provides a comprehensive overview of the emerging integration of LLMs and multimodal LLMs into various robotic tasks. Additionally, we propose a framework that utilizes multimodal GPT-4V to enhance embodied task planning through the combination of natural language instructions and robot visual perceptions. Our results, based on diverse datasets, indicate that GPT-4V effectively enhances robot performance in embodied tasks. This extensive survey and evaluation of LLMs",
    "link": "http://arxiv.org/abs/2401.04334",
    "context": "Title: Large Language Models for Robotics: Opportunities, Challenges, and Perspectives. (arXiv:2401.04334v1 [cs.RO])\nAbstract: Large language models (LLMs) have undergone significant expansion and have been increasingly integrated across various domains. Notably, in the realm of robot task planning, LLMs harness their advanced reasoning and language comprehension capabilities to formulate precise and efficient action plans based on natural language instructions. However, for embodied tasks, where robots interact with complex environments, text-only LLMs often face challenges due to a lack of compatibility with robotic visual perception. This study provides a comprehensive overview of the emerging integration of LLMs and multimodal LLMs into various robotic tasks. Additionally, we propose a framework that utilizes multimodal GPT-4V to enhance embodied task planning through the combination of natural language instructions and robot visual perceptions. Our results, based on diverse datasets, indicate that GPT-4V effectively enhances robot performance in embodied tasks. This extensive survey and evaluation of LLMs",
    "path": "papers/24/01/2401.04334.json",
    "total_tokens": 926,
    "translated_title": "大规模语言模型与机器人技术：机遇、挑战和前景",
    "translated_abstract": "大规模语言模型（LLMs）经历了重大扩展，并在各个领域得到越来越广泛的应用。特别是在机器人任务规划领域，LLMs利用其高级推理和语言理解能力，根据自然语言指令制定精确高效的行动计划。然而，在与复杂环境互动的实体任务中，仅有文本的LLMs常常面临与机器人视觉感知不兼容的挑战。本研究对LLMs和多模态LLMs在各种机器人任务中的新兴集成进行了全面概述。此外，我们提出了一个框架，利用多模态GPT-4V通过自然语言指令和机器人视觉感知的结合来增强实体任务规划。基于多样化的数据集，我们的结果表明，GPT-4V在实体任务中有效地提升了机器人的性能。这项广泛的LLMs调研和评估",
    "tldr": "大规模语言模型与机器人技术的结合在机器人任务规划中具有巨大潜力，但在与复杂环境互动的实体任务中存在挑战。本研究提出了一个通过多模态GPT-4V的框架来增强实体任务规划效果，并在多样化的数据集上验证了其有效性。",
    "en_tdlr": "The integration of large language models with robotics has great potential in robot task planning, but faces challenges in embodied tasks with complex environments. This study proposes a framework using multimodal GPT-4V to enhance embodied task planning and validates its effectiveness on diverse datasets."
}