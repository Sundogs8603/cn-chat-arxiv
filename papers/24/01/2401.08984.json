{
    "title": "A GAN-based data poisoning framework against anomaly detection in vertical federated learning. (arXiv:2401.08984v1 [cs.LG])",
    "abstract": "In vertical federated learning (VFL), commercial entities collaboratively train a model while preserving data privacy. However, a malicious participant's poisoning attack may degrade the performance of this collaborative model. The main challenge in achieving the poisoning attack is the absence of access to the server-side top model, leaving the malicious participant without a clear target model. To address this challenge, we introduce an innovative end-to-end poisoning framework P-GAN. Specifically, the malicious participant initially employs semi-supervised learning to train a surrogate target model. Subsequently, this participant employs a GAN-based method to produce adversarial perturbations to degrade the surrogate target model's performance. Finally, the generator is obtained and tailored for VFL poisoning. Besides, we develop an anomaly detection algorithm based on a deep auto-encoder (DAE), offering a robust defense mechanism to VFL scenarios. Through extensive experiments, we ",
    "link": "http://arxiv.org/abs/2401.08984",
    "context": "Title: A GAN-based data poisoning framework against anomaly detection in vertical federated learning. (arXiv:2401.08984v1 [cs.LG])\nAbstract: In vertical federated learning (VFL), commercial entities collaboratively train a model while preserving data privacy. However, a malicious participant's poisoning attack may degrade the performance of this collaborative model. The main challenge in achieving the poisoning attack is the absence of access to the server-side top model, leaving the malicious participant without a clear target model. To address this challenge, we introduce an innovative end-to-end poisoning framework P-GAN. Specifically, the malicious participant initially employs semi-supervised learning to train a surrogate target model. Subsequently, this participant employs a GAN-based method to produce adversarial perturbations to degrade the surrogate target model's performance. Finally, the generator is obtained and tailored for VFL poisoning. Besides, we develop an anomaly detection algorithm based on a deep auto-encoder (DAE), offering a robust defense mechanism to VFL scenarios. Through extensive experiments, we ",
    "path": "papers/24/01/2401.08984.json",
    "total_tokens": 1001,
    "translated_title": "基于GAN的数据污染框架对抗纵向联合学习中的异常检测",
    "translated_abstract": "在纵向联合学习 (VFL) 中，商业实体在保护数据隐私的同时协作训练模型。然而，恶意参与者的污染攻击可能会降低这个协作模型的性能。实现污染攻击的主要挑战是缺乏对服务器端顶层模型的访问，使得恶意参与者没有明确的目标模型。为了应对这个挑战，我们引入了一种创新的端到端污染框架 P-GAN。具体而言，恶意参与者最初采用半监督学习训练一个替代目标模型。随后，该参与者采用基于GAN的方法产生对抗性扰动，以降低替代目标模型的性能。最后，生成器被获得并针对VFL污染进行了改进。此外，我们还基于深度自编码器 (DAE) 开发了一种异常检测算法，为VFL场景提供了强大的防御机制。通过大量实验，我们证明了…",
    "tldr": "这篇论文介绍了一种基于GAN的数据污染框架（P-GAN），用于对抗纵向联合学习中的异常检测。通过使用半监督学习训练一个替代目标模型，并使用GAN生成对抗性扰动来降低模型性能，最后通过深度自编码器开发的异常检测算法提供了强大的防御机制。",
    "en_tdlr": "This paper introduces a GAN-based data poisoning framework (P-GAN) to counter anomaly detection in vertical federated learning. It trains a surrogate target model using semi-supervised learning and generates adversarial perturbations using GAN to degrade the model's performance. Additionally, it provides a robust defense mechanism through an anomaly detection algorithm based on deep auto-encoders."
}