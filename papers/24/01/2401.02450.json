{
    "title": "Locally Differentially Private Embedding Models in Distributed Fraud Prevention Systems. (arXiv:2401.02450v1 [cs.CR])",
    "abstract": "Global financial crime activity is driving demand for machine learning solutions in fraud prevention. However, prevention systems are commonly serviced to financial institutions in isolation, and few provisions exist for data sharing due to fears of unintentional leaks and adversarial attacks. Collaborative learning advances in finance are rare, and it is hard to find real-world insights derived from privacy-preserving data processing systems. In this paper, we present a collaborative deep learning framework for fraud prevention, designed from a privacy standpoint, and awarded at the recent PETs Prize Challenges. We leverage latent embedded representations of varied-length transaction sequences, along with local differential privacy, in order to construct a data release mechanism which can securely inform externally hosted fraud and anomaly detection models. We assess our contribution on two distributed data sets donated by large payment networks, and demonstrate robustness to popular ",
    "link": "http://arxiv.org/abs/2401.02450",
    "context": "Title: Locally Differentially Private Embedding Models in Distributed Fraud Prevention Systems. (arXiv:2401.02450v1 [cs.CR])\nAbstract: Global financial crime activity is driving demand for machine learning solutions in fraud prevention. However, prevention systems are commonly serviced to financial institutions in isolation, and few provisions exist for data sharing due to fears of unintentional leaks and adversarial attacks. Collaborative learning advances in finance are rare, and it is hard to find real-world insights derived from privacy-preserving data processing systems. In this paper, we present a collaborative deep learning framework for fraud prevention, designed from a privacy standpoint, and awarded at the recent PETs Prize Challenges. We leverage latent embedded representations of varied-length transaction sequences, along with local differential privacy, in order to construct a data release mechanism which can securely inform externally hosted fraud and anomaly detection models. We assess our contribution on two distributed data sets donated by large payment networks, and demonstrate robustness to popular ",
    "path": "papers/24/01/2401.02450.json",
    "total_tokens": 892,
    "translated_title": "在分布式欺诈预防系统中的本地差分隐私嵌入模型",
    "translated_abstract": "全球金融犯罪活动促使欺诈预防中需要机器学习解决方案。然而，由于担心意外泄漏和敌对攻击，预防系统通常只为金融机构提供服务而缺乏数据共享的机制。金融领域的协作学习进展较少，也很难从隐私保护的数据处理系统中获得实际洞察。本文介绍了一个从隐私角度设计的协作深度学习框架，用于欺诈预防，并在最近的PETs Prize Challenges中获奖。我们利用变长交易序列的潜在嵌入表示和本地差分隐私构建了一个数据发布机制，可以安全地提供给外部托管的欺诈和异常检测模型。我们在两个来自大型支付网络的分布式数据集上评估了我们的贡献，并展示了对常见攻击方法的鲁棒性。",
    "tldr": "本文提出了一个基于本地差分隐私的协作深度学习框架，用于在分布式欺诈预防系统中构建安全的数据发布机制，以支持外部欺诈检测模型。在实验中展示了其对多种攻击方法的鲁棒性。",
    "en_tdlr": "This paper presents a collaborative deep learning framework based on local differential privacy, that constructs a secure data release mechanism for distributed fraud prevention systems to support external fraud detection models. The experiments demonstrate its robustness against various attacks."
}