{
    "title": "Team IELAB at TREC Clinical Trial Track 2023: Enhancing Clinical Trial Retrieval with Neural Rankers and Large Language Models. (arXiv:2401.01566v1 [cs.IR])",
    "abstract": "We describe team ielab from CSIRO and The University of Queensland's approach to the 2023 TREC Clinical Trials Track. Our approach was to use neural rankers but to utilise Large Language Models to overcome the issue of lack of training data for such rankers. Specifically, we employ ChatGPT to generate relevant patient descriptions for randomly selected clinical trials from the corpus. This synthetic dataset, combined with human-annotated training data from previous years, is used to train both dense and sparse retrievers based on PubmedBERT. Additionally, a cross-encoder re-ranker is integrated into the system. To further enhance the effectiveness of our approach, we prompting GPT-4 as a TREC annotator to provide judgments on our run files. These judgments are subsequently employed to re-rank the results. This architecture tightly integrates strong PubmedBERT-based rankers with the aid of SOTA Large Language Models, demonstrating a new approach to clinical trial retrieval.",
    "link": "http://arxiv.org/abs/2401.01566",
    "context": "Title: Team IELAB at TREC Clinical Trial Track 2023: Enhancing Clinical Trial Retrieval with Neural Rankers and Large Language Models. (arXiv:2401.01566v1 [cs.IR])\nAbstract: We describe team ielab from CSIRO and The University of Queensland's approach to the 2023 TREC Clinical Trials Track. Our approach was to use neural rankers but to utilise Large Language Models to overcome the issue of lack of training data for such rankers. Specifically, we employ ChatGPT to generate relevant patient descriptions for randomly selected clinical trials from the corpus. This synthetic dataset, combined with human-annotated training data from previous years, is used to train both dense and sparse retrievers based on PubmedBERT. Additionally, a cross-encoder re-ranker is integrated into the system. To further enhance the effectiveness of our approach, we prompting GPT-4 as a TREC annotator to provide judgments on our run files. These judgments are subsequently employed to re-rank the results. This architecture tightly integrates strong PubmedBERT-based rankers with the aid of SOTA Large Language Models, demonstrating a new approach to clinical trial retrieval.",
    "path": "papers/24/01/2401.01566.json",
    "total_tokens": 1033,
    "translated_title": "Team IELAB在TREC临床试验跟踪2023中的研究：利用神经排序器和大型语言模型提升临床试验检索能力。",
    "translated_abstract": "我们介绍了澳大利亚联邦科学与工业研究组织（CSIRO）和昆士兰大学团队ielab在2023年TREC临床试验跟踪中的方法。我们的方法是使用神经排序器，但利用大型语言模型来解决这类排序器缺乏训练数据的问题。具体而言，我们采用ChatGPT从语料库中生成与随机选择的临床试验相关的患者描述。这个合成数据集与之前几年的人工注释训练数据结合，用于基于PubmedBERT的稠密和稀疏检索器的训练。此外，还将一个交叉编码器重新排序器集成到系统中。为了进一步提升我们的方法的有效性，我们使用GPT-4作为TREC注释器提供对我们的运行文件的判断。这些判断结果随后被用来重新排序结果。这种架构将强大的基于PubmedBERT的排序器与最先进的大型语言模型紧密集成在一起，展示了一个新的临床试验检索方法。",
    "tldr": "Team IELAB在2023年TREC临床试验跟踪中采用神经排序器和大型语言模型的方法提升了临床试验检索的效果，通过使用ChatGPT生成合成数据集和整合交叉编码器重新排序器，实现了PubmedBERT的强大排序器的集成，为临床试验检索带来了新的方法。"
}