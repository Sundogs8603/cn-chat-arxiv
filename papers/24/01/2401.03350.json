{
    "title": "Accurate and Scalable Estimation of Epistemic Uncertainty for Graph Neural Networks. (arXiv:2401.03350v1 [cs.LG])",
    "abstract": "While graph neural networks (GNNs) are widely used for node and graph representation learning tasks, the reliability of GNN uncertainty estimates under distribution shifts remains relatively under-explored. Indeed, while post-hoc calibration strategies can be used to improve in-distribution calibration, they need not also improve calibration under distribution shift. However, techniques which produce GNNs with better intrinsic uncertainty estimates are particularly valuable, as they can always be combined with post-hoc strategies later. Therefore, in this work, we propose G-$\\Delta$UQ, a novel training framework designed to improve intrinsic GNN uncertainty estimates. Our framework adapts the principle of stochastic data centering to graph data through novel graph anchoring strategies, and is able to support partially stochastic GNNs. While, the prevalent wisdom is that fully stochastic networks are necessary to obtain reliable estimates, we find that the functional diversity induced b",
    "link": "http://arxiv.org/abs/2401.03350",
    "context": "Title: Accurate and Scalable Estimation of Epistemic Uncertainty for Graph Neural Networks. (arXiv:2401.03350v1 [cs.LG])\nAbstract: While graph neural networks (GNNs) are widely used for node and graph representation learning tasks, the reliability of GNN uncertainty estimates under distribution shifts remains relatively under-explored. Indeed, while post-hoc calibration strategies can be used to improve in-distribution calibration, they need not also improve calibration under distribution shift. However, techniques which produce GNNs with better intrinsic uncertainty estimates are particularly valuable, as they can always be combined with post-hoc strategies later. Therefore, in this work, we propose G-$\\Delta$UQ, a novel training framework designed to improve intrinsic GNN uncertainty estimates. Our framework adapts the principle of stochastic data centering to graph data through novel graph anchoring strategies, and is able to support partially stochastic GNNs. While, the prevalent wisdom is that fully stochastic networks are necessary to obtain reliable estimates, we find that the functional diversity induced b",
    "path": "papers/24/01/2401.03350.json",
    "total_tokens": 948,
    "translated_title": "准确可扩展的图神经网络表观不确定性估计",
    "translated_abstract": "尽管图神经网络（GNN）广泛用于节点和图表示学习任务，但在分布变化下GNN不确定性估计的可靠性仍相对较少探索。事实上，虽然事后校准策略可以用于改善内部分布校准，但它们不一定也能改进分布变化下的校准。然而，产生更好的内部不确定性估计的技术尤其有价值，因为它们可以随后与事后策略结合使用。因此，在本研究中，我们提出了一种名为G-$\\Delta$UQ的新型训练框架，旨在改善内在的GNN不确定性估计。我们的框架通过新颖的图锚定策略将随机数据中心化原则应用于图数据，并能够支持部分随机的GNN。虽然主流观点是为了获得可靠的估计，需要完全随机网络，但我们发现通过功能多样性引入的中观锚定可以在保证准确性的同时降低计算成本。",
    "tldr": "提出了G-$\\Delta$UQ，一种新的训练框架，旨在改善图神经网络（GNN）的内在不确定性估计。该框架通过图锚定策略将随机数据中心化应用于图数据，并且能够支持部分随机的GNN。"
}