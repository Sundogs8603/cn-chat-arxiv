{
    "title": "Meta-forests: Domain generalization on random forests with meta-learning. (arXiv:2401.04425v1 [cs.CV])",
    "abstract": "Domain generalization is a popular machine learning technique that enables models to perform well on the unseen target domain, by learning from multiple source domains. Domain generalization is useful in cases where data is limited, difficult, or expensive to collect, such as in object recognition and biomedicine. In this paper, we propose a novel domain generalization algorithm called \"meta-forests\", which builds upon the basic random forests model by incorporating the meta-learning strategy and maximum mean discrepancy measure. The aim of meta-forests is to enhance the generalization ability of classifiers by reducing the correlation among trees and increasing their strength. More specifically, meta-forests conducts meta-learning optimization during each meta-task, while also utilizing the maximum mean discrepancy as a regularization term to penalize poor generalization performance in the meta-test process. To evaluate the effectiveness of our algorithm, we test it on two publicly ob",
    "link": "http://arxiv.org/abs/2401.04425",
    "context": "Title: Meta-forests: Domain generalization on random forests with meta-learning. (arXiv:2401.04425v1 [cs.CV])\nAbstract: Domain generalization is a popular machine learning technique that enables models to perform well on the unseen target domain, by learning from multiple source domains. Domain generalization is useful in cases where data is limited, difficult, or expensive to collect, such as in object recognition and biomedicine. In this paper, we propose a novel domain generalization algorithm called \"meta-forests\", which builds upon the basic random forests model by incorporating the meta-learning strategy and maximum mean discrepancy measure. The aim of meta-forests is to enhance the generalization ability of classifiers by reducing the correlation among trees and increasing their strength. More specifically, meta-forests conducts meta-learning optimization during each meta-task, while also utilizing the maximum mean discrepancy as a regularization term to penalize poor generalization performance in the meta-test process. To evaluate the effectiveness of our algorithm, we test it on two publicly ob",
    "path": "papers/24/01/2401.04425.json",
    "total_tokens": 963,
    "translated_title": "元森林：基于元学习的随机森林的领域泛化",
    "translated_abstract": "领域泛化是一种流行的机器学习技术，通过从多个源领域学习，使模型在未见过的目标领域上表现良好。领域泛化在数据有限、困难或昂贵收集的情况下非常有用，比如目标识别和生物医学领域。本文提出了一种新颖的领域泛化算法，名为\"元森林\"，它在基本的随机森林模型基础上，结合了元学习策略和最大均值差异度量。元森林的目标是通过减少树之间的相关性并增强其强度，提高分类器的泛化能力。具体而言，元森林在每个元任务中进行元学习优化，同时利用最大均值差异作为正则化项，在元测试过程中惩罚泛化性能差的情况。为了评估我们算法的有效性，我们将其应用于两个公开的领域泛化数据集上。",
    "tldr": "本文提出了一种新的领域泛化算法\"元森林\"，通过整合元学习策略和最大均值差异度量，提高分类器的泛化能力。该算法在每个元任务中进行元学习优化，并利用最大均值差异作为正则化项，来惩罚泛化性能差的情况。",
    "en_tdlr": "This paper proposes a novel domain generalization algorithm called \"meta-forests\", which enhances the generalization ability of classifiers by integrating meta-learning strategy and maximum mean discrepancy measure. The algorithm conducts meta-learning optimization for each meta-task and utilizes maximum mean discrepancy as a regularization term to penalize poor generalization performance."
}