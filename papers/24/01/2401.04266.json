{
    "title": "Attention versus Contrastive Learning of Tabular Data -- A Data-centric Benchmarking. (arXiv:2401.04266v1 [cs.LG])",
    "abstract": "Despite groundbreaking success in image and text learning, deep learning has not achieved significant improvements against traditional machine learning (ML) when it comes to tabular data. This performance gap underscores the need for data-centric treatment and benchmarking of learning algorithms. Recently, attention and contrastive learning breakthroughs have shifted computer vision and natural language processing paradigms. However, the effectiveness of these advanced deep models on tabular data is sparsely studied using a few data sets with very large sample sizes, reporting mixed findings after benchmarking against a limited number of baselines. We argue that the heterogeneity of tabular data sets and selective baselines in the literature can bias the benchmarking outcomes. This article extensively evaluates state-of-the-art attention and contrastive learning methods on a wide selection of 28 tabular data sets (14 easy and 14 hard-to-classify) against traditional deep and machine le",
    "link": "http://arxiv.org/abs/2401.04266",
    "context": "Title: Attention versus Contrastive Learning of Tabular Data -- A Data-centric Benchmarking. (arXiv:2401.04266v1 [cs.LG])\nAbstract: Despite groundbreaking success in image and text learning, deep learning has not achieved significant improvements against traditional machine learning (ML) when it comes to tabular data. This performance gap underscores the need for data-centric treatment and benchmarking of learning algorithms. Recently, attention and contrastive learning breakthroughs have shifted computer vision and natural language processing paradigms. However, the effectiveness of these advanced deep models on tabular data is sparsely studied using a few data sets with very large sample sizes, reporting mixed findings after benchmarking against a limited number of baselines. We argue that the heterogeneity of tabular data sets and selective baselines in the literature can bias the benchmarking outcomes. This article extensively evaluates state-of-the-art attention and contrastive learning methods on a wide selection of 28 tabular data sets (14 easy and 14 hard-to-classify) against traditional deep and machine le",
    "path": "papers/24/01/2401.04266.json",
    "total_tokens": 948,
    "translated_title": "Attention versus Contrastive Learning of Tabular Data -- A Data-centric Benchmarking. (arXiv:2401.04266v1 [cs.LG])",
    "translated_abstract": "尽管在图像和文本学习方面取得了突破性的成功，深度学习在处理表格数据方面与传统机器学习相比并未取得显著改进。这种性能差距凸显了对学习算法进行以数据为中心的处理和评测的需求。最近，注意力和对比学习的突破已经改变了计算机视觉和自然语言处理的范式。然而，这些先进的深度模型在表格数据上的有效性研究非常有限，仅使用了少数几个具有非常大的样本数量的数据集，并在与有限数量的基线模型进行评测后报告了混合的结果。我们认为，文献中表格数据集的异质性和基线模型的选择性可能会对评测结果产生偏差。本文在28个表格数据集（14个易于分类和14个难以分类）上广泛评估了最先进的注意力和对比学习方法与传统深度学习和机器学习方法的对比表现。",
    "tldr": "本文通过广泛评估28个表格数据集，对比了注意力和对比学习方法与传统深度学习和机器学习方法在表格数据上的性能，结果表明需要以数据为中心进行评测，以解决性能差距问题。",
    "en_tdlr": "This paper extensively evaluates the performance of attention and contrastive learning methods against traditional deep learning and machine learning methods on 28 tabular data sets, highlighting the need for data-centric benchmarking to address the performance gap."
}