{
    "title": "Source-Free and Image-Only Unsupervised Domain Adaptation for Category Level Object Pose Estimation. (arXiv:2401.10848v1 [cs.CV])",
    "abstract": "We consider the problem of source-free unsupervised category-level pose estimation from only RGB images to a target domain without any access to source domain data or 3D annotations during adaptation. Collecting and annotating real-world 3D data and corresponding images is laborious, expensive, yet unavoidable process, since even 3D pose domain adaptation methods require 3D data in the target domain. We introduce 3DUDA, a method capable of adapting to a nuisance-ridden target domain without 3D or depth data. Our key insight stems from the observation that specific object subparts remain stable across out-of-domain (OOD) scenarios, enabling strategic utilization of these invariant subcomponents for effective model updates. We represent object categories as simple cuboid meshes, and harness a generative model of neural feature activations modeled at each mesh vertex learnt using differential rendering. We focus on individual locally robust mesh vertex features and iteratively update them",
    "link": "http://arxiv.org/abs/2401.10848",
    "context": "Title: Source-Free and Image-Only Unsupervised Domain Adaptation for Category Level Object Pose Estimation. (arXiv:2401.10848v1 [cs.CV])\nAbstract: We consider the problem of source-free unsupervised category-level pose estimation from only RGB images to a target domain without any access to source domain data or 3D annotations during adaptation. Collecting and annotating real-world 3D data and corresponding images is laborious, expensive, yet unavoidable process, since even 3D pose domain adaptation methods require 3D data in the target domain. We introduce 3DUDA, a method capable of adapting to a nuisance-ridden target domain without 3D or depth data. Our key insight stems from the observation that specific object subparts remain stable across out-of-domain (OOD) scenarios, enabling strategic utilization of these invariant subcomponents for effective model updates. We represent object categories as simple cuboid meshes, and harness a generative model of neural feature activations modeled at each mesh vertex learnt using differential rendering. We focus on individual locally robust mesh vertex features and iteratively update them",
    "path": "papers/24/01/2401.10848.json",
    "total_tokens": 1026,
    "translated_title": "无源和仅图像无监督领域适应的类别级目标姿态估计",
    "translated_abstract": "我们考虑在适应过程中仅使用RGB图像到目标领域进行无源无监督类别级别姿态估计的问题，而不需要访问源领域数据或3D注释。收集和注释现实世界的3D数据和相应的图像是一项费时费力的过程，但不可避免，因为即使是3D姿态域适应方法也需要目标领域中的3D数据。我们介绍了一种名为3DUDA的方法，可以适应于充满干扰的目标领域，而无需3D或深度数据。我们的关键观点源于这样的观察：特定的物体子部分在域外情景中保持稳定，从而可以有效地利用这些不变的子组件进行模型更新。我们将物体类别表示为简单的立方体网格，并利用在每个网格顶点上学习的神经特征激活的生成模型进行建模。我们专注于个体局部稳健的网格顶点特征，并对其进行迭代更新。",
    "tldr": "本研究提出了一种无源和仅图像无监督领域适应的方法，用于类别级目标姿态估计。通过利用物体特定子部分在跨域情景中的稳定性，我们可以有效地更新模型。使用简单的立方体网格和基于神经特征激活的生成模型，我们可以在没有3D或深度数据的情况下适应充满干扰的目标领域。",
    "en_tdlr": "This paper proposes a source-free and image-only unsupervised domain adaptation method for category-level object pose estimation. By exploiting the stability of specific object subparts in out-of-domain scenarios, the model can be effectively updated. Using simple cuboid meshes and a generative model based on neural feature activations, the method is able to adapt to a nuisance-ridden target domain without 3D or depth data."
}