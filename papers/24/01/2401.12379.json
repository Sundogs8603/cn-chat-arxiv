{
    "title": "Analyzing the Effectiveness of Large Language Models on Text-to-SQL Synthesis. (arXiv:2401.12379v1 [cs.AI])",
    "abstract": "This study investigates various approaches to using Large Language Models (LLMs) for Text-to-SQL program synthesis, focusing on the outcomes and insights derived. Employing the popular Text-to-SQL dataset, spider, the goal was to input a natural language question along with the database schema and output the correct SQL SELECT query. The initial approach was to fine-tune a local and open-source model to generate the SELECT query. After QLoRa fine-tuning WizardLM's WizardCoder-15B model on the spider dataset, the execution accuracy for generated queries rose to a high of 61%. With the second approach, using the fine-tuned gpt-3.5-turbo-16k (Few-shot) + gpt-4-turbo (Zero-shot error correction), the execution accuracy reached a high of 82.1%. Of all the incorrect queries, most can be categorized into a seven different categories of what went wrong: selecting the wrong columns or wrong order of columns, grouping by the wrong column, predicting the wrong values in conditionals, using differ",
    "link": "http://arxiv.org/abs/2401.12379",
    "context": "Title: Analyzing the Effectiveness of Large Language Models on Text-to-SQL Synthesis. (arXiv:2401.12379v1 [cs.AI])\nAbstract: This study investigates various approaches to using Large Language Models (LLMs) for Text-to-SQL program synthesis, focusing on the outcomes and insights derived. Employing the popular Text-to-SQL dataset, spider, the goal was to input a natural language question along with the database schema and output the correct SQL SELECT query. The initial approach was to fine-tune a local and open-source model to generate the SELECT query. After QLoRa fine-tuning WizardLM's WizardCoder-15B model on the spider dataset, the execution accuracy for generated queries rose to a high of 61%. With the second approach, using the fine-tuned gpt-3.5-turbo-16k (Few-shot) + gpt-4-turbo (Zero-shot error correction), the execution accuracy reached a high of 82.1%. Of all the incorrect queries, most can be categorized into a seven different categories of what went wrong: selecting the wrong columns or wrong order of columns, grouping by the wrong column, predicting the wrong values in conditionals, using differ",
    "path": "papers/24/01/2401.12379.json",
    "total_tokens": 935,
    "translated_title": "分析大型语言模型在文本转SQL合成中的有效性",
    "translated_abstract": "本研究调查了使用大型语言模型（LLM）进行文本转SQL程序合成的各种方法，重点关注了产生的结果和洞察。使用流行的文本转SQL数据集spider，目标是输入自然语言问题和数据库模式，输出正确的SQL SELECT查询。最初的方法是对本地和开源模型进行微调，生成SELECT查询。在spider数据集上通过QLoRa微调WizardLM的WizardCoder-15B模型后，生成查询的执行准确率达到61%的高水平。通过第二种方法，使用微调的gpt-3.5-turbo-16k（Few-shot）+ gpt-4-turbo（Zero-shot错误修正），执行准确率达到82.1%的高水平。在所有错误的查询中，大部分可以分为七个不同的类别，说明了出错的原因：选择错误的列或列的顺序不正确，按错误的列进行分组，预测条件中的值错误，使用了不同的...",
    "tldr": "本论文研究了大型语言模型在文本转SQL合成中的有效性，通过对比两种方法，发现微调gpt-3.5-turbo-16k + gpt-4-turbo模型的执行准确率较高，达到82.1%。同时，对错误查询进行分类分析，找出错误的原因。",
    "en_tdlr": "This paper analyzes the effectiveness of large language models on text-to-SQL synthesis, comparing two approaches and finding that fine-tuning the gpt-3.5-turbo-16k + gpt-4-turbo model achieves a high execution accuracy of 82.1%. It also categorizes and analyzes the reasons for incorrect queries."
}