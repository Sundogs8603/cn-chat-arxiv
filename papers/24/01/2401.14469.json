{
    "title": "Unveiling the Unseen: Identifiable Clusters in Trained Depthwise Convolutional Kernels. (arXiv:2401.14469v1 [cs.LG])",
    "abstract": "Recent advances in depthwise-separable convolutional neural networks (DS-CNNs) have led to novel architectures, that surpass the performance of classical CNNs, by a considerable scalability and accuracy margin. This paper reveals another striking property of DS-CNN architectures: discernible and explainable patterns emerge in their trained depthwise convolutional kernels in all layers. Through an extensive analysis of millions of trained filters, with different sizes and from various models, we employed unsupervised clustering with autoencoders, to categorize these filters. Astonishingly, the patterns converged into a few main clusters, each resembling the difference of Gaussian (DoG) functions, and their first and second-order derivatives. Notably, we were able to classify over 95\\% and 90\\% of the filters from state-of-the-art ConvNextV2 and ConvNeXt models, respectively. This finding is not merely a technological curiosity; it echoes the foundational models neuroscientists have long",
    "link": "http://arxiv.org/abs/2401.14469",
    "context": "Title: Unveiling the Unseen: Identifiable Clusters in Trained Depthwise Convolutional Kernels. (arXiv:2401.14469v1 [cs.LG])\nAbstract: Recent advances in depthwise-separable convolutional neural networks (DS-CNNs) have led to novel architectures, that surpass the performance of classical CNNs, by a considerable scalability and accuracy margin. This paper reveals another striking property of DS-CNN architectures: discernible and explainable patterns emerge in their trained depthwise convolutional kernels in all layers. Through an extensive analysis of millions of trained filters, with different sizes and from various models, we employed unsupervised clustering with autoencoders, to categorize these filters. Astonishingly, the patterns converged into a few main clusters, each resembling the difference of Gaussian (DoG) functions, and their first and second-order derivatives. Notably, we were able to classify over 95\\% and 90\\% of the filters from state-of-the-art ConvNextV2 and ConvNeXt models, respectively. This finding is not merely a technological curiosity; it echoes the foundational models neuroscientists have long",
    "path": "papers/24/01/2401.14469.json",
    "total_tokens": 1048,
    "translated_title": "揭示看不见的：训练的深度可分离卷积核中的可识别聚类",
    "translated_abstract": "最近深度可分离卷积神经网络(DS-CNNs)的进展已经导致了新颖的架构，通过显着的可扩展性和准确性差距超越了经典CNNs的性能。本文揭示了DS-CNN架构的另一个引人注目的特性：在其所有层的训练深度卷积核中出现了可辨别和可解释的模式。通过对数百万个不同大小和来自各种模型的训练滤波器的广泛分析，我们使用自编码器的无监督聚类将这些滤波器分类。令人惊讶的是，这些模式收敛成几个主要的聚类，",
    "tldr": "本研究揭示了深度可分离卷积神经网络中训练的卷积核中出现的可辨别和可解释的模式，这些模式类似于高斯差分函数和它们的一阶和二阶导数。研究通过对数百万个训练滤波器进行无监督聚类，成功将最先进的模型中的大部分滤波器进行分类。",
    "en_tdlr": "This study reveals identifiable and explainable patterns in the trained convolutional kernels of depthwise-separable convolutional neural networks. These patterns resemble the difference of Gaussian functions and their derivatives. The study successfully classifies a significant portion of filters from state-of-the-art models through unsupervised clustering."
}