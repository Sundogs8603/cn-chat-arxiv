{
    "title": "Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks. (arXiv:2401.09665v1 [math.PR])",
    "abstract": "We study a family of distributed stochastic optimization algorithms where gradients are sampled by a token traversing a network of agents in random-walk fashion. Typically, these random-walks are chosen to be Markov chains that asymptotically sample from a desired target distribution, and play a critical role in the convergence of the optimization iterates. In this paper, we take a novel approach by replacing the standard linear Markovian token by one which follows a nonlinear Markov chain - namely the Self-Repellent Radom Walk (SRRW). Defined for any given 'base' Markov chain, the SRRW, parameterized by a positive scalar {\\alpha}, is less likely to transition to states that were highly visited in the past, thus the name. In the context of MCMC sampling on a graph, a recent breakthrough in Doshi et al. (2023) shows that the SRRW achieves O(1/{\\alpha}) decrease in the asymptotic variance for sampling. We propose the use of a 'generalized' version of the SRRW to drive token algorithms fo",
    "link": "http://arxiv.org/abs/2401.09665",
    "context": "Title: Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks. (arXiv:2401.09665v1 [math.PR])\nAbstract: We study a family of distributed stochastic optimization algorithms where gradients are sampled by a token traversing a network of agents in random-walk fashion. Typically, these random-walks are chosen to be Markov chains that asymptotically sample from a desired target distribution, and play a critical role in the convergence of the optimization iterates. In this paper, we take a novel approach by replacing the standard linear Markovian token by one which follows a nonlinear Markov chain - namely the Self-Repellent Radom Walk (SRRW). Defined for any given 'base' Markov chain, the SRRW, parameterized by a positive scalar {\\alpha}, is less likely to transition to states that were highly visited in the past, thus the name. In the context of MCMC sampling on a graph, a recent breakthrough in Doshi et al. (2023) shows that the SRRW achieves O(1/{\\alpha}) decrease in the asymptotic variance for sampling. We propose the use of a 'generalized' version of the SRRW to drive token algorithms fo",
    "path": "papers/24/01/2401.09665.json",
    "total_tokens": 966,
    "translated_title": "加速分布式随机优化的自排斥随机游走",
    "translated_abstract": "我们研究了一类分布式随机优化算法，其中梯度是由一个在代理网络中以随机游走方式移动的令牌采样得到的。通常情况下，这些随机游走被选择为渐近采样一个目标分布的马尔可夫链，在优化迭代的收敛中起着关键作用。本文采用一种新颖的方法，通过将标准线性马尔可夫令牌替换为遵循非线性马尔可夫链的令牌 - 即自排斥随机游走(SRRW)。对于任给的'base'马尔可夫链，由正标量{\\alpha}参数化的SRRW，在过去高访问的状态转移概率较低，因此得名。在图上的MCMC采样的背景下，Doshi等人(2023)的最新突破表明，SRRW在采样方面在渐近方差上达到了O(1/{\\alpha})的减小。我们提出了使用'generalized'版本的SRRW来驱动令牌算法。",
    "tldr": "本文研究了一种通过自排斥随机游走加速分布式随机优化的方法，该方法用非线性马尔可夫链取代传统的线性马尔可夫链，并在渐近方差方面取得了显著的改进。"
}