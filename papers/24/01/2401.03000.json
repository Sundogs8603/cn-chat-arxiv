{
    "title": "Bridging Modalities: Knowledge Distillation and Masked Training for Translating Multi-Modal Emotion Recognition to Uni-Modal, Speech-Only Emotion Recognition. (arXiv:2401.03000v1 [cs.SD])",
    "abstract": "This paper presents an innovative approach to address the challenges of translating multi-modal emotion recognition models to a more practical and resource-efficient uni-modal counterpart, specifically focusing on speech-only emotion recognition. Recognizing emotions from speech signals is a critical task with applications in human-computer interaction, affective computing, and mental health assessment. However, existing state-of-the-art models often rely on multi-modal inputs, incorporating information from multiple sources such as facial expressions and gestures, which may not be readily available or feasible in real-world scenarios. To tackle this issue, we propose a novel framework that leverages knowledge distillation and masked training techniques.",
    "link": "http://arxiv.org/abs/2401.03000",
    "context": "Title: Bridging Modalities: Knowledge Distillation and Masked Training for Translating Multi-Modal Emotion Recognition to Uni-Modal, Speech-Only Emotion Recognition. (arXiv:2401.03000v1 [cs.SD])\nAbstract: This paper presents an innovative approach to address the challenges of translating multi-modal emotion recognition models to a more practical and resource-efficient uni-modal counterpart, specifically focusing on speech-only emotion recognition. Recognizing emotions from speech signals is a critical task with applications in human-computer interaction, affective computing, and mental health assessment. However, existing state-of-the-art models often rely on multi-modal inputs, incorporating information from multiple sources such as facial expressions and gestures, which may not be readily available or feasible in real-world scenarios. To tackle this issue, we propose a novel framework that leverages knowledge distillation and masked training techniques.",
    "path": "papers/24/01/2401.03000.json",
    "total_tokens": 824,
    "translated_title": "跨模态连接：知识蒸馏和屏蔽训练用于将多模态情感识别转化为单模态、仅语音的情感识别",
    "translated_abstract": "本文提出了一种创新方法，以解决将多模态情感识别模型转化为更实用且资源高效的单模态情感识别模型的挑战，具体关注语音情感识别。从语音信号中识别情感是一项关键任务，应用于人机交互、情感计算和心理健康评估。然而，现有的最先进模型通常依赖于多模态输入，包括来自多个来源的信息，如面部表情和手势，在实际场景中可能不易获得或不可行。为了解决这个问题，我们提出了一种利用知识蒸馏和屏蔽训练技术的新框架。",
    "tldr": "本文介绍了一种创新方法，用于将多模态情感识别转化为更实用且资源高效的单模态、仅语音的情感识别。使用知识蒸馏和屏蔽训练技术来解决现有模型所依赖的多模态输入在实际应用中可能不可行的问题。"
}