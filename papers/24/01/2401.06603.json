{
    "title": "Mutual Enhancement of Large Language and Reinforcement Learning Models through Bi-Directional Feedback Mechanisms: A Case Study. (arXiv:2401.06603v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities for reinforcement learning (RL) models, such as planning and reasoning capabilities. However, the problems of LLMs and RL model collaboration still need to be solved. In this study, we employ a teacher-student learning framework to tackle these problems, specifically by offering feedback for LLMs using RL models and providing high-level information for RL models with LLMs in a cooperative multi-agent setting. Within this framework, the LLM acts as a teacher, while the RL model acts as a student. The two agents cooperatively assist each other through a process of recursive help, such as \"I help you help I help.\" The LLM agent supplies abstract information to the RL agent, enabling efficient exploration and policy improvement. In turn, the RL agent offers feedback to the LLM agent, providing valuable, real-time information that helps generate more useful tokens. This bi-directional feedback loop promotes optimization,",
    "link": "http://arxiv.org/abs/2401.06603",
    "context": "Title: Mutual Enhancement of Large Language and Reinforcement Learning Models through Bi-Directional Feedback Mechanisms: A Case Study. (arXiv:2401.06603v1 [cs.CL])\nAbstract: Large Language Models (LLMs) have demonstrated remarkable capabilities for reinforcement learning (RL) models, such as planning and reasoning capabilities. However, the problems of LLMs and RL model collaboration still need to be solved. In this study, we employ a teacher-student learning framework to tackle these problems, specifically by offering feedback for LLMs using RL models and providing high-level information for RL models with LLMs in a cooperative multi-agent setting. Within this framework, the LLM acts as a teacher, while the RL model acts as a student. The two agents cooperatively assist each other through a process of recursive help, such as \"I help you help I help.\" The LLM agent supplies abstract information to the RL agent, enabling efficient exploration and policy improvement. In turn, the RL agent offers feedback to the LLM agent, providing valuable, real-time information that helps generate more useful tokens. This bi-directional feedback loop promotes optimization,",
    "path": "papers/24/01/2401.06603.json",
    "total_tokens": 1032,
    "translated_title": "通过双向反馈机制增强大型语言模型和强化学习模型的相互合作：一个案例研究",
    "translated_abstract": "大型语言模型(LLMs)已经展示出对强化学习模型(如规划和推理能力)的显著能力，然而LLMs和强化学习模型之间的合作问题仍然需要解决。在这项研究中，我们采用了师生学习框架来解决这些问题，具体是通过使用强化学习模型提供LLMs反馈，并在合作的多智能体环境中使用LLMs为强化学习模型提供高级信息。在这个框架内，LLM扮演教师角色，而强化学习模型则扮演学生角色。这两个智能体通过递归互助的方式相互协助，如“我帮你帮我帮”等。LLM智能体向强化学习智能体提供抽象信息，实现有效的探索和策略改进。反过来，强化学习智能体向LLM智能体提供反馈，提供有价值的实时信息，帮助生成更有用的标记。这种双向反馈循环促进了优化。",
    "tldr": "通过双向反馈机制，这个研究探索了大型语言模型(LLMs)和强化学习模型的合作。LLM充当教师，强化学习模型充当学生，它们通过递归互助实现了相互协助。这种合作提供了高级信息和实时反馈，促进了优化。",
    "en_tdlr": "This study investigates the collaboration between Large Language Models (LLMs) and reinforcement learning models through a bi-directional feedback mechanism. LLMs act as teachers, providing high-level information to reinforcement learning models, while reinforcement learning models act as students, offering valuable real-time feedback. This cooperative approach promotes optimization and enhances the capabilities of both models."
}