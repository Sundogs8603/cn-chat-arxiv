{
    "title": "Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain. (arXiv:2401.16444v1 [cs.HC])",
    "abstract": "Existing game AI research mainly focuses on enhancing agents' abilities to win games, but this does not inherently make humans have a better experience when collaborating with these agents. For example, agents may dominate the collaboration and exhibit unintended or detrimental behaviors, leading to poor experiences for their human partners. In other words, most game AI agents are modeled in a \"self-centered\" manner. In this paper, we propose a \"human-centered\" modeling scheme for collaborative agents that aims to enhance the experience of humans. Specifically, we model the experience of humans as the goals they expect to achieve during the task. We expect that agents should learn to enhance the extent to which humans achieve these goals while maintaining agents' original abilities (e.g., winning games). To achieve this, we propose the Reinforcement Learning from Human Gain (RLHG) approach. The RLHG approach introduces a \"baseline\", which corresponds to the extent to which humans primi",
    "link": "http://arxiv.org/abs/2401.16444",
    "context": "Title: Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain. (arXiv:2401.16444v1 [cs.HC])\nAbstract: Existing game AI research mainly focuses on enhancing agents' abilities to win games, but this does not inherently make humans have a better experience when collaborating with these agents. For example, agents may dominate the collaboration and exhibit unintended or detrimental behaviors, leading to poor experiences for their human partners. In other words, most game AI agents are modeled in a \"self-centered\" manner. In this paper, we propose a \"human-centered\" modeling scheme for collaborative agents that aims to enhance the experience of humans. Specifically, we model the experience of humans as the goals they expect to achieve during the task. We expect that agents should learn to enhance the extent to which humans achieve these goals while maintaining agents' original abilities (e.g., winning games). To achieve this, we propose the Reinforcement Learning from Human Gain (RLHG) approach. The RLHG approach introduces a \"baseline\", which corresponds to the extent to which humans primi",
    "path": "papers/24/01/2401.16444.json",
    "total_tokens": 939,
    "translated_title": "提升人机协作中的人类体验：基于积极人类收益的以人为中心的建模方法",
    "translated_abstract": "现有的游戏人工智能研究主要集中在提升代理人在游戏中的能力，但这并不能本质上让人们在与这些代理人协作时拥有更好的体验。例如，代理人可能会控制协作并展示意外或有害的行为，导致人类合作伙伴的体验不佳。换句话说，大多数游戏人工智能代理人是以“自我为中心”建模的。在本文中，我们提出了一种“以人为中心”的协作代理人建模方案，旨在增强人类的体验。具体而言，我们将人类的体验建模为他们在任务期望达到的目标。我们期望代理人能够学会在保持其原始能力（如在游戏中获胜）的同时，增强人类实现这些目标的程度。为此，我们提出了基于人类收益的强化学习（RLHG）方法。RLHG方法引入了一个“基准”，对应于人类最初预期的程度。",
    "tldr": "本研究提出了一种以人为中心的协作代理人建模方法，旨在增强人类的体验。通过引入基于人类收益的强化学习方法，代理人可以在保持自身能力的同时，增强人类实现预期目标的程度。",
    "en_tdlr": "This study proposes a human-centered modeling approach for collaborative agents to enhance human experience. By introducing reinforcement learning based on human gain, agents can enhance the extent to which humans achieve their goals while maintaining their own abilities."
}