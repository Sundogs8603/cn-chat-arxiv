{
    "title": "VideoDrafter: Content-Consistent Multi-Scene Video Generation with LLM. (arXiv:2401.01256v1 [cs.CV])",
    "abstract": "The recent innovations and breakthroughs in diffusion models have significantly expanded the possibilities of generating high-quality videos for the given prompts. Most existing works tackle the single-scene scenario with only one video event occurring in a single background. Extending to generate multi-scene videos nevertheless is not trivial and necessitates to nicely manage the logic in between while preserving the consistent visual appearance of key content across video scenes. In this paper, we propose a novel framework, namely VideoDrafter, for content-consistent multi-scene video generation. Technically, VideoDrafter leverages Large Language Models (LLM) to convert the input prompt into comprehensive multi-scene script that benefits from the logical knowledge learnt by LLM. The script for each scene includes a prompt describing the event, the foreground/background entities, as well as camera movement. VideoDrafter identifies the common entities throughout the script and asks LLM",
    "link": "http://arxiv.org/abs/2401.01256",
    "context": "Title: VideoDrafter: Content-Consistent Multi-Scene Video Generation with LLM. (arXiv:2401.01256v1 [cs.CV])\nAbstract: The recent innovations and breakthroughs in diffusion models have significantly expanded the possibilities of generating high-quality videos for the given prompts. Most existing works tackle the single-scene scenario with only one video event occurring in a single background. Extending to generate multi-scene videos nevertheless is not trivial and necessitates to nicely manage the logic in between while preserving the consistent visual appearance of key content across video scenes. In this paper, we propose a novel framework, namely VideoDrafter, for content-consistent multi-scene video generation. Technically, VideoDrafter leverages Large Language Models (LLM) to convert the input prompt into comprehensive multi-scene script that benefits from the logical knowledge learnt by LLM. The script for each scene includes a prompt describing the event, the foreground/background entities, as well as camera movement. VideoDrafter identifies the common entities throughout the script and asks LLM",
    "path": "papers/24/01/2401.01256.json",
    "total_tokens": 864,
    "translated_title": "VideoDrafter: 利用LLM实现内容一致的多场景视频生成",
    "translated_abstract": "最近扩展模型的创新和突破显著扩大了根据给定提示生成高质量视频的可能性。现有的大多数作品仅处理在单个背景中发生单个视频事件的单场景情况。然而，扩展到生成多场景视频并且在保持各个场景之间的逻辑一致同时保持视觉外观一致性方面并不简单。在本文中，我们提出了一种新颖的框架，即VideoDrafter，用于内容一致的多场景视频生成。技术上，VideoDrafter利用大型语言模型（LLM）将输入提示转化为综合的多场景脚本，该脚本从LLM学到的逻辑知识中受益。每个场景的脚本包括描述事件、前景/背景实体以及摄像机运动的提示。VideoDrafter识别脚本中的共同实体，并询问LLM来选择生成逻辑连贯的视频场景。",
    "tldr": "VideoDrafter是一个利用LLM实现内容一致的多场景视频生成的框架，能够根据输入提示生成逻辑连贯的多场景脚本，并生成高质量的视频。"
}