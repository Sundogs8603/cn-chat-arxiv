{
    "title": "Instruct-Imagen: Image Generation with Multi-modal Instruction. (arXiv:2401.01952v1 [cs.CV])",
    "abstract": "This paper presents instruct-imagen, a model that tackles heterogeneous image generation tasks and generalizes across unseen tasks. We introduce *multi-modal instruction* for image generation, a task representation articulating a range of generation intents with precision. It uses natural language to amalgamate disparate modalities (e.g., text, edge, style, subject, etc.), such that abundant generation intents can be standardized in a uniform format.  We then build instruct-imagen by fine-tuning a pre-trained text-to-image diffusion model with a two-stage framework. First, we adapt the model using the retrieval-augmented training, to enhance model's capabilities to ground its generation on external multimodal context. Subsequently, we fine-tune the adapted model on diverse image generation tasks that requires vision-language understanding (e.g., subject-driven generation, etc.), each paired with a multi-modal instruction encapsulating the task's essence. Human evaluation on various ima",
    "link": "http://arxiv.org/abs/2401.01952",
    "context": "Title: Instruct-Imagen: Image Generation with Multi-modal Instruction. (arXiv:2401.01952v1 [cs.CV])\nAbstract: This paper presents instruct-imagen, a model that tackles heterogeneous image generation tasks and generalizes across unseen tasks. We introduce *multi-modal instruction* for image generation, a task representation articulating a range of generation intents with precision. It uses natural language to amalgamate disparate modalities (e.g., text, edge, style, subject, etc.), such that abundant generation intents can be standardized in a uniform format.  We then build instruct-imagen by fine-tuning a pre-trained text-to-image diffusion model with a two-stage framework. First, we adapt the model using the retrieval-augmented training, to enhance model's capabilities to ground its generation on external multimodal context. Subsequently, we fine-tune the adapted model on diverse image generation tasks that requires vision-language understanding (e.g., subject-driven generation, etc.), each paired with a multi-modal instruction encapsulating the task's essence. Human evaluation on various ima",
    "path": "papers/24/01/2401.01952.json",
    "total_tokens": 939,
    "translated_title": "Instruct-Imagen: 带有多模式指令的图像生成",
    "translated_abstract": "本文提出了Instruct-Imagen，这是一种处理异构图像生成任务并在未见任务中进行泛化的模型。我们引入了多模式指令用于图像生成，这是一种任务表示方法，可以精确地表达各种生成意图。它使用自然语言来整合不同的模态（例如文本、边缘、风格、主题等），使得丰富的生成意图能够以统一的格式标准化。然后，我们通过微调预训练的文本到图像扩散模型构建了Instruct-Imagen的两阶段框架。首先，我们使用检索增强的训练来使模型能够在外部多模态环境下基于其生成。然后，我们在需要视觉-语言理解的多样化图像生成任务中对这个调整后的模型进行微调，每个任务都配对一个包含任务本质的多模式指令。对各种图像生成任务的人工评估表明，",
    "tldr": "Instruct-Imagen是一种处理异构图像生成任务并进行泛化的模型，引入了多模式指令以实现各种生成意图的统一标准化。通过微调预训练的文本到图像扩散模型，并使用检索增强的训练提升模型在外部多模态环境下的生成能力。对多样化图像生成任务的人工评估表明，该模型取得了良好的效果。"
}