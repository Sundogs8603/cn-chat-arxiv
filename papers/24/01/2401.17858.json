{
    "title": "Probing Language Models' Gesture Understanding for Enhanced Human-AI Interaction",
    "abstract": "The rise of Large Language Models (LLMs) has affected various disciplines that got beyond mere text generation. Going beyond their textual nature, this project proposal aims to investigate the interaction between LLMs and non-verbal communication, specifically focusing on gestures. The proposal sets out a plan to examine the proficiency of LLMs in deciphering both explicit and implicit non-verbal cues within textual prompts and their ability to associate these gestures with various contextual factors. The research proposes to test established psycholinguistic study designs to construct a comprehensive dataset that pairs textual prompts with detailed gesture descriptions, encompassing diverse regional variations, and semantic labels. To assess LLMs' comprehension of gestures, experiments are planned, evaluating their ability to simulate human behaviour in order to replicate psycholinguistic experiments. These experiments consider cultural dimensions and measure the agreement between LLM",
    "link": "https://arxiv.org/abs/2401.17858",
    "context": "Title: Probing Language Models' Gesture Understanding for Enhanced Human-AI Interaction\nAbstract: The rise of Large Language Models (LLMs) has affected various disciplines that got beyond mere text generation. Going beyond their textual nature, this project proposal aims to investigate the interaction between LLMs and non-verbal communication, specifically focusing on gestures. The proposal sets out a plan to examine the proficiency of LLMs in deciphering both explicit and implicit non-verbal cues within textual prompts and their ability to associate these gestures with various contextual factors. The research proposes to test established psycholinguistic study designs to construct a comprehensive dataset that pairs textual prompts with detailed gesture descriptions, encompassing diverse regional variations, and semantic labels. To assess LLMs' comprehension of gestures, experiments are planned, evaluating their ability to simulate human behaviour in order to replicate psycholinguistic experiments. These experiments consider cultural dimensions and measure the agreement between LLM",
    "path": "papers/24/01/2401.17858.json",
    "total_tokens": 901,
    "translated_title": "探索语言模型对增强人机交互的手势理解",
    "translated_abstract": "大型语言模型（LLM）的崛起已经影响到超越纯文本生成的各个学科。本项目提出超越纯文本性质，探究LLM与非语言交流，特别关注手势之间的互动。该项目计划研究LLM在解析文字提示中的明示和隐含非语言暗示的能力，以及它们将这些手势与各种语境因素联系起来的能力。研究计划测试已建立的心理语言学研究设计，构建一个全面的数据集，将文字提示与详细的手势描述相配对，涵盖各种区域变异和语义标签。为了评估LLMs对手势的理解能力，计划进行一系列实验，评估它们模拟人类行为的能力，以重现心理语言学实验。这些实验考虑到文化维度，并测量LLM和人类之间的一致性。",
    "tldr": "该项目旨在探究语言模型对非语言交流中的手势理解，通过测试LLMs对明示和隐含非语言暗示的能力以及与语境因素的关联。实验将使用心理语言学设计和全面的数据集进行，同时考虑文化维度，并测量LLM和人类之间的一致性。",
    "en_tdlr": "This project aims to explore language models' understanding of non-verbal communication through gestures by testing their ability to decipher explicit and implicit non-verbal cues and associate them with contextual factors. The experiments will be conducted using psycholinguistic designs and a comprehensive dataset, taking cultural dimensions into account and measuring agreement between language models and humans."
}