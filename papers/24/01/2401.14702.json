{
    "title": "FairSample: Training Fair and Accurate Graph Convolutional Neural Networks Efficiently. (arXiv:2401.14702v1 [cs.LG])",
    "abstract": "Fairness in Graph Convolutional Neural Networks (GCNs) becomes a more and more important concern as GCNs are adopted in many crucial applications. Societal biases against sensitive groups may exist in many real world graphs. GCNs trained on those graphs may be vulnerable to being affected by such biases. In this paper, we adopt the well-known fairness notion of demographic parity and tackle the challenge of training fair and accurate GCNs efficiently. We present an in-depth analysis on how graph structure bias, node attribute bias, and model parameters may affect the demographic parity of GCNs. Our insights lead to FairSample, a framework that jointly mitigates the three types of biases. We employ two intuitive strategies to rectify graph structures. First, we inject edges across nodes that are in different sensitive groups but similar in node features. Second, to enhance model fairness and retain model quality, we develop a learnable neighbor sampling policy using reinforcement learni",
    "link": "http://arxiv.org/abs/2401.14702",
    "context": "Title: FairSample: Training Fair and Accurate Graph Convolutional Neural Networks Efficiently. (arXiv:2401.14702v1 [cs.LG])\nAbstract: Fairness in Graph Convolutional Neural Networks (GCNs) becomes a more and more important concern as GCNs are adopted in many crucial applications. Societal biases against sensitive groups may exist in many real world graphs. GCNs trained on those graphs may be vulnerable to being affected by such biases. In this paper, we adopt the well-known fairness notion of demographic parity and tackle the challenge of training fair and accurate GCNs efficiently. We present an in-depth analysis on how graph structure bias, node attribute bias, and model parameters may affect the demographic parity of GCNs. Our insights lead to FairSample, a framework that jointly mitigates the three types of biases. We employ two intuitive strategies to rectify graph structures. First, we inject edges across nodes that are in different sensitive groups but similar in node features. Second, to enhance model fairness and retain model quality, we develop a learnable neighbor sampling policy using reinforcement learni",
    "path": "papers/24/01/2401.14702.json",
    "total_tokens": 994,
    "translated_title": "FairSample: 高效训练公平准确的图卷积神经网络",
    "translated_abstract": "随着图卷积神经网络在许多关键应用中的应用，图卷积神经网络中的公平性越来越成为一个重要问题。许多真实世界的图中存在对敏感群体的社会偏见。在这篇论文中，我们采用了公平性的经典概念“人口统计平均值”，并解决了高效训练公平准确的图卷积神经网络的挑战。我们对图结构偏见、节点属性偏见和模型参数对图卷积神经网络的人口统计平均性能的影响进行了深入分析。我们的洞察力导致了FairSample，一个可以同时减轻这三种偏见的框架。我们采用了两种直观的策略来纠正图结构。首先，我们在不同敏感群体但具有相似节点特征的节点之间插入边。其次，为了增强模型的公平性并保持模型的质量，我们使用强化学习方法开发了一种可学习的邻居采样策略。",
    "tldr": "本文提出了一种名为FairSample的框架，旨在高效训练公平准确的图卷积神经网络。该框架通过对图结构进行纠正，并使用可学习的邻居采样策略来同时减轻图卷积神经网络中的图结构偏见、节点属性偏见和模型参数偏见。",
    "en_tdlr": "This paper introduces a framework called FairSample, aiming to train fair and accurate graph convolutional neural networks efficiently. It addresses the challenge of mitigating bias caused by graph structure, node attributes, and model parameters. The framework rectifies the graph structure and utilizes a learnable neighbor sampling strategy to promote fairness and retain model quality."
}