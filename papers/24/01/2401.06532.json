{
    "title": "INTERS: Unlocking the Power of Large Language Models in Search with Instruction Tuning. (arXiv:2401.06532v1 [cs.CL])",
    "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in various natural language processing tasks. Despite this, their application to information retrieval (IR) tasks is still challenging due to the infrequent occurrence of many IR-specific concepts in natural language. While prompt-based methods can provide task descriptions to LLMs, they often fall short in facilitating comprehensive understanding and execution of IR tasks, thereby limiting LLMs' applicability. To address this gap, in this work, we explore the potential of instruction tuning to enhance LLMs' proficiency in IR tasks. We introduce a novel instruction tuning dataset, INTERS, encompassing 21 tasks across three fundamental IR categories: query understanding, document understanding, and query-document relationship understanding. The data are derived from 43 distinct datasets with manually written templates. Our empirical results reveal that INTERS significantly boosts the performance of various publicly a",
    "link": "http://arxiv.org/abs/2401.06532",
    "context": "Title: INTERS: Unlocking the Power of Large Language Models in Search with Instruction Tuning. (arXiv:2401.06532v1 [cs.CL])\nAbstract: Large language models (LLMs) have demonstrated impressive capabilities in various natural language processing tasks. Despite this, their application to information retrieval (IR) tasks is still challenging due to the infrequent occurrence of many IR-specific concepts in natural language. While prompt-based methods can provide task descriptions to LLMs, they often fall short in facilitating comprehensive understanding and execution of IR tasks, thereby limiting LLMs' applicability. To address this gap, in this work, we explore the potential of instruction tuning to enhance LLMs' proficiency in IR tasks. We introduce a novel instruction tuning dataset, INTERS, encompassing 21 tasks across three fundamental IR categories: query understanding, document understanding, and query-document relationship understanding. The data are derived from 43 distinct datasets with manually written templates. Our empirical results reveal that INTERS significantly boosts the performance of various publicly a",
    "path": "papers/24/01/2401.06532.json",
    "total_tokens": 896,
    "translated_title": "INTERS: 使用指令调优解锁大型语言模型在搜索中的力量",
    "translated_abstract": "大型语言模型（LLMs）在各种自然语言处理任务中展示了令人印象深刻的能力。然而，由于许多与信息检索（IR）具体概念的不经常出现在自然语言中，它们在信息检索任务中的应用仍然具有挑战性。虽然基于提示的方法可以向LLMs提供任务描述，但它们往往在促进全面理解和执行IR任务方面存在不足，从而限制了LLMs的适用性。为了弥补这一差距，本研究探索了指令调优的潜力，以提高LLMs在IR任务中的熟练程度。我们引入了一个新的指令调优数据集INTERS，涵盖了3个基本IR类别中的21个任务：查询理解、文档理解和查询文档关系理解。数据来自43个不同的由手动编写的模板构成的数据集。我们的实证结果表明，INTERS显著提升了各种公开数据集上的性能。",
    "tldr": "本研究探索了指令调优的方法，以增强大型语言模型在信息检索任务中的能力，通过引入一个新的指令调优数据集INTERS，涵盖了21个IR任务，该方法显著提升了性能。"
}