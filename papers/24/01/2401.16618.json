{
    "title": "A comparison of RL-based and PID controllers for 6-DOF swimming robots: hybrid underwater object tracking. (arXiv:2401.16618v1 [cs.RO])",
    "abstract": "In this paper, we present an exploration and assessment of employing a centralized deep Q-network (DQN) controller as a substitute for the prevalent use of PID controllers in the context of 6DOF swimming robots. Our primary focus centers on illustrating this transition with the specific case of underwater object tracking. DQN offers advantages such as data efficiency and off-policy learning, while remaining simpler to implement than other reinforcement learning methods. Given the absence of a dynamic model for our robot, we propose an RL agent to control this multi-input-multi-output (MIMO) system, where a centralized controller may offer more robust control than distinct PIDs. Our approach involves initially using classical controllers for safe exploration, then gradually shifting to DQN to take full control of the robot.  We divide the underwater tracking task into vision and control modules. We use established methods for vision-based tracking and introduce a centralized DQN control",
    "link": "http://arxiv.org/abs/2401.16618",
    "context": "Title: A comparison of RL-based and PID controllers for 6-DOF swimming robots: hybrid underwater object tracking. (arXiv:2401.16618v1 [cs.RO])\nAbstract: In this paper, we present an exploration and assessment of employing a centralized deep Q-network (DQN) controller as a substitute for the prevalent use of PID controllers in the context of 6DOF swimming robots. Our primary focus centers on illustrating this transition with the specific case of underwater object tracking. DQN offers advantages such as data efficiency and off-policy learning, while remaining simpler to implement than other reinforcement learning methods. Given the absence of a dynamic model for our robot, we propose an RL agent to control this multi-input-multi-output (MIMO) system, where a centralized controller may offer more robust control than distinct PIDs. Our approach involves initially using classical controllers for safe exploration, then gradually shifting to DQN to take full control of the robot.  We divide the underwater tracking task into vision and control modules. We use established methods for vision-based tracking and introduce a centralized DQN control",
    "path": "papers/24/01/2401.16618.json",
    "total_tokens": 950,
    "translated_title": "基于RL和PID控制器的六自由度游泳机器人的比较：混合水下目标跟踪",
    "translated_abstract": "本文在六自由度游泳机器人的背景下，探讨和评估了使用中央深度Q网络（DQN）控制器来代替常用的PID控制器的可能性。我们主要将重点放在水下目标跟踪这一具体案例上，DQN具有数据效率和离策略学习的优势，同时比其他强化学习方法更容易实现。考虑到我们的机器人没有动力学模型，我们提出了一个RL代理来控制这个多输入多输出（MIMO）系统，在这种情况下，中心控制器可能比独立的PID控制器提供更强健的控制。我们的方法涉及使用经典控制器进行安全探索，然后逐渐转向DQN来完全掌控机器人。我们将水下跟踪任务分为视觉和控制模块，使用了已建立的基于视觉的跟踪方法，并引入了一个中心DQN控制器。",
    "tldr": "本文比较了基于RL和PID控制器的六自由度游泳机器人，重点研究了水下目标跟踪。使用中央深度Q网络（DQN）控制器代替PID控制器在数据效率和离策略学习方面具有优势，并且较易实现。在没有动力学模型的情况下，我们提出了一个RL代理来控制多输入多输出的系统，中心控制器可能比独立的PID控制器提供更强健的控制。"
}