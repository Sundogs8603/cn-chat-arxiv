{
    "title": "High-precision Voice Search Query Correction via Retrievable Speech-text Embedings. (arXiv:2401.04235v1 [cs.CL])",
    "abstract": "Automatic speech recognition (ASR) systems can suffer from poor recall for various reasons, such as noisy audio, lack of sufficient training data, etc.  Previous work has shown that recall can be improved by retrieving rewrite candidates from a large database of likely, contextually-relevant alternatives to the hypothesis text using nearest-neighbors search over embeddings of the ASR hypothesis text to correct and candidate corrections.  However, ASR-hypothesis-based retrieval can yield poor precision if the textual hypotheses are too phonetically dissimilar to the transcript truth. In this paper, we eliminate the hypothesis-audio mismatch problem by querying the correction database directly using embeddings derived from the utterance audio; the embeddings of the utterance audio and candidate corrections are produced by multimodal speech-text embedding networks trained to place the embedding of the audio of an utterance and the embedding of its corresponding textual transcript close to",
    "link": "http://arxiv.org/abs/2401.04235",
    "context": "Title: High-precision Voice Search Query Correction via Retrievable Speech-text Embedings. (arXiv:2401.04235v1 [cs.CL])\nAbstract: Automatic speech recognition (ASR) systems can suffer from poor recall for various reasons, such as noisy audio, lack of sufficient training data, etc.  Previous work has shown that recall can be improved by retrieving rewrite candidates from a large database of likely, contextually-relevant alternatives to the hypothesis text using nearest-neighbors search over embeddings of the ASR hypothesis text to correct and candidate corrections.  However, ASR-hypothesis-based retrieval can yield poor precision if the textual hypotheses are too phonetically dissimilar to the transcript truth. In this paper, we eliminate the hypothesis-audio mismatch problem by querying the correction database directly using embeddings derived from the utterance audio; the embeddings of the utterance audio and candidate corrections are produced by multimodal speech-text embedding networks trained to place the embedding of the audio of an utterance and the embedding of its corresponding textual transcript close to",
    "path": "papers/24/01/2401.04235.json",
    "total_tokens": 875,
    "translated_title": "高精度语音搜索查询纠错的可检索语音文本嵌入",
    "translated_abstract": "自动语音识别(ASR)系统可能因为各种原因而导致召回率较低，例如嘈杂的音频、缺乏足够的训练数据等。先前的研究表明，可以通过使用ASR假设文本的嵌入进行最近邻搜索，从大型数据库中检索与上下文相关的可能候选项来改进召回率并纠正候选纠正。然而，如果文本假设与转录的真实文本在语音上差异太大，基于ASR假设的检索可能会导致精度较低。在本文中，我们通过直接使用由话语音频产生的嵌入来查询纠正数据库，消除了假设和音频不匹配的问题；话语音频和候选纠正的嵌入是由多模式语音文本嵌入网络训练产生的，目的是将话语音频的嵌入和其相应的文本转录的嵌入放置在靠近的位置。",
    "tldr": "本文提出了一种通过使用可检索的语音文本嵌入进行高精度语音搜索查询纠错的方法，消除了语音识别系统中的假设-音频不匹配问题，并提高了纠错的准确性。"
}