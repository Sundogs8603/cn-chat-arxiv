{
    "title": "Do We Really Even Need Data?. (arXiv:2401.08702v1 [stat.ME])",
    "abstract": "As artificial intelligence and machine learning tools become more accessible, and scientists face new obstacles to data collection (e.g. rising costs, declining survey response rates), researchers increasingly use predictions from pre-trained algorithms as outcome variables. Though appealing for financial and logistical reasons, using standard tools for inference can misrepresent the association between independent variables and the outcome of interest when the true, unobserved outcome is replaced by a predicted value. In this paper, we characterize the statistical challenges inherent to this so-called ``post-prediction inference'' problem and elucidate three potential sources of error: (i) the relationship between predicted outcomes and their true, unobserved counterparts, (ii) robustness of the machine learning model to resampling or uncertainty about the training data, and (iii) appropriately propagating not just bias but also uncertainty from predictions into the ultimate inference",
    "link": "http://arxiv.org/abs/2401.08702",
    "context": "Title: Do We Really Even Need Data?. (arXiv:2401.08702v1 [stat.ME])\nAbstract: As artificial intelligence and machine learning tools become more accessible, and scientists face new obstacles to data collection (e.g. rising costs, declining survey response rates), researchers increasingly use predictions from pre-trained algorithms as outcome variables. Though appealing for financial and logistical reasons, using standard tools for inference can misrepresent the association between independent variables and the outcome of interest when the true, unobserved outcome is replaced by a predicted value. In this paper, we characterize the statistical challenges inherent to this so-called ``post-prediction inference'' problem and elucidate three potential sources of error: (i) the relationship between predicted outcomes and their true, unobserved counterparts, (ii) robustness of the machine learning model to resampling or uncertainty about the training data, and (iii) appropriately propagating not just bias but also uncertainty from predictions into the ultimate inference",
    "path": "papers/24/01/2401.08702.json",
    "total_tokens": 781,
    "translated_title": "我们真的需要数据吗？",
    "translated_abstract": "随着人工智能和机器学习工具的普及，科学家在数据收集方面面临着新的障碍（例如成本上升、调查响应率下降），研究人员越来越多地使用预训练算法的预测作为因变量。虽然从财务和后勤的角度来看这样做具有吸引力，但使用标准的推论工具可能会在替换真实的未观察到的结果值时误代表自变量与所关心的结果之间的联系。本文对这种所谓“后预测推断”问题的统计挑战进行了表征，并阐明了可能存在的三个错误来源：（i）预测结果与其真实未观察到的对应物之间的关系，（ii）机器学习模型对重新采样或对训练数据的不确定性的鲁棒性，以及（iii）适当地将预测结果的偏差和不确定性传播到最终的推断中。",
    "tldr": "本文探讨了使用预训练算法的预测作为因变量的统计挑战，并着重阐述了三个可能的错误来源。"
}