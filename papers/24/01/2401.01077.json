{
    "title": "Constrained Online Two-stage Stochastic Optimization: Algorithm with (and without) Predictions. (arXiv:2401.01077v1 [cs.LG])",
    "abstract": "We consider an online two-stage stochastic optimization with long-term constraints over a finite horizon of $T$ periods. At each period, we take the first-stage action, observe a model parameter realization and then take the second-stage action from a feasible set that depends both on the first-stage decision and the model parameter. We aim to minimize the cumulative objective value while guaranteeing that the long-term average second-stage decision belongs to a set. We develop online algorithms for the online two-stage problem from adversarial learning algorithms. Also, the regret bound of our algorithm can be reduced to the regret bound of embedded adversarial learning algorithms. Based on this framework, we obtain new results under various settings. When the model parameters are drawn from unknown non-stationary distributions and we are given machine-learned predictions of the distributions, we develop a new algorithm from our framework with a regret $O(W_T+\\sqrt{T})$, where $W_T$ m",
    "link": "http://arxiv.org/abs/2401.01077",
    "context": "Title: Constrained Online Two-stage Stochastic Optimization: Algorithm with (and without) Predictions. (arXiv:2401.01077v1 [cs.LG])\nAbstract: We consider an online two-stage stochastic optimization with long-term constraints over a finite horizon of $T$ periods. At each period, we take the first-stage action, observe a model parameter realization and then take the second-stage action from a feasible set that depends both on the first-stage decision and the model parameter. We aim to minimize the cumulative objective value while guaranteeing that the long-term average second-stage decision belongs to a set. We develop online algorithms for the online two-stage problem from adversarial learning algorithms. Also, the regret bound of our algorithm can be reduced to the regret bound of embedded adversarial learning algorithms. Based on this framework, we obtain new results under various settings. When the model parameters are drawn from unknown non-stationary distributions and we are given machine-learned predictions of the distributions, we develop a new algorithm from our framework with a regret $O(W_T+\\sqrt{T})$, where $W_T$ m",
    "path": "papers/24/01/2401.01077.json",
    "total_tokens": 953,
    "translated_title": "受约束的在线两阶段随机优化：具有（和不具有）预测的算法",
    "translated_abstract": "我们考虑了在有限时间段的T个期间内具有长期约束的在线两阶段随机优化问题。在每个期间，我们首先采取第一阶段的行动，然后观察模型参数的实现，并在可行集上采取第二阶段的行动，可行集同时依赖于第一阶段决策和模型参数。我们的目标是最小化累积目标值，同时保证长期平均的第二阶段决策属于一个集合。我们从对抗性学习算法中开发了在线算法来解决在线两阶段问题。此外，我们算法的遗憾边界可以转化为嵌入对抗性学习算法的遗憾边界。基于此框架，我们在不同的设置下获得了新的结果。当模型参数来自未知的非平稳分布且给定了对分布进行机器学习的预测时，我们从我们的框架中开发了一种新的算法，其遗憾边界为O（WT+√T），其中WT为...",
    "tldr": "这项研究考虑了在线两阶段随机优化问题，采用对抗性学习算法开发了在线算法。当模型参数来自未知的非平稳分布且给定了机器学习的预测时，提出的算法具有较低的遗憾边界。"
}