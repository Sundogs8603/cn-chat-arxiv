{
    "title": "CascadedGaze: Efficiency in Global Context Extraction for Image Restoration. (arXiv:2401.15235v1 [eess.IV])",
    "abstract": "Image restoration tasks traditionally rely on convolutional neural networks. However, given the local nature of the convolutional operator, they struggle to capture global information. The promise of attention mechanisms in Transformers is to circumvent this problem, but it comes at the cost of intensive computational overhead. Many recent studies in image restoration have focused on solving the challenge of balancing performance and computational cost via Transformer variants. In this paper, we present CascadedGaze Network (CGNet), an encoder-decoder architecture that employs Global Context Extractor (GCE), a novel and efficient way to capture global information for image restoration. The GCE module leverages small kernels across convolutional layers to learn global dependencies, without requiring self-attention. Extensive experimental results show that our approach outperforms a range of state-of-the-art methods on denoising benchmark datasets including both real image denoising and ",
    "link": "http://arxiv.org/abs/2401.15235",
    "context": "Title: CascadedGaze: Efficiency in Global Context Extraction for Image Restoration. (arXiv:2401.15235v1 [eess.IV])\nAbstract: Image restoration tasks traditionally rely on convolutional neural networks. However, given the local nature of the convolutional operator, they struggle to capture global information. The promise of attention mechanisms in Transformers is to circumvent this problem, but it comes at the cost of intensive computational overhead. Many recent studies in image restoration have focused on solving the challenge of balancing performance and computational cost via Transformer variants. In this paper, we present CascadedGaze Network (CGNet), an encoder-decoder architecture that employs Global Context Extractor (GCE), a novel and efficient way to capture global information for image restoration. The GCE module leverages small kernels across convolutional layers to learn global dependencies, without requiring self-attention. Extensive experimental results show that our approach outperforms a range of state-of-the-art methods on denoising benchmark datasets including both real image denoising and ",
    "path": "papers/24/01/2401.15235.json",
    "total_tokens": 972,
    "translated_title": "CascadedGaze: 图像恢复中的全局上下文提取的高效方法",
    "translated_abstract": "传统的图像恢复任务依赖于卷积神经网络。然而，由于卷积运算符的局部性质，它们很难捕捉到全局信息。Transformer中的注意力机制的优势在于解决了这个问题，但却需要大量的计算资源。最近的一些图像恢复研究集中在通过变种Transformer解决性能和计算成本之间的平衡挑战。在本文中，我们提出了CascadedGaze网络（CGNet），它是一种编码器-解码器架构，采用了全局上下文提取器（GCE），一种新颖且高效的图像恢复全局信息的方法。GCE模块通过在卷积层之间使用小的卷积核来学习全局依赖关系，而无需自注意力机制。广泛的实验结果表明，我们的方法在去噪基准数据集上（包括真实图像去噪和）的性能优于许多最先进的方法。",
    "tldr": "本文提出了一种名为CascadedGaze的网络架构，使用了一种新颖而高效的全局上下文提取方法，以解决图像恢复中全局信息的问题。通过在卷积层之间引入小的卷积核，该方法可以学习到全局的依赖关系，而无需使用自注意力机制。实验结果表明，该方法在多种图像去噪任务上优于其他先进方法。",
    "en_tdlr": "This paper proposes a network architecture called CascadedGaze, which uses a novel and efficient method for extracting global context in image restoration. By introducing small convolutional kernels between convolutional layers, the method learns global dependencies without the need for self-attention mechanisms. Experimental results demonstrate that the approach outperforms other state-of-the-art methods in various image denoising tasks."
}