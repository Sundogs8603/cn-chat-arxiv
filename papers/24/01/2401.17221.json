{
    "title": "MouSi: Poly-Visual-Expert Vision-Language Models",
    "abstract": "Current large vision-language models (VLMs) often encounter challenges such as insufficient capabilities of a single visual component and excessively long visual tokens. These issues can limit the model's effectiveness in accurately interpreting complex visual information and over-lengthy contextual information. Addressing these challenges is crucial for enhancing the performance and applicability of VLMs. This paper proposes the use of ensemble experts technique to synergizes the capabilities of individual visual encoders, including those skilled in image-text matching, OCR, image segmentation, etc. This technique introduces a fusion network to unify the processing of outputs from different visual experts, while bridging the gap between image encoders and pre-trained LLMs. In addition, we explore different positional encoding schemes to alleviate the waste of positional encoding caused by lengthy image feature sequences, effectively addressing the issue of position overflow and length",
    "link": "https://arxiv.org/abs/2401.17221",
    "context": "Title: MouSi: Poly-Visual-Expert Vision-Language Models\nAbstract: Current large vision-language models (VLMs) often encounter challenges such as insufficient capabilities of a single visual component and excessively long visual tokens. These issues can limit the model's effectiveness in accurately interpreting complex visual information and over-lengthy contextual information. Addressing these challenges is crucial for enhancing the performance and applicability of VLMs. This paper proposes the use of ensemble experts technique to synergizes the capabilities of individual visual encoders, including those skilled in image-text matching, OCR, image segmentation, etc. This technique introduces a fusion network to unify the processing of outputs from different visual experts, while bridging the gap between image encoders and pre-trained LLMs. In addition, we explore different positional encoding schemes to alleviate the waste of positional encoding caused by lengthy image feature sequences, effectively addressing the issue of position overflow and length",
    "path": "papers/24/01/2401.17221.json",
    "total_tokens": 857,
    "translated_title": "MouSi：多视觉专家视觉语言模型",
    "translated_abstract": "当前的大型视觉语言模型（VLMs）常常面临诸如单一视觉组件能力不足和过长的视觉标记等挑战。这些问题可能限制模型在准确解读复杂视觉信息和过长上下文信息方面的有效性。解决这些挑战对于提高VLMs的性能和适用性至关重要。本文提出了使用集成专家技术来协同单独的视觉编码器的能力，包括擅长图像文本匹配、OCR、图像分割等。该技术引入了融合网络，统一处理来自不同视觉专家的输出，同时弥合了图像编码器和预训练LLMs之间的差距。此外，我们还探索了不同的位置编码方案，以减轻长序列图像特征的位置编码浪费问题，有效解决了位置溢出和长度问题。",
    "tldr": "本文提出了MouSi模型，使用多视觉专家的集成技术来协同处理图像的视觉信息，解决了单一视觉组件能力不足和过长的视觉标记的问题。同时，通过探索不同的位置编码方案，有效解决了位置溢出和长度问题。",
    "en_tdlr": "This paper proposes the MouSi model that utilizes ensemble experts technique to synergize the capabilities of individual visual encoders and addresses challenges such as insufficient capabilities of a single visual component and excessively long visual tokens. It also explores different positional encoding schemes to effectively address the issue of position overflow and length."
}