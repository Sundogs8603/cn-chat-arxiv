{
    "title": "Text Classification Based on Knowledge Graphs and Improved Attention Mechanism. (arXiv:2401.03591v2 [cs.CL] UPDATED)",
    "abstract": "To resolve the semantic ambiguity in texts, we propose a model, which innovatively combines a knowledge graph with an improved attention mechanism. An existing knowledge base is utilized to enrich the text with relevant contextual concepts. The model operates at both character and word levels to deepen its understanding by integrating the concepts. We first adopt information gain to select import words. Then an encoder-decoder framework is used to encode the text along with the related concepts. The local attention mechanism adjusts the weight of each concept, reducing the influence of irrelevant or noisy concepts during classification. We improve the calculation formula for attention scores in the local self-attention mechanism, ensuring that words with different frequencies of occurrence in the text receive higher attention scores. Finally, the model employs a Bi-directional Gated Recurrent Unit (Bi-GRU), which is effective in feature extraction from texts for improved classification",
    "link": "http://arxiv.org/abs/2401.03591",
    "context": "Title: Text Classification Based on Knowledge Graphs and Improved Attention Mechanism. (arXiv:2401.03591v2 [cs.CL] UPDATED)\nAbstract: To resolve the semantic ambiguity in texts, we propose a model, which innovatively combines a knowledge graph with an improved attention mechanism. An existing knowledge base is utilized to enrich the text with relevant contextual concepts. The model operates at both character and word levels to deepen its understanding by integrating the concepts. We first adopt information gain to select import words. Then an encoder-decoder framework is used to encode the text along with the related concepts. The local attention mechanism adjusts the weight of each concept, reducing the influence of irrelevant or noisy concepts during classification. We improve the calculation formula for attention scores in the local self-attention mechanism, ensuring that words with different frequencies of occurrence in the text receive higher attention scores. Finally, the model employs a Bi-directional Gated Recurrent Unit (Bi-GRU), which is effective in feature extraction from texts for improved classification",
    "path": "papers/24/01/2401.03591.json",
    "total_tokens": 887,
    "translated_title": "基于知识图谱和改进的注意机制的文本分类",
    "translated_abstract": "为了解决文本中的语义歧义问题，我们提出了一个模型，创新地将知识图谱与改进的注意机制相结合。该模型利用现有知识库来丰富文本与相关的上下文概念的内容。该模型在字符和单词级别上操作，通过整合概念来加深其理解。我们首先采用信息增益来选择重要的单词。然后使用编码器-解码器框架对文本进行编码，同时包含相关的概念。局部注意机制调整每个概念的权重，在分类过程中减少无关或噪音概念的影响。我们改进了局部自注意机制中注意力分数的计算公式，确保在文本中出现频率不同的单词获得更高的注意力分数。最后，模型采用了双向门控循环单元（Bi-GRU），有效地从文本中提取特征以提高分类效果。",
    "tldr": "该论文介绍了一种基于知识图谱和改进的注意机制的文本分类模型，通过将知识图谱与注意机制相结合，解决了文本中的语义歧义问题，并通过局部注意机制和双向门控循环单元实现了更好的分类效果。"
}