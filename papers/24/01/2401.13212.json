{
    "title": "AdCorDA: Classifier Refinement via Adversarial Correction and Domain Adaptation. (arXiv:2401.13212v1 [cs.CV])",
    "abstract": "This paper describes a simple yet effective technique for refining a pretrained classifier network. The proposed AdCorDA method is based on modification of the training set and making use of the duality between network weights and layer inputs. We call this input space training. The method consists of two stages - adversarial correction followed by domain adaptation. Adversarial correction uses adversarial attacks to correct incorrect training-set classifications. The incorrectly classified samples of the training set are removed and replaced with the adversarially corrected samples to form a new training set, and then, in the second stage, domain adaptation is performed back to the original training set. Extensive experimental validations show significant accuracy boosts of over 5% on the CIFAR-100 dataset. The technique can be straightforwardly applied to refinement of weight-quantized neural networks, where experiments show substantial enhancement in performance over the baseline. T",
    "link": "http://arxiv.org/abs/2401.13212",
    "context": "Title: AdCorDA: Classifier Refinement via Adversarial Correction and Domain Adaptation. (arXiv:2401.13212v1 [cs.CV])\nAbstract: This paper describes a simple yet effective technique for refining a pretrained classifier network. The proposed AdCorDA method is based on modification of the training set and making use of the duality between network weights and layer inputs. We call this input space training. The method consists of two stages - adversarial correction followed by domain adaptation. Adversarial correction uses adversarial attacks to correct incorrect training-set classifications. The incorrectly classified samples of the training set are removed and replaced with the adversarially corrected samples to form a new training set, and then, in the second stage, domain adaptation is performed back to the original training set. Extensive experimental validations show significant accuracy boosts of over 5% on the CIFAR-100 dataset. The technique can be straightforwardly applied to refinement of weight-quantized neural networks, where experiments show substantial enhancement in performance over the baseline. T",
    "path": "papers/24/01/2401.13212.json",
    "total_tokens": 859,
    "translated_title": "AdCorDA: 通过对抗修正和领域适应进行分类器改进",
    "translated_abstract": "本文描述了一种简单而有效的技术，用于改进预训练分类器网络。所提出的AdCorDA方法基于修改训练集，并利用网络权重和层输入之间的对偶性。我们称之为输入空间训练。该方法由两个阶段组成 - 对抗修正，然后进行领域适应。对抗修正使用对抗性攻击来修正错误的训练集分类。将训练集中错误分类的样本移除，并用对抗修正的样本替换，形成新的训练集，然后在第二阶段，进行领域适应回到原始训练集。大量的实验证明，在CIFAR-100数据集上，准确率提升超过5%。该技术可以直接应用于权重量化的神经网络的改进，实验证明在基线上性能得到了显著提升。",
    "tldr": "AdCorDA方法通过对抗修正和领域适应改进预训练分类器网络，实验证明在CIFAR-100数据集上能够显著提升准确率，并且在权重量化的神经网络上也表现出显著的性能提升。"
}