{
    "title": "LEGO:Language Enhanced Multi-modal Grounding Model. (arXiv:2401.06071v1 [cs.CV])",
    "abstract": "Multi-modal large language models have demonstrated impressive performance across various tasks in different modalities. However, existing multi-modal models primarily emphasize capturing global information within each modality while neglecting the importance of perceiving local information across modalities. Consequently, these models lack the ability to effectively understand the fine-grained details of input data, limiting their performance in tasks that require a more nuanced understanding. To address this limitation, there is a compelling need to develop models that enable fine-grained understanding across multiple modalities, thereby enhancing their applicability to a wide range of tasks. In this paper, we propose LEGO, a language enhanced multi-modal grounding model. Beyond capturing global information like other multi-modal models, our proposed model excels at tasks demanding a detailed understanding of local information within the input. It demonstrates precise identification ",
    "link": "http://arxiv.org/abs/2401.06071",
    "context": "Title: LEGO:Language Enhanced Multi-modal Grounding Model. (arXiv:2401.06071v1 [cs.CV])\nAbstract: Multi-modal large language models have demonstrated impressive performance across various tasks in different modalities. However, existing multi-modal models primarily emphasize capturing global information within each modality while neglecting the importance of perceiving local information across modalities. Consequently, these models lack the ability to effectively understand the fine-grained details of input data, limiting their performance in tasks that require a more nuanced understanding. To address this limitation, there is a compelling need to develop models that enable fine-grained understanding across multiple modalities, thereby enhancing their applicability to a wide range of tasks. In this paper, we propose LEGO, a language enhanced multi-modal grounding model. Beyond capturing global information like other multi-modal models, our proposed model excels at tasks demanding a detailed understanding of local information within the input. It demonstrates precise identification ",
    "path": "papers/24/01/2401.06071.json",
    "total_tokens": 797,
    "translated_title": "LEGO: 语言增强的多模态关联模型",
    "translated_abstract": "多模态大型语言模型在不同模态的各种任务中展现出了令人印象深刻的性能。然而，现有的多模态模型主要强调捕捉每种模态内的全局信息，而忽视了跨模态感知局部信息的重要性。因此，这些模型缺乏有效理解输入数据细粒度细节的能力，从而限制了它们在需要更细致理解的任务中的性能。为了解决这个限制，迫切需要开发能够在多个模态之间进行细粒度理解的模型，从而增强它们在各种任务中的适用性。在本文中，我们提出了LEGO，一种语言增强的多模态关联模型。除了像其他多模态模型一样捕捉全局信息外，我们提出的模型在需要详细理解输入内的局部信息的任务中表现出色。它展示了精确的标识能力。",
    "tldr": "LEGO是一种语言增强的多模态关联模型，它能够在各种任务中实现细粒度的理解和精确的标识能力。",
    "en_tdlr": "LEGO is a language enhanced multi-modal grounding model that enables fine-grained understanding and precise identification in various tasks."
}