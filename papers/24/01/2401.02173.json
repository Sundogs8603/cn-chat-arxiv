{
    "title": "Prompt Decoupling for Text-to-Image Person Re-identification. (arXiv:2401.02173v1 [cs.CV])",
    "abstract": "Text-to-image person re-identification (TIReID) aims to retrieve the target person from an image gallery via a textual description query. Recently, pre-trained vision-language models like CLIP have attracted significant attention and have been widely utilized for this task due to their robust capacity for semantic concept learning and rich multi-modal knowledge. However, recent CLIP-based TIReID methods commonly rely on direct fine-tuning of the entire network to adapt the CLIP model for the TIReID task. Although these methods show competitive performance on this topic, they are suboptimal as they necessitate simultaneous domain adaptation and task adaptation. To address this issue, we attempt to decouple these two processes during the training stage. Specifically, we introduce the prompt tuning strategy to enable domain adaptation and propose a two-stage training approach to disentangle domain adaptation from task adaptation. In the first stage, we freeze the two encoders from CLIP an",
    "link": "http://arxiv.org/abs/2401.02173",
    "context": "Title: Prompt Decoupling for Text-to-Image Person Re-identification. (arXiv:2401.02173v1 [cs.CV])\nAbstract: Text-to-image person re-identification (TIReID) aims to retrieve the target person from an image gallery via a textual description query. Recently, pre-trained vision-language models like CLIP have attracted significant attention and have been widely utilized for this task due to their robust capacity for semantic concept learning and rich multi-modal knowledge. However, recent CLIP-based TIReID methods commonly rely on direct fine-tuning of the entire network to adapt the CLIP model for the TIReID task. Although these methods show competitive performance on this topic, they are suboptimal as they necessitate simultaneous domain adaptation and task adaptation. To address this issue, we attempt to decouple these two processes during the training stage. Specifically, we introduce the prompt tuning strategy to enable domain adaptation and propose a two-stage training approach to disentangle domain adaptation from task adaptation. In the first stage, we freeze the two encoders from CLIP an",
    "path": "papers/24/01/2401.02173.json",
    "total_tokens": 952,
    "translated_title": "用于文本到图像人员再识别的提示解耦方法",
    "translated_abstract": "文本到图像人员再识别（TIReID）旨在通过文本描述查询从图像画廊中检索目标人员。最近，像CLIP这样的预训练视觉语言模型引起了重大关注，并广泛用于此任务，因为它们具有强大的语义概念学习和丰富的多模式知识能力。然而，最近基于CLIP的TIReID方法通常依赖于直接微调整个网络以适应TIReID任务的CLIP模型。尽管这些方法在这个主题上表现出竞争力，但它们并不是最优的，因为它们需要同时进行领域适应和任务适应。为了解决这个问题，我们尝试在训练阶段对这两个过程进行解耦。具体而言，我们引入提示调整策略来实现领域适应，并提出了一个两阶段训练方法，将领域适应与任务适应分离。在第一阶段，我们冻结CLIP中的两个编码器。",
    "tldr": "该论文介绍了一种用于文本到图像人员再识别的提示解耦方法，通过引入提示调整策略和两阶段训练方法来分离领域适应和任务适应过程。该方法在实现竞争性性能的同时避免了同时进行领域适应和任务适应的子优化问题。"
}