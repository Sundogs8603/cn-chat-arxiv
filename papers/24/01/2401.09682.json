{
    "title": "Comparative Study on the Performance of Categorical Variable Encoders in Classification and Regression Tasks. (arXiv:2401.09682v1 [cs.LG])",
    "abstract": "Categorical variables often appear in datasets for classification and regression tasks, and they need to be encoded into numerical values before training. Since many encoders have been developed and can significantly impact performance, choosing the appropriate encoder for a task becomes a time-consuming yet important practical issue. This study broadly classifies machine learning models into three categories: 1) ATI models that implicitly perform affine transformations on inputs, such as multi-layer perceptron neural network; 2) Tree-based models that are based on decision trees, such as random forest; and 3) the rest, such as kNN. Theoretically, we prove that the one-hot encoder is the best choice for ATI models in the sense that it can mimic any other encoders by learning suitable weights from the data. We also explain why the target encoder and its variants are the most suitable encoders for tree-based models. This study conducted comprehensive computational experiments to evaluate",
    "link": "http://arxiv.org/abs/2401.09682",
    "context": "Title: Comparative Study on the Performance of Categorical Variable Encoders in Classification and Regression Tasks. (arXiv:2401.09682v1 [cs.LG])\nAbstract: Categorical variables often appear in datasets for classification and regression tasks, and they need to be encoded into numerical values before training. Since many encoders have been developed and can significantly impact performance, choosing the appropriate encoder for a task becomes a time-consuming yet important practical issue. This study broadly classifies machine learning models into three categories: 1) ATI models that implicitly perform affine transformations on inputs, such as multi-layer perceptron neural network; 2) Tree-based models that are based on decision trees, such as random forest; and 3) the rest, such as kNN. Theoretically, we prove that the one-hot encoder is the best choice for ATI models in the sense that it can mimic any other encoders by learning suitable weights from the data. We also explain why the target encoder and its variants are the most suitable encoders for tree-based models. This study conducted comprehensive computational experiments to evaluate",
    "path": "papers/24/01/2401.09682.json",
    "total_tokens": 897,
    "translated_title": "分类和回归任务中分类变量编码器性能的比较研究",
    "translated_abstract": "分类变量经常出现在分类和回归任务的数据集中，在训练之前需要将其编码为数值。由于已经开发出了许多编码器并且可以显著影响性能，选择适当的编码器成为一项耗时但重要的实践问题。本研究将机器学习模型大致分为三类：1）隐式对输入进行仿射变换的ATI模型，如多层感知机神经网络；2）基于决策树的树模型，如随机森林；3）其他模型，如kNN。在理论上，我们证明了对于ATI模型来说，独热编码器是最佳选择，因为它可以通过从数据中学习合适的权重模拟任何其他编码器。我们还解释了为什么目标编码器及其变体是树模型中最合适的编码器。本研究进行了综合的计算实验来评估",
    "tldr": "本研究比较了不同分类变量编码器在分类和回归任务中的性能，验证了对于ATI模型来说，独热编码器是最佳选择，而目标编码器及其变体是树模型中最合适的编码器。"
}