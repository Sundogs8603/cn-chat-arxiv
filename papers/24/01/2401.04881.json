{
    "title": "Attendre: Wait To Attend By Retrieval With Evicted Queries in Memory-Based Transformers for Long Context Processing. (arXiv:2401.04881v1 [cs.CL])",
    "abstract": "As LLMs have become capable of processing more complex types of inputs, researchers have recently studied how to efficiently and affordably process possibly arbitrarily long sequences. One effective approach is to use a FIFO memory to store keys and values of an attention sublayer from past chunks to allow subsequent queries to attend. However, this approach requires a large memory and/or takes into the consideration the specific LM architecture. Moreover, due to the causal nature between the key-values in prior context and the queries at present, this approach cannot be extended to bidirectional attention such as in an encoder-decoder or PrefixLM decoder-only architecture. In this paper, we propose to use eviction policies, such as LRA and LFA, to reduce the memory size and adapt to various architectures, and we also propose the Attendre layer, a wait-to-attend mechanism by retrieving the key-value memory (K/V memory) with evicted queries in the query memory (Q memory). As a first ste",
    "link": "http://arxiv.org/abs/2401.04881",
    "context": "Title: Attendre: Wait To Attend By Retrieval With Evicted Queries in Memory-Based Transformers for Long Context Processing. (arXiv:2401.04881v1 [cs.CL])\nAbstract: As LLMs have become capable of processing more complex types of inputs, researchers have recently studied how to efficiently and affordably process possibly arbitrarily long sequences. One effective approach is to use a FIFO memory to store keys and values of an attention sublayer from past chunks to allow subsequent queries to attend. However, this approach requires a large memory and/or takes into the consideration the specific LM architecture. Moreover, due to the causal nature between the key-values in prior context and the queries at present, this approach cannot be extended to bidirectional attention such as in an encoder-decoder or PrefixLM decoder-only architecture. In this paper, we propose to use eviction policies, such as LRA and LFA, to reduce the memory size and adapt to various architectures, and we also propose the Attendre layer, a wait-to-attend mechanism by retrieving the key-value memory (K/V memory) with evicted queries in the query memory (Q memory). As a first ste",
    "path": "papers/24/01/2401.04881.json",
    "total_tokens": 895,
    "translated_title": "Attendre: 用反驱逐查询在基于记忆的变压器中等待参与长上下文处理",
    "translated_abstract": "随着LLMs能够处理更复杂类型的输入，研究人员最近研究了如何高效且经济地处理可能任意长的序列。一种有效的方法是使用FIFO内存来存储过去块的注意子层的键和值，以允许后续查询参与。然而，这种方法需要大量内存和/或考虑特定的LM架构。此外，由于先前上下文中的键-值与当前查询之间的因果关系，这种方法无法扩展到具有双向注意力的架构，例如编码器-解码器或PrefixLM仅解码器架构。在本文中，我们提出使用逐出策略，例如LRA和LFA，来减少内存大小并适应各种架构，我们还提出了Attendre层，一种通过在查询内存中检索带有驱逐查询的键值存储器（K/V存储器）的等待参与机制。",
    "tldr": "本文提出了一种新的等待参与机制，通过在查询内存中检索带有驱逐查询的键值存储器（K/V存储器），使用逐出策略来减少内存大小并适应各种架构。",
    "en_tdlr": "This paper proposes a new wait-to-attend mechanism by retrieving the key-value memory (K/V memory) with evicted queries in the query memory (Q memory), using eviction policies to reduce memory size and adapt to various architectures."
}