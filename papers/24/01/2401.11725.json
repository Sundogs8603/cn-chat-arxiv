{
    "title": "Speak It Out: Solving Symbol-Related Problems with Symbol-to-Language Conversion for Language Models",
    "abstract": "arXiv:2401.11725v2 Announce Type: replace  Abstract: Symbols (or more broadly, non-natural language textual representations) such as numerical sequences, molecular formulas, and table delimiters widely exist, playing important roles in various tasks such as abstract reasoning, chemical property prediction, and table question answering. Despite the impressive natural language comprehension capabilities of large language models (LLMs), their reasoning abilities for symbols remain inadequate, which could attributed to the difference between symbol representations and general natural languages. We propose symbol-to-language (S2L), a tuning-free method that enables large language models to solve symbol-related problems with information expressed in natural language. Specifically, S2L first converts the symbols involved to language-based representations, which can be implemented by prompting LLMs or leveraging external tools, then these language-based representations are integrated into the ",
    "link": "https://arxiv.org/abs/2401.11725",
    "context": "Title: Speak It Out: Solving Symbol-Related Problems with Symbol-to-Language Conversion for Language Models\nAbstract: arXiv:2401.11725v2 Announce Type: replace  Abstract: Symbols (or more broadly, non-natural language textual representations) such as numerical sequences, molecular formulas, and table delimiters widely exist, playing important roles in various tasks such as abstract reasoning, chemical property prediction, and table question answering. Despite the impressive natural language comprehension capabilities of large language models (LLMs), their reasoning abilities for symbols remain inadequate, which could attributed to the difference between symbol representations and general natural languages. We propose symbol-to-language (S2L), a tuning-free method that enables large language models to solve symbol-related problems with information expressed in natural language. Specifically, S2L first converts the symbols involved to language-based representations, which can be implemented by prompting LLMs or leveraging external tools, then these language-based representations are integrated into the ",
    "path": "papers/24/01/2401.11725.json",
    "total_tokens": 797,
    "translated_title": "通过符号转换为语言解决符号相关问题的语言模型",
    "translated_abstract": "符号（或更广义的，非自然语言文本表示）如数字序列、分子式以及表格边界等广泛存在，在各种任务中扮演重要角色，比如抽象推理、化学性质预测以及表格问题回答。尽管大语言模型（LLMs）具有令人印象深刻的自然语言理解能力，但它们在处理符号方面的推理能力仍然不足，这可能归因于符号表示与一般自然语言之间的差异。我们提出了一种无需调参的符号转换为语言（S2L）方法，使大语言模型能够利用自然语言表达的信息来解决符号相关问题。具体而言，S2L首先将涉及的符号转换为基于语言的表示，这可以通过提示LLMs或利用外部工具来实现，然后这些基于语言的表示被整合到",
    "tldr": "提出了符号转换为语言（S2L）方法，通过将符号转换为基于语言的表示，使得大语言模型能够解决符号相关问题。",
    "en_tdlr": "Proposed the Symbol-to-Language (S2L) method, which enables large language models to solve symbol-related problems by converting symbols into language-based representations."
}