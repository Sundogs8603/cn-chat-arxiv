{
    "title": "FakeClaim: A Multiple Platform-driven Dataset for Identification of Fake News on 2023 Israel-Hamas War. (arXiv:2401.16625v1 [cs.IR])",
    "abstract": "We contribute the first publicly available dataset of factual claims from different platforms and fake YouTube videos on the 2023 Israel-Hamas war for automatic fake YouTube video classification. The FakeClaim data is collected from 60 fact-checking organizations in 30 languages and enriched with metadata from the fact-checking organizations curated by trained journalists specialized in fact-checking. Further, we classify fake videos within the subset of YouTube videos using textual information and user comments. We used a pre-trained model to classify each video with different feature combinations. Our best-performing fine-tuned language model, Universal Sentence Encoder (USE), achieves a Macro F1 of 87\\%, which shows that the trained model can be helpful for debunking fake videos using the comments from the user discussion. The dataset is available on Github\\footnote{https://github.com/Gautamshahi/FakeClaim}",
    "link": "http://arxiv.org/abs/2401.16625",
    "context": "Title: FakeClaim: A Multiple Platform-driven Dataset for Identification of Fake News on 2023 Israel-Hamas War. (arXiv:2401.16625v1 [cs.IR])\nAbstract: We contribute the first publicly available dataset of factual claims from different platforms and fake YouTube videos on the 2023 Israel-Hamas war for automatic fake YouTube video classification. The FakeClaim data is collected from 60 fact-checking organizations in 30 languages and enriched with metadata from the fact-checking organizations curated by trained journalists specialized in fact-checking. Further, we classify fake videos within the subset of YouTube videos using textual information and user comments. We used a pre-trained model to classify each video with different feature combinations. Our best-performing fine-tuned language model, Universal Sentence Encoder (USE), achieves a Macro F1 of 87\\%, which shows that the trained model can be helpful for debunking fake videos using the comments from the user discussion. The dataset is available on Github\\footnote{https://github.com/Gautamshahi/FakeClaim}",
    "path": "papers/24/01/2401.16625.json",
    "total_tokens": 894,
    "translated_title": "FakeClaim: 2023年以色列哈马斯战争中的假新闻识别的多平台驱动数据集",
    "translated_abstract": "我们提供了首个公开可用的来自不同平台的事实性主张和2023年以色列哈马斯战争的假YouTube视频数据集，用于自动识别假YouTube视频。FakeClaim数据集是从60个事实核查机构、30种语言中收集的，并通过训练有素的事实核查专业记者维护的事实核查机构元数据进行丰富。此外，我们使用文本信息和用户评论对YouTube视频子集中的假视频进行分类。我们使用了预训练模型来使用不同的特征组合对每个视频进行分类。我们表现最佳的微调语言模型，即Universal Sentence Encoder (USE)，达到了87\\%的宏F1，这表明训练模型可以通过用户讨论中的评论帮助揭穿假视频。该数据集可在Github上找到。",
    "tldr": "FakeClaim数据集是首个公开可用的用于自动识别2023年以色列哈马斯战争中假新闻的数据集，包含了来自不同平台的事实性主张和假YouTube视频。通过使用预训练的语言模型，该研究展示了使用用户评论可以帮助辟谣假视频的潜力。"
}