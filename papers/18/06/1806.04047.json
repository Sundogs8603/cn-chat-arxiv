{
    "title": "High Dimensional Data Enrichment: Interpretable, Fast, and Data-Efficient. (arXiv:1806.04047v4 [stat.ML] UPDATED)",
    "abstract": "We consider the problem of multi-task learning in the high dimensional setting. In particular, we introduce an estimator and investigate its statistical and computational properties for the problem of multiple connected linear regressions known as Data Enrichment/Sharing. The between-tasks connections are captured by a cross-tasks \\emph{common parameter}, which gets refined by per-task \\emph{individual parameters}. Any convex function, e.g., norm, can characterize the structure of both common and individual parameters. We delineate the sample complexity of our estimator and provide a high probability non-asymptotic bound for estimation error of all parameters under a geometric condition. We show that the recovery of the common parameter benefits from \\emph{all} of the pooled samples. We propose an iterative estimation algorithm with a geometric convergence rate and supplement our theoretical analysis with experiments on synthetic data. Overall, we present a first thorough statistical a",
    "link": "http://arxiv.org/abs/1806.04047",
    "context": "Title: High Dimensional Data Enrichment: Interpretable, Fast, and Data-Efficient. (arXiv:1806.04047v4 [stat.ML] UPDATED)\nAbstract: We consider the problem of multi-task learning in the high dimensional setting. In particular, we introduce an estimator and investigate its statistical and computational properties for the problem of multiple connected linear regressions known as Data Enrichment/Sharing. The between-tasks connections are captured by a cross-tasks \\emph{common parameter}, which gets refined by per-task \\emph{individual parameters}. Any convex function, e.g., norm, can characterize the structure of both common and individual parameters. We delineate the sample complexity of our estimator and provide a high probability non-asymptotic bound for estimation error of all parameters under a geometric condition. We show that the recovery of the common parameter benefits from \\emph{all} of the pooled samples. We propose an iterative estimation algorithm with a geometric convergence rate and supplement our theoretical analysis with experiments on synthetic data. Overall, we present a first thorough statistical a",
    "path": "papers/18/06/1806.04047.json",
    "total_tokens": 918,
    "translated_title": "高维数据丰富化：可解释、快速和数据有效",
    "translated_abstract": "我们考虑在高维设置中的多任务学习问题。特别地，我们引入了一个估计器，并研究了其在多个连接线性回归问题中的统计和计算特性，该问题被称为数据丰富/共享。任务间的连接由跨任务的“公共参数”捕捉，该参数通过任务级的“个体参数”进行细化。任何凸函数，如范数，都可以表征公共参数和个体参数的结构。我们勾勒了我们估计器的样本复杂度，并在几何条件下为所有参数的估计误差提供了高概率的非渐进边界。我们展示了从汇集样本中受益于公共参数的恢复。我们提出了一种具有几何收敛速度的迭代估计算法，并通过合成数据的实验补充了我们的理论分析。总的来说，我们提供了第一个全面的统计和计算分析，用于解决高维数据丰富化问题。",
    "tldr": "本文研究了在高维设置中的多任务学习问题，并引入了一个估计器来处理多连接线性回归问题，称为数据丰富/共享。我们通过凸函数来描述公共参数和个体参数的结构，并提出了一种具有几何收敛速度的迭代估计算法。",
    "en_tdlr": "This paper investigates the problem of multi-task learning in high-dimensional settings and introduces an estimator for multiple connected linear regressions known as Data Enrichment/Sharing. The paper presents a thorough statistical and computational analysis and proposes an iterative estimation algorithm with geometric convergence rate."
}