{
    "title": "Modality-based Factorization for Multimodal Fusion. (arXiv:1811.12624v3 [cs.LG] UPDATED)",
    "abstract": "We propose a novel method, Modality-based Redundancy Reduction Fusion (MRRF), for understanding and modulating the relative contribution of each modality in multimodal inference tasks. This is achieved by obtaining an $(M+1)$-way tensor to consider the high-order relationships between $M$ modalities and the output layer of a neural network model. Applying a modality-based tensor factorization method, which adopts different factors for different modalities, results in removing information present in a modality that can be compensated by other modalities, with respect to model outputs. This helps to understand the relative utility of information in each modality. In addition it leads to a less complicated model with less parameters and therefore could be applied as a regularizer avoiding overfitting. We have applied this method to three different multimodal datasets in sentiment analysis, personality trait recognition, and emotion recognition. We are able to recognize relationships and r",
    "link": "http://arxiv.org/abs/1811.12624",
    "context": "Title: Modality-based Factorization for Multimodal Fusion. (arXiv:1811.12624v3 [cs.LG] UPDATED)\nAbstract: We propose a novel method, Modality-based Redundancy Reduction Fusion (MRRF), for understanding and modulating the relative contribution of each modality in multimodal inference tasks. This is achieved by obtaining an $(M+1)$-way tensor to consider the high-order relationships between $M$ modalities and the output layer of a neural network model. Applying a modality-based tensor factorization method, which adopts different factors for different modalities, results in removing information present in a modality that can be compensated by other modalities, with respect to model outputs. This helps to understand the relative utility of information in each modality. In addition it leads to a less complicated model with less parameters and therefore could be applied as a regularizer avoiding overfitting. We have applied this method to three different multimodal datasets in sentiment analysis, personality trait recognition, and emotion recognition. We are able to recognize relationships and r",
    "path": "papers/18/11/1811.12624.json",
    "total_tokens": 890,
    "tldr": "本文提出了一种新的方法来理解和调节多模态推理任务中每种模态的相对贡献，从而实现多模态融合。此方法通过移除可以由其他模态补偿的模态中存在的信息，以便理解每种模态中信息的相对实用性，并可用于减少模型复杂度以避免过拟合。"
}