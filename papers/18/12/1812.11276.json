{
    "title": "Learn to Interpret Atari Agents. (arXiv:1812.11276v3 [cs.LG] UPDATED)",
    "abstract": "Deep reinforcement learning (DeepRL) agents surpass human-level performance in many tasks. However, the direct mapping from states to actions makes it hard to interpret the rationale behind the decision-making of the agents. In contrast to previous a-posteriori methods for visualizing DeepRL policies, in this work, we propose to equip the DeepRL model with an innate visualization ability. Our proposed agent, named region-sensitive Rainbow (RS-Rainbow), is an end-to-end trainable network based on the original Rainbow, a powerful deep Q-network agent. It learns important regions in the input domain via an attention module. At inference time, after each forward pass, we can visualize regions that are most important to decision-making by backpropagating gradients from the attention module to the input frames. The incorporation of our proposed module not only improves model interpretability, but leads to performance improvement. Extensive experiments on games from the Atari 2600 suite demon",
    "link": "http://arxiv.org/abs/1812.11276",
    "context": "Title: Learn to Interpret Atari Agents. (arXiv:1812.11276v3 [cs.LG] UPDATED)\nAbstract: Deep reinforcement learning (DeepRL) agents surpass human-level performance in many tasks. However, the direct mapping from states to actions makes it hard to interpret the rationale behind the decision-making of the agents. In contrast to previous a-posteriori methods for visualizing DeepRL policies, in this work, we propose to equip the DeepRL model with an innate visualization ability. Our proposed agent, named region-sensitive Rainbow (RS-Rainbow), is an end-to-end trainable network based on the original Rainbow, a powerful deep Q-network agent. It learns important regions in the input domain via an attention module. At inference time, after each forward pass, we can visualize regions that are most important to decision-making by backpropagating gradients from the attention module to the input frames. The incorporation of our proposed module not only improves model interpretability, but leads to performance improvement. Extensive experiments on games from the Atari 2600 suite demon",
    "path": "papers/18/12/1812.11276.json",
    "total_tokens": 968,
    "tldr": "本文提出的区域敏感Rainbow (RS-Rainbow)模型是一种基于原始Rainbow模型的端到端可训练网络，通过注意力模块学习输入域中的重要区域。在每次前向传递后，梯度可以反向传递以可视化最重要的决策区域。这样做可以不仅提高模型的解释性，而且提高性能。"
}