{
    "title": "Perturbed-History Exploration in Stochastic Linear Bandits. (arXiv:1903.09132v2 [cs.LG] UPDATED)",
    "abstract": "We propose a new online algorithm for cumulative regret minimization in a stochastic linear bandit. The algorithm pulls the arm with the highest estimated reward in a linear model trained on its perturbed history. Therefore, we call it perturbed-history exploration in a linear bandit (LinPHE). The perturbed history is a mixture of observed rewards and randomly generated i.i.d. pseudo-rewards. We derive a $\\tilde{O}(d \\sqrt{n})$ gap-free bound on the $n$-round regret of LinPHE, where $d$ is the number of features. The key steps in our analysis are new concentration and anti-concentration bounds on the weighted sum of Bernoulli random variables. To show the generality of our design, we generalize LinPHE to a logistic model. We evaluate our algorithms empirically and show that they are practical.",
    "link": "http://arxiv.org/abs/1903.09132",
    "context": "Title: Perturbed-History Exploration in Stochastic Linear Bandits. (arXiv:1903.09132v2 [cs.LG] UPDATED)\nAbstract: We propose a new online algorithm for cumulative regret minimization in a stochastic linear bandit. The algorithm pulls the arm with the highest estimated reward in a linear model trained on its perturbed history. Therefore, we call it perturbed-history exploration in a linear bandit (LinPHE). The perturbed history is a mixture of observed rewards and randomly generated i.i.d. pseudo-rewards. We derive a $\\tilde{O}(d \\sqrt{n})$ gap-free bound on the $n$-round regret of LinPHE, where $d$ is the number of features. The key steps in our analysis are new concentration and anti-concentration bounds on the weighted sum of Bernoulli random variables. To show the generality of our design, we generalize LinPHE to a logistic model. We evaluate our algorithms empirically and show that they are practical.",
    "path": "papers/19/03/1903.09132.json",
    "total_tokens": 927,
    "translated_title": "在随机线性赌博机中的干扰历史探索",
    "translated_abstract": "我们提出了一种新的在线算法，用于在随机线性赌博机中最小化累积遗憾。该算法在训练于其干扰历史的线性模型上选择估计奖励最高的臂。因此，我们称之为线性赌博机中的干扰历史探索（LinPHE）。所谓干扰历史是指观察到的奖励和随机生成的独立同分布的伪奖励的混合。我们推导出对于LinPHE的$n$轮遗憾，其中$d$是特征数量，有一个$\\tilde{O}(d \\sqrt{n})$的间隙自由界。我们分析的关键步骤是关于伯努利随机变量的加权和的新的集中和反集中边界。为了展示我们设计的普遍性，我们将LinPHE推广到一个逻辑模型中。我们通过实证评估证明了我们的算法的实用性。",
    "tldr": "我们提出了一种在线算法，通过在训练于其干扰历史的线性模型上选择估计奖励最高的臂，用于在随机线性赌博机中最小化累积遗憾。我们推导出了一个关于算法遗憾的较好界限，并通过实证评估展示了算法的实用性。",
    "en_tdlr": "We propose a new online algorithm for cumulative regret minimization in a stochastic linear bandit, which selects the arm with the highest estimated reward in a linear model trained on its perturbed history. We derive a good bound on the algorithm's regret and demonstrate its practicality through empirical evaluation."
}