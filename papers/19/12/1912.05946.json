{
    "title": "Leveraging End-to-End Speech Recognition with Neural Architecture Search. (arXiv:1912.05946v2 [eess.AS] UPDATED)",
    "abstract": "Deep neural networks (DNNs) have been demonstrated to outperform many traditional machine learning algorithms in Automatic Speech Recognition (ASR). In this paper, we show that a large improvement in the accuracy of deep speech models can be achieved with effective Neural Architecture Optimization at a very low computational cost. Phone recognition tests with the popular LibriSpeech and TIMIT benchmarks proved this fact by displaying the ability to discover and train novel candidate models within a few hours (less than a day) many times faster than the attention-based seq2seq models. Our method achieves test error of 7% Word Error Rate (WER) on the LibriSpeech corpus and 13% Phone Error Rate (PER) on the TIMIT corpus, on par with state-of-the-art results.",
    "link": "http://arxiv.org/abs/1912.05946",
    "context": "Title: Leveraging End-to-End Speech Recognition with Neural Architecture Search. (arXiv:1912.05946v2 [eess.AS] UPDATED)\nAbstract: Deep neural networks (DNNs) have been demonstrated to outperform many traditional machine learning algorithms in Automatic Speech Recognition (ASR). In this paper, we show that a large improvement in the accuracy of deep speech models can be achieved with effective Neural Architecture Optimization at a very low computational cost. Phone recognition tests with the popular LibriSpeech and TIMIT benchmarks proved this fact by displaying the ability to discover and train novel candidate models within a few hours (less than a day) many times faster than the attention-based seq2seq models. Our method achieves test error of 7% Word Error Rate (WER) on the LibriSpeech corpus and 13% Phone Error Rate (PER) on the TIMIT corpus, on par with state-of-the-art results.",
    "path": "papers/19/12/1912.05946.json",
    "total_tokens": 801,
    "translated_title": "利用神经架构搜索提升端到端语音识别效果",
    "translated_abstract": "深度神经网络已经被证实在自动语音识别方面优于许多传统机器学习算法。本文研究表明，通过有效实施神经架构搜索可以在非常低的计算成本情况下显著提高深度语音模型的准确性。在使用流行的LibriSpeech和TIMIT基准测试中进行的音素识别测试证明了这一事实，该方法能够在几个小时之内（不到一天），比基于注意力机制的seq2seq模型快多次，探测和训练新的候选模型。我们的方法在LibriSpeech语料库上的测试误差率（WER）为7％，在TIMIT语料库上的音素误差率（PER）为13％，达到了与最先进结果相当的水平。",
    "tldr": "本文研究表明，通过神经架构搜索可以在非常低的计算成本情况下显著提高深度语音模型的准确性，取得了与最先进结果相当的水平。",
    "en_tdlr": "The paper shows that effective Neural Architecture Optimization can significantly improve the accuracy of deep speech models at very low computational cost. The method achieved results on par with state-of-the-art and was many times faster than attention-based seq2seq models."
}