{
    "title": "Implicit Regularization and Momentum Algorithms in Nonlinearly Parameterized Adaptive Control and Prediction. (arXiv:1912.13154v7 [math.OC] UPDATED)",
    "abstract": "Stable concurrent learning and control of dynamical systems is the subject of adaptive control. Despite being an established field with many practical applications and a rich theory, much of the development in adaptive control for nonlinear systems revolves around a few key algorithms. By exploiting strong connections between classical adaptive nonlinear control techniques and recent progress in optimization and machine learning, we show that there exists considerable untapped potential in algorithm development for both adaptive nonlinear control and adaptive dynamics prediction. We begin by introducing first-order adaptation laws inspired by natural gradient descent and mirror descent. We prove that when there are multiple dynamics consistent with the data, these non-Euclidean adaptation laws implicitly regularize the learned model. Local geometry imposed during learning thus may be used to select parameter vectors -- out of the many that will achieve perfect tracking or prediction --",
    "link": "http://arxiv.org/abs/1912.13154",
    "context": "Title: Implicit Regularization and Momentum Algorithms in Nonlinearly Parameterized Adaptive Control and Prediction. (arXiv:1912.13154v7 [math.OC] UPDATED)\nAbstract: Stable concurrent learning and control of dynamical systems is the subject of adaptive control. Despite being an established field with many practical applications and a rich theory, much of the development in adaptive control for nonlinear systems revolves around a few key algorithms. By exploiting strong connections between classical adaptive nonlinear control techniques and recent progress in optimization and machine learning, we show that there exists considerable untapped potential in algorithm development for both adaptive nonlinear control and adaptive dynamics prediction. We begin by introducing first-order adaptation laws inspired by natural gradient descent and mirror descent. We prove that when there are multiple dynamics consistent with the data, these non-Euclidean adaptation laws implicitly regularize the learned model. Local geometry imposed during learning thus may be used to select parameter vectors -- out of the many that will achieve perfect tracking or prediction --",
    "path": "papers/19/12/1912.13154.json",
    "total_tokens": 1025,
    "translated_title": "非线性参数自适应控制和预测中的隐式正则化和动量算法",
    "translated_abstract": "稳定的并发学习和控制动态系统是自适应控制的主题。尽管自适应控制是一个已经建立起来具有许多实际应用和丰富理论的领域，但非线性系统的自适应控制和自适应动态预测的发展主要围绕着一些关键算法。通过利用经典自适应非线性控制技术和最近在优化和机器学习领域的进展之间的密切联系，我们展示了在自适应非线性控制和自适应动态预测的算法发展中存在着相当大的潜力。我们首先介绍了受自然梯度下降和镜像下降启发的一阶自适应法则。我们证明了当存在多种与数据一致的动态时，这些非欧几里德自适应法则隐式正则化了学习的模型。因此，在学习过程中施加的局部几何性质可以用来选择参数向量 - 在可能实现完美跟踪或预测的许多参数向量中选择一个。",
    "tldr": "本论文通过利用经典自适应非线性控制技术和最近在优化和机器学习领域的进展之间的联系，展示了在自适应非线性控制和自适应动态预测的算法发展中存在相当大的潜力。通过引入受自然梯度下降和镜像下降启发的一阶自适应法则，证明了这些法则在存在多种与数据一致的动态时隐式正则化了学习的模型。",
    "en_tdlr": "This paper exploits the connection between classical adaptive nonlinear control techniques and recent progress in optimization and machine learning, demonstrating the untapped potential in algorithm development for both adaptive nonlinear control and adaptive dynamics prediction. It introduces first-order adaptation laws inspired by natural gradient descent and mirror descent, proving that these laws implicitly regularize the learned model when there are multiple dynamics consistent with the data."
}