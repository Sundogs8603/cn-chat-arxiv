{
    "title": "On Low-rank Trace Regression under General Sampling Distribution. (arXiv:1904.08576v5 [cs.LG] UPDATED)",
    "abstract": "In this paper, we study the trace regression when a matrix of parameters B* is estimated via the convex relaxation of a rank-regularized regression or via regularized non-convex optimization. It is known that these estimators satisfy near-optimal error bounds under assumptions on the rank, coherence, and spikiness of B*. We start by introducing a general notion of spikiness for B* that provides a generic recipe to prove the restricted strong convexity of the sampling operator of the trace regression and obtain near-optimal and non-asymptotic error bounds for the estimation error. Similar to the existing literature, these results require the regularization parameter to be above a certain theory-inspired threshold that depends on observation noise that may be unknown in practice. Next, we extend the error bounds to cases where the regularization parameter is chosen via cross-validation. This result is significant in that existing theoretical results on cross-validated estimators (Kale et",
    "link": "http://arxiv.org/abs/1904.08576",
    "context": "Title: On Low-rank Trace Regression under General Sampling Distribution. (arXiv:1904.08576v5 [cs.LG] UPDATED)\nAbstract: In this paper, we study the trace regression when a matrix of parameters B* is estimated via the convex relaxation of a rank-regularized regression or via regularized non-convex optimization. It is known that these estimators satisfy near-optimal error bounds under assumptions on the rank, coherence, and spikiness of B*. We start by introducing a general notion of spikiness for B* that provides a generic recipe to prove the restricted strong convexity of the sampling operator of the trace regression and obtain near-optimal and non-asymptotic error bounds for the estimation error. Similar to the existing literature, these results require the regularization parameter to be above a certain theory-inspired threshold that depends on observation noise that may be unknown in practice. Next, we extend the error bounds to cases where the regularization parameter is chosen via cross-validation. This result is significant in that existing theoretical results on cross-validated estimators (Kale et",
    "path": "papers/19/04/1904.08576.json",
    "total_tokens": 954,
    "translated_title": "关于在一般采样分布下的低秩迹回归的研究",
    "translated_abstract": "本文研究了通过秩正则化回归的凸松弛或正则化非凸优化来估计参数矩阵B*的迹回归问题。已知这些估计器在对B*的秩、一致性和峰值性假设下满足近乎最优的误差界。我们首先引入了对B*的一种通用峰值概念，该概念提供了证明迹回归采样算子的受限强凸性以及获得估计误差的非渐进、近乎最优界的通用方法。与现有文献类似，这些结果要求正则化参数高于某个理论上的阈值，该阈值取决于实践中可能未知的观测噪声。接下来，我们将误差界扩展到以交叉验证选择正则化参数的情况。这个结果的重要性在于现有关于交叉验证估计器的理论结果(Kale等)。",
    "tldr": "本文研究了在一般采样分布下的低秩迹回归问题，并引入了一种通用峰值概念，提供了证明迹回归采样算子强凸性和获得非渐进、近乎最优界的方法。同时，将误差界扩展到以交叉验证选择正则化参数的情况下。"
}