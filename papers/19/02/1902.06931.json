{
    "title": "On the consistency of supervised learning with missing values",
    "abstract": "arXiv:1902.06931v4 Announce Type: replace-cross  Abstract: In many application settings, the data have missing entries which make analysis challenging. An abundant literature addresses missing values in an inferential framework: estimating parameters and their variance from incomplete tables. Here, we consider supervised-learning settings: predicting a target when missing values appear in both training and testing data. We show the consistency of two approaches in prediction. A striking result is that the widely-used method of imputing with a constant, such as the mean prior to learning is consistent when missing values are not informative. This contrasts with inferential settings where mean imputation is pointed at for distorting the distribution of the data. That such a simple approach can be consistent is important in practice. We also show that a predictor suited for complete observations can predict optimally on incomplete data,through multiple imputation.Finally, to compare imput",
    "link": "https://arxiv.org/abs/1902.06931",
    "context": "Title: On the consistency of supervised learning with missing values\nAbstract: arXiv:1902.06931v4 Announce Type: replace-cross  Abstract: In many application settings, the data have missing entries which make analysis challenging. An abundant literature addresses missing values in an inferential framework: estimating parameters and their variance from incomplete tables. Here, we consider supervised-learning settings: predicting a target when missing values appear in both training and testing data. We show the consistency of two approaches in prediction. A striking result is that the widely-used method of imputing with a constant, such as the mean prior to learning is consistent when missing values are not informative. This contrasts with inferential settings where mean imputation is pointed at for distorting the distribution of the data. That such a simple approach can be consistent is important in practice. We also show that a predictor suited for complete observations can predict optimally on incomplete data,through multiple imputation.Finally, to compare imput",
    "path": "papers/19/02/1902.06931.json",
    "total_tokens": 844,
    "translated_title": "关于带缺失值的监督学习的一致性",
    "translated_abstract": "在许多应用设置中，数据存在缺失值，这使得分析变得具有挑战性。丰富的文献涉及缺失值在推断框架中的处理：从不完整的表中估计参数及其方差。在这里，我们考虑监督学习设置：在训练和测试数据中出现缺失值时预测目标。我们表明了两种方法在预测中的一致性。一个引人注目的结果是，当缺失值不具信息性时，使用常数进行插补，例如在学习之前使用均值，是一致的。这与推断设置形成鲜明对比，推断设置中常用的均值插补方法被指责扭曲数据的分布。这样一个简单的方法在实践中能够保持一致性是很重要的。我们还展示了适用于完整观测的预测器可以通过多重插补在不完整数据上进行最佳预测。最后，为了比较插补",
    "tldr": "两种方法在带缺失值的监督学习中表现出一致性，当缺失值不具信息性时，使用常数进行插补是一种简单且重要的实践方法。",
    "en_tdlr": "Two approaches show consistency in supervised learning with missing values, with imputing using a constant being a simple and important practical method when the missing values are not informative."
}