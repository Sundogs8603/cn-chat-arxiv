{
    "title": "Sampling-based sublinear low-rank matrix arithmetic framework for dequantizing quantum machine learning. (arXiv:1910.06151v4 [cs.DS] UPDATED)",
    "abstract": "We present an algorithmic framework for quantum-inspired classical algorithms on close-to-low-rank matrices, generalizing the series of results started by Tang's breakthrough quantum-inspired algorithm for recommendation systems [STOC'19]. Motivated by quantum linear algebra algorithms and the quantum singular value transformation (SVT) framework of Gily\\'en, Su, Low, and Wiebe [STOC'19], we develop classical algorithms for SVT that run in time independent of input dimension, under suitable quantum-inspired sampling assumptions. Our results give compelling evidence that in the corresponding QRAM data structure input model, quantum SVT does not yield exponential quantum speedups. Since the quantum SVT framework generalizes essentially all known techniques for quantum linear algebra, our results, combined with sampling lemmas from previous work, suffice to generalize all recent results about dequantizing quantum machine learning algorithms. In particular, our classical SVT framework reco",
    "link": "http://arxiv.org/abs/1910.06151",
    "context": "Title: Sampling-based sublinear low-rank matrix arithmetic framework for dequantizing quantum machine learning. (arXiv:1910.06151v4 [cs.DS] UPDATED)\nAbstract: We present an algorithmic framework for quantum-inspired classical algorithms on close-to-low-rank matrices, generalizing the series of results started by Tang's breakthrough quantum-inspired algorithm for recommendation systems [STOC'19]. Motivated by quantum linear algebra algorithms and the quantum singular value transformation (SVT) framework of Gily\\'en, Su, Low, and Wiebe [STOC'19], we develop classical algorithms for SVT that run in time independent of input dimension, under suitable quantum-inspired sampling assumptions. Our results give compelling evidence that in the corresponding QRAM data structure input model, quantum SVT does not yield exponential quantum speedups. Since the quantum SVT framework generalizes essentially all known techniques for quantum linear algebra, our results, combined with sampling lemmas from previous work, suffice to generalize all recent results about dequantizing quantum machine learning algorithms. In particular, our classical SVT framework reco",
    "path": "papers/19/10/1910.06151.json",
    "total_tokens": 1039,
    "translated_title": "基于采样的亚线性低秩矩阵算法框架用于去量化量子机器学习",
    "translated_abstract": "我们提出了一个基于算法的框架，用于对接近低秩矩阵进行量子启发的经典算法，并且推广了Tang在推荐系统上的突破性量子启发算法的一系列结果[STOC'19]。受到量子线性代数算法和Gilyén、Su、Low和Wiebe [STOC'19]的量子奇异值变换（SVT）框架启发，我们开发了经典的SVT算法，在适当的量子启发抽样假设下，运行时间与输入维度无关。我们的结果提供了有力的证据，说明在相应的QRAM数据结构输入模型下，量子SVT并不产生指数级的量子加速。由于量子SVT框架基本上包含了所有已知的量子线性代数技术，我们的结果与前期工作中的采样引理结合起来，足以推广所有最近关于去量化量子机器学习算法的结果。",
    "tldr": "我们提出了一个基于采样的亚线性低秩矩阵算法框架，用于去量化量子机器学习，推广了Tang的量子启发算法的一系列结果。基于量子线性代数算法和量子奇异值变换框架，我们开发了经典的SVT算法，运行时间与输入维度无关，证明了量子SVT无法实现指数级的量子加速。我们的结果足以推广去量化量子机器学习算法的所有最近研究成果。",
    "en_tdlr": "We propose a sampling-based sublinear low-rank matrix arithmetic framework for dequantizing quantum machine learning, generalizing the series of results started by Tang's breakthrough quantum-inspired algorithm. Using quantum linear algebra algorithms and the quantum singular value transformation (SVT) framework, we develop classical SVT algorithms that run in time independent of input dimension, providing evidence that quantum SVT does not yield exponential quantum speedups. Our results generalize all recent research on dequantizing quantum machine learning algorithms."
}