{
    "title": "Recurrent Attention Walk for Semi-supervised Classification",
    "abstract": "arXiv:1910.10266v1 Announce Type: cross  Abstract: In this paper, we study the graph-based semi-supervised learning for classifying nodes in attributed networks, where the nodes and edges possess content information. Recent approaches like graph convolution networks and attention mechanisms have been proposed to ensemble the first-order neighbors and incorporate the relevant neighbors. However, it is costly (especially in memory) to consider all neighbors without a prior differentiation. We propose to explore the neighborhood in a reinforcement learning setting and find a walk path well-tuned for classifying the unlabelled target nodes. We let an agent (of node classification task) walk over the graph and decide where to direct to maximize classification accuracy. We define the graph walk as a partially observable Markov decision process (POMDP). The proposed method is flexible for working in both transductive and inductive setting. Extensive experiments on four datasets demonstrate th",
    "link": "https://arxiv.org/abs/1910.10266",
    "context": "Title: Recurrent Attention Walk for Semi-supervised Classification\nAbstract: arXiv:1910.10266v1 Announce Type: cross  Abstract: In this paper, we study the graph-based semi-supervised learning for classifying nodes in attributed networks, where the nodes and edges possess content information. Recent approaches like graph convolution networks and attention mechanisms have been proposed to ensemble the first-order neighbors and incorporate the relevant neighbors. However, it is costly (especially in memory) to consider all neighbors without a prior differentiation. We propose to explore the neighborhood in a reinforcement learning setting and find a walk path well-tuned for classifying the unlabelled target nodes. We let an agent (of node classification task) walk over the graph and decide where to direct to maximize classification accuracy. We define the graph walk as a partially observable Markov decision process (POMDP). The proposed method is flexible for working in both transductive and inductive setting. Extensive experiments on four datasets demonstrate th",
    "path": "papers/19/10/1910.10266.json",
    "total_tokens": 821,
    "translated_title": "基于循环注意力步行的半监督分类",
    "translated_abstract": "在本文中，我们研究了基于图的半监督学习，用于对带属性网络中的节点进行分类，其中节点和边都包含内容信息。最近的方法，如图卷积网络和注意力机制，已被提出来组合一阶邻居并整合相关邻居。然而，考虑所有邻居而不进行先前区分显得昂贵（尤其是在内存方面）。我们提出在强化学习设置中探索邻域，并找到一个经过调整以便对未标记目标节点进行分类的路径。我们让一个代理人（节点分类任务）在图上行走，并决定在哪里前进以最大化分类准确性。我们将图漫步定义为部分可观察的马尔可夫决策过程（POMDP）。所提出的方法灵活地适用于工作在转导和归纳设置中。对四个数据集的广泛实验证明了承认",
    "tldr": "本文提出了一种基于循环注意力步行的方法，使用强化学习设置来探索图中的邻域，找到适合分类未标记目标节点的路径。",
    "en_tdlr": "This paper proposes a method based on recurrent attention walk, utilizing a reinforcement learning setting to explore neighborhoods in a graph and find a path suitable for classifying unlabeled target nodes."
}