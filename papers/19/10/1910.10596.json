{
    "title": "Sparse Orthogonal Variational Inference for Gaussian Processes",
    "abstract": "arXiv:1910.10596v5 Announce Type: replace-cross  Abstract: We introduce a new interpretation of sparse variational approximations for Gaussian processes using inducing points, which can lead to more scalable algorithms than previous methods. It is based on decomposing a Gaussian process as a sum of two independent processes: one spanned by a finite basis of inducing points and the other capturing the remaining variation. We show that this formulation recovers existing approximations and at the same time allows to obtain tighter lower bounds on the marginal likelihood and new stochastic variational inference algorithms. We demonstrate the efficiency of these algorithms in several Gaussian process models ranging from standard regression to multi-class classification using (deep) convolutional Gaussian processes and report state-of-the-art results on CIFAR-10 among purely GP-based models.",
    "link": "https://arxiv.org/abs/1910.10596",
    "context": "Title: Sparse Orthogonal Variational Inference for Gaussian Processes\nAbstract: arXiv:1910.10596v5 Announce Type: replace-cross  Abstract: We introduce a new interpretation of sparse variational approximations for Gaussian processes using inducing points, which can lead to more scalable algorithms than previous methods. It is based on decomposing a Gaussian process as a sum of two independent processes: one spanned by a finite basis of inducing points and the other capturing the remaining variation. We show that this formulation recovers existing approximations and at the same time allows to obtain tighter lower bounds on the marginal likelihood and new stochastic variational inference algorithms. We demonstrate the efficiency of these algorithms in several Gaussian process models ranging from standard regression to multi-class classification using (deep) convolutional Gaussian processes and report state-of-the-art results on CIFAR-10 among purely GP-based models.",
    "path": "papers/19/10/1910.10596.json",
    "total_tokens": 757,
    "translated_title": "稀疏正交变分推断用于高斯过程",
    "translated_abstract": "我们介绍了一种新的稀疏变分逼近高斯过程的解释，使用感应点，这可以导致比先前方法更具可扩展性的算法。它基于将高斯过程分解为两个独立过程之和：一个由有限基感应点展开，另一个捕获剩余变化。我们展示了这种形式可恢复现有逼近，并同时允许获得更紧的边缘似然下界和新的随机变分推断算法。我们展示了这些算法在几种高斯过程模型中的效率，从标准回归到多类分类，使用(深度)卷积高斯过程，并在CIFAR-10上报告了纯GP模型中的最新结果。",
    "tldr": "介绍了一种使用感应点进行稀疏正交变分推断的新方法，可以得到更具可扩展性的算法，实现了更紧的边缘似然下界和新的随机变分推断算法",
    "en_tdlr": "Introduced a new approach of sparse orthogonal variational inference using inducing points, leading to more scalable algorithms, tighter lower bounds on marginal likelihood, and new stochastic variational inference algorithms"
}