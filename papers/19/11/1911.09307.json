{
    "title": "Patch-level Neighborhood Interpolation: A General and Effective Graph-based Regularization Strategy. (arXiv:1911.09307v2 [cs.LG] UPDATED)",
    "abstract": "Regularization plays a crucial role in machine learning models, especially for deep neural networks. The existing regularization techniques mainly rely on the i.i.d. assumption and only consider the knowledge from the current sample, without the leverage of the neighboring relationship between samples. In this work, we propose a general regularizer called \\textbf{Patch-level Neighborhood Interpolation~(Pani)} that conducts a non-local representation in the computation of networks. Our proposal explicitly constructs patch-level graphs in different layers and then linearly interpolates neighborhood patch features, serving as a general and effective regularization strategy. Further, we customize our approach into two kinds of popular regularization methods, namely Virtual Adversarial Training (VAT) and MixUp as well as its variants. The first derived \\textbf{Pani VAT} presents a novel way to construct non-local adversarial smoothness by employing patch-level interpolated perturbations. Th",
    "link": "http://arxiv.org/abs/1911.09307",
    "context": "Title: Patch-level Neighborhood Interpolation: A General and Effective Graph-based Regularization Strategy. (arXiv:1911.09307v2 [cs.LG] UPDATED)\nAbstract: Regularization plays a crucial role in machine learning models, especially for deep neural networks. The existing regularization techniques mainly rely on the i.i.d. assumption and only consider the knowledge from the current sample, without the leverage of the neighboring relationship between samples. In this work, we propose a general regularizer called \\textbf{Patch-level Neighborhood Interpolation~(Pani)} that conducts a non-local representation in the computation of networks. Our proposal explicitly constructs patch-level graphs in different layers and then linearly interpolates neighborhood patch features, serving as a general and effective regularization strategy. Further, we customize our approach into two kinds of popular regularization methods, namely Virtual Adversarial Training (VAT) and MixUp as well as its variants. The first derived \\textbf{Pani VAT} presents a novel way to construct non-local adversarial smoothness by employing patch-level interpolated perturbations. Th",
    "path": "papers/19/11/1911.09307.json",
    "total_tokens": 875,
    "translated_title": "Patch-level Neighborhood Interpolation: 一种通用且有效的基于图的正则化策略",
    "translated_abstract": "正则化对于机器学习模型尤其是深度神经网络非常重要。现有的正则化技术主要依赖于独立同分布假设，并且仅考虑当前样本的知识，没有利用样本之间的邻居关系。在这项工作中，我们提出了一种称为“Patch-level Neighborhood Interpolation（Pani）”的通用正则化器，在网络计算中进行非局部表示。我们的提议明确地构建了不同层次的补丁级图，然后线性插值邻域补丁特征，作为一种通用且有效的正则化策略。此外，我们将我们的方法定制为两种流行的正则化方法，即虚拟对抗训练（VAT）和MixUp以及其变体。首先派生的“Pani VAT”通过使用补丁级插值扰动构建非局部对抗平滑度，提出了一种新颖的方法。",
    "tldr": "这项工作提出了一种名为Pani的通用正则化器，它在深度神经网络中进行非局部表示，并将邻域补丁特征进行线性插值，从而构建了一种通用且有效的正则化策略。",
    "en_tdlr": "This work proposes a general regularizer called Pani that conducts non-local representation and linearly interpolates neighborhood patch features in deep neural networks, serving as a general and effective regularization strategy."
}