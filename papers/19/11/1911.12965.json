{
    "title": "Sparse and Low-Rank High-Order Tensor Regression via Parallel Proximal Method. (arXiv:1911.12965v2 [cs.LG] UPDATED)",
    "abstract": "Recently, tensor data (or multidimensional array) have been generated in many modern applications, such as functional magnetic resonance imaging (fMRI) in neuroscience and videos in video analysis. Many efforts are made in recent years to predict the relationship between tensor features and univariate responses. However, previously proposed methods either lose structural information within tensor data or have prohibitively expensive time costs, especially for large-scale data with high-order structures. To address such problems, we propose the Sparse and Low-rank Tensor Regression (SLTR) model. Our model enforces sparsity and low-rankness of the tensor coefficient by directly applying $\\ell_1$ norm and tensor nuclear norm, such that it preserves structural information of the tensor. To make the solving procedure scalable and efficient, SLTR makes use of the proximal gradient method, which can be easily implemented parallelly. We evaluate SLTR on several simulated datasets and one video",
    "link": "http://arxiv.org/abs/1911.12965",
    "context": "Title: Sparse and Low-Rank High-Order Tensor Regression via Parallel Proximal Method. (arXiv:1911.12965v2 [cs.LG] UPDATED)\nAbstract: Recently, tensor data (or multidimensional array) have been generated in many modern applications, such as functional magnetic resonance imaging (fMRI) in neuroscience and videos in video analysis. Many efforts are made in recent years to predict the relationship between tensor features and univariate responses. However, previously proposed methods either lose structural information within tensor data or have prohibitively expensive time costs, especially for large-scale data with high-order structures. To address such problems, we propose the Sparse and Low-rank Tensor Regression (SLTR) model. Our model enforces sparsity and low-rankness of the tensor coefficient by directly applying $\\ell_1$ norm and tensor nuclear norm, such that it preserves structural information of the tensor. To make the solving procedure scalable and efficient, SLTR makes use of the proximal gradient method, which can be easily implemented parallelly. We evaluate SLTR on several simulated datasets and one video",
    "path": "papers/19/11/1911.12965.json",
    "total_tokens": 923,
    "translated_title": "稀疏和低秩高阶张量回归通过并行近端方法",
    "translated_abstract": "在许多现代应用中生成了张量数据（或多维数组），例如神经科学中的功能性磁共振成像（fMRI）以及视频分析中的视频。近年来，针对预测张量特征与单变量响应之间的关系提出了许多方法。然而，以往的方法要么丢失了张量数据中的结构信息，要么在处理高阶结构的大规模数据时时间成本过高。为了解决这些问题，我们提出了稀疏和低秩张量回归（SLTR）模型。我们的模型通过直接应用$\\ell_1$范数和张量核范数来强制张量系数的稀疏性和低秩性，从而保留了张量的结构信息。为了使求解过程可扩展和高效，SLTR利用了近端梯度法，可以轻松地并行实现。我们在几个模拟数据集和一个视频数据集上评估了SLTR。",
    "tldr": "本论文提出了一种通过并行近端方法实现稀疏和低秩高阶张量回归的模型，该模型通过直接应用$\\ell_1$范数和张量核范数来保留张量的结构信息，并且在处理大规模数据和高阶结构时具有可扩展性和高效性。",
    "en_tdlr": "This paper proposes a model for sparse and low-rank high-order tensor regression via parallel proximal method, which preserves the structural information of the tensor by directly applying the $\\ell_1$ norm and tensor nuclear norm, and has scalability and efficiency in handling large-scale data and high-order structures."
}