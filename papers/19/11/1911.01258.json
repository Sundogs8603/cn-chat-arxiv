{
    "title": "SHARP: An Adaptable, Energy-Efficient Accelerator for Recurrent Neural Network. (arXiv:1911.01258v3 [cs.LG] UPDATED)",
    "abstract": "The effectiveness of Recurrent Neural Networks (RNNs) for tasks such as Automatic Speech Recognition has fostered interest in RNN inference acceleration. Due to the recurrent nature and data dependencies of RNN computations, prior work has designed customized architectures specifically tailored to the computation pattern of RNN, getting high computation efficiency for certain chosen model sizes. However, given that the dimensionality of RNNs varies a lot for different tasks, it is crucial to generalize this efficiency to diverse configurations. In this work, we identify adaptiveness as a key feature that is missing from today's RNN accelerators. In particular, we first show the problem of low resource-utilization and low adaptiveness for the state-of-the-art RNN implementations on GPU, FPGA and ASIC architectures. To solve these issues, we propose an intelligent tiled-based dispatching mechanism for increasing the adaptiveness of RNN computation, in order to efficiently handle the data",
    "link": "http://arxiv.org/abs/1911.01258",
    "context": "Title: SHARP: An Adaptable, Energy-Efficient Accelerator for Recurrent Neural Network. (arXiv:1911.01258v3 [cs.LG] UPDATED)\nAbstract: The effectiveness of Recurrent Neural Networks (RNNs) for tasks such as Automatic Speech Recognition has fostered interest in RNN inference acceleration. Due to the recurrent nature and data dependencies of RNN computations, prior work has designed customized architectures specifically tailored to the computation pattern of RNN, getting high computation efficiency for certain chosen model sizes. However, given that the dimensionality of RNNs varies a lot for different tasks, it is crucial to generalize this efficiency to diverse configurations. In this work, we identify adaptiveness as a key feature that is missing from today's RNN accelerators. In particular, we first show the problem of low resource-utilization and low adaptiveness for the state-of-the-art RNN implementations on GPU, FPGA and ASIC architectures. To solve these issues, we propose an intelligent tiled-based dispatching mechanism for increasing the adaptiveness of RNN computation, in order to efficiently handle the data",
    "path": "papers/19/11/1911.01258.json",
    "total_tokens": 856,
    "translated_title": "SHARP：一种适应性和节能型的循环神经网络加速器",
    "translated_abstract": "循环神经网络（RNN）在自动语音识别等任务中的有效性引发了对RNN推理加速的兴趣。由于RNN计算的递归性和数据依赖性，先前的工作设计了专门针对RNN计算模式的定制化架构，为某些选择的模型大小获得了高计算效率。然而，鉴于RNN的维度对于不同任务变化很大，将这种效率推广到各种不同配置非常关键。在这项工作中，我们认为适应性是当今RNN加速器所缺少的关键特征。特别地，我们首先显示了现有的GPU、FPGA和ASIC架构的最新RNN实现在资源利用率和适应性方面存在问题。为了解决这些问题，我们提出了一种智能的基于瓦片的分派机制，以增加RNN计算的适应性，以便有效地处理数据。",
    "tldr": "论文提出了一种适应性和节能型的循环神经网络加速器，通过智能的瓦片分派机制，实现了处理不同RNN维度的高计算效率。"
}