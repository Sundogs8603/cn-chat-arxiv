{
    "title": "Copula Representations and Error Surface Projections for the Exclusive Or Problem. (arXiv:1907.04483v2 [cs.LG] UPDATED)",
    "abstract": "The exclusive or (xor) function is one of the simplest examples that illustrate why nonlinear feedforward networks are superior to linear regression for machine learning applications. We review the xor representation and approximation problems and discuss their solutions in terms of probabilistic logic and associative copula functions. After briefly reviewing the specification of feedforward networks, we compare the dynamics of learned error surfaces with different activation functions such as RELU and tanh through a set of colorful three-dimensional charts. The copula representations extend xor from Boolean to real values, thereby providing a convenient way to demonstrate the concept of cross-validation on in-sample and out-sample data sets. Our approach is pedagogical and is meant to be a machine learning prolegomenon.",
    "link": "http://arxiv.org/abs/1907.04483",
    "context": "Title: Copula Representations and Error Surface Projections for the Exclusive Or Problem. (arXiv:1907.04483v2 [cs.LG] UPDATED)\nAbstract: The exclusive or (xor) function is one of the simplest examples that illustrate why nonlinear feedforward networks are superior to linear regression for machine learning applications. We review the xor representation and approximation problems and discuss their solutions in terms of probabilistic logic and associative copula functions. After briefly reviewing the specification of feedforward networks, we compare the dynamics of learned error surfaces with different activation functions such as RELU and tanh through a set of colorful three-dimensional charts. The copula representations extend xor from Boolean to real values, thereby providing a convenient way to demonstrate the concept of cross-validation on in-sample and out-sample data sets. Our approach is pedagogical and is meant to be a machine learning prolegomenon.",
    "path": "papers/19/07/1907.04483.json",
    "total_tokens": 812,
    "translated_title": "Copula表示和误差面投影对于异或问题的应用",
    "translated_abstract": "异或（xor）函数是展示为什么非线性前馈网络在机器学习应用中优于线性回归的最简单的示例之一。我们通过概率逻辑和关联Copula函数讨论了xor表示和逼近问题及其解决方案。在简要回顾前馈网络规范之后，我们通过一组色彩丰富的三维图表比较了使用RELU和tanh等不同激活函数的学习误差面的动态。Copula表示将xor从布尔值扩展到实数值，从而提供了一种方便的方式来演示在样本内和样本外数据集上的交叉验证的概念。我们的方法是教学性的，旨在成为机器学习导论。",
    "tldr": "本研究讨论了通过概率逻辑和关联Copula函数解决异或表示和逼近问题的方法，并通过比较不同激活函数下的误差面动态来说明其优势。通过将xor表示从布尔值扩展到实数值，我们提供了一种演示交叉验证概念的方便方式。",
    "en_tdlr": "This study discusses the solution of xor representation and approximation problems using probabilistic logic and associative copula functions, and illustrates its advantages by comparing the dynamics of error surfaces with different activation functions. By extending xor representation from Boolean to real values, a convenient way to demonstrate the concept of cross-validation is provided."
}