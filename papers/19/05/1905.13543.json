{
    "title": "DDPNAS: Efficient Neural Architecture Search via Dynamic Distribution Pruning. (arXiv:1905.13543v3 [cs.CV] UPDATED)",
    "abstract": "Neural Architecture Search (NAS) has demonstrated state-of-the-art performance on various computer vision tasks. Despite the superior performance achieved, the efficiency and generality of existing methods are highly valued due to their high computational complexity and low generality. In this paper, we propose an efficient and unified NAS framework termed DDPNAS via dynamic distribution pruning, facilitating a theoretical bound on accuracy and efficiency. In particular, we first sample architectures from a joint categorical distribution. Then the search space is dynamically pruned and its distribution is updated every few epochs. With the proposed efficient network generation method, we directly obtain the optimal neural architectures on given constraints, which is practical for on-device models across diverse search spaces and constraints. The architectures searched by our method achieve remarkable top-1 accuracies, 97.56 and 77.2 on CIFAR-10 and ImageNet (mobile settings), respectiv",
    "link": "http://arxiv.org/abs/1905.13543",
    "raw_ret": "{\n    \"translated_title\": \"DDPNAS: 通过动态分布裁剪实现高效的神经架构搜索\",\n    \"translated_abstract\": \"神经架构搜索（NAS）已经在各种计算机视觉任务上展现出了最先进的性能。尽管取得了优异的性能，但由于计算复杂度高且泛化性差，现有方法的效率和通用性受到高度重视。本文提出了一种称为DDPNAS的高效且统一的NAS框架，通过动态分布裁剪来促进精确度和效率的理论边界。具体而言，我们首先从联合分类分布中对体系结构进行采样。然后，搜索空间被动态裁剪，其分布每隔几个时期更新一次。通过所提出的高效网络生成方法，我们直接获得给定约束条件下的最优神经结构，这对于跨不同搜索空间和约束条件的设备上的模型非常实用。我们的方法搜索到的架构在CIFAR-10和ImageNet（移动设置）上实现了显着的top-1准确性，分别为97.56和77.2。\",\n    \"tldr\": \"本文提出了一种高效的神经架构搜索方法DDPNAS，通过动态分布裁剪来促进精确度和效率的理论边界，实现了在给定约束条件下的最优神经结构的直接获取，能够跨不同搜索空间和约束条件的设备上的模型实现显着的top-1准确性。\"\n}",
    "total_tokens": 901,
    "ret": {
        "translated_title": "DDPNAS: 通过动态分布裁剪实现高效的神经架构搜索",
        "translated_abstract": "神经架构搜索（NAS）已经在各种计算机视觉任务上展现出了最先进的性能。尽管取得了优异的性能，但由于计算复杂度高且泛化性差，现有方法的效率和通用性受到高度重视。本文提出了一种称为DDPNAS的高效且统一的NAS框架，通过动态分布裁剪来促进精确度和效率的理论边界。具体而言，我们首先从联合分类分布中对体系结构进行采样。然后，搜索空间被动态裁剪，其分布每隔几个时期更新一次。通过所提出的高效网络生成方法，我们直接获得给定约束条件下的最优神经结构，这对于跨不同搜索空间和约束条件的设备上的模型非常实用。我们的方法搜索到的架构在CIFAR-10和ImageNet（移动设置）上实现了显着的top-1准确性，分别为97.56和77.2。",
        "tldr": "本文提出了一种高效的神经架构搜索方法DDPNAS，通过动态分布裁剪来促进精确度和效率的理论边界，实现了在给定约束条件下的最优神经结构的直接获取，能够跨不同搜索空间和约束条件的设备上的模型实现显着的top-1准确性。"
    }
}