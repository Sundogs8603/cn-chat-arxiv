{
    "title": "Randomized Exploration in Generalized Linear Bandits. (arXiv:1906.08947v3 [cs.LG] UPDATED)",
    "abstract": "We study two randomized algorithms for generalized linear bandits. The first, GLM-TSL, samples a generalized linear model (GLM) from the Laplace approximation to the posterior distribution. The second, GLM-FPL, fits a GLM to a randomly perturbed history of past rewards. We analyze both algorithms and derive $\\tilde{O}(d \\sqrt{n \\log K})$ upper bounds on their $n$-round regret, where $d$ is the number of features and $K$ is the number of arms. The former improves on prior work while the latter is the first for Gaussian noise perturbations in non-linear models. We empirically evaluate both GLM-TSL and GLM-FPL in logistic bandits, and apply GLM-FPL to neural network bandits. Our work showcases the role of randomization, beyond posterior sampling, in exploration.",
    "link": "http://arxiv.org/abs/1906.08947",
    "context": "Title: Randomized Exploration in Generalized Linear Bandits. (arXiv:1906.08947v3 [cs.LG] UPDATED)\nAbstract: We study two randomized algorithms for generalized linear bandits. The first, GLM-TSL, samples a generalized linear model (GLM) from the Laplace approximation to the posterior distribution. The second, GLM-FPL, fits a GLM to a randomly perturbed history of past rewards. We analyze both algorithms and derive $\\tilde{O}(d \\sqrt{n \\log K})$ upper bounds on their $n$-round regret, where $d$ is the number of features and $K$ is the number of arms. The former improves on prior work while the latter is the first for Gaussian noise perturbations in non-linear models. We empirically evaluate both GLM-TSL and GLM-FPL in logistic bandits, and apply GLM-FPL to neural network bandits. Our work showcases the role of randomization, beyond posterior sampling, in exploration.",
    "path": "papers/19/06/1906.08947.json",
    "total_tokens": 1095,
    "translated_title": "在广义线性赌臂问题中的随机探索",
    "translated_abstract": "我们研究了两种广义线性赌臂问题的随机算法。第一种算法GLM-TSL从后验分布的拉普拉斯拟合中采样广义线性模型(GLM)。第二种算法GLM-FPL将一个广义线性模型拟合到过去奖励的随机扰动历史中。我们分析了这两种算法，并得出了它们在n轮中遗憾上界$\\tilde{O}(d \\sqrt{n \\log K})$，其中$d$是特征的数量，$K$是臂的数量。前者改进了先前的工作，而后者是非线性模型中高斯噪声扰动的首次尝试。我们在逻辑赌臂问题中对GLM-TSL和GLM-FPL进行了实证评估，并将GLM-FPL应用于神经网络赌臂问题。我们的工作展示了探索中随机化的作用，不仅仅是后验采样。",
    "tldr": "本文研究了广义线性赌臂问题中的两种随机算法，GLM-TSL和GLM-FPL。GLM-TSL从后验分布中采样广义线性模型，GLM-FPL则将广义线性模型拟合到过去奖励的随机扰动历史中。我们分析了这两种算法并得出了它们的遗憾上界，此前的工作中的遗憾上界得到了改进，并且对于非线性模型中的高斯噪声扰动问题，GLM-FPL是首次尝试。我们在逻辑赌臂问题和神经网络赌臂问题上对这两种算法进行了实证评估。这项工作展示了随机化在探索中的作用，超越了仅仅进行后验采样。",
    "en_tdlr": "This paper examines two randomized algorithms, GLM-TSL and GLM-FPL, for generalized linear bandits. GLM-TSL samples from the posterior distribution and GLM-FPL fits a generalized linear model to a randomly perturbed history of past rewards. The regret bounds for both algorithms are analyzed and improved upon prior work, with GLM-FPL being the first attempt for Gaussian noise perturbations in non-linear models. Empirical evaluations on logistic bandits and neural network bandits further demonstrate the role of randomization in exploration beyond posterior sampling."
}