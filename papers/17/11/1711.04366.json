{
    "title": "A unified framework for hard and soft clustering with regularized optimal transport",
    "abstract": "arXiv:1711.04366v2 Announce Type: replace  Abstract: In this paper, we formulate the problem of inferring a Finite Mixture Model from discrete data as an optimal transport problem with entropic regularization of parameter $\\lambda\\geq 0$. Our method unifies hard and soft clustering, the Expectation-Maximization (EM) algorithm being exactly recovered for $\\lambda=1$. The family of clustering algorithm we propose rely on the resolution of nonconvex problems using alternating minimization. We study the convergence property of our generalized $\\lambda-$EM algorithms and show that each step in the minimization process has a closed form solution when inferring finite mixture models of exponential families. Experiments highlight the benefits of taking a parameter $\\lambda>1$ to improve the inference performance and $\\lambda\\to 0$ for classification.",
    "link": "https://arxiv.org/abs/1711.04366",
    "context": "Title: A unified framework for hard and soft clustering with regularized optimal transport\nAbstract: arXiv:1711.04366v2 Announce Type: replace  Abstract: In this paper, we formulate the problem of inferring a Finite Mixture Model from discrete data as an optimal transport problem with entropic regularization of parameter $\\lambda\\geq 0$. Our method unifies hard and soft clustering, the Expectation-Maximization (EM) algorithm being exactly recovered for $\\lambda=1$. The family of clustering algorithm we propose rely on the resolution of nonconvex problems using alternating minimization. We study the convergence property of our generalized $\\lambda-$EM algorithms and show that each step in the minimization process has a closed form solution when inferring finite mixture models of exponential families. Experiments highlight the benefits of taking a parameter $\\lambda>1$ to improve the inference performance and $\\lambda\\to 0$ for classification.",
    "path": "papers/17/11/1711.04366.json",
    "total_tokens": 856,
    "translated_title": "一个带有正则化最优输运的硬聚类和软聚类统一框架",
    "translated_abstract": "在这篇论文中，我们将从离散数据推断有限混合模型的问题阐述为一个带有参数$\\lambda\\geq 0$的熵正则化的最优输运问题。我们的方法统一了硬聚类和软聚类，当$\\lambda=1$时，期望最大化（EM）算法被完全恢复。我们提出的聚类算法族依赖于使用交替最小化来解决非凸问题。我们研究了我们的广义$\\lambda$-EM算法的收敛性质，并展示了在推断指数族有限混合模型时，最小化过程中的每一步都有一个封闭形式的解。实验突出了采用参数$\\lambda>1$来提高推断性能以及$\\lambda\\to 0$用于分类的好处。",
    "tldr": "这个方法提出了一个统一的框架，将离散数据推断有限混合模型的问题建模为带有正则化最优输运的问题，同时在聚类中融合了硬聚类和软聚类，并且实验证明当参数$\\lambda>1$时可以提高推断性能，当$\\lambda\\to 0$时适用于分类。",
    "en_tdlr": "This paper presents a unified framework that formulates the problem of inferring Finite Mixture Models from discrete data as an optimal transport problem with regularization, unifying hard and soft clustering, with experiments showing the benefits of using parameter $\\lambda>1$ for improved inference performance and $\\lambda\\to 0$ for classification."
}