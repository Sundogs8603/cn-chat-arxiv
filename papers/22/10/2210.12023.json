{
    "title": "A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models. (arXiv:2210.12023v3 [cs.CL] UPDATED)",
    "abstract": "We have recently witnessed a number of impressive results on hard mathematical reasoning problems with language models. At the same time, the robustness of these models has also been called into question; recent works have shown that models can rely on shallow patterns in the problem description when generating a solution. Building on the idea of behavioral testing, we propose a novel framework, which pins down the causal effect of various factors in the input, e.g., the surface form of the problem text, the operands, and math operators on the output solution. By grounding the behavioral analysis in a causal graph describing an intuitive reasoning process, we study the behavior of language models in terms of robustness and sensitivity to direct interventions in the input space. We apply our framework on a test bed of math word problems. Our analysis shows that robustness does not appear to continuously improve as a function of size, but the GPT-3 Davinci models (175B) achieve a dramati",
    "link": "http://arxiv.org/abs/2210.12023",
    "context": "Title: A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models. (arXiv:2210.12023v3 [cs.CL] UPDATED)\nAbstract: We have recently witnessed a number of impressive results on hard mathematical reasoning problems with language models. At the same time, the robustness of these models has also been called into question; recent works have shown that models can rely on shallow patterns in the problem description when generating a solution. Building on the idea of behavioral testing, we propose a novel framework, which pins down the causal effect of various factors in the input, e.g., the surface form of the problem text, the operands, and math operators on the output solution. By grounding the behavioral analysis in a causal graph describing an intuitive reasoning process, we study the behavior of language models in terms of robustness and sensitivity to direct interventions in the input space. We apply our framework on a test bed of math word problems. Our analysis shows that robustness does not appear to continuously improve as a function of size, but the GPT-3 Davinci models (175B) achieve a dramati",
    "path": "papers/22/10/2210.12023.json",
    "total_tokens": 1027,
    "translated_title": "一种量化语言模型数学推理鲁棒性的因果框架",
    "translated_abstract": "最近，语言模型在解决困难数学推理问题方面取得了一些令人印象深刻的成果，同时，这些模型的鲁棒性也备受质疑。最近的研究表明，当生成解决方案时，模型可能会依赖于问题描述中的浅层模式。我们提出了一个新的框架，建立在行为测试的思想基础上，它能够确定输入中各种因素，例如问题文本的表面形式、操作数和数学运算符对输出解决方案的因果影响。通过在直观推理过程中描述因果图，将行为分析根据鲁棒性和对输入空间的直接干预敏感性研究语言模型的行为。我们将这个框架应用于数学题的测试中。我们的分析显示，鲁棒性似乎并不会随着模型大小的增加而不断改善，但与较小的模型相比，GPT-3 Davinci模型（175B）在鲁棒性方面取得了显着改善。我们提供了一种系统而可解释的方法来理解语言模型在数学推理任务中的行为。",
    "tldr": "该研究提出了一种基于因果框架的新方法，用于确定语言模型在数学推理任务中各种因素对输出解决方案的因果影响，研究结果显示GPT-3 Davinci模型（175B）在鲁棒性方面取得了显着改善。",
    "en_tdlr": "This study proposes a novel causal framework to quantify the causal effect of various factors in mathematical reasoning tasks on the output solution of language models, and shows that the GPT-3 Davinci models (175B) achieve a significant improvement in robustness."
}