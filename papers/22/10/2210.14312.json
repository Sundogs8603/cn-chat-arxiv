{
    "title": "JAX-DIPS: Neural bootstrapping of finite discretization methods and application to elliptic problems with discontinuities. (arXiv:2210.14312v2 [math.NA] UPDATED)",
    "abstract": "We present a scalable strategy for development of mesh-free hybrid neuro-symbolic partial differential equation solvers based on existing mesh-based numerical discretization methods. Particularly, this strategy can be used to efficiently train neural network surrogate models of partial differential equations by (i) leveraging the accuracy and convergence properties of advanced numerical methods, solvers, and preconditioners, as well as (ii) better scalability to higher order PDEs by strictly limiting optimization to first order automatic differentiation. The presented neural bootstrapping method (hereby dubbed NBM) is based on evaluation of the finite discretization residuals of the PDE system obtained on implicit Cartesian cells centered on a set of random collocation points with respect to trainable parameters of the neural network. Importantly, the conservation laws and symmetries present in the bootstrapped finite discretization equations inform the neural network about solution re",
    "link": "http://arxiv.org/abs/2210.14312",
    "context": "Title: JAX-DIPS: Neural bootstrapping of finite discretization methods and application to elliptic problems with discontinuities. (arXiv:2210.14312v2 [math.NA] UPDATED)\nAbstract: We present a scalable strategy for development of mesh-free hybrid neuro-symbolic partial differential equation solvers based on existing mesh-based numerical discretization methods. Particularly, this strategy can be used to efficiently train neural network surrogate models of partial differential equations by (i) leveraging the accuracy and convergence properties of advanced numerical methods, solvers, and preconditioners, as well as (ii) better scalability to higher order PDEs by strictly limiting optimization to first order automatic differentiation. The presented neural bootstrapping method (hereby dubbed NBM) is based on evaluation of the finite discretization residuals of the PDE system obtained on implicit Cartesian cells centered on a set of random collocation points with respect to trainable parameters of the neural network. Importantly, the conservation laws and symmetries present in the bootstrapped finite discretization equations inform the neural network about solution re",
    "path": "papers/22/10/2210.14312.json",
    "total_tokens": 870,
    "translated_title": "JAX-DIPS：有限离散方法的神经引导法及其在具有间断的椭圆问题中的应用",
    "translated_abstract": "我们提出了一种可伸缩的策略，用于基于现有基于网格的数值离散方法开发无网格混合神经符号偏微分方程求解器。特别是，这种策略可以通过（i）利用先进数值方法、求解器和预处理器的准确性和收敛性以及（ii）将优化限制在一阶自动微分上，以更高效地训练偏微分方程的神经网络代理模型。所提出的神经引导方法（以下简称NBM）基于相对于神经网络的可训练参数的随机取样点上隐式笛卡尔单元格上获得的PDE系统的有限离散残差的评估。值得注意的是，引导有限离散方程中存在的守恒定律和对称性能够向神经网络提供有关解的信息。",
    "tldr": "JAX-DIPS是一种基于有限离散方法和神经网络的可伸缩策略，用于开发无网格混合神经符号偏微分方程求解器，并在具有间断的椭圆问题中得到应用。",
    "en_tdlr": "JAX-DIPS is a scalable strategy that combines finite discretization methods with neural networks to develop mesh-free hybrid neuro-symbolic partial differential equation solvers, with applications in elliptic problems with discontinuities."
}