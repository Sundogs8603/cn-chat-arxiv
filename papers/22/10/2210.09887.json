{
    "title": "MotionDeltaCNN: Sparse CNN Inference of Frame Differences in Moving Camera Videos. (arXiv:2210.09887v4 [cs.CV] UPDATED)",
    "abstract": "Convolutional neural network inference on video input is computationally expensive and requires high memory bandwidth. Recently, DeltaCNN managed to reduce the cost by only processing pixels with significant updates over the previous frame. However, DeltaCNN relies on static camera input. Moving cameras add new challenges in how to fuse newly unveiled image regions with already processed regions efficiently to minimize the update rate - without increasing memory overhead and without knowing the camera extrinsics of future frames. In this work, we propose MotionDeltaCNN, a sparse CNN inference framework that supports moving cameras. We introduce spherical buffers and padded convolutions to enable seamless fusion of newly unveiled regions and previously processed regions -- without increasing memory footprint. Our evaluation shows that we outperform DeltaCNN by up to 90% for moving camera videos.",
    "link": "http://arxiv.org/abs/2210.09887",
    "context": "Title: MotionDeltaCNN: Sparse CNN Inference of Frame Differences in Moving Camera Videos. (arXiv:2210.09887v4 [cs.CV] UPDATED)\nAbstract: Convolutional neural network inference on video input is computationally expensive and requires high memory bandwidth. Recently, DeltaCNN managed to reduce the cost by only processing pixels with significant updates over the previous frame. However, DeltaCNN relies on static camera input. Moving cameras add new challenges in how to fuse newly unveiled image regions with already processed regions efficiently to minimize the update rate - without increasing memory overhead and without knowing the camera extrinsics of future frames. In this work, we propose MotionDeltaCNN, a sparse CNN inference framework that supports moving cameras. We introduce spherical buffers and padded convolutions to enable seamless fusion of newly unveiled regions and previously processed regions -- without increasing memory footprint. Our evaluation shows that we outperform DeltaCNN by up to 90% for moving camera videos.",
    "path": "papers/22/10/2210.09887.json",
    "total_tokens": 921,
    "translated_title": "MotionDeltaCNN：移动摄像机视频中稀疏CNN对帧差异的推断",
    "translated_abstract": "在视频输入上进行卷积神经网络推断计算代价高昂，并且需要高内存带宽。最近，DeltaCNN通过仅处理与上一帧相比有显著更新的像素来减少成本。然而，DeltaCNN依赖于静态摄像机输入。移动摄像机给如何高效融合新揭示的图像区域与已处理区域带来了新的挑战，以最小化更新率 - 同时不增加内存开销且无需知道未来帧的摄像机外参数。在这项工作中，我们提出了MotionDeltaCNN，这是一个支持移动摄像机的稀疏CNN推断框架。我们引入了球面缓冲区和填充卷积，以便无缝融合新揭示的区域和以前处理的区域 - 同时不增加内存占用。我们的评估结果表明，对于移动摄像头视频，我们的性能超过DeltaCNN多达90%。",
    "tldr": "本文提出了MotionDeltaCNN，一个支持移动摄像机的稀疏CNN推断框架，通过引入球面缓冲区和填充卷积来高效融合新揭示的图像区域和已处理区域，从而实现对帧差异的推断。在移动摄像机视频中，相对于DeltaCNN，我们的方法性能提升了高达90%。"
}