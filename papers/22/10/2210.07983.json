{
    "title": "Improving Transfer Learning with a Dual Image and Video Transformer for Multi-label Movie Trailer Genre Classification. (arXiv:2210.07983v4 [cs.CV] UPDATED)",
    "abstract": "In this paper, we study the transferability of ImageNet spatial and Kinetics spatio-temporal representations to multi-label Movie Trailer Genre Classification (MTGC). In particular, we present an extensive evaluation of the transferability of ConvNet and Transformer models pretrained on ImageNet and Kinetics to Trailers12k, a new manually-curated movie trailer dataset composed of 12,000 videos labeled with 10 different genres and associated metadata. We analyze different aspects that can influence transferability, such as frame rate, input video extension, and spatio-temporal modeling. In order to reduce the spatio-temporal structure gap between ImageNet/Kinetics and Trailers12k, we propose Dual Image and Video Transformer Architecture (DIViTA), which performs shot detection so as to segment the trailer into highly correlated clips, providing a more cohesive input for pretrained backbones and improving transferability (a 1.83% increase for ImageNet and 3.75% for Kinetics). Our results ",
    "link": "http://arxiv.org/abs/2210.07983",
    "context": "Title: Improving Transfer Learning with a Dual Image and Video Transformer for Multi-label Movie Trailer Genre Classification. (arXiv:2210.07983v4 [cs.CV] UPDATED)\nAbstract: In this paper, we study the transferability of ImageNet spatial and Kinetics spatio-temporal representations to multi-label Movie Trailer Genre Classification (MTGC). In particular, we present an extensive evaluation of the transferability of ConvNet and Transformer models pretrained on ImageNet and Kinetics to Trailers12k, a new manually-curated movie trailer dataset composed of 12,000 videos labeled with 10 different genres and associated metadata. We analyze different aspects that can influence transferability, such as frame rate, input video extension, and spatio-temporal modeling. In order to reduce the spatio-temporal structure gap between ImageNet/Kinetics and Trailers12k, we propose Dual Image and Video Transformer Architecture (DIViTA), which performs shot detection so as to segment the trailer into highly correlated clips, providing a more cohesive input for pretrained backbones and improving transferability (a 1.83% increase for ImageNet and 3.75% for Kinetics). Our results ",
    "path": "papers/22/10/2210.07983.json",
    "total_tokens": 890,
    "translated_title": "双重图像和视频Transformer的应用在多标签电影预告片类型分类中，提升了迁移学习",
    "translated_abstract": "本文研究了ImageNet空间和Kinetics时空表示对于多标签电影预告片类型分类（MTGC）的可迁移性。我们评估了在ImageNet和Kinetics预先训练的ConvNet和Transformer模型的可迁移性，并在Trailers12k上进行了展示，Trailers12k是一个由12,000个视频组成的手工标注的电影预告片数据集，并带有10种不同的类型和相关元数据的标签。我们分析了可以影响可迁移性的不同方面，例如帧率，输入视频扩展和时空建模。为了缩小ImageNet/Kinetics和Trailers12k之间的时空结构差距，我们提出了Dual Image and Video Transformer Architecture (DIViTA)，该架构执行拍摄检测，将预告片分割成高度相关的片段，为预先训练的骨干提供更连贯的输入，提高了可迁移性（ImageNet提高了1.83%，Kinetics提高了3.75%）。我们的结果...",
    "tldr": "本文研究了ImageNet和Kinetics预先训练的模型在多标签电影预告片类型分类中的可迁移性，通过Dual Image and Video Transformer Architecture提高了可迁移性。",
    "en_tdlr": "The paper studies the transferability of ImageNet and Kinetics pre-trained models in multi-label movie trailer genre classification, and proposes the Dual Image and Video Transformer Architecture to improve transferability."
}