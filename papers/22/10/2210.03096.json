{
    "title": "Accelerated Single-Call Methods for Constrained Min-Max Optimization. (arXiv:2210.03096v2 [math.OC] UPDATED)",
    "abstract": "We study first-order methods for constrained min-max optimization. Existing methods either require two gradient calls or two projections in each iteration, which may be costly in some applications. In this paper, we first show that a variant of the Optimistic Gradient (OG) method, a single-call single-projection algorithm, has $O(\\frac{1}{\\sqrt{T}})$ best-iterate convergence rate for inclusion problems with operators that satisfy the weak Minty variation inequality (MVI). Our second result is the first single-call single-projection algorithm -- the Accelerated Reflected Gradient (ARG) method that achieves the optimal $O(\\frac{1}{T})$ last-iterate convergence rate for inclusion problems that satisfy negative comonotonicity. Both the weak MVI and negative comonotonicity are well-studied assumptions and capture a rich set of non-convex non-concave min-max optimization problems. Finally, we show that the Reflected Gradient (RG) method, another single-call single-projection algorithm, has $",
    "link": "http://arxiv.org/abs/2210.03096",
    "context": "Title: Accelerated Single-Call Methods for Constrained Min-Max Optimization. (arXiv:2210.03096v2 [math.OC] UPDATED)\nAbstract: We study first-order methods for constrained min-max optimization. Existing methods either require two gradient calls or two projections in each iteration, which may be costly in some applications. In this paper, we first show that a variant of the Optimistic Gradient (OG) method, a single-call single-projection algorithm, has $O(\\frac{1}{\\sqrt{T}})$ best-iterate convergence rate for inclusion problems with operators that satisfy the weak Minty variation inequality (MVI). Our second result is the first single-call single-projection algorithm -- the Accelerated Reflected Gradient (ARG) method that achieves the optimal $O(\\frac{1}{T})$ last-iterate convergence rate for inclusion problems that satisfy negative comonotonicity. Both the weak MVI and negative comonotonicity are well-studied assumptions and capture a rich set of non-convex non-concave min-max optimization problems. Finally, we show that the Reflected Gradient (RG) method, another single-call single-projection algorithm, has $",
    "path": "papers/22/10/2210.03096.json",
    "total_tokens": 1039,
    "translated_title": "加速受限制的最小-最大优化的单调用方法",
    "translated_abstract": "我们研究了约束最小-最大优化的一阶方法。现有方法每次迭代要求两个梯度调用或两个投影，这在某些应用中可能很昂贵。本文首先展示了一种乐观梯度方法的变种，即单次调用单次投影算法，对于满足弱Minty变分不等式（MVI）的包含问题，具有$O(\\frac{1}{\\sqrt{T}})$的最佳迭代收敛率。我们的第二个结果是第一个单调用单投影算法——加速反射梯度（ARG）方法，它对于满足负共同单调性的包含问题实现了最优的$O(\\frac{1}{T})$后式收敛率。弱MVI和负共同单调性都是深入研究过的假设，涵盖了一组丰富的非凸非凹最小-最大优化问题。最后，我们展示另一种单调用单投影算法——反射梯度（RG）方法，具有$O(\\frac{1}{\\sqrt{T}})$的最佳迭代收敛率，但需要两个投影。",
    "tldr": "本文提出了两种单调用单投影算法，分别是优化梯度方法和加速反射梯度方法，分别适用于满足弱Minty变分不等式和负共同单调性的包含问题，可以加速最小-最大优化，并分别取得了$O(\\frac{1}{\\sqrt{T}})$和$O(\\frac{1}{T})$的收敛率。",
    "en_tdlr": "This paper proposes two single-call single-projection algorithms, the Optimistic Gradient method and the Accelerated Reflected Gradient method, which are respectively applicable to inclusion problems satisfying the weak Minty variation inequality and negative comonotonicity, can accelerate min-max optimization, and achieve convergence rates of $O(\\frac{1}{\\sqrt{T}})$ and $O(\\frac{1}{T})$ respectively."
}