{
    "title": "Do We Need Explainable AI in Companies? Investigation of Challenges, Expectations, and Chances from Employees' Perspective. (arXiv:2210.03527v2 [cs.HC] UPDATED)",
    "abstract": "Companies' adoption of artificial intelligence (AI) is increasingly becoming an essential element of business success. However, using AI poses new requirements for companies and their employees, including transparency and comprehensibility of AI systems. The field of Explainable AI (XAI) aims to address these issues. Yet, the current research primarily consists of laboratory studies, and there is a need to improve the applicability of the findings to real-world situations. Therefore, this project report paper provides insights into employees' needs and attitudes towards (X)AI. For this, we investigate employees' perspectives on (X)AI. Our findings suggest that AI and XAI are well-known terms perceived as important for employees. This recognition is a critical first step for XAI to potentially drive successful usage of AI by providing comprehensible insights into AI technologies. In a lessons-learned section, we discuss the open questions identified and suggest future research direction",
    "link": "http://arxiv.org/abs/2210.03527",
    "context": "Title: Do We Need Explainable AI in Companies? Investigation of Challenges, Expectations, and Chances from Employees' Perspective. (arXiv:2210.03527v2 [cs.HC] UPDATED)\nAbstract: Companies' adoption of artificial intelligence (AI) is increasingly becoming an essential element of business success. However, using AI poses new requirements for companies and their employees, including transparency and comprehensibility of AI systems. The field of Explainable AI (XAI) aims to address these issues. Yet, the current research primarily consists of laboratory studies, and there is a need to improve the applicability of the findings to real-world situations. Therefore, this project report paper provides insights into employees' needs and attitudes towards (X)AI. For this, we investigate employees' perspectives on (X)AI. Our findings suggest that AI and XAI are well-known terms perceived as important for employees. This recognition is a critical first step for XAI to potentially drive successful usage of AI by providing comprehensible insights into AI technologies. In a lessons-learned section, we discuss the open questions identified and suggest future research direction",
    "path": "papers/22/10/2210.03527.json",
    "total_tokens": 868,
    "translated_title": "公司需要可解释的人工智能吗？员工角度的挑战、期望和机会调查",
    "translated_abstract": "人工智能（AI）对于企业的采用越来越成为业务成功的必要元素。然而，使用 AI 提出了公司和其员工的新要求，包括 AI 系统的透明度和可理解性。可解释人工智能（XAI）领域旨在解决这些问题。然而，目前研究主要包括实验室研究，需要改进研究结果在实际情况下的适用性。因此，本研究提供了员工对（X）AI 需求和态度的见解。我们的研究发现，AI 和 XAI 是众所周知的术语，被认为对员工非常重要。这一认知是推动 AI 成功使用的关键第一步，为提供可理解的 AI 技术洞见做出贡献。在“教训学习”部分，我们讨论了发现的开放问题，并提出了未来的研究方向。",
    "tldr": "本论文探究员工对(X)AI的需求和态度。研究发现员工普遍认为解释性AI对公司的成功非常重要。",
    "en_tdlr": "This paper investigates employees' needs and attitudes towards (X)AI. The research finds that employees generally believe that explainable AI is critical to the success of companies."
}