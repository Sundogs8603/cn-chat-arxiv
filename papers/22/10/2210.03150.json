{
    "title": "Towards Out-of-Distribution Adversarial Robustness. (arXiv:2210.03150v4 [cs.LG] UPDATED)",
    "abstract": "Adversarial robustness continues to be a major challenge for deep learning. A core issue is that robustness to one type of attack often fails to transfer to other attacks. While prior work establishes a theoretical trade-off in robustness against different $L_p$ norms, we show that there is potential for improvement against many commonly used attacks by adopting a domain generalisation approach. Concretely, we treat each type of attack as a domain, and apply the Risk Extrapolation method (REx), which promotes similar levels of robustness against all training attacks. Compared to existing methods, we obtain similar or superior worst-case adversarial robustness on attacks seen during training. Moreover, we achieve superior performance on families or tunings of attacks only encountered at test time. On ensembles of attacks, our approach improves the accuracy from 3.4% with the best existing baseline to 25.9% on MNIST, and from 16.9% to 23.5% on CIFAR10.",
    "link": "http://arxiv.org/abs/2210.03150",
    "context": "Title: Towards Out-of-Distribution Adversarial Robustness. (arXiv:2210.03150v4 [cs.LG] UPDATED)\nAbstract: Adversarial robustness continues to be a major challenge for deep learning. A core issue is that robustness to one type of attack often fails to transfer to other attacks. While prior work establishes a theoretical trade-off in robustness against different $L_p$ norms, we show that there is potential for improvement against many commonly used attacks by adopting a domain generalisation approach. Concretely, we treat each type of attack as a domain, and apply the Risk Extrapolation method (REx), which promotes similar levels of robustness against all training attacks. Compared to existing methods, we obtain similar or superior worst-case adversarial robustness on attacks seen during training. Moreover, we achieve superior performance on families or tunings of attacks only encountered at test time. On ensembles of attacks, our approach improves the accuracy from 3.4% with the best existing baseline to 25.9% on MNIST, and from 16.9% to 23.5% on CIFAR10.",
    "path": "papers/22/10/2210.03150.json",
    "total_tokens": 962,
    "translated_title": "迈向面向OOD的对抗鲁棒性",
    "translated_abstract": "对抗鲁棒性仍然是深度学习的一个主要挑战。一个核心问题是对一种攻击的鲁棒性往往不能转移到其他攻击。我们展示了通过采用领域泛化方法，可以在许多常用攻击中改善鲁棒性。具体来说，我们将每种攻击视为一个领域，并应用风险外推方法（REx），促进对所有训练攻击的相似鲁棒水平。与现有方法相比，在训练期间看到的攻击上，我们获得类似或更高级别的最坏情况下的对抗鲁棒性。此外，在家族或测试时只遇到的攻击的调整中，我们实现了更高的性能。在攻击集合上，我们的方法将MNIST的最佳现有基线的准确性从3.4%提高到25.9％，在CIFAR10上从16.9％提高到23.5％。",
    "tldr": "该论文介绍了一种面向OOD的对抗鲁棒性方法，通过将每个攻击类型视为一个领域，应用风险外推方法实现对各攻击的相似鲁棒性水平，实现了在训练和测试时的更高性能，是对抗鲁棒性研究中的创新贡献。",
    "en_tdlr": "This paper introduces a method towards out-of-distribution adversarial robustness by treating each attack type as a domain and applying the Risk Extrapolation method to achieve similar levels of robustness against different attacks. This approach improves performance in training and testing on different attacks and makes significant contributions to the research of adversarial robustness."
}