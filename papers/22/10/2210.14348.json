{
    "title": "Synthetic Text Generation with Differential Privacy: A Simple and Practical Recipe. (arXiv:2210.14348v2 [cs.CL] UPDATED)",
    "abstract": "Privacy concerns have attracted increasing attention in data-driven products due to the tendency of machine learning models to memorize sensitive training data. Generating synthetic versions of such data with a formal privacy guarantee, such as differential privacy (DP), provides a promising path to mitigating these privacy concerns, but previous approaches in this direction have typically failed to produce synthetic data of high quality. In this work, we show that a simple and practical recipe in the text domain is effective: simply fine-tuning a pretrained generative language model with DP enables the model to generate useful synthetic text with strong privacy protection. Through extensive empirical analyses on both benchmark and private customer data, we demonstrate that our method produces synthetic text that is competitive in terms of utility with its non-private counterpart, meanwhile providing strong protection against potential privacy leakages.",
    "link": "http://arxiv.org/abs/2210.14348",
    "context": "Title: Synthetic Text Generation with Differential Privacy: A Simple and Practical Recipe. (arXiv:2210.14348v2 [cs.CL] UPDATED)\nAbstract: Privacy concerns have attracted increasing attention in data-driven products due to the tendency of machine learning models to memorize sensitive training data. Generating synthetic versions of such data with a formal privacy guarantee, such as differential privacy (DP), provides a promising path to mitigating these privacy concerns, but previous approaches in this direction have typically failed to produce synthetic data of high quality. In this work, we show that a simple and practical recipe in the text domain is effective: simply fine-tuning a pretrained generative language model with DP enables the model to generate useful synthetic text with strong privacy protection. Through extensive empirical analyses on both benchmark and private customer data, we demonstrate that our method produces synthetic text that is competitive in terms of utility with its non-private counterpart, meanwhile providing strong protection against potential privacy leakages.",
    "path": "papers/22/10/2210.14348.json",
    "total_tokens": 881,
    "translated_title": "差分隐私下的合成文本生成：一个简单而实用的方法",
    "translated_abstract": "随着机器学习模型对敏感数据的记忆倾向引起越来越多的关注，隐私问题成为数据驱动产品的重要关注点。生成具有形式隐私保证的合成数据，如差分隐私（DP），为缓解这些隐私问题提供了一个有前途的方向。但是，以往的指向此方向的方法通常未能生成高质量的合成数据。在这项工作中，我们展示了差分隐私下文本领域的一个简单实用的方法：通过对经过预训练的生成语言模型进行微调并加入DP，使模型能够生成具有强隐私保护的有用的合成文本。通过对基准数据和私人客户数据的广泛实证分析，我们证明了我们的方法能够生成具有与非隐私版本相似的实用性的合成文本，同时提供强大的隐私保护，避免潜在的隐私泄露。",
    "tldr": "该论文介绍了一种简单而实用的方法，使用差分隐私对预训练的生成语言模型进行微调，能够生成具有强隐私保护的高质量合成文本，并且与非隐私版本相似。",
    "en_tdlr": "This paper presents a simple and practical method of fine-tuning a pre-trained generative language model with differential privacy, which can generate high-quality synthetic text with strong privacy protection. The method produces synthetic text that is competitive in terms of utility with its non-private counterpart, while providing strong protection against potential privacy leakages."
}