{
    "title": "STAP: Sequencing Task-Agnostic Policies. (arXiv:2210.12250v3 [cs.RO] UPDATED)",
    "abstract": "Advances in robotic skill acquisition have made it possible to build general-purpose libraries of learned skills for downstream manipulation tasks. However, naively executing these skills one after the other is unlikely to succeed without accounting for dependencies between actions prevalent in long-horizon plans. We present Sequencing Task-Agnostic Policies (STAP), a scalable framework for training manipulation skills and coordinating their geometric dependencies at planning time to solve long-horizon tasks never seen by any skill during training. Given that Q-functions encode a measure of skill feasibility, we formulate an optimization problem to maximize the joint success of all skills sequenced in a plan, which we estimate by the product of their Q-values. Our experiments indicate that this objective function approximates ground truth plan feasibility and, when used as a planning objective, reduces myopic behavior and thereby promotes long-horizon task success. We further demonstra",
    "link": "http://arxiv.org/abs/2210.12250",
    "context": "Title: STAP: Sequencing Task-Agnostic Policies. (arXiv:2210.12250v3 [cs.RO] UPDATED)\nAbstract: Advances in robotic skill acquisition have made it possible to build general-purpose libraries of learned skills for downstream manipulation tasks. However, naively executing these skills one after the other is unlikely to succeed without accounting for dependencies between actions prevalent in long-horizon plans. We present Sequencing Task-Agnostic Policies (STAP), a scalable framework for training manipulation skills and coordinating their geometric dependencies at planning time to solve long-horizon tasks never seen by any skill during training. Given that Q-functions encode a measure of skill feasibility, we formulate an optimization problem to maximize the joint success of all skills sequenced in a plan, which we estimate by the product of their Q-values. Our experiments indicate that this objective function approximates ground truth plan feasibility and, when used as a planning objective, reduces myopic behavior and thereby promotes long-horizon task success. We further demonstra",
    "path": "papers/22/10/2210.12250.json",
    "total_tokens": 905,
    "translated_title": "STAP: 序列化任务无关策略",
    "translated_abstract": "机器人技能获取的进步使构建下游操纵任务通用的学习技能库成为可能。然而，单纯地执行这些技能进行任务总会失败，因为它没有考虑到长远计划中普遍存在的动作依赖关系。我们提出了一种名为STAP的可扩展框架，用于训练操作技能和在规划时协调它们的几何依赖关系，以解决任何技能在训练期间都没有见过的长远任务。鉴于Q函数编码了技能可行性的度量，我们制定了一个优化问题，最大化所有技能联合成功的计划序列中的成功，并通过它们的Q值的乘积来估计。我们的实验表明，该目标函数近似于实现计划的可能性，当用作规划目标时，能减少近视行为，从而促进长远任务的成功。我们进一步展示了STAP在多个任务和机器人平台上的有效性和可伸缩性。",
    "tldr": "STAP提出了一种可扩展框架，能够训练操作技能并在规划时协调它们的几何依赖关系，从而解决任何技能在训练期间都没有见过的长远任务，以此提升长远任务的成功率。",
    "en_tdlr": "STAP presents a scalable framework for training manipulation skills and coordinating their geometric dependencies at planning time to solve long-horizon tasks never seen by any skill during training, which promises to improve the success rate of long-horizon tasks."
}