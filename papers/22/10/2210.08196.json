{
    "title": "Deep Regression Unlearning. (arXiv:2210.08196v2 [cs.LG] UPDATED)",
    "abstract": "With the introduction of data protection and privacy regulations, it has become crucial to remove the lineage of data on demand from a machine learning (ML) model. In the last few years, there have been notable developments in machine unlearning to remove the information of certain training data efficiently and effectively from ML models. In this work, we explore unlearning for the regression problem, particularly in deep learning models. Unlearning in classification and simple linear regression has been considerably investigated. However, unlearning in deep regression models largely remains an untouched problem till now. In this work, we introduce deep regression unlearning methods that generalize well and are robust to privacy attacks. We propose the Blindspot unlearning method which uses a novel weight optimization process. A randomly initialized model, partially exposed to the retain samples and a copy of the original model are used together to selectively imprint knowledge about t",
    "link": "http://arxiv.org/abs/2210.08196",
    "context": "Title: Deep Regression Unlearning. (arXiv:2210.08196v2 [cs.LG] UPDATED)\nAbstract: With the introduction of data protection and privacy regulations, it has become crucial to remove the lineage of data on demand from a machine learning (ML) model. In the last few years, there have been notable developments in machine unlearning to remove the information of certain training data efficiently and effectively from ML models. In this work, we explore unlearning for the regression problem, particularly in deep learning models. Unlearning in classification and simple linear regression has been considerably investigated. However, unlearning in deep regression models largely remains an untouched problem till now. In this work, we introduce deep regression unlearning methods that generalize well and are robust to privacy attacks. We propose the Blindspot unlearning method which uses a novel weight optimization process. A randomly initialized model, partially exposed to the retain samples and a copy of the original model are used together to selectively imprint knowledge about t",
    "path": "papers/22/10/2210.08196.json",
    "total_tokens": 857,
    "translated_title": "深度回归去学习",
    "translated_abstract": "随着数据保护和隐私法规的引入，从机器学习（ML）模型中按需删除数据来源已经变得至关重要。近年来，机器去学习在有效和高效地从ML模型中删除某些训练数据信息方面取得了显著发展。在本研究中，我们探索了回归问题的去学习，特别是在深度学习模型中的去学习。分类和简单线性回归的去学习已经得到了相当广泛的研究。然而，深度回归模型的去学习问题在现在仍然未得到解决。在这项工作中，我们介绍了可以广泛推广且对隐私攻击具有强韧性的深度回归去学习方法。我们提出了一种使用新颖的权重优化过程的Blindspot去学习方法。一种随机初始化的模型、部分暴露于保留样本的模型和原始模型的副本一起使用，以选择性地印记有关该模型的知识。",
    "tldr": "本文研究了深度回归去学习的问题，并提出了可以广泛推广且对隐私攻击具有强韧性的深度回归去学习方法Blindspot。",
    "en_tdlr": "This paper explores the problem of deep regression unlearning and proposes a method called Blindspot which is widely generalizable and robust to privacy attacks."
}