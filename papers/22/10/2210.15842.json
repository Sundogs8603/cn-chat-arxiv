{
    "title": "Leveraging Label Correlations in a Multi-label Setting: A Case Study in Emotion. (arXiv:2210.15842v2 [cs.CL] UPDATED)",
    "abstract": "Detecting emotions expressed in text has become critical to a range of fields. In this work, we investigate ways to exploit label correlations in multi-label emotion recognition models to improve emotion detection. First, we develop two modeling approaches to the problem in order to capture word associations of the emotion words themselves, by either including the emotions in the input, or by leveraging Masked Language Modeling (MLM). Second, we integrate pairwise constraints of emotion representations as regularization terms alongside the classification loss of the models. We split these terms into two categories, local and global. The former dynamically change based on the gold labels, while the latter remain static during training. We demonstrate state-of-the-art performance across Spanish, English, and Arabic in SemEval 2018 Task 1 E-c using monolingual BERT-based models. On top of better performance, we also demonstrate improved robustness. Code is available at https://github.com/",
    "link": "http://arxiv.org/abs/2210.15842",
    "total_tokens": 954,
    "translated_title": "在多标签情感识别中利用标签相关性的研究：以情感为例",
    "translated_abstract": "在文本中检测表达的情感已经成为许多领域的关键。本文研究了利用多标签情感识别模型中的标签相关性来改善情感检测的方法。首先，我们开发了两种建模方法来捕捉情感词本身的词汇关联性，一种是将情感包含在输入中，另一种是利用遮蔽语言建模（MLM）。其次，我们将情感表示的成对约束作为正则化项与模型的分类损失一起集成。我们将这些项分为两类，局部和全局。前者根据金标签动态变化，而后者在训练期间保持不变。我们在SemEval 2018任务1 E-c中使用单语BERT模型展示了西班牙语、英语和阿拉伯语的最新性能。除了更好的性能外，我们还展示了改进的鲁棒性。",
    "tldr": "本文研究了利用标签相关性来改善情感检测的方法，开发了两种建模方法来捕捉情感词本身的词汇关联性，并将情感表示的成对约束作为正则化项与模型的分类损失一起集成，展示了在SemEval 2018任务1 E-c中使用单语BERT模型展示了西班牙语、英语和阿拉伯语的最新性能。",
    "en_tldr": "This paper investigates ways to exploit label correlations in multi-label emotion recognition models to improve emotion detection, develops two modeling approaches to capture word associations of the emotion words themselves, and integrates pairwise constraints of emotion representations as regularization terms alongside the classification loss of the models, demonstrating state-of-the-art performance across Spanish, English, and Arabic in SemEval 2018 Task 1 E-c using monolingual BERT-based models."
}