{
    "title": "IsoVec: Controlling the Relative Isomorphism of Word Embedding Spaces. (arXiv:2210.05098v3 [cs.CL] UPDATED)",
    "abstract": "The ability to extract high-quality translation dictionaries from monolingual word embedding spaces depends critically on the geometric similarity of the spaces -- their degree of \"isomorphism.\" We address the root-cause of faulty cross-lingual mapping: that word embedding training resulted in the underlying spaces being non-isomorphic. We incorporate global measures of isomorphism directly into the Skip-gram loss function, successfully increasing the relative isomorphism of trained word embedding spaces and improving their ability to be mapped to a shared cross-lingual space. The result is improved bilingual lexicon induction in general data conditions, under domain mismatch, and with training algorithm dissimilarities. We release IsoVec at https://github.com/kellymarchisio/isovec.",
    "link": "http://arxiv.org/abs/2210.05098",
    "context": "Title: IsoVec: Controlling the Relative Isomorphism of Word Embedding Spaces. (arXiv:2210.05098v3 [cs.CL] UPDATED)\nAbstract: The ability to extract high-quality translation dictionaries from monolingual word embedding spaces depends critically on the geometric similarity of the spaces -- their degree of \"isomorphism.\" We address the root-cause of faulty cross-lingual mapping: that word embedding training resulted in the underlying spaces being non-isomorphic. We incorporate global measures of isomorphism directly into the Skip-gram loss function, successfully increasing the relative isomorphism of trained word embedding spaces and improving their ability to be mapped to a shared cross-lingual space. The result is improved bilingual lexicon induction in general data conditions, under domain mismatch, and with training algorithm dissimilarities. We release IsoVec at https://github.com/kellymarchisio/isovec.",
    "path": "papers/22/10/2210.05098.json",
    "total_tokens": 825,
    "translated_title": "IsoVec: 控制词向量空间的相对同构性",
    "translated_abstract": "从单语言词向量空间提取高质量的翻译词典的能力取决于空间的几何相似性——它们的“同构度”。我们解决了跨语言映射出现问题的根本原因：即词向量训练导致底层空间不同构。我们将同构度的全局度量直接合并到Skip-gram损失函数中，成功地增加了训练后词向量空间的相对同构度，并提高了它们映射到共享的跨语言空间的能力。结果是在一般数据条件下，领域不匹配和训练算法不相似情况下改善了双语词汇表归纳的效果。我们在https://github.com/kellymarchisio/isovec 上发布了IsoVec。",
    "tldr": "这项研究介绍了IsoVec，一种控制词向量空间相对同构性的方法，通过在Skip-gram损失函数中加入全局同构度度量，提高了训练后词向量空间的同构性，进而改善了跨语言映射效果。",
    "en_tdlr": "This research introduces IsoVec, a method for controlling the relative isomorphism of word embedding spaces. By incorporating global measures of isomorphism into the Skip-gram loss function, the method successfully increases the relative isomorphism of trained word embedding spaces and improves cross-lingual mapping."
}