{
    "title": "ViNL: Visual Navigation and Locomotion Over Obstacles. (arXiv:2210.14791v3 [cs.RO] UPDATED)",
    "abstract": "We present Visual Navigation and Locomotion over obstacles (ViNL), which enables a quadrupedal robot to navigate unseen apartments while stepping over small obstacles that lie in its path (e.g., shoes, toys, cables), similar to how humans and pets lift their feet over objects as they walk. ViNL consists of: (1) a visual navigation policy that outputs linear and angular velocity commands that guides the robot to a goal coordinate in unfamiliar indoor environments; and (2) a visual locomotion policy that controls the robot's joints to avoid stepping on obstacles while following provided velocity commands. Both the policies are entirely \"model-free\", i.e. sensors-to-actions neural networks trained end-to-end. The two are trained independently in two entirely different simulators and then seamlessly co-deployed by feeding the velocity commands from the navigator to the locomotor, entirely \"zero-shot\" (without any co-training). While prior works have developed learning methods for visual na",
    "link": "http://arxiv.org/abs/2210.14791",
    "context": "Title: ViNL: Visual Navigation and Locomotion Over Obstacles. (arXiv:2210.14791v3 [cs.RO] UPDATED)\nAbstract: We present Visual Navigation and Locomotion over obstacles (ViNL), which enables a quadrupedal robot to navigate unseen apartments while stepping over small obstacles that lie in its path (e.g., shoes, toys, cables), similar to how humans and pets lift their feet over objects as they walk. ViNL consists of: (1) a visual navigation policy that outputs linear and angular velocity commands that guides the robot to a goal coordinate in unfamiliar indoor environments; and (2) a visual locomotion policy that controls the robot's joints to avoid stepping on obstacles while following provided velocity commands. Both the policies are entirely \"model-free\", i.e. sensors-to-actions neural networks trained end-to-end. The two are trained independently in two entirely different simulators and then seamlessly co-deployed by feeding the velocity commands from the navigator to the locomotor, entirely \"zero-shot\" (without any co-training). While prior works have developed learning methods for visual na",
    "path": "papers/22/10/2210.14791.json",
    "total_tokens": 1106,
    "translated_title": "ViNL：通过视觉导航和足球术行走避免障碍物",
    "translated_abstract": "我们提出了一种名为ViNL（Visual Navigation and Locomotion）的方法，它使四足机器人能够在路径上跨过小障碍物（例如鞋子、玩具、电缆），类似于人和宠物在行走时抬起脚步超过物体。ViNL包括：（1）一个视觉导航策略，输出线性和角速度命令，指导机器人在陌生的室内环境中达到目标坐标；（2）一个视觉运动策略，通过控制机器人的关节，避免踩到障碍物，并按照提供的速度命令移动。这两个策略都是完全“无模型”的，即通过端到端训练的传感器到行动神经网络进行训练。这两者在两个完全不同的模拟器中独立训练，然后通过将导航器的速度命令输入到定位器中协同部署，完全“零训练”。虽然之前的研究已经开发出了用于视觉导航的学习方法，但通常需要模型先验和/或人工特征工程。ViNL与这些方法不同，能够在没有环境先验知识的情况下，在未知的室内环境中实现高效且稳定的导航和足球术运动。",
    "tldr": "ViNL是通过视觉导航和足球术在未知室内环境中实现机器人导航和足球术运动的方法。它包括无模型的视觉导航策略和视觉运动策略，通过端到端训练实现，并能够避免踩到小障碍物。ViNL能够实现高效且稳定的导航和足球术运动，无需环境先验知识。",
    "en_tdlr": "ViNL is a method for robot navigation and locomotion in unknown indoor environments using visual navigation and locomotion techniques. It includes model-free visual navigation and locomotion policies trained end-to-end, and enables the robot to avoid stepping on small obstacles. ViNL achieves efficient and stable navigation and locomotion without the need for prior environmental knowledge."
}