{
    "title": "Flexible Attention-Based Multi-Policy Fusion for Efficient Deep Reinforcement Learning. (arXiv:2210.03729v2 [cs.LG] UPDATED)",
    "abstract": "Reinforcement learning (RL) agents have long sought to approach the efficiency of human learning. Humans are great observers who can learn by aggregating external knowledge from various sources, including observations from others' policies of attempting a task. Prior studies in RL have incorporated external knowledge policies to help agents improve sample efficiency. However, it remains non-trivial to perform arbitrary combinations and replacements of those policies, an essential feature for generalization and transferability. In this work, we present Knowledge-Grounded RL (KGRL), an RL paradigm fusing multiple knowledge policies and aiming for human-like efficiency and flexibility. We propose a new actor architecture for KGRL, Knowledge-Inclusive Attention Network (KIAN), which allows free knowledge rearrangement due to embedding-based attentive action prediction. KIAN also addresses entropy imbalance, a problem arising in maximum entropy KGRL that hinders an agent from efficiently ex",
    "link": "http://arxiv.org/abs/2210.03729",
    "context": "Title: Flexible Attention-Based Multi-Policy Fusion for Efficient Deep Reinforcement Learning. (arXiv:2210.03729v2 [cs.LG] UPDATED)\nAbstract: Reinforcement learning (RL) agents have long sought to approach the efficiency of human learning. Humans are great observers who can learn by aggregating external knowledge from various sources, including observations from others' policies of attempting a task. Prior studies in RL have incorporated external knowledge policies to help agents improve sample efficiency. However, it remains non-trivial to perform arbitrary combinations and replacements of those policies, an essential feature for generalization and transferability. In this work, we present Knowledge-Grounded RL (KGRL), an RL paradigm fusing multiple knowledge policies and aiming for human-like efficiency and flexibility. We propose a new actor architecture for KGRL, Knowledge-Inclusive Attention Network (KIAN), which allows free knowledge rearrangement due to embedding-based attentive action prediction. KIAN also addresses entropy imbalance, a problem arising in maximum entropy KGRL that hinders an agent from efficiently ex",
    "path": "papers/22/10/2210.03729.json",
    "total_tokens": 950,
    "translated_title": "灵活的基于注意力的多策略融合用于高效深度强化学习的研究",
    "translated_abstract": "强化学习 (RL) 代理长期以来一直致力于接近人类学习的效率。人类是优秀的观察者，可以通过聚合来自各种来源的外部知识（包括他人在尝试任务时的观察）来学习。之前在RL中的研究已经将外部知识策略结合到代理中，以帮助其提高样本效率。然而，执行任意组合和替换这些策略仍然是非平凡的，这是泛化和可转移性的重要特征。在这项工作中，我们提出了知识引导的RL(KGRL)，这是一种融合多个知识策略并旨在实现人类学习效率和灵活性的RL范式。我们为KGRL提出了一种新的演员架构，即知识包容性注意网络(KIAN)，该网络通过基于嵌入的注意力行动预测实现了自由的知识重新排列。KIAN还解决了熵不平衡的问题，这是在最大熵KGRL中出现的问题，阻碍了代理的高效表现。",
    "tldr": "该论文提出了一种知识引导的强化学习方法（KGRL），通过融合多个知识策略并利用注意力机制实现了灵活的知识重新排列。这种方法可以提高强化学习代理的样本效率和泛化能力。",
    "en_tdlr": "This paper introduces a knowledge-guided reinforcement learning method (KGRL) that incorporates multiple knowledge policies and utilizes attention mechanism for flexible knowledge rearrangement. This approach improves the sample efficiency and generalization capability of reinforcement learning agents."
}