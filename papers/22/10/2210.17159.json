{
    "title": "PAGE: Prototype-Based Model-Level Explanations for Graph Neural Networks",
    "abstract": "arXiv:2210.17159v2 Announce Type: replace  Abstract: Aside from graph neural networks (GNNs) attracting significant attention as a powerful framework revolutionizing graph representation learning, there has been an increasing demand for explaining GNN models. Although various explanation methods for GNNs have been developed, most studies have focused on instance-level explanations, which produce explanations tailored to a given graph instance. In our study, we propose Prototype-bAsed GNN-Explainer (PAGE), a novel model-level GNN explanation method that explains what the underlying GNN model has learned for graph classification by discovering human-interpretable prototype graphs. Our method produces explanations for a given class, thus being capable of offering more concise and comprehensive explanations than those of instance-level explanations. First, PAGE selects embeddings of class-discriminative input graphs on the graph-level embedding space after clustering them. Then, PAGE disco",
    "link": "https://arxiv.org/abs/2210.17159",
    "context": "Title: PAGE: Prototype-Based Model-Level Explanations for Graph Neural Networks\nAbstract: arXiv:2210.17159v2 Announce Type: replace  Abstract: Aside from graph neural networks (GNNs) attracting significant attention as a powerful framework revolutionizing graph representation learning, there has been an increasing demand for explaining GNN models. Although various explanation methods for GNNs have been developed, most studies have focused on instance-level explanations, which produce explanations tailored to a given graph instance. In our study, we propose Prototype-bAsed GNN-Explainer (PAGE), a novel model-level GNN explanation method that explains what the underlying GNN model has learned for graph classification by discovering human-interpretable prototype graphs. Our method produces explanations for a given class, thus being capable of offering more concise and comprehensive explanations than those of instance-level explanations. First, PAGE selects embeddings of class-discriminative input graphs on the graph-level embedding space after clustering them. Then, PAGE disco",
    "path": "papers/22/10/2210.17159.json",
    "total_tokens": 880,
    "translated_title": "PAGE: 基于原型的模型级图神经网络解释",
    "translated_abstract": "除了图神经网络（GNNs）作为一种强大的框架吸引了相当多的关注，带来了图表示学习的革命，对解释GNN模型的需求也在增加。尽管已经开发了各种GNN解释方法，但大部分研究都集中在实例级别的解释上，这些解释定制给定图实例。在我们的研究中，我们提出了基于原型的GNN解释器（PAGE），这是一种解释模型级GNN的全新方法，通过发现人类可解释的原型图来解释图分类中GNN模型学到了什么。我们的方法为特定类别生成解释，因此能够提供比实例级解释更简洁和全面的解释。首先，PAGE在对它们进行聚类后选择类别判别性输入图的嵌入在图级嵌入空间上。然后，PAGE展示了一种新的解释技能，因为它揭示了一个类别的数据将会如何在嵌入空间的含义上发生变化。",
    "tldr": "PAGE提出了一种新型的模型级图神经网络解释方法，通过发现人类可解释的原型图来解释GNN模型对图分类学习的内容，相比实例级解释，该方法提供更为简洁和全面的解释。"
}