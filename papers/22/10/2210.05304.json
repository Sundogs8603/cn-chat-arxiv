{
    "title": "Learning Provably Stabilizing Neural Controllers for Discrete-Time Stochastic Systems. (arXiv:2210.05304v2 [cs.LG] UPDATED)",
    "abstract": "We consider the problem of learning control policies in discrete-time stochastic systems which guarantee that the system stabilizes within some specified stabilization region with probability~$1$. Our approach is based on the novel notion of stabilizing ranking supermartingales (sRSMs) that we introduce in this work. Our sRSMs overcome the limitation of methods proposed in previous works whose applicability is restricted to systems in which the stabilizing region cannot be left once entered under any control policy. We present a learning procedure that learns a control policy together with an sRSM that formally certifies probability~$1$ stability, both learned as neural networks. We show that this procedure can also be adapted to formally verifying that, under a given Lipschitz continuous control policy, the stochastic system stabilizes within some stabilizing region with probability~$1$. Our experimental evaluation shows that our learning procedure can successfully learn provably stab",
    "link": "http://arxiv.org/abs/2210.05304",
    "context": "Title: Learning Provably Stabilizing Neural Controllers for Discrete-Time Stochastic Systems. (arXiv:2210.05304v2 [cs.LG] UPDATED)\nAbstract: We consider the problem of learning control policies in discrete-time stochastic systems which guarantee that the system stabilizes within some specified stabilization region with probability~$1$. Our approach is based on the novel notion of stabilizing ranking supermartingales (sRSMs) that we introduce in this work. Our sRSMs overcome the limitation of methods proposed in previous works whose applicability is restricted to systems in which the stabilizing region cannot be left once entered under any control policy. We present a learning procedure that learns a control policy together with an sRSM that formally certifies probability~$1$ stability, both learned as neural networks. We show that this procedure can also be adapted to formally verifying that, under a given Lipschitz continuous control policy, the stochastic system stabilizes within some stabilizing region with probability~$1$. Our experimental evaluation shows that our learning procedure can successfully learn provably stab",
    "path": "papers/22/10/2210.05304.json",
    "total_tokens": 943,
    "translated_title": "学习离散时间随机系统的可证明稳定神经控制器",
    "translated_abstract": "本文考虑在离散时间随机系统中学习控制策略的问题，该策略保证系统以概率1在某个指定的稳定区域内稳定。我们的方法基于我们在本文中引入的创新概念——稳定排序超级鞅(sRSMs)。我们的sRSMs克服了先前方法的局限性，这些方法仅适用于进入稳定区域后无法离开的系统。我们提出了一个学习过程，该过程学习一个控制策略和一个正式证明概率1稳定性的sRSM，两者都以神经网络的形式学习。我们还表明，该过程可以适应于在给定的Lipschitz连续控制策略下，验证随机系统以概率1在某个稳定区域内稳定。我们的实验评估表明，我们的学习过程能够成功地学习可证明稳定的神经控制器。",
    "tldr": "本文提出了一种学习离散时间随机系统中的神经控制器的方法，该方法能够以概率1在指定的稳定区域内实现系统稳定，并引入了稳定排序超级鞅(sRSMs)的概念来克服先前方法的局限性。实验结果证明了该方法的有效性。"
}