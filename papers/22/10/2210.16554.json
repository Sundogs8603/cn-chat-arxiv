{
    "title": "End-to-end Spoken Language Understanding with Tree-constrained Pointer Generator. (arXiv:2210.16554v2 [cs.CL] UPDATED)",
    "abstract": "End-to-end spoken language understanding (SLU) suffers from the long-tail word problem. This paper exploits contextual biasing, a technique to improve the speech recognition of rare words, in end-to-end SLU systems. Specifically, a tree-constrained pointer generator (TCPGen), a powerful and efficient biasing model component, is studied, which leverages a slot shortlist with corresponding entities to extract biasing lists. Meanwhile, to bias the SLU model output slot distribution, a slot probability biasing (SPB) mechanism is proposed to calculate a slot distribution from TCPGen. Experiments on the SLURP dataset showed consistent SLU-F1 improvements using TCPGen and SPB, especially on unseen entities. On a new split by holding out 5 slot types for the test, TCPGen with SPB achieved zero-shot learning with an SLU-F1 score over 50% compared to baselines which can not deal with it. In addition to slot filling, the intent classification accuracy was also improved.",
    "link": "http://arxiv.org/abs/2210.16554",
    "context": "Title: End-to-end Spoken Language Understanding with Tree-constrained Pointer Generator. (arXiv:2210.16554v2 [cs.CL] UPDATED)\nAbstract: End-to-end spoken language understanding (SLU) suffers from the long-tail word problem. This paper exploits contextual biasing, a technique to improve the speech recognition of rare words, in end-to-end SLU systems. Specifically, a tree-constrained pointer generator (TCPGen), a powerful and efficient biasing model component, is studied, which leverages a slot shortlist with corresponding entities to extract biasing lists. Meanwhile, to bias the SLU model output slot distribution, a slot probability biasing (SPB) mechanism is proposed to calculate a slot distribution from TCPGen. Experiments on the SLURP dataset showed consistent SLU-F1 improvements using TCPGen and SPB, especially on unseen entities. On a new split by holding out 5 slot types for the test, TCPGen with SPB achieved zero-shot learning with an SLU-F1 score over 50% compared to baselines which can not deal with it. In addition to slot filling, the intent classification accuracy was also improved.",
    "path": "papers/22/10/2210.16554.json",
    "total_tokens": 985,
    "translated_title": "带树约束的指针生成器的端到端口语理解",
    "translated_abstract": "端到端的口语理解系统面临着长尾词问题。本文利用上下文偏置技术提高了口语理解系统的稀有词识别能力，具体研究了一种称为树约束指针生成器（TCPGen）的强大高效的偏置模型组件，该组件利用对应的实体和短槽列表提取偏置列表。同时，为了偏置SLU模型的输出槽分布，提出一种称为槽概率偏置（SPB）机制，从TCPGen计算槽分布。在SLURP数据集上的实验证明，使用TCPGen和SPB可以持续改善SLU-F1得分，尤其是在看不见的实体上。在保留5个槽类型进行测试的新分割上，TCPGen和SPB实现了零样本学习，在SLU-F1得分上超过了50%的基线水平。除了槽填充外，意图分类准确性也有所提高。",
    "tldr": "本论文针对口语理解中的长尾词问题，提出了一种带树约束的指针生成器TCPGen和槽概率偏置机制SPB，通过对应的实体和短槽列表提取偏置列表来偏置SLU模型的输出槽分布，取得了不错的实验结果。"
}