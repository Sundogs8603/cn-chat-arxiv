{
    "title": "Maximum Likelihood Learning of Unnormalized Models for Simulation-Based Inference. (arXiv:2210.14756v2 [cs.LG] UPDATED)",
    "abstract": "We introduce two synthetic likelihood methods for Simulation-Based Inference (SBI), to conduct either amortized or targeted inference from experimental observations when a high-fidelity simulator is available. Both methods learn a conditional energy-based model (EBM) of the likelihood using synthetic data generated by the simulator, conditioned on parameters drawn from a proposal distribution. The learned likelihood can then be combined with any prior to obtain a posterior estimate, from which samples can be drawn using MCMC. Our methods uniquely combine a flexible Energy-Based Model and the minimization of a KL loss: this is in contrast to other synthetic likelihood methods, which either rely on normalizing flows, or minimize score-based objectives; choices that come with known pitfalls. We demonstrate the properties of both methods on a range of synthetic datasets, and apply them to a neuroscience model of the pyloric network in the crab, where our method outperforms prior art for a ",
    "link": "http://arxiv.org/abs/2210.14756",
    "context": "Title: Maximum Likelihood Learning of Unnormalized Models for Simulation-Based Inference. (arXiv:2210.14756v2 [cs.LG] UPDATED)\nAbstract: We introduce two synthetic likelihood methods for Simulation-Based Inference (SBI), to conduct either amortized or targeted inference from experimental observations when a high-fidelity simulator is available. Both methods learn a conditional energy-based model (EBM) of the likelihood using synthetic data generated by the simulator, conditioned on parameters drawn from a proposal distribution. The learned likelihood can then be combined with any prior to obtain a posterior estimate, from which samples can be drawn using MCMC. Our methods uniquely combine a flexible Energy-Based Model and the minimization of a KL loss: this is in contrast to other synthetic likelihood methods, which either rely on normalizing flows, or minimize score-based objectives; choices that come with known pitfalls. We demonstrate the properties of both methods on a range of synthetic datasets, and apply them to a neuroscience model of the pyloric network in the crab, where our method outperforms prior art for a ",
    "path": "papers/22/10/2210.14756.json",
    "total_tokens": 851,
    "translated_title": "用于基于仿真推断的非归一化模型的最大似然学习",
    "translated_abstract": "我们引入了两种用于基于仿真推断（SBI）的合成似然方法，可以在高保真度模拟器存在时从实验观测中进行分摊或有针对性的推断。两种方法均使用从提议分布中抽取的参数所生成的模拟数据来学习 likelihood 的条件能量模型(EBM)。然后可以将学习到的 likelihood 与任何先验组合以获得后验估计，随后可以使用 MCMC 从中抽取样本。与其他合成似然方法不同，我们的方法独特地结合了灵活的能量模型和 KL 损失的最小化。",
    "tldr": "该论文提出了两种用于基于仿真推断的合成似然方法，使用高保真度模拟器生成模拟数据，学习条件能量模型(EBM)的 likelihood，结合先验估计后验分布，可以使用MCMC抽取样本，该方法相较于其他方法更加灵活和准确。",
    "en_tdlr": "This paper presents two synthetic likelihood methods for Simulation-Based Inference (SBI), which generate synthetic data using a high-fidelity simulator, learn the conditional energy-based model (EBM) of the likelihood and combine it with any prior to estimate posterior distributions. The learned likelihood can be sampled using MCMC. The proposed methods combine a flexible Energy-Based Model and the minimization of KL loss, which provides better results than other methods."
}