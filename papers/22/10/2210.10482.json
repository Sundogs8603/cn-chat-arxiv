{
    "title": "Effective Targeted Attacks for Adversarial Self-Supervised Learning. (arXiv:2210.10482v2 [cs.LG] UPDATED)",
    "abstract": "Recently, unsupervised adversarial training (AT) has been highlighted as a means of achieving robustness in models without any label information. Previous studies in unsupervised AT have mostly focused on implementing self-supervised learning (SSL) frameworks, which maximize the instance-wise classification loss to generate adversarial examples. However, we observe that simply maximizing the self-supervised training loss with an untargeted adversarial attack often results in generating ineffective adversaries that may not help improve the robustness of the trained model, especially for non-contrastive SSL frameworks without negative examples. To tackle this problem, we propose a novel positive mining for targeted adversarial attack to generate effective adversaries for adversarial SSL frameworks. Specifically, we introduce an algorithm that selects the most confusing yet similar target example for a given instance based on entropy and similarity, and subsequently perturbs the given ins",
    "link": "http://arxiv.org/abs/2210.10482",
    "context": "Title: Effective Targeted Attacks for Adversarial Self-Supervised Learning. (arXiv:2210.10482v2 [cs.LG] UPDATED)\nAbstract: Recently, unsupervised adversarial training (AT) has been highlighted as a means of achieving robustness in models without any label information. Previous studies in unsupervised AT have mostly focused on implementing self-supervised learning (SSL) frameworks, which maximize the instance-wise classification loss to generate adversarial examples. However, we observe that simply maximizing the self-supervised training loss with an untargeted adversarial attack often results in generating ineffective adversaries that may not help improve the robustness of the trained model, especially for non-contrastive SSL frameworks without negative examples. To tackle this problem, we propose a novel positive mining for targeted adversarial attack to generate effective adversaries for adversarial SSL frameworks. Specifically, we introduce an algorithm that selects the most confusing yet similar target example for a given instance based on entropy and similarity, and subsequently perturbs the given ins",
    "path": "papers/22/10/2210.10482.json",
    "total_tokens": 884,
    "translated_title": "针对对抗自监督学习的有效目标攻击",
    "translated_abstract": "最近，无监督对抗训练（AT）一直被认为是在没有任何标签信息的模型中实现鲁棒性的手段。以往的无监督AT研究主要集中在实现自监督学习（SSL）框架，通过最大化每个实例的分类损失来生成对抗性样本。然而，我们观察到，简单地通过无目标对抗攻击来最大化自监督训练损失往往会生成无效的对手，这些对手可能无法帮助提高训练模型的鲁棒性，特别是对于没有负样本的非对比性SSL框架。为了解决这个问题，我们提出了一种针对对抗SSL框架的新型正向挖掘方法来生成有效的对手。具体而言，我们介绍了一种基于熵和相似性的算法，为给定实例选择最令人困惑但相似的目标样本，然后扰动给定实例。",
    "tldr": "该论文提出了一种针对无监督对抗训练框架的正向挖掘方法，通过选择最令人困惑但相似的目标样本来生成有效的对手，以提高训练模型的鲁棒性。",
    "en_tdlr": "This paper proposes a positive mining method for unsupervised adversarial training frameworks, which generates effective adversaries by selecting the most confusing yet similar target examples, aiming to improve the robustness of the trained model."
}