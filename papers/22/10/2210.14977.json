{
    "title": "Knowledge Transfer For On-Device Speech Emotion Recognition with Neural Structured Learning. (arXiv:2210.14977v3 [cs.SD] UPDATED)",
    "abstract": "Speech emotion recognition (SER) has been a popular research topic in human-computer interaction (HCI). As edge devices are rapidly springing up, applying SER to edge devices is promising for a huge number of HCI applications. Although deep learning has been investigated to improve the performance of SER by training complex models, the memory space and computational capability of edge devices represents a constraint for embedding deep learning models. We propose a neural structured learning (NSL) framework through building synthesized graphs. An SER model is trained on a source dataset and used to build graphs on a target dataset. A relatively lightweight model is then trained with the speech samples and graphs together as the input. Our experiments demonstrate that training a lightweight SER model on the target dataset with speech samples and graphs can not only produce small SER models, but also enhance the model performance compared to models with speech samples only and those using",
    "link": "http://arxiv.org/abs/2210.14977",
    "context": "Title: Knowledge Transfer For On-Device Speech Emotion Recognition with Neural Structured Learning. (arXiv:2210.14977v3 [cs.SD] UPDATED)\nAbstract: Speech emotion recognition (SER) has been a popular research topic in human-computer interaction (HCI). As edge devices are rapidly springing up, applying SER to edge devices is promising for a huge number of HCI applications. Although deep learning has been investigated to improve the performance of SER by training complex models, the memory space and computational capability of edge devices represents a constraint for embedding deep learning models. We propose a neural structured learning (NSL) framework through building synthesized graphs. An SER model is trained on a source dataset and used to build graphs on a target dataset. A relatively lightweight model is then trained with the speech samples and graphs together as the input. Our experiments demonstrate that training a lightweight SER model on the target dataset with speech samples and graphs can not only produce small SER models, but also enhance the model performance compared to models with speech samples only and those using",
    "path": "papers/22/10/2210.14977.json",
    "total_tokens": 908,
    "translated_title": "在设备情感识别的知识迁移与神经结构化学习",
    "translated_abstract": "语音情感识别（SER）是人机交互（HCI）中热门的研究课题。随着边缘设备的快速兴起，将SER应用于边缘设备对于大量HCI应用是有前途的。虽然已经研究过使用深度学习训练复杂模型来提高SER的性能，但边缘设备的内存空间和计算能力是深度学习模型的限制因素。我们提出了一个通过构建综合图表的神经结构化学习（NSL）框架。在源数据集上训练SER模型，并使用它来在目标数据集上构建图表。然后使用语音样本和图表作为输入，训练相对较轻量的模型。我们的实验证明，在目标数据集上使用语音样本和图表训练轻量级SER模型既可以产生小模型，也可以提高模型性能，而不是单独使用语音样本或使用知识蒸馏的模型。",
    "tldr": "本文提出了一个通过构建综合图表的神经结构化学习（NSL）框架，在目标数据集上使用语音样本和图表训练轻量级SER模型既可以产生小模型，也可以提高模型性能",
    "en_tdlr": "This paper proposes a neural structured learning (NSL) framework that trains a lightweight SER model on a target dataset using speech samples and synthesized graphs as input, which can produce small models and enhance performance compared to using speech samples only or knowledge distillation."
}