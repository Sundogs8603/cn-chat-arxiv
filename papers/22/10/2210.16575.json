{
    "title": "Self-Improving Safety Performance of Reinforcement Learning Based Driving with Black-Box Verification Algorithms. (arXiv:2210.16575v3 [cs.AI] UPDATED)",
    "abstract": "In this work, we propose a self-improving artificial intelligence system to enhance the safety performance of reinforcement learning (RL)-based autonomous driving (AD) agents using black-box verification methods. RL algorithms have become popular in AD applications in recent years. However, the performance of existing RL algorithms heavily depends on the diversity of training scenarios. A lack of safety-critical scenarios during the training phase could result in poor generalization performance in real-world driving applications. We propose a novel framework in which the weaknesses of the training set are explored through black-box verification methods. After discovering AD failure scenarios, the RL agent's training is re-initiated via transfer learning to improve the performance of previously unsafe scenarios. Simulation results demonstrate that our approach efficiently discovers safety failures of action decisions in RL-based adaptive cruise control (ACC) applications and significant",
    "link": "http://arxiv.org/abs/2210.16575",
    "context": "Title: Self-Improving Safety Performance of Reinforcement Learning Based Driving with Black-Box Verification Algorithms. (arXiv:2210.16575v3 [cs.AI] UPDATED)\nAbstract: In this work, we propose a self-improving artificial intelligence system to enhance the safety performance of reinforcement learning (RL)-based autonomous driving (AD) agents using black-box verification methods. RL algorithms have become popular in AD applications in recent years. However, the performance of existing RL algorithms heavily depends on the diversity of training scenarios. A lack of safety-critical scenarios during the training phase could result in poor generalization performance in real-world driving applications. We propose a novel framework in which the weaknesses of the training set are explored through black-box verification methods. After discovering AD failure scenarios, the RL agent's training is re-initiated via transfer learning to improve the performance of previously unsafe scenarios. Simulation results demonstrate that our approach efficiently discovers safety failures of action decisions in RL-based adaptive cruise control (ACC) applications and significant",
    "path": "papers/22/10/2210.16575.json",
    "total_tokens": 982,
    "translated_title": "基于黑盒验证算法的自我改进强化学习驾驶安全性能的研究",
    "translated_abstract": "本文提出了一种自我改进的人工智能系统，利用黑盒验证方法来增强基于强化学习的自主驾驶代理的安全性能。最近几年来，强化学习算法在自主驾驶应用中越来越受欢迎。然而，现有的强化学习算法的性能严重依赖于训练场景的多样性。在训练阶段缺乏安全关键的场景可能导致在真实驾驶应用中的泛化性能较差。我们提出了一个新的框架，通过黑盒验证方法探索训练集的弱点。发现自动驾驶失败场景后，通过迁移学习重新启动RL代理的训练，以改进先前不安全的场景的性能。模拟结果表明，我们的方法有效地发现了基于强化学习的自适应巡航控制（ACC）应用中行为决策的安全失败，并且取得了显著的效果。",
    "tldr": "本研究提出了一种使用黑盒验证方法来增强强化学习驾驶的安全性能的自我改进的人工智能系统。该方法通过发现自动驾驶的失败场景并重新训练，以改善在训练中缺乏的安全关键场景的性能。模拟结果表明该方法在自适应巡航控制应用中取得了显著的效果。"
}