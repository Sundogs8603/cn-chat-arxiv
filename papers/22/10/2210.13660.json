{
    "title": "SpacePhish: The Evasion-space of Adversarial Attacks against Phishing Website Detectors using Machine Learning. (arXiv:2210.13660v2 [cs.CR] UPDATED)",
    "abstract": "Existing literature on adversarial Machine Learning (ML) focuses either on showing attacks that break every ML model, or defenses that withstand most attacks. Unfortunately, little consideration is given to the actual feasibility of the attack or the defense. Moreover, adversarial samples are often crafted in the \"feature-space\", making the corresponding evaluations of questionable value. Simply put, the current situation does not allow to estimate the actual threat posed by adversarial attacks, leading to a lack of secure ML systems.  We aim to clarify such confusion in this paper. By considering the application of ML for Phishing Website Detection (PWD), we formalize the \"evasion-space\" in which an adversarial perturbation can be introduced to fool a ML-PWD -- demonstrating that even perturbations in the \"feature-space\" are useful. Then, we propose a realistic threat model describing evasion attacks against ML-PWD that are cheap to stage, and hence intrinsically more attractive for r",
    "link": "http://arxiv.org/abs/2210.13660",
    "context": "Title: SpacePhish: The Evasion-space of Adversarial Attacks against Phishing Website Detectors using Machine Learning. (arXiv:2210.13660v2 [cs.CR] UPDATED)\nAbstract: Existing literature on adversarial Machine Learning (ML) focuses either on showing attacks that break every ML model, or defenses that withstand most attacks. Unfortunately, little consideration is given to the actual feasibility of the attack or the defense. Moreover, adversarial samples are often crafted in the \"feature-space\", making the corresponding evaluations of questionable value. Simply put, the current situation does not allow to estimate the actual threat posed by adversarial attacks, leading to a lack of secure ML systems.  We aim to clarify such confusion in this paper. By considering the application of ML for Phishing Website Detection (PWD), we formalize the \"evasion-space\" in which an adversarial perturbation can be introduced to fool a ML-PWD -- demonstrating that even perturbations in the \"feature-space\" are useful. Then, we propose a realistic threat model describing evasion attacks against ML-PWD that are cheap to stage, and hence intrinsically more attractive for r",
    "path": "papers/22/10/2210.13660.json",
    "total_tokens": 984,
    "translated_title": "SpacePhish: 使用机器学习对抗钓鱼网站检测器的攻击的逃避空间",
    "translated_abstract": "现有的关于对抗机器学习的文献要么展示能够破坏所有机器学习模型的攻击，要么展示能够抵御大部分攻击的防御措施。然而，很少考虑攻击或防御的实际可行性。此外，对抗样本通常是在“特征空间”中生成的，这使得相关评估的价值值得怀疑。简而言之，目前的情况不允许估计对抗攻击所带来的真实威胁，这导致缺乏安全的机器学习系统。本文旨在澄清这种困惑。通过考虑机器学习用于钓鱼网站检测的应用，我们将“逃避空间”形式化为一种能够引入对抗扰动以欺骗机器学习-钓鱼网站检测的空间-证明即使在“特征空间”中的扰动也是有用的。然后，我们提出了一个描述针对机器学习-钓鱼网站检测的逃避攻击的现实威胁模型，这种攻击容易实施，因此更具吸引力。",
    "tldr": "该论文研究了对抗机器学习中钓鱼网站检测的攻击以及针对这些攻击的逃避防御空间，并提出了一种现实威胁模型。",
    "en_tdlr": "This paper discusses adversarial attacks against phishing website detectors in the context of machine learning, and explores the evasion space for these attacks. A realistic threat model for evasion attacks is proposed."
}