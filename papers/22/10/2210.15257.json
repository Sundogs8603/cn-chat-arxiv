{
    "title": "ERNIE-ViLG 2.0: Improving Text-to-Image Diffusion Model with Knowledge-Enhanced Mixture-of-Denoising-Experts. (arXiv:2210.15257v2 [cs.CV] UPDATED)",
    "abstract": "Recent progress in diffusion models has revolutionized the popular technology of text-to-image generation. While existing approaches could produce photorealistic high-resolution images with text conditions, there are still several open problems to be solved, which limits the further improvement of image fidelity and text relevancy. In this paper, we propose ERNIE-ViLG 2.0, a large-scale Chinese text-to-image diffusion model, to progressively upgrade the quality of generated images by: (1) incorporating fine-grained textual and visual knowledge of key elements in the scene, and (2) utilizing different denoising experts at different denoising stages. With the proposed mechanisms, ERNIE-ViLG 2.0 not only achieves a new state-of-the-art on MS-COCO with zero-shot FID score of 6.75, but also significantly outperforms recent models in terms of image fidelity and image-text alignment, with side-by-side human evaluation on the bilingual prompt set ViLG-300.",
    "link": "http://arxiv.org/abs/2210.15257",
    "context": "Title: ERNIE-ViLG 2.0: Improving Text-to-Image Diffusion Model with Knowledge-Enhanced Mixture-of-Denoising-Experts. (arXiv:2210.15257v2 [cs.CV] UPDATED)\nAbstract: Recent progress in diffusion models has revolutionized the popular technology of text-to-image generation. While existing approaches could produce photorealistic high-resolution images with text conditions, there are still several open problems to be solved, which limits the further improvement of image fidelity and text relevancy. In this paper, we propose ERNIE-ViLG 2.0, a large-scale Chinese text-to-image diffusion model, to progressively upgrade the quality of generated images by: (1) incorporating fine-grained textual and visual knowledge of key elements in the scene, and (2) utilizing different denoising experts at different denoising stages. With the proposed mechanisms, ERNIE-ViLG 2.0 not only achieves a new state-of-the-art on MS-COCO with zero-shot FID score of 6.75, but also significantly outperforms recent models in terms of image fidelity and image-text alignment, with side-by-side human evaluation on the bilingual prompt set ViLG-300.",
    "path": "papers/22/10/2210.15257.json",
    "total_tokens": 1006,
    "translated_title": "ERNIE-ViLG 2.0：基于知识增强的去噪二次混合模型优化文本到图像模型",
    "translated_abstract": "最近弥漫模型在文本到图像生成领域取得了突破性进展。尽管现有的方法能够在文本条件下产生高分辨率的逼真图像，但仍存在一些需要解决的问题，这限制了图像保真度和文本相关性的进一步提高。本文提出了ERNIE-ViLG 2.0，一种大规模的中文文本到图像扩散模型，通过以下方式逐步提高生成图像的质量：（1）合并场景中关键元素的细粒度文本和视觉知识，（2）在不同的去噪阶段利用不同的去噪专家。通过这些机制，ERNIE-ViLG 2.0不仅在MS-COCO上实现了新的FID得分零射击最佳表现，而且在ViLG-300双语提示集的人类评估中在图像保真度和图像-文本对齐方面显著优于最新的模型。",
    "tldr": "本文提出了ERNIE-ViLG 2.0，一种基于知识增强的去噪二次混合模型，通过合并场景关键元素文本和视觉知识以及使用不同的去噪专家的方法，成功提高了中文文本到图像模型的质量和图像-文本对齐的表现。",
    "en_tdlr": "This paper proposes ERNIE-ViLG 2.0, a knowledge-enhanced mixture-of-denoising-experts text-to-image diffusion model. By incorporating fine-grained textual and visual knowledge of key elements in the scene and utilizing different denoising experts, ERNIE-ViLG 2.0 significantly improves the quality of Chinese text-to-image generation and alignment between text and image."
}