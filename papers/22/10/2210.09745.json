{
    "title": "Transfer learning with affine model transformation. (arXiv:2210.09745v2 [stat.ML] UPDATED)",
    "abstract": "Supervised transfer learning has received considerable attention due to its potential to boost the predictive power of machine learning in scenarios where data are scarce. Generally, a given set of source models and a dataset from a target domain are used to adapt the pre-trained models to a target domain by statistically learning domain shift and domain-specific factors. While such procedurally and intuitively plausible methods have achieved great success in a wide range of real-world applications, the lack of a theoretical basis hinders further methodological development. This paper presents a general class of transfer learning regression called affine model transfer, following the principle of expected-square loss minimization. It is shown that the affine model transfer broadly encompasses various existing methods, including the most common procedure based on neural feature extractors. Furthermore, the current paper clarifies theoretical properties of the affine model transfer such ",
    "link": "http://arxiv.org/abs/2210.09745",
    "context": "Title: Transfer learning with affine model transformation. (arXiv:2210.09745v2 [stat.ML] UPDATED)\nAbstract: Supervised transfer learning has received considerable attention due to its potential to boost the predictive power of machine learning in scenarios where data are scarce. Generally, a given set of source models and a dataset from a target domain are used to adapt the pre-trained models to a target domain by statistically learning domain shift and domain-specific factors. While such procedurally and intuitively plausible methods have achieved great success in a wide range of real-world applications, the lack of a theoretical basis hinders further methodological development. This paper presents a general class of transfer learning regression called affine model transfer, following the principle of expected-square loss minimization. It is shown that the affine model transfer broadly encompasses various existing methods, including the most common procedure based on neural feature extractors. Furthermore, the current paper clarifies theoretical properties of the affine model transfer such ",
    "path": "papers/22/10/2210.09745.json",
    "total_tokens": 853,
    "translated_title": "利用仿射模型变换的迁移学习",
    "translated_abstract": "由于在数据稀缺的情况下能够提高机器学习的预测能力，受到了广泛关注。传统上，使用给定的源模型集和来自目标领域的数据集，通过统计学习来适应预训练模型到目标领域，学习领域转移和领域特定因素。虽然这种方法在广泛的实际应用中取得了巨大的成功，但缺乏理论基础阻碍了进一步的方法发展。本文提出了一种称为仿射模型转移的通用类别的迁移学习回归方法，遵循期望平方损失最小化的原则。结果表明，仿射模型转移广泛包括各种现有方法，包括基于神经特征提取器的最常见过程。此外，本文阐明了仿射模型转移的理论特性。",
    "tldr": "本文提出了一种叫做仿射模型转移的迁移学习方法，通过最小化期望平方损失，可以适应各种不同的方法，包括基于神经特征提取器的方法。对于这个方法也给出了理论上的解释。",
    "en_tdlr": "This paper introduces a transfer learning approach called affine model transfer, which adapts various methods, including those based on neural feature extractors, by minimizing expected square loss. Theoretical properties of this approach are also clarified."
}