{
    "title": "Bayesian Learning via Q-Exponential Process. (arXiv:2210.07987v2 [stat.ME] UPDATED)",
    "abstract": "Regularization is one of the most fundamental topics in optimization, statistics and machine learning. To get sparsity in estimating a parameter $u\\in\\mbR^d$, an $\\ell_q$ penalty term, $\\Vert u\\Vert_q$, is usually added to the objective function. What is the probabilistic distribution corresponding to such $\\ell_q$ penalty? What is the correct stochastic process corresponding to $\\Vert u\\Vert_q$ when we model functions $u\\in L^q$? This is important for statistically modeling large dimensional objects, e.g. images, with penalty to preserve certainty properties, e.g. edges in the image. In this work, we generalize the $q$-exponential distribution (with density proportional to) $\\exp{(- \\half|u|^q)}$ to a stochastic process named \\emph{$Q$-exponential (Q-EP) process} that corresponds to the $L_q$ regularization of functions. The key step is to specify consistent multivariate $q$-exponential distributions by choosing from a large family of elliptic contour distributions. The work is closel",
    "link": "http://arxiv.org/abs/2210.07987",
    "context": "Title: Bayesian Learning via Q-Exponential Process. (arXiv:2210.07987v2 [stat.ME] UPDATED)\nAbstract: Regularization is one of the most fundamental topics in optimization, statistics and machine learning. To get sparsity in estimating a parameter $u\\in\\mbR^d$, an $\\ell_q$ penalty term, $\\Vert u\\Vert_q$, is usually added to the objective function. What is the probabilistic distribution corresponding to such $\\ell_q$ penalty? What is the correct stochastic process corresponding to $\\Vert u\\Vert_q$ when we model functions $u\\in L^q$? This is important for statistically modeling large dimensional objects, e.g. images, with penalty to preserve certainty properties, e.g. edges in the image. In this work, we generalize the $q$-exponential distribution (with density proportional to) $\\exp{(- \\half|u|^q)}$ to a stochastic process named \\emph{$Q$-exponential (Q-EP) process} that corresponds to the $L_q$ regularization of functions. The key step is to specify consistent multivariate $q$-exponential distributions by choosing from a large family of elliptic contour distributions. The work is closel",
    "path": "papers/22/10/2210.07987.json",
    "total_tokens": 927,
    "translated_title": "基于Q-指数过程的贝叶斯学习",
    "translated_abstract": "正则化是优化、统计和机器学习中最基础的主题之一。为了在估计参数$u\\in\\mbR^d$时获得稀疏性，在目标函数中通常会添加$\\ell_q$惩罚项，即$\\Vert u\\Vert_q$。这样的$\\ell_q$惩罚对应的概率分布是什么？当我们对函数$u\\in L^q$建模时，$\\Vert u\\Vert_q$对应的正确随机过程是什么？这对于统计建模大维度对象（例如图像）并保留确定性特性（例如图像边缘）的惩罚非常重要。在这项工作中，我们将$Q$-指数分布（密度正比于$\\exp{(- \\half|u|^q)}$）推广为一种称为\\emph{$Q$-指数（Q-EP）过程}的随机过程，它对应于函数的$L_q$正则化。关键步骤是通过从大型椭圆轮廓分布族中选择来指定一致的多元$q$-指数分布。",
    "tldr": "该论文研究了基于Q-指数过程的贝叶斯学习，通过推广Q-指数分布为Q-指数过程，来对函数的L_q正则化进行建模，并选择一致的多元q-指数分布。",
    "en_tdlr": "This paper investigates Bayesian learning via Q-exponential process, generalizing Q-exponential distribution to model L_q regularization of functions, and choosing consistent multivariate q-exponential distributions."
}