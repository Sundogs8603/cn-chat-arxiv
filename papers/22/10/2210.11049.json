{
    "title": "How Does a Deep Learning Model Architecture Impact Its Privacy? A Comprehensive Study of Privacy Attacks on CNNs and Transformers. (arXiv:2210.11049v2 [cs.CR] UPDATED)",
    "abstract": "As a booming research area in the past decade, deep learning technologies have been driven by big data collected and processed on an unprecedented scale. However, privacy concerns arise due to the potential leakage of sensitive information from the training data. Recent research has revealed that deep learning models are vulnerable to various privacy attacks, including membership inference attacks, attribute inference attacks, and gradient inversion attacks. Notably, the efficacy of these attacks varies from model to model. In this paper, we answer a fundamental question: Does model architecture affect model privacy? By investigating representative model architectures from CNNs to Transformers, we demonstrate that Transformers generally exhibit higher vulnerability to privacy attacks compared to CNNs. Additionally, We identify the micro design of activation layers, stem layers, and LN layers, as major factors contributing to the resilience of CNNs against privacy attacks, while the pre",
    "link": "http://arxiv.org/abs/2210.11049",
    "context": "Title: How Does a Deep Learning Model Architecture Impact Its Privacy? A Comprehensive Study of Privacy Attacks on CNNs and Transformers. (arXiv:2210.11049v2 [cs.CR] UPDATED)\nAbstract: As a booming research area in the past decade, deep learning technologies have been driven by big data collected and processed on an unprecedented scale. However, privacy concerns arise due to the potential leakage of sensitive information from the training data. Recent research has revealed that deep learning models are vulnerable to various privacy attacks, including membership inference attacks, attribute inference attacks, and gradient inversion attacks. Notably, the efficacy of these attacks varies from model to model. In this paper, we answer a fundamental question: Does model architecture affect model privacy? By investigating representative model architectures from CNNs to Transformers, we demonstrate that Transformers generally exhibit higher vulnerability to privacy attacks compared to CNNs. Additionally, We identify the micro design of activation layers, stem layers, and LN layers, as major factors contributing to the resilience of CNNs against privacy attacks, while the pre",
    "path": "papers/22/10/2210.11049.json",
    "total_tokens": 920,
    "tldr": "本文研究了深度学习模型在面对隐私攻击时的鲁棒性，发现Transformers相对于CNNs更易受到隐私攻击，并确认了CNNs的激活层、干分支层和LN层的微设计是影响CNNs对抗隐私攻击的主要因素。",
    "en_tdlr": "This paper investigates the robustness of deep learning models against privacy attacks and finds that Transformers are more vulnerable compared to CNNs. It identifies the micro design of activation layers, stem layers, and LN layers as major factors contributing to the resilience of CNNs against privacy attacks."
}