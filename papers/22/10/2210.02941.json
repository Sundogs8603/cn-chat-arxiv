{
    "title": "BootAug: Boosting Text Augmentation via Hybrid Instance Filtering Framework",
    "abstract": "arXiv:2210.02941v2 Announce Type: replace  Abstract: Text augmentation is an effective technique for addressing the problem of insufficient data in natural language processing. However, existing text augmentation methods tend to focus on few-shot scenarios and usually perform poorly on large public datasets. Our research indicates that existing augmentation methods often generate instances with shifted feature spaces, which leads to a drop in performance on the augmented data (for example, EDA generally loses $\\approx 2\\%$ in aspect-based sentiment classification). To address this problem, we propose a hybrid instance-filtering framework (BootAug) based on pre-trained language models that can maintain a similar feature space with natural datasets. BootAug is transferable to existing text augmentation methods (such as synonym substitution and back translation) and significantly improves the augmentation performance by $\\approx 2-3\\%$ in classification accuracy. Our experimental results ",
    "link": "https://arxiv.org/abs/2210.02941",
    "context": "Title: BootAug: Boosting Text Augmentation via Hybrid Instance Filtering Framework\nAbstract: arXiv:2210.02941v2 Announce Type: replace  Abstract: Text augmentation is an effective technique for addressing the problem of insufficient data in natural language processing. However, existing text augmentation methods tend to focus on few-shot scenarios and usually perform poorly on large public datasets. Our research indicates that existing augmentation methods often generate instances with shifted feature spaces, which leads to a drop in performance on the augmented data (for example, EDA generally loses $\\approx 2\\%$ in aspect-based sentiment classification). To address this problem, we propose a hybrid instance-filtering framework (BootAug) based on pre-trained language models that can maintain a similar feature space with natural datasets. BootAug is transferable to existing text augmentation methods (such as synonym substitution and back translation) and significantly improves the augmentation performance by $\\approx 2-3\\%$ in classification accuracy. Our experimental results ",
    "path": "papers/22/10/2210.02941.json",
    "total_tokens": 810,
    "translated_title": "BootAug: 通过混合实例过滤框架增强文本增强",
    "translated_abstract": "文本增强是解决自然语言处理中数据不足问题的有效技术。然而，现有的文本增强方法往往专注于少样本场景，并且通常在大规模公开数据集上表现不佳。我们的研究表明，现有的增强方法往往生成具有移位特征空间的实例，导致在增强数据上表现下降。为了解决这一问题，我们提出了一个基于预训练语言模型的混合实例过滤框架（BootAug），该框架能够保持与自然数据集类似的特征空间。BootAug可以应用于现有的文本增强方法（如同义词替换和反向翻译），并在分类准确率上显著提高了约 2-3% 的增强性能。",
    "tldr": "提出了BootAug，一个基于预训练语言模型的混合实例过滤框架，能够改进文本增强方法在大规模数据集上的表现，提高了约2-3%的分类准确率。",
    "en_tdlr": "Introduced BootAug, a hybrid instance filtering framework based on pre-trained language models, which enhances the performance of text augmentation methods on large datasets, improving classification accuracy by approximately 2-3%."
}