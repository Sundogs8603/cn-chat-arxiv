{
    "title": "Learnware: Small Models Do Big. (arXiv:2210.03647v2 [cs.LG] UPDATED)",
    "abstract": "There are complaints about current machine learning techniques such as the requirement of a huge amount of training data and proficient training skills, the difficulty of continual learning, the risk of catastrophic forgetting, the leaking of data privacy/proprietary, etc. Most research efforts have been focusing on one of those concerned issues separately, paying less attention to the fact that most issues are entangled in practice. The prevailing big model paradigm, which has achieved impressive results in natural language processing and computer vision applications, has not yet addressed those issues, whereas becoming a serious source of carbon emissions. This article offers an overview of the learnware paradigm, which attempts to enable users not need to build machine learning models from scratch, with the hope of reusing small models to do things even beyond their original purposes, where the key ingredient is the specification which enables a trained model to be adequately identi",
    "link": "http://arxiv.org/abs/2210.03647",
    "context": "Title: Learnware: Small Models Do Big. (arXiv:2210.03647v2 [cs.LG] UPDATED)\nAbstract: There are complaints about current machine learning techniques such as the requirement of a huge amount of training data and proficient training skills, the difficulty of continual learning, the risk of catastrophic forgetting, the leaking of data privacy/proprietary, etc. Most research efforts have been focusing on one of those concerned issues separately, paying less attention to the fact that most issues are entangled in practice. The prevailing big model paradigm, which has achieved impressive results in natural language processing and computer vision applications, has not yet addressed those issues, whereas becoming a serious source of carbon emissions. This article offers an overview of the learnware paradigm, which attempts to enable users not need to build machine learning models from scratch, with the hope of reusing small models to do things even beyond their original purposes, where the key ingredient is the specification which enables a trained model to be adequately identi",
    "path": "papers/22/10/2210.03647.json",
    "total_tokens": 767,
    "translated_title": "Learnware: 小模型实现大作为",
    "translated_abstract": "当前机器学习技术存在训练数据量大、训练技能高、连续学习难、遗忘风险大、数据隐私和专有信息泄露等问题，而过去的大模型范式虽然在自然语言处理和计算机视觉应用中取得了惊人的结果，但并未解决这些问题，反而成为严重的碳排放源。该文概述了Learnware范式，让用户不需要从头构建机器学习模型，希望利用小型模型可以实现超越原始目的的事情，其中关键是规范，可以使训练的模型得到充分鉴别。",
    "tldr": "Learnware范式旨在帮助用户充分利用小型模型，实现超越原始目的的事情，以解决当前机器学习技术面临的数据量大、训练难度高、数据安全等问题。",
    "en_tdlr": "The Learnware paradigm aims to help users make full use of small models to achieve things beyond their original purposes, in order to solve the problems of large data volume, high training difficulty, and data security faced by current machine learning techniques."
}