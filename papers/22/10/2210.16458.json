{
    "title": "Reformulating van Rijsbergen's $F_{\\beta}$ metric for weighted binary cross-entropy. (arXiv:2210.16458v2 [stat.ML] UPDATED)",
    "abstract": "The separation of performance metrics from gradient based loss functions may not always give optimal results and may miss vital aggregate information. This paper investigates incorporating a performance metric alongside differentiable loss functions to inform training outcomes. The goal is to guide model performance and interpretation by assuming statistical distributions on this performance metric for dynamic weighting. The focus is on van Rijsbergens $F_{\\beta}$ metric -- a popular choice for gauging classification performance. Through distributional assumptions on the $F_{\\beta}$, an intermediary link can be established to the standard binary cross-entropy via dynamic penalty weights. First, the $F_{\\beta}$ metric is reformulated to facilitate assuming statistical distributions with accompanying proofs for the cumulative density function. These probabilities are used within a knee curve algorithm to find an optimal $\\beta$ or $\\beta_{opt}$. This $\\beta_{opt}$ is used as a weight or ",
    "link": "http://arxiv.org/abs/2210.16458",
    "context": "Title: Reformulating van Rijsbergen's $F_{\\beta}$ metric for weighted binary cross-entropy. (arXiv:2210.16458v2 [stat.ML] UPDATED)\nAbstract: The separation of performance metrics from gradient based loss functions may not always give optimal results and may miss vital aggregate information. This paper investigates incorporating a performance metric alongside differentiable loss functions to inform training outcomes. The goal is to guide model performance and interpretation by assuming statistical distributions on this performance metric for dynamic weighting. The focus is on van Rijsbergens $F_{\\beta}$ metric -- a popular choice for gauging classification performance. Through distributional assumptions on the $F_{\\beta}$, an intermediary link can be established to the standard binary cross-entropy via dynamic penalty weights. First, the $F_{\\beta}$ metric is reformulated to facilitate assuming statistical distributions with accompanying proofs for the cumulative density function. These probabilities are used within a knee curve algorithm to find an optimal $\\beta$ or $\\beta_{opt}$. This $\\beta_{opt}$ is used as a weight or ",
    "path": "papers/22/10/2210.16458.json",
    "total_tokens": 1003,
    "tldr": "本文研究将性能度量与可微分损失函数结合在一起，以指导训练结果的性能和解释性。通过对$F_{\\beta}$的分布假设，利用动态加权来指导模型性能和解释；膝曲线算法用于找到最优的$\\beta$或$\\beta_{opt}$，作为优化过程中的权重或增加损失。",
    "en_tdlr": "This paper investigates incorporating a performance metric alongside differentiable loss functions to inform training outcomes. Through distributional assumptions on the $F_{\\beta}$ metric, dynamic weighting is used to guide model performance and interpretation. The knee curve algorithm is used to find an optimal $\\beta$ or $\\beta_{opt}$, which is used as a weight or increase in loss for optimization."
}