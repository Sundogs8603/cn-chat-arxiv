{
    "title": "Towards Summary Candidates Fusion. (arXiv:2210.08779v2 [cs.CL] UPDATED)",
    "abstract": "Sequence-to-sequence deep neural models fine-tuned for abstractive summarization can achieve great performance on datasets with enough human annotations. Yet, it has been shown that they have not reached their full potential, with a wide gap between the top beam search output and the oracle beam. Recently, re-ranking methods have been proposed, to learn to select a better summary candidate. However, such methods are limited by the summary quality aspects captured by the first-stage candidates. To bypass this limitation, we propose a new paradigm in second-stage abstractive summarization called SummaFusion that fuses several summary candidates to produce a novel abstractive second-stage summary. Our method works well on several summarization datasets, improving both the ROUGE scores and qualitative properties of fused summaries. It is especially good when the candidates to fuse are worse, such as in the few-shot setup where we set a new state-of-the-art. We will make our code and checkp",
    "link": "http://arxiv.org/abs/2210.08779",
    "context": "Title: Towards Summary Candidates Fusion. (arXiv:2210.08779v2 [cs.CL] UPDATED)\nAbstract: Sequence-to-sequence deep neural models fine-tuned for abstractive summarization can achieve great performance on datasets with enough human annotations. Yet, it has been shown that they have not reached their full potential, with a wide gap between the top beam search output and the oracle beam. Recently, re-ranking methods have been proposed, to learn to select a better summary candidate. However, such methods are limited by the summary quality aspects captured by the first-stage candidates. To bypass this limitation, we propose a new paradigm in second-stage abstractive summarization called SummaFusion that fuses several summary candidates to produce a novel abstractive second-stage summary. Our method works well on several summarization datasets, improving both the ROUGE scores and qualitative properties of fused summaries. It is especially good when the candidates to fuse are worse, such as in the few-shot setup where we set a new state-of-the-art. We will make our code and checkp",
    "path": "papers/22/10/2210.08779.json",
    "total_tokens": 938,
    "translated_title": "向总结候选项融合迈进",
    "translated_abstract": "细调用于抽象总结的序列到序列深度神经模型可以在具有足够人为注释的数据集上取得良好的性能。然而，研究表明它们尚未达到其全部潜力，最佳束搜索输出与完美结果之间存在着很大差距。最近出现了重新排名方法，学习选择更好的摘要候选项。然而，这种方法受第一阶段候选项捕获的摘要质量方面的限制。为了绕过这种限制，我们提出了一种新范式，称为“SummaFusion”，它在第二阶段的抽象总结中融合了多个总结候选项，从而产生了一个新的抽象总结。我们的方法在几个摘要数据集上表现良好，提高了融合总结的ROUGE分数和质量特性。当需要融合的候选项较差时，特别是在少样本设置下，我们取得了新的最高水平。我们将在发表后公开我们的代码和检查点。",
    "tldr": "本文提出了一种名为SummaFusion的新范式，通过融合多个总结候选项来产生一个新的抽象总结，以改善第一阶段候选项的限制，并在多个摘要数据集上取得良好的性能，尤其是在少样本设置下。",
    "en_tdlr": "This paper proposes a new paradigm called SummaFusion that fuses several summary candidates to produce a novel abstractive second-stage summary, improving the limitation of the first-stage candidates, and achieves good performance on several summarization datasets, especially in the few-shot setup."
}