{
    "title": "Stochastic Differentially Private and Fair Learning. (arXiv:2210.08781v2 [cs.LG] UPDATED)",
    "abstract": "Machine learning models are increasingly used in high-stakes decision-making systems. In such applications, a major concern is that these models sometimes discriminate against certain demographic groups such as individuals with certain race, gender, or age. Another major concern in these applications is the violation of the privacy of users. While fair learning algorithms have been developed to mitigate discrimination issues, these algorithms can still leak sensitive information, such as individuals' health or financial records. Utilizing the notion of differential privacy (DP), prior works aimed at developing learning algorithms that are both private and fair. However, existing algorithms for DP fair learning are either not guaranteed to converge or require full batch of data in each iteration of the algorithm to converge. In this paper, we provide the first stochastic differentially private algorithm for fair learning that is guaranteed to converge. Here, the term \"stochastic\" refers",
    "link": "http://arxiv.org/abs/2210.08781",
    "context": "Title: Stochastic Differentially Private and Fair Learning. (arXiv:2210.08781v2 [cs.LG] UPDATED)\nAbstract: Machine learning models are increasingly used in high-stakes decision-making systems. In such applications, a major concern is that these models sometimes discriminate against certain demographic groups such as individuals with certain race, gender, or age. Another major concern in these applications is the violation of the privacy of users. While fair learning algorithms have been developed to mitigate discrimination issues, these algorithms can still leak sensitive information, such as individuals' health or financial records. Utilizing the notion of differential privacy (DP), prior works aimed at developing learning algorithms that are both private and fair. However, existing algorithms for DP fair learning are either not guaranteed to converge or require full batch of data in each iteration of the algorithm to converge. In this paper, we provide the first stochastic differentially private algorithm for fair learning that is guaranteed to converge. Here, the term \"stochastic\" refers",
    "path": "papers/22/10/2210.08781.json",
    "total_tokens": 879,
    "translated_title": "随机差分隐私与公平学习",
    "translated_abstract": "机器学习模型正在越来越多地应用于高风险决策系统中。在这些应用中，一个主要问题是这些模型有时会对某些人口统计学群体进行歧视，比如某些种族、性别或年龄的个体。这些应用中另一个主要问题是侵犯用户的隐私。虽然已经开发出公平学习算法来减轻歧视问题，但这些算法仍然可能泄漏敏感信息，如个人的健康或财务记录。利用差分隐私（DP）的概念，早期的研究旨在开发既能够保护隐私又能够进行公平学习的学习算法。然而，现有的随机 DP 公平学习算法要么不能保证收敛，要么需要每次算法迭代中使用完整的批量数据来进行收敛。在本文中，我们提供了第一个可以保证收敛的随机差分隐私公平学习算法。这里的“随机”一词指的是",
    "tldr": "本文提供了第一个能够保证收敛的随机差分隐私公平学习算法。该算法解决了高风险决策系统中面临的歧视和隐私泄漏问题。",
    "en_tdlr": "This paper proposes the first stochastic differentially private algorithm for fair learning that is guaranteed to converge, addressing discrimination and privacy leakage issues in high-stakes decision-making systems."
}