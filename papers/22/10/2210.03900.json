{
    "title": "Bottleneck Analysis of Dynamic Graph Neural Network Inference on CPU and GPU. (arXiv:2210.03900v2 [cs.AR] UPDATED)",
    "abstract": "Dynamic graph neural network (DGNN) is becoming increasingly popular because of its widespread use in capturing dynamic features in the real world. A variety of dynamic graph neural networks designed from algorithmic perspectives have succeeded in incorporating temporal information into graph processing. Despite the promising algorithmic performance, deploying DGNNs on hardware presents additional challenges due to the model complexity, diversity, and the nature of the time dependency. Meanwhile, the differences between DGNNs and static graph neural networks make hardware-related optimizations for static graph neural networks unsuitable for DGNNs. In this paper, we select eight prevailing DGNNs with different characteristics and profile them on both CPU and GPU. The profiling results are summarized and analyzed, providing in-depth insights into the bottlenecks of DGNNs on hardware and identifying potential optimization opportunities for future DGNN acceleration. Followed by a comprehen",
    "link": "http://arxiv.org/abs/2210.03900",
    "context": "Title: Bottleneck Analysis of Dynamic Graph Neural Network Inference on CPU and GPU. (arXiv:2210.03900v2 [cs.AR] UPDATED)\nAbstract: Dynamic graph neural network (DGNN) is becoming increasingly popular because of its widespread use in capturing dynamic features in the real world. A variety of dynamic graph neural networks designed from algorithmic perspectives have succeeded in incorporating temporal information into graph processing. Despite the promising algorithmic performance, deploying DGNNs on hardware presents additional challenges due to the model complexity, diversity, and the nature of the time dependency. Meanwhile, the differences between DGNNs and static graph neural networks make hardware-related optimizations for static graph neural networks unsuitable for DGNNs. In this paper, we select eight prevailing DGNNs with different characteristics and profile them on both CPU and GPU. The profiling results are summarized and analyzed, providing in-depth insights into the bottlenecks of DGNNs on hardware and identifying potential optimization opportunities for future DGNN acceleration. Followed by a comprehen",
    "path": "papers/22/10/2210.03900.json",
    "total_tokens": 811,
    "translated_title": "CPU和GPU上动态图神经网络推理的瓶颈分析",
    "translated_abstract": "动态图神经网络(DGNN)因其在捕捉现实世界动态特征方面的广泛应用而变得越来越受欢迎。从算法的角度设计了各种动态图神经网络，成功地将时间信息纳入了图形处理中。尽管算法性能表现有前途，但将DGNN部署到硬件上仍面临着额外的挑战，包括模型复杂性、多样性以及时间依赖性的特性。同时，DGNN与静态图神经网络之间的差异使得针对静态图神经网络的硬件相关优化不适用于DGNN。本文选取了八种具有不同特征的流行DGNN，并在CPU和GPU上进行了分析。总结并分析了分析结果，深入探讨了DGNN在硬件上的瓶颈，并确定了未来DGNN加速的潜在优化机会。",
    "tldr": "本文分析了8种不同特征的DGNN在CPU和GPU上的性能瓶颈，并提出了未来优化的机会。",
    "en_tdlr": "This paper analyzes the performance bottlenecks of 8 different DGNNs on both CPU and GPU, and identifies potential optimization opportunities for future acceleration."
}