{
    "title": "Learning from Demonstrations of Critical Driving Behaviours Using Driver's Risk Field. (arXiv:2210.01747v2 [cs.RO] UPDATED)",
    "abstract": "In recent years, imitation learning (IL) has been widely used in industry as the core of autonomous vehicle (AV) planning modules. However, previous IL works show sample inefficiency and low generalisation in safety-critical scenarios, on which they are rarely tested. As a result, IL planners can reach a performance plateau where adding more training data ceases to improve the learnt policy. First, our work presents an IL model using the spline coefficient parameterisation and offline expert queries to enhance safety and training efficiency. Then, we expose the weakness of the learnt IL policy by synthetically generating critical scenarios through optimisation of parameters of the driver's risk field (DRF), a parametric human driving behaviour model implemented in a multi-agent traffic simulator based on the Lyft Prediction Dataset. To continuously improve the learnt policy, we retrain the IL model with augmented data. Thanks to the expressivity and interpretability of the DRF, the des",
    "link": "http://arxiv.org/abs/2210.01747",
    "context": "Title: Learning from Demonstrations of Critical Driving Behaviours Using Driver's Risk Field. (arXiv:2210.01747v2 [cs.RO] UPDATED)\nAbstract: In recent years, imitation learning (IL) has been widely used in industry as the core of autonomous vehicle (AV) planning modules. However, previous IL works show sample inefficiency and low generalisation in safety-critical scenarios, on which they are rarely tested. As a result, IL planners can reach a performance plateau where adding more training data ceases to improve the learnt policy. First, our work presents an IL model using the spline coefficient parameterisation and offline expert queries to enhance safety and training efficiency. Then, we expose the weakness of the learnt IL policy by synthetically generating critical scenarios through optimisation of parameters of the driver's risk field (DRF), a parametric human driving behaviour model implemented in a multi-agent traffic simulator based on the Lyft Prediction Dataset. To continuously improve the learnt policy, we retrain the IL model with augmented data. Thanks to the expressivity and interpretability of the DRF, the des",
    "path": "papers/22/10/2210.01747.json",
    "total_tokens": 976,
    "tldr": "本文提出一种使用样条系数参数化和离线专家查询的模仿学习模型来增强安全性和训练效率，通过对驾驶员风险场的优化来暴露学习的模仿学习策略弱点，最后使用增强数据重新训练模型以不断改进学习策略。",
    "en_tdlr": "The paper proposes an imitation learning model using spline coefficient parameterisation and offline expert queries to enhance safety and training efficiency, exposes the weakness of the learned policy through synthetic generation of critical scenarios by optimizing parameters of the driver's risk field, and eventually retrain the model with augmented data to continuously improve the learned policy."
}