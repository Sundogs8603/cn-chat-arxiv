{
    "title": "Investigating Neuron Disturbing in Fusing Heterogeneous Neural Networks. (arXiv:2210.12974v2 [cs.LG] UPDATED)",
    "abstract": "Fusing deep learning models trained on separately located clients into a global model in a one-shot communication round is a straightforward implementation of Federated Learning. Although current model fusion methods are shown experimentally valid in fusing neural networks with almost identical architectures, they are rarely theoretically analyzed. In this paper, we reveal the phenomenon of neuron disturbing, where neurons from heterogeneous local models interfere with each other mutually. We give detailed explanations from a Bayesian viewpoint combining the data heterogeneity among clients and properties of neural networks. Furthermore, to validate our findings, we propose an experimental method that excludes neuron disturbing and fuses neural networks via adaptively selecting a local model, called AMS, to execute the prediction according to the input. The experiments demonstrate that AMS is more robust in data heterogeneity than general model fusion and ensemble methods. This implies",
    "link": "http://arxiv.org/abs/2210.12974",
    "context": "Title: Investigating Neuron Disturbing in Fusing Heterogeneous Neural Networks. (arXiv:2210.12974v2 [cs.LG] UPDATED)\nAbstract: Fusing deep learning models trained on separately located clients into a global model in a one-shot communication round is a straightforward implementation of Federated Learning. Although current model fusion methods are shown experimentally valid in fusing neural networks with almost identical architectures, they are rarely theoretically analyzed. In this paper, we reveal the phenomenon of neuron disturbing, where neurons from heterogeneous local models interfere with each other mutually. We give detailed explanations from a Bayesian viewpoint combining the data heterogeneity among clients and properties of neural networks. Furthermore, to validate our findings, we propose an experimental method that excludes neuron disturbing and fuses neural networks via adaptively selecting a local model, called AMS, to execute the prediction according to the input. The experiments demonstrate that AMS is more robust in data heterogeneity than general model fusion and ensemble methods. This implies",
    "path": "papers/22/10/2210.12974.json",
    "total_tokens": 867,
    "translated_title": "研究异构神经网络中的神经干扰",
    "translated_abstract": "将在不同位置上训练的深度学习模型融合成一个全局模型是联邦学习的直接实现。尽管当前的模型融合方法在融合几乎相同结构的神经网络时在实验上是有效的，但它们很少被进行理论分析。本文从贝叶斯观点结合来自客户端的数据异质性和神经网络的特性，揭示了神经元干扰的现象，即异构本地模型的神经元相互干扰。此外，为了验证我们的发现，我们提出了一种通过自适应选择本地模型来执行预测的实验方法，称为AMS，以排除神经元干扰并融合神经网络。实验结果表明，AMS在数据异质性方面比一般的模型融合和集成方法更加鲁棒。",
    "tldr": "该论文提出了研究异构神经网络中神经干扰现象的理论分析和实验验证，并提出了一种通过自适应选择本地模型来执行预测的方法。实验结果表明，该方法在数据异质性方面更加鲁棒。"
}