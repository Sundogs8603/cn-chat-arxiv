{
    "title": "PAC-Bayes Generalisation Bounds for Heavy-Tailed Losses through Supermartingales. (arXiv:2210.00928v2 [stat.ML] UPDATED)",
    "abstract": "While PAC-Bayes is now an established learning framework for light-tailed losses (\\emph{e.g.}, subgaussian or subexponential), its extension to the case of heavy-tailed losses remains largely uncharted and has attracted a growing interest in recent years. We contribute PAC-Bayes generalisation bounds for heavy-tailed losses under the sole assumption of bounded variance of the loss function. Under that assumption, we extend previous results from \\citet{kuzborskij2019efron}. Our key technical contribution is exploiting an extention of Markov's inequality for supermartingales. Our proof technique unifies and extends different PAC-Bayesian frameworks by providing bounds for unbounded martingales as well as bounds for batch and online learning with heavy-tailed losses.",
    "link": "http://arxiv.org/abs/2210.00928",
    "context": "Title: PAC-Bayes Generalisation Bounds for Heavy-Tailed Losses through Supermartingales. (arXiv:2210.00928v2 [stat.ML] UPDATED)\nAbstract: While PAC-Bayes is now an established learning framework for light-tailed losses (\\emph{e.g.}, subgaussian or subexponential), its extension to the case of heavy-tailed losses remains largely uncharted and has attracted a growing interest in recent years. We contribute PAC-Bayes generalisation bounds for heavy-tailed losses under the sole assumption of bounded variance of the loss function. Under that assumption, we extend previous results from \\citet{kuzborskij2019efron}. Our key technical contribution is exploiting an extention of Markov's inequality for supermartingales. Our proof technique unifies and extends different PAC-Bayesian frameworks by providing bounds for unbounded martingales as well as bounds for batch and online learning with heavy-tailed losses.",
    "path": "papers/22/10/2210.00928.json",
    "total_tokens": 867,
    "translated_title": "通过超马氏过程推导重尾损失的PAC-Bayes泛化界",
    "translated_abstract": "尽管PAC-Bayes已经成为一种用于轻尾损失（例如亚高斯或亚指数）的学习框架，但其在重尾损失情况下的推广仍然未得到广泛研究，近年来受到越来越多的关注。本文在假定损失函数有界方差的情况下，为重尾损失提供了PAC-Bayes泛化界。在该假设下，我们扩展了\\citet{kuzborskij2019efron}的先前结果。我们的关键技术贡献在于利用超马氏过程的马尔科夫不等式的扩展。我们的证明技术通过为无界鞅提供界限，以及为重尾损失的批处理和在线学习提供界限，统一和扩展了不同的PAC-Bayesian框架。",
    "tldr": "本文为重尾损失情况下的PAC-Bayes提供了泛化界，扩展了先前的研究，并通过马尔科夫不等式的扩展为不同的PAC-Bayesian框架提供了界限。",
    "en_tdlr": "This article provides PAC-Bayes generalization bounds for heavy-tailed losses and extends previous research by exploiting an extension of Markov's inequality for supermartingales. The proof unifies and extends different PAC-Bayesian frameworks by providing bounds for unbounded martingales as well as bounds for batch and online learning with heavy-tailed losses."
}