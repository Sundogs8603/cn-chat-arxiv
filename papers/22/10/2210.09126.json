{
    "title": "Verifiable and Provably Secure Machine Unlearning. (arXiv:2210.09126v2 [cs.LG] UPDATED)",
    "abstract": "Machine unlearning aims to remove points from the training dataset of a machine learning model after training; for example when a user requests their data to be deleted. While many machine unlearning methods have been proposed, none of them enable users to audit the procedure. Furthermore, recent work shows a user is unable to verify if their data was unlearnt from an inspection of the model alone. Rather than reasoning about model parameters, we propose to view verifiable unlearning as a security problem. To this end, we present the first cryptographic definition of verifiable unlearning to formally capture the guarantees of a machine unlearning system. In this framework, the server first computes a proof that the model was trained on a dataset $D$. Given a user data point $d$ requested to be deleted, the server updates the model using an unlearning algorithm. It then provides a proof of the correct execution of unlearning and that $d \\notin D'$, where $D'$ is the new training dataset",
    "link": "http://arxiv.org/abs/2210.09126",
    "context": "Title: Verifiable and Provably Secure Machine Unlearning. (arXiv:2210.09126v2 [cs.LG] UPDATED)\nAbstract: Machine unlearning aims to remove points from the training dataset of a machine learning model after training; for example when a user requests their data to be deleted. While many machine unlearning methods have been proposed, none of them enable users to audit the procedure. Furthermore, recent work shows a user is unable to verify if their data was unlearnt from an inspection of the model alone. Rather than reasoning about model parameters, we propose to view verifiable unlearning as a security problem. To this end, we present the first cryptographic definition of verifiable unlearning to formally capture the guarantees of a machine unlearning system. In this framework, the server first computes a proof that the model was trained on a dataset $D$. Given a user data point $d$ requested to be deleted, the server updates the model using an unlearning algorithm. It then provides a proof of the correct execution of unlearning and that $d \\notin D'$, where $D'$ is the new training dataset",
    "path": "papers/22/10/2210.09126.json",
    "total_tokens": 856,
    "translated_title": "可验证且具有证明安全性的机器学习去除算法",
    "translated_abstract": "机器学习去除算法旨在在训练后从训练数据集中移除某些点；例如当用户请求删除数据时。虽然已经提出了许多机器学习去除算法，但是没有一种算法使得用户可以审计这个过程。此外，最近的研究表明，用户无法通过检查模型本身来验证其数据是否已被删除。为了解决这个问题，我们不是考虑模型参数，而是将可验证的算法视为一种安全问题。为此，我们提出了可验证去除算法的第一个加密定义，以正式捕捉机器学习去除算法系统的保证。在此框架下，服务器首先计算一个证明，证明该模型在数据集 $D$ 上进行了训练。给定一个要删除的用户数据点 $d$，服务器使用去除算法更新模型。然后它提供正确执行去除算法并且 $d \\notin D'$ 的证明，其中 $D'$ 是新的训练数据集。",
    "tldr": "该论文提出了可证明安全的机器学习去除算法，可以让用户审计这个过程，以确保训练数据的隐私得到保护。",
    "en_tdlr": "This paper proposes a verifiable and provably secure machine unlearning algorithm, which allows users to audit the process and ensure the privacy of their training data."
}