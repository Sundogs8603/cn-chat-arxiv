{
    "title": "C2KD: Cross-Lingual Cross-Modal Knowledge Distillation for Multilingual Text-Video Retrieval. (arXiv:2210.03625v2 [cs.CL] UPDATED)",
    "abstract": "Multilingual text-video retrieval methods have improved significantly in recent years, but the performance for other languages lags behind English. We propose a Cross-Lingual Cross-Modal Knowledge Distillation method to improve multilingual text-video retrieval. Inspired by the fact that English text-video retrieval outperforms other languages, we train a student model using input text in different languages to match the cross-modal predictions from teacher models using input text in English. We propose a cross entropy based objective which forces the distribution over the student's text-video similarity scores to be similar to those of the teacher models. We introduce a new multilingual video dataset, Multi-YouCook2, by translating the English captions in the YouCook2 video dataset to 8 other languages. Our method improves multilingual text-video retrieval performance on Multi-YouCook2 and several other datasets such as Multi-MSRVTT and VATEX. We also conducted an analysis on the effe",
    "link": "http://arxiv.org/abs/2210.03625",
    "context": "Title: C2KD: Cross-Lingual Cross-Modal Knowledge Distillation for Multilingual Text-Video Retrieval. (arXiv:2210.03625v2 [cs.CL] UPDATED)\nAbstract: Multilingual text-video retrieval methods have improved significantly in recent years, but the performance for other languages lags behind English. We propose a Cross-Lingual Cross-Modal Knowledge Distillation method to improve multilingual text-video retrieval. Inspired by the fact that English text-video retrieval outperforms other languages, we train a student model using input text in different languages to match the cross-modal predictions from teacher models using input text in English. We propose a cross entropy based objective which forces the distribution over the student's text-video similarity scores to be similar to those of the teacher models. We introduce a new multilingual video dataset, Multi-YouCook2, by translating the English captions in the YouCook2 video dataset to 8 other languages. Our method improves multilingual text-video retrieval performance on Multi-YouCook2 and several other datasets such as Multi-MSRVTT and VATEX. We also conducted an analysis on the effe",
    "path": "papers/22/10/2210.03625.json",
    "total_tokens": 1020,
    "translated_title": "C2KD: 跨语言跨模态知识蒸馏以提升多语言文本-视频检索",
    "translated_abstract": "近年来，多语言文本-视频检索方法有了显著提升，但其它语言的表现仍然落后于英语。本文提出了一种跨语言跨模态知识蒸馏方法，以提升多语言文本-视频检索。受到英语文本-视频检索胜过其它语言的事实启发，我们使用不同语言的输入文本训练一个学生模型，使其与使用英语输入文本的教师模型的跨模态预测相匹配。我们提出了一个基于交叉熵的目标函数，强制学生的文本-视频相似度分数分布与教师模型的相似度分数分布相似。我们引入了一个新的多语言视频数据集Multi-YouCook2，通过将YouCook2视频数据集中的英语字幕翻译为8种其他语言来创建。我们的方法提高了Multi-YouCook2以及多个其他数据集，比如Multi-MSRVTT和VATEX的多语言文本-视频检索性能。我们还对方法效果进行了分析。",
    "tldr": "本文提出了一种跨语言跨模态知识蒸馏方法，使用不同语言的输入文本训练一个学生模型，与使用英语输入文本的教师模型的跨模态预测相匹配，以提升多语言文本-视频检索。我们引入了一个新的多语言视频数据集，Multi-YouCook2，以及在多个数据集上验证了我们方法的性能提升。",
    "en_tdlr": "This paper proposes a Cross-Lingual Cross-Modal Knowledge Distillation method to improve multilingual text-video retrieval. By training a student model using input text in different languages to match the cross-modal predictions from teacher models using input text in English, the proposed method introduces a new multilingual video dataset, Multi-YouCook2, and improves performance on several datasets including Multi-MSRVTT and VATEX."
}