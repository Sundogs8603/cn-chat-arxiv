{
    "title": "Using Both Demonstrations and Language Instructions to Efficiently Learn Robotic Tasks. (arXiv:2210.04476v2 [cs.RO] UPDATED)",
    "abstract": "Demonstrations and natural language instructions are two common ways to specify and teach robots novel tasks. However, for many complex tasks, a demonstration or language instruction alone contains ambiguities, preventing tasks from being specified clearly. In such cases, a combination of both a demonstration and an instruction more concisely and effectively conveys the task to the robot than either modality alone. To instantiate this problem setting, we train a single multi-task policy on a few hundred challenging robotic pick-and-place tasks and propose DeL-TaCo (Joint Demo-Language Task Conditioning), a method for conditioning a robotic policy on task embeddings comprised of two components: a visual demonstration and a language instruction. By allowing these two modalities to mutually disambiguate and clarify each other during novel task specification, DeL-TaCo (1) substantially decreases the teacher effort needed to specify a new task and (2) achieves better generalization performa",
    "link": "http://arxiv.org/abs/2210.04476",
    "context": "Title: Using Both Demonstrations and Language Instructions to Efficiently Learn Robotic Tasks. (arXiv:2210.04476v2 [cs.RO] UPDATED)\nAbstract: Demonstrations and natural language instructions are two common ways to specify and teach robots novel tasks. However, for many complex tasks, a demonstration or language instruction alone contains ambiguities, preventing tasks from being specified clearly. In such cases, a combination of both a demonstration and an instruction more concisely and effectively conveys the task to the robot than either modality alone. To instantiate this problem setting, we train a single multi-task policy on a few hundred challenging robotic pick-and-place tasks and propose DeL-TaCo (Joint Demo-Language Task Conditioning), a method for conditioning a robotic policy on task embeddings comprised of two components: a visual demonstration and a language instruction. By allowing these two modalities to mutually disambiguate and clarify each other during novel task specification, DeL-TaCo (1) substantially decreases the teacher effort needed to specify a new task and (2) achieves better generalization performa",
    "path": "papers/22/10/2210.04476.json",
    "total_tokens": 922,
    "translated_title": "使用演示和自然语言指令高效学习机器人任务",
    "translated_abstract": "演示和自然语言指令是指定和教授机器人新任务的两种常见方式。然而，对于许多复杂任务，单独使用演示或语言指令会存在歧义，导致任务无法清晰地被指定。在这种情况下，演示和指令的组合可以更简明地有效地向机器人传达任务。为了演示这个问题设置，我们在几百个挑战性的机器人拾取放置任务上训练了一个多任务策略，并提出了一种名为 DeL-TaCo（联合演示 - 语言任务调节）的方法，用于将机器人策略调节为由两个组成部分组成的任务嵌入：视觉演示和语言指令。通过允许这两种模式在新任务规范时相互消除歧义和澄清彼此，DeL-TaCo（1）大大降低了指定新任务所需的教师工作量，并且（2）实现了更好的泛化性能。",
    "tldr": "本论文提出了一种使用演示和自然语言指令相结合的机器人任务学习方法，其基于两种模式相互消除歧义来有效地指定和教授机器人复杂任务。此方法可以减少教师工作量并实现更好的泛化性能。",
    "en_tdlr": "This paper proposes a method for robot task learning that combines demonstrations and natural language instructions to effectively specify and teach complex tasks. By allowing the two modalities to disambiguate each other, this method reduces teacher effort and achieves better generalization performance."
}