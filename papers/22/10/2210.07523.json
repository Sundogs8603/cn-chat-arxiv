{
    "title": "Self-Adaptive Named Entity Recognition by Retrieving Unstructured Knowledge. (arXiv:2210.07523v3 [cs.CL] UPDATED)",
    "abstract": "Although named entity recognition (NER) helps us to extract domain-specific entities from text (e.g., artists in the music domain), it is costly to create a large amount of training data or a structured knowledge base to perform accurate NER in the target domain. Here, we propose self-adaptive NER, which retrieves external knowledge from unstructured text to learn the usages of entities that have not been learned well. To retrieve useful knowledge for NER, we design an effective two-stage model that retrieves unstructured knowledge using uncertain entities as queries. Our model predicts the entities in the input and then finds those of which the prediction is not confident. Then, it retrieves knowledge by using these uncertain entities as queries and concatenates the retrieved text to the original input to revise the prediction. Experiments on CrossNER datasets demonstrated that our model outperforms strong baselines by 2.35 points in F1 metric.",
    "link": "http://arxiv.org/abs/2210.07523",
    "context": "Title: Self-Adaptive Named Entity Recognition by Retrieving Unstructured Knowledge. (arXiv:2210.07523v3 [cs.CL] UPDATED)\nAbstract: Although named entity recognition (NER) helps us to extract domain-specific entities from text (e.g., artists in the music domain), it is costly to create a large amount of training data or a structured knowledge base to perform accurate NER in the target domain. Here, we propose self-adaptive NER, which retrieves external knowledge from unstructured text to learn the usages of entities that have not been learned well. To retrieve useful knowledge for NER, we design an effective two-stage model that retrieves unstructured knowledge using uncertain entities as queries. Our model predicts the entities in the input and then finds those of which the prediction is not confident. Then, it retrieves knowledge by using these uncertain entities as queries and concatenates the retrieved text to the original input to revise the prediction. Experiments on CrossNER datasets demonstrated that our model outperforms strong baselines by 2.35 points in F1 metric.",
    "path": "papers/22/10/2210.07523.json",
    "total_tokens": 888,
    "translated_title": "通过检索非结构化知识进行自适应命名实体识别",
    "translated_abstract": "命名实体识别（NER）可以用于从文本中提取特定领域的实体（例如音乐领域中的艺术家），但是创建大量的训练数据或结构化知识库来执行目标领域的准确NER是很昂贵的。为了检索未被很好地学习的实体的用法，我们提出了一种自适应NER方法，它从非结构化文本中检索外部知识。为了检索NER的有用知识，我们设计了一个有效的两阶段模型，使用不确定的实体作为查询来检索非结构化知识。我们的模型预测输入中的实体，然后找到那些预测不自信的实体。然后，它使用这些不确定的实体作为查询来检索知识，并将检索到的文本连接到原始输入以修正预测。在CrossNER数据集上的实验表明，我们的模型在F1度量上比强基线模型高2.35个百分点。",
    "tldr": "本文提出了一种自适应命名实体识别方法，通过检索非结构化知识以修正预测，实验结果表明该方法在F1度量上优于强基线模型2.35个百分点。",
    "en_tdlr": "This paper proposes a self-adaptive named entity recognition method by retrieving external knowledge from unstructured text to revise predictions, and the experimental results show that it outperforms strong baselines by 2.35 points in F1 metric on CrossNER dataset."
}