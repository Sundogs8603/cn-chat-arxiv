{
    "title": "Multi-Level Firing with Spiking DS-ResNet: Enabling Better and Deeper Directly-Trained Spiking Neural Networks. (arXiv:2210.06386v2 [cs.NE] UPDATED)",
    "abstract": "Spiking neural networks (SNNs) are bio-inspired neural networks with asynchronous discrete and sparse characteristics, which have increasingly manifested their superiority in low energy consumption. Recent research is devoted to utilizing spatio-temporal information to directly train SNNs by backpropagation. However, the binary and non-differentiable properties of spike activities force directly trained SNNs to suffer from serious gradient vanishing and network degradation, which greatly limits the performance of directly trained SNNs and prevents them from going deeper. In this paper, we propose a multi-level firing (MLF) method based on the existing spatio-temporal back propagation (STBP) method, and spiking dormant-suppressed residual network (spiking DS-ResNet). MLF enables more efficient gradient propagation and the incremental expression ability of the neurons. Spiking DS-ResNet can efficiently perform identity mapping of discrete spikes, as well as provide a more suitable connec",
    "link": "http://arxiv.org/abs/2210.06386",
    "context": "Title: Multi-Level Firing with Spiking DS-ResNet: Enabling Better and Deeper Directly-Trained Spiking Neural Networks. (arXiv:2210.06386v2 [cs.NE] UPDATED)\nAbstract: Spiking neural networks (SNNs) are bio-inspired neural networks with asynchronous discrete and sparse characteristics, which have increasingly manifested their superiority in low energy consumption. Recent research is devoted to utilizing spatio-temporal information to directly train SNNs by backpropagation. However, the binary and non-differentiable properties of spike activities force directly trained SNNs to suffer from serious gradient vanishing and network degradation, which greatly limits the performance of directly trained SNNs and prevents them from going deeper. In this paper, we propose a multi-level firing (MLF) method based on the existing spatio-temporal back propagation (STBP) method, and spiking dormant-suppressed residual network (spiking DS-ResNet). MLF enables more efficient gradient propagation and the incremental expression ability of the neurons. Spiking DS-ResNet can efficiently perform identity mapping of discrete spikes, as well as provide a more suitable connec",
    "path": "papers/22/10/2210.06386.json",
    "total_tokens": 1003,
    "translated_title": "多层射击和沉默禁制残差网络：实现更好和更深的直接训练尖峰神经网络",
    "translated_abstract": "尖峰神经网络（SNN）具有异步离散和稀疏特性，是一种生物启发的神经网络，它们在低能耗方面越来越表现出优越性。最近的研究致力于利用时空信息通过反向传播直接训练SNN。然而，尖峰活动的二进制和不可微的特性迫使直接训练的SNN遭受严重的梯度消失和网络退化，这极大地限制了直接训练的SNN的性能并阻止它们变得更深。本文提出了一种基于现有时空反向传播（STBP）方法的多层射击（MLF）方法和尖峰沉默禁制残差网络（spiking DS-ResNet）。MLF使梯度传播更加高效，并增量表达神经元的能力。尖峰DS-ResNet可以有效地执行离散尖峰的恒等映射，同时提供更合适的连接方式。",
    "tldr": "本文提出了一种多层射击（MLF）方法和尖峰沉默禁制残差网络（spiking DS-ResNet），通过 MLF 方法，可以更高效地传播梯度，增加神经元的增量表达能力；DS-ResNet 可以有效地执行离散尖峰的恒等映射，提高网络的表达能力。",
    "en_tdlr": "This paper proposes a multi-level firing (MLF) method and spiking dormant-suppressed residual network (spiking DS-ResNet), which enable more efficient gradient propagation and incremental expression ability of neurons. DS-ResNet efficiently performs identity mapping of discrete spikes, providing a more suitable connection for directly trained SNNs."
}