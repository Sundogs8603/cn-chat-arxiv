{
    "title": "Supervised Metric Learning to Rank for Retrieval via Contextual Similarity Optimization. (arXiv:2210.01908v3 [cs.LG] UPDATED)",
    "abstract": "There is extensive interest in metric learning methods for image retrieval. Many metric learning loss functions focus on learning a correct ranking of training samples, but strongly overfit semantically inconsistent labels and require a large amount of data. To address these shortcomings, we propose a new metric learning method, called contextual loss, which optimizes contextual similarity in addition to cosine similarity. Our contextual loss implicitly enforces semantic consistency among neighbors while converging to the correct ranking. We empirically show that the proposed loss is more robust to label noise, and is less prone to overfitting even when a large portion of train data is withheld. Extensive experiments demonstrate that our method achieves a new state-of-the-art across four image retrieval benchmarks and multiple different evaluation settings. Code is available at: https://github.com/Chris210634/metric-learning-using-contextual-similarity",
    "link": "http://arxiv.org/abs/2210.01908",
    "context": "Title: Supervised Metric Learning to Rank for Retrieval via Contextual Similarity Optimization. (arXiv:2210.01908v3 [cs.LG] UPDATED)\nAbstract: There is extensive interest in metric learning methods for image retrieval. Many metric learning loss functions focus on learning a correct ranking of training samples, but strongly overfit semantically inconsistent labels and require a large amount of data. To address these shortcomings, we propose a new metric learning method, called contextual loss, which optimizes contextual similarity in addition to cosine similarity. Our contextual loss implicitly enforces semantic consistency among neighbors while converging to the correct ranking. We empirically show that the proposed loss is more robust to label noise, and is less prone to overfitting even when a large portion of train data is withheld. Extensive experiments demonstrate that our method achieves a new state-of-the-art across four image retrieval benchmarks and multiple different evaluation settings. Code is available at: https://github.com/Chris210634/metric-learning-using-contextual-similarity",
    "path": "papers/22/10/2210.01908.json",
    "total_tokens": 943,
    "translated_title": "监督式度量学习以排序为目标的检索，通过上下文相似性优化",
    "translated_abstract": "在图像检索领域，度量学习方法备受关注。很多度量学习的损失函数都集中于对训练样本的正确排序，但是往往会过度拟合不一致的语义标签，需要大量的数据。为了解决这些缺陷，我们提出了一种新的度量学习方法——上下文损失，它除了优化余弦相似度以外，还优化了上下文相似性。我们的上下文损失能隐式地确保邻居之间的语义一致性并收敛于正确的排序。我们通过实验表明所提出的损失对标签噪声更加鲁棒，并且即使在保留大部分训练数据的情况下仍然不易过拟合。广泛的实验表明，我们的方法在四个图像检索基准和多种不同的评估环境下以新的最优状态取得了成功。本文代码可在以下链接中获得：https://github.com/Chris210634/metric-learning-using-contextual-similarity。",
    "tldr": "这项研究提出了一种新的度量学习方法——上下文损失，它通过优化上下文相似性隐式地确保邻居之间的语义一致性，并表现出更好的鲁棒性和抗噪声能力，取得了四个图像检索基准的最新最佳结果。",
    "en_tdlr": "This paper presents a new metric learning method called contextual loss, which implicitly enforces semantic consistency among neighbors by optimizing contextual similarity in addition to cosine similarity. The proposed loss is more robust to label noise and less prone to overfitting, achieving a new state-of-the-art across four image retrieval benchmarks."
}