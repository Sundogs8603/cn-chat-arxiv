{
    "title": "Towards Multi-Agent Reinforcement Learning driven Over-The-Counter Market Simulations. (arXiv:2210.07184v2 [cs.MA] UPDATED)",
    "abstract": "We study a game between liquidity provider and liquidity taker agents interacting in an over-the-counter market, for which the typical example is foreign exchange. We show how a suitable design of parameterized families of reward functions coupled with shared policy learning constitutes an efficient solution to this problem. By playing against each other, our deep-reinforcement-learning-driven agents learn emergent behaviors relative to a wide spectrum of objectives encompassing profit-and-loss, optimal execution and market share. In particular, we find that liquidity providers naturally learn to balance hedging and skewing, where skewing refers to setting their buy and sell prices asymmetrically as a function of their inventory. We further introduce a novel RL-based calibration algorithm which we found performed well at imposing constraints on the game equilibrium. On the theoretical side, we are able to show convergence rates for our multi-agent policy gradient algorithm under a tran",
    "link": "http://arxiv.org/abs/2210.07184",
    "context": "Title: Towards Multi-Agent Reinforcement Learning driven Over-The-Counter Market Simulations. (arXiv:2210.07184v2 [cs.MA] UPDATED)\nAbstract: We study a game between liquidity provider and liquidity taker agents interacting in an over-the-counter market, for which the typical example is foreign exchange. We show how a suitable design of parameterized families of reward functions coupled with shared policy learning constitutes an efficient solution to this problem. By playing against each other, our deep-reinforcement-learning-driven agents learn emergent behaviors relative to a wide spectrum of objectives encompassing profit-and-loss, optimal execution and market share. In particular, we find that liquidity providers naturally learn to balance hedging and skewing, where skewing refers to setting their buy and sell prices asymmetrically as a function of their inventory. We further introduce a novel RL-based calibration algorithm which we found performed well at imposing constraints on the game equilibrium. On the theoretical side, we are able to show convergence rates for our multi-agent policy gradient algorithm under a tran",
    "path": "papers/22/10/2210.07184.json",
    "total_tokens": 987,
    "translated_title": "多智能体强化学习驱动的场外交易市场模拟",
    "translated_abstract": "我们研究了场外交易市场中流动性提供者和流动性接受者代理之间的博弈，典型示例是外汇市场。我们展示了如何通过适当设计参数化的奖励函数家族，并结合共享策略学习，构建出这个问题的高效解决方案。通过相互对战，我们基于深度强化学习的智能体能够学习到相对于利润损失、最优执行和市场份额等广泛目标的新兴行为。特别地，我们发现流动性提供者自然地学习到平衡对冲和偏斜的策略，其中偏斜是指根据其库存量将买入价格和卖出价格设置为非对称。我们还提出了一种新颖的基于强化学习的校准算法，我们发现它在对博弈均衡施加约束方面表现良好。在理论方面，我们能够展示我们的多智能体策略梯度算法在转换下的收敛速度。",
    "tldr": "该论文研究了多智能体强化学习在场外交易市场模拟中的应用，通过适当设计奖励函数和共享策略学习，智能体能够学习到涵盖利润损失、最优执行和市场份额等多目标的新兴行为，同时也提出了一种基于强化学习的校准算法。",
    "en_tdlr": "This paper studies the application of multi-agent reinforcement learning in over-the-counter market simulations. By designing suitable reward functions and utilizing shared policy learning, the agents learn emergent behaviors encompassing various objectives, such as profit-and-loss, optimal execution, and market share. The paper also introduces a novel RL-based calibration algorithm and presents convergence rates for the multi-agent policy gradient algorithm."
}