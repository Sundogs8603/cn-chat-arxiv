{
    "title": "Being Comes from Not-being: Open-vocabulary Text-to-Motion Generation with Wordless Training. (arXiv:2210.15929v2 [cs.CV] UPDATED)",
    "abstract": "Text-to-motion generation is an emerging and challenging problem, which aims to synthesize motion with the same semantics as the input text. However, due to the lack of diverse labeled training data, most approaches either limit to specific types of text annotations or require online optimizations to cater to the texts during inference at the cost of efficiency and stability. In this paper, we investigate offline open-vocabulary text-to-motion generation in a zero-shot learning manner that neither requires paired training data nor extra online optimization to adapt for unseen texts. Inspired by the prompt learning in NLP, we pretrain a motion generator that learns to reconstruct the full motion from the masked motion. During inference, instead of changing the motion generator, our method reformulates the input text into a masked motion as the prompt for the motion generator to ``reconstruct'' the motion. In constructing the prompt, the unmasked poses of the prompt are synthesized by a ",
    "link": "http://arxiv.org/abs/2210.15929",
    "context": "Title: Being Comes from Not-being: Open-vocabulary Text-to-Motion Generation with Wordless Training. (arXiv:2210.15929v2 [cs.CV] UPDATED)\nAbstract: Text-to-motion generation is an emerging and challenging problem, which aims to synthesize motion with the same semantics as the input text. However, due to the lack of diverse labeled training data, most approaches either limit to specific types of text annotations or require online optimizations to cater to the texts during inference at the cost of efficiency and stability. In this paper, we investigate offline open-vocabulary text-to-motion generation in a zero-shot learning manner that neither requires paired training data nor extra online optimization to adapt for unseen texts. Inspired by the prompt learning in NLP, we pretrain a motion generator that learns to reconstruct the full motion from the masked motion. During inference, instead of changing the motion generator, our method reformulates the input text into a masked motion as the prompt for the motion generator to ``reconstruct'' the motion. In constructing the prompt, the unmasked poses of the prompt are synthesized by a ",
    "path": "papers/22/10/2210.15929.json",
    "total_tokens": 917,
    "tldr": "本文提出了一种零样本学习的方法，通过预训练的运动生成器，以掩蔽的运动作为提示，将输入文本转化成运动，实现了离线开放式文本生成运动的目标。"
}