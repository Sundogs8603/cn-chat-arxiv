{
    "title": "An Approach for Noisy, Crowdsourced Datasets Utilizing Ensemble Modeling, Normalized Distributions of Annotations, and Entropic Measures of Uncertainty. (arXiv:2210.16380v2 [cs.CV] UPDATED)",
    "abstract": "Performing classification on noisy, crowdsourced image datasets can prove challenging even for the best neural networks. Two issues which complicate the problem on such datasets are class imbalance and ground-truth uncertainty in labeling. The AL-ALL and AL-PUB datasets -- consisting of tightly cropped, individual characters from images of ancient Greek papyri -- are strongly affected by both issues. The application of ensemble modeling to such datasets can help identify images where the ground-truth is questionable and quantify the trustworthiness of those samples. As such, we apply stacked generalization consisting of nearly identical ResNets with different loss functions: one utilizing sparse cross-entropy (CXE) and the other Kullback-Liebler Divergence (KLD). Both networks use labels drawn from the crowdsourced consensus. For the second network, the KLD is calculated with respect to the proposed Normalized Distribution of Annotations (NDA). For our ensemble model, we apply a k-near",
    "link": "http://arxiv.org/abs/2210.16380",
    "context": "Title: An Approach for Noisy, Crowdsourced Datasets Utilizing Ensemble Modeling, Normalized Distributions of Annotations, and Entropic Measures of Uncertainty. (arXiv:2210.16380v2 [cs.CV] UPDATED)\nAbstract: Performing classification on noisy, crowdsourced image datasets can prove challenging even for the best neural networks. Two issues which complicate the problem on such datasets are class imbalance and ground-truth uncertainty in labeling. The AL-ALL and AL-PUB datasets -- consisting of tightly cropped, individual characters from images of ancient Greek papyri -- are strongly affected by both issues. The application of ensemble modeling to such datasets can help identify images where the ground-truth is questionable and quantify the trustworthiness of those samples. As such, we apply stacked generalization consisting of nearly identical ResNets with different loss functions: one utilizing sparse cross-entropy (CXE) and the other Kullback-Liebler Divergence (KLD). Both networks use labels drawn from the crowdsourced consensus. For the second network, the KLD is calculated with respect to the proposed Normalized Distribution of Annotations (NDA). For our ensemble model, we apply a k-near",
    "path": "papers/22/10/2210.16380.json",
    "total_tokens": 1011,
    "translated_title": "一种利用集合建模、注释的归一化分布和熵测量的不精确、众包数据集的方法",
    "translated_abstract": "在不精确的、众包的图像数据集上进行分类对于最好的神经网络来说都是具有挑战性的。两个问题使得这类数据集上的问题更加复杂，即类别不平衡和标签的不确定性。AL-ALL和AL-PUB数据集--包含来自古希腊纸草的图像的紧密裁剪的单个字符--受到这两个问题的严重影响。将集合建模应用于这样的数据集可以帮助识别标签不确定的图像，并量化这些样本的可信度。因此，我们应用由几乎相同的ResNets组成的堆叠泛化，它们具有不同的损失函数：一个利用稀疏交叉熵（CXE），另一个利用Kullback-Liebler散度（KLD）。两个网络都使用从众包一致性中得出的标签。对于第二个网络，KLD是相对于所提出的注释的归一化分布（NDA）计算的。对于我们的集合模型，我们应用k-近邻算法。",
    "tldr": "在众包图像数据集上的分类是具有挑战性的。本文提出了一种利用集合建模、注释的归一化分布和熵测量的方法，以帮助识别标签不确定的图像，并量化这些样本的可信度。",
    "en_tdlr": "Classifying images in crowdsourced datasets is challenging. This paper proposes an ensemble modeling approach that utilizes normalized distributions of annotations and entropic measures to identify potentially unreliable labels and quantify their trustworthiness on the AL-ALL and AL-PUB datasets containing individual characters from ancient Greek papyri. Two ResNet networks with different loss functions are employed, one using sparse cross-entropy and the other using Kullback-Liebler Divergence, with labels drawn from crowdsourced consensus."
}