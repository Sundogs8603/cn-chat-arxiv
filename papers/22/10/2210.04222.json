{
    "title": "Correlative Information Maximization Based Biologically Plausible Neural Networks for Correlated Source Separation. (arXiv:2210.04222v2 [eess.SP] UPDATED)",
    "abstract": "The brain effortlessly extracts latent causes of stimuli, but how it does this at the network level remains unknown. Most prior attempts at this problem proposed neural networks that implement independent component analysis which works under the limitation that latent causes are mutually independent. Here, we relax this limitation and propose a biologically plausible neural network that extracts correlated latent sources by exploiting information about their domains. To derive this network, we choose maximum correlative information transfer from inputs to outputs as the separation objective under the constraint that the outputs are restricted to their presumed sets. The online formulation of this optimization problem naturally leads to neural networks with local learning rules. Our framework incorporates infinitely many source domain choices and flexibly models complex latent structures. Choices of simplex or polytopic source domains result in networks with piecewise-linear activation ",
    "link": "http://arxiv.org/abs/2210.04222",
    "context": "Title: Correlative Information Maximization Based Biologically Plausible Neural Networks for Correlated Source Separation. (arXiv:2210.04222v2 [eess.SP] UPDATED)\nAbstract: The brain effortlessly extracts latent causes of stimuli, but how it does this at the network level remains unknown. Most prior attempts at this problem proposed neural networks that implement independent component analysis which works under the limitation that latent causes are mutually independent. Here, we relax this limitation and propose a biologically plausible neural network that extracts correlated latent sources by exploiting information about their domains. To derive this network, we choose maximum correlative information transfer from inputs to outputs as the separation objective under the constraint that the outputs are restricted to their presumed sets. The online formulation of this optimization problem naturally leads to neural networks with local learning rules. Our framework incorporates infinitely many source domain choices and flexibly models complex latent structures. Choices of simplex or polytopic source domains result in networks with piecewise-linear activation ",
    "path": "papers/22/10/2210.04222.json",
    "total_tokens": 879,
    "translated_title": "基于相关信息最大化的神经网络进行相关源分离",
    "translated_abstract": "大脑可以轻松地提取刺激的潜在原因，但它如何在网络层面上做到这一点仍然未知。先前解决这个问题的大多数尝试都提出了实现独立成分分析的神经网络，但这种方法的限制在于潜在原因是相互独立的。在此我们不再遵循此限制，提出一种基于生物学的神经网络，通过利用有关其领域的信息来提取相关的潜在源。我们选取从输入到输出的最大相关信息传输作为分离目标，并约束输出量限制在其预定集合内，以导出此网络。在线形式化此优化问题自然地导致具有本地学习规则的神经网络。我们的框架包括无限多种源域选择，并可以灵活地对复杂的潜在结构进行建模。选择单纯形或多面体源域的结果是具有分段线性激活函数的网络，从而极大地改善了对相关源分离的性能。",
    "tldr": "该论文提出了一种基于生物学原理的神经网络，通过利用有关潜在源领域的信息来提取相关联的潜在源，从而极大地改善了对相关源分离的性能。",
    "en_tdlr": "This paper proposes a biologically plausible neural network that extracts correlated latent sources by exploiting information about their domains, greatly improving the performance on separating correlated sources."
}