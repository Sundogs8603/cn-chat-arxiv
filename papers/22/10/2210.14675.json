{
    "title": "Comparison of neural closure models for discretised PDEs. (arXiv:2210.14675v2 [cs.LG] UPDATED)",
    "abstract": "Neural closure models have recently been proposed as a method for efficiently approximating small scales in multiscale systems with neural networks. The choice of loss function and associated training procedure has a large effect on the accuracy and stability of the resulting neural closure model. In this work, we systematically compare three distinct procedures: \"derivative fitting\", \"trajectory fitting\" with discretise-then-optimise, and \"trajectory fitting\" with optimise-then-discretise. Derivative fitting is conceptually the simplest and computationally the most efficient approach and is found to perform reasonably well on one of the test problems (Kuramoto-Sivashinsky) but poorly on the other (Burgers). Trajectory fitting is computationally more expensive but is more robust and is therefore the preferred approach. Of the two trajectory fitting procedures, the discretise-then-optimise approach produces more accurate models than the optimise-then-discretise approach. While the optim",
    "link": "http://arxiv.org/abs/2210.14675",
    "context": "Title: Comparison of neural closure models for discretised PDEs. (arXiv:2210.14675v2 [cs.LG] UPDATED)\nAbstract: Neural closure models have recently been proposed as a method for efficiently approximating small scales in multiscale systems with neural networks. The choice of loss function and associated training procedure has a large effect on the accuracy and stability of the resulting neural closure model. In this work, we systematically compare three distinct procedures: \"derivative fitting\", \"trajectory fitting\" with discretise-then-optimise, and \"trajectory fitting\" with optimise-then-discretise. Derivative fitting is conceptually the simplest and computationally the most efficient approach and is found to perform reasonably well on one of the test problems (Kuramoto-Sivashinsky) but poorly on the other (Burgers). Trajectory fitting is computationally more expensive but is more robust and is therefore the preferred approach. Of the two trajectory fitting procedures, the discretise-then-optimise approach produces more accurate models than the optimise-then-discretise approach. While the optim",
    "path": "papers/22/10/2210.14675.json",
    "total_tokens": 999,
    "translated_title": "离散PDEs的神经封闭模型比较",
    "translated_abstract": "最近，神经封闭模型已经被提出作为一种用神经网络有效逼近多尺度系统中小尺度的方法。损失函数的选择和相关的训练过程对生成的神经封闭模型的精度和稳定性影响巨大。本文系统地比较了三种不同的方法：\"导数拟合\"、先离散化再优化的轨迹拟合和先优化再离散化的轨迹拟合。导数拟合是概念上最简单和计算上最高效的方法，在一个测试问题（Kuramoto-Sivashinsky）上表现良好，但在另一个测试问题（Burgers）上表现不佳。轨迹拟合计算上更加昂贵，但更加鲁棒，因此是首选的方法。在两种轨迹拟合方法中，先离散化再优化的方法比先优化再离散化的方法生成的模型更准确。虽然先优化再离散化的方法在计算时间上更加高效，但稳定性较差，可能需要精心调整超参数。",
    "tldr": "本文系统地比较了三个离散PDEs的神经封闭模型的训练过程，并发现先离散化再优化的轨迹拟合是首选，比导数拟合更准确、比先优化再离散化更稳定，但计算成本较高。",
    "en_tdlr": "This paper systematically compares three neural closure models for discretised PDEs and finds that \"trajectory fitting\" with discretise-then-optimise is the preferred approach, which is more accurate and more stable than \"derivative fitting\" and \"trajectory fitting\" with optimise-then-discretise, while computationally more expensive."
}