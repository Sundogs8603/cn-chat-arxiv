{
    "title": "AMPNet: Attention as Message Passing for Graph Neural Networks. (arXiv:2210.09475v2 [cs.LG] UPDATED)",
    "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful representation learning framework for graph-structured data. A key limitation of conventional GNNs is their representation of each node with a singular feature vector, potentially overlooking intricate details about individual node features. Here, we propose an Attention-based Message-Passing layer for GNNs (AMPNet) that encodes individual features per node and models feature-level interactions through cross-node attention during message-passing steps. We demonstrate the abilities of AMPNet through extensive benchmarking on real-world biological systems such as fMRI brain activity recordings and spatial genomic data, improving over existing baselines by 20% on fMRI signal reconstruction, and further improving another 8% with positional embedding added. Finally, we validate the ability of AMPNet to uncover meaningful feature-level interactions through case studies on biological systems. We anticipate that our architecture will be h",
    "link": "http://arxiv.org/abs/2210.09475",
    "context": "Title: AMPNet: Attention as Message Passing for Graph Neural Networks. (arXiv:2210.09475v2 [cs.LG] UPDATED)\nAbstract: Graph Neural Networks (GNNs) have emerged as a powerful representation learning framework for graph-structured data. A key limitation of conventional GNNs is their representation of each node with a singular feature vector, potentially overlooking intricate details about individual node features. Here, we propose an Attention-based Message-Passing layer for GNNs (AMPNet) that encodes individual features per node and models feature-level interactions through cross-node attention during message-passing steps. We demonstrate the abilities of AMPNet through extensive benchmarking on real-world biological systems such as fMRI brain activity recordings and spatial genomic data, improving over existing baselines by 20% on fMRI signal reconstruction, and further improving another 8% with positional embedding added. Finally, we validate the ability of AMPNet to uncover meaningful feature-level interactions through case studies on biological systems. We anticipate that our architecture will be h",
    "path": "papers/22/10/2210.09475.json",
    "total_tokens": 967,
    "translated_title": "AMPNet: 基于注意力的消息传递用于图神经网络",
    "translated_abstract": "图神经网络（GNNs）已成为一种强大的用于图结构数据的表示学习框架。传统GNNs的一个关键限制是将每个节点表示为一个单一的特征向量，可能忽视了关于个体节点特征的复杂细节。我们提出了一种基于注意力的消息传递层AMPNet，用于GNNs，它对节点进行逐个特征编码，并在消息传递步骤中通过跨节点注意力模型特征级别的交互。我们通过在真实生物系统（如fMRI脑活动记录和空间基因组数据）上进行广泛的基准测试，证明了AMPNet的能力，它在fMRI信号重建方面相比现有基准提高了20％，在添加位置嵌入后又进一步提高了8％。最后，我们通过对生物系统的案例研究验证了AMPNet发现有意义的特征级别交互的能力。我们预计我们的架构将被广泛应用于图神经网络的研究中。",
    "tldr": "AMPNet是一种用于图神经网络的基于注意力的消息传递层，能够对节点进行逐个特征编码，并通过跨节点注意力模型特征级别的交互。在实际生物系统上进行广泛基准测试表明，AMPNet在fMRI信号重建方面优于现有基准，并通过案例研究验证了其发现有意义的特征级别交互的能力。",
    "en_tdlr": "AMPNet is an attention-based message-passing layer for graph neural networks that encodes individual features per node and models feature-level interactions through cross-node attention. Extensive benchmarking on real-world biological systems demonstrates that AMPNet outperforms existing baselines in fMRI signal reconstruction and showcases its ability to uncover meaningful feature-level interactions through case studies."
}