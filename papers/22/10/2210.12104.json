{
    "title": "XAI for transparent wind turbine power curve models. (arXiv:2210.12104v2 [cs.LG] UPDATED)",
    "abstract": "Accurate wind turbine power curve models, which translate ambient conditions into turbine power output, are crucial for wind energy to scale and fulfill its proposed role in the global energy transition. While machine learning (ML) methods have shown significant advantages over parametric, physics-informed approaches, they are often criticised for being opaque 'black boxes', which hinders their application in practice. We apply Shapley values, a popular explainable artificial intelligence (XAI) method, and the latest findings from XAI for regression models, to uncover the strategies ML models have learned from operational wind turbine data. Our findings reveal that the trend towards ever larger model architectures, driven by a focus on test set performance, can result in physically implausible model strategies. Therefore, we call for a more prominent role of XAI methods in model selection. Moreover, we propose a practical approach to utilize explanations for root cause analysis in the ",
    "link": "http://arxiv.org/abs/2210.12104",
    "context": "Title: XAI for transparent wind turbine power curve models. (arXiv:2210.12104v2 [cs.LG] UPDATED)\nAbstract: Accurate wind turbine power curve models, which translate ambient conditions into turbine power output, are crucial for wind energy to scale and fulfill its proposed role in the global energy transition. While machine learning (ML) methods have shown significant advantages over parametric, physics-informed approaches, they are often criticised for being opaque 'black boxes', which hinders their application in practice. We apply Shapley values, a popular explainable artificial intelligence (XAI) method, and the latest findings from XAI for regression models, to uncover the strategies ML models have learned from operational wind turbine data. Our findings reveal that the trend towards ever larger model architectures, driven by a focus on test set performance, can result in physically implausible model strategies. Therefore, we call for a more prominent role of XAI methods in model selection. Moreover, we propose a practical approach to utilize explanations for root cause analysis in the ",
    "path": "papers/22/10/2210.12104.json",
    "total_tokens": 942,
    "translated_title": "XAI用于透明的风力涡轮机功率曲线模型",
    "translated_abstract": "准确的风力涡轮机功率曲线模型对于风能发电行业的规模扩大和实现其在全球能源转型中的拟议角色至关重要。虽然机器学习方法已经证明了相对于参数化、基于物理学的方法的显著优势，但它们经常因为不透明的“黑匣子”而受到批评，这阻碍了它们在实践中的应用。我们应用流行的可解释人工智能（XAI）方法——Shapley值以及最新的XAI回归模型发现，揭示了机器学习模型从操作风力涡轮机数据中学到的策略。我们的发现表明，由于专注于测试集表现，越来越大的模型结构的趋势可能导致物理上不可行的模型策略。因此，我们呼吁在模型选择中更加突出地采用XAI方法。此外，我们提出了一种实用的方法，利用解释进行根本原因分析，找出风力涡轮机工业中的问题。",
    "tldr": "本论文应用XAI方法揭示机器学习模型从大量风力涡轮机数据中学到的策略，并且呼吁在模型选择中更加突出地采用XAI方法，提出了一种利用解释进行根本原因分析的实用方法。"
}