{
    "title": "Lifelong Bandit Optimization: No Prior and No Regret. (arXiv:2210.15513v3 [stat.ML] UPDATED)",
    "abstract": "Machine learning algorithms are often repeatedly applied to problems with similar structure over and over again. We focus on solving a sequence of bandit optimization tasks and develop LIBO, an algorithm which adapts to the environment by learning from past experience and becomes more sample-efficient in the process. We assume a kernelized structure where the kernel is unknown but shared across all tasks. LIBO sequentially meta-learns a kernel that approximates the true kernel and solves the incoming tasks with the latest kernel estimate. Our algorithm can be paired with any kernelized or linear bandit algorithm and guarantees oracle optimal performance, meaning that as more tasks are solved, the regret of LIBO on each task converges to the regret of the bandit algorithm with oracle knowledge of the true kernel. Naturally, if paired with a sublinear bandit algorithm, LIBO yields a sublinear lifelong regret. We also show that direct access to the data from each task is not necessary for",
    "link": "http://arxiv.org/abs/2210.15513",
    "context": "Title: Lifelong Bandit Optimization: No Prior and No Regret. (arXiv:2210.15513v3 [stat.ML] UPDATED)\nAbstract: Machine learning algorithms are often repeatedly applied to problems with similar structure over and over again. We focus on solving a sequence of bandit optimization tasks and develop LIBO, an algorithm which adapts to the environment by learning from past experience and becomes more sample-efficient in the process. We assume a kernelized structure where the kernel is unknown but shared across all tasks. LIBO sequentially meta-learns a kernel that approximates the true kernel and solves the incoming tasks with the latest kernel estimate. Our algorithm can be paired with any kernelized or linear bandit algorithm and guarantees oracle optimal performance, meaning that as more tasks are solved, the regret of LIBO on each task converges to the regret of the bandit algorithm with oracle knowledge of the true kernel. Naturally, if paired with a sublinear bandit algorithm, LIBO yields a sublinear lifelong regret. We also show that direct access to the data from each task is not necessary for",
    "path": "papers/22/10/2210.15513.json",
    "total_tokens": 778,
    "translated_title": "终身赌博优化：无先验知识和无后悔算法",
    "translated_abstract": "机器学习算法经常重复应用于相似结构的问题。本文关注解决一系列赌博优化任务，并开发了一种适应环境的算法LIBO。我们假设内核化结构，其中的内核在所有任务中都是未知的但共享的。LIBO依次元学习一个逼近真实内核的内核，然后用最新的内核估计来解决即将到来的任务。本算法可以与任何内核化或线性赌博算法配对，并保证最优的预期性能。如果与亚线性赌博算法配对，LIBO将产生一个亚线性终身后悔率。",
    "tldr": "本文提出了一种算法LIBO，可以无需直接访问数据，对一系列赌博优化任务进行学习和适应，并保证最优性能和亚线性终身后悔率。",
    "en_tdlr": "This paper proposes an algorithm, LIBO, that can adapt to a sequence of bandit optimization tasks without direct access to data, guaranteeing optimal performance and sublinear lifelong regret when paired with appropriate algorithms."
}