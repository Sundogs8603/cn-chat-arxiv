{
    "title": "Dictionary Learning for the Almost-Linear Sparsity Regime. (arXiv:2210.10855v2 [cs.LG] UPDATED)",
    "abstract": "Dictionary learning, the problem of recovering a sparsely used matrix $\\mathbf{D} \\in \\mathbb{R}^{M \\times K}$ and $N$ $s$-sparse vectors $\\mathbf{x}_i \\in \\mathbb{R}^{K}$ from samples of the form $\\mathbf{y}_i = \\mathbf{D}\\mathbf{x}_i$, is of increasing importance to applications in signal processing and data science. When the dictionary is known, recovery of $\\mathbf{x}_i$ is possible even for sparsity linear in dimension $M$, yet to date, the only algorithms which provably succeed in the linear sparsity regime are Riemannian trust-region methods, which are limited to orthogonal dictionaries, and methods based on the sum-of-squares hierarchy, which requires super-polynomial time in order to obtain an error which decays in $M$. In this work, we introduce SPORADIC (SPectral ORAcle DICtionary Learning), an efficient spectral method on family of reweighted covariance matrices. We prove that in high enough dimensions, SPORADIC can recover overcomplete ($K > M$) dictionaries satisfying the",
    "link": "http://arxiv.org/abs/2210.10855",
    "context": "Title: Dictionary Learning for the Almost-Linear Sparsity Regime. (arXiv:2210.10855v2 [cs.LG] UPDATED)\nAbstract: Dictionary learning, the problem of recovering a sparsely used matrix $\\mathbf{D} \\in \\mathbb{R}^{M \\times K}$ and $N$ $s$-sparse vectors $\\mathbf{x}_i \\in \\mathbb{R}^{K}$ from samples of the form $\\mathbf{y}_i = \\mathbf{D}\\mathbf{x}_i$, is of increasing importance to applications in signal processing and data science. When the dictionary is known, recovery of $\\mathbf{x}_i$ is possible even for sparsity linear in dimension $M$, yet to date, the only algorithms which provably succeed in the linear sparsity regime are Riemannian trust-region methods, which are limited to orthogonal dictionaries, and methods based on the sum-of-squares hierarchy, which requires super-polynomial time in order to obtain an error which decays in $M$. In this work, we introduce SPORADIC (SPectral ORAcle DICtionary Learning), an efficient spectral method on family of reweighted covariance matrices. We prove that in high enough dimensions, SPORADIC can recover overcomplete ($K > M$) dictionaries satisfying the",
    "path": "papers/22/10/2210.10855.json",
    "total_tokens": 952,
    "translated_title": "几乎线性稀疏度下的字典学习",
    "translated_abstract": "字典学习指的是从形如$\\mathbf{y}_i = \\mathbf{D}\\mathbf{x}_i$的样本中恢复一个矩阵$\\mathbf{D} \\in \\mathbb{R}^{M \\times K}$和$N$个$s$-稀疏向量$\\mathbf{x}_i \\in \\mathbb{R}^{K}$的问题。在字典已知的情况下，即使稀疏度线性增长到尺寸$M$，也可以恢复$x_i$，但迄今为止，唯一能在线性稀疏度范围内有保证成功的算法是黎曼信赖区域方法，这种方法仅适用于正交字典，并且基于平方和层次的方法需要超多项式时间才能获得在$M$中衰减的误差。在这项工作中，我们介绍了SPORADIC（SPectral ORAcle DICtionary Learning），这是一种基于一系列加权协方差矩阵的高效谱方法。我们证明，在足够高的维度下，SPORADIC可以恢复满足$K>M$的超完备字典。",
    "tldr": "本文提出了一种高效的谱方法SPORADIC，在几乎线性稀疏度下的字典学习问题中可以恢复超完备字典。",
    "en_tdlr": "This paper proposes an efficient spectral method called SPORADIC, which can recover overcomplete dictionaries in the almost-linear sparsity regime for the problem of dictionary learning."
}