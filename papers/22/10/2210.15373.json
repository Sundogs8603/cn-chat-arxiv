{
    "title": "Self-consistent Reasoning For Solving Math Word Problems",
    "abstract": "arXiv:2210.15373v2 Announce Type: replace  Abstract: Math word problems (MWPs) is a task that automatically derives solution expression from a giving math problems in text. The previous studies suffer from spurious correlations between input text and output expression. To mitigate this issue, we propose a self-consistent reasoning framework called SCR, which attempts to adopt a pruning strategy to correct the output distribution shift so as to implicitly fix those spurious correlative samples. Specifically, we firstly obtain a sub-network by pruning a roberta2tree model, for the sake to use the gap on output distribution between the original roberta2tree model and the pruned sub-network to expose spurious correlative samples. Then, we calibrate the output distribution shift by applying symmetric Kullback-Leibler divergence to alleviate spurious correlations. In addition, SCR generates equivalent expressions, thereby, capturing the original text's logic rather than relying on hints from",
    "link": "https://arxiv.org/abs/2210.15373",
    "context": "Title: Self-consistent Reasoning For Solving Math Word Problems\nAbstract: arXiv:2210.15373v2 Announce Type: replace  Abstract: Math word problems (MWPs) is a task that automatically derives solution expression from a giving math problems in text. The previous studies suffer from spurious correlations between input text and output expression. To mitigate this issue, we propose a self-consistent reasoning framework called SCR, which attempts to adopt a pruning strategy to correct the output distribution shift so as to implicitly fix those spurious correlative samples. Specifically, we firstly obtain a sub-network by pruning a roberta2tree model, for the sake to use the gap on output distribution between the original roberta2tree model and the pruned sub-network to expose spurious correlative samples. Then, we calibrate the output distribution shift by applying symmetric Kullback-Leibler divergence to alleviate spurious correlations. In addition, SCR generates equivalent expressions, thereby, capturing the original text's logic rather than relying on hints from",
    "path": "papers/22/10/2210.15373.json",
    "total_tokens": 832,
    "translated_title": "自洽推理用于解决数学应用题",
    "translated_abstract": "数学应用题（MWPs）是一个从给定的数学问题文本中自动推导解题表达式的任务。先前的研究受到输入文本和输出表达式之间虚假相关性的困扰。为了缓解这一问题，我们提出了一个自洽推理框架SCR，试图采用修剪策略来纠正输出分布偏移，以隐式修复这些虚假相关样本。具体来说，我们首先通过修剪roberta2tree模型来获取一个子网络，以便利用原始roberta2tree模型和被修剪子网络之间的输出分布差距来暴露虚假相关样本。然后，我们通过对称Kullback-Leibler散度来校准输出分布偏移，以减轻虚假相关。此外，SCR生成等效表达式，从而捕捉原始文本的逻辑，而不是依赖于提示。",
    "tldr": "提出了自洽推理框架SCR，通过修剪策略和对称Kullback-Leibler散度校准输出分布偏移，从而解决数学应用题中虚假相关性的问题"
}