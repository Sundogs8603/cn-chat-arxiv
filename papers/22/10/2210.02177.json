{
    "title": "Multi-objective optimization via equivariant deep hypervolume approximation. (arXiv:2210.02177v2 [cs.LG] UPDATED)",
    "abstract": "Optimizing multiple competing objectives is a common problem across science and industry. The inherent inextricable trade-off between those objectives leads one to the task of exploring their Pareto front. A meaningful quantity for the purpose of the latter is the hypervolume indicator, which is used in Bayesian Optimization (BO) and Evolutionary Algorithms (EAs). However, the computational complexity for the calculation of the hypervolume scales unfavorably with increasing number of objectives and data points, which restricts its use in those common multi-objective optimization frameworks. To overcome these restrictions we propose to approximate the hypervolume function with a deep neural network, which we call DeepHV. For better sample efficiency and generalization, we exploit the fact that the hypervolume is scale-equivariant in each of the objectives as well as permutation invariant w.r.t. both the objectives and the samples, by using a deep neural network that is equivariant w.r.t",
    "link": "http://arxiv.org/abs/2210.02177",
    "context": "Title: Multi-objective optimization via equivariant deep hypervolume approximation. (arXiv:2210.02177v2 [cs.LG] UPDATED)\nAbstract: Optimizing multiple competing objectives is a common problem across science and industry. The inherent inextricable trade-off between those objectives leads one to the task of exploring their Pareto front. A meaningful quantity for the purpose of the latter is the hypervolume indicator, which is used in Bayesian Optimization (BO) and Evolutionary Algorithms (EAs). However, the computational complexity for the calculation of the hypervolume scales unfavorably with increasing number of objectives and data points, which restricts its use in those common multi-objective optimization frameworks. To overcome these restrictions we propose to approximate the hypervolume function with a deep neural network, which we call DeepHV. For better sample efficiency and generalization, we exploit the fact that the hypervolume is scale-equivariant in each of the objectives as well as permutation invariant w.r.t. both the objectives and the samples, by using a deep neural network that is equivariant w.r.t",
    "path": "papers/22/10/2210.02177.json",
    "total_tokens": 848,
    "translated_title": "多目标优化通过等变深度超体积逼近",
    "translated_abstract": "在科学和工业领域，优化多个相互竞争的目标是一个常见问题。这些目标之间的不可避免的权衡使得我们需要探索它们的帕累托前沿。对于后者而言，一个有意义的量是超体积指标，它在贝叶斯优化 (BO) 和进化算法 (EA) 中被使用。然而，随着目标数量和数据点数量的增加，计算超体积的复杂度不利地扩展，限制了它在常见多目标优化框架中的使用。为了克服这些限制，我们提出了一种用深度神经网络近似超体积函数的方法，称之为DeepHV。为了实现更好的样本效率和泛化性能，我们利用了每个目标上超体积的尺度等变性以及对目标和样本的排列不变性，通过使用一种等变的深度神经网络。",
    "tldr": "本研究提出了一种通过等变深度神经网络来近似多目标优化中的超体积函数的方法，以克服计算复杂度随目标和数据点增加的限制。"
}