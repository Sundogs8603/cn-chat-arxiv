{
    "title": "Gradient Gating for Deep Multi-Rate Learning on Graphs. (arXiv:2210.00513v2 [cs.LG] UPDATED)",
    "abstract": "We present Gradient Gating (G$^2$), a novel framework for improving the performance of Graph Neural Networks (GNNs). Our framework is based on gating the output of GNN layers with a mechanism for multi-rate flow of message passing information across nodes of the underlying graph. Local gradients are harnessed to further modulate message passing updates. Our framework flexibly allows one to use any basic GNN layer as a wrapper around which the multi-rate gradient gating mechanism is built. We rigorously prove that G$^2$ alleviates the oversmoothing problem and allows the design of deep GNNs. Empirical results are presented to demonstrate that the proposed framework achieves state-of-the-art performance on a variety of graph learning tasks, including on large-scale heterophilic graphs.",
    "link": "http://arxiv.org/abs/2210.00513",
    "context": "Title: Gradient Gating for Deep Multi-Rate Learning on Graphs. (arXiv:2210.00513v2 [cs.LG] UPDATED)\nAbstract: We present Gradient Gating (G$^2$), a novel framework for improving the performance of Graph Neural Networks (GNNs). Our framework is based on gating the output of GNN layers with a mechanism for multi-rate flow of message passing information across nodes of the underlying graph. Local gradients are harnessed to further modulate message passing updates. Our framework flexibly allows one to use any basic GNN layer as a wrapper around which the multi-rate gradient gating mechanism is built. We rigorously prove that G$^2$ alleviates the oversmoothing problem and allows the design of deep GNNs. Empirical results are presented to demonstrate that the proposed framework achieves state-of-the-art performance on a variety of graph learning tasks, including on large-scale heterophilic graphs.",
    "path": "papers/22/10/2210.00513.json",
    "total_tokens": 792,
    "translated_title": "基于梯度门控机制的图深度多速率学习",
    "translated_abstract": "我们提出了一种名为 Gradient Gating (G$^2$) 的新型框架，旨在改善图神经网络 (GNNs) 的性能。我们的框架基于对 GNN 层的输出进行门控，其中包含了一种跨本质图节点的消息传递信息的多速率流机制。本地梯度被利用来进一步调制消息传递的更新。我们的框架可以灵活地允许使用任何基本的 GNN 层作为包装器，以构建多速率梯度门控机制。我们严格证明 G$^2$ 缓解了过度平滑问题，并允许设计深度 GNNs。我们展示了实证结果，证明所提出的框架在各种图学习任务上实现了最先进的性能，包括大规模异质图上的任务。",
    "tldr": "G2是一种利用梯度门控机制的新型GNN框架，可缓解过度平滑问题，并实现了各种图学习任务上的最先进性能。",
    "en_tdlr": "G2 is a novel GNN framework that utilizes gradient gating mechanism to alleviate the oversmoothing problem and achieve state-of-the-art performance on a variety of graph learning tasks."
}