{
    "title": "Distributionally Robust Multiclass Classification and Applications in Deep Image Classifiers. (arXiv:2210.08198v2 [cs.CV] UPDATED)",
    "abstract": "We develop a Distributionally Robust Optimization (DRO) formulation for Multiclass Logistic Regression (MLR), which could tolerate data contaminated by outliers. The DRO framework uses a probabilistic ambiguity set defined as a ball of distributions that are close to the empirical distribution of the training set in the sense of the Wasserstein metric. We relax the DRO formulation into a regularized learning problem whose regularizer is a norm of the coefficient matrix. We establish out-of-sample performance guarantees for the solutions to our model, offering insights on the role of the regularizer in controlling the prediction error. We apply the proposed method in rendering deep Vision Transformer (ViT)-based image classifiers robust to random and adversarial attacks. Specifically, using the MNIST and CIFAR-10 datasets, we demonstrate reductions in test error rate by up to 83.5% and loss by up to 91.3% compared with baseline methods, by adopting a novel random training method.",
    "link": "http://arxiv.org/abs/2210.08198",
    "context": "Title: Distributionally Robust Multiclass Classification and Applications in Deep Image Classifiers. (arXiv:2210.08198v2 [cs.CV] UPDATED)\nAbstract: We develop a Distributionally Robust Optimization (DRO) formulation for Multiclass Logistic Regression (MLR), which could tolerate data contaminated by outliers. The DRO framework uses a probabilistic ambiguity set defined as a ball of distributions that are close to the empirical distribution of the training set in the sense of the Wasserstein metric. We relax the DRO formulation into a regularized learning problem whose regularizer is a norm of the coefficient matrix. We establish out-of-sample performance guarantees for the solutions to our model, offering insights on the role of the regularizer in controlling the prediction error. We apply the proposed method in rendering deep Vision Transformer (ViT)-based image classifiers robust to random and adversarial attacks. Specifically, using the MNIST and CIFAR-10 datasets, we demonstrate reductions in test error rate by up to 83.5% and loss by up to 91.3% compared with baseline methods, by adopting a novel random training method.",
    "path": "papers/22/10/2210.08198.json",
    "total_tokens": 1012,
    "translated_title": "分布式鲁棒多分类和在深度图像分类器中的应用",
    "translated_abstract": "我们提出了一种分布式鲁棒优化(DRO)的多分类逻辑回归(MLR)公式，可以容忍受到异常值干扰的数据。DRO框架使用一个概率模糊集合，该集合被定义为接近于Wasserstein度量意义下的训练集经验分布的分布球。 我们将DRO公式放松为一个规则化学习问题，其规则化器是系数矩阵的范数。 我们为我们模型的解决方案建立了样本外性能保证，为控制预测误差的规则化器的作用提供了洞察。我们将所提出的方法应用于深度视觉变换器(ViT)为基础的图像分类器中，使其对随机和对抗性攻击具有鲁棒性。具体地，在MNIST和CIFAR-10数据集上，我们通过采用一种新颖的随机训练方法，展示了测试错误率减少高达83.5％和损失减少高达91.3％的结果。",
    "tldr": "该论文提出了一种能够容忍异常值干扰数据的分布式鲁棒优化(DRO)公式，将其应用于图像分类器中可以使其对随机和对抗性攻击具有鲁棒性。在MNIST和CIFAR-10数据集上，相较于基准方法，采用新颖的随机训练方法，测试错误率减少高达83.5％，损失减少高达91.3％。",
    "en_tdlr": "This paper proposes a distributionally robust optimization (DRO) formulation to tolerate data contaminated by outliers, and applies it to deep image classifiers to enhance their robustness to random and adversarial attacks. The proposed method achieves substantial error rate and loss reductions compared with baseline methods on the MNIST and CIFAR-10 datasets by adopting a novel random training method."
}