{
    "title": "Two Models are Better than One: Federated Learning Is Not Private For Google GBoard Next Word Prediction. (arXiv:2210.16947v2 [cs.LG] UPDATED)",
    "abstract": "In this paper we present new attacks against federated learning when used to train natural language text models. We illustrate the effectiveness of the attacks against the next word prediction model used in Google's GBoard app, a widely used mobile keyboard app that has been an early adopter of federated learning for production use. We demonstrate that the words a user types on their mobile handset, e.g. when sending text messages, can be recovered with high accuracy under a wide range of conditions and that counter-measures such a use of mini-batches and adding local noise are ineffective. We also show that the word order (and so the actual sentences typed) can be reconstructed with high fidelity. This raises obvious privacy concerns, particularly since GBoard is in production use.",
    "link": "http://arxiv.org/abs/2210.16947",
    "context": "Title: Two Models are Better than One: Federated Learning Is Not Private For Google GBoard Next Word Prediction. (arXiv:2210.16947v2 [cs.LG] UPDATED)\nAbstract: In this paper we present new attacks against federated learning when used to train natural language text models. We illustrate the effectiveness of the attacks against the next word prediction model used in Google's GBoard app, a widely used mobile keyboard app that has been an early adopter of federated learning for production use. We demonstrate that the words a user types on their mobile handset, e.g. when sending text messages, can be recovered with high accuracy under a wide range of conditions and that counter-measures such a use of mini-batches and adding local noise are ineffective. We also show that the word order (and so the actual sentences typed) can be reconstructed with high fidelity. This raises obvious privacy concerns, particularly since GBoard is in production use.",
    "path": "papers/22/10/2210.16947.json",
    "total_tokens": 854,
    "translated_title": "两个模型胜过一个：联邦学习对于谷歌GBoard下一个单词预测并不私密",
    "translated_abstract": "在本文中，我们介绍了针对联邦学习用于训练自然语言文本模型的新攻击。我们展示了对谷歌GBoard应用中使用的下一个单词预测模型的攻击效果，谷歌GBoard是一款广泛使用的移动键盘应用，早期采用了联邦学习用于生产。我们证明，在各种条件下，可以高准确度地恢复用户在移动设备上输入的单词，例如发送短信时，而诸如使用小批量和添加本地噪音等对策无效。我们还展示了可以高度准确地重建单词顺序（从而重建实际输入的句子）。这引发了明显的隐私担忧，特别是考虑到GBoard正在使用。",
    "tldr": "本文介绍了对联邦学习用于训练自然语言文本模型的新攻击，展示了对谷歌GBoard应用中下一个单词预测模型的攻击效果，揭示了用户输入的单词和句子可以被高准确度地恢复，引发了隐私担忧。",
    "en_tdlr": "This paper presents new attacks against federated learning for training natural language text models, demonstrating the effectiveness of the attacks against the next word prediction model used in Google's GBoard app. It reveals that user's input words and sentences can be accurately recovered, raising privacy concerns."
}