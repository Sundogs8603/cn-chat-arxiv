{
    "title": "DPAR: Decoupled Graph Neural Networks with Node-Level Differential Privacy",
    "abstract": "arXiv:2210.04442v2 Announce Type: replace  Abstract: Graph Neural Networks (GNNs) have achieved great success in learning with graph-structured data. Privacy concerns have also been raised for the trained models which could expose the sensitive information of graphs including both node features and the structure information. In this paper, we aim to achieve node-level differential privacy (DP) for training GNNs so that a node and its edges are protected. Node DP is inherently difficult for GNNs because all direct and multi-hop neighbors participate in the calculation of gradients for each node via layer-wise message passing and there is no bound on how many direct and multi-hop neighbors a node can have, so existing DP methods will result in high privacy cost or poor utility due to high node sensitivity. We propose a \\textbf{D}ecoupled GNN with Differentially \\textbf{P}rivate \\textbf{A}pproximate Personalized Page\\textbf{R}ank (DPAR) for training GNNs with an enhanced privacy-utility t",
    "link": "https://arxiv.org/abs/2210.04442",
    "context": "Title: DPAR: Decoupled Graph Neural Networks with Node-Level Differential Privacy\nAbstract: arXiv:2210.04442v2 Announce Type: replace  Abstract: Graph Neural Networks (GNNs) have achieved great success in learning with graph-structured data. Privacy concerns have also been raised for the trained models which could expose the sensitive information of graphs including both node features and the structure information. In this paper, we aim to achieve node-level differential privacy (DP) for training GNNs so that a node and its edges are protected. Node DP is inherently difficult for GNNs because all direct and multi-hop neighbors participate in the calculation of gradients for each node via layer-wise message passing and there is no bound on how many direct and multi-hop neighbors a node can have, so existing DP methods will result in high privacy cost or poor utility due to high node sensitivity. We propose a \\textbf{D}ecoupled GNN with Differentially \\textbf{P}rivate \\textbf{A}pproximate Personalized Page\\textbf{R}ank (DPAR) for training GNNs with an enhanced privacy-utility t",
    "path": "papers/22/10/2210.04442.json",
    "total_tokens": 851,
    "translated_title": "DPAR: 具有节点级差分隐私的分离图神经网络",
    "translated_abstract": "图神经网络（GNNs）在学习图结构数据方面取得了巨大成功。 还提出了对训练模型的隐私问题，这可能暴露图的敏感信息，包括节点特征和结构信息。 本文旨在实现对GNNs进行节点级差分隐私（DP），以保护节点及其边缘。 GNNs的节点DP在本质上是困难的，因为所有直接和多跳邻居通过逐层消息传递参与每个节点的梯度计算，并且节点可以具有多少直接和多跳邻居，因此现有的DP方法将导致很高的隐私成本或由于节点敏感性高而效用不佳。 我们提出了具有差异性私人化调整页面排名（DPAR）的\\textbf{D}ecoupled GNN，用于训练带有增强隐私效用",
    "tldr": "本研究提出了一种名为DPAR的分离图神经网络，能实现对GNNs进行节点级差分隐私，从而保护节点及其边缘。",
    "en_tdlr": "This paper introduces a decoupled graph neural network named DPAR, which achieves node-level differential privacy for GNNs to protect nodes and their edges."
}