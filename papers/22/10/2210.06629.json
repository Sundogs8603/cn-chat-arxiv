{
    "title": "Instruction Tuning for Few-Shot Aspect-Based Sentiment Analysis. (arXiv:2210.06629v2 [cs.CL] UPDATED)",
    "abstract": "Aspect-based Sentiment Analysis (ABSA) is a fine-grained sentiment analysis task which involves four elements from user-generated texts: aspect term, aspect category, opinion term, and sentiment polarity. Most computational approaches focus on some of the ABSA sub-tasks such as tuple (aspect term, sentiment polarity) or triplet (aspect term, opinion term, sentiment polarity) extraction using either pipeline or joint modeling approaches. Recently, generative approaches have been proposed to extract all four elements as (one or more) quadruplets from text as a single task. In this work, we take a step further and propose a unified framework for solving ABSA, and the associated sub-tasks to improve the performance in few-shot scenarios. To this end, we fine-tune a T5 model with instructional prompts in a multi-task learning fashion covering all the sub-tasks, as well as the entire quadruple prediction task. In experiments with multiple benchmark datasets, we show that the proposed multi-t",
    "link": "http://arxiv.org/abs/2210.06629",
    "context": "Title: Instruction Tuning for Few-Shot Aspect-Based Sentiment Analysis. (arXiv:2210.06629v2 [cs.CL] UPDATED)\nAbstract: Aspect-based Sentiment Analysis (ABSA) is a fine-grained sentiment analysis task which involves four elements from user-generated texts: aspect term, aspect category, opinion term, and sentiment polarity. Most computational approaches focus on some of the ABSA sub-tasks such as tuple (aspect term, sentiment polarity) or triplet (aspect term, opinion term, sentiment polarity) extraction using either pipeline or joint modeling approaches. Recently, generative approaches have been proposed to extract all four elements as (one or more) quadruplets from text as a single task. In this work, we take a step further and propose a unified framework for solving ABSA, and the associated sub-tasks to improve the performance in few-shot scenarios. To this end, we fine-tune a T5 model with instructional prompts in a multi-task learning fashion covering all the sub-tasks, as well as the entire quadruple prediction task. In experiments with multiple benchmark datasets, we show that the proposed multi-t",
    "path": "papers/22/10/2210.06629.json",
    "total_tokens": 945,
    "translated_abstract": "方面级情感分析（ABSA）是一项细粒度的情感分析任务，涉及用户生成的文本中的四个元素：方面术语、方面类别、观点术语和情感极性。大多数计算方法集中在 ABSA 的某些子任务上，如使用管道或联合建模方法提取元组（方面术语、情感极性）或三元组（方面术语、观点术语、情感极性）等。最近，提出了生成方法以从文本中提取所有四个元素作为（一个或多个）四元组的单一任务。在这项工作中，我们采取了一步进一步，提出了一个统一的框架来解决 ABSA 和相关子任务，以改进少样本情况下的性能。为此，我们利用指令提示在多任务学习模式下对 T5 模型进行微调，涵盖了所有子任务以及整个四元组预测任务。在多个基准数据集的实验中，我们展示了所提出的多任务模型在少样本场景中的优越性能。",
    "tldr": "本文提出了一种针对少样本情感分析的指令调整方法，采用多任务学习模式对 T5 模型进行微调，可同时解决 ABSA 的所有子任务以及整个四元组预测任务，实验结果表明其在多个基准数据集上具有优越性能。",
    "en_tdlr": "This paper proposes an instruction tuning method for few-shot aspect-based sentiment analysis task, which fine-tunes a T5 model with instructional prompts in a mult-task learning fashion covering all sub-tasks and the entire quadruple prediction task. The experimental results on multiple benchmark datasets demonstrate its superior performance."
}