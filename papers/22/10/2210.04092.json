{
    "title": "Advancing Model Pruning via Bi-level Optimization. (arXiv:2210.04092v4 [cs.LG] UPDATED)",
    "abstract": "The deployment constraints in practical applications necessitate the pruning of large-scale deep learning models, i.e., promoting their weight sparsity. As illustrated by the Lottery Ticket Hypothesis (LTH), pruning also has the potential of improving their generalization ability. At the core of LTH, iterative magnitude pruning (IMP) is the predominant pruning method to successfully find 'winning tickets'. Yet, the computation cost of IMP grows prohibitively as the targeted pruning ratio increases. To reduce the computation overhead, various efficient 'one-shot' pruning methods have been developed, but these schemes are usually unable to find winning tickets as good as IMP. This raises the question of how to close the gap between pruning accuracy and pruning efficiency? To tackle it, we pursue the algorithmic advancement of model pruning. Specifically, we formulate the pruning problem from a fresh and novel viewpoint, bi-level optimization (BLO). We show that the BLO interpretation pro",
    "link": "http://arxiv.org/abs/2210.04092",
    "context": "Title: Advancing Model Pruning via Bi-level Optimization. (arXiv:2210.04092v4 [cs.LG] UPDATED)\nAbstract: The deployment constraints in practical applications necessitate the pruning of large-scale deep learning models, i.e., promoting their weight sparsity. As illustrated by the Lottery Ticket Hypothesis (LTH), pruning also has the potential of improving their generalization ability. At the core of LTH, iterative magnitude pruning (IMP) is the predominant pruning method to successfully find 'winning tickets'. Yet, the computation cost of IMP grows prohibitively as the targeted pruning ratio increases. To reduce the computation overhead, various efficient 'one-shot' pruning methods have been developed, but these schemes are usually unable to find winning tickets as good as IMP. This raises the question of how to close the gap between pruning accuracy and pruning efficiency? To tackle it, we pursue the algorithmic advancement of model pruning. Specifically, we formulate the pruning problem from a fresh and novel viewpoint, bi-level optimization (BLO). We show that the BLO interpretation pro",
    "path": "papers/22/10/2210.04092.json",
    "total_tokens": 783,
    "translated_title": "通过双层优化推进模型修剪",
    "translated_abstract": "实际应用中的部署限制需要修剪大规模深度学习模型，即促进它们的权重稀疏性。修剪还有可能提高它们的泛化能力。本文提出了一种新颖的修剪方法：双层优化（BLOP），利用双层优化的方法对修剪问题进行了重新解释，并在多个常用基准数据集上实现了表现的提升。该方法比现有方法具有更快的计算速度和更高的准确率。",
    "tldr": "BLOP是一种新颖的模型修剪方法，利用双层优化的方法对修剪问题进行了重新解释，可以在多个常用基准数据集上实现表现的提升，并比现有方法具有更快的计算速度和更高的准确率。",
    "en_tdlr": "BLOP is a novel model pruning method that reformulates the pruning problem using bi-level optimization, achieving improved performance on multiple benchmark datasets and faster computation speed compared to existing methods."
}