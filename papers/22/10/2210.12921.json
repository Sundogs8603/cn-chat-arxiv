{
    "title": "Investigating self-supervised, weakly supervised and fully supervised training approaches for multi-domain automatic speech recognition: a study on Bangladeshi Bangla. (arXiv:2210.12921v3 [cs.CL] UPDATED)",
    "abstract": "Despite huge improvements in automatic speech recognition (ASR) employing neural networks, ASR systems still suffer from a lack of robustness and generalizability issues due to domain shifting. This is mainly because principal corpus design criteria are often not identified and examined adequately while compiling ASR datasets. In this study, we investigate the robustness of the state-of-the-art transfer learning approaches such as self-supervised wav2vec 2.0 and weakly supervised Whisper as well as fully supervised convolutional neural networks (CNNs) for multi-domain ASR. We also demonstrate the significance of domain selection while building a corpus by assessing these models on a novel multi-domain Bangladeshi Bangla ASR evaluation benchmark - BanSpeech, which contains approximately 6.52 hours of human-annotated speech and 8085 utterances from 13 distinct domains. SUBAK.KO, a mostly read speech corpus for the morphologically rich language Bangla, has been used to train the ASR syste",
    "link": "http://arxiv.org/abs/2210.12921",
    "context": "Title: Investigating self-supervised, weakly supervised and fully supervised training approaches for multi-domain automatic speech recognition: a study on Bangladeshi Bangla. (arXiv:2210.12921v3 [cs.CL] UPDATED)\nAbstract: Despite huge improvements in automatic speech recognition (ASR) employing neural networks, ASR systems still suffer from a lack of robustness and generalizability issues due to domain shifting. This is mainly because principal corpus design criteria are often not identified and examined adequately while compiling ASR datasets. In this study, we investigate the robustness of the state-of-the-art transfer learning approaches such as self-supervised wav2vec 2.0 and weakly supervised Whisper as well as fully supervised convolutional neural networks (CNNs) for multi-domain ASR. We also demonstrate the significance of domain selection while building a corpus by assessing these models on a novel multi-domain Bangladeshi Bangla ASR evaluation benchmark - BanSpeech, which contains approximately 6.52 hours of human-annotated speech and 8085 utterances from 13 distinct domains. SUBAK.KO, a mostly read speech corpus for the morphologically rich language Bangla, has been used to train the ASR syste",
    "path": "papers/22/10/2210.12921.json",
    "total_tokens": 932,
    "translated_title": "探讨多领域自动语音识别的自监督、弱监督和完全监督的训练方法：孟加拉布尔语的研究。",
    "translated_abstract": "尽管神经网络为自动语音识别（ASR）带来了巨大的改进，但由于领域转移而导致的鲁棒性和通用性问题仍然困扰着ASR系统。这主要是因为在编译ASR数据集时，通常不足够地识别和检查主要的语料库设计标准。在这项研究中，我们调查了最先进的转移学习方法（如自监督 wav2vec 2.0 和弱监督 Whisper）以及完全监督的卷积神经网络（CNN）在多领域ASR中的鲁棒性。我们还通过在一个新的多领域孟加拉国布尔语ASR评估基准BanSpeech上评估这些模型来证明在构建语料库时领域选择的重要性，BanSpeech包含大约6.52小时的人工标注语音和来自13个不同领域的8085个发言。",
    "tldr": "本研究研究了自监督、弱监督和完全监督的训练方法对多领域自动语音识别的影响，并且证明了在构建语料库时领域选择的重要性。",
    "en_tdlr": "This study investigates the impacts of self-supervised, weakly supervised and fully supervised training approaches on multi-domain automatic speech recognition, and demonstrates the significance of domain selection while building a corpus."
}