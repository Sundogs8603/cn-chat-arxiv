{
    "title": "ToupleGDD: A Fine-Designed Solution of Influence Maximization by Deep Reinforcement Learning. (arXiv:2210.07500v3 [cs.SI] UPDATED)",
    "abstract": "Aiming at selecting a small subset of nodes with maximum influence on networks, the Influence Maximization (IM) problem has been extensively studied. Since it is #P-hard to compute the influence spread given a seed set, the state-of-the-art methods, including heuristic and approximation algorithms, faced with great difficulties such as theoretical guarantee, time efficiency, generalization, etc. This makes it unable to adapt to large-scale networks and more complex applications. On the other side, with the latest achievements of Deep Reinforcement Learning (DRL) in artificial intelligence and other fields, lots of works have been focused on exploiting DRL to solve combinatorial optimization problems. Inspired by this, we propose a novel end-to-end DRL framework, ToupleGDD, to address the IM problem in this paper, which incorporates three coupled graph neural networks for network embedding and double deep Q-networks for parameters learning. Previous efforts to solve IM problem with DRL ",
    "link": "http://arxiv.org/abs/2210.07500",
    "context": "Title: ToupleGDD: A Fine-Designed Solution of Influence Maximization by Deep Reinforcement Learning. (arXiv:2210.07500v3 [cs.SI] UPDATED)\nAbstract: Aiming at selecting a small subset of nodes with maximum influence on networks, the Influence Maximization (IM) problem has been extensively studied. Since it is #P-hard to compute the influence spread given a seed set, the state-of-the-art methods, including heuristic and approximation algorithms, faced with great difficulties such as theoretical guarantee, time efficiency, generalization, etc. This makes it unable to adapt to large-scale networks and more complex applications. On the other side, with the latest achievements of Deep Reinforcement Learning (DRL) in artificial intelligence and other fields, lots of works have been focused on exploiting DRL to solve combinatorial optimization problems. Inspired by this, we propose a novel end-to-end DRL framework, ToupleGDD, to address the IM problem in this paper, which incorporates three coupled graph neural networks for network embedding and double deep Q-networks for parameters learning. Previous efforts to solve IM problem with DRL ",
    "path": "papers/22/10/2210.07500.json",
    "total_tokens": 1208,
    "translated_title": "ToupleGDD：基于深度强化学习的影响力最大化问题的精细解决方案",
    "translated_abstract": "影响力最大化（IM）问题始终是选择具有在网络中最大影响力的节点小子集的一个重要问题。然而，由于给定种子集合计算影响力扩散是#P-hard问题，现有的方法，包括启发式算法和近似算法，面临着理论保证，时间效率，泛化能力等方面的困难。同时，随着深度强化学习在人工智能和其他领域的最新成果，越来越多的工作已经关注于利用DRL解决组合优化问题。在此基础上，我们提出了一种新颖的端到端DRL框架ToupleGDD，用于解决IM问题，该框架将三个耦合的图神经网络用于网络嵌入，双重深度Q网络用于参数学习。与之前仅使用一个图神经网络或多个网络的线性组合来解决IM问题的DRL方法相比，ToupleGDD框架利用具有特定任务的多个图神经网络，并通过统一的损失函数将它们集成起来，从而能够捕获网络中节点和边缘的更丰富和多样化的信息。在真实的数据集上的实验结果表明，ToupleGDD框架具有最先进的性能和泛化能力，并且具有广泛应用的潜力。",
    "tldr": "提出了一个新颖的端到端DRL框架ToupleGDD，用于解决影响力最大化问题，该框架将三个耦合的图神经网络用于网络嵌入，双重深度Q网络用于参数学习，通过统一的损失函数将它们集成起来，捕获网络中节点和边缘的更丰富和多样化的信息，实验结果表明ToupleGDD具有最先进的性能和泛化能力。",
    "en_tdlr": "ToupleGDD is proposed as a novel end-to-end DRL framework for addressing the Influence Maximization problem by integrating three coupled graph neural networks and double deep Q-networks through a unified loss function, achieving state-of-the-art performance and generalization capability."
}