{
    "title": "On the Feasibility of Cross-Task Transfer with Model-Based Reinforcement Learning. (arXiv:2210.10763v2 [cs.LG] UPDATED)",
    "abstract": "Reinforcement Learning (RL) algorithms can solve challenging control problems directly from image observations, but they often require millions of environment interactions to do so. Recently, model-based RL algorithms have greatly improved sample-efficiency by concurrently learning an internal model of the world, and supplementing real environment interactions with imagined rollouts for policy improvement. However, learning an effective model of the world from scratch is challenging, and in stark contrast to humans that rely heavily on world understanding and visual cues for learning new skills. In this work, we investigate whether internal models learned by modern model-based RL algorithms can be leveraged to solve new, distinctly different tasks faster. We propose Model-Based Cross-Task Transfer (XTRA), a framework for sample-efficient online RL with scalable pretraining and finetuning of learned world models. By offline multi-task pretraining and online cross-task finetuning, we ach",
    "link": "http://arxiv.org/abs/2210.10763",
    "context": "Title: On the Feasibility of Cross-Task Transfer with Model-Based Reinforcement Learning. (arXiv:2210.10763v2 [cs.LG] UPDATED)\nAbstract: Reinforcement Learning (RL) algorithms can solve challenging control problems directly from image observations, but they often require millions of environment interactions to do so. Recently, model-based RL algorithms have greatly improved sample-efficiency by concurrently learning an internal model of the world, and supplementing real environment interactions with imagined rollouts for policy improvement. However, learning an effective model of the world from scratch is challenging, and in stark contrast to humans that rely heavily on world understanding and visual cues for learning new skills. In this work, we investigate whether internal models learned by modern model-based RL algorithms can be leveraged to solve new, distinctly different tasks faster. We propose Model-Based Cross-Task Transfer (XTRA), a framework for sample-efficient online RL with scalable pretraining and finetuning of learned world models. By offline multi-task pretraining and online cross-task finetuning, we ach",
    "path": "papers/22/10/2210.10763.json",
    "total_tokens": 1069,
    "translated_title": "关于采用基于模型的强化学习进行跨任务转移的可行性研究",
    "translated_abstract": "强化学习算法可以直接从图像观测中解决具有挑战性的控制问题，但通常需要数百万的环境交互才能做到。最近，基于模型的强化学习算法通过同时学习内部世界模型并补充真实环境交互以进行策略改进，极大地提高了样本效率。但是，从零开始学习有效的世界模型是具有挑战性的，与人类依赖于理解世界和视觉线索学习新技能形成鲜明对比。在本研究中，我们调查了现代基于模型的强化学习算法所学习的内部模型是否可以利用来更快地解决新的、明显不同的任务。我们提出了基于模型的跨任务转移（XTRA）框架，该框架具有可扩展的预训练和微调学习的世界模型。通过离线多任务预训练和在线跨任务微调，我们在各种模拟机器人操作任务中实现了显著的样本效率改进。我们的结果表明，XTRA是一种有效和可推广的RL方向。",
    "tldr": "本文研究了是否可以利用现代基于模型的强化学习算法学习的内部模型来更加快速地解决新的、明显不同的任务。我们提出了一种基于模型的跨任务转移框架，通过离线多任务预训练和在线跨任务微调，获得了在各种模拟机器人操作任务中显著的样本效率改进。",
    "en_tdlr": "This paper investigates whether the internal models learned by modern model-based reinforcement learning algorithms can be leveraged to solve new, distinctly different tasks faster. The study proposes a Model-Based Cross-Task Transfer (XTRA) framework, achieving significant sample efficiency improvements on a variety of simulated robotic manipulation tasks through offline multi-task pretraining and online cross-task finetuning."
}