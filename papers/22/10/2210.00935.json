{
    "title": "Analysis of (sub-)Riemannian PDE-G-CNNs. (arXiv:2210.00935v4 [cs.LG] UPDATED)",
    "abstract": "Group equivariant convolutional neural networks (G-CNNs) have been successfully applied in geometric deep learning. Typically, G-CNNs have the advantage over CNNs that they do not waste network capacity on training symmetries that should have been hard-coded in the network. The recently introduced framework of PDE-based G-CNNs (PDE-G-CNNs) generalises G-CNNs. PDE-G-CNNs have the core advantages that they simultaneously 1) reduce network complexity, 2) increase classification performance, and 3) provide geometric interpretability. Their implementations primarily consist of linear and morphological convolutions with kernels.  In this paper we show that the previously suggested approximative morphological kernels do not always accurately approximate the exact kernels accurately. More specifically, depending on the spatial anisotropy of the Riemannian metric, we argue that one must resort to sub-Riemannian approximations. We solve this problem by providing a new approximative kernel that w",
    "link": "http://arxiv.org/abs/2210.00935",
    "context": "Title: Analysis of (sub-)Riemannian PDE-G-CNNs. (arXiv:2210.00935v4 [cs.LG] UPDATED)\nAbstract: Group equivariant convolutional neural networks (G-CNNs) have been successfully applied in geometric deep learning. Typically, G-CNNs have the advantage over CNNs that they do not waste network capacity on training symmetries that should have been hard-coded in the network. The recently introduced framework of PDE-based G-CNNs (PDE-G-CNNs) generalises G-CNNs. PDE-G-CNNs have the core advantages that they simultaneously 1) reduce network complexity, 2) increase classification performance, and 3) provide geometric interpretability. Their implementations primarily consist of linear and morphological convolutions with kernels.  In this paper we show that the previously suggested approximative morphological kernels do not always accurately approximate the exact kernels accurately. More specifically, depending on the spatial anisotropy of the Riemannian metric, we argue that one must resort to sub-Riemannian approximations. We solve this problem by providing a new approximative kernel that w",
    "path": "papers/22/10/2210.00935.json",
    "total_tokens": 778,
    "translated_title": "(子)黎曼几何PDE-G-CNN的分析",
    "translated_abstract": "群等变卷积神经网络 (G-CNN) 在几何深度学习中得到了成功的应用。PDE-G-CNN框架是对G-CNN的推广，其主要优点是同时降低网络复杂性、提高分类性能和提供几何可解释性。本文发现先前推荐的近似形态学核不总是准确的，具体而言，取决于黎曼度量的空间各向异性，我们认为必须使用子黎曼逼近。我们通过提供新的近似核来解决这个问题。",
    "tldr": "本文为PDE-G-CNN模型中的形态学卷积核问题提供了新的解决方案，解决了先前推荐的近似核不准确的问题。"
}