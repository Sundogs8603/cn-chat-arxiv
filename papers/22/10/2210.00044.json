{
    "title": "Task Formulation Matters When Learning Continually: A Case Study in Visual Question Answering. (arXiv:2210.00044v2 [cs.LG] UPDATED)",
    "abstract": "Continual learning aims to train a model incrementally on a sequence of tasks without forgetting previous knowledge. Although continual learning has been widely studied in computer vision, its application to Vision+Language tasks is not that straightforward, as settings can be parameterized in multiple ways according to their input modalities. In this paper, we present a detailed study of how different settings affect performance for Visual Question Answering. We first propose three plausible task formulations and demonstrate their impact on the performance of continual learning algorithms. We break down several factors of task similarity, showing that performance and sensitivity to task order highly depend on the shift of the output distribution. We also investigate the potential of pretrained models and compare the robustness of transformer models with different visual embeddings. Finally, we provide an analysis interpreting model representations and their impact on forgetting. Our r",
    "link": "http://arxiv.org/abs/2210.00044",
    "context": "Title: Task Formulation Matters When Learning Continually: A Case Study in Visual Question Answering. (arXiv:2210.00044v2 [cs.LG] UPDATED)\nAbstract: Continual learning aims to train a model incrementally on a sequence of tasks without forgetting previous knowledge. Although continual learning has been widely studied in computer vision, its application to Vision+Language tasks is not that straightforward, as settings can be parameterized in multiple ways according to their input modalities. In this paper, we present a detailed study of how different settings affect performance for Visual Question Answering. We first propose three plausible task formulations and demonstrate their impact on the performance of continual learning algorithms. We break down several factors of task similarity, showing that performance and sensitivity to task order highly depend on the shift of the output distribution. We also investigate the potential of pretrained models and compare the robustness of transformer models with different visual embeddings. Finally, we provide an analysis interpreting model representations and their impact on forgetting. Our r",
    "path": "papers/22/10/2210.00044.json",
    "total_tokens": 952,
    "translated_title": "连续学习中任务的表述方式很重要：视觉问答案例研究",
    "translated_abstract": "连续学习旨在在一系列任务上增量训练模型，而不会遗忘之前的知识。尽管连续学习在计算机视觉中已被广泛研究，但在视觉+语言任务中的应用并不那么直观，因为根据输入模态可以有多种方式进行参数化。在本文中，我们对不同设置如何影响视觉问答的性能进行了详细研究。首先，我们提出了三种合理的任务表述，并展示了它们对连续学习算法性能的影响。我们对任务相似性的几个因素进行了细分，表明性能和对任务顺序的敏感度高度依赖于输出分布的变化。我们还调查了预训练模型的潜力，并比较了使用不同视觉嵌入的Transformer模型的稳健性。最后，我们提供了对模型表示和其对遗忘的影响的分析。",
    "tldr": "这项研究在连续学习领域中深入研究了任务的不同表述方式对视觉问答任务的性能的影响，发现输出分布的变化是性能和任务顺序敏感度的关键，同时探讨了预训练模型和不同视觉嵌入的Transformer模型的稳健性及模型表示对遗忘的影响。"
}