{
    "title": "When are Local Queries Useful for Robust Learning?. (arXiv:2210.06089v2 [cs.LG] UPDATED)",
    "abstract": "Distributional assumptions have been shown to be necessary for the robust learnability of concept classes when considering the exact-in-the-ball robust risk and access to random examples by Gourdeau et al. (2019). In this paper, we study learning models where the learner is given more power through the use of local queries, and give the first distribution-free algorithms that perform robust empirical risk minimization (ERM) for this notion of robustness. The first learning model we consider uses local membership queries (LMQ), where the learner can query the label of points near the training sample. We show that, under the uniform distribution, LMQs do not increase the robustness threshold of conjunctions and any superclass, e.g., decision lists and halfspaces. Faced with this negative result, we introduce the local equivalence query ($\\mathsf{LEQ}$) oracle, which returns whether the hypothesis and target concept agree in the perturbation region around a point in the training sample, a",
    "link": "http://arxiv.org/abs/2210.06089",
    "context": "Title: When are Local Queries Useful for Robust Learning?. (arXiv:2210.06089v2 [cs.LG] UPDATED)\nAbstract: Distributional assumptions have been shown to be necessary for the robust learnability of concept classes when considering the exact-in-the-ball robust risk and access to random examples by Gourdeau et al. (2019). In this paper, we study learning models where the learner is given more power through the use of local queries, and give the first distribution-free algorithms that perform robust empirical risk minimization (ERM) for this notion of robustness. The first learning model we consider uses local membership queries (LMQ), where the learner can query the label of points near the training sample. We show that, under the uniform distribution, LMQs do not increase the robustness threshold of conjunctions and any superclass, e.g., decision lists and halfspaces. Faced with this negative result, we introduce the local equivalence query ($\\mathsf{LEQ}$) oracle, which returns whether the hypothesis and target concept agree in the perturbation region around a point in the training sample, a",
    "path": "papers/22/10/2210.06089.json",
    "total_tokens": 1046,
    "translated_title": "何时局部查询在鲁棒学习中有用？",
    "translated_abstract": "在Gourdeau等人的研究中已经表明，对于考虑精确-球内鲁棒风险和随机示例访问的概念类的鲁棒可学习性，分布假设是必要的。在本文中，我们研究了学习模型，在通过使用局部查询增强学习者的能力，并给出了第一个针对这种鲁棒性概念进行鲁棒经验风险最小化（ERM）的无分布算法。我们考虑的第一个学习模型使用局部成员查询（LMQ），在这种查询中，学习者可以查询接近训练样本的点的标签。我们证明，在均匀分布下，LMQ不会增加并且不会超过连词和任何超类的鲁棒性阈值，例如决策列表和半空间。面对这一负面结果，我们引入了局部等价查询（LEQ）oracle，它返回假设和目标概念在训练样本中的扰动区域内是否一致。",
    "tldr": "本文研究了在鲁棒学习中使用局部查询的实用性，并提出了第一个针对这种鲁棒性概念进行鲁棒经验风险最小化的无分布算法。我们证明，在均匀分布下，局部成员查询不会增加并且不会超过连词和任何超类的鲁棒性阈值。另外，我们引入了局部等价查询oracle，用于在训练样本中判断假设和目标概念在扰动区域内是否一致。",
    "en_tdlr": "This paper investigates the usefulness of local queries in robust learning and proposes the first distribution-free algorithms for robust empirical risk minimization using local queries. It is shown that, under the uniform distribution, local membership queries do not increase the robustness threshold of conjunctions and any superclass. Furthermore, a local equivalence query oracle is introduced to determine the consistency between the hypothesis and target concept in the perturbation region around the training sample."
}