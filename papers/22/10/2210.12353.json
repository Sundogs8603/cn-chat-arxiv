{
    "title": "Leveraging Large Language Models for Multiple Choice Question Answering. (arXiv:2210.12353v3 [cs.CL] UPDATED)",
    "abstract": "While large language models (LLMs) like GPT-3 have achieved impressive results on multiple choice question answering (MCQA) tasks in the zero, one, and few-shot settings, they generally lag behind the MCQA state of the art (SOTA). MCQA tasks have traditionally been presented to LLMs like cloze tasks. An LLM is conditioned on a question (without the associated answer options) and its chosen option is the one assigned the highest probability after normalization (for length, etc.). A more natural prompting approach is to present the question and answer options to the LLM jointly and have it output the symbol (e.g., \"A\") associated with its chosen answer option. This approach allows the model to explicitly compare answer options, reduces computational costs, and mitigates the effects of tokenization scheme and answer option representations on answer selection. For the natural approach to be effective, the LLM it is used with must be able to associate answer options with the symbols that re",
    "link": "http://arxiv.org/abs/2210.12353",
    "context": "Title: Leveraging Large Language Models for Multiple Choice Question Answering. (arXiv:2210.12353v3 [cs.CL] UPDATED)\nAbstract: While large language models (LLMs) like GPT-3 have achieved impressive results on multiple choice question answering (MCQA) tasks in the zero, one, and few-shot settings, they generally lag behind the MCQA state of the art (SOTA). MCQA tasks have traditionally been presented to LLMs like cloze tasks. An LLM is conditioned on a question (without the associated answer options) and its chosen option is the one assigned the highest probability after normalization (for length, etc.). A more natural prompting approach is to present the question and answer options to the LLM jointly and have it output the symbol (e.g., \"A\") associated with its chosen answer option. This approach allows the model to explicitly compare answer options, reduces computational costs, and mitigates the effects of tokenization scheme and answer option representations on answer selection. For the natural approach to be effective, the LLM it is used with must be able to associate answer options with the symbols that re",
    "path": "papers/22/10/2210.12353.json",
    "total_tokens": 717,
    "translated_title": "利用大型语言模型进行多项选择题的答案推断",
    "translated_abstract": "大型语言模型如GPT-3在多项选择题答案推断任务中已经取得了令人瞩目的成果。然而，它们通常落后于多项选择题的最新研究成果。本文探讨了一种更自然的问题提示方式，即将问题和答案选项联合呈现给大型语言模型，以便模型能够明确比较答案选项，减少计算成本，降低标记化方案和答案选项表示对答案选择的影响。",
    "tldr": "本文研究了利用大型语言模型进行多项选择题的答案推断，并探讨了一种更自然的问题提示方式，以提高准确性。"
}