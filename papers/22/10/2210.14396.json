{
    "title": "FeDXL: Provable Federated Learning for Deep X-Risk Optimization. (arXiv:2210.14396v3 [cs.LG] UPDATED)",
    "abstract": "In this paper, we tackle a novel federated learning (FL) problem for optimizing a family of X-risks, to which no existing FL algorithms are applicable. In particular, the objective has the form of $\\mathbb E_{z\\sim S_1} f(\\mathbb E_{z'\\sim S_2} \\ell(w; z, z'))$, where two sets of data $S_1, S_2$ are distributed over multiple machines, $\\ell(\\cdot)$ is a pairwise loss that only depends on the prediction outputs of the input data pairs $(z, z')$, and $f(\\cdot)$ is possibly a non-linear non-convex function. This problem has important applications in machine learning, e.g., AUROC maximization with a pairwise loss, and partial AUROC maximization with a compositional loss. The challenges for designing an FL algorithm for X-risks lie in the non-decomposability of the objective over multiple machines and the interdependency between different machines. To this end, we propose an active-passive decomposition framework that decouples the gradient's components with two types, namely active parts a",
    "link": "http://arxiv.org/abs/2210.14396",
    "context": "Title: FeDXL: Provable Federated Learning for Deep X-Risk Optimization. (arXiv:2210.14396v3 [cs.LG] UPDATED)\nAbstract: In this paper, we tackle a novel federated learning (FL) problem for optimizing a family of X-risks, to which no existing FL algorithms are applicable. In particular, the objective has the form of $\\mathbb E_{z\\sim S_1} f(\\mathbb E_{z'\\sim S_2} \\ell(w; z, z'))$, where two sets of data $S_1, S_2$ are distributed over multiple machines, $\\ell(\\cdot)$ is a pairwise loss that only depends on the prediction outputs of the input data pairs $(z, z')$, and $f(\\cdot)$ is possibly a non-linear non-convex function. This problem has important applications in machine learning, e.g., AUROC maximization with a pairwise loss, and partial AUROC maximization with a compositional loss. The challenges for designing an FL algorithm for X-risks lie in the non-decomposability of the objective over multiple machines and the interdependency between different machines. To this end, we propose an active-passive decomposition framework that decouples the gradient's components with two types, namely active parts a",
    "path": "papers/22/10/2210.14396.json",
    "total_tokens": 756,
    "tldr": "本文提出了一种可以解决X风险优化问题的新型联邦学习算法"
}