{
    "title": "Lyapunov Function Consistent Adaptive Network Signal Control with Back Pressure and Reinforcement Learning. (arXiv:2210.02612v2 [eess.SY] UPDATED)",
    "abstract": "In traffic signal control, flow-based (optimizing the overall flow) and pressure-based methods (equalizing and alleviating congestion) are commonly used but often considered separately. This study introduces a unified framework using Lyapunov control theory, defining specific Lyapunov functions respectively for these methods. We have found interesting results. For example, the well-recognized back-pressure method is equal to differential queue lengths weighted by intersection lane saturation flows. We further improve it by adding basic traffic flow theory. Rather than ensuring that the control system be stable, the system should be also capable of adaptive to various performance metrics. Building on insights from Lyapunov theory, this study designs a reward function for the Reinforcement Learning (RL)-based network signal control, whose agent is trained with Double Deep Q-Network (DDQN) for effective control over complex traffic networks. The proposed algorithm is compared with several",
    "link": "http://arxiv.org/abs/2210.02612",
    "context": "Title: Lyapunov Function Consistent Adaptive Network Signal Control with Back Pressure and Reinforcement Learning. (arXiv:2210.02612v2 [eess.SY] UPDATED)\nAbstract: In traffic signal control, flow-based (optimizing the overall flow) and pressure-based methods (equalizing and alleviating congestion) are commonly used but often considered separately. This study introduces a unified framework using Lyapunov control theory, defining specific Lyapunov functions respectively for these methods. We have found interesting results. For example, the well-recognized back-pressure method is equal to differential queue lengths weighted by intersection lane saturation flows. We further improve it by adding basic traffic flow theory. Rather than ensuring that the control system be stable, the system should be also capable of adaptive to various performance metrics. Building on insights from Lyapunov theory, this study designs a reward function for the Reinforcement Learning (RL)-based network signal control, whose agent is trained with Double Deep Q-Network (DDQN) for effective control over complex traffic networks. The proposed algorithm is compared with several",
    "path": "papers/22/10/2210.02612.json",
    "total_tokens": 908,
    "translated_title": "具有背压和强化学习的Lyapunov函数一致自适应网络信号控制",
    "translated_abstract": "在交通信号控制中，基于流量和基于压力的方法通常分别使用，但往往被单独考虑。本研究引入了一个统一的框架，利用Lyapunov控制理论，分别为这些方法定义了特定的Lyapunov函数。我们发现了有趣的结果。例如，著名的背压方法等于交叉口车道饱和流量加权的差分队列长度。我们进一步通过添加基本的交通流理论来改进它。控制系统不仅应该确保稳定，还应该能够适应各种性能指标。基于Lyapunov理论的启示，本研究为基于强化学习的网络信号控制设计了一个奖励函数，该函数使用Double Deep Q-Network (DDQN)训练智能体，以有效控制复杂的交通网络。所提出的算法与几种常用的控制算法进行了比较。",
    "tldr": "这项研究提出了一种利用Lyapunov控制理论的统一框架，将基于流量和基于压力的交通信号控制方法相结合。通过引入背压方法和强化学习算法，实现对复杂交通网络的有效控制。",
    "en_tdlr": "This study introduces a unified framework using Lyapunov control theory to combine flow-based and pressure-based traffic signal control methods. By incorporating the back-pressure method and reinforcement learning algorithm, effective control over complex traffic networks is achieved."
}