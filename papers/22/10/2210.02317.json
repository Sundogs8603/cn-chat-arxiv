{
    "title": "Real-Time Reinforcement Learning for Vision-Based Robotics Utilizing Local and Remote Computers. (arXiv:2210.02317v2 [cs.RO] UPDATED)",
    "abstract": "Real-time learning is crucial for robotic agents adapting to ever-changing, non-stationary environments. A common setup for a robotic agent is to have two different computers simultaneously: a resource-limited local computer tethered to the robot and a powerful remote computer connected wirelessly. Given such a setup, it is unclear to what extent the performance of a learning system can be affected by resource limitations and how to efficiently use the wirelessly connected powerful computer to compensate for any performance loss. In this paper, we implement a real-time learning system called the Remote-Local Distributed (ReLoD) system to distribute computations of two deep reinforcement learning (RL) algorithms, Soft Actor-Critic (SAC) and Proximal Policy Optimization (PPO), between a local and a remote computer. The performance of the system is evaluated on two vision-based control tasks developed using a robotic arm and a mobile robot. Our results show that SAC's performance degrades",
    "link": "http://arxiv.org/abs/2210.02317",
    "context": "Title: Real-Time Reinforcement Learning for Vision-Based Robotics Utilizing Local and Remote Computers. (arXiv:2210.02317v2 [cs.RO] UPDATED)\nAbstract: Real-time learning is crucial for robotic agents adapting to ever-changing, non-stationary environments. A common setup for a robotic agent is to have two different computers simultaneously: a resource-limited local computer tethered to the robot and a powerful remote computer connected wirelessly. Given such a setup, it is unclear to what extent the performance of a learning system can be affected by resource limitations and how to efficiently use the wirelessly connected powerful computer to compensate for any performance loss. In this paper, we implement a real-time learning system called the Remote-Local Distributed (ReLoD) system to distribute computations of two deep reinforcement learning (RL) algorithms, Soft Actor-Critic (SAC) and Proximal Policy Optimization (PPO), between a local and a remote computer. The performance of the system is evaluated on two vision-based control tasks developed using a robotic arm and a mobile robot. Our results show that SAC's performance degrades",
    "path": "papers/22/10/2210.02317.json",
    "total_tokens": 898,
    "translated_title": "实时强化学习用于基于视觉的机器人，利用本地和远程计算机",
    "translated_abstract": "实时学习对于适应不断变化的非稳定环境的机器人代理至关重要。一个常见的机器人代理设置是同时有两台不同的计算机：与机器人相连的资源受限本地计算机和无线连接的强大远程计算机。在这样的设置下，尚不清楚学习系统的性能在资源限制方面能受到多大的影响，以及如何高效利用无线连接的强大计算机来弥补性能损失。在本文中，我们实现了一个实时学习系统，称为Remote-Local Distributed (ReLoD)系统，用于在本地和远程计算机之间分配两个深度强化学习算法Soft Actor-Critic (SAC)和Proximal Policy Optimization (PPO)的计算。该系统的性能在使用机械臂和移动机器人开发的两个基于视觉的控制任务上进行了评估。我们的结果表明SAC的性能下降了。",
    "tldr": "本文实现了一个名为ReLoD的实时学习系统，利用本地和远程计算机来分配深度强化学习算法的计算，并在基于视觉的控制任务上进行了评估。结果显示SAC的性能下降了。"
}