{
    "title": "Decoding Visual Neural Representations by Multimodal Learning of Brain-Visual-Linguistic Features. (arXiv:2210.06756v2 [cs.CV] UPDATED)",
    "abstract": "Decoding human visual neural representations is a challenging task with great scientific significance in revealing vision-processing mechanisms and developing brain-like intelligent machines. Most existing methods are difficult to generalize to novel categories that have no corresponding neural data for training. The two main reasons are 1) the under-exploitation of the multimodal semantic knowledge underlying the neural data and 2) the small number of paired (stimuli-responses) training data. To overcome these limitations, this paper presents a generic neural decoding method called BraVL that uses multimodal learning of brain-visual-linguistic features. We focus on modeling the relationships between brain, visual and linguistic features via multimodal deep generative models. Specifically, we leverage the mixture-of-product-of-experts formulation to infer a latent code that enables a coherent joint generation of all three modalities. To learn a more consistent joint representation and ",
    "link": "http://arxiv.org/abs/2210.06756",
    "context": "Title: Decoding Visual Neural Representations by Multimodal Learning of Brain-Visual-Linguistic Features. (arXiv:2210.06756v2 [cs.CV] UPDATED)\nAbstract: Decoding human visual neural representations is a challenging task with great scientific significance in revealing vision-processing mechanisms and developing brain-like intelligent machines. Most existing methods are difficult to generalize to novel categories that have no corresponding neural data for training. The two main reasons are 1) the under-exploitation of the multimodal semantic knowledge underlying the neural data and 2) the small number of paired (stimuli-responses) training data. To overcome these limitations, this paper presents a generic neural decoding method called BraVL that uses multimodal learning of brain-visual-linguistic features. We focus on modeling the relationships between brain, visual and linguistic features via multimodal deep generative models. Specifically, we leverage the mixture-of-product-of-experts formulation to infer a latent code that enables a coherent joint generation of all three modalities. To learn a more consistent joint representation and ",
    "path": "papers/22/10/2210.06756.json",
    "total_tokens": 1000,
    "translated_title": "通过多模态学习脑视觉语言特征解码视觉神经表征",
    "translated_abstract": "解码人类视觉神经表征是一个充满挑战的任务，在揭示视觉处理机制和开发类似大脑的智能机器方面具有重要的科学意义。本文提出了一种名为 BraVL 的通用神经解码方法，它利用了脑视觉语言特征的多模态学习。我们通过多模态深度生成模型建模脑、视觉和语言特征之间的关系，具体地说，我们利用产品混合模型的形式来推断潜在代码，从而实现三种模态的协同生成。为了学习更一致的联合表示并促进跨模态泛化，我们引入了一种称为模态丢失正则化的新的训练策略。在两个不同的人类 fMRI 数据集上的实验结果表明 BraVL 在对多个类别的视觉神经表征进行解码方面优于现有的最先进方法，包括新颖和未见过的。",
    "tldr": "本文提出了一种通用神经解码方法 BraVL，它利用了脑视觉语言特征的多模态学习，通过产品混合模型推断潜在代码，实现三种模态的协同生成，在解码视觉神经表征方面表现优于现有的最先进方法。",
    "en_tdlr": "This paper proposes a generic neural decoding method called BraVL, which uses multimodal learning of brain-visual-linguistic features to decode visual neural representations. The method outperforms state-of-the-art methods in decoding multiple categories of visual neural representations, including novel and unseen ones, by leveraging mixture-of-product-of-experts formulation to jointly generate all three modalities."
}