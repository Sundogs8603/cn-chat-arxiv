{
    "title": "Cross-lingual Text-To-Speech with Flow-based Voice Conversion for Improved Pronunciation",
    "abstract": "arXiv:2210.17264v2 Announce Type: replace-cross  Abstract: This paper presents a method for end-to-end cross-lingual text-to-speech (TTS) which aims to preserve the target language's pronunciation regardless of the original speaker's language. The model used is based on a non-attentive Tacotron architecture, where the decoder has been replaced with a normalizing flow network conditioned on the speaker identity, allowing both TTS and voice conversion (VC) to be performed by the same model due to the inherent linguistic content and speaker identity disentanglement. When used in a cross-lingual setting, acoustic features are initially produced with a native speaker of the target language and then voice conversion is applied by the same model in order to convert these features to the target speaker's voice. We verify through objective and subjective evaluations that our method can have benefits compared to baseline cross-lingual synthesis. By including speakers averaging 7.5 minutes of spe",
    "link": "https://arxiv.org/abs/2210.17264",
    "context": "Title: Cross-lingual Text-To-Speech with Flow-based Voice Conversion for Improved Pronunciation\nAbstract: arXiv:2210.17264v2 Announce Type: replace-cross  Abstract: This paper presents a method for end-to-end cross-lingual text-to-speech (TTS) which aims to preserve the target language's pronunciation regardless of the original speaker's language. The model used is based on a non-attentive Tacotron architecture, where the decoder has been replaced with a normalizing flow network conditioned on the speaker identity, allowing both TTS and voice conversion (VC) to be performed by the same model due to the inherent linguistic content and speaker identity disentanglement. When used in a cross-lingual setting, acoustic features are initially produced with a native speaker of the target language and then voice conversion is applied by the same model in order to convert these features to the target speaker's voice. We verify through objective and subjective evaluations that our method can have benefits compared to baseline cross-lingual synthesis. By including speakers averaging 7.5 minutes of spe",
    "path": "papers/22/10/2210.17264.json",
    "total_tokens": 801,
    "translated_title": "具有基于流的语音转换的跨语言文本到语音方法以改善发音",
    "translated_abstract": "本文提出了一种用于端到端跨语言文本到语音（TTS）的方法，旨在保留目标语言的发音，而不考虑原始说话者的语言。所使用的模型基于非注意力Tacotron架构，其中解码器已经被替换为一个受讲话者身份条件的归一化流网络，允许通过相同模型执行TTS和声音转换（VC），因为固有的语言内容和说话者身份解耦。在跨语言设置中使用时，首先使用目标语言的本地发音者产生声学特征，然后通过相同模型应用声音转换，以将这些特征转换为目标说话者的声音。我们通过客观和主观评估验证，我们的方法与基准跨语言合成相比具有一定好处。",
    "tldr": "通过基于流的语音转换实现了跨语言文本到语音，提升了发音质量，并在客观和主观评估中表现出优势。"
}