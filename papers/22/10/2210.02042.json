{
    "title": "FedMT: Federated Learning with Mixed-type Labels",
    "abstract": "arXiv:2210.02042v3 Announce Type: replace-cross Abstract: In federated learning (FL), classifiers (e.g., deep networks) are trained on datasets from multiple centers without exchanging data across them, and thus improves sample efficiency. In the classical setting of FL, the same labeling criterion is usually employed across all centers being involved in training. This constraint greatly limits the applicability of FL. For example, standards used for disease diagnosis are more likely to be different across clinical centers, which mismatches the classical FL setting. In this paper, we consider an important yet under-explored setting of FL, namely FL with mixed-type labels where different labeling criteria can be employed by various centers, leading to inter-center label space differences and challenging existing FL methods designed for the classical setting. To effectively and efficiently train models with mixed-type labels, we propose a theory-guided and model-agnostic approach that ca",
    "link": "https://arxiv.org/abs/2210.02042",
    "context": "Title: FedMT: Federated Learning with Mixed-type Labels\nAbstract: arXiv:2210.02042v3 Announce Type: replace-cross Abstract: In federated learning (FL), classifiers (e.g., deep networks) are trained on datasets from multiple centers without exchanging data across them, and thus improves sample efficiency. In the classical setting of FL, the same labeling criterion is usually employed across all centers being involved in training. This constraint greatly limits the applicability of FL. For example, standards used for disease diagnosis are more likely to be different across clinical centers, which mismatches the classical FL setting. In this paper, we consider an important yet under-explored setting of FL, namely FL with mixed-type labels where different labeling criteria can be employed by various centers, leading to inter-center label space differences and challenging existing FL methods designed for the classical setting. To effectively and efficiently train models with mixed-type labels, we propose a theory-guided and model-agnostic approach that ca",
    "path": "papers/22/10/2210.02042.json",
    "total_tokens": 880,
    "translated_title": "FedMT: 混合类型标签的联邦学习",
    "translated_abstract": "在联邦学习（FL）中，分类器（例如深度网络）在多个中心的数据集上进行训练，而无需在这些中心之间交换数据，从而提高了样本效率。在传统的FL设置中，通常在所有参与训练的中心中采用相同的标签准则。这个限制极大地限制了FL的适用性。例如，在疾病诊断中使用的标准很可能在临床中心之间存在差异，这与传统FL的设置不匹配。在本文中，我们考虑了一个重要但尚未充分探索的FL设置，即具有混合类型标签的FL，其中各个中心可以使用不同的标签准则，从而导致中心间标签空间的差异，并对为传统设置设计的现有FL方法提出了挑战。为了有效而高效地训练具有混合类型标签的模型，我们提出了一种基于理论指导和模型无关的方法",
    "tldr": "本文提出了一种概念新颖的联邦学习设置，即具有混合类型标签的联邦学习，在其中不同的中心可以使用不同的标签准则。为了有效地训练具有混合类型标签的模型，作者提出了一种理论指导和模型无关的方法。"
}