{
    "title": "LEAGUE: Guided Skill Learning and Abstraction for Long-Horizon Manipulation. (arXiv:2210.12631v2 [cs.AI] UPDATED)",
    "abstract": "To assist with everyday human activities, robots must solve complex long-horizon tasks and generalize to new settings. Recent deep reinforcement learning (RL) methods show promise in fully autonomous learning, but they struggle to reach long-term goals in large environments. On the other hand, Task and Motion Planning (TAMP) approaches excel at solving and generalizing across long-horizon tasks, thanks to their powerful state and action abstractions. But they assume predefined skill sets, which limits their real-world applications. In this work, we combine the benefits of these two paradigms and propose an integrated task planning and skill learning framework named LEAGUE (Learning and Abstraction with Guidance). LEAGUE leverages the symbolic interface of a task planner to guide RL-based skill learning and creates abstract state space to enable skill reuse. More importantly, LEAGUE learns manipulation skills in-situ of the task planning system, continuously growing its capability and t",
    "link": "http://arxiv.org/abs/2210.12631",
    "context": "Title: LEAGUE: Guided Skill Learning and Abstraction for Long-Horizon Manipulation. (arXiv:2210.12631v2 [cs.AI] UPDATED)\nAbstract: To assist with everyday human activities, robots must solve complex long-horizon tasks and generalize to new settings. Recent deep reinforcement learning (RL) methods show promise in fully autonomous learning, but they struggle to reach long-term goals in large environments. On the other hand, Task and Motion Planning (TAMP) approaches excel at solving and generalizing across long-horizon tasks, thanks to their powerful state and action abstractions. But they assume predefined skill sets, which limits their real-world applications. In this work, we combine the benefits of these two paradigms and propose an integrated task planning and skill learning framework named LEAGUE (Learning and Abstraction with Guidance). LEAGUE leverages the symbolic interface of a task planner to guide RL-based skill learning and creates abstract state space to enable skill reuse. More importantly, LEAGUE learns manipulation skills in-situ of the task planning system, continuously growing its capability and t",
    "path": "papers/22/10/2210.12631.json",
    "total_tokens": 901,
    "translated_title": "LEAGUE: 长期操纵的引导式技能学习与抽象化",
    "translated_abstract": "为了辅助日常的人类活动，机器人必须解决复杂的长期操纵任务，并且能够泛化到新环境中。近期的深度强化学习方法在完全自主学习方面显示出了希望，但是它们在大型环境中难以达到长期目标。另一方面，任务与动作规划（TAMP）方法在解决和泛化长期操纵任务方面表现出色，这要归功于它们强大的状态和动作抽象化。但是它们假设预先定义的技能集，这限制了它们在现实世界中的应用。在这项工作中，我们结合了这两种范式的优点，提出了一个集成任务规划和技能学习框架，名为LEAGUE（带引导的学习和抽象化）。LEAGUE利用任务规划器的符号接口来引导基于RL的技能学习，并创建抽象的状态空间以实现技能复用。更重要的是，LEAGUE在任务规划系统的场景中学习操纵技能，不断增强其能力。",
    "tldr": "这项工作提出了一种名为LEAGUE的集成任务规划和技能学习框架，通过利用任务规划器的引导，结合符号接口和抽象化技巧，实现了长期操纵任务的学习和泛化。"
}