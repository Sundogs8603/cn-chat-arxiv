{
    "title": "Rhythmic Gesticulator: Rhythm-Aware Co-Speech Gesture Synthesis with Hierarchical Neural Embeddings. (arXiv:2210.01448v3 [cs.SD] UPDATED)",
    "abstract": "Automatic synthesis of realistic co-speech gestures is an increasingly important yet challenging task in artificial embodied agent creation. Previous systems mainly focus on generating gestures in an end-to-end manner, which leads to difficulties in mining the clear rhythm and semantics due to the complex yet subtle harmony between speech and gestures. We present a novel co-speech gesture synthesis method that achieves convincing results both on the rhythm and semantics. For the rhythm, our system contains a robust rhythm-based segmentation pipeline to ensure the temporal coherence between the vocalization and gestures explicitly. For the gesture semantics, we devise a mechanism to effectively disentangle both low- and high-level neural embeddings of speech and motion based on linguistic theory. The high-level embedding corresponds to semantics, while the low-level embedding relates to subtle variations. Lastly, we build correspondence between the hierarchical embeddings of the speech ",
    "link": "http://arxiv.org/abs/2210.01448",
    "context": "Title: Rhythmic Gesticulator: Rhythm-Aware Co-Speech Gesture Synthesis with Hierarchical Neural Embeddings. (arXiv:2210.01448v3 [cs.SD] UPDATED)\nAbstract: Automatic synthesis of realistic co-speech gestures is an increasingly important yet challenging task in artificial embodied agent creation. Previous systems mainly focus on generating gestures in an end-to-end manner, which leads to difficulties in mining the clear rhythm and semantics due to the complex yet subtle harmony between speech and gestures. We present a novel co-speech gesture synthesis method that achieves convincing results both on the rhythm and semantics. For the rhythm, our system contains a robust rhythm-based segmentation pipeline to ensure the temporal coherence between the vocalization and gestures explicitly. For the gesture semantics, we devise a mechanism to effectively disentangle both low- and high-level neural embeddings of speech and motion based on linguistic theory. The high-level embedding corresponds to semantics, while the low-level embedding relates to subtle variations. Lastly, we build correspondence between the hierarchical embeddings of the speech ",
    "path": "papers/22/10/2210.01448.json",
    "total_tokens": 1010,
    "translated_title": "节奏性手势生成器：带有分层神经嵌入的节奏感知语音协同手势合成",
    "translated_abstract": "在人造智能体的创作中，自动生成逼真的协同手势成为了越来越重要的、具有挑战性的任务。过去的系统主要集中在以端到端的方式生成手势，这导致了在语音和手势之间的复杂但微妙的和谐关系中挖掘清晰的节奏和语义的困难。我们提出了一种新颖的协同手势合成方法，能够在节奏和语义方面都实现令人信服的结果。对于节奏，我们的系统包含了一个强大的基于节奏的分割流程，以确保语音和手势之间的时间协调明确可见。对于手势的语义，我们设计了一种机制来有效地区分基于语言学理论的语音和动作的低级和高级神经嵌入。高级嵌入对应语义，而低级嵌入则涉及微小的变化。最后，我们建立了语音和动作的分层嵌入之间的对应关系，使得我们的系统可以在语音和手势之间实现真正的情感互动。",
    "tldr": "本论文提出了一种新颖的协同手势合成方法，设计了一个强大的基于节奏的分割流程，并有效地区分了基于语言学理论的语音和动作的低级和高级神经嵌入，从而实现了在语音和手势之间的真正情感互动。",
    "en_tdlr": "The paper proposes a novel co-speech gesture synthesis method, which contains a robust rhythm-based segmentation pipeline and effectively disentangles low- and high-level neural embeddings of speech and motion based on linguistic theory, achieving a real emotional interaction between speech and gesture."
}