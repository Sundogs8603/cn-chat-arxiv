{
    "title": "Toxicity in Multilingual Machine Translation at Scale. (arXiv:2210.03070v2 [cs.CL] UPDATED)",
    "abstract": "Machine Translation systems can produce different types of errors, some of which are characterized as critical or catastrophic due to the specific negative impact that they can have on users. In this paper we focus on one type of critical error: added toxicity. We evaluate and analyze added toxicity when translating a large evaluation dataset (HOLISTICBIAS, over 472k sentences, covering 13 demographic axes) from English into 164 languages. An automatic toxicity evaluation shows that added toxicity across languages varies from 0% to 5%. The output languages with the most added toxicity tend to be low-resource ones, and the demographic axes with the most added toxicity include sexual orientation, gender and sex, and ability. We also perform human evaluation on a subset of 8 translation directions, confirming the prevalence of true added toxicity. We use a measurement of the amount of source contribution to the translation, where a low source contribution implies hallucination, to interpr",
    "link": "http://arxiv.org/abs/2210.03070",
    "context": "Title: Toxicity in Multilingual Machine Translation at Scale. (arXiv:2210.03070v2 [cs.CL] UPDATED)\nAbstract: Machine Translation systems can produce different types of errors, some of which are characterized as critical or catastrophic due to the specific negative impact that they can have on users. In this paper we focus on one type of critical error: added toxicity. We evaluate and analyze added toxicity when translating a large evaluation dataset (HOLISTICBIAS, over 472k sentences, covering 13 demographic axes) from English into 164 languages. An automatic toxicity evaluation shows that added toxicity across languages varies from 0% to 5%. The output languages with the most added toxicity tend to be low-resource ones, and the demographic axes with the most added toxicity include sexual orientation, gender and sex, and ability. We also perform human evaluation on a subset of 8 translation directions, confirming the prevalence of true added toxicity. We use a measurement of the amount of source contribution to the translation, where a low source contribution implies hallucination, to interpr",
    "path": "papers/22/10/2210.03070.json",
    "total_tokens": 970,
    "translated_title": "大规模多语言机器翻译中的毒性问题",
    "translated_abstract": "机器翻译系统可能会产生不同类型的错误，其中某些被称为关键或灾难性错误，因为它们可能对用户产生特定的负面影响。本文重点研究一种关键错误类型：添加的毒性。我们评估和分析了将一个大型评估数据集（HOLISTICBIAS，超过472k句，覆盖13个人口统计轴）从英语翻译成164种语言时添加毒性的情况。自动毒性评估显示，跨语言的添加毒性在0％至5％之间变化。添加毒性最严重的输出语言往往是低资源语言，而添加毒性最多的人口统计轴包括性取向，性别和能力。我们还对8个翻译方向的子集进行了人工评估，确认了真正存在添加毒性的现象。我们使用了对翻译的源贡献量的度量，其中低的源贡献意味着幻觉，以解释结果。",
    "tldr": "本文研究了在大规模多语言机器翻译中一种关键错误类型——添加毒性。自动和人工评估均表明低资源语言和特定人口统计轴，如性取向、性别和能力等，往往会出现更多的毒性。为了更好地解释这些结果，我们使用了度量翻译源贡献量的方法。",
    "en_tdlr": "This paper investigates a critical error type, added toxicity, in large-scale multilingual machine translation. The automatic and human evaluations show that low-resource languages and certain demographic axes, such as sexual orientation, gender, and ability, tend to have more added toxicity. To better explain these results, a measurement of the amount of source contribution to the translation is used."
}