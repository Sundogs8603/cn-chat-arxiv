{
    "title": "Evidence of Vocal Tract Articulation in Self-Supervised Learning of Speech. (arXiv:2210.11723v3 [eess.AS] UPDATED)",
    "abstract": "Recent self-supervised learning (SSL) models have proven to learn rich representations of speech, which can readily be utilized by diverse downstream tasks. To understand such utilities, various analyses have been done for speech SSL models to reveal which and how information is encoded in the learned representations. Although the scope of previous analyses is extensive in acoustic, phonetic, and semantic perspectives, the physical grounding by speech production has not yet received full attention. To bridge this gap, we conduct a comprehensive analysis to link speech representations to articulatory trajectories measured by electromagnetic articulography (EMA). Our analysis is based on a linear probing approach where we measure articulatory score as an average correlation of linear mapping to EMA. We analyze a set of SSL models selected from the leaderboard of the SUPERB benchmark and perform further layer-wise analyses on two most successful models, Wav2Vec 2.0 and HuBERT. Surprisingl",
    "link": "http://arxiv.org/abs/2210.11723",
    "context": "Title: Evidence of Vocal Tract Articulation in Self-Supervised Learning of Speech. (arXiv:2210.11723v3 [eess.AS] UPDATED)\nAbstract: Recent self-supervised learning (SSL) models have proven to learn rich representations of speech, which can readily be utilized by diverse downstream tasks. To understand such utilities, various analyses have been done for speech SSL models to reveal which and how information is encoded in the learned representations. Although the scope of previous analyses is extensive in acoustic, phonetic, and semantic perspectives, the physical grounding by speech production has not yet received full attention. To bridge this gap, we conduct a comprehensive analysis to link speech representations to articulatory trajectories measured by electromagnetic articulography (EMA). Our analysis is based on a linear probing approach where we measure articulatory score as an average correlation of linear mapping to EMA. We analyze a set of SSL models selected from the leaderboard of the SUPERB benchmark and perform further layer-wise analyses on two most successful models, Wav2Vec 2.0 and HuBERT. Surprisingl",
    "path": "papers/22/10/2210.11723.json",
    "total_tokens": 878,
    "translated_title": "证据显示自监督学习中的声道发音",
    "translated_abstract": "最近的自监督学习模型已经证明能够学习到丰富的语音表示，这些表示可以方便地被各种下游任务利用。为了理解这种效用，对语音自监督学习模型进行了各种分析，以揭示学习表示中的信息是哪些以及如何编码的。尽管先前的分析范围涵盖了声学、音位和语义等方面，但对语音产生的物理基础的关注还不够。为了弥补这一差距，我们进行了一项全面的分析，将语音表示与电磁装置记录的发音轨迹相联系。我们的分析基于线性探测方法，其中我们以EMA线性映射的平均相关性测量发音得分。我们分析了SUPERB基准测试排行榜中选择的一组自监督学习模型，并对最成功的两个模型Wav2Vec 2.0和HuBERT进行了更进一步的逐层分析。",
    "tldr": "这项研究分析了一系列自监督学习模型，通过线性探测方法将语音表示与发音轨迹相联系。结果显示声道发音在自监督学习中发挥了重要作用。"
}