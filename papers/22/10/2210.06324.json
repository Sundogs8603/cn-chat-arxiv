{
    "title": "SQuId: Measuring Speech Naturalness in Many Languages. (arXiv:2210.06324v2 [cs.CL] UPDATED)",
    "abstract": "Much of text-to-speech research relies on human evaluation, which incurs heavy costs and slows down the development process. The problem is particularly acute in heavily multilingual applications, where recruiting and polling judges can take weeks. We introduce SQuId (Speech Quality Identification), a multilingual naturalness prediction model trained on over a million ratings and tested in 65 locales-the largest effort of this type to date. The main insight is that training one model on many locales consistently outperforms mono-locale baselines. We present our task, the model, and show that it outperforms a competitive baseline based on w2v-BERT and VoiceMOS by 50.0%. We then demonstrate the effectiveness of cross-locale transfer during fine-tuning and highlight its effect on zero-shot locales, i.e., locales for which there is no fine-tuning data. Through a series of analyses, we highlight the role of non-linguistic effects such as sound artifacts in cross-locale transfer. Finally, we",
    "link": "http://arxiv.org/abs/2210.06324",
    "context": "Title: SQuId: Measuring Speech Naturalness in Many Languages. (arXiv:2210.06324v2 [cs.CL] UPDATED)\nAbstract: Much of text-to-speech research relies on human evaluation, which incurs heavy costs and slows down the development process. The problem is particularly acute in heavily multilingual applications, where recruiting and polling judges can take weeks. We introduce SQuId (Speech Quality Identification), a multilingual naturalness prediction model trained on over a million ratings and tested in 65 locales-the largest effort of this type to date. The main insight is that training one model on many locales consistently outperforms mono-locale baselines. We present our task, the model, and show that it outperforms a competitive baseline based on w2v-BERT and VoiceMOS by 50.0%. We then demonstrate the effectiveness of cross-locale transfer during fine-tuning and highlight its effect on zero-shot locales, i.e., locales for which there is no fine-tuning data. Through a series of analyses, we highlight the role of non-linguistic effects such as sound artifacts in cross-locale transfer. Finally, we",
    "path": "papers/22/10/2210.06324.json",
    "total_tokens": 1062,
    "translated_title": "SQuId: 在多语言中测量语音自然度",
    "translated_abstract": "文本到语音的许多研究都依赖于人类评估，这会产生重大成本并减缓开发进程。在重度多语言应用中，招募和调查评审员可能需要数周时间。我们介绍了SQuId（语音质量识别），这是一个使用一百万个评分进行训练并在65个语言环境下进行测试的多语言自然度预测模型，是迄今为止这种类型中最大的努力。主要的见解是，在许多环境中训练一个模型始终优于单一环境的基线。我们介绍了我们的任务、模型，并展示了它的表现优于基于w2v-BERT和VoiceMOS的竞争基线50.0%。然后，我们演示了跨语言细调的有效性，并强调了它对零样本环境的影响，即没有细调数据的环境。通过一系列分析，我们突出了非语言效果（如声音畸变）在跨语言细调中的作用。最后，我们展示了可能是第一个多语言自然度数据集，其中包含65个环境中超过一百万评分。",
    "tldr": "SQuId是一个使用一百万个评分进行训练并在65个语言环境下进行测试的多语言自然度预测模型，该模型的训练在许多环境中始终优于单一环境的基线，并展现了比竞争基线更出色的表现;研究还突出了跨语言细调的有效性，以及非语言效果如声音畸变在跨语言细调中的作用。",
    "en_tdlr": "SQuId is a multilingual naturalness prediction model trained on over a million ratings and tested in 65 locales, consistently outperforming mono-locale baselines; it highlights the effectiveness of cross-locale transfer during fine-tuning and the role of non-linguistic effects such as sound artifacts."
}