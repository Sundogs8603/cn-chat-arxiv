{
    "title": "Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs. (arXiv:2210.13312v2 [cs.CL] UPDATED)",
    "abstract": "Social intelligence and Theory of Mind (ToM), i.e., the ability to reason about the different mental states, intents, and reactions of all people involved, allow humans to effectively navigate and understand everyday social interactions. As NLP systems are used in increasingly complex social situations, their ability to grasp social dynamics becomes crucial. In this work, we examine the open question of social intelligence and Theory of Mind in modern NLP systems from an empirical and theory-based perspective. We show that one of today's largest language models (GPT-3; Brown et al., 2020) lacks this kind of social intelligence out-of-the box, using two tasks: SocialIQa (Sap et al., 2019), which measures models' ability to understand intents and reactions of participants of social interactions, and ToMi (Le et al., 2019), which measures whether models can infer mental states and realities of participants of situations. Our results show that models struggle substantially at these Theory ",
    "link": "http://arxiv.org/abs/2210.13312",
    "context": "Title: Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs. (arXiv:2210.13312v2 [cs.CL] UPDATED)\nAbstract: Social intelligence and Theory of Mind (ToM), i.e., the ability to reason about the different mental states, intents, and reactions of all people involved, allow humans to effectively navigate and understand everyday social interactions. As NLP systems are used in increasingly complex social situations, their ability to grasp social dynamics becomes crucial. In this work, we examine the open question of social intelligence and Theory of Mind in modern NLP systems from an empirical and theory-based perspective. We show that one of today's largest language models (GPT-3; Brown et al., 2020) lacks this kind of social intelligence out-of-the box, using two tasks: SocialIQa (Sap et al., 2019), which measures models' ability to understand intents and reactions of participants of social interactions, and ToMi (Le et al., 2019), which measures whether models can infer mental states and realities of participants of situations. Our results show that models struggle substantially at these Theory ",
    "path": "papers/22/10/2210.13312.json",
    "total_tokens": 1053,
    "translated_title": "神经心理理论？关于大型语言模型中社交智能局限的研究",
    "translated_abstract": "社交智能和心理理论（ToM）即理解所有参与者的不同心理状态、意图和反应的能力，使得人类能够有效地理解和应对日常社交互动。随着NLP系统在越来越复杂的社交场景中得到应用，理解社交动态的能力变得至关重要。本文从实证和理论的角度探讨了现代NLP系统中社交智能和心理理论这一开放性问题。我们使用两项任务：SocialIQa（Sap et al。，2019）和ToMi（Le et al。，2019）来衡量模型理解社交互动参与者意图和反应以及推断参与者心理状态和现实的能力。结果显示，当今最大的语言模型（GPT-3；Brown et al。，2020）缺乏这种社交智能。我们的研究结果强调了NLP系统在理解社交动态方面的当前局限性以及需要进一步研究这一领域的原因。",
    "tldr": "本文研究了现代NLP系统中社交智能和心理理论的问题。作者使用两个任务评估模型在理解社交互动意图和推断参与者心理状态和现实方面的能力，结果表明当前最大的语言模型GPT-3缺乏这种能力。这一发现强调了NLP系统在理解社交动态方面的当前局限性，并需要进一步研究。",
    "en_tdlr": "This paper examines the issue of social intelligence and Theory of Mind in modern NLP systems. The authors use two tasks to evaluate models' abilities to understand social interactions and infer participants' mental states and realities, demonstrating that even the largest language model, GPT-3, lacks this kind of social intelligence out-of-the-box. These findings highlight the current limitations of NLP systems in understanding social dynamics and the need for further research in this area."
}