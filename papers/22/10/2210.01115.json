{
    "title": "LASP: Text-to-Text Optimization for Language-Aware Soft Prompting of Vision & Language Models. (arXiv:2210.01115v2 [cs.CV] UPDATED)",
    "abstract": "Soft prompt learning has recently emerged as one of the methods of choice for adapting V&L models to a downstream task using a few training examples. However, current methods significantly overfit the training data, suffering from large accuracy degradation when tested on unseen classes from the same domain. To this end, in this paper, we make the following 4 contributions: (1) To alleviate base class overfitting, we propose a novel Language-Aware Soft Prompting (LASP) learning method by means of a text-to-text cross-entropy loss that maximizes the probability of the learned prompts to be correctly classified with respect to pre-defined hand-crafted textual prompts. (2) To increase the representation capacity of the prompts, we propose grouped LASP where each group of prompts is optimized with respect to a separate subset of textual prompts. (3) We identify a visual-language misalignment introduced by prompt learning and LASP, and more importantly, propose a re-calibration mechanism to",
    "link": "http://arxiv.org/abs/2210.01115",
    "context": "Title: LASP: Text-to-Text Optimization for Language-Aware Soft Prompting of Vision & Language Models. (arXiv:2210.01115v2 [cs.CV] UPDATED)\nAbstract: Soft prompt learning has recently emerged as one of the methods of choice for adapting V&L models to a downstream task using a few training examples. However, current methods significantly overfit the training data, suffering from large accuracy degradation when tested on unseen classes from the same domain. To this end, in this paper, we make the following 4 contributions: (1) To alleviate base class overfitting, we propose a novel Language-Aware Soft Prompting (LASP) learning method by means of a text-to-text cross-entropy loss that maximizes the probability of the learned prompts to be correctly classified with respect to pre-defined hand-crafted textual prompts. (2) To increase the representation capacity of the prompts, we propose grouped LASP where each group of prompts is optimized with respect to a separate subset of textual prompts. (3) We identify a visual-language misalignment introduced by prompt learning and LASP, and more importantly, propose a re-calibration mechanism to",
    "path": "papers/22/10/2210.01115.json",
    "total_tokens": 877,
    "translated_title": "适用于视觉与语言模型的LASP：面向语言感知的文本优化的文本提示。",
    "translated_abstract": "软模板学习最近已成为适应下游任务的V&L模型的选择方法之一，但当前的方法在经过训练数据的泛化性能方面存在较大缺陷。针对这一问题，本文提出了一种基于文本到文本交叉熵损失的语言感知的文本提示（LASP）学习方法，该方法可以有效地减少基类的过拟合，增加提示的表示能力，校准视觉-语言不匹配问题，并在三个下游任务上取得了显著的性能优于现有技术的实验结果。",
    "tldr": "本文提出了一种针对软模板学习中存在的基类过拟合问题的文本提示学习方法——LASP, 同时通过增加提示的表示能力和校准视觉-语言不匹配问题， 在三个下游任务上取得了显著的性能优于现有技术的实验结果。",
    "en_tdlr": "LASP is a language-aware soft prompting method that effectively reduces base class overfitting, increases prompt representation capacity, corrects the visual-language misalignment, and outperforms state-of-the-art methods in three downstream tasks."
}