{
    "title": "Preprocessors Matter! Realistic Decision-Based Attacks on Machine Learning Systems. (arXiv:2210.03297v2 [cs.CR] UPDATED)",
    "abstract": "Decision-based attacks construct adversarial examples against a machine learning (ML) model by making only hard-label queries. These attacks have mainly been applied directly to standalone neural networks. However, in practice, ML models are just one component of a larger learning system. We find that by adding a single preprocessor in front of a classifier, state-of-the-art query-based attacks are up to 7$\\times$ less effective at attacking a prediction pipeline than at attacking the model alone. We explain this discrepancy by the fact that most preprocessors introduce some notion of invariance to the input space. Hence, attacks that are unaware of this invariance inevitably waste a large number of queries to re-discover or overcome it. We, therefore, develop techniques to (i) reverse-engineer the preprocessor and then (ii) use this extracted information to attack the end-to-end system. Our preprocessors extraction method requires only a few hundred queries, and our preprocessor-aware",
    "link": "http://arxiv.org/abs/2210.03297",
    "context": "Title: Preprocessors Matter! Realistic Decision-Based Attacks on Machine Learning Systems. (arXiv:2210.03297v2 [cs.CR] UPDATED)\nAbstract: Decision-based attacks construct adversarial examples against a machine learning (ML) model by making only hard-label queries. These attacks have mainly been applied directly to standalone neural networks. However, in practice, ML models are just one component of a larger learning system. We find that by adding a single preprocessor in front of a classifier, state-of-the-art query-based attacks are up to 7$\\times$ less effective at attacking a prediction pipeline than at attacking the model alone. We explain this discrepancy by the fact that most preprocessors introduce some notion of invariance to the input space. Hence, attacks that are unaware of this invariance inevitably waste a large number of queries to re-discover or overcome it. We, therefore, develop techniques to (i) reverse-engineer the preprocessor and then (ii) use this extracted information to attack the end-to-end system. Our preprocessors extraction method requires only a few hundred queries, and our preprocessor-aware",
    "path": "papers/22/10/2210.03297.json",
    "total_tokens": 974,
    "translated_title": "预处理器很重要！对机器学习系统的现实决策攻击",
    "translated_abstract": "基于决策的攻击通过只进行硬标签查询来构建针对机器学习(ML)模型的对抗样本。这些攻击主要直接应用于独立的神经网络。然而，在实践中，ML模型只是更大学习系统的一个组成部分。我们发现，通过在分类器前添加一个预处理器，最先进的基于查询的攻击对攻击预测流水线的效果要比对单独的模型攻击高效7倍。我们解释了这种差异的原因是大多数预处理器引入了输入空间的某种不变性。因此，不知道这种不变性的攻击必然会浪费大量的查询来重新发现或克服它。因此，我们开发了技术来(i)逆向工程预处理器，然后(ii)利用提取的信息攻击端到端系统。我们的预处理器提取方法只需要几百个查询，并且我们的预处理器感知攻击可以有效绕过这些预处理器的防御。",
    "tldr": "在目标机器学习系统中加入预处理器可以有效提高对基于查询的攻击的防御能力。预处理器引入输入空间的不变性，攻击者需要大量的查询才能重新发现或克服这种不变性。通过逆向工程预处理器并利用提取的信息攻击端到端系统可以绕过这些预处理器的防御。",
    "en_tdlr": "Adding preprocessors to machine learning systems can effectively improve defense against query-based attacks. Preprocessors introduce invariance to the input space, requiring attackers to spend a large number of queries to rediscover or overcome this invariance. By reverse-engineering preprocessors and utilizing the extracted information, the end-to-end system can be attacked bypassing the defense provided by these preprocessors."
}