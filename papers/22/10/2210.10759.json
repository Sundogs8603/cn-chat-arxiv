{
    "title": "On Representing Mixed-Integer Linear Programs by Graph Neural Networks. (arXiv:2210.10759v2 [cs.LG] UPDATED)",
    "abstract": "While Mixed-integer linear programming (MILP) is NP-hard in general, practical MILP has received roughly 100--fold speedup in the past twenty years. Still, many classes of MILPs quickly become unsolvable as their sizes increase, motivating researchers to seek new acceleration techniques for MILPs. With deep learning, they have obtained strong empirical results, and many results were obtained by applying graph neural networks (GNNs) to making decisions in various stages of MILP solution processes. This work discovers a fundamental limitation: there exist feasible and infeasible MILPs that all GNNs will, however, treat equally, indicating GNN's lacking power to express general MILPs. Then, we show that, by restricting the MILPs to unfoldable ones or by adding random features, there exist GNNs that can reliably predict MILP feasibility, optimal objective values, and optimal solutions up to prescribed precision. We conducted small-scale numerical experiments to validate our theoretical fin",
    "link": "http://arxiv.org/abs/2210.10759",
    "context": "Title: On Representing Mixed-Integer Linear Programs by Graph Neural Networks. (arXiv:2210.10759v2 [cs.LG] UPDATED)\nAbstract: While Mixed-integer linear programming (MILP) is NP-hard in general, practical MILP has received roughly 100--fold speedup in the past twenty years. Still, many classes of MILPs quickly become unsolvable as their sizes increase, motivating researchers to seek new acceleration techniques for MILPs. With deep learning, they have obtained strong empirical results, and many results were obtained by applying graph neural networks (GNNs) to making decisions in various stages of MILP solution processes. This work discovers a fundamental limitation: there exist feasible and infeasible MILPs that all GNNs will, however, treat equally, indicating GNN's lacking power to express general MILPs. Then, we show that, by restricting the MILPs to unfoldable ones or by adding random features, there exist GNNs that can reliably predict MILP feasibility, optimal objective values, and optimal solutions up to prescribed precision. We conducted small-scale numerical experiments to validate our theoretical fin",
    "path": "papers/22/10/2210.10759.json",
    "total_tokens": 954,
    "translated_title": "论述用图神经网络表示混合整数线性规划问题",
    "translated_abstract": "尽管混合整数线性规划(MILP)问题通常为NP难问题，但是在过去的二十年中，实际的MILP问题已经获得了大约100倍的加速。尽管如此，许多类别的MILP问题在规模不断增加时迅速变得不可解，这促使研究人员寻求新的加速技术以解决MILP问题。通过深度学习，研究人员获得了强有力的实证结果，并且许多结果都是通过将图神经网络(GNN)应用于MILP解决过程的各个阶段来获得的。本研究发现了一个根本性的局限性：存在可行和不可行的MILP问题，而所有的GNN都会平等地处理这些问题，表明GNN对于表示一般的MILP问题的能力不足。然后，我们通过限制MILP为可展开的问题或添加随机特征，证明了存在能够可靠地预测MILP可行性、最优目标值和最优解的GNN。我们进行了小规模的数值实验来验证理论结果。",
    "tldr": "本研究探讨了用图神经网络表示混合整数线性规划问题的局限性，证明了一些针对特定情况下的限制条件下存在可靠的GNN方法，可以预测MILP问题的可行性、最优目标值和最优解。",
    "en_tdlr": "This study explores the limitations of using graph neural networks to represent mixed-integer linear programming problems and proves the existence of reliable GNN methods for predicting the feasibility, optimal objective values, and optimal solutions of MILPs under specific restricted conditions."
}