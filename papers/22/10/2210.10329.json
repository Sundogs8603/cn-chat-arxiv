{
    "title": "Language Detoxification with Attribute-Discriminative Latent Space. (arXiv:2210.10329v2 [cs.CL] UPDATED)",
    "abstract": "Transformer-based Language Models (LMs) have achieved impressive results on natural language understanding tasks, but they can also generate toxic text such as insults, threats, and profanity, limiting their real-world applications. To overcome this issue, a few text generation approaches aim to detoxify toxic texts using additional LMs or perturbations. However, previous methods require excessive memory, computations, and time which are serious bottlenecks in their real-world application. To address such limitations, we propose an effective yet efficient method for language detoxification using an attribute-discriminative latent space. Specifically, we project the latent space of an original Transformer LM onto a discriminative latent space that well-separates texts by their attributes using a projection block and an attribute discriminator. This allows the LM to control the text generation to be non-toxic with minimal memory and computation overhead. We validate our model, Attribute-",
    "link": "http://arxiv.org/abs/2210.10329",
    "context": "Title: Language Detoxification with Attribute-Discriminative Latent Space. (arXiv:2210.10329v2 [cs.CL] UPDATED)\nAbstract: Transformer-based Language Models (LMs) have achieved impressive results on natural language understanding tasks, but they can also generate toxic text such as insults, threats, and profanity, limiting their real-world applications. To overcome this issue, a few text generation approaches aim to detoxify toxic texts using additional LMs or perturbations. However, previous methods require excessive memory, computations, and time which are serious bottlenecks in their real-world application. To address such limitations, we propose an effective yet efficient method for language detoxification using an attribute-discriminative latent space. Specifically, we project the latent space of an original Transformer LM onto a discriminative latent space that well-separates texts by their attributes using a projection block and an attribute discriminator. This allows the LM to control the text generation to be non-toxic with minimal memory and computation overhead. We validate our model, Attribute-",
    "path": "papers/22/10/2210.10329.json",
    "total_tokens": 930,
    "translated_title": "带属性辨别潜空间的语言去毒化",
    "translated_abstract": "基于Transformer的语言模型已在自然语言理解任务上取得了令人瞩目的结果，但它们也可能生成包含侮辱、威胁和亵渎等有毒文本，限制了它们在现实世界中的应用。为了克服这个问题，一些文本生成方法旨在使用额外的语言模型或扰动来去毒化有毒文本。然而，先前的方法需要过多的内存、计算和时间，这在实际应用中成为了严重的瓶颈。为了解决这些限制，我们提出了一种有效 yet 高效的语言去毒化方法，使用一个带属性辨别的潜空间。具体而言，我们通过投影块和属性辨别器，将原始Transformer语言模型的潜空间投影到一个能够通过属性将文本进行良好分离的辨别性潜空间上。这允许语言模型在最小的内存和计算开销下控制文本生成为非有毒的。我们验证了我们的模型，",
    "tldr": "本研究提出了一种使用属性辨别潜空间进行语言去毒化的方法，通过将原始Transformer语言模型的潜空间投影到一个能够通过属性将文本进行良好分离的潜空间上，最小化内存和计算开销，实现了对有毒文本的控制。",
    "en_tdlr": "This study proposes a method for language detoxification using attribute-discriminative latent space, which projects the latent space of the original Transformer language model onto a discriminative latent space that separates texts by their attributes, minimizing memory and computation overhead, and enabling control over toxic text generation."
}