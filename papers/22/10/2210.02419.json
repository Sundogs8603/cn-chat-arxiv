{
    "title": "Boundary-Aware Uncertainty for Feature Attribution Explainers. (arXiv:2210.02419v4 [cs.LG] UPDATED)",
    "abstract": "Post-hoc explanation methods have become a critical tool for understanding black-box classifiers in high-stakes applications. However, high-performing classifiers are often highly nonlinear and can exhibit complex behavior around the decision boundary, leading to brittle or misleading local explanations. Therefore there is an impending need to quantify the uncertainty of such explanation methods in order to understand when explanations are trustworthy. In this work we propose the Gaussian Process Explanation unCertainty (GPEC) framework, which generates a unified uncertainty estimate combining decision boundary-aware uncertainty with explanation function approximation uncertainty. We introduce a novel geodesic-based kernel, which captures the complexity of the target black-box decision boundary. We show theoretically that the proposed kernel similarity increases with decision boundary complexity. The proposed framework is highly flexible; it can be used with any black-box classifier an",
    "link": "http://arxiv.org/abs/2210.02419",
    "context": "Title: Boundary-Aware Uncertainty for Feature Attribution Explainers. (arXiv:2210.02419v4 [cs.LG] UPDATED)\nAbstract: Post-hoc explanation methods have become a critical tool for understanding black-box classifiers in high-stakes applications. However, high-performing classifiers are often highly nonlinear and can exhibit complex behavior around the decision boundary, leading to brittle or misleading local explanations. Therefore there is an impending need to quantify the uncertainty of such explanation methods in order to understand when explanations are trustworthy. In this work we propose the Gaussian Process Explanation unCertainty (GPEC) framework, which generates a unified uncertainty estimate combining decision boundary-aware uncertainty with explanation function approximation uncertainty. We introduce a novel geodesic-based kernel, which captures the complexity of the target black-box decision boundary. We show theoretically that the proposed kernel similarity increases with decision boundary complexity. The proposed framework is highly flexible; it can be used with any black-box classifier an",
    "path": "papers/22/10/2210.02419.json",
    "total_tokens": 980,
    "translated_title": "边界感知不确定性可解释特征的探索",
    "translated_abstract": "后续的解释方法已经成为理解高风险应用中黑盒分类器的关键工具。然而，高性能分类器通常是高度非线性的，并且在决策边界周围展现出复杂的行为，导致脆弱或误导性的局部解释。因此，有必要量化这种解释方法的不确定性，以了解何时可以信任解释。在本文中，我们提出了高斯过程解释不确定性（GPEC）框架，它生成了一个统一的不确定性估计，将决策边界感知不确定性与解释函数逼近不确定性相结合。我们介绍了一种新的基于测地线的核，它捕捉目标黑盒决策边界的复杂性。我们理论上证明所提出的核相似度随着决策边界的复杂性递增。该提出的框架非常灵活，可以与任何黑盒分类器和任何解释方法一起使用。我们在各种数据集上进行实验，并显示GPEC优于现有方法的不确定度估计，并导致更可靠的特征归因。",
    "tldr": "本文提出了一种名为高斯过程解释不确定性（GPEC）框架，它可以对复杂的黑盒分类器进行可靠的特征归因，该框架结合了决策边界感知不确定性和解释函数逼近不确定性，能够生成一个统一的不确定性估计。"
}