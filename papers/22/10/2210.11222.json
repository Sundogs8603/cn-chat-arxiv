{
    "title": "Learning-Augmented Private Algorithms for Multiple Quantile Release. (arXiv:2210.11222v2 [cs.CR] UPDATED)",
    "abstract": "When applying differential privacy to sensitive data, we can often improve performance using external information such as other sensitive data, public data, or human priors. We propose to use the learning-augmented algorithms (or algorithms with predictions) framework -- previously applied largely to improve time complexity or competitive ratios -- as a powerful way of designing and analyzing privacy-preserving methods that can take advantage of such external information to improve utility. This idea is instantiated on the important task of multiple quantile release, for which we derive error guarantees that scale with a natural measure of prediction quality while (almost) recovering state-of-the-art prediction-independent guarantees. Our analysis enjoys several advantages, including minimal assumptions about the data, a natural way of adding robustness, and the provision of useful surrogate losses for two novel ``meta\" algorithms that learn predictions from other (potentially sensitiv",
    "link": "http://arxiv.org/abs/2210.11222",
    "context": "Title: Learning-Augmented Private Algorithms for Multiple Quantile Release. (arXiv:2210.11222v2 [cs.CR] UPDATED)\nAbstract: When applying differential privacy to sensitive data, we can often improve performance using external information such as other sensitive data, public data, or human priors. We propose to use the learning-augmented algorithms (or algorithms with predictions) framework -- previously applied largely to improve time complexity or competitive ratios -- as a powerful way of designing and analyzing privacy-preserving methods that can take advantage of such external information to improve utility. This idea is instantiated on the important task of multiple quantile release, for which we derive error guarantees that scale with a natural measure of prediction quality while (almost) recovering state-of-the-art prediction-independent guarantees. Our analysis enjoys several advantages, including minimal assumptions about the data, a natural way of adding robustness, and the provision of useful surrogate losses for two novel ``meta\" algorithms that learn predictions from other (potentially sensitiv",
    "path": "papers/22/10/2210.11222.json",
    "total_tokens": 858,
    "translated_title": "多分位数发布的学习增强私有算法",
    "translated_abstract": "当应用差分隐私于敏感数据时，我们常常可以利用额外的信息例如其他敏感数据、公众数据或人类信息先验来提升性能。本文提出了使用学习增强算法（或具有预测能力的算法）框架，这个框架通常使用于优化时间复杂度或竞争比率。该框架为设计和分析保护隐私的方法提供了一种强有力的方法，并能够利用这些额外信息以提高效用。该想法体现在重要的多分位数发布任务中，在此我们得出了随着自然质量预测的错误保证，同时（几乎）恢复了最先进的预测独立的保证。我们的分析具有几个优点，包括对数据的最小假设，一种自然的增强鲁棒性的方法，以及为两个从其他数据中学习预测的新颖“元”算法提供有用的替代损失。",
    "tldr": "本文提出一种新的隐私保护方法：使用学习增强算法框架，为多分位数发布任务提供可扩展的预测质量误差保证。",
    "en_tdlr": "This paper proposes a new privacy-preserving method that utilizes the learning-augmented algorithm framework to improve utility by taking advantage of external information, and applies it to the important task of multiple quantile release, achieving scalable error guarantees based on prediction quality measures."
}