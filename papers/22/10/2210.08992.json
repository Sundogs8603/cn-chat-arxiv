{
    "title": "Language-agnostic Code-Switching in Sequence-To-Sequence Speech Recognition. (arXiv:2210.08992v2 [cs.CL] UPDATED)",
    "abstract": "Code-Switching (CS) is referred to the phenomenon of alternately using words and phrases from different languages. While today's neural end-to-end (E2E) models deliver state-of-the-art performances on the task of automatic speech recognition (ASR) it is commonly known that these systems are very data-intensive. However, there is only a few transcribed and aligned CS speech available. To overcome this problem and train multilingual systems which can transcribe CS speech, we propose a simple yet effective data augmentation in which audio and corresponding labels of different source languages are concatenated. By using this training data, our E2E model improves on transcribing CS speech. It also surpasses monolingual models on monolingual tests. The results show that this augmentation technique can even improve the model's performance on inter-sentential language switches not seen during training by 5,03% WER.",
    "link": "http://arxiv.org/abs/2210.08992",
    "context": "Title: Language-agnostic Code-Switching in Sequence-To-Sequence Speech Recognition. (arXiv:2210.08992v2 [cs.CL] UPDATED)\nAbstract: Code-Switching (CS) is referred to the phenomenon of alternately using words and phrases from different languages. While today's neural end-to-end (E2E) models deliver state-of-the-art performances on the task of automatic speech recognition (ASR) it is commonly known that these systems are very data-intensive. However, there is only a few transcribed and aligned CS speech available. To overcome this problem and train multilingual systems which can transcribe CS speech, we propose a simple yet effective data augmentation in which audio and corresponding labels of different source languages are concatenated. By using this training data, our E2E model improves on transcribing CS speech. It also surpasses monolingual models on monolingual tests. The results show that this augmentation technique can even improve the model's performance on inter-sentential language switches not seen during training by 5,03% WER.",
    "path": "papers/22/10/2210.08992.json",
    "total_tokens": 961,
    "translated_title": "无语言限制的代码切换在序列到序列语音识别中的应用",
    "translated_abstract": "代码切换（CS）是指交替使用不同语言的单词和短语的现象。尽管现今的神经端到端（E2E）模型在自动语音识别（ASR）任务上表现出卓越的性能，但众所周知这些系统需要海量的数据。然而，现有的转录和对齐的CS语音数据很少。为了解决这个问题，并训练能够转录CS语音的多语言系统，我们提出了一种简单而有效的数据增强方法，即将不同源语言的音频和相应标签连接起来。通过使用这些训练数据，我们的E2E模型在转录CS语音方面得到了改进。它还在单语测试上超过了单语模型。结果表明，这种增强技术甚至可以提高模型在训练期间未见过的句间语言切换上的性能，WER提高了5.03%。",
    "tldr": "这项研究提出了一种数据增强方法，用于训练能够转录代码切换（CS）语音的多语言系统。通过将不同源语言的音频和标签连接起来，可以改善模型在转录CS语音上的性能，并在单语测试中超过了单语模型。这种增强技术甚至可以提高模型在训练期间未见过的句间语言切换上的性能。",
    "en_tdlr": "This study proposes a data augmentation method for training multilingual systems capable of transcribing code-switching (CS) speech. By concatenating audio and labels from different source languages, the model's performance on transcribing CS speech is improved and surpasses monolingual models on monolingual tests. This augmentation technique even enhances the model's performance on inter-sentential language switches not seen during training."
}