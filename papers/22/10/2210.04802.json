{
    "title": "SimSCOOD: Systematic Analysis of Out-of-Distribution Generalization in Fine-tuned Source Code Models. (arXiv:2210.04802v2 [cs.SE] UPDATED)",
    "abstract": "Large code datasets have become increasingly accessible for pre-training source code models. However, for the fine-tuning phase, obtaining representative training data that fully covers the code distribution for specific downstream tasks remains challenging due to the task-specific nature and limited labeling resources. Moreover, fine-tuning pretrained models can result in forgetting previously acquired pre-training knowledge. These lead to out-of-distribution (OOD) generalization issues with unexpected model inference behaviors that have not been systematically studied yet. In this paper, we contribute the first systematic approach that simulates various OOD scenarios along different dimensions of source code data properties and study the fine-tuned model behaviors in such scenarios. We investigate the behaviors of models under different fine-tuning methodologies, including full fine-tuning and Low-Rank Adaptation (LoRA) fine-tuning methods. Our comprehensive analysis, conducted on fo",
    "link": "http://arxiv.org/abs/2210.04802",
    "context": "Title: SimSCOOD: Systematic Analysis of Out-of-Distribution Generalization in Fine-tuned Source Code Models. (arXiv:2210.04802v2 [cs.SE] UPDATED)\nAbstract: Large code datasets have become increasingly accessible for pre-training source code models. However, for the fine-tuning phase, obtaining representative training data that fully covers the code distribution for specific downstream tasks remains challenging due to the task-specific nature and limited labeling resources. Moreover, fine-tuning pretrained models can result in forgetting previously acquired pre-training knowledge. These lead to out-of-distribution (OOD) generalization issues with unexpected model inference behaviors that have not been systematically studied yet. In this paper, we contribute the first systematic approach that simulates various OOD scenarios along different dimensions of source code data properties and study the fine-tuned model behaviors in such scenarios. We investigate the behaviors of models under different fine-tuning methodologies, including full fine-tuning and Low-Rank Adaptation (LoRA) fine-tuning methods. Our comprehensive analysis, conducted on fo",
    "path": "papers/22/10/2210.04802.json",
    "total_tokens": 853,
    "translated_title": "SimSCOOD: Fine-tuned源代码模型的超分布泛化的系统分析",
    "translated_abstract": "大型代码数据集已经越来越容易地用于预训练源代码模型。然而，对于微调阶段来说，获取代表性的训练数据以充分覆盖特定下游任务的代码分布仍然具有挑战性，原因是任务特定性和有限的标注资源。此外，微调预训练模型可能会导致遗忘以前获得的预训练知识。这些问题导致了超分布泛化问题，即模型的推理行为出现意外情况，这尚未进行系统研究。在本文中，我们提出了第一个系统方法，模拟了不同维度源代码数据属性的各种超分布场景，并研究了这些场景中微调模型的行为。我们研究了不同微调方法（包括全微调和低秩适应微调方法）下模型的行为。我们在各个系统上进行了全面分析。",
    "tldr": "本文是第一个系统研究超分布泛化问题的方法，通过模拟不同维度的源代码数据属性和微调方法，在不同场景中研究了模型的行为。",
    "en_tdlr": "This paper presents the first systematic approach to studying the out-of-distribution generalization issues in fine-tuned source code models. By simulating various scenarios and analyzing model behaviors under different fine-tuning methodologies, the authors provide insights into unexpected inference behaviors."
}