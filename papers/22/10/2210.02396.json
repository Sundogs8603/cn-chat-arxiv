{
    "title": "Temporally Consistent Transformers for Video Generation. (arXiv:2210.02396v2 [cs.CV] UPDATED)",
    "abstract": "To generate accurate videos, algorithms have to understand the spatial and temporal dependencies in the world. Current algorithms enable accurate predictions over short horizons but tend to suffer from temporal inconsistencies. When generated content goes out of view and is later revisited, the model invents different content instead. Despite this severe limitation, no established benchmarks on complex data exist for rigorously evaluating video generation with long temporal dependencies. In this paper, we curate 3 challenging video datasets with long-range dependencies by rendering walks through 3D scenes of procedural mazes, Minecraft worlds, and indoor scans. We perform a comprehensive evaluation of current models and observe their limitations in temporal consistency. Moreover, we introduce the Temporally Consistent Transformer (TECO), a generative model that substantially improves long-term consistency while also reducing sampling time. By compressing its input sequence into fewer e",
    "link": "http://arxiv.org/abs/2210.02396",
    "context": "Title: Temporally Consistent Transformers for Video Generation. (arXiv:2210.02396v2 [cs.CV] UPDATED)\nAbstract: To generate accurate videos, algorithms have to understand the spatial and temporal dependencies in the world. Current algorithms enable accurate predictions over short horizons but tend to suffer from temporal inconsistencies. When generated content goes out of view and is later revisited, the model invents different content instead. Despite this severe limitation, no established benchmarks on complex data exist for rigorously evaluating video generation with long temporal dependencies. In this paper, we curate 3 challenging video datasets with long-range dependencies by rendering walks through 3D scenes of procedural mazes, Minecraft worlds, and indoor scans. We perform a comprehensive evaluation of current models and observe their limitations in temporal consistency. Moreover, we introduce the Temporally Consistent Transformer (TECO), a generative model that substantially improves long-term consistency while also reducing sampling time. By compressing its input sequence into fewer e",
    "path": "papers/22/10/2210.02396.json",
    "total_tokens": 878,
    "translated_title": "时态一致的变换器用于视频生成",
    "translated_abstract": "为了生成准确的视频，算法必须理解世界中的时空依赖关系。目前的算法虽然能够准确预测短期内的内容，但往往存在时间上的不一致性。当生成的内容消失后再次出现时，模型会发明不同的内容。尽管存在这种严重的限制，但目前尚不存在复杂数据的已建立基准来对具有长期时间依赖性的视频生成进行严格评估。在本文中，我们通过渲染通过 3D 场景的流程迷宫，Minecraft 世界和室内扫描，策划了三个具有长程依赖的视频数据集。我们对当前模型进行全面评估，并观察到它们在时间一致性方面的局限性。此外，我们引入了时态一致的变换器（TECO），一种生成模型，它显著提高了长期一致性，同时也减少了采样时间。通过将其输入序列压缩为更少的项，",
    "tldr": "本文介绍了一种名为TECO的生成模型，其可以大大提高视频生成的长期时间一致性。作者提出了3个难度不同的视频数据集以评估该模型和现有模型在时间一致性方面的局限性。"
}