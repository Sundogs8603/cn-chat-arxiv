{
    "title": "Learning Graphical Factor Models with Riemannian Optimization. (arXiv:2210.11950v2 [stat.ML] UPDATED)",
    "abstract": "Graphical models and factor analysis are well-established tools in multivariate statistics. While these models can be both linked to structures exhibited by covariance and precision matrices, they are generally not jointly leveraged within graph learning processes. This paper therefore addresses this issue by proposing a flexible algorithmic framework for graph learning under low-rank structural constraints on the covariance matrix. The problem is expressed as penalized maximum likelihood estimation of an elliptical distribution (a generalization of Gaussian graphical models to possibly heavy-tailed distributions), where the covariance matrix is optionally constrained to be structured as low-rank plus diagonal (low-rank factor model). The resolution of this class of problems is then tackled with Riemannian optimization, where we leverage geometries of positive definite matrices and positive semi-definite matrices of fixed rank that are well suited to elliptical models. Numerical experi",
    "link": "http://arxiv.org/abs/2210.11950",
    "context": "Title: Learning Graphical Factor Models with Riemannian Optimization. (arXiv:2210.11950v2 [stat.ML] UPDATED)\nAbstract: Graphical models and factor analysis are well-established tools in multivariate statistics. While these models can be both linked to structures exhibited by covariance and precision matrices, they are generally not jointly leveraged within graph learning processes. This paper therefore addresses this issue by proposing a flexible algorithmic framework for graph learning under low-rank structural constraints on the covariance matrix. The problem is expressed as penalized maximum likelihood estimation of an elliptical distribution (a generalization of Gaussian graphical models to possibly heavy-tailed distributions), where the covariance matrix is optionally constrained to be structured as low-rank plus diagonal (low-rank factor model). The resolution of this class of problems is then tackled with Riemannian optimization, where we leverage geometries of positive definite matrices and positive semi-definite matrices of fixed rank that are well suited to elliptical models. Numerical experi",
    "path": "papers/22/10/2210.11950.json",
    "total_tokens": 810,
    "translated_title": "用Riemannian优化学习图形因子模型",
    "translated_abstract": "图形模型和因子分析是多元统计学中成熟的工具。尽管这些模型都可以与协方差和精度矩阵的结构联系起来，但它们通常在图的学习过程中没有被共同利用。因此，本文通过提出一种在协方差矩阵上具有低秩结构约束的图学习的灵活算法框架来解决这个问题。该问题被表达为基于最大似然估计的罚函数方法，其中协方差矩阵可以选择性地被约束为低秩加对角线结构（低秩因子模型）。然后，我们利用正定矩阵和固定秩正半定矩阵的几何特性（这些特性非常适用于椭圆模型）来解决这类问题中的最优化问题。数值实验",
    "tldr": "本文提出了一种灵活的算法框架，用于在协方差矩阵上具有低秩结构约束的图学习。通过使用Riemannian优化，利用正定矩阵和固定秩正半定矩阵的几何特性，解决了这类问题。"
}