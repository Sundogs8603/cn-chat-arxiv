{
    "title": "Omnigrok: Grokking Beyond Algorithmic Data. (arXiv:2210.01117v2 [cs.LG] UPDATED)",
    "abstract": "Grokking, the unusual phenomenon for algorithmic datasets where generalization happens long after overfitting the training data, has remained elusive. We aim to understand grokking by analyzing the loss landscapes of neural networks, identifying the mismatch between training and test losses as the cause for grokking. We refer to this as the \"LU mechanism\" because training and test losses (against model weight norm) typically resemble \"L\" and \"U\", respectively. This simple mechanism can nicely explain many aspects of grokking: data size dependence, weight decay dependence, the emergence of representations, etc. Guided by the intuitive picture, we are able to induce grokking on tasks involving images, language and molecules. In the reverse direction, we are able to eliminate grokking for algorithmic datasets. We attribute the dramatic nature of grokking for algorithmic datasets to representation learning.",
    "link": "http://arxiv.org/abs/2210.01117",
    "context": "Title: Omnigrok: Grokking Beyond Algorithmic Data. (arXiv:2210.01117v2 [cs.LG] UPDATED)\nAbstract: Grokking, the unusual phenomenon for algorithmic datasets where generalization happens long after overfitting the training data, has remained elusive. We aim to understand grokking by analyzing the loss landscapes of neural networks, identifying the mismatch between training and test losses as the cause for grokking. We refer to this as the \"LU mechanism\" because training and test losses (against model weight norm) typically resemble \"L\" and \"U\", respectively. This simple mechanism can nicely explain many aspects of grokking: data size dependence, weight decay dependence, the emergence of representations, etc. Guided by the intuitive picture, we are able to induce grokking on tasks involving images, language and molecules. In the reverse direction, we are able to eliminate grokking for algorithmic datasets. We attribute the dramatic nature of grokking for algorithmic datasets to representation learning.",
    "path": "papers/22/10/2210.01117.json",
    "total_tokens": 916,
    "translated_title": "Omnigrok：理解超越算法数据的“Grokking”",
    "translated_abstract": "Grokking是一种不寻常的现象，指算法数据集在过拟合训练数据后长时间仍然能进行泛化，一直以来一直难以理解。本文旨在通过分析神经网络的损失景观来理解grokking，并确定训练和测试损失之间的不匹配是grokking的原因。我们将其称为“LU机制”，因为训练和测试损失（对模型权重规范）通常分别类似于“L”和“U”。这个简单的机制可以很好地解释grokking的许多方面：数据大小依赖性、权重衰减依赖性、表示的出现等。在直觉上给定的基础上，我们能够在涉及图像、语言和分子的任务中诱导grokking。反向来看，我们能够消除算法数据集的grokking。我们将算法数据集的dramatic grokking归因于表示学习。",
    "tldr": "本文通过分析神经网络的损失景观，发现训练和测试损失之间的不匹配是grokking的原因，提出了“LU机制”，并成功诱导了算法数据集的grokking和消除了其grokking现象。它们的dramatic grokking依赖于表示学习。",
    "en_tdlr": "This paper aims to understand grokking phenomenon where generalization happens long after overfitting the training data. The authors identify the mismatch between training and test losses as the cause for grokking, propose the \"LU mechanism\", and successfully induce grokking and eliminate grokking for algorithmic datasets. The dramatic grokking of algorithmic datasets is attributed to representation learning."
}