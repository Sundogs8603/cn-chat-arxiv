{
    "title": "The Tail Wagging the Dog: Dataset Construction Biases of Social Bias Benchmarks. (arXiv:2210.10040v2 [cs.CL] UPDATED)",
    "abstract": "How reliably can we trust the scores obtained from social bias benchmarks as faithful indicators of problematic social biases in a given language model? In this work, we study this question by contrasting social biases with non-social biases stemming from choices made during dataset construction that might not even be discernible to the human eye. To do so, we empirically simulate various alternative constructions for a given benchmark based on innocuous modifications (such as paraphrasing or random-sampling) that maintain the essence of their social bias. On two well-known social bias benchmarks (Winogender and BiasNLI) we observe that these shallow modifications have a surprising effect on the resulting degree of bias across various models. We hope these troubling observations motivate more robust measures of social biases.",
    "link": "http://arxiv.org/abs/2210.10040",
    "context": "Title: The Tail Wagging the Dog: Dataset Construction Biases of Social Bias Benchmarks. (arXiv:2210.10040v2 [cs.CL] UPDATED)\nAbstract: How reliably can we trust the scores obtained from social bias benchmarks as faithful indicators of problematic social biases in a given language model? In this work, we study this question by contrasting social biases with non-social biases stemming from choices made during dataset construction that might not even be discernible to the human eye. To do so, we empirically simulate various alternative constructions for a given benchmark based on innocuous modifications (such as paraphrasing or random-sampling) that maintain the essence of their social bias. On two well-known social bias benchmarks (Winogender and BiasNLI) we observe that these shallow modifications have a surprising effect on the resulting degree of bias across various models. We hope these troubling observations motivate more robust measures of social biases.",
    "path": "papers/22/10/2210.10040.json",
    "total_tokens": 774,
    "translated_title": "数据集构建的偏见：社会偏见基准的问题",
    "translated_abstract": "我们能否可靠地相信从社会偏见基准得到的分数是对给定语言模型中存在的问题社会偏见的忠实指标？本文通过将社会偏见与来源于数据集构建过程中的非社会偏见进行对比研究这一问题。为此，我们根据无害的修改（如释义或随机抽样）实际模拟了给定基准的各种替代结构，这些修改保持其社会偏见的本质。在两个众所周知的社会偏见基准（Winogender和BiasNLI）中，我们观察到这些浅显的修改对各种模型中导致的偏见程度产生了惊人的影响。我们希望这些令人不安的观察结果能够激发更严谨的社会偏见度量方法。",
    "tldr": "研究揭示了社会偏见基准中数据集构建偏见可能对结果造成了重要影响，需要更严谨的社会偏见度量方法。",
    "en_tdlr": "The study reveals that dataset construction biases in social bias benchmarks may have significant effects on results and calls for more rigorous measures of social biases."
}