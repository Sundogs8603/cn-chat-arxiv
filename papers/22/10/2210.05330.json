{
    "title": "Label Noise-Robust Learning using a Confidence-Based Sieving Strategy. (arXiv:2210.05330v3 [cs.LG] UPDATED)",
    "abstract": "In learning tasks with label noise, improving model robustness against overfitting is a pivotal challenge because the model eventually memorizes labels, including the noisy ones. Identifying the samples with noisy labels and preventing the model from learning them is a promising approach to address this challenge. When training with noisy labels, the per-class confidence scores of the model, represented by the class probabilities, can be reliable criteria for assessing whether the input label is the true label or the corrupted one. In this work, we exploit this observation and propose a novel discriminator metric called confidence error and a sieving strategy called CONFES to differentiate between the clean and noisy samples effectively. We provide theoretical guarantees on the probability of error for our proposed metric. Then, we experimentally illustrate the superior performance of our proposed approach compared to recent studies on various settings, such as synthetic and real-world",
    "link": "http://arxiv.org/abs/2210.05330",
    "context": "Title: Label Noise-Robust Learning using a Confidence-Based Sieving Strategy. (arXiv:2210.05330v3 [cs.LG] UPDATED)\nAbstract: In learning tasks with label noise, improving model robustness against overfitting is a pivotal challenge because the model eventually memorizes labels, including the noisy ones. Identifying the samples with noisy labels and preventing the model from learning them is a promising approach to address this challenge. When training with noisy labels, the per-class confidence scores of the model, represented by the class probabilities, can be reliable criteria for assessing whether the input label is the true label or the corrupted one. In this work, we exploit this observation and propose a novel discriminator metric called confidence error and a sieving strategy called CONFES to differentiate between the clean and noisy samples effectively. We provide theoretical guarantees on the probability of error for our proposed metric. Then, we experimentally illustrate the superior performance of our proposed approach compared to recent studies on various settings, such as synthetic and real-world",
    "path": "papers/22/10/2210.05330.json",
    "total_tokens": 951,
    "translated_title": "使用基于置信度的筛选策略实现标签噪声鲁棒学习",
    "translated_abstract": "在存在标签噪声的学习任务中，改善模型对过拟合的鲁棒性是一个关键挑战，因为模型最终会记住包括噪声标签在内的标签。识别具有噪声标签的样本并防止模型学习它们是解决这个挑战的一种有效方法。在训练过程中，模型的每个类别的置信度分数，表示为类别概率，可以作为评估输入标签是否真实标签或者是损坏标签的可靠标准。在这项工作中，我们利用这一观察结果，提出了一种新颖的判别度量称为置信度误差和一种称为CONFES的筛选策略，能够有效区分干净样本和有噪声的样本。我们提供了关于我们提出的度量的误差概率的理论保证。然后，通过实验证明了我们提出的方法在各种设置下（例如合成数据和真实世界数据）相对于最近的研究具有卓越性能。",
    "tldr": "本文提出了一种使用基于置信度的筛选策略实现标签噪声鲁棒学习的方法。通过利用模型的置信度分数，可以有效区分干净样本和有噪声的样本，提供了理论保证并在实验证明了其相对于最近的研究具有卓越性能。"
}