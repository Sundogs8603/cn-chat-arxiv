{
    "title": "Using Interventions to Improve Out-of-Distribution Generalization of Text-Matching Recommendation Systems. (arXiv:2210.10636v2 [cs.IR] UPDATED)",
    "abstract": "Given a user's input text, text-matching recommender systems output relevant items by comparing the input text to available items' description, such as product-to-product recommendation on e-commerce platforms. As users' interests and item inventory are expected to change, it is important for a text-matching system to generalize to data shifts, a task known as out-of-distribution (OOD) generalization. However, we find that the popular approach of fine-tuning a large, base language model on paired item relevance data (e.g., user clicks) can be counter-productive for OOD generalization. For a product recommendation task, fine-tuning obtains worse accuracy than the base model when recommending items in a new category or for a future time period. To explain this generalization failure, we consider an intervention-based importance metric, which shows that a fine-tuned model captures spurious correlations and fails to learn the causal features that determine the relevance between any two tex",
    "link": "http://arxiv.org/abs/2210.10636",
    "context": "Title: Using Interventions to Improve Out-of-Distribution Generalization of Text-Matching Recommendation Systems. (arXiv:2210.10636v2 [cs.IR] UPDATED)\nAbstract: Given a user's input text, text-matching recommender systems output relevant items by comparing the input text to available items' description, such as product-to-product recommendation on e-commerce platforms. As users' interests and item inventory are expected to change, it is important for a text-matching system to generalize to data shifts, a task known as out-of-distribution (OOD) generalization. However, we find that the popular approach of fine-tuning a large, base language model on paired item relevance data (e.g., user clicks) can be counter-productive for OOD generalization. For a product recommendation task, fine-tuning obtains worse accuracy than the base model when recommending items in a new category or for a future time period. To explain this generalization failure, we consider an intervention-based importance metric, which shows that a fine-tuned model captures spurious correlations and fails to learn the causal features that determine the relevance between any two tex",
    "path": "papers/22/10/2210.10636.json",
    "total_tokens": 944,
    "translated_title": "使用干预方法提高文本匹配推荐系统的跨领域泛化能力",
    "translated_abstract": "给定用户的输入文本，文本匹配推荐系统通过将输入文本与可用商品的描述进行比较来输出相关商品，例如在电子商务平台上的商品推荐。由于用户的兴趣和物品库存预计会发生变化，因此文本匹配系统具有泛化至数据变化的能力，这是一项称为跨领域（OOD）泛化的任务。然而，我们发现，精调大型基础语言模型相对于已配对的商品相关数据（例如用户点击）的流行方法可能对OOD泛化具有反效果。对于商品推荐任务，在推荐新类别或未来时间段的商品时，微调获得的准确性比基础模型更差。为了解释这种泛化失败，我们考虑了基于干预的重要性指标，该指标显示微调模型捕捉了虚假相关性，并未学习确定任何两个文本之间相关性的因果特征。",
    "tldr": "本文提出了使用干预方法来提高文本匹配推荐系统的跨领域泛化能力。研究发现，常用的基于精调模型的方法在具有新领域数据时有反效果，为此，提出了基于干预的重要性度量来解释泛化失败的原因。",
    "en_tdlr": "This paper proposes using intervention methods to improve the out-of-distribution generalization of text-matching recommendation system. The study found that the popular approach of fine-tuning a large, base language model on paired item relevance data can be counter-productive for out-of-distribution generalization. An intervention-based importance metric is proposed to explain the reason for this generalization failure."
}