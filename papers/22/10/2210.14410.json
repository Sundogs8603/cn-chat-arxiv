{
    "title": "Improving Adversarial Robustness via Joint Classification and Multiple Explicit Detection Classes. (arXiv:2210.14410v2 [cs.CV] UPDATED)",
    "abstract": "This work concerns the development of deep networks that are certifiably robust to adversarial attacks. Joint robust classification-detection was recently introduced as a certified defense mechanism, where adversarial examples are either correctly classified or assigned to the \"abstain\" class. In this work, we show that such a provable framework can benefit by extension to networks with multiple explicit abstain classes, where the adversarial examples are adaptively assigned to those. We show that naively adding multiple abstain classes can lead to \"model degeneracy\", then we propose a regularization approach and a training method to counter this degeneracy by promoting full use of the multiple abstain classes. Our experiments demonstrate that the proposed approach consistently achieves favorable standard vs. robust verified accuracy tradeoffs, outperforming state-of-the-art algorithms for various choices of number of abstain classes.",
    "link": "http://arxiv.org/abs/2210.14410",
    "context": "Title: Improving Adversarial Robustness via Joint Classification and Multiple Explicit Detection Classes. (arXiv:2210.14410v2 [cs.CV] UPDATED)\nAbstract: This work concerns the development of deep networks that are certifiably robust to adversarial attacks. Joint robust classification-detection was recently introduced as a certified defense mechanism, where adversarial examples are either correctly classified or assigned to the \"abstain\" class. In this work, we show that such a provable framework can benefit by extension to networks with multiple explicit abstain classes, where the adversarial examples are adaptively assigned to those. We show that naively adding multiple abstain classes can lead to \"model degeneracy\", then we propose a regularization approach and a training method to counter this degeneracy by promoting full use of the multiple abstain classes. Our experiments demonstrate that the proposed approach consistently achieves favorable standard vs. robust verified accuracy tradeoffs, outperforming state-of-the-art algorithms for various choices of number of abstain classes.",
    "path": "papers/22/10/2210.14410.json",
    "total_tokens": 985,
    "translated_title": "通过联合分类和多个明确检测类来提高对抗鲁棒性",
    "translated_abstract": "本文关注于开发能够在对抗性攻击下有保障的深度神经网络。联合鲁棒性分类和检测被最近引入作为一种可验证的防御机制，其中对抗性示例被正确分类或分配到“弃权”类别。在本文中，我们表明这样的可证明框架可以通过扩展到具有多个明确弃权类别的网络中而获益，其中对抗性示例被适应地分配到那些类别。我们表明，简单地添加多个弃权类别可能会导致“模型退化”，然后我们提出了一种正则化方法和训练方法来对抗这种退化，通过促进充分使用多个弃权类别。我们的实验表明，所提出的方法一致地实现了有利的标准和鲁棒性验证准确性平衡点，并在各种选择弃权类别数量的情况下优于最先进的算法。",
    "tldr": "本文提出一种联合分类和多个明确检测类的方法来提高对抗鲁棒性，在保证可验证的防御机制的基础上，实现了对具有多个明确弃权类别的网络的保障，并通过正则化方法和训练方法对抗了模型的退化。所提出的方法在实现有利的标准和鲁棒性验证准确性平衡点方面表现出色，比现有算法更出色。",
    "en_tdlr": "This paper proposes a method of joint classification and multiple explicit detection classes to improve adversarial robustness, which realizes the assurance of networks with multiple explicit abstain classes on the basis of a certifiable defense mechanism and counteracts model degeneracy through regularization approach and training method. The proposed method outperforms state-of-the-art algorithms in achieving favorable standard vs. robust verified accuracy tradeoffs for various choices of number of abstain classes."
}