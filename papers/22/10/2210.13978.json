{
    "title": "Boosting the Cycle Counting Power of Graph Neural Networks with I$^2$-GNNs. (arXiv:2210.13978v2 [cs.LG] UPDATED)",
    "abstract": "Message Passing Neural Networks (MPNNs) are a widely used class of Graph Neural Networks (GNNs). The limited representational power of MPNNs inspires the study of provably powerful GNN architectures. However, knowing one model is more powerful than another gives little insight about what functions they can or cannot express. It is still unclear whether these models are able to approximate specific functions such as counting certain graph substructures, which is essential for applications in biology, chemistry and social network analysis. Motivated by this, we propose to study the counting power of Subgraph MPNNs, a recent and popular class of powerful GNN models that extract rooted subgraphs for each node, assign the root node a unique identifier and encode the root node's representation within its rooted subgraph. Specifically, we prove that Subgraph MPNNs fail to count more-than-4-cycles at node level, implying that node representations cannot correctly encode the surrounding substru",
    "link": "http://arxiv.org/abs/2210.13978",
    "context": "Title: Boosting the Cycle Counting Power of Graph Neural Networks with I$^2$-GNNs. (arXiv:2210.13978v2 [cs.LG] UPDATED)\nAbstract: Message Passing Neural Networks (MPNNs) are a widely used class of Graph Neural Networks (GNNs). The limited representational power of MPNNs inspires the study of provably powerful GNN architectures. However, knowing one model is more powerful than another gives little insight about what functions they can or cannot express. It is still unclear whether these models are able to approximate specific functions such as counting certain graph substructures, which is essential for applications in biology, chemistry and social network analysis. Motivated by this, we propose to study the counting power of Subgraph MPNNs, a recent and popular class of powerful GNN models that extract rooted subgraphs for each node, assign the root node a unique identifier and encode the root node's representation within its rooted subgraph. Specifically, we prove that Subgraph MPNNs fail to count more-than-4-cycles at node level, implying that node representations cannot correctly encode the surrounding substru",
    "path": "papers/22/10/2210.13978.json",
    "total_tokens": 827,
    "translated_title": "提升I$^2$-GNN在循环计数方面的图神经网络性能",
    "translated_abstract": "消息传递神经网络(MPNNs)是一类被广泛应用的图神经网络(GNNs)。然而，MPNNs的表达能力有限，这启发我们研究可证明具有更强表达能力的GNN体系结构。本文提出研究子图MPNNs的计数能力，这是一类最新和常用的强大GNN模型，其从每个节点提取根据子图，在根节点分配唯一标识符并在其根据子图中编码根节点的表示。具体地，我们证明子图MPNNs不能在节点级别上计数超过4个的环，这意味着节点表示不能正确地编码周围的子结构。",
    "tldr": "本文研究了一种名为Subgraph MPNNs的GNN模型。我们发现，Subgraph MPNNs不能在节点级别上计数超过4个的环，这对于生物学、化学和社交网络分析等应用至关重要。"
}