{
    "title": "TuneUp: A Simple Improved Training Strategy for Graph Neural Networks. (arXiv:2210.14843v2 [stat.ML] UPDATED)",
    "abstract": "Despite recent advances in Graph Neural Networks (GNNs), their training strategies remain largely under-explored. The conventional training strategy learns over all nodes in the original graph(s) equally, which can be sub-optimal as certain nodes are often more difficult to learn than others. Here we present TuneUp, a simple curriculum-based training strategy for improving the predictive performance of GNNs. TuneUp trains a GNN in two stages. In the first stage, TuneUp applies conventional training to obtain a strong base GNN. The base GNN tends to perform well on head nodes (nodes with large degrees) but less so on tail nodes (nodes with small degrees). Therefore, the second stage of TuneUp focuses on improving prediction on the difficult tail nodes by further training the base GNN on synthetically generated tail node data. We theoretically analyze TuneUp and show it provably improves generalization performance on tail nodes. TuneUp is simple to implement and applicable to a broad ran",
    "link": "http://arxiv.org/abs/2210.14843",
    "context": "Title: TuneUp: A Simple Improved Training Strategy for Graph Neural Networks. (arXiv:2210.14843v2 [stat.ML] UPDATED)\nAbstract: Despite recent advances in Graph Neural Networks (GNNs), their training strategies remain largely under-explored. The conventional training strategy learns over all nodes in the original graph(s) equally, which can be sub-optimal as certain nodes are often more difficult to learn than others. Here we present TuneUp, a simple curriculum-based training strategy for improving the predictive performance of GNNs. TuneUp trains a GNN in two stages. In the first stage, TuneUp applies conventional training to obtain a strong base GNN. The base GNN tends to perform well on head nodes (nodes with large degrees) but less so on tail nodes (nodes with small degrees). Therefore, the second stage of TuneUp focuses on improving prediction on the difficult tail nodes by further training the base GNN on synthetically generated tail node data. We theoretically analyze TuneUp and show it provably improves generalization performance on tail nodes. TuneUp is simple to implement and applicable to a broad ran",
    "path": "papers/22/10/2210.14843.json",
    "total_tokens": 914,
    "translated_title": "TuneUp:一种简单的改进的图神经网络训练策略",
    "translated_abstract": "尽管图神经网络（GNN）在近期取得了许多进展，但它们的训练策略仍然未被充分探索。传统的训练策略对原始图中的所有节点进行平等学习，这可能是次优的，因为某些节点往往比其他节点更难学习。在这里，我们提出了TuneUp，一种简单的基于课程的训练策略，用于提高GNN的预测性能。TuneUp将GNN分为两个阶段进行训练。在第一阶段，TuneUp应用传统的训练方法，获得一个强大的基础GNN。基础GNN在头节点（具有大度数的节点）上表现良好，但在尾节点（具有小度数的节点）上表现较差。因此，TuneUp的第二阶段侧重于通过进一步训练基础GNN以在难以预测的尾节点上提高预测能力。我们在理论上分析了TuneUp，并证明它能够改善尾节点的泛化性能。TuneUp实现简单，适用于广泛的范围。",
    "tldr": "TuneUp是一种简单的基于课程的训练策略，用于改进图神经网络在难以预测的尾节点上的泛化性能。",
    "en_tdlr": "TuneUp is a simple curriculum-based training strategy that improves the generalization performance of Graph Neural Networks on difficult-to-predict tail nodes."
}