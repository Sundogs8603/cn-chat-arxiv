{
    "title": "Code4Struct: Code Generation for Few-Shot Event Structure Prediction. (arXiv:2210.12810v2 [cs.CL] UPDATED)",
    "abstract": "Large Language Model (LLM) trained on a mixture of text and code has demonstrated impressive capability in translating natural language (NL) into structured code. We observe that semantic structures can be conveniently translated into code and propose Code4Struct to leverage such text-to-structure translation capability to tackle structured prediction tasks. As a case study, we formulate Event Argument Extraction (EAE) as converting text into event-argument structures that can be represented as a class object using code. This alignment between structures and code enables us to take advantage of Programming Language (PL) features such as inheritance and type annotation to introduce external knowledge or add constraints. We show that, with sufficient in-context examples, formulating EAE as a code generation problem is advantageous over using variants of text-based prompts. Despite only using 20 training event instances for each event type, Code4Struct is comparable to supervised models t",
    "link": "http://arxiv.org/abs/2210.12810",
    "context": "Title: Code4Struct: Code Generation for Few-Shot Event Structure Prediction. (arXiv:2210.12810v2 [cs.CL] UPDATED)\nAbstract: Large Language Model (LLM) trained on a mixture of text and code has demonstrated impressive capability in translating natural language (NL) into structured code. We observe that semantic structures can be conveniently translated into code and propose Code4Struct to leverage such text-to-structure translation capability to tackle structured prediction tasks. As a case study, we formulate Event Argument Extraction (EAE) as converting text into event-argument structures that can be represented as a class object using code. This alignment between structures and code enables us to take advantage of Programming Language (PL) features such as inheritance and type annotation to introduce external knowledge or add constraints. We show that, with sufficient in-context examples, formulating EAE as a code generation problem is advantageous over using variants of text-based prompts. Despite only using 20 training event instances for each event type, Code4Struct is comparable to supervised models t",
    "path": "papers/22/10/2210.12810.json",
    "total_tokens": 998,
    "translated_abstract": "混合文本和代码训练的大型语言模型(LLM)展示了在将自然语言(NL)转换为结构化代码方面的出色能力。我们观察到语义结构可以方便地转换为代码，并提出了Code4Struct来利用这种文本到结构的转换能力来解决结构化预测任务。作为案例研究，我们将事件论元抽取(EAE)阐述为将文本转换为可用代码表示为类对象的事件-论元结构。这种结构与代码之间的对齐使我们能够利用编程语言(PL)功能，如继承和类型注释，以引入外部知识或添加约束。我们证明了，在足够的上下文示例下，将EAE阐述为代码生成问题优于使用基于文本的提示的变体。尽管每种事件类型仅使用20个训练事件实例，但Code4Struct与监督模型相当。",
    "tldr": "Code4Struct是一种面向Few-Shot事件结构预测的代码生成方法，利用混合文本和代码训练的大型语言模型，将事件论元抽取问题阐述为将文本转换为可用代码表示为类对象的事件-论元结构。Code4Struct通过对齐结构和代码并利用编程语言(PL)功能解决结构化预测任务，证明当存在足够的上下文示例时，将问题阐述为代码生成问题比使用基于文本的提示变体更优。",
    "en_tdlr": "Code4Struct is a code generation method for Few-Shot event structure prediction, which uses a large language model trained on a mixture of text and code to convert event arguments extracted from text into class objects represented in code. The alignment between the structures and the code allows for the utilization of programming language features, such as inheritance and type annotation, to introduce external knowledge or add constraints for structured prediction tasks. Code4Struct is proved to be advantageous over using text-based prompts when sufficient in-context examples exist, even with only 20 training event instances for each event type."
}