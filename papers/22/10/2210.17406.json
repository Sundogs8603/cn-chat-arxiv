{
    "title": "Emergent Linguistic Structures in Neural Networks are Fragile. (arXiv:2210.17406v7 [cs.LG] UPDATED)",
    "abstract": "Large Language Models (LLMs) have been reported to have strong performance on natural language processing tasks. However, performance metrics such as accuracy do not measure the quality of the model in terms of its ability to robustly represent complex linguistic structure. In this paper, focusing on the ability of language models to represent syntax, we propose a framework to assess the consistency and robustness of linguistic representations. To this end, we introduce measures of robustness of neural network models that leverage recent advances in extracting linguistic constructs from LLMs via probing tasks, i.e., simple tasks used to extract meaningful information about a single facet of a language model, such as syntax reconstruction and root identification. Empirically, we study the performance of four LLMs across six different corpora on the proposed robustness measures by analysing their performance and robustness with respect to syntax-preserving perturbations. We provide evide",
    "link": "http://arxiv.org/abs/2210.17406",
    "context": "Title: Emergent Linguistic Structures in Neural Networks are Fragile. (arXiv:2210.17406v7 [cs.LG] UPDATED)\nAbstract: Large Language Models (LLMs) have been reported to have strong performance on natural language processing tasks. However, performance metrics such as accuracy do not measure the quality of the model in terms of its ability to robustly represent complex linguistic structure. In this paper, focusing on the ability of language models to represent syntax, we propose a framework to assess the consistency and robustness of linguistic representations. To this end, we introduce measures of robustness of neural network models that leverage recent advances in extracting linguistic constructs from LLMs via probing tasks, i.e., simple tasks used to extract meaningful information about a single facet of a language model, such as syntax reconstruction and root identification. Empirically, we study the performance of four LLMs across six different corpora on the proposed robustness measures by analysing their performance and robustness with respect to syntax-preserving perturbations. We provide evide",
    "path": "papers/22/10/2210.17406.json",
    "total_tokens": 834,
    "translated_title": "神经网络中的 emergent 语言结构是脆弱的",
    "translated_abstract": "大型语言模型（LLM）在自然语言处理任务中表现强劲。然而，准确度等性能指标并不能衡量模型在代表复杂语言结构方面的质量。本文针对语言模型代表语法的能力，提出了一个评估语言表述的一致性和稳健性的框架。为此，我们介绍了一些稳健性的神经网络模型度量方式，这些度量方式利用最近在通过探测任务从LLM中提取语言结构的先进技术，即用于从语言模型中提取有意义信息的简单任务，如语法重构和根识别。实证上，我们通过分析四种LLM在六个不同的语料库上对语法保持扰动的性能和稳健性来研究所提出的稳健度量方式的表现。我们提供了证据",
    "tldr": "本文提出了一个框架来评估语言模型对于语法的表述的一致性和稳健性，通过多项实验证据表明，神经网络中 emergent 语言结构是脆弱的。",
    "en_tdlr": "This paper proposes a framework to assess the consistency and robustness of language model representations of syntax, and provides empirical evidence that emergent linguistic structures in neural networks are fragile."
}