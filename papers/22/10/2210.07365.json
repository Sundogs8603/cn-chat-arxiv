{
    "title": "Is It Worth the (Environmental) Cost? Limited Evidence for Temporal Adaptation via Continuous Training. (arXiv:2210.07365v2 [cs.CL] UPDATED)",
    "abstract": "Language is constantly changing and evolving, leaving language models to become quickly outdated. Consequently, we should continuously update our models with new data to expose them to new events and facts. However, that requires additional computing, which means new carbon emissions. Do any measurable benefits justify this cost? This paper looks for empirical evidence to support continuous training. We reproduce existing benchmarks and extend them to include additional time periods, models, and tasks. Our results show that the downstream task performance of temporally adapted English models for social media data do not improve over time. Pretrained models without temporal adaptation are actually significantly more effective and efficient. However, we also note a lack of suitable temporal benchmarks. Our findings invite a critical reflection on when and how to temporally adapt language models, accounting for sustainability.",
    "link": "http://arxiv.org/abs/2210.07365",
    "context": "Title: Is It Worth the (Environmental) Cost? Limited Evidence for Temporal Adaptation via Continuous Training. (arXiv:2210.07365v2 [cs.CL] UPDATED)\nAbstract: Language is constantly changing and evolving, leaving language models to become quickly outdated. Consequently, we should continuously update our models with new data to expose them to new events and facts. However, that requires additional computing, which means new carbon emissions. Do any measurable benefits justify this cost? This paper looks for empirical evidence to support continuous training. We reproduce existing benchmarks and extend them to include additional time periods, models, and tasks. Our results show that the downstream task performance of temporally adapted English models for social media data do not improve over time. Pretrained models without temporal adaptation are actually significantly more effective and efficient. However, we also note a lack of suitable temporal benchmarks. Our findings invite a critical reflection on when and how to temporally adapt language models, accounting for sustainability.",
    "path": "papers/22/10/2210.07365.json",
    "total_tokens": 886,
    "translated_title": "以环境成本为代价进行持续训练是否值得？对于时间适应性的证据不足。",
    "translated_abstract": "语言不断变化和演变，从而导致语言模型很快过时。因此，我们应该通过新数据不断更新我们的模型，使其暴露于新的事件和事实中。然而，这需要额外的计算，也就意味着新的碳排放。有没有可衡量的效益可以证明这个成本是合理的呢？本文寻找实证证据来支持持续训练。我们重现了现有的基准测试，并扩展了它们，包括额外的时间段、模型和任务。我们的结果表明，针对社交媒体数据的英语模型经过时间调整后的下游任务性能不会随时间改善。没有经过时间调整的预训练模型实际上更加有效和高效。然而，我们也注意到缺乏合适的时间基准。我们的研究结果促使人们对何时以及如何适应语言模型在可持续性方面进行批判性的反思。",
    "tldr": "本研究发现，在社交媒体数据的下游任务中，经过时间调整的英语模型性能并不会随时间改善，而没有经过时间调整的预训练模型实际上更加有效和高效。",
    "en_tdlr": "This research finds that temporal adaptation of English language models for social media data does not lead to improved downstream task performance over time, and pretrained models without temporal adaptation are actually more effective and efficient. The study invites reflection on when and how to adapt language models temporally while accounting for sustainability."
}