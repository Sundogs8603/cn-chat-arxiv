{
    "title": "Mitigating spectral bias for the multiscale operator learning with hierarchical attention. (arXiv:2210.10890v2 [cs.LG] UPDATED)",
    "abstract": "Neural operators have emerged as a powerful tool for learning the mapping between infinite-dimensional parameter and solution spaces of partial differential equations (PDEs). In this work, we focus on multiscale PDEs that have important applications such as reservoir modeling and turbulence prediction. We demonstrate that for such PDEs, the spectral bias towards low-frequency components presents a significant challenge for existing neural operators. To address this challenge, we propose a hierarchical attention neural operator (HANO) inspired by the hierarchical matrix approach. HANO features a scale-adaptive interaction range and self-attentions over a hierarchy of levels, enabling nested feature computation with controllable linear cost and encoding/decoding of multiscale solution space. We also incorporate an empirical $H^1$ loss function to enhance the learning of high-frequency components. Our numerical experiments demonstrate that HANO outperforms state-of-the-art (SOTA) methods ",
    "link": "http://arxiv.org/abs/2210.10890",
    "context": "Title: Mitigating spectral bias for the multiscale operator learning with hierarchical attention. (arXiv:2210.10890v2 [cs.LG] UPDATED)\nAbstract: Neural operators have emerged as a powerful tool for learning the mapping between infinite-dimensional parameter and solution spaces of partial differential equations (PDEs). In this work, we focus on multiscale PDEs that have important applications such as reservoir modeling and turbulence prediction. We demonstrate that for such PDEs, the spectral bias towards low-frequency components presents a significant challenge for existing neural operators. To address this challenge, we propose a hierarchical attention neural operator (HANO) inspired by the hierarchical matrix approach. HANO features a scale-adaptive interaction range and self-attentions over a hierarchy of levels, enabling nested feature computation with controllable linear cost and encoding/decoding of multiscale solution space. We also incorporate an empirical $H^1$ loss function to enhance the learning of high-frequency components. Our numerical experiments demonstrate that HANO outperforms state-of-the-art (SOTA) methods ",
    "path": "papers/22/10/2210.10890.json",
    "total_tokens": 872,
    "translated_title": "缓解分层注意力多尺度算子学习中的光谱偏差问题",
    "translated_abstract": "神经算子已经成为学习偏微分方程（PDE）的无限维参数和解空间之间映射的强大工具。本文关注于具有重要应用的多尺度PDE，如油藏建模和湍流预测。我们证明对于这种PDE，对低频分量存在光谱偏差是现有神经算子的一大挑战。为了解决这个挑战，我们提出了一种受层次矩阵方法启发的分层注意力神经算子（HANO）。HANO具有自适应尺度交互范围和层次结构上的自注意力机制，能够实现可控线性成本的嵌套特征计算和多尺度解空间的编码/解码。我们还采用经验H^1损失函数来增强对高频分量的学习。我们的数值实验表明，HANO优于现有的最先进方法（SOTA）。",
    "tldr": "本文提出了一种分层注意力神经算子（HANO），用于解决多尺度偏微分方程学习中存在的光谱偏差问题，并通过数值实验证明其优于现有方法。"
}