{
    "title": "Enhancing Interpretability and Interactivity in Robot Manipulation: A Neurosymbolic Approach. (arXiv:2210.00858v3 [cs.RO] UPDATED)",
    "abstract": "In this paper we present a neurosymbolic architecture for coupling language-guided visual reasoning with robot manipulation. A non-expert human user can prompt the robot using unconstrained natural language, providing a referring expression (REF), a question (VQA), or a grasp action instruction. The system tackles all cases in a task-agnostic fashion through the utilization of a shared library of primitive skills. Each primitive handles an independent sub-task, such as reasoning about visual attributes, spatial relation comprehension, logic and enumeration, as well as arm control. A language parser maps the input query to an executable program composed of such primitives, depending on the context. While some primitives are purely symbolic operations (e.g. counting), others are trainable neural functions (e.g. visual grounding), therefore marrying the interpretability and systematic generalization benefits of discrete symbolic approaches with the scalability and representational power o",
    "link": "http://arxiv.org/abs/2210.00858",
    "context": "Title: Enhancing Interpretability and Interactivity in Robot Manipulation: A Neurosymbolic Approach. (arXiv:2210.00858v3 [cs.RO] UPDATED)\nAbstract: In this paper we present a neurosymbolic architecture for coupling language-guided visual reasoning with robot manipulation. A non-expert human user can prompt the robot using unconstrained natural language, providing a referring expression (REF), a question (VQA), or a grasp action instruction. The system tackles all cases in a task-agnostic fashion through the utilization of a shared library of primitive skills. Each primitive handles an independent sub-task, such as reasoning about visual attributes, spatial relation comprehension, logic and enumeration, as well as arm control. A language parser maps the input query to an executable program composed of such primitives, depending on the context. While some primitives are purely symbolic operations (e.g. counting), others are trainable neural functions (e.g. visual grounding), therefore marrying the interpretability and systematic generalization benefits of discrete symbolic approaches with the scalability and representational power o",
    "path": "papers/22/10/2210.00858.json",
    "total_tokens": 939,
    "translated_title": "增强机器人操作的可解释性和互动性：一种神经符号方法",
    "translated_abstract": "本文提出了一种神经符号架构，用于将语言引导的视觉推理与机器人操作相结合。非专业人士可以使用自然语言引导机器人，提供指代表达式（REF）、问题（VQA）或抓握动作指令。该系统通过利用共享的原始技能库以任务无关的方式解决所有情况。每个原始技能都处理一个独立的子任务，例如推理视觉属性、空间关系理解、逻辑和枚举以及手臂控制。语言解析器将输入查询映射到由这些原语组成的可执行程序上，具体取决于上下文。尽管有些原语是纯符号操作（例如计数），但另一些是可训练的神经函数（例如视觉接地），因此融合了离散符号方法的可解释性和系统化泛化优势与可扩展性和再现性的代表性权力。",
    "tldr": "本文介绍了一种机器人操作的神经符号架构，可以通过自然语言指引机器人完成各种任务，利用共享的原始技能库以任务无关的方式解决所有情况。这将离散符号方法的可解释性和系统化泛化优势与可扩展性和代表性权力相结合。",
    "en_tdlr": "This paper presents a neurosymbolic architecture for coupling language-guided visual reasoning with robot manipulation. The system uses a shared library of primitive skills to address all cases in a task-agnostic fashion. The approach marries the interpretability and systematic generalization benefits of discrete symbolic approaches with the scalability and representational power of trainable neural functions."
}