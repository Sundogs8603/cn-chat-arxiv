{
    "title": "Are Sample-Efficient NLP Models More Robust?. (arXiv:2210.06456v2 [cs.CL] UPDATED)",
    "abstract": "Recent results in image classification and extractive question answering have observed that pre-trained models trained on less in-distribution data have better out-of-distribution performance. However, it is unclear how broadly these trends hold. We conduct a large empirical study across three tasks, three broadly-applicable modeling interventions (increasing model size, using a different adaptation method, and pre-training on more data), and 14 diverse datasets to investigate the relationship between sample efficiency (amount of data needed to reach a given ID accuracy) and robustness (how models fare on OOD evaluation). We find that higher sample efficiency is only correlated with better average OOD robustness on some modeling interventions and tasks, but not others. On individual datasets, models with lower sample efficiency can even be more robust. These results suggest that general-purpose methods for improving sample efficiency are unlikely to yield universal OOD robustness impro",
    "link": "http://arxiv.org/abs/2210.06456",
    "context": "Title: Are Sample-Efficient NLP Models More Robust?. (arXiv:2210.06456v2 [cs.CL] UPDATED)\nAbstract: Recent results in image classification and extractive question answering have observed that pre-trained models trained on less in-distribution data have better out-of-distribution performance. However, it is unclear how broadly these trends hold. We conduct a large empirical study across three tasks, three broadly-applicable modeling interventions (increasing model size, using a different adaptation method, and pre-training on more data), and 14 diverse datasets to investigate the relationship between sample efficiency (amount of data needed to reach a given ID accuracy) and robustness (how models fare on OOD evaluation). We find that higher sample efficiency is only correlated with better average OOD robustness on some modeling interventions and tasks, but not others. On individual datasets, models with lower sample efficiency can even be more robust. These results suggest that general-purpose methods for improving sample efficiency are unlikely to yield universal OOD robustness impro",
    "path": "papers/22/10/2210.06456.json",
    "total_tokens": 915,
    "translated_title": "采样效率更高的NLP模型更加鲁棒吗？",
    "translated_abstract": "最近在图像分类和抽取式问答中的研究表明，预训练模型在更少的内部数据上训练可以获得更好的外部评测性能。然而，这些趋势的普适性还不清楚。在三个任务、三个广泛适用的建模干预（增加模型大小、使用不同的适应方法和在更多数据上进行预训练）和14个不同数据集上，我们进行了大规模的实证研究，以研究样本效率（达到给定ID准确度所需的数据量）和鲁棒性（模型在OOD评估中的表现）之间的关系。我们发现，较高的样本效率仅在某些建模干预和任务上与更好的平均OOD鲁棒性相关，而在其他情况下则不然。在个别数据集上，样本效率较低的模型甚至更为健壮。这些结果表明，提高样本效率的通用方法不太可能改善自然语言处理中的普遍OOD鲁棒性。",
    "tldr": "较低采样效率的NLP模型在特定情况下可能比较高采样效率的模型更为鲁棒，表明通用的提高采样效率方法不太可能改善自然语言处理中的OOD鲁棒性。",
    "en_tdlr": "Lower sample-efficient NLP models may be more robust in specific situations than higher sample-efficient models, suggesting that general methods for improving sample efficiency are unlikely to yield universal OOD robustness improvement in natural language processing."
}