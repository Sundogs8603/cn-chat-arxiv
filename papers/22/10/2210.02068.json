{
    "title": "Nonparametric Decoding for Generative Retrieval. (arXiv:2210.02068v3 [cs.IR] UPDATED)",
    "abstract": "The generative retrieval model depends solely on the information encoded in its model parameters without external memory, its information capacity is limited and fixed. To overcome the limitation, we propose Nonparametric Decoding (Np Decoding) which can be applied to existing generative retrieval models. Np Decoding uses nonparametric contextualized vocab embeddings (external memory) rather than vanilla vocab embeddings as decoder vocab embeddings. By leveraging the contextualized vocab embeddings, the generative retrieval model is able to utilize both the parametric and nonparametric space. Evaluation over 9 datasets (8 single-hop and 1 multi-hop) in the document retrieval task shows that applying Np Decoding to generative retrieval models significantly improves the performance. We also show that Np Decoding is dataand parameter-efficient, and shows high performance in the zero-shot setting.",
    "link": "http://arxiv.org/abs/2210.02068",
    "context": "Title: Nonparametric Decoding for Generative Retrieval. (arXiv:2210.02068v3 [cs.IR] UPDATED)\nAbstract: The generative retrieval model depends solely on the information encoded in its model parameters without external memory, its information capacity is limited and fixed. To overcome the limitation, we propose Nonparametric Decoding (Np Decoding) which can be applied to existing generative retrieval models. Np Decoding uses nonparametric contextualized vocab embeddings (external memory) rather than vanilla vocab embeddings as decoder vocab embeddings. By leveraging the contextualized vocab embeddings, the generative retrieval model is able to utilize both the parametric and nonparametric space. Evaluation over 9 datasets (8 single-hop and 1 multi-hop) in the document retrieval task shows that applying Np Decoding to generative retrieval models significantly improves the performance. We also show that Np Decoding is dataand parameter-efficient, and shows high performance in the zero-shot setting.",
    "path": "papers/22/10/2210.02068.json",
    "total_tokens": 848,
    "translated_title": "生成式检索的非参数化解码方法",
    "translated_abstract": "生成式检索模型仅依赖于其模型参数中编码的信息，没有外部存储器，其信息容量受到限制并且是固定的。为了克服这一限制，我们提出了一种非参数化解码方法（Np Decoding），可以应用于现有的生成式检索模型中。Np Decoding使用非参数化的上下文化词汇嵌入（外部存储器），而不是作为解码器词汇嵌入的常规词汇嵌入。通过利用上下文化词汇嵌入，生成式检索模型能够同时利用参数空间和非参数空间。在9个数据集（8个单跳和1个多跳）的文档检索任务中的评估表明，将Np Decoding应用于生成式检索模型可以显著提高性能。我们还表明，Np Decoding具有数据和参数效率，并在零样本设置中表现出高性能。",
    "tldr": "本文提出了一种非参数化解码方法，通过利用上下文化词汇嵌入，解决了生成式检索模型信息容量受限的问题，在文档检索任务中具有高效性和高性能。",
    "en_tdlr": "This paper proposes a non-parametric decoding method, which utilizes contextualized embeddings to overcome the limited information capacity of generative retrieval models without external memory. Applying this method significantly improves the performance in document retrieval task while showing high efficiency and effectiveness in data and parameter usage as well as zero-shot setting."
}