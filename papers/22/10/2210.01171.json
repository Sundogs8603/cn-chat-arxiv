{
    "title": "TPGNN: Learning High-order Information in Dynamic Graphs via Temporal Propagation. (arXiv:2210.01171v2 [cs.LG] UPDATED)",
    "abstract": "Temporal graph is an abstraction for modeling dynamic systems that consist of evolving interaction elements. In this paper, we aim to solve an important yet neglected problem -- how to learn information from high-order neighbors in temporal graphs? -- to enhance the informativeness and discriminativeness for the learned node representations. We argue that when learning high-order information from temporal graphs, we encounter two challenges, i.e., computational inefficiency and over-smoothing, that cannot be solved by conventional techniques applied on static graphs. To remedy these deficiencies, we propose a temporal propagation-based graph neural network, namely TPGNN. To be specific, the model consists of two distinct components, i.e., propagator and node-wise encoder. The propagator is leveraged to propagate messages from the anchor node to its temporal neighbors within $k$-hop, and then simultaneously update the state of neighborhoods, which enables efficient computation, especial",
    "link": "http://arxiv.org/abs/2210.01171",
    "context": "Title: TPGNN: Learning High-order Information in Dynamic Graphs via Temporal Propagation. (arXiv:2210.01171v2 [cs.LG] UPDATED)\nAbstract: Temporal graph is an abstraction for modeling dynamic systems that consist of evolving interaction elements. In this paper, we aim to solve an important yet neglected problem -- how to learn information from high-order neighbors in temporal graphs? -- to enhance the informativeness and discriminativeness for the learned node representations. We argue that when learning high-order information from temporal graphs, we encounter two challenges, i.e., computational inefficiency and over-smoothing, that cannot be solved by conventional techniques applied on static graphs. To remedy these deficiencies, we propose a temporal propagation-based graph neural network, namely TPGNN. To be specific, the model consists of two distinct components, i.e., propagator and node-wise encoder. The propagator is leveraged to propagate messages from the anchor node to its temporal neighbors within $k$-hop, and then simultaneously update the state of neighborhoods, which enables efficient computation, especial",
    "path": "papers/22/10/2210.01171.json",
    "total_tokens": 1026,
    "translated_title": "TPGNN: 通过时间传播学习动态图中的高阶信息",
    "translated_abstract": "时间图是用于建模由演化互动要素组成的动态系统的抽象概念。本文旨在解决一个被忽视的重要问题——如何从时间图中学习高阶邻居的信息，以增强所学节点表示的信息量和区分度？我们认为，在学习动态图中的高阶信息时，我们会遇到两个挑战：计算效率低和过度平滑，这些问题无法通过应用静态图上的传统技术来解决。为了弥补这些缺陷，我们提出了一种基于时间传播的图卷积神经网络，即TPGNN。具体而言，该模型由两个不同的部分组成，即传播器和节点编码器。传播器是用于将消息从锚节点传播到其$k$步时间邻居的工具，然后同时更新邻域状态，从而实现高效的计算，特别是当$k$很大时。节点编码器旨在编码锚节点及其$k$步邻居的信息，并生成最终的节点嵌入。我们将TPGNN应用于一组真实世界的动态网络上的节点分类和链接预测任务中，并且实验结果表明，TPGNN明显优于现有的一些方法。",
    "tldr": "TPGNN 是一种基于时间传播的图卷积神经网络，用于学习动态图中的高阶信息。对节点分类和链接预测任务上的实验表明，TPGNN明显优于现有方法。"
}