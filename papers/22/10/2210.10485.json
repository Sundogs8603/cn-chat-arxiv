{
    "title": "Learning Transferable Adversarial Robust Representations via Multi-view Consistency. (arXiv:2210.10485v2 [cs.LG] UPDATED)",
    "abstract": "Despite the success on few-shot learning problems, most meta-learned models only focus on achieving good performance on clean examples and thus easily break down when given adversarially perturbed samples. While some recent works have shown that a combination of adversarial learning and meta-learning could enhance the robustness of a meta-learner against adversarial attacks, they fail to achieve generalizable adversarial robustness to unseen domains and tasks, which is the ultimate goal of meta-learning. To address this challenge, we propose a novel meta-adversarial multi-view representation learning framework with dual encoders. Specifically, we introduce the discrepancy across the two differently augmented samples of the same data instance by first updating the encoder parameters with them and further imposing a novel label-free adversarial attack to maximize their discrepancy. Then, we maximize the consistency across the views to learn transferable robust representations across doma",
    "link": "http://arxiv.org/abs/2210.10485",
    "context": "Title: Learning Transferable Adversarial Robust Representations via Multi-view Consistency. (arXiv:2210.10485v2 [cs.LG] UPDATED)\nAbstract: Despite the success on few-shot learning problems, most meta-learned models only focus on achieving good performance on clean examples and thus easily break down when given adversarially perturbed samples. While some recent works have shown that a combination of adversarial learning and meta-learning could enhance the robustness of a meta-learner against adversarial attacks, they fail to achieve generalizable adversarial robustness to unseen domains and tasks, which is the ultimate goal of meta-learning. To address this challenge, we propose a novel meta-adversarial multi-view representation learning framework with dual encoders. Specifically, we introduce the discrepancy across the two differently augmented samples of the same data instance by first updating the encoder parameters with them and further imposing a novel label-free adversarial attack to maximize their discrepancy. Then, we maximize the consistency across the views to learn transferable robust representations across doma",
    "path": "papers/22/10/2210.10485.json",
    "total_tokens": 950,
    "translated_title": "通过多视角一致性学习可迁移的对抗鲁棒表示",
    "translated_abstract": "尽管在少样本学习问题上取得了成功，但大多数元学习模型只关注在干净样本上的良好性能，因此在面对对抗性扰动样本时容易崩溃。近期的一些工作表明，对抗学习和元学习的结合可以增强元学习器对对抗攻击的鲁棒性，但它们未能实现在未见领域和任务上的一般化对抗鲁棒性，这是元学习的最终目标。为了解决这个挑战，我们提出了一个新颖的元对抗多视角表示学习框架，该框架具有双编码器。具体而言，我们通过首先使用两个不同增强样本的数据实例之间的差异来更新编码器的参数，并进一步施加一种新颖的无标签对抗攻击来最大化它们的差异。然后，我们通过最大化视图之间的一致性来学习可迁移的鲁棒表示跨领域",
    "tldr": "本论文提出了一种新颖的元对抗多视角表示学习框架，通过差异更新编码器参数并施加对抗攻击来增强元学习器的鲁棒性。此外，通过最大化视图之间的一致性，实现在未见领域和任务上的可迁移的鲁棒表示。"
}