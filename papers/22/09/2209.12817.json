{
    "title": "Word to Sentence Visual Semantic Similarity for Caption Generation: Lessons Learned. (arXiv:2209.12817v2 [cs.CL] UPDATED)",
    "abstract": "This paper focuses on enhancing the captions generated by image-caption generation systems. We propose an approach for improving caption generation systems by choosing the most closely related output to the image rather than the most likely output produced by the model. Our model revises the language generation output beam search from a visual context perspective. We employ a visual semantic measure in a word and sentence level manner to match the proper caption to the related information in the image. The proposed approach can be applied to any caption system as a post-processing based method.",
    "link": "http://arxiv.org/abs/2209.12817",
    "context": "Title: Word to Sentence Visual Semantic Similarity for Caption Generation: Lessons Learned. (arXiv:2209.12817v2 [cs.CL] UPDATED)\nAbstract: This paper focuses on enhancing the captions generated by image-caption generation systems. We propose an approach for improving caption generation systems by choosing the most closely related output to the image rather than the most likely output produced by the model. Our model revises the language generation output beam search from a visual context perspective. We employ a visual semantic measure in a word and sentence level manner to match the proper caption to the related information in the image. The proposed approach can be applied to any caption system as a post-processing based method.",
    "path": "papers/22/09/2209.12817.json",
    "total_tokens": 622,
    "translated_title": "图像标题生成的词语与句子视觉语义相似度：经验教训",
    "translated_abstract": "本文的重点是增强图像标题生成系统生成的标题。我们提出了一种方法，通过选择与图像最相关的输出而不是模型产生的最可能输出来改进标题生成系统。我们的模型从视觉背景的角度重新调整了语言生成输出的波束搜索。我们以词语和句子级别上的视觉语义度量来匹配图像中的相关信息与合适的标题。这种方法可以作为后处理的基于方法应用于任何标题系统中。",
    "tldr": "本文提出了一种通过选择最相关的输出来改进图像标题生成系统的方法，同时采用视觉语义度量来匹配图像中的相关信息与合适的标题。"
}