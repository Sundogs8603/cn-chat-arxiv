{
    "title": "How GPT-3 responds to different publics on climate change and Black Lives Matter: A critical appraisal of equity in conversational AI. (arXiv:2209.13627v2 [cs.AI] UPDATED)",
    "abstract": "Autoregressive language models, which use deep learning to produce human-like texts, have become increasingly widespread. Such models are powering popular virtual assistants in areas like smart health, finance, and autonomous driving. While the parameters of these large language models are improving, concerns persist that these models might not work equally for all subgroups in society. Despite growing discussions of AI fairness across disciplines, there lacks systemic metrics to assess what equity means in dialogue systems and how to engage different populations in the assessment loop. Grounded in theories of deliberative democracy and science and technology studies, this paper proposes an analytical framework for unpacking the meaning of equity in human-AI dialogues. Using this framework, we conducted an auditing study to examine how GPT-3 responded to different sub-populations on crucial science and social topics: climate change and the Black Lives Matter (BLM) movement. Our corpus ",
    "link": "http://arxiv.org/abs/2209.13627",
    "context": "Title: How GPT-3 responds to different publics on climate change and Black Lives Matter: A critical appraisal of equity in conversational AI. (arXiv:2209.13627v2 [cs.AI] UPDATED)\nAbstract: Autoregressive language models, which use deep learning to produce human-like texts, have become increasingly widespread. Such models are powering popular virtual assistants in areas like smart health, finance, and autonomous driving. While the parameters of these large language models are improving, concerns persist that these models might not work equally for all subgroups in society. Despite growing discussions of AI fairness across disciplines, there lacks systemic metrics to assess what equity means in dialogue systems and how to engage different populations in the assessment loop. Grounded in theories of deliberative democracy and science and technology studies, this paper proposes an analytical framework for unpacking the meaning of equity in human-AI dialogues. Using this framework, we conducted an auditing study to examine how GPT-3 responded to different sub-populations on crucial science and social topics: climate change and the Black Lives Matter (BLM) movement. Our corpus ",
    "path": "papers/22/09/2209.13627.json",
    "total_tokens": 1254,
    "translated_title": "GPT-3 如何处理气候变化和“黑人的命也是命”等不同公众的话题：关于对话式 AI 公平性的批判性评估",
    "translated_abstract": "自回归语言模型越来越普遍，这种模型利用深度学习生成接近人类的文本。这些模型驱动着智能健康、金融和自主驾驶等领域的流行虚拟助手。虽然这些大型语言模型的参数正在改进，但人们仍然担心这些模型可能不同程度地为社会中的所有子群体提供服务。尽管跨学科的 AI 公平讨论越来越多，但缺乏系统性的指标来评估对话系统中公平的含义，以及如何让不同的人群参与评估循环。本文基于民主决策理论和科学技术研究，提出了一个分析框架来揭示人工智能和人类对话中公平性的含义。使用这一框架，我们进行了审计研究，以检查 GPT-3 如何响应关键的科学和社会话题：气候变化和“黑人的命也是命”运动。我们的语料库包括 480 次提示，其中系统地变化发言人的性别、种族和地理位置。我们的发现表明，当回应气候变化和 BLM 的提示时，GPT-3 有时会强化刻板印象，边缘化某些群体，如土著民族。我们认为必须解决这些偏见，以防止权力结构在 AI 动力服务中进一步巩固。",
    "tldr": "本论文提出了一个分析框架，以检查人工智能和人类对话中公平性的含义。作者使用这个框架进行了审计研究，发现 GPT-3 在回应气候变化和BBL运动的提示时存在不公平的行为，强化了刻板印象，边缘化了某些特定的群体。该研究表明有必要解决这些偏见，以防止AI-powered服务中进一步巩固权力结构。",
    "en_tdlr": "This paper proposes an analytical framework to unpack the meaning of equity in human-AI dialogues and conducted an auditing study to examine how GPT-3 responded to sub-populations on climate change and Black Lives Matter. The findings suggest that biases must be addressed to prevent the entrenchment of power structures in AI-powered services."
}