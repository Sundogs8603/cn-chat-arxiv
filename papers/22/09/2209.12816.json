{
    "title": "Fast-FNet: Accelerating Transformer Encoder Models via Efficient Fourier Layers. (arXiv:2209.12816v2 [cs.CL] UPDATED)",
    "abstract": "Transformer-based language models utilize the attention mechanism for substantial performance improvements in almost all natural language processing (NLP) tasks. Similar attention structures are also extensively studied in several other areas. Although the attention mechanism enhances the model performances significantly, its quadratic complexity prevents efficient processing of long sequences. Recent works focused on eliminating the disadvantages of computational inefficiency and showed that transformer-based models can still reach competitive results without the attention layer. A pioneering study proposed the FNet, which replaces the attention layer with the Fourier Transform (FT) in the transformer encoder architecture. FNet achieves competitive performances concerning the original transformer encoder model while accelerating training process by removing the computational burden of the attention mechanism. However, the FNet model ignores essential properties of the FT from the clas",
    "link": "http://arxiv.org/abs/2209.12816",
    "context": "Title: Fast-FNet: Accelerating Transformer Encoder Models via Efficient Fourier Layers. (arXiv:2209.12816v2 [cs.CL] UPDATED)\nAbstract: Transformer-based language models utilize the attention mechanism for substantial performance improvements in almost all natural language processing (NLP) tasks. Similar attention structures are also extensively studied in several other areas. Although the attention mechanism enhances the model performances significantly, its quadratic complexity prevents efficient processing of long sequences. Recent works focused on eliminating the disadvantages of computational inefficiency and showed that transformer-based models can still reach competitive results without the attention layer. A pioneering study proposed the FNet, which replaces the attention layer with the Fourier Transform (FT) in the transformer encoder architecture. FNet achieves competitive performances concerning the original transformer encoder model while accelerating training process by removing the computational burden of the attention mechanism. However, the FNet model ignores essential properties of the FT from the clas",
    "path": "papers/22/09/2209.12816.json",
    "total_tokens": 800,
    "translated_title": "快速FNet：通过高效的傅里叶层加速Transformer编码器模型",
    "translated_abstract": "基于Transformer的语言模型在几乎所有自然语言处理任务中利用注意力机制实现了显著的性能提升。相似的注意力结构也在其他领域广泛研究。虽然注意力机制显著增强了模型性能，但其二次复杂度阻碍了对长序列的高效处理。最近的研究集中在消除计算效率的缺点上，并表明在无需注意力层的情况下，基于Transformer的模型仍然能够达到竞争性的结果。一项开创性的研究提出了FNet，在Transformer编码器结构中用傅里叶变换（FT）替换注意力层。FNet在加速训练过程中去除了注意力机制的运算负担，同时实现了与原始Transformer编码器模型相当的性能。然而，FNet模型忽略了FT的基本属性..",
    "tldr": "FNet模型通过替换注意力层为傅里叶变换，加速了Transformer编码器模型的训练过程并保持相同的性能水平。",
    "en_tdlr": "The FNet model accelerates the training process and maintains the same level of performance in Transformer encoder models by replacing the attention layer with the Fourier Transform."
}