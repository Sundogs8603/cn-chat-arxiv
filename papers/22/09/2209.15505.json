{
    "title": "Momentum Tracking: Momentum Acceleration for Decentralized Deep Learning on Heterogeneous Data. (arXiv:2209.15505v2 [cs.LG] UPDATED)",
    "abstract": "SGD with momentum is one of the key components for improving the performance of neural networks. For decentralized learning, a straightforward approach using momentum is Distributed SGD (DSGD) with momentum (DSGDm). However, DSGDm performs worse than DSGD when the data distributions are statistically heterogeneous. Recently, several studies have addressed this issue and proposed methods with momentum that are more robust to data heterogeneity than DSGDm, although their convergence rates remain dependent on data heterogeneity and deteriorate when the data distributions are heterogeneous. In this study, we propose Momentum Tracking, which is a method with momentum whose convergence rate is proven to be independent of data heterogeneity. More specifically, we analyze the convergence rate of Momentum Tracking in the setting where the objective function is non-convex and the stochastic gradient is used. Then, we identify that it is independent of data heterogeneity for any momentum coeffici",
    "link": "http://arxiv.org/abs/2209.15505",
    "context": "Title: Momentum Tracking: Momentum Acceleration for Decentralized Deep Learning on Heterogeneous Data. (arXiv:2209.15505v2 [cs.LG] UPDATED)\nAbstract: SGD with momentum is one of the key components for improving the performance of neural networks. For decentralized learning, a straightforward approach using momentum is Distributed SGD (DSGD) with momentum (DSGDm). However, DSGDm performs worse than DSGD when the data distributions are statistically heterogeneous. Recently, several studies have addressed this issue and proposed methods with momentum that are more robust to data heterogeneity than DSGDm, although their convergence rates remain dependent on data heterogeneity and deteriorate when the data distributions are heterogeneous. In this study, we propose Momentum Tracking, which is a method with momentum whose convergence rate is proven to be independent of data heterogeneity. More specifically, we analyze the convergence rate of Momentum Tracking in the setting where the objective function is non-convex and the stochastic gradient is used. Then, we identify that it is independent of data heterogeneity for any momentum coeffici",
    "path": "papers/22/09/2209.15505.json",
    "total_tokens": 859,
    "translated_title": "动量追踪：异构数据上分布式深度学习中的动量加速",
    "translated_abstract": "SGD动量是提高神经网络性能的关键组成部分之一。对于分布式学习，使用动量的一种直接方法是动量分布式SGD（DSGDm）。然而，当数据分布具有统计异质性时，DSGDm的性能不如DSGD。最近，一些研究解决了这个问题，并提出了具有动量的方法，相比DSGDm更能适应数据异质性，尽管它们的收敛速度仍然依赖于数据异质性，并且当数据分布异质时会恶化。在本研究中，我们提出了一种名为动量追踪的方法，其收敛速度被证明与数据异质性无关。具体而言，我们分析了动量追踪在目标函数为非凸函数且使用随机梯度的情况下的收敛速度。然后，我们发现它对于任何动量系数都与数据异质性无关。",
    "tldr": "本研究提出了一种名为动量追踪的方法，其收敛速度与数据异质性无关，在分布式深度学习中具有应对异质数据的能力。",
    "en_tdlr": "This study proposes a method called Momentum Tracking, which has a convergence rate that is independent of data heterogeneity, and is capable of handling heterogeneous data in decentralized deep learning."
}