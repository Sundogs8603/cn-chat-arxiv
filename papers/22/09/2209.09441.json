{
    "title": "Locally Constrained Representations in Reinforcement Learning",
    "abstract": "The success of Reinforcement Learning (RL) heavily relies on the ability to learn robust representations from the observations of the environment. In most cases, the representations learned purely by the reinforcement learning loss can differ vastly across states depending on how the value functions change. However, the representations learned need not be very specific to the task at hand. Relying only on the RL objective may yield representations that vary greatly across successive time steps. In addition, since the RL loss has a changing target, the representations learned would depend on how good the current values/policies are. Thus, disentangling the representations from the main task would allow them to focus not only on the task-specific features but also the environment dynamics. To this end, we propose locally constrained representations, where an auxiliary loss forces the state representations to be predictable by the representations of the neighboring states. This encourages",
    "link": "https://arxiv.org/abs/2209.09441",
    "context": "Title: Locally Constrained Representations in Reinforcement Learning\nAbstract: The success of Reinforcement Learning (RL) heavily relies on the ability to learn robust representations from the observations of the environment. In most cases, the representations learned purely by the reinforcement learning loss can differ vastly across states depending on how the value functions change. However, the representations learned need not be very specific to the task at hand. Relying only on the RL objective may yield representations that vary greatly across successive time steps. In addition, since the RL loss has a changing target, the representations learned would depend on how good the current values/policies are. Thus, disentangling the representations from the main task would allow them to focus not only on the task-specific features but also the environment dynamics. To this end, we propose locally constrained representations, where an auxiliary loss forces the state representations to be predictable by the representations of the neighboring states. This encourages",
    "path": "papers/22/09/2209.09441.json",
    "total_tokens": 857,
    "translated_title": "强化学习中的局部约束表示",
    "translated_abstract": "强化学习的成功很大程度上依赖于从环境观测数据中学习到稳健的表示。在大多数情况下，纯粹通过强化学习损失函数学习到的表示在不同状态下可能差异巨大，这取决于值函数的变化。然而，学习到的表示并不一定需要与当前任务非常相关。仅依赖强化学习目标可能会导致表示在连续的时间步长中差异很大。此外，由于强化学习损失函数有一个变化的目标，学习到的表示将取决于当前值/策略的好坏。因此，将表示与主要任务解耦可以使其不仅关注于任务特定特征，还关注环境动态特征。为此，我们提出了局部约束表示，其中辅助损失函数迫使状态表示能够由相邻状态的表示进行预测。这鼓励表示更好地捕捉到环境的局部变化。",
    "tldr": "本论文提出了一种在强化学习中使用局部约束表示的方法，通过辅助损失函数迫使状态表示与相邻状态的表示具有一定的可预测性，以更好地捕捉到环境的局部变化情况。",
    "en_tdlr": "This paper proposes a method of using locally constrained representations in reinforcement learning, where an auxiliary loss function is used to encourage the predictability between state representations and neighboring state representations, in order to better capture the local changes in the environment."
}