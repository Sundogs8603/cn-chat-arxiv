{
    "title": "Value Summation: A Novel Scoring Function for MPC-based Model-based Reinforcement Learning. (arXiv:2209.08169v2 [cs.LG] UPDATED)",
    "abstract": "This paper proposes a novel scoring function for the planning module of MPC-based reinforcement learning methods to address the inherent bias of using the reward function to score trajectories. The proposed method enhances the learning efficiency of existing MPC-based MBRL methods using the discounted sum of values. The method utilizes optimal trajectories to guide policy learning and updates its state-action value function based on real-world and augmented onboard data. The learning efficiency of the proposed method is evaluated in selected MuJoCo Gym environments as well as in learning locomotion skills for a simulated model of the Cassie robot. The results demonstrate that the proposed method outperforms the current state-of-the-art algorithms in terms of learning efficiency and average reward return.",
    "link": "http://arxiv.org/abs/2209.08169",
    "context": "Title: Value Summation: A Novel Scoring Function for MPC-based Model-based Reinforcement Learning. (arXiv:2209.08169v2 [cs.LG] UPDATED)\nAbstract: This paper proposes a novel scoring function for the planning module of MPC-based reinforcement learning methods to address the inherent bias of using the reward function to score trajectories. The proposed method enhances the learning efficiency of existing MPC-based MBRL methods using the discounted sum of values. The method utilizes optimal trajectories to guide policy learning and updates its state-action value function based on real-world and augmented onboard data. The learning efficiency of the proposed method is evaluated in selected MuJoCo Gym environments as well as in learning locomotion skills for a simulated model of the Cassie robot. The results demonstrate that the proposed method outperforms the current state-of-the-art algorithms in terms of learning efficiency and average reward return.",
    "path": "papers/22/09/2209.08169.json",
    "total_tokens": 799,
    "translated_title": "基于MPC的模型导向强化学习的新型评分函数：价值求和",
    "translated_abstract": "本文提出了一种用于MPC-based强化学习方法规划模块的新型评分函数，以解决使用奖励函数来评分轨迹时的固有偏差。该方法利用价值的折扣和求和来提高现有MPC-based MBRL方法的学习效率。该方法利用最优轨迹来指导策略学习，并根据实际世界和增强型板载数据更新其状态-动作值函数。通过在选定的MuJoCo Gym环境中评估提出的方法的学习效率，并在学习Cassie机器人模型的运动技能中进行评估，结果表明该方法在学习效率和平均奖励回报方面优于当前最先进的算法。",
    "tldr": "本文提出了一种新的评分函数，用于解决使用奖励函数评分轨迹时的偏差问题，该方法通过利用价值的折扣和求和来提高MPC-based强化学习的学习效率，并在实验中表现出优于当前最先进算法的结果。"
}