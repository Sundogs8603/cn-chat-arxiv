{
    "title": "End-to-End Label Uncertainty Modeling in Speech Emotion Recognition using Bayesian Neural Networks and Label Distribution Learning. (arXiv:2209.15449v2 [eess.AS] UPDATED)",
    "abstract": "To train machine learning algorithms to predict emotional expressions in terms of arousal and valence, annotated datasets are needed. However, as different people perceive others' emotional expressions differently, their annotations are subjective. To account for this, annotations are typically collected from multiple annotators and averaged to obtain ground-truth labels. However, when exclusively trained on this averaged ground-truth, the model is agnostic to the inherent subjectivity in emotional expressions. In this work, we therefore propose an end-to-end Bayesian neural network capable of being trained on a distribution of annotations to also capture the subjectivity-based label uncertainty. Instead of a Gaussian, we model the annotation distribution using Student's t-distribution, which also accounts for the number of annotations available. We derive the corresponding Kullback-Leibler divergence loss and use it to train an estimator for the annotation distribution, from which the",
    "link": "http://arxiv.org/abs/2209.15449",
    "context": "Title: End-to-End Label Uncertainty Modeling in Speech Emotion Recognition using Bayesian Neural Networks and Label Distribution Learning. (arXiv:2209.15449v2 [eess.AS] UPDATED)\nAbstract: To train machine learning algorithms to predict emotional expressions in terms of arousal and valence, annotated datasets are needed. However, as different people perceive others' emotional expressions differently, their annotations are subjective. To account for this, annotations are typically collected from multiple annotators and averaged to obtain ground-truth labels. However, when exclusively trained on this averaged ground-truth, the model is agnostic to the inherent subjectivity in emotional expressions. In this work, we therefore propose an end-to-end Bayesian neural network capable of being trained on a distribution of annotations to also capture the subjectivity-based label uncertainty. Instead of a Gaussian, we model the annotation distribution using Student's t-distribution, which also accounts for the number of annotations available. We derive the corresponding Kullback-Leibler divergence loss and use it to train an estimator for the annotation distribution, from which the",
    "path": "papers/22/09/2209.15449.json",
    "total_tokens": 934,
    "translated_title": "使用贝叶斯神经网络和标签分布学习的语音情感识别中的端到端标签不确定性建模",
    "translated_abstract": "训练机器学习算法以预测情绪表达方面的唤醒度和价值时，需要有注释数据集。然而，由于不同的人以不同的方式感知他人的情感表达，他们的注释是主观的。为了考虑这一点，通常从多个注释者收集注释，并对其进行平均以获得地面真实标签。然而，当仅在这个平均地面真实标签上进行训练时，模型对情感表达中固有的主观性是不可知的。因此，在这项工作中，我们提出了一种端到端的贝叶斯神经网络，能够在注释分布上进行训练，以捕捉基于主观性的标签不确定性。我们使用学生t分布来模拟注释分布，而不是高斯分布，这也考虑到了可用注释数量。我们推导相应的KL散度损失，并使用它来训练注释分布的估计器，从中获得预测结果。",
    "tldr": "本文提出了一种端到端的贝叶斯神经网络，使用学生t分布来模拟注释分布，并通过推导相应的KL散度损失进行训练，以捕捉情感识别中基于主观性的标签不确定性。",
    "en_tdlr": "This paper proposes an end-to-end Bayesian neural network that models annotation distribution using Student's t-distribution, and trains the estimator for the annotation distribution using the corresponding Kullback-Leibler divergence loss, in order to capture label uncertainty that is based on subjectivity in speech emotion recognition."
}