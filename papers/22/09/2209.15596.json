{
    "title": "Individual Privacy Accounting with Gaussian Differential Privacy. (arXiv:2209.15596v2 [cs.CR] UPDATED)",
    "abstract": "Individual privacy accounting enables bounding differential privacy (DP) loss individually for each participant involved in the analysis. This can be informative as often the individual privacy losses are considerably smaller than those indicated by the DP bounds that are based on considering worst-case bounds at each data access. In order to account for the individual privacy losses in a principled manner, we need a privacy accountant for adaptive compositions of randomised mechanisms, where the loss incurred at a given data access is allowed to be smaller than the worst-case loss. This kind of analysis has been carried out for the R\\'enyi differential privacy (RDP) by Feldman and Zrnic (2021), however not yet for the so-called optimal privacy accountants. We make first steps in this direction by providing a careful analysis using the Gaussian differential privacy which gives optimal bounds for the Gaussian mechanism, one of the most versatile DP mechanisms. This approach is based on ",
    "link": "http://arxiv.org/abs/2209.15596",
    "context": "Title: Individual Privacy Accounting with Gaussian Differential Privacy. (arXiv:2209.15596v2 [cs.CR] UPDATED)\nAbstract: Individual privacy accounting enables bounding differential privacy (DP) loss individually for each participant involved in the analysis. This can be informative as often the individual privacy losses are considerably smaller than those indicated by the DP bounds that are based on considering worst-case bounds at each data access. In order to account for the individual privacy losses in a principled manner, we need a privacy accountant for adaptive compositions of randomised mechanisms, where the loss incurred at a given data access is allowed to be smaller than the worst-case loss. This kind of analysis has been carried out for the R\\'enyi differential privacy (RDP) by Feldman and Zrnic (2021), however not yet for the so-called optimal privacy accountants. We make first steps in this direction by providing a careful analysis using the Gaussian differential privacy which gives optimal bounds for the Gaussian mechanism, one of the most versatile DP mechanisms. This approach is based on ",
    "path": "papers/22/09/2209.15596.json",
    "total_tokens": 865,
    "translated_title": "用高斯机器隐私实现个体隐私核算",
    "translated_abstract": "个体隐私核算能够为参与分析的每个参与者个别地限制差分隐私损失。这通常是有意义的，因为个体隐私损失往往比考虑每次数据访问的最坏情况边界所示的差分隐私边界要小得多。为了以有原则的方式核算个体隐私损失，我们需要一种针对自适应组合随机机制的隐私核算方法，其中在给定的数据访问中所产生的损失允许比最坏情况损失要小。费尔德曼和兹尔尼克（2021）已对Rényi差分隐私（RDP）进行了这种分析，但尚未应用于所谓的最优隐私核算方法。我们通过使用高斯差分隐私进行仔细分析，为此方向迈出了第一步，高斯差分隐私为最多功能的差分隐私机制之一提供了最优边界。这种方法基于...",
    "tldr": "本论文介绍了用于个体隐私核算的高斯差分隐私方法，通过对自适应组合随机机制进行仔细分析，为高斯机制提供了最优边界。",
    "en_tdlr": "This paper introduces the use of Gaussian differential privacy for individual privacy accounting and provides optimal bounds for the Gaussian mechanism through careful analysis of adaptive compositions of randomised mechanisms."
}