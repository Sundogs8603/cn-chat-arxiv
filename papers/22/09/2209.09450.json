{
    "title": "A Few-shot Approach to Resume Information Extraction via Prompts. (arXiv:2209.09450v2 [cs.CL] UPDATED)",
    "abstract": "Prompt learning's fine-tune performance on text classification tasks has attracted the NLP community. This paper applies it to resume information extraction, improving existing methods for this task. We created manual templates and verbalizers tailored to resume texts and compared the performance of Masked Language Model (MLM) and Seq2Seq PLMs. Also, we enhanced the verbalizer design for Knowledgeable Prompt-tuning, contributing to prompt template design across NLP tasks. We present the Manual Knowledgeable Verbalizer (MKV), a rule for constructing verbalizers for specific applications. Our tests show that MKV rules yield more effective, robust templates and verbalizers than existing methods. Our MKV approach resolved sample imbalance, surpassing current automatic prompt methods. This study underscores the value of tailored prompt learning for resume extraction, stressing the importance of custom-designed templates and verbalizers.",
    "link": "http://arxiv.org/abs/2209.09450",
    "context": "Title: A Few-shot Approach to Resume Information Extraction via Prompts. (arXiv:2209.09450v2 [cs.CL] UPDATED)\nAbstract: Prompt learning's fine-tune performance on text classification tasks has attracted the NLP community. This paper applies it to resume information extraction, improving existing methods for this task. We created manual templates and verbalizers tailored to resume texts and compared the performance of Masked Language Model (MLM) and Seq2Seq PLMs. Also, we enhanced the verbalizer design for Knowledgeable Prompt-tuning, contributing to prompt template design across NLP tasks. We present the Manual Knowledgeable Verbalizer (MKV), a rule for constructing verbalizers for specific applications. Our tests show that MKV rules yield more effective, robust templates and verbalizers than existing methods. Our MKV approach resolved sample imbalance, surpassing current automatic prompt methods. This study underscores the value of tailored prompt learning for resume extraction, stressing the importance of custom-designed templates and verbalizers.",
    "path": "papers/22/09/2209.09450.json",
    "total_tokens": 925,
    "translated_title": "基于提示的少样本简历信息提取方法",
    "translated_abstract": "在文本分类任务上，提示学习的微调性能引起了自然语言处理（NLP）社区的关注。本文将其应用于简历信息提取，并改进了现有的方法。我们创建了适用于简历文本的手动模板和语言表述，并比较了掩蔽式语言模型（MLM）和序列到序列提示语言模型（Seq2Seq PLMs）的性能。此外，我们增强了知识性提示微调（Knowledgeable Prompt-tuning）的语言表述设计，为跨NLP任务的提示模板设计做出了贡献。我们提出了“手动知识语言表述器”（MKV），用于构建特定应用程序的语言表述器的规则。我们的测试表明，MKV规则产生的模板和语言表述器比现有方法更有效和鲁棒。我们的MKV方法解决了样本失衡的问题，超越了当前自动提示方法。本研究强调了为简历提取量身定制的提示学习的价值，并强调了定制模板和语言表述器的重要性。",
    "tldr": "本文提出了一种基于提示的少样本简历信息提取方法，使用手动创建的模板和语言表述，改善了现有方法。他们的MKV方法解决了样本失衡问题，产生了更有效，更鲁棒的模板和语言表述器，为简历提取的定制提示学习方法提供了价值。",
    "en_tdlr": "This paper proposes a few-shot approach to resume information extraction via prompts, using manually created templates and verbalizers to improve existing methods. Their MKV method addresses the problem of sample imbalance and produces more effective and robust templates and verbalizers, contributing to the value of tailored prompt learning for resume extraction."
}