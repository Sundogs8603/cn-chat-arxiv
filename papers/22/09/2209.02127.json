{
    "title": "Design of the topology for contrastive visual-textual alignment. (arXiv:2209.02127v2 [cs.CV] UPDATED)",
    "abstract": "Cosine similarity is the common choice for measuring the distance between the feature representations in contrastive visual-textual alignment learning. However, empirically a learnable softmax temperature parameter is required when learning on large-scale noisy training data. In this work, we first discuss the role of softmax temperature from the embedding space's topological properties. We argue that the softmax temperature is the key mechanism for contrastive learning on noisy training data. It acts as a scaling factor of the distance range (e.g. [-1, 1] for the cosine similarity), and its learned value indicates the level of noise in the training data. Then, we propose an alternative design of the topology for the embedding alignment. We make use of multiple class tokens in the transformer architecture; then map the feature representations onto an oblique manifold endowed with the negative inner product as the distance function. With this configuration, we largely improve the zero-s",
    "link": "http://arxiv.org/abs/2209.02127",
    "context": "Title: Design of the topology for contrastive visual-textual alignment. (arXiv:2209.02127v2 [cs.CV] UPDATED)\nAbstract: Cosine similarity is the common choice for measuring the distance between the feature representations in contrastive visual-textual alignment learning. However, empirically a learnable softmax temperature parameter is required when learning on large-scale noisy training data. In this work, we first discuss the role of softmax temperature from the embedding space's topological properties. We argue that the softmax temperature is the key mechanism for contrastive learning on noisy training data. It acts as a scaling factor of the distance range (e.g. [-1, 1] for the cosine similarity), and its learned value indicates the level of noise in the training data. Then, we propose an alternative design of the topology for the embedding alignment. We make use of multiple class tokens in the transformer architecture; then map the feature representations onto an oblique manifold endowed with the negative inner product as the distance function. With this configuration, we largely improve the zero-s",
    "path": "papers/22/09/2209.02127.json",
    "total_tokens": 874,
    "translated_title": "对比视觉-文本对齐拓扑设计",
    "translated_abstract": "余弦相似度是对比视觉-文本对齐学习中测量特征表示之间距离的常见选择。然而，实验证明，在学习大规模嘈杂训练数据时，需要一个可学习的softmax温度参数。在这项工作中，我们首先讨论了softmax温度在嵌入空间拓扑属性中的作用。我们认为softmax温度是对嘈杂训练数据进行对比学习的关键机制。它作为距离范围的缩放因子（例如，余弦相似度的范围是[-1, 1]），其学到的值表明训练数据中的噪音水平。然后，我们提出了一种嵌入对齐拓扑的替代设计。我们利用Transformer架构中的多个类标记，将特征表示映射到具有负内积作为距离函数的斜面流形上。通过这种配置，我们大大提高了零-shot",
    "tldr": "对比视觉-文本对齐学习中，我们讨论了softmax温度参数的作用，并提出了一种新的嵌入对齐拓扑设计。采用这种设计可以显著提高零-shot学习的性能。",
    "en_tdlr": "In contrastive visual-textual alignment learning, we discuss the role of the softmax temperature parameter and propose a new design for embedding alignment topology. This design significantly improves the performance of zero-shot learning."
}