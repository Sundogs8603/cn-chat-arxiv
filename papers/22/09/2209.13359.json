{
    "title": "Towards Parameter-Efficient Integration of Pre-Trained Language Models In Temporal Video Grounding. (arXiv:2209.13359v2 [cs.CV] UPDATED)",
    "abstract": "This paper explores the task of Temporal Video Grounding (TVG) where, given an untrimmed video and a natural language sentence query, the goal is to recognize and determine temporal boundaries of action instances in the video described by the query. Recent works tackled this task by improving query inputs with large pre-trained language models (PLM) at the cost of more expensive training. However, the effects of this integration are unclear, as these works also propose improvements in the visual inputs. Therefore, this paper studies the effects of PLMs in TVG and assesses the applicability of parameter-efficient training with NLP adapters. We couple popular PLMs with a selection of existing approaches and test different adapters to reduce the impact of the additional parameters. Our results on three challenging datasets show that, without changing the visual inputs, TVG models greatly benefited from the PLM integration and fine-tuning, stressing the importance of sentence query represe",
    "link": "http://arxiv.org/abs/2209.13359",
    "context": "Title: Towards Parameter-Efficient Integration of Pre-Trained Language Models In Temporal Video Grounding. (arXiv:2209.13359v2 [cs.CV] UPDATED)\nAbstract: This paper explores the task of Temporal Video Grounding (TVG) where, given an untrimmed video and a natural language sentence query, the goal is to recognize and determine temporal boundaries of action instances in the video described by the query. Recent works tackled this task by improving query inputs with large pre-trained language models (PLM) at the cost of more expensive training. However, the effects of this integration are unclear, as these works also propose improvements in the visual inputs. Therefore, this paper studies the effects of PLMs in TVG and assesses the applicability of parameter-efficient training with NLP adapters. We couple popular PLMs with a selection of existing approaches and test different adapters to reduce the impact of the additional parameters. Our results on three challenging datasets show that, without changing the visual inputs, TVG models greatly benefited from the PLM integration and fine-tuning, stressing the importance of sentence query represe",
    "path": "papers/22/09/2209.13359.json",
    "total_tokens": 947,
    "translated_title": "为了更加高效地将预训练语言模型应用于视频时间对齐，本文提出了一种方法",
    "translated_abstract": "本文旨在探讨视频时间对齐（TVG）任务，即在给定未修剪视频和自然语言句子查询的情况下，识别并确定与查询描述的视频动作实例的时间边界。最近的研究通过利用较大的预训练语言模型（PLM）改进查询输入来解决这个任务，但代价是更昂贵的训练费用。然而，这种集成的效果还不清楚，因为这些研究还提出了改进视觉输入的方法。因此，本文研究了PLM在TVG中的影响，并评估了使用NLP适配器进行参数高效训练的适用性。我们将流行的PLM与现有方法的选择结合使用，并测试不同的适配器以减少额外参数的影响。我们在三个具有挑战性的数据集上的实验结果显示，不改变视觉输入的情况下，TVG模型从PLM集成和微调中受益匪浅，强调了句子查询表示的重要性。",
    "tldr": "本文探讨了如何更加高效地将预训练语言模型应用于视频时间对齐任务中，并通过将PLMs与现有方法相结合，证明了在三个具有挑战性的数据集上，TVG模型从PLM集成和微调中受益匪浅。",
    "en_tdlr": "This paper explores how to efficiently integrate pre-trained language models into the task of Temporal Video Grounding and demonstrates that TVG models greatly benefited from PLM integration and fine-tuning on three challenging datasets by coupling PLMs with existing approaches."
}