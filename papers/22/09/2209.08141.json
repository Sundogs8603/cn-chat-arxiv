{
    "title": "Psychologically-informed chain-of-thought prompts for metaphor understanding in large language models. (arXiv:2209.08141v2 [cs.CL] UPDATED)",
    "abstract": "Probabilistic models of language understanding are valuable tools for investigating human language use. However, they need to be hand-designed for a particular domain. In contrast, large language models (LLMs) are trained on text that spans a wide array of domains, but they lack the structure and interpretability of probabilistic models. In this paper, we use chain-of-thought prompts to introduce structures from probabilistic models into LLMs. We explore this approach in the case of metaphor understanding. Our chain-of-thought prompts lead language models to infer latent variables and reason about their relationships in order to choose appropriate paraphrases for metaphors. The latent variables and relationships chosen are informed by theories of metaphor understanding from cognitive psychology. We apply these prompts to the two largest versions of GPT-3 and show that they can improve performance in a paraphrase selection task.",
    "link": "http://arxiv.org/abs/2209.08141",
    "context": "Title: Psychologically-informed chain-of-thought prompts for metaphor understanding in large language models. (arXiv:2209.08141v2 [cs.CL] UPDATED)\nAbstract: Probabilistic models of language understanding are valuable tools for investigating human language use. However, they need to be hand-designed for a particular domain. In contrast, large language models (LLMs) are trained on text that spans a wide array of domains, but they lack the structure and interpretability of probabilistic models. In this paper, we use chain-of-thought prompts to introduce structures from probabilistic models into LLMs. We explore this approach in the case of metaphor understanding. Our chain-of-thought prompts lead language models to infer latent variables and reason about their relationships in order to choose appropriate paraphrases for metaphors. The latent variables and relationships chosen are informed by theories of metaphor understanding from cognitive psychology. We apply these prompts to the two largest versions of GPT-3 and show that they can improve performance in a paraphrase selection task.",
    "path": "papers/22/09/2209.08141.json",
    "total_tokens": 851,
    "translated_title": "大语言模型中用心理学启发的思维链触发识别隐含变量和推理关系进行隐喻理解",
    "translated_abstract": "语言理解的概率模型是研究人们语言使用的有价值的工具，但它们需要手动设计。相比之下，大语言模型（LLMs）是用跨领域的文本进行训练的，但它们缺乏概率模型的结构和可解释性。本文采用思维链触发方式来将概率模型中的结构引入LLMs中，以隐喻理解为例来探究这一方法。我们的思维链触发方式导致语言模型推断隐含变量，并思考它们之间的关系，以选择适当的隐喻释义。所选择的隐含变量和关系都基于认知心理学中的隐喻理解理论。我们将这些提示应用于GPT-3的两个最大版本，并显示它们可以提高释义选择任务的性能。",
    "tldr": "本文介绍了一种在大语言模型中使用心理学引导思维的方法来增强隐喻理解的性能。这种方法使用了隐含变量和关系来选择正确的释义。",
    "en_tdlr": "This paper presents a psychologically-guided approach to enhance metaphor understanding performance in large language models, using latent variables and relationships to choose the correct paraphrase. The approach is applied to the two largest versions of GPT-3 and improves performance in a paraphrase selection task."
}