{
    "title": "SATformer: Transformer-Based UNSAT Core Learning",
    "abstract": "arXiv:2209.00953v2 Announce Type: replace  Abstract: This paper introduces SATformer, a novel Transformer-based approach for the Boolean Satisfiability (SAT) problem. Rather than solving the problem directly, SATformer approaches the problem from the opposite direction by focusing on unsatisfiability. Specifically, it models clause interactions to identify any unsatisfiable sub-problems. Using a graph neural network, we convert clauses into clause embeddings and employ a hierarchical Transformer-based model to understand clause correlation. SATformer is trained through a multi-task learning approach, using the single-bit satisfiability result and the minimal unsatisfiable core (MUC) for UNSAT problems as clause supervision. As an end-to-end learning-based satisfiability classifier, the performance of SATformer surpasses that of NeuroSAT significantly. Furthermore, we integrate the clause predictions made by SATformer into modern heuristic-based SAT solvers and validate our approach wit",
    "link": "https://arxiv.org/abs/2209.00953",
    "context": "Title: SATformer: Transformer-Based UNSAT Core Learning\nAbstract: arXiv:2209.00953v2 Announce Type: replace  Abstract: This paper introduces SATformer, a novel Transformer-based approach for the Boolean Satisfiability (SAT) problem. Rather than solving the problem directly, SATformer approaches the problem from the opposite direction by focusing on unsatisfiability. Specifically, it models clause interactions to identify any unsatisfiable sub-problems. Using a graph neural network, we convert clauses into clause embeddings and employ a hierarchical Transformer-based model to understand clause correlation. SATformer is trained through a multi-task learning approach, using the single-bit satisfiability result and the minimal unsatisfiable core (MUC) for UNSAT problems as clause supervision. As an end-to-end learning-based satisfiability classifier, the performance of SATformer surpasses that of NeuroSAT significantly. Furthermore, we integrate the clause predictions made by SATformer into modern heuristic-based SAT solvers and validate our approach wit",
    "path": "papers/22/09/2209.00953.json",
    "total_tokens": 810,
    "translated_title": "SATformer: 基于Transformer的UNSAT核心学习",
    "translated_abstract": "本文介绍了SATformer，这是一种用于布尔可满足性（SAT）问题的新型基于Transformer的方法。 SATformer并非直接解决问题，而是从相反的方向入手，着重于不可满足性。具体来说，它通过模拟子句之间的相互作用来识别任何不可满足的子问题。我们利用图神经网络将子句转换为子句嵌入，并采用分层Transformer模型来理解子句之间的相关性。 SATformer通过多任务学习方法进行训练，使用单比特可满足性结果以及最小不可满足核心（MUC）作为子句监督来处理UNSAT问题。作为端到端学习的可满足性分类器，SATformer的性能显著超越了NeuroSAT。此外，我们将SATformer做出的子句预测集成到现代启发式SAT求解器中，并验证了我们的方法。",
    "tldr": "SATformer通过引入基于Transformer的方法，采用对不可满足性进行建模的方式，以识别不可满足的子问题，得到了优于NeuroSAT的性能。",
    "en_tdlr": "SATformer achieves better performance than NeuroSAT by introducing a Transformer-based approach that models unsatisfiability to identify unsatisfiable sub-problems."
}