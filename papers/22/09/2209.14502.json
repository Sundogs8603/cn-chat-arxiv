{
    "title": "Fast Inference for Quantile Regression with Tens of Millions of Observations. (arXiv:2209.14502v5 [econ.EM] UPDATED)",
    "abstract": "Big data analytics has opened new avenues in economic research, but the challenge of analyzing datasets with tens of millions of observations is substantial. Conventional econometric methods based on extreme estimators require large amounts of computing resources and memory, which are often not readily available. In this paper, we focus on linear quantile regression applied to \"ultra-large\" datasets, such as U.S. decennial censuses. A fast inference framework is presented, utilizing stochastic subgradient descent (S-subGD) updates. The inference procedure handles cross-sectional data sequentially: (i) updating the parameter estimate with each incoming \"new observation\", (ii) aggregating it as a $\\textit{Polyak-Ruppert}$ average, and (iii) computing a pivotal statistic for inference using only a solution path. The methodology draws from time-series regression to create an asymptotically pivotal statistic through random scaling. Our proposed test statistic is calculated in a fully online",
    "link": "http://arxiv.org/abs/2209.14502",
    "context": "Title: Fast Inference for Quantile Regression with Tens of Millions of Observations. (arXiv:2209.14502v5 [econ.EM] UPDATED)\nAbstract: Big data analytics has opened new avenues in economic research, but the challenge of analyzing datasets with tens of millions of observations is substantial. Conventional econometric methods based on extreme estimators require large amounts of computing resources and memory, which are often not readily available. In this paper, we focus on linear quantile regression applied to \"ultra-large\" datasets, such as U.S. decennial censuses. A fast inference framework is presented, utilizing stochastic subgradient descent (S-subGD) updates. The inference procedure handles cross-sectional data sequentially: (i) updating the parameter estimate with each incoming \"new observation\", (ii) aggregating it as a $\\textit{Polyak-Ruppert}$ average, and (iii) computing a pivotal statistic for inference using only a solution path. The methodology draws from time-series regression to create an asymptotically pivotal statistic through random scaling. Our proposed test statistic is calculated in a fully online",
    "path": "papers/22/09/2209.14502.json",
    "total_tokens": 967,
    "translated_title": "处理数量级达数千万观测值的分位数回归的快速推断方法",
    "translated_abstract": "大数据分析在经济研究中开辟了新的道路，但是分析具有数千万观测值的数据集的挑战是巨大的。传统的基于极值估计的计量经济学方法需要大量的计算资源和内存，这些资源通常并不容易获得。本文针对应用于“超大规模”数据集（例如美国十年一次的人口普查数据）的线性分位数回归，提出了一个快速推断框架，利用随机次梯度下降（S-subGD）更新。推断过程按顺序处理横截面数据：(i) 对每个新观测值进行参数估计的更新，(ii) 将其作为 $\\textit{Polyak-Ruppert}$ 平均值进行聚合，(iii) 使用解路径仅计算用于推断的关键统计量。该方法借鉴了时间序列回归的思想，通过随机缩放创建一个渐近可靠的统计量。我们提出的检验统计量是在完全在线的情况下计算的。",
    "tldr": "本文提出了一个快速推断框架，利用随机次梯度下降更新处理数量级达数千万观测值的分位数回归问题。通过顺序处理数据、聚合参数估计和计算关键统计量的解路径，该方法在处理超大规模数据集时具有较低的计算资源和内存需求。",
    "en_tdlr": "This paper presents a fast inference framework utilizing stochastic subgradient descent updates for quantile regression with tens of millions of observations. The proposed method reduces the computational resources and memory requirements by sequentially processing the data, aggregating parameter estimates, and calculating pivotal statistics along the solution path."
}