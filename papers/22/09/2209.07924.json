{
    "title": "GNNInterpreter: A Probabilistic Generative Model-Level Explanation for Graph Neural Networks",
    "abstract": "arXiv:2209.07924v4 Announce Type: replace-cross  Abstract: Recently, Graph Neural Networks (GNNs) have significantly advanced the performance of machine learning tasks on graphs. However, this technological breakthrough makes people wonder: how does a GNN make such decisions, and can we trust its prediction with high confidence? When it comes to some critical fields, such as biomedicine, where making wrong decisions can have severe consequences, it is crucial to interpret the inner working mechanisms of GNNs before applying them. In this paper, we propose a model-agnostic model-level explanation method for different GNNs that follow the message passing scheme, GNNInterpreter, to explain the high-level decision-making process of the GNN model. More specifically, GNNInterpreter learns a probabilistic generative graph distribution that produces the most discriminative graph pattern the GNN tries to detect when making a certain prediction by optimizing a novel objective function specifical",
    "link": "https://arxiv.org/abs/2209.07924",
    "context": "Title: GNNInterpreter: A Probabilistic Generative Model-Level Explanation for Graph Neural Networks\nAbstract: arXiv:2209.07924v4 Announce Type: replace-cross  Abstract: Recently, Graph Neural Networks (GNNs) have significantly advanced the performance of machine learning tasks on graphs. However, this technological breakthrough makes people wonder: how does a GNN make such decisions, and can we trust its prediction with high confidence? When it comes to some critical fields, such as biomedicine, where making wrong decisions can have severe consequences, it is crucial to interpret the inner working mechanisms of GNNs before applying them. In this paper, we propose a model-agnostic model-level explanation method for different GNNs that follow the message passing scheme, GNNInterpreter, to explain the high-level decision-making process of the GNN model. More specifically, GNNInterpreter learns a probabilistic generative graph distribution that produces the most discriminative graph pattern the GNN tries to detect when making a certain prediction by optimizing a novel objective function specifical",
    "path": "papers/22/09/2209.07924.json",
    "total_tokens": 836,
    "translated_title": "GNNInterpreter：图神经网络的生成模型级解释",
    "translated_abstract": "最近，图神经网络（GNNs）显著提升了在图上的机器学习任务的性能。然而，这一技术突破使人们产生了疑问：GNN是如何做出决策的，我们能否高度信任其预测？在一些关键领域，如生物医学，做出错误决策可能带来严重后果，因此在应用之前解释GNN的内部工作机制至关重要。本文提出了一种适用于遵循消息传递方案的不同GNN的模型不可知的模型级解释方法GNNInterpreter，来解释GNN模型的高级决策过程。具体而言，GNNInterpreter通过优化一种新颖的目标函数学习一个能够产生GNN在做出某个预测时试图检测到的最具辨识性图模式的概率生成图分布。",
    "tldr": "提出了GNNInterpreter，一种用于解释图神经网络高级决策过程的模型级解释方法，通过学习概率生成图分布来揭示GNN模型内部工作机制。",
    "en_tdlr": "Introduced GNNInterpreter, a model-level explanation method for interpreting the high-level decision-making process of Graph Neural Networks by learning a probabilistic generative graph distribution to reveal the inner working mechanisms of GNN models."
}