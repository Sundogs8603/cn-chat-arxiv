{
    "title": "Fairness and robustness in anti-causal prediction. (arXiv:2209.09423v2 [cs.LG] UPDATED)",
    "abstract": "Robustness to distribution shift and fairness have independently emerged as two important desiderata required of modern machine learning models. While these two desiderata seem related, the connection between them is often unclear in practice. Here, we discuss these connections through a causal lens, focusing on anti-causal prediction tasks, where the input to a classifier (e.g., an image) is assumed to be generated as a function of the target label and the protected attribute. By taking this perspective, we draw explicit connections between a common fairness criterion - separation - and a common notion of robustness - risk invariance. These connections provide new motivation for applying the separation criterion in anticausal settings, and inform old discussions regarding fairness-performance tradeoffs. In addition, our findings suggest that robustness-motivated approaches can be used to enforce separation, and that they often work better in practice than methods designed to directly ",
    "link": "http://arxiv.org/abs/2209.09423",
    "context": "Title: Fairness and robustness in anti-causal prediction. (arXiv:2209.09423v2 [cs.LG] UPDATED)\nAbstract: Robustness to distribution shift and fairness have independently emerged as two important desiderata required of modern machine learning models. While these two desiderata seem related, the connection between them is often unclear in practice. Here, we discuss these connections through a causal lens, focusing on anti-causal prediction tasks, where the input to a classifier (e.g., an image) is assumed to be generated as a function of the target label and the protected attribute. By taking this perspective, we draw explicit connections between a common fairness criterion - separation - and a common notion of robustness - risk invariance. These connections provide new motivation for applying the separation criterion in anticausal settings, and inform old discussions regarding fairness-performance tradeoffs. In addition, our findings suggest that robustness-motivated approaches can be used to enforce separation, and that they often work better in practice than methods designed to directly ",
    "path": "papers/22/09/2209.09423.json",
    "total_tokens": 932,
    "translated_title": "公平性和鲁棒性在反因果预测中的应用",
    "translated_abstract": "鲁棒性和公平性作为现代机器学习模型的重要要求，独立地出现。虽然这两个要求似乎相关，但在实践中它们之间的连接常常不清楚。在本文中，我们通过因果关系的视角讨论这些连接，重点关注反因果预测任务，其中分类器的输入（例如图像）被假定为由目标标签和受保护属性的函数生成。通过采取这种视角，我们明确了一个常见的公平性准则 - 分离性 - 与一种常见的鲁棒性概念 - 风险不变性之间的联系。这些连接为在反因果设置中应用分离准则提供了新的动机，并为关于公平性-性能权衡的旧讨论提供了信息。此外，我们的研究结果表明，鲁棒性驱动的方法可以用来实现分离，并且通常比直接设计公平性方法的方法在实践中表现更好。",
    "tldr": "这项研究通过因果关系的视角探讨了反因果预测中公平性和鲁棒性的关系，并提出了将分离准则应用于反因果设置的新动机。该研究还发现，以鲁棒性为驱动的方法可以用来实现分离，且通常比直接设计公平性方法的方法更有效。",
    "en_tdlr": "This research examines the relationship between fairness and robustness in anti-causal prediction from a causal perspective. It provides new motivation for applying the separation criterion in anti-causal settings, and suggests that robustness-driven approaches can be more effective than directly designing fairness methods."
}