{
    "title": "The Space of Adversarial Strategies. (arXiv:2209.04521v2 [cs.CR] UPDATED)",
    "abstract": "Adversarial examples, inputs designed to induce worst-case behavior in machine learning models, have been extensively studied over the past decade. Yet, our understanding of this phenomenon stems from a rather fragmented pool of knowledge; at present, there are a handful of attacks, each with disparate assumptions in threat models and incomparable definitions of optimality. In this paper, we propose a systematic approach to characterize worst-case (i.e., optimal) adversaries. We first introduce an extensible decomposition of attacks in adversarial machine learning by atomizing attack components into surfaces and travelers. With our decomposition, we enumerate over components to create 576 attacks (568 of which were previously unexplored). Next, we propose the Pareto Ensemble Attack (PEA): a theoretical attack that upper-bounds attack performance. With our new attacks, we measure performance relative to the PEA on: both robust and non-robust models, seven datasets, and three extended lp",
    "link": "http://arxiv.org/abs/2209.04521",
    "context": "Title: The Space of Adversarial Strategies. (arXiv:2209.04521v2 [cs.CR] UPDATED)\nAbstract: Adversarial examples, inputs designed to induce worst-case behavior in machine learning models, have been extensively studied over the past decade. Yet, our understanding of this phenomenon stems from a rather fragmented pool of knowledge; at present, there are a handful of attacks, each with disparate assumptions in threat models and incomparable definitions of optimality. In this paper, we propose a systematic approach to characterize worst-case (i.e., optimal) adversaries. We first introduce an extensible decomposition of attacks in adversarial machine learning by atomizing attack components into surfaces and travelers. With our decomposition, we enumerate over components to create 576 attacks (568 of which were previously unexplored). Next, we propose the Pareto Ensemble Attack (PEA): a theoretical attack that upper-bounds attack performance. With our new attacks, we measure performance relative to the PEA on: both robust and non-robust models, seven datasets, and three extended lp",
    "path": "papers/22/09/2209.04521.json",
    "total_tokens": 924,
    "translated_title": "对抗性策略的空间",
    "translated_abstract": "过去十年中，对抗性样本，即旨在在机器学习模型中诱发最糟糕行为的输入，已经得到广泛研究。然而，我们对这一现象的理解来自于一片相对零散的知识池；目前，存在着一些攻击方法，每种方法在威胁模型上都有不同的假设，并且定义的最优性不可比较。在本文中，我们提出了一种系统的方法来刻画最坏情况（即最优）的对抗。我们首先引入了对抗性机器学习中攻击的可拓展分解，将攻击组件分解为表面和旅行者。借助于我们的分解，我们枚举了各种组件以创建了576种攻击（其中568种以前尚未探索）。接下来，我们提出了帕累托组合攻击（PEA）：一种理论上限制攻击性能的攻击方法。通过我们新的攻击方法，我们在鲁棒和非鲁棒模型、七个数据集以及三个扩展lp上相对于PEA衡量了性能。",
    "tldr": "本文提出了一种系统的方法来研究对抗性策略的空间。通过分解攻击组件，并引入新的攻击方法，我们可以更好地理解最坏情况下的对抗行为，并且衡量攻击性能。"
}