{
    "title": "Isotropic Representation Can Improve Dense Retrieval. (arXiv:2209.00218v2 [cs.CL] UPDATED)",
    "abstract": "The recent advancement in language representation modeling has broadly affected the design of dense retrieval models. In particular, many of the high-performing dense retrieval models evaluate representations of query and document using BERT, and subsequently apply a cosine-similarity based scoring to determine the relevance. BERT representations, however, are known to follow an anisotropic distribution of a narrow cone shape and such an anisotropic distribution can be undesirable for the cosine-similarity based scoring. In this work, we first show that BERT-based DR also follows an anisotropic distribution. To cope with the problem, we introduce unsupervised post-processing methods of Normalizing Flow and whitening, and develop token-wise method in addition to the sequence-wise method for applying the post-processing methods to the representations of dense retrieval models. We show that the proposed methods can effectively enhance the representations to be isotropic, then we perform e",
    "link": "http://arxiv.org/abs/2209.00218",
    "context": "Title: Isotropic Representation Can Improve Dense Retrieval. (arXiv:2209.00218v2 [cs.CL] UPDATED)\nAbstract: The recent advancement in language representation modeling has broadly affected the design of dense retrieval models. In particular, many of the high-performing dense retrieval models evaluate representations of query and document using BERT, and subsequently apply a cosine-similarity based scoring to determine the relevance. BERT representations, however, are known to follow an anisotropic distribution of a narrow cone shape and such an anisotropic distribution can be undesirable for the cosine-similarity based scoring. In this work, we first show that BERT-based DR also follows an anisotropic distribution. To cope with the problem, we introduce unsupervised post-processing methods of Normalizing Flow and whitening, and develop token-wise method in addition to the sequence-wise method for applying the post-processing methods to the representations of dense retrieval models. We show that the proposed methods can effectively enhance the representations to be isotropic, then we perform e",
    "path": "papers/22/09/2209.00218.json",
    "total_tokens": 868,
    "translated_title": "同性质的表示可以改善密集检索",
    "translated_abstract": "最近语言表示建模的进展广泛影响了密集检索模型的设计。特别是，许多高性能的密集检索模型使用BERT评估查询和文档的表示，并随后应用基于余弦相似度的评分来确定相关性。然而，已知BERT表示遵循一个狭窄锥形的非均匀分布，这种非均匀分布对于基于余弦相似度的评分可能是不可取的。在这项工作中，我们首先展示了基于BERT的密集检索模型也遵循非均匀分布。为了应对这个问题，我们引入了无监督的后处理方法：正则化流和白化，并开发了单词级方法来将这些后处理方法应用到密集检索模型的表示中。我们展示了所提出的方法能够有效地增强表示的同性质，然后我们进行了实验。",
    "tldr": "本研究发现BERT-based DR遵循非均匀分布，为了解决这个问题，我们引入了正则化流和白化的后处理方法，并开发了单词级方法来应用这些后处理方法，实验证明这些方法能够有效地增强表示的同性质。"
}