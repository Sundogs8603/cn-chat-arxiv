{
    "title": "Hyperbolic VAE via Latent Gaussian Distributions. (arXiv:2209.15217v3 [cs.LG] UPDATED)",
    "abstract": "We propose a Gaussian manifold variational auto-encoder (GM-VAE) whose latent space consists of a set of Gaussian distributions. It is known that the set of the univariate Gaussian distributions with the Fisher information metric form a hyperbolic space, which we call a Gaussian manifold. To learn the VAE endowed with the Gaussian manifolds, we propose a pseudo-Gaussian manifold normal distribution based on the Kullback-Leibler divergence, a local approximation of the squared Fisher-Rao distance, to define a density over the latent space. In experiments, we demonstrate the efficacy of GM-VAE on two different tasks: density estimation of image datasets and environment modeling in model-based reinforcement learning. GM-VAE outperforms the other variants of hyperbolicand Euclidean-VAEs on density estimation tasks and shows competitive performance in model-based reinforcement learning. We observe that our model provides strong numerical stability, addressing a common limitation reported ",
    "link": "http://arxiv.org/abs/2209.15217",
    "context": "Title: Hyperbolic VAE via Latent Gaussian Distributions. (arXiv:2209.15217v3 [cs.LG] UPDATED)\nAbstract: We propose a Gaussian manifold variational auto-encoder (GM-VAE) whose latent space consists of a set of Gaussian distributions. It is known that the set of the univariate Gaussian distributions with the Fisher information metric form a hyperbolic space, which we call a Gaussian manifold. To learn the VAE endowed with the Gaussian manifolds, we propose a pseudo-Gaussian manifold normal distribution based on the Kullback-Leibler divergence, a local approximation of the squared Fisher-Rao distance, to define a density over the latent space. In experiments, we demonstrate the efficacy of GM-VAE on two different tasks: density estimation of image datasets and environment modeling in model-based reinforcement learning. GM-VAE outperforms the other variants of hyperbolicand Euclidean-VAEs on density estimation tasks and shows competitive performance in model-based reinforcement learning. We observe that our model provides strong numerical stability, addressing a common limitation reported ",
    "path": "papers/22/09/2209.15217.json",
    "total_tokens": 934,
    "translated_title": "通过隐变量高斯分布的双曲 VAE",
    "translated_abstract": "我们提出了一种高斯流形变分自编码器(GM-VAE)，其潜空间由一组高斯分布组成。已知一维高斯分布集合在 Fisher 信息度量下形成了一个双曲空间，我们称之为高斯流形。为了学习具有高斯流形的 VAE，我们提出了基于 Kullback-Leibler 散度的伪高斯流形正态分布，它是对平方 Fisher-Rao 距离的局部近似，用于定义潜空间上的密度。在实验中，我们展示了 GM-VAE 在两个不同任务上的有效性：图像数据集密度估计和模型驱动的强化学习中的环境建模。GM-VAE 在密度估计任务上超越了其他双曲和欧几里得 VAE 的变体，并在模型驱动的强化学习中展现了竞争性的性能。我们观察到我们的模型提供了强大的数值稳定性，解决了一个常见的限制问题。",
    "tldr": "这项研究提出了一种通过使用高斯流形的潜空间来改进变分自编码器(VAE)的方法。实验证明，这种GM-VAE方法在密度估计和模型驱动的强化学习任务中表现出色，具有较强的数值稳定性。",
    "en_tdlr": "This research proposes a method to improve Variational Auto-Encoders (VAEs) by utilizing a latent space consisting of Gaussian distributions on a Gaussian manifold. Experimental results demonstrate that this GM-VAE approach performs well in density estimation and model-based reinforcement learning tasks, while providing strong numerical stability."
}