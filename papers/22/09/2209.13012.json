{
    "title": "Survey on Fairness Notions and Related Tensions. (arXiv:2209.13012v2 [cs.CY] UPDATED)",
    "abstract": "Automated decision systems are increasingly used to take consequential decisions in problems such as job hiring and loan granting with the hope of replacing subjective human decisions with objective machine learning (ML) algorithms. However, ML-based decision systems are prone to bias, which results in yet unfair decisions. Several notions of fairness have been defined in the literature to capture the different subtleties of this ethical and social concept (e.g., statistical parity, equal opportunity, etc.). Fairness requirements to be satisfied while learning models created several types of tensions among the different notions of fairness and other desirable properties such as privacy and classification accuracy. This paper surveys the commonly used fairness notions and discusses the tensions among them with privacy and accuracy. Different methods to address the fairness-accuracy trade-off (classified into four approaches, namely, pre-processing, in-processing, post-processing, and hy",
    "link": "http://arxiv.org/abs/2209.13012",
    "context": "Title: Survey on Fairness Notions and Related Tensions. (arXiv:2209.13012v2 [cs.CY] UPDATED)\nAbstract: Automated decision systems are increasingly used to take consequential decisions in problems such as job hiring and loan granting with the hope of replacing subjective human decisions with objective machine learning (ML) algorithms. However, ML-based decision systems are prone to bias, which results in yet unfair decisions. Several notions of fairness have been defined in the literature to capture the different subtleties of this ethical and social concept (e.g., statistical parity, equal opportunity, etc.). Fairness requirements to be satisfied while learning models created several types of tensions among the different notions of fairness and other desirable properties such as privacy and classification accuracy. This paper surveys the commonly used fairness notions and discusses the tensions among them with privacy and accuracy. Different methods to address the fairness-accuracy trade-off (classified into four approaches, namely, pre-processing, in-processing, post-processing, and hy",
    "path": "papers/22/09/2209.13012.json",
    "total_tokens": 849,
    "translated_title": "公平性概念及其相关张力研究综述",
    "translated_abstract": "自动决策系统越来越多地用于解决招聘和贷款等涉及重大决策的问题，希望用机器学习算法代替主观人为决策。然而，基于机器学习的决策系统容易出现偏见，导致不公平的决策。文献中定义了几种公平性概念以捕捉这个伦理和社会概念的不同微妙之处（例如统计平等、机会平等等）。在学习模型时需要满足公平性要求，这产生了不同的公平概念之间以及隐私和分类准确性等其他期望属性之间的紧张关系。本文概述了通常使用的公平性概念，并讨论了它们与隐私和准确性之间的张力。本综述介绍了解决公平性与准确性权衡问题的不同方法（分为预处理、处理中、后处理和混合四种方法）。",
    "tldr": "本文调查了公平性的不同概念以及它们与其他期望属性的紧张关系，并介绍了处理公平性-准确性权衡问题的不同方法。",
    "en_tdlr": "This paper surveys the different notions of fairness and their tensions with other desirable properties, and introduces various methods to address the fairness-accuracy trade-off."
}