{
    "title": "Generalized Kernel Regularized Least Squares. (arXiv:2209.14355v3 [stat.ML] UPDATED)",
    "abstract": "Kernel Regularized Least Squares (KRLS) is a popular method for flexibly estimating models that may have complex relationships between variables. However, its usefulness to many researchers is limited for two reasons. First, existing approaches are inflexible and do not allow KRLS to be combined with theoretically-motivated extensions such as random effects, unregularized fixed effects, or non-Gaussian outcomes. Second, estimation is extremely computationally intensive for even modestly sized datasets. Our paper addresses both concerns by introducing generalized KRLS (gKRLS). We note that KRLS can be re-formulated as a hierarchical model thereby allowing easy inference and modular model construction where KRLS can be used alongside random effects, splines, and unregularized fixed effects. Computationally, we also implement random sketching to dramatically accelerate estimation while incurring a limited penalty in estimation quality. We demonstrate that gKRLS can be fit on datasets with",
    "link": "http://arxiv.org/abs/2209.14355",
    "context": "Title: Generalized Kernel Regularized Least Squares. (arXiv:2209.14355v3 [stat.ML] UPDATED)\nAbstract: Kernel Regularized Least Squares (KRLS) is a popular method for flexibly estimating models that may have complex relationships between variables. However, its usefulness to many researchers is limited for two reasons. First, existing approaches are inflexible and do not allow KRLS to be combined with theoretically-motivated extensions such as random effects, unregularized fixed effects, or non-Gaussian outcomes. Second, estimation is extremely computationally intensive for even modestly sized datasets. Our paper addresses both concerns by introducing generalized KRLS (gKRLS). We note that KRLS can be re-formulated as a hierarchical model thereby allowing easy inference and modular model construction where KRLS can be used alongside random effects, splines, and unregularized fixed effects. Computationally, we also implement random sketching to dramatically accelerate estimation while incurring a limited penalty in estimation quality. We demonstrate that gKRLS can be fit on datasets with",
    "path": "papers/22/09/2209.14355.json",
    "total_tokens": 953,
    "translated_title": "广义核正则化最小二乘法",
    "translated_abstract": "核正则化最小二乘法 (KRLS) 是一种流行的方法，用于灵活地估计具有复杂变量关系的模型。然而，其可用性因两个原因而受到许多研究人员的限制。首先，现有方法缺乏灵活性，不允许将KRLS与理论动机下的扩展如随机效应、未经正则化的固定效应或非高斯结果组合使用。其次，即使是规模较小的数据集，估计也非常计算密集。本文通过引入广义KRLS (gKRLS) 来解决这两个问题。我们指出，KRLS可以重新设定为分层模型，从而允许轻松推理和模块化模型构建，在其中KRLS可以与随机效应、样条和未经正则化的固定效应并用。在计算方面，我们还实现了随机草图方法，以极大地加速估计，并在估计质量上承担有限的惩罚。我们证明gKRLS可适用于具有大量样本的数据集的拟合。",
    "tldr": "本论文提出了广义核正则化最小二乘法 (gKRLS)，解决了核正则化最小二乘法 (KRLS) 在当前使用中的两个限制：它的扩展能力不足，且即使在小规模数据集上，其计算代价也非常高昂。",
    "en_tdlr": "This paper proposes a Generalized Kernel Regularized Least Squares (gKRLS) method that overcomes the limitations of the popular Kernel Regularized Least Squares (KRLS) method: its limited ability for theoretical extensions and its high computational cost, even for modestly sized datasets."
}