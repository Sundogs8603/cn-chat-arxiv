{
    "title": "Deep Double Descent via Smooth Interpolation. (arXiv:2209.10080v4 [cs.LG] UPDATED)",
    "abstract": "The ability of overparameterized deep networks to interpolate noisy data, while at the same time showing good generalization performance, has been recently characterized in terms of the double descent curve for the test error. Common intuition from polynomial regression suggests that overparameterized networks are able to sharply interpolate noisy data, without considerably deviating from the ground-truth signal, thus preserving generalization ability. At present, a precise characterization of the relationship between interpolation and generalization for deep networks is missing. In this work, we quantify sharpness of fit of the training data interpolated by neural network functions, by studying the loss landscape w.r.t. to the input variable locally to each training point, over volumes around cleanly- and noisily-labelled training samples, as we systematically increase the number of model parameters and training epochs. Our findings show that loss sharpness in the input space follows ",
    "link": "http://arxiv.org/abs/2209.10080",
    "context": "Title: Deep Double Descent via Smooth Interpolation. (arXiv:2209.10080v4 [cs.LG] UPDATED)\nAbstract: The ability of overparameterized deep networks to interpolate noisy data, while at the same time showing good generalization performance, has been recently characterized in terms of the double descent curve for the test error. Common intuition from polynomial regression suggests that overparameterized networks are able to sharply interpolate noisy data, without considerably deviating from the ground-truth signal, thus preserving generalization ability. At present, a precise characterization of the relationship between interpolation and generalization for deep networks is missing. In this work, we quantify sharpness of fit of the training data interpolated by neural network functions, by studying the loss landscape w.r.t. to the input variable locally to each training point, over volumes around cleanly- and noisily-labelled training samples, as we systematically increase the number of model parameters and training epochs. Our findings show that loss sharpness in the input space follows ",
    "path": "papers/22/09/2209.10080.json",
    "total_tokens": 995,
    "translated_title": "基于平滑插值的深度双重下降",
    "translated_abstract": "近期研究表明，超参数化深度网络具有插值噪声数据和表现良好的泛化性能的能力，这种现象通过测试误差的双重下降曲线得到了表征。然而，对于深度网络插值和泛化之间的精确关系还没有得到明确的定量描述。本文通过研究神经网络函数插值训练数据时与每个训练点周围的输入变量相关联的损失景观，定量衡量训练数据的拟合锐度。我们发现，输入空间中的损失锐度遵循一个非光滑的二次曲线，这与传统的多项式回归的分析结论有一定差异。此外，我们还发现当神经网络的复杂度逐渐增加时，测试误差会先降后升（即“双下降”现象），这与之前研究的结论有所不同。",
    "tldr": "本文研究神经网络在插值训练数据时的损失景观，发现其损失锐度遵循非光滑的二次曲线，当神经网络的复杂度逐渐增加时，测试误差会先降后升（即“双下降”现象）。"
}