{
    "title": "Minimizing Human Assistance: Augmenting a Single Demonstration for Deep Reinforcement Learning. (arXiv:2209.11275v2 [cs.LG] UPDATED)",
    "abstract": "The use of human demonstrations in reinforcement learning has proven to significantly improve agent performance. However, any requirement for a human to manually 'teach' the model is somewhat antithetical to the goals of reinforcement learning. This paper attempts to minimize human involvement in the learning process while retaining the performance advantages by using a single human example collected through a simple-to-use virtual reality simulation to assist with RL training. Our method augments a single demonstration to generate numerous human-like demonstrations that, when combined with Deep Deterministic Policy Gradients and Hindsight Experience Replay (DDPG + HER) significantly improve training time on simple tasks and allows the agent to solve a complex task (block stacking) that DDPG + HER alone cannot solve. The model achieves this significant training advantage using a single human example, requiring less than a minute of human input. Moreover, despite learning from a human e",
    "link": "http://arxiv.org/abs/2209.11275",
    "context": "Title: Minimizing Human Assistance: Augmenting a Single Demonstration for Deep Reinforcement Learning. (arXiv:2209.11275v2 [cs.LG] UPDATED)\nAbstract: The use of human demonstrations in reinforcement learning has proven to significantly improve agent performance. However, any requirement for a human to manually 'teach' the model is somewhat antithetical to the goals of reinforcement learning. This paper attempts to minimize human involvement in the learning process while retaining the performance advantages by using a single human example collected through a simple-to-use virtual reality simulation to assist with RL training. Our method augments a single demonstration to generate numerous human-like demonstrations that, when combined with Deep Deterministic Policy Gradients and Hindsight Experience Replay (DDPG + HER) significantly improve training time on simple tasks and allows the agent to solve a complex task (block stacking) that DDPG + HER alone cannot solve. The model achieves this significant training advantage using a single human example, requiring less than a minute of human input. Moreover, despite learning from a human e",
    "path": "papers/22/09/2209.11275.json",
    "total_tokens": 1037,
    "translated_title": "减少人工干预：增强单一演示的深度强化学习",
    "translated_abstract": "强化学习中使用人类示范已被证明可以显著提高智能体的表现。然而，任何需要人为地手动“教授”模型的要求都与加强学习的目标相冲突。本文尝试在保留性能优势的同时，最小化人类参与学习过程，使用通过简单易用的虚拟现实模拟收集的单个人类示例来协助RL培训。我们的方法增强了单个演示，生成了许多类似于人类的演示。当这些演示与深度确定性策略梯度和后见之明的经验重放（DDPG + HER）相结合时，可以显著提高简单任务的训练时间，并使智能体能够解决DDPG + HER无法解决的复杂任务（块叠放）。该模型使用单个人类示例实现了这一显著的训练优势，需要不到一分钟的人类输入。此外，尽管从人类示例中学习，但代理的运行表现与原始演示者的行为风格不同。",
    "tldr": "本文通过使用虚拟现实模拟收集的单个人类示例辅助RL训练，从而在最小化人类干预的同时保留了使用人类示范的性能优势。这种方法使用单个示例生成的多个演示可显著提高训练速度，并使智能体能够解决复杂任务。",
    "en_tdlr": "This paper proposes a method to use a single human example collected through a simple-to-use virtual reality simulation to assist with reinforcement learning training. The method augments a single demonstration to generate numerous human-like demonstrations that significantly improve training time and allows the agent to solve a complex task that cannot be solved by Deep Deterministic Policy Gradients and Hindsight Experience Replay alone. The model achieves this significant training advantage using a single human example, which requires less than a minute of human input. This approach minimizes human involvement in the learning process while retaining the performance advantages of using human demonstrations."
}