{
    "title": "Defend Data Poisoning Attacks on Voice Authentication. (arXiv:2209.04547v2 [cs.CR] UPDATED)",
    "abstract": "With the advances in deep learning, speaker verification has achieved very high accuracy and is gaining popularity as a type of biometric authentication option in many scenes of our daily life, especially the growing market of web services. Compared to traditional passwords, \"vocal passwords\" are much more convenient as they relieve people from memorizing different passwords. However, new machine learning attacks are putting these voice authentication systems at risk. Without a strong security guarantee, attackers could access legitimate users' web accounts by fooling the deep neural network (DNN) based voice recognition models. In this paper, we demonstrate an easy-to-implement data poisoning attack to the voice authentication system, which can hardly be captured by existing defense mechanisms. Thus, we propose a more robust defense method, called Guardian, which is a convolutional neural network-based discriminator. The Guardian discriminator integrates a series of novel techniques i",
    "link": "http://arxiv.org/abs/2209.04547",
    "context": "Title: Defend Data Poisoning Attacks on Voice Authentication. (arXiv:2209.04547v2 [cs.CR] UPDATED)\nAbstract: With the advances in deep learning, speaker verification has achieved very high accuracy and is gaining popularity as a type of biometric authentication option in many scenes of our daily life, especially the growing market of web services. Compared to traditional passwords, \"vocal passwords\" are much more convenient as they relieve people from memorizing different passwords. However, new machine learning attacks are putting these voice authentication systems at risk. Without a strong security guarantee, attackers could access legitimate users' web accounts by fooling the deep neural network (DNN) based voice recognition models. In this paper, we demonstrate an easy-to-implement data poisoning attack to the voice authentication system, which can hardly be captured by existing defense mechanisms. Thus, we propose a more robust defense method, called Guardian, which is a convolutional neural network-based discriminator. The Guardian discriminator integrates a series of novel techniques i",
    "path": "papers/22/09/2209.04547.json",
    "total_tokens": 900,
    "translated_title": "防御语音认证中的数据中毒攻击",
    "translated_abstract": "随着深度学习的进展，说话人验证已经取得了非常高的准确性，并且正在作为一种生物特征认证选项在我们日常生活的许多场景中越来越受欢迎，特别是在不断增长的网络服务市场中。与传统密码相比，\"声音密码\"更方便，因为它们使人们不必记忆不同的密码。然而，新的机器学习攻击正在使这些语音认证系统面临风险。在没有强大的安全保证的情况下，攻击者可以通过欺骗基于深度神经网络（DNN）的语音识别模型来访问合法用户的网络账户。在本文中，我们展示了一种易于实施的语音认证系统数据中毒攻击，这种攻击几乎难以被现有的防御机制捕捉到。因此，我们提出了一种更加强大的防御方法，称为Guardian，它是一种基于卷积神经网络的鉴别器。Guardian鉴别器结合了一系列新技术，包括...",
    "tldr": "本文展示了一种易于实施的语音认证系统数据中毒攻击，并提出了一种更加强大的防御方法，称为Guardian，它是一种基于卷积神经网络的鉴别器。"
}