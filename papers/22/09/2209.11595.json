{
    "title": "Differentially private partitioned variational inference. (arXiv:2209.11595v2 [cs.LG] UPDATED)",
    "abstract": "Learning a privacy-preserving model from sensitive data which are distributed across multiple devices is an increasingly important problem. The problem is often formulated in the federated learning context, with the aim of learning a single global model while keeping the data distributed. Moreover, Bayesian learning is a popular approach for modelling, since it naturally supports reliable uncertainty estimates. However, Bayesian learning is generally intractable even with centralised non-private data and so approximation techniques such as variational inference are a necessity. Variational inference has recently been extended to the non-private federated learning setting via the partitioned variational inference algorithm. For privacy protection, the current gold standard is called differential privacy. Differential privacy guarantees privacy in a strong, mathematically clearly defined sense.  In this paper, we present differentially private partitioned variational inference, the first",
    "link": "http://arxiv.org/abs/2209.11595",
    "context": "Title: Differentially private partitioned variational inference. (arXiv:2209.11595v2 [cs.LG] UPDATED)\nAbstract: Learning a privacy-preserving model from sensitive data which are distributed across multiple devices is an increasingly important problem. The problem is often formulated in the federated learning context, with the aim of learning a single global model while keeping the data distributed. Moreover, Bayesian learning is a popular approach for modelling, since it naturally supports reliable uncertainty estimates. However, Bayesian learning is generally intractable even with centralised non-private data and so approximation techniques such as variational inference are a necessity. Variational inference has recently been extended to the non-private federated learning setting via the partitioned variational inference algorithm. For privacy protection, the current gold standard is called differential privacy. Differential privacy guarantees privacy in a strong, mathematically clearly defined sense.  In this paper, we present differentially private partitioned variational inference, the first",
    "path": "papers/22/09/2209.11595.json",
    "total_tokens": 925,
    "translated_title": "差分隐私的分区变分推断方法",
    "translated_abstract": "从分布在多个设备上的敏感数据中学习隐私保护模型是一个日益重要的问题。该问题通常在联邦学习背景下进行规划，目标是在保持数据分布的同时学习单个全局模型。此外，贝叶斯学习是一种流行的建模方法，因为它自然地支持可靠的不确定性估计。然而，即使对于集中的非隐私数据，贝叶斯学习也通常是不可操作的，因此变分推断等近似技术是必需的。近期，通过分区变分推断算法，变分推断已经扩展到非隐私联邦学习的情况。对于隐私保护，目前的黄金标准被称为差分隐私。差分隐私在数学上定义了一个强的隐私保护概念。本文提出了差分隐私的分区变分推断方法，是第一种通过分区变分推断算法在联邦贝叶斯学习环境下实现差分隐私的方法。我们在人造和真实基准测试中展示了我们提出的方法的有效性和效率。",
    "tldr": "本论文提出了差分隐私的分区变分推断算法，是第一种在联邦贝叶斯学习环境下实现差分隐私的方法。",
    "en_tdlr": "This paper proposes differentially private partitioned variational inference, the first method that achieves differential privacy in the federated Bayesian learning setting via the partitioned variational inference algorithm."
}