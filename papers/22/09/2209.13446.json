{
    "title": "Feature-based Learning for Diverse and Privacy-Preserving Counterfactual Explanations. (arXiv:2209.13446v5 [cs.AI] UPDATED)",
    "abstract": "Interpretable machine learning seeks to understand the reasoning process of complex black-box systems that are long notorious for lack of explainability. One flourishing approach is through counterfactual explanations, which provide suggestions on what a user can do to alter an outcome. Not only must a counterfactual example counter the original prediction from the black-box classifier but it should also satisfy various constraints for practical applications. Diversity is one of the critical constraints that however remains less discussed. While diverse counterfactuals are ideal, it is computationally challenging to simultaneously address some other constraints. Furthermore, there is a growing privacy concern over the released counterfactual data. To this end, we propose a feature-based learning framework that effectively handles the counterfactual constraints and contributes itself to the limited pool of private explanation models. We demonstrate the flexibility and effectiveness of o",
    "link": "http://arxiv.org/abs/2209.13446",
    "context": "Title: Feature-based Learning for Diverse and Privacy-Preserving Counterfactual Explanations. (arXiv:2209.13446v5 [cs.AI] UPDATED)\nAbstract: Interpretable machine learning seeks to understand the reasoning process of complex black-box systems that are long notorious for lack of explainability. One flourishing approach is through counterfactual explanations, which provide suggestions on what a user can do to alter an outcome. Not only must a counterfactual example counter the original prediction from the black-box classifier but it should also satisfy various constraints for practical applications. Diversity is one of the critical constraints that however remains less discussed. While diverse counterfactuals are ideal, it is computationally challenging to simultaneously address some other constraints. Furthermore, there is a growing privacy concern over the released counterfactual data. To this end, we propose a feature-based learning framework that effectively handles the counterfactual constraints and contributes itself to the limited pool of private explanation models. We demonstrate the flexibility and effectiveness of o",
    "path": "papers/22/09/2209.13446.json",
    "total_tokens": 870,
    "translated_title": "基于特征学习的多样性隐私保护反事实解释方法",
    "translated_abstract": "可解释的机器学习致力于理解长期以来因缺乏可解释性而声名狼藉的复杂黑盒子系统的推理过程。其中一种蓬勃发展的方法是通过反事实解释，为用户提供如何改变结果的建议。反事实样本不仅必须反驳黑盒分类器的原始预测，还必须满足各种实际应用的约束条件，其中多样性是关键约束之一但仍较少讨论。虽然多样化的反事实很理想，但同时解决其他约束条件在计算上具有挑战性。此外，共享反事实数据存在越来越多的隐私问题。因此，本文提出了一种基于特征学习的框架来有效地处理反事实约束条件，并为私有解释模型的有限资料库做出贡献。我们在各种数据集和黑盒模型上展示了我们的框架的灵活性和有效性。",
    "tldr": "本文提出了一种基于特征学习的多样性隐私保护反事实解释方法，可以有效地处理反事实约束条件，并为私有解释模型做出贡献。",
    "en_tdlr": "This paper proposes a feature-based learning framework for diverse and privacy-preserving counterfactual explanations, which effectively handles the constraints and contributes itself to the limited pool of private explanation models."
}