{
    "title": "Augmentation Invariant Discrete Representation for Generative Spoken Language Modeling. (arXiv:2209.15483v2 [cs.CL] UPDATED)",
    "abstract": "Generative Spoken Language Modeling research focuses on optimizing speech Language Models (LMs) using raw audio recordings without accessing any textual supervision. Such speech LMs usually operate over discrete units obtained from quantizing internal representations of self-supervised models. Although such units show impressive modeling results, their robustness capabilities have not been extensively investigated. This work focuses on improving the robustness of discrete input representations for generative spoken language modeling. First, we formally define how to measure the robustness of such representations to various signal variations that do not alter the spoken information (e.g., time-stretch). Next, we empirically demonstrate how current state-of-the-art representation models lack robustness to such variations. To overcome this, we propose an effective and efficient method to learn robust discrete speech representation for generative spoken language modeling. The proposed appr",
    "link": "http://arxiv.org/abs/2209.15483",
    "context": "Title: Augmentation Invariant Discrete Representation for Generative Spoken Language Modeling. (arXiv:2209.15483v2 [cs.CL] UPDATED)\nAbstract: Generative Spoken Language Modeling research focuses on optimizing speech Language Models (LMs) using raw audio recordings without accessing any textual supervision. Such speech LMs usually operate over discrete units obtained from quantizing internal representations of self-supervised models. Although such units show impressive modeling results, their robustness capabilities have not been extensively investigated. This work focuses on improving the robustness of discrete input representations for generative spoken language modeling. First, we formally define how to measure the robustness of such representations to various signal variations that do not alter the spoken information (e.g., time-stretch). Next, we empirically demonstrate how current state-of-the-art representation models lack robustness to such variations. To overcome this, we propose an effective and efficient method to learn robust discrete speech representation for generative spoken language modeling. The proposed appr",
    "path": "papers/22/09/2209.15483.json",
    "total_tokens": 1031,
    "translated_title": "面向生成式语音语言建模的增强不变离散表示方法",
    "translated_abstract": "生成式语音语言建模的研究关注于使用原始音频记录优化语言模型，而不使用任何文本监督。这种语言模型通常使用从自监督模型的内部表示量化得到的离散单位进行操作。本研究旨在改善离散输入表示对生成式语音语言建模的鲁棒性。我们定义了如何测量这些表示对各种不会改变语音信息（例如时间拉伸）的信号变化的鲁棒性，并通过实验证明了目前最先进的表示模型缺乏对此类变化的鲁棒性。为了克服这一问题，我们提出了一种有效且高效的方法来学习面向生成式语音语言建模的鲁棒离散语音表示。该方法利用基于transformer的模型的最新进展，针对数据增强的不变性，提出了一种非线性量化方法，以学习增强不变表示。该方法在鲁棒性上表现出了显著的改进，并在语音生成任务上取得了竞争性的表现。",
    "tldr": "本研究提出了一种增强不变的离散语音表示方法，以提高其在生成式语音语言建模中的鲁棒性。该方法利用了transformer-based模型，并通过一种非线性量化方法来学习增强不变表示。实验证明，该方法相对于现有最先进方法具有显著的鲁棒性改进，并在语音生成任务上表现出了竞争性的表现。",
    "en_tdlr": "This study proposes an augmentation-invariant discrete representation method for improving the robustness of discrete input representations for generative spoken language modeling. It leverages transformer-based models and a non-linear quantization method to learn augmented-invariant representations, achieving significant improvements in robustness and competitive performance on speech generation tasks."
}