{
    "title": "Inverted Landing in a Small Aerial Robot via Deep Reinforcement Learning for Triggering and Control of Rotational Maneuvers. (arXiv:2209.11043v2 [cs.RO] UPDATED)",
    "abstract": "Inverted landing in a rapid and robust manner is a challenging feat for aerial robots, especially while depending entirely on onboard sensing and computation. In spite of this, this feat is routinely performed by biological fliers such as bats, flies, and bees. Our previous work has identified a direct causal connection between a series of onboard visual cues and kinematic actions that allow for reliable execution of this challenging aerobatic maneuver in small aerial robots. In this work, we first utilized Deep Reinforcement Learning and a physics-based simulation to obtain a general, optimal control policy for robust inverted landing starting from any arbitrary approach condition. This optimized control policy provides a computationally-efficient mapping from the system's observational space to its motor command action space, including both triggering and control of rotational maneuvers. This was done by training the system over a large range of approach flight velocities that varied",
    "link": "http://arxiv.org/abs/2209.11043",
    "context": "Title: Inverted Landing in a Small Aerial Robot via Deep Reinforcement Learning for Triggering and Control of Rotational Maneuvers. (arXiv:2209.11043v2 [cs.RO] UPDATED)\nAbstract: Inverted landing in a rapid and robust manner is a challenging feat for aerial robots, especially while depending entirely on onboard sensing and computation. In spite of this, this feat is routinely performed by biological fliers such as bats, flies, and bees. Our previous work has identified a direct causal connection between a series of onboard visual cues and kinematic actions that allow for reliable execution of this challenging aerobatic maneuver in small aerial robots. In this work, we first utilized Deep Reinforcement Learning and a physics-based simulation to obtain a general, optimal control policy for robust inverted landing starting from any arbitrary approach condition. This optimized control policy provides a computationally-efficient mapping from the system's observational space to its motor command action space, including both triggering and control of rotational maneuvers. This was done by training the system over a large range of approach flight velocities that varied",
    "path": "papers/22/09/2209.11043.json",
    "total_tokens": 1021,
    "translated_title": "基于深度强化学习的小型空中机器人倒立降落触发和旋转机动控制",
    "translated_abstract": "小型空中机器人通过仅依赖机载感应和计算，在短时间内实现倒立降落是一项富有挑战性的任务。然而，蝙蝠、苍蝇和蜜蜂等生物飞行者经常执行这项飞行技巧。本研究利用深度强化学习和基于物理学的仿真，获得了一种通用的最优控制策略，可以从任意的起始状态开始，实现小型空中机器人的倒立降落触发和旋转机动控制。通过将所学习的策略转移至实体机器人，我们证明了这种方法可以使机器人具有高可靠性地完成任意初态的倒立降落，即使在明显的风扰动下。",
    "tldr": "本研究利用深度强化学习和基于物理学的仿真技术，获得一种通用的最优控制策略，可以使小型空中机器人从任意状态开始，实现倒立降落触发和旋转机动控制。通过将所学习的策略转移至实体机器人，成功实现高可靠性的倒立降落，即使在受到风扰动的情况下。",
    "en_tdlr": "This study utilized deep reinforcement learning and physics-based simulation to obtain a general, optimal control policy for triggering and controlling rotational maneuvers of a small aerial robot for inverted landing. The learned policy was successfully transferred to a physical robot, demonstrating the ability to perform inverted landing with high reliability from various initial approach conditions, including under significant wind disturbances."
}