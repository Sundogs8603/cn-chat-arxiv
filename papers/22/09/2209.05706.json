{
    "title": "Non-Parametric Temporal Adaptation for Social Media Topic Classification. (arXiv:2209.05706v2 [cs.CL] UPDATED)",
    "abstract": "User-generated social media data is constantly changing as new trends influence online discussion and personal information is deleted due to privacy concerns. However, most current NLP models are static and rely on fixed training data, which means they are unable to adapt to temporal change -- both test distribution shift and deleted training data -- without frequent, costly re-training. In this paper, we study temporal adaptation through the task of longitudinal hashtag prediction and propose a non-parametric dense retrieval technique, which does not require re-training, as a simple but effective solution. In experiments on a newly collected, publicly available, year-long Twitter dataset exhibiting temporal distribution shift, our method improves by 64.12% over the best parametric baseline without any of its costly gradient-based updating. Our dense retrieval approach is also particularly well-suited to dynamically deleted user data in line with data privacy laws, with negligible comp",
    "link": "http://arxiv.org/abs/2209.05706",
    "context": "Title: Non-Parametric Temporal Adaptation for Social Media Topic Classification. (arXiv:2209.05706v2 [cs.CL] UPDATED)\nAbstract: User-generated social media data is constantly changing as new trends influence online discussion and personal information is deleted due to privacy concerns. However, most current NLP models are static and rely on fixed training data, which means they are unable to adapt to temporal change -- both test distribution shift and deleted training data -- without frequent, costly re-training. In this paper, we study temporal adaptation through the task of longitudinal hashtag prediction and propose a non-parametric dense retrieval technique, which does not require re-training, as a simple but effective solution. In experiments on a newly collected, publicly available, year-long Twitter dataset exhibiting temporal distribution shift, our method improves by 64.12% over the best parametric baseline without any of its costly gradient-based updating. Our dense retrieval approach is also particularly well-suited to dynamically deleted user data in line with data privacy laws, with negligible comp",
    "path": "papers/22/09/2209.05706.json",
    "total_tokens": 905,
    "translated_title": "面向社交媒体话题分类的非参数化时间自适应方法",
    "translated_abstract": "用户生成的社交媒体数据不断变化，新的趋势影响在线讨论，个人信息由于隐私问题而被删除。然而，大多数当前的自然语言处理模型是静态的，并依赖于固定的训练数据，这意味着它们无法适应时间变化，无法应对测试数据分布变化和已删除的训练数据，需要经常昂贵的重新训练。本文通过长期的话题预测任务研究时间自适应，提出了一种非参数化的密集检索技术作为简单但有效的解决方案。在一个新收集的、公开可用的、为期一年的Twitter数据集上进行了实验，该数据集表现出时间分布变化，我们方法比最佳参数基线改善了64.12%，而且不需要其昂贵的基于梯度的更新。我们的密集检索方法也非常适用于符合数据隐私法规的动态删除用户数据，几乎没有计算成本。",
    "tldr": "本文提出了一种非参数化的密集检索技术，可以解决当前自然语言处理模型无法适应时间变化，无法应对测试数据分布变化和已删除的训练数据的问题，并在Twitter数据集上取得了显著的实验结果。",
    "en_tdlr": "This paper proposes a non-parametric dense retrieval technique to address the issue of current NLP models' inability to adapt to temporal change and deleted training data without frequent re-training. It achieves significant improvements on a year-long Twitter dataset exhibiting temporal distribution shift, without the costly gradient-based updating of the best parametric baseline."
}