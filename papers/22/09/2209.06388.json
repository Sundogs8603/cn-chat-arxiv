{
    "title": "TSFool: Crafting Highly-imperceptible Adversarial Time Series through Multi-objective Black-box Attack to Fool RNN Classifiers. (arXiv:2209.06388v2 [cs.LG] UPDATED)",
    "abstract": "Neural network (NN) classifiers are vulnerable to adversarial attacks. Although the existing gradient-based attacks achieve state-of-the-art performance in feed-forward NNs and image recognition tasks, they do not perform as well on time series classification with recurrent neural network (RNN) models. This is because the cyclical structure of RNN prevents direct model differentiation and the visual sensitivity of time series data to perturbations challenges the traditional local optimization objective of the adversarial attack. In this paper, a black-box method called TSFool is proposed to efficiently craft highly-imperceptible adversarial time series for RNN classifiers. We propose a novel global optimization objective named Camouflage Coefficient to consider the imperceptibility of adversarial samples from the perspective of class distribution, and accordingly refine the adversarial attack as a multi-objective optimization problem to enhance the perturbation quality. To get rid of t",
    "link": "http://arxiv.org/abs/2209.06388",
    "context": "Title: TSFool: Crafting Highly-imperceptible Adversarial Time Series through Multi-objective Black-box Attack to Fool RNN Classifiers. (arXiv:2209.06388v2 [cs.LG] UPDATED)\nAbstract: Neural network (NN) classifiers are vulnerable to adversarial attacks. Although the existing gradient-based attacks achieve state-of-the-art performance in feed-forward NNs and image recognition tasks, they do not perform as well on time series classification with recurrent neural network (RNN) models. This is because the cyclical structure of RNN prevents direct model differentiation and the visual sensitivity of time series data to perturbations challenges the traditional local optimization objective of the adversarial attack. In this paper, a black-box method called TSFool is proposed to efficiently craft highly-imperceptible adversarial time series for RNN classifiers. We propose a novel global optimization objective named Camouflage Coefficient to consider the imperceptibility of adversarial samples from the perspective of class distribution, and accordingly refine the adversarial attack as a multi-objective optimization problem to enhance the perturbation quality. To get rid of t",
    "path": "papers/22/09/2209.06388.json",
    "total_tokens": 1136,
    "translated_title": "TSFool: 通过多目标黑盒攻击方法生成高度难以察觉的对循环神经网络分类器的对抗性时间序列",
    "translated_abstract": "神经网络分类器很容易受到对抗性攻击。现有的梯度攻击方法在前馈神经网络和图像识别任务中取得了最先进的性能，但它们在循环神经网络模型下的时间序列分类中表现不佳。这是因为RNN的循环结构阻止了直接的模型差分，而时间序列数据对扰动的视觉敏感性挑战了对抗性攻击的传统局部优化目标。本文提出了一种名为TSFool的黑盒方法，用于有效地生成针对RNN分类器的高度难以察觉的对抗性时间序列。我们提出了一种新的全局优化目标，称为Camouflage Coefficient，从类分布的角度考虑对抗样本的难以察觉性，并相应地将对抗性攻击改进为多目标优化问题，以增强扰动的质量。为了摆脱不同模型间的转移性，设计了一个特定于模型的回避规则。在人造数据和实际数据集上的实验结果表明，TSFool可以生成高难度攻击同时保持对抗样本的不易被检测性，并有很高的转移性。",
    "tldr": "本文提出了一种名为TSFool的黑盒方法, 可以有效地生成针对RNN分类器的高度难以察觉的对抗性时间序列，在考虑对抗样本难以察觉性的情况下，将对抗性攻击改进为多目标优化问题来增强扰动的质量。",
    "en_tdlr": "This paper proposes a black-box method called TSFool, which efficiently creates highly imperceptible adversarial time series for RNN classifiers. It introduces a novel global optimization objective called Camouflage Coefficient to refine the adversarial attack as a multi-objective optimization problem, thus enhancing the perturbation quality while considering the imperceptibility of adversarial samples from the perspective of class distribution. A model-specific evasion rule is also designed to avoid transferability across models. The experiments on both synthetic and real-world datasets demonstrate high success rates, imperceptibility and transferability of the proposed method."
}