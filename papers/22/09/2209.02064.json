{
    "title": "GRASP: A Goodness-of-Fit Test for Classification Learning. (arXiv:2209.02064v2 [stat.ME] UPDATED)",
    "abstract": "Performance of classifiers is often measured in terms of average accuracy on test data. Despite being a standard measure, average accuracy fails in characterizing the fit of the model to the underlying conditional law of labels given the features vector ($Y|X$), e.g. due to model misspecification, over fitting, and high-dimensionality. In this paper, we consider the fundamental problem of assessing the goodness-of-fit for a general binary classifier. Our framework does not make any parametric assumption on the conditional law $Y|X$, and treats that as a black box oracle model which can be accessed only through queries. We formulate the goodness-of-fit assessment problem as a tolerance hypothesis testing of the form \\[ H_0: \\mathbb{E}\\Big[D_f\\Big({\\sf Bern}(\\eta(X))\\|{\\sf Bern}(\\hat{\\eta}(X))\\Big)\\Big]\\leq \\tau\\,, \\] where $D_f$ represents an $f$-divergence function, and $\\eta(x)$, $\\hat{\\eta}(x)$ respectively denote the true and an estimate likelihood for a feature vector $x$ admitting",
    "link": "http://arxiv.org/abs/2209.02064",
    "context": "Title: GRASP: A Goodness-of-Fit Test for Classification Learning. (arXiv:2209.02064v2 [stat.ME] UPDATED)\nAbstract: Performance of classifiers is often measured in terms of average accuracy on test data. Despite being a standard measure, average accuracy fails in characterizing the fit of the model to the underlying conditional law of labels given the features vector ($Y|X$), e.g. due to model misspecification, over fitting, and high-dimensionality. In this paper, we consider the fundamental problem of assessing the goodness-of-fit for a general binary classifier. Our framework does not make any parametric assumption on the conditional law $Y|X$, and treats that as a black box oracle model which can be accessed only through queries. We formulate the goodness-of-fit assessment problem as a tolerance hypothesis testing of the form \\[ H_0: \\mathbb{E}\\Big[D_f\\Big({\\sf Bern}(\\eta(X))\\|{\\sf Bern}(\\hat{\\eta}(X))\\Big)\\Big]\\leq \\tau\\,, \\] where $D_f$ represents an $f$-divergence function, and $\\eta(x)$, $\\hat{\\eta}(x)$ respectively denote the true and an estimate likelihood for a feature vector $x$ admitting",
    "path": "papers/22/09/2209.02064.json",
    "total_tokens": 911,
    "translated_title": "GRASP: 一种用于分类学习的适合度检验方法",
    "translated_abstract": "分类器的性能通常以测试数据的平均准确率衡量。尽管平均准确率是一种标准的衡量方法，但它在描述模型对给定特征向量的标签的条件概率分布的拟合程度方面存在缺陷，例如模型错误规范化、过拟合和高维度等。在本文中，我们考虑了评估通用二分类器拟合程度的基本问题。我们的框架不对条件概率分布$Y|X$进行任何参数假设，并将其视为黑盒子模型，只能通过查询访问。我们将适合度评估问题表述为容忍度假设检验的形式\\[ H_0: \\mathbb{E}\\Big[D_f\\Big({\\sf Bern}(\\eta(X))\\|{\\sf Bern}(\\hat{\\eta}(X))\\Big)\\Big]\\leq \\tau\\,, \\]其中$D_f$表示一个$f$-散度函数，$\\eta(x)$和$\\hat{\\eta}(x)$分别表示特征向量$x$的真实和估计的似然度。",
    "tldr": "本文提出了一种适合度检验方法GRASP，用于评估通用二分类器对给定特征向量的标签的条件概率分布的拟合程度。",
    "en_tdlr": "This paper introduces a goodness-of-fit test called GRASP for evaluating the fit of a general binary classifier to the underlying conditional law of labels given the features vector."
}