{
    "title": "Risk of Bias in Chest Radiography Deep Learning Foundation Models. (arXiv:2209.02965v3 [cs.LG] UPDATED)",
    "abstract": "Purpose: To analyze a recently published chest radiography foundation model for the presence of biases that could lead to subgroup performance disparities across biological sex and race.  Materials and Methods: This retrospective study used 127,118 chest radiographs from 42,884 patients (mean age, 63 [SD] 17 years; 23,623 male, 19,261 female) from the CheXpert dataset collected between October 2002 and July 2017. To determine the presence of bias in features generated by a chest radiography foundation model and baseline deep learning model, dimensionality reduction methods together with two-sample Kolmogorov-Smirnov tests were used to detect distribution shifts across sex and race. A comprehensive disease detection performance analysis was then performed to associate any biases in the features to specific disparities in classification performance across patient subgroups.  Results: Ten out of twelve pairwise comparisons across biological sex and race showed statistically significant di",
    "link": "http://arxiv.org/abs/2209.02965",
    "context": "Title: Risk of Bias in Chest Radiography Deep Learning Foundation Models. (arXiv:2209.02965v3 [cs.LG] UPDATED)\nAbstract: Purpose: To analyze a recently published chest radiography foundation model for the presence of biases that could lead to subgroup performance disparities across biological sex and race.  Materials and Methods: This retrospective study used 127,118 chest radiographs from 42,884 patients (mean age, 63 [SD] 17 years; 23,623 male, 19,261 female) from the CheXpert dataset collected between October 2002 and July 2017. To determine the presence of bias in features generated by a chest radiography foundation model and baseline deep learning model, dimensionality reduction methods together with two-sample Kolmogorov-Smirnov tests were used to detect distribution shifts across sex and race. A comprehensive disease detection performance analysis was then performed to associate any biases in the features to specific disparities in classification performance across patient subgroups.  Results: Ten out of twelve pairwise comparisons across biological sex and race showed statistically significant di",
    "path": "papers/22/09/2209.02965.json",
    "total_tokens": 838,
    "translated_title": "胸部X光深度学习基础模型中的偏倚风险",
    "translated_abstract": "目的：分析最近发布的胸部X光基础模型是否存在偏倚，可能导致在生物性别和种族之间存在亚组性能差距。材料和方法：本回顾性研究使用CheXpert数据集中自2002年10月至2017年7月期间收集的42,884名患者（年龄平均为63岁，标准偏差为17岁；男性23,623人，女性19,261人）的127,118张胸部X光。使用降维方法和两样本Kolmogorov-Smirnov检验检测胸部X光基础模型和基础深度学习模型生成的特征中的分布偏差，以确定是否存在偏倚。然后进行全面的疾病检测性能分析，将特征中的任何偏倚与患者亚组的分类性能差异相关联。",
    "tldr": "该研究分析了一种最近发布的胸部X光基础模型中的偏倚风险，并发现在生物性别和种族之间存在亚组性能差距。",
    "en_tdlr": "This study analyzed the risk of bias in a recently published chest radiography foundation model and found subgroup performance disparities across biological sex and race."
}