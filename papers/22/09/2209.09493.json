{
    "title": "A framework for benchmarking clustering algorithms. (arXiv:2209.09493v3 [cs.LG] UPDATED)",
    "abstract": "The evaluation of clustering algorithms can involve running them on a variety of benchmark problems, and comparing their outputs to the reference, ground-truth groupings provided by experts. Unfortunately, many research papers and graduate theses consider only a small number of datasets. Also, the fact that there can be many equally valid ways to cluster a given problem set is rarely taken into account. In order to overcome these limitations, we have developed a framework whose aim is to introduce a consistent methodology for testing clustering algorithms. Furthermore, we have aggregated, polished, and standardised many clustering benchmark dataset collections referred to across the machine learning and data mining literature, and included new datasets of different dimensionalities, sizes, and cluster types. An interactive datasets explorer, the documentation of the Python API, a description of the ways to interact with the framework from other programming languages such as R or MATLAB",
    "link": "http://arxiv.org/abs/2209.09493",
    "context": "Title: A framework for benchmarking clustering algorithms. (arXiv:2209.09493v3 [cs.LG] UPDATED)\nAbstract: The evaluation of clustering algorithms can involve running them on a variety of benchmark problems, and comparing their outputs to the reference, ground-truth groupings provided by experts. Unfortunately, many research papers and graduate theses consider only a small number of datasets. Also, the fact that there can be many equally valid ways to cluster a given problem set is rarely taken into account. In order to overcome these limitations, we have developed a framework whose aim is to introduce a consistent methodology for testing clustering algorithms. Furthermore, we have aggregated, polished, and standardised many clustering benchmark dataset collections referred to across the machine learning and data mining literature, and included new datasets of different dimensionalities, sizes, and cluster types. An interactive datasets explorer, the documentation of the Python API, a description of the ways to interact with the framework from other programming languages such as R or MATLAB",
    "path": "papers/22/09/2209.09493.json",
    "total_tokens": 888,
    "translated_title": "一个用于基准测试聚类算法的框架",
    "translated_abstract": "聚类算法的评估可以涉及在各种基准问题上运行它们，并将其输出与专家提供的参考真实分组进行比较。不幸的是，许多研究论文和研究生论文只考虑了少数数据集。而且，很少考虑到在给定问题集上可以有许多同样有效的聚类方法的事实。为了克服这些限制，我们开发了一个框架，其目的是引入一种一致的方法来测试聚类算法。此外，我们还汇总、改进和标准化了机器学习和数据挖掘文献中提到的许多聚类基准数据集合，并包含了具有不同维度、大小和聚类类型的新数据集。还有一个互动数据集浏览器、Python API的文档以及如何与其他编程语言（如R或MATLAB）进行框架交互的描述。",
    "tldr": "该论文开发了一个用于基准测试聚类算法的框架，旨在引入一种一致的方法进行测试。还汇总、改进和标准化了许多聚类基准数据集合，并包含了新数据集。提供了互动数据集浏览器、Python API的文档以及与其他编程语言进行框架交互的方式。",
    "en_tdlr": "This paper proposes a framework for benchmarking clustering algorithms, introducing a consistent methodology for testing and providing a wide range of benchmark datasets. The framework includes an interactive datasets explorer, documentation of the Python API, and support for interaction with other programming languages."
}