{
    "title": "Fast Lifelong Adaptive Inverse Reinforcement Learning from Demonstrations. (arXiv:2209.11908v5 [cs.LG] UPDATED)",
    "abstract": "Learning from Demonstration (LfD) approaches empower end-users to teach robots novel tasks via demonstrations of the desired behaviors, democratizing access to robotics. However, current LfD frameworks are not capable of fast adaptation to heterogeneous human demonstrations nor the large-scale deployment in ubiquitous robotics applications. In this paper, we propose a novel LfD framework, Fast Lifelong Adaptive Inverse Reinforcement learning (FLAIR). Our approach (1) leverages learned strategies to construct policy mixtures for fast adaptation to new demonstrations, allowing for quick end-user personalization, (2) distills common knowledge across demonstrations, achieving accurate task inference; and (3) expands its model only when needed in lifelong deployments, maintaining a concise set of prototypical strategies that can approximate all behaviors via policy mixtures. We empirically validate that FLAIR achieves adaptability (i.e., the robot adapts to heterogeneous, user-specific task",
    "link": "http://arxiv.org/abs/2209.11908",
    "context": "Title: Fast Lifelong Adaptive Inverse Reinforcement Learning from Demonstrations. (arXiv:2209.11908v5 [cs.LG] UPDATED)\nAbstract: Learning from Demonstration (LfD) approaches empower end-users to teach robots novel tasks via demonstrations of the desired behaviors, democratizing access to robotics. However, current LfD frameworks are not capable of fast adaptation to heterogeneous human demonstrations nor the large-scale deployment in ubiquitous robotics applications. In this paper, we propose a novel LfD framework, Fast Lifelong Adaptive Inverse Reinforcement learning (FLAIR). Our approach (1) leverages learned strategies to construct policy mixtures for fast adaptation to new demonstrations, allowing for quick end-user personalization, (2) distills common knowledge across demonstrations, achieving accurate task inference; and (3) expands its model only when needed in lifelong deployments, maintaining a concise set of prototypical strategies that can approximate all behaviors via policy mixtures. We empirically validate that FLAIR achieves adaptability (i.e., the robot adapts to heterogeneous, user-specific task",
    "path": "papers/22/09/2209.11908.json",
    "total_tokens": 1032,
    "translated_title": "来自演示的快速生涯适应性逆强化学习",
    "translated_abstract": "演示学习（LfD）方法使终端用户通过所需行为的演示来教授机器人新任务，从而使机器人技术的使用面更广。然而，当前的LfD框架无法快速适应异构的人类演示，也不能在普适的机器人应用中进行大规模部署。在本文中，我们提出了一种新的LfD框架——快速生涯适应性逆强化学习（FLAIR）。我们的方法(1)利用学习策略构建多样策略的组合，从而快速适应新的演示，允许快速的终端用户个性化，(2)整合演示中的共性知识，实现准确的任务推断；(3)在终身部署中只在需要时扩展其模型，通过策略组合维护一个精简的原型策略集合，并能够逼近所有行为。我们在实验证明，FLAIR实现了适应性（即机器人适应了异构的、特定于用户的任务）并且在大规模部署中节省了模型大小。",
    "tldr": "本文提出了一种快速生涯适应性逆强化学习框架，从学习的策略中构建多样策略的组合实现了对新的演示的快速适应，同时整合演示中的共性知识，实现准确的任务推断，还能够在大规模部署中通过维护一个精简的原型策略集合并通过策略组合来逼近所有行为。",
    "en_tdlr": "This paper proposes a Fast Lifelong Adaptive Inverse Reinforcement Learning (FLAIR) framework that constructs policy mixtures from learned strategies for fast adaptation to new demonstrations, distills common knowledge across demonstrations, and maintains a concise set of prototypical strategies to approximate all behaviors via policy mixtures during lifelong deployments. FLAIR achieves adaptability and model size reduction in large-scale deployment."
}