{
    "title": "Robust leave-one-out cross-validation for high-dimensional Bayesian models. (arXiv:2209.09190v2 [stat.CO] UPDATED)",
    "abstract": "Leave-one-out cross-validation (LOO-CV) is a popular method for estimating out-of-sample predictive accuracy. However, computing LOO-CV criteria can be computationally expensive due to the need to fit the model multiple times. In the Bayesian context, importance sampling provides a possible solution but classical approaches can easily produce estimators whose asymptotic variance is infinite, making them potentially unreliable. Here we propose and analyze a novel mixture estimator to compute Bayesian LOO-CV criteria. Our method retains the simplicity and computational convenience of classical approaches, while guaranteeing finite asymptotic variance of the resulting estimators. Both theoretical and numerical results are provided to illustrate the improved robustness and efficiency. The computational benefits are particularly significant in high-dimensional problems, allowing to perform Bayesian LOO-CV for a broader range of models, and datasets with highly influential observations. The ",
    "link": "http://arxiv.org/abs/2209.09190",
    "context": "Title: Robust leave-one-out cross-validation for high-dimensional Bayesian models. (arXiv:2209.09190v2 [stat.CO] UPDATED)\nAbstract: Leave-one-out cross-validation (LOO-CV) is a popular method for estimating out-of-sample predictive accuracy. However, computing LOO-CV criteria can be computationally expensive due to the need to fit the model multiple times. In the Bayesian context, importance sampling provides a possible solution but classical approaches can easily produce estimators whose asymptotic variance is infinite, making them potentially unreliable. Here we propose and analyze a novel mixture estimator to compute Bayesian LOO-CV criteria. Our method retains the simplicity and computational convenience of classical approaches, while guaranteeing finite asymptotic variance of the resulting estimators. Both theoretical and numerical results are provided to illustrate the improved robustness and efficiency. The computational benefits are particularly significant in high-dimensional problems, allowing to perform Bayesian LOO-CV for a broader range of models, and datasets with highly influential observations. The ",
    "path": "papers/22/09/2209.09190.json",
    "total_tokens": 934,
    "translated_title": "高维贝叶斯模型的鲁棒离群值交叉验证",
    "translated_abstract": "离群值交叉验证（LOO-CV）是估计样本外预测准确性的一种常用方法。然而，由于需要多次拟合模型，计算LOO-CV准则可能非常耗时。在贝叶斯背景下，重要性抽样提供了一种可能的解决方案，但经典方法很容易产生渐近方差为无穷大的估计量，使其潜在地不可靠。在这里，我们提出并分析了一种新的混合估计量来计算贝叶斯LOO-CV准则。我们的方法保持了经典方法的简单性和计算方便性，同时保证了所得估计量的渐近方差有限。我们提供了理论和数值结果来说明改进的鲁棒性和效率。在高维问题中，这种计算优势尤为显著，可以在更广泛的模型和具有高度影响性的观测数据集上进行贝叶斯LOO-CV。",
    "tldr": "提出了一个计算贝叶斯LOO-CV准则的新的混合估计量，保持了经典方法的简便性和计算方便性，并确保了结果估计量的渐近方差有限。在高维问题中尤为显著，可以应用于更广泛的模型和具有高度影响的观测数据集。",
    "en_tdlr": "A novel mixture estimator is proposed to compute Bayesian LOO-CV criteria, which retains the simplicity and computational convenience of classical approaches while guaranteeing finite asymptotic variance. It provides significant computational benefits in high-dimensional problems and allows for a broader range of models and datasets with highly influential observations."
}