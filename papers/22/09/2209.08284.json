{
    "title": "Structured Knowledge Grounding for Question Answering. (arXiv:2209.08284v3 [cs.CL] UPDATED)",
    "abstract": "Can language models (LM) ground question-answering (QA) tasks in the knowledge base via inherent relational reasoning ability? While previous models that use only LMs have seen some success on many QA tasks, more recent methods include knowledge graphs (KG) to complement LMs with their more logic-driven implicit knowledge. However, effectively extracting information from structured data, like KGs, empowers LMs to remain an open question, and current models rely on graph techniques to extract knowledge. In this paper, we propose to solely leverage the LMs to combine the language and knowledge for knowledge based question-answering with flexibility, breadth of coverage and structured reasoning. Specifically, we devise a knowledge construction method that retrieves the relevant context with a dynamic hop, which expresses more comprehensivenes than traditional GNN-based techniques. And we devise a deep fusion mechanism to further bridge the information exchanging bottleneck between the lan",
    "link": "http://arxiv.org/abs/2209.08284",
    "context": "Title: Structured Knowledge Grounding for Question Answering. (arXiv:2209.08284v3 [cs.CL] UPDATED)\nAbstract: Can language models (LM) ground question-answering (QA) tasks in the knowledge base via inherent relational reasoning ability? While previous models that use only LMs have seen some success on many QA tasks, more recent methods include knowledge graphs (KG) to complement LMs with their more logic-driven implicit knowledge. However, effectively extracting information from structured data, like KGs, empowers LMs to remain an open question, and current models rely on graph techniques to extract knowledge. In this paper, we propose to solely leverage the LMs to combine the language and knowledge for knowledge based question-answering with flexibility, breadth of coverage and structured reasoning. Specifically, we devise a knowledge construction method that retrieves the relevant context with a dynamic hop, which expresses more comprehensivenes than traditional GNN-based techniques. And we devise a deep fusion mechanism to further bridge the information exchanging bottleneck between the lan",
    "path": "papers/22/09/2209.08284.json",
    "total_tokens": 1084,
    "translated_title": "问答任务中的结构化知识基础构建",
    "translated_abstract": "语言模型（LM）能否通过固有的关系推理能力在知识库中对问答任务进行知识基础构建？虽然之前只使用LM的模型在许多问答任务上取得了一定成功，但最近的一些方法包括知识图谱（KG），通过其更具逻辑驱动的隐含知识来补充LM。然而，有效地从结构化数据（如KG）中提取信息，使得LM保持面向未知问题的灵活性和广度，目前仍是个未解之谜，并且当前的模型依赖于图技术来提取知识。在本文中，我们提出仅利用LM来结合语言和知识，以实现具有灵活性、覆盖面和结构推理的知识基础问答。具体来说，我们设计了一种知识构建方法，通过动态跳跃来检索相关的上下文，这种方法表现出了比传统基于GNN技术更全面的表现力。并且我们设计了一种深度融合机制，进一步弥合了语言和知识模态之间信息交换的瓶颈。我们在几个基准数据集上的实验表明，我们的方法优于现有的知识基础构建方法，并展示出与依赖于外部信息资源的最先进系统相竞争的性能。",
    "tldr": "本文提出了一种基于语言模型的知识基础问答方法，通过动态跳跃检索相关上下文，并使用深度融合机制，实现具有灵活性、覆盖面和结构推理，优于现有的知识基础构建方法，并达到与依赖于外部信息资源的最先进系统相竞争的性能。",
    "en_tdlr": "This paper proposes a language model-based approach for knowledge-based question answering, which retrieves relevant context with a dynamic hop and uses a deep fusion mechanism to achieve flexibility, coverage, and structured reasoning. The approach outperforms existing knowledge grounding methods and achieves competitive performance with state-of-the-art systems that rely on external information resources."
}