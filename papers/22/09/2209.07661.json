{
    "title": "On the Relation between Sensitivity and Accuracy in In-context Learning. (arXiv:2209.07661v3 [cs.CL] UPDATED)",
    "abstract": "In-context learning (ICL) suffers from oversensitivity to the prompt, making it unreliable in real-world scenarios. We study the sensitivity of ICL with respect to multiple perturbation types. First, we find that label bias obscures the true sensitivity, and therefore prior work may have significantly underestimated ICL sensitivity. Second, we observe a strong negative correlation between ICL sensitivity and accuracy: predictions sensitive to perturbations are less likely to be correct. Motivated by these findings, we propose \\textsc{SenSel}, a few-shot selective prediction method that abstains from sensitive predictions. Experiments on ten classification datasets show that \\textsc{SenSel} consistently outperforms two commonly used confidence-based and entropy-based baselines on abstention decisions.",
    "link": "http://arxiv.org/abs/2209.07661",
    "context": "Title: On the Relation between Sensitivity and Accuracy in In-context Learning. (arXiv:2209.07661v3 [cs.CL] UPDATED)\nAbstract: In-context learning (ICL) suffers from oversensitivity to the prompt, making it unreliable in real-world scenarios. We study the sensitivity of ICL with respect to multiple perturbation types. First, we find that label bias obscures the true sensitivity, and therefore prior work may have significantly underestimated ICL sensitivity. Second, we observe a strong negative correlation between ICL sensitivity and accuracy: predictions sensitive to perturbations are less likely to be correct. Motivated by these findings, we propose \\textsc{SenSel}, a few-shot selective prediction method that abstains from sensitive predictions. Experiments on ten classification datasets show that \\textsc{SenSel} consistently outperforms two commonly used confidence-based and entropy-based baselines on abstention decisions.",
    "path": "papers/22/09/2209.07661.json",
    "total_tokens": 962,
    "translated_title": "关于敏感性与准确性在上下文学习中的关系",
    "translated_abstract": "上下文学习 (In-context learning, ICL) 在实际场景中常常受到提示的过度敏感性的影响，导致其在现实世界中不可靠。我们研究了ICL对多种扰动类型的敏感性。首先，我们发现标签偏差掩盖了真实的敏感性，因此之前的研究可能大大低估了ICL的敏感性。其次，我们观察到ICL的敏感性与准确性之间存在强烈的负相关关系：对扰动敏感的预测更不容易正确。在这些发现的基础上，我们提出了一种称为SenSel的少样本选择性预测方法，该方法避免了对敏感预测的使用。在十个分类数据集上的实验证明，SenSel在放弃预测决策上始终优于两种常用的基于置信度和基于熵的基准方法。",
    "tldr": "在上下文学习中，我们发现ICL对多种扰动类型具有敏感性，标签偏差导致过去的研究低估了ICL的敏感性。同时，我们观察到ICL的敏感性和准确性之间呈现负相关关系。基于这些发现，我们提出了一种少样本选择性预测方法SenSel，它在放弃敏感预测决策上取得了优于常用基准方法的结果。"
}