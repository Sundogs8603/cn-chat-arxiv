{
    "title": "Order-Disorder: Imitation Adversarial Attacks for Black-box Neural Ranking Models. (arXiv:2209.06506v2 [cs.IR] UPDATED)",
    "abstract": "Neural text ranking models have witnessed significant advancement and are increasingly being deployed in practice. Unfortunately, they also inherit adversarial vulnerabilities of general neural models, which have been detected but remain underexplored by prior studies. Moreover, the inherit adversarial vulnerabilities might be leveraged by blackhat SEO to defeat better-protected search engines. In this study, we propose an imitation adversarial attack on black-box neural passage ranking models. We first show that the target passage ranking model can be transparentized and imitated by enumerating critical queries/candidates and then train a ranking imitation model. Leveraging the ranking imitation model, we can elaborately manipulate the ranking results and transfer the manipulation attack to the target ranking model. For this purpose, we propose an innovative gradient-based attack method, empowered by the pairwise objective function, to generate adversarial triggers, which causes preme",
    "link": "http://arxiv.org/abs/2209.06506",
    "context": "Title: Order-Disorder: Imitation Adversarial Attacks for Black-box Neural Ranking Models. (arXiv:2209.06506v2 [cs.IR] UPDATED)\nAbstract: Neural text ranking models have witnessed significant advancement and are increasingly being deployed in practice. Unfortunately, they also inherit adversarial vulnerabilities of general neural models, which have been detected but remain underexplored by prior studies. Moreover, the inherit adversarial vulnerabilities might be leveraged by blackhat SEO to defeat better-protected search engines. In this study, we propose an imitation adversarial attack on black-box neural passage ranking models. We first show that the target passage ranking model can be transparentized and imitated by enumerating critical queries/candidates and then train a ranking imitation model. Leveraging the ranking imitation model, we can elaborately manipulate the ranking results and transfer the manipulation attack to the target ranking model. For this purpose, we propose an innovative gradient-based attack method, empowered by the pairwise objective function, to generate adversarial triggers, which causes preme",
    "path": "papers/22/09/2209.06506.json",
    "total_tokens": 872,
    "translated_title": "阶-无序：黑盒神经排名模型的模拟对抗攻击",
    "translated_abstract": "神经文本排名模型取得了显着进展，并越来越多地被应用于实践中。然而，它们也继承了一般神经模型的对抗性弱点，虽然已被发现，但仍未被先前的研究充分探讨。此外，这种对抗性弱点可能被黑帽SEO用来打败更好防护的搜索引擎。本研究提出了一种模拟黑盒神经段落排名模型的对抗攻击。我们首先展示了目标排名模型可以通过枚举关键查询/候选项透明化并模仿，然后训练一个排名模仿模型。利用排名模仿模型，我们可以精心操纵排名结果并将操纵攻击转移到目标排名模型上。为此，我们提出了一种创新的基于梯度的攻击方法，使用配对目标函数强化，以生成对抗触发器，从而导致PremE.",
    "tldr": "本研究提出了一种模拟黑盒神经排名模型的对抗攻击，可被黑帽SEO用来打败更好防护的搜索引擎。",
    "en_tdlr": "This study proposes an imitation adversarial attack on black-box neural passage ranking models, which could be leveraged by blackhat SEO to defeat better-protected search engines."
}