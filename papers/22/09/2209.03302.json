{
    "title": "Quantifying Aleatoric and Epistemic Uncertainty in Machine Learning: Are Conditional Entropy and Mutual Information Appropriate Measures?. (arXiv:2209.03302v2 [cs.LG] UPDATED)",
    "abstract": "The quantification of aleatoric and epistemic uncertainty in terms of conditional entropy and mutual information, respectively, has recently become quite common in machine learning. While the properties of these measures, which are rooted in information theory, seem appealing at first glance, we identify various incoherencies that call their appropriateness into question. In addition to the measures themselves, we critically discuss the idea of an additive decomposition of total uncertainty into its aleatoric and epistemic constituents. Experiments across different computer vision tasks support our theoretical findings and raise concerns about current practice in uncertainty quantification.",
    "link": "http://arxiv.org/abs/2209.03302",
    "context": "Title: Quantifying Aleatoric and Epistemic Uncertainty in Machine Learning: Are Conditional Entropy and Mutual Information Appropriate Measures?. (arXiv:2209.03302v2 [cs.LG] UPDATED)\nAbstract: The quantification of aleatoric and epistemic uncertainty in terms of conditional entropy and mutual information, respectively, has recently become quite common in machine learning. While the properties of these measures, which are rooted in information theory, seem appealing at first glance, we identify various incoherencies that call their appropriateness into question. In addition to the measures themselves, we critically discuss the idea of an additive decomposition of total uncertainty into its aleatoric and epistemic constituents. Experiments across different computer vision tasks support our theoretical findings and raise concerns about current practice in uncertainty quantification.",
    "path": "papers/22/09/2209.03302.json",
    "total_tokens": 834,
    "translated_title": "机器学习中量化Aleatoric和Epistemic不确定性：条件熵和互信息是否适当的度量？",
    "translated_abstract": "近来在机器学习中，以条件熵和互信息的形式量化Aleatoric和Epistemic这两种不确定性的趋势日益增长。这些度量的信息理论根基看起来很有吸引力，但我们发现了各种不一致性，这使得它们的适用性成为问题。除了这些度量，我们还批判性地讨论了将总不确定性分解为其Aleatoric和Epistemic成分的加法分解的想法。不同的计算机视觉任务的实验支持我们的理论发现，并提出了关于不确定性量化的当前实践的担忧。",
    "tldr": "该论文提出了对于机器学习中量化Aleatoric和Epistemic不确定性的条件熵和互信息作为度量方法的批评和质疑，提出了这些度量存在的各种不一致性，并对将总不确定性分解为其Aleatoric和Epistemic成分的加法分解进行了讨论。实验结果证明了这些理论发现的合理性，并提出了当前有关不确定性量化的实践存在的问题。",
    "en_tdlr": "This paper critiques and questions the use of conditional entropy and mutual information as measures for quantifying Aleatoric and Epistemic uncertainty in machine learning, identifying various incoherencies. The idea of an additive decomposition of total uncertainty into its aleatoric and epistemic constituents is also discussed. Experimental results support the theoretical findings and raise concerns about current practices in uncertainty quantification."
}