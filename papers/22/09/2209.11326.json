{
    "title": "Towards Faithful Model Explanation in NLP: A Survey. (arXiv:2209.11326v4 [cs.CL] UPDATED)",
    "abstract": "End-to-end neural Natural Language Processing (NLP) models are notoriously difficult to understand. This has given rise to numerous efforts towards model explainability in recent years. One desideratum of model explanation is faithfulness, i.e. an explanation should accurately represent the reasoning process behind the model's prediction. In this survey, we review over 110 model explanation methods in NLP through the lens of faithfulness. We first discuss the definition and evaluation of faithfulness, as well as its significance for explainability. We then introduce recent advances in faithful explanation, grouping existing approaches into five categories: similarity-based methods, analysis of model-internal structures, backpropagation-based methods, counterfactual intervention, and self-explanatory models. For each category, we synthesize its representative studies, strengths, and weaknesses. Finally, we summarize their common virtues and remaining challenges, and reflect on future wo",
    "link": "http://arxiv.org/abs/2209.11326",
    "context": "Title: Towards Faithful Model Explanation in NLP: A Survey. (arXiv:2209.11326v4 [cs.CL] UPDATED)\nAbstract: End-to-end neural Natural Language Processing (NLP) models are notoriously difficult to understand. This has given rise to numerous efforts towards model explainability in recent years. One desideratum of model explanation is faithfulness, i.e. an explanation should accurately represent the reasoning process behind the model's prediction. In this survey, we review over 110 model explanation methods in NLP through the lens of faithfulness. We first discuss the definition and evaluation of faithfulness, as well as its significance for explainability. We then introduce recent advances in faithful explanation, grouping existing approaches into five categories: similarity-based methods, analysis of model-internal structures, backpropagation-based methods, counterfactual intervention, and self-explanatory models. For each category, we synthesize its representative studies, strengths, and weaknesses. Finally, we summarize their common virtues and remaining challenges, and reflect on future wo",
    "path": "papers/22/09/2209.11326.json",
    "total_tokens": 894,
    "translated_title": "对于自然语言处理中忠实的模型解释的探索：一项调查研究",
    "translated_abstract": "端到端的神经网络自然语言处理模型一直以来都难以理解。这引发了近年来许多关于模型可解释性的努力。其中一个解释模型的要求是忠实性，即解释应准确地表达模型预测背后的推理过程。本调查通过忠实性的视角对超过110种自然语言处理模型解释方法进行了回顾。我们首先讨论忠实性的定义和评估，以及其对可解释性的意义。然后，我们介绍了忠实解释中的最新进展，并将现有方法分为五个类别：基于相似性的方法、模型内部结构的分析、反向传播方法、反事实干预和自解释模型。对于每个类别，我们综合了其代表性研究、优点和缺点。最后，我们总结了它们的共同优点和挑战，并展望了未来的研究方向。",
    "tldr": "本调查研究回顾了超过110种自然语言处理模型解释方法，并从忠实性的角度进行了分类和综合。研究介绍了忠实解释的最新进展，并讨论了各个方法的优点、缺点以及未来的挑战。"
}