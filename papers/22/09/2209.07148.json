{
    "title": "Semi-supervised Batch Learning From Logged Data",
    "abstract": "arXiv:2209.07148v3 Announce Type: replace-cross  Abstract: Off-policy learning methods are intended to learn a policy from logged data, which includes context, action, and feedback (cost or reward) for each sample point. In this work, we build on the counterfactual risk minimization framework, which also assumes access to propensity scores. We propose learning methods for problems where feedback is missing for some samples, so there are samples with feedback and samples missing-feedback in the logged data. We refer to this type of learning as semi-supervised batch learning from logged data, which arises in a wide range of application domains. We derive a novel upper bound for the true risk under the inverse propensity score estimator to address this kind of learning problem. Using this bound, we propose a regularized semi-supervised batch learning method with logged data where the regularization term is feedback-independent and, as a result, can be evaluated using the logged missing-fe",
    "link": "https://arxiv.org/abs/2209.07148",
    "context": "Title: Semi-supervised Batch Learning From Logged Data\nAbstract: arXiv:2209.07148v3 Announce Type: replace-cross  Abstract: Off-policy learning methods are intended to learn a policy from logged data, which includes context, action, and feedback (cost or reward) for each sample point. In this work, we build on the counterfactual risk minimization framework, which also assumes access to propensity scores. We propose learning methods for problems where feedback is missing for some samples, so there are samples with feedback and samples missing-feedback in the logged data. We refer to this type of learning as semi-supervised batch learning from logged data, which arises in a wide range of application domains. We derive a novel upper bound for the true risk under the inverse propensity score estimator to address this kind of learning problem. Using this bound, we propose a regularized semi-supervised batch learning method with logged data where the regularization term is feedback-independent and, as a result, can be evaluated using the logged missing-fe",
    "path": "papers/22/09/2209.07148.json",
    "total_tokens": 883,
    "translated_title": "从已记录数据中进行半监督批量学习",
    "translated_abstract": "异策略学习方法旨在从已记录数据中学习策略，该数据包括每个样本点的环境、动作和反馈（成本或奖励）。在这项工作中，我们基于反事实风险最小化框架，该框架还假设能够访问概率得分。我们提出了针对一些样本缺失反馈的问题提出的学习方法，因此在已记录数据中有些样本有反馈，有些样本缺失反馈。我们将这种类型的学习称为从已记录数据中的半监督批量学习，这在广泛的应用领域中出现。为了解决这种学习问题，我们推导出了真实风险的新上界，采用倒数概率得分估计器。利用这个上界，我们提出了一种带有已记录数据的正则化半监督批量学习方法，其中正则化项与反馈无关，结果可以使用已记录的缺失反馈进行评估。",
    "tldr": "本研究基于反事实风险最小化框架提出了一种半监督批量学习方法，解决了在已记录数据中反馈缺失的问题，提出了一个新的上界来处理这种学习问题。",
    "en_tdlr": "This study proposes a semi-supervised batch learning method based on the counterfactual risk minimization framework, addressing the issue of missing feedback in logged data, and introduces a new upper bound to tackle this learning problem."
}