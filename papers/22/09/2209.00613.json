{
    "title": "ID and OOD Performance Are Sometimes Inversely Correlated on Real-world Datasets. (arXiv:2209.00613v4 [cs.LG] UPDATED)",
    "abstract": "Several studies have compared the in-distribution (ID) and out-of-distribution (OOD) performance of models in computer vision and NLP. They report a frequent positive correlation and some surprisingly never even observe an inverse correlation indicative of a necessary trade-off. The possibility of inverse patterns is important to determine whether ID performance can serve as a proxy for OOD generalization capabilities.  This paper shows with multiple datasets that inverse correlations between ID and OOD performance do happen in real-world data - not only in theoretical worst-case settings. We also explain theoretically how these cases can arise even in a minimal linear setting, and why past studies could miss such cases due to a biased selection of models.  Our observations lead to recommendations that contradict those found in much of the current literature. - High OOD performance sometimes requires trading off ID performance. - Focusing on ID performance alone may not lead to optimal",
    "link": "http://arxiv.org/abs/2209.00613",
    "context": "Title: ID and OOD Performance Are Sometimes Inversely Correlated on Real-world Datasets. (arXiv:2209.00613v4 [cs.LG] UPDATED)\nAbstract: Several studies have compared the in-distribution (ID) and out-of-distribution (OOD) performance of models in computer vision and NLP. They report a frequent positive correlation and some surprisingly never even observe an inverse correlation indicative of a necessary trade-off. The possibility of inverse patterns is important to determine whether ID performance can serve as a proxy for OOD generalization capabilities.  This paper shows with multiple datasets that inverse correlations between ID and OOD performance do happen in real-world data - not only in theoretical worst-case settings. We also explain theoretically how these cases can arise even in a minimal linear setting, and why past studies could miss such cases due to a biased selection of models.  Our observations lead to recommendations that contradict those found in much of the current literature. - High OOD performance sometimes requires trading off ID performance. - Focusing on ID performance alone may not lead to optimal",
    "path": "papers/22/09/2209.00613.json",
    "total_tokens": 868,
    "translated_title": "ID和OOD性能在现实世界的数据集中有时是反相关的",
    "translated_abstract": "许多研究比较了计算机视觉和NLP模型的分布内（ID）和分布外（OOD）性能。它们报道了频繁的正相关性，并有一些惊人的研究甚至没有观察到反相关，表明必须进行权衡。确定反向模式的可能性很重要，以确定ID性能是否可以作为OOD泛化能力的代理。本文显示了多个数据集中ID性能和OOD性能之间的反相关关系在现实世界数据中确实存在 - 不仅在理论最坏情况下。我们还从理论上解释了即使在最小线性设置中也可以出现这些情况以及为什么以前的研究可能由于模型选择的偏见而忽略了这些情况。我们的观察结果导致的建议与当前文献中的大部分相反。 - 高OOD性能有时需要牺牲ID性能。- 单纯关注ID性能可能无法达到最佳性能。",
    "tldr": "本文发现在现实世界数据中，ID性能和OOD性能之间存在反相关关系，提示需要在两者之间进行权衡，单纯关注ID性能可能无法达到最佳性能。",
    "en_tdlr": "This paper discovers the inverse correlations between ID and OOD performance in real-world data, indicating the necessary trade-off between them, and suggests that focusing solely on ID performance may not lead to optimal results."
}