{
    "title": "On the benefits of self-taught learning for brain decoding. (arXiv:2209.10099v4 [cs.NE] UPDATED)",
    "abstract": "Context. We study the benefits of using a large public neuroimaging database composed of fMRI statistic maps, in a self-taught learning framework, for improving brain decoding on new tasks. First, we leverage the NeuroVault database to train, on a selection of relevant statistic maps, a convolutional autoencoder to reconstruct these maps. Then, we use this trained encoder to initialize a supervised convolutional neural network to classify tasks or cognitive processes of unseen statistic maps from large collections of the NeuroVault database. Results. We show that such a self-taught learning process always improves the performance of the classifiers but the magnitude of the benefits strongly depends on the number of samples available both for pre-training and finetuning the models and on the complexity of the targeted downstream task. Conclusion. The pre-trained model improves the classification performance and displays more generalizable features, less sensitive to individual differenc",
    "link": "http://arxiv.org/abs/2209.10099",
    "context": "Title: On the benefits of self-taught learning for brain decoding. (arXiv:2209.10099v4 [cs.NE] UPDATED)\nAbstract: Context. We study the benefits of using a large public neuroimaging database composed of fMRI statistic maps, in a self-taught learning framework, for improving brain decoding on new tasks. First, we leverage the NeuroVault database to train, on a selection of relevant statistic maps, a convolutional autoencoder to reconstruct these maps. Then, we use this trained encoder to initialize a supervised convolutional neural network to classify tasks or cognitive processes of unseen statistic maps from large collections of the NeuroVault database. Results. We show that such a self-taught learning process always improves the performance of the classifiers but the magnitude of the benefits strongly depends on the number of samples available both for pre-training and finetuning the models and on the complexity of the targeted downstream task. Conclusion. The pre-trained model improves the classification performance and displays more generalizable features, less sensitive to individual differenc",
    "path": "papers/22/09/2209.10099.json",
    "total_tokens": 826,
    "translated_title": "自学习对大脑解码的益处研究",
    "translated_abstract": "本文研究了在自学习框架下使用大规模公共神经成像数据库中的功能磁共振成像统计图的好处，以改善解码新任务时的表现。首先，我们利用NeuroVault数据库，在一些相关的统计图上训练卷积自动编码器，对这些图进行重建。然后，我们使用这个已训练好的编码器来初始化一个有监督的卷积神经网络，以对从NeuroVault数据库大量收集的未见过的统计图的任务或认知过程进行分类。我们发现自学习过程始终可以提高分类器的性能，但其益处的大小强烈依赖于预训练和微调模型使用的样本数量以及目标下游任务的复杂度。",
    "tldr": "本文探索了利用大量公共神经成像数据库进行自学习的方法，以改善大脑解码的性能。研究表明这种方法可以提高分类器的性能，但其益处的大小受到多个因素的影响。",
    "en_tdlr": "This paper explores the method of self-taught learning using a large public neuroimaging database to improve brain decoding performance. The study shows that this method can improve the performance of classifiers, but the magnitude of the benefits is influenced by several factors."
}