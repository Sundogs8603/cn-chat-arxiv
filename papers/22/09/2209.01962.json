{
    "title": "Adversarial Detection: Attacking Object Detection in Real Time. (arXiv:2209.01962v4 [cs.AI] UPDATED)",
    "abstract": "Intelligent robots rely on object detection models to perceive the environment. Following advances in deep learning security it has been revealed that object detection models are vulnerable to adversarial attacks. However, prior research primarily focuses on attacking static images or offline videos. Therefore, it is still unclear if such attacks could jeopardize real-world robotic applications in dynamic environments. This paper bridges this gap by presenting the first real-time online attack against object detection models. We devise three attacks that fabricate bounding boxes for nonexistent objects at desired locations. The attacks achieve a success rate of about 90\\% within about 20 iterations. The demo video is available at https://youtu.be/zJZ1aNlXsMU.",
    "link": "http://arxiv.org/abs/2209.01962",
    "context": "Title: Adversarial Detection: Attacking Object Detection in Real Time. (arXiv:2209.01962v4 [cs.AI] UPDATED)\nAbstract: Intelligent robots rely on object detection models to perceive the environment. Following advances in deep learning security it has been revealed that object detection models are vulnerable to adversarial attacks. However, prior research primarily focuses on attacking static images or offline videos. Therefore, it is still unclear if such attacks could jeopardize real-world robotic applications in dynamic environments. This paper bridges this gap by presenting the first real-time online attack against object detection models. We devise three attacks that fabricate bounding boxes for nonexistent objects at desired locations. The attacks achieve a success rate of about 90\\% within about 20 iterations. The demo video is available at https://youtu.be/zJZ1aNlXsMU.",
    "path": "papers/22/09/2209.01962.json",
    "total_tokens": 789,
    "translated_title": "对抗检测: 实时攻击目标检测",
    "translated_abstract": "智能机器人依赖目标检测模型来感知环境。随着深度学习安全性的进步，揭示了目标检测模型易受到对抗性攻击的威胁。然而先前的研究主要侧重于攻击静态图像或离线视频。因此，仍不清楚此类攻击是否会危及动态环境下实际的机器人应用。本文通过提出针对目标检测模型的首次实时在线攻击来填补这一空白。我们设计了三种攻击方式，可以在所需位置生成不存在对象的边界框。这些攻击在约20次迭代内达到约90\\%的成功率。演示视频可在https://youtu.be/zJZ1aNlXsMU上观看。",
    "tldr": "本文首次提出了针对目标检测模型的实时在线攻击，这些攻击可以在所需要的位置制造不存在的物体，攻击成功率约为90\\%，揭示了目标检测模型的弱点和安全性问题。",
    "en_tdlr": "This paper presents the first real-time online attack against object detection models, which fabricate non-existent objects at desired locations, achieving a success rate of about 90\\% in about 20 iterations, revealing the vulnerabilities and security issues of object detection models."
}