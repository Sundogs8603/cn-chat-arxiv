{
    "title": "Neural Networks Based on Power Method and Inverse Power Method for Solving Linear Eigenvalue Problems. (arXiv:2209.11134v5 [math.NA] UPDATED)",
    "abstract": "In this article, we propose two kinds of neural networks inspired by power method and inverse power method to solve linear eigenvalue problems. These neural networks share similar ideas with traditional methods, in which the differential operator is realized by automatic differentiation. The eigenfunction of the eigenvalue problem is learned by the neural network and the iterative algorithms are implemented by optimizing the specially defined loss function. The largest positive eigenvalue, smallest eigenvalue and interior eigenvalues with the given prior knowledge can be solved efficiently. We examine the applicability and accuracy of our methods in the numerical experiments in one dimension, two dimensions and higher dimensions. Numerical results show that accurate eigenvalue and eigenfunction approximations can be obtained by our methods.",
    "link": "http://arxiv.org/abs/2209.11134",
    "context": "Title: Neural Networks Based on Power Method and Inverse Power Method for Solving Linear Eigenvalue Problems. (arXiv:2209.11134v5 [math.NA] UPDATED)\nAbstract: In this article, we propose two kinds of neural networks inspired by power method and inverse power method to solve linear eigenvalue problems. These neural networks share similar ideas with traditional methods, in which the differential operator is realized by automatic differentiation. The eigenfunction of the eigenvalue problem is learned by the neural network and the iterative algorithms are implemented by optimizing the specially defined loss function. The largest positive eigenvalue, smallest eigenvalue and interior eigenvalues with the given prior knowledge can be solved efficiently. We examine the applicability and accuracy of our methods in the numerical experiments in one dimension, two dimensions and higher dimensions. Numerical results show that accurate eigenvalue and eigenfunction approximations can be obtained by our methods.",
    "path": "papers/22/09/2209.11134.json",
    "total_tokens": 820,
    "translated_title": "基于幂法和反幂法的神经网络求解线性特征值问题",
    "translated_abstract": "本文提出了两种受幂法和反幂法启发的神经网络，用于求解线性特征值问题。这些神经网络与传统方法类似，其中微分算子通过自动微分实现。特征值问题的特征函数通过神经网络学习，并通过优化特定定义的损失函数实施迭代算法。在给定先验知识的情况下，可以高效地求解最大正特征值、最小特征值和内部特征值。我们在一维、二维和高维数值实验中考察了我们方法的适用性和精确性。数值结果表明，我们的方法可以得到准确的特征值和特征函数近似值。",
    "tldr": "本文提出了两种神经网络方法，分别基于幂法和反幂法，用于求解线性特征值问题。通过自动微分实现微分算子，通过优化损失函数实施迭代算法，可以高效地求解最大正特征值、最小特征值和内部特征值，并在实验中证明了方法的准确性。"
}