{
    "title": "EffEval: A Comprehensive Evaluation of Efficiency for MT Evaluation Metrics. (arXiv:2209.09593v2 [cs.CL] UPDATED)",
    "abstract": "Efficiency is a key property to foster inclusiveness and reduce environmental costs, especially in an era of LLMs. In this work, we provide a comprehensive evaluation of efficiency for MT evaluation metrics. Our approach involves replacing computation-intensive transformers with lighter alternatives and employing linear and quadratic approximations for alignment algorithms on top of LLM representations. We evaluate six (reference-free and reference-based) metrics across three MT datasets and examine 16 lightweight transformers. In addition, we look into the training efficiency of metrics like COMET by utilizing adapters. Our results indicate that (a) TinyBERT provides the optimal balance between quality and efficiency, (b) CPU speed-ups are more substantial than those on GPU; (c) WMD approximations yield no efficiency gains while reducing quality and (d) adapters enhance training efficiency (regarding backward pass speed and memory requirements) as well as, in some cases, metric qualit",
    "link": "http://arxiv.org/abs/2209.09593",
    "context": "Title: EffEval: A Comprehensive Evaluation of Efficiency for MT Evaluation Metrics. (arXiv:2209.09593v2 [cs.CL] UPDATED)\nAbstract: Efficiency is a key property to foster inclusiveness and reduce environmental costs, especially in an era of LLMs. In this work, we provide a comprehensive evaluation of efficiency for MT evaluation metrics. Our approach involves replacing computation-intensive transformers with lighter alternatives and employing linear and quadratic approximations for alignment algorithms on top of LLM representations. We evaluate six (reference-free and reference-based) metrics across three MT datasets and examine 16 lightweight transformers. In addition, we look into the training efficiency of metrics like COMET by utilizing adapters. Our results indicate that (a) TinyBERT provides the optimal balance between quality and efficiency, (b) CPU speed-ups are more substantial than those on GPU; (c) WMD approximations yield no efficiency gains while reducing quality and (d) adapters enhance training efficiency (regarding backward pass speed and memory requirements) as well as, in some cases, metric qualit",
    "path": "papers/22/09/2209.09593.json",
    "total_tokens": 948,
    "translated_title": "EffEval:一种全面评估机器翻译评价指标效率的方法",
    "translated_abstract": "效率是促进包容性和减少环境成本的关键特性，特别是在LLM时代。在这项工作中，我们对机器翻译评价指标的效率进行了全面评估。我们的方法是用轻量级替代计算密集型的transformers，并在LLM表示之上采用线性和二次近似的对齐算法。我们评估了六个（无参考和有参考）指标在三个机器翻译数据集上，并检查了16个轻量级transformers。此外，我们通过使用适配器来研究COMET等指标的训练效率。我们的结果表明：（a）TinyBERT在质量和效率之间提供了最佳平衡，（b）CPU加速比GPU更显著，（c）WMD近似没有提高效率，但降低了质量，（d）适配器提高了训练效率（关于反向传播速度和内存要求），在某些情况下提高了指标的质量。",
    "tldr": "EffEval是一种对机器翻译评价指标效率进行全面评估的方法，其中TinyBERT在质量和效率之间提供了最佳平衡，CPU加速比GPU更显著，WMD近似没有提高效率但降低了质量，适配器提高了训练效率并在某些情况下提高了指标的质量。",
    "en_tdlr": "EffEval is a comprehensive evaluation method for efficiency of MT evaluation metrics, highlighting that TinyBERT offers the optimal balance between quality and efficiency, CPU speed-ups are more substantial than GPU, WMD approximations do not improve efficiency while reducing quality, and adapters enhance training efficiency and, in some cases, metric quality."
}