{
    "title": "Robust Inference of Manifold Density and Geometry by Doubly Stochastic Scaling. (arXiv:2209.08004v2 [math.ST] UPDATED)",
    "abstract": "The Gaussian kernel and its traditional normalizations (e.g., row-stochastic) are popular approaches for assessing similarities between data points. Yet, they can be inaccurate under high-dimensional noise, especially if the noise magnitude varies considerably across the data, e.g., under heteroskedasticity or outliers. In this work, we investigate a more robust alternative -- the doubly stochastic normalization of the Gaussian kernel. We consider a setting where points are sampled from an unknown density on a low-dimensional manifold embedded in high-dimensional space and corrupted by possibly strong, non-identically distributed, sub-Gaussian noise. We establish that the doubly stochastic affinity matrix and its scaling factors concentrate around certain population forms, and provide corresponding finite-sample probabilistic error bounds. We then utilize these results to develop several tools for robust inference under general high-dimensional noise. First, we derive a robust density ",
    "link": "http://arxiv.org/abs/2209.08004",
    "context": "Title: Robust Inference of Manifold Density and Geometry by Doubly Stochastic Scaling. (arXiv:2209.08004v2 [math.ST] UPDATED)\nAbstract: The Gaussian kernel and its traditional normalizations (e.g., row-stochastic) are popular approaches for assessing similarities between data points. Yet, they can be inaccurate under high-dimensional noise, especially if the noise magnitude varies considerably across the data, e.g., under heteroskedasticity or outliers. In this work, we investigate a more robust alternative -- the doubly stochastic normalization of the Gaussian kernel. We consider a setting where points are sampled from an unknown density on a low-dimensional manifold embedded in high-dimensional space and corrupted by possibly strong, non-identically distributed, sub-Gaussian noise. We establish that the doubly stochastic affinity matrix and its scaling factors concentrate around certain population forms, and provide corresponding finite-sample probabilistic error bounds. We then utilize these results to develop several tools for robust inference under general high-dimensional noise. First, we derive a robust density ",
    "path": "papers/22/09/2209.08004.json",
    "total_tokens": 935,
    "translated_title": "通过双重随机缩放方法对流形密度和几何的稳健推断 (arXiv:2209.08004v2 [math.ST] UPDATED)",
    "translated_abstract": "高斯核及其传统的标准化方法（例如，行随机化）是评估数据点之间相似性的常用方法。然而，在高维噪声下，它们可能不准确，特别是当噪声的幅度在数据中变化较大时，例如在异方差性或异常值下。在这项工作中，我们研究了一种更稳健的替代方案--高斯核的双重随机标准化。我们考虑一种情况，即从高维空间中嵌入低维流形上的未知密度中采样的点，并且可能受到可能强烈的、非同分布的、亚高斯噪声的污染。我们证明了双重随机亲和矩阵及其缩放因子在某些种群形式附近集中，并提供相应的有限样本概率误差界。然后，我们利用这些结果开发了几种在一般高维噪声下的稳健推断工具。首先，我们推导出一个稳健密度...",
    "tldr": "本论文提出了一种对高维噪声下的流形密度和几何进行稳健推断的方法，通过双重随机缩放高斯核进行标准化，以解决高维噪声对传统标准化方法的不准确性问题。",
    "en_tdlr": "This paper proposes a robust inference method for manifold density and geometry under high-dimensional noise by using doubly stochastic scaling of the Gaussian kernel, addressing the inaccuracy issue of traditional normalization methods caused by high-dimensional noise."
}