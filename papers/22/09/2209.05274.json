{
    "title": "Fairness in Forecasting of Observations of Linear Dynamical Systems. (arXiv:2209.05274v4 [cs.LG] UPDATED)",
    "abstract": "In machine learning, training data often capture the behaviour of multiple subgroups of some underlying human population. This behaviour can often be modelled as observations of an unknown dynamical system with an unobserved state. When the training data for the subgroups are not controlled carefully, however, under-representation bias arises. To counter under-representation bias, we introduce two natural notions of fairness in time-series forecasting problems: subgroup fairness and instantaneous fairness. These notions extend predictive parity to the learning of dynamical systems. We also show globally convergent methods for the fairness-constrained learning problems using hierarchies of convexifications of non-commutative polynomial optimisation problems. We also show that by exploiting sparsity in the convexifications, we can reduce the run time of our methods considerably. Our empirical results on a biased data set motivated by insurance applications and the well-known COMPAS data ",
    "link": "http://arxiv.org/abs/2209.05274",
    "context": "Title: Fairness in Forecasting of Observations of Linear Dynamical Systems. (arXiv:2209.05274v4 [cs.LG] UPDATED)\nAbstract: In machine learning, training data often capture the behaviour of multiple subgroups of some underlying human population. This behaviour can often be modelled as observations of an unknown dynamical system with an unobserved state. When the training data for the subgroups are not controlled carefully, however, under-representation bias arises. To counter under-representation bias, we introduce two natural notions of fairness in time-series forecasting problems: subgroup fairness and instantaneous fairness. These notions extend predictive parity to the learning of dynamical systems. We also show globally convergent methods for the fairness-constrained learning problems using hierarchies of convexifications of non-commutative polynomial optimisation problems. We also show that by exploiting sparsity in the convexifications, we can reduce the run time of our methods considerably. Our empirical results on a biased data set motivated by insurance applications and the well-known COMPAS data ",
    "path": "papers/22/09/2209.05274.json",
    "total_tokens": 923,
    "translated_title": "线性动态系统观测预测中的公平性",
    "translated_abstract": "在机器学习中，训练数据经常会捕捉到某个潜在人口的多个子群体的行为。这种行为经常可以被建模为一个未知动态系统的观测值，该系统具有未观察到的状态。然而，如果子群体的训练数据没有得到精心控制，那么就会出现代表性不足的偏见。为了对抗代表性不足的偏见，我们介绍了两种时间序列预测问题中公平的自然概念：子群体公平和瞬时公平。这些概念将预测公正性扩展到了动态系统的学习中。我们还展示了使用非交换多项式优化问题的凸化层次结构来公平地学习问题时的全球收敛方法。我们还展示，通过利用凸化中的稀疏性，可以大大减少运行时间。我们在一个由保险应用程序和著名的COMPAS数据激发的有偏数据集上展示了我们的经验结果。",
    "tldr": "该论文介绍了在机器学习中公平性的概念，并为线性动态系统观测预测中的子群体公平和瞬时公平引入了全球收敛方法，以解决代表性不足的偏见问题。",
    "en_tdlr": "This paper introduces the concept of fairness in machine learning and proposes globally convergent methods for subgroup fairness and instantaneous fairness in forecasting observations of linear dynamical systems, using hierarchies of convexifications of non-commutative polynomial optimization problems, to counter under-representation bias. Empirical results on a biased dataset and the COMPAS data are presented."
}