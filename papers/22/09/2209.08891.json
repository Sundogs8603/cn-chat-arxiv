{
    "title": "Exploiting Cultural Biases via Homoglyphs in Text-to-Image Synthesis. (arXiv:2209.08891v3 [cs.CV] UPDATED)",
    "abstract": "Models for text-to-image synthesis, such as DALL-E~2 and Stable Diffusion, have recently drawn a lot of interest from academia and the general public. These models are capable of producing high-quality images that depict a variety of concepts and styles when conditioned on textual descriptions. However, these models adopt cultural characteristics associated with specific Unicode scripts from their vast amount of training data, which may not be immediately apparent. We show that by simply inserting single non-Latin characters in a textual description, common models reflect cultural stereotypes and biases in their generated images. We analyze this behavior both qualitatively and quantitatively, and identify a model's text encoder as the root cause of the phenomenon. Additionally, malicious users or service providers may try to intentionally bias the image generation to create racist stereotypes by replacing Latin characters with similarly-looking characters from non-Latin scripts, so-cal",
    "link": "http://arxiv.org/abs/2209.08891",
    "context": "Title: Exploiting Cultural Biases via Homoglyphs in Text-to-Image Synthesis. (arXiv:2209.08891v3 [cs.CV] UPDATED)\nAbstract: Models for text-to-image synthesis, such as DALL-E~2 and Stable Diffusion, have recently drawn a lot of interest from academia and the general public. These models are capable of producing high-quality images that depict a variety of concepts and styles when conditioned on textual descriptions. However, these models adopt cultural characteristics associated with specific Unicode scripts from their vast amount of training data, which may not be immediately apparent. We show that by simply inserting single non-Latin characters in a textual description, common models reflect cultural stereotypes and biases in their generated images. We analyze this behavior both qualitatively and quantitatively, and identify a model's text encoder as the root cause of the phenomenon. Additionally, malicious users or service providers may try to intentionally bias the image generation to create racist stereotypes by replacing Latin characters with similarly-looking characters from non-Latin scripts, so-cal",
    "path": "papers/22/09/2209.08891.json",
    "total_tokens": 938,
    "translated_title": "利用同形异义字在文本到图像合成中挖掘文化偏见",
    "translated_abstract": "文本到图像合成模型，例如DALL-E 2和Stable Diffusion，近年来吸引了学术界和广大公众的广泛关注。这些模型可以在文本描述的条件下生成描绘各种概念和风格的高质量图像。然而，这些模型从大量的训练数据中采用了与特定Unicode脚本相关的文化特征，这可能不会立即显现。我们展示了通过在文本描述中简单插入单个非拉丁字符，常见模型呈现出生成图像中的文化刻板印象和偏见。我们定性和定量分析了这种行为，并确定了模型的文本编码器是这一现象的根本原因。此外，恶意用户或服务提供商可能试图意图性地通过将拉丁字符替换为非拉丁脚本中外形相似的字符，来引入偏见，创造种族主义刻板印象。",
    "tldr": "研究表明，在文本到图像合成过程中，通过插入异形字，模型会反映生成图片中的文化刻板印象和偏见。这一现象的根本原因是模型的文本编码器。而恶意用户或服务提供商还可能利用类似外形的非拉丁字符，故意引入偏见，创造种族主义刻板印象。"
}