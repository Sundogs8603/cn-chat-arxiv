{
    "title": "PreSTU: Pre-Training for Scene-Text Understanding. (arXiv:2209.05534v3 [cs.CV] UPDATED)",
    "abstract": "The ability to recognize and reason about text embedded in visual inputs is often lacking in vision-and-language (V&L) models, perhaps because V&L pre-training methods have often failed to include such an ability in their training objective. In this paper, we propose PreSTU, a novel pre-training recipe dedicated to scene-text understanding (STU). PreSTU introduces OCR-aware pre-training objectives that encourage the model to recognize text from an image and connect it to the rest of the image content. We implement PreSTU using a simple transformer-based encoder-decoder architecture, combined with large-scale image-text datasets with scene text obtained from an off-the-shelf OCR system. We empirically demonstrate the effectiveness of this pre-training approach on eight visual question answering and four image captioning benchmarks.",
    "link": "http://arxiv.org/abs/2209.05534",
    "context": "Title: PreSTU: Pre-Training for Scene-Text Understanding. (arXiv:2209.05534v3 [cs.CV] UPDATED)\nAbstract: The ability to recognize and reason about text embedded in visual inputs is often lacking in vision-and-language (V&L) models, perhaps because V&L pre-training methods have often failed to include such an ability in their training objective. In this paper, we propose PreSTU, a novel pre-training recipe dedicated to scene-text understanding (STU). PreSTU introduces OCR-aware pre-training objectives that encourage the model to recognize text from an image and connect it to the rest of the image content. We implement PreSTU using a simple transformer-based encoder-decoder architecture, combined with large-scale image-text datasets with scene text obtained from an off-the-shelf OCR system. We empirically demonstrate the effectiveness of this pre-training approach on eight visual question answering and four image captioning benchmarks.",
    "path": "papers/22/09/2209.05534.json",
    "total_tokens": 839,
    "translated_title": "PreSTU: 场景文本理解的预训练方法",
    "translated_abstract": "在视觉与语言模型中，对于嵌入在视觉输入中的文本进行识别和推理的能力通常是缺乏的，可能是因为视觉与语言的预训练方法在其训练目标中往往没有包括这种能力。在本文中，我们提出了一种名为PreSTU的新型预训练方法，专注于场景文本理解。PreSTU引入了OCR感知的预训练目标，鼓励模型识别图像中的文本并将其与图像的其他内容连接起来。我们使用基于transformer编码器-解码器架构和大规模图像文本数据集实现了PreSTU，其中的场景文本来自现成的OCR系统。我们通过在八个视觉问答和四个图像字幕基准上进行实证，验证了这种预训练方法的有效性。",
    "tldr": "PreSTU是一种针对场景文本理解的预训练方法，通过引入OCR感知的预训练目标，可以提高模型对于图像中嵌入文本的识别和连接能力，并在多个视觉问答和图像字幕基准上展示了其有效性。",
    "en_tdlr": "PreSTU is a pre-training method dedicated to scene-text understanding, which improves the model's ability to recognize and connect text embedded in images by introducing OCR-aware pre-training objectives. It has been demonstrated to be effective on various visual question answering and image captioning benchmarks."
}