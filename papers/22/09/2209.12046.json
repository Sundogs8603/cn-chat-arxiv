{
    "title": "Blinder: End-to-end Privacy Protection in Sensing Systems via Personalized Federated Learning. (arXiv:2209.12046v3 [cs.LG] UPDATED)",
    "abstract": "This paper proposes a sensor data anonymization model that is trained on decentralized data and strikes a desirable trade-off between data utility and privacy, even in heterogeneous settings where the sensor data have different underlying distributions. Our anonymization model, dubbed Blinder, is based on a variational autoencoder and one or multiple discriminator networks trained in an adversarial fashion. We use the model-agnostic meta-learning framework to adapt the anonymization model trained via federated learning to each user's data distribution. We evaluate Blinder under different settings and show that it provides end-to-end privacy protection on two IMU datasets at the cost of increasing privacy loss by up to 4.00% and decreasing data utility by up to 4.24%, compared to the state-of-the-art anonymization model trained on centralized data. We also showcase Blinder's ability to anonymize the radio frequency sensing modality. Our experiments confirm that Blinder can obscure multi",
    "link": "http://arxiv.org/abs/2209.12046",
    "context": "Title: Blinder: End-to-end Privacy Protection in Sensing Systems via Personalized Federated Learning. (arXiv:2209.12046v3 [cs.LG] UPDATED)\nAbstract: This paper proposes a sensor data anonymization model that is trained on decentralized data and strikes a desirable trade-off between data utility and privacy, even in heterogeneous settings where the sensor data have different underlying distributions. Our anonymization model, dubbed Blinder, is based on a variational autoencoder and one or multiple discriminator networks trained in an adversarial fashion. We use the model-agnostic meta-learning framework to adapt the anonymization model trained via federated learning to each user's data distribution. We evaluate Blinder under different settings and show that it provides end-to-end privacy protection on two IMU datasets at the cost of increasing privacy loss by up to 4.00% and decreasing data utility by up to 4.24%, compared to the state-of-the-art anonymization model trained on centralized data. We also showcase Blinder's ability to anonymize the radio frequency sensing modality. Our experiments confirm that Blinder can obscure multi",
    "path": "papers/22/09/2209.12046.json",
    "total_tokens": 1015,
    "translated_title": "Blinder: 通过个性化联合学习实现感知系统的端到端隐私保护",
    "translated_abstract": "本论文提出了一种基于分散数据训练的传感器数据匿名化模型，能够在传感器数据具有不同基础分布的异构环境中，在数据效用和隐私之间取得可取的平衡。我们的匿名化模型名为Blinder，基于变分自编码器和一个或多个对抗训练的鉴别器网络。我们使用模型无关元学习框架，将通过联合学习训练的匿名化模型适应到每个用户的数据分布上。我们在不同设置下评估了Blinder，并展示了与在集中数据上训练的最先进匿名化模型相比，Blinder在两个IMU数据集上提供了端到端的隐私保护，造成的隐私损失增加最多4.00%，数据效用降低最多4.24%。我们还展示了Blinder匿名化射频感知模态的能力。实验证实了Blinder能够模糊多个传感器模态同时进行匿名化。",
    "tldr": "本论文提出了一种基于个性化联合学习的Blinder匿名化模型，能在异构环境中提供端到端的隐私保护。与在集中数据上训练的最先进模型相比，Blinder在保护隐私的同时，仅增加最多4.00%的隐私损失，并降低最多4.24%的数据效用。同时，Blinder还展示了匿名化射频感知模态的能力。",
    "en_tdlr": "This paper proposes Blinder, a personalized federated learning model that provides end-to-end privacy protection in sensing systems. Compared to state-of-the-art models trained on centralized data, Blinder achieves a desirable trade-off between data utility and privacy, with a maximum privacy loss increase of 4.00% and a maximum data utility decrease of 4.24%. Additionally, Blinder demonstrates the ability to anonymize the radio frequency sensing modality."
}