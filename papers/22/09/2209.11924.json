{
    "title": "Interventional Causal Representation Learning",
    "abstract": "arXiv:2209.11924v4 Announce Type: replace-cross  Abstract: Causal representation learning seeks to extract high-level latent factors from low-level sensory data. Most existing methods rely on observational data and structural assumptions (e.g., conditional independence) to identify the latent factors. However, interventional data is prevalent across applications. Can interventional data facilitate causal representation learning? We explore this question in this paper. The key observation is that interventional data often carries geometric signatures of the latent factors' support (i.e. what values each latent can possibly take). For example, when the latent factors are causally connected, interventions can break the dependency between the intervened latents' support and their ancestors'. Leveraging this fact, we prove that the latent causal factors can be identified up to permutation and scaling given data from perfect $do$ interventions. Moreover, we can achieve block affine identific",
    "link": "https://arxiv.org/abs/2209.11924",
    "context": "Title: Interventional Causal Representation Learning\nAbstract: arXiv:2209.11924v4 Announce Type: replace-cross  Abstract: Causal representation learning seeks to extract high-level latent factors from low-level sensory data. Most existing methods rely on observational data and structural assumptions (e.g., conditional independence) to identify the latent factors. However, interventional data is prevalent across applications. Can interventional data facilitate causal representation learning? We explore this question in this paper. The key observation is that interventional data often carries geometric signatures of the latent factors' support (i.e. what values each latent can possibly take). For example, when the latent factors are causally connected, interventions can break the dependency between the intervened latents' support and their ancestors'. Leveraging this fact, we prove that the latent causal factors can be identified up to permutation and scaling given data from perfect $do$ interventions. Moreover, we can achieve block affine identific",
    "path": "papers/22/09/2209.11924.json",
    "total_tokens": 790,
    "translated_title": "干预因果表示学习",
    "translated_abstract": "因果表示学习旨在从低级感官数据中提取高级潜在因素。大多数现有方法依赖于观测数据和结构假设（如条件独立性）来识别潜在因素。然而，干预数据在各种应用中普遍存在。干预数据能否促进因果表示学习？本文探讨了这个问题。关键观察是，干预数据通常携带潜在因素支持的几何特征（即每个潜在因素可能采取的值）。举例来说，当潜在因素存在因果联系时，干预可以打破干预潜在因素支持和它们祖先之间的依赖关系。利用这一事实，我们证明在获得完美$do$干预数据后，可以确定潜在的因果因素，而且能够实现区块仿射识别。",
    "tldr": "干预数据有助于因果表示学习，可以通过干预数据中潜在因素支持的几何特征来识别潜在的因果因素。"
}