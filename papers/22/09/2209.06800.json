{
    "title": "MGG: Accelerating Graph Neural Networks with Fine-grained intra-kernel Communication-Computation Pipelining on Multi-GPU Platforms. (arXiv:2209.06800v2 [cs.DC] UPDATED)",
    "abstract": "The increasing size of input graphs for graph neural networks (GNNs) highlights the demand for using multi-GPU platforms. However, existing multi-GPU GNN systems optimize the computation and communication individually based on the conventional practice of scaling dense DNNs. For irregularly sparse and fine-grained GNN workloads, such solutions miss the opportunity to jointly schedule/optimize the computation and communication operations for high-performance delivery. To this end, we propose MGG, a novel system design to accelerate full-graph GNNs on multi-GPU platforms. The core of MGG is its novel dynamic software pipeline to facilitate fine-grained computation-communication overlapping within a GPU kernel. Specifically, MGG introduces GNN-tailored pipeline construction and GPU-aware pipeline mapping to facilitate workload balancing and operation overlapping. MGG also incorporates an intelligent runtime design with analytical modeling and optimization heuristics to dynamically improve",
    "link": "http://arxiv.org/abs/2209.06800",
    "context": "Title: MGG: Accelerating Graph Neural Networks with Fine-grained intra-kernel Communication-Computation Pipelining on Multi-GPU Platforms. (arXiv:2209.06800v2 [cs.DC] UPDATED)\nAbstract: The increasing size of input graphs for graph neural networks (GNNs) highlights the demand for using multi-GPU platforms. However, existing multi-GPU GNN systems optimize the computation and communication individually based on the conventional practice of scaling dense DNNs. For irregularly sparse and fine-grained GNN workloads, such solutions miss the opportunity to jointly schedule/optimize the computation and communication operations for high-performance delivery. To this end, we propose MGG, a novel system design to accelerate full-graph GNNs on multi-GPU platforms. The core of MGG is its novel dynamic software pipeline to facilitate fine-grained computation-communication overlapping within a GPU kernel. Specifically, MGG introduces GNN-tailored pipeline construction and GPU-aware pipeline mapping to facilitate workload balancing and operation overlapping. MGG also incorporates an intelligent runtime design with analytical modeling and optimization heuristics to dynamically improve",
    "path": "papers/22/09/2209.06800.json",
    "total_tokens": 874,
    "translated_title": "MGG: 多GPU平台上通过精细的内核通信计算流水线加速图神经网络",
    "translated_abstract": "图神经网络（GNNs）输入图的大小越来越大，需要使用多GPU平台。然而，现有的多GPU GNN系统仅基于传统做法缩放稠密DNN，优化计算和通信操作，对于不规则稀疏的GNN工作负载，缺失同时调度优化计算和通信操作以提高性能的机会。因此，我们提出了MGG，这是一种新的系统设计，可以在多GPU平台上加速全图GNN。MGG的核心是其新颖的动态软件流水线，以促进GPU内部精细的计算通信重叠。具体而言，MGG引入了适用于GNN的流水线构建和GPU感知的流水线映射，以促进工作负载平衡和操作重叠。MGG还结合了智能的运行时设计和分析建模和优化启发式方法，以动态改进性能。",
    "tldr": "MGG是一种软件流水线设计，可在多GPU平台上加速GNNs，通过采用GNN特殊的流水线构建和GPU感知的流水线映射，实现精细计算通信重叠以提高性能。",
    "en_tdlr": "MGG is a novel software pipeline design that accelerates GNNs on multi-GPU platforms by implementing fine-grained computation-communication overlapping through GNN-tailored pipeline construction and GPU-aware pipeline mapping."
}