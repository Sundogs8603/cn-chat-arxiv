{
    "title": "Bridging Implicit and Explicit Geometric Transformation for Single-Image View Synthesis",
    "abstract": "arXiv:2209.07105v3 Announce Type: replace-cross  Abstract: Creating novel views from a single image has achieved tremendous strides with advanced autoregressive models, as unseen regions have to be inferred from the visible scene contents. Although recent methods generate high-quality novel views, synthesizing with only one explicit or implicit 3D geometry has a trade-off between two objectives that we call the \"seesaw\" problem: 1) preserving reprojected contents and 2) completing realistic out-of-view regions. Also, autoregressive models require a considerable computational cost. In this paper, we propose a single-image view synthesis framework for mitigating the seesaw problem while utilizing an efficient non-autoregressive model. Motivated by the characteristics that explicit methods well preserve reprojected pixels and implicit methods complete realistic out-of-view regions, we introduce a loss function to complement two renderers. Our loss function promotes that explicit features ",
    "link": "https://arxiv.org/abs/2209.07105",
    "context": "Title: Bridging Implicit and Explicit Geometric Transformation for Single-Image View Synthesis\nAbstract: arXiv:2209.07105v3 Announce Type: replace-cross  Abstract: Creating novel views from a single image has achieved tremendous strides with advanced autoregressive models, as unseen regions have to be inferred from the visible scene contents. Although recent methods generate high-quality novel views, synthesizing with only one explicit or implicit 3D geometry has a trade-off between two objectives that we call the \"seesaw\" problem: 1) preserving reprojected contents and 2) completing realistic out-of-view regions. Also, autoregressive models require a considerable computational cost. In this paper, we propose a single-image view synthesis framework for mitigating the seesaw problem while utilizing an efficient non-autoregressive model. Motivated by the characteristics that explicit methods well preserve reprojected pixels and implicit methods complete realistic out-of-view regions, we introduce a loss function to complement two renderers. Our loss function promotes that explicit features ",
    "path": "papers/22/09/2209.07105.json",
    "total_tokens": 858,
    "translated_title": "将隐式和显式几何变换桥接用于单图像视图合成",
    "translated_abstract": "用先进的自回归模型从单个图像中创建新视图已经取得了巨大进展，因为不可见区域必须从可见场景内容中推断出来。尽管最近的方法生成了高质量的新视图，但只使用一个显式或隐式的3D几何体进行合成存在两个目标之间的折衷，我们称之为“跷跷板”问题：1）保留重新投影的内容，2）完成逼真的视野之外区域。此外，自回归模型需要相当大的计算成本。在本文中，我们提出了一个单图像视图合成框架，用于缓解“跷跷板”问题，同时利用高效的非自回归模型。受到显式方法很好地保留重新投影像素和隐式方法完成逼真视野外区域的特点的启发，我们引入了一个损失函数来补充两个渲染器。我们的损失函数促进了显式特征",
    "tldr": "提出了一种单图像视图合成框架，通过结合显式和隐式的几何变换，利用高效的非自回归模型，解决了“跷跷板”问题。",
    "en_tdlr": "Propose a single-image view synthesis framework that addresses the \"seesaw\" problem by combining explicit and implicit geometric transformations, utilizing an efficient non-autoregressive model."
}