{
    "title": "Adversarial Catoptric Light: An Effective, Stealthy and Robust Physical-World Attack to DNNs. (arXiv:2209.11739v2 [cs.CV] UPDATED)",
    "abstract": "Deep neural networks (DNNs) have demonstrated exceptional success across various tasks, underscoring the need to evaluate the robustness of advanced DNNs. However, traditional methods using stickers as physical perturbations to deceive classifiers present challenges in achieving stealthiness and suffer from printing loss. Recent advancements in physical attacks have utilized light beams such as lasers and projectors to perform attacks, where the optical patterns generated are artificial rather than natural. In this study, we introduce a novel physical attack, adversarial catoptric light (AdvCL), where adversarial perturbations are generated using a common natural phenomenon, catoptric light, to achieve stealthy and naturalistic adversarial attacks against advanced DNNs in a black-box setting. We evaluate the proposed method in three aspects: effectiveness, stealthiness, and robustness. Quantitative results obtained in simulated environments demonstrate the effectiveness of the proposed",
    "link": "http://arxiv.org/abs/2209.11739",
    "context": "Title: Adversarial Catoptric Light: An Effective, Stealthy and Robust Physical-World Attack to DNNs. (arXiv:2209.11739v2 [cs.CV] UPDATED)\nAbstract: Deep neural networks (DNNs) have demonstrated exceptional success across various tasks, underscoring the need to evaluate the robustness of advanced DNNs. However, traditional methods using stickers as physical perturbations to deceive classifiers present challenges in achieving stealthiness and suffer from printing loss. Recent advancements in physical attacks have utilized light beams such as lasers and projectors to perform attacks, where the optical patterns generated are artificial rather than natural. In this study, we introduce a novel physical attack, adversarial catoptric light (AdvCL), where adversarial perturbations are generated using a common natural phenomenon, catoptric light, to achieve stealthy and naturalistic adversarial attacks against advanced DNNs in a black-box setting. We evaluate the proposed method in three aspects: effectiveness, stealthiness, and robustness. Quantitative results obtained in simulated environments demonstrate the effectiveness of the proposed",
    "path": "papers/22/09/2209.11739.json",
    "total_tokens": 945,
    "translated_title": "对DNN的攻击的有效、隐秘和强大的物理世界攻击：对抗性镜面光",
    "translated_abstract": "深度神经网络（DNN）在各种任务中展示了异常的成功，凸显了评估先进DNN的稳健性的必要性。然而，传统的使用贴纸作为物理扰动欺骗分类器的方法在实现隐秘性和印刷损失方面存在挑战。最近在物理攻击方面的进展利用了光束（如激光器和投影仪）执行攻击，所生成的光学图案是人造的，而不是自然的。在本研究中，我们介绍了一种新颖的物理攻击，即对抗性镜面光（AdvCL），其中使用常见的自然现象——镜面光产生对抗性扰动，以在黑盒模式下实现先进DNN的隐秘和自然的对抗性攻击。我们从三个方面评估了所提出的方法：有效性、隐秘性和稳健性。在模拟环境下获得的定量结果展示了所提出的方法的有效性。",
    "tldr": "本研究介绍了一种对抗性镜面光物理攻击方法，利用镜面光产生对抗性扰动以实现对先进DNN的隐秘和自然的攻击，在模拟环境下取得了有效性的结果。"
}