{
    "title": "Variationally Mimetic Operator Networks. (arXiv:2209.12871v3 [math.NA] UPDATED)",
    "abstract": "In recent years operator networks have emerged as promising deep learning tools for approximating the solution to partial differential equations (PDEs). These networks map input functions that describe material properties, forcing functions and boundary data to the solution of a PDE. This work describes a new architecture for operator networks that mimics the form of the numerical solution obtained from an approximate variational or weak formulation of the problem. The application of these ideas to a generic elliptic PDE leads to a variationally mimetic operator network (VarMiON). Like the conventional Deep Operator Network (DeepONet) the VarMiON is also composed of a sub-network that constructs the basis functions for the output and another that constructs the coefficients for these basis functions. However, in contrast to the DeepONet, the architecture of these sub-networks in the VarMiON is precisely determined. An analysis of the error in the VarMiON solution reveals that it contai",
    "link": "http://arxiv.org/abs/2209.12871",
    "context": "Title: Variationally Mimetic Operator Networks. (arXiv:2209.12871v3 [math.NA] UPDATED)\nAbstract: In recent years operator networks have emerged as promising deep learning tools for approximating the solution to partial differential equations (PDEs). These networks map input functions that describe material properties, forcing functions and boundary data to the solution of a PDE. This work describes a new architecture for operator networks that mimics the form of the numerical solution obtained from an approximate variational or weak formulation of the problem. The application of these ideas to a generic elliptic PDE leads to a variationally mimetic operator network (VarMiON). Like the conventional Deep Operator Network (DeepONet) the VarMiON is also composed of a sub-network that constructs the basis functions for the output and another that constructs the coefficients for these basis functions. However, in contrast to the DeepONet, the architecture of these sub-networks in the VarMiON is precisely determined. An analysis of the error in the VarMiON solution reveals that it contai",
    "path": "papers/22/09/2209.12871.json",
    "total_tokens": 803,
    "translated_title": "变分拟态算子网络",
    "translated_abstract": "最近，算子网络已经成为近似解决偏微分方程（PDEs）的有希望的深度学习工具。这些网络将描述材料属性、强迫函数和边界数据的输入函数映射到PDE的解。本文描述了一种新的算子网络架构，该架构模拟了从近似变分或弱形式问题中获得的数值解的形式。将这些思想应用于通用椭圆PDE，得到了一种变分拟态算子网络（VarMiON）。类似于传统的深度算子网络（DeepONet），VarMiON也由一个子网络和另一个子网络组成，用于构造输出的基函数和这些基函数的系数。然而，与DeepONet不同的是，VarMiON中这些子网络的架构是精确定义的。对VarMiON解的误差分析表明，它包含一些与传统算子网络不同的优点。",
    "tldr": "这项工作提出了一种新的算子网络架构，用于近似解决偏微分方程。这种架构模拟了从近似变分或弱形式问题中获得的数值解的形式，可以提高解的准确性。"
}