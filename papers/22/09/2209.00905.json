{
    "title": "From latent dynamics to meaningful representations. (arXiv:2209.00905v2 [cs.LG] UPDATED)",
    "abstract": "While representation learning has been central to the rise of machine learning and artificial intelligence, a key problem remains in making the learnt representations meaningful. For this the typical approach is to regularize the learned representation through prior probability distributions. However such priors are usually unavailable or ad hoc. To deal with this, we propose a dynamics-constrained representation learning framework. Instead of using predefined probabilities, we restrict the latent representation to follow specific dynamics, which is a more natural constraint for representation learning in dynamical systems. Our belief stems from a fundamental observation in physics that though different systems can have different marginalized probability distributions, they typically obey the same dynamics, such as Newton's and Schrodinger's equations. We validate our framework for different systems including a real-world fluorescent DNA movie dataset. We show that our algorithm can un",
    "link": "http://arxiv.org/abs/2209.00905",
    "context": "Title: From latent dynamics to meaningful representations. (arXiv:2209.00905v2 [cs.LG] UPDATED)\nAbstract: While representation learning has been central to the rise of machine learning and artificial intelligence, a key problem remains in making the learnt representations meaningful. For this the typical approach is to regularize the learned representation through prior probability distributions. However such priors are usually unavailable or ad hoc. To deal with this, we propose a dynamics-constrained representation learning framework. Instead of using predefined probabilities, we restrict the latent representation to follow specific dynamics, which is a more natural constraint for representation learning in dynamical systems. Our belief stems from a fundamental observation in physics that though different systems can have different marginalized probability distributions, they typically obey the same dynamics, such as Newton's and Schrodinger's equations. We validate our framework for different systems including a real-world fluorescent DNA movie dataset. We show that our algorithm can un",
    "path": "papers/22/09/2209.00905.json",
    "total_tokens": 911,
    "translated_title": "从潜在动力学到有意义的表示法",
    "translated_abstract": "虽然表示学习已成为机器学习和人工智能崛起的核心，但一个关键问题仍然是使学习到的表示具有意义。为此，典型的方法是通过先验概率分布来规范学习到的表示。然而，这样的先验通常是不可用或临时的。为了解决这个问题，我们提出了一个动力学约束的表示学习框架。我们不使用预定义的概率，而是限制潜在表示遵循特定的动态规律，这是动态系统表示学习更自然的约束。我们的信仰源于物理学中的一个基本观察，即虽然不同的系统可以有不同的边际概率分布，但通常遵循相同的动态规律，例如牛顿和薛定谔方程。我们对不同系统验证了我们的框架，包括一个真实世界的荧光DNA电影数据集。我们展示了我们的算法可以准确地学习动态规律，并获得有意义的表示。",
    "tldr": "本文提出了一个动力学约束的表示学习框架，通过限制潜在表示遵循特定动态规律以使得学习到的表示具有意义。在真实世界的DNA荧光电影数据集上验证了该算法，表明其可以准确地学习动态规律，并获得有意义的表示。"
}