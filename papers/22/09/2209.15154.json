{
    "title": "Variable-Based Calibration for Machine Learning Classifiers. (arXiv:2209.15154v3 [cs.LG] UPDATED)",
    "abstract": "The deployment of machine learning classifiers in high-stakes domains requires well-calibrated confidence scores for model predictions. In this paper we introduce the notion of variable-based calibration to characterize calibration properties of a model with respect to a variable of interest, generalizing traditional score-based metrics such as expected calibration error (ECE). In particular, we find that models with near-perfect ECE can exhibit significant miscalibration as a function of features of the data. We demonstrate this phenomenon both theoretically and in practice on multiple well-known datasets, and show that it can persist after the application of existing calibration methods. To mitigate this issue, we propose strategies for detection, visualization, and quantification of variable-based calibration error. We then examine the limitations of current score-based calibration methods and explore potential modifications. Finally, we discuss the implications of these findings, e",
    "link": "http://arxiv.org/abs/2209.15154",
    "context": "Title: Variable-Based Calibration for Machine Learning Classifiers. (arXiv:2209.15154v3 [cs.LG] UPDATED)\nAbstract: The deployment of machine learning classifiers in high-stakes domains requires well-calibrated confidence scores for model predictions. In this paper we introduce the notion of variable-based calibration to characterize calibration properties of a model with respect to a variable of interest, generalizing traditional score-based metrics such as expected calibration error (ECE). In particular, we find that models with near-perfect ECE can exhibit significant miscalibration as a function of features of the data. We demonstrate this phenomenon both theoretically and in practice on multiple well-known datasets, and show that it can persist after the application of existing calibration methods. To mitigate this issue, we propose strategies for detection, visualization, and quantification of variable-based calibration error. We then examine the limitations of current score-based calibration methods and explore potential modifications. Finally, we discuss the implications of these findings, e",
    "path": "papers/22/09/2209.15154.json",
    "total_tokens": 876,
    "translated_title": "可变校准机器学习分类器",
    "translated_abstract": "在高风险领域部署机器学习分类器需要有良好校准信心分数以预测模型。本文介绍了可变校准的概念来描述模型在特定兴趣变量方面的调节属性，将传统的基于得分的指标如预期校准误差（ECE）进行推广。通过理论和实践在多个知名数据集上演示了即使拥有接近完美 ECE 的模型在数据特征方面还是可能存在显著的校准失误，而且这种校准失误可能在应用现有的校准方法后还会持续存在。为了减轻这个问题，我们提出了检测、可视化和定量化可变校准误差的策略。接着我们分析了当前得分校准方法的局限性并探讨了潜在的修改方法。最后，我们讨论了这些发现的启示。",
    "tldr": "提出可变校准的概念，并发现在数据特征方面即使拥有良好 ECE 的模型还是可能存在显著的校准失误，为此提出了检测、可视化和定量化可变校准误差的策略。"
}