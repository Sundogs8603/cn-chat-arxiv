{
    "title": "Ensemble Reinforcement Learning in Continuous Spaces -- A Hierarchical Multi-Step Approach for Policy Training. (arXiv:2209.14488v2 [cs.LG] UPDATED)",
    "abstract": "Actor-critic deep reinforcement learning (DRL) algorithms have recently achieved prominent success in tackling various challenging reinforcement learning (RL) problems, particularly complex control tasks with high-dimensional continuous state and action spaces. Nevertheless, existing research showed that actor-critic DRL algorithms often failed to explore their learning environments effectively, resulting in limited learning stability and performance. To address this limitation, several ensemble DRL algorithms have been proposed lately to boost exploration and stabilize the learning process. However, most of existing ensemble algorithms do not explicitly train all base learners towards jointly optimizing the performance of the ensemble. In this paper, we propose a new technique to train an ensemble of base learners based on an innovative multi-step integration method. This training technique enables us to develop a new hierarchical learning algorithm for ensemble DRL that effectively p",
    "link": "http://arxiv.org/abs/2209.14488",
    "context": "Title: Ensemble Reinforcement Learning in Continuous Spaces -- A Hierarchical Multi-Step Approach for Policy Training. (arXiv:2209.14488v2 [cs.LG] UPDATED)\nAbstract: Actor-critic deep reinforcement learning (DRL) algorithms have recently achieved prominent success in tackling various challenging reinforcement learning (RL) problems, particularly complex control tasks with high-dimensional continuous state and action spaces. Nevertheless, existing research showed that actor-critic DRL algorithms often failed to explore their learning environments effectively, resulting in limited learning stability and performance. To address this limitation, several ensemble DRL algorithms have been proposed lately to boost exploration and stabilize the learning process. However, most of existing ensemble algorithms do not explicitly train all base learners towards jointly optimizing the performance of the ensemble. In this paper, we propose a new technique to train an ensemble of base learners based on an innovative multi-step integration method. This training technique enables us to develop a new hierarchical learning algorithm for ensemble DRL that effectively p",
    "path": "papers/22/09/2209.14488.json",
    "total_tokens": 867,
    "translated_title": "连续空间中的集成强化学习——一种多步层次策略训练方法",
    "translated_abstract": "最近，演员-评论家深度强化学习算法在解决各种具有高维连续状态和动作空间的复杂控制任务方面取得了杰出的成功。然而，现有的研究表明，演员-评论家强化学习算法通常无法有效地探索其学习环境，导致有限的学习稳定性和性能。为了解决这个问题，最近提出了几种集成强化学习算法来增加探索并稳定学习过程。然而，现有大多数集成算法没有明确地训练所有基学习器以共同优化集成的性能。本文提出了一种基于创新的多步集成方法来训练基学习器集成的新技术。这种训练技术使我们能够开发一种新的层次集成强化学习算法，有效地提高了学习稳定性和性能。",
    "tldr": "本文提出了一种新的集成强化学习算法，基于多步层次策略训练方法来训练基学习器集成，以提高学习稳定性和性能。",
    "en_tdlr": "This paper proposes a new ensemble reinforcement learning algorithm based on a hierarchical multi-step training method to train the base learners to jointly optimize the performance of the ensemble. This technique improves learning stability and performance for complex control tasks with high-dimensional continuous state and action spaces."
}