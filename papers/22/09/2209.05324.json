{
    "title": "Delving into the Devils of Bird's-eye-view Perception: A Review, Evaluation and Recipe. (arXiv:2209.05324v3 [cs.CV] UPDATED)",
    "abstract": "Learning powerful representations in bird's-eye-view (BEV) for perception tasks is trending and drawing extensive attention both from industry and academia. Conventional approaches for most autonomous driving algorithms perform detection, segmentation, tracking, etc., in a front or perspective view. As sensor configurations get more complex, integrating multi-source information from different sensors and representing features in a unified view come of vital importance. BEV perception inherits several advantages, as representing surrounding scenes in BEV is intuitive and fusion-friendly; and representing objects in BEV is most desirable for subsequent modules as in planning and/or control. The core problems for BEV perception lie in (a) how to reconstruct the lost 3D information via view transformation from perspective view to BEV; (b) how to acquire ground truth annotations in BEV grid; (c) how to formulate the pipeline to incorporate features from different sources and views; and (d) ",
    "link": "http://arxiv.org/abs/2209.05324",
    "context": "Title: Delving into the Devils of Bird's-eye-view Perception: A Review, Evaluation and Recipe. (arXiv:2209.05324v3 [cs.CV] UPDATED)\nAbstract: Learning powerful representations in bird's-eye-view (BEV) for perception tasks is trending and drawing extensive attention both from industry and academia. Conventional approaches for most autonomous driving algorithms perform detection, segmentation, tracking, etc., in a front or perspective view. As sensor configurations get more complex, integrating multi-source information from different sensors and representing features in a unified view come of vital importance. BEV perception inherits several advantages, as representing surrounding scenes in BEV is intuitive and fusion-friendly; and representing objects in BEV is most desirable for subsequent modules as in planning and/or control. The core problems for BEV perception lie in (a) how to reconstruct the lost 3D information via view transformation from perspective view to BEV; (b) how to acquire ground truth annotations in BEV grid; (c) how to formulate the pipeline to incorporate features from different sources and views; and (d) ",
    "path": "papers/22/09/2209.05324.json",
    "total_tokens": 907,
    "translated_title": "探索鸟瞰视角感知中的挑战：一项综述、评估和方法",
    "translated_abstract": "在感知任务中，学习鸟瞰视角（BEV）的强大表示正变得越来越流行，并引起了业界和学术界的广泛关注。传统方法中，大多数自动驾驶算法在前方或透视视图中进行检测、分割、跟踪等操作。随着传感器配置越来越复杂，从不同传感器中集成多源信息并以统一的视图表示特征变得非常重要。BEV感知具有几个优势，即以BEV表示周围场景直观且易于融合；以BEV表示物体对于后续的规划和/或控制模块是最理想的。BEV感知的核心问题在于：（a）如何通过从透视视图到BEV的视角转换重建丢失的3D信息；（b）如何在BEV网格中获取地面真值注释；（c）如何构建包含来自不同来源和视图的特征的流程；以及（d）...",
    "tldr": "本综述文章探讨了鸟瞰视角感知领域的挑战和方法，主要关注了从透视视图到鸟瞰视图的信息转换、地面真值注释获取、特征融合以及整体流程的构建。"
}