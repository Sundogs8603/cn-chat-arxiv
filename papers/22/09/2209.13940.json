{
    "title": "Revamping Multilingual Agreement Bidirectionally via Switched Back-translation for Multilingual Neural Machine Translation. (arXiv:2209.13940v3 [cs.CL] UPDATED)",
    "abstract": "Despite the fact that multilingual agreement (MA) has shown its importance for multilingual neural machine translation (MNMT), current methodologies in the field have two shortages: (i) require parallel data between multiple language pairs, which is not always realistic and (ii) optimize the agreement in an ambiguous direction, which hampers the translation performance. We present \\textbf{B}idirectional \\textbf{M}ultilingual \\textbf{A}greement via \\textbf{S}witched \\textbf{B}ack-\\textbf{t}ranslation (\\textbf{BMA-SBT}), a novel and universal multilingual agreement framework for fine-tuning pre-trained MNMT models, which (i) exempts the need for aforementioned parallel data by using a novel method called switched BT that creates synthetic text written in another source language using the translation target and (ii) optimizes the agreement bidirectionally with the Kullback-Leibler Divergence loss. Experiments indicate that BMA-SBT clearly improves the strong baselines on the task of MNMT ",
    "link": "http://arxiv.org/abs/2209.13940",
    "context": "Title: Revamping Multilingual Agreement Bidirectionally via Switched Back-translation for Multilingual Neural Machine Translation. (arXiv:2209.13940v3 [cs.CL] UPDATED)\nAbstract: Despite the fact that multilingual agreement (MA) has shown its importance for multilingual neural machine translation (MNMT), current methodologies in the field have two shortages: (i) require parallel data between multiple language pairs, which is not always realistic and (ii) optimize the agreement in an ambiguous direction, which hampers the translation performance. We present \\textbf{B}idirectional \\textbf{M}ultilingual \\textbf{A}greement via \\textbf{S}witched \\textbf{B}ack-\\textbf{t}ranslation (\\textbf{BMA-SBT}), a novel and universal multilingual agreement framework for fine-tuning pre-trained MNMT models, which (i) exempts the need for aforementioned parallel data by using a novel method called switched BT that creates synthetic text written in another source language using the translation target and (ii) optimizes the agreement bidirectionally with the Kullback-Leibler Divergence loss. Experiments indicate that BMA-SBT clearly improves the strong baselines on the task of MNMT ",
    "path": "papers/22/09/2209.13940.json",
    "total_tokens": 967,
    "translated_title": "通过 Switched Back-translation 对多语言神经机器翻译进行双向升级的多语言协议",
    "translated_abstract": "尽管多语言协议 (MA) 在多语言神经机器翻译 (MNMT) 中显示出其重要性，但当前领域中的方法存在两个缺点：(i)需要多个语言对之间的平行数据，这并不总是现实，并且(ii)在一个模棱两可的方向上优化协议，这会妨碍翻译的性能。我们提出了一种全新的通用多语言协议框架，名为经由 Switched Back-translation 的双向多语言协议 (BMA-SBT)，用于微调预训练的 MNMT 模型，它通过使用一种名为 switched BT 的新方法，在另一种源语言中创建用于翻译目标的合成文本，使得不需要前述的平行数据，并使用 Kullback-Leibler 散度损失双向优化协议。实验表明，BMA-SBT 在 MNMT 任务上明显改善了强基线的效果。",
    "tldr": "提出了一种名为 BMA-SBT 的新型通用多语言协议框架，通过使用 switched BT 方法，使得不需要平行数据就可以建立多语言协议，同时使用 Kullback-Leibler 散度损失双向优化协议，在 MNMT 任务上明显改善了强基线的效果。",
    "en_tdlr": "A novel multilingual agreement framework called BMA-SBT is proposed, which uses switched BT to construct multilingual agreement without using parallel data and optimizes the agreement bidirectionally with Kullback-Leibler Divergence loss, leading to significant improvements on the MNMT task compared to strong baselines."
}