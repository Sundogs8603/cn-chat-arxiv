{
    "title": "Pretraining the Vision Transformer using self-supervised methods for vision based Deep Reinforcement Learning. (arXiv:2209.10901v2 [cs.LG] UPDATED)",
    "abstract": "The Vision Transformer architecture has shown to be competitive in the computer vision (CV) space where it has dethroned convolution-based networks in several benchmarks. Nevertheless, convolutional neural networks (CNN) remain the preferential architecture for the representation module in reinforcement learning. In this work, we study pretraining a Vision Transformer using several state-of-the-art self-supervised methods and assess the quality of the learned representations. To show the importance of the temporal dimension in this context we propose an extension of VICReg to better capture temporal relations between observations by adding a temporal order verification task. Our results show that all methods are effective in learning useful representations and avoiding representational collapse for observations from Atari Learning Environment (ALE) which leads to improvements in data efficiency when we evaluated in reinforcement learning (RL). Moreover, the encoder pretrained with the ",
    "link": "http://arxiv.org/abs/2209.10901",
    "context": "Title: Pretraining the Vision Transformer using self-supervised methods for vision based Deep Reinforcement Learning. (arXiv:2209.10901v2 [cs.LG] UPDATED)\nAbstract: The Vision Transformer architecture has shown to be competitive in the computer vision (CV) space where it has dethroned convolution-based networks in several benchmarks. Nevertheless, convolutional neural networks (CNN) remain the preferential architecture for the representation module in reinforcement learning. In this work, we study pretraining a Vision Transformer using several state-of-the-art self-supervised methods and assess the quality of the learned representations. To show the importance of the temporal dimension in this context we propose an extension of VICReg to better capture temporal relations between observations by adding a temporal order verification task. Our results show that all methods are effective in learning useful representations and avoiding representational collapse for observations from Atari Learning Environment (ALE) which leads to improvements in data efficiency when we evaluated in reinforcement learning (RL). Moreover, the encoder pretrained with the ",
    "path": "papers/22/09/2209.10901.json",
    "total_tokens": 898,
    "translated_title": "使用自监督方法预训练视觉转换器用于基于视觉的深度强化学习",
    "translated_abstract": "视觉转换器架构在计算机视觉领域表现出竞争力，在几个基准测试中取代了基于卷积的网络。然而，在强化学习中，卷积神经网络仍然是表示模块的首选架构。本文研究了使用几种最先进的自监督方法来预训练视觉转换器，并评估所学表示的质量。为了展示在这个上下文中时间维度的重要性，我们提出了VICReg的扩展，通过添加一个时间顺序验证任务来更好地捕捉观测之间的时间关系。我们的结果表明，所有方法在学习有用的表示和避免在Atari Learning Environment (ALE)中观测数据上出现重复表示方面都是有效的，这导致了在强化学习中的数据效率提高。此外，使用预训练的编码器要比从头开始训练的模型在强化学习任务中表现更好。",
    "tldr": "本文研究了使用自监督方法预训练视觉转换器，并通过添加时间顺序验证任务来捕捉观测之间的时间关系。实验结果表明，这些方法在学习有用的表示和提高强化学习数据效率方面都很有效。"
}