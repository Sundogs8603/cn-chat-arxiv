{
    "title": "Learning GFlowNets from partial episodes for improved convergence and stability. (arXiv:2209.12782v3 [cs.LG] UPDATED)",
    "abstract": "Generative flow networks (GFlowNets) are a family of algorithms for training a sequential sampler of discrete objects under an unnormalized target density and have been successfully used for various probabilistic modeling tasks. Existing training objectives for GFlowNets are either local to states or transitions, or propagate a reward signal over an entire sampling trajectory. We argue that these alternatives represent opposite ends of a gradient bias-variance tradeoff and propose a way to exploit this tradeoff to mitigate its harmful effects. Inspired by the TD($\\lambda$) algorithm in reinforcement learning, we introduce subtrajectory balance or SubTB($\\lambda$), a GFlowNet training objective that can learn from partial action subsequences of varying lengths. We show that SubTB($\\lambda$) accelerates sampler convergence in previously studied and new environments and enables training GFlowNets in environments with longer action sequences and sparser reward landscapes than what was poss",
    "link": "http://arxiv.org/abs/2209.12782",
    "context": "Title: Learning GFlowNets from partial episodes for improved convergence and stability. (arXiv:2209.12782v3 [cs.LG] UPDATED)\nAbstract: Generative flow networks (GFlowNets) are a family of algorithms for training a sequential sampler of discrete objects under an unnormalized target density and have been successfully used for various probabilistic modeling tasks. Existing training objectives for GFlowNets are either local to states or transitions, or propagate a reward signal over an entire sampling trajectory. We argue that these alternatives represent opposite ends of a gradient bias-variance tradeoff and propose a way to exploit this tradeoff to mitigate its harmful effects. Inspired by the TD($\\lambda$) algorithm in reinforcement learning, we introduce subtrajectory balance or SubTB($\\lambda$), a GFlowNet training objective that can learn from partial action subsequences of varying lengths. We show that SubTB($\\lambda$) accelerates sampler convergence in previously studied and new environments and enables training GFlowNets in environments with longer action sequences and sparser reward landscapes than what was poss",
    "path": "papers/22/09/2209.12782.json",
    "total_tokens": 969,
    "translated_title": "从部分 episode 中学习 GFlowNets 以改善收敛性和稳定性",
    "translated_abstract": "生成流网络(GFlowNets)是一类算法，用于在未归一化的目标密度下对离散对象进行顺序采样训练，并已成功应用于各种概率建模任务中。现有的GFlowNets训练目标既可以局部关注状态或转换，也可以在整个采样轨迹上传播奖励信号。我们认为这些替代方案代表了梯度偏差—方差平衡的两端，并提出了一种利用这种平衡来减轻其有害影响的方法。受强化学习中的 TD($\\lambda$)算法的启发，我们引入了子轨迹平衡(SubTB($\\lambda$))，一种 GFlowNets 训练目标，可以从不同长度的部分动作子序列中学习。我们展示了 SubTB($\\lambda$) 加速了在先前研究过的和新的环境中的采样器收敛，并使得在动作序列更长、奖励更稀疏的环境中训练 GFlowNets 成为了可能。",
    "tldr": "本文提出了一种 GFlowNets 训练目标——子轨迹平衡(SubTB($\\lambda$))，从部分 episode 学习的方式可以加速采样器在环境中的收敛速度，并使得在之前难以训练的长动作序列和奖励稀疏的环境中也能够训练 GFlowNets。",
    "en_tdlr": "This paper proposes a GFlowNets training objective, SubTB($\\lambda$), which learns from partial action subsequences and can accelerate sampler convergence in both previously studied and new environments while enabling training GFlowNets in longer action sequences and sparser reward landscapes."
}