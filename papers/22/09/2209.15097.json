{
    "title": "Likelihood Adjusted Semidefinite Programs for Clustering Heterogeneous Data. (arXiv:2209.15097v2 [stat.ML] UPDATED)",
    "abstract": "Clustering is a widely deployed unsupervised learning tool. Model-based clustering is a flexible framework to tackle data heterogeneity when the clusters have different shapes. Likelihood-based inference for mixture distributions often involves non-convex and high-dimensional objective functions, imposing difficult computational and statistical challenges. The classic expectation-maximization (EM) algorithm is a computationally thrifty iterative method that maximizes a surrogate function minorizing the log-likelihood of observed data in each iteration, which however suffers from bad local maxima even in the special case of the standard Gaussian mixture model with common isotropic covariance matrices. On the other hand, recent studies reveal that the unique global solution of a semidefinite programming (SDP) relaxed $K$-means achieves the information-theoretically sharp threshold for perfectly recovering the cluster labels under the standard Gaussian mixture model. In this paper, we ext",
    "link": "http://arxiv.org/abs/2209.15097",
    "context": "Title: Likelihood Adjusted Semidefinite Programs for Clustering Heterogeneous Data. (arXiv:2209.15097v2 [stat.ML] UPDATED)\nAbstract: Clustering is a widely deployed unsupervised learning tool. Model-based clustering is a flexible framework to tackle data heterogeneity when the clusters have different shapes. Likelihood-based inference for mixture distributions often involves non-convex and high-dimensional objective functions, imposing difficult computational and statistical challenges. The classic expectation-maximization (EM) algorithm is a computationally thrifty iterative method that maximizes a surrogate function minorizing the log-likelihood of observed data in each iteration, which however suffers from bad local maxima even in the special case of the standard Gaussian mixture model with common isotropic covariance matrices. On the other hand, recent studies reveal that the unique global solution of a semidefinite programming (SDP) relaxed $K$-means achieves the information-theoretically sharp threshold for perfectly recovering the cluster labels under the standard Gaussian mixture model. In this paper, we ext",
    "path": "papers/22/09/2209.15097.json",
    "total_tokens": 984,
    "translated_title": "基于似然函数修正的半定规划方法用于异质数据聚类",
    "translated_abstract": "聚类是一种广泛使用的无监督学习工具。基于模型的聚类是一种灵活的框架，用来处理聚类具有不同形状的数据的异质性。对于混合分布的基于似然的推断通常涉及非凸和高维的目标函数，带来了复杂的计算和统计挑战。在本文中，我们将基于似然函数修正的半定规划（LA-SDP）方法应用于异质数据聚类。我们的方法通过一组新的矩阵不等式实现了似然函数调整的凸松弛。我们证明，在混合组分的一些温和的前提条件下，LA-SDP 可以一致而有效地计算出最大似然估计值。我们的实验表明，与现有的方法相比，尤其是当聚类显著异质时，我们的方法在合成数据和真实数据的实验中表现优异。",
    "tldr": "本论文提出了一种基于似然函数修正的半定规划方法用于异质数据聚类。经过实验表明，本方法在处理聚类形状不同的数据异质性时表现优异。",
    "en_tdlr": "This paper proposes a Likelihood Adjusted Semidefinite Programming (LA-SDP) method based on likelihood function adjustment for clustering heterogeneous data, which shows superior performance compared to state-of-the-art methods, especially with significantly heterogeneous clusters."
}