{
    "title": "Learning Symbolic Model-Agnostic Loss Functions via Meta-Learning. (arXiv:2209.08907v2 [cs.LG] UPDATED)",
    "abstract": "In this paper, we develop upon the emerging topic of loss function learning, which aims to learn loss functions that significantly improve the performance of the models trained under them. Specifically, we propose a new meta-learning framework for learning model-agnostic loss functions via a hybrid neuro-symbolic search approach. The framework first uses evolution-based methods to search the space of primitive mathematical operations to find a set of symbolic loss functions. Second, the set of learned loss functions are subsequently parameterized and optimized via an end-to-end gradient-based training procedure. The versatility of the proposed framework is empirically validated on a diverse set of supervised learning tasks. Results show that the meta-learned loss functions discovered by the newly proposed method outperform both the cross-entropy loss and state-of-the-art loss function learning methods on a diverse range of neural network architectures and datasets.",
    "link": "http://arxiv.org/abs/2209.08907",
    "context": "Title: Learning Symbolic Model-Agnostic Loss Functions via Meta-Learning. (arXiv:2209.08907v2 [cs.LG] UPDATED)\nAbstract: In this paper, we develop upon the emerging topic of loss function learning, which aims to learn loss functions that significantly improve the performance of the models trained under them. Specifically, we propose a new meta-learning framework for learning model-agnostic loss functions via a hybrid neuro-symbolic search approach. The framework first uses evolution-based methods to search the space of primitive mathematical operations to find a set of symbolic loss functions. Second, the set of learned loss functions are subsequently parameterized and optimized via an end-to-end gradient-based training procedure. The versatility of the proposed framework is empirically validated on a diverse set of supervised learning tasks. Results show that the meta-learned loss functions discovered by the newly proposed method outperform both the cross-entropy loss and state-of-the-art loss function learning methods on a diverse range of neural network architectures and datasets.",
    "path": "papers/22/09/2209.08907.json",
    "total_tokens": 832,
    "translated_title": "通过元学习学习符号模型无关损失函数",
    "translated_abstract": "本文研究损失函数学习的新兴主题，旨在学习可以显著提高模型性能的损失函数。我们提出了一种新的元学习框架，通过混合神经符号搜索方法学习模型无关的损失函数。该框架首先使用基于进化的方法在原始数学操作空间中搜索符号损失函数的集合。然后，学习到的一组损失函数通过端到端的梯度训练过程进行参数化和优化。所提出的框架的多功能性在一组多样化的监督学习任务上得到了经验证实。结果显示，新提出的方法发现的元学习损失函数在各种神经网络架构和数据集上均优于交叉熵损失和现有最先进的损失函数学习方法。",
    "tldr": "本文提出了一种通过元学习框架学习模型无关损失函数的方法，并通过对多个监督学习任务的实验证明，该方法学到的损失函数优于目前最优方法和交叉熵损失函数。",
    "en_tdlr": "This paper proposes a meta-learning framework for learning model-agnostic loss functions through a hybrid neuro-symbolic search approach, which outperforms both cross-entropy loss and state-of-the-art loss function learning methods on various neural network architectures and datasets."
}