{
    "title": "Seeking Interpretability and Explainability in Binary Activated Neural Networks. (arXiv:2209.03450v2 [cs.LG] UPDATED)",
    "abstract": "We study the use of binary activated neural networks as interpretable and explainable predictors in the context of regression tasks on tabular data; more specifically, we provide guarantees on their expressiveness, present an approach based on the efficient computation of SHAP values for quantifying the relative importance of the features, hidden neurons and even weights. As the model's simplicity is instrumental in achieving interpretability, we propose a greedy algorithm for building compact binary activated networks. This approach doesn't need to fix an architecture for the network in advance: it is built one layer at a time, one neuron at a time, leading to predictors that aren't needlessly complex for a given task.",
    "link": "http://arxiv.org/abs/2209.03450",
    "context": "Title: Seeking Interpretability and Explainability in Binary Activated Neural Networks. (arXiv:2209.03450v2 [cs.LG] UPDATED)\nAbstract: We study the use of binary activated neural networks as interpretable and explainable predictors in the context of regression tasks on tabular data; more specifically, we provide guarantees on their expressiveness, present an approach based on the efficient computation of SHAP values for quantifying the relative importance of the features, hidden neurons and even weights. As the model's simplicity is instrumental in achieving interpretability, we propose a greedy algorithm for building compact binary activated networks. This approach doesn't need to fix an architecture for the network in advance: it is built one layer at a time, one neuron at a time, leading to predictors that aren't needlessly complex for a given task.",
    "path": "papers/22/09/2209.03450.json",
    "total_tokens": 840,
    "translated_title": "在二进制激活神经网络中寻求解释性和可解释性",
    "translated_abstract": "我们研究了在表格数据的回归任务中，将二进制激活神经网络作为可解释和可解释的预测器的使用。具体而言，我们对它们的表达能力提供了保证，并提出了一种基于有效计算SHAP值的方法，用于量化特征、隐藏神经元甚至权重的相对重要性。由于模型的简单性在实现解释性方面起着关键作用，我们提出了一种贪婪算法，用于构建紧凑的二进制激活网络。这种方法不需要预先设定网络的架构：它逐层、逐个神经元地构建，使得对于给定任务，预测器不会过于复杂。",
    "tldr": "本论文研究了在表格数据回归任务中使用二进制激活神经网络作为可解释和可解释的预测器的方法。我们提供了对其表达能力的保证，并提出了一种基于SHAP值的方法来量化特征、隐藏神经元和权重的相对重要性。同时，我们提出了一种贪婪算法来构建紧凑的网络，以实现解释性。",
    "en_tdlr": "This paper studies the use of binary activated neural networks as interpretable and explainable predictors in regression tasks on tabular data. It provides guarantees on their expressiveness and presents an approach based on SHAP values to quantify the relative importance of features, hidden neurons, and weights. Additionally, a greedy algorithm is proposed to build compact networks for interpretability."
}