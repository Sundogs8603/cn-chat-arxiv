{
    "title": "Recipe Generation from Unsegmented Cooking Videos",
    "abstract": "arXiv:2209.10134v2 Announce Type: replace-cross  Abstract: This paper tackles recipe generation from unsegmented cooking videos, a task that requires agents to (1) extract key events in completing the dish and (2) generate sentences for the extracted events. Our task is similar to dense video captioning (DVC), which aims at detecting events thoroughly and generating sentences for them. However, unlike DVC, in recipe generation, recipe story awareness is crucial, and a model should extract an appropriate number of events in the correct order and generate accurate sentences based on them. We analyze the output of the DVC model and confirm that although (1) several events are adoptable as a recipe story, (2) the generated sentences for such events are not grounded in the visual content. Based on this, we set our goal to obtain correct recipes by selecting oracle events from the output events and re-generating sentences for them. To achieve this, we propose a transformer-based multimodal r",
    "link": "https://arxiv.org/abs/2209.10134",
    "context": "Title: Recipe Generation from Unsegmented Cooking Videos\nAbstract: arXiv:2209.10134v2 Announce Type: replace-cross  Abstract: This paper tackles recipe generation from unsegmented cooking videos, a task that requires agents to (1) extract key events in completing the dish and (2) generate sentences for the extracted events. Our task is similar to dense video captioning (DVC), which aims at detecting events thoroughly and generating sentences for them. However, unlike DVC, in recipe generation, recipe story awareness is crucial, and a model should extract an appropriate number of events in the correct order and generate accurate sentences based on them. We analyze the output of the DVC model and confirm that although (1) several events are adoptable as a recipe story, (2) the generated sentences for such events are not grounded in the visual content. Based on this, we set our goal to obtain correct recipes by selecting oracle events from the output events and re-generating sentences for them. To achieve this, we propose a transformer-based multimodal r",
    "path": "papers/22/09/2209.10134.json",
    "total_tokens": 820,
    "translated_title": "来自未分割烹饪视频的食谱生成",
    "translated_abstract": "本文解决了从未分割的烹饪视频中生成食谱的问题，这需要代理程序提取完成菜肴时的关键事件并为提取的事件生成句子。我们的任务类似于密集视频字幕生成（DVC），其目标是彻底检测事件并为其生成句子。然而，与DVC不同，对于食谱生成，食谱故事意识至关重要，模型应该按正确顺序提取适当数量的事件并基于它们生成准确的句子。我们分析了DVC模型的输出并确认，尽管几个事件可以被采用作为食谱故事，但为这些事件生成的句子与视觉内容并不相关。基于此，我们的目标是通过从输出事件中选择神谕事件并为其重新生成句子来获得正确的食谱。为实现这一目标，我们提出了一种基于变压器的多模式r",
    "tldr": "本文研究如何从未分割的烹饪视频中生成正确的食谱，通过选择神谕事件并重新生成句子来实现。",
    "en_tdlr": "This paper addresses the generation of accurate recipes from unsegmented cooking videos by selecting oracle events and regenerating sentences based on them."
}