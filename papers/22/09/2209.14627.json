{
    "title": "An Equal-Size Hard EM Algorithm for Diverse Dialogue Generation. (arXiv:2209.14627v2 [cs.CL] UPDATED)",
    "abstract": "Open-domain dialogue systems aim to interact with humans through natural language texts in an open-ended fashion. Despite the recent success of super large dialogue systems such as ChatGPT, using medium-to-small-sized dialogue systems remains the common practice as they are more lightweight and accessible; however, generating diverse dialogue responses is challenging, especially with smaller models. In this work, we propose an Equal-size Hard Expectation--Maximization (EqHard-EM) algorithm to train a multi-decoder model for diverse dialogue generation. Our algorithm assigns a sample to a decoder in a hard manner and additionally imposes an equal-assignment constraint to ensure that all decoders are well-trained. We provide detailed theoretical analysis to justify our approach. Further, experiments on two large-scale open-domain dialogue datasets verify that our EqHard-EM algorithm generates high-quality diverse responses.",
    "link": "http://arxiv.org/abs/2209.14627",
    "context": "Title: An Equal-Size Hard EM Algorithm for Diverse Dialogue Generation. (arXiv:2209.14627v2 [cs.CL] UPDATED)\nAbstract: Open-domain dialogue systems aim to interact with humans through natural language texts in an open-ended fashion. Despite the recent success of super large dialogue systems such as ChatGPT, using medium-to-small-sized dialogue systems remains the common practice as they are more lightweight and accessible; however, generating diverse dialogue responses is challenging, especially with smaller models. In this work, we propose an Equal-size Hard Expectation--Maximization (EqHard-EM) algorithm to train a multi-decoder model for diverse dialogue generation. Our algorithm assigns a sample to a decoder in a hard manner and additionally imposes an equal-assignment constraint to ensure that all decoders are well-trained. We provide detailed theoretical analysis to justify our approach. Further, experiments on two large-scale open-domain dialogue datasets verify that our EqHard-EM algorithm generates high-quality diverse responses.",
    "path": "papers/22/09/2209.14627.json",
    "total_tokens": 830,
    "translated_title": "《一种针对多样对话生成的等大小硬EM算法》",
    "translated_abstract": "开放领域对话系统旨在以自然语言文本与人类互动。尽管像ChatGPT这样的超大型对话系统最近取得了成功，但使用中小型对话系统仍然是常见的做法，因为它们更加轻便易用。然而，在较小的模型中生成多样的对话响应是具有挑战性的。在本文中，我们提出了一种等大小硬EM（EqHard-EM）算法，用于训练多解码器模型以实现多样的对话生成。我们的算法以硬方式将样本分配给解码器，并额外施加平衡约束条件，以确保所有解码器都经过充分的训练。我们提供了详细的理论分析来证明我们的方法。此外，我们在两个大规模的开放领域对话数据集上进行实验，证明我们的EqHard-EM算法可以生成高质量的多样化响应。",
    "tldr": "本文提出了一种平衡约束的等大小硬EM算法，用于训练多解码器模型以实现多样的对话生成，可在小型模型中生成高质量的多样化响应。",
    "en_tdlr": "This paper proposes an equal-size hard EM algorithm with a balanced constraint to train a multi-decoder model for diverse dialogue generation, which can generate high-quality diverse responses even with smaller models."
}