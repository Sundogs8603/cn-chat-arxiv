{
    "title": "Fair admission risk prediction with proportional multicalibration. (arXiv:2209.14613v3 [cs.LG] UPDATED)",
    "abstract": "Fair calibration is a widely desirable fairness criteria in risk prediction contexts. One way to measure and achieve fair calibration is with multicalibration. Multicalibration constrains calibration error among flexibly-defined subpopulations while maintaining overall calibration. However, multicalibrated models can exhibit a higher percent calibration error among groups with lower base rates than groups with higher base rates. As a result, it is possible for a decision-maker to learn to trust or distrust model predictions for specific groups. To alleviate this, we propose \\emph{proportional multicalibration}, a criteria that constrains the percent calibration error among groups and within prediction bins. We prove that satisfying proportional multicalibration bounds a model's multicalibration as well its \\emph{differential calibration}, a fairness criteria that directly measures how closely a model approximates sufficiency. Therefore, proportionally calibrated models limit the abilit",
    "link": "http://arxiv.org/abs/2209.14613",
    "context": "Title: Fair admission risk prediction with proportional multicalibration. (arXiv:2209.14613v3 [cs.LG] UPDATED)\nAbstract: Fair calibration is a widely desirable fairness criteria in risk prediction contexts. One way to measure and achieve fair calibration is with multicalibration. Multicalibration constrains calibration error among flexibly-defined subpopulations while maintaining overall calibration. However, multicalibrated models can exhibit a higher percent calibration error among groups with lower base rates than groups with higher base rates. As a result, it is possible for a decision-maker to learn to trust or distrust model predictions for specific groups. To alleviate this, we propose \\emph{proportional multicalibration}, a criteria that constrains the percent calibration error among groups and within prediction bins. We prove that satisfying proportional multicalibration bounds a model's multicalibration as well its \\emph{differential calibration}, a fairness criteria that directly measures how closely a model approximates sufficiency. Therefore, proportionally calibrated models limit the abilit",
    "path": "papers/22/09/2209.14613.json",
    "total_tokens": 910,
    "translated_title": "具有比例多校准的公平入学风险预测",
    "translated_abstract": "公平校准是风险预测环境中广泛需要的公平标准之一。实现公平校准的一种方法是采用多校准。多校准通过在灵活定义的子群体之间限制校准误差来实现整体校准。然而，多校准模型在低基础率群体中可能会表现出较高的校准误差百分比，而在高基础率群体中则较低。因此，决策者可能会学习信任或不信任特定群体的模型预测。为了缓解这个问题，我们提出了“比例多校准”标准，该标准限制了群体和预测区间内的校准误差百分比。我们证明满足比例多校准不仅限制了模型的多校准，而且还限制了模型作为一个直接衡量模型近似充分性的公平标准的“差分校准”。因此，比例校准模型限制了模型的能力。",
    "tldr": "提出了一种称为比例多校准的方法来实现公平校准，在限制校准误差的同时保持整体校准。通过比例多校准可以避免模型对特定群体的预测信任或不信任的问题。",
    "en_tdlr": "Proposed a method called proportional multicalibration to achieve fair calibration by constraining calibration error while maintaining overall calibration. Proportional multicalibration avoids the issue of model trust or distrust in specific groups."
}