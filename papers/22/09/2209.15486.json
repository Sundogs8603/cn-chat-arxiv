{
    "title": "Graph Neural Networks for Link Prediction with Subgraph Sketching. (arXiv:2209.15486v3 [cs.LG] UPDATED)",
    "abstract": "Many Graph Neural Networks (GNNs) perform poorly compared to simple heuristics on Link Prediction (LP) tasks. This is due to limitations in expressive power such as the inability to count triangles (the backbone of most LP heuristics) and because they can not distinguish automorphic nodes (those having identical structural roles). Both expressiveness issues can be alleviated by learning link (rather than node) representations and incorporating structural features such as triangle counts. Since explicit link representations are often prohibitively expensive, recent works resorted to subgraph-based methods, which have achieved state-of-the-art performance for LP, but suffer from poor efficiency due to high levels of redundancy between subgraphs. We analyze the components of subgraph GNN (SGNN) methods for link prediction. Based on our analysis, we propose a novel full-graph GNN called ELPH (Efficient Link Prediction with Hashing) that passes subgraph sketches as messages to approximate t",
    "link": "http://arxiv.org/abs/2209.15486",
    "context": "Title: Graph Neural Networks for Link Prediction with Subgraph Sketching. (arXiv:2209.15486v3 [cs.LG] UPDATED)\nAbstract: Many Graph Neural Networks (GNNs) perform poorly compared to simple heuristics on Link Prediction (LP) tasks. This is due to limitations in expressive power such as the inability to count triangles (the backbone of most LP heuristics) and because they can not distinguish automorphic nodes (those having identical structural roles). Both expressiveness issues can be alleviated by learning link (rather than node) representations and incorporating structural features such as triangle counts. Since explicit link representations are often prohibitively expensive, recent works resorted to subgraph-based methods, which have achieved state-of-the-art performance for LP, but suffer from poor efficiency due to high levels of redundancy between subgraphs. We analyze the components of subgraph GNN (SGNN) methods for link prediction. Based on our analysis, we propose a novel full-graph GNN called ELPH (Efficient Link Prediction with Hashing) that passes subgraph sketches as messages to approximate t",
    "path": "papers/22/09/2209.15486.json",
    "total_tokens": 938,
    "translated_title": "基于子图草图的图神经网络用于链路预测",
    "translated_abstract": "许多图神经网络在链路预测任务中表现不佳，这是由于表达能力的限制，例如无法计算三角形（大多数LP启发式算法的骨干），以及不能区分同构节点（具有相同结构角色的节点）。这两种表达问题可以通过学习链路（而不是节点）表示，并结合三角形计数等结构特征来缓解。由于显式链路表示通常代价高昂，因此最近的研究采用了基于子图的方法，这些方法在LP方面取得了最先进的性能，但由于子图之间存在高度冗余，效率较低。我们分析了子图GNN（SGNN）方法的组件，基于我们的分析，提出了一种名为ELPH（高效哈希链路预测）的新型全图GNN，将子图草图作为消息传递以近似全图上的转换。ELPH在多个基准数据集上实现了最先进的结果，同时需要比现有基于子图的方法更少的计算资源。",
    "tldr": "本研究提出了一种名为ELPH的全图GNN模型，它使用子图草图作为消息传递，以缓解LP任务中子图之间的冗余问题，并在多个基准数据集上取得了最先进的结果。",
    "en_tdlr": "This paper proposes a full-graph GNN model called ELPH, which uses subgraph sketches as messages to overcome the redundancy issue between subgraphs in LP tasks, achieving state-of-the-art results on multiple benchmark datasets with less computational resources."
}