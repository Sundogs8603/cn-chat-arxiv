{
    "title": "OmDet: Large-scale vision-language multi-dataset pre-training with multimodal detection network",
    "abstract": "arXiv:2209.05946v2 Announce Type: replace-cross  Abstract: The advancement of object detection (OD) in open-vocabulary and open-world scenarios is a critical challenge in computer vision. This work introduces OmDet, a novel language-aware object detection architecture, and an innovative training mechanism that harnesses continual learning and multi-dataset vision-language pre-training. Leveraging natural language as a universal knowledge representation, OmDet accumulates a \"visual vocabulary\" from diverse datasets, unifying the task as a language-conditioned detection framework. Our multimodal detection network (MDN) overcomes the challenges of multi-dataset joint training and generalizes to numerous training datasets without manual label taxonomy merging. We demonstrate superior performance of OmDet over strong baselines in object detection in the wild, open-vocabulary detection, and phrase grounding, achieving state-of-the-art results. Ablation studies reveal the impact of scaling th",
    "link": "https://arxiv.org/abs/2209.05946",
    "context": "Title: OmDet: Large-scale vision-language multi-dataset pre-training with multimodal detection network\nAbstract: arXiv:2209.05946v2 Announce Type: replace-cross  Abstract: The advancement of object detection (OD) in open-vocabulary and open-world scenarios is a critical challenge in computer vision. This work introduces OmDet, a novel language-aware object detection architecture, and an innovative training mechanism that harnesses continual learning and multi-dataset vision-language pre-training. Leveraging natural language as a universal knowledge representation, OmDet accumulates a \"visual vocabulary\" from diverse datasets, unifying the task as a language-conditioned detection framework. Our multimodal detection network (MDN) overcomes the challenges of multi-dataset joint training and generalizes to numerous training datasets without manual label taxonomy merging. We demonstrate superior performance of OmDet over strong baselines in object detection in the wild, open-vocabulary detection, and phrase grounding, achieving state-of-the-art results. Ablation studies reveal the impact of scaling th",
    "path": "papers/22/09/2209.05946.json",
    "total_tokens": 964,
    "translated_title": "OmDet: 大规模视觉-语言多数据集预训练与多模式检测网络",
    "translated_abstract": "目标检测（OD）在开放式词汇和开放式场景中的进展是计算机视觉中的一项重要挑战。本文介绍了OmDet，一种新颖的具有语言意识的目标检测架构，以及一种创新的训练机制，利用持续学习和多数据集视觉-语言预训练。OmDet利用自然语言作为通用知识表示，从各种数据集中积累“视觉词汇”，将任务统一为一个以语言为条件的检测框架。我们的多模态检测网络（MDN）克服了多数据集联合训练的挑战，并在不需要手动标签分类合并的情况下泛化到众多训练数据集中。我们展示了OmDet在野外目标检测、开放式词汇检测和短语定位方面优于强基线方法的性能表现，达到了最先进的结果。消融研究揭示了扩展的影响。",
    "tldr": "OmDet 提出了一种语言意识的目标检测架构和创新的训练机制，利用多数据集视觉-语言预训练，从不同数据集中积累“视觉词汇”，实现以语言为条件的多模态检测网络，在目标检测、开放式词汇检测和短语定位等场景中表现出优越性能。",
    "en_tdlr": "OmDet introduces a language-aware object detection architecture and an innovative training mechanism that leverages multi-dataset vision-language pre-training to accumulate a \"visual vocabulary\" from diverse datasets, achieving a language-conditioned multimodal detection network, demonstrating superior performance in object detection, open-vocabulary detection, and phrase grounding scenarios."
}