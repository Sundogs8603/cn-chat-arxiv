{
    "title": "DISA: A Dual Inexact Splitting Algorithm for Distributed Convex Composite Optimization. (arXiv:2209.01850v2 [math.OC] UPDATED)",
    "abstract": "In this paper, we propose a novel Dual Inexact Splitting Algorithm (DISA) for distributed convex composite optimization problems, where the local loss function consists of a smooth term and a possibly nonsmooth term composed with a linear mapping. DISA, for the first time, eliminates the dependence of the convergent step-size range on the Euclidean norm of the linear mapping, while inheriting the advantages of the classic Primal-Dual Proximal Splitting Algorithm (PD-PSA): simple structure and easy implementation. This indicates that DISA can be executed without prior knowledge of the norm, and tiny step-sizes can be avoided when the norm is large. Additionally, we prove sublinear and linear convergence rates of DISA under general convexity and metric subregularity, respectively. Moreover, we provide a variant of DISA with approximate proximal mapping and prove its global convergence and sublinear convergence rate. Numerical experiments corroborate our theoretical analyses and demonstra",
    "link": "http://arxiv.org/abs/2209.01850",
    "context": "Title: DISA: A Dual Inexact Splitting Algorithm for Distributed Convex Composite Optimization. (arXiv:2209.01850v2 [math.OC] UPDATED)\nAbstract: In this paper, we propose a novel Dual Inexact Splitting Algorithm (DISA) for distributed convex composite optimization problems, where the local loss function consists of a smooth term and a possibly nonsmooth term composed with a linear mapping. DISA, for the first time, eliminates the dependence of the convergent step-size range on the Euclidean norm of the linear mapping, while inheriting the advantages of the classic Primal-Dual Proximal Splitting Algorithm (PD-PSA): simple structure and easy implementation. This indicates that DISA can be executed without prior knowledge of the norm, and tiny step-sizes can be avoided when the norm is large. Additionally, we prove sublinear and linear convergence rates of DISA under general convexity and metric subregularity, respectively. Moreover, we provide a variant of DISA with approximate proximal mapping and prove its global convergence and sublinear convergence rate. Numerical experiments corroborate our theoretical analyses and demonstra",
    "path": "papers/22/09/2209.01850.json",
    "total_tokens": 981,
    "translated_abstract": "本文提出了一种用于解决分布式凸复合优化问题的新型双重非精确拆分算法（DISA），其中局部损失函数由平滑项和与线性映射组合的可能非平滑项组成。DISA首次消除了收敛步长范围对于线性映射欧几里得范数的依赖性，同时继承了经典的原始-对偶近端拆分算法（PD-PSA）的优点，具有简单的结构和易于实现的特点。这表明DISA可以在不知道范数的情况下执行，且当范数较大时可以避免使用微小的步长。此外，我们证明了DISA在一般凸性和度量亚正则性下的次线性和线性收敛率。此外，我们提供了一种带有近似近端映射的DISA变体，并证明了其全局收敛和次线性收敛率。数值实验证实了我们的理论分析，并展示了DISA算法的效果。",
    "tldr": "本文提出了一种用于分布式凸复合优化问题的新型双重非精确拆分算法DISA，该算法消除了步长范围对于线性映射欧几里得范数的依赖，具有次线性和线性收敛率。",
    "en_tdlr": "This paper proposes a novel Dual Inexact Splitting Algorithm (DISA) for distributed convex composite optimization problems, which eliminates the dependence of the convergent step-size range on the Euclidean norm of the linear mapping and achieves sublinear and linear convergence rates under general convexity and metric subregularity, respectively. DISA can be executed without prior knowledge of the norm and tiny step-sizes can be avoided when the norm is large."
}