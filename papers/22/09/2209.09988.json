{
    "title": "Investigating and Mitigating Failure Modes in Physics-informed Neural Networks (PINNs). (arXiv:2209.09988v3 [cs.LG] UPDATED)",
    "abstract": "This paper explores the difficulties in solving partial differential equations (PDEs) using physics-informed neural networks (PINNs). PINNs use physics as a regularization term in the objective function. However, a drawback of this approach is the requirement for manual hyperparameter tuning, making it impractical in the absence of validation data or prior knowledge of the solution. Our investigations of the loss landscapes and backpropagated gradients in the presence of physics reveal that existing methods produce non-convex loss landscapes that are hard to navigate. Our findings demonstrate that high-order PDEs contaminate backpropagated gradients and hinder convergence. To address these challenges, we introduce a novel method that bypasses the calculation of high-order derivative operators and mitigates the contamination of backpropagated gradients. Consequently, we reduce the dimension of the search space and make learning PDEs with non-smooth solutions feasible. Our method also pr",
    "link": "http://arxiv.org/abs/2209.09988",
    "context": "Title: Investigating and Mitigating Failure Modes in Physics-informed Neural Networks (PINNs). (arXiv:2209.09988v3 [cs.LG] UPDATED)\nAbstract: This paper explores the difficulties in solving partial differential equations (PDEs) using physics-informed neural networks (PINNs). PINNs use physics as a regularization term in the objective function. However, a drawback of this approach is the requirement for manual hyperparameter tuning, making it impractical in the absence of validation data or prior knowledge of the solution. Our investigations of the loss landscapes and backpropagated gradients in the presence of physics reveal that existing methods produce non-convex loss landscapes that are hard to navigate. Our findings demonstrate that high-order PDEs contaminate backpropagated gradients and hinder convergence. To address these challenges, we introduce a novel method that bypasses the calculation of high-order derivative operators and mitigates the contamination of backpropagated gradients. Consequently, we reduce the dimension of the search space and make learning PDEs with non-smooth solutions feasible. Our method also pr",
    "path": "papers/22/09/2209.09988.json",
    "total_tokens": 974,
    "translated_title": "探究物理知识神经网络中的故障模式及其缓解方法",
    "translated_abstract": "本文探讨了使用物理知识神经网络（PINNs）求解偏微分方程（PDEs）时所面临的困难。PINNs在目标函数中使用物理知识作为正则化项。然而，这种方法的缺点是需要手动调节超参数，如果没有验证数据或先前的解决方案知识，则不切实际。我们研究了存在物理学的损失景观和反向传播梯度困难，发现现有的方法会产生难以导航的非凸损失景观。我们的发现表明，高阶PDEs会污染反向传播梯度并且阻碍收敛。为解决这些挑战，我们介绍了一种新的方法，绕过高阶导数算子的计算，并减轻反向传播梯度的污染。因此，我们降低了搜索空间的维度，并使非平滑解的PDE学习成为可能。我们的方法还提供了自动调节能力，消除了手动调节超参数的需求。",
    "tldr": "本文探究了PINN在解决PDE问题时所面临的困难，并提出了一种新的方法解决了高阶PDE污染反向传播梯度的问题，减小了搜索空间维度，使非平滑解的PDE学习成为可能。",
    "en_tdlr": "This paper investigates the difficulties of using physics-informed neural networks (PINNs) to solve partial differential equations (PDEs) and proposes a novel method to mitigate the contamination of backpropagated gradients caused by high-order PDEs, reducing the dimension of the search space and enabling the learning of PDEs with non-smooth solutions."
}