{
    "title": "Dynamics-Adaptive Continual Reinforcement Learning via Progressive Contextualization. (arXiv:2209.00347v2 [cs.LG] UPDATED)",
    "abstract": "A key challenge of continual reinforcement learning (CRL) in dynamic environments is to promptly adapt the RL agent's behavior as the environment changes over its lifetime, while minimizing the catastrophic forgetting of the learned information. To address this challenge, in this article, we propose DaCoRL, i.e., dynamics-adaptive continual RL. DaCoRL learns a context-conditioned policy using progressive contextualization, which incrementally clusters a stream of stationary tasks in the dynamic environment into a series of contexts and opts for an expandable multihead neural network to approximate the policy. Specifically, we define a set of tasks with similar dynamics as an environmental context and formalize context inference as a procedure of online Bayesian infinite Gaussian mixture clustering on environment features, resorting to online Bayesian inference to infer the posterior distribution over contexts. Under the assumption of a Chinese restaurant process prior, this technique c",
    "link": "http://arxiv.org/abs/2209.00347",
    "context": "Title: Dynamics-Adaptive Continual Reinforcement Learning via Progressive Contextualization. (arXiv:2209.00347v2 [cs.LG] UPDATED)\nAbstract: A key challenge of continual reinforcement learning (CRL) in dynamic environments is to promptly adapt the RL agent's behavior as the environment changes over its lifetime, while minimizing the catastrophic forgetting of the learned information. To address this challenge, in this article, we propose DaCoRL, i.e., dynamics-adaptive continual RL. DaCoRL learns a context-conditioned policy using progressive contextualization, which incrementally clusters a stream of stationary tasks in the dynamic environment into a series of contexts and opts for an expandable multihead neural network to approximate the policy. Specifically, we define a set of tasks with similar dynamics as an environmental context and formalize context inference as a procedure of online Bayesian infinite Gaussian mixture clustering on environment features, resorting to online Bayesian inference to infer the posterior distribution over contexts. Under the assumption of a Chinese restaurant process prior, this technique c",
    "path": "papers/22/09/2209.00347.json",
    "total_tokens": 807,
    "translated_title": "动态自适应连续强化学习：通过渐进式上下文化学习",
    "translated_abstract": "连续强化学习（CRL）在动态环境中的一个关键挑战是迅速调整RL代理的行为，随着环境在其生命周期内的改变，同时最小化学习到的信息的灾难性遗忘。为了解决这个问题，本文提出了DaCoRL，即动态自适应连续RL。DaCoRL使用渐进式上下文化学习学习一个上下文条件化策略，将一系列动态环境中的静态任务逐步聚类为一系列上下文，并选择一个可扩展的多头神经网络来近似策略。",
    "tldr": "本文提出了动态自适应连续RL（DaCoRL）算法，在动态环境中运用了渐进式上下文化学习方法逐步聚类任务，学习一个上下文条件化策略，解决了连续强化学习过程中环境与任务变化带来的问题。",
    "en_tdlr": "The paper proposes DaCoRL, a dynamics-adaptive continual RL algorithm that uses progressive contextualization to cluster a series of stationary tasks in a dynamic environment and learn a context-conditioned policy. It solves the issue of environment and task changes in continuous reinforcement learning."
}