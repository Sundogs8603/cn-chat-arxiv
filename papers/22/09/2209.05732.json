{
    "title": "R\\'{e}nyi Divergence Deep Mutual Learning. (arXiv:2209.05732v4 [cs.LG] UPDATED)",
    "abstract": "This paper revisits Deep Mutual Learning (DML), a simple yet effective computing paradigm. We propose using R\\'{e}nyi divergence instead of the KL divergence, which is more flexible and tunable, to improve vanilla DML. This modification is able to consistently improve performance over vanilla DML with limited additional complexity. The convergence properties of the proposed paradigm are analyzed theoretically, and Stochastic Gradient Descent with a constant learning rate is shown to converge with $\\mathcal{O}(1)$-bias in the worst case scenario for nonconvex optimization tasks. That is, learning will reach nearby local optima but continue searching within a bounded scope, which may help mitigate overfitting. Finally, our extensive empirical results demonstrate the advantage of combining DML and R\\'{e}nyi divergence, which further improves generalized models.",
    "link": "http://arxiv.org/abs/2209.05732",
    "context": "Title: R\\'{e}nyi Divergence Deep Mutual Learning. (arXiv:2209.05732v4 [cs.LG] UPDATED)\nAbstract: This paper revisits Deep Mutual Learning (DML), a simple yet effective computing paradigm. We propose using R\\'{e}nyi divergence instead of the KL divergence, which is more flexible and tunable, to improve vanilla DML. This modification is able to consistently improve performance over vanilla DML with limited additional complexity. The convergence properties of the proposed paradigm are analyzed theoretically, and Stochastic Gradient Descent with a constant learning rate is shown to converge with $\\mathcal{O}(1)$-bias in the worst case scenario for nonconvex optimization tasks. That is, learning will reach nearby local optima but continue searching within a bounded scope, which may help mitigate overfitting. Finally, our extensive empirical results demonstrate the advantage of combining DML and R\\'{e}nyi divergence, which further improves generalized models.",
    "path": "papers/22/09/2209.05732.json",
    "total_tokens": 746,
    "translated_title": "R\\'{e}nyi散度深度互相学习",
    "translated_abstract": "本文重审了一种简单而有效的计算范式——深度互相学习（DML）。我们提出使用R\\'{e}nyi散度而不是KL散度，这种做法更加灵活、可调，以改善vanilla DML。这种修改能够在有限的附加复杂性下不断提高性能。该范例的收敛性进行了理论分析，并且表明具有恒定学习率的随机梯度下降在非凸优化任务的最坏情况下收敛的偏差为$\\mathcal{O}(1)$。",
    "tldr": "本文提出在深度互相学习中使用R\\'{e}nyi散度，它能够在不引入大量复杂度的情况下持续提高性能，获得了广泛的实证结果的支持。",
    "en_tdlr": "This paper proposes using R\\'{e}nyi divergence in Deep Mutual Learning, which consistently improves performance without introducing significant complexity. The convergence of the proposed paradigm is also analyzed theoretically, and empirical results demonstrate its advantage."
}