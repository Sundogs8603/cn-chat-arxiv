{
    "title": "Evaluating Step-by-Step Reasoning through Symbolic Verification",
    "abstract": "arXiv:2212.08686v2 Announce Type: replace  Abstract: Pre-trained language models (LMs) have shown remarkable reasoning performance using explanations or chain-of-thoughts (CoT)) for in-context learning. On the other hand, these reasoning tasks are usually presumed to be more approachable for symbolic programming. To understand the mechanism of reasoning of LMs, we curate synthetic datasets containing equivalent (natural, symbolic) data pairs, where symbolic examples contain first-order logic rules and predicates from non-parametric knowledge bases (KBs), supporting automated verification of intermediate reasoning results. Then we revisit neuro-symbolic approaches and propose to learn from demonstrations containing logic rules and corresponding examples to iteratively reason over KBs, recovering Prolog's backward chaining algorithm and supporting automated verification of LMs' outputs. Comprehensive experiments are included to systematically compare LMLP with CoT in deductive reasoning ",
    "link": "https://arxiv.org/abs/2212.08686",
    "context": "Title: Evaluating Step-by-Step Reasoning through Symbolic Verification\nAbstract: arXiv:2212.08686v2 Announce Type: replace  Abstract: Pre-trained language models (LMs) have shown remarkable reasoning performance using explanations or chain-of-thoughts (CoT)) for in-context learning. On the other hand, these reasoning tasks are usually presumed to be more approachable for symbolic programming. To understand the mechanism of reasoning of LMs, we curate synthetic datasets containing equivalent (natural, symbolic) data pairs, where symbolic examples contain first-order logic rules and predicates from non-parametric knowledge bases (KBs), supporting automated verification of intermediate reasoning results. Then we revisit neuro-symbolic approaches and propose to learn from demonstrations containing logic rules and corresponding examples to iteratively reason over KBs, recovering Prolog's backward chaining algorithm and supporting automated verification of LMs' outputs. Comprehensive experiments are included to systematically compare LMLP with CoT in deductive reasoning ",
    "path": "papers/22/12/2212.08686.json",
    "total_tokens": 755,
    "translated_title": "通过符号验证评估逐步推理",
    "translated_abstract": "预训练语言模型（LMs）展示了在上下文学习中使用解释或思维链（CoT）获得卓越的推理表现。我们构建了包含等效（自然、符号）数据对的合成数据集，其中符号示例包含来自非参数知识库（KBs）的一阶逻辑规则和谓词，支持对中间推理结果的自动验证。我们提出从包含逻辑规则和相应示例的演示中学习，以迭代地在知识库上进行推理，恢复Prolog的向后链接算法，并支持LMs输出的自动验证。",
    "tldr": "文中研究了预训练语言模型（LMs）通过解释或思维链（CoT）进行推理，在推理机制上提出了一种神经符号方法，通过学习逻辑规则和示例进行迭代推理，支持LMs输出自动验证"
}