{
    "title": "Attention as a Guide for Simultaneous Speech Translation. (arXiv:2212.07850v2 [cs.CL] UPDATED)",
    "abstract": "The study of the attention mechanism has sparked interest in many fields, such as language modeling and machine translation. Although its patterns have been exploited to perform different tasks, from neural network understanding to textual alignment, no previous work has analysed the encoder-decoder attention behavior in speech translation (ST) nor used it to improve ST on a specific task. In this paper, we fill this gap by proposing an attention-based policy (EDAtt) for simultaneous ST (SimulST) that is motivated by an analysis of the existing attention relations between audio input and textual output. Its goal is to leverage the encoder-decoder attention scores to guide inference in real time. Results on en->{de, es} show that the EDAtt policy achieves overall better results compared to the SimulST state of the art, especially in terms of computational-aware latency.",
    "link": "http://arxiv.org/abs/2212.07850",
    "context": "Title: Attention as a Guide for Simultaneous Speech Translation. (arXiv:2212.07850v2 [cs.CL] UPDATED)\nAbstract: The study of the attention mechanism has sparked interest in many fields, such as language modeling and machine translation. Although its patterns have been exploited to perform different tasks, from neural network understanding to textual alignment, no previous work has analysed the encoder-decoder attention behavior in speech translation (ST) nor used it to improve ST on a specific task. In this paper, we fill this gap by proposing an attention-based policy (EDAtt) for simultaneous ST (SimulST) that is motivated by an analysis of the existing attention relations between audio input and textual output. Its goal is to leverage the encoder-decoder attention scores to guide inference in real time. Results on en->{de, es} show that the EDAtt policy achieves overall better results compared to the SimulST state of the art, especially in terms of computational-aware latency.",
    "path": "papers/22/12/2212.07850.json",
    "total_tokens": 812,
    "translated_title": "利用注意力机制提升同声翻译性能",
    "translated_abstract": "注意力机制的研究在多个领域中引起了浓厚的兴趣，如语言模型和机器翻译。本文研究针对同声翻译中的编码器-解码器注意力行为，并提出了一种基于注意力的策略（EDAtt），旨在通过实时引导编码器-解码器注意力得分来提高同声翻译性能。在英译德和英译西任务中，与现有同声翻译技术相比，EDAtt 策略在计算感知延迟等方面表现更好。",
    "tldr": "本文研究了同声翻译中的编码器-解码器注意力行为，提出了一种基于注意力的策略（EDAtt），旨在通过实时引导编码器-解码器注意力得分来提高同声翻译性能。在英译德和英译西任务中，EDAtt 策略具有计算感知延迟优势并取得了更好的结果。",
    "en_tdlr": "This paper studies the encoder-decoder attention behavior in simultaneous speech translation and proposes an attention-based policy to guide inference. Results on en->{de, es} show that the EDAtt policy achieves overall better results compared to state-of-the-art simultaneous speech translation techniques, especially in terms of computational-aware latency."
}