{
    "title": "Effectiveness of Text, Acoustic, and Lattice-based representations in Spoken Language Understanding tasks. (arXiv:2212.08489v2 [cs.CL] UPDATED)",
    "abstract": "In this paper, we perform an exhaustive evaluation of different representations to address the intent classification problem in a Spoken Language Understanding (SLU) setup. We benchmark three types of systems to perform the SLU intent detection task: 1) text-based, 2) lattice-based, and a novel 3) multimodal approach. Our work provides a comprehensive analysis of what could be the achievable performance of different state-of-the-art SLU systems under different circumstances, e.g., automatically- vs. manually-generated transcripts. We evaluate the systems on the publicly available SLURP spoken language resource corpus. Our results indicate that using richer forms of Automatic Speech Recognition (ASR) outputs, namely word-consensus-networks, allows the SLU system to improve in comparison to the 1-best setup (5.5% relative improvement). However, crossmodal approaches, i.e., learning from acoustic and text embeddings, obtains performance similar to the oracle setup, a relative improvement ",
    "link": "http://arxiv.org/abs/2212.08489",
    "context": "Title: Effectiveness of Text, Acoustic, and Lattice-based representations in Spoken Language Understanding tasks. (arXiv:2212.08489v2 [cs.CL] UPDATED)\nAbstract: In this paper, we perform an exhaustive evaluation of different representations to address the intent classification problem in a Spoken Language Understanding (SLU) setup. We benchmark three types of systems to perform the SLU intent detection task: 1) text-based, 2) lattice-based, and a novel 3) multimodal approach. Our work provides a comprehensive analysis of what could be the achievable performance of different state-of-the-art SLU systems under different circumstances, e.g., automatically- vs. manually-generated transcripts. We evaluate the systems on the publicly available SLURP spoken language resource corpus. Our results indicate that using richer forms of Automatic Speech Recognition (ASR) outputs, namely word-consensus-networks, allows the SLU system to improve in comparison to the 1-best setup (5.5% relative improvement). However, crossmodal approaches, i.e., learning from acoustic and text embeddings, obtains performance similar to the oracle setup, a relative improvement ",
    "path": "papers/22/12/2212.08489.json",
    "total_tokens": 868,
    "translated_title": "文本、声学和基于lattice的表示在口语理解任务中的有效性",
    "translated_abstract": "本文针对口语理解（SLU）中的意图分类问题进行了多种表示方法的详细评估。我们对三种系统进行了基准评估来执行SLU意图检测任务：1）基于文本的，2）基于lattice的，以及一种新的3）多模式方法。我们提供了对不同情况下（例如，自动生成的转录 vs 手动转录等）不同最先进的SLU系统的可实现性能的全面分析。我们基于公开资源SLURP口语语言资源语料库评估了这些系统。结果表明，使用更丰富的自动语音识别（ASR）输出形式，即词共识网络，可以使SLU系统相对于1-best设置获得改善（相对提高5.5%）。然而，跨模态方法，即学习声学和文本嵌入，得到了与oracle设置相似的性能，即相对提高...",
    "tldr": "本文研究了在口语理解任务中使用文本、声学和基于lattice的表示方法，结果表明使用更丰富的自动语音识别输出形式可以获得更好的性能。",
    "en_tdlr": "This paper evaluates different representations for intent classification in a Spoken Language Understanding setup and finds that using richer forms of Automatic Speech Recognition outputs can improve performance. Crossmodal approaches, i.e., learning from both acoustic and text embeddings, can achieve similar performance as the oracle setup."
}