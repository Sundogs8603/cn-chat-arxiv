{
    "title": "DialogCC: An Automated Pipeline for Creating High-Quality Multi-Modal Dialogue Dataset",
    "abstract": "arXiv:2212.04119v2 Announce Type: replace-cross  Abstract: As sharing images in an instant message is a crucial factor, there has been active research on learning an image-text multi-modal dialogue models. However, training a well-generalized multi-modal dialogue model remains challenging due to the low quality and limited diversity of images per dialogue in existing multi-modal dialogue datasets. In this paper, we propose an automated pipeline to construct a multi-modal dialogue dataset, ensuring both dialogue quality and image diversity without requiring minimum human effort. In our pipeline, to guarantee the coherence between images and dialogue, we prompt GPT-4 to infer potential image-sharing moments - specifically, the utterance, speaker, rationale, and image description. Furthermore, we leverage CLIP similarity to maintain consistency between aligned multiple images to the utterance. Through this pipeline, we introduce DialogCC, a high-quality and diverse multi-modal dialogue da",
    "link": "https://arxiv.org/abs/2212.04119",
    "context": "Title: DialogCC: An Automated Pipeline for Creating High-Quality Multi-Modal Dialogue Dataset\nAbstract: arXiv:2212.04119v2 Announce Type: replace-cross  Abstract: As sharing images in an instant message is a crucial factor, there has been active research on learning an image-text multi-modal dialogue models. However, training a well-generalized multi-modal dialogue model remains challenging due to the low quality and limited diversity of images per dialogue in existing multi-modal dialogue datasets. In this paper, we propose an automated pipeline to construct a multi-modal dialogue dataset, ensuring both dialogue quality and image diversity without requiring minimum human effort. In our pipeline, to guarantee the coherence between images and dialogue, we prompt GPT-4 to infer potential image-sharing moments - specifically, the utterance, speaker, rationale, and image description. Furthermore, we leverage CLIP similarity to maintain consistency between aligned multiple images to the utterance. Through this pipeline, we introduce DialogCC, a high-quality and diverse multi-modal dialogue da",
    "path": "papers/22/12/2212.04119.json",
    "total_tokens": 831,
    "translated_title": "DialogCC: 一个用于创建高质量多模态对话数据集的自动化流水线",
    "translated_abstract": "随着在即时消息中分享图片成为一个关键因素，对学习图像文本多模态对话模型进行了积极研究。然而，由于现有多模态对话数据集中每个对话中图像的质量低和多样性有限，训练一个良好泛化的多模态对话模型仍具挑战性。本文提出了一个自动化流水线来构建多模态对话数据集，确保对话质量和图像多样性，并且不需要人力介入。在我们的流水线中，为了确保图像与对话之间的连贯性，我们引导GPT-4推断潜在的图像分享时刻 - 具体地，话语、说话者、理由和图像描述。此外，我们利用CLIP相似度来保持多个对齐图像与话语之间的一致性。通过这个流水线，我们介绍了DialogCC，一个高质量且多样化的多模态对话数据集。",
    "tldr": "提出了一个自动化流水线来构建高质量和多样化的多模态对话数据集，确保对话质量和图像多样性，并且不需要人力介入。"
}