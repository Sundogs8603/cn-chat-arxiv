{
    "title": "Lessons learned from the evaluation of Spanish Language Models. (arXiv:2212.08390v2 [cs.CL] UPDATED)",
    "abstract": "Given the impact of language models on the field of Natural Language Processing, a number of Spanish encoder-only masked language models (aka BERTs) have been trained and released. These models were developed either within large projects using very large private corpora or by means of smaller scale academic efforts leveraging freely available data. In this paper we present a comprehensive head-to-head comparison of language models for Spanish with the following results: (i) Previously ignored multilingual models from large companies fare better than monolingual models, substantially changing the evaluation landscape of language models in Spanish; (ii) Results across the monolingual models are not conclusive, with supposedly smaller and inferior models performing competitively. Based on these empirical results, we argue for the need of more research to understand the factors underlying them. In this sense, the effect of corpus size, quality and pre-training techniques need to be further",
    "link": "http://arxiv.org/abs/2212.08390",
    "context": "Title: Lessons learned from the evaluation of Spanish Language Models. (arXiv:2212.08390v2 [cs.CL] UPDATED)\nAbstract: Given the impact of language models on the field of Natural Language Processing, a number of Spanish encoder-only masked language models (aka BERTs) have been trained and released. These models were developed either within large projects using very large private corpora or by means of smaller scale academic efforts leveraging freely available data. In this paper we present a comprehensive head-to-head comparison of language models for Spanish with the following results: (i) Previously ignored multilingual models from large companies fare better than monolingual models, substantially changing the evaluation landscape of language models in Spanish; (ii) Results across the monolingual models are not conclusive, with supposedly smaller and inferior models performing competitively. Based on these empirical results, we argue for the need of more research to understand the factors underlying them. In this sense, the effect of corpus size, quality and pre-training techniques need to be further",
    "path": "papers/22/12/2212.08390.json",
    "total_tokens": 918,
    "translated_title": "从西班牙语语言模型评估中得出的教训",
    "translated_abstract": "鉴于语言模型对自然语言处理领域的影响，已经训练并发布了一些仅有编码器的西班牙语掩码语言模型（即BERT）。这些模型要么是在使用非常大的私有语料库的大型项目中开发的，要么是通过利用免费可用数据的小规模学术工作开发的。本文对西班牙语语言模型进行了全面的比较，得出以下结果：（i）先前被忽视的大公司的多语言模型优于单语言模型，在西班牙语语言模型的评估领域产生了重大变化；（ii）单语言模型的结果并不明确，据说更小且更差的模型也具有竞争力。基于这些实证结果，我们主张需要更多的研究来理解其背后的因素。在这方面，语料库的大小、质量和预训练技术的影响需要进一步研究。",
    "tldr": "该论文对西班牙语语言模型进行了全面比较，发现先前被忽视的大公司的多语言模型优于单语言模型，在西班牙语语言模型的评估领域产生了重大变化。需要进一步研究语料库大小、质量和预训练技术的影响。"
}