{
    "title": "SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation. (arXiv:2212.04493v2 [cs.CV] UPDATED)",
    "abstract": "In this work, we present a novel framework built to simplify 3D asset generation for amateur users. To enable interactive generation, our method supports a variety of input modalities that can be easily provided by a human, including images, text, partially observed shapes and combinations of these, further allowing to adjust the strength of each input. At the core of our approach is an encoder-decoder, compressing 3D shapes into a compact latent representation, upon which a diffusion model is learned. To enable a variety of multi-modal inputs, we employ task-specific encoders with dropout followed by a cross-attention mechanism. Due to its flexibility, our model naturally supports a variety of tasks, outperforming prior works on shape completion, image-based 3D reconstruction, and text-to-3D. Most interestingly, our model can combine all these tasks into one swiss-army-knife tool, enabling the user to perform shape generation using incomplete shapes, images, and textual descriptions a",
    "link": "http://arxiv.org/abs/2212.04493",
    "context": "Title: SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation. (arXiv:2212.04493v2 [cs.CV] UPDATED)\nAbstract: In this work, we present a novel framework built to simplify 3D asset generation for amateur users. To enable interactive generation, our method supports a variety of input modalities that can be easily provided by a human, including images, text, partially observed shapes and combinations of these, further allowing to adjust the strength of each input. At the core of our approach is an encoder-decoder, compressing 3D shapes into a compact latent representation, upon which a diffusion model is learned. To enable a variety of multi-modal inputs, we employ task-specific encoders with dropout followed by a cross-attention mechanism. Due to its flexibility, our model naturally supports a variety of tasks, outperforming prior works on shape completion, image-based 3D reconstruction, and text-to-3D. Most interestingly, our model can combine all these tasks into one swiss-army-knife tool, enabling the user to perform shape generation using incomplete shapes, images, and textual descriptions a",
    "path": "papers/22/12/2212.04493.json",
    "total_tokens": 979,
    "translated_title": "SDFusion：多模态三维形状完成、重建和生成",
    "translated_abstract": "本文提出了一个新的框架，旨在简化业余用户的三维资源生成。该方法支持各种输入模式，包括图像、文本、部分观察到的形状和这些的组合，进一步允许调整每个输入的强度，以实现交互式生成。在我们方法的核心是一个编码器-解码器，将三维形状压缩成一个紧凑的潜在表示，然后学习扩散模型。为了支持各种多模态输入，我们采用了具有辍学的任务特定编码器，后跟交叉注意机制。由于其灵活性，我们的模型自然支持各种任务，在形状完成、基于图像的三维重建和文本到3D方面的性能表现均优于之前的工作。最有趣的是，我们的模型可以将所有这些任务组合成一个“瑞士军刀”工具，使用户能够使用不完整的形状、图像和文本描述来进行形状生成。",
    "tldr": "本文提出了一个多模态三维形状生成的新框架，支持图像、文本、部分观察到的形状等多种输入模式，模型具有较强的灵活性和性能表现，在目前相关工作中处于领先地位，能够将多种任务整合成一个工具，为业余用户简化了三维资源生成的流程。"
}