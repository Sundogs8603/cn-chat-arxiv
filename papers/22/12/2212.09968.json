{
    "title": "On Improving Summarization Factual Consistency from Natural Language Feedback. (arXiv:2212.09968v2 [cs.CL] UPDATED)",
    "abstract": "Despite the recent progress in language generation models, their outputs may not always meet user expectations. In this work, we study whether informational feedback in natural language can be leveraged to improve generation quality and user preference alignment. To this end, we consider factual consistency in summarization, the quality that the summary should only contain information supported by the input documents, as the user-expected preference. We collect a high-quality dataset, DeFacto, containing human demonstrations and informational natural language feedback consisting of corrective instructions, edited summaries, and explanations with respect to the factual consistency of the summary. Using our dataset, we study three natural language generation tasks: (1) editing a summary by following the human feedback, (2) generating human feedback for editing the original summary, and (3) revising the initial summary to correct factual errors by generating both the human feedback and ed",
    "link": "http://arxiv.org/abs/2212.09968",
    "context": "Title: On Improving Summarization Factual Consistency from Natural Language Feedback. (arXiv:2212.09968v2 [cs.CL] UPDATED)\nAbstract: Despite the recent progress in language generation models, their outputs may not always meet user expectations. In this work, we study whether informational feedback in natural language can be leveraged to improve generation quality and user preference alignment. To this end, we consider factual consistency in summarization, the quality that the summary should only contain information supported by the input documents, as the user-expected preference. We collect a high-quality dataset, DeFacto, containing human demonstrations and informational natural language feedback consisting of corrective instructions, edited summaries, and explanations with respect to the factual consistency of the summary. Using our dataset, we study three natural language generation tasks: (1) editing a summary by following the human feedback, (2) generating human feedback for editing the original summary, and (3) revising the initial summary to correct factual errors by generating both the human feedback and ed",
    "path": "papers/22/12/2212.09968.json",
    "total_tokens": 862,
    "translated_title": "关于从自然语言反馈中提高摘要的事实一致性的研究",
    "translated_abstract": "尽管语言生成模型近年来取得了很大进展，但它们的输出并不总是符合用户的期望。在这项工作中，我们研究了是否可以利用自然语言的信息反馈来提高生成质量和用户偏好的一致性。为此，我们将摘要中的事实一致性作为用户期望的质量指标，即摘要只应包含由输入文档支持的信息。我们收集了一个高质量的数据集DeFacto，其中包含人类的演示和有关摘要事实一致性的纠正性指示、编辑后的摘要和解释。利用我们的数据集，我们研究了三个自然语言生成任务：（1）根据人类反馈编辑摘要，（2）为编辑原始摘要生成人类反馈，（3）通过生成人类反馈和编辑来修正初始摘要的事实错误。",
    "tldr": "本研究通过收集人类反馈信息，探讨利用自然语言反馈来提高摘要的生成质量和用户偏好一致性，特别关注摘要的事实一致性，并通过三个自然语言生成任务进行研究。",
    "en_tdlr": "This study investigates the use of natural language feedback to improve the generation quality and user preference consistency of summarization. The focus is on factual consistency, and three natural language generation tasks are studied using a high-quality dataset called DeFacto."
}