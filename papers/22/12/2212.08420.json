{
    "title": "Fake it till you make it: Learning transferable representations from synthetic ImageNet clones. (arXiv:2212.08420v2 [cs.CV] UPDATED)",
    "abstract": "Recent image generation models such as Stable Diffusion have exhibited an impressive ability to generate fairly realistic images starting from a simple text prompt. Could such models render real images obsolete for training image prediction models? In this paper, we answer part of this provocative question by investigating the need for real images when training models for ImageNet classification. Provided only with the class names that have been used to build the dataset, we explore the ability of Stable Diffusion to generate synthetic clones of ImageNet and measure how useful these are for training classification models from scratch. We show that with minimal and class-agnostic prompt engineering, ImageNet clones are able to close a large part of the gap between models produced by synthetic images and models trained with real images, for the several standard classification benchmarks that we consider in this study. More importantly, we show that models trained on synthetic images exhi",
    "link": "http://arxiv.org/abs/2212.08420",
    "context": "Title: Fake it till you make it: Learning transferable representations from synthetic ImageNet clones. (arXiv:2212.08420v2 [cs.CV] UPDATED)\nAbstract: Recent image generation models such as Stable Diffusion have exhibited an impressive ability to generate fairly realistic images starting from a simple text prompt. Could such models render real images obsolete for training image prediction models? In this paper, we answer part of this provocative question by investigating the need for real images when training models for ImageNet classification. Provided only with the class names that have been used to build the dataset, we explore the ability of Stable Diffusion to generate synthetic clones of ImageNet and measure how useful these are for training classification models from scratch. We show that with minimal and class-agnostic prompt engineering, ImageNet clones are able to close a large part of the gap between models produced by synthetic images and models trained with real images, for the several standard classification benchmarks that we consider in this study. More importantly, we show that models trained on synthetic images exhi",
    "path": "papers/22/12/2212.08420.json",
    "total_tokens": 885,
    "translated_title": "逆境求生：从合成 ImageNet 克隆体中学习可迁移的表示方法",
    "translated_abstract": "最近的图像生成模型（如 Stable Diffusion）展现出令人印象深刻的能力，从简单的文本提示开始生成相当真实的图像。当训练图像预测模型时，这样的模型能否使真实图像变得过时？ 在本文中，我们从建立数据集的分类名称开始，探索了仅提供 ImageNet 克隆体的情况下，Stable Diffusion 生成合成图像进行模型训练的必要性，并测量它们对于从头开始训练分类模型的有用性。 我们展示了，在最小且类不可知的提示工程的情况下，ImageNet 克隆体能够弥合合成图像制作模型和使用真实图像训练模型之间的巨大差距，对于我们在本研究中考虑的多个标准分类基准测试。",
    "tldr": "本文探究了在训练分类模型时，是否需要使用真实图像，而使用合成 ImageNet 克隆体能否弥补差距。通过最小和类不可知的提示工程，证明了合成图像制作模型和使用真实图像训练模型的巨大差距得到了弥合。",
    "en_tdlr": "This paper investigates whether real images are necessary when training models for ImageNet classification, and whether synthetic ImageNet clones can close the gap. The study shows, with minimal and class-agnostic prompt engineering, that the gap between models produced by synthetic images and models trained with real images can be bridged."
}