{
    "title": "Predictive Coding Based Multiscale Network with Encoder-Decoder LSTM for Video Prediction. (arXiv:2212.11642v3 [cs.CV] UPDATED)",
    "abstract": "We present a multi-scale predictive coding model for future video frames prediction. Drawing inspiration on the ``Predictive Coding\" theories in cognitive science, it is updated by a combination of bottom-up and top-down information flows, which can enhance the interaction between different network levels. However, traditional predictive coding models only predict what is happening hierarchically rather than predicting the future. To address the problem, our model employs a multi-scale approach (Coarse to Fine), where the higher level neurons generate coarser predictions (lower resolution), while the lower level generate finer predictions (higher resolution). In terms of network architecture, we directly incorporate the encoder-decoder network within the LSTM module and share the final encoded high-level semantic information across different network levels. This enables comprehensive interaction between the current input and the historical states of LSTM compared with the traditional E",
    "link": "http://arxiv.org/abs/2212.11642",
    "context": "Title: Predictive Coding Based Multiscale Network with Encoder-Decoder LSTM for Video Prediction. (arXiv:2212.11642v3 [cs.CV] UPDATED)\nAbstract: We present a multi-scale predictive coding model for future video frames prediction. Drawing inspiration on the ``Predictive Coding\" theories in cognitive science, it is updated by a combination of bottom-up and top-down information flows, which can enhance the interaction between different network levels. However, traditional predictive coding models only predict what is happening hierarchically rather than predicting the future. To address the problem, our model employs a multi-scale approach (Coarse to Fine), where the higher level neurons generate coarser predictions (lower resolution), while the lower level generate finer predictions (higher resolution). In terms of network architecture, we directly incorporate the encoder-decoder network within the LSTM module and share the final encoded high-level semantic information across different network levels. This enables comprehensive interaction between the current input and the historical states of LSTM compared with the traditional E",
    "path": "papers/22/12/2212.11642.json",
    "total_tokens": 945,
    "translated_title": "基于预测编码的多尺度网络和编码-解码LSTM用于视频预测",
    "translated_abstract": "我们提出了一种多尺度预测编码模型用于未来视频帧的预测。借鉴了认知科学中的“预测编码”理论，该模型通过从下到上和从上到下的信息流更新，增强了不同网络层之间的交互。然而，传统的预测编码模型只能按层次预测目前正在发生的事情，而不能预测未来。为了解决这个问题，我们的模型采用了多尺度方法（从粗糙到精细），其中高层神经元生成粗糙预测（低分辨率），而低层神经元生成细节预测（高分辨率）。在网络架构方面，我们直接将编码-解码网络融入LSTM模块，并在不同网络层之间共享最终编码的高层语义信息。与传统的编码解码方法相比，这使得当前输入与LSTM的历史状态之间能够进行全面的交互。",
    "tldr": "本论文提出了一种基于预测编码和多尺度网络的视频预测模型。通过从下到上和从上到下的信息流更新，增强了不同网络层之间的交互。模型通过多尺度方法实现粗糙和细节预测，同时结合编码-解码网络和LSTM模块，实现了全面的输入与历史状态的交互。",
    "en_tdlr": "This paper proposes a video prediction model based on predictive coding and multiscale network. The model enhances the interaction between different network levels through bottom-up and top-down information flows. It achieves coarse and fine prediction through a multiscale approach, and combines the encoder-decoder network with the LSTM module to enable comprehensive interaction between the input and historical states."
}