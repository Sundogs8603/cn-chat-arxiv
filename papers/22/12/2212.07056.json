{
    "title": "On the Probability of Necessity and Sufficiency of Explaining Graph Neural Networks: A Lower Bound Optimization Approach. (arXiv:2212.07056v3 [cs.LG] UPDATED)",
    "abstract": "The explainability of Graph Neural Networks (GNNs) is critical to various GNN applications, yet it remains a significant challenge. A convincing explanation should be both necessary and sufficient simultaneously. However, existing GNN explaining approaches focus on only one of the two aspects, necessity or sufficiency, or a heuristic trade-off between the two. Theoretically, the Probability of Necessity and Sufficiency (PNS) holds the potential to identify the most necessary and sufficient explanation since it can mathematically quantify the necessity and sufficiency of an explanation. Nevertheless, the difficulty of obtaining PNS due to non-monotonicity and the challenge of counterfactual estimation limit its wide use. To address the non-identifiability of PNS, we resort to a lower bound of PNS that can be optimized via counterfactual estimation, and propose a framework of Necessary and Sufficient Explanation for GNN (NSEG) via optimizing that lower bound. Specifically, we depict the ",
    "link": "http://arxiv.org/abs/2212.07056",
    "context": "Title: On the Probability of Necessity and Sufficiency of Explaining Graph Neural Networks: A Lower Bound Optimization Approach. (arXiv:2212.07056v3 [cs.LG] UPDATED)\nAbstract: The explainability of Graph Neural Networks (GNNs) is critical to various GNN applications, yet it remains a significant challenge. A convincing explanation should be both necessary and sufficient simultaneously. However, existing GNN explaining approaches focus on only one of the two aspects, necessity or sufficiency, or a heuristic trade-off between the two. Theoretically, the Probability of Necessity and Sufficiency (PNS) holds the potential to identify the most necessary and sufficient explanation since it can mathematically quantify the necessity and sufficiency of an explanation. Nevertheless, the difficulty of obtaining PNS due to non-monotonicity and the challenge of counterfactual estimation limit its wide use. To address the non-identifiability of PNS, we resort to a lower bound of PNS that can be optimized via counterfactual estimation, and propose a framework of Necessary and Sufficient Explanation for GNN (NSEG) via optimizing that lower bound. Specifically, we depict the ",
    "path": "papers/22/12/2212.07056.json",
    "total_tokens": 931,
    "translated_title": "关于解释图神经网络的必要性和充分性的概率：一种下界优化方法",
    "translated_abstract": "图神经网络（GNNs）的可解释性对各种GNN应用至关重要，然而它仍然是一个重大挑战。一个令人信服的解释应该同时具有必要性和充分性。然而，现有的GNN解释方法仅关注其中之一，必要性或充分性，或者是两者之间的启发式权衡。从理论上讲，必要性和充分性的概率（PNS）有潜力确定最必要和充分的解释，因为它可以数学上量化解释的必要性和充分性。然而，由于非单调性和反事实估计的挑战，获得PNS的困难限制了其广泛使用。为了解决PNS的不可识别性，我们求助于PNS的一个下界，可以通过反事实估计进行优化，并提出了一个GNN的必要和充分解释的框架（NSEG）。具体来说，我们描述了一种下界优化方法。",
    "tldr": "该论文提出了一种利用下界优化来解释图神经网络（GNNs）的方法。该方法考虑解释的必要性和充分性，并通过数学量化这些要求。通过优化下界，可以获得最必要且充分的解释。",
    "en_tdlr": "This paper proposes a method that utilizes lower bound optimization to explain Graph Neural Networks (GNNs). The method considers the necessity and sufficiency of explanations and quantifies these requirements mathematically. By optimizing the lower bound, the most necessary and sufficient explanations can be obtained."
}