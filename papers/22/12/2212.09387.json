{
    "title": "An Extensible Plug-and-Play Method for Multi-Aspect Controllable Text Generation. (arXiv:2212.09387v2 [cs.CL] UPDATED)",
    "abstract": "Recently, multi-aspect controllable text generation that controls the generated text in multiple aspects (e.g., sentiment, topic, and keywords) has attracted increasing attention. Although methods based on parameter efficient tuning like prefix-tuning could achieve multi-aspect controlling in a plug-and-play way, the mutual interference of multiple prefixes leads to significant degeneration of constraints and limits their extensibility to training-time unseen aspect combinations. In this work, we provide a theoretical lower bound for the interference and empirically found that the interference grows with the number of layers where prefixes are inserted. Based on these analyses, we propose using trainable gates to normalize the intervention of prefixes to restrain the growing interference. As a result, controlling training-time unseen combinations of aspects can be realized by simply concatenating corresponding plugins such that new constraints can be extended at a lower cost. In additi",
    "link": "http://arxiv.org/abs/2212.09387",
    "context": "Title: An Extensible Plug-and-Play Method for Multi-Aspect Controllable Text Generation. (arXiv:2212.09387v2 [cs.CL] UPDATED)\nAbstract: Recently, multi-aspect controllable text generation that controls the generated text in multiple aspects (e.g., sentiment, topic, and keywords) has attracted increasing attention. Although methods based on parameter efficient tuning like prefix-tuning could achieve multi-aspect controlling in a plug-and-play way, the mutual interference of multiple prefixes leads to significant degeneration of constraints and limits their extensibility to training-time unseen aspect combinations. In this work, we provide a theoretical lower bound for the interference and empirically found that the interference grows with the number of layers where prefixes are inserted. Based on these analyses, we propose using trainable gates to normalize the intervention of prefixes to restrain the growing interference. As a result, controlling training-time unseen combinations of aspects can be realized by simply concatenating corresponding plugins such that new constraints can be extended at a lower cost. In additi",
    "path": "papers/22/12/2212.09387.json",
    "total_tokens": 992,
    "translated_title": "多方面可控文本生成的可扩展即插即用方法",
    "translated_abstract": "最近，控制生成文本的多个方面（如情感、主题和关键词）的多方面可控文本生成引起了越来越多的关注。虽然基于参数有效调整的方法，如前缀调整，可以以即插即用的方式实现多方面控制，但多个前缀的相互干扰导致了约束的显著恶化，并限制了它们对于训练时未见过的方面组合的可扩展性。在这项工作中，我们为干扰提供了一个理论下限，并实验证明干扰随插入前缀的层数增加而增加。基于这些分析，我们提出使用可训练门来规范前缀的干预，以抑制不断增长的干扰。因此，通过简单地连接相应的插件，可以实现对训练时未见过的方面组合的控制，从而可以低成本地扩展新的约束条件。此外，我们提出了一个框架，使各种插件能够灵活集成，以对应不同的方面。实验结果表明，我们提出的方法在可控性、连贯性和多样性方面优于先前的方法。",
    "tldr": "本论文提出了一种基于可训练门的多方面可控文本生成方法，用于规范前缀的干预，从而实现对训练时未见过的方面组合的控制，具有良好的可扩展性和性能表现。",
    "en_tdlr": "This paper proposes an extensible, plug-and-play method for multi-aspect controllable text generation using trainable gates to constrain the interference of prefixes, allowing for control over training-time unseen aspect combinations while maintaining good scalability and performance."
}