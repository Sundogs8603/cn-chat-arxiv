{
    "title": "Reusable Options through Gradient-based Meta Learning. (arXiv:2212.11726v2 [cs.LG] UPDATED)",
    "abstract": "Hierarchical methods in reinforcement learning have the potential to reduce the amount of decisions that the agent needs to perform when learning new tasks. However, finding reusable useful temporal abstractions that facilitate fast learning remains a challenging problem. Recently, several deep learning approaches were proposed to learn such temporal abstractions in the form of options in an end-to-end manner. In this work, we point out several shortcomings of these methods and discuss their potential negative consequences. Subsequently, we formulate the desiderata for reusable options and use these to frame the problem of learning options as a gradient-based meta-learning problem. This allows us to formulate an objective that explicitly incentivizes options which allow a higher-level decision maker to adjust in few steps to different tasks. Experimentally, we show that our method is able to learn transferable components which accelerate learning and performs better than existing prior",
    "link": "http://arxiv.org/abs/2212.11726",
    "context": "Title: Reusable Options through Gradient-based Meta Learning. (arXiv:2212.11726v2 [cs.LG] UPDATED)\nAbstract: Hierarchical methods in reinforcement learning have the potential to reduce the amount of decisions that the agent needs to perform when learning new tasks. However, finding reusable useful temporal abstractions that facilitate fast learning remains a challenging problem. Recently, several deep learning approaches were proposed to learn such temporal abstractions in the form of options in an end-to-end manner. In this work, we point out several shortcomings of these methods and discuss their potential negative consequences. Subsequently, we formulate the desiderata for reusable options and use these to frame the problem of learning options as a gradient-based meta-learning problem. This allows us to formulate an objective that explicitly incentivizes options which allow a higher-level decision maker to adjust in few steps to different tasks. Experimentally, we show that our method is able to learn transferable components which accelerate learning and performs better than existing prior",
    "path": "papers/22/12/2212.11726.json",
    "total_tokens": 859,
    "translated_title": "基于梯度元学习的重复使用的选项方法",
    "translated_abstract": "强化学习中的分层方法有潜力减少智能体在学习新任务时需要执行的决策数量。然而，在寻找有用的可重复使用的时间抽象方面，仍存在挑战。最近，提出了几种深度学习方法，以端到端的方式学习这些时间抽象，形成了选项。本文指出了这些方法的几个不足之处并讨论了它们的潜在负面影响。随后，我们制定了可重复使用选项的愿望和使用这些愿望来将学习选项问题框架化为一个基于梯度的元学习问题。这使我们能够制定一种目标，明确激励能够使高层决策者能够在少数步骤中适应不同任务的选项。实验表明，我们的方法能够学习可转移的组件，加速学习，并表现优于现有的先前方法。",
    "tldr": "本文提出了一个基于梯度元学习的方法，以解决学习可重复使用的选项的问题。实验表明，该方法能够学习可转移的组件，加速学习，并表现优于现有的先前方法。",
    "en_tdlr": "This paper proposes a gradient-based meta-learning method to tackle the problem of learning reusable options. Experimental results show that the method is able to learn transferable components which accelerate learning and outperforms existing prior methods."
}