{
    "title": "True Detective: A Deep Abductive Reasoning Benchmark Undoable for GPT-3 and Challenging for GPT-4. (arXiv:2212.10114v2 [cs.CL] UPDATED)",
    "abstract": "Large language models (LLMs) have demonstrated solid zero-shot reasoning capabilities, which is reflected in their performance on the current test tasks. This calls for a more challenging benchmark requiring highly advanced reasoning ability to be solved. In this paper, we introduce such a benchmark, consisting of 191 long-form (1200 words on average) mystery narratives constructed as detective puzzles. Puzzles are sourced from the \"5 Minute Mystery\" platform and include a multiple-choice question for evaluation. Only 47% of humans solve a puzzle successfully on average, while the best human solvers achieve over 80% success rate. We show that GPT-3 models barely outperform random on this benchmark (with 28% accuracy) while state-of-the-art GPT-4 solves only 38% of puzzles. This indicates that there is still a significant gap in the deep reasoning abilities of LLMs and humans and highlights the need for further research in this area. Our work introduces a challenging benchmark for futur",
    "link": "http://arxiv.org/abs/2212.10114",
    "context": "Title: True Detective: A Deep Abductive Reasoning Benchmark Undoable for GPT-3 and Challenging for GPT-4. (arXiv:2212.10114v2 [cs.CL] UPDATED)\nAbstract: Large language models (LLMs) have demonstrated solid zero-shot reasoning capabilities, which is reflected in their performance on the current test tasks. This calls for a more challenging benchmark requiring highly advanced reasoning ability to be solved. In this paper, we introduce such a benchmark, consisting of 191 long-form (1200 words on average) mystery narratives constructed as detective puzzles. Puzzles are sourced from the \"5 Minute Mystery\" platform and include a multiple-choice question for evaluation. Only 47% of humans solve a puzzle successfully on average, while the best human solvers achieve over 80% success rate. We show that GPT-3 models barely outperform random on this benchmark (with 28% accuracy) while state-of-the-art GPT-4 solves only 38% of puzzles. This indicates that there is still a significant gap in the deep reasoning abilities of LLMs and humans and highlights the need for further research in this area. Our work introduces a challenging benchmark for futur",
    "path": "papers/22/12/2212.10114.json",
    "total_tokens": 1123,
    "translated_title": "《真探》：一项深度模因推理基准，难倒GPT-3，对GPT-4构成挑战（arXiv：2212.10114v2 [cs.CL] UPDATED）",
    "translated_abstract": "大型语言模型（LLMs）已经证明了它们的零-shot推理能力，并在当前的测试任务中表现出色。这需要一个更具挑战性的基准测试，需要解决高度先进的推理问题。在本文中，我们介绍了这样一个基准测试，由191个包含长篇故事（平均1200个单词）的侦探谜题构成。题目来自“5分钟的谜”平台，并包括用于评估的多项选择题。仅有47%的人平均能成功解决一个谜题，而最好的人类解谜者则能够取得超过80%的成功率。我们展示了GPT-3模型在这个基准测试上的表现仅略胜于随机猜测（准确率28%），而最先进的GPT-4仅能解决38%的谜题。这表明，LLMs与人类在深度推理能力上仍存在显著差距，并凸显了对这个领域进一步研究的需求。我们的研究引入了一个具有挑战性的基准测试，为未来的研究提供了方向。",
    "tldr": "本文介绍了一项深度模因推理基准测试，由191个侦探故事谜题构成，只有47%的人能成功解决其中一个谜题。研究表明，GPT-3模型在此基准测试中准确性仅为28％，而GPT-4仅能解决38%的谜题。这表明LLMs与人类在深度推理能力上仍存在显著差距，需要进一步的研究。",
    "en_tdlr": "This paper introduces a challenging benchmark for deep abductive reasoning, consisting of 191 long-form detective puzzles sourced from the \"5 Minute Mystery\" platform. The study reveals that GPT-3 models barely outperform random at 28% accuracy, while state-of-the-art GPT-4 solves only 38% of the puzzles, indicating a significant gap between LLMs' deep reasoning abilities and humans'. Further research in this area is needed."
}