{
    "title": "Z-ICL: Zero-Shot In-Context Learning with Pseudo-Demonstrations. (arXiv:2212.09865v2 [cs.CL] UPDATED)",
    "abstract": "Although large language models can be prompted for both zero- and few-shot learning, performance drops significantly when no demonstrations are available. In this paper, we introduce Z-ICL, a new zero-shot method that closes the gap by constructing pseudo-demonstrations for a given test input using a raw text corpus. Concretely, pseudo-demonstrations are constructed by (1) finding the nearest neighbors to the test input from the corpus and pairing them with random task labels, and (2) applying a set of techniques to reduce the amount of direct copying the model does from the resulting demonstrations. Evaluation on nine classification datasets shows that Z-ICL outperforms previous zero-shot methods by a significant margin, and is on par with in-context learning with labeled training data in the few-shot setting. Overall, Z-ICL provides a significantly higher estimate of the zero-shot performance levels of a model, and supports future efforts to develop better pseudo-demonstrations that ",
    "link": "http://arxiv.org/abs/2212.09865",
    "context": "Title: Z-ICL: Zero-Shot In-Context Learning with Pseudo-Demonstrations. (arXiv:2212.09865v2 [cs.CL] UPDATED)\nAbstract: Although large language models can be prompted for both zero- and few-shot learning, performance drops significantly when no demonstrations are available. In this paper, we introduce Z-ICL, a new zero-shot method that closes the gap by constructing pseudo-demonstrations for a given test input using a raw text corpus. Concretely, pseudo-demonstrations are constructed by (1) finding the nearest neighbors to the test input from the corpus and pairing them with random task labels, and (2) applying a set of techniques to reduce the amount of direct copying the model does from the resulting demonstrations. Evaluation on nine classification datasets shows that Z-ICL outperforms previous zero-shot methods by a significant margin, and is on par with in-context learning with labeled training data in the few-shot setting. Overall, Z-ICL provides a significantly higher estimate of the zero-shot performance levels of a model, and supports future efforts to develop better pseudo-demonstrations that ",
    "path": "papers/22/12/2212.09865.json",
    "total_tokens": 967,
    "translated_title": "Z-ICL: 使用伪样本进行零样本视角下的上下文学习",
    "translated_abstract": "虽然大型语言模型可以进行零样本和少样本学习，但当没有提供演示时，性能会显著下降。本文提出了一种新的零样本方法Z-ICL，在给定测试输入的情况下，使用原始文本语料库构建伪演示。具体地，伪演示是通过 (1) 从语料库中找到与测试输入最相近的邻居，并将它们与随机任务标签配对，以及 (2) 应用一组技术来减少模型从生成的演示中直接复制的数量来构建的。在九个分类数据集上的评估表明，Z-ICL 的表现显著优于以前的零样本方法，并在少样本设置中与使用有标记训练数据的上下文学习方法相当。总的来说，Z-ICL 提供了一个显著更高的模型零样本性能水平估计，并支持未来努力发展更好的伪演示来提高上下文学习而无需任何有标记数据。",
    "tldr": "本文提出了一种新的零样本上下文学习方法Z-ICL，通过构建基于原始文本的伪演示，显著提升了模型的零样本性能水平，同时支持未来优化伪演示提高上下文学习表现而无需标记数据。",
    "en_tdlr": "This paper proposes a new zero-shot in-context learning method, Z-ICL, that constructs pseudo-demonstrations from raw text and significantly enhances the zero-shot performance of a model without labeled data, while supporting future efforts to optimize pseudo-demonstrations for better in-context learning."
}