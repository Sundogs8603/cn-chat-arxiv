{
    "title": "Decision-making and control with diffractive optical networks. (arXiv:2212.11278v3 [cs.LG] UPDATED)",
    "abstract": "The ultimate goal of artificial intelligence is to mimic the human brain to perform decision-making and control directly from high-dimensional sensory input. Diffractive optical networks provide a promising solution for implementing artificial intelligence with high-speed and low-power consumption. Most of the reported diffractive optical networks focus on single or multiple tasks that do not involve environmental interaction, such as object recognition and image classification. In contrast, the networks capable of performing decision-making and control have not yet been developed to our knowledge. Here, we propose using deep reinforcement learning to implement diffractive optical networks that imitate human-level decision-making and control capability. Such networks taking advantage of a residual architecture, allow for finding optimal control policies through interaction with the environment and can be readily implemented with existing optical devices. The superior performance of the",
    "link": "http://arxiv.org/abs/2212.11278",
    "context": "Title: Decision-making and control with diffractive optical networks. (arXiv:2212.11278v3 [cs.LG] UPDATED)\nAbstract: The ultimate goal of artificial intelligence is to mimic the human brain to perform decision-making and control directly from high-dimensional sensory input. Diffractive optical networks provide a promising solution for implementing artificial intelligence with high-speed and low-power consumption. Most of the reported diffractive optical networks focus on single or multiple tasks that do not involve environmental interaction, such as object recognition and image classification. In contrast, the networks capable of performing decision-making and control have not yet been developed to our knowledge. Here, we propose using deep reinforcement learning to implement diffractive optical networks that imitate human-level decision-making and control capability. Such networks taking advantage of a residual architecture, allow for finding optimal control policies through interaction with the environment and can be readily implemented with existing optical devices. The superior performance of the",
    "path": "papers/22/12/2212.11278.json",
    "total_tokens": 883,
    "translated_title": "使用衍射光学网络的决策和控制",
    "translated_abstract": "人工智能的终极目标是模拟人脑，从高维感知输入中直接进行决策和控制。衍射光学网络提供了一个有希望的解决方案，可以实现高速和低功耗的人工智能。大多数报道的衍射光学网络都集中在单个或多个任务上，这些任务不涉及环境交互，比如物体识别和图像分类。相反，我们目前还没有开发出能够进行决策和控制的网络。在这里，我们提出使用深度强化学习来实现模拟人类级别的决策和控制能力的衍射光学网络。这些网络利用残差架构的优势，通过与环境的交互找到最优的控制策略，并且可以通过现有的光学设备轻松实现。这种方法展现了卓越的性能。",
    "tldr": "本文提出使用深度强化学习来实现具备决策和控制能力的衍射光学网络，以模拟人类的决策和控制能力。这种网络利用残差架构，并通过与环境的交互来找到最优的控制策略，具备高速和低功耗的特点。",
    "en_tdlr": "This paper proposes using deep reinforcement learning to implement diffractive optical networks that mimic human-level decision-making and control capability. These networks, taking advantage of a residual architecture, find optimal control policies through interaction with the environment and have the advantages of high speed and low power consumption."
}