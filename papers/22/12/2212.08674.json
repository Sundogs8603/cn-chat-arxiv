{
    "title": "An unfolding method based on conditional Invertible Neural Networks (cINN) using iterative training. (arXiv:2212.08674v3 [hep-ph] UPDATED)",
    "abstract": "The unfolding of detector effects is crucial for the comparison of data to theory predictions. While traditional methods are limited to representing the data in a low number of dimensions, machine learning has enabled new unfolding techniques while retaining the full dimensionality. Generative networks like invertible neural networks~(INN) enable a probabilistic unfolding, which map individual events to their corresponding unfolded probability distribution. The accuracy of such methods is however limited by how well simulated training samples model the actual data that is unfolded. We introduce the iterative conditional INN~(IcINN) for unfolding that adjusts for deviations between simulated training samples and data. The IcINN unfolding is first validated on toy data and then applied to pseudo-data for the $pp \\to Z \\gamma \\gamma$ process.",
    "link": "http://arxiv.org/abs/2212.08674",
    "context": "Title: An unfolding method based on conditional Invertible Neural Networks (cINN) using iterative training. (arXiv:2212.08674v3 [hep-ph] UPDATED)\nAbstract: The unfolding of detector effects is crucial for the comparison of data to theory predictions. While traditional methods are limited to representing the data in a low number of dimensions, machine learning has enabled new unfolding techniques while retaining the full dimensionality. Generative networks like invertible neural networks~(INN) enable a probabilistic unfolding, which map individual events to their corresponding unfolded probability distribution. The accuracy of such methods is however limited by how well simulated training samples model the actual data that is unfolded. We introduce the iterative conditional INN~(IcINN) for unfolding that adjusts for deviations between simulated training samples and data. The IcINN unfolding is first validated on toy data and then applied to pseudo-data for the $pp \\to Z \\gamma \\gamma$ process.",
    "path": "papers/22/12/2212.08674.json",
    "total_tokens": 788,
    "translated_title": "基于条件可逆神经网络（cINN）的展开方法及其迭代训练（arXiv：2212.08674v3 [hep-ph] UPDATED）",
    "translated_abstract": "探测器效应展开对于数据与理论预测的比较至关重要。传统方法只能将数据表示为低维度，而机器学习使得保留完整维度的新展开技术成为可能。生成网络如可逆神经网络（INN）可以实现概率展开，将个体事件映射到相应的展开概率分布。然而，这种方法的准确性受到训练样本与实际展开数据的一致性的限制。我们引入了迭代条件INN（IcINN）展开方法，用于调整训练样本与数据之间的偏差。首先在玩具数据上验证了IcINN展开方法，然后将其应用于$pp \\to Z \\gamma \\gamma$过程的伪数据。",
    "tldr": "该论文提出了一种基于条件可逆神经网络（cINN）的展开方法（IcINN），通过迭代训练调整训练样本与数据之间的偏差，实现了对数据与理论预测的比较中探测器效应的展开。"
}