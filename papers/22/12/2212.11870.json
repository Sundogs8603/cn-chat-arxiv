{
    "title": "Impossibility Theorems for Feature Attribution. (arXiv:2212.11870v2 [cs.LG] UPDATED)",
    "abstract": "Despite a sea of interpretability methods that can produce plausible explanations, the field has also empirically seen many failure cases of such methods. In light of these results, it remains unclear for practitioners how to use these methods and choose between them in a principled way. In this paper, we show that for moderately rich model classes (easily satisfied by neural networks), any feature attribution method that is complete and linear -- for example, Integrated Gradients and SHAP -- can provably fail to improve on random guessing for inferring model behaviour. Our results apply to common end-tasks such as characterizing local model behaviour, identifying spurious features, and algorithmic recourse. One takeaway from our work is the importance of concretely defining end-tasks: once such an end-task is defined, a simple and direct approach of repeated model evaluations can outperform many other complex feature attribution methods.",
    "link": "http://arxiv.org/abs/2212.11870",
    "context": "Title: Impossibility Theorems for Feature Attribution. (arXiv:2212.11870v2 [cs.LG] UPDATED)\nAbstract: Despite a sea of interpretability methods that can produce plausible explanations, the field has also empirically seen many failure cases of such methods. In light of these results, it remains unclear for practitioners how to use these methods and choose between them in a principled way. In this paper, we show that for moderately rich model classes (easily satisfied by neural networks), any feature attribution method that is complete and linear -- for example, Integrated Gradients and SHAP -- can provably fail to improve on random guessing for inferring model behaviour. Our results apply to common end-tasks such as characterizing local model behaviour, identifying spurious features, and algorithmic recourse. One takeaway from our work is the importance of concretely defining end-tasks: once such an end-task is defined, a simple and direct approach of repeated model evaluations can outperform many other complex feature attribution methods.",
    "path": "papers/22/12/2212.11870.json",
    "total_tokens": 909,
    "translated_title": "特征归因的不可能定理",
    "translated_abstract": "尽管有许多可产生合理解释的可解释性方法，但该领域也经验性地看到了许多失败案例。鉴于这些结果，对于实践者如何以原则性方式使用这些方法并在它们之间进行选择仍不清楚。在本文中，我们展示了对于中等规模的模型类（神经网络容易满足），任何完整的线性特征归因方法（例如Integrated Gradients和SHAP）可以被证明对于推断模型行为的改进都无法胜任。我们的结果适用于常见的最终任务，如描述局部模型行为、识别虚假特征和算法回溯。我们工作的一个重要启示是具体定义最终任务的重要性：一旦这样的最终任务被定义，一个简单和直接的方法——重复模型评估——可以胜过许多其他复杂的特征归因方法。",
    "tldr": "本文阐述了对于中等规模的模型类，任何完整的线性特征归因方法都无法胜任推断模型行为的改进，启示我们在具体定义最终任务的重要性方面要汲取经验，采用重复模型评估的简单直接方法可以胜过许多其他复杂的特征归因方法。",
    "en_tdlr": "This paper presents the impossibility theorems for feature attribution methods, showing that for moderately rich model classes, any complete and linear feature attribution method cannot improve on random guessing for inferring model behaviour. The work emphasizes the importance of concretely defining end-tasks and suggests using a simple and direct approach of repeated model evaluations to outperform other complex feature attribution methods."
}