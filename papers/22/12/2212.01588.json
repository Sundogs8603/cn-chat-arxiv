{
    "title": "RHO ($\\rho$): Reducing Hallucination in Open-domain Dialogues with Knowledge Grounding. (arXiv:2212.01588v2 [cs.CL] UPDATED)",
    "abstract": "Dialogue systems can leverage large pre-trained language models and knowledge to generate fluent and informative responses. However, these models are still prone to produce hallucinated responses not supported by the input source, which greatly hinders their application. The heterogeneity between external knowledge and dialogue context challenges representation learning and source integration, and further contributes to unfaithfulness. To handle this challenge and generate more faithful responses, this paper presents RHO ($\\rho$) utilizing the representations of linked entities and relation predicates from a knowledge graph (KG). We propose (1) local knowledge grounding to combine textual embeddings with the corresponding KG embeddings; and (2) global knowledge grounding to equip RHO with multi-hop reasoning abilities via the attention mechanism. In addition, we devise a response re-ranking technique based on walks over KG sub-graphs for better conversational reasoning. Experimental re",
    "link": "http://arxiv.org/abs/2212.01588",
    "context": "Title: RHO ($\\rho$): Reducing Hallucination in Open-domain Dialogues with Knowledge Grounding. (arXiv:2212.01588v2 [cs.CL] UPDATED)\nAbstract: Dialogue systems can leverage large pre-trained language models and knowledge to generate fluent and informative responses. However, these models are still prone to produce hallucinated responses not supported by the input source, which greatly hinders their application. The heterogeneity between external knowledge and dialogue context challenges representation learning and source integration, and further contributes to unfaithfulness. To handle this challenge and generate more faithful responses, this paper presents RHO ($\\rho$) utilizing the representations of linked entities and relation predicates from a knowledge graph (KG). We propose (1) local knowledge grounding to combine textual embeddings with the corresponding KG embeddings; and (2) global knowledge grounding to equip RHO with multi-hop reasoning abilities via the attention mechanism. In addition, we devise a response re-ranking technique based on walks over KG sub-graphs for better conversational reasoning. Experimental re",
    "path": "papers/22/12/2212.01588.json",
    "total_tokens": 925,
    "translated_title": "《RHO ($\\rho$)：利用知识链接减少开放域对话中的幻觉》",
    "translated_abstract": "对话系统可以利用大型预训练语言模型和知识库生成流畅且信息丰富的回复。然而，这些模型仍然容易产生幻觉式的回复，并严重影响应用。外部知识和对话上下文之间的异构性挑战了表征学习和源集成，进一步导致不忠实性。为了应对这一挑战并生成更忠实的回复，本文提出了一种使用知识图谱中链接实体和关系谓词的表示来减少幻觉的方法，即RHO ($\\rho$)。我们提出了(1)本地知识基础，将文本嵌入与对应的知识图谱嵌入相结合；以及(2)全局知识基础，通过注意机制使RHO具有多次跳推理能力。此外，我们设计了一种基于知识图谱子图漫步的回复重新排序技术，以实现更好的对话推理。",
    "tldr": "本文介绍了一种名为RHO ($\\rho$)的方法，利用知识图谱中链接实体和关系谓词的表示来减少对话系统中产生的幻觉，提高了对话推理能力，并采用基于知识图谱子图漫步的回复重新排序技术。"
}