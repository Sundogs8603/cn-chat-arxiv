{
    "title": "DiSTRICT: Dialogue State Tracking with Retriever Driven In-Context Tuning. (arXiv:2212.02851v2 [cs.CL] UPDATED)",
    "abstract": "Dialogue State Tracking (DST), a key component of task-oriented conversation systems, represents user intentions by determining the values of pre-defined slots in an ongoing dialogue. Existing approaches use hand-crafted templates and additional slot information to fine-tune and prompt large pre-trained language models and elicit slot values from the dialogue context. Significant manual effort and domain knowledge is required to design effective prompts, limiting the generalizability of these approaches to new domains and tasks. In this work, we propose DiSTRICT, a generalizable in-context tuning approach for DST that retrieves highly relevant training examples for a given dialogue to fine-tune the model without any hand-crafted templates. Experiments with the MultiWOZ benchmark datasets show that DiSTRICT outperforms existing approaches in various zero-shot and few-shot settings using a much smaller model, thereby providing an important advantage for real-world deployments that often ",
    "link": "http://arxiv.org/abs/2212.02851",
    "context": "Title: DiSTRICT: Dialogue State Tracking with Retriever Driven In-Context Tuning. (arXiv:2212.02851v2 [cs.CL] UPDATED)\nAbstract: Dialogue State Tracking (DST), a key component of task-oriented conversation systems, represents user intentions by determining the values of pre-defined slots in an ongoing dialogue. Existing approaches use hand-crafted templates and additional slot information to fine-tune and prompt large pre-trained language models and elicit slot values from the dialogue context. Significant manual effort and domain knowledge is required to design effective prompts, limiting the generalizability of these approaches to new domains and tasks. In this work, we propose DiSTRICT, a generalizable in-context tuning approach for DST that retrieves highly relevant training examples for a given dialogue to fine-tune the model without any hand-crafted templates. Experiments with the MultiWOZ benchmark datasets show that DiSTRICT outperforms existing approaches in various zero-shot and few-shot settings using a much smaller model, thereby providing an important advantage for real-world deployments that often ",
    "path": "papers/22/12/2212.02851.json",
    "total_tokens": 917,
    "translated_title": "DiSTRICT: 通过Retriever驱动的上下文调优对话状态跟踪",
    "translated_abstract": "对话状态跟踪(DST)是任务导向型对话系统的关键组件，它通过确定进行中对话中预定义槽位的值来表示用户意图。现有方法使用手工制作的模板和额外的槽位信息来对大型预训练语言模型进行微调和提示，并从对话上下文中引出槽位的值。然而，设计有效的提示需要大量手动工作和领域知识，限制了这些方法在新的领域和任务上的泛化能力。在这项工作中，我们提出了DiSTRICT，一种适用于DST的通用上下文调优方法，它通过检索与给定对话高度相关的训练样本来进行模型的微调，而无需使用手工制作的模板。在使用MultiWOZ基准数据集进行的实验中，DiSTRICT在各种零样本和少样本情况下使用较小的模型优于现有方法，从而为经常进行实际部署的实际情况提供了重要优势。",
    "tldr": "DiSTRICT是一种无需手工制作模板的通用上下文调优方法，通过检索相关的训练样本来微调对话状态跟踪模型，从而在各种零样本和少样本情况下使用更小的模型时获得了优于现有方法的性能。",
    "en_tdlr": "DiSTRICT is a generalizable in-context tuning approach for Dialogue State Tracking (DST) that does not require hand-crafted templates. It retrieves relevant training examples to fine-tune the DST model in various zero-shot and few-shot settings, outperforming existing methods with a smaller model."
}