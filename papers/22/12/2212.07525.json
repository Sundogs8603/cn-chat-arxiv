{
    "title": "Efficient Self-supervised Learning with Contextualized Target Representations for Vision, Speech and Language. (arXiv:2212.07525v2 [cs.LG] UPDATED)",
    "abstract": "Current self-supervised learning algorithms are often modality-specific and require large amounts of computational resources. To address these issues, we increase the training efficiency of data2vec, a learning objective that generalizes across several modalities. We do not encode masked tokens, use a fast convolutional decoder and amortize the effort to build teacher representations. data2vec 2.0 benefits from the rich contextualized target representations introduced in data2vec which enable a fast self-supervised learner. Experiments on ImageNet-1K image classification show that data2vec 2.0 matches the accuracy of Masked Autoencoders in 16.4x lower pre-training time, on Librispeech speech recognition it performs as well as wav2vec 2.0 in 10.6x less time, and on GLUE natural language understanding it matches a retrained RoBERTa model in half the time. Trading some speed for accuracy results in ImageNet-1K top-1 accuracy of 86.8\\% with a ViT-L model trained for 150 epochs.",
    "link": "http://arxiv.org/abs/2212.07525",
    "context": "Title: Efficient Self-supervised Learning with Contextualized Target Representations for Vision, Speech and Language. (arXiv:2212.07525v2 [cs.LG] UPDATED)\nAbstract: Current self-supervised learning algorithms are often modality-specific and require large amounts of computational resources. To address these issues, we increase the training efficiency of data2vec, a learning objective that generalizes across several modalities. We do not encode masked tokens, use a fast convolutional decoder and amortize the effort to build teacher representations. data2vec 2.0 benefits from the rich contextualized target representations introduced in data2vec which enable a fast self-supervised learner. Experiments on ImageNet-1K image classification show that data2vec 2.0 matches the accuracy of Masked Autoencoders in 16.4x lower pre-training time, on Librispeech speech recognition it performs as well as wav2vec 2.0 in 10.6x less time, and on GLUE natural language understanding it matches a retrained RoBERTa model in half the time. Trading some speed for accuracy results in ImageNet-1K top-1 accuracy of 86.8\\% with a ViT-L model trained for 150 epochs.",
    "path": "papers/22/12/2212.07525.json",
    "total_tokens": 980,
    "translated_title": "面向视觉、语音和语言的上下文化目标表示自监督学习高效性改进",
    "translated_abstract": "当前的自监督学习算法通常是模态特定的，需要大量的计算资源。为了解决这些问题，我们提高了data2vec的训练效率，该学习目标可以推广到多种模态。我们不对掩蔽标记进行编码，使用快速卷积解码器，并分摊构建教师表示的工作。data2vec 2.0受到data2vec引入的丰富上下文化目标表示的益处，可以实现快速自监督学习。在ImageNet-1K图像分类实验中，data2vec 2.0在低16.4倍的预训练时间内与蒙版自编码器的准确率相匹配，在Librispeech语音识别中，它的表现与wav2vec 2.0相当，时间少10.6倍，在GLUE自然语言理解方面，它与重新训练的RoBERTa模型的时间相比减半。在牺牲一定的速度以换取准确性的情况下，使用训练了150个epochs的ViT-L模型可以得到86.8\\%的ImageNet-1K top-1准确率。",
    "tldr": "本文提出了一种上下文化目标表示自监督学习的高效性改进方法，称为data2vec 2.0，它在多项任务中取得了和其他算法相当的准确率，但需要的预训练时间较短。",
    "en_tdlr": "This paper proposes an efficient improvement method for self-supervised learning with contextualized target representations, called data2vec 2.0, which achieves comparable accuracy in multiple tasks to other algorithms but with shorter pre-training time."
}