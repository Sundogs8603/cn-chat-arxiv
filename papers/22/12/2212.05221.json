{
    "title": "REVEAL: Retrieval-Augmented Visual-Language Pre-Training with Multi-Source Multimodal Knowledge Memory. (arXiv:2212.05221v2 [cs.CV] UPDATED)",
    "abstract": "In this paper, we propose an end-to-end Retrieval-Augmented Visual Language Model (REVEAL) that learns to encode world knowledge into a large-scale memory, and to retrieve from it to answer knowledge-intensive queries. REVEAL consists of four key components: the memory, the encoder, the retriever and the generator. The large-scale memory encodes various sources of multimodal world knowledge (e.g. image-text pairs, question answering pairs, knowledge graph triplets, etc) via a unified encoder. The retriever finds the most relevant knowledge entries in the memory, and the generator fuses the retrieved knowledge with the input query to produce the output. A key novelty in our approach is that the memory, encoder, retriever and generator are all pre-trained end-to-end on a massive amount of data. Furthermore, our approach can use a diverse set of multimodal knowledge sources, which is shown to result in significant gains. We show that REVEAL achieves state-of-the-art results on visual ques",
    "link": "http://arxiv.org/abs/2212.05221",
    "context": "Title: REVEAL: Retrieval-Augmented Visual-Language Pre-Training with Multi-Source Multimodal Knowledge Memory. (arXiv:2212.05221v2 [cs.CV] UPDATED)\nAbstract: In this paper, we propose an end-to-end Retrieval-Augmented Visual Language Model (REVEAL) that learns to encode world knowledge into a large-scale memory, and to retrieve from it to answer knowledge-intensive queries. REVEAL consists of four key components: the memory, the encoder, the retriever and the generator. The large-scale memory encodes various sources of multimodal world knowledge (e.g. image-text pairs, question answering pairs, knowledge graph triplets, etc) via a unified encoder. The retriever finds the most relevant knowledge entries in the memory, and the generator fuses the retrieved knowledge with the input query to produce the output. A key novelty in our approach is that the memory, encoder, retriever and generator are all pre-trained end-to-end on a massive amount of data. Furthermore, our approach can use a diverse set of multimodal knowledge sources, which is shown to result in significant gains. We show that REVEAL achieves state-of-the-art results on visual ques",
    "path": "papers/22/12/2212.05221.json",
    "total_tokens": 1019,
    "translated_title": "REVEAL: 检索增强的多源多模态知识存储的视觉语言预训练。",
    "translated_abstract": "本文提出了一种端到端的检索增强的视觉语言模型(REVEAL)，该模型学会将世界知识编码到大规模存储器中，并从中检索以回答知识密集型查询。REVEAL由四个关键组件组成：存储器、编码器、检索器和生成器。大规模存储器通过统一编码器对各种多模态世界知识来源（如图像-文本对、问答对、知识图谱三元组等）进行编码。检索器在存储器中找到最相关的知识条目，生成器将检索到的知识与输入查询融合产生输出。我们方法的一个关键创新是，存储器、编码器、检索器和生成器都在海量数据上进行端到端预训练。此外，我们的方法可以使用多种多模态知识源，这在实验中证明了显著的收益。我们展示了REVEAL在视觉问答任务上取得了最先进的结果。",
    "tldr": "本文提出了一种检索增强的视觉语言模型(REVEAL)，其中包含四个关键组件：存储器、编码器、检索器和生成器。该模型可以利用多种多模态知识源，并实现了端到端预训练，在视觉问答任务上取得了最先进的结果。",
    "en_tdlr": "This paper proposes a Retrieval-Augmented Visual Language Model (REVEAL) that encodes world knowledge into a large-scale memory and retrieves it to answer knowledge-intensive queries. REVEAL consists of four key components: the memory, the encoder, the retriever, and the generator. A key novelty in our approach is that the memory, encoder, retriever, and generator are all pre-trained end-to-end on a massive amount of data. REVEAL achieves state-of-the-art results on visual question answering tasks by leveraging diverse multimodal knowledge sources."
}