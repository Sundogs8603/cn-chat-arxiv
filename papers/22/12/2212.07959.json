{
    "title": "Scalable Bayesian Uncertainty Quantification for Neural Network Potentials: Promise and Pitfalls. (arXiv:2212.07959v2 [physics.chem-ph] UPDATED)",
    "abstract": "Neural network (NN) potentials promise highly accurate molecular dynamics (MD) simulations within the computational complexity of classical MD force fields. However, when applied outside their training domain, NN potential predictions can be inaccurate, increasing the need for Uncertainty Quantification (UQ). Bayesian modeling provides the mathematical framework for UQ, but classical Bayesian methods based on Markov chain Monte Carlo (MCMC) are computationally intractable for NN potentials. By training graph NN potentials for coarse-grained systems of liquid water and alanine dipeptide, we demonstrate here that scalable Bayesian UQ via stochastic gradient MCMC (SG-MCMC) yields reliable uncertainty estimates for MD observables. We show that cold posteriors can reduce the required training data size and that for reliable UQ, multiple Markov chains are needed. Additionally, we find that SG-MCMC and the Deep Ensemble method achieve comparable results, despite shorter training and less hype",
    "link": "http://arxiv.org/abs/2212.07959",
    "context": "Title: Scalable Bayesian Uncertainty Quantification for Neural Network Potentials: Promise and Pitfalls. (arXiv:2212.07959v2 [physics.chem-ph] UPDATED)\nAbstract: Neural network (NN) potentials promise highly accurate molecular dynamics (MD) simulations within the computational complexity of classical MD force fields. However, when applied outside their training domain, NN potential predictions can be inaccurate, increasing the need for Uncertainty Quantification (UQ). Bayesian modeling provides the mathematical framework for UQ, but classical Bayesian methods based on Markov chain Monte Carlo (MCMC) are computationally intractable for NN potentials. By training graph NN potentials for coarse-grained systems of liquid water and alanine dipeptide, we demonstrate here that scalable Bayesian UQ via stochastic gradient MCMC (SG-MCMC) yields reliable uncertainty estimates for MD observables. We show that cold posteriors can reduce the required training data size and that for reliable UQ, multiple Markov chains are needed. Additionally, we find that SG-MCMC and the Deep Ensemble method achieve comparable results, despite shorter training and less hype",
    "path": "papers/22/12/2212.07959.json",
    "total_tokens": 970,
    "translated_title": "可扩展的贝叶斯不确定性量化方法用于神经网络势的研究：机遇与挑战",
    "translated_abstract": "神经网络（NN）势方法在计算复杂度可达到经典分子动力学力场的情况下，具有高精度的分子动力学（MD）模拟的潜力。然而，当应用于其训练领域之外时，NN势的预测可能不准确，因此增加了对不确定性量化（UQ）的需求。贝叶斯建模提供了UQ的数学框架，但基于马尔科夫链蒙特卡罗（MCMC）的传统贝叶斯方法在NN势中计算复杂性上存在问题。通过对粗粒化的液态水和丙氨酸二肽系统训练图NN势，我们在这里展示了通过随机梯度MCMC（SG-MCMC）实现可扩展贝叶斯UQ的可靠性估计MD可观测量。我们表明冷后验分布可以减少所需的训练数据大小，而为了可靠的UQ，需要多个马尔科夫链。此外，我们发现SG-MCMC和深度集合方法在结果上具有可比性，尽管训练时间较短且没有过度宣传。",
    "tldr": "神经网络势的贝叶斯不确定性量化方法通过随机梯度MCMC实现可扩展的UQ，可准确估计MD可观测量，要求更少的训练数据和多个马尔科夫链。"
}