{
    "title": "FunkNN: Neural Interpolation for Functional Generation. (arXiv:2212.14042v2 [eess.IV] UPDATED)",
    "abstract": "Can we build continuous generative models which generalize across scales, can be evaluated at any coordinate, admit calculation of exact derivatives, and are conceptually simple? Existing MLP-based architectures generate worse samples than the grid-based generators with favorable convolutional inductive biases. Models that focus on generating images at different scales do better, but employ complex architectures not designed for continuous evaluation of images and derivatives. We take a signal-processing perspective and treat continuous image generation as interpolation from samples. Indeed, correctly sampled discrete images contain all information about the low spatial frequencies. The question is then how to extrapolate the spectrum in a data-driven way while meeting the above design criteria. Our answer is FunkNN -- a new convolutional network which learns how to reconstruct continuous images at arbitrary coordinates and can be applied to any image dataset. Combined with a discrete ",
    "link": "http://arxiv.org/abs/2212.14042",
    "context": "Title: FunkNN: Neural Interpolation for Functional Generation. (arXiv:2212.14042v2 [eess.IV] UPDATED)\nAbstract: Can we build continuous generative models which generalize across scales, can be evaluated at any coordinate, admit calculation of exact derivatives, and are conceptually simple? Existing MLP-based architectures generate worse samples than the grid-based generators with favorable convolutional inductive biases. Models that focus on generating images at different scales do better, but employ complex architectures not designed for continuous evaluation of images and derivatives. We take a signal-processing perspective and treat continuous image generation as interpolation from samples. Indeed, correctly sampled discrete images contain all information about the low spatial frequencies. The question is then how to extrapolate the spectrum in a data-driven way while meeting the above design criteria. Our answer is FunkNN -- a new convolutional network which learns how to reconstruct continuous images at arbitrary coordinates and can be applied to any image dataset. Combined with a discrete ",
    "path": "papers/22/12/2212.14042.json",
    "total_tokens": 890,
    "translated_title": "FunkNN：功能生成的神经插值",
    "translated_abstract": "我们能否构建连续的生成模型，这些模型可以跨尺度泛化，并在任何坐标处进行评估，可以计算精确的导数，并且在概念上很简单？现有的基于MLP的架构生成的样本比具有有利卷积归纳偏差的网格生成器差。专注于在不同尺度上生成图像的模型效果更好，但采用的架构复杂，不适用于对图像和导数进行连续评估。我们采用信号处理的视角，并将连续图像生成视为从样本进行插值。确实，正确采样的离散图像包含有关低空间频率的所有信息。问题是如何以数据驱动的方式外推频谱，同时满足上述设计标准。我们的答案是FunkNN--一种新的卷积网络，它学习如何在任意坐标重构连续图像，并可以应用于任何图像数据集。结合离散采样步骤，FunkNN在连续域中实现了最先进的图像生成质量，优于现有的基于MLP的方法。",
    "tldr": "FunkNN是一种新的卷积网络，可以连续地重建图像，实现了最先进的图像生成质量，优于现有的基于MLP的方法。",
    "en_tdlr": "FunkNN is a new convolutional network that can reconstruct images continuously, achieving state-of-the-art image generation quality and outperforming existing MLP-based methods."
}