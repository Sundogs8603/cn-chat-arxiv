{
    "title": "Provable Robust Saliency-based Explanations. (arXiv:2212.14106v3 [cs.LG] UPDATED)",
    "abstract": "Robust explanations of machine learning models are critical to establishing human trust in the models. The top-$k$ intersection is widely used to evaluate the robustness of explanations. However, most existing attacking and defense strategies are based on $\\ell_p$ norms, thus creating a mismatch between the evaluation and optimization objectives. To this end, we define explanation thickness for measuring top-$k$ salient features ranking stability, and design the \\textit{R2ET} algorithm based on a novel tractable surrogate to maximize the thickness and stabilize the top salient features efficiently. Theoretically, we prove a connection between R2ET and adversarial training; using a novel multi-objective optimization formulation and a generalization error bound, we further prove that the surrogate objective can improve both the numerical and statistical stability of the explanations. Experiments with a wide spectrum of network architectures and data modalities demonstrate that R2ET attai",
    "link": "http://arxiv.org/abs/2212.14106",
    "context": "Title: Provable Robust Saliency-based Explanations. (arXiv:2212.14106v3 [cs.LG] UPDATED)\nAbstract: Robust explanations of machine learning models are critical to establishing human trust in the models. The top-$k$ intersection is widely used to evaluate the robustness of explanations. However, most existing attacking and defense strategies are based on $\\ell_p$ norms, thus creating a mismatch between the evaluation and optimization objectives. To this end, we define explanation thickness for measuring top-$k$ salient features ranking stability, and design the \\textit{R2ET} algorithm based on a novel tractable surrogate to maximize the thickness and stabilize the top salient features efficiently. Theoretically, we prove a connection between R2ET and adversarial training; using a novel multi-objective optimization formulation and a generalization error bound, we further prove that the surrogate objective can improve both the numerical and statistical stability of the explanations. Experiments with a wide spectrum of network architectures and data modalities demonstrate that R2ET attai",
    "path": "papers/22/12/2212.14106.json",
    "total_tokens": 905,
    "translated_title": "可证明鲁棒的基于显著性的解释",
    "translated_abstract": "机器学习模型的鲁棒解释对于建立人类对模型的信任至关重要。通过使用顶部-k的交集来评估解释的鲁棒性是常用的方法。然而，大多数现有的攻击和防御策略都基于$\\ell_p$范数，从而在评估和优化目标之间存在不匹配。为此，我们定义了解释的厚度来衡量顶部-k显著特征排名的稳定性，并设计了基于一种新颖可行的替代目标的R2ET算法，以高效地最大化厚度并稳定顶部显著特征。在理论上，我们证明了R2ET和对抗训练之间的联系；通过使用一种新颖的多目标优化公式和泛化误差界，我们进一步证明了替代目标可以改进解释的数值和统计稳定性。通过对各种网络架构和数据模态进行实验，验证了R2ET的性能。",
    "tldr": "本文提出了一种可证明鲁棒的基于显著性的解释方法，通过最大化解释厚度和稳定顶部显著特征，改进了解释的数值和统计稳定性。实验证明了该方法在各种网络和数据上的性能。",
    "en_tdlr": "This paper proposes a provable robust saliency-based explanation method, which improves the numerical and statistical stability of explanations by maximizing explanation thickness and stabilizing top salient features. Experiments demonstrate its performance on various networks and datasets."
}