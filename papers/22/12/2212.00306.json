{
    "title": "Decentralized Matrix Factorization with Heterogeneous Differential Privacy. (arXiv:2212.00306v2 [cs.LG] UPDATED)",
    "abstract": "Conventional matrix factorization relies on centralized collection of users' data for recommendation, which might introduce an increased risk of privacy leakage especially when the recommender is untrusted. Existing differentially private matrix factorization methods either assume the recommender is trusted, or can only provide a uniform level of privacy protection for all users and items with untrusted recommender. In this paper, we propose a novel Heterogeneous Differentially Private Matrix Factorization algorithm (denoted as HDPMF) for untrusted recommender. To the best of our knowledge, we are the first to achieve heterogeneous differential privacy for decentralized matrix factorization in untrusted recommender scenario. Specifically, our framework uses modified stretching mechanism with an innovative rescaling scheme to achieve better trade off between privacy and accuracy. Meanwhile, by allocating privacy budget properly, we can capture homogeneous privacy preference within a use",
    "link": "http://arxiv.org/abs/2212.00306",
    "context": "Title: Decentralized Matrix Factorization with Heterogeneous Differential Privacy. (arXiv:2212.00306v2 [cs.LG] UPDATED)\nAbstract: Conventional matrix factorization relies on centralized collection of users' data for recommendation, which might introduce an increased risk of privacy leakage especially when the recommender is untrusted. Existing differentially private matrix factorization methods either assume the recommender is trusted, or can only provide a uniform level of privacy protection for all users and items with untrusted recommender. In this paper, we propose a novel Heterogeneous Differentially Private Matrix Factorization algorithm (denoted as HDPMF) for untrusted recommender. To the best of our knowledge, we are the first to achieve heterogeneous differential privacy for decentralized matrix factorization in untrusted recommender scenario. Specifically, our framework uses modified stretching mechanism with an innovative rescaling scheme to achieve better trade off between privacy and accuracy. Meanwhile, by allocating privacy budget properly, we can capture homogeneous privacy preference within a use",
    "path": "papers/22/12/2212.00306.json",
    "total_tokens": 869,
    "translated_title": "具有异构差分隐私的分散矩阵分解",
    "translated_abstract": "传统的矩阵分解依赖于对用户数据的集中收集来进行推荐，这可能会增加隐私泄露的风险，特别是在推荐者不可信的情况下。现有的差分隐私矩阵分解方法要么假设推荐者是可信的，要么只能为所有用户和物品提供统一级别的隐私保护，当推荐者不可信时。在本文中，我们提出了一种新颖的用于不可信推荐者的异构差分隐私矩阵分解算法（称为HDPMF）。据我们所知，我们是第一个在不可信推荐者场景下实现分布式矩阵分解的异构差分隐私的方法。具体而言，我们的框架使用改进的拉伸机制和创新的重新缩放方案，在隐私和准确性之间实现更好的权衡。同时，通过适当分配隐私预算，我们可以捕捉到用户内的同质隐私偏好。",
    "tldr": "本文提出了一种用于不可信推荐者的异构差分隐私矩阵分解算法，通过修改拉伸机制和重新缩放方案，实现了隐私和准确性的权衡。",
    "en_tdlr": "This paper presents a heterogeneous differentially private matrix factorization algorithm for untrusted recommenders, achieving a trade-off between privacy and accuracy through modified stretching mechanism and rescaling scheme."
}