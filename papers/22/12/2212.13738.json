{
    "title": "TempCLR: Temporal Alignment Representation with Contrastive Learning. (arXiv:2212.13738v2 [cs.CV] UPDATED)",
    "abstract": "Video representation learning has been successful in video-text pre-training for zero-shot transfer, where each sentence is trained to be close to the paired video clips in a common feature space. For long videos, given a paragraph of description where the sentences describe different segments of the video, by matching all sentence-clip pairs, the paragraph and the full video are aligned implicitly. However, such unit-level comparison may ignore global temporal context, which inevitably limits the generalization ability. In this paper, we propose a contrastive learning framework TempCLR to compare the full video and the paragraph explicitly. As the video/paragraph is formulated as a sequence of clips/sentences, under the constraint of their temporal order, we use dynamic time warping to compute the minimum cumulative cost over sentence-clip pairs as the sequence-level distance. To explore the temporal dynamics, we break the consistency of temporal succession by shuffling video clips w.",
    "link": "http://arxiv.org/abs/2212.13738",
    "context": "Title: TempCLR: Temporal Alignment Representation with Contrastive Learning. (arXiv:2212.13738v2 [cs.CV] UPDATED)\nAbstract: Video representation learning has been successful in video-text pre-training for zero-shot transfer, where each sentence is trained to be close to the paired video clips in a common feature space. For long videos, given a paragraph of description where the sentences describe different segments of the video, by matching all sentence-clip pairs, the paragraph and the full video are aligned implicitly. However, such unit-level comparison may ignore global temporal context, which inevitably limits the generalization ability. In this paper, we propose a contrastive learning framework TempCLR to compare the full video and the paragraph explicitly. As the video/paragraph is formulated as a sequence of clips/sentences, under the constraint of their temporal order, we use dynamic time warping to compute the minimum cumulative cost over sentence-clip pairs as the sequence-level distance. To explore the temporal dynamics, we break the consistency of temporal succession by shuffling video clips w.",
    "path": "papers/22/12/2212.13738.json",
    "total_tokens": 706,
    "translated_title": "TempCLR:基于对比学习的时间对齐表示",
    "translated_abstract": "视频表示学习在视频-文本预训练中取得了成功，在其中每个句子都被训练为接近于共同特征空间中配对的视频剪辑。然而，对于长视频，由于句子描述视频的不同部分，单元级别的比较可能会忽略全局的时间上下文，这必然会限制泛化能力。为此，我们提出了一个对比学习框架TempCLR，以显式地比较完整的视频和段落。",
    "tldr": "本文提出了一个基于对比学习的框架TempCLR，用于显式比较完整的视频和段落，解决单元级别比较可能忽略全局时间上下文的问题。"
}