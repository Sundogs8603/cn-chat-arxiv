{
    "title": "Transformers learn in-context by gradient descent. (arXiv:2212.07677v2 [cs.LG] UPDATED)",
    "abstract": "At present, the mechanisms of in-context learning in Transformers are not well understood and remain mostly an intuition. In this paper, we suggest that training Transformers on auto-regressive objectives is closely related to gradient-based meta-learning formulations. We start by providing a simple weight construction that shows the equivalence of data transformations induced by 1) a single linear self-attention layer and by 2) gradient-descent (GD) on a regression loss. Motivated by that construction, we show empirically that when training self-attention-only Transformers on simple regression tasks either the models learned by GD and Transformers show great similarity or, remarkably, the weights found by optimization match the construction. Thus we show how trained Transformers become mesa-optimizers i.e. learn models by gradient descent in their forward pass. This allows us, at least in the domain of regression problems, to mechanistically understand the inner workings of in-context",
    "link": "http://arxiv.org/abs/2212.07677",
    "context": "Title: Transformers learn in-context by gradient descent. (arXiv:2212.07677v2 [cs.LG] UPDATED)\nAbstract: At present, the mechanisms of in-context learning in Transformers are not well understood and remain mostly an intuition. In this paper, we suggest that training Transformers on auto-regressive objectives is closely related to gradient-based meta-learning formulations. We start by providing a simple weight construction that shows the equivalence of data transformations induced by 1) a single linear self-attention layer and by 2) gradient-descent (GD) on a regression loss. Motivated by that construction, we show empirically that when training self-attention-only Transformers on simple regression tasks either the models learned by GD and Transformers show great similarity or, remarkably, the weights found by optimization match the construction. Thus we show how trained Transformers become mesa-optimizers i.e. learn models by gradient descent in their forward pass. This allows us, at least in the domain of regression problems, to mechanistically understand the inner workings of in-context",
    "path": "papers/22/12/2212.07677.json",
    "total_tokens": 966,
    "translated_title": "Transformer模型通过梯度下降实现上下文学习",
    "translated_abstract": "目前，Transformers模型中上下文学习的机制尚未得到很好的理解，大多只停留在直觉上。本文提出，训练Transformer模型应用于自回归目标问题时，与基于梯度的元学习的形式密切相关。我们首先提供一个简单的权重构造，证明了由单个线性自注意力层引发的数据转换与由具有回归损失的梯度下降（GD）获得的转换具有等价性。在此基础上，我们通过实验证明，当仅训练自注意力Transformer模型进行简单的回归任务时，通过GD优化得到的模型与模型权重十分相似，或者在某些情况下，GD优化的权重与构造的权重相同。因此，我们展示了经过训练的Transformer模型是如何在前向传递中通过梯度下降学习模型的“底层优化程序”的。在回归问题的领域中，这使我们能够从机械的角度理解Transformers模型中上下文学习的内部机制。",
    "tldr": "本文提出，训练Transformer模型应用于自回归目标问题时，与基于梯度的元学习的形式密切相关，通过梯度下降学习模型的“底层优化程序”的机制，在回归问题的领域中从机械的角度理解了Transformers模型中上下文学习的内部机制。",
    "en_tdlr": "This paper proposes that training Transformer models on auto-regressive objectives is closely related to gradient-based meta-learning formulations, which allows the trained models to become mesa-optimizers by learning models through gradient descent in their forward pass, providing a mechanistic understanding of in-context learning in Transformers in the field of regression problems."
}