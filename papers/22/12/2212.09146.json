{
    "title": "Can Retriever-Augmented Language Models Reason? The Blame Game Between the Retriever and the Language Model. (arXiv:2212.09146v2 [cs.CL] UPDATED)",
    "abstract": "Augmenting pretrained language models with retrievers to select the supporting documents has shown promise in effectively solving common NLP problems, including language modeling and question answering, in an interpretable way. In this paper, we first study the strengths and weaknesses of different retriever-augmented language models (REALM, $k$NN-LM, FiD coupled with DPR, and ATLAS and Flan-T5 coupled with Contriever) in reasoning over the retrieved statements in different tasks. We show how the retrieve-then-read models' limitations in reasoning are rooted both in the retriever module as well as the language model. Our experimental results demonstrate that the similarity metric used by the retrievers is generally insufficient for reasoning tasks. Additionally, we show that the language models in retriever-augmented models do not take the complicated relations between the statements into account, which leads to poor reasoning performance even when using the larger models. Moreover, we",
    "link": "http://arxiv.org/abs/2212.09146",
    "context": "Title: Can Retriever-Augmented Language Models Reason? The Blame Game Between the Retriever and the Language Model. (arXiv:2212.09146v2 [cs.CL] UPDATED)\nAbstract: Augmenting pretrained language models with retrievers to select the supporting documents has shown promise in effectively solving common NLP problems, including language modeling and question answering, in an interpretable way. In this paper, we first study the strengths and weaknesses of different retriever-augmented language models (REALM, $k$NN-LM, FiD coupled with DPR, and ATLAS and Flan-T5 coupled with Contriever) in reasoning over the retrieved statements in different tasks. We show how the retrieve-then-read models' limitations in reasoning are rooted both in the retriever module as well as the language model. Our experimental results demonstrate that the similarity metric used by the retrievers is generally insufficient for reasoning tasks. Additionally, we show that the language models in retriever-augmented models do not take the complicated relations between the statements into account, which leads to poor reasoning performance even when using the larger models. Moreover, we",
    "path": "papers/22/12/2212.09146.json",
    "total_tokens": 1298,
    "translated_title": "检索增强语言模型是否具备推理能力？检索模块和语言模型之争",
    "translated_abstract": "预先训练的语言模型采用检索器来选择支持文档，在解决常见的NLP问题（包括语言建模和问答）方面表现出良好的效果，并且具有可解释性。本文首先研究了检索增强语言模型（REALM，kNN-LM，FiD和DPR，ATLAS和Flan-T5和Contriever耦合）在不同任务中推理检索语句的优点和局限性。我们展示了检索-阅读模型在推理方面的局限性既来自检索模块，也来自语言模型。实验结果表明，检索器使用的相似度度量通常不足以用于推理任务。此外，我们发现，检索增强模型中的语言模型不考虑语句之间的复杂关系，导致即使使用较大的模型，推理性能也不佳。此外，我们发现检索器和语言模型在推理中面临着“责怪游戏”的问题：当检索器选择正确的语句时，语言模型可以进行良好的推理；当检索器选择错误的语句时，语言模型无法进行良好的推理。为解决这些问题，我们提出了一种新的框架ReForMask，采用掩码检索方法来更好地捕捉语句之间的复杂关系。我们的实验结果表明，ReForMask在多种常见的NLP任务上显著优于现有的检索增强模型。",
    "tldr": "本论文研究了检索增强语言模型的推理能力，发现检索器和语言模型之间存在推卸责任的问题，且检索器选择的句子和语言模型不考虑句子之间的复杂关系都会影响推理性能。针对这些问题，本文提出了一种新的框架ReForMask，采用掩码检索方法来更好地捕捉语句之间的复杂关系并在多个任务上实现了显著优化。",
    "en_tdlr": "This paper investigates the reasoning ability of retriever-augmented language models, and finds that the retriever and language model face a blame game problem, and that the retriever's choice of sentences and the language model's failure to consider the complex relations between sentences both affect reasoning performance. To address these issues, the paper proposes a novel framework, ReForMask, which uses a masked retrieval approach to better capture the complex relations between sentences and achieves significant optimization on multiple tasks."
}