{
    "title": "Large Language Models Are Reasoning Teachers. (arXiv:2212.10071v2 [cs.CL] UPDATED)",
    "abstract": "Recent works have shown that chain-of-thought (CoT) prompting can elicit language models to solve complex reasoning tasks, step-by-step. However, prompt-based CoT methods are dependent on very large models such as GPT-3 175B which are prohibitive to deploy at scale. In this paper, we use these large models as reasoning teachers to enable complex reasoning in smaller models and reduce model size requirements by several orders of magnitude. We propose Fine-tune-CoT, a method that generates reasoning samples from very large teacher models to fine-tune smaller models. We evaluate our method on a wide range of public models and complex tasks. We find that Fine-tune-CoT enables substantial reasoning capability in small models, far outperforming prompt-based baselines and even the teacher model in many tasks. Additionally, we extend our method by leveraging the teacher model's ability to generate multiple distinct rationales for each original sample. Enriching the fine-tuning data with such d",
    "link": "http://arxiv.org/abs/2212.10071",
    "context": "Title: Large Language Models Are Reasoning Teachers. (arXiv:2212.10071v2 [cs.CL] UPDATED)\nAbstract: Recent works have shown that chain-of-thought (CoT) prompting can elicit language models to solve complex reasoning tasks, step-by-step. However, prompt-based CoT methods are dependent on very large models such as GPT-3 175B which are prohibitive to deploy at scale. In this paper, we use these large models as reasoning teachers to enable complex reasoning in smaller models and reduce model size requirements by several orders of magnitude. We propose Fine-tune-CoT, a method that generates reasoning samples from very large teacher models to fine-tune smaller models. We evaluate our method on a wide range of public models and complex tasks. We find that Fine-tune-CoT enables substantial reasoning capability in small models, far outperforming prompt-based baselines and even the teacher model in many tasks. Additionally, we extend our method by leveraging the teacher model's ability to generate multiple distinct rationales for each original sample. Enriching the fine-tuning data with such d",
    "path": "papers/22/12/2212.10071.json",
    "total_tokens": 915,
    "translated_title": "大型语言模型是推理教师",
    "translated_abstract": "最近的研究表明，思维链条提示可以引导语言模型逐步解决复杂的推理任务。然而，基于提示的思维链条方法依赖于像GPT-3 175B这样非常大的模型，这在规模上是不可行的。本文提出了Fine-tune-CoT方法，使用这些大型模型作为推理教师，以让较小的模型也能进行复杂推理，从而使模型尺寸要求减少数个数量级。我们在公共模型和复杂任务上评估了该方法，发现Fine-tune-CoT可以在小型模型中实现实质性的推理能力，远远优于基于提示的基线方法，甚至在许多任务中也优于教师模型。此外，我们扩展了该方法，利用教师模型的能力为每个原始样本生成多个不同的原因解释，从而增强了微调数据。",
    "tldr": "本文提出了Fine-tune-CoT，一种使用大型模型作为推理教师让较小模型也能进行复杂推理的方法，可以远远优于基于提示的基线方法，在多个任务上进行了评估。此外，该方法还利用教师模型的能力为每个原始样本生成多个不同的原因解释。",
    "en_tdlr": "This paper proposes Fine-tune-CoT, a method that uses large language models as reasoning teachers to enable complex reasoning in smaller models. It outperforms prompt-based baselines and even the teacher model in many tasks. The method is also extended to generate multiple distinct rationales for each original sample."
}