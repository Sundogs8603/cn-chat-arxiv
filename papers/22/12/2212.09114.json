{
    "title": "CAPSTONE: Curriculum Sampling for Dense Retrieval with Document Expansion. (arXiv:2212.09114v2 [cs.CL] UPDATED)",
    "abstract": "The dual-encoder has become the de facto architecture for dense retrieval. Typically, it computes the latent representations of the query and document independently, thus failing to fully capture the interactions between the query and document. To alleviate this, recent research has focused on obtaining query-informed document representations. During training, it expands the document with a real query, but during inference, it replaces the real query with a generated one. This inconsistency between training and inference causes the dense retrieval model to prioritize query information while disregarding the document when computing the document representation. Consequently, it performs even worse than the vanilla dense retrieval model because its performance heavily relies on the relevance between the generated queries and the real query.In this paper, we propose a curriculum sampling strategy that utilizes pseudo queries during training and progressively enhances the relevance between ",
    "link": "http://arxiv.org/abs/2212.09114",
    "context": "Title: CAPSTONE: Curriculum Sampling for Dense Retrieval with Document Expansion. (arXiv:2212.09114v2 [cs.CL] UPDATED)\nAbstract: The dual-encoder has become the de facto architecture for dense retrieval. Typically, it computes the latent representations of the query and document independently, thus failing to fully capture the interactions between the query and document. To alleviate this, recent research has focused on obtaining query-informed document representations. During training, it expands the document with a real query, but during inference, it replaces the real query with a generated one. This inconsistency between training and inference causes the dense retrieval model to prioritize query information while disregarding the document when computing the document representation. Consequently, it performs even worse than the vanilla dense retrieval model because its performance heavily relies on the relevance between the generated queries and the real query.In this paper, we propose a curriculum sampling strategy that utilizes pseudo queries during training and progressively enhances the relevance between ",
    "path": "papers/22/12/2212.09114.json",
    "total_tokens": 825,
    "translated_title": "CAPSTONE: 使用课程采样进行密集检索与文档扩展",
    "translated_abstract": "双编码器已成为密集检索的事实标准架构。通常，它独立计算查询和文档的潜在表示，因此未能充分捕捉查询和文档之间的交互。为了缓解这个问题，最近的研究集中在获得查询相关的文档表示。在训练过程中，它通过真实查询扩展文档，但在推断过程中，它用生成的查询替换真实查询。这种训练和推断之间的不一致导致密集检索模型在计算文档表示时更加重视查询信息，而忽视文档。因此，它的性能比普通的密集检索模型还要差，因为它的性能严重依赖于生成的查询和真实查询之间的相关性。本文提出了一种课程采样策略，在训练过程中使用伪查询，并逐步增强生成的查询和真实查询之间的相关性。",
    "tldr": "本文提出了一种使用课程采样策略的密集检索方法，通过在训练中使用伪查询，逐步增强了生成的查询和真实查询之间的相关性。",
    "en_tdlr": "This paper proposes a curriculum sampling strategy for dense retrieval, which gradually enhances the relevance between the generated queries and the real query by using pseudo queries during training."
}