{
    "title": "Integration of Pre-trained Protein Language Models into Geometric Deep Learning Networks. (arXiv:2212.03447v2 [cs.LG] UPDATED)",
    "abstract": "Geometric deep learning has recently achieved great success in non-Euclidean domains, and learning on 3D structures of large biomolecules is emerging as a distinct research area. However, its efficacy is largely constrained due to the limited quantity of structural data. Meanwhile, protein language models trained on substantial 1D sequences have shown burgeoning capabilities with scale in a broad range of applications. Several previous studies consider combining these different protein modalities to promote the representation power of geometric neural networks, but fail to present a comprehensive understanding of their benefits. In this work, we integrate the knowledge learned by well-trained protein language models into several state-of-the-art geometric networks and evaluate a variety of protein representation learning benchmarks, including protein-protein interface prediction, model quality assessment, protein-protein rigid-body docking, and binding affinity prediction. Our findings",
    "link": "http://arxiv.org/abs/2212.03447",
    "context": "Title: Integration of Pre-trained Protein Language Models into Geometric Deep Learning Networks. (arXiv:2212.03447v2 [cs.LG] UPDATED)\nAbstract: Geometric deep learning has recently achieved great success in non-Euclidean domains, and learning on 3D structures of large biomolecules is emerging as a distinct research area. However, its efficacy is largely constrained due to the limited quantity of structural data. Meanwhile, protein language models trained on substantial 1D sequences have shown burgeoning capabilities with scale in a broad range of applications. Several previous studies consider combining these different protein modalities to promote the representation power of geometric neural networks, but fail to present a comprehensive understanding of their benefits. In this work, we integrate the knowledge learned by well-trained protein language models into several state-of-the-art geometric networks and evaluate a variety of protein representation learning benchmarks, including protein-protein interface prediction, model quality assessment, protein-protein rigid-body docking, and binding affinity prediction. Our findings",
    "path": "papers/22/12/2212.03447.json",
    "total_tokens": 904,
    "translated_title": "将预训练蛋白质语言模型集成到几何深度学习网络中",
    "translated_abstract": "几何深度学习在非欧几里得领域取得了巨大成功，学习大型生物分子的三维结构正在成为一个新兴的研究领域。然而，由于结构数据数量有限，其有效性受到很大限制。与此同时，针对丰富的一维序列训练的蛋白质语言模型在各种应用中展现出了不断增长的能力。之前的研究中有几个尝试将这些不同的蛋白质模态组合起来，以提升几何神经网络的表征能力，但未能给出对其优势的全面理解。本研究将经过良好训练的蛋白质语言模型的知识集成到几种最先进的几何网络中，并评估了多种蛋白质表征学习基准，包括蛋白质相互作用预测、模型质量评估、蛋白质相互作用刚体对接和结合亲和力预测。我们的发现",
    "tldr": "将预训练的蛋白质语言模型与几何深度学习网络相结合，提高了几何网络的表征能力，并在多个蛋白质学习任务上取得了良好的性能。",
    "en_tdlr": "Integrating pre-trained protein language models into geometric deep learning networks improves the representation power of geometric networks and achieves good performance on multiple protein learning tasks."
}