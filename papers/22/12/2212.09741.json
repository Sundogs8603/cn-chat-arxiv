{
    "title": "One Embedder, Any Task: Instruction-Finetuned Text Embeddings. (arXiv:2212.09741v3 [cs.CL] UPDATED)",
    "abstract": "We introduce INSTRUCTOR, a new method for computing text embeddings given task instructions: every text input is embedded together with instructions explaining the use case (e.g., task and domain descriptions). Unlike encoders from prior work that are more specialized, INSTRUCTOR is a single embedder that can generate text embeddings tailored to different downstream tasks and domains, without any further training. We first annotate instructions for 330 diverse tasks and train INSTRUCTOR on this multitask mixture with a contrastive loss. We evaluate INSTRUCTOR on 70 embedding evaluation tasks (66 of which are unseen during training), ranging from classification and information retrieval to semantic textual similarity and text generation evaluation. INSTRUCTOR, while having an order of magnitude fewer parameters than the previous best model, achieves state-of-the-art performance, with an average improvement of 3.4% compared to the previous best results on the 70 diverse datasets. Our ana",
    "link": "http://arxiv.org/abs/2212.09741",
    "context": "Title: One Embedder, Any Task: Instruction-Finetuned Text Embeddings. (arXiv:2212.09741v3 [cs.CL] UPDATED)\nAbstract: We introduce INSTRUCTOR, a new method for computing text embeddings given task instructions: every text input is embedded together with instructions explaining the use case (e.g., task and domain descriptions). Unlike encoders from prior work that are more specialized, INSTRUCTOR is a single embedder that can generate text embeddings tailored to different downstream tasks and domains, without any further training. We first annotate instructions for 330 diverse tasks and train INSTRUCTOR on this multitask mixture with a contrastive loss. We evaluate INSTRUCTOR on 70 embedding evaluation tasks (66 of which are unseen during training), ranging from classification and information retrieval to semantic textual similarity and text generation evaluation. INSTRUCTOR, while having an order of magnitude fewer parameters than the previous best model, achieves state-of-the-art performance, with an average improvement of 3.4% compared to the previous best results on the 70 diverse datasets. Our ana",
    "path": "papers/22/12/2212.09741.json",
    "total_tokens": 1015,
    "translated_title": "一种嵌入器，多种任务: 基于任务说明微调的文本嵌入方法",
    "translated_abstract": "我们引入了一种名为INSTRUCTOR的新方法，用于根据任务说明计算文本嵌入：每个文本输入都与解释用例（例如，任务和领域描述）一起嵌入。与之前更专业化的编码器不同，INSTRUCTOR是一个单一嵌入器，可以生成适用于不同下游任务和领域的文本嵌入，无需进一步训练。我们首先为330个不同的任务注释了任务说明，并使用对比损失在此多任务混合中训练INSTRUCTOR。我们在70个嵌入评估任务上评估了INSTRUCTOR（其中有66个在训练期间未见过），涵盖分类、信息检索、语义文本相似性和文本生成等方面的任务。INSTRUCTOR虽然拥有比之前最佳模型少一个数量级的参数，但在70个不同数据集上平均改进了3.4％，实现了最先进的性能。我们的分析显示，INSTRUCTOR适应不同任务和领域的能力是由于它有效地使用任务说明，它们作为编码器的软提示。我们还在三个下游任务上证明了INSTRUCTOR的实用性：领域适应、小样本学习和跨语言转移，在所有情况下都优于先前的最佳性能。",
    "tldr": "使用任务说明微调的单一文本嵌入器INSTRUCTOR，在多个领域和任务的基准测试中实现了最先进的性能，并且功能强大，适应性强。",
    "en_tdlr": "INSTRUCTOR, a single text embedder finetuned with task instructions, achieved state-of-the-art performance across diverse benchmarks and tasks, showcasing its powerful and adaptable capabilities."
}