{
    "title": "Quantizing Heavy-tailed Data in Statistical Estimation: (Near) Minimax Rates, Covariate Quantization, and Uniform Recovery. (arXiv:2212.14562v2 [math.ST] UPDATED)",
    "abstract": "This paper studies the quantization of heavy-tailed data in some fundamental statistical estimation problems, where the underlying distributions have bounded moments of some order. We propose to truncate and properly dither the data prior to a uniform quantization. Our major standpoint is that (near) minimax rates of estimation error are achievable merely from the quantized data produced by the proposed scheme. In particular, concrete results are worked out for covariance estimation, compressed sensing, and matrix completion, all agreeing that the quantization only slightly worsens the multiplicative factor. Besides, we study compressed sensing where both covariate (i.e., sensing vector) and response are quantized. Under covariate quantization, although our recovery program is non-convex because the covariance matrix estimator lacks positive semi-definiteness, all local minimizers are proved to enjoy near optimal error bound. Moreover, by the concentration inequality of product process",
    "link": "http://arxiv.org/abs/2212.14562",
    "context": "Title: Quantizing Heavy-tailed Data in Statistical Estimation: (Near) Minimax Rates, Covariate Quantization, and Uniform Recovery. (arXiv:2212.14562v2 [math.ST] UPDATED)\nAbstract: This paper studies the quantization of heavy-tailed data in some fundamental statistical estimation problems, where the underlying distributions have bounded moments of some order. We propose to truncate and properly dither the data prior to a uniform quantization. Our major standpoint is that (near) minimax rates of estimation error are achievable merely from the quantized data produced by the proposed scheme. In particular, concrete results are worked out for covariance estimation, compressed sensing, and matrix completion, all agreeing that the quantization only slightly worsens the multiplicative factor. Besides, we study compressed sensing where both covariate (i.e., sensing vector) and response are quantized. Under covariate quantization, although our recovery program is non-convex because the covariance matrix estimator lacks positive semi-definiteness, all local minimizers are proved to enjoy near optimal error bound. Moreover, by the concentration inequality of product process",
    "path": "papers/22/12/2212.14562.json",
    "total_tokens": 1103,
    "translated_title": "对统计估计中重尾数据的量化：（近乎）最小化速率，协变量量化和一致恢复",
    "translated_abstract": "本文研究了在一些基本统计估计问题中对重尾数据的量化，其中底层分布具有一定阶数的有界矩。我们提出在均匀量化之前对数据进行截断和适当抖动。我们的主要观点是，通过所提出的方案产生的量化数据仅需实现（近乎）最小化的估计误差速率。特别地，对协方差估计、压缩感知和矩阵补全进行了具体的结果推导，所有结果都表明量化仅使乘法因子稍微恶化。此外，我们研究了同时对协变量（即感知向量）和响应进行量化的压缩感知问题。在协变量量化下，尽管我们的恢复程序是非凸的，因为协方差矩阵估计值缺乏正半定性，但所有局部极小值都被证明具有近乎最优的误差界。此外，通过乘积过程的集中不等式",
    "tldr": "本文研究了在统计估计问题中对重尾数据的量化方法，提出了一种截断和适当抖动的方案，并证明了该方案可以实现（近乎）最小化的估计误差速率。具体应用包括协方差估计、压缩感知和矩阵补全，结果表明量化对乘法因子的影响较小。在同时对协变量和响应进行量化的压缩感知问题中，虽然恢复程序是非凸的，但所有局部极小值都有近乎最优的误差界。",
    "en_tdlr": "This paper investigates the quantization of heavy-tailed data in statistical estimation problems, proposing a truncation and proper dithering scheme. It shows that (near) minimax rates of estimation error can be achieved from the quantized data produced by this scheme. Concrete results are presented for covariance estimation, compressed sensing, and matrix completion, all demonstrating that quantization only slightly deteriorates the multiplicative factor. Furthermore, the paper addresses the compressed sensing problem with quantized covariates and response, proving that all local minimizers have near-optimal error bounds."
}