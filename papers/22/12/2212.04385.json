{
    "title": "BEVBert: Multimodal Map Pre-training for Language-guided Navigation. (arXiv:2212.04385v2 [cs.CV] UPDATED)",
    "abstract": "Large-scale pre-training has shown promising results on the vision-and-language navigation (VLN) task. However, most existing pre-training methods employ discrete panoramas to learn visual-textual associations. This requires the model to implicitly correlate incomplete, duplicate observations within the panoramas, which may impair an agent's spatial understanding. Thus, we propose a new map-based pre-training paradigm that is spatial-aware for use in VLN. Concretely, we build a local metric map to explicitly aggregate incomplete observations and remove duplicates, while modeling navigation dependency in a global topological map. This hybrid design can balance the demand of VLN for both short-term reasoning and long-term planning. Then, based on the hybrid map, we devise a pre-training framework to learn a multimodal map representation, which enhances spatial-aware cross-modal reasoning thereby facilitating the language-guided navigation goal. Extensive experiments demonstrate the effec",
    "link": "http://arxiv.org/abs/2212.04385",
    "context": "Title: BEVBert: Multimodal Map Pre-training for Language-guided Navigation. (arXiv:2212.04385v2 [cs.CV] UPDATED)\nAbstract: Large-scale pre-training has shown promising results on the vision-and-language navigation (VLN) task. However, most existing pre-training methods employ discrete panoramas to learn visual-textual associations. This requires the model to implicitly correlate incomplete, duplicate observations within the panoramas, which may impair an agent's spatial understanding. Thus, we propose a new map-based pre-training paradigm that is spatial-aware for use in VLN. Concretely, we build a local metric map to explicitly aggregate incomplete observations and remove duplicates, while modeling navigation dependency in a global topological map. This hybrid design can balance the demand of VLN for both short-term reasoning and long-term planning. Then, based on the hybrid map, we devise a pre-training framework to learn a multimodal map representation, which enhances spatial-aware cross-modal reasoning thereby facilitating the language-guided navigation goal. Extensive experiments demonstrate the effec",
    "path": "papers/22/12/2212.04385.json",
    "total_tokens": 946,
    "translated_title": "BEVBert: 用于语言导向导航的多模态地图预训练",
    "translated_abstract": "大规模预训练已经在视觉与语言导航（VLN）任务上显示出了很好的结果。然而，大多数现有的预训练方法采用离散的全景图来学习视觉-文本关联。这要求模型隐式地关联全景图中的不完整、重复的观察数据，这可能影响到智能体的空间理解能力。因此，我们提出了一种新的基于地图的预训练范式，以用于VLN中的空间感知。具体而言，我们构建了一个局部度量地图，明确地汇聚不完整的观察数据并消除重复，同时在一个全局拓扑地图中建模导航依赖关系。这种混合设计可以平衡VLN对短期推理和长期规划的需求。然后，基于混合地图，我们设计了一个预训练框架来学习多模态地图表示，从而增强了空间感知跨模态推理，有助于语言导向导航目标的实现。广泛的实验验证了该方法的有效性。",
    "tldr": "本论文提出了一种多模态地图预训练方法，用于语言导向导航任务。通过构建局部度量地图和全局拓扑地图，该方法能够准确刻画空间感知和导航依赖关系，从而提高了语言导向导航的性能。"
}