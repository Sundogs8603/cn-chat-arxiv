{
    "title": "SegAugment: Maximizing the Utility of Speech Translation Data with Segmentation-based Augmentations. (arXiv:2212.09699v2 [cs.CL] UPDATED)",
    "abstract": "End-to-end Speech Translation is hindered by a lack of available data resources. While most of them are based on documents, a sentence-level version is available, which is however single and static, potentially impeding the usefulness of the data. We propose a new data augmentation strategy, SegAugment, to address this issue by generating multiple alternative sentence-level versions of a dataset. Our method utilizes an Audio Segmentation system, which re-segments the speech of each document with different length constraints, after which we obtain the target text via alignment methods. Experiments demonstrate consistent gains across eight language pairs in MuST-C, with an average increase of 2.5 BLEU points, and up to 5 BLEU for low-resource scenarios in mTEDx. Furthermore, when combined with a strong system, SegAugment establishes new state-of-the-art results in MuST-C. Finally, we show that the proposed method can also successfully augment sentence-level datasets, and that it enables ",
    "link": "http://arxiv.org/abs/2212.09699",
    "context": "Title: SegAugment: Maximizing the Utility of Speech Translation Data with Segmentation-based Augmentations. (arXiv:2212.09699v2 [cs.CL] UPDATED)\nAbstract: End-to-end Speech Translation is hindered by a lack of available data resources. While most of them are based on documents, a sentence-level version is available, which is however single and static, potentially impeding the usefulness of the data. We propose a new data augmentation strategy, SegAugment, to address this issue by generating multiple alternative sentence-level versions of a dataset. Our method utilizes an Audio Segmentation system, which re-segments the speech of each document with different length constraints, after which we obtain the target text via alignment methods. Experiments demonstrate consistent gains across eight language pairs in MuST-C, with an average increase of 2.5 BLEU points, and up to 5 BLEU for low-resource scenarios in mTEDx. Furthermore, when combined with a strong system, SegAugment establishes new state-of-the-art results in MuST-C. Finally, we show that the proposed method can also successfully augment sentence-level datasets, and that it enables ",
    "path": "papers/22/12/2212.09699.json",
    "total_tokens": 1016,
    "translated_title": "SegAugment: 基于分段增强的语音翻译数据利用最大化",
    "translated_abstract": "端到端的语音翻译由于缺乏可用的数据资源而受到限制。虽然大多数资源是基于文档的，但也提供了一种句子级别的版本，但是它只有单个并且是固定的，可能会妨碍数据的有用性。我们提出了一种新的数据增强策略，SegAugment，通过生成数据集的多个句子级别的替代版本来解决这个问题。我们的方法利用音频分段系统，根据不同的长度约束重新分段每个文档的语音，然后通过对齐方法获取目标文本。实验证明，在MuST-C的八种语言对中，我们的方法具有一致的增益，平均增加了2.5 BLEU分数，并在mTEDx的低资源场景中获得了多达5 BLEU分数的提升。此外，当与强大的系统结合时，SegAugment在MuST-C中树立了新的状态记录。最后，我们还展示了该方法可以成功地增强句子级别数据集，并且使得端到端模型在低资源条件下的表现得到了提升。",
    "tldr": "该论文提出了一种新的数据增强策略SegAugment，利用音频分段系统生成数据集的多个句子级别的替代版本，能够提高语音翻译的性能，实验结果显示平均BLEU分数提高了2.5分，甚至在低资源情况下提高了5分。",
    "en_tdlr": "This paper proposes a new data augmentation strategy, SegAugment, which utilizes an audio segmentation system to generate multiple alternative sentence-level versions of a dataset, and consistently improves the performance of end-to-end speech translation, with an average increase of 2.5 BLEU points and up to 5 BLEU for low-resource scenarios in mTEDx, establishing new state-of-the-art results in MuST-C when combined with a strong system."
}