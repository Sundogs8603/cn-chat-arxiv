{
    "title": "DePlot: One-shot visual language reasoning by plot-to-table translation. (arXiv:2212.10505v2 [cs.CL] UPDATED)",
    "abstract": "Visual language such as charts and plots is ubiquitous in the human world. Comprehending plots and charts requires strong reasoning skills. Prior state-of-the-art (SOTA) models require at least tens of thousands of training examples and their reasoning capabilities are still much limited, especially on complex human-written queries. This paper presents the first one-shot solution to visual language reasoning. We decompose the challenge of visual language reasoning into two steps: (1) plot-to-text translation, and (2) reasoning over the translated text. The key in this method is a modality conversion module, named as DePlot, which translates the image of a plot or chart to a linearized table. The output of DePlot can then be directly used to prompt a pretrained large language model (LLM), exploiting the few-shot reasoning capabilities of LLMs. To obtain DePlot, we standardize the plot-to-table task by establishing unified task formats and metrics, and train DePlot end-to-end on this tas",
    "link": "http://arxiv.org/abs/2212.10505",
    "context": "Title: DePlot: One-shot visual language reasoning by plot-to-table translation. (arXiv:2212.10505v2 [cs.CL] UPDATED)\nAbstract: Visual language such as charts and plots is ubiquitous in the human world. Comprehending plots and charts requires strong reasoning skills. Prior state-of-the-art (SOTA) models require at least tens of thousands of training examples and their reasoning capabilities are still much limited, especially on complex human-written queries. This paper presents the first one-shot solution to visual language reasoning. We decompose the challenge of visual language reasoning into two steps: (1) plot-to-text translation, and (2) reasoning over the translated text. The key in this method is a modality conversion module, named as DePlot, which translates the image of a plot or chart to a linearized table. The output of DePlot can then be directly used to prompt a pretrained large language model (LLM), exploiting the few-shot reasoning capabilities of LLMs. To obtain DePlot, we standardize the plot-to-table task by establishing unified task formats and metrics, and train DePlot end-to-end on this tas",
    "path": "papers/22/12/2212.10505.json",
    "total_tokens": 884,
    "translated_title": "DePlot：利用图表转表格翻译的一次性视觉语言推理",
    "translated_abstract": "视觉语言如图表和图形在人类世界中无处不在，理解图表需要强大的推理能力。本论文提出了一种新的一次性视觉语言推理方法，将视觉语言推理的挑战分解为两个步骤：（1）图形到文本的翻译，（2）对翻译后的文本进行推理。该方法的关键是一个称为DePlot的模态转换模块，它将图表的图像转换为线性表格。DePlot的输出可以直接用于启动预训练的大型语言模型，利用大型语言模型的少量推理能力。为了获得DePlot，我们通过建立统一的任务格式和指标，对图形到表格的任务进行标准化，并在此任务上对DePlot进行端到端训练。",
    "tldr": "本论文提出了一种名为DePlot的方法，它是一个模态转换模块，能够将图表的图像转换为线性化的表格。利用这个模块和预训练的大型语言模型的少量推理能力，我们开发了一种新的一次性视觉语言推理方法。",
    "en_tdlr": "DePlot is proposed, which is a modality conversion module that can translate the image of a plot or chart to a linearized table. With this module and the few-shot reasoning capabilities of a pretrained large language model, a novel one-shot solution to visual language reasoning is developed."
}