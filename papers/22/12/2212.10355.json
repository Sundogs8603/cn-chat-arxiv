{
    "title": "Optimizing Serially Concatenated Neural Codes with Classical Decoders. (arXiv:2212.10355v3 [cs.IT] UPDATED)",
    "abstract": "For improving short-length codes, we demonstrate that classic decoders can also be used with real-valued, neural encoders, i.e., deep-learning based codeword sequence generators. Here, the classical decoder can be a valuable tool to gain insights into these neural codes and shed light on weaknesses. Specifically, the turbo-autoencoder is a recently developed channel coding scheme where both encoder and decoder are replaced by neural networks. We first show that the limited receptive field of convolutional neural network (CNN)-based codes enables the application of the BCJR algorithm to optimally decode them with feasible computational complexity. These maximum a posteriori (MAP) component decoders then are used to form classical (iterative) turbo decoders for parallel or serially concatenated CNN encoders, offering a close-to-maximum likelihood (ML) decoding of the learned codes. To the best of our knowledge, this is the first time that a classical decoding algorithm is applied to a no",
    "link": "http://arxiv.org/abs/2212.10355",
    "context": "Title: Optimizing Serially Concatenated Neural Codes with Classical Decoders. (arXiv:2212.10355v3 [cs.IT] UPDATED)\nAbstract: For improving short-length codes, we demonstrate that classic decoders can also be used with real-valued, neural encoders, i.e., deep-learning based codeword sequence generators. Here, the classical decoder can be a valuable tool to gain insights into these neural codes and shed light on weaknesses. Specifically, the turbo-autoencoder is a recently developed channel coding scheme where both encoder and decoder are replaced by neural networks. We first show that the limited receptive field of convolutional neural network (CNN)-based codes enables the application of the BCJR algorithm to optimally decode them with feasible computational complexity. These maximum a posteriori (MAP) component decoders then are used to form classical (iterative) turbo decoders for parallel or serially concatenated CNN encoders, offering a close-to-maximum likelihood (ML) decoding of the learned codes. To the best of our knowledge, this is the first time that a classical decoding algorithm is applied to a no",
    "path": "papers/22/12/2212.10355.json",
    "total_tokens": 847,
    "translated_title": "优化串联神经编码的经典解码器",
    "translated_abstract": "本文提出了一种在短长度编码中改进的方法，即使用基于深度学习的编码序列生成器——实值神经编码器与经典解码器相结合的方式。具体而言，通过经典解码器，可以更好地了解这些神经编码的优点及缺陷。研究显示，基于卷积神经网络（CNN）的编码的局部感受野使得可以应用BCJR算法对其进行最优解码，并且保证计算复杂度可操作。我们利用这些极大后验（MAP）分解器来构建经典（迭代）Turbo解码器，对串联或并联CNN编码器进行近似的最大似然（ML）解码来优化学习编码。据我们所知，这是首次将经典解码算法应用于神经编码器并优化解码。",
    "tldr": "本文介绍了一种使用经典解码器优化神经编码的方法，并且应用BCJR算法进行了最优解码，形成了迭代Turbo解码器，优化了学习编码并取得了较好的效果。"
}