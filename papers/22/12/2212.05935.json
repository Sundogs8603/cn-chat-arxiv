{
    "title": "Hierarchical multimodal transformers for Multi-Page DocVQA. (arXiv:2212.05935v2 [cs.CV] UPDATED)",
    "abstract": "Document Visual Question Answering (DocVQA) refers to the task of answering questions from document images. Existing work on DocVQA only considers single-page documents. However, in real scenarios documents are mostly composed of multiple pages that should be processed altogether. In this work we extend DocVQA to the multi-page scenario. For that, we first create a new dataset, MP-DocVQA, where questions are posed over multi-page documents instead of single pages. Second, we propose a new hierarchical method, Hi-VT5, based on the T5 architecture, that overcomes the limitations of current methods to process long multi-page documents. The proposed method is based on a hierarchical transformer architecture where the encoder summarizes the most relevant information of every page and then, the decoder takes this summarized information to generate the final answer. Through extensive experimentation, we demonstrate that our method is able, in a single stage, to answer the questions and provid",
    "link": "http://arxiv.org/abs/2212.05935",
    "context": "Title: Hierarchical multimodal transformers for Multi-Page DocVQA. (arXiv:2212.05935v2 [cs.CV] UPDATED)\nAbstract: Document Visual Question Answering (DocVQA) refers to the task of answering questions from document images. Existing work on DocVQA only considers single-page documents. However, in real scenarios documents are mostly composed of multiple pages that should be processed altogether. In this work we extend DocVQA to the multi-page scenario. For that, we first create a new dataset, MP-DocVQA, where questions are posed over multi-page documents instead of single pages. Second, we propose a new hierarchical method, Hi-VT5, based on the T5 architecture, that overcomes the limitations of current methods to process long multi-page documents. The proposed method is based on a hierarchical transformer architecture where the encoder summarizes the most relevant information of every page and then, the decoder takes this summarized information to generate the final answer. Through extensive experimentation, we demonstrate that our method is able, in a single stage, to answer the questions and provid",
    "path": "papers/22/12/2212.05935.json",
    "total_tokens": 836,
    "translated_title": "多级模态变压器用于多页 DocVQA",
    "translated_abstract": "文档视觉问答（DocVQA）是指回答文档图像中的问题的任务。现有的 DocVQA 工作仅考虑单页文档。但是，在实际场景中，文档主要由多个页面组成，应该一起处理。在本文中，我们将 DocVQA 扩展到多页面场景。为此，首先创建一个新的数据集 MP-DocVQA，其中问题是针对多页文档而非单页提出的。其次，我们提出了一种新的分层方法 Hi-VT5，基于 T5 结构，克服了处理长多页文档的当前方法的局限性。所提出的方法基于分层变压器结构，编码器对每个页面的最相关信息进行摘要，然后解码器利用这些摘要信息生成最终答案。通过广泛实验，我们证明了我们的方法能够在单个阶段中回答问题并提供",
    "tldr": "本文提出了一种新方法，Hi-VT5，它是一种分层 transformer 结构，能够处理多页文档 DocVQA 任务。实验表明该方法能够有效地回答问题。"
}