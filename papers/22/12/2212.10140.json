{
    "title": "Tackling Ambiguity with Images: Improved Multimodal Machine Translation and Contrastive Evaluation. (arXiv:2212.10140v2 [cs.CL] UPDATED)",
    "abstract": "One of the major challenges of machine translation (MT) is ambiguity, which can in some cases be resolved by accompanying context such as images. However, recent work in multimodal MT (MMT) has shown that obtaining improvements from images is challenging, limited not only by the difficulty of building effective cross-modal representations, but also by the lack of specific evaluation and training data. We present a new MMT approach based on a strong text-only MT model, which uses neural adapters, a novel guided self-attention mechanism and which is jointly trained on both visually-conditioned masking and MMT. We also introduce CoMMuTE, a Contrastive Multilingual Multimodal Translation Evaluation set of ambiguous sentences and their possible translations, accompanied by disambiguating images corresponding to each translation. Our approach obtains competitive results compared to strong text-only models on standard English-to-French, English-to-German and English-to-Czech benchmarks and ou",
    "link": "http://arxiv.org/abs/2212.10140",
    "context": "Title: Tackling Ambiguity with Images: Improved Multimodal Machine Translation and Contrastive Evaluation. (arXiv:2212.10140v2 [cs.CL] UPDATED)\nAbstract: One of the major challenges of machine translation (MT) is ambiguity, which can in some cases be resolved by accompanying context such as images. However, recent work in multimodal MT (MMT) has shown that obtaining improvements from images is challenging, limited not only by the difficulty of building effective cross-modal representations, but also by the lack of specific evaluation and training data. We present a new MMT approach based on a strong text-only MT model, which uses neural adapters, a novel guided self-attention mechanism and which is jointly trained on both visually-conditioned masking and MMT. We also introduce CoMMuTE, a Contrastive Multilingual Multimodal Translation Evaluation set of ambiguous sentences and their possible translations, accompanied by disambiguating images corresponding to each translation. Our approach obtains competitive results compared to strong text-only models on standard English-to-French, English-to-German and English-to-Czech benchmarks and ou",
    "path": "papers/22/12/2212.10140.json",
    "total_tokens": 965,
    "translated_title": "处理图像歧义：改善多模式机器翻译和对比评估",
    "translated_abstract": "机器翻译中的一个主要挑战是歧义，而图像等上下文信息可以在某些情况下解决此问题。然而，最近的多模式机器翻译研究表明，利用图像提高翻译效果具有挑战性，不仅受到跨模态表达有效性的困难限制，还受到特定评估和训练数据缺乏的限制。本文提出了一种新的基于强文本机器翻译模型的多模式翻译方法，该方法使用神经适配器和新颖的引导自注意力机制，并在视觉条件掩蔽和多模式翻译上进行联合训练。同时，我们还介绍了CoMMuTE，一组包含模糊句子及其可能的翻译方案和对应图像的对比多语言多模式翻译评估数据集。我们的方法在标准的英法、英德和英捷翻译基准测试中获得了与强文本模型相当的结果。",
    "tldr": "本文提出了一种基于强文本机器翻译模型的多模式翻译方法，该方法利用图像解决机器翻译中的歧义问题，同时引入了CoMMuTE数据集以进行对比多语言多模式翻译评估，取得了与强文本模型相当的结果。",
    "en_tdlr": "This paper proposes a multimodal translation approach based on a strong text-only MT model, which uses images to address ambiguity in machine translation and introduces a contrastive evaluation dataset CoMMuTE. Competitive results are achieved on standard benchmarks compared to strong text-only models."
}