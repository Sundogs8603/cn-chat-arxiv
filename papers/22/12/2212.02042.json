{
    "title": "Refiner: Data Refining against Gradient Leakage Attacks in Federated Learning. (arXiv:2212.02042v2 [cs.LG] UPDATED)",
    "abstract": "Recent works have brought attention to the vulnerability of Federated Learning (FL) systems to gradient leakage attacks. Such attacks exploit clients' uploaded gradients to reconstruct their sensitive data, thereby compromising the privacy protection capability of FL. In response, various defense mechanisms have been proposed to mitigate this threat by manipulating the uploaded gradients. Unfortunately, empirical evaluations have demonstrated limited resilience of these defenses against sophisticated attacks, indicating an urgent need for more effective defenses. In this paper, we explore a novel defensive paradigm that departs from conventional gradient perturbation approaches and instead focuses on the construction of robust data. Intuitively, if robust data exhibits low semantic similarity with clients' raw data, the gradients associated with robust data can effectively obfuscate attackers. To this end, we design Refiner that jointly optimizes two metrics for privacy protection and ",
    "link": "http://arxiv.org/abs/2212.02042",
    "context": "Title: Refiner: Data Refining against Gradient Leakage Attacks in Federated Learning. (arXiv:2212.02042v2 [cs.LG] UPDATED)\nAbstract: Recent works have brought attention to the vulnerability of Federated Learning (FL) systems to gradient leakage attacks. Such attacks exploit clients' uploaded gradients to reconstruct their sensitive data, thereby compromising the privacy protection capability of FL. In response, various defense mechanisms have been proposed to mitigate this threat by manipulating the uploaded gradients. Unfortunately, empirical evaluations have demonstrated limited resilience of these defenses against sophisticated attacks, indicating an urgent need for more effective defenses. In this paper, we explore a novel defensive paradigm that departs from conventional gradient perturbation approaches and instead focuses on the construction of robust data. Intuitively, if robust data exhibits low semantic similarity with clients' raw data, the gradients associated with robust data can effectively obfuscate attackers. To this end, we design Refiner that jointly optimizes two metrics for privacy protection and ",
    "path": "papers/22/12/2212.02042.json",
    "total_tokens": 922,
    "translated_title": "Refiner: 针对联邦学习中的梯度泄漏攻击的数据精炼方法",
    "translated_abstract": "最近的研究引起了对联邦学习系统易受梯度泄漏攻击的关注。这类攻击利用客户端上传的梯度来重构其敏感数据，从而破坏了联邦学习的隐私保护能力。为了应对这一威胁，已经提出了各种防御机制来减轻攻击的影响，这些机制通过操纵上传的梯度来防止攻击。然而，实证评估表明这些防御措施在面对复杂攻击时具有有限的弹性，这表明迫切需要更有效的防御方法。本文提出了一种新的防御范式，不同于传统的梯度扰动方法，而是专注于构建健壮数据。直观地说，如果健壮数据与客户端原始数据具有很低的语义相似性，与健壮数据相关的梯度可以有效地混淆攻击者。为此，我们设计了Refiner，它同时优化了两个指标，用于隐私保护和...",
    "tldr": "Refiner提出了一种创新的防御范式，通过构建与原始数据具有低语义相似性的健壮数据，有效地混淆梯度泄漏攻击者，从而提高联邦学习系统的隐私保护能力。",
    "en_tdlr": "Refiner proposes a novel defensive paradigm that focuses on constructing robust data with low semantic similarity to the original data, effectively confusing gradient leakage attackers and enhancing the privacy protection capability of federated learning systems."
}