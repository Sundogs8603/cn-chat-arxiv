{
    "title": "The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources in Natural Language Understanding Systems. (arXiv:2212.08192v2 [cs.CL] UPDATED)",
    "abstract": "Many state-of-the-art natural language understanding (NLU) models are based on pretrained neural language models. These models often make inferences using information from multiple sources. An important class of such inferences are those that require both background knowledge, presumably contained in a model's pretrained parameters, and instance-specific information that is supplied at inference time. However, the integration and reasoning abilities of NLU models in the presence of multiple knowledge sources have been largely understudied. In this work, we propose a test suite of coreference resolution subtasks that require reasoning over multiple facts. These subtasks differ in terms of which knowledge sources contain the relevant facts. We also introduce subtasks where knowledge is present only at inference time using fictional knowledge. We evaluate state-of-the-art coreference resolution models on our dataset. Our results indicate that several models struggle to reason on-the-fly o",
    "link": "http://arxiv.org/abs/2212.08192",
    "context": "Title: The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources in Natural Language Understanding Systems. (arXiv:2212.08192v2 [cs.CL] UPDATED)\nAbstract: Many state-of-the-art natural language understanding (NLU) models are based on pretrained neural language models. These models often make inferences using information from multiple sources. An important class of such inferences are those that require both background knowledge, presumably contained in a model's pretrained parameters, and instance-specific information that is supplied at inference time. However, the integration and reasoning abilities of NLU models in the presence of multiple knowledge sources have been largely understudied. In this work, we propose a test suite of coreference resolution subtasks that require reasoning over multiple facts. These subtasks differ in terms of which knowledge sources contain the relevant facts. We also introduce subtasks where knowledge is present only at inference time using fictional knowledge. We evaluate state-of-the-art coreference resolution models on our dataset. Our results indicate that several models struggle to reason on-the-fly o",
    "path": "papers/22/12/2212.08192.json",
    "total_tokens": 874,
    "translated_title": "KITMUS测试：评估自然语言理解系统中多源知识整合能力",
    "translated_abstract": "许多最先进的自然语言理解模型都基于预训练的神经语言模型。这些模型通常会利用多个来源的信息进行推理，其中一个重要类别的推理需要在推理时间提供预训练参数中包含的背景知识以及特定实例的信息。然而，在多源知识存在的情况下，自然语言理解模型的整合和推理能力还没有得到充分的研究。在这项工作中，我们提出了一个核心指代消解子任务的测试套件，需要针对多个事实进行推理。这些子任务在哪些知识来源包含相关的事实方面存在差异。我们还引入了在推理时间仅使用虚构知识的子任务。我们评估了最先进的核心指代消解模型在我们的数据集上。我们的结果表明，有几个模型难以实时进行推理。",
    "tldr": "本文提出了一个KITMUS测试套件，用于评估自然语言理解模型对多源知识进行整合和推理的能力，在测试中的核心子任务需要进行针对多个事实的推理。实验结果表明，许多模型难以实时进行推理。"
}