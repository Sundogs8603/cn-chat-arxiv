{
    "title": "Visual CPG-RL: Learning Central Pattern Generators for Visually-Guided Quadruped Locomotion",
    "abstract": "arXiv:2212.14400v2 Announce Type: replace-cross  Abstract: We present a framework for learning visually-guided quadruped locomotion by integrating exteroceptive sensing and central pattern generators (CPGs), i.e. systems of coupled oscillators, into the deep reinforcement learning (DRL) framework. Through both exteroceptive and proprioceptive sensing, the agent learns to coordinate rhythmic behavior among different oscillators to track velocity commands, while at the same time override these commands to avoid collisions with the environment. We investigate several open robotics and neuroscience questions: 1) What is the role of explicit interoscillator couplings between oscillators, and can such coupling improve sim-to-real transfer for navigation robustness? 2) What are the effects of using a memory-enabled vs. a memory-free policy network with respect to robustness, energy-efficiency, and tracking performance in sim-to-real navigation tasks? 3) How do animals manage to tolerate high ",
    "link": "https://arxiv.org/abs/2212.14400",
    "context": "Title: Visual CPG-RL: Learning Central Pattern Generators for Visually-Guided Quadruped Locomotion\nAbstract: arXiv:2212.14400v2 Announce Type: replace-cross  Abstract: We present a framework for learning visually-guided quadruped locomotion by integrating exteroceptive sensing and central pattern generators (CPGs), i.e. systems of coupled oscillators, into the deep reinforcement learning (DRL) framework. Through both exteroceptive and proprioceptive sensing, the agent learns to coordinate rhythmic behavior among different oscillators to track velocity commands, while at the same time override these commands to avoid collisions with the environment. We investigate several open robotics and neuroscience questions: 1) What is the role of explicit interoscillator couplings between oscillators, and can such coupling improve sim-to-real transfer for navigation robustness? 2) What are the effects of using a memory-enabled vs. a memory-free policy network with respect to robustness, energy-efficiency, and tracking performance in sim-to-real navigation tasks? 3) How do animals manage to tolerate high ",
    "path": "papers/22/12/2212.14400.json",
    "total_tokens": 999,
    "translated_title": "Visual CPG-RL：学习用于视觉引导的四足动物运动的中枢模式发生器",
    "translated_abstract": "我们提出了一个框架，通过将外感知传感和中枢模式发生器（CPGs，即耦合振荡器系统）整合到深度强化学习（DRL）框架中，学习视觉引导的四足动物运动。通过外感知和本体感知，代理学习协调不同振荡器之间的节律行为，以跟踪速度指令，同时覆盖这些指令以避免与环境碰撞。我们探讨了几个开放的机器人技术和神经科学问题：1）振荡器之间的显式相互耦合的作用是什么，这种耦合是否能提高用于导航鲁棒性的从模拟到真实的转移？2）使用具有记忆功能与无记忆策略网络对于鲁棒性、能效和从模拟到真实导航任务的跟踪性能有什么影响？3）动物是如何容忍高",
    "tldr": "该论文提出了一个框架，通过将外感知传感和中枢模式发生器整合到深度强化学习框架中，学习视觉引导的四足动物运动，探索了耦合振荡器系统对导航鲁棒性的改进、具有记忆功能的策略网络与无记忆策略网络在导航任务中的效果以及动物如何容忍高。",
    "en_tdlr": "This paper presents a framework for learning visually-guided quadruped locomotion by integrating exteroceptive sensing and central pattern generators into the deep reinforcement learning framework, investigating the improvements of interoscillator couplings on navigation robustness, the effects of memory-enabled policy networks versus memory-free policy networks on navigation tasks, and how animals tolerate high."
}