{
    "title": "Algorithmic progress in computer vision. (arXiv:2212.05153v4 [cs.CV] UPDATED)",
    "abstract": "We investigate algorithmic progress in image classification on ImageNet, perhaps the most well-known test bed for computer vision. We estimate a model, informed by work on neural scaling laws, and infer a decomposition of progress into the scaling of compute, data, and algorithms. Using Shapley values to attribute performance improvements, we find that algorithmic improvements have been roughly as important as the scaling of compute for progress computer vision. Our estimates indicate that algorithmic innovations mostly take the form of compute-augmenting algorithmic advances (which enable researchers to get better performance from less compute), not data-augmenting algorithmic advances. We find that compute-augmenting algorithmic advances are made at a pace more than twice as fast as the rate usually associated with Moore's law. In particular, we estimate that compute-augmenting innovations halve compute requirements every nine months (95\\% confidence interval: 4 to 25 months).",
    "link": "http://arxiv.org/abs/2212.05153",
    "context": "Title: Algorithmic progress in computer vision. (arXiv:2212.05153v4 [cs.CV] UPDATED)\nAbstract: We investigate algorithmic progress in image classification on ImageNet, perhaps the most well-known test bed for computer vision. We estimate a model, informed by work on neural scaling laws, and infer a decomposition of progress into the scaling of compute, data, and algorithms. Using Shapley values to attribute performance improvements, we find that algorithmic improvements have been roughly as important as the scaling of compute for progress computer vision. Our estimates indicate that algorithmic innovations mostly take the form of compute-augmenting algorithmic advances (which enable researchers to get better performance from less compute), not data-augmenting algorithmic advances. We find that compute-augmenting algorithmic advances are made at a pace more than twice as fast as the rate usually associated with Moore's law. In particular, we estimate that compute-augmenting innovations halve compute requirements every nine months (95\\% confidence interval: 4 to 25 months).",
    "path": "papers/22/12/2212.05153.json",
    "total_tokens": 875,
    "translated_title": "计算机视觉中的算法进展",
    "translated_abstract": "我们研究了在ImageNet上的图像分类中的算法进展，这是计算机视觉领域最著名的测试平台之一。我们估计了一个模型，并根据神经缩放定律的工作推断了进展的分解，包括计算、数据和算法的缩放。使用Shapley值来归因性能改进，我们发现算法改进在计算机视觉进展中的作用与计算的缩放差不多重要。我们的估计表明，算法创新主要以增强计算的算法进步的形式出现（使研究人员能够在较少计算资源的情况下获得更好的性能），而不是增加数据的算法进步。我们发现，增强计算的算法创新的速度比通常与摩尔定律相关的速度更快两倍以上。特别是，我们估计每九个月计算增强的创新将使计算需求减半（95％的置信区间为4到25个月）。",
    "tldr": "计算机视觉领域的算法进展对进步起到了重要作用，特别是增强计算的算法创新使计算需求减半，速度比摩尔定律相关速度快两倍以上。"
}