{
    "title": "3D-TOGO: Towards Text-Guided Cross-Category 3D Object Generation. (arXiv:2212.01103v2 [cs.CV] UPDATED)",
    "abstract": "Text-guided 3D object generation aims to generate 3D objects described by user-defined captions, which paves a flexible way to visualize what we imagined. Although some works have been devoted to solving this challenging task, these works either utilize some explicit 3D representations (e.g., mesh), which lack texture and require post-processing for rendering photo-realistic views; or require individual time-consuming optimization for every single case. Here, we make the first attempt to achieve generic text-guided cross-category 3D object generation via a new 3D-TOGO model, which integrates a text-to-views generation module and a views-to-3D generation module. The text-to-views generation module is designed to generate different views of the target 3D object given an input caption. prior-guidance, caption-guidance and view contrastive learning are proposed for achieving better view-consistency and caption similarity. Meanwhile, a pixelNeRF model is adopted for the views-to-3D generati",
    "link": "http://arxiv.org/abs/2212.01103",
    "context": "Title: 3D-TOGO: Towards Text-Guided Cross-Category 3D Object Generation. (arXiv:2212.01103v2 [cs.CV] UPDATED)\nAbstract: Text-guided 3D object generation aims to generate 3D objects described by user-defined captions, which paves a flexible way to visualize what we imagined. Although some works have been devoted to solving this challenging task, these works either utilize some explicit 3D representations (e.g., mesh), which lack texture and require post-processing for rendering photo-realistic views; or require individual time-consuming optimization for every single case. Here, we make the first attempt to achieve generic text-guided cross-category 3D object generation via a new 3D-TOGO model, which integrates a text-to-views generation module and a views-to-3D generation module. The text-to-views generation module is designed to generate different views of the target 3D object given an input caption. prior-guidance, caption-guidance and view contrastive learning are proposed for achieving better view-consistency and caption similarity. Meanwhile, a pixelNeRF model is adopted for the views-to-3D generati",
    "path": "papers/22/12/2212.01103.json",
    "total_tokens": 1010,
    "translated_title": "3D-TOGO: 跨类别文本引导的三维物体生成",
    "translated_abstract": "文本引导的三维物体生成旨在生成由用户定义的标题描述的三维物体，为我们设想中的事物提供了一种灵活的可视化方式。尽管一些研究致力于解决这一挑战性任务，但这些研究要么利用一些显式的三维表示（例如网格），缺乏纹理并需要后处理以渲染照片般逼真的视图；要么需要个别耗时的优化来处理每个单独的情况。在这里，我们首次尝试通过新的3D-TOGO模型实现通用的跨类别文本引导的三维物体生成，该模型整合了文本到视图生成模块和视图到三维生成模块。文本到视图生成模块专门用于根据输入标题生成目标三维物体的不同视图。提出了先验引导、标题引导和视图对比学习以实现更好的视图一致性和标题相似性。同时，采用了pixelNeRF模型进行视图到三维生成。",
    "tldr": "本论文提出了一个名为3D-TOGO的模型，旨在实现跨类别的文本引导的三维物体生成。模型包括文本到视图生成模块和视图到三维生成模块，使用先验引导、标题引导和视图对比学习等方法提高视图一致性和标题相似性。采用pixelNeRF模型进行视图到三维生成。",
    "en_tdlr": "This paper proposes a model called 3D-TOGO for cross-category text-guided 3D object generation. The model consists of a text-to-views generation module and a views-to-3D generation module, using prior-guidance, caption-guidance, and view contrastive learning to improve view-consistency and caption similarity. PixelNeRF model is utilized for views-to-3D generation."
}