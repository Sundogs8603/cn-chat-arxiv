{
    "title": "On the Relationship Between Explanation and Prediction: A Causal View. (arXiv:2212.06925v4 [cs.LG] UPDATED)",
    "abstract": "Being able to provide explanations for a model's decision has become a central requirement for the development, deployment, and adoption of machine learning models. However, we are yet to understand what explanation methods can and cannot do. How do upstream factors such as data, model prediction, hyperparameters, and random initialization influence downstream explanations? While previous work raised concerns that explanations (E) may have little relationship with the prediction (Y), there is a lack of conclusive study to quantify this relationship. Our work borrows tools from causal inference to systematically assay this relationship. More specifically, we study the relationship between E and Y by measuring the treatment effect when intervening on their causal ancestors, i.e., on hyperparameters and inputs used to generate saliency-based Es or Ys. Our results suggest that the relationships between E and Y is far from ideal. In fact, the gap between 'ideal' case only increase in higher",
    "link": "http://arxiv.org/abs/2212.06925",
    "context": "Title: On the Relationship Between Explanation and Prediction: A Causal View. (arXiv:2212.06925v4 [cs.LG] UPDATED)\nAbstract: Being able to provide explanations for a model's decision has become a central requirement for the development, deployment, and adoption of machine learning models. However, we are yet to understand what explanation methods can and cannot do. How do upstream factors such as data, model prediction, hyperparameters, and random initialization influence downstream explanations? While previous work raised concerns that explanations (E) may have little relationship with the prediction (Y), there is a lack of conclusive study to quantify this relationship. Our work borrows tools from causal inference to systematically assay this relationship. More specifically, we study the relationship between E and Y by measuring the treatment effect when intervening on their causal ancestors, i.e., on hyperparameters and inputs used to generate saliency-based Es or Ys. Our results suggest that the relationships between E and Y is far from ideal. In fact, the gap between 'ideal' case only increase in higher",
    "path": "papers/22/12/2212.06925.json",
    "total_tokens": 835,
    "translated_title": "论解释与预测的关系：一种因果视角",
    "translated_abstract": "提供模型决策解释的能力成为了机器学习模型开发、部署和应用的核心要求。然而，我们尚未理解解释方法的优缺点。数据、模型预测、超参数和随机初始化等上游因素如何影响下游的解释？虽然先前的研究提出了解释与预测之间关系较小的担忧，但缺乏确定性的研究来量化这种关系。我们的工作借鉴因果推断的方法系统地评估了这种关系。具体而言，我们通过干预解释和预测的因果祖先，在使用以显眼度为基础的解释或预测时对超参数和输入进行测量，来研究解释和预测之间的关系。我们的研究结果表明，解释和预测之间的关系远非理想。事实上，“理想”情况下的差距只会在更高的情况下增加。",
    "tldr": "本篇论文用因果推断的方法系统地评估了解释与预测的关系，结果表明这种关系远不如理想情况。",
    "en_tdlr": "This paper systematically examines the relationship between explanation and prediction using causal inference and finds that the relationship falls short of the ideal case."
}