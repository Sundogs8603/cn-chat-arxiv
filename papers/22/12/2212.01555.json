{
    "title": "Contrastive Domain Adaptation for Time-Series via Temporal Mixup. (arXiv:2212.01555v2 [cs.LG] UPDATED)",
    "abstract": "Unsupervised Domain Adaptation (UDA) has emerged as a powerful solution for the domain shift problem via transferring the knowledge from a labeled source domain to a shifted unlabeled target domain. Despite the prevalence of UDA for visual applications, it remains relatively less explored for time-series applications. In this work, we propose a novel lightweight contrastive domain adaptation framework called CoTMix for time-series data. Unlike existing approaches that either use statistical distances or adversarial techniques, we leverage contrastive learning solely to mitigate the distribution shift across the different domains. Specifically, we propose a novel temporal mixup strategy to generate two intermediate augmented views for the source and target domains. Subsequently, we leverage contrastive learning to maximize the similarity between each domain and its corresponding augmented view. The generated views consider the temporal dynamics of time-series data during the adaptation ",
    "link": "http://arxiv.org/abs/2212.01555",
    "context": "Title: Contrastive Domain Adaptation for Time-Series via Temporal Mixup. (arXiv:2212.01555v2 [cs.LG] UPDATED)\nAbstract: Unsupervised Domain Adaptation (UDA) has emerged as a powerful solution for the domain shift problem via transferring the knowledge from a labeled source domain to a shifted unlabeled target domain. Despite the prevalence of UDA for visual applications, it remains relatively less explored for time-series applications. In this work, we propose a novel lightweight contrastive domain adaptation framework called CoTMix for time-series data. Unlike existing approaches that either use statistical distances or adversarial techniques, we leverage contrastive learning solely to mitigate the distribution shift across the different domains. Specifically, we propose a novel temporal mixup strategy to generate two intermediate augmented views for the source and target domains. Subsequently, we leverage contrastive learning to maximize the similarity between each domain and its corresponding augmented view. The generated views consider the temporal dynamics of time-series data during the adaptation ",
    "path": "papers/22/12/2212.01555.json",
    "total_tokens": 813,
    "translated_title": "基于时间混合的时序对比域自适应",
    "translated_abstract": "无监督域自适应（UDA）已经成为解决域偏移问题的强大解决方案，通过将有标签的源领域的知识转移到有转移的无标签的目标领域。尽管UDA在视觉应用中普遍存在，但在时序应用中相对较少探索。在这项工作中，我们提出了一种新颖且轻量级的对比域自适应框架CoTMix，用于时序数据。与现有方法不同，该方法仅利用对比学习来减轻不同域之间的分布偏移。具体来说，我们提出了一种新颖的时间混合策略，为源领域和目标领域生成两个中间增强视图。随后，我们利用对比学习来最大化每个领域与其相应增强视图之间的相似性。生成的视图在适应过程中考虑了时序数据的时间动态性。",
    "tldr": "本文提出了一种基于时间混合的对比域自适应方法，用于解决时序数据中的领域偏移问题。",
    "en_tdlr": "This paper proposes a contrastive domain adaptation method based on temporal mixup to address domain shift in time-series data."
}