{
    "title": "Rainproof: An Umbrella To Shield Text Generators From Out-Of-Distribution Data. (arXiv:2212.09171v2 [cs.CL] UPDATED)",
    "abstract": "Implementing effective control mechanisms to ensure the proper functioning and security of deployed NLP models, from translation to chatbots, is essential. A key ingredient to ensure safe system behaviour is Out-Of-Distribution (OOD) detection, which aims to detect whether an input sample is statistically far from the training distribution. Although OOD detection is a widely covered topic in classification tasks, most methods rely on hidden features output by the encoder. In this work, we focus on leveraging soft-probabilities in a black-box framework, i.e. we can access the soft-predictions but not the internal states of the model. Our contributions include: (i) RAINPROOF a Relative informAItioN Projection OOD detection framework; and (ii) a more operational evaluation setting for OOD detection. Surprisingly, we find that OOD detection is not necessarily aligned with task-specific measures. The OOD detector may filter out samples well processed by the model and keep samples that are n",
    "link": "http://arxiv.org/abs/2212.09171",
    "context": "Title: Rainproof: An Umbrella To Shield Text Generators From Out-Of-Distribution Data. (arXiv:2212.09171v2 [cs.CL] UPDATED)\nAbstract: Implementing effective control mechanisms to ensure the proper functioning and security of deployed NLP models, from translation to chatbots, is essential. A key ingredient to ensure safe system behaviour is Out-Of-Distribution (OOD) detection, which aims to detect whether an input sample is statistically far from the training distribution. Although OOD detection is a widely covered topic in classification tasks, most methods rely on hidden features output by the encoder. In this work, we focus on leveraging soft-probabilities in a black-box framework, i.e. we can access the soft-predictions but not the internal states of the model. Our contributions include: (i) RAINPROOF a Relative informAItioN Projection OOD detection framework; and (ii) a more operational evaluation setting for OOD detection. Surprisingly, we find that OOD detection is not necessarily aligned with task-specific measures. The OOD detector may filter out samples well processed by the model and keep samples that are n",
    "path": "papers/22/12/2212.09171.json",
    "total_tokens": 914,
    "translated_title": "Rainproof:一种用于保护文本生成器免受来自分布外数据的雨伞",
    "translated_abstract": "在部署的NLP模型中，从翻译到聊天机器人，实施有效的控制机制以确保正确运行和安全性至关重要。确保安全系统行为的关键要素是Out-Of-Distribution（OOD）检测，旨在检测输入样本是否与训练分布统计上过于偏离。尽管OOD检测是分类任务中广泛讨论的话题，但大多数方法依赖于编码器输出的隐藏特征。在这项工作中，我们专注于在黑盒框架中利用软概率，即我们可以访问软预测但不能访问模型的内部状态。我们的贡献包括：（i）RAINPROOF相对信息投影OOD检测框架；和（ii）一种更实际的OOD检测评估设置。令人惊讶的是，我们发现OOD检测不一定与任务特定的度量相一致。OOD检测器可能会过滤掉模型处理得很好的样本，同时保留一些样本，这些样本其实模型处理得不好。",
    "tldr": "该论文提出了一种名为RAINPROOF的相对信息投影OOD检测框架，该框架可以在黑盒模型中利用软概率进行检测。论文还提供了一种更实际的OOD检测评估设置。研究发现，OOD检测不一定与任务特定的度量相一致。"
}