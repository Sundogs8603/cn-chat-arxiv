{
    "title": "Generalized Gradient Flows with Provable Fixed-Time Convergence and Fast Evasion of Non-Degenerate Saddle Points. (arXiv:2212.03765v2 [cs.LG] UPDATED)",
    "abstract": "Gradient-based first-order convex optimization algorithms find widespread applicability in a variety of domains, including machine learning tasks. Motivated by the recent advances in fixed-time stability theory of continuous-time dynamical systems, we introduce a generalized framework for designing accelerated optimization algorithms with strongest convergence guarantees that further extend to a subclass of non-convex functions. In particular, we introduce the GenFlow algorithm and its momentum variant that provably converge to the optimal solution of objective functions satisfying the Polyak-{\\L}ojasiewicz (PL) inequality in a fixed time. Moreover, for functions that admit non-degenerate saddle-points, we show that for the proposed GenFlow algorithm, the time required to evade these saddle-points is uniformly bounded for all initial conditions. Finally, for strongly convex-strongly concave minimax problems whose optimal solution is a saddle point, a similar scheme is shown to arrive a",
    "link": "http://arxiv.org/abs/2212.03765",
    "context": "Title: Generalized Gradient Flows with Provable Fixed-Time Convergence and Fast Evasion of Non-Degenerate Saddle Points. (arXiv:2212.03765v2 [cs.LG] UPDATED)\nAbstract: Gradient-based first-order convex optimization algorithms find widespread applicability in a variety of domains, including machine learning tasks. Motivated by the recent advances in fixed-time stability theory of continuous-time dynamical systems, we introduce a generalized framework for designing accelerated optimization algorithms with strongest convergence guarantees that further extend to a subclass of non-convex functions. In particular, we introduce the GenFlow algorithm and its momentum variant that provably converge to the optimal solution of objective functions satisfying the Polyak-{\\L}ojasiewicz (PL) inequality in a fixed time. Moreover, for functions that admit non-degenerate saddle-points, we show that for the proposed GenFlow algorithm, the time required to evade these saddle-points is uniformly bounded for all initial conditions. Finally, for strongly convex-strongly concave minimax problems whose optimal solution is a saddle point, a similar scheme is shown to arrive a",
    "path": "papers/22/12/2212.03765.json",
    "total_tokens": 880,
    "translated_title": "可证明固定时间收敛和快速逃逸非退化鞍点的广义梯度流",
    "translated_abstract": "基于梯度的一阶凸优化算法在各种领域中得到了广泛的应用，包括机器学习任务。受连续时间动力系统固定时间稳定性理论的最新进展的启发，我们引入了一个广义框架，用于设计具有最强收敛性保证的加速优化算法，这些算法进一步适用于非凸函数的子类。我们特别介绍了GenFlow算法及其动量变体，它们可证明在固定时间内收敛到满足Polyak-Lojasiewicz (PL)不等式的目标函数的最优解。此外，对于具有非退化鞍点的函数，我们证明了对于提出的GenFlow算法，躲避这些鞍点所需的时间在所有初始条件下都有一致的上界。最后，对于最优解为鞍点的强凸-强凹极小极大问题，类似的方案被证明可以达到。",
    "tldr": "该论文介绍了一种广义梯度流算法，它能够在固定时间内收敛到非凸函数的最优解，并且能够快速逃逸非退化鞍点。",
    "en_tdlr": "This paper introduces a generalized gradient flow algorithm that achieves fixed-time convergence to the optimal solution of non-convex functions and provides fast evasion of non-degenerate saddle points."
}