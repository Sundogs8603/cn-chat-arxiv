{
    "title": "Advancing Multilingual Pre-training: TRIP Triangular Document-level Pre-training for Multilingual Language Models. (arXiv:2212.07752v2 [cs.CL] UPDATED)",
    "abstract": "Despite the success of multilingual sequence-to-sequence pre-training, most existing approaches rely on document-level monolingual corpora in many different languages, sentence-level bilingual corpora,\\footnote{In this paper, we use `bilingual corpora' to denote parallel corpora with `bilingual translation pairs' in many different language pairs, each consisting of two sentences/documents with the same meaning written in different languages. We use `trilingual corpora' to denote parallel corpora with `trilingual translation pairs' in many different language combinations, each consisting of three sentences/documents.} and sometimes synthetic document-level bilingual corpora. This hampers the performance with cross-lingual document-level tasks such as document-level translation. Therefore, we propose to mine and leverage document-level trilingual parallel corpora to improve sequence-to-sequence multilingual pre-training. We present \\textbf{Tri}angular Document-level \\textbf{P}re-training",
    "link": "http://arxiv.org/abs/2212.07752",
    "context": "Title: Advancing Multilingual Pre-training: TRIP Triangular Document-level Pre-training for Multilingual Language Models. (arXiv:2212.07752v2 [cs.CL] UPDATED)\nAbstract: Despite the success of multilingual sequence-to-sequence pre-training, most existing approaches rely on document-level monolingual corpora in many different languages, sentence-level bilingual corpora,\\footnote{In this paper, we use `bilingual corpora' to denote parallel corpora with `bilingual translation pairs' in many different language pairs, each consisting of two sentences/documents with the same meaning written in different languages. We use `trilingual corpora' to denote parallel corpora with `trilingual translation pairs' in many different language combinations, each consisting of three sentences/documents.} and sometimes synthetic document-level bilingual corpora. This hampers the performance with cross-lingual document-level tasks such as document-level translation. Therefore, we propose to mine and leverage document-level trilingual parallel corpora to improve sequence-to-sequence multilingual pre-training. We present \\textbf{Tri}angular Document-level \\textbf{P}re-training",
    "path": "papers/22/12/2212.07752.json",
    "total_tokens": 869,
    "translated_title": "推动多语言预训练：TRIP三角形文档级多语言预训练模型",
    "translated_abstract": "尽管多语言序列到序列预训练获得成功，但大多数现有方法依赖于包含多种语言的单语言文档级语料库、句子级双语语料库，有时还利用合成的文档级双语语料库。这阻碍了跨语言文档级任务（如文档级翻译）的性能。因此，我们提出了利用文档级三语言平行语料库改进序列到序列的多语言预训练的TRIP框架。该框架通过新颖的三角形预训练模式利用三语平行语料库。在各种跨语言基准测试中，我们通过广泛的实验证明了我们方法的有效性，在一些任务上取得了最优结果。",
    "tldr": "TRIP模型利用文档级三语言平行语料库改进序列到序列的多语言预训练，获得了在多项任务上的最优结果。",
    "en_tdlr": "The TRIP model improves sequence-to-sequence multilingual pre-training by utilizing trilingual parallel corpora at the document level, achieving state-of-the-art results on several cross-lingual tasks."
}