{
    "title": "SoftCTC -- Semi-Supervised Learning for Text Recognition using Soft Pseudo-Labels. (arXiv:2212.02135v3 [cs.LG] UPDATED)",
    "abstract": "This paper explores semi-supervised training for sequence tasks, such as Optical Character Recognition or Automatic Speech Recognition. We propose a novel loss function $\\unicode{x2013}$ SoftCTC $\\unicode{x2013}$ which is an extension of CTC allowing to consider multiple transcription variants at the same time. This allows to omit the confidence based filtering step which is otherwise a crucial component of pseudo-labeling approaches to semi-supervised learning. We demonstrate the effectiveness of our method on a challenging handwriting recognition task and conclude that SoftCTC matches the performance of a finely-tuned filtering based pipeline. We also evaluated SoftCTC in terms of computational efficiency, concluding that it is significantly more efficient than a na\\\"ive CTC-based approach for training on multiple transcription variants, and we make our GPU implementation public.",
    "link": "http://arxiv.org/abs/2212.02135",
    "context": "Title: SoftCTC -- Semi-Supervised Learning for Text Recognition using Soft Pseudo-Labels. (arXiv:2212.02135v3 [cs.LG] UPDATED)\nAbstract: This paper explores semi-supervised training for sequence tasks, such as Optical Character Recognition or Automatic Speech Recognition. We propose a novel loss function $\\unicode{x2013}$ SoftCTC $\\unicode{x2013}$ which is an extension of CTC allowing to consider multiple transcription variants at the same time. This allows to omit the confidence based filtering step which is otherwise a crucial component of pseudo-labeling approaches to semi-supervised learning. We demonstrate the effectiveness of our method on a challenging handwriting recognition task and conclude that SoftCTC matches the performance of a finely-tuned filtering based pipeline. We also evaluated SoftCTC in terms of computational efficiency, concluding that it is significantly more efficient than a na\\\"ive CTC-based approach for training on multiple transcription variants, and we make our GPU implementation public.",
    "path": "papers/22/12/2212.02135.json",
    "total_tokens": 872,
    "translated_title": "SoftCTC -- 利用软伪标签进行半监督学习的文本识别",
    "translated_abstract": "本文探索了序列任务的半监督训练，如光学字符识别或自动语音识别。我们提出了一种新的损失函数 SoftCTC，它是CTC的扩展，可以同时考虑多个转录变体。这使得可以省略基于置信度的过滤步骤，该步骤对于伪标签方法的半监督学习是一个重要组成部分。我们在具有挑战性的手写识别任务上展示了我们方法的有效性，并得出结论，SoftCTC可以与精调的基于过滤的流水线的性能相匹配。我们还评估了SoftCTC的计算效率，得出结论它在训练多个转录变体方面比朴素的CTC方法更高效，并且我们公开了我们的GPU实现。",
    "tldr": "本文研究了半监督学习在文本识别中的应用，提出了一种新的损失函数 SoftCTC，可以同时考虑多个转录变体，避免了基于置信度的过滤步骤，实验表明其在手写识别任务上与过滤流水线性能相当，并且计算效率更高。",
    "en_tdlr": "This paper explores the application of semi-supervised learning in text recognition and proposes a novel loss function, SoftCTC, which considers multiple transcription variants simultaneously and eliminates the need for confidence-based filtering. The experiments show that SoftCTC performs comparably to a filtering-based pipeline in handwriting recognition tasks while being more computationally efficient."
}