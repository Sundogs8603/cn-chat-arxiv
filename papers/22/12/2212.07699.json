{
    "title": "Retrieval-based Disentangled Representation Learning with Natural Language Supervision",
    "abstract": "Disentangled representation learning remains challenging as the underlying factors of variation in the data do not naturally exist. The inherent complexity of real-world data makes it unfeasible to exhaustively enumerate and encapsulate all its variations within a finite set of factors. However, it is worth noting that most real-world data have linguistic equivalents, typically in the form of textual descriptions. These linguistic counterparts can represent the data and effortlessly decomposed into distinct tokens. In light of this, we present Vocabulary Disentangled Retrieval (VDR), a retrieval-based framework that harnesses natural language as proxies of the underlying data variation to drive disentangled representation learning. Our approach employ a bi-encoder model to represent both data and natural language in a vocabulary space, enabling the model to distinguish dimensions that capture intrinsic characteristics within data through its natural language counterpart, thus facilitat",
    "link": "https://arxiv.org/abs/2212.07699",
    "context": "Title: Retrieval-based Disentangled Representation Learning with Natural Language Supervision\nAbstract: Disentangled representation learning remains challenging as the underlying factors of variation in the data do not naturally exist. The inherent complexity of real-world data makes it unfeasible to exhaustively enumerate and encapsulate all its variations within a finite set of factors. However, it is worth noting that most real-world data have linguistic equivalents, typically in the form of textual descriptions. These linguistic counterparts can represent the data and effortlessly decomposed into distinct tokens. In light of this, we present Vocabulary Disentangled Retrieval (VDR), a retrieval-based framework that harnesses natural language as proxies of the underlying data variation to drive disentangled representation learning. Our approach employ a bi-encoder model to represent both data and natural language in a vocabulary space, enabling the model to distinguish dimensions that capture intrinsic characteristics within data through its natural language counterpart, thus facilitat",
    "path": "papers/22/12/2212.07699.json",
    "total_tokens": 854,
    "translated_title": "基于检索的带自然语言监督的解缠表示学习",
    "translated_abstract": "解缠表示学习仍然具有挑战性，因为数据中的基本变化因素并不存在。真实世界数据的固有复杂性使得在有限的因素集中穷尽地列举和概括所有变化是不可行的。然而，值得注意的是，大多数真实世界数据都有语言等价物，通常以文本描述的形式存在。这些语言对应物可以代表数据，并轻松地分解为不同的标记。基于此，我们提出了单词表解缠检索（VDR），这是一个基于检索的框架，利用自然语言作为潜在数据变化的代理，以推动解缠表示学习。我们的方法使用双编码器模型在词汇空间中表示数据和自然语言，使模型能够通过其自然语言对应物区分捕捉数据内在特征的维度，从而促进解缠表示学习。",
    "tldr": "本研究提出了基于检索的带自然语言监督的解缠表示学习框架，利用自然语言作为数据变化的代理，通过词汇空间中的双编码器模型实现对数据内在特征的解缠表示学习。",
    "en_tdlr": "This paper proposes a retrieval-based disentangled representation learning framework with natural language supervision, which utilizes natural language as proxies of data variations and employs a bi-encoder model in the vocabulary space to achieve disentangled representation learning of intrinsic characteristics within the data."
}