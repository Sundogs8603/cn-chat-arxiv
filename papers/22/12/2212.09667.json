{
    "title": "Foveate, Attribute, and Rationalize: Towards Physically Safe and Trustworthy AI. (arXiv:2212.09667v2 [cs.CL] UPDATED)",
    "abstract": "Users' physical safety is an increasing concern as the market for intelligent systems continues to grow, where unconstrained systems may recommend users dangerous actions that can lead to serious injury. Covertly unsafe text is an area of particular interest, as such text may arise from everyday scenarios and are challenging to detect as harmful. We propose FARM, a novel framework leveraging external knowledge for trustworthy rationale generation in the context of safety. In particular, FARM foveates on missing knowledge to qualify the information required to reason in specific scenarios and retrieves this information with attribution to trustworthy sources. This knowledge is used to both classify the safety of the original text and generate human-interpretable rationales, shedding light on the risk of systems to specific user groups and helping both stakeholders manage the risks of their systems and policymakers to provide concrete safeguards for consumer safety. Our experiments show ",
    "link": "http://arxiv.org/abs/2212.09667",
    "context": "Title: Foveate, Attribute, and Rationalize: Towards Physically Safe and Trustworthy AI. (arXiv:2212.09667v2 [cs.CL] UPDATED)\nAbstract: Users' physical safety is an increasing concern as the market for intelligent systems continues to grow, where unconstrained systems may recommend users dangerous actions that can lead to serious injury. Covertly unsafe text is an area of particular interest, as such text may arise from everyday scenarios and are challenging to detect as harmful. We propose FARM, a novel framework leveraging external knowledge for trustworthy rationale generation in the context of safety. In particular, FARM foveates on missing knowledge to qualify the information required to reason in specific scenarios and retrieves this information with attribution to trustworthy sources. This knowledge is used to both classify the safety of the original text and generate human-interpretable rationales, shedding light on the risk of systems to specific user groups and helping both stakeholders manage the risks of their systems and policymakers to provide concrete safeguards for consumer safety. Our experiments show ",
    "path": "papers/22/12/2212.09667.json",
    "total_tokens": 962,
    "translated_title": "注重视觉、属性和理性：迈向物理安全和可信的人工智能",
    "translated_abstract": "随着智能系统市场的不断增长，用户的身体安全越来越受到关注。不受限制的系统可能会向用户推荐危险的行为，导致严重的伤害。隐蔽的不安全文本是一个特别关注的领域，因为这样的文本可能会出现在日常场景中，并且很难被检测为有害。我们提出了FARM，这是一个新颖的框架，利用外部知识在安全上下文中生成可信的原理。具体而言，FARM注重于缺失的知识，以确认在特定情境中进行推理所需的信息，并通过可信源进行归因以获取此信息。这些知识用于分类原始文本的安全性并生成人类可解释的原理，揭示系统对特定用户群体的风险，并帮助利益相关者管理其系统的风险，帮助政策制定者为消费者安全提供具体的保障。我们的实验表明，FARM在识别不安全文本和生成可信的原理方面优于现有方法。",
    "tldr": "研究提出了一种新颖的FARM框架，通过利用外部知识生成能够被信任的原理，解决了不安全文本检测的问题，并能够帮助利益相关者和政策制定者保障消费者的安全。",
    "en_tdlr": "The paper proposes a novel FARM framework, which leverages external knowledge to generate trustworthy rationales that can detect covertly unsafe text and shed light on the risk of systems to specific user groups, helping stakeholders manage the risks of their systems and policymakers to provide concrete safeguards for consumer safety."
}