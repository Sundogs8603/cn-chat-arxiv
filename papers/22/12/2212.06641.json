{
    "title": "Simplicity Bias Leads to Amplified Performance Disparities. (arXiv:2212.06641v2 [cs.LG] UPDATED)",
    "abstract": "Which parts of a dataset will a given model find difficult? Recent work has shown that SGD-trained models have a bias towards simplicity, leading them to prioritize learning a majority class, or to rely upon harmful spurious correlations. Here, we show that the preference for \"easy\" runs far deeper: A model may prioritize any class or group of the dataset that it finds simple-at the expense of what it finds complex-as measured by performance difference on the test set. When subsets with different levels of complexity align with demographic groups, we term this difficulty disparity, a phenomenon that occurs even with balanced datasets that lack group/label associations. We show how difficulty disparity is a model-dependent quantity, and is further amplified in commonly-used models as selected by typical average performance scores. We quantify an amplification factor across a range of settings in order to compare disparity of different models on a fixed dataset. Finally, we present two r",
    "link": "http://arxiv.org/abs/2212.06641",
    "context": "Title: Simplicity Bias Leads to Amplified Performance Disparities. (arXiv:2212.06641v2 [cs.LG] UPDATED)\nAbstract: Which parts of a dataset will a given model find difficult? Recent work has shown that SGD-trained models have a bias towards simplicity, leading them to prioritize learning a majority class, or to rely upon harmful spurious correlations. Here, we show that the preference for \"easy\" runs far deeper: A model may prioritize any class or group of the dataset that it finds simple-at the expense of what it finds complex-as measured by performance difference on the test set. When subsets with different levels of complexity align with demographic groups, we term this difficulty disparity, a phenomenon that occurs even with balanced datasets that lack group/label associations. We show how difficulty disparity is a model-dependent quantity, and is further amplified in commonly-used models as selected by typical average performance scores. We quantify an amplification factor across a range of settings in order to compare disparity of different models on a fixed dataset. Finally, we present two r",
    "path": "papers/22/12/2212.06641.json",
    "total_tokens": 990,
    "translated_title": "简单性偏见导致表现差异扩大",
    "translated_abstract": "给定的模型将会把数据集中哪些部分视为困难？最近的研究表明，SGD训练的模型具有偏向简单的偏见，导致它们优先学习多数类，或依赖有害的表面相关性。我们在这里展示了偏好\"简单\"的情况远不止于此：一个模型可能会优先考虑任何它发现简单的类别或数据集中的任何组-以牺牲它发现复杂的部分的性能差异测量为代价。当不同复杂度水平的子集与人口统计学群体相一致时，我们将此称为困难差异，即使数据集是平衡的，也缺乏群体/标签关联。我们展示了困难差异是一个依赖于模型的量，并在通常的平均表现得分所选择的常用模型中进一步放大。我们量化了一个扩增因子，以便在固定数据集上比较不同模型的差异。最后，我们提出了两个建议，可以减少困难差异。",
    "tldr": "模型在训练和测试过程中会优先考虑简单部分而非复杂部分，导致性能差异扩大，即使数据集平衡且没有群体/标签关联。困难差异是一个依赖于模型的量，并在常用模型中进一步放大。这个问题可以通过几种方法得到缓解。",
    "en_tdlr": "Models have a bias towards simplicity, leading them to prioritize learning easy parts of the dataset over complex ones, which can result in amplified performance disparities. This phenomenon, known as difficulty disparity, can occur even with balanced datasets that lack group/label associations. Difficulty disparity is a model-dependent quantity, and is further amplified in commonly-used models. The problem can be mitigated through several methods."
}