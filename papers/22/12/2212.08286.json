{
    "title": "ALERT: Adapting Language Models to Reasoning Tasks. (arXiv:2212.08286v2 [cs.CL] UPDATED)",
    "abstract": "Current large language models can perform reasonably well on complex tasks that require step-by-step reasoning with few-shot learning. Are these models applying reasoning skills they have learnt during pre-training and reason outside of their training context, or are they simply memorizing their training corpus at finer granularity and have learnt to better understand their context? To tease apart these possibilities, we introduce ALERT, a benchmark and suite of analyses for assessing language models' reasoning ability comparing pre-trained and finetuned models on complex tasks that require reasoning skills to solve. ALERT provides a test bed to asses any language model on fine-grained reasoning skills, which spans over 20 datasets and covers 10 different reasoning skills. We leverage ALERT to further investigate the role of finetuning. With extensive empirical analysis we find that language models learn more reasoning skills such as textual entailment, abductive reasoning, and analogi",
    "link": "http://arxiv.org/abs/2212.08286",
    "context": "Title: ALERT: Adapting Language Models to Reasoning Tasks. (arXiv:2212.08286v2 [cs.CL] UPDATED)\nAbstract: Current large language models can perform reasonably well on complex tasks that require step-by-step reasoning with few-shot learning. Are these models applying reasoning skills they have learnt during pre-training and reason outside of their training context, or are they simply memorizing their training corpus at finer granularity and have learnt to better understand their context? To tease apart these possibilities, we introduce ALERT, a benchmark and suite of analyses for assessing language models' reasoning ability comparing pre-trained and finetuned models on complex tasks that require reasoning skills to solve. ALERT provides a test bed to asses any language model on fine-grained reasoning skills, which spans over 20 datasets and covers 10 different reasoning skills. We leverage ALERT to further investigate the role of finetuning. With extensive empirical analysis we find that language models learn more reasoning skills such as textual entailment, abductive reasoning, and analogi",
    "path": "papers/22/12/2212.08286.json",
    "total_tokens": 948,
    "translated_title": "ALERT：将语言模型适应推理任务",
    "translated_abstract": "当前的大型语言模型在需要逐步推理和少样本学习的复杂任务上表现得相当不错。这些模型是应用了他们在预训练中学到的推理技巧并在他们的训练上下文之外进行推理，还是仅仅在更细粒度上记住了他们的训练语料库并学会了更好地理解上下文？为了分解这些可能性，我们引入了ALERT，一个用于评估语言模型推理能力的基准和一套分析工具，比较了预训练模型和微调模型在需要推理技能解决的复杂任务上的表现。ALERT提供了一个测试平台，可以评估任何语言模型在细粒度推理技能上的表现，它涵盖了20个数据集和10种不同的推理技能。我们利用ALERT进一步对微调的作用进行研究。通过广泛的经验分析，我们发现语言模型学会了更多的推理技能，例如文本蕴涵、演绎推理和类比推理。",
    "tldr": "该论文介绍了ALERT，它是一个用于评估语言模型在推理任务上能力的基准和分析工具。通过对预训练模型和微调模型在复杂任务上的比较，研究发现语言模型学会了更多推理技能，并提供了一个测试平台来评估模型在细粒度推理技能上的表现。"
}