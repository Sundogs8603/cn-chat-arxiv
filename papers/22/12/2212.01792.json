{
    "title": "Classification by sparse additive models. (arXiv:2212.01792v2 [math.ST] UPDATED)",
    "abstract": "We consider (nonparametric) sparse additive models (SpAM) for classification. The design of a SpAM classifier is based on minimizing the logistic loss with a sparse group Lasso and more general sparse group Slope-type penalties on the coefficients of univariate components' expansions in orthonormal series (e.g., Fourier or wavelets). The resulting classifiers are inherently adaptive to the unknown sparsity and smoothness. We show that under certain sparse group restricted eigenvalue condition the sparse group Lasso classifier is nearly-minimax (up to log-factors) within the entire range of analytic, Sobolev and Besov classes while the sparse group Slope classifier achieves the exact minimax order (without the extra log-factors) for sparse and moderately dense setups. The performance of the proposed classifier is illustrated on the real-data example.",
    "link": "http://arxiv.org/abs/2212.01792",
    "context": "Title: Classification by sparse additive models. (arXiv:2212.01792v2 [math.ST] UPDATED)\nAbstract: We consider (nonparametric) sparse additive models (SpAM) for classification. The design of a SpAM classifier is based on minimizing the logistic loss with a sparse group Lasso and more general sparse group Slope-type penalties on the coefficients of univariate components' expansions in orthonormal series (e.g., Fourier or wavelets). The resulting classifiers are inherently adaptive to the unknown sparsity and smoothness. We show that under certain sparse group restricted eigenvalue condition the sparse group Lasso classifier is nearly-minimax (up to log-factors) within the entire range of analytic, Sobolev and Besov classes while the sparse group Slope classifier achieves the exact minimax order (without the extra log-factors) for sparse and moderately dense setups. The performance of the proposed classifier is illustrated on the real-data example.",
    "path": "papers/22/12/2212.01792.json",
    "total_tokens": 842,
    "translated_title": "稀疏加性模型的分类",
    "translated_abstract": "我们考虑了用于分类的非参数稀疏加性模型（SpAM）。SpAM分类器的设计基于最小化logistic损失，通过对分量展开系数施加稀疏组Lasso和更一般的稀疏组Slope型惩罚（例如，傅里叶或小波）。所得的分类器对未知的稀疏性和平滑性具有固有的自适应性。我们证明，在某些稀疏组受限特征值条件下，稀疏组Lasso分类器在整个解析、Sobolev和Besov类范围内几乎是最小化极小（加上对数因子），而稀疏组Slope分类器在稀疏和适度稠密设定下达到了确切的最小化极小阶数（不含额外的对数因子）。该分类器的性能在实际数据例子中得到了证明。",
    "tldr": "这篇论文研究了非参数的稀疏加性模型用于分类，通过对分量系数施加稀疏组Lasso和稀疏组Slope型惩罚来设计分类器，实验证明了分类器在未知稀疏性和平滑性上的自适应性能。",
    "en_tdlr": "This paper investigates nonparametric sparse additive models for classification, using sparse group Lasso and sparse group Slope penalties on component coefficients. The proposed classifier demonstrates adaptive performance on unknown sparsity and smoothness."
}