{
    "title": "Stochastic First-Order Learning for Large-Scale Flexibly Tied Gaussian Mixture Model. (arXiv:2212.05402v2 [cs.LG] UPDATED)",
    "abstract": "Gaussian Mixture Models (GMM) are one of the most potent parametric density estimators based on the kernel model that finds application in many scientific domains. In recent years, with the dramatic enlargement of data sources, typical machine learning algorithms, e.g. Expectation Maximization (EM), encounters difficulty with high-dimensional and streaming data. Moreover, complicated densities often demand a large number of Gaussian components. This paper proposes a fast online parameter estimation algorithm for GMM by using first-order stochastic optimization. This approach provides a framework to cope with the challenges of GMM when faced with high-dimensional streaming data and complex densities by leveraging the flexibly-tied factorization of the covariance matrix. A new stochastic Manifold optimization algorithm that preserves the orthogonality is introduced and used along with the well-known Euclidean space numerical optimization. Numerous empirical results on both synthetic and ",
    "link": "http://arxiv.org/abs/2212.05402",
    "context": "Title: Stochastic First-Order Learning for Large-Scale Flexibly Tied Gaussian Mixture Model. (arXiv:2212.05402v2 [cs.LG] UPDATED)\nAbstract: Gaussian Mixture Models (GMM) are one of the most potent parametric density estimators based on the kernel model that finds application in many scientific domains. In recent years, with the dramatic enlargement of data sources, typical machine learning algorithms, e.g. Expectation Maximization (EM), encounters difficulty with high-dimensional and streaming data. Moreover, complicated densities often demand a large number of Gaussian components. This paper proposes a fast online parameter estimation algorithm for GMM by using first-order stochastic optimization. This approach provides a framework to cope with the challenges of GMM when faced with high-dimensional streaming data and complex densities by leveraging the flexibly-tied factorization of the covariance matrix. A new stochastic Manifold optimization algorithm that preserves the orthogonality is introduced and used along with the well-known Euclidean space numerical optimization. Numerous empirical results on both synthetic and ",
    "path": "papers/22/12/2212.05402.json",
    "total_tokens": 925,
    "translated_title": "面向大规模灵活绑定高斯混合模型的随机一阶学习",
    "translated_abstract": "高斯混合模型(GMM)是一种基于核模型的最有效的参数密度估计器，广泛应用于许多科学领域。随着数据源的剧增，传统的机器学习算法，如期望最大化(EM)，在面对高维和流数据时遇到困难。此外，复杂的密度往往需要大量的高斯组件。本文提出了一种快速的在线参数估计算法，通过使用一阶随机优化来处理GMM所面临的高维流数据和复杂密度的挑战，利用协方差矩阵的灵活绑定因子分解提供了一个框架。引入了一种新的随机流形优化算法，保持正交性，并与众所周知的欧几里得空间数值优化一起使用。在合成和实验数据上进行了大量实证结果。",
    "tldr": "本文提出了一种面对高维流数据和复杂密度挑战的快速在线参数估计算法，并利用灵活绑定因子分解的协方差矩阵提供了一个框架。通过引入一阶随机优化和新的随机流形优化算法，实现了高斯混合模型的优化。",
    "en_tdlr": "This paper proposes a fast online parameter estimation algorithm for GMM by using first-order stochastic optimization and provides a framework for the challenges of high-dimensional streaming data and complex densities using the flexibly-tied factorization of the covariance matrix. The paper also introduces a new stochastic Manifold optimization algorithm that preserves the orthogonality, achieving GMM optimization."
}