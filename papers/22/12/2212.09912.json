{
    "title": "Tokenization Consistency Matters for Generative Models on Extractive NLP Tasks. (arXiv:2212.09912v2 [cs.CL] UPDATED)",
    "abstract": "Generative models have been widely applied to solve extractive tasks, where parts of the input is extracted to form the desired output, and achieved significant success. For example, in extractive question answering (QA), generative models have constantly yielded state-of-the-art results. In this work, we identify the issue of tokenization inconsistency that is commonly neglected in training these models. This issue damages the extractive nature of these tasks after the input and output are tokenized inconsistently by the tokenizer, and thus leads to performance drop as well as hallucination. We propose a simple yet effective fix to this issue and conduct a case study on extractive QA. We show that, with consistent tokenization, the model performs better in both in-domain and out-of-domain datasets, with a notable average of +1.7 F2 gain when a BART model is trained on SQuAD and evaluated on 8 QA datasets. Further, the model converges faster, and becomes less likely to generate out-of-",
    "link": "http://arxiv.org/abs/2212.09912",
    "context": "Title: Tokenization Consistency Matters for Generative Models on Extractive NLP Tasks. (arXiv:2212.09912v2 [cs.CL] UPDATED)\nAbstract: Generative models have been widely applied to solve extractive tasks, where parts of the input is extracted to form the desired output, and achieved significant success. For example, in extractive question answering (QA), generative models have constantly yielded state-of-the-art results. In this work, we identify the issue of tokenization inconsistency that is commonly neglected in training these models. This issue damages the extractive nature of these tasks after the input and output are tokenized inconsistently by the tokenizer, and thus leads to performance drop as well as hallucination. We propose a simple yet effective fix to this issue and conduct a case study on extractive QA. We show that, with consistent tokenization, the model performs better in both in-domain and out-of-domain datasets, with a notable average of +1.7 F2 gain when a BART model is trained on SQuAD and evaluated on 8 QA datasets. Further, the model converges faster, and becomes less likely to generate out-of-",
    "path": "papers/22/12/2212.09912.json",
    "total_tokens": 997,
    "translated_title": "生成式模型在抽取型自然语言处理任务中的标记一致性问题对结果影响的重要性",
    "translated_abstract": "生成式模型在解决抽取型任务时取得了显著的成功，例如在抽取式问答（QA）中，生成式模型一直保持着最先进的结果。本研究发现，在训练这些模型时经常被忽视的标记化不一致性问题。这个问题在标记器对输入和输出进行不一致的标记化后会破坏这些任务的抽取性质，从而导致性能下降和虚构。我们提出了一个简单而有效的解决方案，并在抽取式问答方面进行了案例研究。我们发现，通过一致的标记化，模型在领域内和领域外的数据集上表现更好，在将 BART 模型训练于 SQuAD 并在 8 个 QA 数据集上评估时，平均 F2 增益显著，为 +1.7。同时，模型收敛速度更快，并且更不容易生成不相关的输出。",
    "tldr": "本论文发现了在训练生成式模型时常被忽视的标记一致性问题的重要性，并提出了一个简单且有效的解决方案。通过一致的标记化，模型在抽取型问答任务上表现更好，在领域内和领域外的数据集上平均 F2 增益为 +1.7，同时具有更快的收敛速度和更少的不相关输出生成。",
    "en_tdlr": "This paper highlights the importance of tokenization consistency in training generative models for extractive NLP tasks and proposes a simple yet effective fix. Consistent tokenization improves performance in extractive question answering, with an average F2 gain of +1.7 on both in-domain and out-of-domain datasets, faster convergence, and reduced generation of irrelevant outputs."
}