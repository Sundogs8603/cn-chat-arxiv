{
    "title": "Designing Ecosystems of Intelligence from First Principles. (arXiv:2212.01354v2 [cs.AI] UPDATED)",
    "abstract": "This white paper lays out a vision of research and development in the field of artificial intelligence for the next decade (and beyond). Its denouement is a cyber-physical ecosystem of natural and synthetic sense-making, in which humans are integral participants -- what we call ''shared intelligence''. This vision is premised on active inference, a formulation of adaptive behavior that can be read as a physics of intelligence, and which inherits from the physics of self-organization. In this context, we understand intelligence as the capacity to accumulate evidence for a generative model of one's sensed world -also known as self-evidencing. Formally, this corresponds to maximizing (Bayesian) model evidence, via belief updating over several scales: i.e., inference, learning, and model selection. Operationally, this self-evidencing can be realized via (variational) message passing or belief propagation on a factor graph. Crucially, active inference foregrounds an existential imperative",
    "link": "http://arxiv.org/abs/2212.01354",
    "context": "Title: Designing Ecosystems of Intelligence from First Principles. (arXiv:2212.01354v2 [cs.AI] UPDATED)\nAbstract: This white paper lays out a vision of research and development in the field of artificial intelligence for the next decade (and beyond). Its denouement is a cyber-physical ecosystem of natural and synthetic sense-making, in which humans are integral participants -- what we call ''shared intelligence''. This vision is premised on active inference, a formulation of adaptive behavior that can be read as a physics of intelligence, and which inherits from the physics of self-organization. In this context, we understand intelligence as the capacity to accumulate evidence for a generative model of one's sensed world -also known as self-evidencing. Formally, this corresponds to maximizing (Bayesian) model evidence, via belief updating over several scales: i.e., inference, learning, and model selection. Operationally, this self-evidencing can be realized via (variational) message passing or belief propagation on a factor graph. Crucially, active inference foregrounds an existential imperative",
    "path": "papers/22/12/2212.01354.json",
    "total_tokens": 965,
    "translated_title": "从第一原理设计智能生态系统",
    "translated_abstract": "本白皮书提出了人工智能领域未来十年（甚至更久）的研究和开发愿景。其中，核心是构建一个自然与合成感知的协同智能生态系统，将人类作为不可或缺的参与者 - 我们称之为“共享智能”。该愿景基于主动推理，一种自适应行为的形式，可以被视为智能的物理学，并继承了自组织物理学的特征。在这个背景下，我们将智能理解为累积关于自己感知世界的生成模型的证据的能力 - 也被称为自证明。在形式上，这对应于通过在多个尺度上进行信念更新来最大化（贝叶斯）模型证据，包括推理、学习和模型选择。在操作上，这种自证明可以通过对因子图进行（变分）消息传递或信念传播来实现。主动推理的关键是突出了存在的紧迫性。",
    "tldr": "本文提出了一个关于未来人工智能领域研究和发展的愿景，该愿景是基于主动推理和自证明的智能生态系统，其中人类作为共享智能的不可或缺的参与者。该愿景旨在最大化模型证据，通过不同尺度上的信念更新来累积关于自身感知世界的证据。",
    "en_tdlr": "This paper presents a vision for the future research and development in the field of artificial intelligence, based on active inference and self-evidencing. The vision aims to maximize model evidence by accumulating evidence about one's sensed world through belief updating at multiple scales, and involves the creation of a cyber-physical ecosystem where humans are integral participants in shared intelligence."
}