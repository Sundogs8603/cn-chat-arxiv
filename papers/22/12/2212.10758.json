{
    "title": "ORCA: A Challenging Benchmark for Arabic Language Understanding. (arXiv:2212.10758v2 [cs.CL] UPDATED)",
    "abstract": "Due to their crucial role in all NLP, several benchmarks have been proposed to evaluate pretrained language models. In spite of these efforts, no public benchmark of diverse nature currently exists for evaluation of Arabic. This makes it challenging to measure progress for both Arabic and multilingual language models. This challenge is compounded by the fact that any benchmark targeting Arabic needs to take into account the fact that Arabic is not a single language but rather a collection of languages and varieties. In this work, we introduce ORCA, a publicly available benchmark for Arabic language understanding evaluation. ORCA is carefully constructed to cover diverse Arabic varieties and a wide range of challenging Arabic understanding tasks exploiting 60 different datasets across seven NLU task clusters. To measure current progress in Arabic NLU, we use ORCA to offer a comprehensive comparison between 18 multilingual and Arabic language models. We also provide a public leaderboard ",
    "link": "http://arxiv.org/abs/2212.10758",
    "context": "Title: ORCA: A Challenging Benchmark for Arabic Language Understanding. (arXiv:2212.10758v2 [cs.CL] UPDATED)\nAbstract: Due to their crucial role in all NLP, several benchmarks have been proposed to evaluate pretrained language models. In spite of these efforts, no public benchmark of diverse nature currently exists for evaluation of Arabic. This makes it challenging to measure progress for both Arabic and multilingual language models. This challenge is compounded by the fact that any benchmark targeting Arabic needs to take into account the fact that Arabic is not a single language but rather a collection of languages and varieties. In this work, we introduce ORCA, a publicly available benchmark for Arabic language understanding evaluation. ORCA is carefully constructed to cover diverse Arabic varieties and a wide range of challenging Arabic understanding tasks exploiting 60 different datasets across seven NLU task clusters. To measure current progress in Arabic NLU, we use ORCA to offer a comprehensive comparison between 18 multilingual and Arabic language models. We also provide a public leaderboard ",
    "path": "papers/22/12/2212.10758.json",
    "total_tokens": 942,
    "translated_title": "ORCA: 一项挑战性的阿拉伯语言理解基准评估",
    "translated_abstract": "由于其在所有 NLP 中的关键作用，已提出了多个基准来评估预训练语言模型。尽管有这些努力，目前尚不存在专门用于评估阿拉伯语的多样化公共基准。这使得同时评估阿拉伯语和多语言语言模型的进展变得具有挑战性。这个挑战还因阿拉伯语不是单一语言而是一系列语言和方言而变得更加困难。在这项工作中，我们介绍了 ORCA，一项公开可用的阿拉伯语言理解评估基准。ORCA 被精心构建，以覆盖多种阿拉伯语言和一系列有挑战性的阿拉伯语言理解任务，利用七个 NLU 任务集群中的 60 种不同数据集。为了衡量当前阿拉伯语 NLU 的进展，我们使用 ORCA 在 18 个多语言和阿拉伯语言模型之间进行了全面对比。我们还提供了一个公共排行榜。",
    "tldr": "ORCA 是一个公开可用的阿拉伯语言理解评估基准，利用各种阿拉伯语言和一系列有挑战性的阿拉伯语言理解任务构建。当前使用 ORCA 对 18 个多语言和阿拉伯语言模型进行比较。",
    "en_tdlr": "ORCA is a public benchmark for Arabic language understanding evaluation, covering diverse Arabic varieties and a wide range of challenging Arabic understanding tasks, utilizing 60 different datasets across seven NLU task clusters. ORCA is used to offer a comprehensive comparison between 18 multilingual and Arabic language models. A public leaderboard is also provided."
}