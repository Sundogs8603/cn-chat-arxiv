{
    "title": "Blessings and Curses of Covariate Shifts: Adversarial Learning Dynamics, Directional Convergence, and Equilibria. (arXiv:2212.02457v2 [stat.ML] UPDATED)",
    "abstract": "Covariate distribution shifts and adversarial perturbations present robustness challenges to the conventional statistical learning framework: mild shifts in the test covariate distribution can significantly affect the performance of the statistical model learned based on the training distribution. The model performance typically deteriorates when extrapolation happens: namely, covariates shift to a region where the training distribution is scarce, and naturally, the learned model has little information. For robustness and regularization considerations, adversarial perturbation techniques are proposed as a remedy; however, careful study needs to be carried out about what extrapolation region adversarial covariate shift will focus on, given a learned model. This paper precisely characterizes the extrapolation region, examining both regression and classification in an infinite-dimensional setting. We study the implications of adversarial covariate shifts to subsequent learning of the equi",
    "link": "http://arxiv.org/abs/2212.02457",
    "context": "Title: Blessings and Curses of Covariate Shifts: Adversarial Learning Dynamics, Directional Convergence, and Equilibria. (arXiv:2212.02457v2 [stat.ML] UPDATED)\nAbstract: Covariate distribution shifts and adversarial perturbations present robustness challenges to the conventional statistical learning framework: mild shifts in the test covariate distribution can significantly affect the performance of the statistical model learned based on the training distribution. The model performance typically deteriorates when extrapolation happens: namely, covariates shift to a region where the training distribution is scarce, and naturally, the learned model has little information. For robustness and regularization considerations, adversarial perturbation techniques are proposed as a remedy; however, careful study needs to be carried out about what extrapolation region adversarial covariate shift will focus on, given a learned model. This paper precisely characterizes the extrapolation region, examining both regression and classification in an infinite-dimensional setting. We study the implications of adversarial covariate shifts to subsequent learning of the equi",
    "path": "papers/22/12/2212.02457.json",
    "total_tokens": 913,
    "translated_title": "协变量转移的祝福和诅咒：对抗学习动态、方向收敛和平衡的影响",
    "translated_abstract": "协变量分布转移和对抗扰动对传统统计学习框架的稳健性提出了挑战：测试协变量分布中的轻微转移能显著影响基于训练分布学习的统计模型性能。当外推发生时，即协变量转移到训练分布稀缺的区域时，模型性能通常会降低，因此，学习模型信息很少。为了稳健性和正则化考虑，建议采用对抗扰动技术，然而，需要对给定学习模型时对抗协变量转移的外推区域进行仔细研究。本文在无限维度的设置中精确刻画了外推区域，在回归和分类方面进行了研究。研究了对抗协变量转移对随后的平衡学习的影响。",
    "tldr": "协变量转移和对抗扰动对统计学习的稳健性提出了挑战。本文在无限维度的情况下研究了对抗协变量转移对外推区域的影响以及其对后续学习的平衡的影响。",
    "en_tdlr": "Covariate distribution shifts and adversarial perturbations challenge the robustness of statistical learning, but adversarial perturbation techniques can improve it. This paper precisely characterizes the extrapolation region and studies the implications of adversarial covariate shifts to subsequent learning of the equilibrium, in an infinite-dimensional setting."
}