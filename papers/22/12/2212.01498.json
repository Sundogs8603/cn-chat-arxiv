{
    "title": "Policy Learning for Active Target Tracking over Continuous SE(3) Trajectories. (arXiv:2212.01498v2 [cs.RO] UPDATED)",
    "abstract": "This paper proposes a novel model-based policy gradient algorithm for tracking dynamic targets using a mobile robot, equipped with an onboard sensor with limited field of view. The task is to obtain a continuous control policy for the mobile robot to collect sensor measurements that reduce uncertainty in the target states, measured by the target distribution entropy. We design a neural network control policy with the robot $SE(3)$ pose and the mean vector and information matrix of the joint target distribution as inputs and attention layers to handle variable numbers of targets. We also derive the gradient of the target entropy with respect to the network parameters explicitly, allowing efficient model-based policy gradient optimization.",
    "link": "http://arxiv.org/abs/2212.01498",
    "context": "Title: Policy Learning for Active Target Tracking over Continuous SE(3) Trajectories. (arXiv:2212.01498v2 [cs.RO] UPDATED)\nAbstract: This paper proposes a novel model-based policy gradient algorithm for tracking dynamic targets using a mobile robot, equipped with an onboard sensor with limited field of view. The task is to obtain a continuous control policy for the mobile robot to collect sensor measurements that reduce uncertainty in the target states, measured by the target distribution entropy. We design a neural network control policy with the robot $SE(3)$ pose and the mean vector and information matrix of the joint target distribution as inputs and attention layers to handle variable numbers of targets. We also derive the gradient of the target entropy with respect to the network parameters explicitly, allowing efficient model-based policy gradient optimization.",
    "path": "papers/22/12/2212.01498.json",
    "total_tokens": 814,
    "translated_title": "在连续的 SE(3) 轨迹上学习用于动态目标跟踪的策略学习算法",
    "translated_abstract": "本文提出了一种基于模型的策略梯度算法，用于利用搭载有限视野传感器的移动机器人跟踪动态目标。任务是获取连续的控制策略，以收集传感器测量结果，从而减少目标状态的不确定性，其由目标分布熵度量。我们设计了一个神经网络控制策略，以机器人的 SE(3) 姿态、联合目标分布的均值向量和信息矩阵作为输入，并使用注意力层来处理可变数量的目标。我们还明确导出了目标熵对网络参数的梯度，从而允许高效的基于模型的策略梯度优化。",
    "tldr": "本论文提出了一种基于模型的策略梯度算法，用于利用移动机器人跟踪动态目标，通过设计神经网络控制策略和注意力层，从而实现目标熵对网络参数的梯度运算，以实现高效的基于模型的策略梯度优化。",
    "en_tdlr": "This paper proposes a novel model-based policy gradient algorithm for tracking dynamic targets using a mobile robot, by designing a neural network control policy and attention layers to handle variable numbers of targets, and deriving the gradient of the target entropy with respect to the network parameters for efficient model-based policy gradient optimization."
}