{
    "title": "Improving Faithfulness of Abstractive Summarization by Controlling Confounding Effect of Irrelevant Sentences. (arXiv:2212.09726v2 [cs.CL] UPDATED)",
    "abstract": "Lack of factual correctness is an issue that still plagues state-of-the-art summarization systems despite their impressive progress on generating seemingly fluent summaries. In this paper, we show that factual inconsistency can be caused by irrelevant parts of the input text, which act as confounders. To that end, we leverage information-theoretic measures of causal effects to quantify the amount of confounding and precisely quantify how they affect the summarization performance. Based on insights derived from our theoretical results, we design a simple multi-task model to control such confounding by leveraging human-annotated relevant sentences when available. Crucially, we give a principled characterization of data distributions where such confounding can be large thereby necessitating the use of human annotated relevant sentences to generate factual summaries. Our approach improves faithfulness scores by 20\\% over strong baselines on AnswerSumm \\citep{fabbri2021answersumm}, a conver",
    "link": "http://arxiv.org/abs/2212.09726",
    "context": "Title: Improving Faithfulness of Abstractive Summarization by Controlling Confounding Effect of Irrelevant Sentences. (arXiv:2212.09726v2 [cs.CL] UPDATED)\nAbstract: Lack of factual correctness is an issue that still plagues state-of-the-art summarization systems despite their impressive progress on generating seemingly fluent summaries. In this paper, we show that factual inconsistency can be caused by irrelevant parts of the input text, which act as confounders. To that end, we leverage information-theoretic measures of causal effects to quantify the amount of confounding and precisely quantify how they affect the summarization performance. Based on insights derived from our theoretical results, we design a simple multi-task model to control such confounding by leveraging human-annotated relevant sentences when available. Crucially, we give a principled characterization of data distributions where such confounding can be large thereby necessitating the use of human annotated relevant sentences to generate factual summaries. Our approach improves faithfulness scores by 20\\% over strong baselines on AnswerSumm \\citep{fabbri2021answersumm}, a conver",
    "path": "papers/22/12/2212.09726.json",
    "total_tokens": 891,
    "translated_title": "通过控制无关句子的混淆效应，提高抽象摘要的准确性",
    "translated_abstract": "尽管最先进的摘要系统在生成看似流利的摘要方面取得了令人印象深刻的进展，但缺乏事实正确性仍然是一个问题。本文表明，无关的输入文本部分可能导致事实不一致，作为混淆因素。为此，我们利用因果效应的信息理论度量来量化混淆的程度，并准确衡量其对摘要性能的影响。基于从理论结果中得出的见解，当有人工注释的相关句子可用时，我们设计了一个简单的多任务模型来控制这种混淆。关键是，我们对数据分布进行了原则性的刻画，从而确保了使用人工注释的相关句子来生成准确的摘要。我们的方法在AnswerSumm上（参考文献：fabbri2021answersumm）上强基准的基础上将准确性得分提高了20\\%。",
    "tldr": "通过控制无关句子的混淆效应，本文提出了一种改进抽象摘要准确性的方法，并在AnswerSumm数据集上实现了20\\%的准确性提升。",
    "en_tdlr": "This paper proposes a method to improve the accuracy of abstractive summarization by controlling the confounding effect of irrelevant sentences. By leveraging information-theoretic measures of causal effects and human-annotated relevant sentences, the proposed approach achieves a 20% improvement in accuracy on the AnswerSumm dataset."
}