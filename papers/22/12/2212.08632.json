{
    "title": "Enhancing Multi-modal and Multi-hop Question Answering via Structured Knowledge and Unified Retrieval-Generation. (arXiv:2212.08632v2 [cs.CL] UPDATED)",
    "abstract": "Multi-modal multi-hop question answering involves answering a question by reasoning over multiple input sources from different modalities. Existing methods often retrieve evidences separately and then use a language model to generate an answer based on the retrieved evidences, and thus do not adequately connect candidates and are unable to model the interdependent relations during retrieval. Moreover, the pipelined approaches of retrieval and generation might result in poor generation performance when retrieval performance is low. To address these issues, we propose a Structured Knowledge and Unified Retrieval-Generation (SKURG) approach. SKURG employs an Entity-centered Fusion Encoder to align sources from different modalities using shared entities. It then uses a unified Retrieval-Generation Decoder to integrate intermediate retrieval results for answer generation and also adaptively determine the number of retrieval steps. Extensive experiments on two representative multi-modal mult",
    "link": "http://arxiv.org/abs/2212.08632",
    "context": "Title: Enhancing Multi-modal and Multi-hop Question Answering via Structured Knowledge and Unified Retrieval-Generation. (arXiv:2212.08632v2 [cs.CL] UPDATED)\nAbstract: Multi-modal multi-hop question answering involves answering a question by reasoning over multiple input sources from different modalities. Existing methods often retrieve evidences separately and then use a language model to generate an answer based on the retrieved evidences, and thus do not adequately connect candidates and are unable to model the interdependent relations during retrieval. Moreover, the pipelined approaches of retrieval and generation might result in poor generation performance when retrieval performance is low. To address these issues, we propose a Structured Knowledge and Unified Retrieval-Generation (SKURG) approach. SKURG employs an Entity-centered Fusion Encoder to align sources from different modalities using shared entities. It then uses a unified Retrieval-Generation Decoder to integrate intermediate retrieval results for answer generation and also adaptively determine the number of retrieval steps. Extensive experiments on two representative multi-modal mult",
    "path": "papers/22/12/2212.08632.json",
    "total_tokens": 862,
    "translated_title": "通过结构化的知识和统一的检索-生成，增强多模态多跳问答",
    "translated_abstract": "多模态多跳问答涉及通过推理多个来自不同模态的输入源来回答问题。现有方法通常分别检索证据，然后使用语言模型根据检索到的证据生成答案，因此不能充分连接候选项，并且无法建模检索过程中的相互关系。此外，检索和生成的流水线方法可能导致检索性能较低时生成性能差。为了解决这些问题，我们提出了一种结构化的知识和统一的检索-生成（SKURG）方法。SKURG使用实体中心融合编码器来对齐不同模态的来源，使用共享实体。然后，它使用统一的检索-生成解码器来整合中间检索结果进行答案生成，并自适应决定检索步骤的数量。",
    "tldr": "通过结构化的知识和统一的检索-生成方法，增强多模态多跳问答。使用实体中心融合编码器对齐不同模态的来源，使用统一的检索-生成解码器整合中间检索结果进行答案生成，并自适应决定检索步骤的数量。",
    "en_tdlr": "Enhancing multi-modal multi-hop question answering through structured knowledge and unified retrieval-generation. Using an entity-centered fusion encoder to align sources from different modalities and a unified retrieval-generation decoder to integrate intermediate retrieval results for answer generation, and adaptively determine the number of retrieval steps."
}