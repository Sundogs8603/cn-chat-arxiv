{
    "title": "Federated Neural Topic Models. (arXiv:2212.02269v2 [cs.LG] UPDATED)",
    "abstract": "Over the last years, topic modeling has emerged as a powerful technique for organizing and summarizing big collections of documents or searching for particular patterns in them. However, privacy concerns may arise when cross-analyzing data from different sources. Federated topic modeling solves this issue by allowing multiple parties to jointly train a topic model without sharing their data. While several federated approximations of classical topic models do exist, no research has been conducted on their application for neural topic models. To fill this gap, we propose and analyze a federated implementation based on state-of-the-art neural topic modeling implementations, showing its benefits when there is a diversity of topics across the nodes' documents and the need to build a joint model. In practice, our approach is equivalent to a centralized model training, but preserves the privacy of the nodes. Advantages of this federated scenario are illustrated by means of experiments using b",
    "link": "http://arxiv.org/abs/2212.02269",
    "context": "Title: Federated Neural Topic Models. (arXiv:2212.02269v2 [cs.LG] UPDATED)\nAbstract: Over the last years, topic modeling has emerged as a powerful technique for organizing and summarizing big collections of documents or searching for particular patterns in them. However, privacy concerns may arise when cross-analyzing data from different sources. Federated topic modeling solves this issue by allowing multiple parties to jointly train a topic model without sharing their data. While several federated approximations of classical topic models do exist, no research has been conducted on their application for neural topic models. To fill this gap, we propose and analyze a federated implementation based on state-of-the-art neural topic modeling implementations, showing its benefits when there is a diversity of topics across the nodes' documents and the need to build a joint model. In practice, our approach is equivalent to a centralized model training, but preserves the privacy of the nodes. Advantages of this federated scenario are illustrated by means of experiments using b",
    "path": "papers/22/12/2212.02269.json",
    "total_tokens": 777,
    "translated_title": "联邦神经主题模型",
    "translated_abstract": "近年来，主题建模已成为组织和总结大型文档集合或在其中搜索特定模式的强大技术。然而，当从不同来源交叉分析数据时，可能会出现隐私问题。联邦主题建模通过允许多个方共同训练主题模型而不共享其数据来解决此问题。我们提出并分析了一种基于最先进的神经主题建模实现的联邦实现，显示其在节点文档的主题多样性和建立联合模型的需要时的优势。在实践中，我们的方法相当于集中模型训练，但保护节点的隐私。使用基准数据集进行的实验说明了这种联邦场景的优点。",
    "tldr": "该论文提出了一种基于神经主题建模实现的联邦神经主题模型，可以在不共享数据的情况下允许多个方共同训练主题模型和保护节点隐私。",
    "en_tdlr": "This paper proposes a federated neural topic model based on state-of-the-art neural topic modeling implementations, which allows multiple parties to jointly train a topic model without sharing their data and preserves the privacy of the nodes."
}