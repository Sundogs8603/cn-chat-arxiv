{
    "title": "Rethinking the Role of Pre-Trained Networks in Source-Free Domain Adaptation. (arXiv:2212.07585v2 [cs.CV] UPDATED)",
    "abstract": "Source-free domain adaptation (SFDA) aims to adapt a source model trained on a fully-labeled source domain to an unlabeled target domain. Large-data pre-trained networks are used to initialize source models during source training, and subsequently discarded. However, source training can cause the model to overfit to source data distribution and lose applicable target domain knowledge. We propose to integrate the pre-trained network into the target adaptation process as it has diversified features important for generalization and provides an alternate view of features and classification decisions different from the source model. We propose to distil useful target domain information through a co-learning strategy to improve target pseudolabel quality for finetuning the source model. Evaluation on 4 benchmark datasets show that our proposed strategy improves adaptation performance and can be successfully integrated with existing SFDA methods. Leveraging modern pre-trained networks that ha",
    "link": "http://arxiv.org/abs/2212.07585",
    "context": "Title: Rethinking the Role of Pre-Trained Networks in Source-Free Domain Adaptation. (arXiv:2212.07585v2 [cs.CV] UPDATED)\nAbstract: Source-free domain adaptation (SFDA) aims to adapt a source model trained on a fully-labeled source domain to an unlabeled target domain. Large-data pre-trained networks are used to initialize source models during source training, and subsequently discarded. However, source training can cause the model to overfit to source data distribution and lose applicable target domain knowledge. We propose to integrate the pre-trained network into the target adaptation process as it has diversified features important for generalization and provides an alternate view of features and classification decisions different from the source model. We propose to distil useful target domain information through a co-learning strategy to improve target pseudolabel quality for finetuning the source model. Evaluation on 4 benchmark datasets show that our proposed strategy improves adaptation performance and can be successfully integrated with existing SFDA methods. Leveraging modern pre-trained networks that ha",
    "path": "papers/22/12/2212.07585.json",
    "total_tokens": 945,
    "translated_title": "重新思考预训练网络在无源领域自适应中的作用",
    "translated_abstract": "无源领域自适应（SFDA）旨在将在完全标记的源领域上训练的源模型适应到无标签的目标领域。在源训练期间，使用大数据预训练网络来初始化源模型，然后将其丢弃。然而，源训练可能导致模型在源数据分布上过拟合，并丧失适用于目标领域的知识。我们提议将预训练网络整合到目标自适应过程中，因为它具有重要的泛化性能的多样化特征，并提供与源模型不同的特征和分类决策的另一视角。我们提出通过共同学习策略提炼有用的目标领域信息，以改善微调源模型的目标伪标签质量。对4个基准数据集的评估结果显示，我们提出的策略改善了自适应性能，并可以成功地与现有的SFDA方法集成。利用现代预训练网络具有多样化的特征来实现领域自适应具有重要意义。",
    "tldr": "本研究提出将预训练网络整合到目标领域自适应中，通过共同学习策略提取有用的目标领域信息，以改善源模型的自适应性能。实验证明这种策略能够成功地提高自适应性能，并与现有的方法集成。"
}