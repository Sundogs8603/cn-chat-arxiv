{
    "title": "Visual Query Tuning: Towards Effective Usage of Intermediate Representations for Parameter and Memory Efficient Transfer Learning. (arXiv:2212.03220v2 [cs.LG] UPDATED)",
    "abstract": "Intermediate features of a pre-trained model have been shown informative for making accurate predictions on downstream tasks, even if the model backbone is kept frozen. The key challenge is how to utilize these intermediate features given their gigantic amount. We propose visual query tuning (VQT), a simple yet effective approach to aggregate intermediate features of Vision Transformers. Through introducing a handful of learnable ``query'' tokens to each layer, VQT leverages the inner workings of Transformers to ``summarize'' rich intermediate features of each layer, which can then be used to train the prediction heads of downstream tasks. As VQT keeps the intermediate features intact and only learns to combine them, it enjoys memory efficiency in training, compared to many other parameter-efficient fine-tuning approaches that learn to adapt features and need back-propagation through the entire backbone. This also suggests the complementary role between VQT and those approaches in tran",
    "link": "http://arxiv.org/abs/2212.03220",
    "context": "Title: Visual Query Tuning: Towards Effective Usage of Intermediate Representations for Parameter and Memory Efficient Transfer Learning. (arXiv:2212.03220v2 [cs.LG] UPDATED)\nAbstract: Intermediate features of a pre-trained model have been shown informative for making accurate predictions on downstream tasks, even if the model backbone is kept frozen. The key challenge is how to utilize these intermediate features given their gigantic amount. We propose visual query tuning (VQT), a simple yet effective approach to aggregate intermediate features of Vision Transformers. Through introducing a handful of learnable ``query'' tokens to each layer, VQT leverages the inner workings of Transformers to ``summarize'' rich intermediate features of each layer, which can then be used to train the prediction heads of downstream tasks. As VQT keeps the intermediate features intact and only learns to combine them, it enjoys memory efficiency in training, compared to many other parameter-efficient fine-tuning approaches that learn to adapt features and need back-propagation through the entire backbone. This also suggests the complementary role between VQT and those approaches in tran",
    "path": "papers/22/12/2212.03220.json",
    "total_tokens": 1045,
    "translated_title": "视觉查询调整：为了有效利用中间表示进行参数和内存高效的迁移学习",
    "translated_abstract": "先前训练模型的中间特征已被证明对于在下游任务中进行准确预测非常有用，即使模型骨干保持冻结。关键挑战在于如何利用这些中间特征。我们提出了一种简单而有效的方法-视觉查询调整（VQT），用于聚合Vision Transformers的中间特征。通过为每个层引入少量可学习的“查询”令牌，VQT利用Transformer的内部运行机制来“总结”每个层的丰富中间特征，然后可以用于训练下游任务的预测头。由于VQT保持了中间特征的完整性并仅学习了如何组合它们，因此与许多其他参数高效的微调方法相比，VQT在训练中具有内存效率，后者需要学习如何适应特征并需要对整个骨干进行反向传播。这也表明了VQT与这些方法在翻译学习流程中的互补作用。我们在几个基准测试中展示了VQT的有效性，包括对象检测、实例分割和密集预测任务，并展示了它与最先进的微调方法相比的优势。",
    "tldr": "本文介绍了一种名为视觉查询调整（VQT）的简单而有效的方法，用于聚合Vision Transformers的中间特征。VQT在训练中具有内存效率，相比于许多其他 fine-tuning 方法，不需要对整个骨干进行反向传播。该方法在几个基准测试中优于最先进的微调方法。",
    "en_tdlr": "This paper proposes a simple yet effective approach called visual query tuning (VQT) for aggregating intermediate features of Vision Transformers, which enjoys memory efficiency in training and outperforms state-of-the-art fine-tuning methods on several benchmarks."
}