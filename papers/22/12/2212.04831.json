{
    "title": "Uncertainty Estimation in Deep Speech Enhancement Using Complex Gaussian Mixture Models. (arXiv:2212.04831v2 [eess.AS] UPDATED)",
    "abstract": "Single-channel deep speech enhancement approaches often estimate a single multiplicative mask to extract clean speech without a measure of its accuracy. Instead, in this work, we propose to quantify the uncertainty associated with clean speech estimates in neural network-based speech enhancement. Predictive uncertainty is typically categorized into aleatoric uncertainty and epistemic uncertainty. The former accounts for the inherent uncertainty in data and the latter corresponds to the model uncertainty. Aiming for robust clean speech estimation and efficient predictive uncertainty quantification, we propose to integrate statistical complex Gaussian mixture models (CGMMs) into a deep speech enhancement framework. More specifically, we model the dependency between input and output stochastically by means of a conditional probability density and train a neural network to map the noisy input to the full posterior distribution of clean speech, modeled as a mixture of multiple complex Gauss",
    "link": "http://arxiv.org/abs/2212.04831",
    "context": "Title: Uncertainty Estimation in Deep Speech Enhancement Using Complex Gaussian Mixture Models. (arXiv:2212.04831v2 [eess.AS] UPDATED)\nAbstract: Single-channel deep speech enhancement approaches often estimate a single multiplicative mask to extract clean speech without a measure of its accuracy. Instead, in this work, we propose to quantify the uncertainty associated with clean speech estimates in neural network-based speech enhancement. Predictive uncertainty is typically categorized into aleatoric uncertainty and epistemic uncertainty. The former accounts for the inherent uncertainty in data and the latter corresponds to the model uncertainty. Aiming for robust clean speech estimation and efficient predictive uncertainty quantification, we propose to integrate statistical complex Gaussian mixture models (CGMMs) into a deep speech enhancement framework. More specifically, we model the dependency between input and output stochastically by means of a conditional probability density and train a neural network to map the noisy input to the full posterior distribution of clean speech, modeled as a mixture of multiple complex Gauss",
    "path": "papers/22/12/2212.04831.json",
    "total_tokens": 1027,
    "translated_title": "基于复高斯混合模型的深度语音增强中的不确定性估计",
    "translated_abstract": "单通道深度语音增强方法通常估计单一的乘性掩码以提取干净的语音信号，但缺乏其准确性的度量。本研究提出在神经网络语音增强中量化与干净语音估计相关的不确定性。预测不确定性通常分为先验不确定性和模型不确定性。前者解释了数据固有的不确定性，后者则对应模型不确定性。为了实现鲁棒的干净语音估计和高效的预测不确定性量化，我们提出将统计复高斯混合模型（CGMM）集成到深度语音增强框架中。具体而言，我们通过条件概率密度函数随机建模输入和输出之间的依赖关系，并训练神经网络将噪声输入映射到干净语音的完整后验分布，该分布建模为多个复高斯分布的混合。在CHiME-5数据集上的实验结果表明，我们的方法优于现有的单通道语音增强方法，并提供了更可靠的预测干净语音相关的不确定性的度量。",
    "tldr": "本研究提出了一种基于复高斯混合模型的深度语音增强方法，可以估计干净语音的完整后验分布，而不是单一的乘性掩码。这种方法在准确性和预测不确定性的量化方面都表现优异，超越了现有的单通道语音增强方法。",
    "en_tdlr": "This study proposes a deep speech enhancement method based on complex Gaussian mixture models, which can estimate the full posterior distribution of clean speech instead of a single multiplicative mask. This method outperforms existing single-channel speech enhancement methods in terms of accuracy and the quantification of predictive uncertainty."
}