{
    "title": "Optimal Transport for Unsupervised Hallucination Detection in Neural Machine Translation. (arXiv:2212.09631v2 [cs.CL] UPDATED)",
    "abstract": "Neural machine translation (NMT) has become the de-facto standard in real-world machine translation applications. However, NMT models can unpredictably produce severely pathological translations, known as hallucinations, that seriously undermine user trust. It becomes thus crucial to implement effective preventive strategies to guarantee their proper functioning. In this paper, we address the problem of hallucination detection in NMT by following a simple intuition: as hallucinations are detached from the source content, they exhibit encoder-decoder attention patterns that are statistically different from those of good quality translations. We frame this problem with an optimal transport formulation and propose a fully unsupervised, plug-in detector that can be used with any attention-based NMT model. Experimental results show that our detector not only outperforms all previous model-based detectors, but is also competitive with detectors that employ large models trained on millions of",
    "link": "http://arxiv.org/abs/2212.09631",
    "context": "Title: Optimal Transport for Unsupervised Hallucination Detection in Neural Machine Translation. (arXiv:2212.09631v2 [cs.CL] UPDATED)\nAbstract: Neural machine translation (NMT) has become the de-facto standard in real-world machine translation applications. However, NMT models can unpredictably produce severely pathological translations, known as hallucinations, that seriously undermine user trust. It becomes thus crucial to implement effective preventive strategies to guarantee their proper functioning. In this paper, we address the problem of hallucination detection in NMT by following a simple intuition: as hallucinations are detached from the source content, they exhibit encoder-decoder attention patterns that are statistically different from those of good quality translations. We frame this problem with an optimal transport formulation and propose a fully unsupervised, plug-in detector that can be used with any attention-based NMT model. Experimental results show that our detector not only outperforms all previous model-based detectors, but is also competitive with detectors that employ large models trained on millions of",
    "path": "papers/22/12/2212.09631.json",
    "total_tokens": 932,
    "tldr": "本文提出了一种无监督、可插入的NMT幻觉检测方法，通过最优输运的方法，检测出编码器-解码器注意力模式与高质量翻译有明显差异。"
}