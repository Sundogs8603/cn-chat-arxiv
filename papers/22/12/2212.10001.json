{
    "title": "Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters. (arXiv:2212.10001v2 [cs.CL] UPDATED)",
    "abstract": "Chain-of-Thought (CoT) prompting can dramatically improve the multi-step reasoning abilities of large language models (LLMs). CoT explicitly encourages the LLM to generate intermediate rationales for solving a problem, by providing a series of reasoning steps in the demonstrations. Despite its success, there is still little understanding of what makes CoT prompting effective and which aspects of the demonstrated reasoning steps contribute to its performance. In this paper, we show that CoT reasoning is possible even with invalid demonstrations - prompting with invalid reasoning steps can achieve over 80-90% of the performance obtained using CoT under various metrics, while still generating coherent lines of reasoning during inference. Further experiments show that other aspects of the rationales, such as being relevant to the query and correctly ordering the reasoning steps, are much more important for effective CoT reasoning. Overall, these findings both deepen our understanding of Co",
    "link": "http://arxiv.org/abs/2212.10001",
    "context": "Title: Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters. (arXiv:2212.10001v2 [cs.CL] UPDATED)\nAbstract: Chain-of-Thought (CoT) prompting can dramatically improve the multi-step reasoning abilities of large language models (LLMs). CoT explicitly encourages the LLM to generate intermediate rationales for solving a problem, by providing a series of reasoning steps in the demonstrations. Despite its success, there is still little understanding of what makes CoT prompting effective and which aspects of the demonstrated reasoning steps contribute to its performance. In this paper, we show that CoT reasoning is possible even with invalid demonstrations - prompting with invalid reasoning steps can achieve over 80-90% of the performance obtained using CoT under various metrics, while still generating coherent lines of reasoning during inference. Further experiments show that other aspects of the rationales, such as being relevant to the query and correctly ordering the reasoning steps, are much more important for effective CoT reasoning. Overall, these findings both deepen our understanding of Co",
    "path": "papers/22/12/2212.10001.json",
    "total_tokens": 926,
    "translated_title": "探索“Chain-of-Thought”提示的有效性：一个关于重点的实证研究",
    "translated_abstract": "“Chain-of-Thought”（CoT）提示可以极大地提高大型语言模型（LLMs）的多步推理能力。CoT通过在演示中提供一系列的推理步骤，明确鼓励LLM生成解决问题的中间理性，从而实现。尽管CoT取得了成功，但目前仍很少了解什么使CoT提示有效，以及演示的推理步骤的哪些方面对其性能起到贡献。在本文中，我们表明，即使在使用无效推理步骤的情况下，提示也可以实现CoT推理，而使用各种度量方法，提示的性能也可以达到使用CoT时的80-90％以上，同时在推理期间仍会生成连贯的推理链条。进一步的实验表明，理性的其他方面，比如与查询相关和正确排序的推理步骤，对于有效的CoT推理更为重要。总体而言，这些发现深化了我们对CoT提示的理解，并为提高其效果提出了策略。",
    "tldr": "本文通过实验证明，即使在使用无效推理步骤的情况下，CoT提示也可以实现CoT推理，并显示出其他方面对于CoT的有效性更为关键，这有助于深入了解CoT提示的有效性并提出改进策略。",
    "en_tdlr": "This paper empirically demonstrates that CoT prompting can achieve CoT reasoning even with invalid demonstrations, and identifies other aspects such as relevance to query and correct ordering of reasoning steps to be more important for CoT effectiveness, which provides insights for understanding and improving CoT prompting."
}