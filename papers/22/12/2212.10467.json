{
    "title": "Generic Temporal Reasoning with Differential Analysis and Explanation. (arXiv:2212.10467v2 [cs.CL] UPDATED)",
    "abstract": "Temporal reasoning is the task of predicting temporal relations of event pairs. While temporal reasoning models can perform reasonably well on in-domain benchmarks, we have little idea of these systems' generalizability due to existing datasets' limitations. In this work, we introduce a novel task named TODAY that bridges this gap with temporal differential analysis, which as the name suggests, evaluates whether systems can correctly understand the effect of incremental changes. Specifically, TODAY introduces slight contextual changes for given event pairs, and systems are asked to tell how this subtle contextual change would affect relevant temporal relation distributions. To facilitate learning, TODAY also annotates human explanations. We show that existing models, including GPT-3.5, drop to random guessing on TODAY, suggesting that they heavily rely on spurious information rather than proper reasoning for temporal predictions. On the other hand, we show that TODAY's supervision styl",
    "link": "http://arxiv.org/abs/2212.10467",
    "context": "Title: Generic Temporal Reasoning with Differential Analysis and Explanation. (arXiv:2212.10467v2 [cs.CL] UPDATED)\nAbstract: Temporal reasoning is the task of predicting temporal relations of event pairs. While temporal reasoning models can perform reasonably well on in-domain benchmarks, we have little idea of these systems' generalizability due to existing datasets' limitations. In this work, we introduce a novel task named TODAY that bridges this gap with temporal differential analysis, which as the name suggests, evaluates whether systems can correctly understand the effect of incremental changes. Specifically, TODAY introduces slight contextual changes for given event pairs, and systems are asked to tell how this subtle contextual change would affect relevant temporal relation distributions. To facilitate learning, TODAY also annotates human explanations. We show that existing models, including GPT-3.5, drop to random guessing on TODAY, suggesting that they heavily rely on spurious information rather than proper reasoning for temporal predictions. On the other hand, we show that TODAY's supervision styl",
    "path": "papers/22/12/2212.10467.json",
    "total_tokens": 929,
    "tldr": "本研究提出了一个名为TODAY的新任务，利用时间差分分析检验时间推理模型的通用性。现有模型在此任务上表现差，说明它们过于依赖虚假信息而非适当的推理。但TODAY的监督方法有助于提高模型的学习能力，从而提高其通用性。"
}