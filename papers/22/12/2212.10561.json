{
    "title": "Parsel: Algorithmic Reasoning with Language Models by Composing Decompositions. (arXiv:2212.10561v3 [cs.CL] UPDATED)",
    "abstract": "Despite recent success in large language model (LLM) reasoning, LLMs struggle with hierarchical multi-step reasoning tasks like generating complex programs. For these tasks, humans often start with a high-level algorithmic design and implement each part gradually. We introduce Parsel, a framework enabling automatic implementation and validation of complex algorithms with code LLMs. With Parsel, we automatically decompose algorithmic tasks into hierarchical natural language function descriptions and then search over combinations of possible function implementations using tests. We show that Parsel can be used across domains requiring hierarchical reasoning, including program synthesis and robotic planning. We find that, using Parsel, LLMs solve more competition-level problems in the APPS dataset, resulting in pass rates over 75\\% higher than prior results from directly sampling AlphaCode and Codex, while often using a smaller sample budget. Moreover, with automatically generated tests, ",
    "link": "http://arxiv.org/abs/2212.10561",
    "context": "Title: Parsel: Algorithmic Reasoning with Language Models by Composing Decompositions. (arXiv:2212.10561v3 [cs.CL] UPDATED)\nAbstract: Despite recent success in large language model (LLM) reasoning, LLMs struggle with hierarchical multi-step reasoning tasks like generating complex programs. For these tasks, humans often start with a high-level algorithmic design and implement each part gradually. We introduce Parsel, a framework enabling automatic implementation and validation of complex algorithms with code LLMs. With Parsel, we automatically decompose algorithmic tasks into hierarchical natural language function descriptions and then search over combinations of possible function implementations using tests. We show that Parsel can be used across domains requiring hierarchical reasoning, including program synthesis and robotic planning. We find that, using Parsel, LLMs solve more competition-level problems in the APPS dataset, resulting in pass rates over 75\\% higher than prior results from directly sampling AlphaCode and Codex, while often using a smaller sample budget. Moreover, with automatically generated tests, ",
    "path": "papers/22/12/2212.10561.json",
    "total_tokens": 945,
    "translated_abstract": "尽管最近大型语言模型(LLM)在推理方面取得了成功，但在生成复杂程序等分层多步推理任务中，LLM仍然面临困难。对于这些任务，人类通常从高级算法设计开始，逐步实现每个部分。我们介绍了Parsel，这是一个框架，能够使用代码LLM自动实现和验证复杂算法。使用Parsel，我们将算法任务自动分解为分层的自然语言函数描述，然后使用测试搜索可能的函数实现组合。我们发现Parsel可用于需要分层推理的各个领域，包括程序合成和机器人规划。我们发现，使用Parsel，LLM可以在APPS数据集中解决更多竞争级别的问题，通过直接采样AlphaCode和Codex的先前结果，通过使用更小的样本预算，通过率比先前高达75％以上。此外，通过自动生成测试，",
    "tldr": "Parsel是一个使用代码LLM进行算法推理的框架，可以自动实现和验证复杂算法。使用分层的自然语言函数描述和测试搜索可能的函数实现组合。Parsel可用于需要分层推理的各个领域，包括程序合成和机器人规划。使用Parsel，LLMs可以在APPS数据集中解决更多竞争级别的问题，并获得更高的通过率。"
}