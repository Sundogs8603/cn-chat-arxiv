{
    "title": "Explanation Regeneration via Information Bottleneck. (arXiv:2212.09603v2 [cs.CL] UPDATED)",
    "abstract": "Explaining the black-box predictions of NLP models naturally and accurately is an important open problem in natural language generation. These free-text explanations are expected to contain sufficient and carefully-selected evidence to form supportive arguments for predictions. Due to the superior generative capacity of large pretrained language models, recent work built on prompt engineering enables explanation generation without specific training. However, explanation generated through single-pass prompting often lacks sufficiency and conciseness. To address this problem, we develop an information bottleneck method EIB to produce refined explanations that are sufficient and concise. Our approach regenerates the free-text explanation by polishing the single-pass output from the pretrained language model but retaining the information that supports the contents being explained. Experiments on two out-of-domain tasks verify the effectiveness of EIB through automatic evaluation and thorou",
    "link": "http://arxiv.org/abs/2212.09603",
    "context": "Title: Explanation Regeneration via Information Bottleneck. (arXiv:2212.09603v2 [cs.CL] UPDATED)\nAbstract: Explaining the black-box predictions of NLP models naturally and accurately is an important open problem in natural language generation. These free-text explanations are expected to contain sufficient and carefully-selected evidence to form supportive arguments for predictions. Due to the superior generative capacity of large pretrained language models, recent work built on prompt engineering enables explanation generation without specific training. However, explanation generated through single-pass prompting often lacks sufficiency and conciseness. To address this problem, we develop an information bottleneck method EIB to produce refined explanations that are sufficient and concise. Our approach regenerates the free-text explanation by polishing the single-pass output from the pretrained language model but retaining the information that supports the contents being explained. Experiments on two out-of-domain tasks verify the effectiveness of EIB through automatic evaluation and thorou",
    "path": "papers/22/12/2212.09603.json",
    "total_tokens": 816,
    "translated_title": "信息瓶颈通过解释重建",
    "translated_abstract": "在自然语言生成中，解释NLP模型的黑盒预测自然而准确地是一个重要的开放性问题。这些自由文本的解释被期望包含足够和经过精心选择的证据，以形成对预测的支持性论据。由于大型预训练语言模型具有更强大的生成能力，最近的工作借助提示工程使得解释生成可以不需要特定的训练。然而，通过单次提示生成的解释往往缺乏充分性和简明性。为了解决这个问题，我们开发了一种信息瓶颈方法EIB，用于产生充分和简明的精炼解释。我们的方法通过对预训练语言模型的单次输出进行优化，同时保留支持所解释内容的信息来重建自由文本解释。通过对两个领域外任务的实验，通过自动评估和彻底验证了EIB的有效性。",
    "tldr": "该论文介绍了一种通过信息瓶颈方法来生成充分和简明解释的方法，以解决解释自然语言生成中的黑盒预测问题。实验证实了该方法的有效性。",
    "en_tdlr": "This paper presents a method using the information bottleneck approach to generate sufficient and concise explanations, addressing the problem of explaining black-box predictions in natural language generation. Experimental results confirm the effectiveness of the proposed method."
}