{
    "title": "MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning. (arXiv:2212.10773v2 [cs.CL] UPDATED)",
    "abstract": "Instruction tuning, a new learning paradigm that fine-tunes pre-trained language models on tasks specified through instructions, has shown promising zero-shot performance on various natural language processing tasks. However, it's still not explored for vision and multimodal tasks. In this work, we introduce MultiInstruct, the first multimodal instruction tuning benchmark dataset that consists of 47 diverse multimodal tasks covering 11 broad categories. Each task is designed at least with 5,000 instances (input-out pairs) from existing open-source datasets and 5 expert-written instructions. We take OFA as the base pre-trained model for multimodal instruction tuning, and to improve its performance, we explore multiple transfer learning strategies to leverage the large-scale Natural Instructions dataset. Experimental results demonstrate its strong zero-shot performance on various unseen multimodal tasks and the benefit of transfer learning from text-only instructions. We also design a ne",
    "link": "http://arxiv.org/abs/2212.10773",
    "context": "Title: MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning. (arXiv:2212.10773v2 [cs.CL] UPDATED)\nAbstract: Instruction tuning, a new learning paradigm that fine-tunes pre-trained language models on tasks specified through instructions, has shown promising zero-shot performance on various natural language processing tasks. However, it's still not explored for vision and multimodal tasks. In this work, we introduce MultiInstruct, the first multimodal instruction tuning benchmark dataset that consists of 47 diverse multimodal tasks covering 11 broad categories. Each task is designed at least with 5,000 instances (input-out pairs) from existing open-source datasets and 5 expert-written instructions. We take OFA as the base pre-trained model for multimodal instruction tuning, and to improve its performance, we explore multiple transfer learning strategies to leverage the large-scale Natural Instructions dataset. Experimental results demonstrate its strong zero-shot performance on various unseen multimodal tasks and the benefit of transfer learning from text-only instructions. We also design a ne",
    "path": "papers/22/12/2212.10773.json",
    "total_tokens": 1043,
    "translated_title": "MultiInstruct: 通过指令调优来改善多模态零样本学习",
    "translated_abstract": "指令调优是一种新的学习范式，它在指令指定的任务上对预训练的语言模型进行微调，在各种自然语言处理任务上展现了有希望的零样本表现。然而，它尚未被用于视觉和多模态任务。本文介绍了 MultiInstruct，这是第一个多模态指令调优基准数据集，包含 47 个不同的多模态任务，涵盖了 11 个广泛的类别。每个任务至少设计有 5,000 个实例（输入-输出对）来自现有的开源数据集和 5 个专家编写的指令。我们选取 OFA 作为多模态指令调优的基础预训练模型，并探索多种迁移学习策略，以利用大规模的自然语言指令数据集。实验结果展示了其在各种未见过的多模态任务中具有强大的零样本表现，以及从纯文本指令中获得迁移学习的好处。我们还设计了一种新的任务完成率指标来评估零样本性能，度量模型在仅有指令的情况下完成任务的能力。",
    "tldr": "本文介绍了 MultiInstruct，这是第一个多模态指令调优基准数据集，并探索多种迁移学习策略从大规模的自然语言指令数据集中提高预训练模型的性能。实验结果展示了其在各种未见过的多模态任务中具有强大的零样本表现，以及设计的新的任务完成率指标。",
    "en_tdlr": "This paper introduces MultiInstruct, the first multimodal instruction tuning benchmark dataset, and explores multiple transfer learning strategies to improve the performance of pre-trained models from a large-scale natural language instruction dataset. The experimental results demonstrate its strong zero-shot performance on various unseen multimodal tasks and introduce a new evaluation metric for task completion rate."
}