{
    "title": "SPARF: Large-Scale Learning of 3D Sparse Radiance Fields from Few Input Images. (arXiv:2212.09100v2 [cs.CV] UPDATED)",
    "abstract": "Recent advances in Neural Radiance Fields (NeRFs) treat the problem of novel view synthesis as Sparse Radiance Field (SRF) optimization using sparse voxels for efficient and fast rendering (plenoxels,InstantNGP). In order to leverage machine learning and adoption of SRFs as a 3D representation, we present SPARF, a large-scale ShapeNet-based synthetic dataset for novel view synthesis consisting of $\\sim$ 17 million images rendered from nearly 40,000 shapes at high resolution (400 X 400 pixels). The dataset is orders of magnitude larger than existing synthetic datasets for novel view synthesis and includes more than one million 3D-optimized radiance fields with multiple voxel resolutions. Furthermore, we propose a novel pipeline (SuRFNet) that learns to generate sparse voxel radiance fields from only few views. This is done by using the densely collected SPARF dataset and 3D sparse convolutions. SuRFNet employs partial SRFs from few/one images and a specialized SRF loss to learn to gener",
    "link": "http://arxiv.org/abs/2212.09100",
    "context": "Title: SPARF: Large-Scale Learning of 3D Sparse Radiance Fields from Few Input Images. (arXiv:2212.09100v2 [cs.CV] UPDATED)\nAbstract: Recent advances in Neural Radiance Fields (NeRFs) treat the problem of novel view synthesis as Sparse Radiance Field (SRF) optimization using sparse voxels for efficient and fast rendering (plenoxels,InstantNGP). In order to leverage machine learning and adoption of SRFs as a 3D representation, we present SPARF, a large-scale ShapeNet-based synthetic dataset for novel view synthesis consisting of $\\sim$ 17 million images rendered from nearly 40,000 shapes at high resolution (400 X 400 pixels). The dataset is orders of magnitude larger than existing synthetic datasets for novel view synthesis and includes more than one million 3D-optimized radiance fields with multiple voxel resolutions. Furthermore, we propose a novel pipeline (SuRFNet) that learns to generate sparse voxel radiance fields from only few views. This is done by using the densely collected SPARF dataset and 3D sparse convolutions. SuRFNet employs partial SRFs from few/one images and a specialized SRF loss to learn to gener",
    "path": "papers/22/12/2212.09100.json",
    "total_tokens": 1035,
    "translated_title": "SPARF：从少量输入图像中学习大规模的 3D 稀疏辐射场",
    "translated_abstract": "最近神经辐射场 (NeRFs) 的进展将新视角合成问题看作是稀疏辐射场 (SRF) 优化，使用稀疏体素进行高效快速渲染 (plenoxels, InstantNGP)。为了利用机器学习和采用 SRF 作为 3D 表示，我们提出了 SPARF，这是一个基于 ShapeNet 的大规模合成数据集，用于新视角合成，由 $\\sim$ 17 百万张图像组成，从近 40,000 个高分辨率形状渲染而来 (400 X 400 像素)。该数据集比现有的用于新视角合成的合成数据集大几个数量级，包括超过一百万个具有多个体素分辨率的 3D 优化过的辐射场。此外，我们提出了一种新颖的管线（SuRFNet），它从少量视图中学习生成稀疏体素辐射场。这是通过使用密集收集的 SPARF 数据集和 3D 稀疏卷积来实现的。SuRFNet 使用少量/单个图像的部分 SRF 和特定的 SRF 损失来学习生成稀疏体素辐射场。",
    "tldr": "提出了一个大规模的 ShapeNet 合成数据集 SPARF，包括超过 100 万个有多个体素分辨率的 3D 优化的辐射场，用于新视角合成。同时提出了一种新颖的管线 SuRFNet，通过学习少量视图生成稀疏体素辐射场。",
    "en_tdlr": "A large-scale synthetic dataset SPARF is proposed for novel view synthesis, consisting of over 1 million 3D optimized radiance fields with multiple voxel resolutions. A novel pipeline SuRFNet is also proposed to learn to generate sparse voxel radiance fields from only few views."
}