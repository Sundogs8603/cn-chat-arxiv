{
    "title": "From CNNs to Shift-Invariant Twin Models Based on Complex Wavelets. (arXiv:2212.00394v2 [cs.CV] UPDATED)",
    "abstract": "We propose a novel antialiasing method to increase shift invariance and prediction accuracy in convolutional neural networks. Specifically, we replace the first-layer combination \"real-valued convolutions + max pooling\" ($\\mathbb{R}$Max) by \"complex-valued convolutions + modulus\" ($\\mathbb{C}$Mod), which is stable to translations. To justify our approach, we claim that $\\mathbb{C}$Mod and $\\mathbb{R}$Max produce comparable outputs when the convolution kernel is band-pass and oriented (Gabor-like filter). In this context, $\\mathbb{C}$Mod can be considered as a stable alternative to $\\mathbb{R}$Max. Thus, prior to antialiasing, we force the convolution kernels to adopt such a Gabor-like structure. The corresponding architecture is called mathematical twin, because it employs a well-defined mathematical operator to mimic the behavior of the original, freely-trained model. Our antialiasing approach achieves superior accuracy on ImageNet and CIFAR-10 classification tasks, compared to prior ",
    "link": "http://arxiv.org/abs/2212.00394",
    "context": "Title: From CNNs to Shift-Invariant Twin Models Based on Complex Wavelets. (arXiv:2212.00394v2 [cs.CV] UPDATED)\nAbstract: We propose a novel antialiasing method to increase shift invariance and prediction accuracy in convolutional neural networks. Specifically, we replace the first-layer combination \"real-valued convolutions + max pooling\" ($\\mathbb{R}$Max) by \"complex-valued convolutions + modulus\" ($\\mathbb{C}$Mod), which is stable to translations. To justify our approach, we claim that $\\mathbb{C}$Mod and $\\mathbb{R}$Max produce comparable outputs when the convolution kernel is band-pass and oriented (Gabor-like filter). In this context, $\\mathbb{C}$Mod can be considered as a stable alternative to $\\mathbb{R}$Max. Thus, prior to antialiasing, we force the convolution kernels to adopt such a Gabor-like structure. The corresponding architecture is called mathematical twin, because it employs a well-defined mathematical operator to mimic the behavior of the original, freely-trained model. Our antialiasing approach achieves superior accuracy on ImageNet and CIFAR-10 classification tasks, compared to prior ",
    "path": "papers/22/12/2212.00394.json",
    "total_tokens": 933,
    "translated_title": "从CNN到基于复小波的平移不变双模型",
    "translated_abstract": "我们提出了一种新颖的抗混叠方法来增加卷积神经网络中的平移不变性和预测准确性。具体来说，我们用“复值卷积+模运算”（$\\mathbb{C}$Mod）代替第一层的“实值卷积+最大池化”（$\\mathbb{R}$Max），因为它稳定于平移。为了证明我们的方法，我们声称当卷积核是带通和定向的（类似于Gabor滤波器）时，$\\mathbb{C}$Mod和$\\mathbb{R}$Max产生可比较的输出。在这种情况下，$\\mathbb{C}$Mod可以被认为是$\\mathbb{R}$Max的稳定替代品。因此，在抗混叠之前，我们强制卷积核采用这种Gabor样式的结构。相应的架构称为数学双模型，因为它使用一个明确定义的数学运算符来模拟原始的自由训练模型的行为。我们的抗混叠方法在Imagenet和CIFAR-10分类任务上实现了比之前更高的准确性。",
    "tldr": "论文提出了一种消除OCV（Aliasing）的方法，该方法基于复数卷积，同时采用Gabor样式的卷积核，可以提高卷积神经网络的分类准确性。",
    "en_tdlr": "The paper proposes a method to eliminate aliasing based on complex-valued convolutions and Gabor-like convolution kernels, which improves the classification accuracy of CNNs."
}