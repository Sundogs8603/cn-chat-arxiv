{
    "title": "On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning. (arXiv:2212.08061v2 [cs.CL] UPDATED)",
    "abstract": "Generating a Chain of Thought (CoT) has been shown to consistently improve large language model (LLM) performance on a wide range of NLP tasks. However, prior work has mainly focused on logical reasoning tasks (e.g. arithmetic, commonsense QA); it remains unclear whether improvements hold for more diverse types of reasoning, especially in socially situated contexts. Concretely, we perform a controlled evaluation of zero-shot CoT across two socially sensitive domains: harmful questions and stereotype benchmarks. We find that zero-shot CoT reasoning in sensitive domains significantly increases a model's likelihood to produce harmful or undesirable output, with trends holding across different prompt formats and model variants. Furthermore, we show that harmful CoTs increase with model size, but decrease with improved instruction following. Our work suggests that zero-shot CoT should be used with caution on socially important tasks, especially when marginalized groups or sensitive topics a",
    "link": "http://arxiv.org/abs/2212.08061",
    "context": "Title: On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning. (arXiv:2212.08061v2 [cs.CL] UPDATED)\nAbstract: Generating a Chain of Thought (CoT) has been shown to consistently improve large language model (LLM) performance on a wide range of NLP tasks. However, prior work has mainly focused on logical reasoning tasks (e.g. arithmetic, commonsense QA); it remains unclear whether improvements hold for more diverse types of reasoning, especially in socially situated contexts. Concretely, we perform a controlled evaluation of zero-shot CoT across two socially sensitive domains: harmful questions and stereotype benchmarks. We find that zero-shot CoT reasoning in sensitive domains significantly increases a model's likelihood to produce harmful or undesirable output, with trends holding across different prompt formats and model variants. Furthermore, we show that harmful CoTs increase with model size, but decrease with improved instruction following. Our work suggests that zero-shot CoT should be used with caution on socially important tasks, especially when marginalized groups or sensitive topics a",
    "path": "papers/22/12/2212.08061.json",
    "total_tokens": 1031,
    "translated_title": "再三考虑，我们不要按步就班地思考！零样本推理中的偏见和有害性。",
    "translated_abstract": "已经证明，生成“思考链”（CoT）可以在各种NLP任务的大型语言模型（LLM）上始终提高性能。然而，先前的研究主要集中在逻辑推理任务上（例如算术，常识QA）；目前尚不清楚对于更多样化的推理类型（特别是在社会情境中），该改进是否会保持。具体来说，我们进行了针对两个社会敏感领域的零样本CoT控制评估：有害问题和刻板印象基准。我们发现，零样本CoT推理在敏感领域中显着增加了模型产生有害或不良输出的可能性，这种趋势在不同的提示格式和模型变体中始终存在。此外，我们还展示了有害的CoT随着模型大小增加而增加，但随着改进的指令遵循而减少。我们的工作表明，在涉及边缘化群体或敏感话题时，应谨慎使用零样本CoT推理。",
    "tldr": "该论文的研究探讨了零样本推理中的偏见和有害性。通过对社会敏感领域进行的控制评估，发现使用零样本CoT推理在敏感领域中会显着增加产生有害或不良输出的可能性。同时也指出，有害的CoT随着模型大小增加而增加，但随着改进的指令遵循而减少。",
    "en_tdlr": "This paper explores bias and toxicity in zero-shot reasoning, and shows that using zero-shot CoT reasoning in sensitive domains significantly increases the likelihood of harmful or undesirable output. It also suggests that harmful CoTs increase with model size but decrease with improved instruction following. The work highlights the need for caution in using zero-shot CoT reasoning in socially important tasks, especially when marginalized groups or sensitive topics are involved."
}