{
    "title": "Theoretical Guarantees for Sparse Principal Component Analysis based on the Elastic Net. (arXiv:2212.14194v2 [math.ST] UPDATED)",
    "abstract": "Sparse principal component analysis (SPCA) is widely used for dimensionality reduction and feature extraction in high-dimensional data analysis. Despite many methodological and theoretical developments in the past two decades, the theoretical guarantees of the popular SPCA algorithm proposed by Zou, Hastie & Tibshirani (2006) are still unknown. This paper aims to address this critical gap. We first revisit the SPCA algorithm of Zou et al. (2006) and present our implementation. We also study a computationally more efficient variant of the SPCA algorithm in Zou et al. (2006) that can be considered as the limiting case of SPCA. We provide the guarantees of convergence to a stationary point for both algorithms and prove that, under a sparse spiked covariance model, both algorithms can recover the principal subspace consistently under mild regularity conditions. We show that their estimation error bounds match the best available bounds of existing works or the minimax rates up to some logar",
    "link": "http://arxiv.org/abs/2212.14194",
    "context": "Title: Theoretical Guarantees for Sparse Principal Component Analysis based on the Elastic Net. (arXiv:2212.14194v2 [math.ST] UPDATED)\nAbstract: Sparse principal component analysis (SPCA) is widely used for dimensionality reduction and feature extraction in high-dimensional data analysis. Despite many methodological and theoretical developments in the past two decades, the theoretical guarantees of the popular SPCA algorithm proposed by Zou, Hastie & Tibshirani (2006) are still unknown. This paper aims to address this critical gap. We first revisit the SPCA algorithm of Zou et al. (2006) and present our implementation. We also study a computationally more efficient variant of the SPCA algorithm in Zou et al. (2006) that can be considered as the limiting case of SPCA. We provide the guarantees of convergence to a stationary point for both algorithms and prove that, under a sparse spiked covariance model, both algorithms can recover the principal subspace consistently under mild regularity conditions. We show that their estimation error bounds match the best available bounds of existing works or the minimax rates up to some logar",
    "path": "papers/22/12/2212.14194.json",
    "total_tokens": 908,
    "translated_title": "基于弹性网的稀疏主成分分析的理论保证",
    "translated_abstract": "稀疏主成分分析（SPCA）在高维数据分析中广泛用于降维和特征提取。尽管在过去的二十年中出现了许多方法论和理论发展，但流行的SPCA算法（由Zou、Hastie和Tibshirani于2006年提出）的理论保证仍然不明确。本文旨在填补这一关键差距。我们首先重新审视了Zou等人（2006年）的SPCA算法并呈现了我们的实现。同时，我们还研究了一种在Zou等人（2006年）中可以被认为是SPCA的极限情况的计算更有效的变体。我们为两种算法提供了到达稳定点的收敛性保证，并证明了，在稀疏峰值协方差模型下，在温和的正则条件下，这两种算法都可以一致地恢复主子空间。我们还表明，它们的估计误差边界与现有工作的最佳边界或最小极限速率匹配，直到某些对数。",
    "tldr": "本文填补了流行的SPCA算法的理论保证的空白，证明了在稀疏峰值协方差模型下，该算法一致地恢复了主子空间。",
    "en_tdlr": "This paper fills the gap in the theoretical guarantees of the popular SPCA algorithm and proves that the algorithm consistently recovers the principal subspace under a sparse spiked covariance model."
}