{
    "title": "Learning Latent Representations to Co-Adapt to Humans. (arXiv:2212.09586v3 [cs.RO] UPDATED)",
    "abstract": "When robots interact with humans in homes, roads, or factories the human's behavior often changes in response to the robot. Non-stationary humans are challenging for robot learners: actions the robot has learned to coordinate with the original human may fail after the human adapts to the robot. In this paper we introduce an algorithmic formalism that enables robots (i.e., ego agents) to co-adapt alongside dynamic humans (i.e., other agents) using only the robot's low-level states, actions, and rewards. A core challenge is that humans not only react to the robot's behavior, but the way in which humans react inevitably changes both over time and between users. To deal with this challenge, our insight is that -- instead of building an exact model of the human -- robots can learn and reason over high-level representations of the human's policy and policy dynamics. Applying this insight we develop RILI: Robustly Influencing Latent Intent. RILI first embeds low-level robot observations into ",
    "link": "http://arxiv.org/abs/2212.09586",
    "context": "Title: Learning Latent Representations to Co-Adapt to Humans. (arXiv:2212.09586v3 [cs.RO] UPDATED)\nAbstract: When robots interact with humans in homes, roads, or factories the human's behavior often changes in response to the robot. Non-stationary humans are challenging for robot learners: actions the robot has learned to coordinate with the original human may fail after the human adapts to the robot. In this paper we introduce an algorithmic formalism that enables robots (i.e., ego agents) to co-adapt alongside dynamic humans (i.e., other agents) using only the robot's low-level states, actions, and rewards. A core challenge is that humans not only react to the robot's behavior, but the way in which humans react inevitably changes both over time and between users. To deal with this challenge, our insight is that -- instead of building an exact model of the human -- robots can learn and reason over high-level representations of the human's policy and policy dynamics. Applying this insight we develop RILI: Robustly Influencing Latent Intent. RILI first embeds low-level robot observations into ",
    "path": "papers/22/12/2212.09586.json",
    "total_tokens": 951,
    "translated_title": "学习潜在表示以与人类共适应",
    "translated_abstract": "当机器人在家庭、道路或工厂中与人类互动时，人类的行为通常会因为机器人而改变。对于机器人学习者来说，非稳态的人类是一个挑战：机器人已经学会与原始人类协调一起执行的动作可能在人类适应机器人后失败。在本文中，我们提出了一个算法形式，使得机器人（即自我代理）能够与动态人类（即其他代理）共同适应，只利用机器人的低级状态、动作和奖励。一个核心挑战是，人类不仅会对机器人的行为做出反应，而且人类的反应方式随着时间和用户之间的变化而变化。为了应对这个挑战，我们的洞察力是，机器人不需要建立人类的精确模型，而是可以学习和推理人类策略和策略动态的高级表示。基于这个洞察，我们开发了RILI：稳健地影响潜在意图。RILI首先将低级机器人观察嵌入到高级表示中...",
    "tldr": "机器人学习者在与非稳态人类共同互动时面临挑战，本文通过学习和推理人类策略和策略动态的高级表示，提出了一种算法形式以实现机器人与动态人类共适应。"
}