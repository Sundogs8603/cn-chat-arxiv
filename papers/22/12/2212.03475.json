{
    "title": "PyGFI: Analyzing and Enhancing Robustness of Graph Neural Networks Against Hardware Errors. (arXiv:2212.03475v2 [cs.LG] UPDATED)",
    "abstract": "Graph neural networks (GNNs) have recently emerged as a promising learning paradigm in learning graph-structured data and have demonstrated wide success across various domains such as recommendation systems, social networks, and electronic design automation (EDA). Like other deep learning (DL) methods, GNNs are being deployed in sophisticated modern hardware systems, as well as dedicated accelerators. However, despite the popularity of GNNs and the recent efforts of bringing GNNs to hardware, the fault tolerance and resilience of GNNs have generally been overlooked. Inspired by the inherent algorithmic resilience of DL methods, this paper conducts, for the first time, a large-scale and empirical study of GNN resilience, aiming to understand the relationship between hardware faults and GNN accuracy. By developing a customized fault injection tool on top of PyTorch, we perform extensive fault injection experiments on various GNN models and application datasets. We observe that the error ",
    "link": "http://arxiv.org/abs/2212.03475",
    "context": "Title: PyGFI: Analyzing and Enhancing Robustness of Graph Neural Networks Against Hardware Errors. (arXiv:2212.03475v2 [cs.LG] UPDATED)\nAbstract: Graph neural networks (GNNs) have recently emerged as a promising learning paradigm in learning graph-structured data and have demonstrated wide success across various domains such as recommendation systems, social networks, and electronic design automation (EDA). Like other deep learning (DL) methods, GNNs are being deployed in sophisticated modern hardware systems, as well as dedicated accelerators. However, despite the popularity of GNNs and the recent efforts of bringing GNNs to hardware, the fault tolerance and resilience of GNNs have generally been overlooked. Inspired by the inherent algorithmic resilience of DL methods, this paper conducts, for the first time, a large-scale and empirical study of GNN resilience, aiming to understand the relationship between hardware faults and GNN accuracy. By developing a customized fault injection tool on top of PyTorch, we perform extensive fault injection experiments on various GNN models and application datasets. We observe that the error ",
    "path": "papers/22/12/2212.03475.json",
    "total_tokens": 1302,
    "translated_title": "PyGFI：分析和增强图神经网络对硬件错误的稳健性",
    "translated_abstract": "图神经网络（GNN）最近成为一种有前途的学习范式，用于学习图结构数据，并已在推荐系统、社交网络和电子设计自动化（EDA）等各个领域广泛成功。与其他深度学习（DL）方法一样，GNN被部署在先进的现代硬件系统以及专用加速器上。然而，尽管GNN的普及和将其引入硬件的最近努力，GNN的容错性和韧性通常被忽视。本文受DL方法内在的算法韧性启发，首次对GNN韧性进行了大规模和实证研究，旨在理解硬件故障与GNN准确性之间的关系。通过在PyTorch之上开发定制的故障注入工具，我们对各种GNN模型和应用数据集进行了广泛的故障注入实验。我们观察到，与传统基于图像的DL模型相比，GNN的容错能力显著较低，并且常见的硬件故障会显著降低GNN的准确性。基于我们的发现，我们提出了PyGFI，这是一种用于增强GNN对硬件错误鲁棒性的新框架。PyGFI利用故障注入在训练数据中生成合成故障，从而训练出更加鲁棒的GNN模型，可以容忍各种类型的硬件故障。在实际硬件上的实验结果表明，PyGFI可以有效提高GNN模型的准确性和鲁棒性，并可以轻松集成到现有的GNN训练流程中。",
    "tldr": "本文针对图神经网络对硬件错误的鲁棒性进行了研究，提出了PyGFI框架，利用故障注入生成合成故障来训练更加鲁棒的GNN模型，可以容忍各种类型的硬件故障，有效提高GNN模型的准确性和鲁棒性，并可以轻松集成到现有的GNN训练流程中。",
    "en_tdlr": "This paper investigates the resilience of graph neural networks against hardware errors and proposes PyGFI, a framework that uses fault injection to train more robust GNN models that can tolerate various types of hardware faults, effectively improving their accuracy and robustness."
}