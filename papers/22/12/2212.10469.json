{
    "title": "BMX: Boosting Natural Language Generation Metrics with Explainability",
    "abstract": "arXiv:2212.10469v2 Announce Type: replace  Abstract: State-of-the-art natural language generation evaluation metrics are based on black-box language models. Hence, recent works consider their explainability with the goals of better understandability for humans and better metric analysis, including failure cases. In contrast, our proposed method BMX: Boosting Natural Language Generation Metrics with explainability explicitly leverages explanations to boost the metrics' performance. In particular, we perceive feature importance explanations as word-level scores, which we convert, via power means, into a segment-level score. We then combine this segment-level score with the original metric to obtain a better metric. Our tests show improvements for multiple metrics across MT and summarization datasets. While improvements in machine translation are small, they are strong for summarization. Notably, BMX with the LIME explainer and preselected parameters achieves an average improvement of 0.0",
    "link": "https://arxiv.org/abs/2212.10469",
    "context": "Title: BMX: Boosting Natural Language Generation Metrics with Explainability\nAbstract: arXiv:2212.10469v2 Announce Type: replace  Abstract: State-of-the-art natural language generation evaluation metrics are based on black-box language models. Hence, recent works consider their explainability with the goals of better understandability for humans and better metric analysis, including failure cases. In contrast, our proposed method BMX: Boosting Natural Language Generation Metrics with explainability explicitly leverages explanations to boost the metrics' performance. In particular, we perceive feature importance explanations as word-level scores, which we convert, via power means, into a segment-level score. We then combine this segment-level score with the original metric to obtain a better metric. Our tests show improvements for multiple metrics across MT and summarization datasets. While improvements in machine translation are small, they are strong for summarization. Notably, BMX with the LIME explainer and preselected parameters achieves an average improvement of 0.0",
    "path": "papers/22/12/2212.10469.json",
    "total_tokens": 828,
    "translated_title": "BMX：使用可解释性提升自然语言生成度量",
    "translated_abstract": "最先进的自然语言生成评估度量基于黑盒语言模型。因此，最近的工作考虑了它们的可解释性，目标是更好地为人类理解和更好地度量分析，包括失败案例。相反，我们提出的方法BMX：使用可解释性提升自然语言生成度量明确利用解释来提升指标的性能。具体来说，我们将特征重要性解释视为单词级分数，通过幂均值将其转换为段落级分数。然后，我们将此段落级分数与原始度量结合以获得更好的度量。我们的测试显示，在多个机器翻译和摘要数据集上取得了改进。虽然机器翻译方面的改进很小，但在摘要方面效果显著。值得注意的是，使用LIME解释器和预选参数的BMX达到了平均0.0的改进。",
    "tldr": "提出的方法BMX利用解释来提升自然语言生成度量的性能，通过将特征重要性解释转化为段落级分数，并结合原始度量，取得了更好的评估结果。",
    "en_tdlr": "The proposed method BMX leverages explanations to enhance natural language generation metrics performance by converting feature importance explanations into segment-level scores and combining them with original metrics to achieve better evaluation results."
}