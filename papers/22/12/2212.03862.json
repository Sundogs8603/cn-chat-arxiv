{
    "title": "Teaching Matters: Investigating the Role of Supervision in Vision Transformers. (arXiv:2212.03862v2 [cs.CV] UPDATED)",
    "abstract": "Vision Transformers (ViTs) have gained significant popularity in recent years and have proliferated into many applications. However, their behavior under different learning paradigms is not well explored. We compare ViTs trained through different methods of supervision, and show that they learn a diverse range of behaviors in terms of their attention, representations, and downstream performance. We also discover ViT behaviors that are consistent across supervision, including the emergence of Offset Local Attention Heads. These are self-attention heads that attend to a token adjacent to the current token with a fixed directional offset, a phenomenon that to the best of our knowledge has not been highlighted in any prior work. Our analysis shows that ViTs are highly flexible and learn to process local and global information in different orders depending on their training method. We find that contrastive self-supervised methods learn features that are competitive with explicitly supervise",
    "link": "http://arxiv.org/abs/2212.03862",
    "context": "Title: Teaching Matters: Investigating the Role of Supervision in Vision Transformers. (arXiv:2212.03862v2 [cs.CV] UPDATED)\nAbstract: Vision Transformers (ViTs) have gained significant popularity in recent years and have proliferated into many applications. However, their behavior under different learning paradigms is not well explored. We compare ViTs trained through different methods of supervision, and show that they learn a diverse range of behaviors in terms of their attention, representations, and downstream performance. We also discover ViT behaviors that are consistent across supervision, including the emergence of Offset Local Attention Heads. These are self-attention heads that attend to a token adjacent to the current token with a fixed directional offset, a phenomenon that to the best of our knowledge has not been highlighted in any prior work. Our analysis shows that ViTs are highly flexible and learn to process local and global information in different orders depending on their training method. We find that contrastive self-supervised methods learn features that are competitive with explicitly supervise",
    "path": "papers/22/12/2212.03862.json",
    "total_tokens": 1017,
    "translated_title": "教育很重要：探究监督对Vision Transformers中的作用。",
    "translated_abstract": "Vision Transformers (ViTs)在近年中广受欢迎，并在许多应用中得到了推广。然而，它们在不同的学习范式下的行为尚未得到很好的研究。我们比较了通过不同监督方法训练的ViTs，并展示了它们在注意力、表示和下游性能方面学习了各种不同的行为。我们还发现了ViT行为在不同训练模式下的一致性，包括新出现的Offset Local Attention Heads，这是一种我们之前没有意识到的自注意力头类型。我们的分析表明，ViTs非常灵活，通过不同的训练方法学习处理本地和全局信息。我们发现，对比自监督方法学习的特征与显式监督方法学习的特征具有竞争力，且具有更好的可解释性。总的来说，我们的研究揭示了监督方式对于ViT学习行为的影响，发现了一种新的注意力头类型，并且证明了对于Vision Transformers而言，自监督学习是一种非常有效的学习范式。",
    "tldr": "本研究比较了不同的监督方法对于Vision Transformers的训练效果，并发现了一种新的注意力头类型。并证明了对于Vision Transformers而言，自监督学习是一种非常有效的学习范式。"
}