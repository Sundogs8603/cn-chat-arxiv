{
    "title": "Differentially-Private Data Synthetisation for Efficient Re-Identification Risk Control. (arXiv:2212.00484v2 [cs.LG] UPDATED)",
    "abstract": "Protecting user data privacy can be achieved via many methods, from statistical transformations to generative models. However, all of them have critical drawbacks. For example, creating a transformed data set using traditional techniques is highly time-consuming. Also, recent deep learning-based solutions require significant computational resources in addition to long training phases, and differentially private-based solutions may undermine data utility. In this paper, we propose $\\epsilon$-PrivateSMOTE, a technique designed for safeguarding against re-identification and linkage attacks, particularly addressing cases with a high re-identification risk. Our proposal combines synthetic data generation via noise-induced interpolation to obfuscate high-risk cases while maximising the data utility of the original data. Compared to multiple traditional and state-of-the-art privacy-preservation methods on 17 data sets, $\\epsilon$-PrivateSMOTE achieves competitive results in privacy risk and b",
    "link": "http://arxiv.org/abs/2212.00484",
    "context": "Title: Differentially-Private Data Synthetisation for Efficient Re-Identification Risk Control. (arXiv:2212.00484v2 [cs.LG] UPDATED)\nAbstract: Protecting user data privacy can be achieved via many methods, from statistical transformations to generative models. However, all of them have critical drawbacks. For example, creating a transformed data set using traditional techniques is highly time-consuming. Also, recent deep learning-based solutions require significant computational resources in addition to long training phases, and differentially private-based solutions may undermine data utility. In this paper, we propose $\\epsilon$-PrivateSMOTE, a technique designed for safeguarding against re-identification and linkage attacks, particularly addressing cases with a high re-identification risk. Our proposal combines synthetic data generation via noise-induced interpolation to obfuscate high-risk cases while maximising the data utility of the original data. Compared to multiple traditional and state-of-the-art privacy-preservation methods on 17 data sets, $\\epsilon$-PrivateSMOTE achieves competitive results in privacy risk and b",
    "path": "papers/22/12/2212.00484.json",
    "total_tokens": 913,
    "translated_title": "高效控制重新识别风险的差分隐私数据合成",
    "translated_abstract": "保护用户数据隐私可以通过多种方法实现，从统计转换到生成模型。然而，所有这些方法都存在重要的缺陷。例如，使用传统技术创建转换数据集非常耗时。此外，最近基于深度学习的解决方案除了长时间的训练阶段外，还需要大量的计算资源，而差分隐私解决方案可能会削弱数据效用。在本文中，我们提议了一种名为ε-PrivateSMOTE的技术，用于保护免受重新识别和链接攻击的风险，并特别解决高重新识别风险的情况。我们的提议通过噪声引入插值的合成数据生成，以模糊高风险案例，同时最大限度地保持原始数据的数据效用。与17个数据集上的多个传统和最新隐私保护方法相比，ε-PrivateSMOTE在隐私风险和数据效用方面取得了竞争性的结果。",
    "tldr": "本文提出了一种名为ε-PrivateSMOTE的技术，通过噪声引入插值的合成数据生成，以达到保护免受重新识别和链接攻击的风险的目的，并在同时最大限度地保持数据效用的情况下取得了竞争性的结果。",
    "en_tdlr": "This paper proposes a technique called ε-PrivateSMOTE, which uses noise-induced interpolation for synthetic data generation to protect against re-identification and linkage attacks while maximizing data utility, achieving competitive results in privacy risk and data utility compared to traditional and state-of-the-art privacy-preservation methods."
}