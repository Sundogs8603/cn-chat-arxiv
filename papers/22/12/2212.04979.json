{
    "title": "VideoCoCa: Video-Text Modeling with Zero-Shot Transfer from Contrastive Captioners. (arXiv:2212.04979v3 [cs.CV] UPDATED)",
    "abstract": "We explore an efficient approach to establish a foundational video-text model. We present VideoCoCa that maximally reuses a pretrained image-text contrastive captioner (CoCa) model and adapt it to video-text tasks with minimal extra training. While previous works adapt image-text models with various cross-frame fusion modules, we find that the generative attentional pooling and contrastive attentional pooling layers in CoCa are instantly adaptable to flattened frame embeddings, yielding state-of-the-art results on zero-shot video classification and zero-shot text-to-video retrieval. Furthermore, we explore lightweight finetuning on top of VideoCoCa, and achieve strong results on video question-answering and video captioning.",
    "link": "http://arxiv.org/abs/2212.04979",
    "context": "Title: VideoCoCa: Video-Text Modeling with Zero-Shot Transfer from Contrastive Captioners. (arXiv:2212.04979v3 [cs.CV] UPDATED)\nAbstract: We explore an efficient approach to establish a foundational video-text model. We present VideoCoCa that maximally reuses a pretrained image-text contrastive captioner (CoCa) model and adapt it to video-text tasks with minimal extra training. While previous works adapt image-text models with various cross-frame fusion modules, we find that the generative attentional pooling and contrastive attentional pooling layers in CoCa are instantly adaptable to flattened frame embeddings, yielding state-of-the-art results on zero-shot video classification and zero-shot text-to-video retrieval. Furthermore, we explore lightweight finetuning on top of VideoCoCa, and achieve strong results on video question-answering and video captioning.",
    "path": "papers/22/12/2212.04979.json",
    "total_tokens": 870,
    "translated_title": "VideoCoCa: 从对比式字幕生成器实现零样本跨域视频文本建模",
    "translated_abstract": "本文探索了一种高效的方法来建立一个基础的视频-文本模型。我们提出了VideoCoCa，它最大限度地重用了预训练的图像-文本对比式字幕生成器（CoCa）模型，并通过最小的额外训练来适应视频-文本任务。我们发现，在以往的工作中，通过不同的帧间融合模块来适应图像-文本模型，而CoCa中的生成式注意力池化和对比式注意力池化层可以立即适应扁平化的帧嵌入，从而在零样本视频分类和零样本文本到视频检索方面取得了最先进的结果。此外，我们探索了在VideoCoCa之上进行轻微微调的方法，并在视频问答和视频字幕生成方面取得了强大的结果。",
    "tldr": "本文提出了一种名为VideoCoCa的基于对比式字幕生成技术的零样本视频文本建模方法，能够在最小的额外训练下，取得最先进的零样本视频分类和零样本文本到视频检索结果，并在轻微微调情况下也能取得强大的结果。",
    "en_tdlr": "The paper proposes a zero-shot video-text modeling method, named VideoCoCa, based on contrastive captioner. By adapting the model to video-text tasks with minimal extra training, VideoCoCa achieves state-of-the-art results on zero-shot video classification and zero-shot text-to-video retrieval. The paper also explores light finetuning on VideoCoCa and obtains strong results on video question-answering and video captioning."
}