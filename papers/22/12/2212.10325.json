{
    "title": "SeqDiffuSeq: Text Diffusion Model with Encoder-Decoder Transformers for Sequence-to-Sequence Generation. (arXiv:2212.10325v2 [cs.CL] UPDATED)",
    "abstract": "Diffusion model, a new generative modelling paradigm, has achieved great success in image, audio, and video generation. However, considering the discrete categorical nature of text, it is not trivial to extend continuous diffusion models to natural language, and text diffusion models are less studied. Sequence-to-sequence text generation is one of the essential natural language processing topics. In this work, we apply diffusion models to approach sequence-to-sequence text generation, and explore whether the superiority generation performance of diffusion model can transfer to natural language domain. We propose SeqDiffuSeq, a text diffusion model for sequence-to-sequence generation. SeqDiffuSeq uses an encoder-decoder Transformers architecture to model denoising function. In order to improve generation quality, SeqDiffuSeq combines the self-conditioning technique and a newly proposed adaptive noise schedule technique. The adaptive noise schedule has the difficulty of denoising evenly ",
    "link": "http://arxiv.org/abs/2212.10325",
    "context": "Title: SeqDiffuSeq: Text Diffusion Model with Encoder-Decoder Transformers for Sequence-to-Sequence Generation. (arXiv:2212.10325v2 [cs.CL] UPDATED)\nAbstract: Diffusion model, a new generative modelling paradigm, has achieved great success in image, audio, and video generation. However, considering the discrete categorical nature of text, it is not trivial to extend continuous diffusion models to natural language, and text diffusion models are less studied. Sequence-to-sequence text generation is one of the essential natural language processing topics. In this work, we apply diffusion models to approach sequence-to-sequence text generation, and explore whether the superiority generation performance of diffusion model can transfer to natural language domain. We propose SeqDiffuSeq, a text diffusion model for sequence-to-sequence generation. SeqDiffuSeq uses an encoder-decoder Transformers architecture to model denoising function. In order to improve generation quality, SeqDiffuSeq combines the self-conditioning technique and a newly proposed adaptive noise schedule technique. The adaptive noise schedule has the difficulty of denoising evenly ",
    "path": "papers/22/12/2212.10325.json",
    "total_tokens": 910,
    "translated_title": "SeqDiffuSeq: 一种使用编码器-解码器Transformer的文本扩散模型用于序列生成",
    "translated_abstract": "扩散模型是一种新的生成建模范式，在图像、音频和视频生成方面取得了巨大成功。然而，考虑到文本的离散分类性质，将连续扩散模型扩展到自然语言并不是微不足道的，而且文本扩散模型研究较少。序列生成是自然语言处理中至关重要的话题之一。在本文中，我们将扩散模型应用于序列生成，探索扩散模型的优越生成性能能否转移到自然语言领域。我们提出SeqDiffuSeq，一种用于序列生成的文本扩散模型。SeqDiffuSeq使用编码器-解码器Transformer架构来建模去噪函数。为了提高生成质量，SeqDiffuSeq结合了自我调节技术和一个新提出的自适应噪声调度技术。自适应噪声调度具有均匀去噪的困难",
    "tldr": "本文提出了一种名为SeqDiffuSeq的文本扩散模型，用于序列生成，采用了编码器-解码器Transformer架构和自适应噪声调度技术，旨在探索扩散模型在自然语言生成方面的性能表现。",
    "en_tdlr": "This paper proposes a text diffusion model called SeqDiffuSeq for sequence-to-sequence generation, which uses an encoder-decoder transformer architecture and an adaptive noise schedule technique. The aim is to explore the performance of diffusion models in natural language generation."
}