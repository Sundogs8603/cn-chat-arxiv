{
    "title": "Multiarmed Bandits Problem Under the Mean-Variance Setting. (arXiv:2212.09192v3 [math.OC] UPDATED)",
    "abstract": "The classical multi-armed bandit (MAB) problem involves a learner and a collection of K independent arms, each with its own ex ante unknown independent reward distribution. At each one of a finite number of rounds, the learner selects one arm and receives new information. The learner often faces an exploration-exploitation dilemma: exploiting the current information by playing the arm with the highest estimated reward versus exploring all arms to gather more reward information. The design objective aims to maximize the expected cumulative reward over all rounds. However, such an objective does not account for a risk-reward tradeoff, which is often a fundamental precept in many areas of applications, most notably in finance and economics. In this paper, we build upon Sani et al. (2012) and extend the classical MAB problem to a mean-variance setting. Specifically, we relax the assumptions of independent arms and bounded rewards made in Sani et al. (2012) by considering sub-Gaussian arms.",
    "link": "http://arxiv.org/abs/2212.09192",
    "context": "Title: Multiarmed Bandits Problem Under the Mean-Variance Setting. (arXiv:2212.09192v3 [math.OC] UPDATED)\nAbstract: The classical multi-armed bandit (MAB) problem involves a learner and a collection of K independent arms, each with its own ex ante unknown independent reward distribution. At each one of a finite number of rounds, the learner selects one arm and receives new information. The learner often faces an exploration-exploitation dilemma: exploiting the current information by playing the arm with the highest estimated reward versus exploring all arms to gather more reward information. The design objective aims to maximize the expected cumulative reward over all rounds. However, such an objective does not account for a risk-reward tradeoff, which is often a fundamental precept in many areas of applications, most notably in finance and economics. In this paper, we build upon Sani et al. (2012) and extend the classical MAB problem to a mean-variance setting. Specifically, we relax the assumptions of independent arms and bounded rewards made in Sani et al. (2012) by considering sub-Gaussian arms.",
    "path": "papers/22/12/2212.09192.json",
    "total_tokens": 919,
    "translated_title": "均值-方差设置下的多臂赌博机问题",
    "translated_abstract": "经典的多臂赌博机（MAB）问题涉及一个学习者和一个包含K个独立臂的集合，每个臂都有自己的事前未知独立奖励分布。在有限次选择中的每一次，学习者选择一个臂并接收新信息。学习者经常面临一个勘探-开发困境：通过玩估计奖励最高的臂来利用当前信息，还是探索所有臂以收集更多奖励信息。设计目标旨在最大化所有回合中的期望累积奖励。然而，这样的目标并不考虑风险-回报权衡，而这在许多应用领域，特别是金融和经济领域，常常是一项基本原则。在本文中，我们在Sani等人（2012）的基础上，将经典的MAB问题扩展到均值-方差设置。具体而言，我们通过考虑亚高斯臂放松了Sani等人（2012）做出的独立臂和有界奖励的假设。",
    "tldr": "本文将经典的多臂赌博机问题扩展到均值-方差设置，并通过考虑亚高斯臂放松了先前假设，解决了风险-回报权衡的问题。",
    "en_tdlr": "This paper extends the classical multi-armed bandit (MAB) problem to the mean-variance setting by relaxing previous assumptions and solving the risk-reward tradeoff."
}