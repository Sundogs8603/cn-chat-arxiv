{
    "title": "In and Out-of-Domain Text Adversarial Robustness via Label Smoothing. (arXiv:2212.10258v2 [cs.CL] UPDATED)",
    "abstract": "Recently it has been shown that state-of-the-art NLP models are vulnerable to adversarial attacks, where the predictions of a model can be drastically altered by slight modifications to the input (such as synonym substitutions). While several defense techniques have been proposed, and adapted, to the discrete nature of text adversarial attacks, the benefits of general-purpose regularization methods such as label smoothing for language models, have not been studied. In this paper, we study the adversarial robustness provided by various label smoothing strategies in foundational models for diverse NLP tasks in both in-domain and out-of-domain settings. Our experiments show that label smoothing significantly improves adversarial robustness in pre-trained models like BERT, against various popular attacks. We also analyze the relationship between prediction confidence and robustness, showing that label smoothing reduces over-confident errors on adversarial examples.",
    "link": "http://arxiv.org/abs/2212.10258",
    "context": "Title: In and Out-of-Domain Text Adversarial Robustness via Label Smoothing. (arXiv:2212.10258v2 [cs.CL] UPDATED)\nAbstract: Recently it has been shown that state-of-the-art NLP models are vulnerable to adversarial attacks, where the predictions of a model can be drastically altered by slight modifications to the input (such as synonym substitutions). While several defense techniques have been proposed, and adapted, to the discrete nature of text adversarial attacks, the benefits of general-purpose regularization methods such as label smoothing for language models, have not been studied. In this paper, we study the adversarial robustness provided by various label smoothing strategies in foundational models for diverse NLP tasks in both in-domain and out-of-domain settings. Our experiments show that label smoothing significantly improves adversarial robustness in pre-trained models like BERT, against various popular attacks. We also analyze the relationship between prediction confidence and robustness, showing that label smoothing reduces over-confident errors on adversarial examples.",
    "path": "papers/22/12/2212.10258.json",
    "total_tokens": 946,
    "translated_title": "利用标签平滑实现领域内外文本对抗鲁棒性",
    "translated_abstract": "最近研究表明，最新的自然语言处理模型容易受到对抗性攻击，即对输入进行细微修改（如同义词替换）会极大地改变模型的预测结果。虽然已经提出了几种针对文本对抗性攻击的防御技术，并将其调整至离散性质的文本数据上，但是综合性的规则化方法，如语言模型的标签平滑对于文本模型的鲁棒性提供的效果还没有被研究过。在本文中，我们研究了各种标签平滑策略在领域内和领域外的基础模型中对多样化自然语言处理任务的对抗鲁棒性。我们的实验证明，标签平滑显著提高了预训练模型（如BERT）在各种流行攻击中的对抗鲁棒性。我们还分析了预测可信度与鲁棒性之间的关系，并显示标签平滑减少了在对抗样本上出现的过度自信错误。",
    "tldr": "本文研究了标签平滑策略在不同领域的自然语言处理任务中对对抗鲁棒性的影响。实验证明，标签平滑显著提高了预训练模型的鲁棒性，并减少了在对抗样本上出现的过度自信错误。",
    "en_tdlr": "This paper investigates the impact of label smoothing strategies on adversarial robustness in various domains of natural language processing tasks. The experiments show that label smoothing significantly improves the robustness of pre-trained models and reduces over-confident errors on adversarial examples."
}