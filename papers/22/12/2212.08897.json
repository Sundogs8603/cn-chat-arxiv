{
    "title": "PolQA: Polish Question Answering Dataset",
    "abstract": "arXiv:2212.08897v2 Announce Type: replace  Abstract: Recently proposed systems for open-domain question answering (OpenQA) require large amounts of training data to achieve state-of-the-art performance. However, data annotation is known to be time-consuming and therefore expensive to acquire. As a result, the appropriate datasets are available only for a handful of languages (mainly English and Chinese). In this work, we introduce and publicly release PolQA, the first Polish dataset for OpenQA. It consists of 7,000 questions, 87,525 manually labeled evidence passages, and a corpus of over 7,097,322 candidate passages. Each question is classified according to its formulation, type, as well as entity type of the answer. This resource allows us to evaluate the impact of different annotation choices on the performance of the QA system and propose an efficient annotation strategy that increases the passage retrieval accuracy@10 by 10.55 p.p. while reducing the annotation cost by 82%.",
    "link": "https://arxiv.org/abs/2212.08897",
    "context": "Title: PolQA: Polish Question Answering Dataset\nAbstract: arXiv:2212.08897v2 Announce Type: replace  Abstract: Recently proposed systems for open-domain question answering (OpenQA) require large amounts of training data to achieve state-of-the-art performance. However, data annotation is known to be time-consuming and therefore expensive to acquire. As a result, the appropriate datasets are available only for a handful of languages (mainly English and Chinese). In this work, we introduce and publicly release PolQA, the first Polish dataset for OpenQA. It consists of 7,000 questions, 87,525 manually labeled evidence passages, and a corpus of over 7,097,322 candidate passages. Each question is classified according to its formulation, type, as well as entity type of the answer. This resource allows us to evaluate the impact of different annotation choices on the performance of the QA system and propose an efficient annotation strategy that increases the passage retrieval accuracy@10 by 10.55 p.p. while reducing the annotation cost by 82%.",
    "path": "papers/22/12/2212.08897.json",
    "total_tokens": 905,
    "translated_title": "PolQA：波兰问答数据集",
    "translated_abstract": "最近提出的面向开放域问答（OpenQA）系统需要大量的训练数据才能达到最先进的性能。然而，数据注释被认为是耗时且昂贵的，因此获取起来很困难。因此，适用于语言少数（主要是英语和汉语）的数据集仅有少数。在这项工作中，我们介绍和公开发布了波兰问答（PolQA）数据集，这是用于OpenQA的第一个波兰语数据集。它包括7,000个问题，87,525个手动标记的证据段落，以及超过7,097,322个候选段落的语料库。每个问题都根据其公式、类型以及答案的实体类型进行了分类。这一资源允许我们评估不同注释选择对QA系统性能的影响，并提出一种有效的注释策略，将段落的检索准确度@10提高了10.55个百分点，同时将注释成本降低了82%。",
    "tldr": "波兰问答数据集（PolQA）是用于OpenQA的第一个波兰语数据集，包括7,000个问题和87,525个手动标记的证据段落，在QA系统性能方面提出了有效的注释策略，以提高段落的检索准确度@10并降低注释成本。",
    "en_tdlr": "PolQA is the first Polish dataset for OpenQA, containing 7,000 questions and 87,525 manually labeled evidence passages. It proposes an efficient annotation strategy to improve passage retrieval accuracy@10 and reduce annotation cost in QA system performance."
}