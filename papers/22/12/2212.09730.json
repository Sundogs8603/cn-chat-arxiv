{
    "title": "Speaking Style Conversion in the Waveform Domain Using Discrete Self-Supervised Units. (arXiv:2212.09730v2 [cs.SD] UPDATED)",
    "abstract": "We introduce DISSC, a novel, lightweight method that converts the rhythm, pitch contour and timbre of a recording to a target speaker in a textless manner. Unlike DISSC, most voice conversion (VC) methods focus primarily on timbre, and ignore people's unique speaking style (prosody). The proposed approach uses a pretrained, self-supervised model for encoding speech to discrete units, which makes it simple, effective, and fast to train. All conversion modules are only trained on reconstruction like tasks, thus suitable for any-to-many VC with no paired data. We introduce a suite of quantitative and qualitative evaluation metrics for this setup, and empirically demonstrate that DISSC significantly outperforms the evaluated baselines. Code and samples are available at https://pages.cs.huji.ac.il/adiyoss-lab/dissc/.",
    "link": "http://arxiv.org/abs/2212.09730",
    "context": "Title: Speaking Style Conversion in the Waveform Domain Using Discrete Self-Supervised Units. (arXiv:2212.09730v2 [cs.SD] UPDATED)\nAbstract: We introduce DISSC, a novel, lightweight method that converts the rhythm, pitch contour and timbre of a recording to a target speaker in a textless manner. Unlike DISSC, most voice conversion (VC) methods focus primarily on timbre, and ignore people's unique speaking style (prosody). The proposed approach uses a pretrained, self-supervised model for encoding speech to discrete units, which makes it simple, effective, and fast to train. All conversion modules are only trained on reconstruction like tasks, thus suitable for any-to-many VC with no paired data. We introduce a suite of quantitative and qualitative evaluation metrics for this setup, and empirically demonstrate that DISSC significantly outperforms the evaluated baselines. Code and samples are available at https://pages.cs.huji.ac.il/adiyoss-lab/dissc/.",
    "path": "papers/22/12/2212.09730.json",
    "total_tokens": 948,
    "translated_title": "在波形域中使用离散自监督单元进行语音风格转换",
    "translated_abstract": "我们介绍了一种名为DISSC的新颖、轻量级的方法，它可以以无需文本的方式将录音的节奏、音高轮廓和音色转换为目标说话者的风格。与DISSC不同，大多数语音转换（VC）方法主要关注音色，并忽略人们独特的说话风格（韵律）。所提出的方法使用预训练的自监督模型将语音编码为离散单元，使得训练简单、有效且快速。所有的转换模块仅在重建任务上进行训练，因此适用于无配对数据的多对多语音转换。我们介绍了一套定量和定性评估指标，并通过实验证明DISSC在这个设置下明显优于评估基线。代码和样例可在https://pages.cs.huji.ac.il/adiyoss-lab/dissc/ 上找到。",
    "tldr": "DISSC是一种新颖、轻量级的语音风格转换方法，它可以以无需文本的方式将录音的节奏、音高轮廓和音色转换为目标说话者的风格。该方法使用自监督模型编码语音为离散单元，具有简单、有效且快速的训练过程，适用于无配对数据的多对多语音转换。",
    "en_tdlr": "DISSC is a novel and lightweight method for speech style conversion, which can convert the rhythm, pitch contour, and timbre of a recording to the target speaker's style in a textless manner. It uses a self-supervised model to encode speech into discrete units, allowing for simple, effective, and fast training. DISSC outperforms the evaluated baselines in both quantitative and qualitative evaluations for any-to-many voice conversion without paired data."
}