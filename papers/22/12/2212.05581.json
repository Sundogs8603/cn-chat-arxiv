{
    "title": "Efficient Relation-aware Neighborhood Aggregation in Graph Neural Networks via Tensor Decomposition. (arXiv:2212.05581v3 [cs.LG] UPDATED)",
    "abstract": "Many Graph Neural Networks (GNNs) are proposed for Knowledge Graph Embedding (KGE). However, lots of these methods neglect the importance of the information of relations and combine it with the information of entities inefficiently, leading to low expressiveness. To address this issue, we introduce a general knowledge graph encoder incorporating tensor decomposition in the aggregation function of Relational Graph Convolutional Network (R-GCN). In our model, neighbor entities are transformed using projection matrices of a low-rank tensor which are defined by relation types to benefit from multi-task learning and produce expressive relation-aware representations. Besides, we propose a low-rank estimation of the core tensor using CP decomposition to compress and regularize our model. We use a training method inspired by contrastive learning, which relieves the training limitation of the 1-N method on huge graphs. We achieve favorably competitive results on FB15k-237 and WN18RR with embedd",
    "link": "http://arxiv.org/abs/2212.05581",
    "context": "Title: Efficient Relation-aware Neighborhood Aggregation in Graph Neural Networks via Tensor Decomposition. (arXiv:2212.05581v3 [cs.LG] UPDATED)\nAbstract: Many Graph Neural Networks (GNNs) are proposed for Knowledge Graph Embedding (KGE). However, lots of these methods neglect the importance of the information of relations and combine it with the information of entities inefficiently, leading to low expressiveness. To address this issue, we introduce a general knowledge graph encoder incorporating tensor decomposition in the aggregation function of Relational Graph Convolutional Network (R-GCN). In our model, neighbor entities are transformed using projection matrices of a low-rank tensor which are defined by relation types to benefit from multi-task learning and produce expressive relation-aware representations. Besides, we propose a low-rank estimation of the core tensor using CP decomposition to compress and regularize our model. We use a training method inspired by contrastive learning, which relieves the training limitation of the 1-N method on huge graphs. We achieve favorably competitive results on FB15k-237 and WN18RR with embedd",
    "path": "papers/22/12/2212.05581.json",
    "total_tokens": 1003,
    "translated_title": "基于张量分解的图神经网络中高效的关系感知邻域聚合",
    "translated_abstract": "许多面向知识图谱嵌入的图神经网络(GNN)被提出。然而，大量这种方法忽略了关系信息的重要性，将其与实体信息组合使用效率低下，导致表达能力低。为了解决这个问题，我们在关系图卷积网络(R-GCN)的聚合函数中引入了张量分解，提出了一个通用的知识图编码器。在我们的模型中，使用由关系类型定义的低秩张量的投影矩阵，将邻居实体进行转换，以获得多任务学习的好处，并生成具有表达能力的关系感知表示。此外，我们还提出使用CP分解来估计核心张量的低秩估计，从而压缩和规范我们的模型。我们采用了对比学习的训练方法，以缓解基于1-N方法在大型图上的训练限制。我们使用低维度嵌入，在FB15k-237和WN18RR数据集上取得了有竞争力的结果，说明了我们的模型的效率和有效性。",
    "tldr": "本文提出了一个张量分解的知识图编码器，将邻居实体使用由关系类型定义的低秩张量的投影矩阵进行转换，从而产生具有表达能力和关系感知性的表示，并使用对比学习的方法进行训练，从而提高了基于图的神经网络模型的效率和表现。"
}