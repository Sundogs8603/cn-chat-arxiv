{
    "title": "Differentially Private Adaptive Optimization with Delayed Preconditioners. (arXiv:2212.00309v2 [cs.LG] UPDATED)",
    "abstract": "Privacy noise may negate the benefits of using adaptive optimizers in differentially private model training. Prior works typically address this issue by using auxiliary information (e.g., public data) to boost the effectiveness of adaptive optimization. In this work, we explore techniques to estimate and efficiently adapt to gradient geometry in private adaptive optimization without auxiliary data. Motivated by the observation that adaptive methods can tolerate stale preconditioners, we propose differentially private adaptive training with delayed preconditioners (DP^2), a simple method that constructs delayed but less noisy preconditioners to better realize the benefits of adaptivity. Theoretically, we provide convergence guarantees for our method for both convex and non-convex problems, and analyze trade-offs between delay and privacy noise reduction. Empirically, we explore DP^2 across several real-world datasets, demonstrating that it can improve convergence speed by as much as 4x ",
    "link": "http://arxiv.org/abs/2212.00309",
    "context": "Title: Differentially Private Adaptive Optimization with Delayed Preconditioners. (arXiv:2212.00309v2 [cs.LG] UPDATED)\nAbstract: Privacy noise may negate the benefits of using adaptive optimizers in differentially private model training. Prior works typically address this issue by using auxiliary information (e.g., public data) to boost the effectiveness of adaptive optimization. In this work, we explore techniques to estimate and efficiently adapt to gradient geometry in private adaptive optimization without auxiliary data. Motivated by the observation that adaptive methods can tolerate stale preconditioners, we propose differentially private adaptive training with delayed preconditioners (DP^2), a simple method that constructs delayed but less noisy preconditioners to better realize the benefits of adaptivity. Theoretically, we provide convergence guarantees for our method for both convex and non-convex problems, and analyze trade-offs between delay and privacy noise reduction. Empirically, we explore DP^2 across several real-world datasets, demonstrating that it can improve convergence speed by as much as 4x ",
    "path": "papers/22/12/2212.00309.json",
    "total_tokens": 989,
    "translated_title": "延迟预条件器的差分隐私自适应优化",
    "translated_abstract": "差分隐私的噪音可能会抵消在差分隐私模型训练中使用自适应优化器的好处。先前的研究通常通过使用辅助信息（例如，公共数据）来增强自适应优化的效果来解决这个问题。在本文中，我们探索了在没有辅助数据的情况下，评估和有效适应私有自适应优化的梯度几何技术。受到自适应方法可以容忍陈旧预条件器的观察启发，我们提出了延迟预条件差分隐私自适应训练（DP ^ 2），这是一种简单的方法，构建具有延迟但噪音较小的预条件器，以更好地实现自适应性的好处。理论上，我们为我们的方法提供了针对凸和非凸问题的收敛保证，并分析了延迟和隐私噪声减少之间的权衡。在实证方面，我们在几个实际数据集上探索了 DP ^ 2，证明它可以将收敛速度提高多达4倍。",
    "tldr": "本篇论文提出了一种称为DP^2的方法，用于解决差分隐私自适应优化中的隐私噪声问题。该方法通过使用具有延迟但噪声较小的预条件器来实现自适应性的好处，并在凸和非凸问题上提供收敛保证，经实验证明可以将收敛速度提高多达4倍。",
    "en_tdlr": "This paper proposes a method called DP^2 to address the privacy noise issue in differentially private adaptive optimization. It uses delayed preconditioners with less noise to realize the benefits of adaptivity without auxiliary data, and guarantees convergence for convex and non-convex problems. Empirical results show that it can improve convergence speed by up to 4x."
}