{
    "title": "Beyond Triplet: Leveraging the Most Data for Multimodal Machine Translation. (arXiv:2212.10313v2 [cs.CL] UPDATED)",
    "abstract": "Multimodal machine translation (MMT) aims to improve translation quality by incorporating information from other modalities, such as vision. Previous MMT systems mainly focus on better access and use of visual information and tend to validate their methods on image-related datasets. These studies face two challenges. First, they can only utilize triple data (bilingual texts with images), which is scarce; second, current benchmarks are relatively restricted and do not correspond to realistic scenarios. Therefore, this paper correspondingly establishes new methods and new datasets for MMT. First, we propose a framework 2/3-Triplet with two new approaches to enhance MMT by utilizing large-scale non-triple data: monolingual image-text data and parallel text-only data. Second, we construct an English-Chinese {e}-commercial {m}ulti{m}odal {t}ranslation dataset (including training and testing), named EMMT, where its test set is carefully selected as some words are ambiguous and shall be trans",
    "link": "http://arxiv.org/abs/2212.10313",
    "context": "Title: Beyond Triplet: Leveraging the Most Data for Multimodal Machine Translation. (arXiv:2212.10313v2 [cs.CL] UPDATED)\nAbstract: Multimodal machine translation (MMT) aims to improve translation quality by incorporating information from other modalities, such as vision. Previous MMT systems mainly focus on better access and use of visual information and tend to validate their methods on image-related datasets. These studies face two challenges. First, they can only utilize triple data (bilingual texts with images), which is scarce; second, current benchmarks are relatively restricted and do not correspond to realistic scenarios. Therefore, this paper correspondingly establishes new methods and new datasets for MMT. First, we propose a framework 2/3-Triplet with two new approaches to enhance MMT by utilizing large-scale non-triple data: monolingual image-text data and parallel text-only data. Second, we construct an English-Chinese {e}-commercial {m}ulti{m}odal {t}ranslation dataset (including training and testing), named EMMT, where its test set is carefully selected as some words are ambiguous and shall be trans",
    "path": "papers/22/12/2212.10313.json",
    "total_tokens": 948,
    "translated_title": "超越三元组：利用最多的数据进行多模态机器翻译",
    "translated_abstract": "多模态机器翻译旨在通过引入其他模态（如视觉）的信息来提高翻译质量。以往的多模态机器翻译系统主要关注更好地获取和利用视觉信息，并倾向于验证其方法在与图像相关的数据集上。这些研究面临两个挑战。首先，它们只能利用三元组数据（带有图像的双语文本），这种数据稀缺；其次，当前的基准相对受限，不符合真实场景。因此，本文相应地建立了多模态机器翻译的新方法和新数据集。首先，我们提出了一个名为2/3-Triplet的框架，并采用两种新方法来增强多模态机器翻译，即利用大规模非三元组数据：单语图像文本数据和平行文本数据。其次，我们构建了一个英汉电子商务多模态翻译数据集（包括训练和测试），命名为EMMT，其中测试集的选择经过精心考虑，因为其中有些词是模糊的，需要进行翻译。",
    "tldr": "本论文提出了一个新的多模态机器翻译方法，利用大规模非三元组数据来增强翻译质量，并构建了一个新的英汉电子商务多模态翻译数据集EMMT。",
    "en_tdlr": "This paper proposes a new approach for multimodal machine translation that utilizes large-scale non-triplet data to enhance translation quality, and also introduces a new English-Chinese e-commerce multimodal translation dataset called EMMT."
}