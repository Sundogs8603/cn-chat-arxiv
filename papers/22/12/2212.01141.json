{
    "title": "MHCCL: Masked Hierarchical Cluster-Wise Contrastive Learning for Multivariate Time Series. (arXiv:2212.01141v3 [cs.LG] UPDATED)",
    "abstract": "Learning semantic-rich representations from raw unlabeled time series data is critical for downstream tasks such as classification and forecasting. Contrastive learning has recently shown its promising representation learning capability in the absence of expert annotations. However, existing contrastive approaches generally treat each instance independently, which leads to false negative pairs that share the same semantics. To tackle this problem, we propose MHCCL, a Masked Hierarchical Cluster-wise Contrastive Learning model, which exploits semantic information obtained from the hierarchical structure consisting of multiple latent partitions for multivariate time series. Motivated by the observation that fine-grained clustering preserves higher purity while coarse-grained one reflects higher-level semantics, we propose a novel downward masking strategy to filter out fake negatives and supplement positives by incorporating the multi-granularity information from the clustering hierarchy",
    "link": "http://arxiv.org/abs/2212.01141",
    "context": "Title: MHCCL: Masked Hierarchical Cluster-Wise Contrastive Learning for Multivariate Time Series. (arXiv:2212.01141v3 [cs.LG] UPDATED)\nAbstract: Learning semantic-rich representations from raw unlabeled time series data is critical for downstream tasks such as classification and forecasting. Contrastive learning has recently shown its promising representation learning capability in the absence of expert annotations. However, existing contrastive approaches generally treat each instance independently, which leads to false negative pairs that share the same semantics. To tackle this problem, we propose MHCCL, a Masked Hierarchical Cluster-wise Contrastive Learning model, which exploits semantic information obtained from the hierarchical structure consisting of multiple latent partitions for multivariate time series. Motivated by the observation that fine-grained clustering preserves higher purity while coarse-grained one reflects higher-level semantics, we propose a novel downward masking strategy to filter out fake negatives and supplement positives by incorporating the multi-granularity information from the clustering hierarchy",
    "path": "papers/22/12/2212.01141.json",
    "total_tokens": 919,
    "translated_title": "MHCCL：用于多元时间序列的层次掩蔽聚类对比学习",
    "translated_abstract": "从原始无标签时间序列数据中学习语义丰富的表示对于分类和预测等下游任务至关重要。对比学习最近展示了在缺乏专家注释的情况下具有良好的表示学习能力。然而，现有的对比学习方法通常独立处理每个实例，导致共享相同语义的假负样本。为了解决这个问题，我们提出了MHCCL，一种层次掩蔽聚类对比学习模型，它利用由多个潜在分区组成的层次结构获得的语义信息来为多元时间序列建模。受到细粒度聚类保留更高纯度，而粗粒度聚类反映更高级别语义的观察的启发，我们提出了一种新颖的向下掩蔽策略，通过结合聚类层次结构中的多粒度信息，过滤掉虚假负面实例并补充正面实例。",
    "tldr": "本文提出了一种名为MHCCL的对比学习模型，可以从多元时间序列数据中学习语义丰富的表示，并利用层次聚类结构中的多粒度信息来滤除虚假负样本和补充正样本。",
    "en_tdlr": "The paper proposes a Masked Hierarchical Cluster-Wise Contrastive Learning (MHCCL) model to learn semantic-rich representations from raw unlabeled multivariate time series data. It exploits semantic information obtained from a hierarchical structure consisting of multiple latent partitions and uses a downward masking strategy to filter out false negatives and supplement positives by incorporating multi-granularity information from the clustering hierarchy."
}