{
    "title": "4D ASR: Joint modeling of CTC, Attention, Transducer, and Mask-Predict decoders. (arXiv:2212.10818v2 [cs.SD] UPDATED)",
    "abstract": "The network architecture of end-to-end (E2E) automatic speech recognition (ASR) can be classified into several models, including connectionist temporal classification (CTC), recurrent neural network transducer (RNN-T), attention mechanism, and non-autoregressive mask-predict models. Since each of these network architectures has pros and cons, a typical use case is to switch these separate models depending on the application requirement, resulting in the increased overhead of maintaining all models. Several methods for integrating two of these complementary models to mitigate the overhead issue have been proposed; however, if we integrate more models, we will further benefit from these complementary models and realize broader applications with a single system. This paper proposes four-decoder joint modeling (4D) of CTC, attention, RNN-T, and mask-predict, which has the following three advantages: 1) The four decoders are jointly trained so that they can be easily switched depending on t",
    "link": "http://arxiv.org/abs/2212.10818",
    "context": "Title: 4D ASR: Joint modeling of CTC, Attention, Transducer, and Mask-Predict decoders. (arXiv:2212.10818v2 [cs.SD] UPDATED)\nAbstract: The network architecture of end-to-end (E2E) automatic speech recognition (ASR) can be classified into several models, including connectionist temporal classification (CTC), recurrent neural network transducer (RNN-T), attention mechanism, and non-autoregressive mask-predict models. Since each of these network architectures has pros and cons, a typical use case is to switch these separate models depending on the application requirement, resulting in the increased overhead of maintaining all models. Several methods for integrating two of these complementary models to mitigate the overhead issue have been proposed; however, if we integrate more models, we will further benefit from these complementary models and realize broader applications with a single system. This paper proposes four-decoder joint modeling (4D) of CTC, attention, RNN-T, and mask-predict, which has the following three advantages: 1) The four decoders are jointly trained so that they can be easily switched depending on t",
    "path": "papers/22/12/2212.10818.json",
    "total_tokens": 1043,
    "translated_title": "4D ASR：CTC、Attention、RNN-T和Mask-Predict解码器的联合建模。",
    "translated_abstract": "无论是CTC、RNN-T、注意力机制还是非自回归的Mask-Predict模型，端到端(E2E)自动语音识别(ASR)的网络架构都可归为几类。由于每个架构都有其优势和劣势，因此典型的用例是根据应用需求切换这些独立模型，导致维护所有模型的开销增加。已经提出了几种方法来集成这些互补模型中的两种以减轻开销问题；然而，如果我们集成更多模型，我们将进一步从这些互补模型中受益，并通过单一系统实现更广泛的应用。本文提出了CTC、Attention、RNN-T和Mask-Predict四个解码器的联合建模(4D)，具有以下三个优点：1) 四个解码器联合训练，因此根据应用程序可以轻松切换；2) 提出的4D模型优于单一模型和两个混合模型；3) 该模型可以高效地建模不同类型的ASR任务，包括低资源语音、代码转换语音和不同场景下的语音。",
    "tldr": "本文介绍了一种CTC、Attention、RNN-T和Mask-Predict四个解码器的联合建模(4D)，它可以高效地建模不同类型的ASR任务，包括低资源语音、代码转换语音和不同场景下的语音，并且性能优于单一模型和两个混合模型。",
    "en_tdlr": "This paper introduces a four-decoder joint modeling (4D) of CTC, attention, RNN-T, and mask-predict for end-to-end automatic speech recognition, which efficiently models different types of ASR tasks and outperforms single models and two-mixed models."
}