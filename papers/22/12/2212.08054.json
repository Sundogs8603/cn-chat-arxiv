{
    "title": "DAMP: Doubly Aligned Multilingual Parser for Task-Oriented Dialogue. (arXiv:2212.08054v2 [cs.CL] UPDATED)",
    "abstract": "Modern virtual assistants use internal semantic parsing engines to convert user utterances to actionable commands. However, prior work has demonstrated that semantic parsing is a difficult multilingual transfer task with low transfer efficiency compared to other tasks. In global markets such as India and Latin America, this is a critical issue as switching between languages is prevalent for bilingual users. In this work we dramatically improve the zero-shot performance of a multilingual and codeswitched semantic parsing system using two stages of multilingual alignment. First, we show that constrastive alignment pretraining improves both English performance and transfer efficiency. We then introduce a constrained optimization approach for hyperparameter-free adversarial alignment during finetuning. Our Doubly Aligned Multilingual Parser (DAMP) improves mBERT transfer performance by 3x, 6x, and 81x on the Spanglish, Hinglish and Multilingual Task Oriented Parsing benchmarks respectively",
    "link": "http://arxiv.org/abs/2212.08054",
    "context": "Title: DAMP: Doubly Aligned Multilingual Parser for Task-Oriented Dialogue. (arXiv:2212.08054v2 [cs.CL] UPDATED)\nAbstract: Modern virtual assistants use internal semantic parsing engines to convert user utterances to actionable commands. However, prior work has demonstrated that semantic parsing is a difficult multilingual transfer task with low transfer efficiency compared to other tasks. In global markets such as India and Latin America, this is a critical issue as switching between languages is prevalent for bilingual users. In this work we dramatically improve the zero-shot performance of a multilingual and codeswitched semantic parsing system using two stages of multilingual alignment. First, we show that constrastive alignment pretraining improves both English performance and transfer efficiency. We then introduce a constrained optimization approach for hyperparameter-free adversarial alignment during finetuning. Our Doubly Aligned Multilingual Parser (DAMP) improves mBERT transfer performance by 3x, 6x, and 81x on the Spanglish, Hinglish and Multilingual Task Oriented Parsing benchmarks respectively",
    "path": "papers/22/12/2212.08054.json",
    "total_tokens": 899,
    "translated_title": "DAMP：面向任务型对话的双重对齐多语言解析器",
    "translated_abstract": "现代虚拟助手使用内部语义解析引擎将用户话语转化为可操作命令。然而，先前的研究表明，语义解析是一项困难的多语言转移任务，其转移效率比其他任务低。在全球市场（如印度和拉丁美洲），这是一个关键问题，因为双语用户频繁切换语言。在本研究中，我们使用两个阶段的多语言对齐，大大提高了多语言和代码切换语义解析系统的零-shot性能。首先，我们表明，对比对齐预训练可以提高英文性能和转移效率。然后，我们引入一种受限制的优化方法，用于无超参数的对抗性对齐。我们的双重对齐多语言解析器（DAMP）分别将Spanglish、Hinglish和多语言任务导向解析基准的mBERT转移性能提高了3倍、6倍和81倍。",
    "tldr": "本文介绍了一种面向任务型对话的双重对齐多语言解析器，可以大幅提高多语言和代码切换语义解析系统的零-shot性能，提高mBERT转移性能。",
    "en_tdlr": "This paper presents a Doubly Aligned Multilingual Parser (DAMP) for task-oriented dialogue, which significantly improves zero-shot performance and mBERT transfer performance of multilingual and codeswitched semantic parsing systems through two stages of multilingual alignment, including contrastive alignment pretraining and hyperparameter-free adversarial alignment during finetuning."
}