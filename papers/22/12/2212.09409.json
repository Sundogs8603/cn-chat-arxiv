{
    "title": "Multi-View Knowledge Distillation from Crowd Annotations for Out-of-Domain Generalization. (arXiv:2212.09409v2 [cs.CL] UPDATED)",
    "abstract": "Selecting an effective training signal for tasks in natural language processing is difficult: expert annotations are expensive, and crowd-sourced annotations may not be reliable. At the same time, recent work in NLP has demonstrated that learning from a distribution over labels acquired from crowd annotations can be effective. However, there are many ways to acquire such a distribution, and the performance allotted by any one method can fluctuate based on the task and the amount of available crowd annotations, making it difficult to know a priori which distribution is best. This paper systematically analyzes this in the out-of-domain setting, adding to the NLP literature which has focused on in-domain evaluation, and proposes new methods for acquiring soft-labels from crowd-annotations by aggregating the distributions produced by existing methods. In particular, we propose to aggregate multiple-views of crowd annotations via temperature scaling and finding their Jensen-Shannon centroid",
    "link": "http://arxiv.org/abs/2212.09409",
    "context": "Title: Multi-View Knowledge Distillation from Crowd Annotations for Out-of-Domain Generalization. (arXiv:2212.09409v2 [cs.CL] UPDATED)\nAbstract: Selecting an effective training signal for tasks in natural language processing is difficult: expert annotations are expensive, and crowd-sourced annotations may not be reliable. At the same time, recent work in NLP has demonstrated that learning from a distribution over labels acquired from crowd annotations can be effective. However, there are many ways to acquire such a distribution, and the performance allotted by any one method can fluctuate based on the task and the amount of available crowd annotations, making it difficult to know a priori which distribution is best. This paper systematically analyzes this in the out-of-domain setting, adding to the NLP literature which has focused on in-domain evaluation, and proposes new methods for acquiring soft-labels from crowd-annotations by aggregating the distributions produced by existing methods. In particular, we propose to aggregate multiple-views of crowd annotations via temperature scaling and finding their Jensen-Shannon centroid",
    "path": "papers/22/12/2212.09409.json",
    "total_tokens": 788,
    "translated_title": "从众包注释中进行多视角知识蒸馏以实现跨领域泛化",
    "translated_abstract": "在自然语言处理任务中选择有效的训练信号很困难：专家注释很昂贵，而众包注释可能不可靠。最近的NLP研究表明，从众包注释中获取标签分布的学习可以是有效的。然而，有很多获取这种分布的方法，任何一种方法的性能都可能因任务和可用众包注释量而波动，这使得事先不知道哪种分布最好。本文在领域外系统地分析了这个问题，并提出了通过聚合现有方法产生的分布来获取来自众包注释的软标签的新方法。特别地，我们建议通过温度缩放和找到它们的Jensen-Shannon中心来聚合众包注释的多个视图。",
    "tldr": "本文提出了一种新方法，通过聚合多个视图的众包注释来获取软标签，从而进行跨领域泛化。",
    "en_tdlr": "This paper proposes a new method to acquire soft-labels from crowd-annotations by aggregating multiple-views, which is effective for out-of-domain generalization in natural language processing tasks."
}