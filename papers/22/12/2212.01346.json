{
    "title": "Guaranteed Conformance of Neurosymbolic Models to Natural Constraints. (arXiv:2212.01346v7 [cs.LG] UPDATED)",
    "abstract": "Deep neural networks have emerged as the workhorse for a large section of robotics and control applications, especially as models for dynamical systems. Such data-driven models are in turn used for designing and verifying autonomous systems. They are particularly useful in modeling medical systems where data can be leveraged to individualize treatment. In safety-critical applications, it is important that the data-driven model is conformant to established knowledge from the natural sciences. Such knowledge is often available or can often be distilled into a (possibly black-box) model. For instance, an F1 racing car should conform to Newton's laws (which are encoded within a unicycle model). In this light, we consider the following problem - given a model $M$ and a state transition dataset, we wish to best approximate the system model while being a bounded distance away from $M$. We propose a method to guarantee this conformance. Our first step is to distill the dataset into a few repre",
    "link": "http://arxiv.org/abs/2212.01346",
    "context": "Title: Guaranteed Conformance of Neurosymbolic Models to Natural Constraints. (arXiv:2212.01346v7 [cs.LG] UPDATED)\nAbstract: Deep neural networks have emerged as the workhorse for a large section of robotics and control applications, especially as models for dynamical systems. Such data-driven models are in turn used for designing and verifying autonomous systems. They are particularly useful in modeling medical systems where data can be leveraged to individualize treatment. In safety-critical applications, it is important that the data-driven model is conformant to established knowledge from the natural sciences. Such knowledge is often available or can often be distilled into a (possibly black-box) model. For instance, an F1 racing car should conform to Newton's laws (which are encoded within a unicycle model). In this light, we consider the following problem - given a model $M$ and a state transition dataset, we wish to best approximate the system model while being a bounded distance away from $M$. We propose a method to guarantee this conformance. Our first step is to distill the dataset into a few repre",
    "path": "papers/22/12/2212.01346.json",
    "total_tokens": 848,
    "translated_title": "神经符号模型的自然约束担保一致性",
    "translated_abstract": "深度神经网络已经成为大部分机器人和控制应用的主要模型，特别是作为动态系统模型。这类数据驱动模型又可以用于设计和验证自主系统。在医疗系统建模方面尤其有用，因为数据能够被用于个体化治疗。在安全关键的应用中，数据驱动模型对来自自然科学的已有知识的符合性显得尤为重要。这些知识通常是可用的，或者可以被浓缩成（可能是黑盒的）模型。例如，F1赛车应符合牛顿定律（这被编码在一个单轮模型中）。鉴于这一点，我们考虑以下问题——给定一个模型M和一个状态转移数据集，我们希望在距离M的范围内最好地近似系统模型。我们提出一种方法来担保这种一致性。我们的第一步是将数据集浓缩成几个代表性的样例。",
    "tldr": "该论文提出了一种能够担保数据驱动模型符合自然科学已有知识并最优逼近系统模型的方法。"
}