{
    "title": "Source-Free Domain Adaptation for Question Answering with Masked Self-training",
    "abstract": "arXiv:2212.09563v2 Announce Type: replace  Abstract: Most previous unsupervised domain adaptation (UDA) methods for question answering(QA) require access to source domain data while fine-tuning the model for the target domain. Source domain data may, however, contain sensitive information and may be restricted. In this study, we investigate a more challenging setting, source-free UDA, in which we have only the pretrained source model and target domain data, without access to source domain data. We propose a novel self-training approach to QA models that integrates a unique mask module for domain adaptation. The mask is auto-adjusted to extract key domain knowledge while trained on the source domain. To maintain previously learned domain knowledge, certain mask weights are frozen during adaptation, while other weights are adjusted to mitigate domain shifts with pseudo-labeled samples generated in the target domain. %As part of the self-training process, we generate pseudo-labeled sample",
    "link": "https://arxiv.org/abs/2212.09563",
    "context": "Title: Source-Free Domain Adaptation for Question Answering with Masked Self-training\nAbstract: arXiv:2212.09563v2 Announce Type: replace  Abstract: Most previous unsupervised domain adaptation (UDA) methods for question answering(QA) require access to source domain data while fine-tuning the model for the target domain. Source domain data may, however, contain sensitive information and may be restricted. In this study, we investigate a more challenging setting, source-free UDA, in which we have only the pretrained source model and target domain data, without access to source domain data. We propose a novel self-training approach to QA models that integrates a unique mask module for domain adaptation. The mask is auto-adjusted to extract key domain knowledge while trained on the source domain. To maintain previously learned domain knowledge, certain mask weights are frozen during adaptation, while other weights are adjusted to mitigate domain shifts with pseudo-labeled samples generated in the target domain. %As part of the self-training process, we generate pseudo-labeled sample",
    "path": "papers/22/12/2212.09563.json",
    "total_tokens": 896,
    "translated_title": "面向问题回答的无源领域自适应方法及其蒙版自训练",
    "translated_abstract": "大多数先前针对问题回答（QA）的无监督领域自适应（UDA）方法在Fine-tuning目标域模型时需要访问源域数据。然而，源域数据可能包含敏感信息并受到限制。在本研究中，我们研究了更具挑战性的设置，即无源UDA，在此设置中，我们只有预训练的源模型和目标域数据，无法访问源域数据。我们提出了一种新颖的自训练方法来提升QA模型，该方法集成了一个用于领域自适应的独特蒙版模块。该蒙版在训练源域时进行自动调整，以提取关键的领域知识。为了保持先前学习到的领域知识，适应过程中某些蒙版权重被冻结，而其他权重则根据目标域中生成的伪标签样本来调整，以减轻领域偏移。",
    "tldr": "提出了一种面向问题回答的无源领域自适应方法，通过独特的蒙版模块实现自训练，成功解决了无法访问源域数据的挑战，提升了模型在目标领域上的性能。",
    "en_tdlr": "Introduced a source-free domain adaptation method for question answering that utilizes a unique mask module for self-training, successfully addressing the challenge of inaccessible source domain data and improving the model performance in the target domain."
}