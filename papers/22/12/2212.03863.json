{
    "title": "X-Paste: Revisiting Scalable Copy-Paste for Instance Segmentation using CLIP and StableDiffusion. (arXiv:2212.03863v2 [cs.CV] UPDATED)",
    "abstract": "Copy-Paste is a simple and effective data augmentation strategy for instance segmentation. By randomly pasting object instances onto new background images, it creates new training data for free and significantly boosts the segmentation performance, especially for rare object categories. Although diverse, high-quality object instances used in Copy-Paste result in more performance gain, previous works utilize object instances either from human-annotated instance segmentation datasets or rendered from 3D object models, and both approaches are too expensive to scale up to obtain good diversity. In this paper, we revisit Copy-Paste at scale with the power of newly emerged zero-shot recognition models (e.g., CLIP) and text2image models (e.g., StableDiffusion). We demonstrate for the first time that using a text2image model to generate images or zero-shot recognition model to filter noisily crawled images for different object categories is a feasible way to make Copy-Paste truly scalable. To ",
    "link": "http://arxiv.org/abs/2212.03863",
    "context": "Title: X-Paste: Revisiting Scalable Copy-Paste for Instance Segmentation using CLIP and StableDiffusion. (arXiv:2212.03863v2 [cs.CV] UPDATED)\nAbstract: Copy-Paste is a simple and effective data augmentation strategy for instance segmentation. By randomly pasting object instances onto new background images, it creates new training data for free and significantly boosts the segmentation performance, especially for rare object categories. Although diverse, high-quality object instances used in Copy-Paste result in more performance gain, previous works utilize object instances either from human-annotated instance segmentation datasets or rendered from 3D object models, and both approaches are too expensive to scale up to obtain good diversity. In this paper, we revisit Copy-Paste at scale with the power of newly emerged zero-shot recognition models (e.g., CLIP) and text2image models (e.g., StableDiffusion). We demonstrate for the first time that using a text2image model to generate images or zero-shot recognition model to filter noisily crawled images for different object categories is a feasible way to make Copy-Paste truly scalable. To ",
    "path": "papers/22/12/2212.03863.json",
    "total_tokens": 844,
    "translated_title": "X-Paste：利用CLIP和StableDiffusion重新思考可扩展的实例分割复制粘贴(arXiv:2212.03863v2 [cs.CV] 修订版)",
    "translated_abstract": "复制粘贴是一种简单且有效的实例分割数据增强策略。通过将对象实例随机粘贴到新的背景图像中，可以免费创建新的训练数据并显著提高分割性能，特别是对于罕见的物体类别。本文利用新出现的零样本识别模型（例如CLIP）和text2image模型（例如StableDiffusion）的能力，重新思考了可扩展的复制粘贴。我们首次展示了使用text2image模型生成图像或使用零样本识别模型过滤嘈杂爬取的图像以获取不同物体类别的可行性。",
    "tldr": "本文利用零样本识别和text2image模型，重新思考了可扩展的复制粘贴，实现了利用不同物体类别的图像进行实例分割，以获得更高的性能",
    "en_tdlr": "This paper revisits scalable Copy-Paste for instance segmentation using the power of zero-shot recognition models and text2image models, allowing for diverse object instances to significantly boost performance. The use of these models enables the generation of new training data and demonstrates a feasible way to make Copy-Paste truly scalable and effective."
}