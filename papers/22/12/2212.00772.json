{
    "title": "Margin-based sampling in high dimensions: When being active is less efficient than staying passive. (arXiv:2212.00772v2 [cs.LG] UPDATED)",
    "abstract": "It is widely believed that given the same labeling budget, active learning (AL) algorithms like margin-based active learning achieve better predictive performance than passive learning (PL), albeit at a higher computational cost. Recent empirical evidence suggests that this added cost might be in vain, as margin-based AL can sometimes perform even worse than PL. While existing works offer different explanations in the low-dimensional regime, this paper shows that the underlying mechanism is entirely different in high dimensions: we prove for logistic regression that PL outperforms margin-based AL even for noiseless data and when using the Bayes optimal decision boundary for sampling. Insights from our proof indicate that this high-dimensional phenomenon is exacerbated when the separation between the classes is small. We corroborate this intuition with experiments on 20 high-dimensional datasets spanning a diverse range of applications, from finance and histology to chemistry and comput",
    "link": "http://arxiv.org/abs/2212.00772",
    "context": "Title: Margin-based sampling in high dimensions: When being active is less efficient than staying passive. (arXiv:2212.00772v2 [cs.LG] UPDATED)\nAbstract: It is widely believed that given the same labeling budget, active learning (AL) algorithms like margin-based active learning achieve better predictive performance than passive learning (PL), albeit at a higher computational cost. Recent empirical evidence suggests that this added cost might be in vain, as margin-based AL can sometimes perform even worse than PL. While existing works offer different explanations in the low-dimensional regime, this paper shows that the underlying mechanism is entirely different in high dimensions: we prove for logistic regression that PL outperforms margin-based AL even for noiseless data and when using the Bayes optimal decision boundary for sampling. Insights from our proof indicate that this high-dimensional phenomenon is exacerbated when the separation between the classes is small. We corroborate this intuition with experiments on 20 high-dimensional datasets spanning a diverse range of applications, from finance and histology to chemistry and comput",
    "path": "papers/22/12/2212.00772.json",
    "total_tokens": 932,
    "translated_title": "高维情况下的基于边缘采样：主动学习效率不如被动学习",
    "translated_abstract": "通常认为，给定相同的标注预算，基于边缘值的主动学习算法会比被动学习算法获得更好的预测性能，尽管计算成本更高。最近的经验证据表明，这种额外的成本可能是徒劳的，因为基于边缘值的主动学习有时甚至比被动学习表现更差。本文在逻辑回归的背景下证明，即使对于无噪声数据和使用贝叶斯最优决策边界进行采样，被动学习仍然优于基于边缘值的主动学习。我们证明所得的结论表明，该现象在高维情况下加剧，特别是在类之间的分离较小的情况下。我们通过对20个高维数据集的实验进行实证，证实了这种直觉，这些数据集涵盖了从金融和组织学到化学和计算机等各种应用领域。",
    "tldr": "基于边缘值的主动学习在高维情况下效率不如被动学习，即使对于无噪声数据和使用贝叶斯最优决策边界进行采样，被动学习仍然更优。特别是在类之间的分离较小的情况下，这种现象更加明显。",
    "en_tdlr": "Margin-based active learning is less efficient than passive learning in high dimensional scenarios, even for noiseless data and when using the Bayes optimal decision boundary for sampling. Specifically, this phenomenon is exacerbated when the separation between the classes is small."
}