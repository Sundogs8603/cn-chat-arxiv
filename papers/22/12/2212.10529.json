{
    "title": "Does GPT-3 Demonstrate Psychopathy? Evaluating Large Language Models from a Psychological Perspective. (arXiv:2212.10529v2 [cs.CL] UPDATED)",
    "abstract": "In this work, we determined whether large language models (LLMs) are psychologically safe. We designed unbiased prompts to systematically evaluate LLMs from a psychological perspective. First, we tested three different LLMs by using two personality tests: Short Dark Triad (SD-3) and Big Five Inventory (BFI). All models scored higher than the human average on SD-3, suggesting a relatively darker personality pattern. Despite being instruction fine-tuned with safety metrics to reduce toxicity, InstructGPT and FLAN-T5 still showed implicit dark personality patterns; both models scored higher than self-supervised GPT-3 on the Machiavellianism and narcissism traits on SD-3. Then, we evaluated the LLMs in the GPT-3 series by using well-being tests to study the impact of fine-tuning with more training data. We observed a continuous increase in the well-being scores of GPT-3 and InstructGPT. Following these observations, we showed that instruction fine-tuning FLAN-T5 with positive answers from ",
    "link": "http://arxiv.org/abs/2212.10529",
    "context": "Title: Does GPT-3 Demonstrate Psychopathy? Evaluating Large Language Models from a Psychological Perspective. (arXiv:2212.10529v2 [cs.CL] UPDATED)\nAbstract: In this work, we determined whether large language models (LLMs) are psychologically safe. We designed unbiased prompts to systematically evaluate LLMs from a psychological perspective. First, we tested three different LLMs by using two personality tests: Short Dark Triad (SD-3) and Big Five Inventory (BFI). All models scored higher than the human average on SD-3, suggesting a relatively darker personality pattern. Despite being instruction fine-tuned with safety metrics to reduce toxicity, InstructGPT and FLAN-T5 still showed implicit dark personality patterns; both models scored higher than self-supervised GPT-3 on the Machiavellianism and narcissism traits on SD-3. Then, we evaluated the LLMs in the GPT-3 series by using well-being tests to study the impact of fine-tuning with more training data. We observed a continuous increase in the well-being scores of GPT-3 and InstructGPT. Following these observations, we showed that instruction fine-tuning FLAN-T5 with positive answers from ",
    "path": "papers/22/12/2212.10529.json",
    "total_tokens": 1073,
    "translated_title": "GPT-3是否展示出精神病态？从心理学角度评估大型语言模型",
    "translated_abstract": "本文旨在从心理学角度确定大型语言模型（LLMs）的安全性。我们设计了无偏的提示来系统性地评估LLMs。首先，我们使用了两个人格测试——短暗三合一测验（SD-3）和大五人格问卷（BFI）测试了三个不同的LLMs。所有模型在SD-3上的得分都高于人类平均水平，表明存在相对较暗的人格模式。尽管经过指标微调以减少毒性，InstructGPT和FLAN-T5仍然呈现出隐含的黑暗人格模式；在SD-3的玛基雅维利主义和自恋狂特征上，这两种模型的得分都高于自监督GPT-3。然后，我们使用幸福感测试评估了GPT-3系列中的LLMs，以研究更多训练数据的微调对其影响。我们观察到GPT-3和InstructGPT的幸福感得分持续增加。鉴于这些观察结果，我们展示了使用正面回答从而指标微调FLAN-T5的方法。",
    "tldr": "本文从心理学角度评估大型语言模型的安全性，发现所有模型在短暗三合一测验上的得分都高于人类平均水平，存在相对较暗的人格模式。尽管经过指标微调，两种模型仍呈现隐含的黑暗人格模式。同时，本文观察到GPT-3和InstructGPT的幸福感得分持续增加。",
    "en_tdlr": "This paper evaluates the psychological safety of large language models (LLMs) and finds that all models exhibit a relatively darker personality pattern based on Short Dark Triad tests. Despite being fine-tuned with safety metrics, InstructGPT and FLAN-T5 still show implicit dark personality patterns. The paper also observes a continuous increase in the well-being scores of GPT-3 and InstructGPT with more training data."
}