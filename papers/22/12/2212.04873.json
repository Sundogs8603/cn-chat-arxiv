{
    "title": "Multimodal Prototype-Enhanced Network for Few-Shot Action Recognition. (arXiv:2212.04873v2 [cs.CV] UPDATED)",
    "abstract": "Current methods for few-shot action recognition mainly fall into the metric learning framework following ProtoNet, which demonstrates the importance of prototypes. Although they achieve relatively good performance, the effect of multimodal information is ignored, e.g. label texts. In this work, we propose a novel MultimOdal PRototype-ENhanced Network (MORN), which uses the semantic information of label texts as multimodal information to enhance prototypes. A CLIP visual encoder and a frozen CLIP text encoder are introduced to obtain features with good multimodal initialization. Then in the visual flow, visual prototypes are computed by a Temporal-Relational CrossTransformer (TRX) module for example. In the text flow, a semantic-enhanced (SE) module and an inflating operation are used to obtain text prototypes. The final multimodal prototypes are then computed by a multimodal prototype-enhanced (MPE) module. Besides, we define a PRototype SImilarity DiffErence (PRIDE) to evaluate the qu",
    "link": "http://arxiv.org/abs/2212.04873",
    "context": "Title: Multimodal Prototype-Enhanced Network for Few-Shot Action Recognition. (arXiv:2212.04873v2 [cs.CV] UPDATED)\nAbstract: Current methods for few-shot action recognition mainly fall into the metric learning framework following ProtoNet, which demonstrates the importance of prototypes. Although they achieve relatively good performance, the effect of multimodal information is ignored, e.g. label texts. In this work, we propose a novel MultimOdal PRototype-ENhanced Network (MORN), which uses the semantic information of label texts as multimodal information to enhance prototypes. A CLIP visual encoder and a frozen CLIP text encoder are introduced to obtain features with good multimodal initialization. Then in the visual flow, visual prototypes are computed by a Temporal-Relational CrossTransformer (TRX) module for example. In the text flow, a semantic-enhanced (SE) module and an inflating operation are used to obtain text prototypes. The final multimodal prototypes are then computed by a multimodal prototype-enhanced (MPE) module. Besides, we define a PRototype SImilarity DiffErence (PRIDE) to evaluate the qu",
    "path": "papers/22/12/2212.04873.json",
    "total_tokens": 897,
    "translated_title": "多模态原型增强网络用于少样本动作识别",
    "translated_abstract": "当前的少样本动作识别方法主要采用原型学习框架，遵循ProtoNet的方法，显示了原型的重要性。虽然它们取得了相对较好的性能，但多模态信息的效果被忽略，例如标签文本。在这项工作中，我们提出了一种新颖的多模态原型增强网络（MORN），它利用标签文本的语义信息作为多模态信息来增强原型。我们引入了一个CLIP视觉编码器和一个冻结的CLIP文本编码器，以获得具有良好多模态初始化的特征。然后，在视觉流程中，通过一个时间关系交叉变换器(TRX)模块计算视觉原型。在文本流程中，使用一个语义增强(SE)模块和一个扩张操作来获取文本原型。最后，通过一个多模态原型增强(MPE)模块计算最终的多模态原型。此外，我们定义了一个原型相似性差异(PRIDE)来评估质量。",
    "tldr": "该论文提出了一种多模态原型增强网络(MORN)用于少样本动作识别，通过利用标签文本的语义信息来增强原型，具有较好的性能表现。",
    "en_tdlr": "This paper proposes a multimodal prototype-enhanced network (MORN) for few-shot action recognition, which enhances prototypes by utilizing the semantic information of label texts, resulting in improved performance."
}