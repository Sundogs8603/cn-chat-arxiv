{
    "title": "Spuriosity Rankings: Sorting Data to Measure and Mitigate Biases. (arXiv:2212.02648v2 [cs.CV] UPDATED)",
    "abstract": "We present a simple but effective method to measure and mitigate model biases caused by reliance on spurious cues. Instead of requiring costly changes to one's data or model training, our method better utilizes the data one already has by sorting them. Specifically, we rank images within their classes based on spuriosity (the degree to which common spurious cues are present), proxied via deep neural features of an interpretable network. With spuriosity rankings, it is easy to identify minority subpopulations (i.e. low spuriosity images) and assess model bias as the gap in accuracy between high and low spuriosity images. One can even efficiently remove a model's bias at little cost to accuracy by finetuning its classification head on low spuriosity images, resulting in fairer treatment of samples regardless of spuriosity. We demonstrate our method on ImageNet, annotating $5000$ class-feature dependencies ($630$ of which we find to be spurious) and generating a dataset of $325k$ soft seg",
    "link": "http://arxiv.org/abs/2212.02648",
    "context": "Title: Spuriosity Rankings: Sorting Data to Measure and Mitigate Biases. (arXiv:2212.02648v2 [cs.CV] UPDATED)\nAbstract: We present a simple but effective method to measure and mitigate model biases caused by reliance on spurious cues. Instead of requiring costly changes to one's data or model training, our method better utilizes the data one already has by sorting them. Specifically, we rank images within their classes based on spuriosity (the degree to which common spurious cues are present), proxied via deep neural features of an interpretable network. With spuriosity rankings, it is easy to identify minority subpopulations (i.e. low spuriosity images) and assess model bias as the gap in accuracy between high and low spuriosity images. One can even efficiently remove a model's bias at little cost to accuracy by finetuning its classification head on low spuriosity images, resulting in fairer treatment of samples regardless of spuriosity. We demonstrate our method on ImageNet, annotating $5000$ class-feature dependencies ($630$ of which we find to be spurious) and generating a dataset of $325k$ soft seg",
    "path": "papers/22/12/2212.02648.json",
    "total_tokens": 1035,
    "translated_title": "Spuriosity Rankings: 使用排序数据来测量和减少偏见的方法",
    "translated_abstract": "我们提出了一种简单但有效的方法，通过排序数据来测量和减少模型对虚假线索的依赖所引起的偏见。我们的方法不需要对数据或模型训练进行昂贵的改变，而是更好地利用已有的数据。具体而言，我们基于通过可解释网络的深度神经特征来对图像进行类内排序，以衡量其虚假性（即常见虚假线索的存在程度）。通过虚假性排名，可以很容易地识别出少数子群体（即虚假性较低的图像），并通过准确率差来评估模型的偏见。甚至可以通过在虚假性较低的图像上微调分类头部，以极少的准确率损失来有效消除模型的偏见，从而实现对样本的更公正处理，无论虚假性如何。我们在ImageNet上展示了我们的方法，注释了5000个类特征依赖关系（其中630个是虚假的），并生成了一个包含325k个软分割数据的数据集。",
    "tldr": "这个论文提出了一种使用排序数据来测量和减少模型对虚假线索的偏见的简单有效方法。通过排名图像的虚假性，可以识别出少数子群体，并通过准确率差来评估模型的偏见。此外，通过在虚假性较低的图像上微调模型，可以在几乎不损失准确率的情况下消除模型的偏见，实现对样本的公正处理。",
    "en_tdlr": "This paper presents a simple and effective method to measure and reduce model biases caused by reliance on spurious cues. By ranking the images based on spuriosity, minority subpopulations can be identified and model bias can be assessed. Furthermore, by fine-tuning the model on low spuriosity images, model bias can be eliminated with little loss in accuracy, resulting in fair treatment of samples."
}