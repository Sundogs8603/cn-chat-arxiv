{
    "title": "Disentangling Prosody Representations with Unsupervised Speech Reconstruction. (arXiv:2212.06972v2 [cs.SD] UPDATED)",
    "abstract": "Human speech can be characterized by different components, including semantic content, speaker identity and prosodic information. Significant progress has been made in disentangling representations for semantic content and speaker identity in Automatic Speech Recognition (ASR) and speaker verification tasks respectively. However, it is still an open challenging research question to extract prosodic information because of the intrinsic association of different attributes, such as timbre and rhythm, and because of the need for supervised training schemes to achieve robust large-scale and speaker-independent ASR. The aim of this paper is to address the disentanglement of emotional prosody from speech based on unsupervised reconstruction. Specifically, we identify, design, implement and integrate three crucial components in our proposed speech reconstruction model Prosody2Vec: (1) a unit encoder that transforms speech signals into discrete units for semantic content, (2) a pretrained speak",
    "link": "http://arxiv.org/abs/2212.06972",
    "context": "Title: Disentangling Prosody Representations with Unsupervised Speech Reconstruction. (arXiv:2212.06972v2 [cs.SD] UPDATED)\nAbstract: Human speech can be characterized by different components, including semantic content, speaker identity and prosodic information. Significant progress has been made in disentangling representations for semantic content and speaker identity in Automatic Speech Recognition (ASR) and speaker verification tasks respectively. However, it is still an open challenging research question to extract prosodic information because of the intrinsic association of different attributes, such as timbre and rhythm, and because of the need for supervised training schemes to achieve robust large-scale and speaker-independent ASR. The aim of this paper is to address the disentanglement of emotional prosody from speech based on unsupervised reconstruction. Specifically, we identify, design, implement and integrate three crucial components in our proposed speech reconstruction model Prosody2Vec: (1) a unit encoder that transforms speech signals into discrete units for semantic content, (2) a pretrained speak",
    "path": "papers/22/12/2212.06972.json",
    "total_tokens": 970,
    "translated_title": "用无监督语音重构解开韵律表示的纠缠",
    "translated_abstract": "人类语音可以通过不同的组成部分进行表征，包括语义内容、说话者身份和韵律信息。在自动语音识别（ASR）和说话人验证任务中，已经取得了在语义内容和说话者身份的表示分离方面的重要进展。然而，从语音中提取韵律信息仍然是一个具有挑战性的开放性研究问题，主要是因为不同属性（如音色和节奏）之间的内在联系以及需要有监督训练方案来实现强大的大规模、与说话者无关的ASR。本文旨在通过无监督重构来解决从语音中分离情绪韵律的任务。具体而言，我们在提出的语音重构模型Prosody2Vec中鉴别、设计、实现和集成了三个关键组件：(1) 一个单元编码器，将语音信号转化为离散单元以表示语义内容，(2) 一个预训练的说话者编码器，用于分离出说话者身份的表示，以及 (3) 一个情绪编码器，用于分离出情绪韵律的表示。",
    "tldr": "本文提出了一种利用无监督语音重构来解决从语音中分离情绪韵律的任务的方法。通过设计和集成多个关键组件，我们能够在没有标签的情况下有效地提取出韵律信息。这对于自动语音识别和说话人验证等应用具有重要意义。"
}