{
    "title": "HiTSKT: A Hierarchical Transformer Model for Session-Aware Knowledge Tracing. (arXiv:2212.12139v3 [cs.AI] UPDATED)",
    "abstract": "Knowledge tracing (KT) aims to leverage students' learning histories to estimate their mastery levels on a set of pre-defined skills, based on which the corresponding future performance can be accurately predicted. As an important way of providing personalized experience for online education, KT has gained increased attention in recent years. In practice, a student's learning history comprises answers to sets of massed questions, each known as a session, rather than merely being a sequence of independent answers. Theoretically, within and across these sessions, students' learning dynamics can be very different. Therefore, how to effectively model the dynamics of students' knowledge states within and across the sessions is crucial for handling the KT problem. Most existing KT models treat student's learning records as a single continuing sequence, without capturing the sessional shift of students' knowledge state. To address the above issue, we propose a novel hierarchical transformer m",
    "link": "http://arxiv.org/abs/2212.12139",
    "context": "Title: HiTSKT: A Hierarchical Transformer Model for Session-Aware Knowledge Tracing. (arXiv:2212.12139v3 [cs.AI] UPDATED)\nAbstract: Knowledge tracing (KT) aims to leverage students' learning histories to estimate their mastery levels on a set of pre-defined skills, based on which the corresponding future performance can be accurately predicted. As an important way of providing personalized experience for online education, KT has gained increased attention in recent years. In practice, a student's learning history comprises answers to sets of massed questions, each known as a session, rather than merely being a sequence of independent answers. Theoretically, within and across these sessions, students' learning dynamics can be very different. Therefore, how to effectively model the dynamics of students' knowledge states within and across the sessions is crucial for handling the KT problem. Most existing KT models treat student's learning records as a single continuing sequence, without capturing the sessional shift of students' knowledge state. To address the above issue, we propose a novel hierarchical transformer m",
    "path": "papers/22/12/2212.12139.json",
    "total_tokens": 1100,
    "translated_title": "HiTSKT：一种用于会话感知知识追踪的分层Transformer模型。",
    "translated_abstract": "知识跟踪(KT)旨在利用学生的学习历史来估计他们在一组预定义的技能上的掌握水平，从而可以准确预测相应的未来表现。作为为在线教育提供个性化体验的重要方式，KT近年来受到越来越多的关注。在实践中，学生的学习历史是由一组集中的问题答案组成的，每个问题集被称为一个会话，而不仅仅是独立答案的序列。在理论上，学生的学习动态可以在这些会话中内部和跨会话之间非常不同。因此，如何有效地在会话内部和跨会话模拟学生的知识状态动态对于处理KT问题至关重要。大多数现有的KT模型将学生的学习记录视为单个连续序列，而没有捕捉学生知识状态的会话转移。为了解决上述问题，本文提出了一种新颖的分层Transformer模型，称为HiTSKT，以分层的方式表示学生的知识状态，企业级表示和技能级表示，分别。具体而言，HiTSKT首先利用自我注意机制捕捉不同会话之间的关系，然后基于会话级别的表示学习技能级别的表示。实验结果表明，HiTSKT在真实世界数据集上的表现优于现有技术基线模型。",
    "tldr": "HiTSKT是一种分层Transformer模型，用于会话感知知识追踪，能够捕捉学生不同会话之间的关系，并学习技能级别表示，相对于现有技术基线模型表现优异。",
    "en_tdlr": "HiTSKT is a hierarchical Transformer model for session-aware knowledge tracing, which can capture the relationships between different sessions and learn skill-level representation. It outperforms state-of-the-art baselines on real-world datasets."
}