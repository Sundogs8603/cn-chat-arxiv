{
    "title": "Learning to Generate Questions by Enhancing Text Generation with Sentence Selection. (arXiv:2212.12192v2 [cs.CL] UPDATED)",
    "abstract": "We introduce an approach for the answer-aware question generation problem. Instead of only relying on the capability of strong pre-trained language models, we observe that the information of answers and questions can be found in some relevant sentences in the context. Based on that, we design a model which includes two modules: a selector and a generator. The selector forces the model to more focus on relevant sentences regarding an answer to provide implicit local information. The generator generates questions by implicitly combining local information from the selector and global information from the whole context encoded by the encoder. The model is trained jointly to take advantage of latent interactions between the two modules. Experimental results on two benchmark datasets show that our model is better than strong pre-trained models for the question generation task. The code is also available.",
    "link": "http://arxiv.org/abs/2212.12192",
    "context": "Title: Learning to Generate Questions by Enhancing Text Generation with Sentence Selection. (arXiv:2212.12192v2 [cs.CL] UPDATED)\nAbstract: We introduce an approach for the answer-aware question generation problem. Instead of only relying on the capability of strong pre-trained language models, we observe that the information of answers and questions can be found in some relevant sentences in the context. Based on that, we design a model which includes two modules: a selector and a generator. The selector forces the model to more focus on relevant sentences regarding an answer to provide implicit local information. The generator generates questions by implicitly combining local information from the selector and global information from the whole context encoded by the encoder. The model is trained jointly to take advantage of latent interactions between the two modules. Experimental results on two benchmark datasets show that our model is better than strong pre-trained models for the question generation task. The code is also available.",
    "path": "papers/22/12/2212.12192.json",
    "total_tokens": 864,
    "translated_title": "通过加强句子选择来增强文本生成的学习生成问题方法",
    "translated_abstract": "我们提出了一种针对回答感知的问题生成问题的方法。我们观察到，回答和问题的信息可以在上下文中的一些相关句子中找到，而不仅仅依赖于强大的预训练语言模型的能力。基于此，我们设计了一个模型，包括两个模块：选择器和生成器。选择器强制模型更加关注与答案相关的句子，以提供隐含的局部信息。生成器通过将选择器提供的局部信息与编码器编码的整个上下文的全局信息隐式结合来生成问题。模型联合训练以利用两个模块之间的潜在交互。在两个基准数据集上的实验结果表明，我们的模型比强大的预训练模型在问题生成任务上更好。代码也可用。",
    "tldr": "本研究提出了一种通过加强句子选择来增强文本生成的学习生成问题方法，该方法通过设计选择器和生成器两个模块，使模型更关注与答案相关的句子，并隐式结合局部信息和全局信息来生成问题。实验结果表明该方法在问题生成任务上优于强大的预训练模型。"
}