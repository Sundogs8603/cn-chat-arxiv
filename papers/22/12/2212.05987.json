{
    "title": "Selective classification using a robust meta-learning approach. (arXiv:2212.05987v2 [cs.LG] UPDATED)",
    "abstract": "Predictive uncertainty-a model's self awareness regarding its accuracy on an input-is key for both building robust models via training interventions and for test-time applications such as selective classification. We propose a novel instance-conditioned reweighting approach that captures predictive uncertainty using an auxiliary network and unifies these train- and test-time applications. The auxiliary network is trained using a meta-objective in a bilevel optimization framework. A key contribution of our proposal is the meta-objective of minimizing the dropout variance, an approximation of Bayesian Predictive uncertainty. We show in controlled experiments that we effectively capture the diverse specific notions of uncertainty through this meta-objective, while previous approaches only capture certain aspects. These results translate to significant gains in real-world settings-selective classification, label noise, domain adaptation, calibration-and across datasets-Imagenet, Cifar100, ",
    "link": "http://arxiv.org/abs/2212.05987",
    "context": "Title: Selective classification using a robust meta-learning approach. (arXiv:2212.05987v2 [cs.LG] UPDATED)\nAbstract: Predictive uncertainty-a model's self awareness regarding its accuracy on an input-is key for both building robust models via training interventions and for test-time applications such as selective classification. We propose a novel instance-conditioned reweighting approach that captures predictive uncertainty using an auxiliary network and unifies these train- and test-time applications. The auxiliary network is trained using a meta-objective in a bilevel optimization framework. A key contribution of our proposal is the meta-objective of minimizing the dropout variance, an approximation of Bayesian Predictive uncertainty. We show in controlled experiments that we effectively capture the diverse specific notions of uncertainty through this meta-objective, while previous approaches only capture certain aspects. These results translate to significant gains in real-world settings-selective classification, label noise, domain adaptation, calibration-and across datasets-Imagenet, Cifar100, ",
    "path": "papers/22/12/2212.05987.json",
    "total_tokens": 883,
    "translated_title": "使用鲁棒性元学习方法的选择性分类",
    "translated_abstract": "预测不确定性-模型对其在输入上的准确性的自我意识-对于通过训练干预构建鲁棒模型和选择性分类等测试应用至关重要。我们提出了一种新颖的实例条件重新加权方法，利用辅助网络捕捉预测不确定性，并统一了这些训练时间和测试时间应用。辅助网络是在双层优化框架中使用元目标进行训练的。我们提议的一个重要贡献是最小化辍学方差的元目标，这是贝叶斯预测不确定性的近似值。我们通过控制实验表明，通过这个元目标，我们能够有效捕捉到不确定性的多样化特定概念，而之前的方法只能捕捉到某些方面。这些结果在真实世界的设置-选择性分类、标签噪声、领域适应、校准和数据集-Imagenet、Cifar100中转化为显著的收益。",
    "tldr": "这项研究提出了使用鲁棒性元学习方法的选择性分类。通过一个辅助网络捕捉预测不确定性，并在训练和测试中应用，我们成功地最小化了辍学方差，从而提高了在真实世界中的分类性能。"
}