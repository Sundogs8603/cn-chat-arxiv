{
    "title": "WeCheck: Strong Factual Consistency Checker via Weakly Supervised Learning. (arXiv:2212.10057v2 [cs.CL] UPDATED)",
    "abstract": "A crucial issue of current text generation models is that they often uncontrollably generate factually inconsistent text with respective of their inputs. Limited by the lack of annotated data, existing works in evaluating factual consistency directly transfer the reasoning ability of models trained on other data-rich upstream tasks like question answering (QA) and natural language inference (NLI) without any further adaptation. As a result, they perform poorly on the real generated text and are biased heavily by their single-source upstream tasks. To alleviate this problem, we propose a weakly supervised framework that aggregates multiple resources to train a precise and efficient factual metric, namely WeCheck. WeCheck first utilizes a generative model to accurately label a real generated sample by aggregating its weak labels, which are inferred from multiple resources. Then, we train the target metric model with the weak supervision while taking noises into consideration. Comprehensi",
    "link": "http://arxiv.org/abs/2212.10057",
    "context": "Title: WeCheck: Strong Factual Consistency Checker via Weakly Supervised Learning. (arXiv:2212.10057v2 [cs.CL] UPDATED)\nAbstract: A crucial issue of current text generation models is that they often uncontrollably generate factually inconsistent text with respective of their inputs. Limited by the lack of annotated data, existing works in evaluating factual consistency directly transfer the reasoning ability of models trained on other data-rich upstream tasks like question answering (QA) and natural language inference (NLI) without any further adaptation. As a result, they perform poorly on the real generated text and are biased heavily by their single-source upstream tasks. To alleviate this problem, we propose a weakly supervised framework that aggregates multiple resources to train a precise and efficient factual metric, namely WeCheck. WeCheck first utilizes a generative model to accurately label a real generated sample by aggregating its weak labels, which are inferred from multiple resources. Then, we train the target metric model with the weak supervision while taking noises into consideration. Comprehensi",
    "path": "papers/22/12/2212.10057.json",
    "total_tokens": 845,
    "translated_title": "WeCheck：基于弱监督学习的强实际一致性检查器",
    "translated_abstract": "当前文本生成模型的一个关键问题是它们经常会生成与其输入存在事实不一致的文本。由于缺乏注释数据，现有的在评估事实一致性方面的作品直接转移模型在其他数据丰富的上游任务，例如问题回答和自然语言推理的推理能力，而没有进一步的适应性。因此，它们在真正生成的文本上表现不佳，并且受其单一源上游任务的严重偏见所影响。为了缓解这个问题，我们提出了一个弱监督框架，通过聚合多个资源来训练一个精确和高效的事实度量标准，即WeCheck。WeCheck首先利用生成模型通过聚合多个资源推断出的弱标签来准确标记真实生成的样本。然后，我们在考虑噪声的情况下使用弱监督训练目标度量模型。",
    "tldr": "本研究提出了一种弱监督框架WeCheck，通过聚合多种资源训练模型，准确和高效地检查文本生成模型是否存在实际事实一致性问题。",
    "en_tdlr": "We propose a weakly supervised framework WeCheck that trains a precise and efficient factual metric by aggregating multiple resources to check for factual consistency in text generation models."
}