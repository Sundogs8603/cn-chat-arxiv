{
    "title": "Pareto Regret Analyses in Multi-objective Multi-armed Bandit. (arXiv:2212.00884v2 [cs.LG] UPDATED)",
    "abstract": "We study Pareto optimality in multi-objective multi-armed bandit by providing a formulation of adversarial multi-objective multi-armed bandit and defining its Pareto regrets that can be applied to both stochastic and adversarial settings. The regrets do not rely on any scalarization functions and reflect Pareto optimality compared to scalarized regrets. We also present new algorithms assuming both with and without prior information of the multi-objective multi-armed bandit setting. The algorithms are shown optimal in adversarial settings and nearly optimal up to a logarithmic factor in stochastic settings simultaneously by our established upper bounds and lower bounds on Pareto regrets. Moreover, the lower bound analyses show that the new regrets are consistent with the existing Pareto regret for stochastic settings and extend an adversarial attack mechanism from bandit to the multi-objective one.",
    "link": "http://arxiv.org/abs/2212.00884",
    "context": "Title: Pareto Regret Analyses in Multi-objective Multi-armed Bandit. (arXiv:2212.00884v2 [cs.LG] UPDATED)\nAbstract: We study Pareto optimality in multi-objective multi-armed bandit by providing a formulation of adversarial multi-objective multi-armed bandit and defining its Pareto regrets that can be applied to both stochastic and adversarial settings. The regrets do not rely on any scalarization functions and reflect Pareto optimality compared to scalarized regrets. We also present new algorithms assuming both with and without prior information of the multi-objective multi-armed bandit setting. The algorithms are shown optimal in adversarial settings and nearly optimal up to a logarithmic factor in stochastic settings simultaneously by our established upper bounds and lower bounds on Pareto regrets. Moreover, the lower bound analyses show that the new regrets are consistent with the existing Pareto regret for stochastic settings and extend an adversarial attack mechanism from bandit to the multi-objective one.",
    "path": "papers/22/12/2212.00884.json",
    "total_tokens": 931,
    "translated_title": "多目标多臂赌博机中的Pareto后悔分析",
    "translated_abstract": "本文研究了多目标多臂赌博机中的Pareto最优性。通过提出对抗性多目标多臂赌博机的表述并定义其Pareto后悔，可以应用于随机和对抗性环境。这些后悔不依赖于任何标量化函数，并反映了与标量化后悔相比的Pareto最优性。同时，我们提出了在有和无先验信息的多目标多臂赌博机环境下的新算法。通过我们对Pareto后悔的上下界分析证明，在对抗性环境中算法是最优的，在随机环境中也接近最优。此外，下界分析表明，新的后悔与随机环境下的现有Pareto后悔一致，并将对抗性攻击机制从赌徒推广到了多目标领域。",
    "tldr": "本文研究了多目标多臂赌博机中的Pareto最优性，提出了对抗性多目标多臂赌博机的表述和定义了Pareto后悔，提出了新算法，分析证明算法在对抗性环境最优，在随机环境中也接近最优，并将对抗性攻击机制从赌徒推广到多目标领域。",
    "en_tdlr": "This paper studies Pareto optimality in multi-objective multi-armed bandit, proposes a formulation of adversarial multi-objective multi-armed bandit and defines its Pareto regrets. New algorithms are presented and proven nearly optimal in stochastic settings and optimal in adversarial settings. The new regrets are consistent with existing Pareto regret for stochastic settings and extend an adversarial attack mechanism to the multi-objective one."
}