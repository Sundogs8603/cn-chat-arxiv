{
    "title": "PIVOT: Prompting for Video Continual Learning. (arXiv:2212.04842v2 [cs.CV] UPDATED)",
    "abstract": "Modern machine learning pipelines are limited due to data availability, storage quotas, privacy regulations, and expensive annotation processes. These constraints make it difficult or impossible to train and update large-scale models on such dynamic annotated sets. Continual learning directly approaches this problem, with the ultimate goal of devising methods where a deep neural network effectively learns relevant patterns for new (unseen) classes, without significantly altering its performance on previously learned ones. In this paper, we address the problem of continual learning for video data. We introduce PIVOT, a novel method that leverages extensive knowledge in pre-trained models from the image domain, thereby reducing the number of trainable parameters and the associated forgetting. Unlike previous methods, ours is the first approach that effectively uses prompting mechanisms for continual learning without any in-domain pre-training. Our experiments show that PIVOT improves sta",
    "link": "http://arxiv.org/abs/2212.04842",
    "context": "Title: PIVOT: Prompting for Video Continual Learning. (arXiv:2212.04842v2 [cs.CV] UPDATED)\nAbstract: Modern machine learning pipelines are limited due to data availability, storage quotas, privacy regulations, and expensive annotation processes. These constraints make it difficult or impossible to train and update large-scale models on such dynamic annotated sets. Continual learning directly approaches this problem, with the ultimate goal of devising methods where a deep neural network effectively learns relevant patterns for new (unseen) classes, without significantly altering its performance on previously learned ones. In this paper, we address the problem of continual learning for video data. We introduce PIVOT, a novel method that leverages extensive knowledge in pre-trained models from the image domain, thereby reducing the number of trainable parameters and the associated forgetting. Unlike previous methods, ours is the first approach that effectively uses prompting mechanisms for continual learning without any in-domain pre-training. Our experiments show that PIVOT improves sta",
    "path": "papers/22/12/2212.04842.json",
    "total_tokens": 915,
    "translated_title": "PIVOT：基于提示的视频持续学习方法",
    "translated_abstract": "现代机器学习管道由于数据可用性、存储配额、隐私规定和昂贵的注释过程而受限。这些约束使得在此类动态注释集上训练和更新大规模模型变得困难或不可能。不断学习直接解决了这个问题，其最终目标是设计出方法，在新（未见过的）类别中，深度神经网络能够有效地学习相关模式，而不会对先前学习的类别的表现产生显著影响。在本文中，我们解决了针对视频数据的持续学习问题。我们介绍了PIVOT，这是一种新颖的方法，利用来自图像领域的预训练模型的广泛知识，从而减少了可训练参数的数量以及相应的遗忘。与以前的方法不同，我们的方法是第一种在没有域内预训练的情况下有效使用提示机制进行持续学习的方法。我们的实验结果表明，PIVOT 改善了现有技术的性能。",
    "tldr": "PIVOT 是一种针对视频数据的基于提示的持续学习方法，利用预训练模型减少了可训练参数的数量以及相应的遗忘，并且是第一个能够在无域内预训练情况下有效使用提示机制的方法。",
    "en_tdlr": "PIVOT is a prompting-based continual learning method for video data, which reduces the number of trainable parameters and associated forgetting by leveraging extensive knowledge from pre-trained models in the image domain, and is the first approach that effectively uses prompting mechanisms in continual learning without any in-domain pre-training."
}