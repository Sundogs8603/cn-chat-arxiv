{
    "title": "Fine-grained Image Editing by Pixel-wise Guidance Using Diffusion Models. (arXiv:2212.02024v3 [cs.CV] UPDATED)",
    "abstract": "Our goal is to develop fine-grained real-image editing methods suitable for real-world applications. In this paper, we first summarize four requirements for these methods and propose a novel diffusion-based image editing framework with pixel-wise guidance that satisfies these requirements. Specifically, we train pixel-classifiers with a few annotated data and then infer the segmentation map of a target image. Users then manipulate the map to instruct how the image will be edited. We utilize a pre-trained diffusion model to generate edited images aligned with the user's intention with pixel-wise guidance. The effective combination of proposed guidance and other techniques enables highly controllable editing with preserving the outside of the edited area, which results in meeting our requirements. The experimental results demonstrate that our proposal outperforms the GAN-based method for editing quality and speed.",
    "link": "http://arxiv.org/abs/2212.02024",
    "context": "Title: Fine-grained Image Editing by Pixel-wise Guidance Using Diffusion Models. (arXiv:2212.02024v3 [cs.CV] UPDATED)\nAbstract: Our goal is to develop fine-grained real-image editing methods suitable for real-world applications. In this paper, we first summarize four requirements for these methods and propose a novel diffusion-based image editing framework with pixel-wise guidance that satisfies these requirements. Specifically, we train pixel-classifiers with a few annotated data and then infer the segmentation map of a target image. Users then manipulate the map to instruct how the image will be edited. We utilize a pre-trained diffusion model to generate edited images aligned with the user's intention with pixel-wise guidance. The effective combination of proposed guidance and other techniques enables highly controllable editing with preserving the outside of the edited area, which results in meeting our requirements. The experimental results demonstrate that our proposal outperforms the GAN-based method for editing quality and speed.",
    "path": "papers/22/12/2212.02024.json",
    "total_tokens": 856,
    "translated_title": "基于扩散模型的像素级指导的细粒度图像编辑方法",
    "translated_abstract": "本文旨在开发适用于实际应用的细粒度真实图像编辑方法。我们首先总结了这些方法的四个要求，并提出了一种新的基于扩散的带有像素级指导的图像编辑框架，以满足这些要求。具体而言，我们使用少量带注释数据训练像素分类器，然后推断目标图像的分割映射。然后用户通过操作映射来指导编辑操作。我们利用预训练的扩散模型以像素级指导生成与用户意图相关联的已编辑图像。所提出的指导和其他技术的有效组合实现了高度可控的编辑，并保留编辑区域之外，从而满足我们的要求。实验结果表明，我们的方法在编辑质量和速度方面均优于基于GAN的方法。",
    "tldr": "本文提出了一种基于扩散模型的像素级指导的细粒度图像编辑方法，通过少量带注释数据训练像素分类器和映射编辑操作快速生成满足用户意图的图像，并且编辑结果质量和速度均优于基于GAN的方法。",
    "en_tdlr": "This paper proposes a diffusion-based framework with pixel-wise guidance for fine-grained real-image editing, which utilizes pixel-classifiers to infer the segmentation map of a target image and allows users to manipulate the map to guide the editing process. The proposed method outperforms GAN-based methods in terms of editing quality and speed."
}