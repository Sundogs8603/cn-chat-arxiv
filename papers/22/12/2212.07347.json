{
    "title": "Lorentz group equivariant autoencoders. (arXiv:2212.07347v2 [hep-ex] UPDATED)",
    "abstract": "There has been significant work recently in developing machine learning (ML) models in high energy physics (HEP) for tasks such as classification, simulation, and anomaly detection. Often these models are adapted from those designed for datasets in computer vision or natural language processing, which lack inductive biases suited to HEP data, such as equivariance to its inherent symmetries. Such biases have been shown to make models more performant and interpretable, and reduce the amount of training data needed. To that end, we develop the Lorentz group autoencoder (LGAE), an autoencoder model equivariant with respect to the proper, orthochronous Lorentz group $\\mathrm{SO}^+(3,1)$, with a latent space living in the representations of the group. We present our architecture and several experimental results on jets at the LHC and find it outperforms graph and convolutional neural network baseline models on several compression, reconstruction, and anomaly detection metrics. We also demons",
    "link": "http://arxiv.org/abs/2212.07347",
    "context": "Title: Lorentz group equivariant autoencoders. (arXiv:2212.07347v2 [hep-ex] UPDATED)\nAbstract: There has been significant work recently in developing machine learning (ML) models in high energy physics (HEP) for tasks such as classification, simulation, and anomaly detection. Often these models are adapted from those designed for datasets in computer vision or natural language processing, which lack inductive biases suited to HEP data, such as equivariance to its inherent symmetries. Such biases have been shown to make models more performant and interpretable, and reduce the amount of training data needed. To that end, we develop the Lorentz group autoencoder (LGAE), an autoencoder model equivariant with respect to the proper, orthochronous Lorentz group $\\mathrm{SO}^+(3,1)$, with a latent space living in the representations of the group. We present our architecture and several experimental results on jets at the LHC and find it outperforms graph and convolutional neural network baseline models on several compression, reconstruction, and anomaly detection metrics. We also demons",
    "path": "papers/22/12/2212.07347.json",
    "total_tokens": 949,
    "translated_title": "洛伦兹群等变自编码器",
    "translated_abstract": "近年来，高能物理中使用机器学习（ML）模型进行分类、仿真和异常检测等任务的工作已经取得了显著进展。通常情况下，这些模型是从针对计算机视觉或自然语言处理数据集设计的模型进行改进的，这些模型缺乏适合于高能物理数据的归纳偏差，例如以其固有的对称性等变。这些偏差已被证明可以使模型更加性能优良和可解释，并减少所需的训练数据量。为此，我们开发了洛伦兹群自编码器（LGAE），这是一个自编码器模型，相对于适当的、正交的洛伦兹群$\\mathrm{SO}^+(3,1)$等变，并且潜在空间在群的表示中。我们提出了我们的体系结构，并在LHC的喷注上展示了几个实验结果，并发现它在几个压缩、重构和异常检测指标上优于图形和卷积神经网络基线模型。我们还证明...",
    "tldr": "本论文提出了一种洛伦兹群自编码器（LGAE）模型，它具有上述群的等变性，且在高能物理数据的压缩、重构和异常检测等任务方面表现出色。",
    "en_tdlr": "This paper proposes a Lorentz group equivariant autoencoder (LGAE) model with equivariance to the proper, orthochronous Lorentz group $\\mathrm{SO}^+(3,1)$. The LGAE outperforms graph and convolutional neural network baseline models on several compression, reconstruction, and anomaly detection metrics in high energy physics data."
}