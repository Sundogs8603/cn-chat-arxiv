{
    "title": "Unsupervised Summarization Re-ranking. (arXiv:2212.09593v2 [cs.CL] UPDATED)",
    "abstract": "With the rise of task-specific pre-training objectives, abstractive summarization models like PEGASUS offer appealing zero-shot performance on downstream summarization tasks. However, the performance of such unsupervised models still lags significantly behind their supervised counterparts. Similarly to the supervised setup, we notice a very high variance in quality among summary candidates from these models while only one candidate is kept as the summary output. In this paper, we propose to re-rank summary candidates in an unsupervised manner, aiming to close the performance gap between unsupervised and supervised models. Our approach improves the unsupervised PEGASUS by up to 7.27% and ChatGPT by up to 6.86% relative mean ROUGE across four widely-adopted summarization benchmarks ; and achieves relative gains of 7.51% (up to 23.73% from XSum to WikiHow) averaged over 30 zero-shot transfer setups (finetuning on a dataset, evaluating on another).",
    "link": "http://arxiv.org/abs/2212.09593",
    "context": "Title: Unsupervised Summarization Re-ranking. (arXiv:2212.09593v2 [cs.CL] UPDATED)\nAbstract: With the rise of task-specific pre-training objectives, abstractive summarization models like PEGASUS offer appealing zero-shot performance on downstream summarization tasks. However, the performance of such unsupervised models still lags significantly behind their supervised counterparts. Similarly to the supervised setup, we notice a very high variance in quality among summary candidates from these models while only one candidate is kept as the summary output. In this paper, we propose to re-rank summary candidates in an unsupervised manner, aiming to close the performance gap between unsupervised and supervised models. Our approach improves the unsupervised PEGASUS by up to 7.27% and ChatGPT by up to 6.86% relative mean ROUGE across four widely-adopted summarization benchmarks ; and achieves relative gains of 7.51% (up to 23.73% from XSum to WikiHow) averaged over 30 zero-shot transfer setups (finetuning on a dataset, evaluating on another).",
    "path": "papers/22/12/2212.09593.json",
    "total_tokens": 911,
    "translated_title": "无监督摘要再排序",
    "translated_abstract": "随着任务特定的预训练目标的兴起，像PEGASUS这样的抽象摘要模型在下游摘要任务中提供了令人满意的零样本性能。然而，这些无监督模型的性能仍然明显落后于它们的有监督对应物。本文提出了一种无监督的摘要再排序方法，旨在缩小无监督和有监督模型之间的性能差距。我们的方法在四个被广泛采用的摘要基准测试中，将PEGASUS的相对平均ROUGE提高了最多7.27％，ChatGPT提高了最多6.86％；并且在30种零样本转移设置（在一个数据集上微调，另一个数据集上评估）中，平均获得了7.51％的相对增益（从XSum到WikiHow最高可达23.73％）。",
    "tldr": "该论文提出了一种无监督的摘要再排序方法，可以将无监督模型的摘要表现提高，缩小其与有监督模型之间的性能差距。",
    "en_tdlr": "This paper proposes an unsupervised summarization re-ranking approach to improve unsupervised models and bridge the performance gap between unsupervised and supervised models. By re-ranking summary candidates, relative improvements of up to 7.27% and 6.86% are achieved on PEGASUS and ChatGPT, respectively, and average relative gains of 7.51% (up to 23.73% on XSum to WikiHow) are observed over 30 zero-shot transfer setups."
}