{
    "title": "Integrating Multimodal Data for Joint Generative Modeling of Complex Dynamics",
    "abstract": "arXiv:2212.07892v2 Announce Type: replace  Abstract: Many, if not most, systems of interest in science are naturally described as nonlinear dynamical systems. Empirically, we commonly access these systems through time series measurements. Often such time series may consist of discrete random variables rather than continuous measurements, or may be composed of measurements from multiple data modalities observed simultaneously. For instance, in neuroscience we may have behavioral labels in addition to spike counts and continuous physiological recordings. While by now there is a burgeoning literature on deep learning for dynamical systems reconstruction (DSR), multimodal data integration has hardly been considered in this context. Here we provide such an efficient and flexible algorithmic framework that rests on a multimodal variational autoencoder for generating a sparse teacher signal that guides training of a reconstruction model, exploiting recent advances in DSR training techniques. ",
    "link": "https://arxiv.org/abs/2212.07892",
    "context": "Title: Integrating Multimodal Data for Joint Generative Modeling of Complex Dynamics\nAbstract: arXiv:2212.07892v2 Announce Type: replace  Abstract: Many, if not most, systems of interest in science are naturally described as nonlinear dynamical systems. Empirically, we commonly access these systems through time series measurements. Often such time series may consist of discrete random variables rather than continuous measurements, or may be composed of measurements from multiple data modalities observed simultaneously. For instance, in neuroscience we may have behavioral labels in addition to spike counts and continuous physiological recordings. While by now there is a burgeoning literature on deep learning for dynamical systems reconstruction (DSR), multimodal data integration has hardly been considered in this context. Here we provide such an efficient and flexible algorithmic framework that rests on a multimodal variational autoencoder for generating a sparse teacher signal that guides training of a reconstruction model, exploiting recent advances in DSR training techniques. ",
    "path": "papers/22/12/2212.07892.json",
    "total_tokens": 793,
    "translated_title": "整合多模态数据用于复杂动力学的联合生成建模",
    "translated_abstract": "许多科学中感兴趣的系统本质上是非线性动力系统。通常，我们通过时间序列测量来访问这些系统。这些时间序列可能由离散随机变量而非连续测量组成，或者可能由同时观察到的多个数据模态的测量组成。在神经科学中，我们可能除了脉冲计数和连续生理记录外，还有行为标签。虽然现在关于深度学习用于动态系统重建的文献正在蓬勃发展，但多模态数据集成在这个背景下几乎没有被考虑。在这里，我们提供了一个基于多模态变分自动编码器的高效灵活算法框架，用于生成稀疏教师信号，指导重建模型的训练，利用了DSR训练技术的最新进展。",
    "tldr": "提出了一种基于多模态变分自动编码器的算法框架，用于联合生成建模复杂动力学，引导重建模型训练。",
    "en_tdlr": "Proposed an algorithmic framework based on multimodal variational autoencoder for joint generative modeling of complex dynamics, guiding the training of reconstruction model."
}