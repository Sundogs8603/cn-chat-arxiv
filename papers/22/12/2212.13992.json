{
    "title": "Social-Aware Clustered Federated Learning with Customized Privacy Preservation",
    "abstract": "arXiv:2212.13992v2 Announce Type: replace-cross  Abstract: A key feature of federated learning (FL) is to preserve the data privacy of end users. However, there still exist potential privacy leakage in exchanging gradients under FL. As a result, recent research often explores the differential privacy (DP) approaches to add noises to the computing results to address privacy concerns with low overheads, which however degrade the model performance. In this paper, we strike the balance of data privacy and efficiency by utilizing the pervasive social connections between users. Specifically, we propose SCFL, a novel Social-aware Clustered Federated Learning scheme, where mutually trusted individuals can freely form a social cluster and aggregate their raw model updates (e.g., gradients) inside each cluster before uploading to the cloud for global aggregation. By mixing model updates in a social group, adversaries can only eavesdrop the social-layer combined results, but not the privacy of in",
    "link": "https://arxiv.org/abs/2212.13992",
    "context": "Title: Social-Aware Clustered Federated Learning with Customized Privacy Preservation\nAbstract: arXiv:2212.13992v2 Announce Type: replace-cross  Abstract: A key feature of federated learning (FL) is to preserve the data privacy of end users. However, there still exist potential privacy leakage in exchanging gradients under FL. As a result, recent research often explores the differential privacy (DP) approaches to add noises to the computing results to address privacy concerns with low overheads, which however degrade the model performance. In this paper, we strike the balance of data privacy and efficiency by utilizing the pervasive social connections between users. Specifically, we propose SCFL, a novel Social-aware Clustered Federated Learning scheme, where mutually trusted individuals can freely form a social cluster and aggregate their raw model updates (e.g., gradients) inside each cluster before uploading to the cloud for global aggregation. By mixing model updates in a social group, adversaries can only eavesdrop the social-layer combined results, but not the privacy of in",
    "path": "papers/22/12/2212.13992.json",
    "total_tokens": 862,
    "translated_title": "具有定制隐私保护的社交感知聚类联邦学习",
    "translated_abstract": "联邦学习（FL）的一个关键特性是保护端用户的数据隐私。然而，在FL中仍然存在通过交换梯度可能导致的潜在隐私泄漏。因此，最近的研究通常探讨微分隐私（DP）方法，通过向计算结果添加噪声来解决隐私问题，并具有较低的开销，但这些方法会降低模型性能。本文通过利用用户之间的普遍社交连接，平衡了数据隐私和效率。具体来说，我们提出了一种新颖的社交感知聚类联邦学习方案SCFL，其中相互信任的个体可以自由组成一个社交集群，并在每个集群内聚合他们的原始模型更新（例如梯度），然后上传到云端进行全局聚合。通过在社交群体中混合模型更新，对手只能窃听社交层组合的结果，而无法窃听到个体隐私。",
    "tldr": "通过利用用户之间的社交关系，提出了SCFL，一种具有定制隐私保护的社交感知聚类联邦学习方案，实现了数据隐私和效率之间的平衡。"
}