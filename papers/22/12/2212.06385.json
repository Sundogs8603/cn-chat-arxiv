{
    "title": "TencentPretrain: A Scalable and Flexible Toolkit for Pre-training Models of Different Modalities. (arXiv:2212.06385v2 [cs.CL] UPDATED)",
    "abstract": "Recently, the success of pre-training in text domain has been fully extended to vision, audio, and cross-modal scenarios. The proposed pre-training models of different modalities are showing a rising trend of homogeneity in their model structures, which brings the opportunity to implement different pre-training models within a uniform framework. In this paper, we present TencentPretrain, a toolkit supporting pre-training models of different modalities. The core feature of TencentPretrain is the modular design. The toolkit uniformly divides pre-training models into 5 components: embedding, encoder, target embedding, decoder, and target. As almost all of common modules are provided in each component, users can choose the desired modules from different components to build a complete pre-training model. The modular design enables users to efficiently reproduce existing pre-training models or build brand-new one. We test the toolkit on text, vision, and audio benchmarks and show that it can",
    "link": "http://arxiv.org/abs/2212.06385",
    "context": "Title: TencentPretrain: A Scalable and Flexible Toolkit for Pre-training Models of Different Modalities. (arXiv:2212.06385v2 [cs.CL] UPDATED)\nAbstract: Recently, the success of pre-training in text domain has been fully extended to vision, audio, and cross-modal scenarios. The proposed pre-training models of different modalities are showing a rising trend of homogeneity in their model structures, which brings the opportunity to implement different pre-training models within a uniform framework. In this paper, we present TencentPretrain, a toolkit supporting pre-training models of different modalities. The core feature of TencentPretrain is the modular design. The toolkit uniformly divides pre-training models into 5 components: embedding, encoder, target embedding, decoder, and target. As almost all of common modules are provided in each component, users can choose the desired modules from different components to build a complete pre-training model. The modular design enables users to efficiently reproduce existing pre-training models or build brand-new one. We test the toolkit on text, vision, and audio benchmarks and show that it can",
    "path": "papers/22/12/2212.06385.json",
    "total_tokens": 939,
    "translated_title": "TencentPretrain:一种可扩展和灵活的不同模态预训练模型工具包",
    "translated_abstract": "最近，文本领域中预训练的成功已经完全扩展到视觉、音频和跨模态的场景。提出的不同模态的预训练模型在其模型结构上呈现出越来越趋同的趋势，这为在统一框架内实现不同的预训练模型提供了机会。在本文中，我们提出了TencentPretrain，一个支持不同模态预训练模型的工具包。TencentPretrain的核心特性是模块化设计。该工具包将预训练模型统一划分为5个组件：嵌入、编码器、目标嵌入、解码器和目标。由于每个组件中提供了几乎所有常见的模块，用户可以从不同的组件中选择所需的模块来构建完整的预训练模型。模块化设计使用户能够高效地复现现有的预训练模型或构建全新的模型。我们在文本、视觉和音频基准测试上对该工具包进行了测试，并展示了它的可行性。",
    "tldr": "TencentPretrain是一个支持不同模态预训练模型的工具包，具有灵活的模块化设计，用户可以根据自己的需求选择组件和模块来构建预训练模型。在文本、视觉和音频基准测试中验证了其有效性。",
    "en_tdlr": "TencentPretrain is a toolkit that supports pre-training models of different modalities with flexible modular design. Users can select components and modules to build pre-training models according to their needs. Its effectiveness has been validated in text, vision, and audio benchmarks."
}