{
    "title": "Harnessing the Power of Multi-Task Pretraining for Ground-Truth Level Natural Language Explanations. (arXiv:2212.04231v2 [cs.CV] UPDATED)",
    "abstract": "Natural language explanations promise to offer intuitively understandable explanations of a neural network's decision process in complex vision-language tasks, as pursued in recent VL-NLE models. While current models offer impressive performance on task accuracy and explanation plausibility, they suffer from a range of issues: Some models feature a modular design where the explanation generation module is poorly integrated with a separate module for task-answer prediction, employ backbone models trained on limited sets of tasks, or incorporate ad hoc solutions to increase performance on single datasets. We propose to evade these limitations by applying recent advances in large-scale multi-task pretraining of generative Transformer models to the problem of VL-NLE tasks. Our approach outperforms recent models by a large margin, with human annotators preferring the generated explanations over the ground truth in two out of three evaluated datasets. As a novel challenge in VL-NLE research,",
    "link": "http://arxiv.org/abs/2212.04231",
    "context": "Title: Harnessing the Power of Multi-Task Pretraining for Ground-Truth Level Natural Language Explanations. (arXiv:2212.04231v2 [cs.CV] UPDATED)\nAbstract: Natural language explanations promise to offer intuitively understandable explanations of a neural network's decision process in complex vision-language tasks, as pursued in recent VL-NLE models. While current models offer impressive performance on task accuracy and explanation plausibility, they suffer from a range of issues: Some models feature a modular design where the explanation generation module is poorly integrated with a separate module for task-answer prediction, employ backbone models trained on limited sets of tasks, or incorporate ad hoc solutions to increase performance on single datasets. We propose to evade these limitations by applying recent advances in large-scale multi-task pretraining of generative Transformer models to the problem of VL-NLE tasks. Our approach outperforms recent models by a large margin, with human annotators preferring the generated explanations over the ground truth in two out of three evaluated datasets. As a novel challenge in VL-NLE research,",
    "path": "papers/22/12/2212.04231.json",
    "total_tokens": 864,
    "translated_title": "利用多任务预训练技术，提升自然语言解释的准确性",
    "translated_abstract": "在复杂的视觉语言任务中，自然语言解释能够提供对神经网络决策过程的直观理解。当前的VL-NLE模型在任务准确性和解释可信度上表现出色。然而，它们存在一系列问题：一些模型设计上存在缺陷，解释生成模块与任务答案预测模块集成不良；在训练骨干模型时，存在训练数据集较小的情况；模型采用临时性的解决方案来在单个数据集上提高性能等。我们提出了一种解决方案，利用最新的大规模多任务预训练生成Transformer模型的技术来应对VL-NLE任务的问题。我们的方法大大优于最近的模型，在三个评估数据集中，人类注释员更倾向于使用我们生成的解释而非真实解释。这是VL-NLE研究中的一项新挑战。",
    "tldr": "本文提出了一种新的解决方案利用多任务预训练生成Transformer模型的技术来应对VL-NLE任务的问题，有效提高了解释的准确性和可信度，具有良好的应用前景。"
}