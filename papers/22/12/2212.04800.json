{
    "title": "AUC Maximization for Low-Resource Named Entity Recognition. (arXiv:2212.04800v3 [cs.CL] UPDATED)",
    "abstract": "Current work in named entity recognition (NER) uses either cross entropy (CE) or conditional random fields (CRF) as the objective/loss functions to optimize the underlying NER model. Both of these traditional objective functions for the NER problem generally produce adequate performance when the data distribution is balanced and there are sufficient annotated training examples. But since NER is inherently an imbalanced tagging problem, the model performance under the low-resource settings could suffer using these standard objective functions. Based on recent advances in area under the ROC curve (AUC) maximization, we propose to optimize the NER model by maximizing the AUC score. We give evidence that by simply combining two binary-classifiers that maximize the AUC score, significant performance improvement over traditional loss functions is achieved under low-resource NER settings. We also conduct extensive experiments to demonstrate the advantages of our method under the low-resource ",
    "link": "http://arxiv.org/abs/2212.04800",
    "context": "Title: AUC Maximization for Low-Resource Named Entity Recognition. (arXiv:2212.04800v3 [cs.CL] UPDATED)\nAbstract: Current work in named entity recognition (NER) uses either cross entropy (CE) or conditional random fields (CRF) as the objective/loss functions to optimize the underlying NER model. Both of these traditional objective functions for the NER problem generally produce adequate performance when the data distribution is balanced and there are sufficient annotated training examples. But since NER is inherently an imbalanced tagging problem, the model performance under the low-resource settings could suffer using these standard objective functions. Based on recent advances in area under the ROC curve (AUC) maximization, we propose to optimize the NER model by maximizing the AUC score. We give evidence that by simply combining two binary-classifiers that maximize the AUC score, significant performance improvement over traditional loss functions is achieved under low-resource NER settings. We also conduct extensive experiments to demonstrate the advantages of our method under the low-resource ",
    "path": "papers/22/12/2212.04800.json",
    "total_tokens": 858,
    "translated_title": "低资源命名实体识别中的AUC最大化",
    "translated_abstract": "目前命名实体识别领域的工作使用交叉熵（CE）或条件随机场（CRF）作为优化NER模型的目标/损失函数。然而，这两种传统的NER问题的目标函数通常在数据分布平衡，并且有足够的注释训练样例时可以产生足够的性能。但由于NER本质上是一个不平衡的标记问题，在低资源情况下使用这些标准目标函数时，模型性能可能会受到影响。基于最大化ROC曲线下面积（AUC）的最新进展，我们提出通过最大化AUC分数来优化NER模型。我们提供证据表明，通过简单地结合两个最大化AUC分数的二进制分类器，在低资源NER设置下实现了显着的性能提高，优于传统的损失函数。我们还进行了广泛的实验，以展示我们的方法在低资源情况下的优势。",
    "tldr": "本文提出了在低资源命名实体识别中使用AUC最大化的方法，通过结合两个最大化AUC分数的二进制分类器，在低资源NER设置下实现了显着的性能提高，优于传统的损失函数。",
    "en_tdlr": "This paper proposes to use AUC maximization for low-resource named entity recognition, which achieves significant performance improvement over traditional loss functions by combining two binary-classifiers that maximize the AUC score."
}