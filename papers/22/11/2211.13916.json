{
    "title": "Towards Good Practices for Missing Modality Robust Action Recognition. (arXiv:2211.13916v2 [cs.CV] UPDATED)",
    "abstract": "Standard multi-modal models assume the use of the same modalities in training and inference stages. However, in practice, the environment in which multi-modal models operate may not satisfy such assumption. As such, their performances degrade drastically if any modality is missing in the inference stage. We ask: how can we train a model that is robust to missing modalities? This paper seeks a set of good practices for multi-modal action recognition, with a particular interest in circumstances where some modalities are not available at an inference time. First, we study how to effectively regularize the model during training (e.g., data augmentation). Second, we investigate on fusion methods for robustness to missing modalities: we find that transformer-based fusion shows better robustness for missing modality than summation or concatenation. Third, we propose a simple modular network, ActionMAE, which learns missing modality predictive coding by randomly dropping modality features and ",
    "link": "http://arxiv.org/abs/2211.13916",
    "context": "Title: Towards Good Practices for Missing Modality Robust Action Recognition. (arXiv:2211.13916v2 [cs.CV] UPDATED)\nAbstract: Standard multi-modal models assume the use of the same modalities in training and inference stages. However, in practice, the environment in which multi-modal models operate may not satisfy such assumption. As such, their performances degrade drastically if any modality is missing in the inference stage. We ask: how can we train a model that is robust to missing modalities? This paper seeks a set of good practices for multi-modal action recognition, with a particular interest in circumstances where some modalities are not available at an inference time. First, we study how to effectively regularize the model during training (e.g., data augmentation). Second, we investigate on fusion methods for robustness to missing modalities: we find that transformer-based fusion shows better robustness for missing modality than summation or concatenation. Third, we propose a simple modular network, ActionMAE, which learns missing modality predictive coding by randomly dropping modality features and ",
    "path": "papers/22/11/2211.13916.json",
    "total_tokens": 854,
    "tldr": "本文提出了针对缺失模态的多模态动作识别的良好实践，包括数据扩增、基于transformer的融合方法和ActionMAE网络。",
    "en_tdlr": "This paper proposes good practices for multi-modal action recognition with missing modalities, including data augmentation, transformer-based fusion, and ActionMAE network that learns predictive coding by randomly dropping modality features."
}