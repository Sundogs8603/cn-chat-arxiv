{
    "title": "Neural networks trained with SGD learn distributions of increasing complexity. (arXiv:2211.11567v2 [stat.ML] UPDATED)",
    "abstract": "The ability of deep neural networks to generalise well even when they interpolate their training data has been explained using various \"simplicity biases\". These theories postulate that neural networks avoid overfitting by first learning simple functions, say a linear classifier, before learning more complex, non-linear functions. Meanwhile, data structure is also recognised as a key ingredient for good generalisation, yet its role in simplicity biases is not yet understood. Here, we show that neural networks trained using stochastic gradient descent initially classify their inputs using lower-order input statistics, like mean and covariance, and exploit higher-order statistics only later during training. We first demonstrate this distributional simplicity bias (DSB) in a solvable model of a neural network trained on synthetic data. We empirically demonstrate DSB in a range of deep convolutional networks and visual transformers trained on CIFAR10, and show that it even holds in network",
    "link": "http://arxiv.org/abs/2211.11567",
    "context": "Title: Neural networks trained with SGD learn distributions of increasing complexity. (arXiv:2211.11567v2 [stat.ML] UPDATED)\nAbstract: The ability of deep neural networks to generalise well even when they interpolate their training data has been explained using various \"simplicity biases\". These theories postulate that neural networks avoid overfitting by first learning simple functions, say a linear classifier, before learning more complex, non-linear functions. Meanwhile, data structure is also recognised as a key ingredient for good generalisation, yet its role in simplicity biases is not yet understood. Here, we show that neural networks trained using stochastic gradient descent initially classify their inputs using lower-order input statistics, like mean and covariance, and exploit higher-order statistics only later during training. We first demonstrate this distributional simplicity bias (DSB) in a solvable model of a neural network trained on synthetic data. We empirically demonstrate DSB in a range of deep convolutional networks and visual transformers trained on CIFAR10, and show that it even holds in network",
    "path": "papers/22/11/2211.11567.json",
    "total_tokens": 953,
    "translated_title": "使用随机梯度下降算法训练的神经网络学习日益复杂的分布",
    "translated_abstract": "深度神经网络即使在插值训练数据时也能很好地进行泛化的能力已经通过各种“简单性偏差”得到了解释。这些理论假设神经网络在学习更复杂的非线性函数之前先学习简单函数，例如线性分类器。同时，数据结构也被认为是良好泛化的关键因素，然而，数据结构在简单性偏差中的作用尚未被理解。本文中，我们展示了使用随机梯度下降算法训练的神经网络最初使用低阶输入统计（如均值和协方差）来对其输入进行分类，只有在训练后期才利用更高阶的统计信息。我们首先在神经网络对合成数据进行训练的可解模型中展示了这种分布式简单性偏差（DSB）。然后，我们在训练于CIFAR10上的一系列深度卷积网络和视觉转换器中经验性地证明了DSB，甚至发现该偏差在更大的数据集和更广泛的神经网络体系结构中也存在。",
    "tldr": "本文证明了随机梯度下降算法训练的神经网络在学习期间会出现分布式简单性偏差（DSB），即最初使用低阶输入统计来分类输入，只有在训练后期才利用更高阶的统计信息。",
    "en_tdlr": "This paper demonstrates the existence of Distributional Simplicity Bias (DSB) in neural networks trained with stochastic gradient descent, where the networks initially classify inputs using lower-order statistics before utilizing higher-order statistics later in training."
}