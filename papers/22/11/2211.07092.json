{
    "title": "Offline Estimation of Controlled Markov Chains: Minimaxity and Sample Complexity. (arXiv:2211.07092v4 [stat.ML] UPDATED)",
    "abstract": "In this work, we study a natural nonparametric estimator of the transition probability matrices of a finite controlled Markov chain. We consider an offline setting with a fixed dataset, collected using a so-called logging policy. We develop sample complexity bounds for the estimator and establish conditions for minimaxity. Our statistical bounds depend on the logging policy through its mixing properties. We show that achieving a particular statistical risk bound involves a subtle and interesting trade-off between the strength of the mixing properties and the number of samples. We demonstrate the validity of our results under various examples, such as ergodic Markov chains, weakly ergodic inhomogeneous Markov chains, and controlled Markov chains with non-stationary Markov, episodic, and greedy controls. Lastly, we use these sample complexity bounds to establish concomitant ones for offline evaluation of stationary Markov control policies.",
    "link": "http://arxiv.org/abs/2211.07092",
    "context": "Title: Offline Estimation of Controlled Markov Chains: Minimaxity and Sample Complexity. (arXiv:2211.07092v4 [stat.ML] UPDATED)\nAbstract: In this work, we study a natural nonparametric estimator of the transition probability matrices of a finite controlled Markov chain. We consider an offline setting with a fixed dataset, collected using a so-called logging policy. We develop sample complexity bounds for the estimator and establish conditions for minimaxity. Our statistical bounds depend on the logging policy through its mixing properties. We show that achieving a particular statistical risk bound involves a subtle and interesting trade-off between the strength of the mixing properties and the number of samples. We demonstrate the validity of our results under various examples, such as ergodic Markov chains, weakly ergodic inhomogeneous Markov chains, and controlled Markov chains with non-stationary Markov, episodic, and greedy controls. Lastly, we use these sample complexity bounds to establish concomitant ones for offline evaluation of stationary Markov control policies.",
    "path": "papers/22/11/2211.07092.json",
    "total_tokens": 1040,
    "translated_title": "离线估计控制马尔可夫链：最小化和样本复杂度",
    "translated_abstract": "在这项工作中，我们研究了有限控制马尔可夫链的转移概率矩阵的自然非参数估计器。我们考虑了一个固定数据集的离线设置，该数据集是使用所谓的记录策略收集的。我们为估计器开发了样本复杂性的界限，并建立了最小化的条件。我们的统计界限通过记录策略的混合特性来确定。我们表明，实现特定的统计风险界限涉及到混合特性的强度和样本数量之间微妙而有趣的权衡。我们在各种示例中验证了我们结果的有效性，包括遗传马尔可夫链，弱遗传非齐次马尔可夫链和具有非平稳马尔可夫、阶段性和贪婪控制的控制马尔可夫链。最后，我们使用这些样本复杂性界限来建立离线评估恒定马尔可夫控制策略的相关界限。",
    "tldr": "本论文研究了离线估计有限控制马尔可夫链的转移概率矩阵的非参数估计器，并通过记录策略的混合特性建立了样本复杂性界限和最小化条件。结果表明，实现特定的统计风险界限涉及到混合特性的强度和样本数量之间微妙而有趣的权衡。还使用这些样本复杂性界限建立了离线评估恒定马尔可夫控制策略的相关界限。",
    "en_tdlr": "This paper investigates a nonparametric estimator for the transition probability matrices of a finite controlled Markov chain in an offline setting. The study establishes sample complexity bounds and conditions for minimaxity, revealing a trade-off between the strength of mixing properties and the number of samples. The findings are demonstrated in various examples, including different types of Markov chains. Moreover, the results are used to establish concomitant bounds for offline evaluation of stationary Markov control policies."
}