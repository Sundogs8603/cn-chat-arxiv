{
    "title": "Examining the Differential Risk from High-level Artificial Intelligence and the Question of Control. (arXiv:2211.03157v3 [cs.AI] UPDATED)",
    "abstract": "Artificial Intelligence (AI) is one of the most transformative technologies of the 21st century. The extent and scope of future AI capabilities remain a key uncertainty, with widespread disagreement on timelines and potential impacts. As nations and technology companies race toward greater complexity and autonomy in AI systems, there are concerns over the extent of integration and oversight of opaque AI decision processes. This is especially true in the subfield of machine learning (ML), where systems learn to optimize objectives without human assistance. Objectives can be imperfectly specified or executed in an unexpected or potentially harmful way. This becomes more concerning as systems increase in power and autonomy, where an abrupt capability jump could result in unexpected shifts in power dynamics or even catastrophic failures. This study presents a hierarchical complex systems framework to model AI risk and provide a template for alternative futures analysis. Survey data were co",
    "link": "http://arxiv.org/abs/2211.03157",
    "context": "Title: Examining the Differential Risk from High-level Artificial Intelligence and the Question of Control. (arXiv:2211.03157v3 [cs.AI] UPDATED)\nAbstract: Artificial Intelligence (AI) is one of the most transformative technologies of the 21st century. The extent and scope of future AI capabilities remain a key uncertainty, with widespread disagreement on timelines and potential impacts. As nations and technology companies race toward greater complexity and autonomy in AI systems, there are concerns over the extent of integration and oversight of opaque AI decision processes. This is especially true in the subfield of machine learning (ML), where systems learn to optimize objectives without human assistance. Objectives can be imperfectly specified or executed in an unexpected or potentially harmful way. This becomes more concerning as systems increase in power and autonomy, where an abrupt capability jump could result in unexpected shifts in power dynamics or even catastrophic failures. This study presents a hierarchical complex systems framework to model AI risk and provide a template for alternative futures analysis. Survey data were co",
    "path": "papers/22/11/2211.03157.json",
    "total_tokens": 944,
    "translated_title": "检验高级人工智能差异风险和控制问题",
    "translated_abstract": "人工智能（AI）是21世纪最具变革性的技术之一。未来AI能力的程度和范围仍存在关键不确定性，各方对时间表和潜在影响有不同的看法。随着国家和技术公司竞相追求更复杂和自主的AI系统，人们担心半透明AI决策过程的集成和监督程度。这在机器学习（ML）领域尤其如此，其中系统学习优化目标而无需人类帮助。目标可能无法完美地制定或以意外或潜在有害的方式执行。随着系统增加功率和自主性，这变得更加令人担忧，一个突然的能力跃升可能导致权力动态意外转变甚至灾难性故障。本研究提出了一个层次化复杂系统框架来模拟AI风险，并提供替代未来分析的模板。",
    "tldr": "本研究提出了基于层次化复杂系统框架的模型，用于模拟风险和提供未来分析模板，深入探讨了机器学习领域的AI决策透明度和集成度的担忧，并强调了增强系统能力和自治性可能会导致权力动态的意外改变或灾难性故障。",
    "en_tdlr": "This study proposes a hierarchical complex systems framework to model AI risk and provide a template for alternative futures analysis. It discusses concerns over the integration and oversight of opaque AI decision processes, particularly in the field of machine learning, and emphasizes the potential for abrupt changes in power dynamics or catastrophic failures as systems increase in power and autonomy."
}