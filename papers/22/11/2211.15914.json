{
    "title": "Prompted Opinion Summarization with GPT-3.5. (arXiv:2211.15914v2 [cs.CL] UPDATED)",
    "abstract": "Large language models have shown impressive performance across a wide variety of tasks, including text summarization. In this paper, we show that this strong performance extends to opinion summarization. We explore several pipeline methods for applying GPT-3.5 to summarize a large collection of user reviews in a prompted fashion. To handle arbitrarily large numbers of user reviews, we explore recursive summarization as well as methods for selecting salient content to summarize through supervised clustering or extraction. On two datasets, an aspect-oriented summarization dataset of hotel reviews (SPACE) and a generic summarization dataset of Amazon and Yelp reviews (FewSum), we show that GPT-3.5 models achieve very strong performance in human evaluation. We argue that standard evaluation metrics do not reflect this, and introduce three new metrics targeting faithfulness, factuality, and genericity to contrast these different methods.",
    "link": "http://arxiv.org/abs/2211.15914",
    "context": "Title: Prompted Opinion Summarization with GPT-3.5. (arXiv:2211.15914v2 [cs.CL] UPDATED)\nAbstract: Large language models have shown impressive performance across a wide variety of tasks, including text summarization. In this paper, we show that this strong performance extends to opinion summarization. We explore several pipeline methods for applying GPT-3.5 to summarize a large collection of user reviews in a prompted fashion. To handle arbitrarily large numbers of user reviews, we explore recursive summarization as well as methods for selecting salient content to summarize through supervised clustering or extraction. On two datasets, an aspect-oriented summarization dataset of hotel reviews (SPACE) and a generic summarization dataset of Amazon and Yelp reviews (FewSum), we show that GPT-3.5 models achieve very strong performance in human evaluation. We argue that standard evaluation metrics do not reflect this, and introduce three new metrics targeting faithfulness, factuality, and genericity to contrast these different methods.",
    "path": "papers/22/11/2211.15914.json",
    "total_tokens": 855,
    "translated_title": "GPT-3.5下的提示意见摘要化",
    "translated_abstract": "大型语言模型在各种任务中展现出了惊人的性能，包括文本摘要。本文展示了这种强大性能扩展到了意见摘要。我们探索了几种 GPT-3.5 应用于提示方式下对大量用户评论进行摘要的流水线方法。为了处理任意数量的用户评论，我们探索了递归摘要以及通过监督聚类或抽取选择显著内容进行摘要的方法。在两个数据集上（一个是酒店评论的方面导向的摘要数据集（SPACE），另一个是关于亚马逊和 Yelp 评论的通用摘要数据集（FewSum）），我们展示了 GPT-3.5 模型在人类评估中表现出了非常强大的性能。我们认为标准评估指标不能反映这一点，并引入了三个新的指标，以对比这些不同的方法，分别针对忠诚度、事实性和通用性。",
    "tldr": "本文展示了使用GPT-3.5模型实现意见摘要的方法，通过递归摘要和显著内容选择的方式来处理大量用户评论，并使用三个新的评估指标来评估性能。",
    "en_tdlr": "This paper demonstrates the method of using GPT-3.5 model for opinion summarization by handling large amounts of user reviews through recursive summarization and selecting salient content, and introduces three new evaluation metrics to assess performance."
}