{
    "title": "Peekaboo: Text to Image Diffusion Models are Zero-Shot Segmentors. (arXiv:2211.13224v2 [cs.CV] UPDATED)",
    "abstract": "Recently, text-to-image diffusion models have shown remarkable capabilities in creating realistic images from natural language prompts. However, few works have explored using these models for semantic localization or grounding. In this work, we explore how an off-the-shelf text-to-image diffusion model, trained without exposure to localization information, can ground various semantic phrases without segmentation-specific re-training. We introduce an inference time optimization process capable of generating segmentation masks conditioned on natural language prompts. Our proposal, Peekaboo, is a first-of-its-kind zero-shot, open-vocabulary, unsupervised semantic grounding technique leveraging diffusion models without any training. We evaluate Peekaboo on the Pascal VOC dataset for unsupervised semantic segmentation and the RefCOCO dataset for referring segmentation, showing results competitive with promising results. We also demonstrate how Peekaboo can be used to generate images with tr",
    "link": "http://arxiv.org/abs/2211.13224",
    "context": "Title: Peekaboo: Text to Image Diffusion Models are Zero-Shot Segmentors. (arXiv:2211.13224v2 [cs.CV] UPDATED)\nAbstract: Recently, text-to-image diffusion models have shown remarkable capabilities in creating realistic images from natural language prompts. However, few works have explored using these models for semantic localization or grounding. In this work, we explore how an off-the-shelf text-to-image diffusion model, trained without exposure to localization information, can ground various semantic phrases without segmentation-specific re-training. We introduce an inference time optimization process capable of generating segmentation masks conditioned on natural language prompts. Our proposal, Peekaboo, is a first-of-its-kind zero-shot, open-vocabulary, unsupervised semantic grounding technique leveraging diffusion models without any training. We evaluate Peekaboo on the Pascal VOC dataset for unsupervised semantic segmentation and the RefCOCO dataset for referring segmentation, showing results competitive with promising results. We also demonstrate how Peekaboo can be used to generate images with tr",
    "path": "papers/22/11/2211.13224.json",
    "total_tokens": 986,
    "translated_title": "Peekaboo：文本到图像扩散模型是零-shot细分器",
    "translated_abstract": "最近，文本到图像扩散模型展示了在从自然语言提示中创建逼真图像方面的显着能力。然而，鲜有研究探讨如何利用这些模型进行语义定位或基础。在这项工作中，我们探讨了一个现成的文本到图像扩散模型，它没有接触到本地化信息的训练如何在无需细分特定重新训练的情况下，以自然语言提示为条件建立各种语义短语。我们引入了一个推理时间优化过程，能够在与自然语言提示相关联的情况下生成分割掩模。我们的提议——Peekaboo，是一种首款无训练开放词汇无监督语义接地技术，利用扩散模型。我们在Pascal VOC数据集上对Peekaboo进行了评估，用于无监督语义细分，以及在RefCOCO数据集上对其进行了评估，用于引用细分，显示具有有希望的结果的竞争优势。我们还展示了如何使用Peekaboo通过条件自然语言提示来生成带透明背景的图像。",
    "tldr": "本文介绍了一种名为Peekaboo的技术，可以用于使用现成的文本到图像扩散模型进行无监督语义细分并基础，而无需任何重新培训。这项技术的推理时间优化过程可以在与自然语言提示相关联的情况下生成分割掩模。",
    "en_tdlr": "This paper introduces a technique called Peekaboo, which can be used for unsupervised semantic segmentation and grounding using an off-the-shelf text-to-image diffusion model without any retraining. The inference time optimization process of this technique can generate segmentation masks based on natural language prompts."
}