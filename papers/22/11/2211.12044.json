{
    "title": "Backdoor Cleansing with Unlabeled Data. (arXiv:2211.12044v3 [cs.LG] UPDATED)",
    "abstract": "Due to the increasing computational demand of Deep Neural Networks (DNNs), companies and organizations have begun to outsource the training process. However, the externally trained DNNs can potentially be backdoor attacked. It is crucial to defend against such attacks, i.e., to postprocess a suspicious model so that its backdoor behavior is mitigated while its normal prediction power on clean inputs remain uncompromised. To remove the abnormal backdoor behavior, existing methods mostly rely on additional labeled clean samples. However, such requirement may be unrealistic as the training data are often unavailable to end users. In this paper, we investigate the possibility of circumventing such barrier. We propose a novel defense method that does not require training labels. Through a carefully designed layer-wise weight re-initialization and knowledge distillation, our method can effectively cleanse backdoor behaviors of a suspicious network with negligible compromise in its normal beh",
    "link": "http://arxiv.org/abs/2211.12044",
    "context": "Title: Backdoor Cleansing with Unlabeled Data. (arXiv:2211.12044v3 [cs.LG] UPDATED)\nAbstract: Due to the increasing computational demand of Deep Neural Networks (DNNs), companies and organizations have begun to outsource the training process. However, the externally trained DNNs can potentially be backdoor attacked. It is crucial to defend against such attacks, i.e., to postprocess a suspicious model so that its backdoor behavior is mitigated while its normal prediction power on clean inputs remain uncompromised. To remove the abnormal backdoor behavior, existing methods mostly rely on additional labeled clean samples. However, such requirement may be unrealistic as the training data are often unavailable to end users. In this paper, we investigate the possibility of circumventing such barrier. We propose a novel defense method that does not require training labels. Through a carefully designed layer-wise weight re-initialization and knowledge distillation, our method can effectively cleanse backdoor behaviors of a suspicious network with negligible compromise in its normal beh",
    "path": "papers/22/11/2211.12044.json",
    "total_tokens": 931,
    "translated_title": "无标签数据的后门清除",
    "translated_abstract": "随着深度神经网络的计算需求增加，公司和组织已经开始外部化训练过程。但是，外部训练的深度神经网络可能会面临后门攻击。因此，关键在于防御这种攻击，即后处理一个可疑模型，使其的后门行为得到缓解，同时其对于干净输入的正常预测能力仍然保持不受影响。为了消除异常的后门行为，现有方法主要依赖于额外的标记干净样本。然而，这样的要求可能是不切实际的，因为训练数据通常对最终用户不可用。本文研究了绕过这种障碍的可能性，并提出了一种新的防御方法，不需要训练标签。通过精心设计的逐层权重重新初始化和知识蒸馏，我们的方法可以有效地清除可疑网络的后门行为，同时对其正常行为的影响微乎其微。我们在基准数据集上评估了我们的方法，并显示它胜过现有的无标签防御方法。",
    "tldr": "本文提出了一种无标签数据的后门清除方法，通过逐层权重重新初始化和知识蒸馏来有效清除可疑网络的后门行为，并在基准数据集上取得较好效果。",
    "en_tdlr": "This paper proposes a label-free defense method for backdoor cleansing, which effectively removes the abnormal backdoor behaviors of a suspicious network using layer-wise weight re-initialization and knowledge distillation, and outperforms existing label-free defenses on benchmark datasets."
}