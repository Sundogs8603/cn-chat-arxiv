{
    "title": "Variable Attention Masking for Configurable Transformer Transducer Speech Recognition. (arXiv:2211.01438v2 [eess.AS] UPDATED)",
    "abstract": "This work studies the use of attention masking in transformer transducer based speech recognition for building a single configurable model for different deployment scenarios. We present a comprehensive set of experiments comparing fixed masking, where the same attention mask is applied at every frame, with chunked masking, where the attention mask for each frame is determined by chunk boundaries, in terms of recognition accuracy and latency. We then explore the use of variable masking, where the attention masks are sampled from a target distribution at training time, to build models that can work in different configurations. Finally, we investigate how a single configurable model can be used to perform both first pass streaming recognition and second pass acoustic rescoring. Experiments show that chunked masking achieves a better accuracy vs latency trade-off compared to fixed masking, both with and without FastEmit. We also show that variable masking improves the accuracy by up to 8% ",
    "link": "http://arxiv.org/abs/2211.01438",
    "context": "Title: Variable Attention Masking for Configurable Transformer Transducer Speech Recognition. (arXiv:2211.01438v2 [eess.AS] UPDATED)\nAbstract: This work studies the use of attention masking in transformer transducer based speech recognition for building a single configurable model for different deployment scenarios. We present a comprehensive set of experiments comparing fixed masking, where the same attention mask is applied at every frame, with chunked masking, where the attention mask for each frame is determined by chunk boundaries, in terms of recognition accuracy and latency. We then explore the use of variable masking, where the attention masks are sampled from a target distribution at training time, to build models that can work in different configurations. Finally, we investigate how a single configurable model can be used to perform both first pass streaming recognition and second pass acoustic rescoring. Experiments show that chunked masking achieves a better accuracy vs latency trade-off compared to fixed masking, both with and without FastEmit. We also show that variable masking improves the accuracy by up to 8% ",
    "path": "papers/22/11/2211.01438.json",
    "total_tokens": 881,
    "translated_title": "可配置Transformer Transducer语音识别中的可变注意力掩模",
    "translated_abstract": "本论文研究了在基于Transformer Transducer的语音识别中使用注意力掩模以构建适应不同部署场景的单个可配置模型。我们展示了一系列实验，比较了固定掩模(每个帧应用相同的注意力掩模)和分块掩模(每个帧的注意力掩模由块边界确定)在识别准确性和延迟方面的表现。然后，我们探讨了如何在训练时从目标分布中对注意力掩模进行采样以构建能够在不同配置下工作的模型。最后，我们研究了如何使用单个可配置模型来执行第一阶段流识别和第二阶段声学重打分。实验结果表明，与固定掩模相比，分块掩模在准确性与延迟的折衷方面表现更好，无论是否使用FastEmit。我们还表明，可变掩模可使准确性提高最多8％。",
    "tldr": "本文研究了在Transformer Transducer语音识别中使用可变注意力掩模来构建可适应不同场景的模型，实验结果表明分块掩模表现更优，使用可变掩模可以提高准确性。",
    "en_tdlr": "This paper studies the use of variable attention masking in Transformer Transducer-based speech recognition to build adaptable models for different deployment scenarios. The experiments show that chunked masking performs better and variable masking can improve accuracy by up to 8%."
}