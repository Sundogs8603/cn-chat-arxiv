{
    "title": "Does Debiasing Inevitably Degrade the Model Performance. (arXiv:2211.07350v2 [cs.CL] UPDATED)",
    "abstract": "Gender bias in language models has attracted sufficient attention because it threatens social justice. However, most of the current debiasing methods degraded the model's performance on other tasks while the degradation mechanism is still mysterious. We propose a theoretical framework explaining the three candidate mechanisms of the language model's gender bias. We use our theoretical framework to explain why the current debiasing methods cause performance degradation. We also discover a pathway through which debiasing will not degrade the model performance. We further develop a causality-detection fine-tuning approach to correct gender bias. The numerical experiment demonstrates that our method is able to lead to double dividends: partially mitigating gender bias while avoiding performance degradation.",
    "link": "http://arxiv.org/abs/2211.07350",
    "context": "Title: Does Debiasing Inevitably Degrade the Model Performance. (arXiv:2211.07350v2 [cs.CL] UPDATED)\nAbstract: Gender bias in language models has attracted sufficient attention because it threatens social justice. However, most of the current debiasing methods degraded the model's performance on other tasks while the degradation mechanism is still mysterious. We propose a theoretical framework explaining the three candidate mechanisms of the language model's gender bias. We use our theoretical framework to explain why the current debiasing methods cause performance degradation. We also discover a pathway through which debiasing will not degrade the model performance. We further develop a causality-detection fine-tuning approach to correct gender bias. The numerical experiment demonstrates that our method is able to lead to double dividends: partially mitigating gender bias while avoiding performance degradation.",
    "path": "papers/22/11/2211.07350.json",
    "total_tokens": 853,
    "translated_title": "去偏置一定会降低模型性能吗?",
    "translated_abstract": "语言模型中的性别偏见已经引起了足够的关注，因为它威胁到社会公正。然而，目前大多数去偏置方法在降低模型在其他任务上的表现方面表现出了不稳定的性质，而这种降低的机制仍然是神秘的。我们提出了一个理论框架来解释语言模型性别偏见的三种候选机制，使用我们的理论框架来解释目前的去偏置方法如何导致性能降低。我们还发现了一种去偏置不会降低模型性能的途径，并进一步开发了一种因果检测微调方法来纠正性别偏见。数值实验表明，我们的方法能够实现双重收益：部分缓解性别偏见同时避免性能下降。",
    "tldr": "语言模型中的性别偏见问题日益引起关注，但当前去偏置方法往往会降低模型在其他任务上的表现；本论文提出了一个理论框架解释模型中性别偏见的机制，并发现了一种新的去偏置方法，能实现缓解性别偏见同时避免性能下降的双重优势。",
    "en_tdlr": "Gender bias in language models is a growing concern, but current debiasing methods often degrade the model's performance on other tasks; this paper proposes a theoretical framework and a new debiasing method that can achieve the dual advantage of mitigating gender bias while avoiding performance degradation."
}