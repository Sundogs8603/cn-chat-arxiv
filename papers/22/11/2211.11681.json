{
    "title": "Multiresolution kernel matrix algebra. (arXiv:2211.11681v2 [math.NA] UPDATED)",
    "abstract": "We propose a sparse algebra for samplet compressed kernel matrices, to enable efficient scattered data analysis. We show the compression of kernel matrices by means of samplets produces optimally sparse matrices in a certain S-format. It can be performed in cost and memory that scale essentially linearly with the matrix size $N$, for kernels of finite differentiability, along with addition and multiplication of S-formatted matrices. We prove and exploit the fact that the inverse of a kernel matrix (if it exists) is compressible in the S-format as well. Selected inversion allows to directly compute the entries in the corresponding sparsity pattern. The S-formatted matrix operations enable the efficient, approximate computation of more complicated matrix functions such as ${\\bm A}^\\alpha$ or $\\exp({\\bm A})$. The matrix algebra is justified mathematically by pseudo differential calculus. As an application, efficient Gaussian process learning algorithms for spatial statistics is considered",
    "link": "http://arxiv.org/abs/2211.11681",
    "context": "Title: Multiresolution kernel matrix algebra. (arXiv:2211.11681v2 [math.NA] UPDATED)\nAbstract: We propose a sparse algebra for samplet compressed kernel matrices, to enable efficient scattered data analysis. We show the compression of kernel matrices by means of samplets produces optimally sparse matrices in a certain S-format. It can be performed in cost and memory that scale essentially linearly with the matrix size $N$, for kernels of finite differentiability, along with addition and multiplication of S-formatted matrices. We prove and exploit the fact that the inverse of a kernel matrix (if it exists) is compressible in the S-format as well. Selected inversion allows to directly compute the entries in the corresponding sparsity pattern. The S-formatted matrix operations enable the efficient, approximate computation of more complicated matrix functions such as ${\\bm A}^\\alpha$ or $\\exp({\\bm A})$. The matrix algebra is justified mathematically by pseudo differential calculus. As an application, efficient Gaussian process learning algorithms for spatial statistics is considered",
    "path": "papers/22/11/2211.11681.json",
    "total_tokens": 936,
    "translated_title": "多分辨率核矩阵代数",
    "translated_abstract": "我们提出了一种用于压缩核矩阵的稀疏代数，以实现对散乱数据的高效分析。我们展示了通过采样压缩核矩阵可以在某种S格式下产生最优稀疏矩阵。针对有限可微核的核矩阵，可以实现S格式矩阵的加法和乘法，并且它们的内存和计算代价随矩阵大小$N$线性增长。我们证明并利用了一个事实，即核矩阵（如果存在）的逆矩阵也可以在S格式下被压缩。选择逆运算可以直接计算相应稀疏模式中的条目。S格式矩阵操作使得能够高效近似计算更复杂的矩阵函数，如${\\bm A}^\\alpha$或$\\exp({\\bm A})$。该矩阵代数通过伪微分计算得到数学上的正当性。作为应用，我们考虑了用于空间统计学的高效高斯过程学习算法。",
    "tldr": "该论文提出了一种压缩核矩阵的稀疏代数，可用于高效分析散乱数据并计算更复杂的矩阵函数，如${\\bm A}^\\alpha$或$\\exp({\\bm A})$，并应用于空间统计学中的高斯过程学习算法。",
    "en_tdlr": "The paper proposes a sparse algebra for compressed kernel matrices to enable efficient scattered data analysis as well as computing more complicated matrix functions such as ${\\bm A}^\\alpha$ or $\\exp({\\bm A})$. The algebra is applied to the efficient Gaussian process learning algorithm for spatial statistics."
}