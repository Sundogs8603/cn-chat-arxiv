{
    "title": "A Novel Sampling Scheme for Text- and Image-Conditional Image Synthesis in Quantized Latent Spaces. (arXiv:2211.07292v2 [cs.CV] UPDATED)",
    "abstract": "Recent advancements in the domain of text-to-image synthesis have culminated in a multitude of enhancements pertaining to quality, fidelity, and diversity. Contemporary techniques enable the generation of highly intricate visuals which rapidly approach near-photorealistic quality. Nevertheless, as progress is achieved, the complexity of these methodologies increases, consequently intensifying the comprehension barrier between individuals within the field and those external to it.  In an endeavor to mitigate this disparity, we propose a streamlined approach for text-to-image generation, which encompasses both the training paradigm and the sampling process. Despite its remarkable simplicity, our method yields aesthetically pleasing images with few sampling iterations, allows for intriguing ways for conditioning the model, and imparts advantages absent in state-of-the-art techniques. To demonstrate the efficacy of this approach in achieving outcomes comparable to existing works, we have t",
    "link": "http://arxiv.org/abs/2211.07292",
    "context": "Title: A Novel Sampling Scheme for Text- and Image-Conditional Image Synthesis in Quantized Latent Spaces. (arXiv:2211.07292v2 [cs.CV] UPDATED)\nAbstract: Recent advancements in the domain of text-to-image synthesis have culminated in a multitude of enhancements pertaining to quality, fidelity, and diversity. Contemporary techniques enable the generation of highly intricate visuals which rapidly approach near-photorealistic quality. Nevertheless, as progress is achieved, the complexity of these methodologies increases, consequently intensifying the comprehension barrier between individuals within the field and those external to it.  In an endeavor to mitigate this disparity, we propose a streamlined approach for text-to-image generation, which encompasses both the training paradigm and the sampling process. Despite its remarkable simplicity, our method yields aesthetically pleasing images with few sampling iterations, allows for intriguing ways for conditioning the model, and imparts advantages absent in state-of-the-art techniques. To demonstrate the efficacy of this approach in achieving outcomes comparable to existing works, we have t",
    "path": "papers/22/11/2211.07292.json",
    "total_tokens": 856,
    "translated_title": "量化潜空间中文本和图像条件图像合成的新型采样方案",
    "translated_abstract": "最近，在文本到图像合成领域取得了许多提高，包括质量、保真度和多样性等方面的提高。现代技术使得生成高度复杂的视觉效果，接近于逼真的质量。然而，随着进展的实现，这些方法的复杂性不断增加，从而加剧了领域内外个人之间的理解障碍。为了缓解这种差异，我们提出了一种简化了训练范式和采样过程的文本到图像生成的方法。尽管其简单性显著，但我们的方法通过很少的采样迭代产生出美观的图像，允许采用有趣的方式来调节模型，并提供了现有技术所没有的优势。为了证明这种方法在实现与现有方法可比的结果方面的有效性，我们已经进行了...",
    "tldr": "本文提出了一种简化的文本到图像生成方法，同时包括训练范式和采样过程。该方法通过很少的采样迭代产生出美观的图像，允许通过有趣的调制方式来调整模型。",
    "en_tdlr": "This paper proposes a simplified method for text-to-image generation, including the training paradigm and the sampling process. The method yields aesthetically pleasing images with few sampling iterations, and allows for intriguing ways to condition the model."
}