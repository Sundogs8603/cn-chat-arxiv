{
    "title": "PIP: Positional-encoding Image Prior. (arXiv:2211.14298v2 [cs.CV] UPDATED)",
    "abstract": "In Deep Image Prior (DIP), a Convolutional Neural Network (CNN) is fitted to map a latent space to a degraded (e.g. noisy) image but in the process learns to reconstruct the clean image. This phenomenon is attributed to CNN's internal image-prior. We revisit the DIP framework, examining it from the perspective of a neural implicit representation. Motivated by this perspective, we replace the random or learned latent with Fourier-Features (Positional Encoding). We show that thanks to the Fourier features properties, we can replace the convolution layers with simple pixel-level MLPs. We name this scheme ``Positional Encoding Image Prior\" (PIP) and exhibit that it performs very similarly to DIP on various image-reconstruction tasks with much less parameters required. Additionally, we demonstrate that PIP can be easily extended to videos, where 3D-DIP struggles and suffers from instability. Code and additional examples for all tasks, including videos, are available on the project page http",
    "link": "http://arxiv.org/abs/2211.14298",
    "context": "Title: PIP: Positional-encoding Image Prior. (arXiv:2211.14298v2 [cs.CV] UPDATED)\nAbstract: In Deep Image Prior (DIP), a Convolutional Neural Network (CNN) is fitted to map a latent space to a degraded (e.g. noisy) image but in the process learns to reconstruct the clean image. This phenomenon is attributed to CNN's internal image-prior. We revisit the DIP framework, examining it from the perspective of a neural implicit representation. Motivated by this perspective, we replace the random or learned latent with Fourier-Features (Positional Encoding). We show that thanks to the Fourier features properties, we can replace the convolution layers with simple pixel-level MLPs. We name this scheme ``Positional Encoding Image Prior\" (PIP) and exhibit that it performs very similarly to DIP on various image-reconstruction tasks with much less parameters required. Additionally, we demonstrate that PIP can be easily extended to videos, where 3D-DIP struggles and suffers from instability. Code and additional examples for all tasks, including videos, are available on the project page http",
    "path": "papers/22/11/2211.14298.json",
    "total_tokens": 941,
    "translated_title": "PIP：位置编码图像先验",
    "translated_abstract": "在深度图像先验（DIP）中，卷积神经网络（CNN）被适配为将潜空间映射到降质（例如噪音）图像，但在此过程中学习重建干净图像。这种现象归因于CNN的内部图像先验。我们从神经隐式表示的角度重新审视了DIP框架。受到这种观点的启发，我们用傅里叶特征（位置编码）替换了随机或学习得到的潜码。我们展示了由于傅里叶特征的属性，我们可以用简单的像素级MLP替换卷积层。我们将此方案命名为“位置编码图像先验”（PIP），并展示它在各种图像重建任务中与DIP表现非常相似，但所需的参数要少得多。此外，我们展示PIP可以轻松扩展到视频，其中3D-DIP表现不佳且不稳定。所有任务的代码和其他例子（包括视频）均可在项目页面http://people.csail.mit.edu/yilun/pip/上获得。",
    "tldr": "本文提出的PIP（位置编码图像先验）与DIP表现相似，但所需参数更少，并且可以轻松扩展到视频领域，解决了3D-DIP的问题。",
    "en_tdlr": "The article proposes a new framework called PIP (Positional Encoding Image Prior), which replaces the random or learned latent with Fourier-Features (Positional Encoding), and allows to perform similarly to Deep Image Prior (DIP) with much fewer parameters while being easily extendable to the video domain, solving issues with 3D-DIP."
}