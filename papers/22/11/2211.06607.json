{
    "title": "Few-shot Multimodal Sentiment Analysis based on Multimodal Probabilistic Fusion Prompts. (arXiv:2211.06607v2 [cs.CL] UPDATED)",
    "abstract": "Multimodal sentiment analysis has gained significant attention due to the proliferation of multimodal content on social media. However, existing studies in this area rely heavily on large-scale supervised data, which is time-consuming and labor-intensive to collect. Thus, there is a need to address the challenge of few-shot multimodal sentiment analysis. To tackle this problem, we propose a novel method called Multimodal Probabilistic Fusion Prompts (MultiPoint) that leverages diverse cues from different modalities for multimodal sentiment detection in the few-shot scenario. Specifically, we start by introducing a Consistently Distributed Sampling approach called CDS, which ensures that the few-shot dataset has the same category distribution as the full dataset. Unlike previous approaches primarily using prompts based on the text modality, we design unified multimodal prompts to reduce discrepancies between different modalities and dynamically incorporate multimodal demonstrations into",
    "link": "http://arxiv.org/abs/2211.06607",
    "context": "Title: Few-shot Multimodal Sentiment Analysis based on Multimodal Probabilistic Fusion Prompts. (arXiv:2211.06607v2 [cs.CL] UPDATED)\nAbstract: Multimodal sentiment analysis has gained significant attention due to the proliferation of multimodal content on social media. However, existing studies in this area rely heavily on large-scale supervised data, which is time-consuming and labor-intensive to collect. Thus, there is a need to address the challenge of few-shot multimodal sentiment analysis. To tackle this problem, we propose a novel method called Multimodal Probabilistic Fusion Prompts (MultiPoint) that leverages diverse cues from different modalities for multimodal sentiment detection in the few-shot scenario. Specifically, we start by introducing a Consistently Distributed Sampling approach called CDS, which ensures that the few-shot dataset has the same category distribution as the full dataset. Unlike previous approaches primarily using prompts based on the text modality, we design unified multimodal prompts to reduce discrepancies between different modalities and dynamically incorporate multimodal demonstrations into",
    "path": "papers/22/11/2211.06607.json",
    "total_tokens": 904,
    "translated_title": "基于多模态概率融合提示的少样本多模态情感分析",
    "translated_abstract": "随着社交媒体上多模态内容的普及，多模态情感分析引起了人们的重视。然而，现有研究在这一领域依赖于大规模监督数据，而这种数据的采集非常耗时和劳动密集。因此，有必要解决少样本多模态情感分析的挑战。为了解决这个问题，我们提出了一种新的方法，名为多模态概率融合提示（MultiPoint），它利用来自不同模态的多样线索进行少样本情感检测。具体而言，我们首先引入了一种一致分布采样方法（CDS），以确保少样本数据集具有与整个数据集相同的类别分布。与之前主要使用基于文本模态的提示的方法不同，我们设计了统一的多模态提示，以减少不同模态之间的差异并动态地将多模态演示纳入其中。",
    "tldr": "本论文提出了一种名为多模态概率融合提示（MultiPoint）的方法，通过利用多模态的不同线索进行少样本情感分析。这种方法解决了现有研究中依赖于大规模监督数据的问题，并通过统一的多模态提示来减少不同模态之间的差异。"
}