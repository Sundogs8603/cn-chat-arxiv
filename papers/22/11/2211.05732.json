{
    "title": "The Sample Complexity of Online Contract Design. (arXiv:2211.05732v2 [cs.GT] UPDATED)",
    "abstract": "We study the hidden-action principal-agent problem in an online setting. In each round, the principal posts a contract that specifies the payment to the agent based on each outcome. The agent then makes a strategic choice of action that maximizes her own utility, but the action is not directly observable by the principal. The principal observes the outcome and receives utility from the agent's choice of action. Based on past observations, the principal dynamically adjusts the contracts with the goal of maximizing her utility.  We introduce an online learning algorithm and provide an upper bound on its Stackelberg regret. We show that when the contract space is $[0,1]^m$, the Stackelberg regret is upper bounded by $\\widetilde O(\\sqrt{m} \\cdot T^{1-1/(2m+1)})$, and lower bounded by $\\Omega(T^{1-1/(m+2)})$, where $\\widetilde O$ omits logarithmic factors. This result shows that exponential-in-$m$ samples are sufficient and necessary to learn a near-optimal contract, resolving an open probl",
    "link": "http://arxiv.org/abs/2211.05732",
    "context": "Title: The Sample Complexity of Online Contract Design. (arXiv:2211.05732v2 [cs.GT] UPDATED)\nAbstract: We study the hidden-action principal-agent problem in an online setting. In each round, the principal posts a contract that specifies the payment to the agent based on each outcome. The agent then makes a strategic choice of action that maximizes her own utility, but the action is not directly observable by the principal. The principal observes the outcome and receives utility from the agent's choice of action. Based on past observations, the principal dynamically adjusts the contracts with the goal of maximizing her utility.  We introduce an online learning algorithm and provide an upper bound on its Stackelberg regret. We show that when the contract space is $[0,1]^m$, the Stackelberg regret is upper bounded by $\\widetilde O(\\sqrt{m} \\cdot T^{1-1/(2m+1)})$, and lower bounded by $\\Omega(T^{1-1/(m+2)})$, where $\\widetilde O$ omits logarithmic factors. This result shows that exponential-in-$m$ samples are sufficient and necessary to learn a near-optimal contract, resolving an open probl",
    "path": "papers/22/11/2211.05732.json",
    "total_tokens": 905,
    "translated_title": "在线合同设计的样本复杂度",
    "translated_abstract": "本文研究在线情境下的隐藏-行动委托问题。在每轮中，委托人发布一份合同，根据每个结果规定代理人的支付。代理人然后做出一个最大化她自己效用的战略行动选择，但直接观察不到行动。委托人观察结果并从代理人的行动选择中获得效用。根据过去的观察，委托人动态地调整合同，目标是最大化其效用。我们引入了一种在线学习算法，并给出了其Stackelberg遗憾的上界。我们证明，在合同空间为$[0,1]^m$时，Stackelberg遗憾的上界为$\\widetilde O(\\sqrt{m} \\cdot T^{1-1/(2m+1)})$，下界为$\\Omega(T^{1-1/(m+2)})$，其中$\\widetilde O$排除对数因子。 这个结果表明，指数级的$m$个样本就足以学习一个近乎最优的合同，解决了在线合同设计中的一个悬而未决的问题。",
    "tldr": "本文解决了在线合同设计中一个悬而未决的问题，证明了指数级的$m$个样本就足以学习一个近乎最优的合同。",
    "en_tdlr": "This paper resolves an open problem in online contract design by showing that exponential-in-$m$ samples are sufficient and necessary to learn a near-optimal contract."
}