{
    "title": "Contextual information integration for stance detection via cross-attention. (arXiv:2211.01874v2 [cs.CL] UPDATED)",
    "abstract": "Stance detection deals with identifying an author's stance towards a target. Most existing stance detection models are limited because they do not consider relevant contextual information which allows for inferring the stance correctly. Complementary context can be found in knowledge bases but integrating the context into pretrained language models is non-trivial due to the graph structure of standard knowledge bases. To overcome this, we explore an approach to integrate contextual information as text which allows for integrating contextual information from heterogeneous sources, such as structured knowledge sources and by prompting large language models. Our approach can outperform competitive baselines on a large and diverse stance detection benchmark in a cross-target setup, i.e. for targets unseen during training. We demonstrate that it is more robust to noisy context and can regularize for unwanted correlations between labels and target-specific vocabulary. Finally, it is independ",
    "link": "http://arxiv.org/abs/2211.01874",
    "context": "Title: Contextual information integration for stance detection via cross-attention. (arXiv:2211.01874v2 [cs.CL] UPDATED)\nAbstract: Stance detection deals with identifying an author's stance towards a target. Most existing stance detection models are limited because they do not consider relevant contextual information which allows for inferring the stance correctly. Complementary context can be found in knowledge bases but integrating the context into pretrained language models is non-trivial due to the graph structure of standard knowledge bases. To overcome this, we explore an approach to integrate contextual information as text which allows for integrating contextual information from heterogeneous sources, such as structured knowledge sources and by prompting large language models. Our approach can outperform competitive baselines on a large and diverse stance detection benchmark in a cross-target setup, i.e. for targets unseen during training. We demonstrate that it is more robust to noisy context and can regularize for unwanted correlations between labels and target-specific vocabulary. Finally, it is independ",
    "path": "papers/22/11/2211.01874.json",
    "total_tokens": 835,
    "translated_title": "基于交叉注意力的立场检测中的上下文信息整合",
    "translated_abstract": "立场检测旨在确定作者对目标的立场。然而，大多数现有的立场检测模型存在局限性，因为它们没有考虑相关的上下文信息来正确地推断立场。为了解决这个问题，我们探索了一种方法，即将上下文信息作为文本进行整合。这种方法可以从异构数据源，如结构化知识源和大型语言模型，整合上下文信息，并可以克服标准知识库的图形结构对预训练语言模型的集成的复杂性。我们的方法在一个大型和多样化的立场检测基准测试中可以优于竞争基线，在交叉目标设置中，即针对在训练期间未见过的目标。我们证明它对噪声上下文更加鲁棒，并且可以为标签和目标特定词汇之间的不必要相关性进行正则化。最后，它是独立的。",
    "tldr": "本论文提出一种将来自异构数据源的上下文信息作为文本整合的方法，用于立场检测，取得了优于竞争基线的结果，对于未被提前见过的目标仍然有效。",
    "en_tdlr": "This paper proposes an approach to integrate contextual information from heterogeneous sources as text for stance detection, achieving better results than competitive baselines, and remaining effective for unseen targets."
}