{
    "title": "Effective Audio Classification Network Based on Paired Inverse Pyramid Structure and Dense MLP Block. (arXiv:2211.02940v3 [cs.SD] UPDATED)",
    "abstract": "Recently, massive architectures based on Convolutional Neural Network (CNN) and self-attention mechanisms have become necessary for audio classification. While these techniques are state-of-the-art, these works' effectiveness can only be guaranteed with huge computational costs and parameters, large amounts of data augmentation, transfer from large datasets and some other tricks. By utilizing the lightweight nature of audio, we propose an efficient network structure called Paired Inverse Pyramid Structure (PIP) and a network called Paired Inverse Pyramid Structure MLP Network (PIPMN). The PIPMN reaches 96\\% of Environmental Sound Classification (ESC) accuracy on the UrbanSound8K dataset and 93.2\\% of Music Genre Classification (MGC) on the GTAZN dataset, with only 1 million parameters. Both of the results are achieved without data augmentation or model transfer. Public code is available at: https://github.com/JNAIC/PIPMN",
    "link": "http://arxiv.org/abs/2211.02940",
    "context": "Title: Effective Audio Classification Network Based on Paired Inverse Pyramid Structure and Dense MLP Block. (arXiv:2211.02940v3 [cs.SD] UPDATED)\nAbstract: Recently, massive architectures based on Convolutional Neural Network (CNN) and self-attention mechanisms have become necessary for audio classification. While these techniques are state-of-the-art, these works' effectiveness can only be guaranteed with huge computational costs and parameters, large amounts of data augmentation, transfer from large datasets and some other tricks. By utilizing the lightweight nature of audio, we propose an efficient network structure called Paired Inverse Pyramid Structure (PIP) and a network called Paired Inverse Pyramid Structure MLP Network (PIPMN). The PIPMN reaches 96\\% of Environmental Sound Classification (ESC) accuracy on the UrbanSound8K dataset and 93.2\\% of Music Genre Classification (MGC) on the GTAZN dataset, with only 1 million parameters. Both of the results are achieved without data augmentation or model transfer. Public code is available at: https://github.com/JNAIC/PIPMN",
    "path": "papers/22/11/2211.02940.json",
    "total_tokens": 896,
    "translated_title": "基于配对逆金字塔结构和密集多层感知机块的有效音频分类网络",
    "translated_abstract": "最近，基于卷积神经网络（CNN）和自注意机制的大规模架构已经成为音频分类领域的必要技术。虽然这些技术是最先进的，但只有通过巨大的计算成本和参数、大量的数据增强、来自大型数据集的迁移以及一些其他技巧才能保证有效性。通过利用音频的轻量级特性，我们提出了一种高效的网络结构——配对逆金字塔结构（PIP），以及一种称为配对逆金字塔结构MLP网络（PIPMN）的网络。PIP网络在UrbanSound8K数据集上达到96%的环境声音分类准确度，在GTAZN数据集上达到93.2%的音乐流派分类准确度，仅使用100万个参数即可实现这两个结果，而不需要进行数据增强或模型迁移。公共代码可在以下网址获取：https://github.com/JNAIC/PIPMN",
    "tldr": "该论文通过提出基于轻量级音频的配对逆金字塔结构网络和密集多层感知机块网络，实现了在不进行数据增强或模型迁移情况下，对UrbanSound8K数据集和GTAZN数据集的高准确度分类任务。",
    "en_tdlr": "This paper proposes an efficient audio classification network using lightweight Paired Inverse Pyramid Structure (PIP) and Dense MLP Block, achieving high accuracy on UrbanSound8K and GTAZN datasets without data augmentation or model transfer."
}