{
    "title": "Fully Bayesian inference for latent variable Gaussian process models. (arXiv:2211.02218v2 [stat.ML] UPDATED)",
    "abstract": "Real engineering and scientific applications often involve one or more qualitative inputs. Standard Gaussian processes (GPs), however, cannot directly accommodate qualitative inputs. The recently introduced latent variable Gaussian process (LVGP) overcomes this issue by first mapping each qualitative factor to underlying latent variables (LVs), and then uses any standard GP covariance function over these LVs. The LVs are estimated similarly to the other GP hyperparameters through maximum likelihood estimation, and then plugged into the prediction expressions. However, this plug-in approach will not account for uncertainty in estimation of the LVs, which can be significant especially with limited training data. In this work, we develop a fully Bayesian approach for the LVGP model and for visualizing the effects of the qualitative inputs via their LVs. We also develop approximations for scaling up LVGPs and fully Bayesian inference for the LVGP hyperparameters. We conduct numerical studi",
    "link": "http://arxiv.org/abs/2211.02218",
    "context": "Title: Fully Bayesian inference for latent variable Gaussian process models. (arXiv:2211.02218v2 [stat.ML] UPDATED)\nAbstract: Real engineering and scientific applications often involve one or more qualitative inputs. Standard Gaussian processes (GPs), however, cannot directly accommodate qualitative inputs. The recently introduced latent variable Gaussian process (LVGP) overcomes this issue by first mapping each qualitative factor to underlying latent variables (LVs), and then uses any standard GP covariance function over these LVs. The LVs are estimated similarly to the other GP hyperparameters through maximum likelihood estimation, and then plugged into the prediction expressions. However, this plug-in approach will not account for uncertainty in estimation of the LVs, which can be significant especially with limited training data. In this work, we develop a fully Bayesian approach for the LVGP model and for visualizing the effects of the qualitative inputs via their LVs. We also develop approximations for scaling up LVGPs and fully Bayesian inference for the LVGP hyperparameters. We conduct numerical studi",
    "path": "papers/22/11/2211.02218.json",
    "total_tokens": 928,
    "translated_title": "隐变量高斯过程模型的完全贝叶斯推断",
    "translated_abstract": "实际工程和科学应用常常涉及一个或多个定性输入。然而，标准高斯过程（GP）不能直接适应定性输入。最近引入的隐变量高斯过程（LVGP）通过首先将每个定性因素映射到底层隐变量（LV），然后在这些LV上使用任何标准GP协方差函数来解决这个问题。通过最大似然估计，对LV进行估计，然后将其插入到预测表达式中。然而，这种插入方法不考虑LV估计的不确定性，而这种不确定性在训练数据有限的情况下可能会很大。在这项工作中，我们为LVGP模型开发了一个完全贝叶斯方法，并通过其LV可视化了定性输入的效果。我们还开发了适用于扩展LVGP和LVGP超参数的完全贝叶斯推断的近似方法。我们进行了数值研究。",
    "tldr": "隐变量高斯过程模型通过将定性因素映射到底层隐变量的方式解决了标准高斯过程无法适应定性输入的问题。本文提出了一种考虑隐变量估计不确定性的完全贝叶斯方法，支持通过隐变量可视化定性输入的效果。",
    "en_tdlr": "The latent variable Gaussian process (LVGP) overcomes the inability of standard Gaussian processes (GPs) to directly accommodate qualitative inputs by mapping them to underlying latent variables. This paper proposes a fully Bayesian approach for the LVGP model that accounts for uncertainty in estimation of the latent variables, and supports visualizing the effects of qualitative inputs through the latent variables."
}