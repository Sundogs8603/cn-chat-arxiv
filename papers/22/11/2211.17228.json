{
    "title": "AIO-P: Expanding Neural Performance Predictors Beyond Image Classification. (arXiv:2211.17228v2 [cs.CV] UPDATED)",
    "abstract": "Evaluating neural network performance is critical to deep neural network design but a costly procedure. Neural predictors provide an efficient solution by treating architectures as samples and learning to estimate their performance on a given task. However, existing predictors are task-dependent, predominantly estimating neural network performance on image classification benchmarks. They are also search-space dependent; each predictor is designed to make predictions for a specific architecture search space with predefined topologies and set of operations. In this paper, we propose a novel All-in-One Predictor (AIO-P), which aims to pretrain neural predictors on architecture examples from multiple, separate computer vision (CV) task domains and multiple architecture spaces, and then transfer to unseen downstream CV tasks or neural architectures. We describe our proposed techniques for general graph representation, efficient predictor pretraining and knowledge infusion techniques, as wel",
    "link": "http://arxiv.org/abs/2211.17228",
    "context": "Title: AIO-P: Expanding Neural Performance Predictors Beyond Image Classification. (arXiv:2211.17228v2 [cs.CV] UPDATED)\nAbstract: Evaluating neural network performance is critical to deep neural network design but a costly procedure. Neural predictors provide an efficient solution by treating architectures as samples and learning to estimate their performance on a given task. However, existing predictors are task-dependent, predominantly estimating neural network performance on image classification benchmarks. They are also search-space dependent; each predictor is designed to make predictions for a specific architecture search space with predefined topologies and set of operations. In this paper, we propose a novel All-in-One Predictor (AIO-P), which aims to pretrain neural predictors on architecture examples from multiple, separate computer vision (CV) task domains and multiple architecture spaces, and then transfer to unseen downstream CV tasks or neural architectures. We describe our proposed techniques for general graph representation, efficient predictor pretraining and knowledge infusion techniques, as wel",
    "path": "papers/22/11/2211.17228.json",
    "total_tokens": 886,
    "translated_title": "AIO-P：将神经网络性能预测扩展到图像分类之外",
    "translated_abstract": "评估神经网络性能对于深度神经网络设计至关重要，但是这是一个昂贵的过程。神经预测器提供了一种有效的解决方案，通过将架构视为样本，学习估计其在给定任务上的性能。然而，现有的预测器是任务相关的，主要估计神经网络在图像分类基准测试上的性能。它们也是搜索空间相关的；每个预测器都设计为针对具有预定义拓扑和操作集的特定架构搜索空间进行预测。本文提出了一种新颖的All-in-One Predictor（AIO-P），旨在预训练神经预测器，使用来自多个独立计算机视觉（CV）任务域和多个架构空间的架构示例，并转移到未使用的下游CV任务或神经架构上。我们描述了我们提出的通用图形表示、高效预测器预训练和知识注入技术。",
    "tldr": "本文提出了一种新颖的All-in-One Predictor（AIO-P），旨在预训练神经预测器，使用来自多个独立计算机视觉（CV）任务域和多个架构空间的架构示例，并转移到未使用的下游CV任务或神经架构上。"
}