{
    "title": "Privacy in Practice: Private COVID-19 Detection in X-Ray Images (Extended Version). (arXiv:2211.11434v3 [cs.LG] UPDATED)",
    "abstract": "Machine learning (ML) can help fight pandemics like COVID-19 by enabling rapid screening of large volumes of images. To perform data analysis while maintaining patient privacy, we create ML models that satisfy Differential Privacy (DP). Previous works exploring private COVID-19 models are in part based on small datasets, provide weaker or unclear privacy guarantees, and do not investigate practical privacy. We suggest improvements to address these open gaps. We account for inherent class imbalances and evaluate the utility-privacy trade-off more extensively and over stricter privacy budgets. Our evaluation is supported by empirically estimating practical privacy through black-box Membership Inference Attacks (MIAs). The introduced DP should help limit leakage threats posed by MIAs, and our practical analysis is the first to test this hypothesis on the COVID-19 classification task. Our results indicate that needed privacy levels might differ based on the task-dependent practical threat ",
    "link": "http://arxiv.org/abs/2211.11434",
    "context": "Title: Privacy in Practice: Private COVID-19 Detection in X-Ray Images (Extended Version). (arXiv:2211.11434v3 [cs.LG] UPDATED)\nAbstract: Machine learning (ML) can help fight pandemics like COVID-19 by enabling rapid screening of large volumes of images. To perform data analysis while maintaining patient privacy, we create ML models that satisfy Differential Privacy (DP). Previous works exploring private COVID-19 models are in part based on small datasets, provide weaker or unclear privacy guarantees, and do not investigate practical privacy. We suggest improvements to address these open gaps. We account for inherent class imbalances and evaluate the utility-privacy trade-off more extensively and over stricter privacy budgets. Our evaluation is supported by empirically estimating practical privacy through black-box Membership Inference Attacks (MIAs). The introduced DP should help limit leakage threats posed by MIAs, and our practical analysis is the first to test this hypothesis on the COVID-19 classification task. Our results indicate that needed privacy levels might differ based on the task-dependent practical threat ",
    "path": "papers/22/11/2211.11434.json",
    "total_tokens": 958,
    "translated_title": "实践中的隐私：X射线图像中的COVID-19检测的私有化（扩展版）",
    "translated_abstract": "机器学习（ML）可以通过使大量图像快速筛选来帮助抗击COVID-19等全球大流行病。为了在保护患者隐私的同时进行数据分析，我们创建了满足差分隐私（DP）要求的ML模型。以往探索私有COVID-19模型的研究在一定程度上基于小型数据集，提供较弱或不明确的隐私保证，并且没有研究实际隐私。我们提出改进措施以解决这些空缺。我们考虑天生的类别不平衡，并更广泛地评估效用-隐私权衡以及更严格的隐私预算。我们的评估得到黑盒成员推理攻击（MIAs）的实际隐私估计支持。引入的DP应有助于限制MIAs带来的泄漏威胁，而我们的实际分析是第一个在COVID-19分类任务上测试这个假设的。",
    "tldr": "该研究提出了通过差分隐私保护COVID-19检测模型，解决数据分析和患者隐私保护的问题。通过黑盒成员推理攻击，实现了对实际隐私的评估，结论表明所需的隐私等级可能因受到实际威胁的任务而异。"
}