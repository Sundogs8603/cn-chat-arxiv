{
    "title": "Learning to Generate Image Embeddings with User-level Differential Privacy. (arXiv:2211.10844v2 [cs.LG] UPDATED)",
    "abstract": "Small on-device models have been successfully trained with user-level differential privacy (DP) for next word prediction and image classification tasks in the past. However, existing methods can fail when directly applied to learn embedding models using supervised training data with a large class space. To achieve user-level DP for large image-to-embedding feature extractors, we propose DP-FedEmb, a variant of federated learning algorithms with per-user sensitivity control and noise addition, to train from user-partitioned data centralized in the datacenter. DP-FedEmb combines virtual clients, partial aggregation, private local fine-tuning, and public pretraining to achieve strong privacy utility trade-offs. We apply DP-FedEmb to train image embedding models for faces, landmarks and natural species, and demonstrate its superior utility under same privacy budget on benchmark datasets DigiFace, EMNIST, GLD and iNaturalist. We further illustrate it is possible to achieve strong user-level",
    "link": "http://arxiv.org/abs/2211.10844",
    "context": "Title: Learning to Generate Image Embeddings with User-level Differential Privacy. (arXiv:2211.10844v2 [cs.LG] UPDATED)\nAbstract: Small on-device models have been successfully trained with user-level differential privacy (DP) for next word prediction and image classification tasks in the past. However, existing methods can fail when directly applied to learn embedding models using supervised training data with a large class space. To achieve user-level DP for large image-to-embedding feature extractors, we propose DP-FedEmb, a variant of federated learning algorithms with per-user sensitivity control and noise addition, to train from user-partitioned data centralized in the datacenter. DP-FedEmb combines virtual clients, partial aggregation, private local fine-tuning, and public pretraining to achieve strong privacy utility trade-offs. We apply DP-FedEmb to train image embedding models for faces, landmarks and natural species, and demonstrate its superior utility under same privacy budget on benchmark datasets DigiFace, EMNIST, GLD and iNaturalist. We further illustrate it is possible to achieve strong user-level",
    "path": "papers/22/11/2211.10844.json",
    "total_tokens": 1061,
    "translated_title": "学习使用用户级差分隐私生成图像嵌入",
    "translated_abstract": "在过去，用户级差分隐私已成功地用于训练小型设备上的模型，用于下一个单词预测和图像分类任务。然而，现有的方法在直接应用于使用大型类空间的受监督训练数据来学习嵌入式模型时可能会失败。为了实现大型图像到嵌入特征提取器的用户级差分隐私，我们提出了DP-FedEmb，这是一种联邦学习算法的变体，具有每个用户的灵敏度控制和噪声添加，以从在数据中心集中的用户分区数据中进行训练。DP-FedEmb结合了虚拟客户端、部分聚合、私有本地微调和公共预训练，以实现强大的隐私效用权衡。我们将DP-FedEmb应用于为面部、地标和自然物种训练图像嵌入模型，并在基准数据集DigiFace、EMNIST、GLD和iNaturalist上展示了其在相同隐私预算下的优越效用。我们进一步说明，在学习大型图像到嵌入特征提取器时，可以实现强大的用户级差分隐私，同时保持良好的模型效用。",
    "tldr": "本文提出了一种DP-FedEmb算法，通过虚拟客户端、部分聚合、私有本地微调和公共预训练，实现了用户级差分隐私。在图像嵌入模型的学习中，DP-FedEmb能够在保持良好模型效用的同时，实现较强的隐私保护，得到的实验结果表明其在基准数据集上的表现优越。",
    "en_tdlr": "This paper proposes a DP-FedEmb algorithm that achieves user-level differential privacy through virtual clients, partial aggregation, private local fine-tuning, and public pretraining. DP-FedEmb can learn large image-to-embedding feature extractors with strong privacy protection and good model utility under the same privacy budget. Experimental results show its superior performance on benchmark datasets."
}