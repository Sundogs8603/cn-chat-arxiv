{
    "title": "A Theoretical Study of Inductive Biases in Contrastive Learning. (arXiv:2211.14699v2 [cs.LG] UPDATED)",
    "abstract": "Understanding self-supervised learning is important but challenging. Previous theoretical works study the role of pretraining losses, and view neural networks as general black boxes. However, the recent work of Saunshi et al. argues that the model architecture -- a component largely ignored by previous works -- also has significant influences on the downstream performance of self-supervised learning. In this work, we provide the first theoretical analysis of self-supervised learning that incorporates the effect of inductive biases originating from the model class. In particular, we focus on contrastive learning -- a popular self-supervised learning method that is widely used in the vision domain. We show that when the model has limited capacity, contrastive representations would recover certain special clustering structures that are compatible with the model architecture, but ignore many other clustering structures in the data distribution. As a result, our theory can capture the more ",
    "link": "http://arxiv.org/abs/2211.14699",
    "context": "Title: A Theoretical Study of Inductive Biases in Contrastive Learning. (arXiv:2211.14699v2 [cs.LG] UPDATED)\nAbstract: Understanding self-supervised learning is important but challenging. Previous theoretical works study the role of pretraining losses, and view neural networks as general black boxes. However, the recent work of Saunshi et al. argues that the model architecture -- a component largely ignored by previous works -- also has significant influences on the downstream performance of self-supervised learning. In this work, we provide the first theoretical analysis of self-supervised learning that incorporates the effect of inductive biases originating from the model class. In particular, we focus on contrastive learning -- a popular self-supervised learning method that is widely used in the vision domain. We show that when the model has limited capacity, contrastive representations would recover certain special clustering structures that are compatible with the model architecture, but ignore many other clustering structures in the data distribution. As a result, our theory can capture the more ",
    "path": "papers/22/11/2211.14699.json",
    "total_tokens": 910,
    "translated_title": "对比学习中的归纳偏差的理论研究",
    "translated_abstract": "理解自监督学习是重要而具有挑战性的。之前的理论研究对预训练损失的作用进行了研究，将神经网络视为普通的黑盒子。然而，Saunshi等人最近的研究表明，模型结构——之前的研究中很少关注的一个组成部分——对于自监督学习的下游性能也有显著的影响。在本研究中，我们提供了第一个将源于模型类的归纳偏差的影响纳入自监督学习的理论分析。特别地，我们关注对于视觉领域普遍使用的一种流行的自监督学习方法——对比学习。我们展示了当模型具有有限的容量时，对比表示会恢复与模型结构兼容的某些特殊聚类结构，但会忽略数据分布中的许多其他聚类结构。因此，我们的理论可以捕捉对比学习更为复杂的行为，提供了有关模型结构选择如何影响学习过程的见解。",
    "tldr": "本文提供了对比学习中的归纳偏差的影响的理论分析，揭示了模型选择对学习过程的影响。",
    "en_tdlr": "This paper provides a theoretical analysis of the impact of inductive biases in contrastive learning, revealing how choice of model architecture affects the learning process."
}