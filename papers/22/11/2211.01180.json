{
    "title": "M-SpeechCLIP: Leveraging Large-Scale, Pre-Trained Models for Multilingual Speech to Image Retrieval. (arXiv:2211.01180v2 [cs.CL] UPDATED)",
    "abstract": "This work investigates the use of large-scale, English-only pre-trained models (CLIP and HuBERT) for multilingual image-speech retrieval. For non-English image-speech retrieval, we outperform the current state-of-the-art performance by a wide margin both when training separate models for each language, and with a single model which processes speech in all three languages. We identify key differences in model behavior and performance between English and non-English settings, attributable to the English-only pre-training of CLIP and HuBERT, and investigate how fine-tuning the pre-trained models impacts these differences. Finally, we show that our models can be used for mono- and cross-lingual speech-text retrieval and cross-lingual speech-speech retrieval, despite never having seen any parallel speech-text or speech-speech data during training.",
    "link": "http://arxiv.org/abs/2211.01180",
    "context": "Title: M-SpeechCLIP: Leveraging Large-Scale, Pre-Trained Models for Multilingual Speech to Image Retrieval. (arXiv:2211.01180v2 [cs.CL] UPDATED)\nAbstract: This work investigates the use of large-scale, English-only pre-trained models (CLIP and HuBERT) for multilingual image-speech retrieval. For non-English image-speech retrieval, we outperform the current state-of-the-art performance by a wide margin both when training separate models for each language, and with a single model which processes speech in all three languages. We identify key differences in model behavior and performance between English and non-English settings, attributable to the English-only pre-training of CLIP and HuBERT, and investigate how fine-tuning the pre-trained models impacts these differences. Finally, we show that our models can be used for mono- and cross-lingual speech-text retrieval and cross-lingual speech-speech retrieval, despite never having seen any parallel speech-text or speech-speech data during training.",
    "path": "papers/22/11/2211.01180.json",
    "total_tokens": 869,
    "translated_title": "M-SpeechCLIP：利用大规模预训练模型进行多语音到图像检索",
    "translated_abstract": "本文探讨使用大规模的英语预训练模型（CLIP和HuBERT）进行多语种图像-语音检索的方法。对于非英语图像-语音检索，我们在分别为每种语言训练单独模型以及处理所有三种语言语音的单一模型方面都取得了当前最先进性能的显著提高。我们确定了英语和非英语背景下模型行为和表现之间的主要差异，这些差异可以归因于CLIP和HuBERT的英语预训练，并探究了微调预训练模型如何影响这些差异。最后，我们展示了即使在训练期间从未看到任何平行语音-文本或语音-语音数据，我们的模型也可以用于单语和跨语音文本检索以及跨语音语音检索。",
    "tldr": "本文研究使用大规模预训练模型多语音到图像检索的方法，取得了在非英语检索中比当前最先进性能大幅提高的效果，并证明这些模型也适用于跨语音检索和跨语音文本检索。",
    "en_tdlr": "This paper investigates the use of large-scale pre-trained models for multilingual speech to image retrieval, achieving significant improvements in non-English retrieval and demonstrating the models' applicability for cross-lingual speech-text and speech-speech retrieval despite never having seen parallel speech-text or speech-speech data during training."
}