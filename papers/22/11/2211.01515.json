{
    "title": "MAST: Multiscale Audio Spectrogram Transformers. (arXiv:2211.01515v2 [eess.AS] UPDATED)",
    "abstract": "We present Multiscale Audio Spectrogram Transformer (MAST) for audio classification, which brings the concept of multiscale feature hierarchies to the Audio Spectrogram Transformer (AST). Given an input audio spectrogram, we first patchify and project it into an initial temporal resolution and embedding dimension, post which the multiple stages in MAST progressively expand the embedding dimension while reducing the temporal resolution of the input. We use a pyramid structure that allows early layers of MAST operating at a high temporal resolution but low embedding space to model simple low-level acoustic information and deeper temporally coarse layers to model high-level acoustic information with high-dimensional embeddings. We also extend our approach to present a new Self-Supervised Learning (SSL) method called SS-MAST, which calculates a symmetric contrastive loss between latent representations from a student and a teacher encoder, leveraging patch-drop, a novel audio augmentation a",
    "link": "http://arxiv.org/abs/2211.01515",
    "context": "Title: MAST: Multiscale Audio Spectrogram Transformers. (arXiv:2211.01515v2 [eess.AS] UPDATED)\nAbstract: We present Multiscale Audio Spectrogram Transformer (MAST) for audio classification, which brings the concept of multiscale feature hierarchies to the Audio Spectrogram Transformer (AST). Given an input audio spectrogram, we first patchify and project it into an initial temporal resolution and embedding dimension, post which the multiple stages in MAST progressively expand the embedding dimension while reducing the temporal resolution of the input. We use a pyramid structure that allows early layers of MAST operating at a high temporal resolution but low embedding space to model simple low-level acoustic information and deeper temporally coarse layers to model high-level acoustic information with high-dimensional embeddings. We also extend our approach to present a new Self-Supervised Learning (SSL) method called SS-MAST, which calculates a symmetric contrastive loss between latent representations from a student and a teacher encoder, leveraging patch-drop, a novel audio augmentation a",
    "path": "papers/22/11/2211.01515.json",
    "total_tokens": 973,
    "translated_title": "MAST:多尺度音频谱图变压器",
    "translated_abstract": "本文提出了一种用于音频分类的多尺度音频谱图变压器（MAST），将多尺度特征分层概念引入音频谱图变换器（AST）中。给定一个输入的音频谱图，我们首先将其裁剪成初步的时间分辨率和嵌入维度，随后MAST中的多个阶段逐渐扩展嵌入维度，同时降低输入的时间分辨率。我们使用金字塔结构，使得MAST的早期层在高时间分辨率但低嵌入空间下建模简单的低级声学信息，而较深的时间粗糙层则用高维嵌入来建模高级声学信息。我们还扩展了我们的方法，提出了一种新的自监督学习（SSL）方法，称为SS-MAST，它计算了一个对称的对比损失，利用patch-drop - 一种新的音频增强技术来自学习和教师编码器的潜在表示之间。",
    "tldr": "MAST是一种多尺度音频谱图变压器，引入了多尺度特征分层概念，同时扩展嵌入维度，降低时间分辨率，用于音频分类。通过金字塔结构实现早期层和深层的建模，扩展方法为SS-MAST。",
    "en_tdlr": "MAST is a multiscale audio spectrogram transformer that introduces the concept of multiscale feature hierarchies and expands embedding dimension while reducing temporal resolution for audio classification. It models simple low-level acoustic information in early layers and high-level acoustic information with high-dimensional embeddings in later layers using a pyramid structure. The approach is extended to SS-MAST, a new self-supervised learning method that calculates symmetric contrastive loss using patch-drop audio augmentation."
}