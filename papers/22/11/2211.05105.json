{
    "title": "Safe Latent Diffusion: Mitigating Inappropriate Degeneration in Diffusion Models. (arXiv:2211.05105v3 [cs.CV] UPDATED)",
    "abstract": "Text-conditioned image generation models have recently achieved astonishing results in image quality and text alignment and are consequently employed in a fast-growing number of applications. Since they are highly data-driven, relying on billion-sized datasets randomly scraped from the internet, they also suffer, as we demonstrate, from degenerated and biased human behavior. In turn, they may even reinforce such biases. To help combat these undesired side effects, we present safe latent diffusion (SLD). Specifically, to measure the inappropriate degeneration due to unfiltered and imbalanced training sets, we establish a novel image generation test bed-inappropriate image prompts (I2P)-containing dedicated, real-world image-to-text prompts covering concepts such as nudity and violence. As our exhaustive empirical evaluation demonstrates, the introduced SLD removes and suppresses inappropriate image parts during the diffusion process, with no additional training required and no adverse e",
    "link": "http://arxiv.org/abs/2211.05105",
    "context": "Title: Safe Latent Diffusion: Mitigating Inappropriate Degeneration in Diffusion Models. (arXiv:2211.05105v3 [cs.CV] UPDATED)\nAbstract: Text-conditioned image generation models have recently achieved astonishing results in image quality and text alignment and are consequently employed in a fast-growing number of applications. Since they are highly data-driven, relying on billion-sized datasets randomly scraped from the internet, they also suffer, as we demonstrate, from degenerated and biased human behavior. In turn, they may even reinforce such biases. To help combat these undesired side effects, we present safe latent diffusion (SLD). Specifically, to measure the inappropriate degeneration due to unfiltered and imbalanced training sets, we establish a novel image generation test bed-inappropriate image prompts (I2P)-containing dedicated, real-world image-to-text prompts covering concepts such as nudity and violence. As our exhaustive empirical evaluation demonstrates, the introduced SLD removes and suppresses inappropriate image parts during the diffusion process, with no additional training required and no adverse e",
    "path": "papers/22/11/2211.05105.json",
    "total_tokens": 908,
    "translated_title": "安全潜向扩散：缓解扩散模型中不当退化",
    "translated_abstract": "最近，基于文本的图像生成模型在图像质量和文本对齐方面取得了惊人的成果，并因此被广泛应用于越来越多的应用程序。由于它们高度依赖于随机从互联网上抓取的数十亿大小的数据集，因此它们也面临来自退化和偏见的人类行为的不良影响，正如我们所展示的那样。反过来，它们甚至可能强化这些偏见。为了帮助应对这些不良影响，我们提出了安全潜向扩散（SLD）。具体而言，为了衡量由于未过滤和不平衡的训练集而引起的不当退化，我们建立了一个新颖的图像生成测试平台——包含专门的、覆盖裸露和暴力等概念的实际图像到文本提示的不当图像提示（I2P）。正如我们详尽的实证评估所证明的那样，引入的SLD在扩散过程中移除和抑制了不当的图像部分，无需额外的训练，并且对图像质量没有不良影响。",
    "tldr": "该论文提出了一种名为安全潜向扩散的方法，可以在图像生成过程中移除和抑制不当的图像部分，从而缓解基于文本的图像生成模型因不当数据集带来的不良影响。"
}