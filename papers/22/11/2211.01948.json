{
    "title": "Efficiently Trained Low-Resource Mongolian Text-to-Speech System Based On FullConv-TTS. (arXiv:2211.01948v3 [cs.CL] UPDATED)",
    "abstract": "Recurrent Neural Networks (RNNs) have become the standard modeling technique for sequence data, and are used in a number of novel text-to-speech models. However, training a TTS model including RNN components has certain requirements for GPU performance and takes a long time. In contrast, studies have shown that CNN-based sequence synthesis technology can greatly reduce training time in text-to-speech models while ensuring a certain performance due to its high parallelism. We propose a new text-to-speech system based on deep convolutional neural networks that does not employ any RNN components (recurrent units). At the same time, we improve the generality and robustness of our model through a series of data augmentation methods such as Time Warping, Frequency Mask, and Time Mask. The final experimental results show that the TTS model using only the CNN component can reduce the training time compared to the classic TTS models such as Tacotron while ensuring the quality of the synthesized",
    "link": "http://arxiv.org/abs/2211.01948",
    "context": "Title: Efficiently Trained Low-Resource Mongolian Text-to-Speech System Based On FullConv-TTS. (arXiv:2211.01948v3 [cs.CL] UPDATED)\nAbstract: Recurrent Neural Networks (RNNs) have become the standard modeling technique for sequence data, and are used in a number of novel text-to-speech models. However, training a TTS model including RNN components has certain requirements for GPU performance and takes a long time. In contrast, studies have shown that CNN-based sequence synthesis technology can greatly reduce training time in text-to-speech models while ensuring a certain performance due to its high parallelism. We propose a new text-to-speech system based on deep convolutional neural networks that does not employ any RNN components (recurrent units). At the same time, we improve the generality and robustness of our model through a series of data augmentation methods such as Time Warping, Frequency Mask, and Time Mask. The final experimental results show that the TTS model using only the CNN component can reduce the training time compared to the classic TTS models such as Tacotron while ensuring the quality of the synthesized",
    "path": "papers/22/11/2211.01948.json",
    "total_tokens": 934,
    "translated_title": "基于全卷积神经网络训练的低资源蒙古语文本到语音系统的高效实现",
    "translated_abstract": "循环神经网络(RNN)已经成为了序列数据建模的标准技术，也被用于构建一些新奇的文本到语音模型。但是，包含RNN组件的TTS模型要求GPU性能高且训练时间长。相反，研究发现基于CNN的序列合成技术可以大大减少TTS模型的训练时间，同时由于其高度并行化，可以保证一定的性能。我们提出了一个基于深度卷积神经网络的新型文本到语音系统，不使用任何RNN组件(循环单元)。同时，通过一系列的数据增强方法，如时间扭曲，频率屏蔽和时间屏蔽等，提高了我们模型的普适性和鲁棒性。最终的实验结果表明，仅使用CNN组件的TTS模型可以减少与Tacotron等传统TTS模型相比的训练时间，同时确保合成音频的质量。",
    "tldr": "该论文提出了一个基于全卷积神经网络训练的低资源蒙古语文本到语音系统，相较于传统的包含循环神经网络的TTS模型，训练时间更短且音频合成质量不降低。"
}