{
    "title": "Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning. (arXiv:2211.03044v2 [cs.CL] UPDATED)",
    "abstract": "Recent studies have revealed the intriguing few-shot learning ability of pretrained language models (PLMs): They can quickly adapt to a new task when fine-tuned on a small amount of labeled data formulated as prompts, without requiring abundant task-specific annotations. Despite their promising performance, most existing few-shot approaches that only learn from the small training set still underperform fully supervised training by nontrivial margins. In this work, we study few-shot learning with PLMs from a different perspective: We first tune an autoregressive PLM on the few-shot samples and then use it as a generator to synthesize a large amount of novel training samples which augment the original training set. To encourage the generator to produce label-discriminative samples, we train it via weighted maximum likelihood where the weight of each token is automatically adjusted based on a discriminative meta-learning objective. A classification PLM can then be fine-tuned on both the f",
    "link": "http://arxiv.org/abs/2211.03044",
    "context": "Title: Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning. (arXiv:2211.03044v2 [cs.CL] UPDATED)\nAbstract: Recent studies have revealed the intriguing few-shot learning ability of pretrained language models (PLMs): They can quickly adapt to a new task when fine-tuned on a small amount of labeled data formulated as prompts, without requiring abundant task-specific annotations. Despite their promising performance, most existing few-shot approaches that only learn from the small training set still underperform fully supervised training by nontrivial margins. In this work, we study few-shot learning with PLMs from a different perspective: We first tune an autoregressive PLM on the few-shot samples and then use it as a generator to synthesize a large amount of novel training samples which augment the original training set. To encourage the generator to produce label-discriminative samples, we train it via weighted maximum likelihood where the weight of each token is automatically adjusted based on a discriminative meta-learning objective. A classification PLM can then be fine-tuned on both the f",
    "path": "papers/22/11/2211.03044.json",
    "total_tokens": 879,
    "translated_title": "以训练数据生成器为调整语言模型的增强学习少样本方法",
    "translated_abstract": "最近的研究揭示了预训练语言模型（PLM）惊人的少样本学习能力：它们可以在以提示形式表达的少量标记数据上微调后快速适应新任务，而无需丰富的任务特定注释。尽管有着很有前途的表现，但大多数仅从少量训练集学习的现有少样本方法仍然比非平凡的全监督训练表现不佳。在本文中，我们从不同的角度研究了使用PLMs进行少样本学习：我们首先调整自回归PLM，然后使用它作为生成器，合成大量新的训练样本，以增强原始训练集。为了鼓励生成器产生具有标签区分能力的样本，我们通过加权最大似然度量训练它，在其中每个令牌的权重基于一个区分性元学习目标自动调整。然后可以在增加后的训练集上微调分类PLM。",
    "tldr": "该论文通过调整预训练语言模型生成大量新的训练样本，从而增强原始训练集，提高了少样本学习的性能。",
    "en_tdlr": "This paper improves few-shot learning performance by tuning a pre-trained language model to generate a large amount of novel training samples, which then augment the original training set."
}