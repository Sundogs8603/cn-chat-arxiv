{
    "title": "Differentiable Model Selection for Ensemble Learning. (arXiv:2211.00251v2 [cs.LG] UPDATED)",
    "abstract": "Model selection is a strategy aimed at creating accurate and robust models. A key challenge in designing these algorithms is identifying the optimal model for classifying any particular input sample. This paper addresses this challenge and proposes a novel framework for differentiable model selection integrating machine learning and combinatorial optimization. The framework is tailored for ensemble learning, a strategy that combines the outputs of individually pre-trained models, and learns to select appropriate ensemble members for a particular input sample by transforming the ensemble learning task into a differentiable selection program trained end-to-end within the ensemble learning model. Tested on various tasks, the proposed framework demonstrates its versatility and effectiveness, outperforming conventional and advanced consensus rules across a variety of settings and learning tasks.",
    "link": "http://arxiv.org/abs/2211.00251",
    "context": "Title: Differentiable Model Selection for Ensemble Learning. (arXiv:2211.00251v2 [cs.LG] UPDATED)\nAbstract: Model selection is a strategy aimed at creating accurate and robust models. A key challenge in designing these algorithms is identifying the optimal model for classifying any particular input sample. This paper addresses this challenge and proposes a novel framework for differentiable model selection integrating machine learning and combinatorial optimization. The framework is tailored for ensemble learning, a strategy that combines the outputs of individually pre-trained models, and learns to select appropriate ensemble members for a particular input sample by transforming the ensemble learning task into a differentiable selection program trained end-to-end within the ensemble learning model. Tested on various tasks, the proposed framework demonstrates its versatility and effectiveness, outperforming conventional and advanced consensus rules across a variety of settings and learning tasks.",
    "path": "papers/22/11/2211.00251.json",
    "total_tokens": 822,
    "translated_title": "集成学习的可微分模型选择",
    "translated_abstract": "模型选择是创造准确和稳健模型的策略。设计这些算法的一个关键挑战是确定任何特定输入样本的最佳分类模型。本文解决了这一挑战，提出了一种新颖的可微分模型选择框架，整合了机器学习和组合优化。该框架专为集成学习而设计，该策略结合了单个预训练模型的输出，并通过将集成学习任务转化为可微分选择程序，在集成学习模型内端到端地训练学习为特定输入样本选择合适的集成成员。在各种任务上测试，所提出的框架展示了其多功能性和有效性，且在各种设置和学习任务中均优于传统和先进的共识规则。",
    "tldr": "本文提出了一种可微分模型选择框架，专为集成学习而设计，通过将集成学习任务转化为可微分选择程序，在集成学习模型内端到端地训练学习为特定输入样本选择合适的集成成员，有效性和多功能性均优于传统和先进的共识规则。",
    "en_tdlr": "This paper proposes a differentiable model selection framework tailored for ensemble learning, training the model to select appropriate ensemble members for a particular input sample by transforming the ensemble learning task into a differentiable selection program, demonstrating its versatility and effectiveness in various tasks and outperforming conventional and advanced consensus rules."
}