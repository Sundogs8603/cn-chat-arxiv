{
    "title": "Modelling black-box audio effects with time-varying feature modulation. (arXiv:2211.00497v2 [cs.SD] UPDATED)",
    "abstract": "Deep learning approaches for black-box modelling of audio effects have shown promise, however, the majority of existing work focuses on nonlinear effects with behaviour on relatively short time-scales, such as guitar amplifiers and distortion. While recurrent and convolutional architectures can theoretically be extended to capture behaviour at longer time scales, we show that simply scaling the width, depth, or dilation factor of existing architectures does not result in satisfactory performance when modelling audio effects such as fuzz and dynamic range compression. To address this, we propose the integration of time-varying feature-wise linear modulation into existing temporal convolutional backbones, an approach that enables learnable adaptation of the intermediate activations. We demonstrate that our approach more accurately captures long-range dependencies for a range of fuzz and compressor implementations across both time and frequency domain metrics. We provide sound examples, s",
    "link": "http://arxiv.org/abs/2211.00497",
    "context": "Title: Modelling black-box audio effects with time-varying feature modulation. (arXiv:2211.00497v2 [cs.SD] UPDATED)\nAbstract: Deep learning approaches for black-box modelling of audio effects have shown promise, however, the majority of existing work focuses on nonlinear effects with behaviour on relatively short time-scales, such as guitar amplifiers and distortion. While recurrent and convolutional architectures can theoretically be extended to capture behaviour at longer time scales, we show that simply scaling the width, depth, or dilation factor of existing architectures does not result in satisfactory performance when modelling audio effects such as fuzz and dynamic range compression. To address this, we propose the integration of time-varying feature-wise linear modulation into existing temporal convolutional backbones, an approach that enables learnable adaptation of the intermediate activations. We demonstrate that our approach more accurately captures long-range dependencies for a range of fuzz and compressor implementations across both time and frequency domain metrics. We provide sound examples, s",
    "path": "papers/22/11/2211.00497.json",
    "total_tokens": 868,
    "translated_title": "利用时变特征调制模拟黑盒音频效应",
    "translated_abstract": "深度学习方法用于黑盒建模音效已显示出很大的潜力。但是，现有大部分工作集中在具有相对较短时间尺度行为的非线性效应，例如吉他放大器和失真。虽然递归和卷积结构在理论上可以扩展到长时间尺度来捕获行为，但我们发现简单地扩展现有结构的宽度、深度或膨胀因子不能令其在模拟fuzz和动态范围压缩等音频效应时表现得十分令人满意。为了解决这个问题，我们提出在现有的时间卷积骨干中整合时变特征的线性调制的方法，使中间激活可以进行可学习的自适应。我们展示了我们的方法更准确捕获了一系列fuzz和压缩实现的长距离依赖关系，包括时间和频率领域的指标。我们提供了声音示例。",
    "tldr": "提出了利用时变特征调制来模拟黑盒音频效应，可以更好地捕获长时间尺度上的依赖关系，适用于fuzz和压缩等音频效应。",
    "en_tdlr": "A time-varying feature modulation approach is proposed to model black-box audio effects, which enables the learnable adaptation of intermediate activations and better captures long-range dependencies, showing promising results for a range of audio effects including fuzz and compressor implementations."
}