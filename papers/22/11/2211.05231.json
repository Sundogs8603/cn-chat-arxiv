{
    "title": "Biologically-Inspired Continual Learning of Human Motion Sequences. (arXiv:2211.05231v2 [cs.CV] UPDATED)",
    "abstract": "This work proposes a model for continual learning on tasks involving temporal sequences, specifically, human motions. It improves on a recently proposed brain-inspired replay model (BI-R) by building a biologically-inspired conditional temporal variational autoencoder (BI-CTVAE), which instantiates a latent mixture-of-Gaussians for class representation. We investigate a novel continual-learning-to-generate (CL2Gen) scenario where the model generates motion sequences of different classes. The generative accuracy of the model is tested over a set of tasks. The final classification accuracy of BI-CTVAE on a human motion dataset after sequentially learning all action classes is 78%, which is 63% higher than using no-replay, and only 5.4% lower than a state-of-the-art offline trained GRU model.",
    "link": "http://arxiv.org/abs/2211.05231",
    "context": "Title: Biologically-Inspired Continual Learning of Human Motion Sequences. (arXiv:2211.05231v2 [cs.CV] UPDATED)\nAbstract: This work proposes a model for continual learning on tasks involving temporal sequences, specifically, human motions. It improves on a recently proposed brain-inspired replay model (BI-R) by building a biologically-inspired conditional temporal variational autoencoder (BI-CTVAE), which instantiates a latent mixture-of-Gaussians for class representation. We investigate a novel continual-learning-to-generate (CL2Gen) scenario where the model generates motion sequences of different classes. The generative accuracy of the model is tested over a set of tasks. The final classification accuracy of BI-CTVAE on a human motion dataset after sequentially learning all action classes is 78%, which is 63% higher than using no-replay, and only 5.4% lower than a state-of-the-art offline trained GRU model.",
    "path": "papers/22/11/2211.05231.json",
    "total_tokens": 856,
    "translated_title": "受生物启示的人类运动序列的持续学习模型",
    "translated_abstract": "本文提出了一种持续学习模型，专注于涉及时间序列——具体而言，是人的运动。该模型改进了最近提出的类似于大脑的重放模型(BI-R)，它建立了一个受生物启示的条件时间变分自动编码器(BI-CTVAE)，其实例化了一个高斯函数混合体来表示类别。我们研究了一种新颖的持续学习生成(CL2Gen)场景，其中模型生成不同类别的运动序列。模型的生成准确性在一组任务上进行了测试。在按顺序学习所有动作类别之后，BI-CTVAE在一个人类运动数据集上的最终分类准确性达到了78％，比不使用重放高63％，比最先进的离线训练GRU模型低5.4％。",
    "tldr": "本文提出了一个受生物启示的条件时间变分自动编码器(BI-CTVAE)模型，通过持续学习生成(CL2Gen)场景，可以对不同类别的运动序列进行生成，并在一组任务上得到较高的生成准确性和分类准确性。",
    "en_tdlr": "This paper proposes a biologically-inspired conditional temporal variational autoencoder (BI-CTVAE) model for continual learning on tasks involving human motion sequences. The model achieves high generative and classification accuracy on a set of tasks, and can generate motion sequences of different classes in a continual-learning-to-generate (CL2Gen) scenario."
}