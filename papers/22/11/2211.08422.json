{
    "title": "Mechanistic Mode Connectivity. (arXiv:2211.08422v2 [cs.LG] UPDATED)",
    "abstract": "We study neural network loss landscapes through the lens of mode connectivity, the observation that minimizers of neural networks retrieved via training on a dataset are connected via simple paths of low loss. Specifically, we ask the following question: are minimizers that rely on different mechanisms for making their predictions connected via simple paths of low loss? We provide a definition of mechanistic similarity as shared invariances to input transformations and demonstrate that lack of linear connectivity between two models implies they use dissimilar mechanisms for making their predictions. Relevant to practice, this result helps us demonstrate that naive fine-tuning on a downstream dataset can fail to alter a model's mechanisms, e.g., fine-tuning can fail to eliminate a model's reliance on spurious attributes. Our analysis also motivates a method for targeted alteration of a model's mechanisms, named connectivity-based fine-tuning (CBFT), which we analyze using several synthe",
    "link": "http://arxiv.org/abs/2211.08422",
    "context": "Title: Mechanistic Mode Connectivity. (arXiv:2211.08422v2 [cs.LG] UPDATED)\nAbstract: We study neural network loss landscapes through the lens of mode connectivity, the observation that minimizers of neural networks retrieved via training on a dataset are connected via simple paths of low loss. Specifically, we ask the following question: are minimizers that rely on different mechanisms for making their predictions connected via simple paths of low loss? We provide a definition of mechanistic similarity as shared invariances to input transformations and demonstrate that lack of linear connectivity between two models implies they use dissimilar mechanisms for making their predictions. Relevant to practice, this result helps us demonstrate that naive fine-tuning on a downstream dataset can fail to alter a model's mechanisms, e.g., fine-tuning can fail to eliminate a model's reliance on spurious attributes. Our analysis also motivates a method for targeted alteration of a model's mechanisms, named connectivity-based fine-tuning (CBFT), which we analyze using several synthe",
    "path": "papers/22/11/2211.08422.json",
    "total_tokens": 922,
    "translated_title": "机制模式连通性",
    "translated_abstract": "我们从模式连通性的视角研究神经网络损失景观，即通过在数据集上训练而检索到的神经网络的最小化器通过低损失的简单路径相互连接。具体而言，我们提出了机制相似性的定义，即与输入转换的共享不变性，并演示了两个模型之间缺乏线性连通性意味着它们使用不同的机制来做出预测。与实践相关的是，这个结果帮助我们证明了在下游数据集上的简单微调可能无法改变模型的机制，例如，微调可能无法消除模型对虚假特征的依赖。我们的分析还推动了一种名为基于连通性的微调（CBFT）的目标变化模型机制的方法，我们使用几个合成数据集对其进行了分析。",
    "tldr": "本文从模式连通性的视角研究神经网络损失景观，提出了机制相似性的定义，并演示了两个模型之间缺乏线性连通性意味着它们使用不同的机制来做出预测。此外，本文还提出了一种名为基于连通性的微调（CBFT）的方法，用于目标修改模型机制，有助于消除模型对虚假特征的依赖。",
    "en_tdlr": "This paper studies the neural network loss landscapes from the perspective of mode connectivity and defines mechanistic similarity as shared invariances to input transformations. Lack of linear connectivity between two models implies they use dissimilar mechanisms for making their predictions. The paper proposes a connectivity-based fine-tuning method (CBFT) to target alteration of a model's mechanisms and eliminate the model's reliance on spurious attributes."
}