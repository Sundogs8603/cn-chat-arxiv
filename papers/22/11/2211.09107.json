{
    "title": "Interpretable Few-shot Learning with Online Attribute Selection. (arXiv:2211.09107v2 [cs.LG] UPDATED)",
    "abstract": "Few-shot learning (FSL) is a challenging learning problem in which only a few samples are available for each class. Decision interpretation is more important in few-shot classification since there is a greater chance of error than in traditional classification. However, most of the previous FSL methods are black-box models. In this paper, we propose an inherently interpretable model for FSL based on human-friendly attributes. Moreover, we propose an online attribute selection mechanism that can effectively filter out irrelevant attributes in each episode. The attribute selection mechanism improves the accuracy and helps with interpretability by reducing the number of participated attributes in each episode. We propose a mechanism that automatically detects the episodes where the pool of human-friendly attributes are not adequate, and compensates by engaging learned unknown attributes. We demonstrate that the proposed method achieves results on par with black-box few-shot-learning model",
    "link": "http://arxiv.org/abs/2211.09107",
    "context": "Title: Interpretable Few-shot Learning with Online Attribute Selection. (arXiv:2211.09107v2 [cs.LG] UPDATED)\nAbstract: Few-shot learning (FSL) is a challenging learning problem in which only a few samples are available for each class. Decision interpretation is more important in few-shot classification since there is a greater chance of error than in traditional classification. However, most of the previous FSL methods are black-box models. In this paper, we propose an inherently interpretable model for FSL based on human-friendly attributes. Moreover, we propose an online attribute selection mechanism that can effectively filter out irrelevant attributes in each episode. The attribute selection mechanism improves the accuracy and helps with interpretability by reducing the number of participated attributes in each episode. We propose a mechanism that automatically detects the episodes where the pool of human-friendly attributes are not adequate, and compensates by engaging learned unknown attributes. We demonstrate that the proposed method achieves results on par with black-box few-shot-learning model",
    "path": "papers/22/11/2211.09107.json",
    "total_tokens": 843,
    "translated_title": "在线属性选择的可解释的小样本学习",
    "translated_abstract": "小样本学习(few-shot learning, FSL)是一种挑战性的学习问题，每个类别只有很少的样本可用。在FSL中决策的解释比传统分类更加重要，因为错误的几率更大。然而，大多数以前的FSL方法都是黑匣子模型。本文提出了一种基于易于理解的属性的天然可解释模型来处理FSL。此外，我们提出了一种在线属性选择机制，以有效过滤每个episode中不相关的属性。该属性选择机制通过减少每个episode中涉及的属性数量来提高准确性和可解释性。我们提出了一种机制，自动检测人工智能属性池不足的episode，并通过涉及学习的未知属性来补偿。我们证明了所提出的方法可以实现与黑匣子小样本学习模型相当的结果。",
    "tldr": "本文提出了一种在线属性选择机制的天然可解释模型来处理小样本学习，通过减少每个episode中涉及的属性数量提高准确性和可解释性，同时自动检测并补偿人工智能属性池不足的episode。",
    "en_tdlr": "This paper proposes a naturally interpretable model for few-shot learning based on an online attribute selection mechanism, which improves accuracy and interpretability by reducing the number of involved attributes in each episode, and automatically detects and compensates for episodes where the pool of human-friendly attributes is insufficient."
}