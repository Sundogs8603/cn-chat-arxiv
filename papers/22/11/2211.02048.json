{
    "title": "Efficient Spatially Sparse Inference for Conditional GANs and Diffusion Models. (arXiv:2211.02048v3 [cs.CV] UPDATED)",
    "abstract": "During image editing, existing deep generative models tend to re-synthesize the entire output from scratch, including the unedited regions. This leads to a significant waste of computation, especially for minor editing operations. In this work, we present Spatially Sparse Inference (SSI), a general-purpose technique that selectively performs computation for edited regions and accelerates various generative models, including both conditional GANs and diffusion models. Our key observation is that users tend to gradually change the input image. This motivates us to cache and reuse the feature maps of the original image. Given an edited image, we sparsely apply the convolutional filters to the edited regions while reusing the cached features for the unedited areas. Based on our algorithm, we further propose Sparse Incremental Generative Engine (SIGE) to convert the computation reduction to latency reduction on off-the-shelf hardware. With about $1\\%$-area edits, our method reduces the comp",
    "link": "http://arxiv.org/abs/2211.02048",
    "context": "Title: Efficient Spatially Sparse Inference for Conditional GANs and Diffusion Models. (arXiv:2211.02048v3 [cs.CV] UPDATED)\nAbstract: During image editing, existing deep generative models tend to re-synthesize the entire output from scratch, including the unedited regions. This leads to a significant waste of computation, especially for minor editing operations. In this work, we present Spatially Sparse Inference (SSI), a general-purpose technique that selectively performs computation for edited regions and accelerates various generative models, including both conditional GANs and diffusion models. Our key observation is that users tend to gradually change the input image. This motivates us to cache and reuse the feature maps of the original image. Given an edited image, we sparsely apply the convolutional filters to the edited regions while reusing the cached features for the unedited areas. Based on our algorithm, we further propose Sparse Incremental Generative Engine (SIGE) to convert the computation reduction to latency reduction on off-the-shelf hardware. With about $1\\%$-area edits, our method reduces the comp",
    "path": "papers/22/11/2211.02048.json",
    "total_tokens": 1033,
    "translated_title": "有效稀疏推理用于条件GAN和扩散模型",
    "translated_abstract": "在图像编辑中，现有的深度生成模型往往会从头开始重新合成整个输出，包括未编辑的区域。这导致计算资源的浪费，尤其是对于较小的编辑操作。在这项工作中，我们提出了空间稀疏推理（SSI）的通用技术，该技术选择性地为编辑区域执行计算并加速各种生成模型，包括条件GAN和扩散模型。我们的关键观察是用户倾向于逐渐改变输入图像，这激发了我们缓存和重复使用原始图像的特征图的想法。给定编辑过的图像，我们稀疏地将卷积滤波器应用于编辑区域，同时重复使用未编辑区域的缓存特征。基于我们的算法，我们进一步提出了稀疏渐进式生成引擎（SIGE）来将计算减少转化为在现成硬件上的延迟减少。我们的方法通过约$1\\%$的区域编辑，减少了计算资源的浪费。",
    "tldr": "提出了空间稀疏推理（SSI）的通用技术，该技术选择性地为编辑区域执行计算并加速各种生成模型，包括条件GAN和扩散模型。通过缓存和重复使用原始图像的特征图，我们将卷积滤波器稀疏地应用于编辑区域，并在未编辑的区域中重复使用缓存特征，从而通过约$1\\%$的区域编辑来减少计算资源的浪费。"
}