{
    "title": "Harnessing the Power of Explanations for Incremental Training: A LIME-Based Approach. (arXiv:2211.01413v2 [cs.LG] UPDATED)",
    "abstract": "Explainability of neural network prediction is essential to understand feature importance and gain interpretable insight into neural network performance. However, explanations of neural network outcomes are mostly limited to visualization, and there is scarce work that looks to use these explanations as feedback to improve model performance. In this work, model explanations are fed back to the feed-forward training to help the model generalize better. To this extent, a custom weighted loss where the weights are generated by considering the Euclidean distances between true LIME (Local Interpretable Model-Agnostic Explanations) explanations and model-predicted LIME explanations is proposed. Also, in practical training scenarios, developing a solution that can help the model learn sequentially without losing information on previous data distribution is imperative due to the unavailability of all the training data at once. Thus, the framework incorporates the custom weighted loss with Elas",
    "link": "http://arxiv.org/abs/2211.01413",
    "context": "Title: Harnessing the Power of Explanations for Incremental Training: A LIME-Based Approach. (arXiv:2211.01413v2 [cs.LG] UPDATED)\nAbstract: Explainability of neural network prediction is essential to understand feature importance and gain interpretable insight into neural network performance. However, explanations of neural network outcomes are mostly limited to visualization, and there is scarce work that looks to use these explanations as feedback to improve model performance. In this work, model explanations are fed back to the feed-forward training to help the model generalize better. To this extent, a custom weighted loss where the weights are generated by considering the Euclidean distances between true LIME (Local Interpretable Model-Agnostic Explanations) explanations and model-predicted LIME explanations is proposed. Also, in practical training scenarios, developing a solution that can help the model learn sequentially without losing information on previous data distribution is imperative due to the unavailability of all the training data at once. Thus, the framework incorporates the custom weighted loss with Elas",
    "path": "papers/22/11/2211.01413.json",
    "total_tokens": 976,
    "translated_title": "利用解释的力量进行增量训练：基于LIME的方法",
    "translated_abstract": "神经网络预测的可解释性对于理解特征重要性并获得可解释的洞察力至关重要。然而，对神经网络结果的解释大多局限于可视化，并且很少有研究将这些解释用作改进模型性能的反馈。本研究将模型的解释反馈到前馈训练中，以帮助模型更好地泛化。为此，提出了一种自定义加权损失，其中权重是通过考虑真实LIME（局部可解释的模型无关解释）解释和模型预测的LIME解释之间的欧式距离来生成的。此外，在实际的训练场景中，开发一个能够帮助模型顺序学习而不丢失先前数据分布信息的解决方案是必要的，因为不会一次性提供所有的训练数据。因此，该框架将自定义加权损失与弹性训练相结合。",
    "tldr": "本研究提出了一种基于LIME的方法，利用解释来改善神经网络模型性能。通过引入自定义加权损失，将真实LIME解释与模型预测的LIME解释之间的距离考虑在内，帮助模型更好地泛化。此外，该研究还提出了一种适用于实际训练场景的解决方案，以帮助模型顺序学习而不丢失先前数据分布信息。",
    "en_tdlr": "This work proposes a LIME-based approach to improve neural network model performance by utilizing explanations. The custom weighted loss, considering the distances between true and predicted LIME explanations, helps the model generalize better. Additionally, a solution for sequential learning in practical training scenarios is developed to retain previous data distribution information."
}