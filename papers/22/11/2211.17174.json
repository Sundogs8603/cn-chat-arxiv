{
    "title": "Optimizing Explanations by Network Canonization and Hyperparameter Search. (arXiv:2211.17174v2 [cs.CV] UPDATED)",
    "abstract": "Explainable AI (XAI) is slowly becoming a key component for many AI applications. Rule-based and modified backpropagation XAI approaches however often face challenges when being applied to modern model architectures including innovative layer building blocks, which is caused by two reasons. Firstly, the high flexibility of rule-based XAI methods leads to numerous potential parameterizations. Secondly, many XAI methods break the implementation-invariance axiom because they struggle with certain model components, e.g., BatchNorm layers. The latter can be addressed with model canonization, which is the process of re-structuring the model to disregard problematic components without changing the underlying function. While model canonization is straightforward for simple architectures (e.g., VGG, ResNet), it can be challenging for more complex and highly interconnected models (e.g., DenseNet). Moreover, there is only little quantifiable evidence that model canonization is beneficial for XAI.",
    "link": "http://arxiv.org/abs/2211.17174",
    "context": "Title: Optimizing Explanations by Network Canonization and Hyperparameter Search. (arXiv:2211.17174v2 [cs.CV] UPDATED)\nAbstract: Explainable AI (XAI) is slowly becoming a key component for many AI applications. Rule-based and modified backpropagation XAI approaches however often face challenges when being applied to modern model architectures including innovative layer building blocks, which is caused by two reasons. Firstly, the high flexibility of rule-based XAI methods leads to numerous potential parameterizations. Secondly, many XAI methods break the implementation-invariance axiom because they struggle with certain model components, e.g., BatchNorm layers. The latter can be addressed with model canonization, which is the process of re-structuring the model to disregard problematic components without changing the underlying function. While model canonization is straightforward for simple architectures (e.g., VGG, ResNet), it can be challenging for more complex and highly interconnected models (e.g., DenseNet). Moreover, there is only little quantifiable evidence that model canonization is beneficial for XAI.",
    "path": "papers/22/11/2211.17174.json",
    "total_tokens": 851,
    "translated_title": "通过网络规范化和超参数搜索优化解释",
    "translated_abstract": "解释型人工智能（XAI）正在逐渐成为许多人工智能应用的关键组成部分。然而，基于规则和修改后的反向传播XAI方法往往在应用于现代模型架构时面临挑战，包括创新的层构建块，这是由两个原因造成的。首先，基于规则的XAI方法的高灵活性导致了许多潜在的参数化。其次，许多XAI方法破坏了实现不变性公理，因为他们无法处理某些模型组件，例如BatchNorm层。后者可以通过模型规范化来解决，模型规范化是重新组织模型以忽略有问题的组件而不改变基本函数的过程。虽然对于简单的架构（例如VGG、ResNet），模型规范化很简单，但对于更复杂和高度互联的模型（例如DenseNet），它可能具有挑战性。此外，只有很少的可量化证据表明模型规范化对XAI有益。",
    "tldr": "这篇论文介绍了新的解释人工智能方法，通过网络规范化和超参数搜索来提高解释效果。",
    "en_tdlr": "This paper introduces new methods for explainable artificial intelligence, which aim to improve explanation effectiveness through network canonization and hyperparameter search."
}