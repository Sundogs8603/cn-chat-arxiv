{
    "title": "Self-Destructing Models: Increasing the Costs of Harmful Dual Uses of Foundation Models. (arXiv:2211.14946v2 [cs.LG] UPDATED)",
    "abstract": "A growing ecosystem of large, open-source foundation models has reduced the labeled data and technical expertise necessary to apply machine learning to many new problems. Yet foundation models pose a clear dual-use risk, indiscriminately reducing the costs of building both harmful and beneficial machine learning systems. Policy tools such as restricted model access and export controls are the primary methods currently used to mitigate such dual-use risks. In this work, we review potential safe-release strategies and argue that both policymakers and AI researchers would benefit from fundamentally new technologies enabling more precise control over the downstream usage of open-source foundation models. We propose one such approach: the task blocking paradigm, in which foundation models are trained with an additional mechanism to impede adaptation to harmful tasks without sacrificing performance on desirable tasks. We call the resulting models self-destructing models, inspired by mechanis",
    "link": "http://arxiv.org/abs/2211.14946",
    "context": "Title: Self-Destructing Models: Increasing the Costs of Harmful Dual Uses of Foundation Models. (arXiv:2211.14946v2 [cs.LG] UPDATED)\nAbstract: A growing ecosystem of large, open-source foundation models has reduced the labeled data and technical expertise necessary to apply machine learning to many new problems. Yet foundation models pose a clear dual-use risk, indiscriminately reducing the costs of building both harmful and beneficial machine learning systems. Policy tools such as restricted model access and export controls are the primary methods currently used to mitigate such dual-use risks. In this work, we review potential safe-release strategies and argue that both policymakers and AI researchers would benefit from fundamentally new technologies enabling more precise control over the downstream usage of open-source foundation models. We propose one such approach: the task blocking paradigm, in which foundation models are trained with an additional mechanism to impede adaptation to harmful tasks without sacrificing performance on desirable tasks. We call the resulting models self-destructing models, inspired by mechanis",
    "path": "papers/22/11/2211.14946.json",
    "total_tokens": 889,
    "translated_title": "自毁模型：增加基础模型有害双重用途的成本",
    "translated_abstract": "一个日益增长的大规模开源基础模型生态系统，降低了应用机器学习解决许多新问题所需的标注数据和技术专长。然而，基础模型存在明显的双重用途风险，无差别地降低了构建有害和有益机器学习系统的成本。目前，政策工具如限制模型访问和出口管制是缓解此类双重用途风险的主要方法。在这项工作中，我们回顾了潜在的安全发布策略，并认为政策制定者和人工智能研究人员都将受益于能够更精确控制开源基础模型下游使用的基础新技术。我们提出了一种方法：任务阻断范式，即在基础模型训练时使用额外机制阻碍对有害任务的适应而不损失对理想任务的性能。我们称这种模型为自毁模型，受到机械设备的启发。",
    "tldr": "本论文提出了一种名为自毁模型的方法，通过任务阻断范式实现对基础模型下游使用的更精确控制，从而降低基础模型的有害双重用途风险。",
    "en_tdlr": "This paper proposes a method called self-destructing models, which uses the task blocking paradigm to achieve more precise control over the downstream usage of foundation models, thus reducing the dual-use risk of foundation models."
}