{
    "title": "Learning Antidote Data to Individual Unfairness. (arXiv:2211.15897v3 [cs.LG] UPDATED)",
    "abstract": "Fairness is essential for machine learning systems deployed in high-stake applications. Among all fairness notions, individual fairness, deriving from a consensus that `similar individuals should be treated similarly,' is a vital notion to describe fair treatment for individual cases. Previous studies typically characterize individual fairness as a prediction-invariant problem when perturbing sensitive attributes on samples, and solve it by Distributionally Robust Optimization (DRO) paradigm. However, such adversarial perturbations along a direction covering sensitive information used in DRO do not consider the inherent feature correlations or innate data constraints, therefore could mislead the model to optimize at off-manifold and unrealistic samples. In light of this drawback, in this paper, we propose to learn and generate antidote data that approximately follows the data distribution to remedy individual unfairness. These generated on-manifold antidote data can be used through a g",
    "link": "http://arxiv.org/abs/2211.15897",
    "context": "Title: Learning Antidote Data to Individual Unfairness. (arXiv:2211.15897v3 [cs.LG] UPDATED)\nAbstract: Fairness is essential for machine learning systems deployed in high-stake applications. Among all fairness notions, individual fairness, deriving from a consensus that `similar individuals should be treated similarly,' is a vital notion to describe fair treatment for individual cases. Previous studies typically characterize individual fairness as a prediction-invariant problem when perturbing sensitive attributes on samples, and solve it by Distributionally Robust Optimization (DRO) paradigm. However, such adversarial perturbations along a direction covering sensitive information used in DRO do not consider the inherent feature correlations or innate data constraints, therefore could mislead the model to optimize at off-manifold and unrealistic samples. In light of this drawback, in this paper, we propose to learn and generate antidote data that approximately follows the data distribution to remedy individual unfairness. These generated on-manifold antidote data can be used through a g",
    "path": "papers/22/11/2211.15897.json",
    "total_tokens": 934,
    "translated_title": "学习用于消除个人不公平性的解毒数据",
    "translated_abstract": "在高风险应用中部署机器学习系统时，公平性至关重要。在所有公平性概念中，个体公平性是一个重要概念，它源自一个共识：`相似的个体应该得到相似的对待'，以此来描述个别案例的公平对待。以往的研究通常将个体公平性描述为在样本上扰动敏感属性时的预测不变性问题，并通过分布鲁棒优化（DRO）范式来解决它。然而，这种沿着覆盖敏感信息的方向的对抗性扰动没有考虑特征相关性或内在的数据约束，因此可能会使模型优化到离曲面较远和不现实的样本。鉴于此缺点，本文提出了学习和生成近似遵循数据分布的解毒数据，用来治疗个体不公平性。这些生成的曲面上解毒数据可以通过生成式对抗网络（GAN）和一种基于潜在空间超平面的方法进行生成和控制。",
    "tldr": "本文提出了一种通过生成解毒数据来治疗个体不公平性的方法。通过使用生成式对抗网络（GAN）和基于潜在空间超平面的方法生成近似遵循数据分布的解毒数据，可以消除模型在非真实样本上的优化。",
    "en_tdlr": "This paper proposes a method for remedying individual unfairness by generating antidote data that approximately follows the data distribution. The generated on-manifold antidote data, created using a Generative Adversarial Network (GAN) and a method based on the latent space hyperplane, can eliminate the model's optimization on unrealistic samples."
}