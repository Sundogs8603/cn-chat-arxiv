{
    "title": "DeepTaster: Adversarial Perturbation-Based Fingerprinting to Identify Proprietary Dataset Use in Deep Neural Networks. (arXiv:2211.13535v2 [cs.CR] UPDATED)",
    "abstract": "Training deep neural networks (DNNs) requires large datasets and powerful computing resources, which has led some owners to restrict redistribution without permission. Watermarking techniques that embed confidential data into DNNs have been used to protect ownership, but these can degrade model performance and are vulnerable to watermark removal attacks. Recently, DeepJudge was introduced as an alternative approach to measuring the similarity between a suspect and a victim model. While DeepJudge shows promise in addressing the shortcomings of watermarking, it primarily addresses situations where the suspect model copies the victim's architecture. In this study, we introduce DeepTaster, a novel DNN fingerprinting technique, to address scenarios where a victim's data is unlawfully used to build a suspect model. DeepTaster can effectively identify such DNN model theft attacks, even when the suspect model's architecture deviates from the victim's. To accomplish this, DeepTaster generates a",
    "link": "http://arxiv.org/abs/2211.13535",
    "context": "Title: DeepTaster: Adversarial Perturbation-Based Fingerprinting to Identify Proprietary Dataset Use in Deep Neural Networks. (arXiv:2211.13535v2 [cs.CR] UPDATED)\nAbstract: Training deep neural networks (DNNs) requires large datasets and powerful computing resources, which has led some owners to restrict redistribution without permission. Watermarking techniques that embed confidential data into DNNs have been used to protect ownership, but these can degrade model performance and are vulnerable to watermark removal attacks. Recently, DeepJudge was introduced as an alternative approach to measuring the similarity between a suspect and a victim model. While DeepJudge shows promise in addressing the shortcomings of watermarking, it primarily addresses situations where the suspect model copies the victim's architecture. In this study, we introduce DeepTaster, a novel DNN fingerprinting technique, to address scenarios where a victim's data is unlawfully used to build a suspect model. DeepTaster can effectively identify such DNN model theft attacks, even when the suspect model's architecture deviates from the victim's. To accomplish this, DeepTaster generates a",
    "path": "papers/22/11/2211.13535.json",
    "total_tokens": 1001,
    "translated_title": "DeepTaster: 基于对抗扰动的指纹识别技术，用于在深度神经网络中识别专有数据集的使用。",
    "translated_abstract": "训练深度神经网络（DNN）需要大量的数据集和强大的计算资源，这导致一些所有者限制未经许可的重新分发。将保密数据嵌入DNN的水印技术被用于保护所有权，但这些技术可能会降低模型性能，并且易受水印去除攻击的影响。最近，DeepJudge被引入为一种替代方法，用于衡量嫌疑模型与受害模型之间的相似性。虽然DeepJudge在解决水印技术的不足方面表现出了潜力，但它主要应用于嫌疑模型抄袭受害模型架构的情况。在本研究中，我们引入了DeepTaster，一种新颖的DNN指纹识别技术，用于解决使用受害者数据非法构建嫌疑模型的情况。DeepTaster能够有效地识别这种DNN模型盗窃攻击，即使嫌疑模型的架构与受害模型不同。为了实现这一点，DeepTaster生成一个对受害模型具有鲁棒性且可以一致性地识别的独特指纹。",
    "tldr": "DeepTaster是一种新颖的DNN指纹识别技术，可以有效识别使用受害者数据非法构建嫌疑模型的攻击，即使嫌疑模型的架构与受害模型不同。"
}