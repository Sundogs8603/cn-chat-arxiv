{
    "title": "Understanding BLOOM: An empirical study on diverse NLP tasks. (arXiv:2211.14865v2 [cs.CL] UPDATED)",
    "abstract": "We view the landscape of large language models (LLMs) through the lens of the recently released BLOOM model to understand the performance of BLOOM and other decoder-only LLMs compared to BERT-style encoder-only models. We achieve this by evaluating the smaller BLOOM model variants (\\textit{350m/560m} and \\textit{1b3/1b7}) on several NLP benchmark datasets and popular leaderboards. We make the following observations: (1) BLOOM performance does not scale with parameter size, unlike other LLMs like GPT and BERT. Experiments fine-tuning BLOOM models show that the 560m variant performs similarly to or better than the 1b7 variant, (2) Zero-shot cross-lingual and multi-lingual fine-tuning experiments show that BLOOM is at par or worse than monolingual GPT-2 models, and (3) Toxicity analysis of prompt-based text generation using the RealToxicityPrompts dataset shows that the text generated by BLOOM is at least 17\\% less toxic than GPT-2 and GPT-3 models.",
    "link": "http://arxiv.org/abs/2211.14865",
    "context": "Title: Understanding BLOOM: An empirical study on diverse NLP tasks. (arXiv:2211.14865v2 [cs.CL] UPDATED)\nAbstract: We view the landscape of large language models (LLMs) through the lens of the recently released BLOOM model to understand the performance of BLOOM and other decoder-only LLMs compared to BERT-style encoder-only models. We achieve this by evaluating the smaller BLOOM model variants (\\textit{350m/560m} and \\textit{1b3/1b7}) on several NLP benchmark datasets and popular leaderboards. We make the following observations: (1) BLOOM performance does not scale with parameter size, unlike other LLMs like GPT and BERT. Experiments fine-tuning BLOOM models show that the 560m variant performs similarly to or better than the 1b7 variant, (2) Zero-shot cross-lingual and multi-lingual fine-tuning experiments show that BLOOM is at par or worse than monolingual GPT-2 models, and (3) Toxicity analysis of prompt-based text generation using the RealToxicityPrompts dataset shows that the text generated by BLOOM is at least 17\\% less toxic than GPT-2 and GPT-3 models.",
    "path": "papers/22/11/2211.14865.json",
    "total_tokens": 971,
    "translated_title": "解析BLOOM：对各种NLP任务的实证研究",
    "translated_abstract": "本文通过评估较小的BLOOM模型（350m/560m和1b3/1b7）在多个NLP基准数据集和流行排行榜上的表现，以了解BLOOM和其他仅使用解码器的LLM与BERT式编码器-仅模型的性能。 我们得出以下观察结果:（1）BLOOM的性能与参数大小没有正比例关系，不同于GPT和BERT等其他LLM。微调BLOOM模型的实验表明，与1b7变体相比，560m变体的表现相似或更好。（2）零-shot交叉语言和多语言微调实验表明，BLOOM与单语言的GPT-2模型相当或更差，（3）使用RealToxicityPrompts数据集进行基于提示的文本生成毒性分析显示，BLOOM生成的文本至少比GPT-2和GPT-3模型毒性低17％。",
    "tldr": "本文对比了BLOOM和其他语言模型在性能、跨语言和多语言微调以及基于提示文本生成中的毒性分析方面的表现，发现BLOOM与其他LLM的性能不成正比，但在生成毒性低的文本方面表现更好。",
    "en_tdlr": "This paper compares the performance, cross-lingual and multi-lingual fine-tuning, and toxicity analysis of the BLOOM model to other large language models (LLMs), finding that BLOOM's performance does not scale with parameter size and is less toxic in prompt-based text generation. However, it performs similarly or worse than monolingual GPT-2 models in zero-shot cross-lingual and multi-lingual fine-tuning."
}