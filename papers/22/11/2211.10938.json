{
    "title": "AI-KD: Adversarial learning and Implicit regularization for self-Knowledge Distillation",
    "abstract": "arXiv:2211.10938v2 Announce Type: replace-cross  Abstract: We present a novel adversarial penalized self-knowledge distillation method, named adversarial learning and implicit regularization for self-knowledge distillation (AI-KD), which regularizes the training procedure by adversarial learning and implicit distillations. Our model not only distills the deterministic and progressive knowledge which are from the pre-trained and previous epoch predictive probabilities but also transfers the knowledge of the deterministic predictive distributions using adversarial learning. The motivation is that the self-knowledge distillation methods regularize the predictive probabilities with soft targets, but the exact distributions may be hard to predict. Our method deploys a discriminator to distinguish the distributions between the pre-trained and student models while the student model is trained to fool the discriminator in the trained procedure. Thus, the student model not only can learn the pr",
    "link": "https://arxiv.org/abs/2211.10938",
    "context": "Title: AI-KD: Adversarial learning and Implicit regularization for self-Knowledge Distillation\nAbstract: arXiv:2211.10938v2 Announce Type: replace-cross  Abstract: We present a novel adversarial penalized self-knowledge distillation method, named adversarial learning and implicit regularization for self-knowledge distillation (AI-KD), which regularizes the training procedure by adversarial learning and implicit distillations. Our model not only distills the deterministic and progressive knowledge which are from the pre-trained and previous epoch predictive probabilities but also transfers the knowledge of the deterministic predictive distributions using adversarial learning. The motivation is that the self-knowledge distillation methods regularize the predictive probabilities with soft targets, but the exact distributions may be hard to predict. Our method deploys a discriminator to distinguish the distributions between the pre-trained and student models while the student model is trained to fool the discriminator in the trained procedure. Thus, the student model not only can learn the pr",
    "path": "papers/22/11/2211.10938.json",
    "total_tokens": 945,
    "translated_title": "AI-KD: 对抗学习和隐式正则化用于自知识蒸馏的方法",
    "translated_abstract": "我们提出了一种新颖的对抗惩罚自知识蒸馏方法，名为对抗学习和隐式正则化自知识蒸馏（AI-KD），通过对抗学习和隐式蒸馏来规范训练过程。我们的模型不仅可以从预训练和先前时期的预测概率中蒸馏确定性和渐进式知识，还可以使用对抗学习传输确定性预测分布的知识。方法的动机在于自知识蒸馏方法通过软目标规范预测概率，但确切的分布可能难以预测。我们的方法部署了一个鉴别器来区分预训练模型和学生模型之间的分布，而学生模型在训练过程中被训练来愚弄鉴别器。因此，学生模型不仅可以学习到确定性预测分布，还可以从对抗学习中受益。",
    "tldr": "提出了一种名为AI-KD的对抗学习和隐式正则化自知识蒸馏的方法，通过对抗学习和隐式蒸馏规范训练过程，使得学生模型可以从预训练和先前时期的预测概率中蒸馏确定性和渐进式知识，同时通过对抗学习传输确定性预测分布的知识。",
    "en_tdlr": "Proposed a method named AI-KD for self-knowledge distillation that combines adversarial learning and implicit regularization to regulate the training process, allowing the student model to distill deterministic and progressive knowledge from pre-trained and previous epoch predictive probabilities, as well as transfer knowledge of deterministic predictive distributions through adversarial learning."
}