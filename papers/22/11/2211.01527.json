{
    "title": "Sensor Control for Information Gain in Dynamic, Sparse and Partially Observed Environments. (arXiv:2211.01527v2 [cs.AI] UPDATED)",
    "abstract": "We present an approach for autonomous sensor control for information gathering under partially observable, dynamic and sparsely sampled environments that maximizes information about entities present in that space. We describe our approach for the task of Radio-Frequency (RF) spectrum monitoring, where the goal is to search for and track unknown, dynamic signals in the environment. To this end, we extend the Deep Anticipatory Network (DAN) Reinforcement Learning (RL) framework by (1) improving exploration in sparse, non-stationary environments using a novel information gain reward, and (2) scaling up the control space and enabling the monitoring of complex, dynamic activity patterns using hybrid convolutional-recurrent neural layers. We also extend this problem to situations in which sampling from the intended RF spectrum/field is limited and propose a model-based version of the original RL algorithm that fine-tunes the controller via a model that is iteratively improved from the limite",
    "link": "http://arxiv.org/abs/2211.01527",
    "context": "Title: Sensor Control for Information Gain in Dynamic, Sparse and Partially Observed Environments. (arXiv:2211.01527v2 [cs.AI] UPDATED)\nAbstract: We present an approach for autonomous sensor control for information gathering under partially observable, dynamic and sparsely sampled environments that maximizes information about entities present in that space. We describe our approach for the task of Radio-Frequency (RF) spectrum monitoring, where the goal is to search for and track unknown, dynamic signals in the environment. To this end, we extend the Deep Anticipatory Network (DAN) Reinforcement Learning (RL) framework by (1) improving exploration in sparse, non-stationary environments using a novel information gain reward, and (2) scaling up the control space and enabling the monitoring of complex, dynamic activity patterns using hybrid convolutional-recurrent neural layers. We also extend this problem to situations in which sampling from the intended RF spectrum/field is limited and propose a model-based version of the original RL algorithm that fine-tunes the controller via a model that is iteratively improved from the limite",
    "path": "papers/22/11/2211.01527.json",
    "total_tokens": 962,
    "translated_title": "动态、稀疏和部分观测环境下的信息收集的传感器控制方法",
    "translated_abstract": "我们提出了一种自主传感器控制方法，用于在部分可观测、动态和稀疏采样的环境下最大化有关该空间中存在的实体的信息收集。我们描述了我们针对无线电频谱监测任务的方法，其中目标是搜索和跟踪环境中的未知动态信号。为此，我们通过（1）改进探索稀疏、非平稳环境的新型信息收益奖励和（2）扩展控制空间并使用混合卷积-递归神经层来监测复杂动态活动模式来扩展了深度先行网络(DAN)强化学习（RL）框架。我们还将这个问题扩展到采样预期的无线电频谱/场有限的情况，并提出了原始RL算法的基于模型的版本，通过从限制中不断提高的模型来微调控制器。",
    "tldr": "本文提出了一种自主传感器控制方法，用于在动态、稀疏和部分可观测的环境中最大化收集有关实体信息。采用深度先行网络强化学习框架，扩展控制空间并使用混合卷积递归神经层来监测复杂的动态活动模式。",
    "en_tdlr": "This paper proposes an autonomous sensor control method for maximizing information gathering about entities present in dynamic, sparse, and partially observable environments, using the Deep Anticipatory Network reinforcement learning framework and hybrid convolutional-recurrent neural layers to enable monitoring of complex, dynamic activity patterns, including situations with limited sampling. A novel information gain reward is also introduced to improve exploration in sparse, non-stationary environments."
}