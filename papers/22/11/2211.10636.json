{
    "title": "Efficient Video Representation Learning via Motion-Aware Token Selection. (arXiv:2211.10636v2 [cs.CV] UPDATED)",
    "abstract": "Recently emerged Masked Video Modeling techniques demonstrated their potential by significantly outperforming previous methods in self-supervised learning for video. However, they require an excessive amount of computations and memory while predicting uninformative tokens/frames due to random masking strategies, requiring excessive computing power for training. (e.g., over 16 nodes with 128 NVIDIA A100 GPUs). To resolve this issue, we exploit the unequal information density among the patches in videos and propose a new token selection method, MATS: Motion-Aware Token Selection, that finds tokens containing rich motion features and drops uninformative ones during both self-supervised pre-training and fine-tuning. We further present an adaptive frame selection strategy that allows the model to focus on informative and causal frames with minimal redundancy. Our method significantly reduces computation and memory requirements, enabling the pre-training and fine-tuning on a single machine w",
    "link": "http://arxiv.org/abs/2211.10636",
    "context": "Title: Efficient Video Representation Learning via Motion-Aware Token Selection. (arXiv:2211.10636v2 [cs.CV] UPDATED)\nAbstract: Recently emerged Masked Video Modeling techniques demonstrated their potential by significantly outperforming previous methods in self-supervised learning for video. However, they require an excessive amount of computations and memory while predicting uninformative tokens/frames due to random masking strategies, requiring excessive computing power for training. (e.g., over 16 nodes with 128 NVIDIA A100 GPUs). To resolve this issue, we exploit the unequal information density among the patches in videos and propose a new token selection method, MATS: Motion-Aware Token Selection, that finds tokens containing rich motion features and drops uninformative ones during both self-supervised pre-training and fine-tuning. We further present an adaptive frame selection strategy that allows the model to focus on informative and causal frames with minimal redundancy. Our method significantly reduces computation and memory requirements, enabling the pre-training and fine-tuning on a single machine w",
    "path": "papers/22/11/2211.10636.json",
    "total_tokens": 893,
    "translated_title": "运动感知标记选择实现高效视频表征学习",
    "translated_abstract": "最近出现的蒙版视频建模技术通过在视频的自我监督学习中获得了显着的优势。然而，由于随机蒙版策略导致预测无效的标记/帧，这些技术需要大量的计算和存储，需要昂贵的计算机和大量显卡进行训练。我们利用视频补丁中的不均匀信息密度，并提出一种新的标记选择方法：MATS：运动感知标记选择，在自监督预训练和微调过程中找到包含丰富动态特性的标记，并放弃无效的标记，我们还提出了自适应帧选择策略，使模型能够关注最重要和因果性的帧，并使计算和存储需求得到显着降低，使得在单台机器上进行预训练和微调而不影响性能。",
    "tldr": "该论文提出了一种新的运动感知标记选择方法，针对视频中不同补丁的信息密度，选择包含丰富动态特性的标记，放弃无效的标记，从而大大降低计算和存储需求，实现了在单台机器上进行预训练和微调而不影响性能。",
    "en_tdlr": "The paper proposes a new motion-aware token selection method, MATS, for video self-supervised learning. By exploiting the unequal information density among video patches, the method significantly reduces computation and memory requirements, enabling pre-training and fine-tuning on a single machine without sacrificing performance."
}