{
    "title": "Using explainability to design physics-aware CNNs for solving subsurface inverse problems. (arXiv:2211.08651v2 [cs.LG] UPDATED)",
    "abstract": "We present a novel method of using explainability techniques to design physics-aware neural networks. We demonstrate our approach by developing a convolutional neural network (CNN) for solving an inverse problem for shallow subsurface imaging. Although CNNs have gained popularity in recent years across many fields, the development of CNNs remains an art, as there are no clear guidelines regarding the selection of hyperparameters that will yield the best network. While optimization algorithms may be used to select hyperparameters automatically, these methods focus on developing networks with high predictive accuracy while disregarding model explainability (descriptive accuracy). However, the field of Explainable Artificial Intelligence (XAI) addresses the absence of model explainability by providing tools that allow developers to evaluate the internal logic of neural networks. In this study, we use the explainability methods Score-CAM and Deep SHAP to select hyperparameters, such as ker",
    "link": "http://arxiv.org/abs/2211.08651",
    "context": "Title: Using explainability to design physics-aware CNNs for solving subsurface inverse problems. (arXiv:2211.08651v2 [cs.LG] UPDATED)\nAbstract: We present a novel method of using explainability techniques to design physics-aware neural networks. We demonstrate our approach by developing a convolutional neural network (CNN) for solving an inverse problem for shallow subsurface imaging. Although CNNs have gained popularity in recent years across many fields, the development of CNNs remains an art, as there are no clear guidelines regarding the selection of hyperparameters that will yield the best network. While optimization algorithms may be used to select hyperparameters automatically, these methods focus on developing networks with high predictive accuracy while disregarding model explainability (descriptive accuracy). However, the field of Explainable Artificial Intelligence (XAI) addresses the absence of model explainability by providing tools that allow developers to evaluate the internal logic of neural networks. In this study, we use the explainability methods Score-CAM and Deep SHAP to select hyperparameters, such as ker",
    "path": "papers/22/11/2211.08651.json",
    "total_tokens": 905,
    "translated_title": "应用可解释性设计物理感知卷积神经网络求解地下反问题",
    "translated_abstract": "本文提出了一种使用可解释性技术设计物理感知神经网络的新方法，并通过开发卷积神经网络 (CNN) 求解浅层地下成像反问题来展示我们的方法。虽然CNN在许多领域中近年来变得流行，但是它们的开发仍然是一种艺术，因为关于选择会产生最佳网络的超参数的明确指导并不存在。虽然可以使用优化算法自动选择超参数，但是这些方法着重于开发具有高预测准确性的网络，而忽略了模型解释性（描述准确性）。然而，可解释人工智能 (XAI) 领域通过提供允许开发者评估神经网络内部逻辑的工具来解决模型解释性的缺失。在本研究中，我们使用可解释性方法 Score-CAM 和 Deep SHAP 来选择超参数，例如 kern...",
    "tldr": "本研究提出了一种使用可解释性技术设计物理感知神经网络的新方法，通过开发卷积神经网络求解地下反问题展示应用价值。研究使用Score-CAM和Deep SHAP等方法选择超参数以提高解释性和预测准确性。",
    "en_tdlr": "This study proposes a novel method of using explainability techniques to design physics-aware neural networks, and demonstrates its application through developing a convolutional neural network for solving subsurface inverse problems. By using explainability methods such as Score-CAM and Deep SHAP to select hyperparameters, the study improves both the interpretability and predictive accuracy of the network."
}