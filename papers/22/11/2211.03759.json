{
    "title": "Easily Accessible Text-to-Image Generation Amplifies Demographic Stereotypes at Large Scale. (arXiv:2211.03759v2 [cs.CL] UPDATED)",
    "abstract": "Machine learning models that convert user-written text descriptions into images are now widely available online and used by millions of users to generate millions of images a day. We investigate the potential for these models to amplify dangerous and complex stereotypes. We find a broad range of ordinary prompts produce stereotypes, including prompts simply mentioning traits, descriptors, occupations, or objects. For example, we find cases of prompting for basic traits or social roles resulting in images reinforcing whiteness as ideal, prompting for occupations resulting in amplification of racial and gender disparities, and prompting for objects resulting in reification of American norms. Stereotypes are present regardless of whether prompts explicitly mention identity and demographic language or avoid such language. Moreover, stereotypes persist despite mitigation strategies; neither user attempts to counter stereotypes by requesting images with specific counter-stereotypes nor insti",
    "link": "http://arxiv.org/abs/2211.03759",
    "context": "Title: Easily Accessible Text-to-Image Generation Amplifies Demographic Stereotypes at Large Scale. (arXiv:2211.03759v2 [cs.CL] UPDATED)\nAbstract: Machine learning models that convert user-written text descriptions into images are now widely available online and used by millions of users to generate millions of images a day. We investigate the potential for these models to amplify dangerous and complex stereotypes. We find a broad range of ordinary prompts produce stereotypes, including prompts simply mentioning traits, descriptors, occupations, or objects. For example, we find cases of prompting for basic traits or social roles resulting in images reinforcing whiteness as ideal, prompting for occupations resulting in amplification of racial and gender disparities, and prompting for objects resulting in reification of American norms. Stereotypes are present regardless of whether prompts explicitly mention identity and demographic language or avoid such language. Moreover, stereotypes persist despite mitigation strategies; neither user attempts to counter stereotypes by requesting images with specific counter-stereotypes nor insti",
    "path": "papers/22/11/2211.03759.json",
    "total_tokens": 990,
    "translated_title": "易于访问的文本到图像生成技术在大规模上放大了人口群体的刻板印象",
    "translated_abstract": "将用户编写的文本描述转换为图像的机器学习模型现在在网上广泛可用，并被数百万用户用于每天生成数百万张图像。我们调查了这些模型放大危险和复杂刻板印象的潜力。我们发现广泛的普通提示会产生刻板印象，包括仅提到特征、描述符、职业或对象的提示。例如，我们发现提示基本特征或社会角色的情况下，结果生成了强调白人作为理想的形象，提示职业的情况下导致种族和性别差异的放大，提示对象的情况下导致美国规范的再现。刻板印象存在，无论提示是否明确提到身份和人口统计语言或避免此类语言。此外，尽管采取了缓解策略，刻板印象仍然存在；用户试图通过请求具有特定反刻板印象的图像来打破刻板印象，或者机构试图过滤提示在固有效应上都不能成功。我们的研究揭示了技术在规模上可以放大有害的刻板印象，并强调了小心谨慎地处理文本到图像生成的重要性。",
    "tldr": "文本到图像生成技术在大规模上放大了人口群体的刻板印象，即使提示不明确提到身份和人口统计语言或采取缓解策略也无法消除这种印象。"
}