{
    "title": "Expressibility-Enhancing Strategies for Quantum Neural Networks. (arXiv:2211.12670v2 [quant-ph] UPDATED)",
    "abstract": "Quantum neural networks (QNNs), represented by parameterized quantum circuits, can be trained in the paradigm of supervised learning to map input data to predictions. Much work has focused on theoretically analyzing the expressive power of QNNs. However, in almost all literature, QNNs' expressive power is numerically validated using only simple univariate functions. We surprisingly discover that state-of-the-art QNNs with strong expressive power can have poor performance in approximating even just a simple sinusoidal function. To fill the gap, we propose four expressibility-enhancing strategies for QNNs: Sinusoidal-friendly embedding, redundant measurement, post-measurement function, and random training data. We analyze the effectiveness of these strategies via mathematical analysis and/or numerical studies including learning complex sinusoidal-based functions. Our results from comparative experiments validate that the four strategies can significantly increase the QNNs' performance in",
    "link": "http://arxiv.org/abs/2211.12670",
    "context": "Title: Expressibility-Enhancing Strategies for Quantum Neural Networks. (arXiv:2211.12670v2 [quant-ph] UPDATED)\nAbstract: Quantum neural networks (QNNs), represented by parameterized quantum circuits, can be trained in the paradigm of supervised learning to map input data to predictions. Much work has focused on theoretically analyzing the expressive power of QNNs. However, in almost all literature, QNNs' expressive power is numerically validated using only simple univariate functions. We surprisingly discover that state-of-the-art QNNs with strong expressive power can have poor performance in approximating even just a simple sinusoidal function. To fill the gap, we propose four expressibility-enhancing strategies for QNNs: Sinusoidal-friendly embedding, redundant measurement, post-measurement function, and random training data. We analyze the effectiveness of these strategies via mathematical analysis and/or numerical studies including learning complex sinusoidal-based functions. Our results from comparative experiments validate that the four strategies can significantly increase the QNNs' performance in",
    "path": "papers/22/11/2211.12670.json",
    "total_tokens": 873,
    "translated_title": "量子神经网络的表达能力增强策略",
    "translated_abstract": "量子神经网络通过参数化量子电路来表示，可以在监督学习范式中训练模型将输入数据映射到预测结果。先前大多数工作都集中于理论分析QNN的表达能力。然而，几乎所有文献中，QNN的表达能力仅基于简单的单变量函数进行数值验证。我们惊奇地发现，具有强表达能力的最先进QNN即使在近似简单的正弦函数上，也可能表现不佳。为此，我们提出了四个增强QNN表达能力的策略：适用于正弦函数的嵌入、冗余测量、后测量函数和随机训练数据。我们通过数学分析和/或数值研究，包括学习复杂的基于正弦函数的函数，分析了这些策略的有效性。我们的比较实验结果验证了这四个策略可以显著提高QNN在近似简单单变量函数之外的复杂函数的表现。",
    "tldr": "本文提出四项增强量子神经网络表达能力的策略，并验证其可以显著提高QNN在近似复杂函数方面的性能表现。",
    "en_tdlr": "This paper proposes four strategies to enhance the expressibility of quantum neural networks and validates their effectiveness in improving the performance of QNNs in approximating complex functions beyond simple univariate ones."
}