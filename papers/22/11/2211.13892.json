{
    "title": "Complementary Explanations for Effective In-Context Learning. (arXiv:2211.13892v2 [cs.CL] UPDATED)",
    "abstract": "Large language models (LLMs) have exhibited remarkable capabilities in learning from explanations in prompts, but there has been limited understanding of exactly how these explanations function or why they are effective. This work aims to better understand the mechanisms by which explanations are used for in-context learning. We first study the impact of two different factors on the performance of prompts with explanations: the computation trace (the way the solution is decomposed) and the natural language used to express the prompt. By perturbing explanations on three controlled tasks, we show that both factors contribute to the effectiveness of explanations. We further study how to form maximally effective sets of explanations for solving a given test query. We find that LLMs can benefit from the complementarity of the explanation set: diverse reasoning skills shown by different exemplars can lead to better performance. Therefore, we propose a maximal marginal relevance-based exempla",
    "link": "http://arxiv.org/abs/2211.13892",
    "context": "Title: Complementary Explanations for Effective In-Context Learning. (arXiv:2211.13892v2 [cs.CL] UPDATED)\nAbstract: Large language models (LLMs) have exhibited remarkable capabilities in learning from explanations in prompts, but there has been limited understanding of exactly how these explanations function or why they are effective. This work aims to better understand the mechanisms by which explanations are used for in-context learning. We first study the impact of two different factors on the performance of prompts with explanations: the computation trace (the way the solution is decomposed) and the natural language used to express the prompt. By perturbing explanations on three controlled tasks, we show that both factors contribute to the effectiveness of explanations. We further study how to form maximally effective sets of explanations for solving a given test query. We find that LLMs can benefit from the complementarity of the explanation set: diverse reasoning skills shown by different exemplars can lead to better performance. Therefore, we propose a maximal marginal relevance-based exempla",
    "path": "papers/22/11/2211.13892.json",
    "total_tokens": 889,
    "translated_title": "有效的上下文学习的互补解释",
    "translated_abstract": "大规模的语言模型(LLMs)在从提示中学习解释方面展现出了显著的能力，但对这些解释的功能或为何有效的理解还有限。本文旨在更好地理解解释在上下文学习中的作用机制。我们首先研究了两个不同因素对具有解释提示性能的影响:计算跟踪(解决方案的分解方式)和用于表达提示的自然语言。通过在三个受控任务上扰动解释，我们表明两个因素都有助于解释的有效性。我们进一步研究了如何形成最大有效解释集以解决给定的测试查询。我们发现，LLMs可以从解释集的互补性中受益:不同示例展示的多样推理技能可以提高性能。因此，我们提出了一种基于最大边际相关性的实例集合方法，",
    "tldr": "本文研究了解释对于在上下文学习中的作用机制，证明了解释的分解和自然语言表达对于解释的有效性都有贡献；并且指出，不同的解释集可以提高LLMs的性能，因此提出了一种基于最大边际相关性的实例集合方法。",
    "en_tdlr": "This paper investigates mechanisms by which explanations are used for in-context learning, demonstrates that both the computation trace and natural language used to express prompts contribute to the effectiveness of explanations, suggests that diverse sets of explanations can lead to better performance, and proposes a maximal marginal relevance-based exemplar selection method."
}