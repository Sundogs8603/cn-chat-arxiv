{
    "title": "Visual Dexterity: In-hand Dexterous Manipulation from Depth. (arXiv:2211.11744v2 [cs.RO] UPDATED)",
    "abstract": "In-hand object reorientation is necessary for performing many dexterous manipulation tasks, such as tool use in less structured environments that remain beyond the reach of current robots. Prior works built reorientation systems assuming one or many of the following: reorienting only specific objects with simple shapes, limited range of reorientation, slow or quasistatic manipulation, simulation-only results, the need for specialized and costly sensor suites, and other constraints which make the system infeasible for real-world deployment. We present a general object reorientation controller that does not make these assumptions. It uses readings from a single commodity depth camera to dynamically reorient complex and new object shapes by any rotation in real-time, with the median reorientation time being close to seven seconds. The controller is trained using reinforcement learning in simulation and evaluated in the real world on new object shapes not used for training, including the m",
    "link": "http://arxiv.org/abs/2211.11744",
    "context": "Title: Visual Dexterity: In-hand Dexterous Manipulation from Depth. (arXiv:2211.11744v2 [cs.RO] UPDATED)\nAbstract: In-hand object reorientation is necessary for performing many dexterous manipulation tasks, such as tool use in less structured environments that remain beyond the reach of current robots. Prior works built reorientation systems assuming one or many of the following: reorienting only specific objects with simple shapes, limited range of reorientation, slow or quasistatic manipulation, simulation-only results, the need for specialized and costly sensor suites, and other constraints which make the system infeasible for real-world deployment. We present a general object reorientation controller that does not make these assumptions. It uses readings from a single commodity depth camera to dynamically reorient complex and new object shapes by any rotation in real-time, with the median reorientation time being close to seven seconds. The controller is trained using reinforcement learning in simulation and evaluated in the real world on new object shapes not used for training, including the m",
    "path": "papers/22/11/2211.11744.json",
    "total_tokens": 898,
    "translated_title": "通过深度感知实现手持灵巧操作",
    "translated_abstract": "手持物体的重新定向对于执行许多灵巧操作任务非常必要，例如在当前机器人无法触及的结构不太完善的环境中使用工具。之前的研究建立了重新定向系统，假设以下情况之一或多种情况同时存在：仅重新定向具有简单形状的特定物体、重新定向范围有限、慢速或准静态操作、仅模拟结果、需要专用且昂贵的传感器套件以及其他不适用于实际部署的限制。我们提出了一种不做这些假设的通用物体重新定向控制器。它使用来自单个普通深度摄像机的读数，以实时方式通过任意旋转动态重新定向复杂且新颖的物体形状，中位数重新定向时间接近于七秒。该控制器经过强化学习在仿真环境中进行训练，并在未用于训练的新物体形状上在实际世界中进行评估，包括 ...",
    "tldr": "通过使用深度相机的读数，我们提出了一种通用物体重新定向控制器，可以实时、动态地重新定向复杂和新颖的物体形状，中位数重新定向时间接近于七秒。该控制器经过强化学习在仿真环境中训练，并在实际世界中对未用于训练的新物体形状进行了评估。"
}