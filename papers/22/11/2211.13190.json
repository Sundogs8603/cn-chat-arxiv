{
    "title": "BiasBed -- Rigorous Texture Bias Evaluation. (arXiv:2211.13190v3 [cs.CV] UPDATED)",
    "abstract": "The well-documented presence of texture bias in modern convolutional neural networks has led to a plethora of algorithms that promote an emphasis on shape cues, often to support generalization to new domains. Yet, common datasets, benchmarks and general model selection strategies are missing, and there is no agreed, rigorous evaluation protocol. In this paper, we investigate difficulties and limitations when training networks with reduced texture bias. In particular, we also show that proper evaluation and meaningful comparisons between methods are not trivial. We introduce BiasBed, a testbed for textureand style-biased training, including multiple datasets and a range of existing algorithms. It comes with an extensive evaluation protocol that includes rigorous hypothesis testing to gauge the significance of the results, despite the considerable training instability of some style bias methods. Our extensive experiments, shed new light on the need for careful, statistically founded ev",
    "link": "http://arxiv.org/abs/2211.13190",
    "context": "Title: BiasBed -- Rigorous Texture Bias Evaluation. (arXiv:2211.13190v3 [cs.CV] UPDATED)\nAbstract: The well-documented presence of texture bias in modern convolutional neural networks has led to a plethora of algorithms that promote an emphasis on shape cues, often to support generalization to new domains. Yet, common datasets, benchmarks and general model selection strategies are missing, and there is no agreed, rigorous evaluation protocol. In this paper, we investigate difficulties and limitations when training networks with reduced texture bias. In particular, we also show that proper evaluation and meaningful comparisons between methods are not trivial. We introduce BiasBed, a testbed for textureand style-biased training, including multiple datasets and a range of existing algorithms. It comes with an extensive evaluation protocol that includes rigorous hypothesis testing to gauge the significance of the results, despite the considerable training instability of some style bias methods. Our extensive experiments, shed new light on the need for careful, statistically founded ev",
    "path": "papers/22/11/2211.13190.json",
    "total_tokens": 945,
    "translated_title": "BiasBed -- 严格的纹理偏差评估",
    "translated_abstract": "现代卷积神经网络存在纹理偏差的问题已有充分文献证明，这导致出现了大量算法，强调形状线索，以支持到新领域的概括。然而，普通数据集、基准和一般的模型选择策略都缺失，且没有共识的、严格的评估协议。在本文中，我们研究了使用降低了纹理偏差的网络进行训练时的困难和限制。特别地，我们还展示了适当的评估和方法之间有意义的比较并不是一件容易的事情。我们引入了 BiasBed，一个用于测试纹理和风格偏差训练的测试平台，包括多个数据集和一系列现有算法。它配备了广泛的评估协议，包括严格的假设检验，以衡量结果的显著性，尽管一些风格偏差方法的训练不稳定。我们的大量实验证明了需要仔细、基于统计的对纹理偏差降低方法进行评估，并展示了严格的评估协议的价值。",
    "tldr": "本文介绍了 BiasBed，一个测试平台，用于严格评估降低纹理偏差的方法，包括多个数据集和现有算法，并配备了广泛的评估协议以揭示其显著性。",
    "en_tdlr": "This paper introduces BiasBed, a testing platform to rigorously evaluate texture bias reduction methods, including multiple datasets and existing algorithms, and comes with an extensive evaluation protocol to reveal the significance of results."
}