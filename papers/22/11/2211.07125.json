{
    "title": "Global Performance Guarantees for Neural Network Models of AC Power Flow. (arXiv:2211.07125v2 [eess.SY] UPDATED)",
    "abstract": "Machine learning can generate black-box surrogate models which are both extremely fast and highly accurate. Rigorously verifying the accuracy of these black-box models, however, is computationally challenging. When it comes to power systems, learning AC power flow is the cornerstone of any machine learning surrogate model wishing to drastically accelerate computations, whether it is for optimization, control, or dynamics. This paper develops for the first time, to our knowledge, a tractable neural network verification procedure which incorporates the ground truth of the non-linear AC power flow equations to determine worst-case neural network performance. Our approach, termed Sequential Targeted Tightening (STT), leverages a loosely convexified reformulation of the original verification problem, which is a mixed integer quadratic program (MIQP). Using the sequential addition of targeted cuts, we iteratively tighten our formulation until either the solution is sufficiently tight or a sa",
    "link": "http://arxiv.org/abs/2211.07125",
    "context": "Title: Global Performance Guarantees for Neural Network Models of AC Power Flow. (arXiv:2211.07125v2 [eess.SY] UPDATED)\nAbstract: Machine learning can generate black-box surrogate models which are both extremely fast and highly accurate. Rigorously verifying the accuracy of these black-box models, however, is computationally challenging. When it comes to power systems, learning AC power flow is the cornerstone of any machine learning surrogate model wishing to drastically accelerate computations, whether it is for optimization, control, or dynamics. This paper develops for the first time, to our knowledge, a tractable neural network verification procedure which incorporates the ground truth of the non-linear AC power flow equations to determine worst-case neural network performance. Our approach, termed Sequential Targeted Tightening (STT), leverages a loosely convexified reformulation of the original verification problem, which is a mixed integer quadratic program (MIQP). Using the sequential addition of targeted cuts, we iteratively tighten our formulation until either the solution is sufficiently tight or a sa",
    "path": "papers/22/11/2211.07125.json",
    "total_tokens": 902,
    "translated_title": "AC电力流的神经网络建模的全局性能保证",
    "translated_abstract": "机器学习可以生成既快又准的黑盒子模型。但严格验证黑盒模型的准确性是计算上具有挑战性的。对于电力系统来说，学习AC电力流是任何希望显著加速计算的机器学习黑盒模型的基石，无论是为了优化、控制还是动力学。本文首次开发一种可行的神经网络验证程序，它结合了非线性AC电力流方程的ground truth，以确定最坏的神经网络性能。我们的方法称为Sequential Targeted Tightening (STT)，它利用松弛的凸规划重构了原始的验证问题，该问题是一个混合整数二次规划（MIQP）。通过顺序添加有针对性的切割，我们迭代地收紧我们的公式，直到解决方案足够紧密或达到一个安全性阈值。",
    "tldr": "本文首次开发了一种可行的神经网络验证程序，它结合了非线性AC电力流方程的ground truth，以确定最坏的神经网络性能。使用顺序添加有针对性的切割，我们迭代地收紧我们的公式，直到解决方案足够紧密或达到一个安全性阈值。",
    "en_tdlr": "This paper develops a tractable neural network verification procedure for AC power flow modeling, which incorporates the ground truth of non-linear equations to determine worst-case neural network performance. Their approach, Sequential Targeted Tightening, iteratively tightens their formulation until either the solution is sufficiently tight or a safety threshold is reached."
}