{
    "title": "Recurrent Neural Networks and Universal Approximation of Bayesian Filters. (arXiv:2211.00335v2 [stat.ML] UPDATED)",
    "abstract": "We consider the Bayesian optimal filtering problem: i.e. estimating some conditional statistics of a latent time-series signal from an observation sequence. Classical approaches often rely on the use of assumed or estimated transition and observation models. Instead, we formulate a generic recurrent neural network framework and seek to learn directly a recursive mapping from observational inputs to the desired estimator statistics. The main focus of this article is the approximation capabilities of this framework. We provide approximation error bounds for filtering in general non-compact domains. We also consider strong time-uniform approximation error bounds that guarantee good long-time performance. We discuss and illustrate a number of practical concerns and implications of these results.",
    "link": "http://arxiv.org/abs/2211.00335",
    "context": "Title: Recurrent Neural Networks and Universal Approximation of Bayesian Filters. (arXiv:2211.00335v2 [stat.ML] UPDATED)\nAbstract: We consider the Bayesian optimal filtering problem: i.e. estimating some conditional statistics of a latent time-series signal from an observation sequence. Classical approaches often rely on the use of assumed or estimated transition and observation models. Instead, we formulate a generic recurrent neural network framework and seek to learn directly a recursive mapping from observational inputs to the desired estimator statistics. The main focus of this article is the approximation capabilities of this framework. We provide approximation error bounds for filtering in general non-compact domains. We also consider strong time-uniform approximation error bounds that guarantee good long-time performance. We discuss and illustrate a number of practical concerns and implications of these results.",
    "path": "papers/22/11/2211.00335.json",
    "total_tokens": 817,
    "translated_title": "循环神经网络和贝叶斯滤波器的通用逼近性",
    "translated_abstract": "本文考虑贝叶斯最优滤波问题，即从观测序列中估计潜在时间序列信号的条件统计量。传统方法通常依赖于假定或估计的转移和观测模型。相反，我们制定了一个通用的循环神经网络框架，并试图直接从观测输入到所需的估计器统计量学习递归映射。本文的重点是此框架的逼近能力。我们提供了一般非紧致域的滤波逼近误差界限。我们还考虑了强时间一致的逼近误差界限，保证良好的长期性能。我们讨论和说明了这些结果的许多实际关注点和影响。",
    "tldr": "本文提出一个循环神经网络框架，用于直接从观测输入到所需的估计器统计量学习递归映射，可以近似估计潜在时间序列信号的条件统计量，在非紧致域中有误差界限，在长时间上有良好性能。",
    "en_tdlr": "This paper proposes a recurrent neural network framework for directly learning a recursive mapping from observational inputs to the desired estimator statistics and provides approximation error bounds for filtering in general non-compact domains and strong time-uniform approximation error bounds that guarantee good long-time performance for estimating conditional statistics of a latent time-series signal from an observation sequence."
}