{
    "title": "KRLS: Improving End-to-End Response Generation in Task Oriented Dialog with Reinforced Keywords Learning. (arXiv:2211.16773v4 [cs.CL] UPDATED)",
    "abstract": "In task-oriented dialogs, an informative and successful system response needs to include key information such as the phone number of a hotel. Therefore, we hypothesize that a model can achieve better overall performance by focusing on correctly generating key quantities. In this paper, we propose a new training algorithm, Keywords Reinforcement Learning with Next-word Sampling (KRLS), that utilizes Reinforcement Learning but avoids the time-consuming auto-regressive generation, and a fine-grained per-token reward function to help the model learn keywords generation more robustly. Empirical results show that the KRLS algorithm can achieve state-of-the-art performance on the inform, success, and combined score on the MultiWoZ benchmark dataset.",
    "link": "http://arxiv.org/abs/2211.16773",
    "context": "Title: KRLS: Improving End-to-End Response Generation in Task Oriented Dialog with Reinforced Keywords Learning. (arXiv:2211.16773v4 [cs.CL] UPDATED)\nAbstract: In task-oriented dialogs, an informative and successful system response needs to include key information such as the phone number of a hotel. Therefore, we hypothesize that a model can achieve better overall performance by focusing on correctly generating key quantities. In this paper, we propose a new training algorithm, Keywords Reinforcement Learning with Next-word Sampling (KRLS), that utilizes Reinforcement Learning but avoids the time-consuming auto-regressive generation, and a fine-grained per-token reward function to help the model learn keywords generation more robustly. Empirical results show that the KRLS algorithm can achieve state-of-the-art performance on the inform, success, and combined score on the MultiWoZ benchmark dataset.",
    "path": "papers/22/11/2211.16773.json",
    "total_tokens": 822,
    "translated_title": "基于关键词强化学习的任务导向对话中端到端响应生成的改进",
    "translated_abstract": "在任务导向的对话中，一个信息丰富且成功的系统响应需要包含关键信息，例如酒店的电话号码。因此，我们假设通过正确生成关键数量，模型可以实现更好的整体性能。在本文中，我们提出了一种新的训练算法，即关键词强化学习与下一个单词采样（KRLS），利用强化学习，但避免了耗时的自回归生成，并采用了细粒度的逐令牌奖励函数来帮助模型更加强健地学习关键词生成。实证结果表明，KRLS算法可以在MultiWoZ基准数据集上实现良好的信息、成功和综合分数的最先进表现。",
    "tldr": "本文提出了一种新的训练算法，KRLS，该算法通过关键词强化学习和精细的奖励函数来帮助模型在任务导向对话中生成关键词，实验结果显示，该算法在MultiWoZ基准数据集上取得了最先进的表现。",
    "en_tdlr": "This paper proposes a new training algorithm, KRLS, which utilizes reinforced keywords learning and fine-grained rewards to help the model generate keywords in task-oriented dialogues. The experimental results show that the KRLS algorithm achieves state-of-the-art performance on the MultiWoZ benchmark dataset."
}