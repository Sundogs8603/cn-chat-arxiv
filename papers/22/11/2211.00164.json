{
    "title": "Agent-Controller Representations: Principled Offline RL with Rich Exogenous Information. (arXiv:2211.00164v2 [cs.LG] UPDATED)",
    "abstract": "Learning to control an agent from data collected offline in a rich pixel-based visual observation space is vital for real-world applications of reinforcement learning (RL). A major challenge in this setting is the presence of input information that is hard to model and irrelevant to controlling the agent. This problem has been approached by the theoretical RL community through the lens of exogenous information, i.e, any control-irrelevant information contained in observations. For example, a robot navigating in busy streets needs to ignore irrelevant information, such as other people walking in the background, textures of objects, or birds in the sky. In this paper, we focus on the setting with visually detailed exogenous information, and introduce new offline RL benchmarks offering the ability to study this problem. We find that contemporary representation learning techniques can fail on datasets where the noise is a complex and time dependent process, which is prevalent in practical ",
    "link": "http://arxiv.org/abs/2211.00164",
    "context": "Title: Agent-Controller Representations: Principled Offline RL with Rich Exogenous Information. (arXiv:2211.00164v2 [cs.LG] UPDATED)\nAbstract: Learning to control an agent from data collected offline in a rich pixel-based visual observation space is vital for real-world applications of reinforcement learning (RL). A major challenge in this setting is the presence of input information that is hard to model and irrelevant to controlling the agent. This problem has been approached by the theoretical RL community through the lens of exogenous information, i.e, any control-irrelevant information contained in observations. For example, a robot navigating in busy streets needs to ignore irrelevant information, such as other people walking in the background, textures of objects, or birds in the sky. In this paper, we focus on the setting with visually detailed exogenous information, and introduce new offline RL benchmarks offering the ability to study this problem. We find that contemporary representation learning techniques can fail on datasets where the noise is a complex and time dependent process, which is prevalent in practical ",
    "path": "papers/22/11/2211.00164.json",
    "total_tokens": 913,
    "translated_title": "代理-控制器表示：具有丰富外部信息的原则性离线强化学习",
    "translated_abstract": "在丰富的像素视觉观测空间中，从离线数据中学习控制代理对于强化学习在实际应用中至关重要。这种设置中的一个主要挑战是输入信息中存在难以建模和控制代理相关的信息。理论强化学习领域已经通过外部信息的观点来解决这个问题，即观测中包含的与控制无关的信息。例如，一个在繁忙街道上导航的机器人需要忽略与控制无关的信息，如背景中的其他人行走、物体的纹理或天空中的鸟类。本文针对具有视觉细节的外部信息的设置，并引入了新的离线强化学习基准，以研究这个问题。我们发现当噪声是复杂且与时间相关的过程时，当代的表示学习技术可能在数据集上失败，而这种噪声在实际中普遍存在。",
    "tldr": "本文针对具有丰富外部信息的原则性离线强化学习进行研究，并提出了新的离线强化学习基准。研究发现，当噪声是复杂且与时间相关的过程时，现有的表示学习技术可能无法成功应用于这类数据集。",
    "en_tdlr": "This paper investigates principled offline reinforcement learning with rich exogenous information and introduces new benchmarks. It finds that contemporary representation learning techniques may fail on datasets with complex and time dependent noise."
}