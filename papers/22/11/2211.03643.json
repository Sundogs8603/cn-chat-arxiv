{
    "title": "Egocentric Audio-Visual Noise Suppression. (arXiv:2211.03643v2 [cs.SD] UPDATED)",
    "abstract": "This paper studies audio-visual noise suppression for egocentric videos -where the speaker is not captured in the video. Instead, potential noise sources are visible on screen with the camera emulating the off-screen speaker's view of the outside world. This setting is different from prior work in audio-visual speech enhancement that relies on lip and facial visuals. In this paper, we first demonstrate that egocentric visual information is helpful for noise suppression. We compare object recognition and action classification-based visual feature extractors and investigate methods to align audio and visual representations. Then, we examine different fusion strategies for the aligned features, and locations within the noise suppression model to incorporate visual information. Experiments demonstrate that visual features are most helpful when used to generate additive correction masks. Finally, in order to ensure that the visual features are discriminative with respect to different nois",
    "link": "http://arxiv.org/abs/2211.03643",
    "context": "Title: Egocentric Audio-Visual Noise Suppression. (arXiv:2211.03643v2 [cs.SD] UPDATED)\nAbstract: This paper studies audio-visual noise suppression for egocentric videos -where the speaker is not captured in the video. Instead, potential noise sources are visible on screen with the camera emulating the off-screen speaker's view of the outside world. This setting is different from prior work in audio-visual speech enhancement that relies on lip and facial visuals. In this paper, we first demonstrate that egocentric visual information is helpful for noise suppression. We compare object recognition and action classification-based visual feature extractors and investigate methods to align audio and visual representations. Then, we examine different fusion strategies for the aligned features, and locations within the noise suppression model to incorporate visual information. Experiments demonstrate that visual features are most helpful when used to generate additive correction masks. Finally, in order to ensure that the visual features are discriminative with respect to different nois",
    "path": "papers/22/11/2211.03643.json",
    "total_tokens": 845,
    "translated_title": "自我中心的音视频噪声抑制",
    "translated_abstract": "本文研究了自我中心视频（即未捕获到视频中的讲话者）的音视频噪声抑制。相比于以前依赖于唇部和面部视觉的音视频增强技术，本文中所使用的摄像头在画面中捕捉到的是潜在噪声源所看到的外部世界。首先，我们证明了自我中心视觉信息对于噪声抑制有帮助。我们比较了基于物体识别和动作分类的视觉特征提取器，并研究了将音频和视觉表示对齐的方法。然后，我们研究了不同的融合策略，以及在噪声抑制模型中整合视觉信息的位置。实验证明，视觉特征对于生成加性校正掩码最有帮助。最后，为了确保视觉特征在不同噪声条件下有辨识度，我们采用了噪声自适应的训练方式。",
    "tldr": "本文研究了对自我中心视频中的音频和视频进行噪声抑制的问题，并证明了自我中心视觉信息对于生成加性校正掩码最有帮助。",
    "en_tdlr": "This paper studies audio-visual noise suppression for egocentric videos and demonstrates that egocentric visual information is helpful for noise suppression."
}