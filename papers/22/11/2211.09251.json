{
    "title": "Learning-Augmented B-Trees. (arXiv:2211.09251v2 [cs.DS] UPDATED)",
    "abstract": "We study learning-augmented binary search trees (BSTs) and B-Trees via Treaps with composite priorities. The result is a simple search tree where the depth of each item is determined by its predicted weight $w_x$. To achieve the result, each item $x$ has its composite priority $-\\lfloor\\log\\log(1/w_x)\\rfloor + U(0, 1)$ where $U(0, 1)$ is the uniform random variable. This generalizes the recent learning-augmented BSTs [Lin-Luo-Woodruff ICML`22], which only work for Zipfian distributions, to arbitrary inputs and predictions. It also gives the first B-Tree data structure that can provably take advantage of localities in the access sequence via online self-reorganization. The data structure is robust to prediction errors and handles insertions, deletions, as well as prediction updates.",
    "link": "http://arxiv.org/abs/2211.09251",
    "context": "Title: Learning-Augmented B-Trees. (arXiv:2211.09251v2 [cs.DS] UPDATED)\nAbstract: We study learning-augmented binary search trees (BSTs) and B-Trees via Treaps with composite priorities. The result is a simple search tree where the depth of each item is determined by its predicted weight $w_x$. To achieve the result, each item $x$ has its composite priority $-\\lfloor\\log\\log(1/w_x)\\rfloor + U(0, 1)$ where $U(0, 1)$ is the uniform random variable. This generalizes the recent learning-augmented BSTs [Lin-Luo-Woodruff ICML`22], which only work for Zipfian distributions, to arbitrary inputs and predictions. It also gives the first B-Tree data structure that can provably take advantage of localities in the access sequence via online self-reorganization. The data structure is robust to prediction errors and handles insertions, deletions, as well as prediction updates.",
    "path": "papers/22/11/2211.09251.json",
    "total_tokens": 886,
    "translated_title": "学习增强的B树",
    "translated_abstract": "本研究通过使用具有复合优先级的Treaps来研究学习增强的二叉搜索树（BST）和B树。结果是一个简单的搜索树，其中每个项目的深度由其预测权重$w_x$确定。为了实现这个结果，每个项目$x$都有其复合优先级$-\\lfloor\\log\\log(1/w_x)\\rfloor + U(0, 1)$，其中$U(0, 1)$是均匀分布的随机变量。这将最近的学习增强BST（Lin-Luo-Woodruff ICML`22）推广到任意输入和预测，而不仅仅适用于Zipfian分布。它还提供了第一个可以根据访问序列中的局部性进行在线自我重组的B树数据结构。该数据结构对于预测错误是健壮的，可以处理插入、删除以及预测更新。",
    "tldr": "这是一个学习增强的B树，通过使用具有复合优先级的Treaps，每个项目的深度由其预测权重确定，推广了最近的学习增强BST，并且是第一个可以利用访问序列中的局部性的B树数据结构。",
    "en_tdlr": "This paper presents a learning-augmented B-tree that uses Treaps with composite priorities to determine the depth of each item based on its predicted weight. It generalizes previous work on learning-augmented BSTs and introduces the first B-tree data structure that can take advantage of localities in the access sequence. It is robust to prediction errors and supports insertions, deletions, and prediction updates."
}