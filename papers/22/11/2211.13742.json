{
    "title": "Assessing Quality-Diversity Neuro-Evolution Algorithms Performance in Hard Exploration Problems. (arXiv:2211.13742v2 [cs.NE] UPDATED)",
    "abstract": "A fascinating aspect of nature lies in its ability to produce a collection of organisms that are all high-performing in their niche. Quality-Diversity (QD) methods are evolutionary algorithms inspired by this observation, that obtained great results in many applications, from wing design to robot adaptation. Recently, several works demonstrated that these methods could be applied to perform neuro-evolution to solve control problems in large search spaces. In such problems, diversity can be a target in itself. Diversity can also be a way to enhance exploration in tasks exhibiting deceptive reward signals. While the first aspect has been studied in depth in the QD community, the latter remains scarcer in the literature. Exploration is at the heart of several domains trying to solve control problems such as Reinforcement Learning and QD methods are promising candidates to overcome the challenges associated. Therefore, we believe that standardized benchmarks exhibiting control problems in ",
    "link": "http://arxiv.org/abs/2211.13742",
    "context": "Title: Assessing Quality-Diversity Neuro-Evolution Algorithms Performance in Hard Exploration Problems. (arXiv:2211.13742v2 [cs.NE] UPDATED)\nAbstract: A fascinating aspect of nature lies in its ability to produce a collection of organisms that are all high-performing in their niche. Quality-Diversity (QD) methods are evolutionary algorithms inspired by this observation, that obtained great results in many applications, from wing design to robot adaptation. Recently, several works demonstrated that these methods could be applied to perform neuro-evolution to solve control problems in large search spaces. In such problems, diversity can be a target in itself. Diversity can also be a way to enhance exploration in tasks exhibiting deceptive reward signals. While the first aspect has been studied in depth in the QD community, the latter remains scarcer in the literature. Exploration is at the heart of several domains trying to solve control problems such as Reinforcement Learning and QD methods are promising candidates to overcome the challenges associated. Therefore, we believe that standardized benchmarks exhibiting control problems in ",
    "path": "papers/22/11/2211.13742.json",
    "total_tokens": 868,
    "translated_title": "在困难的探索问题中评估质量多样性神经进化算法的性能",
    "translated_abstract": "自然界的一个迷人之处在于它能产生一系列在各自领域表现出色的生物体。质量多样性（QD）方法是灵感来自于这一观察的进化算法，在许多应用中取得了巨大的成果，从翅膀设计到机器人适应性。最近，多项研究表明这些方法可以应用于神经进化来解决大搜索空间中的控制问题。在这种问题中，多样性本身可以成为一个目标。多样性也可以成为增强具有欺骗性奖励信号的任务探索的一种方式。虽然QD社区已经深入研究了前者，但后者在文献中相对较少。探索是许多领域如强化学习中试图解决控制问题的核心，QD方法是克服相关挑战的有希望的候选方法。因此，我们相信标准化的基准测试在这些控制问题上是必要的。",
    "tldr": "本文评估了质量多样性神经进化算法在困难探索问题中的性能，并强调了探索在解决控制问题中的重要性。",
    "en_tdlr": "This paper assesses the performance of quality-diversity neuro-evolution algorithms in hard exploration problems, emphasizing the importance of exploration in solving control problems."
}