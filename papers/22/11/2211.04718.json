{
    "title": "On the Application of Efficient Neural Mapping to Real-Time Indoor Localisation for Unmanned Ground Vehicles. (arXiv:2211.04718v2 [cs.RO] UPDATED)",
    "abstract": "Global localisation from visual data is a challenging problem applicable to many robotics domains. Prior works have shown that neural networks can be trained to map images of an environment to absolute camera pose within that environment, learning an implicit neural mapping in the process. In this work we evaluate the applicability of such an approach to real-world robotics scenarios, demonstrating that by constraining the problem to 2-dimensions and significantly increasing the quantity of training data, a compact model capable of real-time inference on embedded platforms can be used to achieve localisation accuracy of several centimetres. We deploy our trained model onboard a UGV platform, demonstrating its effectiveness in a waypoint navigation task, wherein it is able to localise with a mean accuracy of 9cm at a rate of 6fps running on the UGV onboard CPU, 35fps on an embedded GPU, or 220fps on a desktop GPU. Along with this work we will release a novel localisation dataset compris",
    "link": "http://arxiv.org/abs/2211.04718",
    "context": "Title: On the Application of Efficient Neural Mapping to Real-Time Indoor Localisation for Unmanned Ground Vehicles. (arXiv:2211.04718v2 [cs.RO] UPDATED)\nAbstract: Global localisation from visual data is a challenging problem applicable to many robotics domains. Prior works have shown that neural networks can be trained to map images of an environment to absolute camera pose within that environment, learning an implicit neural mapping in the process. In this work we evaluate the applicability of such an approach to real-world robotics scenarios, demonstrating that by constraining the problem to 2-dimensions and significantly increasing the quantity of training data, a compact model capable of real-time inference on embedded platforms can be used to achieve localisation accuracy of several centimetres. We deploy our trained model onboard a UGV platform, demonstrating its effectiveness in a waypoint navigation task, wherein it is able to localise with a mean accuracy of 9cm at a rate of 6fps running on the UGV onboard CPU, 35fps on an embedded GPU, or 220fps on a desktop GPU. Along with this work we will release a novel localisation dataset compris",
    "path": "papers/22/11/2211.04718.json",
    "total_tokens": 962,
    "translated_title": "关于高效神经映射在无人地面车辆实时室内定位中的应用",
    "translated_abstract": "从视觉数据中进行全局定位是一个具有挑战性的问题，适用于许多机器人领域。先前的研究表明，可以训练神经网络将环境的图像映射到该环境下的绝对相机姿态，从而在此过程中学习隐式神经映射。在本研究中，我们评估了这种方法在实际机器人场景中的适用性，证明通过将问题限制在二维空间，并显著增加训练数据量，可以使用紧凑的模型在嵌入式平台上实时推理，实现几厘米的定位精度。我们在地面车辆平台上部署了训练好的模型，在航点导航任务中展示了其有效性，在地面车辆的嵌入式CPU上以6fps的速率和平均精度为9cm进行定位，在嵌入式GPU上以35fps的速率进行定位，在桌面GPU上以220fps的速率进行定位。除此之外，我们还将发布一个新颖的定位数据集",
    "tldr": "本文评估了将神经网络映射应用于实际机器人场景中的可行性，通过限制问题维度并增加训练数据量，可以实现嵌入式平台上几厘米级别的实时定位精度。",
    "en_tdlr": "This paper evaluates the applicability of using neural networks to map images of the environment to absolute camera pose for real-world robotics scenarios. By constraining the problem to 2-dimensions and increasing the training data, a compact model capable of real-time inference on embedded platforms can achieve centimeter-level localization accuracy."
}