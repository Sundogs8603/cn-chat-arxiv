{
    "title": "On counterfactual inference with unobserved confounding. (arXiv:2211.08209v3 [cs.LG] UPDATED)",
    "abstract": "Given an observational study with $n$ independent but heterogeneous units, our goal is to learn the counterfactual distribution for each unit using only one $p$-dimensional sample per unit containing covariates, interventions, and outcomes. Specifically, we allow for unobserved confounding that introduces statistical biases between interventions and outcomes as well as exacerbates the heterogeneity across units. Modeling the conditional distribution of the outcomes as an exponential family, we reduce learning the unit-level counterfactual distributions to learning $n$ exponential family distributions with heterogeneous parameters and only one sample per distribution. We introduce a convex objective that pools all $n$ samples to jointly learn all $n$ parameter vectors, and provide a unit-wise mean squared error bound that scales linearly with the metric entropy of the parameter space. For example, when the parameters are $s$-sparse linear combination of $k$ known vectors, the error is $",
    "link": "http://arxiv.org/abs/2211.08209",
    "context": "Title: On counterfactual inference with unobserved confounding. (arXiv:2211.08209v3 [cs.LG] UPDATED)\nAbstract: Given an observational study with $n$ independent but heterogeneous units, our goal is to learn the counterfactual distribution for each unit using only one $p$-dimensional sample per unit containing covariates, interventions, and outcomes. Specifically, we allow for unobserved confounding that introduces statistical biases between interventions and outcomes as well as exacerbates the heterogeneity across units. Modeling the conditional distribution of the outcomes as an exponential family, we reduce learning the unit-level counterfactual distributions to learning $n$ exponential family distributions with heterogeneous parameters and only one sample per distribution. We introduce a convex objective that pools all $n$ samples to jointly learn all $n$ parameter vectors, and provide a unit-wise mean squared error bound that scales linearly with the metric entropy of the parameter space. For example, when the parameters are $s$-sparse linear combination of $k$ known vectors, the error is $",
    "path": "papers/22/11/2211.08209.json",
    "total_tokens": 902,
    "translated_title": "关于未观察到的混淆因素下的反事实推断",
    "translated_abstract": "在观测研究中，我们的目标是利用每个单位只有一个包含协变量、干预和结果的$p$维样本来学习每个单位的反事实分布，这些单位是独立但异质的。具体而言，我们允许存在未观察到的混淆因素，它引入了干预和结果之间的统计偏差，并加剧了单位之间的异质性。将结果的条件分布建模为指数族，我们将学习单位级反事实分布简化为学习具有异质参数和仅有一个样本的$n$个指数族分布。我们引入了一个凸优化目标，将所有$n$个样本汇集起来共同学习所有$n$个参数向量，并提供了一个单位级均方误差的界限，该界限与参数空间的度量熵成线性关系。例如，当参数是$k$个已知向量的$s$稀疏线性组合时，误差为$O(k\\sqrt{\\frac{s\\log p}{n}})$。",
    "tldr": "本研究提出了一种在观测研究中应对未观察到混淆因素进行反事实推断的方法，通过建模条件分布，学习了各单位的反事实分布，并提供了一个均方误差的界限。",
    "en_tdlr": "This paper presents a method for counterfactual inference in observational studies with unobserved confounding. By modeling the conditional distribution and learning the counterfactual distributions for each unit, the study provides an error bound for the estimation of the distributions."
}