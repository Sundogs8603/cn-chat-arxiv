{
    "title": "Improving Proactive Dialog Agents Using Socially-Aware Reinforcement Learning. (arXiv:2211.15359v2 [cs.CL] UPDATED)",
    "abstract": "The next step for intelligent dialog agents is to escape their role as silent bystanders and become proactive. Well-defined proactive behavior may improve human-machine cooperation, as the agent takes a more active role during interaction and takes off responsibility from the user. However, proactivity is a double-edged sword because poorly executed pre-emptive actions may have a devastating effect not only on the task outcome but also on the relationship with the user. For designing adequate proactive dialog strategies, we propose a novel approach including both social as well as task-relevant features in the dialog. Here, the primary goal is to optimize proactive behavior so that it is task-oriented - this implies high task success and efficiency - while also being socially effective by fostering user trust. Including both aspects in the reward function for training a proactive dialog agent using reinforcement learning showed the benefit of our approach for more successful human-mach",
    "link": "http://arxiv.org/abs/2211.15359",
    "context": "Title: Improving Proactive Dialog Agents Using Socially-Aware Reinforcement Learning. (arXiv:2211.15359v2 [cs.CL] UPDATED)\nAbstract: The next step for intelligent dialog agents is to escape their role as silent bystanders and become proactive. Well-defined proactive behavior may improve human-machine cooperation, as the agent takes a more active role during interaction and takes off responsibility from the user. However, proactivity is a double-edged sword because poorly executed pre-emptive actions may have a devastating effect not only on the task outcome but also on the relationship with the user. For designing adequate proactive dialog strategies, we propose a novel approach including both social as well as task-relevant features in the dialog. Here, the primary goal is to optimize proactive behavior so that it is task-oriented - this implies high task success and efficiency - while also being socially effective by fostering user trust. Including both aspects in the reward function for training a proactive dialog agent using reinforcement learning showed the benefit of our approach for more successful human-mach",
    "path": "papers/22/11/2211.15359.json",
    "total_tokens": 905,
    "translated_title": "使用社交感知强化学习提高主动对话代理的性能",
    "translated_abstract": "智能对话代理的下一个步骤是从旁观者的角色中解脱出来，变得更加主动。明确定义的主动行为可以改善人机合作，因为代理在交互过程中扮演更积极的角色并解除了用户的责任。然而，主动性是一把双刃剑，因为执行不当的预防性行动可能不仅对任务结果产生破坏性影响，而且还会对与用户的关系产生影响。为了设计合适的主动对话策略，我们提出了一种新的方法，将社交和任务相关特征都考虑在对话中。这里的主要目标是优化主动行为，使其任务导向——这意味着高任务成功率和效率——同时在促进用户信任时也具有社交效益。将这两个方面包含在用强化学习训练主动对话代理的奖励函数中，显示出我们的方法对于更加成功的人机交互的益处。",
    "tldr": "本论文的主要贡献在于提出了一种新的方法，通过将社交和任务相关特征考虑在对话中，来优化主动对话策略，使其在任务效率高的同时，也能促进用户信任，从而提高人机交互的成功率和效率。",
    "en_tdlr": "This paper proposes a novel approach to optimize proactive dialog strategies by considering both social and task-relevant features in the dialog using reinforcement learning, which improves human-machine interactions by promoting user trust while maintaining high task success and efficiency."
}