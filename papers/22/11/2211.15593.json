{
    "title": "GPT-Neo for commonsense reasoning -- a theoretical and practical lens. (arXiv:2211.15593v2 [cs.CL] UPDATED)",
    "abstract": "Recent work has demonstrated substantial gains in pre-training large-language models (LLMs) followed by supervised fine-tuning on the downstream task. In this paper, we evaluate the performance of the GPT-neo model using $6$ commonsense reasoning benchmark tasks. We aim to examine the performance of smaller models using the GPT-neo models against several larger model baselines such as GPT-$3$, Llama-$2$, MPT and Falcon. Upon fine-tuning with the appropriate set of hyperparameters, our model achieves competitive accuracy on several tasks. We also investigate and substantiate our results using attention-head visualization to better understand the model performance. Finally, we conduct various robustness tests using various methods to gauge the model performance under numerous settings.",
    "link": "http://arxiv.org/abs/2211.15593",
    "context": "Title: GPT-Neo for commonsense reasoning -- a theoretical and practical lens. (arXiv:2211.15593v2 [cs.CL] UPDATED)\nAbstract: Recent work has demonstrated substantial gains in pre-training large-language models (LLMs) followed by supervised fine-tuning on the downstream task. In this paper, we evaluate the performance of the GPT-neo model using $6$ commonsense reasoning benchmark tasks. We aim to examine the performance of smaller models using the GPT-neo models against several larger model baselines such as GPT-$3$, Llama-$2$, MPT and Falcon. Upon fine-tuning with the appropriate set of hyperparameters, our model achieves competitive accuracy on several tasks. We also investigate and substantiate our results using attention-head visualization to better understand the model performance. Finally, we conduct various robustness tests using various methods to gauge the model performance under numerous settings.",
    "path": "papers/22/11/2211.15593.json",
    "total_tokens": 795,
    "translated_title": "GPT-Neo用于常识推理--理论与实践视角",
    "translated_abstract": "最近的研究展示了在大型语言模型（LLM）上进行预训练，然后在下游任务中进行有监督微调可以取得显著的进展。在本文中，我们对GPT-Neo模型在6个常识推理基准任务上的性能进行了评估。我们旨在对使用GPT-Neo模型的较小模型与GPT-3、Llama-2、MPT和Falcon等几个较大模型基准进行性能比较。在使用适当的超参数集进行微调后，我们的模型在多个任务上取得了有竞争力的准确性。我们还使用注意力头可视化来调查和证实我们的结果，以更好地理解模型的性能。最后，我们使用各种方法进行了多种鲁棒性测试，以评估模型在多种设置下的性能。",
    "tldr": "本文评估了GPT-Neo模型在常识推理任务上的性能，并与其他较大模型进行了比较。在适当的超参数设置下，该模型在多个任务上取得了具有竞争力的准确性。",
    "en_tdlr": "This paper evaluates the performance of the GPT-Neo model on commonsense reasoning tasks and compares it with larger models. The model achieves competitive accuracy on multiple tasks with appropriate hyperparameter settings."
}