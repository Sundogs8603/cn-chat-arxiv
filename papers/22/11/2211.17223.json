{
    "title": "Topological Data Analysis for Speech Processing. (arXiv:2211.17223v3 [cs.SD] UPDATED)",
    "abstract": "We apply topological data analysis (TDA) to speech classification problems and to the introspection of a pretrained speech model, HuBERT. To this end, we introduce a number of topological and algebraic features derived from Transformer attention maps and embeddings. We show that a simple linear classifier built on top of such features outperforms a fine-tuned classification head. In particular, we achieve an improvement of about $9\\%$ accuracy and $5\\%$ ERR on four common datasets; on CREMA-D, the proposed feature set reaches a new state of the art performance with accuracy $80.155$. We also show that topological features are able to reveal functional roles of speech Transformer heads; e.g., we find the heads capable to distinguish between pairs of sample sources (natural/synthetic) or voices without any downstream fine-tuning. Our results demonstrate that TDA is a promising new approach for speech analysis, especially for tasks that require structural prediction. Appendices, an introd",
    "link": "http://arxiv.org/abs/2211.17223",
    "context": "Title: Topological Data Analysis for Speech Processing. (arXiv:2211.17223v3 [cs.SD] UPDATED)\nAbstract: We apply topological data analysis (TDA) to speech classification problems and to the introspection of a pretrained speech model, HuBERT. To this end, we introduce a number of topological and algebraic features derived from Transformer attention maps and embeddings. We show that a simple linear classifier built on top of such features outperforms a fine-tuned classification head. In particular, we achieve an improvement of about $9\\%$ accuracy and $5\\%$ ERR on four common datasets; on CREMA-D, the proposed feature set reaches a new state of the art performance with accuracy $80.155$. We also show that topological features are able to reveal functional roles of speech Transformer heads; e.g., we find the heads capable to distinguish between pairs of sample sources (natural/synthetic) or voices without any downstream fine-tuning. Our results demonstrate that TDA is a promising new approach for speech analysis, especially for tasks that require structural prediction. Appendices, an introd",
    "path": "papers/22/11/2211.17223.json",
    "total_tokens": 1057,
    "translated_title": "基于拓扑数据分析的语音处理",
    "translated_abstract": "我们将拓扑数据分析（TDA）应用于语音分类问题及预训练语音模型HuBERT的内省。为此，我们介绍了一些基于Transformer注意力图和嵌入的拓扑和代数特征。我们证明，在这些特征基础上构建的简单线性分类器胜过精调分类器头部。特别地，在四个常见数据集上，我们实现了约9%的准确率提高和5%的ERR提高。在CREMA-D数据集上，提出的特征集达到了准确率80.155的新的最优性能。我们还展示了拓扑特征能够揭示语音Transformer头的功能角色。例如，我们发现在没有任何下游精调的情况下，这些头可区分样本来源（自然/合成）或声音对。我们的结果表明，TDA是一种有前途的语音分析方法，尤其是对于需要结构预测的任务。此外，我们还提供了附录、对TDA和HuBERT模型的介绍以及使用其他数据集的实验。",
    "tldr": "本论文将拓扑数据分析应用于语音分类问题和预训练语音模型的内省，并介绍了一系列基于Transformer注意力图和嵌入的拓扑和代数特征。在这些特征基础上构建的简单线性分类器胜过精调分类器头部，并实现了在许多数据集上的最新最优性能。拓扑特征能够揭示语音Transformer头的功能角色，这表明TDA是一种有前途的语音分析方法。",
    "en_tdlr": "This paper applies topological data analysis (TDA) to speech classification tasks and introspection of the pretrained speech model HuBERT, introducing a range of topological and algebraic features derived from transformer attention maps and embeddings. Using these features, a simple linear classifier outperforms a fine-tuned classification head, achieving state-of-the-art performance on multiple datasets. Furthermore, topological features reveal functional roles of speech transformer heads, promising a new approach to speech analysis for tasks requiring structural prediction."
}