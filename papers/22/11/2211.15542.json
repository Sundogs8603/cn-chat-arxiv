{
    "title": "Autonomous Assessment of Demonstration Sufficiency via Bayesian Inverse Reinforcement Learning. (arXiv:2211.15542v3 [cs.LG] UPDATED)",
    "abstract": "We examine the problem of determining demonstration sufficiency: how can a robot self-assess whether it has received enough demonstrations from an expert to ensure a desired level of performance? To address this problem, we propose a novel self-assessment approach based on Bayesian inverse reinforcement learning and value-at-risk, enabling learning-from-demonstration (\"LfD\") robots to compute high-confidence bounds on their performance and use these bounds to determine when they have a sufficient number of demonstrations. We propose and evaluate two definitions of sufficiency: (1) normalized expected value difference, which measures regret with respect to the human's unobserved reward function, and (2) percent improvement over a baseline policy. We demonstrate how to formulate high-confidence bounds on both of these metrics. We evaluate our approach in simulation for both discrete and continuous state-space domains and illustrate the feasibility of developing a robotic system that can ",
    "link": "http://arxiv.org/abs/2211.15542",
    "context": "Title: Autonomous Assessment of Demonstration Sufficiency via Bayesian Inverse Reinforcement Learning. (arXiv:2211.15542v3 [cs.LG] UPDATED)\nAbstract: We examine the problem of determining demonstration sufficiency: how can a robot self-assess whether it has received enough demonstrations from an expert to ensure a desired level of performance? To address this problem, we propose a novel self-assessment approach based on Bayesian inverse reinforcement learning and value-at-risk, enabling learning-from-demonstration (\"LfD\") robots to compute high-confidence bounds on their performance and use these bounds to determine when they have a sufficient number of demonstrations. We propose and evaluate two definitions of sufficiency: (1) normalized expected value difference, which measures regret with respect to the human's unobserved reward function, and (2) percent improvement over a baseline policy. We demonstrate how to formulate high-confidence bounds on both of these metrics. We evaluate our approach in simulation for both discrete and continuous state-space domains and illustrate the feasibility of developing a robotic system that can ",
    "path": "papers/22/11/2211.15542.json",
    "total_tokens": 962,
    "translated_title": "自主评估通过贝叶斯逆强化学习的演示充分性",
    "translated_abstract": "我们研究了确定演示充分性的问题：机器人如何自我评估它是否已经从专家那里获得足够的演示以确保所需的性能水平？为了解决这个问题，我们提出了一种基于贝叶斯逆强化学习和风险价值的新型自我评估方法，使得学习从演示中的机器人能够计算其性能的高置信度边界，并使用这些边界来确定它们是否有足够数量的演示。我们提出并评估了两种充分性的定义：（1）标准化期望值差异，用于衡量相对于人类未观察到的奖励函数的遗憾，以及（2）相对于基准策略的改进百分比。我们展示了如何对这两个指标制定高置信度边界。我们在离散和连续状态空间领域的模拟中评估了我们的方法，并且说明了开发一个能够实现自主评估演示充分性的机器人系统的可行性。",
    "tldr": "本论文提出了一种基于贝叶斯逆强化学习和风险价值的自主评估方法，使得机器人可以通过计算高置信度边界来确定是否有足够数量的演示。作者定义了两种充分性指标，并在模拟环境中评估了该方法的可行性。",
    "en_tdlr": "This paper presents a novel autonomous assessment approach based on Bayesian inverse reinforcement learning and value-at-risk, allowing robots to compute high-confidence bounds on their performance to determine if they have enough demonstrations. The authors define two metrics for sufficiency and evaluate the feasibility of the approach in simulation environments."
}