{
    "title": "A Low Latency Adaptive Coding Spiking Framework for Deep Reinforcement Learning. (arXiv:2211.11760v2 [cs.LG] UPDATED)",
    "abstract": "In recent years, spiking neural networks (SNNs) have been used in reinforcement learning (RL) due to their low power consumption and event-driven features. However, spiking reinforcement learning (SRL), which suffers from fixed coding methods, still faces the problems of high latency and poor versatility. In this paper, we use learnable matrix multiplication to encode and decode spikes, improving the flexibility of the coders and thus reducing latency. Meanwhile, we train the SNNs using the direct training method and use two different structures for online and offline RL algorithms, which gives our model a wider range of applications. Extensive experiments have revealed that our method achieves optimal performance with ultra-low latency (as low as 0.8% of other SRL methods) and excellent energy efficiency (up to 5X the DNNs) in different algorithms and different environments.",
    "link": "http://arxiv.org/abs/2211.11760",
    "context": "Title: A Low Latency Adaptive Coding Spiking Framework for Deep Reinforcement Learning. (arXiv:2211.11760v2 [cs.LG] UPDATED)\nAbstract: In recent years, spiking neural networks (SNNs) have been used in reinforcement learning (RL) due to their low power consumption and event-driven features. However, spiking reinforcement learning (SRL), which suffers from fixed coding methods, still faces the problems of high latency and poor versatility. In this paper, we use learnable matrix multiplication to encode and decode spikes, improving the flexibility of the coders and thus reducing latency. Meanwhile, we train the SNNs using the direct training method and use two different structures for online and offline RL algorithms, which gives our model a wider range of applications. Extensive experiments have revealed that our method achieves optimal performance with ultra-low latency (as low as 0.8% of other SRL methods) and excellent energy efficiency (up to 5X the DNNs) in different algorithms and different environments.",
    "path": "papers/22/11/2211.11760.json",
    "total_tokens": 885,
    "translated_title": "一个低延迟自适应编码脉冲框架用于深度强化学习",
    "translated_abstract": "近年来，由于低功耗和事件驱动特性，脉冲神经网络（SNNs）被用于强化学习（RL）。然而，固定编码方法导致的脉冲强化学习（SRL）仍然面临高延迟和较差的灵活性问题。本文中，我们使用可学习的矩阵乘法对脉冲进行编码和解码，提高编码器的灵活性，从而降低延迟。同时，我们使用直接训练方法训练SNNs，并使用两种不同的结构用于在线和离线强化学习算法，使我们的模型拥有更广泛的应用范围。广泛的实验表明，我们的方法在不同的算法和不同的环境中实现了最佳性能，延迟极低（仅为其他SRL方法的0.8%）且具有极高的能量效率（高达DNNs的5倍）。",
    "tldr": "本文提出了一个低延迟自适应编码脉冲框架用于深度强化学习，在编码器灵活性、延迟和能量效率方面具有优异性能和广泛应用范围。",
    "en_tdlr": "This paper proposes a low-latency adaptive coding spiking framework for deep reinforcement learning, achieving optimal performance in terms of flexibility, latency, and energy efficiency, with a wide range of applications."
}