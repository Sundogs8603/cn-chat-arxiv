{
    "title": "Analysis and Detectability of Offline Data Poisoning Attacks on Linear Dynamical Systems. (arXiv:2211.08804v4 [eess.SY] UPDATED)",
    "abstract": "In recent years, there has been a growing interest in the effects of data poisoning attacks on data-driven control methods. Poisoning attacks are well-known to the Machine Learning community, which, however, make use of assumptions, such as cross-sample independence, that in general do not hold for linear dynamical systems. Consequently, these systems require different attack and detection methods than those developed for supervised learning problems in the i.i.d.\\ setting. Since most data-driven control algorithms make use of the least-squares estimator, we study how poisoning impacts the least-squares estimate through the lens of statistical testing, and question in what way data poisoning attacks can be detected. We establish under which conditions the set of models compatible with the data includes the true model of the system, and we analyze different poisoning strategies for the attacker. On the basis of the arguments hereby presented, we propose a stealthy data poisoning attack ",
    "link": "http://arxiv.org/abs/2211.08804",
    "context": "Title: Analysis and Detectability of Offline Data Poisoning Attacks on Linear Dynamical Systems. (arXiv:2211.08804v4 [eess.SY] UPDATED)\nAbstract: In recent years, there has been a growing interest in the effects of data poisoning attacks on data-driven control methods. Poisoning attacks are well-known to the Machine Learning community, which, however, make use of assumptions, such as cross-sample independence, that in general do not hold for linear dynamical systems. Consequently, these systems require different attack and detection methods than those developed for supervised learning problems in the i.i.d.\\ setting. Since most data-driven control algorithms make use of the least-squares estimator, we study how poisoning impacts the least-squares estimate through the lens of statistical testing, and question in what way data poisoning attacks can be detected. We establish under which conditions the set of models compatible with the data includes the true model of the system, and we analyze different poisoning strategies for the attacker. On the basis of the arguments hereby presented, we propose a stealthy data poisoning attack ",
    "path": "papers/22/11/2211.08804.json",
    "total_tokens": 943,
    "translated_title": "线性动态系统离线数据污染攻击的分析和可检测性",
    "translated_abstract": "近年来，对数据驱动控制方法中的数据污染攻击影响的研究越来越受关注。机器学习社区已经熟知了毒化攻击，但这些攻击通常使用交叉样本独立等假设，而这些假设在线性动态系统中通常不成立。因此，这些系统需要与i.i.d.设置下针对监督学习问题开发的攻击和检测方法不同的攻击和检测方法。由于大多数数据驱动控制算法使用最小二乘估计，我们通过统计测试来研究污染如何影响最小二乘估计，并质疑数据污染攻击可以以什么方式被检测到。我们确定了在哪些条件下与数据兼容的模型集包含系统的真实模型，并分析了攻击者的不同污染策略。基于此，我们提出了一种隐蔽的数据污染攻击。",
    "tldr": "研究发现，针对线性动态系统的数据污染攻击需要不同的攻击和检测方法。论文针对最小二乘估计进行了统计测试，确定了与数据兼容的模型集是否包括系统的真实模型，并提出了一种隐蔽的数据污染攻击。",
    "en_tdlr": "The study finds that data poisoning attacks on linear dynamical systems require different attack and detection methods than those developed for supervised learning problems. The paper proposes a stealthy data poisoning attack and uses statistical testing on the least-squares estimator to determine if the set of models compatible with the data includes the true model of the system."
}