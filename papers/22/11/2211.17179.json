{
    "title": "Investigation of Proper Orthogonal Decomposition for Echo State Networks. (arXiv:2211.17179v3 [cs.LG] UPDATED)",
    "abstract": "Echo State Networks (ESN) are a type of Recurrent Neural Network that yields promising results in representing time series and nonlinear dynamic systems. Although they are equipped with a very efficient training procedure, Reservoir Computing strategies, such as the ESN, require high-order networks, i.e., many neurons, resulting in a large number of states that are magnitudes higher than the number of model inputs and outputs. A large number of states not only makes the time-step computation more costly but also may pose robustness issues, especially when applying ESNs to problems such as Model Predictive Control (MPC) and other optimal control problems. One way to circumvent this complexity issue is through Model Order Reduction strategies such as the Proper Orthogonal Decomposition (POD) and its variants (POD-DEIM), whereby we find an equivalent lower order representation to an already trained high dimension ESN. To this end, this work aims to investigate and analyze the performance ",
    "link": "http://arxiv.org/abs/2211.17179",
    "context": "Title: Investigation of Proper Orthogonal Decomposition for Echo State Networks. (arXiv:2211.17179v3 [cs.LG] UPDATED)\nAbstract: Echo State Networks (ESN) are a type of Recurrent Neural Network that yields promising results in representing time series and nonlinear dynamic systems. Although they are equipped with a very efficient training procedure, Reservoir Computing strategies, such as the ESN, require high-order networks, i.e., many neurons, resulting in a large number of states that are magnitudes higher than the number of model inputs and outputs. A large number of states not only makes the time-step computation more costly but also may pose robustness issues, especially when applying ESNs to problems such as Model Predictive Control (MPC) and other optimal control problems. One way to circumvent this complexity issue is through Model Order Reduction strategies such as the Proper Orthogonal Decomposition (POD) and its variants (POD-DEIM), whereby we find an equivalent lower order representation to an already trained high dimension ESN. To this end, this work aims to investigate and analyze the performance ",
    "path": "papers/22/11/2211.17179.json",
    "total_tokens": 1194,
    "translated_title": "适用于回声状态网络的适当正交分解的探讨",
    "translated_abstract": "回声状态网络（ESN）是一种递归神经网络，在表示时间序列和非线性动态系统方面展现出良好的效果。虽然它们配备了非常有效的训练程序，例如ESN这样的储留计算策略，但却需要高阶网络即许多神经元，导致状态数量远高于模型的输入和输出数量。大量的状态不仅会增加时间步计算的成本，还会导致鲁棒性问题，尤其是将ESN应用于模型预测控制（MPC）和其他最优控制问题时。一种避免这种复杂性问题的方法是通过模型阶数降低策略，例如适当正交分解（POD）及其变体（POD-DEIM），从而找到一个等效的低阶表示形式来替换已经训练过的高维ESN。为此，本文旨在探讨并分析适用于回声状态网络的适当正交分解（POD）在时间序列建模和最优控制问题中的表现。研究旨在表明如何通过POD有效地减少ESN的复杂度，找到一个低阶表示形式，从而保留ESN的动态性和性能。结果表明，基于POD的ESN可以显著减少所需的状态数，同时保持良好的性能，使其在计算时间和鲁棒性方面更加高效。",
    "tldr": "本研究探讨了适用于回声状态网络的适当正交分解策略，该策略可通过找到等效性的低阶表示形式来替换高维的ESN。结果表明，基于POD的ESN显著减少所需的状态数，同时保持良好的性能，使其在计算时间和鲁棒性方面更加高效。",
    "en_tdlr": "This study investigates the use of Proper Orthogonal Decomposition (POD) for Echo State Networks (ESN) to reduce their complexity and increase their efficiency by finding a lower order representation that maintains performance. Results show that POD-based ESNs significantly reduce state requirements while maintaining good performance, making them more efficient in terms of computation time and robustness."
}