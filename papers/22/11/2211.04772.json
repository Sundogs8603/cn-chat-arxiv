{
    "title": "Efficient Large-scale Audio Tagging via Transformer-to-CNN Knowledge Distillation. (arXiv:2211.04772v3 [cs.SD] UPDATED)",
    "abstract": "Audio Spectrogram Transformer models rule the field of Audio Tagging, outrunning previously dominating Convolutional Neural Networks (CNNs). Their superiority is based on the ability to scale up and exploit large-scale datasets such as AudioSet. However, Transformers are demanding in terms of model size and computational requirements compared to CNNs. We propose a training procedure for efficient CNNs based on offline Knowledge Distillation (KD) from high-performing yet complex transformers. The proposed training schema and the efficient CNN design based on MobileNetV3 results in models outperforming previous solutions in terms of parameter and computational efficiency and prediction performance. We provide models of different complexity levels, scaling from low-complexity models up to a new state-of-the-art performance of .483 mAP on AudioSet. Source Code available at: https://github.com/fschmid56/EfficientAT",
    "link": "http://arxiv.org/abs/2211.04772",
    "context": "Title: Efficient Large-scale Audio Tagging via Transformer-to-CNN Knowledge Distillation. (arXiv:2211.04772v3 [cs.SD] UPDATED)\nAbstract: Audio Spectrogram Transformer models rule the field of Audio Tagging, outrunning previously dominating Convolutional Neural Networks (CNNs). Their superiority is based on the ability to scale up and exploit large-scale datasets such as AudioSet. However, Transformers are demanding in terms of model size and computational requirements compared to CNNs. We propose a training procedure for efficient CNNs based on offline Knowledge Distillation (KD) from high-performing yet complex transformers. The proposed training schema and the efficient CNN design based on MobileNetV3 results in models outperforming previous solutions in terms of parameter and computational efficiency and prediction performance. We provide models of different complexity levels, scaling from low-complexity models up to a new state-of-the-art performance of .483 mAP on AudioSet. Source Code available at: https://github.com/fschmid56/EfficientAT",
    "path": "papers/22/11/2211.04772.json",
    "total_tokens": 873,
    "translated_title": "基于Transformer-to-CNN知识蒸馏的高效大规模音频标记",
    "translated_abstract": "音频谱变换器模型统治着音频标记领域，超越了以前占主导地位的卷积神经网络(CNN)。它们的优势在于能够扩展和利用像AudioSet这样的大规模数据集。但是，与CNN相比，变换器在模型大小和计算要求方面要求更高。我们提出了一种基于高性能但复杂的变换器的离线知识蒸馏(KD)的高效CNN训练过程。所提出的训练架构和基于MobileNetV3的高效CNN设计导致了参数和计算效率以及预测性能方面优于以前的解决方案的模型。我们提供了不同复杂度级别的模型，从低复杂度模型到新的AudioSet .483 mAP的最新性能。源代码可在https://github.com/fschmid56/EfficientAT上获得。",
    "tldr": "本文提出了一种基于离线知识蒸馏的训练方法，将高性能但复杂的Transformer模型转化为高效的CNN模型，从而取得了优于以前方法的预测性能和参数以及计算效率。",
    "en_tdlr": "This paper proposes an efficient training procedure for CNN models based on offline knowledge distillation from high-performing yet complex Transformers for large-scale audio tagging, resulting in models with better prediction performance, parameter efficiency and computational efficiency than previous solutions, with a new state-of-the-art performance of .483 mAP on AudioSet."
}