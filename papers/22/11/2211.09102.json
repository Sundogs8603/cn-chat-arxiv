{
    "title": "Prompting PaLM for Translation: Assessing Strategies and Performance. (arXiv:2211.09102v3 [cs.CL] UPDATED)",
    "abstract": "Large language models (LLMs) that have been trained on multilingual but not parallel text exhibit a remarkable ability to translate between languages. We probe this ability in an in-depth study of the pathways language model (PaLM), which has demonstrated the strongest machine translation (MT) performance among similarly-trained LLMs to date. We investigate various strategies for choosing translation examples for few-shot prompting, concluding that example quality is the most important factor. Using optimized prompts, we revisit previous assessments of PaLM's MT capabilities with more recent test sets, modern MT metrics, and human evaluation, and find that its performance, while impressive, still lags that of state-of-the-art supervised systems. We conclude by providing an analysis of PaLM's MT output which reveals some interesting properties and prospects for future work.",
    "link": "http://arxiv.org/abs/2211.09102",
    "context": "Title: Prompting PaLM for Translation: Assessing Strategies and Performance. (arXiv:2211.09102v3 [cs.CL] UPDATED)\nAbstract: Large language models (LLMs) that have been trained on multilingual but not parallel text exhibit a remarkable ability to translate between languages. We probe this ability in an in-depth study of the pathways language model (PaLM), which has demonstrated the strongest machine translation (MT) performance among similarly-trained LLMs to date. We investigate various strategies for choosing translation examples for few-shot prompting, concluding that example quality is the most important factor. Using optimized prompts, we revisit previous assessments of PaLM's MT capabilities with more recent test sets, modern MT metrics, and human evaluation, and find that its performance, while impressive, still lags that of state-of-the-art supervised systems. We conclude by providing an analysis of PaLM's MT output which reveals some interesting properties and prospects for future work.",
    "path": "papers/22/11/2211.09102.json",
    "total_tokens": 864,
    "translated_title": "PaLM的翻译提示：评估策略和性能",
    "translated_abstract": "在多语言但非并行文本上训练的大型语言模型(LLMs)展示了出色的翻译能力。我们对Pathways语言模型(PaLM)进行了深入研究，这是迄今为止经过类似训练的LLMs中表现最强的机器翻译(MT)模型之一。我们研究了选择少量样例进行提示的各种策略，得出结论是样例的质量是最重要的因素。使用优化后的提示，我们重新评估了PaLM在最新的测试集、现代MT度量和人工评价方面的MT能力，并发现它的表现虽然令人印象深刻，但仍然落后于最先进的监督系统。最后，我们提供了一份对PaLM的MT输出进行分析的报告，这揭示了一些有趣的特性和未来工作的前景。",
    "tldr": "本文通过对PaLM的研究评估了少量样例提示翻译的各种策略，并发现样例的质量是最重要的因素。此外，研究表明PaLM的性能虽然令人印象深刻，但仍然落后于最先进的监督系统。",
    "en_tdlr": "This paper evaluates various strategies for few-shot prompting translation examples in the Pathways language model (PaLM). It finds that example quality is the most important factor and that while PaLM's machine translation performance is impressive, it still lags behind state-of-the-art supervised systems."
}