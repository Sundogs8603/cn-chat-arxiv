{
    "title": "Bidirectional Generation of Structure and Properties Through a Single Molecular Foundation Model. (arXiv:2211.10590v4 [cs.LG] UPDATED)",
    "abstract": "The recent success of large foundation models in artificial intelligence has prompted the emergence of chemical pre-trained models. Despite the growing interest in large molecular pre-trained models that provide informative representations for downstream tasks, attempts for multimodal pre-training approaches on the molecule domain were limited. To address this, we present a novel multimodal molecular pre-trained model that incorporates the modalities of structure and biochemical properties, drawing inspiration from recent advances in multimodal learning techniques. Our proposed model pipeline of data handling and training objectives aligns the structure/property features in a common embedding space, which enables the model to regard bidirectional information between the molecules' structure and properties. These contributions emerge synergistic knowledge, allowing us to tackle both multimodal and unimodal downstream tasks through a single model. Through extensive experiments, we demons",
    "link": "http://arxiv.org/abs/2211.10590",
    "context": "Title: Bidirectional Generation of Structure and Properties Through a Single Molecular Foundation Model. (arXiv:2211.10590v4 [cs.LG] UPDATED)\nAbstract: The recent success of large foundation models in artificial intelligence has prompted the emergence of chemical pre-trained models. Despite the growing interest in large molecular pre-trained models that provide informative representations for downstream tasks, attempts for multimodal pre-training approaches on the molecule domain were limited. To address this, we present a novel multimodal molecular pre-trained model that incorporates the modalities of structure and biochemical properties, drawing inspiration from recent advances in multimodal learning techniques. Our proposed model pipeline of data handling and training objectives aligns the structure/property features in a common embedding space, which enables the model to regard bidirectional information between the molecules' structure and properties. These contributions emerge synergistic knowledge, allowing us to tackle both multimodal and unimodal downstream tasks through a single model. Through extensive experiments, we demons",
    "path": "papers/22/11/2211.10590.json",
    "total_tokens": 883,
    "translated_title": "单个分子基础模型的双向结构和性质的生成",
    "translated_abstract": "人工智能中大型基础模型的成功促使了化学预训练模型的出现。尽管近年来对提供下游任务的信息表示的大分子预训练模型的兴趣日益增长，但分子领域的多模态预训练方法尝试有限。为了解决这个问题，我们提出了一种新颖的多模态分子预训练模型，从多模态学习技术的最新进展中汲取灵感，将结构和生化性质的模态结合起来。我们提出的模型管道处理数据并根据共同的嵌入空间对齐结构/性质特征，使得模型能够将分子的结构和性质之间的双向信息联系起来。这些贡献产生了协同的知识，使我们能够通过单一模型处理多模态和单模态的下游任务。通过大量实验证明，我们的模型足以生成具有双向结构和性质的分子。",
    "tldr": "本论文提出了一种新颖的多模态分子预训练模型，通过将结构和生化性质的模态结合，使得模型能够将分子的结构和性质之间的双向信息联系起来，并能够处理多模态和单模态的下游任务。",
    "en_tdlr": "This paper proposes a novel multimodal molecular pre-trained model, which combines the modes of structure and biochemical properties, enabling the model to connect bidirectional information between the molecules' structure and properties, and handle both multimodal and unimodal downstream tasks."
}