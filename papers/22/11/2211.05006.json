{
    "title": "Almost Tight Error Bounds on Differentially Private Continual Counting",
    "abstract": "The first large-scale deployment of private federated learning uses differentially private counting in the continual release model as a subroutine (Google AI blog titled \"Federated Learning with Formal Differential Privacy Guarantees\"). In this case, a concrete bound on the error is very relevant to reduce the privacy parameter. The standard mechanism for continual counting is the binary mechanism. We present a novel mechanism and show that its mean squared error is both asymptotically optimal and a factor 10 smaller than the error of the binary mechanism. We also show that the constants in our analysis are almost tight by giving non-asymptotic lower and upper bounds that differ only in the constants of lower-order terms. Our algorithm is a matrix mechanism for the counting matrix and takes constant time per release. We also use our explicit factorization of the counting matrix to give an upper bound on the excess risk of the private learning algorithm of Denisov et al. (NeurIPS 2022).",
    "link": "https://arxiv.org/abs/2211.05006",
    "context": "Title: Almost Tight Error Bounds on Differentially Private Continual Counting\nAbstract: The first large-scale deployment of private federated learning uses differentially private counting in the continual release model as a subroutine (Google AI blog titled \"Federated Learning with Formal Differential Privacy Guarantees\"). In this case, a concrete bound on the error is very relevant to reduce the privacy parameter. The standard mechanism for continual counting is the binary mechanism. We present a novel mechanism and show that its mean squared error is both asymptotically optimal and a factor 10 smaller than the error of the binary mechanism. We also show that the constants in our analysis are almost tight by giving non-asymptotic lower and upper bounds that differ only in the constants of lower-order terms. Our algorithm is a matrix mechanism for the counting matrix and takes constant time per release. We also use our explicit factorization of the counting matrix to give an upper bound on the excess risk of the private learning algorithm of Denisov et al. (NeurIPS 2022).",
    "path": "papers/22/11/2211.05006.json",
    "total_tokens": 935,
    "translated_title": "关于差分隐私持续计数的几乎严格的误差界限",
    "translated_abstract": "私有联邦学习的首个大规模部署在持续发布模型中使用差分隐私计数作为子程序 (标题为 \"带有正式差分隐私保证的联邦学习\")。在这种情况下，对误差的具体界限非常重要，以减小隐私参数。持续计数的标准机制是二进制机制。我们提出了一种新颖的机制，并且证明其均方误差既是渐近优化的，又比二进制机制的误差小一个因子10。我们还通过给出非渐近的下界和上界，证明了我们分析中的常数几乎是严格的，只在低阶项的常数中有所不同。我们的算法是计数矩阵的矩阵机制，并且每次发布都需要常数时间。我们还利用我们对计数矩阵的明确因式分解，给出了Denisov等人的私有学习算法的超出风险的上界 (NeurIPS 2022)。",
    "tldr": "这项研究提出了一种新颖的机制，能够在差分隐私持续计数中减小误差，并证明其均方误差比二进制机制小一个因子10。研究还给出了几乎严格的常数界限，以及对私有学习算法超出风险的上界。",
    "en_tdlr": "This research introduces a novel mechanism to reduce the error in differentially private continual counting and proves that its mean squared error is 10 times smaller than the binary mechanism. The study also provides nearly tight bounds on the constants and an upper bound on the excess risk of a private learning algorithm."
}