{
    "title": "A Light Touch Approach to Teaching Transformers Multi-view Geometry. (arXiv:2211.15107v2 [cs.CV] UPDATED)",
    "abstract": "Transformers are powerful visual learners, in large part due to their conspicuous lack of manually-specified priors. This flexibility can be problematic in tasks that involve multiple-view geometry, due to the near-infinite possible variations in 3D shapes and viewpoints (requiring flexibility), and the precise nature of projective geometry (obeying rigid laws). To resolve this conundrum, we propose a \"light touch\" approach, guiding visual Transformers to learn multiple-view geometry but allowing them to break free when needed. We achieve this by using epipolar lines to guide the Transformer's cross-attention maps, penalizing attention values outside the epipolar lines and encouraging higher attention along these lines since they contain geometrically plausible matches. Unlike previous methods, our proposal does not require any camera pose information at test-time. We focus on pose-invariant object instance retrieval, where standard Transformer networks struggle, due to the large diffe",
    "link": "http://arxiv.org/abs/2211.15107",
    "context": "Title: A Light Touch Approach to Teaching Transformers Multi-view Geometry. (arXiv:2211.15107v2 [cs.CV] UPDATED)\nAbstract: Transformers are powerful visual learners, in large part due to their conspicuous lack of manually-specified priors. This flexibility can be problematic in tasks that involve multiple-view geometry, due to the near-infinite possible variations in 3D shapes and viewpoints (requiring flexibility), and the precise nature of projective geometry (obeying rigid laws). To resolve this conundrum, we propose a \"light touch\" approach, guiding visual Transformers to learn multiple-view geometry but allowing them to break free when needed. We achieve this by using epipolar lines to guide the Transformer's cross-attention maps, penalizing attention values outside the epipolar lines and encouraging higher attention along these lines since they contain geometrically plausible matches. Unlike previous methods, our proposal does not require any camera pose information at test-time. We focus on pose-invariant object instance retrieval, where standard Transformer networks struggle, due to the large diffe",
    "path": "papers/22/11/2211.15107.json",
    "total_tokens": 940,
    "translated_title": "一种简单的方法教授Transformer多视角几何",
    "translated_abstract": "Transformer在视觉学习中表现强大，这主要归因于它们缺乏手动规定的先验知识。然而，这种灵活性在涉及多视角几何的任务中可能会成为问题，因为3D形状和视点的近乎无限可能的变化需要灵活性，而投影几何的精确性则需要严格的规则。为了解决这个问题，我们提出了一种“轻触”方法，引导视觉Transformer学习多视角几何，但在需要时允许它们自由发挥。我们通过使用极线来引导Transformer的交叉注意力图，惩罚极线以外的注意值，并鼓励沿这些线的更高的注意，因为它们包含几何上合理的匹配。与以前的方法不同，我们的方法不需要在测试时提供任何摄像机姿态信息。我们关注于姿态不变的物体实例检索，标准的Transformer网络由于不同姿态之间的巨大差异而难以处理。",
    "tldr": "本论文提出了一种轻触式的方法，引导视觉Transformer学习多视角几何，这种方法通过使用极线来引导Transformer的交叉注意力图，可以在测试时不需要提供任何摄像机姿态信息，适用于姿态不变的物体实例检索。",
    "en_tdlr": "This paper proposes a \"light touch\" approach to guide visual Transformers to learn multiple-view geometry without camera pose information at test-time, and focuses on pose-invariant object instance retrieval. The approach uses epipolar lines to guide the Transformer's cross-attention maps, penalizing attention values outside the epipolar lines and encouraging higher attention along these lines for geometrically plausible matches."
}