{
    "title": "Unbiased Supervised Contrastive Learning. (arXiv:2211.05568v3 [cs.LG] UPDATED)",
    "abstract": "Many datasets are biased, namely they contain easy-to-learn features that are highly correlated with the target class only in the dataset but not in the true underlying distribution of the data. For this reason, learning unbiased models from biased data has become a very relevant research topic in the last years. In this work, we tackle the problem of learning representations that are robust to biases. We first present a margin-based theoretical framework that allows us to clarify why recent contrastive losses (InfoNCE, SupCon, etc.) can fail when dealing with biased data. Based on that, we derive a novel formulation of the supervised contrastive loss (epsilon-SupInfoNCE), providing more accurate control of the minimal distance between positive and negative samples. Furthermore, thanks to our theoretical framework, we also propose FairKL, a new debiasing regularization loss, that works well even with extremely biased data. We validate the proposed losses on standard vision datasets inc",
    "link": "http://arxiv.org/abs/2211.05568",
    "context": "Title: Unbiased Supervised Contrastive Learning. (arXiv:2211.05568v3 [cs.LG] UPDATED)\nAbstract: Many datasets are biased, namely they contain easy-to-learn features that are highly correlated with the target class only in the dataset but not in the true underlying distribution of the data. For this reason, learning unbiased models from biased data has become a very relevant research topic in the last years. In this work, we tackle the problem of learning representations that are robust to biases. We first present a margin-based theoretical framework that allows us to clarify why recent contrastive losses (InfoNCE, SupCon, etc.) can fail when dealing with biased data. Based on that, we derive a novel formulation of the supervised contrastive loss (epsilon-SupInfoNCE), providing more accurate control of the minimal distance between positive and negative samples. Furthermore, thanks to our theoretical framework, we also propose FairKL, a new debiasing regularization loss, that works well even with extremely biased data. We validate the proposed losses on standard vision datasets inc",
    "path": "papers/22/11/2211.05568.json",
    "total_tokens": 930,
    "translated_title": "无偏的监督对比学习",
    "translated_abstract": "许多数据集存在偏差，即它们包含仅在数据集中与目标类高度相关的易于学习的特征，但不在真实的数据分布中。因此，从有偏数据中学习无偏模型已成为近年来非常相关的研究课题。在这项工作中，我们解决了学习对偏差具有鲁棒性的表征的问题。我们首先提出了一种基于边缘的理论框架，可以帮助我们澄清为什么最近的对比损失（InfoNCE，SupCon等）在处理偏差数据时可能失败。基于此，我们推导出了一种新的监督对比损失形式（epsilon-SupInfoNCE），提供了更准确的对正负样本之间最小距离的控制。此外，由于我们的理论框架，我们还提出了FairKL，一种新的去偏正则化损失，即使在极度偏差的数据情况下也可以很好地工作。我们在标准的视觉数据集上验证了所提出的损失。",
    "tldr": "本文提出了一种新的监督对比损失形式（epsilon-SupInfoNCE）以及一种新的去偏正则化损失（FairKL），旨在解决从有偏数据中学习无偏模型的问题。",
    "en_tdlr": "This paper proposes a novel supervised contrastive loss (epsilon-SupInfoNCE) and a new debiasing regularization loss (FairKL) to address the problem of learning unbiased models from biased data. These novel formulations aim to provide more accurate control of the minimal distance between positive and negative samples, and have been validated on standard vision datasets."
}