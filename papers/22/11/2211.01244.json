{
    "title": "EquiMod: An Equivariance Module to Improve Self-Supervised Learning. (arXiv:2211.01244v2 [cs.LG] UPDATED)",
    "abstract": "Self-supervised visual representation methods are closing the gap with supervised learning performance. These methods rely on maximizing the similarity between embeddings of related synthetic inputs created through data augmentations. This can be seen as a task that encourages embeddings to leave out factors modified by these augmentations, i.e. to be invariant to them. However, this only considers one side of the trade-off in the choice of the augmentations: they need to strongly modify the images to avoid simple solution shortcut learning (e.g. using only color histograms), but on the other hand, augmentations-related information may be lacking in the representations for some downstream tasks (e.g. color is important for birds and flower classification). Few recent works proposed to mitigate the problem of using only an invariance task by exploring some form of equivariance to augmentations. This has been performed by learning additional embeddings space(s), where some augmentation(s",
    "link": "http://arxiv.org/abs/2211.01244",
    "context": "Title: EquiMod: An Equivariance Module to Improve Self-Supervised Learning. (arXiv:2211.01244v2 [cs.LG] UPDATED)\nAbstract: Self-supervised visual representation methods are closing the gap with supervised learning performance. These methods rely on maximizing the similarity between embeddings of related synthetic inputs created through data augmentations. This can be seen as a task that encourages embeddings to leave out factors modified by these augmentations, i.e. to be invariant to them. However, this only considers one side of the trade-off in the choice of the augmentations: they need to strongly modify the images to avoid simple solution shortcut learning (e.g. using only color histograms), but on the other hand, augmentations-related information may be lacking in the representations for some downstream tasks (e.g. color is important for birds and flower classification). Few recent works proposed to mitigate the problem of using only an invariance task by exploring some form of equivariance to augmentations. This has been performed by learning additional embeddings space(s), where some augmentation(s",
    "path": "papers/22/11/2211.01244.json",
    "total_tokens": 1210,
    "translated_title": "EquiMod：一种提高自监督学习的等变模块",
    "translated_abstract": "自监督视觉表示方法正在缩小与监督学习性能之间的差距。这些方法依赖于通过数据增强创建的相关合成输入的嵌入之间的相似性最大化。这可以看作是一种鼓励嵌入排除这些增强修改的因素（即对它们具有不变性）的任务。然而，这只考虑了增强选择的权衡中的一侧：它们需要强烈修改图像以避免简单的解决方案（例如仅使用颜色直方图）和同时可能缺乏某些下游任务所需的增强相关信息（例如，对于鸟类和花卉分类，颜色非常重要）。最近的少量研究提出通过探索某种形式的增强等变性来缓解仅使用不变性任务的问题。这是通过学习另外的嵌入空间来完成的，其中一些增强会导致原始和增强嵌入之间的映射。在本文中，我们提出了EquiMod，它是一种等变模块，可插入现有的自监督学习管道中，以改善得到的嵌入的下游性能。我们的模块通过引入一个学习到的转换，将增强的嵌入映射回到它们的底层原始样本，从而促进学习既对某些增强具有不变性又对其他增强具有等变性的嵌入。我们在多个基准数据集上评估了我们的方法，并显示了相对于基线的一致改进。",
    "tldr": "本文提出了一种名为EquiMod的等变模块，通过学习到的转换将增强的嵌入映射回到其底层的原始样本，从而促进学习嵌入的不变性和等变性，从而提高了自监督学习嵌入的下游性能。",
    "en_tdlr": "This paper proposes an equivariance module, called EquiMod, which promotes learning embeddings that are both invariant and equivariant to certain augmentations by introducing a learned transformation that maps augmented embeddings back to their underlying original samples. The method consistently improves downstream performance of self-supervised learning embeddings on multiple benchmark datasets."
}