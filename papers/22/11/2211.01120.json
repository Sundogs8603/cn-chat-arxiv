{
    "title": "Variational Hierarchical Mixtures for Probabilistic Learning of Inverse Dynamics. (arXiv:2211.01120v2 [cs.LG] UPDATED)",
    "abstract": "Well-calibrated probabilistic regression models are a crucial learning component in robotics applications as datasets grow rapidly and tasks become more complex. Unfortunately, classical regression models are usually either probabilistic kernel machines with a flexible structure that does not scale gracefully with data or deterministic and vastly scalable automata, albeit with a restrictive parametric form and poor regularization. In this paper, we consider a probabilistic hierarchical modeling paradigm that combines the benefits of both worlds to deliver computationally efficient representations with inherent complexity regularization. The presented approaches are probabilistic interpretations of local regression techniques that approximate nonlinear functions through a set of local linear or polynomial units. Importantly, we rely on principles from Bayesian nonparametrics to formulate flexible models that adapt their complexity to the data and can potentially encompass an infinite nu",
    "link": "http://arxiv.org/abs/2211.01120",
    "context": "Title: Variational Hierarchical Mixtures for Probabilistic Learning of Inverse Dynamics. (arXiv:2211.01120v2 [cs.LG] UPDATED)\nAbstract: Well-calibrated probabilistic regression models are a crucial learning component in robotics applications as datasets grow rapidly and tasks become more complex. Unfortunately, classical regression models are usually either probabilistic kernel machines with a flexible structure that does not scale gracefully with data or deterministic and vastly scalable automata, albeit with a restrictive parametric form and poor regularization. In this paper, we consider a probabilistic hierarchical modeling paradigm that combines the benefits of both worlds to deliver computationally efficient representations with inherent complexity regularization. The presented approaches are probabilistic interpretations of local regression techniques that approximate nonlinear functions through a set of local linear or polynomial units. Importantly, we rely on principles from Bayesian nonparametrics to formulate flexible models that adapt their complexity to the data and can potentially encompass an infinite nu",
    "path": "papers/22/11/2211.01120.json",
    "total_tokens": 870,
    "translated_title": "可变层次混合模型用于概率逆动力学学习",
    "translated_abstract": "随着数据集的快速增长和任务的复杂化，良好校准的概率回归模型在机器人应用中是至关重要的学习组成部分。不幸的是，经典的回归模型通常要么是具有灵活结构但不随数据优雅扩展的概率核机器，要么是具有限制参数形式和较差正则化的确定性且可扩展的自动机。在本文中，我们考虑了一种概率层次建模范式，将两者的优势结合起来，以提供具有内在复杂性正则化的计算高效的表示。所提出的方法是对局部回归技术的概率解释，通过一组局部线性或多项式单元来逼近非线性函数。重要的是，我们依赖于贝叶斯非参数的原则，构建了适应数据复杂性并且潜在地涵盖无限个模型的灵活模型。",
    "tldr": "本文提出了一种可变层次混合模型方法，通过概率层次化建模来学习机器人应用中的逆动力学。该方法结合了传统回归模型的优势，实现了计算高效的表示和自适应数据复杂性的灵活性。",
    "en_tdlr": "This paper presents a variational hierarchical mixture model for probabilistic learning of inverse dynamics in robotics applications. The proposed approach combines the advantages of classical regression models to achieve computationally efficient representations and adaptability to data complexity."
}