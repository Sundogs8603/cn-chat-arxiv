{
    "title": "Resource frugal optimizer for quantum machine learning. (arXiv:2211.04965v2 [quant-ph] UPDATED)",
    "abstract": "Quantum-enhanced data science, also known as quantum machine learning (QML), is of growing interest as an application of near-term quantum computers. Variational QML algorithms have the potential to solve practical problems on real hardware, particularly when involving quantum data. However, training these algorithms can be challenging and calls for tailored optimization procedures. Specifically, QML applications can require a large shot-count overhead due to the large datasets involved. In this work, we advocate for simultaneous random sampling over both the dataset as well as the measurement operators that define the loss function. We consider a highly general loss function that encompasses many QML applications, and we show how to construct an unbiased estimator of its gradient. This allows us to propose a shot-frugal gradient descent optimizer called Refoqus (REsource Frugal Optimizer for QUantum Stochastic gradient descent). Our numerics indicate that Refoqus can save several orde",
    "link": "http://arxiv.org/abs/2211.04965",
    "context": "Title: Resource frugal optimizer for quantum machine learning. (arXiv:2211.04965v2 [quant-ph] UPDATED)\nAbstract: Quantum-enhanced data science, also known as quantum machine learning (QML), is of growing interest as an application of near-term quantum computers. Variational QML algorithms have the potential to solve practical problems on real hardware, particularly when involving quantum data. However, training these algorithms can be challenging and calls for tailored optimization procedures. Specifically, QML applications can require a large shot-count overhead due to the large datasets involved. In this work, we advocate for simultaneous random sampling over both the dataset as well as the measurement operators that define the loss function. We consider a highly general loss function that encompasses many QML applications, and we show how to construct an unbiased estimator of its gradient. This allows us to propose a shot-frugal gradient descent optimizer called Refoqus (REsource Frugal Optimizer for QUantum Stochastic gradient descent). Our numerics indicate that Refoqus can save several orde",
    "path": "papers/22/11/2211.04965.json",
    "total_tokens": 832,
    "translated_title": "资源节约的量子机器学习优化器",
    "translated_abstract": "量子增强的数据科学，也称为量子机器学习（QML），作为近期量子计算机的应用越来越受关注。变分QML算法在涉及量子数据时有能力解决实际问题。然而，训练这些算法可能具有挑战性，并需要定制的优化程序。具体而言，QML应用可能需要大量的采样次数，因为涉及大型数据集。在这项工作中，我们提倡对数据集和定义损失函数的测量操作进行同时随机采样。我们考虑了一个高度通用的损失函数，包括了许多QML应用，并展示了如何构建其梯度的无偏估计器。这使我们能够提出一种称为Refoqus（资源节约的量子随机梯度下降优化器）的节约采样梯度下降优化器。我们的数值结果表明，Refoqus能够节省几个数量级的资源。",
    "tldr": "提出了一种名为Refoqus的资源节约的量子随机梯度下降优化器，通过同时随机采样数据集和测量操作，能够保存大量资源。",
    "en_tdlr": "Proposed a resource-frugal quantum stochastic gradient descent optimizer called Refoqus, which saves significant resources by simultaneously sampling the dataset and measurement operators."
}