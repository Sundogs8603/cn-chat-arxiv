{
    "title": "Shape, Pose, and Appearance from a Single Image via Bootstrapped Radiance Field Inversion. (arXiv:2211.11674v2 [cs.CV] UPDATED)",
    "abstract": "Neural Radiance Fields (NeRF) coupled with GANs represent a promising direction in the area of 3D reconstruction from a single view, owing to their ability to efficiently model arbitrary topologies. Recent work in this area, however, has mostly focused on synthetic datasets where exact ground-truth poses are known, and has overlooked pose estimation, which is important for certain downstream applications such as augmented reality (AR) and robotics. We introduce a principled end-to-end reconstruction framework for natural images, where accurate ground-truth poses are not available. Our approach recovers an SDF-parameterized 3D shape, pose, and appearance from a single image of an object, without exploiting multiple views during training. More specifically, we leverage an unconditional 3D-aware generator, to which we apply a hybrid inversion scheme where a model produces a first guess of the solution which is then refined via optimization. Our framework can de-render an image in as few a",
    "link": "http://arxiv.org/abs/2211.11674",
    "context": "Title: Shape, Pose, and Appearance from a Single Image via Bootstrapped Radiance Field Inversion. (arXiv:2211.11674v2 [cs.CV] UPDATED)\nAbstract: Neural Radiance Fields (NeRF) coupled with GANs represent a promising direction in the area of 3D reconstruction from a single view, owing to their ability to efficiently model arbitrary topologies. Recent work in this area, however, has mostly focused on synthetic datasets where exact ground-truth poses are known, and has overlooked pose estimation, which is important for certain downstream applications such as augmented reality (AR) and robotics. We introduce a principled end-to-end reconstruction framework for natural images, where accurate ground-truth poses are not available. Our approach recovers an SDF-parameterized 3D shape, pose, and appearance from a single image of an object, without exploiting multiple views during training. More specifically, we leverage an unconditional 3D-aware generator, to which we apply a hybrid inversion scheme where a model produces a first guess of the solution which is then refined via optimization. Our framework can de-render an image in as few a",
    "path": "papers/22/11/2211.11674.json",
    "total_tokens": 1115,
    "translated_title": "通过自回归光场反演从单张图像中重构形状、姿态和外观",
    "translated_abstract": "组合神经辐射场 (NeRF) 和生成对抗网络 (GAN) 在从单视角进行三维重建方面展现出了很好的潜力，因为它们能够有效地建模任意拓扑结构。然而，最近该领域的工作主要集中在合成数据集上，其中确切的地面真实姿势是已知的，并忽略了姿势估计，而姿势估计是某些下游应用，如增强现实 (AR) 和机器人技术中的关键问题。本文提出了一种自然图像的有原则的端到端重建框架，其中准确的真实姿势是不可用的。我们的方法从一个物体的单个图像中恢复了 SDF 参数化的 3D 形状、姿态和外观，而没有在训练过程中利用多个视角。具体来说，我们利用了一个无条件的 3D-aware 生成器，对其应用了混合反演方案，其中一个模型产生了解的第一个猜测，然后通过优化进行改进。我们的框架可以在一次前向传递中对图像进行去渲染，因此速度快且计算有效。我们证明了我们的方法在 DTU 和 Tanks & Temples 等基准测试中优于现有最先进技术，并证明了在真实世界图像上的有效性。",
    "tldr": "本文提出了一个自回归光场反演框架，可以从单个图像中恢复 SDF 参数化的 3D 形状、姿态和外观，而无需准确的真实姿势，且速度快、计算有效。",
    "en_tdlr": "This paper proposes a bootstrapped radiance field inversion framework that can recover SDF-parameterized 3D shape, pose, and appearance from a single image without relying on accurate ground-truth poses, and is fast and computationally efficient. The method outperforms state-of-the-art on benchmarks such as the DTU and Tanks & Temples datasets, and is effective on real-world images."
}