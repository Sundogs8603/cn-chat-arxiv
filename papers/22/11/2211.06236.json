{
    "title": "Efficient Deep Reinforcement Learning with Predictive Processing Proximal Policy Optimization. (arXiv:2211.06236v2 [cs.LG] UPDATED)",
    "abstract": "Advances in reinforcement learning (RL) often rely on massive compute resources and remain notoriously sample inefficient. In contrast, the human brain is able to efficiently learn effective control strategies using limited resources. This raises the question whether insights from neuroscience can be used to improve current RL methods. Predictive processing is a popular theoretical framework which maintains that the human brain is actively seeking to minimize surprise. We show that recurrent neural networks which predict their own sensory states can be leveraged to minimise surprise, yielding substantial gains in cumulative reward. Specifically, we present the Predictive Processing Proximal Policy Optimization (P4O) agent; an actor-critic reinforcement learning agent that applies predictive processing to a recurrent variant of the PPO algorithm by integrating a world model in its hidden state. Even without hyperparameter tuning, P4O significantly outperforms a baseline recurrent varian",
    "link": "http://arxiv.org/abs/2211.06236",
    "context": "Title: Efficient Deep Reinforcement Learning with Predictive Processing Proximal Policy Optimization. (arXiv:2211.06236v2 [cs.LG] UPDATED)\nAbstract: Advances in reinforcement learning (RL) often rely on massive compute resources and remain notoriously sample inefficient. In contrast, the human brain is able to efficiently learn effective control strategies using limited resources. This raises the question whether insights from neuroscience can be used to improve current RL methods. Predictive processing is a popular theoretical framework which maintains that the human brain is actively seeking to minimize surprise. We show that recurrent neural networks which predict their own sensory states can be leveraged to minimise surprise, yielding substantial gains in cumulative reward. Specifically, we present the Predictive Processing Proximal Policy Optimization (P4O) agent; an actor-critic reinforcement learning agent that applies predictive processing to a recurrent variant of the PPO algorithm by integrating a world model in its hidden state. Even without hyperparameter tuning, P4O significantly outperforms a baseline recurrent varian",
    "path": "papers/22/11/2211.06236.json",
    "total_tokens": 919,
    "translated_title": "高效的深度强化学习与预测处理近端策略优化",
    "translated_abstract": "强化学习的进步常常依赖于大量的计算资源，且在样本效率上仍然不高。相比之下，人类大脑能够使用有限的资源有效地学习控制策略。这引发了一个问题，即是否可以借鉴神经科学的见解来改进当前的强化学习方法。预测处理是一个流行的理论框架，它认为人类大脑主动寻求最小化惊异。我们展示了能够预测自身感觉状态的递归神经网络可以被利用来最小化惊异，从而在累积奖励上取得巨大的收益。具体而言，我们提出了预测处理近端策略优化（P4O）智能体；它是一个将预测处理应用到基于递归的PPO算法的演员批判强化学习智能体，通过将世界模型集成到其隐藏状态中。即使没有超参数调整，P4O与基线递归变体相比，也能显著提高性能。",
    "tldr": "该论文介绍了一种名为预测处理近端策略优化（P4O）的深度强化学习方法，通过利用递归神经网络预测自身感觉状态来最小化惊异，从而显著提高累积奖励。",
    "en_tdlr": "This paper introduces an efficient deep reinforcement learning method called Predictive Processing Proximal Policy Optimization (P4O), which utilizes recurrent neural networks to predict sensory states and minimize surprise, resulting in substantial gains in cumulative reward."
}