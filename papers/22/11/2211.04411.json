{
    "title": "Motif-guided Time Series Counterfactual Explanations",
    "abstract": "With the rising need of interpretable machine learning methods, there is a necessity for a rise in human effort to provide diverse explanations of the influencing factors of the model decisions. To improve the trust and transparency of AI-based systems, the EXplainable Artificial Intelligence (XAI) field has emerged. The XAI paradigm is bifurcated into two main categories: feature attribution and counterfactual explanation methods. While feature attribution methods are based on explaining the reason behind a model decision, counterfactual explanation methods discover the smallest input changes that will result in a different decision. In this paper, we aim at building trust and transparency in time series models by using motifs to generate counterfactual explanations. We propose Motif-Guided Counterfactual Explanation (MG-CF), a novel model that generates intuitive post-hoc counterfactual explanations that make full use of important motifs to provide interpretive information in decisio",
    "link": "https://rss.arxiv.org/abs/2211.04411",
    "context": "Title: Motif-guided Time Series Counterfactual Explanations\nAbstract: With the rising need of interpretable machine learning methods, there is a necessity for a rise in human effort to provide diverse explanations of the influencing factors of the model decisions. To improve the trust and transparency of AI-based systems, the EXplainable Artificial Intelligence (XAI) field has emerged. The XAI paradigm is bifurcated into two main categories: feature attribution and counterfactual explanation methods. While feature attribution methods are based on explaining the reason behind a model decision, counterfactual explanation methods discover the smallest input changes that will result in a different decision. In this paper, we aim at building trust and transparency in time series models by using motifs to generate counterfactual explanations. We propose Motif-Guided Counterfactual Explanation (MG-CF), a novel model that generates intuitive post-hoc counterfactual explanations that make full use of important motifs to provide interpretive information in decisio",
    "path": "papers/22/11/2211.04411.json",
    "total_tokens": 814,
    "translated_title": "基于图案的时间序列对抗性解释",
    "translated_abstract": "随着对可解释的机器学习方法的需求增加，有必要增加人类工作量来提供模型决策的不同影响因素的多样化解释。为了提高AI系统的信任和透明性，可解释的人工智能（XAI）领域应运而生。XAI范式分为两大类：特征归因和对抗性解释方法。特征归因方法基于解释模型决策的原因，而对抗性解释方法发现最小的输入变化将导致不同的决策。本文旨在通过使用图案来生成对抗性解释，从而在时间序列模型中建立信任和透明度。我们提出了一种新颖的模型Motif-Guided Counterfactual Explanation（MG-CF），它生成直观的事后对抗性解释，充分利用重要的图案提供决策的解释信息。",
    "tldr": "本论文提出了一种基于图案的时间序列对抗性解释方法（MG-CF），通过利用重要的图案来生成直观的解释信息，以提高时间序列模型的信任和透明度。"
}