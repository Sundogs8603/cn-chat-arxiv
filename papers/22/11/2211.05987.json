{
    "title": "CCPrefix: Counterfactual Contrastive Prefix-Tuning for Many-Class Classification",
    "abstract": "Recently, prefix-tuning was proposed to efficiently adapt pre-trained language models to a broad spectrum of natural language classification tasks. It leverages soft prefix as task-specific indicators and language verbalizers as categorical-label mentions to narrow the formulation gap from pre-training language models. However, when the label space increases considerably (i.e., many-class classification), such a tuning technique suffers from a verbalizer ambiguity problem since the many-class labels are represented by semantic-similar verbalizers in short language phrases. To overcome this, inspired by the human-decision process that the most ambiguous classes would be mulled over for each instance, we propose a brand-new prefix-tuning method, Counterfactual Contrastive Prefix-tuning (CCPrefix), for many-class classification. Basically, an instance-dependent soft prefix, derived from fact-counterfactual pairs in the label space, is leveraged to complement the language verbalizers in ma",
    "link": "https://arxiv.org/abs/2211.05987",
    "context": "Title: CCPrefix: Counterfactual Contrastive Prefix-Tuning for Many-Class Classification\nAbstract: Recently, prefix-tuning was proposed to efficiently adapt pre-trained language models to a broad spectrum of natural language classification tasks. It leverages soft prefix as task-specific indicators and language verbalizers as categorical-label mentions to narrow the formulation gap from pre-training language models. However, when the label space increases considerably (i.e., many-class classification), such a tuning technique suffers from a verbalizer ambiguity problem since the many-class labels are represented by semantic-similar verbalizers in short language phrases. To overcome this, inspired by the human-decision process that the most ambiguous classes would be mulled over for each instance, we propose a brand-new prefix-tuning method, Counterfactual Contrastive Prefix-tuning (CCPrefix), for many-class classification. Basically, an instance-dependent soft prefix, derived from fact-counterfactual pairs in the label space, is leveraged to complement the language verbalizers in ma",
    "path": "papers/22/11/2211.05987.json",
    "total_tokens": 811,
    "translated_title": "CCPrefix:反事实对比前缀调整用于多类分类",
    "translated_abstract": "最近，提出了前缀调整以有效地将预训练语言模型适应广泛的自然语言分类任务。它利用软前缀作为任务特定的指示器和语言表示器作为分类标签的提及，以减少从预训练语言模型到特定任务的差异。然而，当标签空间大幅增加时（即多类分类），这种调整技术会面临语言表示器模糊性问题，因为短语言短句中的类别标签由语义相似的语言表示器表示。为了克服这个问题，受人类决策过程的启发，即每个实例都会考虑最模糊的类别，我们提出了全新的前缀调整方法，即反事实对比前缀调整方法（CCPrefix），用于多类分类。基本上，我们利用标签空间中的事实-反事实对来得到依赖于实例的软前缀，以补充语言表示器。",
    "tldr": "CCPrefix是一种针对多类分类的新型前缀调整方法，利用反事实对比来解决语言表示器模糊性问题。",
    "en_tdlr": "CCPrefix is a novel prefix-tuning method for many-class classification that addresses the problem of verbalizer ambiguity by leveraging counterfactual contrast and instance-dependent soft prefixes."
}