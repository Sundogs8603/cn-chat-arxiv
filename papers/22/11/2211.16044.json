{
    "title": "Model Extraction Attack against Self-supervised Speech Models. (arXiv:2211.16044v2 [cs.SD] UPDATED)",
    "abstract": "Self-supervised learning (SSL) speech models generate meaningful representations of given clips and achieve incredible performance across various downstream tasks. Model extraction attack (MEA) often refers to an adversary stealing the functionality of the victim model with only query access. In this work, we study the MEA problem against SSL speech model with a small number of queries. We propose a two-stage framework to extract the model. In the first stage, SSL is conducted on the large-scale unlabeled corpus to pre-train a small speech model. Secondly, we actively sample a small portion of clips from the unlabeled corpus and query the target model with these clips to acquire their representations as labels for the small model's second-stage training. Experiment results show that our sampling methods can effectively extract the target model without knowing any information about its model architecture.",
    "link": "http://arxiv.org/abs/2211.16044",
    "context": "Title: Model Extraction Attack against Self-supervised Speech Models. (arXiv:2211.16044v2 [cs.SD] UPDATED)\nAbstract: Self-supervised learning (SSL) speech models generate meaningful representations of given clips and achieve incredible performance across various downstream tasks. Model extraction attack (MEA) often refers to an adversary stealing the functionality of the victim model with only query access. In this work, we study the MEA problem against SSL speech model with a small number of queries. We propose a two-stage framework to extract the model. In the first stage, SSL is conducted on the large-scale unlabeled corpus to pre-train a small speech model. Secondly, we actively sample a small portion of clips from the unlabeled corpus and query the target model with these clips to acquire their representations as labels for the small model's second-stage training. Experiment results show that our sampling methods can effectively extract the target model without knowing any information about its model architecture.",
    "path": "papers/22/11/2211.16044.json",
    "total_tokens": 924,
    "translated_title": "针对自监督语音模型的模型提取攻击",
    "translated_abstract": "自监督学习（SSL）语音模型能够生成给定片段的有意义表示，并在各种下游任务中取得令人难以置信的性能。模型提取攻击（MEA）通常指的是攻击者仅通过查询访问就能窃取受害模型的功能。在本研究中，我们研究了在仅有少量查询的情况下针对SSL语音模型的MEA问题。我们提出了一个两阶段的框架来提取模型。在第一阶段，我们对大规模未标注语料库进行SSL预训练，得到一个小的语音模型。然后，我们主动从未标注语料库中抽样一小部分片段，并用这些片段向目标模型进行查询，以获得它们的表示作为小模型第二阶段训练的标签。实验结果表明，我们的抽样方法可以有效提取目标模型，而无需知道其任何有关模型架构的信息。",
    "tldr": "本研究针对自监督语音模型提出了一种模型提取攻击方法，通过仅使用少量查询访问，可以窃取目标模型的功能。通过两个阶段的框架，我们可以在大规模未标注语料库上进行自监督预训练，然后使用主动抽样和查询的方式提取目标模型，而无需了解其模型架构。",
    "en_tdlr": "We propose a model extraction attack method against self-supervised speech models, which allows stealing the functionality of the target model with only a small number of queries. By utilizing a two-stage framework, we perform self-supervised pre-training on a large-scale unlabeled corpus and actively sample and query the target model to extract its functionality without knowing its model architecture."
}