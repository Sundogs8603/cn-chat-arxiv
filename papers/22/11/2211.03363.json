{
    "title": "Over-The-Air Clustered Wireless Federated Learning. (arXiv:2211.03363v3 [cs.LG] UPDATED)",
    "abstract": "Privacy and bandwidth constraints have led to the use of federated learning (FL) in wireless systems, where training a machine learning (ML) model is accomplished collaboratively without sharing raw data. While using bandwidth-constrained uplink wireless channels, over-the-air (OTA) FL is preferred since the clients can transmit parameter updates simultaneously to a server. A powerful server may not be available for parameter aggregation due to increased latency and server failures. In the absence of a powerful server, decentralised strategy is employed where clients communicate with their neighbors to obtain a consensus ML model while incurring huge communication cost. In this work, we propose the OTA semi-decentralised clustered wireless FL (CWFL) and CWFL-Prox algorithms, which is communication efficient as compared to the decentralised FL strategy, while the parameter updates converge to global minima as O(1/T) for each cluster. Using the MNIST and CIFAR10 datasets, we demonstrate ",
    "link": "http://arxiv.org/abs/2211.03363",
    "context": "Title: Over-The-Air Clustered Wireless Federated Learning. (arXiv:2211.03363v3 [cs.LG] UPDATED)\nAbstract: Privacy and bandwidth constraints have led to the use of federated learning (FL) in wireless systems, where training a machine learning (ML) model is accomplished collaboratively without sharing raw data. While using bandwidth-constrained uplink wireless channels, over-the-air (OTA) FL is preferred since the clients can transmit parameter updates simultaneously to a server. A powerful server may not be available for parameter aggregation due to increased latency and server failures. In the absence of a powerful server, decentralised strategy is employed where clients communicate with their neighbors to obtain a consensus ML model while incurring huge communication cost. In this work, we propose the OTA semi-decentralised clustered wireless FL (CWFL) and CWFL-Prox algorithms, which is communication efficient as compared to the decentralised FL strategy, while the parameter updates converge to global minima as O(1/T) for each cluster. Using the MNIST and CIFAR10 datasets, we demonstrate ",
    "path": "papers/22/11/2211.03363.json",
    "total_tokens": 833,
    "translated_title": "无线群集化联邦学习中的空中聚合",
    "translated_abstract": "隐私和带宽限制导致在无线系统中使用联邦学习（FL），即在不共享原始数据的情况下协作进行机器学习（ML）模型训练。使用带宽受限的上行无线信道时，空中（OTA）FL更受青睐，因为客户端可以同时向服务器传输参数更新。由于延迟增加和服务器故障，可能无法使用强大的服务器进行参数聚合。在没有强大服务器的情况下，采用分散策略，即客户端与其邻居通信，以获得共识ML模型，但通信成本巨大。在这项工作中，我们提出了OTA半分散群集无线FL（CWFL）和CWFL-Prox算法，与分散FL策略相比，该算法具有较高的通信效率，同时参数更新收敛于全局极小值，每个聚类的收敛速度为O（1/T）。使用MNIST和CIFAR10数据集，我们证明了...",
    "tldr": "本论文提出了一种OTA半分散群集无线FL（CWFL）和CWFL-Prox算法，它在通信效率上优于分散FL策略，同时参数更新收敛到全局极小值。"
}