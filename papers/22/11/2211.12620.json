{
    "title": "Promises and Pitfalls of Threshold-based Auto-labeling",
    "abstract": "arXiv:2211.12620v2 Announce Type: replace-cross  Abstract: Creating large-scale high-quality labeled datasets is a major bottleneck in supervised machine learning workflows. Threshold-based auto-labeling (TBAL), where validation data obtained from humans is used to find a confidence threshold above which the data is machine-labeled, reduces reliance on manual annotation. TBAL is emerging as a widely-used solution in practice. Given the long shelf-life and diverse usage of the resulting datasets, understanding when the data obtained by such auto-labeling systems can be relied on is crucial. This is the first work to analyze TBAL systems and derive sample complexity bounds on the amount of human-labeled validation data required for guaranteeing the quality of machine-labeled data. Our results provide two crucial insights. First, reasonable chunks of unlabeled data can be automatically and accurately labeled by seemingly bad models. Second, a hidden downside of TBAL systems is potentially",
    "link": "https://arxiv.org/abs/2211.12620",
    "context": "Title: Promises and Pitfalls of Threshold-based Auto-labeling\nAbstract: arXiv:2211.12620v2 Announce Type: replace-cross  Abstract: Creating large-scale high-quality labeled datasets is a major bottleneck in supervised machine learning workflows. Threshold-based auto-labeling (TBAL), where validation data obtained from humans is used to find a confidence threshold above which the data is machine-labeled, reduces reliance on manual annotation. TBAL is emerging as a widely-used solution in practice. Given the long shelf-life and diverse usage of the resulting datasets, understanding when the data obtained by such auto-labeling systems can be relied on is crucial. This is the first work to analyze TBAL systems and derive sample complexity bounds on the amount of human-labeled validation data required for guaranteeing the quality of machine-labeled data. Our results provide two crucial insights. First, reasonable chunks of unlabeled data can be automatically and accurately labeled by seemingly bad models. Second, a hidden downside of TBAL systems is potentially",
    "path": "papers/22/11/2211.12620.json",
    "total_tokens": 854,
    "translated_title": "基于阈值的自动标注的优势与局限性",
    "translated_abstract": "创建大规模高质量标记数据集是监督机器学习工作流程中的一个主要瓶颈。阈值自动标注（TBAL）通过使用人类获取的验证数据来寻找一个置信阈值，高于该阈值的数据将由机器标记，从而减少了对手动注释的依赖。TBAL正逐渐成为实践中被广泛采用的解决方案。鉴于所得数据的长期有效性和多样化使用，理解这种自动标注系统获取的数据何时可以被依赖是至关重要的。这是第一项分析TBAL系统并推导需要保证机器标记数据质量的人工标记验证数据量样本复杂性界限的工作。我们的结果提供了两个关键见解。首先，表面上糟糕的模型可以自动、准确地标记合理数量的未标记数据。其次，TBAL系统的一个隐藏的缺点是潜在地",
    "tldr": "TBAL系统可以通过验证数据自动标注未标注数据，减少手动标注的依赖；研究结果展示了即使模型表现不佳也可以准确自动标记数据，并揭示了TBAL系统的潜在缺陷",
    "en_tdlr": "TBAL systems can automatically label unlabeled data using validation data, reducing reliance on manual annotation; research shows that even seemingly bad models can accurately auto-label data, and reveals the potential pitfalls of TBAL systems."
}