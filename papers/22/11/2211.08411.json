{
    "title": "Large Language Models Struggle to Learn Long-Tail Knowledge. (arXiv:2211.08411v2 [cs.CL] UPDATED)",
    "abstract": "The Internet contains a wealth of knowledge -- from the birthdays of historical figures to tutorials on how to code -- all of which may be learned by language models. However, while certain pieces of information are ubiquitous on the web, others appear extremely rarely. In this paper, we study the relationship between the knowledge memorized by large language models and the information in pre-training datasets scraped from the web. In particular, we show that a language model's ability to answer a fact-based question relates to how many documents associated with that question were seen during pre-training. We identify these relevant documents by entity linking pre-training datasets and counting documents that contain the same entities as a given question-answer pair. Our results demonstrate strong correlational and causal relationships between accuracy and relevant document count for numerous question answering datasets (e.g., TriviaQA), pre-training corpora (e.g., ROOTS), and model si",
    "link": "http://arxiv.org/abs/2211.08411",
    "context": "Title: Large Language Models Struggle to Learn Long-Tail Knowledge. (arXiv:2211.08411v2 [cs.CL] UPDATED)\nAbstract: The Internet contains a wealth of knowledge -- from the birthdays of historical figures to tutorials on how to code -- all of which may be learned by language models. However, while certain pieces of information are ubiquitous on the web, others appear extremely rarely. In this paper, we study the relationship between the knowledge memorized by large language models and the information in pre-training datasets scraped from the web. In particular, we show that a language model's ability to answer a fact-based question relates to how many documents associated with that question were seen during pre-training. We identify these relevant documents by entity linking pre-training datasets and counting documents that contain the same entities as a given question-answer pair. Our results demonstrate strong correlational and causal relationships between accuracy and relevant document count for numerous question answering datasets (e.g., TriviaQA), pre-training corpora (e.g., ROOTS), and model si",
    "path": "papers/22/11/2211.08411.json",
    "total_tokens": 887,
    "translated_title": "大型语言模型在学习长尾知识方面存在困难",
    "translated_abstract": "互联网中包含着丰富的知识，从历史人物的生日到编程教程等，所有这些都可以由语言模型学习。然而，尽管某些信息在网上无处不在，但其他信息的出现非常罕见。在本文中，我们研究了大型语言模型记忆的知识与从网络抓取的预训练数据集中的信息之间的关系。特别是，我们展示了语言模型回答基于事实的问题的能力与在预训练过程中看到与此问题相关的文档数量之间的关系。我们通过实体链接预训练数据集并计算包含与给定问题-答案对相同实体的文档数量来识别这些相关文档。我们的结果表明，在众多问答数据集（例如 TriviaQA）、预训练语料库（例如 ROOTS）和模型上，准确性与相关文档数量之间存在着强相关性和因果关系。",
    "tldr": "本文研究了大型语言模型记忆的知识与预训练数据集中信息之间的关系，并发现其回答基于事实的问题的能力与在预训练过程中接触到的相关文档数量之间存在强相关性和因果关系。"
}