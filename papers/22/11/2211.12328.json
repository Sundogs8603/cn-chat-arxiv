{
    "title": "A survey on knowledge-enhanced multimodal learning",
    "abstract": "arXiv:2211.12328v3 Announce Type: replace-cross  Abstract: Multimodal learning has been a field of increasing interest, aiming to combine various modalities in a single joint representation. Especially in the area of visiolinguistic (VL) learning multiple models and techniques have been developed, targeting a variety of tasks that involve images and text. VL models have reached unprecedented performances by extending the idea of Transformers, so that both modalities can learn from each other. Massive pre-training procedures enable VL models to acquire a certain level of real-world understanding, although many gaps can be identified: the limited comprehension of commonsense, factual, temporal and other everyday knowledge aspects questions the extendability of VL tasks. Knowledge graphs and other knowledge sources can fill those gaps by explicitly providing missing information, unlocking novel capabilities of VL models. In the same time, knowledge graphs enhance explainability, fairness ",
    "link": "https://arxiv.org/abs/2211.12328",
    "context": "Title: A survey on knowledge-enhanced multimodal learning\nAbstract: arXiv:2211.12328v3 Announce Type: replace-cross  Abstract: Multimodal learning has been a field of increasing interest, aiming to combine various modalities in a single joint representation. Especially in the area of visiolinguistic (VL) learning multiple models and techniques have been developed, targeting a variety of tasks that involve images and text. VL models have reached unprecedented performances by extending the idea of Transformers, so that both modalities can learn from each other. Massive pre-training procedures enable VL models to acquire a certain level of real-world understanding, although many gaps can be identified: the limited comprehension of commonsense, factual, temporal and other everyday knowledge aspects questions the extendability of VL tasks. Knowledge graphs and other knowledge sources can fill those gaps by explicitly providing missing information, unlocking novel capabilities of VL models. In the same time, knowledge graphs enhance explainability, fairness ",
    "path": "papers/22/11/2211.12328.json",
    "total_tokens": 809,
    "translated_title": "知识增强多模态学习综述",
    "translated_abstract": "多模态学习是一个越来越受关注的领域，旨在将各种模态结合成一个联合表示。特别是在视觉语言学习领域，已经开发出多种模型和技术，针对涉及图像和文本的各种任务。VL模型通过扩展Transformer的思想，使得两种模态可以相互学习，已经达到了前所未有的性能。大规模的预训练程序使得VL模型能够获得一定水平的现实世界理解，尽管仍然存在许多差距：对常识、事实、时间和其他日常知识方面的限制理解，对VL任务的可扩展性提出了质疑。知识图和其他知识来源可以通过明确提供缺失信息来填补这些差距，解锁VL模型的新能力。同时，知识图增强了可解释性、公平性。",
    "tldr": "知识图和其他知识来源填补了视觉语言学习模型在日常知识理解方面的差距，提升了模型的性能和可解释性。",
    "en_tdlr": "Knowledge graphs and other knowledge sources fill the gaps in visiolinguistic models' understanding of everyday knowledge, enhancing the performance and explainability of the models."
}