{
    "title": "Combating noisy labels in object detection datasets. (arXiv:2211.13993v2 [cs.CV] UPDATED)",
    "abstract": "The quality of training datasets for deep neural networks is a key factor contributing to the accuracy of resulting models. This effect is amplified in difficult tasks such as object detection. Dealing with errors in datasets is often limited to accepting that some fraction of examples is incorrect, estimating their confidence and assigning appropriate weights or ignoring uncertain ones during training. In this work, we propose a different approach. We introduce the Confident Learning for Object Detection (CLOD) algorithm for assessing the quality of each label in object detection datasets, identifying missing, spurious, mislabeled and mislocated bounding boxes and suggesting corrections. By focusing on finding incorrect examples in the training datasets, we can eliminate them at the root. Suspicious bounding boxes can be reviewed in order to improve the quality of the dataset, leading to better models without further complicating their already complex architectures. The proposed metho",
    "link": "http://arxiv.org/abs/2211.13993",
    "context": "Title: Combating noisy labels in object detection datasets. (arXiv:2211.13993v2 [cs.CV] UPDATED)\nAbstract: The quality of training datasets for deep neural networks is a key factor contributing to the accuracy of resulting models. This effect is amplified in difficult tasks such as object detection. Dealing with errors in datasets is often limited to accepting that some fraction of examples is incorrect, estimating their confidence and assigning appropriate weights or ignoring uncertain ones during training. In this work, we propose a different approach. We introduce the Confident Learning for Object Detection (CLOD) algorithm for assessing the quality of each label in object detection datasets, identifying missing, spurious, mislabeled and mislocated bounding boxes and suggesting corrections. By focusing on finding incorrect examples in the training datasets, we can eliminate them at the root. Suspicious bounding boxes can be reviewed in order to improve the quality of the dataset, leading to better models without further complicating their already complex architectures. The proposed metho",
    "path": "papers/22/11/2211.13993.json",
    "total_tokens": 1007,
    "translated_title": "在目标检测数据集中解决标注噪声",
    "translated_abstract": "深度神经网络的训练数据集的质量是影响模型准确性的关键因素，特别是在像目标检测这样的困难任务中。在处理数据集中的错误时，通常会接受一定比例的错误样本，估算它们的置信度并在训练过程中赋予适当的权重，或者忽略不确定的样本。本文提出了一种名为“Confident Learning for Object Detection”（CLOD）的算法，用于评估目标检测数据集中每个标签的质量，识别缺失、虚假、标签错误和位置错误的边界框，并建议纠正方法。通过专注于找到训练数据集中的错误示例，我们可以从根本上消除它们。可疑的边界框可以进行检查，以提高数据集的质量，从而在不进一步复杂化复杂架构的情况下提高模型的准确性。该方法在错误校正方面提供了最先进的性能，并在存在大量噪声的情况下显著提高了模型的准确性。",
    "tldr": "本文提出了一种名为CLOD的算法，用于评估目标检测数据集中每个标签的质量，识别和纠正缺失、虚假、标签错误和位置错误的边界框，从而消除训练数据集中的错误示例，提高数据集的质量，并在存在大量噪声的情况下显著提高模型的准确性。",
    "en_tdlr": "This paper proposes a CLOD algorithm for assessing the quality of each label in object detection datasets, identifying and correcting missing, spurious, mislabeled, and mislocated bounding boxes, eliminating errors in the training dataset, improving dataset quality, and significantly improving model accuracy, especially in the presence of large amounts of noise."
}