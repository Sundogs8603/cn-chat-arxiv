{
    "title": "Dynamic Loss For Robust Learning. (arXiv:2211.12506v2 [cs.LG] UPDATED)",
    "abstract": "Label noise and class imbalance commonly coexist in real-world data. Previous works for robust learning, however, usually address either one type of the data biases and underperform when facing them both. To mitigate this gap, this work presents a novel meta-learning based dynamic loss that automatically adjusts the objective functions with the training process to robustly learn a classifier from long-tailed noisy data. Concretely, our dynamic loss comprises a label corrector and a margin generator, which respectively correct noisy labels and generate additive per-class classification margins by perceiving the underlying data distribution as well as the learning state of the classifier. Equipped with a new hierarchical sampling strategy that enriches a small amount of unbiased metadata with diverse and hard samples, the two components in the dynamic loss are optimized jointly through meta-learning and cultivate the classifier to well adapt to clean and balanced test data. Extensive exp",
    "link": "http://arxiv.org/abs/2211.12506",
    "context": "Title: Dynamic Loss For Robust Learning. (arXiv:2211.12506v2 [cs.LG] UPDATED)\nAbstract: Label noise and class imbalance commonly coexist in real-world data. Previous works for robust learning, however, usually address either one type of the data biases and underperform when facing them both. To mitigate this gap, this work presents a novel meta-learning based dynamic loss that automatically adjusts the objective functions with the training process to robustly learn a classifier from long-tailed noisy data. Concretely, our dynamic loss comprises a label corrector and a margin generator, which respectively correct noisy labels and generate additive per-class classification margins by perceiving the underlying data distribution as well as the learning state of the classifier. Equipped with a new hierarchical sampling strategy that enriches a small amount of unbiased metadata with diverse and hard samples, the two components in the dynamic loss are optimized jointly through meta-learning and cultivate the classifier to well adapt to clean and balanced test data. Extensive exp",
    "path": "papers/22/11/2211.12506.json",
    "total_tokens": 969,
    "translated_title": "动态损失用于鲁棒学习",
    "translated_abstract": "实际数据中常常存在标签噪声和类别不平衡。然而，先前的鲁棒学习方法通常只针对其中一种数据偏差并在同时遇到两种偏差时表现不佳。为了弥补这一差距，本文提出了一种基于元学习的动态损失函数，通过训练过程自动调整目标函数，从长尾噪声数据中鲁棒地学习分类器。具体来说，我们的动态损失由一个标签修正器和一个边界生成器组成，分别通过感知底层数据分布和分类器的学习状态来纠正噪声标签和生成每个类别的添加性分类边界。通过一种新的分层采样策略，在少量无偏元数据中丰富多样且困难的样本，动态损失中的两个组件通过元学习联合优化，并培养分类器以适应干净且平衡的测试数据。",
    "tldr": "本文提出了一种动态损失函数用于鲁棒学习，通过自动调整目标函数的方式从长尾噪声数据中学习分类器。动态损失包括标签修正器和边界生成器，能够纠正噪声标签并生成每个类别的分类边界，通过元学习来优化这两个组件，使分类器适应干净且平衡的测试数据。"
}