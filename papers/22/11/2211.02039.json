{
    "title": "The Projected Covariance Measure for assumption-lean variable significance testing. (arXiv:2211.02039v2 [math.ST] UPDATED)",
    "abstract": "Testing the significance of a variable or group of variables $X$ for predicting a response $Y$, given additional covariates $Z$, is a ubiquitous task in statistics. A simple but common approach is to specify a linear model, and then test whether the regression coefficient for $X$ is non-zero. However, when the model is misspecified, the test may have poor power, for example when $X$ is involved in complex interactions, or lead to many false rejections. In this work we study the problem of testing the model-free null of conditional mean independence, i.e. that the conditional mean of $Y$ given $X$ and $Z$ does not depend on $X$. We propose a simple and general framework that can leverage flexible nonparametric or machine learning methods, such as additive models or random forests, to yield both robust error control and high power. The procedure involves using these methods to perform regressions, first to estimate a form of projection of $Y$ on $X$ and $Z$ using one half of the data, an",
    "link": "http://arxiv.org/abs/2211.02039",
    "context": "Title: The Projected Covariance Measure for assumption-lean variable significance testing. (arXiv:2211.02039v2 [math.ST] UPDATED)\nAbstract: Testing the significance of a variable or group of variables $X$ for predicting a response $Y$, given additional covariates $Z$, is a ubiquitous task in statistics. A simple but common approach is to specify a linear model, and then test whether the regression coefficient for $X$ is non-zero. However, when the model is misspecified, the test may have poor power, for example when $X$ is involved in complex interactions, or lead to many false rejections. In this work we study the problem of testing the model-free null of conditional mean independence, i.e. that the conditional mean of $Y$ given $X$ and $Z$ does not depend on $X$. We propose a simple and general framework that can leverage flexible nonparametric or machine learning methods, such as additive models or random forests, to yield both robust error control and high power. The procedure involves using these methods to perform regressions, first to estimate a form of projection of $Y$ on $X$ and $Z$ using one half of the data, an",
    "path": "papers/22/11/2211.02039.json",
    "total_tokens": 882,
    "translated_title": "假设简约的变量重要性检验的投影协方差测量",
    "translated_abstract": "在统计学中，对于给定附加协变量Z，测试变量或变量组X对于预测响应Y的重要性是一项普遍任务。一种简单但常见的方法是指定一个线性模型，然后测试X的回归系数是否为非零。然而，当模型错误指定时，测试的功效可能很差，例如当X参与复杂的交互作用，或者导致许多错误拒绝。在这项工作中，我们研究了测试条件均值独立的无模型假设，即给定X和Z，Y的条件均值不依赖于X。我们提出了一个简单而通用的框架，可以利用灵活的非参数或机器学习方法，如加法模型或随机森林，实现稳健的误差控制和高功效。该过程包括使用这些方法进行回归，首先使用一半的数据估计以X和Z为基础的Y的一种投影形式。",
    "tldr": "该论文介绍了一种假设简约的变量重要性检验方法，利用非参数或机器学习方法实现稳健的误差控制和高功效。",
    "en_tdlr": "This paper presents an assumption-lean variable significance testing method that achieves robust error control and high power using nonparametric or machine learning methods."
}