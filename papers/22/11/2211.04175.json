{
    "title": "Centaur: Federated Learning for Constrained Edge Devices",
    "abstract": "arXiv:2211.04175v3 Announce Type: replace  Abstract: Federated learning (FL) facilitates new applications at the edge, especially for wearable and Internet-of-Thing devices. Such devices capture a large and diverse amount of data, but they have memory, compute, power, and connectivity constraints which hinder their participation in FL. We propose Centaur, a multitier FL framework, enabling ultra-constrained devices to efficiently participate in FL on large neural nets. Centaur combines two major ideas: (i) a data selection scheme to choose a portion of samples that accelerates the learning, and (ii) a partition-based training algorithm that integrates both constrained and powerful devices owned by the same user. Evaluations, on four benchmark neural nets and three datasets, show that Centaur gains ~10\\% higher accuracy than local training on constrained devices with ~58\\% energy saving on average. Our experimental results also demonstrate the superior efficiency of Centaur when dealing",
    "link": "https://arxiv.org/abs/2211.04175",
    "context": "Title: Centaur: Federated Learning for Constrained Edge Devices\nAbstract: arXiv:2211.04175v3 Announce Type: replace  Abstract: Federated learning (FL) facilitates new applications at the edge, especially for wearable and Internet-of-Thing devices. Such devices capture a large and diverse amount of data, but they have memory, compute, power, and connectivity constraints which hinder their participation in FL. We propose Centaur, a multitier FL framework, enabling ultra-constrained devices to efficiently participate in FL on large neural nets. Centaur combines two major ideas: (i) a data selection scheme to choose a portion of samples that accelerates the learning, and (ii) a partition-based training algorithm that integrates both constrained and powerful devices owned by the same user. Evaluations, on four benchmark neural nets and three datasets, show that Centaur gains ~10\\% higher accuracy than local training on constrained devices with ~58\\% energy saving on average. Our experimental results also demonstrate the superior efficiency of Centaur when dealing",
    "path": "papers/22/11/2211.04175.json",
    "total_tokens": 909,
    "translated_title": "Centaur: 面向受限边缘设备的联邦学习",
    "translated_abstract": "联邦学习（FL）促进了在边缘设备上的新应用，尤其是对于可穿戴和物联网设备。这些设备捕获大量多样化的数据，但它们受到内存、计算、功耗和连接性约束，这些约束阻碍了它们参与FL。我们提出Centaur，一个多层FL框架，使超限制的设备能够高效地参与大型神经网络的FL。Centaur结合了两个主要的想法：（i）数据选择方案选择一部分样本加速学习，以及（ii）一个基于分区的训练算法，整合同一用户拥有的受限和强大设备。在四个基准神经网络和三个数据集上的评估显示，Centaur相比于在受限设备上的本地训练，能够获得约10\\%更高的准确性，平均能节约约58\\%的能量。我们的实验结果也表明了Centaur在处理时的卓越效率。",
    "tldr": "Centaur提出了面向受限边缘设备的联邦学习框架，通过数据选择方案和基于分区的训练算法，实现了超限制设备在大型神经网络的高效参与，相比本地训练能获得更高准确性和节约能量。",
    "en_tdlr": "Centaur proposes a federated learning framework for constrained edge devices, which enables ultra-constrained devices to efficiently participate in large neural networks through data selection scheme and partition-based training algorithm, achieving higher accuracy and energy saving compared to local training."
}