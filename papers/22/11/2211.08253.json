{
    "title": "HMOE: Hypernetwork-based Mixture of Experts for Domain Generalization. (arXiv:2211.08253v2 [cs.LG] UPDATED)",
    "abstract": "Due to domain shift, machine learning systems typically fail to generalize well to domains different from those of training data, which is what domain generalization (DG) aims to address. Although various DG methods have been developed, most of them lack interpretability and require domain labels that are not available in many real-world scenarios. This paper presents a novel DG method, called HMOE: Hypernetwork-based Mixture of Experts (MoE), which does not rely on domain labels and is more interpretable. MoE proves effective in identifying heterogeneous patterns in data. For the DG problem, heterogeneity arises exactly from domain shift. HMOE uses hypernetworks taking vectors as input to generate experts' weights, which allows experts to share useful meta-knowledge and enables exploring experts' similarities in a low-dimensional vector space. We compare HMOE with other DG algorithms under a fair and unified benchmark-DomainBed. Our extensive experiments show that HMOE can divide mixe",
    "link": "http://arxiv.org/abs/2211.08253",
    "total_tokens": 991,
    "translated_title": "HMOE: 基于超网络的专家混合模型用于领域泛化",
    "translated_abstract": "由于领域转移，机器学习系统通常无法很好地推广到与训练数据不同的领域，这就是领域泛化（DG）的目的。尽管已经开发了各种各样的DG方法，但大多数缺乏可解释性，并且需要在许多实际场景中不可用的领域标签。本文提出了一种新的DG方法，称为HMOE：基于超网络的专家混合模型（MoE），它不依赖于领域标签，并且更具可解释性。MoE在识别数据中的异质模式方面证明了其有效性。对于DG问题，异质性正是由于领域转移而产生的。HMOE使用超网络将向量作为输入来生成专家权重，这使得专家可以共享有用的元知识，并能够在低维向量空间中探索专家的相似性。我们在公平和统一的基准测试-DomainBed下将HMOE与其他DG算法进行比较。我们的广泛实验表明，HMOE可以划分混合数据并取得更好的效果。",
    "tldr": "本文提出了一种新的领域泛化方法HMOE，它不需要领域标签，更具可解释性，使用超网络生成专家权重，能够在低维向量空间中探索专家的相似性，实验结果表明HMOE可以划分混合数据并取得更好的效果。",
    "en_tldr": "This paper proposes a novel domain generalization method called HMOE, which does not rely on domain labels and is more interpretable. HMOE uses hypernetworks to generate experts' weights, which allows experts to share useful meta-knowledge and enables exploring experts' similarities in a low-dimensional vector space. Experimental results show that HMOE can divide mixed data and achieve better performance."
}