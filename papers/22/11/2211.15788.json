{
    "title": "A Visual Active Search Framework for Geospatial Exploration. (arXiv:2211.15788v2 [cs.CV] UPDATED)",
    "abstract": "Many problems can be viewed as forms of geospatial search aided by aerial imagery, with examples ranging from detecting poaching activity to human trafficking. We model this class of problems in a visual active search (VAS) framework, which takes as input an image of a broad area, and aims to identify as many examples of a target object as possible. It does this through a limited sequence of queries, each of which verifies whether an example is present in a given region. A crucial feature of VAS is that each such query is informative about the spatial distribution of target objects beyond what is captured visually (for example, due to spatial correlation). We propose a reinforcement learning approach for VAS that leverages a collection of fully annotated search tasks as training data to learn a search policy, and combines features of the input image with a natural representation of active search state. Additionally, we propose domain adaptation techniques to improve the policy at decis",
    "link": "http://arxiv.org/abs/2211.15788",
    "context": "Title: A Visual Active Search Framework for Geospatial Exploration. (arXiv:2211.15788v2 [cs.CV] UPDATED)\nAbstract: Many problems can be viewed as forms of geospatial search aided by aerial imagery, with examples ranging from detecting poaching activity to human trafficking. We model this class of problems in a visual active search (VAS) framework, which takes as input an image of a broad area, and aims to identify as many examples of a target object as possible. It does this through a limited sequence of queries, each of which verifies whether an example is present in a given region. A crucial feature of VAS is that each such query is informative about the spatial distribution of target objects beyond what is captured visually (for example, due to spatial correlation). We propose a reinforcement learning approach for VAS that leverages a collection of fully annotated search tasks as training data to learn a search policy, and combines features of the input image with a natural representation of active search state. Additionally, we propose domain adaptation techniques to improve the policy at decis",
    "path": "papers/22/11/2211.15788.json",
    "total_tokens": 905,
    "translated_title": "用于地理空间探索的视觉主动搜索框架",
    "translated_abstract": "许多问题可以被视为利用航空影像协助的地理空间搜索的形式，例如检测盗猎活动和人口贩卖等。本论文在视觉主动搜索（VAS）框架中建立了这类问题的模型，该框架以广阔区域的图像为输入，并旨在尽可能多地识别目标对象的示例。通过一系列有限的查询，VAS会验证在给定区域内是否存在示例。VAS的一个关键特征是，每个这样的查询都会提供有关目标对象空间分布的信息，超出了可视化所捕捉的内容（例如，由于空间相关性）。我们提出了针对VAS的强化学习方法，利用完全注释的搜索任务集作为训练数据来学习搜索策略，并将输入图像的特征与主动搜索状态的自然表示相结合。此外，我们提出了域自适应技术，以改善决策时的策略。",
    "tldr": "本论文提出了基于视觉主动搜索框架的强化学习方法，以协助地理空间探索问题。该框架以广阔区域的图像为输入，通过有限的查询来验证目标对象示例的存在，并提供关于目标对象空间分布的信息。",
    "en_tdlr": "This paper proposes a reinforcement learning approach based on a visual active search framework to assist in geospatial exploration problems. The framework takes an image of a broad area as input, verifies the existence of target object examples through limited queries, and provides information about the spatial distribution of target objects."
}