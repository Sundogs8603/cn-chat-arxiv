{
    "title": "Will My Robot Achieve My Goals? Predicting the Probability that an MDP Policy Reaches a User-Specified Behavior Target",
    "abstract": "arXiv:2211.16462v2 Announce Type: replace  Abstract: As an autonomous system performs a task, it should maintain a calibrated estimate of the probability that it will achieve the user's goal. If that probability falls below some desired level, it should alert the user so that appropriate interventions can be made. This paper considers settings where the user's goal is specified as a target interval for a real-valued performance summary, such as the cumulative reward, measured at a fixed horizon $H$. At each time $t \\in \\{0, \\ldots, H-1\\}$, our method produces a calibrated estimate of the probability that the final cumulative reward will fall within a user-specified target interval $[y^-,y^+].$ Using this estimate, the autonomous system can raise an alarm if the probability drops below a specified threshold. We compute the probability estimates by inverting conformal prediction. Our starting point is the Conformalized Quantile Regression (CQR) method of Romano et al., which applies spli",
    "link": "https://arxiv.org/abs/2211.16462",
    "context": "Title: Will My Robot Achieve My Goals? Predicting the Probability that an MDP Policy Reaches a User-Specified Behavior Target\nAbstract: arXiv:2211.16462v2 Announce Type: replace  Abstract: As an autonomous system performs a task, it should maintain a calibrated estimate of the probability that it will achieve the user's goal. If that probability falls below some desired level, it should alert the user so that appropriate interventions can be made. This paper considers settings where the user's goal is specified as a target interval for a real-valued performance summary, such as the cumulative reward, measured at a fixed horizon $H$. At each time $t \\in \\{0, \\ldots, H-1\\}$, our method produces a calibrated estimate of the probability that the final cumulative reward will fall within a user-specified target interval $[y^-,y^+].$ Using this estimate, the autonomous system can raise an alarm if the probability drops below a specified threshold. We compute the probability estimates by inverting conformal prediction. Our starting point is the Conformalized Quantile Regression (CQR) method of Romano et al., which applies spli",
    "path": "papers/22/11/2211.16462.json",
    "total_tokens": 874,
    "translated_title": "我的机器人会实现我的目标吗？预测MDP策略达到用户指定行为目标的概率",
    "translated_abstract": "当自主系统执行任务时，应保持对实现用户目标概率的校准估计。如果该概率低于某个期望水平，应向用户发出警报，以便采取适当干预。本文考虑了用户将目标规定为实值性能摘要的目标区间的设置，例如在固定时间段$H$内测量的累积奖励。在每个时间$t \\in \\{0, \\ldots, H-1\\}$，我们的方法会产生一个校准概率估计，即最终累积奖励落在用户指定目标区间$[y^-,y^+]$内的概率。利用这一估计，自主系统可以在概率低于指定阈值时发出警报。我们通过反转符合预测来计算概率估计。我们的出发点是Romano等人的Quantile Regression (CQR)方法，该方法应用了spli",
    "tldr": "本文提出了一种能够预测MDP策略达到用户指定行为目标概率的方法，并通过对符合预测进行反转来计算概率估计。",
    "en_tdlr": "This paper presents a method to predict the probability that an MDP policy reaches a user-specified behavior target and computes the probability estimates by inverting conformal prediction."
}