{
    "title": "Unsupervised 3D Keypoint Discovery with Multi-View Geometry",
    "abstract": "Analyzing and training 3D body posture models depend heavily on the availability of joint labels that are commonly acquired through laborious manual annotation of body joints or via marker-based joint localization using carefully curated markers and capturing systems. However, such annotations are not always available, especially for people performing unusual activities. In this paper, we propose an algorithm that learns to discover 3D keypoints on human bodies from multiple-view images without any supervision or labels other than the constraints multiple-view geometry provides. To ensure that the discovered 3D keypoints are meaningful, they are re-projected to each view to estimate the person's mask that the model itself has initially estimated without supervision. Our approach discovers more interpretable and accurate 3D keypoints compared to other state-of-the-art unsupervised approaches on Human3.6M and MPI-INF-3DHP benchmark datasets.",
    "link": "https://arxiv.org/abs/2211.12829",
    "context": "Title: Unsupervised 3D Keypoint Discovery with Multi-View Geometry\nAbstract: Analyzing and training 3D body posture models depend heavily on the availability of joint labels that are commonly acquired through laborious manual annotation of body joints or via marker-based joint localization using carefully curated markers and capturing systems. However, such annotations are not always available, especially for people performing unusual activities. In this paper, we propose an algorithm that learns to discover 3D keypoints on human bodies from multiple-view images without any supervision or labels other than the constraints multiple-view geometry provides. To ensure that the discovered 3D keypoints are meaningful, they are re-projected to each view to estimate the person's mask that the model itself has initially estimated without supervision. Our approach discovers more interpretable and accurate 3D keypoints compared to other state-of-the-art unsupervised approaches on Human3.6M and MPI-INF-3DHP benchmark datasets.",
    "path": "papers/22/11/2211.12829.json",
    "total_tokens": 930,
    "translated_title": "无监督的多视角几何下的3D关键点发现",
    "translated_abstract": "分析和训练3D身体姿势模型在很大程度上依赖于关节标签的可用性，这些标签通常通过繁琐的手动标注或者通过经过精心策划的标记和捕捉系统的基于标记的关节定位来获得。然而，这样的标注并不总是可用的，特别是对于进行不寻常活动的人。在本文中，我们提出了一种算法，学习从多视图图像中发现人体的3D关键点，而无需任何监督或标签，仅依靠多视图几何提供的约束。为了确保发现的3D关键点是有意义的，它们被重新投影到每个视图以估计模型在没有监督的情况下最初估计的人的掩模。我们的方法在Human3.6M和MPI-INF-3DHP基准数据集上比其他最先进的无监督方法发现了更有解释性和更准确的3D关键点。",
    "tldr": "本文提出了一种无监督算法，利用多视图几何约束，从多视图图像中学习发现人体的3D关键点，并通过重新投影到每个视图来估计3D关键点的准确性和可解释性。在多个基准数据集上，与其他无监督方法相比，我们的方法发现了更准确和具有解释性的3D关键点。",
    "en_tdlr": "This paper proposes an unsupervised algorithm that learns to discover 3D keypoints on human bodies using multi-view geometry constraints. The discovered 3D keypoints are re-projected to each view to estimate their accuracy and interpretability. Compared to other unsupervised methods, our approach discovers more accurate and interpretable 3D keypoints on multiple benchmark datasets."
}