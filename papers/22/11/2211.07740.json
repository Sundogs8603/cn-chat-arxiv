{
    "title": "Denoising diffusion models for out-of-distribution detection. (arXiv:2211.07740v4 [cs.LG] UPDATED)",
    "abstract": "Out-of-distribution detection is crucial to the safe deployment of machine learning systems. Currently, unsupervised out-of-distribution detection is dominated by generative-based approaches that make use of estimates of the likelihood or other measurements from a generative model. Reconstruction-based methods offer an alternative approach, in which a measure of reconstruction error is used to determine if a sample is out-of-distribution. However, reconstruction-based approaches are less favoured, as they require careful tuning of the model's information bottleneck - such as the size of the latent dimension - to produce good results. In this work, we exploit the view of denoising diffusion probabilistic models (DDPM) as denoising autoencoders where the bottleneck is controlled externally, by means of the amount of noise applied. We propose to use DDPMs to reconstruct an input that has been noised to a range of noise levels, and use the resulting multi-dimensional reconstruction error t",
    "link": "http://arxiv.org/abs/2211.07740",
    "context": "Title: Denoising diffusion models for out-of-distribution detection. (arXiv:2211.07740v4 [cs.LG] UPDATED)\nAbstract: Out-of-distribution detection is crucial to the safe deployment of machine learning systems. Currently, unsupervised out-of-distribution detection is dominated by generative-based approaches that make use of estimates of the likelihood or other measurements from a generative model. Reconstruction-based methods offer an alternative approach, in which a measure of reconstruction error is used to determine if a sample is out-of-distribution. However, reconstruction-based approaches are less favoured, as they require careful tuning of the model's information bottleneck - such as the size of the latent dimension - to produce good results. In this work, we exploit the view of denoising diffusion probabilistic models (DDPM) as denoising autoencoders where the bottleneck is controlled externally, by means of the amount of noise applied. We propose to use DDPMs to reconstruct an input that has been noised to a range of noise levels, and use the resulting multi-dimensional reconstruction error t",
    "path": "papers/22/11/2211.07740.json",
    "total_tokens": 838,
    "translated_abstract": "在机器学习系统的安全部署中，ODD（out-of-distribution detection）至关重要。目前，无监督ODD主要由基于生成模型估计可能性或其他测量的基于生成的方法主导。基于重构的方法提供了另一种方法，其中重构误差的度量用于确定样本是否为ODD。然而，基于重构的方法不太受欢迎，因为需要仔细调节模型的信息瓶颈（例如潜在维度的大小）才能产生良好的结果。在本文中，我们利用去噪扩散概率模型（DDPM）作为去噪自编码器的观点，由于噪声的数量而在外部控制模型的瓶颈。我们建议使用DDPM对已加噪到一定噪声水平的输入进行重构，并使用产生的多维重构误差来检测ODD。",
    "tldr": "本文提出使用去噪扩散模型对已加噪到一定噪声水平的输入进行重构，并使用多维重构误差来检测ODD。",
    "en_tdlr": "This paper proposes to use denoising diffusion models to reconstruct an input that has been noised to a range of noise levels, and utilize the resulting multi-dimensional reconstruction error to detect out-of-distribution (ODD) samples."
}