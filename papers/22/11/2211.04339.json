{
    "title": "Toward Adaptive Semantic Communications: Efficient Data Transmission via Online Learned Nonlinear Transform Source-Channel Coding. (arXiv:2211.04339v2 [cs.IT] UPDATED)",
    "abstract": "The emerging field semantic communication is driving the research of end-to-end data transmission. By utilizing the powerful representation ability of deep learning models, learned data transmission schemes have exhibited superior performance than the established source and channel coding methods. While, so far, research efforts mainly concentrated on architecture and model improvements toward a static target domain. Despite their successes, such learned models are still suboptimal due to the limitations in model capacity and imperfect optimization and generalization, particularly when the testing data distribution or channel response is different from that adopted for model training, as is likely to be the case in real-world. To tackle this, we propose a novel online learned joint source and channel coding approach that leverages the deep learning model's overfitting property. Specifically, we update the off-the-shelf pre-trained models after deployment in a lightweight online fashion",
    "link": "http://arxiv.org/abs/2211.04339",
    "context": "Title: Toward Adaptive Semantic Communications: Efficient Data Transmission via Online Learned Nonlinear Transform Source-Channel Coding. (arXiv:2211.04339v2 [cs.IT] UPDATED)\nAbstract: The emerging field semantic communication is driving the research of end-to-end data transmission. By utilizing the powerful representation ability of deep learning models, learned data transmission schemes have exhibited superior performance than the established source and channel coding methods. While, so far, research efforts mainly concentrated on architecture and model improvements toward a static target domain. Despite their successes, such learned models are still suboptimal due to the limitations in model capacity and imperfect optimization and generalization, particularly when the testing data distribution or channel response is different from that adopted for model training, as is likely to be the case in real-world. To tackle this, we propose a novel online learned joint source and channel coding approach that leverages the deep learning model's overfitting property. Specifically, we update the off-the-shelf pre-trained models after deployment in a lightweight online fashion",
    "path": "papers/22/11/2211.04339.json",
    "total_tokens": 898,
    "translated_title": "迈向自适应语义通信：基于在线学习非线性变换源通道编码的高效数据传输",
    "translated_abstract": "新兴的语义通信领域推动了端到端数据传输的研究。通过利用深度学习模型的强大表示能力，学习的数据传输方案表现出比已有的源码和信道编码方法更优越的性能。然而，迄今为止，研究重点主要集中在架构和模型改进方面，朝向静态目标域。尽管这些学习模型取得了成功，但由于模型容量的限制和不完美的优化和推广，特别是在测试数据分布或信道响应与模型训练不同的情况下，它们仍然是次优的，而这在实际情况下很可能发生。为了解决这个问题，我们提出了一种新颖的在线学习联合源和信道编码方法，利用了深度学习模型的过度拟合属性。具体而言，我们以轻量级在线方式更新部署后的现成预训练模型。",
    "tldr": "本论文的主要贡献是提出了一种基于深度学习模型的在线学习联合源和信道编码方法，通过利用模型的过度拟合能力，提高模型的适应性，从而在实际应用中实现更高效的数据传输。",
    "en_tdlr": "This paper proposes an online learned joint source and channel coding approach based on deep learning models, which leverages the overfitting property of the model to improve its adaptability and achieve more efficient data transmission in practical applications."
}