{
    "title": "Taming Reachability Analysis of DNN-Controlled Systems via Abstraction-Based Training. (arXiv:2211.11127v2 [cs.LG] UPDATED)",
    "abstract": "The intrinsic complexity of deep neural networks (DNNs) makes it challenging to verify not only the networks themselves but also the hosting DNN-controlled systems. Reachability analysis of these systems faces the same challenge. Existing approaches rely on over-approximating DNNs using simpler polynomial models. However, they suffer from low efficiency and large overestimation, and are restricted to specific types of DNNs. This paper presents a novel abstraction-based approach to bypass the crux of over-approximating DNNs in reachability analysis. Specifically, we extend conventional DNNs by inserting an additional abstraction layer, which abstracts a real number to an interval for training. The inserted abstraction layer ensures that the values represented by an interval are indistinguishable to the network for both training and decision-making. Leveraging this, we devise the first black-box reachability analysis approach for DNN-controlled systems, where trained DNNs are only querie",
    "link": "http://arxiv.org/abs/2211.11127",
    "context": "Title: Taming Reachability Analysis of DNN-Controlled Systems via Abstraction-Based Training. (arXiv:2211.11127v2 [cs.LG] UPDATED)\nAbstract: The intrinsic complexity of deep neural networks (DNNs) makes it challenging to verify not only the networks themselves but also the hosting DNN-controlled systems. Reachability analysis of these systems faces the same challenge. Existing approaches rely on over-approximating DNNs using simpler polynomial models. However, they suffer from low efficiency and large overestimation, and are restricted to specific types of DNNs. This paper presents a novel abstraction-based approach to bypass the crux of over-approximating DNNs in reachability analysis. Specifically, we extend conventional DNNs by inserting an additional abstraction layer, which abstracts a real number to an interval for training. The inserted abstraction layer ensures that the values represented by an interval are indistinguishable to the network for both training and decision-making. Leveraging this, we devise the first black-box reachability analysis approach for DNN-controlled systems, where trained DNNs are only querie",
    "path": "papers/22/11/2211.11127.json",
    "total_tokens": 959,
    "translated_title": "通过基于抽象的训练驯服DNN控制系统的可达性分析",
    "translated_abstract": "深度神经网络(DNNs)的内在复杂性使得验证网络本身和托管DNN控制系统变得具有挑战性。这些系统的可达性分析面临相同的挑战。现有的方法依赖于使用更简单的多项式模型对DNN进行过度近似。然而，它们效率低下并且过度估计较大，并且限于特定类型的DNNs。本文提出了一种新颖的基于抽象的方法，绕过在可达性分析中对DNNs进行过度近似的关键问题。具体而言，我们通过插入一个额外的抽象层来扩展传统的DNNs，该抽象层将实数抽象化为一个区间进行训练。插入的抽象层确保区间表示的值在训练和决策过程中对网络不可区分。利用这一点，我们设计了第一个适用于DNN控制系统的黑盒可达性分析方法，其中只对训练过的DNN进行查询。",
    "tldr": "本文提出了一种基于抽象的方法，用于绕过在DNN控制系统中对DNN进行过度近似的可达性分析问题。通过在传统的DNN中插入一个抽象层，将实数抽象化为一个区间进行训练，进而实现对DNN控制系统的黑盒可达性分析。",
    "en_tdlr": "This paper presents a novel abstraction-based approach to bypass the crux of over-approximating DNNs in reachability analysis of DNN-controlled systems. By inserting an additional abstraction layer in conventional DNNs to abstract real numbers into intervals for training, it enables black-box reachability analysis for DNN-controlled systems."
}