{
    "title": "Validating Large Language Models with ReLM. (arXiv:2211.15458v2 [cs.LG] UPDATED)",
    "abstract": "Although large language models (LLMs) have been touted for their ability to generate natural-sounding text, there are growing concerns around possible negative effects of LLMs such as data memorization, bias, and inappropriate language. Unfortunately, the complexity and generation capacities of LLMs make validating (and correcting) such concerns difficult. In this work, we introduce ReLM, a system for validating and querying LLMs using standard regular expressions. ReLM formalizes and enables a broad range of language model evaluations, reducing complex evaluation rules to simple regular expression queries. Our results exploring queries surrounding memorization, gender bias, toxicity, and language understanding show that ReLM achieves up to 15x higher system efficiency, 2.5x data efficiency, and increased statistical and prompt-tuning coverage compared to state-of-the-art ad-hoc queries. ReLM offers a competitive and general baseline for the increasingly important problem of LLM valida",
    "link": "http://arxiv.org/abs/2211.15458",
    "context": "Title: Validating Large Language Models with ReLM. (arXiv:2211.15458v2 [cs.LG] UPDATED)\nAbstract: Although large language models (LLMs) have been touted for their ability to generate natural-sounding text, there are growing concerns around possible negative effects of LLMs such as data memorization, bias, and inappropriate language. Unfortunately, the complexity and generation capacities of LLMs make validating (and correcting) such concerns difficult. In this work, we introduce ReLM, a system for validating and querying LLMs using standard regular expressions. ReLM formalizes and enables a broad range of language model evaluations, reducing complex evaluation rules to simple regular expression queries. Our results exploring queries surrounding memorization, gender bias, toxicity, and language understanding show that ReLM achieves up to 15x higher system efficiency, 2.5x data efficiency, and increased statistical and prompt-tuning coverage compared to state-of-the-art ad-hoc queries. ReLM offers a competitive and general baseline for the increasingly important problem of LLM valida",
    "path": "papers/22/11/2211.15458.json",
    "total_tokens": 881,
    "translated_title": "使用ReLM验证大型语言模型",
    "translated_abstract": "即使大型语言模型(LLM)因为可以生成自然的文本而备受推崇，但是越来越多人关注LLM可能带来的负面影响，如数据记忆、偏见和不恰当语言使用。不幸的是，LLM的复杂性和生成能力使得验证（和纠正）这些问题变得困难。在这项工作中，我们介绍了ReLM，这是一种使用标准正则表达式验证和查询LLM的系统。ReLM将广泛的语言模型评估形式化并启用，将复杂的评估规则简化为简单的正则表达式查询。我们的结果探索了关于记忆、性别偏见、毒性和语言理解的查询，显示ReLM相比最先进的特定查询技术达到了高达15倍的系统效率、2.5倍的数据效率以及更广泛的统计和提示调整覆盖范围。ReLM为越来越重要的LLM验证问题提供了竞争性和通用的基准。",
    "tldr": "ReLM是一种使用正则表达式验证和查询LLM的系统，可以解决LLM数据记忆、偏见、毒性和语言理解等问题，具有高效性和广泛性。"
}