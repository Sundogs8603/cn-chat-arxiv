{
    "title": "Guided Depth Super-Resolution by Deep Anisotropic Diffusion. (arXiv:2211.11592v3 [cs.CV] UPDATED)",
    "abstract": "Performing super-resolution of a depth image using the guidance from an RGB image is a problem that concerns several fields, such as robotics, medical imaging, and remote sensing. While deep learning methods have achieved good results in this problem, recent work highlighted the value of combining modern methods with more formal frameworks. In this work, we propose a novel approach which combines guided anisotropic diffusion with a deep convolutional network and advances the state of the art for guided depth super-resolution. The edge transferring/enhancing properties of the diffusion are boosted by the contextual reasoning capabilities of modern networks, and a strict adjustment step guarantees perfect adherence to the source image. We achieve unprecedented results in three commonly used benchmarks for guided depth super-resolution. The performance gain compared to other methods is the largest at larger scales, such as x32 scaling. Code (https://github.com/prs-eth/Diffusion-Super-Reso",
    "link": "http://arxiv.org/abs/2211.11592",
    "context": "Title: Guided Depth Super-Resolution by Deep Anisotropic Diffusion. (arXiv:2211.11592v3 [cs.CV] UPDATED)\nAbstract: Performing super-resolution of a depth image using the guidance from an RGB image is a problem that concerns several fields, such as robotics, medical imaging, and remote sensing. While deep learning methods have achieved good results in this problem, recent work highlighted the value of combining modern methods with more formal frameworks. In this work, we propose a novel approach which combines guided anisotropic diffusion with a deep convolutional network and advances the state of the art for guided depth super-resolution. The edge transferring/enhancing properties of the diffusion are boosted by the contextual reasoning capabilities of modern networks, and a strict adjustment step guarantees perfect adherence to the source image. We achieve unprecedented results in three commonly used benchmarks for guided depth super-resolution. The performance gain compared to other methods is the largest at larger scales, such as x32 scaling. Code (https://github.com/prs-eth/Diffusion-Super-Reso",
    "path": "papers/22/11/2211.11592.json",
    "total_tokens": 897,
    "translated_title": "通过深度各向异性扩散进行引导的深度超分辨率",
    "translated_abstract": "利用RGB图像的指导实现深度图像的超分辨率是涉及到机器人，医学成像和遥感等多个领域的问题。尽管深度学习方法在此问题上取得了良好的结果，但最近的研究突显了将现代方法与更为正式的框架相结合的价值。在本文中，我们提出了一种新颖的方法，将引导各向异性扩散与深度卷积网络相结合，推进了引导深度超分辨率的状态。扩散的边缘转移/增强特性由现代网络的上下文推理能力加强，严格的调整步骤确保完全粘合到源图像上。我们在三个常用的引导深度超分辨率基准测试中实现了前所未有的结果。与其他方法相比，性能在较大比例尺下，例如x32缩放时获得了最大的提升。",
    "tldr": "本研究提出了一种结合了各向异性扩散和深度卷积网络的新方法，用于引导深度超分辨率，取得了前所未有的结果，在x32缩放下的性能提升最大。",
    "en_tdlr": "This paper proposes a novel approach that combines guided anisotropic diffusion with a deep convolutional network to advance the state-of-the-art for guided depth super-resolution. The results are unprecedented, and the largest performance gain compared to other methods is achieved at larger scales, such as x32 scaling."
}