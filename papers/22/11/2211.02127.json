{
    "title": "Scalable Multi-Agent Reinforcement Learning through Intelligent Information Aggregation. (arXiv:2211.02127v3 [cs.MA] UPDATED)",
    "abstract": "We consider the problem of multi-agent navigation and collision avoidance when observations are limited to the local neighborhood of each agent. We propose InforMARL, a novel architecture for multi-agent reinforcement learning (MARL) which uses local information intelligently to compute paths for all the agents in a decentralized manner. Specifically, InforMARL aggregates information about the local neighborhood of agents for both the actor and the critic using a graph neural network and can be used in conjunction with any standard MARL algorithm. We show that (1) in training, InforMARL has better sample efficiency and performance than baseline approaches, despite using less information, and (2) in testing, it scales well to environments with arbitrary numbers of agents and obstacles. We illustrate these results using four task environments, including one with predetermined goals for each agent, and one in which the agents collectively try to cover all goals. Code available at https://",
    "link": "http://arxiv.org/abs/2211.02127",
    "context": "Title: Scalable Multi-Agent Reinforcement Learning through Intelligent Information Aggregation. (arXiv:2211.02127v3 [cs.MA] UPDATED)\nAbstract: We consider the problem of multi-agent navigation and collision avoidance when observations are limited to the local neighborhood of each agent. We propose InforMARL, a novel architecture for multi-agent reinforcement learning (MARL) which uses local information intelligently to compute paths for all the agents in a decentralized manner. Specifically, InforMARL aggregates information about the local neighborhood of agents for both the actor and the critic using a graph neural network and can be used in conjunction with any standard MARL algorithm. We show that (1) in training, InforMARL has better sample efficiency and performance than baseline approaches, despite using less information, and (2) in testing, it scales well to environments with arbitrary numbers of agents and obstacles. We illustrate these results using four task environments, including one with predetermined goals for each agent, and one in which the agents collectively try to cover all goals. Code available at https://",
    "path": "papers/22/11/2211.02127.json",
    "total_tokens": 918,
    "tldr": "提出了一种名为InforMARL的多智能体强化学习架构，利用图神经网络智能地聚合智能体的局部邻域信息进行路径分散计算，具有较高的样本效率和性能以及可扩展性。",
    "en_tdlr": "Introducing InforMARL, a novel multi-agent reinforcement learning architecture that leverages a graph neural network to intelligently aggregate local information for decentralized path planning. InforMARL outperforms baseline approaches in both sample efficiency and scalability, while using less information, and is applicable to various environments with arbitrary numbers of agents and obstacles."
}