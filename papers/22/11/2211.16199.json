{
    "title": "Latent Graph Inference using Product Manifolds. (arXiv:2211.16199v2 [cs.LG] UPDATED)",
    "abstract": "Graph Neural Networks usually rely on the assumption that the graph topology is available to the network as well as optimal for the downstream task. Latent graph inference allows models to dynamically learn the intrinsic graph structure of problems where the connectivity patterns of data may not be directly accessible. In this work, we generalize the discrete Differentiable Graph Module (dDGM) for latent graph learning. The original dDGM architecture used the Euclidean plane to encode latent features based on which the latent graphs were generated. By incorporating Riemannian geometry into the model and generating more complex embedding spaces, we can improve the performance of the latent graph inference system. In particular, we propose a computationally tractable approach to produce product manifolds of constant curvature model spaces that can encode latent features of varying structure. The latent representations mapped onto the inferred product manifold are used to compute richer s",
    "link": "http://arxiv.org/abs/2211.16199",
    "context": "Title: Latent Graph Inference using Product Manifolds. (arXiv:2211.16199v2 [cs.LG] UPDATED)\nAbstract: Graph Neural Networks usually rely on the assumption that the graph topology is available to the network as well as optimal for the downstream task. Latent graph inference allows models to dynamically learn the intrinsic graph structure of problems where the connectivity patterns of data may not be directly accessible. In this work, we generalize the discrete Differentiable Graph Module (dDGM) for latent graph learning. The original dDGM architecture used the Euclidean plane to encode latent features based on which the latent graphs were generated. By incorporating Riemannian geometry into the model and generating more complex embedding spaces, we can improve the performance of the latent graph inference system. In particular, we propose a computationally tractable approach to produce product manifolds of constant curvature model spaces that can encode latent features of varying structure. The latent representations mapped onto the inferred product manifold are used to compute richer s",
    "path": "papers/22/11/2211.16199.json",
    "total_tokens": 858,
    "translated_title": "利用积流形进行潜在图推断",
    "translated_abstract": "图神经网络通常依赖于图拓扑结构对网络的可用性以及对下游任务的最优性。而潜在图推断允许模型动态学习问题内在的图结构，这些数据的连通性模式可能无法直接访问。本文将离散可微图模块（dDGM）推广到潜在图学习。原始的dDGM架构使用欧几里得平面来编码潜在特征，基于此生成潜在图。通过将黎曼几何引入模型并生成更复杂的嵌入空间，我们可以提高潜在图推断系统的性能。特别是，我们提出了一种计算上可行的方法来产生常曲率模型空间的积流形，可以编码不同结构的潜在特征。映射到推断出的积流形上的潜在表示用于计算更丰富的表示。",
    "tldr": "本文提出了一种利用积流形进行推断的潜在图学习方法，以动态学习问题内在的图结构。通过使用Riemannian几何学和生成更复杂的嵌入空间，可以提高系统性能并产生更丰富的表示。",
    "en_tdlr": "This paper presents a method for latent graph learning using product manifolds to dynamically learn the intrinsic graph structure of a problem. By incorporating Riemannian geometry and generating complex embedding spaces, the system performance and representation can be improved."
}