{
    "title": "A Self-Attention Ansatz for Ab-initio Quantum Chemistry. (arXiv:2211.13672v2 [physics.chem-ph] UPDATED)",
    "abstract": "We present a novel neural network architecture using self-attention, the Wavefunction Transformer (Psiformer), which can be used as an approximation (or Ansatz) for solving the many-electron Schr\\\"odinger equation, the fundamental equation for quantum chemistry and material science. This equation can be solved from first principles, requiring no external training data. In recent years, deep neural networks like the FermiNet and PauliNet have been used to significantly improve the accuracy of these first-principle calculations, but they lack an attention-like mechanism for gating interactions between electrons. Here we show that the Psiformer can be used as a drop-in replacement for these other neural networks, often dramatically improving the accuracy of the calculations. On larger molecules especially, the ground state energy can be improved by dozens of kcal/mol, a qualitative leap over previous methods. This demonstrates that self-attention networks can learn complex quantum mechani",
    "link": "http://arxiv.org/abs/2211.13672",
    "context": "Title: A Self-Attention Ansatz for Ab-initio Quantum Chemistry. (arXiv:2211.13672v2 [physics.chem-ph] UPDATED)\nAbstract: We present a novel neural network architecture using self-attention, the Wavefunction Transformer (Psiformer), which can be used as an approximation (or Ansatz) for solving the many-electron Schr\\\"odinger equation, the fundamental equation for quantum chemistry and material science. This equation can be solved from first principles, requiring no external training data. In recent years, deep neural networks like the FermiNet and PauliNet have been used to significantly improve the accuracy of these first-principle calculations, but they lack an attention-like mechanism for gating interactions between electrons. Here we show that the Psiformer can be used as a drop-in replacement for these other neural networks, often dramatically improving the accuracy of the calculations. On larger molecules especially, the ground state energy can be improved by dozens of kcal/mol, a qualitative leap over previous methods. This demonstrates that self-attention networks can learn complex quantum mechani",
    "path": "papers/22/11/2211.13672.json",
    "total_tokens": 868,
    "translated_title": "自注意力框架在从头计算量子化学中的应用",
    "translated_abstract": "我们提出了一种新的神经网络架构-波函数变压器（Psiformer），它使用自注意力作为近似方法（或Ansatz）来解决许多电子薛定谔方程，这是量子化学和材料科学的基本方程。这个方程可以从第一原理中解决，不需要外部训练数据。近年来，像FermiNet和PauliNet这样的深度神经网络已被用于显著提高这些第一原理计算的准确性，但它们缺乏控制电子之间相互作用的注意力机制。在这里，我们展示了Psiformer可以作为这些其他神经网络的可替换品，经常显著提高计算的准确性。尤其是在大分子上，基态能量的提高可以达到几十kcal/mol，比以前的方法有了质的飞跃。这表明，自注意力网络可以学习复杂的量子力学。",
    "tldr": "Psiformer是一种使用自注意力机制的新型神经网络架构，可显著提高从头计算量子化学中基态能量的准确性，特别是在大分子上。",
    "en_tdlr": "Psiformer is a novel neural network architecture using self-attention and a drop-in replacement for previous deep neural networks. It significantly improves the accuracy of the ground state energy calculations in ab-initio quantum chemistry, particularly for larger molecules."
}