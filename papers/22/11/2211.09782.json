{
    "title": "Assessing Neural Network Robustness via Adversarial Pivotal Tuning. (arXiv:2211.09782v2 [cs.CV] UPDATED)",
    "abstract": "The robustness of image classifiers is essential to their deployment in the real world. The ability to assess this resilience to manipulations or deviations from the training data is thus crucial. These modifications have traditionally consisted of minimal changes that still manage to fool classifiers, and modern approaches are increasingly robust to them. Semantic manipulations that modify elements of an image in meaningful ways have thus gained traction for this purpose. However, they have primarily been limited to style, color, or attribute changes. While expressive, these manipulations do not make use of the full capabilities of a pretrained generative model. In this work, we aim to bridge this gap. We show how a pretrained image generator can be used to semantically manipulate images in a detailed, diverse, and photorealistic way while still preserving the class of the original image. Inspired by recent GAN-based image inversion methods, we propose a method called Adversarial Pivo",
    "link": "http://arxiv.org/abs/2211.09782",
    "context": "Title: Assessing Neural Network Robustness via Adversarial Pivotal Tuning. (arXiv:2211.09782v2 [cs.CV] UPDATED)\nAbstract: The robustness of image classifiers is essential to their deployment in the real world. The ability to assess this resilience to manipulations or deviations from the training data is thus crucial. These modifications have traditionally consisted of minimal changes that still manage to fool classifiers, and modern approaches are increasingly robust to them. Semantic manipulations that modify elements of an image in meaningful ways have thus gained traction for this purpose. However, they have primarily been limited to style, color, or attribute changes. While expressive, these manipulations do not make use of the full capabilities of a pretrained generative model. In this work, we aim to bridge this gap. We show how a pretrained image generator can be used to semantically manipulate images in a detailed, diverse, and photorealistic way while still preserving the class of the original image. Inspired by recent GAN-based image inversion methods, we propose a method called Adversarial Pivo",
    "path": "papers/22/11/2211.09782.json",
    "total_tokens": 883,
    "translated_title": "通过对抗基础调整评估神经网络的鲁棒性",
    "translated_abstract": "图像分类器的鲁棒性对于它们在现实世界中的部署至关重要。评估其对于训练数据的操纵或偏离能力因此至关重要。传统上，这些修改通常仅包括最小的变化，仍能欺骗分类器，而现代方法对此越来越具有鲁棒性。因此，对图像进行有意义的语义操作的方式在此目的上得到了广泛应用，但主要局限于样式、颜色或属性的变化。虽然表达力强，但这些操作并没有充分利用预训练生成模型的全部能力。在这项工作中，我们旨在弥合这个差距。我们展示了如何使用预训练图像生成器在详细、多样和逼真的方式上对图像进行语义操作，同时保留原始图像的类别。受最近的基于GAN的图像反演方法的启发，我们提出了一种名为“Adversarial Pivo”的方法",
    "tldr": "本研究旨在通过使用预训练图像生成器对图像进行详细、多样和逼真的语义操作，同时保留原始图像的类别，来评估神经网络的鲁棒性。",
    "en_tdlr": "This study aims to assess the robustness of neural networks by using a pretrained image generator to perform detailed, diverse, and photorealistic semantic manipulations on images while preserving the original image's class."
}