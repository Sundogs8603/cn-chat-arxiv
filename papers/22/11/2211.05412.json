{
    "title": "Desire Backpropagation: A Lightweight Training Algorithm for Multi-Layer Spiking Neural Networks based on Spike-Timing-Dependent Plasticity. (arXiv:2211.05412v2 [cs.NE] UPDATED)",
    "abstract": "Spiking neural networks (SNNs) are a viable alternative to conventional artificial neural networks when resource efficiency and computational complexity are of importance. A major advantage of SNNs is their binary information transfer through spike trains which eliminates multiplication operations. The training of SNNs has, however, been a challenge, since neuron models are non-differentiable and traditional gradient-based backpropagation algorithms cannot be applied directly. Furthermore, spike-timing-dependent plasticity (STDP), albeit being a spike-based learning rule, updates weights locally and does not optimize for the output error of the network. We present desire backpropagation, a method to derive the desired spike activity of all neurons, including the hidden ones, from the output error. By incorporating this desire value into the local STDP weight update, we can efficiently capture the neuron dynamics while minimizing the global error and attaining a high classification accu",
    "link": "http://arxiv.org/abs/2211.05412",
    "context": "Title: Desire Backpropagation: A Lightweight Training Algorithm for Multi-Layer Spiking Neural Networks based on Spike-Timing-Dependent Plasticity. (arXiv:2211.05412v2 [cs.NE] UPDATED)\nAbstract: Spiking neural networks (SNNs) are a viable alternative to conventional artificial neural networks when resource efficiency and computational complexity are of importance. A major advantage of SNNs is their binary information transfer through spike trains which eliminates multiplication operations. The training of SNNs has, however, been a challenge, since neuron models are non-differentiable and traditional gradient-based backpropagation algorithms cannot be applied directly. Furthermore, spike-timing-dependent plasticity (STDP), albeit being a spike-based learning rule, updates weights locally and does not optimize for the output error of the network. We present desire backpropagation, a method to derive the desired spike activity of all neurons, including the hidden ones, from the output error. By incorporating this desire value into the local STDP weight update, we can efficiently capture the neuron dynamics while minimizing the global error and attaining a high classification accu",
    "path": "papers/22/11/2211.05412.json",
    "total_tokens": 973,
    "translated_title": "渴望反向传播：基于时序相关可塑性的多层脉冲神经网络的轻量级训练算法",
    "translated_abstract": "脉冲神经网络（SNNs）是传统人工神经网络的一种可行替代，当资源效率和计算复杂性至关重要时。SNNs 的一个重要优势是通过脉冲序列进行二进制信息传输，消除了乘法运算。然而，SNNs 的训练一直以来都是个挑战，因为神经元模型是不可微分的，传统的基于梯度的反向传播算法无法直接应用。此外，虽然时序相关可塑性（STDP）是一种基于脉冲的学习规则，但它只在本地更新权重，没有针对网络输出误差进行优化。我们提出了渴望反向传播方法，从输出误差中推导出所有神经元（包括隐藏神经元）的期望脉冲活动。通过将这个期望值结合到本地STDP权重更新中，我们能够有效捕捉神经元的动态，并最小化全局误差达到高分类准确度。",
    "tldr": "渴望反向传播是一种轻量级训练算法，用于解决多层脉冲神经网络的训练挑战。通过将期望脉冲活动与脉冲序列的本地STDP权重更新相结合，可以捕捉神经元的动态并最小化输出误差，从而获得高分类准确度。",
    "en_tdlr": "Desire Backpropagation is a lightweight training algorithm that addresses the training challenge of multi-layer spiking neural networks. By incorporating the desired spike activity with local STDP weight updates, it captures neuron dynamics and minimizes output error, achieving high classification accuracy."
}