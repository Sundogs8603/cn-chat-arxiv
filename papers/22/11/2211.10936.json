{
    "title": "Deep Reinforcement Learning Guided Improvement Heuristic for Job Shop Scheduling",
    "abstract": "arXiv:2211.10936v3 Announce Type: replace-cross Abstract: Recent studies in using deep reinforcement learning (DRL) to solve Job-shop scheduling problems (JSSP) focus on construction heuristics. However, their performance is still far from optimality, mainly because the underlying graph representation scheme is unsuitable for modelling partial solutions at each construction step. This paper proposes a novel DRL-guided improvement heuristic for solving JSSP, where graph representation is employed to encode complete solutions. We design a Graph Neural-Network-based representation scheme, consisting of two modules to effectively capture the information of dynamic topology and different types of nodes in graphs encountered during the improvement process. To speed up solution evaluation during improvement, we present a novel message-passing mechanism that can evaluate multiple solutions simultaneously. We prove that the computational complexity of our method scales linearly with problem siz",
    "link": "https://arxiv.org/abs/2211.10936",
    "context": "Title: Deep Reinforcement Learning Guided Improvement Heuristic for Job Shop Scheduling\nAbstract: arXiv:2211.10936v3 Announce Type: replace-cross Abstract: Recent studies in using deep reinforcement learning (DRL) to solve Job-shop scheduling problems (JSSP) focus on construction heuristics. However, their performance is still far from optimality, mainly because the underlying graph representation scheme is unsuitable for modelling partial solutions at each construction step. This paper proposes a novel DRL-guided improvement heuristic for solving JSSP, where graph representation is employed to encode complete solutions. We design a Graph Neural-Network-based representation scheme, consisting of two modules to effectively capture the information of dynamic topology and different types of nodes in graphs encountered during the improvement process. To speed up solution evaluation during improvement, we present a novel message-passing mechanism that can evaluate multiple solutions simultaneously. We prove that the computational complexity of our method scales linearly with problem siz",
    "path": "papers/22/11/2211.10936.json",
    "total_tokens": 879,
    "translated_title": "深度强化学习指导下的作业车间调度改进启发式方法",
    "translated_abstract": "近期研究将深度强化学习（DRL）应用于解决作业车间调度问题时，主要关注的是构建启发式方法。然而，他们的性能仍远离最优，主要是因为底层图表示方案不适合对每个构建步骤中的部分解进行建模。本文提出了一种新颖的DRL指导下的作业车间调度改进启发式方法，采用图表示法来编码完整的解决方案。我们设计了一个基于图神经网络的表示方案，包含两个模块，可以有效地捕捉改进过程中遇到的动态拓扑和不同类型的节点的信息。为了在改进过程中加快解决方案评估，我们提出了一种新颖的消息传递机制，可以同时评估多个解决方案。我们证明了我们的方法的计算复杂性与问题规模呈线性关系。",
    "tldr": "本文提出了一种基于深度强化学习的指导下的作业车间调度改进启发式方法，采用图表示法来编码完整的解决方案，并设计了基于图神经网络的表示方案和新颖的消息传递机制，以提高性能和加快解决方案评估。",
    "en_tdlr": "This paper proposes a novel DRL-guided improvement heuristic for job shop scheduling, using graph representation to encode complete solutions, and designing a Graph Neural-Network-based representation scheme and a novel message-passing mechanism to enhance performance and accelerate solution evaluation."
}