{
    "title": "Masked Autoencoding for Scalable and Generalizable Decision Making. (arXiv:2211.12740v2 [cs.LG] UPDATED)",
    "abstract": "We are interested in learning scalable agents for reinforcement learning that can learn from large-scale, diverse sequential data similar to current large vision and language models. To this end, this paper presents masked decision prediction (MaskDP), a simple and scalable self-supervised pretraining method for reinforcement learning (RL) and behavioral cloning (BC). In our MaskDP approach, we employ a masked autoencoder (MAE) to state-action trajectories, wherein we randomly mask state and action tokens and reconstruct the missing data. By doing so, the model is required to infer masked-out states and actions and extract information about dynamics. We find that masking different proportions of the input sequence significantly helps with learning a better model that generalizes well to multiple downstream tasks. In our empirical study, we find that a MaskDP model gains the capability of zero-shot transfer to new BC tasks, such as single and multiple goal reaching, and it can zero-shot",
    "link": "http://arxiv.org/abs/2211.12740",
    "context": "Title: Masked Autoencoding for Scalable and Generalizable Decision Making. (arXiv:2211.12740v2 [cs.LG] UPDATED)\nAbstract: We are interested in learning scalable agents for reinforcement learning that can learn from large-scale, diverse sequential data similar to current large vision and language models. To this end, this paper presents masked decision prediction (MaskDP), a simple and scalable self-supervised pretraining method for reinforcement learning (RL) and behavioral cloning (BC). In our MaskDP approach, we employ a masked autoencoder (MAE) to state-action trajectories, wherein we randomly mask state and action tokens and reconstruct the missing data. By doing so, the model is required to infer masked-out states and actions and extract information about dynamics. We find that masking different proportions of the input sequence significantly helps with learning a better model that generalizes well to multiple downstream tasks. In our empirical study, we find that a MaskDP model gains the capability of zero-shot transfer to new BC tasks, such as single and multiple goal reaching, and it can zero-shot",
    "path": "papers/22/11/2211.12740.json",
    "total_tokens": 940,
    "translated_title": "可扩展和可推广决策制定的遮盖自编码",
    "translated_abstract": "本文关注于学习可扩展的增强学习代理，使其能够从类似于当前大规模视觉和语言模型的大规模多样的序列数据中学习。为了实现这一目标，本文提出了一种遮盖式决策预测 (MaskDP) 的简单可扩展的自监督预训练方法，用于增强学习和行为克隆。在 MaskDP 方法中，我们利用遮挡自编码器 (MAE) 处理状态-动作轨迹，随机遮盖状态和操作标记并重建缺失的数据。通过这样做，模型需要推断出遮挡的状态和操作，并提取关于动态的信息。我们发现，遮盖不同比例的输入序列显著有助于学习一个更好的模型，能够推广到多个后续任务。在实证研究中，我们发现 MaskDP 模型获得了零样本转移到新的 BC 任务的能力，例如单一和多个目标到达任务，并且可以零样本进行连续控制。",
    "tldr": "本文提出了一种遮盖式决策预测 (MaskDP) 的简单可扩展的自监督预训练方法，在可扩展的增强学习和行为克隆中能够有效地从大规模多样的序列数据中学习，并且零样本转移至新任务。",
    "en_tdlr": "This paper presents a simple and scalable self-supervised pretraining method, called masked decision prediction (MaskDP), for reinforcement learning and behavioral cloning. It can effectively learn from large-scale diverse sequential data, and achieve zero-shot transfer to new tasks."
}