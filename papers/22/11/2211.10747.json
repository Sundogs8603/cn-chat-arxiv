{
    "title": "Exploring validation metrics for offline model-based optimisation with diffusion models. (arXiv:2211.10747v3 [stat.ML] UPDATED)",
    "abstract": "In model-based optimisation (MBO) we are interested in using machine learning to design candidates that maximise some measure of reward with respect to a black box function called the (ground truth) oracle, which is expensive to compute since it involves executing a real world process. In offline MBO we wish to do so without assuming access to such an oracle during training or validation, with makes evaluation non-straightforward. While an approximation to the ground oracle can be trained and used in place of it during model validation to measure the mean reward over generated candidates, the evaluation is approximate and vulnerable to adversarial examples. Measuring the mean reward of generated candidates over this approximation is one such `validation metric', whereas we are interested in a more fundamental question which is finding which validation metrics correlate the most with the ground truth. This involves proposing validation metrics and quantifying them over many datasets for",
    "link": "http://arxiv.org/abs/2211.10747",
    "context": "Title: Exploring validation metrics for offline model-based optimisation with diffusion models. (arXiv:2211.10747v3 [stat.ML] UPDATED)\nAbstract: In model-based optimisation (MBO) we are interested in using machine learning to design candidates that maximise some measure of reward with respect to a black box function called the (ground truth) oracle, which is expensive to compute since it involves executing a real world process. In offline MBO we wish to do so without assuming access to such an oracle during training or validation, with makes evaluation non-straightforward. While an approximation to the ground oracle can be trained and used in place of it during model validation to measure the mean reward over generated candidates, the evaluation is approximate and vulnerable to adversarial examples. Measuring the mean reward of generated candidates over this approximation is one such `validation metric', whereas we are interested in a more fundamental question which is finding which validation metrics correlate the most with the ground truth. This involves proposing validation metrics and quantifying them over many datasets for",
    "path": "papers/22/11/2211.10747.json",
    "total_tokens": 922,
    "translated_title": "探索基于扩散模型的离线模型优化的验证指标",
    "translated_abstract": "在基于模型的优化中，我们希望利用机器学习设计候选方案，以最大化对于一个称为（地面真值）预言机的黑盒函数的某种奖励度量。然而，由于涉及到执行真实世界过程，计算预言机是昂贵的。在离线模型优化中，我们希望在训练或验证过程中不假设对预言机有访问权限，这使得评估变得复杂。虽然可以训练一个预言机的近似模型并在模型验证过程中使用它代替真值预言机来测量生成候选方案的平均奖励，但这种评估是近似的且容易受到对抗性样本的影响。我们将这种近似下生成候选方案的平均奖励作为一种“验证指标”，而我们更关心的是一个更基本的问题，即找到与真值预言机最相关的验证指标。这涉及到提出验证指标并对许多数据集进行量化。",
    "tldr": "本论文研究基于扩散模型的离线模型优化中的验证指标。在离线模型优化中，我们希望在没有访问真值预言机的情况下设计候选方案。现有的验证指标是对预言机的近似，我们希望找到与真值预言机最相关的验证指标。",
    "en_tdlr": "This paper explores validation metrics for offline model-based optimization with diffusion models. The goal is to find validation metrics that are most correlated with the ground truth oracle, as existing approximation methods are vulnerable to adversarial examples."
}