{
    "title": "Link Prediction with Non-Contrastive Learning. (arXiv:2211.14394v2 [cs.LG] UPDATED)",
    "abstract": "A recent focal area in the space of graph neural networks (GNNs) is graph self-supervised learning (SSL), which aims to derive useful node representations without labeled data. Notably, many state-of-the-art graph SSL methods are contrastive methods, which use a combination of positive and negative samples to learn node representations. Owing to challenges in negative sampling (slowness and model sensitivity), recent literature introduced non-contrastive methods, which instead only use positive samples. Though such methods have shown promising performance in node-level tasks, their suitability for link prediction tasks, which are concerned with predicting link existence between pairs of nodes (and have broad applicability to recommendation systems contexts) is yet unexplored. In this work, we extensively evaluate the performance of existing non-contrastive methods for link prediction in both transductive and inductive settings. While most existing non-contrastive methods perform poorly",
    "link": "http://arxiv.org/abs/2211.14394",
    "context": "Title: Link Prediction with Non-Contrastive Learning. (arXiv:2211.14394v2 [cs.LG] UPDATED)\nAbstract: A recent focal area in the space of graph neural networks (GNNs) is graph self-supervised learning (SSL), which aims to derive useful node representations without labeled data. Notably, many state-of-the-art graph SSL methods are contrastive methods, which use a combination of positive and negative samples to learn node representations. Owing to challenges in negative sampling (slowness and model sensitivity), recent literature introduced non-contrastive methods, which instead only use positive samples. Though such methods have shown promising performance in node-level tasks, their suitability for link prediction tasks, which are concerned with predicting link existence between pairs of nodes (and have broad applicability to recommendation systems contexts) is yet unexplored. In this work, we extensively evaluate the performance of existing non-contrastive methods for link prediction in both transductive and inductive settings. While most existing non-contrastive methods perform poorly",
    "path": "papers/22/11/2211.14394.json",
    "total_tokens": 752,
    "translated_title": "非对比学习的链路预测",
    "translated_abstract": "图神经网络（GNN）的一个最新热点是图自监督学习（SSL），旨在推导出没有标签数据的有用节点表示。尽管许多最先进的图形SSL方法都是对比方法，但由于负样本采样的挑战（速度缓慢和模型敏感性），最近的文献引入了非对比学习方法，这些方法只使用正样本。本文评估了现有的非对比方法在链路预测中的性能，包括传递性和归纳性。虽然大多数现有的非对比方法表现不佳，但我们提出了一种新的SSL方法来在链路预测中提高节点表示的性能。",
    "tldr": "本文介绍了一种新的非对比学习方法，用于链路预测任务，该方法可以在提高节点表示性能的同时减少负样本采样的挑战。"
}