{
    "title": "POLICE: Provably Optimal Linear Constraint Enforcement for Deep Neural Networks. (arXiv:2211.01340v3 [cs.LG] UPDATED)",
    "abstract": "Deep Neural Networks (DNNs) outshine alternative function approximators in many settings thanks to their modularity in composing any desired differentiable operator. The formed parametrized functional is then tuned to solve a task at hand from simple gradient descent. This modularity comes at the cost of making strict enforcement of constraints on DNNs, e.g. from a priori knowledge of the task, or from desired physical properties, an open challenge. In this paper we propose the first provable affine constraint enforcement method for DNNs that only requires minimal changes into a given DNN's forward-pass, that is computationally friendly, and that leaves the optimization of the DNN's parameter to be unconstrained, i.e. standard gradient-based method can be employed. Our method does not require any sampling and provably ensures that the DNN fulfills the affine constraint on a given input space's region at any point during training, and testing. We coin this method POLICE, standing for Pr",
    "link": "http://arxiv.org/abs/2211.01340",
    "raw_ret": "{\n    \"translated_title\": \"POLICE: 用于深度神经网络的可证明最优线性约束强制\",\n    \"translated_abstract\": \"深度神经网络在许多情况下比其他函数逼近器表现更出色，这要归功于它们在组合任何所需可微算子方面的模块化性。然后，形成参数化的功能，通过简单的梯度下降来调整以解决手头的任务。这种模块化性的代价是使得对DNN强制执行约束成为一个开放的挑战，例如来自任务的先验知识或期望的物理属性。在本文中，我们提出了第一个可证明的针对DNN的仿射约束强制方法，它仅需要对给定DNN的前向传递进行最小的更改，具有计算友好性，并且使DNN参数的优化无约束，即可以使用标准的基于梯度的方法。我们的方法不需要任何抽样，并且可以证明它确保DNN在训练和测试期间在给定输入空间区域内的任何点上都满足仿射约束。我们将这种方法称为POLICE，即代表Provably Optimal Linear Constraint Enforcement for Deep Neural Networks的缩写。\",\n    \"tldr\": \"本文提出了一种针对DNN的可证明仿射约束强制方法，该方法只需要最小的更改，具有计算友好性，并且可以使DNN参数的优化无约束，确保DNN在给定输入空间区域内的任何点上都满足仿射约束。\"\n}<|im_sep|>",
    "total_tokens": 929,
    "ret": {
        "translated_title": "POLICE: 用于深度神经网络的可证明最优线性约束强制",
        "translated_abstract": "深度神经网络在许多情况下比其他函数逼近器表现更出色，这要归功于它们在组合任何所需可微算子方面的模块化性。然后，形成参数化的功能，通过简单的梯度下降来调整以解决手头的任务。这种模块化性的代价是使得对DNN强制执行约束成为一个开放的挑战，例如来自任务的先验知识或期望的物理属性。在本文中，我们提出了第一个可证明的针对DNN的仿射约束强制方法，它仅需要对给定DNN的前向传递进行最小的更改，具有计算友好性，并且使DNN参数的优化无约束，即可以使用标准的基于梯度的方法。我们的方法不需要任何抽样，并且可以证明它确保DNN在训练和测试期间在给定输入空间区域内的任何点上都满足仿射约束。我们将这种方法称为POLICE，即代表Provably Optimal Linear Constraint Enforcement for Deep Neural Networks的缩写。",
        "tldr": "本文提出了一种针对DNN的可证明仿射约束强制方法，该方法只需要最小的更改，具有计算友好性，并且可以使DNN参数的优化无约束，确保DNN在给定输入空间区域内的任何点上都满足仿射约束。"
    }
}