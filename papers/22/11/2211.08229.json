{
    "title": "CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive Learning. (arXiv:2211.08229v4 [cs.CR] UPDATED)",
    "abstract": "Contrastive learning (CL) pre-trains general-purpose encoders using an unlabeled pre-training dataset, which consists of images or image-text pairs. CL is vulnerable to data poisoning based backdoor attacks (DPBAs), in which an attacker injects poisoned inputs into the pre-training dataset so the encoder is backdoored. However, existing DPBAs achieve limited effectiveness. In this work, we take the first step to analyze the limitations of existing attacks and propose new DPBAs called CorruptEncoder to CL. CorruptEncoder uses a theory-guided method to create optimal poisoned inputs to maximize attack effectiveness. Our experiments show that CorruptEncoder substantially outperforms existing DPBAs. In particular, CorruptEncoder is the first DPBA that achieves more than 90% attack success rates with only a few (3) reference images and a small poisoning ratio (0.5%). Moreover, we also propose a defense, called localized cropping, to defend against DPBAs. Our results show that our defense ca",
    "link": "http://arxiv.org/abs/2211.08229",
    "context": "Title: CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive Learning. (arXiv:2211.08229v4 [cs.CR] UPDATED)\nAbstract: Contrastive learning (CL) pre-trains general-purpose encoders using an unlabeled pre-training dataset, which consists of images or image-text pairs. CL is vulnerable to data poisoning based backdoor attacks (DPBAs), in which an attacker injects poisoned inputs into the pre-training dataset so the encoder is backdoored. However, existing DPBAs achieve limited effectiveness. In this work, we take the first step to analyze the limitations of existing attacks and propose new DPBAs called CorruptEncoder to CL. CorruptEncoder uses a theory-guided method to create optimal poisoned inputs to maximize attack effectiveness. Our experiments show that CorruptEncoder substantially outperforms existing DPBAs. In particular, CorruptEncoder is the first DPBA that achieves more than 90% attack success rates with only a few (3) reference images and a small poisoning ratio (0.5%). Moreover, we also propose a defense, called localized cropping, to defend against DPBAs. Our results show that our defense ca",
    "path": "papers/22/11/2211.08229.json",
    "total_tokens": 986,
    "translated_title": "CorruptEncoder：基于数据污染的对比学习后门攻击",
    "translated_abstract": "对比学习使用无标签的预训练数据集对通用编码器进行预训练，包括图像或图像-文本对。对比学习容易受到基于数据污染的后门攻击（DPBA）的攻击，攻击者通过向预训练数据集中注入被污染的输入来后门化编码器。然而，现有的DPBA的效果有限。本文首先分析现有攻击的局限性，并提出了一种名为CorruptEncoder的新型DPBA来对抗对比学习。CorruptEncoder使用理论导向的方法创建最优的污染输入以最大限度地提高攻击效果。实验结果表明，CorruptEncoder在攻击效果上明显优于现有的DPBA。尤其是，CorruptEncoder是首个仅需要少量（3个）参考图像和小规模污染比例（0.5%）即可达到90%以上的攻击成功率的DPBA。此外，本文还提出了一种名为局部裁剪的防御策略来抵御DPBA。实验结果表明，我们的防御策略能有效抵御DPBA。",
    "tldr": "本文分析了现有数据污染后门攻击对对比学习的局限性，并提出了一种名为CorruptEncoder的新型攻击方法，通过理论导向的方式创建优化的污染输入，大幅提高攻击效果。实验证明，CorruptEncoder是首个仅需要少量图像和污染比例即可达到90%以上攻击成功率的攻击方法。同时，本文提出了一种名为局部裁剪的防御策略来应对数据污染后门攻击。"
}