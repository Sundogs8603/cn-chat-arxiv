{
    "title": "CRAFT: Concept Recursive Activation FacTorization for Explainability. (arXiv:2211.10154v2 [cs.CV] UPDATED)",
    "abstract": "Attribution methods, which employ heatmaps to identify the most influential regions of an image that impact model decisions, have gained widespread popularity as a type of explainability method. However, recent research has exposed the limited practical value of these methods, attributed in part to their narrow focus on the most prominent regions of an image -- revealing \"where\" the model looks, but failing to elucidate \"what\" the model sees in those areas. In this work, we try to fill in this gap with CRAFT -- a novel approach to identify both \"what\" and \"where\" by generating concept-based explanations. We introduce 3 new ingredients to the automatic concept extraction literature: (i) a recursive strategy to detect and decompose concepts across layers, (ii) a novel method for a more faithful estimation of concept importance using Sobol indices, and (iii) the use of implicit differentiation to unlock Concept Attribution Maps.  We conduct both human and computer vision experiments to de",
    "link": "http://arxiv.org/abs/2211.10154",
    "context": "Title: CRAFT: Concept Recursive Activation FacTorization for Explainability. (arXiv:2211.10154v2 [cs.CV] UPDATED)\nAbstract: Attribution methods, which employ heatmaps to identify the most influential regions of an image that impact model decisions, have gained widespread popularity as a type of explainability method. However, recent research has exposed the limited practical value of these methods, attributed in part to their narrow focus on the most prominent regions of an image -- revealing \"where\" the model looks, but failing to elucidate \"what\" the model sees in those areas. In this work, we try to fill in this gap with CRAFT -- a novel approach to identify both \"what\" and \"where\" by generating concept-based explanations. We introduce 3 new ingredients to the automatic concept extraction literature: (i) a recursive strategy to detect and decompose concepts across layers, (ii) a novel method for a more faithful estimation of concept importance using Sobol indices, and (iii) the use of implicit differentiation to unlock Concept Attribution Maps.  We conduct both human and computer vision experiments to de",
    "path": "papers/22/11/2211.10154.json",
    "total_tokens": 878,
    "translated_title": "CRAFT: 概念递归激活分解用于可解释性",
    "translated_abstract": "归因方法通过热图识别影响模型决策的最具影响力区域，已成为一种普遍的可解释性方法。然而，最近的研究已经揭示了这些方法有限的实际价值，部分归因于它们对图像最显著区域的狭窄关注,揭示了模型“注视”哪里，但未能阐明模型在这些区域“看到”的内容。在本文中，我们通过生成基于概念的解释，尝试填补这一空白，来确定“是什么”和“在哪里”。我们引入了三个新要素来自动提取概念：（i）一种递归策略来检测和分解跨层的概念，（ii）用 Sobol 指数更准确地估计概念重要性的新方法，和（iii）使用隐式微分来解锁概念归因图。我们进行了人类和计算机视觉实验来证明该方法的可行性和有效性。",
    "tldr": "CRAFT通过生成基于概念的解释来填补归因方法的局限性，实现了对图像“是什么”和“在哪里”的同时解释。",
    "en_tdlr": "CRAFT overcomes the limitations of attribution methods by generating concept-based explanations and achieves simultaneous explanation of \"what\" and \"where\" of the model's decisions on images."
}