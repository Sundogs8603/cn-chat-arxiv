{
    "title": "Exploratory Control with Tsallis Entropy for Latent Factor Models. (arXiv:2211.07622v2 [q-fin.MF] UPDATED)",
    "abstract": "We study optimal control in models with latent factors where the agent controls the distribution over actions, rather than actions themselves, in both discrete and continuous time. To encourage exploration of the state space, we reward exploration with Tsallis Entropy and derive the optimal distribution over states - which we prove is $q$-Gaussian distributed with location characterized through the solution of an FBS$\\Delta$E and FBSDE in discrete and continuous time, respectively. We discuss the relation between the solutions of the optimal exploration problems and the standard dynamic optimal control solution. Finally, we develop the optimal policy in a model-agnostic setting along the lines of soft $Q$-learning. The approach may be applied in, e.g., developing more robust statistical arbitrage trading strategies.",
    "link": "http://arxiv.org/abs/2211.07622",
    "context": "Title: Exploratory Control with Tsallis Entropy for Latent Factor Models. (arXiv:2211.07622v2 [q-fin.MF] UPDATED)\nAbstract: We study optimal control in models with latent factors where the agent controls the distribution over actions, rather than actions themselves, in both discrete and continuous time. To encourage exploration of the state space, we reward exploration with Tsallis Entropy and derive the optimal distribution over states - which we prove is $q$-Gaussian distributed with location characterized through the solution of an FBS$\\Delta$E and FBSDE in discrete and continuous time, respectively. We discuss the relation between the solutions of the optimal exploration problems and the standard dynamic optimal control solution. Finally, we develop the optimal policy in a model-agnostic setting along the lines of soft $Q$-learning. The approach may be applied in, e.g., developing more robust statistical arbitrage trading strategies.",
    "path": "papers/22/11/2211.07622.json",
    "total_tokens": 834,
    "translated_title": "使用Tsallis熵进行潜在因子模型的探索性控制",
    "translated_abstract": "我们研究了在具有潜在因子的模型中的最优控制问题，其中代理控制的是行为分布，而不是具体的行为，在离散和连续时间下均是如此。为了鼓励对状态空间的探索，我们使用Tsallis熵对探索进行奖励，并推导出最优的状态分布 - 我们证明了在离散时间和连续时间下的解都是$q$-高斯分布，其位置通过FBS$\\Delta$E和FBSDE的解来刻画。我们讨论了最优探索问题的解与标准动态最优控制解之间的关系。最后，我们在一个模型无关的设置中沿着软$Q$-学习的思路开发了最优策略。该方法可以应用于开发更健壮的统计套利交易策略等。",
    "tldr": "本研究探究了在具有潜在因子的模型中的最优控制问题，通过使用Tsallis熵来鼓励对状态空间的探索，并推导出最优的状态分布，可应用于开发更健壮的统计套利交易策略等。",
    "en_tdlr": "This study investigates optimal control problems in models with latent factors, promoting exploration of the state space using Tsallis entropy and deriving the optimal distribution over states. The approach has potential applications in developing more robust statistical arbitrage trading strategies."
}