{
    "title": "Examining Policy Entropy of Reinforcement Learning Agents for Personalization Tasks. (arXiv:2211.11869v3 [cs.LG] UPDATED)",
    "abstract": "This effort is focused on examining the behavior of reinforcement learning systems in personalization environments and detailing the differences in policy entropy associated with the type of learning algorithm utilized. We demonstrate that Policy Optimization agents often possess low-entropy policies during training, which in practice results in agents prioritizing certain actions and avoiding others. Conversely, we also show that Q-Learning agents are far less susceptible to such behavior and generally maintain high-entropy policies throughout training, which is often preferable in real-world applications. We provide a wide range of numerical experiments as well as theoretical justification to show that these differences in entropy are due to the type of learning being employed.",
    "link": "http://arxiv.org/abs/2211.11869",
    "context": "Title: Examining Policy Entropy of Reinforcement Learning Agents for Personalization Tasks. (arXiv:2211.11869v3 [cs.LG] UPDATED)\nAbstract: This effort is focused on examining the behavior of reinforcement learning systems in personalization environments and detailing the differences in policy entropy associated with the type of learning algorithm utilized. We demonstrate that Policy Optimization agents often possess low-entropy policies during training, which in practice results in agents prioritizing certain actions and avoiding others. Conversely, we also show that Q-Learning agents are far less susceptible to such behavior and generally maintain high-entropy policies throughout training, which is often preferable in real-world applications. We provide a wide range of numerical experiments as well as theoretical justification to show that these differences in entropy are due to the type of learning being employed.",
    "path": "papers/22/11/2211.11869.json",
    "total_tokens": 802,
    "translated_title": "研究强化学习智能体在个性化任务中的策略熵",
    "translated_abstract": "本文着重研究了强化学习系统在个性化环境中的行为，并详细描述了不同学习算法所关联的策略熵的差异。我们证明了在训练过程中，策略优化智能体往往具有低熵策略，实际上导致智能体优先考虑某些动作而避免其他动作。相反地，我们也表明了Q学习智能体对这种行为的影响要小得多，并且通常在训练过程中保持高熵策略，这在实际应用中往往更可取。我们提供了各种数值实验以及理论上的证明，以表明这些熵差异是由所采用的学习类型所导致的。",
    "tldr": "研究了个性化任务中强化学习智能体的策略熵，并发现策略优化智能体在训练过程中往往具有低熵策略，然而Q学习智能体对此影响较小，通常保持高熵策略。",
    "en_tdlr": "Explored the policy entropy of reinforcement learning agents in personalization tasks and found that policy optimization agents often have low-entropy policies during training, while Q-learning agents are less affected and generally maintain high-entropy policies."
}