{
    "title": "Dynamical Linear Bandits. (arXiv:2211.08997v2 [cs.LG] UPDATED)",
    "abstract": "In many real-world sequential decision-making problems, an action does not immediately reflect on the feedback and spreads its effects over a long time frame. For instance, in online advertising, investing in a platform produces an instantaneous increase of awareness, but the actual reward, i.e., a conversion, might occur far in the future. Furthermore, whether a conversion takes place depends on: how fast the awareness grows, its vanishing effects, and the synergy or interference with other advertising platforms. Previous work has investigated the Multi-Armed Bandit framework with the possibility of delayed and aggregated feedback, without a particular structure on how an action propagates in the future, disregarding possible dynamical effects. In this paper, we introduce a novel setting, the Dynamical Linear Bandits (DLB), an extension of the linear bandits characterized by a hidden state. When an action is performed, the learner observes a noisy reward whose mean is a linear functio",
    "link": "http://arxiv.org/abs/2211.08997",
    "context": "Title: Dynamical Linear Bandits. (arXiv:2211.08997v2 [cs.LG] UPDATED)\nAbstract: In many real-world sequential decision-making problems, an action does not immediately reflect on the feedback and spreads its effects over a long time frame. For instance, in online advertising, investing in a platform produces an instantaneous increase of awareness, but the actual reward, i.e., a conversion, might occur far in the future. Furthermore, whether a conversion takes place depends on: how fast the awareness grows, its vanishing effects, and the synergy or interference with other advertising platforms. Previous work has investigated the Multi-Armed Bandit framework with the possibility of delayed and aggregated feedback, without a particular structure on how an action propagates in the future, disregarding possible dynamical effects. In this paper, we introduce a novel setting, the Dynamical Linear Bandits (DLB), an extension of the linear bandits characterized by a hidden state. When an action is performed, the learner observes a noisy reward whose mean is a linear functio",
    "path": "papers/22/11/2211.08997.json",
    "total_tokens": 927,
    "translated_title": "动态线性臂机（Dynamical Linear Bandits）",
    "translated_abstract": "在许多实际的顺序决策问题中，一个行动不会立即反映在反馈上，并在较长的时间范围内扩散其影响。例如，在在线广告中，投资于某个平台会产生即时的意识增长，但实际回报，即转化，可能发生在未来较远的时间。此外，转化是否发生取决于意识的增长速度、其消失效应以及与其他广告平台的协同或干扰。先前的研究调查了具有延迟和聚合反馈可能性的多臂赌博机框架，没有关于一个行动在未来如何传播的特定结构，忽略了可能的动态效应。在本文中，我们引入了一种新的设置，即动态线性臂机（DLB），这是线性臂机的一种扩展，其特征是具有隐藏状态。当执行一个行动时，学习者观察到一个噪声回报，其均值是一个线性函数",
    "tldr": "本文提出了动态线性臂机（DLB）这一概念，这是线性臂机的扩展，具有隐藏状态。这一方法可用于解决在实际决策中行动不会立即反映在反馈上，并在较长的时间范围内扩散其影响所引起的问题。",
    "en_tdlr": "This paper proposes a concept of Dynamical Linear Bandits (DLB), an extension of the linear bandits characterized by a hidden state, which can be used to address the problem where an action does not immediately reflect on the feedback and spreads its effects over a long time frame in practical decision-making."
}