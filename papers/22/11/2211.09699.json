{
    "title": "PromptCap: Prompt-Guided Image Captioning for VQA with GPT-3. (arXiv:2211.09699v2 [cs.CV] UPDATED)",
    "abstract": "Knowledge-based visual question answering (VQA) involves questions that require world knowledge beyond the image to yield the correct answer. Large language models (LMs) like GPT-3 are particularly helpful for this task because of their strong knowledge retrieval and reasoning capabilities. To enable LM to understand images, prior work uses a captioning model to convert images into text. However, when summarizing an image in a single caption sentence, which visual entities to describe are often underspecified. Generic image captions often miss visual details essential for the LM to answer visual questions correctly. To address this challenge, we propose PromptCap (Prompt-guided image Captioning), a captioning model designed to serve as a better connector between images and black-box LMs. Different from generic captions, PromptCap takes a natural-language prompt to control the visual entities to describe in the generated caption. The prompt contains a question that the caption should ai",
    "link": "http://arxiv.org/abs/2211.09699",
    "context": "Title: PromptCap: Prompt-Guided Image Captioning for VQA with GPT-3. (arXiv:2211.09699v2 [cs.CV] UPDATED)\nAbstract: Knowledge-based visual question answering (VQA) involves questions that require world knowledge beyond the image to yield the correct answer. Large language models (LMs) like GPT-3 are particularly helpful for this task because of their strong knowledge retrieval and reasoning capabilities. To enable LM to understand images, prior work uses a captioning model to convert images into text. However, when summarizing an image in a single caption sentence, which visual entities to describe are often underspecified. Generic image captions often miss visual details essential for the LM to answer visual questions correctly. To address this challenge, we propose PromptCap (Prompt-guided image Captioning), a captioning model designed to serve as a better connector between images and black-box LMs. Different from generic captions, PromptCap takes a natural-language prompt to control the visual entities to describe in the generated caption. The prompt contains a question that the caption should ai",
    "path": "papers/22/11/2211.09699.json",
    "total_tokens": 856,
    "translated_title": "PromptCap：使用GPT-3的提示引导图像字幕生成进行视觉问答",
    "translated_abstract": "基于知识的视觉问答涉及需要超越图片以产生正确答案的世界知识的问题。像GPT-3这样的大型语言模型特别适用于此任务，因为它们具有强大的知识检索和推理能力。为了使LM理解图像，先前的工作使用字幕模型将图像转换为文本。然而，在单个字幕句子中总结图像时，要描述哪些视觉实体经常不明确。通用图像字幕经常错过LM回答视觉问题所必需的视觉细节。为了解决这一挑战，我们提出了PromptCap（Prompt-guided image Captioning），一种字幕模型，旨在成为图像和黑盒LM之间更好的连接器。与通用字幕不同，PromptCap采用自然语言提示来控制生成的字幕中要描述的视觉实体。提示包含字幕应回答的问题。",
    "tldr": "提出了PromptCap，一种使用提示引导的图像字幕生成模型，用于解决基于知识的视觉问答中通用图像字幕无法准确描述视觉实体的问题。",
    "en_tdlr": "PromptCap, a prompt-guided image captioning model, is proposed to address the issue of generic image captions failing to accurately describe visual entities in knowledge-based visual question answering."
}