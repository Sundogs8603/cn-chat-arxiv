{
    "title": "Understanding the Impact of Adversarial Robustness on Accuracy Disparity. (arXiv:2211.15762v2 [cs.LG] UPDATED)",
    "abstract": "While it has long been empirically observed that adversarial robustness may be at odds with standard accuracy and may have further disparate impacts on different classes, it remains an open question to what extent such observations hold and how the class imbalance plays a role within. In this paper, we attempt to understand this question of accuracy disparity by taking a closer look at linear classifiers under a Gaussian mixture model. We decompose the impact of adversarial robustness into two parts: an inherent effect that will degrade the standard accuracy on all classes due to the robustness constraint, and the other caused by the class imbalance ratio, which will increase the accuracy disparity compared to standard training. Furthermore, we also show that such effects extend beyond the Gaussian mixture model, by generalizing our data model to the general family of stable distributions. More specifically, we demonstrate that while the constraint of adversarial robustness consistentl",
    "link": "http://arxiv.org/abs/2211.15762",
    "context": "Title: Understanding the Impact of Adversarial Robustness on Accuracy Disparity. (arXiv:2211.15762v2 [cs.LG] UPDATED)\nAbstract: While it has long been empirically observed that adversarial robustness may be at odds with standard accuracy and may have further disparate impacts on different classes, it remains an open question to what extent such observations hold and how the class imbalance plays a role within. In this paper, we attempt to understand this question of accuracy disparity by taking a closer look at linear classifiers under a Gaussian mixture model. We decompose the impact of adversarial robustness into two parts: an inherent effect that will degrade the standard accuracy on all classes due to the robustness constraint, and the other caused by the class imbalance ratio, which will increase the accuracy disparity compared to standard training. Furthermore, we also show that such effects extend beyond the Gaussian mixture model, by generalizing our data model to the general family of stable distributions. More specifically, we demonstrate that while the constraint of adversarial robustness consistentl",
    "path": "papers/22/11/2211.15762.json",
    "total_tokens": 963,
    "translated_title": "理解对准确性不平衡影响的对抗鲁棒性问题",
    "translated_abstract": "尽管长期以来已经从经验上观察到对抗鲁棒性可能与标准准确性存在一些矛盾，并且可能对不同类别产生不平等影响，但它仍然是一个未解决的问题，即这些观察有多大程度的保持，以及类别不平衡在其中扮演什么样的角色。在本文中，我们试图通过更深入地研究高斯混合模型下的线性分类器来理解这个准确性不平衡问题。我们将对抗鲁棒性的影响分解成两部分：一部分是因为鲁棒性约束而会降低所有类别的标准准确性而固有的影响，另一部分是由于类别不平衡比率引起的，这将增加与标准训练相比的准确性差异。此外，我们还表明这些影响超越了高斯混合模型，通过将数据模型推广到稳定分布的一般家族。具体而言，我们证明了，虽然对抗鲁棒性的约束一致会减少所有类别的标准准确性，但通常会增加对少数类别的准确性不平衡。",
    "tldr": "本文通过研究高斯混合模型下的线性分类器，分析了对抗鲁棒性对准确性不平衡的影响，并证明了在稳定分布的一般家族中也存在类似影响。",
    "en_tdlr": "This paper analyzes the impact of adversarial robustness on accuracy disparity by studying linear classifiers under a Gaussian mixture model, and shows that such effects extend to the general family of stable distributions."
}