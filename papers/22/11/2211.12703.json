{
    "title": "Subgroup Robustness Grows On Trees: An Empirical Baseline Investigation. (arXiv:2211.12703v2 [cs.LG] UPDATED)",
    "abstract": "Researchers have proposed many methods for fair and robust machine learning, but comprehensive empirical evaluation of their subgroup robustness is lacking. In this work, we address this gap in the context of tabular data, where sensitive subgroups are clearly-defined, real-world fairness problems abound, and prior works often do not compare to state-of-the-art tree-based models as baselines. We conduct an empirical comparison of several previously-proposed methods for fair and robust learning alongside state-of-the-art tree-based methods and other baselines. Via experiments with more than $340{,}000$ model configurations on eight datasets, we show that tree-based methods have strong subgroup robustness, even when compared to robustness- and fairness-enhancing methods. Moreover, the best tree-based models tend to show good performance over a range of metrics, while robust or group-fair models can show brittleness, with significant performance differences across different metrics for a ",
    "link": "http://arxiv.org/abs/2211.12703",
    "context": "Title: Subgroup Robustness Grows On Trees: An Empirical Baseline Investigation. (arXiv:2211.12703v2 [cs.LG] UPDATED)\nAbstract: Researchers have proposed many methods for fair and robust machine learning, but comprehensive empirical evaluation of their subgroup robustness is lacking. In this work, we address this gap in the context of tabular data, where sensitive subgroups are clearly-defined, real-world fairness problems abound, and prior works often do not compare to state-of-the-art tree-based models as baselines. We conduct an empirical comparison of several previously-proposed methods for fair and robust learning alongside state-of-the-art tree-based methods and other baselines. Via experiments with more than $340{,}000$ model configurations on eight datasets, we show that tree-based methods have strong subgroup robustness, even when compared to robustness- and fairness-enhancing methods. Moreover, the best tree-based models tend to show good performance over a range of metrics, while robust or group-fair models can show brittleness, with significant performance differences across different metrics for a ",
    "path": "papers/22/11/2211.12703.json",
    "total_tokens": 861,
    "translated_title": "基于树的机器学习方法的子群健壮性：一个实证基线调查",
    "translated_abstract": "研究人员提出了许多公平和稳健的机器学习方法，但缺乏对它们的子群健壮性的全面实证评估。本文通过与基于状态-of-the-art树模型的基准线比较，以表格数据为背景，介绍了先前提出的多种公平和稳健学习方法的实证比较。通过在八个数据集上进行超过340,000个模型配置的实验，我们发现基于树的方法具有极强的子群健壮性，即使与稳健性和公平性增强方法进行比较。此外，最佳的基于树的模型往往表现出良好的综合性能，而稳健或群体公平的模型可能表现出脆弱性，对于不同的指标可能存在显著的性能差异。",
    "tldr": "本文通过实证比较多种公平和稳健的机器学习方法的子群健壮性，并表明基于树的方法具有极强的健壮性，可能比其他稳健或群体公平的方法表现更好。"
}