{
    "title": "Improving Speech Emotion Recognition with Unsupervised Speaking Style Transfer. (arXiv:2211.08843v2 [cs.SD] UPDATED)",
    "abstract": "Humans can effortlessly modify various prosodic attributes, such as the placement of stress and the intensity of sentiment, to convey a specific emotion while maintaining consistent linguistic content. Motivated by this capability, we propose EmoAug, a novel style transfer model designed to enhance emotional expression and tackle the data scarcity issue in speech emotion recognition tasks. EmoAug consists of a semantic encoder and a paralinguistic encoder that represent verbal and non-verbal information respectively. Additionally, a decoder reconstructs speech signals by conditioning on the aforementioned two information flows in an unsupervised fashion. Once training is completed, EmoAug enriches expressions of emotional speech with different prosodic attributes, such as stress, rhythm and intensity, by feeding different styles into the paralinguistic encoder. EmoAug enables us to generate similar numbers of samples for each class to tackle the data imbalance issue as well. Experiment",
    "link": "http://arxiv.org/abs/2211.08843",
    "context": "Title: Improving Speech Emotion Recognition with Unsupervised Speaking Style Transfer. (arXiv:2211.08843v2 [cs.SD] UPDATED)\nAbstract: Humans can effortlessly modify various prosodic attributes, such as the placement of stress and the intensity of sentiment, to convey a specific emotion while maintaining consistent linguistic content. Motivated by this capability, we propose EmoAug, a novel style transfer model designed to enhance emotional expression and tackle the data scarcity issue in speech emotion recognition tasks. EmoAug consists of a semantic encoder and a paralinguistic encoder that represent verbal and non-verbal information respectively. Additionally, a decoder reconstructs speech signals by conditioning on the aforementioned two information flows in an unsupervised fashion. Once training is completed, EmoAug enriches expressions of emotional speech with different prosodic attributes, such as stress, rhythm and intensity, by feeding different styles into the paralinguistic encoder. EmoAug enables us to generate similar numbers of samples for each class to tackle the data imbalance issue as well. Experiment",
    "path": "papers/22/11/2211.08843.json",
    "total_tokens": 937,
    "translated_title": "通过无监督说话风格转换提升语音情感识别",
    "translated_abstract": "人类可以轻松修改各种韵律属性，例如重音位置和情感强度，以传达特定的情感，同时保持一致的语言内容。受到这种能力的启发，我们提出了EmoAug，这是一种新颖的风格转换模型，旨在增强情感表达并解决语音情感识别任务中的数据稀缺问题。EmoAug由一个语义编码器和一个语调编码器组成，分别表示语言和非语言信息。此外，解码器以无监督的方式在上述两个信息流的条件下重建语音信号。训练完成后，EmoAug通过将不同风格输入到语调编码器中，丰富了情感语音的表达，包括重音、节奏和强度等不同的韵律属性。同时，EmoAug能够生成每个类别相似数量的样本，以解决数据不平衡问题。",
    "tldr": "本文介绍了EmoAug，一种通过无监督说话风格转换来提升语音情感识别的模型。EmoAug利用语义编码器和语调编码器表示语言和非语言信息，并通过无监督方式重建语音信号。训练完成后，EmoAug通过引入不同风格丰富了情感语音的表达，并解决了数据不平衡问题。",
    "en_tdlr": "This paper presents EmoAug, a model that improves speech emotion recognition through unsupervised speaking style transfer. EmoAug utilizes semantic and paralinguistic encoders to represent linguistic and non-verbal information, and reconstructs speech signals in an unsupervised manner. After training, EmoAug enriches the expressions of emotional speech with different styles and addresses the issue of data imbalance."
}