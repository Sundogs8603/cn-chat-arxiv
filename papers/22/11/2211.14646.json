{
    "title": "Towards Improved Input Masking for Convolutional Neural Networks. (arXiv:2211.14646v2 [cs.CV] UPDATED)",
    "abstract": "The ability to remove features from the input of machine learning models is very important to understand and interpret model predictions. However, this is non-trivial for vision models since masking out parts of the input image typically causes large distribution shifts. This is because the baseline color used for masking (typically grey or black) is out of distribution. Furthermore, the shape of the mask itself can contain unwanted signals which can be used by the model for its predictions. Recently, there has been some progress in mitigating this issue (called missingness bias) in image masking for vision transformers. In this work, we propose a new masking method for CNNs we call layer masking in which the missingness bias caused by masking is reduced to a large extent. Intuitively, layer masking applies a mask to intermediate activation maps so that the model only processes the unmasked input. We show that our method (i) is able to eliminate or minimize the influence of the mask sh",
    "link": "http://arxiv.org/abs/2211.14646",
    "context": "Title: Towards Improved Input Masking for Convolutional Neural Networks. (arXiv:2211.14646v2 [cs.CV] UPDATED)\nAbstract: The ability to remove features from the input of machine learning models is very important to understand and interpret model predictions. However, this is non-trivial for vision models since masking out parts of the input image typically causes large distribution shifts. This is because the baseline color used for masking (typically grey or black) is out of distribution. Furthermore, the shape of the mask itself can contain unwanted signals which can be used by the model for its predictions. Recently, there has been some progress in mitigating this issue (called missingness bias) in image masking for vision transformers. In this work, we propose a new masking method for CNNs we call layer masking in which the missingness bias caused by masking is reduced to a large extent. Intuitively, layer masking applies a mask to intermediate activation maps so that the model only processes the unmasked input. We show that our method (i) is able to eliminate or minimize the influence of the mask sh",
    "path": "papers/22/11/2211.14646.json",
    "total_tokens": 922,
    "translated_title": "改进卷积神经网络的输入遮罩方法研究",
    "translated_abstract": "对于理解和解释模型预测结果来说，从机器学习模型的输入中移除特征非常重要。然而，对于视觉模型来说，这是非常困难的，因为遮罩图像的一部分通常会引起很大的分布偏移。这是因为用于遮罩的基准颜色（通常是灰色或黑色）是处于分布之外的。此外，遮罩本身的形状可以包含不需要的信号，模型可能会利用这些信号进行预测。最近，在视觉变换器中对图像遮罩的缺失偏差问题方面已经取得了一些进展。在本研究中，我们提出了一种新的CNN遮罩方法，称之为层遮罩，可以在很大程度上减少遮罩引起的缺失偏差。直观上，层遮罩将一个遮罩应用于中间激活图，使得模型只处理没有遮罩的输入。我们展示了我们的方法（i）能够消除或最小化遮罩的影响。",
    "tldr": "本论文提出了一种改进的卷积神经网络的输入遮罩方法，通过层遮罩能够有效减少遮罩引起的缺失偏差，并消除或最小化了遮罩对模型预测的影响。",
    "en_tdlr": "This paper proposes an improved input masking method for convolutional neural networks, where layer masking is used to reduce the missingness bias caused by masking and eliminate or minimize its impact on model predictions."
}