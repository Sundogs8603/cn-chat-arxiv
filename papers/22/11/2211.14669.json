{
    "title": "Game Theoretic Mixed Experts for Combinational Adversarial Machine Learning. (arXiv:2211.14669v2 [cs.LG] UPDATED)",
    "abstract": "Recent advances in adversarial machine learning have shown that defenses considered to be robust are actually susceptible to adversarial attacks which are specifically customized to target their weaknesses. These defenses include Barrage of Random Transforms (BaRT), Friendly Adversarial Training (FAT), Trash is Treasure (TiT) and ensemble models made up of Vision Transformers (ViTs), Big Transfer models and Spiking Neural Networks (SNNs). We first conduct a transferability analysis, to demonstrate the adversarial examples generated by customized attacks on one defense, are not often misclassified by another defense.  This finding leads to two important questions. First, how can the low transferability between defenses be utilized in a game theoretic framework to improve the robustness? Second, how can an adversary within this framework develop effective multi-model attacks? In this paper, we provide a game-theoretic framework for ensemble adversarial attacks and defenses. Our framework",
    "link": "http://arxiv.org/abs/2211.14669",
    "context": "Title: Game Theoretic Mixed Experts for Combinational Adversarial Machine Learning. (arXiv:2211.14669v2 [cs.LG] UPDATED)\nAbstract: Recent advances in adversarial machine learning have shown that defenses considered to be robust are actually susceptible to adversarial attacks which are specifically customized to target their weaknesses. These defenses include Barrage of Random Transforms (BaRT), Friendly Adversarial Training (FAT), Trash is Treasure (TiT) and ensemble models made up of Vision Transformers (ViTs), Big Transfer models and Spiking Neural Networks (SNNs). We first conduct a transferability analysis, to demonstrate the adversarial examples generated by customized attacks on one defense, are not often misclassified by another defense.  This finding leads to two important questions. First, how can the low transferability between defenses be utilized in a game theoretic framework to improve the robustness? Second, how can an adversary within this framework develop effective multi-model attacks? In this paper, we provide a game-theoretic framework for ensemble adversarial attacks and defenses. Our framework",
    "path": "papers/22/11/2211.14669.json",
    "total_tokens": 1042,
    "translated_title": "博弈论混合专家用于组合对抗机器学习",
    "translated_abstract": "最近在对抗机器学习方面的一些进展表明，那些被认为是强健的防御措施实际上还是容易受到针对其弱点进行定制化攻击的对抗攻击。这些防御措施包括随机变换的攻击（BaRT），有益人类的对抗训练（FAT），垃圾就是珍宝（TiT）以及由视觉转换器、大型转移模型和尖峰神经网络组成的组合模型。本文提出了一种博弈论框架，用于组合对抗攻击和防御，我们的框架提出了一种混合专家模型，每个专家专门针对特定的防御攻击进行防御。然后，这些专家会以博弈论的方式进行合作和竞争，形成一个联合防御。我们在各种数据集和攻击上展示了我们方法的有效性，并表明我们的模型优于现有的最先进的防御措施。",
    "tldr": "本文提出了一种博弈论框架，用于组合对抗攻击和防御，我们的框架提出了一种混合专家模型，专门针对特定的防御攻击进行防御，并以博弈论的方式进行合作和竞争，形成一个联合防御。",
    "en_tdlr": "This paper proposes a game-theoretic framework for ensemble adversarial attacks and defenses, in which a mixed expert model is introduced to specialize in defending against specific attacks generated by defenses, and they collaborate and compete with one another in a game-theoretic manner to form a joint defense, outperforming existing state-of-the-art defenses."
}