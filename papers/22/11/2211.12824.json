{
    "title": "Tell Me What Happened: Unifying Text-guided Video Completion via Multimodal Masked Video Generation. (arXiv:2211.12824v2 [cs.CV] UPDATED)",
    "abstract": "Generating a video given the first several static frames is challenging as it anticipates reasonable future frames with temporal coherence. Besides video prediction, the ability to rewind from the last frame or infilling between the head and tail is also crucial, but they have rarely been explored for video completion. Since there could be different outcomes from the hints of just a few frames, a system that can follow natural language to perform video completion may significantly improve controllability. Inspired by this, we introduce a novel task, text-guided video completion (TVC), which requests the model to generate a video from partial frames guided by an instruction. We then propose Multimodal Masked Video Generation (MMVG) to address this TVC task. During training, MMVG discretizes the video frames into visual tokens and masks most of them to perform video completion from any time point. At inference time, a single MMVG model can address all 3 cases of TVC, including video pred",
    "link": "http://arxiv.org/abs/2211.12824",
    "context": "Title: Tell Me What Happened: Unifying Text-guided Video Completion via Multimodal Masked Video Generation. (arXiv:2211.12824v2 [cs.CV] UPDATED)\nAbstract: Generating a video given the first several static frames is challenging as it anticipates reasonable future frames with temporal coherence. Besides video prediction, the ability to rewind from the last frame or infilling between the head and tail is also crucial, but they have rarely been explored for video completion. Since there could be different outcomes from the hints of just a few frames, a system that can follow natural language to perform video completion may significantly improve controllability. Inspired by this, we introduce a novel task, text-guided video completion (TVC), which requests the model to generate a video from partial frames guided by an instruction. We then propose Multimodal Masked Video Generation (MMVG) to address this TVC task. During training, MMVG discretizes the video frames into visual tokens and masks most of them to perform video completion from any time point. At inference time, a single MMVG model can address all 3 cases of TVC, including video pred",
    "path": "papers/22/11/2211.12824.json",
    "total_tokens": 1089,
    "translated_title": "讲述故事：通过多模态掩码视频生成统一文本引导的视频补全",
    "translated_abstract": "在给定前几个静态帧的情况下生成一个视频是具有挑战性的，因为它需要以时间上的连贯性来预测合理的未来帧。除了视频预测之外，从最后一帧倒回或者在头尾之间进行插值也是至关重要的，但是它们很少被用于视频补全。由于仅凭几个帧的提示可能会有不同的结果，因此能够遵循自然语言来执行视频补全的系统可能会显著提高可控性。受此启发，我们引入了一种新的任务，文本引导的视频补全(TVC)，要求模型在指令的指导下从部分帧中生成视频。然后我们提出了多模态掩码视频生成(MMVG)来解决这个TVC任务。在训练期间，MMVG将视频帧离散为视觉令牌，并遮盖了大部分令牌以进行任意时间点的视频补全。在推理时，一个单独的MMVG模型可以处理TVC的所有三种情况，包括从前几个帧预测的视频，从最后一帧倒回的视频以及在头部和尾部之间进行插值。我们提出的方法在基准数据集上取得了最好的性能，与先前的视频补全方法相比，证明了我们的MMVG在文本引导的视频补全中的有效性。",
    "tldr": "本论文引入了一种新的任务，文本引导的视频补全，提出了多模态掩码视频生成方法，能够处理三种情况的视频补全。该方法在基准数据集上取得了最好的性能。",
    "en_tdlr": "This paper introduces a novel task of text-guided video completion and proposes a Multimodal Masked Video Generation (MMVG) method that can handle video completion in three cases. The proposed method achieves state-of-the-art performance on benchmark datasets."
}