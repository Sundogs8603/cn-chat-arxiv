{
    "title": "lilGym: Natural Language Visual Reasoning with Reinforcement Learning. (arXiv:2211.01994v3 [cs.LG] UPDATED)",
    "abstract": "We present lilGym, a new benchmark for language-conditioned reinforcement learning in visual environments. lilGym is based on 2,661 highly-compositional human-written natural language statements grounded in an interactive visual environment. We introduce a new approach for exact reward computation in every possible world state by annotating all statements with executable Python programs. Each statement is paired with multiple start states and reward functions to form thousands of distinct Markov Decision Processes of varying difficulty. We experiment with lilGym with different models and learning regimes. Our results and analysis show that while existing methods are able to achieve non-trivial performance, lilGym forms a challenging open problem. lilGym is available at https://lil.nlp.cornell.edu/lilgym/.",
    "link": "http://arxiv.org/abs/2211.01994",
    "context": "Title: lilGym: Natural Language Visual Reasoning with Reinforcement Learning. (arXiv:2211.01994v3 [cs.LG] UPDATED)\nAbstract: We present lilGym, a new benchmark for language-conditioned reinforcement learning in visual environments. lilGym is based on 2,661 highly-compositional human-written natural language statements grounded in an interactive visual environment. We introduce a new approach for exact reward computation in every possible world state by annotating all statements with executable Python programs. Each statement is paired with multiple start states and reward functions to form thousands of distinct Markov Decision Processes of varying difficulty. We experiment with lilGym with different models and learning regimes. Our results and analysis show that while existing methods are able to achieve non-trivial performance, lilGym forms a challenging open problem. lilGym is available at https://lil.nlp.cornell.edu/lilgym/.",
    "path": "papers/22/11/2211.01994.json",
    "total_tokens": 928,
    "translated_title": "基于强化学习的自然语言视觉推理：lilGym",
    "translated_abstract": "本文介绍了一种新的有关语言条件下强化学习在视觉环境下的基准测试——lilGym。lilGym基于2661个高度组合的人类编写的自然语言陈述，这些陈述是基于一个交互式视觉环境的。我们采用了一种新的方法，在每种可能的世界状态下，通过为所有语句注释可执行的Python程序，实现了精确的奖励计算。每个语句都与多个起始状态和奖励函数配对，以形成数千个不同难度的马尔可夫决策过程。我们使用不同的模型和学习机制进行了lilGym实验。我们的实验结果和分析表明，虽然现有的方法能够实现较高的性能，但是lilGym形成了一个具有挑战性的开放性问题。lilGym可以在 https://lil.nlp.cornell.edu/lilgym/ 上获得。",
    "tldr": "本文提出了一个基于自然语言视觉推理的强化学习基准测试——lilGym，它由2661个高度组合的人类编写自然语言语句和交互式视觉环境组成，并通过注释可执行Python程序来实现精确的奖励计算。本文的实验结果和分析表明，lilGym是一个具有挑战性的开放性问题。",
    "en_tdlr": "This paper proposes a new benchmark for language-conditioned reinforcement learning in visual environments called lilGym, which consists of 2,661 highly-compositional human-written natural language statements grounded in an interactive visual environment and achieves exact reward computation by annotating all statements with executable Python programs. The results and analysis show that lilGym forms a challenging open problem."
}