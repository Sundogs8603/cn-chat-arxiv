{
    "title": "NVDiff: Graph Generation through the Diffusion of Node Vectors. (arXiv:2211.10794v2 [cs.LG] UPDATED)",
    "abstract": "Learning to generate graphs is challenging as a graph is a set of pairwise connected, unordered nodes encoding complex combinatorial structures. Recently, several works have proposed graph generative models based on normalizing flows or score-based diffusion models. However, these models need to generate nodes and edges in parallel from the same process, whose dimensionality is unnecessarily high. We propose NVDiff, which takes the VGAE structure and uses a score-based generative model (SGM) as a flexible prior to sample node vectors. By modeling only node vectors in the latent space, NVDiff significantly reduces the dimension of the diffusion process and thus improves sampling speed. Built on the NVDiff framework, we introduce an attention-based score network capable of capturing both local and global contexts of graphs. Experiments indicate that NVDiff significantly reduces computations and can model much larger graphs than competing methods. At the same time, it achieves superior or",
    "link": "http://arxiv.org/abs/2211.10794",
    "context": "Title: NVDiff: Graph Generation through the Diffusion of Node Vectors. (arXiv:2211.10794v2 [cs.LG] UPDATED)\nAbstract: Learning to generate graphs is challenging as a graph is a set of pairwise connected, unordered nodes encoding complex combinatorial structures. Recently, several works have proposed graph generative models based on normalizing flows or score-based diffusion models. However, these models need to generate nodes and edges in parallel from the same process, whose dimensionality is unnecessarily high. We propose NVDiff, which takes the VGAE structure and uses a score-based generative model (SGM) as a flexible prior to sample node vectors. By modeling only node vectors in the latent space, NVDiff significantly reduces the dimension of the diffusion process and thus improves sampling speed. Built on the NVDiff framework, we introduce an attention-based score network capable of capturing both local and global contexts of graphs. Experiments indicate that NVDiff significantly reduces computations and can model much larger graphs than competing methods. At the same time, it achieves superior or",
    "path": "papers/22/11/2211.10794.json",
    "total_tokens": 894,
    "translated_title": "NVDiff：通过节点向量扩散生成图形",
    "translated_abstract": "学习生成图形是具有挑战性的，因为图形是一组成对连接的无序节点，编码具有复杂组合结构的信息。最近，一些研究提出了基于归一化流或基于分数的扩散模型的图形生成模型。然而，这些模型需要从相同的过程并行生成节点和边，其维数是不必要地高。我们提出了NVDiff，采用VGAE结构，并以分数为基础的生成模型（SGM）作为灵活的先验来采样节点向量。通过仅在潜空间中建模节点向量，NVDiff显着降低了扩散过程的维度，从而提高了采样速度。基于NVDiff框架，我们引入了一种基于注意力的分数网络，能够捕捉图形的局部和全局上下文。实验表明，NVDiff显着减少了计算量，可以模拟比竞争方法更大的图形。与此同时，它也实现了更好的生成质量。",
    "tldr": "NVDiff利用分数为基础的生成模型采样节点向量来生成图形，显著降低了扩散过程的维度，提高了采样速度，同时在生成质量方面表现更好。"
}