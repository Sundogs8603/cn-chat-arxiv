{
    "title": "A noise based novel strategy for faster SNN training. (arXiv:2211.05453v2 [cs.NE] UPDATED)",
    "abstract": "Spiking neural networks (SNNs) are receiving increasing attention due to their low power consumption and strong bio-plausibility. Optimization of SNNs is a challenging task. Two main methods, artificial neural network (ANN)-to-SNN conversion and spike-based backpropagation (BP), both have their advantages and limitations. For ANN-to-SNN conversion, it requires a long inference time to approximate the accuracy of ANN, thus diminishing the benefits of SNN. With spike-based BP, training high-precision SNNs typically consumes dozens of times more computational resources and time than their ANN counterparts. In this paper, we propose a novel SNN training approach that combines the benefits of the two methods. We first train a single-step SNN(T=1) by approximating the neural potential distribution with random noise, then convert the single-step SNN(T=1) to a multi-step SNN(T=N) losslessly. The introduction of Gaussian distributed noise leads to a significant gain in accuracy after conversion",
    "link": "http://arxiv.org/abs/2211.05453",
    "context": "Title: A noise based novel strategy for faster SNN training. (arXiv:2211.05453v2 [cs.NE] UPDATED)\nAbstract: Spiking neural networks (SNNs) are receiving increasing attention due to their low power consumption and strong bio-plausibility. Optimization of SNNs is a challenging task. Two main methods, artificial neural network (ANN)-to-SNN conversion and spike-based backpropagation (BP), both have their advantages and limitations. For ANN-to-SNN conversion, it requires a long inference time to approximate the accuracy of ANN, thus diminishing the benefits of SNN. With spike-based BP, training high-precision SNNs typically consumes dozens of times more computational resources and time than their ANN counterparts. In this paper, we propose a novel SNN training approach that combines the benefits of the two methods. We first train a single-step SNN(T=1) by approximating the neural potential distribution with random noise, then convert the single-step SNN(T=1) to a multi-step SNN(T=N) losslessly. The introduction of Gaussian distributed noise leads to a significant gain in accuracy after conversion",
    "path": "papers/22/11/2211.05453.json",
    "total_tokens": 947,
    "translated_title": "一种基于噪声的快速SNN训练新策略",
    "translated_abstract": "脉冲神经网络（SNN）因其低功耗和强的生物合理性而受到越来越多的关注。SNN的优化是一个具有挑战性的任务。两种主要方法，即人工神经网络（ANN）到SNN的转换和基于脉冲的反向传播（BP），都有其优点和局限性。对于ANN到SNN的转换，它需要长时间的推理来逼近ANN的准确性，从而降低了SNN的优势。使用基于脉冲的BP来训练高精度SNN通常需要比它们的ANN相对应地消耗几十倍的计算资源和时间。在本文中，我们提出了一种结合了两种方法优点的新的SNN训练方法。我们首先通过将神经电位分布近似为随机噪声来训练单步SNN(T=1)，然后无损地将单步SNN(T=1)转换为多步SNN(T=N)。引入高斯分布噪声可以显著提高转换后的精度。",
    "tldr": "本篇论文提出了一种引入噪声的新的SNN训练方法，它结合了ANN到SNN转换和基于脉冲的反向传播，通过训练单步SNN并将其转换为多步SNN来显著提高精度。",
    "en_tdlr": "This paper proposes a novel SNN training approach that combines the advantages of ANN-to-SNN conversion and spike-based backpropagation by training a single-step SNN with random noise and converting it to a multi-step lossless SNN, leading to significant improvement in accuracy."
}