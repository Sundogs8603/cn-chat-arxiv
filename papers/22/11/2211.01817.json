{
    "title": "Liability regimes in the age of AI: a use-case driven analysis of the burden of proof. (arXiv:2211.01817v2 [cs.AI] UPDATED)",
    "abstract": "New emerging technologies powered by Artificial Intelligence (AI) have the potential to disruptively transform our societies for the better. In particular, data-driven learning approaches (i.e., Machine Learning (ML)) have been a true revolution in the advancement of multiple technologies in various application domains. But at the same time there is growing concern about certain intrinsic characteristics of these methodologies that carry potential risks to both safety and fundamental rights. Although there are mechanisms in the adoption process to minimize these risks (e.g., safety regulations), these do not exclude the possibility of harm occurring, and if this happens, victims should be able to seek compensation. Liability regimes will therefore play a key role in ensuring basic protection for victims using or interacting with these systems. However, the same characteristics that make AI systems inherently risky, such as lack of causality, opacity, unpredictability or their self and ",
    "link": "http://arxiv.org/abs/2211.01817",
    "context": "Title: Liability regimes in the age of AI: a use-case driven analysis of the burden of proof. (arXiv:2211.01817v2 [cs.AI] UPDATED)\nAbstract: New emerging technologies powered by Artificial Intelligence (AI) have the potential to disruptively transform our societies for the better. In particular, data-driven learning approaches (i.e., Machine Learning (ML)) have been a true revolution in the advancement of multiple technologies in various application domains. But at the same time there is growing concern about certain intrinsic characteristics of these methodologies that carry potential risks to both safety and fundamental rights. Although there are mechanisms in the adoption process to minimize these risks (e.g., safety regulations), these do not exclude the possibility of harm occurring, and if this happens, victims should be able to seek compensation. Liability regimes will therefore play a key role in ensuring basic protection for victims using or interacting with these systems. However, the same characteristics that make AI systems inherently risky, such as lack of causality, opacity, unpredictability or their self and ",
    "path": "papers/22/11/2211.01817.json",
    "total_tokens": 1034,
    "translated_title": "AI时代的责任制度：基于用例的证明负担分析",
    "translated_abstract": "由人工智能（AI）驱动的新兴技术有可能为我们的社会带来颠覆性的转型，并推进各种应用领域的多项技术的发展，其中数据驱动的学习方法（即机器学习（ML））是一次真正的革命。但与此同时，人们越来越关注这些方法学固有的某些特征，这些特征可能对安全和基本权利带来潜在风险。尽管在采用过程中有机制来最小化这些风险（例如安全规定），但这并不排除损害发生的可能，如果这种情况发生，受害者应该能够寻求补偿。因此，责任制度将在确保使用或与这些系统交互的受害者的基本保护方面发挥关键作用。然而，使AI系统固有风险的相同特征，例如缺乏因果关系、不透明、不可预测或他们自我和自适应的本质，也使得传统的责任规则难以应用。本文通过对各种用例及其潜在危害的分析，提出了基于用例的责任规则证明负担分析，识别了当前责任规则在AI技术领域面临的挑战，并探讨了改革这些规则的建议。",
    "tldr": "本文通过用例分析探讨了基于AI技术的责任制度下证明负担的挑战和规则改革的建议。",
    "en_tdlr": "This paper analyzes the challenge of burden of proof in the liability regimes related to AI technologies and proposes reforms through a use-case driven approach."
}