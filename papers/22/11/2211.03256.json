{
    "title": "On Web-based Visual Corpus Construction for Visual Document Understanding. (arXiv:2211.03256v2 [cs.CV] UPDATED)",
    "abstract": "In recent years, research on visual document understanding (VDU) has grown significantly, with a particular emphasis on the development of self-supervised learning methods. However, one of the significant challenges faced in this field is the limited availability of publicly accessible visual corpora or extensive collections of images with detailed text annotations, particularly for non-Latin or resource-scarce languages. To address this challenge, we propose Web-based Visual Corpus Builder (Webvicob), a dataset generator engine capable of constructing large-scale, multilingual visual corpora from raw Wikipedia HTML dumps. Our experiments demonstrate that the data generated by Webvicob can be used to train robust VDU models that perform well on various downstream tasks, such as DocVQA and post-OCR parsing. Furthermore, when using a dataset of 1 million images generated by Webvicob, we observed an improvement of over 13% on the DocVQA Task 3 compared to a dataset of 11 million images fr",
    "link": "http://arxiv.org/abs/2211.03256",
    "context": "Title: On Web-based Visual Corpus Construction for Visual Document Understanding. (arXiv:2211.03256v2 [cs.CV] UPDATED)\nAbstract: In recent years, research on visual document understanding (VDU) has grown significantly, with a particular emphasis on the development of self-supervised learning methods. However, one of the significant challenges faced in this field is the limited availability of publicly accessible visual corpora or extensive collections of images with detailed text annotations, particularly for non-Latin or resource-scarce languages. To address this challenge, we propose Web-based Visual Corpus Builder (Webvicob), a dataset generator engine capable of constructing large-scale, multilingual visual corpora from raw Wikipedia HTML dumps. Our experiments demonstrate that the data generated by Webvicob can be used to train robust VDU models that perform well on various downstream tasks, such as DocVQA and post-OCR parsing. Furthermore, when using a dataset of 1 million images generated by Webvicob, we observed an improvement of over 13% on the DocVQA Task 3 compared to a dataset of 11 million images fr",
    "path": "papers/22/11/2211.03256.json",
    "total_tokens": 959,
    "translated_title": "基于Web的视觉语料库构建用于视觉文档理解",
    "translated_abstract": "近年来，关于视觉文档理解（VDU）的研究取得了显著的进展，特别是在自监督学习方法的发展方面。然而，在这个领域面临的一个重要挑战是可公开获取的视觉语料库的有限性，尤其是对于非拉丁语言或资源短缺的语言而言，大规模的图像集合与详细文本注释难以得到。为了解决这一挑战，我们提出了基于Web的视觉语料库构建工具（Webvicob），该工具能够从原始的Wikipedia HTML转储文件中构建大规模的多语言视觉语料库。我们的实验表明，Webvicob生成的数据可用于训练稳健的VDU模型，并在各种下游任务（例如DocVQA和后OCR解析）中表现良好。此外，当使用由Webvicob生成的100万张图像数据集时，我们观察到在DocVQA任务3上相对于COCO-Text数据集的1100万张图像数据集，有超过13％的提升。",
    "tldr": "这篇论文提出了一个基于Web的视觉语料库构建工具（Webvicob），用于从Wikipedia HTML转储文件中构建大规模的、多语言的视觉语料库，通过数据集的使用可以提升视觉文档理解模型的性能。",
    "en_tdlr": "This paper proposes a Web-based visual corpus builder (Webvicob) which can construct large-scale and multilingual visual corpora from raw Wikipedia HTML dumps, and the experiments show that the dataset generated by Webvicob can be used to train robust visual document understanding models that perform well on various downstream tasks."
}