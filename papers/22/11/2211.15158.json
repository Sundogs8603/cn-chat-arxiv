{
    "title": "Heterogeneous Graph Learning for Multi-modal Medical Data Analysis. (arXiv:2211.15158v3 [cs.CV] UPDATED)",
    "abstract": "Routine clinical visits of a patient produce not only image data, but also non-image data containing clinical information regarding the patient, i.e., medical data is multi-modal in nature. Such heterogeneous modalities offer different and complementary perspectives on the same patient, resulting in more accurate clinical decisions when they are properly combined. However, despite its significance, how to effectively fuse the multi-modal medical data into a unified framework has received relatively little attention. In this paper, we propose an effective graph-based framework called HetMed (Heterogeneous Graph Learning for Multi-modal Medical Data Analysis) for fusing the multi-modal medical data. Specifically, we construct a multiplex network that incorporates multiple types of non-image features of patients to capture the complex relationship between patients in a systematic way, which leads to more accurate clinical decisions. Extensive experiments on various real-world datasets dem",
    "link": "http://arxiv.org/abs/2211.15158",
    "context": "Title: Heterogeneous Graph Learning for Multi-modal Medical Data Analysis. (arXiv:2211.15158v3 [cs.CV] UPDATED)\nAbstract: Routine clinical visits of a patient produce not only image data, but also non-image data containing clinical information regarding the patient, i.e., medical data is multi-modal in nature. Such heterogeneous modalities offer different and complementary perspectives on the same patient, resulting in more accurate clinical decisions when they are properly combined. However, despite its significance, how to effectively fuse the multi-modal medical data into a unified framework has received relatively little attention. In this paper, we propose an effective graph-based framework called HetMed (Heterogeneous Graph Learning for Multi-modal Medical Data Analysis) for fusing the multi-modal medical data. Specifically, we construct a multiplex network that incorporates multiple types of non-image features of patients to capture the complex relationship between patients in a systematic way, which leads to more accurate clinical decisions. Extensive experiments on various real-world datasets dem",
    "path": "papers/22/11/2211.15158.json",
    "total_tokens": 860,
    "translated_title": "多模态医学数据分析的异构图学习",
    "translated_abstract": "病人的常规临床访问不仅会产生图像数据，还会包含有关病人的临床信息等非图像数据，即医学数据的多模态性质。这样的异构模态提供了不同和互补的病人视角，当它们被正确地组合时，可以导致更准确的临床决策。然而，尽管其重要性，如何将多模态医学数据有效地融合到统一框架中却受到了相对较少的关注。本文提出了一种名为HetMed（多模态医学数据分析的异构图学习）的有效图形框架，用于融合多模态医学数据。具体而言，我们构建一个包括多种病人非图像特征的多重网络，以系统化方式捕获病人之间的复杂关系，从而导致更准确的临床决策。大量实验结果表明，与最先进的方法相比，我们的方法具有更优越性。",
    "tldr": "该论文提出了一种名为HetMed的异构图学习框架，用于融合多模态医学数据，以提高临床决策的准确性。",
    "en_tdlr": "This paper proposes a graph-based framework called HetMed for fusing multi-modal medical data to improve the accuracy of clinical decisions."
}