{
    "title": "Data-free Defense of Black Box Models Against Adversarial Attacks. (arXiv:2211.01579v2 [cs.LG] UPDATED)",
    "abstract": "Several companies often safeguard their trained deep models (i.e., details of architecture, learnt weights, training details etc.) from third-party users by exposing them only as black boxes through APIs. Moreover, they may not even provide access to the training data due to proprietary reasons or sensitivity concerns. In this work, we propose a novel defense mechanism for black box models against adversarial attacks in a data-free set up. We construct synthetic data via generative model and train surrogate network using model stealing techniques. To minimize adversarial contamination on perturbed samples, we propose 'wavelet noise remover' (WNR) that performs discrete wavelet decomposition on input images and carefully select only a few important coefficients determined by our 'wavelet coefficient selection module' (WCSM). To recover the high-frequency content of the image after noise removal via WNR, we further train a 'regenerator' network with the objective of retrieving the coeffi",
    "link": "http://arxiv.org/abs/2211.01579",
    "context": "Title: Data-free Defense of Black Box Models Against Adversarial Attacks. (arXiv:2211.01579v2 [cs.LG] UPDATED)\nAbstract: Several companies often safeguard their trained deep models (i.e., details of architecture, learnt weights, training details etc.) from third-party users by exposing them only as black boxes through APIs. Moreover, they may not even provide access to the training data due to proprietary reasons or sensitivity concerns. In this work, we propose a novel defense mechanism for black box models against adversarial attacks in a data-free set up. We construct synthetic data via generative model and train surrogate network using model stealing techniques. To minimize adversarial contamination on perturbed samples, we propose 'wavelet noise remover' (WNR) that performs discrete wavelet decomposition on input images and carefully select only a few important coefficients determined by our 'wavelet coefficient selection module' (WCSM). To recover the high-frequency content of the image after noise removal via WNR, we further train a 'regenerator' network with the objective of retrieving the coeffi",
    "path": "papers/22/11/2211.01579.json",
    "total_tokens": 898,
    "translated_title": "无数据情况下对黑盒模型进行防御的方法",
    "translated_abstract": "许多公司通过API仅将训练好的深度模型作为黑盒暴露给第三方用户，以保护模型的细节（如架构、学习权重、训练细节等）。本研究提出了一种针对黑盒模型在无数据情况下进行对抗攻击的新型防御机制。我们通过生成模型构建合成数据，并使用模型窃取技术训练替代模型网络。为了最小化扰动样本上的对抗性污染，我们提出了“小波噪声去除器”(WNR)，它在输入图像上执行离散小波分解，并仅选择我们的“小波系数选择模块”(WCSM)确定的少数重要系数。为了在通过WNR去除噪声后恢复图像的高频内容，我们进一步训练了一个“再生器”网络，目标是恢复系数。",
    "tldr": "本研究提出了一种无数据情况下对黑盒模型进行防御的方法，通过生成模型构建合成数据，并使用模型窃取技术训练替代模型网络，同时采用小波噪声去除器（WNR）减少对抗性污染。",
    "en_tdlr": "This paper proposes a defense mechanism for black box models against adversarial attacks in a data-free setup. Synthetic data is generated and a surrogate network is trained using model stealing techniques. The use of a wavelet noise remover (WNR) helps to minimize adversarial contamination on perturbed samples."
}