{
    "title": "MMD-B-Fair: Learning Fair Representations with Statistical Testing. (arXiv:2211.07907v2 [stat.ML] UPDATED)",
    "abstract": "We introduce a method, MMD-B-Fair, to learn fair representations of data via kernel two-sample testing. We find neural features of our data where a maximum mean discrepancy (MMD) test cannot distinguish between representations of different sensitive groups, while preserving information about the target attributes. Minimizing the power of an MMD test is more difficult than maximizing it (as done in previous work), because the test threshold's complex behavior cannot be simply ignored. Our method exploits the simple asymptotics of block testing schemes to efficiently find fair representations without requiring complex adversarial optimization or generative modelling schemes widely used by existing work on fair representation learning. We evaluate our approach on various datasets, showing its ability to ``hide'' information about sensitive attributes, and its effectiveness in downstream transfer tasks.",
    "link": "http://arxiv.org/abs/2211.07907",
    "context": "Title: MMD-B-Fair: Learning Fair Representations with Statistical Testing. (arXiv:2211.07907v2 [stat.ML] UPDATED)\nAbstract: We introduce a method, MMD-B-Fair, to learn fair representations of data via kernel two-sample testing. We find neural features of our data where a maximum mean discrepancy (MMD) test cannot distinguish between representations of different sensitive groups, while preserving information about the target attributes. Minimizing the power of an MMD test is more difficult than maximizing it (as done in previous work), because the test threshold's complex behavior cannot be simply ignored. Our method exploits the simple asymptotics of block testing schemes to efficiently find fair representations without requiring complex adversarial optimization or generative modelling schemes widely used by existing work on fair representation learning. We evaluate our approach on various datasets, showing its ability to ``hide'' information about sensitive attributes, and its effectiveness in downstream transfer tasks.",
    "path": "papers/22/11/2211.07907.json",
    "total_tokens": 726,
    "translated_title": "基于统计检验的MMD-B-Fair：学习公平的表示",
    "translated_abstract": "我们提出了一种通过核双样本测试学习数据公平表示的方法MMD-B-Fair。我们找到了数据的神经特征，其中最大平均偏差（MMD）测试无法区分不同敏感组的表示，同时保留有关目标属性的信息。我们的方法利用块测试方案的简单渐近性能够有效地找到公平表示，而不需要使用现有公平表示学习方法中广泛使用的复杂对抗性优化或生成建模方案。我们在各种数据集上评估了我们的方法，显示其能够“隐藏”有关敏感属性的信息，并在下游传输任务中的有效性。",
    "tldr": "提出了一种基于统计检验的 MMD-B-Fair 方法，用于学习公平的数据表示，并在各种数据集上得到了验证。",
    "en_tdlr": "MMD-B-Fair is a method proposed for learning fair representations of data via kernel two-sample testing, which exploits the simple asymptotics of block testing schemes to efficiently find fair representations without requiring complex adversarial optimization or generative modelling schemes."
}