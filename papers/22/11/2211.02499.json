{
    "title": "A Weakly-Supervised Streaming Multilingual Speech Model with Truly Zero-Shot Capability. (arXiv:2211.02499v2 [cs.CL] UPDATED)",
    "abstract": "In this paper, we introduce our work of building a Streaming Multilingual Speech Model (SM2), which can transcribe or translate multiple spoken languages into texts of the target language. The backbone of SM2 is Transformer Transducer, which has high streaming capability. Instead of human labeled speech translation (ST) data, SM2 models are trained using weakly supervised data generated by converting the transcriptions in speech recognition corpora with a machine translation service. With 351 thousand hours of anonymized speech training data from 25 languages, SM2 models achieve comparable or even better ST quality than some recent popular large-scale non-streaming speech models. More importantly, we show that SM2 has the truly zero-shot capability when expanding to new target languages, yielding high quality ST results for {source-speech, target-text} pairs that are not seen during training.",
    "link": "http://arxiv.org/abs/2211.02499",
    "context": "Title: A Weakly-Supervised Streaming Multilingual Speech Model with Truly Zero-Shot Capability. (arXiv:2211.02499v2 [cs.CL] UPDATED)\nAbstract: In this paper, we introduce our work of building a Streaming Multilingual Speech Model (SM2), which can transcribe or translate multiple spoken languages into texts of the target language. The backbone of SM2 is Transformer Transducer, which has high streaming capability. Instead of human labeled speech translation (ST) data, SM2 models are trained using weakly supervised data generated by converting the transcriptions in speech recognition corpora with a machine translation service. With 351 thousand hours of anonymized speech training data from 25 languages, SM2 models achieve comparable or even better ST quality than some recent popular large-scale non-streaming speech models. More importantly, we show that SM2 has the truly zero-shot capability when expanding to new target languages, yielding high quality ST results for {source-speech, target-text} pairs that are not seen during training.",
    "path": "papers/22/11/2211.02499.json",
    "total_tokens": 888,
    "translated_title": "具有真正零-shot能力的弱监督流式多语言语音模型",
    "translated_abstract": "本文介绍了我们构建的流式多语言语音模型（SM2）的工作，该模型可以将多种口语语言转录或翻译为目标语言的文本。SM2的核心是Transformer Transducer，具有高度流式处理能力。我们使用通过机器翻译服务将语音识别语料库中的转录转化而成的弱监督数据来训练SM2模型，而非人工标记的语音翻译数据。利用来自25种语言的35.1万小时的匿名语音训练数据，SM2模型的语音翻译质量与某些最新的大规模非流式语音模型相当甚至更好。更重要的是，我们展示了当扩展到新的目标语言时，SM2具有真正的零-shot能力，可以为训练过程中未见过的{源语音，目标文本}对产生高质量的语音翻译结果。",
    "tldr": "本文介绍了一个弱监督流式多语言语音模型，利用机器翻译服务将语音识别转录转化为弱监督数据来训练模型。该模型具有真正的零-shot能力，可以在扩展到新的目标语言时产生高质量的语音翻译结果。",
    "en_tdlr": "This paper introduces a weakly-supervised streaming multilingual speech model, trained using machine translated weakly supervised data, that has truly zero-shot capability and can generate high-quality speech translation results when expanding to new target languages."
}