{
    "title": "Markovian Gaussian Process Variational Autoencoders. (arXiv:2207.05543v3 [cs.LG] UPDATED)",
    "abstract": "Sequential VAEs have been successfully considered for many high-dimensional time series modelling problems, with many variant models relying on discrete-time mechanisms such as recurrent neural networks (RNNs). On the other hand, continuous-time methods have recently gained attraction, especially in the context of irregularly-sampled time series, where they can better handle the data than discrete-time methods. One such class are Gaussian process variational autoencoders (GPVAEs), where the VAE prior is set as a Gaussian process (GP). However, a major limitation of GPVAEs is that it inherits the cubic computational cost as GPs, making it unattractive to practioners. In this work, we leverage the equivalent discrete state space representation of Markovian GPs to enable linear time GPVAE training via Kalman filtering and smoothing. For our model, Markovian GPVAE (MGPVAE), we show on a variety of high-dimensional temporal and spatiotemporal tasks that our method performs favourably compar",
    "link": "http://arxiv.org/abs/2207.05543",
    "context": "Title: Markovian Gaussian Process Variational Autoencoders. (arXiv:2207.05543v3 [cs.LG] UPDATED)\nAbstract: Sequential VAEs have been successfully considered for many high-dimensional time series modelling problems, with many variant models relying on discrete-time mechanisms such as recurrent neural networks (RNNs). On the other hand, continuous-time methods have recently gained attraction, especially in the context of irregularly-sampled time series, where they can better handle the data than discrete-time methods. One such class are Gaussian process variational autoencoders (GPVAEs), where the VAE prior is set as a Gaussian process (GP). However, a major limitation of GPVAEs is that it inherits the cubic computational cost as GPs, making it unattractive to practioners. In this work, we leverage the equivalent discrete state space representation of Markovian GPs to enable linear time GPVAE training via Kalman filtering and smoothing. For our model, Markovian GPVAE (MGPVAE), we show on a variety of high-dimensional temporal and spatiotemporal tasks that our method performs favourably compar",
    "path": "papers/22/07/2207.05543.json",
    "total_tokens": 992,
    "translated_title": "马尔科夫高斯过程变分自编码器",
    "translated_abstract": "在许多高维时间序列建模问题中，序列VAE已经被广泛应用，其中许多变种模型依赖于离散时间机制，如循环神经网络（RNN）。另一方面，连续时间方法最近在非规则采样时间序列的背景下引起了人们的兴趣，在这种情况下，它们可以更好地处理数据。其中一种是高斯过程变分自编码器（GPVAEs），其中VAE先验被设置为高斯过程（GP）。然而，GPVAEs的一个主要限制是它继承了高斯过程的立方计算成本，使其对实际应用者不太吸引人。在这项工作中，我们利用马尔科夫高斯过程的等效离散状态空间表示，通过卡尔曼滤波和平滑来实现线性时间的GPVAE训练。对于我们的模型，马尔可夫高斯过程变分自编码器（MGPVAE），我们在各种高维时间和时空任务上展示了我们的方法的有利性能。",
    "tldr": "本文提出了一种马尔科夫高斯过程变分自编码器（MGPVAE）模型，通过利用马尔科夫高斯过程的等效离散状态空间表示，并使用卡尔曼滤波和平滑技术实现了线性时间的GPVAE训练。在各种高维时间和时空任务中，该方法表现优异。",
    "en_tdlr": "This paper proposes a Markovian Gaussian Process Variational Autoencoder (MGPVAE) model, which leverages the equivalent discrete state space representation of Markovian GPs and achieves linear time GPVAE training using Kalman filtering and smoothing techniques. The method performs favorably on various high-dimensional temporal and spatiotemporal tasks."
}