{
    "title": "A Survey of Learning on Small Data: Generalization, Optimization, and Challenge. (arXiv:2207.14443v2 [cs.LG] UPDATED)",
    "abstract": "Learning on big data brings success for artificial intelligence (AI), but the annotation and training costs are expensive. In future, learning on small data that approximates the generalization ability of big data is one of the ultimate purposes of AI, which requires machines to recognize objectives and scenarios relying on small data as humans. A series of learning topics is going on this way such as active learning and few-shot learning. However, there are few theoretical guarantees for their generalization performance. Moreover, most of their settings are passive, that is, the label distribution is explicitly controlled by finite training resources from known distributions. This survey follows the agnostic active sampling theory under a PAC (Probably Approximately Correct) framework to analyze the generalization error and label complexity of learning on small data in model-agnostic supervised and unsupervised fashion. Considering multiple learning communities could produce small dat",
    "link": "http://arxiv.org/abs/2207.14443",
    "context": "Title: A Survey of Learning on Small Data: Generalization, Optimization, and Challenge. (arXiv:2207.14443v2 [cs.LG] UPDATED)\nAbstract: Learning on big data brings success for artificial intelligence (AI), but the annotation and training costs are expensive. In future, learning on small data that approximates the generalization ability of big data is one of the ultimate purposes of AI, which requires machines to recognize objectives and scenarios relying on small data as humans. A series of learning topics is going on this way such as active learning and few-shot learning. However, there are few theoretical guarantees for their generalization performance. Moreover, most of their settings are passive, that is, the label distribution is explicitly controlled by finite training resources from known distributions. This survey follows the agnostic active sampling theory under a PAC (Probably Approximately Correct) framework to analyze the generalization error and label complexity of learning on small data in model-agnostic supervised and unsupervised fashion. Considering multiple learning communities could produce small dat",
    "path": "papers/22/07/2207.14443.json",
    "total_tokens": 1120,
    "translated_title": "小数据学习综述：泛化、优化和挑战",
    "translated_abstract": "在人工智能取得了成功的今天，大规模数据学习带来的标注和训练成本是非常昂贵的。在未来，利用小数据进行学习以逼近大数据的泛化能力是人工智能的终极目标之一，这需要机器能够像人类一样在少量数据中识别目标和场景。目前的研究方向主要包括主动学习和少样本学习，但是它们的泛化性能缺乏理论保证，大多数设置为被动学习，即已知分布下有限的训练资源中控制标签分布。本综述采用以 PAC (Probably Approximately Correct) 框架下的不可知主动采样理论来分析模型无关监督和非监督小数据学习中的泛化误差和标签复杂度。考虑到不同目的的多个学习社区都可以产生小数据，我们将小数据分为不同大小和复杂度的光谱。然后，我们回顾了一系列针对小数据的学习方法，包括主动学习、少样本学习、元学习和无监督学习，以及它们相关的挑战，如领域自适应、类别不平衡和标签噪音。最后，我们总结了小数据学习的潜在研究方向。",
    "tldr": "小数据学习综述，包括主动学习、少样本学习、元学习和无监督学习等方面，但它们在泛化性能上缺乏理论保证；考虑到不同目的的多个学习社区都可以产生小数据，我们将小数据分为不同大小和复杂度的光谱。",
    "en_tdlr": "This survey provides an overview of small data learning, including active learning, few-shot learning, meta-learning, and unsupervised learning, but they lack theoretical guarantees on generalization performance. Small data is categorized into a spectrum of sizes and complexities based on multiple learning communities that could produce small data for different purposes."
}