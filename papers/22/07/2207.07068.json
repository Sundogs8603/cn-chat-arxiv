{
    "title": "Bias Mitigation for Machine Learning Classifiers: A Comprehensive Survey. (arXiv:2207.07068v4 [cs.LG] UPDATED)",
    "abstract": "This paper provides a comprehensive survey of bias mitigation methods for achieving fairness in Machine Learning (ML) models. We collect a total of 341 publications concerning bias mitigation for ML classifiers. These methods can be distinguished based on their intervention procedure (i.e., pre-processing, in-processing, post-processing) and the technique they apply. We investigate how existing bias mitigation methods are evaluated in the literature. In particular, we consider datasets, metrics and benchmarking. Based on the gathered insights (e.g., What is the most popular fairness metric? How many datasets are used for evaluating bias mitigation methods?), we hope to support practitioners in making informed choices when developing and evaluating new bias mitigation methods.",
    "link": "http://arxiv.org/abs/2207.07068",
    "context": "Title: Bias Mitigation for Machine Learning Classifiers: A Comprehensive Survey. (arXiv:2207.07068v4 [cs.LG] UPDATED)\nAbstract: This paper provides a comprehensive survey of bias mitigation methods for achieving fairness in Machine Learning (ML) models. We collect a total of 341 publications concerning bias mitigation for ML classifiers. These methods can be distinguished based on their intervention procedure (i.e., pre-processing, in-processing, post-processing) and the technique they apply. We investigate how existing bias mitigation methods are evaluated in the literature. In particular, we consider datasets, metrics and benchmarking. Based on the gathered insights (e.g., What is the most popular fairness metric? How many datasets are used for evaluating bias mitigation methods?), we hope to support practitioners in making informed choices when developing and evaluating new bias mitigation methods.",
    "path": "papers/22/07/2207.07068.json",
    "total_tokens": 841,
    "translated_title": "机器学习分类器的偏差缓解：一项全面调研",
    "translated_abstract": "本文对实现机器学习模型中的公平性的偏差缓解方法进行了全面调研。我们收集了总计341篇关于机器学习分类器偏差缓解的研究论文。这些方法可以根据它们的干预过程（预处理、处处理、后处理）和应用技术进行区分。我们调查了现有的偏差缓解方法在文献中的评估方式。特别是，我们考虑了数据集、评估指标和基准测试。基于所收集到的见解（例如，最流行的公平性指标是什么？有多少数据集用于评估偏差缓解方法？），我们希望能够支持从业者在开发和评估新的偏差缓解方法时作出明智的选择。",
    "tldr": "这项研究提供了一份全面调研，总结了机器学习模型中实现公平性的偏差缓解方法。通过对341篇论文进行分析，研究了不同的干预过程和应用技术，并调查了评估方法。这将为从业者在开发和评估新的偏差缓解方法时提供有益的指导。",
    "en_tdlr": "This study presents a comprehensive survey on bias mitigation methods in achieving fairness in Machine Learning models. By analyzing 341 publications, this research investigates various intervention procedures and techniques, as well as evaluation methods. It aims to provide valuable insights for practitioners in developing and evaluating new bias mitigation methods."
}