{
    "title": "Statistical and Computational Trade-offs in Variational Inference: A Case Study in Inferential Model Selection. (arXiv:2207.11208v2 [stat.ML] UPDATED)",
    "abstract": "Variational inference has recently emerged as a popular alternative to the classical Markov chain Monte Carlo (MCMC) in large-scale Bayesian inference. The core idea is to trade statistical accuracy for computational efficiency. In this work, we study these statistical and computational trade-offs in variational inference via a case study in inferential model selection. Focusing on Gaussian inferential models (or variational approximating families) with diagonal plus low-rank precision matrices, we initiate a theoretical study of the trade-offs in two aspects, Bayesian posterior inference error and frequentist uncertainty quantification error. From the Bayesian posterior inference perspective, we characterize the error of the variational posterior relative to the exact posterior. We prove that, given a fixed computation budget, a lower-rank inferential model produces variational posteriors with a higher statistical approximation error, but a lower computational error; it reduces varian",
    "link": "http://arxiv.org/abs/2207.11208",
    "context": "Title: Statistical and Computational Trade-offs in Variational Inference: A Case Study in Inferential Model Selection. (arXiv:2207.11208v2 [stat.ML] UPDATED)\nAbstract: Variational inference has recently emerged as a popular alternative to the classical Markov chain Monte Carlo (MCMC) in large-scale Bayesian inference. The core idea is to trade statistical accuracy for computational efficiency. In this work, we study these statistical and computational trade-offs in variational inference via a case study in inferential model selection. Focusing on Gaussian inferential models (or variational approximating families) with diagonal plus low-rank precision matrices, we initiate a theoretical study of the trade-offs in two aspects, Bayesian posterior inference error and frequentist uncertainty quantification error. From the Bayesian posterior inference perspective, we characterize the error of the variational posterior relative to the exact posterior. We prove that, given a fixed computation budget, a lower-rank inferential model produces variational posteriors with a higher statistical approximation error, but a lower computational error; it reduces varian",
    "path": "papers/22/07/2207.11208.json",
    "total_tokens": 919,
    "translated_title": "变分推断中的统计和计算权衡：推理模型选择中的案例研究",
    "translated_abstract": "变分推断最近在大规模贝叶斯推断中成为了传统马尔可夫链蒙特卡洛(MCMC)的热门替代方法。其核心思想是通过权衡统计准确性和计算效率。本文通过一个推理模型选择的案例研究，研究了变分推断中的统计和计算权衡。我们着重研究了具有对角加低秩精度矩阵的高斯推理模型（或变分逼近家族）中的这种权衡的两个方面：贝叶斯后验推断误差和频率主义不确定性量化误差。从贝叶斯后验推断的角度，我们表征了变分后验相对于精确后验的误差。我们证明，在固定的计算预算下，低秩推断模型产生具有更高统计逼近误差但更低计算误差的变分后验。",
    "tldr": "本文通过一个推理模型选择的案例研究，研究了变分推断中的统计和计算权衡。在高斯推理模型中，我们发现，低秩推断模型在固定计算预算下产生了更高的统计近似误差，但较低的计算误差。",
    "en_tdlr": "This paper studies the statistical and computational trade-offs in variational inference through a case study in inferential model selection. Specifically, in Gaussian inferential models, it is found that lower-rank models have higher statistical approximation error but lower computational error under a fixed computation budget."
}