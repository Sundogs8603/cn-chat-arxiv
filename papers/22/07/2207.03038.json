{
    "title": "Dual-Stream Transformer for Generic Event Boundary Captioning. (arXiv:2207.03038v2 [cs.CV] UPDATED)",
    "abstract": "This paper describes our champion solution for the CVPR2022 Generic Event Boundary Captioning (GEBC) competition. GEBC requires the captioning model to have a comprehension of instantaneous status changes around the given video boundary, which makes it much more challenging than conventional video captioning task. In this paper, a Dual-Stream Transformer with improvements on both video content encoding and captions generation is proposed: (1) We utilize three pre-trained models to extract the video features from different granularities. Moreover, we exploit the types of boundary as hints to help the model generate captions. (2) We particularly design an model, termed as Dual-Stream Transformer, to learn discriminative representations for boundary captioning. (3) Towards generating content-relevant and human-like captions, we improve the description quality by designing a word-level ensemble strategy. The promising results on the GEBC test split demonstrate the efficacy of our proposed ",
    "link": "http://arxiv.org/abs/2207.03038",
    "context": "Title: Dual-Stream Transformer for Generic Event Boundary Captioning. (arXiv:2207.03038v2 [cs.CV] UPDATED)\nAbstract: This paper describes our champion solution for the CVPR2022 Generic Event Boundary Captioning (GEBC) competition. GEBC requires the captioning model to have a comprehension of instantaneous status changes around the given video boundary, which makes it much more challenging than conventional video captioning task. In this paper, a Dual-Stream Transformer with improvements on both video content encoding and captions generation is proposed: (1) We utilize three pre-trained models to extract the video features from different granularities. Moreover, we exploit the types of boundary as hints to help the model generate captions. (2) We particularly design an model, termed as Dual-Stream Transformer, to learn discriminative representations for boundary captioning. (3) Towards generating content-relevant and human-like captions, we improve the description quality by designing a word-level ensemble strategy. The promising results on the GEBC test split demonstrate the efficacy of our proposed ",
    "path": "papers/22/07/2207.03038.json",
    "total_tokens": 879,
    "translated_title": "基于双流Transformer的通用事件边界字幕生成",
    "translated_abstract": "本文介绍了我们参加CVPR2022通用事件边界字幕生成比赛的优胜解决方案。该任务要求字幕生成模型在给定视频边界周围能够理解瞬时状态变化，使其比传统视频字幕生成任务更具挑战性。文章提出了一种双流Transformer，改进了视频内容编码和字幕生成两个方面：(1)我们利用三个预训练模型从不同粒度提取视频特征。此外，我们利用边界类型作为提示，帮助模型生成字幕。(2)我们特别设计一个称为双流Transformer的模型，以学习区分性边界字幕表示。(3)为了生成与内容相关且更加人性化的字幕，我们通过设计一个单词级别的集成策略来改善描述质量。在GEBC测试集上前景不俗的结果证明了我们提出的方法的有效性。",
    "tldr": "本文提出了一种双流Transformer的通用事件边界字幕生成方法，结合多个预训练模型和边界类型提示，以及单词级别的集成策略，实现了生成更人性化的字幕，并在GEBC测试集上取得了令人满意的结果。",
    "en_tdlr": "This paper proposes a dual-stream transformer for generic event boundary captioning, which combines pre-trained models and boundary type hints to generate more human-like captions with a word-level ensemble strategy. The results on the GEBC test split demonstrate the effectiveness of the proposed method."
}