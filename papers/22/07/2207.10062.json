{
    "title": "DataPerf: Benchmarks for Data-Centric AI Development. (arXiv:2207.10062v2 [cs.LG] UPDATED)",
    "abstract": "Machine learning research has long focused on models rather than datasets, and prominent datasets are used for common ML tasks without regard to the breadth, difficulty, and faithfulness of the underlying problems. Neglecting the fundamental importance of data has given rise to inaccuracy, bias, and fragility in real-world applications, and research is hindered by saturation across existing dataset benchmarks. In response, we present DataPerf, a community-led benchmark suite for evaluating ML datasets and data-centric algorithms. We aim to foster innovation in data-centric AI through competition, comparability, and reproducibility. We enable the ML community to iterate on datasets, instead of just architectures, and we provide an open, online platform with multiple rounds of challenges to support this iterative development. The first iteration of DataPerf contains five benchmarks covering a wide spectrum of data-centric techniques, tasks, and modalities in vision, speech, acquisition, ",
    "link": "http://arxiv.org/abs/2207.10062",
    "context": "Title: DataPerf: Benchmarks for Data-Centric AI Development. (arXiv:2207.10062v2 [cs.LG] UPDATED)\nAbstract: Machine learning research has long focused on models rather than datasets, and prominent datasets are used for common ML tasks without regard to the breadth, difficulty, and faithfulness of the underlying problems. Neglecting the fundamental importance of data has given rise to inaccuracy, bias, and fragility in real-world applications, and research is hindered by saturation across existing dataset benchmarks. In response, we present DataPerf, a community-led benchmark suite for evaluating ML datasets and data-centric algorithms. We aim to foster innovation in data-centric AI through competition, comparability, and reproducibility. We enable the ML community to iterate on datasets, instead of just architectures, and we provide an open, online platform with multiple rounds of challenges to support this iterative development. The first iteration of DataPerf contains five benchmarks covering a wide spectrum of data-centric techniques, tasks, and modalities in vision, speech, acquisition, ",
    "path": "papers/22/07/2207.10062.json",
    "total_tokens": 868,
    "translated_title": "DataPerf：数据中心人工智能开发的基准测试",
    "translated_abstract": "长期以来，机器学习研究一直注重模型而不是数据集，并且著名数据集被用于常见的机器学习任务，而忽视了底层问题的广度、难度和准确性。忽视数据的重要性导致了现实应用中的不准确性、偏见和脆弱性，并且现有的数据集基准测试已经达到了饱和状态，阻碍了研究的进展。为此，我们提出了DataPerf，这是一个由社区主导的评估机器学习数据集和数据中心算法的基准测试套件。我们旨在通过竞争、可比性和可重复性促进数据中心人工智能的创新。我们使机器学习社区能够迭代数据集，而不仅仅是架构，并提供一个开放的在线平台，以支持这种迭代开发。DataPerf的第一个迭代包含了五个基准测试，涵盖了视觉、语音、获取等多种数据中心技术、任务和模态。",
    "tldr": "DataPerf是一个由社区主导的基准测试套件，旨在通过竞争、可比性和可重复性促进数据中心人工智能的创新。",
    "en_tdlr": "DataPerf is a community-led benchmark suite that aims to foster innovation in data-centric AI through competition, comparability, and reproducibility."
}