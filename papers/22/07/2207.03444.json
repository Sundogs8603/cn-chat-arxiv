{
    "title": "Fairness and Bias in Robot Learning. (arXiv:2207.03444v2 [cs.RO] UPDATED)",
    "abstract": "Machine learning has significantly enhanced the abilities of robots, enabling them to perform a wide range of tasks in human environments and adapt to our uncertain real world. Recent works in various machine learning domains have highlighted the importance of accounting for fairness to ensure that these algorithms do not reproduce human biases and consequently lead to discriminatory outcomes. With robot learning systems increasingly performing more and more tasks in our everyday lives, it is crucial to understand the influence of such biases to prevent unintended behavior toward certain groups of people. In this work, we present the first survey on fairness in robot learning from an interdisciplinary perspective spanning technical, ethical, and legal challenges. We propose a taxonomy for sources of bias and the resulting types of discrimination due to them. Using examples from different robot learning domains, we examine scenarios of unfair outcomes and strategies to mitigate them. We",
    "link": "http://arxiv.org/abs/2207.03444",
    "context": "Title: Fairness and Bias in Robot Learning. (arXiv:2207.03444v2 [cs.RO] UPDATED)\nAbstract: Machine learning has significantly enhanced the abilities of robots, enabling them to perform a wide range of tasks in human environments and adapt to our uncertain real world. Recent works in various machine learning domains have highlighted the importance of accounting for fairness to ensure that these algorithms do not reproduce human biases and consequently lead to discriminatory outcomes. With robot learning systems increasingly performing more and more tasks in our everyday lives, it is crucial to understand the influence of such biases to prevent unintended behavior toward certain groups of people. In this work, we present the first survey on fairness in robot learning from an interdisciplinary perspective spanning technical, ethical, and legal challenges. We propose a taxonomy for sources of bias and the resulting types of discrimination due to them. Using examples from different robot learning domains, we examine scenarios of unfair outcomes and strategies to mitigate them. We",
    "path": "papers/22/07/2207.03444.json",
    "total_tokens": 874,
    "translated_title": "机器人学习中的公平性和偏见",
    "translated_abstract": "机器学习显著增强了机器人的能力，使它们能够在人类环境中执行各种任务并适应我们不确定的真实世界。最近各个机器学习领域的研究强调了考虑公平性的重要性，以确保这些算法不会重复人类的偏见，并因此导致具有歧视性的结果。随着机器人学习系统在我们日常生活中执行越来越多的任务，了解这种偏见的影响以防止对某些人群产生意外行为至关重要。在这项工作中，我们从技术、伦理和法律挑战的跨学科角度提出了机器人学习中公平性的首次调查。我们提出了偏见来源的分类法和由它们引起的歧视类型。通过不同机器人学习领域的示例，我们探讨了不公平结果的场景和缓解策略。",
    "tldr": "本文从技术、伦理和法律角度出发，首次调查了机器人学习中的公平性问题。提出了偏见来源的分类法和由其引起的歧视类型，并探讨了不同机器人学习领域中不公平结果的场景和缓解策略。"
}