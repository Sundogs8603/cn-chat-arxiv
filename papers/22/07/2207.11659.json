{
    "title": "Training Robust Spiking Neural Networks on Neuromorphic Data with Spatiotemporal Fragments. (arXiv:2207.11659v3 [cs.CV] UPDATED)",
    "abstract": "Neuromorphic vision sensors (event cameras) are inherently suitable for spiking neural networks (SNNs) and provide novel neuromorphic vision data for this biomimetic model. Due to the spatiotemporal characteristics, novel data augmentations are required to process the unconventional visual signals of these cameras. In this paper, we propose a novel Event SpatioTemporal Fragments (ESTF) augmentation method. It preserves the continuity of neuromorphic data by drifting or inverting fragments of the spatiotemporal event stream to simulate the disturbance of brightness variations, leading to more robust spiking neural networks. Extensive experiments are performed on prevailing neuromorphic datasets. It turns out that ESTF provides substantial improvements over pure geometric transformations and outperforms other event data augmentation methods. It is worth noting that the SNNs with ESTF achieve the state-of-the-art accuracy of 83.9\\% on the CIFAR10-DVS dataset.",
    "link": "http://arxiv.org/abs/2207.11659",
    "context": "Title: Training Robust Spiking Neural Networks on Neuromorphic Data with Spatiotemporal Fragments. (arXiv:2207.11659v3 [cs.CV] UPDATED)\nAbstract: Neuromorphic vision sensors (event cameras) are inherently suitable for spiking neural networks (SNNs) and provide novel neuromorphic vision data for this biomimetic model. Due to the spatiotemporal characteristics, novel data augmentations are required to process the unconventional visual signals of these cameras. In this paper, we propose a novel Event SpatioTemporal Fragments (ESTF) augmentation method. It preserves the continuity of neuromorphic data by drifting or inverting fragments of the spatiotemporal event stream to simulate the disturbance of brightness variations, leading to more robust spiking neural networks. Extensive experiments are performed on prevailing neuromorphic datasets. It turns out that ESTF provides substantial improvements over pure geometric transformations and outperforms other event data augmentation methods. It is worth noting that the SNNs with ESTF achieve the state-of-the-art accuracy of 83.9\\% on the CIFAR10-DVS dataset.",
    "path": "papers/22/07/2207.11659.json",
    "total_tokens": 935,
    "translated_title": "使用时空片段在神经形态数据上训练鲁棒性脉冲神经网络",
    "translated_abstract": "神经形态视觉传感器（事件相机）天生适合脉冲神经网络（SNN），为这种仿生模型提供了新颖的神经形态视觉数据。由于时空特性，需要使用新颖的数据增强方法处理这些相机的非传统视觉信号。本文提出了一种新颖的事件时空片段（ESTF）增强方法。通过漂移或反转时空事件流的片段来模拟亮度变化的干扰，以此保留神经形态数据的连续性，从而提高脉冲神经网络的鲁棒性。在流行的神经形态数据集上进行了大量实验，结果表明ESTF比纯几何变换的方法提供了实质性改进，并且优于其他事件数据增强方法。值得注意的是，使用ESTF的SNN在CIFAR10-DVS数据集上实现了最先进的83.9\\%的准确度。",
    "tldr": "本文介绍了一种新颖的事件时空片段（ESTF）增强方法，可用于处理神经形态视觉数据，并提高使用SNN处理这些数据时的鲁棒性。使用ESTF的SNN在CIFAR10-DVS数据集上实现了最先进的83.9\\%准确度。",
    "en_tdlr": "This paper proposes a novel Event SpatioTemporal Fragments (ESTF) augmentation method to process neuromorphic vision data and improve the robustness of using SNN. SNNs with ESTF achieve the state-of-the-art accuracy of 83.9% on the CIFAR10-DVS dataset."
}