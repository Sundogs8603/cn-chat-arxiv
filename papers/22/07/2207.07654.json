{
    "title": "Learning inducing points and uncertainty on molecular data by scalable variational Gaussian processes",
    "abstract": "arXiv:2207.07654v3 Announce Type: replace-cross  Abstract: Uncertainty control and scalability to large datasets are the two main issues for the deployment of Gaussian process (GP) models within the autonomous machine learning-based prediction pipelines in material science and chemistry. One way to address both of these issues is by introducing the latent inducing point variables and choosing the right approximation for the marginal log-likelihood objective. Here, we empirically show that variational learning of the inducing points in a molecular descriptor space improves the prediction of energies and atomic forces on two molecular dynamics datasets. First, we show that variational GPs can learn to represent the configurations of the molecules of different types that were not present within the initialization set of configurations. We provide a comparison of alternative log-likelihood training objectives and variational distributions. Among several evaluated approximate marginal log-l",
    "link": "https://arxiv.org/abs/2207.07654",
    "context": "Title: Learning inducing points and uncertainty on molecular data by scalable variational Gaussian processes\nAbstract: arXiv:2207.07654v3 Announce Type: replace-cross  Abstract: Uncertainty control and scalability to large datasets are the two main issues for the deployment of Gaussian process (GP) models within the autonomous machine learning-based prediction pipelines in material science and chemistry. One way to address both of these issues is by introducing the latent inducing point variables and choosing the right approximation for the marginal log-likelihood objective. Here, we empirically show that variational learning of the inducing points in a molecular descriptor space improves the prediction of energies and atomic forces on two molecular dynamics datasets. First, we show that variational GPs can learn to represent the configurations of the molecules of different types that were not present within the initialization set of configurations. We provide a comparison of alternative log-likelihood training objectives and variational distributions. Among several evaluated approximate marginal log-l",
    "path": "papers/22/07/2207.07654.json",
    "total_tokens": 768,
    "translated_title": "通过可扩展的变分高斯过程在分子数据上学习引导点和不确定性",
    "translated_abstract": "不确定性控制和可扩展性是在材料科学和化学中部署高斯过程（GP）模型到自主机器学习预测管道中的两个主要问题。引入潜在的引导点变量并选择合适的近似以获得边缘对数似然目标是解决这两个问题的一种方法。本文在分子描述符空间中经验性地展示了通过变分学习引导点可以提高两个分子动力学数据集上能量和原子力的预测性能。首先，我们表明变分高斯过程可以学习表示初始化集合中不存在的不同类型分子的构型。我们提供了不同训练目标和变分分布的比较。在评估了几种近似边缘对数似然的训练目标和变分分布后",
    "tldr": "通过引入潜在的引导点变量并选择合适的边缘对数似然目标，可在分子描述符空间中改进预测性能。",
    "en_tdlr": "Improved predictive performance in molecular descriptor space by introducing latent inducing point variables and selecting appropriate marginal log-likelihood objective."
}