{
    "title": "The prediction of the quality of results in Logic Synthesis using Transformer and Graph Neural Networks. (arXiv:2207.11437v2 [cs.AR] UPDATED)",
    "abstract": "In the logic synthesis stage, structure transformations in the synthesis tool need to be combined into optimization sequences and act on the circuit to meet the specified circuit area and delay. However, logic synthesis optimization sequences are time-consuming to run, and predicting the quality of the results (QoR) against the synthesis optimization sequence for a circuit can help engineers find a better optimization sequence faster. In this work, we propose a deep learning method to predict the QoR of unseen circuit-optimization sequences pairs. Specifically, the structure transformations are translated into vectors by embedding methods and advanced natural language processing (NLP) technology (Transformer) is used to extract the features of the optimization sequences. In addition, to enable the prediction process of the model to be generalized from circuit to circuit, the graph representation of the circuit is represented as an adjacency matrix and a feature matrix. Graph neural net",
    "link": "http://arxiv.org/abs/2207.11437",
    "context": "Title: The prediction of the quality of results in Logic Synthesis using Transformer and Graph Neural Networks. (arXiv:2207.11437v2 [cs.AR] UPDATED)\nAbstract: In the logic synthesis stage, structure transformations in the synthesis tool need to be combined into optimization sequences and act on the circuit to meet the specified circuit area and delay. However, logic synthesis optimization sequences are time-consuming to run, and predicting the quality of the results (QoR) against the synthesis optimization sequence for a circuit can help engineers find a better optimization sequence faster. In this work, we propose a deep learning method to predict the QoR of unseen circuit-optimization sequences pairs. Specifically, the structure transformations are translated into vectors by embedding methods and advanced natural language processing (NLP) technology (Transformer) is used to extract the features of the optimization sequences. In addition, to enable the prediction process of the model to be generalized from circuit to circuit, the graph representation of the circuit is represented as an adjacency matrix and a feature matrix. Graph neural net",
    "path": "papers/22/07/2207.11437.json",
    "total_tokens": 919,
    "translated_title": "使用Transformer和图神经网络预测逻辑综合结果的质量",
    "translated_abstract": "在逻辑综合阶段，综合工具中的结构转换需要与优化序列结合，并作用于电路，以满足指定的电路面积和延迟。然而，逻辑综合优化序列的运行时间较长，为电路对综合优化序列的结果质量（QoR）进行预测可以帮助工程师更快地找到更好的优化序列。在这项工作中，我们提出了一种深度学习方法，用于预测未见过的电路-优化序列对的QoR。具体而言，通过嵌入方法将结构转换转化为向量，并利用先进的自然语言处理（NLP）技术（Transformer）提取优化序列的特征。此外，为了使模型的预测过程能够从电路泛化到电路，电路的图表示被表示为邻接矩阵和特征矩阵。图神经网络被用于学习电路的图表示和预测QoR。",
    "tldr": "该论文介绍了一种使用Transformer和图神经网络预测逻辑综合结果质量的深度学习方法，通过将结构转换表示为向量并提取优化序列的特征，以及利用图神经网络学习电路的图表示和预测QoR。",
    "en_tdlr": "This paper presents a deep learning method using Transformer and Graph Neural Networks to predict the quality of results in logic synthesis. By translating structure transformations into vectors and extracting features of optimization sequences, as well as utilizing Graph Neural Networks to learn the graph representation of circuits and predict QoR, the proposed method enables faster and better optimization sequence selection."
}