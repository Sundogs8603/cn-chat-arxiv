{
    "title": "Federated Unlearning: How to Efficiently Erase a Client in FL?. (arXiv:2207.05521v3 [cs.LG] UPDATED)",
    "abstract": "With privacy legislation empowering the users with the right to be forgotten, it has become essential to make a model amenable for forgetting some of its training data. However, existing unlearning methods in the machine learning context can not be directly applied in the context of distributed settings like federated learning due to the differences in learning protocol and the presence of multiple actors. In this paper, we tackle the problem of federated unlearning for the case of erasing a client by removing the influence of their entire local data from the trained global model. To erase a client, we propose to first perform local unlearning at the client to be erased, and then use the locally unlearned model as the initialization to run very few rounds of federated learning between the server and the remaining clients to obtain the unlearned global model. We empirically evaluate our unlearning method by employing multiple performance measures on three datasets, and demonstrate that ",
    "link": "http://arxiv.org/abs/2207.05521",
    "context": "Title: Federated Unlearning: How to Efficiently Erase a Client in FL?. (arXiv:2207.05521v3 [cs.LG] UPDATED)\nAbstract: With privacy legislation empowering the users with the right to be forgotten, it has become essential to make a model amenable for forgetting some of its training data. However, existing unlearning methods in the machine learning context can not be directly applied in the context of distributed settings like federated learning due to the differences in learning protocol and the presence of multiple actors. In this paper, we tackle the problem of federated unlearning for the case of erasing a client by removing the influence of their entire local data from the trained global model. To erase a client, we propose to first perform local unlearning at the client to be erased, and then use the locally unlearned model as the initialization to run very few rounds of federated learning between the server and the remaining clients to obtain the unlearned global model. We empirically evaluate our unlearning method by employing multiple performance measures on three datasets, and demonstrate that ",
    "path": "papers/22/07/2207.05521.json",
    "total_tokens": 875,
    "translated_title": "联邦遗忘：如何高效地从FL中删除客户？",
    "translated_abstract": "随着隐私法规赋予用户被遗忘权，使模型能够遗忘部分训练数据变得至关重要。然而，现有的机器学习上的遗忘方法不能直接应用于联邦学习等分布式环境下，因为学习协议的差异和多个参与者的存在。在本文中，我们解决了联邦学习中删除客户的问题，通过从全局模型中删除客户的整个本地数据的影响。为了删除一个客户，我们建议首先在要删除的客户端执行本地遗忘，然后使用本地遗忘的模型作为初始化，在服务器和剩余客户之间进行少量轮次的联邦学习，以获得遗忘的全局模型。我们通过在三个数据集上采用多种性能指标对我们的遗忘方法进行了实证评估，并证明了其有效性。",
    "tldr": "本文介绍了在联邦学习中如何高效地删除客户的问题，并提出了一种联邦遗忘的方法，通过在客户端执行本地遗忘并结合少量轮次的联邦学习来获得遗忘的全局模型。",
    "en_tdlr": "This paper addresses the problem of efficiently deleting clients in federated learning and proposes a method called federated unlearning, which combines local unlearning at the client level and a few rounds of federated learning to obtain the unlearned global model."
}