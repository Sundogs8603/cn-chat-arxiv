{
    "title": "Simple and Efficient Heterogeneous Graph Neural Network. (arXiv:2207.02547v3 [cs.LG] UPDATED)",
    "abstract": "Heterogeneous graph neural networks (HGNNs) have powerful capability to embed rich structural and semantic information of a heterogeneous graph into node representations. Existing HGNNs inherit many mechanisms from graph neural networks (GNNs) over homogeneous graphs, especially the attention mechanism and the multi-layer structure. These mechanisms bring excessive complexity, but seldom work studies whether they are really effective on heterogeneous graphs. This paper conducts an in-depth and detailed study of these mechanisms and proposes Simple and Efficient Heterogeneous Graph Neural Network (SeHGNN). To easily capture structural information, SeHGNN pre-computes the neighbor aggregation using a light-weight mean aggregator, which reduces complexity by removing overused neighbor attention and avoiding repeated neighbor aggregation in every training epoch. To better utilize semantic information, SeHGNN adopts the single-layer structure with long metapaths to extend the receptive fiel",
    "link": "http://arxiv.org/abs/2207.02547",
    "context": "Title: Simple and Efficient Heterogeneous Graph Neural Network. (arXiv:2207.02547v3 [cs.LG] UPDATED)\nAbstract: Heterogeneous graph neural networks (HGNNs) have powerful capability to embed rich structural and semantic information of a heterogeneous graph into node representations. Existing HGNNs inherit many mechanisms from graph neural networks (GNNs) over homogeneous graphs, especially the attention mechanism and the multi-layer structure. These mechanisms bring excessive complexity, but seldom work studies whether they are really effective on heterogeneous graphs. This paper conducts an in-depth and detailed study of these mechanisms and proposes Simple and Efficient Heterogeneous Graph Neural Network (SeHGNN). To easily capture structural information, SeHGNN pre-computes the neighbor aggregation using a light-weight mean aggregator, which reduces complexity by removing overused neighbor attention and avoiding repeated neighbor aggregation in every training epoch. To better utilize semantic information, SeHGNN adopts the single-layer structure with long metapaths to extend the receptive fiel",
    "path": "papers/22/07/2207.02547.json",
    "total_tokens": 845,
    "translated_title": "简单高效的异构图神经网络",
    "translated_abstract": "异构图神经网络（HGNNs）能够将异构图的丰富结构和语义信息嵌入节点表示中。现有的HGNNs从同质图神经网络中继承了许多机制，尤其是注意力机制和多层结构。然而很少有研究探讨这些机制是否在异构图上真正有效。本文进行了深入而详细的研究，并提出了简单高效的异构图神经网络（SeHGNN）。为了轻松捕捉结构信息，SeHGNN使用轻量级的均值聚合器预先计算邻居聚合，通过去除过度使用的邻居注意力和避免在每个训练周期中重复进行邻居聚合来降低复杂性。为了更好地利用语义信息，SeHGNN采用具有长浏览路径的单层结构来扩展感受野。",
    "tldr": "SeHGNN是一个简单高效的异构图神经网络，通过轻量级的均值聚合器预先计算邻居聚合来捕捉结构信息，采用单层结构和长浏览路径来更好地利用语义信息。",
    "en_tdlr": "SeHGNN is a simple and efficient heterogeneous graph neural network that captures structural information by pre-computing neighbor aggregation using a lightweight mean aggregator and utilizes semantic information through a single-layer structure with long metapaths."
}