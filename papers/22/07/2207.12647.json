{
    "title": "Cross-Modal Causal Relational Reasoning for Event-Level Visual Question Answering. (arXiv:2207.12647v5 [cs.CV] UPDATED)",
    "abstract": "Existing visual question answering methods tend to capture the cross-modal spurious correlations and fail to discover the true causal mechanism that facilitates reasoning truthfully based on the dominant visual evidence and the question intention. Additionally, the existing methods usually ignore the cross-modal event-level understanding that requires to jointly model event temporality, causality, and dynamics. In this work, we focus on event-level visual question answering from a new perspective, i.e., cross-modal causal relational reasoning, by introducing causal intervention methods to discover the true causal structures for visual and linguistic modalities. Specifically, we propose a novel event-level visual question answering framework named Cross-Modal Causal RelatIonal Reasoning (CMCIR), to achieve robust causality-aware visual-linguistic question answering. To discover cross-modal causal structures, the Causality-aware Visual-Linguistic Reasoning (CVLR) module is proposed to co",
    "link": "http://arxiv.org/abs/2207.12647",
    "context": "Title: Cross-Modal Causal Relational Reasoning for Event-Level Visual Question Answering. (arXiv:2207.12647v5 [cs.CV] UPDATED)\nAbstract: Existing visual question answering methods tend to capture the cross-modal spurious correlations and fail to discover the true causal mechanism that facilitates reasoning truthfully based on the dominant visual evidence and the question intention. Additionally, the existing methods usually ignore the cross-modal event-level understanding that requires to jointly model event temporality, causality, and dynamics. In this work, we focus on event-level visual question answering from a new perspective, i.e., cross-modal causal relational reasoning, by introducing causal intervention methods to discover the true causal structures for visual and linguistic modalities. Specifically, we propose a novel event-level visual question answering framework named Cross-Modal Causal RelatIonal Reasoning (CMCIR), to achieve robust causality-aware visual-linguistic question answering. To discover cross-modal causal structures, the Causality-aware Visual-Linguistic Reasoning (CVLR) module is proposed to co",
    "path": "papers/22/07/2207.12647.json",
    "total_tokens": 903,
    "translated_title": "跨模态因果关系推理在事件级视觉问答中的应用",
    "translated_abstract": "现有的视觉问答方法往往捕捉跨模态的伪相关性，而未能发现真正的因果机制，以真实地基于主导视觉证据和问题意图进行推理。此外，现有方法通常忽略了跨模态事件级理解，需要联合建模事件的时间性、因果性和动态性。在本文中，我们从新的角度，即跨模态因果关系推理，聚焦于事件级视觉问答，引入因果干预方法来发现视觉和语言模态的真正因果结构。具体而言，我们提出了一个名为跨模态因果关系推理（CMCIR）的新型事件级视觉问答框架，以实现强健的因果感知视觉语言问答。为了发现跨模态因果结构，我们提出了因果感知视觉语言推理（CVLR）模块，用于共同对视觉和语言模态建模。",
    "tldr": "本篇论文提出了一个新型的事件级视觉问答框架——跨模态因果关系推理（CMCIR），通过引入因果干预方法，发现视觉和语言模态的真正因果结构，实现强健的因果感知视觉语言问答。",
    "en_tdlr": "This paper proposes a novel event-level visual question answering framework, Cross-Modal Causal Relational Reasoning (CMCIR), which introduces causal intervention methods to discover the true causal structures for visual and linguistic modalities, achieving robust causality-aware visual-linguistic question answering."
}