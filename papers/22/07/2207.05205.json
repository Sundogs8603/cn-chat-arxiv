{
    "title": "Scaling Novel Object Detection with Weakly Supervised Detection Transformers. (arXiv:2207.05205v2 [cs.CV] UPDATED)",
    "abstract": "A critical object detection task is finetuning an existing model to detect novel objects, but the standard workflow requires bounding box annotations which are time-consuming and expensive to collect. Weakly supervised object detection (WSOD) offers an appealing alternative, where object detectors can be trained using image-level labels. However, the practical application of current WSOD models is limited, as they only operate at small data scales and require multiple rounds of training and refinement. To address this, we propose the Weakly Supervised Detection Transformer, which enables efficient knowledge transfer from a large-scale pretraining dataset to WSOD finetuning on hundreds of novel objects. Additionally, we leverage pretrained knowledge to improve the multiple instance learning (MIL) framework often used in WSOD methods. Our experiments show that our approach outperforms previous state-of-the-art models on large-scale novel object detection datasets, and our scaling study r",
    "link": "http://arxiv.org/abs/2207.05205",
    "context": "Title: Scaling Novel Object Detection with Weakly Supervised Detection Transformers. (arXiv:2207.05205v2 [cs.CV] UPDATED)\nAbstract: A critical object detection task is finetuning an existing model to detect novel objects, but the standard workflow requires bounding box annotations which are time-consuming and expensive to collect. Weakly supervised object detection (WSOD) offers an appealing alternative, where object detectors can be trained using image-level labels. However, the practical application of current WSOD models is limited, as they only operate at small data scales and require multiple rounds of training and refinement. To address this, we propose the Weakly Supervised Detection Transformer, which enables efficient knowledge transfer from a large-scale pretraining dataset to WSOD finetuning on hundreds of novel objects. Additionally, we leverage pretrained knowledge to improve the multiple instance learning (MIL) framework often used in WSOD methods. Our experiments show that our approach outperforms previous state-of-the-art models on large-scale novel object detection datasets, and our scaling study r",
    "path": "papers/22/07/2207.05205.json",
    "total_tokens": 961,
    "translated_title": "利用弱监督检测变形器扩展新型物品检测",
    "translated_abstract": "目标检测中一个关键任务是微调现有模型以便检测新型物品，但标注边界框需要耗费大量的时间和金钱。弱监督目标检测可以通过使用图像级别标签来训练物品检测器，它提供了一种吸引人的替代方法。然而，当前弱监督模型的实际应用受到限制，因为它们仅适用于小规模数据，并需要多次训练和改进。为了解决这个问题，我们提出了弱监督检测变形器，它能够将大规模预训练数据集的知识有效地转移至数百种新型物品的WSOD微调中。此外，我们还利用预训练知识来改进在WSOD方法中常用的多实例学习（MIL）框架。实验证明，我们的方法在大规模新型物品检测数据集上优于先前的最先进模型，并且我们的扩展研究…",
    "tldr": "本篇文章提出了一个新方法：弱监督检测变形器（Weakly Supervised Detection Transformer），可以有效地将大规模预训练数据集的知识转移至数百种新型物品的WSOD微调中，同时提高了多实例学习的准确性。实验结果表明，该方法优于现有的先进模型，在大规模新型物品检测数据集上达到了更好的性能。",
    "en_tdlr": "This paper proposes a new method called Weakly Supervised Detection Transformer, which can efficiently transfer knowledge from a large pretraining dataset to WSOD fine-tuning on hundreds of novel objects, while improving the accuracy of multiple instance learning. Experimental results show that this method outperforms state-of-the-art models and achieves better performance on large-scale novel object detection datasets."
}