{
    "title": "Bootstrap Latent Representations for Multi-modal Recommendation. (arXiv:2207.05969v3 [cs.IR] UPDATED)",
    "abstract": "This paper studies the multi-modal recommendation problem, where the item multi-modality information (e.g., images and textual descriptions) is exploited to improve the recommendation accuracy. Besides the user-item interaction graph, existing state-of-the-art methods usually use auxiliary graphs (e.g., user-user or item-item relation graph) to augment the learned representations of users and/or items. These representations are often propagated and aggregated on auxiliary graphs using graph convolutional networks, which can be prohibitively expensive in computation and memory, especially for large graphs. Moreover, existing multi-modal recommendation methods usually leverage randomly sampled negative examples in Bayesian Personalized Ranking (BPR) loss to guide the learning of user/item representations, which increases the computational cost on large graphs and may also bring noisy supervision signals into the training process. To tackle the above issues, we propose a novel self-superv",
    "link": "http://arxiv.org/abs/2207.05969",
    "context": "Title: Bootstrap Latent Representations for Multi-modal Recommendation. (arXiv:2207.05969v3 [cs.IR] UPDATED)\nAbstract: This paper studies the multi-modal recommendation problem, where the item multi-modality information (e.g., images and textual descriptions) is exploited to improve the recommendation accuracy. Besides the user-item interaction graph, existing state-of-the-art methods usually use auxiliary graphs (e.g., user-user or item-item relation graph) to augment the learned representations of users and/or items. These representations are often propagated and aggregated on auxiliary graphs using graph convolutional networks, which can be prohibitively expensive in computation and memory, especially for large graphs. Moreover, existing multi-modal recommendation methods usually leverage randomly sampled negative examples in Bayesian Personalized Ranking (BPR) loss to guide the learning of user/item representations, which increases the computational cost on large graphs and may also bring noisy supervision signals into the training process. To tackle the above issues, we propose a novel self-superv",
    "path": "papers/22/07/2207.05969.json",
    "total_tokens": 945,
    "translated_title": "多模态推荐中的 Bootstrap 潜在表示法",
    "translated_abstract": "本文研究了多模态推荐问题，其中利用物品的多模态信息（例如图像和文本描述）来提高推荐准确性。针对现有的最先进方法通常使用辅助图形（例如用户-用户或物品-物品关系图）来增强用户和/或物品的学习表示，本文提出了一种名为自助潜在表示（BLR）的新型自监督方法，可以结合学习用户/物品表示和图形结构。同时，为了减轻噪声监督信号的问题，我们提出了一种自举采样策略来有效地对待正负样本。在三个真实世界数据集上的大量实验表明，我们提出的方法在推荐精度和效率方面都优于现有最先进的方法。",
    "tldr": "本文提出了一种名为自助潜在表示（BLR）的新型自监督方法，它可以在不涉及辅助图形的情况下增强用户/物品表示并有效地对待正负样本，从而提高了多模态推荐的准确性和效率。",
    "en_tdlr": "This paper proposes a novel self-supervised method called Bootstrap Latent Representations (BLR) to enhance user/item representations without involving extra computation on auxiliary graphs, and to treat positive and negative samples equally and effectively, thus improving the accuracy and efficiency of multi-modal recommendation."
}