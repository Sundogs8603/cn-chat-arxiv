{
    "title": "TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second. (arXiv:2207.01848v5 [cs.LG] UPDATED)",
    "abstract": "We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods. TabPFN is fully entailed in the weights of our network, which accepts training and test samples as a set-valued input and yields predictions for the entire test set in a single forward pass. TabPFN is a Prior-Data Fitted Network (PFN) and is trained offline once, to approximate Bayesian inference on synthetic datasets drawn from our prior. This prior incorporates ideas from causal reasoning: It entails a large space of structural causal models with a preference for simple structures. On the 18 datasets in the OpenML-CC18 suite that contain up to 1 000 training data points, up to 100 purely numerical features without missing values, and up to 10 classes, we show that our method clearly outperforms boosted trees and performs on par with complex state-of-the-art AutoM",
    "link": "http://arxiv.org/abs/2207.01848",
    "context": "Title: TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second. (arXiv:2207.01848v5 [cs.LG] UPDATED)\nAbstract: We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods. TabPFN is fully entailed in the weights of our network, which accepts training and test samples as a set-valued input and yields predictions for the entire test set in a single forward pass. TabPFN is a Prior-Data Fitted Network (PFN) and is trained offline once, to approximate Bayesian inference on synthetic datasets drawn from our prior. This prior incorporates ideas from causal reasoning: It entails a large space of structural causal models with a preference for simple structures. On the 18 datasets in the OpenML-CC18 suite that contain up to 1 000 training data points, up to 100 purely numerical features without missing values, and up to 10 classes, we show that our method clearly outperforms boosted trees and performs on par with complex state-of-the-art AutoM",
    "path": "papers/22/07/2207.01848.json",
    "total_tokens": 933,
    "translated_title": "TabPFN：在一秒内解决小型表格分类问题的Transformer",
    "translated_abstract": "本文提出了TabPFN，一种经过训练的Transformer，可以在不到一秒钟的时间内完成小型表格数据集的监督分类，无需超参数调整，并且在分类方法的最新状态下具有竞争力。TabPFN完全包含在我们网络的权重中，接受训练和测试样本作为设置值输入，并在单个前向传递中为整个测试集提供预测。TabPFN是一种先验适应网络（PFN），只需要线下训练一次，即可逼近基于我们的先验的合成数据集上的贝叶斯推断。这个先验融合了因果推理的思想：它包括一个大的结构因果模型空间，偏好于简单结构。在OpenML-CC18套件的18个包含最多1000个训练数据点、最多100个纯数值特征且无缺失值、最多10个类别的数据集中，我们展示了我们的方法明显优于提升树，与复杂的最新AutoM方法表现相当。",
    "tldr": "TabPFN是一种可以在不到一秒钟内完成小型表格数据集的监督分类的Transformer，无需超参数调整，并且具有竞争力。它使用先验适应网络（PFN）逼近基于先验的贝叶斯推断，先验融合了因果推理的思想。",
    "en_tdlr": "TabPFN is a transformer that can complete supervised classification of small tabular datasets in less than a second, without hyperparameter tuning and with competitiveness. It uses a prior-data fitted network (PFN) to approximate Bayesian inference based on prior incorporating causal reasoning ideas."
}