{
    "title": "Vision-and-Language Pretraining. (arXiv:2207.01772v2 [cs.CL] UPDATED)",
    "abstract": "With the burgeoning amount of data of image-text pairs and diversity of Vision-and-Language (V\\&L) tasks, scholars have introduced an abundance of deep learning models in this research domain. Furthermore, in recent years, transfer learning has also shown tremendous success in Computer Vision for tasks such as Image Classification, Object Detection, etc., and in Natural Language Processing for Question Answering, Machine Translation, etc. Inheriting the spirit of Transfer Learning, research works in V\\&L have devised multiple pretraining techniques on large-scale datasets in order to enhance the performance of downstream tasks. The aim of this article is to provide a comprehensive revision of contemporary V\\&L pretraining models. In particular, we categorize and delineate pretraining approaches, along with the summary of state-of-the-art vision-and-language pretrained models. Moreover, a list of training datasets and downstream tasks is supplied to further polish the perspective into V",
    "link": "http://arxiv.org/abs/2207.01772",
    "context": "Title: Vision-and-Language Pretraining. (arXiv:2207.01772v2 [cs.CL] UPDATED)\nAbstract: With the burgeoning amount of data of image-text pairs and diversity of Vision-and-Language (V\\&L) tasks, scholars have introduced an abundance of deep learning models in this research domain. Furthermore, in recent years, transfer learning has also shown tremendous success in Computer Vision for tasks such as Image Classification, Object Detection, etc., and in Natural Language Processing for Question Answering, Machine Translation, etc. Inheriting the spirit of Transfer Learning, research works in V\\&L have devised multiple pretraining techniques on large-scale datasets in order to enhance the performance of downstream tasks. The aim of this article is to provide a comprehensive revision of contemporary V\\&L pretraining models. In particular, we categorize and delineate pretraining approaches, along with the summary of state-of-the-art vision-and-language pretrained models. Moreover, a list of training datasets and downstream tasks is supplied to further polish the perspective into V",
    "path": "papers/22/07/2207.01772.json",
    "total_tokens": 892,
    "tldr": "本文全面回顾当代视觉-语言预训练模型，分类和划分预训练方法，概述了最先进的视觉-语言预训练模型，并提供了一份培训数据集和下游任务清单。",
    "en_tdlr": "This article provides a comprehensive review of contemporary Vision-and-Language pretraining models, including categorization and delineation of pretraining approaches, a summary of state-of-the-art vision-and-language pretrained models, and a list of training datasets and downstream tasks."
}