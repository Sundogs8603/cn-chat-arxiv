{
    "title": "Learning Sparsity-Promoting Regularizers using Bilevel Optimization. (arXiv:2207.08939v2 [cs.LG] UPDATED)",
    "abstract": "We present a method for supervised learning of sparsity-promoting regularizers for denoising signals and images. Sparsity-promoting regularization is a key ingredient in solving modern signal reconstruction problems; however, the operators underlying these regularizers are usually either designed by hand or learned from data in an unsupervised way. The recent success of supervised learning (mainly convolutional neural networks) in solving image reconstruction problems suggests that it could be a fruitful approach to designing regularizers. Towards this end, we propose to denoise signals using a variational formulation with a parametric, sparsity-promoting regularizer, where the parameters of the regularizer are learned to minimize the mean squared error of reconstructions on a training set of ground truth image and measurement pairs. Training involves solving a challenging bilievel optimization problem; we derive an expression for the gradient of the training loss using the closed-form",
    "link": "http://arxiv.org/abs/2207.08939",
    "context": "Title: Learning Sparsity-Promoting Regularizers using Bilevel Optimization. (arXiv:2207.08939v2 [cs.LG] UPDATED)\nAbstract: We present a method for supervised learning of sparsity-promoting regularizers for denoising signals and images. Sparsity-promoting regularization is a key ingredient in solving modern signal reconstruction problems; however, the operators underlying these regularizers are usually either designed by hand or learned from data in an unsupervised way. The recent success of supervised learning (mainly convolutional neural networks) in solving image reconstruction problems suggests that it could be a fruitful approach to designing regularizers. Towards this end, we propose to denoise signals using a variational formulation with a parametric, sparsity-promoting regularizer, where the parameters of the regularizer are learned to minimize the mean squared error of reconstructions on a training set of ground truth image and measurement pairs. Training involves solving a challenging bilievel optimization problem; we derive an expression for the gradient of the training loss using the closed-form",
    "path": "papers/22/07/2207.08939.json",
    "total_tokens": 924,
    "translated_title": "使用双层优化学习稀疏促进正则化器",
    "translated_abstract": "我们提出了一种方法，用于监督学习稀疏促进正则化器来去噪信号和图像。稀疏促进正则化器是解决现代信号重建问题的关键因素；然而，这些正则化器的操作符通常要么是手工设计的，要么是通过无监督方式从数据中学习得到的。监督学习（主要是卷积神经网络）在解决图像重建问题方面取得了最近的成功，这表明它可能是设计正则化器的一种富有成效的方法。为了实现这一目标，我们提出使用变分表达式和参数化的、稀疏促进的正则化器来去噪信号，其中正则化器的参数通过最小化训练集上重建结果与真实图像及测量对的均方误差来学习。训练涉及解决具有挑战性的双层优化问题；我们推导出了训练损失的梯度的闭式表达式",
    "tldr": "本文提出了一种使用双层优化学习稀疏促进正则化器的方法，可以用于去噪信号和图像。通过监督学习的方式，将稀疏促进正则化器的参数学习最小化重建结果误差，从而提高信号重建的效果。",
    "en_tdlr": "This paper proposes a method for learning sparsity-promoting regularizers using bilevel optimization, which can be applied to denoise signals and images. By employing supervised learning, the parameters of the regularizer are learned to minimize the reconstruction error, improving the effectiveness of signal reconstruction."
}