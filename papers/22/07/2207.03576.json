{
    "title": "Robustness Evaluation of Deep Unsupervised Learning Algorithms for Intrusion Detection Systems. (arXiv:2207.03576v2 [cs.CR] UPDATED)",
    "abstract": "Recently, advances in deep learning have been observed in various fields, including computer vision, natural language processing, and cybersecurity. Machine learning (ML) has demonstrated its ability as a potential tool for anomaly detection-based intrusion detection systems to build secure computer networks. Increasingly, ML approaches are widely adopted than heuristic approaches for cybersecurity because they learn directly from data. Data is critical for the development of ML systems, and becomes potential targets for attackers. Basically, data poisoning or contamination is one of the most common techniques used to fool ML models through data. This paper evaluates the robustness of six recent deep learning algorithms for intrusion detection on contaminated data. Our experiments suggest that the state-of-the-art algorithms used in this study are sensitive to data contamination and reveal the importance of self-defense against data perturbation when developing novel models, especially",
    "link": "http://arxiv.org/abs/2207.03576",
    "context": "Title: Robustness Evaluation of Deep Unsupervised Learning Algorithms for Intrusion Detection Systems. (arXiv:2207.03576v2 [cs.CR] UPDATED)\nAbstract: Recently, advances in deep learning have been observed in various fields, including computer vision, natural language processing, and cybersecurity. Machine learning (ML) has demonstrated its ability as a potential tool for anomaly detection-based intrusion detection systems to build secure computer networks. Increasingly, ML approaches are widely adopted than heuristic approaches for cybersecurity because they learn directly from data. Data is critical for the development of ML systems, and becomes potential targets for attackers. Basically, data poisoning or contamination is one of the most common techniques used to fool ML models through data. This paper evaluates the robustness of six recent deep learning algorithms for intrusion detection on contaminated data. Our experiments suggest that the state-of-the-art algorithms used in this study are sensitive to data contamination and reveal the importance of self-defense against data perturbation when developing novel models, especially",
    "path": "papers/22/07/2207.03576.json",
    "total_tokens": 901,
    "translated_title": "深度无监督学习算法对入侵检测系统的鲁棒性评估",
    "translated_abstract": "最近，深度学习在包括计算机视觉、自然语言处理和网络安全等多个领域取得了进展。机器学习已经被证明是建立安全计算机网络的潜在工具，尤其是基于异常检测的入侵检测系统。与启发式方法相比，越来越多的网络安全领域开始广泛采用机器学习方法，因为它们能够直接从数据中进行学习。数据对于机器学习系统的发展至关重要，但也成为了攻击者的潜在目标。数据毒化或污染基本上是一种通过数据欺骗机器学习模型的常用技术之一。本文评估了六种最新的深度学习算法在受污染数据上的鲁棒性。我们的实验表明，本研究中使用的最先进算法对数据污染敏感，同时也揭示了在开发新模型时自我防御对于数据扰动的重要性。",
    "tldr": "本论文评估了六种最新的深度学习算法在受污染数据上的鲁棒性，结果表明这些算法对于数据污染非常敏感，强调了开发新模型时对于数据扰动的自我防御的重要性。"
}