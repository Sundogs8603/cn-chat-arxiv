{
    "title": "Robust Multivariate Time-Series Forecasting: Adversarial Attacks and Defense Mechanisms. (arXiv:2207.09572v3 [cs.LG] UPDATED)",
    "abstract": "This work studies the threats of adversarial attack on multivariate probabilistic forecasting models and viable defense mechanisms. Our studies discover a new attack pattern that negatively impact the forecasting of a target time series via making strategic, sparse (imperceptible) modifications to the past observations of a small number of other time series. To mitigate the impact of such attack, we have developed two defense strategies. First, we extend a previously developed randomized smoothing technique in classification to multivariate forecasting scenarios. Second, we develop an adversarial training algorithm that learns to create adversarial examples and at the same time optimizes the forecasting model to improve its robustness against such adversarial simulation. Extensive experiments on real-world datasets confirm that our attack schemes are powerful and our defense algorithms are more effective compared with baseline defense mechanisms.",
    "link": "http://arxiv.org/abs/2207.09572",
    "context": "Title: Robust Multivariate Time-Series Forecasting: Adversarial Attacks and Defense Mechanisms. (arXiv:2207.09572v3 [cs.LG] UPDATED)\nAbstract: This work studies the threats of adversarial attack on multivariate probabilistic forecasting models and viable defense mechanisms. Our studies discover a new attack pattern that negatively impact the forecasting of a target time series via making strategic, sparse (imperceptible) modifications to the past observations of a small number of other time series. To mitigate the impact of such attack, we have developed two defense strategies. First, we extend a previously developed randomized smoothing technique in classification to multivariate forecasting scenarios. Second, we develop an adversarial training algorithm that learns to create adversarial examples and at the same time optimizes the forecasting model to improve its robustness against such adversarial simulation. Extensive experiments on real-world datasets confirm that our attack schemes are powerful and our defense algorithms are more effective compared with baseline defense mechanisms.",
    "path": "papers/22/07/2207.09572.json",
    "total_tokens": 901,
    "translated_title": "鲁棒性多变量时间序列预测：对抗攻击与防御机制",
    "translated_abstract": "本文研究了对多元概率预测模型的对抗攻击威胁和有效的防御机制。我们的研究发现一种新的攻击模式，通过对少数其他时间序列的过去观测进行战略性的稀疏（不可察觉的）修改，对目标时间序列的预测产生负面影响。为了减轻这种攻击的影响，我们开发了两种防御策略。首先，我们将先前开发的分类随机平滑技术扩展到多元预测场景中。其次，我们开发了一种对抗训练算法，学习创建对抗性示例，同时优化预测模型以提高其对此类对抗模拟的鲁棒性。在真实世界数据集上进行的广泛实验证实了我们的攻击方案强大，我们的防御算法与基线防御机制相比更加有效。",
    "tldr": "本文研究多元概率预测模型的对抗攻击威胁和有效的防御机制，发现稀疏修改其他时间序列的观测对目标时间序列的预测有负面影响，并开发了两种防御策略，实验验证了其有效性。",
    "en_tdlr": "This paper explores the threats of adversarial attack on multivariate probabilistic forecasting models and proposes two viable defense mechanisms, including extending randomized smoothing and developing an adversarial training algorithm. The experiments on real-world datasets confirm the effectiveness of the proposed defense strategies."
}