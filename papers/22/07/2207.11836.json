{
    "title": "Mitigating the Performance Sacrifice in DP-Satisfied Federated Settings through Graph Contrastive Learning. (arXiv:2207.11836v3 [cs.LG] UPDATED)",
    "abstract": "Currently, graph learning models are indispensable tools to help researchers explore graph-structured data. In academia, using sufficient training data to optimize a graph model on a single device is a typical approach for training a capable graph learning model. Due to privacy concerns, however, it is infeasible to do so in real-world scenarios. Federated learning provides a practical means of addressing this limitation by introducing various privacy-preserving mechanisms, such as differential privacy (DP) on the graph edges. However, although DP in federated graph learning can ensure the security of sensitive information represented in graphs, it usually causes the performance of graph learning models to degrade. In this paper, we investigate how DP can be implemented on graph edges and observe a performance decrease in our experiments. In addition, we note that DP on graph edges introduces noise that perturbs graph proximity, which is one of the graph augmentations in graph contrast",
    "link": "http://arxiv.org/abs/2207.11836",
    "context": "Title: Mitigating the Performance Sacrifice in DP-Satisfied Federated Settings through Graph Contrastive Learning. (arXiv:2207.11836v3 [cs.LG] UPDATED)\nAbstract: Currently, graph learning models are indispensable tools to help researchers explore graph-structured data. In academia, using sufficient training data to optimize a graph model on a single device is a typical approach for training a capable graph learning model. Due to privacy concerns, however, it is infeasible to do so in real-world scenarios. Federated learning provides a practical means of addressing this limitation by introducing various privacy-preserving mechanisms, such as differential privacy (DP) on the graph edges. However, although DP in federated graph learning can ensure the security of sensitive information represented in graphs, it usually causes the performance of graph learning models to degrade. In this paper, we investigate how DP can be implemented on graph edges and observe a performance decrease in our experiments. In addition, we note that DP on graph edges introduces noise that perturbs graph proximity, which is one of the graph augmentations in graph contrast",
    "path": "papers/22/07/2207.11836.json",
    "total_tokens": 920,
    "translated_title": "通过图对比学习减轻DP满足的联邦设置中的性能损失",
    "translated_abstract": "目前，图学习模型是帮助研究人员探索图结构化数据的不可或缺的工具。在学术界，使用足够的训练数据在单个设备上优化图模型是训练强大图学习模型的典型方法。然而，由于隐私问题，在实际场景中这样做是不可行的。联邦学习通过引入各种隐私保护机制（例如基于图边的差分隐私），提供了解决这个限制的实际方法。然而，尽管联邦图学习中的差分隐私能确保表示在图中的敏感信息的安全，但通常会导致图学习模型的性能下降。在本文中，我们研究了如何在图边上实现差分隐私，并在实验中观察到性能下降。此外，我们注意到图边上的差分隐私引入噪声扰乱了图的相似性，这是图对比增强的一种方式。",
    "tldr": "本文研究了如何在联邦图学习中实现差分隐私，并观察到性能下降。图边上的差分隐私引入的噪声扰乱了图的相似性，限制了图学习模型的性能。",
    "en_tdlr": "This paper investigates how to implement differential privacy in federated graph learning and observes a performance decrease. The differential privacy on graph edges introduces noise that perturbs graph proximity, which limits the performance of graph learning models."
}