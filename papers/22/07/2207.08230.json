{
    "title": "A Context-Sensitive Word Embedding Approach for The Detection of Troll Tweets. (arXiv:2207.08230v4 [cs.CL] UPDATED)",
    "abstract": "In this study, we aimed to address the growing concern of trolling behavior on social media by developing and evaluating a set of model architectures for the automatic detection of troll tweets. Utilizing deep learning techniques and pre-trained word embedding methods such as BERT, ELMo, and GloVe, we evaluated the performance of each architecture using metrics such as classification accuracy, F1 score, AUC, and precision. Our results indicate that BERT and ELMo embedding methods performed better than the GloVe method, likely due to their ability to provide contextualized word embeddings that better capture the nuances and subtleties of language use in online social media. Additionally, we found that CNN and GRU encoders performed similarly in terms of F1 score and AUC, suggesting their effectiveness in extracting relevant information from input text. The best-performing method was found to be an ELMo-based architecture that employed a GRU classifier, with an AUC score of 0.929. This r",
    "link": "http://arxiv.org/abs/2207.08230",
    "context": "Title: A Context-Sensitive Word Embedding Approach for The Detection of Troll Tweets. (arXiv:2207.08230v4 [cs.CL] UPDATED)\nAbstract: In this study, we aimed to address the growing concern of trolling behavior on social media by developing and evaluating a set of model architectures for the automatic detection of troll tweets. Utilizing deep learning techniques and pre-trained word embedding methods such as BERT, ELMo, and GloVe, we evaluated the performance of each architecture using metrics such as classification accuracy, F1 score, AUC, and precision. Our results indicate that BERT and ELMo embedding methods performed better than the GloVe method, likely due to their ability to provide contextualized word embeddings that better capture the nuances and subtleties of language use in online social media. Additionally, we found that CNN and GRU encoders performed similarly in terms of F1 score and AUC, suggesting their effectiveness in extracting relevant information from input text. The best-performing method was found to be an ELMo-based architecture that employed a GRU classifier, with an AUC score of 0.929. This r",
    "path": "papers/22/07/2207.08230.json",
    "total_tokens": 949,
    "translated_title": "一种基于上下文敏感的单词嵌入方法用于检测恶意推文",
    "translated_abstract": "本研究旨在通过开发和评估一组模型架构来自动检测 troll 推文，从而解决社交媒体上滋扰行为日趋严重的问题。我们利用深度学习技术和预训练的单词嵌入方法，如BERT、ELMo和GloVe，使用分类准确度、F1得分、AUC和精确度等指标评估了每个架构的性能。结果表明，BERT和ELMo嵌入方法表现优于GloVe方法，可能是因为它们能够提供更好地捕捉在线社交媒体语言使用细微差别的上下文化单词嵌入。此外，我们还发现CNN和GRU编码器在F1分数和AUC方面表现相似，表明它们在从输入文本中提取相关信息方面具有有效性。最佳表现方法是基于ELMo的架构，采用了一个GRU分类器，具有0.929的AUC得分。",
    "tldr": "本研究开发了一种基于上下文敏感的单词嵌入方法用于自动检测 troll 推文，结果表明采用ELMo和BERT嵌入方法的性能更好，最佳表现方法为基于ELMo的架构，采用了一个GRU分类器，具有0.929的AUC得分。",
    "en_tdlr": "This study developed a context-sensitive word embedding approach for automatic detection of troll tweets. Results showed that ELMo and BERT embedding methods performed better, and the best-performing method utilized an ELMo-based architecture with a GRU classifier and achieved an AUC score of 0.929."
}