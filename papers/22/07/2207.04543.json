{
    "title": "Challenging Common Assumptions about Catastrophic Forgetting. (arXiv:2207.04543v2 [cs.LG] UPDATED)",
    "abstract": "Building learning agents that can progressively learn and accumulate knowledge is the core goal of the continual learning (CL) research field. Unfortunately, training a model on new data usually compromises the performance on past data. In the CL literature, this effect is referred to as catastrophic forgetting (CF). CF has been largely studied, and a plethora of methods have been proposed to address it on short sequences of non-overlapping tasks. In such setups, CF always leads to a quick and significant drop in performance in past tasks. Nevertheless, despite CF, recent work showed that SGD training on linear models accumulates knowledge in a CL regression setup. This phenomenon becomes especially visible when tasks reoccur. We might then wonder if DNNs trained with SGD or any standard gradient-based optimization accumulate knowledge in such a way. Such phenomena would have interesting consequences for applying DNNs to real continual scenarios. Indeed, standard gradient-based optimiz",
    "link": "http://arxiv.org/abs/2207.04543",
    "context": "Title: Challenging Common Assumptions about Catastrophic Forgetting. (arXiv:2207.04543v2 [cs.LG] UPDATED)\nAbstract: Building learning agents that can progressively learn and accumulate knowledge is the core goal of the continual learning (CL) research field. Unfortunately, training a model on new data usually compromises the performance on past data. In the CL literature, this effect is referred to as catastrophic forgetting (CF). CF has been largely studied, and a plethora of methods have been proposed to address it on short sequences of non-overlapping tasks. In such setups, CF always leads to a quick and significant drop in performance in past tasks. Nevertheless, despite CF, recent work showed that SGD training on linear models accumulates knowledge in a CL regression setup. This phenomenon becomes especially visible when tasks reoccur. We might then wonder if DNNs trained with SGD or any standard gradient-based optimization accumulate knowledge in such a way. Such phenomena would have interesting consequences for applying DNNs to real continual scenarios. Indeed, standard gradient-based optimiz",
    "path": "papers/22/07/2207.04543.json",
    "total_tokens": 1271,
    "translated_title": "挑战关于灾难性遗忘的常见假设",
    "translated_abstract": "建立能够逐步学习和积累知识的学习智能体是连续学习(CL)研究领域的核心目标。然而，将模型训练在新数据上通常会损害过去数据的性能。在CL文献中，这种效应被称为灾难性遗忘(CF)。尽管CF已被广泛研究，且已提出了大量方法来解决非重叠任务短序列的CF问题，但在这种设置下，CF总是导致过去任务的性能迅速而显著地下降。然而，最近的工作表明，在CL回归设置下，SGD训练线性模型可以累积知识。当任务重新发生时，这种现象尤为明显。我们可能会想知道，是否使用SGD或任何标准梯度下降优化方法训练的DNNs会以这种方式积累知识。这些现象会对将DNNs应用于真实的连续情境产生有趣的影响。实际上，标准的梯度下降优化技术被广泛使用，并为大规模问题提供高效的训练策略。在这项工作中，我们挑战常见的DNNs遭受CF的假设，并提出当前的优化技术可以缓解这种现象。我们展示了在回归任务上使用SGD训练的DNNs可以积累知识，即使任务重新出现，也不会遗忘过去的知识。我们在实际数据集上的实验表明，这种知识积累可以改善在未见任务上的泛化性能。",
    "tldr": "本文挑战了DNNs遭受灾难性遗忘的常见假设，提出当前优化技术可以缓解这种现象。我们的实验表明，使用标准梯度下降优化方法训练的DNNs在回归任务上可以积累知识，即使任务重新出现，也不会遗忘过去的知识，这种知识积累可以改善在未见任务上的泛化性能。",
    "en_tdlr": "This paper challenges the common assumption that DNNs suffer from catastrophic forgetting (CF) and proposes that current optimization techniques can alleviate this phenomenon. The experiments show that DNNs trained with the standard gradient-based optimization method can accumulate knowledge even when tasks reoccur without forgetting past knowledge, which can improve generalization performance on unseen tasks."
}