{
    "title": "Predicting Out-of-Domain Generalization with Neighborhood Invariance. (arXiv:2207.02093v3 [cs.LG] UPDATED)",
    "abstract": "Developing and deploying machine learning models safely depends on the ability to characterize and compare their abilities to generalize to new environments. Although recent work has proposed a variety of methods that can directly predict or theoretically bound the generalization capacity of a model, they rely on strong assumptions such as matching train/test distributions and access to model gradients. In order to characterize generalization when these assumptions are not satisfied, we propose neighborhood invariance, a measure of a classifier's output invariance in a local transformation neighborhood. Specifically, we sample a set of transformations and given an input test point, calculate the invariance as the largest fraction of transformed points classified into the same class. Crucially, our measure is simple to calculate, does not depend on the test point's true label, makes no assumptions about the data distribution or model, and can be applied even in out-of-domain (OOD) setti",
    "link": "http://arxiv.org/abs/2207.02093",
    "context": "Title: Predicting Out-of-Domain Generalization with Neighborhood Invariance. (arXiv:2207.02093v3 [cs.LG] UPDATED)\nAbstract: Developing and deploying machine learning models safely depends on the ability to characterize and compare their abilities to generalize to new environments. Although recent work has proposed a variety of methods that can directly predict or theoretically bound the generalization capacity of a model, they rely on strong assumptions such as matching train/test distributions and access to model gradients. In order to characterize generalization when these assumptions are not satisfied, we propose neighborhood invariance, a measure of a classifier's output invariance in a local transformation neighborhood. Specifically, we sample a set of transformations and given an input test point, calculate the invariance as the largest fraction of transformed points classified into the same class. Crucially, our measure is simple to calculate, does not depend on the test point's true label, makes no assumptions about the data distribution or model, and can be applied even in out-of-domain (OOD) setti",
    "path": "papers/22/07/2207.02093.json",
    "total_tokens": 858,
    "translated_title": "使用邻域不变性预测域外泛化",
    "translated_abstract": "安全地开发和部署机器学习模型取决于对其泛化能力在新环境中的特征和比较能力。尽管最近的工作提出了一系列可以直接预测或理论上限制模型的泛化能力的方法，但它们都依赖于匹配的训练/测试分布和访问模型梯度等强假设。为了在这些假设不满足时描述泛化能力，我们提出了邻域不变性，一种分类器在局部转换邻域中输出不变的度量。具体而言，我们采样一组转换，对于一个输入测试点，计算不变性作为被分类为同一类别的转换点的最大比例。关键的是，我们的度量方法简单易计算，不依赖于测试点的真实标签，不对数据分布或模型做任何假设，甚至可以在域外环境下应用。",
    "tldr": "提出了一种测量分类器输出在局部转换邻域中不变性的方法，用于描述模型的泛化能力，不依赖于数据分布或模型假设，可应用于域外环境。",
    "en_tdlr": "A method is proposed to measure the invariance of a classifier's output in a local transformation neighborhood, which characterizes the generalization capacity of the model without relying on data distribution or model assumptions, and can be applied in out-of-domain settings."
}