{
    "title": "Interactive Volume Visualization via Multi-Resolution Hash Encoding based Neural Representation. (arXiv:2207.11620v3 [cs.GR] UPDATED)",
    "abstract": "Neural networks have shown great potential in compressing volume data for visualization. However, due to the high cost of training and inference, such volumetric neural representations have thus far only been applied to offline data processing and non-interactive rendering. In this paper, we demonstrate that by simultaneously leveraging modern GPU tensor cores, a native CUDA neural network framework, and a well-designed rendering algorithm with macro-cell acceleration, we can interactively ray trace volumetric neural representations (10-60fps). Our neural representations are also high-fidelity (PSNR > 30dB) and compact (10-1000x smaller). Additionally, we show that it is possible to fit the entire training step inside a rendering loop and skip the pre-training process completely. To support extreme-scale volume data, we also develop an efficient out-of-core training strategy, which allows our volumetric neural representation training to potentially scale up to terascale using only an N",
    "link": "http://arxiv.org/abs/2207.11620",
    "context": "Title: Interactive Volume Visualization via Multi-Resolution Hash Encoding based Neural Representation. (arXiv:2207.11620v3 [cs.GR] UPDATED)\nAbstract: Neural networks have shown great potential in compressing volume data for visualization. However, due to the high cost of training and inference, such volumetric neural representations have thus far only been applied to offline data processing and non-interactive rendering. In this paper, we demonstrate that by simultaneously leveraging modern GPU tensor cores, a native CUDA neural network framework, and a well-designed rendering algorithm with macro-cell acceleration, we can interactively ray trace volumetric neural representations (10-60fps). Our neural representations are also high-fidelity (PSNR > 30dB) and compact (10-1000x smaller). Additionally, we show that it is possible to fit the entire training step inside a rendering loop and skip the pre-training process completely. To support extreme-scale volume data, we also develop an efficient out-of-core training strategy, which allows our volumetric neural representation training to potentially scale up to terascale using only an N",
    "path": "papers/22/07/2207.11620.json",
    "total_tokens": 999,
    "translated_title": "基于多分辨率哈希编码的神经表示的交互式体积可视化",
    "translated_abstract": "神经网络已经展示了在压缩体积数据进行可视化方面的巨大潜力。然而，由于训练和推理的成本高昂，这种体积神经表示迄今只被应用于离线数据处理和非交互式渲染。在本文中，我们展示了通过同时利用现代GPU张量核心、本地CUDA神经网络框架以及具有宏单元加速的精心设计的渲染算法，我们可以交互地Ray Tracing体积神经表示（10-60帧/秒）。我们的神经表示也具有高保真度（PSNR > 30dB）和紧凑性（大小减小了10-1000倍）。此外，我们还展示了在渲染循环内完全跳过预训练过程的可能性，将整个训练步骤适应于渲染循环中。为了支持极大规模的体积数据，我们还开发了一种高效的离核训练策略，使我们的体积神经表示训练能够潜在地扩展到使用仅一个N进行TeraScale的规模。",
    "tldr": "本文通过同时利用现代GPU张量核心、本地CUDA神经网络框架以及具有宏单元加速的渲染算法，实现了交互式的体积神经表示光线追踪。这种神经表示具有高保真度和紧凑性，同时还开发了高效的离核训练策略以支持极大规模的体积数据。"
}