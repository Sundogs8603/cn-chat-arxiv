{
    "title": "Reducing Training Time in Cross-Silo Federated Learning using Multigraph Topology. (arXiv:2207.09657v3 [cs.LG] UPDATED)",
    "abstract": "Federated learning is an active research topic since it enables several participants to jointly train a model without sharing local data. Currently, cross-silo federated learning is a popular training setting that utilizes a few hundred reliable data silos with high-speed access links to training a model. While this approach has been widely applied in real-world scenarios, designing a robust topology to reduce the training time remains an open problem. In this paper, we present a new multigraph topology for cross-silo federated learning. We first construct the multigraph using the overlay graph. We then parse this multigraph into different simple graphs with isolated nodes. The existence of isolated nodes allows us to perform model aggregation without waiting for other nodes, hence effectively reducing the training time. Intensive experiments on three public datasets show that our proposed method significantly reduces the training time compared with recent state-of-the-art topologies w",
    "link": "http://arxiv.org/abs/2207.09657",
    "context": "Title: Reducing Training Time in Cross-Silo Federated Learning using Multigraph Topology. (arXiv:2207.09657v3 [cs.LG] UPDATED)\nAbstract: Federated learning is an active research topic since it enables several participants to jointly train a model without sharing local data. Currently, cross-silo federated learning is a popular training setting that utilizes a few hundred reliable data silos with high-speed access links to training a model. While this approach has been widely applied in real-world scenarios, designing a robust topology to reduce the training time remains an open problem. In this paper, we present a new multigraph topology for cross-silo federated learning. We first construct the multigraph using the overlay graph. We then parse this multigraph into different simple graphs with isolated nodes. The existence of isolated nodes allows us to perform model aggregation without waiting for other nodes, hence effectively reducing the training time. Intensive experiments on three public datasets show that our proposed method significantly reduces the training time compared with recent state-of-the-art topologies w",
    "path": "papers/22/07/2207.09657.json",
    "total_tokens": 891,
    "translated_title": "使用多图拓扑在跨数据仓库联邦学习中减少训练时间",
    "translated_abstract": "联邦学习是一个活跃的研究课题，因为它使得多个参与者能够共同训练一个模型而无需共享本地数据。目前，跨数据仓库联邦学习是一种常见的训练设置，它利用几百个可靠的数据仓库和高速访问链路来训练模型。虽然这种方法在实际场景中被广泛应用，但设计一个稳健的拓扑结构以减少训练时间仍然是一个未解决的问题。本文提出了一种新的用于跨数据仓库联邦学习的多图拓扑。我们首先使用覆盖图构建多图，然后将这个多图解析成具有孤立节点的不同简单图。孤立节点的存在使得我们可以在等待其他节点的情况下进行模型聚合，从而有效地减少训练时间。对三个公共数据集进行的大量实验表明，我们提出的方法与最新的拓扑结构相比，显著减少了训练时间。",
    "tldr": "本文提出了一种新的多图拓扑结构，用于跨数据仓库联邦学习，通过孤立节点实现模型聚合，从而有效地减少了训练时间。",
    "en_tdlr": "This paper proposes a new multigraph topology for cross-silo federated learning, which effectively reduces training time by aggregating models through isolated nodes."
}