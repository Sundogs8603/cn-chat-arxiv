{
    "title": "Beyond mAP: Towards better evaluation of instance segmentation. (arXiv:2207.01614v2 [cs.CV] UPDATED)",
    "abstract": "Correctness of instance segmentation constitutes counting the number of objects, correctly localizing all predictions and classifying each localized prediction. Average Precision is the de-facto metric used to measure all these constituents of segmentation. However, this metric does not penalize duplicate predictions in the high-recall range, and cannot distinguish instances that are localized correctly but categorized incorrectly. This weakness has inadvertently led to network designs that achieve significant gains in AP but also introduce a large number of false positives. We therefore cannot rely on AP to choose a model that provides an optimal tradeoff between false positives and high recall. To resolve this dilemma, we review alternative metrics in the literature and propose two new measures to explicitly measure the amount of both spatial and categorical duplicate predictions. We also propose a Semantic Sorting and NMS module to remove these duplicates based on a pixel occupancy ",
    "link": "http://arxiv.org/abs/2207.01614",
    "context": "Title: Beyond mAP: Towards better evaluation of instance segmentation. (arXiv:2207.01614v2 [cs.CV] UPDATED)\nAbstract: Correctness of instance segmentation constitutes counting the number of objects, correctly localizing all predictions and classifying each localized prediction. Average Precision is the de-facto metric used to measure all these constituents of segmentation. However, this metric does not penalize duplicate predictions in the high-recall range, and cannot distinguish instances that are localized correctly but categorized incorrectly. This weakness has inadvertently led to network designs that achieve significant gains in AP but also introduce a large number of false positives. We therefore cannot rely on AP to choose a model that provides an optimal tradeoff between false positives and high recall. To resolve this dilemma, we review alternative metrics in the literature and propose two new measures to explicitly measure the amount of both spatial and categorical duplicate predictions. We also propose a Semantic Sorting and NMS module to remove these duplicates based on a pixel occupancy ",
    "path": "papers/22/07/2207.01614.json",
    "total_tokens": 865,
    "translated_title": "超越mAP：迈向更好的实例分割评估。",
    "translated_abstract": "正确性是实例分割中的一个重要问题，它包括计算正确定位所有预测的对象数和对每个定位预测进行分类。平均精度是衡量这些分割构成部分的事实标准。然而，这个指标在高召回率范围内不惩罚重复预测，并且不能区分定位正确但分类错误的实例。这个弱点无意中导致了网络设计在AP上取得了显著增益，但也引入了大量的误报。因此，我们不能依赖AP来选择提供假阳性和高召回之间最佳折衷的模型。为解决这一问题，我们回顾了文献中的替代度量标准，并提出了两个新的度量标准来明确测量空间重复预测和分类重复预测的数量。我们还提出了一种基于像素占用的语义排序和NMS模块来消除这些重复预测。",
    "tldr": "本文提出了两个新的度量标准以明确衡量空间和分类重复预测的数量，研究人员还提出了一种Semantic Sorting and NMS模块以消除这些重复预测，以超越传统的平均精度度量标准。",
    "en_tdlr": "This paper proposes two new metrics to explicitly measure the quantity of both spatial and categorical duplicate predictions and a Semantic Sorting and NMS module to remove these duplicates, beyond the traditional average precision metric."
}