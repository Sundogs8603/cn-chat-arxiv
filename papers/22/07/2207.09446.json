{
    "title": "ShapeCrafter: A Recursive Text-Conditioned 3D Shape Generation Model. (arXiv:2207.09446v4 [cs.CV] UPDATED)",
    "abstract": "We present ShapeCrafter, a neural network for recursive text-conditioned 3D shape generation. Existing methods to generate text-conditioned 3D shapes consume an entire text prompt to generate a 3D shape in a single step. However, humans tend to describe shapes recursively-we may start with an initial description and progressively add details based on intermediate results. To capture this recursive process, we introduce a method to generate a 3D shape distribution, conditioned on an initial phrase, that gradually evolves as more phrases are added. Since existing datasets are insufficient for training this approach, we present Text2Shape++, a large dataset of 369K shape-text pairs that supports recursive shape generation. To capture local details that are often used to refine shape descriptions, we build on top of vector-quantized deep implicit functions that generate a distribution of high-quality shapes. Results show that our method can generate shapes consistent with text descriptions",
    "link": "http://arxiv.org/abs/2207.09446",
    "context": "Title: ShapeCrafter: A Recursive Text-Conditioned 3D Shape Generation Model. (arXiv:2207.09446v4 [cs.CV] UPDATED)\nAbstract: We present ShapeCrafter, a neural network for recursive text-conditioned 3D shape generation. Existing methods to generate text-conditioned 3D shapes consume an entire text prompt to generate a 3D shape in a single step. However, humans tend to describe shapes recursively-we may start with an initial description and progressively add details based on intermediate results. To capture this recursive process, we introduce a method to generate a 3D shape distribution, conditioned on an initial phrase, that gradually evolves as more phrases are added. Since existing datasets are insufficient for training this approach, we present Text2Shape++, a large dataset of 369K shape-text pairs that supports recursive shape generation. To capture local details that are often used to refine shape descriptions, we build on top of vector-quantized deep implicit functions that generate a distribution of high-quality shapes. Results show that our method can generate shapes consistent with text descriptions",
    "path": "papers/22/07/2207.09446.json",
    "total_tokens": 913,
    "translated_title": "ShapeCrafter：一种递归文本条件下的三维形状生成模型",
    "translated_abstract": "本文提出了ShapeCrafter，这是一个用于递归文本条件下的三维形状生成的神经网络。现有的生成文本条件下的三维形状的方法会利用整个文本提示来一次性生成一个三维形状。然而，人类倾向于递归地描述形状——我们可能会从一个初始描述开始，并根据中间结果逐渐添加细节。为了捕捉这个递归过程，我们介绍了一种方法来生成一个三维形状分布，该分布以初始短语为条件，并随着添加更多的短语而逐渐演变。由于现有数据集不足以训练这种方法，我们提供了Text2Shape++，这是一个包含369K个形状-文本对的大型数据集，支持递归形状生成。为了捕捉经常用于精细形状描述的局部细节，我们利用基于向量量化的深度隐式函数，生成高质量形状的分布。结果表明，我们的方法可以生成与文本描述一致的形状。",
    "tldr": "本文提出了一个用于递归文本条件下三维形状生成的神经网络，通过一种逐步添加短语的方法，可以生成与文本描述一致的形状。",
    "en_tdlr": "This paper presents a neural network for recursive text-conditioned 3D shape generation, which gradually evolves as more phrases are added, and a large dataset of shape-text pairs Text2Shape++ to support it, generating shapes consistent with the given text descriptions."
}