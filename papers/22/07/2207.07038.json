{
    "title": "SHAP-XRT: The Shapley Value Meets Conditional Independence Testing. (arXiv:2207.07038v4 [cs.LG] UPDATED)",
    "abstract": "The complex nature of artificial neural networks raises concerns on their reliability, trustworthiness, and fairness in real-world scenarios. The Shapley value -- a solution concept from game theory -- is one of the most popular explanation methods for machine learning models. More traditionally, from a statistical perspective, feature importance is defined in terms of conditional independence. So far, these two approaches to interpretability and feature importance have been considered separate and distinct. In this work, we show that Shapley-based explanation methods and conditional independence testing are closely related. We introduce the $\\textbf{SHAP}$ley-E$\\textbf{X}$planation $\\textbf{R}$andomization $\\textbf{T}$est (SHAP-XRT), a testing procedure inspired by the Conditional Randomization Test (CRT) for a specific notion of local (i.e., on a sample) conditional independence. With it, we prove that for binary classification problems, the marginal contributions in the Shapley valu",
    "link": "http://arxiv.org/abs/2207.07038",
    "context": "Title: SHAP-XRT: The Shapley Value Meets Conditional Independence Testing. (arXiv:2207.07038v4 [cs.LG] UPDATED)\nAbstract: The complex nature of artificial neural networks raises concerns on their reliability, trustworthiness, and fairness in real-world scenarios. The Shapley value -- a solution concept from game theory -- is one of the most popular explanation methods for machine learning models. More traditionally, from a statistical perspective, feature importance is defined in terms of conditional independence. So far, these two approaches to interpretability and feature importance have been considered separate and distinct. In this work, we show that Shapley-based explanation methods and conditional independence testing are closely related. We introduce the $\\textbf{SHAP}$ley-E$\\textbf{X}$planation $\\textbf{R}$andomization $\\textbf{T}$est (SHAP-XRT), a testing procedure inspired by the Conditional Randomization Test (CRT) for a specific notion of local (i.e., on a sample) conditional independence. With it, we prove that for binary classification problems, the marginal contributions in the Shapley valu",
    "path": "papers/22/07/2207.07038.json",
    "total_tokens": 862,
    "translated_title": "SHAP-XRT: Shapley Value遇上条件独立性测试",
    "translated_abstract": "人工神经网络的复杂性引发了对其在现实场景中的可靠性、可信度和公平性的关注。Shapley值是机器学习模型最流行的解释方法之一。从统计学的角度来看，特征重要性是通过条件独立性来定义的。到目前为止，这两种解释方法和特征重要性的方法被认为是分开的。本文展示了Shapley值解释方法与条件独立性测试之间的紧密关系。我们引入了SHAPley-E$\\textbf{X}$planation $\\textbf{R}$andomization $\\textbf{T}$est (SHAP-XRT)，一种受条件随机化测试(CRT)启发的测试过程，用于检验特定概念的局部（在样本上的）条件独立性。通过SHAP-XRT，在二分类问题中证明了Shapley值的边际贡献。",
    "tldr": "本文展示了Shapley值解释方法与条件独立性测试之间的紧密关系，并介绍了一种基于条件随机化测试的测试过程SHAP-XRT，用于二分类问题中证明了Shapley值的边际贡献。",
    "en_tdlr": "This work demonstrates the close relationship between Shapley-based explanation methods and conditional independence testing and introduces a testing procedure called SHAP-XRT, which proves the marginal contributions of Shapley value in binary classification problems."
}