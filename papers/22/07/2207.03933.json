{
    "title": "A law of adversarial risk, interpolation, and label noise. (arXiv:2207.03933v3 [stat.ML] UPDATED)",
    "abstract": "In supervised learning, it has been shown that label noise in the data can be interpolated without penalties on test accuracy. We show that interpolating label noise induces adversarial vulnerability, and prove the first theorem showing the relationship between label noise and adversarial risk for any data distribution. Our results are almost tight if we do not make any assumptions on the inductive bias of the learning algorithm. We then investigate how different components of this problem affect this result, including properties of the distribution. We also discuss non-uniform label noise distributions; and prove a new theorem showing uniform label noise induces nearly as large an adversarial risk as the worst poisoning with the same noise rate. Then, we provide theoretical and empirical evidence that uniform label noise is more harmful than typical real-world label noise. Finally, we show how inductive biases amplify the effect of label noise and argue the need for future work in thi",
    "link": "http://arxiv.org/abs/2207.03933",
    "context": "Title: A law of adversarial risk, interpolation, and label noise. (arXiv:2207.03933v3 [stat.ML] UPDATED)\nAbstract: In supervised learning, it has been shown that label noise in the data can be interpolated without penalties on test accuracy. We show that interpolating label noise induces adversarial vulnerability, and prove the first theorem showing the relationship between label noise and adversarial risk for any data distribution. Our results are almost tight if we do not make any assumptions on the inductive bias of the learning algorithm. We then investigate how different components of this problem affect this result, including properties of the distribution. We also discuss non-uniform label noise distributions; and prove a new theorem showing uniform label noise induces nearly as large an adversarial risk as the worst poisoning with the same noise rate. Then, we provide theoretical and empirical evidence that uniform label noise is more harmful than typical real-world label noise. Finally, we show how inductive biases amplify the effect of label noise and argue the need for future work in thi",
    "path": "papers/22/07/2207.03933.json",
    "total_tokens": 1073,
    "translated_title": "对抗风险、插值与标签噪声的一项定律",
    "translated_abstract": "在监督学习中，已经证明了数据中的标签噪声可以在不影响测试准确度的情况下进行插值。我们证明了插值标签噪声会导致对抗性漏洞，并且证明了标签噪声与对抗风险之间的关系定理，其适用于任何数据分布。我们的结果在不做任何归纳偏差假设的情况下几乎是最优的。然后，我们研究了该问题的不同组成部分对结果的影响，包括分布的性质。我们还讨论了非均匀标签噪声分布，并证明了一条新的定理，表明具有相同噪声率的均匀标签噪声引起的对抗风险与最糟的污染差不多相同。然后，我们提供了理论和经验证据表明，均匀标签噪声比典型的现实世界标签噪声更具危害性。最后，我们展示了归纳偏差如何放大标签噪声的影响，并论证了未来在这一领域的研究重要性。",
    "tldr": "该研究发现，在监督学习中进行标签噪声插值可以导致对抗风险，在任何数据分布中标签噪声与对抗风险之间都存在一定关系。同时，均匀标签噪声的对抗风险与最糟的污染相差无几，并且比典型现实世界标签噪声更具危害性。进行警惕并深入研究此领域的重要性不容忽视。"
}