{
    "title": "Learning Temporally Extended Skills in Continuous Domains as Symbolic Actions for Planning. (arXiv:2207.05018v3 [cs.LG] UPDATED)",
    "abstract": "Problems which require both long-horizon planning and continuous control capabilities pose significant challenges to existing reinforcement learning agents. In this paper we introduce a novel hierarchical reinforcement learning agent which links temporally extended skills for continuous control with a forward model in a symbolic discrete abstraction of the environment's state for planning. We term our agent SEADS for Symbolic Effect-Aware Diverse Skills. We formulate an objective and corresponding algorithm which leads to unsupervised learning of a diverse set of skills through intrinsic motivation given a known state abstraction. The skills are jointly learned with the symbolic forward model which captures the effect of skill execution in the state abstraction. After training, we can leverage the skills as symbolic actions using the forward model for long-horizon planning and subsequently execute the plan using the learned continuous-action control skills. The proposed algorithm learn",
    "link": "http://arxiv.org/abs/2207.05018",
    "context": "Title: Learning Temporally Extended Skills in Continuous Domains as Symbolic Actions for Planning. (arXiv:2207.05018v3 [cs.LG] UPDATED)\nAbstract: Problems which require both long-horizon planning and continuous control capabilities pose significant challenges to existing reinforcement learning agents. In this paper we introduce a novel hierarchical reinforcement learning agent which links temporally extended skills for continuous control with a forward model in a symbolic discrete abstraction of the environment's state for planning. We term our agent SEADS for Symbolic Effect-Aware Diverse Skills. We formulate an objective and corresponding algorithm which leads to unsupervised learning of a diverse set of skills through intrinsic motivation given a known state abstraction. The skills are jointly learned with the symbolic forward model which captures the effect of skill execution in the state abstraction. After training, we can leverage the skills as symbolic actions using the forward model for long-horizon planning and subsequently execute the plan using the learned continuous-action control skills. The proposed algorithm learn",
    "path": "papers/22/07/2207.05018.json",
    "total_tokens": 902,
    "translated_title": "在连续领域中将时间延展技能作为符号动作进行规划的学习",
    "translated_abstract": "对于既需要长程规划又需要连续控制能力的问题，现有的强化学习代理面临着重大挑战。在本文中，我们引入了一种新颖的分层强化学习代理，它将连续控制的时间延展技能与环境状态的符号离散抽象的前向模型相连接，用于规划。我们将我们的代理称为SEADS，即Symbolic Effect-Aware Diverse Skills。我们制定了一个目标和相应的算法，通过内在动机在已知状态抽象下进行无监督学习，从而学习到一组多样化的技能。这些技能与捕捉技能执行在状态抽象中的影响的符号前向模型共同学习。训练完成后，我们可以利用这些技能作为符号动作使用前向模型进行长程规划，并随后使用学习到的连续动作控制技能执行计划。所提出的算法实现了技能的学习。",
    "tldr": "本文提出了一种新颖的分层强化学习代理SEADS，将连续控制的时间延展技能与环境状态的符号离散抽象的前向模型相连接，实现了在连续领域中的长程规划和控制能力的学习。",
    "en_tdlr": "This paper proposes a novel hierarchical reinforcement learning agent SEADS, which links temporally extended skills for continuous control with a forward model in a symbolic discrete abstraction of the environment's state, enabling learning of long-term planning and control capabilities in continuous domains."
}