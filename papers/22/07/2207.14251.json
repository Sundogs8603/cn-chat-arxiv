{
    "title": "Measuring Causal Effects of Data Statistics on Language Model's `Factual' Predictions. (arXiv:2207.14251v2 [cs.CL] UPDATED)",
    "abstract": "Large amounts of training data are one of the major reasons for the high performance of state-of-the-art NLP models. But what exactly in the training data causes a model to make a certain prediction? We seek to answer this question by providing a language for describing how training data influences predictions, through a causal framework. Importantly, our framework bypasses the need to retrain expensive models and allows us to estimate causal effects based on observational data alone. Addressing the problem of extracting factual knowledge from pretrained language models (PLMs), we focus on simple data statistics such as co-occurrence counts and show that these statistics do influence the predictions of PLMs, suggesting that such models rely on shallow heuristics. Our causal framework and our results demonstrate the importance of studying datasets and the benefits of causality for understanding NLP models.",
    "link": "http://arxiv.org/abs/2207.14251",
    "context": "Title: Measuring Causal Effects of Data Statistics on Language Model's `Factual' Predictions. (arXiv:2207.14251v2 [cs.CL] UPDATED)\nAbstract: Large amounts of training data are one of the major reasons for the high performance of state-of-the-art NLP models. But what exactly in the training data causes a model to make a certain prediction? We seek to answer this question by providing a language for describing how training data influences predictions, through a causal framework. Importantly, our framework bypasses the need to retrain expensive models and allows us to estimate causal effects based on observational data alone. Addressing the problem of extracting factual knowledge from pretrained language models (PLMs), we focus on simple data statistics such as co-occurrence counts and show that these statistics do influence the predictions of PLMs, suggesting that such models rely on shallow heuristics. Our causal framework and our results demonstrate the importance of studying datasets and the benefits of causality for understanding NLP models.",
    "path": "papers/22/07/2207.14251.json",
    "total_tokens": 920,
    "translated_title": "测量数据统计对语言模型“事实性”预测的因果影响",
    "translated_abstract": "大量训练数据是最先进的自然语言处理模型表现出色的主要原因之一。但是，在训练数据中，到底是什么导致模型做出了某个预测呢？我们通过一个因果框架提供了一种描述训练数据如何影响预测的语言来回答这个问题。重要的是，我们的框架避免了重新训练昂贵模型的需要，仅通过观察数据就可以估计因果效应。针对从预训练语言模型（PLMs）中提取事实知识的问题，我们关注简单的数据统计，例如共现计数，并展示了这些统计对PLMs的预测具有影响，暗示这样的模型依赖于浅显的启发式策略。我们的因果框架和研究结果证明了研究数据集的重要性，以及因果关系对于理解NLP模型的益处。",
    "tldr": "本文提供了一个因果框架，描述了数据统计对预训练语言模型的“事实性”预测的影响。结果表明，PLMs的预测受到这些统计的影响，暗示这样的模型依赖于浅显的启发式策略。",
    "en_tdlr": "This paper presents a causal framework to describe the effects of data statistics on the \"factual\" predictions of pretrained language models (PLMs). Results show that the predictions of PLMs are influenced by these statistics, suggesting that these models rely on shallow heuristics. The framework highlights the importance of studying datasets and the benefits of causality for understanding NLP models."
}