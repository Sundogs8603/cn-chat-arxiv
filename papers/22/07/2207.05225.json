{
    "title": "Susceptibility of Continual Learning Against Adversarial Attacks. (arXiv:2207.05225v4 [cs.LG] UPDATED)",
    "abstract": "Recent continual learning approaches have primarily focused on mitigating catastrophic forgetting. Nevertheless, two critical areas have remained relatively unexplored: 1) evaluating the robustness of proposed methods and 2) ensuring the security of learned tasks. This paper investigates the susceptibility of continually learned tasks, including current and previously acquired tasks, to adversarial attacks. Specifically, we have observed that any class belonging to any task can be easily targeted and misclassified as the desired target class of any other task. Such susceptibility or vulnerability of learned tasks to adversarial attacks raises profound concerns regarding data integrity and privacy. To assess the robustness of continual learning approaches, we consider continual learning approaches in all three scenarios, i.e., task-incremental learning, domain-incremental learning, and class-incremental learning. In this regard, we explore the robustness of three regularization-based me",
    "link": "http://arxiv.org/abs/2207.05225",
    "context": "Title: Susceptibility of Continual Learning Against Adversarial Attacks. (arXiv:2207.05225v4 [cs.LG] UPDATED)\nAbstract: Recent continual learning approaches have primarily focused on mitigating catastrophic forgetting. Nevertheless, two critical areas have remained relatively unexplored: 1) evaluating the robustness of proposed methods and 2) ensuring the security of learned tasks. This paper investigates the susceptibility of continually learned tasks, including current and previously acquired tasks, to adversarial attacks. Specifically, we have observed that any class belonging to any task can be easily targeted and misclassified as the desired target class of any other task. Such susceptibility or vulnerability of learned tasks to adversarial attacks raises profound concerns regarding data integrity and privacy. To assess the robustness of continual learning approaches, we consider continual learning approaches in all three scenarios, i.e., task-incremental learning, domain-incremental learning, and class-incremental learning. In this regard, we explore the robustness of three regularization-based me",
    "path": "papers/22/07/2207.05225.json",
    "total_tokens": 871,
    "translated_title": "连续学习对抗对抗性攻击的易感性",
    "translated_abstract": "近期的连续学习方法主要集中在减少灾难性遗忘。然而，有两个关键领域相对未被探索：1）评估所提出方法的鲁棒性和2）确保学习任务的安全性。本文研究了连续学习任务，包括当前和先前获取的任务，对抗攻击的易感性。具体而言，我们观察到任何属于任何任务的类别都可以很容易地成为任何其他任务所需目标类别的目标，并且被错误分类。这种学习任务对抗攻击的易感性引发了有关数据完整性和隐私的深刻关切。为了评估连续学习方法的鲁棒性，我们考虑了三种场景下的连续学习方法，即任务递增学习、领域递增学习和类递增学习。在这方面，我们探索了三种基于正则化的方法的鲁棒性。",
    "tldr": "本文研究了连续学习任务对抗攻击的易感性，发现学习任务容易受到对抗性攻击导致的目标类别错误分类。这对数据完整性和隐私构成了重大威胁。",
    "en_tdlr": "This paper investigates the susceptibility of continual learning tasks to adversarial attacks and finds that the tasks are easily targeted and misclassified, posing significant threats to data integrity and privacy."
}