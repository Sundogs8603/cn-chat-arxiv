{
    "title": "Probing Classifiers are Unreliable for Concept Removal and Detection. (arXiv:2207.04153v3 [cs.LG] UPDATED)",
    "abstract": "Neural network models trained on text data have been found to encode undesirable linguistic or sensitive concepts in their representation. Removing such concepts is non-trivial because of a complex relationship between the concept, text input, and the learnt representation. Recent work has proposed post-hoc and adversarial methods to remove such unwanted concepts from a model's representation. Through an extensive theoretical and empirical analysis, we show that these methods can be counter-productive: they are unable to remove the concepts entirely, and in the worst case may end up destroying all task-relevant features. The reason is the methods' reliance on a probing classifier as a proxy for the concept. Even under the most favorable conditions for learning a probing classifier when a concept's relevant features in representation space alone can provide 100% accuracy, we prove that a probing classifier is likely to use non-concept features and thus post-hoc or adversarial methods wi",
    "link": "http://arxiv.org/abs/2207.04153",
    "context": "Title: Probing Classifiers are Unreliable for Concept Removal and Detection. (arXiv:2207.04153v3 [cs.LG] UPDATED)\nAbstract: Neural network models trained on text data have been found to encode undesirable linguistic or sensitive concepts in their representation. Removing such concepts is non-trivial because of a complex relationship between the concept, text input, and the learnt representation. Recent work has proposed post-hoc and adversarial methods to remove such unwanted concepts from a model's representation. Through an extensive theoretical and empirical analysis, we show that these methods can be counter-productive: they are unable to remove the concepts entirely, and in the worst case may end up destroying all task-relevant features. The reason is the methods' reliance on a probing classifier as a proxy for the concept. Even under the most favorable conditions for learning a probing classifier when a concept's relevant features in representation space alone can provide 100% accuracy, we prove that a probing classifier is likely to use non-concept features and thus post-hoc or adversarial methods wi",
    "path": "papers/22/07/2207.04153.json",
    "total_tokens": 1181,
    "translated_title": "探测分类器对于概念去除和检测不可靠",
    "translated_abstract": "在文本数据上训练的神经网络模型被发现在其表示中编码了不良的语言或敏感概念，移除这些概念是不容易的，因为概念、文本输入和学习到的表示之间存在复杂的关系。最近的研究提出了后期和对抗性方法来从模型的表示中去除这些不需要的概念。通过广泛的理论和实证分析，我们表明这些方法可能是适得其反的：它们不能完全去除概念，而在最糟糕的情况下可能会破坏所有任务相关的特征。原因是这些方法依赖于一个探测分类器作为概念的代理。即使在概念相关特征在表示空间中就可以提供100%准确性的最有利条件下学习探测分类器，我们证明探测分类器很可能会使用非概念特征，因此后期或对抗性处理方法将不能完全去除不需要的概念。我们提出一种替代方法，通过在损失函数中训练正则化项来直接学习从模型表示中去除概念。我们的实验表明，这种方法在去除概念的同时保留任务相关特征方面优于最先进的后期和对抗性方法。",
    "tldr": "本文研究了在文本数据上神经网络模型中的不良概念去除。对于现有的后期和对抗性方法，本文理论和实证分析表明其依赖的探测分类器可能使用非概念特征，导致无法完全去除不需要的概念。我们提出了一种直接学习从模型的表示中去除概念的方法，实验结果表明其优于最先进的后期和对抗性方法。",
    "en_tdlr": "This paper studies the removal of undesirable concepts from neural network models trained on text data. The theoretical and empirical analysis shows that current post-hoc and adversarial methods, relying on a probing classifier as a proxy for the concept, may use non-concept features and fail to completely remove unwanted concepts. Therefore, the paper proposes a direct learning method for concept removal through training a regularization term in the loss function, which outperforms existing methods in terms of both removing unwanted concepts and preserving task-relevant features."
}