{
    "title": "Set-based value operators for non-stationary Markovian environments. (arXiv:2207.07271v3 [cs.LG] UPDATED)",
    "abstract": "This paper analyzes finite state Markov Decision Processes (MDPs) with uncertain parameters in compact sets and re-examines results from robust MDP via set-based fixed point theory. To this end, we generalize the Bellman and policy evaluation operators to contracting operators on the value function space and denote them as \\emph{value operators}. We lift these value operators to act on \\emph{sets} of value functions and denote them as \\emph{set-based value operators}. We prove that the set-based value operators are \\emph{contractions} in the space of compact value function sets. Leveraging insights from set theory, we generalize the rectangularity condition in classic robust MDP literature to a containment condition for all value operators, which is weaker and can be applied to a larger set of parameter-uncertain MDPs and contracting operators in dynamic programming. We prove that both the rectangularity condition and the containment condition sufficiently ensure that the set-based val",
    "link": "http://arxiv.org/abs/2207.07271",
    "context": "Title: Set-based value operators for non-stationary Markovian environments. (arXiv:2207.07271v3 [cs.LG] UPDATED)\nAbstract: This paper analyzes finite state Markov Decision Processes (MDPs) with uncertain parameters in compact sets and re-examines results from robust MDP via set-based fixed point theory. To this end, we generalize the Bellman and policy evaluation operators to contracting operators on the value function space and denote them as \\emph{value operators}. We lift these value operators to act on \\emph{sets} of value functions and denote them as \\emph{set-based value operators}. We prove that the set-based value operators are \\emph{contractions} in the space of compact value function sets. Leveraging insights from set theory, we generalize the rectangularity condition in classic robust MDP literature to a containment condition for all value operators, which is weaker and can be applied to a larger set of parameter-uncertain MDPs and contracting operators in dynamic programming. We prove that both the rectangularity condition and the containment condition sufficiently ensure that the set-based val",
    "path": "papers/22/07/2207.07271.json",
    "total_tokens": 998,
    "translated_title": "非平稳马尔可夫环境中基于集合的值运算符",
    "translated_abstract": "本文分析了具有不确定参数的有限状态马尔可夫决策过程（MDP），并通过基于集合的不动点理论重新审视了鲁棒MDP的结果。为此，我们将Bellman算子和策略评估算子推广为值函数空间上的压缩算子，并称之为“值运算符”。我们将这些值运算符提升为作用于值函数集合的“基于集合的值运算符”。我们证明了在紧致值函数集合空间中，基于集合的值运算符是“压缩”运算符。借助集合论的见解，我们将经典鲁棒MDP文献中的矩形条件推广为适用于更多参数不确定MDP和动态规划中的压缩算子的包含条件，该条件相对较弱。我们证明了矩形条件和包含条件都足以确保基于集合的值运算符的奇性。",
    "tldr": "本文将Bellman算子和策略评估算子推广为值函数空间上的压缩算子，并将其提升为作用于值函数集合的基于集合的值运算符。利用集合论的见解，我们将经典鲁棒MDP文献中的矩形条件推广为适用于更多参数不确定MDP和动态规划中的压缩算子的包含条件。研究结果表明，基于集合的值运算符具有压缩性。"
}