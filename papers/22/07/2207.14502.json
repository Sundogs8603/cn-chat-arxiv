{
    "title": "Language Models Can Teach Themselves to Program Better. (arXiv:2207.14502v4 [cs.LG] UPDATED)",
    "abstract": "Recent Language Models (LMs) achieve breakthrough performance in code generation when trained on human-authored problems, even solving some competitive-programming problems. Self-play has proven useful in games such as Go, and thus it is natural to ask whether LMs can generate their own instructive programming problems to improve their performance. We show that it is possible for an LM to synthesize programming problems and solutions, which are filtered for correctness by a Python interpreter. The LM's performance is then seen to improve when it is fine-tuned on its own synthetic problems and verified solutions; thus the model 'improves itself' using the Python interpreter. Problems are specified formally as programming puzzles [Schuster et al., 2021], a code-based problem format where solutions can easily be verified for correctness by execution. In experiments on publicly-available LMs, test accuracy more than doubles. This work demonstrates the potential for code LMs, with an interp",
    "link": "http://arxiv.org/abs/2207.14502",
    "context": "Title: Language Models Can Teach Themselves to Program Better. (arXiv:2207.14502v4 [cs.LG] UPDATED)\nAbstract: Recent Language Models (LMs) achieve breakthrough performance in code generation when trained on human-authored problems, even solving some competitive-programming problems. Self-play has proven useful in games such as Go, and thus it is natural to ask whether LMs can generate their own instructive programming problems to improve their performance. We show that it is possible for an LM to synthesize programming problems and solutions, which are filtered for correctness by a Python interpreter. The LM's performance is then seen to improve when it is fine-tuned on its own synthetic problems and verified solutions; thus the model 'improves itself' using the Python interpreter. Problems are specified formally as programming puzzles [Schuster et al., 2021], a code-based problem format where solutions can easily be verified for correctness by execution. In experiments on publicly-available LMs, test accuracy more than doubles. This work demonstrates the potential for code LMs, with an interp",
    "path": "papers/22/07/2207.14502.json",
    "total_tokens": 1075,
    "translated_title": "语言模型可以自我训练以实现更好的编程能力",
    "tldr": "通过训练人类编写的编程问题，语言模型可以通过自我对弈生成指导性编程问题，通过Python解释器筛选，进而提升自身性能。在公开可用的语言模型实验中，测试准确率提高了至少两倍。"
}