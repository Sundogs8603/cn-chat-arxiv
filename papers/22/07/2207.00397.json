{
    "title": "Conditional Generation with a Question-Answering Blueprint. (arXiv:2207.00397v2 [cs.CL] UPDATED)",
    "abstract": "The ability to convey relevant and faithful information is critical for many tasks in conditional generation and yet remains elusive for neural seq-to-seq models whose outputs often reveal hallucinations and fail to correctly cover important details. In this work, we advocate planning as a useful intermediate representation for rendering conditional generation less opaque and more grounded. Our work proposes a new conceptualization of text plans as a sequence of question-answer (QA) pairs. We enhance existing datasets (e.g., for summarization) with a QA blueprint operating as a proxy for both content selection (i.e.,~what to say) and planning (i.e.,~in what order). We obtain blueprints automatically by exploiting state-of-the-art question generation technology and convert input-output pairs into input-blueprint-output tuples. We develop Transformer-based models, each varying in how they incorporate the blueprint in the generated output (e.g., as a global plan or iteratively). Evaluatio",
    "link": "http://arxiv.org/abs/2207.00397",
    "context": "Title: Conditional Generation with a Question-Answering Blueprint. (arXiv:2207.00397v2 [cs.CL] UPDATED)\nAbstract: The ability to convey relevant and faithful information is critical for many tasks in conditional generation and yet remains elusive for neural seq-to-seq models whose outputs often reveal hallucinations and fail to correctly cover important details. In this work, we advocate planning as a useful intermediate representation for rendering conditional generation less opaque and more grounded. Our work proposes a new conceptualization of text plans as a sequence of question-answer (QA) pairs. We enhance existing datasets (e.g., for summarization) with a QA blueprint operating as a proxy for both content selection (i.e.,~what to say) and planning (i.e.,~in what order). We obtain blueprints automatically by exploiting state-of-the-art question generation technology and convert input-output pairs into input-blueprint-output tuples. We develop Transformer-based models, each varying in how they incorporate the blueprint in the generated output (e.g., as a global plan or iteratively). Evaluatio",
    "path": "papers/22/07/2207.00397.json",
    "total_tokens": 864,
    "translated_title": "带有问答蓝图的条件生成",
    "translated_abstract": "在条件生成的许多任务中，传达相关和真实的信息的能力非常关键，然而神经 seq-to-seq 模型往往会产生幻觉而未能正确涵盖重要细节。在本文中，我们提出了规划作为渲染条件生成较少模糊和更可操作中间表达方式的建议。我们的工作提出了文本规划的新概念，作为一系列问答对的序列。我们通过使用最先进的问答生成技术自动获取蓝图，并将输入-输出对转换为输入蓝图-输出元组。我们开发了基于 Transformer 的模型，每个模型在生成的输出中如何结合蓝图不同（例如作为全局计划或迭代计划）。针对两个条件生成任务的评估显示了我们方法的有效性，包括忠实度、覆盖率和信息量。",
    "tldr": "本文提出了一种新的文本规划方法，将其作为一系列问答对的序列来带有问答蓝图的条件生成，通过该方法可以提高生成结果的忠实度、覆盖率和信息量。",
    "en_tdlr": "This paper proposes a novel approach in text planning as a sequence of question-answer pairs for conditional generation, using a question-answering blueprint to enhance the quality of generated outputs, and achieving higher faithfulness, coverage, and informativeness in evaluation."
}