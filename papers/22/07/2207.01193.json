{
    "title": "A Customized Text Sanitization Mechanism with Differential Privacy. (arXiv:2207.01193v2 [cs.CR] CROSS LISTED)",
    "abstract": "As privacy issues are receiving increasing attention within the Natural Language Processing (NLP) community, numerous methods have been proposed to sanitize texts subject to differential privacy. However, the state-of-the-art text sanitization mechanisms based on metric local differential privacy (MLDP) do not apply to non-metric semantic similarity measures and cannot achieve good trade-offs between privacy and utility. To address the above limitations, we propose a novel Customized Text (CusText) sanitization mechanism based on the original $\\epsilon$-differential privacy (DP) definition, which is compatible with any similarity measure. Furthermore, CusText assigns each input token a customized output set of tokens to provide more advanced privacy protection at the token level. Extensive experiments on several benchmark datasets show that CusText achieves a better trade-off between privacy and utility than existing mechanisms. The code is available at https://github.com/sai4july/CusT",
    "link": "http://arxiv.org/abs/2207.01193",
    "context": "Title: A Customized Text Sanitization Mechanism with Differential Privacy. (arXiv:2207.01193v2 [cs.CR] CROSS LISTED)\nAbstract: As privacy issues are receiving increasing attention within the Natural Language Processing (NLP) community, numerous methods have been proposed to sanitize texts subject to differential privacy. However, the state-of-the-art text sanitization mechanisms based on metric local differential privacy (MLDP) do not apply to non-metric semantic similarity measures and cannot achieve good trade-offs between privacy and utility. To address the above limitations, we propose a novel Customized Text (CusText) sanitization mechanism based on the original $\\epsilon$-differential privacy (DP) definition, which is compatible with any similarity measure. Furthermore, CusText assigns each input token a customized output set of tokens to provide more advanced privacy protection at the token level. Extensive experiments on several benchmark datasets show that CusText achieves a better trade-off between privacy and utility than existing mechanisms. The code is available at https://github.com/sai4july/CusT",
    "path": "papers/22/07/2207.01193.json",
    "total_tokens": 891,
    "translated_title": "一种基于差分隐私的定制文本消毒机制",
    "translated_abstract": "随着隐私问题在自然语言处理 (NLP) 社区中引起越来越多的关注，已提出了许多方法来按照差分隐私原则对文本进行消毒。然而，基于度量局部差分隐私 (MLDP) 的最先进文本消毒机制不适用于非度量语义相似度度量，并且无法在隐私和效用之间取得良好的权衡。为了解决上述局限性，我们提出了一种基于原始 ε-差分隐私 (DP) 定义的新型定制文本 (CusText) 消毒机制，该机制与任何相似度度量兼容。此外，CusText为每个输入标记分配一个定制的输出标记集，以在标记级别提供更高级的隐私保护。在几个基准数据集上进行的大量实验证明，CusText在隐私和效用之间实现了更好的权衡。代码可在 https://github.com/sai4july/CusT 获取。",
    "tldr": "一种基于差分隐私的定制文本消毒机制 (CusText) 提供了更好的隐私保护与效用权衡，适用于任何相似度度量，并在标记级别实现了先进的隐私保护。"
}