{
    "title": "Learning an Adaptive Forwarding Strategy for Mobile Wireless Networks: Resource Usage vs. Latency. (arXiv:2207.11386v2 [cs.NI] UPDATED)",
    "abstract": "Designing effective routing strategies for mobile wireless networks is challenging due to the need to seamlessly adapt routing behavior to spatially diverse and temporally changing network conditions. In this work, we use deep reinforcement learning (DeepRL) to learn a scalable and generalizable single-copy routing strategy for such networks. We make the following contributions: i) we design a reward function that enables the DeepRL agent to explicitly trade-off competing network goals, such as minimizing delay vs. the number of transmissions per packet; ii) we propose a novel set of relational neighborhood, path, and context features to characterize mobile wireless networks and model device mobility independently of a specific network topology; and iii) we use a flexible training approach that allows us to combine data from all packets and devices into a single offline centralized training set to train a single DeepRL agent. To evaluate generalizeability and scalability, we train our ",
    "link": "http://arxiv.org/abs/2207.11386",
    "context": "Title: Learning an Adaptive Forwarding Strategy for Mobile Wireless Networks: Resource Usage vs. Latency. (arXiv:2207.11386v2 [cs.NI] UPDATED)\nAbstract: Designing effective routing strategies for mobile wireless networks is challenging due to the need to seamlessly adapt routing behavior to spatially diverse and temporally changing network conditions. In this work, we use deep reinforcement learning (DeepRL) to learn a scalable and generalizable single-copy routing strategy for such networks. We make the following contributions: i) we design a reward function that enables the DeepRL agent to explicitly trade-off competing network goals, such as minimizing delay vs. the number of transmissions per packet; ii) we propose a novel set of relational neighborhood, path, and context features to characterize mobile wireless networks and model device mobility independently of a specific network topology; and iii) we use a flexible training approach that allows us to combine data from all packets and devices into a single offline centralized training set to train a single DeepRL agent. To evaluate generalizeability and scalability, we train our ",
    "path": "papers/22/07/2207.11386.json",
    "total_tokens": 1008,
    "translated_title": "移动无线网络中学习自适应转发策略：资源使用与延迟的平衡",
    "translated_abstract": "为移动无线网络设计有效的路由策略是一项具有挑战性的任务，因为需要无缝地适应时空变化的网络条件。本文利用深度强化学习（DeepRL）来学习适用于此类网络的可扩展且普适的单副本路由策略。本文的贡献如下：一、设计了一种奖励函数，使得DeepRL代理可以明确权衡竞争的网络目标，如在最小化延迟与每个包的传输次数之间进行权衡；二、提出了一组新颖的关系领域、路径和上下文特征来描述移动无线网络，并独立于特定的网络拓扑模型设备移动模型；三、采用灵活的训练方法，将所有数据从所有包和设备汇总成一个离线中心化的训练集，以训练单个DeepRL代理。为了评估其可扩展性和普适性，我们将其与其他机器学习模型进行比较，并在真实数据集上进行了实验。",
    "tldr": "本文利用深度强化学习为移动无线网络设计了一种可扩展和普适的单副本路由策略，通过权衡竞争的网络目标，设计了一种具有奖励函数的路由策略，并提出了一组新颖的关系领域、路径和上下文特征来描述设备移动情况，同时采用灵活的训练方法来训练单个DeepRL代理。",
    "en_tdlr": "This paper uses deep reinforcement learning to design a scalable and generalizable single-copy routing strategy for mobile wireless networks, which balances competing network goals and characterizes device mobility independently of network topology using a novel set of features. A flexible training approach is used to train a single DeepRL agent, and experiments show its effectiveness compared to other machine learning models."
}