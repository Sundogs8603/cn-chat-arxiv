{
    "title": "Tuning Stochastic Gradient Algorithms for Statistical Inference via Large-Sample Asymptotics. (arXiv:2207.12395v3 [stat.CO] UPDATED)",
    "abstract": "The tuning of stochastic gradient algorithms (SGAs) for optimization and sampling is often based on heuristics and trial-and-error rather than generalizable theory. We address this theory--practice gap by characterizing the large-sample statistical asymptotics of SGAs via a joint step-size--sample-size scaling limit. We show that iterate averaging with a large fixed step size is robust to the choice of tuning parameters and asymptotically has covariance proportional to that of the MLE sampling distribution. We also prove a Bernstein--von Mises-like theorem to guide tuning, including for generalized posteriors that are robust to model misspecification. Numerical experiments validate our results and recommendations in realistic finite-sample regimes. Our work lays the foundation for a systematic analysis of other stochastic gradient Markov chain Monte Carlo algorithms for a wide range of models.",
    "link": "http://arxiv.org/abs/2207.12395",
    "context": "Title: Tuning Stochastic Gradient Algorithms for Statistical Inference via Large-Sample Asymptotics. (arXiv:2207.12395v3 [stat.CO] UPDATED)\nAbstract: The tuning of stochastic gradient algorithms (SGAs) for optimization and sampling is often based on heuristics and trial-and-error rather than generalizable theory. We address this theory--practice gap by characterizing the large-sample statistical asymptotics of SGAs via a joint step-size--sample-size scaling limit. We show that iterate averaging with a large fixed step size is robust to the choice of tuning parameters and asymptotically has covariance proportional to that of the MLE sampling distribution. We also prove a Bernstein--von Mises-like theorem to guide tuning, including for generalized posteriors that are robust to model misspecification. Numerical experiments validate our results and recommendations in realistic finite-sample regimes. Our work lays the foundation for a systematic analysis of other stochastic gradient Markov chain Monte Carlo algorithms for a wide range of models.",
    "path": "papers/22/07/2207.12395.json",
    "total_tokens": 977,
    "translated_title": "通过大样本渐近理论优化随机梯度算法的统计推断",
    "translated_abstract": "针对优化和抽样的随机梯度算法（SGA）的调优通常基于试错和启发式方法，而不是可推广的理论。我们通过一种联合步长-样本大小缩放极限来表征SGA的大样本统计渐近性。我们证明了使用固定的大步长进行迭代平均是对调优参数选择鲁棒的，并且在渐近意义下，具有和MLE抽样分布协方差成比例的鲁棒性。我们还证明了一种类似于Bernstein-von Mises的定理以指导调优，包括针对模型错误规范鲁棒的广义后验。数值实验验证了我们在实际有限样本范围内的结果和建议。我们的工作为大范围模型的其他随机梯度Markov Chain Monte Carlo算法的系统分析奠定了基础。",
    "tldr": "我们利用大样本渐近理论对随机梯度算法进行调优，发现使用固定的大步长进行迭代平均可以鲁棒地优化算法，且具有和MLE抽样分布协方差成比例的鲁棒性。我们还提出了一种类似于Bernstein-von Mises的定理用于指导调优，包括针对模型错误规范鲁棒的广义后验。数值实验验证了我们的结果和建议在实际有限样本情况下的有效性。这些成果为分析其他随机梯度Markov Chain Monte Carlo算法提供了基础。",
    "en_tdlr": "We optimize stochastic gradient algorithms using large-sample asymptotics, demonstrating the robustness of iterate averaging with a large step size and providing a theorem similar to Bernstein-von Mises for tuning. Numerical experiments validate our results, laying the foundation for the analysis of other stochastic gradient Markov Chain Monte Carlo algorithms."
}