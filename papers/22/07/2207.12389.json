{
    "title": "MemSAC: Memory Augmented Sample Consistency for Large Scale Unsupervised Domain Adaptation. (arXiv:2207.12389v2 [cs.CV] UPDATED)",
    "abstract": "Practical real world datasets with plentiful categories introduce new challenges for unsupervised domain adaptation like small inter-class discriminability, that existing approaches relying on domain invariance alone cannot handle sufficiently well. In this work we propose MemSAC, which exploits sample level similarity across source and target domains to achieve discriminative transfer, along with architectures that scale to a large number of categories. For this purpose, we first introduce a memory augmented approach to efficiently extract pairwise similarity relations between labeled source and unlabeled target domain instances, suited to handle an arbitrary number of classes. Next, we propose and theoretically justify a novel variant of the contrastive loss to promote local consistency among within-class cross domain samples while enforcing separation between classes, thus preserving discriminative transfer from source to target. We validate the advantages of MemSAC with significant",
    "link": "http://arxiv.org/abs/2207.12389",
    "context": "Title: MemSAC: Memory Augmented Sample Consistency for Large Scale Unsupervised Domain Adaptation. (arXiv:2207.12389v2 [cs.CV] UPDATED)\nAbstract: Practical real world datasets with plentiful categories introduce new challenges for unsupervised domain adaptation like small inter-class discriminability, that existing approaches relying on domain invariance alone cannot handle sufficiently well. In this work we propose MemSAC, which exploits sample level similarity across source and target domains to achieve discriminative transfer, along with architectures that scale to a large number of categories. For this purpose, we first introduce a memory augmented approach to efficiently extract pairwise similarity relations between labeled source and unlabeled target domain instances, suited to handle an arbitrary number of classes. Next, we propose and theoretically justify a novel variant of the contrastive loss to promote local consistency among within-class cross domain samples while enforcing separation between classes, thus preserving discriminative transfer from source to target. We validate the advantages of MemSAC with significant",
    "path": "papers/22/07/2207.12389.json",
    "total_tokens": 858,
    "translated_title": "MemSAC: 大规模无监督领域自适应的记忆增强样本一致性",
    "translated_abstract": "实际的现实世界数据集引入了无监督领域自适应的新挑战，如类间区分度小，现有的仅依赖于域不变性的方法无法很好地处理。在这项工作中，我们提出了MemSAC，它利用源域和目标域之间的样本级相似性实现判别转移，并可扩展到大量类别。为此，我们首先引入了一种记忆增强方法，以有效地提取标记源域和未标记目标域实例之间的成对相似性关系，适合处理任意数量的类别。接下来，我们提出并从理论上证明了一种新颖的对比损失的变体，以促进类内跨域样本之间的局部一致性，同时确保类别之间的分离，从而保持从源域到目标域的判别转移。我们验证了MemSAC的优势和显著性。",
    "tldr": "MemSAC提出了一种记忆增强样本一致性方法，通过利用源域和目标域之间的样本级相似性实现判别转移，并且在大规模数据集上表现出明显的优势。",
    "en_tdlr": "MemSAC proposes a memory augmented sample consistency approach that achieves discriminative transfer by utilizing sample level similarity between source and target domains, and it has shown significant advantages on large-scale datasets."
}