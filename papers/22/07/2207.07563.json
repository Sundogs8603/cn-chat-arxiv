{
    "title": "QSAN: A Near-term Achievable Quantum Self-Attention Network. (arXiv:2207.07563v4 [quant-ph] UPDATED)",
    "abstract": "Self-Attention Mechanism (SAM) is good at capturing the internal connections of features and greatly improves the performance of machine learning models, espeacially requiring efficient characterization and feature extraction of high-dimensional data. A novel Quantum Self-Attention Network (QSAN) is proposed for image classification tasks on near-term quantum devices. First, a Quantum Self-Attention Mechanism (QSAM) including Quantum Logic Similarity (QLS) and Quantum Bit Self-Attention Score Matrix (QBSASM) is explored as the theoretical basis of QSAN to enhance the data representation of SAM. QLS is employed to prevent measurements from obtaining inner products to allow QSAN to be fully implemented on quantum computers, and QBSASM as a result of the evolution of QSAN to produce a density matrix that effectively reflects the attention distribution of the output. Then, the framework for one-step realization and quantum circuits of QSAN are designed for fully considering the compression",
    "link": "http://arxiv.org/abs/2207.07563",
    "context": "Title: QSAN: A Near-term Achievable Quantum Self-Attention Network. (arXiv:2207.07563v4 [quant-ph] UPDATED)\nAbstract: Self-Attention Mechanism (SAM) is good at capturing the internal connections of features and greatly improves the performance of machine learning models, espeacially requiring efficient characterization and feature extraction of high-dimensional data. A novel Quantum Self-Attention Network (QSAN) is proposed for image classification tasks on near-term quantum devices. First, a Quantum Self-Attention Mechanism (QSAM) including Quantum Logic Similarity (QLS) and Quantum Bit Self-Attention Score Matrix (QBSASM) is explored as the theoretical basis of QSAN to enhance the data representation of SAM. QLS is employed to prevent measurements from obtaining inner products to allow QSAN to be fully implemented on quantum computers, and QBSASM as a result of the evolution of QSAN to produce a density matrix that effectively reflects the attention distribution of the output. Then, the framework for one-step realization and quantum circuits of QSAN are designed for fully considering the compression",
    "path": "papers/22/07/2207.07563.json",
    "total_tokens": 870,
    "translated_title": "QSAN: 一种近期可实现的量子自注意力网络",
    "translated_abstract": "自注意机制（SAM）擅长捕捉特征的内部连接，并极大地提高了机器学习模型的性能，尤其是对高维数据的高效特征提取和表征。本文提出了一种新型的量子自注意力网络（QSAN），用于近期量子设备上的图像分类任务。首先，探索了量子自注意力机制（QSAM），包括量子逻辑相似度（QLS）和量子位自注意力得分矩阵（QBSASM），作为QSAN的理论基础，以增强SAM的数据表示能力。QLS用于防止测量获取内积，使得QSAN能够在量子计算机上完全实现，而QBSASM作为QSAN演进的结果，产生一个能有效反映输出的注意力分布的密度矩阵。然后，设计了QSAN的一步实现和量子电路框架，充分考虑了数据压缩等因素。",
    "tldr": "本文提出了一种量子自注意力网络（QSAN），用于近期量子设备上的图像分类任务。该网络利用量子自注意力机制来增强数据表示能力，并设计了对应的一步实现和量子电路框架。",
    "en_tdlr": "A Quantum Self-Attention Network (QSAN) is proposed for image classification tasks on near-term quantum devices. It enhances data representation using a quantum self-attention mechanism and is supported by a designed implementation and quantum circuit framework."
}