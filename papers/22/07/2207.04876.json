{
    "title": "On the Generalization of Spiking Neural Networks via Minimum Description Length and Structural Stability. (arXiv:2207.04876v2 [cs.NE] UPDATED)",
    "abstract": "The past decades have witnessed an increasing interest in spiking neural networks due to their great potential of modeling time-dependent data. Many empirical algorithms and techniques have been developed. However, theoretically, it remains unknown whether and to what extent a trained spiking neural network performs well on unseen data. This work takes one step in this direction by exploiting the minimum description length principle and thus, presents an explicit generalization bound for spiking neural networks. Further, we implement the description length of SNNs through structural stability and specify the lower and upper bounds of the maximum number of stable bifurcation solutions, which convert the challenge of qualifying structural stability in SNNs into a mathematical problem with quantitative properties.",
    "link": "http://arxiv.org/abs/2207.04876",
    "context": "Title: On the Generalization of Spiking Neural Networks via Minimum Description Length and Structural Stability. (arXiv:2207.04876v2 [cs.NE] UPDATED)\nAbstract: The past decades have witnessed an increasing interest in spiking neural networks due to their great potential of modeling time-dependent data. Many empirical algorithms and techniques have been developed. However, theoretically, it remains unknown whether and to what extent a trained spiking neural network performs well on unseen data. This work takes one step in this direction by exploiting the minimum description length principle and thus, presents an explicit generalization bound for spiking neural networks. Further, we implement the description length of SNNs through structural stability and specify the lower and upper bounds of the maximum number of stable bifurcation solutions, which convert the challenge of qualifying structural stability in SNNs into a mathematical problem with quantitative properties.",
    "path": "papers/22/07/2207.04876.json",
    "total_tokens": 770,
    "translated_title": "基于最小描述长度和结构稳定性的脉冲神经网络的泛化研究",
    "translated_abstract": "过去几十年中，由于其对于建模时间相关数据的潜力，脉冲神经网络引起了越来越多的关注。许多经验算法和技术已经被开发出来。然而，从理论上讲，训练后的脉冲神经网络在未见数据上的表现仍然是未知的。本研究通过利用最小描述长度原则，为脉冲神经网络提供一个明确的泛化界限。此外，我们通过结构稳定性实施了SNN的描述长度，并指定了最大稳定分歧解数的下限和上限，将在SNN中确定结构稳定性的挑战转化为一个具有定量特性的数学问题。",
    "tldr": "本研究通过利用最小描述长度原则和结构稳定性为脉冲神经网络提供了一个明确的泛化界限，并指定了最大稳定分歧解数的下限和上限。",
    "en_tdlr": "This study presents an explicit generalization bound for spiking neural networks by exploiting the minimum description length principle, and specifies the lower and upper bounds of the maximum number of stable bifurcation solutions through structural stability."
}