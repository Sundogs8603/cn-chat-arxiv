{
    "title": "Linguistically inspired roadmap for building biologically reliable protein language models. (arXiv:2207.00982v2 [q-bio.QM] UPDATED)",
    "abstract": "Deep neural-network-based language models (LMs) are increasingly applied to large-scale protein sequence data to predict protein function. However, being largely black-box models and thus challenging to interpret, current protein LM approaches do not contribute to a fundamental understanding of sequence-function mappings, hindering rule-based biotherapeutic drug development. We argue that guidance drawn from linguistics, a field specialized in analytical rule extraction from natural language data, can aid with building more interpretable protein LMs that are more likely to learn relevant domain-specific rules. Differences between protein sequence data and linguistic sequence data require the integration of more domain-specific knowledge in protein LMs compared to natural language LMs. Here, we provide a linguistics-based roadmap for protein LM pipeline choices with regard to training data, tokenization, token embedding, sequence embedding, and model interpretation. Incorporating lingui",
    "link": "http://arxiv.org/abs/2207.00982",
    "context": "Title: Linguistically inspired roadmap for building biologically reliable protein language models. (arXiv:2207.00982v2 [q-bio.QM] UPDATED)\nAbstract: Deep neural-network-based language models (LMs) are increasingly applied to large-scale protein sequence data to predict protein function. However, being largely black-box models and thus challenging to interpret, current protein LM approaches do not contribute to a fundamental understanding of sequence-function mappings, hindering rule-based biotherapeutic drug development. We argue that guidance drawn from linguistics, a field specialized in analytical rule extraction from natural language data, can aid with building more interpretable protein LMs that are more likely to learn relevant domain-specific rules. Differences between protein sequence data and linguistic sequence data require the integration of more domain-specific knowledge in protein LMs compared to natural language LMs. Here, we provide a linguistics-based roadmap for protein LM pipeline choices with regard to training data, tokenization, token embedding, sequence embedding, and model interpretation. Incorporating lingui",
    "path": "papers/22/07/2207.00982.json",
    "total_tokens": 908,
    "translated_title": "基于语言学的建立生物可靠的蛋白质语言模型的路线图",
    "translated_abstract": "基于深度神经网络的语言模型（LM）被越来越多地应用于大规模蛋白质序列数据以预测蛋白质功能。然而，由于它们大多是黑盒模型，因此难以解释，目前的蛋白质LM方法并没有对序列-功能映射的基本理解作出贡献，从而阻碍了基于规则的生物治疗药物的开发。我们认为，从语言学中得出的指导可以帮助建立更可解释的蛋白质LM，这些模型更有可能学习相关的领域特定规则。与自然语言数据不同，蛋白质序列数据需要比自然语言LM提供更多领域特定知识的整合。在这里，我们提供了一个基于语言学的蛋白质LM流程选择的路线图，涉及培训数据、标记化、标记嵌入、序列嵌入和模型解释。",
    "tldr": "研究提供了一个基于语言学的蛋白质语言模型建立的路线图，以帮助建立更可解释的蛋白质LM，这将有助于发现相关领域特定的规则，从而促进基于规则的生物治疗药物的开发。",
    "en_tdlr": "The study presents a linguistics-based roadmap for building more interpretable protein language models, which can aid in discovering relevant domain-specific rules and promoting the development of rule-based biotherapeutic drugs."
}