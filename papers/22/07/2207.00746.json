{
    "title": "INSCIT: Information-Seeking Conversations with Mixed-Initiative Interactions. (arXiv:2207.00746v2 [cs.CL] UPDATED)",
    "abstract": "In an information-seeking conversation, a user may ask questions that are under-specified or unanswerable. An ideal agent would interact by initiating different response types according to the available knowledge sources. However, most current studies either fail to or artificially incorporate such agent-side initiative. This work presents InSCIt, a dataset for Information-Seeking Conversations with mixed-initiative Interactions. It contains 4.7K user-agent turns from 805 human-human conversations where the agent searches over Wikipedia and either directly answers, asks for clarification, or provides relevant information to address user queries. The data supports two subtasks, evidence passage identification and response generation, as well as a human evaluation protocol to assess model performance. We report results of two systems based on state-of-the-art models of conversational knowledge identification and open-domain question answering. Both systems significantly underperform huma",
    "link": "http://arxiv.org/abs/2207.00746",
    "context": "Title: INSCIT: Information-Seeking Conversations with Mixed-Initiative Interactions. (arXiv:2207.00746v2 [cs.CL] UPDATED)\nAbstract: In an information-seeking conversation, a user may ask questions that are under-specified or unanswerable. An ideal agent would interact by initiating different response types according to the available knowledge sources. However, most current studies either fail to or artificially incorporate such agent-side initiative. This work presents InSCIt, a dataset for Information-Seeking Conversations with mixed-initiative Interactions. It contains 4.7K user-agent turns from 805 human-human conversations where the agent searches over Wikipedia and either directly answers, asks for clarification, or provides relevant information to address user queries. The data supports two subtasks, evidence passage identification and response generation, as well as a human evaluation protocol to assess model performance. We report results of two systems based on state-of-the-art models of conversational knowledge identification and open-domain question answering. Both systems significantly underperform huma",
    "path": "papers/22/07/2207.00746.json",
    "total_tokens": 935,
    "translated_title": "INSCIT: 混合主动交互的信息查寻对话",
    "translated_abstract": "在信息查寻对话中，用户可能会提出模糊或无法回答的问题。理想的代理人应根据可用的知识源启动不同的响应类型进行交互。然而，大多数当前的研究要么未能够，要么人为地纳入这种代理人端的主动性。本文提出了 InSCIt 数据集，用于混合主动交互的信息查寻对话。它包含805个人-人对话中4.7K个用户-代理人交互，其中代理人在维基百科上搜索，直接回答、要求澄清或提供相关信息以回应用户的查询。该数据支持两个子任务，证据段落识别和回答生成，以及一个人工评估协议，以评估模型性能。我们报告了两个基于最先进的对话知识识别和开放域问答模型的系统的结果。这两个系统都明显表现不及人类。",
    "tldr": "本文提出了 InSCIt 数据集，用于混合主动交互的信息查寻对话，其中代理人在维基百科上搜索，直接回答、要求澄清或提供相关信息以回应用户的查询。该数据集包含两个子任务（证据段落识别和回答生成）以及人工评估协议，可用于评估模型性能。",
    "en_tdlr": "This paper presents the InSCIt dataset for information-seeking conversations with mixed-initiative interactions, which contains user-agent interactions where the agent searches over Wikipedia and either directly answers, asks for clarification, or provides relevant information to address user queries. The dataset supports two subtasks (evidence passage identification and response generation) and a human evaluation protocol for assessing model performance."
}