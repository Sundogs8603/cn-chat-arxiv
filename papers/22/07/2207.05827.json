{
    "title": "Differentially Private Linear Bandits with Partial Distributed Feedback",
    "abstract": "arXiv:2207.05827v2 Announce Type: replace  Abstract: In this paper, we study the problem of global reward maximization with only partial distributed feedback. This problem is motivated by several real-world applications (e.g., cellular network configuration, dynamic pricing, and policy selection) where an action taken by a central entity influences a large population that contributes to the global reward. However, collecting such reward feedback from the entire population not only incurs a prohibitively high cost but often leads to privacy concerns. To tackle this problem, we consider differentially private distributed linear bandits, where only a subset of users from the population are selected (called clients) to participate in the learning process and the central server learns the global model from such partial feedback by iteratively aggregating these clients' local feedback in a differentially private fashion. We then propose a unified algorithmic learning framework, called differ",
    "link": "https://arxiv.org/abs/2207.05827",
    "context": "Title: Differentially Private Linear Bandits with Partial Distributed Feedback\nAbstract: arXiv:2207.05827v2 Announce Type: replace  Abstract: In this paper, we study the problem of global reward maximization with only partial distributed feedback. This problem is motivated by several real-world applications (e.g., cellular network configuration, dynamic pricing, and policy selection) where an action taken by a central entity influences a large population that contributes to the global reward. However, collecting such reward feedback from the entire population not only incurs a prohibitively high cost but often leads to privacy concerns. To tackle this problem, we consider differentially private distributed linear bandits, where only a subset of users from the population are selected (called clients) to participate in the learning process and the central server learns the global model from such partial feedback by iteratively aggregating these clients' local feedback in a differentially private fashion. We then propose a unified algorithmic learning framework, called differ",
    "path": "papers/22/07/2207.05827.json",
    "total_tokens": 829,
    "translated_title": "具有部分分布式反馈的差分私有线性Bandits",
    "translated_abstract": "在本文中，我们研究了仅具有部分分布式反馈时的全局奖励最大化问题。 这个问题受到几个现实世界应用的启发（例如，蜂窝网络配置，动态定价和策略选择），在这些应用中，中央实体采取的一个行动影响了为全局奖励做出贡献的大量人口。 然而，从整个人口收集这样的奖励反馈不仅成本过高，而且通常会引起隐私问题。 为了解决这个问题，我们考虑具有差分私有分布式线性Bandits，其中仅选择人口的一个子集（称为客户端）参与学习过程，并且中央服务器通过在不同于差分的隐私方式中迭代聚合这些客户端的本地反馈来从这些部分反馈中学习全局模型。 然后，我们提出一个统一的算法学习框架，称为 differ",
    "tldr": "该论文研究了具有部分分布式反馈的差分私有线性Bandits，在隐私保护的前提下实现了全局奖励的最大化",
    "en_tdlr": "This paper investigates differentially private linear bandits with partial distributed feedback, achieving global reward maximization while ensuring privacy protection."
}