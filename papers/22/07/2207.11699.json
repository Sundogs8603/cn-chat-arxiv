{
    "title": "Semi-supervised Deep Multi-view Stereo. (arXiv:2207.11699v3 [cs.CV] UPDATED)",
    "abstract": "Significant progress has been witnessed in learning-based Multi-view Stereo (MVS) under supervised and unsupervised settings. To combine their respective merits in accuracy and completeness, meantime reducing the demand for expensive labeled data, this paper explores the problem of learning-based MVS in a semi-supervised setting that only a tiny part of the MVS data is attached with dense depth ground truth. However, due to huge variation of scenarios and flexible settings in views, it may break the basic assumption in classic semi-supervised learning, that unlabeled data and labeled data share the same label space and data distribution, named as semi-supervised distribution-gap ambiguity in the MVS problem. To handle these issues, we propose a novel semi-supervised distribution-augmented MVS framework, namely SDA-MVS. For the simple case that the basic assumption works in MVS data, consistency regularization encourages the model predictions to be consistent between original sample and",
    "link": "http://arxiv.org/abs/2207.11699",
    "context": "Title: Semi-supervised Deep Multi-view Stereo. (arXiv:2207.11699v3 [cs.CV] UPDATED)\nAbstract: Significant progress has been witnessed in learning-based Multi-view Stereo (MVS) under supervised and unsupervised settings. To combine their respective merits in accuracy and completeness, meantime reducing the demand for expensive labeled data, this paper explores the problem of learning-based MVS in a semi-supervised setting that only a tiny part of the MVS data is attached with dense depth ground truth. However, due to huge variation of scenarios and flexible settings in views, it may break the basic assumption in classic semi-supervised learning, that unlabeled data and labeled data share the same label space and data distribution, named as semi-supervised distribution-gap ambiguity in the MVS problem. To handle these issues, we propose a novel semi-supervised distribution-augmented MVS framework, namely SDA-MVS. For the simple case that the basic assumption works in MVS data, consistency regularization encourages the model predictions to be consistent between original sample and",
    "path": "papers/22/07/2207.11699.json",
    "total_tokens": 908,
    "translated_title": "半监督深度多视图立体",
    "translated_abstract": "在监督和无监督设置下，学习为基础的多视图立体(MVS)取得了显著进展。为了将它们各自的优点(准确性和完整性)结合起来，同时减少对昂贵有标签数据的需求，本文探讨了仅有一小部分MVS数据附带稠密深度准确值的半监督设置下的学习式MVS问题。然而，由于视图中的场景巨大变化和灵活设置，这可能破坏了经典半监督学习的基本假设，即无标签数据和有标签数据共享相同的标签空间和数据分布，在MVS问题中称为半监督分布间隙多义性。为了处理这些问题，我们提出了一种新颖的半监督分布增强MVS框架，即SDA-MVS。对于MVS数据中基本假设适用的简单情况，一致性正则化鼓励模型预测在原始样本和...",
    "tldr": "本文针对学习式多视图立体问题，探讨了仅有一部分带有深度准确值的数据的半监督设置。通过引入新的半监督分布增强框架，提出了一种方法来解决MVS中的分布间隙多义性问题。"
}