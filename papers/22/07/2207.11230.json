{
    "title": "You Actually Look Twice At it (YALTAi): using an object detection approach instead of region segmentation within the Kraken engine. (arXiv:2207.11230v2 [cs.CV] UPDATED)",
    "abstract": "Layout Analysis (the identification of zones and their classification) is the first step along line segmentation in Optical Character Recognition and similar tasks. The ability of identifying main body of text from marginal text or running titles makes the difference between extracting the work full text of a digitized book and noisy outputs. We show that most segmenters focus on pixel classification and that polygonization of this output has not been used as a target for the latest competition on historical document (ICDAR 2017 and onwards), despite being the focus in the early 2010s. We propose to shift, for efficiency, the task from a pixel classification-based polygonization to an object detection using isothetic rectangles. We compare the output of Kraken and YOLOv5 in terms of segmentation and show that the later severely outperforms the first on small datasets (1110 samples and below). We release two datasets for training and evaluation on historical documents as well as a new p",
    "link": "http://arxiv.org/abs/2207.11230",
    "context": "Title: You Actually Look Twice At it (YALTAi): using an object detection approach instead of region segmentation within the Kraken engine. (arXiv:2207.11230v2 [cs.CV] UPDATED)\nAbstract: Layout Analysis (the identification of zones and their classification) is the first step along line segmentation in Optical Character Recognition and similar tasks. The ability of identifying main body of text from marginal text or running titles makes the difference between extracting the work full text of a digitized book and noisy outputs. We show that most segmenters focus on pixel classification and that polygonization of this output has not been used as a target for the latest competition on historical document (ICDAR 2017 and onwards), despite being the focus in the early 2010s. We propose to shift, for efficiency, the task from a pixel classification-based polygonization to an object detection using isothetic rectangles. We compare the output of Kraken and YOLOv5 in terms of segmentation and show that the later severely outperforms the first on small datasets (1110 samples and below). We release two datasets for training and evaluation on historical documents as well as a new p",
    "path": "papers/22/07/2207.11230.json",
    "total_tokens": 939,
    "translated_title": "使用对象检测方法而非区域分割在Kraken引擎中进行布局分析",
    "translated_abstract": "布局分析是光学字符识别等任务中线分割的第一步，它是识别区域和进行分类的过程。从边缘文本或标题中识别正文是提取数字化书籍全文和产生噪音输出之间的区别。我们发现，大多数分割器都专注于像素分类，而且尽管在2010年代初期是重点研究领域，但将此输出的多边形化作为历史文档最新竞赛（ICDAR 2017及以后）的目标尚未得到广泛应用。为了在效率上改进，我们提出将任务从基于像素分类的多边形化转变为使用等宽矩形的对象检测。通过对比Kraken和YOLOv5在分割方面的输出，我们发现后者在小数据集（1110个样本及以下）上表现优异。我们发布了两个历史文档培训和评估数据集，以及一个新的p...",
    "tldr": "本研究使用对象检测方法替代了区域分割，提出了一种高效的布局分析方法。通过与Kraken和YOLOv5对比，我们发现使用YOLOv5在小数据集上的分割效果显著优于Kraken。研究还发布了两个历史文档数据集和一个新的p..."
}