{
    "title": "Back to the Source: Diffusion-Driven Test-Time Adaptation. (arXiv:2207.03442v2 [cs.LG] UPDATED)",
    "abstract": "Test-time adaptation harnesses test inputs to improve the accuracy of a model trained on source data when tested on shifted target data. Existing methods update the source model by (re-)training on each target domain. While effective, re-training is sensitive to the amount and order of the data and the hyperparameters for optimization. We instead update the target data, by projecting all test inputs toward the source domain with a generative diffusion model. Our diffusion-driven adaptation method, DDA, shares its models for classification and generation across all domains. Both models are trained on the source domain, then fixed during testing. We augment diffusion with image guidance and self-ensembling to automatically decide how much to adapt. Input adaptation by DDA is more robust than prior model adaptation approaches across a variety of corruptions, architectures, and data regimes on the ImageNet-C benchmark. With its input-wise updates, DDA succeeds where model adaptation degrad",
    "link": "http://arxiv.org/abs/2207.03442",
    "context": "Title: Back to the Source: Diffusion-Driven Test-Time Adaptation. (arXiv:2207.03442v2 [cs.LG] UPDATED)\nAbstract: Test-time adaptation harnesses test inputs to improve the accuracy of a model trained on source data when tested on shifted target data. Existing methods update the source model by (re-)training on each target domain. While effective, re-training is sensitive to the amount and order of the data and the hyperparameters for optimization. We instead update the target data, by projecting all test inputs toward the source domain with a generative diffusion model. Our diffusion-driven adaptation method, DDA, shares its models for classification and generation across all domains. Both models are trained on the source domain, then fixed during testing. We augment diffusion with image guidance and self-ensembling to automatically decide how much to adapt. Input adaptation by DDA is more robust than prior model adaptation approaches across a variety of corruptions, architectures, and data regimes on the ImageNet-C benchmark. With its input-wise updates, DDA succeeds where model adaptation degrad",
    "path": "papers/22/07/2207.03442.json",
    "total_tokens": 930,
    "translated_title": "回到源头: 扩散驱动的测试时自适应",
    "translated_abstract": "测试时自适应利用测试输入来提高源数据训练的模型在经过移动的目标数据时的准确性。现有的方法通过在每个目标域中重复训练来更新源模型。虽然有效，但重新训练对于数据量和顺序以及优化的超参数非常敏感。相反，我们通过将所有测试输入投影到具有生成扩散模型的源域中来更新目标数据。我们的扩散驱动适应方法 DDA 在所有域中共享其用于分类和生成的模型。这两个模型在源域中训练，然后在测试期间固定。我们通过图像引导和自学习来增强扩散，以自动决定适应程度。相比以前的模型适应方法，DDA 的输入适应对于 ImageNet-C 数据集中各种损坏、架构和数据情况更为稳健。在输入逐个更新的情况下，DDA 成功地克服了模型适应所面临的问题。",
    "tldr": "本文提出了基于扩散驱动的测试时自适应方法 DDA，通过将测试输入投影到生成扩散模型的源域中来更新目标数据，相比以往的模型适应方法更为稳健，适用于各种损坏、架构和数据情况。"
}