{
    "title": "Nonlinear Sufficient Dimension Reduction for Distribution-on-Distribution Regression. (arXiv:2207.04613v2 [stat.ME] UPDATED)",
    "abstract": "We introduce a new approach to nonlinear sufficient dimension reduction in cases where both the predictor and the response are distributional data, modeled as members of a metric space. Our key step is to build universal kernels (cc-universal) on the metric spaces, which results in reproducing kernel Hilbert spaces for the predictor and response that are rich enough to characterize the conditional independence that determines sufficient dimension reduction. For univariate distributions, we construct the universal kernel using the Wasserstein distance, while for multivariate distributions, we resort to the sliced Wasserstein distance. The sliced Wasserstein distance ensures that the metric space possesses similar topological properties to the Wasserstein space while also offering significant computation benefits. Numerical results based on synthetic data show that our method outperforms possible competing methods. The method is also applied to several data sets, including fertility and ",
    "link": "http://arxiv.org/abs/2207.04613",
    "context": "Title: Nonlinear Sufficient Dimension Reduction for Distribution-on-Distribution Regression. (arXiv:2207.04613v2 [stat.ME] UPDATED)\nAbstract: We introduce a new approach to nonlinear sufficient dimension reduction in cases where both the predictor and the response are distributional data, modeled as members of a metric space. Our key step is to build universal kernels (cc-universal) on the metric spaces, which results in reproducing kernel Hilbert spaces for the predictor and response that are rich enough to characterize the conditional independence that determines sufficient dimension reduction. For univariate distributions, we construct the universal kernel using the Wasserstein distance, while for multivariate distributions, we resort to the sliced Wasserstein distance. The sliced Wasserstein distance ensures that the metric space possesses similar topological properties to the Wasserstein space while also offering significant computation benefits. Numerical results based on synthetic data show that our method outperforms possible competing methods. The method is also applied to several data sets, including fertility and ",
    "path": "papers/22/07/2207.04613.json",
    "total_tokens": 955,
    "translated_title": "分布回归的非线性充分降维",
    "translated_abstract": "我们提出了一种新的非线性充分降维方法，用于同时处理预测变量和响应变量均为分布数据的情形，这两种数据都被建模为度量空间中的成员。我们的关键步骤是在度量空间上构建通用核，以建立可以描述决定充分降维的条件独立性的预测变量和响应变量的复现核希尔伯特空间。对于单变量分布，我们使用Wasserstein距离构建通用核，而对于多元分布，我们则采用分片Wasserstein距离。分片Wasserstein距离确保度量空间具有与Wasserstein空间相似的拓扑特性，同时还提供了显著的计算优势。基于合成数据的数值结果表明，我们的方法优于可能的竞争方法。该方法也被应用于多个数据集，包括生育数据和...",
    "tldr": "本文提出了一种新的非线性降维方法，用于同时处理预测变量和响应变量均为分布数据的情形。该方法使用通用核建立预测变量和响应变量的复现核希尔伯特空间以描述条件独立性，对于单变量分布和多元分布分别采用Wasserstein距离和分片Wasserstein距离构建通用核，经合成数据测试表现优于竞争方法。"
}