{
    "title": "Using Anomaly Detection to Detect Poisoning Attacks in Federated Learning Applications. (arXiv:2207.08486v2 [cs.LG] UPDATED)",
    "abstract": "Adversarial attacks such as poisoning attacks have attracted the attention of many machine learning researchers. Traditionally, poisoning attacks attempt to inject adversarial training data in order to manipulate the trained model. In federated learning (FL), data poisoning attacks can be generalized to model poisoning attacks, which cannot be detected by simpler methods due to the lack of access to local training data by the detector. State-of-the-art poisoning attack detection methods for FL have various weaknesses, e.g., the number of attackers has to be known or not high enough, working with i.i.d. data only, and high computational complexity. To overcome above weaknesses, we propose a novel framework for detecting poisoning attacks in FL, which employs a reference model based on a public dataset and an auditor model to detect malicious updates. We implemented a detector based on the proposed framework and using a one-class support vector machine (OC-SVM), which reaches the lowest ",
    "link": "http://arxiv.org/abs/2207.08486",
    "context": "Title: Using Anomaly Detection to Detect Poisoning Attacks in Federated Learning Applications. (arXiv:2207.08486v2 [cs.LG] UPDATED)\nAbstract: Adversarial attacks such as poisoning attacks have attracted the attention of many machine learning researchers. Traditionally, poisoning attacks attempt to inject adversarial training data in order to manipulate the trained model. In federated learning (FL), data poisoning attacks can be generalized to model poisoning attacks, which cannot be detected by simpler methods due to the lack of access to local training data by the detector. State-of-the-art poisoning attack detection methods for FL have various weaknesses, e.g., the number of attackers has to be known or not high enough, working with i.i.d. data only, and high computational complexity. To overcome above weaknesses, we propose a novel framework for detecting poisoning attacks in FL, which employs a reference model based on a public dataset and an auditor model to detect malicious updates. We implemented a detector based on the proposed framework and using a one-class support vector machine (OC-SVM), which reaches the lowest ",
    "path": "papers/22/07/2207.08486.json",
    "total_tokens": 921,
    "tldr": "本研究提出了一种在联邦学习中检测污染攻击的框架，该框架利用基于公共数据集的参考模型和审核人模型来检测恶意更新。",
    "en_tdlr": "This paper proposes a framework to detect poisoning attacks in federated learning using a reference model based on a public dataset and an auditor model, addressing the weaknesses of previous methods in terms of the number of attackers, i.i.d. data, and computational complexity."
}