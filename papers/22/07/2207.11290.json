{
    "title": "TRUST-LAPSE: An Explainable and Actionable Mistrust Scoring Framework for Model Monitoring. (arXiv:2207.11290v2 [cs.LG] UPDATED)",
    "abstract": "Continuous monitoring of trained ML models to determine when their predictions should and should not be trusted is essential for their safe deployment. Such a framework ought to be high-performing, explainable, post-hoc and actionable. We propose TRUST-LAPSE, a \"mistrust\" scoring framework for continuous model monitoring. We assess the trustworthiness of each input sample's model prediction using a sequence of latent-space embeddings. Specifically, (a) our latent-space mistrust score estimates mistrust using distance metrics (Mahalanobis distance) and similarity metrics (cosine similarity) in the latent-space and (b) our sequential mistrust score determines deviations in correlations over the sequence of past input representations in a non-parametric, sliding-window based algorithm for actionable continuous monitoring. We evaluate TRUST-LAPSE via two downstream tasks: (1) distributionally shifted input detection, and (2) data drift detection. We evaluate across diverse domains - audio ",
    "link": "http://arxiv.org/abs/2207.11290",
    "context": "Title: TRUST-LAPSE: An Explainable and Actionable Mistrust Scoring Framework for Model Monitoring. (arXiv:2207.11290v2 [cs.LG] UPDATED)\nAbstract: Continuous monitoring of trained ML models to determine when their predictions should and should not be trusted is essential for their safe deployment. Such a framework ought to be high-performing, explainable, post-hoc and actionable. We propose TRUST-LAPSE, a \"mistrust\" scoring framework for continuous model monitoring. We assess the trustworthiness of each input sample's model prediction using a sequence of latent-space embeddings. Specifically, (a) our latent-space mistrust score estimates mistrust using distance metrics (Mahalanobis distance) and similarity metrics (cosine similarity) in the latent-space and (b) our sequential mistrust score determines deviations in correlations over the sequence of past input representations in a non-parametric, sliding-window based algorithm for actionable continuous monitoring. We evaluate TRUST-LAPSE via two downstream tasks: (1) distributionally shifted input detection, and (2) data drift detection. We evaluate across diverse domains - audio ",
    "path": "papers/22/07/2207.11290.json",
    "total_tokens": 960,
    "translated_title": "TRUST-LAPSE：一种可解释和可操作的模型监控不信任评分框架",
    "translated_abstract": "连续监测训练好的机器学习模型，在确定何时应该信任它们的预测和何时不应该信任它们的预测方面非常重要，这对于安全部署是必需的。我们提出了TRUST-LAPSE，这是一个用于连续模型监控的“不信任”评分框架。我们使用一系列潜空间嵌入来评估每个输入样本的模型预测的可信度。具体来说，（a）我们的潜空间不信任评分使用潜空间中的距离度量（马氏距离）和相似度度量（余弦相似度）来估计不信任度，（b）我们的顺序不信任评分使用非参数、滑动窗口算法来确定过去输入表示序列中的相关性偏差，从而实现可操作的连续监控。我们通过两个下游任务对TRUST-LAPSE进行评估：（1）分布偏移输入检测，（2）数据漂移检测。我们在不同领域进行评估-音频...",
    "tldr": "TRUST-LAPSE是一个可解释和可操作的连续模型监控框架，通过使用潜空间嵌入评估每个输入样本的模型预测的可信度，并利用距离和相似度度量以及顺序相关性偏差来实现对模型的连续监控。",
    "en_tdlr": "TRUST-LAPSE is an explainable and actionable framework for continuous model monitoring. It assesses the trustworthiness of model predictions for each input sample using latent-space embeddings and evaluates deviations in correlations over input representations for continuous monitoring."
}