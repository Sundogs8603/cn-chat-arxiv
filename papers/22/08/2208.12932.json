{
    "title": "BOBA: Byzantine-Robust Federated Learning with Label Skewness",
    "abstract": "arXiv:2208.12932v2 Announce Type: replace  Abstract: In federated learning, most existing robust aggregation rules (AGRs) combat Byzantine attacks in the IID setting, where client data is assumed to be independent and identically distributed. In this paper, we address label skewness, a more realistic and challenging non-IID setting, where each client only has access to a few classes of data. In this setting, state-of-the-art AGRs suffer from selection bias, leading to significant performance drop for particular classes; they are also more vulnerable to Byzantine attacks due to the increased variation among gradients of honest clients. To address these limitations, we propose an efficient two-stage method named BOBA. Theoretically, we prove the convergence of BOBA with an error of the optimal order. Our empirical evaluations demonstrate BOBA's superior unbiasedness and robustness across diverse models and datasets when compared to various baselines. Our code is available at https://gith",
    "link": "https://arxiv.org/abs/2208.12932",
    "context": "Title: BOBA: Byzantine-Robust Federated Learning with Label Skewness\nAbstract: arXiv:2208.12932v2 Announce Type: replace  Abstract: In federated learning, most existing robust aggregation rules (AGRs) combat Byzantine attacks in the IID setting, where client data is assumed to be independent and identically distributed. In this paper, we address label skewness, a more realistic and challenging non-IID setting, where each client only has access to a few classes of data. In this setting, state-of-the-art AGRs suffer from selection bias, leading to significant performance drop for particular classes; they are also more vulnerable to Byzantine attacks due to the increased variation among gradients of honest clients. To address these limitations, we propose an efficient two-stage method named BOBA. Theoretically, we prove the convergence of BOBA with an error of the optimal order. Our empirical evaluations demonstrate BOBA's superior unbiasedness and robustness across diverse models and datasets when compared to various baselines. Our code is available at https://gith",
    "path": "papers/22/08/2208.12932.json",
    "total_tokens": 965,
    "translated_title": "BOBA：具有标签偏斜度的拜占庭-强健联邦学习",
    "translated_abstract": "在联邦学习中，大多数现有的抗击拜占庭攻击的鲁棒聚合规则（AGRs）是针对独立同分布（IID）设置而设计的。在这篇论文中，我们解决了标签偏斜度这一更加现实和具有挑战性的非IID设置，其中每个客户端只能访问少数类别的数据。在这种情况下，最先进的AGR存在着选择偏差，导致特定类别的性能显著下降；由于诚实客户端的梯度之间的变化增加，它们也更容易受到拜占庭攻击的影响。为了解决这些局限性，我们提出了一种名为BOBA的高效的两阶段方法。理论上，我们证明了BOBA的收敛性具有最佳级别的误差。我们的实证评估表明，在与各种基线模型和数据集相比，BOBA在各种模型和数据集上的无偏性和鲁棒性方面表现出优势。我们的代码可在https://gith上获得",
    "tldr": "提出了一种名为BOBA的拜占庭-强健联邦学习方法，针对非IID设置中的标签偏斜问题，通过两阶段方法解决了现有方法中存在的选择偏差和拜占庭攻击易受影响的问题，并在理论和实证评估中都验证了其优越性。",
    "en_tdlr": "Introduced BOBA, a Byzantine-robust federated learning method that tackles label skewness in the non-IID setting, addressing selection bias and vulnerability to Byzantine attacks, with theoretical convergence proof and empirical superiority over existing methods."
}