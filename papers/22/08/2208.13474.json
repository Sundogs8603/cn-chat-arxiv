{
    "title": "Prompt Tuning with Soft Context Sharing for Vision-Language Models",
    "abstract": "arXiv:2208.13474v2 Announce Type: replace-cross  Abstract: Vision-language models have recently shown great potential on many tasks in computer vision. Meanwhile, prior work demonstrates prompt tuning designed for vision-language models could acquire superior performance on few-shot image recognition compared to linear probe, a strong baseline. In practice, many few-shot tasks are inherently correlated, particularly within specialized domains. However, such information is overlooked previously. Inspired by the fact that modeling task relationship by multi-task learning can usually boost performance, we propose a novel method SoftCPT (Soft Context Sharing for Prompt Tuning) to tune pre-trained vision-language models on multiple target few-shot tasks jointly. Specifically, we design a task-shared meta network to generate prompt context for each task using task name together with a learnable task context as input. The parameters of this meta network as well as the task context are tuned o",
    "link": "https://arxiv.org/abs/2208.13474",
    "context": "Title: Prompt Tuning with Soft Context Sharing for Vision-Language Models\nAbstract: arXiv:2208.13474v2 Announce Type: replace-cross  Abstract: Vision-language models have recently shown great potential on many tasks in computer vision. Meanwhile, prior work demonstrates prompt tuning designed for vision-language models could acquire superior performance on few-shot image recognition compared to linear probe, a strong baseline. In practice, many few-shot tasks are inherently correlated, particularly within specialized domains. However, such information is overlooked previously. Inspired by the fact that modeling task relationship by multi-task learning can usually boost performance, we propose a novel method SoftCPT (Soft Context Sharing for Prompt Tuning) to tune pre-trained vision-language models on multiple target few-shot tasks jointly. Specifically, we design a task-shared meta network to generate prompt context for each task using task name together with a learnable task context as input. The parameters of this meta network as well as the task context are tuned o",
    "path": "papers/22/08/2208.13474.json",
    "total_tokens": 859,
    "translated_title": "使用软上下文共享的提示调整视觉-语言模型",
    "translated_abstract": "视觉-语言模型最近在计算机视觉的许多任务中展现出了巨大潜力。与此同时，先前的研究表明，专为视觉-语言模型设计的提示调整相较于线性探测（一种强基准）在少样本图像识别方面可以获得更优异的性能。在实践中，许多少样本任务在本质上是相关的，特别是在专业领域内。然而，这样的信息先前被忽视了。受到将任务关系建模为多任务学习通常可以提升性能的启发，我们提出了一种新颖的方法SoftCPT（用于提示调整的软上下文共享）来联合调整预训练的视觉-语言模型对多个目标少样本任务进行调整。具体地，我们设计了一个任务共享的元网络，利用任务名称以及可学习的任务上下文作为输入为每个任务生成提示上下文。这个元网络的参数以及任务上下文被调整为",
    "tldr": "提出了一种名为SoftCPT的新方法，利用软上下文共享来联合调整预训练的视觉-语言模型对多个目标少样本任务进行调整，并设计了一个任务共享的元网络来生成提示上下文。",
    "en_tdlr": "Proposed a novel method named SoftCPT that jointly tunes pre-trained vision-language models on multiple target few-shot tasks using soft context sharing, and designed a task-shared meta network to generate prompt context."
}