{
    "title": "Shortcut Learning of Large Language Models in Natural Language Understanding. (arXiv:2208.11857v2 [cs.CL] UPDATED)",
    "abstract": "Large language models (LLMs) have achieved state-of-the-art performance on a series of natural language understanding tasks. However, these LLMs might rely on dataset bias and artifacts as shortcuts for prediction. This has significantly affected their generalizability and adversarial robustness. In this paper, we provide a review of recent developments that address the shortcut learning and robustness challenge of LLMs. We first introduce the concepts of shortcut learning of language models. We then introduce methods to identify shortcut learning behavior in language models, characterize the reasons for shortcut learning, as well as introduce mitigation solutions. Finally, we discuss key research challenges and potential research directions in order to advance the field of LLMs.",
    "link": "http://arxiv.org/abs/2208.11857",
    "context": "Title: Shortcut Learning of Large Language Models in Natural Language Understanding. (arXiv:2208.11857v2 [cs.CL] UPDATED)\nAbstract: Large language models (LLMs) have achieved state-of-the-art performance on a series of natural language understanding tasks. However, these LLMs might rely on dataset bias and artifacts as shortcuts for prediction. This has significantly affected their generalizability and adversarial robustness. In this paper, we provide a review of recent developments that address the shortcut learning and robustness challenge of LLMs. We first introduce the concepts of shortcut learning of language models. We then introduce methods to identify shortcut learning behavior in language models, characterize the reasons for shortcut learning, as well as introduce mitigation solutions. Finally, we discuss key research challenges and potential research directions in order to advance the field of LLMs.",
    "path": "papers/22/08/2208.11857.json",
    "total_tokens": 831,
    "translated_title": "自然语言理解中大型语言模型的快捷学习",
    "translated_abstract": "大型语言模型(LLMs)在一系列自然语言理解任务中取得了最先进的性能。然而，这些LLMs可能会依赖于数据集的偏见和缺陷作为预测的快捷方式。这显著地影响了它们的泛化能力和对抗鲁棒性。本文综述了最近解决LLMs快捷学习和鲁棒性挑战的发展。我们首先介绍语言模型的快捷学习概念。然后介绍了识别语言模型快捷学习行为的方法，表征快捷学习的原因，并介绍了缓解解决方案。最后，我们讨论了LLMs领域的主要研究挑战和潜在研究方向。",
    "tldr": "本文综述了大型语言模型中快捷学习和鲁棒性挑战的解决方法和相关研究，包括识别其快捷学习行为、原因和解决方案，并探讨了领域的主要研究挑战和潜在研究方向。",
    "en_tdlr": "This paper provides a review of recent developments in addressing shortcut learning and robustness challenges in large language models, including identifying shortcut learning behavior, its reasons and mitigation solutions, as well as discussing key research challenges and potential research directions in the field of LLMs."
}