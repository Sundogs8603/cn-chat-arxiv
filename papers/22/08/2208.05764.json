{
    "title": "The dynamics of belief: continuously monitoring and visualising complex systems. (arXiv:2208.05764v2 [cs.AI] UPDATED)",
    "abstract": "The rise of AI in human contexts places new demands on automated systems to be transparent and explainable. We examine some anthropomorphic ideas and principles relevant to such accountablity in order to develop a theoretical framework for thinking about digital systems in complex human contexts and the problem of explaining their behaviour. Structurally, systems are made of modular and hierachical components, which we abstract in a new system model using notions of modes and mode transitions. A mode is an independent component of the system with its own objectives, monitoring data, and algorithms. The behaviour of a mode, including its transitions to other modes, is determined by functions that interpret each mode's monitoring data in the light of its objectives and algorithms. We show how these belief functions can help explain system behaviour by visualising their evaluation as trajectories in higher-dimensional geometric spaces. These ideas are formalised mathematically by abstract",
    "link": "http://arxiv.org/abs/2208.05764",
    "context": "Title: The dynamics of belief: continuously monitoring and visualising complex systems. (arXiv:2208.05764v2 [cs.AI] UPDATED)\nAbstract: The rise of AI in human contexts places new demands on automated systems to be transparent and explainable. We examine some anthropomorphic ideas and principles relevant to such accountablity in order to develop a theoretical framework for thinking about digital systems in complex human contexts and the problem of explaining their behaviour. Structurally, systems are made of modular and hierachical components, which we abstract in a new system model using notions of modes and mode transitions. A mode is an independent component of the system with its own objectives, monitoring data, and algorithms. The behaviour of a mode, including its transitions to other modes, is determined by functions that interpret each mode's monitoring data in the light of its objectives and algorithms. We show how these belief functions can help explain system behaviour by visualising their evaluation as trajectories in higher-dimensional geometric spaces. These ideas are formalised mathematically by abstract",
    "path": "papers/22/08/2208.05764.json",
    "total_tokens": 917,
    "translated_title": "信念的动态：连续监测和可视化复杂系统",
    "translated_abstract": "人类环境中人工智能的崛起对自动化系统提出了新的透明和可解释性要求。我们研究了与这种可解释性相关的一些拟人化思想和原则，以便在复杂人类环境中开发关于数字系统的理论框架，并解决解释其行为的问题。就结构而言，系统由模块化和层次化组件构成，我们使用模式和模式转换的概念在一个新的系统模型中对其进行抽象。模式是系统的独立组件，具有自己的目标、监测数据和算法。模式的行为，包括其向其他模式的转换，由解释每个模式的监测数据并根据其目标和算法的函数确定。我们通过将这些信念函数的评估视觉化为高维几何空间中的轨迹来展示它们如何帮助解释系统行为。这些思想在数学上被抽象化。",
    "tldr": "本论文研究了在人类环境中人工智能的透明和可解释性问题，提出了一种关于数字系统的理论框架，利用模式和模式转换的概念对系统的结构进行抽象。通过将信念函数的评估视觉化为高维几何空间中的轨迹，解释了系统行为。",
    "en_tdlr": "This paper examines the transparency and explainability challenges of AI in human contexts and proposes a theoretical framework for digital systems. It abstracts system structure using modes and mode transitions, and visualizes belief functions as trajectories in higher-dimensional geometric spaces to explain system behavior."
}