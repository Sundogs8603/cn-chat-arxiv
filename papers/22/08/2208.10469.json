{
    "title": "Get It in Writing: Formal Contracts Mitigate Social Dilemmas in Multi-Agent RL. (arXiv:2208.10469v3 [cs.AI] UPDATED)",
    "abstract": "Multi-agent reinforcement learning (MARL) is a powerful tool for training automated systems acting independently in a common environment. However, it can lead to sub-optimal behavior when individual incentives and group incentives diverge. Humans are remarkably capable at solving these social dilemmas. It is an open problem in MARL to replicate such cooperative behaviors in selfish agents. In this work, we draw upon the idea of formal contracting from economics to overcome diverging incentives between agents in MARL. We propose an augmentation to a Markov game where agents voluntarily agree to binding state-dependent transfers of reward, under pre-specified conditions. Our contributions are theoretical and empirical. First, we show that this augmentation makes all subgame-perfect equilibria of all fully observed Markov games exhibit socially optimal behavior, given a sufficiently rich space of contracts. Next, we complement our game-theoretic analysis by showing that state-of-the-art R",
    "link": "http://arxiv.org/abs/2208.10469",
    "context": "Title: Get It in Writing: Formal Contracts Mitigate Social Dilemmas in Multi-Agent RL. (arXiv:2208.10469v3 [cs.AI] UPDATED)\nAbstract: Multi-agent reinforcement learning (MARL) is a powerful tool for training automated systems acting independently in a common environment. However, it can lead to sub-optimal behavior when individual incentives and group incentives diverge. Humans are remarkably capable at solving these social dilemmas. It is an open problem in MARL to replicate such cooperative behaviors in selfish agents. In this work, we draw upon the idea of formal contracting from economics to overcome diverging incentives between agents in MARL. We propose an augmentation to a Markov game where agents voluntarily agree to binding state-dependent transfers of reward, under pre-specified conditions. Our contributions are theoretical and empirical. First, we show that this augmentation makes all subgame-perfect equilibria of all fully observed Markov games exhibit socially optimal behavior, given a sufficiently rich space of contracts. Next, we complement our game-theoretic analysis by showing that state-of-the-art R",
    "path": "papers/22/08/2208.10469.json",
    "total_tokens": 1112,
    "translated_title": "写下来吧：正式合同缓解多智能体强化学习中的社会困境",
    "translated_abstract": "多智能体强化学习（MARL）是训练在共同环境中独立行动的自动化系统的强大工具。然而，当个体激励和集体激励出现分歧时，它可能导致次优行为。人类在解决这些社会困境方面具有非凡的能力。在MARL中复制这种合作行为对于自私的智能体来说是一个未解决的问题。在这项工作中，我们借鉴了经济学中正式合同的思想，以克服MARL中智能体之间的激励分歧。我们提出了一种对马尔可夫博弈进行增强的方法，智能体自愿同意在预先规定的条件下进行有约束的状态依赖奖励转移。我们的贡献是理论的和实证的。首先，我们展示了这种增强使得所有完全可观察马尔可夫博弈的子博弈完美均衡都表现出社会最优行为，只要合同空间足够丰富。接下来，我们通过展示最先进的强化学习算法在增强后的MARL中表现出更好的社会性能来补充我们的博弈论分析。",
    "tldr": "本研究通过引入正式合同的概念，解决了多智能体强化学习中个体激励和集体激励分歧导致的次优行为问题。理论和实证结果表明，通过在马尔可夫博弈中引入有约束的状态依赖奖励转移，实现了所有可观察马尔可夫博弈的子博弈完美均衡表现出社会最优行为，并提升了算法的社会性能。",
    "en_tdlr": "This study addresses the issue of sub-optimal behavior in multi-agent reinforcement learning caused by diverging individual and group incentives through the introduction of formal contracts. Theoretical and empirical results demonstrate that by implementing state-dependent transfers of reward within a Markov game framework, socially optimal behavior can be achieved in all subgame-perfect equilibria of fully observed Markov games, leading to improved social performance of the algorithms."
}