{
    "title": "StoryTrans: Non-Parallel Story Author-Style Transfer with Discourse Representations and Content Enhancing. (arXiv:2208.13423v2 [cs.CL] UPDATED)",
    "abstract": "Non-parallel text style transfer is an important task in natural language generation. However, previous studies concentrate on the token or sentence level, such as sentence sentiment and formality transfer, but neglect long style transfer at the discourse level. Long texts usually involve more complicated author linguistic preferences such as discourse structures than sentences. In this paper, we formulate the task of non-parallel story author-style transfer, which requires transferring an input story into a specified author style while maintaining source semantics. To tackle this problem, we propose a generation model, named StoryTrans, which leverages discourse representations to capture source content information and transfer them to target styles with learnable style embeddings. We use an additional training objective to disentangle stylistic features from the learned discourse representation to prevent the model from degenerating to an auto-encoder. Moreover, to enhance content pr",
    "link": "http://arxiv.org/abs/2208.13423",
    "context": "Title: StoryTrans: Non-Parallel Story Author-Style Transfer with Discourse Representations and Content Enhancing. (arXiv:2208.13423v2 [cs.CL] UPDATED)\nAbstract: Non-parallel text style transfer is an important task in natural language generation. However, previous studies concentrate on the token or sentence level, such as sentence sentiment and formality transfer, but neglect long style transfer at the discourse level. Long texts usually involve more complicated author linguistic preferences such as discourse structures than sentences. In this paper, we formulate the task of non-parallel story author-style transfer, which requires transferring an input story into a specified author style while maintaining source semantics. To tackle this problem, we propose a generation model, named StoryTrans, which leverages discourse representations to capture source content information and transfer them to target styles with learnable style embeddings. We use an additional training objective to disentangle stylistic features from the learned discourse representation to prevent the model from degenerating to an auto-encoder. Moreover, to enhance content pr",
    "path": "papers/22/08/2208.13423.json",
    "total_tokens": 1074,
    "translated_title": "StoryTrans: 带语篇表示和内容增强的非平行故事作者风格转换",
    "translated_abstract": "非平行文本风格转换是自然语言生成中的重要任务。然而，以往的研究集中在单词或句子级别上，例如句子情感和形式转换，但忽略了在语篇级别上较长的风格转换。长文本通常涉及更为复杂的作者语言偏好，例如语篇结构。本文提出了非平行故事作者风格转换的任务，需要将输入故事转换为指定作者的风格，同时保持源语义。为了解决这个问题，我们提出了一个生成模型，名为StoryTrans，它利用语篇表示来捕捉源内容信息，并使用可学习风格嵌入将它们转换为目标风格。我们使用了额外的训练目标来将风格特征从学习的语篇表示中解开，以防止模型退化为自动编码器。此外，为了强化内容保留，我们引入了一个内容增强模块，改善了输入和输出故事之间的语义一致性。两个数据集上的实验结果表明，我们提出的模型在自动指标和人类评估方面均优于最先进的基线模型。",
    "tldr": "本文提出了StoryTrans模型，用于解决非平行故事作者风格转换的任务。该模型利用语篇表示和可学习的风格嵌入实现源内容信息到目标风格的转换，并引入了一个内容增强模块以提高语义一致性。在两个数据集上的评测中，该模型表现出了显著的性能优势。",
    "en_tdlr": "This paper proposes the StoryTrans model for non-parallel story author-style transfer, which leverages discourse representations and learnable style embeddings to transfer input stories into a specified author style while maintaining source semantics. The model also introduces a content enhancing module to improve semantic consistency. Experimental results show that the proposed model outperforms state-of-the-art baselines on two datasets."
}