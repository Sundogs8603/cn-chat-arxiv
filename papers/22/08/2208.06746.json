{
    "title": "Contrastive Counterfactual Learning for Causality-aware Interpretable Recommender Systems. (arXiv:2208.06746v2 [cs.IR] UPDATED)",
    "abstract": "There has been a recent surge in the study of generating recommendations within the framework of causal inference, with the recommendation being treated as a treatment. This approach enhances our understanding of how recommendations influence user behaviour and allows for identification of the factors that contribute to this impact. Many researchers in the field of causal inference for recommender systems have focused on using propensity scores, which can reduce bias but may also introduce additional variance. Other studies have proposed the use of unbiased data from randomized controlled trials, though this approach requires certain assumptions that may be difficult to satisfy in practice. In this paper, we first explore the causality-aware interpretation of recommendations and show that the underlying exposure mechanism can bias the maximum likelihood estimation (MLE) of observational feedback. Given that confounders may be inaccessible for measurement, we propose using contrastive S",
    "link": "http://arxiv.org/abs/2208.06746",
    "context": "Title: Contrastive Counterfactual Learning for Causality-aware Interpretable Recommender Systems. (arXiv:2208.06746v2 [cs.IR] UPDATED)\nAbstract: There has been a recent surge in the study of generating recommendations within the framework of causal inference, with the recommendation being treated as a treatment. This approach enhances our understanding of how recommendations influence user behaviour and allows for identification of the factors that contribute to this impact. Many researchers in the field of causal inference for recommender systems have focused on using propensity scores, which can reduce bias but may also introduce additional variance. Other studies have proposed the use of unbiased data from randomized controlled trials, though this approach requires certain assumptions that may be difficult to satisfy in practice. In this paper, we first explore the causality-aware interpretation of recommendations and show that the underlying exposure mechanism can bias the maximum likelihood estimation (MLE) of observational feedback. Given that confounders may be inaccessible for measurement, we propose using contrastive S",
    "path": "papers/22/08/2208.06746.json",
    "total_tokens": 1037,
    "translated_title": "因果感知的可解释推荐系统的对比反事实学习",
    "translated_abstract": "最近在因果推断框架下生成推荐的研究有所增加，推荐被视为一种处理，旨在加强我们对推荐如何影响用户行为的理解，并允许确定有助于该影响的因素。许多因果推断领域的研究人员专注于使用倾向分数，这可以减少偏差，但可能会引入额外的差异。其他研究则提出使用随机对照试验中的无偏数据，不过这种方法需要满足一定的假设，这在实践中可能难以满足。本文首先探讨了推荐的因果感知解释，并表明底层的暴露机制可以偏向于最大似然估计（MLE）的观测反馈。鉴于混淆因素可能无法测量，我们提出使用对比S对反事实学习（CCL）来学习鲁棒且可解释的推荐系统。我们的方法使用反事实推理来估计推荐的因果效应，并确定有助于用户行为的关键因素。我们在几个真实数据集上进行实验，证明了我们的方法在准确性和可解释性方面优于现有方法。",
    "tldr": "本文提出了一种因果感知的推荐系统方法，使用对比反事实学习来学习鲁棒且可解释的推荐系统，利用反事实推理来估计推荐的因果效应，并确定有助于用户行为的关键因素。",
    "en_tdlr": "The paper proposes a causality-aware approach for generating interpretable recommendations by using contrastive counterfactual learning to estimate causal effects and identify the key factors that contribute to user behavior, which outperforms existing methods in terms of both accuracy and interpretability on real-world datasets."
}