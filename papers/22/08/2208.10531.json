{
    "title": "RAIN: RegulArization on Input and Network for Black-Box Domain Adaptation. (arXiv:2208.10531v3 [cs.CV] UPDATED)",
    "abstract": "Source-Free domain adaptation transits the source-trained model towards target domain without exposing the source data, trying to dispel these concerns about data privacy and security. However, this paradigm is still at risk of data leakage due to adversarial attacks on the source model. Hence, the Black-Box setting only allows to use the outputs of source model, but still suffers from overfitting on the source domain more severely due to source model's unseen weights. In this paper, we propose a novel approach named RAIN (RegulArization on Input and Network) for Black-Box domain adaptation from both input-level and network-level regularization. For the input-level, we design a new data augmentation technique as Phase MixUp, which highlights task-relevant objects in the interpolations, thus enhancing input-level regularization and class consistency for target models. For network-level, we develop a Subnetwork Distillation mechanism to transfer knowledge from the target subnetwork to th",
    "link": "http://arxiv.org/abs/2208.10531",
    "context": "Title: RAIN: RegulArization on Input and Network for Black-Box Domain Adaptation. (arXiv:2208.10531v3 [cs.CV] UPDATED)\nAbstract: Source-Free domain adaptation transits the source-trained model towards target domain without exposing the source data, trying to dispel these concerns about data privacy and security. However, this paradigm is still at risk of data leakage due to adversarial attacks on the source model. Hence, the Black-Box setting only allows to use the outputs of source model, but still suffers from overfitting on the source domain more severely due to source model's unseen weights. In this paper, we propose a novel approach named RAIN (RegulArization on Input and Network) for Black-Box domain adaptation from both input-level and network-level regularization. For the input-level, we design a new data augmentation technique as Phase MixUp, which highlights task-relevant objects in the interpolations, thus enhancing input-level regularization and class consistency for target models. For network-level, we develop a Subnetwork Distillation mechanism to transfer knowledge from the target subnetwork to th",
    "path": "papers/22/08/2208.10531.json",
    "total_tokens": 976,
    "tldr": "本文提出了一种名为RAIN的新方法，旨在通过输入级别和网络级别的正则化，用于黑盒域自适应。其中，相较于传统技术，采用的数据增强技术Phase MixUp能够增强输入级别的正则化和类别一致性，而子网络蒸馏机制则可实现网络级别的正则化，从而增强了黑盒域自适应的效果。"
}