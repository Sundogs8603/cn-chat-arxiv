{
    "title": "Adversarial Bayesian Simulation. (arXiv:2208.12113v2 [stat.ME] UPDATED)",
    "abstract": "In the absence of explicit or tractable likelihoods, Bayesians often resort to approximate Bayesian computation (ABC) for inference. Our work bridges ABC with deep neural implicit samplers based on generative adversarial networks (GANs) and adversarial variational Bayes. Both ABC and GANs compare aspects of observed and fake data to simulate from posteriors and likelihoods, respectively. We develop a Bayesian GAN (B-GAN) sampler that directly targets the posterior by solving an adversarial optimization problem. B-GAN is driven by a deterministic mapping learned on the ABC reference by conditional GANs. Once the mapping has been trained, iid posterior samples are obtained by filtering noise at a negligible additional cost. We propose two post-processing local refinements using (1) data-driven proposals with importance reweighting, and (2) variational Bayes. We support our findings with frequentist-Bayesian results, showing that the typical total variation distance between the true and a",
    "link": "http://arxiv.org/abs/2208.12113",
    "context": "Title: Adversarial Bayesian Simulation. (arXiv:2208.12113v2 [stat.ME] UPDATED)\nAbstract: In the absence of explicit or tractable likelihoods, Bayesians often resort to approximate Bayesian computation (ABC) for inference. Our work bridges ABC with deep neural implicit samplers based on generative adversarial networks (GANs) and adversarial variational Bayes. Both ABC and GANs compare aspects of observed and fake data to simulate from posteriors and likelihoods, respectively. We develop a Bayesian GAN (B-GAN) sampler that directly targets the posterior by solving an adversarial optimization problem. B-GAN is driven by a deterministic mapping learned on the ABC reference by conditional GANs. Once the mapping has been trained, iid posterior samples are obtained by filtering noise at a negligible additional cost. We propose two post-processing local refinements using (1) data-driven proposals with importance reweighting, and (2) variational Bayes. We support our findings with frequentist-Bayesian results, showing that the typical total variation distance between the true and a",
    "path": "papers/22/08/2208.12113.json",
    "total_tokens": 1057,
    "translated_title": "对抗贝叶斯模拟",
    "translated_abstract": "在没有明确或可计算的似然函数的情况下，贝叶斯推断常常使用近似贝叶斯计算（ABC）。我们的工作将ABC与基于生成对抗网络（GANs）和对抗变分贝叶斯的深度神经隐式采样器相结合。ABC和GANs分别比较观测数据和虚假数据的各个方面以模拟后验概率和似然函数。我们开发了一种贝叶斯GAN（B-GAN）采样器，通过解决一个对抗优化问题直接对准目标后验概率。B-GAN由在ABC参考上通过条件GANs学习的确定性映射驱动。一旦映射被训练好，通过滤除噪声以几乎没有额外代价的方式获得独立同分布的后验样本。我们提出了两个后处理局部改进方法，分别使用了（1）数据驱动的建议和重要性重新加权，和（2）变分贝叶斯。我们用频率学-贝叶斯的结果支持我们的发现，显示真实值与一个常见的总变差距离之间的差异",
    "tldr": "本文提出了对抗贝叶斯模拟的方法，通过将近似贝叶斯计算与生成对抗网络和对抗变分贝叶斯相结合，开发了一种直接针对后验概率的贝叶斯GAN（B-GAN）采样器，通过解决一个对抗优化问题。通过使用数据驱动建议和重要性重新加权以及变分贝叶斯等后处理技术，进一步提高了模拟结果的准确性。",
    "en_tdlr": "This paper proposes the method of adversarial Bayesian simulation, which combines approximate Bayesian computation (ABC) with generative adversarial networks (GANs) and adversarial variational Bayes. The Bayesian GAN (B-GAN) sampler directly targets the posterior by solving an adversarial optimization problem. Post-processing techniques such as data-driven proposals with importance reweighting and variational Bayes are used to improve the accuracy of the simulation results."
}