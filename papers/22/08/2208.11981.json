{
    "title": "On Reality and the Limits of Language Data: Aligning LLMs with Human Norms. (arXiv:2208.11981v2 [cs.CL] UPDATED)",
    "abstract": "Recent advancements in Large Language Models (LLMs) harness linguistic associations in vast natural language data for practical applications. However, their ability to understand the physical world using only language data remains a question. After reviewing existing protocols, we explore this question using a novel and tightly controlled reasoning test (ART) and compare human norms against versions of GPT-3. Our findings highlight the categories of common-sense relations models that could learn directly from data and areas of weakness. GPT-3 offers evidence for verbal reasoning on a par with human subjects for several relations including Synonymy, Antonymy, and Default inheritance, Without reinforcement learning from human judgements, it appears GPT-3 performs at the lower end of the reference interval for Has-part and Contained-in. Weaknesses were observed also in affordance characteristics through Necessary-quality, Order-of-size and Order-of-intensity. Combining LLMs with symbolic ",
    "link": "http://arxiv.org/abs/2208.11981",
    "context": "Title: On Reality and the Limits of Language Data: Aligning LLMs with Human Norms. (arXiv:2208.11981v2 [cs.CL] UPDATED)\nAbstract: Recent advancements in Large Language Models (LLMs) harness linguistic associations in vast natural language data for practical applications. However, their ability to understand the physical world using only language data remains a question. After reviewing existing protocols, we explore this question using a novel and tightly controlled reasoning test (ART) and compare human norms against versions of GPT-3. Our findings highlight the categories of common-sense relations models that could learn directly from data and areas of weakness. GPT-3 offers evidence for verbal reasoning on a par with human subjects for several relations including Synonymy, Antonymy, and Default inheritance, Without reinforcement learning from human judgements, it appears GPT-3 performs at the lower end of the reference interval for Has-part and Contained-in. Weaknesses were observed also in affordance characteristics through Necessary-quality, Order-of-size and Order-of-intensity. Combining LLMs with symbolic ",
    "path": "papers/22/08/2208.11981.json",
    "total_tokens": 1003,
    "translated_title": "论现实和语言数据限制：将LLMs与人类规范对齐",
    "translated_abstract": "最近，大型语言模型（LLMs）在利用大量自然语言数据中的语言关联进行实际应用方面取得了进展。然而，它们仅使用语言数据来理解物理世界的能力仍有疑问。在回顾现有协议之后，我们使用一种新颖且严密控制的推理测试（ART）来探讨这个问题，并比较人类规范与GPT-3版本之间的差异。我们的研究结果突出了通常可以直接从数据中学习的常识关系模型类别以及弱点所在。GPT-3为包括同义词、反义词和默认继承在内的几个关系方面提供了与人类主体相当的口头推理证据。没有来自人类判断的强化学习，GPT-3在具有部分和包含关系方面表现的区间下限处。在必要品质、大小顺序和强度顺序等方面也观察到了不足之处。把LLMs与象征性方法相结合，",
    "tldr": "本文研究了大型语言模型（LLMs）在仅使用语言数据的情况下理解物理世界的能力，使用新颖且严密控制的推理测试（ART）与人类规范进行对比，研究发现了LLMs在某些常识关系模型中可以直接从数据中学习，但存在弱点，例如在部分和包含关系方面表现不足。",
    "en_tdlr": "This paper explores the ability of Large Language Models (LLMs) to understand the physical world using only language data by comparing them to human norms through a novel and tightly controlled reasoning test (ART). The study finds that LLMs can learn some common-sense relations models directly from data, but weaknesses exist such as in the areas of \"Has-part\" and \"Contained-in\" relations."
}