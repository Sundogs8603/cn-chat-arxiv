{
    "title": "Bayesian Optimization with Informative Covariance. (arXiv:2208.02704v2 [cs.LG] UPDATED)",
    "abstract": "Bayesian optimization is a methodology for global optimization of unknown and expensive objectives. It combines a surrogate Bayesian regression model with an acquisition function to decide where to evaluate the objective. Typical regression models are given by Gaussian processes with stationary covariance functions. However, these functions are unable to express prior input-dependent information, including possible locations of the optimum. The ubiquity of stationary models has led to the common practice of exploiting prior information via informative mean functions. In this paper, we highlight that these models can perform poorly, especially in high dimensions. We propose novel informative covariance functions for optimization, leveraging nonstationarity to encode preferences for certain regions of the search space and adaptively promote local exploration during optimization. We demonstrate that the proposed functions can increase the sample efficiency of Bayesian optimization in high",
    "link": "http://arxiv.org/abs/2208.02704",
    "context": "Title: Bayesian Optimization with Informative Covariance. (arXiv:2208.02704v2 [cs.LG] UPDATED)\nAbstract: Bayesian optimization is a methodology for global optimization of unknown and expensive objectives. It combines a surrogate Bayesian regression model with an acquisition function to decide where to evaluate the objective. Typical regression models are given by Gaussian processes with stationary covariance functions. However, these functions are unable to express prior input-dependent information, including possible locations of the optimum. The ubiquity of stationary models has led to the common practice of exploiting prior information via informative mean functions. In this paper, we highlight that these models can perform poorly, especially in high dimensions. We propose novel informative covariance functions for optimization, leveraging nonstationarity to encode preferences for certain regions of the search space and adaptively promote local exploration during optimization. We demonstrate that the proposed functions can increase the sample efficiency of Bayesian optimization in high",
    "path": "papers/22/08/2208.02704.json",
    "total_tokens": 903,
    "translated_title": "带信息协方差的贝叶斯优化",
    "translated_abstract": "贝叶斯优化是一种处理未知和昂贵目标的全局优化方法。它将一个拟合贝叶斯回归模型与一个收获函数结合起来，以决定在哪里评估目标。典型的回归模型由具有平稳协方差函数的高斯过程表示。然而，这些函数无法表达输入相关的先验信息，包括最优点可能出现的位置。平稳模型的普及导致了通过信息丰富的均值函数利用先验信息的常见做法。本文中，我们强调这些模型在高维情况下可能表现不佳。我们提出了一种新颖的用于优化的信息丰富协方差函数，利用非平稳性来编码对搜索空间中某些区域的偏好，并在优化过程中自适应地促进局部探索。我们证明了所提出的函数可以提高贝叶斯优化在高维空间中的样本效率，在基准问题中达到了最先进的性能。",
    "tldr": "提出了一种新颖的用于优化的信息丰富协方差函数，利用非平稳性来编码对搜索空间中某些区域的偏好，并在优化过程中自适应地促进局部探索，以提高贝叶斯优化在高维空间中的样本效率。",
    "en_tdlr": "This paper proposes a novel informative covariance function for optimization, using nonstationarity to encode preferences for certain regions of the search space and adaptively promote local exploration during optimization, to improve the sample efficiency of Bayesian optimization in high-dimensional spaces."
}