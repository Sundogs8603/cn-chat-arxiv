{
    "title": "Local Context-Aware Active Domain Adaptation. (arXiv:2208.12856v3 [cs.LG] UPDATED)",
    "abstract": "Active Domain Adaptation (ADA) queries the labels of a small number of selected target samples to help adapting a model from a source domain to a target domain. The local context of queried data is important, especially when the domain gap is large. However, this has not been fully explored by existing ADA works. In this paper, we propose a Local context-aware ADA framework, named LADA, to address this issue. To select informative target samples, we devise a novel criterion based on the local inconsistency of model predictions. Since the labeling budget is usually small, fine-tuning model on only queried data can be inefficient. We progressively augment labeled target data with the confident neighbors in a class-balanced manner. Experiments validate that the proposed criterion chooses more informative target samples than existing active selection strategies. Furthermore, our full method clearly surpasses recent ADA arts on various benchmarks. Code is available at https://github.com/tsu",
    "link": "http://arxiv.org/abs/2208.12856",
    "context": "Title: Local Context-Aware Active Domain Adaptation. (arXiv:2208.12856v3 [cs.LG] UPDATED)\nAbstract: Active Domain Adaptation (ADA) queries the labels of a small number of selected target samples to help adapting a model from a source domain to a target domain. The local context of queried data is important, especially when the domain gap is large. However, this has not been fully explored by existing ADA works. In this paper, we propose a Local context-aware ADA framework, named LADA, to address this issue. To select informative target samples, we devise a novel criterion based on the local inconsistency of model predictions. Since the labeling budget is usually small, fine-tuning model on only queried data can be inefficient. We progressively augment labeled target data with the confident neighbors in a class-balanced manner. Experiments validate that the proposed criterion chooses more informative target samples than existing active selection strategies. Furthermore, our full method clearly surpasses recent ADA arts on various benchmarks. Code is available at https://github.com/tsu",
    "path": "papers/22/08/2208.12856.json",
    "total_tokens": 945,
    "translated_title": "局部上下文感知的主动域自适应",
    "translated_abstract": "主动域自适应（ADA）通过查询少量选择的目标样本的标签来帮助将模型从源域适应到目标域。当存在较大的域差距时，查询数据的局部上下文非常重要。然而，现有的ADA方法并没有充分探索这一点。在本文中，我们提出了一种名为LADA的局部上下文感知的ADA框架来解决这个问题。为了选择信息量丰富的目标样本，我们设计了一种基于模型预测的局部不一致性的新标准。由于标注预算通常很小，仅在查询数据上微调模型可能效率低下。我们以类平衡的方式逐步增加标注的目标数据与自信的邻居。实验证实，所提出的标准选择的目标样本比现有的主动选择策略更具信息量。此外，我们的完整方法在各种基准测试中明显优于最近的ADA方法。代码可在https://github.com/tsu获得。",
    "tldr": "本文提出了一种局部上下文感知的主动域自适应框架 LADA，通过引入局部不一致性标准选择信息量更丰富的目标样本，并以类平衡的方式逐步增加标注的目标数据与自信的邻居。实验证实 LADA 方法在各种基准测试中明显优于最近的 ADA 方法。",
    "en_tdlr": "This paper proposes a Local context-aware Active Domain Adaptation (ADA) framework called LADA, which selects more informative target samples by introducing a criterion based on the local inconsistency of model predictions, and progressively augments labeled target data with confident neighbors in a class-balanced manner. Experiments validate that LADA clearly outperforms recent ADA methods on various benchmarks."
}