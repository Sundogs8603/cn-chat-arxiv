{
    "title": "Unifying Gradients to Improve Real-world Robustness for Deep Networks. (arXiv:2208.06228v2 [stat.ML] UPDATED)",
    "abstract": "The wide application of deep neural networks (DNNs) demands an increasing amount of attention to their real-world robustness, i.e., whether a DNN resists black-box adversarial attacks, among which score-based query attacks (SQAs) are most threatening since they can effectively hurt a victim network with the only access to model outputs. Defending against SQAs requires a slight but artful variation of outputs due to the service purpose for users, who share the same output information with SQAs. In this paper, we propose a real-world defense by Unifying Gradients (UniG) of different data so that SQAs could only probe a much weaker attack direction that is similar for different samples. Since such universal attack perturbations have been validated as less aggressive than the input-specific perturbations, UniG protects real-world DNNs by indicating attackers a twisted and less informative attack direction. We implement UniG efficiently by a Hadamard product module which is plug-and-play. A",
    "link": "http://arxiv.org/abs/2208.06228",
    "context": "Title: Unifying Gradients to Improve Real-world Robustness for Deep Networks. (arXiv:2208.06228v2 [stat.ML] UPDATED)\nAbstract: The wide application of deep neural networks (DNNs) demands an increasing amount of attention to their real-world robustness, i.e., whether a DNN resists black-box adversarial attacks, among which score-based query attacks (SQAs) are most threatening since they can effectively hurt a victim network with the only access to model outputs. Defending against SQAs requires a slight but artful variation of outputs due to the service purpose for users, who share the same output information with SQAs. In this paper, we propose a real-world defense by Unifying Gradients (UniG) of different data so that SQAs could only probe a much weaker attack direction that is similar for different samples. Since such universal attack perturbations have been validated as less aggressive than the input-specific perturbations, UniG protects real-world DNNs by indicating attackers a twisted and less informative attack direction. We implement UniG efficiently by a Hadamard product module which is plug-and-play. A",
    "path": "papers/22/08/2208.06228.json",
    "total_tokens": 926,
    "translated_title": "将梯度统一化以提高深度网络的真实世界鲁棒性",
    "translated_abstract": "深度神经网络（DNN）的广泛应用对它们的真实世界鲁棒性提出了更多关注，即DNN是否能够抵抗黑盒对抗攻击，其中基于评分的查询攻击（SQAs）最具威胁性，因为它们只能通过访问模型输出有效地攻击受害网络。抵御SQAs需要对输出进行轻微但巧妙的变化，因为用户与SQAs共享相同的输出信息。在本文中，我们提出了一种通过统一不同数据的梯度来进行真实世界防御的方法，使得SQAs只能探测到一个更弱的攻击方向，这个攻击方向对于不同样本是相似的。由于这种统一的攻击扰动被验证为比输入特定的扰动更不具侵略性，UniG通过指示攻击者一个扭曲且信息较少的攻击方向来保护真实世界的DNN。我们通过一个可插拔的Hadamard乘积模块高效实现了UniG。",
    "tldr": "通过统一不同数据的梯度来防御基于评分的查询攻击（SQAs），这样SQAs只能探测到一个更弱的攻击方向，保护真实世界的深度神经网络。",
    "en_tdlr": "Defend against score-based query attacks (SQAs) by unifying gradients of different data, so that SQAs only probe a weaker attack direction, protecting real-world deep neural networks."
}