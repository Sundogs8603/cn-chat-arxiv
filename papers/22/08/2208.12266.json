{
    "title": "Decoding speech perception from non-invasive brain recordings. (arXiv:2208.12266v2 [eess.AS] UPDATED)",
    "abstract": "Decoding speech from brain activity is a long-awaited goal in both healthcare and neuroscience. Invasive devices have recently led to major milestones in that regard: deep learning algorithms trained on intracranial recordings now start to decode elementary linguistic features (e.g. letters, words, spectrograms). However, extending this approach to natural speech and non-invasive brain recordings remains a major challenge. Here, we introduce a model trained with contrastive-learning to decode self-supervised representations of perceived speech from the non-invasive recordings of a large cohort of healthy individuals. To evaluate this approach, we curate and integrate four public datasets, encompassing 175 volunteers recorded with magneto- or electro-encephalography (M/EEG), while they listened to short stories and isolated sentences. The results show that our model can identify, from 3 seconds of MEG signals, the corresponding speech segment with up to 41% accuracy out of more than 1,0",
    "link": "http://arxiv.org/abs/2208.12266",
    "context": "Title: Decoding speech perception from non-invasive brain recordings. (arXiv:2208.12266v2 [eess.AS] UPDATED)\nAbstract: Decoding speech from brain activity is a long-awaited goal in both healthcare and neuroscience. Invasive devices have recently led to major milestones in that regard: deep learning algorithms trained on intracranial recordings now start to decode elementary linguistic features (e.g. letters, words, spectrograms). However, extending this approach to natural speech and non-invasive brain recordings remains a major challenge. Here, we introduce a model trained with contrastive-learning to decode self-supervised representations of perceived speech from the non-invasive recordings of a large cohort of healthy individuals. To evaluate this approach, we curate and integrate four public datasets, encompassing 175 volunteers recorded with magneto- or electro-encephalography (M/EEG), while they listened to short stories and isolated sentences. The results show that our model can identify, from 3 seconds of MEG signals, the corresponding speech segment with up to 41% accuracy out of more than 1,0",
    "path": "papers/22/08/2208.12266.json",
    "total_tokens": 928,
    "translated_title": "从非侵入性脑电记录中解码语音知觉",
    "translated_abstract": "从脑电活动中解码语音一直是医疗保健和神经科学中期待已久的目标。最近的研究中，侵入性设备已经取得了重大突破：基于颅内记录的深度学习算法现在可以解码基本的语言特征（例如字母、单词、频谱图）。然而，将这种方法推广到自然语音和非侵入性脑电记录仍然是一个重大挑战。本文介绍了一个使用对比学习训练的模型，可以从大量健康个体的非侵入性记录中解码自我监督表示的感知语音。为了评估这种方法，我们整合了四个公共数据集，包括175名志愿者的脑磁图或脑电图记录，他们在听短篇故事和孤立的句子时记录。结果显示，我们的模型可以从3秒的脑磁图信号中以高达41%的准确率识别相应的语音片段，其中包含了1000个以上的候选项。",
    "tldr": "本研究通过使用对比学习训练的模型，成功从非侵入性脑电记录中解码感知语音。结果显示，该模型能够以高达41%的准确率识别出与脑电信号相对应的语音片段。",
    "en_tdlr": "This study successfully decodes perceived speech from non-invasive brain recordings using a model trained with contrastive learning. The results show that the model can identify the corresponding speech segment with up to 41% accuracy."
}