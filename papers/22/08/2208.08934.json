{
    "title": "A Hybrid Self-Supervised Learning Framework for Vertical Federated Learning. (arXiv:2208.08934v2 [cs.LG] UPDATED)",
    "abstract": "Vertical federated learning (VFL), a variant of Federated Learning (FL), has recently drawn increasing attention as the VFL matches the enterprises' demands of leveraging more valuable features to achieve better model performance. However, conventional VFL methods may run into data deficiency as they exploit only aligned and labeled samples (belonging to different parties), leaving often the majority of unaligned and unlabeled samples unused. The data deficiency hampers the effort of the federation.  In this work, we propose a Federated Hybrid Self-Supervised Learning framework, named FedHSSL, that utilizes cross-party views (i.e., dispersed features) of samples aligned among parties and local views (i.e., augmentation) of unaligned samples within each party to improve the representation learning capability of the VFL joint model. FedHSSL further exploits invariant features across parties to boost the performance of the joint model through partial model aggregation. FedHSSL, as a frame",
    "link": "http://arxiv.org/abs/2208.08934",
    "context": "Title: A Hybrid Self-Supervised Learning Framework for Vertical Federated Learning. (arXiv:2208.08934v2 [cs.LG] UPDATED)\nAbstract: Vertical federated learning (VFL), a variant of Federated Learning (FL), has recently drawn increasing attention as the VFL matches the enterprises' demands of leveraging more valuable features to achieve better model performance. However, conventional VFL methods may run into data deficiency as they exploit only aligned and labeled samples (belonging to different parties), leaving often the majority of unaligned and unlabeled samples unused. The data deficiency hampers the effort of the federation.  In this work, we propose a Federated Hybrid Self-Supervised Learning framework, named FedHSSL, that utilizes cross-party views (i.e., dispersed features) of samples aligned among parties and local views (i.e., augmentation) of unaligned samples within each party to improve the representation learning capability of the VFL joint model. FedHSSL further exploits invariant features across parties to boost the performance of the joint model through partial model aggregation. FedHSSL, as a frame",
    "path": "papers/22/08/2208.08934.json",
    "total_tokens": 899,
    "translated_title": "一种混合自监督学习框架用于纵向联邦学习",
    "translated_abstract": "纵向联邦学习（VFL）是联邦学习（FL）的一种变体，近年来备受关注。然而，传统的VFL方法可能会遭遇数据不足的问题，因为它们仅利用经过对齐和标记的样本（属于不同方），经常忽略了大多数未对齐和未标记的样本。这个数据不足阻碍了联邦一方的努力。本文提出了一种名为FedHSSL的联邦混合自监督学习框架，利用方间视角（即分散的特征）和各方内未对齐样本的本地视角（即数据增强）来提高VFL联合模型的表示学习能力。FedHSSL通过部分模型聚合进一步利用各方共同的特征来提高联合模型的性能。",
    "tldr": "本文提出了一种名为FedHSSL的联邦混合自监督学习框架，通过跨方视角和本地视角相结合，以解决纵向联邦学习中数据不足的问题，并且可以通过部分模型聚合进一步提高联合模型的性能。",
    "en_tdlr": "This paper proposes a Federated Hybrid Self-Supervised Learning framework named FedHSSL to address the data deficiency problem in vertical federated learning. FedHSSL utilizes a combination of cross-party views and local views to improve the representation learning capability of the joint model and incorporates partial model aggregation to boost its performance."
}