{
    "title": "A Maintenance Planning Framework using Online and Offline Deep Reinforcement Learning. (arXiv:2208.00808v2 [cs.LG] UPDATED)",
    "abstract": "Cost-effective asset management is an area of interest across several industries. Specifically, this paper develops a deep reinforcement learning (DRL) solution to automatically determine an optimal rehabilitation policy for continuously deteriorating water pipes. We approach the problem of rehabilitation planning in an online and offline DRL setting. In online DRL, the agent interacts with a simulated environment of multiple pipes with distinct lengths, materials, and failure rate characteristics. We train the agent using deep Q-learning (DQN) to learn an optimal policy with minimal average costs and reduced failure probability. In offline learning, the agent uses static data, e.g., DQN replay data, to learn an optimal policy via a conservative Q-learning algorithm without further interactions with the environment. We demonstrate that DRL-based policies improve over standard preventive, corrective, and greedy planning alternatives. Additionally, learning from the fixed DQN replay data",
    "link": "http://arxiv.org/abs/2208.00808",
    "context": "Title: A Maintenance Planning Framework using Online and Offline Deep Reinforcement Learning. (arXiv:2208.00808v2 [cs.LG] UPDATED)\nAbstract: Cost-effective asset management is an area of interest across several industries. Specifically, this paper develops a deep reinforcement learning (DRL) solution to automatically determine an optimal rehabilitation policy for continuously deteriorating water pipes. We approach the problem of rehabilitation planning in an online and offline DRL setting. In online DRL, the agent interacts with a simulated environment of multiple pipes with distinct lengths, materials, and failure rate characteristics. We train the agent using deep Q-learning (DQN) to learn an optimal policy with minimal average costs and reduced failure probability. In offline learning, the agent uses static data, e.g., DQN replay data, to learn an optimal policy via a conservative Q-learning algorithm without further interactions with the environment. We demonstrate that DRL-based policies improve over standard preventive, corrective, and greedy planning alternatives. Additionally, learning from the fixed DQN replay data",
    "path": "papers/22/08/2208.00808.json",
    "total_tokens": 936,
    "translated_title": "一种利用在线和离线深度强化学习的维护计划框架",
    "translated_abstract": "成本效益的资产管理是各个行业关注的领域。本文针对不断恶化的水管开发了一种深度强化学习（DRL）解决方案，用于自动确定最优恢复策略。我们采用在线和离线DRL设置来解决维修计划问题。在在线DRL中，智能体与具有不同长度、材料和失效率特征的多个水管的模拟环境进行交互。我们使用深度Q学习（DQN）对智能体进行训练，以学习具有最小平均成本和降低失效概率的最优策略。在离线学习中，智能体使用静态数据（如DQN重放数据）通过保守的Q学习算法学习最优策略，无需与环境进行进一步交互。我们证明了基于DRL的策略比标准的预防性、纠正性和贪婪式计划方案有所改进。此外，我们还能够从固定的DQN重放数据中学习知识。",
    "tldr": "本论文提出了一种利用在线和离线深度强化学习的维护计划框架，以确定最优恢复策略，经过实验证明该框架比标准的预防性、纠正性和贪婪式计划方案有所改进。",
    "en_tdlr": "This paper proposes a maintenance planning framework using online and offline deep reinforcement learning to determine an optimal rehabilitation policy for deteriorating water pipes, and shows through experiments that the framework has improved over standard preventive, corrective and greedy planning alternatives."
}