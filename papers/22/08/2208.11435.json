{
    "title": "UniCon: Unidirectional Split Learning with Contrastive Loss for Visual Question Answering. (arXiv:2208.11435v2 [cs.CV] UPDATED)",
    "abstract": "Visual Question Answering (VQA) using multi-modal data facilitates real-life applications, such as home robots and medical diagnoses. However, one significant challenge is to design a robust learning method for various client tasks. One critical aspect is to ensure privacy, as client data sharing is limited due to confidentiality concerns. This work focuses on addressing the issue of confidentiality constraints in multi-client VQA tasks and limited labeled training data of clients. We propose the Unidirectional Split Learning with Contrastive Loss (UniCon) method to overcome these limitations. The proposed method trains a global model on the entire data distribution of different clients, learning refined cross-modal representations through model sharing. Privacy is ensured by utilizing a split learning architecture in which a complete model is partitioned into two components for independent training. Moreover, recent self-supervised learning techniques were found to be highly compatibl",
    "link": "http://arxiv.org/abs/2208.11435",
    "context": "Title: UniCon: Unidirectional Split Learning with Contrastive Loss for Visual Question Answering. (arXiv:2208.11435v2 [cs.CV] UPDATED)\nAbstract: Visual Question Answering (VQA) using multi-modal data facilitates real-life applications, such as home robots and medical diagnoses. However, one significant challenge is to design a robust learning method for various client tasks. One critical aspect is to ensure privacy, as client data sharing is limited due to confidentiality concerns. This work focuses on addressing the issue of confidentiality constraints in multi-client VQA tasks and limited labeled training data of clients. We propose the Unidirectional Split Learning with Contrastive Loss (UniCon) method to overcome these limitations. The proposed method trains a global model on the entire data distribution of different clients, learning refined cross-modal representations through model sharing. Privacy is ensured by utilizing a split learning architecture in which a complete model is partitioned into two components for independent training. Moreover, recent self-supervised learning techniques were found to be highly compatibl",
    "path": "papers/22/08/2208.11435.json",
    "total_tokens": 887,
    "translated_title": "UniCon: 带有对比损失的单向分歧学习用于视觉问答",
    "translated_abstract": "多模式数据的视觉问答（VQA）有助于现实应用，如家庭机器人和医学诊断。然而，面临的一个重要挑战是为各种客户任务设计强大的学习方法。其中一个关键方面是确保隐私，因为由于保密问题，客户数据共享受到限制。本文致力于解决多客户VQA任务的保密性约束和客户有限标记训练数据的问题。我们提出了带有对比损失的单向分歧学习（UniCon）方法来克服这些限制。所提出的方法在不同客户的整个数据分布上训练全局模型，通过模型共享学习精细的跨模态表示来实现隐私保证，利用分裂学习架构确保隐私，其中完整模型分为两个组件进行独立训练。此外，最近发现自我监督学习技术与我们的方法高度兼容。",
    "tldr": "本文提出了UniCon方法，用于解决多客户VQA任务的保密性约束和客户有限标记训练数据的问题。该方法通过模型共享学习跨模态表示，采用分裂学习架构确保隐私。",
    "en_tdlr": "This paper proposes the UniCon method to address the issues of privacy constraints and limited labeled training data in multi-client VQA tasks. The method utilizes model sharing to learn refined cross-modal representations and ensures privacy through a split learning architecture."
}