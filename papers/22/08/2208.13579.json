{
    "title": "Shaken, and Stirred: Long-Range Dependencies Enable Robust Outlier Detection with PixelCNN++. (arXiv:2208.13579v2 [cs.LG] UPDATED)",
    "abstract": "Reliable outlier detection is critical for real-world deployment of deep learning models. Although extensively studied, likelihoods produced by deep generative models have been largely dismissed as being impractical for outlier detection. First, deep generative model likelihoods are readily biased by low-level input statistics. Second, many recent solutions for correcting these biases are computationally expensive, or do not generalize well to complex, natural datasets. Here, we explore outlier detection with a state-of-the-art deep autoregressive model: PixelCNN++. We show that biases in PixelCNN++ likelihoods arise primarily from predictions based on local dependencies. We propose two families of bijective transformations -- ``stirring'' and ``shaking'' -- which ameliorate low-level biases and isolate the contribution of long-range dependencies to PixelCNN++ likelihoods. These transformations are inexpensive and readily computed at evaluation time. We test our approaches extensively ",
    "link": "http://arxiv.org/abs/2208.13579",
    "context": "Title: Shaken, and Stirred: Long-Range Dependencies Enable Robust Outlier Detection with PixelCNN++. (arXiv:2208.13579v2 [cs.LG] UPDATED)\nAbstract: Reliable outlier detection is critical for real-world deployment of deep learning models. Although extensively studied, likelihoods produced by deep generative models have been largely dismissed as being impractical for outlier detection. First, deep generative model likelihoods are readily biased by low-level input statistics. Second, many recent solutions for correcting these biases are computationally expensive, or do not generalize well to complex, natural datasets. Here, we explore outlier detection with a state-of-the-art deep autoregressive model: PixelCNN++. We show that biases in PixelCNN++ likelihoods arise primarily from predictions based on local dependencies. We propose two families of bijective transformations -- ``stirring'' and ``shaking'' -- which ameliorate low-level biases and isolate the contribution of long-range dependencies to PixelCNN++ likelihoods. These transformations are inexpensive and readily computed at evaluation time. We test our approaches extensively ",
    "path": "papers/22/08/2208.13579.json",
    "total_tokens": 1040,
    "translated_title": "摇晃着前行：基于PixelCNN++的长程依赖关系实现健壮离群检测",
    "translated_abstract": "可靠的离群检测对于深度学习模型的实际应用至关重要。尽管已经进行了广泛的研究，但由深度生成模型产生的似然性通常被认为在离群检测方面不实用。首先，深度生成模型似然性易受低级输入统计的偏见影响。其次，许多最近的解决方案对纠正这些偏见的计算成本很高，或者在复杂的自然数据集上泛化能力差。在本文中，我们探讨了一种基于最先进的深度自回归模型PixelCNN++的离群检测方法。我们表明，PixelCNN++似然性中的偏见主要来自于基于局部依赖关系的预测。我们提出了两种双射变换族--“搅拌”和“摇晃”，这可以改善低级偏差，并将长程依赖关系的贡献隔离在PixelCNN++的似然性中。这些变换成本低廉，并且在评估时可以很容易地计算。我们对我们的方法进行了广泛的测试。",
    "tldr": "本文提出了两种双射变换方法（“搅拌”和“摇晃”），用于改善深度自回归模型PixelCNN++似然性中的低级偏差，并隔离长程依赖的贡献。这些方法可以在评估时很容易计算，并且在离群检测方面表现出了很好的效果。",
    "en_tdlr": "This paper proposes two families of bijective transformations (\"stirring\" and \"shaking\") to ameliorate low-level biases and isolate the contribution of long-range dependencies to the likelihoods of the state-of-the-art deep autoregressive model PixelCNN++. These transformations are inexpensive and readily computed at evaluation time, and have been extensively tested for outlier detection with good performance."
}