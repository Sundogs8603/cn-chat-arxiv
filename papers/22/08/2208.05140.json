{
    "title": "Self-supervised Multi-modal Training from Uncurated Image and Reports Enables Zero-shot Oversight Artificial Intelligence in Radiology. (arXiv:2208.05140v4 [eess.IV] UPDATED)",
    "abstract": "Oversight AI is an emerging concept in radiology where the AI forms a symbiosis with radiologists by continuously supporting radiologists in their decision-making. Recent advances in vision-language models sheds a light on the long-standing problems of the oversight AI by the understanding both visual and textual concepts and their semantic correspondences. However, there have been limited successes in the application of vision-language models in the medical domain, as the current vision-language models and learning strategies for photographic images and captions call for the web-scale data corpus of image and text pairs which was not often feasible in the medical domain. To address this, here we present a model dubbed Medical Cross-attention Vision-Language model (Medical X-VL), leveraging the key components to be tailored for the medical domain. Our medical X-VL model is based on the following components: self-supervised uni-modal models in medical domain and fusion encoder to bridge",
    "link": "http://arxiv.org/abs/2208.05140",
    "context": "Title: Self-supervised Multi-modal Training from Uncurated Image and Reports Enables Zero-shot Oversight Artificial Intelligence in Radiology. (arXiv:2208.05140v4 [eess.IV] UPDATED)\nAbstract: Oversight AI is an emerging concept in radiology where the AI forms a symbiosis with radiologists by continuously supporting radiologists in their decision-making. Recent advances in vision-language models sheds a light on the long-standing problems of the oversight AI by the understanding both visual and textual concepts and their semantic correspondences. However, there have been limited successes in the application of vision-language models in the medical domain, as the current vision-language models and learning strategies for photographic images and captions call for the web-scale data corpus of image and text pairs which was not often feasible in the medical domain. To address this, here we present a model dubbed Medical Cross-attention Vision-Language model (Medical X-VL), leveraging the key components to be tailored for the medical domain. Our medical X-VL model is based on the following components: self-supervised uni-modal models in medical domain and fusion encoder to bridge",
    "path": "papers/22/08/2208.05140.json",
    "total_tokens": 890,
    "translated_title": "自监督的多模态训练，利用未经整理的图像和报告实现放射学零样本监督人工智能",
    "translated_abstract": "监管型AI是放射学中的新兴概念，其中AI通过不断支持放射学家的决策，形成与放射学家的共生关系。视觉语言模型的最新进展揭示了监管性AI的长期问题，即它们理解视觉和文本概念及其语义对应关系。然而，将视觉语言模型应用于医学领域的成功案例还很有限，因为目前的视觉语言模型和学习策略需要图像和文本对的网络规模数据语料库，这在医学领域通常难以实现。因此，我们提出了一种被称为医学交叉关注视觉语言模型（Medical X-VL）的模型，利用适用于医学领域的关键组件。我们的医学X-VL模型基于以下组件：医学领域的自监督单模型和融合编码器，以构建多模态视觉语言模型。",
    "tldr": "本文提出了一种名为Medical X-VL的视觉语言模型，使用自监督单模型和融合编码器，以实现放射学中的零样本监督人工智能。"
}