{
    "title": "Prompting as Probing: Using Language Models for Knowledge Base Construction. (arXiv:2208.11057v3 [cs.CL] UPDATED)",
    "abstract": "Language Models (LMs) have proven to be useful in various downstream applications, such as summarisation, translation, question answering and text classification. LMs are becoming increasingly important tools in Artificial Intelligence, because of the vast quantity of information they can store. In this work, we present ProP (Prompting as Probing), which utilizes GPT-3, a large Language Model originally proposed by OpenAI in 2020, to perform the task of Knowledge Base Construction (KBC). ProP implements a multi-step approach that combines a variety of prompting techniques to achieve this. Our results show that manual prompt curation is essential, that the LM must be encouraged to give answer sets of variable lengths, in particular including empty answer sets, that true/false questions are a useful device to increase precision on suggestions generated by the LM, that the size of the LM is a crucial factor, and that a dictionary of entity aliases improves the LM score. Our evaluation stu",
    "link": "http://arxiv.org/abs/2208.11057",
    "context": "Title: Prompting as Probing: Using Language Models for Knowledge Base Construction. (arXiv:2208.11057v3 [cs.CL] UPDATED)\nAbstract: Language Models (LMs) have proven to be useful in various downstream applications, such as summarisation, translation, question answering and text classification. LMs are becoming increasingly important tools in Artificial Intelligence, because of the vast quantity of information they can store. In this work, we present ProP (Prompting as Probing), which utilizes GPT-3, a large Language Model originally proposed by OpenAI in 2020, to perform the task of Knowledge Base Construction (KBC). ProP implements a multi-step approach that combines a variety of prompting techniques to achieve this. Our results show that manual prompt curation is essential, that the LM must be encouraged to give answer sets of variable lengths, in particular including empty answer sets, that true/false questions are a useful device to increase precision on suggestions generated by the LM, that the size of the LM is a crucial factor, and that a dictionary of entity aliases improves the LM score. Our evaluation stu",
    "path": "papers/22/08/2208.11057.json",
    "total_tokens": 959,
    "translated_title": "提示作为探测器：利用语言模型进行知识库构建",
    "translated_abstract": "语言模型已经被证明在各种下游应用中都很有用，例如摘要、翻译、问答和文本分类。由于它们可以存储大量信息，因此语言模型正在成为人工智能中越来越重要的工具。本文介绍了ProP（提示作为探测器），它利用OpenAI在2020年提出的大型语言模型GPT-3来执行知识库构建任务。ProP采用多步骤方法，结合各种提示技术来实现这一目标。我们的结果表明，手动提示策略的编制至关重要；必须鼓励语言模型给出不同长度的答案集，特别是包括空答案集；真/假问题是增加语言模型生成的建议的准确性的有用方法；语言模型的大小是一个至关重要的因素；实体别名字典可以提高语言模型的得分。",
    "tldr": "本文介绍了一种利用语言模型进行知识库构建的方法，该方法采用了多种提示技术，手动提示策略的编制至关重要，并且必须鼓励语言模型给出不同长度的答案集，特别是包括空答案集。实体别名字典可以提高语言模型的得分。",
    "en_tdlr": "This paper presents a method for Knowledge Base Construction (KBC) using GPT-3, a large Language Model, combining various prompting techniques. The manual prompt curation is crucial, and the LM should be encouraged to give answer sets of variable length, including empty ones. A dictionary of entity aliases improves the LM score. True/false questions are useful to increase precision on suggestions generated by the LM, and the LM size is a crucial factor."
}