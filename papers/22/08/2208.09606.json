{
    "title": "General-to-Specific Transfer Labeling for Domain Adaptable Keyphrase Generation. (arXiv:2208.09606v2 [cs.CL] UPDATED)",
    "abstract": "Training keyphrase generation (KPG) models require a large amount of annotated data, which can be prohibitively expensive and often limited to specific domains. In this study, we first demonstrate that large distribution shifts among different domains severely hinder the transferability of KPG models. We then propose a three-stage pipeline, which gradually guides KPG models' learning focus from general syntactical features to domain-related semantics, in a data-efficient manner. With Domain-general Phrase pre-training, we pre-train Sequence-to-Sequence models with generic phrase annotations that are widely available on the web, which enables the models to generate phrases in a wide range of domains. The resulting model is then applied in the Transfer Labeling stage to produce domain-specific pseudo keyphrases, which help adapt models to a new domain. Finally, we fine-tune the model with limited data with true labels to fully adapt it to the target domain. Our experiment results show th",
    "link": "http://arxiv.org/abs/2208.09606",
    "context": "Title: General-to-Specific Transfer Labeling for Domain Adaptable Keyphrase Generation. (arXiv:2208.09606v2 [cs.CL] UPDATED)\nAbstract: Training keyphrase generation (KPG) models require a large amount of annotated data, which can be prohibitively expensive and often limited to specific domains. In this study, we first demonstrate that large distribution shifts among different domains severely hinder the transferability of KPG models. We then propose a three-stage pipeline, which gradually guides KPG models' learning focus from general syntactical features to domain-related semantics, in a data-efficient manner. With Domain-general Phrase pre-training, we pre-train Sequence-to-Sequence models with generic phrase annotations that are widely available on the web, which enables the models to generate phrases in a wide range of domains. The resulting model is then applied in the Transfer Labeling stage to produce domain-specific pseudo keyphrases, which help adapt models to a new domain. Finally, we fine-tune the model with limited data with true labels to fully adapt it to the target domain. Our experiment results show th",
    "path": "papers/22/08/2208.09606.json",
    "total_tokens": 948,
    "translated_title": "面向领域适应关键短语生成的通用到特定迁移标记方法",
    "translated_abstract": "训练关键短语生成（KPG）模型需要大量的注释数据，这可能会成为限制其通用性的障碍，并且这些数据通常限定在特定的领域。本研究首先证明不同领域之间的大规模分布转变会严重阻碍KPG模型的可迁移性。然后我们提出了一个三阶段的流程，该流程通过高效利用数据，逐步引导KPG模型学习焦点从通用的句法特征到与领域相关的语义。我们使用领域通用短语预训练，利用网络上广泛可用的通用短语注释对序列到序列模型进行预训练，从而使模型能够在各种领域生成短语。生成的模型然后在迁移标记阶段中应用于产生领域特定的伪关键短语，这有助于将模型适应到一个新领域。最后，我们使用有限的数据对真实标签进行微调，以充分适应目标领域。我们的实验结果显示...",
    "tldr": "本文提出了一种三阶段流程，通过领域通用短语预训练、迁移标记和有限真实标注数据微调来适应新领域，使关键短语生成（KPG）模型具备更强的可迁移性。",
    "en_tdlr": "This paper proposes a three-stage pipeline that enables keyphrase generation (KPG) models to be more transferable by using domain-general phrase pre-training, transfer labeling, and fine-tuning with limited true labels data for domain adaptation."
}