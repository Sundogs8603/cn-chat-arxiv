{
    "title": "Classical-to-quantum convolutional neural network transfer learning. (arXiv:2208.14708v2 [quant-ph] UPDATED)",
    "abstract": "Machine learning using quantum convolutional neural networks (QCNNs) has demonstrated success in both quantum and classical data classification. In previous studies, QCNNs attained a higher classification accuracy than their classical counterparts under the same training conditions in the few-parameter regime. However, the general performance of large-scale quantum models is difficult to examine because of the limited size of quantum circuits, which can be reliably implemented in the near future. We propose transfer learning as an effective strategy for utilizing small QCNNs in the noisy intermediate-scale quantum era to the full extent. In the classical-to-quantum transfer learning framework, a QCNN can solve complex classification problems without requiring a large-scale quantum circuit by utilizing a pre-trained classical convolutional neural network (CNN). We perform numerical simulations of QCNN models with various sets of quantum convolution and pooling operations for MNIST data ",
    "link": "http://arxiv.org/abs/2208.14708",
    "context": "Title: Classical-to-quantum convolutional neural network transfer learning. (arXiv:2208.14708v2 [quant-ph] UPDATED)\nAbstract: Machine learning using quantum convolutional neural networks (QCNNs) has demonstrated success in both quantum and classical data classification. In previous studies, QCNNs attained a higher classification accuracy than their classical counterparts under the same training conditions in the few-parameter regime. However, the general performance of large-scale quantum models is difficult to examine because of the limited size of quantum circuits, which can be reliably implemented in the near future. We propose transfer learning as an effective strategy for utilizing small QCNNs in the noisy intermediate-scale quantum era to the full extent. In the classical-to-quantum transfer learning framework, a QCNN can solve complex classification problems without requiring a large-scale quantum circuit by utilizing a pre-trained classical convolutional neural network (CNN). We perform numerical simulations of QCNN models with various sets of quantum convolution and pooling operations for MNIST data ",
    "path": "papers/22/08/2208.14708.json",
    "total_tokens": 859,
    "translated_title": "经典到量子卷积神经网络迁移学习",
    "translated_abstract": "使用量子卷积神经网络（QCNN）的机器学习在量子和经典数据分类中取得了成功。在之前的研究中，QCNN在少参数情况下的分类准确率比其经典对应物更高。然而，由于可靠实现的量子电路规模有限，在大规模量子模型的整体性能上很难进行检验。我们提出了迁移学习作为一种有效的策略，以充分利用在噪声中间规模量子时代中较小的QCNN。在经典到量子迁移学习框架中，QCNN可以通过利用预训练的经典卷积神经网络（CNN）解决复杂的分类问题，而无需大规模量子电路。我们对具有不同量子卷积和池化操作集的QCNN模型进行了数值模拟，以处理MNIST数据集。",
    "tldr": "本研究提出了经典到量子迁移学习的框架，通过利用预训练的经典卷积神经网络，实现了在噪声中间规模量子时代中较小的QCNN在复杂分类问题上的解决，充分利用了QCNN的优势。",
    "en_tdlr": "This study proposes a classical-to-quantum transfer learning framework, achieving complex classification tasks in the noisy intermediate-scale quantum era using pre-trained classical convolutional neural networks, effectively leveraging the advantages of QCNNs."
}