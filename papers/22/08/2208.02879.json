{
    "title": "PointConvFormer: Revenge of the Point-based Convolution. (arXiv:2208.02879v3 [cs.CV] UPDATED)",
    "abstract": "We introduce PointConvFormer, a novel building block for point cloud based deep network architectures. Inspired by generalization theory, PointConvFormer combines ideas from point convolution, where filter weights are only based on relative position, and Transformers which utilize feature-based attention. In PointConvFormer, attention computed from feature difference between points in the neighborhood is used to modify the convolutional weights at each point. Hence, we preserved the invariances from point convolution, whereas attention helps to select relevant points in the neighborhood for convolution. PointConvFormer is suitable for multiple tasks that require details at the point level, such as segmentation and scene flow estimation tasks. We experiment on both tasks with multiple datasets including ScanNet, SemanticKitti, FlyingThings3D and KITTI. Our results show that PointConvFormer offers a better accuracy-speed tradeoff than classic convolutions, regular transformers, and voxel",
    "link": "http://arxiv.org/abs/2208.02879",
    "context": "Title: PointConvFormer: Revenge of the Point-based Convolution. (arXiv:2208.02879v3 [cs.CV] UPDATED)\nAbstract: We introduce PointConvFormer, a novel building block for point cloud based deep network architectures. Inspired by generalization theory, PointConvFormer combines ideas from point convolution, where filter weights are only based on relative position, and Transformers which utilize feature-based attention. In PointConvFormer, attention computed from feature difference between points in the neighborhood is used to modify the convolutional weights at each point. Hence, we preserved the invariances from point convolution, whereas attention helps to select relevant points in the neighborhood for convolution. PointConvFormer is suitable for multiple tasks that require details at the point level, such as segmentation and scene flow estimation tasks. We experiment on both tasks with multiple datasets including ScanNet, SemanticKitti, FlyingThings3D and KITTI. Our results show that PointConvFormer offers a better accuracy-speed tradeoff than classic convolutions, regular transformers, and voxel",
    "path": "papers/22/08/2208.02879.json",
    "total_tokens": 856,
    "translated_title": "PointConvFormer：基于注意力机制的点云卷积神经网络构建模块",
    "translated_abstract": "我们介绍了PointConvFormer，这是一种用于点云深度网络架构的新颖构建模块。PointConvFormer结合了点卷积和Transformer思想，利用特征差异计算出的注意力来修改每个点的卷积权重。它适用于需要点级细节的多个任务，如分割和场景流估计任务。我们在多个数据集上进行了实验，包括ScanNet、SemanticKitti、FlyingThings3D和KITTI，结果表明PointConvFormer比经典卷积、常规Transformer和体素卷积提供更好的精度-速度平衡。",
    "tldr": "PointConvFormer 是一种新颖的点云深度网络架构构建模块，它利用特征差异计算出的注意力来修改卷积权重，保留了点卷积的不变性，同时能够选择具有相关性的点进行卷积操作，适用于点级细节的多个任务，既提高了精度，又提高了速度。",
    "en_tdlr": "PointConvFormer is a novel building block for point cloud based deep network architectures, which uses attention computed from feature difference between points in the neighborhood to modify the convolutional weights at each point, preserving the invariances from point convolution and selecting relevant points for convolution. It is suitable for multiple tasks that require details at the point level, offering a better accuracy-speed tradeoff compared to classic convolutions, regular transformers, and voxel based convolutions."
}