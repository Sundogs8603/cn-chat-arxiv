{
    "title": "Differentially Private Vertical Federated Clustering. (arXiv:2208.01700v2 [cs.CR] UPDATED)",
    "abstract": "In many applications, multiple parties have private data regarding the same set of users but on disjoint sets of attributes, and a server wants to leverage the data to train a model. To enable model learning while protecting the privacy of the data subjects, we need vertical federated learning (VFL) techniques, where the data parties share only information for training the model, instead of the private data. However, it is challenging to ensure that the shared information maintains privacy while learning accurate models. To the best of our knowledge, the algorithm proposed in this paper is the first practical solution for differentially private vertical federated k-means clustering, where the server can obtain a set of global centers with a provable differential privacy guarantee. Our algorithm assumes an untrusted central server that aggregates differentially private local centers and membership encodings from local data parties. It builds a weighted grid as the synopsis of the global",
    "link": "http://arxiv.org/abs/2208.01700",
    "context": "Title: Differentially Private Vertical Federated Clustering. (arXiv:2208.01700v2 [cs.CR] UPDATED)\nAbstract: In many applications, multiple parties have private data regarding the same set of users but on disjoint sets of attributes, and a server wants to leverage the data to train a model. To enable model learning while protecting the privacy of the data subjects, we need vertical federated learning (VFL) techniques, where the data parties share only information for training the model, instead of the private data. However, it is challenging to ensure that the shared information maintains privacy while learning accurate models. To the best of our knowledge, the algorithm proposed in this paper is the first practical solution for differentially private vertical federated k-means clustering, where the server can obtain a set of global centers with a provable differential privacy guarantee. Our algorithm assumes an untrusted central server that aggregates differentially private local centers and membership encodings from local data parties. It builds a weighted grid as the synopsis of the global",
    "path": "papers/22/08/2208.01700.json",
    "total_tokens": 862,
    "translated_title": "差分隐私垂直联邦聚类",
    "translated_abstract": "在许多应用中，多个方有关同一组用户的私有数据，但在不同的属性集上，服务器希望利用这些数据来训练模型。为了在保护数据主体隐私的同时实现模型学习，我们需要垂直联邦学习（VFL）技术，其中数据方仅共享用于训练模型的信息，而不是私有数据。然而，确保共享的信息在学习准确模型的同时保持隐私非常具有挑战性。据我们所知，本文提出的算法是差分隐私垂直联邦k均值聚类的第一个实际解决方案，其中服务器可以获得具有可证明差分隐私保证的全局中心集。我们的算法假设不受信任的中央服务器从本地数据方聚合不同ially private的局部中心和成员编码。它构建一个加权网格作为全局的摘要。",
    "tldr": "该论文提出了一种差分隐私的垂直联邦聚类算法，它可以在保护数据隐私的同时训练准确模型，是差分隐私垂直联邦k均值聚类的第一个实际解决方案。",
    "en_tdlr": "This paper proposes a differentially private vertical federated clustering algorithm that can train accurate models while protecting data privacy, which is the first practical solution for differentially private vertical federated k-means clustering."
}