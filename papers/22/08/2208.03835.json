{
    "title": "On Transfer of Adversarial Robustness from Pretraining to Downstream Tasks. (arXiv:2208.03835v2 [cs.LG] UPDATED)",
    "abstract": "As large-scale training regimes have gained popularity, the use of pretrained models for downstream tasks has become common practice in machine learning. While pretraining has been shown to enhance the performance of models in practice, the transfer of robustness properties from pretraining to downstream tasks remains poorly understood. In this study, we demonstrate that the robustness of a linear predictor on downstream tasks can be constrained by the robustness of its underlying representation, regardless of the protocol used for pretraining. We prove (i) a bound on the loss that holds independent of any downstream task, as well as (ii) a criterion for robust classification in particular. We validate our theoretical results in practical applications, show how our results can be used for calibrating expectations of downstream robustness, and when our results are useful for optimal transfer learning. Taken together, our results offer an initial step towards characterizing the requireme",
    "link": "http://arxiv.org/abs/2208.03835",
    "context": "Title: On Transfer of Adversarial Robustness from Pretraining to Downstream Tasks. (arXiv:2208.03835v2 [cs.LG] UPDATED)\nAbstract: As large-scale training regimes have gained popularity, the use of pretrained models for downstream tasks has become common practice in machine learning. While pretraining has been shown to enhance the performance of models in practice, the transfer of robustness properties from pretraining to downstream tasks remains poorly understood. In this study, we demonstrate that the robustness of a linear predictor on downstream tasks can be constrained by the robustness of its underlying representation, regardless of the protocol used for pretraining. We prove (i) a bound on the loss that holds independent of any downstream task, as well as (ii) a criterion for robust classification in particular. We validate our theoretical results in practical applications, show how our results can be used for calibrating expectations of downstream robustness, and when our results are useful for optimal transfer learning. Taken together, our results offer an initial step towards characterizing the requireme",
    "path": "papers/22/08/2208.03835.json",
    "total_tokens": 915,
    "translated_title": "关于从预训练到下游任务的对抗鲁棒性转移",
    "translated_abstract": "随着大规模训练方案的流行，预训练模型在机器学习中的下游任务中被广泛使用。虽然实践中已经证明预训练可以提高模型的性能，但是从预训练到下游任务的鲁棒性属性的转移仍然不够理解。在本研究中，我们证明了线性预测器在下游任务中的鲁棒性可以由其基础表示的鲁棒性限制，而不管预训练使用的协议如何。我们证明了(i)一个在任何下游任务中都成立的损失上界，以及(ii)特定于鲁棒分类的准则。我们在实际应用中验证了我们的理论结果，展示了我们的结果如何用于校准下游鲁棒性的期望，以及我们的结果在最优迁移学习中的用途。综合起来，我们的结果为表征要求进行了初步的步骤。",
    "tldr": "本研究证明了无论预训练采用何种协议，线性预测器在下游任务中的鲁棒性受其基础表示鲁棒性的限制。我们提出了损失上界和鲁棒分类准则，并在实际应用中验证了这些理论结果。"
}