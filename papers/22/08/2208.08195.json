{
    "title": "Benchmarking Compositionality with Formal Languages. (arXiv:2208.08195v3 [cs.CL] UPDATED)",
    "abstract": "Recombining known primitive concepts into larger novel combinations is a quintessentially human cognitive capability. Whether large neural models in NLP can acquire this ability while learning from data is an open question. In this paper, we investigate this problem from the perspective of formal languages. We use deterministic finite-state transducers to make an unbounded number of datasets with controllable properties governing compositionality. By randomly sampling over many transducers, we explore which of their properties contribute to learnability of a compositional relation by a neural network. We find that the models either learn the relations completely or not at all. The key is transition coverage, setting a soft learnability limit at 400 examples per transition.",
    "link": "http://arxiv.org/abs/2208.08195",
    "context": "Title: Benchmarking Compositionality with Formal Languages. (arXiv:2208.08195v3 [cs.CL] UPDATED)\nAbstract: Recombining known primitive concepts into larger novel combinations is a quintessentially human cognitive capability. Whether large neural models in NLP can acquire this ability while learning from data is an open question. In this paper, we investigate this problem from the perspective of formal languages. We use deterministic finite-state transducers to make an unbounded number of datasets with controllable properties governing compositionality. By randomly sampling over many transducers, we explore which of their properties contribute to learnability of a compositional relation by a neural network. We find that the models either learn the relations completely or not at all. The key is transition coverage, setting a soft learnability limit at 400 examples per transition.",
    "path": "papers/22/08/2208.08195.json",
    "total_tokens": 767,
    "translated_title": "使用形式语言对组合性进行基准测试",
    "translated_abstract": "将已知的原始概念重新组合成更大的新组合是一种典型的人类认知能力。在从数据中学习的过程中，大型NLP神经模型是否能够获得这种能力是一个开放的问题。本文从形式语言的角度研究了这个问题。我们使用确定性有限状态转换器生成具有可控组合性属性的无界数据集。通过对许多转换器进行随机抽样，我们探讨了它们的哪些属性能够对神经网络对组合性关系的可学习性做出贡献。我们发现模型要么完全学习关系，要么完全不学习。关键在于转换覆盖率，将软可学习界限设置为每个转换400个示例。",
    "tldr": "通过使用形式语言的方法进行基准测试，我们发现大型NLP神经模型要么完全学习关系，要么完全不学习。转换覆盖率是关键，将软可学习界限设置为每个转换400个示例。",
    "en_tdlr": "By benchmarking with formal languages, we found that large NLP neural models either completely learn the relations or not at all. Transition coverage, with a soft learnability limit of 400 examples per transition, is the key factor."
}