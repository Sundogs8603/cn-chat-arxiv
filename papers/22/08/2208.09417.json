{
    "title": "Target-oriented Sentiment Classification with Sequential Cross-modal Semantic Graph. (arXiv:2208.09417v2 [cs.CV] UPDATED)",
    "abstract": "Multi-modal aspect-based sentiment classification (MABSC) is task of classifying the sentiment of a target entity mentioned in a sentence and an image. However, previous methods failed to account for the fine-grained semantic association between the image and the text, which resulted in limited identification of fine-grained image aspects and opinions. To address these limitations, in this paper we propose a new approach called SeqCSG, which enhances the encoder-decoder sentiment classification framework using sequential cross-modal semantic graphs. SeqCSG utilizes image captions and scene graphs to extract both global and local fine-grained image information and considers them as elements of the cross-modal semantic graph along with tokens from tweets. The sequential cross-modal semantic graph is represented as a sequence with a multi-modal adjacency matrix indicating relationships between elements. Experimental results show that the approach outperforms existing methods and achieves ",
    "link": "http://arxiv.org/abs/2208.09417",
    "context": "Title: Target-oriented Sentiment Classification with Sequential Cross-modal Semantic Graph. (arXiv:2208.09417v2 [cs.CV] UPDATED)\nAbstract: Multi-modal aspect-based sentiment classification (MABSC) is task of classifying the sentiment of a target entity mentioned in a sentence and an image. However, previous methods failed to account for the fine-grained semantic association between the image and the text, which resulted in limited identification of fine-grained image aspects and opinions. To address these limitations, in this paper we propose a new approach called SeqCSG, which enhances the encoder-decoder sentiment classification framework using sequential cross-modal semantic graphs. SeqCSG utilizes image captions and scene graphs to extract both global and local fine-grained image information and considers them as elements of the cross-modal semantic graph along with tokens from tweets. The sequential cross-modal semantic graph is represented as a sequence with a multi-modal adjacency matrix indicating relationships between elements. Experimental results show that the approach outperforms existing methods and achieves ",
    "path": "papers/22/08/2208.09417.json",
    "total_tokens": 858,
    "translated_title": "基于顺序跨模态语义图的目标导向情感分类",
    "translated_abstract": "多模态的方面级情感分类(MABSC)是一种将句子和图像中提到的目标实体的情感进行分类的任务。然而，以前的方法未能考虑到图像和文本之间精细的语义关联，导致了对精细图像方面和意见的有限识别。为了解决这些限制，本文提出了一种名为SeqCSG的新方法，它利用顺序跨模态语义图增强了编码器-解码器情感分类框架。SeqCSG利用图像标题和场景图提取全局和局部的精细图像信息，并将它们与推文中的标记一起作为跨模态语义图的元素。顺序跨模态语义图被表示为一个序列，其中多模态邻接矩阵指示元素之间的关系。实验结果表明，该方法优于现有方法，并取得了较好的效果。",
    "tldr": "本文提出了一种基于顺序跨模态语义图的目标导向情感分类方法，通过利用图像标题和场景图提取全局和局部的精细图像信息，与推文中的标记结合形成跨模态语义图，取得了较好的效果。",
    "en_tdlr": "This paper presents a target-oriented sentiment classification method based on sequential cross-modal semantic graph, which improves the identification of fine-grained image aspects and opinions by utilizing image captions and scene graphs. It achieves better performance compared to existing methods."
}