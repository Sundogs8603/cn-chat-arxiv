{
    "title": "A Comprehensive Analysis of AI Biases in DeepFake Detection With Massively Annotated Databases. (arXiv:2208.05845v2 [cs.CV] UPDATED)",
    "abstract": "In recent years, image and video manipulations with Deepfake have become a severe concern for security and society. Many detection models and datasets have been proposed to detect Deepfake data reliably. However, there is an increased concern that these models and training databases might be biased and, thus, cause Deepfake detectors to fail. In this work, we investigate the bias issue caused by public Deepfake datasets by (a) providing large-scale demographic and non-demographic attribute annotations of 47 different attributes for five popular Deepfake datasets and (b) comprehensively analysing AI-bias of three state-of-the-art Deepfake detection backbone models on these datasets. The investigation analyses the influence of a large variety of distinctive attributes (from over 65M labels) on the detection performance, including demographic (age, gender, ethnicity) and non-demographic (hair, skin, accessories, etc.) information. The results indicate that investigated databases lack dive",
    "link": "http://arxiv.org/abs/2208.05845",
    "context": "Title: A Comprehensive Analysis of AI Biases in DeepFake Detection With Massively Annotated Databases. (arXiv:2208.05845v2 [cs.CV] UPDATED)\nAbstract: In recent years, image and video manipulations with Deepfake have become a severe concern for security and society. Many detection models and datasets have been proposed to detect Deepfake data reliably. However, there is an increased concern that these models and training databases might be biased and, thus, cause Deepfake detectors to fail. In this work, we investigate the bias issue caused by public Deepfake datasets by (a) providing large-scale demographic and non-demographic attribute annotations of 47 different attributes for five popular Deepfake datasets and (b) comprehensively analysing AI-bias of three state-of-the-art Deepfake detection backbone models on these datasets. The investigation analyses the influence of a large variety of distinctive attributes (from over 65M labels) on the detection performance, including demographic (age, gender, ethnicity) and non-demographic (hair, skin, accessories, etc.) information. The results indicate that investigated databases lack dive",
    "path": "papers/22/08/2208.05845.json",
    "total_tokens": 915,
    "translated_title": "基于大规模注释数据库的深度伪造检测 AI 偏差的全面分析",
    "translated_abstract": "近年来，Deepfake 对图像和视频的篡改已经成为安全和社会的严重关注点。许多检测模型和数据集已经被提出，可靠地检测 Deepfake 数据。然而，人们越来越担心这些模型和训练数据集可能存在偏差，从而导致 Deepfake 检测器失效。本研究通过提供五个流行的 Deepfake 数据集中 47 种不同属性的大规模人口统计和非人口统计属性注释，并全面分析三种最先进的 Deepfake 检测模型对这些数据集的 AI 偏差问题，调查研究了超过 6500 万个标签的许多不同属性（包括人口统计学（年龄、性别、种族）和非人口统计学（头发、皮肤、配饰等）信息对检测性能的影响。结果表明，调查的数据库缺乏多样性，可能导致 AI 偏差。",
    "tldr": "本研究通过提供包含47种不同属性注释的大规模数据集，并对三种最先进的Deepfake检测模型进行全面分析，旨在研究公共Deepfake数据集可能带来的AI偏差问题",
    "en_tdlr": "This study aims to investigate the issue of AI bias caused by public Deepfake datasets by providing annotations of 47 different attributes for five popular Deepfake datasets and comprehensively analyzing the AI bias of three state-of-the-art Deepfake detection backbone models on these datasets, which lack diversity and may lead to AI bias."
}