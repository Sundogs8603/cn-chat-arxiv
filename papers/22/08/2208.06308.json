{
    "title": "Developing a Philosophical Framework for Fair Machine Learning: Lessons From The Case of Algorithmic Collusion. (arXiv:2208.06308v2 [cs.LG] UPDATED)",
    "abstract": "Fair machine learning research has been primarily concerned with classification tasks that result in discrimination. However, as machine learning algorithms are applied in new contexts the harms and injustices that result are qualitatively different than those presently studied. The existing research paradigm in machine learning which develops metrics and definitions of fairness cannot account for these qualitatively different types of injustice. One example of this is the problem of algorithmic collusion and market fairness. The negative consequences of algorithmic collusion affect all consumers, not only particular members of a protected class. Drawing on this case study, I propose an ethical framework for researchers and practitioners in machine learning seeking to develop and apply fairness metrics that extends to new domains. This contribution ties the development of formal metrics of fairness to specifically scoped normative principles. This enables fairness metrics to reflect di",
    "link": "http://arxiv.org/abs/2208.06308",
    "context": "Title: Developing a Philosophical Framework for Fair Machine Learning: Lessons From The Case of Algorithmic Collusion. (arXiv:2208.06308v2 [cs.LG] UPDATED)\nAbstract: Fair machine learning research has been primarily concerned with classification tasks that result in discrimination. However, as machine learning algorithms are applied in new contexts the harms and injustices that result are qualitatively different than those presently studied. The existing research paradigm in machine learning which develops metrics and definitions of fairness cannot account for these qualitatively different types of injustice. One example of this is the problem of algorithmic collusion and market fairness. The negative consequences of algorithmic collusion affect all consumers, not only particular members of a protected class. Drawing on this case study, I propose an ethical framework for researchers and practitioners in machine learning seeking to develop and apply fairness metrics that extends to new domains. This contribution ties the development of formal metrics of fairness to specifically scoped normative principles. This enables fairness metrics to reflect di",
    "path": "papers/22/08/2208.06308.json",
    "total_tokens": 893,
    "translated_title": "为公正机器学习开发哲学框架：从算法串通案例中的教训",
    "translated_abstract": "公正机器学习研究主要关注导致歧视的分类任务。然而，随着机器学习算法在新的背景下的应用，产生的伤害和不公正与目前研究的本质上不同。机器学习中现有的研究范式无法解释这些本质上不同类型的不公正。算法串通和市场公平性问题是其中一个例子。算法串通的负面后果影响所有消费者，而不仅仅是某个受保护类别的成员。借鉴这个案例研究，我提出了一个伦理框架，供机器学习研究人员和实践者在开发和应用公正指标时使用，以扩展到新的领域。这个贡献将公正的形式指标的发展与特定范围的规范原则联系起来。这使得公正指标能够反映出各种领域中的公正要求。",
    "tldr": "该论文提出了一个伦理框架，用于为公正机器学习开发和应用扩展到新领域的公正指标，通过提出特定范围的规范原则来使公正指标能够反映出各种领域中的公正要求。",
    "en_tdlr": "This paper proposes an ethical framework for developing and applying fairness metrics in fair machine learning, extending to new domains, by introducing specifically scoped normative principles to reflect the fairness requirements in various areas."
}