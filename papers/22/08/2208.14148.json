{
    "title": "Large-step neural network for learning the symplectic evolution from partitioned data. (arXiv:2208.14148v2 [astro-ph.EP] UPDATED)",
    "abstract": "In this study, we focus on learning Hamiltonian systems, which involves predicting the coordinate (q) and momentum (p) variables generated by a symplectic mapping. Based on Chen & Tao (2021), the symplectic mapping is represented by a generating function. To extend the prediction time period, we develop a new learning scheme by splitting the time series (q_i, p_i) into several partitions. We then train a large-step neural network (LSNN) to approximate the generating function between the first partition (i.e. the initial condition) and each one of the remaining partitions. This partition approach makes our LSNN effectively suppress the accumulative error when predicting the system evolution. Then we train the LSNN to learn the motions of the 2:3 resonant Kuiper belt objects for a long time period of 25000 yr. The results show that there are two significant improvements over the neural network constructed in our previous work (Li et al. 2022): (1) the conservation of the Jacobi integral,",
    "link": "http://arxiv.org/abs/2208.14148",
    "context": "Title: Large-step neural network for learning the symplectic evolution from partitioned data. (arXiv:2208.14148v2 [astro-ph.EP] UPDATED)\nAbstract: In this study, we focus on learning Hamiltonian systems, which involves predicting the coordinate (q) and momentum (p) variables generated by a symplectic mapping. Based on Chen & Tao (2021), the symplectic mapping is represented by a generating function. To extend the prediction time period, we develop a new learning scheme by splitting the time series (q_i, p_i) into several partitions. We then train a large-step neural network (LSNN) to approximate the generating function between the first partition (i.e. the initial condition) and each one of the remaining partitions. This partition approach makes our LSNN effectively suppress the accumulative error when predicting the system evolution. Then we train the LSNN to learn the motions of the 2:3 resonant Kuiper belt objects for a long time period of 25000 yr. The results show that there are two significant improvements over the neural network constructed in our previous work (Li et al. 2022): (1) the conservation of the Jacobi integral,",
    "path": "papers/22/08/2208.14148.json",
    "total_tokens": 872,
    "translated_title": "大步神经网络学习来自分区数据的辛演化",
    "translated_abstract": "本研究关注学习哈密顿系统，需要预测辛映射生成的坐标（q）和动量（p）变量。基于Chen＆Tao（2021）的研究，辛映射由生成函数表示。为了延长预测时间，我们将时间序列（q_i、p_i）分成几个区间，并用大步神经网络（LSNN）来逼近第一区间（即初始条件）和其余各个区间之间的生成函数。这种分区方法使我们的LSNN在预测系统演化时能有效抑制累积误差。然后，我们训练LSNN学习25000年的2：3共振柯伊伯带对象的运动。结果显示，在我们先前工作中构建的神经网络（Li等，2022）基础上，有两个显著的改进：（1）Jacobi积分的守恒，",
    "tldr": "本研究使用分区的方法来训练大步神经网络，学习辛哈密顿系统的演化，有效抑制累积误差，并成功保持Jacobi积分的守恒。",
    "en_tdlr": "This study trains a large-step neural network using a partition approach to effectively suppress the accumulative error when predicting the evolution of a symplectic Hamiltonian system and successfully conserve the Jacobi integral."
}