{
    "title": "Communication Size Reduction of Federated Learning using Neural ODE Models. (arXiv:2208.09478v3 [cs.LG] UPDATED)",
    "abstract": "Federated learning is a machine learning approach in which data is not aggregated on a server, but is trained at clients locally, in consideration of security and privacy. ResNet is a classic but representative neural network that succeeds in deepening the neural network by learning a residual function that adds the inputs and outputs together. In federated learning, communication is performed between the server and clients to exchange weight parameters. Since ResNet has deep layers and a large number of parameters, the communication size becomes large. In this paper, we use Neural ODE as a lightweight model of ResNet to reduce communication size in federated learning. In addition, we newly introduce a flexible federated learning using Neural ODE models with different number of iterations, which correspond to ResNet models with different depths. Evaluation results using CIFAR-10 dataset show that the use of Neural ODE reduces communication size by up to 92.4% compared to ResNet. We als",
    "link": "http://arxiv.org/abs/2208.09478",
    "raw_ret": "{\n    \"translated_title\": \"使用神经ODE模型减少联邦学习的通信大小\",\n    \"translated_abstract\": \"联邦学习是一种机器学习方法，其中数据不在服务器上聚合，而是在客户端本地训练，考虑安全和隐私。ResNet是一种经典但具有代表性的神经网络，通过学习将输入和输出相加的残差函数来加深神经网络。在联邦学习中，服务器和客户端之间执行通信以交换权重参数。由于ResNet具有深层和大量参数，因此通信大小变大。在本文中，我们使用神经ODE作为ResNet的轻量级模型，以减少联邦学习中的通信大小。此外，我们新引入了一种使用具有不同迭代次数的神经ODE模型的灵活联邦学习，这些迭代次数对应于具有不同深度的ResNet模型。使用CIFAR-10数据集的评估结果表明，与ResNet相比，使用神经ODE可以将通信大小减少高达92.4％。我们也是\",\n    \"tldr\": \"本文使用神经ODE作为ResNet的轻量级模型，在联邦学习中减少通信大小。评估结果显示，与ResNet相比，使用神经ODE可以将通信大小减少高达92.4％。\"\n}",
    "total_tokens": 855,
    "ret": {
        "translated_title": "使用神经ODE模型减少联邦学习的通信大小",
        "translated_abstract": "联邦学习是一种机器学习方法，其中数据不在服务器上聚合，而是在客户端本地训练，考虑安全和隐私。ResNet是一种经典但具有代表性的神经网络，通过学习将输入和输出相加的残差函数来加深神经网络。在联邦学习中，服务器和客户端之间执行通信以交换权重参数。由于ResNet具有深层和大量参数，因此通信大小变大。在本文中，我们使用神经ODE作为ResNet的轻量级模型，以减少联邦学习中的通信大小。此外，我们新引入了一种使用具有不同迭代次数的神经ODE模型的灵活联邦学习，这些迭代次数对应于具有不同深度的ResNet模型。使用CIFAR-10数据集的评估结果表明，与ResNet相比，使用神经ODE可以将通信大小减少高达92.4％。我们也是",
        "tldr": "本文使用神经ODE作为ResNet的轻量级模型，在联邦学习中减少通信大小。评估结果显示，与ResNet相比，使用神经ODE可以将通信大小减少高达92.4％。"
    }
}