{
    "title": "E2EG: End-to-End Node Classification Using Graph Topology and Text-based Node Attributes. (arXiv:2208.04609v2 [cs.LG] UPDATED)",
    "abstract": "Node classification utilizing text-based node attributes has many real-world applications, ranging from prediction of paper topics in academic citation graphs to classification of user characteristics in social media networks. State-of-the-art node classification frameworks, such as GIANT, use a two-stage pipeline: first embedding the text attributes of graph nodes then feeding the resulting embeddings into a node classification model. In this paper, we eliminate these two stages and develop an end-to-end node classification model that builds upon GIANT, called End-to-End-GIANT (E2EG). The tandem utilization of a main and an auxiliary classification objectives in our approach results in a more robust model, enabling the BERT backbone to be switched out for a distilled encoder with a 25% - 40% reduction in the number of parameters. Moreover, the model's end-to-end nature increases ease of use, as it avoids the need of chaining multiple models for node classification. Compared to a GIANT",
    "link": "http://arxiv.org/abs/2208.04609",
    "context": "Title: E2EG: End-to-End Node Classification Using Graph Topology and Text-based Node Attributes. (arXiv:2208.04609v2 [cs.LG] UPDATED)\nAbstract: Node classification utilizing text-based node attributes has many real-world applications, ranging from prediction of paper topics in academic citation graphs to classification of user characteristics in social media networks. State-of-the-art node classification frameworks, such as GIANT, use a two-stage pipeline: first embedding the text attributes of graph nodes then feeding the resulting embeddings into a node classification model. In this paper, we eliminate these two stages and develop an end-to-end node classification model that builds upon GIANT, called End-to-End-GIANT (E2EG). The tandem utilization of a main and an auxiliary classification objectives in our approach results in a more robust model, enabling the BERT backbone to be switched out for a distilled encoder with a 25% - 40% reduction in the number of parameters. Moreover, the model's end-to-end nature increases ease of use, as it avoids the need of chaining multiple models for node classification. Compared to a GIANT",
    "path": "papers/22/08/2208.04609.json",
    "total_tokens": 895,
    "translated_title": "E2EG: 使用图拓扑和基于文本的节点属性进行端到端节点分类",
    "translated_abstract": "利用基于文本的节点属性进行节点分类在现实世界中有许多应用，从学术引用图中预测论文主题到社交媒体网络中用户特征的分类。现有的节点分类框架，如GIANT，使用了两个阶段的流程：首先嵌入图节点的文本属性，然后将得到的嵌入输入节点分类模型。在本文中，我们消除了这两个阶段，并开发了一个建立在GIANT基础上的端到端节点分类模型，称为End-to-End-GIANT（E2EG）。我们的方法中主要分类目标和辅助分类目标的串行利用结果使得模型更加稳健，使得BERT主干可以被一个参数减少25%-40%的蒸馏编码器取代。此外，模型的端到端特性增加了使用的便捷性，因为它避免了为节点分类链接多个模型的需求。与GIANT相比，",
    "tldr": "E2EG是一个端到端节点分类模型，通过利用图拓扑和基于文本的节点属性，消除了嵌入和分类两个阶段，引入了主要和辅助分类目标的串行利用，减少了参数数量并提高了使用的便捷性。",
    "en_tdlr": "E2EG is an end-to-end node classification model that eliminates the embedding and classification stages by utilizing graph topology and text-based node attributes, introduces the tandem utilization of main and auxiliary classification objectives, reduces the number of parameters, and increases ease of use."
}