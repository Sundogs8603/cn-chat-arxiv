{
    "title": "SFusion: Self-attention based N-to-One Multimodal Fusion Block. (arXiv:2208.12776v2 [cs.CV] UPDATED)",
    "abstract": "People perceive the world with different senses, such as sight, hearing, smell, and touch. Processing and fusing information from multiple modalities enables Artificial Intelligence to understand the world around us more easily. However, when there are missing modalities, the number of available modalities is different in diverse situations, which leads to an N-to-One fusion problem. To solve this problem, we propose a self-attention based fusion block called SFusion. Different from preset formulations or convolution based methods, the proposed block automatically learns to fuse available modalities without synthesizing or zero-padding missing ones. Specifically, the feature representations extracted from upstream processing model are projected as tokens and fed into self-attention module to generate latent multimodal correlations. Then, a modal attention mechanism is introduced to build a shared representation, which can be applied by the downstream decision model. The proposed SFusio",
    "link": "http://arxiv.org/abs/2208.12776",
    "context": "Title: SFusion: Self-attention based N-to-One Multimodal Fusion Block. (arXiv:2208.12776v2 [cs.CV] UPDATED)\nAbstract: People perceive the world with different senses, such as sight, hearing, smell, and touch. Processing and fusing information from multiple modalities enables Artificial Intelligence to understand the world around us more easily. However, when there are missing modalities, the number of available modalities is different in diverse situations, which leads to an N-to-One fusion problem. To solve this problem, we propose a self-attention based fusion block called SFusion. Different from preset formulations or convolution based methods, the proposed block automatically learns to fuse available modalities without synthesizing or zero-padding missing ones. Specifically, the feature representations extracted from upstream processing model are projected as tokens and fed into self-attention module to generate latent multimodal correlations. Then, a modal attention mechanism is introduced to build a shared representation, which can be applied by the downstream decision model. The proposed SFusio",
    "path": "papers/22/08/2208.12776.json",
    "total_tokens": 946,
    "translated_title": "SFusion: 基于自注意力的N对一多模态融合模块",
    "translated_abstract": "人们通过不同的感官（如视觉、听觉、嗅觉和触觉）来感知世界。处理和融合来自多个模态的信息使得人工智能更容易理解我们周围的世界。然而，当存在缺失的模态时，在不同的情况下可用的模态数量是不同的，这就导致了一个N对一的融合问题。为了解决这个问题，我们提出了一个基于自注意力的融合模块，称为SFusion。与预设的公式化或基于卷积的方法不同，所提出的模块自动学习融合可用的模态，而不是合成或填充缺失的模态。具体而言，从上游处理模型提取的特征表示被投影为令牌，并输入自注意力模块以生成潜在的多模态相关性。然后，引入模态注意机制构建一个共享表示，可以被下游决策模型使用。所提出的SFusion模块能够有效地解决N对一的多模态融合问题。",
    "tldr": "SFusion是一个基于自注意力的融合模块，用于解决N对一的多模态融合问题，不需要合成或填充缺失的模态。它通过自动学习融合可用的模态，并构建共享表示来实现多模态的融合，以便下游决策模型使用。",
    "en_tdlr": "SFusion is a self-attention based fusion block designed to solve the N-to-One multimodal fusion problem. It automatically learns to fuse available modalities without synthesizing or zero-padding missing ones. By generating latent multimodal correlations and building a shared representation, SFusion enables downstream decision models to effectively utilize multimodal information."
}