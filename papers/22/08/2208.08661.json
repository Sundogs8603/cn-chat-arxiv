{
    "title": "Domain-Specific Risk Minimization for Out-of-Distribution Generalization. (arXiv:2208.08661v4 [cs.LG] UPDATED)",
    "abstract": "Recent domain generalization (DG) approaches typically use the hypothesis learned on source domains for inference on the unseen target domain. However, such a hypothesis can be arbitrarily far from the optimal one for the target domain, induced by a gap termed ``adaptivity gap''. Without exploiting the domain information from the unseen test samples, adaptivity gap estimation and minimization are intractable, which hinders us to robustify a model to any unknown distribution. In this paper, we first establish a generalization bound that explicitly considers the adaptivity gap. Our bound motivates two strategies to reduce the gap: the first one is ensembling multiple classifiers to enrich the hypothesis space, then we propose effective gap estimation methods for guiding the selection of a better hypothesis for the target. The other method is minimizing the gap directly by adapting model parameters using online target samples. We thus propose \\textbf{Domain-specific Risk Minimization (DRM",
    "link": "http://arxiv.org/abs/2208.08661",
    "context": "Title: Domain-Specific Risk Minimization for Out-of-Distribution Generalization. (arXiv:2208.08661v4 [cs.LG] UPDATED)\nAbstract: Recent domain generalization (DG) approaches typically use the hypothesis learned on source domains for inference on the unseen target domain. However, such a hypothesis can be arbitrarily far from the optimal one for the target domain, induced by a gap termed ``adaptivity gap''. Without exploiting the domain information from the unseen test samples, adaptivity gap estimation and minimization are intractable, which hinders us to robustify a model to any unknown distribution. In this paper, we first establish a generalization bound that explicitly considers the adaptivity gap. Our bound motivates two strategies to reduce the gap: the first one is ensembling multiple classifiers to enrich the hypothesis space, then we propose effective gap estimation methods for guiding the selection of a better hypothesis for the target. The other method is minimizing the gap directly by adapting model parameters using online target samples. We thus propose \\textbf{Domain-specific Risk Minimization (DRM",
    "path": "papers/22/08/2208.08661.json",
    "total_tokens": 1024,
    "translated_title": "面向领域特定风险最小化的外样本泛化研究",
    "translated_abstract": "近期的领域泛化方法通常使用在源域上学习的假设来推断未见目标域。然而，这种假设可能与针对目标域的最优假设相去甚远，这种差距被称为“适应性差距”。如果不利用测试样本中的领域信息，适应性差距的估计和最小化是不可行的，这妨碍了我们将模型硬化到任何未知分布。因此，本文首先建立了一个明确考虑适应性差距的泛化界限。我们的界限鼓励通过两种策略来减少差距：第一种方法是使用多个分类器来丰富假设空间，然后我们提出了有效的差距估计方法来指导为目标选择更好的假设。另一种方法是通过使用在线目标样本来直接适应模型参数来最小化差距。我们因此提出了一个框架，统一了这两种策略，允许有效地减少适应性差距。广泛的实验表明，DRM在低数据条件下显著优于最先进的DG方法。",
    "tldr": "本篇论文提出了一种面向领域特定风险最小化的泛化框架(DRM)，该框架通过多分类器集成和在线目标样本适应来减少适应性差距，并在实验中表现出了明显优于现有方法的表现。",
    "en_tdlr": "This paper proposes a domain-specific risk minimization framework (DRM) for effective reduction of adaptivity gap through ensemble of multiple classifiers and adapting model parameters using online target samples. The proposed method outperforms state-of-the-art domain generalization methods, especially in the low-data regime."
}