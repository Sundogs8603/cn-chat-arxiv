{
    "title": "Approximate blocked Gibbs sampling for Bayesian neural networks. (arXiv:2208.11389v3 [stat.ML] UPDATED)",
    "abstract": "In this work, minibatch MCMC sampling for feedforward neural networks is made more feasible. To this end, it is proposed to sample subgroups of parameters via a blocked Gibbs sampling scheme. By partitioning the parameter space, sampling is possible irrespective of layer width. It is also possible to alleviate vanishing acceptance rates for increasing depth by reducing the proposal variance in deeper layers. Increasing the length of a non-convergent chain increases the predictive accuracy in classification tasks, so avoiding vanishing acceptance rates and consequently enabling longer chain runs have practical benefits. Moreover, non-convergent chain realizations aid in the quantification of predictive uncertainty. An open problem is how to perform minibatch MCMC sampling for feedforward neural networks in the presence of augmented data.",
    "link": "http://arxiv.org/abs/2208.11389",
    "context": "Title: Approximate blocked Gibbs sampling for Bayesian neural networks. (arXiv:2208.11389v3 [stat.ML] UPDATED)\nAbstract: In this work, minibatch MCMC sampling for feedforward neural networks is made more feasible. To this end, it is proposed to sample subgroups of parameters via a blocked Gibbs sampling scheme. By partitioning the parameter space, sampling is possible irrespective of layer width. It is also possible to alleviate vanishing acceptance rates for increasing depth by reducing the proposal variance in deeper layers. Increasing the length of a non-convergent chain increases the predictive accuracy in classification tasks, so avoiding vanishing acceptance rates and consequently enabling longer chain runs have practical benefits. Moreover, non-convergent chain realizations aid in the quantification of predictive uncertainty. An open problem is how to perform minibatch MCMC sampling for feedforward neural networks in the presence of augmented data.",
    "path": "papers/22/08/2208.11389.json",
    "total_tokens": 790,
    "translated_title": "Bayesian神经网络中的近似阻塞Gibbs采样",
    "translated_abstract": "本文提出了一种更可行的前馈神经网络的小批量MCMC采样方法。为此，文中提出了通过阻塞Gibbs采样方案对参数进行子组抽样的方法。通过对参数空间进行划分，无论层宽如何，都能进行采样。同时，通过在深层减小建议方差，可以减轻递增深度时消失的接受率问题。在分类任务中，增加非收敛链的长度可以提高预测准确性，因此避免消失的接受率和允许更长的链运行具有实际好处。此外，非收敛链的实现有助于量化预测不确定性。一个未解决的问题是在存在增广数据的情况下如何进行前馈神经网络的小批量MCMC采样。",
    "tldr": "本文提出了一种近似阻塞Gibbs采样方法，可以更可行地进行小批量MCMC采样，提高了前馈神经网络的预测准确性和预测不确定性的量化能力。",
    "en_tdlr": "This paper proposes an approximate blocked Gibbs sampling method for more feasible minibatch MCMC sampling in Bayesian neural networks. It improves predictive accuracy and enables quantification of predictive uncertainty."
}