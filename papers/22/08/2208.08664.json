{
    "title": "Enhancing Diffusion-Based Image Synthesis with Robust Classifier Guidance. (arXiv:2208.08664v2 [cs.CV] UPDATED)",
    "abstract": "Denoising diffusion probabilistic models (DDPMs) are a recent family of generative models that achieve state-of-the-art results. In order to obtain class-conditional generation, it was suggested to guide the diffusion process by gradients from a time-dependent classifier. While the idea is theoretically sound, deep learning-based classifiers are infamously susceptible to gradient-based adversarial attacks. Therefore, while traditional classifiers may achieve good accuracy scores, their gradients are possibly unreliable and might hinder the improvement of the generation results. Recent work discovered that adversarially robust classifiers exhibit gradients that are aligned with human perception, and these could better guide a generative process towards semantically meaningful images. We utilize this observation by defining and training a time-dependent adversarially robust classifier and use it as guidance for a generative diffusion model. In experiments on the highly challenging and di",
    "link": "http://arxiv.org/abs/2208.08664",
    "context": "Title: Enhancing Diffusion-Based Image Synthesis with Robust Classifier Guidance. (arXiv:2208.08664v2 [cs.CV] UPDATED)\nAbstract: Denoising diffusion probabilistic models (DDPMs) are a recent family of generative models that achieve state-of-the-art results. In order to obtain class-conditional generation, it was suggested to guide the diffusion process by gradients from a time-dependent classifier. While the idea is theoretically sound, deep learning-based classifiers are infamously susceptible to gradient-based adversarial attacks. Therefore, while traditional classifiers may achieve good accuracy scores, their gradients are possibly unreliable and might hinder the improvement of the generation results. Recent work discovered that adversarially robust classifiers exhibit gradients that are aligned with human perception, and these could better guide a generative process towards semantically meaningful images. We utilize this observation by defining and training a time-dependent adversarially robust classifier and use it as guidance for a generative diffusion model. In experiments on the highly challenging and di",
    "path": "papers/22/08/2208.08664.json",
    "total_tokens": 870,
    "translated_title": "利用稳健分类器引导改进扩散式图像合成",
    "translated_abstract": "去噪扩散概率模型（DDPM）是一类最新的生成模型族，能够达到最先进的结果。为了获得类条件生成，建议利用来自时间相关分类器的梯度来指导扩散过程。尽管这个想法理论上很正确，但基于深度学习的分类器容易受到基于梯度的对手攻击的影响。因此，虽然传统分类器可能达到良好的准确性分数，但它们的梯度可能不可靠，可能会妨碍生成结果的改善。最近的研究发现，对手稳健分类器的梯度与人类感知一致，这些分类器可以更好地引导生成过程朝着语义相关的图像方向进行。我们利用这一观察结果，定义和训练一个时间相关的对手稳健分类器，并将其用作生成扩散模型的指导。在高度具有挑战性和多样性的自然图像数据集上进行实验，实验结果表明，我们的方法能够改进扩散模型的生成效果。",
    "tldr": "该论文提出利用来自时间相关的对手稳健分类器的梯度来指导生成扩散模型，以促进生成结果的改善。",
    "en_tdlr": "This paper proposes to utilize gradients from a time-dependent adversarially robust classifier to guide the generative diffusion model, which leads to improved generation results."
}