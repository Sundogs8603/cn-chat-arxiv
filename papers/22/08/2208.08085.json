{
    "title": "Detection and Mitigation of Byzantine Attacks in Distributed Training. (arXiv:2208.08085v4 [cs.LG] UPDATED)",
    "abstract": "A plethora of modern machine learning tasks require the utilization of large-scale distributed clusters as a critical component of the training pipeline. However, abnormal Byzantine behavior of the worker nodes can derail the training and compromise the quality of the inference. Such behavior can be attributed to unintentional system malfunctions or orchestrated attacks; as a result, some nodes may return arbitrary results to the parameter server (PS) that coordinates the training. Recent work considers a wide range of attack models and has explored robust aggregation and/or computational redundancy to correct the distorted gradients.  In this work, we consider attack models ranging from strong ones: $q$ omniscient adversaries with full knowledge of the defense protocol that can change from iteration to iteration to weak ones: $q$ randomly chosen adversaries with limited collusion abilities which only change every few iterations at a time. Our algorithms rely on redundant task assignme",
    "link": "http://arxiv.org/abs/2208.08085",
    "context": "Title: Detection and Mitigation of Byzantine Attacks in Distributed Training. (arXiv:2208.08085v4 [cs.LG] UPDATED)\nAbstract: A plethora of modern machine learning tasks require the utilization of large-scale distributed clusters as a critical component of the training pipeline. However, abnormal Byzantine behavior of the worker nodes can derail the training and compromise the quality of the inference. Such behavior can be attributed to unintentional system malfunctions or orchestrated attacks; as a result, some nodes may return arbitrary results to the parameter server (PS) that coordinates the training. Recent work considers a wide range of attack models and has explored robust aggregation and/or computational redundancy to correct the distorted gradients.  In this work, we consider attack models ranging from strong ones: $q$ omniscient adversaries with full knowledge of the defense protocol that can change from iteration to iteration to weak ones: $q$ randomly chosen adversaries with limited collusion abilities which only change every few iterations at a time. Our algorithms rely on redundant task assignme",
    "path": "papers/22/08/2208.08085.json",
    "total_tokens": 936,
    "translated_title": "分布式训练中拜占庭攻击的检测与缓解",
    "translated_abstract": "大量现代机器学习任务需要使用大规模分布式集群作为训练流程的关键组成部分。但是工作节点的异常拜占庭行为可能会破坏训练并危及推理的质量。此类行为可以归因于无意的系统故障或有组织的攻击，结果可能是一些节点向协调训练的参数服务器（PS）返回任意结果。最近的工作考虑了各种攻击模型并探索了强大的聚合和/或计算冗余来纠正扭曲的梯度。在这项工作中，我们考虑攻击模型从强到弱不等：$ q $具有完全了解防御协议并且每迭代都可以更改的全知对手到$ q $具有有限勾结能力并且仅每隔几次迭代更改的随机对手。我们的算法依赖于冗余任务分配、基于阈值的接收梯度过滤和基于时期的工作节点重启，以识别和缓解分布式训练中的拜占庭攻击。",
    "tldr": "本文探讨了分布式训练中的拜占庭攻击及其检测和缓解方法。"
}