{
    "title": "Learning Better Masking for Better Language Model Pre-training. (arXiv:2208.10806v3 [cs.CL] UPDATED)",
    "abstract": "Masked Language Modeling (MLM) has been widely used as the denoising objective in pre-training language models (PrLMs). Existing PrLMs commonly adopt a Random-Token Masking strategy where a fixed masking ratio is applied and different contents are masked by an equal probability throughout the entire training. However, the model may receive complicated impact from pre-training status, which changes accordingly as training time goes on. In this paper, we show that such time-invariant MLM settings on masking ratio and masked content are unlikely to deliver an optimal outcome, which motivates us to explore the influence of time-variant MLM settings. We propose two scheduled masking approaches that adaptively tune the masking ratio and masked content in different training stages, which improves the pre-training efficiency and effectiveness verified on the downstream tasks. Our work is a pioneer study on time-variant masking strategy on ratio and content and gives a better understanding of h",
    "link": "http://arxiv.org/abs/2208.10806",
    "context": "Title: Learning Better Masking for Better Language Model Pre-training. (arXiv:2208.10806v3 [cs.CL] UPDATED)\nAbstract: Masked Language Modeling (MLM) has been widely used as the denoising objective in pre-training language models (PrLMs). Existing PrLMs commonly adopt a Random-Token Masking strategy where a fixed masking ratio is applied and different contents are masked by an equal probability throughout the entire training. However, the model may receive complicated impact from pre-training status, which changes accordingly as training time goes on. In this paper, we show that such time-invariant MLM settings on masking ratio and masked content are unlikely to deliver an optimal outcome, which motivates us to explore the influence of time-variant MLM settings. We propose two scheduled masking approaches that adaptively tune the masking ratio and masked content in different training stages, which improves the pre-training efficiency and effectiveness verified on the downstream tasks. Our work is a pioneer study on time-variant masking strategy on ratio and content and gives a better understanding of h",
    "path": "papers/22/08/2208.10806.json",
    "total_tokens": 907,
    "translated_title": "学习更好的掩蔽策略以实现更好的语言模型预训练",
    "translated_abstract": "掩蔽语言建模（MLM）已被广泛用作预训练语言模型（PrLM）中的去噪目标。现有模型通常采用随机掩蔽策略，其中应用固定的掩蔽比例，并且以相等的概率掩蔽不同的内容。然而，模型可能会受到预训练状态的复杂影响，这种影响会随着训练时间的推移而变化。在本文中，我们展示了这种时间不变的MLM设置可能无法产生最佳结果，这促使我们探索时间变化的MLM设置的影响。我们提出了两种计划掩蔽方法，可以在不同的训练阶段自适应地调整掩蔽比例和掩蔽的内容，从而提高预训练效率和有效性，并在下游任务中得到验证。我们的工作是关于比率和内容的时间变化掩蔽策略的先驱研究，可以更好地理解和应用这些策略。",
    "tldr": "本文提出了两种时间变化的MLM掩蔽策略，可以在不同的训练阶段自适应地调整掩蔽比例和掩蔽内容，提高语言模型的预训练效率和有效性。",
    "en_tdlr": "The paper proposes two time-variant MLM masking strategies that adaptively adjust the masking ratio and masked content in different training stages, improving the efficiency and effectiveness of pre-training language models."
}