{
    "title": "GANs and Closures: Micro-Macro Consistency in Multiscale Modeling. (arXiv:2208.10715v3 [cs.LG] UPDATED)",
    "abstract": "Sampling the phase space of molecular systems -- and, more generally, of complex systems effectively modeled by stochastic differential equations -- is a crucial modeling step in many fields, from protein folding to materials discovery. These problems are often multiscale in nature: they can be described in terms of low-dimensional effective free energy surfaces parametrized by a small number of \"slow\" reaction coordinates; the remaining \"fast\" degrees of freedom populate an equilibrium measure on the reaction coordinate values. Sampling procedures for such problems are used to estimate effective free energy differences as well as ensemble averages with respect to the conditional equilibrium distributions; these latter averages lead to closures for effective reduced dynamic models. Over the years, enhanced sampling techniques coupled with molecular simulation have been developed. An intriguing analogy arises with the field of Machine Learning (ML), where Generative Adversarial Networks",
    "link": "http://arxiv.org/abs/2208.10715",
    "context": "Title: GANs and Closures: Micro-Macro Consistency in Multiscale Modeling. (arXiv:2208.10715v3 [cs.LG] UPDATED)\nAbstract: Sampling the phase space of molecular systems -- and, more generally, of complex systems effectively modeled by stochastic differential equations -- is a crucial modeling step in many fields, from protein folding to materials discovery. These problems are often multiscale in nature: they can be described in terms of low-dimensional effective free energy surfaces parametrized by a small number of \"slow\" reaction coordinates; the remaining \"fast\" degrees of freedom populate an equilibrium measure on the reaction coordinate values. Sampling procedures for such problems are used to estimate effective free energy differences as well as ensemble averages with respect to the conditional equilibrium distributions; these latter averages lead to closures for effective reduced dynamic models. Over the years, enhanced sampling techniques coupled with molecular simulation have been developed. An intriguing analogy arises with the field of Machine Learning (ML), where Generative Adversarial Networks",
    "path": "papers/22/08/2208.10715.json",
    "total_tokens": 833,
    "translated_title": "GAN和闭合性: 多尺度建模中的微观-宏观一致性",
    "translated_abstract": "采样分子系统的相空间（更广义的是，用随机微分方程描述的复杂系统的相空间）在许多领域中是重要的建模步骤，从蛋白质折叠到材料发现。这些问题通常具有多尺度性质：它们可以用少量“缓慢”反应坐标参数化的低维有效自由能面来描述；剩余的“快速”自由度在反应坐标值上填充平衡测度。这些问题的采样过程用于估计有效的自由能差异和与条件平衡分布相关的集合平均数；这些后者的平均数导致有效的减少动态模型的闭合。多年来，增强采样技术与分子模拟相结合。与机器学习（ML）领域存在一个有趣的类比。",
    "tldr": "论文探讨了多尺度建模中采样和集合平均的问题，并将增强采样技术与分子模拟与机器学习中的生成对抗网络相结合。",
    "en_tdlr": "This paper discusses the issues of sampling and ensemble averages in multiscale modeling and combines enhanced sampling techniques with molecular simulation, drawing an intriguing analogy with the field of Machine Learning through the use of Generative Adversarial Networks."
}