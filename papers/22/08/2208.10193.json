{
    "title": "Convergent autoencoder approximation of low bending and low distortion manifold embeddings. (arXiv:2208.10193v2 [math.NA] UPDATED)",
    "abstract": "Autoencoders, which consist of an encoder and a decoder, are widely used in machine learning for dimension reduction of high-dimensional data. The encoder embeds the input data manifold into a lower-dimensional latent space, while the decoder represents the inverse map, providing a parametrization of the data manifold by the manifold in latent space. A good regularity and structure of the embedded manifold may substantially simplify further data processing tasks such as cluster analysis or data interpolation. We propose and analyze a novel regularization for learning the encoder component of an autoencoder: a loss functional that prefers isometric, extrinsically flat embeddings and allows to train the encoder on its own. To perform the training it is assumed that for pairs of nearby points on the input manifold their local Riemannian distance and their local Riemannian average can be evaluated. The loss functional is computed via Monte Carlo integration with different sampling strategi",
    "link": "http://arxiv.org/abs/2208.10193",
    "context": "Title: Convergent autoencoder approximation of low bending and low distortion manifold embeddings. (arXiv:2208.10193v2 [math.NA] UPDATED)\nAbstract: Autoencoders, which consist of an encoder and a decoder, are widely used in machine learning for dimension reduction of high-dimensional data. The encoder embeds the input data manifold into a lower-dimensional latent space, while the decoder represents the inverse map, providing a parametrization of the data manifold by the manifold in latent space. A good regularity and structure of the embedded manifold may substantially simplify further data processing tasks such as cluster analysis or data interpolation. We propose and analyze a novel regularization for learning the encoder component of an autoencoder: a loss functional that prefers isometric, extrinsically flat embeddings and allows to train the encoder on its own. To perform the training it is assumed that for pairs of nearby points on the input manifold their local Riemannian distance and their local Riemannian average can be evaluated. The loss functional is computed via Monte Carlo integration with different sampling strategi",
    "path": "papers/22/08/2208.10193.json",
    "total_tokens": 974,
    "translated_title": "具有低弯曲和低畸变的流形嵌入的收敛自动编码器逼近",
    "translated_abstract": "自动编码器由编码器和解码器组成，在机器学习中广泛用于高维数据的降维。编码器将输入数据流形嵌入到较低维的潜在空间中，而解码器则表示反向映射，通过潜在空间中的流形给出数据流形的参数化。良好的嵌入流形的规则性和结构性可以极大地简化进一步的数据处理任务，如聚类分析或数据插值。我们提出并分析了一种新颖的正则化方法，用于学习自动编码器的编码器部分：一种偏好等距、外在平坦嵌入的损失函数，允许单独对编码器进行训练。为了进行训练，假设可以评估输入流形上附近点对的局部Riemannian距离和局部Riemannian均值。通过蒙特卡洛积分和不同的采样策略计算损失函数。",
    "tldr": "这项研究提出了一种新的正则化方法，用于学习自动编码器的编码器部分，该方法偏好等距、外在平坦嵌入，并允许单独对编码器进行训练。研究通过蒙特卡洛积分计算损失函数，使用局部Riemannian距离和局部Riemannian均值评估输入流形上的点对。",
    "en_tdlr": "This study proposes a novel regularization method for learning the encoder component of an autoencoder, which prefers isometric, extrinsically flat embeddings and allows individual training of the encoder. The loss function is computed via Monte Carlo integration using the local Riemannian distance and local Riemannian average of nearby points on the input manifold."
}