{
    "title": "NeuralVDB: High-resolution Sparse Volume Representation using Hierarchical Neural Networks",
    "abstract": "We introduce NeuralVDB, which improves on an existing industry standard for efficient storage of sparse volumetric data, denoted VDB [Museth 2013], by leveraging recent advancements in machine learning. Our novel hybrid data structure can reduce the memory footprints of VDB volumes by orders of magnitude, while maintaining its flexibility and only incurring small (user-controlled) compression errors. Specifically, NeuralVDB replaces the lower nodes of a shallow and wide VDB tree structure with multiple hierarchical neural networks that separately encode topology and value information by means of neural classifiers and regressors respectively. This approach is proven to maximize the compression ratio while maintaining the spatial adaptivity offered by the higher-level VDB data structure. For sparse signed distance fields and density volumes, we have observed compression ratios on the order of 10x to more than 100x from already compressed VDB inputs, with little to no visual artifacts. F",
    "link": "https://arxiv.org/abs/2208.04448",
    "context": "Title: NeuralVDB: High-resolution Sparse Volume Representation using Hierarchical Neural Networks\nAbstract: We introduce NeuralVDB, which improves on an existing industry standard for efficient storage of sparse volumetric data, denoted VDB [Museth 2013], by leveraging recent advancements in machine learning. Our novel hybrid data structure can reduce the memory footprints of VDB volumes by orders of magnitude, while maintaining its flexibility and only incurring small (user-controlled) compression errors. Specifically, NeuralVDB replaces the lower nodes of a shallow and wide VDB tree structure with multiple hierarchical neural networks that separately encode topology and value information by means of neural classifiers and regressors respectively. This approach is proven to maximize the compression ratio while maintaining the spatial adaptivity offered by the higher-level VDB data structure. For sparse signed distance fields and density volumes, we have observed compression ratios on the order of 10x to more than 100x from already compressed VDB inputs, with little to no visual artifacts. F",
    "path": "papers/22/08/2208.04448.json",
    "total_tokens": 859,
    "translated_title": "NeuralVDB: 使用分层神经网络的高分辨率稀疏体积表示方法",
    "translated_abstract": "我们引入了NeuralVDB，通过利用机器学习的最新进展，改进了现有的用于高效存储稀疏体积数据的行业标准VDB[Museth 2013]。我们的新颖混合数据结构可以将VDB体积的内存占用减少数个数量级，同时保持其灵活性，并只产生小的（用户可控制的）压缩误差。具体而言，NeuralVDB使用多个分层神经网络替换了浅而宽的VDB树结构的较低节点，通过神经分类器和回归器分别编码拓扑和数值信息。此方法已被证明在保持高级VDB数据结构所提供的空间适应性的同时最大化了压缩比。对于稀疏有符号距离场和密度体积，我们观察到从已经压缩的VDB输入得到的压缩比在10倍到100倍以上，并且几乎没有可见的伪影。",
    "tldr": "NeuralVDB使用分层神经网络改进了VDB的存储效率，将内存占用减少数个数量级同时保持了灵活性，并实现了高压缩比和空间适应性。",
    "en_tdlr": "NeuralVDB improves the storage efficiency of VDB by using hierarchical neural networks, reducing memory footprints by several orders of magnitude while maintaining flexibility, achieving high compression ratios, and spatial adaptivity."
}