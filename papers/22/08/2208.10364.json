{
    "title": "Scaling Up Dynamic Graph Representation Learning via Spiking Neural Networks. (arXiv:2208.10364v3 [cs.NE] UPDATED)",
    "abstract": "Recent years have seen a surge in research on dynamic graph representation learning, which aims to model temporal graphs that are dynamic and evolving constantly over time. However, current work typically models graph dynamics with recurrent neural networks (RNNs), making them suffer seriously from computation and memory overheads on large temporal graphs. So far, scalability of dynamic graph representation learning on large temporal graphs remains one of the major challenges. In this paper, we present a scalable framework, namely SpikeNet, to efficiently capture the temporal and structural patterns of temporal graphs. We explore a new direction in that we can capture the evolving dynamics of temporal graphs with spiking neural networks (SNNs) instead of RNNs. As a low-power alternative to RNNs, SNNs explicitly model graph dynamics as spike trains of neuron populations and enable spike-based propagation in an efficient way. Experiments on three large real-world temporal graph datasets ",
    "link": "http://arxiv.org/abs/2208.10364",
    "context": "Title: Scaling Up Dynamic Graph Representation Learning via Spiking Neural Networks. (arXiv:2208.10364v3 [cs.NE] UPDATED)\nAbstract: Recent years have seen a surge in research on dynamic graph representation learning, which aims to model temporal graphs that are dynamic and evolving constantly over time. However, current work typically models graph dynamics with recurrent neural networks (RNNs), making them suffer seriously from computation and memory overheads on large temporal graphs. So far, scalability of dynamic graph representation learning on large temporal graphs remains one of the major challenges. In this paper, we present a scalable framework, namely SpikeNet, to efficiently capture the temporal and structural patterns of temporal graphs. We explore a new direction in that we can capture the evolving dynamics of temporal graphs with spiking neural networks (SNNs) instead of RNNs. As a low-power alternative to RNNs, SNNs explicitly model graph dynamics as spike trains of neuron populations and enable spike-based propagation in an efficient way. Experiments on three large real-world temporal graph datasets ",
    "path": "papers/22/08/2208.10364.json",
    "total_tokens": 917,
    "tldr": "本文提出了SpikeNet框架，用脉冲神经网络代替循环神经网络，有效的捕获大型时态图形的动态演变.",
    "en_tdlr": "This paper proposes a scalable framework SpikeNet to capture the temporal and structural patterns of temporal graphs by using spiking neural networks (SNNs) instead of recurrent neural networks (RNNs). It achieves a low-power alternative to RNNs and enables spike-based propagation in an efficient way."
}