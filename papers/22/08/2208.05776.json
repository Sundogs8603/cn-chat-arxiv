{
    "title": "Neural Networks for Scalar Input and Functional Output. (arXiv:2208.05776v2 [stat.ML] UPDATED)",
    "abstract": "The regression of a functional response on a set of scalar predictors can be a challenging task, especially if there is a large number of predictors, or the relationship between those predictors and the response is nonlinear. In this work, we propose a solution to this problem: a feed-forward neural network (NN) designed to predict a functional response using scalar inputs. First, we transform the functional response to a finite-dimensional representation and construct an NN that outputs this representation. Then, we propose to modify the output of an NN via the objective function and introduce different objective functions for network training. The proposed models are suited for both regularly and irregularly spaced data, and a roughness penalty can be further applied to control the smoothness of the predicted curve. The difficulty in implementing both those features lies in the definition of objective functions that can be back-propagated. In our experiments, we demonstrate that our ",
    "link": "http://arxiv.org/abs/2208.05776",
    "context": "Title: Neural Networks for Scalar Input and Functional Output. (arXiv:2208.05776v2 [stat.ML] UPDATED)\nAbstract: The regression of a functional response on a set of scalar predictors can be a challenging task, especially if there is a large number of predictors, or the relationship between those predictors and the response is nonlinear. In this work, we propose a solution to this problem: a feed-forward neural network (NN) designed to predict a functional response using scalar inputs. First, we transform the functional response to a finite-dimensional representation and construct an NN that outputs this representation. Then, we propose to modify the output of an NN via the objective function and introduce different objective functions for network training. The proposed models are suited for both regularly and irregularly spaced data, and a roughness penalty can be further applied to control the smoothness of the predicted curve. The difficulty in implementing both those features lies in the definition of objective functions that can be back-propagated. In our experiments, we demonstrate that our ",
    "path": "papers/22/08/2208.05776.json",
    "total_tokens": 887,
    "translated_title": "标量输入和函数输出的神经网络",
    "translated_abstract": "在一组标量预测变量上回归函数响应可以是一项具有挑战性的任务，特别是当有大量预测变量或者预测变量与响应之间的关系是非线性的时候。在这项工作中，我们提出了一个解决方案：使用前馈神经网络（NN）预测标量输入下的函数响应。首先，我们将函数响应转化为有限维度表示，并构建一个输出该表示的神经网络。然后，我们提出通过目标函数修改神经网络的输出，并引入不同的目标函数来进行网络训练。所提出的模型适用于均匀和不均匀间隔的数据，并可以进一步应用平滑惩罚项来控制预测曲线的平滑程度。实现这些特性的困难在于定义可以进行反向传播的目标函数。在我们的实验中，我们展示了我们的方法在多个数据集上的有效性。",
    "tldr": "该论文提出了一种解决标量输入和函数输出之间回归问题的方法，使用前馈神经网络预测函数响应。该方法适用于大量预测变量或非线性关系，并可以控制预测曲线的平滑程度。在实验中验证了方法的有效性。",
    "en_tdlr": "This paper proposes a method to solve the regression problem between scalar inputs and functional outputs using a feed-forward neural network. The method is applicable to scenarios with a large number of predictors or non-linear relationships, and allows for control of the smoothness of the predicted curve. Experimental results demonstrate the effectiveness of the proposed approach."
}