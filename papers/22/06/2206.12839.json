{
    "title": "Repository-Level Prompt Generation for Large Language Models of Code. (arXiv:2206.12839v3 [cs.LG] UPDATED)",
    "abstract": "With the success of large language models (LLMs) of code and their use as code assistants (e.g. Codex used in GitHub Copilot), techniques for introducing domain-specific knowledge in the prompt design process become important. In this work, we propose a framework called Repo-Level Prompt Generator that learns to generate example-specific prompts using prompt proposals. The prompt proposals take context from the entire repository, thereby incorporating both the structure of the repository and the context from other relevant files (e.g. imports, parent class files). Our technique doesn't require any access to the weights of the LLM, making it applicable in cases where we only have black-box access to the LLM. We conduct experiments on the task of single-line code-autocompletion using code repositories taken from Google Code archives. We demonstrate that an oracle constructed from our prompt proposals gives a remarkably high relative improvement of 36% over Codex, showing the quality of t",
    "link": "http://arxiv.org/abs/2206.12839",
    "context": "Title: Repository-Level Prompt Generation for Large Language Models of Code. (arXiv:2206.12839v3 [cs.LG] UPDATED)\nAbstract: With the success of large language models (LLMs) of code and their use as code assistants (e.g. Codex used in GitHub Copilot), techniques for introducing domain-specific knowledge in the prompt design process become important. In this work, we propose a framework called Repo-Level Prompt Generator that learns to generate example-specific prompts using prompt proposals. The prompt proposals take context from the entire repository, thereby incorporating both the structure of the repository and the context from other relevant files (e.g. imports, parent class files). Our technique doesn't require any access to the weights of the LLM, making it applicable in cases where we only have black-box access to the LLM. We conduct experiments on the task of single-line code-autocompletion using code repositories taken from Google Code archives. We demonstrate that an oracle constructed from our prompt proposals gives a remarkably high relative improvement of 36% over Codex, showing the quality of t",
    "path": "papers/22/06/2206.12839.json",
    "total_tokens": 873,
    "translated_abstract": "随着大型代码语言模型（LLM）的成功和它们作为代码助手（例如在GitHub Copilot中使用的Codex）的使用，引入领域特定知识的提示设计过程的技术变得重要。在本文中，我们提出了一个名为Repo-Level Prompt Generator的框架，它可以使用提示提议来学习生成针对示例特定的提示。提示提议从整个代码仓库中获取上下文，从而将仓库的结构和来自其他相关文件（例如导入，父类文件）的上下文结合起来。我们的技术不需要访问LLM的权重，因此适用于只有黑盒访问LLM的情况。我们在从Google Code存档中取出的代码存储库上进行单行代码自动完成任务的实验。我们证明了从我们的提示提案构建的oracle相对于Codex显著提高了36％的相对改进，说明了技术的质量。",
    "tldr": "本文提出了一个名为Repo-Level Prompt Generator的框架，它可以根据整个代码仓库的上下文生成示例特定的提示，从而进一步提高代码助手的性能。",
    "en_tdlr": "This paper proposes a framework, named Repo-Level Prompt Generator, to generate example-specific prompts based on the context from the entire code repository, without accessing the weights of the large language models (LLMs). It significantly improves the performance of the code assistant by 36% relative to Codex on the task of single-line code-autocompletion."
}