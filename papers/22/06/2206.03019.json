{
    "title": "The Survival Bandit Problem. (arXiv:2206.03019v4 [cs.LG] UPDATED)",
    "abstract": "We introduce and study a new variant of the multi-armed bandit problem (MAB), called the survival bandit problem (S-MAB). While in both problems, the objective is to maximize the so-called cumulative reward, in this new variant, the procedure is interrupted if the cumulative reward falls below a preset threshold. This simple yet unexplored extension of the MAB follows from many practical applications. For example, when testing two medicines against each other on voluntary patients, people's health are at stake, and it is necessary to be able to interrupt experiments if serious side effects occur or if the disease syndromes are not dissipated by the treatment. From a theoretical perspective, the S-MAB is the first variant of the MAB where the procedure may or may not be interrupted. We start by formalizing the S-MAB and we define its objective as the minimization of the so-called survival regret, which naturally generalizes the regret of the MAB. Then, we show that the objective of the ",
    "link": "http://arxiv.org/abs/2206.03019",
    "context": "Title: The Survival Bandit Problem. (arXiv:2206.03019v4 [cs.LG] UPDATED)\nAbstract: We introduce and study a new variant of the multi-armed bandit problem (MAB), called the survival bandit problem (S-MAB). While in both problems, the objective is to maximize the so-called cumulative reward, in this new variant, the procedure is interrupted if the cumulative reward falls below a preset threshold. This simple yet unexplored extension of the MAB follows from many practical applications. For example, when testing two medicines against each other on voluntary patients, people's health are at stake, and it is necessary to be able to interrupt experiments if serious side effects occur or if the disease syndromes are not dissipated by the treatment. From a theoretical perspective, the S-MAB is the first variant of the MAB where the procedure may or may not be interrupted. We start by formalizing the S-MAB and we define its objective as the minimization of the so-called survival regret, which naturally generalizes the regret of the MAB. Then, we show that the objective of the ",
    "path": "papers/22/06/2206.03019.json",
    "total_tokens": 907,
    "translated_title": "生存强盗问题",
    "translated_abstract": "我们介绍并研究了多臂赌博机问题(MAB)的一个新变种，称为生存强盗问题(S-MAB)。虽然在这两个问题中，目标都是最大化所谓的累积奖励，但在这个新的变种中，如果累积奖励低于预设的阈值，程序将被中断。这个简单但未被探讨的MAB扩展源自许多实际应用。例如，当对自愿患者进行两种药物的测试时，人们的健康问题至关重要，如果出现严重副作用或者疾病综合症没有得到治疗，有必要能够中断实验。从理论的角度来看，S-MAB是第一种可能中断或不中断的MAB变种。我们首先对S-MAB进行形式化，将其目标定义为所谓的生存遗憾的最小化，自然推广了MAB的遗憾。然后，我们证明了同时最小化生存遗憾和加速收敛的适用于S-MAB的算法存在。",
    "tldr": "这个研究介绍了生存强盗问题，这是多臂赌博机问题的一个新变种。该问题的目标是最小化生存遗憾，同时要求算法加速收敛。",
    "en_tdlr": "This research introduces the survival bandit problem, a new variant of the multi-armed bandit problem. The objective of this problem is to minimize the survival regret while also achieving accelerated convergence in the algorithm."
}