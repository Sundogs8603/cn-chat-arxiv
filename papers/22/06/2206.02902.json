{
    "title": "Goal-Space Planning with Subgoal Models",
    "abstract": "arXiv:2206.02902v5 Announce Type: replace-cross  Abstract: This paper investigates a new approach to model-based reinforcement learning using background planning: mixing (approximate) dynamic programming updates and model-free updates, similar to the Dyna architecture. Background planning with learned models is often worse than model-free alternatives, such as Double DQN, even though the former uses significantly more memory and computation. The fundamental problem is that learned models can be inaccurate and often generate invalid states, especially when iterated many steps. In this paper, we avoid this limitation by constraining background planning to a set of (abstract) subgoals and learning only local, subgoal-conditioned models. This goal-space planning (GSP) approach is more computationally efficient, naturally incorporates temporal abstraction for faster long-horizon planning and avoids learning the transition dynamics entirely. We show that our GSP algorithm can propagate value",
    "link": "https://arxiv.org/abs/2206.02902",
    "context": "Title: Goal-Space Planning with Subgoal Models\nAbstract: arXiv:2206.02902v5 Announce Type: replace-cross  Abstract: This paper investigates a new approach to model-based reinforcement learning using background planning: mixing (approximate) dynamic programming updates and model-free updates, similar to the Dyna architecture. Background planning with learned models is often worse than model-free alternatives, such as Double DQN, even though the former uses significantly more memory and computation. The fundamental problem is that learned models can be inaccurate and often generate invalid states, especially when iterated many steps. In this paper, we avoid this limitation by constraining background planning to a set of (abstract) subgoals and learning only local, subgoal-conditioned models. This goal-space planning (GSP) approach is more computationally efficient, naturally incorporates temporal abstraction for faster long-horizon planning and avoids learning the transition dynamics entirely. We show that our GSP algorithm can propagate value",
    "path": "papers/22/06/2206.02902.json",
    "total_tokens": 873,
    "translated_title": "具有子目标模型的目标空间规划",
    "translated_abstract": "本文研究了一种新的基于模型的强化学习方法，使用背景规划：混合（近似的）动态规划更新和模型无关的更新，类似于Dyna架构。利用学习的模型进行背景规划通常比模型无关的替代方法（如Double DQN）更差，尽管前者使用了显著更多的内存和计算资源。根本问题在于，学习的模型可能不准确，并且在迭代多个步骤时通常会产生无效状态。在本文中，我们通过将背景规划限制在一组（抽象的）子目标，并仅学习本地、子目标条件的模型来避免这种限制。这种目标空间规划（GSP）方法更具计算效率，自然地结合了用于更快长时程规划的时间抽象，并完全避免了学习转换动力学。我们展示了我们的GSP算法可以传播价值",
    "tldr": "通过在一组（抽象的）子目标上进行约束和学习本地、子目标条件的模型，本文提出的目标空间规划（GSP）方法更具计算效率，自然地结合了时间抽象，避免了学习转换动力学。",
    "en_tdlr": "The goal-space planning (GSP) approach proposed in this paper is more computationally efficient by constraining and learning local, subgoal-conditioned models on a set of (abstract) subgoals, naturally incorporating temporal abstraction and avoiding learning the transition dynamics entirely."
}