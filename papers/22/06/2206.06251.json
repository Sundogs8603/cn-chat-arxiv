{
    "title": "A Methodology and Software Architecture to Support Explainability-by-Design. (arXiv:2206.06251v2 [cs.SE] UPDATED)",
    "abstract": "Algorithms play a crucial role in many technological systems that control or affect various aspects of our lives. As a result, providing explanations for their decisions to address the needs of users and organisations is increasingly expected by laws, regulations, codes of conduct, and the public. However, as laws and regulations do not prescribe how to meet such expectations, organisations are often left to devise their own approaches to explainability, inevitably increasing the cost of compliance and good governance. Hence, we envision Explainability-by-Design, a holistic methodology characterised by proactive measures to include explanation capability in the design of decision-making systems. The methodology consists of three phases: (A) Explanation Requirement Analysis, (B) Explanation Technical Design, and (C) Explanation Validation. This paper describes phase (B), a technical workflow to implement explanation capability from requirements elicited by domain experts for a specific ",
    "link": "http://arxiv.org/abs/2206.06251",
    "context": "Title: A Methodology and Software Architecture to Support Explainability-by-Design. (arXiv:2206.06251v2 [cs.SE] UPDATED)\nAbstract: Algorithms play a crucial role in many technological systems that control or affect various aspects of our lives. As a result, providing explanations for their decisions to address the needs of users and organisations is increasingly expected by laws, regulations, codes of conduct, and the public. However, as laws and regulations do not prescribe how to meet such expectations, organisations are often left to devise their own approaches to explainability, inevitably increasing the cost of compliance and good governance. Hence, we envision Explainability-by-Design, a holistic methodology characterised by proactive measures to include explanation capability in the design of decision-making systems. The methodology consists of three phases: (A) Explanation Requirement Analysis, (B) Explanation Technical Design, and (C) Explanation Validation. This paper describes phase (B), a technical workflow to implement explanation capability from requirements elicited by domain experts for a specific ",
    "path": "papers/22/06/2206.06251.json",
    "total_tokens": 880,
    "translated_title": "支持“可解释设计”的方法论和软件架构",
    "translated_abstract": "算法在控制或影响我们生活的许多技术系统中扮演着至关重要的角色。因此，为了满足用户和组织的需求，根据法律、规定、道德准则以及公众的期望提供算法决策的解释越来越受到关注。然而，由于法律和规定并未规定如何满足这些期望，因此组织通常需要自行制定解释方法，从而增加了合规成本和良好管理的成本。因此，本文提出了“可解释设计”方法论，这是一种综合性方法，采用积极的措施，在决策系统的设计中包括解释能力。该方法论由三个阶段组成：（A）解释需求分析，（B）解释技术设计，（C）解释验证。本文描述了第二阶段（B），即根据领域专家提出的需求实现解释能力的技术工作流程。",
    "tldr": "本文提出了“可解释设计”方法论，针对算法决策的解释提出了一个综合性的解决方案，由三个阶段组成：（A）解释需求分析，（B）解释技术设计，（C）解释验证。",
    "en_tdlr": "This paper proposes the Explainability-by-Design methodology, which provides a comprehensive solution for explaining algorithm decisions with three phases: (A) Explanation Requirement Analysis, (B) Explanation Technical Design, and (C) Explanation Validation."
}