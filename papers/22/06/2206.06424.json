{
    "title": "Look, Radiate, and Learn: Self-Supervised Localisation via Radio-Visual Correspondence. (arXiv:2206.06424v4 [cs.LG] UPDATED)",
    "abstract": "Next generation cellular networks will implement radio sensing functions alongside customary communications, thereby enabling unprecedented worldwide sensing coverage outdoors. Deep learning has revolutionised computer vision but has had limited application to radio perception tasks, in part due to lack of systematic datasets and benchmarks dedicated to the study of the performance and promise of radio sensing. To address this gap, we present MaxRay: a synthetic radio-visual dataset and benchmark that facilitate precise target localisation in radio. We further propose to learn to localise targets in radio without supervision by extracting self-coordinates from radio-visual correspondence. We use such self-supervised coordinates to train a radio localiser network. We characterise our performance against a number of state-of-the-art baselines. Our results indicate that accurate radio target localisation can be automatically learned from paired radio-visual data without labels, which is i",
    "link": "http://arxiv.org/abs/2206.06424",
    "context": "Title: Look, Radiate, and Learn: Self-Supervised Localisation via Radio-Visual Correspondence. (arXiv:2206.06424v4 [cs.LG] UPDATED)\nAbstract: Next generation cellular networks will implement radio sensing functions alongside customary communications, thereby enabling unprecedented worldwide sensing coverage outdoors. Deep learning has revolutionised computer vision but has had limited application to radio perception tasks, in part due to lack of systematic datasets and benchmarks dedicated to the study of the performance and promise of radio sensing. To address this gap, we present MaxRay: a synthetic radio-visual dataset and benchmark that facilitate precise target localisation in radio. We further propose to learn to localise targets in radio without supervision by extracting self-coordinates from radio-visual correspondence. We use such self-supervised coordinates to train a radio localiser network. We characterise our performance against a number of state-of-the-art baselines. Our results indicate that accurate radio target localisation can be automatically learned from paired radio-visual data without labels, which is i",
    "path": "papers/22/06/2206.06424.json",
    "total_tokens": 917,
    "translated_title": "看、辐射和学习：基于无监督的无线电-视觉对应的自助定位",
    "translated_abstract": "下一代移动通信网络将在惯常通信的基础上实现射频感知功能，从而使室外的感知范围空前。深度学习已经彻底改变了计算机视觉，但对于无线电感知任务的应用还受到限制，部分原因是缺乏系统性的数据集和基准以研究无线电感知的性能和前景。为了填补这一空白，我们提出了MaxRay：一个合成的无线电-视觉数据集和基准，有助于精确的无线电目标定位。我们进一步提出通过从无线电-视觉对应中提取自坐标来学习无线电目标的无监督定位。我们使用这种自助定位的坐标来训练一个无线电定位器网络，并与许多最先进的基准进行性能比较。我们的结果表明，通过配对的无线电-视觉数据，可以无需标签来自动学习准确的无线电目标定位。",
    "tldr": "本文提出了一个合成的无线电-视觉数据集和基准(MaxRay)，通过从无线电-视觉对应中提取自坐标来自主学习目标在无线电中的定位，最终实现了无需标签的准确无线电目标定位。",
    "en_tdlr": "This paper proposes a synthetic radio-visual dataset and benchmark (MaxRay) for precise target localization in radio, and presents a self-supervised approach to learn to localize targets in radio via extracting self-coordinates from radio-visual correspondence, achieving accurate radio target localization without labels."
}