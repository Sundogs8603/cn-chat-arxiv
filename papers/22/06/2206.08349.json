{
    "title": "Know your audience: specializing grounded language models with listener subtraction. (arXiv:2206.08349v2 [cs.LG] UPDATED)",
    "abstract": "Effective communication requires adapting to the idiosyncrasies of each communicative context--such as the common ground shared with each partner. Humans demonstrate this ability to specialize to their audience in many contexts, such as the popular game Dixit. We take inspiration from Dixit to formulate a multi-agent image reference game where a (trained) speaker model is rewarded for describing a target image such that one (pretrained) listener model can correctly identify it among distractors, but another listener cannot. To adapt, the speaker must exploit differences in the knowledge it shares with the different listeners. We show that finetuning an attention-based adapter between a CLIP vision encoder and a large language model in this contrastive, multi-agent setting gives rise to context-dependent natural language specialization from rewards only, without direct supervision. Through controlled experiments, we show that training a speaker with two listeners that perceive different",
    "link": "http://arxiv.org/abs/2206.08349",
    "context": "Title: Know your audience: specializing grounded language models with listener subtraction. (arXiv:2206.08349v2 [cs.LG] UPDATED)\nAbstract: Effective communication requires adapting to the idiosyncrasies of each communicative context--such as the common ground shared with each partner. Humans demonstrate this ability to specialize to their audience in many contexts, such as the popular game Dixit. We take inspiration from Dixit to formulate a multi-agent image reference game where a (trained) speaker model is rewarded for describing a target image such that one (pretrained) listener model can correctly identify it among distractors, but another listener cannot. To adapt, the speaker must exploit differences in the knowledge it shares with the different listeners. We show that finetuning an attention-based adapter between a CLIP vision encoder and a large language model in this contrastive, multi-agent setting gives rise to context-dependent natural language specialization from rewards only, without direct supervision. Through controlled experiments, we show that training a speaker with two listeners that perceive different",
    "path": "papers/22/06/2206.08349.json",
    "total_tokens": 1109,
    "translated_title": "了解你的听众：用听众减法专门化基于上下文的语言模型",
    "translated_abstract": "有效的沟通需要适应每个交际情境的特殊性，比如与每个交互伙伴分享的共同语境。本研究通过借鉴对话游戏 Dixit 的思想设计了一个多智能体图像参照游戏，训练一个说话者模型来描述一个目标图像，使得一个听者能够在干扰项中正确地识别出目标图像，而另一个听者则不能。这要求说话者利用它与不同听者的共同知识差异进行适应。本研究还展示了在这种对比、多智能体的语境下微调 CLIP 视觉编码器和大型语言模型之间的注意力适配器会自然地产生上下文依赖的自然语言专业化，且只需要通过奖励而无需直接监督来实现。通过控制实验，本研究证明了用两个听者来训练说话者的有效性。",
    "tldr": "本文介绍了一种利用多智能体图像参照游戏自适应不同听众的目标任务描述的方法，并通过微调 CLIP 视觉编码器和大型语言模型之间的适配器，在适应听众的语言上下文的情况下进行了自然语言专业化。",
    "en_tdlr": "This paper proposes a method for adapting target task descriptions to different listeners using a multi-agent image reference game, inspired by the game Dixit. By fine-tuning an attention-based adapter between CLIP vision encoder and a large language model, the paper shows how to achieve context-dependent natural language specialization through rewards only. Experimental results demonstrate the effectiveness of training a speaker with two listeners who perceive different language contexts."
}