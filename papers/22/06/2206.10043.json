{
    "title": "Classification Utility, Fairness, and Compactness via Tunable Information Bottleneck and R\\'enyi Measures. (arXiv:2206.10043v2 [cs.LG] UPDATED)",
    "abstract": "Designing machine learning algorithms that are accurate yet fair, not discriminating based on any sensitive attribute, is of paramount importance for society to accept AI for critical applications. In this article, we propose a novel fair representation learning method termed the R\\'enyi Fair Information Bottleneck Method (RFIB) which incorporates constraints for utility, fairness, and compactness (compression) of representation, and apply it to image and tabular data classification. A key attribute of our approach is that we consider - in contrast to most prior work - both demographic parity and equalized odds as fairness constraints, allowing for a more nuanced satisfaction of both criteria. Leveraging a variational approach, we show that our objectives yield a loss function involving classical Information Bottleneck (IB) measures and establish an upper bound in terms of two R\\'enyi measures of order $\\alpha$ on the mutual information IB term measuring compactness between the input a",
    "link": "http://arxiv.org/abs/2206.10043",
    "context": "Title: Classification Utility, Fairness, and Compactness via Tunable Information Bottleneck and R\\'enyi Measures. (arXiv:2206.10043v2 [cs.LG] UPDATED)\nAbstract: Designing machine learning algorithms that are accurate yet fair, not discriminating based on any sensitive attribute, is of paramount importance for society to accept AI for critical applications. In this article, we propose a novel fair representation learning method termed the R\\'enyi Fair Information Bottleneck Method (RFIB) which incorporates constraints for utility, fairness, and compactness (compression) of representation, and apply it to image and tabular data classification. A key attribute of our approach is that we consider - in contrast to most prior work - both demographic parity and equalized odds as fairness constraints, allowing for a more nuanced satisfaction of both criteria. Leveraging a variational approach, we show that our objectives yield a loss function involving classical Information Bottleneck (IB) measures and establish an upper bound in terms of two R\\'enyi measures of order $\\alpha$ on the mutual information IB term measuring compactness between the input a",
    "path": "papers/22/06/2206.10043.json",
    "total_tokens": 1327,
    "translated_title": "可调信息瓶颈和Rényi度量通过分类效用、公平性和紧凑性",
    "translated_abstract": "在机器学习中，设计可以准确获取信息而不歧视任何敏感属性的算法对于社会接受AI用于关键应用场景至关重要。本文提出了一种新型公平表示学习方法，称为Rényi公平信息瓶颈方法(RFIB)，它兼顾了表示的效用、公平性和紧凑性，并将其应用于图像和表格数据分类中。与以往的工作相比，我们的方法考虑到了人口平等和等化赔率等不同的公平性约束，使得满足这两个准则更加精细。利用变分方法，我们证明了我们的目标可以产生一个损失函数，其中涉及了经典信息瓶颈(IB)度量，并在两个Rényi$(\\alpha)$度量中建立了一个上界，用于衡量输入和表示之间的紧凑度。实验表明，我们的方法在实现公平性的同时，也取得了有竞争力的准确性。",
    "tldr": "本文提出了一种新型公平表示学习方法(RFIB)，兼顾了表示效用、公平性和紧凑性，并将其应用于图像和表格数据分类中。该方法考虑到了人口平等和等化赔率等不同的公平性约束，通过涉及经典信息瓶颈(IB)度量的损失函数实现。实验表明，该方法能够在实现公平性的同时保持较高的准确性。",
    "en_tdlr": "This paper proposes a novel fair representation learning method, the Rényi Fair Information Bottleneck Method (RFIB), which incorporates constraints for utility, fairness, and compactness of representation, and applies it to image and tabular data classification. The proposed method considers both demographic parity and equalized odds as fairness constraints, allowing for a more nuanced satisfaction of both criteria. The loss function involves classical Information Bottleneck (IB) measures and establishes an upper bound in terms of two Renyi measures of order α on the mutual information IB term measuring compactness. Experiments show that the proposed method outperforms state-of-the-art methods in terms of fairness while achieving competitive accuracy."
}