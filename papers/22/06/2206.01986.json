{
    "title": "Delving into the Openness of CLIP. (arXiv:2206.01986v3 [cs.CV] UPDATED)",
    "abstract": "Contrastive Language-Image Pre-training (CLIP) formulates image classification as an image-to-text matching task, i.e., matching images to the corresponding natural language descriptions instead of discrete category IDs. This allows for open-vocabulary visual recognition, where the model can recognize images from an open class set (also known as an open vocabulary) in a zero-shot manner. However, evaluating the openness of CLIP-like models is challenging, as the models are open to arbitrary vocabulary in theory, but their accuracy varies in practice. To address this, we resort to an incremental perspective to assess the openness through vocabulary expansions, and define extensibility to measure a model's ability to handle novel classes. Our evaluation shows that CLIP-like models are not truly open, and their performance deteriorates as the vocabulary expands. We further dissect the feature space of CLIP from the perspectives of representation alignment and uniformity. Our investigation",
    "link": "http://arxiv.org/abs/2206.01986",
    "context": "Title: Delving into the Openness of CLIP. (arXiv:2206.01986v3 [cs.CV] UPDATED)\nAbstract: Contrastive Language-Image Pre-training (CLIP) formulates image classification as an image-to-text matching task, i.e., matching images to the corresponding natural language descriptions instead of discrete category IDs. This allows for open-vocabulary visual recognition, where the model can recognize images from an open class set (also known as an open vocabulary) in a zero-shot manner. However, evaluating the openness of CLIP-like models is challenging, as the models are open to arbitrary vocabulary in theory, but their accuracy varies in practice. To address this, we resort to an incremental perspective to assess the openness through vocabulary expansions, and define extensibility to measure a model's ability to handle novel classes. Our evaluation shows that CLIP-like models are not truly open, and their performance deteriorates as the vocabulary expands. We further dissect the feature space of CLIP from the perspectives of representation alignment and uniformity. Our investigation",
    "path": "papers/22/06/2206.01986.json",
    "total_tokens": 1021,
    "translated_title": "探究CLIP的开放性",
    "translated_abstract": "对比语言-图像预训练（CLIP）将图像分类作为一项图像到文本匹配任务，即将图像与相应的自然语言描述进行匹配，而不是离散的类别ID。这使得模型可以以零-shot方式从开放类集（也称为开放词汇表）中识别图像。然而，评估类似于CLIP的模型的开放性很具有挑战性，因为这些模型理论上对任意词汇开放，但在实践中其精度有所变化。为解决这个问题，我们采用了递增的视角通过词汇扩展来评估开放性，并定义了可扩展性来衡量模型处理新类的能力。我们的评估结果表明，类似于CLIP的模型并不真正开放，并且随着词汇表的扩展其性能会恶化。我们进一步从表示对齐和统一性的角度剖析了CLIP的特征空间。我们的研究揭示CLIP表示在不监督的预训练中在不变性和特定性之间存在权衡，通过微调可提高其特定性。",
    "tldr": "本研究探究了CLIP模型的开放性，并通过词汇扩展来评估模型的可扩展性。研究发现，类似于CLIP的模型并不真正开放，并且随着词汇表的扩展其性能会恶化。此外，研究还揭示了CLIP表示在不变性和特定性之间存在权衡。",
    "en_tdlr": "This research explores the openness of CLIP models and evaluates their extensibility through vocabulary expansions. The study finds that CLIP-like models are not truly open and deteriorate in performance as the vocabulary expands. Additionally, the investigation discovers a trade-off between invariance and specificity in CLIP representations."
}