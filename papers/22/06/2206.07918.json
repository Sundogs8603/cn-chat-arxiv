{
    "title": "\"Understanding Robustness Lottery\": A Geometric Visual Comparative Analysis of Neural Network Pruning Approaches. (arXiv:2206.07918v2 [cs.HC] UPDATED)",
    "abstract": "Deep learning approaches have provided state-of-the-art performance in many applications by relying on large and overparameterized neural networks. However, such networks have been shown to be very brittle and are difficult to deploy on resource-limited platforms. Model pruning, i.e., reducing the size of the network, is a widely adopted strategy that can lead to a more robust and compact model. Many heuristics exist for model pruning, but empirical studies show that some heuristics improve performance whereas others can make models more brittle or have other side effects. This work aims to shed light on how different pruning methods alter the network's internal feature representation and the corresponding impact on model performance. To facilitate a comprehensive comparison and characterization of the high-dimensional model feature space, we introduce a visual geometric analysis of feature representations. We decomposed and evaluated a set of critical geometric concepts from the commo",
    "link": "http://arxiv.org/abs/2206.07918",
    "context": "Title: \"Understanding Robustness Lottery\": A Geometric Visual Comparative Analysis of Neural Network Pruning Approaches. (arXiv:2206.07918v2 [cs.HC] UPDATED)\nAbstract: Deep learning approaches have provided state-of-the-art performance in many applications by relying on large and overparameterized neural networks. However, such networks have been shown to be very brittle and are difficult to deploy on resource-limited platforms. Model pruning, i.e., reducing the size of the network, is a widely adopted strategy that can lead to a more robust and compact model. Many heuristics exist for model pruning, but empirical studies show that some heuristics improve performance whereas others can make models more brittle or have other side effects. This work aims to shed light on how different pruning methods alter the network's internal feature representation and the corresponding impact on model performance. To facilitate a comprehensive comparison and characterization of the high-dimensional model feature space, we introduce a visual geometric analysis of feature representations. We decomposed and evaluated a set of critical geometric concepts from the commo",
    "path": "papers/22/06/2206.07918.json",
    "total_tokens": 868,
    "translated_title": "\"理解鲁棒性之彩票\": 神经网络剪枝方法的几何可视化比较分析",
    "translated_abstract": "通过依赖大而过参数化的神经网络，深度学习方法在许多应用中提供了最先进的性能。然而，这样的网络被证明非常脆弱，难以部署在资源有限的平台上。模型剪枝，即减小网络的规模，是一种广泛采用的策略，可以产生更强韧和紧凑的模型。存在许多模型剪枝的启发式方法，但实证研究表明，某些启发式方法可以改善性能，而其他方法可能使模型更加脆弱或产生其他副作用。本研究旨在揭示不同剪枝方法如何改变网络的内部特征表示以及对模型性能的相应影响。为了便于全面比较和描述高维模型特征空间，我们引入了一种基于可视化几何分析的特征表示方法。我们对常见的几何概念进行了分解和评估。",
    "tldr": "本研究通过几何可视化分析，比较了不同神经网络剪枝方法对网络内部特征表示的影响，并对模型性能进行了评估。",
    "en_tdlr": "This research provides a comprehensive comparison and evaluation of the impact of different neural network pruning methods on the internal feature representation and model performance through geometric visual analysis."
}