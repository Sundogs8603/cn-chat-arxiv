{
    "title": "Exploiting Cross-domain And Cross-Lingual Ultrasound Tongue Imaging Features For Elderly And Dysarthric Speech Recognition. (arXiv:2206.07327v3 [eess.AS] UPDATED)",
    "abstract": "Articulatory features are inherently invariant to acoustic signal distortion and have been successfully incorporated into automatic speech recognition (ASR) systems designed for normal speech. Their practical application to atypical task domains such as elderly and disordered speech across languages is often limited by the difficulty in collecting such specialist data from target speakers. This paper presents a cross-domain and cross-lingual A2A inversion approach that utilizes the parallel audio and ultrasound tongue imaging (UTI) data of the 24-hour TaL corpus in A2A model pre-training before being cross-domain and cross-lingual adapted to three datasets across two languages: the English DementiaBank Pitt and Cantonese JCCOCC MoCA elderly speech corpora; and the English TORGO dysarthric speech data, to produce UTI based articulatory features. Experiments conducted on three tasks suggested incorporating the generated articulatory features consistently outperformed the baseline TDNN an",
    "link": "http://arxiv.org/abs/2206.07327",
    "context": "Title: Exploiting Cross-domain And Cross-Lingual Ultrasound Tongue Imaging Features For Elderly And Dysarthric Speech Recognition. (arXiv:2206.07327v3 [eess.AS] UPDATED)\nAbstract: Articulatory features are inherently invariant to acoustic signal distortion and have been successfully incorporated into automatic speech recognition (ASR) systems designed for normal speech. Their practical application to atypical task domains such as elderly and disordered speech across languages is often limited by the difficulty in collecting such specialist data from target speakers. This paper presents a cross-domain and cross-lingual A2A inversion approach that utilizes the parallel audio and ultrasound tongue imaging (UTI) data of the 24-hour TaL corpus in A2A model pre-training before being cross-domain and cross-lingual adapted to three datasets across two languages: the English DementiaBank Pitt and Cantonese JCCOCC MoCA elderly speech corpora; and the English TORGO dysarthric speech data, to produce UTI based articulatory features. Experiments conducted on three tasks suggested incorporating the generated articulatory features consistently outperformed the baseline TDNN an",
    "path": "papers/22/06/2206.07327.json",
    "total_tokens": 1092,
    "translated_title": "开发跨领域跨语言超声舌头成像特征用于老年人和患有发音障碍者的语音识别",
    "translated_abstract": "发音特征本质上不变形于声学信号失真，并已成功地被整合进了设计用于正常语音的自动语音识别（ASR）系统中。然而，在老年人和患有语音障碍的跨语言非正常任务领域中，这些发音特征的实际应用往往受到从目标说话人收集此类特殊数据的困难所限制。为此，本文提出了一种跨领域和跨语言的A2A反演方法，该方法在模型预训练时利用24小时TaL语料库的平行音频和超声舌头成像（UTI）数据，并在跨领域和跨语言适应到两种语言的三个数据集上：英语DementiaBank Pitt和广东话JCCOCC MoCA的老年人的语音语料库；以及英语TORGO的发音障碍言语数据，从而产生基于UTI的发音特征。实验表明，在三个任务上整合生成的发音特征始终优于基线TDNN和PLP特征ASR系统，在所有数据集上相对误差率（RER）的降低范围为7.2％到36.2％。",
    "tldr": "本文利用跨领域和跨语言的A2A反演方法，利用平行音频和超声舌头成像（UTI）数据来产生基于UTI的发音特征，用于老年人和患有发音障碍者的语音识别研究，实验表明该方法相比基线ASR系统有更好的效果。",
    "en_tdlr": "This paper proposes a cross-domain and cross-lingual A2A inversion approach that utilizes parallel audio and ultrasound tongue imaging data to generate UTI-based articulatory features for elderly and dysarthric speech recognition. Experiments show that incorporating the generated feature consistently outperforms the baseline TDNN and PLP feature-based ASR system, achieving relative error rate reductions ranging from 7.2% to 36.2%."
}