{
    "title": "Learning Instance-Specific Augmentations by Capturing Local Invariances. (arXiv:2206.00051v3 [cs.LG] UPDATED)",
    "abstract": "We introduce InstaAug, a method for automatically learning input-specific augmentations from data. Previous methods for learning augmentations have typically assumed independence between the original input and the transformation applied to that input. This can be highly restrictive, as the invariances we hope our augmentation will capture are themselves often highly input dependent. InstaAug instead introduces a learnable invariance module that maps from inputs to tailored transformation parameters, allowing local invariances to be captured. This can be simultaneously trained alongside the downstream model in a fully end-to-end manner, or separately learned for a pre-trained model. We empirically demonstrate that InstaAug learns meaningful input-dependent augmentations for a wide range of transformation classes, which in turn provides better performance on both supervised and self-supervised tasks.",
    "link": "http://arxiv.org/abs/2206.00051",
    "context": "Title: Learning Instance-Specific Augmentations by Capturing Local Invariances. (arXiv:2206.00051v3 [cs.LG] UPDATED)\nAbstract: We introduce InstaAug, a method for automatically learning input-specific augmentations from data. Previous methods for learning augmentations have typically assumed independence between the original input and the transformation applied to that input. This can be highly restrictive, as the invariances we hope our augmentation will capture are themselves often highly input dependent. InstaAug instead introduces a learnable invariance module that maps from inputs to tailored transformation parameters, allowing local invariances to be captured. This can be simultaneously trained alongside the downstream model in a fully end-to-end manner, or separately learned for a pre-trained model. We empirically demonstrate that InstaAug learns meaningful input-dependent augmentations for a wide range of transformation classes, which in turn provides better performance on both supervised and self-supervised tasks.",
    "path": "papers/22/06/2206.00051.json",
    "total_tokens": 831,
    "translated_title": "捕捉局部不变性的学习实例特定增强方法",
    "translated_abstract": "我们介绍了InstaAug，一种从数据中自动学习特定于输入的增强方法。以往的学习增强方法通常假设原始输入和应用于该输入的变换之间存在独立性。这可能会非常限制，因为我们希望我们的增强捕捉的不变性本身通常高度依赖于输入。InstaAug引入了可学习的不变性模块，从输入中映射到量身定制的变换参数，以捕捉局部不变性。这可以同时与下游模型完全端到端地训练，或者为预训练模型单独学习。我们通过实验证明，InstaAug学习了广泛的变换类别的有意义的输入相关增强，这进而提高了监督和自我监督任务的性能。",
    "tldr": "InstaAug是一种能够自动学习输入特定增强的方法，通过引入可学习的不变性模块从输入中映射到量身定制的变换参数，捕捉局部不变性，从而提高了监督和自我监督任务的性能。",
    "en_tdlr": "InstaAug is a method that can automatically learn input-specific augmentations by introducing a learnable invariance module to capture local invariances. It improves the performance of both supervised and self-supervised tasks by learning meaningful input-dependent augmentations for a wide range of transformation classes."
}