{
    "title": "Dict-TTS: Learning to Pronounce with Prior Dictionary Knowledge for Text-to-Speech. (arXiv:2206.02147v3 [eess.AS] UPDATED)",
    "abstract": "Polyphone disambiguation aims to capture accurate pronunciation knowledge from natural text sequences for reliable Text-to-speech (TTS) systems. However, previous approaches require substantial annotated training data and additional efforts from language experts, making it difficult to extend high-quality neural TTS systems to out-of-domain daily conversations and countless languages worldwide. This paper tackles the polyphone disambiguation problem from a concise and novel perspective: we propose Dict-TTS, a semantic-aware generative text-to-speech model with an online website dictionary (the existing prior information in the natural language). Specifically, we design a semantics-to-pronunciation attention (S2PA) module to match the semantic patterns between the input text sequence and the prior semantics in the dictionary and obtain the corresponding pronunciations; The S2PA module can be easily trained with the end-to-end TTS model without any annotated phoneme labels. Experimental ",
    "link": "http://arxiv.org/abs/2206.02147",
    "context": "Title: Dict-TTS: Learning to Pronounce with Prior Dictionary Knowledge for Text-to-Speech. (arXiv:2206.02147v3 [eess.AS] UPDATED)\nAbstract: Polyphone disambiguation aims to capture accurate pronunciation knowledge from natural text sequences for reliable Text-to-speech (TTS) systems. However, previous approaches require substantial annotated training data and additional efforts from language experts, making it difficult to extend high-quality neural TTS systems to out-of-domain daily conversations and countless languages worldwide. This paper tackles the polyphone disambiguation problem from a concise and novel perspective: we propose Dict-TTS, a semantic-aware generative text-to-speech model with an online website dictionary (the existing prior information in the natural language). Specifically, we design a semantics-to-pronunciation attention (S2PA) module to match the semantic patterns between the input text sequence and the prior semantics in the dictionary and obtain the corresponding pronunciations; The S2PA module can be easily trained with the end-to-end TTS model without any annotated phoneme labels. Experimental ",
    "path": "papers/22/06/2206.02147.json",
    "total_tokens": 984,
    "translated_title": "Dict-TTS: 利用先前的字典知识学习发音以用于文本到语音系统",
    "translated_abstract": "多音字消歧旨在从自然文本序列中获取准确的发音知识，以构建可靠的文本到语音系统。然而，以往的方法需要大量的注释训练数据和语言专家的额外努力，使得难以将高质量的神经网络语音合成系统扩展到日常对话和全球各种语言中。本文从简洁而新颖的角度解决了多音字消歧问题：我们提出了Dict-TTS，这是一个语义感知的生成文本到语音模型，利用在线网站字典（即自然语言中已存在的先前信息）。具体来说，我们设计了一个语义到发音注意力（S2PA）模块，用于匹配输入文本序列与字典中先前语义之间的语义模式，并获取相应的发音；S2PA模块可以轻松地与端到端的语音合成模型一起训练，而无需任何注释的音素标签。",
    "tldr": "本论文提出了Dict-TTS模型，利用在线字典作为先前信息来解决多音字消歧问题。通过设计语义到发音注意力模块，该模型能够在没有注释的情况下自动匹配文本语义和字典中的语义模式，并生成相应的发音，使得高质量的文本到语音系统能够更容易地扩展到不同领域和语言。",
    "en_tdlr": "This paper proposes the Dict-TTS model, which utilizes an online dictionary as prior knowledge to address the problem of polyphone disambiguation. By designing a semantics-to-pronunciation attention module, the model is able to automatically match the semantic patterns between the input text and the dictionary and generate corresponding pronunciations without the need for annotated phoneme labels, making it easier to extend high-quality text-to-speech systems to different domains and languages."
}