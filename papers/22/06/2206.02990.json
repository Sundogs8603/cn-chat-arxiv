{
    "title": "Enhancing Distributional Stability among Sub-populations",
    "abstract": "arXiv:2206.02990v2 Announce Type: replace Abstract: Enhancing the stability of machine learning algorithms under distributional shifts is at the heart of the Out-of-Distribution (OOD) Generalization problem. Derived from causal learning, recent works of invariant learning pursue strict invariance with multiple training environments. Although intuitively reasonable, strong assumptions on the availability and quality of environments are made to learn the strict invariance property. In this work, we come up with the ``distributional stability\" notion to mitigate such limitations. It quantifies the stability of prediction mechanisms among sub-populations down to a prescribed scale. Based on this, we propose the learnability assumption and derive the generalization error bound under distribution shifts. Inspired by theoretical analyses, we propose our novel stable risk minimization (SRM) algorithm to enhance the model's stability w.r.t. shifts in prediction mechanisms ($Y|X$-shifts). Experi",
    "link": "https://arxiv.org/abs/2206.02990",
    "context": "Title: Enhancing Distributional Stability among Sub-populations\nAbstract: arXiv:2206.02990v2 Announce Type: replace Abstract: Enhancing the stability of machine learning algorithms under distributional shifts is at the heart of the Out-of-Distribution (OOD) Generalization problem. Derived from causal learning, recent works of invariant learning pursue strict invariance with multiple training environments. Although intuitively reasonable, strong assumptions on the availability and quality of environments are made to learn the strict invariance property. In this work, we come up with the ``distributional stability\" notion to mitigate such limitations. It quantifies the stability of prediction mechanisms among sub-populations down to a prescribed scale. Based on this, we propose the learnability assumption and derive the generalization error bound under distribution shifts. Inspired by theoretical analyses, we propose our novel stable risk minimization (SRM) algorithm to enhance the model's stability w.r.t. shifts in prediction mechanisms ($Y|X$-shifts). Experi",
    "path": "papers/22/06/2206.02990.json",
    "total_tokens": 949,
    "translated_title": "提高子群体间分布稳定性的方法",
    "translated_abstract": "强调机器学习算法在分布变化条件下的稳定性是解决超出分布（Out-of-Distribution，OOD）泛化问题的关键。从因果学习中衍生出来的不变学习方法追求对于多个训练环境的严格不变性。虽然直观上是合理的，但是要学习严格的不变性性质需要对环境的可用性和质量做出强假设。本研究提出了“分布稳定性”概念来缓解这些限制。它在预测机制的子群体之间的特定尺度上量化了其稳定性。基于此，我们提出了学习假设，并推导了在分布变化下的泛化误差上界。在理论分析的基础上，我们提出了我们的新型稳定风险最小化（SRM）算法，以增强模型在预测机制（$Y|X$-shifts）变化时的稳定性。",
    "tldr": "本文提出了一种称为“分布稳定性”的概念，旨在提高机器学习算法在分布变化条件下的稳定性。通过量化预测机制子群体之间的稳定性，并基于此提出了学习假设和泛化误差上界。通过稳定风险最小化（SRM）算法，我们增强了模型在预测机制变化时的稳定性。",
    "en_tdlr": "This paper proposes the concept of \"distributional stability\" to enhance the stability of machine learning algorithms under distributional shifts. By quantifying the stability of prediction mechanisms among sub-populations and deriving a learnability assumption and generalization error bound, the novel stable risk minimization (SRM) algorithm improves the model's stability in prediction mechanism changes."
}