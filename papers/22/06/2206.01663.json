{
    "title": "Joint Energy Dispatch and Unit Commitment in Microgrids Based on Deep Reinforcement Learning. (arXiv:2206.01663v3 [cs.LG] UPDATED)",
    "abstract": "Nowadays, the application of microgrids (MG) with renewable energy is becoming more and more extensive, which creates a strong need for dynamic energy management. In this paper, deep reinforcement learning (DRL) is applied to learn an optimal policy for making joint energy dispatch (ED) and unit commitment (UC) decisions in an isolated MG, with the aim for reducing the total power generation cost on the premise of ensuring the supply-demand balance. In order to overcome the challenge of discrete-continuous hybrid action space due to joint ED and UC, we propose a DRL algorithm, i.e., the hybrid action finite-horizon DDPG (HAFH-DDPG), that seamlessly integrates two classical DRL algorithms, i.e., deep Q-network (DQN) and deep deterministic policy gradient (DDPG), based on a finite-horizon dynamic programming (DP) framework. Moreover, a diesel generator (DG) selection strategy is presented to support a simplified action space for reducing the computation complexity of this algorithm. Fina",
    "link": "http://arxiv.org/abs/2206.01663",
    "context": "Title: Joint Energy Dispatch and Unit Commitment in Microgrids Based on Deep Reinforcement Learning. (arXiv:2206.01663v3 [cs.LG] UPDATED)\nAbstract: Nowadays, the application of microgrids (MG) with renewable energy is becoming more and more extensive, which creates a strong need for dynamic energy management. In this paper, deep reinforcement learning (DRL) is applied to learn an optimal policy for making joint energy dispatch (ED) and unit commitment (UC) decisions in an isolated MG, with the aim for reducing the total power generation cost on the premise of ensuring the supply-demand balance. In order to overcome the challenge of discrete-continuous hybrid action space due to joint ED and UC, we propose a DRL algorithm, i.e., the hybrid action finite-horizon DDPG (HAFH-DDPG), that seamlessly integrates two classical DRL algorithms, i.e., deep Q-network (DQN) and deep deterministic policy gradient (DDPG), based on a finite-horizon dynamic programming (DP) framework. Moreover, a diesel generator (DG) selection strategy is presented to support a simplified action space for reducing the computation complexity of this algorithm. Fina",
    "path": "papers/22/06/2206.01663.json",
    "total_tokens": 938,
    "translated_title": "基于深度强化学习的微电网联合能量分配和机组开启",
    "translated_abstract": "如今，应用可再生能源的微电网（MG）越来越广泛，这创造了对动态能源管理的强烈需求。本文采用深度强化学习（DRL）来学习隔离式MG中联合能量分配（ED）和机组开启（UC）决策的最优策略，以在确保供需平衡的前提下降低总电力成本。为了克服由于联合ED和UC而导致的离散-连续混合行动空间的挑战，我们提出了一种DRL算法，即混合行动有限地平线DDPG（HAFH-DDPG），它基于有限地平线动态规划（DP）框架，无缝地整合了两种经典DRL算法，即深度Q网络（DQN）和深度确定性策略梯度（DDPG）。此外，提出了一种柴油发电机（DG）选择策略，以支持简化行动空间，以降低此算法的计算复杂度。",
    "tldr": "本文采用深度强化学习算法HAFH-DDPG来学习隔离式微电网中的联合能量分配和机组开启决策问题，并提出了柴油发电机选择策略，以降低计算复杂度。",
    "en_tdlr": "This paper applies the DRL algorithm HAFH-DDPG to learn optimal joint energy dispatch and unit commitment decisions in isolated microgrids with a diesel generator selection strategy to reduce computation complexity."
}