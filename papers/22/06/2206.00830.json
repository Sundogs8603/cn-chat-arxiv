{
    "title": "Progressive Purification for Instance-Dependent Partial Label Learning. (arXiv:2206.00830v2 [cs.LG] UPDATED)",
    "abstract": "Partial label learning (PLL) aims to train multiclass classifiers from the examples each annotated with a set of candidate labels where a fixed but unknown candidate label is correct. In the last few years, the instance-independent generation process of candidate labels has been extensively studied, on the basis of which many theoretical advances have been made in PLL. Nevertheless, the candidate labels are always instance-dependent in practice and there is no theoretical guarantee that the model trained on the instance-dependent PLL examples can converge to an ideal one. In this paper, a theoretically grounded and practically effective approach named POP, i.e. PrOgressive Purification for instance-dependent partial label learning, is proposed. Specifically, POP updates the learning model and purifies each candidate label set progressively in every epoch. Theoretically, we prove that POP enlarges the region appropriately fast where the model is reliable, and eventually approximates the",
    "link": "http://arxiv.org/abs/2206.00830",
    "context": "Title: Progressive Purification for Instance-Dependent Partial Label Learning. (arXiv:2206.00830v2 [cs.LG] UPDATED)\nAbstract: Partial label learning (PLL) aims to train multiclass classifiers from the examples each annotated with a set of candidate labels where a fixed but unknown candidate label is correct. In the last few years, the instance-independent generation process of candidate labels has been extensively studied, on the basis of which many theoretical advances have been made in PLL. Nevertheless, the candidate labels are always instance-dependent in practice and there is no theoretical guarantee that the model trained on the instance-dependent PLL examples can converge to an ideal one. In this paper, a theoretically grounded and practically effective approach named POP, i.e. PrOgressive Purification for instance-dependent partial label learning, is proposed. Specifically, POP updates the learning model and purifies each candidate label set progressively in every epoch. Theoretically, we prove that POP enlarges the region appropriately fast where the model is reliable, and eventually approximates the",
    "path": "papers/22/06/2206.00830.json",
    "total_tokens": 895,
    "translated_title": "实例相关的局部标签学习的渐进式纯化方法",
    "translated_abstract": "局部标签学习（PLL）旨在从每个注释有候选标签集的示例中训练多类分类器，其中一个固定但未知的候选标签是正确的。近几年来，候选标签的无实例独立生成过程已被广泛研究，基于此在PLL方面取得了许多理论进展。然而，实际上候选标签总是与实例相关的，没有理论保证在实例相关的PLL示例上训练的模型能够收敛到理想值。因此，本文提出了一种名为POP的理论上有根据和实际有效的方法，即逐步纯化实例相关的局部标签学习。具体而言，POP在每个时代更新学习模型并逐步净化每个候选标签集。理论上，我们证明了POP在合适的快速速度下扩大模型可靠性的范围，并最终逼近",
    "tldr": "本研究提出了一种叫做POP的方法来解决实例相关的局部标签学习问题，POP在每个时代更新学习模型并逐步净化每个候选标签集，能以特定的快速速度扩大模型可靠性的范围。",
    "en_tdlr": "The paper proposes a method called POP to address the problem of instance-dependent partial label learning, which updates the learning model and purifies each candidate label set progressively in every epoch. Theoretically, POP enlarges the region appropriately fast where the model is reliable, and eventually approximates the ideal value."
}