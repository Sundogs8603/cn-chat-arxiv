{
    "title": "Fair Classification via Domain Adaptation: A Dual Adversarial Learning Approach. (arXiv:2206.03656v2 [cs.LG] UPDATED)",
    "abstract": "Modern machine learning (ML) models are becoming increasingly popular and are widely used in decision-making systems. However, studies have shown critical issues of ML discrimination and unfairness, which hinder their adoption on high-stake applications. Recent research on fair classifiers has drawn significant attention to developing effective algorithms to achieve fairness and good classification performance. Despite the great success of these fairness-aware machine learning models, most of the existing models require sensitive attributes to pre-process the data, regularize the model learning or post-process the prediction to have fair predictions. However, sensitive attributes are often incomplete or even unavailable due to privacy, legal or regulation restrictions. Though we lack the sensitive attribute for training a fair model in the target domain, there might exist a similar domain that has sensitive attributes. Thus, it is important to exploit auxiliary information from a simil",
    "link": "http://arxiv.org/abs/2206.03656",
    "context": "Title: Fair Classification via Domain Adaptation: A Dual Adversarial Learning Approach. (arXiv:2206.03656v2 [cs.LG] UPDATED)\nAbstract: Modern machine learning (ML) models are becoming increasingly popular and are widely used in decision-making systems. However, studies have shown critical issues of ML discrimination and unfairness, which hinder their adoption on high-stake applications. Recent research on fair classifiers has drawn significant attention to developing effective algorithms to achieve fairness and good classification performance. Despite the great success of these fairness-aware machine learning models, most of the existing models require sensitive attributes to pre-process the data, regularize the model learning or post-process the prediction to have fair predictions. However, sensitive attributes are often incomplete or even unavailable due to privacy, legal or regulation restrictions. Though we lack the sensitive attribute for training a fair model in the target domain, there might exist a similar domain that has sensitive attributes. Thus, it is important to exploit auxiliary information from a simil",
    "path": "papers/22/06/2206.03656.json",
    "total_tokens": 855,
    "translated_title": "通过领域适应实现公平分类：一种双重对抗学习方法",
    "translated_abstract": "现代的机器学习模型越来越受欢迎，在决策系统中得到广泛应用。然而，研究表明机器学习歧视和不公的问题十分严重，这些问题阻碍了高风险应用的采用。公平分类器的最近研究引起了人们的广泛关注，旨在开发有效的算法实现公平和良好的分类性能。尽管这些公平感知的机器学习模型取得了极大的成功，但大多数现有模型需要使用敏感属性对数据进行预处理，正则化模型学习或后处理预测，以实现公平预测。然而，由于隐私、法律或监管限制，敏感属性常常是不完整甚至不可用的。虽然我们没有敏感属性来训练目标域的公平模型，但可能存在具有敏感属性的类似域。因此，利用类似域的辅助信息非常重要。",
    "tldr": "通过利用类似域的辅助信息，本论文提出了一种双重对抗学习方法，以实现没有敏感属性的目标域的公平分类。",
    "en_tdlr": "This paper proposes a dual adversarial learning approach to achieve fair classification in a target domain without sensitive attributes, by utilizing auxiliary information from a similar domain."
}