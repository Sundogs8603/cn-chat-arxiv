{
    "title": "Denoised MDPs: Learning World Models Better Than the World Itself. (arXiv:2206.15477v5 [cs.LG] UPDATED)",
    "abstract": "The ability to separate signal from noise, and reason with clean abstractions, is critical to intelligence. With this ability, humans can efficiently perform real world tasks without considering all possible nuisance factors.How can artificial agents do the same? What kind of information can agents safely discard as noises?  In this work, we categorize information out in the wild into four types based on controllability and relation with reward, and formulate useful information as that which is both controllable and reward-relevant. This framework clarifies the kinds information removed by various prior work on representation learning in reinforcement learning (RL), and leads to our proposed approach of learning a Denoised MDP that explicitly factors out certain noise distractors. Extensive experiments on variants of DeepMind Control Suite and RoboDesk demonstrate superior performance of our denoised world model over using raw observations alone, and over prior works, across policy opt",
    "link": "http://arxiv.org/abs/2206.15477",
    "context": "Title: Denoised MDPs: Learning World Models Better Than the World Itself. (arXiv:2206.15477v5 [cs.LG] UPDATED)\nAbstract: The ability to separate signal from noise, and reason with clean abstractions, is critical to intelligence. With this ability, humans can efficiently perform real world tasks without considering all possible nuisance factors.How can artificial agents do the same? What kind of information can agents safely discard as noises?  In this work, we categorize information out in the wild into four types based on controllability and relation with reward, and formulate useful information as that which is both controllable and reward-relevant. This framework clarifies the kinds information removed by various prior work on representation learning in reinforcement learning (RL), and leads to our proposed approach of learning a Denoised MDP that explicitly factors out certain noise distractors. Extensive experiments on variants of DeepMind Control Suite and RoboDesk demonstrate superior performance of our denoised world model over using raw observations alone, and over prior works, across policy opt",
    "path": "papers/22/06/2206.15477.json",
    "total_tokens": 894,
    "translated_title": "消除噪声的MDPs：学习比现实世界本身更好的世界模型",
    "translated_abstract": "分离信号与噪声，并能理性地把握有效信息对于智能至关重要。这使得人类可以高效地完成现实任务而不必考虑所有可能的烦琐因素。那么，人工智能代理如何才能做到这一点？代理可以放弃哪些信息以避免噪声的干扰？本文基于可控性和与奖励的关系将信息分为四类，并将有用信息定义为既可控制又与奖励相关的信息。该框架澄清了各种强化学习（RL）中的表示学习的先前工作删除的信息类型，并导致我们提出了学习消除某些噪声干扰的去噪MDP的方法。在DeepMind控制套件和RoboDesk的各种变体上进行的广泛实验表明，与仅使用原始观测数据以及先前的工作相比，我们的去噪世界模型表现出卓越的性能。",
    "tldr": "本文提出一种新的去噪MDP学习方法，该方法可以将现实数据中的噪声干扰因素去除，学习一个更好的世界模型，实验结果表明该方法在任务上表现更加优秀。",
    "en_tdlr": "This paper proposes a new method for learning denoised MDPs that can remove noise interferences from real-world data to learn a better world model, and the experimental results demonstrate superior performance in tasks."
}