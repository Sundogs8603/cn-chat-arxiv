{
    "title": "Robust Universal Adversarial Perturbations. (arXiv:2206.10858v2 [cs.LG] UPDATED)",
    "abstract": "Universal Adversarial Perturbations (UAPs) are imperceptible, image-agnostic vectors that cause deep neural networks (DNNs) to misclassify inputs with high probability. In practical attack scenarios, adversarial perturbations may undergo transformations such as changes in pixel intensity, scaling, etc. before being added to DNN inputs. Existing methods do not create UAPs robust to these real-world transformations, thereby limiting their applicability in practical attack scenarios. In this work, we introduce and formulate UAPs robust against real-world transformations. We build an iterative algorithm using probabilistic robustness bounds and construct such UAPs robust to transformations generated by composing arbitrary sub-differentiable transformation functions. We perform an extensive evaluation on the popular CIFAR-10 and ILSVRC 2012 datasets measuring our UAPs' robustness under a wide range common, real-world transformations such as rotation, contrast changes, etc. We further show t",
    "link": "http://arxiv.org/abs/2206.10858",
    "context": "Title: Robust Universal Adversarial Perturbations. (arXiv:2206.10858v2 [cs.LG] UPDATED)\nAbstract: Universal Adversarial Perturbations (UAPs) are imperceptible, image-agnostic vectors that cause deep neural networks (DNNs) to misclassify inputs with high probability. In practical attack scenarios, adversarial perturbations may undergo transformations such as changes in pixel intensity, scaling, etc. before being added to DNN inputs. Existing methods do not create UAPs robust to these real-world transformations, thereby limiting their applicability in practical attack scenarios. In this work, we introduce and formulate UAPs robust against real-world transformations. We build an iterative algorithm using probabilistic robustness bounds and construct such UAPs robust to transformations generated by composing arbitrary sub-differentiable transformation functions. We perform an extensive evaluation on the popular CIFAR-10 and ILSVRC 2012 datasets measuring our UAPs' robustness under a wide range common, real-world transformations such as rotation, contrast changes, etc. We further show t",
    "path": "papers/22/06/2206.10858.json",
    "total_tokens": 867,
    "translated_title": "鲁棒性通用对抗扰动",
    "translated_abstract": "通用对抗扰动（UAP）是一种不可察觉的图像无关向量，可以导致深度神经网络（DNN）高概率地将输入错误分类。在实际攻击场景中，对抗性扰动可能会在添加到DNN输入之前经历像素强度的变化、缩放等变换。现有方法不能创建对这些现实世界变换具有鲁棒性的UAP，因此在实际攻击场景中应用受到限制。在本文中，我们介绍并制定了对现实世界变换具有鲁棒性的UAP。我们使用概率鲁棒性界限构建了一个迭代算法，并构造了这样的UAP，它们对由任意子可微变换函数组成的变换具有鲁棒性。我们对流行的CIFAR-10和ILSVRC 2012数据集进行了广泛评估，衡量了我们的UAP在一系列常见的现实世界变换下的鲁棒性，例如旋转、对比度变化等。我们进一步展示。",
    "tldr": "本文提出了一种对现实世界变换具有鲁棒性的通用对抗扰动生成算法，并在多个数据集上进行了评估。",
    "en_tdlr": "This paper proposes an algorithm for generating universal adversarial perturbations with robustness against real-world transformations, which is evaluated on multiple datasets."
}