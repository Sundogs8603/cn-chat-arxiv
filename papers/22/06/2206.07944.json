{
    "title": "Distributed Online Private Learning of Convex Nondecomposable Objectives. (arXiv:2206.07944v4 [math.OC] UPDATED)",
    "abstract": "We deal with a general distributed constrained online learning problem with privacy over time-varying networks, where a class of nondecomposable objectives are considered. Under this setting, each node only controls a part of the global decision, and the goal of all nodes is to collaboratively minimize the global cost over a time horizon $T$ while guarantees the security of the transmitted information. For such problems, we first design a novel generic algorithm framework, named as DPSDA, of differentially private distributed online learning using the Laplace mechanism and the stochastic variants of dual averaging method. Note that in the dual updates, all nodes of DPSDA employ the noise-corrupted gradients for more generality. Then, we propose two algorithms, named as DPSDA-C and DPSDA-PS, under this framework. In DPSDA-C, the nodes implement a circulation-based communication in the primal updates so as to alleviate the disagreements over time-varying undirected networks. In addition,",
    "link": "http://arxiv.org/abs/2206.07944",
    "context": "Title: Distributed Online Private Learning of Convex Nondecomposable Objectives. (arXiv:2206.07944v4 [math.OC] UPDATED)\nAbstract: We deal with a general distributed constrained online learning problem with privacy over time-varying networks, where a class of nondecomposable objectives are considered. Under this setting, each node only controls a part of the global decision, and the goal of all nodes is to collaboratively minimize the global cost over a time horizon $T$ while guarantees the security of the transmitted information. For such problems, we first design a novel generic algorithm framework, named as DPSDA, of differentially private distributed online learning using the Laplace mechanism and the stochastic variants of dual averaging method. Note that in the dual updates, all nodes of DPSDA employ the noise-corrupted gradients for more generality. Then, we propose two algorithms, named as DPSDA-C and DPSDA-PS, under this framework. In DPSDA-C, the nodes implement a circulation-based communication in the primal updates so as to alleviate the disagreements over time-varying undirected networks. In addition,",
    "path": "papers/22/06/2206.07944.json",
    "total_tokens": 951,
    "translated_title": "分布式在线隐私学习的凸非可分目标",
    "translated_abstract": "我们处理了一个通用的分布式约束在线学习问题，该问题涉及随时间变化的网络隐私，考虑了一类非可分目标。在这种设置下，每个节点只控制全局决策的一部分，所有节点的目标是在时间范围T内协同最小化全局成本，并保证传输信息的安全性。针对这种问题，我们首先设计了一种新颖的通用算法框架，称为DPSDA，使用Laplace机制和随机变量的对偶平均法进行差分私有分布式在线学习。注意，在对偶更新中，DPSDA的所有节点都使用受噪声干扰的梯度，以提高通用性。然后，我们在该框架下提出了两种算法，分别称为DPSDA-C和DPSDA-PS。在DPSDA-C中，节点在原始更新中实现基于循环的通信，以减轻随时间变化的无向网络上的分歧。",
    "tldr": "该论文提出了一种分布式在线隐私学习的算法框架DPSDA，通过差分私有方式和对偶平均法来处理具有隐私和时间变化特性的约束在线学习问题，并提出了两种算法DPSDA-C和DPSDA-PS，其分别采用了循环式通信和具有噪声干扰梯度的对偶更新策略。",
    "en_tdlr": "This paper proposes a novel algorithm framework DPSDA for distributed online private learning, which deals with constrained learning problems in time-varying networks and ensures privacy. It introduces two algorithms, DPSDA-C and DPSDA-PS, that utilize circulation-based communication and noise-corrupted gradients in the dual updates."
}