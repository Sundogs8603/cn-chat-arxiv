{
    "title": "Algorithmic Gaussianization through Sketching: Converting Data into Sub-gaussian Random Designs. (arXiv:2206.10291v2 [cs.LG] UPDATED)",
    "abstract": "Algorithmic Gaussianization is a phenomenon that can arise when using randomized sketching or sampling methods to produce smaller representations of large datasets: For certain tasks, these sketched representations have been observed to exhibit many robust performance characteristics that are known to occur when a data sample comes from a sub-gaussian random design, which is a powerful statistical model of data distributions. However, this phenomenon has only been studied for specific tasks and metrics, or by relying on computationally expensive methods. We address this by providing an algorithmic framework for gaussianizing data distributions via averaging, proving that it is possible to efficiently construct data sketches that are nearly indistinguishable (in terms of total variation distance) from sub-gaussian random designs. In particular, relying on a recently introduced sketching technique called Leverage Score Sparsified (LESS) embeddings, we show that one can construct an $n\\ti",
    "link": "http://arxiv.org/abs/2206.10291",
    "context": "Title: Algorithmic Gaussianization through Sketching: Converting Data into Sub-gaussian Random Designs. (arXiv:2206.10291v2 [cs.LG] UPDATED)\nAbstract: Algorithmic Gaussianization is a phenomenon that can arise when using randomized sketching or sampling methods to produce smaller representations of large datasets: For certain tasks, these sketched representations have been observed to exhibit many robust performance characteristics that are known to occur when a data sample comes from a sub-gaussian random design, which is a powerful statistical model of data distributions. However, this phenomenon has only been studied for specific tasks and metrics, or by relying on computationally expensive methods. We address this by providing an algorithmic framework for gaussianizing data distributions via averaging, proving that it is possible to efficiently construct data sketches that are nearly indistinguishable (in terms of total variation distance) from sub-gaussian random designs. In particular, relying on a recently introduced sketching technique called Leverage Score Sparsified (LESS) embeddings, we show that one can construct an $n\\ti",
    "path": "papers/22/06/2206.10291.json",
    "total_tokens": 924,
    "translated_title": "通过草图技术实现算法高斯化：将数据转换为次高斯随机设计",
    "translated_abstract": "算法高斯化是使用随机草图方法或采样方法生成大型数据集的较小表示时可能出现的现象：对于某些任务，观察到的这些草图表示具有许多稳健性能特征，这些特征在数据样本来自次高斯随机设计时已被确认存在，而次高斯随机设计是数据分布的一个强大统计模型。然而，这种现象仅在特定任务和度量标准上进行了研究，或者依赖于计算昂贵的方法。我们通过提供一种通过平均来高斯化数据分布的算法框架来解决这个问题，并证明可以高效地构建与次高斯随机设计在总变异距离上几乎无法区分的数据草图。特别地，依赖于最近引入的一种称为杠杆分数稀疏（LESS）嵌入的草图技术，我们展示了可以构建一个n逼真的高斯化数据草图。",
    "tldr": "该论文通过引入杠杆分数稀疏（LESS）嵌入的草图技术，提供了一种算法框架，实现了对数据分布的高斯化，从而能够高效地构建与次高斯随机设计几乎无法区分的数据草图。",
    "en_tdlr": "This paper presents an algorithmic framework for Gaussianizing data distributions through the introduction of sketching technique called Leverage Score Sparsified (LESS) embeddings. It enables the efficient construction of data sketches that are almost indistinguishable from sub-gaussian random designs."
}