{
    "title": "Subject Membership Inference Attacks in Federated Learning. (arXiv:2206.03317v3 [cs.LG] UPDATED)",
    "abstract": "Privacy attacks on Machine Learning (ML) models often focus on inferring the existence of particular data points in the training data. However, what the adversary really wants to know is if a particular individual's (subject's) data was included during training. In such scenarios, the adversary is more likely to have access to the distribution of a particular subject than actual records. Furthermore, in settings like cross-silo Federated Learning (FL), a subject's data can be embodied by multiple data records that are spread across multiple organizations. Nearly all of the existing private FL literature is dedicated to studying privacy at two granularities -- item-level (individual data records), and user-level (participating user in the federation), neither of which apply to data subjects in cross-silo FL. This insight motivates us to shift our attention from the privacy of data records to the privacy of data subjects, also known as subject-level privacy. We propose two novel black-bo",
    "link": "http://arxiv.org/abs/2206.03317",
    "context": "Title: Subject Membership Inference Attacks in Federated Learning. (arXiv:2206.03317v3 [cs.LG] UPDATED)\nAbstract: Privacy attacks on Machine Learning (ML) models often focus on inferring the existence of particular data points in the training data. However, what the adversary really wants to know is if a particular individual's (subject's) data was included during training. In such scenarios, the adversary is more likely to have access to the distribution of a particular subject than actual records. Furthermore, in settings like cross-silo Federated Learning (FL), a subject's data can be embodied by multiple data records that are spread across multiple organizations. Nearly all of the existing private FL literature is dedicated to studying privacy at two granularities -- item-level (individual data records), and user-level (participating user in the federation), neither of which apply to data subjects in cross-silo FL. This insight motivates us to shift our attention from the privacy of data records to the privacy of data subjects, also known as subject-level privacy. We propose two novel black-bo",
    "path": "papers/22/06/2206.03317.json",
    "total_tokens": 696,
    "translated_title": "联邦学习中的主体成员推理攻击",
    "translated_abstract": "机器学习模型的隐私攻击通常着重于推论训练数据中特定数据点的存在。然而，攻击者真正想知道的是特定个体的（主体的）数据是否包含在训练中。在这种情况下，攻击者更可能拥有特定主体分布而非实际记录。本文研究跨边界联邦学习中主体级别的隐私，提出两种新颖的黑盒推理攻击方法，并进行评估。",
    "tldr": "本文研究跨边界联邦学习中主体级别的隐私，并提出两种新颖的黑盒推理攻击方法。",
    "en_tdlr": "This paper focuses on subject-level privacy in cross-silo Federated Learning and proposes two novel black-box inference attacks."
}