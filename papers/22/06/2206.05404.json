{
    "title": "Squeeze All: Novel Estimator and Self-Normalized Bound for Linear Contextual Bandits. (arXiv:2206.05404v3 [stat.ML] UPDATED)",
    "abstract": "We propose a linear contextual bandit algorithm with $O(\\sqrt{dT\\log T})$ regret bound, where $d$ is the dimension of contexts and $T$ isthe time horizon. Our proposed algorithm is equipped with a novel estimator in which exploration is embedded through explicit randomization. Depending on the randomization, our proposed estimator takes contributions either from contexts of all arms or from selected contexts. We establish a self-normalized bound for our estimator, which allows a novel decomposition of the cumulative regret into \\textit{additive} dimension-dependent terms instead of multiplicative terms. We also prove a novel lower bound of $\\Omega(\\sqrt{dT})$ under our problem setting. Hence, the regret of our proposed algorithm matches the lower bound up to logarithmic factors. The numerical experiments support the theoretical guarantees and show that our proposed method outperforms the existing linear bandit algorithms.",
    "link": "http://arxiv.org/abs/2206.05404",
    "context": "Title: Squeeze All: Novel Estimator and Self-Normalized Bound for Linear Contextual Bandits. (arXiv:2206.05404v3 [stat.ML] UPDATED)\nAbstract: We propose a linear contextual bandit algorithm with $O(\\sqrt{dT\\log T})$ regret bound, where $d$ is the dimension of contexts and $T$ isthe time horizon. Our proposed algorithm is equipped with a novel estimator in which exploration is embedded through explicit randomization. Depending on the randomization, our proposed estimator takes contributions either from contexts of all arms or from selected contexts. We establish a self-normalized bound for our estimator, which allows a novel decomposition of the cumulative regret into \\textit{additive} dimension-dependent terms instead of multiplicative terms. We also prove a novel lower bound of $\\Omega(\\sqrt{dT})$ under our problem setting. Hence, the regret of our proposed algorithm matches the lower bound up to logarithmic factors. The numerical experiments support the theoretical guarantees and show that our proposed method outperforms the existing linear bandit algorithms.",
    "path": "papers/22/06/2206.05404.json",
    "total_tokens": 941,
    "translated_title": "Squeeze All：线性上下文Bandit的新估计器和自标准化界限",
    "translated_abstract": "我们提出了一种具有$O(\\sqrt{dT\\log T})$遗憾界的线性上下文Bandit算法，其中$d$是上下文的维数，$T$是时间跨度。我们的算法具有一种新颖的估计量，其中通过显式随机化嵌入了探索。根据随机性，我们的建议估计器可以从所有武器的上下文或从选定的上下文中获得贡献。我们为我们的估计器建立了一个自标准化界限，它允许将累积遗憾分解为基于维度的\\textit{可加}项，而不是乘法项。我们还证明了在我们的问题设置下的$\\Omega(\\sqrt{dT})$的新的下限。因此，我们提出的算法的遗憾匹配下限，直到对数因子。数值实验支持理论保证，并表明我们的方法优于现有的线性Bandit算法。",
    "tldr": "我们提出了一种具有新颖估计量和自标准化界限的线性上下文Bandit算法，具有$O(\\sqrt{dT\\log T})$遗憾界，维度相关的加法项分解遗憾累积，性能优于现有方法。",
    "en_tdlr": "We propose a linear contextual bandit algorithm with a novel estimator and a self-normalized bound, achieving a regret bound of $O(\\sqrt{dT\\log T})$. The novel estimator allows for exploration through explicit randomization and can take contributions from all arms or selected contexts. The self-normalized bound enables a decomposition of cumulative regret into additive, dimension-dependent terms. Our proposed algorithm matches the lower bound up to logarithmic factors and outperforms existing methods in numerical experiments."
}