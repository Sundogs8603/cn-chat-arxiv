{
    "title": "Auditing Visualizations: Transparency Methods Struggle to Detect Anomalous Behavior. (arXiv:2206.13498v2 [cs.LG] UPDATED)",
    "abstract": "Model visualizations provide information that outputs alone might miss. But can we trust that model visualizations reflect model behavior? For instance, can they diagnose abnormal behavior such as planted backdoors or overregularization? To evaluate visualization methods, we test whether they assign different visualizations to anomalously trained models and normal models. We find that while existing methods can detect models with starkly anomalous behavior, they struggle to identify more subtle anomalies. Moreover, they often fail to recognize the inputs that induce anomalous behavior, e.g. images containing a spurious cue. These results reveal blind spots and limitations of some popular model visualizations. By introducing a novel evaluation framework for visualizations, our work paves the way for developing more reliable model transparency methods in the future.",
    "link": "http://arxiv.org/abs/2206.13498",
    "context": "Title: Auditing Visualizations: Transparency Methods Struggle to Detect Anomalous Behavior. (arXiv:2206.13498v2 [cs.LG] UPDATED)\nAbstract: Model visualizations provide information that outputs alone might miss. But can we trust that model visualizations reflect model behavior? For instance, can they diagnose abnormal behavior such as planted backdoors or overregularization? To evaluate visualization methods, we test whether they assign different visualizations to anomalously trained models and normal models. We find that while existing methods can detect models with starkly anomalous behavior, they struggle to identify more subtle anomalies. Moreover, they often fail to recognize the inputs that induce anomalous behavior, e.g. images containing a spurious cue. These results reveal blind spots and limitations of some popular model visualizations. By introducing a novel evaluation framework for visualizations, our work paves the way for developing more reliable model transparency methods in the future.",
    "path": "papers/22/06/2206.13498.json",
    "total_tokens": 829,
    "translated_title": "可视化审计：透明方法难以检测异常行为。",
    "translated_abstract": "模型可视化提供了仅有输出可能会忽略的信息。但我们能相信模型可视化反映了模型行为吗？例如，它们能否诊断出种植的后门或过度正则化等异常行为？为了评估可视化方法，我们测试了它们是否将不正常训练的模型和正常模型分配给不同的可视化。我们发现，虽然现有的方法可以检测到明显异常行为的模型，但它们很难识别更微妙的异常。此外，它们经常无法识别导致异常行为的输入，例如包含虚假提示的图像。这些结果揭示了一些流行模型可视化的盲点和局限性。通过引入一种新的可视化评估框架，我们的工作为未来开发更可靠的模型透明度方法铺平了道路。",
    "tldr": "本研究评估了可视化方法检测模型异常行为的能力，发现现有方法难以识别微妙的异常行为，并且无法识别导致异常行为的输入。因此，需要开发更可靠的模型透明度方法。",
    "en_tdlr": "This study evaluates the ability of visualization methods to detect anomalous behavior in models and finds that existing methods struggle to identify subtle anomalies and input-induced anomalies, highlighting the need for more reliable model transparency methods."
}