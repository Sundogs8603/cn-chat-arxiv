{
    "title": "Stability Verification of Neural Network Controllers using Mixed-Integer Programming. (arXiv:2206.13374v2 [eess.SY] UPDATED)",
    "abstract": "We propose a framework for the stability verification of Mixed-Integer Linear Programming (MILP) representable control policies. This framework compares a fixed candidate policy, which admits an efficient parameterization and can be evaluated at a low computational cost, against a fixed baseline policy, which is known to be stable but expensive to evaluate. We provide sufficient conditions for the closed-loop stability of the candidate policy in terms of the worst-case approximation error with respect to the baseline policy, and we show that these conditions can be checked by solving a Mixed-Integer Quadratic Program (MIQP). Additionally, we demonstrate that an outer and inner approximation of the stability region of the candidate policy can be computed by solving an MILP. The proposed framework is sufficiently general to accommodate a broad range of candidate policies including ReLU Neural Networks (NNs), optimal solution maps of parametric quadratic programs, and Model Predictive Con",
    "link": "http://arxiv.org/abs/2206.13374",
    "context": "Title: Stability Verification of Neural Network Controllers using Mixed-Integer Programming. (arXiv:2206.13374v2 [eess.SY] UPDATED)\nAbstract: We propose a framework for the stability verification of Mixed-Integer Linear Programming (MILP) representable control policies. This framework compares a fixed candidate policy, which admits an efficient parameterization and can be evaluated at a low computational cost, against a fixed baseline policy, which is known to be stable but expensive to evaluate. We provide sufficient conditions for the closed-loop stability of the candidate policy in terms of the worst-case approximation error with respect to the baseline policy, and we show that these conditions can be checked by solving a Mixed-Integer Quadratic Program (MIQP). Additionally, we demonstrate that an outer and inner approximation of the stability region of the candidate policy can be computed by solving an MILP. The proposed framework is sufficiently general to accommodate a broad range of candidate policies including ReLU Neural Networks (NNs), optimal solution maps of parametric quadratic programs, and Model Predictive Con",
    "path": "papers/22/06/2206.13374.json",
    "total_tokens": 906,
    "translated_title": "混合整数规划验证神经网络控制器的稳定性",
    "translated_abstract": "我们提出了一个框架，用于混合整数线性规划（MILP）可表示控制策略的稳定性验证。该框架将一个固定的候选策略与一个已知稳定但计算成本高的固定基准策略进行比较，并提供了有关候选策略的闭环稳定性的充分条件，这些条件是基于与基准策略的最坏近似误差关系的，并且这些条件可以通过解决混合整数二次规划（MIQP）来检查。此外，我们展示了一个MIPL可以计算候选策略稳定区域的外部和内部逼近。所提出的框架足够通用，可适应广泛的候选策略，包括ReLU神经网络（NN）、参数二次规划的最优解映射和带有混合整数约束的模型预测控制（MPC）策略。",
    "tldr": "本文提出了一种用混合整数规划方法验证神经网络控制器稳定性的方法，通过解决混合整数二次规划来检查策略的稳定性。此方法通用，适用于广泛的控制策略。",
    "en_tdlr": "This paper proposes a framework for verifying the stability of neural network controllers using mixed-integer programming, which checks the stability of the policy by solving mixed-integer quadratic programming. The method is general and applicable to a wide range of control policies."
}