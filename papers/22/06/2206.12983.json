{
    "title": "Explainable and High-Performance Hate and Offensive Speech Detection. (arXiv:2206.12983v2 [cs.CL] UPDATED)",
    "abstract": "The spread of information through social media platforms can create environments possibly hostile to vulnerable communities and silence certain groups in society. To mitigate such instances, several models have been developed to detect hate and offensive speech. Since detecting hate and offensive speech in social media platforms could incorrectly exclude individuals from social media platforms, which can reduce trust, there is a need to create explainable and interpretable models. Thus, we build an explainable and interpretable high performance model based on the XGBoost algorithm, trained on Twitter data. For unbalanced Twitter data, XGboost outperformed the LSTM, AutoGluon, and ULMFiT models on hate speech detection with an F1 score of 0.75 compared to 0.38 and 0.37, and 0.38 respectively. When we down-sampled the data to three separate classes of approximately 5000 tweets, XGBoost performed better than LSTM, AutoGluon, and ULMFiT; with F1 scores for hate speech detection of 0.79 vs ",
    "link": "http://arxiv.org/abs/2206.12983",
    "context": "Title: Explainable and High-Performance Hate and Offensive Speech Detection. (arXiv:2206.12983v2 [cs.CL] UPDATED)\nAbstract: The spread of information through social media platforms can create environments possibly hostile to vulnerable communities and silence certain groups in society. To mitigate such instances, several models have been developed to detect hate and offensive speech. Since detecting hate and offensive speech in social media platforms could incorrectly exclude individuals from social media platforms, which can reduce trust, there is a need to create explainable and interpretable models. Thus, we build an explainable and interpretable high performance model based on the XGBoost algorithm, trained on Twitter data. For unbalanced Twitter data, XGboost outperformed the LSTM, AutoGluon, and ULMFiT models on hate speech detection with an F1 score of 0.75 compared to 0.38 and 0.37, and 0.38 respectively. When we down-sampled the data to three separate classes of approximately 5000 tweets, XGBoost performed better than LSTM, AutoGluon, and ULMFiT; with F1 scores for hate speech detection of 0.79 vs ",
    "path": "papers/22/06/2206.12983.json",
    "total_tokens": 1004,
    "translated_title": "可解释且高性能的仇恨和冒犯性言论检测",
    "translated_abstract": "社交媒体平台上信息的传播可能会在脆弱社群中创造敌对的环境，并使某些群体沉默。为了缓解这种情况，已开发了多个模型来检测仇恨和冒犯性言论。由于在社交媒体平台上检测仇恨和冒犯性言论可能错误地将个体排除在社交媒体平台之外，从而降低了信任度，因此有必要创建可解释且可解释的模型。因此，我们基于XGBoost算法构建了一个可解释且可解释的高性能模型，该模型使用Twitter数据进行训练。对于不平衡的Twitter数据，相比于LSTM、AutoGluon和ULMFiT模型的F1得分分别为0.38和0.37，以及0.38，XGBoost在仇恨言论检测方面的F1得分为0.75，表现更好。当我们将数据降采样为约5000条推文的三个独立类别时，XGBoost在仇恨言论检测方面的F1得分也优于LSTM、AutoGluon和ULMFiT，为0.79。",
    "tldr": "这项研究构建了一个可解释且高性能的模型，基于XGBoost算法，用于检测社交媒体平台上的仇恨和冒犯性言论。该模型在不平衡的Twitter数据上显示出更好的性能，并且在降采样后的数据中也表现出优越性能。"
}