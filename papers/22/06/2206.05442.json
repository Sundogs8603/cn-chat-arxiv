{
    "title": "From Human Days to Machine Seconds: Automatically Answering and Generating Machine Learning Final Exams. (arXiv:2206.05442v6 [cs.LG] UPDATED)",
    "abstract": "A final exam in machine learning at a top institution such as MIT, Harvard, or Cornell typically takes faculty days to write, and students hours to solve. We demonstrate that large language models pass machine learning finals at a human level on a corpus drawn from MIT, Harvard, and Cornell and automatically generate new human-quality final exam questions in seconds. Previous work has developed program synthesis and few-shot learning methods to solve university-level problem set questions in mathematics and STEM courses. In this work, we develop and compare methods that solve final exams, which differ from problem sets in several ways: the questions are longer, have multiple parts, are more complicated, and span a broader set of topics. We provide a new dataset and benchmark of questions from machine learning final exams and code for answering these questions and generating new questions. We show how to generate new questions from other questions and course notes. We evaluate a large o",
    "link": "http://arxiv.org/abs/2206.05442",
    "context": "Title: From Human Days to Machine Seconds: Automatically Answering and Generating Machine Learning Final Exams. (arXiv:2206.05442v6 [cs.LG] UPDATED)\nAbstract: A final exam in machine learning at a top institution such as MIT, Harvard, or Cornell typically takes faculty days to write, and students hours to solve. We demonstrate that large language models pass machine learning finals at a human level on a corpus drawn from MIT, Harvard, and Cornell and automatically generate new human-quality final exam questions in seconds. Previous work has developed program synthesis and few-shot learning methods to solve university-level problem set questions in mathematics and STEM courses. In this work, we develop and compare methods that solve final exams, which differ from problem sets in several ways: the questions are longer, have multiple parts, are more complicated, and span a broader set of topics. We provide a new dataset and benchmark of questions from machine learning final exams and code for answering these questions and generating new questions. We show how to generate new questions from other questions and course notes. We evaluate a large o",
    "path": "papers/22/06/2206.05442.json",
    "total_tokens": 921,
    "tldr": "该论文使用大型语言模型在短时间内自动回答和生成了来自顶尖机构的机器学习期末考试，提供了一个新的数据集和基准测试，并开发了比先前工作更复杂的解决方法。"
}