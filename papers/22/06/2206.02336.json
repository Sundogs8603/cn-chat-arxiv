{
    "title": "Making Large Language Models Better Reasoners with Step-Aware Verifier. (arXiv:2206.02336v3 [cs.CL] UPDATED)",
    "abstract": "Few-shot learning is a challenging task that requires language models to generalize from limited examples. Large language models like GPT-3 and PaLM have made impressive progress in this area, but they still face difficulties in reasoning tasks such as GSM8K, a benchmark for arithmetic problems. To improve their reasoning skills, previous work has proposed to guide the language model with prompts that elicit a series of reasoning steps before giving the final answer, achieving a significant improvement on GSM8K from 17.9% to 58.1% in problem-solving rate. In this paper, we present DIVERSE (Diverse Verifier on Reasoning Step), a novel approach that further enhances the reasoning capability of language models. DIVERSE has three main components: first, it generates diverse prompts to explore different reasoning paths for the same question; second, it uses a verifier to filter out incorrect answers based on a weighted voting scheme; and third, it verifies each reasoning step individually i",
    "link": "http://arxiv.org/abs/2206.02336",
    "context": "Title: Making Large Language Models Better Reasoners with Step-Aware Verifier. (arXiv:2206.02336v3 [cs.CL] UPDATED)\nAbstract: Few-shot learning is a challenging task that requires language models to generalize from limited examples. Large language models like GPT-3 and PaLM have made impressive progress in this area, but they still face difficulties in reasoning tasks such as GSM8K, a benchmark for arithmetic problems. To improve their reasoning skills, previous work has proposed to guide the language model with prompts that elicit a series of reasoning steps before giving the final answer, achieving a significant improvement on GSM8K from 17.9% to 58.1% in problem-solving rate. In this paper, we present DIVERSE (Diverse Verifier on Reasoning Step), a novel approach that further enhances the reasoning capability of language models. DIVERSE has three main components: first, it generates diverse prompts to explore different reasoning paths for the same question; second, it uses a verifier to filter out incorrect answers based on a weighted voting scheme; and third, it verifies each reasoning step individually i",
    "path": "papers/22/06/2206.02336.json",
    "total_tokens": 928,
    "translated_title": "使用步骤感知验证器使大型语言模型成为更好的推理者",
    "translated_abstract": "小样本学习是一个具有挑战性的任务，需要语言模型从有限的示例中进行泛化。像GPT-3和PaLM这样的大型语言模型在这个领域取得了令人瞩目的进展，但它们在推理任务中仍然面临困难，比如GSM8K，这是一个算术问题的基准。为了提高它们的推理能力，之前的工作提出了使用提示来引导语言模型在给出最终答案之前进行一系列推理步骤，从而在GSM8K上实现了显着的提高，从17.9%提高到了58.1%的解题率。在本文中，我们提出了一种名为DIVERSE（多样的推理步骤验证器）的新方法，进一步增强了语言模型的推理能力。DIVERSE有三个主要组成部分：第一，它生成多样的提示，探索相同问题的不同推理路径；第二，它使用验证器根据加权投票方案过滤掉不正确的答案；第三，它逐个验证每个推理步骤。",
    "tldr": "本论文提出了一种名为DIVERSE的新方法，它使用多样的提示、验证器过滤不正确的答案并逐个验证每个推理步骤，以进一步增强语言模型的推理能力。",
    "en_tdlr": "This paper proposes a novel approach called DIVERSE, which enhances the reasoning capability of language models by generating diverse prompts, using a verifier to filter incorrect answers and verifying each reasoning step individually."
}