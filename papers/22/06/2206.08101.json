{
    "title": "Towards More Objective Evaluation of Class Incremental Learning: Representation Learning Perspective. (arXiv:2206.08101v2 [cs.LG] UPDATED)",
    "abstract": "Class incremental learning (CIL) is the process of continually learning new object classes from incremental data while not forgetting past learned classes. While the common method for evaluating CIL algorithms is based on average test accuracy for all learned classes, we argue that maximizing accuracy alone does not necessarily lead to effective CIL algorithms. In this paper, we experimentally analyze neural network models trained by CIL algorithms using various evaluation protocols in representation learning and propose a new analysis method. Our experiments show that most state-of-the-art algorithms prioritize high stability and do not significantly change the learned representation, and sometimes even learn a representation of lower quality than a naive baseline. However, we observe that these algorithms can still achieve high test accuracy because they learn a classifier that is closer to the optimal classifier. We also found that the base model learned in the first task varies in ",
    "link": "http://arxiv.org/abs/2206.08101",
    "context": "Title: Towards More Objective Evaluation of Class Incremental Learning: Representation Learning Perspective. (arXiv:2206.08101v2 [cs.LG] UPDATED)\nAbstract: Class incremental learning (CIL) is the process of continually learning new object classes from incremental data while not forgetting past learned classes. While the common method for evaluating CIL algorithms is based on average test accuracy for all learned classes, we argue that maximizing accuracy alone does not necessarily lead to effective CIL algorithms. In this paper, we experimentally analyze neural network models trained by CIL algorithms using various evaluation protocols in representation learning and propose a new analysis method. Our experiments show that most state-of-the-art algorithms prioritize high stability and do not significantly change the learned representation, and sometimes even learn a representation of lower quality than a naive baseline. However, we observe that these algorithms can still achieve high test accuracy because they learn a classifier that is closer to the optimal classifier. We also found that the base model learned in the first task varies in ",
    "path": "papers/22/06/2206.08101.json",
    "total_tokens": 890,
    "translated_title": "从表示学习的角度探索更客观的评价类增量学习",
    "translated_abstract": "类增量学习（CIL）是指在不忘记已经学习的类别的情况下，不断地从增量数据中学习新的对象类别的过程。虽然评估CIL算法的常见方法是基于所有已学习类别的平均测试准确率，但我们认为仅仅最大化准确率并不一定能导致有效的CIL算法。本文通过在表示学习中使用各种评估协议实验分析CIL算法训练的神经网络模型，并提出了一种新的分析方法。我们的实验表明，大多数最先进的算法优先考虑高稳定性，且没有显著改变学习的表示，有时甚至学习了比朴素基线更差的表示。但我们观察到这些算法仍然可以实现高测试准确率，因为它们学习了更接近最优分类器的分类器。我们还发现，第一个任务中学习的基模型会有所不同。",
    "tldr": "本文提出了利用表示学习对类增量学习进行客观评估的方法，并实验分析了CIL算法训练的神经网络模型，发现大多数最新算法优先考虑高稳定性，但仍然能够实现高测试准确率。",
    "en_tdlr": "This paper proposes a method for objectively evaluating class incremental learning using representation learning and experimentally analyzes neural network models trained by CIL algorithms, finding that while most state-of-the-art algorithms prioritize high stability, they can still achieve high test accuracy."
}