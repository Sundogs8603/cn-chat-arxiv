{
    "title": "Benign Overfitting in Classification: Provably Counter Label Noise with Larger Models. (arXiv:2206.00501v2 [cs.LG] UPDATED)",
    "abstract": "Studies on benign overfitting provide insights for the success of overparameterized deep learning models. In this work, we examine whether overfitting is truly benign in real-world classification tasks. We start with the observation that a ResNet model overfits benignly on Cifar10 but not benignly on ImageNet. To understand why benign overfitting fails in the ImageNet experiment, we theoretically analyze benign overfitting under a more restrictive setup where the number of parameters is not significantly larger than the number of data points. Under this mild overparameterization setup, our analysis identifies a phase change: unlike in the previous heavy overparameterization settings, benign overfitting can now fail in the presence of label noise. Our analysis explains our empirical observations, and is validated by a set of control experiments with ResNets. Our work highlights the importance of understanding implicit bias in underfitting regimes as a future direction.",
    "link": "http://arxiv.org/abs/2206.00501",
    "context": "Title: Benign Overfitting in Classification: Provably Counter Label Noise with Larger Models. (arXiv:2206.00501v2 [cs.LG] UPDATED)\nAbstract: Studies on benign overfitting provide insights for the success of overparameterized deep learning models. In this work, we examine whether overfitting is truly benign in real-world classification tasks. We start with the observation that a ResNet model overfits benignly on Cifar10 but not benignly on ImageNet. To understand why benign overfitting fails in the ImageNet experiment, we theoretically analyze benign overfitting under a more restrictive setup where the number of parameters is not significantly larger than the number of data points. Under this mild overparameterization setup, our analysis identifies a phase change: unlike in the previous heavy overparameterization settings, benign overfitting can now fail in the presence of label noise. Our analysis explains our empirical observations, and is validated by a set of control experiments with ResNets. Our work highlights the importance of understanding implicit bias in underfitting regimes as a future direction.",
    "path": "papers/22/06/2206.00501.json",
    "total_tokens": 856,
    "translated_title": "分类中的良性过拟合：更大模型的发现可证明对抗标签噪声",
    "translated_abstract": "良性过拟合的研究为超参数化深度学习模型的成功提供了见解。本文研究了过拟合是否在真实世界的分类任务中真的是良性的。我们开始观察到一个 ResNet 模型在 Cifar10 上表现良好，但在 ImageNet 上则不良。为了了解为什么良性过拟合在 ImageNet 实验中失败，我们在一个比数据点数量不明显大的限定条件下从理论上分析了良性过拟合。在这个轻微超参数化的设置下，我们的分析发现了一个相变：与之前的重超参数化设置不同，当存在标签噪声时，良性过拟合现在可能会失败。我们的分析解释了我们的经验观察，并通过一组 ResNet 的控制实验进行了验证。我们的工作强调了理解欠拟合制度下的隐式偏见的重要性，作为未来的一个方向。",
    "tldr": "本文发现良性过拟合在存在标签噪声的情况下可能会失败，提醒未来需要理解欠拟合制度下的隐式偏见。",
    "en_tdlr": "This paper discovers that benign overfitting can fail in the presence of label noise and highlights the importance of understanding implicit bias in underfitting regimes for future research."
}