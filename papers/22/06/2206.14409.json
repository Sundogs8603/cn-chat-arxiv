{
    "title": "BATFormer: Towards Boundary-Aware Lightweight Transformer for Efficient Medical Image Segmentation. (arXiv:2206.14409v3 [cs.CV] UPDATED)",
    "abstract": "Objective: Transformers, born to remedy the inadequate receptive fields of CNNs, have drawn explosive attention recently. However, the daunting computational complexity of global representation learning, together with rigid window partitioning, hinders their deployment in medical image segmentation. This work aims to address the above two issues in transformers for better medical image segmentation. Methods: We propose a boundary-aware lightweight transformer (BATFormer) that can build cross-scale global interaction with lower computational complexity and generate windows flexibly under the guidance of entropy. Specifically, to fully explore the benefits of transformers in long-range dependency establishment, a cross-scale global transformer (CGT) module is introduced to jointly utilize multiple small-scale feature maps for richer global features with lower computational complexity. Given the importance of shape modeling in medical image segmentation, a boundary-aware local transformer",
    "link": "http://arxiv.org/abs/2206.14409",
    "context": "Title: BATFormer: Towards Boundary-Aware Lightweight Transformer for Efficient Medical Image Segmentation. (arXiv:2206.14409v3 [cs.CV] UPDATED)\nAbstract: Objective: Transformers, born to remedy the inadequate receptive fields of CNNs, have drawn explosive attention recently. However, the daunting computational complexity of global representation learning, together with rigid window partitioning, hinders their deployment in medical image segmentation. This work aims to address the above two issues in transformers for better medical image segmentation. Methods: We propose a boundary-aware lightweight transformer (BATFormer) that can build cross-scale global interaction with lower computational complexity and generate windows flexibly under the guidance of entropy. Specifically, to fully explore the benefits of transformers in long-range dependency establishment, a cross-scale global transformer (CGT) module is introduced to jointly utilize multiple small-scale feature maps for richer global features with lower computational complexity. Given the importance of shape modeling in medical image segmentation, a boundary-aware local transformer",
    "path": "papers/22/06/2206.14409.json",
    "total_tokens": 906,
    "translated_title": "BATFormer: 用于高效医学图像分割的边界感知轻量级Transformer",
    "translated_abstract": "摘要：Transformer近来因其弥补了CNN不足的感受野而备受关注。但全局表示学习的高计算复杂度，以及刚性的窗口分割，阻碍了它们在医学图像分割中的应用。本文旨在解决Transformer在医学图像分割中的这两个问题。我们提出了一种名为边界感知轻量级Transformer（BATFormer）的方法，它可以以较低的计算复杂度建立跨尺度全局交互，并在熵的指导下灵活地生成窗口。具体而言，为了充分发挥Transformer在建立长距离依赖方面的优势，我们引入了一个跨尺度全局Transformer（CGT）模块，以联合利用多个小尺度特征图，生成更丰富的全局特征，同时计算复杂度更低。鉴于形状建模在医学图像分割中的重要性，我们还引入了一种边界感知本地Transformer。",
    "tldr": "本文提出了一种名为BATFormer的方法，以较低的计算复杂度实现跨尺度全局交互，即建立长距离依赖。同时，指导下灵活地生成窗口，增强了在医学图像分割中的形状建模。"
}