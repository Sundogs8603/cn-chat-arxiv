{
    "title": "Adversarial Ensemble Training by Jointly Learning Label Dependencies and Member Models. (arXiv:2206.14477v3 [cs.LG] UPDATED)",
    "abstract": "Training an ensemble of diverse sub-models has been empirically demonstrated as an effective strategy for improving the adversarial robustness of deep neural networks. However, current ensemble training methods for image recognition typically encode image labels using one-hot vectors, which overlook dependency relationships between the labels. In this paper, we propose a novel adversarial en-semble training approach that jointly learns the label dependencies and member models. Our approach adaptively exploits the learned label dependencies to pro-mote diversity among the member models. We evaluate our approach on widely used datasets including MNIST, FashionMNIST, and CIFAR-10, and show that it achieves superior robustness against black-box attacks compared to state-of-the-art methods. Our code is available at https://github.com/ZJLAB-AMMI/LSD.",
    "link": "http://arxiv.org/abs/2206.14477",
    "context": "Title: Adversarial Ensemble Training by Jointly Learning Label Dependencies and Member Models. (arXiv:2206.14477v3 [cs.LG] UPDATED)\nAbstract: Training an ensemble of diverse sub-models has been empirically demonstrated as an effective strategy for improving the adversarial robustness of deep neural networks. However, current ensemble training methods for image recognition typically encode image labels using one-hot vectors, which overlook dependency relationships between the labels. In this paper, we propose a novel adversarial en-semble training approach that jointly learns the label dependencies and member models. Our approach adaptively exploits the learned label dependencies to pro-mote diversity among the member models. We evaluate our approach on widely used datasets including MNIST, FashionMNIST, and CIFAR-10, and show that it achieves superior robustness against black-box attacks compared to state-of-the-art methods. Our code is available at https://github.com/ZJLAB-AMMI/LSD.",
    "path": "papers/22/06/2206.14477.json",
    "total_tokens": 870,
    "translated_title": "通过共同学习标签依赖性和成员模型的敌对集合训练",
    "translated_abstract": "实验证明，训练多样的子模型是提高深度神经网络对抗鲁棒性的有效策略。然而，目前用于图像识别的集合训练方法通常使用 one-hot 向量对图像标签进行编码，而忽略了标签之间的依赖关系。本文提出了一种新颖的敌对集合训练方法，它共同学习标签依赖关系和成员模型，自适应地利用学习到的标签依赖关系促进成员模型之间的多样性。在广泛使用的数据集 MNIST、FashionMNIST 和 CIFAR-10 上进行评估，结果表明该方法相比现有最先进的方法，在黑盒攻击方面具有更强的鲁棒性。我们的代码可在 https://github.com/ZJLAB-AMMI/LSD 获取。",
    "tldr": "训练深度神经网络的多样子模型是提高其防御对抗攻击的有效方法，本文提出了一种新的敌对集合训练方法，通过共同学习标签依赖性和成员模型来促进多样性，并在多个数据集上超越最先进方法。",
    "en_tdlr": "Training an ensemble of diverse sub-models is an effective strategy for improving the adversarial robustness of deep neural networks. This paper proposes a novel adversarial ensemble training approach that jointly learns the label dependencies and member models to promote diversity, achieving superior robustness against black-box attacks compared to state-of-the-art methods on widely used datasets."
}