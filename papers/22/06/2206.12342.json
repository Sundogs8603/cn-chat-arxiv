{
    "title": "FEATHERS: Federated Architecture and Hyperparameter Search. (arXiv:2206.12342v3 [cs.LG] UPDATED)",
    "abstract": "Deep neural architectures have profound impact on achieved performance in many of today's AI tasks, yet, their design still heavily relies on human prior knowledge and experience. Neural architecture search (NAS) together with hyperparameter optimization (HO) helps to reduce this dependence. However, state of the art NAS and HO rapidly become infeasible with increasing amount of data being stored in a distributed fashion, typically violating data privacy regulations such as GDPR and CCPA. As a remedy, we introduce FEATHERS $\\textbf{FE}$derated $\\textbf{A}$rchi$\\textbf{T}$ecture and $\\textbf{H}$yp$\\textbf{ER}$parameter $\\textbf{S}$earch, a method that not only optimizes both neural architectures and optimization-related hyperparameters jointly in distributed data settings, but further adheres to data privacy through the use of differential privacy (DP). We show that FEATHERS efficiently optimizes architectural and optimization-related hyperparameters alike, while demonstrating converg",
    "link": "http://arxiv.org/abs/2206.12342",
    "context": "Title: FEATHERS: Federated Architecture and Hyperparameter Search. (arXiv:2206.12342v3 [cs.LG] UPDATED)\nAbstract: Deep neural architectures have profound impact on achieved performance in many of today's AI tasks, yet, their design still heavily relies on human prior knowledge and experience. Neural architecture search (NAS) together with hyperparameter optimization (HO) helps to reduce this dependence. However, state of the art NAS and HO rapidly become infeasible with increasing amount of data being stored in a distributed fashion, typically violating data privacy regulations such as GDPR and CCPA. As a remedy, we introduce FEATHERS $\\textbf{FE}$derated $\\textbf{A}$rchi$\\textbf{T}$ecture and $\\textbf{H}$yp$\\textbf{ER}$parameter $\\textbf{S}$earch, a method that not only optimizes both neural architectures and optimization-related hyperparameters jointly in distributed data settings, but further adheres to data privacy through the use of differential privacy (DP). We show that FEATHERS efficiently optimizes architectural and optimization-related hyperparameters alike, while demonstrating converg",
    "path": "papers/22/06/2206.12342.json",
    "total_tokens": 852,
    "translated_title": "FEATHERS：联邦体系结构和超参数搜索。",
    "translated_abstract": "深度神经结构对于当今许多人工智能任务的性能有着深远影响，然而其设计仍然严重依赖于人类的先前知识和经验。神经结构搜索（NAS）以及超参数优化（HO）有助于减少这种依赖。然而，随着分布式存储数据量的增加，最先进的NAS和HO往往变得不可行，通常违反数据隐私法规，如GDPR和CCPA。为此，我们引入了FEATHERS（联邦体系结构和超参数搜索），这种方法不仅可以在分布式数据设置中联合优化神经结构和优化相关的超参数，而且还通过使用差分隐私（DP）遵守数据隐私规定。我们证明，FEATHERS可以有效地优化体系结构和优化相关的超参数，同时展示收敛情况。",
    "tldr": "介绍了一种名为FEATHERS的方法，它使用差分隐私保护数据隐私，可以联合优化在分布式数据设置中的神经结构和超参数，具有高效率和良好的收敛性能。",
    "en_tdlr": "FEATHERS is a method that uses differential privacy to protect data privacy, jointly optimizing neural architecture and optimization-related hyperparameters in distributed data settings, with high efficiency and good convergence performance."
}