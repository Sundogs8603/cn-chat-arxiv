{
    "title": "Decomposed Linear Dynamical Systems (dLDS) for learning the latent components of neural dynamics. (arXiv:2206.02972v2 [stat.ML] UPDATED)",
    "abstract": "Learning interpretable representations of neural dynamics at a population level is a crucial first step to understanding how observed neural activity relates to perception and behavior. Models of neural dynamics often focus on either low-dimensional projections of neural activity, or on learning dynamical systems that explicitly relate to the neural state over time. We discuss how these two approaches are interrelated by considering dynamical systems as representative of flows on a low-dimensional manifold. Building on this concept, we propose a new decomposed dynamical system model that represents complex non-stationary and nonlinear dynamics of time series data as a sparse combination of simpler, more interpretable components. Our model is trained through a dictionary learning procedure, where we leverage recent results in tracking sparse vectors over time. The decomposed nature of the dynamics is more expressive than previous switched approaches for a given number of parameters and ",
    "link": "http://arxiv.org/abs/2206.02972",
    "context": "Title: Decomposed Linear Dynamical Systems (dLDS) for learning the latent components of neural dynamics. (arXiv:2206.02972v2 [stat.ML] UPDATED)\nAbstract: Learning interpretable representations of neural dynamics at a population level is a crucial first step to understanding how observed neural activity relates to perception and behavior. Models of neural dynamics often focus on either low-dimensional projections of neural activity, or on learning dynamical systems that explicitly relate to the neural state over time. We discuss how these two approaches are interrelated by considering dynamical systems as representative of flows on a low-dimensional manifold. Building on this concept, we propose a new decomposed dynamical system model that represents complex non-stationary and nonlinear dynamics of time series data as a sparse combination of simpler, more interpretable components. Our model is trained through a dictionary learning procedure, where we leverage recent results in tracking sparse vectors over time. The decomposed nature of the dynamics is more expressive than previous switched approaches for a given number of parameters and ",
    "path": "papers/22/06/2206.02972.json",
    "total_tokens": 881,
    "translated_title": "分解线性动态系统（dLDS）用于学习神经动力学的潜在成分",
    "translated_abstract": "在群体水平上学习神经动力学的可解释表示是理解观察到的神经活动如何与知觉和行为相关的关键第一步。神经动力学模型通常集中于神经活动的低维投影，或者学习与神经状态随时间明确相关的动力系统。通过将动力系统视为低维流的代表，我们讨论了这两种方法之间的相互关系。在此概念基础上，我们提出了一种新的分解动力系统模型，将时间序列数据的复杂非平稳和非线性动态表示为更简单、更可解释的成分的稀疏组合。我们的模型通过一个字典学习过程进行训练，其中我们利用了最近在跟踪稀疏向量随时间变化方面的结果。相较于以往的开关方法，在给定参数数量的情况下，我们的分解动态性质更为明显。",
    "tldr": "该论文提出了一种新的分解动力系统模型，将复杂非平稳和非线性动态表示为简单、可解释的稀疏组合，并通过字典学习过程进行训练。"
}