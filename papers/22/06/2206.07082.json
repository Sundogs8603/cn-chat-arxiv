{
    "title": "Stability and Generalization of Stochastic Optimization with Nonconvex and Nonsmooth Problems. (arXiv:2206.07082v2 [cs.AI] UPDATED)",
    "abstract": "Stochastic optimization has found wide applications in minimizing objective functions in machine learning, which motivates a lot of theoretical studies to understand its practical success. Most of existing studies focus on the convergence of optimization errors, while the generalization analysis of stochastic optimization is much lagging behind. This is especially the case for nonconvex and nonsmooth problems often encountered in practice. In this paper, we initialize a systematic stability and generalization analysis of stochastic optimization on nonconvex and nonsmooth problems. We introduce novel algorithmic stability measures and establish their quantitative connection on the gap between population gradients and empirical gradients, which is then further extended to study the gap between the Moreau envelope of the empirical risk and that of the population risk. To our knowledge, these quantitative connection between stability and generalization in terms of either gradients or Morea",
    "link": "http://arxiv.org/abs/2206.07082",
    "context": "Title: Stability and Generalization of Stochastic Optimization with Nonconvex and Nonsmooth Problems. (arXiv:2206.07082v2 [cs.AI] UPDATED)\nAbstract: Stochastic optimization has found wide applications in minimizing objective functions in machine learning, which motivates a lot of theoretical studies to understand its practical success. Most of existing studies focus on the convergence of optimization errors, while the generalization analysis of stochastic optimization is much lagging behind. This is especially the case for nonconvex and nonsmooth problems often encountered in practice. In this paper, we initialize a systematic stability and generalization analysis of stochastic optimization on nonconvex and nonsmooth problems. We introduce novel algorithmic stability measures and establish their quantitative connection on the gap between population gradients and empirical gradients, which is then further extended to study the gap between the Moreau envelope of the empirical risk and that of the population risk. To our knowledge, these quantitative connection between stability and generalization in terms of either gradients or Morea",
    "path": "papers/22/06/2206.07082.json",
    "total_tokens": 1043,
    "translated_title": "非凸非光滑问题中随机优化的稳定性和泛化能力",
    "translated_abstract": "随机优化在机器学习中的应用非常广泛，这促使了许多理论研究，以理解其实际成功。大多数现有的研究都集中在优化误差的收敛性上，而随机优化的泛化分析远远滞后。这尤其适用于实践中经常遇到的非凸非光滑问题。在本文中，我们首次启动了对非凸非光滑问题上随机优化的系统稳定性和泛化分析。我们引入了新颖的算法稳定性度量，并建立了它们与种群梯度和经验梯度之间的定量连接，然后进一步将其扩展到研究经验风险和群体风险的Moreau包络之间的差距。据我们所知，这些稳定性和泛化性的定量联系，无论是在梯度还是Moreau包络方面，都是文献中首次出现的。我们进一步将我们的泛化理论应用于分析深度线性神经网络(DLNN)，在其中我们展示了所提出的理论可以比现有的工作提供更紧的泛化误差界。我们的理论结果通过对合成和现实世界数据集的数值实验进行了验证。",
    "tldr": "本文首次启动了对非凸非光滑问题上随机优化的系统稳定性和泛化分析，引入了新颖的算法稳定性度量，并建立了它们与种群梯度和经验梯度之间的定量连接。",
    "en_tdlr": "This paper initiates a systematic stability and generalization analysis of stochastic optimization on nonconvex and nonsmooth problems, introducing novel algorithmic stability measures and establishing their quantitative connection with the population gradients and empirical gradients."
}