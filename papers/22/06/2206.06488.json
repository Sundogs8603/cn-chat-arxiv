{
    "title": "Multimodal Learning with Transformers: A Survey. (arXiv:2206.06488v2 [cs.CV] UPDATED)",
    "abstract": "Transformer is a promising neural network learner, and has achieved great success in various machine learning tasks. Thanks to the recent prevalence of multimodal applications and big data, Transformer-based multimodal learning has become a hot topic in AI research. This paper presents a comprehensive survey of Transformer techniques oriented at multimodal data. The main contents of this survey include: (1) a background of multimodal learning, Transformer ecosystem, and the multimodal big data era, (2) a theoretical review of Vanilla Transformer, Vision Transformer, and multimodal Transformers, from a geometrically topological perspective, (3) a review of multimodal Transformer applications, via two important paradigms, i.e., for multimodal pretraining and for specific multimodal tasks, (4) a summary of the common challenges and designs shared by the multimodal Transformer models and applications, and (5) a discussion of open problems and potential research directions for the community",
    "link": "http://arxiv.org/abs/2206.06488",
    "context": "Title: Multimodal Learning with Transformers: A Survey. (arXiv:2206.06488v2 [cs.CV] UPDATED)\nAbstract: Transformer is a promising neural network learner, and has achieved great success in various machine learning tasks. Thanks to the recent prevalence of multimodal applications and big data, Transformer-based multimodal learning has become a hot topic in AI research. This paper presents a comprehensive survey of Transformer techniques oriented at multimodal data. The main contents of this survey include: (1) a background of multimodal learning, Transformer ecosystem, and the multimodal big data era, (2) a theoretical review of Vanilla Transformer, Vision Transformer, and multimodal Transformers, from a geometrically topological perspective, (3) a review of multimodal Transformer applications, via two important paradigms, i.e., for multimodal pretraining and for specific multimodal tasks, (4) a summary of the common challenges and designs shared by the multimodal Transformer models and applications, and (5) a discussion of open problems and potential research directions for the community",
    "path": "papers/22/06/2206.06488.json",
    "total_tokens": 886,
    "translated_title": "基于Transformer的多模态学习综述",
    "translated_abstract": "Transformer是一种有前途的神经网络学习器，在各种机器学习任务中取得了巨大成功。由于多模态应用和大数据的普及，基于Transformer的多模态学习成为人工智能研究的热门话题。本文介绍了一项针对多模态数据的Transformer技术全面综述。该综述的主要内容包括：（1）多模态学习与Transformer生态系统及多模态大数据时代的背景，（2）从几何拓扑学的角度对Vanilla Transformer、Vision Transformer和多模态Transformer进行理论综述，（3）通过两种重要范例，即多模态预训练和特定多模态任务，综述多模态Transformer应用，（4）总结多模态Transformer模型和应用所共享的常见挑战和设计，（5）讨论社区的开放性问题和潜在研究方向。",
    "tldr": "本文综述了基于Transformer的多模态学习技术，包括Vanilla Transformer、Vision Transformer和多模态Transformer，在多模态预训练和特定任务中的应用，以及共享的常见挑战和设计。并探讨了开放的问题和潜在研究方向。",
    "en_tdlr": "This paper presents a comprehensive survey of Transformer techniques oriented at multimodal data, including Vanilla Transformer, Vision Transformer, and multimodal Transformers, their applications in multimodal pretraining and specific tasks, and the common challenges and designs shared by the models and applications. It also discusses open problems and potential research directions."
}