{
    "title": "Masked Frequency Modeling for Self-Supervised Visual Pre-Training. (arXiv:2206.07706v2 [cs.CV] UPDATED)",
    "abstract": "We present Masked Frequency Modeling (MFM), a unified frequency-domain-based approach for self-supervised pre-training of visual models. Instead of randomly inserting mask tokens to the input embeddings in the spatial domain, in this paper, we shift the perspective to the frequency domain. Specifically, MFM first masks out a portion of frequency components of the input image and then predicts the missing frequencies on the frequency spectrum. Our key insight is that predicting masked components in the frequency domain is more ideal to reveal underlying image patterns rather than predicting masked patches in the spatial domain, due to the heavy spatial redundancy. Our findings suggest that with the right configuration of mask-and-predict strategy, both the structural information within high-frequency components and the low-level statistics among low-frequency counterparts are useful in learning good representations. For the first time, MFM demonstrates that, for both ViT and CNN, a simp",
    "link": "http://arxiv.org/abs/2206.07706",
    "context": "Title: Masked Frequency Modeling for Self-Supervised Visual Pre-Training. (arXiv:2206.07706v2 [cs.CV] UPDATED)\nAbstract: We present Masked Frequency Modeling (MFM), a unified frequency-domain-based approach for self-supervised pre-training of visual models. Instead of randomly inserting mask tokens to the input embeddings in the spatial domain, in this paper, we shift the perspective to the frequency domain. Specifically, MFM first masks out a portion of frequency components of the input image and then predicts the missing frequencies on the frequency spectrum. Our key insight is that predicting masked components in the frequency domain is more ideal to reveal underlying image patterns rather than predicting masked patches in the spatial domain, due to the heavy spatial redundancy. Our findings suggest that with the right configuration of mask-and-predict strategy, both the structural information within high-frequency components and the low-level statistics among low-frequency counterparts are useful in learning good representations. For the first time, MFM demonstrates that, for both ViT and CNN, a simp",
    "path": "papers/22/06/2206.07706.json",
    "total_tokens": 924,
    "translated_title": "自监督视觉预训练中的掩膜频率建模",
    "translated_abstract": "本文提出了掩膜频率建模（MFM）, 一种用于自监督视觉模型预训练的基于频率域的统一方法。相比于在空间域中随机插入掩膜标记， MFM将视角转向频率域。具体来说，MFM首先屏蔽输入图像频率成分的一部分, 然后预测频谱上缺失的频率。我们的关键见解是，在频率域中预测掩膜组件比预测空间域中的掩膜补丁更能够揭示底层图像模式，因为后者具有较大的空间冗余性。我们的研究结果表明，通过正确的掩膜和预测策略, 高频成分中的结构信息以及低频成分中的低阶统计信息都有助于学习良好的表示方法。MFM首次证明, 对于ViT和CNN模型，简单的在线掩膜预测机制可以在自监督预训练中实现很好的表现。",
    "tldr": "本文提出了掩膜频率建模（MFM）方法，用于自监督视觉预训练，通过对高低频成分进行掩膜预测，可以更好地揭示底层图像模式，并在ViT和CNN模型中实现很好的表现。"
}