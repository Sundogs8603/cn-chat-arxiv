{
    "title": "GAMR: A Guided Attention Model for (visual) Reasoning. (arXiv:2206.04928v5 [cs.AI] UPDATED)",
    "abstract": "Humans continue to outperform modern AI systems in their ability to flexibly parse and understand complex visual scenes. Here, we present a novel module for visual reasoning, the Guided Attention Model for (visual) Reasoning (GAMR), which instantiates an active vision theory -- positing that the brain solves complex visual reasoning problems dynamically -- via sequences of attention shifts to select and route task-relevant visual information into memory. Experiments on an array of visual reasoning tasks and datasets demonstrate GAMR's ability to learn visual routines in a robust and sample-efficient manner. In addition, GAMR is shown to be capable of zero-shot generalization on completely novel reasoning tasks. Overall, our work provides computational support for cognitive theories that postulate the need for a critical interplay between attention and memory to dynamically maintain and manipulate task-relevant visual information to solve complex visual reasoning tasks.",
    "link": "http://arxiv.org/abs/2206.04928",
    "context": "Title: GAMR: A Guided Attention Model for (visual) Reasoning. (arXiv:2206.04928v5 [cs.AI] UPDATED)\nAbstract: Humans continue to outperform modern AI systems in their ability to flexibly parse and understand complex visual scenes. Here, we present a novel module for visual reasoning, the Guided Attention Model for (visual) Reasoning (GAMR), which instantiates an active vision theory -- positing that the brain solves complex visual reasoning problems dynamically -- via sequences of attention shifts to select and route task-relevant visual information into memory. Experiments on an array of visual reasoning tasks and datasets demonstrate GAMR's ability to learn visual routines in a robust and sample-efficient manner. In addition, GAMR is shown to be capable of zero-shot generalization on completely novel reasoning tasks. Overall, our work provides computational support for cognitive theories that postulate the need for a critical interplay between attention and memory to dynamically maintain and manipulate task-relevant visual information to solve complex visual reasoning tasks.",
    "path": "papers/22/06/2206.04928.json",
    "total_tokens": 887,
    "translated_title": "GAMR: 一种用于 (视觉) 推理的引导式注意力模型",
    "translated_abstract": "人类在灵活分析和理解复杂的视觉场景方面仍然优于现代人工智能系统。本文提出了一种新的视觉推理模块——引导式注意力模型(GAMR)，它通过选择和路由与任务相关的视觉信息到记忆中的注意力转移序列来体现主动视觉理论。在各种视觉推理任务和数据集上的实验显示，GAMR能够以稳健且样本高效的方式学习视觉例程。此外，GAMR在全新的推理任务上表现出了零样本泛化的能力。总的来说，我们的研究提供了计算支持，支持认知理论假设需要注意力和记忆之间的关键相互作用，以动态地维护和操作任务相关的视觉信息来解决复杂的视觉推理任务。",
    "tldr": "本文介绍了一个新的模块——GAMR，它是一种用于(视觉)推理的引导式注意力模型，以动态选择任务相关的视觉信息并将其路由到记忆中来解决复杂的视觉推理任务，并在各种任务和数据集上取得了成功的实验结果。",
    "en_tdlr": "The paper presents a novel module for visual reasoning, GAMR, which implements an active vision theory via attention shifts to select and route task-relevant visual information into memory, and demonstrates its ability to learn visual routines in a robust and sample-efficient manner on various tasks and datasets, as well as zero-shot generalization on new reasoning tasks."
}