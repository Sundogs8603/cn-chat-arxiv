{
    "title": "Agreement-on-the-Line: Predicting the Performance of Neural Networks under Distribution Shift. (arXiv:2206.13089v2 [cs.LG] UPDATED)",
    "abstract": "Recently, Miller et al. showed that a model's in-distribution (ID) accuracy has a strong linear correlation with its out-of-distribution (OOD) accuracy on several OOD benchmarks -- a phenomenon they dubbed ''accuracy-on-the-line''. While a useful tool for model selection (i.e., the model most likely to perform the best OOD is the one with highest ID accuracy), this fact does not help estimate the actual OOD performance of models without access to a labeled OOD validation set. In this paper, we show a similar but surprising phenomenon also holds for the agreement between pairs of neural network classifiers: whenever accuracy-on-the-line holds, we observe that the OOD agreement between the predictions of any two pairs of neural networks (with potentially different architectures) also observes a strong linear correlation with their ID agreement. Furthermore, we observe that the slope and bias of OOD vs ID agreement closely matches that of OOD vs ID accuracy. This phenomenon, which we call",
    "link": "http://arxiv.org/abs/2206.13089",
    "context": "Title: Agreement-on-the-Line: Predicting the Performance of Neural Networks under Distribution Shift. (arXiv:2206.13089v2 [cs.LG] UPDATED)\nAbstract: Recently, Miller et al. showed that a model's in-distribution (ID) accuracy has a strong linear correlation with its out-of-distribution (OOD) accuracy on several OOD benchmarks -- a phenomenon they dubbed ''accuracy-on-the-line''. While a useful tool for model selection (i.e., the model most likely to perform the best OOD is the one with highest ID accuracy), this fact does not help estimate the actual OOD performance of models without access to a labeled OOD validation set. In this paper, we show a similar but surprising phenomenon also holds for the agreement between pairs of neural network classifiers: whenever accuracy-on-the-line holds, we observe that the OOD agreement between the predictions of any two pairs of neural networks (with potentially different architectures) also observes a strong linear correlation with their ID agreement. Furthermore, we observe that the slope and bias of OOD vs ID agreement closely matches that of OOD vs ID accuracy. This phenomenon, which we call",
    "path": "papers/22/06/2206.13089.json",
    "total_tokens": 1164,
    "translated_title": "“在线一致性”：预测在分布转换下神经网络的性能表现",
    "translated_abstract": "最近，Miller等人展示了模型在内部分布（ID）上的准确性与其在几个OOD基准上的准确性具有强烈的线性相关性，他们称之为“准确性在线”。 虽然这对于模型选择（即，ID准确度最高的模型最有可能表现最好OOD）是有用的工具，但这一事实无法帮助估计没有标记的OOD验证集的模型实际OOD表现。在本文中，我们展示了类似但令人惊讶的现象也适用于一对神经网络分类器之间的一致性：每当准确性在线成立时，我们观察到任意两对神经网络（具有潜在不同体系结构）的预测在OOD上的协议也与其ID协议之间具有强烈的线性相关性。此外，我们观察到OOD与ID协议的斜率和偏差与OOD与ID准确度非常接近。这种现象被我们称为“在线一致性”，它提供了一种实际的方法来估计OOD性能，而不需要访问标记的OOD验证集。 我们通过在几个公共基准测试（ImageNet、CIFAR-10-C和-10-P）上部署我们的方法来展示这一点，并展示它优于现有的OOD检测基线。",
    "tldr": "本研究发现神经网络内部分布的准确性与在分布转换下的准确性具有强线性相关性。这种现象也适用于一对神经网络分类器之间的一致性。我们提出了“在线一致性”这一理论，并展示其在估算没有标记的OOD验证集时的效果优于现有基线检测模型。",
    "en_tdlr": "This paper reveals a strong linear correlation between ID accuracy and OOD accuracy of neural networks, which is called \"accuracy-on-the-line\". By introducing the \"Agreement-on-the-Line\" phenomenon that holds between pairs of neural network classifiers, the authors provide a practical means of estimating OOD performance without a labeled validation set. They demonstrate the effectiveness of their method on ImageNet, CIFAR-10-C, and -10-P, outperforming existing OOD detection baselines."
}