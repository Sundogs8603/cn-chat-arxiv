{
    "title": "Gradient Boosting Performs Gaussian Process Inference. (arXiv:2206.05608v3 [cs.LG] UPDATED)",
    "abstract": "This paper shows that gradient boosting based on symmetric decision trees can be equivalently reformulated as a kernel method that converges to the solution of a certain Kernel Ridge Regression problem. Thus, we obtain the convergence to a Gaussian Process' posterior mean, which, in turn, allows us to easily transform gradient boosting into a sampler from the posterior to provide better knowledge uncertainty estimates through Monte-Carlo estimation of the posterior variance. We show that the proposed sampler allows for better knowledge uncertainty estimates leading to improved out-of-domain detection.",
    "link": "http://arxiv.org/abs/2206.05608",
    "total_tokens": 786,
    "translated_title": "梯度提升执行高斯过程推断",
    "translated_abstract": "本文表明，基于对称决策树的梯度提升可以等价地重构为一种核方法，该方法收敛于某个核岭回归问题的解。因此，我们获得了收敛于高斯过程后验均值的收敛性，从而使我们能够轻松地将梯度提升转换为从后验中提供更好的知识不确定性估计的采样器，通过后验方差的蒙特卡罗估计。我们展示了所提出的采样器允许更好的知识不确定性估计，从而导致改进的域外检测。",
    "tldr": "本文表明，基于对称决策树的梯度提升可以等价地重构为一种核方法，该方法收敛于某个核岭回归问题的解，从而使我们能够轻松地将梯度提升转换为从后验中提供更好的知识不确定性估计的采样器，通过后验方差的蒙特卡罗估计，从而允许更好的知识不确定性估计，导致改进的域外检测。",
    "en_tldr": "This paper shows that gradient boosting based on symmetric decision trees can be equivalently reformulated as a kernel method that converges to the solution of a certain Kernel Ridge Regression problem, which allows us to easily transform gradient boosting into a sampler from the posterior to provide better knowledge uncertainty estimates through Monte-Carlo estimation of the posterior variance, leading to improved out-of-domain detection."
}