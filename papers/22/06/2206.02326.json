{
    "title": "Asymptotic Instance-Optimal Algorithms for Interactive Decision Making. (arXiv:2206.02326v2 [cs.LG] UPDATED)",
    "abstract": "Past research on interactive decision making problems (bandits, reinforcement learning, etc.) mostly focuses on the minimax regret that measures the algorithm's performance on the hardest instance. However, an ideal algorithm should adapt to the complexity of a particular problem instance and incur smaller regrets on easy instances than worst-case instances. In this paper, we design the first asymptotic instance-optimal algorithm for general interactive decision making problems with finite number of decisions under mild conditions. On every instance $f$, our algorithm outperforms all consistent algorithms (those achieving non-trivial regrets on all instances), and has asymptotic regret $\\mathcal{C}(f) \\ln n$, where $\\mathcal{C}(f)$ is an exact characterization of the complexity of $f$. The key step of the algorithm involves hypothesis testing with active data collection. It computes the most economical decisions with which the algorithm collects observations to test whether an estimate",
    "link": "http://arxiv.org/abs/2206.02326",
    "context": "Title: Asymptotic Instance-Optimal Algorithms for Interactive Decision Making. (arXiv:2206.02326v2 [cs.LG] UPDATED)\nAbstract: Past research on interactive decision making problems (bandits, reinforcement learning, etc.) mostly focuses on the minimax regret that measures the algorithm's performance on the hardest instance. However, an ideal algorithm should adapt to the complexity of a particular problem instance and incur smaller regrets on easy instances than worst-case instances. In this paper, we design the first asymptotic instance-optimal algorithm for general interactive decision making problems with finite number of decisions under mild conditions. On every instance $f$, our algorithm outperforms all consistent algorithms (those achieving non-trivial regrets on all instances), and has asymptotic regret $\\mathcal{C}(f) \\ln n$, where $\\mathcal{C}(f)$ is an exact characterization of the complexity of $f$. The key step of the algorithm involves hypothesis testing with active data collection. It computes the most economical decisions with which the algorithm collects observations to test whether an estimate",
    "path": "papers/22/06/2206.02326.json",
    "total_tokens": 968,
    "translated_title": "交互式决策制定的渐近最优算法",
    "translated_abstract": "过去关于交互式决策制定问题（赌博机问题、强化学习等）的研究主要聚焦于度量算法在最难情况下的性能的最小化遗憾。然而，理想的算法应该能够适应特定问题实例的复杂性，并对易于处理的实例产生比最坏情况下更小的遗憾。本文设计了第一个在温和条件下适用于有限决策个数的一般交互式决策制定问题的渐近最优算法。在每个实例 $f$ 上，我们的算法优于所有一致算法（那些在所有实例上实现非平凡遗憾的算法），并且具有 $\\mathcal{C}(f) \\ln n$ 的渐近遗憾，其中 $\\mathcal{C}(f)$ 是 $f$ 的复杂度的精确表征。算法的关键步骤涉及带有活动数据收集的假设检验。它计算出最经济的决策，通过这些决策算法收集观察结果以检验估计值是否落在预期范围内。",
    "tldr": "本论文提出了适用于特定决策问题的渐近最优算法，该算法能够根据该问题的复杂度，在遗憾最小的前提下最大程度地收集观察结果。",
    "en_tdlr": "This paper proposes an asymptotic instance-optimal algorithm for interactive decision making problems, which adapts to the complexity of a particular problem instance and incurs smaller regrets on easy instances than worst-case instances. It outperforms all consistent algorithms and has asymptotic regret that depends on the complexity of the problem instance. The algorithm involves hypothesis testing with active data collection to compute the most economical decisions with which to collect observations."
}