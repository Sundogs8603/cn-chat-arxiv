{
    "title": "DEP-RL: Embodied Exploration for Reinforcement Learning in Overactuated and Musculoskeletal Systems. (arXiv:2206.00484v2 [cs.RO] UPDATED)",
    "abstract": "Muscle-actuated organisms are capable of learning an unparalleled diversity of dexterous movements despite their vast amount of muscles. Reinforcement learning (RL) on large musculoskeletal models, however, has not been able to show similar performance. We conjecture that ineffective exploration in large overactuated action spaces is a key problem. This is supported by the finding that common exploration noise strategies are inadequate in synthetic examples of overactuated systems. We identify differential extrinsic plasticity (DEP), a method from the domain of self-organization, as being able to induce state-space covering exploration within seconds of interaction. By integrating DEP into RL, we achieve fast learning of reaching and locomotion in musculoskeletal systems, outperforming current approaches in all considered tasks in sample efficiency and robustness.",
    "link": "http://arxiv.org/abs/2206.00484",
    "context": "Title: DEP-RL: Embodied Exploration for Reinforcement Learning in Overactuated and Musculoskeletal Systems. (arXiv:2206.00484v2 [cs.RO] UPDATED)\nAbstract: Muscle-actuated organisms are capable of learning an unparalleled diversity of dexterous movements despite their vast amount of muscles. Reinforcement learning (RL) on large musculoskeletal models, however, has not been able to show similar performance. We conjecture that ineffective exploration in large overactuated action spaces is a key problem. This is supported by the finding that common exploration noise strategies are inadequate in synthetic examples of overactuated systems. We identify differential extrinsic plasticity (DEP), a method from the domain of self-organization, as being able to induce state-space covering exploration within seconds of interaction. By integrating DEP into RL, we achieve fast learning of reaching and locomotion in musculoskeletal systems, outperforming current approaches in all considered tasks in sample efficiency and robustness.",
    "path": "papers/22/06/2206.00484.json",
    "total_tokens": 831,
    "translated_title": "DEP-RL：过度作动和肌骨系统中的强化学习探索",
    "translated_abstract": "肌肉作动的生物能够在拥有大量肌肉的情况下学习无与伦比的巧妙动作。然而，大型肌骨系统模型上的强化学习（RL）尚未能展示类似的表现。我们针对大型过度作动动作空间中的无效探索提出了假设，证明了常见的探索噪声策略在过度作动系统的合成示例中不够充分。我们认为微分外在可塑性（DEP），一种自组织领域的方法，能够在互动几秒钟内诱导状态空间覆盖探索。通过将DEP与RL集成，我们在肌骨系统中实现了快速学习到达和运动，在所有考虑到的任务中，在样本效率和鲁棒性方面均优于当前方法。",
    "tldr": "通过在RL中集成微分外在可塑性（DEP），我们可以快速学习到达和运动，并在所有考虑到的任务中，在样本效率和鲁棒性方面优于当前方法。",
    "en_tdlr": "By integrating differential extrinsic plasticity (DEP) into RL, we achieved fast learning of reaching and locomotion in musculoskeletal systems, outperforming current approaches in all considered tasks in sample efficiency and robustness."
}