{
    "title": "Out-of-distribution Detection by Cross-class Vicinity Distribution of In-distribution Data. (arXiv:2206.09385v2 [cs.LG] UPDATED)",
    "abstract": "Deep neural networks for image classification only learn to map in-distribution inputs to their corresponding ground truth labels in training without differentiating out-of-distribution samples from in-distribution ones. This results from the assumption that all samples are independent and identically distributed (IID) without distributional distinction. Therefore, a pretrained network learned from in-distribution samples treats out-of-distribution samples as in-distribution and makes high-confidence predictions on them in the test phase. To address this issue, we draw out-of-distribution samples from the vicinity distribution of training in-distribution samples for learning to reject the prediction on out-of-distribution inputs. A \\textit{Cross-class Vicinity Distribution} is introduced by assuming that an out-of-distribution sample generated by mixing multiple in-distribution samples does not share the same classes of its constituents. We thus improve the discriminability of a pretra",
    "link": "http://arxiv.org/abs/2206.09385",
    "context": "Title: Out-of-distribution Detection by Cross-class Vicinity Distribution of In-distribution Data. (arXiv:2206.09385v2 [cs.LG] UPDATED)\nAbstract: Deep neural networks for image classification only learn to map in-distribution inputs to their corresponding ground truth labels in training without differentiating out-of-distribution samples from in-distribution ones. This results from the assumption that all samples are independent and identically distributed (IID) without distributional distinction. Therefore, a pretrained network learned from in-distribution samples treats out-of-distribution samples as in-distribution and makes high-confidence predictions on them in the test phase. To address this issue, we draw out-of-distribution samples from the vicinity distribution of training in-distribution samples for learning to reject the prediction on out-of-distribution inputs. A \\textit{Cross-class Vicinity Distribution} is introduced by assuming that an out-of-distribution sample generated by mixing multiple in-distribution samples does not share the same classes of its constituents. We thus improve the discriminability of a pretra",
    "path": "papers/22/06/2206.09385.json",
    "total_tokens": 919,
    "translated_title": "通过交叉类接近分布的训练数据检测非分布样本",
    "translated_abstract": "图像分类的深度神经网络只学习将训练中的分布输入映射到对应的正确标签，而无法区分分布外样本和分布内样本。这是因为假设所有样本都是独立同分布的，并没有分布区别。因此，从分布内样本中学习到的预训练网络会将分布外样本视为分布内样本，在测试阶段对其进行高置信度预测。为了解决这个问题，我们从训练分布内样本的邻近分布中抽取出分布外样本，用于学习在分布外输入上拒绝预测。我们引入了一种“交叉类接近分布”，假设通过混合多个分布内样本生成的分布外样本与其组成部分不共享相同的类别。从而提高了预训练模型的区分度。",
    "tldr": "本研究提出了一种通过在训练数据的邻近分布中选择非分布样本来解决深度神经网络对分布外样本的识别问题的方法。引入了交叉类接近分布的概念，通过假设混合多个分布内样本生成的分布外样本与其组成部分具有不同的类别，提高了模型的区分能力。"
}