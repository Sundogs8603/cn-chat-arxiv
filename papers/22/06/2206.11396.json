{
    "title": "Multi-Horizon Representations with Hierarchical Forward Models for Reinforcement Learning. (arXiv:2206.11396v2 [cs.LG] UPDATED)",
    "abstract": "Learning control from pixels is difficult for reinforcement learning (RL) agents because representation learning and policy learning are intertwined. Previous approaches remedy this issue with auxiliary representation learning tasks, but they either do not consider the temporal aspect of the problem or only consider single-step transitions, which may cause learning inefficiencies if important environmental changes take many steps to manifest. We propose Hierarchical $k$-Step Latent (HKSL), an auxiliary task that learns multiple representations via a hierarchy of forward models that learn to communicate and an ensemble of $n$-step critics that all operate at varying magnitudes of step skipping. We evaluate HKSL in a suite of 30 robotic control tasks with and without distractors and a task of our creation. We find that HKSL either converges to higher or optimal episodic returns more quickly than several alternative representation learning approaches. Furthermore, we find that HKSL's repr",
    "link": "http://arxiv.org/abs/2206.11396",
    "context": "Title: Multi-Horizon Representations with Hierarchical Forward Models for Reinforcement Learning. (arXiv:2206.11396v2 [cs.LG] UPDATED)\nAbstract: Learning control from pixels is difficult for reinforcement learning (RL) agents because representation learning and policy learning are intertwined. Previous approaches remedy this issue with auxiliary representation learning tasks, but they either do not consider the temporal aspect of the problem or only consider single-step transitions, which may cause learning inefficiencies if important environmental changes take many steps to manifest. We propose Hierarchical $k$-Step Latent (HKSL), an auxiliary task that learns multiple representations via a hierarchy of forward models that learn to communicate and an ensemble of $n$-step critics that all operate at varying magnitudes of step skipping. We evaluate HKSL in a suite of 30 robotic control tasks with and without distractors and a task of our creation. We find that HKSL either converges to higher or optimal episodic returns more quickly than several alternative representation learning approaches. Furthermore, we find that HKSL's repr",
    "path": "papers/22/06/2206.11396.json",
    "total_tokens": 881,
    "translated_title": "使用层级前向模型实现多时间段表示的强化学习方法",
    "translated_abstract": "对于强化学习（RL）代理来说，从像素学习控制是困难的，因为表示学习和策略学习是相互交织的。先前的方法通过辅助表示学习任务来解决这个问题，但它们要么不考虑问题的时间方面，要么只考虑单步转换，如果重要的环境变化需要多个步骤才能表现出来，可能导致学习效率低下。我们提出了Hierarchical $k$-Step Latent (HKSL)，一种通过层级前向模型学习多个表示的辅助任务，这些模型学习通信以及一系列在不同步长下工作的$n$步评论家。我们在30个机器人控制任务和一个我们创建的任务中评估了HKSL的性能，包括有和无干扰物的情况。我们发现，与其他几种替代的表示学习方法相比，HKSL要么更快地收敛到更高的或最优的回报，要么更快地收敛到最优的回报。",
    "tldr": "提出了一种使用层级前向模型实现多时间段表示的辅助任务HKSL，通过学习多个表示和不同步长下的评论家，能够更快地收敛到更高的或最优的回报。",
    "en_tdlr": "We propose HKSL, an auxiliary task that uses hierarchical forward models to learn multi-horizon representations, enabling RL agents to converge to higher or optimal returns more quickly."
}