{
    "title": "BertNet: Harvesting Knowledge Graphs with Arbitrary Relations from Pretrained Language Models. (arXiv:2206.14268v3 [cs.CL] UPDATED)",
    "abstract": "It is crucial to automatically construct knowledge graphs (KGs) of diverse new relations to support knowledge discovery and broad applications. Previous KG construction methods, based on either crowdsourcing or text mining, are often limited to a small predefined set of relations due to manual cost or restrictions in text corpus. Recent research proposed to use pretrained language models (LMs) as implicit knowledge bases that accept knowledge queries with prompts. Yet, the implicit knowledge lacks many desirable properties of a full-scale symbolic KG, such as easy access, navigation, editing, and quality assurance. In this paper, we propose a new approach of harvesting massive KGs of arbitrary relations from pretrained LMs. With minimal input of a relation definition (a prompt and a few shot of example entity pairs), the approach efficiently searches in the vast entity pair space to extract diverse accurate knowledge of the desired relation. We develop an effective search-and-rescore m",
    "link": "http://arxiv.org/abs/2206.14268",
    "context": "Title: BertNet: Harvesting Knowledge Graphs with Arbitrary Relations from Pretrained Language Models. (arXiv:2206.14268v3 [cs.CL] UPDATED)\nAbstract: It is crucial to automatically construct knowledge graphs (KGs) of diverse new relations to support knowledge discovery and broad applications. Previous KG construction methods, based on either crowdsourcing or text mining, are often limited to a small predefined set of relations due to manual cost or restrictions in text corpus. Recent research proposed to use pretrained language models (LMs) as implicit knowledge bases that accept knowledge queries with prompts. Yet, the implicit knowledge lacks many desirable properties of a full-scale symbolic KG, such as easy access, navigation, editing, and quality assurance. In this paper, we propose a new approach of harvesting massive KGs of arbitrary relations from pretrained LMs. With minimal input of a relation definition (a prompt and a few shot of example entity pairs), the approach efficiently searches in the vast entity pair space to extract diverse accurate knowledge of the desired relation. We develop an effective search-and-rescore m",
    "path": "papers/22/06/2206.14268.json",
    "total_tokens": 899,
    "translated_title": "BertNet：从预训练语言模型中提取任意关系的知识图谱",
    "translated_abstract": "自动构建多种关系的知识图谱以支持知识发现和广泛应用是至关重要的。以往的知识图谱构建方法基于众包或文本挖掘，往往由于手动成本或文本语料库的限制而仅限于小型预定义关系集。最近的研究提出使用预训练的语言模型作为隐式的知识库，以接受提示的知识查询。然而，这种隐式知识缺少完整符号知识图谱的许多理想属性，如易于访问、导航、编辑和质量保证。本文提出一种新的方法，从预训练语言模型中提取大规模的任意关系的知识图谱。通过最小的关系定义输入（提示和示例实体对的短语），该方法可以有效地在庞大的实体对空间中搜索，提取所需关系的多样准确的知识。我们开发了一个有效的搜索和重新评分的机制，让这个方法更加实用。",
    "tldr": "本文提出了一种从预训练语言模型中提取任意关系的知识图谱的方法，通过最小的关系定义输入，实现在庞大的实体对空间中搜索，提取准确的知识。",
    "en_tdlr": "This paper proposes an approach to harvest massive knowledge graphs of arbitrary relations from pretrained language models, which efficiently searches in the vast entity pair space to extract accurate knowledge of the desired relation with minimal input of a relation definition."
}