{
    "title": "Assessing Privacy Leakage in Synthetic 3-D PET Imaging using Transversal GAN. (arXiv:2206.06448v2 [eess.IV] UPDATED)",
    "abstract": "Training computer-vision related algorithms on medical images for disease diagnosis or image segmentation is difficult in large part due to privacy concerns. For this reason, generative image models are highly sought after to facilitate data sharing. However, 3-D generative models are understudied, and investigation of their privacy leakage is needed. We introduce our 3-D generative model, Transversal GAN (TrGAN), using head & neck PET images which are conditioned on tumour masks as a case study. We define quantitative measures of image fidelity, utility and privacy for our model. These metrics are evaluated in the course of training to identify ideal fidelity, utility and privacy trade-offs and establish the relationships between these parameters. We show that the discriminator of the TrGAN is vulnerable to attack, and that an attacker can identify which samples were used in training with almost perfect accuracy (AUC = 0.99). We also show that an attacker with access to only the gener",
    "link": "http://arxiv.org/abs/2206.06448",
    "context": "Title: Assessing Privacy Leakage in Synthetic 3-D PET Imaging using Transversal GAN. (arXiv:2206.06448v2 [eess.IV] UPDATED)\nAbstract: Training computer-vision related algorithms on medical images for disease diagnosis or image segmentation is difficult in large part due to privacy concerns. For this reason, generative image models are highly sought after to facilitate data sharing. However, 3-D generative models are understudied, and investigation of their privacy leakage is needed. We introduce our 3-D generative model, Transversal GAN (TrGAN), using head & neck PET images which are conditioned on tumour masks as a case study. We define quantitative measures of image fidelity, utility and privacy for our model. These metrics are evaluated in the course of training to identify ideal fidelity, utility and privacy trade-offs and establish the relationships between these parameters. We show that the discriminator of the TrGAN is vulnerable to attack, and that an attacker can identify which samples were used in training with almost perfect accuracy (AUC = 0.99). We also show that an attacker with access to only the gener",
    "path": "papers/22/06/2206.06448.json",
    "total_tokens": 981,
    "translated_title": "用横向生成对抗网络评估合成的三维PET成像中的隐私泄漏",
    "translated_abstract": "由于隐私问题，在医学图像上训练与计算机视觉相关的算法进行疾病诊断或图像分割是困难的。因此，生成图像模型被广泛使用以促进数据共享。然而，三维生成模型的研究较少，需要对其隐私泄漏进行调查。我们介绍了我们的三维生成模型Transversal GAN (TrGAN)，使用头颈PET图像作为案例研究，并以肿瘤掩蔽为条件。我们为我们的模型定义了图像准确性、实用性和隐私的定量度量标准。这些度量标准在训练过程中进行评估，以确定理想的准确性、实用性和隐私折衷，并建立这些参数之间的关系。我们显示TrGAN的判别器容易受到攻击，攻击者几乎可以完全准确地识别出哪些样本用于训练（AUC = 0.99）。我们还展示，即使只有对生成模型有限的访问权限的攻击者也可以推断出受保护数据的一些特征。",
    "tldr": "通过研究三维PET图像生成模型Transversal GAN（TrGAN），我们发现TrGAN的判别器易受到攻击，攻击者可以准确地识别出训练样本，并在有限的访问权限情况下推断出受保护数据的特征。",
    "en_tdlr": "By studying the three-dimensional PET image generative model Transversal GAN (TrGAN), we found that the discriminator of TrGAN is vulnerable to attack, allowing attackers to accurately identify training samples and infer features of protected data even with limited access."
}