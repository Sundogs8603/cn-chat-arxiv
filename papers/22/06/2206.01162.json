{
    "title": "Posterior Coreset Construction with Kernelized Stein Discrepancy for Model-Based Reinforcement Learning. (arXiv:2206.01162v2 [cs.LG] UPDATED)",
    "abstract": "Model-based approaches to reinforcement learning (MBRL) exhibit favorable performance in practice, but their theoretical guarantees in large spaces are mostly restricted to the setting when transition model is Gaussian or Lipschitz, and demands a posterior estimate whose representational complexity grows unbounded with time. In this work, we develop a novel MBRL method (i) which relaxes the assumptions on the target transition model to belong to a generic family of mixture models; (ii) is applicable to large-scale training by incorporating a compression step such that the posterior estimate consists of a Bayesian coreset of only statistically significant past state-action pairs; and (iii) exhibits a sublinear Bayesian regret. To achieve these results, we adopt an approach based upon Stein's method, which, under a smoothness condition on the constructed posterior and target, allows distributional distance to be evaluated in closed form as the kernelized Stein discrepancy (KSD). The afor",
    "link": "http://arxiv.org/abs/2206.01162",
    "context": "Title: Posterior Coreset Construction with Kernelized Stein Discrepancy for Model-Based Reinforcement Learning. (arXiv:2206.01162v2 [cs.LG] UPDATED)\nAbstract: Model-based approaches to reinforcement learning (MBRL) exhibit favorable performance in practice, but their theoretical guarantees in large spaces are mostly restricted to the setting when transition model is Gaussian or Lipschitz, and demands a posterior estimate whose representational complexity grows unbounded with time. In this work, we develop a novel MBRL method (i) which relaxes the assumptions on the target transition model to belong to a generic family of mixture models; (ii) is applicable to large-scale training by incorporating a compression step such that the posterior estimate consists of a Bayesian coreset of only statistically significant past state-action pairs; and (iii) exhibits a sublinear Bayesian regret. To achieve these results, we adopt an approach based upon Stein's method, which, under a smoothness condition on the constructed posterior and target, allows distributional distance to be evaluated in closed form as the kernelized Stein discrepancy (KSD). The afor",
    "path": "papers/22/06/2206.01162.json",
    "total_tokens": 1038,
    "translated_title": "带有核化Stein距离的后验Coreset构建用于基于模型的强化学习",
    "translated_abstract": "模型为基础的强化学习方法在实践中表现出优异的性能，但在大空间的理论保证大多数限于转移模型为高斯或Lipschitz的情况下，并且需要后验估计其表示复杂度随时间增长而无界。 在本文中，我们开发了一种新的MBRL方法，(i) 放松目标转移模型属于通用混合模型族的假设；(ii) 通过包含压缩步骤以仅由统计显着的过去状态 - 操作对的贝叶斯Coreset组成，适用于大规模训练；(iii) 表现出亚线性的贝叶斯遗憾。为了实现这些结果，我们采用一种基于Stein方法的方法，该方法在构造后验和目标上满足平滑性条件的情况下，允许以核Stein距离（KSD）的形式封闭地评估分布距离。前面提到的后验Coreset构建是通过最小化这个KSD来完成的，其中混合组件的位置取决于l-inf预算，以限制中心的数量。我们在一系列模拟机器人控制任务中展示了该方法的有效性。",
    "tldr": "本文提出一种通过核化Stein距离构建后验Coreset的MBRL方法，在放松转移模型高斯或Lipschitz的限制下表现出优异的性能，并且可以应用于大规模训练。",
    "en_tdlr": "This paper proposes a novel MBRL method that constructs a posterior coreset with kernelized Stein discrepancy, allowing for relaxed assumptions on the transition model and large-scale training. The method exhibits sublinear Bayesian regret and is demonstrated to be effective on a suite of robotic control tasks."
}