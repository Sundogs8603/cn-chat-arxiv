{
    "title": "Chordal Sparsity for SDP-based Neural Network Verification. (arXiv:2206.03482v2 [cs.LG] UPDATED)",
    "abstract": "Neural networks are central to many emerging technologies, but verifying their correctness remains a major challenge. It is known that network outputs can be sensitive and fragile to even small input perturbations, thereby increasing the risk of unpredictable and undesirable behavior. Fast and accurate verification of neural networks is therefore critical to their widespread adoption, and in recent years a variety of methods have been developed as a response to this problem. In this paper, we focus on improving semidefinite programming (SDP) based techniques for neural network verification. Such techniques offer the power of expressing complex geometric constraints while retaining a convex problem formulation, but in practice, scalability remains a major issue. Our starting point is the DeepSDP framework proposed by Fazlyab et al, which uses quadratic constraints to abstract the verification problem into a large-scale SDP. When the network size grows, however, solving this SDP quickly ",
    "link": "http://arxiv.org/abs/2206.03482",
    "context": "Title: Chordal Sparsity for SDP-based Neural Network Verification. (arXiv:2206.03482v2 [cs.LG] UPDATED)\nAbstract: Neural networks are central to many emerging technologies, but verifying their correctness remains a major challenge. It is known that network outputs can be sensitive and fragile to even small input perturbations, thereby increasing the risk of unpredictable and undesirable behavior. Fast and accurate verification of neural networks is therefore critical to their widespread adoption, and in recent years a variety of methods have been developed as a response to this problem. In this paper, we focus on improving semidefinite programming (SDP) based techniques for neural network verification. Such techniques offer the power of expressing complex geometric constraints while retaining a convex problem formulation, but in practice, scalability remains a major issue. Our starting point is the DeepSDP framework proposed by Fazlyab et al, which uses quadratic constraints to abstract the verification problem into a large-scale SDP. When the network size grows, however, solving this SDP quickly ",
    "path": "papers/22/06/2206.03482.json",
    "total_tokens": 860,
    "translated_title": "基于半定规划的神经网络验证中的弦状稀疏性",
    "translated_abstract": "神经网络在许多新兴技术中起着核心作用，但验证其正确性仍然是一个重要挑战。已知网络输出对于即使是小的输入扰动也非常敏感和脆弱，从而增加了不可预测和不希望的行为的风险。快速而准确地验证神经网络对其广泛采用至关重要，并且近年来已经开发出多种方法来应对这个问题。在本文中，我们关注于改进基于半定规划（SDP）的神经网络验证技术。这些技术在保留凸问题形式的同时，提供了表达复杂几何约束的能力，但在实践中，可扩展性仍然是一个重要问题。我们的起点是Fazlyab等人提出的DeepSDP框架，该框架使用二次约束将验证问题抽象为一个大规模的SDP。然而，当网络规模增长时，解决这个SDP问题变得困难且耗时。",
    "tldr": "本文提出了一种基于半定规划的神经网络验证方法，通过引入弦状稀疏性，旨在改善现有技术中存在的可扩展性问题。",
    "en_tdlr": "This paper presents a SDP-based method for neural network verification, aiming to improve scalability issues by introducing chordal sparsity."
}