{
    "title": "Composition of Relational Features with an Application to Explaining Black-Box Predictors. (arXiv:2206.00738v2 [cs.LG] UPDATED)",
    "abstract": "Relational machine learning programs like those developed in Inductive Logic Programming (ILP) offer several advantages: (1) The ability to model complex relationships amongst data instances; (2) The use of domain-specific relations during model construction; and (3) The models constructed are human-readable, which is often one step closer to being human-understandable. However, these ILP-like methods have not been able to capitalise fully on the rapid hardware, software and algorithmic developments fuelling current developments in deep neural networks. In this paper, we treat relational features as functions and use the notion of generalised composition of functions to derive complex functions from simpler ones. We formulate the notion of a set of $\\text{M}$-simple features in a mode language $\\text{M}$ and identify two composition operators ($\\rho_1$ and $\\rho_2$) from which all possible complex features can be derived. We use these results to implement a form of \"explainable neural ",
    "link": "http://arxiv.org/abs/2206.00738",
    "context": "Title: Composition of Relational Features with an Application to Explaining Black-Box Predictors. (arXiv:2206.00738v2 [cs.LG] UPDATED)\nAbstract: Relational machine learning programs like those developed in Inductive Logic Programming (ILP) offer several advantages: (1) The ability to model complex relationships amongst data instances; (2) The use of domain-specific relations during model construction; and (3) The models constructed are human-readable, which is often one step closer to being human-understandable. However, these ILP-like methods have not been able to capitalise fully on the rapid hardware, software and algorithmic developments fuelling current developments in deep neural networks. In this paper, we treat relational features as functions and use the notion of generalised composition of functions to derive complex functions from simpler ones. We formulate the notion of a set of $\\text{M}$-simple features in a mode language $\\text{M}$ and identify two composition operators ($\\rho_1$ and $\\rho_2$) from which all possible complex features can be derived. We use these results to implement a form of \"explainable neural ",
    "path": "papers/22/06/2206.00738.json",
    "total_tokens": 872,
    "translated_title": "关于关系特征的构成及其在解释黑盒预测器中的应用",
    "translated_abstract": "类似归纳逻辑编程（ILP）的关系机器学习程序具有以下优点：（1）能够对数据实例之间的复杂关系建模；（2）在模型构建期间使用特定于领域的关系；（3）构建的模型是人类可读的，这通常更接近人类的理解。本文将关系特征视为函数，并使用通用函数组合的概念从简单函数推导出复杂函数。我们制定了一种在模据语言M中的 $\\text{M}$-简单特征集的概念，并确定了两个组合算子（$\\rho_1$和$\\rho_2$），所有可能的复杂特征都可以从中派生出来。我们利用这些结果实现了一种“可解释的神经网络”，其中我们使用我们的方法构建和解释黑盒预测器的预测。",
    "tldr": "本文提出了一种将关系特征视为函数，并使用通用函数组合的概念从简单函数推导出复杂函数的方法，将其应用于解释黑盒预测器的预测。",
    "en_tdlr": "This paper proposes a method that treats relational features as functions, and uses the notion of generalised composition of functions to derive complex functions from simpler ones. It is applied to explaining the predictions of black-box predictors."
}