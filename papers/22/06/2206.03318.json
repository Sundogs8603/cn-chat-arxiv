{
    "title": "LegoNN: Building Modular Encoder-Decoder Models. (arXiv:2206.03318v2 [cs.CL] UPDATED)",
    "abstract": "State-of-the-art encoder-decoder models (e.g. for machine translation (MT) or automatic speech recognition (ASR)) are constructed and trained end-to-end as an atomic unit. No component of the model can be (re-)used without the others, making it impossible to share parts, e.g. a high resourced decoder, across tasks. We describe LegoNN, a procedure for building encoder-decoder architectures in a way so that its parts can be applied to other tasks without the need for any fine-tuning. To achieve this reusability, the interface between encoder and decoder modules is grounded to a sequence of marginal distributions over a pre-defined discrete vocabulary. We present two approaches for ingesting these marginals; one is differentiable, allowing the flow of gradients across the entire network, and the other is gradient-isolating. To enable the portability of decoder modules between MT tasks for different source languages and across other tasks like ASR, we introduce a modality agnostic encoder ",
    "link": "http://arxiv.org/abs/2206.03318",
    "context": "Title: LegoNN: Building Modular Encoder-Decoder Models. (arXiv:2206.03318v2 [cs.CL] UPDATED)\nAbstract: State-of-the-art encoder-decoder models (e.g. for machine translation (MT) or automatic speech recognition (ASR)) are constructed and trained end-to-end as an atomic unit. No component of the model can be (re-)used without the others, making it impossible to share parts, e.g. a high resourced decoder, across tasks. We describe LegoNN, a procedure for building encoder-decoder architectures in a way so that its parts can be applied to other tasks without the need for any fine-tuning. To achieve this reusability, the interface between encoder and decoder modules is grounded to a sequence of marginal distributions over a pre-defined discrete vocabulary. We present two approaches for ingesting these marginals; one is differentiable, allowing the flow of gradients across the entire network, and the other is gradient-isolating. To enable the portability of decoder modules between MT tasks for different source languages and across other tasks like ASR, we introduce a modality agnostic encoder ",
    "path": "papers/22/06/2206.03318.json",
    "total_tokens": 985,
    "translated_title": "LegoNN：构建模块化编码器-解码器模型",
    "translated_abstract": "最先进的编码器-解码器模型（例如用于机器翻译（MT）或自动语音识别（ASR））被构建和训练为一个不可分割的整体。模型的任何组件都不能独立使用或重复使用，因此无法在不同任务之间共享部分，例如高资源解码器。我们介绍了LegoNN，一种构建编码器-解码器架构的方法，使其各个组件可以在无需微调的情况下应用于其他任务。为了实现这种可重用性，编码器和解码器模块之间的接口基于预定义离散词汇的边缘分布序列。我们提出了两种摄取这些边缘分布的方法；其中一种是可微分的，允许梯度在整个网络中传递，另一种是梯度隔离的。为了实现解码器模块在不同源语言的MT任务和其他任务（如ASR）之间的可移植性，我们引入了一种模态不可知的编码器。",
    "tldr": "LegoNN是一种可以构建模块化编码器-解码器模型的方法，其中各个组件可以被应用于其他任务而无需微调。为了实现这种可重用性，我们使用了基于离散词汇边缘分布的接口。这种方法具备对梯度的可传递性或隔离性，并且可以实现解码器模块在不同任务之间的可移植性。",
    "en_tdlr": "LegoNN is a method for building modular encoder-decoder models, where the components can be applied to other tasks without fine-tuning. It uses an interface based on marginal distributions over a discrete vocabulary to enable reusability. The method supports gradient flow or isolation and allows for the portability of decoder modules across different tasks."
}