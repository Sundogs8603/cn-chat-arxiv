{
    "title": "Reproducibility in Learning. (arXiv:2201.08430v2 [cs.LG] UPDATED)",
    "abstract": "We introduce the notion of a reproducible algorithm in the context of learning. A reproducible learning algorithm is resilient to variations in its samples -- with high probability, it returns the exact same output when run on two samples from the same underlying distribution. We begin by unpacking the definition, clarifying how randomness is instrumental in balancing accuracy and reproducibility. We initiate a theory of reproducible algorithms, showing how reproducibility implies desirable properties such as data reuse and efficient testability. Despite the exceedingly strong demand of reproducibility, there are efficient reproducible algorithms for several fundamental problems in statistics and learning. First, we show that any statistical query algorithm can be made reproducible with a modest increase in sample complexity, and we use this to construct reproducible algorithms for finding approximate heavy-hitters and medians. Using these ideas, we give the first reproducible algorith",
    "link": "http://arxiv.org/abs/2201.08430",
    "context": "Title: Reproducibility in Learning. (arXiv:2201.08430v2 [cs.LG] UPDATED)\nAbstract: We introduce the notion of a reproducible algorithm in the context of learning. A reproducible learning algorithm is resilient to variations in its samples -- with high probability, it returns the exact same output when run on two samples from the same underlying distribution. We begin by unpacking the definition, clarifying how randomness is instrumental in balancing accuracy and reproducibility. We initiate a theory of reproducible algorithms, showing how reproducibility implies desirable properties such as data reuse and efficient testability. Despite the exceedingly strong demand of reproducibility, there are efficient reproducible algorithms for several fundamental problems in statistics and learning. First, we show that any statistical query algorithm can be made reproducible with a modest increase in sample complexity, and we use this to construct reproducible algorithms for finding approximate heavy-hitters and medians. Using these ideas, we give the first reproducible algorith",
    "path": "papers/22/01/2201.08430.json",
    "total_tokens": 996,
    "translated_title": "学习中的可重复性",
    "translated_abstract": "我们在学习的背景下介绍了一个可重复性算法的概念。可重复性的学习算法能够抵御样本变异——在相同的基础分布下，运行在两个样本上时能够以高概率返回相同的输出。我们开始解开该定义，澄清随机性如何在平衡准确性和可重复性方面起到了作用。我们启动了一个可重复算法的理论，展示了可重复性如何暗示着具有良好性质，例如数据重用和高效性可测试性，尽管要求重复性非常强。我们展示了对于统计学和学习中的若干基础问题，有一些高效率的可重复性算法。首先，我们证明了任何统计查询算法都可以通过适度增加样本复杂度而变得可重复，并且我们使用这一点构建了寻找近似关键值和中位数的可重复性算法。利用这些想法，我们为寻找对数凹密度估计提供了第一个可重复性算法。",
    "tldr": "该论文介绍了可重复性学习算法的概念，这种算法能够抵御样本变异，在保证高准确度的同时，能够以高概率返回相同的输出。同时，该论文证明了可重复性并不与学习效果相悖，设计可重复性算法可以推动我们开发更高效、更稳健的数据分析和建模方法。",
    "en_tdlr": "The paper introduces the concept of reproducible algorithms in learning, which can withstand sample variations while ensuring high accuracy and returning the same output with high probability. It also shows that reproducibility is not at odds with learning efficiency and can lead to the development of more efficient and robust methods for data analysis and modeling."
}