{
    "title": "pvCNN: Privacy-Preserving and Verifiable Convolutional Neural Network Testing. (arXiv:2201.09186v3 [cs.CR] UPDATED)",
    "abstract": "This paper proposes a new approach for privacy-preserving and verifiable convolutional neural network (CNN) testing, enabling a CNN model developer to convince a user of the truthful CNN performance over non-public data from multiple testers, while respecting model privacy. To balance the security and efficiency issues, three new efforts are done by appropriately integrating homomorphic encryption (HE) and zero-knowledge succinct non-interactive argument of knowledge (zk-SNARK) primitives with the CNN testing. First, a CNN model to be tested is strategically partitioned into a private part kept locally by the model developer, and a public part outsourced to an outside server. Then, the private part runs over HE-protected test data sent by a tester and transmits its outputs to the public part for accomplishing subsequent computations of the CNN testing. Second, the correctness of the above CNN testing is enforced by generating zk-SNARK based proofs, with an emphasis on optimizing provin",
    "link": "http://arxiv.org/abs/2201.09186",
    "context": "Title: pvCNN: Privacy-Preserving and Verifiable Convolutional Neural Network Testing. (arXiv:2201.09186v3 [cs.CR] UPDATED)\nAbstract: This paper proposes a new approach for privacy-preserving and verifiable convolutional neural network (CNN) testing, enabling a CNN model developer to convince a user of the truthful CNN performance over non-public data from multiple testers, while respecting model privacy. To balance the security and efficiency issues, three new efforts are done by appropriately integrating homomorphic encryption (HE) and zero-knowledge succinct non-interactive argument of knowledge (zk-SNARK) primitives with the CNN testing. First, a CNN model to be tested is strategically partitioned into a private part kept locally by the model developer, and a public part outsourced to an outside server. Then, the private part runs over HE-protected test data sent by a tester and transmits its outputs to the public part for accomplishing subsequent computations of the CNN testing. Second, the correctness of the above CNN testing is enforced by generating zk-SNARK based proofs, with an emphasis on optimizing provin",
    "path": "papers/22/01/2201.09186.json",
    "total_tokens": 783,
    "translated_title": "pvCNN: 隐私保护和可验证的CNN测试",
    "translated_abstract": "本文提出了一种新的方法，用于隐私保护和可验证的卷积神经网络（CNN）测试，使CNN模型的开发人员能够通过适当地集成同态加密（HE）和零知识简洁非交互式知识（zk-SNARK），以及将 CNN模型划分为私有部分和公共部分并分别处理CNN测试中的不同部分，从而平衡安全和效率问题。通过这样的方法，从多个测试者选择非公开数据，从而使用户对CNN性能的真实表现确信无疑，并且也保护了模型的隐私。",
    "tldr": "本文提出了一种新的方法，用于隐私保护和可验证的卷积神经网络（CNN）测试，从多个测试者选择非公开数据，保护模型的隐私，并使用户对CNN性能的真实表现确信无疑。",
    "en_tdlr": "This paper proposes a new approach for privacy-preserving and verifiable convolutional neural network (CNN) testing, selecting non-public data from multiple testers to protect the model's privacy and convince users of the truthful CNN performance."
}