{
    "title": "Does Transliteration Help Multilingual Language Modeling?. (arXiv:2201.12501v2 [cs.CL] UPDATED)",
    "abstract": "As there is a scarcity of large representative corpora for most languages, it is important for Multilingual Language Models (MLLM) to extract the most out of existing corpora. In this regard, script diversity presents a challenge to MLLMs by reducing lexical overlap among closely related languages. Therefore, transliterating closely related languages that use different writing scripts to a common script may improve the downstream task performance of MLLMs. In this paper, we pretrain two ALBERT models to empirically measure the effect of transliteration on MLLMs. We specifically focus on the Indo-Aryan language family, which has the highest script diversity in the world. Afterward, we evaluate our models on the IndicGLUE benchmark. We perform Mann-Whitney U test to rigorously verify whether the effect of transliteration is significant or not. We find that transliteration benefits the low-resource languages without negatively affecting the comparatively high-resource languages. We also m",
    "link": "http://arxiv.org/abs/2201.12501",
    "context": "Title: Does Transliteration Help Multilingual Language Modeling?. (arXiv:2201.12501v2 [cs.CL] UPDATED)\nAbstract: As there is a scarcity of large representative corpora for most languages, it is important for Multilingual Language Models (MLLM) to extract the most out of existing corpora. In this regard, script diversity presents a challenge to MLLMs by reducing lexical overlap among closely related languages. Therefore, transliterating closely related languages that use different writing scripts to a common script may improve the downstream task performance of MLLMs. In this paper, we pretrain two ALBERT models to empirically measure the effect of transliteration on MLLMs. We specifically focus on the Indo-Aryan language family, which has the highest script diversity in the world. Afterward, we evaluate our models on the IndicGLUE benchmark. We perform Mann-Whitney U test to rigorously verify whether the effect of transliteration is significant or not. We find that transliteration benefits the low-resource languages without negatively affecting the comparatively high-resource languages. We also m",
    "path": "papers/22/01/2201.12501.json",
    "total_tokens": 933,
    "translated_title": "翻译：汉语拼音是否有助于多语言语言建模？",
    "translated_abstract": "由于大部分语言缺乏大规模的代表性语料库，对于多语言语言模型（MLLM）来说，从现有的语料库中提取最重要的信息非常重要。在这方面，不同语言的文本表现形式的多样性使得MLLM面临困难，因为相近的语言之间词汇重叠较少。因此，把使用不同书写系统的相近的语言音译成同一种书写系统可以提高MLLM的下游任务表现。本文中，我们预训练两个ALBERT模型，以实证的方式测量音译对MLLM的影响。我们特别关注印度语-雅利安语系，该系在世界上拥有最高的书写系统多样性。然后，我们在IndicGLUE基准测试中对模型进行评估。我们进行曼－惠特尼U检验，以严格验证音译的效果是否显著。我们发现，音译有利于低资源语言，而不会对资源相对较高的语言产生负面影响。",
    "tldr": "本文探究了把使用不同书写系统的相近语言音译成同一种书写系统，对于多语言语言模型的提升的影响，发现音译可以提高低资源语言的表现，而不会对资源相对较高的语言产生负面影响。"
}