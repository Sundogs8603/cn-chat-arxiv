{
    "title": "Neural Implicit Surface Evolution. (arXiv:2201.09636v4 [cs.LG] UPDATED)",
    "abstract": "This work investigates the use of smooth neural networks for modeling dynamic variations of implicit surfaces under the level set equation (LSE). For this, it extends the representation of neural implicit surfaces to the space-time $\\mathbb{R}^3\\times \\mathbb{R}$, which opens up mechanisms for continuous geometric transformations. Examples include evolving an initial surface towards general vector fields, smoothing and sharpening using the mean curvature equation, and interpolations of initial conditions.  The network training considers two constraints. A data term is responsible for fitting the initial condition to the corresponding time instant, usually $\\mathbb{R}^3 \\times \\{0\\}$. Then, a LSE term forces the network to approximate the underlying geometric evolution given by the LSE, without any supervision. The network can also be initialized based on previously trained initial conditions, resulting in faster convergence compared to the standard approach.",
    "link": "http://arxiv.org/abs/2201.09636",
    "context": "Title: Neural Implicit Surface Evolution. (arXiv:2201.09636v4 [cs.LG] UPDATED)\nAbstract: This work investigates the use of smooth neural networks for modeling dynamic variations of implicit surfaces under the level set equation (LSE). For this, it extends the representation of neural implicit surfaces to the space-time $\\mathbb{R}^3\\times \\mathbb{R}$, which opens up mechanisms for continuous geometric transformations. Examples include evolving an initial surface towards general vector fields, smoothing and sharpening using the mean curvature equation, and interpolations of initial conditions.  The network training considers two constraints. A data term is responsible for fitting the initial condition to the corresponding time instant, usually $\\mathbb{R}^3 \\times \\{0\\}$. Then, a LSE term forces the network to approximate the underlying geometric evolution given by the LSE, without any supervision. The network can also be initialized based on previously trained initial conditions, resulting in faster convergence compared to the standard approach.",
    "path": "papers/22/01/2201.09636.json",
    "total_tokens": 883,
    "translated_title": "神经隐式曲面演变",
    "translated_abstract": "本文研究使用平滑神经网络来建模隐式曲面在水平集方程下的动态变化。为此，它将神经隐式曲面的表示扩展到时空 $\\mathbb{R}^3\\times \\mathbb{R}$，从而为连续几何变换提供了机制。例子包括将初始曲面演化为一般的向量场，使用平均曲率方程进行平滑和尖锐化，以及使用初始条件进行插值。网络训练考虑两个约束。数据项负责将初始条件适配到相应的时间点，通常为 $\\mathbb{R}^3 \\times \\{0\\}$。然后，水平集方程项迫使网络逼近水平集方程给出的底层几何演化，无需任何监督。网络还可以基于先前训练过的初始条件进行初始化，与标准方法相比，收敛速度更快。",
    "tldr": "本文研究了神经网络在建模隐式曲面动态变化方面的应用，将其扩展到时空维度，实现了连续几何变换。通过考虑数据拟合和水平集方程的约束，网络能够快速收敛并逼近底层几何演化。",
    "en_tdlr": "This work investigates the use of smooth neural networks for modeling dynamic variations of implicit surfaces under the level set equation, extending the representation to the space-time domain. By considering data fitting and level set equation constraints, the network can quickly converge and approximate the underlying geometric evolution."
}