{
    "title": "Efficiently Disentangle Causal Representations. (arXiv:2201.01942v2 [cs.LG] UPDATED)",
    "abstract": "This paper proposes an efficient approach to learning disentangled representations with causal mechanisms based on the difference of conditional probabilities in original and new distributions. We approximate the difference with models' generalization abilities so that it fits in the standard machine learning framework and can be efficiently computed. In contrast to the state-of-the-art approach, which relies on the learner's adaptation speed to new distribution, the proposed approach only requires evaluating the model's generalization ability. We provide a theoretical explanation for the advantage of the proposed method, and our experiments show that the proposed technique is 1.9--11.0$\\times$ more sample efficient and 9.4--32.4 times quicker than the previous method on various tasks. The source code is available at \\url{https://github.com/yuanpeng16/EDCR}.",
    "link": "http://arxiv.org/abs/2201.01942",
    "context": "Title: Efficiently Disentangle Causal Representations. (arXiv:2201.01942v2 [cs.LG] UPDATED)\nAbstract: This paper proposes an efficient approach to learning disentangled representations with causal mechanisms based on the difference of conditional probabilities in original and new distributions. We approximate the difference with models' generalization abilities so that it fits in the standard machine learning framework and can be efficiently computed. In contrast to the state-of-the-art approach, which relies on the learner's adaptation speed to new distribution, the proposed approach only requires evaluating the model's generalization ability. We provide a theoretical explanation for the advantage of the proposed method, and our experiments show that the proposed technique is 1.9--11.0$\\times$ more sample efficient and 9.4--32.4 times quicker than the previous method on various tasks. The source code is available at \\url{https://github.com/yuanpeng16/EDCR}.",
    "path": "papers/22/01/2201.01942.json",
    "total_tokens": 890,
    "translated_title": "高效地解开因果表示交织问题",
    "translated_abstract": "本文提出了一种基于原始分布和新分布的条件概率之差的因果机制学习分离表示的高效方法。我们利用模型的泛化能力来逼近这种差异，使其适应标准的机器学习框架并能够高效地计算。与现有方法相比，该方法只需要评估模型的泛化能力，而不依赖于学习者对新分布的适应速度。我们为所提出方法的优势提供了理论解释，实验结果表明，所提出的技术在各种任务上比先前方法更节约样本，速度更快，分别提升了1.9-11.0倍和9.4-32.4倍。源代码可在 \\url{https://github.com/yuanpeng16/EDCR} 找到。",
    "tldr": "本文提出了一种高效的方法来学习具有因果机制的分离表示，通过估计原始和新分布之间的条件概率差异，并利用模型的泛化能力进行逼近。与现有方法相比，该方法只需要评估模型的泛化能力，而不需要依赖学习者对新分布的适应速度。实验证明该方法在各种任务上更加样本高效且速度更快。",
    "en_tdlr": "This paper proposes an efficient method for learning disentangled representations with causal mechanisms by approximating the difference of conditional probabilities in original and new distributions using models' generalization abilities. The proposed method only requires evaluating the model's generalization ability, unlike existing methods that rely on the learner's adaptation speed to new distribution. Experimental results demonstrate that the proposed technique is more sample efficient and faster on various tasks."
}