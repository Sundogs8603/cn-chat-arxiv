{
    "title": "ALA: Naturalness-aware Adversarial Lightness Attack. (arXiv:2201.06070v2 [cs.CV] UPDATED)",
    "abstract": "Most researchers have tried to enhance the robustness of DNNs by revealing and repairing the vulnerability of DNNs with specialized adversarial examples. Parts of the attack examples have imperceptible perturbations restricted by Lp norm. However, due to their high-frequency property, the adversarial examples can be defended by denoising methods and are hard to realize in the physical world. To avoid the defects, some works have proposed unrestricted attacks to gain better robustness and practicality. It is disappointing that these examples usually look unnatural and can alert the guards. In this paper, we propose Adversarial Lightness Attack (ALA), a white-box unrestricted adversarial attack that focuses on modifying the lightness of the images. The shape and color of the samples, which are crucial to human perception, are barely influenced. To obtain adversarial examples with a high attack success rate, we propose unconstrained enhancement in terms of the light and shade relationship",
    "link": "http://arxiv.org/abs/2201.06070",
    "context": "Title: ALA: Naturalness-aware Adversarial Lightness Attack. (arXiv:2201.06070v2 [cs.CV] UPDATED)\nAbstract: Most researchers have tried to enhance the robustness of DNNs by revealing and repairing the vulnerability of DNNs with specialized adversarial examples. Parts of the attack examples have imperceptible perturbations restricted by Lp norm. However, due to their high-frequency property, the adversarial examples can be defended by denoising methods and are hard to realize in the physical world. To avoid the defects, some works have proposed unrestricted attacks to gain better robustness and practicality. It is disappointing that these examples usually look unnatural and can alert the guards. In this paper, we propose Adversarial Lightness Attack (ALA), a white-box unrestricted adversarial attack that focuses on modifying the lightness of the images. The shape and color of the samples, which are crucial to human perception, are barely influenced. To obtain adversarial examples with a high attack success rate, we propose unconstrained enhancement in terms of the light and shade relationship",
    "path": "papers/22/01/2201.06070.json",
    "total_tokens": 922,
    "translated_title": "ALA: 具有自然感知的对抗亮度攻击",
    "translated_abstract": "大多数研究人员通过揭示和修复深度神经网络(DNN)的脆弱性来提高其鲁棒性，并使用专门的对抗性示例。攻击样本的部分是受Lp范数限制的几乎不可感知的扰动。然而，由于其高频属性，对抗性示例可以通过去噪方法进行防御，并且很难在物理世界中实现。为了避免这些缺陷，有些工作提出了无限制攻击来获得更好的鲁棒性和实用性。令人失望的是，这些示例通常看起来不自然，会引起警觉。在本文中，我们提出了对抗亮度攻击(ALA)，一种针对修改图像亮度的白盒无限制对抗攻击。对于人类感知至关重要的样本的形状和颜色几乎没有受到影响。为了获得具有高攻击成功率的对抗性示例，我们在亮度和阴影关系方面提出了无约束的增强方法。",
    "tldr": "本文提出了一种针对图像亮度的白盒无限制对抗攻击方法，通过修改图像的亮度来攻击深度神经网络，而对人类感知的形状和颜色几乎没有影响。",
    "en_tdlr": "This paper proposes a white-box unrestricted adversarial attack method that focuses on modifying the lightness of images to attack deep neural networks, while barely affecting the shape and color that are crucial to human perception."
}