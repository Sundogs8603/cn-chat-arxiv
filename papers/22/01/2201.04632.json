{
    "title": "The Concept of Criticality in AI Safety. (arXiv:2201.04632v2 [cs.HC] UPDATED)",
    "abstract": "When AI agents don't align their actions with human values they may cause serious harm. One way to solve the value alignment problem is by including a human operator who monitors all of the agent's actions. Despite the fact, that this solution guarantees maximal safety, it is very inefficient, since it requires the human operator to dedicate all of his attention to the agent. In this paper, we propose a much more efficient solution that allows an operator to be engaged in other activities without neglecting his monitoring task. In our approach the AI agent requests permission from the operator only for critical actions, that is, potentially harmful actions. We introduce the concept of critical actions with respect to AI safety and discuss how to build a model that measures action criticality. We also discuss how the operator's feedback could be used to make the agent smarter.",
    "link": "http://arxiv.org/abs/2201.04632",
    "context": "Title: The Concept of Criticality in AI Safety. (arXiv:2201.04632v2 [cs.HC] UPDATED)\nAbstract: When AI agents don't align their actions with human values they may cause serious harm. One way to solve the value alignment problem is by including a human operator who monitors all of the agent's actions. Despite the fact, that this solution guarantees maximal safety, it is very inefficient, since it requires the human operator to dedicate all of his attention to the agent. In this paper, we propose a much more efficient solution that allows an operator to be engaged in other activities without neglecting his monitoring task. In our approach the AI agent requests permission from the operator only for critical actions, that is, potentially harmful actions. We introduce the concept of critical actions with respect to AI safety and discuss how to build a model that measures action criticality. We also discuss how the operator's feedback could be used to make the agent smarter.",
    "path": "papers/22/01/2201.04632.json",
    "total_tokens": 841,
    "translated_title": "人工智能安全中的重要性概念",
    "translated_abstract": "当AI代理没有与人类价值观保持一致时，他们可能会造成严重的伤害。解决价值观对齐问题的一种方法是包括一个人类操作员监控所有代理的活动。尽管这种解决方案保证了最大的安全性，但它非常低效，因为它要求人类操作员将所有注意力都专注于代理。在本文中，我们提出了一个更加高效的解决方案，使得操作员可以参与其他活动而不忽略监控任务。在我们的方法中，AI代理仅请求关键操作的许可，也就是潜在的有害操作。我们引入了与AI安全相关的关键操作概念，并讨论如何构建一个度量行动关键性的模型。我们还讨论了如何利用操作员的反馈使代理更加智能化。",
    "tldr": "本文提出了一种在AI安全领域中的重要性概念——关键操作，并提出了一种更加高效的解决方案，使操作员可以参与其他活动而不忽略监控任务。AI代理仅请求关键操作的许可，并用操作员的反馈使代理更加智能化。",
    "en_tdlr": "This paper introduces the concept of critical actions in AI safety and proposes a more efficient solution, where the AI agent requests permission from the operator only for critical actions, and utilizes the operator's feedback to improve its intelligence."
}