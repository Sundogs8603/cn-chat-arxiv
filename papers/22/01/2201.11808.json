{
    "title": "LAP: An Attention-Based Module for Concept Based Self-Interpretation and Knowledge Injection in Convolutional Neural Networks. (arXiv:2201.11808v5 [cs.CV] UPDATED)",
    "abstract": "Despite the state-of-the-art performance of deep convolutional neural networks, they are susceptible to bias and malfunction in unseen situations. Moreover, the complex computation behind their reasoning is not human-understandable to develop trust. External explainer methods have tried to interpret network decisions in a human-understandable way, but they are accused of fallacies due to their assumptions and simplifications. On the other side, the inherent self-interpretability of models, while being more robust to the mentioned fallacies, cannot be applied to the already trained models. In this work, we propose a new attention-based pooling layer, called Local Attention Pooling (LAP), that accomplishes self-interpretability and the possibility for knowledge injection without performance loss. The module is easily pluggable into any convolutional neural network, even the already trained ones. We have defined a weakly supervised training scheme to learn the distinguishing features in d",
    "link": "http://arxiv.org/abs/2201.11808",
    "context": "Title: LAP: An Attention-Based Module for Concept Based Self-Interpretation and Knowledge Injection in Convolutional Neural Networks. (arXiv:2201.11808v5 [cs.CV] UPDATED)\nAbstract: Despite the state-of-the-art performance of deep convolutional neural networks, they are susceptible to bias and malfunction in unseen situations. Moreover, the complex computation behind their reasoning is not human-understandable to develop trust. External explainer methods have tried to interpret network decisions in a human-understandable way, but they are accused of fallacies due to their assumptions and simplifications. On the other side, the inherent self-interpretability of models, while being more robust to the mentioned fallacies, cannot be applied to the already trained models. In this work, we propose a new attention-based pooling layer, called Local Attention Pooling (LAP), that accomplishes self-interpretability and the possibility for knowledge injection without performance loss. The module is easily pluggable into any convolutional neural network, even the already trained ones. We have defined a weakly supervised training scheme to learn the distinguishing features in d",
    "path": "papers/22/01/2201.11808.json",
    "total_tokens": 968,
    "translated_title": "LAP: 基于注意力的模块用于卷积神经网络中基于概念的自解释和知识注入",
    "translated_abstract": "尽管深度卷积神经网络具有最先进的性能，但它们在未知情况下容易受到偏见和故障的影响。此外，它们推理背后的复杂计算对于人类来说并不可理解，难以建立信任。外部解释方法试图以人类可理解的方式解释网络决策，但由于其假设和简化而被指责存在谬误。与此相反，模型的固有自解释性虽然更抗坚持上述谬误，但无法应用于已经训练过的模型。在这项工作中，我们提出了一种新的基于注意力的汇聚层，称为局部注意力汇聚（LAP），它可以实现自解释性和可能性，而不会丧失性能。该模块可以轻松地插入任何卷积神经网络中，包括已经训练好的网络。我们提供了一种弱监督训练方案，以学习区分特征。",
    "tldr": "本研究提出了一种新的基于注意力的汇聚层，称为LAP，它在卷积神经网络中实现了自解释性和知识注入的可能性，而不会降低性能。该模块可以轻松地插入任何卷积神经网络中，甚至是已经训练好的网络。"
}