{
    "title": "Can't Steal? Cont-Steal! Contrastive Stealing Attacks Against Image Encoders. (arXiv:2201.07513v2 [cs.CR] UPDATED)",
    "abstract": "Self-supervised representation learning techniques have been developing rapidly to make full use of unlabeled images. They encode images into rich features that are oblivious to downstream tasks. Behind their revolutionary representation power, the requirements for dedicated model designs and a massive amount of computation resources expose image encoders to the risks of potential model stealing attacks - a cheap way to mimic the well-trained encoder performance while circumventing the demanding requirements. Yet conventional attacks only target supervised classifiers given their predicted labels and/or posteriors, which leaves the vulnerability of unsupervised encoders unexplored.  In this paper, we first instantiate the conventional stealing attacks against encoders and demonstrate their severer vulnerability compared with downstream classifiers. To better leverage the rich representation of encoders, we further propose Cont-Steal, a contrastive-learning-based attack, and validate it",
    "link": "http://arxiv.org/abs/2201.07513",
    "context": "Title: Can't Steal? Cont-Steal! Contrastive Stealing Attacks Against Image Encoders. (arXiv:2201.07513v2 [cs.CR] UPDATED)\nAbstract: Self-supervised representation learning techniques have been developing rapidly to make full use of unlabeled images. They encode images into rich features that are oblivious to downstream tasks. Behind their revolutionary representation power, the requirements for dedicated model designs and a massive amount of computation resources expose image encoders to the risks of potential model stealing attacks - a cheap way to mimic the well-trained encoder performance while circumventing the demanding requirements. Yet conventional attacks only target supervised classifiers given their predicted labels and/or posteriors, which leaves the vulnerability of unsupervised encoders unexplored.  In this paper, we first instantiate the conventional stealing attacks against encoders and demonstrate their severer vulnerability compared with downstream classifiers. To better leverage the rich representation of encoders, we further propose Cont-Steal, a contrastive-learning-based attack, and validate it",
    "path": "papers/22/01/2201.07513.json",
    "total_tokens": 812,
    "translated_title": "无法盗窃？尝试对抗窃听！针对图像编码器的对比窃听攻击",
    "translated_abstract": "自我监督的表示学习技术正在快速发展，以充分利用未标记的图像。它们将图像编码为丰富的特征，这些特征对下游任务是不可知的。然而，为了实现其革命性的表示能力，需要专用的模型设计和大量的计算资源，这使图像编码器面临着潜在的模型盗窃攻击风险，这是一种廉价的方式，可以模仿经过充分训练的编码器性能而规避苛刻的要求。但是传统攻击仅针对于有标签和/或后验的受监督分类器，因此未受监督的编码器的漏洞尚未得到探索。",
    "tldr": "本文针对未受监督编码器面临的盗窃攻击漏洞，提出了基于对比学习的新型攻击方法 Cont-Steal，以更好地利用编码器的丰富特征。",
    "en_tdlr": "This paper proposes a novel contrastive-learning-based attack, called Cont-Steal, to better exploit the rich features of image encoders and addresses the vulnerability of unsupervised encoders to potential model stealing attacks."
}