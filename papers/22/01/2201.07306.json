{
    "title": "Bregman Deviations of Generic Exponential Families. (arXiv:2201.07306v4 [cs.LG] UPDATED)",
    "abstract": "We revisit the method of mixture technique, also known as the Laplace method, to study the concentration phenomenon in generic exponential families. Combining the properties of Bregman divergence associated with log-partition function of the family with the method of mixtures for super-martingales, we establish a generic bound controlling the Bregman divergence between the parameter of the family and a finite sample estimate of the parameter. Our bound is time-uniform and makes appear a quantity extending the classical information gain to exponential families, which we call the Bregman information gain. For the practitioner, we instantiate this novel bound to several classical families, e.g., Gaussian, Bernoulli, Exponential, Weibull, Pareto, Poisson and Chi-square yielding explicit forms of the confidence sets and the Bregman information gain. We further numerically compare the resulting confidence bounds to state-of-the-art alternatives for time-uniform concentration and show that th",
    "link": "http://arxiv.org/abs/2201.07306",
    "context": "Title: Bregman Deviations of Generic Exponential Families. (arXiv:2201.07306v4 [cs.LG] UPDATED)\nAbstract: We revisit the method of mixture technique, also known as the Laplace method, to study the concentration phenomenon in generic exponential families. Combining the properties of Bregman divergence associated with log-partition function of the family with the method of mixtures for super-martingales, we establish a generic bound controlling the Bregman divergence between the parameter of the family and a finite sample estimate of the parameter. Our bound is time-uniform and makes appear a quantity extending the classical information gain to exponential families, which we call the Bregman information gain. For the practitioner, we instantiate this novel bound to several classical families, e.g., Gaussian, Bernoulli, Exponential, Weibull, Pareto, Poisson and Chi-square yielding explicit forms of the confidence sets and the Bregman information gain. We further numerically compare the resulting confidence bounds to state-of-the-art alternatives for time-uniform concentration and show that th",
    "path": "papers/22/01/2201.07306.json",
    "total_tokens": 968,
    "translated_title": "一般指数族的Bregman偏差",
    "translated_abstract": "我们重新审视了混合技术方法，也称为拉普拉斯方法，以研究一般指数族中的浓度现象。将与家族的对数分区函数相关联的Bregman差异的特性与超马丁格尔混合方法相结合，我们建立了一个通用的界限，控制家族的参数与参数的有限样本估计之间的Bregman差异。我们的界限是时间均匀的，并且出现了一种扩展经典信息增益到指数族的量，我们称之为Bregman信息增益。对于实践者，我们将这个新颖的界限实例化到几个经典家族中，例如，高斯、伯努利、指数、韦伯、帕累托、泊松和卡方，得到了置信区间和Bregman信息增益的明确形式。我们进一步数值比较了与时间均匀浓度的最新替代方法得到的置信界限，并表明th。",
    "tldr": "我们通过结合Bregman差异和超马丁格尔混合方法，建立了一种通用边界，控制指数族参数与参数有限样本估计之间的Bregman差异，该边界是时间均匀的，并引入了Bregman信息增益。我们将此边界应用于多个经典指数族，并得到了置信区间和Bregman信息增益的明确形式。",
    "en_tdlr": "We establish a generic bound controlling the Bregman deviation between the parameter of a generic exponential family and a finite sample estimate of the parameter using the method of mixtures and Bregman divergence. Our bound is time-uniform and introduces a quantity called the Bregman information gain. Applying this bound to various classical families, we obtain explicit forms of confidence intervals and the Bregman information gain."
}