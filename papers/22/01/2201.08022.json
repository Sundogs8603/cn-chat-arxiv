{
    "title": "HEAM: High-Efficiency Approximate Multiplier Optimization for Deep Neural Networks. (arXiv:2201.08022v4 [cs.AR] UPDATED)",
    "abstract": "We propose an optimization method for the automatic design of approximate multipliers, which minimizes the average error according to the operand distributions. Our multiplier achieves up to 50.24% higher accuracy than the best reproduced approximate multiplier in DNNs, with 15.76% smaller area, 25.05% less power consumption, and 3.50% shorter delay. Compared with an exact multiplier, our multiplier reduces the area, power consumption, and delay by 44.94%, 47.63%, and 16.78%, respectively, with negligible accuracy losses. The tested DNN accelerator modules with our multiplier obtain up to 18.70% smaller area and 9.99% less power consumption than the original modules.",
    "link": "http://arxiv.org/abs/2201.08022",
    "context": "Title: HEAM: High-Efficiency Approximate Multiplier Optimization for Deep Neural Networks. (arXiv:2201.08022v4 [cs.AR] UPDATED)\nAbstract: We propose an optimization method for the automatic design of approximate multipliers, which minimizes the average error according to the operand distributions. Our multiplier achieves up to 50.24% higher accuracy than the best reproduced approximate multiplier in DNNs, with 15.76% smaller area, 25.05% less power consumption, and 3.50% shorter delay. Compared with an exact multiplier, our multiplier reduces the area, power consumption, and delay by 44.94%, 47.63%, and 16.78%, respectively, with negligible accuracy losses. The tested DNN accelerator modules with our multiplier obtain up to 18.70% smaller area and 9.99% less power consumption than the original modules.",
    "path": "papers/22/01/2201.08022.json",
    "total_tokens": 836,
    "translated_title": "HEAM: 高效近似乘法器优化的深度神经网络",
    "translated_abstract": "我们提出了一种自动设计近似乘法器的优化方法，根据操作数分布最小化平均误差。我们的乘法器在DNN中比最佳复制的近似乘法器高达50.24%的准确性，同时面积减小15.76%，功耗减少25.05%，延迟缩短3.50%。与精确乘法器相比，我们的乘法器分别减少了44.94%的面积、47.63%的功耗和16.78%的延迟，几乎没有准确性损失。使用我们的乘法器进行测试的DNN加速器模块比原始模块面积减小了18.70%，功耗减少了9.99%。",
    "tldr": "本文提出了一种优化方法，用于自动设计近似乘法器，并根据操作数分布来最小化平均误差。所提乘法器在DNN中达到了比最佳复制的近似乘法器高达50.24%的准确性，同时具有较小的面积、功耗和延迟。",
    "en_tdlr": "This paper proposes an optimization method for automatically designing approximate multipliers, minimizing average error based on operand distributions. The multiplier achieved up to 50.24% higher accuracy than the best reproduced approximate multiplier in DNNs, with smaller area, power consumption, and delay. It also showed significant reductions in area and power consumption when tested in DNN accelerator modules."
}