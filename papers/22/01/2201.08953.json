{
    "title": "FedMed-GAN: Federated Domain Translation on Unsupervised Cross-Modality Brain Image Synthesis. (arXiv:2201.08953v3 [cs.CV] UPDATED)",
    "abstract": "Utilizing multi-modal neuroimaging data has been proved to be effective to investigate human cognitive activities and certain pathologies. However, it is not practical to obtain the full set of paired neuroimaging data centrally since the collection faces several constraints, e.g., high examination cost, long acquisition time, and image corruption. In addition, these data are dispersed into different medical institutions and thus cannot be aggregated for centralized training considering the privacy issues. There is a clear need to launch a federated learning and facilitate the integration of the dispersed data from different institutions. In this paper, we propose a new benchmark for federated domain translation on unsupervised brain image synthesis (termed as FedMed-GAN) to bridge the gap between federated learning and medical GAN. FedMed-GAN mitigates the mode collapse without sacrificing the performance of generators, and is widely applied to different proportions of unpaired and pa",
    "link": "http://arxiv.org/abs/2201.08953",
    "context": "Title: FedMed-GAN: Federated Domain Translation on Unsupervised Cross-Modality Brain Image Synthesis. (arXiv:2201.08953v3 [cs.CV] UPDATED)\nAbstract: Utilizing multi-modal neuroimaging data has been proved to be effective to investigate human cognitive activities and certain pathologies. However, it is not practical to obtain the full set of paired neuroimaging data centrally since the collection faces several constraints, e.g., high examination cost, long acquisition time, and image corruption. In addition, these data are dispersed into different medical institutions and thus cannot be aggregated for centralized training considering the privacy issues. There is a clear need to launch a federated learning and facilitate the integration of the dispersed data from different institutions. In this paper, we propose a new benchmark for federated domain translation on unsupervised brain image synthesis (termed as FedMed-GAN) to bridge the gap between federated learning and medical GAN. FedMed-GAN mitigates the mode collapse without sacrificing the performance of generators, and is widely applied to different proportions of unpaired and pa",
    "path": "papers/22/01/2201.08953.json",
    "total_tokens": 1083,
    "translated_title": "FedMed-GAN: 基于联邦学习的无监督跨模态脑图像合成与翻译",
    "translated_abstract": "利用多模态神经影像数据被证明对于研究人类认知活动和某些疾病很有效。然而，由于高昂的检查成本、长时间的获取时间和图像损坏等多种限制，集中获得完整配对的神经影像数据是不现实的。此外，这些数据分散在不同的医疗机构中，由于隐私问题无法进行中央集中培训。因此，迫切需要开展联邦学习，促进来自不同机构的分散数据的集成。本文提出了一个新的基准方法-FedMed-GAN，用于联邦领域翻译和无监督脑图像合成上，弥补了联邦学习和医疗GAN之间的差距。FedMed-GAN通过减轻模式崩溃现象而不损失生成器的性能，并广泛应用于联邦设置下不配对、配对数据集的不同比例。实验结果表明，我们的方法在公共数据集和真实临床数据上都达到了最先进的性能，证明了其在无监督跨模态脑图像合成方面的有效性。",
    "tldr": "本文提出了一种新的基准方法FedMed-GAN: 用于联邦学习和医疗GAN之间的无监督脑图像合成和翻译,具有模式崩溃现象小、数据性能高等优点，广泛适用于不配对和配对数据集的联邦训练。",
    "en_tdlr": "This paper proposes a new benchmark FedMed-GAN for unsupervised cross-modality brain image synthesis in a federated learning setting, which bridges the gap between federated learning and medical GAN. FedMed-GAN mitigates the mode collapse while maintaining high data performance and is widely applicable to various proportions of unpaired and paired datasets in a federated setting. The experimental results demonstrate its effectiveness in both public datasets and real clinical data."
}