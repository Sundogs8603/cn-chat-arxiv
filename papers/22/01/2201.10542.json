{
    "title": "Augmented RBMLE-UCB Approach for Adaptive Control of Linear Quadratic Systems. (arXiv:2201.10542v2 [math.OC] UPDATED)",
    "abstract": "We consider the problem of controlling an unknown stochastic linear system with quadratic costs - called the adaptive LQ control problem. We re-examine an approach called ''Reward Biased Maximum Likelihood Estimate'' (RBMLE) that was proposed more than forty years ago, and which predates the ''Upper Confidence Bound'' (UCB) method as well as the definition of ''regret'' for bandit problems. It simply added a term favoring parameters with larger rewards to the criterion for parameter estimation. We show how the RBMLE and UCB methods can be reconciled, and thereby propose an Augmented RBMLE-UCB algorithm that combines the penalty of the RBMLE method with the constraints of the UCB method, uniting the two approaches to optimism in the face of uncertainty. We establish that theoretically, this method retains $\\Tilde{\\mathcal{O}}(\\sqrt{T})$ regret, the best-known so far. We further compare the empirical performance of the proposed Augmented RBMLE-UCB and the standard RBMLE (without the augm",
    "link": "http://arxiv.org/abs/2201.10542",
    "context": "Title: Augmented RBMLE-UCB Approach for Adaptive Control of Linear Quadratic Systems. (arXiv:2201.10542v2 [math.OC] UPDATED)\nAbstract: We consider the problem of controlling an unknown stochastic linear system with quadratic costs - called the adaptive LQ control problem. We re-examine an approach called ''Reward Biased Maximum Likelihood Estimate'' (RBMLE) that was proposed more than forty years ago, and which predates the ''Upper Confidence Bound'' (UCB) method as well as the definition of ''regret'' for bandit problems. It simply added a term favoring parameters with larger rewards to the criterion for parameter estimation. We show how the RBMLE and UCB methods can be reconciled, and thereby propose an Augmented RBMLE-UCB algorithm that combines the penalty of the RBMLE method with the constraints of the UCB method, uniting the two approaches to optimism in the face of uncertainty. We establish that theoretically, this method retains $\\Tilde{\\mathcal{O}}(\\sqrt{T})$ regret, the best-known so far. We further compare the empirical performance of the proposed Augmented RBMLE-UCB and the standard RBMLE (without the augm",
    "path": "papers/22/01/2201.10542.json",
    "total_tokens": 1044,
    "translated_title": "基于增强式RBMLE-UCB方法的线性二次系统自适应控制研究",
    "translated_abstract": "本文考虑了控制一个未知随机线性系统，该系统具有二次代价，即自适应LQ控制问题。我们重新审视了一个称为“奖励偏向最大似然估计”(RBMLE) 的方法，该方法提出了40多年前，在“上限置信区间法”(UCB)方法和针对赌博机问题的“遗憾”的定义之前。它简单地为参数估计的标准添加了一个倾向于具有更大奖励的参数的项。我们展示了如何协调RBMLE和UCB方法，并因此提出了一种增强的RBMLE-UCB算法，它将RBMLE方法的惩罚与UCB方法的约束相结合，将两种面对不确定性的方法统一了起来。我们理论上证明了，这种方法保持了迄今为止最好的$\\Tilde{\\mathcal{O}}(\\sqrt{T})$遗憾值。我们进一步比较了所提出的增强式RBMLE-UCB和标准RBMLE(不带增强UCB方法)在模拟系统上的实证表现，并证明了增强算法在噪声较高或样本数较少时表现更优。",
    "tldr": "本文提出一种增强式RBMLE-UCB算法，将RBMLE方法的惩罚与UCB方法的约束相结合，解决了自适应LQ控制问题。在噪声较高或样本数较少时，该算法表现更优。",
    "en_tdlr": "This paper proposes an augmented RBMLE-UCB algorithm that combines the penalty of the RBMLE method with the constraints of the UCB method, solving the adaptive LQ control problem. The empirical results show that the augmented algorithm outperforms the standard RBMLE when the noise is high or when a small number of samples are availab"
}