{
    "title": "Consistent 3D Hand Reconstruction in Video via self-supervised Learning. (arXiv:2201.09548v2 [cs.CV] UPDATED)",
    "abstract": "We present a method for reconstructing accurate and consistent 3D hands from a monocular video. We observe that detected 2D hand keypoints and the image texture provide important cues about the geometry and texture of the 3D hand, which can reduce or even eliminate the requirement on 3D hand annotation. Thus we propose ${\\rm {S}^{2}HAND}$, a self-supervised 3D hand reconstruction model, that can jointly estimate pose, shape, texture, and the camera viewpoint from a single RGB input through the supervision of easily accessible 2D detected keypoints. We leverage the continuous hand motion information contained in the unlabeled video data and propose ${\\rm {S}^{2}HAND(V)}$, which uses a set of weights shared ${\\rm {S}^{2}HAND}$ to process each frame and exploits additional motion, texture, and shape consistency constrains to promote more accurate hand poses and more consistent shapes and textures. Experiments on benchmark datasets demonstrate that our self-supervised approach produces com",
    "link": "http://arxiv.org/abs/2201.09548",
    "context": "Title: Consistent 3D Hand Reconstruction in Video via self-supervised Learning. (arXiv:2201.09548v2 [cs.CV] UPDATED)\nAbstract: We present a method for reconstructing accurate and consistent 3D hands from a monocular video. We observe that detected 2D hand keypoints and the image texture provide important cues about the geometry and texture of the 3D hand, which can reduce or even eliminate the requirement on 3D hand annotation. Thus we propose ${\\rm {S}^{2}HAND}$, a self-supervised 3D hand reconstruction model, that can jointly estimate pose, shape, texture, and the camera viewpoint from a single RGB input through the supervision of easily accessible 2D detected keypoints. We leverage the continuous hand motion information contained in the unlabeled video data and propose ${\\rm {S}^{2}HAND(V)}$, which uses a set of weights shared ${\\rm {S}^{2}HAND}$ to process each frame and exploits additional motion, texture, and shape consistency constrains to promote more accurate hand poses and more consistent shapes and textures. Experiments on benchmark datasets demonstrate that our self-supervised approach produces com",
    "path": "papers/22/01/2201.09548.json",
    "total_tokens": 1146,
    "translated_title": "基于自监督学习的视频一致三维手部重建方法",
    "translated_abstract": "本论文提出了一种从单目视频中重建准确且一致的三维手部模型的方法。文章发现检测到的二维手部关键点和图像纹理可以提供关于三维手部几何形状和纹理的重要线索，从而可以减少或甚至消除对三维手部标注的要求。作者提出了一种自监督的三维手部重建模型${\\rm {S}^{2}HAND}$，通过易于获取的二维检测关键点进行监督，在单个RGB输入中共同估计手部姿势、形状、纹理和相机视角。",
    "tldr": "本文提出了一种无需手部标注，在单目视频中基于自监督学习实现的一致三维手部重建方法。",
    "en_tdlr": "This paper proposed a self-supervised approach for consistent 3D hand reconstruction from monocular video without requiring hand annotations, by leveraging the detected 2D hand keypoints and image texture as important cues, and joint estimating pose, shape, texture, and camera viewpoint through supervision of these cues."
}