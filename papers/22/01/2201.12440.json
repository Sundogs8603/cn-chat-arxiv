{
    "title": "Certifying Model Accuracy under Distribution Shifts. (arXiv:2201.12440v3 [cs.LG] UPDATED)",
    "abstract": "Certified robustness in machine learning has primarily focused on adversarial perturbations of the input with a fixed attack budget for each point in the data distribution. In this work, we present provable robustness guarantees on the accuracy of a model under bounded Wasserstein shifts of the data distribution. We show that a simple procedure that randomizes the input of the model within a transformation space is provably robust to distributional shifts under the transformation. Our framework allows the datum-specific perturbation size to vary across different points in the input distribution and is general enough to include fixed-sized perturbations as well. Our certificates produce guaranteed lower bounds on the performance of the model for any (natural or adversarial) shift of the input distribution within a Wasserstein ball around the original distribution. We apply our technique to: (i) certify robustness against natural (non-adversarial) transformations of images such as color ",
    "link": "http://arxiv.org/abs/2201.12440",
    "context": "Title: Certifying Model Accuracy under Distribution Shifts. (arXiv:2201.12440v3 [cs.LG] UPDATED)\nAbstract: Certified robustness in machine learning has primarily focused on adversarial perturbations of the input with a fixed attack budget for each point in the data distribution. In this work, we present provable robustness guarantees on the accuracy of a model under bounded Wasserstein shifts of the data distribution. We show that a simple procedure that randomizes the input of the model within a transformation space is provably robust to distributional shifts under the transformation. Our framework allows the datum-specific perturbation size to vary across different points in the input distribution and is general enough to include fixed-sized perturbations as well. Our certificates produce guaranteed lower bounds on the performance of the model for any (natural or adversarial) shift of the input distribution within a Wasserstein ball around the original distribution. We apply our technique to: (i) certify robustness against natural (non-adversarial) transformations of images such as color ",
    "path": "papers/22/01/2201.12440.json",
    "total_tokens": 892,
    "translated_title": "在分布变化下验证模型准确性",
    "translated_abstract": "机器学习中的认证鲁棒性主要关注数据分布中每个数据点的固定攻击预算下对输入的对抗扰动。本文提出了在数据分布的低阶Wasserstein变换下对模型准确性的可证明鲁棒性保证。我们展示了一种简单的方法，通过在一个转换空间内对模型输入进行随机化，从而在转换下证明其对分布变化具有鲁棒性。我们的框架允许数据特定的扰动大小在输入分布的不同点之间变化，并且也包括固定大小的扰动。我们的证书为原始分布周围的任何（自然或对抗性）输入分布的Wasserstein球内的模型性能提供了确保的下界。我们将我们的技术应用于以下领域：（i）对图像进行自然（非对抗性）转换的鲁棒性认证，例如颜色转换。",
    "tldr": "本文提出了一种针对数据分布变化的模型准确性的可证明鲁棒性保证方法，通过在转换空间内随机化模型输入来实现鲁棒性。该方法适用于不同点之间变化的数据特定的扰动大小，并且能够产生对固定大小扰动的确保下界。",
    "en_tdlr": "This paper presents a provable robustness guarantee for model accuracy under distribution shifts by randomizing model inputs within a transformation space. The method allows for varying perturbation sizes across different points and provides guaranteed lower bounds for fixed-sized perturbations."
}