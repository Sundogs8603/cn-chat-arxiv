{
    "title": "Temporal Detection of Anomalies via Actor-Critic Based Controlled Sensing. (arXiv:2201.00879v2 [cs.LG] UPDATED)",
    "abstract": "We address the problem of monitoring a set of binary stochastic processes and generating an alert when the number of anomalies among them exceeds a threshold. For this, the decision-maker selects and probes a subset of the processes to obtain noisy estimates of their states (normal or anomalous). Based on the received observations, the decisionmaker first determines whether to declare that the number of anomalies has exceeded the threshold or to continue taking observations. When the decision is to continue, it then decides whether to collect observations at the next time instant or defer it to a later time. If it chooses to collect observations, it further determines the subset of processes to be probed. To devise this three-step sequential decision-making process, we use a Bayesian formulation wherein we learn the posterior probability on the states of the processes. Using the posterior probability, we construct a Markov decision process and solve it using deep actor-critic reinforce",
    "link": "http://arxiv.org/abs/2201.00879",
    "context": "Title: Temporal Detection of Anomalies via Actor-Critic Based Controlled Sensing. (arXiv:2201.00879v2 [cs.LG] UPDATED)\nAbstract: We address the problem of monitoring a set of binary stochastic processes and generating an alert when the number of anomalies among them exceeds a threshold. For this, the decision-maker selects and probes a subset of the processes to obtain noisy estimates of their states (normal or anomalous). Based on the received observations, the decisionmaker first determines whether to declare that the number of anomalies has exceeded the threshold or to continue taking observations. When the decision is to continue, it then decides whether to collect observations at the next time instant or defer it to a later time. If it chooses to collect observations, it further determines the subset of processes to be probed. To devise this three-step sequential decision-making process, we use a Bayesian formulation wherein we learn the posterior probability on the states of the processes. Using the posterior probability, we construct a Markov decision process and solve it using deep actor-critic reinforce",
    "path": "papers/22/01/2201.00879.json",
    "total_tokens": 1052,
    "translated_title": "基于Actor-Critic的控制感知方法用于时序异常检测",
    "translated_abstract": "本文讨论了如何在监测一组二元随机过程时，当其中异常个数超过一个阈值时发出警报。为此，决策者选择和检测一组子过程，以获取它们状态（正常或非正常）的噪声估计。基于接受到的观测，决策者首先确定是否宣布异常数超过阈值，或继续观察。当决策是继续时，它会决定是否在下一个时刻收集观测，还是将其推迟到以后的某个时刻。如果它选择收集观测，它还将确定需侦测的子过程组。为了设计这种三步顺序决策过程，我们使用贝叶斯公式学习过程状态的后验概率。使用后验概率，我们构造了一个马尔可夫决策过程，并使用深度的Actor-Critic强化学习方法来解决它。我们提出的方法被称为AC-CST(基于Actor-Critic的控制感知方法用于时序异常检测)，在检测时间数据中的异常情况方面的性能优于现有方法，特别是在信噪比低的情况下。",
    "tldr": "本研究提出了一种基于Actor-Critic的控制感知方法，并使用贝叶斯公式学习过程状态的后验概率，以解决二元随机过程的异常检测问题。其能够优于现有方法，在低信噪比情况下有效地检测时序数据中的异常情况。",
    "en_tdlr": "This paper proposes an Actor-Critic based Controlled Sensing method for detecting anomalies in binary stochastic processes, which outperforms existing approaches, especially in low signal-to-noise ratio scenarios. The method uses Bayesian formulation to learn the posterior probability on the states of the processes and constructs a Markov decision process to solve the problem using deep actor-critic reinforcement learning."
}