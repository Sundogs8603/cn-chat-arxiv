{
    "title": "Tiny, always-on and fragile: Bias propagation through design choices in on-device machine learning workflows. (arXiv:2201.07677v4 [cs.LG] UPDATED)",
    "abstract": "Billions of distributed, heterogeneous and resource constrained IoT devices deploy on-device machine learning (ML) for private, fast and offline inference on personal data. On-device ML is highly context dependent, and sensitive to user, usage, hardware and environment attributes. This sensitivity and the propensity towards bias in ML makes it important to study bias in on-device settings. Our study is one of the first investigations of bias in this emerging domain, and lays important foundations for building fairer on-device ML. We apply a software engineering lens, investigating the propagation of bias through design choices in on-device ML workflows. We first identify reliability bias as a source of unfairness and propose a measure to quantify it. We then conduct empirical experiments for a keyword spotting task to show how complex and interacting technical design choices amplify and propagate reliability bias. Our results validate that design choices made during model training, lik",
    "link": "http://arxiv.org/abs/2201.07677",
    "context": "Title: Tiny, always-on and fragile: Bias propagation through design choices in on-device machine learning workflows. (arXiv:2201.07677v4 [cs.LG] UPDATED)\nAbstract: Billions of distributed, heterogeneous and resource constrained IoT devices deploy on-device machine learning (ML) for private, fast and offline inference on personal data. On-device ML is highly context dependent, and sensitive to user, usage, hardware and environment attributes. This sensitivity and the propensity towards bias in ML makes it important to study bias in on-device settings. Our study is one of the first investigations of bias in this emerging domain, and lays important foundations for building fairer on-device ML. We apply a software engineering lens, investigating the propagation of bias through design choices in on-device ML workflows. We first identify reliability bias as a source of unfairness and propose a measure to quantify it. We then conduct empirical experiments for a keyword spotting task to show how complex and interacting technical design choices amplify and propagate reliability bias. Our results validate that design choices made during model training, lik",
    "path": "papers/22/01/2201.07677.json",
    "total_tokens": 988,
    "translated_title": "微型、始终在线且易碎: 设计选择中的偏见传递与在线机器学习工作流程。",
    "translated_abstract": "数十亿个分布式、异构的 IOT 设备，在个人数据上部署的边缘端机器学习，用于私密、快速且离线推理。边缘端的机器学习高度依赖上下文，对用户、用法、硬件和环境属性非常敏感。这种敏感性和机器学习中偏见的倾向使得研究边缘端机器学习中的偏见非常重要。本研究是对这一新兴领域中偏见研究的首次探索，为构建更公平的边缘端机器学习奠定了重要基础。本文通过软件工程角度调查了边缘端机器学习工作流程中偏见传递的设计选择。我们首先将可靠性偏见确定为不公平性的来源，并提出了一种量化可靠性偏见的方法。然后我们进行了一项关键词检测任务的实验，展示了复杂的和相互作用的技术设计选择如何放大和传播可靠性偏见。我们的研究结果验证了模型训练过程中的设计选择，如模型架构和优化算法，会对可靠性偏见的传播产生巨大影响。",
    "tldr": "本研究调查了边缘端机器学习工作流程中偏见传递的设计选择。结果表明，在模型训练过程中的技术设计选择，如模型架构和优化算法，会放大和传播可靠性偏见。",
    "en_tdlr": "This study investigates the propagation of bias through design choices in on-device machine learning workflows, and finds that technical design choices made during model training, such as model architecture and optimization algorithm, can amplify and propagate reliability bias."
}