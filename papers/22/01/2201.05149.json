{
    "title": "The curse of overparametrization in adversarial training: Precise analysis of robust generalization for random features regression",
    "abstract": "Successful deep learning models often involve training neural network architectures that contain more parameters than the number of training samples. Such overparametrized models have been extensively studied in recent years, and the virtues of overparametrization have been established from both the statistical perspective, via the double-descent phenomenon, and the computational perspective via the structural properties of the optimization landscape.   Despite the remarkable success of deep learning architectures in the overparametrized regime, it is also well known that these models are highly vulnerable to small adversarial perturbations in their inputs. Even when adversarially trained, their performance on perturbed inputs (robust generalization) is considerably worse than their best attainable performance on benign inputs (standard generalization). It is thus imperative to understand how overparametrization fundamentally affects robustness.   In this paper, we will provide a preci",
    "link": "https://arxiv.org/abs/2201.05149",
    "context": "Title: The curse of overparametrization in adversarial training: Precise analysis of robust generalization for random features regression\nAbstract: Successful deep learning models often involve training neural network architectures that contain more parameters than the number of training samples. Such overparametrized models have been extensively studied in recent years, and the virtues of overparametrization have been established from both the statistical perspective, via the double-descent phenomenon, and the computational perspective via the structural properties of the optimization landscape.   Despite the remarkable success of deep learning architectures in the overparametrized regime, it is also well known that these models are highly vulnerable to small adversarial perturbations in their inputs. Even when adversarially trained, their performance on perturbed inputs (robust generalization) is considerably worse than their best attainable performance on benign inputs (standard generalization). It is thus imperative to understand how overparametrization fundamentally affects robustness.   In this paper, we will provide a preci",
    "path": "papers/22/01/2201.05149.json",
    "total_tokens": 884,
    "translated_title": "对对抗训练中过度参数化的诅咒：随机特征回归的鲁棒泛化的精确分析",
    "translated_abstract": "成功的深度学习模型通常涉及训练神经网络架构，其参数数量超过训练样本的数量。过度参数化模型在最近几年中得到了广泛研究，过度参数化的优点从统计学角度（通过双下降现象）和计算角度（通过优化景观的结构特性）已经得到建立。尽管过度参数化的深度学习架构取得了显著的成功，但众所周知，这些模型对其输入中的微小对抗扰动非常脆弱。即使在经过对抗训练的情况下，它们在被扰动的输入上的性能（鲁棒泛化）也明显比在良性输入上的最佳性能（标准泛化）要差。因此，了解过度参数化如何从根本上影响鲁棒性至关重要。",
    "tldr": "本文精确分析了对对抗训练中过度参数化的影响，发现过度参数化模型对微小对抗扰动非常脆弱，显示了鲁棒泛化的性能明显差于标准泛化的性能。",
    "en_tdlr": "This paper provides a precise analysis of the impact of overparametrization in adversarial training, revealing that overparametrized models are highly vulnerable to small adversarial perturbations, resulting in significantly worse performance in robust generalization compared to standard generalization."
}