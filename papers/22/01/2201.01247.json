{
    "title": "Value Functions Factorization with Latent State Information Sharing in Decentralized Multi-Agent Policy Gradients. (arXiv:2201.01247v2 [cs.MA] UPDATED)",
    "abstract": "Value function factorization via centralized training and decentralized execution is promising for solving cooperative multi-agent reinforcement tasks. One of the approaches in this area, QMIX, has become state-of-the-art and achieved the best performance on the StarCraft II micromanagement benchmark. However, the monotonic-mixing of per agent estimates in QMIX is known to restrict the joint action Q-values it can represent, as well as the insufficient global state information for single agent value function estimation, often resulting in suboptimality. To this end, we present LSF-SAC, a novel framework that features a variational inference-based information-sharing mechanism as extra state information to assist individual agents in the value function factorization. We demonstrate that such latent individual state information sharing can significantly expand the power of value function factorization, while fully decentralized execution can still be maintained in LSF-SAC through a soft-",
    "link": "http://arxiv.org/abs/2201.01247",
    "context": "Title: Value Functions Factorization with Latent State Information Sharing in Decentralized Multi-Agent Policy Gradients. (arXiv:2201.01247v2 [cs.MA] UPDATED)\nAbstract: Value function factorization via centralized training and decentralized execution is promising for solving cooperative multi-agent reinforcement tasks. One of the approaches in this area, QMIX, has become state-of-the-art and achieved the best performance on the StarCraft II micromanagement benchmark. However, the monotonic-mixing of per agent estimates in QMIX is known to restrict the joint action Q-values it can represent, as well as the insufficient global state information for single agent value function estimation, often resulting in suboptimality. To this end, we present LSF-SAC, a novel framework that features a variational inference-based information-sharing mechanism as extra state information to assist individual agents in the value function factorization. We demonstrate that such latent individual state information sharing can significantly expand the power of value function factorization, while fully decentralized execution can still be maintained in LSF-SAC through a soft-",
    "path": "papers/22/01/2201.01247.json",
    "total_tokens": 887,
    "translated_title": "带有潜在状态信息共享的分散式多智能体策略梯度中的价值函数分解",
    "translated_abstract": "通过集中训练和分散执行的价值函数分解方法有望解决合作多智能体强化学习任务。在这个领域中，QMIX是一种方法，已经成为最先进的技术，并在StarCraft II微观管理基准测试中取得了最佳性能。然而，QMIX中的单个智能体估计的单调混合被认为限制了它能表示的联合动作Q值的范围，同时全局状态信息不足以进行单个智能体值函数估计，通常会导致结果次优。为此，我们提出了LSF-SAC，这是一个新颖的框架，具有基于变分推理的信息共享机制作为额外的状态信息，以辅助个体智能体在价值函数分解中。我们证明了这种潜在的个体状态信息共享可以显著扩展值函数分解的能力，同时在LSF-SAC中仍然可以通过软限制实现完全分散执行。",
    "tldr": "在QMIX方法的基础上，提出了LSF-SAC框架，其中包括一个潜在信息共享机制，可显著扩展价值函数分解的能力，同时在完全分散执行中保持了有效性。",
    "en_tdlr": "Proposed LSF-SAC framework with a latent information-sharing mechanism based on variational inference that significantly expands the power of value function factorization while maintaining effectiveness in fully decentralized execution."
}