{
    "title": "Optimal and Differentially Private Data Acquisition: Central and Local Mechanisms. (arXiv:2201.03968v2 [cs.GT] UPDATED)",
    "abstract": "We consider a platform's problem of collecting data from privacy sensitive users to estimate an underlying parameter of interest. We formulate this question as a Bayesian-optimal mechanism design problem, in which an individual can share her (verifiable) data in exchange for a monetary reward or services, but at the same time has a (private) heterogeneous privacy cost which we quantify using differential privacy. We consider two popular differential privacy settings for providing privacy guarantees for the users: central and local. In both settings, we establish minimax lower bounds for the estimation error and derive (near) optimal estimators for given heterogeneous privacy loss levels for users. Building on this characterization, we pose the mechanism design problem as the optimal selection of an estimator and payments that will elicit truthful reporting of users' privacy sensitivities. Under a regularity condition on the distribution of privacy sensitivities we develop efficient alg",
    "link": "http://arxiv.org/abs/2201.03968",
    "context": "Title: Optimal and Differentially Private Data Acquisition: Central and Local Mechanisms. (arXiv:2201.03968v2 [cs.GT] UPDATED)\nAbstract: We consider a platform's problem of collecting data from privacy sensitive users to estimate an underlying parameter of interest. We formulate this question as a Bayesian-optimal mechanism design problem, in which an individual can share her (verifiable) data in exchange for a monetary reward or services, but at the same time has a (private) heterogeneous privacy cost which we quantify using differential privacy. We consider two popular differential privacy settings for providing privacy guarantees for the users: central and local. In both settings, we establish minimax lower bounds for the estimation error and derive (near) optimal estimators for given heterogeneous privacy loss levels for users. Building on this characterization, we pose the mechanism design problem as the optimal selection of an estimator and payments that will elicit truthful reporting of users' privacy sensitivities. Under a regularity condition on the distribution of privacy sensitivities we develop efficient alg",
    "path": "papers/22/01/2201.03968.json",
    "total_tokens": 943,
    "translated_title": "最优和差分隐私数据获取: 中央和本地机制",
    "translated_abstract": "我们考虑一个平台从具有隐私敏感性用户那里收集数据以估计感兴趣的基本参数的问题。我们将这个问题形式化为一个贝叶斯最优机制设计问题，在这个问题中，个体可以分享她的（可验证的）数据以换取货币奖励或服务，但同时具有（私密的）异质隐私成本，我们用差分隐私来量化。我们考虑两种常见的差分隐私设置来为用户提供隐私保证：中央和本地。在两种设置中，我们建立了估计误差的最小二乘下界，并根据给定的不同隐私损失水平为用户推导出（近）最优的估计器。基于这个特征，我们将机制设计问题作为选择最优估计器和支付的问题，在用户报告隐私敏感度时引发真实报告。在隐私敏感度分布的正则条件下，我们开发了高效算法",
    "tldr": "本文研究了一个平台从具有隐私敏感性用户那里收集数据以估计参数的问题，并提出了最优机制设计问题，以引发用户的真实报告。通过将问题形式化为贝叶斯最优机制设计问题，并使用差分隐私量化异质隐私成本，我们建立了估计误差的下界并推导出最优的估计器和支付方案。",
    "en_tdlr": "This paper addresses the problem of collecting data from privacy sensitive users to estimate parameters, and proposes an optimal mechanism design problem to elicit truthful reporting from users. By formulating the problem as a Bayesian optimal mechanism design problem and quantifying heterogeneous privacy costs using differential privacy, the paper establishes lower bounds on estimation error and derives optimal estimators and payment schemes."
}