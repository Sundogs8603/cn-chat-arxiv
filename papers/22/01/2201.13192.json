{
    "title": "Uncertainty-aware Pseudo-label Selection for Positive-Unlabeled Learning",
    "abstract": "arXiv:2201.13192v3 Announce Type: replace-cross  Abstract: Positive-unlabeled learning (PUL) aims at learning a binary classifier from only positive and unlabeled training data. Even though real-world applications often involve imbalanced datasets where the majority of examples belong to one class, most contemporary approaches to PUL do not investigate performance in this setting, thus severely limiting their applicability in practice. In this work, we thus propose to tackle the issues of imbalanced datasets and model calibration in a PUL setting through an uncertainty-aware pseudo-labeling procedure (PUUPL): by boosting the signal from the minority class, pseudo-labeling expands the labeled dataset with new samples from the unlabeled set, while explicit uncertainty quantification prevents the emergence of harmful confirmation bias leading to increased predictive performance. Within a series of experiments, PUUPL yields substantial performance gains in highly imbalanced settings while ",
    "link": "https://arxiv.org/abs/2201.13192",
    "context": "Title: Uncertainty-aware Pseudo-label Selection for Positive-Unlabeled Learning\nAbstract: arXiv:2201.13192v3 Announce Type: replace-cross  Abstract: Positive-unlabeled learning (PUL) aims at learning a binary classifier from only positive and unlabeled training data. Even though real-world applications often involve imbalanced datasets where the majority of examples belong to one class, most contemporary approaches to PUL do not investigate performance in this setting, thus severely limiting their applicability in practice. In this work, we thus propose to tackle the issues of imbalanced datasets and model calibration in a PUL setting through an uncertainty-aware pseudo-labeling procedure (PUUPL): by boosting the signal from the minority class, pseudo-labeling expands the labeled dataset with new samples from the unlabeled set, while explicit uncertainty quantification prevents the emergence of harmful confirmation bias leading to increased predictive performance. Within a series of experiments, PUUPL yields substantial performance gains in highly imbalanced settings while ",
    "path": "papers/22/01/2201.13192.json",
    "total_tokens": 861,
    "translated_title": "针对正负样本学习的不确定性感知伪标签选择",
    "translated_abstract": "正负样本学习（PUL）旨在从仅具有正样本和未标记训练数据中学习二元分类器。尽管现实应用通常涉及不平衡数据集，其中大多数示例属于一类，但大多数当代PUL方法并未研究这种情况下的性能，因此严重限制了它们在实践中的适用性。在这项工作中，我们通过一种不确定性感知的伪标签选择过程（PUUPL）来解决不平衡数据集和模型校准问题：通过增强少数类的信号，伪标签从未标记集中扩展了带标签的数据集，而显式的不确定性量化防止了有害的确认偏见的出现，从而提高了预测性能。通过一系列实验，PUUPL在高度不平衡的情况下取得了显著的性能提升。",
    "tldr": "通过不确定性感知的伪标签选择过程，本研究提出了一种解决正负样本学习中不平衡数据集和模型校准问题的方法，实验结果表明在高度不平衡的情况下能显著提高预测性能。",
    "en_tdlr": "This work proposes a method to address the issues of imbalanced datasets and model calibration in positive-unlabeled learning through an uncertainty-aware pseudo-labeling procedure, with experiments demonstrating significant performance gains in highly imbalanced settings."
}