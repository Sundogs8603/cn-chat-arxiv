{
    "title": "Learning Optimal Fair Classification Trees: Trade-offs Between Interpretability, Fairness, and Accuracy. (arXiv:2201.09932v4 [cs.LG] UPDATED)",
    "abstract": "The increasing use of machine learning in high-stakes domains -- where people's livelihoods are impacted -- creates an urgent need for interpretable, fair, and highly accurate algorithms. With these needs in mind, we propose a mixed integer optimization (MIO) framework for learning optimal classification trees -- one of the most interpretable models -- that can be augmented with arbitrary fairness constraints. In order to better quantify the \"price of interpretability\", we also propose a new measure of model interpretability called decision complexity that allows for comparisons across different classes of machine learning models. We benchmark our method against state-of-the-art approaches for fair classification on popular datasets; in doing so, we conduct one of the first comprehensive analyses of the trade-offs between interpretability, fairness, and predictive accuracy. Given a fixed disparity threshold, our method has a price of interpretability of about 4.2 percentage points in t",
    "link": "http://arxiv.org/abs/2201.09932",
    "context": "Title: Learning Optimal Fair Classification Trees: Trade-offs Between Interpretability, Fairness, and Accuracy. (arXiv:2201.09932v4 [cs.LG] UPDATED)\nAbstract: The increasing use of machine learning in high-stakes domains -- where people's livelihoods are impacted -- creates an urgent need for interpretable, fair, and highly accurate algorithms. With these needs in mind, we propose a mixed integer optimization (MIO) framework for learning optimal classification trees -- one of the most interpretable models -- that can be augmented with arbitrary fairness constraints. In order to better quantify the \"price of interpretability\", we also propose a new measure of model interpretability called decision complexity that allows for comparisons across different classes of machine learning models. We benchmark our method against state-of-the-art approaches for fair classification on popular datasets; in doing so, we conduct one of the first comprehensive analyses of the trade-offs between interpretability, fairness, and predictive accuracy. Given a fixed disparity threshold, our method has a price of interpretability of about 4.2 percentage points in t",
    "path": "papers/22/01/2201.09932.json",
    "total_tokens": 902,
    "translated_abstract": "机器学习在高风险领域（可能影响人们的生计）中的应用越来越广泛，迫切需要解释性、公平性和高度准确性的算法。本文提出了一个混合整数优化(MIO)框架，用于学习最优的分类树--最具解释性的模型之一--并且可以增加任意公平性约束。为了更好地量化“解释性的代价”，我们还提出了一种名为“决策复杂度”的新模型解释性度量，可以对不同类别的机器学习模型进行比较。我们在流行数据集上的公平分类的最先进方法中对我们的方法进行了基准测试；在此过程中，我们进行了关于解释性、公平性和预测准确性之间权衡的首次综合分析。在一个固定的差异阈值下，相对于最先进的方法，我们的方法的解释性代价大约为4.2个百分点。",
    "tldr": "本文提出了一个混合整数优化(MIO)框架，用于学习最优的分类树，并且可以增加任意公平性约束。在样本公平性约束下，取得了较高的准确性，但是解释性有一定的代价。",
    "en_tdlr": "This paper proposes a mixed integer optimization (MIO) framework for learning optimal classification trees that can be augmented with arbitrary fairness constraints. The method achieves high accuracy under sample fairness constraints, but at the cost of interpretability."
}