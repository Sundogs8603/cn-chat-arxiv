{
    "title": "Human-Level Control through Directly-Trained Deep Spiking Q-Networks. (arXiv:2201.07211v3 [cs.NE] UPDATED)",
    "abstract": "As the third-generation neural networks, Spiking Neural Networks (SNNs) have great potential on neuromorphic hardware because of their high energy-efficiency. However, Deep Spiking Reinforcement Learning (DSRL), i.e., the Reinforcement Learning (RL) based on SNNs, is still in its preliminary stage due to the binary output and the non-differentiable property of the spiking function. To address these issues, we propose a Deep Spiking Q-Network (DSQN) in this paper. Specifically, we propose a directly-trained deep spiking reinforcement learning architecture based on the Leaky Integrate-and-Fire (LIF) neurons and Deep Q-Network (DQN). Then, we adapt a direct spiking learning algorithm for the Deep Spiking Q-Network. We further demonstrate the advantages of using LIF neurons in DSQN theoretically. Comprehensive experiments have been conducted on 17 top-performing Atari games to compare our method with the state-of-the-art conversion method. The experimental results demonstrate the superiori",
    "link": "http://arxiv.org/abs/2201.07211",
    "context": "Title: Human-Level Control through Directly-Trained Deep Spiking Q-Networks. (arXiv:2201.07211v3 [cs.NE] UPDATED)\nAbstract: As the third-generation neural networks, Spiking Neural Networks (SNNs) have great potential on neuromorphic hardware because of their high energy-efficiency. However, Deep Spiking Reinforcement Learning (DSRL), i.e., the Reinforcement Learning (RL) based on SNNs, is still in its preliminary stage due to the binary output and the non-differentiable property of the spiking function. To address these issues, we propose a Deep Spiking Q-Network (DSQN) in this paper. Specifically, we propose a directly-trained deep spiking reinforcement learning architecture based on the Leaky Integrate-and-Fire (LIF) neurons and Deep Q-Network (DQN). Then, we adapt a direct spiking learning algorithm for the Deep Spiking Q-Network. We further demonstrate the advantages of using LIF neurons in DSQN theoretically. Comprehensive experiments have been conducted on 17 top-performing Atari games to compare our method with the state-of-the-art conversion method. The experimental results demonstrate the superiori",
    "path": "papers/22/01/2201.07211.json",
    "total_tokens": 976,
    "translated_title": "直接训练的深度脉冲Q网络实现人类水平的控制能力",
    "translated_abstract": "作为第三代神经网络，脉冲神经网络（SNN）由于其高能效而在神经形态硬件中具有巨大潜力。然而，基于SNN的深度脉冲强化学习（DSRL）由于脉冲函数输出的二进制以及不可微性等问题，仍处于初步阶段。为了解决这些问题，本文提出了一种深度脉冲Q网络（DSQN）。具体来说，我们基于漏电整流与火（LIF）神经元和深度Q网络（DQN）提出了一个直接训练的深度脉冲强化学习架构。然后，我们为深度脉冲Q网络适应了一种直接脉冲学习算法。我们进一步从理论上论证了在DSQN中使用LIF神经元的优势。我们对17个在Atari游戏中表现最佳的游戏进行了全面实验，将我们的方法与最先进的转换方法进行了比较。实验结果证明了我们方法的优越性。",
    "tldr": "本文提出了一种直接训练的深度脉冲Q网络架构，解决了基于SNN的深度脉冲强化学习中输出二进制和不可微性问题，并在Atari游戏上实现了人类水平的控制能力。",
    "en_tdlr": "This paper proposes a directly-trained deep spiking Q-network architecture to address the binary output and non-differentiable property in Deep Spiking Reinforcement Learning based on Spiking Neural Networks. The proposed method achieves human-level control on 17 Atari games, demonstrating its superiority over state-of-the-art conversion methods."
}