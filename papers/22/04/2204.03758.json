{
    "title": "Compositional Generalization and Decomposition in Neural Program Synthesis. (arXiv:2204.03758v1 [cs.LG] CROSS LISTED)",
    "abstract": "When writing programs, people have the ability to tackle a new complex task by decomposing it into smaller and more familiar subtasks. While it is difficult to measure whether neural program synthesis methods have similar capabilities, what we can measure is whether they compositionally generalize, that is, whether a model that has been trained on the simpler subtasks is subsequently able to solve more complex tasks. In this paper, we focus on measuring the ability of learned program synthesizers to compositionally generalize. We first characterize several different axes along which program synthesis methods would be desired to generalize, e.g., length generalization, or the ability to combine known subroutines in new ways that do not occur in the training data. Based on this characterization, we introduce a benchmark suite of tasks to assess these abilities based on two popular existing datasets, SCAN and RobustFill. Finally, we make first attempts to improve the compositional general",
    "link": "http://arxiv.org/abs/2204.03758",
    "context": "Title: Compositional Generalization and Decomposition in Neural Program Synthesis. (arXiv:2204.03758v1 [cs.LG] CROSS LISTED)\nAbstract: When writing programs, people have the ability to tackle a new complex task by decomposing it into smaller and more familiar subtasks. While it is difficult to measure whether neural program synthesis methods have similar capabilities, what we can measure is whether they compositionally generalize, that is, whether a model that has been trained on the simpler subtasks is subsequently able to solve more complex tasks. In this paper, we focus on measuring the ability of learned program synthesizers to compositionally generalize. We first characterize several different axes along which program synthesis methods would be desired to generalize, e.g., length generalization, or the ability to combine known subroutines in new ways that do not occur in the training data. Based on this characterization, we introduce a benchmark suite of tasks to assess these abilities based on two popular existing datasets, SCAN and RobustFill. Finally, we make first attempts to improve the compositional general",
    "path": "papers/22/04/2204.03758.json",
    "total_tokens": 831,
    "translated_title": "在神经程序综合中的组合泛化和分解",
    "translated_abstract": "当人们编写程序时，他们有能力通过将复杂的任务分解为更小、更熟悉的子任务来解决。虽然测量神经程序综合方法是否具有类似的能力是困难的，但我们可以测量的是它们是否可以以组合方式泛化，即在训练过程中已经训练过简单子任务的模型是否能够解决更复杂的任务。在本文中，我们着重测量了学习的程序综合器以组合泛化的能力。我们首先刻画了程序综合方法应该以不同轴曲线泛化，例如长度泛化，或者结合在训练数据中不存在的新方法组合已知子例程的能力。根据这一刻画，我们根据两个流行的现有数据集SCAN和RobustFill引入了一套任务基准来评估这些能力。最后，我们首次尝试改进组合泛化的方法。",
    "tldr": "本文探讨了神经程序综合方法在组合泛化和分解方面的能力，并提出了一套基准任务来评估这些能力。",
    "en_tdlr": "This paper investigates the ability of neural program synthesis methods in compositional generalization and decomposition, and introduces a benchmark suite of tasks to assess these abilities."
}