{
    "title": "Testing the limits of natural language models for predicting human language judgments. (arXiv:2204.03592v3 [cs.CL] UPDATED)",
    "abstract": "Neural network language models can serve as computational hypotheses about how humans process language. We compared the model-human consistency of diverse language models using a novel experimental approach: controversial sentence pairs. For each controversial sentence pair, two language models disagree about which sentence is more likely to occur in natural text. Considering nine language models (including n-gram, recurrent neural networks, and transformer models), we created hundreds of such controversial sentence pairs by either selecting sentences from a corpus or synthetically optimizing sentence pairs to be highly controversial. Human subjects then provided judgments indicating for each pair which of the two sentences is more likely. Controversial sentence pairs proved highly effective at revealing model failures and identifying models that aligned most closely with human judgments. The most human-consistent model tested was GPT-2, although experiments also revealed significant s",
    "link": "http://arxiv.org/abs/2204.03592",
    "context": "Title: Testing the limits of natural language models for predicting human language judgments. (arXiv:2204.03592v3 [cs.CL] UPDATED)\nAbstract: Neural network language models can serve as computational hypotheses about how humans process language. We compared the model-human consistency of diverse language models using a novel experimental approach: controversial sentence pairs. For each controversial sentence pair, two language models disagree about which sentence is more likely to occur in natural text. Considering nine language models (including n-gram, recurrent neural networks, and transformer models), we created hundreds of such controversial sentence pairs by either selecting sentences from a corpus or synthetically optimizing sentence pairs to be highly controversial. Human subjects then provided judgments indicating for each pair which of the two sentences is more likely. Controversial sentence pairs proved highly effective at revealing model failures and identifying models that aligned most closely with human judgments. The most human-consistent model tested was GPT-2, although experiments also revealed significant s",
    "path": "papers/22/04/2204.03592.json",
    "total_tokens": 861,
    "translated_title": "检验自然语言模型对人类语言判断预测的极限",
    "translated_abstract": "神经网络语言模型可以作为关于人类语言处理方式的计算假设。我们使用一种新颖的实验方法对多样的语言模型进行了模型与人类一致性的比较：争议句对。对于每个争议句对，两个语言模型在哪个句子更可能出现在自然文本中上存在不同意见。考虑到九个语言模型（包括n-gram、循环神经网络和变换器模型），我们通过从语料库中选择句子或者合成优化句对来创建了数百个这样的争议句对。然后，人类受试者提供了判断，指示在每个句对中，哪个句子更可能发生。争议句对被证明极为有效，能够揭示模型的失败和识别与人类判断最为一致的模型。经过测试，最符合人类判断的模型是GPT-2，尽管实验还发现了显著的其他模型。",
    "tldr": "该论文通过对争议句对进行实验比较，发现神经网络语言模型中GPT-2与人类判断最为一致，揭示了模型的失败以及找出最符合人类判断的模型。",
    "en_tdlr": "This paper tests the limits of natural language models for predicting human language judgments and finds that GPT-2 exhibits the highest consistency with human judgments among the models tested, revealing model failures and identifying models that align most closely with human judgments."
}