{
    "title": "Explainable AI via Learning to Optimize. (arXiv:2204.14174v2 [math.OC] UPDATED)",
    "abstract": "Indecipherable black boxes are common in machine learning (ML), but applications increasingly require explainable artificial intelligence (XAI). The core of XAI is to establish transparent and interpretable data-driven algorithms. This work provides concrete tools for XAI in situations where prior knowledge must be encoded and untrustworthy inferences flagged. We use the \"learn to optimize\" (L2O) methodology wherein each inference solves a data-driven optimization problem. Our L2O models are straightforward to implement, directly encode prior knowledge, and yield theoretical guarantees (e.g. satisfaction of constraints). We also propose use of interpretable certificates to verify whether model inferences are trustworthy. Numerical examples are provided in the applications of dictionary-based signal recovery, CT imaging, and arbitrage trading of cryptoassets. Code and additional documentation can be found at https://xai-l2o.research.typal.academy.",
    "link": "http://arxiv.org/abs/2204.14174",
    "context": "Title: Explainable AI via Learning to Optimize. (arXiv:2204.14174v2 [math.OC] UPDATED)\nAbstract: Indecipherable black boxes are common in machine learning (ML), but applications increasingly require explainable artificial intelligence (XAI). The core of XAI is to establish transparent and interpretable data-driven algorithms. This work provides concrete tools for XAI in situations where prior knowledge must be encoded and untrustworthy inferences flagged. We use the \"learn to optimize\" (L2O) methodology wherein each inference solves a data-driven optimization problem. Our L2O models are straightforward to implement, directly encode prior knowledge, and yield theoretical guarantees (e.g. satisfaction of constraints). We also propose use of interpretable certificates to verify whether model inferences are trustworthy. Numerical examples are provided in the applications of dictionary-based signal recovery, CT imaging, and arbitrage trading of cryptoassets. Code and additional documentation can be found at https://xai-l2o.research.typal.academy.",
    "path": "papers/22/04/2204.14174.json",
    "total_tokens": 863,
    "translated_title": "通过学习优化实现可解释人工智能",
    "translated_abstract": "在机器学习中，不易理解的黑盒模型很常见，但越来越多的应用需要可解释的人工智能（XAI）。XAI的核心在于建立透明且可解释的数据驱动算法。本文提供了一种用于XAI的具体工具，可在需要编码先验知识且需要标记不可信推断的情况下使用。我们使用了“学习优化”（L2O）的方法，其中每个推断都解决了一个数据驱动的优化问题。我们的L2O模型易于实现，直接编码先验知识，并产生理论保证（例如满足约束条件）。我们还提出使用可解释的证书，以验证模型推断是否可信。文章还提供了基于字典的信号恢复、CT成像和加密资产套利交易等应用的数值例子。代码和更多文档可在https://xai-l2o.research.typal.academy找到。",
    "tldr": "本文提供了一种在数据驱动模型下用于可解释人工智能的具体工具-L2O方法，通过解决优化问题来实现每个推断，并提出了使用可解释的证书来验证模型推断是否可信。",
    "en_tdlr": "This paper provides concrete tools for explainable artificial intelligence (XAI) using the \"learn to optimize\" (L2O) methodology, which solves an optimization problem for each inference and proposes using interpretable certificates to verify the trustworthiness of the model."
}