{
    "title": "A Dempster-Shafer approach to trustworthy AI with application to fetal brain MRI segmentation. (arXiv:2204.02779v4 [eess.IV] UPDATED)",
    "abstract": "Deep learning models for medical image segmentation can fail unexpectedly and spectacularly for pathological cases and images acquired at different centers than training images, with labeling errors that violate expert knowledge. Such errors undermine the trustworthiness of deep learning models for medical image segmentation. Mechanisms for detecting and correcting such failures are essential for safely translating this technology into clinics and are likely to be a requirement of future regulations on artificial intelligence (AI). In this work, we propose a trustworthy AI theoretical framework and a practical system that can augment any backbone AI system using a fallback method and a fail-safe mechanism based on Dempster-Shafer theory. Our approach relies on an actionable definition of trustworthy AI. Our method automatically discards the voxel-level labeling predicted by the backbone AI that violate expert knowledge and relies on a fallback for those voxels. We demonstrate the effec",
    "link": "http://arxiv.org/abs/2204.02779",
    "context": "Title: A Dempster-Shafer approach to trustworthy AI with application to fetal brain MRI segmentation. (arXiv:2204.02779v4 [eess.IV] UPDATED)\nAbstract: Deep learning models for medical image segmentation can fail unexpectedly and spectacularly for pathological cases and images acquired at different centers than training images, with labeling errors that violate expert knowledge. Such errors undermine the trustworthiness of deep learning models for medical image segmentation. Mechanisms for detecting and correcting such failures are essential for safely translating this technology into clinics and are likely to be a requirement of future regulations on artificial intelligence (AI). In this work, we propose a trustworthy AI theoretical framework and a practical system that can augment any backbone AI system using a fallback method and a fail-safe mechanism based on Dempster-Shafer theory. Our approach relies on an actionable definition of trustworthy AI. Our method automatically discards the voxel-level labeling predicted by the backbone AI that violate expert knowledge and relies on a fallback for those voxels. We demonstrate the effec",
    "path": "papers/22/04/2204.02779.json",
    "total_tokens": 926,
    "translated_title": "一种基于Dempster-Shafer方法的值得信赖的人工智能：胎儿脑MRI分割应用",
    "translated_abstract": "医学图像分割的深度学习模型在病理情况和与训练图像拍摄在不同中心的图像中可能出现意外和显著的失败，其标签错误违反了专家知识。这些错误削弱了深度学习模型在医学图像分割中的可信性。检测和纠正这些失败的机制对于安全地将这项技术应用于临床是必不可少的，并且可能成为未来关于人工智能的法规的要求。在这项工作中，我们提出了一个值得信赖的人工智能理论框架和一个实用系统，可以使用Dempster-Shafer理论的备用方法和故障安全机制来增强任何骨干人工智能系统。我们的方法依赖于对值得信赖的人工智能的可操作定义。我们的方法自动丢弃骨干人工智能预测的体素级标签，这些标签违反了专家知识，并对这些体素使用备用方法。我们展示了该方法的有效性。",
    "tldr": "该论文提出了一种基于Dempster-Shafer方法的值得信赖的人工智能框架和实用系统，用于医学图像分割。通过检测和纠正深度学习模型的失败，增强了其可信性和安全性。",
    "en_tdlr": "This paper presents a trustworthy AI framework and system based on Dempster-Shafer theory for medical image segmentation. It enhances the trustworthiness and safety of deep learning models by detecting and correcting failures."
}