{
    "title": "Marrying Fairness and Explainability in Supervised Learning. (arXiv:2204.02947v3 [cs.LG] UPDATED)",
    "abstract": "Machine learning algorithms that aid human decision-making may inadvertently discriminate against certain protected groups. We formalize direct discrimination as a direct causal effect of the protected attributes on the decisions, while induced discrimination as a change in the causal influence of non-protected features associated with the protected attributes. The measurements of marginal direct effect (MDE) and SHapley Additive exPlanations (SHAP) reveal that state-of-the-art fair learning methods can induce discrimination via association or reverse discrimination in synthetic and real-world datasets. To inhibit discrimination in algorithmic systems, we propose to nullify the influence of the protected attribute on the output of the system, while preserving the influence of remaining features. We introduce and study post-processing methods achieving such objectives, finding that they yield relatively high model accuracy, prevent direct discrimination, and diminishes various disparity",
    "link": "http://arxiv.org/abs/2204.02947",
    "context": "Title: Marrying Fairness and Explainability in Supervised Learning. (arXiv:2204.02947v3 [cs.LG] UPDATED)\nAbstract: Machine learning algorithms that aid human decision-making may inadvertently discriminate against certain protected groups. We formalize direct discrimination as a direct causal effect of the protected attributes on the decisions, while induced discrimination as a change in the causal influence of non-protected features associated with the protected attributes. The measurements of marginal direct effect (MDE) and SHapley Additive exPlanations (SHAP) reveal that state-of-the-art fair learning methods can induce discrimination via association or reverse discrimination in synthetic and real-world datasets. To inhibit discrimination in algorithmic systems, we propose to nullify the influence of the protected attribute on the output of the system, while preserving the influence of remaining features. We introduce and study post-processing methods achieving such objectives, finding that they yield relatively high model accuracy, prevent direct discrimination, and diminishes various disparity",
    "path": "papers/22/04/2204.02947.json",
    "total_tokens": 955,
    "translated_title": "在监督学习中嫁接公平性与可解释性",
    "translated_abstract": "辅助人类决策的机器学习算法可能会无意中歧视某些受保护的群体。我们将直接歧视形式化为受保护属性对决策的直接因果影响，而将间接歧视形式化为与受保护属性相关的非保护特征因果影响的改变。边际直接作用（MDE）和SHapley Additive exPlanations（SHAP）的量度显示，最先进的公平学习方法可以通过合成和真实世界数据集中的关联或反向歧视诱导歧视。为了抑制算法系统中的歧视，我们提出了使受保护属性对系统输出的影响无效，同时保留其他特征影响力的后处理方法。我们引入并研究了实现这些目标的后处理方法，发现它们具有相对较高的模型准确性，可以防止直接歧视，并减轻各种差异。",
    "tldr": "本文关注监督学习中的公平性和可解释性。研究发现，先进的公平学习方法可能在合成和真实世界数据集中诱导歧视。为了防止算法系统中的歧视，提出了一种后处理方法，使受保护属性对系统输出的影响无效，同时保留其他特征的影响力。该方法可以防止直接歧视，并减轻各种差异。",
    "en_tdlr": "This paper focuses on fairness and explainability in supervised learning. The study found that state-of-the-art fair learning methods may induce discrimination in synthetic and real-world datasets. To prevent discrimination in algorithmic systems, a post-processing method is proposed to nullify the influence of protected attributes on the output of the system while maintaining the influence of other features. This method can prevent direct discrimination and reduce various disparities."
}