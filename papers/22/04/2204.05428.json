{
    "title": "A Multilingual Perspective Towards the Evaluation of Attribution Methods in Natural Language Inference. (arXiv:2204.05428v2 [cs.CL] UPDATED)",
    "abstract": "Most evaluations of attribution methods focus on the English language. In this work, we present a multilingual approach for evaluating attribution methods for the Natural Language Inference (NLI) task in terms of faithfulness and plausibility. First, we introduce a novel cross-lingual strategy to measure faithfulness based on word alignments, which eliminates the drawbacks of erasure-based evaluations.We then perform a comprehensive evaluation of attribution methods, considering different output mechanisms and aggregation methods. Finally, we augment the XNLI dataset with highlight-based explanations, providing a multilingual NLI dataset with highlights, to support future exNLP studies. Our results show that attribution methods performing best for plausibility and faithfulness are different.",
    "link": "http://arxiv.org/abs/2204.05428",
    "context": "Title: A Multilingual Perspective Towards the Evaluation of Attribution Methods in Natural Language Inference. (arXiv:2204.05428v2 [cs.CL] UPDATED)\nAbstract: Most evaluations of attribution methods focus on the English language. In this work, we present a multilingual approach for evaluating attribution methods for the Natural Language Inference (NLI) task in terms of faithfulness and plausibility. First, we introduce a novel cross-lingual strategy to measure faithfulness based on word alignments, which eliminates the drawbacks of erasure-based evaluations.We then perform a comprehensive evaluation of attribution methods, considering different output mechanisms and aggregation methods. Finally, we augment the XNLI dataset with highlight-based explanations, providing a multilingual NLI dataset with highlights, to support future exNLP studies. Our results show that attribution methods performing best for plausibility and faithfulness are different.",
    "path": "papers/22/04/2204.05428.json",
    "total_tokens": 846,
    "translated_title": "自然语言推理中归因方法评估的多语言视角",
    "translated_abstract": "大多数归因方法的评估集中在英语语言上。在这项工作中，我们提出了一种多语言方法，用于评估自然语言推理（NLI）任务的归因方法的忠实度和可信度。首先，我们引入了一种基于单词对齐的新型跨语言策略来衡量忠实度，排除了删减评估的缺点。然后，我们对归因方法进行了全面的评估，考虑了不同的输出机制和聚合方法。最后，我们通过基于高亮的解释扩充了XNLI数据集，提供了一个带有高亮的多语言NLI数据集，以支持未来的ExNLP研究。我们的研究结果表明，性能最佳的归因方法对于可信度和可信度的表现是不同的。",
    "tldr": "该论文提出了一种基于多语言的评价方法，以评估自然语言推理任务中归因方法的忠实度和可信度，并且通过高亮的解释扩充了XNLI数据集，研究结果表明在可信度和可信度方面表现最佳的归因方法有所不同。",
    "en_tdlr": "This paper proposes a multilingual approach to evaluate attribution methods in the Natural Language Inference task, presents a novel cross-lingual strategy to measure faithfulness, and augments the XNLI dataset with highlight-based explanations. The results show that the attribution methods performing best for plausibility and faithfulness are different."
}