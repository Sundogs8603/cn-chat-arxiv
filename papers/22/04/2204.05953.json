{
    "title": "Explore More Guidance: A Task-aware Instruction Network for Sign Language Translation Enhanced with Data Augmentation. (arXiv:2204.05953v3 [cs.CL] UPDATED)",
    "abstract": "Sign language recognition and translation first uses a recognition module to generate glosses from sign language videos and then employs a translation module to translate glosses into spoken sentences. Most existing works focus on the recognition step, while paying less attention to sign language translation. In this work, we propose a task-aware instruction network, namely TIN-SLT, for sign language translation, by introducing the instruction module and the learning-based feature fuse strategy into a Transformer network. In this way, the pre-trained model's language ability can be well explored and utilized to further boost the translation performance. Moreover, by exploring the representation space of sign language glosses and target spoken language, we propose a multi-level data augmentation scheme to adjust the data distribution of the training set. We conduct extensive experiments on two challenging benchmark datasets, PHOENIX-2014-T and ASLG-PC12, on which our method outperforms ",
    "link": "http://arxiv.org/abs/2204.05953",
    "context": "Title: Explore More Guidance: A Task-aware Instruction Network for Sign Language Translation Enhanced with Data Augmentation. (arXiv:2204.05953v3 [cs.CL] UPDATED)\nAbstract: Sign language recognition and translation first uses a recognition module to generate glosses from sign language videos and then employs a translation module to translate glosses into spoken sentences. Most existing works focus on the recognition step, while paying less attention to sign language translation. In this work, we propose a task-aware instruction network, namely TIN-SLT, for sign language translation, by introducing the instruction module and the learning-based feature fuse strategy into a Transformer network. In this way, the pre-trained model's language ability can be well explored and utilized to further boost the translation performance. Moreover, by exploring the representation space of sign language glosses and target spoken language, we propose a multi-level data augmentation scheme to adjust the data distribution of the training set. We conduct extensive experiments on two challenging benchmark datasets, PHOENIX-2014-T and ASLG-PC12, on which our method outperforms ",
    "path": "papers/22/04/2204.05953.json",
    "total_tokens": 907,
    "translated_title": "探索更多的指导：一种增强数据增强的任务感知指令网络用于手语翻译",
    "translated_abstract": "手语识别和翻译首先使用识别模块从手语视频中生成手语词汇，然后使用翻译模块将手语词汇翻译成口语句子。本文提出了一种针对手语翻译的任务感知指令网络TIN-SLT，通过将指令模块和基于学习的特征融合策略引入Transformer网络。这样，预训练模型的语言能力可以被充分探索和利用，进一步提升翻译性能。此外，通过探索手语词汇和目标口语的表示空间，我们提出了一种多层数据增强方案，调整训练集的数据分布。我们在两个挑战性基准数据集PHOENIX-2014-T和ASLG-PC12上进行了大量实验，证明了我们的方法的优越性能。",
    "tldr": "本研究提出了一种任务感知指令网络TIN-SLT用于手语翻译，引入指令模块和特征融合策略进一步提升了翻译性能，并且通过多层数据增强方案调整了数据分布。",
    "en_tdlr": "This study proposes a task-aware instruction network TIN-SLT for sign language translation, which introduces instruction module and feature fusion strategy to enhance translation performance, and proposes a multi-level data augmentation scheme to adjust the data distribution, achieving superior results on benchmark datasets PHOENIX-2014-T and ASLG-PC12."
}