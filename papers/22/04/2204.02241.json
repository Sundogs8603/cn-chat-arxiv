{
    "title": "A Set Membership Approach to Discovering Feature Relevance and Explaining Neural Classifier Decisions. (arXiv:2204.02241v2 [cs.LG] UPDATED)",
    "abstract": "Neural classifiers are non linear systems providing decisions on the classes of patterns, for a given problem they have learned. The output computed by a classifier for each pattern constitutes an approximation of the output of some unknown function, mapping pattern data to their respective classes. The lack of knowledge of such a function along with the complexity of neural classifiers, especially when these are deep learning architectures, do not permit to obtain information on how specific predictions have been made. Hence, these powerful learning systems are considered as black boxes and in critical applications their use tends to be considered inappropriate. Gaining insight on such a black box operation constitutes a one way approach in interpreting operation of neural classifiers and assessing the validity of their decisions. In this paper we tackle this problem introducing a novel methodology for discovering which features are considered relevant by a trained neural classifier a",
    "link": "http://arxiv.org/abs/2204.02241",
    "context": "Title: A Set Membership Approach to Discovering Feature Relevance and Explaining Neural Classifier Decisions. (arXiv:2204.02241v2 [cs.LG] UPDATED)\nAbstract: Neural classifiers are non linear systems providing decisions on the classes of patterns, for a given problem they have learned. The output computed by a classifier for each pattern constitutes an approximation of the output of some unknown function, mapping pattern data to their respective classes. The lack of knowledge of such a function along with the complexity of neural classifiers, especially when these are deep learning architectures, do not permit to obtain information on how specific predictions have been made. Hence, these powerful learning systems are considered as black boxes and in critical applications their use tends to be considered inappropriate. Gaining insight on such a black box operation constitutes a one way approach in interpreting operation of neural classifiers and assessing the validity of their decisions. In this paper we tackle this problem introducing a novel methodology for discovering which features are considered relevant by a trained neural classifier a",
    "path": "papers/22/04/2204.02241.json",
    "total_tokens": 1163,
    "translated_title": "一种基于集合成员关系的方法来发现特征相关性并解释神经分类器的决策",
    "translated_abstract": "神经分类器是提供模式类别决策的非线性系统。对于给定的问题，神经分类器的输出构成了某个未知函数的输出的近似，该函数将模式数据映射到其相应的类别。然而，由于缺乏该函数的知识以及神经分类器的复杂性，尤其是对于深度学习体系结构，往往无法获得有关如何进行具体预测的信息。因此，这些强大的学习系统被认为是黑匣子，在关键的应用中使用它们往往被认为是不合适的。本文提出了一种新的方案来解决这个问题，通过基于集合成员分析，我们把输入模式分成子集，以关联不同的输出基类。这种关联是通过计算将分类器决策引导到替代类别所需的最小输入摄动来推断的。我们的方法可以用于发现哪些特征被认为是相关的，并量化其对预测的贡献。此外，我们展示了如何使用我们的方法来解释分类器在处理输入分布变化时的行为。标准的图像分类数据集上的实验结果显示了我们的方法在发现相关输入特征和解释由深度神经网络体系结构做出的分类决策方面的有效性。",
    "tldr": "该论文提出一种基于集合成员关系的方法来发现神经分类器所需的特征，并解释其决策。方法能够标识贡献每个特征对神经网络分类器所做出的预测，并解释分类器处理输入分布变化时的行为。",
    "en_tdlr": "This paper proposes a set membership approach to discover important features and explain decisions made by neural classifiers. The approach partitions input patterns into subsets and associates them with alternative output classes, allowing for identification of relevant input features and quantification of their contribution to the classifier's predictions. Results show the effectiveness of the methodology in interpreting the behavior of the classifier when handling changes in input distribution."
}