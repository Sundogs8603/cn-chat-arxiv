{
    "title": "Detecting Text Formality: A Study of Text Classification Approaches. (arXiv:2204.08975v2 [cs.CL] UPDATED)",
    "abstract": "Formality is one of the important characteristics of text documents. The automatic detection of the formality level of a text is potentially beneficial for various natural language processing tasks. Before, two large-scale datasets were introduced for multiple languages featuring formality annotation -- GYAFC and X-FORMAL. However, they were primarily used for the training of style transfer models. At the same time, the detection of text formality on its own may also be a useful application. This work proposes the first to our knowledge systematic study of formality detection methods based on statistical, neural-based, and Transformer-based machine learning methods and delivers the best-performing models for public usage. We conducted three types of experiments -- monolingual, multilingual, and cross-lingual. The study shows the overcome of Char BiLSTM model over Transformer-based ones for the monolingual and multilingual formality classification task, while Transformer-based classifie",
    "link": "http://arxiv.org/abs/2204.08975",
    "context": "Title: Detecting Text Formality: A Study of Text Classification Approaches. (arXiv:2204.08975v2 [cs.CL] UPDATED)\nAbstract: Formality is one of the important characteristics of text documents. The automatic detection of the formality level of a text is potentially beneficial for various natural language processing tasks. Before, two large-scale datasets were introduced for multiple languages featuring formality annotation -- GYAFC and X-FORMAL. However, they were primarily used for the training of style transfer models. At the same time, the detection of text formality on its own may also be a useful application. This work proposes the first to our knowledge systematic study of formality detection methods based on statistical, neural-based, and Transformer-based machine learning methods and delivers the best-performing models for public usage. We conducted three types of experiments -- monolingual, multilingual, and cross-lingual. The study shows the overcome of Char BiLSTM model over Transformer-based ones for the monolingual and multilingual formality classification task, while Transformer-based classifie",
    "path": "papers/22/04/2204.08975.json",
    "total_tokens": 825,
    "translated_title": "检测文本形式性：一项关于文本分类方法的研究",
    "translated_abstract": "形式性是文本文档的重要特征之一。对文本形式性水平的自动检测对于各种自然语言处理任务有潜在好处。之前，为多种语言引入了两个大规模数据集，包含形式性标注——GYAFC和X-FORMAL。然而，它们主要用于训练风格转移模型。同时，文本形式性的单独检测也可能是一个有用的应用。本研究提出了我们所知的第一项系统研究形式性检测方法，基于统计、基于神经网络和基于Transformer的机器学习方法，并提供了性能最佳的模型供公众使用。我们进行了三种类型的实验——单语言、多语言和跨语言。研究表明，在单语言和多语言形式性分类任务中，Char BiLSTM模型优于基于Transformer的模型。",
    "tldr": "这项研究提供了首个系统研究文本形式性检测方法，并提供了在单语言和多语言任务中表现最佳的Char BiLSTM模型。"
}