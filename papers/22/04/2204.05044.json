{
    "title": "From Modern CNNs to Vision Transformers: Assessing the Performance, Robustness, and Classification Strategies of Deep Learning Models in Histopathology. (arXiv:2204.05044v2 [eess.IV] CROSS LISTED)",
    "abstract": "While machine learning is currently transforming the field of histopathology, the domain lacks a comprehensive evaluation of state-of-the-art models based on essential but complementary quality requirements beyond a mere classification accuracy. In order to fill this gap, we developed a new methodology to extensively evaluate a wide range of classification models, including recent vision transformers, and convolutional neural networks such as: ConvNeXt, ResNet (BiT), Inception, ViT and Swin transformer, with and without supervised or self-supervised pretraining. We thoroughly tested the models on five widely used histopathology datasets containing whole slide images of breast, gastric, and colorectal cancer and developed a novel approach using an image-to-image translation model to assess the robustness of a cancer classification model against stain variations. Further, we extended existing interpretability methods to previously unstudied models and systematically reveal insights of th",
    "link": "http://arxiv.org/abs/2204.05044",
    "context": "Title: From Modern CNNs to Vision Transformers: Assessing the Performance, Robustness, and Classification Strategies of Deep Learning Models in Histopathology. (arXiv:2204.05044v2 [eess.IV] CROSS LISTED)\nAbstract: While machine learning is currently transforming the field of histopathology, the domain lacks a comprehensive evaluation of state-of-the-art models based on essential but complementary quality requirements beyond a mere classification accuracy. In order to fill this gap, we developed a new methodology to extensively evaluate a wide range of classification models, including recent vision transformers, and convolutional neural networks such as: ConvNeXt, ResNet (BiT), Inception, ViT and Swin transformer, with and without supervised or self-supervised pretraining. We thoroughly tested the models on five widely used histopathology datasets containing whole slide images of breast, gastric, and colorectal cancer and developed a novel approach using an image-to-image translation model to assess the robustness of a cancer classification model against stain variations. Further, we extended existing interpretability methods to previously unstudied models and systematically reveal insights of th",
    "path": "papers/22/04/2204.05044.json",
    "total_tokens": 1205,
    "translated_title": "从现代CNN到视觉Transformer：评估深度学习模型在组织病理学中的性能、鲁棒性和分类策略",
    "translated_abstract": "机器学习正在改变组织病理学领域，但该领域缺乏全面评估最新模型的方法，不仅要考虑简单的分类准确性，还要考虑其他质量要求。为此，我们开发了一种新的方法，对一系列分类模型进行了广泛评估，包括最新的视觉Transformer和卷积神经网络，如ConvNeXt、ResNet（BiT）、Inception、ViT和Swin Transformer，并在有监督或无监督预训练的情况下进行了测试。我们对包含乳腺癌、胃癌和结直肠癌全切片图像的五个广泛使用的组织病理学数据集进行了全面测试，并开发了一种新方法，使用图像转换模型来评估癌症分类模型对染色变化的鲁棒性。此外，我们扩展了现有的可解释性方法，系统地揭示了它们学到的特征。我们的评估表明，ViT模型在分类准确性方面优于其他CNN，而Swin Transformer模型在对抗染色变化的鲁棒性方面表现最佳。此外，我们证明了预训练可以提高大多数模型的分类性能和鲁棒性。最后，我们的分析揭示了这些模型学到的特征，包括空间频率信息和肿瘤特征。",
    "tldr": "本文评估了现代CNN和视觉Transformer模型在组织病理学中的性能、鲁棒性和分类策略。在乳腺癌、胃癌和结直肠癌全切片图像等五个数据集上进行了广泛测试，结果表明ViT模型在分类准确性方面优于其他CNN，而Swin Transformer模型在对抗染色变化的鲁棒性方面表现最佳。",
    "en_tdlr": "This paper evaluates the performance, robustness and classification strategies of modern CNNs and Vision Transformers in histopathology, comparing ViT models with other CNNs and demonstrating the effectiveness of pretraining. ViT models outperform other CNNs in classification accuracy, while Swin transformer models perform best in robustness against stain variations."
}