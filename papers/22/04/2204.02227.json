{
    "title": "SD-Conv: Towards the Parameter-Efficiency of Dynamic Convolution. (arXiv:2204.02227v3 [cs.CV] UPDATED)",
    "abstract": "Dynamic convolution achieves better performance for efficient CNNs at the cost of negligible FLOPs increase. However, the performance increase can not match the significantly expanded number of parameters, which is the main bottleneck in real-world applications. Contrastively, mask-based unstructured pruning obtains a lightweight network by removing redundancy in the heavy network. In this paper, we propose a new framework, \\textbf{Sparse Dynamic Convolution} (\\textsc{SD-Conv}), to naturally integrate these two paths such that it can inherit the advantage of dynamic mechanism and sparsity. We first design a binary mask derived from a learnable threshold to prune static kernels, significantly reducing the parameters and computational cost but achieving higher performance in Imagenet-1K. We further transfer pretrained models into a variety of downstream tasks, showing consistently better results than baselines. We hope our SD-Conv could be an efficient alternative to conventional dynamic",
    "link": "http://arxiv.org/abs/2204.02227",
    "context": "Title: SD-Conv: Towards the Parameter-Efficiency of Dynamic Convolution. (arXiv:2204.02227v3 [cs.CV] UPDATED)\nAbstract: Dynamic convolution achieves better performance for efficient CNNs at the cost of negligible FLOPs increase. However, the performance increase can not match the significantly expanded number of parameters, which is the main bottleneck in real-world applications. Contrastively, mask-based unstructured pruning obtains a lightweight network by removing redundancy in the heavy network. In this paper, we propose a new framework, \\textbf{Sparse Dynamic Convolution} (\\textsc{SD-Conv}), to naturally integrate these two paths such that it can inherit the advantage of dynamic mechanism and sparsity. We first design a binary mask derived from a learnable threshold to prune static kernels, significantly reducing the parameters and computational cost but achieving higher performance in Imagenet-1K. We further transfer pretrained models into a variety of downstream tasks, showing consistently better results than baselines. We hope our SD-Conv could be an efficient alternative to conventional dynamic",
    "path": "papers/22/04/2204.02227.json",
    "total_tokens": 916,
    "translated_title": "SD-Conv：实现动态卷积的参数效率",
    "translated_abstract": "动态卷积在保持微不足道的浮点运算增量的同时，实现了有效CNN的更好性能。然而，性能提升无法匹配显著扩大的参数数量，这是现实应用的主要瓶颈。相反，基于掩码的非结构化修剪通过去除重复项来获得轻量级网络。在本文中，我们提出了一个新的框架，称为“稀疏动态卷积”（SD-Conv），自然地将这两个路径集成在一起，以便可以继承动态机制和稀疏性的优点。我们首先设计了一个二进制掩码，从可学习阈值中派生出来，以修剪静态核，大大减少了参数和计算成本，但在Imagenet-1K中实现了更高的性能。我们进一步将预训练模型转移到各种下游任务中，展示了比基线模型更为稳定的结果。我们希望我们的SD-Conv能够成为传统动态卷积和结构化修剪的高效替代品。",
    "tldr": "SD-Conv 是一个新的框架，将动态机制和稀疏性集成在一起，通过设计二进制掩码修剪静态核，大大减少了参数和计算成本，并在多个下游任务中展示了比基线模型更好的结果。"
}