{
    "title": "FedCau: A Proactive Stop Policy for Communication and Computation Efficient Federated Learning",
    "abstract": "arXiv:2204.07773v2 Announce Type: replace  Abstract: This paper investigates efficient distributed training of a Federated Learning~(FL) model over a wireless network of wireless devices. The communication iterations of the distributed training algorithm may be substantially deteriorated or even blocked by the effects of the devices' background traffic, packet losses, congestion, or latency. We abstract the communication-computation impacts as an `iteration cost' and propose a cost-aware causal FL algorithm~(FedCau) to tackle this problem. We propose an iteration-termination method that trade-offs the training performance and networking costs. We apply our approach when clients use the slotted-ALOHA, the carrier-sense multiple access with collision avoidance~(CSMA/CA), and the orthogonal frequency-division multiple access~(OFDMA) protocols. We show that, given a total cost budget, the training performance degrades as either the background communication traffic or the dimension of the t",
    "link": "https://arxiv.org/abs/2204.07773",
    "context": "Title: FedCau: A Proactive Stop Policy for Communication and Computation Efficient Federated Learning\nAbstract: arXiv:2204.07773v2 Announce Type: replace  Abstract: This paper investigates efficient distributed training of a Federated Learning~(FL) model over a wireless network of wireless devices. The communication iterations of the distributed training algorithm may be substantially deteriorated or even blocked by the effects of the devices' background traffic, packet losses, congestion, or latency. We abstract the communication-computation impacts as an `iteration cost' and propose a cost-aware causal FL algorithm~(FedCau) to tackle this problem. We propose an iteration-termination method that trade-offs the training performance and networking costs. We apply our approach when clients use the slotted-ALOHA, the carrier-sense multiple access with collision avoidance~(CSMA/CA), and the orthogonal frequency-division multiple access~(OFDMA) protocols. We show that, given a total cost budget, the training performance degrades as either the background communication traffic or the dimension of the t",
    "path": "papers/22/04/2204.07773.json",
    "total_tokens": 893,
    "translated_title": "FedCau：一种用于通信和计算高效的联邦学习的主动停止策略",
    "translated_abstract": "本文研究了在无线设备组成的无线网络上进行联邦学习（FL）模型的高效分布式训练。分布式训练算法的通信迭代可能受到设备背景流量、数据包丢失、拥塞或延迟等影响而大幅恶化甚至被阻断。我们将通信-计算影响抽象为“迭代成本”，并提出一种成本感知因果FL算法（FedCau）来解决这一问题。我们提出了一种迭代终止方法，权衡了训练性能和网络成本。我们在客户端使用分槽ALOHA、带冲突避免的载波监听多路访问（CSMA/CA）和正交频分多址（OFDMA）协议时应用我们的方法。我们表明，在给定总成本预算的情况下，训练性能会随着背景通信流量或特征的维度增加而降低。",
    "tldr": "本文提出了一种成本感知因果FL算法（FedCau），用于处理无线网络上联邦学习模型的通信和计算高效性问题，通过迭代终止方法权衡了训练性能和网络成本。",
    "en_tdlr": "This paper introduces a cost-aware causal FL algorithm (FedCau) to address the communication and computation efficiency issues of federated learning models on a wireless network, balancing training performance and network costs through an iteration-termination method."
}