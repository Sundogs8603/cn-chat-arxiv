{
    "title": "Reward Reports for Reinforcement Learning. (arXiv:2204.10817v3 [cs.LG] UPDATED)",
    "abstract": "Building systems that are good for society in the face of complex societal effects requires a dynamic approach. Recent approaches to machine learning (ML) documentation have demonstrated the promise of discursive frameworks for deliberation about these complexities. However, these developments have been grounded in a static ML paradigm, leaving the role of feedback and post-deployment performance unexamined. Meanwhile, recent work in reinforcement learning has shown that the effects of feedback and optimization objectives on system behavior can be wide-ranging and unpredictable. In this paper we sketch a framework for documenting deployed and iteratively updated learning systems, which we call Reward Reports. Taking inspiration from various contributions to the technical literature on reinforcement learning, we outline Reward Reports as living documents that track updates to design choices and assumptions behind what a particular automated system is optimizing for. They are intended to",
    "link": "http://arxiv.org/abs/2204.10817",
    "context": "Title: Reward Reports for Reinforcement Learning. (arXiv:2204.10817v3 [cs.LG] UPDATED)\nAbstract: Building systems that are good for society in the face of complex societal effects requires a dynamic approach. Recent approaches to machine learning (ML) documentation have demonstrated the promise of discursive frameworks for deliberation about these complexities. However, these developments have been grounded in a static ML paradigm, leaving the role of feedback and post-deployment performance unexamined. Meanwhile, recent work in reinforcement learning has shown that the effects of feedback and optimization objectives on system behavior can be wide-ranging and unpredictable. In this paper we sketch a framework for documenting deployed and iteratively updated learning systems, which we call Reward Reports. Taking inspiration from various contributions to the technical literature on reinforcement learning, we outline Reward Reports as living documents that track updates to design choices and assumptions behind what a particular automated system is optimizing for. They are intended to",
    "path": "papers/22/04/2204.10817.json",
    "total_tokens": 916,
    "translated_title": "强化学习的奖励报告",
    "translated_abstract": "在面对复杂的社会影响时构建对社会有益的系统需要一种动态的方法。最近的机器学习（ML）文献记录方法展示了讨论这些复杂性的文本框架的前景。然而，这些发展基于静态的机器学习范例，忽略了反馈和部署后性能的作用。同时，强化学习的最近工作表明，反馈和优化目标对系统行为的影响可能是广泛且不可预测的。在本文中，我们提出了一个名为奖励报告的框架，用于记录已部署和迭代更新的学习系统。受到强化学习技术文献的各种贡献启示，我们将奖励报告概述为跟踪一个特定自动化系统正在优化的设计选择和假设的活动文件。它们旨在作为透明地传达系统目标的手段，并跟踪随着时间的推移不断演变，从而更好地了解社会影响技术的动态。",
    "tldr": "本文提出一种名为奖励报告的框架，用于记录已部署和迭代更新的学习系统。通过追踪设计选择和假设，帮助透明地传达系统目标，并跟踪目标的演变。",
    "en_tdlr": "This paper proposes a framework named \"Reward Reports\" for documenting deployed and iteratively updated learning systems. It helps transparently communicate system objectives and track their evolution by keeping records of design choices and assumptions."
}