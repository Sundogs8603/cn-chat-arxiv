{
    "title": "TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models. (arXiv:2204.14211v3 [cs.CL] UPDATED)",
    "abstract": "Language Models (LMs) become outdated as the world changes; they often fail to perform tasks requiring recent factual information which was absent or different during training, a phenomenon called temporal misalignment. This is especially a challenging problem because the research community still lacks a coherent dataset for assessing the adaptability of LMs to frequently-updated knowledge corpus such as Wikipedia. To this end, we introduce TemporalWiki, a lifelong benchmark for ever-evolving LMs that utilizes the difference between consecutive snapshots of English Wikipedia and English Wikidata for training and evaluation, respectively. The benchmark hence allows researchers to periodically track an LM's ability to retain previous knowledge and acquire updated/new knowledge at each point in time. We also find that training an LM on the diff data through continual learning methods achieves similar or better perplexity than on the entire snapshot in our benchmark with 12 times less comp",
    "link": "http://arxiv.org/abs/2204.14211",
    "context": "Title: TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models. (arXiv:2204.14211v3 [cs.CL] UPDATED)\nAbstract: Language Models (LMs) become outdated as the world changes; they often fail to perform tasks requiring recent factual information which was absent or different during training, a phenomenon called temporal misalignment. This is especially a challenging problem because the research community still lacks a coherent dataset for assessing the adaptability of LMs to frequently-updated knowledge corpus such as Wikipedia. To this end, we introduce TemporalWiki, a lifelong benchmark for ever-evolving LMs that utilizes the difference between consecutive snapshots of English Wikipedia and English Wikidata for training and evaluation, respectively. The benchmark hence allows researchers to periodically track an LM's ability to retain previous knowledge and acquire updated/new knowledge at each point in time. We also find that training an LM on the diff data through continual learning methods achieves similar or better perplexity than on the entire snapshot in our benchmark with 12 times less comp",
    "path": "papers/22/04/2204.14211.json",
    "total_tokens": 972,
    "translated_title": "TemporalWiki: 一个用于训练和评估不断更新的语言模型的终身基准",
    "translated_abstract": "随着世界的变化，语言模型（LMs）变得过时，它们通常无法执行需要最新事实信息的任务，这在训练期间不存在或存在不同，这种现象叫做时间错位。这是一个挑战性的问题，因为研究界还缺乏一个一致的数据集，用于评估LMs对于经常更新的知识库（如维基百科）的适应能力。为此，我们引入了TemporalWiki，一个终身基准，用于不断更新的LMs，利用英语维基百科和英语维基数据之间的连续快照差异进行训练和评估。因此，该基准允许研究人员周期性地跟踪LM的保留前一知识和在每个时间点上获取更新/新知识的能力。我们还发现，在我们的基准测试中，通过继续学习方法对差异数据进行LM的训练，与在整个快照上使用12倍更少的计算实现相似或更好的困惑度。",
    "tldr": "TemporalWiki是一个用来训练和评估不断更新的语言模型的终身基准，通过利用英语维基百科和英语维基数据之间的连续快照差异进行训练和评估，使研究者可以周期性地跟踪LM的保留前一知识和在每个时间点上获取更新/新知识的能力。"
}