{
    "title": "Case-Aware Adversarial Training. (arXiv:2204.09398v2 [cs.LG] UPDATED)",
    "abstract": "The neural network (NN) becomes one of the most heated type of models in various signal processing applications. However, NNs are extremely vulnerable to adversarial examples (AEs). To defend AEs, adversarial training (AT) is believed to be the most effective method while due to the intensive computation, AT is limited to be applied in most applications. In this paper, to resolve the problem, we design a generic and efficient AT improvement scheme, namely case-aware adversarial training (CAT). Specifically, the intuition stems from the fact that a very limited part of informative samples can contribute to most of model performance. Alternatively, if only the most informative AEs are used in AT, we can lower the computation complexity of AT significantly as maintaining the defense effect. To achieve this, CAT achieves two breakthroughs. First, a method to estimate the information degree of adversarial examples is proposed for AE filtering. Second, to further enrich the information that ",
    "link": "http://arxiv.org/abs/2204.09398",
    "context": "Title: Case-Aware Adversarial Training. (arXiv:2204.09398v2 [cs.LG] UPDATED)\nAbstract: The neural network (NN) becomes one of the most heated type of models in various signal processing applications. However, NNs are extremely vulnerable to adversarial examples (AEs). To defend AEs, adversarial training (AT) is believed to be the most effective method while due to the intensive computation, AT is limited to be applied in most applications. In this paper, to resolve the problem, we design a generic and efficient AT improvement scheme, namely case-aware adversarial training (CAT). Specifically, the intuition stems from the fact that a very limited part of informative samples can contribute to most of model performance. Alternatively, if only the most informative AEs are used in AT, we can lower the computation complexity of AT significantly as maintaining the defense effect. To achieve this, CAT achieves two breakthroughs. First, a method to estimate the information degree of adversarial examples is proposed for AE filtering. Second, to further enrich the information that ",
    "path": "papers/22/04/2204.09398.json",
    "total_tokens": 890,
    "translated_title": "案例感知对抗训练",
    "translated_abstract": "神经网络（NN）成为各种信号处理应用中最受关注的模型之一。然而，NN对于对抗性示例（AEs）极其容易受到攻击。为了防御AEs，对抗性训练（AT）被认为是最有效的方法，但由于计算量大，AT在大多数应用中受到限制。为了解决这个问题，本文设计了一种通用且高效的AT改进方案，即案例感知对抗训练（CAT）。具体而言，灵感来自于少部分信息丰富的样本对大多数模型性能的贡献。如果只使用最有信息量的AEs进行AT，可以显著降低AT的计算复杂度并保持防御效果。为实现此目标，CAT实现了两个突破。首先，提出了一种估计AE信息度的方法用于AE过滤。其次，为进一步丰富用于AT的信息，引入了一个自适应样本选择机制。",
    "tldr": "本文提出了一种通用且高效的对抗性训练改进方案，即案例感知对抗训练（CAT），通过选择最有信息量的对抗性示例进行训练，降低了计算复杂度并保持防御效果。"
}