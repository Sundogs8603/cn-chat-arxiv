{
    "title": "Neuronal diversity can improve machine learning for physics and beyond. (arXiv:2204.04348v2 [q-bio.NC] UPDATED)",
    "abstract": "Diversity conveys advantages in nature, yet homogeneous neurons typically comprise the layers of artificial neural networks. Here we construct neural networks from neurons that learn their own activation functions, quickly diversify, and subsequently outperform their homogeneous counterparts on image classification and nonlinear regression tasks. Sub-networks instantiate the neurons, which meta-learn especially efficient sets of nonlinear responses. Examples include conventional neural networks classifying digits and forecasting a van der Pol oscillator and a physics-informed Hamiltonian neural network learning H\\'enon-Heiles orbits. Such learned diversity provides examples of dynamical systems selecting diversity over uniformity and elucidates the role of diversity in natural and artificial systems.",
    "link": "http://arxiv.org/abs/2204.04348",
    "context": "Title: Neuronal diversity can improve machine learning for physics and beyond. (arXiv:2204.04348v2 [q-bio.NC] UPDATED)\nAbstract: Diversity conveys advantages in nature, yet homogeneous neurons typically comprise the layers of artificial neural networks. Here we construct neural networks from neurons that learn their own activation functions, quickly diversify, and subsequently outperform their homogeneous counterparts on image classification and nonlinear regression tasks. Sub-networks instantiate the neurons, which meta-learn especially efficient sets of nonlinear responses. Examples include conventional neural networks classifying digits and forecasting a van der Pol oscillator and a physics-informed Hamiltonian neural network learning H\\'enon-Heiles orbits. Such learned diversity provides examples of dynamical systems selecting diversity over uniformity and elucidates the role of diversity in natural and artificial systems.",
    "path": "papers/22/04/2204.04348.json",
    "total_tokens": 867,
    "translated_title": "神经元多样性能够提高物理学及其他领域的机器学习",
    "translated_abstract": "自然界表现出多样性的优点，但是人工神经网络的层通常是由同构神经元构成的。本文中我们建立起能够学习自身激活函数、快速多样化并且在图像分类和非线性回归任务中胜过同构神经元的神经网络。子网络实例化了神经元，而元学习尤其高效的非线性响应集合。例子包括传统的神经网络分类数字和预测一个 van der Pol 振荡器和一种物理学驱动的 Hamiltonian 神经网络学习 Hénond-Heiles 轨道。这种学习到的多样性为动态系统选择多样性而非均匀性提供了例子，并阐明了多样性在自然和人工系统中的作用。",
    "tldr": "本文展示了使用多样化到神经元来改进机器学习，构建出能够通过学习自身激活函数快速多样化的神经网络，并且胜过传统的同构神经元网络，在图像分类和非线性回归任务中表现更优，这种学习到的多样性为动态系统选择多样性而非均匀性提供了例子，并阐明了多样性在自然和人工系统中的作用。",
    "en_tdlr": "This paper demonstrates that using diverse neurons can improve machine learning. The authors construct neural networks that learn their own activation functions and quickly diversify, outperforming homogeneous networks in image classification and nonlinear regression tasks. The learned diversity provides examples of dynamical systems selecting diversity over uniformity and elucidates the role of diversity in natural and artificial systems."
}