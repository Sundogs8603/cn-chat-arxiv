{
    "title": "Differentially Private Sampling from Rashomon Sets, and the Universality of Langevin Diffusion for Convex Optimization. (arXiv:2204.01585v4 [cs.LG] UPDATED)",
    "abstract": "In this paper we provide an algorithmic framework based on Langevin diffusion (LD) and its corresponding discretizations that allow us to simultaneously obtain: i) An algorithm for sampling from the exponential mechanism, whose privacy analysis does not depend on convexity and which can be stopped at anytime without compromising privacy, and ii) tight uniform stability guarantees for the exponential mechanism. As a direct consequence, we obtain optimal excess empirical and population risk guarantees for (strongly) convex losses under both pure and approximate differential privacy (DP). The framework allows us to design a DP uniform sampler from the Rashomon set. Rashomon sets are widely used in interpretable and robust machine learning, understanding variable importance, and characterizing fairness.",
    "link": "http://arxiv.org/abs/2204.01585",
    "context": "Title: Differentially Private Sampling from Rashomon Sets, and the Universality of Langevin Diffusion for Convex Optimization. (arXiv:2204.01585v4 [cs.LG] UPDATED)\nAbstract: In this paper we provide an algorithmic framework based on Langevin diffusion (LD) and its corresponding discretizations that allow us to simultaneously obtain: i) An algorithm for sampling from the exponential mechanism, whose privacy analysis does not depend on convexity and which can be stopped at anytime without compromising privacy, and ii) tight uniform stability guarantees for the exponential mechanism. As a direct consequence, we obtain optimal excess empirical and population risk guarantees for (strongly) convex losses under both pure and approximate differential privacy (DP). The framework allows us to design a DP uniform sampler from the Rashomon set. Rashomon sets are widely used in interpretable and robust machine learning, understanding variable importance, and characterizing fairness.",
    "path": "papers/22/04/2204.01585.json",
    "total_tokens": 908,
    "translated_title": "来自拉什莫恩集合的差分隐私抽样以及Langevin扩散在凸优化中的普适性",
    "translated_abstract": "在本文中，我们提供了一种基于Langevin扩散（LD）及其相应离散化的算法框架，可以同时实现：i）一种从指数机制中进行抽样的算法，其隐私分析不依赖于凸性，并且可以在任何时候停止而不损害隐私；ii）指数机制的紧密均匀稳定性保证。作为直接结果，在纯粹和近似差分隐私（DP）下，获得了（强）凸损失的最优过度经验和总体风险保证。该框架允许我们设计来自拉什莫恩集合的差分隐私均匀抽样器。拉什莫恩集合在可解释和鲁棒机器学习、理解变量重要性和表征公平性方面被广泛使用。",
    "tldr": "本文提供了一种基于Langevin扩散的算法框架，可以同时实现差分隐私抽样和紧密均匀稳定性保证，从而对凸优化中的损失函数提供了最优的过度经验和总体风险保证。该框架还允许设计差分隐私均匀抽样器，应用于可解释和鲁棒机器学习等方向。",
    "en_tdlr": "This paper presents an algorithmic framework based on Langevin diffusion that achieves differentially private sampling and tight uniform stability guarantees for convex optimization. The framework also allows for the design of differentially private uniform samplers for interpretable and robust machine learning tasks."
}