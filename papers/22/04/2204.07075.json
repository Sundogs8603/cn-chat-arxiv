{
    "title": "Learning and controlling the source-filter representation of speech with a variational autoencoder. (arXiv:2204.07075v3 [cs.SD] UPDATED)",
    "abstract": "Understanding and controlling latent representations in deep generative models is a challenging yet important problem for analyzing, transforming and generating various types of data. In speech processing, inspiring from the anatomical mechanisms of phonation, the source-filter model considers that speech signals are produced from a few independent and physically meaningful continuous latent factors, among which the fundamental frequency $f_0$ and the formants are of primary importance. In this work, we start from a variational autoencoder (VAE) trained in an unsupervised manner on a large dataset of unlabeled natural speech signals, and we show that the source-filter model of speech production naturally arises as orthogonal subspaces of the VAE latent space. Using only a few seconds of labeled speech signals generated with an artificial speech synthesizer, we propose a method to identify the latent subspaces encoding $f_0$ and the first three formant frequencies, we show that these su",
    "link": "http://arxiv.org/abs/2204.07075",
    "context": "Title: Learning and controlling the source-filter representation of speech with a variational autoencoder. (arXiv:2204.07075v3 [cs.SD] UPDATED)\nAbstract: Understanding and controlling latent representations in deep generative models is a challenging yet important problem for analyzing, transforming and generating various types of data. In speech processing, inspiring from the anatomical mechanisms of phonation, the source-filter model considers that speech signals are produced from a few independent and physically meaningful continuous latent factors, among which the fundamental frequency $f_0$ and the formants are of primary importance. In this work, we start from a variational autoencoder (VAE) trained in an unsupervised manner on a large dataset of unlabeled natural speech signals, and we show that the source-filter model of speech production naturally arises as orthogonal subspaces of the VAE latent space. Using only a few seconds of labeled speech signals generated with an artificial speech synthesizer, we propose a method to identify the latent subspaces encoding $f_0$ and the first three formant frequencies, we show that these su",
    "path": "papers/22/04/2204.07075.json",
    "total_tokens": 943,
    "translated_title": "用变分自编码器学习和控制语音的源-滤波表示",
    "translated_abstract": "理解和控制深度生成模型中的潜在表示对于分析、转换和生成各种类型的数据是一个具有挑战性但重要的问题。在语音处理方面，受到声音生理学机制的启发，源-滤波模型认为语音信号是从几个独立且物理意义连续的潜在因素产生的，其中基频$f_0$和共振峰是最重要的。本文从一个在大量未标记的自然语音信号上无监督训练的变分自编码器（VAE）开始，展示了语音产生的源-滤波模型自然地显现为VAE潜在空间的正交子空间。仅使用人工语音合成器生成的少量标记语音信号，我们提出了一种方法来识别编码$f_0$和前三个共振峰频率的潜在子空间，并证明了这些子空间可以被用于对语音进行控制。",
    "tldr": "本文提出了一种用变分自编码器学习和控制语音的源-滤波表示的方法。基于源-滤波模型假设，提出了一种方法来识别编码$f_0$和前三个共振峰频率的潜在子空间，并证明了这些子空间可以被用于对语音进行控制。",
    "en_tdlr": "This paper presents a method for learning and controlling the source-filter representation of speech using a variational autoencoder (VAE). Based on the source-filter model assumption, a method is proposed to identify latent subspaces encoding the fundamental frequency and formants, and it is demonstrated that these subspaces can be used for speech control."
}