{
    "title": "Reducing Predictive Feature Suppression in Resource-Constrained Contrastive Image-Caption Retrieval. (arXiv:2204.13382v2 [cs.CV] UPDATED)",
    "abstract": "To train image-caption retrieval (ICR) methods, contrastive loss functions are a common choice for optimization functions. Unfortunately, contrastive ICR methods are vulnerable to predictive feature suppression. Predictive features are features that correctly indicate the similarity between a query and a candidate item. However, in the presence of multiple predictive features during training, encoder models tend to suppress redundant predictive features, since these features are not needed to learn to discriminate between positive and negative pairs. While some predictive features are redundant during training, these features might be relevant during evaluation. We introduce an approach to reduce predictive feature suppression for resource-constrained ICR methods: latent target decoding (LTD). We add an additional decoder to the contrastive ICR framework, to reconstruct the input caption in a latent space of a general-purpose sentence encoder, which prevents the image and caption encod",
    "link": "http://arxiv.org/abs/2204.13382",
    "context": "Title: Reducing Predictive Feature Suppression in Resource-Constrained Contrastive Image-Caption Retrieval. (arXiv:2204.13382v2 [cs.CV] UPDATED)\nAbstract: To train image-caption retrieval (ICR) methods, contrastive loss functions are a common choice for optimization functions. Unfortunately, contrastive ICR methods are vulnerable to predictive feature suppression. Predictive features are features that correctly indicate the similarity between a query and a candidate item. However, in the presence of multiple predictive features during training, encoder models tend to suppress redundant predictive features, since these features are not needed to learn to discriminate between positive and negative pairs. While some predictive features are redundant during training, these features might be relevant during evaluation. We introduce an approach to reduce predictive feature suppression for resource-constrained ICR methods: latent target decoding (LTD). We add an additional decoder to the contrastive ICR framework, to reconstruct the input caption in a latent space of a general-purpose sentence encoder, which prevents the image and caption encod",
    "path": "papers/22/04/2204.13382.json",
    "total_tokens": 1000,
    "translated_title": "减少资源受限对比图像-字幕检索中的预测特征抑制",
    "translated_abstract": "对于训练图像-字幕检索（ICR）方法，对比损失函数是优化函数的常见选择。然而，对比ICR方法容易受到预测特征抑制的影响。预测特征是正确指示查询和候选项之间相似性的特征。然而，在训练过程中存在多个预测特征时，编码器模型往往会抑制冗余的预测特征，因为这些特征不需要学习区分正面和负面对。虽然有些预测特征在训练过程中是冗余的，但在评估过程中可能是有用的。我们提出了一种减少资源受限ICR方法中预测特征抑制的方法：潜在目标解码（LTD）。我们在对比ICR框架中添加了一个额外的解码器，以在通用句子编码器的潜在空间中重建输入字幕，从而防止图像和字幕编码器在不匹配的负面对中抑制预测特征。我们在Flikr30k和MS COCO数据集上验证了LTD，并表明它比资源受限场景中的基线方法改进了性能。",
    "tldr": "本文提出了一种名为潜在目标解码（LTD）的方法，可以在资源受限的情况下减少预测特征抑制，从而为对比图像-字幕检索（ICR）方法提供了一种解决方案。",
    "en_tdlr": "This paper proposes a method called Latent Target Decoding (LTD) to reduce predictive feature suppression in resource-constrained image-caption retrieval (ICR) methods, which provides a solution to the problem of redundant predictive feature suppression during training that can negatively affect performance."
}