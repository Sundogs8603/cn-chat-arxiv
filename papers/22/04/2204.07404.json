{
    "title": "Divide & Conquer Imitation Learning. (arXiv:2204.07404v2 [cs.AI] UPDATED)",
    "abstract": "When cast into the Deep Reinforcement Learning framework, many robotics tasks require solving a long horizon and sparse reward problem, where learning algorithms struggle. In such context, Imitation Learning (IL) can be a powerful approach to bootstrap the learning process. However, most IL methods require several expert demonstrations which can be prohibitively difficult to acquire. Only a handful of IL algorithms have shown efficiency in the context of an extreme low expert data regime where a single expert demonstration is available. In this paper, we present a novel algorithm designed to imitate complex robotic tasks from the states of an expert trajectory. Based on a sequential inductive bias, our method divides the complex task into smaller skills. The skills are learned into a goal-conditioned policy that is able to solve each skill individually and chain skills to solve the entire task. We show that our method imitates a non-holonomic navigation task and scales to a complex sim",
    "link": "http://arxiv.org/abs/2204.07404",
    "context": "Title: Divide & Conquer Imitation Learning. (arXiv:2204.07404v2 [cs.AI] UPDATED)\nAbstract: When cast into the Deep Reinforcement Learning framework, many robotics tasks require solving a long horizon and sparse reward problem, where learning algorithms struggle. In such context, Imitation Learning (IL) can be a powerful approach to bootstrap the learning process. However, most IL methods require several expert demonstrations which can be prohibitively difficult to acquire. Only a handful of IL algorithms have shown efficiency in the context of an extreme low expert data regime where a single expert demonstration is available. In this paper, we present a novel algorithm designed to imitate complex robotic tasks from the states of an expert trajectory. Based on a sequential inductive bias, our method divides the complex task into smaller skills. The skills are learned into a goal-conditioned policy that is able to solve each skill individually and chain skills to solve the entire task. We show that our method imitates a non-holonomic navigation task and scales to a complex sim",
    "path": "papers/22/04/2204.07404.json",
    "total_tokens": 925,
    "translated_title": "分而治之的模仿学习 - Divide & Conquer Imitation Learning",
    "translated_abstract": "当深度强化学习框架用于解决许多机器人任务时，需要解决长时间跨度和奖励稀疏的问题，学习算法很难应对。在这种情况下，模仿学习（IL）可以是启动学习过程的有力方法。然而，大多数IL方法需要多个专家演示，这可能很难获得。只有少数IL算法在极低的专家数据情况下表现出有效性，只有一个专家演示可用。在本文中，我们提出了一种新颖的算法，旨在从专家轨迹的状态中模仿复杂的机器人任务。基于顺序归纳偏见，我们的方法将复杂任务划分为更小的技能。这些技能被学习成为一个目标条件策略，该策略能够独立地解决每个技能，并链接技能以解决整个任务。我们展示了我们的方法模仿了一个非完整导航任务，并扩展到了复杂的仿真环境中。",
    "tldr": "该论文提出了一种新颖的模仿学习算法，通过将复杂任务划分为更小的技能，利用顺序归纳偏见将技能链接以解决整个任务。该算法可以在只有一个专家演示可用的情况下模仿复杂的机器人任务。",
    "en_tdlr": "This paper presents a novel imitation learning algorithm that divides complex tasks into smaller skills and uses sequential inductive bias to chain the skills and solve the entire task. The algorithm can imitate complex robotics tasks with only one expert demonstration available."
}