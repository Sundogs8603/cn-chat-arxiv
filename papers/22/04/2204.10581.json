{
    "title": "FAIR4Cov: Fused Audio Instance and Representation for COVID-19 Detection. (arXiv:2204.10581v2 [cs.SD] UPDATED)",
    "abstract": "Audio-based classification techniques on body sounds have long been studied to support diagnostic decisions, particularly in pulmonary diseases. In response to the urgency of the COVID-19 pandemic, a growing number of models are developed to identify COVID-19 patients based on acoustic input. Most models focus on cough because the dry cough is the best-known symptom of COVID-19. However, other body sounds, such as breath and speech, have also been revealed to correlate with COVID-19 as well. In this work, rather than relying on a specific body sound, we propose Fused Audio Instance and Representation for COVID-19 Detection (FAIR4Cov). It relies on constructing a joint feature vector obtained from a plurality of body sounds in waveform and spectrogram representation. The core component of FAIR4Cov is a self-attention fusion unit that is trained to establish the relation of multiple body sounds and audio representations and integrate it into a compact feature vector. We set up our experi",
    "link": "http://arxiv.org/abs/2204.10581",
    "context": "Title: FAIR4Cov: Fused Audio Instance and Representation for COVID-19 Detection. (arXiv:2204.10581v2 [cs.SD] UPDATED)\nAbstract: Audio-based classification techniques on body sounds have long been studied to support diagnostic decisions, particularly in pulmonary diseases. In response to the urgency of the COVID-19 pandemic, a growing number of models are developed to identify COVID-19 patients based on acoustic input. Most models focus on cough because the dry cough is the best-known symptom of COVID-19. However, other body sounds, such as breath and speech, have also been revealed to correlate with COVID-19 as well. In this work, rather than relying on a specific body sound, we propose Fused Audio Instance and Representation for COVID-19 Detection (FAIR4Cov). It relies on constructing a joint feature vector obtained from a plurality of body sounds in waveform and spectrogram representation. The core component of FAIR4Cov is a self-attention fusion unit that is trained to establish the relation of multiple body sounds and audio representations and integrate it into a compact feature vector. We set up our experi",
    "path": "papers/22/04/2204.10581.json",
    "total_tokens": 1070,
    "translated_title": "FAIR4Cov：用于 COVID-19 检测的融合音频实例和表示",
    "translated_abstract": "基于身体声音的分类技术长期以来一直被研究用于支持诊断决策，特别是在肺部疾病方面。针对 COVID-19 疫情的紧迫性，越来越多的模型被开发来基于声学输入识别 COVID-19 患者。大多数模型侧重于咳嗽，因为干咳是 COVID-19 最为人所知的症状。然而，呼吸和言语等其他身体声音也被发现与 COVID-19 相关。在这项工作中，我们提出了 FAIR4Cov，它不依赖于特定的身体声音，而是提出了一种融合身体声音的波形和谱图表示的关节特征向量。FAIR4Cov 的核心组件是一个自注意融合单元，它的训练目的是建立多个身体声音和音频表示的关系并将其集成到一个紧凑的特征向量中。我们在两个公共数据集上设置了实验，并在不同场景下评估了我们的提议方法，包括跨数据集评估和早期检测设置。实验结果表明，FAIR4Cov 胜过了现有方法，并展示了利用各种身体声音检测 COVID-19 患者的能力。",
    "tldr": "FAIR4Cov是一种针对COVID-19检测的方法，它提出了一种融合身体声音的波形和谱图表示的关节特征向量，可以有效地检测COVID-19患者，胜过了其他方法。",
    "en_tdlr": "FAIR4Cov is a method for COVID-19 detection, which proposes a joint feature vector obtained from a plurality of body sounds in waveform and spectrogram representation. It can effectively detect COVID-19 patients and outperforms other methods."
}