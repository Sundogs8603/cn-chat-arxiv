{
    "title": "Con$^{2}$DA: Simplifying Semi-supervised Domain Adaptation by Learning Consistent and Contrastive Feature Representations. (arXiv:2204.01558v2 [cs.LG] UPDATED)",
    "abstract": "In this work, we present Con$^{2}$DA, a simple framework that extends recent advances in semi-supervised learning to the semi-supervised domain adaptation (SSDA) problem. Our framework generates pairs of associated samples by performing stochastic data transformations to a given input. Associated data pairs are mapped to a feature representation space using a feature extractor. We use different loss functions to enforce consistency between the feature representations of associated data pairs of samples. We show that these learned representations are useful to deal with differences in data distributions in the domain adaptation problem. We performed experiments to study the main components of our model and we show that (i) learning of the consistent and contrastive feature representations is crucial to extract good discriminative features across different domains, and ii) our model benefits from the use of strong augmentation policies. With these findings, our method achieves state-of-t",
    "link": "http://arxiv.org/abs/2204.01558",
    "context": "Title: Con$^{2}$DA: Simplifying Semi-supervised Domain Adaptation by Learning Consistent and Contrastive Feature Representations. (arXiv:2204.01558v2 [cs.LG] UPDATED)\nAbstract: In this work, we present Con$^{2}$DA, a simple framework that extends recent advances in semi-supervised learning to the semi-supervised domain adaptation (SSDA) problem. Our framework generates pairs of associated samples by performing stochastic data transformations to a given input. Associated data pairs are mapped to a feature representation space using a feature extractor. We use different loss functions to enforce consistency between the feature representations of associated data pairs of samples. We show that these learned representations are useful to deal with differences in data distributions in the domain adaptation problem. We performed experiments to study the main components of our model and we show that (i) learning of the consistent and contrastive feature representations is crucial to extract good discriminative features across different domains, and ii) our model benefits from the use of strong augmentation policies. With these findings, our method achieves state-of-t",
    "path": "papers/22/04/2204.01558.json",
    "total_tokens": 872,
    "translated_title": "Con$^{2}$DA：通过学习一致性和对比特征表示简化半监督领域自适应",
    "translated_abstract": "在这项工作中，我们提出了Con$^{2}$DA，一个简单的框架，将半监督学习的最新进展扩展到半监督领域自适应问题。我们的框架通过对给定输入进行随机数据转换生成配对的相关样本。关联的数据对通过特征提取器映射到特征表示空间。我们使用不同的损失函数来强制保持关联数据对样本的特征表示一致性。我们展示了这些学到的表示对于处理领域自适应问题中的数据分布差异是有用的。我们进行了实验来研究我们模型的主要组件，并展示了：(i) 学习一致性和对比特征表示对于跨不同领域提取好的判别特征至关重要，和(ii) 我们的模型从使用强数据增强策略中获益。基于这些发现，我们的方法实现了最先进的水平。",
    "tldr": "Con$^{2}$DA是一个简单的框架，通过学习一致性和对比特征表示，解决了半监督领域自适应问题，并实现了最先进的性能。"
}