{
    "title": "Are We Really Making Much Progress? Bag-of-Words vs. Sequence vs. Graph vs. Hierarchy for Single- and Multi-Label Text Classification. (arXiv:2204.03954v3 [cs.CL] UPDATED)",
    "abstract": "The popularity of graph neural networks has triggered a resurgence of graph-based methods for single-label and multi-label text classification. However, it is unclear whether these graph-based methods are beneficial compared to standard machine learning methods and modern pretrained language models. We compare a rich selection of bag-of-words, sequence-based, graph-based, and hierarchical methods for text classification. We aggregate results from the literature over 5 single-label and 7 multi-label datasets and run our own experiments. Our findings unambiguously demonstrate that for single-label and multi-label classification tasks, the graph-based methods fail to outperform fine-tuned language models and sometimes even perform worse than standard machine learning methods like multilayer perceptron (MLP) on a bag-of-words. This questions the enormous amount of effort put into the development of new graph-based methods in the last years and the promises they make for text classification",
    "link": "http://arxiv.org/abs/2204.03954",
    "context": "Title: Are We Really Making Much Progress? Bag-of-Words vs. Sequence vs. Graph vs. Hierarchy for Single- and Multi-Label Text Classification. (arXiv:2204.03954v3 [cs.CL] UPDATED)\nAbstract: The popularity of graph neural networks has triggered a resurgence of graph-based methods for single-label and multi-label text classification. However, it is unclear whether these graph-based methods are beneficial compared to standard machine learning methods and modern pretrained language models. We compare a rich selection of bag-of-words, sequence-based, graph-based, and hierarchical methods for text classification. We aggregate results from the literature over 5 single-label and 7 multi-label datasets and run our own experiments. Our findings unambiguously demonstrate that for single-label and multi-label classification tasks, the graph-based methods fail to outperform fine-tuned language models and sometimes even perform worse than standard machine learning methods like multilayer perceptron (MLP) on a bag-of-words. This questions the enormous amount of effort put into the development of new graph-based methods in the last years and the promises they make for text classification",
    "path": "papers/22/04/2204.03954.json",
    "total_tokens": 969,
    "translated_title": "我们真的取得了很大的进展吗？针对单标签和多标签文本分类的词袋、序列、图和层次结构的比较",
    "translated_abstract": "图神经网络的流行引发了单标签和多标签文本分类的图形方法的复苏。然而，这些基于图形的方法是否比标准机器学习方法和现代预训练语言模型更有益仍不清楚。本文比较了用于文本分类的丰富的词袋、基于序列、基于图形和分层方法。我们聚合了来自文献的结果，在5个单标签和7个多标签数据集上运行了我们自己的实验。我们的研究结果明确表明，在单标签和多标签分类任务中，基于图形的方法无法超越精调的语言模型，有时甚至表现不如词袋上的标准机器学习方法，这质疑了过去几年中为开发新的图形方法投入的巨大努力以及它们为文本分类带来的承诺。",
    "tldr": "本文比较了用于文本分类的词袋、序列、图形和分层方法，发现基于图形的方法无法超越现代预训练语言模型并且甚至有时表现不如标准机器学习方法，质疑了过去几年中为开发新的图形方法投入的巨大努力以及它们为文本分类带来的承诺。",
    "en_tdlr": "This paper compares bag-of-words, sequence-based, graph-based, and hierarchical methods for text classification and finds that graph-based methods fail to outperform modern pretrained language models and sometimes even perform worse than standard machine learning methods, questioning the enormous effort put into the development of new graph-based methods and the promises they make for text classification."
}