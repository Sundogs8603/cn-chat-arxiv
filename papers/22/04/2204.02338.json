{
    "title": "MGDCF: Distance Learning via Markov Graph Diffusion for Neural Collaborative Filtering. (arXiv:2204.02338v2 [cs.SI] UPDATED)",
    "abstract": "Graph Neural Networks (GNNs) have recently been utilized to build Collaborative Filtering (CF) models to predict user preferences based on historical user-item interactions. However, there is relatively little understanding of how GNN-based CF models relate to some traditional Network Representation Learning (NRL) approaches. In this paper, we show the equivalence between some state-of-the-art GNN-based CF models and a traditional 1-layer NRL model based on context encoding. Based on a Markov process that trades off two types of distances, we present Markov Graph Diffusion Collaborative Filtering (MGDCF) to generalize some state-of-the-art GNN-based CF models. Instead of considering the GNN as a trainable black box that propagates learnable user/item vertex embeddings, we treat GNNs as an untrainable Markov process that can construct constant context features of vertices for a traditional NRL model that encodes context features with a fully-connected layer. Such simplification can help",
    "link": "http://arxiv.org/abs/2204.02338",
    "context": "Title: MGDCF: Distance Learning via Markov Graph Diffusion for Neural Collaborative Filtering. (arXiv:2204.02338v2 [cs.SI] UPDATED)\nAbstract: Graph Neural Networks (GNNs) have recently been utilized to build Collaborative Filtering (CF) models to predict user preferences based on historical user-item interactions. However, there is relatively little understanding of how GNN-based CF models relate to some traditional Network Representation Learning (NRL) approaches. In this paper, we show the equivalence between some state-of-the-art GNN-based CF models and a traditional 1-layer NRL model based on context encoding. Based on a Markov process that trades off two types of distances, we present Markov Graph Diffusion Collaborative Filtering (MGDCF) to generalize some state-of-the-art GNN-based CF models. Instead of considering the GNN as a trainable black box that propagates learnable user/item vertex embeddings, we treat GNNs as an untrainable Markov process that can construct constant context features of vertices for a traditional NRL model that encodes context features with a fully-connected layer. Such simplification can help",
    "path": "papers/22/04/2204.02338.json",
    "total_tokens": 885,
    "translated_title": "MGDCF: 通过马尔可夫图扩散进行神经协同过滤的距离学习",
    "translated_abstract": "最近，图神经网络（GNN）被用于构建协同过滤（CF）模型，根据历史用户-物品交互来预测用户偏好。然而，对于基于GNN的CF模型与传统的网络表示学习（NRL）方法之间的关系，我们的了解还相对较少。本文通过一个交换两种类型的距离的马尔可夫过程，展示了一些最先进的基于GNN的CF模型与传统的一层NRL模型之间的等价性。基于这个马尔可夫图扩散协同过滤（MGDCF）模型，我们将GNN视为一个不可训练的马尔可夫过程，可以为一个基于完全连接层编码上下文特征的传统NRL模型构造顶点的常数上下文特征。这种简化有助于...",
    "tldr": "本文通过马尔可夫图扩散协同过滤（MGDCF）模型，展示了一些最先进的基于GNN的CF模型与传统的一层NRL模型之间的等价性，为神经协同过滤提供了新的距离学习方法。",
    "en_tdlr": "This paper demonstrates the equivalence between state-of-the-art GNN-based CF models and traditional 1-layer NRL models through Markov Graph Diffusion Collaborative Filtering (MGDCF), providing a new distance learning method for neural collaborative filtering."
}