{
    "title": "U-NO: U-shaped Neural Operators. (arXiv:2204.11127v3 [cs.LG] UPDATED)",
    "abstract": "Neural operators generalize classical neural networks to maps between infinite-dimensional spaces, e.g., function spaces. Prior works on neural operators proposed a series of novel methods to learn such maps and demonstrated unprecedented success in learning solution operators of partial differential equations. Due to their close proximity to fully connected architectures, these models mainly suffer from high memory usage and are generally limited to shallow deep learning models. In this paper, we propose U-shaped Neural Operator (U-NO), a U-shaped memory enhanced architecture that allows for deeper neural operators. U-NOs exploit the problem structures in function predictions and demonstrate fast training, data efficiency, and robustness with respect to hyperparameters choices. We study the performance of U-NO on PDE benchmarks, namely, Darcy's flow law and the Navier-Stokes equations. We show that U-NO results in an average of 26% and 44% prediction improvement on Darcy's flow and tu",
    "link": "http://arxiv.org/abs/2204.11127",
    "context": "Title: U-NO: U-shaped Neural Operators. (arXiv:2204.11127v3 [cs.LG] UPDATED)\nAbstract: Neural operators generalize classical neural networks to maps between infinite-dimensional spaces, e.g., function spaces. Prior works on neural operators proposed a series of novel methods to learn such maps and demonstrated unprecedented success in learning solution operators of partial differential equations. Due to their close proximity to fully connected architectures, these models mainly suffer from high memory usage and are generally limited to shallow deep learning models. In this paper, we propose U-shaped Neural Operator (U-NO), a U-shaped memory enhanced architecture that allows for deeper neural operators. U-NOs exploit the problem structures in function predictions and demonstrate fast training, data efficiency, and robustness with respect to hyperparameters choices. We study the performance of U-NO on PDE benchmarks, namely, Darcy's flow law and the Navier-Stokes equations. We show that U-NO results in an average of 26% and 44% prediction improvement on Darcy's flow and tu",
    "path": "papers/22/04/2204.11127.json",
    "total_tokens": 941,
    "translated_title": "U-NO：U形神经算子",
    "translated_abstract": "神经算子将经典神经网络推广到了无限维空间之间的映射，例如函数空间。先前的神经算子研究提出了一系列新方法来学习这样的映射，并在学习偏微分方程的解算子方面取得了空前的成功。由于它们与全连接架构非常接近，这些模型主要受到高内存使用率的困扰，并且通常仅限于浅层的深度学习模型。在本文中，我们提出了U-NO（U形神经算子），这是一种U形记忆增强架构，允许更深的神经算子。U-NO利用函数预测中的问题结构，并展示了快速训练、数据效率和对超参数选择的鲁棒性。我们研究了U-NO在PDE基准测试中的表现，即Darcy流动定律和Navier-Stokes方程。我们展示了U-NO在Darcy流和Tu的平均预测改进分别达到26％和44％。",
    "tldr": "本文提出了U-NO，一种U形记忆增强架构，允许更深的神经算子，通过利用函数预测中的问题结构，在解决偏微分方程方面表现出快速训练、数据效率和对超参数选择的鲁棒性。",
    "en_tdlr": "This paper proposes U-NO, a U-shaped memory-enhanced architecture that allows for deeper neural operators, demonstrating fast training, data efficiency, and robustness with respect to hyperparameters choices by exploiting the problem structures in function predictions. It shows an average of 26% and 44% prediction improvement on Darcy's flow and turbulent heat transfer respectively in PDE benchmarks."
}