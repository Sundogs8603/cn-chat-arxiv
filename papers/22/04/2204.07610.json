{
    "title": "Sources of Irreproducibility in Machine Learning: A Review. (arXiv:2204.07610v2 [cs.LG] UPDATED)",
    "abstract": "Background: Many published machine learning studies are irreproducible. Issues with methodology and not properly accounting for variation introduced by the algorithm themselves or their implementations are attributed as the main contributors to the irreproducibility.Problem: There exist no theoretical framework that relates experiment design choices to potential effects on the conclusions. Without such a framework, it is much harder for practitioners and researchers to evaluate experiment results and describe the limitations of experiments. The lack of such a framework also makes it harder for independent researchers to systematically attribute the causes of failed reproducibility experiments. Objective: The objective of this paper is to develop a framework that enable applied data science practitioners and researchers to understand which experiment design choices can lead to false findings and how and by this help in analyzing the conclusions of reproducibility experiments. Method: We",
    "link": "http://arxiv.org/abs/2204.07610",
    "context": "Title: Sources of Irreproducibility in Machine Learning: A Review. (arXiv:2204.07610v2 [cs.LG] UPDATED)\nAbstract: Background: Many published machine learning studies are irreproducible. Issues with methodology and not properly accounting for variation introduced by the algorithm themselves or their implementations are attributed as the main contributors to the irreproducibility.Problem: There exist no theoretical framework that relates experiment design choices to potential effects on the conclusions. Without such a framework, it is much harder for practitioners and researchers to evaluate experiment results and describe the limitations of experiments. The lack of such a framework also makes it harder for independent researchers to systematically attribute the causes of failed reproducibility experiments. Objective: The objective of this paper is to develop a framework that enable applied data science practitioners and researchers to understand which experiment design choices can lead to false findings and how and by this help in analyzing the conclusions of reproducibility experiments. Method: We",
    "path": "papers/22/04/2204.07610.json",
    "total_tokens": 1149,
    "translated_title": "机器学习中的不可重复性来源：一篇综述",
    "translated_abstract": "背景：许多发布的机器学习研究是不可重复的。方法论问题以及未能正确考虑算法本身或其实现引入的变异被认为是不可重复性的主要贡献因素。问题：不存在将实验设计选择与其对结论的潜在影响联系起来的理论框架。缺乏这样的框架，从业者和研究人员评估实验结果和描述实验的限制会更加困难。缺乏这样的框架也使得独立研究人员难以系统地归因于失败的可重复性实验的原因。目标：本文的目的是开发一个框架，使应用数据科学从业者和研究人员能够理解哪些实验设计选择可能导致误导性的发现，并通过此理解如何分析可重复性实验的结论，从而帮助分析结论。方法：我们提出了一个理解机器学习中不可重复性来源的框架，包括算法选择、数据变异、实验设置和实现细节。我们回顾了关于可重复性的最近文献，确定了常见问题，并提供了如何解决这些问题对机器学习研究可重复性的影响的例子。结果：我们发现实验设置问题和未能正确考虑数据变异是机器学习研究中最常见的不可重复性来源。结论：更好地理解这些不可重复性来源可以提高机器学习研究的可重复性，并增加结果的信心。",
    "tldr": "本文提出了一个理解机器学习中不可重复性来源的框架，并指出实验设置问题和未能正确考虑数据变异是机器学习研究中最常见的不可重复性来源。"
}