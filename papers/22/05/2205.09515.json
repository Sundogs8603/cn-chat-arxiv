{
    "title": "Variational Inference for Bayesian Bridge Regression. (arXiv:2205.09515v2 [stat.ML] UPDATED)",
    "abstract": "We study the implementation of Automatic Differentiation Variational inference (ADVI) for Bayesian inference on regression models with bridge penalization. The bridge approach uses $\\ell_{\\alpha}$ norm, with $\\alpha \\in (0, +\\infty)$ to define a penalization on large values of the regression coefficients, which includes the Lasso ($\\alpha = 1$) and ridge $(\\alpha = 2)$ penalizations as special cases. Full Bayesian inference seamlessly provides joint uncertainty estimates for all model parameters. Although MCMC aproaches are available for bridge regression, it can be slow for large dataset, specially in high dimensions. The ADVI implementation allows the use of small batches of data at each iteration (due to stochastic gradient based algorithms), therefore speeding up computational time in comparison with MCMC. We illustrate the approach on non-parametric regression models with B-splines, although the method works seamlessly for other choices of basis functions. A simulation study shows",
    "link": "http://arxiv.org/abs/2205.09515",
    "context": "Title: Variational Inference for Bayesian Bridge Regression. (arXiv:2205.09515v2 [stat.ML] UPDATED)\nAbstract: We study the implementation of Automatic Differentiation Variational inference (ADVI) for Bayesian inference on regression models with bridge penalization. The bridge approach uses $\\ell_{\\alpha}$ norm, with $\\alpha \\in (0, +\\infty)$ to define a penalization on large values of the regression coefficients, which includes the Lasso ($\\alpha = 1$) and ridge $(\\alpha = 2)$ penalizations as special cases. Full Bayesian inference seamlessly provides joint uncertainty estimates for all model parameters. Although MCMC aproaches are available for bridge regression, it can be slow for large dataset, specially in high dimensions. The ADVI implementation allows the use of small batches of data at each iteration (due to stochastic gradient based algorithms), therefore speeding up computational time in comparison with MCMC. We illustrate the approach on non-parametric regression models with B-splines, although the method works seamlessly for other choices of basis functions. A simulation study shows",
    "path": "papers/22/05/2205.09515.json",
    "total_tokens": 942,
    "translated_title": "变分推断用于贝叶斯桥回归",
    "translated_abstract": "我们研究了自动微分变分推断在具有桥惩罚的回归模型上的贝叶斯推断实现。桥方法使用$\\ell_{\\alpha}$范数，其中$\\alpha \\in (0, +\\infty)$，对回归系数的大值进行惩罚，包括Lasso ($\\alpha = 1$)和岭回归$(\\alpha = 2)$惩罚作为特殊情况。全贝叶斯推断无缝地提供了所有模型参数的联合不确定性估计。尽管桥回归的MCMC方法可用，但对于大规模数据集，特别是在高维情况下，可能较慢。ADVI实现允许在每次迭代中使用小批量数据（由于基于随机梯度的算法），从而加速计算时间与MCMC相比。我们通过对B样条非参数回归模型进行了方法说明，尽管该方法对于其他基础函数的选择也可以无缝使用。模拟研究说明了方法的性能。",
    "tldr": "本文研究了自动微分变分推断在具有桥惩罚的回归模型上的应用，该方法通过使用小批量数据并提供全贝叶斯推断结果来加速计算时间。通过在B样条非参数回归模型上进行的模拟研究，验证了该方法的性能。",
    "en_tdlr": "This paper investigates the application of automatic differentiation variational inference (ADVI) in regression models with bridge penalization. The method accelerates computational time by using small batches of data and provides full Bayesian inference results. The performance of the method is demonstrated through a simulation study on B-spline nonparametric regression models."
}