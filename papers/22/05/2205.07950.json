{
    "title": "The Power of Tests for Detecting $p$-Hacking. (arXiv:2205.07950v2 [econ.EM] UPDATED)",
    "abstract": "$p$-Hacking can undermine the validity of empirical studies. A flourishing empirical literature investigates the prevalence of $p$-hacking based on the empirical distribution of reported $p$-values across studies. Interpreting results in this literature requires a careful understanding of the power of methods used to detect different types of $p$-hacking. We theoretically study the implications of likely forms of $p$-hacking on the distribution of reported $p$-values and the power of existing methods for detecting it. Power can be quite low, depending crucially on the particular $p$-hacking strategy and the distribution of actual effects tested by the studies. Publication bias can enhance the power for testing the joint null hypothesis of no $p$-hacking and no publication bias. We relate the power of the tests to the costs of $p$-hacking and show that power tends to be larger when $p$-hacking is very costly. Monte Carlo simulations support our theoretical results.",
    "link": "http://arxiv.org/abs/2205.07950",
    "context": "Title: The Power of Tests for Detecting $p$-Hacking. (arXiv:2205.07950v2 [econ.EM] UPDATED)\nAbstract: $p$-Hacking can undermine the validity of empirical studies. A flourishing empirical literature investigates the prevalence of $p$-hacking based on the empirical distribution of reported $p$-values across studies. Interpreting results in this literature requires a careful understanding of the power of methods used to detect different types of $p$-hacking. We theoretically study the implications of likely forms of $p$-hacking on the distribution of reported $p$-values and the power of existing methods for detecting it. Power can be quite low, depending crucially on the particular $p$-hacking strategy and the distribution of actual effects tested by the studies. Publication bias can enhance the power for testing the joint null hypothesis of no $p$-hacking and no publication bias. We relate the power of the tests to the costs of $p$-hacking and show that power tends to be larger when $p$-hacking is very costly. Monte Carlo simulations support our theoretical results.",
    "path": "papers/22/05/2205.07950.json",
    "total_tokens": 970,
    "translated_title": "测试揭示“p-hacking”的能力",
    "translated_abstract": "$p$-Hacking可能会削弱经验研究的有效性。一篇繁荣的经验文献调查了基于报告的$p$-value在研究中的分布的$p$-hacking的普遍存在。解释这个文献中的结果需要仔细理解用于检测不同类型$p$-hacking的方法的能力。我们从理论上研究了$p$-hacking的可能形式对报告的$p$-value分布和现有检测方法的能力的影响。能力可能非常低，关键取决于特定的$p$-hacking策略和研究测试的实际效果的分布。出版偏差可以增强测试无$p$-hacking和无出版偏差的联合零假设的能力。我们将测试的能力与$p$-hacking的成本相关联，并显示当$p$-hacking非常昂贵时，能力倾向于更大。蒙特卡罗模拟支持我们的理论结果。",
    "tldr": "本文从理论和模拟的层面，研究了$p$-hacking的可能形式对$p-value$分布和现有检测方法的影响，证明了测试揭示“p-hacking”的能力可能非常低，并且关键取决于具体的$p$-hacking策略和研究测试的实际效果的分布。",
    "en_tdlr": "This paper theoretically and through simulation studies the effects of $p$-hacking on $p$-value distribution and existing detection methods, revealing a potentially low power for detecting $p$-hacking depending on the specific $p$-hacking strategy and distribution of actual effects tested, with publication bias possibly enhancing the detection power of joint null hypothesis of no $p$-hacking and publication bias."
}