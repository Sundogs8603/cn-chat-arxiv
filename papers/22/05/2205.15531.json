{
    "title": "itKD: Interchange Transfer-based Knowledge Distillation for 3D Object Detection. (arXiv:2205.15531v2 [cs.CV] UPDATED)",
    "abstract": "Point-cloud based 3D object detectors recently have achieved remarkable progress. However, most studies are limited to the development of network architectures for improving only their accuracy without consideration of the computational efficiency. In this paper, we first propose an autoencoder-style framework comprising channel-wise compression and decompression via interchange transfer-based knowledge distillation. To learn the map-view feature of a teacher network, the features from teacher and student networks are independently passed through the shared autoencoder; here, we use a compressed representation loss that binds the channel-wised compression knowledge from both student and teacher networks as a kind of regularization. The decompressed features are transferred in opposite directions to reduce the gap in the interchange reconstructions. Lastly, we present an head attention loss to match the 3D object detection information drawn by the multi-head self-attention mechanism. Th",
    "link": "http://arxiv.org/abs/2205.15531",
    "context": "Title: itKD: Interchange Transfer-based Knowledge Distillation for 3D Object Detection. (arXiv:2205.15531v2 [cs.CV] UPDATED)\nAbstract: Point-cloud based 3D object detectors recently have achieved remarkable progress. However, most studies are limited to the development of network architectures for improving only their accuracy without consideration of the computational efficiency. In this paper, we first propose an autoencoder-style framework comprising channel-wise compression and decompression via interchange transfer-based knowledge distillation. To learn the map-view feature of a teacher network, the features from teacher and student networks are independently passed through the shared autoencoder; here, we use a compressed representation loss that binds the channel-wised compression knowledge from both student and teacher networks as a kind of regularization. The decompressed features are transferred in opposite directions to reduce the gap in the interchange reconstructions. Lastly, we present an head attention loss to match the 3D object detection information drawn by the multi-head self-attention mechanism. Th",
    "path": "papers/22/05/2205.15531.json",
    "total_tokens": 855,
    "translated_title": "itKD: 基于交换传递的知识蒸馏用于3D物体检测",
    "translated_abstract": "基于点云的3D物体检测最近取得了显著进展。然而，大多数研究仅关注提高准确性，而没有考虑计算效率。本文首先提出了一个自编码器风格的框架，通过基于交换传递的知识蒸馏进行通道压缩和解压缩。为了学习教师网络的地图视图特征，从教师和学生网络得到的特征被独立地通过共享的自编码器传递；这里，我们使用了一种压缩表示损失，将学生和教师网络的通道压缩知识作为一种正则化进行绑定。解压的特征反向传递以减小交换重构中的差距。最后，我们提出了一个头部注意力损失，以匹配多头自注意机制所提取的3D物体检测信息。",
    "tldr": "提出了基于交换传递的知识蒸馏框架，用于3D物体检测，同时考虑准确性和计算效率，具有压缩表示损失和头部注意力损失等优化手段。",
    "en_tdlr": "Proposed a framework for 3D object detection using interchange transfer-based knowledge distillation, which considers both accuracy and computational efficiency, with optimization measures such as compressed representation loss and head attention loss."
}