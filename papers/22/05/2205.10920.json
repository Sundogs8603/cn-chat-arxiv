{
    "title": "Test-Time Robust Personalization for Federated Learning. (arXiv:2205.10920v4 [cs.LG] UPDATED)",
    "abstract": "Federated Learning (FL) is a machine learning paradigm where many clients collaboratively learn a shared global model with decentralized training data. Personalized FL additionally adapts the global model to different clients, achieving promising results on consistent local training and test distributions. However, for real-world personalized FL applications, it is crucial to go one step further: robustifying FL models under the evolving local test set during deployment, where various distribution shifts can arise. In this work, we identify the pitfalls of existing works under test-time distribution shifts and propose Federated Test-time Head Ensemble plus tuning(FedTHE+), which personalizes FL models with robustness to various test-time distribution shifts. We illustrate the advancement of FedTHE+ (and its computationally efficient variant FedTHE) over strong competitors, by training various neural architectures (CNN, ResNet, and Transformer) on CIFAR10 andImageNet with various test d",
    "link": "http://arxiv.org/abs/2205.10920",
    "context": "Title: Test-Time Robust Personalization for Federated Learning. (arXiv:2205.10920v4 [cs.LG] UPDATED)\nAbstract: Federated Learning (FL) is a machine learning paradigm where many clients collaboratively learn a shared global model with decentralized training data. Personalized FL additionally adapts the global model to different clients, achieving promising results on consistent local training and test distributions. However, for real-world personalized FL applications, it is crucial to go one step further: robustifying FL models under the evolving local test set during deployment, where various distribution shifts can arise. In this work, we identify the pitfalls of existing works under test-time distribution shifts and propose Federated Test-time Head Ensemble plus tuning(FedTHE+), which personalizes FL models with robustness to various test-time distribution shifts. We illustrate the advancement of FedTHE+ (and its computationally efficient variant FedTHE) over strong competitors, by training various neural architectures (CNN, ResNet, and Transformer) on CIFAR10 andImageNet with various test d",
    "path": "papers/22/05/2205.10920.json",
    "total_tokens": 877,
    "translated_title": "基于联邦学习的测试时间鲁棒个性化方法(更新版)",
    "translated_abstract": "联邦学习是一种机器学习模式，在这种模式下，许多客户端协作学习一个共享的全局模型，并利用分散的训练数据进行学习。个性化联邦学习通过将全局模型适应于不同的客户端，实现了在一致的本地训练和测试分布下取得有益结果。然而，在真实世界中，个性化联邦学习应用还需要更进一步：在部署期间，在演化的本地测试集下，建立能够抵御各种测试时间分布转移的联邦学习模型。本论文基于此，提出了Federated Test-time Head Ensemble plus tuning(FedTHE+)方法，它能够让联邦学习模型具有鲁棒性，抵御各种测试时间分布转移的影响。通过对CIFAR10和ImageNet上的各种神经网络架构（CNN，ResNet和Transformer）进行训练，我们展示了FedTHE+（及其计算效率更高的变种FedTHE）相对于其他强有力的竞争对手的改进。",
    "tldr": "本文提出了FedTHE+方法，它能够使联邦学习模型具有鲁棒性，抵御各种测试时间分布转移的影响。",
    "en_tdlr": "This paper proposes the FedTHE+ method, which makes federated learning models robust and resistant to various test-time distribution shifts."
}