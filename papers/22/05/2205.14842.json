{
    "title": "Efficient Reward Poisoning Attacks on Online Deep Reinforcement Learning. (arXiv:2205.14842v2 [cs.LG] UPDATED)",
    "abstract": "We study reward poisoning attacks on online deep reinforcement learning (DRL), where the attacker is oblivious to the learning algorithm used by the agent and the dynamics of the environment. We demonstrate the intrinsic vulnerability of state-of-the-art DRL algorithms by designing a general, black-box reward poisoning framework called adversarial MDP attacks. We instantiate our framework to construct two new attacks which only corrupt the rewards for a small fraction of the total training timesteps and make the agent learn a low-performing policy. We provide a theoretical analysis of the efficiency of our attack and perform an extensive empirical evaluation. Our results show that our attacks efficiently poison agents learning in several popular classical control and MuJoCo environments with a variety of state-of-the-art DRL algorithms, such as DQN, PPO, SAC, etc.",
    "link": "http://arxiv.org/abs/2205.14842",
    "context": "Title: Efficient Reward Poisoning Attacks on Online Deep Reinforcement Learning. (arXiv:2205.14842v2 [cs.LG] UPDATED)\nAbstract: We study reward poisoning attacks on online deep reinforcement learning (DRL), where the attacker is oblivious to the learning algorithm used by the agent and the dynamics of the environment. We demonstrate the intrinsic vulnerability of state-of-the-art DRL algorithms by designing a general, black-box reward poisoning framework called adversarial MDP attacks. We instantiate our framework to construct two new attacks which only corrupt the rewards for a small fraction of the total training timesteps and make the agent learn a low-performing policy. We provide a theoretical analysis of the efficiency of our attack and perform an extensive empirical evaluation. Our results show that our attacks efficiently poison agents learning in several popular classical control and MuJoCo environments with a variety of state-of-the-art DRL algorithms, such as DQN, PPO, SAC, etc.",
    "path": "papers/22/05/2205.14842.json",
    "total_tokens": 892,
    "translated_title": "在线深度强化学习上的高效奖励污染攻击",
    "translated_abstract": "本文研究了在线深度强化学习中的奖励污染攻击，攻击者对智能体使用的学习算法和环境动态一无所知。我们通过设计一种称为对抗MDP攻击的通用黑盒奖励污染框架，展示了现有深度强化学习算法内在的漏洞。我们将该框架实例化为两种新攻击，只破坏了总训练时间步数的少量奖励，并使代理学习低效策略。我们对攻击效率进行了理论分析，并进行了广泛的实证评估。结果表明我们的攻击能有效地污染使用多种最先进DRL算法（如DQN、PPO、SAC等）来学习的智能体，在多个受欢迎的经典控制和MuJoCo环境中具有较高效率。",
    "tldr": "本文通过设计一种通用的奖励污染框架展示了现有深度强化学习算法内在的漏洞，提出了两种新攻击方式，成功污染多种最先进DRL算法的智能体在多个环境中学习的效率，给深度强化学习提供了新的安全风险。",
    "en_tdlr": "This paper demonstrates the intrinsic vulnerability of state-of-the-art DRL algorithms by designing a general, black-box reward poisoning framework, and proposes two new attacks that efficiently poison multiple advanced DRL algorithms in various environments, providing new security risks for deep reinforcement learning."
}