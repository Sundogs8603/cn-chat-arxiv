{
    "title": "Embed to Control Partially Observed Systems: Representation Learning with Provable Sample Efficiency",
    "abstract": "arXiv:2205.13476v2 Announce Type: replace-cross  Abstract: Reinforcement learning in partially observed Markov decision processes (POMDPs) faces two challenges. (i) It often takes the full history to predict the future, which induces a sample complexity that scales exponentially with the horizon. (ii) The observation and state spaces are often continuous, which induces a sample complexity that scales exponentially with the extrinsic dimension. Addressing such challenges requires learning a minimal but sufficient representation of the observation and state histories by exploiting the structure of the POMDP.   To this end, we propose a reinforcement learning algorithm named Embed to Control (ETC), which learns the representation at two levels while optimizing the policy.~(i) For each step, ETC learns to represent the state with a low-dimensional feature, which factorizes the transition kernel. (ii) Across multiple steps, ETC learns to represent the full history with a low-dimensional emb",
    "link": "https://arxiv.org/abs/2205.13476",
    "context": "Title: Embed to Control Partially Observed Systems: Representation Learning with Provable Sample Efficiency\nAbstract: arXiv:2205.13476v2 Announce Type: replace-cross  Abstract: Reinforcement learning in partially observed Markov decision processes (POMDPs) faces two challenges. (i) It often takes the full history to predict the future, which induces a sample complexity that scales exponentially with the horizon. (ii) The observation and state spaces are often continuous, which induces a sample complexity that scales exponentially with the extrinsic dimension. Addressing such challenges requires learning a minimal but sufficient representation of the observation and state histories by exploiting the structure of the POMDP.   To this end, we propose a reinforcement learning algorithm named Embed to Control (ETC), which learns the representation at two levels while optimizing the policy.~(i) For each step, ETC learns to represent the state with a low-dimensional feature, which factorizes the transition kernel. (ii) Across multiple steps, ETC learns to represent the full history with a low-dimensional emb",
    "path": "papers/22/05/2205.13476.json",
    "total_tokens": 869,
    "translated_title": "嵌入控制部分观察系统：具有可证明样本效率的表示学习",
    "translated_abstract": "强化学习在部分观察马尔可夫决策过程（POMDPs）中面临两个挑战。一是通常需要全部历史记录来预测未来，这导致样本复杂度随着时间跨度呈指数级增长。二是观测和状态空间通常是连续的，这导致样本复杂度随外在维数呈指数级增长。为了解决这些挑战，需要通过利用POMDP的结构学习观测和状态历史的最小但足够的表示。为此，我们提出了一种名为Embed to Control (ETC)的强化学习算法，该算法在优化策略的同时学习两个级别的表示。(i)在每一步，ETC学习用低维特征表示状态，这对转移核进行因子分解。(ii)在多个步骤中，ETC学习用低维表示完整历史记录。",
    "tldr": "论文提出了一种名为Embed to Control（ETC）的强化学习算法，通过在两个级别学习表示的方法来解决部分观察马尔可夫决策问题，以实现样本高效利用。",
    "en_tdlr": "The paper introduces a reinforcement learning algorithm named Embed to Control (ETC) that addresses partially observed Markov decision processes by learning representations at two levels, aiming to achieve sample efficiency."
}