{
    "title": "DELTA: Diverse Client Sampling for Fasting Federated Learning. (arXiv:2205.13925v3 [cs.LG] UPDATED)",
    "abstract": "Partial client participation has been widely adopted in Federated Learning (FL) to reduce the communication burden efficiently. However, an inadequate client sampling scheme can lead to the selection of unrepresentative subsets, resulting in significant variance in model updates and slowed convergence. Existing sampling methods are either biased or can be further optimized for faster convergence.In this paper, we present DELTA, an unbiased sampling scheme designed to alleviate these issues. DELTA characterizes the effects of client diversity and local variance, and samples representative clients with valuable information for global model updates. In addition, DELTA is a proven optimal unbiased sampling scheme that minimizes variance caused by partial client participation and outperforms other unbiased sampling schemes in terms of convergence. Furthermore, to address full-client gradient dependence,we provide a practical version of DELTA depending on the available clients' information, ",
    "link": "http://arxiv.org/abs/2205.13925",
    "context": "Title: DELTA: Diverse Client Sampling for Fasting Federated Learning. (arXiv:2205.13925v3 [cs.LG] UPDATED)\nAbstract: Partial client participation has been widely adopted in Federated Learning (FL) to reduce the communication burden efficiently. However, an inadequate client sampling scheme can lead to the selection of unrepresentative subsets, resulting in significant variance in model updates and slowed convergence. Existing sampling methods are either biased or can be further optimized for faster convergence.In this paper, we present DELTA, an unbiased sampling scheme designed to alleviate these issues. DELTA characterizes the effects of client diversity and local variance, and samples representative clients with valuable information for global model updates. In addition, DELTA is a proven optimal unbiased sampling scheme that minimizes variance caused by partial client participation and outperforms other unbiased sampling schemes in terms of convergence. Furthermore, to address full-client gradient dependence,we provide a practical version of DELTA depending on the available clients' information, ",
    "path": "papers/22/05/2205.13925.json",
    "total_tokens": 976,
    "translated_title": "DELTA: 多样化客户抽样用于快速联邦学习",
    "translated_abstract": "在联邦学习中，部分客户端参与已被广泛应用以高效减少通信负担。然而，不合适的客户端抽样方案可能导致选择出不具代表性子集，从而导致模型更新的显著方差和收敛速度的减慢。现有的抽样方法可能会有偏差，或者可以进一步优化以实现更快的收敛。本文介绍了 DELTA，这是一种设计用于缓解这些问题的无偏抽样方案。DELTA 刻画了客户端的多样性和局部方差的影响，并选择具有全局模型更新所需有价值信息的代表性客户端。此外，DELTA 是一种经过证明的最优无偏抽样方案，在减少由部分客户端参与引起的方差方面优于其他无偏抽样方案。此外，为解决全客户端梯度依赖性，我们提供了一个实用版本的 DELTA，它取决于可用客户端的信息。",
    "tldr": "DELTA 提出了一个无偏抽样方案来减少部分客户端参与所引起的方差，以缓解现有抽样方法可能导致性能下降的问题，它考虑了客户端的多样性和局部方差的影响，并选择具有全局模型更新所需有价值信息的代表性客户端。实验结果表明，DELTA 可以优于其他无偏抽样方案并加速模型收敛速度。",
    "en_tdlr": "DELTA proposes an unbiased sampling scheme to alleviate the variance caused by partial client participation in Federated Learning. It considers the diversity of clients and their local variances, and selects representative clients with valuable information for global model updates. DELTA outperforms other unbiased sampling schemes in terms of convergence. Practical versions of DELTA are provided to address full-client gradient dependence."
}