{
    "title": "Phased Progressive Learning with Coupling-Regulation-Imbalance Loss for Imbalanced Data Classification. (arXiv:2205.12117v3 [cs.LG] UPDATED)",
    "abstract": "Deep convolutional neural networks often perform poorly when faced with datasets that suffer from quantity imbalances and classification difficulties. Despite advances in the field, existing two-stage approaches still exhibit dataset bias or domain shift. To counter this, a phased progressive learning schedule has been proposed that gradually shifts the emphasis from representation learning to training the upper classifier. This approach is particularly beneficial for datasets with larger imbalances or fewer samples. Another new method a coupling-regulation-imbalance loss function is proposed, which combines three parts: a correction term, Focal loss, and LDAM loss. This loss is effective in addressing quantity imbalances and outliers, while regulating the focus of attention on samples with varying classification difficulties. These approaches have yielded satisfactory results on several benchmark datasets, including Imbalanced CIFAR10, Imbalanced CIFAR100, ImageNet-LT, and iNaturalist",
    "link": "http://arxiv.org/abs/2205.12117",
    "context": "Title: Phased Progressive Learning with Coupling-Regulation-Imbalance Loss for Imbalanced Data Classification. (arXiv:2205.12117v3 [cs.LG] UPDATED)\nAbstract: Deep convolutional neural networks often perform poorly when faced with datasets that suffer from quantity imbalances and classification difficulties. Despite advances in the field, existing two-stage approaches still exhibit dataset bias or domain shift. To counter this, a phased progressive learning schedule has been proposed that gradually shifts the emphasis from representation learning to training the upper classifier. This approach is particularly beneficial for datasets with larger imbalances or fewer samples. Another new method a coupling-regulation-imbalance loss function is proposed, which combines three parts: a correction term, Focal loss, and LDAM loss. This loss is effective in addressing quantity imbalances and outliers, while regulating the focus of attention on samples with varying classification difficulties. These approaches have yielded satisfactory results on several benchmark datasets, including Imbalanced CIFAR10, Imbalanced CIFAR100, ImageNet-LT, and iNaturalist",
    "path": "papers/22/05/2205.12117.json",
    "total_tokens": 895,
    "translated_title": "使用耦合调节不平衡损失的分阶段渐进学习来解决不平衡数据分类问题",
    "translated_abstract": "当面临数量不平衡和分类困难的数据集时，深度卷积神经网络通常表现不佳。尽管该领域取得了一些进展，但现有的两阶段方法仍然存在数据集偏见或域偏移。为了解决这个问题，提出了一种分阶段逐渐将重点从表示学习转向训练上层分类器的学习计划。对于具有较大失衡或样本较少的数据集，这种方法特别有益。另外，提出了一种耦合调节不平衡损失函数，它将三个部分组合在一起：校正项，Focal 损失和 LDAM 损失。这种损失有效地解决了数量不平衡和离群值问题，同时调节关注具有不同分类困难度的样本。这些方法在多个基准数据集上取得了令人满意的结果，包括 Imbalanced CIFAR10、Imbalanced CIFAR100、ImageNet-LT 和 iNaturalist。",
    "tldr": "该论文提出了一种分阶段渐进学习的方法和一种耦合调节不平衡损失函数来解决不平衡数据分类问题，该方法特别适用于具有失衡或样本较少的数据集。",
    "en_tdlr": "This paper proposes a phased progressive learning approach and a coupling-regulation-imbalance loss function to solve imbalanced data classification problems, which is particularly suitable for datasets with imbalances or fewer samples."
}