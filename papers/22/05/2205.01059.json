{
    "title": "Enhanced Physics-Informed Neural Networks with Augmented Lagrangian Relaxation Method (AL-PINNs). (arXiv:2205.01059v2 [cs.LG] UPDATED)",
    "abstract": "Physics-Informed Neural Networks (PINNs) have become a prominent application of deep learning in scientific computation, as they are powerful approximators of solutions to nonlinear partial differential equations (PDEs). There have been numerous attempts to facilitate the training process of PINNs by adjusting the weight of each component of the loss function, called adaptive loss-balancing algorithms. In this paper, we propose an Augmented Lagrangian relaxation method for PINNs (AL-PINNs). We treat the initial and boundary conditions as constraints for the optimization problem of the PDE residual. By employing Augmented Lagrangian relaxation, the constrained optimization problem becomes a sequential max-min problem so that the learnable parameters $\\lambda$ adaptively balance each loss component. Our theoretical analysis reveals that the sequence of minimizers of the proposed loss functions converges to an actual solution for the Helmholtz, viscous Burgers, and Klein--Gordon equations",
    "link": "http://arxiv.org/abs/2205.01059",
    "context": "Title: Enhanced Physics-Informed Neural Networks with Augmented Lagrangian Relaxation Method (AL-PINNs). (arXiv:2205.01059v2 [cs.LG] UPDATED)\nAbstract: Physics-Informed Neural Networks (PINNs) have become a prominent application of deep learning in scientific computation, as they are powerful approximators of solutions to nonlinear partial differential equations (PDEs). There have been numerous attempts to facilitate the training process of PINNs by adjusting the weight of each component of the loss function, called adaptive loss-balancing algorithms. In this paper, we propose an Augmented Lagrangian relaxation method for PINNs (AL-PINNs). We treat the initial and boundary conditions as constraints for the optimization problem of the PDE residual. By employing Augmented Lagrangian relaxation, the constrained optimization problem becomes a sequential max-min problem so that the learnable parameters $\\lambda$ adaptively balance each loss component. Our theoretical analysis reveals that the sequence of minimizers of the proposed loss functions converges to an actual solution for the Helmholtz, viscous Burgers, and Klein--Gordon equations",
    "path": "papers/22/05/2205.01059.json",
    "total_tokens": 850,
    "translated_title": "增强物理信息神经网络的增广拉格朗日松弛方法（AL-PINNs）",
    "translated_abstract": "物理信息神经网络（PINNs）已成为科学计算中深度学习的杰出应用，它们是非线性偏微分方程（PDE）解的强大逼近器。本文提出了一种增广拉格朗日松弛方法（AL-PINNs）用于PINNs的训练。我们将初始和边界条件视为PDE残差优化问题的约束条件。通过应用增广拉格朗日松弛方法，约束优化问题变成了一个顺序的最大-最小问题，使可以学习的参数λ能自适应平衡每个损失组件。我们的理论分析表明，所提出的损失函数的最小化序列收敛于Helmholtz、粘性Burgers和Klein-Gordon方程的实际解。",
    "tldr": "本文提出一种增广拉格朗日松弛方法(AL-PINNs)用于物理信息神经网络(PINNs)的训练，该方法通过自适应平衡每个损失组件，能够有效地解决非线性偏微分方程问题。",
    "en_tdlr": "The paper proposes an Augmented Lagrangian relaxation method (AL-PINNs) for the training of physics-informed neural networks (PINNs), which can effectively solve nonlinear partial differential equation problems by adaptively balancing each loss component."
}