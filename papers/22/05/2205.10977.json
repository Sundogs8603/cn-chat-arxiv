{
    "title": "What should I Ask: A Knowledge-driven Approach for Follow-up Questions Generation in Conversational Surveys. (arXiv:2205.10977v2 [cs.CL] UPDATED)",
    "abstract": "Generating follow-up questions on the fly could significantly improve conversational survey quality and user experiences by enabling a more dynamic and personalized survey structure. In this paper, we proposed a novel task for knowledge-driven follow-up question generation in conversational surveys. We constructed a new human-annotated dataset of human-written follow-up questions with dialogue history and labeled knowledge in the context of conversational surveys. Along with the dataset, we designed and validated a set of reference-free Gricean-inspired evaluation metrics to systematically evaluate the quality of generated follow-up questions. We then propose a two-staged knowledge-driven model for the task, which generates informative and coherent follow-up questions by using knowledge to steer the generation process. The experiments demonstrate that compared to GPT-based baseline models, our two-staged model generates more informative, coherent, and clear follow-up questions.",
    "link": "http://arxiv.org/abs/2205.10977",
    "context": "Title: What should I Ask: A Knowledge-driven Approach for Follow-up Questions Generation in Conversational Surveys. (arXiv:2205.10977v2 [cs.CL] UPDATED)\nAbstract: Generating follow-up questions on the fly could significantly improve conversational survey quality and user experiences by enabling a more dynamic and personalized survey structure. In this paper, we proposed a novel task for knowledge-driven follow-up question generation in conversational surveys. We constructed a new human-annotated dataset of human-written follow-up questions with dialogue history and labeled knowledge in the context of conversational surveys. Along with the dataset, we designed and validated a set of reference-free Gricean-inspired evaluation metrics to systematically evaluate the quality of generated follow-up questions. We then propose a two-staged knowledge-driven model for the task, which generates informative and coherent follow-up questions by using knowledge to steer the generation process. The experiments demonstrate that compared to GPT-based baseline models, our two-staged model generates more informative, coherent, and clear follow-up questions.",
    "path": "papers/22/05/2205.10977.json",
    "total_tokens": 833,
    "translated_title": "分类调查中基于知识的追加问题生成的知识驱动方法",
    "translated_abstract": "实时生成追加问题可以通过启用更动态和个性化的调查结构，显著提高对话调查的质量和用户体验。本文提出了一种新颖的基于知识驱动的对话调查中的追加问题生成任务。我们构建了一个新的数据集，其中包含人类编写的带有对话历史和标记知识的追加问题。除了数据集，我们还设计并验证了一组无参考Gricean启发式评估指标，系统评估生成的追加问题的质量。然后，我们提出了一个两阶段的基于知识的模型，通过使用知识来引导生成过程，生成信息丰富、连贯和清晰的追加问题。实验结果表明，与基于GPT的基准模型相比，我们的两阶段模型生成的追加问题更具信息量，连贯性和清晰度。",
    "tldr": "本文提出了一种基于知识驱动的方法，用于在对话调查中实时生成追加问题。该方法通过使用知识来引导生成过程，生成更具信息量、连贯性和清晰度的追加问题。",
    "en_tdlr": "This paper proposes a knowledge-driven approach for generating follow-up questions in conversational surveys. The approach uses knowledge to guide the generation process, resulting in more informative, coherent, and clear follow-up questions."
}