{
    "title": "Continual evaluation for lifelong learning: Identifying the stability gap. (arXiv:2205.13452v2 [cs.LG] UPDATED)",
    "abstract": "Time-dependent data-generating distributions have proven to be difficult for gradient-based training of neural networks, as the greedy updates result in catastrophic forgetting of previously learned knowledge. Despite the progress in the field of continual learning to overcome this forgetting, we show that a set of common state-of-the-art methods still suffers from substantial forgetting upon starting to learn new tasks, except that this forgetting is temporary and followed by a phase of performance recovery. We refer to this intriguing but potentially problematic phenomenon as the stability gap. The stability gap had likely remained under the radar due to standard practice in the field of evaluating continual learning models only after each task. Instead, we establish a framework for continual evaluation that uses per-iteration evaluation and we define a new set of metrics to quantify worst-case performance. Empirically we show that experience replay, constraint-based replay, knowledg",
    "link": "http://arxiv.org/abs/2205.13452",
    "context": "Title: Continual evaluation for lifelong learning: Identifying the stability gap. (arXiv:2205.13452v2 [cs.LG] UPDATED)\nAbstract: Time-dependent data-generating distributions have proven to be difficult for gradient-based training of neural networks, as the greedy updates result in catastrophic forgetting of previously learned knowledge. Despite the progress in the field of continual learning to overcome this forgetting, we show that a set of common state-of-the-art methods still suffers from substantial forgetting upon starting to learn new tasks, except that this forgetting is temporary and followed by a phase of performance recovery. We refer to this intriguing but potentially problematic phenomenon as the stability gap. The stability gap had likely remained under the radar due to standard practice in the field of evaluating continual learning models only after each task. Instead, we establish a framework for continual evaluation that uses per-iteration evaluation and we define a new set of metrics to quantify worst-case performance. Empirically we show that experience replay, constraint-based replay, knowledg",
    "path": "papers/22/05/2205.13452.json",
    "total_tokens": 961,
    "translated_title": "终身学习的持续评估：识别稳定性差距。",
    "translated_abstract": "时间相关的数据生成分布已被证明对神经网络的梯度训练是困难的，因为贪婪的更新会导致以前学习的知识灾难性地被遗忘。尽管终身学习领域已经取得了一定进展以克服这种遗忘，但我们发现一组常见的最先进的方法在开始学习新任务时仍然存在严重遗忘，只是这种遗忘是暂时的，会被一段性能恢复的阶段所跟随。我们将这种有趣但潜在有问题的现象称为稳定性差距。由于终身学习模型评估领域仅在每个任务之后进行评估的标准做法，因此稳定性差距可能仍然未被发现。而我们则建立了一个终身评估框架，使用每次迭代的评估，并定义了一组新的指标来量化最坏情况下的性能。实证结果显示，经验回放、基于约束的回放、知识_distillation和_expansion都存在稳定性差距。",
    "tldr": "终身学习中，时间相关的数据生成分布对神经网络的梯度训练具有困难性。一些最先进的方法在开始学习新任务时会存在轻微的遗忘，随后会有一段性能恢复的阶段跟随，我们称之为“稳定性差距”。",
    "en_tdlr": "Time-dependent data-generating distributions pose challenges for gradient-based training of neural networks in lifelong learning. A set of common state-of-the-art methods still suffer from slight forgetting upon starting to learn new tasks, followed by a phase of performance recovery, which we refer to as the \"stability gap\"."
}