{
    "title": "Fast Vision Transformers with HiLo Attention. (arXiv:2205.13213v5 [cs.CV] UPDATED)",
    "abstract": "Vision Transformers (ViTs) have triggered the most recent and significant breakthroughs in computer vision. Their efficient designs are mostly guided by the indirect metric of computational complexity, i.e., FLOPs, which however has a clear gap with the direct metric such as throughput. Thus, we propose to use the direct speed evaluation on the target platform as the design principle for efficient ViTs. Particularly, we introduce LITv2, a simple and effective ViT which performs favourably against the existing state-of-the-art methods across a spectrum of different model sizes with faster speed. At the core of LITv2 is a novel self-attention mechanism, which we dub HiLo. HiLo is inspired by the insight that high frequencies in an image capture local fine details and low frequencies focus on global structures, whereas a multi-head self-attention layer neglects the characteristic of different frequencies. Therefore, we propose to disentangle the high/low frequency patterns in an attention",
    "link": "http://arxiv.org/abs/2205.13213",
    "context": "Title: Fast Vision Transformers with HiLo Attention. (arXiv:2205.13213v5 [cs.CV] UPDATED)\nAbstract: Vision Transformers (ViTs) have triggered the most recent and significant breakthroughs in computer vision. Their efficient designs are mostly guided by the indirect metric of computational complexity, i.e., FLOPs, which however has a clear gap with the direct metric such as throughput. Thus, we propose to use the direct speed evaluation on the target platform as the design principle for efficient ViTs. Particularly, we introduce LITv2, a simple and effective ViT which performs favourably against the existing state-of-the-art methods across a spectrum of different model sizes with faster speed. At the core of LITv2 is a novel self-attention mechanism, which we dub HiLo. HiLo is inspired by the insight that high frequencies in an image capture local fine details and low frequencies focus on global structures, whereas a multi-head self-attention layer neglects the characteristic of different frequencies. Therefore, we propose to disentangle the high/low frequency patterns in an attention",
    "path": "papers/22/05/2205.13213.json",
    "total_tokens": 981,
    "translated_title": "高低注意力的快速视觉Transformer",
    "translated_abstract": "视觉Transformer (ViT) 已经在计算机视觉领域引起了重大突破。它们的高效设计大多由计算复杂性之间的间接指标（即 FLOP）指导，而与直接指标（如吞吐量）存在明显差距。因此，我们提出使用目标平台上的直接速度评估作为高效ViTs的设计原则。特别是，我们引入了LITv2，这是一个简单而有效的ViT，它在不同模型大小的范围内与现有的最先进方法相比表现优异，速度更快。LITv2的核心是一种新颖的自注意机制，我们称之为“高低注意力”。高低注意力的灵感来自于图像中的高频捕捉局部细节，低频专注于全局结构，而多头自注意层忽略了不同频率的特征。因此，我们提出使用分而治之的策略在注意力转换器中分解高/低频模式，其中自注意层分为两个分支，每个分支专门捕捉局部或全局信息。",
    "tldr": "摘要：本文提出了一种名为HiLo注意力的自注意机制，使用分而治之的策略在注意力转换器中分解高/低频模式，可以更加高效地运行视觉Transformer，并在不同模型大小的范围内胜过现有的最先进方法。",
    "en_tdlr": "TLDR: This paper proposes a novel self-attention mechanism called HiLo attention, which disentangles high/low frequency patterns in an attention transformer with a divide-and-conquer strategy, to run vision Transformers more efficiently, and outperform existing state-of-the-art methods across a spectrum of different model sizes."
}