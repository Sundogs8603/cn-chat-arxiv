{
    "title": "Backpropagation through Combinatorial Algorithms: Identity with Projection Works. (arXiv:2205.15213v3 [cs.LG] UPDATED)",
    "abstract": "Embedding discrete solvers as differentiable layers has given modern deep learning architectures combinatorial expressivity and discrete reasoning capabilities. The derivative of these solvers is zero or undefined, therefore a meaningful replacement is crucial for effective gradient-based learning. Prior works rely on smoothing the solver with input perturbations, relaxing the solver to continuous problems, or interpolating the loss landscape with techniques that typically require additional solver calls, introduce extra hyper-parameters, or compromise performance. We propose a principled approach to exploit the geometry of the discrete solution space to treat the solver as a negative identity on the backward pass and further provide a theoretical justification. Our experiments demonstrate that such a straightforward hyper-parameter-free approach is able to compete with previous more complex methods on numerous experiments such as backpropagation through discrete samplers, deep graph m",
    "link": "http://arxiv.org/abs/2205.15213",
    "context": "Title: Backpropagation through Combinatorial Algorithms: Identity with Projection Works. (arXiv:2205.15213v3 [cs.LG] UPDATED)\nAbstract: Embedding discrete solvers as differentiable layers has given modern deep learning architectures combinatorial expressivity and discrete reasoning capabilities. The derivative of these solvers is zero or undefined, therefore a meaningful replacement is crucial for effective gradient-based learning. Prior works rely on smoothing the solver with input perturbations, relaxing the solver to continuous problems, or interpolating the loss landscape with techniques that typically require additional solver calls, introduce extra hyper-parameters, or compromise performance. We propose a principled approach to exploit the geometry of the discrete solution space to treat the solver as a negative identity on the backward pass and further provide a theoretical justification. Our experiments demonstrate that such a straightforward hyper-parameter-free approach is able to compete with previous more complex methods on numerous experiments such as backpropagation through discrete samplers, deep graph m",
    "path": "papers/22/05/2205.15213.json",
    "total_tokens": 958,
    "translated_title": "组合算法的反向传播：使用投影进行的恒等变换。",
    "translated_abstract": "将离散求解器嵌入可微分层中，赋予了现代深度学习架构组合表达能力和离散推理能力。这些求解器的导数为零或未定义，因此寻找有意义的替代方案对于有效的基于梯度的学习至关重要。之前的作品依赖于使用输入扰动平滑求解器、将求解器松弛为连续问题或者通过技术对损失面貌进行插值，这些方法通常需要额外的求解器调用、引入额外的超参数或者牺牲性能。我们提出了一种基于离散解空间几何的原则方法，以在反向传播时将求解器视为负恒等变换，并提供了理论证明。我们的实验证明，这种简单、无超参数的方法能够在许多实验中与之前更复杂的方法竞争，例如在离散采样器、深度图中进行的反向传播。",
    "tldr": "本文提出了一种基于离散解空间几何的原则方法，将求解器视为负恒等变换，以在反向传播时寻找有意义的替代方案，避免使用通过投影平滑求解器、将求解器松弛为连续问题或者通过技术对损失面貌进行插值等更复杂的方法，从而在离散求解器和深度图等情景中发挥作用。",
    "en_tdlr": "This paper proposes a novel approach to exploit the geometry of the discrete solution space and treat the solver as a negative identity on the backward pass, which can effectively address the challenge of finding meaningful replacements for derivative of discrete solvers, and the experiments demonstrate its competitive performance with previous complex methods in scenarios including backpropagation through discrete samplers and deep graph m."
}