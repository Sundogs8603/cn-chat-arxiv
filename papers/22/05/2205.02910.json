{
    "title": "GANs as Gradient Flows that Converge. (arXiv:2205.02910v2 [cs.LG] UPDATED)",
    "abstract": "This paper approaches the unsupervised learning problem by gradient descent in the space of probability density functions. A main result shows that along the gradient flow induced by a distribution-dependent ordinary differential equation (ODE), the unknown data distribution emerges as the long-time limit. That is, one can uncover the data distribution by simulating the distribution-dependent ODE. Intriguingly, the simulation of the ODE is shown equivalent to the training of generative adversarial networks (GANs). This equivalence provides a new \"cooperative\" view of GANs and, more importantly, sheds new light on the divergence of GANs. In particular, it reveals that the GAN algorithm implicitly minimizes the mean squared error (MSE) between two sets of samples, and this MSE fitting alone can cause GANs to diverge. To construct a solution to the distribution-dependent ODE, we first show that the associated nonlinear Fokker-Planck equation has a unique weak solution, by the Crandall-Lig",
    "link": "http://arxiv.org/abs/2205.02910",
    "context": "Title: GANs as Gradient Flows that Converge. (arXiv:2205.02910v2 [cs.LG] UPDATED)\nAbstract: This paper approaches the unsupervised learning problem by gradient descent in the space of probability density functions. A main result shows that along the gradient flow induced by a distribution-dependent ordinary differential equation (ODE), the unknown data distribution emerges as the long-time limit. That is, one can uncover the data distribution by simulating the distribution-dependent ODE. Intriguingly, the simulation of the ODE is shown equivalent to the training of generative adversarial networks (GANs). This equivalence provides a new \"cooperative\" view of GANs and, more importantly, sheds new light on the divergence of GANs. In particular, it reveals that the GAN algorithm implicitly minimizes the mean squared error (MSE) between two sets of samples, and this MSE fitting alone can cause GANs to diverge. To construct a solution to the distribution-dependent ODE, we first show that the associated nonlinear Fokker-Planck equation has a unique weak solution, by the Crandall-Lig",
    "path": "papers/22/05/2205.02910.json",
    "total_tokens": 1186,
    "translated_title": "GAN作为渐进流的梯度下降",
    "translated_abstract": "本文通过在概率密度函数空间中的梯度下降方法来解决无监督学习问题。其中，一个主要结果表明，通过分布依赖的普通微分方程引导的梯度流，未知的数据分布将在长时间极限下出现。也就是说，通过模拟分布依赖ODE，可以揭示数据分布。有趣的是，ODE的模拟被证明等价于生成对抗网络（GAN）的训练。这种等价关系提供了GAN的新“合作”视角，并且更重要的是，为GAN的发散带来了新的启示。特别地，它揭示了GAN算法隐式地最小化了两组样本之间的均方误差（MSE），仅仅这个MSE拟合就足以导致GAN发散。为了构建分布依赖ODE的解，我们首先证明相关的非线性Fokker-Planck方程的弱解是唯一的，这是通过Crandall-Liggett定理得到的。然后，我们展示了使用一个已知的反向采样技术的简单修改，可以构建一个数值方案来近似ODE的解。最后，我们使用这个数值方案来展示，当判别器足够强大时，GAN算法确实收敛于数据分布，从而为GAN收敛的长期难题提供了新的视角。",
    "tldr": "本文通过在概率密度函数空间中的梯度下降方式来解决无监督学习问题，证明了GAN的训练过程可以被视为一种分布依赖的ODE的模拟。GAN算法最小化了两组样本之间的均方误差，并且只有在判别器足够强大时才能真正收敛。",
    "en_tdlr": "This paper presents a new perspective on Generative Adversarial Networks (GANs), showing that the training process can be viewed as simulating a distribution-dependent ordinary differential equation (ODE). The algorithm implicitly minimizes the mean squared error (MSE) between two sets of samples, which can cause GANs to diverge unless the discriminator is sufficiently powerful. The paper provides insight into the longstanding issue of GAN convergence and shows that GANs can converge to the data distribution when the discriminator is sufficiently strong."
}