{
    "title": "Choice of training label matters: how to best use deep learning for quantitative MRI parameter estimation. (arXiv:2205.05587v3 [physics.med-ph] UPDATED)",
    "abstract": "Deep learning (DL) is gaining popularity as a parameter estimation method for quantitative MRI. A range of competing implementations have been proposed, relying on either supervised or self-supervised learning. Self-supervised approaches, sometimes referred to as unsupervised, have been loosely based on auto-encoders, whereas supervised methods have, to date, been trained on groundtruth labels. These two learning paradigms have been shown to have distinct strengths. Notably, self-supervised approaches have offered lower-bias parameter estimates than their supervised alternatives. This result is counterintuitive - incorporating prior knowledge with supervised labels should, in theory, lead to improved accuracy. In this work, we show that this apparent limitation of supervised approaches stems from the naive choice of groundtruth training labels. By training on labels which are deliberately not groundtruth, we show that the low-bias parameter estimation previously associated with self-su",
    "link": "http://arxiv.org/abs/2205.05587",
    "context": "Title: Choice of training label matters: how to best use deep learning for quantitative MRI parameter estimation. (arXiv:2205.05587v3 [physics.med-ph] UPDATED)\nAbstract: Deep learning (DL) is gaining popularity as a parameter estimation method for quantitative MRI. A range of competing implementations have been proposed, relying on either supervised or self-supervised learning. Self-supervised approaches, sometimes referred to as unsupervised, have been loosely based on auto-encoders, whereas supervised methods have, to date, been trained on groundtruth labels. These two learning paradigms have been shown to have distinct strengths. Notably, self-supervised approaches have offered lower-bias parameter estimates than their supervised alternatives. This result is counterintuitive - incorporating prior knowledge with supervised labels should, in theory, lead to improved accuracy. In this work, we show that this apparent limitation of supervised approaches stems from the naive choice of groundtruth training labels. By training on labels which are deliberately not groundtruth, we show that the low-bias parameter estimation previously associated with self-su",
    "path": "papers/22/05/2205.05587.json",
    "total_tokens": 916,
    "translated_title": "训练标签的选择很重要：如何最好地使用深度学习进行定量MRI参数估计",
    "translated_abstract": "深度学习作为一种定量MRI参数估计方法正在变得越来越流行。已经提出了一系列竞争性的实现方法，其中包括监督学习和自监督学习。自监督方法有时被称为无监督方法，它们通常基于自动编码器。而迄今为止的监督方法则是基于已知标签进行训练。这两种学习范式已被证明具有不同的优势。值得注意的是，自监督方法提供了比监督方法更低偏差的参数估计。这个结果与直觉相反 - 在理论上，将先前的知识与监督标签结合应该可以提高准确性。在这项工作中，我们展示了监督方法的这种明显限制源于对训练标签的天真选择。通过训练不是真实标签的标签，我们展示了之前与自监督相关联的低偏差参数估计。",
    "tldr": "本研究表明监督学习方法在选择标签上的天真选择导致了低偏差参数估计的限制。通过使用有意不是真实标签的训练标签，我们发现自监督方法可以提供比监督方法更低的偏差参数估计。",
    "en_tdlr": "This study demonstrates that the naïve choice of labels in supervised learning leads to limitations in low-bias parameter estimation. By using deliberately non-groundtruth training labels, we found that self-supervised methods can offer lower-bias parameter estimation compared to supervised methods."
}