{
    "title": "Revisiting DocRED -- Addressing the False Negative Problem in Relation Extraction. (arXiv:2205.12696v3 [cs.CL] UPDATED)",
    "abstract": "The DocRED dataset is one of the most popular and widely used benchmarks for document-level relation extraction (RE). It adopts a recommend-revise annotation scheme so as to have a large-scale annotated dataset. However, we find that the annotation of DocRED is incomplete, i.e., false negative samples are prevalent. We analyze the causes and effects of the overwhelming false negative problem in the DocRED dataset. To address the shortcoming, we re-annotate 4,053 documents in the DocRED dataset by adding the missed relation triples back to the original DocRED. We name our revised DocRED dataset Re-DocRED. We conduct extensive experiments with state-of-the-art neural models on both datasets, and the experimental results show that the models trained and evaluated on our Re-DocRED achieve performance improvements of around 13 F1 points. Moreover, we conduct a comprehensive analysis to identify the potential areas for further improvement. Our dataset is publicly available at https://github.",
    "link": "http://arxiv.org/abs/2205.12696",
    "context": "Title: Revisiting DocRED -- Addressing the False Negative Problem in Relation Extraction. (arXiv:2205.12696v3 [cs.CL] UPDATED)\nAbstract: The DocRED dataset is one of the most popular and widely used benchmarks for document-level relation extraction (RE). It adopts a recommend-revise annotation scheme so as to have a large-scale annotated dataset. However, we find that the annotation of DocRED is incomplete, i.e., false negative samples are prevalent. We analyze the causes and effects of the overwhelming false negative problem in the DocRED dataset. To address the shortcoming, we re-annotate 4,053 documents in the DocRED dataset by adding the missed relation triples back to the original DocRED. We name our revised DocRED dataset Re-DocRED. We conduct extensive experiments with state-of-the-art neural models on both datasets, and the experimental results show that the models trained and evaluated on our Re-DocRED achieve performance improvements of around 13 F1 points. Moreover, we conduct a comprehensive analysis to identify the potential areas for further improvement. Our dataset is publicly available at https://github.",
    "path": "papers/22/05/2205.12696.json",
    "total_tokens": 913,
    "translated_title": "重新审视 DocRED - 解决关系抽取中的假阴性问题",
    "translated_abstract": "DocRED 数据集是最流行和广泛使用的文档级关系抽取基准数据集之一。它采用了一个推荐-修订的标注方案，以获得大规模的注释数据集。但是，我们发现 DocRED 的标注是不完整的，即假阴性样本很普遍。为了解决这个缺点，我们通过向原始 DocRED 中添加被忽略的关系三元组来重新注释了 4,053 个文档，我们将我们修正后的 DocRED 数据集命名为 Re-DocRED。我们使用最先进的神经模型在这两个数据集上开展了大量的实验，实验结果表明，使用我们的 Re-DocRED 训练和评估的模型性能提高了大约 13 个 F1 分数。此外，我们进行了全面的分析，识别出了进一步改进的潜在领域。我们的数据集公开在 https://github。",
    "tldr": "该论文主要针对文档层面上的关系抽取中存在假阴性的问题，在重新注释 DocRED 数据集中添加被忽略的关系三元组后，我们得到了一个性能提升约 13 F1 分数的新数据集 Re-DocRED，并发现了有效改进的潜在领域。",
    "en_tdlr": "This paper addresses the false negative problem in document-level relation extraction, and presents a revised dataset named Re-DocRED with added missed relation triples, which achieves about 13 F1 score improvement in performance with state-of-the-art neural models. The study also identifies potential areas for further improvement."
}