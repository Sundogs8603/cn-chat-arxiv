{
    "title": "blob loss: instance imbalance aware loss functions for semantic segmentation. (arXiv:2205.08209v3 [cs.CV] UPDATED)",
    "abstract": "Deep convolutional neural networks (CNN) have proven to be remarkably effective in semantic segmentation tasks. Most popular loss functions were introduced targeting improved volumetric scores, such as the Dice coefficient (DSC). By design, DSC can tackle class imbalance, however, it does not recognize instance imbalance within a class. As a result, a large foreground instance can dominate minor instances and still produce a satisfactory DSC. Nevertheless, detecting tiny instances is crucial for many applications, such as disease monitoring. For example, it is imperative to locate and surveil small-scale lesions in the follow-up of multiple sclerosis patients. We propose a novel family of loss functions, \\emph{blob loss}, primarily aimed at maximizing instance-level detection metrics, such as F1 score and sensitivity. \\emph{Blob loss} is designed for semantic segmentation problems where detecting multiple instances matters. We extensively evaluate a DSC-based \\emph{blob loss} in five c",
    "link": "http://arxiv.org/abs/2205.08209",
    "context": "Title: blob loss: instance imbalance aware loss functions for semantic segmentation. (arXiv:2205.08209v3 [cs.CV] UPDATED)\nAbstract: Deep convolutional neural networks (CNN) have proven to be remarkably effective in semantic segmentation tasks. Most popular loss functions were introduced targeting improved volumetric scores, such as the Dice coefficient (DSC). By design, DSC can tackle class imbalance, however, it does not recognize instance imbalance within a class. As a result, a large foreground instance can dominate minor instances and still produce a satisfactory DSC. Nevertheless, detecting tiny instances is crucial for many applications, such as disease monitoring. For example, it is imperative to locate and surveil small-scale lesions in the follow-up of multiple sclerosis patients. We propose a novel family of loss functions, \\emph{blob loss}, primarily aimed at maximizing instance-level detection metrics, such as F1 score and sensitivity. \\emph{Blob loss} is designed for semantic segmentation problems where detecting multiple instances matters. We extensively evaluate a DSC-based \\emph{blob loss} in five c",
    "path": "papers/22/05/2205.08209.json",
    "total_tokens": 762,
    "translated_title": "基于实例不平衡感知的语义分割损失函数：Blob Loss",
    "translated_abstract": "深度卷积神经网络在语义分割任务中表现出良好的效果。然而，已有的损失函数虽然针对改进体量得分进行了设计，如Dice系数（DSC），但其无法识别类别内的实例不平衡问题。这导致大的前景实例可以支配小的实例而仍然产生令人满意的DSC。我们提出了一种新的损失函数——Blob Loss，旨在最大化感知性能指标, 如F1分数和灵敏度，针对多实例检测的语义分割问题。",
    "tldr": "该论文提出了一种针对实例不平衡问题的语义分割损失函数——Blob Loss，用于多实例检测，可通过提高F1分数和灵敏度等指标来优化性能。",
    "en_tdlr": "This paper proposes a semantic segmentation loss function, Blob Loss, which addresses the issue of instance imbalance and is designed for multi-instance detection. It aims to optimize performance by maximizing metrics such as F1 score and sensitivity."
}