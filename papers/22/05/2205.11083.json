{
    "title": "Deep Digging into the Generalization of Self-Supervised Monocular Depth Estimation. (arXiv:2205.11083v3 [cs.CV] UPDATED)",
    "abstract": "Self-supervised monocular depth estimation has been widely studied recently. Most of the work has focused on improving performance on benchmark datasets, such as KITTI, but has offered a few experiments on generalization performance. In this paper, we investigate the backbone networks (e.g. CNNs, Transformers, and CNN-Transformer hybrid models) toward the generalization of monocular depth estimation. We first evaluate state-of-the-art models on diverse public datasets, which have never been seen during the network training. Next, we investigate the effects of texture-biased and shape-biased representations using the various texture-shifted datasets that we generated. We observe that Transformers exhibit a strong shape bias and CNNs do a strong texture-bias. We also find that shape-biased models show better generalization performance for monocular depth estimation compared to texture-biased models. Based on these observations, we newly design a CNN-Transformer hybrid network with a mult",
    "link": "http://arxiv.org/abs/2205.11083",
    "context": "Title: Deep Digging into the Generalization of Self-Supervised Monocular Depth Estimation. (arXiv:2205.11083v3 [cs.CV] UPDATED)\nAbstract: Self-supervised monocular depth estimation has been widely studied recently. Most of the work has focused on improving performance on benchmark datasets, such as KITTI, but has offered a few experiments on generalization performance. In this paper, we investigate the backbone networks (e.g. CNNs, Transformers, and CNN-Transformer hybrid models) toward the generalization of monocular depth estimation. We first evaluate state-of-the-art models on diverse public datasets, which have never been seen during the network training. Next, we investigate the effects of texture-biased and shape-biased representations using the various texture-shifted datasets that we generated. We observe that Transformers exhibit a strong shape bias and CNNs do a strong texture-bias. We also find that shape-biased models show better generalization performance for monocular depth estimation compared to texture-biased models. Based on these observations, we newly design a CNN-Transformer hybrid network with a mult",
    "path": "papers/22/05/2205.11083.json",
    "total_tokens": 1012,
    "translated_title": "深入探讨自监督单目深度估计的泛化能力",
    "translated_abstract": "自监督单目深度估计是近期广泛研究的领域。大部分工作都将重点放在提高KITTI等基准数据集性能上，但是对于泛化性能进行的实验却很少。本文探究了用于单目深度估计的骨干网络（如CNN、Transformers和CNN-Transformer混合模型）的泛化性能。我们首先在多元化的公共数据集上评估了最先进的模型，这些数据集在网络训练期间从未见过。接下来，我们使用不同的纹理位移数据集生成了纹理偏差和形状偏差表示，并研究了其效果。我们观察到Transformers具有很强的形状偏差，而CNN则有很强的纹理偏差。我们还发现，与纹理偏差的模型相比，形状偏差的模型在单目深度估计的泛化性能方面表现更好。基于这些观察结果，我们新设计了一个CNN-Transformer混合网络，其中包含多个形状偏差分支，用于单目深度估计。",
    "tldr": "本文探究了用于单目深度估计的骨干网络的泛化能力，并观察到Transformers具有很强的形状偏差。形状偏差的模型表现更好的单目深度估计泛化性能，作者新设计了一个CNN-Transformer混合网络，以提高单目深度估计的泛化性能。",
    "en_tdlr": "This paper investigates the generalization performance of backbone networks for monocular depth estimation and observes that Transformers exhibit a strong shape bias. Models with shape bias perform better in the generalization performance of monocular depth estimation. The authors newly designed a CNN-Transformer hybrid network to improve the generalization performance of monocular depth estimation."
}