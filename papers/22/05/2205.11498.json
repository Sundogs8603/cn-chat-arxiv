{
    "title": "Injecting Domain Adaptation with Learning-to-hash for Effective and Efficient Zero-shot Dense Retrieval. (arXiv:2205.11498v2 [cs.IR] UPDATED)",
    "abstract": "Dense retrieval overcome the lexical gap and has shown great success in ad-hoc information retrieval (IR). Despite their success, dense retrievers are expensive to serve across practical use cases. For use cases requiring to search from millions of documents, the dense index becomes bulky and requires high memory usage for storing the index. More recently, learning-to-hash (LTH) techniques, for e.g., BPR and JPQ, produce binary document vectors, thereby reducing the memory requirement to efficiently store the dense index. LTH techniques are supervised and finetune the retriever using a ranking loss. They outperform their counterparts, i.e., traditional out-of-the-box vector compression techniques such as PCA or PQ. A missing piece from prior work is that existing techniques have been evaluated only in-domain, i.e., on a single dataset such as MS MARCO. In our work, we evaluate LTH and vector compression techniques for improving the downstream zero-shot retrieval accuracy of the TAS-B d",
    "link": "http://arxiv.org/abs/2205.11498",
    "context": "Title: Injecting Domain Adaptation with Learning-to-hash for Effective and Efficient Zero-shot Dense Retrieval. (arXiv:2205.11498v2 [cs.IR] UPDATED)\nAbstract: Dense retrieval overcome the lexical gap and has shown great success in ad-hoc information retrieval (IR). Despite their success, dense retrievers are expensive to serve across practical use cases. For use cases requiring to search from millions of documents, the dense index becomes bulky and requires high memory usage for storing the index. More recently, learning-to-hash (LTH) techniques, for e.g., BPR and JPQ, produce binary document vectors, thereby reducing the memory requirement to efficiently store the dense index. LTH techniques are supervised and finetune the retriever using a ranking loss. They outperform their counterparts, i.e., traditional out-of-the-box vector compression techniques such as PCA or PQ. A missing piece from prior work is that existing techniques have been evaluated only in-domain, i.e., on a single dataset such as MS MARCO. In our work, we evaluate LTH and vector compression techniques for improving the downstream zero-shot retrieval accuracy of the TAS-B d",
    "path": "papers/22/05/2205.11498.json",
    "total_tokens": 929,
    "translated_title": "为有效和高效的零样本密集检索注入领域适应的学习哈希",
    "translated_abstract": "密集检索在无查询词检索中克服了词汇隔阂，并在自动信息检索中取得了巨大成功。尽管成功，但密集检索器在实际应用中的服务成本较高。对于需要从数百万份文档中搜索的用例，密集索引变得庞大，并且在存储索引时需要高内存使用量。最近的学习哈希（LTH）技术，如BPR和JPQ，生成二进制文档向量，从而降低了存储密集索引的内存需求。LTH技术是有监督的，并使用排名损失对检索器进行微调。它们优于传统的向量压缩技术，如PCA或PQ。之前的研究中缺少的一个环节是现有技术仅在领域内进行评估，即仅在单一数据集（如MS MARCO）上进行评估。在我们的工作中，我们评估了LTH和向量压缩技术，以提高TAS-B d的零样本检索准确性。",
    "tldr": "通过学习哈希技术提高零样本密集检索的准确性和效率，克服了存储密集索引的高内存使用问题，并在跨领域环境中进行了评估。"
}