{
    "title": "The Fairness of Credit Scoring Models",
    "abstract": "In credit markets, screening algorithms aim to discriminate between good-type and bad-type borrowers. However, when doing so, they can also discriminate between individuals sharing a protected attribute (e.g. gender, age, racial origin) and the rest of the population. This can be unintentional and originate from the training dataset or from the model itself. We show how to formally test the algorithmic fairness of scoring models and how to identify the variables responsible for any lack of fairness. We then use these variables to optimize the fairness-performance trade-off. Our framework provides guidance on how algorithmic fairness can be monitored by lenders, controlled by their regulators, improved for the benefit of protected groups, while still maintaining a high level of forecasting accuracy.",
    "link": "https://arxiv.org/abs/2205.10200",
    "context": "Title: The Fairness of Credit Scoring Models\nAbstract: In credit markets, screening algorithms aim to discriminate between good-type and bad-type borrowers. However, when doing so, they can also discriminate between individuals sharing a protected attribute (e.g. gender, age, racial origin) and the rest of the population. This can be unintentional and originate from the training dataset or from the model itself. We show how to formally test the algorithmic fairness of scoring models and how to identify the variables responsible for any lack of fairness. We then use these variables to optimize the fairness-performance trade-off. Our framework provides guidance on how algorithmic fairness can be monitored by lenders, controlled by their regulators, improved for the benefit of protected groups, while still maintaining a high level of forecasting accuracy.",
    "path": "papers/22/05/2205.10200.json",
    "total_tokens": 820,
    "translated_title": "信用评分模型的公平性",
    "translated_abstract": "在信用市场中，筛选算法的目标是区分好类型和坏类型的借款人。然而，在这样做的过程中，他们还可能在具有受保护属性的个体（例如性别、年龄、种族起源）和整个人群之间进行歧视。这可能是无意识的，来源于训练数据集或模型本身。我们展示了如何形式化测试评分模型的算法公平性，以及如何确定影响公平性不足的变量。然后，我们利用这些变量来优化公平性和性能之间的权衡。我们的框架提供了关于如何监测信贷商的算法公平性、如何由监管机构控制、如何改善受保护群体的利益，同时仍保持高水平的预测准确性的指导。",
    "tldr": "本论文研究了信用评分模型的公平性问题，提出了一种形式化测试算法公平性的方法，并探索了影响公平性的变量。研究结果可以指导信贷商监测算法公平性、监管机构控制公平性，同时提高受保护群体的利益，同时保持高水平的预测准确性。",
    "en_tdlr": "This paper investigates the fairness of credit scoring models, proposing a formal method for testing algorithm fairness and exploring the variables that affect fairness. The findings provide guidance for lenders in monitoring algorithmic fairness, regulatory control, improving the interests of protected groups, while maintaining a high level of predictive accuracy."
}