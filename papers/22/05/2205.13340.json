{
    "title": "Deep Active Learning with Noise Stability",
    "abstract": "Uncertainty estimation for unlabeled data is crucial to active learning. With a deep neural network employed as the backbone model, the data selection process is highly challenging due to the potential over-confidence of the model inference. Existing methods resort to special learning fashions (e.g. adversarial) or auxiliary models to address this challenge. This tends to result in complex and inefficient pipelines, which would render the methods impractical. In this work, we propose a novel algorithm that leverages noise stability to estimate data uncertainty. The key idea is to measure the output derivation from the original observation when the model parameters are randomly perturbed by noise. We provide theoretical analyses by leveraging the small Gaussian noise theory and demonstrate that our method favors a subset with large and diverse gradients. Our method is generally applicable in various tasks, including computer vision, natural language processing, and structural data analy",
    "link": "https://arxiv.org/abs/2205.13340",
    "context": "Title: Deep Active Learning with Noise Stability\nAbstract: Uncertainty estimation for unlabeled data is crucial to active learning. With a deep neural network employed as the backbone model, the data selection process is highly challenging due to the potential over-confidence of the model inference. Existing methods resort to special learning fashions (e.g. adversarial) or auxiliary models to address this challenge. This tends to result in complex and inefficient pipelines, which would render the methods impractical. In this work, we propose a novel algorithm that leverages noise stability to estimate data uncertainty. The key idea is to measure the output derivation from the original observation when the model parameters are randomly perturbed by noise. We provide theoretical analyses by leveraging the small Gaussian noise theory and demonstrate that our method favors a subset with large and diverse gradients. Our method is generally applicable in various tasks, including computer vision, natural language processing, and structural data analy",
    "path": "papers/22/05/2205.13340.json",
    "total_tokens": 877,
    "translated_title": "深度主动学习的噪声稳定性",
    "translated_abstract": "对于未标记的数据，不确定性估计对于主动学习至关重要。采用深度神经网络作为主干模型，由于模型推断的过度自信可能导致数据选择过程非常具有挑战性。现有方法借助特殊的学习方式（如对抗性学习）或辅助模型来应对这一挑战。然而，这往往导致复杂且低效的流程，使方法变得不切实际。在本文中，我们提出了一种利用噪声稳定性来估计数据不确定性的新算法。关键思想是通过在模型参数通过噪声进行随机扰动时，测量输出与原始观测值之间的差异。我们通过利用小高斯噪声理论进行理论分析，并证明我们的方法倾向于选择具有大而多样的梯度的子集。我们的方法通常适用于各种任务，包括计算机视觉、自然语言处理和结构数据分析。",
    "tldr": "本文提出了一种利用噪声稳定性来估计数据不确定性的深度主动学习算法，通过测量模型参数通过噪声进行随机扰动时，输出与原始观测值之间的差异。该算法适用于多个领域的任务。",
    "en_tdlr": "This paper proposes a deep active learning algorithm that leverages noise stability to estimate data uncertainty, by measuring the difference between the output and original observation when model parameters are randomly perturbed by noise. The algorithm is applicable to tasks in various domains."
}