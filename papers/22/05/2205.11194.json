{
    "title": "UnifieR: A Unified Retriever for Large-Scale Retrieval. (arXiv:2205.11194v2 [cs.IR] UPDATED)",
    "abstract": "Large-scale retrieval is to recall relevant documents from a huge collection given a query. It relies on representation learning to embed documents and queries into a common semantic encoding space. According to the encoding space, recent retrieval methods based on pre-trained language models (PLM) can be coarsely categorized into either dense-vector or lexicon-based paradigms. These two paradigms unveil the PLMs' representation capability in different granularities, i.e., global sequence-level compression and local word-level contexts, respectively. Inspired by their complementary global-local contextualization and distinct representing views, we propose a new learning framework, UnifieR which unifies dense-vector and lexicon-based retrieval in one model with a dual-representing capability. Experiments on passage retrieval benchmarks verify its effectiveness in both paradigms. A uni-retrieval scheme is further presented with even better retrieval quality. We lastly evaluate the model ",
    "link": "http://arxiv.org/abs/2205.11194",
    "context": "Title: UnifieR: A Unified Retriever for Large-Scale Retrieval. (arXiv:2205.11194v2 [cs.IR] UPDATED)\nAbstract: Large-scale retrieval is to recall relevant documents from a huge collection given a query. It relies on representation learning to embed documents and queries into a common semantic encoding space. According to the encoding space, recent retrieval methods based on pre-trained language models (PLM) can be coarsely categorized into either dense-vector or lexicon-based paradigms. These two paradigms unveil the PLMs' representation capability in different granularities, i.e., global sequence-level compression and local word-level contexts, respectively. Inspired by their complementary global-local contextualization and distinct representing views, we propose a new learning framework, UnifieR which unifies dense-vector and lexicon-based retrieval in one model with a dual-representing capability. Experiments on passage retrieval benchmarks verify its effectiveness in both paradigms. A uni-retrieval scheme is further presented with even better retrieval quality. We lastly evaluate the model ",
    "path": "papers/22/05/2205.11194.json",
    "total_tokens": 895,
    "translated_title": "统一检索器：大规模检索的统一检索器",
    "translated_abstract": "大规模检索是指在给定查询的情况下从大量文档中召回相关文档。它依赖于表征学习，将文档和查询嵌入到一个共同的语义编码空间中。根据编码空间，基于预训练语言模型（PLM）的最近检索方法可以粗略地分为密集向量或基于词汇表的范例。这两种范例在不同粒度的全局序列级压缩和局部单词级上下文中展现了PLMs的表征能力。受到它们互补的全局局部上下文化和不同的代表视角的启发，我们提出了一个新的学习框架，统一检索器，它将密集向量和基于词汇表的检索统一到一个模型中，具有双重表示能力。对段落检索基准的实验验证了它在两个范例中的有效性。进一步提出了更好的检索质量的uni-retrieval方案。最后，我们评估了该模型。",
    "tldr": "UnifieR是一个将PLM的密集向量和基于词汇表的检索统一到一个模型中的学习框架，在段落检索基准测试中证明了其有效性。",
    "en_tdlr": "UnifieR is a learning framework that unifies dense-vector and lexicon-based retrieval using pre-trained language models (PLM) into one model with dual-representing capability. It has been proven effective in both paradigms in passage retrieval benchmarks."
}