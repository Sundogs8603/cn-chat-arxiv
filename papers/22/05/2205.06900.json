{
    "title": "MM-BD: Post-Training Detection of Backdoor Attacks with Arbitrary Backdoor Pattern Types Using a Maximum Margin Statistic. (arXiv:2205.06900v2 [cs.LG] UPDATED)",
    "abstract": "Backdoor attacks are an important type of adversarial threat against deep neural network classifiers, wherein test samples from one or more source classes will be (mis)classified to the attacker's target class when a backdoor pattern is embedded. In this paper, we focus on the post-training backdoor defense scenario commonly considered in the literature, where the defender aims to detect whether a trained classifier was backdoor-attacked without any access to the training set. Many post-training detectors are designed to detect attacks that use either one or a few specific backdoor embedding functions (e.g., patch-replacement or additive attacks). These detectors may fail when the backdoor embedding function used by the attacker (unknown to the defender) is different from the backdoor embedding function assumed by the defender. In contrast, we propose a post-training defense that detects backdoor attacks with arbitrary types of backdoor embeddings, without making any assumptions about ",
    "link": "http://arxiv.org/abs/2205.06900",
    "context": "Title: MM-BD: Post-Training Detection of Backdoor Attacks with Arbitrary Backdoor Pattern Types Using a Maximum Margin Statistic. (arXiv:2205.06900v2 [cs.LG] UPDATED)\nAbstract: Backdoor attacks are an important type of adversarial threat against deep neural network classifiers, wherein test samples from one or more source classes will be (mis)classified to the attacker's target class when a backdoor pattern is embedded. In this paper, we focus on the post-training backdoor defense scenario commonly considered in the literature, where the defender aims to detect whether a trained classifier was backdoor-attacked without any access to the training set. Many post-training detectors are designed to detect attacks that use either one or a few specific backdoor embedding functions (e.g., patch-replacement or additive attacks). These detectors may fail when the backdoor embedding function used by the attacker (unknown to the defender) is different from the backdoor embedding function assumed by the defender. In contrast, we propose a post-training defense that detects backdoor attacks with arbitrary types of backdoor embeddings, without making any assumptions about ",
    "path": "papers/22/05/2205.06900.json",
    "total_tokens": 915,
    "translated_title": "MM-BD: 使用最大边缘统计检测任意类型背景模式的后训练后门攻击 (arXiv:2205.06900v2 [cs.LG] 更新)",
    "translated_abstract": "后门攻击是针对深度神经网络分类器的一种重要对抗威胁，当嵌入后门模式时，来自一个或多个源类的测试样本将被(误)分类为攻击者的目标类。本文聚焦于文献中常见的后训练后门防御场景，防御者的目标是在无法访问训练集的情况下检测出是否受到了后门攻击。许多后训练检测器设计用于检测使用特定的一种或少数几种后门嵌入函数的攻击 (例如，补丁替换或加法攻击)。当攻击者使用的后门嵌入函数（防御者未知）与防御者假设的后门嵌入函数不同时，这些检测器可能会失败。相比之下，我们提出了一种后训练防御方法，可以检测任意类型的后门嵌入攻击，并且不对嵌入函数做任何假设。",
    "tldr": "本研究提出了一种后训练的后门防御方法，可以检测任意类型的后门嵌入攻击，而不需要对嵌入函数做任何假设。",
    "en_tdlr": "This paper proposes a post-training defense method that can detect backdoor attacks with arbitrary types of backdoor embeddings, without making any assumptions about the embedding function."
}