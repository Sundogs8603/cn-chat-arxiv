{
    "title": "A Sea of Words: An In-Depth Analysis of Anchors for Text Data. (arXiv:2205.13789v2 [stat.ML] CROSS LISTED)",
    "abstract": "Anchors (Ribeiro et al., 2018) is a post-hoc, rule-based interpretability method. For text data, it proposes to explain a decision by highlighting a small set of words (an anchor) such that the model to explain has similar outputs when they are present in a document. In this paper, we present the first theoretical analysis of Anchors, considering that the search for the best anchor is exhaustive. After formalizing the algorithm for text classification, we present explicit results on different classes of models when the vectorization step is TF-IDF, and words are replaced by a fixed out-of-dictionary token when removed. Our inquiry covers models such as elementary if-then rules and linear classifiers. We then leverage this analysis to gain insights on the behavior of Anchors for any differentiable classifiers. For neural networks, we empirically show that the words corresponding to the highest partial derivatives of the model with respect to the input, reweighted by the inverse document",
    "link": "http://arxiv.org/abs/2205.13789",
    "context": "Title: A Sea of Words: An In-Depth Analysis of Anchors for Text Data. (arXiv:2205.13789v2 [stat.ML] CROSS LISTED)\nAbstract: Anchors (Ribeiro et al., 2018) is a post-hoc, rule-based interpretability method. For text data, it proposes to explain a decision by highlighting a small set of words (an anchor) such that the model to explain has similar outputs when they are present in a document. In this paper, we present the first theoretical analysis of Anchors, considering that the search for the best anchor is exhaustive. After formalizing the algorithm for text classification, we present explicit results on different classes of models when the vectorization step is TF-IDF, and words are replaced by a fixed out-of-dictionary token when removed. Our inquiry covers models such as elementary if-then rules and linear classifiers. We then leverage this analysis to gain insights on the behavior of Anchors for any differentiable classifiers. For neural networks, we empirically show that the words corresponding to the highest partial derivatives of the model with respect to the input, reweighted by the inverse document",
    "path": "papers/22/05/2205.13789.json",
    "total_tokens": 1007,
    "translated_title": "一片文字海：针对文本数据的 Anchors 深入分析",
    "translated_abstract": "Anchors 是一种基于后处理的基于规则的可解释性方法，该方法旨在解释模型决策并强调一小组词语（锚点），这些词语存在于文档中时，模型输出类似。本文首次对 Anchors 进行了理论分析，考虑到寻找最佳锚点是详尽的。我们将文本分类的算法形式化后，结合不同类别模型的显式结果，探究了 Anchors 的行为特征。我们分别覆盖了基本 if-then 规则和线性分类器这两种模型。我们还利用这项分析，洞见任何可微分分类器的 Anchors 行为特征。对于神经网络，我们经验性地展示了模型对输入的最高偏导数所对应的词语，通过反向文件重新加权，可以作为 Anchors 词语。",
    "tldr": "Anchors 是一种后处理的规则性可解释性方法，它可以通过凸显出一个小组词语（锚点）来强调模型的决策，我们首次对 Anchors 进行了理论分析，考虑到寻找最佳锚点是详尽的，并通过 TF-IDF 向量化步骤以及模型层次的显式结果，探究其在不同类别模型中的行为特征。我们还发现，在神经网络中，最高偏导数所对应的词汇可以重新加权用作 Anchors 词汇。",
    "en_tdlr": "Anchors is a post-hoc, rule-based interpretability method that highlights a small set of words (an anchor) in a document to explain a decision made by the model. This study provides the first theoretical analysis of Anchors considering the exhaustive search for the best anchor and investigates its behavior on different classes of models, including neural networks. The results suggest that the words corresponding to the highest partial derivatives of the model can be reweighted and used as Anchors for neural networks."
}