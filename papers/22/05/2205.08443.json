{
    "title": "On the (In)security of Peer-to-Peer Decentralized Machine Learning. (arXiv:2205.08443v2 [cs.CR] UPDATED)",
    "abstract": "In this work, we carry out the first, in-depth, privacy analysis of Decentralized Learning -- a collaborative machine learning framework aimed at addressing the main limitations of federated learning. We introduce a suite of novel attacks for both passive and active decentralized adversaries. We demonstrate that, contrary to what is claimed by decentralized learning proposers, decentralized learning does not offer any security advantage over federated learning. Rather, it increases the attack surface enabling any user in the system to perform privacy attacks such as gradient inversion, and even gain full control over honest users' local model. We also show that, given the state of the art in protections, privacy-preserving configurations of decentralized learning require fully connected networks, losing any practical advantage over the federated setup and therefore completely defeating the objective of the decentralized approach.",
    "link": "http://arxiv.org/abs/2205.08443",
    "context": "Title: On the (In)security of Peer-to-Peer Decentralized Machine Learning. (arXiv:2205.08443v2 [cs.CR] UPDATED)\nAbstract: In this work, we carry out the first, in-depth, privacy analysis of Decentralized Learning -- a collaborative machine learning framework aimed at addressing the main limitations of federated learning. We introduce a suite of novel attacks for both passive and active decentralized adversaries. We demonstrate that, contrary to what is claimed by decentralized learning proposers, decentralized learning does not offer any security advantage over federated learning. Rather, it increases the attack surface enabling any user in the system to perform privacy attacks such as gradient inversion, and even gain full control over honest users' local model. We also show that, given the state of the art in protections, privacy-preserving configurations of decentralized learning require fully connected networks, losing any practical advantage over the federated setup and therefore completely defeating the objective of the decentralized approach.",
    "path": "papers/22/05/2205.08443.json",
    "total_tokens": 932,
    "translated_title": "关于点对点去中心化机器学习的（不）安全性研究",
    "translated_abstract": "本文对去中心化学习框架进行了首次深入隐私分析，该框架是一种协作机器学习框架，旨在解决联邦学习的主要限制。我们引入了一系列新颖的攻击方法，包括被动和主动的去中心化敌手，我们证明了与去中心化学习提出者所声称的相反，去中心化学习并没有提供任何关于联邦学习的安全优势。相反，它增加了攻击面，使得系统中的任何用户都能够进行隐私攻击，例如梯度逆推，甚至获得对诚实用户的本地模型的完全控制。我们还表明，鉴于当前防护技术，去中心化学习的隐私保护配置需要全连接网络，失去了与联邦设置的任何实际优势，因此完全打败了去中心化方法的目标。",
    "tldr": "本文对去中心化学习进行了首次深入隐私分析，引入了一系列新颖的攻击方法，并证明去中心化学习并未提供比联邦学习更好的安全优势，反而增加了攻击面。而且，隐私保护配置需要全连接网络，失去了实际优势，完全打败了去中心化方法的目标。",
    "en_tdlr": "This work provides the first in-depth privacy analysis of Decentralized Learning, introduces novel attacks for both passive and active decentralized adversaries, and proves that decentralized learning does not offer better security advantages than federated learning but increases the attack surface. It also shows that privacy-preserving configurations of decentralized learning require fully connected networks, defeating the objective of the decentralized approach."
}