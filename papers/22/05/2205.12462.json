{
    "title": "Improving CTC-based ASR Models with Gated Interlayer Collaboration. (arXiv:2205.12462v2 [cs.CL] UPDATED)",
    "abstract": "The CTC-based automatic speech recognition (ASR) models without the external language model usually lack the capacity to model conditional dependencies and textual interactions. In this paper, we present a Gated Interlayer Collaboration (GIC) mechanism to improve the performance of CTC-based models, which introduces textual information into the model and thus relaxes the conditional independence assumption of CTC-based models. Specifically, we consider the weighted sum of token embeddings as the textual representation for each position, where the position-specific weights are the softmax probability distribution constructed via inter-layer auxiliary CTC losses. The textual representations are then fused with acoustic features by developing a gate unit. Experiments on AISHELL-1, TEDLIUM2, and AIDATATANG corpora show that the proposed method outperforms several strong baselines.",
    "link": "http://arxiv.org/abs/2205.12462",
    "context": "Title: Improving CTC-based ASR Models with Gated Interlayer Collaboration. (arXiv:2205.12462v2 [cs.CL] UPDATED)\nAbstract: The CTC-based automatic speech recognition (ASR) models without the external language model usually lack the capacity to model conditional dependencies and textual interactions. In this paper, we present a Gated Interlayer Collaboration (GIC) mechanism to improve the performance of CTC-based models, which introduces textual information into the model and thus relaxes the conditional independence assumption of CTC-based models. Specifically, we consider the weighted sum of token embeddings as the textual representation for each position, where the position-specific weights are the softmax probability distribution constructed via inter-layer auxiliary CTC losses. The textual representations are then fused with acoustic features by developing a gate unit. Experiments on AISHELL-1, TEDLIUM2, and AIDATATANG corpora show that the proposed method outperforms several strong baselines.",
    "path": "papers/22/05/2205.12462.json",
    "total_tokens": 834,
    "translated_title": "基于门控层间协作改进CTC ASR 模型",
    "translated_abstract": "CTC-based ASR 模型在没有外部语言模型的情况下往往缺乏对条件依赖和文本交互的建模能力。本文提出了一种基于门控层间协作（GIC）机制来改进CTC-based模型性能的方法，将文本信息引入模型，从而放松CTC-based模型的条件独立假设。具体而言，我们将标记嵌入的加权和视为每个位置的文本表示，其中位置特定的权重是通过层间辅助CTC losses构建的softmax概率分布。然后，通过开发门控单元将文本表示与声学特征融合。在AISHELL-1，TEDLIUM2 和 AIDATATANG corpus 上的实验表明，所提出的方法优于几个强基准。",
    "tldr": "本文提出了一种基于门控层间协作（GIC）机制来改进CTC-based模型性能的方法，在CTC-based模型中引入文本信息来提升模型性能，三个实验都表明该方法优于其他强基准。",
    "en_tdlr": "This paper proposes a Gated Interlayer Collaboration (GIC) mechanism to improve the performance of CTC-based automatic speech recognition (ASR) models by introducing textual information into the model and thus relaxing the conditional independence assumption of CTC-based models. Experiments on three different corpora show that the proposed method outperforms several strong baselines."
}