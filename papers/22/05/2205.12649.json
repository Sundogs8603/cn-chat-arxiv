{
    "title": "Investigating Lexical Replacements for Arabic-English Code-Switched Data Augmentation. (arXiv:2205.12649v2 [cs.CL] UPDATED)",
    "abstract": "Data sparsity is a main problem hindering the development of code-switching (CS) NLP systems. In this paper, we investigate data augmentation techniques for synthesizing dialectal Arabic-English CS text. We perform lexical replacements using word-aligned parallel corpora where CS points are either randomly chosen or learnt using a sequence-to-sequence model. We compare these approaches against dictionary-based replacements. We assess the quality of the generated sentences through human evaluation and evaluate the effectiveness of data augmentation on machine translation (MT), automatic speech recognition (ASR), and speech translation (ST) tasks. Results show that using a predictive model results in more natural CS sentences compared to the random approach, as reported in human judgements. In the downstream tasks, despite the random approach generating more data, both approaches perform equally (outperforming dictionary-based replacements). Overall, data augmentation achieves 34% improv",
    "link": "http://arxiv.org/abs/2205.12649",
    "context": "Title: Investigating Lexical Replacements for Arabic-English Code-Switched Data Augmentation. (arXiv:2205.12649v2 [cs.CL] UPDATED)\nAbstract: Data sparsity is a main problem hindering the development of code-switching (CS) NLP systems. In this paper, we investigate data augmentation techniques for synthesizing dialectal Arabic-English CS text. We perform lexical replacements using word-aligned parallel corpora where CS points are either randomly chosen or learnt using a sequence-to-sequence model. We compare these approaches against dictionary-based replacements. We assess the quality of the generated sentences through human evaluation and evaluate the effectiveness of data augmentation on machine translation (MT), automatic speech recognition (ASR), and speech translation (ST) tasks. Results show that using a predictive model results in more natural CS sentences compared to the random approach, as reported in human judgements. In the downstream tasks, despite the random approach generating more data, both approaches perform equally (outperforming dictionary-based replacements). Overall, data augmentation achieves 34% improv",
    "path": "papers/22/05/2205.12649.json",
    "total_tokens": 957,
    "translated_title": "研究用于阿拉伯-英语混合代码数据增强的词汇替换方法",
    "translated_abstract": "数据稀疏是阻碍混合代码（CS）NLP系统发展的主要问题。本文研究了一种用于合成方言阿拉伯语-英语混合代码文本的数据增强技术 - 词汇替换。我们使用单词对齐的平行语料库进行词汇替换，其中CS点是随机选择或使用序列到序列模型进行学习的。我们将这些方法与基于词典的替换方法进行比较。通过人工评估评估所生成的句子的质量，评估数据增强对机器翻译（MT）、自动语音识别（ASR）和语音翻译（ST）任务的有效性。结果表明，使用预测模型相对于随机方法生成了更自然的CS句子，这是根据人类判断提出的。在下游任务中，尽管随机方法生成了更多的数据，但两种方法的性能相同（优于基于词典的替换）。总体而言，数据增强实现了34%的改进。",
    "tldr": "本文研究了用于阿拉伯-英语混合代码数据增强的词汇替换方法，通过单词对齐的平行语料库进行词汇替换，评估了其在机器翻译（MT）、自动语音识别（ASR）和语音翻译（ST）任务的有效性，并取得了34%的改进。",
    "en_tdlr": "This paper investigates lexical replacements for data augmentation in dialectal Arabic-English code-switched text, evaluates their effectiveness on machine translation (MT), automatic speech recognition (ASR), and speech translation (ST) tasks, and achieves 34% improvement in overall performance."
}