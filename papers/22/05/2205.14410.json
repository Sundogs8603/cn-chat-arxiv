{
    "title": "Multi-Source Transfer Learning for Deep Model-Based Reinforcement Learning. (arXiv:2205.14410v3 [cs.LG] UPDATED)",
    "abstract": "A crucial challenge in reinforcement learning is to reduce the number of interactions with the environment that an agent requires to master a given task. Transfer learning proposes to address this issue by re-using knowledge from previously learned tasks. However, determining which source task qualifies as the most appropriate for knowledge extraction, as well as the choice regarding which algorithm components to transfer, represent severe obstacles to its application in reinforcement learning. The goal of this paper is to address these issues with modular multi-source transfer learning techniques. The proposed techniques automatically learn how to extract useful information from source tasks, regardless of the difference in state-action space and reward function. We support our claims with extensive and challenging cross-domain experiments for visual control.",
    "link": "http://arxiv.org/abs/2205.14410",
    "context": "Title: Multi-Source Transfer Learning for Deep Model-Based Reinforcement Learning. (arXiv:2205.14410v3 [cs.LG] UPDATED)\nAbstract: A crucial challenge in reinforcement learning is to reduce the number of interactions with the environment that an agent requires to master a given task. Transfer learning proposes to address this issue by re-using knowledge from previously learned tasks. However, determining which source task qualifies as the most appropriate for knowledge extraction, as well as the choice regarding which algorithm components to transfer, represent severe obstacles to its application in reinforcement learning. The goal of this paper is to address these issues with modular multi-source transfer learning techniques. The proposed techniques automatically learn how to extract useful information from source tasks, regardless of the difference in state-action space and reward function. We support our claims with extensive and challenging cross-domain experiments for visual control.",
    "path": "papers/22/05/2205.14410.json",
    "total_tokens": 798,
    "translated_title": "基于多源迁移学习的深度模型强化学习",
    "translated_abstract": "强化学习面临的一个关键挑战是减少智能体在掌握给定任务时需要与环境互动的次数。迁移学习提出通过重复利用先前学习任务中的知识来解决这个问题。然而，确定哪个源任务有资格用于知识提取，以及选择哪些算法组件进行迁移，是其在强化学习应用中面临的严重障碍。本文的目标是通过模块化多源迁移学习技术来解决这些问题。所提出的技术可以自动学习如何从源任务中提取有用信息，而不受状态-动作空间和奖励函数差异的影响。我们在视觉控制方面进行了广泛而具有挑战性的跨域实验来支持我们的想法。",
    "tldr": "本文提出了一种基于多源迁移学习的模块化技术，可以自动学习如何从先前学习的任务中提取有用信息，从而减少智能体在学习新任务时需要与环境互动的次数。",
    "en_tdlr": "This paper proposes modular multi-source transfer learning techniques that can automatically learn how to extract useful information from previously learned tasks, thus reducing the number of interactions an agent requires to learn new tasks."
}