{
    "title": "Addressing Strategic Manipulation Disparities in Fair Classification. (arXiv:2205.10842v2 [cs.CY] UPDATED)",
    "abstract": "In real-world classification settings, such as loan application evaluation or content moderation on online platforms, individuals respond to classifier predictions by strategically updating their features to increase their likelihood of receiving a particular (positive) decision (at a certain cost). Yet, when different demographic groups have different feature distributions or pay different update costs, prior work has shown that individuals from minority groups often pay a higher cost to update their features. Fair classification aims to address such classifier performance disparities by constraining the classifiers to satisfy statistical fairness properties. However, we show that standard fairness constraints do not guarantee that the constrained classifier reduces the disparity in strategic manipulation cost. To address such biases in strategic settings and provide equal opportunities for strategic manipulation, we propose a constrained optimization framework that constructs classif",
    "link": "http://arxiv.org/abs/2205.10842",
    "context": "Title: Addressing Strategic Manipulation Disparities in Fair Classification. (arXiv:2205.10842v2 [cs.CY] UPDATED)\nAbstract: In real-world classification settings, such as loan application evaluation or content moderation on online platforms, individuals respond to classifier predictions by strategically updating their features to increase their likelihood of receiving a particular (positive) decision (at a certain cost). Yet, when different demographic groups have different feature distributions or pay different update costs, prior work has shown that individuals from minority groups often pay a higher cost to update their features. Fair classification aims to address such classifier performance disparities by constraining the classifiers to satisfy statistical fairness properties. However, we show that standard fairness constraints do not guarantee that the constrained classifier reduces the disparity in strategic manipulation cost. To address such biases in strategic settings and provide equal opportunities for strategic manipulation, we propose a constrained optimization framework that constructs classif",
    "path": "papers/22/05/2205.10842.json",
    "total_tokens": 787,
    "translated_title": "解决公平分类中战略操纵的差异",
    "translated_abstract": "在现实世界的分类环境中，如贷款申请评估或在线平台上的内容审查，个体通过战略性地更新其特征来增加其获得特定（积极）决策的可能性（以一定的成本）。然而，当不同人口群体具有不同的特征分布或支付不同的更新成本时，先前的研究表明，来自少数群体的个体付出更高的成本来更新其特征。公平分类旨在通过限制分类器满足统计公平性属性来解决此类分类器性能差异。然而，我们发现标准的公平性约束并不能确保受约束的分类器减少战略操纵成本的差异。为了解决战略环境中的这种偏差并为战略操纵提供平等机会，我们提出了一个受约束的优化框架，构建分类器。",
    "tldr": "该论文研究了公平分类中存在的战略操纵差异问题，提出了一个受约束的优化框架来解决这个问题。",
    "en_tdlr": "This paper addresses the issue of strategic manipulation disparities in fair classification and proposes a constrained optimization framework to solve this problem."
}