{
    "title": "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models. (arXiv:2205.10625v3 [cs.AI] UPDATED)",
    "abstract": "Chain-of-thought prompting has demonstrated remarkable performance on various natural language reasoning tasks. However, it tends to perform poorly on tasks which requires solving problems harder than the exemplars shown in the prompts. To overcome this challenge of easy-to-hard generalization, we propose a novel prompting strategy, least-to-most prompting. The key idea in this strategy is to break down a complex problem into a series of simpler subproblems and then solve them in sequence. Solving each subproblem is facilitated by the answers to previously solved subproblems. Our experimental results on tasks related to symbolic manipulation, compositional generalization, and math reasoning reveal that least-to-most prompting is capable of generalizing to more difficult problems than those seen in the prompts. A notable finding is that when the GPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve the compositional generalization benchmark SCAN in any split (i",
    "link": "http://arxiv.org/abs/2205.10625",
    "context": "Title: Least-to-Most Prompting Enables Complex Reasoning in Large Language Models. (arXiv:2205.10625v3 [cs.AI] UPDATED)\nAbstract: Chain-of-thought prompting has demonstrated remarkable performance on various natural language reasoning tasks. However, it tends to perform poorly on tasks which requires solving problems harder than the exemplars shown in the prompts. To overcome this challenge of easy-to-hard generalization, we propose a novel prompting strategy, least-to-most prompting. The key idea in this strategy is to break down a complex problem into a series of simpler subproblems and then solve them in sequence. Solving each subproblem is facilitated by the answers to previously solved subproblems. Our experimental results on tasks related to symbolic manipulation, compositional generalization, and math reasoning reveal that least-to-most prompting is capable of generalizing to more difficult problems than those seen in the prompts. A notable finding is that when the GPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve the compositional generalization benchmark SCAN in any split (i",
    "path": "papers/22/05/2205.10625.json",
    "total_tokens": 993,
    "translated_title": "最少到最多提示可以使大规模语言模型实现复杂推理",
    "translated_abstract": "思维链提示在各种自然语言推理任务中表现出卓越的性能。然而，它在需要解决比提示中的示例更难的问题时表现不佳。为了克服这种易于困难泛化的挑战，我们提出了一种新的提示策略，即最少到最多提示。该策略的关键思想是将复杂问题分解成一系列更简单的子问题，然后按顺序解决它们。解决每个子问题都得益于先前解决的子问题的答案。我们在符号操作、组合推理和数学推理相关的任务上的实验结果表明，最少到最多提示能够推广到比提示中更难的问题。一个值得注意的发现是，在使用最少到最多提示与GPT-3 code-davinci-002模型的情况下，它可以以完美的准确性解决组合泛化基准SCAN中的任何分割(包括具有挑战性的零样本分割)，尽管之前无法在没有微调的情况下解决任何分割点。",
    "tldr": "本文提出最少到最多提示的策略，能够帮助大规模语言模型实现复杂推理并推广到难度更高的问题。通过这种策略结合GPT-3 code-davinci-002模型能够完美解决组合泛化基准SCAN中的所有分割。",
    "en_tdlr": "This article introduces a new prompting strategy, least-to-most prompting, which can help large language models achieve complex reasoning and generalize to more difficult problems. By using this strategy combined with the GPT-3 code-davinci-002 model, it can solve all splits of the compositional generalization benchmark SCAN with perfect accuracy, including challenging zero-shot splits."
}