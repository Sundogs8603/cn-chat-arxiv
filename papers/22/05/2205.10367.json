{
    "title": "Latent-space disentanglement with untrained generator networks for the isolation of different motion types in video data. (arXiv:2205.10367v2 [eess.IV] UPDATED)",
    "abstract": "Isolating different types of motion in video data is a highly relevant problem in video analysis. Applications can be found, for example, in dynamic medical or biological imaging, where the analysis and further processing of the dynamics of interest is often complicated by additional, unwanted dynamics, such as motion of the measurement subject. In this work, it is empirically shown that a representation of video data via untrained generator networks, together with a specific technique for latent space disentanglement that uses minimal, one-dimensional information on some of the underlying dynamics, allows to efficiently isolate different, highly non-linear motion types. In particular, such a representation allows to freeze any selection of motion types, and to obtain accurate independent representations of other dynamics of interest. Obtaining such a representation does not require any pre-training on a training data set, i.e., all parameters of the generator network are learned direc",
    "link": "http://arxiv.org/abs/2205.10367",
    "context": "Title: Latent-space disentanglement with untrained generator networks for the isolation of different motion types in video data. (arXiv:2205.10367v2 [eess.IV] UPDATED)\nAbstract: Isolating different types of motion in video data is a highly relevant problem in video analysis. Applications can be found, for example, in dynamic medical or biological imaging, where the analysis and further processing of the dynamics of interest is often complicated by additional, unwanted dynamics, such as motion of the measurement subject. In this work, it is empirically shown that a representation of video data via untrained generator networks, together with a specific technique for latent space disentanglement that uses minimal, one-dimensional information on some of the underlying dynamics, allows to efficiently isolate different, highly non-linear motion types. In particular, such a representation allows to freeze any selection of motion types, and to obtain accurate independent representations of other dynamics of interest. Obtaining such a representation does not require any pre-training on a training data set, i.e., all parameters of the generator network are learned direc",
    "path": "papers/22/05/2205.10367.json",
    "total_tokens": 867,
    "translated_title": "未训练生成器网络的潜空间解缠方法用于隔离视频数据中的不同运动类型",
    "translated_abstract": "隔离视频数据中不同类型的动作是视频分析中一个非常相关的问题。例如在动态医学或生物成像中，感兴趣动态的分析和进一步处理通常会因为附加的非关键动态（例如被测主体的运动）而变得复杂。本文通过实证分析表明，利用未经训练的生成器网络对视频数据进行表示，再结合一种特殊的潜空间解缠技术，可仅利用对一些底层动态的最小一维信息，有效隔离不同的高度非线性的运动类型。特别地，这种表示允许冻结任何动作类型的选择，并获得所需的其他关键动态的准确独立表示。获得这种表示不需要对训练数据集进行任何预训练，即生成器网络的所有参数都是直接学习得出的。",
    "tldr": "本文通过未经训练的生成器网络与特定的潜空间解缠技术方法，仅利用最小的底层动态信息，有效隔离视频数据中不同非线性运动类型，而不需要预训练模型。",
    "en_tdlr": "This paper utilizes untrained generator networks and a specific technique for latent space disentanglement to efficiently isolate different highly non-linear motion types in video data, without the need for pre-training on a training dataset."
}