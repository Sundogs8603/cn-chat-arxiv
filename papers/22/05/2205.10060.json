{
    "title": "The Unreasonable Effectiveness of Deep Evidential Regression. (arXiv:2205.10060v3 [cs.LG] UPDATED)",
    "abstract": "There is a significant need for principled uncertainty reasoning in machine learning systems as they are increasingly deployed in safety-critical domains. A new approach with uncertainty-aware regression-based neural networks (NNs), based on learning evidential distributions for aleatoric and epistemic uncertainties, shows promise over traditional deterministic methods and typical Bayesian NNs, notably with the capabilities to disentangle aleatoric and epistemic uncertainties. Despite some empirical success of Deep Evidential Regression (DER), there are important gaps in the mathematical foundation that raise the question of why the proposed technique seemingly works. We detail the theoretical shortcomings and analyze the performance on synthetic and real-world data sets, showing that Deep Evidential Regression is a heuristic rather than an exact uncertainty quantification. We go on to discuss corrections and redefinitions of how aleatoric and epistemic uncertainties should be extracte",
    "link": "http://arxiv.org/abs/2205.10060",
    "context": "Title: The Unreasonable Effectiveness of Deep Evidential Regression. (arXiv:2205.10060v3 [cs.LG] UPDATED)\nAbstract: There is a significant need for principled uncertainty reasoning in machine learning systems as they are increasingly deployed in safety-critical domains. A new approach with uncertainty-aware regression-based neural networks (NNs), based on learning evidential distributions for aleatoric and epistemic uncertainties, shows promise over traditional deterministic methods and typical Bayesian NNs, notably with the capabilities to disentangle aleatoric and epistemic uncertainties. Despite some empirical success of Deep Evidential Regression (DER), there are important gaps in the mathematical foundation that raise the question of why the proposed technique seemingly works. We detail the theoretical shortcomings and analyze the performance on synthetic and real-world data sets, showing that Deep Evidential Regression is a heuristic rather than an exact uncertainty quantification. We go on to discuss corrections and redefinitions of how aleatoric and epistemic uncertainties should be extracte",
    "path": "papers/22/05/2205.10060.json",
    "total_tokens": 871,
    "translated_title": "深度证据回归的不合理有效性",
    "translated_abstract": "随着机器学习系统在安全关键领域的不断部署，对于基于原则的不确定性推理的需求日益迫切。一种新的不确定性感知回归神经网络（NN）方法，通过学习关于内部变量和外部变量的不确定性的证据分布，显示出相对于传统确定性方法和典型贝叶斯NN的优势，尤其在能够解耦内部和外部不确定性方面。尽管深度证据回归（DER）取得了一定的实证成功，但数学基础存在重要的不足，这引发了为何所提出的技术看似有效的问题。我们详细说明了理论上的不足，并分析了在合成和真实数据集上的性能，表明深度证据回归是一种启发式而非精确的不确定性量化方法。我们继续讨论如何修正和重新定义内部和外部不确定性的提取方法。",
    "tldr": "深度证据回归是一种通过学习证据分布来处理不确定性的方法，在不确定性推理中显示出相对于传统方法和贝叶斯神经网络的优势。然而，它并非精确的不确定性量化方法，而是一种启发式方法。"
}