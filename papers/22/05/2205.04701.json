{
    "title": "StableDR: Stabilized Doubly Robust Learning for Recommendation on Data Missing Not at Random. (arXiv:2205.04701v3 [cs.LG] UPDATED)",
    "abstract": "In recommender systems, users always choose the favorite items to rate, which leads to data missing not at random and poses a great challenge for unbiased evaluation and learning of prediction models. Currently, the doubly robust (DR) methods have been widely studied and demonstrate superior performance. However, in this paper, we show that DR methods are unstable and have unbounded bias, variance, and generalization bounds to extremely small propensities. Moreover, the fact that DR relies more on extrapolation will lead to suboptimal performance. To address the above limitations while retaining double robustness, we propose a stabilized doubly robust (StableDR) learning approach with a weaker reliance on extrapolation. Theoretical analysis shows that StableDR has bounded bias, variance, and generalization error bound simultaneously under inaccurate imputed errors and arbitrarily small propensities. In addition, we propose a novel learning approach for StableDR that updates the imputat",
    "link": "http://arxiv.org/abs/2205.04701",
    "context": "Title: StableDR: Stabilized Doubly Robust Learning for Recommendation on Data Missing Not at Random. (arXiv:2205.04701v3 [cs.LG] UPDATED)\nAbstract: In recommender systems, users always choose the favorite items to rate, which leads to data missing not at random and poses a great challenge for unbiased evaluation and learning of prediction models. Currently, the doubly robust (DR) methods have been widely studied and demonstrate superior performance. However, in this paper, we show that DR methods are unstable and have unbounded bias, variance, and generalization bounds to extremely small propensities. Moreover, the fact that DR relies more on extrapolation will lead to suboptimal performance. To address the above limitations while retaining double robustness, we propose a stabilized doubly robust (StableDR) learning approach with a weaker reliance on extrapolation. Theoretical analysis shows that StableDR has bounded bias, variance, and generalization error bound simultaneously under inaccurate imputed errors and arbitrarily small propensities. In addition, we propose a novel learning approach for StableDR that updates the imputat",
    "path": "papers/22/05/2205.04701.json",
    "total_tokens": 984,
    "translated_title": "StableDR:稳定的双重稳健学习方法用于数据缺失非随机的推荐系统",
    "translated_abstract": "在推荐系统中，用户倾向于选择自己喜欢的物品进行评价，这导致了数据缺失非随机的问题，在对预测模型进行无偏评估和学习时带来了很大挑战。目前，双重稳健（DR）方法已经得到广泛研究，并展示出优越的性能。然而，在本文中，我们展示了DR方法的不稳定性以及对极小的倾向性具有无界偏差、方差和泛化界限的问题。此外，DR更多地依赖外推，这会导致次优的性能。为了解决以上问题，我们提出了一种稳定的双重稳健（StableDR）学习方法，对外推的依赖较弱。理论分析表明，在不准确的估计误差和任意小的倾向性下，StableDR同时具有有界的偏差、方差和泛化误差界。此外，我们还提出了一种针对StableDR的新型学习方法来更新估计值。",
    "tldr": "StableDR是一种稳定的双重稳健学习方法，用于解决推荐系统中数据缺失非随机的问题。通过减少对外推的依赖，StableDR能够同时具有有界的偏差、方差和泛化误差界，在不准确的估计误差和任意小的倾向性下表现出优越性能。",
    "en_tdlr": "StableDR is a stable doubly robust learning approach that addresses the issue of data missing not at random in recommender systems. By reducing reliance on extrapolation, StableDR achieves bounded bias, variance, and generalization error bound simultaneously, demonstrating superior performance under inaccurate imputed errors and arbitrarily small propensities."
}