{
    "title": "Towards biologically plausible Dreaming and Planning in recurrent spiking networks. (arXiv:2205.10044v3 [cs.LG] UPDATED)",
    "abstract": "Humans and animals can learn new skills after practicing for a few hours, while current reinforcement learning algorithms require a large amount of data to achieve good performances. Recent model-based approaches show promising results by reducing the number of necessary interactions with the environment to learn a desirable policy. However, these methods require biological implausible ingredients, such as the detailed storage of older experiences, and long periods of offline learning. The optimal way to learn and exploit word-models is still an open question. Taking inspiration from biology, we suggest that dreaming might be an efficient expedient to use an inner model. We propose a two-module (agent and model) spiking neural network in which \"dreaming\" (living new experiences in a model-based simulated environment) significantly boosts learning. We also explore \"planning\", an online alternative to dreaming, that shows comparable performances. Importantly, our model does not require t",
    "link": "http://arxiv.org/abs/2205.10044",
    "context": "Title: Towards biologically plausible Dreaming and Planning in recurrent spiking networks. (arXiv:2205.10044v3 [cs.LG] UPDATED)\nAbstract: Humans and animals can learn new skills after practicing for a few hours, while current reinforcement learning algorithms require a large amount of data to achieve good performances. Recent model-based approaches show promising results by reducing the number of necessary interactions with the environment to learn a desirable policy. However, these methods require biological implausible ingredients, such as the detailed storage of older experiences, and long periods of offline learning. The optimal way to learn and exploit word-models is still an open question. Taking inspiration from biology, we suggest that dreaming might be an efficient expedient to use an inner model. We propose a two-module (agent and model) spiking neural network in which \"dreaming\" (living new experiences in a model-based simulated environment) significantly boosts learning. We also explore \"planning\", an online alternative to dreaming, that shows comparable performances. Importantly, our model does not require t",
    "path": "papers/22/05/2205.10044.json",
    "total_tokens": 928,
    "translated_title": "基于循环脉冲神经网络的生物学可行的梦想与规划方法探究",
    "translated_abstract": "人和动物可以在练习几个小时后学习到新技能，而当前的强化学习算法需要大量数据才能获得良好的性能。最近的基于模型的方法通过减少学习环境中必要的交互次数来学习所需的策略，结果显示出很好的效果。然而，这些方法需要生物学上不合理的因素，例如详细存储旧经验和长时间的离线学习。学习和利用模型的最佳方式仍然是一个未解决的问题。受生物学启发，我们建议梦想可能是使用内部模型的有效方法。我们提出了一个由“梦想”（在基于模型的模拟环境中体验新经历）显著促进学习的两个模块（代理和模型）脉冲神经网络。我们还探讨了“规划”，这是“梦想”的在线替代方案，表现出相当的性能。重要的是，我们的模型不需要详细的旧经验存储。",
    "tldr": "本研究提出了一种基于循环脉冲神经网络的生物学可行的梦想与规划学习方法，该方法可以显著促进学习，而不需要详细存储旧经验和长时间的离线学习。"
}