{
    "title": "Super Images -- A New 2D Perspective on 3D Medical Imaging Analysis. (arXiv:2205.02847v2 [eess.IV] UPDATED)",
    "abstract": "In medical imaging analysis, deep learning has shown promising results. We frequently rely on volumetric data to segment medical images, necessitating the use of 3D architectures, which are commended for their capacity to capture interslice context. However, because of the 3D convolutions, max pooling, up-convolutions, and other operations utilized in these networks, these architectures are often more inefficient in terms of time and computation than their 2D equivalents. Furthermore, there are few 3D pretrained model weights, and pretraining is often difficult. We present a simple yet effective 2D method to handle 3D data while efficiently embedding the 3D knowledge during training. We propose transforming volumetric data into 2D super images and segmenting with 2D networks to solve these challenges. Our method generates a super-resolution image by stitching slices side by side in the 3D image. We expect deep neural networks to capture and learn these properties spatially despite losi",
    "link": "http://arxiv.org/abs/2205.02847",
    "context": "Title: Super Images -- A New 2D Perspective on 3D Medical Imaging Analysis. (arXiv:2205.02847v2 [eess.IV] UPDATED)\nAbstract: In medical imaging analysis, deep learning has shown promising results. We frequently rely on volumetric data to segment medical images, necessitating the use of 3D architectures, which are commended for their capacity to capture interslice context. However, because of the 3D convolutions, max pooling, up-convolutions, and other operations utilized in these networks, these architectures are often more inefficient in terms of time and computation than their 2D equivalents. Furthermore, there are few 3D pretrained model weights, and pretraining is often difficult. We present a simple yet effective 2D method to handle 3D data while efficiently embedding the 3D knowledge during training. We propose transforming volumetric data into 2D super images and segmenting with 2D networks to solve these challenges. Our method generates a super-resolution image by stitching slices side by side in the 3D image. We expect deep neural networks to capture and learn these properties spatially despite losi",
    "path": "papers/22/05/2205.02847.json",
    "total_tokens": 943,
    "translated_title": "超级图像——3D医学成像分析的全新二维视角",
    "translated_abstract": "在医学成像分析中，深度学习表现出了很好的结果。我们经常依赖体积数据来分割医学图像，需要使用3D架构，这些架构因其捕捉interslice context的能力而受到赞赏。然而，由于这些网络中使用了3D卷积、最大池化、up-convolutions和其他操作，这些架构在时间和计算方面通常比它们的2D等价物更低效。此外，很少有3D预训练模型权重，预训练通常很难。我们提出了一种简单而有效的二维方法来有效地嵌入3D知识，同时处理3D数据。我们提出将体积数据转换为2D超级图像，并使用2D网络进行分割以解决这些挑战。我们的方法通过将3D图像的切片并排拼接来生成超分辨率图像。我们期望深度神经网络能够在空间上捕捉和学习这些特性，尽管可能会丢失interslice context信息。",
    "tldr": "本文提出了一种在医学成像分析中处理3D数据的新方法，即将体积数据转换为2D超级图像，并使用2D网络进行分割，以提高效率。该方法可以在训练中有效地嵌入3D知识。",
    "en_tdlr": "This paper proposes a novel method for handling 3D medical imaging analysis by transforming volumetric data into 2D super images and segmenting with 2D networks, which is more efficient than 3D architectures and effectively embeds 3D knowledge during training."
}