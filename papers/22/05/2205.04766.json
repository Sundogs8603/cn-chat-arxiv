{
    "title": "Explainable Deep Learning Methods in Medical Image Classification: A Survey. (arXiv:2205.04766v3 [eess.IV] UPDATED)",
    "abstract": "The remarkable success of deep learning has prompted interest in its application to medical imaging diagnosis. Even though state-of-the-art deep learning models have achieved human-level accuracy on the classification of different types of medical data, these models are hardly adopted in clinical workflows, mainly due to their lack of interpretability. The black-box-ness of deep learning models has raised the need for devising strategies to explain the decision process of these models, leading to the creation of the topic of eXplainable Artificial Intelligence (XAI). In this context, we provide a thorough survey of XAI applied to medical imaging diagnosis, including visual, textual, example-based and concept-based explanation methods. Moreover, this work reviews the existing medical imaging datasets and the existing metrics for evaluating the quality of the explanations. In addition, we include a performance comparison among a set of report generation-based methods. Finally, the major ",
    "link": "http://arxiv.org/abs/2205.04766",
    "context": "Title: Explainable Deep Learning Methods in Medical Image Classification: A Survey. (arXiv:2205.04766v3 [eess.IV] UPDATED)\nAbstract: The remarkable success of deep learning has prompted interest in its application to medical imaging diagnosis. Even though state-of-the-art deep learning models have achieved human-level accuracy on the classification of different types of medical data, these models are hardly adopted in clinical workflows, mainly due to their lack of interpretability. The black-box-ness of deep learning models has raised the need for devising strategies to explain the decision process of these models, leading to the creation of the topic of eXplainable Artificial Intelligence (XAI). In this context, we provide a thorough survey of XAI applied to medical imaging diagnosis, including visual, textual, example-based and concept-based explanation methods. Moreover, this work reviews the existing medical imaging datasets and the existing metrics for evaluating the quality of the explanations. In addition, we include a performance comparison among a set of report generation-based methods. Finally, the major ",
    "path": "papers/22/05/2205.04766.json",
    "total_tokens": 779,
    "translated_title": "医学图像分类中的可解释深度学习方法：一项调查",
    "translated_abstract": "深度学习在医学影像诊断中取得了显著的成功，但由于其缺乏可解释性，这些模型很难在临床工作流程中得到采用。这引发了对解释深度学习模型决策过程的需求，进而形成了可解释人工智能（XAI）的研究领域。本文全面调查了XAI在医学影像诊断中的应用，包括视觉、文本、基于示例和基于概念的解释方法。此外，本文还回顾了现有的医学影像数据集和用于评估解释质量的指标。此外，我们还对一组基于报告生成的方法进行了性能比较。",
    "tldr": "这项调查提供了关于可解释深度学习方法在医学图像分类中的应用的全面概述，包括各种解释方法的比较和性能评估。"
}