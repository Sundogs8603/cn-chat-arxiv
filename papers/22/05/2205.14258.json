{
    "title": "On the Symmetries of Deep Learning Models and their Internal Representations. (arXiv:2205.14258v5 [cs.LG] UPDATED)",
    "abstract": "Symmetry is a fundamental tool in the exploration of a broad range of complex systems. In machine learning symmetry has been explored in both models and data. In this paper we seek to connect the symmetries arising from the architecture of a family of models with the symmetries of that family's internal representation of data. We do this by calculating a set of fundamental symmetry groups, which we call the intertwiner groups of the model. We connect intertwiner groups to a model's internal representations of data through a range of experiments that probe similarities between hidden states across models with the same architecture. Our work suggests that the symmetries of a network are propagated into the symmetries in that network's representation of data, providing us with a better understanding of how architecture affects the learning and prediction process. Finally, we speculate that for ReLU networks, the intertwiner groups may provide a justification for the common practice of con",
    "link": "http://arxiv.org/abs/2205.14258",
    "context": "Title: On the Symmetries of Deep Learning Models and their Internal Representations. (arXiv:2205.14258v5 [cs.LG] UPDATED)\nAbstract: Symmetry is a fundamental tool in the exploration of a broad range of complex systems. In machine learning symmetry has been explored in both models and data. In this paper we seek to connect the symmetries arising from the architecture of a family of models with the symmetries of that family's internal representation of data. We do this by calculating a set of fundamental symmetry groups, which we call the intertwiner groups of the model. We connect intertwiner groups to a model's internal representations of data through a range of experiments that probe similarities between hidden states across models with the same architecture. Our work suggests that the symmetries of a network are propagated into the symmetries in that network's representation of data, providing us with a better understanding of how architecture affects the learning and prediction process. Finally, we speculate that for ReLU networks, the intertwiner groups may provide a justification for the common practice of con",
    "path": "papers/22/05/2205.14258.json",
    "total_tokens": 860,
    "translated_title": "深度学习模型及其内部表示的对称性研究",
    "translated_abstract": "对称性是研究复杂系统的基本工具。在机器学习中，对称性已经在模型和数据中得到了研究。本文旨在通过计算模型的一组基本对称群，即模型的intertwiner groups，将模型架构的对称性与该模型对数据的内部表示的对称性相联系。我们通过一系列实验将intertwiner groups连接到具有相同架构的模型的隐藏状态之间的相似之处。我们的研究表明，网络的对称性传播到该网络对数据的表示中的对称性，更好地理解架构如何影响学习和预测过程。最后，我们推测，对于ReLU网络，intertwiner groups可能为常见的堆叠网络结构提供了正当性。",
    "tldr": "本文研究了深度学习模型及其内部表示的对称性，发现网络的对称性传播到数据的表示中的对称性，为更好地理解架构影响学习和预测过程提供了一种方法。",
    "en_tdlr": "This paper investigates the symmetries of deep learning models and their internal representations, finding that the symmetries of a network are propagated into the symmetries in that network's representation of data, providing a better understanding of how architecture affects the learning and prediction process. The intertwiner groups may provide a justification for the common practice of stacking ReLU networks."
}