{
    "title": "Variational Transfer Learning using Cross-Domain Latent Modulation",
    "abstract": "To successfully apply trained neural network models to new domains, powerful transfer learning solutions are essential. We propose to introduce a novel cross-domain latent modulation mechanism to a variational autoencoder framework so as to achieve effective transfer learning. Our key idea is to procure deep representations from one data domain and use it to influence the reparameterization of the latent variable of another domain. Specifically, deep representations of the source and target domains are first extracted by a unified inference model and aligned by employing gradient reversal. The learned deep representations are then cross-modulated to the latent encoding of the alternative domain, where consistency constraints are also applied. In the empirical validation that includes a number of transfer learning benchmark tasks for unsupervised domain adaptation and image-to-image translation, our model demonstrates competitive performance, which is also supported by evidence obtained",
    "link": "https://arxiv.org/abs/2205.15523",
    "context": "Title: Variational Transfer Learning using Cross-Domain Latent Modulation\nAbstract: To successfully apply trained neural network models to new domains, powerful transfer learning solutions are essential. We propose to introduce a novel cross-domain latent modulation mechanism to a variational autoencoder framework so as to achieve effective transfer learning. Our key idea is to procure deep representations from one data domain and use it to influence the reparameterization of the latent variable of another domain. Specifically, deep representations of the source and target domains are first extracted by a unified inference model and aligned by employing gradient reversal. The learned deep representations are then cross-modulated to the latent encoding of the alternative domain, where consistency constraints are also applied. In the empirical validation that includes a number of transfer learning benchmark tasks for unsupervised domain adaptation and image-to-image translation, our model demonstrates competitive performance, which is also supported by evidence obtained",
    "path": "papers/22/05/2205.15523.json",
    "total_tokens": 892,
    "translated_title": "变分转移学习中的跨领域潜在调制机制",
    "translated_abstract": "为了成功地将训练好的神经网络模型应用到新领域，强大的转移学习解决方案至关重要。我们提出了一种新的跨领域潜在调制机制，将其引入到变分自编码器框架中，以实现有效的转移学习。我们的关键思想是从一个数据领域获取深层表示，并用它来影响另一个领域的潜在变量的重新参数化。具体地说，通过统一的推理模型来提取源领域和目标领域的深层表示，并通过梯度反转进行对齐。然后将学习到的深层表示跨调制到另一领域的潜在编码中，并应用一致性约束。在包括一些无监督领域自适应和图像到图像转换的转移学习基准任务的实证验证中，我们的模型展示了竞争性能，并且得到了支持的证据。",
    "tldr": "本研究提出了一种变分自编码器框架中的跨领域潜在调制机制，通过从一领域获取深层表示并影响另一领域的潜在变量，实现了有效的转移学习。在多个转移学习基准任务中，我们的模型展示了竞争性能。"
}