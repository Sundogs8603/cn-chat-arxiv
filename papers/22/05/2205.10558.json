{
    "title": "CORAL: Contextual Response Retrievability Loss Function for Training Dialog Generation Models. (arXiv:2205.10558v3 [cs.CL] UPDATED)",
    "abstract": "In the field of Natural Language Processing, there are many tasks that can be tackled effectively using the cross-entropy (CE) loss function. However, the task of dialog generation poses unique challenges for CE loss. This is because CE loss assumes that, for any given input, the only possible output is the one available as the ground truth in the training dataset. But, in dialog generation, there can be multiple valid responses (for a given context) that not only have different surface forms but can also be semantically different. Furthermore, CE loss computation for the dialog generation task does not take the input context into consideration and, hence, it grades the response irrespective of the context. To grade the generated response for qualities like relevance, engagingness, etc., the loss function should depend on both the context and the generated response. To address these limitations, this paper proposes CORAL, a novel loss function based on a reinforcement learning (RL) vie",
    "link": "http://arxiv.org/abs/2205.10558",
    "context": "Title: CORAL: Contextual Response Retrievability Loss Function for Training Dialog Generation Models. (arXiv:2205.10558v3 [cs.CL] UPDATED)\nAbstract: In the field of Natural Language Processing, there are many tasks that can be tackled effectively using the cross-entropy (CE) loss function. However, the task of dialog generation poses unique challenges for CE loss. This is because CE loss assumes that, for any given input, the only possible output is the one available as the ground truth in the training dataset. But, in dialog generation, there can be multiple valid responses (for a given context) that not only have different surface forms but can also be semantically different. Furthermore, CE loss computation for the dialog generation task does not take the input context into consideration and, hence, it grades the response irrespective of the context. To grade the generated response for qualities like relevance, engagingness, etc., the loss function should depend on both the context and the generated response. To address these limitations, this paper proposes CORAL, a novel loss function based on a reinforcement learning (RL) vie",
    "path": "papers/22/05/2205.10558.json",
    "total_tokens": 893,
    "translated_title": "CORAL：基于上下文的生成对话模型的响应可检索性损失函数",
    "translated_abstract": "在自然语言处理领域中，使用交叉熵（CE）损失函数可以有效地解决许多任务。然而，生成对话的任务对CE损失提出了独特的挑战。这是因为CE损失假定对于任何给定的输入，唯一可能的输出是训练数据集中作为基本真实的输出。但是，在生成对话中，可以有多个有效的响应（对于给定的上下文），它们不仅具有不同的表面形式，而且可以是语义上不同的。此外，对于对话生成任务的CE损失计算不考虑输入上下文，并且基于响应对其进行评分，而不考虑上下文。要对生成的响应进行类似关联性、吸引力等品质的评分，损失函数应该依赖于上下文和生成的响应。本文提出了基于强化学习（RL）视图的CORAL，这是一种新颖的损失函数，用于解决这些限制。",
    "tldr": "本研究提出了一种基于强化学习视图的损失函数CORAL，用于评估生成对话模型的响应质量，该损失函数同时考虑到了上下文和生成的响应。",
    "en_tdlr": "This paper proposes CORAL, a novel loss function based on a reinforcement learning view, to evaluate the response quality of dialog generation models, which takes both the context and generated response into account."
}