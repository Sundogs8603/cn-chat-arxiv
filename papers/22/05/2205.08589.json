{
    "title": "Hierarchical Distribution-Aware Testing of Deep Learning. (arXiv:2205.08589v2 [cs.SE] UPDATED)",
    "abstract": "Deep Learning (DL) is increasingly used in safety-critical applications, raising concerns about its reliability. DL suffers from a well-known problem of lacking robustness, especially when faced with adversarial perturbations known as Adversarial Examples (AEs). Despite recent efforts to detect AEs using advanced attack and testing methods, these approaches often overlook the input distribution and perceptual quality of the perturbations. As a result, the detected AEs may not be relevant in practical applications or may appear unrealistic to human observers. This can waste testing resources on rare AEs that seldom occur during real-world use, limiting improvements in DL model dependability.  In this paper, we propose a new robustness testing approach for detecting AEs that considers both the feature level distribution and the pixel level distribution, capturing the perceptual quality of adversarial perturbations. The two considerations are encoded by a novel hierarchical mechanism. Fir",
    "link": "http://arxiv.org/abs/2205.08589",
    "context": "Title: Hierarchical Distribution-Aware Testing of Deep Learning. (arXiv:2205.08589v2 [cs.SE] UPDATED)\nAbstract: Deep Learning (DL) is increasingly used in safety-critical applications, raising concerns about its reliability. DL suffers from a well-known problem of lacking robustness, especially when faced with adversarial perturbations known as Adversarial Examples (AEs). Despite recent efforts to detect AEs using advanced attack and testing methods, these approaches often overlook the input distribution and perceptual quality of the perturbations. As a result, the detected AEs may not be relevant in practical applications or may appear unrealistic to human observers. This can waste testing resources on rare AEs that seldom occur during real-world use, limiting improvements in DL model dependability.  In this paper, we propose a new robustness testing approach for detecting AEs that considers both the feature level distribution and the pixel level distribution, capturing the perceptual quality of adversarial perturbations. The two considerations are encoded by a novel hierarchical mechanism. Fir",
    "path": "papers/22/05/2205.08589.json",
    "total_tokens": 885,
    "translated_title": "深度学习的分层分布感知测试",
    "translated_abstract": "深度学习在安全关键应用中的使用越来越多，这引发了对其可靠性的担忧。深度学习在面对对抗扰动（即对手样本）时往往缺乏鲁棒性。尽管最近采用了先进的攻击和测试方法来检测对手样本，但这些方法往往忽视了输入分布和扰动的感知质量。结果，检测到的对手样本在实际应用中可能不相关，或者对人类观察者来说可能看起来不真实。这导致测试资源浪费在在现实世界中很少发生的稀有对手样本上，限制了深度学习模型可靠性的提高。在本文中，我们提出了一种新的鲁棒性测试方法，用于检测对手样本，考虑到了特征级别分布和像素级别分布，捕捉了对抗扰动的感知质量。这两种考虑通过一种新颖的分层机制来编码。",
    "tldr": "本文提出了一种新的深度学习鲁棒性测试方法，通过考虑特征和像素级别的分布，捕捉对抗扰动的感知质量，以改善模型可靠性。"
}