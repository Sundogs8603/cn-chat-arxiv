{
    "title": "Few-shot Reranking for Multi-hop QA via Language Model Prompting. (arXiv:2205.12650v3 [cs.CL] UPDATED)",
    "abstract": "We study few-shot reranking for multi-hop QA with open-domain questions. To alleviate the need for a large number of labeled question-document pairs for retriever training, we propose PromptRank, which relies on large language models prompting for multi-hop path reranking. PromptRank first constructs an instruction-based prompt that includes a candidate document path and then computes the relevance score between a given question and the path based on the conditional likelihood of the question given the path prompt according to a language model. PromptRank yields strong retrieval performance on HotpotQA with only 128 training examples compared to state-of-the-art methods trained on thousands of examples -- 73.6 recall@10 by PromptRank vs. 77.8 by PathRetriever and 77.5 by multi-hop dense retrieval. Code available at https://github.com/mukhal/PromptRank",
    "link": "http://arxiv.org/abs/2205.12650",
    "context": "Title: Few-shot Reranking for Multi-hop QA via Language Model Prompting. (arXiv:2205.12650v3 [cs.CL] UPDATED)\nAbstract: We study few-shot reranking for multi-hop QA with open-domain questions. To alleviate the need for a large number of labeled question-document pairs for retriever training, we propose PromptRank, which relies on large language models prompting for multi-hop path reranking. PromptRank first constructs an instruction-based prompt that includes a candidate document path and then computes the relevance score between a given question and the path based on the conditional likelihood of the question given the path prompt according to a language model. PromptRank yields strong retrieval performance on HotpotQA with only 128 training examples compared to state-of-the-art methods trained on thousands of examples -- 73.6 recall@10 by PromptRank vs. 77.8 by PathRetriever and 77.5 by multi-hop dense retrieval. Code available at https://github.com/mukhal/PromptRank",
    "path": "papers/22/05/2205.12650.json",
    "total_tokens": 865,
    "translated_title": "通过语言模型提示的少样本多跳问题再排名研究",
    "translated_abstract": "我们研究了开放领域问题的少样本多跳问题再排名。为了减少对大量标记的问题-文档对进行检索器训练的需求，我们提出了PromptRank，它依赖于大型语言模型对多跳路径进行再排名。PromptRank首先构建一个基于指令的提示，其中包含一个候选文档路径，然后根据语言模型中给定路径提示的条件概率，计算给定问题和路径之间的相关性得分。与基于大量示例训练的最先进方法相比，PromptRank在只有128个训练示例的情况下在HotpotQA上表现出很强的检索性能——PromptRank的召回率@10为73.6，而PathRetriever为77.8，多跳稠密检索为77.5。代码可在https://github.com/mukhal/PromptRank获得。",
    "tldr": "本研究提出了PromptRank方法，通过语言模型提供的多跳路径再排名，实现了少样本的多跳问题检索。在HotpotQA数据集上，PromptRank相比于其他方法使用的大量训练样本，仅使用128个训练示例就能达到较高的召回率。",
    "en_tdlr": "This paper proposes PromptRank, which utilizes language model prompting for reranking multi-hop QA with few-shot learning. PromptRank achieves strong retrieval performance on HotpotQA dataset with only 128 training examples, outperforming state-of-the-art methods that require thousands of examples."
}