{
    "title": "QAMPARI: An Open-domain Question Answering Benchmark for Questions with Many Answers from Multiple Paragraphs. (arXiv:2205.12665v3 [cs.CL] UPDATED)",
    "abstract": "Existing benchmarks for open-domain question answering (ODQA) typically focus on questions whose answers can be extracted from a single paragraph. By contrast, many natural questions, such as \"What players were drafted by the Brooklyn Nets?\" have a list of answers. Answering such questions requires retrieving and reading from many passages, in a large corpus. We introduce QAMPARI, an ODQA benchmark, where question answers are lists of entities, spread across many paragraphs. We created QAMPARI by (a) generating questions with multiple answers from Wikipedia's knowledge graph and tables, (b) automatically pairing answers with supporting evidence in Wikipedia paragraphs, and (c) manually paraphrasing questions and validating each answer. We train ODQA models from the retrieve-and-read family and find that QAMPARI is challenging in terms of both passage retrieval and answer generation, reaching an F1 score of 32.8 at best. Our results highlight the need for developing ODQA models that han",
    "link": "http://arxiv.org/abs/2205.12665",
    "context": "Title: QAMPARI: An Open-domain Question Answering Benchmark for Questions with Many Answers from Multiple Paragraphs. (arXiv:2205.12665v3 [cs.CL] UPDATED)\nAbstract: Existing benchmarks for open-domain question answering (ODQA) typically focus on questions whose answers can be extracted from a single paragraph. By contrast, many natural questions, such as \"What players were drafted by the Brooklyn Nets?\" have a list of answers. Answering such questions requires retrieving and reading from many passages, in a large corpus. We introduce QAMPARI, an ODQA benchmark, where question answers are lists of entities, spread across many paragraphs. We created QAMPARI by (a) generating questions with multiple answers from Wikipedia's knowledge graph and tables, (b) automatically pairing answers with supporting evidence in Wikipedia paragraphs, and (c) manually paraphrasing questions and validating each answer. We train ODQA models from the retrieve-and-read family and find that QAMPARI is challenging in terms of both passage retrieval and answer generation, reaching an F1 score of 32.8 at best. Our results highlight the need for developing ODQA models that han",
    "path": "papers/22/05/2205.12665.json",
    "total_tokens": 989,
    "translated_title": "QAMPARI: 一个多段落多答案的开放域问答挑战",
    "translated_abstract": "现有的开放域问答（ODQA）基准测试通常专注于可以从单个段落中提取答案的问题。相比之下，许多自然问题，例如“布鲁克林篮网队选了哪些球员？”，都有一系列答案。回答此类问题需要在大型语料库中检索和阅读来自许多段落的内容。我们介绍了QAMPARI，一种ODQA基准测试，其中问题答案是分布在许多段落中的实体列表。我们通过（a）从维基百科的知识图谱和表中生成具有多个答案的问题，（b）自动将答案与维基百科段落中的支持证据配对，以及（c）手动改写问题并验证每个答案来创建QAMPARI。我们训练了来自检索和阅读族的ODQA模型，发现QAMPARI在段落检索和答案生成方面具有挑战性，最高达到32.8的F1分数。我们的研究结果强调了需要开发能够处理多段落多答案问题的ODQA模型。",
    "tldr": "本论文提出了一个针对多段落多答案问题的开放域问答基准测试QAMPARI，并训练了ODQA模型。研究结果表明QAMPARI在段落检索和答案生成方面具有挑战性，强调了需要发展能够处理此类问题的ODQA模型。",
    "en_tdlr": "This paper introduces an ODQA benchmark QAMPARI for questions with many answers from multiple paragraphs, and trains ODQA models. The study finds that QAMPARI is challenging in terms of passage retrieval and answer generation, highlighting the need for developing ODQA models that can handle such questions."
}