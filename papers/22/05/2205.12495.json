{
    "title": "ToKen: Task Decomposition and Knowledge Infusion for Few-Shot Hate Speech Detection. (arXiv:2205.12495v2 [cs.CL] UPDATED)",
    "abstract": "Hate speech detection is complex; it relies on commonsense reasoning, knowledge of stereotypes, and an understanding of social nuance that differs from one culture to the next. It is also difficult to collect a large-scale hate speech annotated dataset. In this work, we frame this problem as a few-shot learning task, and show significant gains with decomposing the task into its \"constituent\" parts. In addition, we see that infusing knowledge from reasoning datasets (e.g. Atomic2020) improves the performance even further. Moreover, we observe that the trained models generalize to out-of-distribution datasets, showing the superiority of task decomposition and knowledge infusion compared to previously used methods. Concretely, our method outperforms the baseline by 17.83% absolute gain in the 16-shot case.",
    "link": "http://arxiv.org/abs/2205.12495",
    "context": "Title: ToKen: Task Decomposition and Knowledge Infusion for Few-Shot Hate Speech Detection. (arXiv:2205.12495v2 [cs.CL] UPDATED)\nAbstract: Hate speech detection is complex; it relies on commonsense reasoning, knowledge of stereotypes, and an understanding of social nuance that differs from one culture to the next. It is also difficult to collect a large-scale hate speech annotated dataset. In this work, we frame this problem as a few-shot learning task, and show significant gains with decomposing the task into its \"constituent\" parts. In addition, we see that infusing knowledge from reasoning datasets (e.g. Atomic2020) improves the performance even further. Moreover, we observe that the trained models generalize to out-of-distribution datasets, showing the superiority of task decomposition and knowledge infusion compared to previously used methods. Concretely, our method outperforms the baseline by 17.83% absolute gain in the 16-shot case.",
    "path": "papers/22/05/2205.12495.json",
    "total_tokens": 863,
    "translated_title": "ToKen：少样本仇恨言论检测的任务拆解和知识注入",
    "translated_abstract": "仇恨言论检测是一个复杂的问题，它依赖于常识推理、对刻板印象的了解以及对不同文化背景下社交细微差别的理解。而且很难收集大规模的标注好的仇恨言论数据集。在本研究中，我们将这个问题视为少样本学习任务，并展示了通过将任务分解为其“构成”部分，可以取得显著的进展。此外，我们发现从推理数据集（例如Atomic2020）中注入知识可以进一步提高性能。此外，我们观察到训练模型可以泛化到分布外的数据集，显示了任务拆解和知识注入相对于先前使用的方法的优越性。具体而言，在16个样本的情况下，我们的方法在基线上表现出17.83％的绝对增益。",
    "tldr": "本研究提出了一种将仇恨言论检测任务拆分为部分并注入推理数据集知识的方法，相较于先前的方法，具有更好的泛化性能，在16个样本的情况下可达到17.83％的绝对增益。",
    "en_tdlr": "This study proposes a method of decomposing hate speech detection tasks into parts and infusing knowledge from reasoning datasets, which has better generalization performance compared to previous methods, and achieves an absolute gain of 17.83% in the 16-shot case."
}