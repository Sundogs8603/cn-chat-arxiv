{
    "title": "META-GUI: Towards Multi-modal Conversational Agents on Mobile GUI",
    "abstract": "arXiv:2205.11029v2 Announce Type: cross  Abstract: Task-oriented dialogue (TOD) systems have been widely used by mobile phone intelligent assistants to accomplish tasks such as calendar scheduling or hotel reservation. Current TOD systems usually focus on multi-turn text/speech interaction, then they would call back-end APIs designed for TODs to perform the task. However, this API-based architecture greatly limits the information-searching capability of intelligent assistants and may even lead to task failure if TOD-specific APIs are not available or the task is too complicated to be executed by the provided APIs. In this paper, we propose a new TOD architecture: GUI-based task-oriented dialogue system (GUI-TOD). A GUI-TOD system can directly perform GUI operations on real APPs and execute tasks without invoking TOD-specific backend APIs. Furthermore, we release META-GUI, a dataset for training a Multi-modal convErsaTional Agent on mobile GUI. We also propose a multi-model action predi",
    "link": "https://arxiv.org/abs/2205.11029",
    "context": "Title: META-GUI: Towards Multi-modal Conversational Agents on Mobile GUI\nAbstract: arXiv:2205.11029v2 Announce Type: cross  Abstract: Task-oriented dialogue (TOD) systems have been widely used by mobile phone intelligent assistants to accomplish tasks such as calendar scheduling or hotel reservation. Current TOD systems usually focus on multi-turn text/speech interaction, then they would call back-end APIs designed for TODs to perform the task. However, this API-based architecture greatly limits the information-searching capability of intelligent assistants and may even lead to task failure if TOD-specific APIs are not available or the task is too complicated to be executed by the provided APIs. In this paper, we propose a new TOD architecture: GUI-based task-oriented dialogue system (GUI-TOD). A GUI-TOD system can directly perform GUI operations on real APPs and execute tasks without invoking TOD-specific backend APIs. Furthermore, we release META-GUI, a dataset for training a Multi-modal convErsaTional Agent on mobile GUI. We also propose a multi-model action predi",
    "path": "papers/22/05/2205.11029.json",
    "total_tokens": 809,
    "translated_title": "META-GUI：面向移动GUI的多模态对话系统",
    "translated_abstract": "任务导向的对话（TOD）系统已被广泛应用于移动电话智能助手，用于完成诸如日历安排或酒店预订等任务。目前的TOD系统通常专注于多轮文本/语音交互，然后调用为TOD设计的后端API来执行任务。然而，这种基于API的架构极大地限制了智能助手的信息搜索能力，甚至可能导致任务失败，如果TOD特定的API不可用或任务过于复杂而无法通过提供的API执行。在本文中，我们提出了一种新的TOD架构：基于GUI的任务导向对话系统（GUI-TOD）。GUI-TOD系统可以直接在真实应用程序上执行GUI操作并执行任务，而无需调用特定于TOD的后端API。此外，我们发布了META-GUI，这是一个用于在移动GUI上训练多模态对话代理的数据集。",
    "tldr": "提出了一种基于GUI的任务导向对话系统（GUI-TOD）架构，并发布了用于在移动GUI上训练多模态对话代理的数据集META-GUI。"
}