{
    "title": "Evaluating natural language processing models with generalization metrics that do not need access to any training or testing data. (arXiv:2202.02842v3 [cs.CL] UPDATED)",
    "abstract": "Selecting suitable architecture parameters and training hyperparameters is essential for enhancing machine learning (ML) model performance. Several recent empirical studies conduct large-scale correlational analysis on neural networks (NNs) to search for effective \\emph{generalization metrics} that can guide this type of model selection. Effective metrics are typically expected to correlate strongly with test performance. In this paper, we expand on prior analyses by examining generalization-metric-based model selection with the following objectives: (i) focusing on natural language processing (NLP) tasks, as prior work primarily concentrates on computer vision (CV) tasks; (ii) considering metrics that directly predict \\emph{test error} instead of the \\emph{generalization gap}; (iii) exploring metrics that do not need access to data to compute. From these objectives, we are able to provide the first model selection results on large pretrained Transformers from Huggingface using general",
    "link": "http://arxiv.org/abs/2202.02842",
    "context": "Title: Evaluating natural language processing models with generalization metrics that do not need access to any training or testing data. (arXiv:2202.02842v3 [cs.CL] UPDATED)\nAbstract: Selecting suitable architecture parameters and training hyperparameters is essential for enhancing machine learning (ML) model performance. Several recent empirical studies conduct large-scale correlational analysis on neural networks (NNs) to search for effective \\emph{generalization metrics} that can guide this type of model selection. Effective metrics are typically expected to correlate strongly with test performance. In this paper, we expand on prior analyses by examining generalization-metric-based model selection with the following objectives: (i) focusing on natural language processing (NLP) tasks, as prior work primarily concentrates on computer vision (CV) tasks; (ii) considering metrics that directly predict \\emph{test error} instead of the \\emph{generalization gap}; (iii) exploring metrics that do not need access to data to compute. From these objectives, we are able to provide the first model selection results on large pretrained Transformers from Huggingface using general",
    "path": "papers/22/02/2202.02842.json",
    "total_tokens": 1020,
    "translated_title": "不需要访问任何训练或测试数据的泛化度量标准评估自然语言处理模型",
    "translated_abstract": "选择合适的结构参数和训练超参数对于提高机器学习（ML）模型的性能至关重要。最近的几项实证研究对神经网络（NNs）进行了大规模的相关分析，以寻找有效的泛化度量标准以指导模型选择。有效的度量标准通常预计与测试性能强相关。在本文中，我们通过以下目标扩展了先前的分析，进行了基于泛化度量标准的模型选择研究：（i）关注自然语言处理（NLP）任务，因为先前的工作主要集中于计算机视觉（CV）任务；（ii）考虑直接预测测试误差而非泛化差距的度量标准；（iii）探索不需要访问数据即可计算的度量标准。从这些目标出发，我们能够提供第一个使用泛化度量标准对来自Huggingface的大型预训练变压器进行模型选择的结果，并比较了许多不同的度量标准。结果表明，我们提出的有用度量标准不止与测试性能高度相关，而且更加简单高效。",
    "tldr": "本文提出了一种无需访问任何数据即可评估自然语言处理模型的泛化度量标准，并通过对Huggingface预训练变压器的模型选择，得到一个简单高效且相关性强的有用度量标准。"
}