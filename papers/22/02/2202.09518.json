{
    "title": "Distributed Out-of-Memory NMF on CPU/GPU Architectures. (arXiv:2202.09518v3 [cs.DC] UPDATED)",
    "abstract": "We propose an efficient distributed out-of-memory implementation of the Non-negative Matrix Factorization (NMF) algorithm for heterogeneous high-performance-computing (HPC) systems. The proposed implementation is based on prior work on NMFk, which can perform automatic model selection and extract latent variables and patterns from data. In this work, we extend NMFk by adding support for dense and sparse matrix operation on multi-node, multi-GPU systems. The resulting algorithm is optimized for out-of-memory (OOM) problems where the memory required to factorize a given matrix is greater than the available GPU memory. Memory complexity is reduced by batching/tiling strategies, and sparse and dense matrix operations are significantly accelerated with GPU cores (or tensor cores when available). Input/Output (I/O) latency associated with batch copies between host and device is hidden using CUDA streams to overlap data transfers and compute asynchronously, and latency associated with collect",
    "link": "http://arxiv.org/abs/2202.09518",
    "context": "Title: Distributed Out-of-Memory NMF on CPU/GPU Architectures. (arXiv:2202.09518v3 [cs.DC] UPDATED)\nAbstract: We propose an efficient distributed out-of-memory implementation of the Non-negative Matrix Factorization (NMF) algorithm for heterogeneous high-performance-computing (HPC) systems. The proposed implementation is based on prior work on NMFk, which can perform automatic model selection and extract latent variables and patterns from data. In this work, we extend NMFk by adding support for dense and sparse matrix operation on multi-node, multi-GPU systems. The resulting algorithm is optimized for out-of-memory (OOM) problems where the memory required to factorize a given matrix is greater than the available GPU memory. Memory complexity is reduced by batching/tiling strategies, and sparse and dense matrix operations are significantly accelerated with GPU cores (or tensor cores when available). Input/Output (I/O) latency associated with batch copies between host and device is hidden using CUDA streams to overlap data transfers and compute asynchronously, and latency associated with collect",
    "path": "papers/22/02/2202.09518.json",
    "total_tokens": 924,
    "translated_title": "分布式CPU/GPU架构上的超内存非负矩阵分解(NMF)",
    "translated_abstract": "我们提出了一种高效的分布式超内存实现的非负矩阵分解(NMF)算法，用于异构高性能计算(HPC)系统。该实现基于NMFk的先前工作，可以自动进行模型选择并从数据中提取潜在变量和模式。在本研究中，我们通过添加对多节点、多GPU系统的稠密和稀疏矩阵操作支持，扩展了NMFk。得到的算法针对超内存问题进行了优化，其中所需内存大于可用的GPU内存来进行矩阵分解。通过批处理/平铺策略降低内存复杂度，并使用GPU核心(或者可用的张量核心)显著加速稀疏和稠密矩阵操作。使用CUDA流隐藏了主机和设备之间的批处理复制的输入/输出(I/O)延迟，以实现数据传输和异步计算的重叠，以及与收集相关的延迟。",
    "tldr": "提出了一种分布式超内存非负矩阵分解(NMF)算法，可以在CPU/GPU架构上实现高效计算。算法通过稀疏和稠密矩阵操作以及批处理/平铺策略，有效地处理超内存问题，并利用CUDA流进行数据传输和异步计算。",
    "en_tdlr": "This paper presents an efficient distributed out-of-memory Non-negative Matrix Factorization (NMF) algorithm that can be implemented on CPU/GPU architectures. The algorithm handles out-of-memory problems by utilizing sparse and dense matrix operations, batching/tiling strategies, and CUDA streams for data transfer and asynchronous computation."
}