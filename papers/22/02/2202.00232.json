{
    "title": "Towards Ignoring Backgrounds and Improving Generalization: a Costless DNN Visual Attention Mechanism. (arXiv:2202.00232v6 [eess.IV] UPDATED)",
    "abstract": "This work introduces an attention mechanism for image classifiers and the corresponding deep neural network (DNN) architecture, dubbed ISNet. During training, the ISNet uses segmentation targets to learn how to find the image's region of interest and concentrate its attention on it. The proposal is based on a novel concept, background relevance minimization in LRP explanation heatmaps. It can be applied to virtually any classification neural network architecture, without any extra computational cost at run-time. Capable of ignoring the background, the resulting single DNN can substitute the common pipeline of a segmenter followed by a classifier, being faster and lighter. After injecting synthetic bias in images' backgrounds (in diverse applications), we compare the ISNet to multiple state-of-the-art neural networks, and quantitatively demonstrate its superior capacity of minimizing the bias influence over the classifier decisions. The tasks of COVID-19 and tuberculosis detection in ch",
    "link": "http://arxiv.org/abs/2202.00232",
    "context": "Title: Towards Ignoring Backgrounds and Improving Generalization: a Costless DNN Visual Attention Mechanism. (arXiv:2202.00232v6 [eess.IV] UPDATED)\nAbstract: This work introduces an attention mechanism for image classifiers and the corresponding deep neural network (DNN) architecture, dubbed ISNet. During training, the ISNet uses segmentation targets to learn how to find the image's region of interest and concentrate its attention on it. The proposal is based on a novel concept, background relevance minimization in LRP explanation heatmaps. It can be applied to virtually any classification neural network architecture, without any extra computational cost at run-time. Capable of ignoring the background, the resulting single DNN can substitute the common pipeline of a segmenter followed by a classifier, being faster and lighter. After injecting synthetic bias in images' backgrounds (in diverse applications), we compare the ISNet to multiple state-of-the-art neural networks, and quantitatively demonstrate its superior capacity of minimizing the bias influence over the classifier decisions. The tasks of COVID-19 and tuberculosis detection in ch",
    "path": "papers/22/02/2202.00232.json",
    "total_tokens": 961,
    "translated_title": "无需成本的DNN视觉注意机制：忽略背景，提高泛化",
    "translated_abstract": "本文介绍了一种用于图像分类器的注意机制，以及相应的深度神经网络（DNN）体系结构，称为ISNet。在训练期间，ISNet使用分割目标来学习如何找到图像的感兴趣区域，并将注意力集中在该区域上。该提议基于一种新颖的概念，即在LRP解释热图中最小化背景相关性。它可以应用于几乎任何分类神经网络架构，而不会在运行时增加任何额外的计算成本。由于能够忽略背景，因此结果单个DNN可以代替常见的分割器后跟分类器的流水线，速度更快，更轻。在注入图像背景的合成偏差之后（在各种应用中），我们将ISNet与多个最先进的神经网络进行比较，并定量证明其在最小化分类器决策中偏差影响方面具有优越的能力。 COVID-19和结核病检测任务分别作为使用案例来使用。",
    "tldr": "本文提出了一种无需额外计算成本的DNN视觉注意机制，名为ISNet，能够忽略图像背景并在COVID-19和结核病检测任务中比多个最先进神经网络具有更好的最小化分类器决策偏差影响的能力。",
    "en_tdlr": "This paper proposes a costless DNN visual attention mechanism, ISNet, which can ignore image backgrounds and has superior capacity of minimizing classifier decision bias influence compared with multiple state-of-the-art neural networks, demonstrated through COVID-19 and tuberculosis detection tasks."
}