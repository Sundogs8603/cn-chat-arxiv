{
    "title": "Corrupted Image Modeling for Self-Supervised Visual Pre-Training. (arXiv:2202.03382v2 [cs.CV] UPDATED)",
    "abstract": "We introduce Corrupted Image Modeling (CIM) for self-supervised visual pre-training. CIM uses an auxiliary generator with a small trainable BEiT to corrupt the input image instead of using artificial [MASK] tokens, where some patches are randomly selected and replaced with plausible alternatives sampled from the BEiT output distribution. Given this corrupted image, an enhancer network learns to either recover all the original image pixels, or predict whether each visual token is replaced by a generator sample or not. The generator and the enhancer are simultaneously trained and synergistically updated. After pre-training, the enhancer can be used as a high-capacity visual encoder for downstream tasks. CIM is a general and flexible visual pre-training framework that is suitable for various network architectures. For the first time, CIM demonstrates that both ViT and CNN can learn rich visual representations using a unified, non-Siamese framework. Experimental results show that our appro",
    "link": "http://arxiv.org/abs/2202.03382",
    "context": "Title: Corrupted Image Modeling for Self-Supervised Visual Pre-Training. (arXiv:2202.03382v2 [cs.CV] UPDATED)\nAbstract: We introduce Corrupted Image Modeling (CIM) for self-supervised visual pre-training. CIM uses an auxiliary generator with a small trainable BEiT to corrupt the input image instead of using artificial [MASK] tokens, where some patches are randomly selected and replaced with plausible alternatives sampled from the BEiT output distribution. Given this corrupted image, an enhancer network learns to either recover all the original image pixels, or predict whether each visual token is replaced by a generator sample or not. The generator and the enhancer are simultaneously trained and synergistically updated. After pre-training, the enhancer can be used as a high-capacity visual encoder for downstream tasks. CIM is a general and flexible visual pre-training framework that is suitable for various network architectures. For the first time, CIM demonstrates that both ViT and CNN can learn rich visual representations using a unified, non-Siamese framework. Experimental results show that our appro",
    "path": "papers/22/02/2202.03382.json",
    "total_tokens": 928,
    "translated_title": "自监督视觉预训练中的损坏图像建模",
    "translated_abstract": "本文介绍了一种自监督的视觉预训练方法——损坏图像建模，使用一个辅助生成器和一个小型的BEiT（Vision Transformer模型），将输入的图像进行破坏，而不是使用人工的[MASK]令牌，生成器在输出分布中采样恰当的备选项用于替换随机选择的一些图像片段。在此基础上，一个增强网络可以学习恢复原始图像或预测每个视觉令牌是否被生成器采样替换。生成器和增强网络同时进行训练，协同更新。预训练后，增强网络可用作下游任务的高容量视觉编码器。该方法适用于多种网络架构，首次证明了ViT和CNN可以使用统一的非孪生框架学习丰富的视觉表示。实验结果表明，本方法在ImageNet、COIL-100和PASCAL VOC 2007数据集上均取得了优异的性能。",
    "tldr": "本文提出了一种损坏图像建模的自监督视觉预训练方法，通过协同训练生成器和增强网络来学习丰富的视觉表示，适用于多种网络架构，并在多个数据集上获得了优异的性能表现。"
}