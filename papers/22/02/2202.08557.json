{
    "title": "CADRE: A Cascade Deep Reinforcement Learning Framework for Vision-based Autonomous Urban Driving. (arXiv:2202.08557v2 [cs.CV] UPDATED)",
    "abstract": "Vision-based autonomous urban driving in dense traffic is quite challenging due to the complicated urban environment and the dynamics of the driving behaviors. Widely-applied methods either heavily rely on hand-crafted rules or learn from limited human experience, which makes them hard to generalize to rare but critical scenarios. In this paper, we present a novel CAscade Deep REinforcement learning framework, CADRE, to achieve model-free vision-based autonomous urban driving. In CADRE, to derive representative latent features from raw observations, we first offline train a Co-attention Perception Module (CoPM) that leverages the co-attention mechanism to learn the inter-relationships between the visual and control information from a pre-collected driving dataset. Cascaded by the frozen CoPM, we then present an efficient distributed proximal policy optimization framework to online learn the driving policy under the guidance of particularly designed reward functions. We perform a compre",
    "link": "http://arxiv.org/abs/2202.08557",
    "context": "Title: CADRE: A Cascade Deep Reinforcement Learning Framework for Vision-based Autonomous Urban Driving. (arXiv:2202.08557v2 [cs.CV] UPDATED)\nAbstract: Vision-based autonomous urban driving in dense traffic is quite challenging due to the complicated urban environment and the dynamics of the driving behaviors. Widely-applied methods either heavily rely on hand-crafted rules or learn from limited human experience, which makes them hard to generalize to rare but critical scenarios. In this paper, we present a novel CAscade Deep REinforcement learning framework, CADRE, to achieve model-free vision-based autonomous urban driving. In CADRE, to derive representative latent features from raw observations, we first offline train a Co-attention Perception Module (CoPM) that leverages the co-attention mechanism to learn the inter-relationships between the visual and control information from a pre-collected driving dataset. Cascaded by the frozen CoPM, we then present an efficient distributed proximal policy optimization framework to online learn the driving policy under the guidance of particularly designed reward functions. We perform a compre",
    "path": "papers/22/02/2202.08557.json",
    "total_tokens": 849,
    "translated_title": "CADRE:基于级联深度强化学习的基于视觉的自主城市驾驶框架",
    "translated_abstract": "在复杂的城市环境和驾驶行为动态的挑战下，基于视觉的自主城市驾驶是非常困难的。现有的方法要么严重依赖于手工规则，要么学习来自于有限人类经验，这使得它们难以推广到罕见但关键的情景。在本文中，我们提出了一种新颖的级联深度强化学习框架 CADRE，以实现无模型的基于视觉的自主城市驾驶。",
    "tldr": "本论文提出了一种基于级联深度强化学习框架 CADRE，通过 CoPM 离线训练，采用联合注意机制从预收集的驾驶数据集中学习视觉和控制信息之间的相互关系，在此基础上采用特别设计的奖励函数指导下，通过高效分布式 PPO 实现在线学习驾驶策略。",
    "en_tdlr": "The paper proposes a novel cascade deep reinforcement learning framework, CADRE, for model-free vision-based autonomous urban driving. It first trains a Co-attention Perception Module (CoPM) to learn the inter-relationships between visual and control information from a pre-collected driving dataset, then uses an efficient distributed proximal policy optimization framework guided by specially designed reward functions to learn driving policy online."
}