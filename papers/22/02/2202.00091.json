{
    "title": "Query Efficient Decision Based Sparse Attacks Against Black-Box Deep Learning Models. (arXiv:2202.00091v2 [cs.LG] UPDATED)",
    "abstract": "Despite our best efforts, deep learning models remain highly vulnerable to even tiny adversarial perturbations applied to the inputs. The ability to extract information from solely the output of a machine learning model to craft adversarial perturbations to black-box models is a practical threat against real-world systems, such as autonomous cars or machine learning models exposed as a service (MLaaS). Of particular interest are sparse attacks. The realization of sparse attacks in black-box models demonstrates that machine learning models are more vulnerable than we believe. Because these attacks aim to minimize the number of perturbed pixels measured by l_0 norm-required to mislead a model by solely observing the decision (the predicted label) returned to a model query; the so-called decision-based attack setting. But, such an attack leads to an NP-hard optimization problem. We develop an evolution-based algorithm-SparseEvo-for the problem and evaluate against both convolutional deep ",
    "link": "http://arxiv.org/abs/2202.00091",
    "context": "Title: Query Efficient Decision Based Sparse Attacks Against Black-Box Deep Learning Models. (arXiv:2202.00091v2 [cs.LG] UPDATED)\nAbstract: Despite our best efforts, deep learning models remain highly vulnerable to even tiny adversarial perturbations applied to the inputs. The ability to extract information from solely the output of a machine learning model to craft adversarial perturbations to black-box models is a practical threat against real-world systems, such as autonomous cars or machine learning models exposed as a service (MLaaS). Of particular interest are sparse attacks. The realization of sparse attacks in black-box models demonstrates that machine learning models are more vulnerable than we believe. Because these attacks aim to minimize the number of perturbed pixels measured by l_0 norm-required to mislead a model by solely observing the decision (the predicted label) returned to a model query; the so-called decision-based attack setting. But, such an attack leads to an NP-hard optimization problem. We develop an evolution-based algorithm-SparseEvo-for the problem and evaluate against both convolutional deep ",
    "path": "papers/22/02/2202.00091.json",
    "total_tokens": 1222,
    "translated_title": "基于决策的稀疏攻击黑盒深度学习模型的有效查询",
    "translated_abstract": "尽管我们已经做了最大的努力，但深度学习模型仍然容易受到微小的对抗性扰动。从机器学习模型的输出中提取信息以制作黑盒模型的对抗扰动是现实世界系统（例如自动驾驶汽车或作为服务（MLaaS）公开的机器学习模型）面临的威胁。 稀疏攻击尤其受到关注。 稀疏攻击在黑盒模型中的实现表明，机器学习模型比我们想象的更容易受到攻击。这项研究提出了一种基于决策的稀疏攻击方法，通过最小化扰动的像素数量，有效地欺骗黑盒深度学习模型，而不需要了解它的内部构造。我们开发了一种基于进化算法的SparseEvo，用于解决NP难的问题。",
    "tldr": "研究提出了基于决策的稀疏攻击方法SparseEvo，通过最小化扰动的像素数量，能够有效地欺骗黑盒深度学习模型，而不需要了解它的内部构造。",
    "en_tdlr": "The study proposed a decision-based sparse attack method named SparseEvo, which can effectively deceive black-box deep learning models by minimizing the number of perturbed pixels without knowing their internal structures."
}