{
    "title": "Continuous-time stochastic gradient descent for optimizing over the stationary distribution of stochastic differential equations. (arXiv:2202.06637v2 [cs.LG] UPDATED)",
    "abstract": "We develop a new continuous-time stochastic gradient descent method for optimizing over the stationary distribution of stochastic differential equation (SDE) models. The algorithm continuously updates the SDE model's parameters using an estimate for the gradient of the stationary distribution. The gradient estimate is simultaneously updated using forward propagation of the SDE state derivatives, asymptotically converging to the direction of steepest descent. We rigorously prove convergence of the online forward propagation algorithm for linear SDE models (i.e., the multi-dimensional Ornstein-Uhlenbeck process) and present its numerical results for nonlinear examples. The proof requires analysis of the fluctuations of the parameter evolution around the direction of steepest descent. Bounds on the fluctuations are challenging to obtain due to the online nature of the algorithm (e.g., the stationary distribution will continuously change as the parameters change). We prove bounds for the s",
    "link": "http://arxiv.org/abs/2202.06637",
    "context": "Title: Continuous-time stochastic gradient descent for optimizing over the stationary distribution of stochastic differential equations. (arXiv:2202.06637v2 [cs.LG] UPDATED)\nAbstract: We develop a new continuous-time stochastic gradient descent method for optimizing over the stationary distribution of stochastic differential equation (SDE) models. The algorithm continuously updates the SDE model's parameters using an estimate for the gradient of the stationary distribution. The gradient estimate is simultaneously updated using forward propagation of the SDE state derivatives, asymptotically converging to the direction of steepest descent. We rigorously prove convergence of the online forward propagation algorithm for linear SDE models (i.e., the multi-dimensional Ornstein-Uhlenbeck process) and present its numerical results for nonlinear examples. The proof requires analysis of the fluctuations of the parameter evolution around the direction of steepest descent. Bounds on the fluctuations are challenging to obtain due to the online nature of the algorithm (e.g., the stationary distribution will continuously change as the parameters change). We prove bounds for the s",
    "path": "papers/22/02/2202.06637.json",
    "total_tokens": 932,
    "translated_title": "连续时间随机梯度下降用于优化随机微分方程的平稳分布",
    "translated_abstract": "我们开发了一种新的连续时间随机梯度下降方法，用于优化随机微分方程模型的平稳分布。算法使用平稳分布的梯度估计连续更新SDE模型的参数。梯度估计同时使用SDE状态导数的正向传播进行更新，渐近地收敛到最陡下降方向。我们严格证明了在线正向传播算法在线性SDE模型（如多维Ornstein-Uhlenbeck过程）上的收敛性，并呈现了非线性示例的数值结果。证明需要对参数演化在最陡下降方向附近的波动进行分析。由于算法的在线性质，获得波动的界限很具挑战性（例如，随着参数的变化，稳定分布将持续变化）。",
    "tldr": "我们提出了一种连续时间随机梯度下降算法用于优化随机微分方程模型的平稳分布。算法通过估计平稳分布的梯度，并使用正向传播进行连续更新参数，实现收敛至最陡下降方向。我们严格证明了在线正向传播算法在线性模型上的收敛性，并在非线性示例上进行了数值验证。",
    "en_tdlr": "We propose a continuous-time stochastic gradient descent algorithm for optimizing the stationary distribution of stochastic differential equation (SDE) models. The algorithm updates the parameters of the SDE model continuously using an estimate of the gradient of the stationary distribution and converges asymptotically to the steepest descent direction. We rigorously prove the convergence of the online forward propagation algorithm for linear SDE models and validate it numerically on nonlinear examples."
}