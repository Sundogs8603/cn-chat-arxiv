{
    "title": "OLIVE: Oblivious Federated Learning on Trusted Execution Environment against the risk of sparsification. (arXiv:2202.07165v4 [cs.LG] UPDATED)",
    "abstract": "Combining Federated Learning (FL) with a Trusted Execution Environment (TEE) is a promising approach for realizing privacy-preserving FL, which has garnered significant academic attention in recent years. Implementing the TEE on the server side enables each round of FL to proceed without exposing the client's gradient information to untrusted servers. This addresses usability gaps in existing secure aggregation schemes as well as utility gaps in differentially private FL. However, to address the issue using a TEE, the vulnerabilities of server-side TEEs need to be considered -- this has not been sufficiently investigated in the context of FL. The main technical contribution of this study is the analysis of the vulnerabilities of TEE in FL and the defense. First, we theoretically analyze the leakage of memory access patterns, revealing the risk of sparsified gradients, which are commonly used in FL to enhance communication efficiency and model accuracy. Second, we devise an inference at",
    "link": "http://arxiv.org/abs/2202.07165",
    "context": "Title: OLIVE: Oblivious Federated Learning on Trusted Execution Environment against the risk of sparsification. (arXiv:2202.07165v4 [cs.LG] UPDATED)\nAbstract: Combining Federated Learning (FL) with a Trusted Execution Environment (TEE) is a promising approach for realizing privacy-preserving FL, which has garnered significant academic attention in recent years. Implementing the TEE on the server side enables each round of FL to proceed without exposing the client's gradient information to untrusted servers. This addresses usability gaps in existing secure aggregation schemes as well as utility gaps in differentially private FL. However, to address the issue using a TEE, the vulnerabilities of server-side TEEs need to be considered -- this has not been sufficiently investigated in the context of FL. The main technical contribution of this study is the analysis of the vulnerabilities of TEE in FL and the defense. First, we theoretically analyze the leakage of memory access patterns, revealing the risk of sparsified gradients, which are commonly used in FL to enhance communication efficiency and model accuracy. Second, we devise an inference at",
    "path": "papers/22/02/2202.07165.json",
    "total_tokens": 1179,
    "translated_title": "OLIVE: 基于可信执行环境的隐私保护联邦学习防范稀疏性风险",
    "translated_abstract": "结合可信执行环境(TEE)的联邦学习(FL)是实现隐私保护FL的一种有前途的方法，近年来引起了广泛的学术关注。在服务器端实现TEE可以使每轮FL在不将客户端梯度信息暴露给不可信的服务器的情况下进行。这解决了现有安全聚合方案中存在的可用性差距以及差分隐私FL中的效用差距。然而，为了解决使用TEE的问题，需要考虑服务器端TEE的漏洞，这在FL的背景下尚未得到充分的研究。本研究的主要技术贡献是分析FL中TEE的漏洞和防御。首先，我们在理论上分析了内存访问模式的泄漏，揭示了稀疏梯度的风险，稀疏梯度通常用于增强通信效率和模型精度。其次，我们设计了一个推理攻击以保护免受稀疏化风险的影响，该攻击使用TEE中的混淆RAM引入了Oblivious Memory Access(OMA)。我们对真实数据集的实验表明，我们提出的算法OLIVE在通信效率和模型精度方面都优于最先进的安全聚合和差分隐私FL算法。",
    "tldr": "本文通过分析FL中TEE的漏洞，并在TEE中引入Oblivious Memory Access（OMA）以保护免受稀疏化风险的影响，提出了OLIVE算法，该算法在通信效率和模型精度方面优于最先进的安全聚合和差分隐私FL算法。",
    "en_tdlr": "This paper proposes OLIVE, which combines Federated Learning with a Trusted Execution Environment (TEE) to realize privacy-preserving FL. It analyzes and defends against vulnerabilities in TEEs in the context of FL, specifically addressing the risk of sparsified gradients. The paper introduces Oblivious Memory Access (OMA) using oblivious RAM in the TEE to protect against this risk and outperforms state-of-the-art secure aggregation and differentially private FL algorithms in terms of communication efficiency and model accuracy."
}