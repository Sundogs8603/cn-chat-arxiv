{
    "title": "Human Detection of Political Speech Deepfakes across Transcripts, Audio, and Video. (arXiv:2202.12883v3 [cs.HC] UPDATED)",
    "abstract": "Recent advances in technology for hyper-realistic visual effects provoke the concern that deepfake videos of political speeches will soon be visually indistinguishable from authentic video recordings. The conventional wisdom in communication theory predicts people will fall for fake news more often when the same version of a story is presented as a video versus text. We conduct 4 pre-registered randomized experiments with 2,015 participants to evaluate how accurately humans distinguish real political speeches from fabrications across base rates of misinformation, audio sources, and media modalities. We find base rates of misinformation minimally influence discernment and deepfakes with audio produced by the state-of-the-art text-to-speech algorithms are harder to discern than the same deepfakes with voice actor audio. Moreover, we find audio and visual information enables more accurate discernment than text alone: human discernment relies more on how something is said, the audio-visual",
    "link": "http://arxiv.org/abs/2202.12883",
    "context": "Title: Human Detection of Political Speech Deepfakes across Transcripts, Audio, and Video. (arXiv:2202.12883v3 [cs.HC] UPDATED)\nAbstract: Recent advances in technology for hyper-realistic visual effects provoke the concern that deepfake videos of political speeches will soon be visually indistinguishable from authentic video recordings. The conventional wisdom in communication theory predicts people will fall for fake news more often when the same version of a story is presented as a video versus text. We conduct 4 pre-registered randomized experiments with 2,015 participants to evaluate how accurately humans distinguish real political speeches from fabrications across base rates of misinformation, audio sources, and media modalities. We find base rates of misinformation minimally influence discernment and deepfakes with audio produced by the state-of-the-art text-to-speech algorithms are harder to discern than the same deepfakes with voice actor audio. Moreover, we find audio and visual information enables more accurate discernment than text alone: human discernment relies more on how something is said, the audio-visual",
    "path": "papers/22/02/2202.12883.json",
    "total_tokens": 904,
    "translated_title": "跨转录本、音频和视频的政治演讲Deepfakes的人类检测",
    "translated_abstract": "最近技术的飞速进步使得超逼真的视觉效果引发了人们对深度伪造的政治演讲视频是否很快就会与真实录像无法区分的担忧。传播理论中的常识预测，当同一个故事以视频形式和文本形式展示时，人们更容易上当受骗。我们进行了4个预先登记的随机实验，涉及2015名参与者，以评估人类在不同的错误信息基准、音频来源和媒体形式下，是否能够准确区分真实的政治演讲和伪造的演讲。我们发现错误信息的基准对辨别判断影响较小，使用最先进的文本转语音算法生成的带有音频的Deepfakes较使用声音演员音频的相同Deepfakes更难辨别。此外，我们发现音频和视觉信息比仅有文本能够更准确地进行辨别：人类的辨别更依赖于事物是如何被表达的，音频-视觉",
    "tldr": "这项研究通过实验发现，人们在判断政治演讲的真实性时，音频和视觉信息对于准确区分真实和伪造的Deepfakes更为重要，而错误信息的基准影响较小。"
}