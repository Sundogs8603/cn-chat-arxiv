{
    "title": "Preserving Privacy and Security in Federated Learning. (arXiv:2202.03402v3 [cs.LG] UPDATED)",
    "abstract": "Federated learning is known to be vulnerable to both security and privacy issues. Existing research has focused either on preventing poisoning attacks from users or on concealing the local model updates from the server, but not both. However, integrating these two lines of research remains a crucial challenge since they often conflict with one another with respect to the threat model. In this work, we develop a principle framework that offers both privacy guarantees for users and detection against poisoning attacks from them. With a new threat model that includes both an honest-but-curious server and malicious users, we first propose a secure aggregation protocol using homomorphic encryption for the server to combine local model updates in a private manner. Then, a zero-knowledge proof protocol is leveraged to shift the task of detecting attacks in the local models from the server to the users. The key observation here is that the server no longer needs access to the local models for a",
    "link": "http://arxiv.org/abs/2202.03402",
    "context": "Title: Preserving Privacy and Security in Federated Learning. (arXiv:2202.03402v3 [cs.LG] UPDATED)\nAbstract: Federated learning is known to be vulnerable to both security and privacy issues. Existing research has focused either on preventing poisoning attacks from users or on concealing the local model updates from the server, but not both. However, integrating these two lines of research remains a crucial challenge since they often conflict with one another with respect to the threat model. In this work, we develop a principle framework that offers both privacy guarantees for users and detection against poisoning attacks from them. With a new threat model that includes both an honest-but-curious server and malicious users, we first propose a secure aggregation protocol using homomorphic encryption for the server to combine local model updates in a private manner. Then, a zero-knowledge proof protocol is leveraged to shift the task of detecting attacks in the local models from the server to the users. The key observation here is that the server no longer needs access to the local models for a",
    "path": "papers/22/02/2202.03402.json",
    "total_tokens": 846,
    "translated_title": "在联合学习中保护隐私和安全",
    "translated_abstract": "联合学习已经被证实存在安全和隐私问题。现有研究要么致力于防止来自用户的攻击，要么致力于将本地模型更新对服务器进行隐藏，但并非两者兼得。然而，将这两个研究领域整合起来仍然是一个重要的挑战，因为它们在威胁模型方面常常相互冲突。在这项工作中，我们开发了一个原则性的框架，为用户提供隐私保证，并对它们的攻击进行检测。我们提出了一种安全的聚合协议，使用同态加密使服务器可以以隐私方式合并本地模型更新。然后，利用零知识证明协议，将检测攻击的任务从服务器转移到用户端。关键观察是，服务器不再需要访问本地模型以进行检测。",
    "tldr": "该论文提出了一个原则性的框架，旨在在联合学习中实现用户隐私保证和防御攻击，并采用了安全的聚合协议和零知识证明协议来解决隐私和安全问题。"
}