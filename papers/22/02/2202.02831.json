{
    "title": "Anticorrelated Noise Injection for Improved Generalization. (arXiv:2202.02831v2 [stat.ML] UPDATED)",
    "abstract": "Injecting artificial noise into gradient descent (GD) is commonly employed to improve the performance of machine learning models. Usually, uncorrelated noise is used in such perturbed gradient descent (PGD) methods. It is, however, not known if this is optimal or whether other types of noise could provide better generalization performance. In this paper, we zoom in on the problem of correlating the perturbations of consecutive PGD steps. We consider a variety of objective functions for which we find that GD with anticorrelated perturbations (\"Anti-PGD\") generalizes significantly better than GD and standard (uncorrelated) PGD. To support these experimental findings, we also derive a theoretical analysis that demonstrates that Anti-PGD moves to wider minima, while GD and PGD remain stuck in suboptimal regions or even diverge. This new connection between anticorrelated noise and generalization opens the field to novel ways to exploit noise for training machine learning models.",
    "link": "http://arxiv.org/abs/2202.02831",
    "context": "Title: Anticorrelated Noise Injection for Improved Generalization. (arXiv:2202.02831v2 [stat.ML] UPDATED)\nAbstract: Injecting artificial noise into gradient descent (GD) is commonly employed to improve the performance of machine learning models. Usually, uncorrelated noise is used in such perturbed gradient descent (PGD) methods. It is, however, not known if this is optimal or whether other types of noise could provide better generalization performance. In this paper, we zoom in on the problem of correlating the perturbations of consecutive PGD steps. We consider a variety of objective functions for which we find that GD with anticorrelated perturbations (\"Anti-PGD\") generalizes significantly better than GD and standard (uncorrelated) PGD. To support these experimental findings, we also derive a theoretical analysis that demonstrates that Anti-PGD moves to wider minima, while GD and PGD remain stuck in suboptimal regions or even diverge. This new connection between anticorrelated noise and generalization opens the field to novel ways to exploit noise for training machine learning models.",
    "path": "papers/22/02/2202.02831.json",
    "total_tokens": 968,
    "translated_title": "抗相关噪声注入用于提高泛化性能",
    "translated_abstract": "将人工噪声注入梯度下降常常被用于改善机器学习模型的性能。通常，这种扰动的梯度下降方法使用的是不相关的噪声。然而，目前尚不清楚是否使用不同类型的噪声能够提供更好的泛化性能。本文聚焦于相关的扰动。我们研究了各种目标函数，发现带有抗相关扰动的梯度下降（\"Anti-PGD\"）比传统的梯度下降和常规的（不相关的）扰动梯度下降有着更好的泛化性能。为了支持这些实验结果，我们还进行了理论分析，证明了 Anti-PGD 能够移动到更宽的最小值点，而 GD 和 PGD 会停滞在次优区域甚至发散。这一新颖的抗相关噪声与泛化性能的联系为训练机器学习模型提供了新的方法。",
    "tldr": "本文发现，在一些目标函数中，抗相关噪声的梯度下降方法比传统的梯度下降和常规扰动梯度下降有更好的泛化性能。理论分析证明了这是因为 Anti-PGD 能够移动到更宽的最小值点，而 GD 和 PGD 会停滞在次优区域甚至发散。",
    "en_tdlr": "This paper discovers that in some objective functions, gradient descent with anticorrelated perturbations (\"Anti-PGD\") has better generalization performance than traditional gradient descent and perturbed gradient descent with uncorrelated noise. The theoretical analysis demonstrates that Anti-PGD moves to wider minima, while GD and PGD remain stuck in suboptimal regions or even diverge."
}