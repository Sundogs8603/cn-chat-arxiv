{
    "title": "Quantus: An Explainable AI Toolkit for Responsible Evaluation of Neural Network Explanations and Beyond. (arXiv:2202.06861v2 [cs.LG] UPDATED)",
    "abstract": "The evaluation of explanation methods is a research topic that has not yet been explored deeply, however, since explainability is supposed to strengthen trust in artificial intelligence, it is necessary to systematically review and compare explanation methods in order to confirm their correctness. Until now, no tool with focus on XAI evaluation exists that exhaustively and speedily allows researchers to evaluate the performance of explanations of neural network predictions. To increase transparency and reproducibility in the field, we therefore built Quantus -- a comprehensive, evaluation toolkit in Python that includes a growing, well-organised collection of evaluation metrics and tutorials for evaluating explainable methods. The toolkit has been thoroughly tested and is available under an open-source license on PyPi (or on https://github.com/understandable-machine-intelligence-lab/Quantus/).",
    "link": "http://arxiv.org/abs/2202.06861",
    "context": "Title: Quantus: An Explainable AI Toolkit for Responsible Evaluation of Neural Network Explanations and Beyond. (arXiv:2202.06861v2 [cs.LG] UPDATED)\nAbstract: The evaluation of explanation methods is a research topic that has not yet been explored deeply, however, since explainability is supposed to strengthen trust in artificial intelligence, it is necessary to systematically review and compare explanation methods in order to confirm their correctness. Until now, no tool with focus on XAI evaluation exists that exhaustively and speedily allows researchers to evaluate the performance of explanations of neural network predictions. To increase transparency and reproducibility in the field, we therefore built Quantus -- a comprehensive, evaluation toolkit in Python that includes a growing, well-organised collection of evaluation metrics and tutorials for evaluating explainable methods. The toolkit has been thoroughly tested and is available under an open-source license on PyPi (or on https://github.com/understandable-machine-intelligence-lab/Quantus/).",
    "path": "papers/22/02/2202.06861.json",
    "total_tokens": 826,
    "translated_title": "Quantus: 一个可解释的AI工具包，用于负责任评估神经网络的解释和更多应用",
    "translated_abstract": "解释方法的评估是一个尚未深入探讨的研究课题，然而，由于可解释性被认为能增强人们对人工智能的信任，有必要系统地审核和比较解释方法以确认其正确性。到目前为止，还没有专注于XAI评估的工具，能够详尽迅速地让研究者评估神经网络预测解释的表现。为了增加领域内的透明度和可重复性，我们建立了Quantus，一个全面的Python评估工具包，其中包括一个不断增长的、良好组织的评估指标和解释方法评估的教程集合。该工具包经过了彻底的测试，可在PyPi下或https://github.com/understandable-machine-intelligence-lab/Quantus/上以开源许可证获得。",
    "tldr": "本文介绍了Quantus，一个可解释的AI工具包，用于详尽迅速地评估神经网络预测的解释表现，并提高领域内的透明度和可重复性。",
    "en_tdlr": "This paper presents Quantus, an explainable AI toolkit that comprehensively and speedily evaluates the explanation performance of neural network predictions, and increases transparency and reproducibility in the field."
}