{
    "title": "Metadata-Induced Contrastive Learning for Zero-Shot Multi-Label Text Classification. (arXiv:2202.05932v2 [cs.CL] CROSS LISTED)",
    "abstract": "Large-scale multi-label text classification (LMTC) aims to associate a document with its relevant labels from a large candidate set. Most existing LMTC approaches rely on massive human-annotated training data, which are often costly to obtain and suffer from a long-tailed label distribution (i.e., many labels occur only a few times in the training set). In this paper, we study LMTC under the zero-shot setting, which does not require any annotated documents with labels and only relies on label surface names and descriptions. To train a classifier that calculates the similarity score between a document and a label, we propose a novel metadata-induced contrastive learning (MICoL) method. Different from previous text-based contrastive learning techniques, MICoL exploits document metadata (e.g., authors, venues, and references of research papers), which are widely available on the Web, to derive similar document-document pairs. Experimental results on two large-scale datasets show that: (1)",
    "link": "http://arxiv.org/abs/2202.05932",
    "context": "Title: Metadata-Induced Contrastive Learning for Zero-Shot Multi-Label Text Classification. (arXiv:2202.05932v2 [cs.CL] CROSS LISTED)\nAbstract: Large-scale multi-label text classification (LMTC) aims to associate a document with its relevant labels from a large candidate set. Most existing LMTC approaches rely on massive human-annotated training data, which are often costly to obtain and suffer from a long-tailed label distribution (i.e., many labels occur only a few times in the training set). In this paper, we study LMTC under the zero-shot setting, which does not require any annotated documents with labels and only relies on label surface names and descriptions. To train a classifier that calculates the similarity score between a document and a label, we propose a novel metadata-induced contrastive learning (MICoL) method. Different from previous text-based contrastive learning techniques, MICoL exploits document metadata (e.g., authors, venues, and references of research papers), which are widely available on the Web, to derive similar document-document pairs. Experimental results on two large-scale datasets show that: (1)",
    "path": "papers/22/02/2202.05932.json",
    "total_tokens": 921,
    "translated_title": "基于元数据引导的对比学习方法用于零样本多标签文本分类",
    "translated_abstract": "大规模多标签文本分类旨在将文档与其相关标签关联起来，并从一个大的候选集中选择标签。大多数现有的大规模多标签文本分类方法依赖于大量的人工标注训练数据，这些数据往往难以获取，并且在训练集中存在长尾标签分布（即许多标签只出现几次）。本文研究零样本情况下的大规模多标签文本分类，这不需要任何带有标签的注释文档，只依赖于标签的表面名称和描述。为了训练一个计算文档与标签之间相似度得分的分类器，我们提出了一种新颖的元数据引导的对比学习（MICoL）方法。与之前基于文本的对比学习技术不同，MICoL利用了广泛可用于Web上的文档元数据（例如作者，会议，研究论文的引用）来推导出相似的文档对。在两个大规模数据集上的实验结果表明：（1）",
    "tldr": "本文研究了零样本情况下的大规模多标签文本分类，提出了一种基于元数据引导的对比学习方法（MICoL）。实验结果表明该方法在两个大规模数据集上取得了良好的效果。"
}