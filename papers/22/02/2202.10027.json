{
    "title": "Toward More Generalized Malicious URL Detection Models",
    "abstract": "This paper reveals a data bias issue that can severely affect the performance while conducting a machine learning model for malicious URL detection. We describe how such bias can be identified using interpretable machine learning techniques, and further argue that such biases naturally exist in the real world security data for training a classification model. We then propose a debiased training strategy that can be applied to most deep-learning based models to alleviate the negative effects from the biased features. The solution is based on the technique of self-supervised adversarial training to train deep neural networks learning invariant embedding from biased data. We conduct a wide range of experiments to demonstrate that the proposed strategy can lead to significantly better generalization capability for both CNN-based and RNN-based detection models.",
    "link": "https://arxiv.org/abs/2202.10027",
    "context": "Title: Toward More Generalized Malicious URL Detection Models\nAbstract: This paper reveals a data bias issue that can severely affect the performance while conducting a machine learning model for malicious URL detection. We describe how such bias can be identified using interpretable machine learning techniques, and further argue that such biases naturally exist in the real world security data for training a classification model. We then propose a debiased training strategy that can be applied to most deep-learning based models to alleviate the negative effects from the biased features. The solution is based on the technique of self-supervised adversarial training to train deep neural networks learning invariant embedding from biased data. We conduct a wide range of experiments to demonstrate that the proposed strategy can lead to significantly better generalization capability for both CNN-based and RNN-based detection models.",
    "path": "papers/22/02/2202.10027.json",
    "total_tokens": 822,
    "translated_title": "更为泛化的恶意URL检测模型的探索",
    "translated_abstract": "本文揭示了一个可能严重影响恶意URL检测机器学习模型性能的数据偏差问题。我们描述了如何使用可解释的机器学习技术来识别这种偏差，并进一步认为这样的偏差在真实世界的安全数据中自然存在，用于训练分类模型。然后，我们提出了一种能够应用于大多数基于深度学习的模型的去偏置训练策略，以减轻因特征偏差而产生的负面影响。该解决方案基于自监督对抗训练技术，用于训练深度神经网络从偏差数据中学习不变特征。我们进行了一系列实验，证明了该策略可以显著改善基于CNN和RNN的检测模型的泛化能力。",
    "tldr": "本文揭示了一个可能严重影响恶意URL检测机器学习模型性能的数据偏差问题，并提出了一种去偏置训练策略，通过自监督对抗训练技术来改善基于深度神经网络的模型的泛化能力。"
}