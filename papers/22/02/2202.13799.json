{
    "title": "One-shot Ultra-high-Resolution Generative Adversarial Network That Synthesizes 16K Images On A Single GPU. (arXiv:2202.13799v3 [cs.CV] UPDATED)",
    "abstract": "We propose a one-shot ultra-high-resolution generative adversarial network (OUR-GAN) framework that generates non-repetitive 16K (16, 384 x 8, 640) images from a single training image and is trainable on a single consumer GPU. OUR-GAN generates an initial image that is visually plausible and varied in shape at low resolution, and then gradually increases the resolution by adding detail through super-resolution. Since OUR-GAN learns from a real ultra-high-resolution (UHR) image, it can synthesize large shapes with fine details and long-range coherence, which is difficult to achieve with conventional generative models that rely on the patch distribution learned from relatively small images. OUR-GAN can synthesize high-quality 16K images with 12.5 GB of GPU memory and 4K images with only 4.29 GB as it synthesizes a UHR image part by part through seamless subregion-wise super-resolution. Additionally, OUR-GAN improves visual coherence while maintaining diversity by applying vertical positi",
    "link": "http://arxiv.org/abs/2202.13799",
    "context": "Title: One-shot Ultra-high-Resolution Generative Adversarial Network That Synthesizes 16K Images On A Single GPU. (arXiv:2202.13799v3 [cs.CV] UPDATED)\nAbstract: We propose a one-shot ultra-high-resolution generative adversarial network (OUR-GAN) framework that generates non-repetitive 16K (16, 384 x 8, 640) images from a single training image and is trainable on a single consumer GPU. OUR-GAN generates an initial image that is visually plausible and varied in shape at low resolution, and then gradually increases the resolution by adding detail through super-resolution. Since OUR-GAN learns from a real ultra-high-resolution (UHR) image, it can synthesize large shapes with fine details and long-range coherence, which is difficult to achieve with conventional generative models that rely on the patch distribution learned from relatively small images. OUR-GAN can synthesize high-quality 16K images with 12.5 GB of GPU memory and 4K images with only 4.29 GB as it synthesizes a UHR image part by part through seamless subregion-wise super-resolution. Additionally, OUR-GAN improves visual coherence while maintaining diversity by applying vertical positi",
    "path": "papers/22/02/2202.13799.json",
    "total_tokens": 1032,
    "translated_title": "用单个GPU合成16K图像的一次性超高分辨率生成对抗网络",
    "translated_abstract": "我们提出了一种一次性超高分辨率生成对抗网络（OUR-GAN）框架，能够从单个训练图像生成非重复的16K（16,384 x 8,640）图像，并可以在单个消费级GPU上进行训练。OUR-GAN在低分辨率下生成一个视觉上合理且形状各异的初始图像，然后通过超分辨率逐渐增加细节来提高分辨率。由于OUR-GAN从真实的超高分辨率（UHR）图像中学习，它可以合成具有细节和长程一致性的大型形状，而传统的依赖于从相对较小图像学习的分块分布的生成模型难以实现这一点。OUR-GAN可以使用12.5 GB的GPU内存合成高质量的16K图像，只需要4.29 GB即可合成4K图像，因为它通过无缝子区域超分辨率逐部分合成UHR图像。另外，OUR-GAN通过应用垂直位移来提高视觉一致性并保持多样性。",
    "tldr": "我们提出了一种名为OUR-GAN的一次性超高分辨率生成对抗网络，能够从单个训练图像生成非重复的16K图像。它通过逐步增加细节和超分辨率来提高图像质量，并能合成具有细节和一致性的大型形状。此外，它还通过垂直位移来提高视觉一致性和多样性。"
}