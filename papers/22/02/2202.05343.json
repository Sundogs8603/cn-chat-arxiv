{
    "title": "Towards Disentangling Information Paths with Coded ResNeXt. (arXiv:2202.05343v2 [cs.CV] UPDATED)",
    "abstract": "The conventional, widely used treatment of deep learning models as black boxes provides limited or no insights into the mechanisms that guide neural network decisions. Significant research effort has been dedicated to building interpretable models to address this issue. Most efforts either focus on the high-level features associated with the last layers, or attempt to interpret the output of a single layer. In this paper, we take a novel approach to enhance the transparency of the function of the whole network. We propose a neural network architecture for classification, in which the information that is relevant to each class flows through specific paths. These paths are designed in advance before training leveraging coding theory and without depending on the semantic similarities between classes. A key property is that each path can be used as an autonomous single-purpose model. This enables us to obtain, without any additional training and for any class, a lightweight binary classifi",
    "link": "http://arxiv.org/abs/2202.05343",
    "context": "Title: Towards Disentangling Information Paths with Coded ResNeXt. (arXiv:2202.05343v2 [cs.CV] UPDATED)\nAbstract: The conventional, widely used treatment of deep learning models as black boxes provides limited or no insights into the mechanisms that guide neural network decisions. Significant research effort has been dedicated to building interpretable models to address this issue. Most efforts either focus on the high-level features associated with the last layers, or attempt to interpret the output of a single layer. In this paper, we take a novel approach to enhance the transparency of the function of the whole network. We propose a neural network architecture for classification, in which the information that is relevant to each class flows through specific paths. These paths are designed in advance before training leveraging coding theory and without depending on the semantic similarities between classes. A key property is that each path can be used as an autonomous single-purpose model. This enables us to obtain, without any additional training and for any class, a lightweight binary classifi",
    "path": "papers/22/02/2202.05343.json",
    "total_tokens": 814,
    "translated_title": "实现通过编码ResNeXt来分离信息路径",
    "translated_abstract": "传统的深度学习模型被视为黑箱，对于指导神经网络决策的机制提供了有限或没有洞察力。为了解决这个问题，已经投入了大量的研究努力来构建可解释的模型。大多数努力要么专注于与最后几层相关的高级特征，要么尝试解释单个层的输出。在本文中，我们采用了一种新颖的方法来增强整个网络功能的透明度。我们提出了一种用于分类的神经网络架构，其中与每个类相关的信息通过特定的路径流动。这些路径在训练之前利用编码理论设计，并且不依赖于类之间的语义相似性。一个关键的特性是每个路径都可以用作自主单用途模型。这使得我们可以在任何类别上获得一个轻量级的二分类器，而无需进行任何额外的训练。",
    "tldr": "本文提出了一种新颖的方法，通过使用编码理论设计特定路径，实现了神经网络的透明度增强和分类模型的轻量级构建。"
}