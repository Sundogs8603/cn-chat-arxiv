{
    "title": "Bayes-Optimal Classifiers under Group Fairness",
    "abstract": "Machine learning algorithms are becoming integrated into more and more high-stakes decision-making processes, such as in social welfare issues. Due to the need of mitigating the potentially disparate impacts from algorithmic predictions, many approaches have been proposed in the emerging area of fair machine learning. However, the fundamental problem of characterizing Bayes-optimal classifiers under various group fairness constraints has only been investigated in some special cases. Based on the classical Neyman-Pearson argument (Neyman and Pearson, 1933; Shao, 2003) for optimal hypothesis testing, this paper provides a unified framework for deriving Bayes-optimal classifiers under group fairness. This enables us to propose a group-based thresholding method we call FairBayes, that can directly control disparity, and achieve an essentially optimal fairness-accuracy tradeoff. These advantages are supported by thorough experiments.",
    "link": "https://arxiv.org/abs/2202.09724",
    "context": "Title: Bayes-Optimal Classifiers under Group Fairness\nAbstract: Machine learning algorithms are becoming integrated into more and more high-stakes decision-making processes, such as in social welfare issues. Due to the need of mitigating the potentially disparate impacts from algorithmic predictions, many approaches have been proposed in the emerging area of fair machine learning. However, the fundamental problem of characterizing Bayes-optimal classifiers under various group fairness constraints has only been investigated in some special cases. Based on the classical Neyman-Pearson argument (Neyman and Pearson, 1933; Shao, 2003) for optimal hypothesis testing, this paper provides a unified framework for deriving Bayes-optimal classifiers under group fairness. This enables us to propose a group-based thresholding method we call FairBayes, that can directly control disparity, and achieve an essentially optimal fairness-accuracy tradeoff. These advantages are supported by thorough experiments.",
    "path": "papers/22/02/2202.09724.json",
    "total_tokens": 841,
    "translated_title": "基于组公平性的贝叶斯最优分类器",
    "translated_abstract": "机器学习算法正越来越多地融入到高风险决策过程中，例如社会福利问题。由于需要减少算法预测可能造成的不平等影响，许多公平机器学习方法已经被提出。然而，在各种组公平性约束下刻画贝叶斯最优分类器的基本问题仅在一些特殊情况下进行了研究。本文基于经典的Neyman-Pearson假设检验理论（Neyman和Pearson，1933；Shao，2003），提供了一个统一框架来推导在组公平性下的贝叶斯最优分类器。这使我们能够提出一种基于组的阈值方法，称为FairBayes，可以直接控制不公平现象，并实现基本最优的公平性-准确性权衡。这些优势通过充分的实验支持。",
    "tldr": "这篇论文提供了一个统一的框架，推导出在组公平性下的贝叶斯最优分类器，并提出了一种名为FairBayes的基于组的阈值方法，可以直接控制不公平现象，实现基本最优的公平性-准确性权衡。"
}