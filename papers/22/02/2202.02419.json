{
    "title": "Learning a Discrete Set of Optimal Allocation Rules in a Queueing System with Unknown Service Rate. (arXiv:2202.02419v2 [eess.SY] UPDATED)",
    "abstract": "Motivated by the wide range of modern applications of the Erlang-B blocking model beyond communication networks and call centers to sizing and pricing in design production systems, messaging systems, and app-based parking systems, we study admission control for such a system but with unknown arrival and service rates. In our model, at every job arrival, a dispatcher decides to assign the job to an available server or block it. Every served job yields a fixed reward for the dispatcher, but it also results in a cost per unit time of service. Our goal is to design a dispatching policy that maximizes the long-term average reward for the dispatcher based on observing only the arrival times and the state of the system at each arrival that reflects a realistic sampling of such systems. Critically, the dispatcher observes neither the service times nor departure times so that standard reinforcement learning-based approaches that use reward signals do not apply. Hence, we develop our learning-ba",
    "link": "http://arxiv.org/abs/2202.02419",
    "context": "Title: Learning a Discrete Set of Optimal Allocation Rules in a Queueing System with Unknown Service Rate. (arXiv:2202.02419v2 [eess.SY] UPDATED)\nAbstract: Motivated by the wide range of modern applications of the Erlang-B blocking model beyond communication networks and call centers to sizing and pricing in design production systems, messaging systems, and app-based parking systems, we study admission control for such a system but with unknown arrival and service rates. In our model, at every job arrival, a dispatcher decides to assign the job to an available server or block it. Every served job yields a fixed reward for the dispatcher, but it also results in a cost per unit time of service. Our goal is to design a dispatching policy that maximizes the long-term average reward for the dispatcher based on observing only the arrival times and the state of the system at each arrival that reflects a realistic sampling of such systems. Critically, the dispatcher observes neither the service times nor departure times so that standard reinforcement learning-based approaches that use reward signals do not apply. Hence, we develop our learning-ba",
    "path": "papers/22/02/2202.02419.json",
    "total_tokens": 970,
    "translated_title": "学习具有未知服务率的排队系统中一组离散的最优分配规则",
    "translated_abstract": "在广泛应用于通信网络、呼叫中心以及设计生产系统、消息系统和基于应用的停车系统等现代应用领域之外的Erlang-B阻塞模型中，考虑到到达和服务率未知的情况下对该系统的入场控制进行研究。在我们的模型中，在每个作业到达时，调度员决定将作业分配给一个可用的服务器或者阻塞它。每个已服务的作业为调度员带来了固定的回报，但也导致了每单位服务时间的成本。我们的目标是设计一种调度策略，基于仅观察到到达时间和每次到达时系统状态的情况，从而最大化调度员的长期平均回报，这反映了对这种系统的现实采样。关键是，调度员既不观察服务时间也不观察离开时间，因此不能应用使用奖励信号的标准强化学习方法。因此，我们发展了我们的学习基于...",
    "tldr": "该论文研究了在具有未知到达和服务率的排队系统中的入场控制问题。通过观察到到达时间和系统状态，我们旨在设计一种调度策略，以最大化调度员的长期平均回报。标准的强化学习方法不适用于此问题，因为调度员无法观察到服务时间和离开时间。",
    "en_tdlr": "This paper investigates admission control in a queueing system with unknown arrival and service rates. By observing arrival times and system states, we aim to design a dispatching policy that maximizes the long-term average reward for the dispatcher. Standard reinforcement learning approaches are not applicable as the dispatcher cannot observe service times and departure times."
}