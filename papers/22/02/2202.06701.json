{
    "title": "UA-FedRec: Untargeted Attack on Federated News Recommendation. (arXiv:2202.06701v2 [cs.IR] UPDATED)",
    "abstract": "News recommendation is critical for personalized news distribution. Federated news recommendation enables collaborative model learning from many clients without sharing their raw data. It is promising for privacy-preserving news recommendation. However, the security of federated news recommendation is still unclear. In this paper, we study this problem by proposing an untargeted attack called UA-FedRec. By exploiting the prior knowledge of news recommendation and federated learning, UA-FedRec can effectively degrade the model performance with a small percentage of malicious clients. First, the effectiveness of news recommendation highly depends on user modeling and news modeling. We design a news similarity perturbation method to make representations of similar news farther and those of dissimilar news closer to interrupt news modeling, and propose a user model perturbation method to make malicious user updates in opposite directions of benign updates to interrupt user modeling. Second",
    "link": "http://arxiv.org/abs/2202.06701",
    "context": "Title: UA-FedRec: Untargeted Attack on Federated News Recommendation. (arXiv:2202.06701v2 [cs.IR] UPDATED)\nAbstract: News recommendation is critical for personalized news distribution. Federated news recommendation enables collaborative model learning from many clients without sharing their raw data. It is promising for privacy-preserving news recommendation. However, the security of federated news recommendation is still unclear. In this paper, we study this problem by proposing an untargeted attack called UA-FedRec. By exploiting the prior knowledge of news recommendation and federated learning, UA-FedRec can effectively degrade the model performance with a small percentage of malicious clients. First, the effectiveness of news recommendation highly depends on user modeling and news modeling. We design a news similarity perturbation method to make representations of similar news farther and those of dissimilar news closer to interrupt news modeling, and propose a user model perturbation method to make malicious user updates in opposite directions of benign updates to interrupt user modeling. Second",
    "path": "papers/22/02/2202.06701.json",
    "total_tokens": 1166,
    "translated_title": "UA-FedRec: 面向联邦新闻推荐的非定向攻击",
    "translated_abstract": "新闻推荐对于个性化新闻传播至关重要。联邦新闻推荐可支持不共享原始数据的许多客户端的协作模型学习，有望实现隐私保护的新闻推荐。然而，联邦新闻推荐的安全性仍不清楚。本文通过提出一种称为 UA-FedRec 的非定向攻击来研究这个问题。UA-FedRec 利用新闻推荐和联邦学习的先验知识，可以通过少量恶意客户端有效降低模型性能。首先，新闻推荐的有效性高度依赖于用户模型和新闻模型。我们设计了一种新闻相似性扰动方法，使类似新闻的表示更远离那些不相似的新闻，以打断新闻建模，并提出一种用户模型扰动方法，使恶意用户更新与良性更新方向相反，以打断用户建模。其次，联邦学习容易受到各种攻击，由于新闻数据的隐私和敏感性，联邦新闻推荐的安全性尤为重要。我们使用各种攻击者场景和度量标准在一个真实的新闻推荐数据集上评估 UA-FedRec，并证明仅少量恶意客户端就可以显著降低模型性能。我们的研究结果揭示了联邦新闻推荐的安全性，并呼吁关注更安全的联邦学习系统的设计。",
    "tldr": "UA-FedRec 是一种针对联邦学习的非定向攻击，该攻击通过扰动新闻相似性和用户模型来在不共享原始数据的联邦模型学习中有效地降低模型性能。需要关注更安全的联邦学习系统的设计。",
    "en_tdlr": "UA-FedRec is an untargeted attack on federated learning that effectively degrades the model performance by perturbing news similarity and user modeling, posing a threat to privacy-preserving news recommendation. Attention should be paid to designing more secure federated learning systems."
}