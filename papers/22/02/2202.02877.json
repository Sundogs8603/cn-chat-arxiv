{
    "title": "HARFE: Hard-Ridge Random Feature Expansion. (arXiv:2202.02877v2 [stat.ML] UPDATED)",
    "abstract": "We propose a random feature model for approximating high-dimensional sparse additive functions called the hard-ridge random feature expansion method (HARFE). This method utilizes a hard-thresholding pursuit-based algorithm applied to the sparse ridge regression (SRR) problem to approximate the coefficients with respect to the random feature matrix. The SRR formulation balances between obtaining sparse models that use fewer terms in their representation and ridge-based smoothing that tend to be robust to noise and outliers. In addition, we use a random sparse connectivity pattern in the random feature matrix to match the additive function assumption. We prove that the HARFE method is guaranteed to converge with a given error bound depending on the noise and the parameters of the sparse ridge regression model. Based on numerical results on synthetic data as well as on real datasets, the HARFE approach obtains lower (or comparable) error than other state-of-the-art algorithms.",
    "link": "http://arxiv.org/abs/2202.02877",
    "context": "Title: HARFE: Hard-Ridge Random Feature Expansion. (arXiv:2202.02877v2 [stat.ML] UPDATED)\nAbstract: We propose a random feature model for approximating high-dimensional sparse additive functions called the hard-ridge random feature expansion method (HARFE). This method utilizes a hard-thresholding pursuit-based algorithm applied to the sparse ridge regression (SRR) problem to approximate the coefficients with respect to the random feature matrix. The SRR formulation balances between obtaining sparse models that use fewer terms in their representation and ridge-based smoothing that tend to be robust to noise and outliers. In addition, we use a random sparse connectivity pattern in the random feature matrix to match the additive function assumption. We prove that the HARFE method is guaranteed to converge with a given error bound depending on the noise and the parameters of the sparse ridge regression model. Based on numerical results on synthetic data as well as on real datasets, the HARFE approach obtains lower (or comparable) error than other state-of-the-art algorithms.",
    "path": "papers/22/02/2202.02877.json",
    "total_tokens": 1020,
    "translated_title": "HARFE: 硬岭随机特征扩展方法",
    "translated_abstract": "本论文针对高维稀疏可加函数，提出一种随机特征模型——硬岭随机特征扩展方法（HARFE）。该方法利用基于硬阈值追踪的算法，应用于稀疏岭回归（SRR）问题，来近似计算相对于随机特征矩阵的系数。该SRR表达式在稀疏模型选择和岭回归平滑之间取得平衡，从而有利于处理噪声和异常值。此外，为了匹配加性函数假设，我们在随机特征矩阵中采用了随机稀疏连接模式。我们证明了HARFE方法会收敛至给定误差界限，具体取决于噪声和稀疏岭回归模型参数。基于合成数据和真实数据集的数值结果表明，HARFE方法的误差低于（或与）其他最先进算法相当。",
    "tldr": "论文提出了一种适用于高维稀疏可加函数的硬岭随机特征扩展方法（HARFE）模型，它可以通过应用基于硬阈值追踪的算法来进行近似计算，同时利用稀疏岭回归（SRR）表达式来取得稀疏模型选择和岭回归平滑之间的平衡，相比其他算法，HARFE方法在合成数据和真实数据集上具有更低的误差。",
    "en_tdlr": "The paper proposes a hard-ridge random feature expansion method (HARFE) model for high-dimensional sparse additive functions. The method approximates the coefficients with respect to the random feature matrix using a hard-thresholding pursuit-based algorithm applied to the sparse ridge regression (SRR) problem. The SRR formulation balances between obtaining sparse models that use fewer terms in their representation and ridge-based smoothing that tend to be robust to noise and outliers. HARFE obtains lower (or comparable) error than other state-of-the-art algorithms based on numerical results on synthetic data as well as on real datasets."
}