{
    "title": "PolicyCleanse: Backdoor Detection and Mitigation in Reinforcement Learning. (arXiv:2202.03609v5 [cs.LG] UPDATED)",
    "abstract": "While real-world applications of reinforcement learning are becoming popular, the security and robustness of RL systems are worthy of more attention and exploration. In particular, recent works have revealed that, in a multi-agent RL environment, backdoor trigger actions can be injected into a victim agent (a.k.a. Trojan agent), which can result in a catastrophic failure as soon as it sees the backdoor trigger action. To ensure the security of RL agents against malicious backdoors, in this work, we propose the problem of Backdoor Detection in a multi-agent competitive reinforcement learning system, with the objective of detecting Trojan agents as well as the corresponding potential trigger actions, and further trying to mitigate their Trojan behavior. In order to solve this problem, we propose PolicyCleanse that is based on the property that the activated Trojan agents accumulated rewards degrade noticeably after several timesteps. Along with PolicyCleanse, we also design a machine unl",
    "link": "http://arxiv.org/abs/2202.03609",
    "context": "Title: PolicyCleanse: Backdoor Detection and Mitigation in Reinforcement Learning. (arXiv:2202.03609v5 [cs.LG] UPDATED)\nAbstract: While real-world applications of reinforcement learning are becoming popular, the security and robustness of RL systems are worthy of more attention and exploration. In particular, recent works have revealed that, in a multi-agent RL environment, backdoor trigger actions can be injected into a victim agent (a.k.a. Trojan agent), which can result in a catastrophic failure as soon as it sees the backdoor trigger action. To ensure the security of RL agents against malicious backdoors, in this work, we propose the problem of Backdoor Detection in a multi-agent competitive reinforcement learning system, with the objective of detecting Trojan agents as well as the corresponding potential trigger actions, and further trying to mitigate their Trojan behavior. In order to solve this problem, we propose PolicyCleanse that is based on the property that the activated Trojan agents accumulated rewards degrade noticeably after several timesteps. Along with PolicyCleanse, we also design a machine unl",
    "path": "papers/22/02/2202.03609.json",
    "total_tokens": 916,
    "translated_title": "PolicyCleanse：强化学习中的后门检测与缓解",
    "translated_abstract": "尽管强化学习在现实世界中的应用越来越受欢迎，但RL系统的安全性和稳健性仍值得更多关注和探索。最近的研究揭示了在多智能体强化学习环境中，可以向受害者智能体（即特洛伊智能体）注入后门触发动作，这可能导致灾难性失败。为确保RL智能体对恶意后门的安全性，本文提出了在多智能体竞争性强化学习系统中的后门检测问题，其目标是检测特洛伊智能体以及相应的潜在触发动作，并进一步尝试缓解其特洛伊行为。为解决这个问题，我们提出了基于激活的特洛伊智能体累积奖励在几个时间步之后明显下降的PolicyCleanse。除了PolicyCleanse，我们还设计了一个机器未完成的部分...",
    "tldr": "本文提出了PolicyCleanse方法，用于检测和缓解多智能体强化学习系统中的后门攻击。该方法基于激活的特洛伊智能体累积奖励的下降特性进行检测，并尝试缓解其特洛伊行为。",
    "en_tdlr": "This paper proposes the PolicyCleanse method for detecting and mitigating backdoor attacks in multi-agent reinforcement learning systems. The method utilizes the characteristic of a noticeable decrease in the accumulated rewards of activated Trojan agents for detection and attempts to mitigate their Trojan behavior."
}