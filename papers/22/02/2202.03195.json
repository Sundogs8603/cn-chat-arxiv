{
    "title": "More is Better (Mostly): On the Backdoor Attacks in Federated Graph Neural Networks. (arXiv:2202.03195v5 [cs.CR] UPDATED)",
    "abstract": "Graph Neural Networks (GNNs) are a class of deep learning-based methods for processing graph domain information. GNNs have recently become a widely used graph analysis method due to their superior ability to learn representations for complex graph data. However, due to privacy concerns and regulation restrictions, centralized GNNs can be difficult to apply to data-sensitive scenarios. Federated learning (FL) is an emerging technology developed for privacy-preserving settings when several parties need to train a shared global model collaboratively. Although several research works have applied FL to train GNNs (Federated GNNs), there is no research on their robustness to backdoor attacks.  This paper bridges this gap by conducting two types of backdoor attacks in Federated GNNs: centralized backdoor attacks (CBA) and distributed backdoor attacks (DBA). Our experiments show that the DBA attack success rate is higher than CBA in almost all evaluated cases. For CBA, the attack success rate ",
    "link": "http://arxiv.org/abs/2202.03195",
    "context": "Title: More is Better (Mostly): On the Backdoor Attacks in Federated Graph Neural Networks. (arXiv:2202.03195v5 [cs.CR] UPDATED)\nAbstract: Graph Neural Networks (GNNs) are a class of deep learning-based methods for processing graph domain information. GNNs have recently become a widely used graph analysis method due to their superior ability to learn representations for complex graph data. However, due to privacy concerns and regulation restrictions, centralized GNNs can be difficult to apply to data-sensitive scenarios. Federated learning (FL) is an emerging technology developed for privacy-preserving settings when several parties need to train a shared global model collaboratively. Although several research works have applied FL to train GNNs (Federated GNNs), there is no research on their robustness to backdoor attacks.  This paper bridges this gap by conducting two types of backdoor attacks in Federated GNNs: centralized backdoor attacks (CBA) and distributed backdoor attacks (DBA). Our experiments show that the DBA attack success rate is higher than CBA in almost all evaluated cases. For CBA, the attack success rate ",
    "path": "papers/22/02/2202.03195.json",
    "total_tokens": 921,
    "translated_title": "更多是更好的（在很多情况下）：关于联邦图神经网络中后门攻击的研究",
    "translated_abstract": "图神经网络（GNNs）是一类基于深度学习的图领域信息处理方法。由于其优越的学习复杂图数据表示的能力，GNNs最近已成为广泛使用的图分析方法。然而，由于隐私问题和监管限制，中心化的GNNs在处理与隐私有关的数据场景时可能很困难。联邦学习（FL）是一种新兴技术，用于在多个参与方需要协作训练共享全局模型的隐私保护设置中。尽管有一些研究将FL应用于训练GNNs（联邦GNNs），但没有研究它们对后门攻击的鲁棒性。本文通过在联邦GNNs中进行两种类型的后门攻击，即集中式后门攻击（CBA）和分布式后门攻击（DBA），填补了这一空白。实验结果表明，在几乎所有评估的情况下，DBA攻击成功率比CBA更高。",
    "tldr": "本文研究了联邦图神经网络中的后门攻击，填补了相关领域的研究空白，并发现在该场景下分布式后门攻击的成功率更高。",
    "en_tdlr": "This paper investigates backdoor attacks in Federated Graph Neural Networks, filling a research gap in the field, and demonstrates that distributed backdoor attacks have higher success rates in this scenario."
}