{
    "title": "Towards Best Practice of Interpreting Deep Learning Models for EEG-based Brain Computer Interfaces. (arXiv:2202.06948v3 [cs.NE] UPDATED)",
    "abstract": "As deep learning has achieved state-of-the-art performance for many tasks of EEG-based BCI, many efforts have been made in recent years trying to understand what have been learned by the models. This is commonly done by generating a heatmap indicating to which extent each pixel of the input contributes to the final classification for a trained model. Despite the wide use, it is not yet understood to which extent the obtained interpretation results can be trusted and how accurate they can reflect the model decisions. In order to fill this research gap, we conduct a study to evaluate different deep interpretation techniques quantitatively on EEG datasets. The results reveal the importance of selecting a proper interpretation technique as the initial step. In addition, we also find that the quality of the interpretation results is inconsistent for individual samples despite when a method with an overall good performance is used. Many factors, including model structure and dataset types, c",
    "link": "http://arxiv.org/abs/2202.06948",
    "context": "Title: Towards Best Practice of Interpreting Deep Learning Models for EEG-based Brain Computer Interfaces. (arXiv:2202.06948v3 [cs.NE] UPDATED)\nAbstract: As deep learning has achieved state-of-the-art performance for many tasks of EEG-based BCI, many efforts have been made in recent years trying to understand what have been learned by the models. This is commonly done by generating a heatmap indicating to which extent each pixel of the input contributes to the final classification for a trained model. Despite the wide use, it is not yet understood to which extent the obtained interpretation results can be trusted and how accurate they can reflect the model decisions. In order to fill this research gap, we conduct a study to evaluate different deep interpretation techniques quantitatively on EEG datasets. The results reveal the importance of selecting a proper interpretation technique as the initial step. In addition, we also find that the quality of the interpretation results is inconsistent for individual samples despite when a method with an overall good performance is used. Many factors, including model structure and dataset types, c",
    "path": "papers/22/02/2202.06948.json",
    "total_tokens": 904,
    "tldr": "本研究在EEG数据集上对不同的深度解释技术进行了量化评估，揭示了选择适当的解释技术的重要性，并发现解释结果质量的一致性存在问题，需谨慎使用。"
}