{
    "title": "New Projection-free Algorithms for Online Convex Optimization with Adaptive Regret Guarantees. (arXiv:2202.04721v3 [cs.LG] UPDATED)",
    "abstract": "We present new efficient \\textit{projection-free} algorithms for online convex optimization (OCO), where by projection-free we refer to algorithms that avoid computing orthogonal projections onto the feasible set, and instead relay on different and potentially much more efficient oracles. While most state-of-the-art projection-free algorithms are based on the \\textit{follow-the-leader} framework, our algorithms are fundamentally different and are based on the \\textit{online gradient descent} algorithm with a novel and efficient approach to computing so-called \\textit{infeasible projections}. As a consequence, we obtain the first projection-free algorithms which naturally yield \\textit{adaptive regret} guarantees, i.e., regret bounds that hold w.r.t. any sub-interval of the sequence. Concretely, when assuming the availability of a linear optimization oracle (LOO) for the feasible set, on a sequence of length $T$, our algorithms guarantee $O(T^{3/4})$ adaptive regret and $O(T^{3/4})$ ada",
    "link": "http://arxiv.org/abs/2202.04721",
    "context": "Title: New Projection-free Algorithms for Online Convex Optimization with Adaptive Regret Guarantees. (arXiv:2202.04721v3 [cs.LG] UPDATED)\nAbstract: We present new efficient \\textit{projection-free} algorithms for online convex optimization (OCO), where by projection-free we refer to algorithms that avoid computing orthogonal projections onto the feasible set, and instead relay on different and potentially much more efficient oracles. While most state-of-the-art projection-free algorithms are based on the \\textit{follow-the-leader} framework, our algorithms are fundamentally different and are based on the \\textit{online gradient descent} algorithm with a novel and efficient approach to computing so-called \\textit{infeasible projections}. As a consequence, we obtain the first projection-free algorithms which naturally yield \\textit{adaptive regret} guarantees, i.e., regret bounds that hold w.r.t. any sub-interval of the sequence. Concretely, when assuming the availability of a linear optimization oracle (LOO) for the feasible set, on a sequence of length $T$, our algorithms guarantee $O(T^{3/4})$ adaptive regret and $O(T^{3/4})$ ada",
    "path": "papers/22/02/2202.04721.json",
    "total_tokens": 905,
    "translated_title": "无需投影的在线凸优化算法与自适应遗憾保证",
    "translated_abstract": "本文提出了新的高效无需投影的在线凸优化算法，它们避免了计算推向可行集上的正交投影，并使用不同且可能更有效的预测。这些算法不是基于现有的跟随领导者（follow-the-leader）框架，而是基于具有新颖而有效的“不可行投影”的在线梯度下降算法。因此，我们得到了第一个能够自然地产生自适应遗憾保证（即与序列的任何子间隔相关的遗憾上限）的无需投影算法。在假设有一个线性优化预测（LOO）可供使用的情况下，对于长度为$T$的序列，我们的算法保证了$O(T^{3/4})$的自适应遗憾和$O(T^{3/4})$的定常性收敛速度。",
    "tldr": "本文提出了无需投影的新型在线凸优化算法，基于在线梯度下降算法和高效的“不可行投影”计算方法，实现了自适应遗憾保证，并达到了$O(T^{3/4})$的定常性收敛速度。",
    "en_tdlr": "This paper proposes new projection-free algorithms for online convex optimization, based on online gradient descent algorithm and efficient \"infeasible projection\" calculation method, achieving adaptive regret guarantee and steady-state convergence rate of $O(T^{3/4})$, which is the first of its kind."
}