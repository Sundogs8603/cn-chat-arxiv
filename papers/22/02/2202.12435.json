{
    "title": "Understanding Adversarial Robustness from Feature Maps of Convolutional Layers. (arXiv:2202.12435v2 [cs.CV] UPDATED)",
    "abstract": "The adversarial robustness of a neural network mainly relies on two factors: model capacity and anti-perturbation ability. In this paper, we study the anti-perturbation ability of the network from the feature maps of convolutional layers. Our theoretical analysis discovers that larger convolutional feature maps before average pooling can contribute to better resistance to perturbations, but the conclusion is not true for max pooling. It brings new inspiration to the design of robust neural networks and urges us to apply these findings to improve existing architectures. The proposed modifications are very simple and only require upsampling the inputs or slightly modifying the stride configurations of downsampling operators. We verify our approaches on several benchmark neural network architectures, including AlexNet, VGG, RestNet18, and PreActResNet18. Non-trivial improvements in terms of both natural accuracy and adversarial robustness can be achieved under various attack and defense m",
    "link": "http://arxiv.org/abs/2202.12435",
    "context": "Title: Understanding Adversarial Robustness from Feature Maps of Convolutional Layers. (arXiv:2202.12435v2 [cs.CV] UPDATED)\nAbstract: The adversarial robustness of a neural network mainly relies on two factors: model capacity and anti-perturbation ability. In this paper, we study the anti-perturbation ability of the network from the feature maps of convolutional layers. Our theoretical analysis discovers that larger convolutional feature maps before average pooling can contribute to better resistance to perturbations, but the conclusion is not true for max pooling. It brings new inspiration to the design of robust neural networks and urges us to apply these findings to improve existing architectures. The proposed modifications are very simple and only require upsampling the inputs or slightly modifying the stride configurations of downsampling operators. We verify our approaches on several benchmark neural network architectures, including AlexNet, VGG, RestNet18, and PreActResNet18. Non-trivial improvements in terms of both natural accuracy and adversarial robustness can be achieved under various attack and defense m",
    "path": "papers/22/02/2202.12435.json",
    "total_tokens": 933,
    "translated_title": "从卷积层的特征图理解对抗鲁棒性",
    "translated_abstract": "神经网络的对抗鲁棒性主要取决于两个因素：模型容量和抗扰动能力。本文从卷积层的特征图研究了网络的抗扰动能力。我们的理论分析发现，在平均池化之前较大的卷积特征图可以提高对扰动的抵抗能力，但对于最大池化并非如此。这为鲁棒神经网络的设计带来了新的启示，并促使我们将这些发现应用于改进现有架构。所提出的修改非常简单，只需要对输入进行上采样或轻微修改下采样运算符的步幅配置。我们在几个基准神经网络架构上验证了我们的方法，包括AlexNet、VGG、RestNet18和PreActResNet18。在各种攻击和防御中，都能实现自然准确度和对抗鲁棒性的非平凡的改进。",
    "tldr": "通过研究卷积层的特征图，本研究发现较大的特征图可以提高神经网络对扰动的抵抗能力，这为设计鲁棒神经网络提供了新的启示，并提出了简单的修改方法来改进现有架构。"
}