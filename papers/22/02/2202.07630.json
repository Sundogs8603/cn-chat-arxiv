{
    "title": "Delving Deeper into Cross-lingual Visual Question Answering. (arXiv:2202.07630v2 [cs.CL] UPDATED)",
    "abstract": "Visual question answering (VQA) is one of the crucial vision-and-language tasks. Yet, existing VQA research has mostly focused on the English language, due to a lack of suitable evaluation resources. Previous work on cross-lingual VQA has reported poor zero-shot transfer performance of current multilingual multimodal Transformers with large gaps to monolingual performance, without any deeper analysis. In this work, we delve deeper into the different aspects of cross-lingual VQA, aiming to understand the impact of 1) modeling methods and choices, including architecture, inductive bias, fine-tuning; 2) learning biases: including question types and modality biases in cross-lingual setups. The key results of our analysis are: 1) We show that simple modifications to the standard training setup can substantially reduce the transfer gap to monolingual English performance, yielding +10 accuracy points over existing methods. 2) We analyze cross-lingual VQA across different question types of var",
    "link": "http://arxiv.org/abs/2202.07630",
    "context": "Title: Delving Deeper into Cross-lingual Visual Question Answering. (arXiv:2202.07630v2 [cs.CL] UPDATED)\nAbstract: Visual question answering (VQA) is one of the crucial vision-and-language tasks. Yet, existing VQA research has mostly focused on the English language, due to a lack of suitable evaluation resources. Previous work on cross-lingual VQA has reported poor zero-shot transfer performance of current multilingual multimodal Transformers with large gaps to monolingual performance, without any deeper analysis. In this work, we delve deeper into the different aspects of cross-lingual VQA, aiming to understand the impact of 1) modeling methods and choices, including architecture, inductive bias, fine-tuning; 2) learning biases: including question types and modality biases in cross-lingual setups. The key results of our analysis are: 1) We show that simple modifications to the standard training setup can substantially reduce the transfer gap to monolingual English performance, yielding +10 accuracy points over existing methods. 2) We analyze cross-lingual VQA across different question types of var",
    "path": "papers/22/02/2202.07630.json",
    "total_tokens": 888,
    "translated_title": "更深入地探究跨语言视觉问答",
    "translated_abstract": "视觉问答（VQA）是关键的视觉与语言任务之一。然而，现有的VQA研究主要集中在英语上，因缺乏合适的评估资源。先前的跨语言VQA研究报道了当前多语言多模态Transformer的零样本转移性能差，与单语性能存在较大差距，但没有进行深入的分析。在本文中，我们更深入地探究了跨语言VQA的不同方面，旨在了解1）建模方法和选择，包括体系结构、归纳偏见和微调；2）学习偏差：包括跨语言设置中的问题类型和模态偏差。我们分析的主要结果是：1）我们显示出标准训练设置的简单修改可以大大减少转移到单语英语性能的差距，从现有方法中获得+10的准确度；2）我们分析了不同问题类型的跨语言VQA。",
    "tldr": "本文探究了跨语言VQA的几个方面，包括建模方法和学习偏差，发现简单修改可以减少到单语英语性能的差距，从而提高准确度。",
    "en_tdlr": "This paper delves deeper into cross-lingual visual question answering, exploring modeling methods, learning biases, and showing that simple modifications can reduce the transfer gap to monolingual English performance, resulting in improved accuracy."
}