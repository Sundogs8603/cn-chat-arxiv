{
    "title": "GLISp-r: A preference-based optimization algorithm with convergence guarantees. (arXiv:2202.01125v2 [math.OC] UPDATED)",
    "abstract": "Preference-based optimization algorithms are iterative procedures that seek the optimal calibration of a decision vector based only on comparisons between couples of different tunings. At each iteration, a human decision-maker expresses a preference between two calibrations (samples), highlighting which one, if any, is better than the other. The optimization procedure must use the observed preferences to find the tuning of the decision vector that is most preferred by the decision-maker, while also minimizing the number of comparisons. In this work, we formulate the preference-based optimization problem from a utility theory perspective. Then, we propose GLISp-r, an extension of a recent preference-based optimization procedure called GLISp. The latter uses a Radial Basis Function surrogate to describe the tastes of the decision-maker. Iteratively, GLISp proposes new samples to compare with the best calibration available by trading off exploitation of the surrogate model and exploration",
    "link": "http://arxiv.org/abs/2202.01125",
    "context": "Title: GLISp-r: A preference-based optimization algorithm with convergence guarantees. (arXiv:2202.01125v2 [math.OC] UPDATED)\nAbstract: Preference-based optimization algorithms are iterative procedures that seek the optimal calibration of a decision vector based only on comparisons between couples of different tunings. At each iteration, a human decision-maker expresses a preference between two calibrations (samples), highlighting which one, if any, is better than the other. The optimization procedure must use the observed preferences to find the tuning of the decision vector that is most preferred by the decision-maker, while also minimizing the number of comparisons. In this work, we formulate the preference-based optimization problem from a utility theory perspective. Then, we propose GLISp-r, an extension of a recent preference-based optimization procedure called GLISp. The latter uses a Radial Basis Function surrogate to describe the tastes of the decision-maker. Iteratively, GLISp proposes new samples to compare with the best calibration available by trading off exploitation of the surrogate model and exploration",
    "path": "papers/22/02/2202.01125.json",
    "total_tokens": 855,
    "translated_title": "GLISp-r：一种具有收敛保证的基于偏好的优化算法",
    "translated_abstract": "基于偏好的优化算法是一种迭代过程，仅基于不同调谐之间的比较，寻求决策向量的最优校准。在每次迭代中，人为决策者表达对两个校准（样本）之间的偏好，强调哪个校准（如果有）优于另一个。优化过程必须使用观察到的偏好来找到决策者最喜欢的决策向量调谐，同时还要最小化比较的次数。在这项工作中，我们从效用理论的角度来阐述基于偏好的优化问题。然后，我们提出了GLISp-r，这是最近一种基于偏好的优化过程GLISp的扩展。后者使用径向基函数替代模型来描述决策者的喜好。GLISp-r通过在利用代理模型开发和资源勘探之间权衡，迭代地提出新的样本与最佳校准进行比较。",
    "tldr": "GLISp-r是一种基于偏好的优化算法，通过利用代理模型和资源勘探，迭代地提出新的样本与最佳校准进行比较。"
}