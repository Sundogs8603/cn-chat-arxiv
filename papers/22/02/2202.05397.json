{
    "title": "Neural Architecture Search for Energy Efficient Always-on Audio Models. (arXiv:2202.05397v2 [eess.AS] UPDATED)",
    "abstract": "Mobile and edge computing devices for always-on classification tasks require energy-efficient neural network architectures. In this paper we present several changes to neural architecture searches (NAS) that improve the chance of success in practical situations. Our search simultaneously optimizes for network accuracy, energy efficiency and memory usage. We benchmark the performance of our search on real hardware, but since running thousands of tests with real hardware is difficult we use a random forest model to roughly predict the energy usage of a candidate network. We present a search strategy that uses both Bayesian and regularized evolutionary search with particle swarms, and employs early-stopping to reduce the computational burden. Our search, evaluated on a sound-event classification dataset based upon AudioSet, results in an order of magnitude less energy per inference and a much smaller memory footprint than our baseline MobileNetV1/V2 implementations while slightly improvin",
    "link": "http://arxiv.org/abs/2202.05397",
    "context": "Title: Neural Architecture Search for Energy Efficient Always-on Audio Models. (arXiv:2202.05397v2 [eess.AS] UPDATED)\nAbstract: Mobile and edge computing devices for always-on classification tasks require energy-efficient neural network architectures. In this paper we present several changes to neural architecture searches (NAS) that improve the chance of success in practical situations. Our search simultaneously optimizes for network accuracy, energy efficiency and memory usage. We benchmark the performance of our search on real hardware, but since running thousands of tests with real hardware is difficult we use a random forest model to roughly predict the energy usage of a candidate network. We present a search strategy that uses both Bayesian and regularized evolutionary search with particle swarms, and employs early-stopping to reduce the computational burden. Our search, evaluated on a sound-event classification dataset based upon AudioSet, results in an order of magnitude less energy per inference and a much smaller memory footprint than our baseline MobileNetV1/V2 implementations while slightly improvin",
    "path": "papers/22/02/2202.05397.json",
    "total_tokens": 908,
    "translated_title": "面向能效的始终开启音频模型的神经架构搜索",
    "translated_abstract": "始终开启的分类任务对移动和边缘计算设备需要能效高的神经网络架构。本文提出了几种神经架构搜索的改进方法，以提高在实际情况下成功的机会。我们的搜索同时优化网络准确性、能效和内存使用量。我们在真实硬件上对我们的搜索性能进行基准测试，但由于使用真实硬件运行成千上万次测试很困难，因此我们使用随机森林模型粗略预测候选网络的能源使用情况。我们提出了一种搜索策略，使用贝叶斯和正则化进化搜索粒子群，并采用提前停止减少计算负担。我们在基于AudioSet的声事件分类数据集上评估我们的搜索，结果每个推理的能量比我们的基线MobileNetV1/V2实现少一个数量级，内存占用量也小得多，同时略微提高了准确率。",
    "tldr": "本研究提出对神经架构搜索的改进，能够优化网络在能效、内存使用和准确性上的表现。评估结果表明相比基线MobileNetV1/V2，搜索出的网络每个推理能量少一个数量级且内存占用小得多，同时略微提高了准确率。",
    "en_tdlr": "This study proposes improvements to neural architecture search for optimizing network performance in terms of energy efficiency, memory usage, and accuracy. Evaluation on a sound-event classification dataset shows that the optimized network has an order of magnitude less energy per inference and a smaller memory footprint compared to baseline MobileNetV1/V2, while slightly improving accuracy."
}