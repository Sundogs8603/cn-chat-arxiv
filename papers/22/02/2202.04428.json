{
    "title": "Adapting to Mixing Time in Stochastic Optimization with Markovian Data. (arXiv:2202.04428v3 [cs.LG] UPDATED)",
    "abstract": "We consider stochastic optimization problems where data is drawn from a Markov chain. Existing methods for this setting crucially rely on knowing the mixing time of the chain, which in real-world applications is usually unknown. We propose the first optimization method that does not require the knowledge of the mixing time, yet obtains the optimal asymptotic convergence rate when applied to convex problems. We further show that our approach can be extended to: (i) finding stationary points in non-convex optimization with Markovian data, and (ii) obtaining better dependence on the mixing time in temporal difference (TD) learning; in both cases, our method is completely oblivious to the mixing time. Our method relies on a novel combination of multi-level Monte Carlo (MLMC) gradient estimation together with an adaptive learning method.",
    "link": "http://arxiv.org/abs/2202.04428",
    "context": "Title: Adapting to Mixing Time in Stochastic Optimization with Markovian Data. (arXiv:2202.04428v3 [cs.LG] UPDATED)\nAbstract: We consider stochastic optimization problems where data is drawn from a Markov chain. Existing methods for this setting crucially rely on knowing the mixing time of the chain, which in real-world applications is usually unknown. We propose the first optimization method that does not require the knowledge of the mixing time, yet obtains the optimal asymptotic convergence rate when applied to convex problems. We further show that our approach can be extended to: (i) finding stationary points in non-convex optimization with Markovian data, and (ii) obtaining better dependence on the mixing time in temporal difference (TD) learning; in both cases, our method is completely oblivious to the mixing time. Our method relies on a novel combination of multi-level Monte Carlo (MLMC) gradient estimation together with an adaptive learning method.",
    "path": "papers/22/02/2202.04428.json",
    "total_tokens": 894,
    "translated_title": "适应具有马尔可夫数据的随机优化中的混合时间",
    "translated_abstract": "我们考虑数据从马尔可夫链中提取的随机优化问题。现有的这种设置的方法关键依赖于对链的混合时间的了解，而在实际应用中通常是未知的。我们提出了一种不需要了解混合时间的最优化方法，但在应用于凸问题时可以获得最优的渐近收敛速度。我们进一步展示了我们的方法可以扩展到：(i)寻找非凸优化中的稳定点以及(ii)在时差学习中获得对混合时间更好的依赖。在这两种情况下，我们的方法对混合时间完全无视。我们的方法依赖于多层蒙特卡洛(MLMC)梯度估计与自适应学习方法的新颖组合。",
    "tldr": "本文提出了一种适用于马尔可夫数据的随机优化问题的方法，不需要对混合时间有任何了解，但在凸问题中可以获得最优收敛速度。这种方法还可以应用于非凸优化以及时差学习，并且完全无视混合时间。方法的关键是多层蒙特卡洛梯度估计与自适应学习方法的组合。",
    "en_tdlr": "This paper proposes a method for stochastic optimization problems with Markovian data that does not require knowledge of the mixing time, yet achieves optimal convergence rate in convex problems. The method can also be applied to non-convex optimization and temporal difference learning with better dependence on mixing time, and it relies on a combination of multi-level Monte Carlo gradient estimation and adaptive learning."
}