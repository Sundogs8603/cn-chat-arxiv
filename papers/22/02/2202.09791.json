{
    "title": "Contextual Semantic Embeddings for Ontology Subsumption Prediction. (arXiv:2202.09791v4 [cs.AI] UPDATED)",
    "abstract": "Automating ontology construction and curation is an important but challenging task in knowledge engineering and artificial intelligence. Prediction by machine learning techniques such as contextual semantic embedding is a promising direction, but the relevant research is still preliminary especially for expressive ontologies in Web Ontology Language (OWL). In this paper, we present a new subsumption prediction method named BERTSubs for classes of OWL ontology. It exploits the pre-trained language model BERT to compute contextual embeddings of a class, where customized templates are proposed to incorporate the class context (e.g., neighbouring classes) and the logical existential restriction. BERTSubs is able to predict multiple kinds of subsumers including named classes from the same ontology or another ontology, and existential restrictions from the same ontology. Extensive evaluation on five real-world ontologies for three different subsumption tasks has shown the effectiveness of th",
    "link": "http://arxiv.org/abs/2202.09791",
    "context": "Title: Contextual Semantic Embeddings for Ontology Subsumption Prediction. (arXiv:2202.09791v4 [cs.AI] UPDATED)\nAbstract: Automating ontology construction and curation is an important but challenging task in knowledge engineering and artificial intelligence. Prediction by machine learning techniques such as contextual semantic embedding is a promising direction, but the relevant research is still preliminary especially for expressive ontologies in Web Ontology Language (OWL). In this paper, we present a new subsumption prediction method named BERTSubs for classes of OWL ontology. It exploits the pre-trained language model BERT to compute contextual embeddings of a class, where customized templates are proposed to incorporate the class context (e.g., neighbouring classes) and the logical existential restriction. BERTSubs is able to predict multiple kinds of subsumers including named classes from the same ontology or another ontology, and existential restrictions from the same ontology. Extensive evaluation on five real-world ontologies for three different subsumption tasks has shown the effectiveness of th",
    "path": "papers/22/02/2202.09791.json",
    "total_tokens": 889,
    "translated_title": "用于本体子类预测的上下文语义嵌入",
    "translated_abstract": "自动化本体构建和维护是知识工程和人工智能中重要但具有挑战性的任务。机器学习技术（如上下文语义嵌入）进行预测是一个有前途的方向，但是相关研究尤其是针对Web本体语言（OWL）中的表达型本体仍处在初步阶段。本文提出了一种名为BERTSubs的新型子类预测方法，用于OWL本体类。它利用预训练的语言模型BERT计算类的上下文嵌入，其中提出了自定义模板来结合类的上下文（例如邻近类）和逻辑存在限制。BERTSubs可以预测多种子类，包括来自同一本体或另一个本体的命名类以及来自同一本体的存在限制。在三种不同的子类任务上对五个真实世界本体进行了广泛评估，表明了BERTSubs的有效性。",
    "tldr": "本文提出了一种名为BERTSubs的新型子类预测方法，用于OWL本体类，它可以预测包括来自同一本体或另一个本体的命名类以及来自同一本体的存在限制等多种子类。",
    "en_tdlr": "The paper presents a new subsumption prediction method named BERTSubs, which utilizes BERT to compute contextual embeddings of a class for predicting multiple kinds of subsumers including named classes from the same or another ontology, and existential restrictions from the same ontology. The method is evaluated on five real-world ontologies for three different subsumption tasks and shows effectiveness."
}