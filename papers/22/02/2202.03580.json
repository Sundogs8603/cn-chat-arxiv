{
    "title": "Convolutional Neural Networks on Graphs with Chebyshev Approximation, Revisited",
    "abstract": "arXiv:2202.03580v5 Announce Type: replace-cross  Abstract: Designing spectral convolutional networks is a challenging problem in graph learning. ChebNet, one of the early attempts, approximates the spectral graph convolutions using Chebyshev polynomials. GCN simplifies ChebNet by utilizing only the first two Chebyshev polynomials while still outperforming it on real-world datasets. GPR-GNN and BernNet demonstrate that the Monomial and Bernstein bases also outperform the Chebyshev basis in terms of learning the spectral graph convolutions. Such conclusions are counter-intuitive in the field of approximation theory, where it is established that the Chebyshev polynomial achieves the optimum convergent rate for approximating a function.   In this paper, we revisit the problem of approximating the spectral graph convolutions with Chebyshev polynomials. We show that ChebNet's inferior performance is primarily due to illegal coefficients learnt by ChebNet approximating analytic filter functio",
    "link": "https://arxiv.org/abs/2202.03580",
    "context": "Title: Convolutional Neural Networks on Graphs with Chebyshev Approximation, Revisited\nAbstract: arXiv:2202.03580v5 Announce Type: replace-cross  Abstract: Designing spectral convolutional networks is a challenging problem in graph learning. ChebNet, one of the early attempts, approximates the spectral graph convolutions using Chebyshev polynomials. GCN simplifies ChebNet by utilizing only the first two Chebyshev polynomials while still outperforming it on real-world datasets. GPR-GNN and BernNet demonstrate that the Monomial and Bernstein bases also outperform the Chebyshev basis in terms of learning the spectral graph convolutions. Such conclusions are counter-intuitive in the field of approximation theory, where it is established that the Chebyshev polynomial achieves the optimum convergent rate for approximating a function.   In this paper, we revisit the problem of approximating the spectral graph convolutions with Chebyshev polynomials. We show that ChebNet's inferior performance is primarily due to illegal coefficients learnt by ChebNet approximating analytic filter functio",
    "path": "papers/22/02/2202.03580.json",
    "total_tokens": 806,
    "translated_title": "使用切比雪夫逼近的图卷积神经网络，重新审视",
    "translated_abstract": "在图学习中，设计谱卷积网络是一个具有挑战性的问题。ChebNet是早期尝试之一，它使用切比雪夫多项式近似谱图卷积。GCN简化了ChebNet，仅利用前两个切比雪夫多项式，同时在真实世界数据集上性能优于其。GPR-GNN和BernNet表明，单项式和伯恩斯坦基也在学习谱图卷积方面优于切比雪夫基。这样的结论在逼近理论领域是反直觉的，逼近函数时切比雪夫多项式实现了最佳收敛速率。",
    "tldr": "重新审视了使用切比雪夫多项式逼近谱图卷积的问题，发现ChebNet性能较差主要是由于其学习到的非法系数近似解析滤波器函数",
    "en_tdlr": "Revisiting the problem of approximating spectral graph convolutions with Chebyshev polynomials, it is found that the inferior performance of ChebNet is primarily due to the illegal coefficients learned by ChebNet approximating analytic filter functions."
}