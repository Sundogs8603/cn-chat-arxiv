{
    "title": "Predicting the generalization gap in neural networks using topological data analysis. (arXiv:2203.12330v2 [cs.LG] UPDATED)",
    "abstract": "Understanding how neural networks generalize on unseen data is crucial for designing more robust and reliable models. In this paper, we study the generalization gap of neural networks using methods from topological data analysis. For this purpose, we compute homological persistence diagrams of weighted graphs constructed from neuron activation correlations after a training phase, aiming to capture patterns that are linked to the generalization capacity of the network. We compare the usefulness of different numerical summaries from persistence diagrams and show that a combination of some of them can accurately predict and partially explain the generalization gap without the need of a test set. Evaluation on two computer vision recognition tasks (CIFAR10 and SVHN) shows competitive generalization gap prediction when compared against state-of-the-art methods.",
    "link": "http://arxiv.org/abs/2203.12330",
    "context": "Title: Predicting the generalization gap in neural networks using topological data analysis. (arXiv:2203.12330v2 [cs.LG] UPDATED)\nAbstract: Understanding how neural networks generalize on unseen data is crucial for designing more robust and reliable models. In this paper, we study the generalization gap of neural networks using methods from topological data analysis. For this purpose, we compute homological persistence diagrams of weighted graphs constructed from neuron activation correlations after a training phase, aiming to capture patterns that are linked to the generalization capacity of the network. We compare the usefulness of different numerical summaries from persistence diagrams and show that a combination of some of them can accurately predict and partially explain the generalization gap without the need of a test set. Evaluation on two computer vision recognition tasks (CIFAR10 and SVHN) shows competitive generalization gap prediction when compared against state-of-the-art methods.",
    "path": "papers/22/03/2203.12330.json",
    "total_tokens": 854,
    "translated_title": "使用拓扑数据分析预测神经网络的泛化差距",
    "translated_abstract": "理解神经网络在未见数据上的泛化能力对于设计更健壮可靠的模型至关重要。本文利用拓扑数据分析的方法研究神经网络的泛化差距。为此，我们在训练阶段后计算神经元激活相关性构建的加权图的同调持久图，旨在捕捉与网络的泛化能力相关的模式。我们比较了持久图的不同数值汇总的有用性，并显示其中一些的组合可以准确预测和部分解释泛化差距，而无需测试集。在两个计算机视觉识别任务（CIFAR10和SVHN）上的评估结果表明，与最先进的方法相比，我们的泛化差距预测具有竞争力。",
    "tldr": "本文利用拓扑数据分析的方法研究神经网络的泛化差距，通过计算加权图的同调持久图，并比较不同数值汇总的有用性，可以准确预测和部分解释泛化差距，而无需测试集。实验结果表明，在计算机视觉识别任务上具有竞争力。"
}