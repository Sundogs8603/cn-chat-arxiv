{
    "title": "Faith-Shap: The Faithful Shapley Interaction Index. (arXiv:2203.00870v3 [cs.LG] UPDATED)",
    "abstract": "Shapley values, which were originally designed to assign attributions to individual players in coalition games, have become a commonly used approach in explainable machine learning to provide attributions to input features for black-box machine learning models. A key attraction of Shapley values is that they uniquely satisfy a very natural set of axiomatic properties. However, extending the Shapley value to assigning attributions to interactions rather than individual players, an interaction index, is non-trivial: as the natural set of axioms for the original Shapley values, extended to the context of interactions, no longer specify a unique interaction index. Many proposals thus introduce additional less ''natural'' axioms, while sacrificing the key axiom of efficiency, in order to obtain unique interaction indices. In this work, rather than introduce additional conflicting axioms, we adopt the viewpoint of Shapley values as coefficients of the most faithful linear approximation to th",
    "link": "http://arxiv.org/abs/2203.00870",
    "context": "Title: Faith-Shap: The Faithful Shapley Interaction Index. (arXiv:2203.00870v3 [cs.LG] UPDATED)\nAbstract: Shapley values, which were originally designed to assign attributions to individual players in coalition games, have become a commonly used approach in explainable machine learning to provide attributions to input features for black-box machine learning models. A key attraction of Shapley values is that they uniquely satisfy a very natural set of axiomatic properties. However, extending the Shapley value to assigning attributions to interactions rather than individual players, an interaction index, is non-trivial: as the natural set of axioms for the original Shapley values, extended to the context of interactions, no longer specify a unique interaction index. Many proposals thus introduce additional less ''natural'' axioms, while sacrificing the key axiom of efficiency, in order to obtain unique interaction indices. In this work, rather than introduce additional conflicting axioms, we adopt the viewpoint of Shapley values as coefficients of the most faithful linear approximation to th",
    "path": "papers/22/03/2203.00870.json",
    "total_tokens": 891,
    "translated_title": "Faith-Shap：忠实的Shapley交互指数",
    "translated_abstract": "Shapley值最初是为了在联盟博弈中为个体玩家分配归因而设计的，现在已成为解释性机器学习中常用的方法，可为黑盒机器学习模型的输入特征提供归因。 Shapley值的关键吸引力在于它们独特地满足一组非常自然的公理属性。然而，将Shapley值扩展到分配相互作用而非个体玩家的归因，即交互指数，是非平凡的：由于原始Shapley值扩展到交互上的自然公理集不再指定唯一的交互指数，因此许多提案引入了更少“自然”的公理，同时放弃效率这一关键公理，以获得唯一的交互指数。在这项工作中，我们不引入其他相互冲突的公理，而是采取Shapley值作为最忠实线性逼近的系数的观点。",
    "tldr": "本文介绍了一种称为Faith-Shap的方法，用于为黑盒机器学习模型中的交互提供归因，它不需要放弃效率这一关键属性，并通过将Shapley值作为最忠实线性逼近系数的方法解决了唯一性问题。",
    "en_tdlr": "This paper presents a method called Faith-Shap for providing attributions to interactions in black-box machine learning models, which avoids sacrificing efficiency and solves the uniqueness problem by using Shapley values as coefficients of the most faithful linear approximation."
}