{
    "title": "Representation Bias in Data: A Survey on Identification and Resolution Techniques. (arXiv:2203.11852v2 [cs.DB] UPDATED)",
    "abstract": "Data-driven algorithms are only as good as the data they work with, while data sets, especially social data, often fail to represent minorities adequately. Representation Bias in data can happen due to various reasons ranging from historical discrimination to selection and sampling biases in the data acquisition and preparation methods. Given that \"bias in, bias out\", one cannot expect AI-based solutions to have equitable outcomes for societal applications, without addressing issues such as representation bias. While there has been extensive study of fairness in machine learning models, including several review papers, bias in the data has been less studied. This paper reviews the literature on identifying and resolving representation bias as a feature of a data set, independent of how consumed later. The scope of this survey is bounded to structured (tabular) and unstructured (e.g., image, text, graph) data. It presents taxonomies to categorize the studied techniques based on multiple",
    "link": "http://arxiv.org/abs/2203.11852",
    "context": "Title: Representation Bias in Data: A Survey on Identification and Resolution Techniques. (arXiv:2203.11852v2 [cs.DB] UPDATED)\nAbstract: Data-driven algorithms are only as good as the data they work with, while data sets, especially social data, often fail to represent minorities adequately. Representation Bias in data can happen due to various reasons ranging from historical discrimination to selection and sampling biases in the data acquisition and preparation methods. Given that \"bias in, bias out\", one cannot expect AI-based solutions to have equitable outcomes for societal applications, without addressing issues such as representation bias. While there has been extensive study of fairness in machine learning models, including several review papers, bias in the data has been less studied. This paper reviews the literature on identifying and resolving representation bias as a feature of a data set, independent of how consumed later. The scope of this survey is bounded to structured (tabular) and unstructured (e.g., image, text, graph) data. It presents taxonomies to categorize the studied techniques based on multiple",
    "path": "papers/22/03/2203.11852.json",
    "total_tokens": 897,
    "translated_title": "数据中的表征偏差：识别和解决技术的综述",
    "translated_abstract": "数据驱动算法表现的好坏取决于其所使用的数据，而数据集尤其是社交数据经常未能足够地代表少数群体。数据中的表征偏差可能出现在不同的原因中，包括历史性的歧视和数据获取和准备方法中的选择和抽样偏差。由于“垃圾进，垃圾出”，如果不解决表征偏差等问题，人工智能解决社会问题的结果就不能公平。虽然关于机器学习模型中的公平性已经有了大量的研究，包括几篇综述文章，但数据中的偏差研究相对较少。本文将作为一种数据特征，独立于后续处理的方式，综述识别和解决表征偏差的文献。本文的范围仅限于结构化（表格）和非结构化（例如图像、文本、图形）数据。文章提出了基于多个因素的分类法，对研究的技术进行分类。",
    "tldr": "本文综述了识别和解决数据表征偏差的文献，提出基于多个因素的分类法，该偏差可能影响人工智能应用的公平性和社会影响。"
}