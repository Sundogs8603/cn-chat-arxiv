{
    "title": "Recent Advances in Vision Transformer: A Survey and Outlook of Recent Work. (arXiv:2203.01536v5 [cs.CV] UPDATED)",
    "abstract": "Vision Transformers (ViTs) are becoming more popular and dominating technique for various vision tasks, compare to Convolutional Neural Networks (CNNs). As a demanding technique in computer vision, ViTs have been successfully solved various vision problems while focusing on long-range relationships. In this paper, we begin by introducing the fundamental concepts and background of the self-attention mechanism. Next, we provide a comprehensive overview of recent top-performing ViT methods describing in terms of strength and weakness, computational cost as well as training and testing dataset. We thoroughly compare the performance of various ViT algorithms and most representative CNN methods on popular benchmark datasets. Finally, we explore some limitations with insightful observations and provide further research direction. The project page along with the collections of papers are available at https://github.com/khawar512/ViT-Survey",
    "link": "http://arxiv.org/abs/2203.01536",
    "context": "Title: Recent Advances in Vision Transformer: A Survey and Outlook of Recent Work. (arXiv:2203.01536v5 [cs.CV] UPDATED)\nAbstract: Vision Transformers (ViTs) are becoming more popular and dominating technique for various vision tasks, compare to Convolutional Neural Networks (CNNs). As a demanding technique in computer vision, ViTs have been successfully solved various vision problems while focusing on long-range relationships. In this paper, we begin by introducing the fundamental concepts and background of the self-attention mechanism. Next, we provide a comprehensive overview of recent top-performing ViT methods describing in terms of strength and weakness, computational cost as well as training and testing dataset. We thoroughly compare the performance of various ViT algorithms and most representative CNN methods on popular benchmark datasets. Finally, we explore some limitations with insightful observations and provide further research direction. The project page along with the collections of papers are available at https://github.com/khawar512/ViT-Survey",
    "path": "papers/22/03/2203.01536.json",
    "total_tokens": 869,
    "translated_title": "近期视觉Transformer研究进展：综述和最新工作展望",
    "translated_abstract": "视觉Transformer（ViTs）相对于卷积神经网络（CNNs）在各种视觉任务中变得越来越受欢迎和主导。作为计算机视觉中一项需求量大的技术，ViTs成功地解决了许多关注长距离关系的视觉问题。本文首先介绍自注意力机制的基本概念和背景，接着全面概述了近期最佳表现ViT方法的优势和劣势、计算成本以及训练和测试数据集。我们全面比较了各种ViT算法和最具代表性的CNN方法在流行的基准数据集上的性能。最后，我们探讨了一些局限性并提出了深入研究方向。项目页面以及论文集合可在https://github.com/khawar512/ViT-Survey找到。",
    "tldr": "本综述回顾了近期视觉Transformer（ViT）的研究进展，包括自注意力机制的基本概念和背景、近期最佳表现的ViT方法的优势和劣势、以及与传统CNN方法的性能比较。未来的研究方向还需要进一步探索。",
    "en_tdlr": "This survey reviews the recent advances in Vision Transformers (ViTs), covering the fundamental concepts and background of self-attention mechanism, strengths and weaknesses of top-performing ViT methods, and performance comparison with conventional CNN methods. The future research direction in this field is also discussed."
}