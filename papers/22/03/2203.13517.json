{
    "title": "Sparse Federated Learning with Hierarchical Personalized Models. (arXiv:2203.13517v3 [cs.LG] UPDATED)",
    "abstract": "Federated learning (FL) can achieve privacy-safe and reliable collaborative training without collecting users' private data. Its excellent privacy security potential promotes a wide range of FL applications in Internet-of-Things (IoT), wireless networks, mobile devices, autonomous vehicles, and cloud medical treatment. However, the FL method suffers from poor model performance on non-i.i.d. data and excessive traffic volume. To this end, we propose a personalized FL algorithm using a hierarchical proximal mapping based on the moreau envelop, named sparse federated learning with hierarchical personalized models (sFedHP), which significantly improves the global model performance facing diverse data. A continuously differentiable approximated L1-norm is also used as the sparse constraint to reduce the communication cost. Convergence analysis shows that sFedHP's convergence rate is state-of-the-art with linear speedup and the sparse constraint only reduces the convergence rate to a small e",
    "link": "http://arxiv.org/abs/2203.13517",
    "context": "Title: Sparse Federated Learning with Hierarchical Personalized Models. (arXiv:2203.13517v3 [cs.LG] UPDATED)\nAbstract: Federated learning (FL) can achieve privacy-safe and reliable collaborative training without collecting users' private data. Its excellent privacy security potential promotes a wide range of FL applications in Internet-of-Things (IoT), wireless networks, mobile devices, autonomous vehicles, and cloud medical treatment. However, the FL method suffers from poor model performance on non-i.i.d. data and excessive traffic volume. To this end, we propose a personalized FL algorithm using a hierarchical proximal mapping based on the moreau envelop, named sparse federated learning with hierarchical personalized models (sFedHP), which significantly improves the global model performance facing diverse data. A continuously differentiable approximated L1-norm is also used as the sparse constraint to reduce the communication cost. Convergence analysis shows that sFedHP's convergence rate is state-of-the-art with linear speedup and the sparse constraint only reduces the convergence rate to a small e",
    "path": "papers/22/03/2203.13517.json",
    "total_tokens": 957,
    "translated_title": "带有层次化个性化模型的稀疏联邦学习",
    "translated_abstract": "联邦学习（FL）可以在不收集用户私人数据的情况下实现隐私安全和可靠的协作训练。其出色的隐私安全潜力促进了FL在物联网（IoT）、无线网络、移动设备、自动驾驶汽车和云医疗治疗等领域的广泛应用。然而，FL方法在非i.i.d.数据上的模型性能较差且通信流量过大。为此，我们提出了一种使用基于Moreau包络的分层近似映射的个性化FL算法，命名为带有层次化个性化模型的稀疏联邦学习（sFedHP），它显著改善了面对多样数据的全局模型性能。连续可微的近似L1范数也被用作稀疏约束以减少通信成本。收敛性分析表明，sFedHP具有最先进的线性加速性能，而稀疏约束只会将收敛速度降低到一个较小的值。",
    "tldr": "本研究提出了一种称为sFedHP的带有层次化个性化模型的稀疏联邦学习算法，通过使用基于Moreau包络的分层近似映射和连续可微的近似L1范数作为稀疏约束，显著提高了面对多样数据的全局模型性能。"
}