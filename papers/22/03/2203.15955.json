{
    "title": "Investigating the Properties of Neural Network Representations in Reinforcement Learning. (arXiv:2203.15955v3 [cs.LG] UPDATED)",
    "abstract": "In this paper we investigate the properties of representations learned by deep reinforcement learning systems. Much of the early work on representations for reinforcement learning focused on designing fixed-basis architectures to achieve properties thought to be desirable, such as orthogonality and sparsity. In contrast, the idea behind deep reinforcement learning methods is that the agent designer should not encode representational properties, but rather that the data stream should determine the properties of the representation -- good representations emerge under appropriate training schemes. In this paper we bring these two perspectives together, empirically investigating the properties of representations that support transfer in reinforcement learning. We introduce and measure six representational properties over more than 25 thousand agent-task settings. We consider Deep Q-learning agents with different auxiliary losses in a pixel-based navigation environment, with source and tran",
    "link": "http://arxiv.org/abs/2203.15955",
    "context": "Title: Investigating the Properties of Neural Network Representations in Reinforcement Learning. (arXiv:2203.15955v3 [cs.LG] UPDATED)\nAbstract: In this paper we investigate the properties of representations learned by deep reinforcement learning systems. Much of the early work on representations for reinforcement learning focused on designing fixed-basis architectures to achieve properties thought to be desirable, such as orthogonality and sparsity. In contrast, the idea behind deep reinforcement learning methods is that the agent designer should not encode representational properties, but rather that the data stream should determine the properties of the representation -- good representations emerge under appropriate training schemes. In this paper we bring these two perspectives together, empirically investigating the properties of representations that support transfer in reinforcement learning. We introduce and measure six representational properties over more than 25 thousand agent-task settings. We consider Deep Q-learning agents with different auxiliary losses in a pixel-based navigation environment, with source and tran",
    "path": "papers/22/03/2203.15955.json",
    "total_tokens": 865,
    "translated_title": "探究强化学习中神经网络表示的特征",
    "translated_abstract": "本文研究了深度强化学习系统学习到的表示特征。在强化学习表示方面的早期工作主要集中在设计固定基础架构上，以达到理想的特征，如正交性和稀疏性。相比之下，深度强化学习方法的理念是代理设计者不应编码表示特征，而应该让数据流决定表示的特征——在适当的训练方案下，良好的表示会显现出来。本文将这两个视角结合起来，通过对超过25,000个代理任务设置的实证研究，探究支持强化学习中迁移性的表示特征。我们引入并测量了六个表征特征。我们在一个基于像素的导航环境中考虑了具有不同辅助损失的深度Q学习代理，包括源和传输。",
    "tldr": "本文探究了深度强化学习系统学习到的表示特征及其对迁移学习的支持能力，并在一个像素导航环境中考虑了具有不同辅助损失的深度Q学习代理。"
}