{
    "title": "Distributed Task Management in Fog Computing: A Socially Concave Bandit Game. (arXiv:2203.14572v2 [cs.MA] UPDATED)",
    "abstract": "Fog computing leverages the task offloading capabilities at the network's edge to improve efficiency and enable swift responses to application demands. However, the design of task allocation strategies in a fog computing network is still challenging because of the heterogeneity of fog nodes and uncertainties in system dynamics. We formulate the distributed task allocation problem as a social-concave game with bandit feedback and show that the game has a unique Nash equilibrium, which is implementable using no-regret learning strategies (regret with sublinear growth). We then develop two no-regret online decision-making strategies. One strategy, namely bandit gradient ascent with momentum, is an online convex optimization algorithm with bandit feedback. The other strategy, Lipschitz bandit with initialization, is an EXP3 multi-armed bandit algorithm. We establish regret bounds for both strategies and analyze their convergence characteristics. Moreover, we compare the proposed strategies",
    "link": "http://arxiv.org/abs/2203.14572",
    "context": "Title: Distributed Task Management in Fog Computing: A Socially Concave Bandit Game. (arXiv:2203.14572v2 [cs.MA] UPDATED)\nAbstract: Fog computing leverages the task offloading capabilities at the network's edge to improve efficiency and enable swift responses to application demands. However, the design of task allocation strategies in a fog computing network is still challenging because of the heterogeneity of fog nodes and uncertainties in system dynamics. We formulate the distributed task allocation problem as a social-concave game with bandit feedback and show that the game has a unique Nash equilibrium, which is implementable using no-regret learning strategies (regret with sublinear growth). We then develop two no-regret online decision-making strategies. One strategy, namely bandit gradient ascent with momentum, is an online convex optimization algorithm with bandit feedback. The other strategy, Lipschitz bandit with initialization, is an EXP3 multi-armed bandit algorithm. We establish regret bounds for both strategies and analyze their convergence characteristics. Moreover, we compare the proposed strategies",
    "path": "papers/22/03/2203.14572.json",
    "total_tokens": 908,
    "translated_title": "雾计算中的分布式任务管理：一个社交凹凸赌博博弈",
    "translated_abstract": "雾计算利用网络边缘的任务卸载功能提高效率并快速响应应用需求。然而，由于雾节点的异构性和系统动态的不确定性，雾计算网络中任务分配策略的设计仍具有挑战性。我们将分布式任务分配问题形式化为具有赌博反馈的社交凹凸博弈，并证明该博弈具有唯一的纳什均衡点，可以使用无悔学习策略（对数减小的遗憾）来实现。我们开发了两种无悔的在线决策策略。一种策略是具有动量的赌博梯度上升，是具有赌博反馈的在线凸优化算法。另一种策略是利普希茨赌徒有初始化算法，是EXP3多臂赌博算法。我们建立了两种策略的遗憾界，并分析了它们的收敛特性。此外，我们比较了所提出的策略。",
    "tldr": "本论文提出了两种无悔在线决策策略，适用于雾计算网络中任务分配的设计。该博弈具有唯一的纳什均衡点，可以使用无悔学习策略来实现。",
    "en_tdlr": "This paper proposes two no-regret online decision-making strategies for task allocation in fog computing networks. The game has a unique Nash equilibrium, which can be implemented using no-regret learning strategies."
}