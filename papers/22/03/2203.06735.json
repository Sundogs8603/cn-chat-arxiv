{
    "title": "Private Non-Convex Federated Learning Without a Trusted Server. (arXiv:2203.06735v3 [cs.LG] UPDATED)",
    "abstract": "We study federated learning (FL) -- especially cross-silo FL -- with non-convex loss functions and data from people who do not trust the server or other silos. In this setting, each silo (e.g. hospital) must protect the privacy of each person's data (e.g. patient's medical record), even if the server or other silos act as adversarial eavesdroppers. To that end, we consider inter-silo record-level (ISRL) differential privacy (DP), which requires silo~$i$'s communications to satisfy record/item-level DP. We propose novel ISRL-DP algorithms for FL with heterogeneous (non-i.i.d.) silo data and two classes of Lipschitz continuous loss functions: First, we consider losses satisfying the Proximal Polyak-Lojasiewicz (PL) inequality, which is an extension of the classical PL condition to the constrained setting. In contrast to our result, prior works only considered unconstrained private optimization with Lipschitz PL loss, which rules out most interesting PL losses such as strongly convex prob",
    "link": "http://arxiv.org/abs/2203.06735",
    "context": "Title: Private Non-Convex Federated Learning Without a Trusted Server. (arXiv:2203.06735v3 [cs.LG] UPDATED)\nAbstract: We study federated learning (FL) -- especially cross-silo FL -- with non-convex loss functions and data from people who do not trust the server or other silos. In this setting, each silo (e.g. hospital) must protect the privacy of each person's data (e.g. patient's medical record), even if the server or other silos act as adversarial eavesdroppers. To that end, we consider inter-silo record-level (ISRL) differential privacy (DP), which requires silo~$i$'s communications to satisfy record/item-level DP. We propose novel ISRL-DP algorithms for FL with heterogeneous (non-i.i.d.) silo data and two classes of Lipschitz continuous loss functions: First, we consider losses satisfying the Proximal Polyak-Lojasiewicz (PL) inequality, which is an extension of the classical PL condition to the constrained setting. In contrast to our result, prior works only considered unconstrained private optimization with Lipschitz PL loss, which rules out most interesting PL losses such as strongly convex prob",
    "path": "papers/22/03/2203.06735.json",
    "total_tokens": 780,
    "translated_title": "无需可信任服务器的私有非凸联邦学习",
    "translated_abstract": "本文研究了在医院等多个数据中心间进行非凸损失函数的联邦学习，需要保证每个数据点的隐私，同时在没有可信赖的服务器的情况下进行计算。我们提出了一种互中心隐私保护方法，并使用它来解决异构数据和多种损失函数的问题。其中，我们研究了满足PPL条件的损失函数和强凸损失函数的情况。",
    "tldr": "本文提出了一种用于非凸联邦学习的新型互中心隐私保护方法，并考虑了多种复杂的损失函数，包括满足PPL条件的损失函数和强凸损失函数。",
    "en_tdlr": "This paper proposes a novel inter-silo privacy preserving approach for non-convex federated learning, which considers various complex loss functions including those satisfying the PPL inequality and strongly convex ones, while ensuring the privacy of each data point in cross-silo FL without relying on a trusted server."
}