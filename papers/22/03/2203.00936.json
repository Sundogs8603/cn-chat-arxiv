{
    "title": "Continual Learning of Multi-modal Dynamics with External Memory. (arXiv:2203.00936v3 [cs.LG] UPDATED)",
    "abstract": "We study the problem of fitting a model to a dynamical environment when new modes of behavior emerge sequentially. The learning model is aware when a new mode appears, but it does not have access to the true modes of individual training sequences. The state-of-the-art continual learning approaches cannot handle this setup, because parameter transfer suffers from catastrophic interference and episodic memory design requires the knowledge of the ground-truth modes of sequences. We devise a novel continual learning method that overcomes both limitations by maintaining a descriptor of the mode of an encountered sequence in a neural episodic memory. We employ a Dirichlet Process prior on the attention weights of the memory to foster efficient storage of the mode descriptors. Our method performs continual learning by transferring knowledge across tasks by retrieving the descriptors of similar modes of past tasks to the mode of a current sequence and feeding this descriptor into its transitio",
    "link": "http://arxiv.org/abs/2203.00936",
    "context": "Title: Continual Learning of Multi-modal Dynamics with External Memory. (arXiv:2203.00936v3 [cs.LG] UPDATED)\nAbstract: We study the problem of fitting a model to a dynamical environment when new modes of behavior emerge sequentially. The learning model is aware when a new mode appears, but it does not have access to the true modes of individual training sequences. The state-of-the-art continual learning approaches cannot handle this setup, because parameter transfer suffers from catastrophic interference and episodic memory design requires the knowledge of the ground-truth modes of sequences. We devise a novel continual learning method that overcomes both limitations by maintaining a descriptor of the mode of an encountered sequence in a neural episodic memory. We employ a Dirichlet Process prior on the attention weights of the memory to foster efficient storage of the mode descriptors. Our method performs continual learning by transferring knowledge across tasks by retrieving the descriptors of similar modes of past tasks to the mode of a current sequence and feeding this descriptor into its transitio",
    "path": "papers/22/03/2203.00936.json",
    "total_tokens": 838,
    "translated_title": "带外部记忆的多模态动态连续学习",
    "translated_abstract": "本文研究了在新的行为模式连续出现时，如何将模型拟合到动态环境中。学习模型能够意识到新的模式出现，但它没有访问单个训练序列的真实模式的信息。目前的连续学习方法无法处理这种情况，因为参数传递受到灾难性干扰的影响，而情节记忆设计需要知道序列的真实模式。我们设计了一种新的连续学习方法，通过在神经情节记忆中维护遇到的序列模式的描述符来克服这两个限制。我们在记忆的注意权重上使用Dirichlet过程先验，以促进模式描述符的有效存储。通过检索先前任务相似模式的描述符，并将此描述符馈入其转移中，我们的方法通过在任务之间传递知识来执行连续学习。",
    "tldr": "本文提出了一种新的连续学习方法，通过在记忆中维护遇到序列模式的描述符来实现，能够有效处理新的行为模式的连续出现。",
    "en_tdlr": "This paper proposes a novel continual learning method that maintains a descriptor of encountered sequence mode in memory and uses a Dirichlet Process prior on the attention weights to overcome the limitations of existing approaches in handling sequential emergence of new behavior modes."
}