{
    "title": "Recent Advances in Neural Text Generation: A Task-Agnostic Survey. (arXiv:2203.03047v3 [cs.CL] UPDATED)",
    "abstract": "In recent years, considerable research has been dedicated to the application of neural models in the field of natural language generation (NLG). The primary objective is to generate text that is both linguistically natural and human-like, while also exerting control over the generation process. This paper offers a comprehensive and task-agnostic survey of the recent advancements in neural text generation. These advancements have been facilitated through a multitude of developments, which we categorize into four key areas: data construction, neural frameworks, training and inference strategies, and evaluation metrics. By examining these different aspects, we aim to provide a holistic overview of the progress made in the field. Furthermore, we explore the future directions for the advancement of neural text generation, which encompass the utilization of neural pipelines and the incorporation of background knowledge. These avenues present promising opportunities to further enhance the cap",
    "link": "http://arxiv.org/abs/2203.03047",
    "context": "Title: Recent Advances in Neural Text Generation: A Task-Agnostic Survey. (arXiv:2203.03047v3 [cs.CL] UPDATED)\nAbstract: In recent years, considerable research has been dedicated to the application of neural models in the field of natural language generation (NLG). The primary objective is to generate text that is both linguistically natural and human-like, while also exerting control over the generation process. This paper offers a comprehensive and task-agnostic survey of the recent advancements in neural text generation. These advancements have been facilitated through a multitude of developments, which we categorize into four key areas: data construction, neural frameworks, training and inference strategies, and evaluation metrics. By examining these different aspects, we aim to provide a holistic overview of the progress made in the field. Furthermore, we explore the future directions for the advancement of neural text generation, which encompass the utilization of neural pipelines and the incorporation of background knowledge. These avenues present promising opportunities to further enhance the cap",
    "path": "papers/22/03/2203.03047.json",
    "total_tokens": 890,
    "translated_title": "神经文本生成的最新进展：一项任务无关的调查",
    "translated_abstract": "近年来，相当多的研究致力于在自然语言生成（NLG）领域中应用神经模型。主要目标是生成既具有语言自然性又具有人类化属性的文本，并同时对生成过程进行控制。本文提供了一份全面的，任务无关的神经文本生成最新进展调查。这些进展通过多种发展得以实现，我们将其分为四个主要方面：数据构建，神经框架，训练和推理策略和评估指标。通过研究这些不同方面，我们旨在提供对该领域的进展的全面概述。此外，我们探讨了神经文本生成的未来方向，这些方向包括利用神经管道和融合背景知识，这些途径为进一步增强神经文本生成系统的能力提供了有希望的机会。",
    "tldr": "本文调查了最近神经文本生成领域的最新进展，包括数据构建、神经框架、训练和推理策略和评估指标等四个方面，并探讨了神经管道和背景知识的利用等未来方向。",
    "en_tdlr": "This paper offers a comprehensive survey on recent advancements in neural text generation, covering four key areas: data construction, neural frameworks, training and inference strategies, and evaluation metrics. The future directions for further enhancing the capabilities of neural text generation systems, such as utilizing neural pipelines and incorporating background knowledge, are also explored."
}