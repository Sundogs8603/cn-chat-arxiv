{
    "title": "Distributionally Robust Bayesian Optimization with $\\phi$-divergences. (arXiv:2203.02128v4 [cs.LG] UPDATED)",
    "abstract": "The study of robustness has received much attention due to its inevitability in data-driven settings where many systems face uncertainty. One such example of concern is Bayesian Optimization (BO), where uncertainty is multi-faceted, yet there only exists a limited number of works dedicated to this direction. In particular, there is the work of Kirschner et al. (2020), which bridges the existing literature of Distributionally Robust Optimization (DRO) by casting the BO problem from the lens of DRO. While this work is pioneering, it admittedly suffers from various practical shortcomings such as finite contexts assumptions, leaving behind the main question Can one devise a computationally tractable algorithm for solving this DRO-BO problem? In this work, we tackle this question to a large degree of generality by considering robustness against data-shift in $\\phi$-divergences, which subsumes many popular choices, such as the $\\chi^2$-divergence, Total Variation, and the extant Kullback-Lei",
    "link": "http://arxiv.org/abs/2203.02128",
    "context": "Title: Distributionally Robust Bayesian Optimization with $\\phi$-divergences. (arXiv:2203.02128v4 [cs.LG] UPDATED)\nAbstract: The study of robustness has received much attention due to its inevitability in data-driven settings where many systems face uncertainty. One such example of concern is Bayesian Optimization (BO), where uncertainty is multi-faceted, yet there only exists a limited number of works dedicated to this direction. In particular, there is the work of Kirschner et al. (2020), which bridges the existing literature of Distributionally Robust Optimization (DRO) by casting the BO problem from the lens of DRO. While this work is pioneering, it admittedly suffers from various practical shortcomings such as finite contexts assumptions, leaving behind the main question Can one devise a computationally tractable algorithm for solving this DRO-BO problem? In this work, we tackle this question to a large degree of generality by considering robustness against data-shift in $\\phi$-divergences, which subsumes many popular choices, such as the $\\chi^2$-divergence, Total Variation, and the extant Kullback-Lei",
    "path": "papers/22/03/2203.02128.json",
    "total_tokens": 709,
    "translated_title": "基于$\\phi$-离散度的分布鲁棒贝叶斯优化",
    "translated_abstract": "鲁棒性研究因其在面对不确定性的许多系统中不可避免而受到广泛关注。其中一个例子是贝叶斯优化，它面临着多方面的不确定性，但仅有少量的研究致力于这个方向。在现有研究的基础上，我们提出了一种基于$\\phi$-离散度的分布鲁棒贝叶斯优化算法。",
    "tldr": "本研究提出了一种基于$\\phi$-离散度的分布鲁棒贝叶斯优化算法。",
    "en_tdlr": "This paper proposes a distributionally robust Bayesian optimization algorithm based on $\\phi$-divergences."
}