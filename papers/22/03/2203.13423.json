{
    "title": "Modeling Attrition in Recommender Systems with Departing Bandits",
    "abstract": "arXiv:2203.13423v2 Announce Type: replace  Abstract: Traditionally, when recommender systems are formalized as multi-armed bandits, the policy of the recommender system influences the rewards accrued, but not the length of interaction. However, in real-world systems, dissatisfied users may depart (and never come back). In this work, we propose a novel multi-armed bandit setup that captures such policy-dependent horizons. Our setup consists of a finite set of user types, and multiple arms with Bernoulli payoffs. Each (user type, arm) tuple corresponds to an (unknown) reward probability. Each user's type is initially unknown and can only be inferred through their response to recommendations. Moreover, if a user is dissatisfied with their recommendation, they might depart the system. We first address the case where all users share the same type, demonstrating that a recent UCB-based algorithm is optimal. We then move forward to the more challenging case, where users are divided among two ",
    "link": "https://arxiv.org/abs/2203.13423",
    "context": "Title: Modeling Attrition in Recommender Systems with Departing Bandits\nAbstract: arXiv:2203.13423v2 Announce Type: replace  Abstract: Traditionally, when recommender systems are formalized as multi-armed bandits, the policy of the recommender system influences the rewards accrued, but not the length of interaction. However, in real-world systems, dissatisfied users may depart (and never come back). In this work, we propose a novel multi-armed bandit setup that captures such policy-dependent horizons. Our setup consists of a finite set of user types, and multiple arms with Bernoulli payoffs. Each (user type, arm) tuple corresponds to an (unknown) reward probability. Each user's type is initially unknown and can only be inferred through their response to recommendations. Moreover, if a user is dissatisfied with their recommendation, they might depart the system. We first address the case where all users share the same type, demonstrating that a recent UCB-based algorithm is optimal. We then move forward to the more challenging case, where users are divided among two ",
    "path": "papers/22/03/2203.13423.json",
    "total_tokens": 830,
    "translated_title": "用离开的赌博机模型建议系统中的流失现象",
    "translated_abstract": "在传统的多臂赌博机中，推荐系统的策略影响奖励的获取，但不影响交互的长度。然而，在现实世界中，不满足的用户可能会离开（并永远不再回来）。在这项工作中，我们提出了一个捕捉这种策略依赖性时段的新型多臂赌博机设置。我们的设置包括一个有限的用户类型集合，和多个具有伯努利回报的臂。每个（用户类型，臂）元组对应一个（未知的）奖励概率。每个用户的类型最初是未知的，只能通过其对推荐的响应来推断。此外，如果用户对他们的推荐不满意，他们可能会离开系统。我们首先解决了所有用户共享相同类型的情况，证明了最近基于UCB的算法的最优性。然后，我们转向更具挑战性的情况，即用户分为两类。",
    "tldr": "本论文提出了一个新型多臂赌博机设置，捕捉了推荐系统中用户离开的情况，首次证明了在所有用户共享相同类型时，基于UCB的算法是最优的。"
}