{
    "title": "WOODS: Benchmarks for Out-of-Distribution Generalization in Time Series. (arXiv:2203.09978v2 [cs.LG] UPDATED)",
    "abstract": "Machine learning models often fail to generalize well under distributional shifts. Understanding and overcoming these failures have led to a research field of Out-of-Distribution (OOD) generalization. Despite being extensively studied for static computer vision tasks, OOD generalization has been underexplored for time series tasks. To shine light on this gap, we present WOODS: eight challenging open-source time series benchmarks covering a diverse range of data modalities, such as videos, brain recordings, and sensor signals. We revise the existing OOD generalization algorithms for time series tasks and evaluate them using our systematic framework. Our experiments show a large room for improvement for empirical risk minimization and OOD generalization algorithms on our datasets, thus underscoring the new challenges posed by time series tasks. Code and documentation are available at https://woods-benchmarks.github.io .",
    "link": "http://arxiv.org/abs/2203.09978",
    "context": "Title: WOODS: Benchmarks for Out-of-Distribution Generalization in Time Series. (arXiv:2203.09978v2 [cs.LG] UPDATED)\nAbstract: Machine learning models often fail to generalize well under distributional shifts. Understanding and overcoming these failures have led to a research field of Out-of-Distribution (OOD) generalization. Despite being extensively studied for static computer vision tasks, OOD generalization has been underexplored for time series tasks. To shine light on this gap, we present WOODS: eight challenging open-source time series benchmarks covering a diverse range of data modalities, such as videos, brain recordings, and sensor signals. We revise the existing OOD generalization algorithms for time series tasks and evaluate them using our systematic framework. Our experiments show a large room for improvement for empirical risk minimization and OOD generalization algorithms on our datasets, thus underscoring the new challenges posed by time series tasks. Code and documentation are available at https://woods-benchmarks.github.io .",
    "path": "papers/22/03/2203.09978.json",
    "total_tokens": 916,
    "translated_title": "WOODS: 时间序列领域的离群分布广义性的基准测试",
    "translated_abstract": "机器学习模型在分布偏移下往往难以进行很好的泛化。理解和克服这些问题形成了离群分布广义性的研究领域。尽管对于静态计算机视觉任务已经得到广泛研究，但在时间序列任务中，离群分布广义性却鲜有探索。为减少这一差距，我们提出WOODS：八个具有挑战性的开源时间序列基准测试，涵盖了各种数据模态，例如视频、脑记录和传感器信号。我们改进了现有的时间序列任务的离群分布广义性算法，并使用我们的系统框架进行评估。我们的实验显示，对于我们的数据集，经验风险最小化和离群分布广义性算法仍有很大的改进空间，从而凸显了时间序列任务面临的新挑战。代码和文档可在https://woods-benchmarks.github.io获得。",
    "tldr": "该论文提出了一个名为WOODS的时间序列基准测试，致力于解决在离群分布下的泛化过程中面临的挑战，还改进了目前时间序列任务中的离群分布广义性算法，并表明仍有很大的改进空间。",
    "en_tdlr": "The research proposes a time series benchmark called WOODS that aims at addressing the difficulties in generalization process under out-of-distribution shifts, improves existing out-of-distribution generalization algorithms for time series tasks, and points out a large room for improvement in such algorithms."
}