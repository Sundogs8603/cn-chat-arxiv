{
    "title": "Interpretable Off-Policy Learning via Hyperbox Search. (arXiv:2203.02473v2 [stat.ML] UPDATED)",
    "abstract": "Personalized treatment decisions have become an integral part of modern medicine. Thereby, the aim is to make treatment decisions based on individual patient characteristics. Numerous methods have been developed for learning such policies from observational data that achieve the best outcome across a certain policy class. Yet these methods are rarely interpretable. However, interpretability is often a prerequisite for policy learning in clinical practice. In this paper, we propose an algorithm for interpretable off-policy learning via hyperbox search. In particular, our policies can be represented in disjunctive normal form (i.e., OR-of-ANDs) and are thus intelligible. We prove a universal approximation theorem that shows that our policy class is flexible enough to approximate any measurable function arbitrarily well. For optimization, we develop a tailored column generation procedure within a branch-and-bound framework. Using a simulation study, we demonstrate that our algorithm outpe",
    "link": "http://arxiv.org/abs/2203.02473",
    "context": "Title: Interpretable Off-Policy Learning via Hyperbox Search. (arXiv:2203.02473v2 [stat.ML] UPDATED)\nAbstract: Personalized treatment decisions have become an integral part of modern medicine. Thereby, the aim is to make treatment decisions based on individual patient characteristics. Numerous methods have been developed for learning such policies from observational data that achieve the best outcome across a certain policy class. Yet these methods are rarely interpretable. However, interpretability is often a prerequisite for policy learning in clinical practice. In this paper, we propose an algorithm for interpretable off-policy learning via hyperbox search. In particular, our policies can be represented in disjunctive normal form (i.e., OR-of-ANDs) and are thus intelligible. We prove a universal approximation theorem that shows that our policy class is flexible enough to approximate any measurable function arbitrarily well. For optimization, we develop a tailored column generation procedure within a branch-and-bound framework. Using a simulation study, we demonstrate that our algorithm outpe",
    "path": "papers/22/03/2203.02473.json",
    "total_tokens": 887,
    "translated_title": "可解释的离线策略学习：基于超立方体搜索的方法",
    "translated_abstract": "个性化治疗决策已成为现代医学的重要组成部分。因此，目标是根据个体患者的特征进行治疗决策。已经开发了许多方法从观测数据中学习这样的策略，以实现在特定策略类别下获得最佳结果。但是，这些方法很少具有可解释性。然而，可解释性通常是临床实践中策略学习的前提条件。在本文中，我们提出了一种基于超立方体搜索的可解释离线策略学习算法。特别地，我们的策略可以用合取范式表示（即AND的OR），因此是容易理解的。我们证明了一个通用逼近定理，证明了我们的策略类可以灵活地逼近任何可测函数。为了优化，我们在分支定界框架内开发了一个定制的列生成过程。通过模拟研究，我们证明了我们的算法优于其他方法。",
    "tldr": "本文提出了一个基于超立方体搜索的可解释离线策略学习算法，可以用合取范式表示，可以灵活逼近任何可测函数。在临床实践中具有重要意义。",
    "en_tdlr": "The paper proposes an interpretable off-policy learning algorithm via hyperbox search, which can represent policies in disjunctive normal form and flexibly approximate any measurable function. It has important implications for clinical practice."
}