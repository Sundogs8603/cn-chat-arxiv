{
    "title": "DeltaCNN: End-to-End CNN Inference of Sparse Frame Differences in Videos. (arXiv:2203.03996v2 [cs.CV] UPDATED)",
    "abstract": "Convolutional neural network inference on video data requires powerful hardware for real-time processing. Given the inherent coherence across consecutive frames, large parts of a video typically change little. By skipping identical image regions and truncating insignificant pixel updates, computational redundancy can in theory be reduced significantly. However, these theoretical savings have been difficult to translate into practice, as sparse updates hamper computational consistency and memory access coherence; which are key for efficiency on real hardware. With DeltaCNN, we present a sparse convolutional neural network framework that enables sparse frame-by-frame updates to accelerate video inference in practice. We provide sparse implementations for all typical CNN layers and propagate sparse feature updates end-to-end - without accumulating errors over time. DeltaCNN is applicable to all convolutional neural networks without retraining. To the best of our knowledge, we are the firs",
    "link": "http://arxiv.org/abs/2203.03996",
    "context": "Title: DeltaCNN: End-to-End CNN Inference of Sparse Frame Differences in Videos. (arXiv:2203.03996v2 [cs.CV] UPDATED)\nAbstract: Convolutional neural network inference on video data requires powerful hardware for real-time processing. Given the inherent coherence across consecutive frames, large parts of a video typically change little. By skipping identical image regions and truncating insignificant pixel updates, computational redundancy can in theory be reduced significantly. However, these theoretical savings have been difficult to translate into practice, as sparse updates hamper computational consistency and memory access coherence; which are key for efficiency on real hardware. With DeltaCNN, we present a sparse convolutional neural network framework that enables sparse frame-by-frame updates to accelerate video inference in practice. We provide sparse implementations for all typical CNN layers and propagate sparse feature updates end-to-end - without accumulating errors over time. DeltaCNN is applicable to all convolutional neural networks without retraining. To the best of our knowledge, we are the firs",
    "path": "papers/22/03/2203.03996.json",
    "total_tokens": 879,
    "translated_title": "DeltaCNN: 视频中稀疏帧差异的端到端卷积神经网络推理",
    "translated_abstract": "对视频数据进行卷积神经网络推理需要强大的硬件以实现实时处理。考虑到连续帧之间的固有一致性，视频的大部分区域通常变化很小。通过跳过相同的图像区域并截断不重要的像素更新，理论上可以显著减少计算冗余。然而，由于稀疏更新阻碍了计算一致性和内存访问一致性，这些理论上的节省在实践中很难实现；而这些特性对于实际硬件的效率至关重要。通过DeltaCNN，我们提出了一种稀疏卷积神经网络框架，能够实现逐帧稀疏更新，加速视频推理的实践应用。我们为所有典型的卷积神经网络层提供了稀疏实现，并端到端地传播稀疏特征更新-无需随时间累积错误。DeltaCNN适用于所有卷积神经网络，无需重新训练。据我们所知，我们是第一个提出这种方法的。",
    "tldr": "DeltaCNN是一种稀疏卷积神经网络框架，通过逐帧稀疏更新，加速视频推理的实践应用，而无需重新训练。",
    "en_tdlr": "DeltaCNN is a sparse convolutional neural network framework that accelerates video inference in practice through frame-by-frame sparse updates without retraining."
}