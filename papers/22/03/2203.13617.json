{
    "title": "EmotionNAS: Two-stream Neural Architecture Search for Speech Emotion Recognition. (arXiv:2203.13617v2 [eess.AS] UPDATED)",
    "abstract": "Speech emotion recognition (SER) is an important research topic in human-computer interaction. Existing works mainly rely on human expertise to design models. Despite their success, different datasets often require distinct structures and hyperparameters. Searching for an optimal model for each dataset is time-consuming and labor-intensive. To address this problem, we propose a two-stream neural architecture search (NAS) based framework, called \\enquote{EmotionNAS}. Specifically, we take two-stream features (i.e., handcrafted and deep features) as the inputs, followed by NAS to search for the optimal structure for each stream. Furthermore, we incorporate complementary information in different streams through an efficient information supplement module. Experimental results demonstrate that our method outperforms existing manually-designed and NAS-based models, setting the new state-of-the-art record.",
    "link": "http://arxiv.org/abs/2203.13617",
    "context": "Title: EmotionNAS: Two-stream Neural Architecture Search for Speech Emotion Recognition. (arXiv:2203.13617v2 [eess.AS] UPDATED)\nAbstract: Speech emotion recognition (SER) is an important research topic in human-computer interaction. Existing works mainly rely on human expertise to design models. Despite their success, different datasets often require distinct structures and hyperparameters. Searching for an optimal model for each dataset is time-consuming and labor-intensive. To address this problem, we propose a two-stream neural architecture search (NAS) based framework, called \\enquote{EmotionNAS}. Specifically, we take two-stream features (i.e., handcrafted and deep features) as the inputs, followed by NAS to search for the optimal structure for each stream. Furthermore, we incorporate complementary information in different streams through an efficient information supplement module. Experimental results demonstrate that our method outperforms existing manually-designed and NAS-based models, setting the new state-of-the-art record.",
    "path": "papers/22/03/2203.13617.json",
    "total_tokens": 863,
    "translated_title": "EmotionNAS: 面向语音情感识别的双流神经架构搜索",
    "translated_abstract": "语音情感识别（SER）是人机交互中的重要研究课题，现有工作主要依赖于人类专业知识来设计模型。尽管这些模型成功率高，但不同的数据集往往需要不同的结构和超参数，为每个数据集搜索最优模型的过程耗费时间和精力。为了解决这个问题，我们提出了一种基于双流神经架构搜索（NAS）的框架，称为“EmotionNAS”。具体而言，我们将两种流（即手工特征和深度特征）作为输入，然后进行NAS以搜索每个流的最佳结构。此外，我们通过高效的信息补充模块整合不同流中的互补信息。实验结果表明，我们的方法超过了现有的手动设计和基于NAS的模型，并创下了新的最优记录。",
    "tldr": "提出了一种基于双流神经架构搜索的框架EmotionNAS用于语音情感识别，将两种流（即手工特征和深度特征）作为输入，通过高效的信息补充模块实现流之间的信息整合，并在实验中创下新的最优记录。",
    "en_tdlr": "EmotionNAS, a two-stream NAS framework, is proposed for speech emotion recognition by taking two types of features as input and incorporating information supplement module to integrate complementary information. It outperforms existing manually-designed and NAS-based models, setting the new state-of-the-art record."
}