{
    "title": "Towards Visual Affordance Learning: A Benchmark for Affordance Segmentation and Recognition. (arXiv:2203.14092v2 [cs.CV] UPDATED)",
    "abstract": "The physical and textural attributes of objects have been widely studied for recognition, detection and segmentation tasks in computer vision.~A number of datasets, such as large scale ImageNet, have been proposed for feature learning using data hungry deep neural networks and for hand-crafted feature extraction. To intelligently interact with objects, robots and intelligent machines need the ability to infer beyond the traditional physical/textural attributes, and understand/learn visual cues, called visual affordances, for affordance recognition, detection and segmentation. To date there is no publicly available large dataset for visual affordance understanding and learning. In this paper, we introduce a large scale multi-view RGBD visual affordance learning dataset, a benchmark of 47210 RGBD images from 37 object categories, annotated with 15 visual affordance categories. To the best of our knowledge, this is the first ever and the largest multi-view RGBD visual affordance learning ",
    "link": "http://arxiv.org/abs/2203.14092",
    "context": "Title: Towards Visual Affordance Learning: A Benchmark for Affordance Segmentation and Recognition. (arXiv:2203.14092v2 [cs.CV] UPDATED)\nAbstract: The physical and textural attributes of objects have been widely studied for recognition, detection and segmentation tasks in computer vision.~A number of datasets, such as large scale ImageNet, have been proposed for feature learning using data hungry deep neural networks and for hand-crafted feature extraction. To intelligently interact with objects, robots and intelligent machines need the ability to infer beyond the traditional physical/textural attributes, and understand/learn visual cues, called visual affordances, for affordance recognition, detection and segmentation. To date there is no publicly available large dataset for visual affordance understanding and learning. In this paper, we introduce a large scale multi-view RGBD visual affordance learning dataset, a benchmark of 47210 RGBD images from 37 object categories, annotated with 15 visual affordance categories. To the best of our knowledge, this is the first ever and the largest multi-view RGBD visual affordance learning ",
    "path": "papers/22/03/2203.14092.json",
    "total_tokens": 928,
    "translated_title": "向视觉可管理学习迈进：一个用于可管理分割和识别的基准。 (arXiv:2203.14092v2 [cs.CV] UPDATED)",
    "translated_abstract": "对于计算机视觉中的识别、检测和分割任务，对象的物理和纹理属性已得到广泛研究。许多数据集，如大规模的ImageNet，已经被提出用于使用数据饥饿的深度神经网络进行特征学习和手工特征提取。为了智能地与对象进行交互，机器人和智能机器需要除了传统的物理/纹理属性之外的推理能力，以及理解/学习被称为视觉可管理的视觉提示，用于可管理的识别、检测和分割。到目前为止，还没有公开可用的用于视觉可管理理解和学习的大规模数据集。在本文中，我们介绍了一个大规模的多视角RGBD视觉可管理学习数据集，这是一个包含37个对象类别的47210个RGBD图像的基准，每个图像都带有15个视觉可管理类别的注释。据我们所知，这是有史以来第一个也是最大的多视角RGBD视觉可管理学习数据集。",
    "tldr": "该论文介绍了一个大规模的多视角RGBD视觉可管理学习数据集，其中包含了37个对象类别的47210个图像，并且每个图像都带有15个视觉可管理类别的注释。",
    "en_tdlr": "This paper introduces a large-scale multi-view RGBD visual affordance learning dataset with 47210 images from 37 object categories, each annotated with 15 visual affordance categories."
}