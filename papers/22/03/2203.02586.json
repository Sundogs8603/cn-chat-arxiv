{
    "title": "Concept-based Explanations for Out-Of-Distribution Detectors. (arXiv:2203.02586v3 [cs.LG] UPDATED)",
    "abstract": "Out-of-distribution (OOD) detection plays a crucial role in ensuring the safe deployment of deep neural network (DNN) classifiers. While a myriad of methods have focused on improving the performance of OOD detectors, a critical gap remains in interpreting their decisions. We help bridge this gap by providing explanations for OOD detectors based on learned high-level concepts. We first propose two new metrics for assessing the effectiveness of a particular set of concepts for explaining OOD detectors: 1) detection completeness, which quantifies the sufficiency of concepts for explaining an OOD-detector's decisions, and 2) concept separability, which captures the distributional separation between in-distribution and OOD data in the concept space. Based on these metrics, we propose an unsupervised framework for learning a set of concepts that satisfy the desired properties of high detection completeness and concept separability, and demonstrate its effectiveness in providing concept-based",
    "link": "http://arxiv.org/abs/2203.02586",
    "context": "Title: Concept-based Explanations for Out-Of-Distribution Detectors. (arXiv:2203.02586v3 [cs.LG] UPDATED)\nAbstract: Out-of-distribution (OOD) detection plays a crucial role in ensuring the safe deployment of deep neural network (DNN) classifiers. While a myriad of methods have focused on improving the performance of OOD detectors, a critical gap remains in interpreting their decisions. We help bridge this gap by providing explanations for OOD detectors based on learned high-level concepts. We first propose two new metrics for assessing the effectiveness of a particular set of concepts for explaining OOD detectors: 1) detection completeness, which quantifies the sufficiency of concepts for explaining an OOD-detector's decisions, and 2) concept separability, which captures the distributional separation between in-distribution and OOD data in the concept space. Based on these metrics, we propose an unsupervised framework for learning a set of concepts that satisfy the desired properties of high detection completeness and concept separability, and demonstrate its effectiveness in providing concept-based",
    "path": "papers/22/03/2203.02586.json",
    "total_tokens": 953,
    "translated_title": "基于概念的解释方法用于外分布检测器",
    "translated_abstract": "外分布（OOD）检测在确保深度神经网络（DNN）分类器安全部署方面发挥着关键作用。虽然有大量方法致力于提高OOD检测器的性能，但其决策的解释仍存在重要缺陷。为解决该问题，我们提出了一种基于学习的高级概念提供OOD检测器解释的方法。首先我们提出了两个新的度量标准，用于评估一组特定概念解释OOD检测器的效果：1）检测完整性，用于量化概念对于解释OOD检测器决策的充分程度；2）概念可分离度，用于捕捉概念空间中正常分布和OOD数据之间的分布差异。基于这些指标，我们提出了一种无监督的框架，用于学习一组具有高检测完整性和概念可分离性特征的概念，并展示了其在提供基于概念解释方面的有效性。",
    "tldr": "本论文提出了一种基于学习的高级概念提供OOD检测器解释的方法，通过提出新的度量标准，学习一组具有高检测完整性和概念可分离性特征的概念，有效提高了OOD检测器的解释性能。",
    "en_tdlr": "This paper proposes a concept-based method for providing explanations for out-of-distribution (OOD) detectors, and introduces two new metrics for evaluating the effectiveness of a set of concepts for explaining OOD detectors. The unsupervised framework is demonstrated to improve the interpretability of OOD detectors by learning a set of concepts with high detection completeness and concept separability."
}