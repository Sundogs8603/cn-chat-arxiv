{
    "title": "Multimodal Fusion Transformer for Remote Sensing Image Classification. (arXiv:2203.16952v2 [cs.CV] UPDATED)",
    "abstract": "Vision transformers (ViTs) have been trending in image classification tasks due to their promising performance when compared to convolutional neural networks (CNNs). As a result, many researchers have tried to incorporate ViTs in hyperspectral image (HSI) classification tasks. To achieve satisfactory performance, close to that of CNNs, transformers need fewer parameters. ViTs and other similar transformers use an external classification (CLS) token which is randomly initialized and often fails to generalize well, whereas other sources of multimodal datasets, such as light detection and ranging (LiDAR) offer the potential to improve these models by means of a CLS. In this paper, we introduce a new multimodal fusion transformer (MFT) network which comprises a multihead cross patch attention (mCrossPA) for HSI land-cover classification. Our mCrossPA utilizes other sources of complementary information in addition to the HSI in the transformer encoder to achieve better generalization. The c",
    "link": "http://arxiv.org/abs/2203.16952",
    "context": "Title: Multimodal Fusion Transformer for Remote Sensing Image Classification. (arXiv:2203.16952v2 [cs.CV] UPDATED)\nAbstract: Vision transformers (ViTs) have been trending in image classification tasks due to their promising performance when compared to convolutional neural networks (CNNs). As a result, many researchers have tried to incorporate ViTs in hyperspectral image (HSI) classification tasks. To achieve satisfactory performance, close to that of CNNs, transformers need fewer parameters. ViTs and other similar transformers use an external classification (CLS) token which is randomly initialized and often fails to generalize well, whereas other sources of multimodal datasets, such as light detection and ranging (LiDAR) offer the potential to improve these models by means of a CLS. In this paper, we introduce a new multimodal fusion transformer (MFT) network which comprises a multihead cross patch attention (mCrossPA) for HSI land-cover classification. Our mCrossPA utilizes other sources of complementary information in addition to the HSI in the transformer encoder to achieve better generalization. The c",
    "path": "papers/22/03/2203.16952.json",
    "total_tokens": 663,
    "translated_title": "遥感图像分类的多模态融合Transformer",
    "translated_abstract": "视觉Transformer在图像分类任务中表现出色，而为了接近卷积神经网络的性能，需要更少的参数。本文引入了一个新的多模态融合Transformer网络，利用多源互补信息来帮助高光谱遥感图像分类任务。我们的网络利用多头交叉补丁注意力机制（mCrossPA）来获取其他数据源的信息，从而提高Transformer的泛化能力。",
    "tldr": "本文引入了一个新的多模态融合Transformer，利用多源互补信息来提高遥感图像分类的性能。",
    "en_tdlr": "The paper introduces a new multimodal fusion Transformer that utilizes complementary information from multiple sources to improve remote sensing image classification performance."
}