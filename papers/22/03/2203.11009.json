{
    "title": "Continual Spatio-Temporal Graph Convolutional Networks. (arXiv:2203.11009v2 [cs.CV] UPDATED)",
    "abstract": "Graph-based reasoning over skeleton data has emerged as a promising approach for human action recognition. However, the application of prior graph-based methods, which predominantly employ whole temporal sequences as their input, to the setting of online inference entails considerable computational redundancy. In this paper, we tackle this issue by reformulating the Spatio-Temporal Graph Convolutional Neural Network as a Continual Inference Network, which can perform step-by-step predictions in time without repeat frame processing. To evaluate our method, we create a continual version of ST-GCN, CoST-GCN, alongside two derived methods with different self-attention mechanisms, CoAGCN and CoS-TR. We investigate weight transfer strategies and architectural modifications for inference acceleration, and perform experiments on the NTU RGB+D 60, NTU RGB+D 120, and Kinetics Skeleton 400 datasets. Retaining similar predictive accuracy, we observe up to 109x reduction in time complexity, on-hard",
    "link": "http://arxiv.org/abs/2203.11009",
    "context": "Title: Continual Spatio-Temporal Graph Convolutional Networks. (arXiv:2203.11009v2 [cs.CV] UPDATED)\nAbstract: Graph-based reasoning over skeleton data has emerged as a promising approach for human action recognition. However, the application of prior graph-based methods, which predominantly employ whole temporal sequences as their input, to the setting of online inference entails considerable computational redundancy. In this paper, we tackle this issue by reformulating the Spatio-Temporal Graph Convolutional Neural Network as a Continual Inference Network, which can perform step-by-step predictions in time without repeat frame processing. To evaluate our method, we create a continual version of ST-GCN, CoST-GCN, alongside two derived methods with different self-attention mechanisms, CoAGCN and CoS-TR. We investigate weight transfer strategies and architectural modifications for inference acceleration, and perform experiments on the NTU RGB+D 60, NTU RGB+D 120, and Kinetics Skeleton 400 datasets. Retaining similar predictive accuracy, we observe up to 109x reduction in time complexity, on-hard",
    "path": "papers/22/03/2203.11009.json",
    "total_tokens": 900,
    "translated_title": "持续的时空图卷积神经网络",
    "translated_abstract": "基于图的推理在骨骼数据的应用已成为人体动作识别的有希望的方法。然而，以整个时间序列作为输入的先前基于图的方法在在线推理设置中应用会导致重复的计算。本文通过将时空图卷积神经网络重新构建为连续推理网络来解决这个问题，这个网络可以在时间上逐步进行预测，而无需重复帧处理。为了评估我们的方法，我们创建了ST-GCN网络的连续版本CoST-GCN，以及两种具有不同自我注意机制的衍生方法——CoAGCN和CoS-TR。我们研究了权重传递策略和架构修改以加速推理，并在NTU RGB+D 60、NTU RGB+D 120和Kinetics Skeleton 400数据集上进行了实验。在保持类似的预测准确性条件下，我们观察到时间复杂度最多减少了109倍。",
    "tldr": "本文提出了一种连续时空图卷积神经网络（CoST-GCN）来解决基于图的方法在在线推理设置中应用时重复计算的问题，相比之前的方法最多可将时间复杂度减少109倍。",
    "en_tdlr": "This paper proposes a Continual Inference Network, CoST-GCN, to solve the computational redundancy issue of prior graph-based methods in online inference settings. The proposed network can perform step-by-step predictions in time without repeat frame processing, and achieves up to 109x reduction in time complexity while maintaining similar predictive accuracy on human action recognition tasks."
}