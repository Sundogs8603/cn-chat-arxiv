{
    "title": "Black-box Selective Inference via Bootstrapping. (arXiv:2203.14504v2 [stat.ME] UPDATED)",
    "abstract": "Conditional selective inference requires an exact characterization of the selection event, which is often unavailable except for a few examples like the lasso. This work addresses this challenge by introducing a generic approach to estimate the selection event, facilitating feasible inference conditioned on the selection event. The method proceeds by repeatedly generating bootstrap data and running the selection algorithm on the new datasets. Using the outputs of the selection algorithm, we can estimate the selection probability as a function of certain summary statistics. This leads to an estimate of the distribution of the data conditioned on the selection event, which forms the basis for conditional selective inference. We provide a theoretical guarantee assuming both asymptotic normality of relevant statistics and accurate estimation of the selection probability. The applicability of the proposed method is demonstrated through a variety of problems that lack exact characterizations",
    "link": "http://arxiv.org/abs/2203.14504",
    "context": "Title: Black-box Selective Inference via Bootstrapping. (arXiv:2203.14504v2 [stat.ME] UPDATED)\nAbstract: Conditional selective inference requires an exact characterization of the selection event, which is often unavailable except for a few examples like the lasso. This work addresses this challenge by introducing a generic approach to estimate the selection event, facilitating feasible inference conditioned on the selection event. The method proceeds by repeatedly generating bootstrap data and running the selection algorithm on the new datasets. Using the outputs of the selection algorithm, we can estimate the selection probability as a function of certain summary statistics. This leads to an estimate of the distribution of the data conditioned on the selection event, which forms the basis for conditional selective inference. We provide a theoretical guarantee assuming both asymptotic normality of relevant statistics and accurate estimation of the selection probability. The applicability of the proposed method is demonstrated through a variety of problems that lack exact characterizations",
    "path": "papers/22/03/2203.14504.json",
    "total_tokens": 813,
    "translated_title": "通过引入自举法进行黑盒选择性推断",
    "translated_abstract": "条件选择性推断需要对选择事件进行精确描述，但通常除了一些示例（如套索法）外，很难获得。本研究通过引入一种通用方法来估计选择事件，从而促进在选择事件条件下的可行推断。该方法通过重复生成自举数据并在新数据集上运行选择算法来进行。利用选择算法的输出，我们可以将选择概率估计为特定摘要统计量的函数。这导致了在选择事件条件下的数据分布的估计，为条件选择性推断奠定了基础。我们提供了一个理论保证，假设相关统计量的渐近正常性和选择概率的准确估计。通过多种缺乏精确描述的问题，我们证明了所提出的方法的适用性。",
    "tldr": "本论文提出了一种通过引入自举法来进行黑盒选择性推断的通用方法。通过重复生成自举数据和运行选择算法，我们能够估计选择事件的概率，并在此基础上进行条件选择性推断。这个方法适用于各种缺乏精确描述的问题。",
    "en_tdlr": "This paper introduces a generic approach to black-box selective inference through bootstrapping. By repeatedly generating bootstrap data and running the selection algorithm, we can estimate the selection probability and perform conditional selective inference. This method is applicable to various problems lacking exact characterizations."
}