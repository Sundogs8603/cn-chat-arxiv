{
    "title": "Towards Interpretable Deep Reinforcement Learning Models via Inverse Reinforcement Learning",
    "abstract": "arXiv:2203.16464v3 Announce Type: replace-cross  Abstract: Artificial intelligence, particularly through recent advancements in deep learning, has achieved exceptional performances in many tasks in fields such as natural language processing and computer vision. In addition to desirable evaluation metrics, a high level of interpretability is often required for these models to be reliably utilized. Therefore, explanations that offer insight into the process by which a model maps its inputs onto its outputs are much sought-after. Unfortunately, the current black box nature of machine learning models is still an unresolved issue and this very nature prevents researchers from learning and providing explicative descriptions for a model's behavior and final predictions. In this work, we propose a novel framework utilizing Adversarial Inverse Reinforcement Learning that can provide global explanations for decisions made by a Reinforcement Learning model and capture intuitive tendencies that th",
    "link": "https://arxiv.org/abs/2203.16464",
    "context": "Title: Towards Interpretable Deep Reinforcement Learning Models via Inverse Reinforcement Learning\nAbstract: arXiv:2203.16464v3 Announce Type: replace-cross  Abstract: Artificial intelligence, particularly through recent advancements in deep learning, has achieved exceptional performances in many tasks in fields such as natural language processing and computer vision. In addition to desirable evaluation metrics, a high level of interpretability is often required for these models to be reliably utilized. Therefore, explanations that offer insight into the process by which a model maps its inputs onto its outputs are much sought-after. Unfortunately, the current black box nature of machine learning models is still an unresolved issue and this very nature prevents researchers from learning and providing explicative descriptions for a model's behavior and final predictions. In this work, we propose a novel framework utilizing Adversarial Inverse Reinforcement Learning that can provide global explanations for decisions made by a Reinforcement Learning model and capture intuitive tendencies that th",
    "path": "papers/22/03/2203.16464.json",
    "total_tokens": 766,
    "translated_title": "通过逆强化学习实现可解释的深度强化学习模型",
    "translated_abstract": "人工智能，尤其是近年来深度学习的最新进展，在自然语言处理和计算机视觉等领域的许多任务中取得了出色的表现。除了令人满意的评估指标外，这些模型通常需要高度可解释性才能被可靠地利用。因此，提供能够深入了解模型如何将其输入映射到输出的解释成为人们迫切需要的。不幸的是，目前机器学习模型的黑盒特性仍然是一个尚未解决的问题，这种特性阻碍了研究人员学习和提供对模型行为和最终预测的解释描述。",
    "tldr": "本研究提出了一个新颖的框架，利用对抗逆强化学习，可以为强化学习模型所作出的决策提供全局解释，并捕捉直观的倾向。",
    "en_tdlr": "This study introduces a novel framework utilizing Adversarial Inverse Reinforcement Learning to provide global explanations for decisions made by a Reinforcement Learning model and capture intuitive tendencies."
}