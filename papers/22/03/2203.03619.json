{
    "title": "Adaptive Cross-Layer Attention for Image Restoration. (arXiv:2203.03619v3 [eess.IV] CROSS LISTED)",
    "abstract": "Non-local attention module has been proven to be crucial for image restoration. Conventional non-local attention processes features of each layer separately, so it risks missing correlation between features among different layers. To address this problem, we aim to design attention modules that aggregate information from different layers. Instead of finding correlated key pixels within the same layer, each query pixel is encouraged to attend to key pixels at multiple previous layers of the network. In order to efficiently embed such attention design into neural network backbones, we propose a novel Adaptive Cross-Layer Attention (ACLA) module. Two adaptive designs are proposed for ACLA: (1) adaptively selecting the keys for non-local attention at each layer; (2) automatically searching for the insertion locations for ACLA modules. By these two adaptive designs, ACLA dynamically selects a flexible number of keys to be aggregated for non-local attention at previous layer while maintainin",
    "link": "http://arxiv.org/abs/2203.03619",
    "context": "Title: Adaptive Cross-Layer Attention for Image Restoration. (arXiv:2203.03619v3 [eess.IV] CROSS LISTED)\nAbstract: Non-local attention module has been proven to be crucial for image restoration. Conventional non-local attention processes features of each layer separately, so it risks missing correlation between features among different layers. To address this problem, we aim to design attention modules that aggregate information from different layers. Instead of finding correlated key pixels within the same layer, each query pixel is encouraged to attend to key pixels at multiple previous layers of the network. In order to efficiently embed such attention design into neural network backbones, we propose a novel Adaptive Cross-Layer Attention (ACLA) module. Two adaptive designs are proposed for ACLA: (1) adaptively selecting the keys for non-local attention at each layer; (2) automatically searching for the insertion locations for ACLA modules. By these two adaptive designs, ACLA dynamically selects a flexible number of keys to be aggregated for non-local attention at previous layer while maintainin",
    "path": "papers/22/03/2203.03619.json",
    "total_tokens": 833,
    "translated_title": "自适应跨层注意力机制用于图像恢复",
    "translated_abstract": "非局部注意力模块被证明在图像恢复中至关重要。传统的非局部注意力单独处理每个层次的特征，可能会错过不同层次之间特征之间的关联性，为解决这个问题，我们旨在设计注意力模块，可以汇总不同层次的信息。我们提出了一种新颖的自适应跨层注意力（ACLA）模块，以有效地将这种注意力设计嵌入神经网络骨干中。ACLA提供了两种自适应设计：（1）在每一层自适应选择非局部注意力的键；（2）自动搜索ACLA模块的插入位置。通过这两个自适应设计，ACLA动态地选择灵活数量的键来汇总前一层次的特征进行非局部注意力的处理，同时保持网络的有效性和效率。",
    "tldr": "本文提出了一种自适应跨层注意力（ACLA）模块，它可以汇总不同层次的特征信息用于非局部注意力的处理，以提高图像恢复的效果。",
    "en_tdlr": "This paper proposes an Adaptive Cross-Layer Attention (ACLA) module that aggregates features from different layers for non-local attention, addressing the issue of missing correlation between features among different layers in image restoration, and improving the restoration result."
}