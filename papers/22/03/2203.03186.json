{
    "title": "Bandits Corrupted by Nature: Lower Bounds on Regret and Robust Optimistic Algorithm. (arXiv:2203.03186v2 [cs.LG] UPDATED)",
    "abstract": "We study the corrupted bandit problem, i.e. a stochastic multi-armed bandit problem with $k$ unknown reward distributions, which are heavy-tailed and corrupted by a history-independent adversary or Nature. To be specific, the reward obtained by playing an arm comes from corresponding heavy-tailed reward distribution with probability $1-\\varepsilon \\in (0.5,1]$ and an arbitrary corruption distribution of unbounded support with probability $\\varepsilon \\in [0,0.5)$.  First, we provide $\\textit{a problem-dependent lower bound on the regret}$ of any corrupted bandit algorithm. The lower bounds indicate that the corrupted bandit problem is harder than the classical stochastic bandit problem with sub-Gaussian or heavy-tail rewards.  Following that, we propose a novel UCB-type algorithm for corrupted bandits, namely HubUCB, that builds on Huber's estimator for robust mean estimation. Leveraging a novel concentration inequality of Huber's estimator, we prove that HubUCB achieves a near-optimal",
    "link": "http://arxiv.org/abs/2203.03186",
    "context": "Title: Bandits Corrupted by Nature: Lower Bounds on Regret and Robust Optimistic Algorithm. (arXiv:2203.03186v2 [cs.LG] UPDATED)\nAbstract: We study the corrupted bandit problem, i.e. a stochastic multi-armed bandit problem with $k$ unknown reward distributions, which are heavy-tailed and corrupted by a history-independent adversary or Nature. To be specific, the reward obtained by playing an arm comes from corresponding heavy-tailed reward distribution with probability $1-\\varepsilon \\in (0.5,1]$ and an arbitrary corruption distribution of unbounded support with probability $\\varepsilon \\in [0,0.5)$.  First, we provide $\\textit{a problem-dependent lower bound on the regret}$ of any corrupted bandit algorithm. The lower bounds indicate that the corrupted bandit problem is harder than the classical stochastic bandit problem with sub-Gaussian or heavy-tail rewards.  Following that, we propose a novel UCB-type algorithm for corrupted bandits, namely HubUCB, that builds on Huber's estimator for robust mean estimation. Leveraging a novel concentration inequality of Huber's estimator, we prove that HubUCB achieves a near-optimal",
    "path": "papers/22/03/2203.03186.json",
    "total_tokens": 910,
    "translated_title": "被自然扭曲的赌徒问题: 对遗憾和鲁棒乐观算法的下限分析",
    "translated_abstract": "本文研究了赌徒问题中的一种特殊情况，即在$k$个未知奖励分布为重尾分布的臂中选择，在每轮操作中，以$1-\\varepsilon \\in(0.5,1]$的概率来自奖励分布，以$\\varepsilon \\in[0,0.5)$的概率来自未知的扭曲分布。首先，我们提供了任何扭曲赌徒算法“遗憾”的一个问题相关下限。较之亚高斯或重尾奖励的经典随机赌徒问题，上述结果表明扭曲赌徒问题更为困难。接下来，我们提出了针对扭曲赌徒的一种新型上置信界算法，名为 HubUCB，该算法基于 Huber 的鲁棒均值估计，利用 Huber 估计量的一种新型集中不等式，证明了 HubUCB 实现了接近最优的效果。",
    "tldr": "本文研究了一种被自然扭曲的赌徒问题，提出了HubUCB算法，利用Huber估计实现了接近最优的效果。",
    "en_tdlr": "This paper studies a corrupted bandit problem where rewards are heavy-tailed and corrupted by an unknown distribution, and proposes a HubUCB algorithm based on Huber estimator, which achieves near-optimal performance."
}