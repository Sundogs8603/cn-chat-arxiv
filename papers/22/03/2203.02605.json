{
    "title": "Reinforcement Learning in Modern Biostatistics: Constructing Optimal Adaptive Interventions. (arXiv:2203.02605v2 [stat.ML] UPDATED)",
    "abstract": "In recent years, reinforcement learning (RL) has acquired a prominent position in the space of health-related sequential decision-making, becoming an increasingly popular tool for delivering adaptive interventions (AIs). However, despite potential benefits, its real-life application is still limited, partly due to a poor synergy between the methodological and the applied communities. In this work, we provide the first unified survey on RL methods for learning AIs, using the common methodological umbrella of RL to bridge the two AI areas of dynamic treatment regimes and just-in-time adaptive interventions in mobile health. We outline similarities and differences between these two AI domains and discuss their implications for using RL. Finally, we leverage our experience in designing case studies in both areas to illustrate the tremendous collaboration opportunities between statistical, RL, and healthcare researchers in the space of AIs.",
    "link": "http://arxiv.org/abs/2203.02605",
    "context": "Title: Reinforcement Learning in Modern Biostatistics: Constructing Optimal Adaptive Interventions. (arXiv:2203.02605v2 [stat.ML] UPDATED)\nAbstract: In recent years, reinforcement learning (RL) has acquired a prominent position in the space of health-related sequential decision-making, becoming an increasingly popular tool for delivering adaptive interventions (AIs). However, despite potential benefits, its real-life application is still limited, partly due to a poor synergy between the methodological and the applied communities. In this work, we provide the first unified survey on RL methods for learning AIs, using the common methodological umbrella of RL to bridge the two AI areas of dynamic treatment regimes and just-in-time adaptive interventions in mobile health. We outline similarities and differences between these two AI domains and discuss their implications for using RL. Finally, we leverage our experience in designing case studies in both areas to illustrate the tremendous collaboration opportunities between statistical, RL, and healthcare researchers in the space of AIs.",
    "path": "papers/22/03/2203.02605.json",
    "total_tokens": 953,
    "translated_title": "现代生物统计中的强化学习：构建最优自适应干预",
    "translated_abstract": "近年来，强化学习（RL）在与健康相关的序列性决策中占据了重要地位，成为交付自适应干预（AIs）的越来越流行的工具。然而，尽管具有潜在优势，但其现实应用仍然受到限制，部分是由于方法论和应用社区之间的协同不足。在这项工作中，我们提供了关于学习AIs的RL方法的第一份统一调查，利用RL的通用方法论伞来桥接动态治疗方案和移动健康中即时自适应干预这两个AI领域。我们概述了这两个AI领域之间的异同，并讨论了它们对使用RL的影响。最后，我们利用自己在两个领域中设计案例研究的经验，说明了在AIs领域中，统计学、RL和医疗研究人员之间的巨大合作机会。",
    "tldr": "本文是关于将强化学习应用于自适应干预中的第一份统一调查，强化学习在动态治疗方案和移动健康中即时自适应干预这两个领域中都具有很大的应用潜力。在这两个领域之间存在相似和不同之处需要考虑，并且这里存在巨大的合作机会。",
    "en_tdlr": "This article is the first unified survey on using reinforcement learning for adaptive interventions, highlighting the potential for RL in both dynamic treatment regimes and just-in-time adaptive interventions in mobile health. It outlines the similarities and differences between these two fields and discusses the collaboration opportunities for statisticians, RL practitioners, and healthcare researchers in this area."
}