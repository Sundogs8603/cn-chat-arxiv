{
    "title": "Rethinking Reconstruction Autoencoder-Based Out-of-Distribution Detection. (arXiv:2203.02194v3 [cs.CV] UPDATED)",
    "abstract": "In some scenarios, classifier requires detecting out-of-distribution samples far from its training data. With desirable characteristics, reconstruction autoencoder-based methods deal with this problem by using input reconstruction error as a metric of novelty vs. normality. We formulate the essence of such approach as a quadruplet domain translation with an intrinsic bias to only query for a proxy of conditional data uncertainty. Accordingly, an improvement direction is formalized as maximumly compressing the autoencoder's latent space while ensuring its reconstructive power for acting as a described domain translator. From it, strategies are introduced including semantic reconstruction, data certainty decomposition and normalized L2 distance to substantially improve original methods, which together establish state-of-the-art performance on various benchmarks, e.g., the FPR@95%TPR of CIFAR-100 vs. TinyImagenet-crop on Wide-ResNet is 0.2%. Importantly, our method works without any addit",
    "link": "http://arxiv.org/abs/2203.02194",
    "context": "Title: Rethinking Reconstruction Autoencoder-Based Out-of-Distribution Detection. (arXiv:2203.02194v3 [cs.CV] UPDATED)\nAbstract: In some scenarios, classifier requires detecting out-of-distribution samples far from its training data. With desirable characteristics, reconstruction autoencoder-based methods deal with this problem by using input reconstruction error as a metric of novelty vs. normality. We formulate the essence of such approach as a quadruplet domain translation with an intrinsic bias to only query for a proxy of conditional data uncertainty. Accordingly, an improvement direction is formalized as maximumly compressing the autoencoder's latent space while ensuring its reconstructive power for acting as a described domain translator. From it, strategies are introduced including semantic reconstruction, data certainty decomposition and normalized L2 distance to substantially improve original methods, which together establish state-of-the-art performance on various benchmarks, e.g., the FPR@95%TPR of CIFAR-100 vs. TinyImagenet-crop on Wide-ResNet is 0.2%. Importantly, our method works without any addit",
    "path": "papers/22/03/2203.02194.json",
    "total_tokens": 968,
    "translated_title": "重新思考基于重构自编码器的外样本检测",
    "translated_abstract": "在某些情况下，分类器需要检测远离其训练数据的外样本。重构自编码器方法利用输入重构误差作为新颖性与正常性的度量来解决这个问题。我们将这种方法的本质表述为具有对条件数据不确定性的代理查询的四元组域转换，其有内在偏见。因此，一种改进方向被形式化为最大压缩自编码器的潜空间，同时确保其重构能力，以充当所描述的域转换器。从中，引入了策略，包括语义重构、数据确定性分解和标准化L2距离，以实质性改善原始方法，这些方法共同在各种基准测试中建立了最先进的性能，例如，在Wide-ResNet上，CIFAR-100与TinyImagenet-crop的FPR@95%TPR为0.2%。重要的是，我们的方法不需要任何额外的标记外样本数据。",
    "tldr": "本文重新考虑了基于重构自编码器方法的外样本检测，在最大压缩自编码器的潜空间和保证重构能力的基础上，通过引入语义重构、数据确定性分解和标准化L2距离等策略，本文提出的方法在各个基准测试中都取得了最先进的性能表现，且不需要额外的标记外样本数据。",
    "en_tdlr": "This paper rethinks out-of-distribution detection based on reconstruction autoencoder methods. By maximizing the compression of the autoencoder's latent space while ensuring its reconstructive power, the proposed method introduces strategies such as semantic reconstruction, data certainty decomposition, and normalized L2 distance to achieve state-of-the-art performance on various benchmarks without requiring additional labeled out-of-distribution data."
}