{
    "title": "A New Basis for Sparse Principal Component Analysis. (arXiv:2007.00596v3 [stat.ML] UPDATED)",
    "abstract": "Previous versions of sparse principal component analysis (PCA) have presumed that the eigen-basis (a $p \\times k$ matrix) is approximately sparse. We propose a method that presumes the $p \\times k$ matrix becomes approximately sparse after a $k \\times k$ rotation. The simplest version of the algorithm initializes with the leading $k$ principal components. Then, the principal components are rotated with an $k \\times k$ orthogonal rotation to make them approximately sparse. Finally, soft-thresholding is applied to the rotated principal components. This approach differs from prior approaches because it uses an orthogonal rotation to approximate a sparse basis. One consequence is that a sparse component need not to be a leading eigenvector, but rather a mixture of them. In this way, we propose a new (rotated) basis for sparse PCA. In addition, our approach avoids \"deflation\" and multiple tuning parameters required for that. Our sparse PCA framework is versatile; for example, it extends nat",
    "link": "http://arxiv.org/abs/2007.00596",
    "context": "Title: A New Basis for Sparse Principal Component Analysis. (arXiv:2007.00596v3 [stat.ML] UPDATED)\nAbstract: Previous versions of sparse principal component analysis (PCA) have presumed that the eigen-basis (a $p \\times k$ matrix) is approximately sparse. We propose a method that presumes the $p \\times k$ matrix becomes approximately sparse after a $k \\times k$ rotation. The simplest version of the algorithm initializes with the leading $k$ principal components. Then, the principal components are rotated with an $k \\times k$ orthogonal rotation to make them approximately sparse. Finally, soft-thresholding is applied to the rotated principal components. This approach differs from prior approaches because it uses an orthogonal rotation to approximate a sparse basis. One consequence is that a sparse component need not to be a leading eigenvector, but rather a mixture of them. In this way, we propose a new (rotated) basis for sparse PCA. In addition, our approach avoids \"deflation\" and multiple tuning parameters required for that. Our sparse PCA framework is versatile; for example, it extends nat",
    "path": "papers/20/07/2007.00596.json",
    "total_tokens": 958,
    "translated_title": "稀疏主成分分析的新基础",
    "translated_abstract": "之前的稀疏主成分分析方法假设特征值基（一个大小为$p \\times k$的矩阵）近似稀疏。我们提出了一种方法，假设在进行$k \\times k$旋转后，特征值基的稀疏性变得近似。算法的简单版本是以前$k$个主成分为初始值，然后使用$k \\times k$正交旋转使主成分近似稀疏，最后对旋转后的主成分进行软阈值处理。该方法与以往方法不同之处在于使用正交旋转来近似稀疏基。一个结果是，稀疏成分不需要是主特征向量，而可以是它们的混合。因此，我们提出了一种新的（旋转后的）稀疏主成分分析基。此外，我们的方法避免了“缩减”和多个调参参数的需求。我们的稀疏主成分分析框架非常灵活，并且可以推广至...",
    "tldr": "我们提出了一种新的方法来进行稀疏主成分分析，该方法使用正交旋转来获得近似稀疏的特征值基。与以往方法不同的是，我们的方法使稀疏成分不需要是主特征向量，而可以是它们的混合。这一方法不需要进行“缩减”操作或使用多个调参参数。",
    "en_tdlr": "We propose a new approach for sparse principal component analysis that utilizes orthogonal rotation to obtain an approximately sparse eigen-basis. Unlike previous methods, our approach allows sparse components to be a mixture of leading eigenvectors, rather than being strictly the leading eigenvectors. This method eliminates the need for deflation and multiple tuning parameters."
}