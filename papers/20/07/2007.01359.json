{
    "title": "A Bayesian Multilingual Document Model for Zero-shot Topic Identification and Discovery",
    "abstract": "arXiv:2007.01359v3 Announce Type: replace  Abstract: In this paper, we present a Bayesian multilingual document model for learning language-independent document embeddings. The model is an extension of BaySMM [Kesiraju et al 2020] to the multilingual scenario. It learns to represent the document embeddings in the form of Gaussian distributions, thereby encoding the uncertainty in its covariance. We propagate the learned uncertainties through linear classifiers that benefit zero-shot cross-lingual topic identification. Our experiments on 17 languages show that the proposed multilingual Bayesian document model performs competitively, when compared to other systems based on large-scale neural networks (LASER, XLM-R, mUSE) on 8 high-resource languages, and outperforms these systems on 9 mid-resource languages. We revisit cross-lingual topic identification in zero-shot settings by taking a deeper dive into current datasets, baseline systems and the languages covered. We identify shortcoming",
    "link": "https://arxiv.org/abs/2007.01359",
    "context": "Title: A Bayesian Multilingual Document Model for Zero-shot Topic Identification and Discovery\nAbstract: arXiv:2007.01359v3 Announce Type: replace  Abstract: In this paper, we present a Bayesian multilingual document model for learning language-independent document embeddings. The model is an extension of BaySMM [Kesiraju et al 2020] to the multilingual scenario. It learns to represent the document embeddings in the form of Gaussian distributions, thereby encoding the uncertainty in its covariance. We propagate the learned uncertainties through linear classifiers that benefit zero-shot cross-lingual topic identification. Our experiments on 17 languages show that the proposed multilingual Bayesian document model performs competitively, when compared to other systems based on large-scale neural networks (LASER, XLM-R, mUSE) on 8 high-resource languages, and outperforms these systems on 9 mid-resource languages. We revisit cross-lingual topic identification in zero-shot settings by taking a deeper dive into current datasets, baseline systems and the languages covered. We identify shortcoming",
    "path": "papers/20/07/2007.01359.json",
    "total_tokens": 933,
    "translated_title": "一种贝叶斯多语言文档模型用于零样本主题识别与发现",
    "translated_abstract": "在本文中，我们提出了一种用于学习与语言无关的文档嵌入的贝叶斯多语言文档模型。该模型是BaySMM[Kesiraju et al 2020]在多语言场景中的扩展。它学习以高斯分布的形式表示文档嵌入，从而编码协方差中的不确定性。我们通过线性分类器传播学到的不确定性，从而有利于零样本跨语言主题识别。我们在17种语言上进行的实验表明，所提出的多语言贝叶斯文档模型在与基于大规模神经网络的其他系统（如LASER、XLM-R、mUSE）相比，对8种高资源语言表现竞争力强，并在9种中资源语言上表现优越。我们通过更深入地研究当前数据集、基准系统和涵盖的语言，重新审视了零样本设定中的跨语言主题识别。我们指出了其中的缺陷。",
    "tldr": "提出了一种贝叶斯多语言文档模型，通过学习文档嵌入的高斯分布形式来编码不确定性，利用学到的不确定性进行零样本跨语言主题识别，在17种不同语言上进行了实验证实该模型在不同资源语言上表现出色",
    "en_tdlr": "Introducing a Bayesian multilingual document model that encodes uncertainty by learning document embeddings in the form of Gaussian distributions, enabling zero-shot cross-lingual topic identification. Experimental results across 17 languages demonstrate competitive performance on high-resource languages and superior performance on mid-resource languages compared to other large-scale neural network systems."
}