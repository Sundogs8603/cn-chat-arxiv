{
    "title": "Human-like Energy Management Based on Deep Reinforcement Learning and Historical Driving Experiences. (arXiv:2007.10126v2 [eess.SY] UPDATED)",
    "abstract": "Development of hybrid electric vehicles depends on an advanced and efficient energy management strategy (EMS). With online and real-time requirements in mind, this article presents a human-like energy management framework for hybrid electric vehicles according to deep reinforcement learning methods and collected historical driving data. The hybrid powertrain studied has a series-parallel topology, and its control-oriented modeling is founded first. Then, the distinctive deep reinforcement learning (DRL) algorithm, named deep deterministic policy gradient (DDPG), is introduced. To enhance the derived power split controls in the DRL framework, the global optimal control trajectories obtained from dynamic programming (DP) are regarded as expert knowledge to train the DDPG model. This operation guarantees the optimality of the proposed control architecture. Moreover, the collected historical driving data based on experienced drivers are employed to replace the DP-based controls, and thus c",
    "link": "http://arxiv.org/abs/2007.10126",
    "context": "Title: Human-like Energy Management Based on Deep Reinforcement Learning and Historical Driving Experiences. (arXiv:2007.10126v2 [eess.SY] UPDATED)\nAbstract: Development of hybrid electric vehicles depends on an advanced and efficient energy management strategy (EMS). With online and real-time requirements in mind, this article presents a human-like energy management framework for hybrid electric vehicles according to deep reinforcement learning methods and collected historical driving data. The hybrid powertrain studied has a series-parallel topology, and its control-oriented modeling is founded first. Then, the distinctive deep reinforcement learning (DRL) algorithm, named deep deterministic policy gradient (DDPG), is introduced. To enhance the derived power split controls in the DRL framework, the global optimal control trajectories obtained from dynamic programming (DP) are regarded as expert knowledge to train the DDPG model. This operation guarantees the optimality of the proposed control architecture. Moreover, the collected historical driving data based on experienced drivers are employed to replace the DP-based controls, and thus c",
    "path": "papers/20/07/2007.10126.json",
    "total_tokens": 910,
    "translated_title": "基于深度强化学习和历史驾驶经验的人类化能量管理",
    "translated_abstract": "混合动力电动车的发展依赖于先进高效的能量管理策略（EMS）。本文提出了一种基于深度强化学习方法和采集的历史驾驶数据的人类化能量管理框架。该研究中的混合动力传动系统采用串联-并联拓扑结构，并首先建立了面向控制的模型。然后引入了独特的深度强化学习算法——深度确定性策略梯度（DDPG）。为了提高深度强化学习框架中的功率分配控制，利用动态规划（DP）获得的全局最优控制轨迹作为专家知识来训练DDPG模型。这个操作确保了所提出的控制架构的最优性。此外，利用基于有经验驾驶员的采集的历史驾驶数据来替代基于DP的控制，从而进一步提升能量管理的性能。",
    "tldr": "本文提出了一种基于深度强化学习和历史驾驶经验的人类化能量管理框架，通过采用深度确定性策略梯度算法和驾驶数据训练模型，提高了混合动力电动车能量管理的性能。",
    "en_tdlr": "This paper proposes a human-like energy management framework based on deep reinforcement learning and historical driving experiences, which improves the performance of energy management in hybrid electric vehicles by using the deep deterministic policy gradient algorithm and training the model with driving data."
}