{
    "title": "Stochastic Low-rank Tensor Bandits for Multi-dimensional Online Decision Making",
    "abstract": "Multi-dimensional online decision making plays a crucial role in many real applications such as online recommendation and digital marketing. In these problems, a decision at each time is a combination of choices from different types of entities. To solve it, we introduce stochastic low-rank tensor bandits, a class of bandits whose mean rewards can be represented as a low-rank tensor. We consider two settings, tensor bandits without context and tensor bandits with context. In the first setting, the platform aims to find the optimal decision with the highest expected reward, a.k.a, the largest entry of true reward tensor. In the second setting, some modes of the tensor are contexts and the rest modes are decisions, and the goal is to find the optimal decision given the contextual information. We propose two learning algorithms tensor elimination and tensor epoch-greedy for tensor bandits without context, and derive finite-time regret bounds for them. Comparing with existing competitive m",
    "link": "https://arxiv.org/abs/2007.15788",
    "context": "Title: Stochastic Low-rank Tensor Bandits for Multi-dimensional Online Decision Making\nAbstract: Multi-dimensional online decision making plays a crucial role in many real applications such as online recommendation and digital marketing. In these problems, a decision at each time is a combination of choices from different types of entities. To solve it, we introduce stochastic low-rank tensor bandits, a class of bandits whose mean rewards can be represented as a low-rank tensor. We consider two settings, tensor bandits without context and tensor bandits with context. In the first setting, the platform aims to find the optimal decision with the highest expected reward, a.k.a, the largest entry of true reward tensor. In the second setting, some modes of the tensor are contexts and the rest modes are decisions, and the goal is to find the optimal decision given the contextual information. We propose two learning algorithms tensor elimination and tensor epoch-greedy for tensor bandits without context, and derive finite-time regret bounds for them. Comparing with existing competitive m",
    "path": "papers/20/07/2007.15788.json",
    "total_tokens": 937,
    "translated_title": "面向多维度在线决策的随机低秩张量赌博算法",
    "translated_abstract": "多维度在线决策在在线推荐和数字营销等实际应用中起着关键作用。在这些问题中，每个时间点的决策是来自不同类型实体的选择的组合。为了解决这个问题，我们引入了随机低秩张量赌博算法，一类其均值收益可表示为低秩张量的赌博算法。我们考虑了两种情况，即没有上下文的张量赌博和有上下文的张量赌博。在第一种情况中，平台旨在找到具有最高期望回报的最佳决策，即真实回报张量的最大条目。在第二种情况中，张量的某些模式是上下文，其余模式是决策，目标是在给定上下文信息的情况下找到最佳决策。我们提出了两种学习算法：张量消除和张量时代贪婪算法，用于没有上下文的张量赌博，并为它们推导了有限时间的遗憾界限。与现有的竞争算法相比，我们的算法表现更好。",
    "tldr": "这项研究提出了一种针对多维度在线决策的随机低秩张量赌博算法。通过考虑有上下文和没有上下文的情况，提出了两种学习算法，并推导了有限时间的遗憾界限。",
    "en_tdlr": "This study introduces a stochastic low-rank tensor bandit algorithm for multi-dimensional online decision making. By considering both contexts and non-contexts scenarios, two learning algorithms are proposed, and finite-time regret bounds are derived."
}