{
    "title": "Quality Inference in Federated Learning with Secure Aggregation. (arXiv:2007.06236v4 [cs.LG] UPDATED)",
    "abstract": "Federated learning algorithms are developed both for efficiency reasons and to ensure the privacy and confidentiality of personal and business data, respectively. Despite no data being shared explicitly, recent studies showed that the mechanism could still leak sensitive information. Hence, secure aggregation is utilized in many real-world scenarios to prevent attribution to specific participants. In this paper, we focus on the quality of individual training datasets and show that such quality information could be inferred and attributed to specific participants even when secure aggregation is applied. Specifically, through a series of image recognition experiments, we infer the relative quality ordering of participants. Moreover, we apply the inferred quality information to detect misbehaviours, to stabilize training performance, and to measure the individual contributions of participants.",
    "link": "http://arxiv.org/abs/2007.06236",
    "context": "Title: Quality Inference in Federated Learning with Secure Aggregation. (arXiv:2007.06236v4 [cs.LG] UPDATED)\nAbstract: Federated learning algorithms are developed both for efficiency reasons and to ensure the privacy and confidentiality of personal and business data, respectively. Despite no data being shared explicitly, recent studies showed that the mechanism could still leak sensitive information. Hence, secure aggregation is utilized in many real-world scenarios to prevent attribution to specific participants. In this paper, we focus on the quality of individual training datasets and show that such quality information could be inferred and attributed to specific participants even when secure aggregation is applied. Specifically, through a series of image recognition experiments, we infer the relative quality ordering of participants. Moreover, we apply the inferred quality information to detect misbehaviours, to stabilize training performance, and to measure the individual contributions of participants.",
    "path": "papers/20/07/2007.06236.json",
    "total_tokens": 869,
    "translated_title": "带有安全聚合的联邦学习中的质量推断",
    "translated_abstract": "为了保障个人和商业数据的隐私和机密性，联邦学习算法既考虑了效率，也注重不共享数据。然而，最近的研究表明，这种机制仍可能泄漏敏感信息。因此，在许多实际情况下，采用安全聚合来防止归因于特定参与者。本文重点研究单个训练数据集的质量，并显示即使应用了安全聚合，这样的质量信息仍可能被推断并归因于具体参与者。具体而言，通过一系列图像识别实验，我们推断参与者的相对质量排序。此外，我们将推断出的质量信息应用于检测不良行为、稳定训练性能以及测量参与者的个人贡献。",
    "tldr": "本文研究了在联邦学习中应用安全聚合后，单个训练集的质量信息仍可能被推断并归因于具体参与者的问题，通过图像识别实验找出了参与者相对的质量排序，进而用于检测不良行为、稳定训练性能以及测量参与者的个人贡献。",
    "en_tdlr": "This paper explores the issue that even with secure aggregation in place, the quality information of individual training datasets in federated learning can still be inferred and attributed to specific participants. Through image recognition experiments, the relative quality ordering of participants is determined and can be applied to detect misbehaviors, stabilize training performance, and measure individual contributions."
}