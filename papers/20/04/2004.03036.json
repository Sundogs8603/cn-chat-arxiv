{
    "title": "Double Debiased Machine Learning Nonparametric Inference with Continuous Treatments. (arXiv:2004.03036v8 [econ.EM] UPDATED)",
    "abstract": "We propose a doubly robust inference method for causal effects of continuous treatment variables, under unconfoundedness and with nonparametric or high-dimensional nuisance functions. Our double debiased machine learning (DML) estimators for the average dose-response function (or the average structural function) and the partial effects are asymptotically normal with non-parametric convergence rates. The first-step estimators for the nuisance conditional expectation function and the conditional density can be nonparametric or ML methods. Utilizing a kernel-based doubly robust moment function and cross-fitting, we give high-level conditions under which the nuisance function estimators do not affect the first-order large sample distribution of the DML estimators. We provide sufficient low-level conditions for kernel, series, and deep neural networks. We justify the use of kernel to localize the continuous treatment at a given value by the Gateaux derivative. We implement various ML method",
    "link": "http://arxiv.org/abs/2004.03036",
    "context": "Title: Double Debiased Machine Learning Nonparametric Inference with Continuous Treatments. (arXiv:2004.03036v8 [econ.EM] UPDATED)\nAbstract: We propose a doubly robust inference method for causal effects of continuous treatment variables, under unconfoundedness and with nonparametric or high-dimensional nuisance functions. Our double debiased machine learning (DML) estimators for the average dose-response function (or the average structural function) and the partial effects are asymptotically normal with non-parametric convergence rates. The first-step estimators for the nuisance conditional expectation function and the conditional density can be nonparametric or ML methods. Utilizing a kernel-based doubly robust moment function and cross-fitting, we give high-level conditions under which the nuisance function estimators do not affect the first-order large sample distribution of the DML estimators. We provide sufficient low-level conditions for kernel, series, and deep neural networks. We justify the use of kernel to localize the continuous treatment at a given value by the Gateaux derivative. We implement various ML method",
    "path": "papers/20/04/2004.03036.json",
    "total_tokens": 881,
    "translated_title": "使用连续治疗进行双重去偏机器学习非参数推断。",
    "translated_abstract": "我们提出了一种双重去偏机器学习方法，用于连续治疗变量的因果效应推断，并在无偏性和非参数或高维度的干扰函数条件下进行。我们的双重去偏机器学习（DML）估计器对于平均剂量响应函数（或平均结构函数）和局部效应是渐近正态的，并具有非参数收敛速度。对于冗余条件期望函数和条件密度的第一步估计器可以是非参数的或最大似然方法。通过利用基于核的双重去偏矩函数和交叉拟合，我们给出了诱导冗余函数估计值不会影响DML估计器的一阶大样本分布的高级条件。我们为核、级数和深度神经网络提供了充分的低级条件。我们通过Gateaux导数来证明了使用核来将连续治疗局部化到给定值的合理性。我们实现了各种机器学习方法。",
    "tldr": "本论文提出了一种双重去偏机器学习方法，用于连续治疗变量的因果效应推断，具有非参数收敛速度，并提供了一些实现细节。",
    "en_tdlr": "This paper proposes a double debiased machine learning method for causal inference of continuous treatment variables, with nonparametric convergence rates. It also provides implementation details and justifies the use of kernel methods for localizing the continuous treatment."
}