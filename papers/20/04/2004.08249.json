{
    "title": "Understanding the Difficulty of Training Transformers. (arXiv:2004.08249v3 [cs.LG] UPDATED)",
    "abstract": "Transformers have proved effective in many NLP tasks. However, their training requires non-trivial efforts regarding designing cutting-edge optimizers and learning rate schedulers carefully (e.g., conventional SGD fails to train Transformers effectively). Our objective here is to understand $\\textit{what complicates Transformer training}$ from both empirical and theoretical perspectives. Our analysis reveals that unbalanced gradients are not the root cause of the instability of training. Instead, we identify an amplification effect that influences training substantially -- for each layer in a multi-layer Transformer model, heavy dependency on its residual branch makes training unstable, since it amplifies small parameter perturbations (e.g., parameter updates) and results in significant disturbances in the model output. Yet we observe that a light dependency limits the model potential and leads to inferior trained models. Inspired by our analysis, we propose Admin ($\\textbf{Ad}$aptive ",
    "link": "http://arxiv.org/abs/2004.08249",
    "context": "Title: Understanding the Difficulty of Training Transformers. (arXiv:2004.08249v3 [cs.LG] UPDATED)\nAbstract: Transformers have proved effective in many NLP tasks. However, their training requires non-trivial efforts regarding designing cutting-edge optimizers and learning rate schedulers carefully (e.g., conventional SGD fails to train Transformers effectively). Our objective here is to understand $\\textit{what complicates Transformer training}$ from both empirical and theoretical perspectives. Our analysis reveals that unbalanced gradients are not the root cause of the instability of training. Instead, we identify an amplification effect that influences training substantially -- for each layer in a multi-layer Transformer model, heavy dependency on its residual branch makes training unstable, since it amplifies small parameter perturbations (e.g., parameter updates) and results in significant disturbances in the model output. Yet we observe that a light dependency limits the model potential and leads to inferior trained models. Inspired by our analysis, we propose Admin ($\\textbf{Ad}$aptive ",
    "path": "papers/20/04/2004.08249.json",
    "total_tokens": 945,
    "translated_title": "理解Transformer训练的困难",
    "translated_abstract": "Transformer在许多自然语言处理任务中被证明是有效的。然而，它们的训练需要设计先进的优化器和学习率调度器的非平凡工作（例如，传统的SGD无法有效训练Transformer）。我们的目标是从经验和理论的角度理解$\\textit{什么使得Transformer的训练变得困难}$。我们的分析表明，不平衡的梯度并不是训练不稳定的根本原因。相反，我们确定了一种影响训练的放大效应--对于多层Transformer模型中的每一层，它对其残差分支的依赖程度较高，导致训练不稳定，因为它放大了小的参数扰动（例如参数更新），并导致模型输出中的显著扰动。然而，我们观察到轻量级的依赖限制了模型的潜力，并导致表现较差的训练模型。在我们的分析启发下，我们提出了Admin（$\\textbf{Ad}$aptive 重述部分",
    "tldr": "该论文研究了Transformer训练的困难。他们发现不平衡的梯度不是训练不稳定的根本原因，而是每一层的放大效应导致训练不稳定。他们观察到轻量级的依赖限制了模型潜力，导致表现较差的训练模型。",
    "en_tdlr": "This paper investigates the difficulty of training Transformers. They find that unbalanced gradients are not the primary cause of training instability, but an amplification effect in each layer that leads to instability. They also observe that a light dependency limits the model potential, resulting in inferior trained models."
}