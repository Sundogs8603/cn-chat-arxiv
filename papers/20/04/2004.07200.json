{
    "title": "Zero-Shot Compositional Policy Learning via Language Grounding. (arXiv:2004.07200v2 [cs.LG] UPDATED)",
    "abstract": "Despite recent breakthroughs in reinforcement learning (RL) and imitation learning (IL), existing algorithms fail to generalize beyond the training environments. In reality, humans can adapt to new tasks quickly by leveraging prior knowledge about the world such as language descriptions. To facilitate the research on language-guided agents with domain adaption, we propose a novel zero-shot compositional policy learning task, where the environments are characterized as a composition of different attributes. Since there are no public environments supporting this study, we introduce a new research platform BabyAI++ in which the dynamics of environments are disentangled from visual appearance. At each episode, BabyAI++ provides varied vision-dynamics combinations along with corresponding descriptive texts. To evaluate the adaption capability of learned agents, a set of vision-dynamics pairings are held-out for testing on BabyAI++. Unsurprisingly, we find that current language-guided RL/IL ",
    "link": "http://arxiv.org/abs/2004.07200",
    "context": "Title: Zero-Shot Compositional Policy Learning via Language Grounding. (arXiv:2004.07200v2 [cs.LG] UPDATED)\nAbstract: Despite recent breakthroughs in reinforcement learning (RL) and imitation learning (IL), existing algorithms fail to generalize beyond the training environments. In reality, humans can adapt to new tasks quickly by leveraging prior knowledge about the world such as language descriptions. To facilitate the research on language-guided agents with domain adaption, we propose a novel zero-shot compositional policy learning task, where the environments are characterized as a composition of different attributes. Since there are no public environments supporting this study, we introduce a new research platform BabyAI++ in which the dynamics of environments are disentangled from visual appearance. At each episode, BabyAI++ provides varied vision-dynamics combinations along with corresponding descriptive texts. To evaluate the adaption capability of learned agents, a set of vision-dynamics pairings are held-out for testing on BabyAI++. Unsurprisingly, we find that current language-guided RL/IL ",
    "path": "papers/20/04/2004.07200.json",
    "total_tokens": 1219,
    "translated_title": "通过语言基础实现零样本组合策略学习",
    "translated_abstract": "尽管强化学习（RL）和模仿学习（IL）在最近都有了突破，但现有算法无法在训练环境之外进行推广。实际上，人类能够通过利用先前关于世界（如语言描述）的知识来快速适应新任务。为了促进带有领域自适应的语言引导代理的研究，我们提出了一项新的零样本组合策略学习任务，其中环境被描述为不同属性的组合。由于没有公共环境支持这项研究，我们介绍了一个新的研究平台BabyAI++，其中环境的动力学与视觉外观解耦。在每个回合中，BabyAI++提供了各种视觉动力学组合以及相应的描述性文本。为了评估所学代理的自适应能力，一组视觉动力学配对被保留在BabyAI++上进行测试。不出所料，我们发现当前的语言引导RL/IL方法无法解决这个零样本组合策略学习任务。因此，我们提出了一种新的语言引导策略学习算法，通过将自然语言描述与策略网络结合，使策略网络能够推广到未见过的属性组合上。为了实现这一目标，我们引入了一种新的语言基础模块，将符号属性表示和自然语言输入集成到策略网络中。我们的实验表明，我们提出的算法在零样本组合策略学习任务上显著优于现有的RL/IL算法。",
    "tldr": "本论文提出了一种通过语言基础实现零样本组合策略学习的算法，该算法将自然语言描述与策略网络结合，使策略网络能够推广到未见过的属性组合上，实验证明该算法在零样本组合策略学习任务中表现优于现有的RL/IL算法。",
    "en_tdlr": "This paper proposes a novel language-guided policy learning algorithm that enables a policy network to generalize to unseen attribute compositions by grounding natural language descriptions into the policy network. The algorithm significantly outperforms state-of-the-art RL/IL algorithms on the zero-shot compositional policy learning task."
}