{
    "title": "STEm-Seg: Spatio-temporal Embeddings for Instance Segmentation in Videos. (arXiv:2003.08429v4 [cs.CV] UPDATED)",
    "abstract": "Existing methods for instance segmentation in videos typically involve multi-stage pipelines that follow the tracking-by-detection paradigm and model a video clip as a sequence of images. Multiple networks are used to detect objects in individual frames, and then associate these detections over time. Hence, these methods are often non-end-to-end trainable and highly tailored to specific tasks. In this paper, we propose a different approach that is well-suited to a variety of tasks involving instance segmentation in videos. In particular, we model a video clip as a single 3D spatio-temporal volume, and propose a novel approach that segments and tracks instances across space and time in a single stage. Our problem formulation is centered around the idea of spatio-temporal embeddings which are trained to cluster pixels belonging to a specific object instance over an entire video clip. To this end, we introduce (i) novel mixing functions that enhance the feature representation of spatio-te",
    "link": "http://arxiv.org/abs/2003.08429",
    "context": "Title: STEm-Seg: Spatio-temporal Embeddings for Instance Segmentation in Videos. (arXiv:2003.08429v4 [cs.CV] UPDATED)\nAbstract: Existing methods for instance segmentation in videos typically involve multi-stage pipelines that follow the tracking-by-detection paradigm and model a video clip as a sequence of images. Multiple networks are used to detect objects in individual frames, and then associate these detections over time. Hence, these methods are often non-end-to-end trainable and highly tailored to specific tasks. In this paper, we propose a different approach that is well-suited to a variety of tasks involving instance segmentation in videos. In particular, we model a video clip as a single 3D spatio-temporal volume, and propose a novel approach that segments and tracks instances across space and time in a single stage. Our problem formulation is centered around the idea of spatio-temporal embeddings which are trained to cluster pixels belonging to a specific object instance over an entire video clip. To this end, we introduce (i) novel mixing functions that enhance the feature representation of spatio-te",
    "path": "papers/20/03/2003.08429.json",
    "total_tokens": 957,
    "translated_title": "STEm-Seg: 用于视频实例分割的时空嵌入",
    "translated_abstract": "现有的视频实例分割方法通常涉及多阶段管道，遵循跟踪-检测范式，并将视频剪辑建模为图像序列。多个网络用于检测单个帧中的对象，然后在时间上关联这些检测结果。因此，这些方法通常不是端到端可训练的，并且高度适应特定任务。在本文中，我们提出了一种不同的方法，适用于涉及视频中的实例分割的各种任务。特别是，我们将视频剪辑建模为一个单一的3D时空体，提出了一种新颖的方法，在一个阶段内对空间和时间进行实例分割和跟踪。我们的问题形式化围绕时空嵌入的思想，这些嵌入被训练为在整个视频剪辑中聚类属于特定对象实例的像素。为此，我们引入了增强时空特征表示的新型混合函数。",
    "tldr": "本文提出了一种适用于视频实例分割的新方法，通过将视频剪辑建模为一个时空体，在一个阶段内对空间和时间进行实例分割和跟踪，从而避免了多阶段管道和特定任务的需求。我们引入了时空嵌入的概念，并使用增强特征表示的混合函数来聚类像素，以实现更好的实例分割效果。",
    "en_tdlr": "This paper proposes a novel approach for instance segmentation in videos by modeling a video clip as a spatio-temporal volume, allowing for single-stage segmentation and tracking across space and time. The concept of spatio-temporal embeddings is introduced, and novel mixing functions are used to enhance feature representation and achieve better segmentation results."
}