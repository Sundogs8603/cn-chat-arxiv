{
    "title": "Adversarial Machine Learning: Bayesian Perspectives",
    "abstract": "arXiv:2003.03546v2 Announce Type: replace  Abstract: Adversarial Machine Learning (AML) is emerging as a major field aimed at protecting machine learning (ML) systems against security threats: in certain scenarios there may be adversaries that actively manipulate input data to fool learning systems. This creates a new class of security vulnerabilities that ML systems may face, and a new desirable property called adversarial robustness essential to trust operations based on ML outputs. Most work in AML is built upon a game-theoretic modelling of the conflict between a learning system and an adversary, ready to manipulate input data. This assumes that each agent knows their opponent's interests and uncertainty judgments, facilitating inferences based on Nash equilibria. However, such common knowledge assumption is not realistic in the security scenarios typical of AML. After reviewing such game-theoretic approaches, we discuss the benefits that Bayesian perspectives provide when defendin",
    "link": "https://arxiv.org/abs/2003.03546",
    "context": "Title: Adversarial Machine Learning: Bayesian Perspectives\nAbstract: arXiv:2003.03546v2 Announce Type: replace  Abstract: Adversarial Machine Learning (AML) is emerging as a major field aimed at protecting machine learning (ML) systems against security threats: in certain scenarios there may be adversaries that actively manipulate input data to fool learning systems. This creates a new class of security vulnerabilities that ML systems may face, and a new desirable property called adversarial robustness essential to trust operations based on ML outputs. Most work in AML is built upon a game-theoretic modelling of the conflict between a learning system and an adversary, ready to manipulate input data. This assumes that each agent knows their opponent's interests and uncertainty judgments, facilitating inferences based on Nash equilibria. However, such common knowledge assumption is not realistic in the security scenarios typical of AML. After reviewing such game-theoretic approaches, we discuss the benefits that Bayesian perspectives provide when defendin",
    "path": "papers/20/03/2003.03546.json",
    "total_tokens": 819,
    "translated_title": "对抗机器学习：贝叶斯视角",
    "translated_abstract": "对抗机器学习(AML)正在成为一个重要的领域，旨在保护机器学习(ML)系统免受安全威胁：在某些情况下，可能存在敌对方积极操纵输入数据以欺骗学习系统。 这创造了一类新的安全漏洞，ML系统可能会面临，并引入了一种新的被称为敌对稳健性的可信操作所必需的性质。 大部分AML工作都建立在对抗学习系统和准备操纵输入数据的对手之间冲突的博弈论建模之上。 这假设每个代理都了解对手的兴趣和不确定性判断，从而促进基于Nash均衡的推理。 然而，在AML典型的安全方案中，这种共同知识假设并不现实。 在回顾了这种博弈论方法之后，我们讨论了贝叶斯视角在防御中提供的好处",
    "tldr": "AML旨在保护机器学习系统免受安全威胁，贝叶斯视角为防御提供了新的好处",
    "en_tdlr": "AML aims to protect ML systems against security threats, and Bayesian perspectives provide new benefits for defense."
}