{
    "title": "Gaussian Hierarchical Latent Dirichlet Allocation: Bringing Polysemy Back. (arXiv:2002.10855v2 [stat.ML] UPDATED)",
    "abstract": "Topic models are widely used to discover the latent representation of a set of documents. The two canonical models are latent Dirichlet allocation, and Gaussian latent Dirichlet allocation, where the former uses multinomial distributions over words, and the latter uses multivariate Gaussian distributions over pre-trained word embedding vectors as the latent topic representations, respectively. Compared with latent Dirichlet allocation, Gaussian latent Dirichlet allocation is limited in the sense that it does not capture the polysemy of a word such as ``bank.'' In this paper, we show that Gaussian latent Dirichlet allocation could recover the ability to capture polysemy by introducing a hierarchical structure in the set of topics that the model can use to represent a given document. Our Gaussian hierarchical latent Dirichlet allocation significantly improves polysemy detection compared with Gaussian-based models and provides more parsimonious topic representations compared with hierarch",
    "link": "http://arxiv.org/abs/2002.10855",
    "context": "Title: Gaussian Hierarchical Latent Dirichlet Allocation: Bringing Polysemy Back. (arXiv:2002.10855v2 [stat.ML] UPDATED)\nAbstract: Topic models are widely used to discover the latent representation of a set of documents. The two canonical models are latent Dirichlet allocation, and Gaussian latent Dirichlet allocation, where the former uses multinomial distributions over words, and the latter uses multivariate Gaussian distributions over pre-trained word embedding vectors as the latent topic representations, respectively. Compared with latent Dirichlet allocation, Gaussian latent Dirichlet allocation is limited in the sense that it does not capture the polysemy of a word such as ``bank.'' In this paper, we show that Gaussian latent Dirichlet allocation could recover the ability to capture polysemy by introducing a hierarchical structure in the set of topics that the model can use to represent a given document. Our Gaussian hierarchical latent Dirichlet allocation significantly improves polysemy detection compared with Gaussian-based models and provides more parsimonious topic representations compared with hierarch",
    "path": "papers/20/02/2002.10855.json",
    "total_tokens": 986,
    "translated_title": "高斯分层潜在狄利克雷分配：再现多义词",
    "translated_abstract": "话题模型被广泛应用于发现一组文档的潜在表示。两种典型的模型是潜在狄利克雷分配和高斯潜在狄利克雷分配，前者使用单词上的多项式分布，后者使用预训练的单词嵌入向量上的多元高斯分布作为潜在主题表示。与潜在狄利克雷分配相比，高斯潜在狄利克雷分配在捕捉“银行”等词的多义性方面存在限制。在本文中，我们证明高斯分层潜在狄利克雷分配通过为模型可以用于表示给定文档的主题集合引入层次结构，可以恢复捕捉多义性的能力。我们的高斯分层潜在狄利克雷分配相对于基于高斯的模型显著提高了多义词检测的能力，并提供了比基于潜在狄利克雷分配的层次模型更为简洁的主题表示。",
    "tldr": "本论文提出了一种高斯分层潜在狄利克雷分配模型，通过引入层次结构恢复了捕捉多义性的能力，相对于基于高斯的模型具有更好的多义词检测性能，相对于潜在狄利克雷分配的层次模型具有更加简洁的主题表示。",
    "en_tdlr": "The paper proposes a Gaussian hierarchical latent Dirichlet allocation model that recovers the ability to capture polysemy by introducing a hierarchical structure, and it outperforms Gaussian-based models in polysemy detection and provides more parsimonious topic representations compared with hierarchical models based on latent Dirichlet allocation."
}