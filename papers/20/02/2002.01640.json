{
    "title": "`Why didn't you allocate this task to them?' Negotiation-Aware Explicable Task Allocation and Contrastive Explanation Generation. (arXiv:2002.01640v4 [cs.AI] UPDATED)",
    "abstract": "Task allocation is an important problem in multi-agent systems. It becomes more challenging when the team-members are humans with imperfect knowledge about their teammates' costs and the overall performance metric. In this paper, we propose a centralized Artificial Intelligence Task Allocation (AITA) that simulates a negotiation and produces a negotiation-aware explicable task allocation. If a team-member is unhappy with the proposed allocation, we allow them to question the proposed allocation using a counterfactual. By using parts of the simulated negotiation, we are able to provide contrastive explanations that provide minimum information about other's cost to refute their foil. With human studies, we show that (1) the allocation proposed using our method appears fair to the majority, and (2) when a counterfactual is raised, explanations generated are easy to comprehend and convincing. Finally, we empirically study the effect of different kinds of incompleteness on the explanation-l",
    "link": "http://arxiv.org/abs/2002.01640",
    "context": "Title: `Why didn't you allocate this task to them?' Negotiation-Aware Explicable Task Allocation and Contrastive Explanation Generation. (arXiv:2002.01640v4 [cs.AI] UPDATED)\nAbstract: Task allocation is an important problem in multi-agent systems. It becomes more challenging when the team-members are humans with imperfect knowledge about their teammates' costs and the overall performance metric. In this paper, we propose a centralized Artificial Intelligence Task Allocation (AITA) that simulates a negotiation and produces a negotiation-aware explicable task allocation. If a team-member is unhappy with the proposed allocation, we allow them to question the proposed allocation using a counterfactual. By using parts of the simulated negotiation, we are able to provide contrastive explanations that provide minimum information about other's cost to refute their foil. With human studies, we show that (1) the allocation proposed using our method appears fair to the majority, and (2) when a counterfactual is raised, explanations generated are easy to comprehend and convincing. Finally, we empirically study the effect of different kinds of incompleteness on the explanation-l",
    "path": "papers/20/02/2002.01640.json",
    "total_tokens": 921,
    "translated_title": "“你为什么不把这个任务分配给他们？”：考虑谈判的可解释任务分配和对比解释生成",
    "translated_abstract": "任务分配是多智能体系统中的一个重要问题。当团队成员具有不完整的关于队友成本和整体性能指标的知识时，问题变得更加具有挑战性。本文提出了一种集中式人工智能任务分配（AITA），该系统模拟谈判，并产生考虑谈判的可解释任务分配。如果团队成员对所提议的分配不满意，我们允许他们使用对事实的反问来质疑所提出的分配。通过使用模拟谈判的一部分，我们能够提供对比解释，最小限度地提供有关其他成本的信息以反驳他们的假设。通过人类研究，我们表明（1）使用我们的方法提出的分配对大多数人来说显得公平，（2）当提出反事实情况时，生成的解释易于理解并且令人信服。最后，我们从实证的角度研究了不同类型的不完整性对解释-学习的影响。",
    "tldr": "本文提出一种考虑谈判的任务分配系统，在任务分配过程中允许成员提出反问。通过模拟谈判，生成对比解释，该方法被证明公平且易于理解。",
    "en_tdlr": "This paper proposes a negotiation-aware task allocation system that allows team-members to question the proposed allocation using a counterfactual. The system generates contrastive explanations based on simulated negotiation, and is demonstrated to be fair and easy to comprehend."
}