{
    "title": "Learning to Switch Among Agents in a Team via 2-Layer Markov Decision Processes. (arXiv:2002.04258v3 [cs.LG] UPDATED)",
    "abstract": "Reinforcement learning agents have been mostly developed and evaluated under the assumption that they will operate in a fully autonomous manner -- they will take all actions. In this work, our goal is to develop algorithms that, by learning to switch control between agents, allow existing reinforcement learning agents to operate under different automation levels. To this end, we first formally define the problem of learning to switch control among agents in a team via a 2-layer Markov decision process. Then, we develop an online learning algorithm that uses upper confidence bounds on the agents' policies and the environment's transition probabilities to find a sequence of switching policies. The total regret of our algorithm with respect to the optimal switching policy is sublinear in the number of learning steps and, whenever multiple teams of agents operate in a similar environment, our algorithm greatly benefits from maintaining shared confidence bounds for the environments' transit",
    "link": "http://arxiv.org/abs/2002.04258",
    "context": "Title: Learning to Switch Among Agents in a Team via 2-Layer Markov Decision Processes. (arXiv:2002.04258v3 [cs.LG] UPDATED)\nAbstract: Reinforcement learning agents have been mostly developed and evaluated under the assumption that they will operate in a fully autonomous manner -- they will take all actions. In this work, our goal is to develop algorithms that, by learning to switch control between agents, allow existing reinforcement learning agents to operate under different automation levels. To this end, we first formally define the problem of learning to switch control among agents in a team via a 2-layer Markov decision process. Then, we develop an online learning algorithm that uses upper confidence bounds on the agents' policies and the environment's transition probabilities to find a sequence of switching policies. The total regret of our algorithm with respect to the optimal switching policy is sublinear in the number of learning steps and, whenever multiple teams of agents operate in a similar environment, our algorithm greatly benefits from maintaining shared confidence bounds for the environments' transit",
    "path": "papers/20/02/2002.04258.json",
    "total_tokens": 1008,
    "translated_title": "通过2层马尔可夫决策过程学习在团队中切换代理的方法",
    "translated_abstract": "强化学习代理在通常以完全自主的方式工作的假设下开发和评估 - 它们将采取所有行动。本文的目标是开发算法，通过学习在代理之间切换控制，使现有的强化学习代理能够在不同的自动化水平下工作。为此，我们首先正式定义了通过2层马尔可夫决策过程在团队中学习切换控制的问题。然后，我们使用代理的策略和环境的转移概率的上置信界开发了一种在线学习算法，以找到一系列切换策略。我们的算法相对于最佳切换策略的总遗憾在学习步骤的数量上是次线性的，并且每当多个代理团队在相似的环境中运行时，我们的算法从维护环境的共享置信界中获得很大的好处。",
    "tldr": "本文研究了在团队中学习切换代理控制的问题，并开发了一种在线学习算法，通过学习代理的策略和环境的转移概率，在不同自动化水平下使现有的强化学习代理能够工作。该算法的总遗憾与最佳切换策略相比是次线性的，当多个代理团队在相似环境中运行时，该算法从维护环境的共享置信界中获益匪浅。",
    "en_tdlr": "This paper studies the problem of learning to switch control among agents in a team and develops an online learning algorithm that enables existing reinforcement learning agents to operate under different levels of automation by learning the agents' policies and environment's transition probabilities. The algorithm's total regret with respect to the optimal switching policy is sublinear, and it greatly benefits from maintaining shared confidence bounds for the environments when multiple agent teams operate in similar environments."
}