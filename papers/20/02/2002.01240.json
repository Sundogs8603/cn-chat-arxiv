{
    "title": "Learning rewards for robotic ultrasound scanning using probabilistic temporal ranking. (arXiv:2002.01240v3 [cs.RO] UPDATED)",
    "abstract": "Informative path-planning is a well established approach to visual-servoing and active viewpoint selection in robotics, but typically assumes that a suitable cost function or goal state is known. This work considers the inverse problem, where the goal of the task is unknown, and a reward function needs to be inferred from exploratory example demonstrations provided by a demonstrator, for use in a downstream informative path-planning policy. Unfortunately, many existing reward inference strategies are unsuited to this class of problems, due to the exploratory nature of the demonstrations. In this paper, we propose an alternative approach to cope with the class of problems where these sub-optimal, exploratory demonstrations occur. We hypothesise that, in tasks which require discovery, successive states of any demonstration are progressively more likely to be associated with a higher reward, and use this hypothesis to generate time-based binary comparison outcomes and infer reward functio",
    "link": "http://arxiv.org/abs/2002.01240",
    "context": "Title: Learning rewards for robotic ultrasound scanning using probabilistic temporal ranking. (arXiv:2002.01240v3 [cs.RO] UPDATED)\nAbstract: Informative path-planning is a well established approach to visual-servoing and active viewpoint selection in robotics, but typically assumes that a suitable cost function or goal state is known. This work considers the inverse problem, where the goal of the task is unknown, and a reward function needs to be inferred from exploratory example demonstrations provided by a demonstrator, for use in a downstream informative path-planning policy. Unfortunately, many existing reward inference strategies are unsuited to this class of problems, due to the exploratory nature of the demonstrations. In this paper, we propose an alternative approach to cope with the class of problems where these sub-optimal, exploratory demonstrations occur. We hypothesise that, in tasks which require discovery, successive states of any demonstration are progressively more likely to be associated with a higher reward, and use this hypothesis to generate time-based binary comparison outcomes and infer reward functio",
    "path": "papers/20/02/2002.01240.json",
    "total_tokens": 816,
    "translated_title": "利用概率时序排名学习医用超声扫描机器人奖励",
    "translated_abstract": "信息化路径规划是机器人视觉伺服和主动视点选择的一种成熟方法，但通常假定已知适当的成本函数或目标状态。本文考虑了逆问题，即任务的目标未知，需要从示教者提供的探索性示例演示中推断出奖励函数，以在下游信息化路径规划策略中使用。然而，由于探索性示范的性质，许多现有的奖励推断策略不适用于这类问题。在本文中，我们提出了一种应对这类问题的替代方法。我们假设，在需要发现的任务中，任何演示的连续状态越来越可能与更高的奖励关联，并使用该假设生成基于时间的二进制比较结果，推断出奖励函数。",
    "tldr": "本文提出了一种利用概率时序排名的方法，从探索性演示中推断医用超声扫描机器人任务的奖励函数。"
}