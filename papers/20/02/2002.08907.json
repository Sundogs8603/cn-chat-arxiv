{
    "title": "Second-order Conditional Gradient Sliding. (arXiv:2002.08907v3 [math.OC] UPDATED)",
    "abstract": "Constrained second-order convex optimization algorithms are the method of choice when a high accuracy solution to a problem is needed, due to their local quadratic convergence. These algorithms require the solution of a constrained quadratic subproblem at every iteration. We present the \\emph{Second-Order Conditional Gradient Sliding} (SOCGS) algorithm, which uses a projection-free algorithm to solve the constrained quadratic subproblems inexactly. When the feasible region is a polytope the algorithm converges quadratically in primal gap after a finite number of linearly convergent iterations. Once in the quadratic regime the SOCGS algorithm requires $\\mathcal{O}(\\log(\\log 1/\\varepsilon))$ first-order and Hessian oracle calls and $\\mathcal{O}(\\log (1/\\varepsilon) \\log(\\log1/\\varepsilon))$ linear minimization oracle calls to achieve an $\\varepsilon$-optimal solution. This algorithm is useful when the feasible region can only be accessed efficiently through a linear optimization oracle, ",
    "link": "http://arxiv.org/abs/2002.08907",
    "context": "Title: Second-order Conditional Gradient Sliding. (arXiv:2002.08907v3 [math.OC] UPDATED)\nAbstract: Constrained second-order convex optimization algorithms are the method of choice when a high accuracy solution to a problem is needed, due to their local quadratic convergence. These algorithms require the solution of a constrained quadratic subproblem at every iteration. We present the \\emph{Second-Order Conditional Gradient Sliding} (SOCGS) algorithm, which uses a projection-free algorithm to solve the constrained quadratic subproblems inexactly. When the feasible region is a polytope the algorithm converges quadratically in primal gap after a finite number of linearly convergent iterations. Once in the quadratic regime the SOCGS algorithm requires $\\mathcal{O}(\\log(\\log 1/\\varepsilon))$ first-order and Hessian oracle calls and $\\mathcal{O}(\\log (1/\\varepsilon) \\log(\\log1/\\varepsilon))$ linear minimization oracle calls to achieve an $\\varepsilon$-optimal solution. This algorithm is useful when the feasible region can only be accessed efficiently through a linear optimization oracle, ",
    "path": "papers/20/02/2002.08907.json",
    "total_tokens": 887,
    "translated_title": "二阶条件梯度滑动",
    "translated_abstract": "当需要高精度解决问题时，约束二阶凸优化算法是首选，因为它们具有局部二次收敛性。这些算法在每次迭代时需要解决一个约束二次子问题。我们提出了\\emph{二阶条件梯度滑动}（SOCGS）算法，它使用一种无投影算法来近似解决约束二次子问题。当可行域是一个多面体时，该算法在有限次线性收敛迭代后二次收敛于原始间隙。进入二次收敛阶段后，SOCGS算法需通过$\\mathcal{O}(\\log(\\log 1/\\varepsilon))$次一阶和Hessian正交调用以及$\\mathcal{O}(\\log (1/\\varepsilon) \\log(\\log1/\\varepsilon))$次线性最小化正交调用来实现$\\varepsilon$-最优解。当可行域只能通过线性优化正交调用高效访问时，此算法非常有用。",
    "tldr": "提出了一种二阶条件梯度滑动（SOCGS）算法，可以高效解决约束二次凸优化问题，并在有限次线性收敛迭代后二次收敛于原始间隙。"
}