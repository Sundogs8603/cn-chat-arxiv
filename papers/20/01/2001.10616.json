{
    "title": "On Newton Screening. (arXiv:2001.10616v3 [stat.ML] UPDATED)",
    "abstract": "Screening and working set techniques are important approaches to reducing the size of an optimization problem. They have been widely used in accelerating first-order methods for solving large-scale sparse learning problems. In this paper, we develop a new screening method called Newton screening (NS) which is a generalized Newton method with a built-in screening mechanism. We derive an equivalent KKT system for the Lasso and utilize a generalized Newton method to solve the KKT equations. Based on this KKT system, a built-in working set with a relatively small size is first determined using the sum of primal and dual variables generated from the previous iteration, then the primal variable is updated by solving a least-squares problem on the working set and the dual variable updated based on a closed-form expression. Moreover, we consider a sequential version of Newton screening (SNS) with a warm-start strategy. We show that NS possesses an optimal convergence property in the sense that",
    "link": "http://arxiv.org/abs/2001.10616",
    "context": "Title: On Newton Screening. (arXiv:2001.10616v3 [stat.ML] UPDATED)\nAbstract: Screening and working set techniques are important approaches to reducing the size of an optimization problem. They have been widely used in accelerating first-order methods for solving large-scale sparse learning problems. In this paper, we develop a new screening method called Newton screening (NS) which is a generalized Newton method with a built-in screening mechanism. We derive an equivalent KKT system for the Lasso and utilize a generalized Newton method to solve the KKT equations. Based on this KKT system, a built-in working set with a relatively small size is first determined using the sum of primal and dual variables generated from the previous iteration, then the primal variable is updated by solving a least-squares problem on the working set and the dual variable updated based on a closed-form expression. Moreover, we consider a sequential version of Newton screening (SNS) with a warm-start strategy. We show that NS possesses an optimal convergence property in the sense that",
    "path": "papers/20/01/2001.10616.json",
    "total_tokens": 864,
    "translated_title": "论牛顿筛选法",
    "translated_abstract": "筛选和工作集技术是减小优化问题规模的重要方法，已广泛应用于加速解决大规模稀疏学习问题的一阶方法中。本文提出了一种新的筛选方法，称为牛顿筛选法（NS），它是一种带有内置筛选机制的广义牛顿方法。我们推导了基于等效KKT系统的Lasso模型，利用广义牛顿方法来求解KKT方程组。基于这个KKT系统，首先利用上一次迭代生成的原始和对偶变量之和确定一个具有相对较小大小的内置工作集，然后通过在工作集上求解最小二乘问题来更新原始变量，并基于闭式表达式更新对偶变量。此外，我们提出了一个带有热启动策略的牛顿筛选法的连续版本。我们证明了NS在最优收敛性方面具有优异的性质。",
    "tldr": "本文提出了一种称为牛顿筛选法的新型Broad-Newton方法，它带有一个内置的较小的工作集，可用于加速解决大规模稀疏学习问题的一阶方法。",
    "en_tdlr": "This paper proposes a new screening method called Newton screening (NS), which is a generalized Newton method with a built-in screening mechanism. NS possesses an optimal convergence property and has a relatively small built-in working set, making it a useful tool for solving large-scale sparse learning problems with accelerated first-order methods."
}