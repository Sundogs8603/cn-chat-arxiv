{
    "title": "Adaptive Stopping Rule for Kernel-based Gradient Descent Algorithms. (arXiv:2001.02879v2 [cs.LG] UPDATED)",
    "abstract": "In this paper, we propose an adaptive stopping rule for kernel-based gradient descent (KGD) algorithms. We introduce the empirical effective dimension to quantify the increments of iterations in KGD and derive an implementable early stopping strategy. We analyze the performance of the adaptive stopping rule in the framework of learning theory. Using the recently developed integral operator approach, we rigorously prove the optimality of the adaptive stopping rule in terms of showing the optimal learning rates for KGD equipped with this rule. Furthermore, a sharp bound on the number of iterations in KGD equipped with the proposed early stopping rule is also given to demonstrate its computational advantage.",
    "link": "http://arxiv.org/abs/2001.02879",
    "context": "Title: Adaptive Stopping Rule for Kernel-based Gradient Descent Algorithms. (arXiv:2001.02879v2 [cs.LG] UPDATED)\nAbstract: In this paper, we propose an adaptive stopping rule for kernel-based gradient descent (KGD) algorithms. We introduce the empirical effective dimension to quantify the increments of iterations in KGD and derive an implementable early stopping strategy. We analyze the performance of the adaptive stopping rule in the framework of learning theory. Using the recently developed integral operator approach, we rigorously prove the optimality of the adaptive stopping rule in terms of showing the optimal learning rates for KGD equipped with this rule. Furthermore, a sharp bound on the number of iterations in KGD equipped with the proposed early stopping rule is also given to demonstrate its computational advantage.",
    "path": "papers/20/01/2001.02879.json",
    "total_tokens": 777,
    "translated_title": "基于内核的梯度下降算法的自适应停止准则",
    "translated_abstract": "本文提出了基于内核的梯度下降算法的自适应停止准则。我们引入了经验有效维度来量化KGD迭代的增量并推导出可实施的提前停止策略。我们在学习理论框架下分析了自适应停止准则的性能。使用最近发展的积分算子方法，我们严格证明了配备此规则的KGD的最优学习速率的最优性。此外，我们还给出了配备所述提前停止规则的KGD的迭代次数的尖锐界限，以说明其计算优势。",
    "tldr": "本文提出了一种自适应的内核梯度下降算法的停止准则，使用经验有效维度来量化增量并推导出可执行的提前停止策略。通过使用积分算子方法得出证明，规则具有优化学习速率的最优性，并且提出的停止策略具有计算上的优势。",
    "en_tdlr": "This paper proposes an adaptive stopping rule for kernel-based gradient descent algorithms, using empirical effective dimension to quantify increments and derive an implementable early stopping strategy. The optimality of the rule in terms of learning rate is rigorously proven using the integral operator approach, and a sharp bound on the number of iterations is given to demonstrate its computational advantage."
}