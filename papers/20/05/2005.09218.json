{
    "title": "Large Margin Mechanism and Pseudo Query Set on Cross-Domain Few-Shot Learning",
    "abstract": "In recent years, few-shot learning problems have received a lot of attention. While methods in most previous works were trained and tested on datasets in one single domain, cross-domain few-shot learning is a brand-new branch of few-shot learning problems, where models handle datasets in different domains between training and testing phases. In this paper, to solve the problem that the model is pre-trained (meta-trained) on a single dataset while fine-tuned on datasets in four different domains, including common objects, satellite images, and medical images, we propose a novel large margin fine-tuning method (LMM-PQS), which generates pseudo query images from support images and fine-tunes the feature extraction modules with a large margin mechanism inspired by methods in face recognition. According to the experiment results, LMM-PQS surpasses the baseline models by a significant margin and demonstrates that our approach is robust and can easily adapt pre-trained models to new domains w",
    "link": "https://arxiv.org/abs/2005.09218",
    "context": "Title: Large Margin Mechanism and Pseudo Query Set on Cross-Domain Few-Shot Learning\nAbstract: In recent years, few-shot learning problems have received a lot of attention. While methods in most previous works were trained and tested on datasets in one single domain, cross-domain few-shot learning is a brand-new branch of few-shot learning problems, where models handle datasets in different domains between training and testing phases. In this paper, to solve the problem that the model is pre-trained (meta-trained) on a single dataset while fine-tuned on datasets in four different domains, including common objects, satellite images, and medical images, we propose a novel large margin fine-tuning method (LMM-PQS), which generates pseudo query images from support images and fine-tunes the feature extraction modules with a large margin mechanism inspired by methods in face recognition. According to the experiment results, LMM-PQS surpasses the baseline models by a significant margin and demonstrates that our approach is robust and can easily adapt pre-trained models to new domains w",
    "path": "papers/20/05/2005.09218.json",
    "total_tokens": 1000,
    "translated_title": "基于大边际机制和伪查询集的跨域少样本学习",
    "translated_abstract": "近年来，少样本学习问题引起了广泛的关注。然而，大多数以前的方法都是在单一领域的数据集上进行训练和测试，跨域少样本学习是少样本学习问题的一个全新分支，其中模型在训练和测试阶段处理不同领域的数据集。在本文中，为了解决在单个数据集上进行预训练（元训练）而在包括普通物体、卫星图像和医学图像在内的四个不同领域的数据集上进行微调的问题，我们提出了一种新颖的大边际微调方法（LMM-PQS）。该方法通过支持图像生成伪查询图像，并借鉴人脸识别方法中的大边际机制对特征提取模块进行微调。根据实验结果，LMM-PQS在比基准模型上取得了显著的优势，并证明了我们的方法具有鲁棒性，并能够轻松地将预训练模型适应新的领域。",
    "tldr": "本文提出了一种基于大边际机制和伪查询集的跨域少样本学习方法，通过生成伪查询图像，并借鉴人脸识别方法中的大边际机制对特征提取模块进行微调。实验证明，该方法在各个领域上都取得了显著的优势，展示了其鲁棒性和适应预训练模型到新领域的能力。",
    "en_tdlr": "This paper proposes a cross-domain few-shot learning method based on a large margin mechanism and a pseudo query set. The method generates pseudo query images from support images and fine-tunes the feature extraction modules using a large margin mechanism inspired by face recognition methods. Experimental results demonstrate the significant advantages of the proposed method in various domains, showing its robustness and ability to adapt pre-trained models to new domains."
}