{
    "title": "Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model. (arXiv:2005.12900v7 [cs.LG] UPDATED)",
    "abstract": "This paper is concerned with the sample efficiency of reinforcement learning, assuming access to a generative model (or simulator). We first consider $\\gamma$-discounted infinite-horizon Markov decision processes (MDPs) with state space $\\mathcal{S}$ and action space $\\mathcal{A}$. Despite a number of prior works tackling this problem, a complete picture of the trade-offs between sample complexity and statistical accuracy is yet to be determined. In particular, all prior results suffer from a severe sample size barrier, in the sense that their claimed statistical guarantees hold only when the sample size exceeds at least $\\frac{|\\mathcal{S}||\\mathcal{A}|}{(1-\\gamma)^2}$. The current paper overcomes this barrier by certifying the minimax optimality of two algorithms -- a perturbed model-based algorithm and a conservative model-based algorithm -- as soon as the sample size exceeds the order of $\\frac{|\\mathcal{S}||\\mathcal{A}|}{1-\\gamma}$ (modulo some log factor). Moving beyond infinite-",
    "link": "http://arxiv.org/abs/2005.12900",
    "context": "Title: Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model. (arXiv:2005.12900v7 [cs.LG] UPDATED)\nAbstract: This paper is concerned with the sample efficiency of reinforcement learning, assuming access to a generative model (or simulator). We first consider $\\gamma$-discounted infinite-horizon Markov decision processes (MDPs) with state space $\\mathcal{S}$ and action space $\\mathcal{A}$. Despite a number of prior works tackling this problem, a complete picture of the trade-offs between sample complexity and statistical accuracy is yet to be determined. In particular, all prior results suffer from a severe sample size barrier, in the sense that their claimed statistical guarantees hold only when the sample size exceeds at least $\\frac{|\\mathcal{S}||\\mathcal{A}|}{(1-\\gamma)^2}$. The current paper overcomes this barrier by certifying the minimax optimality of two algorithms -- a perturbed model-based algorithm and a conservative model-based algorithm -- as soon as the sample size exceeds the order of $\\frac{|\\mathcal{S}||\\mathcal{A}|}{1-\\gamma}$ (modulo some log factor). Moving beyond infinite-",
    "path": "papers/20/05/2005.12900.json",
    "total_tokens": 1036,
    "translated_title": "用生成模型突破模型驱动强化学习中的样本大小障碍",
    "translated_abstract": "本论文着眼于在有生成模型（或模拟器）的情况下，增强学习的样本效率。首先，考虑带有折扣的无限时间步长马尔科夫决策过程（MDP），其状态空间为$\\mathcal{S}$，动作空间为$\\mathcal{A}$。尽管有许多先前的研究在解决这个问题，但是在样本复杂度和统计精度之间权衡的完整图景尚未确定。特别是，所有的先前结果都受到严重的样本大小障碍，因为它们声称的统计保证仅在样本大小超过至少$\\frac{|\\mathcal{S}||\\mathcal{A}|}{(1-\\gamma)^2}$时才成立。本文通过证明两个算法——扰动模型驱动算法和保守模型驱动算法——在样本大小超过$\\frac{|\\mathcal{S}||\\mathcal{A}|}{1-\\gamma}$的情况下就能证明它们的极小化最大算法优化性能（几乎符合一些对数因子）。除了无限时间步长M解决方案之外，我们还考虑了有限样本和近似价值迭代问题，以在实践中实现算法的应用。",
    "tldr": "本文提出了两个算法——扰动模型驱动算法和保守模型驱动算法，通过生成模型在较小的样本大小下证明了它们的极小化最大算法优化性能。"
}