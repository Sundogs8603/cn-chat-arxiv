{
    "title": "A Survey on Visual Transformer. (arXiv:2012.12556v6 [cs.CV] UPDATED)",
    "abstract": "Transformer, first applied to the field of natural language processing, is a type of deep neural network mainly based on the self-attention mechanism. Thanks to its strong representation capabilities, researchers are looking at ways to apply transformer to computer vision tasks. In a variety of visual benchmarks, transformer-based models perform similar to or better than other types of networks such as convolutional and recurrent neural networks. Given its high performance and less need for vision-specific inductive bias, transformer is receiving more and more attention from the computer vision community. In this paper, we review these vision transformer models by categorizing them in different tasks and analyzing their advantages and disadvantages. The main categories we explore include the backbone network, high/mid-level vision, low-level vision, and video processing. We also include efficient transformer methods for pushing transformer into real device-based applications. Furthermo",
    "link": "http://arxiv.org/abs/2012.12556",
    "context": "Title: A Survey on Visual Transformer. (arXiv:2012.12556v6 [cs.CV] UPDATED)\nAbstract: Transformer, first applied to the field of natural language processing, is a type of deep neural network mainly based on the self-attention mechanism. Thanks to its strong representation capabilities, researchers are looking at ways to apply transformer to computer vision tasks. In a variety of visual benchmarks, transformer-based models perform similar to or better than other types of networks such as convolutional and recurrent neural networks. Given its high performance and less need for vision-specific inductive bias, transformer is receiving more and more attention from the computer vision community. In this paper, we review these vision transformer models by categorizing them in different tasks and analyzing their advantages and disadvantages. The main categories we explore include the backbone network, high/mid-level vision, low-level vision, and video processing. We also include efficient transformer methods for pushing transformer into real device-based applications. Furthermo",
    "path": "papers/20/12/2012.12556.json",
    "total_tokens": 910,
    "translated_title": "关于视觉Transformer的调查",
    "translated_abstract": "Transformer是一种基于自注意机制的深度神经网络，最初应用于自然语言处理领域。由于其强大的表示能力，研究人员正在探索将Transformer应用于计算机视觉任务的方法。在各种视觉基准中，基于Transformer的模型表现接近或优于卷积和递归神经网络等其他类型的网络。由于其高性能和较少需要视觉特定的归纳偏见，Transformer越来越受到计算机视觉社区的关注。在本文中，我们通过对不同任务进行分类和分析其优缺点的方式来回顾这些视觉Transformer模型。我们探索的主要类别包括骨干网络、高/中层视觉、低层视觉和视频处理。我们还包括了将Transformer推向真实设备应用的高效方法。",
    "tldr": "这篇论文调查了视觉Transformer的应用。Transformer是一种基于自注意机制的深度神经网络，可在计算机视觉任务中具有较好的性能和较少视觉特定的偏见。本文对不同任务下的视觉Transformer模型进行了分类和分析，包括骨干网络、高/中层视觉、低层视觉和视频处理。同时还介绍了将Transformer应用于真实设备的高效方法。",
    "en_tdlr": "This paper surveys the application of visual Transformer models, which are deep neural networks based on self-attention mechanism, in computer vision tasks. Transformer models show promising performance and less vision-specific bias. The paper categorizes and analyzes these models for different tasks, including backbone networks, high/mid-level vision, low-level vision, and video processing. Efficient methods for implementing Transformer on real devices are also discussed."
}