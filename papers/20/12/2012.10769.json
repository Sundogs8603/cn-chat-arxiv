{
    "title": "Augmentation Inside the Network. (arXiv:2012.10769v2 [cs.CV] UPDATED)",
    "abstract": "In this paper, we present augmentation inside the network, a method that simulates data augmentation techniques for computer vision problems on intermediate features of a convolutional neural network. We perform these transformations, changing the data flow through the network, and sharing common computations when it is possible. Our method allows us to obtain smoother speed-accuracy trade-off adjustment and achieves better results than using standard test-time augmentation (TTA) techniques. Additionally, our approach can improve model performance even further when coupled with test-time augmentation. We validate our method on the ImageNet-2012 and CIFAR-100 datasets for image classification. We propose a modification that is 30% faster than the flip test-time augmentation and achieves the same results for CIFAR-100.",
    "link": "http://arxiv.org/abs/2012.10769",
    "context": "Title: Augmentation Inside the Network. (arXiv:2012.10769v2 [cs.CV] UPDATED)\nAbstract: In this paper, we present augmentation inside the network, a method that simulates data augmentation techniques for computer vision problems on intermediate features of a convolutional neural network. We perform these transformations, changing the data flow through the network, and sharing common computations when it is possible. Our method allows us to obtain smoother speed-accuracy trade-off adjustment and achieves better results than using standard test-time augmentation (TTA) techniques. Additionally, our approach can improve model performance even further when coupled with test-time augmentation. We validate our method on the ImageNet-2012 and CIFAR-100 datasets for image classification. We propose a modification that is 30% faster than the flip test-time augmentation and achieves the same results for CIFAR-100.",
    "path": "papers/20/12/2012.10769.json",
    "total_tokens": 816,
    "translated_title": "网络内数据增强方法",
    "translated_abstract": "本文提出了一种“网络内数据增强”方法，它可以在卷积神经网络的中间层模拟数据增强技术，通过变换数据流，并在可能时共享计算。该方法允许我们获得更平滑的速度-准确率折衷调整，比使用标准测试时间增强（TTA）技术更好地实现更好的结果。此外，当与测试时间增强相结合时，我们的方法可以进一步提高模型性能。我们在ImageNet-2012和CIFAR-100数据集上进行了验证和实验，结果表明我们的方法比翻转测试时间增强更快30％，在CIFAR-100上达到了相同的结果。",
    "tldr": "本文提出了一种将数据增强方法引入卷积神经网络中间层的方法，既使速度-准确性的平衡更平滑，同时在ImageNet和CIFAR-100数据集分类任务上实现更好的结果，特别是在CIFAR-100数据集上的结果可以比标准测试时间增强技术更快30％。",
    "en_tdlr": "This paper presents a method called \"augmentation inside the network\" that brings data augmentation techniques into intermediate features of convolutional neural networks, achieving smoother trade-offs between speed and accuracy, and producing better results than standard test-time augmentation (TTA) techniques on ImageNet and CIFAR-100 datasets; notably, the proposed modification achieves the same results for CIFAR-100 as flip TTA but with a 30% faster speed."
}