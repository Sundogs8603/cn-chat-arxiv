{
    "title": "Perceptron Theory Can Predict the Accuracy of Neural Networks. (arXiv:2012.07881v2 [cs.LG] UPDATED)",
    "abstract": "Multilayer neural networks set the current state of the art for many technical classification problems. But, these networks are still, essentially, black boxes in terms of analyzing them and predicting their performance. Here, we develop a statistical theory for the one-layer perceptron and show that it can predict performances of a surprisingly large variety of neural networks with different architectures. A general theory of classification with perceptrons is developed by generalizing an existing theory for analyzing reservoir computing models and connectionist models for symbolic reasoning known as vector symbolic architectures. Our statistical theory offers three formulas leveraging the signal statistics with increasing detail. The formulas are analytically intractable, but can be evaluated numerically. The description level that captures maximum details requires stochastic sampling methods. Depending on the network model, the simpler formulas already yield high prediction accuracy",
    "link": "http://arxiv.org/abs/2012.07881",
    "context": "Title: Perceptron Theory Can Predict the Accuracy of Neural Networks. (arXiv:2012.07881v2 [cs.LG] UPDATED)\nAbstract: Multilayer neural networks set the current state of the art for many technical classification problems. But, these networks are still, essentially, black boxes in terms of analyzing them and predicting their performance. Here, we develop a statistical theory for the one-layer perceptron and show that it can predict performances of a surprisingly large variety of neural networks with different architectures. A general theory of classification with perceptrons is developed by generalizing an existing theory for analyzing reservoir computing models and connectionist models for symbolic reasoning known as vector symbolic architectures. Our statistical theory offers three formulas leveraging the signal statistics with increasing detail. The formulas are analytically intractable, but can be evaluated numerically. The description level that captures maximum details requires stochastic sampling methods. Depending on the network model, the simpler formulas already yield high prediction accuracy",
    "path": "papers/20/12/2012.07881.json",
    "total_tokens": 765,
    "translated_title": "感知器理论可以预测神经网络的准确性",
    "translated_abstract": "多层神经网络在许多技术分类问题上取得了当前的最新成果。然而，从分析和预测性能角度来看，这些网络仍然是黑箱。在这里，我们开发了一个针对单层感知器的统计理论，并展示它可以预测多种不同结构的神经网络的性能。通过推广用于分析储备计算模型和符号推理的连接主义模型的向量符号体系结构的现有理论，我们发展了感知器分类的一般理论。我们的统计理论提供了三个公式，通过逐步增加详细信息来利用信号统计。这些公式在解析上是难以处理的，但可以通过数值评估。捕捉最详细信息的描述级别需要随机抽样方法。根据网络模型的不同，较简单的公式已经能够提供高度准确的预测。",
    "tldr": "感知器理论可以通过统计方法准确预测不同结构的神经网络的性能。",
    "en_tdlr": "The perceptron theory can accurately predict the performance of neural networks with different architectures using statistical methods."
}