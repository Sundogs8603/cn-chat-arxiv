{
    "title": "A Tractable Online Learning Algorithm for the Multinomial Logit Contextual Bandit. (arXiv:2011.14033v5 [cs.LG] UPDATED)",
    "abstract": "In this paper, we consider the contextual variant of the MNL-Bandit problem. More specifically, we consider a dynamic set optimization problem, where a decision-maker offers a subset (assortment) of products to a consumer and observes the response in every round. Consumers purchase products to maximize their utility. We assume that a set of attributes describe the products, and the mean utility of a product is linear in the values of these attributes. We model consumer choice behavior using the widely used Multinomial Logit (MNL) model and consider the decision maker problem of dynamically learning the model parameters while optimizing cumulative revenue over the selling horizon $T$. Though this problem has attracted considerable attention in recent times, many existing methods often involve solving an intractable non-convex optimization problem. Their theoretical performance guarantees depend on a problem-dependent parameter which could be prohibitively large. In particular, existing ",
    "link": "http://arxiv.org/abs/2011.14033",
    "context": "Title: A Tractable Online Learning Algorithm for the Multinomial Logit Contextual Bandit. (arXiv:2011.14033v5 [cs.LG] UPDATED)\nAbstract: In this paper, we consider the contextual variant of the MNL-Bandit problem. More specifically, we consider a dynamic set optimization problem, where a decision-maker offers a subset (assortment) of products to a consumer and observes the response in every round. Consumers purchase products to maximize their utility. We assume that a set of attributes describe the products, and the mean utility of a product is linear in the values of these attributes. We model consumer choice behavior using the widely used Multinomial Logit (MNL) model and consider the decision maker problem of dynamically learning the model parameters while optimizing cumulative revenue over the selling horizon $T$. Though this problem has attracted considerable attention in recent times, many existing methods often involve solving an intractable non-convex optimization problem. Their theoretical performance guarantees depend on a problem-dependent parameter which could be prohibitively large. In particular, existing ",
    "path": "papers/20/11/2011.14033.json",
    "total_tokens": 1052,
    "translated_title": "MNL上下文Bandit问题的简便在线学习算法",
    "translated_abstract": "本文考虑了MNL-Bandit问题的上下文变体。更具体地说，我们考虑了一个动态集合优化问题，其中决策者向消费者提供一组产品（购物清单），并在每个回合观察响应。消费者购买产品以最大化他们的效用。我们假设一组属性描述了产品，产品的平均效用与这些属性的值呈线性关系。我们使用广泛使用的Multinomial Logit（MNL）模型建模消费者选择行为，并考虑在优化销售周期$T$内累积收益的同时动态学习模型参数的决策者问题。尽管这个问题近来引起了相当大的关注，但许多现有方法通常涉及解决一个难以处理的非凸优化问题。他们的理论性能保证取决于一个可能非常大的问题相关参数。特别地，现有方法需要调整随着属性集规模指数增长的调整参数。本文提供了一种新颖的MNL-Contextual Bandit问题的简便在线学习算法，它不需要调整此类指数参数。我们展示我们的算法具有与该问题的最佳理论界限匹配的遗憾上界。我们还通过模拟和真实世界实验证明了我们算法的有效性。",
    "tldr": "本文提供了一个新颖的、不需要调整指数参数的MNL-Contextual Bandit问题的简便在线学习算法。算法具有与该问题的最佳理论界限匹配的遗憾上界。",
    "en_tdlr": "This paper proposes a novel tractable online learning algorithm for the contextual variant of the MNL-Bandit problem. It does not require tuning an exponential parameter and has a regret upper bound that matches the best theoretical limits of the problem."
}