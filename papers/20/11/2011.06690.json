{
    "title": "Adversarial Image Color Transformations in Explicit Color Filter Space. (arXiv:2011.06690v3 [cs.CV] UPDATED)",
    "abstract": "Deep Neural Networks have been shown to be vulnerable to adversarial images. Conventional attacks strive for indistinguishable adversarial images with strictly restricted perturbations. Recently, researchers have moved to explore distinguishable yet non-suspicious adversarial images and demonstrated that color transformation attacks are effective. In this work, we propose Adversarial Color Filter (AdvCF), a novel color transformation attack that is optimized with gradient information in the parameter space of a simple color filter. In particular, our color filter space is explicitly specified so that we are able to provide a systematic analysis of model robustness against adversarial color transformations, from both the attack and defense perspectives. In contrast, existing color transformation attacks do not offer the opportunity for systematic analysis due to the lack of such an explicit space. We further demonstrate the effectiveness of our AdvCF in fooling image classifiers and als",
    "link": "http://arxiv.org/abs/2011.06690",
    "context": "Title: Adversarial Image Color Transformations in Explicit Color Filter Space. (arXiv:2011.06690v3 [cs.CV] UPDATED)\nAbstract: Deep Neural Networks have been shown to be vulnerable to adversarial images. Conventional attacks strive for indistinguishable adversarial images with strictly restricted perturbations. Recently, researchers have moved to explore distinguishable yet non-suspicious adversarial images and demonstrated that color transformation attacks are effective. In this work, we propose Adversarial Color Filter (AdvCF), a novel color transformation attack that is optimized with gradient information in the parameter space of a simple color filter. In particular, our color filter space is explicitly specified so that we are able to provide a systematic analysis of model robustness against adversarial color transformations, from both the attack and defense perspectives. In contrast, existing color transformation attacks do not offer the opportunity for systematic analysis due to the lack of such an explicit space. We further demonstrate the effectiveness of our AdvCF in fooling image classifiers and als",
    "path": "papers/20/11/2011.06690.json",
    "total_tokens": 905,
    "translated_title": "显式色彩滤镜空间中的对抗性图像颜色变换",
    "translated_abstract": "深度神经网络已被证明容易受到对抗性图像的攻击。传统攻击旨在产生无法区分的对抗性图像，但扰动受到严格限制。近期，研究者开始探索可区分但不引人注意的对抗性图像，并证明颜色变换攻击是有效的。在本论文中，我们提出了Adversarial Color Filter (AdvCF)，这是一种通过简单色彩滤镜参数空间中的梯度信息来优化的新型颜色变换攻击方法。特别地，我们明确指定了色彩滤镜空间，以便可以提供对模型抵抗对抗性颜色变换的系统分析，从攻击和防御的角度分析。相比之下，现有的颜色变换攻击由于缺乏这样明确的空间而无法提供系统分析机会。我们进一步证明了我们的AdvCF在愚弄图像分类器方面的有效性。",
    "tldr": "本论文提出了一种新型颜色变换攻击方法AdvCF，它通过简单色彩滤镜参数空间中的梯度信息进行优化，具有可区分但不引人注意的特点，并提供了对模型抵抗对抗性颜色变换的系统分析。",
    "en_tdlr": "This paper proposes a novel color transformation attack method, AdvCF, which is optimized by gradient information in the parameter space of a simple color filter. It has a distinguishable but not suspicious feature, and provides a systematic analysis of model resistance to adversarial color transformations, from both the attack and defense perspectives."
}