{
    "title": "Optimal and Safe Estimation for High-Dimensional Semi-Supervised Learning. (arXiv:2011.14185v2 [stat.ME] UPDATED)",
    "abstract": "We consider the estimation problem in high-dimensional semi-supervised learning. Our goal is to investigate when and how the unlabeled data can be exploited to improve the estimation of the regression parameters of linear model in light of the fact that such linear models may be misspecified in data analysis. We first establish the minimax lower bound for parameter estimation in the semi-supervised setting, and show that this lower bound cannot be achieved by supervised estimators using the labeled data only. We propose an optimal semi-supervised estimator that can attain this lower bound and therefore improves the supervised estimators, provided that the conditional mean function can be consistently estimated with a proper rate. We further propose a safe semi-supervised estimator. We view it safe, because this estimator is always at least as good as the supervised estimators. We also extend our idea to the aggregation of multiple semi-supervised estimators caused by different misspeci",
    "link": "http://arxiv.org/abs/2011.14185",
    "context": "Title: Optimal and Safe Estimation for High-Dimensional Semi-Supervised Learning. (arXiv:2011.14185v2 [stat.ME] UPDATED)\nAbstract: We consider the estimation problem in high-dimensional semi-supervised learning. Our goal is to investigate when and how the unlabeled data can be exploited to improve the estimation of the regression parameters of linear model in light of the fact that such linear models may be misspecified in data analysis. We first establish the minimax lower bound for parameter estimation in the semi-supervised setting, and show that this lower bound cannot be achieved by supervised estimators using the labeled data only. We propose an optimal semi-supervised estimator that can attain this lower bound and therefore improves the supervised estimators, provided that the conditional mean function can be consistently estimated with a proper rate. We further propose a safe semi-supervised estimator. We view it safe, because this estimator is always at least as good as the supervised estimators. We also extend our idea to the aggregation of multiple semi-supervised estimators caused by different misspeci",
    "path": "papers/20/11/2011.14185.json",
    "total_tokens": 949,
    "translated_title": "高维半监督学习的最优与安全估计",
    "translated_abstract": "本研究考虑高维半监督学习的估计问题，旨在探究无标签数据如何提高线性模型回归参数的估计准确性，因为这样的线性模型可能在数据分析中被错误地规定。首先，我们建立了半监督设置下参数估计的极小极大下界，并证明了仅使用有标签数据的监督估计器无法实现此下界。我们提出了一种最优半监督估计器，可以实现此下界，因此可以改进监督估计器，前提是条件均值函数可以以适当的速率一致地估计。我们进一步提出了一种安全的半监督估计器。我们认为它是安全的，因为这个估计器总是至少和监督估计器一样好。我们还将我们的想法扩展到多个由不同误差引起的半监督估计器的聚合。",
    "tldr": "本研究探究了高维半监督学习的估计问题，提出了最优和安全的半监督估计器。最优估计器可以实现极小极大下界，改进监督估计器。安全估计器至少和监督估计器一样好，且两者聚合可以更好地解决误差问题。",
    "en_tdlr": "This paper investigates the estimation problem in high-dimensional semi-supervised learning, proposes optimal and safe semi-supervised estimators, and extends the idea to the aggregation of multiple semi-supervised estimators caused by different errors. The optimal estimator can achieve the minimax lower bound and improve the supervised estimators, while the safe estimator is at least as good as the supervised estimators."
}