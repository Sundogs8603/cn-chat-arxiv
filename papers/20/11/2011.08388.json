{
    "title": "Domain Adaptation based Interpretable Image Emotion Recognition using Facial Expression Recognition",
    "abstract": "A domain adaptation technique has been proposed in this paper to identify the emotions in generic images containing facial & non-facial objects and non-human components. It addresses the challenge of the insufficient availability of pre-trained models and well-annotated datasets for image emotion recognition (IER). It starts with proposing a facial emotion recognition (FER) system and then moves on to adapting it for image emotion recognition. First, a deep-learning-based FER system has been proposed that classifies a given facial image into discrete emotion classes. Further, an image recognition system has been proposed that adapts the proposed FER system to recognize the emotions portrayed by images using domain adaptation. It classifies the generic images into 'happy,' 'sad,' 'hate,' and 'anger' classes. A novel interpretability approach, Divide and Conquer based Shap (DnCShap), has also been proposed to interpret the highly relevant visual features for emotion recognition. The prop",
    "link": "https://arxiv.org/abs/2011.08388",
    "context": "Title: Domain Adaptation based Interpretable Image Emotion Recognition using Facial Expression Recognition\nAbstract: A domain adaptation technique has been proposed in this paper to identify the emotions in generic images containing facial & non-facial objects and non-human components. It addresses the challenge of the insufficient availability of pre-trained models and well-annotated datasets for image emotion recognition (IER). It starts with proposing a facial emotion recognition (FER) system and then moves on to adapting it for image emotion recognition. First, a deep-learning-based FER system has been proposed that classifies a given facial image into discrete emotion classes. Further, an image recognition system has been proposed that adapts the proposed FER system to recognize the emotions portrayed by images using domain adaptation. It classifies the generic images into 'happy,' 'sad,' 'hate,' and 'anger' classes. A novel interpretability approach, Divide and Conquer based Shap (DnCShap), has also been proposed to interpret the highly relevant visual features for emotion recognition. The prop",
    "path": "papers/20/11/2011.08388.json",
    "total_tokens": 933,
    "translated_title": "基于领域自适应的可解释图像情绪识别，并利用面部表情识别",
    "translated_abstract": "本文提出了一种领域自适应技术，用于识别包含面部和非面部物体以及非人类组件的通用图像中的情绪。它解决了图像情绪识别（IER）中预训练模型和良好注释数据集的不足挑战。首先，提出了一种基于深度学习的面部情绪识别（FER）系统，将给定的面部图像分类为离散情绪类别。然后，提出了一种图像识别系统，将提出的FER系统适应于利用领域自适应识别图像所传达的情绪。它将通用图像分类为“快乐”，“悲伤”，“仇恨”和“愤怒”类别。还提出了一种新颖的解释性方法，称为分而治之的Shap（DnCShap），用于解释情绪识别中高度相关的视觉特征。",
    "tldr": "本论文提出了一种基于领域自适应的图像情绪识别方法，通过提出面部情绪识别系统并将其适应为图像情绪识别系统，解决了预训练模型和数据集不足的挑战。同时提出了一种新颖的解释性方法，用于解释情绪识别中关键的视觉特征。"
}