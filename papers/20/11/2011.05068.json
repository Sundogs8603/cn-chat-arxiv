{
    "title": "Dimension-agnostic inference using cross U-statistics. (arXiv:2011.05068v6 [math.ST] UPDATED)",
    "abstract": "Classical asymptotic theory for statistical inference usually involves calibrating a statistic by fixing the dimension $d$ while letting the sample size $n$ increase to infinity. Recently, much effort has been dedicated towards understanding how these methods behave in high-dimensional settings, where $d$ and $n$ both increase to infinity together. This often leads to different inference procedures, depending on the assumptions about the dimensionality, leaving the practitioner in a bind: given a dataset with 100 samples in 20 dimensions, should they calibrate by assuming $n \\gg d$, or $d/n \\approx 0.2$? This paper considers the goal of dimension-agnostic inference; developing methods whose validity does not depend on any assumption on $d$ versus $n$. We introduce an approach that uses variational representations of existing test statistics along with sample splitting and self-normalization to produce a refined test statistic with a Gaussian limiting distribution, regardless of how $d$",
    "link": "http://arxiv.org/abs/2011.05068",
    "context": "Title: Dimension-agnostic inference using cross U-statistics. (arXiv:2011.05068v6 [math.ST] UPDATED)\nAbstract: Classical asymptotic theory for statistical inference usually involves calibrating a statistic by fixing the dimension $d$ while letting the sample size $n$ increase to infinity. Recently, much effort has been dedicated towards understanding how these methods behave in high-dimensional settings, where $d$ and $n$ both increase to infinity together. This often leads to different inference procedures, depending on the assumptions about the dimensionality, leaving the practitioner in a bind: given a dataset with 100 samples in 20 dimensions, should they calibrate by assuming $n \\gg d$, or $d/n \\approx 0.2$? This paper considers the goal of dimension-agnostic inference; developing methods whose validity does not depend on any assumption on $d$ versus $n$. We introduce an approach that uses variational representations of existing test statistics along with sample splitting and self-normalization to produce a refined test statistic with a Gaussian limiting distribution, regardless of how $d$",
    "path": "papers/20/11/2011.05068.json",
    "total_tokens": 900,
    "translated_title": "使用交叉U统计量的维度不可知推断",
    "translated_abstract": "经典的统计推断渐进理论通常涉及通过固定维度d来让样本量n趋向无穷，从而校准统计量。最近，人们大力研究了这些方法在高维情况下的表现，其中d和n都同时增加到无穷。这往往导致不同的推断过程，取决于对维度性的假设，让从业者感到为难：对于一个20维的100个样本的数据集，他们应该假设n>>d，还是d/n约为0.2？本文考虑了维度不可知推断的目标；开发出的方法的有效性不依赖于对d和n的任何假设。我们引入了一种方法，使用现有测试统计量的变分表示，结合样本拆分和自规范化，产生了一个精细的测试统计量，其高斯极限分布的有效性不取决于d和n的关系。我们证明了该方法的有效性，并研究了其在实际应用中的性能。",
    "tldr": "该论文介绍了一种新的统计推断方法，它不依赖于对数据集维度的假设，可以在高维数据集上进行推断。",
    "en_tdlr": "This paper introduces a new statistical inference method that does not depend on assumptions about the dimensionality of the dataset and can be used for inference on high-dimensional datasets."
}