{
    "title": "ShadowNet: A Secure and Efficient On-device Model Inference System for Convolutional Neural Networks. (arXiv:2011.05905v4 [cs.CR] UPDATED)",
    "abstract": "With the increased usage of AI accelerators on mobile and edge devices, on-device machine learning (ML) is gaining popularity. Thousands of proprietary ML models are being deployed today on billions of untrusted devices. This raises serious security concerns about model privacy. However, protecting model privacy without losing access to the untrusted AI accelerators is a challenging problem. In this paper, we present a novel on-device model inference system, ShadowNet. ShadowNet protects the model privacy with Trusted Execution Environment (TEE) while securely outsourcing the heavy linear layers of the model to the untrusted hardware accelerators. ShadowNet achieves this by transforming the weights of the linear layers before outsourcing them and restoring the results inside the TEE. The non-linear layers are also kept secure inside the TEE. ShadowNet's design ensures efficient transformation of the weights and the subsequent restoration of the results. We build a ShadowNet prototype b",
    "link": "http://arxiv.org/abs/2011.05905",
    "context": "Title: ShadowNet: A Secure and Efficient On-device Model Inference System for Convolutional Neural Networks. (arXiv:2011.05905v4 [cs.CR] UPDATED)\nAbstract: With the increased usage of AI accelerators on mobile and edge devices, on-device machine learning (ML) is gaining popularity. Thousands of proprietary ML models are being deployed today on billions of untrusted devices. This raises serious security concerns about model privacy. However, protecting model privacy without losing access to the untrusted AI accelerators is a challenging problem. In this paper, we present a novel on-device model inference system, ShadowNet. ShadowNet protects the model privacy with Trusted Execution Environment (TEE) while securely outsourcing the heavy linear layers of the model to the untrusted hardware accelerators. ShadowNet achieves this by transforming the weights of the linear layers before outsourcing them and restoring the results inside the TEE. The non-linear layers are also kept secure inside the TEE. ShadowNet's design ensures efficient transformation of the weights and the subsequent restoration of the results. We build a ShadowNet prototype b",
    "path": "papers/20/11/2011.05905.json",
    "total_tokens": 910,
    "translated_title": "ShadowNet：一种用于卷积神经网络的安全高效的设备内推断系统",
    "translated_abstract": "随着在移动设备和边缘设备上使用AI加速器的增加，设备内机器学习（ML）变得越来越受欢迎。今天，在数十亿个不受信任的设备上部署了数千个专有的ML模型。这引起了对模型隐私的严重关注。然而，如何在不丢失对不受信任的AI加速器的访问权的情况下保护模型隐私是一个具有挑战性的问题。在本文中，我们提出了一种新颖的设备内模型推断系统ShadowNet。ShadowNet通过使用可信执行环境（TEE）保护模型隐私，同时安全地将模型的重型线性层外包给不受信任的硬件加速器。ShadowNet通过在外包之前转换线性层的权重并在TEE内恢复结果来实现这一目标。非线性层也被安全地保留在TEE内。ShadowNet的设计确保了权重的高效转换和结果的后续恢复。我们构建了一个ShadowNet原型",
    "tldr": "ShadowNet是一种安全高效的设备内推断系统，通过使用可信执行环境（TEE）保护模型隐私，同时将模型的重型线性层外包给不受信任的硬件加速器，实现了对模型隐私的保护。",
    "en_tdlr": "ShadowNet is a secure and efficient on-device model inference system that protects model privacy by using Trusted Execution Environment (TEE) while securely outsourcing the heavy linear layers of the model to untrusted hardware accelerators."
}