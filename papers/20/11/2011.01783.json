{
    "title": "An Efficiency-boosting Client Selection Scheme for Federated Learning with Fairness Guarantee. (arXiv:2011.01783v5 [cs.LG] UPDATED)",
    "abstract": "The issue of potential privacy leakage during centralized AI's model training has drawn intensive concern from the public. A Parallel and Distributed Computing (or PDC) scheme, termed Federated Learning (FL), has emerged as a new paradigm to cope with the privacy issue by allowing clients to perform model training locally, without the necessity to upload their personal sensitive data. In FL, the number of clients could be sufficiently large, but the bandwidth available for model distribution and re-upload is quite limited, making it sensible to only involve part of the volunteers to participate in the training process. The client selection policy is critical to an FL process in terms of training efficiency, the final model's quality as well as fairness. In this paper, we will model the fairness guaranteed client selection as a Lyapunov optimization problem and then a C2MAB-based method is proposed for estimation of the model exchange time between each client and the server, based on wh",
    "link": "http://arxiv.org/abs/2011.01783",
    "context": "Title: An Efficiency-boosting Client Selection Scheme for Federated Learning with Fairness Guarantee. (arXiv:2011.01783v5 [cs.LG] UPDATED)\nAbstract: The issue of potential privacy leakage during centralized AI's model training has drawn intensive concern from the public. A Parallel and Distributed Computing (or PDC) scheme, termed Federated Learning (FL), has emerged as a new paradigm to cope with the privacy issue by allowing clients to perform model training locally, without the necessity to upload their personal sensitive data. In FL, the number of clients could be sufficiently large, but the bandwidth available for model distribution and re-upload is quite limited, making it sensible to only involve part of the volunteers to participate in the training process. The client selection policy is critical to an FL process in terms of training efficiency, the final model's quality as well as fairness. In this paper, we will model the fairness guaranteed client selection as a Lyapunov optimization problem and then a C2MAB-based method is proposed for estimation of the model exchange time between each client and the server, based on wh",
    "path": "papers/20/11/2011.01783.json",
    "total_tokens": 860,
    "translated_title": "一个提高联邦学习效率的具有公平保证的客户选择方案",
    "translated_abstract": "在集中式人工智能模型训练中潜在的隐私泄露问题引起了公众的广泛关注。一种名为联邦学习的并行和分布式计算方案已经出现，通过允许客户在本地执行模型训练，无需上传个人敏感数据来应对隐私问题。在联邦学习中，客户端的数量可能非常大，但用于模型分发和重新上传的带宽非常有限，因此合理地只让部分志愿者参与训练过程。客户选择策略在联邦学习过程中至关重要，涉及训练效率、最终模型质量以及公平性。本文将公平保证的客户选择建模为一个Lyapunov优化问题，提出了一种基于C2MAB的方法，用于估计每个客户端与服务器之间的模型交换时间，基于此进行客户选择。",
    "tldr": "本文提出了一个基于Lyapunov优化问题的公平保证的客户选择方案，该方案通过估计每个客户端与服务器之间的模型交换时间，提高了联邦学习的效率。",
    "en_tdlr": "This paper proposes a fairness guaranteed client selection scheme based on Lyapunov optimization problem, which improves the efficiency of federated learning by estimating the model exchange time between each client and the server."
}