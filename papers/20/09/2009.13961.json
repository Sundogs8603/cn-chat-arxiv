{
    "title": "Online Action Learning in High Dimensions: A Conservative Perspective",
    "abstract": "arXiv:2009.13961v4 Announce Type: replace-cross  Abstract: Sequential learning problems are common in several fields of research and practical applications. Examples include dynamic pricing and assortment, design of auctions and incentives and permeate a large number of sequential treatment experiments. In this paper, we extend one of the most popular learning solutions, the $\\epsilon_t$-greedy heuristics, to high-dimensional contexts considering a conservative directive. We do this by allocating part of the time the original rule uses to adopt completely new actions to a more focused search in a restrictive set of promising actions. The resulting rule might be useful for practical applications that still values surprises, although at a decreasing rate, while also has restrictions on the adoption of unusual actions. With high probability, we find reasonable bounds for the cumulative regret of a conservative high-dimensional decaying $\\epsilon_t$-greedy rule. Also, we provide a lower bo",
    "link": "https://arxiv.org/abs/2009.13961",
    "context": "Title: Online Action Learning in High Dimensions: A Conservative Perspective\nAbstract: arXiv:2009.13961v4 Announce Type: replace-cross  Abstract: Sequential learning problems are common in several fields of research and practical applications. Examples include dynamic pricing and assortment, design of auctions and incentives and permeate a large number of sequential treatment experiments. In this paper, we extend one of the most popular learning solutions, the $\\epsilon_t$-greedy heuristics, to high-dimensional contexts considering a conservative directive. We do this by allocating part of the time the original rule uses to adopt completely new actions to a more focused search in a restrictive set of promising actions. The resulting rule might be useful for practical applications that still values surprises, although at a decreasing rate, while also has restrictions on the adoption of unusual actions. With high probability, we find reasonable bounds for the cumulative regret of a conservative high-dimensional decaying $\\epsilon_t$-greedy rule. Also, we provide a lower bo",
    "path": "papers/20/09/2009.13961.json",
    "total_tokens": 817,
    "translated_title": "高维度的在线动作学习：一个保守的观点",
    "translated_abstract": "顺序学习问题在多个研究领域和实际应用中很常见。在本文中，我们将最流行的学习解决方案之一，$\\epsilon_t$-贪心启发式，扩展到考虑保守导向的高维情境中。我们通过将原始规则用于采纳全新动作的时间的一部分，分配给在一组有前途的动作中进行更加专注的搜索来实现这一点。所得规则可能对仍然重视惊喜但限制采纳不寻常动作的实际应用有用。我们发现了对于保守高维度衰减$\\epsilon_t$-贪心规则的累积遗憾提供了合理边界的概率很高。",
    "tldr": "该论文将$\\epsilon_t$-贪心启发式方法扩展到高维度情境中，采用保守导向策略，实现在实用应用中对新奇性的重视，同时限制了采纳不寻常动作，有效控制了累积遗憾。",
    "en_tdlr": "The paper extends the $\\epsilon_t$-greedy heuristics to high-dimensional contexts with a conservative directive, balancing the value of surprises in practical applications while restricting the adoption of unusual actions, effectively controlling the cumulative regret."
}