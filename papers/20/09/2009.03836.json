{
    "title": "Graph neural networks-based Scheduler for Production planning problems using Reinforcement Learning. (arXiv:2009.03836v2 [cs.LG] UPDATED)",
    "abstract": "Reinforcement learning (RL) is increasingly adopted in job shop scheduling problems (JSSP). But RL for JSSP is usually done using a vectorized representation of machine features as the state space. It has three major problems: (1) the relationship between the machine units and the job sequence is not fully captured, (2) exponential increase in the size of the state space with increasing machines/jobs, and (3) the generalization of the agent to unseen scenarios. We present a novel framework - GraSP-RL, GRAph neural network-based Scheduler for Production planning problems using Reinforcement Learning. It represents JSSP as a graph and trains the RL agent using features extracted using a graph neural network (GNN). While the graph is itself in the non-euclidean space, the features extracted using the GNNs provide a rich encoding of the current production state in the euclidean space, which is then used by the RL agent to select the next job. Further, we cast the scheduling problem as a de",
    "link": "http://arxiv.org/abs/2009.03836",
    "context": "Title: Graph neural networks-based Scheduler for Production planning problems using Reinforcement Learning. (arXiv:2009.03836v2 [cs.LG] UPDATED)\nAbstract: Reinforcement learning (RL) is increasingly adopted in job shop scheduling problems (JSSP). But RL for JSSP is usually done using a vectorized representation of machine features as the state space. It has three major problems: (1) the relationship between the machine units and the job sequence is not fully captured, (2) exponential increase in the size of the state space with increasing machines/jobs, and (3) the generalization of the agent to unseen scenarios. We present a novel framework - GraSP-RL, GRAph neural network-based Scheduler for Production planning problems using Reinforcement Learning. It represents JSSP as a graph and trains the RL agent using features extracted using a graph neural network (GNN). While the graph is itself in the non-euclidean space, the features extracted using the GNNs provide a rich encoding of the current production state in the euclidean space, which is then used by the RL agent to select the next job. Further, we cast the scheduling problem as a de",
    "path": "papers/20/09/2009.03836.json",
    "total_tokens": 929,
    "translated_title": "基于图神经网络的强化学习生产计划问题调度器",
    "translated_abstract": "强化学习在车间调度问题中得到广泛应用。但对于车间调度问题，强化学习通常使用矢量化机器特征作为状态空间。这种方法存在三个主要问题：（1）机器单元和作业序列之间的关系没有完全捕获，（2）状态空间随着机器/作业数量的增加呈指数增长，（3）代理的泛化能力存在问题。本文提出了一种新的框架——GraSP-RL，基于图神经网络的强化学习生产计划问题调度器。它将车间调度问题表示为图形，并使用图神经网络(GNN)提取特征来训练强化学习代理。虽然图形本身在非欧几里德空间中，但使用GNN提取的特征在欧几里德空间中提供了当前生产状态的丰富编码，然后被强化学习代理用于选择下一个作业。此外，我们将调度问题视为一个基于图神经网络的流问题，使用回溯方法对此进行求解。",
    "tldr": "本文提出了GraSP-RL框架，基于图神经网络来训练强化学习代理，以解决车间调度问题中状态空间难以处理、泛化能力较差的问题。",
    "en_tdlr": "This paper proposes a GraSP-RL framework that trains reinforcement learning agents using a graph neural network to solve the problems of difficult state space processing and poor generalization in job shop scheduling problems."
}