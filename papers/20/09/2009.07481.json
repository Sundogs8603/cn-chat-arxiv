{
    "title": "Unsupervised Summarization by Jointly Extracting Sentences and Keywords. (arXiv:2009.07481v2 [cs.CL] UPDATED)",
    "abstract": "We present RepRank, an unsupervised graph-based ranking model for extractive multi-document summarization in which the similarity between words, sentences, and word-to-sentence can be estimated by the distances between their vector representations in a unified vector space. In order to obtain desirable representations, we propose a self-attention based learning method that represent a sentence by the weighted sum of its word embeddings, and the weights are concentrated to those words hopefully better reflecting the content of a document. We show that salient sentences and keywords can be extracted in a joint and mutual reinforcement process using our learned representations, and prove that this process always converges to a unique solution leading to improvement in performance. A variant of absorbing random walk and the corresponding sampling-based algorithm are also described to avoid redundancy and increase diversity in the summaries. Experiment results with multiple benchmark datase",
    "link": "http://arxiv.org/abs/2009.07481",
    "context": "Title: Unsupervised Summarization by Jointly Extracting Sentences and Keywords. (arXiv:2009.07481v2 [cs.CL] UPDATED)\nAbstract: We present RepRank, an unsupervised graph-based ranking model for extractive multi-document summarization in which the similarity between words, sentences, and word-to-sentence can be estimated by the distances between their vector representations in a unified vector space. In order to obtain desirable representations, we propose a self-attention based learning method that represent a sentence by the weighted sum of its word embeddings, and the weights are concentrated to those words hopefully better reflecting the content of a document. We show that salient sentences and keywords can be extracted in a joint and mutual reinforcement process using our learned representations, and prove that this process always converges to a unique solution leading to improvement in performance. A variant of absorbing random walk and the corresponding sampling-based algorithm are also described to avoid redundancy and increase diversity in the summaries. Experiment results with multiple benchmark datase",
    "path": "papers/20/09/2009.07481.json",
    "total_tokens": 1092,
    "translated_title": "通过联合提取句子和关键词进行无监督摘要",
    "translated_abstract": "我们提出了RepRank，这是一个无监督的基于图的排名模型，用于提取多文档摘要。通过在统一的向量空间中计算它们的向量表示之间的距离，可以估计单词、句子和单词到句子之间的相似度。为了获得理想的表示，我们提出了一种基于自注意力的学习方法，将句子表示为其词嵌入的加权和，权重集中在那些更好地反映文档内容的词上。我们证明了通过使用我们学习到的表示来联合提取突出的句子和关键词的过程可以相互增强，并证明了这个过程总是收敛到一个唯一的解，从而提高了性能。我们还描述了吸收式随机游走的变体和相应的基于采样的算法，以避免摘要中的冗余并增加多样性。在多个基准数据集上进行了实验",
    "tldr": "本论文提出了一种无监督的图排名模型RepRank，通过在统一的向量空间中计算单词、句子和单词到句子之间的距离，来提取多文档摘要中的突出句子和关键词。通过自注意力的学习方法，将句子表示为其词嵌入的加权和，能够更好地反映文档内容。实验证明，通过联合提取句子和关键词的过程可以相互增强，并且总是收敛到唯一的解，从而提高了性能。同时，采用吸收式随机游走的变体和基于采样的算法，可以避免冗余并增加多样性。"
}