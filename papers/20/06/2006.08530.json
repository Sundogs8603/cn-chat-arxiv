{
    "title": "Selecting the Number of Clusters $K$ with a Stability Trade-off: an Internal Validation Criterion. (arXiv:2006.08530v3 [cs.LG] UPDATED)",
    "abstract": "Model selection is a major challenge in non-parametric clustering. There is no universally admitted way to evaluate clustering results for the obvious reason that no ground truth is available. The difficulty to find a universal evaluation criterion is a consequence of the ill-defined objective of clustering. In this perspective, clustering stability has emerged as a natural and model-agnostic principle: an algorithm should find stable structures in the data. If data sets are repeatedly sampled from the same underlying distribution, an algorithm should find similar partitions. However, stability alone is not well-suited to determine the number of clusters. For instance, it is unable to detect if the number of clusters is too small. We propose a new principle: a good clustering should be stable, and within each cluster, there should exist no stable partition. This principle leads to a novel clustering validation criterion based on between-cluster and within-cluster stability, overcoming ",
    "link": "http://arxiv.org/abs/2006.08530",
    "context": "Title: Selecting the Number of Clusters $K$ with a Stability Trade-off: an Internal Validation Criterion. (arXiv:2006.08530v3 [cs.LG] UPDATED)\nAbstract: Model selection is a major challenge in non-parametric clustering. There is no universally admitted way to evaluate clustering results for the obvious reason that no ground truth is available. The difficulty to find a universal evaluation criterion is a consequence of the ill-defined objective of clustering. In this perspective, clustering stability has emerged as a natural and model-agnostic principle: an algorithm should find stable structures in the data. If data sets are repeatedly sampled from the same underlying distribution, an algorithm should find similar partitions. However, stability alone is not well-suited to determine the number of clusters. For instance, it is unable to detect if the number of clusters is too small. We propose a new principle: a good clustering should be stable, and within each cluster, there should exist no stable partition. This principle leads to a novel clustering validation criterion based on between-cluster and within-cluster stability, overcoming ",
    "path": "papers/20/06/2006.08530.json",
    "total_tokens": 1025,
    "translated_title": "带有稳定性折衷的选择聚类数目 $K$：一种内部验证标准",
    "translated_abstract": "模型选择是非参数聚类中的主要挑战之一。毫无疑问，没有可以作为标准答案的真实数据存在，因此评价聚类结果的通用方法尚未出现。聚类目标的不确定性导致了普遍接受的评价标准难以确定。在这方面，聚类稳定性作为一种自然且无需模型的原则而出现：聚类算法应发现数据中稳定的结构。如果数据集从相同的基础分布中重复采样，则算法应找到相似的分区。然而，单纯的稳定性并不适合确定聚类数目。例如，它无法检测聚类数目是否太小。我们提出了一个新的原则：一种好的聚类应该是稳定的，且在每个聚类内部，不存在稳定的子分区。这个原则带来了一种基于聚类稳定性的新型聚类验证标准，克服了传统基于稳定性标准的局限性。我们的框架计算效率高且易于实现。我们在合成和真实世界数据集上展示了我们的标准能够以高精度恢复真实的聚类数目，并且在聚类稳定性和聚类质量方面胜过现有的方法。",
    "tldr": "提出了一种新的聚类验证标准，基于聚类稳定性的内部验证原则，在聚类稳定性和聚类质量方面胜过现有的方法。",
    "en_tdlr": "A new clustering validation criterion based on the internal validation principle of clustering stability is proposed, which outperforms existing methods in both clustering stability and clustering quality."
}