{
    "title": "Imbalanced Gradients: A Subtle Cause of Overestimated Adversarial Robustness. (arXiv:2006.13726v4 [cs.CV] UPDATED)",
    "abstract": "Evaluating the robustness of a defense model is a challenging task in adversarial robustness research. Obfuscated gradients have previously been found to exist in many defense methods and cause a false signal of robustness. In this paper, we identify a more subtle situation called Imbalanced Gradients that can also cause overestimated adversarial robustness. The phenomenon of imbalanced gradients occurs when the gradient of one term of the margin loss dominates and pushes the attack towards to a suboptimal direction. To exploit imbalanced gradients, we formulate a Margin Decomposition (MD) attack that decomposes a margin loss into individual terms and then explores the attackability of these terms separately via a two-stage process. We also propose a multi-targeted and ensemble version of our MD attack. By investigating 24 defense models proposed since 2018, we find that 11 models are susceptible to a certain degree of imbalanced gradients and our MD attack can decrease their robustnes",
    "link": "http://arxiv.org/abs/2006.13726",
    "context": "Title: Imbalanced Gradients: A Subtle Cause of Overestimated Adversarial Robustness. (arXiv:2006.13726v4 [cs.CV] UPDATED)\nAbstract: Evaluating the robustness of a defense model is a challenging task in adversarial robustness research. Obfuscated gradients have previously been found to exist in many defense methods and cause a false signal of robustness. In this paper, we identify a more subtle situation called Imbalanced Gradients that can also cause overestimated adversarial robustness. The phenomenon of imbalanced gradients occurs when the gradient of one term of the margin loss dominates and pushes the attack towards to a suboptimal direction. To exploit imbalanced gradients, we formulate a Margin Decomposition (MD) attack that decomposes a margin loss into individual terms and then explores the attackability of these terms separately via a two-stage process. We also propose a multi-targeted and ensemble version of our MD attack. By investigating 24 defense models proposed since 2018, we find that 11 models are susceptible to a certain degree of imbalanced gradients and our MD attack can decrease their robustnes",
    "path": "papers/20/06/2006.13726.json",
    "total_tokens": 1083,
    "translated_title": "不平衡梯度：对敌对鲁棒性估计过高的微妙原因",
    "translated_abstract": "在敌对鲁棒性研究中，评估防御模型的鲁棒性是一项具有挑战性的任务。以往发现在许多防御方法中存在隐晦的梯度，这些梯度会导致错误的鲁棒性信号。在本文中，我们确定了一种更微妙的情况，称为不平衡梯度，它也会导致对敌对鲁棒性的过高估计。不平衡梯度现象发生在边界损失的一个术语的梯度占主导地位并将攻击推向次优方向时。为了利用不平衡梯度，我们制定了一种边界分解(MD)攻击，将边界损失分解为单独的术语，然后通过两个阶段的过程分别探索这些术语的攻击性。我们还提出了我们的MD攻击的多目标和集合版本。通过调查自2018年以来提出的24个防御模型，我们发现11个模型在某种程度上容易受到不平衡梯度的影响，而我们的MD攻击可以降低它们的鲁棒性。",
    "tldr": "本文研究了对敌对鲁棒性估计过高的微妙原因，发现不平衡梯度也会导致鲁棒性估计过高，我们提出了一种边界分解攻击，并证明11个防御模型在某种程度上容易受到不平衡梯度的影响，MD攻击可以降低它们的鲁棒性。",
    "en_tdlr": "This paper investigates a subtle cause of overestimated adversarial robustness called Imbalanced Gradients, which occurs when the gradient of one term of the margin loss dominates and pushes the attack towards to a suboptimal direction. The authors propose a Margin Decomposition (MD) attack to exploit this phenomenon, and find that 11 out of 24 defense models are susceptible to a certain degree of imbalanced gradients, and their MD attack can decrease their robustness."
}