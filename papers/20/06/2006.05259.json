{
    "title": "Wavelet Networks: Scale-Translation Equivariant Learning From Raw Time-Series. (arXiv:2006.05259v2 [cs.LG] UPDATED)",
    "abstract": "Leveraging the symmetries inherent to specific data domains for the construction of equivariant neural networks has lead to remarkable improvements in terms of data efficiency and generalization. However, most existing research focuses on symmetries arising from planar and volumetric data, leaving a crucial data source largely underexplored: time-series. In this work, we fill this gap by leveraging the symmetries inherent to time-series for the construction of equivariant neural network. We identify two core symmetries: *scale and translation*, and construct scale-translation equivariant neural networks for time-series learning. Intriguingly, we find that scale-translation equivariant mappings share strong resemblance with the wavelet transform. Inspired by this resemblance, we term our networks Wavelet Networks, and show that they perform nested non-linear wavelet-like time-frequency transforms. Empirical results show that Wavelet Networks outperform conventional CNNs on raw waveforms",
    "link": "http://arxiv.org/abs/2006.05259",
    "context": "Title: Wavelet Networks: Scale-Translation Equivariant Learning From Raw Time-Series. (arXiv:2006.05259v2 [cs.LG] UPDATED)\nAbstract: Leveraging the symmetries inherent to specific data domains for the construction of equivariant neural networks has lead to remarkable improvements in terms of data efficiency and generalization. However, most existing research focuses on symmetries arising from planar and volumetric data, leaving a crucial data source largely underexplored: time-series. In this work, we fill this gap by leveraging the symmetries inherent to time-series for the construction of equivariant neural network. We identify two core symmetries: *scale and translation*, and construct scale-translation equivariant neural networks for time-series learning. Intriguingly, we find that scale-translation equivariant mappings share strong resemblance with the wavelet transform. Inspired by this resemblance, we term our networks Wavelet Networks, and show that they perform nested non-linear wavelet-like time-frequency transforms. Empirical results show that Wavelet Networks outperform conventional CNNs on raw waveforms",
    "path": "papers/20/06/2006.05259.json",
    "total_tokens": 882,
    "translated_title": "Wavelet Networks: 从原始时间序列学习尺度平移等变性的学习网络",
    "translated_abstract": "利用特定数据领域中固有的对称性构建等变性神经网络，可显著提高数据效率和泛化能力。然而，大多数现有研究集中在平面和体积数据中产生的对称性上，而把一个关键的数据源基本未开发：时间序列。本文通过利用时间序列的固有对称性来构建等变性神经网络，填补了这一空白。我们确认了两个核心对称性：尺度和平移，并构建了适用于时间序列学习的尺度平移等变性神经网络。有趣的是，我们发现尺度平移等变性映射与小波变换具有很强的相似性。受到这种相似性的启发，我们将我们的网络称为小波网络，并展示它们执行嵌套的非线性小波样的时频变换。实证结果表明，小波网络在原始波形上优于传统的CNN。",
    "tldr": "本文介绍了一种利用时间序列固有对称性构建的小波网络，其表现出嵌套的非线性小波样的时频变换，实验证明其在原始波形上优于传统的CNN。",
    "en_tdlr": "This paper introduces a wavelet network constructed using the inherent symmetries of time-series, which performs nested non-linear wavelet-like time-frequency transforms and outperforms conventional CNNs on raw waveforms."
}