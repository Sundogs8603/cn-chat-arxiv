{
    "title": "Sparse Quantile Regression. (arXiv:2006.11201v4 [stat.ME] UPDATED)",
    "abstract": "We consider both $\\ell _{0}$-penalized and $\\ell _{0}$-constrained quantile regression estimators. For the $\\ell _{0}$-penalized estimator, we derive an exponential inequality on the tail probability of excess quantile prediction risk and apply it to obtain non-asymptotic upper bounds on the mean-square parameter and regression function estimation errors. We also derive analogous results for the $\\ell _{0}$-constrained estimator. The resulting rates of convergence are nearly minimax-optimal and the same as those for $\\ell _{1}$-penalized and non-convex penalized estimators. Further, we characterize expected Hamming loss for the $\\ell _{0}$-penalized estimator. We implement the proposed procedure via mixed integer linear programming and also a more scalable first-order approximation algorithm. We illustrate the finite-sample performance of our approach in Monte Carlo experiments and its usefulness in a real data application concerning conformal prediction of infant birth weights (with $",
    "link": "http://arxiv.org/abs/2006.11201",
    "context": "Title: Sparse Quantile Regression. (arXiv:2006.11201v4 [stat.ME] UPDATED)\nAbstract: We consider both $\\ell _{0}$-penalized and $\\ell _{0}$-constrained quantile regression estimators. For the $\\ell _{0}$-penalized estimator, we derive an exponential inequality on the tail probability of excess quantile prediction risk and apply it to obtain non-asymptotic upper bounds on the mean-square parameter and regression function estimation errors. We also derive analogous results for the $\\ell _{0}$-constrained estimator. The resulting rates of convergence are nearly minimax-optimal and the same as those for $\\ell _{1}$-penalized and non-convex penalized estimators. Further, we characterize expected Hamming loss for the $\\ell _{0}$-penalized estimator. We implement the proposed procedure via mixed integer linear programming and also a more scalable first-order approximation algorithm. We illustrate the finite-sample performance of our approach in Monte Carlo experiments and its usefulness in a real data application concerning conformal prediction of infant birth weights (with $",
    "path": "papers/20/06/2006.11201.json",
    "total_tokens": 942,
    "translated_title": "稀疏分位回归",
    "translated_abstract": "本文考虑了$\\ell_0$惩罚和约束下的分位回归估计器。对于$\\ell_0$惩罚的估计器，我们推导出超额分位预测风险尾部概率的指数不等式，并将其应用于获得非渐近上界的均方误差和回归函数估计误差。我们还为$\\ell_0$约束的估计器推导了类似的结果。得到的收敛速率几乎是极小最优的，并且与$\\ell_1$惩罚和非凸惩罚估计器的速率相同。此外，我们还表征了$\\ell_0$惩罚估计器的期望汉明损失。我们通过混合整数线性规划和一个更可扩展的一阶近似算法实现了所提出的过程。我们通过蒙特卡罗实验展示了我们方法在有限样本情况下的性能，并在涉及婴儿出生体重的实际数据应用中展示了它的实用性。",
    "tldr": "本文研究了稀疏分位回归估计器，通过指数不等式得到了均方误差和回归函数估计误差的非渐近上界，并使用混合整数线性规划和一阶近似算法实现，能在实际数据应用中使用。",
    "en_tdlr": "This paper studies sparse quantile regression estimators, obtains non-asymptotic upper bounds on mean-square parameter and regression function estimation errors through exponential inequality, and implements it using mixed integer linear programming and first-order approximation algorithm, which can be applied in real data application."
}