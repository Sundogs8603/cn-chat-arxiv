{
    "title": "DeepTopPush: Simple and Scalable Method for Accuracy at the Top. (arXiv:2006.12293v2 [cs.LG] UPDATED)",
    "abstract": "Accuracy at the top is a special class of binary classification problems where the performance is evaluated only on a small number of relevant (top) samples. Applications include information retrieval systems or processes with manual (expensive) postprocessing. This leads to minimizing the number of irrelevant samples above a threshold. We consider classifiers in the form of an arbitrary (deep) network and propose a new method DeepTopPush for minimizing the loss function at the top. Since the threshold depends on all samples, the problem is non-decomposable. We modify the stochastic gradient descent to handle the non-decomposability in an end-to-end training manner and propose a way to estimate the threshold only from values on the current minibatch and one delayed value. We demonstrate the excellent performance of DeepTopPush on visual recognition datasets and two real-world applications. The first one selects a small number of molecules for further drug testing. The second one uses r",
    "link": "http://arxiv.org/abs/2006.12293",
    "context": "Title: DeepTopPush: Simple and Scalable Method for Accuracy at the Top. (arXiv:2006.12293v2 [cs.LG] UPDATED)\nAbstract: Accuracy at the top is a special class of binary classification problems where the performance is evaluated only on a small number of relevant (top) samples. Applications include information retrieval systems or processes with manual (expensive) postprocessing. This leads to minimizing the number of irrelevant samples above a threshold. We consider classifiers in the form of an arbitrary (deep) network and propose a new method DeepTopPush for minimizing the loss function at the top. Since the threshold depends on all samples, the problem is non-decomposable. We modify the stochastic gradient descent to handle the non-decomposability in an end-to-end training manner and propose a way to estimate the threshold only from values on the current minibatch and one delayed value. We demonstrate the excellent performance of DeepTopPush on visual recognition datasets and two real-world applications. The first one selects a small number of molecules for further drug testing. The second one uses r",
    "path": "papers/20/06/2006.12293.json",
    "total_tokens": 821,
    "translated_title": "DeepTopPush: 一种简单可扩展的Accuracy at the Top方法",
    "translated_abstract": "Accuracy at the top是一类特殊的二分类问题，其性能仅在少数相关（顶部）样本上评估。应用包括信息检索系统或需要手动（昂贵）后处理的工艺。这导致最小化超过阈值的无关样本数量。我们考虑以任意（深度）网络的形式构建分类器，并提出了一种新的DeepTopPush方法来最小化顶部的损失函数。由于阈值取决于所有样本，因此问题是不可分解的。我们修改了随机梯度下降以处理非可分解性，并提出了一种从当前迷你批次值和一个延迟值估计阈值的方法。我们展示了DeepTopPush在视觉识别数据集和两个真实应用中的优异性能。第一个应用程序选择少量分子进行进一步的药物测试。第二个应用程序使用了",
    "tldr": "DeepTopPush是一种用于解决Accuracy at the Top问题的简单而可扩展的方法，能有效地选择少量重要的样本，并在不同领域取得了优异的性能表现",
    "en_tdlr": "DeepTopPush is a simple and scalable method for solving Accuracy at the Top problems. It effectively selects a small number of relevant samples and achieves excellent performance in various fields."
}