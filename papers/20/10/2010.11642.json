{
    "title": "The Role of Mutual Information in Variational Classifiers. (arXiv:2010.11642v3 [stat.ML] UPDATED)",
    "abstract": "Overfitting data is a well-known phenomenon related with the generation of a model that mimics too closely (or exactly) a particular instance of data, and may therefore fail to predict future observations reliably. In practice, this behaviour is controlled by various--sometimes heuristics--regularization techniques, which are motivated by developing upper bounds to the generalization error. In this work, we study the generalization error of classifiers relying on stochastic encodings trained on the cross-entropy loss, which is often used in deep learning for classification problems. We derive bounds to the generalization error showing that there exists a regime where the generalization error is bounded by the mutual information between input features and the corresponding representations in the latent space, which are randomly generated according to the encoding distribution. Our bounds provide an information-theoretic understanding of generalization in the so-called class of variation",
    "link": "http://arxiv.org/abs/2010.11642",
    "context": "Title: The Role of Mutual Information in Variational Classifiers. (arXiv:2010.11642v3 [stat.ML] UPDATED)\nAbstract: Overfitting data is a well-known phenomenon related with the generation of a model that mimics too closely (or exactly) a particular instance of data, and may therefore fail to predict future observations reliably. In practice, this behaviour is controlled by various--sometimes heuristics--regularization techniques, which are motivated by developing upper bounds to the generalization error. In this work, we study the generalization error of classifiers relying on stochastic encodings trained on the cross-entropy loss, which is often used in deep learning for classification problems. We derive bounds to the generalization error showing that there exists a regime where the generalization error is bounded by the mutual information between input features and the corresponding representations in the latent space, which are randomly generated according to the encoding distribution. Our bounds provide an information-theoretic understanding of generalization in the so-called class of variation",
    "path": "papers/20/10/2010.11642.json",
    "total_tokens": 828,
    "translated_title": "互信息在变分分类器中的作用",
    "translated_abstract": "过拟合是一种众所周知的现象，与生成过度拟合特定数据实例的模型有关，因此可能无法可靠地预测未来观察结果。在实践中，通过各种，有时是启发式的正则化技术控制此行为，这些技术的动机是以开发上限来泛化误差。在这项工作中，我们研究了基于在交叉熵损失上训练的随机编码的分类器的泛化误差，这在深度学习中经常用于分类问题。我们推导了泛化误差的边界，表明存在一种区域，其中泛化误差由输入特征和与编码分布随机生成的潜空间中的相应表示之间的互信息所限制。我们的边界提供了对所谓的变异级别的泛化的信息论理解。",
    "tldr": "本文研究了基于随机编码的分类器的泛化误差，并得出了泛化误差受输入特征和潜空间表示之间互信息限制的结论。",
    "en_tdlr": "This paper studies the generalization errors of classifiers relying on stochastic encodings trained on the cross-entropy loss, and shows that the generalization error in a certain regime is bounded by the mutual information between input features and the corresponding representations in the latent space."
}