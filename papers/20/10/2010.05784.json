{
    "title": "Learning Calibrated Uncertainties for Domain Shift: A Distributionally Robust Learning Approach",
    "abstract": "We propose a framework for learning calibrated uncertainties under domain shifts, where the source (training) distribution differs from the target (test) distribution. We detect such domain shifts via a differentiable density ratio estimator and train it together with the task network, composing an adjusted softmax predictive form concerning domain shift. In particular, the density ratio estimation reflects the closeness of a target (test) sample to the source (training) distribution. We employ it to adjust the uncertainty of prediction in the task network. This idea of using the density ratio is based on the distributionally robust learning (DRL) framework, which accounts for the domain shift by adversarial risk minimization. We show that our proposed method generates calibrated uncertainties that benefit downstream tasks, such as unsupervised domain adaptation (UDA) and semi-supervised learning (SSL). On these tasks, methods like self-training and FixMatch use uncertainties to select",
    "link": "https://arxiv.org/abs/2010.05784",
    "context": "Title: Learning Calibrated Uncertainties for Domain Shift: A Distributionally Robust Learning Approach\nAbstract: We propose a framework for learning calibrated uncertainties under domain shifts, where the source (training) distribution differs from the target (test) distribution. We detect such domain shifts via a differentiable density ratio estimator and train it together with the task network, composing an adjusted softmax predictive form concerning domain shift. In particular, the density ratio estimation reflects the closeness of a target (test) sample to the source (training) distribution. We employ it to adjust the uncertainty of prediction in the task network. This idea of using the density ratio is based on the distributionally robust learning (DRL) framework, which accounts for the domain shift by adversarial risk minimization. We show that our proposed method generates calibrated uncertainties that benefit downstream tasks, such as unsupervised domain adaptation (UDA) and semi-supervised learning (SSL). On these tasks, methods like self-training and FixMatch use uncertainties to select",
    "path": "papers/20/10/2010.05784.json",
    "total_tokens": 927,
    "translated_title": "学习领域转移的校准不确定性：一种分布鲁棒学习方法",
    "translated_abstract": "我们提出了一种在领域转移下学习校准不确定性的框架，其中源（训练）分布与目标（测试）分布不同。我们通过可微的密度比估计器检测这种领域转移，并与任务网络一起训练，构成一个关于领域转移的调整后的softmax预测形式。特别地，密度比估计反映了目标（测试）样本与源（训练）分布的接近程度。我们利用它来调整任务网络中的预测不确定性。这种使用密度比的想法基于分布鲁棒学习（DRL）框架，通过对抗性风险最小化考虑领域转移。我们证明了我们提出的方法生成的校准不确定性有助于下游任务，如无监督领域自适应（UDA）和半监督学习（SSL）。在这些任务中，像自我训练和FixMatch这样的方法使用不确定性进行选择。",
    "tldr": "本论文提出了一种学习校准不确定性的方法，在领域转移下有效应用于无监督领域自适应和半监督学习等任务。通过可微的密度比估计器和分布鲁棒学习框架，我们生成了校准的不确定性，为下游任务提供了帮助。",
    "en_tdlr": "This paper proposes a method for learning calibrated uncertainties, which is effectively applied in tasks such as unsupervised domain adaptation and semi-supervised learning under domain shift. Utilizing a differentiable density ratio estimator and the distributionally robust learning framework, calibrated uncertainties are generated to benefit downstream tasks."
}