{
    "title": "Towards Robust Neural Networks via Orthogonal Diversity. (arXiv:2010.12190v5 [cs.CV] UPDATED)",
    "abstract": "Deep Neural Networks (DNNs) are vulnerable to invisible perturbations on the images generated by adversarial attacks, which raises researches on the adversarial robustness of DNNs. A series of methods represented by the adversarial training and its variants have proven as one of the most effective techniques in enhancing the DNN robustness. Generally, adversarial training focuses on enriching the training data by involving perturbed data. Such data augmentation effect of the involved perturbed data in adversarial training does not contribute to the robustness of DNN itself and usually suffers from clean accuracy drop. Towards the robustness of DNN itself, we in this paper propose a novel defense that aims at augmenting the model in order to learn features that are adaptive to diverse inputs, including adversarial examples. More specifically, to augment the model, multiple paths are embedded into the network, and an orthogonality constraint is imposed on these paths to guarantee the div",
    "link": "http://arxiv.org/abs/2010.12190",
    "context": "Title: Towards Robust Neural Networks via Orthogonal Diversity. (arXiv:2010.12190v5 [cs.CV] UPDATED)\nAbstract: Deep Neural Networks (DNNs) are vulnerable to invisible perturbations on the images generated by adversarial attacks, which raises researches on the adversarial robustness of DNNs. A series of methods represented by the adversarial training and its variants have proven as one of the most effective techniques in enhancing the DNN robustness. Generally, adversarial training focuses on enriching the training data by involving perturbed data. Such data augmentation effect of the involved perturbed data in adversarial training does not contribute to the robustness of DNN itself and usually suffers from clean accuracy drop. Towards the robustness of DNN itself, we in this paper propose a novel defense that aims at augmenting the model in order to learn features that are adaptive to diverse inputs, including adversarial examples. More specifically, to augment the model, multiple paths are embedded into the network, and an orthogonality constraint is imposed on these paths to guarantee the div",
    "path": "papers/20/10/2010.12190.json",
    "total_tokens": 894,
    "translated_title": "通过正交多样性实现稳健的神经网络",
    "translated_abstract": "深度神经网络(DNNs)对于由对抗攻击生成的图像上的看不见的扰动是脆弱的，这引发了对DNN的对抗鲁棒性的研究。一系列方法，如对抗性训练及其变种，已被证明是增强DNN鲁棒性最有效的技术之一。通常，对抗性训练侧重于通过引入扰动数据丰富训练数据。这些扰动数据的数据增强效果并不能贡献到DNN本身的鲁棒性，并且通常会导致准确率下降。为了提高DNN本身的鲁棒性，本文提出了一种新颖的防御方法，旨在通过增强模型来学习适应不同输入（包括对抗性样本）的特征。具体而言，为了增强模型，我们在网络中嵌入了多个路径，并对这些路径施加正交约束，以保证它们的多样性。",
    "tldr": "本文提出了一种通过正交多样性增强神经网络鲁棒性的方法，通过在网络中嵌入多个路径并施加正交约束，让模型学习适应不同输入的特征。",
    "en_tdlr": "This paper proposes a method to enhance the robustness of neural networks through orthogonal diversity, by embedding multiple paths in the network and imposing an orthogonality constraint, allowing the model to learn features that are adaptive to diverse inputs."
}