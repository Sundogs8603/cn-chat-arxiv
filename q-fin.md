# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Techno-Economic Analysis of Synthetic Fuel Production from Existing Nuclear Power Plants across the United States.](http://arxiv.org/abs/2309.12085) | 该论文研究了利用现有核电站生产合成燃料的技术经济潜力，结果显示将合成燃料生产与核电站耦合可以提高核电站的盈利能力，为投资者带来可观的回报。 |
| [^2] | [Estimating Stable Fixed Points and Langevin Potentials for Financial Dynamics.](http://arxiv.org/abs/2309.12082) | 本文将几何布朗运动模型推广为具有多项式漂移的随机微分方程，并通过模型选择确定最优模型为阶数为2的模型。势函数集合表明存在明显的势能井，表明稳定价格的存在。 |
| [^3] | [Singular Control in a Cash Management Model with Ambiguity.](http://arxiv.org/abs/2309.12014) | 本研究提出了一个受不确定性驱动的现金管理奇异控制模型，研究发现不确定性增加会导致最坏情况下的预期成本增加以及不活跃区域变窄。 |
| [^4] | [Stock Market Sentiment Classification and Backtesting via Fine-tuned BERT.](http://arxiv.org/abs/2309.11979) | 本论文通过构建自然语言处理模型BERT并对其进行fine-tune，实现了股市情绪的分类和基于该模型的回测分析。实验结果显示，fine-tuned模型相比原始模型和基准模型有不同程度的性能改进。 |
| [^5] | [A Comprehensive Review on Financial Explainable AI.](http://arxiv.org/abs/2309.11960) | 本文回顾了在金融领域中改善深度学习模型可解释性的各种方法，并讨论了相关的挑战和未来发展方向。 |
| [^6] | [Doubly Robust Mean-CVaR Portfolio.](http://arxiv.org/abs/2309.11693) | 本研究提出了一种双重稳健均值-CVaR投资组合方法，以解决投资组合优化中的不稳定性问题，并实现多个CVaR水平的同时优化，并为均值参数定义了不确定性集合，从而进行稳健优化。 |
| [^7] | [Explosive growth from AI automation: A review of the arguments.](http://arxiv.org/abs/2309.11690) | AI自动化的爆炸性增长是可能的，可能会加速全球经济增长，但目前对此的高度自信是不合适的。 |
| [^8] | [Global universal approximation of functional input maps on weighted spaces.](http://arxiv.org/abs/2306.03303) | 本文提出了功能性输入神经网络，可以在带权重空间上完成全局函数逼近。这一方法适用于连续函数的推广，还可用于路径空间函数的逼近，同时也可以逼近线性函数签名。 |
| [^9] | [Online Self-Concordant and Relatively Smooth Minimization, With Applications to Online Portfolio Selection and Learning Quantum States.](http://arxiv.org/abs/2210.00997) | 本文提出了一种在线自协调且相对平滑的最小化算法，通过分析在线镜像下降算法在凸函数上的遗憾，改进了在线投资组合选择算法的性能，并在在线学习量子态问题中达到了与Soft-Bayes算法相当的效果。 |
| [^10] | [Publication Bias in Asset Pricing Research.](http://arxiv.org/abs/2209.13623) | 发布偏倚是资产定价研究中的一个自然关注点。大规模元研究提供了实证证据，表明发布偏倚并不是影响研究结果的主要因素。通过经验贝叶斯统计方法对发布偏倚进行校正后，发现其对样本内平均收益只有10%至15%的影响。 |

# 详细

[^1]: 美国现有核电站合成燃料生产的技术经济分析

    Techno-Economic Analysis of Synthetic Fuel Production from Existing Nuclear Power Plants across the United States. (arXiv:2309.12085v1 [econ.GN])

    [http://arxiv.org/abs/2309.12085](http://arxiv.org/abs/2309.12085)

    该论文研究了利用现有核电站生产合成燃料的技术经济潜力，结果显示将合成燃料生产与核电站耦合可以提高核电站的盈利能力，为投资者带来可观的回报。

    

    低碳合成燃料可以取代柴油和喷气燃料等传统燃料，有助于全球范围内实现交通领域的脱碳，但需要大规模的成本效益高的生产设施。与此同时，由于经济困难，核电站正在关闭：电力价格过低且不稳定，无法覆盖运营成本。利用现有核电站生产合成燃料可能阻止这些低碳资产的损失，同时大规模生产合成燃料，但目前尚无关于这种整合能源系统的技术经济分析。我们量化了在美国五个示例核电站与合成燃料生产过程耦合的技术经济潜力，以探究不同电力市场、二氧化碳资源的获取以及燃料市场的影响。将合成燃料生产与核电站耦合可以使核电站的盈利能力增加多达7.92亿美元（2020年），同时获得10％的投资回报率。

    Low carbon synfuel can displace transport fossil fuels such as diesel and jet fuel and help achieve the decarbonization of the transportation sector at a global scale, but large-scale cost-effective production facilities are needed. Meanwhile, nuclear power plants are closing due to economic difficulties: electricity prices are too low and variable to cover their operational costs. Using existing nuclear power plants to produce synfuels might prevent loss of these low-carbon assets while producing synfuels at scale, but no technoeconomic analysis of this Integrated Energy System exist. We quantify the technoeconomic potential of coupling a synthetic fuel production process with five example nuclear power plants across the U.S. to explore the influence of different electricity markets, access to carbon dioxide sources, and fuel markets. Coupling synfuel production increases nuclear plant profitability by up to 792 million USD(2020) in addition to a 10 percent rate of return on investmen
    
[^2]: 估计金融动力学的稳定不动点和朗之万势能

    Estimating Stable Fixed Points and Langevin Potentials for Financial Dynamics. (arXiv:2309.12082v1 [q-fin.ST])

    [http://arxiv.org/abs/2309.12082](http://arxiv.org/abs/2309.12082)

    本文将几何布朗运动模型推广为具有多项式漂移的随机微分方程，并通过模型选择确定最优模型为阶数为2的模型。势函数集合表明存在明显的势能井，表明稳定价格的存在。

    

    几何布朗运动是量化金融中的标准模型，但其随机微分方程的势函数不能包含稳定的非零价格。本文将几何布朗运动推广为阶数为q的多项式漂移的随机微分方程，并通过模型选择表明q=2最常被认为是描述数据的最优模型。此外，通过马尔科夫链蒙特卡洛的势函数集合表明存在明显的势能井，表明稳定价格的存在。

    The Geometric Brownian Motion (GBM) is a standard model in quantitative finance, but the potential function of its stochastic differential equation (SDE) cannot include stable nonzero prices. This article generalises the GBM to an SDE with polynomial drift of order q and shows via model selection that q=2 is most frequently the optimal model to describe the data. Moreover, Markov chain Monte Carlo ensembles of the accompanying potential functions show a clear and pronounced potential well, indicating the existence of a stable price.
    
[^3]: 具有不确定性的现金管理模型中的奇异控制

    Singular Control in a Cash Management Model with Ambiguity. (arXiv:2309.12014v1 [q-fin.RM])

    [http://arxiv.org/abs/2309.12014](http://arxiv.org/abs/2309.12014)

    本研究提出了一个受不确定性驱动的现金管理奇异控制模型，研究发现不确定性增加会导致最坏情况下的预期成本增加以及不活跃区域变窄。

    

    本研究考虑了一个受到不确定性驱动的现金储备管理的奇异控制模型。假设经理在一组由κ-无知特征化的先验分布上具有最小最大偏好。建立了一个验证定理来确定公司的成本函数和最优现金策略；后者采用控制屏障策略的形式。在由算术布朗运动驱动的模型中，我们通过数值方法证明了不确定性增加会导致最坏情况下的预期成本增加以及不活跃区域变窄。后一效应可以用来解释观察到的现金管理行为的不确定性驱动因素。

    We consider a singular control model of cash reserve management, driven by a diffusion under ambiguity. The manager is assumed to have maxmin preferences over a set of priors characterized by $\kappa$-ignorance. A verification theorem is established to determine the firm's cost function and the optimal cash policy; the latter taking the form of a control barrier policy. In a model driven by arithmetic Brownian motion, we numerically show that an increase in ambiguity leads to higher expected costs under the worst-case prior and a narrower inaction region. The latter effect can be used to provide an ambiguity-driven explanation for observed cash management behavior.
    
[^4]: 股市情绪分类与基于Fine-tuned BERT的回测

    Stock Market Sentiment Classification and Backtesting via Fine-tuned BERT. (arXiv:2309.11979v1 [q-fin.CP])

    [http://arxiv.org/abs/2309.11979](http://arxiv.org/abs/2309.11979)

    本论文通过构建自然语言处理模型BERT并对其进行fine-tune，实现了股市情绪的分类和基于该模型的回测分析。实验结果显示，fine-tuned模型相比原始模型和基准模型有不同程度的性能改进。

    

    随着大数据和计算设备的快速发展，基于实时信息获取的低延迟自动交易平台成为股票交易市场的主要组成部分，因此量化交易的主题得到了广泛关注。对于非强有效的交易市场来说，人类情绪和期望总是主导市场趋势和交易决策。因此，本文从情绪理论出发，以东方财富为例，从其对应的股吧爬取用户评论标题数据并进行数据清洗。随后，构建了自然语言处理模型BERT，并使用现有的带有标注数据集对BERT模型进行fine-tune。实验结果表明，与原始模型和基准模型相比，fine-tuned模型有不同程度的性能改进。随后，在以上模型的基础上，对爬取的用户评论数据进行了情绪极性标注。

    With the rapid development of big data and computing devices, low-latency automatic trading platforms based on real-time information acquisition have become the main components of the stock trading market, so the topic of quantitative trading has received widespread attention. And for non-strongly efficient trading markets, human emotions and expectations always dominate market trends and trading decisions. Therefore, this paper starts from the theory of emotion, taking East Money as an example, crawling user comment titles data from its corresponding stock bar and performing data cleaning. Subsequently, a natural language processing model BERT was constructed, and the BERT model was fine-tuned using existing annotated data sets. The experimental results show that the fine-tuned model has different degrees of performance improvement compared to the original model and the baseline model. Subsequently, based on the above model, the user comment data crawled is labeled with emotional pola
    
[^5]: 对可解释性人工智能在金融领域的综合回顾

    A Comprehensive Review on Financial Explainable AI. (arXiv:2309.11960v1 [cs.AI])

    [http://arxiv.org/abs/2309.11960](http://arxiv.org/abs/2309.11960)

    本文回顾了在金融领域中改善深度学习模型可解释性的各种方法，并讨论了相关的挑战和未来发展方向。

    

    人工智能（AI）的成功，特别是深度学习模型的成功，使其在各个行业得到了广泛应用，因为它们能够处理大量数据和学习复杂模式。然而，由于缺乏可解释性，人们对于在金融和医疗等重要行业中使用这些模型存在重大担忧，因为决策透明性至关重要。在本文中，我们对在金融背景下改善深度学习模型可解释性的方法进行了对比调查。我们根据各种可解释性人工智能方法的特点对其进行分类，并回顾了采用可解释性人工智能方法的关切和挑战，以及我们认为适当和重要的未来方向。

    The success of artificial intelligence (AI), and deep learning models in particular, has led to their widespread adoption across various industries due to their ability to process huge amounts of data and learn complex patterns. However, due to their lack of explainability, there are significant concerns regarding their use in critical sectors, such as finance and healthcare, where decision-making transparency is of paramount importance. In this paper, we provide a comparative survey of methods that aim to improve the explainability of deep learning models within the context of finance. We categorize the collection of explainable AI methods according to their corresponding characteristics, and we review the concerns and challenges of adopting explainable AI methods, together with future directions we deemed appropriate and important.
    
[^6]: 双重稳健均值-CVaR组合投资组合

    Doubly Robust Mean-CVaR Portfolio. (arXiv:2309.11693v1 [q-fin.PM])

    [http://arxiv.org/abs/2309.11693](http://arxiv.org/abs/2309.11693)

    本研究提出了一种双重稳健均值-CVaR投资组合方法，以解决投资组合优化中的不稳定性问题，并实现多个CVaR水平的同时优化，并为均值参数定义了不确定性集合，从而进行稳健优化。

    

    在本研究中，我们解决了投资组合优化的挑战，这是管理投资风险和最大化回报的关键方面。由于像COVID-19大流行这样当今不稳定的金融市场危机，均值-CVaR投资组合被认为是一种有前景的方法。它将预期收益纳入CVaR中，CVaR考虑的是超过特定概率水平的损失的期望值。然而，与输入参数变化和估计误差相关的不稳定性可能会损害投资组合的表现。因此，在本研究中，我们提出了一种改进的双重稳健均值-CVaR投资组合方法来优化均值-CVaR投资组合。我们的方法可以解决不稳定性问题，同时优化多个CVaR水平，并为均值参数定义不确定性集合以进行稳健优化。从理论上讲，所提出的方法可以被形式化为一个二阶锥规划问题，这与传统的均值-方差组合优化具有相同的形式化。

    In this study, we address the challenge of portfolio optimization, a critical aspect of managing investment risks and maximizing returns. The mean-CVaR portfolio is considered a promising method due to today's unstable financial market crises like the COVID-19 pandemic. It incorporates expected returns into the CVaR, which considers the expected value of losses exceeding a specified probability level. However, the instability associated with the input parameter changes and estimation errors can deteriorate portfolio performance. Therefore in this study, we propose a Doubly Robust mean-CVaR Portfolio refined approach to the mean-CVaR portfolio optimization. Our method can solve the instability problem to simultaneously optimize the multiple levels of CVaRs and define uncertainty sets for the mean parameter to perform robust optimization. Theoretically, the proposed method can be formulated as a second-order cone programming problem which is the same formulation as traditional mean-varia
    
[^7]: AI自动化的爆炸性增长: 论证综述

    Explosive growth from AI automation: A review of the arguments. (arXiv:2309.11690v1 [econ.GN])

    [http://arxiv.org/abs/2309.11690](http://arxiv.org/abs/2309.11690)

    AI自动化的爆炸性增长是可能的，可能会加速全球经济增长，但目前对此的高度自信是不合适的。

    

    我们研究了大规模AI自动化是否能够使全球经济增长加速达到约一个数量级，类似于工业革命所带来的经济增长效应。我们确定了这种增长的三个主要驱动因素：1）AI“劳动力”的可扩展性使得规模递增再现，2）AI劳动力的快速扩张，以及3）在短时间内进行的快速自动化带来的产出大幅增加。在这个背景下，我们评估了九个反对论点，包括监管障碍、产能瓶颈、匹配问题和自动化的速度。我们暂时评估了这些论点，发现大多数都不太可能成为决定因素。我们得出结论认为，如果AI能够广泛替代人力劳动，爆炸性增长似乎是有可能的，但目前对这一说法的高度自信似乎是不合理的。关于AI监管响应的强度、生产中的物理瓶颈和AI的经济价值，仍然存在关键问题。

    We examine whether substantial AI automation could accelerate global economic growth by about an order of magnitude, akin to the economic growth effects of the Industrial Revolution. We identify three primary drivers for such growth: 1) the scalability of an AI ``labor force" restoring a regime of increasing returns to scale, 2) the rapid expansion of an AI labor force, and 3) a massive increase in output from rapid automation occurring over a brief period of time. Against this backdrop, we evaluate nine counterarguments, including regulatory hurdles, production bottlenecks, alignment issues, and the pace of automation. We tentatively assess these arguments, finding most are unlikely deciders. We conclude that explosive growth seems plausible with AI capable of broadly substituting for human labor, but high confidence in this claim seems currently unwarranted. Key questions remain about the intensity of regulatory responses to AI, physical bottlenecks in production, the economic value 
    
[^8]: 带权重空间上功能性输入映射的全局普适逼近

    Global universal approximation of functional input maps on weighted spaces. (arXiv:2306.03303v1 [stat.ML])

    [http://arxiv.org/abs/2306.03303](http://arxiv.org/abs/2306.03303)

    本文提出了功能性输入神经网络，可以在带权重空间上完成全局函数逼近。这一方法适用于连续函数的推广，还可用于路径空间函数的逼近，同时也可以逼近线性函数签名。

    

    我们引入了所谓的功能性输入神经网络，定义在可能是无限维带权重空间上，其值也在可能是无限维的输出空间中。为此，我们使用一个加性族作为隐藏层映射，以及一个非线性激活函数应用于每个隐藏层。依靠带权重空间上的Stone-Weierstrass定理，我们可以证明连续函数的推广的全局普适逼近结果，超越了常规紧集逼近。这特别适用于通过功能性输入神经网络逼近（非先见之明的）路径空间函数。作为带权Stone-Weierstrass定理的进一步应用，我们证明了线性函数签名的全局普适逼近结果。我们还在这个设置中引入了高斯过程回归的观点，并展示了签名内核的再生核希尔伯特空间是某些高斯过程的Cameron-Martin空间。

    We introduce so-called functional input neural networks defined on a possibly infinite dimensional weighted space with values also in a possibly infinite dimensional output space. To this end, we use an additive family as hidden layer maps and a non-linear activation function applied to each hidden layer. Relying on Stone-Weierstrass theorems on weighted spaces, we can prove a global universal approximation result for generalizations of continuous functions going beyond the usual approximation on compact sets. This then applies in particular to approximation of (non-anticipative) path space functionals via functional input neural networks. As a further application of the weighted Stone-Weierstrass theorem we prove a global universal approximation result for linear functions of the signature. We also introduce the viewpoint of Gaussian process regression in this setting and show that the reproducing kernel Hilbert space of the signature kernels are Cameron-Martin spaces of certain Gauss
    
[^9]: 在线自协调且相对平滑的最小化问题及其在在线投资组合选择和学习量子态中的应用

    Online Self-Concordant and Relatively Smooth Minimization, With Applications to Online Portfolio Selection and Learning Quantum States. (arXiv:2210.00997v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.00997](http://arxiv.org/abs/2210.00997)

    本文提出了一种在线自协调且相对平滑的最小化算法，通过分析在线镜像下降算法在凸函数上的遗憾，改进了在线投资组合选择算法的性能，并在在线学习量子态问题中达到了与Soft-Bayes算法相当的效果。

    

    本文考虑一类在线凸优化问题，其中损失函数是自协调障碍函数，在某个凸函数h的相对平滑，可能不是Lipschitz的。我们分析了在线镜像下降算法在h上的遗憾，并基于结果以统一的方式证明了以下结论。对于在线投资组合选择问题，当T>4d/logd时，改进了Helmbold等人提出的指数化梯度算法的遗憾界为O(T^{2/3} d^{1/3})，原有界是O(T^{3/4} d^{1/2})。对于在线投资组合选择问题，使用对数障碍的在线镜像下降算法的遗憾界为O(sqrt(Td))，与Orseau等人的Soft-Bayes算法具有相同的遗憾界，除去对数因子。对于使用对数损失的在线学习量子态问题，使用对数障碍的在线镜像下降算法的遗憾界是...

    Consider an online convex optimization problem where the loss functions are self-concordant barriers, smooth relative to a convex function $h$, and possibly non-Lipschitz. We analyze the regret of online mirror descent with $h$. Then, based on the result, we prove the following in a unified manner. Denote by $T$ the time horizon and $d$ the parameter dimension. 1. For online portfolio selection, the regret of $\widetilde{\text{EG}}$, a variant of exponentiated gradient due to Helmbold et al., is $\tilde{O} ( T^{2/3} d^{1/3} )$ when $T > 4 d / \log d$. This improves on the original $\tilde{O} ( T^{3/4} d^{1/2} )$ regret bound for $\widetilde{\text{EG}}$. 2. For online portfolio selection, the regret of online mirror descent with the logarithmic barrier is $\tilde{O}(\sqrt{T d})$. The regret bound is the same as that of Soft-Bayes due to Orseau et al. up to logarithmic terms. 3. For online learning quantum states with the logarithmic loss, the regret of online mirror descent with the log
    
[^10]: 资产定价研究中的发布偏倚

    Publication Bias in Asset Pricing Research. (arXiv:2209.13623v3 [q-fin.GN] UPDATED)

    [http://arxiv.org/abs/2209.13623](http://arxiv.org/abs/2209.13623)

    发布偏倚是资产定价研究中的一个自然关注点。大规模元研究提供了实证证据，表明发布偏倚并不是影响研究结果的主要因素。通过经验贝叶斯统计方法对发布偏倚进行校正后，发现其对样本内平均收益只有10%至15%的影响。

    

    研究人员更有可能分享显著的研究结果。因此，发表的结果往往夸大了真实世界现象的幅度。这种偏倚是资产定价研究的一个自然关注点，该领域发现了数百个收益预测因子，但对其起源没有共识。大规模元研究提供了关于发布偏倚的实证证据。横截面收益可预测性的元研究已经确定了四个表征发布偏倚不是主要因素的特征：（1）几乎所有的研究结果都能复制，（2）预测能力在样本外仍然存在，（3）经验t统计量远大于2.0，（4）预测因子弱相关。这些特征在至少三个元研究中都被证明。经验贝叶斯统计将这些特征转化为发布偏倚的校正。三个元研究的估计发现，平均校正（收缩）仅占样本内平均收益的10%至15%，而该校正值只考虑了发布偏倚的一小部分。

    Researchers are more likely to share notable findings. As a result, published findings tend to overstate the magnitude of real-world phenomena. This bias is a natural concern for asset pricing research, which has found hundreds of return predictors and little consensus on their origins.  Empirical evidence on publication bias comes from large scale meta-studies. Meta-studies of cross-sectional return predictability have settled on four stylized facts that demonstrate publication bias is not a dominant factor: (1) almost all findings can be replicated, (2) predictability persists out-of-sample, (3) empirical $t$-statistics are much larger than 2.0, and (4) predictors are weakly correlated. Each of these facts has been demonstrated in at least three meta-studies.  Empirical Bayes statistics turn these facts into publication bias corrections. Estimates from three meta-studies find that the average correction (shrinkage) accounts for only 10 to 15 percent of in-sample mean returns and that
    

