# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Applying Reinforcement Learning to Option Pricing and Hedging.](http://arxiv.org/abs/2310.04336) | 本论文研究了将强化学习应用于期权定价和对冲的方法，并介绍了Q学习Black Scholes方法。该方法能够以非模型和数据驱动的方式进行期权定价和对冲，并在不同状态变量和场景下表现出稳健的性能。 |
| [^2] | [Bespoke scapegoats: Scientific advisory bodies and blame avoidance in the Covid-19 pandemic and beyond.](http://arxiv.org/abs/2310.04312) | 本文通过研究美国、英国、瑞典、意大利、波兰和乌干达的案例，结合推卸责任文献，发现政府创建临时科学咨询机构的目的是为了为不受欢迎的政策开脱责任，ahSABs成员通常代表了一个狭窄的观点范围。对于没有创建ahSABs的瑞典的异常案例，进一步证实了这一原则。政策推论是，应该通过立法机构对ahSABs成员进行审核，以确保广泛的成员代表性。 |
| [^3] | [Multi-Industry Simplex : A Probabilistic Extension of GICS.](http://arxiv.org/abs/2310.04280) | 本论文提出了一种名为MIS的多行业概率模型，通过使用主题建模将企业灵活地分配到尽可能多的行业中，克服了当前行业分类标准 GICS 的局限性。 |
| [^4] | [A New Weighted Food CPI from Scanner Big Data in China.](http://arxiv.org/abs/2310.04242) | 这项研究介绍了一种新的加权价格指数S-FCPIw，利用中国扫描仪大数据构建，能更频繁和更丰富地反映商品价格的变动，与CPI和食品CPI存在显著关系。扫描仪大数据可以补充中国传统的CPI计算方法，并提供新的宏观经济趋势和通胀预测见解。 |
| [^5] | [Approximating the set of Nash equilibria for convex games.](http://arxiv.org/abs/2310.04176) | 本文研究了近似计算凸博弈中的纳什均衡解集合，证明了纳什均衡解集合可以等价地表示为多个多目标问题的帕累托最优点的交集。 |
| [^6] | [Efficient option pricing in the rough Heston model using weak simulation schemes.](http://arxiv.org/abs/2310.04146) | 本文提出了一种在粗糙Heston模型中高效且准确的模拟方案，通过低维马尔可夫逼近实现对该模型的弱逼近。该方案在计算成本方面具有线性增加，并表现出二阶弱收敛性。在对多种类型期权进行的数值测试中展示了方案的准确性和效率。 |
| [^7] | [Estimation of market efficiency process within time-varying autoregressive models by extended Kalman filtering approach.](http://arxiv.org/abs/2310.04125) | 本文提出了一种利用扩展卡尔曼滤波器准确估计时间变异自回归模型中市场效率过程的隐藏动力学的方法。 |
| [^8] | [Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models.](http://arxiv.org/abs/2310.04027) | 本文通过引入检索增强型的大型语言模型框架，提升金融情感分析的效果，并解决了传统模型在参数规模和训练数据范围方面的限制。 |
| [^9] | [Income Mobility and Mixing in North Macedonia.](http://arxiv.org/abs/2309.17268) | 本研究分析了北马其顿的收入流动性和混合度，发现90年代的流动性较大，但之后呈下降趋势，混合时间稳定在约4年左右。通过使用MFPT指标，研究还显示了1995年到2006年之间MFPT明显上升，随后下降直至2017年，然后再次上升至2021年的峰值。这些结果为北马其顿的收入流动性提供了基础性的视角。 |
| [^10] | [Predicting China's CPI by Scanner Big Data.](http://arxiv.org/abs/2211.16641) | 本研究利用扫描仪大数据构建了中国的扫描仪食品消费价格指数（S-FCPI），并基于该指数建立了多个机器学习模型，成功预测了CPI增长率和趋势。该研究为中国利用扫描仪大数据构建和预测价格指数提供了新途径。 |
| [^11] | [Exit game with private information.](http://arxiv.org/abs/2210.01610) | 这篇论文研究了一个具有竞争和不确定性的退出随机游戏，在其中玩家通过使用状态变量和后验信念过程的复杂退出策略来确定退出时机，并构建了一种均衡解。这种均衡解在一类对称贝叶斯均衡中是唯一的。 |
| [^12] | [Calibration of Derivative Pricing Models: a Multi-Agent Reinforcement Learning Perspective.](http://arxiv.org/abs/2203.06865) | 本文利用多智能体强化学习提出校准衍生品定价模型问题的博弈论解决方案，并希望该方法可用于解决其他金融领域的问题。实验证明，该算法能够学习局部波动率以及最小化百慕大期权价格所需的路径依赖性。 |
| [^13] | [Analysis of taste heterogeneity in commuters travel decisions using joint parking and mode choice model: A case from urban India.](http://arxiv.org/abs/2109.01045) | 本研究通过将停车选择作为出行模式选择模型的内生决策，综合考虑态度因素和建筑环境变量，填补了单独考虑出行方式和停车选择行为之间权衡的空白。 |
| [^14] | [A Bonus-Malus Framework for Cyber Risk Insurance and Optimal Cybersecurity Provisioning.](http://arxiv.org/abs/2102.05568) | 本研究提出了基于奖惩系统的网络风险保险模型，通过调整风险转移产品的保费以激励网络损失减少，解决道德风险问题并让保险商受益的可能性。 |

# 详细

[^1]: 将强化学习应用于期权定价和对冲的研究

    Applying Reinforcement Learning to Option Pricing and Hedging. (arXiv:2310.04336v1 [q-fin.CP])

    [http://arxiv.org/abs/2310.04336](http://arxiv.org/abs/2310.04336)

    本论文研究了将强化学习应用于期权定价和对冲的方法，并介绍了Q学习Black Scholes方法。该方法能够以非模型和数据驱动的方式进行期权定价和对冲，并在不同状态变量和场景下表现出稳健的性能。

    

    本论文概述了近年来在金融产品定价和对冲中应用强化学习的最新进展，重点介绍了由Halperin（2017）提出的Q学习Black Scholes方法的详细解释。这种强化学习方法将传统的Black and Scholes（1973）模型与新颖的人工智能算法相结合，以完全的非模型和数据驱动的方式进行期权定价和对冲。本文还研究了该算法在不同状态变量和场景下对欧式看跌期权的表现。结果表明，该模型在不同波动率和对冲频率水平下具有较高的准确性。此外，该方法在不同期权平价点的水平上表现出稳健的性能。最后，该算法包括比例交易成本，表明不同状态变量的统计特性对收益和损失产生不同的影响。

    This thesis provides an overview of the recent advances in reinforcement learning in pricing and hedging financial instruments, with a primary focus on a detailed explanation of the Q-Learning Black Scholes approach, introduced by Halperin (2017). This reinforcement learning approach bridges the traditional Black and Scholes (1973) model with novel artificial intelligence algorithms, enabling option pricing and hedging in a completely model-free and data-driven way. This paper also explores the algorithm's performance under different state variables and scenarios for a European put option. The results reveal that the model is an accurate estimator under different levels of volatility and hedging frequency. Moreover, this method exhibits robust performance across various levels of option's moneyness. Lastly, the algorithm incorporates proportional transaction costs, indicating diverse impacts on profit and loss, affected by different statistical properties of the state variables.
    
[^2]: 定制替罪羊：科学咨询机构与新冠疫情及其后续中的推卸责任（arXiv:2310.04312v1 [econ.GN]）

    Bespoke scapegoats: Scientific advisory bodies and blame avoidance in the Covid-19 pandemic and beyond. (arXiv:2310.04312v1 [econ.GN])

    [http://arxiv.org/abs/2310.04312](http://arxiv.org/abs/2310.04312)

    本文通过研究美国、英国、瑞典、意大利、波兰和乌干达的案例，结合推卸责任文献，发现政府创建临时科学咨询机构的目的是为了为不受欢迎的政策开脱责任，ahSABs成员通常代表了一个狭窄的观点范围。对于没有创建ahSABs的瑞典的异常案例，进一步证实了这一原则。政策推论是，应该通过立法机构对ahSABs成员进行审核，以确保广泛的成员代表性。

    

    学者们没有探究为什么这么多政府在应对新冠疫情时创建了临时科学咨询机构（ahSABs）而不依赖现有的公共卫生基础设施。我们通过对美国、英国、瑞典、意大利、波兰和乌干达的案例研究以及对推卸责任文献的借鉴，回答了这个被忽视的问题。我们发现，ahSABs的创建是为了为不受欢迎的政策开脱责任，事情出问题时成为替罪羊。因此，ahSABs的成员通常代表了一个狭窄的观点范围。ahSABs是一个好的替罪羊，因为它对减少政府的自由裁量权几乎没有帮助，并且在转嫁责任给政府方面能力有限。我们对瑞典没有创建ahSABs的异常案例的解释进一步证实了我们的一般原则。我们得出的政策推论是，应该通过立法机构对ahSABs成员进行审核，以确保广泛的成员代表性。

    Scholars have not asked why so many governments created ad hoc scientific advisory bodies (ahSABs) to address the Covid-19 pandemic instead of relying on existing public health infrastructure. We address this neglected question with an exploratory study of the US, UK, Sweden, Italy, Poland, and Uganda. Drawing on our case studies and the blame-avoidance literature, we find that ahSABs are created to excuse unpopular policies and take the blame should things go wrong. Thus, membership typically represents a narrow range of perspectives. An ahSAB is a good scapegoat because it does little to reduce government discretion and has limited ability to deflect blame back to government. Our explanation of our deviant case of Sweden, that did not create and ahSAB, reinforces our general principles. We draw the policy inference that ahSAB membership should be vetted by the legislature to ensure broad membership.
    
[^3]: 多行业Simplex：GICS的概率扩展

    Multi-Industry Simplex : A Probabilistic Extension of GICS. (arXiv:2310.04280v1 [q-fin.PM])

    [http://arxiv.org/abs/2310.04280](http://arxiv.org/abs/2310.04280)

    本论文提出了一种名为MIS的多行业概率模型，通过使用主题建模将企业灵活地分配到尽可能多的行业中，克服了当前行业分类标准 GICS 的局限性。

    

    准确的行业分类是许多资产管理应用程序的重要工具。尽管当前的行业黄金标准GICS（全球行业分类标准）在许多环境下已被证明是可靠和稳健的，但它存在一些不可忽视的局限性。从根本上说，GICS是一个单一行业模型，每个企业都被分配到一个组，不管该企业的多样化程度如何。这种方法在像亚马逊这样的大型企业中失效，这些企业的风险敞口分布在多个部门。我们试图通过开发MIS（Multi-Industry Simplex）来克服这些局限性，这是一个概率模型，可以根据数据灵活地将企业分配给尽可能多的行业。特别是，我们利用主题建模，即自然语言处理方法，利用业务描述提取和识别相应的行业。每个识别的行业都附带着一个相关概率，可以进行高度解释。

    Accurate industry classification is a critical tool for many asset management applications. While the current industry gold-standard GICS (Global Industry Classification Standard) has proven to be reliable and robust in many settings, it has limitations that cannot be ignored. Fundamentally, GICS is a single-industry model, in which every firm is assigned to exactly one group regardless of how diversified that firm may be. This approach breaks down for large conglomerates like Amazon, which have risk exposure spread out across multiple sectors. We attempt to overcome these limitations by developing MIS (Multi-Industry Simplex), a probabilistic model that can flexibly assign a firm to as many industries as can be supported by the data. In particular, we utilize topic modeling, an natural language processing approach that utilizes business descriptions to extract and identify corresponding industries. Each identified industry comes with a relevance probability, allowing for high interp
    
[^4]: 中国基于扫描仪大数据构建的新加权食品CPI

    A New Weighted Food CPI from Scanner Big Data in China. (arXiv:2310.04242v1 [econ.GN])

    [http://arxiv.org/abs/2310.04242](http://arxiv.org/abs/2310.04242)

    这项研究介绍了一种新的加权价格指数S-FCPIw，利用中国扫描仪大数据构建，能更频繁和更丰富地反映商品价格的变动，与CPI和食品CPI存在显著关系。扫描仪大数据可以补充中国传统的CPI计算方法，并提供新的宏观经济趋势和通胀预测见解。

    

    扫描仪大数据有潜力构建消费价格指数（CPI）。本研究介绍了一种新的加权价格指数S-FCPIw，该指数利用中国零售销售的扫描仪大数据构建。我们解决了中国CPI存在的高成本和及时性发布方面的局限性，并通过与现有价格指数的比较证明了S-FCPIw的可靠性。S-FCPIw不仅能更频繁和更丰富地反映商品价格的变动，而且分析结果显示S-FCPIw与CPI和食品CPI存在显著且强烈的关系。研究结果表明，扫描仪大数据可以补充中国传统的CPI计算方法，并为宏观经济趋势和通胀预测提供新的见解。我们已经公开了S-FCPIw并且每周更新，以促进该领域的进一步研究。

    Scanner big data has potential to construct Consumer Price Index (CPI). The study introduces a new weighted price index called S-FCPIw, which is constructed using scanner big data from retail sales in China. We address the limitations of China's CPI especially for its high cost and untimely release, and demonstrate the reliability of S-FCPIw by comparing it with existing price indices. S-FCPIw can not only reflect the changes of goods prices in higher frequency and richer dimension, and the analysis results show that S-FCPIw has a significant and strong relationship with CPI and Food CPI. The findings suggest that scanner big data can supplement traditional CPI calculations in China and provide new insights into macroeconomic trends and inflation prediction. We have made S-FCPIw publicly available and update it on a weekly basis to facilitate further study in this field.
    
[^5]: 近似计算凸博弈中纳什均衡解集合

    Approximating the set of Nash equilibria for convex games. (arXiv:2310.04176v1 [math.OC])

    [http://arxiv.org/abs/2310.04176](http://arxiv.org/abs/2310.04176)

    本文研究了近似计算凸博弈中的纳什均衡解集合，证明了纳什均衡解集合可以等价地表示为多个多目标问题的帕累托最优点的交集。

    

    在Feinstein和Rudloff（2023）中，他们证明了对于任意非合作$N$人博弈，纳什均衡解集合与具有非凸顺序锥的某个向量优化问题的帕累托最优点集合是一致的。为了避免处理非凸顺序锥，我们证明了将纳什均衡解集合等价地表示为$N$个多目标问题（即具有自然顺序锥）的帕累托最优点的交集。目前，计算多目标问题的精确帕累托最优点集合的算法仅适用于线性问题的类别，这将导致这些算法只能用于解线性博弈的真实纳什均衡集合的可能性降低。本文中，我们将考虑更大类别的凸博弈。由于通常只能为凸向量优化问题计算近似解，我们首先展示了类似于上述结果的结果，即$\epsilon$-近似纳什均衡解集合与问题完全相似。

    In Feinstein and Rudloff (2023), it was shown that the set of Nash equilibria for any non-cooperative $N$ player game coincides with the set of Pareto optimal points of a certain vector optimization problem with non-convex ordering cone. To avoid dealing with a non-convex ordering cone, an equivalent characterization of the set of Nash equilibria as the intersection of the Pareto optimal points of $N$ multi-objective problems (i.e.\ with the natural ordering cone) is proven. So far, algorithms to compute the exact set of Pareto optimal points of a multi-objective problem exist only for the class of linear problems, which reduces the possibility of finding the true set of Nash equilibria by those algorithms to linear games only.  In this paper, we will consider the larger class of convex games. As, typically, only approximate solutions can be computed for convex vector optimization problems, we first show, in total analogy to the result above, that the set of $\epsilon$-approximate Nash
    
[^6]: 使用弱模拟方案在粗糙Heston模型中进行高效的期权定价

    Efficient option pricing in the rough Heston model using weak simulation schemes. (arXiv:2310.04146v1 [q-fin.CP])

    [http://arxiv.org/abs/2310.04146](http://arxiv.org/abs/2310.04146)

    本文提出了一种在粗糙Heston模型中高效且准确的模拟方案，通过低维马尔可夫逼近实现对该模型的弱逼近。该方案在计算成本方面具有线性增加，并表现出二阶弱收敛性。在对多种类型期权进行的数值测试中展示了方案的准确性和效率。

    

    我们提供了一种在标准（$H>0$）和超粗糙（$H>-1/2$）范围内对粗糙Heston模型进行高效而准确的模拟方案。该方案基于对粗糙Heston过程的低维马尔可夫逼近，并提供对粗糙Heston过程的弱逼近。数值实验表明，新方案表现出二阶弱收敛性，而计算成本与时间步长的数量线性增加。相比之下，基于对潜在随机Volterra积分的离散化的现有方案（如Gatheral的HQE方案）计算成本呈二次依赖关系。对标准和路径依赖欧式期权以及百慕大期权进行的大量数值测试显示了该方法的准确性和效率。

    We provide an efficient and accurate simulation scheme for the rough Heston model in the standard ($H>0$) as well as the hyper-rough regime ($H > -1/2$). The scheme is based on low-dimensional Markovian approximations of the rough Heston process derived in [Bayer and Breneis, arXiv:2309.07023], and provides weak approximation to the rough Heston process. Numerical experiments show that the new scheme exhibits second order weak convergence, while the computational cost increases linear with respect to the number of time steps. In comparison, existing schemes based on discretization of the underlying stochastic Volterra integrals such as Gatheral's HQE scheme show a quadratic dependence of the computational cost. Extensive numerical tests for standard and path-dependent European options and Bermudan options show the method's accuracy and efficiency.
    
[^7]: 基于扩展卡尔曼滤波方法的时间变异自回归模型中市场效率过程的估计

    Estimation of market efficiency process within time-varying autoregressive models by extended Kalman filtering approach. (arXiv:2310.04125v1 [math.OC])

    [http://arxiv.org/abs/2310.04125](http://arxiv.org/abs/2310.04125)

    本文提出了一种利用扩展卡尔曼滤波器准确估计时间变异自回归模型中市场效率过程的隐藏动力学的方法。

    

    本文探讨了适应性市场假设（AMH）中的弱式市场效率的时间变异版本。在观察到的回报序列的序列自相关分析中，建模和估计市场效率程度的最常见方法之一是采用时间变异自回归（AR）过程，并且传统上通过卡尔曼滤波器（KF）进行估计。然而，作为线性估计器，KF很难跟踪隐含的非线性动力学，而这是所研究模型的重要特征。本文的贡献具体有三个方面：首先，我们简要介绍了计量经济学文献中用于测试弱式市场效率的时间变异AR模型和估计方法；其次，我们提出了一种新的准确估计方法，用于恢复不断演化的市场效率水平的隐藏过程，该方法基于扩展卡尔曼滤波器。

    This paper explores a time-varying version of weak-form market efficiency that is a key component of the so-called Adaptive Market Hypothesis (AMH). One of the most common methodologies used for modeling and estimating a degree of market efficiency lies in an analysis of the serial autocorrelation in observed return series. Under the AMH, a time-varying market efficiency level is modeled by time-varying autoregressive (AR) process and traditionally estimated by the Kalman filter (KF). Being a linear estimator, the KF is hardly capable to track the hidden nonlinear dynamics that is an essential feature of the models under investigation. The contribution of this paper is threefold. We first provide a brief overview of time-varying AR models and estimation methods utilized for testing a weak-form market efficiency in econometrics literature. Secondly, we propose novel accurate estimation approach for recovering the hidden process of evolving market efficiency level by the extended Kalman 
    
[^8]: 通过检索增强的大型语言模型提升金融情感分析

    Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models. (arXiv:2310.04027v1 [cs.CL])

    [http://arxiv.org/abs/2310.04027](http://arxiv.org/abs/2310.04027)

    本文通过引入检索增强型的大型语言模型框架，提升金融情感分析的效果，并解决了传统模型在参数规模和训练数据范围方面的限制。

    

    金融情感分析对于估值和投资决策至关重要。然而，传统的自然语言处理模型受其参数规模和训练数据集范围的限制，其泛化能力和在该领域的有效性受到了限制。最近，以广泛语料库进行预训练的大型语言模型（LLMs）由于其令人称赞的零样本能力，在各种自然语言处理任务中展示了优越的性能。然而，直接将LLMs应用于金融情感分析存在挑战：LLMs的预训练目标与情感标签预测之间的差异可能会 compromise其预测性能。此外，金融新闻的简洁性，常常缺乏足够的上下文，也可能会显著降低LLMs的情感分析可靠性。为了解决这些挑战，我们提出了一个用于金融情感分析的检索增强型LLMs框架。

    Financial sentiment analysis is critical for valuation and investment decision-making. Traditional NLP models, however, are limited by their parameter size and the scope of their training datasets, which hampers their generalization capabilities and effectiveness in this field. Recently, Large Language Models (LLMs) pre-trained on extensive corpora have demonstrated superior performance across various NLP tasks due to their commendable zero-shot abilities. Yet, directly applying LLMs to financial sentiment analysis presents challenges: The discrepancy between the pre-training objective of LLMs and predicting the sentiment label can compromise their predictive performance. Furthermore, the succinct nature of financial news, often devoid of sufficient context, can significantly diminish the reliability of LLMs' sentiment analysis. To address these challenges, we introduce a retrieval-augmented LLMs framework for financial sentiment analysis. This framework includes an instruction-tuned L
    
[^9]: North Macedonia的收入流动性和混合度分析

    Income Mobility and Mixing in North Macedonia. (arXiv:2309.17268v1 [econ.GN])

    [http://arxiv.org/abs/2309.17268](http://arxiv.org/abs/2309.17268)

    本研究分析了北马其顿的收入流动性和混合度，发现90年代的流动性较大，但之后呈下降趋势，混合时间稳定在约4年左右。通过使用MFPT指标，研究还显示了1995年到2006年之间MFPT明显上升，随后下降直至2017年，然后再次上升至2021年的峰值。这些结果为北马其顿的收入流动性提供了基础性的视角。

    

    本研究首次分析了1995年至2021年期间北马其顿的收入流动性，使用了混合时间和平均首次通行时间（MFPT）度量。我们发现在90年代的流动性更大（以混合时间衡量），但在1999年之前流动性呈下降趋势。此后，混合时间保持在约4年左右的稳定值。通过使用MFPT，我们突出了个人在追求更高收入层次时所面临的不断变化的挑战。具体而言，我们发现从1995年到2006年，MFPT呈明显上升趋势，随后下降直至2017年，然后再次上升，达到2021年的峰值。这些发现为我们提供了关于北马其顿的收入流动性的基础性视角。

    This study presents the inaugural analysis of income mobility in North Macedonia from 1995-2021 using the Mixing Time and Mean First Passage Time (MFPT) metrics. We document larger mobility (in terms of Mixing Time) during the '90s, with and decreasing trend (in terms of mobility) until 1999. After this year the Mixing time has been consistent with a value of around 4 years. Using the MFPT, we highlight the evolving challenges individuals face when aspiring to higher income tiers. Namely, we show that there was a noticeable upward trend in MFPT from 1995 to 2006, a subsequent decline until 2017, and then an ascent again, peaking in 2021. These findings provide a foundational perspective on the income mobility in North Macedonia.
    
[^10]: 利用扫描仪大数据预测中国的消费者物价指数

    Predicting China's CPI by Scanner Big Data. (arXiv:2211.16641v3 [econ.GN] UPDATED)

    [http://arxiv.org/abs/2211.16641](http://arxiv.org/abs/2211.16641)

    本研究利用扫描仪大数据构建了中国的扫描仪食品消费价格指数（S-FCPI），并基于该指数建立了多个机器学习模型，成功预测了CPI增长率和趋势。该研究为中国利用扫描仪大数据构建和预测价格指数提供了新途径。

    

    扫描仪大数据有潜力构建消费者物价指数（CPI）。本研究利用中国蚂蚁商户联盟提供的超市零售销售的扫描仪数据，构建中国的扫描仪食品消费价格指数（S-FCPI），并通过其他宏观指标，特别是中国的CPI来验证指数的可靠性。此外，我们基于S-FCPI构建了多个机器学习模型，以定量预测月度CPI增长率，并定性预测其方向和水平。与现有研究中的传统时间序列模型相比，预测模型的性能显著提高。这项工作为利用扫描仪大数据构建和预测价格指数在中国铺平了道路。S-FCPI不仅可以以比CPI更高的频率和更广泛的地理维度反映商品价格的变化，还可以为监测宏观经济运行、预测通胀和理解经济趋势提供新的视角。

    Scanner big data has potential to construct Consumer Price Index (CPI). This work utilizes the scanner data of supermarket retail sales, which are provided by China Ant Business Alliance (CAA), to construct the Scanner-data Food Consumer Price Index (S-FCPI) in China, and the index reliability is verified by other macro indicators, especially by China's CPI. And not only that, we build multiple machine learning models based on S-FCPI to quantitatively predict the CPI growth rate in months, and qualitatively predict those directions and levels. The prediction models achieve much better performance than the traditional time series models in existing research. This work paves the way to construct and predict price indexes through using scanner big data in China. S-FCPI can not only reflect the changes of goods prices in higher frequency and wider geographic dimension than CPI, but also provide a new perspective for monitoring macroeconomic operation, predicting inflation and understanding
    
[^11]: 具有私人信息的退出游戏

    Exit game with private information. (arXiv:2210.01610v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2210.01610](http://arxiv.org/abs/2210.01610)

    这篇论文研究了一个具有竞争和不确定性的退出随机游戏，在其中玩家通过使用状态变量和后验信念过程的复杂退出策略来确定退出时机，并构建了一种均衡解。这种均衡解在一类对称贝叶斯均衡中是唯一的。

    

    确定退出时机是一项重要但困难的商业决策，尤其是在竞争与不确定性之下。受到这个问题的启发，我们研究了一种退出的随机游戏，其中玩家对竞争对手的退出价值存在不确定性。我们构建了一种均衡解，适用于受一维扩散驱动的大类支付流。在均衡中，玩家采用复杂的退出策略，涉及状态变量和后验信念过程。这些策略可以明确地用问题数据和辅助最优停止问题的解来表示。我们得到的均衡被进一步证明在一类对称贝叶斯均衡中是唯一的。

    The timing of strategic exit is one of the most important but difficult business decisions, especially under competition and uncertainty. Motivated by this problem, we examine a stochastic game of exit in which players are uncertain about their competitor's exit value. We construct an equilibrium for a large class of payoff flows driven by a general one-dimensional diffusion. In the equilibrium, the players employ sophisticated exit strategies involving both the state variable and the posterior belief process. These strategies are specified explicitly in terms of the problem data and a solution to an auxiliary optimal stopping problem. The equilibrium we obtain is further shown to be unique within a wide subclass of symmetric Bayesian equilibria.
    
[^12]: 衍生品定价模型的校准：多智能体强化学习观点

    Calibration of Derivative Pricing Models: a Multi-Agent Reinforcement Learning Perspective. (arXiv:2203.06865v3 [q-fin.CP] UPDATED)

    [http://arxiv.org/abs/2203.06865](http://arxiv.org/abs/2203.06865)

    本文利用多智能体强化学习提出校准衍生品定价模型问题的博弈论解决方案，并希望该方法可用于解决其他金融领域的问题。实验证明，该算法能够学习局部波动率以及最小化百慕大期权价格所需的路径依赖性。

    

    在量化金融中最基本的问题之一是存在适合给定一组期权市场价格的连续时间扩散模型。传统上，人们使用直觉、理论和经验分析的混合方法来寻找实现精确或近似匹配的模型。我们的贡献在于展示如何通过适当的博弈理论形式化问题，借助现代深度多智能体强化学习的现有进展来搜索随机过程空间，以解决这个问题。更重要的是，我们希望我们的技术可以被社区利用和扩展，以解决该领域的重要问题，如联合SPX-VIX校准问题。我们的实验表明，我们能够学习局部波动率以及在波动率过程中所需的路径依赖性，以最小化百慕大期权的价格。我们的算法可以看作是一种粒子方法，类似于Guyon et Henry-Labordere的方法。

    One of the most fundamental questions in quantitative finance is the existence of continuous-time diffusion models that fit market prices of a given set of options. Traditionally, one employs a mix of intuition, theoretical and empirical analysis to find models that achieve exact or approximate fits. Our contribution is to show how a suitable game theoretical formulation of this problem can help solve this question by leveraging existing developments in modern deep multi-agent reinforcement learning to search in the space of stochastic processes. More importantly, we hope that our techniques can be leveraged and extended by the community to solve important problems in that field, such as the joint SPX-VIX calibration problem. Our experiments show that we are able to learn local volatility, as well as path-dependence required in the volatility process to minimize the price of a Bermudan option. Our algorithm can be seen as a particle method \`{a} la Guyon et Henry-Labordere where partic
    
[^13]: 利用联合停车和出行模式选择模型分析通勤者出行决策的口味异质性：以印度城市为例

    Analysis of taste heterogeneity in commuters travel decisions using joint parking and mode choice model: A case from urban India. (arXiv:2109.01045v3 [econ.GN] UPDATED)

    [http://arxiv.org/abs/2109.01045](http://arxiv.org/abs/2109.01045)

    本研究通过将停车选择作为出行模式选择模型的内生决策，综合考虑态度因素和建筑环境变量，填补了单独考虑出行方式和停车选择行为之间权衡的空白。

    

    交通需求管理的概念通过在城市中实现最佳平衡的交通模式份额来促进可持续出行的发展，而模式份额管理直接反映了每个交通子系统，包括停车场的TDM。在发展中国家，政策制定者主要关注供给侧措施，而需求侧措施在政策影响方面尚未得到解决。有大量的文献介绍了TDM策略的响应，但大多数研究单独考虑了出行方式和停车选择行为，而没有考虑它们之间的权衡。不这样做可能会导致偏见模型估计和政策应用的不当。本文试图通过将停车选择作为模式选择行为模型中的内生决策来填补这一空白。本研究将态度因素和建筑环境变量与停车和出行属性相结合，以开发综合的联合停车和出行模式选择模型。

    The concept of transportation demand management (TDM) upholds the development of sustainable mobility through the triumph of optimally balanced transport modal share in cities. The modal split management directly reflects on TDM of each transport subsystem, including parking. In developing countries, the policy-makers have largely focused on supply-side measures, yet demand-side measures have remained unaddressed in policy implications. Ample literature is available presenting responses of TDM strategies, but most studies account mode choice and parking choice behaviour separately rather than considering trade-offs between them. Failing to do so may lead to biased model estimates and impropriety in policy implications. This paper seeks to fill this gap by admitting parking choice as an endogenous decision within the model of mode choice behaviour. This study integrates attitudinal factors and built-environment variables in addition to parking and travel attributes for developing compre
    
[^14]: 基于奖惩系统的网络风险保险与最优网络安全配置框架

    A Bonus-Malus Framework for Cyber Risk Insurance and Optimal Cybersecurity Provisioning. (arXiv:2102.05568v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2102.05568](http://arxiv.org/abs/2102.05568)

    本研究提出了基于奖惩系统的网络风险保险模型，通过调整风险转移产品的保费以激励网络损失减少，解决道德风险问题并让保险商受益的可能性。

    

    虽然网络损失的规模越来越大且网络损失事件的发生率也在增加，但网络风险保险市场仍处于发展的初级阶段。现有的网络风险保险产品和学术研究一直关注对网络损失事件进行分类和模型开发，但很少关注通过调整风险转移产品的保费以激励网络损失减少的保险风险转移策略的提出。为了填补这一重要痛点，我们开发了一个基于奖惩系统的网络风险保险模型。具体而言，我们提出了一个网络风险保险和网络安全配置的数学模型，并支持动态规划的高效数值算法。通过数值实验，我们演示了一个正确设计的基于奖惩系统的网络风险保险合同如何解决道德风险的问题并让保险商受益的可能性。

    The cyber risk insurance market is at a nascent stage of its development, even as the magnitude of cyber losses is significant and the rate of cyber loss events is increasing. Existing cyber risk insurance products as well as academic studies have been focusing on classifying cyber loss events and developing models of these events, but little attention has been paid to proposing insurance risk transfer strategies that incentivise mitigation of cyber loss through adjusting the premium of the risk transfer product. To address this important gap, we develop a Bonus-Malus model for cyber risk insurance. Specifically, we propose a mathematical model of cyber risk insurance and cybersecurity provisioning supported with an efficient numerical algorithm based on dynamic programming. Through a numerical experiment, we demonstrate how a properly designed cyber risk insurance contract with a Bonus-Malus system can resolve the issue of moral hazard and benefit the insurer.
    

