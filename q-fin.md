# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A necessary and sufficient condition for the existence of chaotic price dynamics in an exchange economy.](http://arxiv.org/abs/2309.09176) | 该论文研究了一个标准的交换经济模型，给出了在Walras-Samuelson价格调整过程中存在混沌价格动态的必要和充分条件，并应用了最近的研究结果进行了拓扑混沌存在性的分析。 |
| [^2] | [Strategic Trading in Quantitative Markets through Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2303.11959) | 本文将CPPI和TIPP策略集成到多智能体深度确定性策略梯度中，提出了两种特定设计的MARL方法CPPI-MADDPG和TIPP-MADDPG，用于量化市场的战略交易，结果显示这些方法通常优于传统方法。 |

# 详细

[^1]: 一个交换经济中混沌价格动态存在的必要和充分条件

    A necessary and sufficient condition for the existence of chaotic price dynamics in an exchange economy. (arXiv:2309.09176v1 [econ.GN])

    [http://arxiv.org/abs/2309.09176](http://arxiv.org/abs/2309.09176)

    该论文研究了一个标准的交换经济模型，给出了在Walras-Samuelson价格调整过程中存在混沌价格动态的必要和充分条件，并应用了最近的研究结果进行了拓扑混沌存在性的分析。

    

    在这个研究中，我们研究了一个标准的交换经济模型，其中包括Cobb-Douglas类型的消费者，并给出了Walras-Samuelson（tatonnement）价格调整过程中存在拓扑混沌的必要和充分条件。这是对Deng、Khan、Mitra（2022）最近的研究结果在一个单峰区间映射的拓扑混沌存在性进行的新应用。

    In this note, we study a standard exchange economy model with Cobb-Douglas type consumers and give a necessary and sufficient condition for the existence of a topological chaos in the Walras-Samuelson (tatonnement) price adjustment process. This is a new application of a recent result characterising the existence of a topological chaos for a unimodal interval map by Deng, Khan, Mitra (2022).
    
[^2]: 多智能体强化学习在量化市场中的战略交易研究

    Strategic Trading in Quantitative Markets through Multi-Agent Reinforcement Learning. (arXiv:2303.11959v1 [q-fin.TR])

    [http://arxiv.org/abs/2303.11959](http://arxiv.org/abs/2303.11959)

    本文将CPPI和TIPP策略集成到多智能体深度确定性策略梯度中，提出了两种特定设计的MARL方法CPPI-MADDPG和TIPP-MADDPG，用于量化市场的战略交易，结果显示这些方法通常优于传统方法。

    

    在量化市场中，由于市场动态快速变化和大量的不确定性，如何采取适当的行动利润仍然是一个具有挑战性的问题。强化学习作为一种面向奖励的最优控制方法，在这种复杂的金融场景中已成为解决策略决策问题的有希望的方法。本文将两种先前的金融交易策略（恒定比例组合保险（CPPI）和时间不变组合保护（TIPP））集成到多智能体深度确定性策略梯度（MADDPG）中，并提出了两种特别设计的多智能体强化学习（MARL）方法：CPPI-MADDPG和TIPP-MADDPG研究量化市场中的战略交易。之后，我们选择了实际金融市场上的100种不同股票来测试这些特别提出的方法。实验结果表明，CPPI-MADDPG和TIPP-MADDPG方法通常优于传统方法。

    Due to the rapid dynamics and a mass of uncertainties in the quantitative markets, the issue of how to take appropriate actions to make profits in stock trading remains a challenging one. Reinforcement learning (RL), as a reward-oriented approach for optimal control, has emerged as a promising method to tackle this strategic decision-making problem in such a complex financial scenario. In this paper, we integrated two prior financial trading strategies named constant proportion portfolio insurance (CPPI) and time-invariant portfolio protection (TIPP) into multi-agent deep deterministic policy gradient (MADDPG) and proposed two specifically designed multi-agent RL (MARL) methods: CPPI-MADDPG and TIPP-MADDPG for investigating strategic trading in quantitative markets. Afterward, we selected 100 different shares in the real financial market to test these specifically proposed approaches. The experiment results show that CPPI-MADDPG and TIPP-MADDPG approaches generally outperform the conve
    

